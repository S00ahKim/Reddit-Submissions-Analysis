,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2016-6-3,2016,6,3,8,4m9xcb,No programming knowledge - what can I do?,https://www.reddit.com/r/tensorflow/comments/4m9xcb/no_programming_knowledge_what_can_i_do/,castles00,1464908631,"Hi all. Very interested in the possibilities here but have essentially zero programming knowledge (very, very little bit of Python). What can I do with TF? If I can't do anything yet, do you have recommendations for what to learn so that I can do some cool stuff with TF? I'm a newb and most likely an idiot, so apologies/thank you in advance =).",3,5
1,2016-6-4,2016,6,4,8,4mfotp,New to Tensorflow - trying to repurpose an MNIST multilayer network to a calculator,https://www.reddit.com/r/tensorflow/comments/4mfotp/new_to_tensorflow_trying_to_repurpose_an_mnist/,Deinos_Mousike,1464996488,"Could someone help or guide me through what I should do better in order for this to work? 

I changed the number of inputs to 2 and generated some random data, ""x1"" and ""x2"" (one number to be added to another). The idea is to use variables ""add"" and ""mul"" as the real output and base the cost (variable ""Y"") off of that, but I'm having trouble manipulating the data so it inputs properly.

I tried to make another variable with

x = tf.Variable([100 * np.random.random_sample([100]), 100 * np.random.random_sample([100]))

and a few other alternative ways, but that caused errors. Also, if there's anything else wrong in my code, please critique it! Anything helps.

Edit: made some small edits so the code makes more sense and is consistent in inputting two variables from the feed_dict into the optimizer and pred, to replace the two placeholders ""X1"" and ""X2"", however, it still doesn't work. 

Thank you.



    '''
    A Recurrent Neural Network implementation example using TensorFlow Library.
    
    Author: Deinos_Mousike
    '''
    
    import numpy as np
    import tensorflow as tf
    from tensorflow.models.rnn import rnn, rnn_cell
    # import matplotlib.pyplot as plt
    # from mpl_toolkits.mplot3d import Axes3D
    
    # Parameters
    training_iters = 1000
    n_epochs       = 1000
    batch_size     = 128
    display_step   = 100
    learning_rate  = 0.001
    
    n_observations = 100
    n_input        = 2   # Input data (Num + Num)
    n_steps        = 28  # timesteps
    n_hidden_1     = 256 # 1st layer number of features
    n_hidden_2     = 256 # 2nd layer number of features
    n_classes      = 1   # Output
    
    X  = tf.placeholder(""float"", [None, n_input])
    X1 = tf.placeholder(tf.float32)
    X2 = tf.placeholder(tf.float32)
    Y  = tf.placeholder(tf.float32)
    
    # Random input data
    x1 = 100 * np.random.random_sample([100,])
    x2 = 100 * np.random.random_sample([100,])
       
    add = tf.add(X1, X2)
    mul = tf.mul(X1, X2)
    
    weights = {
        'hidden1': tf.Variable(tf.random_normal([n_input,    n_hidden_1])),
        #'hidden2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),
        'out':     tf.Variable(tf.random_normal([n_hidden_1,  n_classes]))
    }
    
    biases = {
        'hidden1': tf.Variable(tf.random_normal([n_hidden_1])),
        #'hidden2': tf.Variable(tf.random_normal([n_hidden_2])),
        'out':     tf.Variable(tf.random_normal([n_classes]))
    }
    
    def RNN(_X1, _X2, _weights, _biases):
    
        # Layer 1.1
        layer_1 = tf.add(tf.matmul(_X1, weights['hidden1']), biases['hidden1'])
        layer_1 = tf.nn.relu(layer_1)
        # Layer 1.2
        # layer_1_2 = tf.add(tf.matmul(_X2, weights['hidden2']), biases['hidden2'])
        # layer_1_2 = tf.nn.relu(layer_1_2)
        # Hidden layer with RELU activation
        layer_2   = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])
    
        output    = tf.nn.relu(layer_2)
    
        return output
    
    pred         = RNN(X1, X2, weights, biases)
    cost         = tf.reduce_sum(tf.pow(pred - Y, 2)) / (n_observations - 1)
    optimizer    = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer
    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y,1))
    
    init     = tf.initialize_all_variables()
    # initData = tf.initialize_variables(x1.all(), x2.all())
    
    with tf.Session() as sess:
        # Here we tell tensorflow that we want to initialize all
        # the variables in the graph so we can use them
        sess.run(init)
    
        # Fit all training data
        prev_training_cost = 0.0
    
        for epoch_i in range(n_epochs) :
            for (_x1) in x1:
                for (_x2) in x2:
                    print(""Input 1:"")
                    print(_x1)
                    print(""Input 2:"")
                    print(_x2)
                    print(""Add function: "")
                    print(sess.run(add, feed_dict={X1: x1, X2: x2}))
                    y =   sess.run(add, feed_dict={X1: x1, X2: x2})
                    print(y)
                    sess.run(optimizer, feed_dict={X1: _x1, X2: _x2, Y: y})
                
    
            training_cost = sess.run(
                cost, feed_dict={X: xs, Y: ys})
            print(training_cost)
    
            if epoch_i % 20 == 0:
                ax.plot(X1, X2, pred.eval(
                    feed_dict={X1: _x1, X2: _x2, Y: y}, session=sess),
                        'k', alpha=epoch_i / n_epochs)
                fig.show()
                plt.draw()
    
            # Allow the training to quit if we've reached a minimum
            if np.abs(prev_training_cost - training_cost) &lt; 0.000001:
                break
            prev_training_cost = training_cost
    ",0,3
2,2016-6-6,2016,6,6,5,4mp9s3,Tensor Builder - A light wrapper over TensorFlow that enables you to easily create complex deep neural networks using the Builder Pattern through a functional fluent immutable API.,https://www.reddit.com/r/tensorflow/comments/4mp9s3/tensor_builder_a_light_wrapper_over_tensorflow/,cgarciae,1465158834,,0,6
3,2016-6-9,2016,6,9,15,4n9iej,New to TesorFlow - NLP in TensorFlow,https://www.reddit.com/r/tensorflow/comments/4n9iej/new_to_tesorflow_nlp_in_tensorflow/,Vibhu27,1465452035,[removed],0,1
4,2016-6-10,2016,6,10,2,4nbv8o,how to run distributed tensorflow test?,https://www.reddit.com/r/tensorflow/comments/4nbv8o/how_to_run_distributed_tensorflow_test/,xyd1989,1465493087,"Is there anyone successfully run the distributed mnist example from tensorflow repository?
link here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dist_test

I tried to run the script dist_mnist_test.sh in script/ folder like this:
bash dist_mnist_test.sh ""grpc://localhost0:2222 grpc://localhost1:2222""

And I got error message like this:

E0609 14:53:07.430440599   62872 tcp_client_posix.c:173]     failed to connect to 'ipv4:127.0.0.1:2223': socket error: connection refused
E0609 14:53:07.445297934   62873 tcp_client_posix.c:173]     failed to connect to 'ipv4:127.0.0.1:2224': socket error: connection refused

Any idea of what's going on?
Thanks.",0,2
5,2016-6-10,2016,6,10,5,4ncndz,Graphing an ROC curve for an image recognition application,https://www.reddit.com/r/tensorflow/comments/4ncndz/graphing_an_roc_curve_for_an_image_recognition/,dthiagar,1465502767,"Hi all,

I've altered the cifar-10 code a little bit to recognize 1 specific object, and now I'd like to graph the ROC curve to evaluate the model - how would I go about doing this? I know there's a method in the sklearn module, but I'm not sure how to apply it syntactically.

More specifically, I know that the main part of the classification happens in the following line of code:
```top_k_op = tf.nn.in_top_k(logits, labels, 1)```

Where can I vary the threshold associated with the ROC curve, and then actually plot it?

Thanks for the help!",0,3
6,2016-6-10,2016,6,10,11,4ne77s,High-level Learn Module in TensorFlow,https://www.reddit.com/r/tensorflow/comments/4ne77s/highlevel_learn_module_in_tensorflow/,terrytangyuan,1465524519,,0,3
7,2016-6-14,2016,6,14,12,4nzen6,Inputting Image Data into TensorFlow for Unsupervised Deep Learning,https://www.reddit.com/r/tensorflow/comments/4nzen6/inputting_image_data_into_tensorflow_for/,mwakanosya,1465873356,,1,2
8,2016-6-14,2016,6,14,23,4o1lhq,Has anyone used SyntaxNet with a Python program?,https://www.reddit.com/r/tensorflow/comments/4o1lhq/has_anyone_used_syntaxnet_with_a_python_program/,[deleted],1465913883,[deleted],0,1
9,2016-6-16,2016,6,16,10,4ob06u,Classifying category of tweet,https://www.reddit.com/r/tensorflow/comments/4ob06u/classifying_category_of_tweet/,SomeRandomBuddy,1466042250,"Noob trigger. What's the high level heuristic of using tensorflow to categorize tweets? Say I have 100k tweets about event A. Hundred k event B. So on so forth. What CNN do I use? How often do I train it?

How do I get data into tensorflow? Can i link it to hadoop or do i only need to train data in batches (eg after new data comes in)?

Is it better to use word based or char based tokenization?

Go soft on me :)",0,1
10,2016-6-17,2016,6,17,22,4oja6u,How does Tensorflow build graphs in memory without the slow-down common in interpreted languages like python?,https://www.reddit.com/r/tensorflow/comments/4oja6u/how_does_tensorflow_build_graphs_in_memory/,criticalcontext,1466171054,"Tensorflow has the user build a graph in memory through function calls to a C interface. It then (presumably) builds an in-memory graph and passes data between internal functions until an output is found.

I created a similar system called [GoFlow](http://www.github.com/ryanpeach/goflow) where users create a graph like in LabVIEW to run normal code via function calls (I wrote this so an AI I am designing could write code or logic diagrams in-memory via function calls easily). However, the boiler-plate of this slows down simple function calls from the assembly break-neck speed of 10~ns to about 1000x measuring in 10s of ms (again, normal for an interpreted language like python).

How does Tensorflow get around this limitation? The only way I can think of is by writing the code entirely in pre-processor script and then basically compiling it.",1,5
11,2016-6-19,2016,6,19,20,4osyzf,Tensorflow:GPU Server docker image,https://www.reddit.com/r/tensorflow/comments/4osyzf/tensorflowgpu_server_docker_image/,whiteshadow13,1466336470,"Hi there,
I have been searching for a bit, but could not find an docker image for grpc_tensorflow_server with GPU support. Only found the typical tensorflow docker images exposed with jupyter. 
Anyone aware if something like this is available?",0,1
12,2016-6-24,2016,6,24,0,4phadv,TF gpu memory usage on non-evaluated tensors,https://www.reddit.com/r/tensorflow/comments/4phadv/tf_gpu_memory_usage_on_nonevaluated_tensors/,Dref360,1466695705,"Hi,
I would like to know if tensors defined but not evaluated take memory on the GPU.
My use-case is that I want to define metrics like accuracy,recall,etc.
Let's say I have my train_op and I define an accuracy op (children of my train_op so not evaluated if I call train_op)

If I do sess.run(train_op,..) does the accuracy op still gets loaded on the gpu?

Thanks",0,2
13,2016-6-26,2016,6,26,7,4pumvk,Q: Has anyone come across a model that sorts/ranks photos based on aesthetics?,https://www.reddit.com/r/tensorflow/comments/4pumvk/q_has_anyone_come_across_a_model_that_sortsranks/,bossjones,1466892218,"Hi friends,

New to this subreddit, but it's good to be here. I'm hoping to find a model that can help me sort through thousands of photos I've taken with my DSLR and help me determine which ones are the most aesthetically ""pleasing"". Having the ability to rank photos would help tremendously with figuring out which photos are worth touching up/editing in photoshop etc. I know the people over at [petapixel](http://petapixel.com/2016/05/31/trained-algorithm-predict-makes-beautiful-photo/) have done something like this and made it into an iOS app, but being able to run something like that programmatically on a arbitrary set of images would be awesome.

Thanks in advance!",0,4
14,2016-6-26,2016,6,26,21,4pxlhx,Custom Optimizer in tensorfow?,https://www.reddit.com/r/tensorflow/comments/4pxlhx/custom_optimizer_in_tensorfow/,shaleenx,1466944921,[removed],0,1
15,2016-6-27,2016,6,27,7,4pzypb,Any TensorFlow books available?,https://www.reddit.com/r/tensorflow/comments/4pzypb/any_tensorflow_books_available/,o-rka,1466978563,I like reading O'Reilly programming books but they don't have one on TensorFlow.  I e-mailed them and they don't have any plans for making one any time soon.  I found one book https://www.amazon.com/Getting-Started-TensorFlow-Giancarlo-Zaccone-ebook/dp/B01H1JD6JO/ref=sr_1_7?ie=UTF8&amp;qid=1466972535&amp;sr=8-7&amp;keywords=tENSORFLOW but couldn't find a PDF.  Can anyone recommend any books? Preferably with a PDF available. ,6,14
16,2016-6-28,2016,6,28,1,4q42po,Is there a way to get a console in windows (docker)?,https://www.reddit.com/r/tensorflow/comments/4q42po/is_there_a_way_to_get_a_console_in_windows_docker/,homestead_cyborg,1467043262,"Hi, you may already understand what I am asking. I'm hosting jupyter with the official TF docker image, and I am editing the notebook  in my browser. I often want to examine objects in the ipython console, but have yet to find a way. Anyone know if there is a way to do this? ",2,2
17,2016-6-29,2016,6,29,20,4qexsy,tf.Tensor` as a Python `bool` is not allowed,https://www.reddit.com/r/tensorflow/comments/4qexsy/tftensor_as_a_python_bool_is_not_allowed/,Vibhu27,1467198304,[removed],0,1
18,2016-6-30,2016,6,30,23,4qlz9v,Wide &amp; Deep Learning: Better Together with TensorFlow,https://www.reddit.com/r/tensorflow/comments/4qlz9v/wide_deep_learning_better_together_with_tensorflow/,fhoffa,1467297259,,0,1
