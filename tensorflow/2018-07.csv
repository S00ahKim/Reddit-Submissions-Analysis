,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-7-2,2018,7,2,0,8vags8,I made a tool to label long and repetitive videos by showing multiple clips simultaneously on screen. It's called MuViLab. What do you think?,https://www.reddit.com/r/tensorflow/comments/8vags8/i_made_a_tool_to_label_long_and_repetitive_videos/,ale152,1530457412,,1,7
1,2018-7-2,2018,7,2,12,8vfoay,Does the backpropagation through time in LSTM apply truncate bptt?,https://www.reddit.com/r/tensorflow/comments/8vfoay/does_the_backpropagation_through_time_in_lstm/,Laurence-Lin,1530503821,"In the optimizer that update the LSTM in tensorflow, does the BPTT apply truncate BPTT or full BPTT?  
If is applies truncate BPTT, how does the code decide the truncate time lag?  


Thanks a lot!  
",0,3
2,2018-7-2,2018,7,2,15,8vgi7a,4 Sequence Encoding Blocks You Must Know Besides RNN/LSTM in Tensorflow  Han Xiao Tech Blog,https://www.reddit.com/r/tensorflow/comments/8vgi7a/4_sequence_encoding_blocks_you_must_know_besides/,h_xiao,1530513246,,2,7
3,2018-7-3,2018,7,3,1,8vjrkz,Getting Started with TensorFlow.js: Linear Regression,https://www.reddit.com/r/tensorflow/comments/8vjrkz/getting_started_with_tensorflowjs_linear/,tristansokol,1530547344,,0,8
4,2018-7-3,2018,7,3,17,8vqosw,Advice about ubuntu 18.04 and tf,https://www.reddit.com/r/tensorflow/comments/8vqosw/advice_about_ubuntu_1804_and_tf/,pemens,1530608191,"Hello guys! Have been working for 1.5 year on ubuntu 16.04 with tf and full stack for AI, 

but all has an and, and system died without possible recovery. How does 18.04 and tf feels?

Don't have problems with installing all packages and libraries, processing at all? 

Thanks for it :3",5,2
5,2018-7-3,2018,7,3,20,8vre0m,Ideas for medicine,https://www.reddit.com/r/tensorflow/comments/8vre0m/ideas_for_medicine/,fatal_quantum_error,1530616679,"While learning about the use of tensorflow in retinal imaging for identification of diabethic retinopathy I was wondering if there are any other applications. Does anyone of you know of areas in medicine, where some minor/major problems could maybe be tackled by AI with tensorflow?",5,3
6,2018-7-4,2018,7,4,2,8vu1y2,Managed/hosted 1080Ti GPU rentals for ML/TenserFlow,https://www.reddit.com/r/tensorflow/comments/8vu1y2/managedhosted_1080ti_gpu_rentals_for_mltenserflow/,adopshire2016,1530638695,"Hello,

I run a sizable GPU mining farm with hundreds of 1080Ti GPUs used primarily for cryptocurrency mining.

We recently started looking into diversifying our revenue channels by introducing custom server builds with stronger CPUs and RAM and larger HDs to be attractive for machine learning. We got some interest from video rendering projects but not machine learning.

Is there any interest in this type of service? If so, what price points and hardware considerations would make this attractive?",11,4
7,2018-7-5,2018,7,5,22,8wad82,face-api.js - Analysis of usage TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/8wad82/faceapijs_analysis_of_usage_tensorflowjs/,ArturSkowronski,1530796694,https://medium.com/@ArturSkowronski/github-all-stars-2-face-api-js-f3d6f135f4f7,0,9
8,2018-7-6,2018,7,6,23,8wkmjq,Some initial efforts for idris on tf,https://www.reddit.com/r/tensorflow/comments/8wkmjq/some_initial_efforts_for_idris_on_tf/,doofin,1530888293,,0,2
9,2018-7-7,2018,7,7,6,8wnvex,Load GloVe embeddings as a TensorFlow GPU Layer [NLP],https://www.reddit.com/r/tensorflow/comments/8wnvex/load_glove_embeddings_as_a_tensorflow_gpu_layer/,GChe,1530912391,,1,3
10,2018-7-7,2018,7,7,18,8wrx4d,Should I create a GUI for creating Tensorflow models?,https://www.reddit.com/r/tensorflow/comments/8wrx4d/should_i_create_a_gui_for_creating_tensorflow/,kite_and_code,1530954217,"Currently, I am evaluating some Master thesis topics. One of the proposals is:

\- Create a GUI for creating Tensorflow models with data flow graphical programming (similar to Rapidminer).

\- After the model phase, the Tensorflow code can be ejected and you can integrate it in your existing workflow.

\- Also, the library will be Open Source.

What do you think about it? Is creating your graphs from code a problem worth solving/improving? Why or why not?

I am looking forward to your suggestions!",32,10
11,2018-7-8,2018,7,8,10,8wxyiu,seq2seq model with MultiRNN and AttentionWrapper: dimension mismatch between LSTM's input and kernel,https://www.reddit.com/r/tensorflow/comments/8wxyiu/seq2seq_model_with_multirnn_and_attentionwrapper/,EthanPhan,1531012210,"\[TF 1.8\]

First of all, I know this kind of question may not appropriate in this sub but I don't know anywhere else to ask (I posted it on stackoverflow but it seem to reach no one's interest)

I'm trying to build a seq2seq model for a toy chatbot to learn tensorflow and deep learning using LSTM, sampled softmax loss, tf.contrib.seq2seq.LuongAttention, beamsearch with the internal representation of 128 dimension. I was able to train my model when there was only 1 layer of LSTM. Now I try 2 layers of LSTM using MultiRNN I get the following error while building the graph:

`ValueError: Dimensions must be equal, but are 384 and 256 for 'rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/MatMul_2' (op: 'MatMul') with input shapes: [64,384], [256,512].`

This is my model:

`class ChatBotModel:`

`def __init__(self, inferring=False, batch_size=1, use_sample_sofmax=True):`

`""""""forward_only: if set, we do not construct the backward pass in the model.`

`""""""`

`print('Initialize new model')`

`self.inferring = inferring`

`self.batch_size = batch_size`

`self.use_sample_sofmax = use_sample_sofmax`

`def build_graph(self):`

`# INPUTS`

`self.X = tf.placeholder(tf.int32, [None, None])`

`self.Y = tf.placeholder(tf.int32, [None, None])`

`self.X_seq_len = tf.placeholder(tf.int32, [None])`

`self.Y_seq_len = tf.placeholder(tf.int32, [None])`

`self.gl_step = tf.Variable(`

`0, dtype=tf.int32, trainable=False, name='global_step')`

`single_cell = tf.nn.rnn_cell.BasicLSTMCell(128)`

`keep_prob = tf.cond(tf.convert_to_tensor(self.inferring, tf.bool), lambda: tf.constant(`

`1.0), lambda: tf.constant(0.8))`

`single_cell = tf.contrib.rnn.DropoutWrapper(`

`single_cell, output_keep_prob=keep_prob)`

`encoder_cell = tf.contrib.rnn.MultiRNNCell([single_cell for _ in range(2)])`

`# ENCODER`         

`encoder_out, encoder_state = tf.nn.dynamic_rnn(`

`cell = encoder_cell,` 

`inputs = tf.contrib.layers.embed_sequence(self.X, 10000, 128),`

`sequence_length = self.X_seq_len,`

`dtype = tf.float32)`

`# encoder_state is ((cell0_c, cell0_h), (cell1_c, cell1_h))`

`# DECODER INPUTS`

`after_slice = tf.strided_slice(self.Y, [0, 0], [self.batch_size, -1], [1, 1])`

`decoder_inputs = tf.concat( [tf.fill([self.batch_size, 1], 2), after_slice], 1)`

`# ATTENTION`

`attention_mechanism = tf.contrib.seq2seq.LuongAttention(`

`num_units = 128,` 

`memory = encoder_out,`

`memory_sequence_length = self.X_seq_len)`

`# DECODER COMPONENTS`

`Y_vocab_size = 10000`

`decoder_cell = tf.contrib.rnn.MultiRNNCell([single_cell for _ in range(2)])`

`decoder_cell = tf.contrib.seq2seq.AttentionWrapper(`

`cell = decoder_cell,`

`attention_mechanism = attention_mechanism,`

`attention_layer_size=128)`

`decoder_embedding = tf.Variable(tf.random_uniform([Y_vocab_size, 128], -1.0, 1.0))`

`projection_layer = CustomDense(Y_vocab_size)`

`if self.use_sample_sofmax:`

`softmax_weight = projection_layer.kernel`

`softmax_biases = projection_layer.bias`

`if not self.inferring:`

`# TRAINING DECODER`

`training_helper = tf.contrib.seq2seq.TrainingHelper(`

`inputs = tf.nn.embedding_lookup(decoder_embedding, decoder_inputs),`

`sequence_length = self.Y_seq_len,`

`time_major = False)`

`decoder_initial_state = decoder_cell.zero_state(self.batch_size, dtype=tf.float32).clone(`

`cell_state=encoder_state)`

`training_decoder = tf.contrib.seq2seq.BasicDecoder(`

`cell = decoder_cell,`

`helper = training_helper,`

`initial_state = decoder_initial_state,`

`output_layer = projection_layer`

`)`

`training_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(`

`decoder = training_decoder,`

`impute_finished = True,`

`maximum_iterations = tf.reduce_max(self.Y_seq_len))`

`training_logits = training_decoder_output.rnn_output`

`# LOSS`

`softmax_loss_function = None`

`if self.use_sample_sofmax:`

`def sampled_loss(labels, logits):`

`labels = tf.reshape(labels, [-1, 1])`

`return tf.nn.sampled_softmax_loss(weights=softmax_weight,`

`biases=softmax_biases,`

`labels=labels,`

`inputs=logits,`

`num_sampled=64,`

`num_classes=10000)`

`softmax_loss_function = sampled_loss`

`masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(self.Y_seq_len), dtype=tf.float32)`

`self.loss = tf.contrib.seq2seq.sequence_loss(logits = training_logits, targets = self.Y, weights = masks, softmax_loss_function=softmax_loss_function)`

`# BACKWARD`

`params = tf.trainable_variables()`

`gradients = tf.gradients(self.loss, params)`

`clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)`

`self.train_op = tf.train.AdamOptimizer().apply_gradients(zip(clipped_gradients, params), global_step=self.gl_step)`

`else:`

`encoder_states = []`

`for i in range(2):`

`if isinstance(encoder_state[i],tf.contrib.rnn.LSTMStateTuple):`

`encoder_state_c = tf.contrib.seq2seq.tile_batch(encoder_state[i].c, multiplier=2)`

`encoder_state_h = tf.contrib.seq2seq.tile_batch(encoder_state[i].h, multiplier=2)`

`encoder_state = tf.contrib.rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)`

`encoder_states.append(encoder_state)`

`encoder_states = tuple(encoder_states)`

`predicting_decoder = tf.contrib.seq2seq.BeamSearchDecoder(`

`cell = decoder_cell,`

`embedding = decoder_embedding,`

`start_tokens = tf.tile(tf.constant([2], dtype=tf.int32), [self.batch_size]),`

`end_token = 3,`

`initial_state = decoder_initial_state,`

`beam_width = 2,`

`output_layer = projection_layer,`

`length_penalty_weight = 0.0)`

`predicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(`

`decoder = predicting_decoder,`

`impute_finished = False,`

`maximum_iterations = 4 * tf.reduce_max(self.Y_seq_len))`

`self.predicting_logits = predicting_decoder_output.predicted_ids`

Tracing back a few lines of log and I saw that the error occurs here:

`/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py in call(self, inputs, state)`

`636` 

`637     gate_inputs = math_ops.matmul(`

`--&gt; 638         array_ops.concat([inputs, h], 1), self._kernel)`

`639     gate_inputs = nn_ops.bias_add(gate_inputs, self._bias)`

I have checked the 'h' tensor of the LSTM cell and it has the shape of \[batch\_size, 128\] so my guess is that the attention output from the previous decoding step is concatenated with the current encoder's input make the 'inputs' has the shape of \[batch\_size, 256\] then it is concatenated with 'h' tensor to form a \[batch\_size, 384\] tensor causing this error.

My question is: Isn't attention output supposed to be concatenated with the next decoder's input or I miss understanding anything? And how to fix this error.",1,7
12,2018-7-9,2018,7,9,7,8x564e,"NoodleFeet Can Now Recognize his First Object, his Favorite Stuffed Animal ""Fisty"" (using TensorFlow)!",https://www.reddit.com/r/tensorflow/comments/8x564e/noodlefeet_can_now_recognize_his_first_object_his/,spetku,1531087224,,0,18
13,2018-7-9,2018,7,9,13,8x86qg,ML patterns and tools recommendation for answering user texts,https://www.reddit.com/r/tensorflow/comments/8x86qg/ml_patterns_and_tools_recommendation_for/,prayagupd,1531110936,"I'm learning ML and see if ML fits into my problem where I am trying to answer user question.

Let's say
user asks: I am having **headache** since yesterday and **fever** as well. what shall I do?
bot: (go and read a book) and reply back a blob of relevant answer. (wondering how can I make that much intelligent)

**OR** potentially I train the bot with (pre-processed) features and target labels.

For the pre-processing, I have to extract the parameters from user texts using NLP then store the data in MySQL or somewhere and then train/evaluate from there. `treatment` actually comes another set of logs which is a mapping of `usertext to treatment`

For example,

    symptom1    | symptom2    | gender  | treatment (label: huge text)
    headache    | fever       | M       | do blah blah, and blah blah
    headache    | fever       | F       | do something, and blah blah
    ...

**What ML patterns and tools do you guys see and recommend in similar scenario as mentioned above.** I am wondering if I can use tensorflow to train and find the treatment label but it does not really feel like prediction problem. As long as I extract parameters using NLP, it feels more of if else to me. than ML, I mean I could solve it using `if (symtom1 &amp;&amp; symtom2) then treatment1` and so on.
",0,1
14,2018-7-10,2018,7,10,19,8xnr5r,How do I set is_training on resnet,https://www.reddit.com/r/tensorflow/comments/8xnr5r/how_do_i_set_is_training_on_resnet/,VirtualHat,1531218535,"I'm training a model from scratch that processes video segments.  I'm using the built in slim resnet model, but have it wired to some LSTM units.  I'm having trouble with the is_training parameter in resnet.  It seems I must set this when creating the model, but I want to be able to switch in and out of training modes while I'm training (i.e. for validation etc), is this possiable?


",2,1
15,2018-7-11,2018,7,11,0,8xpz3j,Error in Compiling the CPU Module for Python,https://www.reddit.com/r/tensorflow/comments/8xpz3j/error_in_compiling_the_cpu_module_for_python/,fifo_thekid,1531235062,"System information

Have I written custom code: No

OS Platform and Distribution: Windows 10 64bit

TensorFlow installed from: Latest master source

TensorFlow version: commit dfcec82

Python version: 3.6.5

CMake version: 3.12.0-rc2

MS C+_+ Compiler version: 19.00.24234.1

CPU model and memory: i5-4460 with 16GB of RAM

Exact command to reproduce:

1- Opening Developer Command Line as admin

2- Choosing the 65bit compiler

""C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\Common7\Tools\vsdevcmd\ext\vcvars.bat"" amd64

3- cd D:\opencv\tensorflow\tensorflow\contrib\cmake\build

4- cmake .. -A x64 -T host=x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=D:/opencv/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=""C:/Users/FiFo/AppData/Local/Programs/Python/Python36/python.exe"" -DPYTHON_LIBRARIES=""C:/Users/FiFo/AppData/Local/Programs/Python/Python36/libs/python36.lib"" -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2 -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_BUILD_PYTHON_TESTS=OFF -Dtensorflow_BUILD_MORE_PYTHON_TESTS=OFF -Dtensorflow_BUILD_CC_EXAMPLE=ON -Dtensorflow_BUILD_PYTHON_BINDINGS=ON -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_OPTIMIZE_FOR_NATIVE_ARCH=ON -Dtensorflow_ENABLE_MKL_SUPPORT=ON -Dtensorflow_ENABLE_MKLDNN_SUPPORT=ON -Dtensorflow_VERBOSE=ON -Dtensorflow_BUILD_SHARED_LIB=ON

5- MSBuild /p:Configuration=Release ALL_BUILD.vcxproj SUCCESS

6- MSBuild /p:Configuration=Release INSTALL.vcxproj SUCCESS

7- MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj

Fails with:

Generating init.py files for Python API.

Traceback (most recent call last):

File ""D:\opencv\tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper return importlib.import_module(mname)

File ""C:\Users\FiFo\AppData\Local\Programs\Python\Python36\lib\importlib_init_.py"", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)

File """", line 994, in _gcd_import File """", line 971, in _find_and_load File """", line 955, in _find_and_load_unlocked File """", line 658, in _load_unlocked File """", line 571, in module_from_spec File """", line 922, in create_module File """", line 219, in _call_with_frames_removed ImportError: DLL load failed: No foi possvel encontrar o mdulo especificado.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

File ""D:\opencv\tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\python\pywrap_tensorflow.py"", line 58, in from tensorflow.python.pywrap_tensorflow_internal import *

File ""D:\opencv\tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in _pywrap_tensorflow_internal = swig_import_helper()

File ""D:\opencv\tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper return importlib.import_module('pywrap_tensorflow_internal')

File ""C:\Users\FiFo\AppData\Local\Programs\Python\Python36\lib\importlib_init.py"", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)

ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

Failed to load the native TensorFlow runtime.

It used to work before with version 1.8

I don't want to install the PIP version

Compilation works without any problem on Ubuntu 16.04",0,1
16,2018-7-11,2018,7,11,0,8xqe2u,A dive into the deep end of deep neural networks for recommender engines.,https://www.reddit.com/r/tensorflow/comments/8xqe2u/a_dive_into_the_deep_end_of_deep_neural_networks/,cptAwesome_070,1531237606,,0,4
17,2018-7-12,2018,7,12,21,8y9c5l,I want to experiment around with game theory where simulated actors live and interact with each other. Would TensorFlow be good for that?,https://www.reddit.com/r/tensorflow/comments/8y9c5l/i_want_to_experiment_around_with_game_theory/,dog_superiority,1531398573,"I've been perusing the TensorFlow web page a little, and it seems that a lot of the tutorials and examples have to do with image recognition stuff.  I'm wondering how suitable it would be for a game theory simulation.

What I would like to do is have a bunch of ""people"" interact with each other on a 2D board where they build stuff, trade stuff, fight each other, etc.  If they don't eat, they get hungry.  If they do that too long, they die.  That sort of thing.  I'd like to have where I can turn it on in the morning let the dudes do their thing while learning as they go, and come home from work and see how they did.  Are they all dead?  Did they all run away forever?  Did they build a futuristic society like that one episode of the Simpsons?

Basically, I am wondering if TensorFlow is something I should consider using for this.  Any pointers on where to start would be helpful.  

(BTW, I code a lot in C++, some in Python, and did Java a lot several years ago.  In case that is important)",13,0
18,2018-7-13,2018,7,13,14,8yh9ki,A complete guide for building machine learning and deep learning solutions using Tensorflow,https://www.reddit.com/r/tensorflow/comments/8yh9ki/a_complete_guide_for_building_machine_learning/,vinnyvessel,1531459481,,0,1
19,2018-7-14,2018,7,14,16,8yrmh9,how do you set weights for RNN cells?,https://www.reddit.com/r/tensorflow/comments/8yrmh9/how_do_you_set_weights_for_rnn_cells/,extra_bigass_fries,1531553572,"The TF website documentation clearly lists methods for setting weights for every type of cell, and yet, invoking them gives error ""no attribute set_weights"".",1,1
20,2018-7-15,2018,7,15,10,8yy37h,Simple Equation in TF?,https://www.reddit.com/r/tensorflow/comments/8yy37h/simple_equation_in_tf/,throwaway775849,1531617132,"For pairs of training data (x,y), how would you code this in Tensorflow?

    f(m_i, x) = y, m_i+1



",4,0
21,2018-7-15,2018,7,15,14,8yzgal,"I'm having this issue whenever I run (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() from the tutorial. How do I fix this?",https://www.reddit.com/r/tensorflow/comments/8yzgal/im_having_this_issue_whenever_i_run_train_images/,AusCro,1531631590,,3,3
22,2018-7-15,2018,7,15,19,8z0wtk,Issues with Save and Restoring Model,https://www.reddit.com/r/tensorflow/comments/8z0wtk/issues_with_save_and_restoring_model/,stealthx9,1531651690,"Hi,

i have the following issue and i hope there is somebody out there who can help me.

I can train my model and i can see the accuracy getting better. I am saving my model every 10 epochs. 

But when i stop the learning process, and restore the model to continue learning, the accuracy suddenly drops much lower then it was when i saved the model.  (None of the Training/Testdata is changing - so i am sure it must be an issue of save and restore)

WHen somebody can hint me in the right direction i would very much appreciate it!

    
    class XModel():
        def __init__(self, num_inputs, num_outputs, hidden_layers=[30,25,15], model=''):
            self.num_inputs = num_inputs
            self.num_outputs = num_outputs
            self.model = model
            # Placeholder
            self.X = tf.placeholder(dtype=tf.float32, shape=[None, num_inputs], name=""X"")
            self.Y = tf.placeholder(dtype=tf.float32, shape=[None, num_outputs], name=""Y"")
    
            # 1ST LAYER
            self.W1 = tf.Variable(tf.random_normal([num_inputs, hidden_layers[0]]), name=""W1"")
            self.b1 = tf.Variable(tf.random_normal([hidden_layers[0]]), name=""b1"")
            # # # 2ND LAYER
            self.W2 = tf.Variable(tf.random_normal([hidden_layers[0], hidden_layers[1]]), name=""W2"")
            self.b2 = tf.Variable(tf.random_normal([hidden_layers[1]]), name=""b2"")
            # # # 2ND LAYER
            self.W3 = tf.Variable(tf.random_normal([hidden_layers[1], hidden_layers[2]]), name=""W3"")
            self.b3 = tf.Variable(tf.random_normal([hidden_layers[2]]), name=""b3"")
            # # # OUTPUT LAYER
            self.Wout = tf.Variable(tf.random_normal([hidden_layers[2], num_outputs]), name=""Wout"")
            self.bout = tf.Variable(tf.random_normal([num_outputs]), name=""bout"")
    
            self.hidden_1 = tf.nn.relu(tf.add(tf.matmul(self.X, self.W1), self.b1))
            self.hidden_2 = tf.nn.relu(tf.add(tf.matmul(self.hidden_1, self.W2), self.b2))
            self.hidden_3 = tf.nn.relu(tf.add(tf.matmul(self.hidden_2, self.W3), self.b3))
    
            self.logits = tf.add(tf.matmul(self.hidden_3, self.Wout), self.bout, name='logits')
            self.train_prediction = tf.nn.softmax(self.logits, name='train_prediction')
            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.Y, logits=self.logits), name='loss')
            self.opt = tf.train.GradientDescentOptimizer(0.02).minimize(self.loss)
    
        def fit(self, train_data, train_labels, test_data, test_labels):
            saver = tf.train.Saver()
            with tf.Session() as sess:
                if os.path.exists(""{0}.index"".format(self.model)):
                    try:
                        saver.restore(sess, self.model)
                        print(""Model restored: {0}"".format(self.model))
                    except:
                        print(""Model could not be loaded, starting fresh."")
                else:
                    print(""Initializing Model"")
                    sess.run(tf.initialize_all_variables())
    
                num_epochs = 1000
                batch_size = 128
                for e in range(num_epochs):
    
                    shuffle_indices = np.random.permutation(np.arange(len(train_labels)))
                    train_data = train_data[shuffle_indices]
                    train_labels = train_labels[shuffle_indices]
    
                    # Batch Training
                    for i in range(0, len(train_labels) // batch_size):
                        batch_data = train_data[i * batch_size:(i + 1) * batch_size]
                        batch_labels = train_labels[i * batch_size:(i + 1) * batch_size]
                        _, l = sess.run([self.opt, self.loss], feed_dict={self.X: batch_data, self.Y: batch_labels})
    
                    # PrintOut Epoche Results
                    l_train, predictions_train = sess.run([self.loss, self.train_prediction],
                                                          feed_dict={self.X: train_data, self.Y: train_labels})
                    l, predictions = sess.run([self.loss, self.train_prediction], feed_dict={self.X: test_data, self.Y: test_labels})
                    print(""Ep: {0:4d}\tT_Loss: {1:8.5f}\tT_Acc: {2:4.2f}%\tTR_Loss: {3:8.5f}\tTR_Acc: {4:4.2f}%"".format(
                        e, np.sum(l), accuracy(predictions, test_labels),
                        np.sum(l_train), accuracy(predictions_train, train_labels)))
    
                    if (e &gt; 0) and (e % 10) == 0:
                        saver.save(sess, self.model)
                        print(""Model saved: {0}"".format(self.model))

loading the model:

    model = XModel(train_data.shape[1], train_labels.shape[1],model='models/netA.ckpt')
    model.fit(train_data, train_labels, test_data, test_labels)",2,5
23,2018-7-16,2018,7,16,16,8z8v88,Could I get some insights for my REINFORCE implementation ?,https://www.reddit.com/r/tensorflow/comments/8z8v88/could_i_get_some_insights_for_my_reinforce/,UpstairsCurrency,1531725453,"Hey there ! 

I'm rather a PyTorch user usually, but recently, I came to realize that some of the tools provided by Tensorflow are lacking in PyTorch, so I decided to try and implement some of my favorite algorithms in TF. 

So here I am, writing a REINFORCE agent for the classic CartPole environment. I can't spot any obvious mistake, but my agent doesn't learn anything. Could someone please help me out on this ? 

Here's the link: https://github.com/Mehd6384/QuickExperiments/blob/master/reinforce_tf.py

Thanks a lot ! 

",0,1
24,2018-7-16,2018,7,16,21,8zaga1,Shape mismatch issue with tf.js - tips?,https://www.reddit.com/r/tensorflow/comments/8zaga1/shape_mismatch_issue_with_tfjs_tips/,Berlinsk,1531743684,"Hi, I'm getting my head around tensorflow and am trying to get this CNN for timeseries analysis example by Siraj Raval working, but I keep getting this error on fit() and evaluate() that I can't get rid of.

The layer stack is a sequential setup with a conv, pool, conv, pool, dense structure.

No matter how I change the parameters of the layers, I get the following error message:

""Error: Error when checking target: expected dense\_Dense1 to have shape \[,57,10\], but got array with shape \[1,1960,1\].""

Link to project page: [https://github.com/llSourcell/Financial\_Forecasting\_with\_TensorflowJS](https://github.com/llSourcell/Financial_Forecasting_with_TensorflowJS)

The data and labels are structured as one array of 1960 entries with one dimension each.

The layer shapes look like this:

INPUT SHAPE ,1960,1 OUTPUT SHAPE ,931,8  
INPUT SHAPE ,931,8 OUTPUT SHAPE ,216,8  
INPUT SHAPE ,216,8 OUTPUT SHAPE ,212,16  
INPUT SHAPE ,212,16 OUTPUT SHAPE ,57,16  
INPUT SHAPE ,57,16 OUTPUT SHAPE ,57,10

initialised like this:

        const model = tf.sequential()
        model.add(tf.layers.conv1d({
          inputShape: [data.dates.length, 1],
          kernelSize: 100,
          filters: 8,
          strides: 2,
          activation: 'relu',
          kernelInitializer: 'VarianceScaling'
        }))
        model.add(tf.layers.maxPooling1d({
          poolSize: [500],
          strides: [2]
        }))
        model.add(tf.layers.conv1d({
          kernelSize: 5,
          filters: 16,
          strides: 1,
          activation: 'relu',
          kernelInitializer: 'VarianceScaling'
        }))
        model.add(tf.layers.maxPooling1d({
          poolSize: [100],
          strides: [2]
        }))
        model.add(tf.layers.dense({
          units: 10,
          kernelInitializer: 'VarianceScaling',
          activation: 'softmax'
        }))

If I inspect the model structure, it all seems correctly connected and I can't see anything that's off.

I'm keen on using this model for a prototype project involving timeseries data for a client, but just got stuck here.

If anyone has any tips on where to read about these kinds of issues and could point me in the right direction, I'd be very grateful.",12,4
25,2018-7-17,2018,7,17,0,8zblej,"Does the Dataset api support ""get"" without ""get_next""?",https://www.reddit.com/r/tensorflow/comments/8zblej/does_the_dataset_api_support_get_without_get_next/,st8ic,1531753248,"I have a list of numpy arrays which are my dataset. Right now I'm using `feed_dict`, but of course it is very slow so I'm looking to move to the Dataset api.  

My problem is that I don't want to iterate through the samples on every run of graph op. I want to run an operation with one sample until I'm satisfied, and then move to the next one. The problem is that the dataset api seems to only provide access to the data in the form of `get_next`, which will automatically move the iterator.  

Is there a way to only move the iterator when I'm ready, instead of every time I run an op?",3,1
26,2018-7-17,2018,7,17,17,8zja3z,Realtime JavaScript Face Tracking and Face Recognition using face-api.js MTCNN Face Detector - Medium,https://www.reddit.com/r/tensorflow/comments/8zja3z/realtime_javascript_face_tracking_and_face/,Fewthp,1531814755,,0,6
27,2018-7-17,2018,7,17,23,8zlj74,seq2seq in tensorflow.js?,https://www.reddit.com/r/tensorflow/comments/8zlj74/seq2seq_in_tensorflowjs/,LightBlueParadox,1531837295,"Hi, I'm new to machine learning so if I'm saying something stupid, you know why.

I'd like to make a chatbot using with my whatsapp chats, I used LSTM (in ml5.js), but it just replied with random answers without context.

I've read online that I should use seq2seq, but i also need to run the model in the browser.

I also want to switch to tensorflow.js, so I can learn more stuff about ML, so can i use it to train seq2seq models?",2,1
28,2018-7-17,2018,7,17,23,8zlmlr,Text Classification Models in TensorFlow,https://www.reddit.com/r/tensorflow/comments/8zlmlr/text_classification_models_in_tensorflow/,ganji1055,1531838007,"Implemented famous text classification models in TensorFlow: [https://github.com/dongjun-Lee/text-classification-models-tf](https://github.com/dongjun-Lee/text-classification-models-tf) Implemented models are 1) Word-level CNN, 2) Character-level CNN 3) VDCNN(Very Deep CNN) 4) Word-level Bidirectional RNN 5) Attention-based Bidirectional RNN, 6) RCNN

Semi-supervised Learning for Text Classification(Transfer Learning) is implemented at: [https://github.com/dongjun-Lee/transfer-learning-text-tf](https://github.com/dongjun-Lee/transfer-learning-text-tf)

Here, auto-encoder or language model is used as a pre-trained model to initialize LSTM text classification model.

I hope it helps! Thanks!",1,8
29,2018-7-18,2018,7,18,3,8znvre,How do I use heightwise and widthwise convolutional layers on tensorflow?,https://www.reddit.com/r/tensorflow/comments/8znvre/how_do_i_use_heightwise_and_widthwise/,marrrvvv,1531853263,"I am asking this question under the assumption that in the convolutional, layer defined in tf.layers.conv2d, each node uses the same weights in the filter for all of its inputs. If i am wrong about this, please correct me.

I am trying to build a CNN whose input image has certain pieces of information guaranteed to appear in certain spots of the image. I tried to do it with the convolutional layer defined in tf.layers.conv2d, but didn't accomplished what I meant to. I believe I would have more chances of succeed using a convolutional layer that uses different filters heightwise and widthwise. I tried to find said layer on the tensorflow documentation page, but I only found a depthwise implementation.

Can someone suggest me a way to do this on tensorflow?",1,1
30,2018-7-20,2018,7,20,2,9081ay,tf.estimator: How to normalize features in TensorFlow,https://www.reddit.com/r/tensorflow/comments/9081ay/tfestimator_how_to_normalize_features_in/,crawles89,1532022255,,0,8
31,2018-7-20,2018,7,20,17,90e6qi,Help with tensor containing Boolean values,https://www.reddit.com/r/tensorflow/comments/90e6qi/help_with_tensor_containing_boolean_values/,the_shape89,1532074499,"I'm trying to create an incremental classifier that will get trained on data containing n classes for some set number of epochs, then n+m classes for a set number of epochs, then n+m+k, etc, where each successive set of classes contains the previous set as a subset.

In order to do this without having to train the model, save it, manually edit the graph, re-train, repeat, I'm simply defining all the weights I will need to classify the entire set of classes, but keeping the weights corresponding to unseen classes frozen at 0 until the classifier is introduced to those classes. 

My strategy for this is to define a placeholder that is fed in an array of Boolean values defining whether or not some given set of weights are trainable. 

Relevant code below:

output\_train = tf.placeholder(tf.int32, shape = (num\_incremental\_grps), name = ""output\_train"")

.

.

.

weights = \[\]

biases = \[\]

for i in range(num\_incremental\_grps):

W = tf.Variable(tf.zeros(\[batch\_size, classes\_per\_grp\]), trainable=tf.cond(tf.equal(output\_train\[i\], tf.constant(1)),           
lambda: tf.constant(True), lambda: tf.constant(False)))

weights.append(W)

b = tf.Variable(tf.zeros(\[classes\_per\_grp\]), trainable=tf.cond(tf.equal(output\_train\[i\], tf.constant(1)), lambda:   
tf.constant(True), lambda: tf.constant(False)))

biases.append(b)

out\_weights = tf.stack(weights, axis=1).reshape((batch\_size, -1))

out\_biases = tf.stack(biases, axis=1).reshape((batch\_size, -1))

outputs = tf.identity(tf.matmul(inputs, out\_weights) + out\_biases, name='values')

.

.

.

output\_trainable = np.zeros(num\_incremental\_grps, dtype=bool)

for i in range(num\_incremental\_grps):

output\_trainable\['output':False\]

.

.

.

with tf.Session() as sess:

   init.run()

   for epoch in range(epochs):

for iteration in range(iterations):

X\_batch, y\_batch = batch.getBatch()

fd={X: X\_batch, y: y\_batch, training: True, output\_train: output\_trainable}

\_, loss\_val = sess.run(\[training\_op, loss\], feed\_dict=fd)

This returns the error message

Using a \`tf.Tensor\` as a Python \`bool\` is not allowed. Use \`if t is not None:\` instead of \`if t:\` to test if a tensor is defined,   
and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.

I've tried tinkering around with this, like making the initial placeholder datatype tf.bool instead of tf.int32, but something else seems to be going on and I have no idea what.",0,1
32,2018-7-20,2018,7,20,17,90e8tn,Question about using tensor of Boolean values,https://www.reddit.com/r/tensorflow/comments/90e8tn/question_about_using_tensor_of_boolean_values/,the_shape89,1532075269,"I'm trying to create an incremental classifier that will get trained on data containing n classes for some set number of epochs, then n+m classes for a set number of epochs, then n+m+k, etc, where each successive set of classes contains the previous set as a subset.

In order to do this without having to train the model, save it, manually edit the graph, re-train, repeat, I'm simply defining all the weights I will need to classify the entire set of classes, but keeping the weights corresponding to unseen classes frozen at 0 until the classifier is introduced to those classes.

My strategy for this is to define a placeholder that is fed in an array of Boolean values defining whether or not some given set of weights are trainable.

Relevant code below:

    output_train = tf.placeholder(tf.int32, shape = (num_incremental_grps), name = ""output_train"")
    .
    .
    .
    weights = []
    biases = []
    for i in range(num_incremental_grps):
        W = tf.Variable(tf.zeros([batch_size, classes_per_grp]),         
        trainable=tf.cond(tf.equal(output_train[i], tf.constant(1)),lambda: tf.constant(True), 
            lambda: tf.constant(False)))
        weights.append(W)
        b = tf.Variable(tf.zeros([classes_per_grp]), trainable=tf.cond(tf.equal(output_train[i], 
        tf.constant(1)), lambda:tf.constant(True), lambda: tf.constant(False)))
        biases.append(b)
    
    out_weights = tf.stack(weights, axis=1).reshape((batch_size, -1))
    out_biases = tf.stack(biases, axis=1).reshape((batch_size, -1))
    outputs = tf.identity(tf.matmul(inputs, out_weights) + out_biases, name='values')
    .
    .
    .
    output_trainable = np.zeros(num_incremental_grps, dtype=bool)
    for i in range(num_incremental_grps):
        output_trainable['output':False]
    .
    .
    .
    with tf.Session() as sess:
        init.run()
        for epoch in range(epochs):
            for iteration in range(iterations):
                X_batch, y_batch = batch.getBatch()
                fd={X: X_batch, y: y_batch, training: True, output_train: output_trainable}
                _, loss_val = sess.run([training_op, loss], feed_dict=fd)

This returns the error message

    Using a 'tf.Tensor' as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined,and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.

I've tried tinkering around with this, like making the initial placeholder datatype tf.bool instead of tf.int32, but something else seems to be going on and I have no idea what. Any help would be much appreciated.",2,1
33,2018-7-20,2018,7,20,20,90fac0,Real-time learning w/ tensorflow,https://www.reddit.com/r/tensorflow/comments/90fac0/realtime_learning_w_tensorflow/,ddzhulay,1532087101,"Hey :)  I'm just interested is there any other (better) way to train model online with new data, than storing new samples locally and retraining?",4,2
34,2018-7-21,2018,7,21,20,90osbx,A Simpe Neural network with Tensorflow-Keras using Colaboratory,https://www.reddit.com/r/tensorflow/comments/90osbx/a_simpe_neural_network_with_tensorflowkeras_using/,machinelearning147,1532174266,,0,9
35,2018-7-21,2018,7,21,22,90pg8k,"How many variable updates per batch using a convolutional layer? One per conv. x,y position of the kernel?",https://www.reddit.com/r/tensorflow/comments/90pg8k/how_many_variable_updates_per_batch_using_a/,kit_hod_jao,1532181429,"Hi, I wondered if someone could answer this question for me. I've not been able to find the answers in the documentation. 

I've got a network with two inputs of dissimilar size. One input is passed to a convolutional layer (specifically tf.nn.conv2d). The other to a non-convolutional layer (tf.layers.dense). 

My question is about balancing the learning rates of the conv and non conv layers, because this could affect the performance of my algorithm. 

For the purpose of the example let's say the output of the conv layer is:

 [b, h,w, d]

This means the conv kernel, ie the variable being learned, is applied at w * h positions per batch sample, or b * w * h times in total over a whole batch.

What I'm not clear on is how many weight updates are applied. I'm assuming that the gradients are averaged over the batch - are they averaged over the w and h as well? Or does it perform w*h updates per batch?

Depending on the answer to the above, do I need to increase the non-conv learning rate by w * h to make the two learn at the same rate?

I don't really care that they are exactly the same (I'm using Adam anyways), but I don't want to introduce a systematic bias on relative learning rate that depends on the size of the convolutional layer. 

Any help much appreciated.  Cheers!",5,4
36,2018-7-22,2018,7,22,6,90si1s,Signing With Alexa: A DIY Experiment in AI Accessibility,https://www.reddit.com/r/tensorflow/comments/90si1s/signing_with_alexa_a_diy_experiment_in_ai/,trcytony,1532206891,,0,1
37,2018-7-22,2018,7,22,12,90v4lm,Can adding dropout decrease training accuracy when the code runs well without dropout,https://www.reddit.com/r/tensorflow/comments/90v4lm/can_adding_dropout_decrease_training_accuracy/,2Ran3Sel,1532231473,"Hello!

I am testing my CNN code on CIFAR-10 images.

I used three conv layers, two maxpool layers, and one dense layer.

Without dropout, the code reaches 100% training accuracy at 300-400 epoch and shows 50-60% of testing accuracy with a new dataset- even though I'm not sure 60% of testing accuracy can be called 'working well.' --&gt; Here is the code: [https://gist.github.com/AudieLee/e4e51695df1b29ef8e34b6e3e45e9bb9](https://gist.github.com/AudieLee/e4e51695df1b29ef8e34b6e3e45e9bb9)

But when I add a dropout in a dense layer, the training accuracy decreases to around 12%(60-&gt;12%...?), a plataeu, despite hours of running. --&gt; Here is the code: [https://gist.github.com/AudieLee/ee3aaa3090eb21f0a072904ae798686d](https://gist.github.com/AudieLee/ee3aaa3090eb21f0a072904ae798686d)

Given the fact that the code runs without dropout, I thought the preprocessing and the structure themselves weren't problem, so I tried changing epoch, learning rate, strides, and keep\_prob. But none worked.

What am I supposed to do?

Thank you.",8,2
38,2018-7-22,2018,7,22,14,90vpwa,Latest TensorFlow Release 1.9 is Out! Let us upgrade,https://www.reddit.com/r/tensorflow/comments/90vpwa/latest_tensorflow_release_19_is_out_let_us_upgrade/,DecipherTechnic,1532238415,,1,15
39,2018-7-22,2018,7,22,22,90xuli,"[Q] Cross Entropy Implementation Tensorflow, Wierd Behavior.",https://www.reddit.com/r/tensorflow/comments/90xuli/q_cross_entropy_implementation_tensorflow_wierd/,Jonas_SV,1532267338,"I've implemented CEM in tensorflow https://github.com/JonasRSV/CEM_Tensorflow

While training it on the cartpole AIGym i noticed wierd behavior. 

https://imgur.com/a/oLK01Yo 
https://imgur.com/a/v4pA4PQ

After each training epoch i sample new weights for each agent using https://www.tensorflow.org/api_docs/python/tf/distributions/Normal

All agents share means and std deviation across each of their weights and after sample'ing fitnesses for all agents i take the top X percent and calculate new means and std-deviations for each weigth. 

The wierd behavior arises when i sample new std-dev and means for each weights. 

As seen on the graphs above every 2'nd sample has very high mean and variance and every 2'nd has very low mean and variance.. 

What's also interesting is that the fitness of the best agent correlates exactly to these spikes aswell.. when the mean and variance spikes so does the fitness and vice-versa.. 

Any insights as to what i've done wrong in my implementation or any other ideas would be super appreciated! :) ",4,3
40,2018-7-23,2018,7,23,8,911yfp,What are the pros and cons of the different installation methods?,https://www.reddit.com/r/tensorflow/comments/911yfp/what_are_the_pros_and_cons_of_the_different/,pgbabse,1532301011,"Hello, I want to reinstall tensorflow and wanted to know what the advantages or disadvantages between the different methods are. 

As tensorflow is an api for python, it affects the python environment.
Could someone elaborate what the difference are between:

Tensorflow/Python pip installer

Tensorflow/Python anaconda installer

Tensorflow/Python in virtual environments

Tensorflow/Python in Docker image",2,6
41,2018-7-23,2018,7,23,9,912dwq,I am new to programming and trying to install tensorflow models repo,https://www.reddit.com/r/tensorflow/comments/912dwq/i_am_new_to_programming_and_trying_to_install/,PhoebusElpollo,1532304763,"I followed the steps in the tutorial, with the python classify image.py, but i keep getting the error ImportantError: Could not find 'cudart64_90.dll. I have installed CUDA 9.0, but I can't find the cudart thing",4,4
42,2018-7-24,2018,7,24,2,918vu5,Beginner dataset for photo classification?,https://www.reddit.com/r/tensorflow/comments/918vu5/beginner_dataset_for_photo_classification/,newwenha,1532365733,"Beginner here following Google's Tensorflow tutorial. It has photo classification for 5 different types of flowers. I want to see other applications and was wondering if there is a free dataset of already sorted pictures in jpeg (boy/girl, races, animals, etc). Thanks!",4,2
43,2018-7-24,2018,7,24,12,91dxld,"Are you interested in Computer Science and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/tensorflow/comments/91dxld/are_you_interested_in_computer_science_and_want/,ailearn12,1532403465,,0,9
44,2018-7-26,2018,7,26,13,91zb6n,Tensor back into std::vector in C++?,https://www.reddit.com/r/tensorflow/comments/91zb6n/tensor_back_into_stdvector_in_c/,magkum123,1532580940,Is anyone aware of how can I convert the data of a tensor into a std::vector efficiently? or even naively?,0,5
45,2018-7-26,2018,7,26,22,922c9w,What shape for images?,https://www.reddit.com/r/tensorflow/comments/922c9w/what_shape_for_images/,greenbluewhite,1532612390,"I am using TF with the Inception\_V3 model to recognize interesting scenes from a surveilance camera.  The raw images are about 430x240 pixels, an aspect ratio of 1.8:1.   My understanding is that Inception wants images 299x299 pixels.  My code currently resizes the images to 299x166 thus preserving the aspect ratio.  It does work, but I wonder if instead *stretching* the images vertically to 299x299 would make better use of the CNN and thus give better accuracy.  Or does it already do this internally?

So far my training material is 24,000 images in 10 categories.  16,000 of those are in the 'nothing' category, meaning that nothing interesting is in the picture - just the yard, street, trees, and shadows.  My current problem is that the shadows are being recognized as objects like ""car"", ""people walking by"" etc.  It is very good at spotting the mail truck, which is large and white, and can distinguish it from the garbage truck, which is larger and grey.",0,3
46,2018-7-28,2018,7,28,7,92gt6u,Binary classification tutorials/documentation,https://www.reddit.com/r/tensorflow/comments/92gt6u/binary_classification_tutorialsdocumentation/,imjacobclark,1532728849,"Could soembody point me in the right direction to some good quality binary classification tutorials? Ideally ones that don't focus on image classification but more on text based feature classification e.g things like the Titanic dataset. 

Thanks ",1,0
47,2018-7-28,2018,7,28,18,92kysf,Can someone please explain what is happening in the Tensorflow playground?,https://www.reddit.com/r/tensorflow/comments/92kysf/can_someone_please_explain_what_is_happening_in/,lakshaydulani,1532770696,"[playground.tensorflow.org](https://hashnode.com/util/redirect?url=https://playground.tensorflow.org/)

I am a ML beginner.  I can understand some basics in the playground like all the layers are  working to classify in different directions i.e horizontal, vertical,  slant.

But still it would be better if someone can write a post which can walkthru newbies with the basic nit bits of whats happening in there?",2,5
48,2018-7-28,2018,7,28,22,92m357,Understanding Tensorflow's tensors shape: static and dynamic,https://www.reddit.com/r/tensorflow/comments/92m357/understanding_tensorflows_tensors_shape_static/,pgaleone,1532784222,,0,1
49,2018-7-29,2018,7,29,9,92qwn7,How do I create heatmaps with TensorFlow? What do I search to develop something to get something like the middle part of the image?,https://www.reddit.com/r/tensorflow/comments/92qwn7/how_do_i_create_heatmaps_with_tensorflow_what_do/,thevbob,1532824575,,0,1
50,2018-7-29,2018,7,29,9,92qyys,Extracting 'heatmaps' with TensorFlow,https://www.reddit.com/r/tensorflow/comments/92qyys/extracting_heatmaps_with_tensorflow/,thevbob,1532825175,"Hello!   


I have successfully used a pretrained model to do object detection with tf.slim, and now I want to understand how the model works. Something I've seen that I want to do is to extract the 'heatmap', like the middle section of  the image abov.

https://i.redd.it/fby1usdo9sc11.png

What do I search in order to be able to extract something like it from the model I've used? The CNN should be specifically made and trained to export this info? I am a noob still, so I don't have the slightest idead of how this works haha  


Thanks in advance.",2,9
51,2018-7-29,2018,7,29,15,92stwd,Experimenting with Tensorflow.js,https://www.reddit.com/r/tensorflow/comments/92stwd/experimenting_with_tensorflowjs/,i_am_adl,1532844862,"Hello Everyone,

I have been experimenting on Tensorflow.js for sometime , I would like to Share my Learnings with the Community.

We know that An increasing number of developers are using TensorFlow in their machine learning projects. In March this year, the TensorFlow team at Google announced the arrival of the much-awaited JavaScript framework, TensorFlow.js (which was previously called DeepLearn.js).

Now developers can build lightweight models and run them in the browser using JavaScript. Lets understand what the need was for the development of this framework.

## History

Before going to TensorFlow.js, I would like to start off with TensorFlow.

TensorFlow was developed in 2011 at Google as their propitiatory library for Machine learning/Deep learning applications at Google. This library was open sourced in 2015 under the Apache License.

TensorFlow is built in C++, which enables the code to execute at a very low level. TensorFlow has bindings to different language like Python, R, &amp; Java. This enables TensorFlow to be used in these languages.

So, the obvious question is: what about JavaScript?

Conventionally, in JavaScript, ML/DL was performed by using an API. An API was made using some framework, and the model was deployed at the server. The client sent a request using JavaScript to get results from the server.

[Client Server Architecture](https://i.redd.it/n3p7iuiiotc11.png)

In 2017, a project called Deeplearn.js appeared, which aimed to enable ML/DL in JavaScript, without the API hassle.

But there were questions about speed. It was very well known that JavaScript code could not run on GPU. To solve this problem, WebGL was introduced. This is a browser interface to OpenGL. WebGL enabled the execution of JavaScript code on GPU.

In March 2018, the DeepLearn.js team got merged into the TensorFlow Team at Google and was renamed TensorFlow.js.

Watch the below video for further details:

[https://youtu.be/qa1OXssGBHw](https://youtu.be/qa1OXssGBHw)

## TensorFlow.js

Tensorflow.js provides two things:

* The CoreAPI, which deals with the low level code
* LayerAPI is built over the CoreAPI, and makes our lives easier by increasing the level of abstraction.

## Getting Started

There are two main ways to get TensorFlow.js in your project:

## 1. via &lt;script&gt;Tag

Add the following code to an HTML file:

    &lt;html&gt;
    &lt;head&gt;
      &lt;!-- Load TensorFlow.js --&gt;
        &lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.0""&gt; &lt;/script&gt;
      &lt;/head&gt;
        &lt;body&gt;
          Hello
      &lt;/body&gt;
    &lt;/html&gt;

## 2. viaNPM

Add TensorFlow.js to your project using yarn or npm.

    yarn add @tensorflow/tfjs  
    npm install @tensorflow/tfjs   

In your main js file:

    import * as tf from '@tensorflow/tfjs';   

## CoreAPI

## 1. Tensors

So, what is a Tensor?

[Visual Representation of Scalar,Vector,Matrix and Tensor](https://i.redd.it/5v3orjdpotc11.jpg)

* A scalar is a single number. For example, x = 1
* A vector is an array of numbers. For example, *x*=\[1,2\]
* A matrix is a 2-D array =&gt; (\[\[1, 2\],\[3, 4\],\[5, 6\]\])
* A tensor is a \*n-\*dimensional array with *n*\&gt;2

TensorFlow.js has utility functions for common cases like Scalar, 1D, 2D, 3D and 4D tensors, as well a number of functions to initialize tensors in ways useful for machine learning.

## Code Examples

**tf.tensor():**

    // Pass an array of values to create a vector.   
    tf.tensor([1, 2, 3, 4]).print();  

**tf.scalar():**

    tf.scalar(3.14).print();   

And so on

Watch the Below Video to get a deep insight into Tensors in TensorFlow.js:

[https://youtu.be/sZrwxnIfHCo](https://youtu.be/sZrwxnIfHCo)

## 2. Variables &amp; Operations

Tensors are immutable data structures. That means their values cant be changed once they are set.

However, tf.variable()is introduced in TensorFlow.js. The real use case for tf.variable()is when we need to change the data frequently, such as when adjusting model weights in Machine Learning.

Code sample:

    const x = tf.variable(tf.tensor([1, 2, 3]));   
    x.assign(tf.tensor([4, 5, 6]));  
     x.print();   

## Operations

There are various operations in TensorFlow.js. In order to perform mathematical computation on Tensors, we use operations. Tensors are immutable, so all operations always return new Tensors and never modify input Tensors. So tf.variable()can be used in order to save memory.

Lets look into some operations:

**tf.add()Adds two** [**tf.Tensor**](https://js.tensorflow.org/api/0.12.0/#class:Tensor)**s element-wise**

    const a = tf.tensor1d([1, 2, 3, 4]);   
    const b = tf.tensor1d([10, 20, 30, 40]);  
     a.add(b).print();  // or tf.add(a, b)   

There are many operations in TensorFlow.js. You can check the [documentation](https://js.tensorflow.org/api/0.12.0/#Operations)for other operations. I will demonstrate one more operation here: **tf.matmul()**

**tf.matmul()Computes the dot product of two matrices, A \* B.**

    const a = tf.tensor2d([1, 2], [1, 2]);   
    const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);  
    a.matMul(b).print();  // or tf.matMul(a, b)   

Watch the below video for deep insight into Variable and Operations:

[https://youtu.be/AP1BmP0BZmQ](https://youtu.be/AP1BmP0BZmQ)

## 3. Memory Management

Memory management is the key in Machine Learning/Deep Learning tasks, because they are generally computationally expensive.

TensorFlow.js provides two major ways to manage memory:

1. tf.dispose()
2. tf.tidy()

They both typically do the same thing, but they do it in different ways.

## tf.tidy()

This executes the provided function function and after it is executed, cleans up all intermediate tensors allocated by function except those returned by function.

tf.tidy() helps avoid memory leaks. In general, it wraps calls to operations in [tf.tidy()](https://js.tensorflow.org/api/0.12.0/#tidy) for automatic memory cleanup.

Code example:

    const y = tf.tidy(() =&gt; {
        // aa, b, and two will be cleaned up when the tidy ends.
    
        const two= tf.scalar(2); 
        const aa = tf.scalar(2); 
        const b = aa.square();
    
        console.log('numTensors (in tidy): ' + tf.memory().numTensors);
    
        // The value returned inside the tidy function will return // through the tidy,     in this case to the variable y. 
    
        return b.add(two); 
    });
    
    console.log('numTensors (outside tidy): ' + tf.memory().numTensors); y.print();
    tf.dispose()

Disposes any [tf.Tensor](https://js.tensorflow.org/api/0.12.0/#class:Tensor)s found within the mentioned object.

Code example:

    const two= tf.scalar(2);   
    two.dispose()   

## LayersAPI

Layers are the primary building block for constructing a ML/DL Model. Each layer will typically perform some computation to transform its input to its output. Under the hood, every layer uses the CoreAPI of Tensorflow.js.

Layers will automatically take care of creating and initializing the various internal variables/weights they need to function. So, basically it makes life easier by increasing the level of abstraction.

We will make a simple example feed forward network using the LayerAPI. The Feed Forward network we will build is as below:

*Processing gif cf4h6msywtc11...*

## Code:

**Index.html**

    &lt;html&gt;
    &lt;head&gt;
    &lt;title&gt;
    &lt;/title&gt;    
       &lt;script src=https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.0""&gt; &lt;/script&gt;
    &lt;script src=main.js type=text/javascript&gt;&lt;/script&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Tensorflow JS Demo
    &lt;/body&gt;
    &lt;/html&gt;

**main.js**

    const model = tf.sequential();
    
    //config for layer
    const config_hidden = {
      inputShape:[3],
      activation:'sigmoid',
      units:4
    }
    const config_output={
      units:2,
      activation:'sigmoid'
    }
    
    //defining the hidden and output layer
    const hidden = tf.layers.dense(config_hidden);
    const output = tf.layers.dense(config_output);
    
    //adding layers to model
    model.add(hidden);
    model.add(output);
    
    //define an optimizer
    const optimize=tf.train.sgd(0.1);
    
    //config for model
    const config={
    optimizer:optimize,
    loss:'meanSquaredError'
    }
    
    //compiling the model
    model.compile(config);
    
    console.log('Model Successfully Compiled');
    
    //Dummy training data
    const x_train = tf.tensor([
      [0.1,0.5,0.1],
      [0.9,0.3,0.4],
      [0.4,0.5,0.5],
      [0.7,0.1,0.9]
    ])
    
    //Dummy training labels
    const y_train = tf.tensor([
      [0.2,0.8],
      [0.9,0.10],
      [0.4,0.6],
      [0.5,0.5]
    ])
    
    //Dummy testing data
    const x_test = tf.tensor([
      [0.9,0.1,0.5]
    ])
    
    train_data().then(function(){
      console.log('Training is Complete');
      console.log('Predictions :');
      model.predict(x_test).print();
    })
    
    async function train_data(){
      for(let i=0;i&lt;10;i++){
      const res = await model.fit(x_train,y_train,epoch=1000,batch_size=10);
       console.log(res.history.loss[0]);
      }
    }

Output:

[Output of the Code](https://i.redd.it/x5cvtzivntc11.png)

Pls watch the below videos for deep insight and code explanation:

[https://youtu.be/z2u-s3NzHhY](https://youtu.be/z2u-s3NzHhY)

[https://youtu.be/lKWUSkwOR5s](https://youtu.be/lKWUSkwOR5s)

## My take onthis

This is excellent for coders who are familiar with JavaScript and are trying to find their way in the ML/DL world!

It makes things a lot simpler for people coming from a non-ML/DL background, but who are looking to understand this field. The use cases for this are many, and I personally think its something we need at the moment.

What do you think about TensorFlow.js? Let me know in the comments section below.

**Thanks For Reading and Giving your Precious Time**",1,10
52,2018-7-30,2018,7,30,12,930hiq,Multiple choice test questionnaire,https://www.reddit.com/r/tensorflow/comments/930hiq/multiple_choice_test_questionnaire/,ccfiel,1532919613,I want to be able to check answer sheets automatically. I myself created the questionnaire so I have the control over the format of the questionnaire and the answer sheet. The questionnaire is multiple choice type and the examinees will just shade the appropriate box corresponding to their answer. My idea is to scan or take a picture of the answer sheet and use TensorFlow to identify the answers selected by the examinees. The answer sheet is printed on paper. Is TensorFlow the right tool to achieve this? Any ideas are very much welcome. ,3,0
53,2018-7-30,2018,7,30,16,931x5d,ResourceExhaustedError that makes no sense,https://www.reddit.com/r/tensorflow/comments/931x5d/resourceexhaustederror_that_makes_no_sense/,ME_PhD,1532934404,"I'm using transfer learning from VGG in TF. I stripped the last layer and made my own small ones.

    fc7 = tf.contrib.layers.fully_connected(fc6, 16)
    fc7dropped = tf.nn.dropout(fc7, keep_prob=hold_p)
    yhat = tf.nn.softmax(tf.contrib.layers.fully_connected(fc7dropped, 2, activation_fn=None))

then my loss functions:

    losses = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=yhat)
    loss = tf.reduce_mean(losses)

Trains fine. When I do
    print(session.run(loss, feed_dict={x:x_train, y:y_train, hold_p:1.0}))

It works no problem. However, when I try
    print(session.run(yhat, feed_dict={x:x_train, hold_p:1.0}))

I get 
`ResourceExhaustedError: OOM when allocating tensor of shape [4096] and type float
	 [[Node: add_13/y = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [4096] values: -0.188697636 0.126556993 -0.29960382...&gt;, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]`

This makes no sense because to compute ""loss"" it must compute ""yhat"". Why would it work fine for ""loss"" but not for ""yhat""? I even lowered the batch size from 8 to 2 and I still get the same error. Can anyone figure it out?
",2,1
54,2018-7-30,2018,7,30,18,932s0q,Translation model with Dataset shape problem,https://www.reddit.com/r/tensorflow/comments/932s0q/translation_model_with_dataset_shape_problem/,albert1905,1532944705,"I'm trying to build a translation model, so I'm getting a text as input, I'm encoding him to a list of integers (the type of enocding is not important).so far so good.
let's say this is what I have so far.
&lt;class 'list'&gt;: [1645, 3, 205, 753, 753, 1332, 18, 7, 7, 24]

Now I want to do this lines:
ds = tf.data.Dataset.from_tensors(encoded_txt)
ds = ds.batch(32)
(btw why do we need the first line, just to be able to do the second?)

But from this lines I'm getting shape=(?,32) , and I don't understand why? I have a batch size of 32 and 10 numbers, why isnt it (1,32) (with paddings or something)???
This impacts me after on in the code, I really need to understand how to handle this.

btw just reshape isn't working :(

Thanks!",0,1
55,2018-7-30,2018,7,30,21,933glc,Concatenated ReLU (CReLU) the cause for slow performance?,https://www.reddit.com/r/tensorflow/comments/933glc/concatenated_relu_crelu_the_cause_for_slow/,MogwaiAllOnYourFace,1532952032,"I have implemented a semantic segmentation model, using CReLU on the first two downsampling layers, however when using CReLU inference speed drops massively.

FPS goes from approximately 42 to 12. 

CReLU doubles the number of output channels, however I take this into account and half the number of filters, such that the output is equal in dimension. It seems to me like this should be quicker, that is performing a positive and negative ReLU and concatenating them together, rather than calculating an increase in convolution filters.

I have tried looking for similar experiences but found nothing. Can anyone share any insight on this?",0,5
56,2018-7-30,2018,7,30,23,934c1b,GPU and bottlenecking?,https://www.reddit.com/r/tensorflow/comments/934c1b/gpu_and_bottlenecking/,T-O-M-52,1532959535,"Now iam I bit of a noob, I know but if I was using the GPU version of tensorflow  on a pc that has a great graphics card but just an old CPU and about 4gb of ram would my program still run fine? 
I only need the pc for tensorflow so the pc wouldn't need to be fast.
Thanks in advance.",8,1
57,2018-7-31,2018,7,31,0,934vuh,What's wrong w/ my GAN graph?,https://www.reddit.com/r/tensorflow/comments/934vuh/whats_wrong_w_my_gan_graph/,ddzhulay,1532963531,"Hey! I'm trying to train vanilla GAN without using tfgan (just for experience). I'm using minimax loss and quiet simple (not convolutional) architecture for my generator and discriminator. But after first three training steps my generator loss is nearby -1 (completely useless) and discriminator loss is almost 0. And I think that problem is in the graph, due to the fact that when I'm using tfgan.gan\_model with same generator, discriminator and loss functions I get great results. But I don't know where I've mistaken... :(",0,4
58,2018-7-31,2018,7,31,1,935puj,trying to design custom estimators,https://www.reddit.com/r/tensorflow/comments/935puj/trying_to_design_custom_estimators/,kei_kuro,1532969259,"In a pre-made Estimator, the general blueprints are:

1) define the feature\_columns

2) initialize the model using feature\_columns,

3) write an input\_fn which converts a data source such as a Dataset to a mapping of features and labels.

The feature\_columns are passed in as an argument to the pre-made Estimator. So far so good.

When I tried to make a custom Estimator, this control flow doesnt work anymore because model\_fn (step 2) requires feature\_columns (step 1) and features (step 3). Well, to be more precise, you pass in features as a parameter and use feature\_columns as a global variable or something, and the input layer requires both features and feature\_columns. I think in one tutorial they defined feature\_columns inside model\_fn, which is inconsistent with how the pre-made Estimators work.

Im planning to define a class to act as a wrapper around the Estimator. That way I can do something like:

```python
class Custom(tf.estimator.Estimator): 
    def \_\_init\_\_(self):
        self.feature\_columns = INITIALIZE HERE
        super().\_\_init\_\_(model\_fn=self.model\_fn)

    def model\_fn(self, features, labels, mode, params):
        net = input\_layer(features, self.feature\_columns)
        ...
```

Does this seem like a good idea, or am I missing something?",0,3
59,2018-7-31,2018,7,31,2,936azv,CNN Classifier tutorial,https://www.reddit.com/r/tensorflow/comments/936azv/cnn_classifier_tutorial/,imjacobclark,1532973203,"I'm looking for an example/tutorial of a CNN Classifier that does not work on images, but text based features and classifications. 

For example, I'm interested in seeing a TF CNN that works on a dataset similiar to the Titanic passengers dataset.",1,4
60,2018-7-31,2018,7,31,20,93dk5r,Tensorflow for AMD GPU?,https://www.reddit.com/r/tensorflow/comments/93dk5r/tensorflow_for_amd_gpu/,Jandevries101,1533035535,"Hey,

i have a AMD GPU is it then still possible for me to use tensorflows gpu version?

If so i know it should be done diffrent then the normal way, atleast from what i've heard.... 

any idea's?

Jan",6,1
61,2018-7-31,2018,7,31,20,93drtc,Can I get some help for the sequence prediction model lstm-based ?,https://www.reddit.com/r/tensorflow/comments/93drtc/can_i_get_some_help_for_the_sequence_prediction/,UpstairsCurrency,1533037673,"Hello, 

I'm trying to predict sequences using the LSTM modules of tensorflow, but to no avail. I can't figure out the problem and I was hoping someone could lend me a helpful hand. Here's my code: 

First I mostly create synthetic data, and prepare the dataloader


    import tensorflow as tf 
    import numpy as np 
    import matplotlib.pyplot as plt 
    plt.style.use('dark_background')

    x = np.linspace(0,30.,500)
    y = x*np.sin(x) + 2*np.sin(5*x)
    nb_steps = 20

    def load_batch(batch_size = 32): 

	    x_b = np.zeros((nb_steps,batch_size,1))
	    y_b = np.zeros((nb_steps*batch_size,1))

	    inds = np.random.randint(0, 479, (batch_size))
	    for i,ind in enumerate(inds): 
		    x_b[:,i,0] = x[ind:ind+nb_steps]
		    y_b[i*nb_steps:(i+1)*nb_steps,0] = y[ind+1:ind+nb_steps+1]

	    return x_b, y_b

Some shortcuts 


    adam = tf.train.AdamOptimizer
    layers = tf.layers
    dense = layers.dense
    lstm = tf.contrib.rnn.LSTMCell
    batch_size = 64

Then, comes the part where I create the model 


    with tf.variable_scope('data'): 

	    x_p = tf.placeholder(tf.float32, shape = [nb_steps, None, 1], name = 'x') # batch, steps, features 
	    y_p = tf.placeholder(tf.float32, shape = [None, 1], name = 'labels')

    with tf.variable_scope('network'): 

	    cell = lstm(num_units = 100)
	    outputs, states = tf.nn.dynamic_rnn(cell, x_p, dtype = tf.float32, time_major = True)


	    reshaped_outputs = tf.reshape(outputs, [-1,100])
	    projection = dense(reshaped_outputs, 1, activation = None, name = 'projection')

Just above is the part I'm the least certain of. I reshape the output of the lstm for each time step and stack them on the first axis (or do I ?). I then send the whole matrix in a linear layer. 



    with tf.variable_scope('training'): 

	    loss = tf.reduce_mean(tf.square(projection - y_p))
	    train_lstm = adam(1e-3).minimize(loss)


Afterward, the rest consits on running and plotting

  
    epochs = 1000
    batch_size = 64
    f, ax = plt.subplots(2,1)
    with tf.Session() as sess:

	    sess.run(tf.global_variables_initializer())

	    mean_loss = 0. 
	    for epoch in range(1,epochs+1): 


		    x_b,y_b = load_batch(batch_size)

		    batch_loss,_ = sess.run([loss, train_lstm], feed_dict = {x_p:x_b, y_p:y_b})

		    mean_loss += batch_loss
	
		    if epoch%100 == 0: 
			    print('Epoch: {} | Loss: {:.6f}'.format(epoch, mean_loss/100.))
			    mean_loss = 0. 

	    while True : 

		    x_b, y_b = load_batch(1)
		    pred = sess.run(projection, feed_dict = {x_p:x_b}).reshape(-1)

		    ax[0].plot(x,y, label= 'Real')
		    ax[0].plot(x_b.reshape(-1),y_b.reshape(-1), label= 'Real batch')
		    ax[0].plot(x_b.reshape(-1), pred, label = 'Pred')

		    ax[1].scatter(x_b.reshape(-1),y_b.reshape(-1), label= 'Real')
		    ax[1].scatter(x_b.reshape(-1), pred, label = 'Pred')

		    for a in ax: a.legend()

		    plt.pause(0.1)
		    input()

		    for a in ax: 
			    a.clear()

Thanks a lot ! ",1,3
