,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2019-3-1,2019,3,1,12,aw0854,Introducing TensorFlow Datasets,https://www.reddit.com/r/tensorflow/comments/aw0854/introducing_tensorflow_datasets/,SerkanKONAKCI,1551412460,[http://on.geeklearn.net/d40f0312a9](http://on.geeklearn.net/d40f0312a9),4,17
1,2019-3-1,2019,3,1,14,aw11nq,How do I save a Bi-LSTM layer from one computation graph and use it in another graph?,https://www.reddit.com/r/tensorflow/comments/aw11nq/how_do_i_save_a_bilstm_layer_from_one_computation/,cant-find-user-name,1551417769,"Hi, I am trying to perform Named entity recognition using Bi-LSTM-CRF network. One component of the network is a bi-lstm network, which learns character level embeddings. Since I have a lot more unlabelled data, I trained a seperate bi-lstm model on the data and learned a language model. 

I want to use the weights of this bi-lstm network to initialize the bi-lstm network in a seperate graph. How do I got about doing this? I know how to save and load tensorflow variables (I have used tf.sess.saver() for this purpose before), but I do not know how to do this for a bi-lstm network. (More specifically, tf.nn.bidirectional_dynamic_rnn with tf.contrib.rnn.LSTMCell).

Any help is very very appreciated. 
Thanks :) ",5,3
2,2019-3-1,2019,3,1,17,aw2jgj,Data Scientists: What are the biggest limitations of using Tensorboard for a team of 3 data scientists?,https://www.reddit.com/r/tensorflow/comments/aw2jgj/data_scientists_what_are_the_biggest_limitations/,treguess,1551429245,,0,0
3,2019-3-2,2019,3,2,9,awbrv0,"Problem with TensorFlow's ""Load Data"" tut.",https://www.reddit.com/r/tensorflow/comments/awbrv0/problem_with_tensorflows_load_data_tut/,caine2003,1551486614,,0,3
4,2019-3-2,2019,3,2,20,awh1ys,Confusion matrix with tensorhub,https://www.reddit.com/r/tensorflow/comments/awh1ys/confusion_matrix_with_tensorhub/,Noemi3,1551527629,Hi! I'm trying to do a confusion matrix with tensorhub of a tensorflow model with 4 input but I can't make it. Is there someone that can suggest me how can I do? Thanks so much ,2,4
5,2019-3-2,2019,3,2,21,awhadd,"Eorror when trying to install on Pi, any ideas?",https://www.reddit.com/r/tensorflow/comments/awhadd/eorror_when_trying_to_install_on_pi_any_ideas/,Redstoner7,1551529566,,3,3
6,2019-3-3,2019,3,3,16,awrwkz,What is the difference between these two code blocks?,https://www.reddit.com/r/tensorflow/comments/awrwkz/what_is_the_difference_between_these_two_code/,begooboi,1551599137,"I have two identical code blocks of gives error and other runs.

	with tf.Session as sess:
		sess.run(init_op)	
		d = {X: np.random.rand(100, 784)}
		print(sess.run(h, feed_dict=d))

This gives 

	Traceback (most recent call last):
	  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
	AttributeError: __exit__

But this code blocks which I copy pasted from a website works

	with tf.Session() as sess:
		# initialize variables
		sess.run(init_op)
		# create the dictionary:
		d = {X: np.random.rand(100, 784)}
		# feed it to placeholder a via the dict 
		print(sess.run(h, feed_dict=d))
",0,1
7,2019-3-3,2019,3,3,23,awu93c,Trouble feeding data into tensorflow graph,https://www.reddit.com/r/tensorflow/comments/awu93c/trouble_feeding_data_into_tensorflow_graph/,atinesh229,1551621908,"I have trained a neural network model on \`MNIST\` dataset using the script [mnist\_3.1\_convolutional\_bigger\_dropout.py](https://www.dropbox.com/s/mzrui1b46qx4zmz/mnist_3.1_convolutional_bigger_dropout.py?dl=0) provided in this [tutorial](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd/tree/master/tensorflow-mnist-tutorial).

&amp;#x200B;

I wanted to test the trained model on the custom dataset, hence I wrote a small script \`predict.py\` which loads the trained model and feed the data to it. I tried 2 methods for preprocessing images so that they are compatible with MNIST format.

&amp;#x200B;

* **Method 1**: Resizing the image to 28x28
* **Method 2**: Technique mentioned [here](https://www.youtube.com/watch?v=oYndcjlzwX8) is used

&amp;#x200B;

Both of these methods result in the error 

&amp;#x200B;

&gt;InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder\_2' with dtype float

&amp;#x200B;

The detailed error can be seen from [here](https://www.dropbox.com/s/zrnduvaxxi5hnbt/error.txt?dl=0)

&amp;#x200B;

\*\*[predict.py](https://predict.py)\*\*

        # Importing libraries
        from scipy.misc import imread
        import tensorflow as tf
        import numpy as np
        import cv2 as cv
        import glob
        
        from test import imageprepare
        
        files = glob.glob('data2/*.*')
        #print(files)
        
        # Method 1
        '''
        img_data = []
        for fl in files:
        	img = imageprepare(fl)
        	img = img.reshape(img.shape[0], img.shape[1], 1)
        	img_data.append(img)
        '''
        
        # Method 2
        dig_cont = [cv.imread(fl, 0) for fl in files]
        #print(len(dig_cont))
        
        img_data = []
        for i in range(len(dig_cont)):
        	img = cv.resize(dig_cont[i], (28, 28))
        	img = img.reshape(img.shape[0], img.shape[1], 1)
        	img_data.append(img)
        print(""Restoring Model ..."")
        
        sess = tf.Session()
        
        # Step-1: Recreate the network graph. At this step only graph is created.
        tf_saver = tf.train.import_meta_graph('model/model.meta')
        
        # Step-2: Now let's load the weights saved using the restore method.
        tf_saver.restore(sess, tf.train.latest_checkpoint('model'))
        
        print(""Model restored"")
        
        x = tf.get_default_graph().get_tensor_by_name('X:0')
        print('x :', x.shape)
        y = tf.get_default_graph().get_tensor_by_name('Y:0')
        print('y :', y.shape)
        
        dict_data = {x: img_data}
        
        result = sess.run(y, feed_dict=dict_data)
        print(result)
        print(result.shape)
        
        sess.close()

[test.py](https://www.dropbox.com/s/k7g28auhn6f6hoa/test.py?dl=0)",4,2
8,2019-3-4,2019,3,4,0,awv4it,Step by Step Guide to Tensorflow - A Free Video Course,https://www.reddit.com/r/tensorflow/comments/awv4it/step_by_step_guide_to_tensorflow_a_free_video/,prithvi45,1551627925,,1,26
9,2019-3-5,2019,3,5,4,axbf4p,Is it possible to export a checkpoint trained in Tensorflow 1.9 to Tensorflow 1.7 graph?,https://www.reddit.com/r/tensorflow/comments/axbf4p/is_it_possible_to_export_a_checkpoint_trained_in/,bboylayz,1551728828,"I'm new to TF and ML, so forgive me if I asked that question using the wrong terminology. I used Google Cloud to train an object detection model using Runtime 1.9, which according to this: [https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list), leverages Tensorflow 1.9.

&amp;#x200B;

However, I am attempting to get image detection working in a Unity project, and their TFSharp lib only supports up to TF1.7. The problem is, Google Cloud deprecated support for training a TF1.7. So unless I train on my own machines, I can only get checkpoints in 1.8 or higher.  


Long story short, I have these files:

model.ckpt-159557.data-00000-of-00003

model.ckpt-159557.data-00001-of-00003

model.ckpt-159557.data-00002-of-00003

model.ckpt-159557.index

model.ckpt-159557.meta

&amp;#x200B;

What can I do from here, if anything, to export a graph.pb (or even better, bytes, since Unity requires a .bytes file) that is ""trained using Tensorflow 1.7?""",0,1
10,2019-3-5,2019,3,5,10,axfc6f,Anaconda Spyder import tensorflow as tf not working,https://www.reddit.com/r/tensorflow/comments/axfc6f/anaconda_spyder_import_tensorflow_as_tf_not/,SuperJMan64,1551749859,"So I installed Anaconda and tensorflow Spyder, but I can't get import tensorflow as tf to work. There are a lot of different answers and so I just wanted to figure out the one I want. This is the error:

&amp;#x200B;

In \[9\]: runfile('C:/Users/jedwa/Anaconda3/envs/tensorflow/lib/imp.py', wdir='C:/Users/jedwa/Anaconda3/envs/tensorflow/lib')

Traceback (most recent call last):

&amp;#x200B;

  File ""&lt;ipython-input-9-a50a85bb1782&gt;"", line 1, in &lt;module&gt;

runfile('C:/Users/jedwa/Anaconda3/envs/tensorflow/lib/imp.py', wdir='C:/Users/jedwa/Anaconda3/envs/tensorflow/lib')

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\spyder\_kernels\\customize\\[spydercustomize.py](https://spydercustomize.py)"", line 786, in runfile

execfile(filename, namespace)

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\spyder\_kernels\\customize\\[spydercustomize.py](https://spydercustomize.py)"", line 110, in execfile

exec(compile([f.read](https://f.read)(), filename, 'exec'), namespace)

&amp;#x200B;

  File ""C:/Users/jedwa/Anaconda3/envs/tensorflow/lib/imp.py"", line 1, in &lt;module&gt;

import tensorflow as tf;

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\\_\_init\_\_.py"", line 24, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow  # pylint: disable=unused-import

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\\_\_init\_\_.py"", line 49, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 74, in &lt;module&gt;

raise ImportError(msg)

&amp;#x200B;

ImportError: Traceback (most recent call last):

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 58, in &lt;module&gt;

from tensorflow.python.pywrap\_tensorflow\_internal import \*

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 28, in &lt;module&gt;

\_pywrap\_tensorflow\_internal = swig\_import\_helper()

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 24, in swig\_import\_helper

\_mod = imp.load\_module('\_pywrap\_tensorflow\_internal', fp, pathname, description)

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\[imp.py](https://imp.py)"", line 243, in load\_module

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\[imp.py](https://imp.py)"", line 343, in load\_dynamic

ImportError: DLL load failed: The specified module could not be found.

&amp;#x200B;

&amp;#x200B;

Failed to load the native TensorFlow runtime.

&amp;#x200B;

See [https://www.tensorflow.org/install/errors](https://www.tensorflow.org/install/errors)

&amp;#x200B;

for some common reasons and solutions.  Include the entire stack trace

above this error message when asking for help.",4,3
11,2019-3-5,2019,3,5,14,axhlbn,"When making an Xcode app with tflite, is there an option to actually take the phot, and then get the prediction?",https://www.reddit.com/r/tensorflow/comments/axhlbn/when_making_an_xcode_app_with_tflite_is_there_an/,jimmothytheunicorn,1551764724,"I need it that way, all I have is the instant detector at the corner of the screen...",0,1
12,2019-3-5,2019,3,5,15,axhvqv,Hyperbolic N-Space embeddings,https://www.reddit.com/r/tensorflow/comments/axhvqv/hyperbolic_nspace_embeddings/,kousun12,1551766794,"I still think hyperbolic geometry is hasn't been appreciated enough in the ML world, following the first few papers by [facebook research](https://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations). Here's an implementation of some basic functions to support the Poincare model for word embeddings in TF. Lorentz model coming eventually...

[https://github.com/kousun12/tf\_hyperbolic](https://github.com/kousun12/tf_hyperbolic)",0,2
13,2019-3-6,2019,3,6,7,axrgdd,Gradient boosted trees in TensorFlow,https://www.reddit.com/r/tensorflow/comments/axrgdd/gradient_boosted_trees_in_tensorflow/,crawles89,1551826577,,4,13
14,2019-3-6,2019,3,6,8,axrj1l,Create tensor with averages of each column?,https://www.reddit.com/r/tensorflow/comments/axrj1l/create_tensor_with_averages_of_each_column/,Yogi_DMT,1551826973,I have a numpy array with data that has a few columns. Is there an easy way to get a tensor in which each value of a particular column is the average of that column's original values.,2,1
15,2019-3-6,2019,3,6,18,axx5oi,How do you run a copy of a model on each GPU for inference?,https://www.reddit.com/r/tensorflow/comments/axx5oi/how_do_you_run_a_copy_of_a_model_on_each_gpu_for/,ttocs167,1551866259,"I am trying to speed up prediction for a semantic segmentation task by running half the data through one GPU and half through the other, however I can' seem to figure out how. I feel like it should be simpler than I'm finding t to be.

How do I define two sessions running the same model onto different GPUs? I have some segmentation models I have trained and I would like to run through large folders of images for prediction, however I can't seem to figure out how to run two copies of the models in parallel each running half a dataset. I'm not very familiar with the behavour of sessions or graphs when it comes to multiple devices and I naiively assumed I could do something like this around the run command:

    ...
    for i, d in enumerate(['\gpu:0', '\gpu:1']):
        with tf.device(d):
            output = sess.run(network, feed_dict={net_input: image_batch[i]})
    ...

With the session already defined above and the model already loaded, however the ""with tf.device()"" blocks are simply ignored and only half of the batch is ran on the first device. 

After some reading it seems that the ""with tf.device"" blocks have to cover the actual definition of the operations that go into the ""session.run()"" function, however if I nest the loading of the network in these blocks I get an error saying the weights already exist and that you cannot redefine them with the same name.

My question is, what do I need to do to be able to run half of my batches through a copy of the model on one GPU whilst running the other half through the other? I want to avoid running two scripts each creating a session on a GPU. I'm not very familiar with device placement and, to my suprise, I can't seem to find any information about this online.

Sorry if I haven't been clear enough, I can offer more information or code snippets if required but I want to keep it general.",3,1
16,2019-3-7,2019,3,7,0,ay085o,Why is batch normalization getting removed so as other features in the next update of TF?,https://www.reddit.com/r/tensorflow/comments/ay085o/why_is_batch_normalization_getting_removed_so_as/,Jandevries101,1551887173,"Hi,

&amp;#x200B;

So i came accros that Batch Normalization and other features are getting removed in the next big update and that their ""replacement"" is keras features, but why and is it compatible with my existing tensorflow network, meaning i can just do a keras.layer.etc to my tensorflow based network?

&amp;#x200B;

Jan",4,5
17,2019-3-7,2019,3,7,10,ay6s1s,Training RNN with GPU causes loud coil whine noise,https://www.reddit.com/r/tensorflow/comments/ay6s1s/training_rnn_with_gpu_causes_loud_coil_whine_noise/,Corpio03,1551921866,"Hello, for the first time that I use my GPU \[Notebook GTX 1060\] to train my RNN, I noticed that it was making  some sort of loud coil whine noises that keep going on and off at each batch.

Is it normal or it will damage the GPU over time?  or should I ignore it?

I am completely new to deep learning and tensorflow so I don't know much about this.

Please tell me what to do.

Thanks.

&amp;#x200B;",18,1
18,2019-3-7,2019,3,7,10,ay6zr8,Is it possible to collect y-outputs from train sessions?,https://www.reddit.com/r/tensorflow/comments/ay6zr8/is_it_possible_to_collect_youtputs_from_train/,Snowybluesky,1551923193,"I am new to tensorflow, sorry if I sound stupid\*

&amp;#x200B;

I am testing a linear-regression model, and I want to see how predicted-y values (per each x) change over training. 

Currently, I have this which successfully trains my model:

&amp;#x200B;

**y = Wx + B**                              \#where W, x, and B are all nodes

**for \_ in range(100):**

**session.run****(fetches=train\_step, feed\_dict={x:x\_train, y:y\_train})**

&amp;#x200B;

I want to view the predicted y values from each x\_train data at each training iteration, so I added the line in the for loop but it does not work:

**print(****sesssion.run****(fetches=y\_out))**

&amp;#x200B;

&amp;#x200B;

**Is it possible to look at every y-out value per x-trainer data (per iteration) as you train a model?**

&amp;#x200B;",4,3
19,2019-3-7,2019,3,7,19,ayb7ne,Where can I find exactly how Tensorflow does matrix multiplication?,https://www.reddit.com/r/tensorflow/comments/ayb7ne/where_can_i_find_exactly_how_tensorflow_does/,stoarmy,1551954730,"Hi everyone.I am searching a code part that does sparse matrix multiplication. For example, I want to do a matrix multiplication, and in doing so, I use the tf.matmul operation inside the tensorflow. And, i want to optimize matrix mulptiplication in tf. However, I cannot reach where the matrix Multiplication is made exactly in tf_matmul. Is there any people who can help me to do this ?

",3,1
20,2019-3-7,2019,3,7,23,ayd55y,"Comprehensive Deep Learning Git Codebook, Video Tutorials and Projects",https://www.reddit.com/r/tensorflow/comments/ayd55y/comprehensive_deep_learning_git_codebook_video/,nalinee_choudhary,1551968726,"&amp;#x200B;

https://i.redd.it/8fl6yf1ggpk21.jpg

**Comprehensive** **Deep Learning tutorials** [(Free Video Tutorials)](https://www.edyoda.com/course/1429) [(Github codebook)](https://github.com/zekelabs/AI101-DeepLearning)  


**Build Deep Learning Projects (Complete Video Series for FREE )**  


**1.** [Making your RL Projects in 20 Minutes](https://www.edyoda.com/course/1421)  


**2.** [Style Transfer, Face Generation using GANs in 20 minutes](https://www.edyoda.com/course/1418)  


**3.** [Language and Machine Learning in 20 minutes](https://www.edyoda.com/course/1419)  


**4.** [AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185)  


**5.** [Dog Breed Prediction](https://www.edyoda.com/course/1336)  


**Free** **Video Series for Beginners to advanced users**  


**1.** [Machine Learning - Mastering NumPy](https://www.edyoda.com/course/1263)  


**2.** [Machine Learning using Tensorflow](https://www.edyoda.com/course/99)  


**3.** [Step by step guide to Tensorflow](https://www.edyoda.com/course/1429)  


**4.** [Introduction to Neural Networks](https://www.edyoda.com/course/1417)  


**5.** [Knowledge Graphs, Deep Learning and Reasoning](https://www.edyoda.com/course/1420)",4,15
21,2019-3-8,2019,3,8,2,ayfguq,TensorFlow can now run on 12 edge hardware,https://www.reddit.com/r/tensorflow/comments/ayfguq/tensorflow_can_now_run_on_12_edge_hardware/,richharms,1551981177,,0,20
22,2019-3-8,2019,3,8,4,aygbva,Using Tensorflow on Windows. A coppie of questions.,https://www.reddit.com/r/tensorflow/comments/aygbva/using_tensorflow_on_windows_a_coppie_of_questions/,xDevi69,1551985585,"Do I need Python knowledge? 
Where do I find tutorials explained step by step from Zero?",0,1
23,2019-3-8,2019,3,8,4,aygg6e,"Started using TensorFlow on Windows, Here to ask a couple of questions.",https://www.reddit.com/r/tensorflow/comments/aygg6e/started_using_tensorflow_on_windows_here_to_ask_a/,xDevi69,1551986194,"Do I need python Knowledge?
Where can I find good tutorials? I can't understand tutorials on the official website.",5,2
24,2019-3-8,2019,3,8,5,ayh568,Tensorflow2.0 Alpha-Preview Released!!,https://www.reddit.com/r/tensorflow/comments/ayh568/tensorflow20_alphapreview_released/,shawnmanuel000,1551989802,,0,27
25,2019-3-8,2019,3,8,9,ayjv77,MultiCUDA: Multiple Versions of CUDA on One Machine,https://www.reddit.com/r/tensorflow/comments/ayjv77/multicuda_multiple_versions_of_cuda_on_one_machine/,Klajv,1552004727,,0,0
26,2019-3-8,2019,3,8,11,ayl5kp,"Error message ""there is no module named tensorflow.data""",https://www.reddit.com/r/tensorflow/comments/ayl5kp/error_message_there_is_no_module_named/,Laurence-Lin,1552012920,"As title, when I want to import tensorflow.data.Iterator and do:  


from [tensorflow.data](https://tensorflow.data) import Iterator

&amp;#x200B;

It shows the error message. However, inside the code I could use the function:  


tf.data.Iterator()

&amp;#x200B;

I wonder what is the problem?",0,1
27,2019-3-9,2019,3,9,1,aysdn0,TensorFlow Dev Summit Recap -- Mobile/Edge,https://www.reddit.com/r/tensorflow/comments/aysdn0/tensorflow_dev_summit_recap_mobileedge/,austin_kodra,1552063614,"Hi everyone! Obviously lots of cool news and updates coming out of this year's summit. Here's a rundown of all the mobile/edge bits from the Summit, just in case you missed any of it. (Disclosure -- I do manage/edit this blog, but I thought this might be useful or helpful for some folks here). Also, would love to hear any thoughts/comments/reactions to all the news included:

[https://heartbeat.fritz.ai/tensorflow-dev-summit-2019-the-mobile-bits-79704e81ad9](https://heartbeat.fritz.ai/tensorflow-dev-summit-2019-the-mobile-bits-79704e81ad9)",0,2
28,2019-3-9,2019,3,9,2,aysqy8,TensorFlow Dev Summit 2019-ML Roundup,https://www.reddit.com/r/tensorflow/comments/aysqy8/tensorflow_dev_summit_2019ml_roundup/,mwitiderrick,1552065554,,0,13
29,2019-3-9,2019,3,9,4,ayu7ei,Google Open-Sources Lingvo Framework for Sequence-To-Sequence Modeling,https://www.reddit.com/r/tensorflow/comments/ayu7ei/google_opensources_lingvo_framework_for/,Yuqing7,1552073169,,0,3
30,2019-3-9,2019,3,9,21,az2y5p,Does Tensorflow/Keras needs internet when doing machine learning prediction?,https://www.reddit.com/r/tensorflow/comments/az2y5p/does_tensorflowkeras_needs_internet_when_doing/,masterbruno11,1552133930,Like image recognition or handwritten reading?,13,2
31,2019-3-9,2019,3,9,23,az3xyq,Variational Autoencoders with Tensorflow Probability Layers,https://www.reddit.com/r/tensorflow/comments/az3xyq/variational_autoencoders_with_tensorflow/,AndyMerskinon,1552141256,[http://tech.learn4startup.com/437a26f4c5](http://tech.learn4startup.com/437a26f4c5),0,6
32,2019-3-9,2019,3,9,23,az4ahg,"Encountered this error ""libcublas.so.10.0: cannot open shared object file: No such file or directory"" after trying to install Tensorflow on my computer.",https://www.reddit.com/r/tensorflow/comments/az4ahg/encountered_this_error_libcublasso100_cannot_open/,bananaskywalker,1552143544,"This has been the second of my two unsucessful attempts to install Tensorflow.  Earlier I tried installing it with CUDA 9.0 but I never found a file for Cuda in my **/usr/local** directory. I then followed this [tutorial](https://medium.com/@taylordenouden/installing-tensorflow-gpu-on-ubuntu-18-04-89a142325138) but with Cuda 10.1 (basically the runfile method)  I did manage to follow the exact steps but even then whenever I type nvcc --version, I get this

    nvcc: NVIDIA (R) Cuda compiler driver
    Copyright (c) 2005-2017 NVIDIA Corporation
    Built on Fri_Nov__3_21:07:56_CDT_2017
    Cuda compilation tools, release 9.1, V9.1.85

I do not understand why. I checked for answers online on stackoverflow and I learnt that the PATH and LD\_LIBRARY\_PATH must point to the correct directory which they do.

Here is the output of echo $PATH

    /home/anshuman/Downloads/bin:/home/anshuman/anaconda3/bin:/usr/class/cs143/cool/bin:~/get-shit-done/get-shit-done.sh:/home/anshuman/.local/bin:/home/anshuman/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/anshuman/Documents/PCAP/.openmpi/bin:/home/anshuman/Documents/PCAP/bin:/usr/local/m4/bin/:/home/anshuman/bin:/usr/local/cuda-10.1/bin:/usr/lib/x86_64-linux-gnu/libcublas.so.10

I even found the file libcublas.so.10.0 in **/usr/lib/x86\_64-linux-gnu**  directory and I added the location to both the variables. 

It might be a redundant question but I just need to figure out how to remove CUDA 9.1 without removing 10.1. The solutions I have found on StackExchange generally seem to say that the PATH variable must be updated to point to the right place, which it has. ",11,4
33,2019-3-10,2019,3,10,0,az4o33,Introducing TensorFlow Federated,https://www.reddit.com/r/tensorflow/comments/az4o33/introducing_tensorflow_federated/,RonEng909,1552145898,[http://tech.learn4startup.com/2bcb323498](http://tech.learn4startup.com/2bcb323498),0,0
34,2019-3-10,2019,3,10,3,az6o4s,Tensorflow 2 + Anaconda + VSCode + Ubuntu 18 = Python Lint: 'tensorflow' has no 'keras' member,https://www.reddit.com/r/tensorflow/comments/az6o4s/tensorflow_2_anaconda_vscode_ubuntu_18_python/,alew3,1552157370,"I was setting up Tensorflow 2 alpha with a virtual environment under Anaconda and VS Code to test it out. The code runs fine on the terminal, but the linting isn't working properly on VS Code even after selecting the correct python interpreter.

For example. 

tf.keras.models.Sequential gives the error: Module 'tensorflow' has no 'keras' member

Any ideas?",1,0
35,2019-3-10,2019,3,10,15,azcuew,Can't download CuDNN,https://www.reddit.com/r/tensorflow/comments/azcuew/cant_download_cudnn/,i4hh,1552197751,"I'm trying to get started with twnsorfow-gpu on my Ubuntu 18, 1080ti, 1070ti, CUDA 10 setup.

I registered at the Nvidia developer website with my Google account, received a verification email, the link didn't work and only took me to the login page. Reset password link doesn't work. Signing up with just email/pass doesn't work.

I tied Chrome and Firefox, both latest versions.

Is there another way to download CuDNN? Does anyone here have an account and can share the installers I need?


Thanks in advance",12,5
36,2019-3-11,2019,3,11,9,azmbhs,Any advice to avoid nan costs while training without increasing precision?,https://www.reddit.com/r/tensorflow/comments/azmbhs/any_advice_to_avoid_nan_costs_while_training/,downvotedbylife,1552262437,"I should start by saying I'm new to Tensorflow. I'll try to keep it short:  
I'm working over someone else's code for solving a commonly ill-posed problem (think of it as a form of deconvolution), and it's been working rather well so far. I'm running into a problem where increasing the network depth (in the form of discrete convolutional layers with set input/output dimensions) starts giving me nan loss errors during training. Lowering the network depth decreases the initial loss and converges faster, increasing it increases initial loss and converges at a similar rate but requires more epochs. This is to be expected and is part of my current study.  

The initial loss for my edge case (max network depth I can train without getting nans) gives some pretty big loss numbers in the first iteration, which made me think the culprit was that for the deeper networks, losses (and consequently weights) were too big for single precision. Changing all the tf variables to float64 fixed it, and it's converging as we speak. However, training times after this change climbed to unreasonable levels (~25 minutes per epoch, more than twice what I was getting with float32).  

I've tried lowering the learning rate and batch sizes, which made no difference and still produced nan values on the first epoch's loss. Is there any other change I could make that would let me get away with training at float32 (or lower, but I don't have high hopes for that). Will clipping the output values from my loss calculation allow the network to converge at all?",7,2
37,2019-3-11,2019,3,11,19,azrsi9,A Quick guide to save and restore model Tensorflow,https://www.reddit.com/r/tensorflow/comments/azrsi9/a_quick_guide_to_save_and_restore_model_tensorflow/,AI_Sangam,1552299809,,0,5
38,2019-3-11,2019,3,11,22,azt9fs,Keras to save model when tensorflow is used as backend,https://www.reddit.com/r/tensorflow/comments/azt9fs/keras_to_save_model_when_tensorflow_is_used_as/,mental_ape101,1552309736,Can we use keras to save our model even though we have used tensorflow as backend in entire functionality of our model?,1,1
39,2019-3-12,2019,3,12,0,azv0w7,My anaconda's tensorflow-gpu inference process is slower than base tensorflow,https://www.reddit.com/r/tensorflow/comments/azv0w7/my_anacondas_tensorflowgpu_inference_process_is/,nyamuk91,1552319626,"I'm running this sample code [here](https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py) on a number of images. I have 2 environments in my anaconda, one is using ""tensorflow-gpu"" and another one is using ""tensorflow"". When running the code on tensorflow-gpu environment, the average time taken for the inference process on 10 images is around 25 seconds while when it's running on base tensorflow, the average time taken is only 23 seconds.   
  
I also got this message when I'm running the GPU version:  
&gt; 2019-03-11 23:37:00.674207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
&gt; 2019-03-11 23:37:00.677725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
&gt; 2019-03-11 23:37:00.681750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
&gt; 2019-03-11 23:37:00.685463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
&gt; 2019-03-11 23:37:00.687898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6368 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)  
  
My spec is:  

* CPU: i7 8700  
* RAM: 16GB  
* GPU: GTX 1080  
",4,3
40,2019-3-12,2019,3,12,1,azvnyz,AttributeError: 'Sequential' object has no attribute 'total_loss',https://www.reddit.com/r/tensorflow/comments/azvnyz/attributeerror_sequential_object_has_no_attribute/,Kaen_No_Mai,1552322933,"I'm currently dying trying to figure out this problem, I'm using tensorflow-gpu v1.13.1.  I'm trying to make a binary classifier to classify a file as malicious or not.  X\_train, y\_train, X\_test, and y\_test are all large numpy arrays.  

&amp;#x200B;

`import tensorflow as tf`  
`import numpy as np`  
`import ember`  
`import random`  
`X_train, y_train, X_test, y_test = ember.read_vectorized_features(""C:\\Users\Cody\Desktop\synopsys\data\ember"")`  
`metadata_dataframe = ember.read_metadata(""C:\\Users\Cody\Desktop\synopsys\data\ember"")`  


`#load training set`  
`def loadTrainSet(X_train, y_train, number):`  
`x = np.split(X_train, 100)`  
`y = np.split(y_train, 100)`  
`features = tf.convert_to_tensor(x[number], dtype=tf.float32)`  
`labels = tf.convert_to_tensor(y[number], dtype=tf.float32)`  
 `return features, labels`  


`#load testing set`  
`def loadTestSet():`  
`X_test_tf = tf.convert_to_tensor(X_test, np.float32)`  
`y_test_tf = tf.convert_to_tensor(y_test, np.float32)`  
 `return X_test_tf, y_test_tf`  


`#create compiled keras model`  
`def createModel():`  
`model = tf.keras.models.Sequential()`  
 `#ADD L2 REGULARIZATION LATER`  
 `model.add(tf.keras.layers.Dense(7351, activation=tf.nn.relu))`  
 `'''model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(4096, activation=tf.nn.relu))'''`  
 `model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(4096, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(4096, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))`  
 `#adam metrhod for stochastic gradient descent`  
 `model.compile(optimizer='adam',`  
 `loss='categorical_crossentropy',`  
 `metrics=['accuracy'])`  
 `return model`  


`def generate_arrays(features, labels, batch_size):`  
`batch_features=np.zeros((batch_size, 7351), dtype=np.float32)`  
`batch_labels=np.zeros((batch_size, 1), dtype=np.float32)`  
 `while True:`  
 `for i in range(batch_size):`  
`index=random.choice(900000,1)`  
`batch_features=X_train[index]`  
`batch_labels=y_train[index]`  
 `yield batch_features, batch_labels`  


`print('creating model')`  
`model=createModel()`  
`print('training model')`  
`model.fit_generator(generate_arrays(X_train, y_train, 500), epochs=10, steps_per_epoch=1800)`  
`print('testing model')`  
`X_test_tf, y_test_tf = loadTestSet()`  
`model.evaluate(X_test_tf, y_test_tf)`

&amp;#x200B;

I keep getting the error: 

Traceback (most recent call last):

  File ""C:/Users/Cody/Desktop/synopsys/train.py"", line 76, in &lt;module&gt;

model.fit\_generator(generate\_arrays(X\_train, y\_train, 500), epochs=10, steps\_per\_epoch=1800)

  File ""C:\\Users\\Cody\\AppData\\Local\\conda\\conda\\envs\\emberenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\[training.py](https://training.py)"", line 1426, in fit\_generator

initial\_epoch=initial\_epoch)

  File ""C:\\Users\\Cody\\AppData\\Local\\conda\\conda\\envs\\emberenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training\_generator.py"", line 125, in model\_iteration

model, mode, class\_weight=class\_weight)

  File ""C:\\Users\\Cody\\AppData\\Local\\conda\\conda\\envs\\emberenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training\_generator.py"", line 427, in \_make\_execution\_function

model.\_make\_fit\_function()

  File ""C:\\Users\\Cody\\AppData\\Local\\conda\\conda\\envs\\emberenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\[training.py](https://training.py)"", line 1926, in \_make\_fit\_function

'\_fit\_function', \[self.total\_loss\] + metrics\_tensors)

AttributeError: 'Sequential' object has no attribute 'total\_loss'

&amp;#x200B;

Does anyone have any suggestions?  I'm completely lost, there's barely any documentation on this at all.  ",1,1
41,2019-3-12,2019,3,12,4,azxu8b,Still No Saving for Subclassed Keras Models? TF2.0,https://www.reddit.com/r/tensorflow/comments/azxu8b/still_no_saving_for_subclassed_keras_models_tf20/,kiunthmo,1552333773,"I've been playing around with TF2.0, I'd actually like to switch to it. But why is there no model saving for subclassed models? 

If I have to start using Keras, I should be able to save after training.",0,1
42,2019-3-12,2019,3,12,7,azzpl7,I made a YouTube tutorial for getting started with Tensorflow 2.0!,https://www.reddit.com/r/tensorflow/comments/azzpl7/i_made_a_youtube_tutorial_for_getting_started/,shawnmanuel000,1552342880,"Hey guys, I uploaded a short video on how to get started with Tensorflow 2.0 to create your own custom neural network using both the High level keras API as well as the lower level building blocks.

Here's the link: [https://www.youtube.com/watch?v=fQCKxzHvYnw](https://www.youtube.com/watch?v=fQCKxzHvYnw)

Let me know if there are any other aspects of Tensorflow that you'd like a tutorial for",9,27
43,2019-3-12,2019,3,12,17,b05gsp,Unknown command line flag error,https://www.reddit.com/r/tensorflow/comments/b05gsp/unknown_command_line_flag_error/,GoBacksIn,1552380501,"FLAGS.meta\_dir = 'meta/' + FLAGS.cipher + '-{}/'.format(m)

has occur 

Traceback (most recent call last):

  File ""C:/Users/ML/Downloads/crypto-rnn-master/main.py"", line 82, in &lt;module&gt;

FLAGS.meta\_dir = 'meta/' + FLAGS.cipher + '/' # directory to save loss history, figures, etc.

  File ""C:\\Users\\ML\\Anaconda3\\envs\\me\\lib\\site-packages\\tensorflow\\python\\platform\\[flags.py](https://flags.py)"", line 88, in \_\_setattr\_\_

return self.\_\_dict\_\_\['\_\_wrapped'\].\_\_setattr\_\_(name, value)

  File ""C:\\Users\\ML\\Anaconda3\\envs\\me\\lib\\site-packages\\absl\\flags\\\_flagvalues.py"", line 499, in \_\_setattr\_\_

return self.\_set\_unknown\_flag(name, value)

  File ""C:\\Users\\ML\\Anaconda3\\envs\\me\\lib\\site-packages\\absl\\flags\\\_flagvalues.py"", line 375, in \_set\_unknown\_flag

raise \_exceptions.UnrecognizedFlagError(name, value)

absl.flags.\_exceptions.UnrecognizedFlagError: Unknown command line flag 'meta\_dir'

&amp;#x200B;

i used code as raw in 

[https://github.com/greydanus/crypto-rnn](https://github.com/greydanus/crypto-rnn)

&amp;#x200B;",0,1
44,2019-3-13,2019,3,13,3,b0ba5s,[help wanted] Embedding a Python interpreter in tfgo - Tensorflow Python API support,https://www.reddit.com/r/tensorflow/comments/b0ba5s/help_wanted_embedding_a_python_interpreter_in/,pgaleone,1552415730,,0,1
45,2019-3-13,2019,3,13,5,b0cewe,Scaling the A3C algorithm to multiple machines using Tensorflow.JS,https://www.reddit.com/r/tensorflow/comments/b0cewe/scaling_the_a3c_algorithm_to_multiple_machines/,naifmeh,1552421344,,1,1
46,2019-3-13,2019,3,13,11,b0ge7m,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/tensorflow/comments/b0ge7m/how_neural_networks_work_simply_explained/,ailearn12,1552442591,,0,20
47,2019-3-13,2019,3,13,16,b0j1yh,Where is configure.py,https://www.reddit.com/r/tensorflow/comments/b0j1yh/where_is_configurepy/,monkeyunited,1552461181,"I apologize. I know this is very low level questions but I'm genuinely stuck.

Using the instruction from [https://www.tensorflow.org/install/source\_windows](https://www.tensorflow.org/install/source_windows), at the step of configure the build, where can I get the [configure.py](https://configure.py) file?

I install everything that was asked beforehand but none of those include a [configure.py](https://configure.py).

I'm super new to python but I'm really just clueless. ",2,1
48,2019-3-13,2019,3,13,17,b0jn0p,tf.gradients returns None for gradient with self for integer variable,https://www.reddit.com/r/tensorflow/comments/b0jn0p/tfgradients_returns_none_for_gradient_with_self/,souljaboy764,1552466375,"I was playing around with tf.gradients and got gradients as None for the below code:

&amp;#x200B;

    &gt;&gt;&gt; x = tf.Variable(10) # integer type
    &gt;&gt;&gt; tf.gradients(x,x)
    [None]
    &gt;&gt;&gt; sess.run(tf.gradients(x,x))
    Traceback (most recent call last):
      File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 929, in run
        run_metadata_ptr)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1137, in _run
        self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 471, in __init__
        self._fetch_mapper = _FetchMapper.for_fetch(fetches)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 261, in for_fetch
        return _ListFetchMapper(fetch)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 370, in __init__
        self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 258, in for_fetch
        type(fetch)))
    TypeError: Fetch argument None has invalid type &lt;type 'NoneType'&gt;
    &gt;&gt;&gt; x = tf.Variable(10.0) # float type
    &gt;&gt;&gt; tf.gradients(x,x)
    [&lt;tf.Tensor 'gradients_6/Fill:0' shape=() dtype=float32&gt;]
    &gt;&gt;&gt; sess.run(tf.gradients(x,x))
    [1.0]

The environment is Python 2.7 with tensorflow 1.12

&amp;#x200B;

I'm not able to understand why this happens. shouldn't it be the same for both the cases of float and int?",4,1
49,2019-3-13,2019,3,13,18,b0jz0c,TensorFlow for JavaScript,https://www.reddit.com/r/tensorflow/comments/b0jz0c/tensorflow_for_javascript/,HazelMadsen,1552469350,[https://www.youtube.com/watch?v=A1EA7VgZt9I](https://www.youtube.com/watch?v=A1EA7VgZt9I),0,0
50,2019-3-13,2019,3,13,20,b0kuxn,"From Keras to C++, a practical example of Tensorflow C API based deployment",https://www.reddit.com/r/tensorflow/comments/b0kuxn/from_keras_to_c_a_practical_example_of_tensorflow/,aljabr0,1552476335,"This small demo project is about deploying deep learning models on embedded platforms. The techniques exposed here have been particularly useful to me in the deployment of deep learning models in industrial applications. We start with a simple example model, trained with **Tensorflow + Keras**. In the end, we'll freeze the model and export a GraphDef that can be loaded and executed through the **Tensorflow C API** (without Python).
[https://github.com/aljabr0/from-keras-to-c](https://github.com/aljabr0/from-keras-to-c)
",0,13
51,2019-3-14,2019,3,14,0,b0ngi6,"What is the difference between neural networks made with tf,tf.nn, tf.keras and tf.layers?",https://www.reddit.com/r/tensorflow/comments/b0ngi6/what_is_the_difference_between_neural_networks/,begooboi,1552491858,"I have seen in tensorflow we can make neural networks with tf.nn, tf.keras and tf.layers. We can also make neural networks from scratch using tensorflow lower level api.

What is the difference between neural networks made with  tf,tf.nn, tf.keras and tf.layers? 

Is there any training speed difference between these four methods? 

If we consider training a model , Is one of these methods  is superior to other?

Why there is this many methods?",8,15
52,2019-3-14,2019,3,14,1,b0o2l3,TensorFlow Serving with Docker  an end-to-end example!,https://www.reddit.com/r/tensorflow/comments/b0o2l3/tensorflow_serving_with_docker_an_endtoend_example/,jingw222,1552494981,,0,4
53,2019-3-14,2019,3,14,10,b0ul60,How can I un-freeze variables from a restored model checkpoint?,https://www.reddit.com/r/tensorflow/comments/b0ul60/how_can_i_unfreeze_variables_from_a_restored/,Morocco_Bama,1552528749,"I have a network that I'm freezing some of the weights in in early epochs of training. When I restore the model from a checkpoint, how can I change those variables to ""trainable""?",0,1
54,2019-3-14,2019,3,14,12,b0v9kj,A relaxing game built in Tensoflow,https://www.reddit.com/r/tensorflow/comments/b0v9kj/a_relaxing_game_built_in_tensoflow/,jcheng91,1552533038,[removed],0,1
55,2019-3-14,2019,3,14,12,b0vfnn,Disconnect display from GPU?,https://www.reddit.com/r/tensorflow/comments/b0vfnn/disconnect_display_from_gpu/,nicksvr4,1552534105,"Probably a stupid question, but I have dual GPUs now (GTX 970, GTX2080Ti). Should I disconnect all displays from the 2080Ti when using it with TF? Just disable the display driver?",8,2
56,2019-3-14,2019,3,14,16,b0xar2,"Tensorflow prediciton error, invalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]",https://www.reddit.com/r/tensorflow/comments/b0xar2/tensorflow_prediciton_error_invalidargumenterror/,MALEK1997,1552547688,"I trained a Tensorflow Ssd object-detection model using Google object-detection Api and i exported the trained model using the provided ""export\_inference\_graph.py"" script as ""Saved\_model.pb"" file with ""encoded\_image\_string\_tensor"" as input type, however when i tried to make prediction to the model, i got the following error:

&amp;#x200B;

`tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]`

&amp;#x200B;

 loaded the model into a graph as follow:

&amp;#x200B;

`with tf.Session() as sess:     tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], saved_model_file)     graph = tf.get_default_graph()`

&amp;#x200B;

And made the prediction as follow:

&amp;#x200B;

`# Convert the image into base64 encoded string img = Image.open(IMAGE_PATH)     resized_img = img.resize((300, 300), Image.ANTIALIAS) binary_io = io.BytesIO() resized_img.save(binary_io, ""JPEG"")  bytes_string_image = base64.b64encode(binary_io.getvalue()).decode(""utf-8"") # Define the input and output placeholder tensors input_tensor = graph.get_tensor_by_name('encoded_image_string_tensor:0') tensor_dict = {} for key in ['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes']:         tensor_name = key + ':0'         tensor_dict[key] = graph.get_tensor_by_name(tensor_name) # Finally, do the prediciton output_dict = sess.run(tensor_dict, feed_dict={                            input_tensor: bytes_string_image})`

&amp;#x200B;",7,2
57,2019-3-15,2019,3,15,1,b12l8g,How we improved Tenserflow Serving performance by over 70%,https://www.reddit.com/r/tensorflow/comments/b12l8g/how_we_improved_tenserflow_serving_performance_by/,GeneticGenesis,1552581881,,2,9
58,2019-3-15,2019,3,15,3,b13kw2,"Build AI that works offline with Coral Dev Board, Edge TPU, and TensorFlow Lite",https://www.reddit.com/r/tensorflow/comments/b13kw2/build_ai_that_works_offline_with_coral_dev_board/,dayanruben,1552586646,,30,22
59,2019-3-15,2019,3,15,23,b1fs6d,Edge TPU: Hands-On with Googles Coral USB Accelerator,https://www.reddit.com/r/tensorflow/comments/b1fs6d/edge_tpu_handson_with_googles_coral_usb/,rdeepc,1552661051,,7,21
60,2019-3-16,2019,3,16,8,b1lx4l,Is it possible to fix the input size of a model when you freeze it?,https://www.reddit.com/r/tensorflow/comments/b1lx4l/is_it_possible_to_fix_the_input_size_of_a_model/,Boozybrain,1552693514,Or would I need to fine tune it with a fixed input size to save the weights based on the size I choose?,0,2
61,2019-3-17,2019,3,17,5,b1woqu,Multi-class Image Recognition,https://www.reddit.com/r/tensorflow/comments/b1woqu/multiclass_image_recognition/,916swift,1552766835,"Does anyone have any recommendations on where to start for building a multiclass model for image recognition on your own data?

I have some basic knowledge of Tensorflow, but most of my experience is on a pretrained model. 

For what I am working, I have created the training/testing sets in the different classes

&amp;#x200B;",3,2
62,2019-3-17,2019,3,17,6,b1xg1f,"I ranked the Best TensorFlow Courses on the internet, based on your reviews",https://www.reddit.com/r/tensorflow/comments/b1xg1f/i_ranked_the_best_tensorflow_courses_on_the/,skj8,1552770977,,4,36
63,2019-3-17,2019,3,17,14,b223vq,tf.nn.conv2d in numpy or scipy?,https://www.reddit.com/r/tensorflow/comments/b223vq/tfnnconv2d_in_numpy_or_scipy/,Morocco_Bama,1552801830,"As part of an embedded project, I have a network that I trained and saved in Tensorflow, and now I'm re-loading the variables in a Numpy/Scipy-based model. I'm trying to convert the following Tensorflow lines:

    # input shape: (1, 224, 224, 1)
    
    weight1 = tf.Variable([3,3,1,16],stddev)
    conv1 = tf.nn.conv2d(input,w,[1,1,1,1])
    
    # conv1 shape: (1, 224, 224, 16)
    
    weight2 = tf.Variable([3,3,16,32],stddev)
    conv2 = tf.nn.conv2d(conv2,w,[1,1,1,1])
    
    # conv2 shape: (1, 224, 224, 32)

I know that tensorflow's conv2d is not an actual convolution, and that for np.convolve the axes have to be flipped for two or three-dimensional weights. But how does this translate for a four-dimensional weight?

    # I tried with numpy and scipy, both fail
    # from numpy import convolve
    from scipy.ndimage.filters import convolve
    
    conv1 = convolve(input, weight1[::-1])
    
    # conv1 shape: (1, 224, 224, 1)
    
    conv2 = convolve(conv1, weight2[::-1])
    
    # conv2 shape: (1, 224, 224, 16)

&amp;#x200B;",0,2
64,2019-3-17,2019,3,17,22,b25dxi,Has anyone here worked with Tensorflow Lite?,https://www.reddit.com/r/tensorflow/comments/b25dxi/has_anyone_here_worked_with_tensorflow_lite/,gitmonk,1552830946,"I need to make an Android application that detects faces and compares them to a database of previously registered faces.

I've done some projects involving Tensorflow, including a GAN. And I'm currently working on 3D reconstruction of colored facial images. However, I am completely new to Android development and using the Tensorflow Lite tool.hah

Could anyone here give me good advice? I really do not expect anyone to do my job for me, I just need to be directed to the right path.

If this posting is inappropriate for the sub, where could I post it properly?

Thank you.",15,11
65,2019-3-18,2019,3,18,1,b26mvr,How do I use Object detection API to find threat in surveillance video,https://www.reddit.com/r/tensorflow/comments/b26mvr/how_do_i_use_object_detection_api_to_find_threat/,ragupal,1552838609," i am trying to do my PG course project i managed to detect object with object detection  API  of tensorflow but how do I approach  my model further to detect threat  in the scenario   
Any suggestions/tutorial  will be highly appreciated for detecting threat in the video 

PS :  I have dataset of various threats like theft, fight,  public knockouts and physical assault ",3,2
66,2019-3-18,2019,3,18,22,b2inr9,error when using tf.metrics.mean_per_class_accuracy,https://www.reddit.com/r/tensorflow/comments/b2inr9/error_when_using_tfmetricsmean_per_class_accuracy/,Dahnaman,1552915231,"tf.metrics.mean_per_class_accuracy(
    labels,
    predictions,
    num_classes,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)

I dont understand what a ground truth label is. I tried putting labels=X_test, predictions=y_test, num_classes=4

But got the AttributeError: 'list' object has no attribute 'get_shape'

I know my labels and predictions are wrong but what exactly do I have to input in?",1,1
67,2019-3-18,2019,3,18,23,b2jd0t,Working with TensorFlow 2.0 Alpha,https://www.reddit.com/r/tensorflow/comments/b2jd0t/working_with_tensorflow_20_alpha/,mwitiderrick,1552919278,,0,3
68,2019-3-19,2019,3,19,5,b2ni64,What is the difference between saving model as pb vs as a checkpoint file,https://www.reddit.com/r/tensorflow/comments/b2ni64/what_is_the_difference_between_saving_model_as_pb/,etmhpe,1552940275,"I am saving my model as a checkpoint file like

`saver.save(sess, checkpoint_prefix, global_step=current_step)`  
and I am also saving my model as a pb file like

`tf.train.write_graph(sess.graph.as_graph_def(), checkpoint_prefix, ""graph""+str(nn)+"".pb"", as_text=False)`  


is this just two different ways of saving a model? i.e. are both methods saving the graph and the weights which can then be restored?",4,13
69,2019-3-19,2019,3,19,13,b2soe8,CUDA + CuDNN + Python versions for TF 2.0?,https://www.reddit.com/r/tensorflow/comments/b2soe8/cuda_cudnn_python_versions_for_tf_20/,clanleader,1552968365,"I'm thinking of diving into the alpha so the new syntax and API doesn't take me by surprise, however every time I install or upgrade TF it takes me a long time to get everything up and running correctly, making sure I have the correct versions of CUDA, CuDNN and Python installed. Not to mention my Internet connection is in the third world, so downloading a 2GB CUDA file is a project in and of itself that can take days.

I'm therefore wondering that if I were to install TF 2.0 Alpha right now, would the current configuration, setup and required versions of everything (CUDA, CuDNN, Python) match those at release and allow me to do a simple pip --upgrade to the release version of Tensorflow 2 without needing to upgrade anything or make other changes?",7,0
70,2019-3-20,2019,3,20,2,b30imf,Qn on image brightening vs normalization (xpost from /r/keras,https://www.reddit.com/r/tensorflow/comments/b30imf/qn_on_image_brightening_vs_normalization_xpost/,simpleharmonicmotion,1553017869,"Quick question on whether we have conflicting effects. Consider a case where I take image.jpg then brighten it to get the augmented example image\_brightened.jpg. Now to improve training, I normalize the tensors for both images. Do the two tensors look alike? Do they collapse to the same example thus diluting the value of doing this in the first place?

&amp;#x200B;

Cheers

shm",2,1
71,2019-3-20,2019,3,20,3,b30qpg,using tf.data API for own dataset,https://www.reddit.com/r/tensorflow/comments/b30qpg/using_tfdata_api_for_own_dataset/,FreddyShrimp,1553018939,"I'm trying to create my own dataset (of images) such that I can call methods such as `my_data.train.next_batch(batch_size)` 

However, I think the tensorflow website is pretty vague. I checked stackoverflow but it doesn't cover my problem.

&amp;#x200B;

Can somebody help pls?",4,4
72,2019-3-20,2019,3,20,10,b362rl,The program blocked when I load and run a saved model,https://www.reddit.com/r/tensorflow/comments/b362rl/the_program_blocked_when_i_load_and_run_a_saved/,vincent341,1553046635," 

I run into a problem when I try to load a saved model written in tensorflow. The code is available [here](https://drive.google.com/file/d/18ldea5pls_AaykEEKfBLRC0SrPgFrfa_/view?usp=sharing)(code1). The code loads a pretrained model and uses the pretrained model to compute results with different inputs. The saved model files are available [here](http://vision.is.tohoku.ac.jp/~liushuang/tank2fieldGAN/model/). Actually the saved model was obtained by training a network which is a variation of [pix2pixgan](https://github.com/affinelayer/pix2pix-tensorflow)(code2).

The toy example is like 
&gt;&gt;
    myinput_np, mytarget_np, bbox = my_readimg_np('test2.jpg')
    #load  gan graph
    saver = tf.train.import_meta_graph(checkpoint_path + ""model-210000.meta"")
    gan_graph = tf.get_default_graph()
    convert_targets = gan_graph.get_tensor_by_name(""convert_inputs/convert_image:0"")
    myinputs_p = tf.placeholder(tf.float32, shape=[1, 256, 256, 4]) 
    mytargets_p = tf.placeholder(tf.float32, shape=[1, 256, 256, 3])
    with tf.Session() as sess:
        saver.restore(sess, tf.train.latest_checkpoint(checkpoint_path))
        #coord = tf.train.Coordinator()
        #threads = tf.train.start_queue_runners(sess=sess, coord=coord)
        #load gan weights
        results = sess.run(convert_targets, feed_dict={myinputs_p: myinput_np, mytargets_p: mytarget_np})
        print(convert_targets.name)
        print (results)

When I run code1 to load the pretrained model and compute results with inputs, the program seems blocked/suspend. The program is running but there isn't any output on the screen when ""results= sess.run()"" runs.

Some guys guessed it may be caused by the read pipeline of tensorlow and suggested to add

    coord = tf.train.Coordinator() 
    threads = tf.train.start_queue_runners(sess=sess, coord=coord). 

After adding these two lines, I got the error ""*Process finished with exit code -1073741819 (0xC0000005)*"".

Could you please help me about it? Your help is of great importance to me. Thanks very much in advance.",0,1
73,2019-3-20,2019,3,20,13,b37pmy,Get started with Apache Spark and TensorFlow on Azure Databricks,https://www.reddit.com/r/tensorflow/comments/b37pmy/get_started_with_apache_spark_and_tensorflow_on/,GlennMulligan,1553056922,,0,2
74,2019-3-20,2019,3,20,15,b38rup,Such an impressive document!,https://www.reddit.com/r/tensorflow/comments/b38rup/such_an_impressive_document/,Gerry_Goe,1553064822,"&amp;#x200B;

https://i.redd.it/670co3jg18n21.png",4,6
75,2019-3-20,2019,3,20,16,b398m4,coloring the Tensorflow object detection Bounding Boxes,https://www.reddit.com/r/tensorflow/comments/b398m4/coloring_the_tensorflow_object_detection_bounding/,8222Tamil,1553068544,i'm doing custom object Detection using SSD Mobilenet V1.I'm getting output with some accuracy.I want  to fill the bounding box with black [color.how](https://color.how) to do that..what to change in visualisation\_utils.py.need help..Thanks in advance!!,0,1
76,2019-3-20,2019,3,20,21,b3bp79,Which do you prefer estimator or fit function in Keras?,https://www.reddit.com/r/tensorflow/comments/b3bp79/which_do_you_prefer_estimator_or_fit_function_in/,thisisiron,1553086710,"If you prefer an estimator, which do you use tf.keras.estimator.model_to_estimator () or tf.estimator.inputs.numpy_input_fn()?

Let me know your opinion.",3,3
77,2019-3-20,2019,3,20,22,b3bv8s,"Doubts on how to proceed with retinanet implementation, can someone help me out?",https://www.reddit.com/r/tensorflow/comments/b3bv8s/doubts_on_how_to_proceed_with_retinanet/,nsiddhu,1553087669,,0,1
78,2019-3-21,2019,3,21,5,b3hcp3,TensorFlow VPS,https://www.reddit.com/r/tensorflow/comments/b3hcp3/tensorflow_vps/,ThrowAway9592795,1553115479,"Hello.
Can you please suggest me any good VPS supporting (python) TensorFlow?
Thanks.",1,1
79,2019-3-21,2019,3,21,11,b3kva0,How To Install and Use TensorFlow on Ubuntu 18.04?,https://www.reddit.com/r/tensorflow/comments/b3kva0/how_to_install_and_use_tensorflow_on_ubuntu_1804/,Sophia102z,1553134199,[removed],0,1
80,2019-3-21,2019,3,21,11,b3kvw9,How To Install and Use TensorFlow on Ubuntu 18.04?,https://www.reddit.com/r/tensorflow/comments/b3kvw9/how_to_install_and_use_tensorflow_on_ubuntu_1804/,JJohnson0x,1553134296,[http://on.morioh.net/8841ac0019](http://on.morioh.net/8841ac0019),0,1
81,2019-3-21,2019,3,21,11,b3kwou,How To Install and Use TensorFlow on Ubuntu 18.04?,https://www.reddit.com/r/tensorflow/comments/b3kwou/how_to_install_and_use_tensorflow_on_ubuntu_1804/,Nancyannh,1553134421,[http://on.geeklearn.net/5033f5a1b0](http://on.geeklearn.net/5033f5a1b0),0,0
82,2019-3-21,2019,3,21,12,b3loov,Are there calculations behind the convnet() function in tensorflow,https://www.reddit.com/r/tensorflow/comments/b3loov/are_there_calculations_behind_the_convnet/,cocobananaohhohh,1553139034,Are there calculations behind the convnet() function in tensorflow that show weights and bias being used?,0,1
83,2019-3-21,2019,3,21,21,b3pwsa,batch_normalization training/test behavior,https://www.reddit.com/r/tensorflow/comments/b3pwsa/batch_normalization_trainingtest_behavior/,lateautumntear,1553171148,"Dear all,

I've been using ```slim``` for a while and I would like to switch to ```tf.layers``` implementation. I know there is an issue when testing a trained network with ```slim.batch_norm```. In this case you are obliged to use the ```slim.learning.create_train_op``` to minimize the optimizer otherwise, the traditional ```opt.minimize(loss)``` does not work when the flag *is_training* in batch norm is set as *False*.

It seems to me that the same issue appears in ```tf.layers```, apparently the solution is to do something like this:

```
self.opt = tf.train.AdamOptimizer(learning_rate=0.00001)
self.trainable_vars = tf.trainable_variables()
update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    self.train_op = self.opt.minimize(self.loss, var_list=self.trainable_vars)
```

Is there someone who can explain to me why I need to use the ```update_ops``` instead of creating the train_op directly? 

Is there a more intuitive way to generate the training operator?",0,1
84,2019-3-22,2019,3,22,0,b3rnn1,Some questions about Convolutional Layers in Tensorflow,https://www.reddit.com/r/tensorflow/comments/b3rnn1/some_questions_about_convolutional_layers_in/,Jehovacoin,1553181035,"Okay so I have been recently looking at working with the convolutional layers provided in tensorflow, but I'm having trouble figuring out if the filters are static or dynamic. If they change with the rest of the weights, how is that done? If they don't change, then how are the filters decided? Is it randomly, or are they generated from a seed of some sort? If I apply 2 identical conv2d layers, one with 10 filters and one with 20 filters, are the first 10 filters going to be identical for both layers?

Sorry if these questions are easily answered elsewhere. I have been having trouble finding a direct answer about this in the documentation, and parsing through the source code is exhausting.",4,3
85,2019-3-22,2019,3,22,0,b3ryhf,How to choose epsilon greedy value when training regression NN,https://www.reddit.com/r/tensorflow/comments/b3ryhf/how_to_choose_epsilon_greedy_value_when_training/,Cwlrs,1553182552,"Hi,

&amp;#x200B;

I'm training a deep NN for connect four, and I'm wondering if there's any ballpark figure for what the epsilon greedy value should be at the start of training, middle, and end? Basically, what I found with some initital training, was that the AI could play strong moves (for a bit) if the human played in the middle (strong moves) but didn't have any defences if the human played bad moves initially, straight upwards to make 4 in a row.

&amp;#x200B;

I think this is because it only trained against initial strong moves at the start, and is not familiar with facing unusual moves.

&amp;#x200B;

I am re running the program with 50% random moves (was 10% random moves before) for the start of the training, and plan on reducing it in the future. But I'm not sure if it's better to start with like 80% random, then 50%, then 20%, or some other combination. Obviously it depends on how long it takes for the NN to learn certain aspects of the game as well...",0,1
86,2019-3-22,2019,3,22,4,b3ujar,Analyzing tf.function to discover AutoGraph strengths and subtleties - part 1,https://www.reddit.com/r/tensorflow/comments/b3ujar/analyzing_tffunction_to_discover_autograph/,pgaleone,1553195018,,0,1
87,2019-3-22,2019,3,22,4,b3uzf9,Can someone explain the application of Tensorflow Probability,https://www.reddit.com/r/tensorflow/comments/b3uzf9/can_someone_explain_the_application_of_tensorflow/,krishnab75,1553197204,"I saw the talk on Tensorflow Probability in the latest set of Dev Summit talks on Youtube. But I was still just trying to understand what the purpose or application of Tensorflow probability was? I think even the authors of the package mentioned that the name Tensorflow Probability sounded a bit confusing. 

&amp;#x200B;

So is the purpose of Tensorflow Probability to do Bayesian analysis in Tensorflow? Like is it meant to be a replacement for other software like STAN/BUGS/JAGS--namely other MCMC samplers. So would we use Tensorflow probability to estimate bayesian hierarchical model and get posterior distributions on the parameters? If that is the case, does Tensorflow Probability perform any better than these other STAN/BUGS/JAGS--has anyone done any benchmarks. 

&amp;#x200B;

Or is Tensorflow Probability about getting posterior distributions from graphical models--like markov random fields?  

&amp;#x200B;

I was hoping someone could explain the application of this new and interesting looking package.  

&amp;#x200B;

&amp;#x200B;",3,16
88,2019-3-22,2019,3,22,5,b3va78,Can someone help me in understanding cross validation in tensorflow?,https://www.reddit.com/r/tensorflow/comments/b3va78/can_someone_help_me_in_understanding_cross/,Sonius94,1553198677,"I am new to tensorflow so I am 100% sure how to read tensorflow code. I found the following model:

[https://github.com/jimmyyfeng/TD-LSTM/blob/master/td\_lstm.py](https://github.com/jimmyyfeng/TD-LSTM/blob/master/td_lstm.py)

This model is using train and test data.

I learned that I should split my dataset as followed (example):

80% train data, 20% test data

The test data should never change if I want to train different valies like learning rate for my model.

The train data I split again on each iteration step into train data and validation data for again like 80/20.

Now my question: Is the model on that github repository doing the same?Will it split the training data on each iteration and not learn from the test data?

If now: How could I achieve this. I want that the model not learns from test data and splits the training data for training and validation on each step instead? Can someone explain me how to if its not the case?

&amp;#x200B;

&amp;#x200B;

Posted the question on stackoverflow, too: [https://stackoverflow.com/questions/55287877/do-this-tensorflow-models-implemented-cross-validation](https://stackoverflow.com/questions/55287877/do-this-tensorflow-models-implemented-cross-validation)",2,1
89,2019-3-23,2019,3,23,4,b49c4u,Error reshaping during linear classifier training,https://www.reddit.com/r/tensorflow/comments/b49c4u/error_reshaping_during_linear_classifier_training/,thenerdbutton,1553283080,"I'm pretty new to tensorflow but I went through a bunch of the lessons and practice exercises on Google's ML Crash Course and decided to give it a shot. 

I'm trying to train a linear classifier but keep getting this error:

""InvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1000 values, but the requested shape has 500
         [[node linear/linear_model/linear_model/linear_model/FGPG/Reshape (defined at C:\Users\reach\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_estimator\python\estimator\canned\linear.py:345) ]]"" 

The error shows up right after the shuffle buffer is filled (with a massive traceback stack). I've done some googling and it looks like everyone is getting this when training NNs. I'm trying to use a linear classifier so I'm not sure what's going on, or how to fix it. None of the example vectors I'm using are 500 or 1000 long (I have like 10 features that are all floats, and I've tried training sets from size 5000 to 35000, all giving this error). 

Any idea what could be going on, or how to fix it? Thanks so much!",0,1
90,2019-3-23,2019,3,23,4,b49fc6,Computer freezes then CudNN Crashes when running two models at once?,https://www.reddit.com/r/tensorflow/comments/b49fc6/computer_freezes_then_cudnn_crashes_when_running/,eigenvergle42,1553283533,"Hi, I've noticed what's described in the title for awhile but just recently got a 2nd GPU to try running to models at once and I'm having the same issue. Here's a code snippet:

&amp;#x200B;

  with tf.device('/GPU:1'):

self.model = LookaheadGAN(rdata.shape\[2\], hdata.shape\[2\])

&amp;#x200B;

i = 0

config = tf.ConfigProto()

config.allow\_soft\_placement = True

saver = tf.train.Saver()

&amp;#x200B;

with tf.device('/GPU:1'):

with tf.Session(config=config) as session:

init = tf.initialize\_all\_variables()

[session.run](https://session.run)(init)

while i &lt; 3000000:

rdata, hdata, target = self.data.get\_train\_batch(batch\_size)

\_, gl, rms = [session.run](https://session.run)(\[self.model.gen\_step, self.model.gen\_loss, self.model.rms\_debug\]...

&amp;#x200B;

If I change both with statements to GPU:0 and run another process concurrently, it will freeze for a minute and pump out an error similar to the following:

&amp;#x200B;

UnknownError (see above for traceback): Fail to find the dnn implementation.

\[\[node cudnn\_lstm\_2/cudnn\_lstm\_2/CudnnRNNCanonicalToParams (defined at C:\\Users\\msfti\\source\\repos\\MLHelpers\\MLHelpers\\Lookahead\\[LookaheadGAN.py:83](https://LookaheadGAN.py:83)) \]\]

\[\[node cudnn\_lstm/cudnn\_lstm/CudnnRNNCanonicalToParams (defined at C:\\Users\\msfti\\source\\repos\\MLHelpers\\MLHelpers\\Lookahead\\[LookaheadGAN.py:63](https://LookaheadGAN.py:63)) \]\]

&amp;#x200B;

Has anyone encountered anything like this? Thanks

",8,6
91,2019-3-24,2019,3,24,0,b4kcpf,Collection of high rated online courses to Learn Tensorflow,https://www.reddit.com/r/tensorflow/comments/b4kcpf/collection_of_high_rated_online_courses_to_learn/,gandhiN,1553354803,,3,14
92,2019-3-24,2019,3,24,2,b4li05,Are you building Convolutional Neural Networks on TensorFlow?,https://www.reddit.com/r/tensorflow/comments/b4li05/are_you_building_convolutional_neural_networks_on/,treguess,1553360749,Here are three examples: https://missinglink.ai/guides/deep-learning-frameworks/building-convolutional-neural-networks-tensorflow-three-examples/,0,1
93,2019-3-24,2019,3,24,21,b4vw1x,I have a problem training my object detection model. mAP equals -1. help appreciated.,https://www.reddit.com/r/tensorflow/comments/b4vw1x/i_have_a_problem_training_my_object_detection/,2ringo,1553430987,"Hey guys,

I have a problem training my object detection model in tensorflow. I am using the ""ssd\_mobilenet\_v2"" from the tensorflow model zoo pretrained on the COCO dataset. I am training it on my own dataset. However, the loss is decreasing but the mAP always shows the value -1. Anyone had the same problem? I really do appreciate your help! :)",3,3
94,2019-3-25,2019,3,25,8,b53dbe,Problem with training a multi-hot encoded model (maybe overfitting),https://www.reddit.com/r/tensorflow/comments/b53dbe/problem_with_training_a_multihot_encoded_model/,Corpio03,1553471428,"Hello,

I have been recently working on a project to create a model that will try to learn how to play a video-game on it's own.

The idea is to record the game frames and which keys I am pressing in each specific frame then the model will try to predict the keys to press.

so the training data is something like this:

  \[ \[ frame , keys\] , \[ frame , keys\] , \[ frame , keys\]......\] 

as a start I choosed a Driving Simulator game and I encoded the keys like this :

W =  \[1,0,0,0\] (forwards)

S = \[0,1,0,0\] (backwards)

Q = \[0,0,1,0\] (left)

D= \[0,0,0,1\] (right)

then I encoded them in a multi-hot vector , for example if the script detects that I am pressing ""W"" and ""Q"" the output

 will be like this :  \[1,0,1,0\] which is forwards-left .

I did record some data which I focused mostly on \[1,0,0,0\] , \[1,0,1,0\] and \[1,0,0,1\] and I balanced it to be 1500 frames of each kind.

I tried 2 types of models (CNN and RNN) both models that have an output layer with 4 nodes, ""sigmoid"" activation function and the ""Binary\_Crossentropy"" as loss function.

 The issue is that when I tested them the prediction was always ""W""  \[1,0,0,0\] only.

At first I thought that it didn't accept the Multi-Hot encoding so I did a small record where I only pressed ""W"" and ""D"" to make it \[1,0,0,1\] and it actually worked perfectly the model was outputting  \[1,0,0,1\] all the  time .

The 2 models gave me the same result ,so I don't know if the issue is that I didn't give it enough data? or is it taking the

vector \[1,0,0,0\] as an average since it exists in the other combinations? 

&amp;#x200B;

I am still a beginner in machine learning and tensorflow so I will appreciate any kind of help.

Thanks in advance.

&amp;#x200B;

&amp;#x200B;",2,5
95,2019-3-25,2019,3,25,10,b54j4v,"resembles SAGER NP8961, 2, 3 / CLEVO P960ED, F, N",https://www.reddit.com/r/tensorflow/comments/b54j4v/resembles_sager_np8961_2_3_clevo_p960ed_f_n/,rebcabin-r,1553478094,"CLAIMER: I am a scientist and a purchaser of high-end machines. I have no stake in any computer supplier. I'm just a user / amateur devops / professional developer / professional physicist.

The chassis strongly resembles the SAGER / CLEVO models in the title. SAGER / CLEVO is an OEM supplier of high-end gaming machines. Alienware used them for a while (maybe still do, but I don't buy Alienware stuff any more). I don't know more than this, for example, I don't know whether SAGER and CLEVO are the same company, though they seem to offer the same products with different model numbers (I've never seen a SAGER that didn't have a corresponding CLEVO and vice versa); I don't know whether SAGER and / or CLEVO consider themselves a ""BRAND"" or just an OEM, etc. I have owned a few high-end machines that I traced back to SAGER / CLEVO (looking for parts), and have mixed positive experience. The are not as robust as Lenovos, for example, but they're pretty lightweight and perform well most of the time. I have a SAGER 8950 now, which freezes every couple of weeks or so and won't respond to the power button. I have to let the battery drain down to reboot it. My Alienware died in a blaze of unrepairable GPU death two days after the warranty expired. However, they SCREAM. My current SAGER 8950 32G runs about 18500 on Geekbench, compared to a Lenovo P72 64G, which runs at 21000 Geekbench and cost $7,000. 

Bottom line: I would buy another SAGER, even rebranded, but I would expect it to be finicky and short-lived. I would value the software stack as maintained by Lambda and would strongly consider buying a Lambda, even if they confirmed it's a SAGER, because I easily spend dollar-equivalent time to the difference between a raw SAGER box and a Lambda maintaining software instead of doing real work, and I hate debugging crossed software dependencies! 

You can buy SAGERs here [https://www.xoticpc.com/custom-gaming-laptops-notebooks-gaming-laptops-ct-118-96-98/custom-gaming-laptops-notebooks-clevo-sager-notebooks-ct-95-51-162.html](https://www.xoticpc.com/custom-gaming-laptops-notebooks-gaming-laptops-ct-118-96-98/custom-gaming-laptops-notebooks-clevo-sager-notebooks-ct-95-51-162.html) amongst other places. ",4,1
96,2019-3-25,2019,3,25,22,b5apn5,Number of layers in model architecture?,https://www.reddit.com/r/tensorflow/comments/b5apn5/number_of_layers_in_model_architecture/,NonsphericalFirmness,1553520577,"Hi, Ive used transfer learning on the model ""ssdlite\_mobilenet\_v2\_coco"" from the TensorFlow detection model zoo to train my own dataset. 

Is there any way to find the number of hidden layers in this model? 

&amp;#x200B;

*I wish something like this would exist:*  [*https://www.mathworks.com/help/deeplearning/ref/analyzenetwork.html*](https://www.mathworks.com/help/deeplearning/ref/analyzenetwork.html)

&amp;#x200B;",0,1
97,2019-3-26,2019,3,26,0,b5bzwt,Can I go straight to learning tf 2?,https://www.reddit.com/r/tensorflow/comments/b5bzwt/can_i_go_straight_to_learning_tf_2/,easylifeforme,1553527413,"I'm curious on what your thoughts are for learning tf 2 without knowing tf 1. I've played around with tf 1 but only other people's code never truly diving into it. Is there a lot of value to be gained by trying to learn, the harder to personally understand, tf 1 while 2 is still being developed?",12,7
98,2019-3-26,2019,3,26,5,b5g7ce,Using Tensorflow.js to run a movement game in the browser. Any feedback?,https://www.reddit.com/r/tensorflow/comments/b5g7ce/using_tensorflowjs_to_run_a_movement_game_in_the/,SameDifference,1553547020,,2,29
99,2019-3-26,2019,3,26,7,b5h4p7,quantizing yolo and SSD to custom fixed point data types,https://www.reddit.com/r/tensorflow/comments/b5h4p7/quantizing_yolo_and_ssd_to_custom_fixed_point/,rafeey,1553551386,"I want to quantize yolo and SSD to custom fixed point data types to study the effect on accuracy. Can anyone who've done that please guide me how to do that?  
I've tried tflite converter but it gives error on custom nets like yolo. Plus it only supports int8 conversion. Is there any other way to do it?",0,1
100,2019-3-26,2019,3,26,21,b5owb3,TFRecords ?,https://www.reddit.com/r/tensorflow/comments/b5owb3/tfrecords/,RemoteReindeer,1553602107,"Hi, 

If I understand well, TFRecords files are read with the help of a protocol buffer.

I have multiples Examples inside my TFRecord. To access a specific Example inside this TFRecord, do I have to read all the previous Example in it (since it's a buffer), or is there a way to access it directly ?",8,2
101,2019-3-26,2019,3,26,22,b5q1km,"alexnet classification while training, showing no signs of training",https://www.reddit.com/r/tensorflow/comments/b5q1km/alexnet_classification_while_training_showing_no/,jango1502,1553608757,"My classification model classify given images in three categories. I trained the model with 7000 images in each category.

During the training:
. Model first starts with 33.3% validation and training accuracy.
. Training and validation loss also kind of remains constant during initial epochs
. After 80-100 epochs, the model shows variation in *validation loss* and *training loss* and thus the training and validation accuracy also start to change.
. At 185 epochs model gives 95% training accuracy and 85% validation accuracy.

(So in short my model stays at 33% training and validation accuracy for a while and then after many epochs accuracies start to change. If my training dataset is even less, this constant intial training and validation accuracy stays almost constant for less number of epochs than training the model with larger dataset.)


Now, I did not change any code in the algorithm but just providing a bigger dataset for training.

Right now, each category has 11k images (I worked on the dataset myself, making sure no image goes to wrong category.) 

Problem: 

.Its 300+ epochs now but that 33% has not changed yet! 
.Fix training loss and validation loss for last 295 epochs.
I did not even double the training set, just 1.5 times it is.



.Is this common? 
Should I keep the training go and see when does it change? (why!? Bcos each epoch takes 256sec on my Gpu system, so in one day it runs 300-350 epochs only)  
Or should I do some other checks??


Any suggestions??

",2,1
102,2019-3-27,2019,3,27,14,b60g49,Implementing autoencoder in TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/b60g49/implementing_autoencoder_in_tensorflow_20/,afagarap,1553664139,,9,18
103,2019-3-27,2019,3,27,20,b636ml,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educational. Do check it out",https://www.reddit.com/r/tensorflow/comments/b636ml/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1553685238,,0,1
104,2019-3-27,2019,3,27,21,b63wwd,"Introduction to TensorFlow for AI, Machine Learning, and Deep Learning",https://www.reddit.com/r/tensorflow/comments/b63wwd/introduction_to_tensorflow_for_ai_machine/,frenchdic,1553689934,,0,1
105,2019-3-28,2019,3,28,0,b65qx5,Possible subtitles for Tensorflow 2,https://www.reddit.com/r/tensorflow/comments/b65qx5/possible_subtitles_for_tensorflow_2/,MrAcurite,1553701015,"Tensorflow 2: Electric Boogaloo

Tensorflow 2: Propagation Strikes Back

Tensorflow 2: Traceback of the Clones

Tensorflow 2: The Wrath of GANN

Tensorflow 2: Redemption

Tensorflow 2: This Time It's Perceptive",5,4
106,2019-3-28,2019,3,28,11,b6dl6l,Variational Autoencoders with Tensorflow Probability Layers,https://www.reddit.com/r/tensorflow/comments/b6dl6l/variational_autoencoders_with_tensorflow/,GariSingh,1553741840,,0,13
107,2019-3-30,2019,3,30,3,b71653,Speed up spectrogram computation with tensorflow,https://www.reddit.com/r/tensorflow/comments/b71653/speed_up_spectrogram_computation_with_tensorflow/,ronald_sumbayak,1553885756,"I don't know if it's okay to post a link to stackoverflow here (please tell me if I should copy paste the question here instead), but you can find the details there:

[https://stackoverflow.com/q/55419515/5447454](https://stackoverflow.com/q/55419515/5447454)

&amp;#x200B;

In short, I am currently trying to compute spectrogram of all 1-second clip from audio files (which is extracted from video) using \` tensorflow.contrib.framework.python.ops.audio\_ops.audio\_spectrogram\` function, but it takes a really long time (it might takes days or even weeks, looking at my data size).

&amp;#x200B;

Is there any way to speed up this computation?",0,2
108,2019-3-30,2019,3,30,5,b725ta,How we improved Tensorflow Serving performance by over 70%,https://www.reddit.com/r/tensorflow/comments/b725ta/how_we_improved_tensorflow_serving_performance_by/,masroorhasan,1553890742,Infrastructure perspective: An overview of techniques on optimizing model server and client to reduce latency of prediction pipeline. ,3,6
109,2019-3-30,2019,3,30,6,b730ms,error when starting training: InvalidArgumentError: logits and labels must have the same first dimension,https://www.reddit.com/r/tensorflow/comments/b730ms/error_when_starting_training_invalidargumenterror/,granular2,1553895180,"I get an error `InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [25088,10] and labels shape [32] 	 [[{{node loss_10/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]`

    # TensorFlow and tf.keras
    import tensorflow as tf
    from tensorflow import keras
    
    (training_images, training_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()
    
    training_images = training_images.reshape(training_images.shape[0], 28, 28, 1)
    
    training_images = training_images / 255.0
    test_images = test_images / 255.0
    
    model = keras.Sequential()
    model.add( keras.layers.Conv2D(filters=64, kernel_size=(4,4), padding='same',
                                   activation='relu'))
    model.add(keras.layers.Dense(10, activation=tf.nn.softmax))
    
    model.compile(optimizer='adam', 
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
                   
    print(training_images.shape)
    print(training_labels.shape)
    
    model.fit(training_images, training_labels, epochs=3)

\# shapes printed

(60000, 28, 28, 1)   
(60000,)

&amp;#x200B;

What is wrong?

Thanks",2,2
110,2019-3-30,2019,3,30,15,b77z7c,"TensorFlow is dead, long live TensorFlow!",https://www.reddit.com/r/tensorflow/comments/b77z7c/tensorflow_is_dead_long_live_tensorflow/,ConfidentMushroom,1553926641,,4,41
111,2019-3-30,2019,3,30,18,b79gjq,Starting pointers?,https://www.reddit.com/r/tensorflow/comments/b79gjq/starting_pointers/,throughdaylight,1553939250,"Hello,

First, a bit of a background - Im a hardware engineer by trade. Ive seldom used Python, but I dont mind learning it over next few days. 

I wanted to repurpose my old android phone, such that I can use its rear camera to capture video feed and post process it to detect cars that pass by our neighborhood street and perhaps also register its directional flow (and tabulate it in a spreadsheet).

Is it too difficult to implement? Where can I get started? What are the things I need to learn or grasp before I can undertake such a project? Do I need a super beefy hardware to implement this project?

Thanks for reading.",0,1
112,2019-3-30,2019,3,30,21,b7ao1l,"By default, tensorflow supports 8-bit quantization, is there a way to implement 4-bit quantization?",https://www.reddit.com/r/tensorflow/comments/b7ao1l/by_default_tensorflow_supports_8bit_quantization/,saurav_97,1553948474,,4,0
