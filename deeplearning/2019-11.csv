,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2019-11-1,2019,11,1,11,dpydxi,Differentiable Inference and Generative Models,https://www.reddit.com/r/deeplearning/comments/dpydxi/differentiable_inference_and_generative_models/,data_datum,1572576280, [https://www.cs.toronto.edu/\~duvenaud/courses/csc2541/index.html](https://www.cs.toronto.edu/~duvenaud/courses/csc2541/index.html),0,1
1,2019-11-1,2019,11,1,12,dpz4qn,caffe: train input with pre-trained network,https://www.reddit.com/r/deeplearning/comments/dpz4qn/caffe_train_input_with_pretrained_network/,arjundupa,1572580510,"I have a pre-trained caffe model for scene recognition. I'd like to find an input image which maximally activates one of the output classes.

The idea is: start with a randomly initialized input image (noise), feed this into the the pre-trained network, see what the probability distribution with respect to each class is (the output of feeding the this input into the network), and then minimize the loss between this output and the desired output (in this case, the desired output would be the one-hot vector corresponding to which class you're looking for).

I am very new to Caffe -- any ideas / pointers as to how I can go about getting started with this?",0,1
2,2019-11-1,2019,11,1,12,dpz5wv,Code Tutorial: Manipulate Hyperparameter Spaces for Hyperparameter Tuning,https://www.reddit.com/r/deeplearning/comments/dpz5wv/code_tutorial_manipulate_hyperparameter_spaces/,GChe,1572580701,,1,1
3,2019-11-1,2019,11,1,13,dpznj2,Here is How to Code Neat Machine Learning Pipelines.,https://www.reddit.com/r/deeplearning/comments/dpznj2/here_is_how_to_code_neat_machine_learning/,GChe,1572583715,,0,1
4,2019-11-1,2019,11,1,22,dq4kqy,"AI, machine learning to dominate CXO agenda over next 5 years | ZDNet",https://www.reddit.com/r/deeplearning/comments/dq4kqy/ai_machine_learning_to_dominate_cxo_agenda_over/,BlisteringBernacle,1572616618,,0,2
5,2019-11-1,2019,11,1,23,dq4t9y,Understanding Images with skimage-Python,https://www.reddit.com/r/deeplearning/comments/dq4t9y/understanding_images_with_skimagepython/,BlisteringBernacle,1572617769,,2,0
6,2019-11-1,2019,11,1,23,dq53vo,Any ideas for podcast name?,https://www.reddit.com/r/deeplearning/comments/dq53vo/any_ideas_for_podcast_name/,Doctor_who1,1572619146," 

i have 've decided to create a podcast about deep learning  machine learning  artifical inteligence , neuroscience ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ? plase hellp me",0,1
7,2019-11-2,2019,11,2,1,dq6tiv,Book Recommendation,https://www.reddit.com/r/deeplearning/comments/dq6tiv/book_recommendation/,Jaszunai,1572626665,"Hi, I've been dabbling in neural networks a bit and was thinking of doing an image classification project. Do you have any recommendations on any good books for Computer Vision?",3,7
8,2019-11-2,2019,11,2,5,dqa1bx,"Boost ResNet ""with a simple twist"": connection to Partial Differential Equations",https://www.reddit.com/r/deeplearning/comments/dqa1bx/boost_resnet_with_a_simple_twist_connection_to/,liuyao12,1572640789,,8,23
9,2019-11-2,2019,11,2,12,dqf2uj,learn to implement NN from the scratch,https://www.reddit.com/r/deeplearning/comments/dqf2uj/learn_to_implement_nn_from_the_scratch/,zhangh12,1572665851,"hello everyone. I am a biostatistician with very little experience in DL. Recently when I looked into a formulation of a specific problem in my area, seems like it could be viewed as a neural network with special activation functions for some layers. Also, a special loss/cost function would be needed. 

I guess given this situation, existing framework of DL would not be applied directly to my problem. I would like to implement the NN from the scratch using C++ or python. I would also like to enable gpu computing in my program. I realized that I have difficulty in design the whole program (e.g. how to make the program be flexible to arbitrary layer structure specified by users, just like the existing frameworks do). In addition, I am not quite sure how to embed cuda code efficiently (I have some experience in cuda programming before). 

&amp;#x200B;

Is there a good repository on github that implements a general NN framework? I would like to learn from an example. Thank you.",3,0
10,2019-11-2,2019,11,2,13,dqfswg,How to build a human emotion recognizer using RAVDESS dataset?,https://www.reddit.com/r/deeplearning/comments/dqfswg/how_to_build_a_human_emotion_recognizer_using/,archx64,1572670501,"I'm making a human emotion recognizer using the RAVDESS dataset. The pipeline is to detect face emotion, speech emotion and speech recognition. After detecting combine detected face and speech emotions and analyze them. Then do sentiment analysis on the words of recognized speech. Is there a better way for the pipe line?",0,4
11,2019-11-2,2019,11,2,17,dqhd6p,Variational autoencoder training,https://www.reddit.com/r/deeplearning/comments/dqhd6p/variational_autoencoder_training/,Mike_Sv86,1572682649,"Hi all.

Iam a little bit confused about variational autoencoders and the KL divergence loss.

When reading about VAEs, there is a term called ""KL divergence collapse"", which as far as I have understood, means that the KL loss decreases to 0.

But isn't that what we want, to make the distribution of the latent space as close as possible to a normal distribution?

When I train a VAE on my dataset, the reconstructions are ok and the KL loss decreases to zero.

Is that a good sign or is it bad that the KL loss is zero?

&amp;#x200B;

Thanks in advance,

cheers,

Michael",14,11
12,2019-11-3,2019,11,3,2,dqmydm,tensorflow-gpu 1.12,https://www.reddit.com/r/deeplearning/comments/dqmydm/tensorflowgpu_112/,yazmaz54,1572714021,"Hi, I need to install tensorflow-gpu 1.12 in order to install a keras-yolo3 module but i am not able to install  tensorflow-gpu 1.12, i installed an anaconda environment which has python3.5 because  tensorflow-gpu 1.12 isn't compatible with python3.6 and above i think but it still doesn't work. can anyone please please please help me?",13,3
13,2019-11-3,2019,11,3,2,dqnor1,I need YOUR help with the NN project!,https://www.reddit.com/r/deeplearning/comments/dqnor1/i_need_your_help_with_the_nn_project/,Treedye,1572717033,"Hi there,

I am a senior in high school here in Ukraine, Eastern Europe and I am developing the project for the Ukrainian Scientific Academy (tournament) among youth, the project's idea is to create a useful and easy-to-use interface to create neural networks, with NO coding needed from the user making his own unique networks.

Please find the attached work-in-progress version of the project below. (NOTE: functions and objects are subject to change, there will be export/import, and everything the manually scripted NN has, but with convenient UI)

&amp;#x200B;

https://i.redd.it/jesigg428bw31.gif

My concern is what to do with the project after the tournament because for me the project seems like a great idea and it would be a stupid move to just throw it away. If you guys have any idea where this project will be really useful, please leave your comment. I was thinking about suggesting schools to implement it, but I am more interested in consumer usage. Any suggestions for the new features are also appreciated.

If you want to join the project and build it together - feel free to dm me, I would love to work with you on this. UI is made on HTML/CSS/JS, I consider using Python to produce the NNs.

Thanks for your time.",1,0
14,2019-11-3,2019,11,3,3,dqnyq1,Why Deep Learning Algorithm takes huge advantages of modern GPUs?,https://www.reddit.com/r/deeplearning/comments/dqnyq1/why_deep_learning_algorithm_takes_huge_advantages/,bastolasushann,1572718186,,4,17
15,2019-11-3,2019,11,3,4,dqpgqm,Machine Learning Will Allow Musicians To Spark Specific Emotions In Listeners,https://www.reddit.com/r/deeplearning/comments/dqpgqm/machine_learning_will_allow_musicians_to_spark/,BlastPalace,1572724529,,0,0
16,2019-11-3,2019,11,3,21,dqzyv9,Pytorch Datasets help,https://www.reddit.com/r/deeplearning/comments/dqzyv9/pytorch_datasets_help/,SEAsFinest,1572785442,"Hi, I'm trying to classify the ESC-50 dataset using pytorch. It comes with a csv file and a set of 2000 audio files. How do I load all of this for training? Pytorch's documentation is unclear to me so I'm sorry if this is a noob question.

&amp;#x200B;

 Here's a link to the screenshot of the beginning of the csv file:

 [https://prnt.sc/pru7yq](https://prnt.sc/pru7yq) 

&amp;#x200B;

And here's the code for loading the data:

import pandas as pd  
import numpy as np  
from torch.utils.data import Dataset, DataLoader  
import torchaudio  
class AudioDataset(Dataset):  
 """"""Audio Files dataset.""""""  
 def \_\_init\_\_(self, csv\_file, root\_dir, transform=None):  
 """"""  
Args:  
csv\_file (string): Path to the csv file with annotations.  
root\_dir (string): Directory with all the audio files.  
transform (callable, optional): Optional transform to be applied  
on a sample.  
""""""  
 self.labels = pd.read\_csv(csv\_file)  
 self.root\_dir = root\_dir  
 self.transform = transform  
 def \_\_len\_\_(self):  
 return len(self.labels)  
 def \_\_getitem\_\_(self, idx):  
 if torch.is\_tensor(idx):  
idx = idx.tolist()  
   
file\_name = os.path.join(self.root\_dir,  
 self.labels.iloc\[idx, 0\])  
data, sample\_rate = torchaudio.load\_wav(file\_name)  
x = data.view(1,1,220500)    #Here I'm just trying to convert each audio file to a Conv1d acceptable format  
landmarks = self.labels.iloc\[idx, 1:\]  
landmarks = np.array(\[landmarks\])  
 \#landmarks = landmarks.astype('float').reshape(-1, 2)  
sample = {'audio': x, 'labels': landmarks}  
 if self.transform:  
sample = self.transform(sample)  
 return sample  
face\_dataset = AudioDataset(csv\_file='/content/drive/My Drive/ESC-50/esc50.csv',  
root\_dir='/content/drive/My Drive/ESC-50/audio')  
dataloader = DataLoader(face\_dataset, batch\_size=16,  
shuffle=True)",5,1
17,2019-11-3,2019,11,3,23,dr1058,shup up call the doctor i see legolas everyone,https://www.reddit.com/r/deeplearning/comments/dr1058/shup_up_call_the_doctor_i_see_legolas_everyone/,ezfopp,1572790913,,0,1
18,2019-11-4,2019,11,4,0,dr1ulz,Help regarding similarity search,https://www.reddit.com/r/deeplearning/comments/dr1ulz/help_regarding_similarity_search/,lonewolf_9,1572794783,"Hi all,

Problem statement :  I have a text ( a sentence / paragraph ) on one side. I have a collection of sentences on other side. Now, for the 1st statement, I need to pick up sentences with best contextual similarity from the database in descending order of some criteria , say, similarity score. The domain is  Life Sciences/ Pharmaceutical/ Healthcare.

Which approach should I proceed with :

1) Elastic search 2) FAISS  3) Building a custom similarity search engine using BERT -as - service. 

Any help will be appreciated.

On the same note, if I don't want to use the database and I have only the 1 sentence as input. However, I want to paraphrase that sentence ( including the context ) in layman terms , how should I proceed ?",4,10
19,2019-11-4,2019,11,4,2,dr3ov4,Recommended native linux laptops with dedicated GPU for &lt;= $1500?,https://www.reddit.com/r/deeplearning/comments/dr3ov4/recommended_native_linux_laptops_with_dedicated/,definitelynotsane,1572802427,"Hi - Looking to spend $1500 or less on a linux laptop that won't have any issues with graphics card drivers, etc.  Would prefer a native install of linux rather than dual booting windows / linux as an MSI machine would force me to do.  

The Lambda laptops start at $2100 so out of my league, and I don't need the full stack pre-installed.  

The system76 systems are pretty expensive despite having similar specs as the MSI desktops (not sure why). An Oryx Pro starts at $1700 and has significantly worse specs than an MSI (GL Series GL65 9SEK-065 15.6"" 144 Hz IPS Intel Core i7 9th Gen 9750H (2.60 GHz) NVIDIA GeForce RTX 2060 16 GB Memory 512 GB NVMe SSD Windows 10 Home 64-bit Gaming Laptop). Not sure why the price discrepancy is so extreme.

Any suggestions?  Thank you!",3,1
20,2019-11-4,2019,11,4,8,dr8tpz,I need help for GANs,https://www.reddit.com/r/deeplearning/comments/dr8tpz/i_need_help_for_gans/,_Berkay_,1572824274,Im searching a kind of algortihm for creating some different vectors from dataset(like image or sound.) but the algortihm that i looked for must have a kind of input. For example i train it with some tagged MNIST data and expect new image of number which i choosed. I heard GANs are good at creating new things. Is there a GAN or any other algorithm that specified at that jobs. Thanks in advance,8,5
21,2019-11-4,2019,11,4,12,drbil6,"What does it mean that ""deep learning"" is ""good"" ?",https://www.reddit.com/r/deeplearning/comments/drbil6/what_does_it_mean_that_deep_learning_is_good/,yetanothernormalG,1572836663,"I wonder if there is some notion in which one could quantify what ""good"" means  
when it comes to deep learning.  


For example, one important aspect in DL is ""throwing away"" not important degrees of freedom. 

In some sense it finds some sort of simple transformations that make two datasets equivalent.

Simple example : machine vision, object recognition.

What transformations are ""equivalent"" transformations ? A bit of rotation, scaling, translation,  
removing colors, changing texture, changing color (of a car, for example), changing the orientation,  
camera angle, source of light. Just to name a few.  


These are all irrelavant degrees of freedom when one wants to classify an image into one that contains a   
car or a motorbike. Just to keep things simple.

Now, the questions comes.

It's not very difficult to write a Stan program that does this without any labeling, having only 100 parameters that   
should be fit.  


Basically you take a software that renders cars, you define some distribution for the parameters to be inferred, and  
then ""just"" do simple Bayesian inference.

This - computation cost aside - would work better than deep learning and it would not need labeled samples.  


Instead, it needs that you specify explicitly what are the degrees of freedom that are not relevant for your classification  
problem. 

So, what deep networks really do, is figuring out the degrees of freedoms that need to be thrown away such that they  
solve your classification problem.  


This is why convnets are useful because they throw away translation symmetric degrees of freedoms, also, polling or what was its name, that throws away scaling related degrees of freedom.

So in essence, deep learning solves an inverse problem, while Bayesian inference solves a ""forward"" problem.

So, if there is some sort of measure, on ""how good a deep learning"" ""something"" is, then it should be related to  
how ""well"" it throws away the ""right"" degrees of freedoms. 

This is a nice idea, because it if problem independent. 

Also, since DL consists of layers, one could wonder, how and where the degrees of freedoms are thrown away.  


If such a measure is found then one could find new training algorithms / or even new algorithms for classification problems, where the algorithm is being built up from building blocks whose task is to throw away degrees of freedoms in one way  
or an other. 

For the case of machine vision, one could engineer such algorithms, since one knows how one can create an image from  
a blueprint, then the questions becomes, if we know the data generating algorithm, then how can we create an algorithm  
that throws away ""the right"" degrees of freedom when inverting the data generating process.

This could be a very specific question, if on starts to think about why deep learning is useful at all.

And maybe more importantly, how can it be made even more useful, if one thinks about such question.

In other words. The problem is the following :

&amp;#x200B;

I have a function (some function, continious or not) with N relvant (fix) +10N irrelevant (randomly varying) input parameters that generates a datasat which has 1000N dimensions and I have only 10N datapoints (that is 10\^4N numbers). The task is, to create an algorithm that predicts the N relevant parameters. If we know what this function is, would that help ? Or would it be better to ""just"" use deep learning ? Or can we use our knowledge of the function to create the inference algorithm ? 

When would Bayesian approach be better and when would deep learning be better ? And why ?

Food for thought.",5,1
22,2019-11-4,2019,11,4,16,dreebx,Nice article on tensorflow 2 and Learning Rates,https://www.reddit.com/r/deeplearning/comments/dreebx/nice_article_on_tensorflow_2_and_learning_rates/,shawemuc,1572853271,How to Improve Training your Deep Neural Network in Tensorflow 2.0 von Simon Hawe https://link.medium.com/UXyF0FASk1,2,16
23,2019-11-4,2019,11,4,17,dret46,Face2Face or something like this,https://www.reddit.com/r/deeplearning/comments/dret46/face2face_or_something_like_this/,sibutum,1572856162,"Hello, anyone here who is experienced and/or can share code for face reenactment like Face2Face or something like this?",5,1
24,2019-11-4,2019,11,4,20,drgby3,Applications of deep learning in the insurance industry,https://www.reddit.com/r/deeplearning/comments/drgby3/applications_of_deep_learning_in_the_insurance/,manneshiva,1572866914,"Build your own scratch and dent detection app or automate KYC by implementing deep learning and OCR. 

[https://nanonets.com/blog/ai-in-insurance/](https://nanonets.com/blog/ai-in-insurance/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=ainsu&amp;utm_content=dl)

&amp;#x200B;

[ai in insurance](https://i.redd.it/po4dxue8nnw31.gif)",2,1
25,2019-11-4,2019,11,4,20,drgcqa,What is the latest technique using in Neural Style Transfer (NST) now ?,https://www.reddit.com/r/deeplearning/comments/drgcqa/what_is_the_latest_technique_using_in_neural/,lmviett,1572867066,"The literature of Gatys et al in 2015 demonstrated the power of CNN in creating artistic. It s been 4 years since then; now ,what kind of neural network is being used for NST?",4,1
26,2019-11-4,2019,11,4,21,drgv5q,5 Facial Recognition Trends and Market Predictions 2019,https://www.reddit.com/r/deeplearning/comments/drgv5q/5_facial_recognition_trends_and_market/,pallavi_sharma,1572870119,,0,0
27,2019-11-5,2019,11,5,0,drjcmq,The test set accuracy is 99%,https://www.reddit.com/r/deeplearning/comments/drjcmq/the_test_set_accuracy_is_99/,cmillionaire9,1572882256,,11,81
28,2019-11-5,2019,11,5,3,drlpjw,"AI Weekly Update - November 4th, 2019!",https://www.reddit.com/r/deeplearning/comments/drlpjw/ai_weekly_update_november_4th_2019/,HenryAILabs,1572891740,"This Weekly Update covers DeepMind's AlphaStar, Microsoft's PipeDream Distributed Training Framework, new tutorials from Tensorflow 2.0 such as HuggingFace in 10 lines of code and many more!

https://youtu.be/-dOW21d8lhU",0,1
29,2019-11-5,2019,11,5,3,drlr0t,University for completing masters in AI / DL/ ML,https://www.reddit.com/r/deeplearning/comments/drlr0t/university_for_completing_masters_in_ai_dl_ml/,kuthubuddinshaik123,1572891913,"I want suggestion on good universities which can provide the above courses. 
US / Canada.
Note;- please let it be budget friendly.",7,3
30,2019-11-5,2019,11,5,5,drn9gn,Need help making Keras generator thread-safe,https://www.reddit.com/r/deeplearning/comments/drn9gn/need_help_making_keras_generator_threadsafe/,Jezebeth,1572897974,"Hello everyone! I'm new to this subreddit, and am really excited to read everything out there. However, during an initial search (multiple, actually) I wasn't able to find any posts on making generator functions thread-safe to use in a Keras fit\_generator() call. 

Backstory: I am working with a CSV that is 38k lines with 4 data points each (so, 38k samples x 4 features). I could probably load this all into memory, but I am hoping to eventually have enough data that it definitely won't fit. I have a generator function (so creatively named generator() below) that feeds my fit\_generator() call with all the samples and batches it wants. However, I recently read up on multiprocessing in Keras, and that my CPU is likely my bottleneck given the GPU is at about... 12% utilization? Somewhere in that ballpark. I've tried just using a wrapper class to try to make it thread-safe, I've made a new class that is supposedly thread-safe, and I'm out of ideas because I keep coming to the same error. The thread-safe generator class is also below, thsf\_generator().

    ValueError: When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.

I am really confused by this because if I comment out the steps\_per\_epoch and validation\_steps in the fit\_generator() call, I still get the error. 

My code is below, any help would be greatly appreciated. I am also open to any optimizations and critiques (I'm not so great with this code - it's been quite a hack and slash to get it working). 

**generator()**

    def generator(data, lookback, lookahead, batch_size=128, step=6):
        i=lookback
        while True:
            if i+batch_size*lookahead&gt;=len(data): i=lookback
            rows=np.arange(i, min(i+batch_size, len(data)))
            i+=1
            samples=np.zeros((len(rows), (-(-lookback//step)), data.shape[-1]))
            targets=np.zeros((len(rows),))
            for j, row in enumerate(rows):
                ind=range(rows[j]-lookback, rows[j], step)
                samples[j]=data.loc[ind]
                targets[j]=data.loc[rows[j]+lookahead]['lowest']
            yield samples, targets

**thsf\_gen()**

    class thsf_gen(Sequence):
        def __init__(self, data, lookback, lookahead, batch_size=128, step=6):
            self.data=data
            self.back, self.ahead, self.i=lookback, lookahead, lookback
            self.batch_size, self.step=batch_size, step
            self.shape=(lookback//step, batch_size)
            self.lock=threading.Lock()
        def __len__(self):
            return int(np.ceil(len(self.data)/float(self.batch_size)))
        def __next__(self):
            with self.lock:
                return self.__getitem__()
        def __getitem__(self):
            if self.i+self.batch_size*self.ahead&gt;=len(self.data): self.i=self.back
            rows=np.arange(self.i, min(self.i+self.batch_size, len(self.data)))
            self.i+=1
            samples=np.zeros((len(rows), (-(-self.back//self.step)), self.data.shape[-1]))
            targets=np.zeros((len(rows),))
            for j, row in enumerate(rows):
                ind=range(rows[j]-self.back, rows[j], self.step)
                samples[j]=self.data.loc[ind]
                targets[j]=self.data.loc[rows[j]+self.ahead]['lowest']
            return samples, targets",10,1
31,2019-11-5,2019,11,5,6,dro75n,Visiting the SOSP 2019 AI System Workshop,https://www.reddit.com/r/deeplearning/comments/dro75n/visiting_the_sosp_2019_ai_system_workshop/,Yuqing7,1572901621,,0,2
32,2019-11-5,2019,11,5,7,drpoqn,Doubt regarding the noise in data,https://www.reddit.com/r/deeplearning/comments/drpoqn/doubt_regarding_the_noise_in_data/,Believinginself,1572907740,"Hey guys, 

I have a doubt. I am confused, for a Deep Learning model while training, given that we know our test data might have noise in it too, whether we should add noise to our train data and let our model learn from the noisy data or should we do the preprocessing step to remove noise in the pipeline and feed the noise removed data. I am asking regarding the efficiency, which one should be preferred and why?

Thanks",1,0
33,2019-11-5,2019,11,5,8,drq6bp,Object Recogntion,https://www.reddit.com/r/deeplearning/comments/drq6bp/object_recogntion/,pranav2109,1572909737,Is there any pretrained model for object recognition trained on dataset other than mscoco in tensor flow or keras?,4,1
34,2019-11-5,2019,11,5,12,drtj6f,Deep Learning Can Be Useful in Eliminating Shortage of Cancer Doctors,https://www.reddit.com/r/deeplearning/comments/drtj6f/deep_learning_can_be_useful_in_eliminating/,analyticsinsight,1572924879,,1,0
35,2019-11-5,2019,11,5,14,druwfd,Deep Learning in the Real World: Dealing with Non-Differentiable Loss Functions,https://www.reddit.com/r/deeplearning/comments/druwfd/deep_learning_in_the_real_world_dealing_with/,HN_Crosspost_Bot,1572932479,,0,4
36,2019-11-5,2019,11,5,16,drvo9f,Deep Learning Inference on Edge Devices,https://www.reddit.com/r/deeplearning/comments/drvo9f/deep_learning_inference_on_edge_devices/,jeffbernard301,1572937456,,1,1
37,2019-11-5,2019,11,5,16,drvt02,Application of deep learning in public policy and governance !!,https://www.reddit.com/r/deeplearning/comments/drvt02/application_of_deep_learning_in_public_policy_and/,cc111222,1572938330,"I just recently bumped with deep learning and it is fascinating but i want to use it for developmental economics for eg. solutions for water and air quality , affordable housing and others. 

Can anyone help me with the process . As a lot of public data is available but how does this fit in  the pipeline and  role of deep learning  along with would really be life saver.",9,6
38,2019-11-5,2019,11,5,21,drybqs,Nice article about how to write better and simpler data science code using funcy,https://www.reddit.com/r/deeplearning/comments/drybqs/nice_article_about_how_to_write_better_and/,shawemuc,1572956166,,0,0
39,2019-11-5,2019,11,5,22,dryzsc,Image document classification,https://www.reddit.com/r/deeplearning/comments/dryzsc/image_document_classification/,sambalshikhar,1572959756," 

https://medium.com/analytics-vidhya/how-i-built-a-document-classification-system-using-deep-convolutional-neural-networks-e1d9a83cbabd

I built a image document classification using Intra-domain transfer learning with inception\_resenet\_v2.Check it out!",0,3
40,2019-11-6,2019,11,6,0,ds1245,Skip connections in Autoencoder,https://www.reddit.com/r/deeplearning/comments/ds1245/skip_connections_in_autoencoder/,Mike_Sv86,1572969175,"Hi all.

I trained an autoencoder for feature extraction purposes. The bottleneck is made up of a fully connected layer with 32 neurons.

When I train my model with skip connections, the reconstructions are perfekt, without them they are a mess, the loss decreases during the first epoch and flattens out after that.

Now Iam wondering if there are any disadvantages with skip connections?

Is my fullly connected layer able to learn good features or is it just ignored due to the skip connections (information leakage?) 

(the model does not seem to Learn something useful without them either though)

Thanks in advance,

Cheers,

Michael",17,10
41,2019-11-6,2019,11,6,4,ds3vex,Do Deep Neural Networks See Faces Like Brains Do?,https://www.reddit.com/r/deeplearning/comments/ds3vex/do_deep_neural_networks_see_faces_like_brains_do/,Yuqing7,1572980864,,0,0
42,2019-11-6,2019,11,6,7,ds7494,Made sentence-similarity calculator,https://www.reddit.com/r/deeplearning/comments/ds7494/made_sentencesimilarity_calculator/,huffonism,1572994730,,0,2
43,2019-11-6,2019,11,6,10,ds96o6,Local entropy maximum in deep belief networks.,https://www.reddit.com/r/deeplearning/comments/ds96o6/local_entropy_maximum_in_deep_belief_networks/,yetanothernormalG,1573004437,"This migh sound trivial or nonsense - but the total
entropy that can be throw away is limitel by the diffence in entopy between the output and input distributions. 

This is nice becouse this gives us an extra constraint that we, both need to maximize the mutual information, between the input and the output. My vague guess is that the  entropy of the network minus the mutual information should be equal to the entropy of the input data. 

This could help in tuning the hyper-parameters (already before the training begins, and making sure, one,way or the other, that during the training the system is driven util the lost entropy is not worse than the entropy loss in the predicted output. The entropy of the output + the entropy loss caused by the network, should be, in ideal case equal to the original entropy.

If you train your deep belief network according to this  idea, then you don't need to wory about regularization. This extra condition makes sure that the network is regularized as much as it could have been.

Also, because this is an extra - purely theoretical calculatnon- no stochasticicity needs to be introduced, explicitly, simply the ""equation of motion""/""steepest descent"" algorithm, extended with this extra entropy term would yield the most relieble predictor, and also calculated point estimates for the mean and variance of each parameter. If our Bayesian model is ""first"" order (not hierarchical, the variances are not random variables) and we have a flat prior, then the this calcultion would agree with the exact Bayesian solution. 

So , a little bit of extra derivation can turn a simple DNN into an exactly solved deep belief network.

It might be even possible to do ""random jumps"" (as it is done in Monte Carlo methods) - akkording to to Metropolis algorithm (or in more generad said, if detailed balance is not violate by the possible jumps).

There are a few interesting thoughts that come to mind in this situation. 

This is basically an algorithm that minimises the Free Energy (F = E-TS)

Systems often freeze below a certain T, especially spin glass like, random systems, they do that even more easily - because liquid configurations are ""just as fine"" as solid ones.  Also, note, that T= dE/dS. 

So, this could be also a steepest descent solution, where the velocity of the ""ball"" which has P-1 number of of spatial degrees of freedom. 

E is the total eneregy in Statistical Physics, in the world of HMC, it depends on the momentum of the ""ball"" and the potential energy of the ""ball"" .

So, in essence, it is pretty straightforward to do HMC without the MC part in DNN-s, this might come handy for searching for a way down (taking into special account how much information are we loosing if we leave the equi-entropic manifold ).  

Ok, so much clever evening thoughts for today :)


Hope it made sense to anyone else than me :)

The reason I wrote about this is the we are allowed to do crazy large jumps, as long as the total energy stays the same. 

So, for example, we could better utilize our neural network if they were ""pinned down"". In other word, all neurons would ""mean"" something. 

For example if the training error does not want to drop then we can start to adjust the network topology, explore several alternatives, akkording to some meaningful way to change the network topology. For example taking away one of the least important (most entropic) wire and connecting two neurons that were yet not connected.  Then trying to stay on the equi-entropic surface, one (can remove a high entropy connection, and replace it with a low entropy connection). Eventually this rearranges the network topology.  Might help removing those 1 million not needed connections and then one could have a chance to understand what that network reallyes means. 

This could also lead to a larger network which is equally accurte (sbut it  generalizes likely better. Since the connections became less entropic and the complexity of the network is higher. So this means that the Neural net was throwing away some irrelevant information and instead created some relevant concepts.

I don't now if this would be so clearly possible if it was not about simple deep belief networks. 

I don't know if ppl are doing this in practice, I am sure they do, but if not, why not?

Cheers,

Jozsef",0,3
44,2019-11-6,2019,11,6,10,ds97v7,How to Build a Deep Learning Computer,https://www.reddit.com/r/deeplearning/comments/ds97v7/how_to_build_a_deep_learning_computer/,MusingEtMachina,1573004593,,17,27
45,2019-11-6,2019,11,6,15,dscco9,[D] Regarding Encryption of Deep Learning Models,https://www.reddit.com/r/deeplearning/comments/dscco9/d_regarding_encryption_of_deep_learning_models/,aseembits93,1573021494,"My team works on deploying models on the edge (android mobile devices).  The data, model, code, everything resides on the client device. Is there any way to protect your model from being probed into by the client? The data and predictions can be unencrypted. Please let me know your thoughts on this and any resources you can point me to. Thanks!",0,1
46,2019-11-6,2019,11,6,16,dsd0g4,AI Insider: What is AI and How Does AI Works? | TechLurn,https://www.reddit.com/r/deeplearning/comments/dsd0g4/ai_insider_what_is_ai_and_how_does_ai_works/,omkar72566,1573025765,,0,1
47,2019-11-6,2019,11,6,17,dsd89v,"DL Book - A^-1 can be represented with only limited precision on a digital computer, WHY?",https://www.reddit.com/r/deeplearning/comments/dsd89v/dl_book_a1_can_be_represented_with_only_limited/,secsilm,1573027264,"In Deep Learningbook 2.3:

https://preview.redd.it/9rv0frorv0x31.png?width=1455&amp;format=png&amp;auto=webp&amp;s=d77f999a35fd89c6e5265d447cd223a3d2e10ab4

If this is due to the calculation of the floating point number, then even if b is used, this problem exists.

Does anyone has a good explanation?",4,3
48,2019-11-6,2019,11,6,18,dsdvr2,Transfer learning behavior on custom image data,https://www.reddit.com/r/deeplearning/comments/dsdvr2/transfer_learning_behavior_on_custom_image_data/,VeeranjaneyuluToka,1573031909,"Hi  All, I am trying to apply transfer learning esp fine-tuning (by  freezing a few layers and allowing a few layers in backprop), i am using  InceptionV3 with ImageNet weights on my own custom data. I have around  76 classes and each class has different objects in it, for ex: class x  has persons, cars, trees and good scenaries etc.. It is not converging  at all with this kind of data. I suspect ImageNet data is kind of  uniformly distributed data (mean that each class has objects of that  type only for ex: cat class has cat images only) but my data is kind of  mixture of Gaussians (mean each class has different objects in it as  described above), is it due to this kind of variation in data or would  there be any other reason. Would really appriaciate if there are any  comments or suggestions on this behavior?",0,1
49,2019-11-6,2019,11,6,19,dsejg2,Numerical gradient descent vs gradient calculation and propagation,https://www.reddit.com/r/deeplearning/comments/dsejg2/numerical_gradient_descent_vs_gradient/,In_for_a_pound,1573036612,"I'm fairly new to gradient based optimisation but was wondering about something.

Why is not done that weights are changed, maybe in staged fashion, and then an approximation of the gradient of error with respect to weights is calculated?

I know it won't be as accurate as taking the derivative of the error function and propagating that backward but considering how SGD is favoured surely some approximation in gradients is workable? It would allow for non-differentiable error functions to be optimised, requiring far less calculation and possibly even avoids the need for back propagation of errors?

Does anyone know of this being done or is it just sub-optimal?

I have heard in passing that this is how optimisation was basically done before the discovery of BP so is that why it has been left behind?",7,0
50,2019-11-6,2019,11,6,23,dsh3io,Cloud services to train ML models,https://www.reddit.com/r/deeplearning/comments/dsh3io/cloud_services_to_train_ml_models/,Jaszunai,1573050780,My PC is unable to handle large datasets. What are some alternatives to training on my PC? Anyone here use cloud services to train their neural networks and have recommendations?,4,2
51,2019-11-7,2019,11,7,2,dsj94t,Object detection,https://www.reddit.com/r/deeplearning/comments/dsj94t/object_detection/,MarkCrass,1573060020,Which Conv net use for object detection ? R-CNN or Mask R-CNN ?,4,1
52,2019-11-7,2019,11,7,2,dsjb6y,Querying about GAN training,https://www.reddit.com/r/deeplearning/comments/dsjb6y/querying_about_gan_training/,ahmedmokhtar97,1573060260,"while training *GAN* network first, i train the Discriminator network to identify the real data,  then i combine the generator and discriminator  together through training leading to question here should i use the learning rate used while training the discriminator to identify real data or not ??  and is there is another way to train GAN network  !!",1,4
53,2019-11-7,2019,11,7,2,dsjtsz,Deep Prognosis: Predicting Mortality in the ICU,https://www.reddit.com/r/deeplearning/comments/dsjtsz/deep_prognosis_predicting_mortality_in_the_icu/,hszafarek,1573062440,,2,24
54,2019-11-7,2019,11,7,3,dsk7u0,Randomly classifying?,https://www.reddit.com/r/deeplearning/comments/dsk7u0/randomly_classifying/,potato-question-mark,1573064074,"Hi

Help me understand this and bear with me if it's a stupid question 

In binary classification, when the accuracy is 50% it means the model is guessing randomly, right?

But for multi class classification, it's not the same. If n_classes = 5, then around 20% accuracy should be when the model is randomly guessing? (1/n_classes)

Thanks!",5,3
55,2019-11-7,2019,11,7,5,dsmeba,600x t-SNE speedups with RAPIDS vs. Sklearn,https://www.reddit.com/r/deeplearning/comments/dsmeba/600x_tsne_speedups_with_rapids_vs_sklearn/,HenryAILabs,1573073674,[removed],0,1
56,2019-11-7,2019,11,7,6,dsn0fc,TensorFlow 2.0 Tutorial in 10 Minutes - Operations (+ Linear Algebra) and CUSTOM training and testing classes.,https://www.reddit.com/r/deeplearning/comments/dsn0fc/tensorflow_20_tutorial_in_10_minutes_operations/,permalip,1573076134,,0,1
57,2019-11-7,2019,11,7,6,dsn5c3,600x t-SNE speedup with RAPIDS!,https://www.reddit.com/r/deeplearning/comments/dsn5c3/600x_tsne_speedup_with_rapids/,HenryAILabs,1573076673,[https://youtu.be/\_4OehmMYr44](https://youtu.be/_4OehmMYr44),0,4
58,2019-11-7,2019,11,7,6,dsn9rh,ProtoPNet Recognizes Birds and Shows Us How in Real Time,https://www.reddit.com/r/deeplearning/comments/dsn9rh/protopnet_recognizes_birds_and_shows_us_how_in/,Yuqing7,1573077156,,2,14
59,2019-11-7,2019,11,7,21,dswtbs,could someone update stackgan,https://www.reddit.com/r/deeplearning/comments/dswtbs/could_someone_update_stackgan/,loopy_fun,1573128430,"could someone update this to the new version of tensorflow so it  can be used in google colab?

[https://github.com/hanzhanggit/StackGAN](https://github.com/hanzhanggit/StackGAN)",2,1
60,2019-11-7,2019,11,7,21,dsx87c,"Saw this review of grokking deep learning on Amazon. Complete noob here, should I still buy/read this book?",https://www.reddit.com/r/deeplearning/comments/dsx87c/saw_this_review_of_grokking_deep_learning_on/,PulkitVyas,1573130753,,9,1
61,2019-11-7,2019,11,7,22,dsxenk,Need Help/Contributions to PyTorch C++ Tutorial for Deep Learning,https://www.reddit.com/r/deeplearning/comments/dsxenk/need_helpcontributions_to_pytorch_c_tutorial_for/,op_prabhuomkar,1573131725,[removed],2,1
62,2019-11-8,2019,11,8,2,dt1fqe,Google T5 Explores the Limits of Transfer Learning,https://www.reddit.com/r/deeplearning/comments/dt1fqe/google_t5_explores_the_limits_of_transfer_learning/,Yuqing7,1573149564,[removed],0,1
63,2019-11-8,2019,11,8,3,dt22ta,Is AutoEncoders in Keras deep learning?,https://www.reddit.com/r/deeplearning/comments/dt22ta/is_autoencoders_in_keras_deep_learning/,fadelbe,1573152152,"The title is enough. I need to make a deep learning project and found a credit card falsification program that uses autoencoders in Keras. I just need to make sure it is indeed a deep learning project and not a machine learning one.

Thank you for any input",2,1
64,2019-11-8,2019,11,8,4,dt2swz,Why my generative adversarial network (gan) is not converging during training?,https://www.reddit.com/r/deeplearning/comments/dt2swz/why_my_generative_adversarial_network_gan_is_not/,classyflyer,1573154906,"I am building a GAN to detect anomalies in images. I built my model on keras because I am only familiar with keras. The generator and discriminator are both an autoencoder, I defined my own loss functions. The concept of this model is this: the model is trained on only normal images and tested on both normal and abnormal images, since the model has only seen normal images during training, it's not able to reconstruct an abnormal image as good as a normal one, so a large reconstruction error can be used as an indication for anomaly. The reason for using 2 autoencoders is that the second reconstructed image will have an even larger distance than the original input thus it can separate the abnormal images even better. I don't know what went wrong but the model doesn't converge no matter how many batches I train it. Can someone please help me find out what went wrong? Thank you so much in advance!

    # Build model
    
    import keras
    from keras import backend as K
    from keras.layers import ReLU, LeakyReLU, Conv2D, Conv2DTranspose, BatchNormalization, concatenate, Flatten, Dense, Reshape
    from keras.models import Model, clone_model
    import numpy as np
    
    
    # Build autoencoder to be the generator
    
    img_shape = (152, 232, 1) # This is the shape of my input images
    latent_dim = 16
    
    inputs = keras.Input(shape=img_shape)
    x = Conv2D(16, 3, padding='same', strides=(2,2), activation='relu')(inputs)
    x = BatchNormalization()(x) 
    x = Conv2D(32, 3, padding='same', strides=(2,2), activation='relu')(x)
    x = BatchNormalization()(x)
    shape = K.int_shape(x)
    x = Flatten()(x)
    latent = Dense(latent_dim, name='latent_vector')(x)
    x = Dense(shape[1] * shape[2] * shape[3])(latent)
    x = Reshape((shape[1], shape[2], shape[3]))(x)
    x = Conv2DTranspose(32, 3, padding='same')(x)
    x = LeakyReLU()(x)
    x = BatchNormalization()(x)
    x = Conv2DTranspose(16, 3, padding='same', strides=(2,2))(x)
    x = LeakyReLU()(x)
    x = BatchNormalization()(x)
    outputs = Conv2DTranspose(1, 3, padding='same', activation='tanh', strides=(2,2))(x)
    
    generator = Model(inputs, outputs)
    
    # Make a second autoencoder to be used as discriminator
    ae_disc = clone_model(generator)
    ae_disc.name=""autoencoder_discriminator""
    
    # Freeze the weights of generator
    generator.trainable = False 
    
    gen_outputs = generator(inputs)
    dis_outputs_1 = ae_disc(inputs)
    dis_outputs_2 = ae_disc(gen_outputs)
    
    # Build discriminator
    discriminator = Model(inputs, [dis_outputs_1, dis_outputs_2])
    
    # Define loss function for discriminator 
    loss_d = K.sum(K.abs(inputs - dis_outputs_1)) - K.sum(K.abs(gen_outputs - dis_outputs_2))
    discriminator.add_loss(loss_d)
    
    # Compile discriminator
    discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)
    discriminator.compile(optimizer=discriminator_optimizer)
    
    # Freeze autoenconder and unfreeze generator
    ae_disc.trainable = False 
    generator.trainable = True 
    
    gen_outputs = generator(inputs)
    gan_outputs_1 = ae_disc(inputs) 
    gan_outputs_2 = ae_disc(gen_outputs)
    
    # Build gan
    gan = Model(inputs, [gan_outputs_1, gan_outputs_2]) 
    
    # Define gan loss
    loss_g = K.sum(K.abs(inputs - gen_outputs)) + K.sum(K.abs(gen_outputs - gan_outputs_2))
    gan.add_loss(loss_g)
    
    # Compile gan
    gan_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)
    gan.compile(optimizer=gan_optimizer)
    
    
    
    # Train model
    
    # Squeeze pixel values into [-1, 1] since I use 'tanh' as activation for the autoencoder output
    x_train = train_imgs.astype('float32') / 255.*2-1 
    
    batch_size = 20
    
    start = 0
    for step in range(1000):
        stop = start + batch_size
        images = x_train[start: stop]
    
        d_loss = discriminator.train_on_batch(images, None)    
        g_loss = gan.train_on_batch(images, None)
    
        start += batch_size
        if start &gt; len(x_train) - batch_size:
            start = 0
    
        # Print losses
        if step % 10 == 0:
            # Print metrics
            print('discriminator loss at step %s: %s' % (step, d_loss))
            print('generator loss at step %s: %s' % (step, g_loss))   

I expected the g\_loss and d\_loss to be smaller and smaller, but they went down after a few batches and kept fluctuating without going down, and I am pretty sure it wasn't overfitted because when I use the trained model to predict a test image, the result is a super blurry image.

I've been trying to get this code to work for days! If you can point me in the right direction it'd be greatly appreciated! Thank you so much!",5,1
65,2019-11-8,2019,11,8,6,dt4cvs,Deep Learning for High-Dimensional Time Series,https://www.reddit.com/r/deeplearning/comments/dt4cvs/deep_learning_for_highdimensional_time_series/,semi_competent,1573160991,,0,1
66,2019-11-8,2019,11,8,6,dt50v4,UNSUPERVISED LEARNING OF 3D REPRESENTATIONS FROM NATURAL IMAGES,https://www.reddit.com/r/deeplearning/comments/dt50v4/unsupervised_learning_of_3d_representations_from/,cmillionaire9,1573163658,,4,1
67,2019-11-8,2019,11,8,9,dt6ut1,Recommendations on GPUs,https://www.reddit.com/r/deeplearning/comments/dt6ut1/recommendations_on_gpus/,topecas,1573171454,[removed],0,1
68,2019-11-8,2019,11,8,10,dt87yo,Classification for low resolution image,https://www.reddit.com/r/deeplearning/comments/dt87yo/classification_for_low_resolution_image/,Yongwook,1573177768,"Hi, I've just joined this community :)

I want to classify low resolution word level text image.

In detail, I want to classify a word image to specific language.

Here's some example below. 

&amp;#x200B;

[Target Result: English](https://preview.redd.it/8k6i1i52adx31.png?width=51&amp;format=png&amp;auto=webp&amp;s=05c232e474def11a43452e6e5b4bb8fb6dcf6f07)

&amp;#x200B;

[Target Result: Korean](https://preview.redd.it/aahpuuv4adx31.png?width=36&amp;format=png&amp;auto=webp&amp;s=d6e99f891ded9003d6447e8903d42f30e7d29c95)

I think, the resolutions of the word images are around (80x30).

The matter is, computational cost and speed.

So, I don't want to scale the image up like (299x299) for Inception network. 

Is there any other solution for this problem?

&amp;#x200B;

Thank you for read this post!",2,1
69,2019-11-8,2019,11,8,10,dt8908,Multi-Million-Dollar AI Data Company Releases New All-in-one Data Annotation Platform (FREE TRIAL),https://www.reddit.com/r/deeplearning/comments/dt8908/multimilliondollar_ai_data_company_releases_new/,LimarcAmbalina,1573177900,[removed],0,1
70,2019-11-8,2019,11,8,12,dt97fx,TensorFlow Flags parsing error: Unknown command line flag 'do_train' Google BERT,https://www.reddit.com/r/deeplearning/comments/dt97fx/tensorflow_flags_parsing_error_unknown_command/,DrowsyTiger22,1573182575,"Hi all,

Im trying to implement google's BERT model as I have a task to complete. 

[https://github.com/tensorflow/models/tree/master/official/nlp/bert](https://github.com/tensorflow/models/tree/master/official/nlp/bert)

1. implement model with parameter do\_train=false, predict data in dev-v1.1.json, creating a CSV file with two columns: question\_id and prediction\_ans to store all your predictions.

I know how to convert the json output into a csv, but when i run the script as shown in the official github, I am getting teh error FLAG Flags parsing error: Unknown command line flag 'do\_train' when in run the script in terminal... so its not recognizing anything in the files. 

I have attached a screenshot of the script and the terminal output. 

[http://prntscr.com/pu0pku](http://prntscr.com/pu0pku)

i think it could be my version of tensorflow? i have v.1.15, installed the tf-nightly build as well, and did the export path thing to connect the path with the model. Im not sure what else could be wrong as it seems like its just not even registering the flags in the run\_squad.py file.",0,1
71,2019-11-8,2019,11,8,12,dt9oyg,How has work on optimizing training cost and model size for deep learning algorithms progressed? Do you have any sources to follow regarding this topic?,https://www.reddit.com/r/deeplearning/comments/dt9oyg/how_has_work_on_optimizing_training_cost_and/,alias_is,1573184973,,0,1
72,2019-11-8,2019,11,8,19,dtdf5n,Greetings from Tessellate Imaging,https://www.reddit.com/r/deeplearning/comments/dtdf5n/greetings_from_tessellate_imaging/,li8bot_,1573208007,[removed],0,1
73,2019-11-8,2019,11,8,19,dtdgb6,Studies in the variation of the features extracted by a CNN?,https://www.reddit.com/r/deeplearning/comments/dtdgb6/studies_in_the_variation_of_the_features/,drr21,1573208207,"Hi, I'm investigating what is the variation in the features extracted by a CNN per class. In other words, if we have a CNN classifier, every time we input an image we can extract a feature layer previous to the classification layer. Let's say we get 1000 features. I'm interesting in knowing what's the variation inside of a class (e.g. dog) for all these 1000 features. Does it follow a gaussian distribution? Or more complex distributions?

I've been looking for work done in this task but I haven't found anything. Do you guys know if someone researched this? Thanks!!",0,1
74,2019-11-8,2019,11,8,22,dtf4y6,Tutorial in how to build nice python CLIs,https://www.reddit.com/r/deeplearning/comments/dtf4y6/tutorial_in_how_to_build_nice_python_clis/,shawemuc,1573218187,How to Write Python Command-Line Interfaces like a Pro  https://link.medium.com/qW8XKsbTr1,0,1
75,2019-11-8,2019,11,8,22,dtf7y6,Problem with training a gan that is chained with a generator(1 input 1 output) and a discriminator (2 inputs 2 outputs).,https://www.reddit.com/r/deeplearning/comments/dtf7y6/problem_with_training_a_gan_that_is_chained_with/,classyflyer,1573218607,"I am building a generator (1 input 2 outputs) and a discriminator (2 inputs and 2 outputs) as two independent networks, and chain them together to build the gan. But unfortunately, when I train the gan, an error keeps telling me that I have to feed values to the first layer of the discriminator, but I think I did feed the following layer to the first layer of the discriminator within the gan. 

    dis_input_1 = keras.activations.linear(gan_inputs)
    

This is the error message I got: 

InvalidArgumentError: You must feed a value for placeholder tensor 'input\_2' with dtype float and shape \[?,152,232,1\] \[\[{{node input\_2}} = Placeholderdtype=DT\_FLOAT, shape=\[?,152,232,1\], \_device=""/job:localhost/replica:0/task:0/device:CPU:0""\]\]

Does anyone know how to fix this? Many thanks in advance!!

This is my entire code:

    import keras
    from keras import backend as K
    from keras.layers import ReLU, LeakyReLU, Conv2D, Conv2DTranspose, BatchNormalization, concatenate, Flatten, Dense, Reshape
    from keras.models import Model, clone_model, load_model
    import numpy as np
    
    
    K.clear_session()
    
    # Build autoencoder to be the generator
    
    img_shape = (152, 232, 1)
    latent_dim = 16
    
    inputs = keras.Input(shape=img_shape)
    x = Conv2D(16, 3, padding='same', strides=(2,2), activation='relu')(inputs)
    x = BatchNormalization()(x)
    x = Conv2D(32, 3, padding='same', strides=(2,2), activation='relu')(x)
    x = BatchNormalization()(x)
    shape = K.int_shape(x)
    x = Flatten()(x)
    latent = Dense(latent_dim, name='latent_vector')(x)
    x = Dense(shape[1] * shape[2] * shape[3])(latent)
    x = Reshape((shape[1], shape[2], shape[3]))(x)
    x = Conv2DTranspose(32, 3, padding='same')(x)
    x = LeakyReLU()(x)
    x = BatchNormalization()(x)
    x = Conv2DTranspose(16, 3, padding='same', strides=(2,2))(x)
    x = LeakyReLU()(x)
    x = BatchNormalization()(x)
    outputs = Conv2DTranspose(1, 3, padding='same', activation='tanh', strides=(2,2))(x)
    
    generator = Model(inputs, outputs)
    generator.summary()
    
    ae_disc = clone_model(generator)
    ae_disc.name=""autoencoder_discriminator""
    
    inputs_1 = keras.Input(shape=img_shape)
    inputs_2 = keras.Input(shape=img_shape)
    dis_outputs_1 = ae_disc(inputs_1)
    dis_outputs_2 = ae_disc(inputs_2)
    
    # Build discriminator
    discriminator = Model([inputs_1, inputs_2], [dis_outputs_1, dis_outputs_2])
    
    # Define loss function for discriminator
    loss_d = K.sum(K.abs(inputs_1 - dis_outputs_1)) - K.sum(K.abs(inputs_2 - dis_outputs_2))
    discriminator.add_loss(loss_d)
    
    # Compile discriminator
    discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)
    discriminator.compile(optimizer=discriminator_optimizer)
    discriminator.summary()
    
    # Freeze discriminator
    discriminator.trainable = False 
    
    gan_inputs = keras.Input(shape=img_shape)
    dis_input_1 = keras.activations.linear(gan_inputs)
    dis_input_2 = generator(gan_inputs)
    [gan_outputs_1, gan_outputs_2] = discriminator([dis_input_1, dis_input_2])
    
    # Build gan
    gan = Model(gan_inputs, [gan_outputs_1, gan_outputs_2]) 
    
    # Define gan loss
    loss_g = K.sum(K.abs(gan_inputs - dis_input_2)) + K.sum(K.abs(dis_input_2 - gan_outputs_2))
    gan.add_loss(loss_g)
    
    # Compile gan
    gan_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)
    gan.compile(optimizer=gan_optimizer)
    gan.summary()
    
    # Train model 
    
    # Squeeze pixel values into [-1, 1] since I use 'tanh' as activation for the autoencoder output
    x_train = train_imgs.astype('float32') / 255.*2-1 
    
    batch_size = 20
    
    start = 0
    for step in range(1000):
        stop = start + batch_size
        images = x_train[start: stop]
        generated_images = generator.predict(images)
    
        d_loss = discriminator.train_on_batch([images, generated_images], None)    
        g_loss = gan.train_on_batch(images, None)
    
        start += batch_size
        if start &gt; len(x_train) - batch_size:
            start = 0
    
        # Print losses
        if step % 10 == 0:
            # Print metrics
            print('discriminator loss at step %s: %s' % (step, d_loss))
            print('generator loss at step %s: %s' % (step, g_loss))",0,1
76,2019-11-8,2019,11,8,23,dtftzk,Learn TensorFlow 2.0: Basic Image Classification Tutorial (Part 1 of 5),https://www.reddit.com/r/deeplearning/comments/dtftzk/learn_tensorflow_20_basic_image_classification/,mippie_moe,1573221730,,1,1
77,2019-11-8,2019,11,8,23,dtgeq0,Conv3D layer with multiple input channels,https://www.reddit.com/r/deeplearning/comments/dtgeq0/conv3d_layer_with_multiple_input_channels/,Mike_Sv86,1573224462,"Hi all.

I have a question regarding keras Conv3D layer. My input are 3D volumes with 4 channels (image plus segmentation masks). 

Now iam wondering how the conv3D layer should be set up to work properly? When I write :

    Conv3D(64, (3, 3, 3), activation='relu', padding='same')(inputs)  

 or

    Conv3D(64, 3, activation='relu', padding='same')(inputs) 

and print out the filter shape it says:

(3, 3, 3, 4, 64)

When I write:  


    Conv3D(64, (3, 3, 4), activation='relu', padding='same')(inputs) 

though, the filter shape is:

(3, 3, 4, 4, 64)

As far as I have understood, the kernel depth should be the same as the image depth, or number of channels.

Now Iam wondering what the correct way is and why the filter shape has 5 dimensions. I would have expected 4 (heigh, width, depth, number of kernels)

&amp;#x200B;

Thanks in advance,

&amp;#x200B;

Cheers,

&amp;#x200B;

M",7,1
78,2019-11-9,2019,11,9,2,dtiaxq,Titanic &amp; Machine Learning Competition: Need somebody to team up with,https://www.reddit.com/r/deeplearning/comments/dtiaxq/titanic_machine_learning_competition_need/,knut_2,1573232585,"I'm looking for somebody to team up with to solve the competition Titanic: Machine Learning from Disaster hosted in [kaggle.com](https://kaggle.com/).

Here's the link:

[https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic)",0,1
79,2019-11-9,2019,11,9,2,dtivam,Choosing cpu / motherboard for a deep learning station,https://www.reddit.com/r/deeplearning/comments/dtivam/choosing_cpu_motherboard_for_a_deep_learning/,S_T47,1573234949,"So Im building a deep learning station because I do deep learning quiet regularly and google cloud just costs too much

I was thinking of the following motherboard;
Asus WS Z390 PRO 
https://www.asus.com/us/Commercial-Servers-Workstations/WS-Z390-PRO/

Mostly because it supports 4 PCIe lanes which allows me to slot more GPUs in (in the future) should I need it (currently I have 1)

Ive heard people say that if you use more GPUs then you need a powerful cpu too. So is the Intel core processors (ones that fit into the 1151 socket) strong enough to run 4 GPUs ? Or more specifically can a Intel core i7 9700k Octa core cpu run 4 GPUs or even 2?",6,1
80,2019-11-9,2019,11,9,4,dtkdm4,RNN not working,https://www.reddit.com/r/deeplearning/comments/dtkdm4/rnn_not_working/,Preetham_Gali,1573241268,,0,1
81,2019-11-9,2019,11,9,4,dtkdrz,Vertical Jump Test with Computer Vision,https://www.reddit.com/r/deeplearning/comments/dtkdrz/vertical_jump_test_with_computer_vision/,HenryAILabs,1573241290,[https://youtu.be/oIqWhCNHa30](https://youtu.be/oIqWhCNHa30),0,1
82,2019-11-9,2019,11,9,4,dtkjb7,help me to find the issue,https://www.reddit.com/r/deeplearning/comments/dtkjb7/help_me_to_find_the_issue/,Preetham_Gali,1573241913,"Can some one please help me out to find the issue with the RNN model which i have written in python.

[https://github.com/preethamgali/RNN\_scratch](https://github.com/preethamgali/RNN_scratch)",2,1
83,2019-11-9,2019,11,9,5,dtlf1d,Questions regarding the design of an experiment with Mask R-CNN,https://www.reddit.com/r/deeplearning/comments/dtlf1d/questions_regarding_the_design_of_an_experiment/,flyingbeanies,1573245470,"Hi, everyone

I'm an undergraduate in Engineering and currently planning an experiment in semantic segmentation using Mask R-CNN (my training data only has mask-type labels, no bouding boxes). I have some questions about training and validation, can someone help me?

**Training**

I have 4 datasets (roughly 30k images): 3 with the same annotation and 1 with more labels. Say, the first 3 have left and right arm labels, while the last one has left arm, right arm, left hand and right hand (my desired labels). I have limited resources (only those $300 in GCP credits). I plan on initializing my weights from COCO or ImageNet. Which is the best strategy:

1. To train with all 3 datasets, freezing my bottom layers and finish training with the final one
2. To train with 1 dataset at a time, freezing the bottom layers for the next dataset until I'm done with the 4th. As in, I train with dataset 1, freeze the bottom layers. Refine for dataset 2, then refine for dataset 3, and finally, for dataset 4.

**Validation**

Considering my resource limitation, how can I guarantee that my analysis is statistically correct? I see many papers training a model once and making affirmations on top of the results for a single iteration (I'm considering training iteration != epoch). Shouldn't I train my model multiple times, say, with a leave-k-out strategy, for instance? In this case, what is an acceptable number of iterations that I should execute?

Thanks a lot!",0,1
84,2019-11-9,2019,11,9,8,dto0py,Training on a cluster,https://www.reddit.com/r/deeplearning/comments/dto0py/training_on_a_cluster/,ssd123456789,1573256721,"I have always either trained models on my own gpu or on Google Colab. However, I need to now train a model on a cluster. All I know is that I need to use SSH and a docker container. Can anyone share any resources that will be helpful in getting started? Couldn't find anything suitable for beginners on YouTube or Google.",2,1
85,2019-11-9,2019,11,9,9,dto8fe,Tensorflow with an AMD GPU in 2019/2020,https://www.reddit.com/r/deeplearning/comments/dto8fe/tensorflow_with_an_amd_gpu_in_20192020/,mobo392,1573257725,,0,1
86,2019-11-9,2019,11,9,9,dtooy1,Java Deep learning cookbook released!,https://www.reddit.com/r/deeplearning/comments/dtooy1/java_deep_learning_cookbook_released/,willis7747,1573259917,[removed],0,1
87,2019-11-9,2019,11,9,11,dtpwsk,Which liquid-cooled RTX 2080 Ti brand to choose? [quiet 4 GPU DL office workstation],https://www.reddit.com/r/deeplearning/comments/dtpwsk/which_liquidcooled_rtx_2080_ti_brand_to_choose/,jakub37,1573266109,"Dear Deep Learning Community,

**tl;dr: What are the best price/value Nvidia RTX 2080 Ti brands for liquid-cooled models worth considering for a future proof, reliable 4 GPU workstation. (3-4 years use).**

I am volunteering to build a 4 GPU, future-proof deep learning workstation for a university lab. The machine will be in the office space and thus we prefer it to be liquid-cooled to reduce the noise. I looked for different GPU brands, and the price differences between liquid cooled models from different companies are substantial. Why is that? Is it good to save money and go with the cheapest?

I found the following RTX 2080 Ti Models so far:

[Zotac GeForce RTX 2080 Ti Graphic Card - 1.35 GHz Core - 1.55 GHz Boost Clock - 11 GB GDDR6](https://www.newegg.com/zotac-rtx-2080-ti-zt-t20810j-10p/p/N82E16814500466) (1244 USD)

[GIGABYTE AORUS GeForce RTX 2080 Ti XTREME WATERFORCE WB 11G Graphics Card, Pre-Installed Waterblock, 11GB 352-Bit GDDR6, GV-N208TAORUSX WB-11GC](https://www.newegg.com/gigabyte-geforce-rtx-2080-ti-gv-n208taorusx-wb-11gc/p/N82E16814932074) (1349 USD)

[EVGA GeForce RTX 2080 Ti FTW3 Ultra Hydro Copper Gaming, 11G-P4-2489-KR, 11GB GDDR6, RGB LED &amp; iCX2 Technology - 9 Thermal Sensors](https://www.amazon.com/EVGA-GeForce-Copper-11G-P4-2489-KR-Technology/dp/B07PWHZT73) (1599 USD)

EVGA brand seems to be a safe choice, according to what I found so far (however I was reading about air-cooled blower style cards). The price for 4 of such GPUs might be to high for decision making people approving the purchase, thus I am looking for alternatives.

I would appreciate your suggestions and comments. Reading a few hardware guides for Deep Learning computer setup, I noticed that the idea of water cooling was recommended but no hardware recommendation were made. Your recommendations with links are welcomed!

Thank you for taking your time to help me in this matter.

Regards, Jakub

P.S. This topic is cross-posted at:

[https://www.reddit.com/r/MachineLearning/comments/dtawvx/which\_liquidcooled\_rtx\_2080\_ti\_brand\_to\_choose/](https://www.reddit.com/r/MachineLearning/comments/dtawvx/which_liquidcooled_rtx_2080_ti_brand_to_choose/)

[https://www.reddit.com/r/buildapc/comments/dtpecb/which\_liquidcooled\_rtx\_2080\_ti\_brand\_to\_choose/](https://www.reddit.com/r/buildapc/comments/dtpecb/which_liquidcooled_rtx_2080_ti_brand_to_choose/)

[https://www.reddit.com/r/MLQuestions/comments/dtpsz7/which\_liquidcooled\_rtx\_2080\_ti\_brand\_to\_choose/](https://www.reddit.com/r/MLQuestions/comments/dtpsz7/which_liquidcooled_rtx_2080_ti_brand_to_choose/)",15,1
88,2019-11-9,2019,11,9,20,dtuv5d,Adding another RTX 2080 Ti or RTX Titan?,https://www.reddit.com/r/deeplearning/comments/dtuv5d/adding_another_rtx_2080_ti_or_rtx_titan/,kitgary,1573299322,"Hi guys, I already have a machine with a RTX 2080 Ti, I want to add another GPU because I want to learn how to train on multiple GPUs and training a larger data set. I can't decide whether I should buy another RTX 2080 Ti and setup NVLink or  buy a RTX Titan instead? Which option is better 2080 Ti NVlink vs 2080 Ti + RTX Titan?

Thanks",8,1
89,2019-11-10,2019,11,10,0,dtxhpi,What can I do to enhance network generalization capability?,https://www.reddit.com/r/deeplearning/comments/dtxhpi/what_can_i_do_to_enhance_network_generalization/,shahriar49,1573314019,"I have a dataset of around 3M training and 300K validation sequences and train an LSTM network with it. I tried many configurations but in most cases I end up with a gap between training and validation loss (and accuracy), as shown in below figure for a 3-layer network of around 90,000 parameters:

&amp;#x200B;

https://preview.redd.it/9izqx9hqkox31.png?width=640&amp;format=png&amp;auto=webp&amp;s=1771440835df1301f6934f6e0d8bbbf81c2df38d

I think it is not the case of overfitting and lack of generalization due to memorizing the input dataset, because number of input samples is way bigger than number of network parameters. What else can be the cause for this gap and how can it be improved?",4,1
90,2019-11-10,2019,11,10,2,dtymkm,2020 AI Residency Guide,https://www.reddit.com/r/deeplearning/comments/dtymkm/2020_ai_residency_guide/,Yuqing7,1573319201,,0,1
91,2019-11-10,2019,11,10,3,dtzqyd,Video processing pipeline with OpenCV,https://www.reddit.com/r/deeplearning/comments/dtzqyd/video_processing_pipeline_with_opencv/,jagin72,1573324348,Hi! Here is [the article](https://medium.com/deepvisionguru/video-processing-pipeline-with-opencv-ac10187d75b) for everybody interested in extracting faces from a video stream using a deep neural networks module from [\#OpenCV](https://www.facebook.com/hashtag/opencv?source=feed_text&amp;epa=HASHTAG). I hope you will like it.,0,1
92,2019-11-10,2019,11,10,6,du1vsn,"Two models containing the same submodel, after training the first model, will the second model's weights be updated also?",https://www.reddit.com/r/deeplearning/comments/du1vsn/two_models_containing_the_same_submodel_after/,classyflyer,1573334272,"Question: after training m1, will the weights in m2 also be updated because it uses the same submodel autoencoder? Thank you very much in advance!

    autoencoder = ...
    
    input1 = keras.Input(shape=img_shape)
    output1 = autoencoder(input1)
    m1 = Model(input1, output1)
    m1.compile(...)
    
    input2 = keras.Input(shape=img_shape)
    output2 = autoencoder(input2)
    m2 = Model(input2, output2)
    m2.compile(...)
    
    # Train model 1 
    m1.train_on_batch(...)",0,1
93,2019-11-10,2019,11,10,8,du3jol,TensorLayer Team Released Reinforcement Learning Algorithm Baseline-RLzoo,https://www.reddit.com/r/deeplearning/comments/du3jol/tensorlayer_team_released_reinforcement_learning/,quantumiracle,1573341927,"Recently,  in order to enable the industry to better use the cutting-edge  reinforcement learning algorithms, the TensorLayer Reinforcement   Learning Team has released a complete library of reinforcement learning   baseline algorithms for the industry  RLzoo. TensorLayer is an  extended  library based on TensorFlow for better supports of basic  neural network  construction and diverse neural network applications.  The RLzoo project  is the first comprehensive open source algorithm  library with  TensorLayer 2.0 and TensorFlow 2.0 since the release of  TensorFlow 2.0.  The library currently supports OpenAI Gym, DeepMind  Control Suite and  other large-scale simulation environments, such as  the robotic learning  environment RLBench, etc.

Link of full post: [https://medium.com/@zhding96/tensorlayer-team-released-reinforcement-learning-algorithm-baseline-rlzoo-2663cfb77904](https://medium.com/@zhding96/tensorlayer-team-released-reinforcement-learning-algorithm-baseline-rlzoo-2663cfb77904)

Link of RLzoo: [https://github.com/tensorlayer/RLzoo](https://github.com/tensorlayer/RLzoo)

Link of RL tutorial: [https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement\_learning](https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement_learning)

Slack group: [https://app.slack.com/client/T5SHUUKNJ/D5SJDERU7](https://app.slack.com/client/T5SHUUKNJ/D5SJDERU7)",2,1
94,2019-11-10,2019,11,10,16,du8ldo,Tensor Core Speedup in FC Network?,https://www.reddit.com/r/deeplearning/comments/du8ldo/tensor_core_speedup_in_fc_network/,salilmathur1690,1573371727,Has anyone benchmarked speed up in fully connected network (without attention/transformer) using a Volta or Turing Tensor Cores?,2,1
95,2019-11-10,2019,11,10,16,du8p0t,Deep learning has a size problem,https://www.reddit.com/r/deeplearning/comments/du8p0t/deep_learning_has_a_size_problem/,HN_Crosspost_Bot,1573372502,,1,1
96,2019-11-10,2019,11,10,22,dub8t7,Fire security warning system(using Yolov3),https://www.reddit.com/r/deeplearning/comments/dub8t7/fire_security_warning_systemusing_yolov3/,christw16,1573391464,"If I use Yolov3 to detect whether there is a fire happened, and then I want to send emails to warn people.

How to send emails automatically?

Thank you.",1,1
97,2019-11-11,2019,11,11,0,dud1h9,AI has learned how to effectively separate audio recordings into music and vocals,https://www.reddit.com/r/deeplearning/comments/dud1h9/ai_has_learned_how_to_effectively_separate_audio/,cmillionaire9,1573400855,,8,1
98,2019-11-11,2019,11,11,8,duj4ye,A simple Android app to transfer Makeup from one face to another. And all processing happens on the device.,https://www.reddit.com/r/deeplearning/comments/duj4ye/a_simple_android_app_to_transfer_makeup_from_one/,cortlandd,1573427511,,7,1
99,2019-11-11,2019,11,11,10,dul1mw,"train a model on synthesis data, generalize it on real data",https://www.reddit.com/r/deeplearning/comments/dul1mw/train_a_model_on_synthesis_data_generalize_it_on/,boostsch,1573436193," I trained a deep learning computer vision model for image segmentation using synthesis data, and it generalizes well on synthesis data. However, when I apply the model in real data, the generalization is not so good. I know I should use some domain adaption techniques, but it is a big topic. Anyone can suggest me some papers that are close to this problem ?",2,1
100,2019-11-11,2019,11,11,17,dupdnz,5 Notable Artificial Intelligence Trends in 2019,https://www.reddit.com/r/deeplearning/comments/dupdnz/5_notable_artificial_intelligence_trends_in_2019/,Karan-Deol,1573459826,,0,1
101,2019-11-11,2019,11,11,18,duq3ar,Awesome Google Tool to build Classifiers - No Code,https://www.reddit.com/r/deeplearning/comments/duq3ar/awesome_google_tool_to_build_classifiers_no_code/,clone290595,1573464717,"I just found this experiment from Google, I've been able to explain Deep Learning to my mom, thanks to this, and that was a hard benchmark.

Very good to build interactive demo's!

[https://teachablemachine.withgoogle.com](https://teachablemachine.withgoogle.com/train/image)",1,1
102,2019-11-11,2019,11,11,19,duqjg9,Transfer Learning with TensorFlow 2,https://www.reddit.com/r/deeplearning/comments/duqjg9/transfer_learning_with_tensorflow_2/,RubiksCodeNMZ,1573467654,,0,1
103,2019-11-11,2019,11,11,20,duqw93,Deep artificial neural networks that can accurately predict the neural responses,https://www.reddit.com/r/deeplearning/comments/duqw93/deep_artificial_neural_networks_that_can/,aiforworld2,1573470057,"A Nature Neuroscience paper shows a deep artificial neural networks that can accurately predict the neural responses produced by a biological brain to arbitrary visual stimuli.

#artificialintelligence #AI #deeplearning #neuralnetworks #brain #Neuroscience 

https://www.nature.com/articles/s41593-019-0517-x.epdf",0,1
104,2019-11-11,2019,11,11,20,dur0cl,Human in the loop workflows for deep learning solutions - OCR review and moderation,https://www.reddit.com/r/deeplearning/comments/dur0cl/human_in_the_loop_workflows_for_deep_learning/,manneshiva,1573470770,"there's a lot of paranoia these days  about how adverse automation's  effects might be on society. there's some tasks that can definitely be automated and will cause certain segments of the workforce their jobs. but alongside, other opportunities will get created that didn't exist  before. our new [blog post](https://nanonets.com/blog/human-in-the-loop-ai/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=hil) discusses how businesses are transforming, about digital information, automation, the future of work and human in the loop workflows as a possible solution to these concerns.

&amp;#x200B;

*Processing gif jojvexrqi1y31...*",0,1
105,2019-11-11,2019,11,11,21,durwiq,Is there a solution for SOTA in the industry for model uncertainty in deep learning?,https://www.reddit.com/r/deeplearning/comments/durwiq/is_there_a_solution_for_sota_in_the_industry_for/,quoniammm,1573476355,[removed],1,1
106,2019-11-12,2019,11,12,0,dutvdi,"Nov 21, Free Talk on PyTorch with Its Co-Author and Maintainer, Adam Paszke",https://www.reddit.com/r/deeplearning/comments/dutvdi/nov_21_free_talk_on_pytorch_with_its_coauthor_and/,ACMLearning,1573485986,,0,1
107,2019-11-12,2019,11,12,0,duu08s,Question regarding data samples for a small dataset,https://www.reddit.com/r/deeplearning/comments/duu08s/question_regarding_data_samples_for_a_small/,topenwor,1573486581,"I'm trying to train an NN for a multiclass text classification problem. The dataset I have is quite small(around 1000-2000 data points) and a total of about 20-30 classes. 

Some classes have more samples available than others, generally around 10-50 more but in some cases 100s more than others. 

For best accuracy and generalization on unknown data, should I limit the number of samples for each class to a certain number or  I should keep the extra samples some of the classes?",3,1
108,2019-11-12,2019,11,12,2,duvpqf,Multiple object detection with CNN,https://www.reddit.com/r/deeplearning/comments/duvpqf/multiple_object_detection_with_cnn/,Betaji2,1573493640,"Hi I am new to deep learning and was wondering if you could detect multiple objects with a CNN in a single frame. For example if I had a CNN trained on cats and dogs and ran a picture of a cat and a dog together through it, then how could I get it to detect both a cat and dog. If this is not possible with a CNN then what method should I use(yolo,SSD,etc). If I could how could do it(in python)?",3,1
109,2019-11-12,2019,11,12,3,duwexu,Open Source Low code transfer learning tool for computer vision,https://www.reddit.com/r/deeplearning/comments/duwexu/open_source_low_code_transfer_learning_tool_for/,abhishek4273,1573496422,"Introducing MONK: An **open-source low code** transfer learning toolkit that acts as a unified wrapper over deep learning frameworks

We used this tool as initial protoypying step while participating in kaggle and codalab competitions, a lot of times accelerating our rankings and reaching top-30% in matter of hours. Ans now releasing it to the public with new future goals. 

Acts as a wrapper over Pytorch, Keras, Mxnet-Gluon

Website: [https://monkai-42.firebaseapp.com/](https://monkai-42.firebaseapp.com/)

Github: [https://github.com/Tessellate-Imaging/monk\_v1](https://github.com/Tessellate-Imaging/monk_v1)

Medium: [https://medium.com/@Abhishek4273/expediting-transfer-learning-the-monks-way-422d7ec40ec6](https://medium.com/@Abhishek4273/expediting-transfer-learning-the-monks-way-422d7ec40ec6)",0,1
110,2019-11-12,2019,11,12,3,duwiq1,Error loading a model (.h5 file) after training yolo-keras classification model,https://www.reddit.com/r/deeplearning/comments/duwiq1/error_loading_a_model_h5_file_after_training/,yazmaz54,1573496824,"I am working on realtime object detection using my laptop's camera with Yolo and Keras. I have trained a model and the resulting output is a .h5 file containing (from my understanding) the model and the weights. When trying to test the model with my webcam I get the following error: ""NameError: name 'yolo\_head' is not defined""

[Here's](https://datascience.stackexchange.com/questions/63017/error-loading-a-model-h5-file-after-training-yolo-keras-classification-model) my code.

Any help would be highly appreciated please I need this for a school project.",3,1
111,2019-11-12,2019,11,12,5,duy5n1,Performance anomaly when testing with part of data,https://www.reddit.com/r/deeplearning/comments/duy5n1/performance_anomaly_when_testing_with_part_of_data/,shahriar49,1573503146,"I have a dataset of around 400K sequences, each sequence being a time-series of imagery observations for a specific pixel within a total of around 32K pixels. The sequences are accumulated over 13 years (each sequence belongs to one year), and I train an LSTM model with different training ratios from 10% to 90% of data (sampling is stratified random). Then I test the model in two scenarios: One time on the whole dataset and another time on one sequences that belong to a specific selected year. I compute overall accuracy and average F1, precision, and recall (averages over classes) and compare the results. I have two problems now:

1- Although in almost all cases I see the performance increases with increasing training ratio from 10% to 90% except in one case of average F1 for ratio of 50%, which is a bit smaller than the same metric for sampling ratio of 30%. What can be the cause? Just random fluctuations?

&amp;#x200B;

2- More important than the above, when I test the trained model on a specific year, the performance measures drop considerably (e.g. overall accuracy of 90% will become 80% or average F1 of 68% become 58%). I don't expect the metrics be exactly the same, but given the sampling for training was done in random and pixels under Landsat measurements was checked to be relatively stable in terms on Landcover conditions, I am a bit surprised by this big performance  decrease. In addition, in this test I have model trained with 70% of data performing considerably worse than model trained with 50% of data (e.g. overall accuracy drop by 5%). Is it just random fluctuation? Doesn't look like that in my eye.",0,1
112,2019-11-12,2019,11,12,5,duyv9i,A great and thorough explanation of convolutional neural networks,https://www.reddit.com/r/deeplearning/comments/duyv9i/a_great_and_thorough_explanation_of_convolutional/,antaloaalonso,1573505808,,2,1
113,2019-11-12,2019,11,12,6,duzfkw,"After watching this - I started to believe that deep learning is not complete BS... if you think it is, like I did, for many years, then watch this. I can imagine that DNNs will change into some form of higher order async functional reactive programming and that might lead to some revolution.",https://www.reddit.com/r/deeplearning/comments/duzfkw/after_watching_this_i_started_to_believe_that/,yetanothernormalG,1573507998,,0,1
114,2019-11-12,2019,11,12,6,duzjh6,Are there any funded conferences with good hindex?,https://www.reddit.com/r/deeplearning/comments/duzjh6/are_there_any_funded_conferences_with_good_hindex/,muaz65,1573508419,"I recently graduated and have 3 publications and 1 submission. All in deep learning and A* confrences. But in order to submit you have to present the paper if accepted. The travel expenditure is quite extensive. Moreover, paper regulations for most confrences cost upto 400$ even for students. Are there any funded conferences with avg Hindex~50 which compensates your travel expenditure?",0,1
115,2019-11-12,2019,11,12,10,dv2ldu,[AI application with source code] Let your machine play Street Fighter!,https://www.reddit.com/r/deeplearning/comments/dv2ldu/ai_application_with_source_code_let_your_machine/,1991viet,1573521839,,12,1
116,2019-11-12,2019,11,12,10,dv2oae,"So Im working on this new project, and I need more data, MUCH more data. So is you could help me out by commenting with some chocolate chip cookie recipes and an honest rating out of 100. This would help me out so much if you could participate.",https://www.reddit.com/r/deeplearning/comments/dv2oae/so_im_working_on_this_new_project_and_i_need_more/,thatnerd69,1573522208,,2,1
117,2019-11-12,2019,11,12,13,dv4wxr,Loss functions for my CNN,https://www.reddit.com/r/deeplearning/comments/dv4wxr/loss_functions_for_my_cnn/,Weap0n_X,1573533198,"Hi everybody! I am currently creating a CNN for digital image processing l, although I would need to implement a loss function different from the standard ones. I would therefore need to ask you if anyone knows where can I find pieces of code with different loss functions created from scratch that I could study in order to learn how to do it (I have already searched on Google but to no avail) or even simple documents, everything that might help me would be extremely welcome.",2,1
118,2019-11-12,2019,11,12,15,dv5xmo,Visualizing output of different filters of CNN,https://www.reddit.com/r/deeplearning/comments/dv5xmo/visualizing_output_of_different_filters_of_cnn/,pranav2109,1573539180,"I am trying to visualize the output of different layers of a CNN for a given input image. The output of the first layer filters are as expected but following that the second and third layers the output are as shown below. In order to visualize I mapped the values to 0-1 but still the problem persists. Is there any specific reason for this?

https://preview.redd.it/93850zpp57y31.png?width=640&amp;format=png&amp;auto=webp&amp;s=b749e88215d09a8fefabd457ed1ead17c751294e",1,1
119,2019-11-12,2019,11,12,16,dv6itq,Visualizing the Future of Computer Vision Across Businesses,https://www.reddit.com/r/deeplearning/comments/dv6itq/visualizing_the_future_of_computer_vision_across/,Karan-Deol,1573542793,,0,1
120,2019-11-12,2019,11,12,19,dv87yw,[Post] Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/dv87yw/post_reinforcement_learning/,cdossman,1573554677," Learning how to train an agent to make decisions that will maximize rewards over time

[https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-4-optimal-policy-search-with-mdp-7fc96158ea8a](https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-4-optimal-policy-search-with-mdp-7fc96158ea8a)",0,1
121,2019-11-13,2019,11,13,3,dvdmxd,Texas A&amp;M and Simon Fraser Universities Open-Source RL Toolkit for Card Games,https://www.reddit.com/r/deeplearning/comments/dvdmxd/texas_am_and_simon_fraser_universities_opensource/,Yuqing7,1573581664,,2,1
122,2019-11-13,2019,11,13,3,dvec5s,Inference in Deep Learning,https://www.reddit.com/r/deeplearning/comments/dvec5s/inference_in_deep_learning/,HenryAILabs,1573584532,[removed],0,1
123,2019-11-13,2019,11,13,8,dviumy,Self-Training with Noisy Student (New ImageNet State-of-the-Art),https://www.reddit.com/r/deeplearning/comments/dviumy/selftraining_with_noisy_student_new_imagenet/,HenryAILabs,1573602482,[https://youtu.be/Y8YaU9mv\_us](https://youtu.be/Y8YaU9mv_us),1,1
124,2019-11-13,2019,11,13,17,dvoqgv,Andrej Karpathys neural network trained on Shakespeares corpus,https://www.reddit.com/r/deeplearning/comments/dvoqgv/andrej_karpathys_neural_network_trained_on/,guacforlife13,1573633359,Was the resulting test produced from his neural network semantically coherent? Grammatically coherent?,2,1
125,2019-11-13,2019,11,13,21,dvqwtc,models for transcription,https://www.reddit.com/r/deeplearning/comments/dvqwtc/models_for_transcription/,kapilg1711,1573647323,"How are acoustic and language models developed for medical and legal transcription services? Is there any way to use the audio files and their transcriptions to build these models? I have many transcription files and their original audio files, but I don't know how to use them to build a model.",1,1
126,2019-11-13,2019,11,13,23,dvsgth,Feature Extraction from Google Maps,https://www.reddit.com/r/deeplearning/comments/dvsgth/feature_extraction_from_google_maps/,pranav2109,1573655066,Is there any work that has been able to extract latent low dimensional features from google maps of the ego vehicle?,4,1
127,2019-11-14,2019,11,14,6,dvyo3e,Is Image/Video Data Collection for Deep Learning is Hard? Share your opinion and we can directly help you with your problem.,https://www.reddit.com/r/deeplearning/comments/dvyo3e/is_imagevideo_data_collection_for_deep_learning/,srbh66,1573680637,,8,1
128,2019-11-14,2019,11,14,7,dvzw1n,Building chess bot for rasberi pi with opencv,https://www.reddit.com/r/deeplearning/comments/dvzw1n/building_chess_bot_for_rasberi_pi_with_opencv/,Jonisas0407,1573685445,"Hello everybody,

I have started attending weekly meetups for ML beginners and all of us needs to think of a project to work on for 10 weeks. I have recently bought a raspi 3 with a camera module and my idea is:

To create a chess bot which would work like this:

- camera on raspi scans the board
- on monitor chess bots move is presented ( i make the move in real life for the bot )
- i make a move
- bots makes a move and so on while scanning the board all the time

Bonus idea:

- instead of playing game from the beginning I could randomly put chess pieces on board and then play from there with the bot


My questions are:

- how would I start to work on this project? I assume I will get the raspi to scan the board and present the live view on monitor.
- what algorithm should I use? There is a dataset on kaggle of 200k chess position images on a board, could I use this to train the model?

Thank you for your suggestions!",2,1
129,2019-11-14,2019,11,14,10,dw27ms,Weird nvidia-smi GPU usage display,https://www.reddit.com/r/deeplearning/comments/dw27ms/weird_nvidiasmi_gpu_usage_display/,Believinginself,1573695768,"Hi, 

I used nvidia-smi to see the GPU memory usage and my GPU 0 has max memory displayed as 11178MiB out of which it displays 6786 MiB is being used. But below that where PIDs are dislayed, it shows 3 users are using GPU 0 each with 5959MiB, 817MiB, 13535MiB resp. The 3rd user's GPU memory usage is more than the capacity of the GPU, how is that possible? Can someone please explain me the weird behavior or if I am interpreting it wrong?",1,1
130,2019-11-14,2019,11,14,12,dw3lnf,A question regarding Mobilenet v3,https://www.reddit.com/r/deeplearning/comments/dw3lnf/a_question_regarding_mobilenet_v3/,awaiss113,1573702581,"I am trying to understand the architecture of Mobilenet v3. I am little confused in the structure. After Conv2d, is 255 added in the output of Conv2d (no. 2 in picture) and then 255 is multiplied by the sum (3 no. in image). and in no. 4, 1x28x28x72 is multiplied by 1x1x1x72. Am I right or I am getting something wrong? After no.4, output size is 1x28x28x72.  
If output of no.3 is multiplied by no.1 then how this multiplication is being done? I am confused at this point.

![img](4gsqpwy5nky31)",1,1
131,2019-11-14,2019,11,14,13,dw48l4,Linux distro,https://www.reddit.com/r/deeplearning/comments/dw48l4/linux_distro/,topecas,1573705914,"Hey everybody! 

Im doing to jump to linux and was just wonder what distro you guys use for DL! I will be using tensorflow 2.0 with NVIDIA GPUS.

Thank you!",0,1
132,2019-11-14,2019,11,14,20,dw7zpy,Any one here tried to create stock perdition,https://www.reddit.com/r/deeplearning/comments/dw7zpy/any_one_here_tried_to_create_stock_perdition/,sarathak7,1573729217,[removed],0,1
133,2019-11-14,2019,11,14,21,dw8rc2,How can a neural net recognize it is out of its training domain?,https://www.reddit.com/r/deeplearning/comments/dw8rc2/how_can_a_neural_net_recognize_it_is_out_of_its/,some_dadaism,1573733943,In a recent kaggle competition with a huge overfitting potential the winning team first searched for features on the training data and after the feature engineering used a Kolmogorov-Smirnov Test for comparing the distribution of the features on the training and validation set. Features with a different distribution on the validation set were excluded. (https://www.kaggle.com/c/LANL-Earthquake-Prediction/discussion/94390#latest-632778) My question is how it is possible to replicate this for a neural network and to realize that the feed forward features of a layer in the end of the network are different from the domain it was trained on? Is there any research that is going into this direction?,13,1
134,2019-11-14,2019,11,14,21,dw8x42,Dropout and Pruning,https://www.reddit.com/r/deeplearning/comments/dw8x42/dropout_and_pruning/,Rebeencs,1573734831," Pruning removes the nodes which add little predictive power for the problem in hand.

&amp;#x200B;

Dropout layer is a regularisation technique, which is used to prevent overfitting during the training phase. Neurons are randomly selected and ignored by the dropout layer during the training phase. Those ignored neurons are temporally removed on the forward pass, and their weights are not updated on the backward pass.

could you please provide some details about their differences, I still think they are doing a similar job, are they?",2,1
135,2019-11-14,2019,11,14,23,dwafhn,Basic question regarding construction of training labels/tensors in YOLOv3 and the concept of anchor box,https://www.reddit.com/r/deeplearning/comments/dwafhn/basic_question_regarding_construction_of_training/,tabmoo,1573742574,[removed],0,1
136,2019-11-15,2019,11,15,0,dwb1h3,Generating Cubism style Modern Art using Generative Adversarial Network(GAN),https://www.reddit.com/r/deeplearning/comments/dwb1h3/generating_cubism_style_modern_art_using/,anyesh,1573745370,"Generating Modern Arts using
Generative Adversarial Network(GAN) on Spell by Anish Shrestha https://link.medium.com/IVnSqLo5A1",0,1
137,2019-11-15,2019,11,15,0,dwb7il,Generating Cubism Style Modern Art using GAN,https://www.reddit.com/r/deeplearning/comments/dwb7il/generating_cubism_style_modern_art_using_gan/,anyesh,1573746102,,3,1
138,2019-11-15,2019,11,15,0,dwbfho,Awesome AI Research and Papers reviewed on Computer Vision News (with codes!) - Nov. 2019,https://www.reddit.com/r/deeplearning/comments/dwbfho/awesome_ai_research_and_papers_reviewed_on/,Gletta,1573747111,"The November issue of Computer Vision News: 38 pages about AI and Deep Learning through research and practical applications.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019November/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-august-pdf/)

Technical articles on pages 4-8 and 24-29. Subscribe for free on page 38.

Enjoy!",0,1
139,2019-11-15,2019,11,15,3,dwdktn,The number of dense layers without activation,https://www.reddit.com/r/deeplearning/comments/dwdktn/the_number_of_dense_layers_without_activation/,fibonacci_bokertov,1573755935,"I've been told that the number of fully connected layers without activation layer between them one after another is limited to 1-2 layers.

 Is this true? I have rnn and then three dense layers, should I use activation layer between fcc layers here?",4,1
140,2019-11-15,2019,11,15,4,dwetp8,Deep Learning in Psychiatry,https://www.reddit.com/r/deeplearning/comments/dwetp8/deep_learning_in_psychiatry/,lkjiomva,1573761230,[removed],0,1
141,2019-11-15,2019,11,15,4,dwevly,FCN full connected network sequence classification ?,https://www.reddit.com/r/deeplearning/comments/dwevly/fcn_full_connected_network_sequence_classification/,nicetryho,1573761451,[removed],0,1
142,2019-11-15,2019,11,15,6,dwgeq2,Looking to use xNN magicsauce to help crack a cold case.,https://www.reddit.com/r/deeplearning/comments/dwgeq2/looking_to_use_xnn_magicsauce_to_help_crack_a/,camwrangles,1573767977,"Hey gang. 

The stakes aren't quite as dramatic as the title, but I thought this would be a great way for me to experiment with deep learning and solve a hit and run at the same time. 

Couple of weeks ago a very inconsiderate woman backed over my motorcycle then proceeded to cover it up by picking the bike up and driving away without leaving a note or inspecting the bike. When I got returned I had no idea it had been damaged, and drove for a couple of blocks before realizing something was off. When I drove back to the scene, I  discovered  the damage, including the fact that my break reservoir was shattered, draining all my brake fluid. I was surley a half a mile away from loosing my front breaks altogether. She literally left me for dead! (cue dramatic music)

Luckily a neighbor security camera caught it all happening. I filed a police report, but unfortunately, I'm unable to recover the license plate so the case is cold.

This is where I was thinking a deep learning project would come in. My thought was that I could set up a similar camera and capture cars parked in this location with similar lighting conditions. I'd then record the actual license plates by hand (or use a higher res camera) so I would have the correct numbers to feed into the training set. 

I've never gone thought this process before, and am not sure if I should use a CNN or GAN here, and frankly not sure what  I would use for a framework (is that the right word). To be honest, I'm not really sure I constructed the last sentence properly. But! I'm eager to learn. I'm a technical person, I enjoy playing around in bash, but I'm just beginning to learn to code. 

I welcome any thoughts, suggestions or advice as I don my digital houndstooth cap and pipe, and begin sleuthing in the AI age. 

&amp;#x200B;

![img](qv8vqax22qy31)

&amp;#x200B;

![video](8ykgowp32qy31)",16,1
143,2019-11-15,2019,11,15,7,dwh1cz,"What are the differences between meta-learning, few-shot learning and imitation learning?",https://www.reddit.com/r/deeplearning/comments/dwh1cz/what_are_the_differences_between_metalearning/,pirilamp,1573770530,[removed],0,1
144,2019-11-15,2019,11,15,13,dwldvm,The Beauty of Deep Neural Networks (Art of the Problem posted today),https://www.reddit.com/r/deeplearning/comments/dwldvm/the_beauty_of_deep_neural_networks_art_of_the/,puppers90,1573791259,,0,1
145,2019-11-15,2019,11,15,19,dwozs8,Kindly let us know your reviews on this in order to improve!,https://www.reddit.com/r/deeplearning/comments/dwozs8/kindly_let_us_know_your_reviews_on_this_in_order/,day1technologies,1573814040,,0,1
146,2019-11-16,2019,11,16,2,dwtvje,Weekly Papers | EMNLP 2019 Best Paper; Facebook XLM-R and More!,https://www.reddit.com/r/deeplearning/comments/dwtvje/weekly_papers_emnlp_2019_best_paper_facebook_xlmr/,Yuqing7,1573838477,,0,1
147,2019-11-16,2019,11,16,4,dwvxvl,DeepMind Research Lead Doina Precup On Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/dwvxvl/deepmind_research_lead_doina_precup_on/,Yuqing7,1573847620,,0,1
148,2019-11-16,2019,11,16,5,dwwmnr,This PyTorch Library Kaolin is Accelerating 3D Deep Learning Research [Paper and Github included in article],https://www.reddit.com/r/deeplearning/comments/dwwmnr/this_pytorch_library_kaolin_is_accelerating_3d/,ai-lover,1573850649,,3,1
149,2019-11-16,2019,11,16,11,dx14vk,Just a fun project :),https://www.reddit.com/r/deeplearning/comments/dx14vk/just_a_fun_project/,JC1DA,1573872527,,1,1
150,2019-11-16,2019,11,16,14,dx2o78,"About beam search. In this 2nd step , i cant to understand that for why for jane we got two outputs . That means for every word there will be 3 words output like for word ""in , jane and September . So total of 9 outputs we will select best 3. And that'y word jane got 2 results(is, visits) ?",https://www.reddit.com/r/deeplearning/comments/dx2o78/about_beam_search_in_this_2nd_step_i_cant_to/,Sahil8141,1573881442,,0,1
151,2019-11-16,2019,11,16,15,dx3icj,My Fun Project --- Need to optimize it further -- Previous link was expired...,https://www.reddit.com/r/deeplearning/comments/dx3icj/my_fun_project_need_to_optimize_it_further/,JC1DA,1573887014,,16,1
152,2019-11-16,2019,11,16,17,dx4874,Resources for understanding Encoder-Decoder networks,https://www.reddit.com/r/deeplearning/comments/dx4874/resources_for_understanding_encoderdecoder/,in_iam,1573892371,"I am trying to design a model for Document Semantic Segmentation. A research paper I'm looking at proposes an encoder-decoder architecture for the model but the paper doesn't go too much into the detail of the architecture.  


Can anyone share with me any/all relevant resources to read up more on Encoder-Decoder models ? (If possible, CNN models)",1,1
153,2019-11-16,2019,11,16,17,dx4e7h,[P] Nearing BERT's accuracy on Sentiment Analysis with a model 56 times smaller by Knowledge Distillation,https://www.reddit.com/r/deeplearning/comments/dx4e7h/p_nearing_berts_accuracy_on_sentiment_analysis/,pirate7777777,1573893672,,0,1
154,2019-11-16,2019,11,16,19,dx5crf,Interesting project ideas for beginner,https://www.reddit.com/r/deeplearning/comments/dx5crf/interesting_project_ideas_for_beginner/,tolo5star,1573900839,"I'm a beginner with some mathematical background and   I am comfortable with python , would love to know any interesting projects as well as some more sources to learn from !",5,1
155,2019-11-17,2019,11,17,1,dx8osj,About beam search,https://www.reddit.com/r/deeplearning/comments/dx8osj/about_beam_search/,Sahil8141,1573920285,,7,1
156,2019-11-17,2019,11,17,7,dxe6hz,Sudden training loss drop.. what is happening?,https://www.reddit.com/r/deeplearning/comments/dxe6hz/sudden_training_loss_drop_what_is_happening/,daisygarland,1573945049,"I was wondering if anyone has seen such a drop in training loss without dropping the learning rate? What could have caused this?

https://preview.redd.it/gpvo31t4p4z31.png?width=1176&amp;format=png&amp;auto=webp&amp;s=d88e3f399d88d4e10480fb3538754d039ceae26a",4,1
157,2019-11-17,2019,11,17,21,dxm4ul,Help request in finding a link,https://www.reddit.com/r/deeplearning/comments/dxm4ul/help_request_in_finding_a_link/,clone290595,1573994775," Crossposting from r/MachineLearning:

Hi, a few months ago I've found in complete serendipity a very cool website, but I can't find it again.

The website was a list of the **several tasks solved by Machine Learning**.

I also think I remember that there was an indicator of ""how much"" the task in question was solved, and I remember that the screen also divides the macro-categories by color.

Can you help me find it?

It was one of the most useful links I've ever seen, and I think it would be good for everyone to have it!

thanks in advance for the help :-)",2,1
158,2019-11-18,2019,11,18,0,dxo2ac,Self- Programmed Self Driving Car with Code,https://www.reddit.com/r/deeplearning/comments/dxo2ac/self_programmed_self_driving_car_with_code/,nowsden,1574005595,"Hello, my last post was this and people said that I should keep you posted so I did that. [https://www.reddit.com/r/deeplearning/comments/ck65xj/is\_it\_weird\_when\_a\_14\_year\_old\_publishes\_a\_paper/](https://www.reddit.com/r/deeplearning/comments/ck65xj/is_it_weird_when_a_14_year_old_publishes_a_paper/). I  came back to my project and kept working on it now I wrote a little post about it. [https://littlemountainman.github.io/2019/11/27/selfdrivingfun/](https://littlemountainman.github.io/2019/11/27/selfdrivingfun/)

I wrote about the development and the steps I took to make this. 

Here is a little sneak peak: 

&amp;#x200B;

https://i.redd.it/j7qxb594p9z31.gif",0,1
159,2019-11-18,2019,11,18,1,dxodbc,Self-Programmed Self Driving Car,https://www.reddit.com/r/deeplearning/comments/dxodbc/selfprogrammed_self_driving_car/,nowsden,1574007008,,0,1
160,2019-11-18,2019,11,18,3,dxpxfn,Deep learning applications in networking and cybersecurity,https://www.reddit.com/r/deeplearning/comments/dxpxfn/deep_learning_applications_in_networking_and/,AlZeus109,1574013718,"Besides anomaly detection, what are other interesting applications of deep learning in networking and cybersecurity?",3,1
161,2019-11-18,2019,11,18,5,dxs3yn,A causal tour of causality - David Lpez Paz -,https://www.reddit.com/r/deeplearning/comments/dxs3yn/a_causal_tour_of_causality_david_lpez_paz/,data_datum,1574022836,"Slides:  [https://drive.google.com/file/d/1IS26HUB20vDKuRGCUGGnukdMxqskRUJ9/view](https://drive.google.com/file/d/1IS26HUB20vDKuRGCUGGnukdMxqskRUJ9/view) 

Video:  [http://tv.vera.com.uy/video/55354](http://tv.vera.com.uy/video/55354)",1,1
162,2019-11-18,2019,11,18,6,dxt9v8,Bias Applications,https://www.reddit.com/r/deeplearning/comments/dxt9v8/bias_applications/,iampaliwal,1574027690,Are there any applications where we can utilise the data bias in the machine learning model?,1,1
163,2019-11-18,2019,11,18,17,dy0n3s,Transfer Learning with TensorFlow 2  Model Fine Tuning,https://www.reddit.com/r/deeplearning/comments/dy0n3s/transfer_learning_with_tensorflow_2_model_fine/,RubiksCodeNMZ,1574066989,,0,1
164,2019-11-18,2019,11,18,18,dy136h,[Research] Explainable Artificial Intelligence (XAI) for 6G: Improving Trust between Human and Machine,https://www.reddit.com/r/deeplearning/comments/dy136h/research_explainable_artificial_intelligence_xai/,cdossman,1574070212,"How can we better build trust between humans and machines? At the heart of our need to add explainability/interpretability/openness to deep learning is the need to build trust in a quantifiable way. Researchers in this paper outline the core concepts of Explainable Artificial Intelligence (XAI) for 6G, including public and legal motivations, definitions of explainability, performance vs. explainability trade-offs, methods to improve explainability, and frameworks to incorporate XAI into future wireless systems.

  
Read more: [https://arxiv.org/abs/1911.04542v1](https://arxiv.org/abs/1911.04542v1?fbclid=IwAR2Pykm3Y_PwC0CozMmLwk2NgRDNJWLhgb9R0sSy1SCxcDAxYBNW1TCVJ-k)",0,1
165,2019-11-18,2019,11,18,20,dy1zuw,AI-powered Optical Character Recognition for Global Businesses,https://www.reddit.com/r/deeplearning/comments/dy1zuw/aipowered_optical_character_recognition_for/,Karan-Deol,1574076560,,0,1
166,2019-11-18,2019,11,18,22,dy3dab,[Research] Interested in Performing End-to-End RL Learning and Experimentation? You Need DeepRacer,https://www.reddit.com/r/deeplearning/comments/dy3dab/research_interested_in_performing_endtoend_rl/,cdossman,1574084739,"To deal with current complexities in training and experimenting RL, researchers recently presented DeepRacer, an experimentation and educational platform for sim2real reinforcement learning.

[https://medium.com/ai%C2%B3-theory-practice-business/interested-in-performing-end-to-end-rl-learning-and-experimentation-you-need-deepracer-d088088ca314](https://medium.com/ai%C2%B3-theory-practice-business/interested-in-performing-end-to-end-rl-learning-and-experimentation-you-need-deepracer-d088088ca314)",0,1
167,2019-11-18,2019,11,18,22,dy3ikz,Bounding box prediction using kalman filter + standard averaging numerical technique,https://www.reddit.com/r/deeplearning/comments/dy3ikz/bounding_box_prediction_using_kalman_filter/,zimmer550king,1574085537,,4,1
168,2019-11-19,2019,11,19,1,dy5cnf,Huawei Tops ETH Zurich 2019 Smartphone Deep Learning Rankings,https://www.reddit.com/r/deeplearning/comments/dy5cnf/huawei_tops_eth_zurich_2019_smartphone_deep/,Yuqing7,1574094067,,1,1
169,2019-11-19,2019,11,19,2,dy6jdk,"About selecting batch size and learning rate, and weight averaging for better generalization. Based on several articles that I encountered recently.",https://www.reddit.com/r/deeplearning/comments/dy6jdk/about_selecting_batch_size_and_learning_rate_and/,senarvi,1574099165,,0,1
170,2019-11-19,2019,11,19,2,dy6lof,Artificial Intelligence and Robotics.,https://www.reddit.com/r/deeplearning/comments/dy6lof/artificial_intelligence_and_robotics/,Fourteen_is_14,1574099429,"These days a lot of courses are being offered on Artificial Intelligence.
The contents of those courses are basically Deep Learning/All kinds of Neural Nets etc.

So I have mainly two questions:
1. Where do Artificial Intelligence and Robotics meet?
2. What are entry level points from career's perspective in those fields?

Additional information apart from these two questions would be helpful too.",1,1
171,2019-11-19,2019,11,19,5,dy8syr,Google Brain Hugo Larochelle on Few-Shot Learning,https://www.reddit.com/r/deeplearning/comments/dy8syr/google_brain_hugo_larochelle_on_fewshot_learning/,Yuqing7,1574108409,,0,1
172,2019-11-19,2019,11,19,6,dy9rhm,Advice on Building a Machine for Deep Learning Research,https://www.reddit.com/r/deeplearning/comments/dy9rhm/advice_on_building_a_machine_for_deep_learning/,TheSmashNGrab,1574112223,"In a nutshell, I'd like to verify that the following build for deep learning research is sensible and if there are ways I can shave off costs or get more bang for my buck with other options: [https://pcpartpicker.com/list/4dj8Mc](https://pcpartpicker.com/list/4dj8Mc)

**Background:** I'm going to be doing research which involves training many different moderately-sized feedforward nets and CNNs. Certainly not at the level of neural architecture search. Without going too much into detail, the research involves comparing neural net performance against other types of models across a number of problems/domains. I intend to train non-neural-net models on the CPU while training the nets on the GPUs.

**Budget/Constraints:** I have about \~$4k to spend at the moment, but can spend more down the line (in next year or so) to buy about 2 more GPUs. As such, in the build above I went with a 2 GPU system that can be easily upgraded to 4 GPUs.

**Rationale for my choices:**

\- I maxed out PSU power, RAM, CPU cores, and chassis size in anticipation of upgrading to 4 GPUs. I don't want to start worrying about PSU/chassis, and CPU/RAM is good for running CPU-heavy experiments in addition to any deep learning on the GPUs going on (even if I upgrade to 4 GPUs, I think each GPU will need at most 2 CPU cores for data batch processing?).

\- In terms of CPU/mobo, from what I've read online it seems like AMD gives you a lot more bang for the buck than Intel, hence the TR+x399 combo. I also don't think it makes sense to wait for the new Ryzen (because they don't have enough PCIe lanes for 4 GPUs?) or the new TR (too expensive).

\- As for the GPUs, I went with GTX 2080 SUPER because that seems like the best option short of 2080 Ti, and I don't think I need the extra memory for my models, so no point paying the premium for the Ti. And I went with blower style, since that seems like a must in terms of cooling if I upgrade to 4 GPUs.

**Questions:**

\- Am I missing any incompatibilities or weird interactions between the components?

\- Are any of the parts/brands I chose not recommended? Perhaps most importantly, PNY for the GPUs?

\- Will this CPU/mobo combo definitely support 4 GTX 2080s? Additionally, If want to install 2 or more NVME SSDs on the mobo, does that affect support for the GPUs (e.g. in terms of PCIe lanes)? Total noob in this regard...

\- Is having blower cards sufficient cooling for the GPUs? Or is additional cooling recommended? And will the answer change in 2 GPU setting vs 4 GPUs?

\- Is there any way to stay around the $4k price point and get 4 2080s right now? Or would that sacrifice too much from the other components?

\-  This will be used in a university setting, and I have the option of putting the build on a rack in the department's server rather than in its own chassis. Ive never installed on a rack before; is that recommended over standalone chassis? And if so, does anyone have advice or resources I can look into for building on a rack?",6,1
173,2019-11-19,2019,11,19,6,dy9vcn,"AI Weekly Update - November 18th, 2019",https://www.reddit.com/r/deeplearning/comments/dy9vcn/ai_weekly_update_november_18th_2019/,HenryAILabs,1574112668,"This Weekly Update covers the new ImageNet state-of-the-art technique with Distillation, a survey on Self-Supervised Learning, trends in Deep Learning and Chip Design from Jeff Dean and many more!

[https://youtu.be/UR1fJs0IIDc](https://youtu.be/UR1fJs0IIDc)",0,1
174,2019-11-19,2019,11,19,10,dydfok,Where to get started. Could use your help yall,https://www.reddit.com/r/deeplearning/comments/dydfok/where_to_get_started_could_use_your_help_yall/,Folow123,1574127886,"Currently switched my major from EE to compsci and statician, Im good at math and know it all minus discrete. Was wondering where I can learn the most machine/ deep learning online? Courses anything I really want to master this subject. I appreciate any and all help",0,1
175,2019-11-19,2019,11,19,11,dydnen,I need help for my project,https://www.reddit.com/r/deeplearning/comments/dydnen/i_need_help_for_my_project/,ApacheT101,1574128854,"Hi, my name is Tan Wei Xian and I am an university student. Currently I am decided to join an international competition and my idea is drone for public safety. 

&amp;#x200B;

Here is my thought about my idea:

1) A surveillance camera detect a criminal in a crowd by using face detection and recognition. The system will send the location to the police department.

&amp;#x200B;

2) The system will send a drone to the area and patrol at there. If the drone spots  the target, it will follow the person and send the current location to the police department. If not, it will patrol at that area.

&amp;#x200B;

Here are my questions:

&amp;#x200B;

1) Do you think this project is possible to do it within five months? If yes, where should I find the resources regarding the system send signal to the drone and drone will fly to that area without any control?

&amp;#x200B;

2) There are two options available for me now, simulation or actual drone, so what method should I choose for this project, if  it is simulation, what software should I choose? If it is actual drone, what drone should I buy? My budget is around 250USD. 

&amp;#x200B;

3) I had contacted with the jury before, he said that I shall make an prototype( an app) . Therefore, does it mean that I don't really need to make a full- functional system?

Thanks a lot!",5,1
176,2019-11-19,2019,11,19,14,dygcgy,Why Deep Learning Beneficial?,https://www.reddit.com/r/deeplearning/comments/dygcgy/why_deep_learning_beneficial/,jefrinadams,1574142890,,0,1
177,2019-11-19,2019,11,19,15,dyguvu,Tensorflow GPU docker image not using GPU,https://www.reddit.com/r/deeplearning/comments/dyguvu/tensorflow_gpu_docker_image_not_using_gpu/,prameshbajra,1574146170,,4,1
178,2019-11-19,2019,11,19,17,dyhirm,5 Notable Artificial Intelligence Trends in 2019,https://www.reddit.com/r/deeplearning/comments/dyhirm/5_notable_artificial_intelligence_trends_in_2019/,aayush-goel,1574150800,,0,1
179,2019-11-19,2019,11,19,17,dyhuyv,List of useful resources - data augmentation,https://www.reddit.com/r/deeplearning/comments/dyhuyv/list_of_useful_resources_data_augmentation/,Chitoyo,1574153368,,0,1
180,2019-11-19,2019,11,19,23,dyl578,Illustrated: Self-Attention,https://www.reddit.com/r/deeplearning/comments/dyl578/illustrated_selfattention/,raibosome,1574173892,,0,1
181,2019-11-20,2019,11,20,2,dyndph,new M.S. in Natural Language Processing in Silicon Valley,https://www.reddit.com/r/deeplearning/comments/dyndph/new_ms_in_natural_language_processing_in_silicon/,marilynawalker,1574183749,[removed],0,1
182,2019-11-20,2019,11,20,3,dyo1ku,Announcing Jupyter Notebooks on AI Cheatsheets (https://www.aicheatsheets.com) - Free 10 Notebook Hours,https://www.reddit.com/r/deeplearning/comments/dyo1ku/announcing_jupyter_notebooks_on_ai_cheatsheets/,kailashahirwar12,1574186576,"Hi Everyone,

Last two months have been hectic for me as we have been working on Jupyter Notebooks for AI Cheatsheets portal.  Two months back, I felt that we need a portal for the beginners with tools to learn data science and machine learning. Sometimes, beginners struggle to acquire resources they need to learn data science and machine learning. 

Finally, we are happy to announce the release of Jupyter Notebooks on AI Cheatsheets portal. Now you can launch Jupyter Notebooks for your data science needs.

We are providing 600 free credits which is equal to 10 Notebook hours. After you use 600 credits, you can request us for a customized package with more credits. 

Visit us at https://www.aicheatsheets.com

Disclaimer: Jupyter Notebooks are in Beta phase and you might face issues while creating or using notebooks. 
We have tried tmake the experience as smooth as possible. In case of any issues, mail us at aicheatsheets@gmail.com.",0,1
183,2019-11-20,2019,11,20,3,dyo4wd,Announcing Jupyter Notebooks on AI Cheatsheets(https://www.aicheatsheets.com) - Free 10 Notebook Hours,https://www.reddit.com/r/deeplearning/comments/dyo4wd/announcing_jupyter_notebooks_on_ai/,kailashahirwar12,1574186952,"Hi Everyone,

Last two months have been hectic for us as we have been working on Jupyter Notebooks for AI Cheatsheets portal.  Two months back, I felt, we need a portal for beginners with tools to learn data science and machine learning. Sometimes, beginners struggle to acquire resources and tools they need to learn data science and machine learning. 

Finally, we are happy to announce the release of Jupyter Notebooks on AI Cheatsheets portal. Now you can launch Jupyter Notebooks for your data science needs.

We are providing 600 free credits which is equal to 10 Notebook hours. After you use 600 credits, you can request us for a customized package with more credits. 

Visit us at [https://www.aicheatsheets.com](https://www.aicheatsheets.com)

We are working on a few more cheatsheets as promised and will release them soon.

Disclaimer: Jupyter Notebooks are in Beta phase and you might face issues while creating or using notebooks. 

We have tried to make the experience as smooth as possible. In case of any issue, reach out to us at [aicheatsheets@gmail.com](mailto:aicheatsheets@gmail.com).",6,1
184,2019-11-20,2019,11,20,4,dypjec,Can Bots Surpass the Realism of Human Dialogue?,https://www.reddit.com/r/deeplearning/comments/dypjec/can_bots_surpass_the_realism_of_human_dialogue/,Yuqing7,1574192581,,2,2
185,2019-11-20,2019,11,20,14,dyxc98,Places365 Dataset,https://www.reddit.com/r/deeplearning/comments/dyxc98/places365_dataset/,arjundupa,1574227143,"Link suggests that the training set of the Places365-Standard dataset is 105 GB. I don't have this much storage. Is there a way I can still access these images?

Also, I have a set of 4000 images that I got from Google Images, and I want to see whether any of these exist in the training set of the Places365-Standard dataset. Is there a way to do this?

Any ideas will be greatly appreciated, thanks!",8,1
186,2019-11-20,2019,11,20,15,dyxyzr,Transforming CRM Operations With Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/dyxyzr/transforming_crm_operations_with_artificial/,Kamlesh_Sarn,1574230671,,0,1
187,2019-11-20,2019,11,20,15,dyy4wf,Neural Responding Machine for Short-Text Conversation,https://www.reddit.com/r/deeplearning/comments/dyy4wf/neural_responding_machine_for_shorttext/,i_amujjawal,1574231698,,0,1
188,2019-11-20,2019,11,20,18,dyzv2d,[Research] Announcing Kaolin - PyTorch Library for Accelerating 3D Deep Learning Research,https://www.reddit.com/r/deeplearning/comments/dyzv2d/research_announcing_kaolin_pytorch_library_for/,cdossman,1574243088," A group of researchers who were working at NVIDIA has introduced Kaolin, a new PyTorch library with an aim to accelerate 3D deep learning research. Kaolin is home for future 3D DL research and you are welcome to make contributions. 

\#PyTorch #3DdeepLearning #ai #aiResearch #educateai #openSourceSoftware

Read more: https://medium.com/ai%C2%B3-theory-practice-business/pytorch-library-for-accelerating-3d-deep-learning-research-6b83df2073bf",0,1
189,2019-11-20,2019,11,20,19,dz0dsi,Is it a good idea to remove the stopwords from the text while performing Deep Learning? (Sentiment Analysis-&gt; RNN),https://www.reddit.com/r/deeplearning/comments/dz0dsi/is_it_a_good_idea_to_remove_the_stopwords_from/,hero_2012,1574246492,"Hi, i was following a course where they taught me about DL. And i am trying to build a sentiment analyser. 

I am using the IMDB movie rating dataset with two labels \`positive\` and \`negative\`.  


While cleaning the reviews, i am performing the following steps.

1. removing punctuations and numbers and other characters and to lowercase

2. remove stopwords

3. remove words with length less than or equal to 2

&amp;#x200B;

However, i have a feeling that removing the stopwords and removing words with length less than 2 is not necessary and this might hurt the prediction by destroying all the structure of the review.",9,1
190,2019-11-20,2019,11,20,19,dz0duh,Sequential combination of CNN and lstm for nlp sentiment analysis,https://www.reddit.com/r/deeplearning/comments/dz0duh/sequential_combination_of_cnn_and_lstm_for_nlp/,ggghash,1574246502,"I'm working on a this approach to sentiment analysis. Pass a 1 hot vector to a CNN convoluting in 1d over n-grams. Then I would like to pass that output along with the original 1 hot sentence vector to an lstm to for sentiment classification.

I'm stuck at the stop between the CNN and lstm. What I'm doing temporarily is just putting them side by side and choosing one each time.

Anyone know of a resource out there to help with this? I'm sure it's been done before.",9,1
191,2019-11-20,2019,11,20,21,dz192e,Harnessing the Intelligence of AI for Content Management,https://www.reddit.com/r/deeplearning/comments/dz192e/harnessing_the_intelligence_of_ai_for_content/,Kunal-sharma,1574251950,,0,1
192,2019-11-20,2019,11,20,22,dz1ubq,Finding Purpose in Life or Why we Exist - Could Stoicism be The Key?,https://www.reddit.com/r/deeplearning/comments/dz1ubq/finding_purpose_in_life_or_why_we_exist_could/,PassionFruit2019,1574255360,,0,1
193,2019-11-20,2019,11,20,22,dz1v4m,Autoencoders,https://www.reddit.com/r/deeplearning/comments/dz1v4m/autoencoders/,atomicBeaver22,1574255487,"Hi everyone, 

Could anyone recommend me a few textbooks and educational resources for generative adversary networks and autoencoders? 

I'm looking for ""deep learning with python"" kind of book. 

Thanks.",7,1
194,2019-11-21,2019,11,21,0,dz38b7,[P] Our team made an app that will tell you if a specific food is allergic to you just by a picture using deep learning and computer vision. I have attached the Github link in the comments.,https://www.reddit.com/r/deeplearning/comments/dz38b7/p_our_team_made_an_app_that_will_tell_you_if_a/,clean_pegasus,1574262231,,19,1
195,2019-11-21,2019,11,21,0,dz3e36,How do anchors in Region Proposal Networks work,https://www.reddit.com/r/deeplearning/comments/dz3e36/how_do_anchors_in_region_proposal_networks_work/,StrasJam,1574262928,"I am having trouble understanding the use of anchors in RPN. From what I understand so far, the final feature map (or maps in case of FPN) is taken as the input for the RPN. RPN first runs a 3x3 convolution on the input, resulting in a new feature map with depth of 512. But here is where I get confused. So a 1x1 convolution is performed twice at each pixel of this 512 depth map, once for the classification (object, nonobject) and once for regression. How do the anchors come into play in all of this. How I understand it is that since the anchors are applied to a given pixel of this 512 depth map, the anchor can be re-projected to the original image based on the field of view of this pixel. So the regression and classification of the 1x1 convolution on this pixel should output 2 classifications and 4 regression values for each of the anchors at this pixel. How can each anchor get a different classification score though? Or a different regression score? Since we are using only a single feature vector of a single pixel in the 512 depth map as input for the classification and regression, how can we tell if one anchor should have a greater classification probability than another. Or how can one anchor get a different regression, again because we only have a single feature vector as the deciding factor.",8,1
196,2019-11-21,2019,11,21,2,dz5ajn,Doing NLP (Swag Task) with GPT-2,https://www.reddit.com/r/deeplearning/comments/dz5ajn/doing_nlp_swag_task_with_gpt2/,h56cho,1574271170,"Hello,

I have a couple of questions about GPT-2. Any help would be highly appreciated.

1. According to the HuggingFace Transformer's website ([https://huggingface.co/transformers/model\_doc/gpt2.html#gpt2doubleheadsmodel](https://huggingface.co/transformers/model_doc/gpt2.html#gpt2doubleheadsmodel)), GPT2DoubleHeadsModel is the GPT2 Model transformer with a language modelling and a multiple-choice classification head on top e.g. for RocStories/SWAG tasks.  Does this mean that the GPT2DoubleHeadsModel can be used for both the regular language modelling tasks (predicting the next token) and also for solving multiple-choice questions? Or does this mean that GPT2DoubleHeadsModel can be used to test machines on the multiple-choice type questions only?
2. How exactly is the SWAG task carried out via GPT-2? For Swag task, do I just feed in the sequence of tokens that represents the question statement along with the sequence that represents multiple choice options into GPT-2, and then simply observe the GPT-2's output, which would denote for the machine's answer to the multiple choice question?

Thank you,",0,1
197,2019-11-21,2019,11,21,3,dz5w8q,Knowledge Distillation with TAs,https://www.reddit.com/r/deeplearning/comments/dz5w8q/knowledge_distillation_with_tas/,HenryAILabs,1574273756,[removed],0,1
198,2019-11-21,2019,11,21,3,dz5yrv,Has anyone programmed mathematical models + deep learning?,https://www.reddit.com/r/deeplearning/comments/dz5yrv/has_anyone_programmed_mathematical_models_deep/,atomicBeaver22,1574274046,"I'm a control systems graduate student trying to program the following paper but using my own mathematical model. 


Https://arxiv.org/pdf/1711.02702&amp;ved=2ahUKEwiv64qwsfnlAhUBWK0KHcv1AQcQFjACegQIBhAB&amp;usg=AOvVaw1bbtns5z5yXOknpz1spM9f

They were kind enough to provide the code that they used for the problem but since I'm not very familiar with the application, it doesn't make much sense.


The problem is that I can only find image processing and sentiment (words) analysis in the internet. I'm looking for a resource that deals with numbers and signals. 

Haven't seen anything on autoencoders and gans for numbers and signals. Any advice or resources?",3,1
199,2019-11-21,2019,11,21,8,dzaid2,RandAugment Explained!,https://www.reddit.com/r/deeplearning/comments/dzaid2/randaugment_explained/,HenryAILabs,1574293745,[https://youtu.be/Zzt9i3gDueE](https://youtu.be/Zzt9i3gDueE),0,1
200,2019-11-21,2019,11,21,12,dzddn6,Created Indoor (Room type) image classification using MONK. Monk is an open-source low-code unified wrapper over major deep learning frameworks. (Links to the blog and framework in comments).,https://www.reddit.com/r/deeplearning/comments/dzddn6/created_indoor_room_type_image_classification/,abhishek4273,1574307513,,4,1
201,2019-11-21,2019,11,21,20,dzhquk,Expansion size from MobileNet V3,https://www.reddit.com/r/deeplearning/comments/dzhquk/expansion_size_from_mobilenet_v3/,Rebeencs,1574334361,[removed],0,1
202,2019-11-21,2019,11,21,23,dzk87m,A good place to start for applying deep learning to algorithmic stock trading?,https://www.reddit.com/r/deeplearning/comments/dzk87m/a_good_place_to_start_for_applying_deep_learning/,phoenix__191,1574347296,"Are there any good MOOC's that can give one a good headstart to work on algorithmic stock trading? There's one specialization on Coursera that involves Reinforcement Learning, is that any good? 

This is for a pet project that my friend and I would like to work on, we don't have a finance background and are relatively new to the field of AI and Machine Learning, it would be great if anyone could suggest how we should go about this. Thanks.",8,1
203,2019-11-22,2019,11,22,3,dzn4pv,Google Brains Nicholas Frosst on Adversarial Examples and Emotional Responses,https://www.reddit.com/r/deeplearning/comments/dzn4pv/google_brains_nicholas_frosst_on_adversarial/,Yuqing7,1574359259,,0,1
204,2019-11-22,2019,11,22,5,dzp2ze,Voila! SOTA French Language Model CamemBERT Debuts,https://www.reddit.com/r/deeplearning/comments/dzp2ze/voila_sota_french_language_model_camembert_debuts/,Yuqing7,1574367005,,0,1
205,2019-11-22,2019,11,22,10,dzt9xi,How multi-head was combined to tokens?,https://www.reddit.com/r/deeplearning/comments/dzt9xi/how_multihead_was_combined_to_tokens/,MrAaronW,1574384405,"I understood that there are multiple attention heads inside BERT. However, how were the attention weights combined to the final hidden state of a token in each layer? For example, \[CLS\] has a hidden size of 1 \* 768 but this was based on 12 attention heads. It would be super nice if someone could point out how to get the final state from these attentions?

&amp;#x200B;

I tried to find the corresponding code in huggingface's repo but I wasn't able to.",0,1
206,2019-11-22,2019,11,22,10,dztzvu,Deep Learning with PyTorch book is now available for free,https://www.reddit.com/r/deeplearning/comments/dztzvu/deep_learning_with_pytorch_book_is_now_available/,ConfidentMushroom,1574387747,,10,1
207,2019-11-22,2019,11,22,16,dzxk7v,Deep Learning with PyTorch,https://www.reddit.com/r/deeplearning/comments/dzxk7v/deep_learning_with_pytorch/,aiforworld2,1574406941,"Deep Learning with PyTorch 

To help developers get started with PyTorch, community is making the 'Deep Learning with PyTorch' book, written by Luca Antiga and Eli Stevens, available for free to the community: 

Free Download:
https://pytorch.org/deep-learning-with-pytorch

https://twitter.com/PyTorch/status/1197603717144432640?s=19",1,1
208,2019-11-22,2019,11,22,18,dzys59,ID card digitization using OCR and graph neural networks. The article will get you started on all the different deep learning based OCR methods and how to use graph convolutional networks for text recognition,https://www.reddit.com/r/deeplearning/comments/dzys59/id_card_digitization_using_ocr_and_graph_neural/,manneshiva,1574415559,,1,1
209,2019-11-22,2019,11,22,18,dzyt7k,Region of interest pooling backpropagation,https://www.reddit.com/r/deeplearning/comments/dzyt7k/region_of_interest_pooling_backpropagation/,0x7A,1574415766,"Hey all,

I'm currently working with the Faster R-CNN object detection network ([https://arxiv.org/pdf/1506.01497.pdf](https://arxiv.org/pdf/1506.01497.pdf)) and wonder how this architecture can be trained end-to-end, as stated in the paper. 

In my understanding, the Region Proposal Network (RPN) outputs (among others) the bounding box offsets for all anchors, leading to the coordinates of all regions of interest. These regions of interest are then fed into a RoI pooling layer, yielding image features which are used for classification as well as further bounding box refinement.

In my opinion, gradients cannot flow back through the RoI pooling layer to the RoI coordinates (which are output by the RPN). So how can the RPN learn to predict good anchor offsets without these gradients? What am I missing here?

Thanks in advance!",0,1
210,2019-11-22,2019,11,22,21,e00l9e,How to tokenize SWAG dataset to use it with GPT-2?,https://www.reddit.com/r/deeplearning/comments/e00l9e/how_to_tokenize_swag_dataset_to_use_it_with_gpt2/,h56cho,1574427250,"Hello,

I am new to NLP so I have lots of questions.

I am interested in doing NLP with GPT-2 and the SWAG dataset ([https://rowanzellers.com/swag/](https://rowanzellers.com/swag/))

&amp;#x200B;

Below is an excerpt from the first data from the SWAG dataset, to show how the dataset is structured:

\`\`\`

,video-id,fold-ind,startphrase,sent1,sent2,gold-source,ending0,ending1,ending2,ending3,label 0,anetv\_jkn6uvmqwh4,3416,

Members of the procession walk down the street holding small horn brass instruments. A drum line,Members of the procession walk down the street holding small horn brass instruments.,A drum line,gold,passes by walking down the street playing their instruments.,has heard approaching them.,arrives and they're outside dancing and asleep.,turns the lead singer watches the performance.,0

\`\`\`

The first line of the data shows how SWAG dataset is structured. Descriptions of the meaning of each item (\`video-id\`, \`fold-ind\`,\`start phrase\`,\`sent1\`... \`ending3\`,\`label\`) can be found on the website below:

[https://github.com/rowanz/swagaf/tree/master/data](https://github.com/rowanz/swagaf/tree/master/data)

How should I tokenize this SWAG dataset to process it with GPT-2 (with the double heads model, for instance)? Can someone please give me an example?

Thank you,",0,1
211,2019-11-22,2019,11,22,22,e00qq2,Is stylized image caption still a direction worth exploring in 2019?,https://www.reddit.com/r/deeplearning/comments/e00qq2/is_stylized_image_caption_still_a_direction_worth/,doragd,1574428078,[removed],0,1
212,2019-11-22,2019,11,22,22,e00thk,Deep Learning PyTorch Template,https://www.reddit.com/r/deeplearning/comments/e00thk/deep_learning_pytorch_template/,FrancescoSZ,1574428480,"*Previosly posted on* r/pytroch *but I think it maybe be usefull to all deep learning enthusiast.*

Hi guys,

I have created a deep learning quick start template for PyTorch. It includes:

* modularity: we split each logic piece into a different python submodule
* data-augmentation: we included [imgaug](https://imgaug.readthedocs.io/en/latest/)
* ready to go: by using [poutyne](https://pypi.org/project/Poutyne/) a Keras-like framework you don't have to write any train loop.
* [torchsummary](https://github.com/sksq96/pytorch-summary) to show a summary of your models
* reduce the learning rate on a plateau
* auto-saving the best model
* experiment tracking with [comet](https://www.comet.ml/)
* logging using python [logging](https://docs.python.org/3/library/logging.html) module
* a playground notebook to quick test/play around

[https://github.com/FrancescoSaverioZuppichini/PyTorch-Deep-Learning-Template](https://github.com/FrancescoSaverioZuppichini/PyTorch-Deep-Learning-Template)

Let me know if you find it useful :)",1,1
213,2019-11-22,2019,11,22,22,e00zcx,Yoshua Bengio on Human-level AI,https://www.reddit.com/r/deeplearning/comments/e00zcx/yoshua_bengio_on_humanlevel_ai/,TheTesseractAcademy,1574429373,,0,1
214,2019-11-22,2019,11,22,22,e012gu,Deep Learning with PyTorch,https://www.reddit.com/r/deeplearning/comments/e012gu/deep_learning_with_pytorch/,HN_Crosspost_Bot,1574429831,,2,1
215,2019-11-22,2019,11,22,22,e01bce,How to process common sense reasoning task with GPT-2?,https://www.reddit.com/r/deeplearning/comments/e01bce/how_to_process_common_sense_reasoning_task_with/,h56cho,1574431072,"Hello,

I am new to NLP so I have lots of questions.  
I am interested in carrying out common sense reasoning task with GPT-2, for example, with Winograd Schema Challenge dataset.

Q1. How should I tokenize the Winograd Schema Challenge dataset to process it with GPT-2 (with the double heads model, for instance)? Can someone please give me an example?

Q2. Can GPT2DoubleHeadsModel ([https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313](https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313)) be used to conduct common sense reasoning task with Winograd Schema Challenge dataset?

Q3. How exactly does the ""next sentence prediction head"" of GPT2DoubleHeadsModel \*[https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313](https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313)) work?

Thank you,",0,1
216,2019-11-23,2019,11,23,2,e045wu,How encoder and decoder work together in Transformer,https://www.reddit.com/r/deeplearning/comments/e045wu/how_encoder_and_decoder_work_together_in/,HippeTeddyBear,1574443708,"What's up guys! Hope everyone is doing well.

I have a question about the Transformer model.  Here is the [paper](https://arxiv.org/pdf/1706.03762.pdf)

From my understanding, the encoder projects each word embedding of inputs into a representation (z) with self-attention considered.  

&gt;In ""encoder-decoder attention"" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder.  

I don't quite understand how the representation (z) got transformed into key and value then applied to the decoder. 

Any help would be appreciated! Have a good day!",0,1
217,2019-11-23,2019,11,23,5,e06f2o,"Why Bounding ""boxes"" and not Bounding ""circles""?",https://www.reddit.com/r/deeplearning/comments/e06f2o/why_bounding_boxes_and_not_bounding_circles/,Believinginself,1574452935,"Why do we have squares/rectangles or boounding ""boxes"" rather than bounding ""circles""? Is it related to computation ease? Would someone be able to give indepth answer to this logic?

Thanks",2,1
218,2019-11-23,2019,11,23,7,e08dn1,"Weekly Papers | Quoc V. Le and Kaiming He Look at Vision; Intelligence, Psychology and AI; Evolving the Hearthstone Meta and More!",https://www.reddit.com/r/deeplearning/comments/e08dn1/weekly_papers_quoc_v_le_and_kaiming_he_look_at/,Yuqing7,1574461087,,0,1
219,2019-11-23,2019,11,23,11,e0bdmu,Promise of spiking neural nets?,https://www.reddit.com/r/deeplearning/comments/e0bdmu/promise_of_spiking_neural_nets/,ndronen,1574474738,"I'm noticing more papers about spiking neural networks on the arXiv and, before I start to delve into them, am wondering whether it's worth the time. The abstracts of some papers claim significant reduction in power consumption, which could be advantageous for inference. Do these claims assume the use of a neuromorphic processor or can the benefits be reaped with CPU/GPU/FPGA? That's inference. And trainkng? How do the best spiking network training schemes work? Is the network first trained with dense layers and then the neurons are modified to make them spiking?",0,1
220,2019-11-23,2019,11,23,15,e0e77q,"Created leaf diseases classifier that can detect 38 diseases using MONK's hyper parameter tuning. Monk is an open-source low-code unified wrapper over major deep learning frameworks. Blog: http://bit.ly/hyper-param-tuning-with-monk, Github: http://bit.ly/monk-github",https://www.reddit.com/r/deeplearning/comments/e0e77q/created_leaf_diseases_classifier_that_can_detect/,abhishek4273,1574490664,,1,1
221,2019-11-23,2019,11,23,16,e0etsr,AI-enabled Time Machine Lens,https://www.reddit.com/r/deeplearning/comments/e0etsr/aienabled_time_machine_lens/,cmillionaire9,1574494919,,5,1
222,2019-11-23,2019,11,23,20,e0glop,OpenAI releases Safety Gym for reinforcement learning | VentureBeat,https://www.reddit.com/r/deeplearning/comments/e0glop/openai_releases_safety_gym_for_reinforcement/,RankLord,1574507557,,0,1
223,2019-11-23,2019,11,23,22,e0hjzg,Should I train my GPT2 neural network on the excerpts on the articles first before I train on the training dataset?,https://www.reddit.com/r/deeplearning/comments/e0hjzg/should_i_train_my_gpt2_neural_network_on_the/,h56cho,1574514074,"Hello,

I am interested in processing ARC dataset with GPT-2 neural network.  
The ARC dataset ([http://nlpprogress.com/english/question\_answering.html](http://nlpprogress.com/english/question_answering.html)) is a question answering, which contains 7,787 genuine grade-school level, multiple-choice science questions. The dataset comes with the regular train/test/val sets of the multiple choice questions, as well as the huge corpus of texts that is extracted from various articles that explains the scientific concepts that can be used to solve these 7,787 multiple choice questions (i.e. this huge corpus is not in the multiple choice format; it's just a series of excerpts from various articles).

My question is, is there a need to train my GPT2 neural network with the series of excerpts from various articles before I train the same network with the training set of multiple-choice questions, since the GPT2 network itself wouldn't have acquired any scientific knowledge that is required to solve these 7,787 multiple-choice questions prior to processing this particular dataset? or is it okay to just directly train the GPT2 neural network based on the training set of multiple choice questions without first training the network on the series of articles?

Thank you,",0,1
224,2019-11-24,2019,11,24,0,e0j1lk,Is the tesla k40 still viable?,https://www.reddit.com/r/deeplearning/comments/e0j1lk/is_the_tesla_k40_still_viable/,LEDNEWB,1574521839,And at what price?,0,1
225,2019-11-24,2019,11,24,0,e0jdgg,How to tokenize ARC dataset (NLP question)?,https://www.reddit.com/r/deeplearning/comments/e0jdgg/how_to_tokenize_arc_dataset_nlp_question/,h56cho,1574523417,"Hello,

I am interested in processing the ARC dataset ([http://nlpprogress.com/english/question\_answering.html](http://nlpprogress.com/english/question_answering.html)) with the GPT2 double heads model neural network. The dataset (tab delimited) is structured as below:

\`\`\`

Question               Answer

Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era? (A) worldwide disease (B) global mountain building (C) rise of mammals that preyed upon plants and animals (D) impact of an asteroid created dust that blocked the sunlight.          D

\`\`\`

I know that I am supposed to tokenize the dataset before passing it into GPT2 double heads model for doing NLP.

How should I tokenize this data? More specifically,

1. should I add a special token before each character that denotes for multiple choice options (A), (B), (C) and (D)?
2. should I add special token before each string that denotes for the contents of the multiple choice options?
3. Am I supposed to add the tokens ""&lt;bos&gt;"" and ""&lt;eos&gt;"" at the beginning and at the end of each question statement?
4. If I am to pass this data into a \*\*GPT2 Double Heads Model\*\* (The GPT2 model with two heads) for processing multiple choice questions,  what should I do with the part that denotes for an actual answer to the multiple choice question?

So for instance, to generate an input sequence for the GPT2 double heads model, should I break up the original question statement into 4 sequences, 1 for each multiple choice option, and apply the tokenization to each of the 4 sequences as below?:

\`\`\`

&lt;bos&gt; Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era? &lt;spec\_token1&gt; (A) &lt;spec\_token2&gt; worldwide disease &lt;eos&gt;

&lt;bos&gt; Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era?  &lt;spec\_token1&gt; (B) &lt;spec\_token2&gt; global mountain building &lt;eos&gt;

&lt;bos&gt; Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era?  &lt;spec\_token1&gt; (C) &lt;spec\_token2&gt; rise of mammals that preyed upon plants and animals &lt;eos&gt;

&lt;bos&gt; Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era?  &lt;spec\_token1&gt; (D) &lt;spec\_token2&gt; impact of an asteroid created dust that blocked the sunlight.    &lt;eos&gt;

\`\`\` 

Thank you,

PS: I found this site [https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313](https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313) and it seem to address some of the questions I have, but still this is not a complete help.",0,1
226,2019-11-24,2019,11,24,0,e0jiz0,"PyTorch, RedisAI &amp; Hangar: The missing pieces of a complete deep learning workflow  Sherin Thomas",https://www.reddit.com/r/deeplearning/comments/e0jiz0/pytorch_redisai_hangar_the_missing_pieces_of_a/,gkorland,1574524142,,0,1
227,2019-11-24,2019,11,24,2,e0kshk,Training CoreML Object Detection model from scratch using CreateML,https://www.reddit.com/r/deeplearning/comments/e0kshk/training_coreml_object_detection_model_from/,TomekB,1574529376,,0,1
228,2019-11-24,2019,11,24,2,e0kxwt,Project implementation based on papers,https://www.reddit.com/r/deeplearning/comments/e0kxwt/project_implementation_based_on_papers/,christw16,1574529975,"Hello everyone,
I wanna ask is there any suggestions for doing a project which is based on deep learning papers

Thank you!",2,1
229,2019-11-24,2019,11,24,12,e0td2v,Deep learning models depends on ?,https://www.reddit.com/r/deeplearning/comments/e0td2v/deep_learning_models_depends_on/,santhuraj,1574567602,"How to get good result or outcome when applying machine learning/deep learning models? 
Try to elaborate your opinion.",7,1
230,2019-11-24,2019,11,24,12,e0teqd,Implementing simple probabilistic model with negative log likelihood loss (CS294-158 Deep Unsupervised Learning Spring 2019 Berkeley Uni Week 1 Warm Up Excercise),https://www.reddit.com/r/deeplearning/comments/e0teqd/implementing_simple_probabilistic_model_with/,dosssman,1574567846,,0,1
231,2019-11-24,2019,11,24,13,e0tk4m,Images as input to LSTM + Teacher Forcing- PyTorch,https://www.reddit.com/r/deeplearning/comments/e0tk4m/images_as_input_to_lstm_teacher_forcing_pytorch/,anand_altekar,1574568581,"Hi,

I want to pass data of shape (18,3,128,128) (these are 18 images of shape (3,128,128) at a time in LSTM of 17 layers.  
at time 0 input = (data\[0\], (h\_0,c\_0)) and output = (h\_1,c\_1)  
at time 1 input = (data\[1\], (h\_1, c\_1)) and output = (h\_2\_c\_2)  
  
at time 16 input = (data\[15\], (h\_15, c\_15)) and output = (h\_16, c\_16)

*(I deliberately want to pass the images directly without encoding.)*

Docs mention that input to LSTM should be (seq\_len, batch\_size, hidden\_size)

I'm guessing for me: (seq\_len=18, batch\_size=1, hidden\_size=3\*128\*128) is that correct? 

How would I implement teacher forcing though? I'm trying something on the following lines but can't figure out exactly how to proceed.  (num\_layers=17)

class trialLSTM(nn.Module):

def \_\_init\_\_(self, seq\_len, input\_size, hidden\_size, batch\_size, num\_layers):

super(trialLSTM, self).\_\_init\_\_()

self.seq\_len = seq\_len

self.input\_size = input\_size

self.hidden\_size = hidden\_size

self.batch\_size = batch\_size

self.lstm = nn.LSTM(seq\_len, batch\_size, input\_size)

def init\_hidden(self):

\# initialize the hidden state and the cell state to zeros

hidden = torch.zeros(self.batch\_size, self.hidden\_size)

cell = torch.zeros(self.batch\_size, self.hidden\_size)

return hidden, cell

&amp;#x200B;

def forward(self, x, (h\_0, c\_0)):

output = torch.empty(17, 17) # format is (hidden\_states, time\_steps)

for t in range(seq\_len+1):

if t==0:

hidden, cell = self.lstm(x\[0\], (h\_0,c\_0))

else:

hidden, cell = self.lstm(x\[t\], (h\_1,c\_1))

I don't know how to go forward from here. Please help. Thanks!",7,1
232,2019-11-24,2019,11,24,16,e0veyw,I improved my previous algorithm to predict 3D bounding boxes,https://www.reddit.com/r/deeplearning/comments/e0veyw/i_improved_my_previous_algorithm_to_predict_3d/,zimmer550king,1574580273,,0,1
233,2019-11-24,2019,11,24,18,e0w73r,3 Ways to Encode Categorical Variables for Deep Learning,https://www.reddit.com/r/deeplearning/comments/e0w73r/3_ways_to_encode_categorical_variables_for_deep/,RankLord,1574586084,,0,1
234,2019-11-24,2019,11,24,23,e0z8xp,career guidance,https://www.reddit.com/r/deeplearning/comments/e0z8xp/career_guidance/,Preetham_Gali,1574606202,[removed],0,1
235,2019-11-25,2019,11,25,0,e0zk36,Help needed,https://www.reddit.com/r/deeplearning/comments/e0zk36/help_needed/,salmanc2,1574607934,"Is there anyone who can help me understand a project and explain each individual line of code? The project is on glaucoma detection. I'm trying to do something similar to it but first I need to understand an example project. I'm fairly new to deep learning, so it would be very helpful if someone can explain what's going on over a videochat/voice call. I'll send over the code of anyone is interested. Thank you.",3,1
236,2019-11-25,2019,11,25,4,e12ulo,Mish: A self regularized non-montonic neural activation function,https://www.reddit.com/r/deeplearning/comments/e12ulo/mish_a_self_regularized_nonmontonic_neural/,Xa9aX,1574622184,[removed],0,1
237,2019-11-25,2019,11,25,5,e1423b,"Question: DVD (4:3), Bluray (16:9 cropped) - image restoration with deep learning possible?",https://www.reddit.com/r/deeplearning/comments/e1423b/question_dvd_43_bluray_169_cropped_image/,Nyard,1574627078,[removed],0,1
238,2019-11-25,2019,11,25,12,e19x2n,grid search hyperparameters for an image classification problem,https://www.reddit.com/r/deeplearning/comments/e19x2n/grid_search_hyperparameters_for_an_image/,47xsquared,1574651976,"if you guys or girls have time could you please help answer my question. 

I have tried solving this myself.

Some help could be nice.

Here is the question:

[my question on stackoverflow](https://stackoverflow.com/questions/59023969/grid-search-hyperparameters-for-an-image-classification-model)

Thank you guys!",2,1
239,2019-11-25,2019,11,25,16,e1cbds,Deep Learning based Seed Quality Tester,https://www.reddit.com/r/deeplearning/comments/e1cbds/deep_learning_based_seed_quality_tester/,zom8ie99,1574665254,"Dear researchers,

I have taken a step in merging of Deep Learning with Agriculture and Industry with this first conference paper. Please take a look at it.

Link: [https://www.researchgate.net/publication/337475039\_DEEP\_LEARNING\_BASED\_SEED\_QUALITY\_TESTER](https://www.researchgate.net/publication/337475039_DEEP_LEARNING_BASED_SEED_QUALITY_TESTER)

Feedbacks are highly welcomed.

Thank you",0,1
240,2019-11-25,2019,11,25,16,e1ckvq,Natural Language Processing is redefining human interaction,https://www.reddit.com/r/deeplearning/comments/e1ckvq/natural_language_processing_is_redefining_human/,day1technologies,1574666919,,0,1
241,2019-11-25,2019,11,25,17,e1dazb,"Training and Deploying a Multi-Label Image Classifier using PyTorch, Flask, ReactJS and Firebase data storage Part 1: Multi-Label Image Classification using PyTorch",https://www.reddit.com/r/deeplearning/comments/e1dazb/training_and_deploying_a_multilabel_image/,thevatsalsaglani,1574671708,,8,1
242,2019-11-25,2019,11,25,18,e1dwyc,Deep Learning for Programmers Ebook,https://www.reddit.com/r/deeplearning/comments/e1dwyc/deep_learning_for_programmers_ebook/,RubiksCodeNMZ,1574675791,,0,1
243,2019-11-25,2019,11,25,19,e1edfn,5 Facial Recognition Trends and Market Predictions 2019,https://www.reddit.com/r/deeplearning/comments/e1edfn/5_facial_recognition_trends_and_market/,Kunal-sharma,1574678752,,0,1
244,2019-11-25,2019,11,25,21,e1fpu1,[Blog Post] The fusion of physics simulation and machine learning,https://www.reddit.com/r/deeplearning/comments/e1fpu1/blog_post_the_fusion_of_physics_simulation_and/,akira_AI,1574686718,,0,1
245,2019-11-25,2019,11,25,22,e1fqyx,How to do dynamic pricing using the PAO framework,https://www.reddit.com/r/deeplearning/comments/e1fqyx/how_to_do_dynamic_pricing_using_the_pao_framework/,TheTesseractAcademy,1574686882,,0,1
246,2019-11-25,2019,11,25,22,e1g00g,I found some easy hacks to Learn AI and ML on my own,https://www.reddit.com/r/deeplearning/comments/e1g00g/i_found_some_easy_hacks_to_learn_ai_and_ml_on_my/,KiranKiller,1574688221,"So its been quite a long time  I have struggled with such a question myself for quite some time. That is why I started studying various blogs and watching short YouTube videos which are useful for anyone who wants to learn about Machine Learning  


I came across many blogs and online courses..but recently I read medium blog which I completely related to and it did really help me get started. I now know how important Mathematics is! Specially Probability.  


I think this will help you too!  


 [https://medium.com/@anupamasingh\_12727/how-do-you-learn-machine-learning-ai-on-your-own-cf671f802d3](https://medium.com/@anupamasingh_12727/how-do-you-learn-machine-learning-ai-on-your-own-cf671f802d3)",1,1
247,2019-11-26,2019,11,26,1,e1i1ic,dreaming about deep learning,https://www.reddit.com/r/deeplearning/comments/e1i1ic/dreaming_about_deep_learning/,47xsquared,1574697797,"I dreamt that my deep learning model achieved an accuracy of 80 percent.

I probably dreamt this because I am having trouble improving my image classification model.

I love deep learning!",0,1
248,2019-11-26,2019,11,26,3,e1kpzn,AI Helps Quantum Chemists Determine Molecular Wave Functions,https://www.reddit.com/r/deeplearning/comments/e1kpzn/ai_helps_quantum_chemists_determine_molecular/,Yuqing7,1574708327,,0,1
249,2019-11-26,2019,11,26,4,e1l3yc,"My first DL post! ""Weight initialization  The Why""",https://www.reddit.com/r/deeplearning/comments/e1l3yc/my_first_dl_post_weight_initialization_the_why/,quazar42,1574709835,"It should be a very quick read, this post will help you increase your intuition on why we need to use a good weight initialization strategy, how important is it anyways?

[Here](https://medium.com/@lgvaz/weight-initialization-the-why-874028fa5939?sk=69cdbae17341e2d034202a773839d372) is the link. Any feedback is very much appreciated, I was never a good writer on school so I do have much to learn =)

Thanks all",6,1
250,2019-11-26,2019,11,26,6,e1njln,"AI Weekly Update - November 25th, 2019",https://www.reddit.com/r/deeplearning/comments/e1njln/ai_weekly_update_november_25th_2019/,HenryAILabs,1574719184,https://youtu.be/4SMkOBOM504,0,1
251,2019-11-26,2019,11,26,7,e1nr02,[P] Does anyone know where I can get document datasets with version histories?,https://www.reddit.com/r/deeplearning/comments/e1nr02/p_does_anyone_know_where_i_can_get_document/,crowdsourcerer,1574719984,"I'm looking for large datasets containing documents with version histories. An obvious place to look is GitHub since they store codebases with version histories, but it looks like the [GH Archive](https://www.gharchive.org/) only tracks activity events, not code.

Any of the following kinds of datasets would serve my purposes:  
\- A dump of codebases from source control (e.g. GitHub)  
\- Documents (e.g. Google Docs) with revision histories  
\- Any other set of entities that go through an evolutionary lifecycle from initial to final version.

Any guidance is greatly appreciated; thank you.",1,1
252,2019-11-26,2019,11,26,7,e1nyab,Does anyone know where I can get document datasets with version histories?,https://www.reddit.com/r/deeplearning/comments/e1nyab/does_anyone_know_where_i_can_get_document/,crowdsourcerer,1574720792,"I'm looking for large datasets containing documents with version histories. An obvious place to look is GitHub since they store codebases with version histories, but it looks like the [GH Archive](https://www.gharchive.org/) only tracks activity events, not code.

Any of the following kinds of datasets would serve my purposes:  
\- A dump of codebases from source control (e.g. GitHub)  
\- Documents (e.g. Google Docs) with revision histories  
\- Any other set of entities that go through an evolutionary lifecycle from initial to final version.

Any guidance is greatly appreciated; thank you.",0,1
253,2019-11-26,2019,11,26,10,e1qhpi,"Introducing dKeras, new framework for distributed Keras, 30x inference improvements on large CPUs",https://www.reddit.com/r/deeplearning/comments/e1qhpi/introducing_dkeras_new_framework_for_distributed/,s-offer,1574731682,[removed],0,1
254,2019-11-26,2019,11,26,13,e1sh2h,How to use SSD to send object that it detected to another class in python,https://www.reddit.com/r/deeplearning/comments/e1sh2h/how_to_use_ssd_to_send_object_that_it_detected_to/,Betaji2,1574741217,"Hi, I made a SSD for my robot. The problem I am having is finding the variable that holds the object predictions of the frame or where the object prediction is being made. I have a robot that has to respond to different outside stimuli differently(ex for stair it would trigger the method to go up it). I am using the tensorflow models code for the SSD.  Where can I find where the prediction is being made so I can use that to trigger a certain method?Thx",0,1
255,2019-11-26,2019,11,26,13,e1sse9,Deep Learning with PyTorch [Free Book],https://www.reddit.com/r/deeplearning/comments/e1sse9/deep_learning_with_pytorch_free_book/,ai-lover,1574742852,,6,1
256,2019-11-26,2019,11,26,14,e1t4gb,Pyramid Vector Quantization and Bit Level Sparsity in Weights for Efficient Neural Networks Inference,https://www.reddit.com/r/deeplearning/comments/e1t4gb/pyramid_vector_quantization_and_bit_level/,BLMACPVQ,1574744703," [arxiv.org/abs/1911.10636](https://arxiv.org/abs/1911.10636)

This paper exploits the sparsity of neural networks weights at the level of their bit representation in order to eliminate multipliers from dot product calculations. It's mainly aimed at hardware implementation of inference engines. Dot products are calculated with a slightly modified accumulator. Arbitrary precision of the weights is supported from binary to floating point, with the same simple accumulator.

An analysis of performance  is given for Tiny Yolo v3 as well as a FIR filter.",0,1
257,2019-11-26,2019,11,26,15,e1u5n7,"Deep Learning Outperforming Classic ML Methods, Says Report",https://www.reddit.com/r/deeplearning/comments/e1u5n7/deep_learning_outperforming_classic_ml_methods/,analyticsinsight,1574750561,,1,1
258,2019-11-26,2019,11,26,15,e1u9l4,Image Classification for Images (below 40x40),https://www.reddit.com/r/deeplearning/comments/e1u9l4/image_classification_for_images_below_40x40/,data_autopsy,1574751256,"I have been exploring options for Image Classification for images (as low as 20x20). Image is bit distorted as well compared to CIFAR (32x32). I have tried focal loss during classification but results are not good. Is there any other approach you guys can nudge me towards? Also, I'm having close to 130+ classes and around 30-40 classes are underrepresented as low as 0.001 of training data. Is there a solution for that as well? I would really appreciate the help.",3,1
259,2019-11-26,2019,11,26,17,e1vbru,Would you use Dual Shot Face Detectors to perform Facial Recognition ?,https://www.reddit.com/r/deeplearning/comments/e1vbru/would_you_use_dual_shot_face_detectors_to_perform/,antmoreau,1574758433,,0,1
260,2019-11-26,2019,11,26,18,e1vied,Deep Learning vs Neural Networks,https://www.reddit.com/r/deeplearning/comments/e1vied/deep_learning_vs_neural_networks/,lukky43,1574759714,,0,1
261,2019-11-26,2019,11,26,19,e1w4rs,"I want to build a NN from scratch, where do I start?",https://www.reddit.com/r/deeplearning/comments/e1w4rs/i_want_to_build_a_nn_from_scratch_where_do_i_start/,veranceftw,1574763888,"Hello, I would like to learn how to build a NN from scratch and I am looking for some good articles/tutorials that can get me into it. 

I want to build a simple texture segmentation/classification network so I can tweak it accordingly to my needs, I feel like I am trying to kill a moth with a cannon and starting from scratch could help me understand what I really need and how to adapt my architecture.

I'll be using Pytorch (we all know why)

&amp;#x200B;

Cheers!",1,1
262,2019-11-26,2019,11,26,19,e1waer,High resolution visualizations of loss landscapes that use real data in both video and image format,https://www.reddit.com/r/deeplearning/comments/e1waer/high_resolution_visualizations_of_loss_landscapes/,javismiles,1574764951,,0,1
263,2019-11-26,2019,11,26,19,e1wew5,"High resolution video visualization of mode connectivity using real data | NeurIPS 2018, ARXIV:1802.10026",https://www.reddit.com/r/deeplearning/comments/e1wew5/high_resolution_video_visualization_of_mode/,javismiles,1574765814,,5,1
264,2019-11-26,2019,11,26,20,e1wmz3,Should I use additive or multiplicative inverse as loss regularizing term?,https://www.reddit.com/r/deeplearning/comments/e1wmz3/should_i_use_additive_or_multiplicative_inverse/,marcoroberti,1574767260,[removed],0,1
265,2019-11-26,2019,11,26,20,e1wxf8,Breaking Black-box AI,https://www.reddit.com/r/deeplearning/comments/e1wxf8/breaking_blackbox_ai/,mto96,1574769135,,1,1
266,2019-11-26,2019,11,26,21,e1x2y3,Intel Core i7-9700K or AMD Ryzen 7 3800X?,https://www.reddit.com/r/deeplearning/comments/e1x2y3/intel_core_i79700k_or_amd_ryzen_7_3800x/,baabaaaam,1574770056," I'm currently building a new machine, mostly for ML (NLP). But I can't decide if I should go for Intel or AMD for the CPU. My budget for the CPU is max 400. So which of the two would be better?",5,1
267,2019-11-26,2019,11,26,23,e1yjcb,Importance of joint distribution.,https://www.reddit.com/r/deeplearning/comments/e1yjcb/importance_of_joint_distribution/,santhuraj,1574777944,Why do we care about joint distribution?try to elaborate in few sentences.,3,1
268,2019-11-27,2019,11,27,1,e20h65,Quick question about transformer ( attention is all you need ),https://www.reddit.com/r/deeplearning/comments/e20h65/quick_question_about_transformer_attention_is_all/,nalra1234,1574786349,"I took an implementation [https://github.com/kpot/keras-transformer](https://github.com/kpot/keras-transformer) and made it ""run"" for a simple problem where inputs are batches of sequences.   


My question is, adding heads means you slice the batch of sequences .. Meaning adding heads doesn't add or remove hyperparameters to the network.  
However, adding depth to the attention layers, isn't that supposed to add a lot more hyperparameters? Surprisingly in my model, when I add depth, and do model.summary, it doesn't evolve at all.  


Thanks in advance.",1,1
269,2019-11-27,2019,11,27,3,e22j0a,How do RNNs for text-to-speech know when a character ends?,https://www.reddit.com/r/deeplearning/comments/e22j0a/how_do_rnns_for_texttospeech_know_when_a/,Johannes8,1574794564,"Im a Little confused about what size the single time frame is that the RNN analyses one after the other.

One assumption would be a single sample, so with a samplerate of 16k that would be 1/16000 second. That sure isnt enough to know what character it will be. I so far thought that for each calculation from the RNN it outputs a matrix of probable letters. A CTC for example would then take the most probable ones and apply the loss function. I know how CTC solves the problem of not having aligned input data but still the question is:

How many ms does the RNN take from a spectrogram so it can make meaningful assumptions. If the neural network knew that one letter is 200ms it could simply look at that. But since it doesnt I wonder how it knows when the letter is finished or if it doesnt how can it output something meaningful for say 10x20ms from a 200ms letter.

I assume its the recurrent part that I dont get if we assume the RNN has a bidirectional recurrent layer. Sure it can propagate knowledge to the next iteration but still it has to output a matrix for the current segment aswell.

I hope you know where I struggle to understand. Im currently trying to understand the DeepSpeech architecture by Baidu",0,1
270,2019-11-27,2019,11,27,4,e22s1c,How do RNNs know what to output for a singe time-frame for e2e speech-to-text,https://www.reddit.com/r/deeplearning/comments/e22s1c/how_do_rnns_know_what_to_output_for_a_singe/,Johannes8,1574795509,"Im a little confused about what size the single time frame is that the RNN analyses one after the other from say a 2sec audio recording.

One assumption would be a single sample, so with a samplerate of 16k that would be 1/16000 second. That sure isnt enough to know what character it will be. I so far thought that for each calculation from the RNN it outputs a matrix of probable letters. A CTC for example would then take the most probable ones and apply the loss function. I know how CTC solves the problem of not having aligned input data but still the question is:

How many ms does the RNN take from a spectrogram so it can make meaningful assumptions. If the neural network knew that one letter is 200ms it could simply look at that. But since it doesnt I wonder how it knows when the letter is finished or if it doesnt how can it output something meaningful for say 10x20ms from a 200ms letter.

I assume its the recurrent part that I dont get if we assume the RNN has a bidirectional recurrent layer. Sure it can propagate knowledge to the next iteration but still it has to output a matrix for the current segment aswell.

I hope you know where I struggle to understand. Im currently trying to understand the DeepSpeech architecture by Baidu",0,1
271,2019-11-27,2019,11,27,4,e234n6,MarioNETte: Few-Shot Identity Preservation in Facial Reenactment,https://www.reddit.com/r/deeplearning/comments/e234n6/marionette_fewshot_identity_preservation_in/,Yuqing7,1574796927,,0,1
272,2019-11-27,2019,11,27,6,e24jal,Are chatbots good source of passive income?,https://www.reddit.com/r/deeplearning/comments/e24jal/are_chatbots_good_source_of_passive_income/,DreamOfDestiny,1574802428,"Apologizing for noob question, I am new here.

I will start my master degree in data science next year, and mostly will be busy studying and researching. And to pay tuition fee I was considered to work part time or freelancing. However, I want to give my all to education, to absorb all knowledge that university can give me and therefore, thinking about ways to make money with deep learning ( I self learned basics - intermediate stuff )

I want to know whether making DL/ML chatbots for messengers any profitable? Or there are better way to make some passive income with ML.

Also, I have an idea of regularizing traffics lights with the help of DL/DRL.
But, I assume that this project is more research based and less commercial.",4,1
273,2019-11-27,2019,11,27,6,e24kaj,Help Us Design the Future,https://www.reddit.com/r/deeplearning/comments/e24kaj/help_us_design_the_future/,danae-ixd,1574802538,"Hello!

We are Interaction Design Master's students from the Estonian Academy of Arts and it would be really awesome if you could give us some **real human insight** for our Service Design project.

We are on a quest to bridge the gap between creative innovators and meaningful work.

How?

Take this short **3-minute** survey and we'll show you what's cooking ;)

[https://creativeinnovators.typeform.com/to/Wytz4N](https://creativeinnovators.typeform.com/to/Wytz4N)",2,1
274,2019-11-27,2019,11,27,7,e2604z,Multiplexed CNN: Selective branch training using control signal in Keras,https://www.reddit.com/r/deeplearning/comments/e2604z/multiplexed_cnn_selective_branch_training_using/,ayvin_tech,1574808034,"Training multiplexed cnn model on MNIST data by selectively switching using control signal. It can be useful in training networks like conditional imitation learning, multi-branch output that depends on control action, etc.

Code available at: [https://github.com/2vin/multiplexed\_cnn](https://github.com/2vin/multiplexed_cnn)",4,1
275,2019-11-27,2019,11,27,10,e28862,I need help for a project,https://www.reddit.com/r/deeplearning/comments/e28862/i_need_help_for_a_project/,Betaji2,1574817551,Hi I need help on my SSD.  I trained the model(using the tensorflow models code on github) but I can find where the prediction of the object is being made. I need this to return that prediction so my robot could preform a certain action based on what that prediction is(ex if their is a ball it picks it up). Where can I find where the prediction is being made? Sorry I know it is a bit of a dumb question.,12,1
276,2019-11-27,2019,11,27,10,e28jm1,Surging training loss,https://www.reddit.com/r/deeplearning/comments/e28jm1/surging_training_loss/,shahriar49,1574818982,"I have a 3 layer recurrent neural network (128 cells in each layer - around 330K parameters for the whole network) and train it with datasets of various sizes (I am using RMSprop as the optimizer with its default parameters). But I get below behavior when I train the model with a data set of around 3 million samples or more while everything is fine with smaller datasets:

&amp;#x200B;

https://preview.redd.it/igh97px0v4141.png?width=640&amp;format=png&amp;auto=webp&amp;s=dc1bb649695b628a9beb8b148864755e5a78378a

What can be the reason for surging training accuracy? It doesn't make sense to me that training loss go upward!

I am running my code under Tensorflow/Keras on a machine with an Nvidia GPU. No runtime or memory error encountered during simulation.",5,1
277,2019-11-27,2019,11,27,12,e29liz,"Is it possible and how to do Object Detection on a STM32 microchip with around 1M Flash and 320K RAM? Not necessary real time, but quicker is better.",https://www.reddit.com/r/deeplearning/comments/e29liz/is_it_possible_and_how_to_do_object_detection_on/,rockkingjy,1574823720,[removed],0,1
278,2019-11-27,2019,11,27,17,e2d4ap,Transformer NN,https://www.reddit.com/r/deeplearning/comments/e2d4ap/transformer_nn/,fibonacci_bokertov,1574843289,How can use tge tranformer network for regression? In other words for many to one task?,0,1
279,2019-11-27,2019,11,27,17,e2dcsf,Build and and Deploy a deep learning app to AWS from scratch: an end-to-end tutorial ,https://www.reddit.com/r/deeplearning/comments/e2dcsf/build_and_and_deploy_a_deep_learning_app_to_aws/,ahmedbesbes,1574844831,,0,1
280,2019-11-27,2019,11,27,21,e2f996,[POST] Why tf.keras? One ring to rule them all!,https://www.reddit.com/r/deeplearning/comments/e2f996/post_why_tfkeras_one_ring_to_rule_them_all/,cdossman,1574856986,"Some of the advanced features in TensorFlow 1.0 like Graph, AutoGraph, and Eager Execution certainly get the job done, but what a headache! 

This TensorFlow 1.0 vs 2.0  series demonstrates how you can take advantage of tf.keras, a much more painless way to build models. Check it out  https://medium.com/@lsgrep/tensorflow-1-0-vs-2-0-part-3-tf-keras-ea403bd752c0",0,1
281,2019-11-28,2019,11,28,1,e2i636,"PyTorch implementation of a transformer chatbot. Code is explained with highschool level language, without jargon, down to the fundamentals with diagrams in ipython notebooks",https://www.reddit.com/r/deeplearning/comments/e2i636/pytorch_implementation_of_a_transformer_chatbot/,clam004,1574871087,,7,1
282,2019-11-28,2019,11,28,5,e2m9dm,Which system(laptop) would be better for deep learning ? i5 9300H and GTX- 1650 VS i79750H and GTX- 1050Ti,https://www.reddit.com/r/deeplearning/comments/e2m9dm/which_systemlaptop_would_be_better_for_deep/,no0b123,1574886649,help me out . thanks,4,1
283,2019-11-28,2019,11,28,6,e2n3y2,How could I make a CNN detect multiple objects in a single frame?,https://www.reddit.com/r/deeplearning/comments/e2n3y2/how_could_i_make_a_cnn_detect_multiple_objects_in/,Betaji2,1574889954,I made a CNN but I want to use it to predict more than one object in a single frame. What modifications would I have to make to make to do this? Thx,7,1
284,2019-11-28,2019,11,28,11,e2rgkw,"Go master Lee Sedol quits, unable to win over AI opponents.",https://www.reddit.com/r/deeplearning/comments/e2rgkw/go_master_lee_sedol_quits_unable_to_win_over_ai/,sinhpi,1574909167,,9,1
285,2019-11-28,2019,11,28,12,e2sa3t,what GPU workstation do you recommend?,https://www.reddit.com/r/deeplearning/comments/e2sa3t/what_gpu_workstation_do_you_recommend/,Deepseed_India,1574913000,"I am looking for a pre-built GPU workstation for Deep learning experiments for my lab. I will be sharing the workstation with another labmate. I was looking for configuration details for the Workstation(CPU, RAM, GPUs, cooling, etc). My budget is $12,000.  Any help is appreciated.

I did find a list of vendors from [Reddit post](https://www.reddit.com/r/deeplearning/comments/9lryzf/what_prebuilt_gpu_workstations_do_you_recommend/). Please suggest a few vendors.",0,1
286,2019-11-28,2019,11,28,16,e2ukg2,Request for papers on deep learning based UAV.,https://www.reddit.com/r/deeplearning/comments/e2ukg2/request_for_papers_on_deep_learning_based_uav/,Dr_Samuel_Hayden,1574925829,"Hi, I've done some work on SLAM algorithms for UAV's in my bachelors. For my masters I want to make a deep learning based drone. I have implemented mono and stereo (inertial and non-inertial) algorithms for drones.

Can you guys please suggest me some papers for my project?",1,1
287,2019-11-28,2019,11,28,16,e2uw3e,GANs revolutionize Anti-Money Laundering  the revolution will not be supervised,https://www.reddit.com/r/deeplearning/comments/e2uw3e/gans_revolutionize_antimoney_laundering_the/,jpdowlin,1574927744,,0,1
288,2019-11-28,2019,11,28,19,e2w4bg,How to free up space in disk on Colab TPU?,https://www.reddit.com/r/deeplearning/comments/e2w4bg/how_to_free_up_space_in_disk_on_colab_tpu/,classyflyer,1574935800,"I am training a few deep learning models on Google Colab with runtime type set to TPU. The RAM and disk status shows that I have used most of my disk storage on Colab. Is there a way to reset it? Or to delete something to free up some more disk space? I know that I can change to GPU which will give me a lot more disk space, however, my models take forever to change, so I would really like to stay with TPU. Thanks in advance!",0,1
289,2019-11-28,2019,11,28,20,e2wt0w,Project ideas related to synthetic Music generation.,https://www.reddit.com/r/deeplearning/comments/e2wt0w/project_ideas_related_to_synthetic_music/,bikigoogler,1574940486,"I am reading a paper, [MuseGAN](https://arxiv.org/pdf/1709.06298.pdf) for generating music using GAN. I am searching for project ideas right now  related to synthetic Music generation. So please give me some hint(any ideas) what i can do.",0,1
290,2019-11-28,2019,11,28,21,e2x9r1,"Demonstrating American Sign Language Classification using Monk. Monk is an open-source low-code unified wrapper over major deep learning frameworks. Blog: http://bit.ly/sign_language_classification, Github: http://bit.ly/monk-github",https://www.reddit.com/r/deeplearning/comments/e2x9r1/demonstrating_american_sign_language/,abhishek4273,1574943405,,6,1
291,2019-11-28,2019,11,28,23,e2yx5o,"[Blog post]Introduction of Adversarial Examples Improve Image Recognition , ImageNet SOTA method using Adversarial Training",https://www.reddit.com/r/deeplearning/comments/e2yx5o/blog_postintroduction_of_adversarial_examples/,akira_AI,1574952335,,4,1
292,2019-11-28,2019,11,28,23,e2z166,can understand dataset of radiologist,https://www.reddit.com/r/deeplearning/comments/e2z166/can_understand_dataset_of_radiologist/,longkum,1574952878,[removed],0,1
293,2019-11-29,2019,11,29,4,e32t0m,"Herring, Not Herring: Deep Learning Accelerates Detection and Classification of Underwater Species",https://www.reddit.com/r/deeplearning/comments/e32t0m/herring_not_herring_deep_learning_accelerates/,Yuqing7,1574968919,,0,1
294,2019-11-29,2019,11,29,4,e32vtu,Show HN: Building websites from Sketch using deep learning  public launch,https://www.reddit.com/r/deeplearning/comments/e32vtu/show_hn_building_websites_from_sketch_using_deep/,HN_Crosspost_Bot,1574969236,,0,1
295,2019-11-29,2019,11,29,5,e33jyb,GitHub - kk7nc/Text_Classification: Text Classification Algorithms: A Survey,https://www.reddit.com/r/deeplearning/comments/e33jyb/github_kk7nctext_classification_text/,kk7nc,1574972020,,0,1
296,2019-11-29,2019,11,29,9,e374e8,Should I re-initialize my optimizer and my scheduler every time when I try to fine tune my neural network on a different dataset?,https://www.reddit.com/r/deeplearning/comments/e374e8/should_i_reinitialize_my_optimizer_and_my/,h56cho,1574988636,"Hello,

I am doing NLP, and I have this block of Transformer body that was already trained on dataset A.

Now I am interested in fine tuning this same Transformer on a new dataset B.

In my Python code, should I re-initialize my optimizer and my scheduler before I try to fine tune my neural network on the different dataset?

&amp;#x200B;

Thank you,",2,1
297,2019-11-29,2019,11,29,10,e37pf6,How to tackle a Person Re-Identification problem?,https://www.reddit.com/r/deeplearning/comments/e37pf6/how_to_tackle_a_person_reidentification_problem/,Sebasuraa,1574991649,"Hi, I need to solve a person re-id problem, where I will receive video from security cameras located in different aisles of a store (they don't overlap) and I have to measure how much time a every person spends in that aisle, count the people in it, etc. I imagine the hardest part is to identify the same person across ever camera, and I'm new to ML/DL, so I don't even know where to begin. I've read about ML and NN, I know a little bit about hyperparameters and I've watched 3brown1blue's videos on NNs, so I kind of get the basics, theoretically. I don't even need to build my own NN, I can use pre-trained models, but I don't know how to begin, what to learn first (pytorch, tensorflow, keras, opencv, etc), how should the pipeline of my program look like, etc. Any guidance, book recommendation, videotutorial would be appreciated. Thanks.",3,1
298,2019-11-29,2019,11,29,13,e39q9z,Creating a neural network for fire detection,https://www.reddit.com/r/deeplearning/comments/e39q9z/creating_a_neural_network_for_fire_detection/,PapaP123,1575002053,,2,1
299,2019-11-29,2019,11,29,15,e3aukg,anybody has work on medical image dataset?,https://www.reddit.com/r/deeplearning/comments/e3aukg/anybody_has_work_on_medical_image_dataset/,longkum,1575008430,[removed],0,1
300,2019-11-29,2019,11,29,18,e3cu3h,A list of Monte Carlo tree search research papers,https://www.reddit.com/r/deeplearning/comments/e3cu3h/a_list_of_monte_carlo_tree_search_research_papers/,benitorosenberg,1575021546,"&amp;#x200B;

![img](y9lb5vkyll141)

[https://github.com/benedekrozemberczki/awesome-monte-carlo-tree-search-papers](https://github.com/benedekrozemberczki/awesome-monte-carlo-tree-search-papers)

It was compiled in a semi-automated way and covers content from the following conferences:

* Machine learning
   * [NeurIPS](https://nips.cc/)
   * [ICML](https://icml.cc/)
* Computer vision
   * [CVPR](http://cvpr2019.thecvf.com/)
   * [ICCV](http://iccv2019.thecvf.com/)
* Natural language processing
   * [ACL](http://www.acl2019.org/EN/index.xhtml)
* Data
   * [KDD](https://www.kdd.org/)
* Artificial intelligence
   * [AAAI](https://www.aaai.org/)
   * [AISTATS](https://www.aistats.org/)
   * [IJCAI](https://www.ijcai.org/)
   * [UAI](http://www.auai.org/)",0,1
301,2019-11-29,2019,11,29,20,e3dmll,(Vanilla) Autoencoder generating zero and highly correlated latent space,https://www.reddit.com/r/deeplearning/comments/e3dmll/vanilla_autoencoder_generating_zero_and_highly/,joefromlondon,1575027119,"Hi all, 

I am building an autoencoder for mixed tabular data, essentially for dimensionality reduction to feed to a clustering algorithm (GMM/ k-means/ other). My data is a mixture of continuous and one hot encoded categorical data with around 450 features/ 1000 samples. 

I am reducing the dimension to 3-10 latent variables being passed though a slightly larger hidden layer, with the decoder the same shape (in reverse). I should note I am using Keras with TF backend.

I seem to be facing two problems. The first is that depending on the seed, some of the latent variables are all 0's. could this be because I have too many latent variables or two few? changing the number doesn't seem to remove this phenomenon. 

Another issue is that many of the latent variables are not orthogonal and in some cases highly correlated (Pearson &gt; 0.6). I understand that this isn't necessarily to be expected from an autoencoder as it is from PCA, but can it be rectified?

I am also considering using VAEs as opposed to AE but not completely seeing the benefits at the moment given my application. 

&amp;#x200B;

Any advice, previous experience with similar effects are very welcome. 

&amp;#x200B;

Thanks!",2,1
302,2019-11-29,2019,11,29,21,e3e29x,Basic Image Classification in Tensorflow 2.0,https://www.reddit.com/r/deeplearning/comments/e3e29x/basic_image_classification_in_tensorflow_20/,dasaradhsk,1575030006,,0,1
303,2019-11-29,2019,11,29,22,e3emm5,Swift for TensorFlow [SUBREDDIT],https://www.reddit.com/r/deeplearning/comments/e3emm5/swift_for_tensorflow_subreddit/,rahulbhalley,1575033476,,0,1
304,2019-11-29,2019,11,29,22,e3ezan,Human Action Recognition with Mixed 3D/2D Convolutional Tube Networks (MiCT-Net),https://www.reddit.com/r/deeplearning/comments/e3ezan/human_action_recognition_with_mixed_3d2d/,Fanos6,1575035437,"&amp;#x200B;

[The MiCT-ResNet-18 architecture for action recognition.](https://preview.redd.it/rq4mk6ajqm141.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=894357b02ea51a5dda850a43d75c0f2b449379dd)

Mixed 3D/2D Convolutional Tubes (MiCT) have been proposed by [Microsoft Research](https://www.microsoft.com/en-us/research/uploads/prod/2018/05/Zhou_MiCT_Mixed_3D2D_CVPR_2018_paper.pdf) to improve Human Action Recognition. The key principle is the introduction of a limited number of 3D residual convolutions at select locations of a 2D-CNN backbone pre-trained on ImageNet. The 3D convolution branches learn residual temporal features, which are the motions of objects and persons, while the 2D backbone learns spatial features and generates deeper and more informative feature representations after each spatio-temporal fusion.  

This [repository](https://github.com/fmahoudeau/MiCT-Net-PyTorch) provides a PyTorch implementation of the MiCT-Net architecture using a ResNet backbone and validates the authors approach for small data sets (namely UCF-101) by comparing its performance with a 3D-ResNet. Let me know your comments.",0,1
305,2019-11-29,2019,11,29,23,e3fe8q,How to check output names from a neuron?,https://www.reddit.com/r/deeplearning/comments/e3fe8q/how_to_check_output_names_from_a_neuron/,Betaji2,1575037654,Hi how would I check the output names from a neuron in a SDD? Also could I get the bounding boxes from this as well or is their something else I need to do?,1,1
306,2019-11-30,2019,11,30,0,e3fwqt,ML Paper Notes: My notes of various ML research papers (DL - CV - NLP),https://www.reddit.com/r/deeplearning/comments/e3fwqt/ml_paper_notes_my_notes_of_various_ml_research/,youali,1575040270,"Hello,

As a PhD student, I read quite a lot of papers, and sometimes I make short summaries with a simple latex template to get a better understanding and have clearer idea of the paper's contributions. For a while I stored them in private Github repo, so I tought why note share them, some people might find them helpful.

PS: Sorry for the (sometimes frequent) spelling mistakes.

Here is the Github link: https://github.com/yassouali/ML_paper_notes",4,1
307,2019-11-30,2019,11,30,2,e3hytg,News Update: Deep Learning Ecosystem,https://www.reddit.com/r/deeplearning/comments/e3hytg/news_update_deep_learning_ecosystem/,surkin143,1575049415,"In terms of investments in the field of artificial intelligence &amp; [deep learning ecosystem](https://www.alltheresearch.com/report/312/global-deep-learning-ecosystem-market), the U.S. has overtaken China to grab the topmost spot as a venture capital investment hub. The U.S. attracted the most investment in 2018, accounting for more than 50% of total investments in AI and Deep Learning ecosystem across the globe.  

For more info Click on the link below:

 [https://www.alltheresearch.com/report/312/global-deep-learning-ecosystem-market](https://www.alltheresearch.com/report/312/global-deep-learning-ecosystem-market)",0,1
308,2019-11-30,2019,11,30,3,e3ibiq,Deep Learning Ecosystem Major Interconnectivity,https://www.reddit.com/r/deeplearning/comments/e3ibiq/deep_learning_ecosystem_major_interconnectivity/,surkin143,1575050907,"[**Deep Learning Ecosystem**](https://www.alltheresearch.com/report/312/global-deep-learning-ecosystem-market)

&amp;#x200B;

https://preview.redd.it/20trhwkg1o141.png?width=1167&amp;format=png&amp;auto=webp&amp;s=a6b16e1ce6cac534da63409c0bc9924663e890c1",0,1
309,2019-11-30,2019,11,30,5,e3k8c7,5700 xt in Tensor Flow and Pytorch.,https://www.reddit.com/r/deeplearning/comments/e3k8c7/5700_xt_in_tensor_flow_and_pytorch/,Grek27,1575058730,"Has there been succesfull and smooth integration of the 5700 xt into the Deep Learning frameworks?

CUDA is the popular thing right now and I haven't found a straightforward answer on how to use the 5700s as general compute units but I thought I would check one more time before dropping money on a 2080.",5,1
310,2019-11-30,2019,11,30,7,e3m3jv,Weekly Papers | Multi-Label Deep Forest (MLDF); Huawei UK Critiques DeepMind -Rank,https://www.reddit.com/r/deeplearning/comments/e3m3jv/weekly_papers_multilabel_deep_forest_mldf_huawei/,Yuqing7,1575066243,,0,1
311,2019-11-30,2019,11,30,7,e3mfnk,Tensorbord - connect local with remote machine and run tensorboard from local machine,https://www.reddit.com/r/deeplearning/comments/e3mfnk/tensorbord_connect_local_with_remote_machine_and/,TrustAnonymity,1575067585,"I have logfiles on remote machine and want to run tensorboard from local machine to run files on remote machine.

Please help, thanks.",4,1
312,2019-11-30,2019,11,30,11,e3peko,New to ML. Useful to start reading papers?,https://www.reddit.com/r/deeplearning/comments/e3peko/new_to_ml_useful_to_start_reading_papers/,Jaszunai,1575081560,I've been taking an ML course and feel confident enough to start working on personal projects. At what point is it a good idea to start reading papers to stay up-to-date on developments in the field?,2,1
313,2019-11-30,2019,11,30,16,e3sql4,"Here is a project ""Dlearn"" a human emotion recognition based learning assistant. This is a product of this year's HACKOH/IO . Please let me know your thoughts!",https://www.reddit.com/r/deeplearning/comments/e3sql4/here_is_a_project_dlearn_a_human_emotion/,iamstark07,1575100154,,3,1
