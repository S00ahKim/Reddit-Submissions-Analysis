,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2012-5-2,2012,5,2,0,t1k5l,"I want to quantify the ""closeness"" (or relatedness) of two scientific articles based on the contents of the text.  I have no idea where to start.  Can anybody help me get oriented?",https://www.reddit.com/r/MachineLearning/comments/t1k5l/i_want_to_quantify_the_closeness_or_relatedness/,omginternets,1335885248,Please feel free to ask for clarifications!,19,12
1,2012-5-2,2012,5,2,1,t1o4k,Ceres Solver: Google's large scale nonlinear least squares solver open sourced,https://www.reddit.com/r/MachineLearning/comments/t1o4k/ceres_solver_googles_large_scale_nonlinear_least/,nathanwiegand,1335889619,,22,83
2,2012-5-2,2012,5,2,4,t1y4d,Probabilistic Data Structures for Web Analytics and Data Mining,https://www.reddit.com/r/MachineLearning/comments/t1y4d/probabilistic_data_structures_for_web_analytics/,daseinphil,1335900471,,1,13
3,2012-5-2,2012,5,2,15,t2ydu,best metal detector,https://www.reddit.com/r/MachineLearning/comments/t2ydu/best_metal_detector/,gasleafblowers12,1335941998,,0,1
4,2012-5-2,2012,5,2,17,t30ok,Determining relationships in data,https://www.reddit.com/r/MachineLearning/comments/t30ok/determining_relationships_in_data/,[deleted],1335947204,"Assumptions:

* The scores are generated by an unknown function
* Hundreds of variables in your data
* Each set of data has a score or rank
* The dataset is large, 10,000 - 1million entries of these sets of data/scores (the data set could be are large as required)

Is it possible to determine the contribution of each variable to the score? It's unknown what the weightings are.

Is it possible to determine the effect of one variable on another? It's known that a high or low value for variable *n* might change the contribution of variable *k* by some amount. But it isn't limited to linear relationships, variables *a*, *b*, and *c* could have their weightings increased by *p*, *q*, and *r* if the value for *s* and *t* are above/below some threshold.

I'm not sure its possible to do this, let alone do it in under exp/factorial time complexity... I hope the question is clear enough. ",10,2
5,2012-5-2,2012,5,2,17,t30ur,I have a good broad knowledge of Machine Learning techniques but lack detailed understanding - can you recommend a book?,https://www.reddit.com/r/MachineLearning/comments/t30ur/i_have_a_good_broad_knowledge_of_machine_learning/,[deleted],1335947620,"I've spent a lot of time trying to work my way through C. Bishop - Pattern Recognition and Machine Learning but I find it a bit difficult to get into. I commonly use a lot of techniques (Logit/SVMs/MRFs - I work in Vision) but I don't really have a deep understanding of the ""story"" of how we arrived at each approach and the mathematical steps it took to get there. I need a book which holds my hand for the first chapter or two so I can improve my maths (British maths education...). Can anyone make any recommendations?

edit: Thanks a lot for all the responses - I've made a few purchases. Hopefully see you Vision guys around ;)",13,20
6,2012-5-3,2012,5,3,4,t3rtn,Launch of the Kaggle Data Science Wiki,https://www.reddit.com/r/MachineLearning/comments/t3rtn/launch_of_the_kaggle_data_science_wiki/,willis77,1335987639,,0,28
7,2012-5-3,2012,5,3,22,t51hy,Used Shears,https://www.reddit.com/r/MachineLearning/comments/t51hy/used_shears/,johnsmithseo25,1336051372,,0,1
8,2012-5-4,2012,5,4,3,t5ify,Teaching a voice-recognition software to recognize rat vocalizations. My lab is looking to collaborate. (x-post from r/AskEngineers),https://www.reddit.com/r/MachineLearning/comments/t5ify/teaching_a_voicerecognition_software_to_recognize/,AmyThaliaGregCalvin,1336071449,"Hi. I was told this was the correct sub-reddit for such a task. My group at McGill University studies ultrasonic vocalizations made by laboratory rats. We recently discovered that rats make at least a dozen different subtypes of vocalization in the ultrasonic range. A spectrogram of their calls can be seen here http://www.avisoft.com/sounds/fit3.gif. Preliminary evidence suggests that at least some of these calls reflect the animal's emotional state.
At present, we have no automated method for categorizing the various call subtypes, so we have to do this ""manually"" from spectrograms - a laborious process to say the least. Automated categorization is complicated by the acoustic variety found within individual call subtypes. On the other hand, we don't think that laboratory rats have an extensive vocabulary, and we have collected tens of thousands of calls but we could use as a training set.
My question is: do you think any commercially available voice recognition software could be trained to categorize call subtypes? If I understand correctly, a program such as Dragon NaturallySpeaking (which I use myself) might not be suitable because it is designed to cater for a limited number of speakers each with a large vocabulary.
If anyone has any ideas, we'd love to collaborate. Please comment or send me a PM and we could discuss further over the phone, skype, or in person if you are near Montreal. Thank you",26,8
9,2012-5-4,2012,5,4,10,t63d7,Machine Learning in Python Has Never Been Easier,https://www.reddit.com/r/MachineLearning/comments/t63d7/machine_learning_in_python_has_never_been_easier/,jjdonald,1336094313,,26,45
10,2012-5-5,2012,5,5,0,t6xeb,Would this be considered a simple Kalman filter or something else?,https://www.reddit.com/r/MachineLearning/comments/t6xeb/would_this_be_considered_a_simple_kalman_filter/,ClusterSoldier,1336144559,"I'm messing around with forecasting (electric) loads. I have two sets of data/models, d1 refers to the day-ahead forecast/dataset and d2 refers to the current actual load dataset both with n points. And the Lbase and Lact variables represent d1 and d2 respectively. v stands for the variance. Initial prediction is set to d1 and the final pred is pred-load. The rest of the algorithm follows this:

set Lact = d2, n

set v1 = Lbase - Lact

set v2 = pred-load - Lact

set weight = v1 / v1 + v2

set Lbase = d1, n+1

set pred-load = Lbase + weight(Lact - Lbase)

set n = n + 1

loop

So basically, I'm adjusting the weight variable each time step based on how correct the datasets were (error). Would this be an example of a simple Kalman filter or just like a weighted moving average?

Note: Originally had the v1 and v2 setting flipped (i.e. v1 = pred-load - Lact) but the current way gives me a lower (MAPE) error.
",3,3
11,2012-5-5,2012,5,5,5,t7cfh,New York recently became the nation's first federal court to explicitly approve the use of predictive coding,https://www.reddit.com/r/MachineLearning/comments/t7cfh/new_york_recently_became_the_nations_first/,cavedave,1336161614,,12,32
12,2012-5-7,2012,5,7,0,t9rw8,Anyone here work in Finance?,https://www.reddit.com/r/MachineLearning/comments/t9rw8/anyone_here_work_in_finance/,ICrepeATATs,1336319263,"If so: 

*How do you like it?

*What degree(s) do you have?

*How does your degree relate to your work? (crucial/relevant/irrelevant/irrelevant but a necessary signal)

*What techniques/methods do you use most?


Thanks!!",23,9
13,2012-5-7,2012,5,7,15,tatgn,Pump Company,https://www.reddit.com/r/MachineLearning/comments/tatgn/pump_company/,michaelbuble12,1336371591,,2,0
14,2012-5-7,2012,5,7,18,tays2,Brainstorming: Recurrent Networks over the Web,https://www.reddit.com/r/MachineLearning/comments/tays2/brainstorming_recurrent_networks_over_the_web/,togomes,1336384356,,0,5
15,2012-5-7,2012,5,7,19,tb06y,Wellpoint Systems,https://www.reddit.com/r/MachineLearning/comments/tb06y/wellpoint_systems/,michaelbuble12,1336388283,,1,1
16,2012-5-7,2012,5,7,23,tb6y9,"I'm after the 2007 KDD cup data set (Netflix), any ideas?",https://www.reddit.com/r/MachineLearning/comments/tb6y9/im_after_the_2007_kdd_cup_data_set_netflix_any/,Jebbers,1336400933,"Couldn't find it on the KDD or Netflix sites, and it is relevant to my interests. Any help would be greatly appreciated.

Edit: [Found](http://www.lifecrunch.biz/archives/207)",12,4
17,2012-5-8,2012,5,8,6,tbsma,Noob Here: Quick question on grouping together related phrases,https://www.reddit.com/r/MachineLearning/comments/tbsma/noob_here_quick_question_on_grouping_together/,umdebaba,1336425859,"I'm trying to implement a method that takes a long list of search terms and groups them together into related groups but don't know how to start.

**Example list:**
shoes for women,
women shoes,
cheap shoes,
wholesale women shoes,
cheap running shoes,
cheap womens shoes

**Example Output Group 1: (Womens Shoes)**
shoes for women,
women shoes,
wholesale women shoes

**Example Output Group 2: (Cheap Shoes)**
cheap shoes,
cheap running shoes,
cheap womens shoes

The number of groups should not be specified in advance. Thanks for the help!",6,4
18,2012-5-8,2012,5,8,22,tcw6t,The thriving data ecosystem in NYC,https://www.reddit.com/r/MachineLearning/comments/tcw6t/the_thriving_data_ecosystem_in_nyc/,agconway,1336484006,,17,13
19,2012-5-9,2012,5,9,4,tdfb9,"Using the ADTree machine learning algorithm &amp; a web-based tool, Harvard researchers can diagnose Autism in minutes",https://www.reddit.com/r/MachineLearning/comments/tdfb9/using_the_adtree_machine_learning_algorithm_a/,kneb,1336506629,,0,1
20,2012-5-9,2012,5,9,23,teqi6,scikit-learn: machine learning in Python,https://www.reddit.com/r/MachineLearning/comments/teqi6/scikitlearn_machine_learning_in_python/,Samus_,1336574300,,7,20
21,2012-5-10,2012,5,10,1,tewbg,R and Data Mining: Examples and Case Studies,https://www.reddit.com/r/MachineLearning/comments/tewbg/r_and_data_mining_examples_and_case_studies/,H4L9000,1336581275,,0,29
22,2012-5-10,2012,5,10,8,tfjs5,Machine Learning Summer School Program Impressions?,https://www.reddit.com/r/MachineLearning/comments/tfjs5/machine_learning_summer_school_program_impressions/,GTanaka,1336606469,"I was wondering if anyone here has had any experience with the [Machine Learning Summer School program](http://www.mlss.cc/).  For those who have attended, 

* Was it a worthwhile experience?  
* Do you feel that you learned something useful beyond what you would have found on  your own time?  
* Did the talks go into sufficient technical depth to truly understand an area of research without becoming too opaque to understand?",3,17
23,2012-5-10,2012,5,10,14,tg1q0,Modified split rule for Adaboost with decision trees,https://www.reddit.com/r/MachineLearning/comments/tg1q0/modified_split_rule_for_adaboost_with_decision/,rudyl313,1336627825,"I've been trying to write code to implement adaboost with decision trees. The vanilla tree training algorithm uses entropy gain as a metric for picking the best split points. 

But, now that I'm trying to pick splits with a distribution of weights over the inputs (due to the adaboosting) I'm not sure how the split rule works anymore. Can anybody explain to me how to decide on the best split given a distribution of weights over the inputs?",8,4
24,2012-5-10,2012,5,10,18,tg91w,"WOW!!!
ARE YOU AWARE OH THIS TECHNOLOGY...",https://www.reddit.com/r/MachineLearning/comments/tg91w/wow_are_you_aware_oh_this_technology/,pallav2122,1336643166,,0,1
25,2012-5-11,2012,5,11,1,tgnjl,R you ready for Big Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/tgnjl/r_you_ready_for_big_machine_learning/,jjdonald,1336666781,,18,12
26,2012-5-11,2012,5,11,3,tgsx9,"Survey: what is ""data science""?",https://www.reddit.com/r/MachineLearning/comments/tgsx9/survey_what_is_data_science/,agconway,1336672853,,0,0
27,2012-5-12,2012,5,12,1,tidkl,"Videos of the UC Berkeley Conference: ""From Data to Knowledge: Machine-Learning with Real-time and Streaming Applications""",https://www.reddit.com/r/MachineLearning/comments/tidkl/videos_of_the_uc_berkeley_conference_from_data_to/,[deleted],1336754517,,0,1
28,2012-5-12,2012,5,12,1,tie3j,"Matrix Factorization and Recommender Systems (Alex Smola's SML class, UC Berkeley) -video and slides-",https://www.reddit.com/r/MachineLearning/comments/tie3j/matrix_factorization_and_recommender_systems_alex/,[deleted],1336755130,,0,22
29,2012-5-12,2012,5,12,10,tj3io,Support Vector Machines,https://www.reddit.com/r/MachineLearning/comments/tj3io/support_vector_machines/,nellaivijay,1336787442,,5,31
30,2012-5-13,2012,5,13,1,tjrsw,"Advanced Matrix Factorization Jungle Page
- A living document featuring some of the most advanced algorithms in advanced Matrix Factorization i.e. beyond vanilla MNF and SVD - ",https://www.reddit.com/r/MachineLearning/comments/tjrsw/advanced_matrix_factorization_jungle_page_a/,[deleted],1336839328,,0,30
31,2012-5-13,2012,5,13,1,tjrz1,"The Big Picture in Compressive Sensing
- A living document trying to paint the Big Picture in the Compressed Sensing or Compressive Sensing Framework- ",https://www.reddit.com/r/MachineLearning/comments/tjrz1/the_big_picture_in_compressive_sensing_a_living/,[deleted],1336839554,,0,10
32,2012-5-13,2012,5,13,3,tjw9f,LinkedIn group on Advanced Matrix Factorization,https://www.reddit.com/r/MachineLearning/comments/tjw9f/linkedin_group_on_advanced_matrix_factorization/,[deleted],1336845950,,0,1
33,2012-5-14,2012,5,14,0,tl24u,ICML 2012  Accepted papers,https://www.reddit.com/r/MachineLearning/comments/tl24u/icml_2012_accepted_papers/,hapagolucky,1336924621,,6,19
34,2012-5-14,2012,5,14,15,tm4kd,Corrugated Packaging: What You Need to Know,https://www.reddit.com/r/MachineLearning/comments/tm4kd/corrugated_packaging_what_you_need_to_know/,gustavoduhamel,1336977661,,1,1
35,2012-5-15,2012,5,15,9,tncod,Books on probabilistic reasoning?,https://www.reddit.com/r/MachineLearning/comments/tncod/books_on_probabilistic_reasoning/,SIULHT,1337041868,"I was looking to read on this topic (and Bayesian inference in general) but wonder if J. Pearl's more recent book on causality supersedes his seminal work, _Probabilistic Reasoning in Intelligent Systems_ (or is that still book relevant in its timeless form?). Also, would appreciate other books that might be relevant for someone with an applied science/engineering background. Thanks!",33,19
36,2012-5-15,2012,5,15,20,to1tf,Data analysis of GitHub timeline data,https://www.reddit.com/r/MachineLearning/comments/to1tf/data_analysis_of_github_timeline_data/,kafka399,1337080556,,4,22
37,2012-5-16,2012,5,16,5,tordj,Will 2015 be the Beginning of the End for SAS and SPSS?,https://www.reddit.com/r/MachineLearning/comments/tordj/will_2015_be_the_beginning_of_the_end_for_sas_and/,talgalili,1337113633,,0,2
38,2012-5-16,2012,5,16,11,tpau8,Civic Data Challenge Announces New Prize: Your own Kaggle competition,https://www.reddit.com/r/MachineLearning/comments/tpau8/civic_data_challenge_announces_new_prize_your_own/,willis77,1337135220,,0,5
39,2012-5-16,2012,5,16,12,tpdwz,SIAM Data Mining 2012 Conference Summary,https://www.reddit.com/r/MachineLearning/comments/tpdwz/siam_data_mining_2012_conference_summary/,LADataJunkie,1337138810,,0,4
40,2012-5-16,2012,5,16,20,tpt6g,Graphical Models -Alex Smola's Scalable Machine Learning Class @UC Berkeley- Videos and Slides ,https://www.reddit.com/r/MachineLearning/comments/tpt6g/graphical_models_alex_smolas_scalable_machine/,[deleted],1337168425,,2,38
41,2012-5-17,2012,5,17,23,trp1f,Open Source SPAMS (SPArse Modeling Software) now with Python and R,https://www.reddit.com/r/MachineLearning/comments/trp1f/open_source_spams_sparse_modeling_software_now/,[deleted],1337265916,,2,9
42,2012-5-17,2012,5,17,23,trpkm,"Develop a Gesture Recognizer for Microsoft Kinect (TM)/ One-shot-learning Gesture Recognition (round 2)/ First place: USD 5,000 / Second place: USD 3,000 / Third place: USD 2,000",https://www.reddit.com/r/MachineLearning/comments/trpkm/develop_a_gesture_recognizer_for_microsoft_kinect/,[deleted],1337266603,,4,7
43,2012-5-17,2012,5,17,23,trpon,Code for MIT Faster Fast Fourier Transform,https://www.reddit.com/r/MachineLearning/comments/trpon/code_for_mit_faster_fast_fourier_transform/,[deleted],1337266751,,7,26
44,2012-5-18,2012,5,18,2,try3l,Assistance with AI design problem,https://www.reddit.com/r/MachineLearning/comments/try3l/assistance_with_ai_design_problem/,RixiM,1337276640,"I have a turn-based tactics game that is played in a persistent world and I would like to write AI for the NPCs. 

There are two scales that the game is currently played on: the World scale and the Field scale. Both the squad AI and the unit AI operate on the Field scale. 

(At some point there will be AI that operate on the World scale and up but that is outside the scope of this very long question.)

At the moment the game plays a lot like chess, there are two sides and each player picks a unit to act, then the unit can target a tile or move to a tile. There are two categories of attacks, magical attacks and physical attacks. The magical attacks are area of effect and damage over time. The physical attacks are ranged and melee. Every unit has a primary element (suit), if a magical attack is of the same element as the unit attacked, the unit is healed using an inversion of what the damage would have been. 

Here is the code that determines this:
https://bitbucket.org/a.f.dudley/binary-tactics/src/06f02072ba11/binary_tactics/hex_battlefield.py#cl-365

The NPCs are called Nescients. Player controlled units are called Scients. The AI would be for controlling Nescients regardless of if they are interacting with players or not. Currently, the plan is for them Forage, Fight and Mate. 

Everything in the world has a composition that is a set of 4 0-255 values: E, F, I, W. 
Units, have a primary element or suit. Depending on the unit type, the distribution of points within the values is constrained. Scients must have 0 points in the value opposite of their suit and a maximum of half (rounded down) the points of their suit can be in their orthogonal elements. A low-level Earth Scient would be {E:5, F:2, I:2 W:0} for example. Nescients are constrained such that points can only be distributed to their primary element and one orthogonal element such that the points in the orthogonal element are always less than the points in the primary. A low-level Earth Nescient would be {E:5, F:4, I:0, W:0}. Magic defense, magic attack, physical defense and physical attack are determined by I, W, E, and F respectively. 

(A full description of unit attributes can be found here: https://bitbucket.org/a.f.dudley/binary-tactics/src/06f02072ba11/binary_tactics/units.py#cl-25 )

I want the composition (and its value) to play a key role in the behavior of units. For example, I want Nescients to have a positive affinity for units of the same suit, a neutral affinity for units of orthogonal suits and a negative affinity for units of opposite suits. The same goes for eating. Also it seems reasonable that E and I units would be less aggressive than W and F units and more aggressive units would be more likely to eat (attack) neutral units.

There will need to be some more thought given to how the Fields treat groups of Nescients when there is no player on the field... one of the problems that is important to AI design that I am leaving out is how turns may change in the future. Without being too digressive, one of the key elements of Yasumi Matsuno's battle systems is the use of an action timer. I feel as though this is what sets tactics game apart from more traditional turn-based board games. But for complexity reasons I do not plan on having action timers in the alpha version of the code. Thus in the current model two Nescients ""fill"" a Field. That way they can take turns as two players would, which is written and (mostly!) working. In idealized game play there can be up to 4 Nescients in player controlled squads and as many Nescients in a NPC field as it can hold. 

What the Nescients sense of the world is the value (the sum of all the points in a composition) of a unit and some vagaries of the point distribution. If a unit strikes or is struck by another unit more information about their composition is revealed. (Sorry, this is still in the hand wavy stages, but should be addressed in AI design.)

Given the above set of constrains my opinion is that braitenberg vehicles controlled by something like a GA/NN would be ideal for the Nescients and player-configurable GA-susceptible behavior trees would be ideal for the squad AI. Currently, I am writing the game in python with the intention of either using pypy or porting to C/C++ as required. Does the above seem like a reasonable course of action? is there an off-the-shelf player-configurable behavior tree system? Are there any recommendations for NN topographies? I have access to enough CPU to run games in the billions to train the AI and I am willing to wait for reasonable results. Any advice, pointers or coding assistance would be appreciated, thanks!",3,3
45,2012-5-18,2012,5,18,3,trzt6,"Not everyone understands us, but the machines sure will...",https://www.reddit.com/r/MachineLearning/comments/trzt6/not_everyone_understands_us_but_the_machines_sure/,jamintime,1337278657,,0,0
46,2012-5-18,2012,5,18,17,tt0kp,Robust PCA in Action / Boy Bands &amp; Football Fans: Algorithmic Discovery for Twitter,https://www.reddit.com/r/MachineLearning/comments/tt0kp/robust_pca_in_action_boy_bands_football_fans/,[deleted],1337329045,,0,14
47,2012-5-19,2012,5,19,4,tto95,Another use of Count-Min Sketch: Particle Sketches,https://www.reddit.com/r/MachineLearning/comments/tto95/another_use_of_countmin_sketch_particle_sketches/,[deleted],1337368603,,0,8
48,2012-5-20,2012,5,20,6,tv5f8,"GraphLab Workshop (Monday, July 9, 2012, San Francisco, CA). GraphLab is a competitor to Map/Reduce-Hadoop",https://www.reddit.com/r/MachineLearning/comments/tv5f8/graphlab_workshop_monday_july_9_2012_san/,[deleted],1337461716,,3,22
49,2012-5-20,2012,5,20,10,tvewb,Just saw John Langford present at STOC,https://www.reddit.com/r/MachineLearning/comments/tvewb/just_saw_john_langford_present_at_stoc/,cypherx,1337476063,,0,0
50,2012-5-20,2012,5,20,10,tvgac,Any movielens equivalent dataset in portuguese (brazilian portuguese) ?,https://www.reddit.com/r/MachineLearning/comments/tvgac/any_movielens_equivalent_dataset_in_portuguese/,tunabr,1337478287,"I've been trying to create a corpus to reproduce sentiment based analysis on brazilian portuguese text, but the hardest part is to find out a corpus like movielens (review + score). Any suggestions ? The corpora that I've been looking for (like floresta) is more geared towards linguistics.",0,1
51,2012-5-21,2012,5,21,2,tw6e6,Modeling Surprise,https://www.reddit.com/r/MachineLearning/comments/tw6e6/modeling_surprise/,szza,1337534648,,0,12
52,2012-5-21,2012,5,21,8,twnm7,Markov Chain Monte Carlo and the Eurovision Song Contest,https://www.reddit.com/r/MachineLearning/comments/twnm7/markov_chain_monte_carlo_and_the_eurovision_song/,[deleted],1337557213,,0,1
53,2012-5-21,2012,5,21,10,twt9g,Markov Chain Monte Carlo and the Eurovision Song Contest,https://www.reddit.com/r/MachineLearning/comments/twt9g/markov_chain_monte_carlo_and_the_eurovision_song/,mewo2,1337564332,,5,62
54,2012-5-21,2012,5,21,23,txijd,Reference Pages in Machine Learning and Related Fields.,https://www.reddit.com/r/MachineLearning/comments/txijd/reference_pages_in_machine_learning_and_related/,[deleted],1337609626,"I am trying to compile a list of pages dedicated to specific topics within Machine Learning and related fields. Below is a list of pages curated by specialists that are not focused on one paper or one research group but rather on techniques and how these techniques have come about and how they are being used by different groups. I am sure I am missing some and look forward to any addition.

* [Superlinear Indexes](http://www.superlinearindexes.org/home)
* [Count-Min Sketches and Applications](https://sites.google.com/site/countminsketch/home)
* [Compressive Sensing: The Big Picture](https://sites.google.com/site/igorcarron2/cs)
* [Advanced Matrix Factorization Jungle](https://sites.google.com/site/igorcarron2/matrixfactorizations)
* [The LASSO page](http://www-stat.stanford.edu/~tibs/lasso.html)
* [Recommender Systems: wiki](http://recsyswiki.com/wiki/Main_Page)
* [The sparse- and low-rank solver wiki]
(http://www.ugcs.caltech.edu/~srbecker/wiki/Main_Page)",1,10
55,2012-5-22,2012,5,22,0,txlhw,Papers on negative transfer of learning in ML?,https://www.reddit.com/r/MachineLearning/comments/txlhw/papers_on_negative_transfer_of_learning_in_ml/,[deleted],1337613723,"As my title suggests, I'd like to get insights to negative transfer of learning studies. There are plenty of positive learning reports, but so far I couldn't really find any comprehensive/descriptive paper on ToL-failure.",0,1
56,2012-5-22,2012,5,22,0,txmsk,"Splines, RBFs and kernel regression - clarification?",https://www.reddit.com/r/MachineLearning/comments/txmsk/splines_rbfs_and_kernel_regression_clarification/,dr_chickolas,1337615347,"I have been reading about splines recently, as well as radial basis functions (RBFs) and kernel regression (local-linear, for example).

I wonder if someone could clarify for me. I am trying to decide on the difference between these terms. As far as I can see, ""kernel regression"" typically refers to local mean or local linear regression, where the influence of each training point is controlled by a kernel function, such as a Gaussian, centred on that point.

A RBF is a basis function that is a function of the distance from its centre point. So, a RBF can be used as a kernel for local-mean or local-linear kernel regression. In this sense, RBF networks are just a particular type of ""kernel regression"" (since there is no requirement for kernel regression to necessarily use RBFs as kernel functions).

Last, splines use polynomial basis functions, which are zero below their origin, so they are asymmetric (in contrast to RBFs and usually to kernel regression). Additionally, they are usually ""penalised"", which means that the coefficients of the basis functions are ""encouraged"" not to be too high. This is equivalent to minimising the sum of squared error and the roughness penalty.

So in summary, RBFs can be used in kernel regression, either in a local-mean or local-linear (or other) context. Splines use the same idea of linear combinations of basis functions, but the basis functions are non-symmetric. They are also usually penalised.

Can anyone comment on how (in)correct this is? Am I barking up the wrong tree? Also if anyone has any opinions on the superiority of one over another (bearing in mind I am doing 1D scatterplot smoothing), they would be very welcome. Thanks.",3,3
57,2012-5-22,2012,5,22,1,txnwi,Can someone explain the Natural Actor Critic algorithm to me in simpler terms?,https://www.reddit.com/r/MachineLearning/comments/txnwi/can_someone_explain_the_natural_actor_critic/,Ruzihm,1337616706,"Paper here: http://homepages.inf.ed.ac.uk/svijayak/publications/peters-ECML2005.pdf

I think I would have an easier time understanding the jargon and math involved if I had a high-level explanation of the process. Can anyone help me out with this? :)",3,3
58,2012-5-22,2012,5,22,1,txofc,Is There Big Money in Big Data? - Technology Review,https://www.reddit.com/r/MachineLearning/comments/txofc/is_there_big_money_in_big_data_technology_review/,postliterate,1337617388,,36,21
59,2012-5-22,2012,5,22,5,ty1ta,The Simple Gibbs example in Julia,https://www.reddit.com/r/MachineLearning/comments/ty1ta/the_simple_gibbs_example_in_julia/,talgalili,1337632337,,0,1
60,2012-5-23,2012,5,23,1,tzfvc,From words to concepts and back again...,https://www.reddit.com/r/MachineLearning/comments/tzfvc/from_words_to_concepts_and_back_again/,RevBooyah,1337704080,,2,12
61,2012-5-23,2012,5,23,6,tzwrk,Quick question about academia and machine learning.,https://www.reddit.com/r/MachineLearning/comments/tzwrk/quick_question_about_academia_and_machine_learning/,cyborgbrain,1337722304,"Hey guys, I am a current high school junior preparing to apply for different colleges. I want to eventually do a PhD in machine learning and do ml research. I took stanford's ML class and am currently going through some textbooks I found online. Given this, I am certain that I want to do ML.

Should I apply for colleges as a Statistics BS or Computer Science BS?",25,2
62,2012-5-23,2012,5,23,8,u0339,Opinion: Depth sensors and machine learning are under-utilized scientific tools (written for a class),https://www.reddit.com/r/MachineLearning/comments/u0339/opinion_depth_sensors_and_machine_learning_are/,mgsloan,1337729423,,10,7
63,2012-5-23,2012,5,23,17,u0r0c,An update on Eurovision,https://www.reddit.com/r/MachineLearning/comments/u0r0c/an_update_on_eurovision/,amair,1337761610,,1,39
64,2012-5-23,2012,5,23,18,u0s4c,Can better data keep students from dropping out of college?,https://www.reddit.com/r/MachineLearning/comments/u0s4c/can_better_data_keep_students_from_dropping_out/,[deleted],1337765394,,0,1
65,2012-5-24,2012,5,24,19,u2k0w,"Need your input on the topic ""Neural Networks in different programming languages""",https://www.reddit.com/r/MachineLearning/comments/u2k0w/need_your_input_on_the_topic_neural_networks_in/,lvomrm,1337854704,"Hi

I'm thinking about writing my thesis about the advantages and disadvantages of several programming languages when building neural networks.

I'm quite early in my planing and don't have a lot of knowledge right now, but I'm getting there, so please be gentle ;) . (I'm playing around with **PyBrain** right now, let's see how that goes)

I am wondering now:

* is this topic realistic (are there just too many languages to consider and is it too much work to get done in one semester)

* is it ""new"" (or are there already a lot of papers on the matter which I haven't found until now)

* is it a stupid topic (because there are already languages/librarys that are focussing on that task)

P.S.: Also posted this in [/r/compsci](http://www.reddit.com/r/compsci/comments/u2j5p/need_your_input_on_the_topic_neural_networks_in/), hope to get different angles that way.

_______________________________________________________________________
Update: I wrote the professor about the Idea and he told me that it would be possible to try to design a NN-language, so it's similar to the Idea someone had further down. The Prof considered haskell, as it already has a library to deal with graphs (which NN are). But I think he does not know about the specialized NN-Modules/Libraries which already exist. I will try to teach myself about existing languages over the weekend and try to decide if this is something I would want to do.",43,3
66,2012-5-25,2012,5,25,1,u2z9j,Need to create something like bigml for inhouse use in a mid-sized company,https://www.reddit.com/r/MachineLearning/comments/u2z9j/need_to_create_something_like_bigml_for_inhouse/,Exibus,1337878044,"Company where I happen to work operate several niche social networks, social network games, etc. I was tasked to create simple prediction and clustering API for in house use. Where should I start? Is there a good library which I could just write a wrapper for starters? Sure I will add specific features later but for now I just need something that somehow works...

In terms of size so far the biggest dataset is a few millions of rows with tag-like features.
Also we have a few netflix like users' votes matrices which are smaller in size (about 100k users and 10k items or something like that). 


To clarify even more basically we have three tasks: 

1. recommend items to users 

2. recommend users to users

3. cluster users for further analysis.  ",6,7
67,2012-5-25,2012,5,25,14,u42i3,"Final Eurovision predictions, and what to watch for in the voting",https://www.reddit.com/r/MachineLearning/comments/u42i3/final_eurovision_predictions_and_what_to_watch/,[deleted],1337924193,,0,1
68,2012-5-25,2012,5,25,14,u42iy,"Final Eurovision predictions, and what to watch for in the voting",https://www.reddit.com/r/MachineLearning/comments/u42iy/final_eurovision_predictions_and_what_to_watch/,mewo2,1337924226,,0,47
69,2012-5-28,2012,5,28,6,u7qc2,"Eurovision statistics: post-game analysis, and an apology to the people of Malta",https://www.reddit.com/r/MachineLearning/comments/u7qc2/eurovision_statistics_postgame_analysis_and_an/,mewo2,1338152969,,2,32
70,2012-5-28,2012,5,28,9,u7zba,"[noob]: Creating preferences list with ""not always correct"" features",https://www.reddit.com/r/MachineLearning/comments/u7zba/noob_creating_preferences_list_with_not_always/,bpger1,1338165663,"I have the following problem:
- A set of 10 classes (for example: dogs, cats, rabbits,...)
- A set of 1000 items (pictures of these animals)
- For every item I have its class (is it a dog picture, or a cat picture, or a rabbit picture)
- There is a 30% chance that the associated class for an item is wrong  (for example: a dog picture we think is cat)
- All items have counter how many people clicked on them

I show to a user 7 pictures, and after he clicks on some, i should update his profile in order to show him better pictures next time.
My current approach is to define a float per category for every user, and use that float in ranking 1000 items. Choose top 7, and when he selects one, increase the number for that category, and decrease for others.
Any ideas on how to work with this?
Thanks!",9,5
71,2012-5-29,2012,5,29,11,u9nj6,Question: Computing similarity of useragents,https://www.reddit.com/r/MachineLearning/comments/u9nj6/question_computing_similarity_of_useragents/,rlayton,1338257480,"I'm writing a program, and part of that program aims to detect if two computers connecting to a website are the same. *Part of that* function uses the useragent strings. I want to build a function that takes two useragents as input and returns an output of value between 0 and 1, where 0 is ""no similarity"" and 1 is ""exactly the same"".

I'm currently just tokenising the useragents and returning the Jaccard similarity (size of intersection divided by size of union of the two sets). Is there a better way? The goal is that the same browser will show with a high similartiy, particularly if something upgrades (i.e. IE8.0 gets upgraded to IE9.0).

An idea I had was to learn a the Baye's probabilities for transitions (i.e. upgrades have a high probability, downgrades a low probability) and use that to calculate an overall probability for the two user-agents being generated by the same browser. If there is a simpler method though, I'd love to hear it.",5,5
72,2012-5-30,2012,5,30,2,uamgk,"Remote sources, tagging, and tree filtering for BigML",https://www.reddit.com/r/MachineLearning/comments/uamgk/remote_sources_tagging_and_tree_filtering_for/,jjdonald,1338313337,,1,0
73,2012-5-30,2012,5,30,5,uau34,Robot gripper teaches itself how to pick up different shaped objects,https://www.reddit.com/r/MachineLearning/comments/uau34/robot_gripper_teaches_itself_how_to_pick_up/,[deleted],1338321811,,0,1
74,2012-5-31,2012,5,31,7,ucvqc,Where can I find internships?,https://www.reddit.com/r/MachineLearning/comments/ucvqc/where_can_i_find_internships/,cyborgbrain,1338418753,"I was looking for internships somehow related to machine learning. The problem is that I am a high school student and most are asking for undergrads.

I was wondering if there is any company willing to let me intern there or if there are professors or grad students willing to let me shadow them and help them out. The other problem is that I am in the Northern VA Area and there aren't very many startups in this area.

So I was wondering, are there any companies in the Greater DC area that may be willing to let a motivated high schooler intern there?",15,7
75,2012-5-31,2012,5,31,9,ud1o3,How to tell if SVM classification is good enough?,https://www.reddit.com/r/MachineLearning/comments/ud1o3/how_to_tell_if_svm_classification_is_good_enough/,science_robot,1338425681,"I'm using Support Vector Machines to predict sample treatment status.

144 data points. Leaving out 50 for validation, I get a 25% false-classification.

Is this ""good"" or ""bad""? Is there even such a thing?",0,1
76,2012-5-31,2012,5,31,10,ud2h3,Mixture of Gaussians with TFIDF sparse vectors,https://www.reddit.com/r/MachineLearning/comments/ud2h3/mixture_of_gaussians_with_tfidf_sparse_vectors/,ColonelHapablap,1338426535,"Hi guys,

I'm a complete newbie when it comes to Machine Learning (and CS in general, I've only had 2 semesters worth of courses).  I'm trying to write an algorithm for document classification for an internship and I'm feeling out of my league.  

Right now I've got approximately 2000 documents I need to classify and that number is expected to grow over time.  I've got tfidf weightings for each documents, so right now I'm trying to write a Mixture of Gaussians mixture model using the sparse vectors of each documents tfidf weighting (right now there are about 44000 unique words after normalization, so that's how many dimensions I've got).

Things seem to be blowing up, though--I can't reasonably computer a 44000*44000 covariance matrix for each gaussian per iteration, so I'm just doing diagonal matrices (the variance of each term).  But then the variance turns out to be so small that when its time for doing the exp() part of this function: http://en.wikipedia.org/wiki/Multivariate_normal_distribution#Non-degenerate_case,
 multiplying by the inverse eventually makes the resulting scalar too huge to compute.  Right now I'm trying to standardize my ifidf scores by subtracting the mean and dividing by the standard deviation, but that hasn't seemed to help with the resulting scalar size. 

I really don't know what I'm doing.  Is MoG the wrong approach to this?  Apparently LDA is the best thing for this sort of thing, but from what I understand that would definitely be out of my league.

I guess don't know what I'm asking, exactly, but if anyone could provide some insight as how I'm approaching this incorrectly or what might be a better strategy, I would really appreciate it.",14,6
77,2012-5-31,2012,5,31,11,ud752,Structure and Overlaps of Communities in Networks,https://www.reddit.com/r/MachineLearning/comments/ud752/structure_and_overlaps_of_communities_in_networks/,imbenzene,1338431668,,0,1
78,2012-5-31,2012,5,31,18,udmrd,Advice for masters ML dissertation project,https://www.reddit.com/r/MachineLearning/comments/udmrd/advice_for_masters_ml_dissertation_project/,unsymbol,1338455912,"I've just completed my first year of an AI-based masters programme (I'm a part-time student) and I'm beginning to think about my dissertation project that will be done in year two. Of all classes this year, both machine learning and natural language processing stood out and were the most interesting.

However, my BA is in music and switching to a CS programme has been a steep, but rewarding, learning curve. As a result, I'm not sure of areas most worthy of further research at this point.

Ideally, I'd like to work on a project focussed around music and machine learning but I'd welcome an advice of things to tackle. Any tips, areas of investigation, possible project suggestions?",15,14
