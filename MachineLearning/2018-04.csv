,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-4-1,2018,4,1,10,88ncat,How would you go about building a model that could generate text based on a user defined topic?,https://www.reddit.com/r/MachineLearning/comments/88ncat/how_would_you_go_about_building_a_model_that/,madzthakz,1522546139,[removed],0,1
1,2018-4-1,2018,4,1,12,88nxnl,Tensor flow tutorials,https://www.reddit.com/r/MachineLearning/comments/88nxnl/tensor_flow_tutorials/,Wajeehrehman,1522552463,[removed],0,1
2,2018-4-1,2018,4,1,13,88o922,[N] Introducing TensorFlow Hub: A Library for Reusable Machine Learning Modules in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/88o922/n_introducing_tensorflow_hub_a_library_for/,yourSAS,1522555880,,9,293
3,2018-4-1,2018,4,1,13,88ofv0,Cost of interpretability in a model,https://www.reddit.com/r/MachineLearning/comments/88ofv0/cost_of_interpretability_in_a_model/,the_great_magician,1522557897,[removed],0,1
4,2018-4-1,2018,4,1,13,88ogsr,[P] mms2text: Let your computer look at your message pics so you dont have to,https://www.reddit.com/r/MachineLearning/comments/88ogsr/p_mms2text_let_your_computer_look_at_your_message/,zitterbewegung,1522558219,,0,1
5,2018-4-1,2018,4,1,14,88okx6,Question on Adam optimization,https://www.reddit.com/r/MachineLearning/comments/88okx6/question_on_adam_optimization/,[deleted],1522559484,,0,1
6,2018-4-1,2018,4,1,14,88ol1h,[D] Clarification on Adam optimization,https://www.reddit.com/r/MachineLearning/comments/88ol1h/d_clarification_on_adam_optimization/,ConfuciusBateman,1522559529,"I'm looking into Adam right now and want to make sure I'm understanding things correctly.

In the paper, it says that the 1st and 2nd moment ""vectors"" are initialized to 0 - are these actually matrices in most implementations, with an entry for each weight or bias parameter?

The reason I ask is that I have a matrix of weight gradients at a given layer, for example, so should I have an entry in the 1st and 2nd moment matrices for each weight? I'm trying to figure out if I need to store an additional matrix for these moment values to be used in the updates (and maybe even an additional two matrices for the bias-corrected moment estimates?) If this is the case, would updates for a given weight use its corresponding entries in the other matrices? Thanks in advance for any clarification.
",7,3
7,2018-4-1,2018,4,1,14,88olsz,Searching for a technical cofounder with a background in visual machine learning.,https://www.reddit.com/r/MachineLearning/comments/88olsz/searching_for_a_technical_cofounder_with_a/,vastwav3,1522559759,[removed],0,1
8,2018-4-1,2018,4,1,15,88ou84,Andrew Ng's Deep Learning Specialization: A Course-by-Course Review,https://www.reddit.com/r/MachineLearning/comments/88ou84/andrew_ngs_deep_learning_specialization_a/,wasabihater,1522562545,,0,1
9,2018-4-1,2018,4,1,15,88ozuw,[P] Minimalist and dependency-free deep learning using caffe64.s,https://www.reddit.com/r/MachineLearning/comments/88ozuw/p_minimalist_and_dependencyfree_deep_learning/,rvonwoofles,1522564581,,7,11
10,2018-4-1,2018,4,1,15,88p1gc,[D] Stabilizing Training of GANs Intuitive Introduction with Kevin Roth (ETH Zurich),https://www.reddit.com/r/MachineLearning/comments/88p1gc/d_stabilizing_training_of_gans_intuitive/,alexmlamb,1522565215,,4,50
11,2018-4-1,2018,4,1,16,88p5qn,WARNING with April fools!,https://www.reddit.com/r/MachineLearning/comments/88p5qn/warning_with_april_fools/,YetAnotherTuring,1522566814,[removed],0,1
12,2018-4-1,2018,4,1,16,88p7kr,Deep Learning Graphics Card,https://www.reddit.com/r/MachineLearning/comments/88p7kr/deep_learning_graphics_card/,dewayneroyj,1522567524,[removed],0,1
13,2018-4-1,2018,4,1,16,88pbn7,[D] Image captioning using GANs?,https://www.reddit.com/r/MachineLearning/comments/88pbn7/d_image_captioning_using_gans/,cbsudux,1522569156,"Suggestions for approaches to Image Captioning using GANs?
Thanks!",2,2
14,2018-4-1,2018,4,1,17,88ph0g,[R] A Course in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/88ph0g/r_a_course_in_machine_learning/,liranbh,1522571397,,0,10
15,2018-4-1,2018,4,1,17,88pi3p,Inference big fuzz,https://www.reddit.com/r/MachineLearning/comments/88pi3p/inference_big_fuzz/,c2Na7X8a,1522571845,[removed],0,1
16,2018-4-1,2018,4,1,17,88pjvd,[R] Introduction to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/88pjvd/r_introduction_to_machine_learning/,liranbh,1522572642,,1,0
17,2018-4-1,2018,4,1,18,88pt70,20+ Best Resources To Learn and Start Career In AI and ML,https://www.reddit.com/r/MachineLearning/comments/88pt70/20_best_resources_to_learn_and_start_career_in_ai/,say2neeraj,1522576675,,0,1
18,2018-4-1,2018,4,1,19,88q1qd,On-line Machine learning tools,https://www.reddit.com/r/MachineLearning/comments/88q1qd/online_machine_learning_tools/,KroosKontroller,1522580167,[removed],0,1
19,2018-4-1,2018,4,1,20,88q6v8,[Discussion]Is NVIDIA lying?,https://www.reddit.com/r/MachineLearning/comments/88q6v8/discussionis_nvidia_lying/,[deleted],1522582171,[deleted],0,1
20,2018-4-1,2018,4,1,20,88q8p3,[D] Is NVIDIA lying?,https://www.reddit.com/r/MachineLearning/comments/88q8p3/d_is_nvidia_lying/,svaisakh,1522582910,"While we're all thankful for NVIDIA and their awesome GPUs for accelerating this phase of deep learning revolution that has sparked tremendous interest in AI, I wonder about their more recent releases.

Specifically, TensorCore.

Are there any frameworks that leverage them?

Could there ever be?

Won't fp16 compromise performance?

Haven't newer architectures moved beyond dense layers and matrix multiplication that these TensorCores try to do?

If there is no practical use, then why does NVIDIA continue to put it up on a pedestal?

The new DGX-2 is supposedly a ""2-petaFLOPS GPU"".

As far as I can see from all real-world benchmarks, the V100 (or it's consumer equivalent Titan V) is ~30-40% faster than the 1080Ti.

If so, that puts the V100 at not more than 16 TFlops and hence, the DGX-2 at a maximum of 256 TFlops.

That's fast.

But it ain't ""2-petaFLOPS GPU"" fast!

Why the miscommunication?

Is NVIDIA lying?",26,0
21,2018-4-1,2018,4,1,22,88qr5t,Something doesnt sound right. on SoundCloud - Hear the worlds soundsww,https://www.reddit.com/r/MachineLearning/comments/88qr5t/something_doesnt_sound_right_on_soundcloud_hear/,artse_,1522589060,,0,1
22,2018-4-1,2018,4,1,23,88qz3g,"A Simple, Beginners Guide to Machine Learning Algorithms",https://www.reddit.com/r/MachineLearning/comments/88qz3g/a_simple_beginners_guide_to_machine_learning/,analyticsinsight,1522591341,,0,1
23,2018-4-1,2018,4,1,23,88r081,ANN Python Visualizer,https://www.reddit.com/r/MachineLearning/comments/88r081/ann_python_visualizer/,[deleted],1522591612,[deleted],0,1
24,2018-4-1,2018,4,1,23,88r3ts,[P] ANN Python Visualizer,https://www.reddit.com/r/MachineLearning/comments/88r3ts/p_ann_python_visualizer/,Tudor_Gheorghiu,1522592505,,17,130
25,2018-4-1,2018,4,1,23,88r8yk,[D] Is there a proof for the local minimum found by gradient-based learning in deep learning will be close to the global minimum?,https://www.reddit.com/r/MachineLearning/comments/88r8yk/d_is_there_a_proof_for_the_local_minimum_found_by/,newperson77777777,1522593791,,18,10
26,2018-4-2,2018,4,2,1,88s6zn,(Reminder) 1 Week Remaining to Get Humble Book Bundle: Makerspace by No Starch Press . (Partner),https://www.reddit.com/r/MachineLearning/comments/88s6zn/reminder_1_week_remaining_to_get_humble_book/,tyui60003,1522601667,,2,1
27,2018-4-2,2018,4,2,3,88sr7i,Where to start? Machine Learning for Robotics,https://www.reddit.com/r/MachineLearning/comments/88sr7i/where_to_start_machine_learning_for_robotics/,hot_soft_pretzel,1522606211,[removed],0,1
28,2018-4-2,2018,4,2,4,88t5yj,[D] Ist there a Dataset for beautiful/ugly?,https://www.reddit.com/r/MachineLearning/comments/88t5yj/d_ist_there_a_dataset_for_beautifulugly/,fimari,1522609547,"And if not, any good ideas how to create one? I would love to see how a generative network generated beautiful pictures and how beautiful they are for humans and then use this data to train the network again and then see how beautiful the result is goto 10.

Maybe we discover what beauty really is ;-)",11,0
29,2018-4-2,2018,4,2,4,88tfxf,Any tools for visualizing Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/88tfxf/any_tools_for_visualizing_neural_networks/,ispeakdatruf,1522611860,[removed],0,1
30,2018-4-2,2018,4,2,4,88tg38,SQL: Creating Tables and Inserting Values (Walkthrough!),https://www.reddit.com/r/MachineLearning/comments/88tg38/sql_creating_tables_and_inserting_values/,AnalystRisingTuts,1522611900,,0,1
31,2018-4-2,2018,4,2,5,88tofi,Linked Word,https://www.reddit.com/r/MachineLearning/comments/88tofi/linked_word/,umarni,1522613842,[removed],0,1
32,2018-4-2,2018,4,2,5,88txkb,Help on implementation of a CNN application on FPGA,https://www.reddit.com/r/MachineLearning/comments/88txkb/help_on_implementation_of_a_cnn_application_on/,spookyboogy22,1522616091,[removed],0,1
33,2018-4-2,2018,4,2,6,88u2eu,"French president: ""Too many white males in AI""",https://www.reddit.com/r/MachineLearning/comments/88u2eu/french_president_too_many_white_males_in_ai/,SVFomin,1522617209,,0,1
34,2018-4-2,2018,4,2,6,88u7n4,[R] Time Series Analysis via Matrix Estimation,https://www.reddit.com/r/MachineLearning/comments/88u7n4/r_time_series_analysis_via_matrix_estimation/,unnamedn00b,1522618466,,16,59
35,2018-4-2,2018,4,2,8,88uv5o,[D] Anyone else hear back from the /r/MachineLearning AI residency program?,https://www.reddit.com/r/MachineLearning/comments/88uv5o/d_anyone_else_hear_back_from_the_rmachinelearning/,DisastrousProgrammer,1522624242,I have my finger crossed!,10,35
36,2018-4-2,2018,4,2,8,88uxxb,"[P] Label Detection using REST API, I'd like Reddit to use it first!",https://www.reddit.com/r/MachineLearning/comments/88uxxb/p_label_detection_using_rest_api_id_like_reddit/,Roots91,1522624911,"I just finished building a project where developers and businesses can use it to understand the content of an image. The project is in limited preview stage and i would really appreciate if you could use the service and give some **feedback**.

* **Label Detection** - Detect broad sets of categories within an image.
* **No credit card needed**, it's free (and always will be).
* To use the REST API from command line, you can use **cURL**.


**How to use it (Using cURL)**: You can use test credentials. You send a POST request with an image ~~or video~~, and you get the tags
   
     curl -u vinayakpahalwan:vinayak12345 -F ""file=@&lt;your-image-path&gt;"" https://7e49cd7b.ngrok.io

*Example*:

     curl -u vinayakpahalwan:vinayak12345 -F ""file=@/Users/vinayakpahalwan/Desktop/demo.jpg"" https://7e49cd7b.ngrok.io

**Future Updates**:

* Face Detection - Detect multiple faces in an image.
* Explicit Content Detection - Detect explicit content in an image.

---------------------------------------
Server: ~~Online~~ **Offline**",5,14
37,2018-4-2,2018,4,2,9,88v82a,MemGEN: Memory is All You Need,https://www.reddit.com/r/MachineLearning/comments/88v82a/memgen_memory_is_all_you_need/,kkurach,1522627527,,0,1
38,2018-4-2,2018,4,2,10,88vmqu,WaveNet TTS: A plugin that reads out loud any text with natural sounding voices. SUPER EASY.,https://www.reddit.com/r/MachineLearning/comments/88vmqu/wavenet_tts_a_plugin_that_reads_out_loud_any_text/,[deleted],1522631364,[deleted],0,1
39,2018-4-2,2018,4,2,10,88vxyv,[P] WaveNet TTS: A plugin that reads out loud any text with natural sounding voices. SUPER EASY.,https://www.reddit.com/r/MachineLearning/comments/88vxyv/p_wavenet_tts_a_plugin_that_reads_out_loud_any/,0b01,1522634369,,3,2
40,2018-4-2,2018,4,2,11,88w77w,"If you had a $500 stipend (from work) for data science/machine learning continuing education, what would you spend it on?",https://www.reddit.com/r/MachineLearning/comments/88w77w/if_you_had_a_500_stipend_from_work_for_data/,Adi_2000,1522636899,[removed],0,1
41,2018-4-2,2018,4,2,12,88wdry,Google Collab notebook for an introduction to Mixture Density Networks (uses Tensorflow eager).,https://www.reddit.com/r/MachineLearning/comments/88wdry/google_collab_notebook_for_an_introduction_to/,agi_is_coming,1522638763,,0,1
42,2018-4-2,2018,4,2,12,88wgvs,Is there a whatsapp group to easily ask questions regarding machine learning?,https://www.reddit.com/r/MachineLearning/comments/88wgvs/is_there_a_whatsapp_group_to_easily_ask_questions/,Aad1tya23,1522639666,[removed],0,1
43,2018-4-2,2018,4,2,13,88wnqr,Question regarding satellite image semantic segmentation,https://www.reddit.com/r/MachineLearning/comments/88wnqr/question_regarding_satellite_image_semantic/,[deleted],1522641759,,0,1
44,2018-4-2,2018,4,2,13,88wqjp,[D] Question regarding satellite image semantic segmentation,https://www.reddit.com/r/MachineLearning/comments/88wqjp/d_question_regarding_satellite_image_semantic/,lifeadvicesponge,1522642601,"Hello r/machinelearning

I wanted to know about the state of the art on satellite image segmentation.   

Last year Kaggle organised a contest called [DSTL Satellite Image Feature Detection](https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection) and I went through the blog posts of the 1st, 3rd and 4th placed solutions :  

* [1st place solution](http://blog.kaggle.com/2017/04/26/dstl-satellite-imagery-competition-1st-place-winners-interview-kyle-lee/)
* [3nd place solution](http://blog.kaggle.com/2017/05/09/dstl-satellite-imagery-competition-3rd-place-winners-interview-vladimir-sergey/)
* [4th place solution](https://blog.deepsense.ai/deep-learning-for-satellite-imagery-via-image-segmentation/)  

This year Spacenet organised another similar challenge called [Spacenet Road Detection and Routing Challenge](https://spacenetchallenge.github.io/Competitions/Competition3.html) and I went through a couple of blog posts about that as well :
   
* [1st place solution](https://i.ho.lc/winning-solution-for-the-spacenet-challenge-joint-learning-with-openstreetmap.html)
* [NVIDIA official blog](https://devblogs.nvidia.com/solving-spacenet-road-detection-challenge-deep-learning/)   

When you go through the solutions you will find that almost all of them use U-Nets with different augmentation techniques. Here are a couple summary blog posts on natural image segmentation approaches : 

* [A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN](https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4) 
* [A 2017 Guide to Semantic Segmentation with Deep Learning](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review)  

I was wondering why people are not using approaches which have been more successful than U-Nets for natural images like DeepLab, Mask R-CNN or Tiramisu (the NVIDIA blog post uses it). Is it because of the the time taken for these approaches is too large for satellite images or convergence issues. I would love for someone with insight into this to help me out here.   

[DeepGlobe](http://deepglobe.org/) is organising  similar challenges as the above two as a part of their workshop at CVPR 18 and I was looking at models to use in order to participate. ",9,12
45,2018-4-2,2018,4,2,13,88wqtp,[P] Washington University Course T81-558: Applications of Deep Neural Networks (with Jupyter notebooks),https://www.reddit.com/r/MachineLearning/comments/88wqtp/p_washington_university_course_t81558/,SupraluminalShift,1522642697,,5,88
46,2018-4-2,2018,4,2,13,88wr66,[N] TensorflowJS - machine learning in javascript. Tensorflow dev summit 2018,https://www.reddit.com/r/MachineLearning/comments/88wr66/n_tensorflowjs_machine_learning_in_javascript/,helixb,1522642812,,30,220
47,2018-4-2,2018,4,2,13,88wsxb,[R] Interpretation of plots for outlier detection in healthcare,https://www.reddit.com/r/MachineLearning/comments/88wsxb/r_interpretation_of_plots_for_outlier_detection/,red-baton-ant,1522643394,"Christy et al. propose cluster-based approach to outlier detection as part of the preprocessing step. However, I don't think the plots are very interpretable. The authors use the R mclustbic function to determine BIC at different cluster sizes using GMMs - what is this supposed to show? 

I would think the plots are designed to illustrate effectiveness of their outlier detection methods, but this fact is not obvious to me. 

Thoughts on this?

[link to paper](https://www.sciencedirect.com/science/article/pii/S1877050915005591)",0,8
48,2018-4-2,2018,4,2,13,88wt84,"Sensors and machine learning: How applications can see, hear, feel, smell, and",https://www.reddit.com/r/MachineLearning/comments/88wt84/sensors_and_machine_learning_how_applications_can/,anonwipq,1522643499,,0,1
49,2018-4-2,2018,4,2,15,88xayh,This is cool!,https://www.reddit.com/r/MachineLearning/comments/88xayh/this_is_cool/,n_unjum,1522649731,,0,1
50,2018-4-2,2018,4,2,15,88xdrm,Which reinforcement algorithm is the most general to date?,https://www.reddit.com/r/MachineLearning/comments/88xdrm/which_reinforcement_algorithm_is_the_most_general/,mrconter1,1522650847,[removed],0,1
51,2018-4-2,2018,4,2,15,88xeva,Solve AI or Die Trying [Music Video],https://www.reddit.com/r/MachineLearning/comments/88xeva/solve_ai_or_die_trying_music_video/,funmaster11,1522651307,,0,1
52,2018-4-2,2018,4,2,16,88xkr9,[R] Stroke Controllable Fast Style Transfer (code and data for paper arxiv:1802.07101),https://www.reddit.com/r/MachineLearning/comments/88xkr9/r_stroke_controllable_fast_style_transfer_code/,YangLouie,1522653644,,1,1
53,2018-4-2,2018,4,2,17,88xs8u,Machine vision with a monocular camera and deep/extreme online learning?,https://www.reddit.com/r/MachineLearning/comments/88xs8u/machine_vision_with_a_monocular_camera_and/,astronaut971,1522656904,[removed],0,1
54,2018-4-2,2018,4,2,17,88xt33,10 Ethical Issues of Artificial Intelligence and Robotics,https://www.reddit.com/r/MachineLearning/comments/88xt33/10_ethical_issues_of_artificial_intelligence_and/,hoaphumanoid,1522657258,,0,1
55,2018-4-2,2018,4,2,17,88xu9f,How does Spatial Pyramid Pooling work on Windows instead of Images.,https://www.reddit.com/r/MachineLearning/comments/88xu9f/how_does_spatial_pyramid_pooling_work_on_windows/,JAGGI_JATT,1522657786,[removed],0,1
56,2018-4-2,2018,4,2,17,88xuw9,Dataset for face direction tracking of driver?,https://www.reddit.com/r/MachineLearning/comments/88xuw9/dataset_for_face_direction_tracking_of_driver/,psurya1994,1522658086,[removed],0,1
57,2018-4-2,2018,4,2,17,88xuwo,"Intelligent dating service, part of our university project.",https://www.reddit.com/r/MachineLearning/comments/88xuwo/intelligent_dating_service_part_of_our_university/,anythingfor_love,1522658093,[removed],0,1
58,2018-4-2,2018,4,2,17,88xvwe,Pytorch Installation help,https://www.reddit.com/r/MachineLearning/comments/88xvwe/pytorch_installation_help/,Bexirt,1522658538,[removed],0,1
59,2018-4-2,2018,4,2,17,88xxpk,[D] What is the correct strategy for training ConvNets where number of classes is not fixed?,https://www.reddit.com/r/MachineLearning/comments/88xxpk/d_what_is_the_correct_strategy_for_training/,maclearner,1522659358,"I am training a CNN for object retrieval, that is, training a classifier and then using an intermediate layer for feature extraction. However, in my problem statement, the number of classes has increased with time. I first fine-tuned a ResNet50 for 10 classes. Since more data has arrived, the number of classes has grown to 15. I retrained the network on 15 classes but the top-k results from the similarity search have become poor. 

What strategy do I use to train the ConvNet for 15 classes without degrading its performance on object retrieval? ",3,3
60,2018-4-2,2018,4,2,18,88y0rw,Hide human from Image - New facebook bot,https://www.reddit.com/r/MachineLearning/comments/88y0rw/hide_human_from_image_new_facebook_bot/,jam_shed,1522660565,[removed],0,1
61,2018-4-2,2018,4,2,18,88y23r,Isn't this NN model huge for a typical DRL paper?,https://www.reddit.com/r/MachineLearning/comments/88y23r/isnt_this_nn_model_huge_for_a_typical_drl_paper/,[deleted],1522661109,,0,1
62,2018-4-2,2018,4,2,18,88y3mp,[D] Is this NN architecture big for DRL?,https://www.reddit.com/r/MachineLearning/comments/88y3mp/d_is_this_nn_architecture_big_for_drl/,seann999,1522661720,"I'm going through the recent [SPIRAL paper](https://deepmind.com/documents/183/SPIRAL.pdf) (link goes directly to pdf) from DeepMind, and was surprised by how large the model is for one that is trained with RL.

I'm used to seeing RL networks consisting of a few layers (like 4?) of convolutions followed by a possible recurrent layer, a fully-connected layer, then the output layer.

However, the model in this paper is quite different. The input image, along with the previous action, is processed through a convolutional layer and a series of ResBlocks (8!). After a recurrent layer, each element of an action tuple is decoded one by one in an autoregressive fashion. So if it's outputting brush color, brush size, and brush location, there are 3 ""iterations"" . And when the output corresponds to a location (e.g. brush location) there are (again) 8 ResBlocks.

My best guess for choosing/being able to train such a large network is because the ""environment"" isn't so dynamic and unpredictable like typical game environments prominent in the DRL literature.

Is it normal to see these kinds of architectures in DRL? Am I behind the times? Or am I just reading this paper wrong?",1,4
63,2018-4-2,2018,4,2,19,88yba7,How is Machine Learning Helping Businesses Grow?,https://www.reddit.com/r/MachineLearning/comments/88yba7/how_is_machine_learning_helping_businesses_grow/,imarticus_nirmal,1522664773,,0,1
64,2018-4-2,2018,4,2,19,88yeaa,What are The Skills You Need to Become a Machine Learning Engineer?,https://www.reddit.com/r/MachineLearning/comments/88yeaa/what_are_the_skills_you_need_to_become_a_machine/,imarticus_nirmal,1522665972,,0,1
65,2018-4-2,2018,4,2,19,88yf6c,what's conceptually hard about ML? understanding the results and tweaking the model?,https://www.reddit.com/r/MachineLearning/comments/88yf6c/whats_conceptually_hard_about_ml_understanding/,erjcan,1522666311,[removed],0,1
66,2018-4-2,2018,4,2,19,88yfnw,Fast GPU Deep Learning for using an Adjacency Matrix. All layers procesed without leaving GPU. #MachineLearning #DeepLearning #GPU,https://www.reddit.com/r/MachineLearning/comments/88yfnw/fast_gpu_deep_learning_for_using_an_adjacency/,3droberto,1522666504,,0,1
67,2018-4-2,2018,4,2,20,88ylck,[R] How to Think About Machine Learning - Machine Learning Mastery,https://www.reddit.com/r/MachineLearning/comments/88ylck/r_how_to_think_about_machine_learning_machine/,polllyyy,1522668419,,0,1
68,2018-4-2,2018,4,2,20,88ylvn,[R] The Variational Autoencoder as a Two-Player Game  Part I,https://www.reddit.com/r/MachineLearning/comments/88ylvn/r_the_variational_autoencoder_as_a_twoplayer_game/,janemoz,1522668606,,0,1
69,2018-4-2,2018,4,2,20,88ym2k,Everything You Need To Know About Machine Learning and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/88ym2k/everything_you_need_to_know_about_machine/,imarticus_nirmal,1522668662,,0,1
70,2018-4-2,2018,4,2,20,88ymco,Instance Embedding: Segmentation Without Proposals  Bar Vinograd,https://www.reddit.com/r/MachineLearning/comments/88ymco/instance_embedding_segmentation_without_proposals/,[deleted],1522668747,[deleted],0,1
71,2018-4-2,2018,4,2,20,88ynp2,How did you get started with Deep Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/88ynp2/how_did_you_get_started_with_deep_reinforcement/,project_elAIne,1522669195,[removed],0,1
72,2018-4-2,2018,4,2,21,88yro0,Write code to implement Decision Tree. You have to print steps for every split in the decision tree.Can anyone help how do to it in python?,https://www.reddit.com/r/MachineLearning/comments/88yro0/write_code_to_implement_decision_tree_you_have_to/,anuraglahon,1522670485,[removed],0,1
73,2018-4-2,2018,4,2,21,88ysfb,Book/Reference Material Questions- Unsupervised Times Series,https://www.reddit.com/r/MachineLearning/comments/88ysfb/bookreference_material_questions_unsupervised/,Cjh411,1522670702,[removed],0,1
74,2018-4-2,2018,4,2,21,88yv08,[R] How Three Lines of Code and Windows Machine Learning Empower .NET Developers to Run AI Locally on Windows 10 Devices,https://www.reddit.com/r/MachineLearning/comments/88yv08/r_how_three_lines_of_code_and_windows_machine/,chris_shpak,1522671484,,0,1
75,2018-4-2,2018,4,2,21,88yy46,[N] How good is a certain soccer player? Let's find out applying Machine Learning to Fifa 18,https://www.reddit.com/r/MachineLearning/comments/88yy46/n_how_good_is_a_certain_soccer_player_lets_find/,molode,1522672356,,0,1
76,2018-4-2,2018,4,2,21,88yye1,Turmeric Powder Pouch Packing Machine,https://www.reddit.com/r/MachineLearning/comments/88yye1/turmeric_powder_pouch_packing_machine/,lgsherry,1522672428,,1,1
77,2018-4-2,2018,4,2,21,88z2gc,Machine Learning Platform for Data Analysis,https://www.reddit.com/r/MachineLearning/comments/88z2gc/machine_learning_platform_for_data_analysis/,[deleted],1522673570,[deleted],0,1
78,2018-4-2,2018,4,2,21,88z2y1,[R] Medical Image Segmentation [Part 1]  UNet: Convolutional Networks with Interactive Code,https://www.reddit.com/r/MachineLearning/comments/88z2y1/r_medical_image_segmentation_part_1_unet/,friscotime,1522673720,,0,1
79,2018-4-2,2018,4,2,21,88z3gc,[R] Machine Learning as a Service with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/88z3gc/r_machine_learning_as_a_service_with_tensorflow/,trumtra,1522673874,,0,1
80,2018-4-2,2018,4,2,22,88z4ix,[P] Machine Learning Platform for Data Analysis,https://www.reddit.com/r/MachineLearning/comments/88z4ix/p_machine_learning_platform_for_data_analysis/,mrshakirov,1522674192,,0,8
81,2018-4-2,2018,4,2,22,88z6iz,"[P] mlpack 3.0 released: a fast, flexible machine learning library",https://www.reddit.com/r/MachineLearning/comments/88z6iz/p_mlpack_30_released_a_fast_flexible_machine/,eusben,1522674702,,9,25
82,2018-4-2,2018,4,2,22,88zbf5,"Aiming to fill skill gaps in machine learning &amp; AI, Microsoft makes training courses available to the public",https://www.reddit.com/r/MachineLearning/comments/88zbf5/aiming_to_fill_skill_gaps_in_machine_learning_ai/,myinnerbanjo,1522675972,,0,1
83,2018-4-2,2018,4,2,22,88zg26,How to Approach Data: Tabular Data,https://www.reddit.com/r/MachineLearning/comments/88zg26/how_to_approach_data_tabular_data/,c0cky_,1522677152,,0,1
84,2018-4-2,2018,4,2,23,88zis2,Frozen French Fries Production Processing Line for Sale,https://www.reddit.com/r/MachineLearning/comments/88zis2/frozen_french_fries_production_processing_line/,gelserena,1522677815,,1,1
85,2018-4-2,2018,4,2,23,88zk7m,MScAC at UofT vs MSc at other univs (US and CA) for ML/AI: Please advice!,https://www.reddit.com/r/MachineLearning/comments/88zk7m/mscac_at_uoft_vs_msc_at_other_univs_us_and_ca_for/,WinPetrol,1522678155,,0,1
86,2018-4-2,2018,4,2,23,88zmf4,Cocoa Liquor Production Line|Cacao Bean Processing Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/88zmf4/cocoa_liquor_production_linecacao_bean_processing/,gelserena,1522678648,,1,1
87,2018-4-2,2018,4,2,23,88zo0r,MScAC at UofT vs MSc at other univs (US and CA) for ML/AI: Please advice!,https://www.reddit.com/r/MachineLearning/comments/88zo0r/mscac_at_uoft_vs_msc_at_other_univs_us_and_ca_for/,WinPetrol,1522679024,[removed],1,1
88,2018-4-2,2018,4,2,23,88zpb6,Top 9 Data Science Use Cases in Banking,https://www.reddit.com/r/MachineLearning/comments/88zpb6/top_9_data_science_use_cases_in_banking/,viktoriia_shulga,1522679307,,0,2
89,2018-4-2,2018,4,2,23,88zpe3,Check out the Pod as a Service [PODaaS] Podcast!,https://www.reddit.com/r/MachineLearning/comments/88zpe3/check_out_the_pod_as_a_service_podaas_podcast/,stephanieweb,1522679329,,0,1
90,2018-4-2,2018,4,2,23,88zrt1,[R] [1803.11373] Learning to generate classifiers,https://www.reddit.com/r/MachineLearning/comments/88zrt1/r_180311373_learning_to_generate_classifiers/,NichG,1522679867,,1,14
91,2018-4-2,2018,4,2,23,88zuk5,[D] Why do people publish to paywalled publications?,https://www.reddit.com/r/MachineLearning/comments/88zuk5/d_why_do_people_publish_to_paywalled_publications/,chris2point0,1522680492,Seems like a way to reach half the audience with little benefit.,21,35
92,2018-4-2,2018,4,2,23,88zvpu,Host Deep learning chat-bot.,https://www.reddit.com/r/MachineLearning/comments/88zvpu/host_deep_learning_chatbot/,dadwal_akshay,1522680767,[removed],0,1
93,2018-4-2,2018,4,2,23,88zxa4,Whats the most interesting applied Machine Learning problem you have worked on ?,https://www.reddit.com/r/MachineLearning/comments/88zxa4/whats_the_most_interesting_applied_machine/,[deleted],1522681117,,0,1
94,2018-4-3,2018,4,3,1,890fnl,Instance Embedding: Segmentation Without Proposals,https://www.reddit.com/r/MachineLearning/comments/890fnl/instance_embedding_segmentation_without_proposals/,[deleted],1522685063,[deleted],0,1
95,2018-4-3,2018,4,3,1,890gi0,[R] Instance Embedding: Segmentation Without Proposals,https://www.reddit.com/r/MachineLearning/comments/890gi0/r_instance_embedding_segmentation_without/,Bardelaz,1522685249,,0,6
96,2018-4-3,2018,4,3,1,890hzt,Project recommendations for a beginner,https://www.reddit.com/r/MachineLearning/comments/890hzt/project_recommendations_for_a_beginner/,theonlyrs10,1522685555,[removed],0,1
97,2018-4-3,2018,4,3,1,890i4n,[D] Combining Momentum and AdaGrad?,https://www.reddit.com/r/MachineLearning/comments/890i4n/d_combining_momentum_and_adagrad/,ConfuciusBateman,1522685582,"As the title says, I'm wondering if it can work to combine these two methods.

The implementation would look something like like: 
`v = friction*v_prev + (1-friction)*gradient`
`grad_history += v**2`
`adjusted_weight = v / sqrt(grad_history) + epsilon`
`weight = weight - step_size * adjusted_weight`

Does this make sense? At a surface level I don't see why this wouldn't work, it seems like the benefits of both methods would be preserved but if I'm wrong please let me know. Also, is Adadelta strictly preferred to AdaGrad, or is it more situational?
",3,5
98,2018-4-3,2018,4,3,1,890prh,"[R] ""MemGEN: Memory is All You Need."" Generative modeling solved. DeepMemory FTW",https://www.reddit.com/r/MachineLearning/comments/890prh/r_memgen_memory_is_all_you_need_generative/,kkurach,1522686590,,16,25
99,2018-4-3,2018,4,3,1,890s2y,How to convert pdf to xml,https://www.reddit.com/r/MachineLearning/comments/890s2y/how_to_convert_pdf_to_xml/,rakesherr,1522686938,[removed],0,1
100,2018-4-3,2018,4,3,1,890w17,Chinese CCTV company hikVision open source it's AI tech,https://www.reddit.com/r/MachineLearning/comments/890w17/chinese_cctv_company_hikvision_open_source_its_ai/,ScotchMonk,1522687379,,0,1
101,2018-4-3,2018,4,3,2,891btr,goo.gl/R9T623 Animated Story of #Kiva #Kaggle Sectorwise Fundings worldwide,https://www.reddit.com/r/MachineLearning/comments/891btr/googlr9t623_animated_story_of_kiva_kaggle/,poonamV,1522688613,,0,1
102,2018-4-3,2018,4,3,2,891o9s,Are recurrent neural networks still trained with backprop through time?,https://www.reddit.com/r/MachineLearning/comments/891o9s/are_recurrent_neural_networks_still_trained_with/,sdmskdlsadaslkd,1522689683,[removed],0,1
103,2018-4-3,2018,4,3,2,891rw3,[D] Sampling techniques for a skewed data set and approaches to analyze the predictive models,https://www.reddit.com/r/MachineLearning/comments/891rw3/d_sampling_techniques_for_a_skewed_data_set_and/,phreak121,1522690000,"I'm doing an undergrad project in which I compare the performance of various classification algorithms which are logistic regression, decision trees, and support vector machines. The data set I chose is the [credit card fraud](https://www.kaggle.com/mlg-ulb/creditcardfraud). At the end of the project I'll have to write a report explaining my whole project.

The sampling techniques I have investigated are under-sampling, over-sampling, SMOTE, and letting the algorithm do the class balancing itself.

The report has two sections. One explains how I tested the algorithms and the second is how I analyzed and compared the algorithms.

Q1. For under-sampling what I done first is to under-sample the original data, this gives me X_under and y_under. I then split the under-sampled data to get X_train_under, y_train_under, X_test_under and y_test_under. After that I split the original training set to get X_train, y_train, X_test and y_test.

I then train a classifier on the under-sampled data and then on the original data. When training and testing for the under-sampled data I would feed in X_train_under, y_train_under, X_test_under and y_test_under into the learning algorithm. When training and testing on the original data I would feed in X_train_under, y_train_under, X_test, y_test. The predictive accuracy of these two approaches were close to each other (around 93%). Afterwards I just feed in the skewed data which is X_train, y_train, X_test and y_test, the performance of this approach is not as accurate (around 64%).

I'm I doing the sampling technique correctly?

Q2. I'm kind of confused between the testing and the analysis/comparison of the algorithms. What I understand by testing the algorithms is that I would train the classifier and then I would **test** it on unseen data. Is this approach correct and what other approaches could I use?

For the analysis and comparison of the algorithms I would use metrics such as ROC, AUC, and confusion matrices to compare the different algorithms to each other. Is this approach correct and what other approaches could I use? Also how would I come to the conclusion that an algorithm is better than the others. For example is it when the AUC score for logistic regression is better than the AUC score for SVM?
 ",3,5
104,2018-4-3,2018,4,3,2,892cny,[D] Buzzword Convergence: Making Sense of Quantum Neural Blockchain AI,https://www.reddit.com/r/MachineLearning/comments/892cny/d_buzzword_convergence_making_sense_of_quantum/,CuttingWithScissors,1522691846,,23,104
105,2018-4-3,2018,4,3,3,892tq0,[P] My startup is building an affordable human-sized robot. Is this something ML hackers would be interested in?,https://www.reddit.com/r/MachineLearning/comments/892tq0/p_my_startup_is_building_an_affordable_humansized/,ZachAllen417,1522693404,,53,39
106,2018-4-3,2018,4,3,4,893oyn,[D] How to be a good machine learning developer ?,https://www.reddit.com/r/MachineLearning/comments/893oyn/d_how_to_be_a_good_machine_learning_developer/,nikr07,1522696491,"I just want to ask what is better(in terms of graduate fresh hire) for software development industry:
1. Full-stack machine learning engineers who know the underlying algorithm but work mostly on high level applications(like Spark)
 ,or,
2. People who know all the algorithms and are up-to-date with recent publications and datasets. (similar to Data scientists)",0,1
107,2018-4-3,2018,4,3,4,893wkm,addition of a kernel and a function,https://www.reddit.com/r/MachineLearning/comments/893wkm/addition_of_a_kernel_and_a_function/,jempt0,1522697278,[removed],0,0
108,2018-4-3,2018,4,3,4,8947ao,[D] A Gentle Introduction to Concept Drift in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8947ao/d_a_gentle_introduction_to_concept_drift_in/,[deleted],1522698412,[deleted],0,1
109,2018-4-3,2018,4,3,4,8948sh,[D] A Gentle Introduction to Concept Drift in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8948sh/d_a_gentle_introduction_to_concept_drift_in/,baylearn,1522698562,,4,31
110,2018-4-3,2018,4,3,6,895hk8,[N] Caffe2 Merges With PyTorch,https://www.reddit.com/r/MachineLearning/comments/895hk8/n_caffe2_merges_with_pytorch/,gwen0927,1522704546,,0,1
111,2018-4-3,2018,4,3,6,895ixm,Collaboratory Google Colab with helpful code snippets,https://www.reddit.com/r/MachineLearning/comments/895ixm/collaboratory_google_colab_with_helpful_code/,ianholing,1522704926,,0,2
112,2018-4-3,2018,4,3,6,895mqb,[D] What is the SotA of Language Modeling?,https://www.reddit.com/r/MachineLearning/comments/895mqb/d_what_is_the_sota_of_language_modeling/,kleinergauss,1522705944,"In 2016, this was easy to answer with the [Exploring the Limits of Language Modeling](https://arxiv.org/pdf/1602.02410.pdf) paper. Have there been improvements (on the One Billion Word benchmark or other datasets) since? ",6,9
113,2018-4-3,2018,4,3,6,895ocu,Time series subsequence clustering,https://www.reddit.com/r/MachineLearning/comments/895ocu/time_series_subsequence_clustering/,[deleted],1522706355,,0,1
114,2018-4-3,2018,4,3,7,895rfd,[D] Clustering models for events within a time series,https://www.reddit.com/r/MachineLearning/comments/895rfd/d_clustering_models_for_events_within_a_time/,violintendencies,1522707102,"Hi! Thanks for giving this a look. I'm hoping for advice on how to build a model for the following problem.

Abstractly, I have a dataset consisting of many independent time series. I would like to create a model that, given an input time series of the same form, outputs clusters within that time series.

Explanatory example: suppose I have a table with fields: [timestamp, bakery_id, order_description, order_amount]. I'd like a model that, given a bakery's log, identifies the groups of orders most likely to be from their most valuable/most retained customers (e.g. the croissants from date A, date B, date C, and date D with amounts $W, $X, $Y, and $Z were likely from customer M, and the buns from date ... with amounts ... were likely from customer N).

Of note:

* The dates within a group of orders tend to be approximately cyclical (e.g. every day, every week, every two weeks, every month, etc.), but different groups may have different cycles (e.g. customer M comes in every other week but customer N comes in monthly)

* The order amounts tend to be the same within a group, perhaps with outliers

* The order descriptions are not sparse (they include the pastry type and noisy notes), and tend to be very similar within a group

The challenges seem to lie mainly in that:

* The number of clusters varies (and is possibly 0) between time series

* Each time series has many noisy rows that ideally would not belong to any cluster

I've looked into clustering with Euclidean distance, both hierarchically and through DBSCAN. Namely, I've mapped the dates to polar coordinates for day-of-week and for day-of-month. However, the results are highly sensitive to scaling factors used for the dimensions (e.g. date-related feature values have a very different distribution than order amount values), so I don't think that will work.

Any advice and help would be greatly appreciated. Thank you!",0,2
115,2018-4-3,2018,4,3,7,895wgt,[D] The differences between tinkering and research (2016),https://www.reddit.com/r/MachineLearning/comments/895wgt/d_the_differences_between_tinkering_and_research/,hardmaru,1522708260,,11,32
116,2018-4-3,2018,4,3,7,8963gf,[D] is openAI dead?,https://www.reddit.com/r/MachineLearning/comments/8963gf/d_is_openai_dead/,insider_7,1522709838,"First, Karpathy left them. Then no ""open"" methodology for their Dota 1v1 bot. Oficial webpage has no new content on over 2 months and finally Elon has left the company.

Is this project officially dead? What is going to happen with the millions of dollars people threw at this experiment? ",7,0
117,2018-4-3,2018,4,3,7,8963pc,[D] Is Caffe becoming part of PyTorch?,https://www.reddit.com/r/MachineLearning/comments/8963pc/d_is_caffe_becoming_part_of_pytorch/,inarrears,1522709893,,3,18
118,2018-4-3,2018,4,3,9,896lb3,Step 2 - People to work with and learn from.,https://www.reddit.com/r/MachineLearning/comments/896lb3/step_2_people_to_work_with_and_learn_from/,itstassy,1522713814,[removed],0,1
119,2018-4-3,2018,4,3,9,896vj8,[N] Caffe2 source code now lives in the PyTorch repository.,https://www.reddit.com/r/MachineLearning/comments/896vj8/n_caffe2_source_code_now_lives_in_the_pytorch/,trcytony,1522716074,,0,1
120,2018-4-3,2018,4,3,10,8976x9,[R] [1804.00222] Learning Unsupervised Learning Rules,https://www.reddit.com/r/MachineLearning/comments/8976x9/r_180400222_learning_unsupervised_learning_rules/,evc123,1522718748,,2,22
121,2018-4-3,2018,4,3,10,897998,Learning to Anonymize Faces for Privacy Preserving Action Detection,https://www.reddit.com/r/MachineLearning/comments/897998/learning_to_anonymize_faces_for_privacy/,[deleted],1522719275,[deleted],0,1
122,2018-4-3,2018,4,3,10,897ckb,2018 Atrial Segmentation Challenge,https://www.reddit.com/r/MachineLearning/comments/897ckb/2018_atrial_segmentation_challenge/,zhaohanxiong,1522719995,[removed],0,1
123,2018-4-3,2018,4,3,10,897d4j,[R] [1803.11556] Learning to Anonymize Faces for Privacy Preserving Action Detection,https://www.reddit.com/r/MachineLearning/comments/897d4j/r_180311556_learning_to_anonymize_faces_for/,jasonren718,1522720059,,4,27
124,2018-4-3,2018,4,3,11,8989rs,How do tune your hyper-parameters in Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/8989rs/how_do_tune_your_hyperparameters_in_reinforcement/,activatedgeek,1522723509,[removed],0,1
125,2018-4-3,2018,4,3,11,898dqm,Cow dung organic fertilizer pellet mill,https://www.reddit.com/r/MachineLearning/comments/898dqm/cow_dung_organic_fertilizer_pellet_mill/,amylee516,1522723956,,0,1
126,2018-4-3,2018,4,3,12,898k2u,AdaDepth: Unsupervised Content Congruent Adaptation for Depth Estimation,https://www.reddit.com/r/MachineLearning/comments/898k2u/adadepth_unsupervised_content_congruent/,QIAriel,1522724727,[removed],0,1
127,2018-4-3,2018,4,3,13,899esw,Looking for applications of machine learning in real estate investing,https://www.reddit.com/r/MachineLearning/comments/899esw/looking_for_applications_of_machine_learning_in/,atlmlphd,1522728965,[removed],0,1
128,2018-4-3,2018,4,3,13,899fl9,[D] What are some good and interesting machine learning papers for people with average mathematical skill?,https://www.reddit.com/r/MachineLearning/comments/899fl9/d_what_are_some_good_and_interesting_machine/,begooboi,1522729084,"I have a basic understanding of undergrad math and I am looking for a good and interesting machine learning papers to read. I have read this paper [""Towards the Automatic Anime Characters Creation with Generative Adversarial Networks""](https://arxiv.org/abs/1708.05509) and understood it. I am looking for similar papers with intersting applications.  

This is a minor question is there a alternative site for [ arxiv-vanity ](https://www.arxiv-vanity.com) for machine learning, where we can read most recent andor popular  arxiv machine learning papers in html format?
",1,8
129,2018-4-3,2018,4,3,13,899pnq,[P] Five video classification methods in Keras and TensorFlow,https://www.reddit.com/r/MachineLearning/comments/899pnq/p_five_video_classification_methods_in_keras_and/,SupraluminalShift,1522730607,,3,30
130,2018-4-3,2018,4,3,13,899s2t,Research in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/899s2t/research_in_machine_learning/,nspunn1993,1522730990,[removed],0,1
131,2018-4-3,2018,4,3,14,89a0dc,[N] Microsoft Professional Program Artificial Intelligence track,https://www.reddit.com/r/MachineLearning/comments/89a0dc/n_microsoft_professional_program_artificial/,galagalagalagala,1522732336,,8,25
132,2018-4-3,2018,4,3,14,89a2jn,[P] Data Version Control - Machine Learning Time Travel (Video Explainer),https://www.reddit.com/r/MachineLearning/comments/89a2jn/p_data_version_control_machine_learning_time/,thumbsdrivesmecrazy,1522732686,,15,76
133,2018-4-3,2018,4,3,14,89a6ou,"Super new to the field; what ""kind"" of machine learning should I use for this example?",https://www.reddit.com/r/MachineLearning/comments/89a6ou/super_new_to_the_field_what_kind_of_machine/,[deleted],1522733351,,0,1
134,2018-4-3,2018,4,3,14,89acbe,[R] Resources for Causal Inference?,https://www.reddit.com/r/MachineLearning/comments/89acbe/r_resources_for_causal_inference/,jerrylessthanthree,1522734302,"Hey all, I'm looking for any papers or surveys to get started on causal inference and the role machine learning has had on it. ",6,10
135,2018-4-3,2018,4,3,15,89aiki,[R] [1804.00645] Universal Planning Networks,https://www.reddit.com/r/MachineLearning/comments/89aiki/r_180400645_universal_planning_networks/,johnschulman,1522735457,,9,24
136,2018-4-3,2018,4,3,15,89ao9o,Automatic Round Bottle Labeling Machine Video sherry@machinehall.com,https://www.reddit.com/r/MachineLearning/comments/89ao9o/automatic_round_bottle_labeling_machine_video/,lgsherry,1522736697,,1,1
137,2018-4-3,2018,4,3,16,89azba,Most Common Myths about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/89azba/most_common_myths_about_machine_learning/,trainingdata,1522739216,,0,1
138,2018-4-3,2018,4,3,16,89azes,[P] Skynet Today - accessible and informed coverage of AI hype and panic,https://www.reddit.com/r/MachineLearning/comments/89azes/p_skynet_today_accessible_and_informed_coverage/,regalalgorithm,1522739236,,0,1
139,2018-4-3,2018,4,3,17,89bitr,OPEN INVITATION TO PARTICIPATE IN THE M4 COMPETITION,https://www.reddit.com/r/MachineLearning/comments/89bitr/open_invitation_to_participate_in_the_m4/,spyrosmakridakis,1522744117,[removed],0,1
140,2018-4-3,2018,4,3,18,89bvqx,Googles machine learning software can now categorize ramen by shop,https://www.reddit.com/r/MachineLearning/comments/89bvqx/googles_machine_learning_software_can_now/,aaron_parker,1522747534,,1,1
141,2018-4-3,2018,4,3,18,89c0cb,Getting Started with Machine Learning: Crack the Code,https://www.reddit.com/r/MachineLearning/comments/89c0cb/getting_started_with_machine_learning_crack_the/,dexlabanalytics,1522748741,,0,1
142,2018-4-3,2018,4,3,19,89c943,[P] Tensorflow Implementation of Expressive Tacotron,https://www.reddit.com/r/MachineLearning/comments/89c943/p_tensorflow_implementation_of_expressive_tacotron/,longinglove,1522750958,,7,51
143,2018-4-3,2018,4,3,19,89ceec,SLA Jobs is the Place for World Class Machine Learning Training Institute in Chennai,https://www.reddit.com/r/MachineLearning/comments/89ceec/sla_jobs_is_the_place_for_world_class_machine/,sugantharaja,1522752273,,0,1
144,2018-4-3,2018,4,3,19,89cetc,Choosing a production machine learning environment,https://www.reddit.com/r/MachineLearning/comments/89cetc/choosing_a_production_machine_learning_environment/,[deleted],1522752379,,0,1
145,2018-4-3,2018,4,3,19,89chaw,[D] Choosing a ML production environment,https://www.reddit.com/r/MachineLearning/comments/89chaw/d_choosing_a_ml_production_environment/,lokimedes,1522752978,"I'm in the market for a reliable production environment for developing and deploying machine learning models. After searching around I found [Anaconda Enterprise](https://www.anaconda.com/enterprise/), and a few others, but it is hard to judge the completeness of these systems.
Can anybody recommend similar offerings?

Additional requirements: 

* Enterprise security (LDAP, Kerberos) 
* GPU and cluster support 
* Ability to develop models in python (e.g. Tensorflow) 
* Deployment of models in a structure and secure way 
* Integrated Data management 
* Off-line support, we will be running the environment in a secure facility.
* Extendable with new formats, packages and customisations 

In general the Anaconda Enterprise seems a good match on paper, and the price is not too scary for our use, but I feel that some due diligence is needed when we talk multi-$k/yr software.


tl;dr: What offerings similar to Anaconda Enterprise exists?",8,14
146,2018-4-3,2018,4,3,20,89ck8q,[D] YOLO9000 Output/Loss Doubt,https://www.reddit.com/r/MachineLearning/comments/89ck8q/d_yolo9000_outputloss_doubt/,ShivamDuggal4,1522753642,"In YOLO9000, the input data for training is normalized w.r.t image width and height. In other words, the centre and the width/height of the bounding boxes are divided by the image width and height. 
I am confused regarding the output of the network. According to the paper, the network predicts offsets relative to the grid cell.  

these offsets are added to cx, and cy.

The cx and cy values are the indices of the cell which contains the object. They are integers lying in the range [0,12].

Also, the pw and ph values are the anchor width and height corresponding to the box with the highest confidence. They are floating point numbers lying in (0, 13).

The output computed using the equations is w.r.t the gridd cell: 
bx = (tx) + cx

by = (ty) + cy

bw = pw * e^tw

bh = ph * e^th

i.e the centre values(bx,by) will be between [0,13]. In order to draw the bounding boxes we need the centre w.r.t the original image(416*416). 

I have the following questions: 
1. So why do we actually compute these equations?  
2. The mean square Loss of the network is computed between the ground truth bounding boxes normalized wr.t. image dimensions and between (bx,by) or (tx,ty) ?
",0,3
147,2018-4-3,2018,4,3,20,89cwl2,[R] Aggregated Momentum: Stability Through Passive Damping,https://www.reddit.com/r/MachineLearning/comments/89cwl2/r_aggregated_momentum_stability_through_passive/,SleepyCoder123,1522756312,,0,3
148,2018-4-3,2018,4,3,21,89d1ig,How General Data Protection Regulation (GDPR) affects AI.?,https://www.reddit.com/r/MachineLearning/comments/89d1ig/how_general_data_protection_regulation_gdpr/,harry_0_0_7,1522757317,[removed],0,1
149,2018-4-3,2018,4,3,21,89d1p7,Can I combine output from different machine learning to get the required solution ?,https://www.reddit.com/r/MachineLearning/comments/89d1p7/can_i_combine_output_from_different_machine/,aaditkapoor1201,1522757356,[removed],0,1
150,2018-4-3,2018,4,3,21,89d42i,AI is a hard field to get into because the training is meager,https://www.reddit.com/r/MachineLearning/comments/89d42i/ai_is_a_hard_field_to_get_into_because_the/,Xilc,1522757841,[removed],0,1
151,2018-4-3,2018,4,3,21,89d4hr,[D] Speech Recognizer using google speech API and call recordings of user in python.,https://www.reddit.com/r/MachineLearning/comments/89d4hr/d_speech_recognizer_using_google_speech_api_and/,ZER_0_NE,1522757925,"I wish on making a speech recognizer which would only listen to me and not to anyone else and further carry out simple instructions on my laptop. The Google speech API would be suitable for this purpose but I wish to know is there any way that I could feed my call recordings so that it could learn to differentiate between me and other users. 
By feeding my call recordings I mean is to feed the calls to a neural network which would learn my voice eventually. Is something like this possible?",1,1
152,2018-4-3,2018,4,3,21,89d5by,[D] Substitute Teacher Networks: Learning with Almost No Supervision [arXiv post-print],https://www.reddit.com/r/MachineLearning/comments/89d5by/d_substitute_teacher_networks_learning_with/,brainggear,1522758099,,2,19
153,2018-4-3,2018,4,3,21,89d7u0,[R] M2M Day 90 How I used Artificial Intelligence to automate Tinder,https://www.reddit.com/r/MachineLearning/comments/89d7u0/r_m2m_day_90_how_i_used_artificial_intelligence/,dearpetra,1522758614,,0,1
154,2018-4-3,2018,4,3,21,89ddag,[D] - Face Recognition in Python,https://www.reddit.com/r/MachineLearning/comments/89ddag/d_face_recognition_in_python/,ogs_kfp_t,1522759642,"As part of a machine learning pipeline, I want to detect and extract faces (bounding boxes) in python. For some of the usecases I work on, detecting faces can speed up the process. Ultimately- I want to use it in Python (keras / pytorch), as a part of method to detect if somebody takes a sip of coffee, or if somebody has a typical programmer face-

I did a little google'ling of course and found this as candidates. I extend the list with entries from comments to make it useful  for later references.

* https://github.com/oarriaga/face_classification
* https://docs.opencv.org/3.4.1/d7/d8b/tutorial_py_face_detection.html
* https://github.com/krasserm/face-recognition (From impulsecorp. thx!)

Anyone with useful pre-trained networks, or other ready to use face detection python compatible code, please add in comments.",5,10
155,2018-4-3,2018,4,3,21,89dfg7,[D] How common is porn in datasets?,https://www.reddit.com/r/MachineLearning/comments/89dfg7/d_how_common_is_porn_in_datasets/,HINDBRAIN,1522760105,"Earlier on today I had an issue with annotation data on an image in the coco-text 2014 dataset, I display the image, and it's a dude in a bunny suit screwing a woman with the caption ""The fuck bunny says congratulation in his own very special way"" ([sfw crop I think](https://i.imgur.com/MVUcPlL.png)). Is that a common occurrence? I'm not very happy to have that pop on my screen with coworkers around!",67,230
156,2018-4-3,2018,4,3,22,89dk7f,"A new metric for generative models for molecules, by Linz University",https://www.reddit.com/r/MachineLearning/comments/89dk7f/a_new_metric_for_generative_models_for_molecules/,mostafabenh,1522760942,,0,1
157,2018-4-3,2018,4,3,22,89dz9i,[P] Triplet Loss and Online Triplet Mining in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/89dz9i/p_triplet_loss_and_online_triplet_mining_in/,omoindrot,1522763647,,7,19
158,2018-4-3,2018,4,3,23,89e2vk,[P] An introduction to Reinforcement Learning - Short Video,https://www.reddit.com/r/MachineLearning/comments/89e2vk/p_an_introduction_to_reinforcement_learning_short/,upulbandara,1522764239,,1,48
159,2018-4-3,2018,4,3,23,89egxo,Learn to build a Convolutional Neural Network on the web with this easy tutorial,https://www.reddit.com/r/MachineLearning/comments/89egxo/learn_to_build_a_convolutional_neural_network_on/,chibuk,1522766536,,0,1
160,2018-4-3,2018,4,3,23,89emc3,What are some good textbooks on Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/89emc3/what_are_some_good_textbooks_on_neural_networks/,slm14b,1522767422,[removed],0,1
161,2018-4-4,2018,4,4,0,89epi7,RetinaNet implementation in Keras with similar results as original implementation,https://www.reddit.com/r/MachineLearning/comments/89epi7/retinanet_implementation_in_keras_with_similar/,[deleted],1522767933,,0,1
162,2018-4-4,2018,4,4,0,89etv1,RetinaNet implementation in Keras with similar results as original one.,https://www.reddit.com/r/MachineLearning/comments/89etv1/retinanet_implementation_in_keras_with_similar/,mkocabas,1522768612,,0,1
163,2018-4-4,2018,4,4,0,89exqn,Free speech recognition datasets?,https://www.reddit.com/r/MachineLearning/comments/89exqn/free_speech_recognition_datasets/,daithibowzy,1522769200,[removed],0,1
164,2018-4-4,2018,4,4,0,89f07g,AWS Sagemaker vs Domino Datalab vs ???,https://www.reddit.com/r/MachineLearning/comments/89f07g/aws_sagemaker_vs_domino_datalab_vs/,sonobenissimo,1522769578,[removed],0,1
165,2018-4-4,2018,4,4,0,89f17m,[D] Current best practices for VAEs,https://www.reddit.com/r/MachineLearning/comments/89f17m/d_current_best_practices_for_vaes/,AndriPi,1522769762,"What are the most commonly used VAE architectures right now, for these tasks:

- missing data imputation
- image generation
- time sequence generation

I've been using mostly VAE-IAF with good results, but I was wondering if this is still considered a BP, or if the various evolutions of disentagled VAEs are preferred now. To be more explicit, I consider https://arxiv.org/pdf/1802.04942.pdf as an evolution of $\beta$-VAE. 

Or maybe models which are neither extensions of the original VAE, such as VAE-IAF, or extensions of the original $\beta$-VAE, such as the $\beta$-TCVAE above. Maybe now other models such as InfoVAE https://arxiv.org/pdf/1706.02262.pdf (or WAE: they're the same model https://arxiv.org/pdf/1711.01558.pdf) are considered the state of the art for VAEs. What's the consensus?
",7,13
166,2018-4-4,2018,4,4,1,89fnbj,[R] Understanding GANs through a statistical divergence perspective,https://www.reddit.com/r/MachineLearning/comments/89fnbj/r_understanding_gans_through_a_statistical/,AlexiaJM,1522773182,,0,5
167,2018-4-4,2018,4,4,1,89fnzk,[D] Best practices for deep networks with fully connected layers.,https://www.reddit.com/r/MachineLearning/comments/89fnzk/d_best_practices_for_deep_networks_with_fully/,VishDev,1522773299,"I am working on a problem where convolutional layers or recurrent layers do not make sense and am trying to use simple fully connected linear layers.
There are lots of network architecture improvements for CNNs. Are there any similar recommended architectures or optimization tricks for deep networks with fully connected layers only? I tried a network with residual connections, but does not seem to work well. Any pointers to papers or implementations or blogs would be really helpful.",11,2
168,2018-4-4,2018,4,4,2,89g21n,MobileNetV2: The Next Generation of On-Device Computer Vision Networks,https://www.reddit.com/r/MachineLearning/comments/89g21n/mobilenetv2_the_next_generation_of_ondevice/,[deleted],1522775480,[deleted],0,1
169,2018-4-4,2018,4,4,2,89g2b1,[R] MobileNetV2: The Next Generation of On-Device Computer Vision Networks,https://www.reddit.com/r/MachineLearning/comments/89g2b1/r_mobilenetv2_the_next_generation_of_ondevice/,yourSAS,1522775522,,16,51
170,2018-4-4,2018,4,4,2,89g479,Developing Heuristics for Evaluating Jeopardy Answers,https://www.reddit.com/r/MachineLearning/comments/89g479/developing_heuristics_for_evaluating_jeopardy/,nonis-,1522775810,,0,1
171,2018-4-4,2018,4,4,2,89gbap,[R] Learning to Navigate in Cities Without a Map (DeepMind),https://www.reddit.com/r/MachineLearning/comments/89gbap/r_learning_to_navigate_in_cities_without_a_map/,baylearn,1522776963,,5,17
172,2018-4-4,2018,4,4,2,89gkgu,GPU monitoring for single computer or cluster with Grafana dashboard,https://www.reddit.com/r/MachineLearning/comments/89gkgu/gpu_monitoring_for_single_computer_or_cluster/,[deleted],1522778374,[deleted],0,1
173,2018-4-4,2018,4,4,3,89glbi,[P] GPU monitoring tool for single computer or cluster using Grafana,https://www.reddit.com/r/MachineLearning/comments/89glbi/p_gpu_monitoring_tool_for_single_computer_or/,reformed_scientist,1522778492,,3,6
174,2018-4-4,2018,4,4,3,89glq5,[D] Normalizing Flows,https://www.reddit.com/r/MachineLearning/comments/89glq5/d_normalizing_flows/,akosiorek,1522778544,,3,11
175,2018-4-4,2018,4,4,4,89heng,Fast GPU Deep Learning for using an Adjacency Matrix. All layers procesed without out to CPU,https://www.reddit.com/r/MachineLearning/comments/89heng/fast_gpu_deep_learning_for_using_an_adjacency/,3droberto,1522783009,,0,1
176,2018-4-4,2018,4,4,4,89hppw,Online news classification,https://www.reddit.com/r/MachineLearning/comments/89hppw/online_news_classification/,fedecaccia,1522784650,[removed],0,1
177,2018-4-4,2018,4,4,5,89i9h8,[P]s The 2018 Stanford CS224n NLP course projects are now online. A lot of them are pretty impressive.,https://www.reddit.com/r/MachineLearning/comments/89i9h8/ps_the_2018_stanford_cs224n_nlp_course_projects/,BatmantoshReturns,1522787614,,26,396
178,2018-4-4,2018,4,4,5,89ifqv,Aigo.ai. The Third Wave of AI. Your truly 'intelligent' personal personal assistant.,https://www.reddit.com/r/MachineLearning/comments/89ifqv/aigoai_the_third_wave_of_ai_your_truly/,AigoToken,1522788574,,0,1
179,2018-4-4,2018,4,4,5,89iiwh,NORMAN -AI-Powered Psychopath,https://www.reddit.com/r/MachineLearning/comments/89iiwh/norman_aipowered_psychopath/,bitbd83,1522789057,[removed],0,1
180,2018-4-4,2018,4,4,6,89ik21,[D] Featurization before or after dataset splitting,https://www.reddit.com/r/MachineLearning/comments/89ik21/d_featurization_before_or_after_dataset_splitting/,villasv,1522789231,"I was reading [this awesome post about a reproducibility tool](https://blog.dataversioncontrol.com/data-version-control-tutorial-9146715eda46) when I realized that the author decided to split the train/test datasets before featurization.

It didn't make sense to me, because why would you not be able to commute those operations? But just a few days later I found this comment in a deepchem repo issue:

&gt; In cases of data augmentation, there are use-cases when it might make sense to featurize data after it has been split into train/test/validation.

And I have no idea how that would be a thing, but apparently it is. Instead of diverting the issue with this random question I decided to bring the discussion here.

What do you usually do? Featurize after splits? What kind of data augmentation could justify that order?",3,2
181,2018-4-4,2018,4,4,6,89j06c,[N] Apple Hires Googles A.I. Chief,https://www.reddit.com/r/MachineLearning/comments/89j06c/n_apple_hires_googles_ai_chief/,chisai_mikan,1522791858,,18,63
182,2018-4-4,2018,4,4,7,89j6dy,Some Reinforcement Learning: The Greedy and Explore-Exploit Algorithms for the Multi-Armed Bandit Framework,https://www.reddit.com/r/MachineLearning/comments/89j6dy/some_reinforcement_learning_the_greedy_and/,SandipanDeyUMBC,1522792869,,0,1
183,2018-4-4,2018,4,4,7,89j81s,[D] what you think are useful read-to-use solutions that could help ML guy's job ?,https://www.reddit.com/r/MachineLearning/comments/89j81s/d_what_you_think_are_useful_readtouse_solutions/,[deleted],1522793135,[deleted],1,3
184,2018-4-4,2018,4,4,7,89j94g,[P] Introducing TensorFlow.js: Machine Learning in Javascript,https://www.reddit.com/r/MachineLearning/comments/89j94g/p_introducing_tensorflowjs_machine_learning_in/,fhoffa,1522793330,,1,18
185,2018-4-4,2018,4,4,8,89jx4b,Advice for Mentorship and Help Exploring a Research Avenue,https://www.reddit.com/r/MachineLearning/comments/89jx4b/advice_for_mentorship_and_help_exploring_a/,www3cam,1522798205,[removed],0,1
186,2018-4-4,2018,4,4,9,89k8df,Best way to structure Q/A dataset for customer support,https://www.reddit.com/r/MachineLearning/comments/89k8df/best_way_to_structure_qa_dataset_for_customer/,moremindful,1522800279,[removed],0,1
187,2018-4-4,2018,4,4,9,89kdia,Data Science Interview Guide,https://www.reddit.com/r/MachineLearning/comments/89kdia/data_science_interview_guide/,snazrul,1522801180,,0,1
188,2018-4-4,2018,4,4,9,89kpvv,Good sources on graph neural networks,https://www.reddit.com/r/MachineLearning/comments/89kpvv/good_sources_on_graph_neural_networks/,jirukulapati,1522803548,[removed],0,1
189,2018-4-4,2018,4,4,11,89ll69,[D] Potential of Client Side Machine Learning,https://www.reddit.com/r/MachineLearning/comments/89ll69/d_potential_of_client_side_machine_learning/,manicman1999,1522809893,"Hello! I am very new to the Machine Learning community, having learned many of the concepts in only the past 3 to 4 months. Recently, the Tensorflow.js API was released. I've seen a lot of people saying that Machine Learning in JavaScript is a waste of time and simply not right.

I would like to challenge this a little. I believe client-side machine learning could open a new world of potential applications of this technology.

First, privacy can be left entirely to the client. Recommendation engines built and stored locally would require little to data being sent to the server. The client would also not rely on the server to pick and choose what options it wants to show to the client, in the case of a busy connection.

Extending onto this, many users are heavily concerned about mobile data usage. If the client does not need to upload and download extra data to the server for the recommendation engine (or other service) to work, this could optimise data usage.

Furthermore, as the video from the summit stated, using javascript allows machine learning applications to be nearly universal. Every commonly used device uses some sort of browser, which typically allow the use of JavaScript. When developing in JavaScript you can spend less time worrying about making things cross-platform, and more time on the important things.

What do you think?

P.S. I am still learning and don't know everything, if I'm mistaken, please correct me!",4,1
190,2018-4-4,2018,4,4,12,89lvug,What is the worst use of machine learning you know of?,https://www.reddit.com/r/MachineLearning/comments/89lvug/what_is_the_worst_use_of_machine_learning_you/,dwddao,1522812225,[removed],0,1
191,2018-4-4,2018,4,4,12,89m0om,"[P] Video series on the Intuition &amp; Math behind Backpropagation, the resulting Vanishing Gradient Problem, and how Xavier Weight Initialization reduces this problem",https://www.reddit.com/r/MachineLearning/comments/89m0om/p_video_series_on_the_intuition_math_behind/,blackHoleDetector,1522813289,"- [Backpropagation explained | Part 1 - The intuition](https://youtu.be/XE3krf3CQls)
- [Backpropagation explained | Part 2 - The mathematical notation](https://youtu.be/2mSysRx-1c0)
- [Backpropagation explained | Part 3 - Mathematical observations](https://youtu.be/G5b4jRBKNxw)
- [Backpropagation explained | Part 4 - Calculating the gradient](https://youtu.be/Zr5viAZGndE)
- [Backpropagation explained | Part 5 - What puts the back in backprop?](https://youtu.be/xClK__CqZnQ)
- [Vanishing &amp; Exploding Gradient explained | A problem resulting from backpropagation](https://youtu.be/qO_NLVjD6zE)
- [Weight Initialization explained | A way to reduce the vanishing/exploding gradient problem](https://youtu.be/8krd5qKVw-Q)

This series is part of this [larger deep learning playlist](https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU).
",1,13
192,2018-4-4,2018,4,4,13,89m7z6,"People who can only use CPU for deep network inference in production, how do you optimise for speed and what framework work best with CPU?",https://www.reddit.com/r/MachineLearning/comments/89m7z6/people_who_can_only_use_cpu_for_deep_network/,[deleted],1522815009,,0,1
193,2018-4-4,2018,4,4,13,89maa3,[D] Two questions about normalizing flows,https://www.reddit.com/r/MachineLearning/comments/89maa3/d_two_questions_about_normalizing_flows/,knowedgelimited,1522815551,"1. Why the emphasis on transformations that have unit determinant? 

Is it because this allows the probability at the output to be explicitly calculated, AND an explicit form of the probability is needed in order to participate in a KL regularizer?

If that is not it, I do not understand.  An generic feedforward net can transform a given distribution to any other distribution I believe (probably with some exceptions where the jacobian would need to be infinity or something). So what is the big deal?

2. Why is it even needed?

The normalizing flows and related works are motivated starting from VAEs.  
In a VAE you have a deep net (arbitrary powerful) mapping from the input to the latent, and another arbitrary powerful DNN mapping from the latent to the output.  So the latent can stay simple, and still express any desired output.

In fact in the paper Kim &amp; Mnih Disentangling by Factorising, they argue that having a simple factorized latent is the goal:
     ""we wish for a factorial distribution q(z) = prod_j q(z_j)''

I read someone say that the posterior for a given data point could be multimodal, and that is why more flexible posterior is needed.  Not understanding this!  
Say the data ""point"" is an image. A particular image is a fixed thing, not a random process. So _ideally_ there should be some particular latent $z$ that generates it, not a multimodal distribution.  The distributions introduced in VAE seem like a regularization introduced by that method, rather than something that is fundamentally true.


I can see that I am deeply misunderstanding something. Thank you for your help people.

",2,5
194,2018-4-4,2018,4,4,13,89mggm,Can someone please answer this question on stackoverflow??,https://www.reddit.com/r/MachineLearning/comments/89mggm/can_someone_please_answer_this_question_on/,danniel_p,1522817080,[removed],0,1
195,2018-4-4,2018,4,4,13,89mgyr,"[D] People who can only use CPU for deep network inference in production, how do you optimise for speed and what framework work best with CPU?",https://www.reddit.com/r/MachineLearning/comments/89mgyr/d_people_who_can_only_use_cpu_for_deep_network/,RavlaAlvar,1522817212,,20,13
196,2018-4-4,2018,4,4,13,89mh9x,[1804.00218] Synthesis of Differentiable Functional Programs for Lifelong Learning,https://www.reddit.com/r/MachineLearning/comments/89mh9x/180400218_synthesis_of_differentiable_functional/,[deleted],1522817289,[deleted],0,1
197,2018-4-4,2018,4,4,13,89mjte,[R] Synthesis of Differentiable Functional Programs for Lifelong Learning,https://www.reddit.com/r/MachineLearning/comments/89mjte/r_synthesis_of_differentiable_functional_programs/,FastPop,1522817945,,0,6
198,2018-4-4,2018,4,4,14,89moe8,What are search probabilities,https://www.reddit.com/r/MachineLearning/comments/89moe8/what_are_search_probabilities/,fishdrops,1522819174,[removed],0,1
199,2018-4-4,2018,4,4,14,89mpd7,[D] Learning to navigate in cities without a map | DeepMind,https://www.reddit.com/r/MachineLearning/comments/89mpd7/d_learning_to_navigate_in_cities_without_a_map/,sksq9,1522819434,,6,81
200,2018-4-4,2018,4,4,14,89mw30,[P] Region-based convolutional neural networks in Keras (Keras-RCNN),https://www.reddit.com/r/MachineLearning/comments/89mw30/p_regionbased_convolutional_neural_networks_in/,SupraluminalShift,1522821328,,0,15
201,2018-4-4,2018,4,4,15,89n6nt,Machine Learning Jobs Portal [p],https://www.reddit.com/r/MachineLearning/comments/89n6nt/machine_learning_jobs_portal_p/,gauthamz,1522824633,,2,18
202,2018-4-4,2018,4,4,16,89nahm,[D] question about The Mutual Autoencoder paper,https://www.reddit.com/r/MachineLearning/comments/89nahm/d_question_about_the_mutual_autoencoder_paper/,knowedgelimited,1522825769,"I am trying to read the paper Phuong et al, The Mutual Autoencoder: Controlling Information in Latent Representations.

Stopped on a notation question.

It describes VAE, then argues that VAE is insufficient for representation learning. 
On page 3, ""...when p_theta(x|z) = q(x) is close to achievable, the task of density estimation becomes disconnected from the goal of representation learning.
Later a theorem (p. 5), that ""...p(x|z)=q(x) is the only global optimum of the VAE objective"".

But what is q(x) in these statements?  

I am too familiar with the VAE notation that q(z|x) is the ""encoder"", but there is no q(x).
I could think the paper is using q() for both the encoder and decoder, but in fact it uses p_theta(x|z) for the encoder.
",2,3
203,2018-4-4,2018,4,4,16,89nbbn,Universal Planning Networks vs. Zero-shot visual imitation(ICLR 2018 oral),https://www.reddit.com/r/MachineLearning/comments/89nbbn/universal_planning_networks_vs_zeroshot_visual/,jeasinema,1522826041,,1,1
204,2018-4-4,2018,4,4,16,89nbjs,[P] A visual introduction to Meta-Learning for Deep-Learning models,https://www.reddit.com/r/MachineLearning/comments/89nbjs/p_a_visual_introduction_to_metalearning_for/,Thomjazz,1522826116,,0,37
205,2018-4-4,2018,4,4,16,89nbz8,What should I learn?,https://www.reddit.com/r/MachineLearning/comments/89nbz8/what_should_i_learn/,Apejann,1522826245,[removed],0,1
206,2018-4-4,2018,4,4,17,89nr5j,Hearthstone Machine Learning Competition,https://www.reddit.com/r/MachineLearning/comments/89nr5j/hearthstone_machine_learning_competition/,ttajmajer,1522831432,,0,1
207,2018-4-4,2018,4,4,17,89nrge,[D] Question about publishing results on publicly available datasets,https://www.reddit.com/r/MachineLearning/comments/89nrge/d_question_about_publishing_results_on_publicly/,newperson77777777,1522831554,"I had a question about publishing results on publicly available datasets. In many cases, there are publicly available datasets with published results from other researchers. However, it's very easy to overfit to one of these publicly available datasets. How is this generally handled in the research community, especially when reviewing papers? Do they tend to look more closely at your methods. With regards to understanding your results in context, do they tend to ignore extremely high results, or do they look more generally at a range rather than specific numbers ? Because it's so easy to overfit, it's seem a matter of trust between the researcher and others that the researcher didn't overfit to a test set (even to a small degree) and just provided a convincing case for their methodology.
 
Also, in many cases, a strong test result can be merely a matter of luck or random test set distribution. Honestly, in some cases a model that scored minutely less than a top scoring model may be just as good if not better than the top scoring model. I know sometimes bootstrapping is used to produce confidence intervals - is there an expectation that bootstrapping or something similar would be used alongside producing any test set results?",3,4
208,2018-4-4,2018,4,4,18,89ntxt,[D] Does anyone here have experience outsourcing the design of NN architectures?,https://www.reddit.com/r/MachineLearning/comments/89ntxt/d_does_anyone_here_have_experience_outsourcing/,blobhammmer,1522832428,"As the title says I'm wondering if any of you gals/guys ever worked/work for a company that outsourced the design of any of your ML components. We're a small team in the computer vision startup that I work for and we're now at the point where we have to start rapidly developing solutions for constrained hardware platforms.

Of course the possibility of outsourcing some of the more tedious work has come up, none of us here are familiar with the ML outsourcing scene and all have different opinions on the subject.

I personally think there are a lot of people chancing their arm and just forking YOLO + some pretrained weights and doing transfer learning approaches with little understanding + ability of designing architectures. The space seems very bubblely at the moment with everyone hopping onto the deep learning bandwagon.

Does anyone here have experience with outsourcing? If so what are the pitfalls? Is it as much of a wild west scenario as I think?

If anyone has any recommendations for companies to check out then that would be appreciated as well.",1,1
209,2018-4-4,2018,4,4,18,89nu1q,Any journal papers on image/video generation?,https://www.reddit.com/r/MachineLearning/comments/89nu1q/any_journal_papers_on_imagevideo_generation/,xjwxjw,1522832470,[removed],0,1
210,2018-4-4,2018,4,4,18,89nwcx,How to use recent domain adaptation algorithms in the real applications?,https://www.reddit.com/r/MachineLearning/comments/89nwcx/how_to_use_recent_domain_adaptation_algorithms_in/,yuecao,1522833209,[removed],0,1
211,2018-4-4,2018,4,4,18,89nz7d,Clothing Recommendations using a Multi-Layer Neural Networks combined with an RBM. (feedback needed to improve),https://www.reddit.com/r/MachineLearning/comments/89nz7d/clothing_recommendations_using_a_multilayer/,Prykorr,1522834174,,0,1
212,2018-4-4,2018,4,4,18,89o30a,How would you tackle this challenge?,https://www.reddit.com/r/MachineLearning/comments/89o30a/how_would_you_tackle_this_challenge/,i-make-robots,1522835387,[removed],2,1
213,2018-4-4,2018,4,4,19,89o5co,[R] Super fast algorithm for solving inverse problems regularized with total variation,https://www.reddit.com/r/MachineLearning/comments/89o5co/r_super_fast_algorithm_for_solving_inverse/,maybelator,1522836147,,36,129
214,2018-4-4,2018,4,4,19,89o6gn,Review b khoan vn vt pin Dewalt DCD796M2 - diyhomedepot.vn,https://www.reddit.com/r/MachineLearning/comments/89o6gn/review_b_khoan_vn_vt_pin_dewalt_dcd796m2/,DIYhomedepot,1522836507,,1,0
215,2018-4-4,2018,4,4,19,89oegh,[NIPS 2017/Google] - Hiding Images in Plain Sight: Deep Steganography with Interactive Code,https://www.reddit.com/r/MachineLearning/comments/89oegh/nips_2017google_hiding_images_in_plain_sight_deep/,ThisisJae2,1522839013,,0,1
216,2018-4-4,2018,4,4,20,89ogkt,Microsoft is now offering public courses for building Artificial Intelligence skills,https://www.reddit.com/r/MachineLearning/comments/89ogkt/microsoft_is_now_offering_public_courses_for/,the_one_forever,1522839659,,0,1
217,2018-4-4,2018,4,4,20,89ojgp,[R] Predictions of the Near-Term Global Catastrophic Risks of Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/89ojgp/r_predictions_of_the_nearterm_global_catastrophic/,TheWayIFeelToday,1522840499,https://docs.google.com/document/d/1Gh5vJ52Zm3qLTKeyU77edQRpkMtOBjGj4xjoaLCXQJY/,0,0
218,2018-4-4,2018,4,4,20,89olm4,Any cooking recipes datasets available?,https://www.reddit.com/r/MachineLearning/comments/89olm4/any_cooking_recipes_datasets_available/,Schtecke,1522841091,[removed],0,1
219,2018-4-4,2018,4,4,21,89owgn,Machine Learning for Apps,https://www.reddit.com/r/MachineLearning/comments/89owgn/machine_learning_for_apps/,SmartUdemy,1522843967,,0,1
220,2018-4-4,2018,4,4,22,89p8rr,YOLOv3 in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/89p8rr/yolov3_in_tensorflow/,taehoonlee86,1522846916,,0,1
221,2018-4-4,2018,4,4,22,89p99s,How relevant is Andrew Ng's machine learning course when it comes to today's state of AI?,https://www.reddit.com/r/MachineLearning/comments/89p99s/how_relevant_is_andrew_ngs_machine_learning/,deeplearner93,1522847015,[removed],0,1
222,2018-4-4,2018,4,4,22,89p9r0,[P] Million Song Dataset Query Tool,https://www.reddit.com/r/MachineLearning/comments/89p9r0/p_million_song_dataset_query_tool/,dhruvmanchala,1522847125,[removed],0,1
223,2018-4-4,2018,4,4,22,89pc4k,This Machine Learning for Apps course focuses mainly how developer working with ML to their app,https://www.reddit.com/r/MachineLearning/comments/89pc4k/this_machine_learning_for_apps_course_focuses/,Deal5star,1522847660,[removed],2,1
224,2018-4-4,2018,4,4,22,89php8,"Neural nets only recently became practical, are there other aspects of neurological we aren't using that have potential?",https://www.reddit.com/r/MachineLearning/comments/89php8/neural_nets_only_recently_became_practical_are/,simstim_addict,1522848865,[removed],0,1
225,2018-4-4,2018,4,4,22,89pjni,Reverse Alphabet of the AI Hype,https://www.reddit.com/r/MachineLearning/comments/89pjni/reverse_alphabet_of_the_ai_hype/,cabichahine,1522849308,,0,1
226,2018-4-4,2018,4,4,22,89pmyi,"[R] Intelligent Edge: Building a Skin Cancer Prediction App with Azure Machine Learning, CoreML &amp; Xamarin",https://www.reddit.com/r/MachineLearning/comments/89pmyi/r_intelligent_edge_building_a_skin_cancer/,chris_shpak,1522849985,,0,1
227,2018-4-4,2018,4,4,23,89pr5k,[D] Help (re-)finding a tic-tac-toe reward hacking story,https://www.reddit.com/r/MachineLearning/comments/89pr5k/d_help_refinding_a_tictactoe_reward_hacking_story/,aaronsnoswell,1522850823,"In the past 6 months I heard a colloquial story about reward hacking in Reinforcement Learning somewhere, and I can't find the reference now.

In the story, students in a university computer science course were asked to write an AI to play an infinite-grid variant of tic-tac-toe. Their implementations were run competitively against one another at test time. One student used some sort of optimisation algorithm that discovered an awesome 'hack' - by placing a move very from the origin, often the opponent's code would run out of memory trying to process the move. As such, this would beat many opponents.

Very cool story, but I can't for the life of me find where I heard it. I think it might have been an r/MachineLearning post, or maybe during one of the ICML talks last year. Does anyone here know the story, and could you point me to it somewhere online?",4,6
228,2018-4-4,2018,4,4,23,89psyc,[P] LDA  How to grid search best topic models? (with complete examples in python),https://www.reddit.com/r/MachineLearning/comments/89psyc/p_lda_how_to_grid_search_best_topic_models_with/,selva86,1522851166,,0,22
229,2018-4-4,2018,4,4,23,89pta7,Do you think a PhD in this instance will provide accelerated career growth long term?,https://www.reddit.com/r/MachineLearning/comments/89pta7/do_you_think_a_phd_in_this_instance_will_provide/,[deleted],1522851228,,0,1
230,2018-4-4,2018,4,4,23,89pulu,"[R] So, You are Working on a Machine Learning Problem...",https://www.reddit.com/r/MachineLearning/comments/89pulu/r_so_you_are_working_on_a_machine_learning_problem/,trumtra,1522851473,,0,1
231,2018-4-4,2018,4,4,23,89pv03,[R] A Robust Real-Time Automatic License Plate Recognition based on the YOLO Detector (comprehensible paper with public dataset and weights),https://www.reddit.com/r/MachineLearning/comments/89pv03/r_a_robust_realtime_automatic_license_plate/,ghostzin,1522851550,,8,40
232,2018-4-4,2018,4,4,23,89px0n,[R] Data Correlation can make or break your Machine Learning Project,https://www.reddit.com/r/MachineLearning/comments/89px0n/r_data_correlation_can_make_or_break_your_machine/,janemoz,1522851996,,0,1
233,2018-4-5,2018,4,5,0,89q8ce,Interpreting visualization of feature vectors extracted from text,https://www.reddit.com/r/MachineLearning/comments/89q8ce/interpreting_visualization_of_feature_vectors/,wardengreams,1522854196,[removed],0,1
234,2018-4-5,2018,4,5,0,89qev7,[D] AlphaGo Zero Is Not a Sign of Imminent Human-Level AI,https://www.reddit.com/r/MachineLearning/comments/89qev7/d_alphago_zero_is_not_a_sign_of_imminent/,regalalgorithm,1522855450,,2,0
235,2018-4-5,2018,4,5,0,89qpie,"Simple Questions Thread April 04, 2018",https://www.reddit.com/r/MachineLearning/comments/89qpie/simple_questions_thread_april_04_2018/,AutoModerator,1522857341,[removed],0,1
236,2018-4-5,2018,4,5,1,89r10m,[P] Google Colaboratory: Automatic Tensorflow/Keras Checkpoints in your Google Drive,https://www.reddit.com/r/MachineLearning/comments/89r10m/p_google_colaboratory_automatic_tensorflowkeras/,Zahlii,1522859375,,8,54
237,2018-4-5,2018,4,5,1,89rai7,"""Depthwise separable convolutions for machine learning"": an explanation in NumPy",https://www.reddit.com/r/MachineLearning/comments/89rai7/depthwise_separable_convolutions_for_machine/,gwern,1522861133,,0,1
238,2018-4-5,2018,4,5,2,89recj,"[D] If I could synthesize any high quality image data set for you with class/feature point/mask annotations, what would pick?",https://www.reddit.com/r/MachineLearning/comments/89recj/d_if_i_could_synthesize_any_high_quality_image/,[deleted],1522861825,[deleted],0,1
239,2018-4-5,2018,4,5,2,89rf35,"[D] If I could synthesize any high quality image data set for you with class/feature point/mask annotations, what would you pick?",https://www.reddit.com/r/MachineLearning/comments/89rf35/d_if_i_could_synthesize_any_high_quality_image/,hwoolery,1522861959,"I've been working on high quality, 3D synthesis of feature points on the hand for training my network, but could likely apply the technique to any 3D object. I can generate hundreds of thousands of images/annotations in very little time. Optionally, what would you be willing to pay to license or purchase the generated data?",16,5
240,2018-4-5,2018,4,5,2,89rinr,Lyme disease (erythema migrans) image dataset,https://www.reddit.com/r/MachineLearning/comments/89rinr/lyme_disease_erythema_migrans_image_dataset/,ahmadchan,1522862596,[removed],0,1
241,2018-4-5,2018,4,5,3,89rvdc,Career advice for academia/industry,https://www.reddit.com/r/MachineLearning/comments/89rvdc/career_advice_for_academiaindustry/,vdua,1522864870,[removed],0,1
242,2018-4-5,2018,4,5,3,89rwnt,[R] Illustrated History of Machine Translation: From Cold War to Deep Learning,https://www.reddit.com/r/MachineLearning/comments/89rwnt/r_illustrated_history_of_machine_translation_from/,sneks,1522865108,,0,2
243,2018-4-5,2018,4,5,3,89s2h3,"The Annotated Transformer: Line-by-Line PyTorch implementation of ""Attention is All You Need""",https://www.reddit.com/r/MachineLearning/comments/89s2h3/the_annotated_transformer_linebyline_pytorch/,harvardnlp,1522866123,,0,3
244,2018-4-5,2018,4,5,3,89s860,Making AI Interpretable with Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/89s860/making_ai_interpretable_with_generative/,andras_k,1522867162,,0,1
245,2018-4-5,2018,4,5,3,89sazd,[D] Looking to connect with Java Machine Learners,https://www.reddit.com/r/MachineLearning/comments/89sazd/d_looking_to_connect_with_java_machine_learners/,[deleted],1522867661,[deleted],0,1
246,2018-4-5,2018,4,5,4,89sgue,[D] Looking to connect with Java Machine Learners,https://www.reddit.com/r/MachineLearning/comments/89sgue/d_looking_to_connect_with_java_machine_learners/,aaanwar,1522868718,"Hi,
I'd like to connect with folks who use, or would like to use, Java for Machine Learning.
I wanted to exchange ideas on why they think Java is, or is not suitable for statical machine learning.
Cheers!
",33,3
247,2018-4-5,2018,4,5,5,89tcxo,How to annotate my video dataset?,https://www.reddit.com/r/MachineLearning/comments/89tcxo/how_to_annotate_my_video_dataset/,kushaj,1522874979,[removed],0,1
248,2018-4-5,2018,4,5,6,89tka7,Looking for work related on machine learning for space optimization.,https://www.reddit.com/r/MachineLearning/comments/89tka7/looking_for_work_related_on_machine_learning_for/,[deleted],1522876340,,0,1
249,2018-4-5,2018,4,5,6,89tl8a,[R] Hopkins faculty promote better climate in machine learning,https://www.reddit.com/r/MachineLearning/comments/89tl8a/r_hopkins_faculty_promote_better_climate_in/,downtownslim,1522876547,,0,0
250,2018-4-5,2018,4,5,6,89tuyn,"AI Grant 3.0: get get $2500 cash and $20,000 in GPU credits for your AI project",https://www.reddit.com/r/MachineLearning/comments/89tuyn/ai_grant_30_get_get_2500_cash_and_20000_in_gpu/,[deleted],1522878326,,0,1
251,2018-4-5,2018,4,5,6,89tyrf,"AI Grant 2.0: get $2500 cash and $20,000 in GPU credits for your AI project",https://www.reddit.com/r/MachineLearning/comments/89tyrf/ai_grant_20_get_2500_cash_and_20000_in_gpu/,complexmaximizer,1522879004,[removed],0,1
252,2018-4-5,2018,4,5,6,89tzsy,[R] CFP: KDD 2018 Workshop on Outlier Detection De-constructed,https://www.reddit.com/r/MachineLearning/comments/89tzsy/r_cfp_kdd_2018_workshop_on_outlier_detection/,burnaevevgeny,1522879196,,3,1
253,2018-4-5,2018,4,5,8,89ujk0,"[N] AI Grant 3.0: $2500 in cash and $20,000 in cloud credits. Apply by April 14th!",https://www.reddit.com/r/MachineLearning/comments/89ujk0/n_ai_grant_30_2500_in_cash_and_20000_in_cloud/,nataigrant,1522883183,"Hi, /r/ml!

Last year my friend Daniel and I launched http://aigrant.org to give away money to people doing interesting open source AI projects. We gave out $100,000 in grants to 30 different projects. You can see some of the winners here: http://aigrant.org/#finalists

We're launching another round of AI Grant. This time, we're giving away up to 30 grants. We reduced the cash amount to $2500, but Google has stepped in to sponsor $20,000 per grantee in GCE credits, which is phenomenal.

The program is open to anyone; no credentials required. We tried to keep the application process as simple as possible so that you can apply in 30 minutes instead of spending days writing a grant proposal. You can apply at https://aigrant.org/apply.html

Applications are due April 14th. We'd be happy to answer questions and would welcome any feedback or ideas.

Thanks!",16,97
254,2018-4-5,2018,4,5,9,89uy75,"[P] The Annotated Transformer: Line-by-Line PyTorch implementation of ""Attention is All You Need""",https://www.reddit.com/r/MachineLearning/comments/89uy75/p_the_annotated_transformer_linebyline_pytorch/,hardmaru,1522886419,,12,224
255,2018-4-5,2018,4,5,9,89v1g8,[P] Intro to XGBoost (detecting Parkinson's with XGBoost Classifiers),https://www.reddit.com/r/MachineLearning/comments/89v1g8/p_intro_to_xgboost_detecting_parkinsons_with/,woodworksio,1522887142,,1,4
256,2018-4-5,2018,4,5,9,89v7s2,Need help finding papers/work on unused space/area minimization with arbitrary factors.,https://www.reddit.com/r/MachineLearning/comments/89v7s2/need_help_finding_paperswork_on_unused_spacearea/,OutOfApplesauce,1522888578,[removed],0,1
257,2018-4-5,2018,4,5,10,89vg84,[D] Preventing exploding gradients when using ReLU?,https://www.reddit.com/r/MachineLearning/comments/89vg84/d_preventing_exploding_gradients_when_using_relu/,ConfuciusBateman,1522890578,"In something I'm currently working on, I've found that switching out my ReLU activations for sigmoids actually ends up letting my network perform better (on MNIST, which is what I'm testing things on). I have found that using ReLU activations, my gradients start to explode quickly and everything NaNs out.

I've tried searching around and I don't see too many people talking about ReLUs causing gradients to explode, but I don't think there's anything wrong with my implementation so I'm wondering if there are any strategies I can look into to see how to control these gradient values, as I'd prefer to use ReLU over sigmoid in general.

TLDR: I was trying to use ReLU activations with softmax + cross entropy at the output, found that gradients were exploding. Switched to sigmoids and everything calmed down and worked better, but want to figure out how I can tame the gradients using ReLUs.",17,13
258,2018-4-5,2018,4,5,10,89vp9y,How to make your Software Development experience painless.,https://www.reddit.com/r/MachineLearning/comments/89vp9y/how_to_make_your_software_development_experience/,snazrul,1522892706,,0,1
259,2018-4-5,2018,4,5,11,89w12x,Can I use the instance norm for image classification problems?,https://www.reddit.com/r/MachineLearning/comments/89w12x/can_i_use_the_instance_norm_for_image/,[deleted],1522895447,,0,1
260,2018-4-5,2018,4,5,11,89w1fk,[D] Can I use the Instance Norm for image classification problems?,https://www.reddit.com/r/MachineLearning/comments/89w1fk/d_can_i_use_the_instance_norm_for_image/,taki0112,1522895535,"Hi

In general, for image classification problems, use the batch norm. But I wonder if using the instance norm will result in poor performance? I wonder if anyone has tried it.",0,1
261,2018-4-5,2018,4,5,11,89w4u6,"[D] Question - Does having shared weights make runtime faster (from an implementation standpoint), or is the benefit just for faster training?",https://www.reddit.com/r/MachineLearning/comments/89w4u6/d_question_does_having_shared_weights_make/,soulslicer0,1522896348,"As above. What are the main advantages for having shared weights, say in a recurrent structure. For runtime. Does it use less memory? Will it run faster? For training. Will it train faster since its more constrained?",2,3
262,2018-4-5,2018,4,5,13,89wvqv,Deep learning for CS:GO cheat detection,https://www.reddit.com/r/MachineLearning/comments/89wvqv/deep_learning_for_csgo_cheat_detection/,HumanTeacher,1522903363,,0,1
263,2018-4-5,2018,4,5,14,89x2d3,Six artificial intelligence apps that will help you reach your goals,https://www.reddit.com/r/MachineLearning/comments/89x2d3/six_artificial_intelligence_apps_that_will_help/,syedali96,1522905342,,0,1
264,2018-4-5,2018,4,5,14,89x5nt,One advice for someone starting out on their first GAN project...,https://www.reddit.com/r/MachineLearning/comments/89x5nt/one_advice_for_someone_starting_out_on_their/,domarps123,1522906354,[removed],0,1
265,2018-4-5,2018,4,5,15,89xc92,[R] The Emergence of Spectral Universality in Deep Networks,https://www.reddit.com/r/MachineLearning/comments/89xc92/r_the_emergence_of_spectral_universality_in_deep/,reninsuture,1522908443,,3,13
266,2018-4-5,2018,4,5,15,89xls4,We work for Google. It shouldn't be in the business of war | Open letter signed by Google employees,https://www.reddit.com/r/MachineLearning/comments/89xls4/we_work_for_google_it_shouldnt_be_in_the_business/,durand101,1522911553,,0,1
267,2018-4-5,2018,4,5,16,89xmhr,Any machine learning advice for automatically determining who broke the build?,https://www.reddit.com/r/MachineLearning/comments/89xmhr/any_machine_learning_advice_for_automatically/,ABlindWanderer,1522911783,[removed],0,1
268,2018-4-5,2018,4,5,16,89xruh,Dummy variable trap,https://www.reddit.com/r/MachineLearning/comments/89xruh/dummy_variable_trap/,rakshith291,1522913634,[removed],0,1
269,2018-4-5,2018,4,5,16,89xsng,[N] Google Staffers Demand End to Work on Pentagon AI project,https://www.reddit.com/r/MachineLearning/comments/89xsng/n_google_staffers_demand_end_to_work_on_pentagon/,phobrain,1522913961,,127,263
270,2018-4-5,2018,4,5,17,89xzm3,[R] ADDING GRADIENT NOISE IMPROVES LEARNING FOR VERY DEEP NETWORKS,https://www.reddit.com/r/MachineLearning/comments/89xzm3/r_adding_gradient_noise_improves_learning_for/,reninsuture,1522916558,,1,0
271,2018-4-5,2018,4,5,18,89y8w8,Adding Gradient Noise Improves Learning for Very Deep Networks,https://www.reddit.com/r/MachineLearning/comments/89y8w8/adding_gradient_noise_improves_learning_for_very/,reninsuture,1522920065,,0,1
272,2018-4-5,2018,4,5,18,89y8zv,Stochastic Adversarial Video Prediction,https://www.reddit.com/r/MachineLearning/comments/89y8zv/stochastic_adversarial_video_prediction/,aravindsrinivas,1522920098,,0,1
273,2018-4-5,2018,4,5,18,89yebr,[P] Korean Single speaker Speech Dataset,https://www.reddit.com/r/MachineLearning/comments/89yebr/p_korean_single_speaker_speech_dataset/,longinglove,1522922033,,1,13
274,2018-4-5,2018,4,5,19,89yjh3,Top 7 Data Science Use Cases in Healthcare,https://www.reddit.com/r/MachineLearning/comments/89yjh3/top_7_data_science_use_cases_in_healthcare/,bgrebeniuk,1522923756,,0,2
275,2018-4-5,2018,4,5,19,89ymyj,What's missing from competitive machine learning platforms like Kaggle/Quantopian/etc?,https://www.reddit.com/r/MachineLearning/comments/89ymyj/whats_missing_from_competitive_machine_learning/,rosstaylor90,1522924898,[removed],0,1
276,2018-4-5,2018,4,5,19,89yniv,"[R] The Tsetlin Machine - an alernative to articicial neurons - outperforms Neural Networks, SVMs, Random Forests, the Naive Bayes Classifier and Logistic Regression",https://www.reddit.com/r/MachineLearning/comments/89yniv/r_the_tsetlin_machine_an_alernative_to_articicial/,[deleted],1522925085,[deleted],1,1
277,2018-4-5,2018,4,5,19,89yp8g,"[R] The Tsetlin Machine - a new approach to ML - outperforms Neural Networks, SVMs, Random Forests, the Naive Bayes Classifier and Logistic Regression",https://www.reddit.com/r/MachineLearning/comments/89yp8g/r_the_tsetlin_machine_a_new_approach_to_ml/,gaau,1522925694,,43,47
278,2018-4-5,2018,4,5,19,89ypi5,Label Propagation in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/89ypi5/label_propagation_in_tensorflow/,negazirana,1522925769,,0,1
279,2018-4-5,2018,4,5,20,89yqfd,[Q] Anyone have an papper about Statistics Inference that's also useful to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/89yqfd/q_anyone_have_an_papper_about_statistics/,mateusmaia11,1522926106,[removed],0,1
280,2018-4-5,2018,4,5,20,89yrho,What progression of proofs does modern machine learning need make the field rigorous again?,https://www.reddit.com/r/MachineLearning/comments/89yrho/what_progression_of_proofs_does_modern_machine/,Turings_Ego,1522926405,[removed],0,2
281,2018-4-5,2018,4,5,21,89z8q2,[R] Supervised vs. Unsupervised Learning,https://www.reddit.com/r/MachineLearning/comments/89z8q2/r_supervised_vs_unsupervised_learning/,digitalson,1522931109,,0,1
282,2018-4-5,2018,4,5,21,89zdiq,Five Steps to help your organisation implement Machine Learning technologies,https://www.reddit.com/r/MachineLearning/comments/89zdiq/five_steps_to_help_your_organisation_implement/,adolfo2582,1522932310,,0,1
283,2018-4-5,2018,4,5,21,89zgjy,"How do people make a classifier for 1000, 10,000 or even 1,000,000+ classes?",https://www.reddit.com/r/MachineLearning/comments/89zgjy/how_do_people_make_a_classifier_for_1000_10000_or/,thisisalmostooreal,1522933043,[removed],0,1
284,2018-4-5,2018,4,5,22,89zigj,[R] Training Tips for the Transformer Model,https://www.reddit.com/r/MachineLearning/comments/89zigj/r_training_tips_for_the_transformer_model/,trowway1239,1522933517,,1,2
285,2018-4-5,2018,4,5,22,89zjgl,[R] Simple Group-Norm experiments on MNIST,https://www.reddit.com/r/MachineLearning/comments/89zjgl/r_simple_groupnorm_experiments_on_mnist/,brainggear,1522933722,,0,2
286,2018-4-5,2018,4,5,22,89zqr3,"[N] Weekly Machine Learning Opensource Roundup  Apr. 5, 2018",https://www.reddit.com/r/MachineLearning/comments/89zqr3/n_weekly_machine_learning_opensource_roundup_apr/,stkim1,1522935371,,0,1
287,2018-4-5,2018,4,5,22,89zrjj,[R] CrowdFlower Unveils New Machine Learning Solutions; Changes Name to Figure Eight,https://www.reddit.com/r/MachineLearning/comments/89zrjj/r_crowdflower_unveils_new_machine_learning/,friscotime,1522935545,,0,1
288,2018-4-5,2018,4,5,22,89zut8,Multi-Variable Gradient Descent using Numpy - Error,https://www.reddit.com/r/MachineLearning/comments/89zut8/multivariable_gradient_descent_using_numpy_error/,khamzah22,1522936288,[removed],0,1
289,2018-4-5,2018,4,5,22,89zwsi,[D] How to (actually) easily detect objects with deep learning,https://www.reddit.com/r/MachineLearning/comments/89zwsi/d_how_to_actually_easily_detect_objects_with_deep/,brnko,1522936715,,4,11
290,2018-4-5,2018,4,5,23,8a0053,Integrated Bias on gbrain,https://www.reddit.com/r/MachineLearning/comments/8a0053/integrated_bias_on_gbrain/,3droberto,1522937401,,0,1
291,2018-4-5,2018,4,5,23,8a0aeg,Comet.ml - Automatically tracking of Machine Learning Experiments,https://www.reddit.com/r/MachineLearning/comments/8a0aeg/cometml_automatically_tracking_of_machine/,gidime,1522939542,[removed],0,1
292,2018-4-6,2018,4,6,0,8a0g3v,[News] Comet.ml - Automatically tracking of Machine Learning Experiments,https://www.reddit.com/r/MachineLearning/comments/8a0g3v/news_cometml_automatically_tracking_of_machine/,gidime,1522940642,"Hi, We built comet.ml to allow machine learning engineers to automatically track their machine learning code, experiments, hyperparameters and results. We're officially out of beta and would love your feedback! Comet is free for public/open source projects and students. It's really easy to use and works no matter where you train your models.

I'm one of the founders so AMA!

http://www.comet.ml",31,85
293,2018-4-6,2018,4,6,0,8a0m9u,"[D] Beginner question: Is this laptop viable for learning and testing neural nets and deep learning? (i7 5700Q, NVIDIA GT 740M 2GB)",https://www.reddit.com/r/MachineLearning/comments/8a0m9u/d_beginner_question_is_this_laptop_viable_for/,arostrat,1522941868,"The GT 740M supports CUDA compute capability level 3.0, so at least it supports tensforflow. But would like to know what times to expect when training some models (e.g. ImageNet, Coco)? And would I face any crippling limitations? Thanks in advance.",26,2
294,2018-4-6,2018,4,6,1,8a145y,"[P] Implementation and reproducible code for deep learning papers on NLP(QA, sentence matching, attention, knowledge base completion), CV(transfer learning, multi-modal learning), Audio(scene recognition, tagging).",https://www.reddit.com/r/MachineLearning/comments/8a145y/p_implementation_and_reproducible_code_for_deep/,[deleted],1522945385,[deleted],0,1
295,2018-4-6,2018,4,6,1,8a15b0,"DeepLearn - Implementation and reproducible code for deep learning papers on NLP(QA, sentence matching, attention, knowledge base completion), CV(transfer learning, multi-modal learning), Audio(scene recognition, tagging).",https://www.reddit.com/r/MachineLearning/comments/8a15b0/deeplearn_implementation_and_reproducible_code/,[deleted],1522945595,[deleted],0,1
296,2018-4-6,2018,4,6,1,8a16ce,"[P] DeepLearn - Implementation and reproducible code for deep learning papers on NLP(QA, sentence matching, attention, knowledge base completion), CV(transfer learning, multi-modal learning), Audio(scene recognition, tagging).",https://www.reddit.com/r/MachineLearning/comments/8a16ce/p_deeplearn_implementation_and_reproducible_code/,bhatt_gaurav,1522945802,,0,7
297,2018-4-6,2018,4,6,1,8a18j4,[P] Live stream of neural network learning to play Minecraft! (Behavioral cloning),https://www.reddit.com/r/MachineLearning/comments/8a18j4/p_live_stream_of_neural_network_learning_to_play/,MadcowD,1522946245,,12,72
298,2018-4-6,2018,4,6,1,8a1f15,China has a new plan to create an army of AI researchers,https://www.reddit.com/r/MachineLearning/comments/8a1f15/china_has_a_new_plan_to_create_an_army_of_ai/,[deleted],1522947527,[deleted],0,1
299,2018-4-6,2018,4,6,2,8a1gtm,MI with python,https://www.reddit.com/r/MachineLearning/comments/8a1gtm/mi_with_python/,tomasz2101,1522947830,[removed],0,1
300,2018-4-6,2018,4,6,2,8a1h22,How to select features for clustering to detect the number of different unique products in a search result?,https://www.reddit.com/r/MachineLearning/comments/8a1h22/how_to_select_features_for_clustering_to_detect/,letsgodevils123,1522947867,[removed],0,1
301,2018-4-6,2018,4,6,2,8a1ouz,[N] China has a new plan to create an army of AI researchers,https://www.reddit.com/r/MachineLearning/comments/8a1ouz/n_china_has_a_new_plan_to_create_an_army_of_ai/,iidealized,1522949369,,5,0
302,2018-4-6,2018,4,6,2,8a1wdj,Advanced AI: Deep Reinforcement Learning in Python. You can buy now this course at price $12.99,https://www.reddit.com/r/MachineLearning/comments/8a1wdj/advanced_ai_deep_reinforcement_learning_in_python/,[deleted],1522950818,[deleted],0,1
303,2018-4-6,2018,4,6,2,8a1y9b,[P] Unsupervised Facial Image Clustering with Autoencoders and Attention Maps,https://www.reddit.com/r/MachineLearning/comments/8a1y9b/p_unsupervised_facial_image_clustering_with/,mind_puzzle,1522951170,,0,2
304,2018-4-6,2018,4,6,3,8a21sq,[D] Retro Contest | OpenAI,https://www.reddit.com/r/MachineLearning/comments/8a21sq/d_retro_contest_openai/,sksq9,1522951813,,34,152
305,2018-4-6,2018,4,6,3,8a2376,I made my very first machine learning post / tutorial on backpropagation - I would appreciate any feedback.,https://www.reddit.com/r/MachineLearning/comments/8a2376/i_made_my_very_first_machine_learning_post/,nzakar17,1522952088,[removed],0,1
306,2018-4-6,2018,4,6,3,8a255v,"Get $2,500 in cash for your open source AI project",https://www.reddit.com/r/MachineLearning/comments/8a255v/get_2500_in_cash_for_your_open_source_ai_project/,caligolae,1522952489,,0,1
307,2018-4-6,2018,4,6,3,8a2h5f,[D] Self-teaching more advanced math required for ML/DL research,https://www.reddit.com/r/MachineLearning/comments/8a2h5f/d_selfteaching_more_advanced_math_required_for/,progfu,1522954772,"I just started doing my Masters in AI this year after finishing a CS bachelor, and am intending to most likely continue on with a PhD in ML/DL (if I can). The problem is, now that I'm finally getting deep into studying ML/DL materials I'm finding that my math skills are really not good enough.

To give a specific example, I just started reading [Machine Learning: A Probabilistic Perspective](https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020). Prior to picking this up, I also looked at the wildly praised Bishop's Pattern Recognition and the Elements of Statistical Learning, but it felt that the book I picked best matched the things I don't know about / want to learn.

But just as I'm working through the probability refresher chapter, I'm starting to feel my usual ""I should know more about this"" feeling. To be extra specific, just the mention of student's/laplace/gamma/beta distributions are something I never experienced in my previous studies. Or things like multi-variate distributions. Or even something like hypothesis testing is something that was almost untouched during my undergrad.

To give another example, I've been trying to catch up on the recent DL papers and most of the time I don't have trouble with the math, but last week I was reading the Wasserstein GAN paper and just a mention of Lipschitz continuity makes me feel like a first year undergrad.

There are many more things I could list, but you probably get the general idea.

To put this in more perspective, my undergrad was quite math-ish, yet there are things that clearly weren't covered, or they were and I have no intuition of them. There also aren't really any more courses I can take that teach more of the advanced stuff without actually taking classes with the math majors at a different faculty.

The reason I'm saying all of this, is that I can't really imagine myself finishing my thesis next year and going into a PhD where it might be expected of me to write a paper like the WGAN one.

I'm not sure how this compares to US, though I asked my professor at a deep learning seminar and he basically said that he knows of one university in Switzerland that teaches DL with lots of applied theory, and that otherwise there isn't really any course I can take to learn the more advanced stuff in probability / linear algebra / calculus.

For example, in my two probability courses we covered stuff like basic probability theory, and then moved on to markov chains, bits of queue theory, bits of poisson processes. But looking at the ML: A Prob Perspective book, it feels as if I had only taken the most basic probability theory. In Linear algebra, we did all the basic stuff, all the fun decompositions (SVD, QR, LU), eigenvalues, orthogonal matrices, etc., but we didn't touch any vector calculus, and I don't really have any intuition for any of the more advanced stuff, other than understanding the definitions/proofs. As for calculus, we kinda ended with Lagrange multipliers and did a bit about theory of metric spaces, but again, reading most of the papers, I feel like knowing what a Jacobian is is the only useful thing I know.

Any tips on how I should continue? What books to read? What online courses to take? What videos to watch?",46,137
308,2018-4-6,2018,4,6,4,8a2l7e,[R]https://aeon.co/videos/a-neural-network-that-keeps-seeing-art-where-we-see-mundane-objects,https://www.reddit.com/r/MachineLearning/comments/8a2l7e/rhttpsaeoncovideosaneuralnetworkthatkeepsseeingart/,finallyifoundvalidUN,1522955543,,1,28
309,2018-4-6,2018,4,6,4,8a2mp8,[D] Why do some authors publish their codes to GitHub months after the paper was submitted to arXiv?,https://www.reddit.com/r/MachineLearning/comments/8a2mp8/d_why_do_some_authors_publish_their_codes_to/,HigherTopoi,1522955846,"Why is this the case? I don't think it should take more than two weeks to polish their codes to publish them on GitHub, but I very frequently observe the cases such that the codes are published more than 3 months later or never published. At the very least, unpolished codes should be published soon after paper submission. Is intentionally delaying publishing codes or not publishing at all beneficial for the authors because they have an advantage in pursuing sequels of the study by forming a monopoly? Isn't it unethical? Is there any community's attempt to discourage such behaviors? What are some justifications for not publishing codes?",13,5
310,2018-4-6,2018,4,6,4,8a2ugr,Software Development Design Principles,https://www.reddit.com/r/MachineLearning/comments/8a2ugr/software_development_design_principles/,snazrul,1522957418,,0,1
311,2018-4-6,2018,4,6,4,8a2w1m,NEAT and One VS Rest,https://www.reddit.com/r/MachineLearning/comments/8a2w1m/neat_and_one_vs_rest/,raptor0816,1522957727,[removed],0,1
312,2018-4-6,2018,4,6,4,8a2y51,"[R] Gotta Learn Fast: A New Benchmark for Generalization in RL (OpenAI, PDF)",https://www.reddit.com/r/MachineLearning/comments/8a2y51/r_gotta_learn_fast_a_new_benchmark_for/,wei_jok,1522958150,,0,13
313,2018-4-6,2018,4,6,5,8a3aj9,[D] EFF commentary on Google's military AI contracts,https://www.reddit.com/r/MachineLearning/comments/8a3aj9/d_eff_commentary_on_googles_military_ai_contracts/,pde,1522960575,,2,2
314,2018-4-6,2018,4,6,5,8a3bu7,[D] Poisoning attacks against neural networks,https://www.reddit.com/r/MachineLearning/comments/8a3bu7/d_poisoning_attacks_against_neural_networks/,ConfuciusBateman,1522960830,"I'm wondering what current approaches are towards this problem in an adversarial distributed ML context.

One paper I came across attempts to group gradients into ""indicative features"" that exhibit a certain distribution in a non-attack setting, and compare incoming gradients against this distribution and reject them if they appear to be significant outliers.

This approach seems like it would be difficult to make work in a scenario where a given ""learner"" (assuming some kind of distributed or peer-to-peer network where nodes learn collaboratively) only has access to a subset of a global dataset, and thus can't know what the expected distribution is for a gradient that was produced by training on data it has never seen. 

I suppose this problem could maybe be attended to by polling peers to see if anyone else has knowledge about this kind of data?

Another approach I considered was simply rejecting proposed weight updates if the update would cause loss to go up. But again this seems like it would only really work if each node/learner has access to the same validation set that is representative of the global dataset. Would also be problematic in the sense that sometimes a slight loss increase is just a natural part of stochastic gradient descent.

In distributed ML settings, what are common approaches to defending against malicious nodes seeking to subvert the overall learning process via poisoning?",3,6
315,2018-4-6,2018,4,6,5,8a3f5f,Designing adversarial chess pieces,https://www.reddit.com/r/MachineLearning/comments/8a3f5f/designing_adversarial_chess_pieces/,AllWoolEverything,1522961502,[removed],0,1
316,2018-4-6,2018,4,6,6,8a3jle,[D] Designing adversarial chess pieces,https://www.reddit.com/r/MachineLearning/comments/8a3jle/d_designing_adversarial_chess_pieces/,AllWoolEverything,1522962380,"Hi! Let me preface this by letting you know that I'm an industrial design student with only a shallow understanding ofcomputer vision, ML and neural networks.  I'vebeengiventhebriefofdesigning asetofchesspiecesto bemadebyaluminumextrusion(thesamemethodused inmakingpasta).

OneoftheconceptsI amresearching, is to designchesspiecesthatwouldfool a computer vision program in a traditional CV chess seutp. The line of though is, that since computers are able to beat humans in chess, and now even inthegame go, we could ""fight back"" by utilizing ourhigh fidelitysenses.I understand that this ""man vs machine"" trope is kind of silly, but I think it would help the layman awareness of compter vision. Theproject would be adiscursivedesign project, whose aim would be to spread knowledge about thehowsand whys of computer vision. Computers ""see"" the world very differently from us, and what might seem obvious for us, can be overwhelmingly confusing for a computer. I think this is aninterestingnotion, that not many casual observers of computer vision and AI technology are aware of.

I have spent a little time reading about computer vision and it application in identifying chess pieces. As far as I understand, this involves some sort of edge detection to separate thepiecesfrom the board, and to identify the individual pieces. I also find the concepts of adversarial images very interesting, as discussed inthesearticles:https://www.theverge.com/2017/4/12/15271874/ai-adversarial-images-fooling-attacks-artificial-intelligencehttps://www.theverge.com/2017/11/2/16597276/google-ai-image-attacks-adversarial-turtle-rifle-3d-printed

Designing a unique looking set of chess pieces would of course fool a program trained on images of conventional chess sets, but I figure that it would be no hassle for it to retrain as long as it could distinguish the new pieces. I'm hoping to design pieces that a neural network would struggle to learn.The first article is how I came across your work. Do you think this is a feasible concept, and what do you thinkis the best strategy to ""counter"" computer vision and machine learning? ",5,3
317,2018-4-6,2018,4,6,6,8a3tbl,[P] A birds-eye view of optimization algorithms,https://www.reddit.com/r/MachineLearning/comments/8a3tbl/p_a_birdseye_view_of_optimization_algorithms/,hardmaru,1522964361,,1,21
318,2018-4-6,2018,4,6,6,8a3uft,"[D] Machine Learning Summer School at Madrid, Spain",https://www.reddit.com/r/MachineLearning/comments/8a3uft/d_machine_learning_summer_school_at_madrid_spain/,blitzzerg,1522964590,"What are your thoughts on it?

http://mlss.ii.uam.es/mlss2018/index.html

From the webpage:

&gt; The Machine Learning Summer School (MLSS) will be held at Universidad Autnoma de Madrid, Spain, from Aug. 27 to Sep. 7, 2018 .

&gt; The MLSS is a course promulgating modern methods of statistical machine learning and inference. While students and professionals are eager to learn about machine learning, only few machine learning courses are taught at universities. The MLSS aims at filling this demand by presenting topics which are at the core of modern machine learning, from fundamentals to state-of-the-art practice. The MLSS is offered mostly to graduate students, but also to researchers and professionals.

&gt; The MLSS speakers are leading experts in their respective field and/or world-recognized professionals from the industry, who explain and talk with enthusiasm about advanced concepts related to, but not limited to, machine learning, data analysis and inference. As in previous editions, we are very happy to announce a set of highly acclaimed speakers.
",2,2
319,2018-4-6,2018,4,6,6,8a3wfk,[R] Error Curvature Optimization: Alternative to first-order derivative learning,https://www.reddit.com/r/MachineLearning/comments/8a3wfk/r_error_curvature_optimization_alternative_to/,morpheby,1522964996,,7,2
320,2018-4-6,2018,4,6,7,8a411a,Machine Learning for BI/Reporting Analyst?,https://www.reddit.com/r/MachineLearning/comments/8a411a/machine_learning_for_bireporting_analyst/,TechyAccountant,1522965940,[removed],0,1
321,2018-4-6,2018,4,6,8,8a4llp,[D] Machine Learning Glossary | Google Developers,https://www.reddit.com/r/MachineLearning/comments/8a4llp/d_machine_learning_glossary_google_developers/,sksq9,1522970391,,1,41
322,2018-4-6,2018,4,6,10,8a5bsg,Cuttlefish: A Lightweight Primitive for Adaptive Query Processing and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8a5bsg/cuttlefish_a_lightweight_primitive_for_adaptive/,dac22219,1522976469,,0,1
323,2018-4-6,2018,4,6,10,8a5kj8,[R] The Kanerva Machine: A Generative Distributed Memory,https://www.reddit.com/r/MachineLearning/comments/8a5kj8/r_the_kanerva_machine_a_generative_distributed/,baylearn,1522978619,,2,21
324,2018-4-6,2018,4,6,10,8a5puu,[project] Check out this visualization of the Newton Raphson method created using my open source library - https://github.com/ryu577/pyray,https://www.reddit.com/r/MachineLearning/comments/8a5puu/project_check_out_this_visualization_of_the/,rohitpandey576,1522979858,,0,22
325,2018-4-6,2018,4,6,11,8a5usa,The DOs and DONTs of Principal Component Analysis,https://www.reddit.com/r/MachineLearning/comments/8a5usa/the_dos_and_donts_of_principal_component_analysis/,snazrul,1522981039,,0,1
326,2018-4-6,2018,4,6,12,8a6d0v,[D] The Scientific Paper Is Obsolete. Here's What's Next.,https://www.reddit.com/r/MachineLearning/comments/8a6d0v/d_the_scientific_paper_is_obsolete_heres_whats/,inarrears,1522985668,,2,2
327,2018-4-6,2018,4,6,12,8a6e3d,[P] Cuttlefish: A Lightweight Primitive for Adaptive Query Processing and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8a6e3d/p_cuttlefish_a_lightweight_primitive_for_adaptive/,dac22219,1522985955,,1,11
328,2018-4-6,2018,4,6,13,8a6lx1,"Craft beer names, invented by neural network",https://www.reddit.com/r/MachineLearning/comments/8a6lx1/craft_beer_names_invented_by_neural_network/,pacmanisfun,1522988094,,0,1
329,2018-4-6,2018,4,6,13,8a6ody,[D] Cremer et al. Inference Suboptimality in Variational Autoencoders - how was figure 2 computed?,https://www.reddit.com/r/MachineLearning/comments/8a6ody/d_cremer_et_al_inference_suboptimality_in/,AloneStretch,1522988797,"Figure 2 in this paper shows the ""True posterior"" of a VAE.

How could they have computed this?  Some of you experts probably have a strong guess.

I thought the motivation for VAE is because the posterior (among other things) is truly difficult to compute?
",5,4
330,2018-4-6,2018,4,6,13,8a6q1w,Ideas for a class project!,https://www.reddit.com/r/MachineLearning/comments/8a6q1w/ideas_for_a_class_project/,xpbit1024,1522989285,[removed],0,1
331,2018-4-6,2018,4,6,14,8a6xhg,"Using computer vision, what's the best algorithm to detect shapeless objects such as fire, smoke, water, fog, etc?",https://www.reddit.com/r/MachineLearning/comments/8a6xhg/using_computer_vision_whats_the_best_algorithm_to/,sudopods,1522991489,[removed],0,2
332,2018-4-6,2018,4,6,14,8a71tx,Advanced AI: Deep Reinforcement Learning in Python,https://www.reddit.com/r/MachineLearning/comments/8a71tx/advanced_ai_deep_reinforcement_learning_in_python/,[deleted],1522992859,[deleted],0,1
333,2018-4-6,2018,4,6,14,8a74bi,How do you deal with floating point roundoff error?,https://www.reddit.com/r/MachineLearning/comments/8a74bi/how_do_you_deal_with_floating_point_roundoff_error/,frozenca,1522993652,[removed],10,7
334,2018-4-6,2018,4,6,14,8a74je,[D] Does anyone know any really good papers on spiking neural networks?,https://www.reddit.com/r/MachineLearning/comments/8a74je/d_does_anyone_know_any_really_good_papers_on/,TheMan_TheMyth,1522993724,,24,71
335,2018-4-6,2018,4,6,14,8a759r,[N] Human Hippocampal Neurogenesis Persists throughout Aging,https://www.reddit.com/r/MachineLearning/comments/8a759r/n_human_hippocampal_neurogenesis_persists/,phobrain,1522994002,,7,7
336,2018-4-6,2018,4,6,15,8a77eo,"[R] Based on the memo's work, I tried storytelling using ML",https://www.reddit.com/r/MachineLearning/comments/8a77eo/r_based_on_the_memos_work_i_tried_storytelling/,neelkadia,1522994644,,0,1
337,2018-4-6,2018,4,6,15,8a79rr,Does the lack of mathematical rigor bother anyone else?,https://www.reddit.com/r/MachineLearning/comments/8a79rr/does_the_lack_of_mathematical_rigor_bother_anyone/,gradientgonewild,1522995447,[removed],0,1
338,2018-4-6,2018,4,6,15,8a7boo,Lack of Mathematical Rigor,https://www.reddit.com/r/MachineLearning/comments/8a7boo/lack_of_mathematical_rigor/,gradientgonewild,1522996106,[removed],0,1
339,2018-4-6,2018,4,6,15,8a7dgx,[P] Convolutional Generative Adversarial Network to Synthesize Novel Quilt Designs,https://www.reddit.com/r/MachineLearning/comments/8a7dgx/p_convolutional_generative_adversarial_network_to/,vishnubob,1522996698,,2,10
340,2018-4-6,2018,4,6,15,8a7dlp,Car Wrapping in Los Angeles,https://www.reddit.com/r/MachineLearning/comments/8a7dlp/car_wrapping_in_los_angeles/,drive-itautogroup,1522996735,[removed],0,1
341,2018-4-6,2018,4,6,16,8a7ntv,[R] [1204.5721] Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems,https://www.reddit.com/r/MachineLearning/comments/8a7ntv/r_12045721_regret_analysis_of_stochastic_and/,reninsuture,1523000341,,3,22
342,2018-4-6,2018,4,6,17,8a7sc5,Mobilenet v2 paper said Depthwise Separable convolution speedup conv op 8-9 times without reducing much accuracy. Should we just use it all the time now? Is there any detail analysis on it?,https://www.reddit.com/r/MachineLearning/comments/8a7sc5/mobilenet_v2_paper_said_depthwise_separable/,[deleted],1523002079,,0,1
343,2018-4-6,2018,4,6,17,8a7sf6,[D] Mobilenet v2 paper said Depthwise Separable convolution speedup conv op 8-9 times without reducing much accuracy. Should we just use it all the time now? Is there any detail analysis on it?,https://www.reddit.com/r/MachineLearning/comments/8a7sf6/d_mobilenet_v2_paper_said_depthwise_separable/,RavlaAlvar,1523002114,"What about spatial separable filter?

",17,34
344,2018-4-6,2018,4,6,19,8a8c30,Prof Andrew Ng is writing a book about managing a ML project - sign up for free updates,https://www.reddit.com/r/MachineLearning/comments/8a8c30/prof_andrew_ng_is_writing_a_book_about_managing_a/,ScotchMonk,1523009445,,0,1
345,2018-4-6,2018,4,6,19,8a8hk0,ClockNet for learning better video representations,https://www.reddit.com/r/MachineLearning/comments/8a8hk0/clocknet_for_learning_better_video_representations/,Not_Again_Reddit,1523011326,,0,1
346,2018-4-6,2018,4,6,21,8a8zn2,[R] Image Generation from Scene Graphs,https://www.reddit.com/r/MachineLearning/comments/8a8zn2/r_image_generation_from_scene_graphs/,cedrickchee,1523016746,,1,36
347,2018-4-6,2018,4,6,21,8a8zz1,"[R] MapNet: An Allocentric Spatial Memory for Mapping Environments (CVPR'18 oral, with videos)",https://www.reddit.com/r/MachineLearning/comments/8a8zz1/r_mapnet_an_allocentric_spatial_memory_for/,brainggear,1523016843,,0,18
348,2018-4-6,2018,4,6,21,8a90c8,"If Your Data Is Bad, Your Machine Learning Efforts Are Counterproductive",https://www.reddit.com/r/MachineLearning/comments/8a90c8/if_your_data_is_bad_your_machine_learning_efforts/,jonfla,1523016960,,0,1
349,2018-4-6,2018,4,6,21,8a92ry,AMA coming up soon.,https://www.reddit.com/r/MachineLearning/comments/8a92ry/ama_coming_up_soon/,davidb04,1523017609,,0,1
350,2018-4-6,2018,4,6,21,8a9a3w,[R] Visualizing Rewards in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8a9a3w/r_visualizing_rewards_in_reinforcement_learning/,jaleyhd,1523019489,,0,5
351,2018-4-6,2018,4,6,22,8a9co1,[R] My Take on Microsoft AI Interview Questions with Interactive Code  Part 1,https://www.reddit.com/r/MachineLearning/comments/8a9co1/r_my_take_on_microsoft_ai_interview_questions/,trumtra,1523020100,,0,1
352,2018-4-6,2018,4,6,22,8a9d45,Difference between thresholding and cost sensitive objective function for classification,https://www.reddit.com/r/MachineLearning/comments/8a9d45/difference_between_thresholding_and_cost/,branch_and_cut,1523020206,[removed],0,1
353,2018-4-6,2018,4,6,22,8a9fge,[P] A reinforcement learning environment for the protein folding problem (2-D HP Lattice Model),https://www.reddit.com/r/MachineLearning/comments/8a9fge/p_a_reinforcement_learning_environment_for_the/,JamminJames921,1523020791,,11,102
354,2018-4-6,2018,4,6,22,8a9j5d,RNN-CharCNN for sequence tagging: convolution best practices?,https://www.reddit.com/r/MachineLearning/comments/8a9j5d/rnncharcnn_for_sequence_tagging_convolution_best/,ishalyminov,1523021630,,0,1
355,2018-4-6,2018,4,6,22,8a9osc,Datasets for RNN benchmarking,https://www.reddit.com/r/MachineLearning/comments/8a9osc/datasets_for_rnn_benchmarking/,[deleted],1523022930,,0,1
356,2018-4-6,2018,4,6,23,8a9qkd,Which class to take?,https://www.reddit.com/r/MachineLearning/comments/8a9qkd/which_class_to_take/,cant_think_of_one25,1523023319,[removed],0,1
357,2018-4-6,2018,4,6,23,8a9qz6,[D] Datasets for RNN benchmarking,https://www.reddit.com/r/MachineLearning/comments/8a9qz6/d_datasets_for_rnn_benchmarking/,Jokeris91,1523023405,"Which are the most used datasets to benchmark recurrent NNs (including LSTM/GRU variants)? 

On many papers I've already seen TIMIT, IAM, MNIST and [musical datasets](http://www-etud.iro.umontreal.ca/~boulanni/icml2012). I'd rather datasets for unidirectional RNNs.",3,7
358,2018-4-6,2018,4,6,23,8a9scq,[N] 9 awesome artificial intelligence and machine learning podcasts you should subscribe to,https://www.reddit.com/r/MachineLearning/comments/8a9scq/n_9_awesome_artificial_intelligence_and_machine/,chris_shpak,1523023698,,0,1
359,2018-4-6,2018,4,6,23,8a9v48,[R] How to Make Predictions with scikit-learn - Machine Learning Mastery,https://www.reddit.com/r/MachineLearning/comments/8a9v48/r_how_to_make_predictions_with_scikitlearn/,magneticono,1523024310,,0,1
360,2018-4-6,2018,4,6,23,8a9zd2,[D] Big Tech ethics vs Research &amp; Open Source ML frameworks.,https://www.reddit.com/r/MachineLearning/comments/8a9zd2/d_big_tech_ethics_vs_research_open_source_ml/,RiceTuna,1523025210,"By now, there's pretty good evidence that not everything big tech is doing is good, esp. Google, FB, Uber, and Amzn. 

Discrimination, excessive data collection and misuse, project Maven (the Google AI project with the Pentagon), monopolistic behaviors, ads ads ads...
The list goes on and on. 

The $ that comes (directly and indirectly) from these questionable activities funds projects that we all use on a daily basis: Tensorflow, PyTorch, Pyro, AWS, ...

The $ that comes (directly and indirectly) from these questionable activities also funds some of the most remarkable research in the field.

Contrast this with ethically cleaner, more academic projects like sk-learn (and to a lesser extent mxnet), and to ethically cleaner research conducted in academic settings. 

Sometimes it's impossible to compete with massive amounts of money thrown at a problem - often resulting in the death of independent projects and independent research. 

Should we, as a group, be more mindful of this distinction and go out of our way, when possible, to support research and frameworks whose funding sources aren't ""compromised""?

",25,27
361,2018-4-6,2018,4,6,23,8aa0x9,Object Detection Demo - Detectron Drone Flight,https://www.reddit.com/r/MachineLearning/comments/8aa0x9/object_detection_demo_detectron_drone_flight/,[deleted],1523025519,[deleted],0,1
362,2018-4-6,2018,4,6,23,8aa57f,[P] Object Detection Demo - Detectron Drone Flight,https://www.reddit.com/r/MachineLearning/comments/8aa57f/p_object_detection_demo_detectron_drone_flight/,omoser,1523026442,,0,3
363,2018-4-6,2018,4,6,23,8aa65j,[R] NeuroSAT: Learning a SAT Solver from Single-Bit Supervision,https://www.reddit.com/r/MachineLearning/comments/8aa65j/r_neurosat_learning_a_sat_solver_from_singlebit/,breandan,1523026643,,6,19
364,2018-4-7,2018,4,7,0,8aa9vi,[P] A collaborative platform for getting more out of AI research,https://www.reddit.com/r/MachineLearning/comments/8aa9vi/p_a_collaborative_platform_for_getting_more_out/,jiaqingai,1523027397,,3,16
365,2018-4-7,2018,4,7,0,8aad84,Convolutional neural networks show potential in search for gravitational waves.,https://www.reddit.com/r/MachineLearning/comments/8aad84/convolutional_neural_networks_show_potential_in/,rebels8040,1523028106,,0,1
366,2018-4-7,2018,4,7,0,8aaizw,An implementation of WaveNet use Pytorch for learning,https://www.reddit.com/r/MachineLearning/comments/8aaizw/an_implementation_of_wavenet_use_pytorch_for/,[deleted],1523029280,[deleted],0,1
367,2018-4-7,2018,4,7,0,8aamsc,[P] An implementation of WaveNet use Pytorch,https://www.reddit.com/r/MachineLearning/comments/8aamsc/p_an_implementation_of_wavenet_use_pytorch/,ts771164,1523029972,,2,2
368,2018-4-7,2018,4,7,1,8aarri,Blogpost on The Facebook Scandal - or how to predict psychological traits from Facebook likes.,https://www.reddit.com/r/MachineLearning/comments/8aarri/blogpost_on_the_facebook_scandal_or_how_to/,plotti,1523030928,,0,1
369,2018-4-7,2018,4,7,1,8aasbf,NVIDIA GTC 2018 Peeks Inside the GPU-Powered World,https://www.reddit.com/r/MachineLearning/comments/8aasbf/nvidia_gtc_2018_peeks_inside_the_gpupowered_world/,trcytony,1523031034,,0,1
370,2018-4-7,2018,4,7,1,8ab477,Collection of data sets?,https://www.reddit.com/r/MachineLearning/comments/8ab477/collection_of_data_sets/,[deleted],1523033453,,0,1
371,2018-4-7,2018,4,7,2,8abdfx,[P] A Tsetlin Machine Implementation (Not from paper author),https://www.reddit.com/r/MachineLearning/comments/8abdfx/p_a_tsetlin_machine_implementation_not_from_paper/,CireNeikual,1523035406,,16,106
372,2018-4-7,2018,4,7,2,8abj1y,Convolutional LSTM - Questions,https://www.reddit.com/r/MachineLearning/comments/8abj1y/convolutional_lstm_questions/,soulslicer0,1523036551,[removed],0,1
373,2018-4-7,2018,4,7,3,8abqph,Is this legit? Seems kinda hand-wavey,https://www.reddit.com/r/MachineLearning/comments/8abqph/is_this_legit_seems_kinda_handwavey/,BPaccount,1523038156,,0,1
374,2018-4-7,2018,4,7,3,8abzuc,AI Weekly 6 April 2018,https://www.reddit.com/r/MachineLearning/comments/8abzuc/ai_weekly_6_april_2018/,TomekB,1523040077,,0,1
375,2018-4-7,2018,4,7,3,8ac47n,My First Machine Learning Classifier - A Predictor On If A Student Would Get Into Stanford University in SciKit Learn,https://www.reddit.com/r/MachineLearning/comments/8ac47n/my_first_machine_learning_classifier_a_predictor/,khanradcoder,1523041027,,0,1
376,2018-4-7,2018,4,7,4,8ac6vd,Probabilistic Programming Libraries,https://www.reddit.com/r/MachineLearning/comments/8ac6vd/probabilistic_programming_libraries/,Draikmage,1523041579,[removed],0,1
377,2018-4-7,2018,4,7,4,8acbey,[D] Which probabilistic programming library do you use?,https://www.reddit.com/r/MachineLearning/comments/8acbey/d_which_probabilistic_programming_library_do_you/,Draikmage,1523042592,"Hello, I was looking for a library to get into probabilistic programming (preferably python). I've seen a lot of comparison between stuff like tf and pytorch but not really much between probabilistic programming packages like pymc3 and Edward. Do you guys have any suggestions about the pros and cons?",10,12
378,2018-4-7,2018,4,7,5,8acq9u,Beating Atari Games with OpenAI's Evolutionary Strategies,https://www.reddit.com/r/MachineLearning/comments/8acq9u/beating_atari_games_with_openais_evolutionary/,nlogox,1523045813,,0,1
379,2018-4-7,2018,4,7,5,8ad0yp,Adversarial Network Compression (Knowledge transfer between deep nets with adversarial learning).,https://www.reddit.com/r/MachineLearning/comments/8ad0yp/adversarial_network_compression_knowledge/,vb_l,1523048188,,0,1
380,2018-4-7,2018,4,7,5,8ad1pr,[P] Optimization of CNC Cutting parameters using Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/8ad1pr/p_optimization_of_cnc_cutting_parameters_using/,khamzah22,1523048374,,0,3
381,2018-4-7,2018,4,7,6,8ad3u6,Difference between MATLAB's NARX NN and Feed-Forward NN with manually lagged input/outputs?,https://www.reddit.com/r/MachineLearning/comments/8ad3u6/difference_between_matlabs_narx_nn_and/,half_a_lime,1523048804,[removed],0,1
382,2018-4-7,2018,4,7,9,8aec29,Research Topics for ML/HPC,https://www.reddit.com/r/MachineLearning/comments/8aec29/research_topics_for_mlhpc/,ApertureCombine,1523059819,[removed],0,1
383,2018-4-7,2018,4,7,10,8aevry,Dogs vs Cats classification using Transfer Learning and PyTorch,https://www.reddit.com/r/MachineLearning/comments/8aevry/dogs_vs_cats_classification_using_transfer/,Gnaneshkunal,1523065394,,0,1
384,2018-4-7,2018,4,7,11,8af7kq,[D] Will taking a course in Digital Signal Processing help people who want to get into ML?,https://www.reddit.com/r/MachineLearning/comments/8af7kq/d_will_taking_a_course_in_digital_signal/,badboyyy112,1523068848,"Hello all, so in my Uni there is a ML program but I need to take some other courses to fill full time status. My prof recommended me to take DSP, and I was wondering how that might help me in the ML field. If anyone can shed some light on this it would be very helpful!",7,1
385,2018-4-7,2018,4,7,11,8af9zc,Production DL Models,https://www.reddit.com/r/MachineLearning/comments/8af9zc/production_dl_models/,country_dev,1523069585,[removed],0,1
386,2018-4-7,2018,4,7,12,8afel4,"What are the input embeddings in the ""Attention is all you need"" paper ?",https://www.reddit.com/r/MachineLearning/comments/8afel4/what_are_the_input_embeddings_in_the_attention_is/,FlyingDope,1523071008,[removed],0,1
387,2018-4-7,2018,4,7,13,8afmyy,Machine Learning in Materials Science Workshop: Introduction to machine learning,https://www.reddit.com/r/MachineLearning/comments/8afmyy/machine_learning_in_materials_science_workshop/,sp8rks,1523073649,,1,3
388,2018-4-7,2018,4,7,14,8ag50e,Real Analysis vs. Algebra,https://www.reddit.com/r/MachineLearning/comments/8ag50e/real_analysis_vs_algebra/,killerbee4992,1523079805,[removed],0,1
389,2018-4-7,2018,4,7,16,8agmc9,[P] Downloading 1000s of images from Google and preparing them for image dataset generation,https://www.reddit.com/r/MachineLearning/comments/8agmc9/p_downloading_1000s_of_images_from_google_and/,hnvasaa,1523086759,,18,223
390,2018-4-7,2018,4,7,16,8agn2s,[R] [1803.10750] Adversarial Network Compression,https://www.reddit.com/r/MachineLearning/comments/8agn2s/r_180310750_adversarial_network_compression/,[deleted],1523087102,[deleted],0,1
391,2018-4-7,2018,4,7,17,8agp6d,[R] [1803.10750] Adversarial Network Compression (Knowledge transfer between deep nets with adversarial learning),https://www.reddit.com/r/MachineLearning/comments/8agp6d/r_180310750_adversarial_network_compression/,vb_l,1523088070,,2,8
392,2018-4-7,2018,4,7,17,8agtpa,What simple games with imperfect information do you know?,https://www.reddit.com/r/MachineLearning/comments/8agtpa/what_simple_games_with_imperfect_information_do/,curiosity_monster,1523090159,[removed],0,1
393,2018-4-7,2018,4,7,17,8aguah,Can Someone suggest me how to plot a graph in Python for the below data.,https://www.reddit.com/r/MachineLearning/comments/8aguah/can_someone_suggest_me_how_to_plot_a_graph_in/,Bhavyapc,1523090427,[removed],0,1
394,2018-4-7,2018,4,7,18,8agysh,What equation is true of neuralnets even if an idiot is writing the code of such a neuralnet yet is unable to defy the truth of the equation?,https://www.reddit.com/r/MachineLearning/comments/8agysh/what_equation_is_true_of_neuralnets_even_if_an/,[deleted],1523092537,,0,1
395,2018-4-7,2018,4,7,18,8agzjk,[D] What equation is true of neuralnets even if an idiot is writing the code of such a neuralnet yet is unable to defy the truth of the equation?,https://www.reddit.com/r/MachineLearning/comments/8agzjk/d_what_equation_is_true_of_neuralnets_even_if_an/,BenRayfield,1523092832,"aka a scientific theory, like a law of physics, that does not take skill to obey the laws of physics but is simply impossible not to",7,0
396,2018-4-7,2018,4,7,18,8ah0bq,[D] Activation for Landmark Detection,https://www.reddit.com/r/MachineLearning/comments/8ah0bq/d_activation_for_landmark_detection/,DonMahallem,1523093206,"I am currently trying to build a landmark detector and found a few papers on this topic specially for Facial Landmarkdetection. My current implementation is a VGG net with few fully connected layers at the end which are supposed to produce the x/y coordinates scaled to the respective interval of the last Activation layer (eg 0-1 for sigmoid or -1 to 1 tanh).

I am currently facing the problem, that the network works quite good but the closer the landmarks are too the border the higher the error margins are. I tried a clamped relu(0,1) but it improved the accuracy by maybe 2% to 86%. The dataset I am using is(currently) fully generated and spreads the landmarks uniform (still in pattern) across the input.

Now my question:

Should I just move the landmarks more inwards (maybe pad the input)  or are there other things I might have missed?",6,3
397,2018-4-7,2018,4,7,18,8ah42f,RNN cells and experience replay.,https://www.reddit.com/r/MachineLearning/comments/8ah42f/rnn_cells_and_experience_replay/,[deleted],1523094959,,0,1
398,2018-4-7,2018,4,7,18,8ah4k5,AI Playing Flappy Bird using Neural Networks and NEAT,https://www.reddit.com/r/MachineLearning/comments/8ah4k5/ai_playing_flappy_bird_using_neural_networks_and/,Byte-Master-101,1523095190,,0,1
399,2018-4-7,2018,4,7,19,8ah9fw,[R] Prefrontal cortex as a meta-reinforcement learning system [DeepMind],https://www.reddit.com/r/MachineLearning/comments/8ah9fw/r_prefrontal_cortex_as_a_metareinforcement/,evc123,1523097323,,14,59
400,2018-4-7,2018,4,7,20,8ahl1n,AlterEgo: Interfacing with devices through silent speech,https://www.reddit.com/r/MachineLearning/comments/8ahl1n/alterego_interfacing_with_devices_through_silent/,[deleted],1523102167,[deleted],0,1
401,2018-4-7,2018,4,7,20,8ahln5,[N] AlterEgo: Interfacing with devices through silent speech,https://www.reddit.com/r/MachineLearning/comments/8ahln5/n_alterego_interfacing_with_devices_through/,lopespm,1523102399,,8,23
402,2018-4-7,2018,4,7,22,8ahzaw,Neural Networks: All YOU Need to Know,https://www.reddit.com/r/MachineLearning/comments/8ahzaw/neural_networks_all_you_need_to_know/,SSuryansh,1523107112,,0,1
403,2018-4-7,2018,4,7,22,8ai3jk,[R] Recruiting statisticians/data analysts participants for a research study on career success,https://www.reddit.com/r/MachineLearning/comments/8ai3jk/r_recruiting_statisticiansdata_analysts/,JNstats,1523108474,"I am a graduate student conducting a research study about the skill and knowledge sets of statisticians/data analysts and their perceived career success. Participation involves filling out a questionnaire, which is expected to take approximately 10-15 minutes to complete. Participants must be 18 years old or older. If you are interested in participating, [click here]( https://usmep.co1.qualtrics.com/SE/?SID=SV_cw0L49DrDO04RsF&amp;Q_JFE=0) to take the survey. If you have any questions or concerns, I can be reached at Harold.noble@eagles.usm.edu. Thank you very much for your consideration",3,2
404,2018-4-7,2018,4,7,23,8aiax5,What are the best online masters in data science or data analytics program.,https://www.reddit.com/r/MachineLearning/comments/8aiax5/what_are_the_best_online_masters_in_data_science/,esenthil,1523110561,[removed],0,1
405,2018-4-7,2018,4,7,23,8aict3,"We have passed 10,000 ELO",https://www.reddit.com/r/MachineLearning/comments/8aict3/we_have_passed_10000_elo/,quantum_entropy,1523111068,,1,1
406,2018-4-7,2018,4,7,23,8aij0u,[D] Computer science/AI... when does school become counter-productive? [much serious],https://www.reddit.com/r/MachineLearning/comments/8aij0u/d_computer_scienceai_when_does_school_become/,maka89,1523112778,"Hi. I live in scandinavia and am currently in my second year taking a bachelors in computer science. I find uni a bit slow, rigorous and boring, but its going OK.

However, I recently became aware that Siraj Raval has started a program with the promise of teaching cmoputer science in 5 months. Mostly by viewing online lectures and youtube videos at 3x speed. Having the cerification of a bachelors is nice, sure, but I have to pay 50$ school tution every semester and the state only covers about half of the loan for my living expenses (2% interest rate!!11). This makes me insecure if im wasting my time and money???

Help, anyone? I want to break into AI.

PS. Don't delete. Very serious.",35,0
407,2018-4-7,2018,4,7,23,8aijdn,The Moments In Time at MIT-IBM laboratory,https://www.reddit.com/r/MachineLearning/comments/8aijdn/the_moments_in_time_at_mitibm_laboratory/,MarketingHacks,1523112858,[removed],0,1
408,2018-4-8,2018,4,8,0,8aimei,[D] What is the right way to parallelize rollouts in gym ?,https://www.reddit.com/r/MachineLearning/comments/8aimei/d_what_is_the_right_way_to_parallelize_rollouts/,metaAI,1523113635,"I tried with Python Multiprocessing Process class, it seems that it doesn't work

Given that `env = gym.make('CartPole-v0')`, we have

For Serial:


    def run1():
        t = time()
        env.reset()
        for _ in range(100):
            env.step(env.action_space.sample())
        print(f'{time() - t} s')

uses `0.0059 s`

For Parallel:

    def run2():
        t = time()
        env.reset()
        l = []
        for _ in range(100):
            p = Process(target=env.step, args=[env.action_space.sample()])
 
            p.start()
            l.append(p)
        [p.join() for p in l]
        print(f'{time() - t} s')

uses `0.83 s`

Both with 100 steps, the parallel version is more than 100 times slower than serial one. ",10,9
409,2018-4-8,2018,4,8,0,8ainix,[N] PyTorch is installable via `pip install torch`,https://www.reddit.com/r/MachineLearning/comments/8ainix/n_pytorch_is_installable_via_pip_install_torch/,Deepblue129,1523113919,http://pytorch.org/ updated to allow `pip install torch`,4,0
410,2018-4-8,2018,4,8,1,8aj2bj,[N] PyTorch as of April is installable via `pip install torch`,https://www.reddit.com/r/MachineLearning/comments/8aj2bj/n_pytorch_as_of_april_is_installable_via_pip/,Deepblue129,1523117534,http://pytorch.org/ updated on April 3rd to allow `pip install torch`,51,266
411,2018-4-8,2018,4,8,1,8aj5zb,Machine Learning Careers in Particle Physics?,https://www.reddit.com/r/MachineLearning/comments/8aj5zb/machine_learning_careers_in_particle_physics/,jirukulapati,1523118439,[removed],0,1
412,2018-4-8,2018,4,8,2,8ajfot,How a machine learning algorithm works?,https://www.reddit.com/r/MachineLearning/comments/8ajfot/how_a_machine_learning_algorithm_works/,pknerd,1523120741,[removed],0,1
413,2018-4-8,2018,4,8,2,8ajn3v,On implementing k Nearest Neighbor for regression in Python,https://www.reddit.com/r/MachineLearning/comments/8ajn3v/on_implementing_k_nearest_neighbor_for_regression/,antoniomallia,1523122528,,0,1
414,2018-4-8,2018,4,8,3,8ajve2,Hourly grid load data of any city needed to test load forecasting neural network algorithm.,https://www.reddit.com/r/MachineLearning/comments/8ajve2/hourly_grid_load_data_of_any_city_needed_to_test/,akashgautam025,1523124549,[removed],0,1
415,2018-4-8,2018,4,8,3,8ak05g,Good references on variety of train images needed for training a TensorFlow Object Detection neural network?,https://www.reddit.com/r/MachineLearning/comments/8ak05g/good_references_on_variety_of_train_images_needed/,Taxi-guy,1523125735,,0,1
416,2018-4-8,2018,4,8,4,8akhos,Talent shortage in AI is a myth: reply to Cedric Villani,https://www.reddit.com/r/MachineLearning/comments/8akhos/talent_shortage_in_ai_is_a_myth_reply_to_cedric/,Zophike1,1523129933,,0,1
417,2018-4-8,2018,4,8,4,8akkja,"Looking to build, compile, and/or find dataset for serial-parallelized code examples",https://www.reddit.com/r/MachineLearning/comments/8akkja/looking_to_build_compile_andor_find_dataset_for/,MandeasyMedina,1523130646,[removed],0,1
418,2018-4-8,2018,4,8,5,8aknz8,Resources for high-level theoretical understanding of deep learning?,https://www.reddit.com/r/MachineLearning/comments/8aknz8/resources_for_highlevel_theoretical_understanding/,jkff,1523131465,[removed],0,1
419,2018-4-8,2018,4,8,5,8akzs1,Fast Sparse PCA using R - An essential tool for your machine learning toolbox!,https://www.reddit.com/r/MachineLearning/comments/8akzs1/fast_sparse_pca_using_r_an_essential_tool_for/,[deleted],1523134298,[deleted],0,1
420,2018-4-8,2018,4,8,6,8al32p,[P] Fast Sparse PCA using R - An essential tool for your machine learning toolbox!,https://www.reddit.com/r/MachineLearning/comments/8al32p/p_fast_sparse_pca_using_r_an_essential_tool_for/,benli11,1523135096,,14,5
421,2018-4-8,2018,4,8,7,8almc9,More and more people find out about AliCoin and perceive its potential. Be ready for 20th April and take advantage of -70% bonus!,https://www.reddit.com/r/MachineLearning/comments/8almc9/more_and_more_people_find_out_about_alicoin_and/,sami3120,1523139826,,0,1
422,2018-4-8,2018,4,8,7,8als9z,Splitting data,https://www.reddit.com/r/MachineLearning/comments/8als9z/splitting_data/,UWbadgers16,1523141330,[removed],0,1
423,2018-4-8,2018,4,8,7,8alu2k,How to score 0.8134 in Titanic Kaggle Challenge,https://www.reddit.com/r/MachineLearning/comments/8alu2k/how_to_score_08134_in_titanic_kaggle_challenge/,ahmedbesbes,1523141755,,0,1
424,2018-4-8,2018,4,8,7,8alual,98 [D] Machine Learning - WAYR (What Are You Reading) - Week 44,https://www.reddit.com/r/MachineLearning/comments/8alual/98_d_machine_learning_wayr_what_are_you_reading/,[deleted],1523141816,[deleted],0,1
425,2018-4-8,2018,4,8,7,8aluhs,[D] Machine Learning - WAYR (What Are You Reading) - Week 44,https://www.reddit.com/r/MachineLearning/comments/8aluhs/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1523141888,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 31](https://www.reddit.com/r/MachineLearning/comments/6s0k1u/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 41](https://www.reddit.com/r/MachineLearning/comments/7tn2ax/d_machine_learning_wayr_what_are_you_reading_week/)|||
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 32](https://www.reddit.com/r/MachineLearning/comments/72ab5y/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 42](https://www.reddit.com/r/MachineLearning/comments/7wvjfk/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 33](https://www.reddit.com/r/MachineLearning/comments/75405d/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 43](https://www.reddit.com/r/MachineLearning/comments/807ex4/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 34](https://www.reddit.com/r/MachineLearning/comments/782js9/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 35](https://www.reddit.com/r/MachineLearning/comments/7b0av0/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 36](https://www.reddit.com/r/MachineLearning/comments/7e3fx6/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 37](https://www.reddit.com/r/MachineLearning/comments/7hcc2c/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|[Week 28](https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 38](https://www.reddit.com/r/MachineLearning/comments/7kgcqr/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|[Week 29](https://www.reddit.com/r/MachineLearning/comments/6m9l1v/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 39](https://www.reddit.com/r/MachineLearning/comments/7nayri/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 30](https://www.reddit.com/r/MachineLearning/comments/6p3ha7/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 40](https://www.reddit.com/r/MachineLearning/comments/7qel9p/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/marcossilva_604: https://arxiv.org/abs/1802.06006.

/u/hohomomo1212: Learning to Play with Intrinsically-Motivated Self-Aware Agents (https://arxiv.org/abs/1802.07442). It is a paper on a form of reinforcement learning without extrinsic rewards. Think of a robot wandering around in the world without being told what to do but instead figuring out what to do by itself using a model of its own abilities. That's why they call it self-aware. Pretty cool :)

Besides that, there are no rules, have fun.",53,119
426,2018-4-8,2018,4,8,8,8am1m2,Convolutional output channels - what prevents them from converging to the same thing?,https://www.reddit.com/r/MachineLearning/comments/8am1m2/convolutional_output_channels_what_prevents_them/,ME_PhD,1523143794,[removed],0,1
427,2018-4-8,2018,4,8,8,8am2zu,[D] Looking for help learning how to read research papers.,https://www.reddit.com/r/MachineLearning/comments/8am2zu/d_looking_for_help_learning_how_to_read_research/,Cartesian_Currents,1523144162,"I am looking for resources on how to read machine learning research.

 In my ideal world someone would provide me with:
 1. a general guide on how to do read a machine learning paper

2.  a set of papers that are basic and representative of the literature, and ideally develop fundamental understanding of useful machine learning topics.

3. a guide sort of ""answer key"" to these papers that breaks down the key concepts that one should have understood as well as things that might have slipped under the radar of someone less experienced.

4. Some sort of ""book club"" (of research papers of course) for those trying to learn either based on the aforementioned set of papers or moving beyond it.

5. A more experienced machine learning engineer willing to at least somewhat guide this bookclub (ideally lead discussion on occasion, but honestly anyone willing to be a resource in any capacity would be ideally.)

6. Some way to guide the development of my skill in understanding what's worth reading and what's not. 

This is a lot to ask for, at this point I don't have much I can offer in return. If anyone else is interested in the book club idea I'm willing to organize it although if it wasn't obvious I lack the experience to properly curate the resources. 
 ",22,49
428,2018-4-8,2018,4,8,10,8amn07,[N] A.I. that trades stocks with you,https://www.reddit.com/r/MachineLearning/comments/8amn07/n_ai_that_trades_stocks_with_you/,chonsin,1523149575,,13,0
429,2018-4-8,2018,4,8,10,8amsu5,Keras implementation of 'Convolutional Sketch Inversion',https://www.reddit.com/r/MachineLearning/comments/8amsu5/keras_implementation_of_convolutional_sketch/,[deleted],1523151289,[deleted],0,1
430,2018-4-8,2018,4,8,10,8amv05,[P] Keras implementation of 'Convolutional Sketch Inversion',https://www.reddit.com/r/MachineLearning/comments/8amv05/p_keras_implementation_of_convolutional_sketch/,SupraluminalShift,1523151926,,1,8
431,2018-4-8,2018,4,8,12,8anb8j,"Explaining the difference between maximum likelihood, maximum a priori, and Bayesian parameter estimation",https://www.reddit.com/r/MachineLearning/comments/8anb8j/explaining_the_difference_between_maximum/,[deleted],1523156700,[deleted],0,1
432,2018-4-8,2018,4,8,12,8andi0,"[D] Explaining the difference between maximum likelihood, MAP, and Bayesian parameter estimation.",https://www.reddit.com/r/MachineLearning/comments/8andi0/d_explaining_the_difference_between_maximum/,akmaki,1523157384,,7,53
433,2018-4-8,2018,4,8,14,8ao4w1,[N] LSTM inference shoot-out: Intel Skylake vs NVIDIA V100,https://www.reddit.com/r/MachineLearning/comments/8ao4w1/n_lstm_inference_shootout_intel_skylake_vs_nvidia/,downtownslim,1523166641,,18,117
434,2018-4-8,2018,4,8,15,8ao9d5,Need help understanding SVM,https://www.reddit.com/r/MachineLearning/comments/8ao9d5/need_help_understanding_svm/,tsailfc,1523168422,[removed],0,1
435,2018-4-8,2018,4,8,16,8aohzy,"Automatic Bottling Equipments, Automatic Filling Machine, Automatic PET Bottle Blow Molding Machine, Automatic Labeling Machine Manufacturer &amp; Supplier China",https://www.reddit.com/r/MachineLearning/comments/8aohzy/automatic_bottling_equipments_automatic_filling/,labelong,1523172105,[removed],0,1
436,2018-4-8,2018,4,8,16,8aom9d,How to deal with dataset having variable no of samples in each file?,https://www.reddit.com/r/MachineLearning/comments/8aom9d/how_to_deal_with_dataset_having_variable_no_of/,mr_meeesix,1523174076,[removed],0,1
437,2018-4-8,2018,4,8,16,8aomk9,Metrics for ML Models Evaliation,https://www.reddit.com/r/MachineLearning/comments/8aomk9/metrics_for_ml_models_evaliation/,rs_12,1523174225,,0,1
438,2018-4-8,2018,4,8,17,8aoom9,Udemy Evolutionary Algorithms,https://www.reddit.com/r/MachineLearning/comments/8aoom9/udemy_evolutionary_algorithms/,shving90,1523175161,[removed],2,1
439,2018-4-8,2018,4,8,17,8aopnp,Questions regarding keras activation maximization visualization,https://www.reddit.com/r/MachineLearning/comments/8aopnp/questions_regarding_keras_activation_maximization/,babuunn,1523175673,[removed],0,1
440,2018-4-8,2018,4,8,18,8aoyis,OpenAI's Retro Contest to solve Sonic the Hedgehog,https://www.reddit.com/r/MachineLearning/comments/8aoyis/openais_retro_contest_to_solve_sonic_the_hedgehog/,half-hitch,1523179911,[removed],0,1
441,2018-4-8,2018,4,8,19,8ap3mr,Automatic Tamarind Packing Machine,https://www.reddit.com/r/MachineLearning/comments/8ap3mr/automatic_tamarind_packing_machine/,lgsherry,1523182337,,1,1
442,2018-4-8,2018,4,8,20,8ape5w,"[D] How to encourage competition and prevent ""working together"" in genetic algorithms",https://www.reddit.com/r/MachineLearning/comments/8ape5w/d_how_to_encourage_competition_and_prevent/,DemiPixel,1523187094,"I got bored tonight and decided to write a genetic algorithm for [dupl.io](https://dupl.io/), curious to know if there's any way to ""get better"" or if it's just a matter of wasting a bunch of time.

How the game works:

&gt; You can select any tile you own every second, and this will increment it. Once it hits 5, it will take ownership of the 4 adjacent tiles, increment them, and remove ownership of the current tile. You can take over other land with this. Score is determined by the count of each tile added together.

The way I approached this was to rewrite the game, set up neural networks in a genetic setting, inputs are a 7x7 grid around each tile (3 times: 0/1 for on the grid or not, count/4 for own tile, and count/4 for enemy tile, effectively creating 7*7*3 inputs). For a given tile owner, I parse each 7x7 grid, get a ""score"", and the tile with the highest score is selected to upgrade/expand.

******

So, unfortunately, the way I handled this was by dumping 20 of them (in grid formation, but randomly sorted) into a 41x41 grid and waited 500 ticks and did my genetic reproduction magic. This meant, however, that what took over is an ""always go left"", because whoever spawns on the left-most side will eat up everybody, and everybody else will ""surrender"" (I presume if I left it running long enough, it will also develop a ""go down afterwards""), **maximizing the fittest, but not the average**.

So, what could a solution be? I could put each agent against bots so they have no impact on each other, but then they just learn to exploit the pre-written bots and not necessarily improve beyond the bots. I could also have them run live, on the site, however that would take much, much longer.

I feel like this would apply to tons of other situations as well, like chess. If a bot does well enough on white to take over a population, it could have a mutation that makes it always forfeit as black. This would cause that agent to win even more, and then reproduce even more.

P.S. I don't know if this is unrelated, but if they're all playing each other, how could you see improvements anyway? The fitness score might even go down as they improve and get on equal footing. I've tried to look at stats like ""tiles claimed"" or ""tiles stolen"" as an indication of whether or not they're getting better, but I'm having no luck.

EDIT: Another solution could be to split up my population of 20 into four populations of 5, so something that takes over in one could only ""control"" a quarter of the total population.",30,23
443,2018-4-8,2018,4,8,21,8apjye,[P] Genetic Algorithms starter kit for Swift,https://www.reddit.com/r/MachineLearning/comments/8apjye/p_genetic_algorithms_starter_kit_for_swift/,TomekB,1523189464,,6,30
444,2018-4-8,2018,4,8,21,8app1m,AUDIO SUPER-RESOLUTION USING NEURAL NETS,https://www.reddit.com/r/MachineLearning/comments/8app1m/audio_superresolution_using_neural_nets/,SuperShinyEyes,1523191328,,0,1
445,2018-4-8,2018,4,8,22,8apvpt,&gt;&gt;&gt;Ok,https://www.reddit.com/r/MachineLearning/comments/8apvpt/ok/,fr34kx,1523193636,,0,1
446,2018-4-8,2018,4,8,22,8apwvz,Meta Learning for Control (PDF),https://www.reddit.com/r/MachineLearning/comments/8apwvz/meta_learning_for_control_pdf/,tsendsuren,1523194027,,0,1
447,2018-4-8,2018,4,8,22,8aq26g,Official Tensorflow blog,https://www.reddit.com/r/MachineLearning/comments/8aq26g/official_tensorflow_blog/,margaretmz,1523195708,,0,1
448,2018-4-8,2018,4,8,23,8aqdd3,[P]Help needed in VNect 3D Pose Estimation paper.,https://www.reddit.com/r/MachineLearning/comments/8aqdd3/phelp_needed_in_vnect_3d_pose_estimation_paper/,Ali_Raza_Syed,1523198922,[removed],1,1
449,2018-4-9,2018,4,9,1,8ar4if,Housing a Titan Xp outside the case,https://www.reddit.com/r/MachineLearning/comments/8ar4if/housing_a_titan_xp_outside_the_case/,negazirana,1523205766,[removed],0,1
450,2018-4-9,2018,4,9,2,8arhxb,R Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/8arhxb/r_machine_learning_algorithms/,wolverine_83,1523208919,[removed],0,1
451,2018-4-9,2018,4,9,4,8as4tu,Not able to increase the accuracy of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8as4tu/not_able_to_increase_the_accuracy_of_neural/,abhisheknadgeri,1523214182,[removed],0,1
452,2018-4-9,2018,4,9,5,8askiy,Top 10 Machine Learning Courses for 2018,https://www.reddit.com/r/MachineLearning/comments/8askiy/top_10_machine_learning_courses_for_2018/,Farrukh_bala,1523217685,,0,1
453,2018-4-9,2018,4,9,6,8at30n,[D] What is the best way of learning Machine Learning on my own?,https://www.reddit.com/r/MachineLearning/comments/8at30n/d_what_is_the_best_way_of_learning_machine/,scrytor,1523221921,"For the past month, I have been trying to learn the basics of machine Learning, but I feel like Im not improving a lot. I dont want only to learn the basics, but also to start trying some more challenging tasks. What do you think is the best way/advice to learn it and how? 
",87,199
454,2018-4-9,2018,4,9,6,8atb91,Tsetlin Machine implementation in Python,https://www.reddit.com/r/MachineLearning/comments/8atb91/tsetlin_machine_implementation_in_python/,[deleted],1523223872,[deleted],1,1
455,2018-4-9,2018,4,9,6,8atd4u,[P] Tsetlin Machine Python implementation,https://www.reddit.com/r/MachineLearning/comments/8atd4u/p_tsetlin_machine_python_implementation/,dzyl,1523224304,,13,42
456,2018-4-9,2018,4,9,7,8attch,Noob Alert. Is machine learning basically about testing/trying out different parameters and algorithms on a framework(eg. Tensorflow) and implementing it?,https://www.reddit.com/r/MachineLearning/comments/8attch/noob_alert_is_machine_learning_basically_about/,deeplearner93,1523228254,[removed],0,1
457,2018-4-9,2018,4,9,8,8atzj2,[D] Screen check for (summer) internship of deep learning in US,https://www.reddit.com/r/MachineLearning/comments/8atzj2/d_screen_check_for_summer_internship_of_deep/,Baduglyboy,1523229861,"I'm a master student studying in France and  applying for some summer internships mostly in US.(For the profile, I have experience working in a lab about Computer Vision). I have some observations and would like to confirm it is true or not:
 
* Is that true that some companies will do screen check if the student had already the working permit or not, if they don't have, they will just reject it?

* Does companies nowadays prefer PhD student than master student? ",14,2
458,2018-4-9,2018,4,9,8,8au0tq,"Now that Macs support external GPUs, what are some options worth considering to implement ML, Neural Networks, etc?",https://www.reddit.com/r/MachineLearning/comments/8au0tq/now_that_macs_support_external_gpus_what_are_some/,Gullies,1523230207,[removed],0,1
459,2018-4-9,2018,4,9,10,8auxga,"Hi, I've created a sub-reddit for ML to have fun",https://www.reddit.com/r/MachineLearning/comments/8auxga/hi_ive_created_a_subreddit_for_ml_to_have_fun/,PewPaw-Grams,1523238837,[removed],0,1
460,2018-4-9,2018,4,9,12,8avci3,[D] maximum likelihood - how can VAE ignore the latent?,https://www.reddit.com/r/MachineLearning/comments/8avci3/d_maximum_likelihood_how_can_vae_ignore_the_latent/,knowedgelimited,1523243086,"A question about this statement:

""If p(x|z) is given arbitrary flexibility, it can in fact learn to ignore z completely and always output the data distribution for each z:  p(x|z) = p(z). ...
If you make the generator of a VAE too complex, give it lots of modeling power on top of z, it will ignore your latent variables as they are not needed to achieving a good likelihood.""

It is from the blog post in Huszar, Is Maximum Likelihood Useful for Representation Learning, however other papers have said the same.

The question: how is this possible? The VAE needs to maximize the data likelihood term

  E__q(z|x)[ log p(x|z) ]

for each data point. So it needs to generate an x on the output that resembles the x on the input. If the generator ignores z, _it will always output the same pattern_ I believe, and so cannot try to match the particular inputs.

Does it have something to do with considering the cost across all the data in a minibatch simultaneously? I do not see it yet.
",5,7
461,2018-4-9,2018,4,9,12,8aver6,[D] Heroes of Deep Learning: Andrew Ng interviews Yann LeCun,https://www.reddit.com/r/MachineLearning/comments/8aver6/d_heroes_of_deep_learning_andrew_ng_interviews/,huehener,1523243749,,21,89
462,2018-4-9,2018,4,9,12,8avhkg,[P] Keras implementation of a CNN for age and gender estimation,https://www.reddit.com/r/MachineLearning/comments/8avhkg/p_keras_implementation_of_a_cnn_for_age_and/,SupraluminalShift,1523244608,,9,15
463,2018-4-9,2018,4,9,12,8avka4,Green waste to organic fertilizer making machine,https://www.reddit.com/r/MachineLearning/comments/8avka4/green_waste_to_organic_fertilizer_making_machine/,amylee516,1523245415,,0,1
464,2018-4-9,2018,4,9,13,8avnxd,May giat Electrolux khong vao nuoc,https://www.reddit.com/r/MachineLearning/comments/8avnxd/may_giat_electrolux_khong_vao_nuoc/,electroluxhn,1523246511,,0,1
465,2018-4-9,2018,4,9,13,8avnxt,[P] PyTorch-NLP: Enabling Rapid NLP Prototyping with Research Tooling with Commented Code! (Github),https://www.reddit.com/r/MachineLearning/comments/8avnxt/p_pytorchnlp_enabling_rapid_nlp_prototyping_with/,[deleted],1523246514,[deleted],0,1
466,2018-4-9,2018,4,9,13,8avoca,[P] PyTorch-NLP: Supporting Rapid NLP Prototyping with Proper Tooling and Commented Code! (Github),https://www.reddit.com/r/MachineLearning/comments/8avoca/p_pytorchnlp_supporting_rapid_nlp_prototyping/,[deleted],1523246636,[deleted],0,1
467,2018-4-9,2018,4,9,13,8avoms,[P] PyTorch-NLP: Supporting Rapid NLP Prototyping with a Toolkit and Commented Code! (Github),https://www.reddit.com/r/MachineLearning/comments/8avoms/p_pytorchnlp_supporting_rapid_nlp_prototyping/,[deleted],1523246699,[deleted],1,2
468,2018-4-9,2018,4,9,13,8avrk1,Why python?,https://www.reddit.com/r/MachineLearning/comments/8avrk1/why_python/,TheOtherGuy9603,1523247533,[removed],0,1
469,2018-4-9,2018,4,9,14,8aw1jr,"Losswise is a monitoring/analytics tool for ML that offers graphs in real time, completion estimates, side-by-side comparisons, smart notifications, and powerful integrations.",https://www.reddit.com/r/MachineLearning/comments/8aw1jr/losswise_is_a_monitoringanalytics_tool_for_ml/,kaitlinmcunningham,1523250586,,0,1
470,2018-4-9,2018,4,9,14,8aw8no,"Speech Verification : Which is a better model, I-Vector based approach with GMM or CNNs?",https://www.reddit.com/r/MachineLearning/comments/8aw8no/speech_verification_which_is_a_better_model/,PM_ME_YOUR_PRESETS,1523253052,[removed],0,1
471,2018-4-9,2018,4,9,14,8aw978,12 Atomic Experiments in Deep Learning [Notebook],https://www.reddit.com/r/MachineLearning/comments/8aw978/12_atomic_experiments_in_deep_learning_notebook/,princealiiiii,1523253223,,1,1
472,2018-4-9,2018,4,9,15,8awh8g,[R] Neural Autoregressive Flows,https://www.reddit.com/r/MachineLearning/comments/8awh8g/r_neural_autoregressive_flows/,baylearn,1523256173,,0,20
473,2018-4-9,2018,4,9,15,8awhnm,Is machine learning pretty much just trial and error?,https://www.reddit.com/r/MachineLearning/comments/8awhnm/is_machine_learning_pretty_much_just_trial_and/,letstryusingreddit,1523256360,[removed],0,1
474,2018-4-9,2018,4,9,15,8awjgu,[D] Waht advantages could a quantum computer have for DL?,https://www.reddit.com/r/MachineLearning/comments/8awjgu/d_waht_advantages_could_a_quantum_computer_have/,91user,1523257028,Are there already some suitable algorithms? Any papers?,14,0
475,2018-4-9,2018,4,9,17,8awtdc,Bishop PRML a bit difficult to read.,https://www.reddit.com/r/MachineLearning/comments/8awtdc/bishop_prml_a_bit_difficult_to_read/,Nag_Slayer,1523260983,[removed],0,1
476,2018-4-9,2018,4,9,17,8awvcu,[D] looking for help to choose between two machine learning internships.,https://www.reddit.com/r/MachineLearning/comments/8awvcu/d_looking_for_help_to_choose_between_two_machine/,thatsadsid,1523261730,"I have two internship options, both in the field of machine learning. They are as follows

Just to mention, I'm a beginner at machine learning.

Company 1: 
-Work is related to detecting pattern in wireless sensor data. 

-Would have to build models in Python (which I prefer) 

-Would be comparetivly easy and give me free time to pursue online courses in machine learning and math. (This is the biggest advantage for me, as I am weak at math and would have to use it a lot in my thesis).

-There would be no mentor, would have to do it all by myself (only the professor to guide me). (This is the biggest drawback, as they don't have an experienced ML engineer and no existing model I can work with).

Company 2
-Works with computer vision (which I don't know).

-Would have to implement algorithms in c++ (which I hear is hard as several algorithms have to be implemented from scratch).

-Would be hard cause I have no knowledge of computer vision, or good knowledge of machine learning and it won't give me time to pursue online courses to solidify my skills.(biggest drawback, as my math is weak and wouldn't give me time to brush up on it.)

-There would be an experienced ML engineer and a computer vision expert to guide me, and they have an existing product that I would be working on (biggest advantage, would give me a chance to learn a lot.)


My end goal is not to work in the field of computer vision. Just learn machine learning and be good at it. Which one should I go for? First company gives me time and flexibility to be better at ML and math myself but no professional guidance, and second one doesn't give me time and flexibility to be better at math but gives me a chance to learn from experts and work on an already existing system.

Please help me choose.",6,0
477,2018-4-9,2018,4,9,17,8awwe1,an intelligent way of using humans in the loop,https://www.reddit.com/r/MachineLearning/comments/8awwe1/an_intelligent_way_of_using_humans_in_the_loop/,saltedcashew,1523262193,,0,1
478,2018-4-9,2018,4,9,17,8awxso,[D] Open Research problems in Deep Learning and Computer Vision?,https://www.reddit.com/r/MachineLearning/comments/8awxso/d_open_research_problems_in_deep_learning_and/,cbsudux,1523262798,"I currently explore Image Captioning, VQA, and Scene Understanding and I want to gain a deeper understanding. What are some important and open research problems in these areas?",2,0
479,2018-4-9,2018,4,9,18,8ax49l,[P]Help implementation Text Clustering,https://www.reddit.com/r/MachineLearning/comments/8ax49l/phelp_implementation_text_clustering/,JackEpp,1523265444,"I'm working on text clustering and I would like to know if i can use this paper https://link.springer.com/article/10.1007/s10618-012-0249-y in order to do text clustering.
Does someone know some exisiting implmentation of this paper?",0,0
480,2018-4-9,2018,4,9,18,8ax5ip,case IH parts catalog,https://www.reddit.com/r/MachineLearning/comments/8ax5ip/case_ih_parts_catalog/,Mypremiummanual,1523265986,,0,1
481,2018-4-9,2018,4,9,18,8ax7eb,Detroit Diesel service manual,https://www.reddit.com/r/MachineLearning/comments/8ax7eb/detroit_diesel_service_manual/,Mypremiummanual,1523266768,,0,1
482,2018-4-9,2018,4,9,18,8ax8x7,[P] AI makes Donald Trump speak Korean,https://www.reddit.com/r/MachineLearning/comments/8ax8x7/p_ai_makes_donald_trump_speak_korean/,cyplus1,1523267431,,20,43
483,2018-4-9,2018,4,9,19,8axgzm,Tea Leaf Filling Machine,https://www.reddit.com/r/MachineLearning/comments/8axgzm/tea_leaf_filling_machine/,lgsherry,1523270476,,1,1
484,2018-4-9,2018,4,9,19,8axh3i,Get StripMeister E2000X Industrial Wire Stripping Machine at StripMeister with these coupons,https://www.reddit.com/r/MachineLearning/comments/8axh3i/get_stripmeister_e2000x_industrial_wire_stripping/,Reviews_For_Save_12,1523270514,[removed],0,1
485,2018-4-9,2018,4,9,19,8axh44,"""[D]"" Need suggestions on creative ways to approach Prostate Cancer detection using deep learning, I have already tried various ways but none of them is good enough.",https://www.reddit.com/r/MachineLearning/comments/8axh44/d_need_suggestions_on_creative_ways_to_approach/,omayrakhtar,1523270523,"I am doing my master thesis titled 'Prostate Cancer Detection using mpMRI scans'. It is a multi-class classification problem with 5 classed. The dataset consists of 112 data points, there are 4 different image modalities. I have tried various techniques of data augmentation using ImgAug (python library) and used custom CNN as well as state of the art architectures like Inception, Xception and Resnet but nothing seems to yield any reasonable results. I have used Accuracy and Quadratic Cohen's Kappa as evaluation metrics.

Link to Image Augmentation library: https://github.com/aleju/imgaug

Link to the dataset: http://spiechallenges.cloudapp.net/competitions/7#learn_the_details",27,2
486,2018-4-9,2018,4,9,20,8axnmk,[D] Metric taking into account webpage position?,https://www.reddit.com/r/MachineLearning/comments/8axnmk/d_metric_taking_into_account_webpage_position/,nikitalpopov,1523272767,"I build a website classifier that uses text data of each page. The data is extracted from websites using the ""first broad"" method (i.e. start with data for pages that can be visited in 1 redirection from the main page, then the page with 2 redirections, etc.).

Then the bag of words of each page is built and the model is trained. But I would like to have some metric which will make training data for pages with less redirections to have a greater weight (or ""significance"", I don't actually know how to call it) for classifier training. So I want kind of (1/n) * weight_of_bag_of_words.

What metric should be? How can I apply it? Appreciate any help.

-----------------------
*UPD:* Thanks @olBaa for idea with PageRank
So if I want to combine bag of words with PageRank for training, what should I consider to use? Pipelines (in terms of python's scikit)? ",2,0
487,2018-4-9,2018,4,9,21,8axwfq,Self Attention Similarity of Query with its own Key.,https://www.reddit.com/r/MachineLearning/comments/8axwfq/self_attention_similarity_of_query_with_its_own/,lysecret,1523275572,[removed],0,1
488,2018-4-9,2018,4,9,21,8axwn8,"What are the input embeddings of the encoder before merging with positional encoding in the ""Attention is all you need"" paper ?",https://www.reddit.com/r/MachineLearning/comments/8axwn8/what_are_the_input_embeddings_of_the_encoder/,FlyingDope,1523275619,,0,1
489,2018-4-9,2018,4,9,21,8axxc3,"[N] TextQL, Colorless Green RNNs, ConvAI2, Machine Learning Yearning, Meta-Learning Tutorial, Tinn, World Models,",https://www.reddit.com/r/MachineLearning/comments/8axxc3/n_textql_colorless_green_rnns_convai2_machine/,omarsar,1523275822,,0,7
490,2018-4-9,2018,4,9,21,8ay03d,[N] Only Numpy: Understanding Back Propagation for Transpose Convolution in Multi Layer CNN with,https://www.reddit.com/r/MachineLearning/comments/8ay03d/n_only_numpy_understanding_back_propagation_for/,polllyyy,1523276651,,0,1
491,2018-4-9,2018,4,9,21,8ay16d,paradox,https://www.reddit.com/r/MachineLearning/comments/8ay16d/paradox/,gama91gama,1523276960,[removed],0,1
492,2018-4-9,2018,4,9,21,8ay1ho,Why we are mentioning the -1 index in argsort after sorting,https://www.reddit.com/r/MachineLearning/comments/8ay1ho/why_we_are_mentioning_the_1_index_in_argsort/,lokeshkumarn,1523277039,[removed],0,1
493,2018-4-9,2018,4,9,21,8ay304,[R] How to Make Predictions with Keras,https://www.reddit.com/r/MachineLearning/comments/8ay304/r_how_to_make_predictions_with_keras/,janemoz,1523277473,,0,1
494,2018-4-9,2018,4,9,21,8ay4u6,[P] Lessons learned reproducing a deep reinforcement learning paper,https://www.reddit.com/r/MachineLearning/comments/8ay4u6/p_lessons_learned_reproducing_a_deep/,mrahtz,1523277979,,29,339
495,2018-4-9,2018,4,9,22,8aybo7,[Discussion] The impact of Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8aybo7/discussion_the_impact_of_azure_machine_learning/,Detharatsh,1523279767,"What impact (if any) will Azure Machine Learning have on the ML industry? It seems to me that the biggest impact will be on ML consultancies who would have built algorithms for their clients. Are tools like this the ""BI"" (a la Tableau) of the future?",3,3
496,2018-4-9,2018,4,9,22,8ayc8y,Slack Release Notes : How release notes should be,https://www.reddit.com/r/MachineLearning/comments/8ayc8y/slack_release_notes_how_release_notes_should_be/,[deleted],1523279906,[deleted],0,1
497,2018-4-9,2018,4,9,22,8ayflo,[R] Choosing the Right Metric for Evaluating ML Models  Part 1,https://www.reddit.com/r/MachineLearning/comments/8ayflo/r_choosing_the_right_metric_for_evaluating_ml/,polllyyy,1523280784,,0,1
498,2018-4-9,2018,4,9,23,8ayoxd,[P] PyTorch Impl. of Stabilizing Adversarial Nets with Prediction Methods (https://openreview.net/pdf?id=Skj8Kag0Z),https://www.reddit.com/r/MachineLearning/comments/8ayoxd/p_pytorch_impl_of_stabilizing_adversarial_nets/,goodcarrot,1523283008,,2,11
499,2018-4-10,2018,4,10,0,8azes4,Image augmentation: the weather aspect,https://www.reddit.com/r/MachineLearning/comments/8azes4/image_augmentation_the_weather_aspect/,erujjwalsaxena,1523288731,,0,1
500,2018-4-10,2018,4,10,0,8azhyx,Which ML algorithms can handle non linear data?,https://www.reddit.com/r/MachineLearning/comments/8azhyx/which_ml_algorithms_can_handle_non_linear_data/,aaditkapoor1201,1523289373,[removed],0,0
501,2018-4-10,2018,4,10,1,8azk2n,[D] OpenAI Charter,https://www.reddit.com/r/MachineLearning/comments/8azk2n/d_openai_charter/,sksq9,1523289819,,18,23
502,2018-4-10,2018,4,10,1,8azk5b,Simultaneous Detection and Segmentation (SDS) Doubt,https://www.reddit.com/r/MachineLearning/comments/8azk5b/simultaneous_detection_and_segmentation_sds_doubt/,ShivamDuggal4,1523289830,[removed],0,1
503,2018-4-10,2018,4,10,1,8azrfa,Which algorithms that use neural networks can be used to play games?,https://www.reddit.com/r/MachineLearning/comments/8azrfa/which_algorithms_that_use_neural_networks_can_be/,LachubCz,1523291282,[removed],0,1
504,2018-4-10,2018,4,10,1,8aztls,"Question about ""Show, Attend and Tell"" paper",https://www.reddit.com/r/MachineLearning/comments/8aztls/question_about_show_attend_and_tell_paper/,skbol,1523291757,[removed],0,1
505,2018-4-10,2018,4,10,1,8azzp2,How can use information gain in text classification? and what output will be like?,https://www.reddit.com/r/MachineLearning/comments/8azzp2/how_can_use_information_gain_in_text/,khaldoon83,1523293063,[removed],0,1
506,2018-4-10,2018,4,10,2,8b0a5h,Generating Drake Lyrics with a Language Model [OC],https://www.reddit.com/r/MachineLearning/comments/8b0a5h/generating_drake_lyrics_with_a_language_model_oc/,nikolaevra,1523295180,,0,1
507,2018-4-10,2018,4,10,2,8b0agu,Created a model to order documents according to their relevance to a query. Try it on your custom data.,https://www.reddit.com/r/MachineLearning/comments/8b0agu/created_a_model_to_order_documents_according_to/,JClub,1523295243,,0,1
508,2018-4-10,2018,4,10,2,8b0bo4,[N] The reference implementation of Tsetlin Machine is out (Cython),https://www.reddit.com/r/MachineLearning/comments/8b0bo4/n_the_reference_implementation_of_tsetlin_machine/,sorrge,1523295494,,10,17
509,2018-4-10,2018,4,10,2,8b0hib,"Where can I still apply for Machine Learning, Deep Learning or Computer Vision research intern preferably in a University as of now(10th April, 2018) for the summers?",https://www.reddit.com/r/MachineLearning/comments/8b0hib/where_can_i_still_apply_for_machine_learning_deep/,Barvin04,1523296686,[removed],0,1
510,2018-4-10,2018,4,10,2,8b0hvo,"[N] SenseTime (Hong Kong-based CV startup) is now worth $3bn, the most valuable AI startup in the world.",https://www.reddit.com/r/MachineLearning/comments/8b0hvo/n_sensetime_hong_kongbased_cv_startup_is_now/,wei_jok,1523296759,,9,9
511,2018-4-10,2018,4,10,3,8b0ias,How we built a 'Hot Dog or Not' machine learning app in 30min without code,https://www.reddit.com/r/MachineLearning/comments/8b0ias/how_we_built_a_hot_dog_or_not_machine_learning/,adserena,1523296852,,0,1
512,2018-4-10,2018,4,10,3,8b0ugx,Accurate Roulette Prediction,https://www.reddit.com/r/MachineLearning/comments/8b0ugx/accurate_roulette_prediction/,sikali21,1523299373,[removed],0,1
513,2018-4-10,2018,4,10,3,8b0vqf,Training data at scale,https://www.reddit.com/r/MachineLearning/comments/8b0vqf/training_data_at_scale/,buflowsean,1523299612,,0,1
514,2018-4-10,2018,4,10,3,8b0y1o,Reinforcement Learning for Recommendation System,https://www.reddit.com/r/MachineLearning/comments/8b0y1o/reinforcement_learning_for_recommendation_system/,salonimundra,1523300058,[removed],0,1
515,2018-4-10,2018,4,10,4,8b14lq,How Math and Computational Geometry Influence Digital Art,https://www.reddit.com/r/MachineLearning/comments/8b14lq/how_math_and_computational_geometry_influence/,nlogox,1523301426,,0,1
516,2018-4-10,2018,4,10,4,8b17s0,[D] Help to build a content based Recommendation Engine,https://www.reddit.com/r/MachineLearning/comments/8b17s0/d_help_to_build_a_content_based_recommendation/,knowme_or_hateme,1523302065,[removed],0,1
517,2018-4-10,2018,4,10,4,8b1ap8,Is Nvidia Titan V worth its price tag for deep learning projects?,https://www.reddit.com/r/MachineLearning/comments/8b1ap8/is_nvidia_titan_v_worth_its_price_tag_for_deep/,fr0zen32,1523302684,[removed],1,1
518,2018-4-10,2018,4,10,5,8b1h2m,Ejemplos adversos que engaan tanto a la visin humana como a la artificial,https://www.reddit.com/r/MachineLearning/comments/8b1h2m/ejemplos_adversos_que_engaan_tanto_a_la_visin/,zgustv,1523304015,,0,1
519,2018-4-10,2018,4,10,5,8b1ox2,[How-to] Easily distribute ML with H2O + Apache Spark,https://www.reddit.com/r/MachineLearning/comments/8b1ox2/howto_easily_distribute_ml_with_h2o_apache_spark/,younggrindin,1523305645,,0,2
520,2018-4-10,2018,4,10,5,8b1uv5,Preference learning by creating user preference vectors: do you know how to explain to me the basics?,https://www.reddit.com/r/MachineLearning/comments/8b1uv5/preference_learning_by_creating_user_preference/,blue_sky_london,1523306860,[removed],0,1
521,2018-4-10,2018,4,10,6,8b20bn,"In DQN, how much can feature engineering improve sample efficiency?",https://www.reddit.com/r/MachineLearning/comments/8b20bn/in_dqn_how_much_can_feature_engineering_improve/,yazriel0,1523308021,[removed],0,1
522,2018-4-10,2018,4,10,6,8b21yx,[N] International Jobs in Machine Learning / Data Science,https://www.reddit.com/r/MachineLearning/comments/8b21yx/n_international_jobs_in_machine_learning_data/,fuck_your_diploma,1523308382,,0,2
523,2018-4-10,2018,4,10,7,8b2pqj,[R] AI Grant Research: Small Object Detection,https://www.reddit.com/r/MachineLearning/comments/8b2pqj/r_ai_grant_research_small_object_detection/,nataigrant,1523313727,,1,3
524,2018-4-10,2018,4,10,8,8b2w1u,[P] Simple and Clean Keras Project Template Architecture,https://www.reddit.com/r/MachineLearning/comments/8b2w1u/p_simple_and_clean_keras_project_template/,Ahmed_El_Hinidy,1523315248,,1,32
525,2018-4-10,2018,4,10,10,8b3rhx,[N] [data available] Breaking: Researchers at CERN break The Speed of Light,https://www.reddit.com/r/MachineLearning/comments/8b3rhx/n_data_available_breaking_researchers_at_cern/,[deleted],1523323029,[deleted],2,1
526,2018-4-10,2018,4,10,10,8b3yb7,[R] [1804.02485] Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations [SheepMind],https://www.reddit.com/r/MachineLearning/comments/8b3yb7/r_180402485_fortified_networks_improving_the/,evc123,1523324754,,13,9
527,2018-4-10,2018,4,10,11,8b47hp,Artificial Intelligence Survey for College,https://www.reddit.com/r/MachineLearning/comments/8b47hp/artificial_intelligence_survey_for_college/,MrStricty,1523327116,[removed],0,1
528,2018-4-10,2018,4,10,11,8b49yl,Learning about DAO's. Fascinating... and scary,https://www.reddit.com/r/MachineLearning/comments/8b49yl/learning_about_daos_fascinating_and_scary/,Promontory_Tech,1523327750,,0,1
529,2018-4-10,2018,4,10,12,8b4j5t,[D] What can Machine?!,https://www.reddit.com/r/MachineLearning/comments/8b4j5t/d_what_can_machine/,[deleted],1523330143,[deleted],0,1
530,2018-4-10,2018,4,10,12,8b4nn0,Granulation equipment for making Cow manure granules fertilizer,https://www.reddit.com/r/MachineLearning/comments/8b4nn0/granulation_equipment_for_making_cow_manure/,amylee516,1523331356,,0,1
531,2018-4-10,2018,4,10,12,8b4s3s,Tigernut Milk Maker|Peanut Milk Making Machine Suppliers,https://www.reddit.com/r/MachineLearning/comments/8b4s3s/tigernut_milk_makerpeanut_milk_making_machine/,gelserena,1523332626,,1,1
532,2018-4-10,2018,4,10,13,8b4vi0,[D] Anyone having trouble reading a particular paper? Post it here and we'll help figure out any parts you are stuck on.,https://www.reddit.com/r/MachineLearning/comments/8b4vi0/d_anyone_having_trouble_reading_a_particular/,BatmantoshReturns,1523333556,"I was surprised to hear that even Andrew Ng has trouble reading certain papers at times and he reaches out to other experts to get help, so I guess that it's something most of us will probably always have to deal with to some extent or another. 

If you're having trouble with a particular paper, post it with the parts you are having trouble with, and hopefully me or someone else may help out. It'll be like a mini study group to extract as much valuable info from each paper. 

Even if it's a paper that you're not per say totally stuck on, but it's just that it'll take a while to completely figure out, post it anyway in case you find some value in shaving off some precious time in pursuing the total comprehension of that paper, so that you can more quickly move onto other papers. 

",135,535
533,2018-4-10,2018,4,10,13,8b4vk0,Preparing image data set for training.,https://www.reddit.com/r/MachineLearning/comments/8b4vk0/preparing_image_data_set_for_training/,Obscurial_gg,1523333566,[removed],0,1
534,2018-4-10,2018,4,10,13,8b4z73,[R] [1804.02477] Programmatically Interpretable Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8b4z73/r_180402477_programmatically_interpretable/,averma2477,1523334595,,2,9
535,2018-4-10,2018,4,10,15,8b5np9,[D] Has any one heard back from Microsoft AI Residency?,https://www.reddit.com/r/MachineLearning/comments/8b5np9/d_has_any_one_heard_back_from_microsoft_ai/,WinPetrol,1523342964,"I've applied there too by Feb 28, 2018, but haven't really heard anything back yet. I tried contacting AIResidency@microsoft.com without any luck. Have anyone of you heard back from them? I've got some university admits to decide as well with deadline approaching. ",11,0
536,2018-4-10,2018,4,10,16,8b5vp9,"[R] My first paper on Ordinal Pooling Networks, a pooling technique in CNN (completed in part time)",https://www.reddit.com/r/MachineLearning/comments/8b5vp9/r_my_first_paper_on_ordinal_pooling_networks_a/,[deleted],1523345980,[deleted],0,1
537,2018-4-10,2018,4,10,16,8b5xip,"[R] My first paper on Ordinal Pooling Networks, a novel pooling scheme in CNNs (completed in part time), would appreciate some feedback, Thanks!",https://www.reddit.com/r/MachineLearning/comments/8b5xip/r_my_first_paper_on_ordinal_pooling_networks_a/,ashz8888,1523346716,,7,4
538,2018-4-10,2018,4,10,18,8b6b8w,Learn About Essential Math Competencies in Machine Learning For Free,https://www.reddit.com/r/MachineLearning/comments/8b6b8w/learn_about_essential_math_competencies_in/,ciaracodes,1523352210,,0,1
539,2018-4-10,2018,4,10,18,8b6c38,An implementation of the SRPGAN paper in Pytorch: https://arxiv.org/abs/1712.05927,https://www.reddit.com/r/MachineLearning/comments/8b6c38/an_implementation_of_the_srpgan_paper_in_pytorch/,Ekami66,1523352567,[removed],0,1
540,2018-4-10,2018,4,10,18,8b6dou,Understanding Decision Boundaries in ML/AI,https://www.reddit.com/r/MachineLearning/comments/8b6dou/understanding_decision_boundaries_in_mlai/,skeering,1523353186,[removed],0,1
541,2018-4-10,2018,4,10,19,8b6mxr,"[P] quick-nlp. Pytorch library extending fastai for nlp tasks, seq2seq and conversation models",https://www.reddit.com/r/MachineLearning/comments/8b6mxr/p_quicknlp_pytorch_library_extending_fastai_for/,outcastofmusic,1523356722,,4,5
542,2018-4-10,2018,4,10,19,8b6ns0,DEEP LEARNING CAMP JEJU,https://www.reddit.com/r/MachineLearning/comments/8b6ns0/deep_learning_camp_jeju/,seleucia,1523357064,,1,1
543,2018-4-10,2018,4,10,19,8b6oiz,What is Machine Learning and How it is different from Artificial Intelligence?,https://www.reddit.com/r/MachineLearning/comments/8b6oiz/what_is_machine_learning_and_how_it_is_different/,vince181,1523357314,,0,1
544,2018-4-10,2018,4,10,19,8b6pqk,What are Neural Networks in Machine Learning  Data Science Jargon,https://www.reddit.com/r/MachineLearning/comments/8b6pqk/what_are_neural_networks_in_machine_learning_data/,howaboutdata,1523357759,,0,1
545,2018-4-10,2018,4,10,20,8b6re8,Inner Bag Packing Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/8b6re8/inner_bag_packing_machine_for_sale/,lgsherry,1523358318,,1,1
546,2018-4-10,2018,4,10,20,8b6w3k,Machine Learning In The Cloud With Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8b6w3k/machine_learning_in_the_cloud_with_azure_machine/,EdwardSchmitt21,1523359786,[removed],0,1
547,2018-4-10,2018,4,10,20,8b6yn4,Need help on starting machine learning,https://www.reddit.com/r/MachineLearning/comments/8b6yn4/need_help_on_starting_machine_learning/,dipbazz,1523360593,[removed],0,1
548,2018-4-10,2018,4,10,20,8b6yzc,[P] The 1cycle policy - an experimental implementation to investigate super-convergence phenomenon described in Leslie Smith's research,https://www.reddit.com/r/MachineLearning/comments/8b6yzc/p_the_1cycle_policy_an_experimental/,[deleted],1523360696,[deleted],0,1
549,2018-4-10,2018,4,10,20,8b701g,the cloud with Azure Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/8b701g/the_cloud_with_azure_machine_learning/,SmartUdemy,1523361015,,0,1
550,2018-4-10,2018,4,10,21,8b72tx,[P] The 1cycle policy - an experiment that investigate super-convergence phenomenon described in Leslie Smith's research,https://www.reddit.com/r/MachineLearning/comments/8b72tx/p_the_1cycle_policy_an_experiment_that/,cedrickchee,1523361829,,2,14
551,2018-4-10,2018,4,10,21,8b73n8,Question relating to querying a collection of texts using ML/MLaaS,https://www.reddit.com/r/MachineLearning/comments/8b73n8/question_relating_to_querying_a_collection_of/,lostandforgottensoul,1523362074,[removed],0,1
552,2018-4-10,2018,4,10,22,8b7gma,[D] shift and stitch upsampling FCN,https://www.reddit.com/r/MachineLearning/comments/8b7gma/d_shift_and_stitch_upsampling_fcn/,ShivamDuggal4,1523365630,"Fully Convolution paper proposed shift and stitch approach for upsampling. Can some please explain it.

The input is shifted using f*f combinations of horizontal and vertical shifts, where f is the downsampled scale. Now all the inputs are passed through a conv net and their outputs are added.
How does this upsample the input feature map? This according to me would increase the receptive field. ",4,3
553,2018-4-10,2018,4,10,22,8b7khy,Raisin Washer Dryer|Wheat Cleaning Drying Mahine,https://www.reddit.com/r/MachineLearning/comments/8b7khy/raisin_washer_dryerwheat_cleaning_drying_mahine/,gelserena,1523366770,,6,0
554,2018-4-10,2018,4,10,22,8b7lha,leadership affects your business in future?,https://www.reddit.com/r/MachineLearning/comments/8b7lha/leadership_affects_your_business_in_future/,kieraberry48,1523367044,,1,0
555,2018-4-10,2018,4,10,22,8b7oj9,Transfer Learning for classification on videos,https://www.reddit.com/r/MachineLearning/comments/8b7oj9/transfer_learning_for_classification_on_videos/,atulshanbhag,1523367866,"Does anyone have any experience in using pre-trained models (such as ResNet, Inception, DenseNet, etc) for videos. I intend to use the spatial weights shared across the temporal dimension of my convnet, and proceed training on this architecture. I intend to implement [this paper](https://arxiv.org/abs/1711.08200). 

I want to know what's the best way to do this. If I am to use Tensorflow / Keras, is it good enough if I extract weights from pretrained models and set weights to my model to each depth manually. ",0,1
556,2018-4-10,2018,4,10,22,8b7qf9,Python wrapper on YOLO 3.0,https://www.reddit.com/r/MachineLearning/comments/8b7qf9/python_wrapper_on_yolo_30/,madhawav,1523368385,,1,3
557,2018-4-10,2018,4,10,22,8b7r39,Data science mock interview,https://www.reddit.com/r/MachineLearning/comments/8b7r39/data_science_mock_interview/,naveenslog,1523368562,I am preparing for data science interviews. Is there any place where someone can take my mock interviews based on my resume. ,0,1
558,2018-4-10,2018,4,10,23,8b7sru,ASL Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8b7sru/asl_machine_learning/,PlasmaBolt,1523369003,"I'm trying to build an ML program to classify hand gesture motions of ASL into words. I understand that static hand signs can be classified using a CNN but I'm not sure how to incorporate motions which are prevalent in ASL beyond the basic alphabet. One idea I had was to wear a glove with different neon colors on both sides so that I could easily isolate and trace a path of the hand's motion (possible with OpenCV), but I think it's still open to flaws. What do you think? Are there better alternatives to this, e.g. a way to perform ML on video streams? ",1,1
559,2018-4-10,2018,4,10,23,8b7tue,How deep learning helps healthcare and weather forecasting industries achieve more with less,https://www.reddit.com/r/MachineLearning/comments/8b7tue/how_deep_learning_helps_healthcare_and_weather/,[deleted],1523369284,[deleted],0,1
560,2018-4-10,2018,4,10,23,8b7vno,A personal selection of what made March important in AI/ML,https://www.reddit.com/r/MachineLearning/comments/8b7vno/a_personal_selection_of_what_made_march_important/,clementwalter,1523369757,,0,2
561,2018-4-10,2018,4,10,23,8b7wgl,[R] How to Design Better Machine Learning Systems with Machine Learning Canvas,https://www.reddit.com/r/MachineLearning/comments/8b7wgl/r_how_to_design_better_machine_learning_systems/,chris_shpak,1523369965,,0,1
562,2018-4-10,2018,4,10,23,8b7wzy,Quantum Computing and AI Tie the Knot  Towards Data Science,https://www.reddit.com/r/MachineLearning/comments/8b7wzy/quantum_computing_and_ai_tie_the_knot_towards/,roelljr,1523370113,,0,1
563,2018-4-10,2018,4,10,23,8b7y9e,Help for my research: Objectively high quality / low quality channels,https://www.reddit.com/r/MachineLearning/comments/8b7y9e/help_for_my_research_objectively_high_quality_low/,gdemos01,1523370424,[removed],0,1
564,2018-4-10,2018,4,10,23,8b7zsk,Machine learning &amp; language complexity: why chatbots cant talk yet,https://www.reddit.com/r/MachineLearning/comments/8b7zsk/machine_learning_language_complexity_why_chatbots/,yfletberliac,1523370822,,0,1
565,2018-4-10,2018,4,10,23,8b81rp,Help: High quality VS Low Quality videos dataset creation,https://www.reddit.com/r/MachineLearning/comments/8b81rp/help_high_quality_vs_low_quality_videos_dataset/,mrsailor23,1523371352,[removed],0,1
566,2018-4-10,2018,4,10,23,8b82dp,[D] Can I use text web to train models and share them ? Can I use them for commercial purpose ?,https://www.reddit.com/r/MachineLearning/comments/8b82dp/d_can_i_use_text_web_to_train_models_and_share/,Jean-Porte,1523371517,"I want to build a dataset and models based on massive text. But I think my work would be less valuable if models and datasets aren't free.

I'm quite surprised that GloVe trained on GigaWord (which is a paid corpus, not free at all) have 
 ""public domain license"" which seems the most permissive
https://nlp.stanford.edu/projects/glove/

Do you know if I can do the same with web text ? Commoncrawl must be a a particular subset of the web. I'm using this web based dataset http://sketch.juls.savba.sk/aranea_about/index.html

Thanks",1,1
567,2018-4-11,2018,4,11,0,8b8afy,"This specialization is an outstanding program. The instructors strike the right balance between theory and practice. Even though I consider myself quite literate in statistics and numerical optimization, I learned several new techniques that I was able to directly apply in various parts of my job.",https://www.reddit.com/r/MachineLearning/comments/8b8afy/this_specialization_is_an_outstanding_program_the/,angela7walker,1523373180,,0,1
568,2018-4-11,2018,4,11,0,8b8c3g,Any ideas on how to do named entity sentiment analysis?,https://www.reddit.com/r/MachineLearning/comments/8b8c3g/any_ideas_on_how_to_do_named_entity_sentiment/,[deleted],1523373478,[deleted],0,1
569,2018-4-11,2018,4,11,0,8b8csk,[R] DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills,https://www.reddit.com/r/MachineLearning/comments/8b8csk/r_deepmimic_exampleguided_deep_reinforcement/,MetricSpade007,1523373610,,1,39
570,2018-4-11,2018,4,11,0,8b8dme,Polynomial regression in C++ with XTensor library,https://www.reddit.com/r/MachineLearning/comments/8b8dme/polynomial_regression_in_c_with_xtensor_library/,[deleted],1523373756,[deleted],0,1
571,2018-4-11,2018,4,11,0,8b8dz1,Simulated characters learning acrobatics and martial arts.,https://www.reddit.com/r/MachineLearning/comments/8b8dz1/simulated_characters_learning_acrobatics_and/,xbpeng,1523373807,,0,1
572,2018-4-11,2018,4,11,0,8b8hci,NEAT algorithm,https://www.reddit.com/r/MachineLearning/comments/8b8hci/neat_algorithm/,Tomaster777,1523374422,[removed],0,1
573,2018-4-11,2018,4,11,0,8b8kgd,"Analyzing sentiment patterns on 3000 securities using machine-learning -- 30k articles, 500k social media posts analyzed per week -- help the system make smarter predictions by using the front-end interface I developed",https://www.reddit.com/r/MachineLearning/comments/8b8kgd/analyzing_sentiment_patterns_on_3000_securities/,TheLoneDonut,1523375001,[removed],0,1
574,2018-4-11,2018,4,11,1,8b8rp4,"Multilayer Perceptron works fine with sigmoid activations, but not with hyperbolic tangent",https://www.reddit.com/r/MachineLearning/comments/8b8rp4/multilayer_perceptron_works_fine_with_sigmoid/,[deleted],1523376313,,0,1
575,2018-4-11,2018,4,11,1,8b8w3z,Any ideas on how to do named entity sentiment analysis?,https://www.reddit.com/r/MachineLearning/comments/8b8w3z/any_ideas_on_how_to_do_named_entity_sentiment/,EquivalentSelf,1523377149,,0,1
576,2018-4-11,2018,4,11,1,8b91tc,[R] Differentiable Plasticity (UberAI),https://www.reddit.com/r/MachineLearning/comments/8b91tc/r_differentiable_plasticity_uberai/,inarrears,1523378313,,20,151
577,2018-4-11,2018,4,11,1,8b9756,I am doing a PhD implementing Machine learning methodologies to a wave modelling problem. Will this open up future careers in machine learning?,https://www.reddit.com/r/MachineLearning/comments/8b9756/i_am_doing_a_phd_implementing_machine_learning/,JP_Data,1523379320,[removed],0,1
578,2018-4-11,2018,4,11,2,8b9dce,[R] Towards a Virtual Stuntman,https://www.reddit.com/r/MachineLearning/comments/8b9dce/r_towards_a_virtual_stuntman/,gdny,1523380468,,7,96
579,2018-4-11,2018,4,11,2,8b9f65,"[P] Supporting rapid prototyping for research, I am LAUNCHING PyTorch-NLP, a deep learning NLP toolkit!",https://www.reddit.com/r/MachineLearning/comments/8b9f65/p_supporting_rapid_prototyping_for_research_i_am/,Deepblue129,1523380814,,1,0
580,2018-4-11,2018,4,11,2,8b9gcv,[P] NuDream - Some changes were made in the original Deep Dream's code to get more control or change the outcome.,https://www.reddit.com/r/MachineLearning/comments/8b9gcv/p_nudream_some_changes_were_made_in_the_original/,[deleted],1523381023,[deleted],0,1
581,2018-4-11,2018,4,11,2,8b9jgt,Smoothed Learning Rate Finder for Keras + SGDR and CLR,https://www.reddit.com/r/MachineLearning/comments/8b9jgt/smoothed_learning_rate_finder_for_keras_sgdr_and/,Koutix12,1523381587,,0,1
582,2018-4-11,2018,4,11,2,8b9pvy,tweets analysis techniques?,https://www.reddit.com/r/MachineLearning/comments/8b9pvy/tweets_analysis_techniques/,fedecaccia,1523382756,[removed],0,1
583,2018-4-11,2018,4,11,2,8b9qo9,[R] Deep Painterly Harmonization (PDF),https://www.reddit.com/r/MachineLearning/comments/8b9qo9/r_deep_painterly_harmonization_pdf/,hardmaru,1523382911,,4,21
584,2018-4-11,2018,4,11,3,8b9t7e,[D] projects that combine speech recognition and machine translation,https://www.reddit.com/r/MachineLearning/comments/8b9t7e/d_projects_that_combine_speech_recognition_and/,Jeriko_One,1523383375,"I am looking for any information about, hopefully completed, projects that combines separate speech recognition (text to speech) and machine translation neural networks to translate speech.

 Full write up with detail, and especially code included, would be very helpful. 

Also interested in discussion of how to combine the networks, inherent problems (error propagation), and encouraging areas of improvement",0,2
585,2018-4-11,2018,4,11,3,8ba2yk,[P] Keras Learning Rate Finder (+ SGDR and CLR),https://www.reddit.com/r/MachineLearning/comments/8ba2yk/p_keras_learning_rate_finder_sgdr_and_clr/,NathanHubens,1523385299,,5,22
586,2018-4-11,2018,4,11,4,8bamt3,Labeled Training Data at Scale,https://www.reddit.com/r/MachineLearning/comments/8bamt3/labeled_training_data_at_scale/,buflowsean,1523389059,,0,1
587,2018-4-11,2018,4,11,4,8bamvk,[D] Detailed description of completed kaggle submissions,https://www.reddit.com/r/MachineLearning/comments/8bamvk/d_detailed_description_of_completed_kaggle/,Jeriko_One,1523389075,"Would anyone have suggestions for outstanding individual examples of discussions of completed kaggle.com competition submissions; including code, discussions of techniques used, limitations, and suggestions for further research?",2,0
588,2018-4-11,2018,4,11,4,8baqjz,[D] Reusing neural networks for different tasks?,https://www.reddit.com/r/MachineLearning/comments/8baqjz/d_reusing_neural_networks_for_different_tasks/,rJohn420,1523389767,"Hi, I was wondering, is it possible to keep the newly learnt things?

This means that if you give the NN the inputs of a photo it recognizes whats in the photo, and if you give him a game of chess it plays the game.

I know you could handle everything with some code, and then run the specific purpose NN, but that would mean developer interaction,  which is not very nice.

I was thinking about using neutral neurons and detached thoughts.

Neutral neurons are neurons that do not affect the result in any way (they are effectively just a placeholder for something new to learn).

Detached thinking means triggering a specific set of neurons (the ones necessary for a specific task) while turning off others, to make sure that the result is correct (not affected by anything external) and also quick.

Is this possible in any way? Are my ideas crazy or they may have some value?

",3,0
589,2018-4-11,2018,4,11,4,8barva,Why is everyone doing the same thing in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8barva/why_is_everyone_doing_the_same_thing_in_machine/,aaditkapoor1201,1523390016,[removed],0,1
590,2018-4-11,2018,4,11,5,8bavgs,Machine Learning Platform architecture,https://www.reddit.com/r/MachineLearning/comments/8bavgs/machine_learning_platform_architecture/,falu2010,1523390712,[removed],0,1
591,2018-4-11,2018,4,11,5,8bbbl6,How you you explain a Principal Component Analysis to non-technical audience,https://www.reddit.com/r/MachineLearning/comments/8bbbl6/how_you_you_explain_a_principal_component/,The_Peter_Quill,1523393819,[removed],0,1
592,2018-4-11,2018,4,11,6,8bbe3i,[D] Online education recommendations,https://www.reddit.com/r/MachineLearning/comments/8bbe3i/d_online_education_recommendations/,Blahcub,1523394303,I've been attending college for about two years now and I want to transition to online education. I want a masters in machine learning and want to know of any programs people would recommend.,0,0
593,2018-4-11,2018,4,11,6,8bbm5f,con2d_transpose in TFLITE,https://www.reddit.com/r/MachineLearning/comments/8bbm5f/con2d_transpose_in_tflite/,ianholing,1523395906,[removed],0,1
594,2018-4-11,2018,4,11,7,8bc8sf,[P] A modular open-source image query dictionary for Android using Tensorflow Lite (TFlite) and SQLite,https://www.reddit.com/r/MachineLearning/comments/8bc8sf/p_a_modular_opensource_image_query_dictionary_for/,[deleted],1523400910,[deleted],0,1
595,2018-4-11,2018,4,11,8,8bcbk8,[P] A modular open-source image query dictionary app for Android using Tensorflow Lite (TFlite) and SQLite,https://www.reddit.com/r/MachineLearning/comments/8bcbk8/p_a_modular_opensource_image_query_dictionary_app/,htyspghtz,1523401510,,1,11
596,2018-4-11,2018,4,11,8,8bcf1q,"[P] PyTorch-NLP: Lightweight deep learning toolkit with common neural network modules, word vector loaders, dataset loaders, iterators and text encoders.",https://www.reddit.com/r/MachineLearning/comments/8bcf1q/p_pytorchnlp_lightweight_deep_learning_toolkit/,[deleted],1523402257,[deleted],0,1
597,2018-4-11,2018,4,11,8,8bciv2,"Call for Deep Learning Camp at Jeju, Korea (fully-funded)",https://www.reddit.com/r/MachineLearning/comments/8bciv2/call_for_deep_learning_camp_at_jeju_korea/,[deleted],1523403112,,0,1
598,2018-4-11,2018,4,11,8,8bclo5,"[N] Call for Deep Learning Camp at Jeju, Korea (fully-funded)",https://www.reddit.com/r/MachineLearning/comments/8bclo5/n_call_for_deep_learning_camp_at_jeju_korea/,[deleted],1523403742,,1,1
599,2018-4-11,2018,4,11,8,8bcmhf,"[N] Deep learning camp 2018 at Jeju, Korea",https://www.reddit.com/r/MachineLearning/comments/8bcmhf/n_deep_learning_camp_2018_at_jeju_korea/,[deleted],1523403925,,0,1
600,2018-4-11,2018,4,11,8,8bcokq,"""[N]"" Call for Deep Learning Camp at Jeju, Korea (Fully-funded)",https://www.reddit.com/r/MachineLearning/comments/8bcokq/n_call_for_deep_learning_camp_at_jeju_korea/,[deleted],1523404366,,0,1
601,2018-4-11,2018,4,11,8,8bcqht,"[D] Call for Deep learning camp 2018 at Jeju, Korea (fully-funded)",https://www.reddit.com/r/MachineLearning/comments/8bcqht/d_call_for_deep_learning_camp_2018_at_jeju_korea/,[deleted],1523404785,,0,1
602,2018-4-11,2018,4,11,9,8bcrb2,Probabilistic Item Mapping,https://www.reddit.com/r/MachineLearning/comments/8bcrb2/probabilistic_item_mapping/,[deleted],1523404974,,0,1
603,2018-4-11,2018,4,11,9,8bcrca,"[N] Deep learning camp at Jeju, Korea",https://www.reddit.com/r/MachineLearning/comments/8bcrca/n_deep_learning_camp_at_jeju_korea/,[deleted],1523404982,,0,1
604,2018-4-11,2018,4,11,9,8bcssm,"[N] Call for Deep Learning Camp, Jeju, Korea (fully-funded)",https://www.reddit.com/r/MachineLearning/comments/8bcssm/n_call_for_deep_learning_camp_jeju_korea/,terryum,1523405346,"""Deep learning camp Jeju (DL@Jeju)"" is back!

DL@Jeju is a one-month program to learn deep learning techniques and implement your ideas together with your mentors at a beautiful place, Jeju Island, Korea. DL@Jeju is sponsored by Google, Kakao, Netmarble and SK telecom.

Please first have a look how fun it was in the last year event.

[Photos - DL@Jeju in 2017] https://photos.google.com/share/AF1QipNjsUS8-WQBNYJRQ6k2taJCS1BT68XbQQDAqtgImNqUUpEKyzhvJVyQbdcpdoubqA?key=NDVHVlpaVWduTllrbXh2ZEN5Qkp4aUp4TkhkQVZB

DL@Jeju is not a summer school where the participants just take lectures, but a hackathon-like camp where the participants set their own goals and achieve them with a collaboration with other participants and mentors. After the camp, you will have an arXiv publication and codes on GitHub as the achievement of the research from the camp.

We are hosting from 20 to 30 participants in this year as (in the last year). All participants will be provided accommodations, 1000USD stipends and a part of the flight support (up to 300USD). We believe that you will have unforgettable summer days in Jeju with great friends and great achievements. The friendly city Jeju does not require Visa for most international visitors to stay up to 30 days. Thus, don't worry about it, but just apply it for your summer and your future.

[Application site] http://jeju.dlcamp.org/2018/

[Deadline] Apri 30, 2018.

[Camp] July 2-31 (30 days)

[Contact] info.jeju.dlcamp.org@gmail.com

Hope to see you soon at Jeju in July!


",23,134
605,2018-4-11,2018,4,11,9,8bczf2,[Free] Google machine learning crash course.,https://www.reddit.com/r/MachineLearning/comments/8bczf2/free_google_machine_learning_crash_course/,kabiir_,1523406773,,0,2
606,2018-4-11,2018,4,11,10,8bdfpt,[D] DL papers worth reproducing?,https://www.reddit.com/r/MachineLearning/comments/8bdfpt/d_dl_papers_worth_reproducing/,tarjanknuth,1523410918,"I'm a PhD in machine learning and graduated years ago - even before AlexNet was published. One of the main differences I've observed between deep learning approaches and traditional ML approaches is that DL algorithms require a lot of engineering efforts and practices.

I've been looking for some DL &amp; CV papers that are worth reproducing so I can get better at actually implementing my own ideas in the future. Some of the most obvious ones might include the AlexNet, VGG, ResNet papers, etc. Can someone suggest more papers that are worth implementing &amp; reproducing?

By ""worth"", I mean people have been trying to implement them and it won't be notoriously hard to reproduce the experimental results. Also by ""worth"", it would be better if implementing some of the papers would help you understand some of the new paradigms when building network blocks.",11,22
607,2018-4-11,2018,4,11,11,8bdju0,[N] meme-based AI coverage,https://www.reddit.com/r/MachineLearning/comments/8bdju0/n_memebased_ai_coverage/,evc123,1523412015,,1,0
608,2018-4-11,2018,4,11,11,8bdl8z,K-Means on Neural Network Layers,https://www.reddit.com/r/MachineLearning/comments/8bdl8z/kmeans_on_neural_network_layers/,[deleted],1523412386,,0,1
609,2018-4-11,2018,4,11,11,8bdnip,[D] K-means on Neural Network Layers (Text data),https://www.reddit.com/r/MachineLearning/comments/8bdnip/d_kmeans_on_neural_network_layers_text_data/,danielcanadia,1523412985,"Hi everyone,

I have a model that's trained to detect various concepts on biomedical papers. It's a pretty standard convolutional neural network. I'm using the last dense layer before the output to use as vector embeddings for these medical papers. I then use k-means on the embedding vectors to cluster the papers together. I prefer this over a pure unsupervised approach as these embeddings will be forced to focus on biological similarity over biological &amp; semantic.

I have about 10M papers and each cluster needs to have ~50 elements. Should I use spherical or euclidean distance for k-means? On a secondary note, anyone have good recommendations of ways to evaluate the accuracy of the clustering aspect? The size of the dense layer is 512.

For reference here's a paper I've taken from inspiration from: https://arxiv.org/pdf/1701.00185.pdf",4,2
610,2018-4-11,2018,4,11,11,8bdpbq,[D] My wish list for AI researchers,https://www.reddit.com/r/MachineLearning/comments/8bdpbq/d_my_wish_list_for_ai_researchers/,chisai_mikan,1523413470,,4,11
611,2018-4-11,2018,4,11,12,8bdxes,"[P] PyTorch-NLP: Lightweight deep learning toolkit with common neural network modules, word vector loaders, dataset loaders, iterators and text encoders.",https://www.reddit.com/r/MachineLearning/comments/8bdxes/p_pytorchnlp_lightweight_deep_learning_toolkit/,[deleted],1523415713,[deleted],0,1
612,2018-4-11,2018,4,11,12,8be7xo,New Explanatory Article on WGAN,https://www.reddit.com/r/MachineLearning/comments/8be7xo/new_explanatory_article_on_wgan/,alexander_liao,1523418768,[removed],0,1
613,2018-4-11,2018,4,11,13,8beapv,How to monitor and track your ML experiments from anywhere in 13 tweets,https://www.reddit.com/r/MachineLearning/comments/8beapv/how_to_monitor_and_track_your_ml_experiments_from/,[deleted],1523419625,[deleted],0,1
614,2018-4-11,2018,4,11,13,8becak,Questions about A.I + Hardware stuff,https://www.reddit.com/r/MachineLearning/comments/8becak/questions_about_ai_hardware_stuff/,[deleted],1523420122,,0,1
615,2018-4-11,2018,4,11,13,8becor,[P] How I monitor and track my machine learning experiments from anywhere (described in 13 tweets),https://www.reddit.com/r/MachineLearning/comments/8becor/p_how_i_monitor_and_track_my_machine_learning/,rlenny,1523420249,,1,2
616,2018-4-11,2018,4,11,13,8begox,[P] Vocalization sign language iOS App with deep learning using CoreML,https://www.reddit.com/r/MachineLearning/comments/8begox/p_vocalization_sign_language_ios_app_with_deep/,SupraluminalShift,1523421523,,0,3
617,2018-4-11,2018,4,11,14,8ben0a,Machine Learning Web application architecture,https://www.reddit.com/r/MachineLearning/comments/8ben0a/machine_learning_web_application_architecture/,mohanradhakrishnan,1523423579,[removed],0,1
618,2018-4-11,2018,4,11,14,8beohl,[P] Deep reinforcement Learning course: Q-learning article and DQN with Doom notebook are published,https://www.reddit.com/r/MachineLearning/comments/8beohl/p_deep_reinforcement_learning_course_qlearning/,cranthir_,1523424102,"Hello, I'm currently writing a series of free articles about Deep Reinforcement Learning, where we'll learn the main algorithms (from Q* learning to PPO), and how to implement them in Tensorflow.

The second article is published, it's about Q-learning and we'll learn to **implement a Q-learning algorithm with Numpy and OpenAI Gym.**

**Q-learning article**: https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe

Moreover, the third article (Deep Q Learning with Doom) will be published **this week**, but the implementation of a Doom playing agent with Tensorflow **is already published.**

**Doom Deep Q agent**: https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/DQN%20Doom/Deep%20Q%20learning%20with%20Doom.ipynb

Let me know what you think! What architectures you want and any feedback.

**The Syllabus**: https://simoninithomas.github.io/Deep_reinforcement_learning_Course/

**Introduction to Reinforcement Learning**: https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419

Thanks!
",16,107
619,2018-4-11,2018,4,11,14,8betxe,"[P] Pytorch Implementation of ""Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization""",https://www.reddit.com/r/MachineLearning/comments/8betxe/p_pytorch_implementation_of_gradcam_visual/,meliketoy,1523426001,,0,7
620,2018-4-11,2018,4,11,14,8beu60,"""Artificial Intelligence: A Modern Approach"" alternatives",https://www.reddit.com/r/MachineLearning/comments/8beu60/artificial_intelligence_a_modern_approach/,ml_nrd,1523426074,[removed],0,1
621,2018-4-11,2018,4,11,15,8bf2ai,BigML vs. Algorithmia,https://www.reddit.com/r/MachineLearning/comments/8bf2ai/bigml_vs_algorithmia/,greatlakes7,1523429041,[removed],0,1
622,2018-4-11,2018,4,11,16,8bf5o8,"Can someone suggest a Optical Character Recognition Neural network, working python implemented code?",https://www.reddit.com/r/MachineLearning/comments/8bf5o8/can_someone_suggest_a_optical_character/,Uvindu_Perera,1523430321,[removed],0,1
623,2018-4-11,2018,4,11,16,8bf7bo,[D] Simple intro to Markov Decision Process via Game of Thorns,https://www.reddit.com/r/MachineLearning/comments/8bf7bo/d_simple_intro_to_markov_decision_process_via/,jaleyhd,1523430936,,7,27
624,2018-4-11,2018,4,11,16,8bf96x,where to find pre trained models for transfer learning of question answering ai?,https://www.reddit.com/r/MachineLearning/comments/8bf96x/where_to_find_pre_trained_models_for_transfer/,sabi0,1523431654,[removed],0,1
625,2018-4-11,2018,4,11,17,8bffbu,What you need to know about machine learning,https://www.reddit.com/r/MachineLearning/comments/8bffbu/what_you_need_to_know_about_machine_learning/,owen_jr,1523434149,,0,1
626,2018-4-11,2018,4,11,17,8bfgfg,What You Must Know Before You Dive Into Machine Learning Training,https://www.reddit.com/r/MachineLearning/comments/8bfgfg/what_you_must_know_before_you_dive_into_machine/,Anusha55,1523434647,,2,1
627,2018-4-11,2018,4,11,17,8bfgid,Build Your Mobile App on XAMARIN with C#. @Affluent is the 1st Partner to be signed as XAMARIN Center of Excellence @Hyderabad &amp; 8th in India.,https://www.reddit.com/r/MachineLearning/comments/8bfgid/build_your_mobile_app_on_xamarin_with_c_affluent/,AffluentGlobal,1523434672,,0,1
628,2018-4-11,2018,4,11,17,8bfhsl,"Opinions about predicting particle matters(weather) using gases/weather and weather forecasts ,with deep learning",https://www.reddit.com/r/MachineLearning/comments/8bfhsl/opinions_about_predicting_particle_mattersweather/,giorgaros2,1523435161,[removed],0,1
629,2018-4-11,2018,4,11,17,8bflph,isuzu worldwide parts manual,https://www.reddit.com/r/MachineLearning/comments/8bflph/isuzu_worldwide_parts_manual/,Mypremiummanual,1523436764,,0,1
630,2018-4-11,2018,4,11,17,8bfm7t,Use sewing machines and make your designs build with your own,https://www.reddit.com/r/MachineLearning/comments/8bfm7t/use_sewing_machines_and_make_your_designs_build/,psmccouk,1523436984,,0,1
631,2018-4-11,2018,4,11,18,8bfqwc,When you're testing your expression modifier neural net,https://www.reddit.com/r/MachineLearning/comments/8bfqwc/when_youre_testing_your_expression_modifier/,iwakan,1523438800,,0,1
632,2018-4-11,2018,4,11,19,8bfzx3,[D] MobileNetv1 convergence speed,https://www.reddit.com/r/MachineLearning/comments/8bfzx3/d_mobilenetv1_convergence_speed/,monte_carlo_method,1523442157,"I've been experimenting with training SSD-like object detection models using MobileNet(v1, 0.5). The average drop in loss per epoch (SGD) is substantially lower than other types of networks that I've worked with (over different datasets). Guess this is expected given the increased dependence across weights, or am I missing something? Anyone seeing the same behavior? 
",0,1
633,2018-4-11,2018,4,11,19,8bg1hr,"Machine Learning, NLP and Python course for Beginner",https://www.reddit.com/r/MachineLearning/comments/8bg1hr/machine_learning_nlp_and_python_course_for/,simplivllc,1523442718,,1,1
634,2018-4-11,2018,4,11,19,8bg4b9,Technical analysis library to financial datasets with pandas (python),https://www.reddit.com/r/MachineLearning/comments/8bg4b9/technical_analysis_library_to_financial_datasets/,bukosabino,1523443739,,0,1
635,2018-4-11,2018,4,11,19,8bg5n2,ICML paper acceptance threshold,https://www.reddit.com/r/MachineLearning/comments/8bg5n2/icml_paper_acceptance_threshold/,Pieranha,1523444180,[removed],0,1
636,2018-4-11,2018,4,11,20,8bggmu,Peanut Butter Filling Machine Suppleirs,https://www.reddit.com/r/MachineLearning/comments/8bggmu/peanut_butter_filling_machine_suppleirs/,lgsherry,1523447599,,1,1
637,2018-4-11,2018,4,11,21,8bgif5,ICML reviews are out!,https://www.reddit.com/r/MachineLearning/comments/8bgif5/icml_reviews_are_out/,blindedbox,1523448123,[removed],0,1
638,2018-4-11,2018,4,11,21,8bgjlq,Point Convolutional Neural Networks by Extension Operators,https://www.reddit.com/r/MachineLearning/comments/8bgjlq/point_convolutional_neural_networks_by_extension/,ferlesh,1523448473,,0,1
639,2018-4-11,2018,4,11,21,8bgk2l,[R] Generative Adversarial Networks for Extreme Learned Image Compression,https://www.reddit.com/r/MachineLearning/comments/8bgk2l/r_generative_adversarial_networks_for_extreme/,SomeoneInTheComments,1523448601,,37,161
640,2018-4-11,2018,4,11,21,8bgoa6,[R] Machine Learning Top 10 Articles for the Past Month (v.Apr 2018),https://www.reddit.com/r/MachineLearning/comments/8bgoa6/r_machine_learning_top_10_articles_for_the_past/,[deleted],1523449818,[deleted],0,1
641,2018-4-11,2018,4,11,21,8bgp32,[R] Machine Learning Top 10 Articles for the Past Month (v.Apr 2018),https://www.reddit.com/r/MachineLearning/comments/8bgp32/r_machine_learning_top_10_articles_for_the_past/,[deleted],1523450004,[deleted],0,1
642,2018-4-11,2018,4,11,21,8bgq34,[R] Machine Learning Top 10 Articles for the Past Month (v.Apr 2018),https://www.reddit.com/r/MachineLearning/comments/8bgq34/r_machine_learning_top_10_articles_for_the_past/,PaulgibPaul,1523450269,,0,1
643,2018-4-11,2018,4,11,21,8bgsv2,[R] Machine Learning Top 10 Articles for the Past Month (v.Apr 2018),https://www.reddit.com/r/MachineLearning/comments/8bgsv2/r_machine_learning_top_10_articles_for_the_past/,redditandjs,1523451046,,0,6
644,2018-4-11,2018,4,11,22,8bgw1z,An Introduction to Neural Networks and Autoencoders,https://www.reddit.com/r/MachineLearning/comments/8bgw1z/an_introduction_to_neural_networks_and/,[deleted],1523451853,[deleted],1,1
645,2018-4-11,2018,4,11,22,8bgx8t,Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition,https://www.reddit.com/r/MachineLearning/comments/8bgx8t/speech_commands_a_dataset_for_limitedvocabulary/,cavedave,1523452143,,5,28
646,2018-4-11,2018,4,11,22,8bgzqf,[D] An Introduction to Neural Networks and Autoencoders,https://www.reddit.com/r/MachineLearning/comments/8bgzqf/d_an_introduction_to_neural_networks_and/,AlanZucconi,1523452785,,7,15
647,2018-4-11,2018,4,11,22,8bh5qq,What is a Deconvolution or Convolution transposed?,https://www.reddit.com/r/MachineLearning/comments/8bh5qq/what_is_a_deconvolution_or_convolution_transposed/,ianholing,1523454264,[removed],0,1
648,2018-4-11,2018,4,11,23,8bheov,Anyone tried making the next learning rate an output of the nn?,https://www.reddit.com/r/MachineLearning/comments/8bheov/anyone_tried_making_the_next_learning_rate_an/,rhys5584,1523456338,[removed],0,1
649,2018-4-11,2018,4,11,23,8bhff4,[P] Best way to approach eye-tracking data? (60Hz),https://www.reddit.com/r/MachineLearning/comments/8bhff4/p_best_way_to_approach_eyetracking_data_60hz/,surf_book,1523456521,"So I have eye-tracking output from a sensor which gives {time, x, y} relative to a computer screen which displays the experiment. I've collected data, for a control setup and a test setup. 
The tasks are designed to be visually similar but force different eye-movement patterns by varying the various other non-visual factors.
I have around 5 minutes of data for each class, from the same participant.
I'm trying to produce a binary classifier which can predict which class a data sequence belongs to (thereby estimating the non-visual factors which were varied in the experiment). I've begun by using simple velocity threshold algorithms to identify saccades and fixations in the eye data, but am lost on how to take this further into a classification algorithm/setup. I would assume some kind of windowing system if I'm pre-processing the input data to identify saccades/fixations. 
I'm somewhat familiar with ML theory - would appreciate help with this real-world data problem. Anyone with experience on eye-tracking data? Or time-series positional data? Thank you!",8,3
650,2018-4-11,2018,4,11,23,8bhfvz,[P] How I monitor and track my machine learning experiments,https://www.reddit.com/r/MachineLearning/comments/8bhfvz/p_how_i_monitor_and_track_my_machine_learning/,[deleted],1523456601,[deleted],0,1
651,2018-4-11,2018,4,11,23,8bhh6h,AI bot that plays billiard,https://www.reddit.com/r/MachineLearning/comments/8bhh6h/ai_bot_that_plays_billiard/,Henshmi,1523456896,[removed],0,1
652,2018-4-11,2018,4,11,23,8bhhkf,A recurrent neural net NOT learing pattern matching BUT learning state-action-pairs,https://www.reddit.com/r/MachineLearning/comments/8bhhkf/a_recurrent_neural_net_not_learing_pattern/,LowestenGangsten,1523456984,,0,1
653,2018-4-11,2018,4,11,23,8bhm4b,[R] On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses,https://www.reddit.com/r/MachineLearning/comments/8bhm4b/r_on_the_robustness_of_the_cvpr_2018_whitebox/,anishathalye,1523457959,,8,2
654,2018-4-11,2018,4,11,23,8bhn11,[N]Symbolic Neural Networks &amp; Automated Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8bhn11/nsymbolic_neural_networks_automated_machine/,MountainHawk81,1523458152,,0,3
655,2018-4-11,2018,4,11,23,8bhnhp,AI Grant 3.0: Applications close in 3 days!,https://www.reddit.com/r/MachineLearning/comments/8bhnhp/ai_grant_30_applications_close_in_3_days/,yfletberliac,1523458251,,0,1
656,2018-4-11,2018,4,11,23,8bho3r,"[P] ArXiv Papers: open source app to search, download and save scientific papers",https://www.reddit.com/r/MachineLearning/comments/8bho3r/p_arxiv_papers_open_source_app_to_search_download/,lopespm,1523458382,,9,6
657,2018-4-11,2018,4,11,23,8bho4f,ICML rebuttal period has started,https://www.reddit.com/r/MachineLearning/comments/8bho4f/icml_rebuttal_period_has_started/,tallhobbit787,1523458385,[removed],0,1
658,2018-4-11,2018,4,11,23,8bhorg,Faster RCNN RPN vs YOLO9000,https://www.reddit.com/r/MachineLearning/comments/8bhorg/faster_rcnn_rpn_vs_yolo9000/,[deleted],1523458560,,0,1
659,2018-4-11,2018,4,11,23,8bhoyd,[D] Faster RCNN's RPN vs YOLO9000,https://www.reddit.com/r/MachineLearning/comments/8bhoyd/d_faster_rcnns_rpn_vs_yolo9000/,ShivamDuggal4,1523458603,"How is YOLO different from faster-RCNN's region proposal network? Both RPN and YOLO output a convolution feature map of size wh(4+2)*k, where k is the number of anchor boxes or proposals per location of the grid. And why is RPN not used to directly output all the class probabilities? In faster CNN, it is made to perform background vs object prediction.",3,1
660,2018-4-12,2018,4,12,0,8bhsg7,Why data scientists and machine learning engineers should start learning Swift.,https://www.reddit.com/r/MachineLearning/comments/8bhsg7/why_data_scientists_and_machine_learning/,[deleted],1523459389,[deleted],0,1
661,2018-4-12,2018,4,12,0,8bhuk6,[D] Why machine learning engineers should start learning Swift,https://www.reddit.com/r/MachineLearning/comments/8bhuk6/d_why_machine_learning_engineers_should_start/,jamesonatfritz,1523459795,,1,0
662,2018-4-12,2018,4,12,0,8bhyqm,Complete Data Science Training with Python for Data Analysis,https://www.reddit.com/r/MachineLearning/comments/8bhyqm/complete_data_science_training_with_python_for/,[deleted],1523460695,[deleted],0,1
663,2018-4-12,2018,4,12,0,8bi15a,Text Summarization using supervised learning,https://www.reddit.com/r/MachineLearning/comments/8bi15a/text_summarization_using_supervised_learning/,wma22by7,1523461209,[removed],0,1
664,2018-4-12,2018,4,12,0,8bi1ju,[N] Complete Data Science Training with Python for Data Analysis,https://www.reddit.com/r/MachineLearning/comments/8bi1ju/n_complete_data_science_training_with_python_for/,alibabaochollish,1523461293,,1,2
665,2018-4-12,2018,4,12,0,8bi5ji,"Simple Questions Thread April 11, 2018",https://www.reddit.com/r/MachineLearning/comments/8bi5ji/simple_questions_thread_april_11_2018/,AutoModerator,1523462143,[removed],0,1
666,2018-4-12,2018,4,12,1,8biaqn,Jupyter Notebook Kernel Error,https://www.reddit.com/r/MachineLearning/comments/8biaqn/jupyter_notebook_kernel_error/,paulmattheww,1523463206,[removed],0,1
667,2018-4-12,2018,4,12,1,8bieha,Favorite intro books for data science ?,https://www.reddit.com/r/MachineLearning/comments/8bieha/favorite_intro_books_for_data_science/,cheechuu,1523464019,[removed],0,1
668,2018-4-12,2018,4,12,1,8bifmv,How Big Pharma Is Using AI to Make Better Drugs,https://www.reddit.com/r/MachineLearning/comments/8bifmv/how_big_pharma_is_using_ai_to_make_better_drugs/,jonfla,1523464252,,0,1
669,2018-4-12,2018,4,12,1,8bigkh,[Research] Point Convolutional Neural Networks by Extension Operators,https://www.reddit.com/r/MachineLearning/comments/8bigkh/research_point_convolutional_neural_networks_by/,ferlesh,1523464451,,0,1
670,2018-4-12,2018,4,12,1,8biirs,"Deep Learning is far from being enough to build an Intelligent Machine. You must think also Deep Modern Physics, Deep Neuroscience, Deep Evolvement, and Deep Bio Neural Networks, among others",https://www.reddit.com/r/MachineLearning/comments/8biirs/deep_learning_is_far_from_being_enough_to_build/,Pearlnv,1523464951,,0,1
671,2018-4-12,2018,4,12,1,8bikt3,[P] In-Browser Tiny YOLO Object Detection using Tensorflow.js,https://www.reddit.com/r/MachineLearning/comments/8bikt3/p_inbrowser_tiny_yolo_object_detection_using/,es6masterrace,1523465337,,17,46
672,2018-4-12,2018,4,12,1,8bikvg,How I track and monitor my experiments anywhere,https://www.reddit.com/r/MachineLearning/comments/8bikvg/how_i_track_and_monitor_my_experiments_anywhere/,Loggerny,1523465355,,0,1
673,2018-4-12,2018,4,12,1,8binru,[D] ICML reviews are out,https://www.reddit.com/r/MachineLearning/comments/8binru/d_icml_reviews_are_out/,blindedbox,1523465960,"ICML reviews are out! Good luck, everyone!",74,34
674,2018-4-12,2018,4,12,2,8biope,[D] Introduction to Unsupervised Learning,https://www.reddit.com/r/MachineLearning/comments/8biope/d_introduction_to_unsupervised_learning/,mikeyanderson,1523466161,,0,0
675,2018-4-12,2018,4,12,3,8bj9dl,Image (of some graph) to Graph (Adjacency Matrix),https://www.reddit.com/r/MachineLearning/comments/8bj9dl/image_of_some_graph_to_graph_adjacency_matrix/,mackie__m,1523470451,[removed],0,1
676,2018-4-12,2018,4,12,3,8bjdq2,presentation help on machine learning and natural language processing,https://www.reddit.com/r/MachineLearning/comments/8bjdq2/presentation_help_on_machine_learning_and_natural/,imnot1234,1523471329,[removed],0,1
677,2018-4-12,2018,4,12,3,8bjk62,[N]Clustering &amp; Classification With Machine Learning in Python,https://www.reddit.com/r/MachineLearning/comments/8bjk62/nclustering_classification_with_machine_learning/,alibabaochollish,1523472645,,0,0
678,2018-4-12,2018,4,12,4,8bjofs,[R] Looking to Listen: Audio-Visual Speech Separation,https://www.reddit.com/r/MachineLearning/comments/8bjofs/r_looking_to_listen_audiovisual_speech_separation/,alxndrkalinin,1523473601,,1,16
679,2018-4-12,2018,4,12,4,8bjtvo,How do you structure your ML Projects in Production ?,https://www.reddit.com/r/MachineLearning/comments/8bjtvo/how_do_you_structure_your_ml_projects_in/,[deleted],1523474734,,0,1
680,2018-4-12,2018,4,12,4,8bjuzk,"Checkpointing And Saving Models in TensorFlow, Keras, And Pytorch (becasue these models are getting huge these days amirite)",https://www.reddit.com/r/MachineLearning/comments/8bjuzk/checkpointing_and_saving_models_in_tensorflow/,gagejustins,1523474959,,0,1
681,2018-4-12,2018,4,12,4,8bjvtc,[D] DeepMimic's Video,https://www.reddit.com/r/MachineLearning/comments/8bjvtc/d_deepmimics_video/,tshrjn,1523475140,,31,217
682,2018-4-12,2018,4,12,4,8bjwqd,How We're Using Natural Language Generation to Scale at Forge.AI,https://www.reddit.com/r/MachineLearning/comments/8bjwqd/how_were_using_natural_language_generation_to/,jenniferlum,1523475342,,0,1
683,2018-4-12,2018,4,12,4,8bjxku,[D] How do you structure your #MachineLearning Projects in Production ?,https://www.reddit.com/r/MachineLearning/comments/8bjxku/d_how_do_you_structure_your_machinelearning/,__Julia,1523475521,"Hi,
I didn't find a standard cookiecutter for TensorFlow/PyTorch/Keras project. I was wondering whether [cookiecutter-data-science](https://drivendata.github.io/cookiecutter-data-science/) is the structure to go when we work on datascience. Can you share some of your in-house best practices when you structure ML code in production ? How you design solutions respecting OOP design ?",2,1
684,2018-4-12,2018,4,12,4,8bk1cz,Advanced Topics in Statistical Machine Learning course (Oxford),https://www.reddit.com/r/MachineLearning/comments/8bk1cz/advanced_topics_in_statistical_machine_learning/,Dannygem,1523476303,,2,4
685,2018-4-12,2018,4,12,5,8bk4yy,Interesting read on how companies use machine learning,https://www.reddit.com/r/MachineLearning/comments/8bk4yy/interesting_read_on_how_companies_use_machine/,lmaisour,1523477072,,0,1
686,2018-4-12,2018,4,12,5,8bk6ap,Outputs From My Neural Conversational Model,https://www.reddit.com/r/MachineLearning/comments/8bk6ap/outputs_from_my_neural_conversational_model/,nuttyartist,1523477338,[removed],0,1
687,2018-4-12,2018,4,12,5,8bkfg2,understanding LSTM &amp; gradient descent,https://www.reddit.com/r/MachineLearning/comments/8bkfg2/understanding_lstm_gradient_descent/,[deleted],1523479395,,0,1
688,2018-4-12,2018,4,12,5,8bkhv6,[N] 2018 Causal Inference Data Challenge,https://www.reddit.com/r/MachineLearning/comments/8bkhv6/n_2018_causal_inference_data_challenge/,urish,1523479916,,0,7
689,2018-4-12,2018,4,12,5,8bkiyq,[D] understanding nonlinearities in LSTM &amp; backpropagation,https://www.reddit.com/r/MachineLearning/comments/8bkiyq/d_understanding_nonlinearities_in_lstm/,elliotmcnaught,1523480138,"Math is not my strong point so I would appreciate some advice around my question from a mathematical perspective.

Let's say you create a simple Parts of speech tagger.

It has randomly initialized word vectors with 100 dimensions. It has an LSTM layer that has 500 dimensions, and is randomly initialized. It has a softmax cross-entropy output layer.

The LSTM layers presumably have a number of pairwise ""and"" functions, such that it might find some association when dimension 5 and dimension 7 are both high simultaneously.

So let's say you train this model and you measure the performance of your model.

Now, let's take the input word vectors from our trained model, and export them. Lets randomly initialize a new network, but instead this time, we will import the vectors from the previously trained model of the word embedding layer, and not only that, we will make them immutable so that the backpropagation error is not allowed to alter these values.

Now, from a mathematical perspective, I would like to understand:

Should gradient descent find a similar solution, and result in a similarly performing model as to the first model we ran?

If not, is there some sort of symbiotic relationship between the original random LSTM network values and the original word vectors that are lost, if you throw just one of them away, and that gradient descent will not likely be able to uncover those non-linear associations in the LSTM that are encoded in the embeddings that were initially created?  (and thus result in poorer performance for model #2)",2,0
690,2018-4-12,2018,4,12,6,8bkmds,From Industrial Revolution to AI Revolution,https://www.reddit.com/r/MachineLearning/comments/8bkmds/from_industrial_revolution_to_ai_revolution/,aqavi,1523480869,[removed],0,1
691,2018-4-12,2018,4,12,6,8bkp89,"[P] PyTorch-NLP: Lightweight deep learning toolkit with common neural network modules, word vector loaders, dataset loaders, iterators and text encoders.",https://www.reddit.com/r/MachineLearning/comments/8bkp89/p_pytorchnlp_lightweight_deep_learning_toolkit/,Deepblue129,1523481465,,6,12
692,2018-4-12,2018,4,12,6,8bkrxh,[R] Deep Reinforcement Learning for Join Order Enumeration,https://www.reddit.com/r/MachineLearning/comments/8bkrxh/r_deep_reinforcement_learning_for_join_order/,Rynsin,1523482047,,0,7
693,2018-4-12,2018,4,12,6,8bksfg,[P] CNN Genre Classification with Spectrograms,https://www.reddit.com/r/MachineLearning/comments/8bksfg/p_cnn_genre_classification_with_spectrograms/,francarranza,1523482157,"Hi! I'm stuck with this multi-label classification task. I'm getting very low accuracy (~40%). 

First of all the data:

* 11000 songs audio songs with 10 balanced genres.
* [Genre Labels](http://www.tagtraum.com/msd_genre_datasets.html)
* The songs are from The Million Song Dataset

I am building **spectrograms** for each song. 128 mel components and 128 time frames.

    S = librosa.feature.melspectrogram(signal, sampling_rate=22050, n_fft=1024, n_mels=128,
    hop_length=512, fmin=27.5, fmax=11000)
--
    S_db = librosa.logamplitude(S)

--
**Then I feed all the data to a CNN.**
You can view the architecture and the run [here] (https://ibb.co/jf6YcH)

&gt;Using Adam optimizer

--

**I am getting these metrics:**

&gt; Validation
Loss: 1.71 | Accuracy: 0.39

&gt;Testing
Loss: 1.72 | Accuracy: 0.41

&gt;mAP = 0.35

&gt;AUC = 0.81 

I don't know what's going on. I've seen amazing results on GTZAN dataset using a similar process.
Thanks in advance...",6,11
694,2018-4-12,2018,4,12,6,8bktvl,Using Topological Data Analysis to Reveal the Dynamical Organization of the Brain,https://www.reddit.com/r/MachineLearning/comments/8bktvl/using_topological_data_analysis_to_reveal_the/,jtsymonds,1523482464,,0,1
695,2018-4-12,2018,4,12,7,8blf3p,Essential papers to read for conducting research?,https://www.reddit.com/r/MachineLearning/comments/8blf3p/essential_papers_to_read_for_conducting_research/,jfishersolutions,1523487334,[removed],0,1
696,2018-4-12,2018,4,12,9,8bm55p,Any studies on a fully-automated business?,https://www.reddit.com/r/MachineLearning/comments/8bm55p/any_studies_on_a_fullyautomated_business/,gp334,1523493735,[removed],0,1
697,2018-4-12,2018,4,12,9,8bm6mu,This is what I believe what the difference between CrowdFlower and MTurk is.,https://www.reddit.com/r/MachineLearning/comments/8bm6mu/this_is_what_i_believe_what_the_difference/,buflowsean,1523494104,[removed],0,1
698,2018-4-12,2018,4,12,9,8bm6zn,Y axis for PPO Learning Graphs (Reinforcement Learning),https://www.reddit.com/r/MachineLearning/comments/8bm6zn/y_axis_for_ppo_learning_graphs_reinforcement/,ashboy64,1523494193,[removed],0,1
699,2018-4-12,2018,4,12,10,8bmeh2,"[D] DeepVariant - Can a ""Google AI"" Build Your Genome Sequence?",https://www.reddit.com/r/MachineLearning/comments/8bmeh2/d_deepvariant_can_a_google_ai_build_your_genome/,regalalgorithm,1523496137,,0,0
700,2018-4-12,2018,4,12,11,8bmx03,Just testing some code,https://www.reddit.com/r/MachineLearning/comments/8bmx03/just_testing_some_code/,poobearcretu,1523500962,,0,1
701,2018-4-12,2018,4,12,12,8bn1bp,Probabilistic reasoning and statistical analysis in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8bn1bp/probabilistic_reasoning_and_statistical_analysis/,[deleted],1523502080,[deleted],0,1
702,2018-4-12,2018,4,12,12,8bn3i7,[N] Tensorflow Probability - probabilistic reasoning and statistical analysis in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8bn3i7/n_tensorflow_probability_probabilistic_reasoning/,matwilso_,1523502682,,4,92
703,2018-4-12,2018,4,12,12,8bn6j5,Deep learning to solve a problem,https://www.reddit.com/r/MachineLearning/comments/8bn6j5/deep_learning_to_solve_a_problem/,Cocada_de_Sal,1523503525,[removed],0,1
704,2018-4-12,2018,4,12,12,8bn7t4,Help with Tic Tac Toe - MENACE Program,https://www.reddit.com/r/MachineLearning/comments/8bn7t4/help_with_tic_tac_toe_menace_program/,Not-The-Government-,1523503898,[removed],0,1
705,2018-4-12,2018,4,12,12,8bncd5,[N] Berkeley Researchers Create Virtual Acrobat,https://www.reddit.com/r/MachineLearning/comments/8bncd5/n_berkeley_researchers_create_virtual_acrobat/,trcytony,1523505241,,0,1
706,2018-4-12,2018,4,12,13,8bnkod,Can I get advice on how to strengthen my fundamentals?,https://www.reddit.com/r/MachineLearning/comments/8bnkod/can_i_get_advice_on_how_to_strengthen_my/,snorermadlysnored,1523507861,[removed],0,1
707,2018-4-12,2018,4,12,13,8bnld4,Writing your first ML paper,https://www.reddit.com/r/MachineLearning/comments/8bnld4/writing_your_first_ml_paper/,goabiaryan,1523508085,[removed],0,1
708,2018-4-12,2018,4,12,14,8bnqcm,Machine Learning Checklist and Datasets,https://www.reddit.com/r/MachineLearning/comments/8bnqcm/machine_learning_checklist_and_datasets/,yuraist,1523509705,,0,1
709,2018-4-12,2018,4,12,14,8bnts0,"[D]What makes ""Meta-SGD: Learning to Learn Quickly for Few-Shot Learning"" to work so good?",https://www.reddit.com/r/MachineLearning/comments/8bnts0/dwhat_makes_metasgd_learning_to_learn_quickly_for/,shamitlal,1523510864,"In Meta-SGD paper (https://arxiv.org/pdf/1707.09835.pdf), authors propose an optimization-based approach to tackle one-shot learning. They proposed a modified stochastic gradient descent where they learned initialization, learning rate, and gradient direction as well. What I didn't understand is how this approach works so good for one shot learning with just one step of parameter updates whereas standard SGD fails miserably in such environment? How is their model, when trained, able to classify samples from new task after just one step parameter update on the support set?",4,20
710,2018-4-12,2018,4,12,16,8bo9kr,"[P] Simple Tensorflow Implementation of ""Spectral Normalization for Generative Adversarial Networks"" (ICLR 2018)",https://www.reddit.com/r/MachineLearning/comments/8bo9kr/p_simple_tensorflow_implementation_of_spectral/,taki0112,1523516655,,0,9
711,2018-4-12,2018,4,12,16,8bofoy,Match Objects from different embedding spaces,https://www.reddit.com/r/MachineLearning/comments/8bofoy/match_objects_from_different_embedding_spaces/,Don_Mahoni,1523518977,[removed],0,1
712,2018-4-12,2018,4,12,16,8boh46,[D]Clustering &amp; Classification With Machine Learning in Python,https://www.reddit.com/r/MachineLearning/comments/8boh46/dclustering_classification_with_machine_learning/,alibabaochollish,1523519543,,0,0
713,2018-4-12,2018,4,12,17,8boqu1,ML Javascript library with new GPU fast method using an Adjacency Matrix. All layers processed without out to CPU!!,https://www.reddit.com/r/MachineLearning/comments/8boqu1/ml_javascript_library_with_new_gpu_fast_method/,3droberto,1523523538,,0,1
714,2018-4-12,2018,4,12,18,8bos68,[D] How to calculate mAP for object detection and localization networks like YOLO using bounding boxes?,https://www.reddit.com/r/MachineLearning/comments/8bos68/d_how_to_calculate_map_for_object_detection_and/,SpecialistProblem,1523524065,"I have searched online for a method to calculate mAP for localization and detection. COCO dataset evaluation page(http://cocodataset.org/#detections-eval) itself shows 4 different types of calculation. I am a bit confused, as to what to chose as a measure.What method do people in academia in general use for quoting in their papers like YOLO?  I have understood that we have to calculate the area under the Precison/Recall curve for each class and then take an average over all the classes. But I don't understand how those Precison/Recall curve should be generated. And also when they mention that Precison vs Recall values should be noted for different thresholds, are these thresholds the object detection or NMS threshold we set in the network or the confidence threshold we use to find if a prediction is a True Positive? I have also seen some of the papers mentioning different mAPs at different FPS of the network. How does mAP change with the FPS achieved by the network? 

I am publishing a paper and am pretty confused with the way to evaluate my network. Any help in this regard would be really appreciated.   ",8,20
715,2018-4-12,2018,4,12,18,8bose0,[D] Negative Attention Weights,https://www.reddit.com/r/MachineLearning/comments/8bose0/d_negative_attention_weights/,spidey-fan,1523524149,Most attention mechanisms involve a softmax or normalization to make all the different attentions scores to sum up to 1. Is there any work that does not do this? Where some of the attention scores are negative?,5,8
716,2018-4-12,2018,4,12,18,8boxlt,5 ways Data Science and Machine Learning impact business - CIOL,https://www.reddit.com/r/MachineLearning/comments/8boxlt/5_ways_data_science_and_machine_learning_impact/,oliviabishop27,1523526279,,0,1
717,2018-4-12,2018,4,12,18,8boxxk,[D] Explain Reinforcement Learning in one sentence,https://www.reddit.com/r/MachineLearning/comments/8boxxk/d_explain_reinforcement_learning_in_one_sentence/,onkelFungus,1523526405,,18,0
718,2018-4-12,2018,4,12,18,8boztm,Found a no-frills ML paper summary channel with FANTASTIC explanations.,https://www.reddit.com/r/MachineLearning/comments/8boztm/found_a_nofrills_ml_paper_summary_channel_with/,BatmantoshReturns,1523527136,,0,1
719,2018-4-12,2018,4,12,19,8bp3c9,[R] We Have Just Released the Largest First Person Video Dataset: EPIC-Kitchens.,https://www.reddit.com/r/MachineLearning/comments/8bp3c9/r_we_have_just_released_the_largest_first_person/,mwray,1523528451,,22,303
720,2018-4-12,2018,4,12,19,8bp8x3,Background removal with deep learning,https://www.reddit.com/r/MachineLearning/comments/8bp8x3/background_removal_with_deep_learning/,nanonets,1523530487,,0,1
721,2018-4-12,2018,4,12,20,8bpfcp,Tomato Paste Packing Machine,https://www.reddit.com/r/MachineLearning/comments/8bpfcp/tomato_paste_packing_machine/,lgsherry,1523532617,,1,1
722,2018-4-12,2018,4,12,20,8bphf7,[N]Online Course: Clustering &amp; Classification With Machine Learning in Python,https://www.reddit.com/r/MachineLearning/comments/8bphf7/nonline_course_clustering_classification_with/,alibabaochollish,1523533267,,0,0
723,2018-4-12,2018,4,12,20,8bpjek,Is there a poorman's version of DeepMind Lab ?,https://www.reddit.com/r/MachineLearning/comments/8bpjek/is_there_a_poormans_version_of_deepmind_lab/,gohu_cd,1523533846,[removed],0,1
724,2018-4-12,2018,4,12,20,8bpjgk,[P] Building Floor Plan Detection,https://www.reddit.com/r/MachineLearning/comments/8bpjgk/p_building_floor_plan_detection/,yamlajatt007,1523533864,"Hello All,

I'm planning to work on detection of building floor plans using neural networks are part of my master thesis.

There has already been significant amount of research in this field, but mostly are done for residential houses and not for commercial/office spaces.

As a result I feel there is gap, where in much research is not done for floor plan detection for office spaces specifically when there is complex structures, specifically narrowing down to curved walls and open spaces. 

My idea is to load image get its vector representation and pass this vector representation to a modelling algorithm to get a digitised model of the paper based floor plan. With this end customer need not have any knowledge of designing softare.


I was not able to find much solutions/research concerned to detection of curved lines.
Any inputs will be of high value.

Thanks",2,1
725,2018-4-12,2018,4,12,21,8bpnrv,[R] Will GDPR Make Machine Learning Illegal?,https://www.reddit.com/r/MachineLearning/comments/8bpnrv/r_will_gdpr_make_machine_learning_illegal/,digitalson,1523535125,,0,1
726,2018-4-12,2018,4,12,21,8bps05,"Speed up your Python with C: a guide to Ctypes, Cython and CFFI",https://www.reddit.com/r/MachineLearning/comments/8bps05/speed_up_your_python_with_c_a_guide_to_ctypes/,recastai,1523536349,[removed],0,1
727,2018-4-12,2018,4,12,21,8bpsoe,Effects of Democratisation and Decentralisation on AI/ML Ecosystem,https://www.reddit.com/r/MachineLearning/comments/8bpsoe/effects_of_democratisation_and_decentralisation/,ravensdraven,1523536545,,0,1
728,2018-4-12,2018,4,12,22,8bpysb,Continuous Integration for Machine Learning - bridging engineering and ML,https://www.reddit.com/r/MachineLearning/comments/8bpysb/continuous_integration_for_machine_learning/,[deleted],1523538152,[deleted],0,1
729,2018-4-12,2018,4,12,22,8bpz45,"Deep Learning is not enough to build an Intelligent Machine. You must think also Deep Modern Physics, Deep Neuroscience, Deep Evolvement, and Deep Bio Neural Networks, among others.",https://www.reddit.com/r/MachineLearning/comments/8bpz45/deep_learning_is_not_enough_to_build_an/,[deleted],1523538214,[deleted],0,1
730,2018-4-12,2018,4,12,22,8bpzew,Machine learning as a Service Provider and Consulting Services from ISHIR,https://www.reddit.com/r/MachineLearning/comments/8bpzew/machine_learning_as_a_service_provider_and/,Gloria_Joyce,1523538297,,0,1
731,2018-4-12,2018,4,12,22,8bq2ae,"[N] Weekly Machine Learning Opensource Roundup  Apr. 12, 2018",https://www.reddit.com/r/MachineLearning/comments/8bq2ae/n_weekly_machine_learning_opensource_roundup_apr/,stkim1,1523539035,,0,1
732,2018-4-12,2018,4,12,22,8bq5la,[D] Continuous Integration for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8bq5la/d_continuous_integration_for_machine_learning/,rstoj,1523539870,,14,19
733,2018-4-12,2018,4,12,22,8bqbzl,"Input Pipeline for pictures, what tools to use?",https://www.reddit.com/r/MachineLearning/comments/8bqbzl/input_pipeline_for_pictures_what_tools_to_use/,zttt,1523541400,[removed],0,1
734,2018-4-12,2018,4,12,23,8bqg87,[R] [1804.03719] Quantum Algorithm Implementations for Beginners,https://www.reddit.com/r/MachineLearning/comments/8bqg87/r_180403719_quantum_algorithm_implementations_for/,bobchennan,1523542385,,8,9
735,2018-4-12,2018,4,12,23,8bqj0o,[D] How Spotify music recommender (ML) works,https://www.reddit.com/r/MachineLearning/comments/8bqj0o/d_how_spotify_music_recommender_ml_works/,insider_7,1523543015,"Hi all, I am very impressed on how Spotify suggest new songs and builds discovery lists, etc based on preferences. Does anybody knows  online articles/webposts detailing the methodology of their systems? (if is open)",9,7
736,2018-4-12,2018,4,12,23,8bqmvz,"A program doing something similar to ""seeing"".",https://www.reddit.com/r/MachineLearning/comments/8bqmvz/a_program_doing_something_similar_to_seeing/,Pearlnv,1523543890,,0,1
737,2018-4-13,2018,4,13,0,8bquse,"""experts"" in machine learning want to raise 13 M with only Coursera.org certificate as proof of expertise",https://www.reddit.com/r/MachineLearning/comments/8bquse/experts_in_machine_learning_want_to_raise_13_m/,Mayavo,1523545564,,0,1
738,2018-4-13,2018,4,13,0,8br348,[D] Online Course: Clustering &amp; Classification With Machine Learning in Python,https://www.reddit.com/r/MachineLearning/comments/8br348/d_online_course_clustering_classification_with/,alibabaochollish,1523547357,,0,0
739,2018-4-13,2018,4,13,0,8br3rj,[D] Instance Segmentation without region proposals,https://www.reddit.com/r/MachineLearning/comments/8br3rj/d_instance_segmentation_without_region_proposals/,ShivamDuggal4,1523547501,"I have seen a few instance segmentation papers, SDS, Instance aware MNC, MASK-RCNN, all of these first propose object bounding box, then perform the segmentation of that ROI. In this way, the output instance segment of the ROI is compared with that particular region of the true segmentation image.

I understand how the model is able to achieve instance segmentation by predicting different segments for different ROIs. If there are two connected humans in an image, then two different ROIs will be proposed for the image, each representing one segment.

Are there any methods in which instance segmentation can happen without ROI proposals. If any, please explain how the loss function is computed and how does the ground truth instance segmentation image looks like.",3,2
740,2018-4-13,2018,4,13,0,8br8rv,A gentle Introduction to TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/8br8rv/a_gentle_introduction_to_tensorflowjs/,zaidalyafeai,1523548568,,0,1
741,2018-4-13,2018,4,13,1,8breip,[D] The Scary Story of Facebook's Unremarkable 'AI Invented Language',https://www.reddit.com/r/MachineLearning/comments/8breip/d_the_scary_story_of_facebooks_unremarkable_ai/,regalalgorithm,1523549782,,5,0
742,2018-4-13,2018,4,13,1,8brmno,[R] Imagine This! Scripts to Compositions to Videos,https://www.reddit.com/r/MachineLearning/comments/8brmno/r_imagine_this_scripts_to_compositions_to_videos/,visarga,1523551529,,1,3
743,2018-4-13,2018,4,13,2,8brs8i,"[N] OA: ""Fitting larger networks into memory"": Tensorflow support for memory checkpointing and sqrt(n) memory use",https://www.reddit.com/r/MachineLearning/comments/8brs8i/n_oa_fitting_larger_networks_into_memory/,gwern,1523552692,,5,19
744,2018-4-13,2018,4,13,2,8brznp,Deep Learning alone is not enough to build an Intelligent Machine.,https://www.reddit.com/r/MachineLearning/comments/8brznp/deep_learning_alone_is_not_enough_to_build_an/,[deleted],1523554211,,0,1
745,2018-4-13,2018,4,13,2,8bs4sn,[R] Large scale distributed neural network training through online distillation (Google Brain),https://www.reddit.com/r/MachineLearning/comments/8bs4sn/r_large_scale_distributed_neural_network_training/,baylearn,1523555277,,1,7
746,2018-4-13,2018,4,13,2,8bs6zk,[N] Online Course: Machine Learning with Python,https://www.reddit.com/r/MachineLearning/comments/8bs6zk/n_online_course_machine_learning_with_python/,alibabaochollish,1523555751,,0,1
747,2018-4-13,2018,4,13,2,8bs73f,[P] Reverse engineering compiled Core ML models.,https://www.reddit.com/r/MachineLearning/comments/8bs73f/p_reverse_engineering_compiled_core_ml_models/,jamesonatfritz,1523555774,,0,5
748,2018-4-13,2018,4,13,3,8bsexs,[D] De-anonymizing Paper on Purpose,https://www.reddit.com/r/MachineLearning/comments/8bsexs/d_deanonymizing_paper_on_purpose/,jigsawpiecesfading,1523557436,"What do you guys think about the current state of people de-anonymizing papers partly on purpose (uploading to arxiv and promoting) or entirely on purpose. 

For example the authors of the Progressive Growing of GANs paper accepted to ICLR 2018 admitted that they *purposefully* de-anonymized their paper and they weren't penalized.

You can check the discussion here: https://openreview.net/forum?id=Hk99zCeAb",18,13
749,2018-4-13,2018,4,13,3,8bsfgo,[R][ICLR2018 Best Paper Award] Spherical CNNs,https://www.reddit.com/r/MachineLearning/comments/8bsfgo/riclr2018_best_paper_award_spherical_cnns/,downtownslim,1523557556,,22,65
750,2018-4-13,2018,4,13,3,8bsnu2,Building Data Science Capabilities That Scale,https://www.reddit.com/r/MachineLearning/comments/8bsnu2/building_data_science_capabilities_that_scale/,TheDataIncubator,1523559372,,0,2
751,2018-4-13,2018,4,13,3,8bso2d,Using Computer Vision to Infer Body Mass Index,https://www.reddit.com/r/MachineLearning/comments/8bso2d/using_computer_vision_to_infer_body_mass_index/,backprop88,1523559427,,0,1
752,2018-4-13,2018,4,13,4,8bsuie,Jobs in machine learning vs computer vision,https://www.reddit.com/r/MachineLearning/comments/8bsuie/jobs_in_machine_learning_vs_computer_vision/,thatsadsid,1523560824,[removed],0,1
753,2018-4-13,2018,4,13,4,8bt18y,[D] Online Course: Machine Learning with Python,https://www.reddit.com/r/MachineLearning/comments/8bt18y/d_online_course_machine_learning_with_python/,alibabaochollish,1523562264,,3,0
754,2018-4-13,2018,4,13,5,8bt7ox,Machine Learning Intro Topics,https://www.reddit.com/r/MachineLearning/comments/8bt7ox/machine_learning_intro_topics/,bearposters,1523563615,[removed],0,1
755,2018-4-13,2018,4,13,5,8btc9y,Machine learning master : MVA ETHZ,https://www.reddit.com/r/MachineLearning/comments/8btc9y/machine_learning_master_mva_ethz/,bicente22,1523564599,[removed],0,1
756,2018-4-13,2018,4,13,5,8btevs,Are commercial GPUs like GTX 1080Ti worth investing in for at-home training of deep networks? or should i not bother and simply use a cloud service?,https://www.reddit.com/r/MachineLearning/comments/8btevs/are_commercial_gpus_like_gtx_1080ti_worth/,Iotatronics,1523565164,[removed],0,1
757,2018-4-13,2018,4,13,5,8bti8r,[D] Does anyone have production models that update themselves automatically?,https://www.reddit.com/r/MachineLearning/comments/8bti8r/d_does_anyone_have_production_models_that_update/,addthelens,1523565906,"It's feasible to build a system where a model is updated regularly based on new data becoming available.  But depending on the application, there might be extensive validation you would want to do on the model before using it in production.  Are there people out there who have systems that automatically update models and use them in production?  If so, how do get confidence that you're not deploying a bad model?",13,27
758,2018-4-13,2018,4,13,6,8btozo,[N] Google Research: Seeing More with In Silico Labeling of Microscopy Images,https://www.reddit.com/r/MachineLearning/comments/8btozo/n_google_research_seeing_more_with_in_silico/,wired-in,1523567338,,0,39
759,2018-4-13,2018,4,13,7,8bu86v,A new Pytorch wrapper to make it easier to save and load models,https://www.reddit.com/r/MachineLearning/comments/8bu86v/a_new_pytorch_wrapper_to_make_it_easier_to_save/,gagejustins,1523571606,[removed],0,1
760,2018-4-13,2018,4,13,7,8buey7,[P] My implementation of Google's QANet,https://www.reddit.com/r/MachineLearning/comments/8buey7/p_my_implementation_of_googles_qanet/,min_sang,1523573201,,5,18
761,2018-4-13,2018,4,13,8,8bumjd,[N] List of French Universities with AI Program just released (french),https://www.reddit.com/r/MachineLearning/comments/8bumjd/n_list_of_french_universities_with_ai_program/,actuia,1523575063,,0,1
762,2018-4-13,2018,4,13,8,8bus7b,[P] Deep Painterly Harmonization,https://www.reddit.com/r/MachineLearning/comments/8bus7b/p_deep_painterly_harmonization/,lopespm,1523576526,,2,28
763,2018-4-13,2018,4,13,11,8bvoj7,Role of utility function in autonomous vehicles,https://www.reddit.com/r/MachineLearning/comments/8bvoj7/role_of_utility_function_in_autonomous_vehicles/,midianite_rambler,1523584816,[removed],0,1
764,2018-4-13,2018,4,13,11,8bvp1u,What's the legality of using copyrighted information to train a model?,https://www.reddit.com/r/MachineLearning/comments/8bvp1u/whats_the_legality_of_using_copyrighted/,Recolumn,1523584945,[removed],0,1
765,2018-4-13,2018,4,13,11,8bvqa9,[P] Python script to extract features from images using various pretrained networks.,https://www.reddit.com/r/MachineLearning/comments/8bvqa9/p_python_script_to_extract_features_from_images/,cryptobionic,1523585281,,8,185
766,2018-4-13,2018,4,13,11,8bvqtb,What is currently the best most efficient and user-friendly manual image label app?,https://www.reddit.com/r/MachineLearning/comments/8bvqtb/what_is_currently_the_best_most_efficient_and/,inkplay_,1523585423,[removed],0,1
767,2018-4-13,2018,4,13,11,8bvz5d,[D] OpenAI baselines A2C does not normalize either advantage estimate or returns ? -&gt; Loss explosion,https://www.reddit.com/r/MachineLearning/comments/8bvz5d/d_openai_baselines_a2c_does_not_normalize_either/,xingdongrobotics,1523587791,[removed],0,1
768,2018-4-13,2018,4,13,12,8bwa58,"Are there any academic papers or use cases which studies comparison of deep learning with other less computationally expensive models (RF,Xgboost) for structured or tabular data?",https://www.reddit.com/r/MachineLearning/comments/8bwa58/are_there_any_academic_papers_or_use_cases_which/,shubchat,1523591005,[removed],0,1
769,2018-4-13,2018,4,13,12,8bwct3,[P] Brand new to machine learning and I thought it would be a fun challenge to calculate the optimal view settings in the video game Rocket League that will help me achieve the best win rate. Is this something that can be done with machine learning?,https://www.reddit.com/r/MachineLearning/comments/8bwct3/p_brand_new_to_machine_learning_and_i_thought_it/,rorywilliamstwin,1523591810,"Rocket League has numerous different sliders to adjust the view settings (field of view, height, distance, angle, etc) that can drastically help or hinder your win rate. The issue with simple trial and error is there are literally hundreds of thousands of different possible combinations that it just wouldn't be feasible to test them all.   
  
For my dataset I would generate random values for each of the view settings and record the result (win/loss) of a few matches and then rinse and repeat with a new set of values several times. What I'd like to do is use the data to calculate a new set of values that will maximize the win rate percentage.   
  
From my very limited understanding of machine learning I'm assuming I would use some kind of linear regression model. Other than that I'm just not really sure how I would begin to go about solving this problem or if machine learning is even the proper tool for the job. Hoping someone can help point me in the right direction.",7,0
770,2018-4-13,2018,4,13,14,8bwpie,Machine Learning: What It Can and Cannot Do For Your Organization,https://www.reddit.com/r/MachineLearning/comments/8bwpie/machine_learning_what_it_can_and_cannot_do_for/,analyticsinsight,1523595849,,0,1
771,2018-4-13,2018,4,13,14,8bwriy,[D] Ways to approach Facebook's hope to identify hate speech,https://www.reddit.com/r/MachineLearning/comments/8bwriy/d_ways_to_approach_facebooks_hope_to_identify/,SpiritedAssociation,1523596508,"There has been some recent discussion in mainstream media about the automated detection of hate speech by Facebook. This interests me, as I had drafted a research proposal last year on this exact topic (the proposal was declined. We went with something else). It's a really cool idea, and I am hopeful that such a tool might have a positive impact on the world, but it is important when considering such a thing the technological and social contexts in which it exists and what that might contribute to the thing itself.

To my knowledge, there is some amount of concern about such a thing. For example, I have heard Glenn Beck express some amount of wariness about there being efforts to even begin to define hate speech as would be necessary to identify hate speech automatically. There is not a small amount of relevancy to such concerns. Even with a clear definition of what hate speech is, there is difficulty in knowing with reasonable confidence that such a definition is not biased. The labeler forms the world to their mind, this is not new and is a very strong point to Mr. Beck.

Where the really interesting stuff takes place is in how Facebook might reach a definition of hate speech. Going into such a venture knowing full well that we bring our subjective bias to the table with us, how might we address a problem that is as precarious as the task of telling a computer how to tag hate speech? For Facebook that answer is likely to involve some amount of crowd sourcing, as they do have existing features in their software that allow users to suggest that a given post has indecent content. After a post has been reported a sufficient amount of times by a variety of different individuals, you have perhaps some amount of filtering done by a computer and then a person or a group of people making a judgement call on whether the post is removed or not. This is probably roughly what Facebook has right now for dealing with offensive posts, and the fruits of this process are likely to be what Facebook will draw on when attempting to create the numerical definition of hate speech necessary to tell a computer what hate speech is (if they haven't drawn on it already. It seems likely they will have been doing this for years now). The process here is to begin with a set of existing posts that are ""known"" to contain offensive content, and then create statistical classifiers like neural networks that take as input a segment of text and provide as output the statistical probability that the given piece of content is offensive. A high probability would be used as the criteria for automatically removing the content assumed to be offensive. An accurate classifier will reflect the biases in the data set of human tagged posts as its purpose is only to reflect the data which it was trained on. This is the technical context in which this discussion occurs.

With an idea of how facebook is likely to begin this gargantuan task, what improvements might we make? My contention, what I might like to put forth to you the reader, is that the most effective path forward would be to improve the data set that this statistical classifier is built on. It is my contention that this might be done by creating a purpose-specific project that fully commits to crowd sourcing the tagging of content as being offensive or containing hate speech, one that does not use any filtering that relies on an axiomatic definition of hate speech or relies on a small set of moderators to filter the tagged content. Let the masses speak their mind as best as we might enable ourselves to. If one draws a sufficiently diverse set of individuals from the general population of the locale in which such an undertaking is happening AND steps are taken to ensure that the tagging process is not exploited by an external agent, the end product of labeled content would be effectively a mirror of the consensus model of truth that drives modern western science. This crowd sourcing has been utilized in the past in the creation of similar datasets such as the ConceptNet of MIT, a database of common knowledge like ""fire is hot"", and perhaps the lessons learned in the creation of resources like ConceptNet might be effectively leveraged here. There aren't a lack of difficulties in actualizing such a crowd sourced tagging of data, but it is something that is incredibly exciting... that perhaps somewhere in a digital world, the complexity and implications of which society is beginning to come to terms with, there exists an ability to formally describe in part the societal contexts from which things like hate speech and opposition to hate speech emerge.

So my question to you, dear reader (if you should happen to still be here. I'm surprised if you are), is this: is a crowd sourced definition of hate speech a valid definition of hate speech, is it merely a chaos of the masses, or perhaps something else entirely?",15,2
772,2018-4-13,2018,4,13,14,8bwuyg,[D] Anyone having trouble finding papers on a particular topic ? Post it here and we'll help you find papers on that topic ! | Plus answers from 'Helping read ML papers' post from few days ago.,https://www.reddit.com/r/MachineLearning/comments/8bwuyg/d_anyone_having_trouble_finding_papers_on_a/,BatmantoshReturns,1523597741,"There's a lot of variation in terms in machine learning which can make finding papers for a particular concept very tricky at times. 

If you have a concept you would like to obtain more papers about, post it here (along with all papers you already found on said concept) and we'll help you find them. 

I've seen a few times someone release a paper, and someone else point out someone has implemented  very similar concepts in a previous paper. 

Even the Google Brain team has trouble looking up all instances of previous work for a particular topic. A few months ago they released a paper of Swish activation function and people pointed out others have published stuff very similar to it. 

&gt;As has been pointed out, we missed prior works that proposed the same activation function. The fault lies entirely with me for not conducting a thorough enough literature search. My sincere apologies. We will revise our paper and give credit where credit is due.

https://www.reddit.com/r/MachineLearning/comments/773epu/r_swish_a_selfgated_activation_function_google/dojjag2/

So if this is something that happens to the Google Brain team, not being able to find all papers on a particular topic is something all people are prone too. 

So post a topic/idea/concept, along with all the papers you already found on it, and we'll help you find more. 

Even if you weren't thinking about looking for one in particular, it doesn't hurt to check if you missed anything. Post your concept anyway. 

Here's an example of two papers whose authors didn't know about each other until they saw each other on twitter, and they posted papers on nearly the exact same idea, which afaik are the only two papers on that concept. 

Word2Bits - Quantized Word Vectors

https://arxiv.org/abs/1803.05651

Binary Latent Representations for Efficient Ranking: Empirical Assessment

https://arxiv.org/abs/1706.07479

Exact same concept, but two very different ways of descriptions and terminology. 

-----------------------------------------------

I also want to give an update to the post I made 3 days ago where I said I would help on any papers anyone was stuck on. 

https://www.reddit.com/r/MachineLearning/comments/8b4vi0/d_anyone_having_trouble_reading_a_particular/

I wasn't able to answer all the questions, but I at least replied to each of them and started a discussion which would hopefully lead to Answers. Some discussions are on going and pretty interesting. 

I actually indexed them by Paper name in this subreddit

https://www.reddit.com/r/MLPapersQandA/

I hope people go through them, because some questions are unanswered so perhaps there were some people who didn't get around to opening the papers, but when they see the discussion of the problem they'll know the answer and can answer it. 

Also, there are a lot of FANTASTIC and insightful answers for the questions that did get answered. Special thanks to everyone who answered. 

/u/TomorrowExam

/u/Sohakes

/u/RSchaeffer

/u/straw1239

/u/stuvx

/u/geomtry

/u/MohKohn

/u/bonoboTP

/u/min_sang

Apologies if I missed anyone. 

I might do a round 2 of this in a week or two depending on how much free time I have, with a much better format I planned out. 

Anyone who participates in this post will have priority if they have a paper by then. 



",90,42
773,2018-4-13,2018,4,13,14,8bwyax,"[P] Implementations of 15 NLP research papers using Keras, Tensorflow, and Scikit Learn.",https://www.reddit.com/r/MachineLearning/comments/8bwyax/p_implementations_of_15_nlp_research_papers_using/,SupraluminalShift,1523598907,,19,426
774,2018-4-13,2018,4,13,15,8bx7ui,[P] Tiny &amp; Customizable Web App Skeleton to Deploy your Keras Model,https://www.reddit.com/r/MachineLearning/comments/8bx7ui/p_tiny_customizable_web_app_skeleton_to_deploy/,[deleted],1523602372,[deleted],0,1
775,2018-4-13,2018,4,13,16,8bx9cw,Can I use ML in this scenario ?,https://www.reddit.com/r/MachineLearning/comments/8bx9cw/can_i_use_ml_in_this_scenario/,sp3co92,1523602943,[removed],0,1
776,2018-4-13,2018,4,13,16,8bx9yi,Finding what areas of tensorflow code is slow?,https://www.reddit.com/r/MachineLearning/comments/8bx9yi/finding_what_areas_of_tensorflow_code_is_slow/,Data-Daddy,1523603163,[removed],0,1
777,2018-4-13,2018,4,13,16,8bxbe6,"[D] I like Reddit, but is there a quality slack out there ?",https://www.reddit.com/r/MachineLearning/comments/8bxbe6/d_i_like_reddit_but_is_there_a_quality_slack_out/,_sulo,1523603717,"Hello !

As much as I like Reddit, I was wondering if there was a Slack channel that existed with such a qualified community, whether it is to discuss papers more informally or maybe to post related content that is still relevant but not enough to make a reddit post ! Maybe have a channel to help as well, without it getting spammed of ""plz i want learn ai"" and why not also share some backpropagation memes.
From what I searched, I couldn't find any on my own ! 

Does that even exist and if so, can someone point me in the right direction ?
Thanks!",8,15
778,2018-4-13,2018,4,13,16,8bxd06,[R] Survey on Deep RL with New Implementations (Bertsekas),https://www.reddit.com/r/MachineLearning/comments/8bxd06/r_survey_on_deep_rl_with_new_implementations/,rbkillea,1523604322,,1,15
779,2018-4-13,2018,4,13,16,8bxhsb,Machine learning used in the dental profession,https://www.reddit.com/r/MachineLearning/comments/8bxhsb/machine_learning_used_in_the_dental_profession/,Sirzorre,1523606216,[removed],0,1
780,2018-4-13,2018,4,13,17,8bxj1k,"Machine and Deep learning are not enough to build an Intelligent Machine. This program is doing something similar to ""seeing"" and is heavily inspired by deep Modern Physics.",https://www.reddit.com/r/MachineLearning/comments/8bxj1k/machine_and_deep_learning_are_not_enough_to_build/,ronit10,1523606708,,0,1
781,2018-4-13,2018,4,13,17,8bxofa,Is there an extension of Grad-CAM to per input channel heatmap instead of over all input channels?,https://www.reddit.com/r/MachineLearning/comments/8bxofa/is_there_an_extension_of_gradcam_to_per_input/,[deleted],1523609003,,0,1
782,2018-4-13,2018,4,13,17,8bxol7,Data Science: Deep Learning in Python,https://www.reddit.com/r/MachineLearning/comments/8bxol7/data_science_deep_learning_in_python/,[deleted],1523609061,[deleted],0,1
783,2018-4-13,2018,4,13,17,8bxqn8,[D] Data Science: Deep Learning in Python,https://www.reddit.com/r/MachineLearning/comments/8bxqn8/d_data_science_deep_learning_in_python/,alibabaochollish,1523609886,,0,0
784,2018-4-13,2018,4,13,17,8bxqpc,[D] Is there an extension of Grad-CAM to per input channel heatmap instead of over all input channels?,https://www.reddit.com/r/MachineLearning/comments/8bxqpc/d_is_there_an_extension_of_gradcam_to_per_input/,kolopiolo,1523609907,"I am working on a project in which i use electrocardiograms. This means that for my input i have 1D dimensional input, with multiple channels, specifically (5000, 8). For now i have extended Grad-CAM to be usable on this input, so i get one heatmap over all the channels, and it looks promising. What i would like is to get is a heatmap of every channel, as this gives much more useful information as the 8 channels are more independent than regular RGB channels of images. As a note. When visualizing saliency with respect to the input tensor, i have gotten one from each channel, but this is much more noisy than using Grad-CAM with the penultimate convolutional layer. I use Keras with Tensorflow as a backend, and the implementation of Grad-CAM i use is a slightly modified version of Keras-vis to work with 1D dimensional data. I hope someone can help me with this, excuse me for the english.",4,3
785,2018-4-13,2018,4,13,18,8bxx8k,"[P] Pytorch basic implementation of ""Distral: Robust Multitask Reinforcement Learning"" [1707.04175]",https://www.reddit.com/r/MachineLearning/comments/8bxx8k/p_pytorch_basic_implementation_of_distral_robust/,alfo5123,1523612432,,0,6
786,2018-4-13,2018,4,13,18,8bxxt3,[D] Triggering a set of Tensors/Neurons based on input?,https://www.reddit.com/r/MachineLearning/comments/8bxxt3/d_triggering_a_set_of_tensorsneurons_based_on/,rJohn420,1523612684,"Hi, I had this idea of triggering neurons based on input. 

This works by using two different neural networks. 

The first one gets the input and returns an integer value corresponding to the correct group of neurons in the second network.

Then, the second network gets the input and the int that we just found, thus providing the correct final output.

Ex. The network is trained on different games, it recognizes the game 1 and thus it executes only the group of neurons relevant to game 1.

Is this possible?",4,0
787,2018-4-13,2018,4,13,18,8bxycn,How to prevent misclassification due to pixel manipulation / adversarial attack (A solution proposition),https://www.reddit.com/r/MachineLearning/comments/8bxycn/how_to_prevent_misclassification_due_to_pixel/,yesterdaybooze,1523612896,[removed],0,1
788,2018-4-13,2018,4,13,18,8bxzsi,[N] Hear from Demis Hassabis on 30th April for the first in this flagship lecture series on AI.,https://www.reddit.com/r/MachineLearning/comments/8bxzsi/n_hear_from_demis_hassabis_on_30th_april_for_the/,valdanylchuk,1523613465,,3,12
789,2018-4-13,2018,4,13,19,8by0fp,[D] what practical projects can I do that may serve as context for going through Bengio deep learning and Sutton's book ?,https://www.reddit.com/r/MachineLearning/comments/8by0fp/d_what_practical_projects_can_i_do_that_may_serve/,joker2895,1523613715,"Hey redditors , I am a huge believer in learning through doing and I was wondering if you had ideas about projects I could do that may help me learn progressively more and more from the deep learning book by bengio and the reinforcement learning book by Sutton.",10,11
790,2018-4-13,2018,4,13,20,8byanz,[D] OpenAI baselines A2C does not normalize either advantage estimate or returns ? -&gt; Loss explosion,https://www.reddit.com/r/MachineLearning/comments/8byanz/d_openai_baselines_a2c_does_not_normalize_either/,metaAI,1523617361,"I am benchmarking OpenAI baselines implementation of A2C in Acrobot-v1. There is a phenomenon
observed, because baselines original implementation does not normalize either advantage estimate before backprop the action head or normalize returns before backprop value head.

When testing with Acrobot-v1, it leads to loss explosion, (loss value becomes very large like 20000), then the policy cannot learn anything.

After adding normalization to the returns for the value head, the problem solved.

So it seems the point is that when we allow large max time step for an episode, without normalization, the MSE loss with become very big ? 

Just to make sure if I made any mistake, is it correct to normalize (actually standardize to [-1, 1]) for both returns (to value head) and GAEs (to action head. )

There is also an [issue posted in the repo](https://github.com/openai/baselines/issues/362)",0,4
791,2018-4-13,2018,4,13,20,8bycye,Understanding the objective of variatonal inference,https://www.reddit.com/r/MachineLearning/comments/8bycye/understanding_the_objective_of_variatonal/,phizaz,1523618132,[removed],0,1
792,2018-4-13,2018,4,13,20,8bydfb,Trained a German GloVe Vector Embedding Model - How to make it available?,https://www.reddit.com/r/MachineLearning/comments/8bydfb/trained_a_german_glove_vector_embedding_model_how/,Seiteshyru,1523618277,[removed],0,1
793,2018-4-13,2018,4,13,21,8byn31,[R] 12 Useful Things to Know About Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8byn31/r_12_useful_things_to_know_about_machine_learning/,trumtra,1523621246,,0,1
794,2018-4-13,2018,4,13,21,8byn44,black garlic fermenter machine box for sale in china creekbay,https://www.reddit.com/r/MachineLearning/comments/8byn44/black_garlic_fermenter_machine_box_for_sale_in/,wigschina556,1523621256,,1,1
795,2018-4-13,2018,4,13,21,8byqjv,[R] Analytical vs Numerical Solutions in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8byqjv/r_analytical_vs_numerical_solutions_in_machine/,jackblun,1523622238,,0,1
796,2018-4-13,2018,4,13,21,8byscu,Continuous Pork Skin Frying Machine,https://www.reddit.com/r/MachineLearning/comments/8byscu/continuous_pork_skin_frying_machine/,lgsherry,1523622742,,1,1
797,2018-4-13,2018,4,13,21,8byxg7,Is the cutting edge in Machine Learning actually worth anything?,https://www.reddit.com/r/MachineLearning/comments/8byxg7/is_the_cutting_edge_in_machine_learning_actually/,gagejustins,1523624089,[removed],0,1
798,2018-4-13,2018,4,13,22,8byytm,"[N] Machine Learning Engineer, Data Scientist among the best US Jobs in 2018",https://www.reddit.com/r/MachineLearning/comments/8byytm/n_machine_learning_engineer_data_scientist_among/,janemoz,1523624459,,0,1
799,2018-4-13,2018,4,13,22,8bz096,[R] Inventory Optimization Solution in the Azure AI Gallery,https://www.reddit.com/r/MachineLearning/comments/8bz096/r_inventory_optimization_solution_in_the_azure_ai/,jackblun,1523624810,,0,1
800,2018-4-13,2018,4,13,22,8bz92y,[N] A third of your math work is useless,https://www.reddit.com/r/MachineLearning/comments/8bz92y/n_a_third_of_your_math_work_is_useless/,narsilouu,1523627036,,0,0
801,2018-4-13,2018,4,13,22,8bz9fh,The Pillar Drill Machine; Key Features and How They Work for You | Blog | Maan TechnoPlus,https://www.reddit.com/r/MachineLearning/comments/8bz9fh/the_pillar_drill_machine_key_features_and_how/,maantechnoplus,1523627131,,0,1
802,2018-4-13,2018,4,13,22,8bzago,"Resources for Pursuing Machine Learning, Computational Cognitive Science, Computational Neuroscience, and their intersection",https://www.reddit.com/r/MachineLearning/comments/8bzago/resources_for_pursuing_machine_learning/,wcarvalho,1523627382,,0,1
803,2018-4-13,2018,4,13,22,8bzbzg,Hello Machine Learners. I am inspired by watching what some of you guys do with machine learning. How can I become a machine learning professional? I currently work in data analytics.,https://www.reddit.com/r/MachineLearning/comments/8bzbzg/hello_machine_learners_i_am_inspired_by_watching/,TheLongTraveller,1523627758,[removed],0,1
804,2018-4-13,2018,4,13,22,8bzcg3,[R] What We Learned Deploying Deep Learning at Scale for Radiology Images,https://www.reddit.com/r/MachineLearning/comments/8bzcg3/r_what_we_learned_deploying_deep_learning_at/,[deleted],1523627867,[deleted],0,1
805,2018-4-13,2018,4,13,23,8bzdwj,Create your own COCO-style datasets,https://www.reddit.com/r/MachineLearning/comments/8bzdwj/create_your_own_cocostyle_datasets/,[deleted],1523628191,[deleted],0,1
806,2018-4-13,2018,4,13,23,8bzfgg,[P] What We Learned Deploying Deep Learning at Scale for Radiology Images,https://www.reddit.com/r/MachineLearning/comments/8bzfgg/p_what_we_learned_deploying_deep_learning_at/,rahulBatmanDravid,1523628536,,8,70
807,2018-4-13,2018,4,13,23,8bzgmj,[P] Create your own COCO-style datasets,https://www.reddit.com/r/MachineLearning/comments/8bzgmj/p_create_your_own_cocostyle_datasets/,waspinator,1523628808,,4,3
808,2018-4-13,2018,4,13,23,8bzk4j,Getting into (research) projects and engaging with the community?,https://www.reddit.com/r/MachineLearning/comments/8bzk4j/getting_into_research_projects_and_engaging_with/,Schtecke,1523629616,[removed],0,1
809,2018-4-13,2018,4,13,23,8bzkxc,Starting weights of the filters in convolutional neural networks,https://www.reddit.com/r/MachineLearning/comments/8bzkxc/starting_weights_of_the_filters_in_convolutional/,travis1bickle,1523629810,[removed],0,1
810,2018-4-13,2018,4,13,23,8bzsst,"[D] Notes on the ""Goals and Principles of Representation Learning"" workshop at DALI'18 + links to videos",https://www.reddit.com/r/MachineLearning/comments/8bzsst/d_notes_on_the_goals_and_principles_of/,fhuszar,1523631563,,1,0
811,2018-4-14,2018,4,14,0,8c00qt,[P] Simple &amp; Customizable Python Web App Skeleton to Deploy your Keras Model,https://www.reddit.com/r/MachineLearning/comments/8c00qt/p_simple_customizable_python_web_app_skeleton_to/,fingr8,1523633266,,3,35
812,2018-4-14,2018,4,14,0,8c08vh,[P] easy way to prepare Pose Estimation dataset,https://www.reddit.com/r/MachineLearning/comments/8c08vh/p_easy_way_to_prepare_pose_estimation_dataset/,zsdh123,1523635028,,2,0
813,2018-4-14,2018,4,14,0,8c092f,[P] Enhancing logistical flows using numerical models and machine learning,https://www.reddit.com/r/MachineLearning/comments/8c092f/p_enhancing_logistical_flows_using_numerical/,fbonawiede,1523635069,,0,1
814,2018-4-14,2018,4,14,1,8c0kb0,"When building a neural network model, how do you assess whether model performance issues are due to optimization issues vs. model structure?",https://www.reddit.com/r/MachineLearning/comments/8c0kb0/when_building_a_neural_network_model_how_do_you/,TissueReligion,1523637454,[removed],0,1
815,2018-4-14,2018,4,14,1,8c0kqc,Sentiment Classification from Keras to the Browser,https://www.reddit.com/r/MachineLearning/comments/8c0kqc/sentiment_classification_from_keras_to_the_browser/,zaidalyafeai,1523637553,,0,1
816,2018-4-14,2018,4,14,1,8c0luf,AWS EC2 instances to actual GPU names chart ?,https://www.reddit.com/r/MachineLearning/comments/8c0luf/aws_ec2_instances_to_actual_gpu_names_chart/,Representative_Limit,1523637790,[removed],0,1
817,2018-4-14,2018,4,14,2,8c10zi,[D] AWS EC2 instances to actual GPU names chart ?,https://www.reddit.com/r/MachineLearning/comments/8c10zi/d_aws_ec2_instances_to_actual_gpu_names_chart/,Representative_Limit,1523640964,"Hello ! I'm planning on renting an AWS EC2 instance for a machine learning research project which needs more than 32 Go of RAM (so 64 Go would be spot on) as well as a GPU equivalent to a Titan Black. I need to train for approximately 12 hours.

The problem is that I have no idea how to compare the power of a Titan Black to AWS EC2's ""g3.4xlarge"", ""g3.8xlarge"" etc ... Is there a FLOPS figure somewhere to compare them one to another ? Or even better, a nice chart with Model name &lt;--&gt; AWS EC2 instances ? I know this isn't so simple as those are virtual environment etc but knowing precisely the power of the instance is crucial to determine the time the training will likely take and thus the cost of renting it.

I have no way of accessing anything remotely as powerful as I need to IRL, so renting computational power is my only option. I already tested it on my machine with smaller dataset and everything runs smoothly so now it's just a matter of scaling it up and seeing if it breaks.

TL;DR: How to compare GPU &amp; AWS EC2 instances ?
",3,5
818,2018-4-14,2018,4,14,2,8c12k0,Sim-to-Real: Learning Agile Locomotion For Quadruped Robots,https://www.reddit.com/r/MachineLearning/comments/8c12k0/simtoreal_learning_agile_locomotion_for_quadruped/,erwincoumans,1523641309,,1,1
819,2018-4-14,2018,4,14,2,8c13ir,[P] Game utilizing Accord.Net framework for AI powered by a Deep Belief Network that evaluates enemies altered by Genetic Algorithms,https://www.reddit.com/r/MachineLearning/comments/8c13ir/p_game_utilizing_accordnet_framework_for_ai/,Cabrill,1523641527,"#Intro:  
Hello, kind stranger.  Im a student at University of Helsinki in pursuit of my MSc in *Algorithms, Data Analysis and Machine Learning.*  For my thesis Ive created a unique story-based game that utilizes all three facets of my degree in novel ways.  The AI utilizes machine learning and the enemies have individual genetics as part of the gameplay, and to fully accomplish the Data Analysis portion of my degree I need as many people to play the game as I can convince to give it a try.  The game is completely free and designed in such a way that anyone of any skill level can play it, because whether you win or lose a level the story will continue progressing on to the next level.   Skip to the bottom of my post to start downloading it from one of three indie game sites.
  

#Game:  
The game is a futuristic, story-based tower defense game that runs on the Windows and MacOS 64-bit platforms.  The premise is that it is the year 2238, and humans have left the destabilized Earth to terraform the nearest habitable planets.  You are Shepherd Cartalia, of planet B382, and have supervised the growth of your colony since its founding in 2148.  You have successfully increased your colonys population from meager beginnings to over a thousand citizens, but at the start of the game your sustenance and nutrient generator has begun to malfunction.  Rather than spawning livestock that is ready for slaughter, the animals now produced have become violent and are attacking your people.  It is now your responsibility to put up defenses against the attacks, while you evacuate your people from the outposts scattered across the land, and search for a lasting solution to the unexplained crisis.  
  

#Gameplay Overview:  
The game features ten levels, six tower types with three shared upgrades each, fifteen enemy types, a branching dialogue tree of over 2,500 interactions, and four different endings.  The primary gameplay mechanics are tower selection/placement/upgrading, and dialogue choice.  It will take an average of an hour to complete.  Theres only a single, non-managed save slot but the game can be replayed with increasing difficulty as the machine learning model improves.  
  

#Development Overview:  
I developed this game alone, starting in November of 2017.  The character art, attribute icons, and landscape objects were designed by Yuexin Du, a UI &amp; UX designer from Aalto University.  I used the Monogame framework, FlatRedBall game engine, Accord.Net for machine learning and genetic algorithm classes, Keen.IO for data collection, Sprite Pro for creating the animations, Articy Draft for creating the dialogue tree, Visual Studio 2017 IDE, Tiled for map design, GIMP for artwork creation, and Audacity for sound design.  Most of the music was created by Anttis Instrumentals (/u/Mrloop), a few of the tracks were created by my brother Brallit (/u/Brallit), and one was by Zack Darshon (/u/how_small_a_thought).  The basis for the sound effects were sourced from many CC0 sources on FreeSound.org.  The UI assets and tileset for levels were purchased from GameDevMarket.net.  The title screen images were found on Google Image search using labeled for reuse with modification.  The base for the world map was purchased from the Unity marketplace, and lastly, the sun/moon calculations were performed using Vladimir Agafonkins   
  

#Technical:  
The game utilizes a Deep Belief Network, with one hundred and fifty hidden nodes, and two layers (input/output).  It is trained at the completion of each wave with six hundred and fifty-five data points, comprised of enemy attributes (health, speed, resistances, etc), defense attributes (range, damage type, attack speed, etc.), pathing points, and water hazard size/locations.  Training is done with a mixture of unsupervised and supervised learning on the resulting score of a group of enemies, i.e. a wave.  Each wave is scored calculated by determining how close to the goal each enemy could get, with the total score being the average of all enemies individual scores.  The score is weighted such that if even one enemy reaches the goal that wave would outscore a wave in which every enemy got 99.9% of the way to the goal.    

In addition to machine learning, the game also implements genetic algorithms.  Each type of animal starts with a set of randomized genetics, consisting of eight chromosomes, that alter the animals base attributes.  After every wave in the game the machine learning model is used to rank the fitness of the genetics, by hypothetically scoring an animal using those genetics in the immediate circumstances, and then a tournament ranking is applied to select the best specimens for the following generations with the ideal of progressively improving the genetics of an animal as the machine learning gains proficiency in evaluating fitness.    

To prevent these computationally intensive processes from impacting game performance, they are delegated to a low priority worker thread.  A new model training process only starts when the last one has completed, but each time the process is kicked off all the available data is used to train the models so the intermittent training wont impact model performance.  The game utilizes whichever model was most recently trained for all its decisions, and that model is replaced after each learning and evaluation process.  
  
#Data Collected:  
First, I want to stress that none of the data is personally identifiable.  It is all anonymous and collected for the sole purpose of presenting my thesis.  None of it will be used commercially or for any use outside of writing my thesis.  Having said that, the following data is collected: machine learning model performance, genetic fitness improvement, dialogue choices, tower selection, ending type received, originating geolocation of the player, game launch count, and time played.  
  
#Objective:  
I will be writing a 50+ page thesis on the usage of machine learning and genetic algorithms in games, and will be doing some data analysis on the anonymous statistics reported by the game.  Primarily I am looking at the effectiveness of the machine learning models and genetic algorithms.  I want to see at what sample size the machine learning model outperforms random guesses, and identify the point at which model performance stabilizes.  I am also going to perform a data analysis on the met data collected with no leading hypothesis, but simply make observations based on player generated data.  This may be what dialogue choices are favored by different parts of the world, what dialogue choices are most often chosen, and attempt to identify correlations between dialogue selection and tower selection.  
  
#Personal Note:  
I started this project with the idea of applying machine learning and genetic algorithms to a game, and the theme that most strongly resonated with those concepts isnt one Im particularly fond of.  To be blunt, its quite dark and a bit depressing.  I personally prefer to play, and make, games with happy, uplifting themes (shout out to Stardew Valley which is the inspiration for my other game, Lets Go Fish King!) and creating this game was entirely out of character for me.    
  

There are still many features I wanted to add to this game, such as a technology tree and more play-reactive dialogue, but I dont believe Ill be returning to it this project after this thesis unless I get strong support for the concept.  Perhaps its not a very good game, or perhaps my dislike for the theme I settled on has bled through, but regardless of the actual cause, Im just not a fan of how it turned out.  For that reason Id like to apologize to you ahead of time for asking you to play this quite depressing game for the sake of helping me with my thesis.  I can assure you my next game will be quite a bit brighter, cheerful and hopefully a lot more fun than this attempt.  Despite those misgivings, I truly hope youll give it a play through in the interest of helping me with my thesis.  
  
[Small Album on Imgur](https://imgur.com/a/7XAOR)  
You can download The Abbattoir Intergrade for Mac/Windows at:  
[Itch.IO](https://cabrill.itch.io/ai)  
[GameJolt] (https://cabrill.gamejolt.io/abbattoirintergrade)  
[Indiexpo]( https://www.indiexpo.net/en/games/the-abbattoir-intergrade)  ",0,7
820,2018-4-14,2018,4,14,2,8c13ww,"Creating Word Vectors using python, Finding Common set of words for clustering in python",https://www.reddit.com/r/MachineLearning/comments/8c13ww/creating_word_vectors_using_python_finding_common/,coolnikhilj22,1523641596,,0,1
821,2018-4-14,2018,4,14,3,8c1au5,[D] DALI 2018 - Workshop - Goals and Principles of Representation Learning - YouTube,https://www.reddit.com/r/MachineLearning/comments/8c1au5/d_dali_2018_workshop_goals_and_principles_of/,sksq9,1523643075,,0,11
822,2018-4-14,2018,4,14,3,8c1dfg,AI Weekly 13 April 2018,https://www.reddit.com/r/MachineLearning/comments/8c1dfg/ai_weekly_13_april_2018/,TomekB,1523643661,,0,1
823,2018-4-14,2018,4,14,3,8c1gld,[R] Google Research Blog: Introducing Semantic Experiences with Talk to Books and Semantris,https://www.reddit.com/r/MachineLearning/comments/8c1gld/r_google_research_blog_introducing_semantic/,sksq9,1523644342,,7,45
824,2018-4-14,2018,4,14,3,8c1gog,SQL: Adding / Deleting Columns and Entire Datatables!!,https://www.reddit.com/r/MachineLearning/comments/8c1gog/sql_adding_deleting_columns_and_entire_datatables/,AnalystRisingTuts,1523644358,,0,1
825,2018-4-14,2018,4,14,4,8c1ss1,Understanding Machine Learning - free book,https://www.reddit.com/r/MachineLearning/comments/8c1ss1/understanding_machine_learning_free_book/,chclau,1523646984,,0,1
826,2018-4-14,2018,4,14,5,8c25t2,[N] A 60-minute MXNet Gluon Crash Course,https://www.reddit.com/r/MachineLearning/comments/8c25t2/n_a_60minute_mxnet_gluon_crash_course/,thomasdlt,1523649829,,0,14
827,2018-4-14,2018,4,14,5,8c2g52,[P] Deep Learning applied to Cricket,https://www.reddit.com/r/MachineLearning/comments/8c2g52/p_deep_learning_applied_to_cricket/,Faizann24,1523652124,,0,12
828,2018-4-14,2018,4,14,7,8c364i,[R] Watch AI create a 3D model of a personfrom just a few seconds of video,https://www.reddit.com/r/MachineLearning/comments/8c364i/r_watch_ai_create_a_3d_model_of_a_personfrom_just/,rstoj,1523658281,,68,251
829,2018-4-14,2018,4,14,8,8c3gly,"[D] Should I stop the training, when the loss began to grow?",https://www.reddit.com/r/MachineLearning/comments/8c3gly/d_should_i_stop_the_training_when_the_loss_began/,zhirzemli,1523660893,"Hello.
I'm training the model and the validation loss began to grow. Actually, not too much, but anyway I'm just wondering: Should I stop the training now?
Validation recall is still increasing (val. precision is slightly decreasing) and validation f1 is also increasing.
Is it any sense to continue the training? I want to pull up the f1 score a little bit more (and especially recall), but as I told loss is going up. So, I'm afraid that this is a nonsense trading.",27,1
830,2018-4-14,2018,4,14,8,8c3mv3,"[R][Genomics team in Google Brain] Nucleus is a library designed to make it easy to read, write and analyze data in common genomics",https://www.reddit.com/r/MachineLearning/comments/8c3mv3/rgenomics_team_in_google_brain_nucleus_is_a/,downtownslim,1523662575,,3,21
831,2018-4-14,2018,4,14,11,8c4kkn,[D] WikiText like dataset for other languages?,https://www.reddit.com/r/MachineLearning/comments/8c4kkn/d_wikitext_like_dataset_for_other_languages/,machinesaredumb,1523671798,"Is there a WikiText like dataset for other languages such as French or German. If not, are there scripts I can run to generate a language modeling dataset from Wikipedia for various languages?",3,9
832,2018-4-14,2018,4,14,12,8c511r,How does YOLO detect large objects?,https://www.reddit.com/r/MachineLearning/comments/8c511r/how_does_yolo_detect_large_objects/,hoonkai,1523676763,[removed],0,1
833,2018-4-14,2018,4,14,13,8c5e1d,Teaching a Computer to Classify Anime,https://www.reddit.com/r/MachineLearning/comments/8c5e1d/teaching_a_computer_to_classify_anime/,tyreest96,1523681064,,0,1
834,2018-4-14,2018,4,14,13,8c5e7a,An interesting problem,https://www.reddit.com/r/MachineLearning/comments/8c5e7a/an_interesting_problem/,macpatel,1523681129,[removed],0,1
835,2018-4-14,2018,4,14,14,8c5juj,Five Most Popular Open Source Frameworks Used in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8c5juj/five_most_popular_open_source_frameworks_used_in/,analyticsinsight,1523683189,,0,1
836,2018-4-14,2018,4,14,14,8c5pdi,"Eliminating ""useless"" variables in deep neural networks?",https://www.reddit.com/r/MachineLearning/comments/8c5pdi/eliminating_useless_variables_in_deep_neural/,ME_PhD,1523685296,[removed],0,1
837,2018-4-14,2018,4,14,15,8c5whv,[D] Starting weights of the filters in convolutional neural networks,https://www.reddit.com/r/MachineLearning/comments/8c5whv/d_starting_weights_of_the_filters_in/,travis1bickle,1523688069,"I am training a CNN (3 convolutional layers and 4 fully connected layers) for seismic wave classification. I normalised/standardised the data etc. I followed the Xavier initialisation principle, but during training the cost function just bounces up and down and never decreases consistently. However, when I increase the standard deviation of the initialisation filter values significantly (sigma=4), the CNN starts to converge (at least to a local minima). My question is does anyone know of such extreme variance initialisation with other networks?  ",10,13
838,2018-4-14,2018,4,14,16,8c6784,"[D] Designer Diary: The Search for AlphaMystica (or how AlphaGo architecture ""didn't work well"" for the board game Terra Mystica)",https://www.reddit.com/r/MachineLearning/comments/8c6784/d_designer_diary_the_search_for_alphamystica_or/,nipusa,1523692734,,11,60
839,2018-4-14,2018,4,14,17,8c6dfn,[P] Best approach for Speech Verification (Not Identification) for a person?,https://www.reddit.com/r/MachineLearning/comments/8c6dfn/p_best_approach_for_speech_verification_not/,PM_ME_YOUR_PRESETS,1523695503,"Context : We are making a biometric authentication application where we use voice to verify who our speaker is (from the voice data in our data base). We are using java as the main programming language.

What shall be the best approach?

I know that MFCCs for the person's speech would be the right input data. Now the question is which one would be the better training method.

So far, we've covered two approaches : First one is using GMMs and reducing the dimensions of the MFCC supervector using the i-vector approach. But for that, no decent libraries are available.


Second approach would be to use a CNN based model, using the MFCC coefficients as an input and training them in a CNN and recognizing the speaker using that. Now before we get to experimentation, we just wanted to know if anyone has done it and which approach did you find the best.



The i-vector approach is extremely mathematically complex (Not that I don't understand Gaussian Mixture Models as such, and not even that I don't understand the mathematics behind any of the operations being done. I just don't know how to implement it).


Side but off the track question : How did you guys learn to implement complex mathematical equations and proofs into good code that works and actually practically uses the concept?",4,8
840,2018-4-14,2018,4,14,18,8c6hch,CoT: Cooperative Training for Generative Modeling,https://www.reddit.com/r/MachineLearning/comments/8c6hch/cot_cooperative_training_for_generative_modeling/,[deleted],1523697286,,0,1
841,2018-4-14,2018,4,14,18,8c6htx,How do I properly classify the 'not' cases while predicting?,https://www.reddit.com/r/MachineLearning/comments/8c6htx/how_do_i_properly_classify_the_not_cases_while/,Starkboy,1523697519,[removed],0,1
842,2018-4-14,2018,4,14,18,8c6iuy,[D] CoT: Cooperative Training for Generative Modeling,https://www.reddit.com/r/MachineLearning/comments/8c6iuy/d_cot_cooperative_training_for_generative_modeling/,KlausRuan,1523698007,"Recently a paper titled ""CoT: Cooperative Training for Generative Modeling"" is posted on arXiv (https://arxiv.org/pdf/1804.03782.pdf).

In the paper, they proposed a low-variance and bias-free method to generate texts without pre-training, and outperforms many famous GAN models such like seqGAN, MaliGAN, RankGAN, etc. Their model also has a sound theory basis.

The most interesting part is, they use a mediator M to facilitate the training of the generator G, which makes GUNs (""Stopping GAN Violence: Generative Unadversarial Networks"". I know this is a joke paper.) come true! By training M and G towards the same goal, they manage to stabilize the training procedure and remove pre-training phase in other text-generating GAN papers.

How do you view this paper?",5,6
843,2018-4-14,2018,4,14,19,8c6rh9,OpenAI's Gym algorithm comparison,https://www.reddit.com/r/MachineLearning/comments/8c6rh9/openais_gym_algorithm_comparison/,pmkiller,1523701967,[removed],0,1
844,2018-4-14,2018,4,14,19,8c6u4s,[D] Here's how you can improve the accuracy of your ML models before even writing them!!,https://www.reddit.com/r/MachineLearning/comments/8c6u4s/d_heres_how_you_can_improve_the_accuracy_of_your/,hailAK,1523703163,,0,1
845,2018-4-14,2018,4,14,20,8c7007,Workshop on Big Data Analytics and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8c7007/workshop_on_big_data_analytics_and_machine/,avideep,1523705597,,0,1
846,2018-4-14,2018,4,14,21,8c755d,"When it comes to implementing AI solutions, you can do better than fitting a square peg in a round hole.",https://www.reddit.com/r/MachineLearning/comments/8c755d/when_it_comes_to_implementing_ai_solutions_you/,skellam-ai,1523707628,,0,1
847,2018-4-14,2018,4,14,21,8c78dt,Should I drop out and learn ML/DApp stuff?,https://www.reddit.com/r/MachineLearning/comments/8c78dt/should_i_drop_out_and_learn_mldapp_stuff/,l0gicbomb,1523708807,[removed],0,1
848,2018-4-14,2018,4,14,21,8c7dms,[P] Deep Learning with the Mavic - Object Recognition from a 360 Camera Attached to a Drone,https://www.reddit.com/r/MachineLearning/comments/8c7dms/p_deep_learning_with_the_mavic_object_recognition/,CaptainMcThorn,1523710680,,18,111
849,2018-4-14,2018,4,14,23,8c7q7n,"Where can I find corpus with misspelled words, sentences with it, in English language ???",https://www.reddit.com/r/MachineLearning/comments/8c7q7n/where_can_i_find_corpus_with_misspelled_words/,tadeuszjasina,1523714656,[removed],0,1
850,2018-4-15,2018,4,15,0,8c8bna,Predicting Sports Outcomes Using Python and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8c8bna/predicting_sports_outcomes_using_python_and/,Pardo_AK,1523720541,,0,5
851,2018-4-15,2018,4,15,1,8c8qmy,The importance of biases in AI and the way to fix them : Diversity (Popular Science),https://www.reddit.com/r/MachineLearning/comments/8c8qmy/the_importance_of_biases_in_ai_and_the_way_to_fix/,actuia,1523724464,,0,1
852,2018-4-15,2018,4,15,1,8c8rzc,[P] How I Taught A Machine To Take My Job - Behavior Cloning and 3D level design,https://www.reddit.com/r/MachineLearning/comments/8c8rzc/p_how_i_taught_a_machine_to_take_my_job_behavior/,samiam46a,1523724826,,20,88
853,2018-4-15,2018,4,15,4,8c9q5o,[D] Self-loops in tensorflow RNN implementation,https://www.reddit.com/r/MachineLearning/comments/8c9q5o/d_selfloops_in_tensorflow_rnn_implementation/,fu_2016,1523733100,"I am trying to implement a simple RNN in tensorflow for predicting next number in a consecutive sequence. Sequence length never exceeds 9. I am declaring my ht as `ht = tf.Variable(initial_value=tf.truncated_normal(shape=(1, 10)))
`. My implementation fails to learn. All output for all test data is some fixed number like 9 or 5. My guess is that the problem is with the above declaration. Anybody every implement RNN this way ? Other tips for debugging are welcome too.",5,7
854,2018-4-15,2018,4,15,4,8c9ugm,"[P] A Python implementation of ""Deep Super Learner: A Deep Ensemble for Classification Problems""",https://www.reddit.com/r/MachineLearning/comments/8c9ugm/p_a_python_implementation_of_deep_super_learner_a/,RevolutionaryWeek,1523734246,,13,43
855,2018-4-15,2018,4,15,5,8ca36k,[D] The fall of RNN / LSTM  Eugenio Culurciello  Medium,https://www.reddit.com/r/MachineLearning/comments/8ca36k/d_the_fall_of_rnn_lstm_eugenio_culurciello_medium/,Writes_A_Bit,1523736470,,16,0
856,2018-4-15,2018,4,15,5,8ca4rt,Why multi-class image classifiers?,https://www.reddit.com/r/MachineLearning/comments/8ca4rt/why_multiclass_image_classifiers/,freedryk,1523736855,[removed],0,1
857,2018-4-15,2018,4,15,6,8cahit,"[D] How was ""Winner-Take-All Autoencoder "" accepted by NIPS?",https://www.reddit.com/r/MachineLearning/comments/8cahit/d_how_was_winnertakeall_autoencoder_accepted_by/,[deleted],1523740091,[deleted],0,1
858,2018-4-15,2018,4,15,6,8cak7b,"How could the ""Winner-Take-All Autoencoders "" paper be accepted in NIPS?",https://www.reddit.com/r/MachineLearning/comments/8cak7b/how_could_the_winnertakeall_autoencoders_paper_be/,[deleted],1523740814,,0,1
859,2018-4-15,2018,4,15,6,8calyh,Data Science  Advanced Topics In Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8calyh/data_science_advanced_topics_in_machine_learning/,EdwardSchmitt21,1523741267,[removed],0,1
860,2018-4-15,2018,4,15,6,8caokr,"[D] How could the ""Winner-Take-All Autoencoders"" paper be accepted in NIPS?",https://www.reddit.com/r/MachineLearning/comments/8caokr/d_how_could_the_winnertakeall_autoencoders_paper/,moron_network,1523741941,"Here is the paper https://arxiv.org/abs/1409.2752

Both the originality and the experiments are essentially nothing (pardon my brutal honesty). How could this paper be accepted in NIPS?",11,0
861,2018-4-15,2018,4,15,7,8caueq,[P] Playing with text-to-image and image-to-text generation to simulate an AI graphic designer and an AI creative director,https://www.reddit.com/r/MachineLearning/comments/8caueq/p_playing_with_texttoimage_and_imagetotext/,aman-tiwari,1523743451,"http://www.aman.work/ai-designer-texts/index.html

I made a project playing around with [AttnGAN](https://github.com/taoxugit/AttnGAN) and [Show and Tell](https://github.com/KranthiGV/Pretrained-Show-and-Tell-model) to play on the kinds of discussions and feedback that occurs between image makers and their clients.

More info: http://www.aman.work/projects/real%20texts%20of%20an%20ai%20graphic%20designer",6,84
862,2018-4-15,2018,4,15,8,8cbd8e,[D] Is machine learning / AI an over saturated field?,https://www.reddit.com/r/MachineLearning/comments/8cbd8e/d_is_machine_learning_ai_an_over_saturated_field/,eks111,1523748515,"For someone considering switching major from mechanical engineering to CS and is very interested in AI research, I was wondering if ML is overcrowded? I would love to get a PhD and do research in the field but if so many people are doing it then would I actually be able to contribute?",133,176
863,2018-4-15,2018,4,15,9,8cbk2z,Realtime Gaussian Material Synthesis from Learned User Preferences in a 2D Latent Space - SIGGRAPH 2018,https://www.reddit.com/r/MachineLearning/comments/8cbk2z/realtime_gaussian_material_synthesis_from_learned/,smt1,1523750499,,0,1
864,2018-4-15,2018,4,15,9,8cbklh,Cloud server rental for machine learning on audio.,https://www.reddit.com/r/MachineLearning/comments/8cbklh/cloud_server_rental_for_machine_learning_on_audio/,ciarandeceol,1523750653,[removed],0,1
865,2018-4-15,2018,4,15,9,8cbnu8,Gentle Introduction to TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/8cbnu8/gentle_introduction_to_tensorflowjs/,zaidalyafeai,1523751538,,0,1
866,2018-4-15,2018,4,15,9,8cbr7l,"[D] How should we search the space of possible cellular automata rules, viewing time as another space dimension, for the simplest possible 2d turing-complete 8-way symmetric which has gliders similar to conways-game-of-life?",https://www.reddit.com/r/MachineLearning/comments/8cbr7l/d_how_should_we_search_the_space_of_possible/,BenRayfield,1523752498,"I am interested in puzzle games that could be built of this, like many people got interested in gliders that emit gliders in conways-game-of-life, but taking it farther since it has 1 less dimension of complexity but the same flexibility.

Conways-game-of-life is symmetric in vertical, horizontal, and diagonal flips, but has 3 dimensions (including time) compared to rule110 which has 2 (including time) but is not symmetric. If we allow npcomplete constraints based on 2d distance (or at least the up to 8 mirrors of a vector), such as rule110 can be emulated by pair exclusions of 8 (unrelated to the quantity of mirrors) colors, and conway life can be emulated by many more (but still finite quantity) of those, then... How could I search such a possible 2d timeless constraint space (such as hopfield / boltzmann neuralnet energy function) for a near-simplest set of weights (smallest convolutional window) which has turing-completeness and 8-way symmetry and gliders that emit gliders similar to conway life?",5,7
867,2018-4-15,2018,4,15,10,8cc2il,[R] Interactive Sketch-Based Normal Map Generation with Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8cc2il/r_interactive_sketchbased_normal_map_generation/,baylearn,1523755845,,2,7
868,2018-4-15,2018,4,15,10,8cc7pp,[P] Donkey: minimalist &amp; modular self-driving library for RC cars,https://www.reddit.com/r/MachineLearning/comments/8cc7pp/p_donkey_minimalist_modular_selfdriving_library/,SupraluminalShift,1523757432,,0,14
869,2018-4-15,2018,4,15,12,8ccl2r,Download free photos along with user generated tags via Unsplash API,https://www.reddit.com/r/MachineLearning/comments/8ccl2r/download_free_photos_along_with_user_generated/,miranthalk,1523761621,,0,1
870,2018-4-15,2018,4,15,12,8ccs38,3D compressor model files || Download free cad,https://www.reddit.com/r/MachineLearning/comments/8ccs38/3d_compressor_model_files_download_free_cad/,Library-3D-Engineer,1523763951,,0,1
871,2018-4-15,2018,4,15,13,8ccx7h,ML jobs for freshers,https://www.reddit.com/r/MachineLearning/comments/8ccx7h/ml_jobs_for_freshers/,shayansadar,1523765673,[removed],0,1
872,2018-4-15,2018,4,15,14,8cd4rf,Missile interception and ML?,https://www.reddit.com/r/MachineLearning/comments/8cd4rf/missile_interception_and_ml/,KingOfBlingBling,1523768478,[removed],0,1
873,2018-4-15,2018,4,15,15,8cdlao,"[D] Eliminating ""useless"" variables in deep neural networks?",https://www.reddit.com/r/MachineLearning/comments/8cdlao/d_eliminating_useless_variables_in_deep_neural/,ME_PhD,1523775253,"In a very deep network such as a conv net with lots of filters and/or full layers, it seems to me that not all filters/weights are equally important - some could even be useless. Is there a scheme that removes these from the network (to save computation time)?

I'm not talking about dropout which temporarily takes them out, I mean permanently take them out based on small gradients, high varience, etc.

If anyone knows anything I'd appreciate some links/papers (sorry I'm new to NN).",36,50
874,2018-4-15,2018,4,15,16,8cdqsu,[D] StackGAN + CycleGAN = Text guided image-to-image translation?,https://www.reddit.com/r/MachineLearning/comments/8cdqsu/d_stackgan_cyclegan_text_guided_imagetoimage/,cbsudux,1523777678,"I am looking to build a model that implements a version of text guided image translation. 

For example, an image of a man + ""walking"" --&gt; Image of man walking. 
Or something even simpler, but you get the basic idea. 

I am unable to find any existing research for this. Any suggestions/ new ideas will be very helpful :)",4,2
875,2018-4-15,2018,4,15,17,8cdvbe,Deep Learning on RESTful API,https://www.reddit.com/r/MachineLearning/comments/8cdvbe/deep_learning_on_restful_api/,dadwal_akshay,1523779786,[removed],0,1
876,2018-4-15,2018,4,15,18,8ce2ee,"Judge me, harshly!",https://www.reddit.com/r/MachineLearning/comments/8ce2ee/judge_me_harshly/,saransh661,1523783165,[removed],0,1
877,2018-4-15,2018,4,15,18,8ce30d,Training data for weekly price of the iPhone 8,https://www.reddit.com/r/MachineLearning/comments/8ce30d/training_data_for_weekly_price_of_the_iphone_8/,xaviersc,1523783462,[removed],0,1
878,2018-4-15,2018,4,15,19,8ceg5i,Working on an architecture for more general AI,https://www.reddit.com/r/MachineLearning/comments/8ceg5i/working_on_an_architecture_for_more_general_ai/,remko66,1523789843,[removed],1,1
879,2018-4-15,2018,4,15,22,8cf6jl,What simple games with imperfect information do you know?,https://www.reddit.com/r/MachineLearning/comments/8cf6jl/what_simple_games_with_imperfect_information_do/,curiosity_monster,1523799584,[removed],0,1
880,2018-4-15,2018,4,15,23,8cfarn,Could you please participate in my survey?,https://www.reddit.com/r/MachineLearning/comments/8cfarn/could_you_please_participate_in_my_survey/,quickshot_cyk,1523800922,[removed],0,1
881,2018-4-16,2018,4,16,0,8cft9w,[R] Representing Language with Recurrent and Convolutional Layers: An Authorship Attribution Example,https://www.reddit.com/r/MachineLearning/comments/8cft9w/r_representing_language_with_recurrent_and/,[deleted],1523805922,[deleted],0,2
882,2018-4-16,2018,4,16,1,8cg3h4,Sparkflow: Train and bring Tensorflow model to Spark ML Pipeline.,https://www.reddit.com/r/MachineLearning/comments/8cg3h4/sparkflow_train_and_bring_tensorflow_model_to/,[deleted],1523808439,[deleted],1,1
883,2018-4-16,2018,4,16,1,8cg4e5,[D] Do nets pretrained on random labels perform better on real labels?,https://www.reddit.com/r/MachineLearning/comments/8cg4e5/d_do_nets_pretrained_on_random_labels_perform/,abstractcontrol,1523808668,"I read once that deep NNs can memorize even large datasets like ImageNet with random labels. Suppose you take such a net pretrained with random labels, does it train better on the true labels?

I guess they would not, but it seems like a question worth asking just to make sure.",6,3
884,2018-4-16,2018,4,16,1,8cg9rn,Gaussian Material Synthesis,https://www.reddit.com/r/MachineLearning/comments/8cg9rn/gaussian_material_synthesis/,keghn,1523809982,,0,1
885,2018-4-16,2018,4,16,2,8cgi39,[D] What is the best recorded history of ML?,https://www.reddit.com/r/MachineLearning/comments/8cgi39/d_what_is_the_best_recorded_history_of_ml/,earlyadopter_12,1523811958,"What would you recommend to someone who's been frozen in time for the past 20 years and wants to be caught up to speed on how ML has evolved? 

Books? Documentaries? Websites? Etc...",30,154
886,2018-4-16,2018,4,16,3,8cgxk9,"How does one learn to get good enough to be able to implement research papers through code, something like jeremy howard does in fast.ai?",https://www.reddit.com/r/MachineLearning/comments/8cgxk9/how_does_one_learn_to_get_good_enough_to_be_able/,Nick7hill,1523815518,[removed],0,1
887,2018-4-16,2018,4,16,3,8ch80e,[R] Harmonic Networks: Deep Translation and Rotation Equivariance,https://www.reddit.com/r/MachineLearning/comments/8ch80e/r_harmonic_networks_deep_translation_and_rotation/,AsIAm,1523817895,,21,106
888,2018-4-16,2018,4,16,4,8chhti,"[P] Sparkflow: Train and integrate Tensorflow models, utilizing Spark ML Pipelines.",https://www.reddit.com/r/MachineLearning/comments/8chhti/p_sparkflow_train_and_integrate_tensorflow_models/,lodev12,1523820100,,3,34
889,2018-4-16,2018,4,16,4,8chhvp,Toy problem for classification that could be generated?,https://www.reddit.com/r/MachineLearning/comments/8chhvp/toy_problem_for_classification_that_could_be/,mir__,1523820112,[removed],0,1
890,2018-4-16,2018,4,16,4,8chjw8,Showing noisy images on real-time/denoised ray traced renders.,https://www.reddit.com/r/MachineLearning/comments/8chjw8/showing_noisy_images_on_realtimedenoised_ray/,mount_sumInt,1523820587,[removed],0,1
891,2018-4-16,2018,4,16,4,8chmqy,"Pursuing a Major in Math and a minor in CS,Applied Stats is it possible to break into the Machine Learning/Computer Vision/Data Science field with just an undergrad and relevant experience?",https://www.reddit.com/r/MachineLearning/comments/8chmqy/pursuing_a_major_in_math_and_a_minor_in_csapplied/,financefickle123,1523821250,[removed],0,1
892,2018-4-16,2018,4,16,4,8chnji,Can I train my digital voice by feeding it with a bunch of lines from an actor?,https://www.reddit.com/r/MachineLearning/comments/8chnji/can_i_train_my_digital_voice_by_feeding_it_with_a/,galwayhooker,1523821433,[removed],0,1
893,2018-4-16,2018,4,16,4,8chnp5,ITree understanding,https://www.reddit.com/r/MachineLearning/comments/8chnp5/itree_understanding/,MLBeginner15,1523821466,[removed],0,1
894,2018-4-16,2018,4,16,4,8cho6w,[R] Representing Language with Recurrent and Convolutional Layers: An Authorship Attribution Example,https://www.reddit.com/r/MachineLearning/comments/8cho6w/r_representing_language_with_recurrent_and/,QuantMountain,1523821588,,3,13
895,2018-4-16,2018,4,16,5,8cht0r,Compering classifiers trained on rolling windows for a time series dataset.,https://www.reddit.com/r/MachineLearning/comments/8cht0r/compering_classifiers_trained_on_rolling_windows/,GauBhakshak,1523822711,[removed],0,1
896,2018-4-16,2018,4,16,5,8chw9t,Machine learning fascinates me. But I feel like it has little use to me,https://www.reddit.com/r/MachineLearning/comments/8chw9t/machine_learning_fascinates_me_but_i_feel_like_it/,Xilc,1523823436,[removed],0,1
897,2018-4-16,2018,4,16,5,8chzjs,Poll: What OS do you use for ML Projects?,https://www.reddit.com/r/MachineLearning/comments/8chzjs/poll_what_os_do_you_use_for_ml_projects/,TheBestCake,1523824217,,0,1
898,2018-4-16,2018,4,16,5,8ci12m,"[P] Deep learning (Keras/TF) implementation of programming-language classification for code files (16 language, &gt;99% accuracy)",https://www.reddit.com/r/MachineLearning/comments/8ci12m/p_deep_learning_kerastf_implementation_of/,SupraluminalShift,1523824564,,16,59
899,2018-4-16,2018,4,16,6,8cic6x,[D]How about the Allen Institute and OpenAI?,https://www.reddit.com/r/MachineLearning/comments/8cic6x/dhow_about_the_allen_institute_and_openai/,staircase7,1523827191,"So,having see many applications of ""AI"" in industry and having an have approximate knowledge of many machine learning methods what i feel is that the industry is pushing machine learning research in way that it solves only specific tasks that have narrow applications. Of course this isn't something strange since usually the funding goes to something that can have short-term returning ex. 2-4 years. That's why i believe that non-profit organization such as OpenAI can lead the way to General AI.

Now, about OpenAI there have been many posts and discussions ,mainly because of the Gym and Universe enviroments and because of Elon Musk's funding but there is an another non-profit AI research center,the Allen Institute for Artificial Intelligence which was funded Paul Allen(Microsoft's co-founder) and it has received funds in the same order as OpenAI. The interesting part is that they have goals that i find much more ambitious than OpenAI's.
They have many projects,varying in their purpuse, such as Semantic Scholar, a ""intelligent"" search engine for scientific papers or  project Alexandria for common sense and reasoning. 
And some smaller projects such as GeoS for End-to-End Geometry Problem Solver http://geometry.allenai.org/
 and AllenNLP for http://demo.allennlp.org/machine-comprehension.

What i find weird is that i don't recall reading something about their results or just them being mention in discussions about General AI or even in machine learning. So these is my question,have you heard about them,and if so,what do you think about their goals and their research.

",10,6
900,2018-4-16,2018,4,16,6,8cilzs,Talk to Books,https://www.reddit.com/r/MachineLearning/comments/8cilzs/talk_to_books/,iamkeyur,1523829595,,0,1
901,2018-4-16,2018,4,16,7,8cishy,Deep learning open source projects to contribute to,https://www.reddit.com/r/MachineLearning/comments/8cishy/deep_learning_open_source_projects_to_contribute/,some_magic_powers,1523831182,[removed],0,1
902,2018-4-16,2018,4,16,7,8civz0,"Building Data Science Capabilities That Scale - Webinar with DataScience.com founder, Ian Swanson",https://www.reddit.com/r/MachineLearning/comments/8civz0/building_data_science_capabilities_that_scale/,TheDataIncubator,1523832071,,0,2
903,2018-4-16,2018,4,16,7,8cixpw,[D] Toy example for computing ELBO and true posterior,https://www.reddit.com/r/MachineLearning/comments/8cixpw/d_toy_example_for_computing_elbo_and_true/,AloneStretch,1523832524,"In some papers, such as ""The Mutual Autoencoder"" (Figure 4 in appendix C) show plots of the True posterior.
I realize I do not understand how this is computed and must try to work through examples instead of just reading.

Question: is there a good toy example of _computing_ all the important quantities, the ELBO, maybe the LL by MC, the true posterior. Either as a textbook with sufficient guidance for the exercise, or as a worked jupyter notebook?  An example with 2 model parmaters could be nice, since it can be shown in 2D plots.
",5,11
904,2018-4-16,2018,4,16,7,8ciy4o,If I have a pool of numbers which has a very distinct pattern - how best to convert these to english using machine learning ?,https://www.reddit.com/r/MachineLearning/comments/8ciy4o/if_i_have_a_pool_of_numbers_which_has_a_very/,THANOSTITAN89888,1523832626,[removed],0,1
905,2018-4-16,2018,4,16,8,8cj0ph,[P] RunwayML: Machine Learning for Everyone,https://www.reddit.com/r/MachineLearning/comments/8cj0ph/p_runwayml_machine_learning_for_everyone/,3tres,1523833277,,0,35
906,2018-4-16,2018,4,16,8,8cj935,"Introduction to random forest with sklearn - EDA, Feature Eng, modeling, grid search",https://www.reddit.com/r/MachineLearning/comments/8cj935/introduction_to_random_forest_with_sklearn_eda/,balla122,1523835464,,0,1
907,2018-4-16,2018,4,16,9,8cjgo0,I am looking for more videos along this scope that mainly explain the biology of neurons to better understand ML concepts,https://www.reddit.com/r/MachineLearning/comments/8cjgo0/i_am_looking_for_more_videos_along_this_scope/,[deleted],1523837502,[deleted],0,1
908,2018-4-16,2018,4,16,9,8cjpez,[D] Market prediction using NN,https://www.reddit.com/r/MachineLearning/comments/8cjpez/d_market_prediction_using_nn/,Siennebjkfsn,1523839754,"I'm currently dipping my toes in quantitative trading. Does anyone here have experience with using ML models to predict markets? I've found it very challenging so far, and I need help.

---

This is how far I've gotten:

Example 1

https://imgur.com/a/qL4Ft

Example 2 - overfitting

https://imgur.com/a/39POJ

   - Plots at the top, in light green background, are predictions using training data.

   - Plots at the bottom, in light blue background, are predictions using testing data.

   - Blue lines are historical prices of a stock/cryptocurrency.

   - Red lines are predicted future ~5 minute prices, made at time at which the blue line ends.

   - Green and yellow lines are actual future values.

---

I'm using an RNN model to make these predictions. Predictions are percent changes. I'm really clueless as to how to transform my inputs, which are just past prices of different stocks or cryptocurrencies. Right now, I'm just normalizing them (z-score) without any feature extraction.

Obviously, the predictions are far from accurate. As I expected, this project isn't anything like Kaggle competitions or problems for which I've used NNs in the past. Given that I don't know much about finance/quant trading, my progress is excruciatingly slow.

I would like to ask if anyone here would be interested in helping me with this project or being a mentor to guide me on what things to try and avoid. Thanks!",3,0
909,2018-4-16,2018,4,16,10,8ck1zn,Calculating derivatives,https://www.reddit.com/r/MachineLearning/comments/8ck1zn/calculating_derivatives/,country_dev,1523843189,[removed],0,1
910,2018-4-16,2018,4,16,11,8ckaen,PORTABLE MILLING MACHINE MILLING HEAD DESIGN,https://www.reddit.com/r/MachineLearning/comments/8ckaen/portable_milling_machine_milling_head_design/,Gurunad,1523845552,,0,1
911,2018-4-16,2018,4,16,12,8ckppx,Metacademy - Level-Up Your Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8ckppx/metacademy_levelup_your_machine_learning/,mathmare,1523849985,,0,1
912,2018-4-16,2018,4,16,14,8cl6br,"QT4 25 automatic 6 inch, 4 5 inch hollow block and standard brick making...",https://www.reddit.com/r/MachineLearning/comments/8cl6br/qt4_25_automatic_6_inch_4_5_inch_hollow_block_and/,dymachine01,1523855293,,1,1
913,2018-4-16,2018,4,16,15,8cllz8,Foster your Machine Learning Efforts with these 5 Best Open Source Frameworks,https://www.reddit.com/r/MachineLearning/comments/8cllz8/foster_your_machine_learning_efforts_with_these_5/,dexlabanalytics,1523861092,,1,1
914,2018-4-16,2018,4,16,15,8clm0l,[P] adversarial vagina: pix2pix trained with images of nude human females. [mildly nsfw],https://www.reddit.com/r/MachineLearning/comments/8clm0l/p_adversarial_vagina_pix2pix_trained_with_images/,gwfarm,1523861106,,5,0
915,2018-4-16,2018,4,16,16,8clouz,Machine Learning Development with R Language,https://www.reddit.com/r/MachineLearning/comments/8clouz/machine_learning_development_with_r_language/,weblineindia-com,1523862165,,0,2
916,2018-4-16,2018,4,16,16,8clvg6,How do you read vectors and display?,https://www.reddit.com/r/MachineLearning/comments/8clvg6/how_do_you_read_vectors_and_display/,[deleted],1523864813,,0,1
917,2018-4-16,2018,4,16,16,8clx4i,How do you read and display a vector?,https://www.reddit.com/r/MachineLearning/comments/8clx4i/how_do_you_read_and_display_a_vector/,dbsopinion,1523865488,[removed],0,1
918,2018-4-16,2018,4,16,18,8cm6qi,I just found out Google and Open AI use 1 of 5 algorithms to make their AI. (skip to 5:29 unless you want to Facebooks facial recognition works).,https://www.reddit.com/r/MachineLearning/comments/8cm6qi/i_just_found_out_google_and_open_ai_use_1_of_5/,Menilik,1523869566,,0,1
919,2018-4-16,2018,4,16,18,8cm87i,[D] Some good paper suggestions for a seminar.,https://www.reddit.com/r/MachineLearning/comments/8cm87i/d_some_good_paper_suggestions_for_a_seminar/,dnamez_nevin,1523870169,"Hello everyone, I'm a pre final year student, a very beginner in AI and ML. I wanted some good research papers to base my final project on. I have a basic understanding on Anns and gradient descent. I'm thinking of projects around image recognition and NLP. I'm also looking for various fields other than this to apply AI on.",1,9
920,2018-4-16,2018,4,16,18,8cmbok,"KaggleDays 18-19th May Warsaw, Poland - presentations/workshops + competition",https://www.reddit.com/r/MachineLearning/comments/8cmbok/kaggledays_1819th_may_warsaw_poland/,mosquit0,1523871559,,1,1
921,2018-4-16,2018,4,16,18,8cmc8h,[P] Multi-lingual speech synthesis: Donald Trump and Kim Jung Un,https://www.reddit.com/r/MachineLearning/comments/8cmc8h/p_multilingual_speech_synthesis_donald_trump_and/,cyplus1,1523871787,"Trump speaks in Korean

Kim speaks in English

Demo videos are uploaded here

https://icepick.ai/demo
",15,67
922,2018-4-16,2018,4,16,18,8cmcl8,First release of the 0Mind skill server,https://www.reddit.com/r/MachineLearning/comments/8cmcl8/first_release_of_the_0mind_skill_server/,xxxa0c,1523871936,[removed],0,1
923,2018-4-16,2018,4,16,19,8cmkqe,[P] 1 BTC bounty on agent that learns SC2 minigame  r/sc2ai,https://www.reddit.com/r/MachineLearning/comments/8cmkqe/p_1_btc_bounty_on_agent_that_learns_sc2_minigame/,archiatrus,1523875093,,8,15
924,2018-4-16,2018,4,16,20,8cmoxa,Using Machine Learning to estimate discriminations by origin in France,https://www.reddit.com/r/MachineLearning/comments/8cmoxa/using_machine_learning_to_estimate/,antmaz,1523876597,,0,1
925,2018-4-16,2018,4,16,20,8cmu5f,"Pyception, all the ML deployment pain points in one video",https://www.reddit.com/r/MachineLearning/comments/8cmu5f/pyception_all_the_ml_deployment_pain_points_in/,The__Lone__Nut,1523878350,,1,1
926,2018-4-16,2018,4,16,20,8cmy4c,[R] 5 ways of looking at Machine Learning What is ML?,https://www.reddit.com/r/MachineLearning/comments/8cmy4c/r_5_ways_of_looking_at_machine_learning_what_is_ml/,digitalson,1523879641,,0,1
927,2018-4-16,2018,4,16,21,8cn0co,Stainless Honey Filling Machine,https://www.reddit.com/r/MachineLearning/comments/8cn0co/stainless_honey_filling_machine/,lgsherry,1523880345,,1,1
928,2018-4-16,2018,4,16,21,8cn3so,[R] Automated Text Classification Using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8cn3so/r_automated_text_classification_using_machine/,dearpetra,1523881363,,0,1
929,2018-4-16,2018,4,16,21,8cn682,Data Categorization and Classification Services,https://www.reddit.com/r/MachineLearning/comments/8cn682/data_categorization_and_classification_services/,trainingdata,1523882066,,0,1
930,2018-4-16,2018,4,16,21,8cn6vf,"[D] Eight-bit floating point | ms-fp8, posit, low precision",https://www.reddit.com/r/MachineLearning/comments/8cn6vf/d_eightbit_floating_point_msfp8_posit_low/,dimber-damber,1523882241,,6,26
931,2018-4-16,2018,4,16,21,8cna67,[R] How to Get the Most From Your Machine Learning Data,https://www.reddit.com/r/MachineLearning/comments/8cna67/r_how_to_get_the_most_from_your_machine_learning/,jackblun,1523883201,,0,1
932,2018-4-16,2018,4,16,22,8cnh4a,"DeepSuperLearner, Spherical CNNs, Google Semantris, Debater Data, AlterEgo, Text-to-Images GANs, Hate Speech Detection,",https://www.reddit.com/r/MachineLearning/comments/8cnh4a/deepsuperlearner_spherical_cnns_google_semantris/,[deleted],1523884988,[deleted],0,1
933,2018-4-16,2018,4,16,22,8cnidd,Help with choosing algorithm,https://www.reddit.com/r/MachineLearning/comments/8cnidd/help_with_choosing_algorithm/,LordFarto,1523885328,[removed],0,1
934,2018-4-16,2018,4,16,22,8cnju1,"[N] DeepSuperLearner, Spherical CNNs, Google Semantris, Debater Data, AlterEgo, Text-to-Images GANs, Hate Speech Detection,",https://www.reddit.com/r/MachineLearning/comments/8cnju1/n_deepsuperlearner_spherical_cnns_google/,omarsar,1523885708,,0,12
935,2018-4-16,2018,4,16,22,8cnk61,How should I start learning machine learning?,https://www.reddit.com/r/MachineLearning/comments/8cnk61/how_should_i_start_learning_machine_learning/,kushagra_bisen,1523885801,[removed],0,1
936,2018-4-16,2018,4,16,23,8cnpo5,Switchback Tests and Randomized Experimentation Under Network Effects at DoorDash,https://www.reddit.com/r/MachineLearning/comments/8cnpo5/switchback_tests_and_randomized_experimentation/,gagejustins,1523887214,,0,1
937,2018-4-16,2018,4,16,23,8cnxrh,Any know about POMDP for motion planning? Is there any suggestion of relative or better method for motion planning for the robot in real-time or online and good performance?,https://www.reddit.com/r/MachineLearning/comments/8cnxrh/any_know_about_pomdp_for_motion_planning_is_there/,[deleted],1523889155,,0,1
938,2018-4-16,2018,4,16,23,8co1g7,"[P] Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity on any text dataset.",https://www.reddit.com/r/MachineLearning/comments/8co1g7/p_generate_text_using_a_pretrained_neural_network/,minimaxir,1523889982,,16,105
939,2018-4-16,2018,4,16,23,8co2rh,[D] Best slides you've seen while studying anything ML related?,https://www.reddit.com/r/MachineLearning/comments/8co2rh/d_best_slides_youve_seen_while_studying_anything/,DonCanas,1523890271,"Hi everyone. The reason of this post is because I usually struggle when designing slides for different courses related to Machine Learning. While everyone has their own opinions on whether slides should contain tons of equations/text vs a more visual approach, I think it would be a good exercise to check which resources have you found to be engaging, easy to read, or anything that made you say ""hey, this slides on SVM are awesome!"".

For example, I tend to favor a lot slides that have a simple visual exercise of the concept, such as Aurlien Gron's Capsule Networks video https://www.youtube.com/watch?v=pPN8d0E3900

If you're also a teaching assistant or a professor, and want to share your insights when designing slides, that would be awesome too.

Thanks!",6,23
940,2018-4-17,2018,4,17,0,8co6sf,Anyone know about POMDP for motion planning? Is there any suggestion of relative or better method for motion planning for the robot in real-time or online and good performance?,https://www.reddit.com/r/MachineLearning/comments/8co6sf/anyone_know_about_pomdp_for_motion_planning_is/,impet14,1523891153,[removed],0,1
941,2018-4-17,2018,4,17,0,8co88p,[R] Ember: And open source dataset and classifier for static malware detection,https://www.reddit.com/r/MachineLearning/comments/8co88p/r_ember_and_open_source_dataset_and_classifier/,aphlipp,1523891466,,0,6
942,2018-4-17,2018,4,17,1,8cos3a,iMIMIC - Interpretability of Machine Intelligence in Medical Image Computing,https://www.reddit.com/r/MachineLearning/comments/8cos3a/imimic_interpretability_of_machine_intelligence/,pereirasrm,1523895753,,0,2
943,2018-4-17,2018,4,17,1,8covwx,Picture Comparison on Analyzer Plots.,https://www.reddit.com/r/MachineLearning/comments/8covwx/picture_comparison_on_analyzer_plots/,JeffTheMess,1523896583,[removed],0,1
944,2018-4-17,2018,4,17,1,8cowtx,[D] How do you use tensorflow (opinion on tf.Estimator/tf.Dataset),https://www.reddit.com/r/MachineLearning/comments/8cowtx/d_how_do_you_use_tensorflow_opinion_on/,Seon-Ho,1523896782,"Hi everyone,

I was curious about how people make use of Tensorflow and I would be glad if people reply to this thread with their own experiences.

For some context I use TF for quite some times now (2 years) and I have my own pipeline that evolved with the different releases  of TF. As of now I divided my process into three stages:

* 1. preprocess data into tfrecords file (specific to each projects) 
* 2. I have a custom parser that read JSON files and create network architecture, the loss to minimize and the training operation related (common to all project, only the JSON changes)
* 3. Implement three function that train, evaluate and export the model. For each project I can use the same backbone and change only few part.

In this regard I was wondering how people use Tensorflow (what does your pipeline looks like, how do you deploy your models, etc.). 

I run my training locally but will surely move on to google cloud platform. That's why I was wondering whether people use tf.Estimator. For now I can't see what it would bring to my pipeline, but maybe I am not informed enough.

Also for dataset, I found this to be very rigid, especially when you need to mix datasets. For instance I had a dataset with 20 classes and have proper balanced batches was a nightmare with tf.Dataset API only so I had to mix everything beforehand. How do you go to shuffle properly your data?

Thanks for reading and hopefully for replying.",22,19
945,2018-4-17,2018,4,17,1,8coxhp,CNC Micro Machines,https://www.reddit.com/r/MachineLearning/comments/8coxhp/cnc_micro_machines/,challengemachine11,1523896923,[removed],0,1
946,2018-4-17,2018,4,17,2,8cp4g6,This is my first machine learning tutorial video on YouTube :),https://www.reddit.com/r/MachineLearning/comments/8cp4g6/this_is_my_first_machine_learning_tutorial_video/,adarsh1021,1523898372,,0,1
947,2018-4-17,2018,4,17,2,8cp8bk,"[N] ICLR 2018s Best Papers: Variant Adam, Spherical CNNs, and Meta-Learning",https://www.reddit.com/r/MachineLearning/comments/8cp8bk/n_iclr_2018s_best_papers_variant_adam_spherical/,trcytony,1523899163,,0,1
948,2018-4-17,2018,4,17,2,8cpb64,Neural Network plays aa in Unity using NEAT,https://www.reddit.com/r/MachineLearning/comments/8cpb64/neural_network_plays_aa_in_unity_using_neat/,Nimblephile,1523899741,,0,1
949,2018-4-17,2018,4,17,2,8cpe7c,[D] Multiple activation functions in same layer?,https://www.reddit.com/r/MachineLearning/comments/8cpe7c/d_multiple_activation_functions_in_same_layer/,ME_PhD,1523900357,"If the first layer in a classical DNN is f(W x + b) where f is the activation function, what if I do f1(W1 x + b1) + f2(W2 x + b2) + fn(... where f1, f2, ...fn are different activation functions?

Is this a thing? If yes, what is it called and does anyone have good links?

If it sucks, can someone explain why it's not used?

Seems like it may model some behaviors more efficiently. For example let f1, f2 ... be orthogonal functions. If the data has periodic behavior, some periodic activation functions could capture that behavior with less parameters.",12,13
950,2018-4-17,2018,4,17,2,8cphok,"[D] If there is a low barrier to enter Ai/ML, what separates the pros from the newbies?",https://www.reddit.com/r/MachineLearning/comments/8cphok/d_if_there_is_a_low_barrier_to_enter_aiml_what/,ivicts,1523901077,,15,8
951,2018-4-17,2018,4,17,3,8cpnp0,[D] Code of AI Ethics proposed in the UK,https://www.reddit.com/r/MachineLearning/comments/8cpnp0/d_code_of_ai_ethics_proposed_in_the_uk/,baylearn,1523902335,,6,23
952,2018-4-17,2018,4,17,3,8cpy87,Predicting customer's next purchase,https://www.reddit.com/r/MachineLearning/comments/8cpy87/predicting_customers_next_purchase/,atinesh229,1523904477,[removed],0,1
953,2018-4-17,2018,4,17,4,8cq4gj,[N] TensorFlow 1.8.0 Release Candidate Announced,https://www.reddit.com/r/MachineLearning/comments/8cq4gj/n_tensorflow_180_release_candidate_announced/,wei_jok,1523905779,,32,113
954,2018-4-17,2018,4,17,4,8cq4ro,[D] Text Classification with TensorFlow Estimators | Sebastian Ruder,https://www.reddit.com/r/MachineLearning/comments/8cq4ro/d_text_classification_with_tensorflow_estimators/,sksq9,1523905842,,0,16
955,2018-4-17,2018,4,17,4,8cqicm,Convolutional Neural Network for Relation Extraction,https://www.reddit.com/r/MachineLearning/comments/8cqicm/convolutional_neural_network_for_relation/,[deleted],1523908691,[deleted],0,1
956,2018-4-17,2018,4,17,5,8cql54,[P] Convolutional Neural Network for Relation Extraction,https://www.reddit.com/r/MachineLearning/comments/8cql54/p_convolutional_neural_network_for_relation/,roomylee,1523909290,,0,1
957,2018-4-17,2018,4,17,5,8cqwla,Personalized Hey Siri - Apple,https://www.reddit.com/r/MachineLearning/comments/8cqwla/personalized_hey_siri_apple/,sidsig,1523911704,,0,1
958,2018-4-17,2018,4,17,6,8cram8,[R] Multimodal Unsupervised Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/8cram8/r_multimodal_unsupervised_imagetoimage_translation/,ofirpress,1523914829,,47,387
959,2018-4-17,2018,4,17,7,8crgo7,Reinforcement learning for Super Smash Brothers Melee,https://www.reddit.com/r/MachineLearning/comments/8crgo7/reinforcement_learning_for_super_smash_brothers/,jjabrams705,1523916208,[removed],0,1
960,2018-4-17,2018,4,17,7,8croy5,Trained Reinforcement Learning Agent Playing Starcraft 2 Using DeepMind/Blizzard's Collaborative Pysc2 Environment,https://www.reddit.com/r/MachineLearning/comments/8croy5/trained_reinforcement_learning_agent_playing/,ilikepancakez,1523918120,,1,1
961,2018-4-17,2018,4,17,8,8crvnj,[D] The Ethics of Reward Shaping,https://www.reddit.com/r/MachineLearning/comments/8crvnj/d_the_ethics_of_reward_shaping/,wei_jok,1523919754,,0,1
962,2018-4-17,2018,4,17,8,8crvyi,Maths of Xavier initialization?,https://www.reddit.com/r/MachineLearning/comments/8crvyi/maths_of_xavier_initialization/,DeepSleepy,1523919820,[removed],0,1
963,2018-4-17,2018,4,17,8,8cs4br,Anyone have experience with the dataset located here? http://cis.jhu.edu/~sachin/digit/digit.html,https://www.reddit.com/r/MachineLearning/comments/8cs4br/anyone_have_experience_with_the_dataset_located/,eyneill,1523921889,[removed],0,1
964,2018-4-17,2018,4,17,9,8cs9t6,"If you had to geuss, how do you think learning and intelligence works in the brain",https://www.reddit.com/r/MachineLearning/comments/8cs9t6/if_you_had_to_geuss_how_do_you_think_learning_and/,simple_cell,1523923300,[removed],0,1
965,2018-4-17,2018,4,17,10,8csyd1,The factors affecting the cutting quality of laser cutting machines,https://www.reddit.com/r/MachineLearning/comments/8csyd1/the_factors_affecting_the_cutting_quality_of/,gldmachina,1523929582,,0,1
966,2018-4-17,2018,4,17,11,8ct3vi,[D] Is the $3000 Titan V STILL only 20% faster than the $700 1080 Ti,https://www.reddit.com/r/MachineLearning/comments/8ct3vi/d_is_the_3000_titan_v_still_only_20_faster_than/,FirstTimeResearcher,1523931024,Has Nvidia improved on these performance numbers at all: https://medium.com/@u39kun/titan-v-vs-1080-ti-head-to-head-battle-of-the-best-desktop-gpus-on-cnns-d55a19866b7c,12,9
967,2018-4-17,2018,4,17,11,8ctbw7,What is best LSTM or CNN for intent classification?,https://www.reddit.com/r/MachineLearning/comments/8ctbw7/what_is_best_lstm_or_cnn_for_intent_classification/,deepankar27,1523933265,[removed],0,1
968,2018-4-17,2018,4,17,12,8ctgg2,Mozambique Hydraform M7MI super interlocking conduit compressed stabiliz...,https://www.reddit.com/r/MachineLearning/comments/8ctgg2/mozambique_hydraform_m7mi_super_interlocking/,dymachine01,1523934506,,1,1
969,2018-4-17,2018,4,17,12,8ctksk,"Didactic, Extensible and Clean Implementation of Alpha Zero",https://www.reddit.com/r/MachineLearning/comments/8ctksk/didactic_extensible_and_clean_implementation_of/,snair21,1523935748,,4,20
970,2018-4-17,2018,4,17,12,8ctn56,[D] Advice for deep learning computer build,https://www.reddit.com/r/MachineLearning/comments/8ctn56/d_advice_for_deep_learning_computer_build/,MLmarlena,1523936429,"Hi all! Im building a personal deep learning computer and I was wondering if anyone had advice on the choice of CPU. This is my first computer build ever, so I apologize in advance for being naive. 

I originally purchased an AMD Ryzen 5 1600 CPU along with ASRock AB350 Pro4 mobo, but being so new I didnt realize that with this configuration I couldnt display anything to the screen without an independent GPU. I have plans to get a Nvidia Titan Xp for my DL computation, but am worried about utilizing it for both displaying and computations.

With this in mind I started to research the AMD Ryzen 5 2400G APU (CPU with integrated GPU) however my understanding is the 2400G comes at a performance ding compared to the 1600 (namely, only 4 cores compared to 6 cores). I am wondering if the difference between these two processors will be significant in my DL build? Whats the best option? 

The way I see it there are three options:
1) go with 2400g for dedicated display graphics, leaving my Titan for pure computation and freeing up a PCIe slot for another graphics card down the line
2) go with 1600, plug my monitor into the Titan and share the display/compute load, hoping this allows me to utilize the PC for simple tasks like web browsing while my models are training
3) go with 1600 and get a baseline GPU (i.e. GTX 1030) for dedicated graphics. This gets me full 6-core CPU power with dedicated compute GPU, but the 1030 may go to waste if I decide to add another Titan/1080 Ti to my build down the line.

Price-wise the 1600 and 2400G are basically equivalent, I just cant find any resources comparing them for computational purposes, as most of the benchmarking involves gaming. 

Tl;dr - How much CPU power is needed for most deep learning machines (think image classification, Kaggle competitions, etc.)? How do the AMD Ryzen 5 1600 compare against the 2400G in this context?",8,2
971,2018-4-17,2018,4,17,13,8cttfq,[R] The Conversation: Deep Audio-Visual Speech Enhancement,https://www.reddit.com/r/MachineLearning/comments/8cttfq/r_the_conversation_deep_audiovisual_speech/,afourast,1523938328,,8,115
972,2018-4-17,2018,4,17,13,8ctva1,[D] Bending 2D space while training your neural network (Neural network training visualization),https://www.reddit.com/r/MachineLearning/comments/8ctva1/d_bending_2d_space_while_training_your_neural/,meatshell,1523938884,"Summary: what I did was feeding data points lying on a grid to the last 2D layer of a trained neural network. This resulted in some interesting 2D space warping-bending effect.

Here are some demo videos:

https://www.youtube.com/watch?v=9XdukiLqP2Y

https://www.youtube.com/watch?v=fj0kUz2nRaU

Full work here:

https://meatbun.space/2018/04/17/bending-2d-space-while-training-your-neural-network-neural-network-training-visualization/",2,2
973,2018-4-17,2018,4,17,13,8ctwwj,Help regarding project selection using Deep Learning.,https://www.reddit.com/r/MachineLearning/comments/8ctwwj/help_regarding_project_selection_using_deep/,YoYoVaTsA,1523939404,[removed],0,1
974,2018-4-17,2018,4,17,13,8cu1cs,[R] The unreasonable effectiveness of the forget gate (of the LSTM),https://www.reddit.com/r/MachineLearning/comments/8cu1cs/r_the_unreasonable_effectiveness_of_the_forget/,inarrears,1523940815,,8,16
975,2018-4-17,2018,4,17,14,8cu3gh,[R] [1804.03599] Understanding disentangling in -VAE,https://www.reddit.com/r/MachineLearning/comments/8cu3gh/r_180403599_understanding_disentangling_in_vae/,evc123,1523941522,,2,15
976,2018-4-17,2018,4,17,14,8cu466,"[P] Gun Violence Database - A comprehensive, accessible database of US gun violence incidents from January 2013 to March 2018.",https://www.reddit.com/r/MachineLearning/comments/8cu466/p_gun_violence_database_a_comprehensive/,Subtle__,1523941762,,7,46
977,2018-4-17,2018,4,17,15,8cud8q,[R] XNORBIN: A 95 TOp/s/W Hardware Accelerator for Binary Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8cud8q/r_xnorbin_a_95_topsw_hardware_accelerator_for/,Skeptic3,1523944856,,1,3
978,2018-4-17,2018,4,17,15,8cudkg,What is Machine Learning | Machine Learning Simplified | Machine Learnin...,https://www.reddit.com/r/MachineLearning/comments/8cudkg/what_is_machine_learning_machine_learning/,Anusha55,1523944969,,0,1
979,2018-4-17,2018,4,17,15,8cuf9v,Can we achieve General Ai using something like PathNet?,https://www.reddit.com/r/MachineLearning/comments/8cuf9v/can_we_achieve_general_ai_using_something_like/,theslt,1523945584,[removed],0,1
980,2018-4-17,2018,4,17,15,8cui6u,Finding common phrases (pieces of text) in documents.,https://www.reddit.com/r/MachineLearning/comments/8cui6u/finding_common_phrases_pieces_of_text_in_documents/,Captain_Droid,1523946671,[removed],0,1
981,2018-4-17,2018,4,17,16,8cunia,"Deep Learning from first principles in Python, R and Octave  Part 6",https://www.reddit.com/r/MachineLearning/comments/8cunia/deep_learning_from_first_principles_in_python_r/,tvganesh,1523948624,,0,1
982,2018-4-17,2018,4,17,16,8cunkc,Pima Dataset Removed From UCI ML Repository,https://www.reddit.com/r/MachineLearning/comments/8cunkc/pima_dataset_removed_from_uci_ml_repository/,InformationEntropy,1523948650,[removed],0,1
983,2018-4-17,2018,4,17,16,8cuss2,[R] [1804.04241v1] Capsules for Object Segmentation,https://www.reddit.com/r/MachineLearning/comments/8cuss2/r_180404241v1_capsules_for_object_segmentation/,Turcik,1523950644,,11,39
984,2018-4-17,2018,4,17,16,8cut52,Listening and Correcting Children Poem Recitation,https://www.reddit.com/r/MachineLearning/comments/8cut52/listening_and_correcting_children_poem_recitation/,ImraneDessai,1523950793,[removed],0,1
985,2018-4-17,2018,4,17,16,8cuulg,Regarding projects in AGI,https://www.reddit.com/r/MachineLearning/comments/8cuulg/regarding_projects_in_agi/,mohit_jarvis29,1523951391,[removed],0,1
986,2018-4-17,2018,4,17,16,8cuvgs,"World's first commercially available image to image deep learning style transfer system, how much would you pay?",https://www.reddit.com/r/MachineLearning/comments/8cuvgs/worlds_first_commercially_available_image_to/,[deleted],1523951755,,0,1
987,2018-4-17,2018,4,17,17,8cuwd9,[P] Estimating discriminations by origin in France with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8cuwd9/p_estimating_discriminations_by_origin_in_france/,antmaz,1523952139,,2,0
988,2018-4-17,2018,4,17,17,8cuyj7,image to image style transfer,https://www.reddit.com/r/MachineLearning/comments/8cuyj7/image_to_image_style_transfer/,[deleted],1523953039,,0,1
989,2018-4-17,2018,4,17,17,8cuywu,Non-standard type of normalization for NN,https://www.reddit.com/r/MachineLearning/comments/8cuywu/nonstandard_type_of_normalization_for_nn/,AlganTrader,1523953201,[removed],1,1
990,2018-4-17,2018,4,17,17,8cuzoo,The best Probability and Statistics course for machine learning,https://www.reddit.com/r/MachineLearning/comments/8cuzoo/the_best_probability_and_statistics_course_for/,arch_dav,1523953512,[removed],0,1
991,2018-4-17,2018,4,17,17,8cv0b5,[P] image to image photographic style transfer deep learning system,https://www.reddit.com/r/MachineLearning/comments/8cv0b5/p_image_to_image_photographic_style_transfer_deep/,stuartprintspace,1523953782,"image to image style transfer

The system works by users uploading their image, plus a style reference image and our system will learn the style of the reference image and apply that to their own image. Here are some results: goo.gl/aWstq1

The idea is that  a machine learning system that would learn any style and apply it to your un-retouched images, to avoid using a human photoshop expert. We would charge $20 to learn a style (you can use any image, any resolution) and $1 per image to apply that style. ",18,0
992,2018-4-17,2018,4,17,17,8cv2sx,"Deep learning scaling is predictable, empirically",https://www.reddit.com/r/MachineLearning/comments/8cv2sx/deep_learning_scaling_is_predictable_empirically/,alexeyr,1523954838,,0,1
993,2018-4-17,2018,4,17,19,8cvjrn,[1804.04128] Text2Colors: Guiding Image Colorization through Text-Driven Palette Generation,https://www.reddit.com/r/MachineLearning/comments/8cvjrn/180404128_text2colors_guiding_image_colorization/,heykeetae,1523961478,,0,1
994,2018-4-17,2018,4,17,19,8cvlb3,Teaching a neural network how to play a game,https://www.reddit.com/r/MachineLearning/comments/8cvlb3/teaching_a_neural_network_how_to_play_a_game/,[deleted],1523962072,,0,1
995,2018-4-17,2018,4,17,20,8cvomm,[R] [1804.05296] Adversarial Attacks Against Medical Deep Learning Systems,https://www.reddit.com/r/MachineLearning/comments/8cvomm/r_180405296_adversarial_attacks_against_medical/,beamsearch,1523963195,,1,9
996,2018-4-17,2018,4,17,20,8cvqo3,Things You Should Know About Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8cvqo3/things_you_should_know_about_machine_learning/,fullstackanalytics1,1523963846,,0,1
997,2018-4-17,2018,4,17,20,8cvszn,Predicting the failures paradox,https://www.reddit.com/r/MachineLearning/comments/8cvszn/predicting_the_failures_paradox/,serkef-,1523964567,[removed],0,1
998,2018-4-17,2018,4,17,20,8cvtzw,Text2Colors: Guiding Image Colorization through Text-Driven Palette Generation [github link],https://www.reddit.com/r/MachineLearning/comments/8cvtzw/text2colors_guiding_image_colorization_through/,heykeetae,1523964898,,0,1
999,2018-4-17,2018,4,17,20,8cvuda,Machine Learning on KubernetesApril 2018 updates,https://www.reddit.com/r/MachineLearning/comments/8cvuda/machine_learning_on_kubernetesapril_2018_updates/,mhausenblas,1523965015,,0,1
1000,2018-4-17,2018,4,17,20,8cvvch,[N] DimensionalMechanics Launches NML 2.0: A Pioneering Programming Language for AI and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8cvvch/n_dimensionalmechanics_launches_nml_20_a/,molode,1523965331,,0,1
1001,2018-4-17,2018,4,17,20,8cvwel,What's up with [JMLR]( http://www.jmlr.org )?,https://www.reddit.com/r/MachineLearning/comments/8cvwel/whats_up_with_jmlr_httpwwwjmlrorg/,singularineet,1523965653,[removed],0,1
1002,2018-4-17,2018,4,17,20,8cvxfb,[R] Bringing Computer Vision Datasets to a Single Format: Step towards Consistency,https://www.reddit.com/r/MachineLearning/comments/8cvxfb/r_bringing_computer_vision_datasets_to_a_single/,magneticono,1523965962,,0,1
1003,2018-4-17,2018,4,17,21,8cvzd0,French Fries Making Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/8cvzd0/french_fries_making_machine_for_sale/,lgsherry,1523966541,,1,1
1004,2018-4-17,2018,4,17,21,8cvziu,"Semantic Experiences - ""Talk to Books"" and Semantris",https://www.reddit.com/r/MachineLearning/comments/8cvziu/semantic_experiences_talk_to_books_and_semantris/,tech_news_man,1523966592,,0,1
1005,2018-4-17,2018,4,17,21,8cw2lg,[D]Should a ML person learn JavaScript?,https://www.reddit.com/r/MachineLearning/comments/8cw2lg/dshould_a_ml_person_learn_javascript/,l0gicbomb,1523967496,"Probably isn't directly useful, but do you find using JS in your projects to give it a web interface? 
Do you find it is useful enough that I should learn it?
Beginner in ML",16,12
1006,2018-4-17,2018,4,17,21,8cw3t3,Lasagne and Keras installation guide,https://www.reddit.com/r/MachineLearning/comments/8cw3t3/lasagne_and_keras_installation_guide/,raul4247,1523967859,[removed],0,1
1007,2018-4-17,2018,4,17,21,8cw6bg,Variable length input vectors for Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8cw6bg/variable_length_input_vectors_for_neural_networks/,s4ndman1,1523968541,[removed],0,1
1008,2018-4-17,2018,4,17,21,8cw6va,[P] Neural Style Transfer: A Review,https://www.reddit.com/r/MachineLearning/comments/8cw6va/p_neural_style_transfer_a_review/,ycjing,1523968693,,0,0
1009,2018-4-17,2018,4,17,21,8cw7u3,[R] Optimizing Video Object Detection via a Scale-Time Lattice,https://www.reddit.com/r/MachineLearning/comments/8cw7u3/r_optimizing_video_object_detection_via_a/,senorstallone,1523968955,,1,4
1010,2018-4-17,2018,4,17,22,8cwfk1,Trouble understanding the algorithm Proximal Policy Optimization (PPO),https://www.reddit.com/r/MachineLearning/comments/8cwfk1/trouble_understanding_the_algorithm_proximal/,ppo_fan,1523970971,[removed],0,1
1011,2018-4-17,2018,4,17,22,8cwgd6,[D] Training ImageNet on a TPU in 12.5 hours with GKE and RiseML,https://www.reddit.com/r/MachineLearning/comments/8cwgd6/d_training_imagenet_on_a_tpu_in_125_hours_with/,henningpeters,1523971174,,0,3
1012,2018-4-17,2018,4,17,22,8cwhe2,[Project] Working with StarCraft II AIs on Google's free Google Colab Environment,https://www.reddit.com/r/MachineLearning/comments/8cwhe2/project_working_with_starcraft_ii_ais_on_googles/,FrozenXZeus,1523971446,,23,190
1013,2018-4-17,2018,4,17,22,8cwnt8,[D] Seq2Seq - Is it possible to output multiple predictions from a multi-layer LSTM network?,https://www.reddit.com/r/MachineLearning/comments/8cwnt8/d_seq2seq_is_it_possible_to_output_multiple/,hoody8,1523973012,"I'm building a predictive text input system where multiple candidate phrases are displayed for the next word the user will likely input (like the predictive input on a phone keyboard).

To tackle this problem I've used the Seq2Seq approach with an LSTM neural net, but the model will only give 1 output sequence for a given input sequence. Is it possible to output multiple sequences, ranked by probability, from a multi-layer LSTM?

I've thought about implementing beam search, but I'm not sure how/if this could retain multiple sequences in the output layer. Would be great to know what you guys think!",3,1
1014,2018-4-17,2018,4,17,22,8cwoa6,[N] Deep|Bayes Summer School  Application deadline in 2 weeks,https://www.reddit.com/r/MachineLearning/comments/8cwoa6/n_deepbayes_summer_school_application_deadline_in/,asobolev,1523973143,,0,2
1015,2018-4-17,2018,4,17,23,8cwsnj,[D] Implementing a variable length input vectors for Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8cwsnj/d_implementing_a_variable_length_input_vectors/,s4ndman1,1523974205,"Hi there

I saw a post of some time ago where somebody wanted to make use of variable length input vectors where the input would represent the pixels of multiple pictures and the resolution of the pictures would change thus the input. 

It seems a bit impossible as removing, changing or adding input nodes makes an impact on the network it self as weights and biases would have to be readjusted. I am doing research about this topic so if you have any insights or interesting papers to read it would be appreciated. 

What do you think ? Would the impact of removing or adding one input node on a relatively small network make a huge impact ? If you keep memory of previous input nodes and place them back into the network after a few time steps would it worsen or better the network ? ",2,6
1016,2018-4-17,2018,4,17,23,8cwukf,[P] voice vector: Which of the Hollywood stars is most similar to my voice?,https://www.reddit.com/r/MachineLearning/comments/8cwukf/p_voice_vector_which_of_the_hollywood_stars_is/,[deleted],1523974631,[deleted],0,1
1017,2018-4-17,2018,4,17,23,8cwv6l,[P] Voice Vector: Which of the Hollywood stars is most similar to my voice?,https://www.reddit.com/r/MachineLearning/comments/8cwv6l/p_voice_vector_which_of_the_hollywood_stars_is/,andabi,1523974766,,0,1
1018,2018-4-17,2018,4,17,23,8cwvba,Trying all different types of models and architectures through trial and error automatically,https://www.reddit.com/r/MachineLearning/comments/8cwvba/trying_all_different_types_of_models_and/,gagejustins,1523974793,[removed],0,1
1019,2018-4-17,2018,4,17,23,8cwyt3,[D] Swift for TensorFlow - a simulation,https://www.reddit.com/r/MachineLearning/comments/8cwyt3/d_swift_for_tensorflow_a_simulation/,jamesonatfritz,1523975606,,1,24
1020,2018-4-17,2018,4,17,23,8cwzsc,[D] Deep Learning using C,https://www.reddit.com/r/MachineLearning/comments/8cwzsc/d_deep_learning_using_c/,Caerbanoob,1523975825,"Hello guys,

Usually I use Tensorflow or Pytorch and do some fancy non sequential stuff. For one project I need to integrate a deep learner into some C code (an old legacy thing that only speak C).

Do you have some ressources (documentation or tutorial) for DNN libraries in C? If you did that before, what is your return of experience?

Cheer!",6,6
1021,2018-4-17,2018,4,17,23,8cx0ks,"[D] Is Data-Driven AI Brainwashing us all, or is it Just the Same as Good ol' Marketing?  Skynet Today",https://www.reddit.com/r/MachineLearning/comments/8cx0ks/d_is_datadriven_ai_brainwashing_us_all_or_is_it/,sksq9,1523976003,,2,19
1022,2018-4-18,2018,4,18,0,8cx7wv,[D] Text Embedding Models Contain Bias. Here's Why That Matters.,https://www.reddit.com/r/MachineLearning/comments/8cx7wv/d_text_embedding_models_contain_bias_heres_why/,julian88888888,1523977571,,2,12
1023,2018-4-18,2018,4,18,0,8cxdlo,Practical Machine Learning Project and DataOps  Part 1: Training Data,https://www.reddit.com/r/MachineLearning/comments/8cxdlo/practical_machine_learning_project_and_dataops/,AllergicToDinosaurs,1523978786,,0,1
1024,2018-4-18,2018,4,18,0,8cxmwn,"[R] Recurrent Neural Networks for Multivariate Time Series with Missing Values (Nature, Open Access PDF)",https://www.reddit.com/r/MachineLearning/comments/8cxmwn/r_recurrent_neural_networks_for_multivariate_time/,baylearn,1523980761,,9,28
1025,2018-4-18,2018,4,18,1,8cxrj8,[P] Neural Machine Translation with Transformer model library in Keras,https://www.reddit.com/r/MachineLearning/comments/8cxrj8/p_neural_machine_translation_with_transformer/,mx0100,1523981718,,0,3
1026,2018-4-18,2018,4,18,1,8cxshv,"[R] PathNet &amp; Beyond  Chrisantha Fernando, DeepMind (reusing NN for multiple tasks; a step towards AGI)",https://www.reddit.com/r/MachineLearning/comments/8cxshv/r_pathnet_beyond_chrisantha_fernando_deepmind/,valdanylchuk,1523981922,,2,0
1027,2018-4-18,2018,4,18,1,8cxtj5,[D] How to implement a neural network to generate a permutation-invariant set of samples?,https://www.reddit.com/r/MachineLearning/comments/8cxtj5/d_how_to_implement_a_neural_network_to_generate_a/,stegben,1523982149,"Say, a model that inputs an image could output several images. The number of output images is variable, and the order is not important.",5,1
1028,2018-4-18,2018,4,18,1,8cxutu,[P] Which of the Hollywood stars is most similar to my voice?,https://www.reddit.com/r/MachineLearning/comments/8cxutu/p_which_of_the_hollywood_stars_is_most_similar_to/,andabi,1523982436,,4,12
1029,2018-4-18,2018,4,18,1,8cy0bn,"[P] Recurrent Neural Network Tutorial for Artists (Javascript, p5.js)",https://www.reddit.com/r/MachineLearning/comments/8cy0bn/p_recurrent_neural_network_tutorial_for_artists/,inarrears,1523983608,,0,20
1030,2018-4-18,2018,4,18,2,8cyaoj,Actor Critic as Generalized or Approximate Policy Iteration,https://www.reddit.com/r/MachineLearning/comments/8cyaoj/actor_critic_as_generalized_or_approximate_policy/,AlphSai1996,1523985796,[removed],0,1
1031,2018-4-18,2018,4,18,2,8cyfrp,Cross-post: An Introduction to Hashing in the Era of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8cyfrp/crosspost_an_introduction_to_hashing_in_the_era/,teb311,1523986858,,0,1
1032,2018-4-18,2018,4,18,2,8cyiu5,What are the topics that are not currently relevant and what are other topics that needs to be added to this learning journey?[X-Post from r/learnmachinelearning],https://www.reddit.com/r/MachineLearning/comments/8cyiu5/what_are_the_topics_that_are_not_currently/,skinni_stick,1523987490,[removed],0,1
1033,2018-4-18,2018,4,18,2,8cykyb,who uses NLTK in production?,https://www.reddit.com/r/MachineLearning/comments/8cykyb/who_uses_nltk_in_production/,PullThisFinger,1523987936,[removed],0,1
1034,2018-4-18,2018,4,18,3,8cysrx,[D] What are the state-of-the-art models for identifying objects in photos?,https://www.reddit.com/r/MachineLearning/comments/8cysrx/d_what_are_the_stateoftheart_models_for/,3vvok,1523989571,"From my observations and little experience it appears that most of the ML project are about classifying stuff. Is there cancer signs on the photo? Does the picture show car, whale or banana? Etc. 
I need to implement a model for face identification. Not detection/recognition, but identification: having two different photos of the same person, my model should determine if the same person is in the picture. 
I want to achieve that using Tensorflow with convolutional nets. I've read this paper: http://ydwen.github.io/papers/WenECCV16.pdf and center loss looks promising. What do you think about that? Are there any new ideas/papers/implementations regarding that problem that are worth attention?",4,0
1035,2018-4-18,2018,4,18,3,8cysyn,Rebuilding Deepdrive on Unreal Engine,https://www.reddit.com/r/MachineLearning/comments/8cysyn/rebuilding_deepdrive_on_unreal_engine/,aiworld,1523989608,,0,1
1036,2018-4-18,2018,4,18,3,8cyttn,[D] Adding new images to data set - retraining ConvNet,https://www.reddit.com/r/MachineLearning/comments/8cyttn/d_adding_new_images_to_data_set_retraining_convnet/,ME_PhD,1523989792,"If I train a CNN and later I gather more labeled images, how do I further train the CNN to include the new data? Could I make a new training set with say 50/50 new/old images and train further, or what's the best practice?",5,0
1037,2018-4-18,2018,4,18,3,8cyz8p,World Models - Jurgen Schmidhuber,https://www.reddit.com/r/MachineLearning/comments/8cyz8p/world_models_jurgen_schmidhuber/,NMcA,1523990911,,0,1
1038,2018-4-18,2018,4,18,3,8cyzx0,"2018 Big Data Trends Report - How Companies are Adopting Data Mining, ML and Cloud Technologies",https://www.reddit.com/r/MachineLearning/comments/8cyzx0/2018_big_data_trends_report_how_companies_are/,younggrindin,1523991060,,0,1
1039,2018-4-18,2018,4,18,4,8czc8y,Instructable for a Matchbox Chess Machine that i made a while back (weekend project),https://www.reddit.com/r/MachineLearning/comments/8czc8y/instructable_for_a_matchbox_chess_machine_that_i/,karmapringle,1523993645,,0,2
1040,2018-4-18,2018,4,18,4,8czjho,Multiple solutions from backpropagation,https://www.reddit.com/r/MachineLearning/comments/8czjho/multiple_solutions_from_backpropagation/,soum16,1523995169,[removed],0,1
1041,2018-4-18,2018,4,18,5,8czqbr,Question About Transformer (Attention is All You Need),https://www.reddit.com/r/MachineLearning/comments/8czqbr/question_about_transformer_attention_is_all_you/,modx07,1523996608,[removed],0,1
1042,2018-4-18,2018,4,18,6,8d05kx,The Batch Normalization layer of Keras is broken,https://www.reddit.com/r/MachineLearning/comments/8d05kx/the_batch_normalization_layer_of_keras_is_broken/,datumbox,1523999914,,0,1
1043,2018-4-18,2018,4,18,6,8d097v,Searching the entire solution space,https://www.reddit.com/r/MachineLearning/comments/8d097v/searching_the_entire_solution_space/,Stone_d_,1524000703,[removed],0,1
1044,2018-4-18,2018,4,18,6,8d0fo3,How to get Blizzard &amp; Google Deepminds PySc2 working for free on Colabs,https://www.reddit.com/r/MachineLearning/comments/8d0fo3/how_to_get_blizzard_google_deepminds_pysc2/,sigmoidp,1524002205,,1,1
1045,2018-4-18,2018,4,18,7,8d0mdx,[D] Question: what is the easiest way to use imagenet?,https://www.reddit.com/r/MachineLearning/comments/8d0mdx/d_question_what_is_the_easiest_way_to_use_imagenet/,itsmerandymarch,1524003749,"I have a CNN written in pytorch and I would like to use imagenet for training. 

I have downloaded the files (memory and time are not an issue) but soon realized that there's a lot more to do before being able to actually use them.

First, the bounding boxes available in the version I have include only a subset of all the pictures. For each class there are 1300 pictures for training, but (at least for some of the classes that I've checked) the number of bounding boxes per class is between 400 and 1000. Not to mention that some of the pictures are already smaller than 224x224 so I'm still not sure how those can be cropped.

I know that there's a tensorflow script to handle all the pictures but it converts them to TFrecords and I'd like to save the cropped pictures and view them.

I only need a subset of imagenet (let's say around 20 classes, each with around 1000 pictures for training and 1000 for testing)

It feels like someone must have done that before me and I was wondering if anyone came across a dataset saved somewhere that is already cropped and includes the final images.

I also noticed that I can download the URLs instead of the images themselves. Does anyone know where can I download the 224x224 bounding boxes for the URL images?

Any suggestions to make this process easier? Are there any other large datasets that I can use instead?",0,0
1046,2018-4-18,2018,4,18,7,8d0okb,[N] MITs Josh Tenenbaum on Intuitive Physics &amp; Psychology in AI,https://www.reddit.com/r/MachineLearning/comments/8d0okb/n_mits_josh_tenenbaum_on_intuitive_physics/,gwen0927,1524004259,,0,1
1047,2018-4-18,2018,4,18,7,8d0r2v,Bringing Light to Dark Data,https://www.reddit.com/r/MachineLearning/comments/8d0r2v/bringing_light_to_dark_data/,alexa_y,1524004870,,0,1
1048,2018-4-18,2018,4,18,7,8d0r3e,Digit Detection From Images,https://www.reddit.com/r/MachineLearning/comments/8d0r3e/digit_detection_from_images/,shomerj,1524004872,[removed],0,1
1049,2018-4-18,2018,4,18,7,8d0sjy,[Project] Using Decision Trees to Identify White Nationalists,https://www.reddit.com/r/MachineLearning/comments/8d0sjy/project_using_decision_trees_to_identify_white/,DataJenius,1524005216,,0,0
1050,2018-4-18,2018,4,18,7,8d0uxp,Reddit! What's your favorite ML dataset?,https://www.reddit.com/r/MachineLearning/comments/8d0uxp/reddit_whats_your_favorite_ml_dataset/,[deleted],1524005805,[deleted],0,1
1051,2018-4-18,2018,4,18,9,8d1auu,"[D] A step-by-step walkthrough (with Keras implementation) of @hardmaru &amp; Juergen's ""World Models"" paper",https://www.reddit.com/r/MachineLearning/comments/8d1auu/d_a_stepbystep_walkthrough_with_keras/,sksq9,1524009661,,6,37
1052,2018-4-18,2018,4,18,9,8d1jhq,[Project] We built this Not Hotdog app in 30min,https://www.reddit.com/r/MachineLearning/comments/8d1jhq/project_we_built_this_not_hotdog_app_in_30min/,adserena,1524011687,,2,0
1053,2018-4-18,2018,4,18,10,8d1svi,Reddit! What is your favorite ML dataset?,https://www.reddit.com/r/MachineLearning/comments/8d1svi/reddit_what_is_your_favorite_ml_dataset/,thegoldcase,1524014073,,0,1
1054,2018-4-18,2018,4,18,10,8d1yrt,What other special processing can the bending machine apply to besides bending,https://www.reddit.com/r/MachineLearning/comments/8d1yrt/what_other_special_processing_can_the_bending/,gldmachina,1524015616,,0,1
1055,2018-4-18,2018,4,18,12,8d2k14,Any public datasets for visual information extraction?,https://www.reddit.com/r/MachineLearning/comments/8d2k14/any_public_datasets_for_visual_information/,jiangfeng1124,1524021364,[removed],0,1
1056,2018-4-18,2018,4,18,12,8d2o5h,[R] Google TPUs tested: DAWN Deep Learning Benchmark,https://www.reddit.com/r/MachineLearning/comments/8d2o5h/r_google_tpus_tested_dawn_deep_learning_benchmark/,downtownslim,1524022552,,9,30
1057,2018-4-18,2018,4,18,14,8d388w,[R] Human-to-Anime portraits using TwinGAN,https://www.reddit.com/r/MachineLearning/comments/8d388w/r_humantoanime_portraits_using_twingan/,jerryli27,1524028828,,65,477
1058,2018-4-18,2018,4,18,14,8d38kp,[D] A New Weapon in the Fight Against Shoddy Statistics - Distance Correlation,https://www.reddit.com/r/MachineLearning/comments/8d38kp/d_a_new_weapon_in_the_fight_against_shoddy/,sugarhilldt2,1524028950,,4,4
1059,2018-4-18,2018,4,18,14,8d3ep6,Tips for finding medical image databases,https://www.reddit.com/r/MachineLearning/comments/8d3ep6/tips_for_finding_medical_image_databases/,FrankStevens5000,1524030954,[removed],0,1
1060,2018-4-18,2018,4,18,15,8d3i1k,"[D] Google Inc. patents ""Processing Sequences Using Convolutional Neural Networks""",https://www.reddit.com/r/MachineLearning/comments/8d3i1k/d_google_inc_patents_processing_sequences_using/,wei_jok,1524032136,,50,96
1061,2018-4-18,2018,4,18,15,8d3i5j,How Can Machine Learning Revamp Your Mobile App?,https://www.reddit.com/r/MachineLearning/comments/8d3i5j/how_can_machine_learning_revamp_your_mobile_app/,DariaAdvisor,1524032176,,0,1
1062,2018-4-18,2018,4,18,16,8d3qms,What are some open problems yet to be solved in Computer Vision?,https://www.reddit.com/r/MachineLearning/comments/8d3qms/what_are_some_open_problems_yet_to_be_solved_in/,fortu1tus,1524035269,[removed],0,1
1063,2018-4-18,2018,4,18,16,8d3u12,Latest Embroidery machines,https://www.reddit.com/r/MachineLearning/comments/8d3u12/latest_embroidery_machines/,psmccouk,1524036560,,0,1
1064,2018-4-18,2018,4,18,17,8d3yt0,[P] Evaluation infrastructure for adversarial competition,https://www.reddit.com/r/MachineLearning/comments/8d3yt0/p_evaluation_infrastructure_for_adversarial/,adjposs,1524038414,,0,4
1065,2018-4-18,2018,4,18,17,8d3zdn,NEAT aa in Unity Tutorial | Part 1: Introduction,https://www.reddit.com/r/MachineLearning/comments/8d3zdn/neat_aa_in_unity_tutorial_part_1_introduction/,Nimblephile,1524038627,,0,1
1066,2018-4-18,2018,4,18,18,8d4bgd,AI Accelerator by China's biggest online retailer.,https://www.reddit.com/r/MachineLearning/comments/8d4bgd/ai_accelerator_by_chinas_biggest_online_retailer/,_JDAI_,1524043406,,0,1
1067,2018-4-18,2018,4,18,19,8d4j2p,bobcat repair manual,https://www.reddit.com/r/MachineLearning/comments/8d4j2p/bobcat_repair_manual/,Mypremiummanual,1524046330,,0,1
1068,2018-4-18,2018,4,18,19,8d4py9,Networks that generate tracklets tracklets directly for multiple targets?,https://www.reddit.com/r/MachineLearning/comments/8d4py9/networks_that_generate_tracklets_tracklets/,Dagusiu,1524048853,[removed],0,1
1069,2018-4-18,2018,4,18,19,8d4qe7,How Machine Learning is benefitting big data analytics?,https://www.reddit.com/r/MachineLearning/comments/8d4qe7/how_machine_learning_is_benefitting_big_data/,smadrid056,1524049010,,0,1
1070,2018-4-18,2018,4,18,20,8d4rl7,[D] Data Augmentation | How to use Deep Learning when you have Limited Data  Part 2,https://www.reddit.com/r/MachineLearning/comments/8d4rl7/d_data_augmentation_how_to_use_deep_learning_when/,tzuchinc,1524049409,,4,8
1071,2018-4-18,2018,4,18,20,8d4rs1,MIT Artificial Intelligence 'RoadTracer' Can Map Out Roads More Efficiently Than Humans,https://www.reddit.com/r/MachineLearning/comments/8d4rs1/mit_artificial_intelligence_roadtracer_can_map/,theslt,1524049475,,0,1
1072,2018-4-18,2018,4,18,20,8d4trv,[R] The Model Performance Mismatch Problem (and what to do about it),https://www.reddit.com/r/MachineLearning/comments/8d4trv/r_the_model_performance_mismatch_problem_and_what/,trumtra,1524050141,,0,1
1073,2018-4-18,2018,4,18,21,8d58d5,"[P] Simple GUI app to collect mouse X,Y data for modelling or analysis",https://www.reddit.com/r/MachineLearning/comments/8d58d5/p_simple_gui_app_to_collect_mouse_xy_data_for/,tfburns,1524054552,,0,6
1074,2018-4-18,2018,4,18,21,8d5c9j,Need help - a fun little project turned complicated,https://www.reddit.com/r/MachineLearning/comments/8d5c9j/need_help_a_fun_little_project_turned_complicated/,MinecrafTech,1524055627,[removed],0,1
1075,2018-4-18,2018,4,18,22,8d5h7f,why theta(1)=0 in regularization?,https://www.reddit.com/r/MachineLearning/comments/8d5h7f/why_theta10_in_regularization/,mohitduklan,1524056892,[removed],0,1
1076,2018-4-18,2018,4,18,22,8d5jfw,Will multi class ml algo like fasttext work for multi label dataset?,https://www.reddit.com/r/MachineLearning/comments/8d5jfw/will_multi_class_ml_algo_like_fasttext_work_for/,midnitekoder,1524057441,[removed],0,1
1077,2018-4-18,2018,4,18,23,8d5uqi,NEAT aa in Unity Tutorial | Part 2: Setting Up The Scene,https://www.reddit.com/r/MachineLearning/comments/8d5uqi/neat_aa_in_unity_tutorial_part_2_setting_up_the/,Nimblephile,1524060283,,0,1
1078,2018-4-18,2018,4,18,23,8d61qg,[D] Visualizing Model Free Prediction in Reinforcement Learning.,https://www.reddit.com/r/MachineLearning/comments/8d61qg/d_visualizing_model_free_prediction_in/,jaleyhd,1524061893,,0,1
1079,2018-4-18,2018,4,18,23,8d62xs,[News] Microsoft Releases LightGBM on Apache Spark,https://www.reddit.com/r/MachineLearning/comments/8d62xs/news_microsoft_releases_lightgbm_on_apache_spark/,mhamilton723,1524062154,,2,26
1080,2018-4-18,2018,4,18,23,8d64mm,[Discussion] Jupyter Notebooks Can't Fix the Scientific Paper,https://www.reddit.com/r/MachineLearning/comments/8d64mm/discussion_jupyter_notebooks_cant_fix_the/,OliverOnTheWeb,1524062532,,3,4
1081,2018-4-18,2018,4,18,23,8d674t,A Mathematical Framework for Superintelligent Machines,https://www.reddit.com/r/MachineLearning/comments/8d674t/a_mathematical_framework_for_superintelligent/,Superintelliscoming,1524063081,[removed],0,1
1082,2018-4-18,2018,4,18,23,8d6859,[R] Learning Awareness Models,https://www.reddit.com/r/MachineLearning/comments/8d6859/r_learning_awareness_models/,Pandoma,1524063305,,3,7
1083,2018-4-19,2018,4,19,0,8d69xb,[R] A Mathematical Framework for Superintelligent Machines,https://www.reddit.com/r/MachineLearning/comments/8d69xb/r_a_mathematical_framework_for_superintelligent/,Superintelliscoming,1524063689,,7,0
1084,2018-4-19,2018,4,19,0,8d6dte,"[D] Olive Oil is Made of Olives, Baby Oil is Made for Babies [Paper Summary]",https://www.reddit.com/r/MachineLearning/comments/8d6dte/d_olive_oil_is_made_of_olives_baby_oil_is_made/,omarsar,1524064492,,8,4
1085,2018-4-19,2018,4,19,0,8d6emi,[Interactive Brokers Webinar] Why is machine learning in finance so hard?,https://www.reddit.com/r/MachineLearning/comments/8d6emi/interactive_brokers_webinar_why_is_machine/,FintechNerd,1524064673,,0,1
1086,2018-4-19,2018,4,19,0,8d6kbl,[R] Shared Autonomy via Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8d6kbl/r_shared_autonomy_via_deep_reinforcement_learning/,gdny,1524065864,,0,13
1087,2018-4-19,2018,4,19,0,8d6phe,"Simple Questions Thread April 18, 2018",https://www.reddit.com/r/MachineLearning/comments/8d6phe/simple_questions_thread_april_18_2018/,AutoModerator,1524066938,[removed],0,1
1088,2018-4-19,2018,4,19,0,8d6pqq,"[D] Terminator Time - New Google Sheets tutorial to teach newbies the intuition behind Convolutional Neural Nets and those scary, red eyes",https://www.reddit.com/r/MachineLearning/comments/8d6pqq/d_terminator_time_new_google_sheets_tutorial_to/,OCData_nerd,1524066990,,0,0
1089,2018-4-19,2018,4,19,0,8d6qhm,"[N] Announcing Luminoth 0.1: new object detection models, checkpoints and more!",https://www.reddit.com/r/MachineLearning/comments/8d6qhm/n_announcing_luminoth_01_new_object_detection/,minmidinosaur,1524067154,,0,5
1090,2018-4-19,2018,4,19,1,8d72cu,[D] Propose new names for NIPS Conference in comments,https://www.reddit.com/r/MachineLearning/comments/8d72cu/d_propose_new_names_for_nips_conference_in/,evc123,1524069633,,90,41
1091,2018-4-19,2018,4,19,1,8d73u0,[D] How Autoencoders Are Used to Swap Faces (and Fruits...),https://www.reddit.com/r/MachineLearning/comments/8d73u0/d_how_autoencoders_are_used_to_swap_faces_and/,AlanZucconi,1524069954,,2,6
1092,2018-4-19,2018,4,19,1,8d74cb,[P] Competitive machine learning at Numerai,https://www.reddit.com/r/MachineLearning/comments/8d74cb/p_competitive_machine_learning_at_numerai/,AllergicToDinosaurs,1524070057,,0,0
1093,2018-4-19,2018,4,19,1,8d74ls,Medical dataset references,https://www.reddit.com/r/MachineLearning/comments/8d74ls/medical_dataset_references/,dnamez_nevin,1524070120,[removed],0,1
1094,2018-4-19,2018,4,19,1,8d77va,Neglected Machine Learning Ideas - Dataconomy,https://www.reddit.com/r/MachineLearning/comments/8d77va/neglected_machine_learning_ideas_dataconomy/,mathmare,1524070793,,0,1
1095,2018-4-19,2018,4,19,2,8d786e,Make an antivirus In just 5 minutes using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8d786e/make_an_antivirus_in_just_5_minutes_using_machine/,sagar03d,1524070857,,0,1
1096,2018-4-19,2018,4,19,2,8d7maz,Replicating Netflix's Video Quality using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8d7maz/replicating_netflixs_video_quality_using_deep/,MutatingNeutrinos,1524073674,,0,1
1097,2018-4-19,2018,4,19,3,8d7pvd,[D] Using Variational Autoencoder for classification,https://www.reddit.com/r/MachineLearning/comments/8d7pvd/d_using_variational_autoencoder_for_classification/,Jeriko_One,1524074429,"I am working on a project to classify a sample dataset but am looking to use a VAE. It has been suggested that I can use the z (mu) output, after training the autoencoder, with a simple neural networks to classify with the validation set.

Could anyone please link me to any examples of the implementation, either from GitHub or other blog post with details, possibly using MNIST or other sample classification dataset?",11,5
1098,2018-4-19,2018,4,19,3,8d7vg3,[R] ShakeDrop Regularization,https://www.reddit.com/r/MachineLearning/comments/8d7vg3/r_shakedrop_regularization/,equinox932,1524075604,,3,0
1099,2018-4-19,2018,4,19,3,8d7y35,Montessorium is trying to use ML to teach kids,https://www.reddit.com/r/MachineLearning/comments/8d7y35/montessorium_is_trying_to_use_ml_to_teach_kids/,darcwader,1524076170,,0,1
1100,2018-4-19,2018,4,19,3,8d83ap,What is the size of posters for ICLR2018?,https://www.reddit.com/r/MachineLearning/comments/8d83ap/what_is_the_size_of_posters_for_iclr2018/,papersilike,1524077248,[removed],0,1
1101,2018-4-19,2018,4,19,4,8d8h2j,IBM Research releases open source Adversarial Robustness Toolkit,https://www.reddit.com/r/MachineLearning/comments/8d8h2j/ibm_research_releases_open_source_adversarial/,inane_blather,1524080155,,0,1
1102,2018-4-19,2018,4,19,5,8d8ylt,How to develop a stock market analytical tool using Shiny and R,https://www.reddit.com/r/MachineLearning/comments/8d8ylt/how_to_develop_a_stock_market_analytical_tool/,[deleted],1524083916,[deleted],0,1
1103,2018-4-19,2018,4,19,5,8d8zl9,"[D] How valid is the ""we don't really understand AI"" statement",https://www.reddit.com/r/MachineLearning/comments/8d8zl9/d_how_valid_is_the_we_dont_really_understand_ai/,veni_vidi_reddit,1524084118,"You could easily have a drinking game where you watch a video about AI and drink every time someone says this. It's never followed with why that is. My gut feeling is that this statement is BS, but I have little to back it up.

I have a CS/Engineering background. I've worked *with* machine learning, but not *on* machine learning (I've taken outputs of algorithms to do things with). So I don't really know what is going on inside the ""black box"", but I know a thing or two about systems. 

The best way I can generalize Machine Learning/AI is:

**""We build a statistical model from a massive sample of data, to figure out what's the best decision given a set of conditions""**

So I understand that we build algorithms that we are not capable of understanding in a modular way (like one would an electric circuit, for example). That doesn't mean we don't understand it, because we very thoroughly understand the process of building this.  One way to think about it is like fluid mechanics. For example:  We can't model the process in a recursively modular way (down to interaction of each molecule), but we understand it by describing it at a larger scale.

So: we do not understand self-learning algorithms on a modular level because they are inherently not fully comprehendable in this way. But we have a pretty good idea how things are working on a macro level.

The statement that ""we don't really understand it"" always seems imply the threat of losing control. Again, I don't really buy that.  You may not fully understand fluid mechanics of bitumen, but there is no question that you can contain it in a pipe (that's a less elegant metaphor but I hope you get what I'm trying to say)


So here's where I'd like some input:

* How would you critique my generalizations above?
* What is the significant difference between machine learning and statistical analysis? What stops us from using the same tools to think about them (from a far enough vantage point)
* Are there concrete examples of mechanisms that we don't understand in ML research? 

	
",19,1
1104,2018-4-19,2018,4,19,6,8d98g1,PMLB - Curated set of benchmark datasets for evaluating and comparing supervised machine learning algorithms,https://www.reddit.com/r/MachineLearning/comments/8d98g1/pmlb_curated_set_of_benchmark_datasets_for/,[deleted],1524085997,[deleted],0,1
1105,2018-4-19,2018,4,19,6,8d98ip,"[P] Reproducing UberAI's ""Deep Neuroevolution"" paper",https://www.reddit.com/r/MachineLearning/comments/8d98ip/p_reproducing_uberais_deep_neuroevolution_paper/,wei_jok,1524086013,,4,16
1106,2018-4-19,2018,4,19,6,8d997r,Charlie is a Cuck,https://www.reddit.com/r/MachineLearning/comments/8d997r/charlie_is_a_cuck/,[deleted],1524086174,,0,1
1107,2018-4-19,2018,4,19,6,8d9boa,[P] PMLB - Curated set of benchmark datasets for evaluating and comparing supervised machine learning algorithms,https://www.reddit.com/r/MachineLearning/comments/8d9boa/p_pmlb_curated_set_of_benchmark_datasets_for/,fariax,1524086732,"Very useful python wrapper that loads the mainly used datasets in order to benchmark ML techniques. 

All data sets are stored in a common format:

* First row is the column names
* Each following row corresponds to one row of the data
* The target column is named target
* All columns are tab (\t) separated
* All files are compressed with gzip to conserve space

Project: https://github.com/EpistasisLab/penn-ml-benchmarks
Paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5725843/",3,8
1108,2018-4-19,2018,4,19,7,8d9m0g,[D] Jeff Bezos's 2018 annual Amazon letter discusses Alexa success and improvements from semi-supervised &amp; transfer learning,https://www.reddit.com/r/MachineLearning/comments/8d9m0g/d_jeff_bezoss_2018_annual_amazon_letter_discusses/,gwern,1524089074,"https://www.sec.gov/Archives/edgar/data/1018724/000119312518121161/d456916dex991.htm 

&gt; *Alexa*  Customer embrace of Alexa continues, with Alexa-enabled devices among the best-selling items across all of Amazon. Were seeing extremely strong adoption by other companies and developers that want to create their own experiences with Alexa. There are now more than 30,000 skills for Alexa from outside developers, and customers can control more than 4,000 smart home devices from 1,200 unique brands with Alexa. The foundations of Alexa continue to get smarter every day too. Weve developed and implemented an on-device fingerprinting technique, which keeps your device from waking up when it hears an Alexa commercial on TV. (This technology ensured that our Alexa Super Bowl commercial didnt wake up millions of devices.) Far-field speech recognition (already very good) has improved by 15% over the last year; and in the U.S., U.K., and Germany, weve improved Alexas spoken language understanding by more than 25% over the last 12 months through enhancements in Alexas machine learning components and the use of semi-supervised learning techniques. (These semi-supervised learning techniques reduced the amount of labeled data needed to achieve the same accuracy improvement by 40 times!) Finally, weve dramatically reduced the amount of time required to teach Alexa new languages by using machine translation and transfer learning techniques, which allows us to serve customers in more countries (like India and Japan).
&gt;
&gt; *Amazon devices*  2017 was our best year yet for hardware sales. Customers bought tens of millions of Echo devices, and Echo Dot and Fire TV Stick with Alexa were the best-selling products across all of Amazon  across all categories and all manufacturers. Customers bought twice as many Fire TV Sticks and Kids Edition Fire Tablets this holiday season versus last year. 2017 marked the release of our all-new Echo with an improved design, better sound, and a lower price; Echo Plus with a built-in smart home hub; and Echo Spot, which is compact and beautiful with a circular screen. We released our next generation Fire TV, featuring 4K Ultra HD and HDR; and the Fire HD 10 Tablet, with 1080p Full HD display. And we celebrated the 10th anniversary of Kindle by releasing the all-new Kindle Oasis, our most advanced reader ever. Its waterproof  take it in the bathtub  with a bigger 7 high-resolution 300 ppi display and has built-in audio so you can also listen to your books with Audible. ",3,0
1109,2018-4-19,2018,4,19,7,8d9p3x,[R] Evolved Policy Gradients,https://www.reddit.com/r/MachineLearning/comments/8d9p3x/r_evolved_policy_gradients/,Kaixhin,1524089797,,6,36
1110,2018-4-19,2018,4,19,8,8da1ke,Training ANN on classes with high inner-class variance,https://www.reddit.com/r/MachineLearning/comments/8da1ke/training_ann_on_classes_with_high_innerclass/,Thomas-K,1524092723,[removed],0,1
1111,2018-4-19,2018,4,19,8,8da364,[N] iMIMIC - Interpretability of Machine Intelligence in Medical Image Computing Workshop @ MICCAI,https://www.reddit.com/r/MachineLearning/comments/8da364/n_imimic_interpretability_of_machine_intelligence/,pereirasrm,1524093100,,0,10
1112,2018-4-19,2018,4,19,9,8daqki,[D] very sobering presentation on the current state of AI by Michael Jordan,https://www.reddit.com/r/MachineLearning/comments/8daqki/d_very_sobering_presentation_on_the_current_state/,elder_price666,1524099021,"https://www.youtube.com/watch?v=4inIBmY8dQI

I think he's a bit too pessimistic/dismissive, but a very sobering presentation nonetheless. Wonder how someone like Hinton would respond to this.",107,221
1113,2018-4-19,2018,4,19,10,8db5bj,[R] Controllable Generative Adversarial Network,https://www.reddit.com/r/MachineLearning/comments/8db5bj/r_controllable_generative_adversarial_network/,CoinflippingMaster,1524102912,,0,1
1114,2018-4-19,2018,4,19,10,8db5fd,A hypothetical AI for segregating responses based on individual stimuli,https://www.reddit.com/r/MachineLearning/comments/8db5fd/a_hypothetical_ai_for_segregating_responses_based/,sachinrjoglekar,1524102939,,0,1
1115,2018-4-19,2018,4,19,11,8dbj37,[R] CREPE: A Convolutional Representation for Pitch Estimation,https://www.reddit.com/r/MachineLearning/comments/8dbj37/r_crepe_a_convolutional_representation_for_pitch/,breandan,1524106649,,3,6
1116,2018-4-19,2018,4,19,12,8dbjpb,"Christopher Manning - ""Building Neural Network Models That Can Reason""",https://www.reddit.com/r/MachineLearning/comments/8dbjpb/christopher_manning_building_neural_network/,aavaas,1524106818,,0,1
1117,2018-4-19,2018,4,19,12,8dbp4d,[R] Fine-tuned noise: anisotropy and the dynamics of SGD,https://www.reddit.com/r/MachineLearning/comments/8dbp4d/r_finetuned_noise_anisotropy_and_the_dynamics_of/,noahgolm,1524108352,,0,10
1118,2018-4-19,2018,4,19,12,8dbrgw,[R] Controllable Generative Adversarial Network,https://www.reddit.com/r/MachineLearning/comments/8dbrgw/r_controllable_generative_adversarial_network/,CoinflippingMaster,1524109045,,1,6
1119,2018-4-19,2018,4,19,12,8dbvfz,Jelly Stick Packing Machine with 4 Sides Sealing,https://www.reddit.com/r/MachineLearning/comments/8dbvfz/jelly_stick_packing_machine_with_4_sides_sealing/,lgsherry,1524110244,,1,1
1120,2018-4-19,2018,4,19,13,8dc4s9,[D] Executing gradient descent on the earth,https://www.reddit.com/r/MachineLearning/comments/8dc4s9/d_executing_gradient_descent_on_the_earth/,baylearn,1524113117,,12,79
1121,2018-4-19,2018,4,19,13,8dc6re,Tooder: Smart flashcards for curious kids,https://www.reddit.com/r/MachineLearning/comments/8dc6re/tooder_smart_flashcards_for_curious_kids/,dowhatyouulove,1524113753,[removed],0,1
1122,2018-4-19,2018,4,19,14,8dcay7,Machine Learning courses that don't rely on frameworks?,https://www.reddit.com/r/MachineLearning/comments/8dcay7/machine_learning_courses_that_dont_rely_on/,deeplearner93,1524115130,[removed],0,1
1123,2018-4-19,2018,4,19,15,8dclr9,Bo qun thc phm trong t mt trng by thc phm nh th no?,https://www.reddit.com/r/MachineLearning/comments/8dclr9/bo_qun_thc_phm_trong_t_mt_trng_by_thc/,tumatsieuthi,1524118919,,0,1
1124,2018-4-19,2018,4,19,15,8dcmhx,[D] Artificial Intelligence  The Revolution Hasnt Happened Yet (Michael Jordan),https://www.reddit.com/r/MachineLearning/comments/8dcmhx/d_artificial_intelligence_the_revolution_hasnt/,chisai_mikan,1524119211,,34,83
1125,2018-4-19,2018,4,19,18,8dddi7,What is the difference between loss and metrics used in machine learning?,https://www.reddit.com/r/MachineLearning/comments/8dddi7/what_is_the_difference_between_loss_and_metrics/,mr_meeesix,1524129974,[removed],0,1
1126,2018-4-19,2018,4,19,19,8ddjaq,What is The Easiest Way To Learn Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8ddjaq/what_is_the_easiest_way_to_learn_machine_learning/,imarticus_nirmal,1524132253,,0,1
1127,2018-4-19,2018,4,19,19,8ddq5q,Leela Chess Zero - The public collaborative project chess AI - Better then Alpha Zero,https://www.reddit.com/r/MachineLearning/comments/8ddq5q/leela_chess_zero_the_public_collaborative_project/,[deleted],1524134786,[deleted],0,1
1128,2018-4-19,2018,4,19,19,8dds6b,How to Start a Career in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8dds6b/how_to_start_a_career_in_machine_learning/,imarticus_nirmal,1524135531,,0,1
1129,2018-4-19,2018,4,19,20,8ddt05,Renko brick size optimization,https://www.reddit.com/r/MachineLearning/comments/8ddt05/renko_brick_size_optimization/,lamres,1524135803,,0,1
1130,2018-4-19,2018,4,19,20,8ddtrw,[P] Leela Chess Zero - The public collaborative project chess AI,https://www.reddit.com/r/MachineLearning/comments/8ddtrw/p_leela_chess_zero_the_public_collaborative/,DrWhatNoName,1524136076,,5,12
1131,2018-4-19,2018,4,19,20,8ddvld,[P] Korean TTS Model: what is the best Hangul processing strategy for Korean speech synthesis?,https://www.reddit.com/r/MachineLearning/comments/8ddvld/p_korean_tts_model_what_is_the_best_hangul/,longinglove,1524136680,,0,8
1132,2018-4-19,2018,4,19,20,8ddvyh,[P] Machine Learning App: How to Implement AI and ML Into Your App,https://www.reddit.com/r/MachineLearning/comments/8ddvyh/p_machine_learning_app_how_to_implement_ai_and_ml/,chris_shpak,1524136795,,0,1
1133,2018-4-19,2018,4,19,20,8ddx0s,[R] Text Classification using machine learning,https://www.reddit.com/r/MachineLearning/comments/8ddx0s/r_text_classification_using_machine_learning/,dearpetra,1524137138,,0,1
1134,2018-4-19,2018,4,19,20,8ddyez,AI based movies recommendations,https://www.reddit.com/r/MachineLearning/comments/8ddyez/ai_based_movies_recommendations/,alta1r,1524137578,,0,1
1135,2018-4-19,2018,4,19,20,8ddykv,[R] Machine Learnings Amazing Ability to Predict Chaos,https://www.reddit.com/r/MachineLearning/comments/8ddykv/r_machine_learnings_amazing_ability_to_predict/,eleitl,1524137636,,49,219
1136,2018-4-19,2018,4,19,20,8ddza9,"[N] The Future of Work is Now: AI Helps Job Hunters Find, Land, &amp; Keep Dream Jobs",https://www.reddit.com/r/MachineLearning/comments/8ddza9/n_the_future_of_work_is_now_ai_helps_job_hunters/,magneticono,1524137862,,0,1
1137,2018-4-19,2018,4,19,20,8de0ij,[D] Are neural networks really capable of learning only one task?,https://www.reddit.com/r/MachineLearning/comments/8de0ij/d_are_neural_networks_really_capable_of_learning/,ghosts_in_the_code,1524138254,"First of all I'm new to this subreddit so if my random doubts/theories don't belong here, please direct me to anywhere they do belong.

Neural networks are not yet [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence) because they are good for learning a specific task rather than multiple diverse tasks.

But is that a flaw in the neural network model or simply the fact that we are not training neural networks to diversify their skills? Maybe if we taught the same neural network to recognise cars in images for some time, then train it to recognise aeroplanes for instance, then maybe switch back to the first task, then the second, so on and so forth ... maybe the neural network will eventually become good at the both the tasks.

Initially when the neural network switches from one task to the other it will take a significant amount of time to unlearn its knowledge on cars while simultaneously learning what aeroplanes are. We provide the neural network enough time to do so. But as we keep switching the tasks, the neural network might learn to remember both the car and the aeroplane at the same time.

If we take this idea to another level, we could potentially teach the same neural network hundreds of tasks given enough training time and sample data. Pretty much the difference between teaching a young kid just chess for the rest of his life, and teaching language, arithmetic, science and social skills altogether at the same pace.

Is there any evidence for or against this theory?",12,0
1138,2018-4-19,2018,4,19,21,8de3th,What do you think about this Machine Learning experiment?,https://www.reddit.com/r/MachineLearning/comments/8de3th/what_do_you_think_about_this_machine_learning/,Maxnewsite,1524139288,,0,1
1139,2018-4-19,2018,4,19,21,8de7nl,Trouble using ML for your business? Fill a 1 min form for a 30 min free consulting session,https://www.reddit.com/r/MachineLearning/comments/8de7nl/trouble_using_ml_for_your_business_fill_a_1_min/,harshsikka123,1524140417,,1,2
1140,2018-4-19,2018,4,19,22,8deism,[N] IBM Research open sources toolkit for deep learning security,https://www.reddit.com/r/MachineLearning/comments/8deism/n_ibm_research_open_sources_toolkit_for_deep/,inane_blather,1524143515,,0,51
1141,2018-4-19,2018,4,19,22,8dek15,[R] [1804.06094] Sparse Unsupervised Capsules Generalize Better,https://www.reddit.com/r/MachineLearning/comments/8dek15/r_180406094_sparse_unsupervised_capsules/,fergbyrne,1524143852,,3,16
1142,2018-4-19,2018,4,19,22,8denv4,"Is it legal to use images that are ""for research purposes only"" to build a model, then use that is used for commercial purposes?",https://www.reddit.com/r/MachineLearning/comments/8denv4/is_it_legal_to_use_images_that_are_for_research/,[deleted],1524144814,,0,1
1143,2018-4-19,2018,4,19,22,8deqgf,"Is it legal to use images that are ""for research purposes only"" to build a model, then use that model for commercial purposes?",https://www.reddit.com/r/MachineLearning/comments/8deqgf/is_it_legal_to_use_images_that_are_for_research/,Mackelday,1524145478,[removed],0,1
1144,2018-4-19,2018,4,19,22,8detnv,How to optimise your Starcraft Machine Learning model for Google Colaboratory,https://www.reddit.com/r/MachineLearning/comments/8detnv/how_to_optimise_your_starcraft_machine_learning/,sigmoidp,1524146269,,0,1
1145,2018-4-19,2018,4,19,23,8df17u,"[N] Weekly Machine Learning Opensource Roundup  Apr. 19, 2018",https://www.reddit.com/r/MachineLearning/comments/8df17u/n_weekly_machine_learning_opensource_roundup_apr/,stkim1,1524148020,,0,1
1146,2018-4-19,2018,4,19,23,8df6q8,"How Deep Learning works, maybe",https://www.reddit.com/r/MachineLearning/comments/8df6q8/how_deep_learning_works_maybe/,[deleted],1524149264,[deleted],0,1
1147,2018-4-19,2018,4,19,23,8df9fk,"How Deep Learning Works, Maybe",https://www.reddit.com/r/MachineLearning/comments/8df9fk/how_deep_learning_works_maybe/,chclau,1524149909,,0,1
1148,2018-4-20,2018,4,20,0,8dfaqx,The state of SageMaker: It's a work in progress.,https://www.reddit.com/r/MachineLearning/comments/8dfaqx/the_state_of_sagemaker_its_a_work_in_progress/,mikejet,1524150190,,0,3
1149,2018-4-20,2018,4,20,0,8dfjmz,Ep 14 INSTAGRAM: #socialmedia #coworking,https://www.reddit.com/r/MachineLearning/comments/8dfjmz/ep_14_instagram_socialmedia_coworking/,MLcoworking,1524152090,,1,1
1150,2018-4-20,2018,4,20,0,8dfllv,"I haven't seen anyone discuss how eerily creepy Google's new experimental AI, TalkToBooks, is... especially when you try talking to it about something other than books",https://www.reddit.com/r/MachineLearning/comments/8dfllv/i_havent_seen_anyone_discuss_how_eerily_creepy/,Vanilla_Buddha,1524152526,,0,1
1151,2018-4-20,2018,4,20,1,8dftfm,Convolutional LSTM Question,https://www.reddit.com/r/MachineLearning/comments/8dftfm/convolutional_lstm_question/,soulslicer0,1524154192,[removed],1,1
1152,2018-4-20,2018,4,20,1,8dg1l9,[N] Cambridge Analytica AI Residency Program,https://www.reddit.com/r/MachineLearning/comments/8dg1l9/n_cambridge_analytica_ai_residency_program/,[deleted],1524155944,[deleted],1,1
1153,2018-4-20,2018,4,20,1,8dg2ox,[N] Cambridge Analytica AI Residency Program,https://www.reddit.com/r/MachineLearning/comments/8dg2ox/n_cambridge_analytica_ai_residency_program/,[deleted],1524156176,[deleted],0,1
1154,2018-4-20,2018,4,20,2,8dg976,Luminoth 0.1: open source toolkit for Computer Vision | SSD model &amp; pre-trained checkpoints,https://www.reddit.com/r/MachineLearning/comments/8dg976/luminoth_01_open_source_toolkit_for_computer/,minmidinosaur,1524157543,,0,1
1155,2018-4-20,2018,4,20,2,8dg9sy,"Data Science for Sports Injuries Using R, Python, and Weka",https://www.reddit.com/r/MachineLearning/comments/8dg9sy/data_science_for_sports_injuries_using_r_python/,Marshall_NYC,1524157661,,0,2
1156,2018-4-20,2018,4,20,2,8dghol,How to confirm that the word in a given position in sentence is true?,https://www.reddit.com/r/MachineLearning/comments/8dghol/how_to_confirm_that_the_word_in_a_given_position/,CompetitiveInside7,1524159344,[removed],0,1
1157,2018-4-20,2018,4,20,2,8dgie5,[D] A suitable way to assign posterior probability for presence of each class label in a deep learning model?,https://www.reddit.com/r/MachineLearning/comments/8dgie5/d_a_suitable_way_to_assign_posterior_probability/,sg_50,1524159502,"When a deep learning model is trained, the final softmax layer outputs a probability for each class label such that the output vector sums to 1. However, I have noticed that [Google Cloud Vision API](https://cloud.google.com/vision/) is able to assign a posterior probability for the presence of each class label in the image. I also found it done in slide 10 of this [slide deck](https://qconlondon.com/system/files/presentation-slides/qconlondon2018_ai_track_-_session_1_-_qcon_london_2018.pdf) from a presenter from Booking.com.

Although I can guess several ways this probability can be assigned, I haven't found much literature that addresses the best way to do it so that the probability measure is consistent across labels and consistent across models deployed, according to the criteria given in [Tag Prediction at Flickr: a View from the Darkroom](https://arxiv.org/abs/1612.01922). The Flickr paper does lists some of the challenges of designing a methodology. I would appreciate some insights or links to papers/research.",2,7
1158,2018-4-20,2018,4,20,2,8dgjbs,"Reading a paper on memetic algorithms, found a diagram of Reddit",https://www.reddit.com/r/MachineLearning/comments/8dgjbs/reading_a_paper_on_memetic_algorithms_found_a/,ObamaNibblesNoMan,1524159699,,1,1
1159,2018-4-20,2018,4,20,3,8dh30o,Is multiple gpus really useful ?,https://www.reddit.com/r/MachineLearning/comments/8dh30o/is_multiple_gpus_really_useful/,agentkirchoff,1524163821,[removed],0,1
1160,2018-4-20,2018,4,20,4,8dhdp9,Novice at ML looking for some pointers for a school project.,https://www.reddit.com/r/MachineLearning/comments/8dhdp9/novice_at_ml_looking_for_some_pointers_for_a/,God_of_Dyslexia,1524166052,[removed],1,1
1161,2018-4-20,2018,4,20,4,8dhl0l,Currently a Senior in CS taking an ML course. My ML professor said I should do an MS and she'd be my advisor. So many questions.,https://www.reddit.com/r/MachineLearning/comments/8dhl0l/currently_a_senior_in_cs_taking_an_ml_course_my/,award28,1524167592,[removed],0,1
1162,2018-4-20,2018,4,20,5,8dhs2m,[R] Two-Stream Convolutional Networks for Dynamic Texture Synthesis,https://www.reddit.com/r/MachineLearning/comments/8dhs2m/r_twostream_convolutional_networks_for_dynamic/,tesfaldet,1524169054,,39,297
1163,2018-4-20,2018,4,20,5,8dhw8m,"Noob question re: arxiv, where is the centralized discussion of papers?",https://www.reddit.com/r/MachineLearning/comments/8dhw8m/noob_question_re_arxiv_where_is_the_centralized/,SunnysideKun,1524169944,[removed],0,1
1164,2018-4-20,2018,4,20,6,8di9nk,"[D] A.I. Researchers Are Making More Than $1 Million, Even at a Nonprofit (OpenAI)",https://www.reddit.com/r/MachineLearning/comments/8di9nk/d_ai_researchers_are_making_more_than_1_million/,baylearn,1524172872,,103,188
1165,2018-4-20,2018,4,20,6,8difvy,[D] what would you do if two papers have appeared at the same time as yours but don't know about it?,https://www.reddit.com/r/MachineLearning/comments/8difvy/d_what_would_you_do_if_two_papers_have_appeared/,da_g_prof,1524174322,"Hi folks. I have a quick puzzle. I will not name the papers for sake of simplicity.
Lets consider 3 papers:
A appeared on arxiv on 1st week of March submitted to conference x.
B (ours) appeared on arxiv a week later but was submitted to conference y with deadline the same week as x but different domain. 
C appeared on arxiv last week and cites A. 

All papers deal with the same problem. All treat the problem very similarly. Papers A and C deal with a different application compared to B.

We are the authors of B.

Q1. Do you approach the authors of papers A and C to alert them of our existence? Such that at least we all cite each other on the footnotes saying concurrent work. (we plan to do that anyway when we update the paper after revision)

Q2. I am inclined to say yes. Am I thinking wrong and risking something? 

Q3. At some point they may all be trying to take these to a journal. I would welcome that we all co author this! But is it likely to happen? 
",4,4
1166,2018-4-20,2018,4,20,6,8digh8,Need some advice on implementing Machine Learning to clean up product brand names,https://www.reddit.com/r/MachineLearning/comments/8digh8/need_some_advice_on_implementing_machine_learning/,FeetOnGrass,1524174445,[removed],0,1
1167,2018-4-20,2018,4,20,7,8dik48,Caesar Robot Platform for Machine Learning Research: PR2-like Robot for 1% the Cost,https://www.reddit.com/r/MachineLearning/comments/8dik48/caesar_robot_platform_for_machine_learning/,[deleted],1524175270,,0,1
1168,2018-4-20,2018,4,20,7,8dip6f,Working with a large dataset,https://www.reddit.com/r/MachineLearning/comments/8dip6f/working_with_a_large_dataset/,greyghost1991,1524176467,[removed],0,1
1169,2018-4-20,2018,4,20,7,8diqmx,Caesar Robot Platform for Machine Learning Research: PR2-like Robot for 1% the Cost,https://www.reddit.com/r/MachineLearning/comments/8diqmx/caesar_robot_platform_for_machine_learning/,EmpiricalAutomation,1524176819,[removed],0,1
1170,2018-4-20,2018,4,20,7,8ditfe,[D] What's the worst part of doing machine learning these days?,https://www.reddit.com/r/MachineLearning/comments/8ditfe/d_whats_the_worst_part_of_doing_machine_learning/,onedeskover,1524177509,Is it cleaning data collection? Optimizing hyper parameters? Trying to find the right architecture? Deploying to production?,70,28
1171,2018-4-20,2018,4,20,7,8diyd8,video recording learning to disregard window's mesh screen,https://www.reddit.com/r/MachineLearning/comments/8diyd8/video_recording_learning_to_disregard_windows/,galwayhooker,1524178737,[removed],0,1
1172,2018-4-20,2018,4,20,9,8djh7d,Talking Face Generation by Conditional Recurrent Adversarial Network,https://www.reddit.com/r/MachineLearning/comments/8djh7d/talking_face_generation_by_conditional_recurrent/,jefferysusan,1524183524,,0,1
1173,2018-4-20,2018,4,20,9,8djirc,Sparse Unsupervised Capsules Generalize Better,https://www.reddit.com/r/MachineLearning/comments/8djirc/sparse_unsupervised_capsules_generalize_better/,[deleted],1524183867,[deleted],0,1
1174,2018-4-20,2018,4,20,9,8djlp3,Looking for someone who works with machine learning to answer a few questions for research paper.,https://www.reddit.com/r/MachineLearning/comments/8djlp3/looking_for_someone_who_works_with_machine/,azureabsolution,1524184642,[removed],0,1
1175,2018-4-20,2018,4,20,9,8djq7i,[R] [1804.06893] A Study on Overfitting in Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8djq7i/r_180406893_a_study_on_overfitting_in_deep/,evc123,1524185798,,0,20
1176,2018-4-20,2018,4,20,11,8dk498,[D] Has anybody been to Intel Artificial Intelligence Academy?,https://www.reddit.com/r/MachineLearning/comments/8dk498/d_has_anybody_been_to_intel_artificial/,FellowOfHorses,1524190166,They will be doing a lecture in my university next week and I'm curious about it. Is the program good?,2,1
1177,2018-4-20,2018,4,20,11,8dkb3w,Machine learning offers new way of designing chiral cryst,https://www.reddit.com/r/MachineLearning/comments/8dkb3w/machine_learning_offers_new_way_of_designing/,Chipdoc,1524192114,,0,1
1178,2018-4-20,2018,4,20,11,8dke42,Preventing learned constriction?,https://www.reddit.com/r/MachineLearning/comments/8dke42/preventing_learned_constriction/,Drag0nDr0p,1524192953,[removed],0,1
1179,2018-4-20,2018,4,20,12,8dkf1e,[P] Caesar Robot Platform for Machine Learning Research: PR2-like Robot for 1% the Cost,https://www.reddit.com/r/MachineLearning/comments/8dkf1e/p_caesar_robot_platform_for_machine_learning/,EmpiricalAutomation,1524193228,"Hey guys, 

My name is James and I'm a Co-Founder at Empirical Automation. Our mission is to make robotics more accessible, especially for researchers in ML and AI, to help advance the field faster. I'm super excited to present to you our Caesar Robot Platform, an affordable industrial robot for only $3K USD:

http://www.empiricalautomation.com/caesar.html  

Inspired by recent exciting work over the last few years in robotics and deep learning, me and a few college buddies wanted to try some experiments of our own. So naturally we went online and tried to buy a PR2 robot - and then realized we had a better chance of putting a downpayment on a house. And so it started! We set out to address to this big gap between research-capable robots that can accomplish tasks in the real world, and the small and impractical toy robots out there. 

After many iterations and pilot trials, we are launching Caesar: a robot with ""human worker-like specs"" that's designed for ML and AI research. Aside from being a reliable and practical arm, Caesar comes with dual stereo cameras on its neck, and a wrist-mounted camera as well, so it can see what it's doing, and collect data, from multiple perspectives. 

http://www.empiricalautomation.com/research.html 

By making robots affordable and easy to use (just plug in to a power bar, and USB to your laptop for direct programming in e.g. Python), we want to enable people to do cool experiments like Google's multi-robot learning. Except you won't need to acquire a company or spend hundreds of thousands of dollars to do it. And by making it easier for schools, labs, and hobbyists to all afford the same platform, there can be much more data sharing and replication of experiments. This we see as critical to helping move the field forward from a research perspective. 

We're also developing a lightweight simulator, with the same goals in mind: something immediately useful for ML and AI, and super acessible. In fact, you can download a trial demo from our website right now: 

http://www.empiricalautomation.com/basis.html 

It's got a physics engine, model of Caesar, the ability to record and export data (robot commands + all vision data), and save/load/replay previously developed motion paths. Of course real Caesar has all these functions as well :) 

Anyways, we're very excited to show this community our robot and get your feedback! Caesar is available for orders right now, with a 4-6 week lead time as we continue to optimize our supply chain and production process. I'll be around to answer questions and take notes from the community. 

Cheers! ",19,22
1180,2018-4-20,2018,4,20,12,8dkmws,Sunflower Seed Shell Removing Machine Manufacturer,https://www.reddit.com/r/MachineLearning/comments/8dkmws/sunflower_seed_shell_removing_machine_manufacturer/,gelserena,1524195483,,1,1
1181,2018-4-20,2018,4,20,13,8dl242,How to classify non linearly separable data using SVM?,https://www.reddit.com/r/MachineLearning/comments/8dl242/how_to_classify_non_linearly_separable_data_using/,siddheshgadkar,1524199978,[removed],1,1
1182,2018-4-20,2018,4,20,14,8dl907,Detailed Machine Learning notes,https://www.reddit.com/r/MachineLearning/comments/8dl907/detailed_machine_learning_notes/,deathbullet,1524202162,,0,1
1183,2018-4-20,2018,4,20,15,8dlia6,Word2vec skip-gram model confusion,https://www.reddit.com/r/MachineLearning/comments/8dlia6/word2vec_skipgram_model_confusion/,[deleted],1524205311,,0,1
1184,2018-4-20,2018,4,20,15,8dlk5s,[D] Word2vec skip-gram output,https://www.reddit.com/r/MachineLearning/comments/8dlk5s/d_word2vec_skipgram_output/,munchler,1524205979,"I'm trying to understand the output layer of the word2vec skip-gram model. To start with, which of the following correctly describes the output format:

* A single vector of length `V`
* A separate vector of length `V` for each nearby word in the context

Where `V` is the vocabulary size.

[This diagram](http://wuciawe.github.io/files/2017-02-12-notes-on-word2vec/sg.png) illustrates the problem. It seems to show multiple output vectors (`y1`, `y2`, etc.), all of which share the same weight matrix (`W'`). Is this correct?

Other diagrams ([1](https://lilianweng.github.io/lil-log/assets/images/word2vec-skip-gram.png), [2](https://cdn-images-1.medium.com/max/800/0*FTfdlZ7yDBoQ8c9W.png)) show a single output vector, which seems simpler, but raises questions.

I think the correct answer is that model produces a single output vector representing nearby words. This would make sense if we trained the model to do basic classification, where each input corresponds to a single correct output (like MNIST image recognition). However, the skip-gram model actually seems to perform multi-label classifcation, where a given input can correspond to multiple correct outputs. For example, if we have ""The quick brown fox jumps over the lazy dog"" in our corpus, then the following are all valid training samples:

* Input: *brown*, Target: *the*
* Input: *brown*, Target: *quick*
* Input: *brown*, Target: *fox*
* Input: *brown*, Target: *jumps*

Clearly, *brown* maps to multiple target labels (*the*, *quick*, *fox*, and *jumps*). How can we train a model on this data using one-hot vectors and a standard softmax output layer? If we give the model (*brown*, *fox*), and it answers *quick*, then that is wrong. But if we give the model (*brown*, *quick*) and it answers *fox*, then that is also wrong. It's hard to see how the parameters could ever converge in this situation, since there is no reliably correct output for any given input.

Sorry for the long, detailed post, but this seems like a glaring problem with the skip-gram approach, yet it's glossed over in all the explanations that I've read. I'm sure I'm missing something. Any clarification would be most appreciated. Thanks.",4,5
1185,2018-4-20,2018,4,20,15,8dllmw,What is online machine learning?,https://www.reddit.com/r/MachineLearning/comments/8dllmw/what_is_online_machine_learning/,mpgls,1524206506,,0,1
1186,2018-4-20,2018,4,20,15,8dlmv1,Why do we have to convert the categorical value into dummy variables(OneHot Categorical Data) ?,https://www.reddit.com/r/MachineLearning/comments/8dlmv1/why_do_we_have_to_convert_the_categorical_value/,CaptainOnBoard,1524206918,[removed],0,1
1187,2018-4-20,2018,4,20,16,8dlrby,"When and why would you use statistical functions like PDF, PMF, CDF in the real world analytics application?",https://www.reddit.com/r/MachineLearning/comments/8dlrby/when_and_why_would_you_use_statistical_functions/,sirkarthik,1524208465,[removed],0,1
1188,2018-4-20,2018,4,20,17,8dm5oe,[R] Dynamic Evaluation of Neural Sequence Models,https://www.reddit.com/r/MachineLearning/comments/8dm5oe/r_dynamic_evaluation_of_neural_sequence_models/,abstractcontrol,1524214477,,1,1
1189,2018-4-20,2018,4,20,18,8dm7xa,Machine Vision Company | Vision Inspection Systems | AddInnovations,https://www.reddit.com/r/MachineLearning/comments/8dm7xa/machine_vision_company_vision_inspection_systems/,addinnovation,1524215359,,0,1
1190,2018-4-20,2018,4,20,18,8dm9tk,Any well-grounded book for learning machine learning with Python?,https://www.reddit.com/r/MachineLearning/comments/8dm9tk/any_wellgrounded_book_for_learning_machine/,Pimp_Fada,1524216113,[removed],0,1
1191,2018-4-20,2018,4,20,18,8dmblh,Vision Inspection System | Vision Systems | machine vision company | Add Innovations,https://www.reddit.com/r/MachineLearning/comments/8dmblh/vision_inspection_system_vision_systems_machine/,addinnovation,1524216855,,0,1
1192,2018-4-20,2018,4,20,18,8dmcaz,[R] Statistical and Machine Learning forecasting methods: Concerns and ways forward,https://www.reddit.com/r/MachineLearning/comments/8dmcaz/r_statistical_and_machine_learning_forecasting/,pmigdal,1524217150,,3,6
1193,2018-4-20,2018,4,20,18,8dmdu4,Retrofit Vision Systems | Machine Vision System,https://www.reddit.com/r/MachineLearning/comments/8dmdu4/retrofit_vision_systems_machine_vision_system/,addinnovation,1524217750,,0,1
1194,2018-4-20,2018,4,20,19,8dmhc8,[R] Multi-armed bandits for the Win,https://www.reddit.com/r/MachineLearning/comments/8dmhc8/r_multiarmed_bandits_for_the_win/,dearpetra,1524219054,,0,1
1195,2018-4-20,2018,4,20,19,8dmiqz,"A List Of Top 10 Deep Learning Papers, The 2018 Edition",https://www.reddit.com/r/MachineLearning/comments/8dmiqz/a_list_of_top_10_deep_learning_papers_the_2018/,sudheeran,1524219565,,0,1
1196,2018-4-20,2018,4,20,19,8dmlg5,Water Pouch Packing Machine|Milk Packing Machine,https://www.reddit.com/r/MachineLearning/comments/8dmlg5/water_pouch_packing_machinemilk_packing_machine/,lgsherry,1524220567,,1,1
1197,2018-4-20,2018,4,20,19,8dmlsd,[R] How To Know if Your Machine Learning Model Has Good Performance,https://www.reddit.com/r/MachineLearning/comments/8dmlsd/r_how_to_know_if_your_machine_learning_model_has/,polllyyy,1524220686,,0,1
1198,2018-4-20,2018,4,20,19,8dmmh6,[R] Networks of Spiking Neurons Learn to Learn and Remember,https://www.reddit.com/r/MachineLearning/comments/8dmmh6/r_networks_of_spiking_neurons_learn_to_learn_and/,abstractcontrol,1524220946,,7,120
1199,2018-4-20,2018,4,20,20,8dmur9,Optimize Your Inventory Using Predictive Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8dmur9/optimize_your_inventory_using_predictive_machine/,visionetsystems,1524223741,,0,1
1200,2018-4-20,2018,4,20,21,8dn8pl,Input to neural network when distance sensor does not detect anything,https://www.reddit.com/r/MachineLearning/comments/8dn8pl/input_to_neural_network_when_distance_sensor_does/,ppo_fan,1524227976,[removed],0,1
1201,2018-4-20,2018,4,20,21,8dncic,Tooder - Smart Flashcards for Curious Kids,https://www.reddit.com/r/MachineLearning/comments/8dncic/tooder_smart_flashcards_for_curious_kids/,[deleted],1524228994,[deleted],0,1
1202,2018-4-20,2018,4,20,22,8dnjjk,Tooder: Smart Flashcards for Curious Kids,https://www.reddit.com/r/MachineLearning/comments/8dnjjk/tooder_smart_flashcards_for_curious_kids/,jnaneshnayak,1524230736,[removed],0,1
1203,2018-4-20,2018,4,20,22,8dnpnu,PyTorch implementation of AAAI'18 paper - Unsupervised Video Summarization with Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8dnpnu/pytorch_implementation_of_aaai18_paper/,zkyzky,1524232222,,0,1
1204,2018-4-20,2018,4,20,22,8dnrrt,Using Deep Learning to Detect Linguistic Cues of Alzheimers patients,https://www.reddit.com/r/MachineLearning/comments/8dnrrt/using_deep_learning_to_detect_linguistic_cues_of/,[deleted],1524232735,[deleted],0,1
1205,2018-4-20,2018,4,20,23,8dnwcc,"Nuru, an Android app by PlantVillage to detect crop disease in East Africa",https://www.reddit.com/r/MachineLearning/comments/8dnwcc/nuru_an_android_app_by_plantvillage_to_detect/,[deleted],1524233743,[deleted],0,1
1206,2018-4-20,2018,4,20,23,8dnxli,[R] [1803.01801] Fast Implementation of a Bayesian Unsupervised Segmentation Algorithm [2018],https://www.reddit.com/r/MachineLearning/comments/8dnxli/r_180301801_fast_implementation_of_a_bayesian/,AforAnonymous,1524234026,,3,11
1207,2018-4-20,2018,4,20,23,8do010,"[P] Nuru, an Android app by PlantVillage to detect crop disease in East Africa",https://www.reddit.com/r/MachineLearning/comments/8do010/p_nuru_an_android_app_by_plantvillage_to_detect/,hsiaoer5,1524234573,,2,34
1208,2018-4-20,2018,4,20,23,8do0nl,[P] Tensorflow Implementation of RNN(Vanilla/LSTM/GRU) for Text Classification,https://www.reddit.com/r/MachineLearning/comments/8do0nl/p_tensorflow_implementation_of_rnnvanillalstmgru/,roomylee,1524234714,,5,48
1209,2018-4-20,2018,4,20,23,8do1cz,Using Deep Learning to Detect Linguistic Cues of Alzheimers Disease Patients,https://www.reddit.com/r/MachineLearning/comments/8do1cz/using_deep_learning_to_detect_linguistic_cues_of/,omarsar,1524234859,,0,1
1210,2018-4-20,2018,4,20,23,8do24l,Possible identification of the principles of cognition and the tools to define them.,https://www.reddit.com/r/MachineLearning/comments/8do24l/possible_identification_of_the_principles_of/,DevisPan,1524235028,[removed],0,1
1211,2018-4-20,2018,4,20,23,8do44r,[D]High resolution image synthesis using AE,https://www.reddit.com/r/MachineLearning/comments/8do44r/dhigh_resolution_image_synthesis_using_ae/,qeVut7tguCpxKqqMPtWU,1524235479,"I was wondering if anyone knows of a paper (or better yet an implementation) of AE that produces images in high resolution. 
I was thinking of something along the lines of PG-GAN but without the GAN (just progressive growth of AE). 
Is it going to fail miserably because for high resolution the loss function is going to be the culprit?",7,4
1212,2018-4-21,2018,4,21,0,8do8zb,How do we know the value of the regularization parameter satisfies the gradient equations required by Lagrange Multipliers?,https://www.reddit.com/r/MachineLearning/comments/8do8zb/how_do_we_know_the_value_of_the_regularization/,real_pinocchio,1524236543,,0,1
1213,2018-4-21,2018,4,21,0,8dog0r,"For model-based RL, what are the methods for which you know T but not R ?",https://www.reddit.com/r/MachineLearning/comments/8dog0r/for_modelbased_rl_what_are_the_methods_for_which/,gohu_cd,1524238058,[removed],0,1
1214,2018-4-21,2018,4,21,0,8dogzp,"How to mine newsfeed data and extract interactive insights in Python (Kmeans, LDA, NMF)",https://www.reddit.com/r/MachineLearning/comments/8dogzp/how_to_mine_newsfeed_data_and_extract_interactive/,ahmedbesbes,1524238266,,0,1
1215,2018-4-21,2018,4,21,0,8domfl,Is this a problem with my code or my data?,https://www.reddit.com/r/MachineLearning/comments/8domfl/is_this_a_problem_with_my_code_or_my_data/,jidkut,1524239428,[removed],0,1
1216,2018-4-21,2018,4,21,1,8dopi7,[D]would there be any conflict if I install tensorflow-gpu on a machine that pytorch-CUDA already on it?,https://www.reddit.com/r/MachineLearning/comments/8dopi7/dwould_there_be_any_conflict_if_i_install/,sonsus,1524240100,"For utilizing *tensorboard* on *pytorch* Im figuring out installing tensorflow-gpu on conda env which already has pytorch with CUDA 8.0 on it.

Before possible defect caused by this action, I've done a lil bit research whether similar issues exist, I found this suspicious thread but quite not sure it's the case. Anybody experienced such a confliction??

https://github.com/tensorflow/tensorflow/issues/14812",3,0
1217,2018-4-21,2018,4,21,1,8dotel,[R] Natural and Effective Obfuscation by Head Inpainting,https://www.reddit.com/r/MachineLearning/comments/8dotel/r_natural_and_effective_obfuscation_by_head/,spaceandthyme,1524240929,,1,4
1218,2018-4-21,2018,4,21,1,8dowic,classification and clustering data mining,https://www.reddit.com/r/MachineLearning/comments/8dowic/classification_and_clustering_data_mining/,kentak1030,1524241611,[removed],0,1
1219,2018-4-21,2018,4,21,2,8dph4l,[D] Learning with more labels than inputs,https://www.reddit.com/r/MachineLearning/comments/8dph4l/d_learning_with_more_labels_than_inputs/,seinchin,1524246043,"Say I have a problem where I have a few input-label pairs $X, y$, and then a bunch of labels $y'$ without known inputs from the same system. (The reverse of semi-supervised learning). Is there a name for this problem domain? Is there much research into it? ",3,3
1220,2018-4-21,2018,4,21,2,8dpi67,Hard textbook recommendations,https://www.reddit.com/r/MachineLearning/comments/8dpi67/hard_textbook_recommendations/,zzzwex,1524246260,[removed],0,1
1221,2018-4-21,2018,4,21,3,8dpn3j,[Discussion] upper-bound on the VC-dimension,https://www.reddit.com/r/MachineLearning/comments/8dpn3j/discussion_upperbound_on_the_vcdimension/,Illidan5,1524247285,"Hi, I failed to understand this question , I'm not strong with all the upper-bound topic I would really appreciate a solution with good explanation, heres the question:

Class C includes all 2D-objects which are hearts, clubs, or diamonds hearts in all sizes and centered at any point in the 2D-plane. Give an upper-bound on the VC-dimension of C. ",11,10
1222,2018-4-21,2018,4,21,3,8dpqu2,Looking for beta feedback on an NLP engine for automated coding of open ends.,https://www.reddit.com/r/MachineLearning/comments/8dpqu2/looking_for_beta_feedback_on_an_nlp_engine_for/,jphgross,1524248087,,0,1
1223,2018-4-21,2018,4,21,3,8dq2tv,What's the coolest ML model you've ever seen?,https://www.reddit.com/r/MachineLearning/comments/8dq2tv/whats_the_coolest_ml_model_youve_ever_seen/,gagejustins,1524250758,[removed],0,1
1224,2018-4-21,2018,4,21,4,8dq46x,Batch Update Gradients Problem,https://www.reddit.com/r/MachineLearning/comments/8dq46x/batch_update_gradients_problem/,zebrasecond,1524251042,[removed],0,1
1225,2018-4-21,2018,4,21,4,8dqce8,How many ways are there to measure the success of a recommendation/collaborative filtering model?,https://www.reddit.com/r/MachineLearning/comments/8dqce8/how_many_ways_are_there_to_measure_the_success_of/,redditpentester,1524252912,[removed],0,1
1226,2018-4-21,2018,4,21,4,8dqd0q,[D] What are some good resources for learning the non-ML part of data science?,https://www.reddit.com/r/MachineLearning/comments/8dqd0q/d_what_are_some_good_resources_for_learning_the/,progfu,1524253049,"I've been reading through PRML and MLAPP and watching lots of ML videos online and I feel like I'm making good progress in that area, but having just tried another Kaggle competition, I feel like I'm really missing some of the ""data science-ish"" skills like just how to preprocess the data properly, what to look for, how to do feature selection/extraction, or even just that there is such thing as a partial dependence plot.

I know that there are tons of data science MOOC's and youtube videos and articles, but to me it feels like most if not all use data science as a motivation to teach programming, or math, or just computers in general. I'm not really interested in a ""here's what a function is, now use that function to load a csv file, then make a plot and a correlation matrix, boom you're a data scientist"".

Are there any more advanced books that don't explain all of the basics but show in a bit more detail how to actually do the ""practical"" part of ML? Every book I own tries to explain things like how to solve the dual problem for an SVM, but none really explain how to look at data and what to do to it before I stick it in the SVM.

Having looked over at Kaggle a bit, I found a few notebooks that look like [this](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python) and [this](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic), which link to the [Multivariate Data Analysis](https://www.amazon.com/Multivariate-Data-Analysis-Joseph-Hair/dp/9332536503/) book. Is this what I'm looking for? Or is there like a complete area of data analysis that is disjoint from ML?

---

Sorry if I'm using the term  _data science_ term wrongly for this, but I'm not really sure how to call it. People always say that things like feature engineering are part of ML, but then there are literally tens or even hundreds of ML books that go in depth on everything but that (just as an example).",8,5
1227,2018-4-21,2018,4,21,4,8dqdqy,[P] How I trained an AI to detect satire in under an hour,https://www.reddit.com/r/MachineLearning/comments/8dqdqy/p_how_i_trained_an_ai_to_detect_satire_in_under/,thetall0ne1,1524253218,,4,0
1228,2018-4-21,2018,4,21,4,8dqihc,How to develop a stock market analytical tool using Shiny and R,https://www.reddit.com/r/MachineLearning/comments/8dqihc/how_to_develop_a_stock_market_analytical_tool/,lamres,1524254272,,0,1
1229,2018-4-21,2018,4,21,5,8dqxi0,chatbot learning content from papers?,https://www.reddit.com/r/MachineLearning/comments/8dqxi0/chatbot_learning_content_from_papers/,cassioalmeidas,1524257675,[removed],0,1
1230,2018-4-21,2018,4,21,6,8dr25z,Incorporating Machine Learning in a Tower Defense Game,https://www.reddit.com/r/MachineLearning/comments/8dr25z/incorporating_machine_learning_in_a_tower_defense/,IndieWatchBlog,1524258752,,0,1
1231,2018-4-21,2018,4,21,6,8dr35m,[D] Chinas National AI Team Gets Busy,https://www.reddit.com/r/MachineLearning/comments/8dr35m/d_chinas_national_ai_team_gets_busy/,trcytony,1524258997,,0,1
1232,2018-4-21,2018,4,21,6,8dr4yt,[D] How do you create and annotate datasets?,https://www.reddit.com/r/MachineLearning/comments/8dr4yt/d_how_do_you_create_and_annotate_datasets/,jamesonatfritz,1524259414,"When starting a new project, what tools are you using to create and annotate datasets? Are people just using public repositories with pre-labeled data like COCO and image net or are they building custom annotation tools? Do you ever build custom applications to capture data from specific sensors like mobile cameras or accelerometers?",14,19
1233,2018-4-21,2018,4,21,6,8dramm,[R] NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations (NNAISENSE),https://www.reddit.com/r/MachineLearning/comments/8dramm/r_naisnet_stable_deep_networks_from_nonautonomous/,inarrears,1524260791,,0,20
1234,2018-4-21,2018,4,21,7,8drm8e,[P] How to Implement a YOLO (v3) Object Detector From Scratch In PyTorch,https://www.reddit.com/r/MachineLearning/comments/8drm8e/p_how_to_implement_a_yolo_v3_object_detector_from/,ArtBears,1524263627,,28,395
1235,2018-4-21,2018,4,21,7,8drnjo,[P] We are aiming at identifying every brand on earth. Looking for beta-testers,https://www.reddit.com/r/MachineLearning/comments/8drnjo/p_we_are_aiming_at_identifying_every_brand_on/,SYGZ95,1524263976,,3,0
1236,2018-4-21,2018,4,21,7,8droah,"[R] In-depth Interview with Professor Tomaso Poggio on Deep Learning Representation, Optimization, and Generalization",https://www.reddit.com/r/MachineLearning/comments/8droah/r_indepth_interview_with_professor_tomaso_poggio/,gwen0927,1524264180,,0,1
1237,2018-4-21,2018,4,21,8,8drszm,PyTorch implementation of OpenAI's Reptile (meta-learning algorithm.,https://www.reddit.com/r/MachineLearning/comments/8drszm/pytorch_implementation_of_openais_reptile/,gabrielhuang,1524265417,,1,6
1238,2018-4-21,2018,4,21,8,8drxoy,Pytorch implementation of conditional generative adversarial networks,https://www.reddit.com/r/MachineLearning/comments/8drxoy/pytorch_implementation_of_conditional_generative/,m_alzantot,1524266651,,0,1
1239,2018-4-21,2018,4,21,9,8dsbck,[D] Best software to write a machine learning based master thesis,https://www.reddit.com/r/MachineLearning/comments/8dsbck/d_best_software_to_write_a_machine_learning_based/,L3GOLAS234,1524270448,"Hello there. I am studying a MSc in Applied Statistics and my master thesis is called ""Unsupervised learning techniques applied to classification of gymnasts through the measuring of individual
elements from acrobatic gymnastic discipline"". That is, I would need to have an index, citations, plots, math (for the theoretical background of machine learning models) and so on. I am going to use Python for the developing. However, I am still thinking about which sofwtare should I use for typing purposes. There are three options that I have taken in account:

1-. Latex + PythonTex

2 -. Jupyter notebook + pandoc

3-. R studio + kntir + reticulate

Regarding the first option, the main inconvenient is that coding has to be developed outside Latex (for testing) and then it has to be pasted in Latex, which results in a loss of hyphenation (at least that happened when I first used it) and the consequent loss of time for making it again. 

With respect to the 2nd option, I have read that citations can be used using latex system and there is even a package for live citations using zotero, but I am not sure how effective would it be to make certain things, as an index.

Finally, I am not even sure 3rd option is possible. I know that through reticulate package in combination with kntir, you can make a Markdown document in R studio using Python code, but I don't know if it is also possible to create a R Sweave document. In negative case, Markdown would be sufficient over Sweave for my task? 

What would you choose and why? Thank you very much for your answer ",3,0
1240,2018-4-21,2018,4,21,9,8dsc3c,[R] Were the ICML 2018 reviews particularly poor this year as compared to ICLR 2018 reviews?,https://www.reddit.com/r/MachineLearning/comments/8dsc3c/r_were_the_icml_2018_reviews_particularly_poor/,FirstTimeResearcher,1524270679,,6,6
1241,2018-4-21,2018,4,21,13,8dtnte,Deep Learning A-Z: Hands-On Artificial Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8dtnte/deep_learning_az_handson_artificial_neural/,[deleted],1524286157,[deleted],0,1
1242,2018-4-21,2018,4,21,14,8dtq5r,[D] Deep Learning A-Z: Hands-On Artificial Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8dtq5r/d_deep_learning_az_handson_artificial_neural/,nnomaan,1524287032,,0,0
1243,2018-4-21,2018,4,21,14,8dtqyu,AI and the ludic fallacy,https://www.reddit.com/r/MachineLearning/comments/8dtqyu/ai_and_the_ludic_fallacy/,mathmare,1524287310,,0,1
1244,2018-4-21,2018,4,21,15,8dtzir,[P] Conditional GAN online demo. Generate faces with conditions.,https://www.reddit.com/r/MachineLearning/comments/8dtzir/p_conditional_gan_online_demo_generate_faces_with/,ThisIsMySeudonym,1524290648,Check it out and post your thoughts: [http://adeel.io/sncgan](http://adeel.io/sncgan),5,14
1245,2018-4-21,2018,4,21,15,8du3a4,[R] [1804.06826] Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking,https://www.reddit.com/r/MachineLearning/comments/8du3a4/r_180406826_dissecting_the_nvidia_volta_gpu/,evc123,1524292266,,0,21
1246,2018-4-21,2018,4,21,15,8du443,Linear Regression using Ordinary Least Squares Calculator,https://www.reddit.com/r/MachineLearning/comments/8du443/linear_regression_using_ordinary_least_squares/,vinay6666,1524292608,,0,1
1247,2018-4-21,2018,4,21,15,8du6rn,"[R] [1804.06218] Hierarchical correlation reconstruction with missing data - first separately estimate density for each coordinate using all its appearances, then add corrections from pair-wise correlations using all appearances of both coordinates, and so on for higher correlations.",https://www.reddit.com/r/MachineLearning/comments/8du6rn/r_180406218_hierarchical_correlation/,jarekduda,1524293726,,0,5
1248,2018-4-21,2018,4,21,19,8duzfc,[D] Research Assistant in Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/8duzfc/d_research_assistant_in_deep_learning/,cbsudux,1524306846,"Hi guys!

I have been trying really hard to land a position of a Research Assistant in Academia/ R&amp;D for the past few months but it's been pretty hard.

I'm a senior undergraduate and I am really interested in DL and CV and I believe I have sufficient experience. I pursue research in GANs and Image Captioning in my school and I have lots of experience implementing DL+RL models in practice. I've read the Deep Learning book thoroughly, among other materials. My plan is to work after I graduate as a RA for a year, get some research experience and hopefully publish a few papers, and apply for a PhD.

What more can I do to improve my chances? 
 
PS : If you're hiring, I am happy to send my CV and Cover Letter over! Cheers!",18,12
1249,2018-4-21,2018,4,21,19,8dv1el,I'm building a web app to convert models between frameworks - Need your help,https://www.reddit.com/r/MachineLearning/comments/8dv1el/im_building_a_web_app_to_convert_models_between/,dar_1978,1524307718,,1,1
1250,2018-4-21,2018,4,21,20,8dv6js,[P] Deploy Deep Learning model on Kubernetes GPU cluster,https://www.reddit.com/r/MachineLearning/comments/8dv6js/p_deploy_deep_learning_model_on_kubernetes_gpu/,reformed_scientist,1524309890,,1,10
1251,2018-4-21,2018,4,21,22,8dvomj,Basic Machine Learning Project on Github,https://www.reddit.com/r/MachineLearning/comments/8dvomj/basic_machine_learning_project_on_github/,nom_adic,1524316653,[removed],0,1
1252,2018-4-21,2018,4,21,22,8dvp1s,Can I create a custom activation function?,https://www.reddit.com/r/MachineLearning/comments/8dvp1s/can_i_create_a_custom_activation_function/,aaditkapoor1201,1524316800,[removed],0,1
1253,2018-4-21,2018,4,21,22,8dvw4m,Apriori algorithm variants for Market Basket Analysis,https://www.reddit.com/r/MachineLearning/comments/8dvw4m/apriori_algorithm_variants_for_market_basket/,atinesh229,1524319055,[removed],0,1
1254,2018-4-21,2018,4,21,23,8dw5rx,From where to start with all this Machine Learning world ? HELP,https://www.reddit.com/r/MachineLearning/comments/8dw5rx/from_where_to_start_with_all_this_machine/,LaPinya95,1524321874,[removed],0,1
1255,2018-4-22,2018,4,22,0,8dwa8d,"The first article in a series exploring Deep Learning in Computer Vision using PyTorch. In this, we set the goal of getting into the top 1% in a Kaggle Competition (you need to be in top 10% to be an expert).",https://www.reddit.com/r/MachineLearning/comments/8dwa8d/the_first_article_in_a_series_exploring_deep/,databiryani,1524323085,,0,1
1256,2018-4-22,2018,4,22,0,8dwkme,[D] Anyone having trouble writing a ML paper ? Post a question or even a draft here and we'll give you feedback,https://www.reddit.com/r/MachineLearning/comments/8dwkme/d_anyone_having_trouble_writing_a_ml_paper_post_a/,BatmantoshReturns,1524325907,"Writing research papers is a bit of discipline it itself. There are a variety of ways to explain and present research and its insights. It's hard to keep track of your blindspots in your descriptions; what may seem unambiguous to you may actually have multiple interpretations to a reader. 

Not sure how well this thread is going to go since its asking people to publicly discuss their unpublished work. But when there's any concern about that, maybe they can come up with a way to ask a question about something without discussing their research. We'll see how it goes lol. Think of this as an experimental thread. ",53,56
1257,2018-4-22,2018,4,22,2,8dx7js,Is subpixel convolution the reverse operation of dilated convolution?,https://www.reddit.com/r/MachineLearning/comments/8dx7js/is_subpixel_convolution_the_reverse_operation_of/,geekfolk,1524331810,,1,1
1258,2018-4-22,2018,4,22,3,8dxlpb,Splitting the features and applying different models,https://www.reddit.com/r/MachineLearning/comments/8dxlpb/splitting_the_features_and_applying_different/,cchopade,1524335344,[removed],0,1
1259,2018-4-22,2018,4,22,3,8dxmrt,[D] Machine Learning A-Z: Hands-On Python &amp; R In Data Science,https://www.reddit.com/r/MachineLearning/comments/8dxmrt/d_machine_learning_az_handson_python_r_in_data/,[deleted],1524335626,[deleted],0,1
1260,2018-4-22,2018,4,22,3,8dxpao,"[P] Preventing ""Learned Constriction""?",https://www.reddit.com/r/MachineLearning/comments/8dxpao/p_preventing_learned_constriction/,Drag0nDr0p,1524336259,"I've been using machine learning on a side project of mine where I train an algorithm to play a video game just to see how well it works. The Neural Network decides what actions to perform in-game, then evaluates the success of those actions. Then it stores a snapshot of the scenario it was in at the time of executing the action, and a value that indicates the success level of that action. This forms the basis of my training set.

I've noticed something happen that I can only explain by calling it ""learned constriction"". What I mean by this is that once the NN learns that something doesn't work in a given scenario enough times it'll just never try it again. This game has a lot of randomness elements to it, meaning the data produced will be quite noisy. Rather than just slowing down the learning rate of the NN, I would like to implement something to make it experiment a bit with what actions it tries to perform.

I'm wondering if there's something like ""standard procedure"" for this type of scenario to combat incorrect modeling of noisy data in an online learning model. Is simple occasional random selection of what action to perform enough? Ideally I would be able to measure its in-game performance while also experimenting, but that's the best case scenario.

",2,1
1261,2018-4-22,2018,4,22,3,8dxpiv,[D] Machine Learning A-Z: Hands-On Python &amp;amp; R In Data Science,https://www.reddit.com/r/MachineLearning/comments/8dxpiv/d_machine_learning_az_handson_python_amp_r_in/,nomaann,1524336321,,0,1
1262,2018-4-22,2018,4,22,3,8dxsco,AI Weekly 21 April 2018,https://www.reddit.com/r/MachineLearning/comments/8dxsco/ai_weekly_21_april_2018/,TomekB,1524337051,,0,1
1263,2018-4-22,2018,4,22,4,8dy4d5,[D] What do you use Keras for?,https://www.reddit.com/r/MachineLearning/comments/8dy4d5/d_what_do_you_use_keras_for/,best_keras_workflow,1524340158,"I've seen quite a few tutorials on Keras, primarily for hobbyists learning about Deep Learning and using it for toy models and the like. I've also seen a few libraries and approaches to make pushing Keras/TF models to production, but I don't know what the market penetration of the framework is like or what it is used for in industry or academia.

From what I can gather, the research world has a heavy Tensorflow and PyTorch presence these days, and industry heavily utilizes Tensorflow or the company's own tools (Caffe2, MXNet, CNTK).

Does anybody here use Keras for model building in your company or for academic research tasks? If so, what does your workflow or development setup like?",34,21
1264,2018-4-22,2018,4,22,5,8dy6wi,[P] Live Object Detection on Raspberry Pi CPU with decent performance,https://www.reddit.com/r/MachineLearning/comments/8dy6wi/p_live_object_detection_on_raspberry_pi_cpu_with/,tlkh,1524340817,"Hi everyone, apologies if this project is a bit noob, but just thought I'd share and get some comments on how we did overall. 

As part of a first-year CS project I've deployed an object detection model (MobileNet + SSD) running on a Raspberry Pi CPU. The overall detection performance + runtime performance (0.8~1.2 FPS detection) was surprisingly good.

The use case was to identify users by their face and identify the object they were holding, if it belongs to one of two categories of recyclable trash. For this we hand labelled 1034 images. 

YouTube video: https://www.youtube.com/watch?v=06DGkJ8wYK0&amp;feature=youtu.be

To make the video stream look more presentable we had multiple threads: one for the video capture, one for bounding box detection and one for the rendering of the latest frame + bounding box.

We applied transfer learning to a MobileNet with ImageNet weights (aided mainly by https://github.com/experiencor/keras-yolo2) and then proceeded to deploy it on a Raspberry Pi with a heavily optimised image processing pipeline (as much as we can get with just Python). I was expected sub 1FPS performance + lousy detection so I was really pleased by what we managed to achieve (in addition to having to run a Kivy GUI. Project requirement *rolls eye*) The Raspberry Pi is really an amazing device for the price and power requirements. 

GitHub: https://github.com/tlkh/SmartBin

This is an exciting time to be a CS undergrad and I'm really excited to do more deep learning projects. This summer I'm going to attempt the CVPR 2018 WAD Video Segmentation Challenge on Kaggle.

Have a good day everyone!",36,197
1265,2018-4-22,2018,4,22,5,8dyecu,What concepts of Linear Algebra are used in different ML algorithms?,https://www.reddit.com/r/MachineLearning/comments/8dyecu/what_concepts_of_linear_algebra_are_used_in/,primemozartmessi,1524342728,[removed],0,1
1266,2018-4-22,2018,4,22,5,8dyfan,[P] Tensorflow Implementation of Dynamic Coattention Network Plus,https://www.reddit.com/r/MachineLearning/comments/8dyfan/p_tensorflow_implementation_of_dynamic/,mjacar,1524342954,,0,0
1267,2018-4-22,2018,4,22,5,8dyhlx,[P] PyTorch Implementation of Neural Episodic Control,https://www.reddit.com/r/MachineLearning/comments/8dyhlx/p_pytorch_implementation_of_neural_episodic/,mjacar,1524343553,,0,0
1268,2018-4-22,2018,4,22,5,8dyjxj,[P] PyTorch Implementation of Trust Region Policy Optimization,https://www.reddit.com/r/MachineLearning/comments/8dyjxj/p_pytorch_implementation_of_trust_region_policy/,mjacar,1524344152,,0,0
1269,2018-4-22,2018,4,22,6,8dyo3y,A point to start with Machine Learning world ? HELP,https://www.reddit.com/r/MachineLearning/comments/8dyo3y/a_point_to_start_with_machine_learning_world_help/,[deleted],1524345271,,0,1
1270,2018-4-22,2018,4,22,6,8dyugp,[D] A point to start with Machine Learning world ?,https://www.reddit.com/r/MachineLearning/comments/8dyugp/d_a_point_to_start_with_machine_learning_world/,LaPinya95,1524346966,"Hi everyone,I have been doing a career on Multimedia Engineering, basically I have studied a bit of everyting (Databases,videogames, networking, image and audio processing, web, front end, back end, apps) and of course some Stadistics, probability, physics. After all this I haven been really undecided to where I want to finally go as a profressional programmer.

A lot of people has talk to me about machine learning but not to much in deep but also I liked almost everything I heard about it. I had some project that I want to use for learning (I think the best idea to learn something is actually practicing with it) and its basically a way to suggest new music according on what you listen, basically like the Spotify Discovery Weekly.

Could someone recommend me some start point or some route I could follow to understanding it properly? Any link or book is welcome. I'm not afraid to go in deep, all the opposite I'm very motivated about this.

Thank you very much in advance :D
",8,3
1271,2018-4-22,2018,4,22,6,8dyw6e,object detection architecture for traffic cone,https://www.reddit.com/r/MachineLearning/comments/8dyw6e/object_detection_architecture_for_traffic_cone/,h1tch2,1524347409,[removed],0,1
1272,2018-4-22,2018,4,22,8,8dzj6i,The Looming Battle Over AI Chips,https://www.reddit.com/r/MachineLearning/comments/8dzj6i/the_looming_battle_over_ai_chips/,CharlesElegans,1524353807,,0,1
1273,2018-4-22,2018,4,22,9,8dzoqd,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8dzoqd/machine_learning/,thelynched,1524355400,[removed],0,1
1274,2018-4-22,2018,4,22,9,8dzxfj,[R] Towards Biologically Plausible Deep Learning: Early Inference in Energy-Based Models Approximates Back-Propagation,https://www.reddit.com/r/MachineLearning/comments/8dzxfj/r_towards_biologically_plausible_deep_learning/,downtownslim,1524357886,,6,60
1275,2018-4-22,2018,4,22,9,8dzzls,Misunderstanding with Naive Bayes Text Classification,https://www.reddit.com/r/MachineLearning/comments/8dzzls/misunderstanding_with_naive_bayes_text/,errminator,1524358550,[removed],0,1
1276,2018-4-22,2018,4,22,11,8e0gho,you guys have been doing it wrong,https://www.reddit.com/r/MachineLearning/comments/8e0gho/you_guys_have_been_doing_it_wrong/,skbobade,1524363852,,0,1
1277,2018-4-22,2018,4,22,11,8e0n0i,[P] Keras implementation of YOLOv3,https://www.reddit.com/r/MachineLearning/comments/8e0n0i/p_keras_implementation_of_yolov3/,SupraluminalShift,1524365903,,6,34
1278,2018-4-22,2018,4,22,12,8e0p7e,[N] President of India thinks Sanskrit is most suitable language for machine learning,https://www.reddit.com/r/MachineLearning/comments/8e0p7e/n_president_of_india_thinks_sanskrit_is_most/,ManageableGrip,1524366582,,15,0
1279,2018-4-22,2018,4,22,13,8e15dz,How will we survive without saving and sharing data of our users?,https://www.reddit.com/r/MachineLearning/comments/8e15dz/how_will_we_survive_without_saving_and_sharing/,dpravi799,1524372174,,0,1
1280,2018-4-22,2018,4,22,14,8e1dbq,Machine Learning Implementation With IVR,https://www.reddit.com/r/MachineLearning/comments/8e1dbq/machine_learning_implementation_with_ivr/,esatyabca,1524375193,,0,1
1281,2018-4-22,2018,4,22,15,8e1k07,[R] Gaussian Material Synthesis (SIGGRAPH 2018),https://www.reddit.com/r/MachineLearning/comments/8e1k07/r_gaussian_material_synthesis_siggraph_2018/,hardmaru,1524377787,,1,54
1282,2018-4-22,2018,4,22,15,8e1ojv,[Project] Monte-Carlo Search for Magic: The Gathering,https://www.reddit.com/r/MachineLearning/comments/8e1ojv/project_montecarlo_search_for_magic_the_gathering/,MTGTraner,1524379779,,40,121
1283,2018-4-22,2018,4,22,18,8e25w5,[D] Question in variational inference derivation (Rui Shu),https://www.reddit.com/r/MachineLearning/comments/8e25w5/d_question_in_variational_inference_derivation/,readinginthewild,1524387895,"In http://ruishu.io/2017/01/14/one-bit/ blog post by Rui Shu (Autoencoding a single bit)
there is this derivation:

    ln(p(x=1)  &gt;=   E_q(z|x=1) [   ln p(z)p(x=1|z)  -   ln(q(z|x=1)   ]
		=   E_q(z|x=1) [   ln p(x=1|z)   ]
		=   -0.693


p(z) is a standard gaussian. The q() funcion is a vae encoder, however I believe that the derivation is meant to be general variational inference, not assuming vae?

My question: how do we derive from the first line to the second line.
The third line: -0.693 is ln(0.5).
",3,7
1284,2018-4-22,2018,4,22,18,8e278e,Suggestions for stamp detection in scanned documents,https://www.reddit.com/r/MachineLearning/comments/8e278e/suggestions_for_stamp_detection_in_scanned/,acolmanj,1524388527,[removed],0,1
1285,2018-4-22,2018,4,22,19,8e2dxl,[D] Need help analyzing incorrect answers,https://www.reddit.com/r/MachineLearning/comments/8e2dxl/d_need_help_analyzing_incorrect_answers/,kserno,1524391717,"So I was given an assignment to analyze wrong answers from learning system related to math and english, I am not that experienced in machine learning but I have grasp of the basic concepts, can anyone recommend me some paper you have accidently came around because I can't really find anything that can help me, or inspire me in some way",2,3
1286,2018-4-22,2018,4,22,19,8e2jsd,Any alternative US masters degree to MS in datascience?,https://www.reddit.com/r/MachineLearning/comments/8e2jsd/any_alternative_us_masters_degree_to_ms_in/,sunny_reddit,1524394411,[removed],0,1
1287,2018-4-22,2018,4,22,21,8e2w6n,Find feature importance in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8e2w6n/find_feature_importance_in_deep_learning/,skeering,1524399460,[removed],1,1
1288,2018-4-22,2018,4,22,21,8e2zbk,0 0 Accelerated discovery of metallic glasses through iteration of machine learning.,https://www.reddit.com/r/MachineLearning/comments/8e2zbk/0_0_accelerated_discovery_of_metallic_glasses/,yazriel0,1524400635,,1,1
1289,2018-4-22,2018,4,22,21,8e318i,"[6 hours left at this price! - 5.0 stars course] ""Hands On Natural Language Processing (NLP) using Python"" Course for FREE",https://www.reddit.com/r/MachineLearning/comments/8e318i/6_hours_left_at_this_price_50_stars_course_hands/,samiali123,1524401337,,0,1
1290,2018-4-22,2018,4,22,22,8e33an,[Project] Watch LeelaChessZero vs GM Andrew Tang @ 11 AM EDT,https://www.reddit.com/r/MachineLearning/comments/8e33an/project_watch_leelachesszero_vs_gm_andrew_tang_11/,careless25,1524402058,"Some people here probably followed Deepmind's AlphaGo, then AlphaGoZero and finally AlphaZero's achievements. However Google did not release the weights for all thoses networks, so a community has formed trying to reproduce and maybe improve the AlphaZero engine.


To do this, a distributed effort to play self-play games has started, and the training is done on a single powerful computer (It can update the weights in about 5 hours currently).


You can see the self-play ELO curve (not representative of real ELO) on the [website](http://lczero.org/).


If you want to help the project by sharing your GPU/CPU, think about following the instructions on the ""Getting Started"" section of the website.

As of now, it would take about ~400 days to reach the 44.000.000 games played by Deepmind, but that could change thanks to you!

Some useful links to learn more and talk about the project:

* Try playing her yourself! (all calculations done server-side): http://play.lczero.org/
* Website: http://lczero.org
* Getting started: https://github.com/glinscott/leela-chess/wiki/Getting-Started
* GitHub: https://github.com/glinscott/leela-chess/
* Discord: https://discord.gg/pKujYxD
* Forum: https://groups.google.com/forum/#!forum/lczero

And finally the match will be hosted on Lichess and streamed by Andrew Tang [here](https://www.twitch.tv/penguingm1)!

More details about the match at [Lichess blog](https://lichess.org/blog/WtNG7CcAAFMTTHPj/gm-andrew-tang-vs-leela-chess-zero).",3,31
1291,2018-4-22,2018,4,22,22,8e37p2,Can ML accelerate the FDAs drug approval process?,https://www.reddit.com/r/MachineLearning/comments/8e37p2/can_ml_accelerate_the_fdas_drug_approval_process/,ggreddituser,1524403508,[removed],0,1
1292,2018-4-22,2018,4,22,23,8e3jqu,Issues during recreating the well-known paper,https://www.reddit.com/r/MachineLearning/comments/8e3jqu/issues_during_recreating_the_wellknown_paper/,mr_dicaprio,1524407222,[removed],0,1
1293,2018-4-22,2018,4,22,23,8e3om2,[D] Combining NN for time series analysis,https://www.reddit.com/r/MachineLearning/comments/8e3om2/d_combining_nn_for_time_series_analysis/,robertbodley,1524408583,"Hi,

I am currently doing a literature review on TS analysis.

One of the papers(linked below) I have read explains using a LSTM RNN that takes trend lines(slope and duration) as input and a CNN that takes the individual prices during each of those trend lines and combining the results into an output that predicts the next trend line.

I understand that they do feature fusion and combine the outputs. My question is what would be the best way to implement this using Scikit Learn?

Any advice would be appreciated! 

Learning the Trend in Time Series: https://www.ijcai.org/proceedings/2017/0316.pdf ",6,2
1294,2018-4-23,2018,4,23,0,8e3qv0,Machine Learnings Amazing Ability to Predict Chaos,https://www.reddit.com/r/MachineLearning/comments/8e3qv0/machine_learnings_amazing_ability_to_predict_chaos/,InsaneRaspberry,1524409217,,0,1
1295,2018-4-23,2018,4,23,0,8e3vn0,Neural network based compiler optimizations?,https://www.reddit.com/r/MachineLearning/comments/8e3vn0/neural_network_based_compiler_optimizations/,dev_matan_tsuberi,1524410470,[removed],0,1
1296,2018-4-23,2018,4,23,0,8e4199,[P] Issues during recreating the well-known paper,https://www.reddit.com/r/MachineLearning/comments/8e4199/p_issues_during_recreating_the_wellknown_paper/,mr_dicaprio,1524411946,"Hi guys, 

for the purpose of my bachelor thesis, I'm trying to recreate a machine learning part of well-known paper published by Frey and Osborne called: **[The Future of Employment: How Susceptible Are Jobs to Computerisation?](https://www.oxfordmartin.ox.ac.uk/downloads/academic/The_Future_of_Employment.pdf)**. I've already manged to get some results, but at the same time I have a lot of second thoughts and issues, with which I think you can help me. These are the most important:

They've hand-labeled 70 observations, which accounts for 10% of all rows, which is understandable since the data source wasn't designed to measure automation impact. Then, they train their models on those data and **test every model 100 times on samples from training data** (50% of labeled observations). My question is: is that a proper approach and if not, what would be better ? Maybe it's better to use 50% of labeled observation (it's relatively small number, like 30) and test it on those which has left. Using authors approach with logistic regression my classifier's AUC is on average equal to 0.94.

Another thing that worries me is **correlation matrix, with most values close to or higher than 0.5**. Clearly it suggests a relationship between the variables. Does this not interfere with the use of the probabilistic classification model (gaussian process classifier) used by the authors ?

Also, what bothers me is the fact that as far as logistic regression is concerned, only two variables are statisticly important.

Thank you for your time. 

Cheers",2,1
1297,2018-4-23,2018,4,23,0,8e41rn,[P] Simple Tensorflow implementation of NVIDIA Multimodal Image-to-Image Translation (MUNIT),https://www.reddit.com/r/MachineLearning/comments/8e41rn/p_simple_tensorflow_implementation_of_nvidia/,[deleted],1524412082,[deleted],1,1
1298,2018-4-23,2018,4,23,0,8e42dl,[P] Simple Tensorflow implementation of Multimodal Unsupervised Image-to-Image Translation (MUNIT),https://www.reddit.com/r/MachineLearning/comments/8e42dl/p_simple_tensorflow_implementation_of_multimodal/,[deleted],1524412241,[deleted],1,1
1299,2018-4-23,2018,4,23,1,8e4765,[P] Simple Tensorflow implementation of Multimodal Unsupervised Image-to-Image Translation (MUNIT),https://www.reddit.com/r/MachineLearning/comments/8e4765/p_simple_tensorflow_implementation_of_multimodal/,taki0112,1524413414,,38,320
1300,2018-4-23,2018,4,23,2,8e4p49,Self-learning Data Science,https://www.reddit.com/r/MachineLearning/comments/8e4p49/selflearning_data_science/,Beneblau,1524417852,[removed],0,1
1301,2018-4-23,2018,4,23,3,8e587d,"How are handwritten (text, numbers, math) datasets gathered? And where to get them?",https://www.reddit.com/r/MachineLearning/comments/8e587d/how_are_handwritten_text_numbers_math_datasets/,xHipster,1524422517,[removed],0,1
1302,2018-4-23,2018,4,23,3,8e59s8,[D] Reproducibility Support Group: Couldn't reproduce a result or idea? Post it here!,https://www.reddit.com/r/MachineLearning/comments/8e59s8/d_reproducibility_support_group_couldnt_reproduce/,rantana,1524422873,"It would be great if we could make a weekly thread to shed light on ideas that have been proposed in research or wherever that have been hard to replicate (including on new data).

One thing that comes to mind is the zoo of replacements for batch normalization:

* Weight Normalization (https://arxiv.org/abs/1602.07868)
* Layer Normalization (https://arxiv.org/abs/1607.06450)
* Group Normalization (https://arxiv.org/abs/1803.08494)

Haven't been able to get any of these working better than the rather clunky batch normalization.",6,14
1303,2018-4-23,2018,4,23,4,8e5kco,"This software is doing something similar to Human-like ""seeing"" and is heavily inspired by Modern Physics.",https://www.reddit.com/r/MachineLearning/comments/8e5kco/this_software_is_doing_something_similar_to/,Pearlnv,1524425451,,0,1
1304,2018-4-23,2018,4,23,4,8e5pmr,"[D] Million Dollar Salaries for AI Researchers? Well, Quants Have Seen This Before",https://www.reddit.com/r/MachineLearning/comments/8e5pmr/d_million_dollar_salaries_for_ai_researchers_well/,inarrears,1524426750,,37,61
1305,2018-4-23,2018,4,23,5,8e5zyl,Survey to improve Question classification classifiers for a classroom application,https://www.reddit.com/r/MachineLearning/comments/8e5zyl/survey_to_improve_question_classification/,carow2222,1524429232,,0,2
1306,2018-4-23,2018,4,23,5,8e606i,[Discussion]Survey about ethics in Data Science,https://www.reddit.com/r/MachineLearning/comments/8e606i/discussionsurvey_about_ethics_in_data_science/,phrich96,1524429289,"Hi I am an undergrad Com Sci Major writing a paper on Ethics in Data Science. If you could fill out this survey it would be much appreciated. It is very short.

https://docs.google.com/forms/d/e/1FAIpQLScTuHyo32NINLs8YW0bDfM1arBib-3JI54DMFVli1TMM-x5CQ/viewform?usp=sf_link",2,3
1307,2018-4-23,2018,4,23,5,8e62r3,[D] Your Brain Is 10 Million Times Slower Than a ComputerSo Why Are You Smarter?,https://www.reddit.com/r/MachineLearning/comments/8e62r3/d_your_brain_is_10_million_times_slower_than_a/,wei_jok,1524429925,,9,0
1308,2018-4-23,2018,4,23,5,8e64nb,How to *use* CNNs,https://www.reddit.com/r/MachineLearning/comments/8e64nb/how_to_use_cnns/,TheBureaucratJosephK,1524430409,[removed],0,1
1309,2018-4-23,2018,4,23,5,8e65so,"ML scientists who got into the field with no prior CS/stats experience, how did you do it? Which online courses/projects/tips would you give to someone who wants to get into the field?",https://www.reddit.com/r/MachineLearning/comments/8e65so/ml_scientists_who_got_into_the_field_with_no/,chubbyostrich,1524430703,[removed],0,1
1310,2018-4-23,2018,4,23,7,8e6vzp,"This software is doing something similar to Human-like ""seeing"" and is heavily inspired by Modern Physics.",https://www.reddit.com/r/MachineLearning/comments/8e6vzp/this_software_is_doing_something_similar_to/,Pearlnv,1524437526,,0,1
1311,2018-4-23,2018,4,23,8,8e72hg,"Implementation of the paper ""Movement Primitives via Optimization"" (Dragan et al., 2016). It includes both the adaptation of trajectories with DMP and learning a better adaptation norm.",https://www.reddit.com/r/MachineLearning/comments/8e72hg/implementation_of_the_paper_movement_primitives/,whiletrue2,1524439263,,0,1
1312,2018-4-23,2018,4,23,8,8e77l9,convert raw video to TensorFlow tfrecord files format,https://www.reddit.com/r/MachineLearning/comments/8e77l9/convert_raw_video_to_tensorflow_tfrecord_files/,whiletrue2,1524440676,,0,1
1313,2018-4-23,2018,4,23,8,8e78l9,[R] Video Compression through Image Interpolation,https://www.reddit.com/r/MachineLearning/comments/8e78l9/r_video_compression_through_image_interpolation/,chisai_mikan,1524440927,,0,17
1314,2018-4-23,2018,4,23,10,8e7nuo,What is a best open-source algorithm for news article summarization?,https://www.reddit.com/r/MachineLearning/comments/8e7nuo/what_is_a_best_opensource_algorithm_for_news/,regpath,1524445224,[removed],0,1
1315,2018-4-23,2018,4,23,10,8e7qfl,Tensorflow Study Plan for Beginners?,https://www.reddit.com/r/MachineLearning/comments/8e7qfl/tensorflow_study_plan_for_beginners/,SIMPLE_EXECUTE,1524445944,[removed],0,1
1316,2018-4-23,2018,4,23,11,8e87t1,A Giant Step in Evolution of AI | Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8e87t1/a_giant_step_in_evolution_of_ai_reinforcement/,LearningFromData,1524450813,,2,1
1317,2018-4-23,2018,4,23,12,8e8dzs,[R] Fast inference of deep neural networks in FPGAs for particle physics,https://www.reddit.com/r/MachineLearning/comments/8e8dzs/r_fast_inference_of_deep_neural_networks_in_fpgas/,SU3xSU2xU1,1524452574,,5,12
1318,2018-4-23,2018,4,23,12,8e8f08,"[R] A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay",https://www.reddit.com/r/MachineLearning/comments/8e8f08/r_a_disciplined_approach_to_neural_network/,downtownslim,1524452845,,20,145
1319,2018-4-23,2018,4,23,13,8e8sjn,Artificial Intelligence: A Summary of Strength and Architecture | My poor attempt to give greater definition to the types of AI to assist with imagining future possibilities,https://www.reddit.com/r/MachineLearning/comments/8e8sjn/artificial_intelligence_a_summary_of_strength_and/,[deleted],1524456928,[deleted],0,1
1320,2018-4-23,2018,4,23,14,8e9501,What is the future of machine learning,https://www.reddit.com/r/MachineLearning/comments/8e9501/what_is_the_future_of_machine_learning/,social789,1524461084,,0,1
1321,2018-4-23,2018,4,23,14,8e95mb,[Project] A collection of popular Data Science Competitions,https://www.reddit.com/r/MachineLearning/comments/8e95mb/project_a_collection_of_popular_data_science/,lifeadvicesponge,1524461304,,1,28
1322,2018-4-23,2018,4,23,14,8e963i,Microsoft Dynamics CRM Software Implementation for Businesses,https://www.reddit.com/r/MachineLearning/comments/8e963i/microsoft_dynamics_crm_software_implementation/,AffluentGlobal,1524461472,,0,1
1323,2018-4-23,2018,4,23,14,8e98vn,Good Textbooks to Learn Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8e98vn/good_textbooks_to_learn_machine_learning/,arjavpatelly,1524462459,[removed],0,1
1324,2018-4-23,2018,4,23,14,8e9apw,Cleanland Hydraulic Sweeping Machine,https://www.reddit.com/r/MachineLearning/comments/8e9apw/cleanland_hydraulic_sweeping_machine/,cleanlandmachinery,1524463147,,0,1
1325,2018-4-23,2018,4,23,15,8e9dz2,[D] Can anyone give an example of non-convex function such as this or function behind this one ?,https://www.reddit.com/r/MachineLearning/comments/8e9dz2/d_can_anyone_give_an_example_of_nonconvex/,geek--god,1524464355,,20,8
1326,2018-4-23,2018,4,23,16,8e9m46,Fake news corpus &amp; Fake news recognition algorithm,https://www.reddit.com/r/MachineLearning/comments/8e9m46/fake_news_corpus_fake_news_recognition_algorithm/,several27,1524467404,[removed],0,1
1327,2018-4-23,2018,4,23,17,8e9uz9,[P] OpenAI baselines ported to pytorch,https://www.reddit.com/r/MachineLearning/comments/8e9uz9/p_openai_baselines_ported_to_pytorch/,rikkajounin,1524470959,"Hi everyone! I decided recently to switch from tensorflow to pytorch for my research projects, but I am not satisfied with the current pytorch implementations of reinforcement learning optimization algorithms like TRPO (i found [this one](https://github.com/ikostrikov/pytorch-trpo) and [this other one](https://github.com/mjacar/pytorch-trpo)), especially when compared with the [OpenAI ones in tensorflow](https://github.com/openai/baselines).

So, I was wondering if it could be useful to port some of the OpenAI baseline implementations to pytorch. I wanted to begin with TRPO and then every other that I will use for my studying/research. Also, if someone is interested in collaborating on this any kind of help will be appreciated. ",16,22
1328,2018-4-23,2018,4,23,17,8e9x8g,[R] [1804.07612] Revisiting Small Batch Training for Deep Neural Networks &lt;-- batch_size&lt;64 yields best stability &amp; generalization,https://www.reddit.com/r/MachineLearning/comments/8e9x8g/r_180407612_revisiting_small_batch_training_for/,evc123,1524471883,,14,34
1329,2018-4-23,2018,4,23,17,8e9zxb,Maths needed for research in AI/RL?,https://www.reddit.com/r/MachineLearning/comments/8e9zxb/maths_needed_for_research_in_airl/,Haithamkhedr,1524473051,[removed],0,1
1330,2018-4-23,2018,4,23,18,8ea7m5,How to compute accuracy for recurrent neural network,https://www.reddit.com/r/MachineLearning/comments/8ea7m5/how_to_compute_accuracy_for_recurrent_neural/,[deleted],1524476144,[deleted],0,1
1331,2018-4-23,2018,4,23,19,8eal4d,Continuous Pellet Chips Fryer Machine Line,https://www.reddit.com/r/MachineLearning/comments/8eal4d/continuous_pellet_chips_fryer_machine_line/,lgsherry,1524481156,,1,1
1332,2018-4-23,2018,4,23,20,8eanjw,Convertor for ssd object detection model from mxnet to caffe,https://www.reddit.com/r/MachineLearning/comments/8eanjw/convertor_for_ssd_object_detection_model_from/,lk05,1524481942,,0,1
1333,2018-4-23,2018,4,23,20,8eaw85,Whats Machine Learning All About?,https://www.reddit.com/r/MachineLearning/comments/8eaw85/whats_machine_learning_all_about/,imarticus_nirmal,1524484725,,0,1
1334,2018-4-23,2018,4,23,21,8eaywi,[R] Looking for papers/books/resources showing current progress of ML/MR/AI in particular fields,https://www.reddit.com/r/MachineLearning/comments/8eaywi/r_looking_for_papersbooksresources_showing/,mr_dicaprio,1524485521,"Hi,

I am looking for some resources (preferably documents, books) that show the current progress of computerization and automation of activities related to *perception and manipulation*, *creativity* and *social intelligence*.

I would be very grateful for any help.

Have a nice day !",1,0
1335,2018-4-23,2018,4,23,21,8eaz1b,[R] What You Must Know Before You Dive Into Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8eaz1b/r_what_you_must_know_before_you_dive_into_machine/,digitalson,1524485564,,0,1
1336,2018-4-23,2018,4,23,21,8eazb2,Metadata Discovery in datasets,https://www.reddit.com/r/MachineLearning/comments/8eazb2/metadata_discovery_in_datasets/,kwambo,1524485637,[removed],0,1
1337,2018-4-23,2018,4,23,21,8eb0hr,Converter for ssd object detection model from Mxnet to Caffe,https://www.reddit.com/r/MachineLearning/comments/8eb0hr/converter_for_ssd_object_detection_model_from/,lk05,1524485963,,0,1
1338,2018-4-23,2018,4,23,21,8eb11s,Aluminum Die Casting Machine |Machinery - Rapid Flow,https://www.reddit.com/r/MachineLearning/comments/8eb11s/aluminum_die_casting_machine_machinery_rapid_flow/,RapidFlowIndia1,1524486124,[removed],0,1
1339,2018-4-23,2018,4,23,22,8eb9r4,"A.I. Researchers Are Making More Than $1 Million, Even at a Nonprofit",https://www.reddit.com/r/MachineLearning/comments/8eb9r4/ai_researchers_are_making_more_than_1_million/,jonfla,1524488534,,0,1
1340,2018-4-23,2018,4,23,22,8ebb7r,Market Research Using Conjoint Analysis In R,https://www.reddit.com/r/MachineLearning/comments/8ebb7r/market_research_using_conjoint_analysis_in_r/,martmull,1524488911,,0,1
1341,2018-4-23,2018,4,23,22,8ebfrt,[R] 3 Reasons Why Machine Learning Should Matter to B2C Businesses Too,https://www.reddit.com/r/MachineLearning/comments/8ebfrt/r_3_reasons_why_machine_learning_should_matter_to/,magneticono,1524490083,,0,1
1342,2018-4-23,2018,4,23,23,8ebosk,A Comparative Analysis of ChatBots APIs,https://www.reddit.com/r/MachineLearning/comments/8ebosk/a_comparative_analysis_of_chatbots_apis/,bgrebeniuk,1524492281,,0,1
1343,2018-4-23,2018,4,23,23,8ebt2o,[D] Write an article before publication to get feedback,https://www.reddit.com/r/MachineLearning/comments/8ebt2o/d_write_an_article_before_publication_to_get/,creiser,1524493241,"I am a M.Sc. student who did a ML project in his own time. The project is going well so far and I am now thinking about next steps. My main worry right now is that my whole idea is not novel at all and just a rediscovery. I already spent quite some time on Google Scholar to try to find similar approaches, but the chance is still pretty high that I might have missed something, especially considering how inexperienced I am. The usual solution for that kind of problem is probably a supervisor. Indeed there might be some people at my university that might be helpful in that regard but to get that kind of connection might take some time. I am wondering whether I could write a quick, informal summary of my idea and share it here to get some feedback.

Assuming my idea is novel and useful \(which is yet to be determined\) is it safe to post it online?

I remember that there was a ""Share your research idea"" thread here and below it there was some discussion whether that is something that you can actually safely do. Unfortunately I cannot find the thread anymore.",6,8
1344,2018-4-23,2018,4,23,23,8ebwsj,Help in Reading Research Papers,https://www.reddit.com/r/MachineLearning/comments/8ebwsj/help_in_reading_research_papers/,havetolearn,1524494132,[removed],0,1
1345,2018-4-23,2018,4,23,23,8ec0h9,[P] PyTorch-GAN: Collection of Generative Adversarial Networks Implemented in PyTorch,https://www.reddit.com/r/MachineLearning/comments/8ec0h9/p_pytorchgan_collection_of_generative_adversarial/,Eriklindernoren,1524494982,,12,181
1346,2018-4-23,2018,4,23,23,8ec0xr,NVIDIA: AI Reconstructs Photos with Realistic Results,https://www.reddit.com/r/MachineLearning/comments/8ec0xr/nvidia_ai_reconstructs_photos_with_realistic/,SamStringTheory,1524495089,,1,1
1347,2018-4-24,2018,4,24,0,8ecc2a,Which path to choose for a ML career abroad?,https://www.reddit.com/r/MachineLearning/comments/8ecc2a/which_path_to_choose_for_a_ml_career_abroad/,JelluPuddingFluff,1524497532,[removed],0,1
1348,2018-4-24,2018,4,24,0,8ecirt,Is there a game bot that can be setup and works with things.,https://www.reddit.com/r/MachineLearning/comments/8ecirt/is_there_a_game_bot_that_can_be_setup_and_works/,Rudyon,1524498973,[removed],0,1
1349,2018-4-24,2018,4,24,2,8ed1qq,Implementing a Soft-Margin Kernelized Support Vector Machine Binary Classifier with Quadratic Programming in R and Python,https://www.reddit.com/r/MachineLearning/comments/8ed1qq/implementing_a_softmargin_kernelized_support/,SandipanDeyUMBC,1524503071,,0,1
1350,2018-4-24,2018,4,24,2,8ed7ua,[R] Accelerating Deep Neuroevolution: Train Atari in Hours on a Single Personal Computer (UberAI),https://www.reddit.com/r/MachineLearning/comments/8ed7ua/r_accelerating_deep_neuroevolution_train_atari_in/,wei_jok,1524504344,,37,233
1351,2018-4-24,2018,4,24,2,8edalv,[P] Pytorch Implementation and Pre-trained Models of OpenAI's PixelCNN++,https://www.reddit.com/r/MachineLearning/comments/8edalv/p_pytorch_implementation_and_pretrained_models_of/,DanielHendrycks,1524504941,,0,10
1352,2018-4-24,2018,4,24,2,8edhly,[R] Feedback Networks,https://www.reddit.com/r/MachineLearning/comments/8edhly/r_feedback_networks/,downtownslim,1524506385,,10,23
1353,2018-4-24,2018,4,24,3,8edter,How does one create a data set in pytorch and save it into a file to later be used?,https://www.reddit.com/r/MachineLearning/comments/8edter/how_does_one_create_a_data_set_in_pytorch_and/,real_charlie_parker,1524508841,[removed],0,1
1354,2018-4-24,2018,4,24,4,8edzo1,"Deep learning engineers, do you like what you do? What are some things you particularly like/dislike about the field?",https://www.reddit.com/r/MachineLearning/comments/8edzo1/deep_learning_engineers_do_you_like_what_you_do/,chubbyostrich,1524510159,[removed],0,1
1355,2018-4-24,2018,4,24,4,8ee02f,[D] Initiative to establish a European Lab for Learning Intelligent Systems,https://www.reddit.com/r/MachineLearning/comments/8ee02f/d_initiative_to_establish_a_european_lab_for/,konasj,1524510237,,4,18
1356,2018-4-24,2018,4,24,4,8ee0ru,Initiative to establish a European Lab for Learning &amp; Intelligent Systems,https://www.reddit.com/r/MachineLearning/comments/8ee0ru/initiative_to_establish_a_european_lab_for/,demonFudgePies,1524510374,,0,1
1357,2018-4-24,2018,4,24,4,8ee183,Open Letter: Initiative to establish a European Lab for Learning &amp; Intelligent Systems,https://www.reddit.com/r/MachineLearning/comments/8ee183/open_letter_initiative_to_establish_a_european/,[deleted],1524510467,[deleted],0,1
1358,2018-4-24,2018,4,24,4,8ee1mr,"I built a simple neural network for univariate linear regression, and while it always achieves high r^2 with momentum, I have extremely high variance in the r^2 when I remove momentum. Why is this?",https://www.reddit.com/r/MachineLearning/comments/8ee1mr/i_built_a_simple_neural_network_for_univariate/,TissueReligion,1524510550,[removed],0,1
1359,2018-4-24,2018,4,24,4,8ee1vg,[N] Open Letter: Initiative to establish a European Lab for Learning &amp; Intelligent Systems,https://www.reddit.com/r/MachineLearning/comments/8ee1vg/n_open_letter_initiative_to_establish_a_european/,[deleted],1524510585,[deleted],0,1
1360,2018-4-24,2018,4,24,4,8ee256,[N] Open Letter: Initiative to establish a European Lab for Learning &amp; Intelligent Systems,https://www.reddit.com/r/MachineLearning/comments/8ee256/n_open_letter_initiative_to_establish_a_european/,[deleted],1524510636,[deleted],0,1
1361,2018-4-24,2018,4,24,5,8eejzh,[N] Keras style model.summary() API in PyTorch,https://www.reddit.com/r/MachineLearning/comments/8eejzh/n_keras_style_modelsummary_api_in_pytorch/,[deleted],1524514447,[deleted],0,1
1362,2018-4-24,2018,4,24,5,8eekaz,[P] Keras style model.summary() API in PyTorch,https://www.reddit.com/r/MachineLearning/comments/8eekaz/p_keras_style_modelsummary_api_in_pytorch/,sksq9,1524514519,,10,23
1363,2018-4-24,2018,4,24,5,8eeox8,[P] Generating multi-instrumental polyphonic music  survey,https://www.reddit.com/r/MachineLearning/comments/8eeox8/p_generating_multiinstrumental_polyphonic_music/,davda54,1524515505,"Hey, 

I've implemented a generative model for music as my bachelor thesis and now I need to rate the results. I'd be very happy if you put your 5 minutes into this small survey :) 

http://dotaznik.neqindi.cz/index.php?lang=en

The model uses a highly preprocessed MIDI as the I/O. The architecture is a standard LSTM with layer normalization to speed up the training. I can give more details if you want  :) ",12,7
1364,2018-4-24,2018,4,24,6,8eexys,"Building Data Science Capabilities That Scale - Free Webinar with DataScience.com founder, Ian Swanson",https://www.reddit.com/r/MachineLearning/comments/8eexys/building_data_science_capabilities_that_scale/,TheDataIncubator,1524517482,,0,2
1365,2018-4-24,2018,4,24,6,8ef012,[P] Generating image segmentation datasets with Unreal Engine 4,https://www.reddit.com/r/MachineLearning/comments/8ef012/p_generating_image_segmentation_datasets_with/,JeffOnReddit,1524517952,"Hello guys,

I am currently doing my master on image segmentation networks and I've been working on generating my own datasets to avoid/augment the manual labeling work. I am applying those networks to industry domains that have no existing datasets and needed such a tool to avoid multiple weeks/months on labeling. I think that it may be useful to others working with those type of networks and who have the same kind of issues.

A summary of what i'm doing: https://medium.com/@jeff_97181/generating-image-segmentation-datasets-with-unreal-engine-4-2b5b9f75da34
I will try to do more documentation if there is an interest from the community.",9,19
1366,2018-4-24,2018,4,24,7,8efke1,Is This Loss? A Tensorflow Lite app will tell you,https://www.reddit.com/r/MachineLearning/comments/8efke1/is_this_loss_a_tensorflow_lite_app_will_tell_you/,starly396,1524522587,,0,1
1367,2018-4-24,2018,4,24,7,8efpb6,[P] TensorFlow backend for TensorFlow.js via Node.js,https://www.reddit.com/r/MachineLearning/comments/8efpb6/p_tensorflow_backend_for_tensorflowjs_via_nodejs/,baylearn,1524523796,,0,1
1368,2018-4-24,2018,4,24,8,8eftdv,[P] Implementing Stochastic Weight Averaging,https://www.reddit.com/r/MachineLearning/comments/8eftdv/p_implementing_stochastic_weight_averaging/,hortonhearsafoo,1524524792,,0,3
1369,2018-4-24,2018,4,24,8,8eg2vm,[P] NVIDIA-Wavenet: Better Speech Synthesis Using GPU-Enabled WaveNet Inference,https://www.reddit.com/r/MachineLearning/comments/8eg2vm/p_nvidiawavenet_better_speech_synthesis_using/,chisai_mikan,1524527186,,1,9
1370,2018-4-24,2018,4,24,8,8eg3er,[N] The Emerging Science of Computational Psychiatry,https://www.reddit.com/r/MachineLearning/comments/8eg3er/n_the_emerging_science_of_computational_psychiatry/,lopespm,1524527307,,3,21
1371,2018-4-24,2018,4,24,8,8eg3og,[R] Image Inpainting for Irregular Holes Using Partial Convolutions,https://www.reddit.com/r/MachineLearning/comments/8eg3og/r_image_inpainting_for_irregular_holes_using/,gannygangans,1524527379,,9,29
1372,2018-4-24,2018,4,24,9,8eg8jk,Deep Learning Identifies High-z Galaxies in a Central Blue Nugget Phase in a Characteristic Mass Range,https://www.reddit.com/r/MachineLearning/comments/8eg8jk/deep_learning_identifies_highz_galaxies_in_a/,GreenFrog76,1524528628,,0,1
1373,2018-4-24,2018,4,24,9,8egars,[Discussion] Learning London Dating Profiles,https://www.reddit.com/r/MachineLearning/comments/8egars/discussion_learning_london_dating_profiles/,audio-nerd,1524529162,,0,0
1374,2018-4-24,2018,4,24,9,8egh2a,"How can I build a intelligent ai chat bot that has a great learning ability, are there any good tutorials online?",https://www.reddit.com/r/MachineLearning/comments/8egh2a/how_can_i_build_a_intelligent_ai_chat_bot_that/,ReasonableFat,1524530852,[removed],0,1
1375,2018-4-24,2018,4,24,9,8egis8,Can you guys recommend good reinforcement/imitation learning research projects?,https://www.reddit.com/r/MachineLearning/comments/8egis8/can_you_guys_recommend_good/,aldentecapone,1524531307,[removed],0,2
1376,2018-4-24,2018,4,24,10,8egjuw,Tensorflow.js Explained,https://www.reddit.com/r/MachineLearning/comments/8egjuw/tensorflowjs_explained/,funmaster11,1524531612,,0,1
1377,2018-4-24,2018,4,24,10,8egot1,[D] Color consistency regularization in StackGAN++,https://www.reddit.com/r/MachineLearning/comments/8egot1/d_color_consistency_regularization_in_stackgan/,RickMcCoy,1524532970,"In the StackGAN++ paper, they introduce a color-consistency regularization term ""to keep samples generated from the same input at different generators more consistent in color and thus to improve the quality of the generated images"". It is calculated as followed:

Lambda1 * (mean1 - mean2)^2 + Lambda2 * (variance1 - variance2)^2

Where mean and variance are of pixels of an image, and lambdas are constants.

However, this term does not equal to zero when calculated with real data. Shrinking the original image with max pooling changes the mean, and average pooling changes the variance.

TL;DR: Why is there a regularization term that doesn't equal zero?",0,2
1378,2018-4-24,2018,4,24,10,8egt4p,How Deep The Deep Learning Is? - Measuring The Depth of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8egt4p/how_deep_the_deep_learning_is_measuring_the_depth/,LearningFromData,1524534135,,0,1
1379,2018-4-24,2018,4,24,12,8ehbas,Future of ML in Healthcare?,https://www.reddit.com/r/MachineLearning/comments/8ehbas/future_of_ml_in_healthcare/,fearful_ai_lad,1524538968,[removed],0,1
1380,2018-4-24,2018,4,24,12,8ehcgp,The birth of AGI: How machines will learn to express meaning,https://www.reddit.com/r/MachineLearning/comments/8ehcgp/the_birth_of_agi_how_machines_will_learn_to/,keyuno,1524539279,,0,1
1381,2018-4-24,2018,4,24,12,8ehhir,"[D] I have an interesting application for ML I think I could potentially monetize, what is the best open-source etiquette?",https://www.reddit.com/r/MachineLearning/comments/8ehhir/d_i_have_an_interesting_application_for_ml_i/,jer_pint,1524540738,"I've been considering taking a side project one step further lately, and am curious to know your opinion on the matter. Most algorithms I'd be using would be an application of a lot of state of the art open-source code. In the case of MIT license, you are free to do what you please with the code, including monetizing. So how can I reconcile having a super cool algorithm with a super cool application, generate revenue from it, and still somehow contribute back to the awesome open source community?  Does it make sense to publish all my code in that context?

Any thoughts or feedback from personal experience is welcome!",12,8
1382,2018-4-24,2018,4,24,12,8ehmnt,[R][ICLR 2018 (Oral)] Zero-Shot Visual Imitation,https://www.reddit.com/r/MachineLearning/comments/8ehmnt/riclr_2018_oral_zeroshot_visual_imitation/,downtownslim,1524542303,,2,11
1383,2018-4-24,2018,4,24,13,8ehow2,[N] Machine learning talks wanted for Strange Loop 2018!,https://www.reddit.com/r/MachineLearning/comments/8ehow2/n_machine_learning_talks_wanted_for_strange_loop/,alexdmiller,1524542951,,0,0
1384,2018-4-24,2018,4,24,13,8ehrul,Dynamics NAV Is a Fully Integrated ERP Solution That Bridges the Gap Between You &amp; Your Partners,https://www.reddit.com/r/MachineLearning/comments/8ehrul/dynamics_nav_is_a_fully_integrated_erp_solution/,AffluentGlobal,1524543852,,0,1
1385,2018-4-24,2018,4,24,13,8ehx44,do i need physics and math,https://www.reddit.com/r/MachineLearning/comments/8ehx44/do_i_need_physics_and_math/,agharibkhanyan,1524545558,[removed],0,1
1386,2018-4-24,2018,4,24,13,8ehxsk,[D] What is your most impressive knowledge distillation story?,https://www.reddit.com/r/MachineLearning/comments/8ehxsk/d_what_is_your_most_impressive_knowledge/,RavlaAlvar,1524545780,,9,4
1387,2018-4-24,2018,4,24,14,8ei6df,ML data annotations made super easy.,https://www.reddit.com/r/MachineLearning/comments/8ei6df/ml_data_annotations_made_super_easy/,gajju3588,1524548727,,0,1
1388,2018-4-24,2018,4,24,15,8eie4z,Future of Machine Learning with AR and VR,https://www.reddit.com/r/MachineLearning/comments/8eie4z/future_of_machine_learning_with_ar_and_vr/,Zeolearn,1524551493,,0,1
1389,2018-4-24,2018,4,24,15,8eiebc,What are new developments in Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/8eiebc/what_are_new_developments_in_reinforcement/,russarthur,1524551551,[removed],0,1
1390,2018-4-24,2018,4,24,16,8eijnn,Employing machine learning to create wear and corrosion resistant metallic glass,https://www.reddit.com/r/MachineLearning/comments/8eijnn/employing_machine_learning_to_create_wear_and/,XBorras,1524553564,,0,2
1391,2018-4-24,2018,4,24,17,8eitk2,[P] Learning London Dating Profiles,https://www.reddit.com/r/MachineLearning/comments/8eitk2/p_learning_london_dating_profiles/,wei_jok,1524557545,,1,24
1392,2018-4-24,2018,4,24,17,8eitvd,When #machineLearning learns #basketball ,https://www.reddit.com/r/MachineLearning/comments/8eitvd/when_machinelearning_learns_basketball/,odingah,1524557688,,0,2
1393,2018-4-24,2018,4,24,17,8eizmb,VLocNet++: Deep Multitask Learning for Semantic Visual Localization and Odometry,https://www.reddit.com/r/MachineLearning/comments/8eizmb/vlocnet_deep_multitask_learning_for_semantic/,nuradwan,1524560109,,0,1
1394,2018-4-24,2018,4,24,18,8ej2a3,[D] Variational nets without sampling,https://www.reddit.com/r/MachineLearning/comments/8ej2a3/d_variational_nets_without_sampling/,svantana,1524561131,"Looking into VAE, I was disappointed that it includes actually sampling the stochastic variables. To me, it would make more sense to instead try to estimate passing the probability distribution through the network. Especially if the loss is MSE, the expected loss is just a function of output expectation and (co-)variance, which are easy to pass through affine functions. Activation inputs should be approximately gaussian for large-ish nets (because CLT) so expectation and variance can be approximated using a gaussian assumption. Other loss functions such as log-likelihood depend on the distribution shape but could also be estimated using a gaussian assumption.

So now for my question: Surely this has been tried already? It seems obvious enough. I have tried to search in the literature but I haven't found anything. If it was tried, what is the reason it doesn't work as well as VAE?",16,16
1395,2018-4-24,2018,4,24,18,8ej2j4,[D] Facebook Visdom vs Google Tensorboard discussion thread,https://www.reddit.com/r/MachineLearning/comments/8ej2j4/d_facebook_visdom_vs_google_tensorboard/,rikkajounin,1524561220,"I'm using pytorch and I'm looking for a good visualization framework. Previously I used [Tensorboard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard), but i just discovered Facebook [Visdom](https://github.com/facebookresearch/visdom) and it also seems nice.

Which one do you think it's better and what are the pro/cons of each of them?",25,63
1396,2018-4-24,2018,4,24,18,8ej6k1,[D] Looking for a paper that describes learning a simulated baseball pitch,https://www.reddit.com/r/MachineLearning/comments/8ej6k1/d_looking_for_a_paper_that_describes_learning_a/,sweatyCameltoe,1524562795,"Hi

I was looking at some videos a couple of weeks ago and came across a video of a simulated environment where a ""stick figure"" or simulated creature learned how to perform a baseball pitch. The reward function was how close it could get the ball to a point in space. However, when no idea was given about the motion, the creature learned to run towards the ball, as it was less difficult \(given its initialization\) to learn how to walk than to learn how to throw the ball. 

If someone can tell me which video / paper this is I would be very thankful.

Thanks ",2,3
1397,2018-4-24,2018,4,24,19,8ejd17,[R] Rethinking Reality: The Circular Relationship Between Artificial and Real,https://www.reddit.com/r/MachineLearning/comments/8ejd17/r_rethinking_reality_the_circular_relationship/,digitalson,1524565310,,0,1
1398,2018-4-24,2018,4,24,20,8ejnbe,"Machine Vision Market Size Study, by Product (PC Based, Smart camera based) by Application (Quality &amp; Inspection, Positioning &amp; Guidance, Measurement, Identification) by Regional Forecasts 2017-2025",https://www.reddit.com/r/MachineLearning/comments/8ejnbe/machine_vision_market_size_study_by_product_pc/,alanmarsh1307,1524568938,,0,1
1399,2018-4-24,2018,4,24,20,8ejnzi,Is it possible to do a coarse-grained max-pool /gating differentiably? (details inside),https://www.reddit.com/r/MachineLearning/comments/8ejnzi/is_it_possible_to_do_a_coarsegrained_maxpool/,Screye,1524569159,,0,1
1400,2018-4-24,2018,4,24,21,8ejx8h,Jeeves The AI Plays Hearthstone,https://www.reddit.com/r/MachineLearning/comments/8ejx8h/jeeves_the_ai_plays_hearthstone/,JeevesTheAI,1524572016,,0,1
1401,2018-4-24,2018,4,24,21,8ejxe7,Shampoo Packing Machine Suppliers,https://www.reddit.com/r/MachineLearning/comments/8ejxe7/shampoo_packing_machine_suppliers/,lgsherry,1524572061,,1,1
1402,2018-4-24,2018,4,24,21,8ek04d,GPU ejecting during training in Keras,https://www.reddit.com/r/MachineLearning/comments/8ek04d/gpu_ejecting_during_training_in_keras/,AlganTrader,1524572867,[removed],0,1
1403,2018-4-24,2018,4,24,21,8ek1o4,[D] Machine learning approach to finding the most common pair of vectors aka high dimensional density estimation,https://www.reddit.com/r/MachineLearning/comments/8ek1o4/d_machine_learning_approach_to_finding_the_most/,mesmer_adama,1524573316,"I've been thinking about this problem for some time but can't come up with a compelling answer or find appropriate papers discussing this specific issue. So maybe you can help me?

Given a sequence of vectors (video, sound, word embedded text) find the approximately most common successive pair of vectors. How would you do this? 

My best approaches is k-means or maybe some sort of RNN solution. The problem with k-means is that I can't find any guarantees that it will actually find the most common pair rather than just a couple of cluster centroids.

In both approaches I would start with concatenating the vectors of the pair into a new vector and then try to find the mode of the density distribution of the new vectors w.

    sequence = (v_1, v_2, ..., v_n)
    pair_i = (v_i, v_i+1)
    w_i = cat(v_i, v_i+1)

But high dimensional density estimation is not that easy and maybe there are some other clever solutions. Can anyone in this subreddit come up with a solution?",22,25
1404,2018-4-24,2018,4,24,21,8ek3yi,Can you explain how a topic model is learnt?,https://www.reddit.com/r/MachineLearning/comments/8ek3yi/can_you_explain_how_a_topic_model_is_learnt/,havetolearn,1524573982,[removed],0,1
1405,2018-4-24,2018,4,24,22,8ekejd,Training a Simple Linear Regression Model From Scratch,https://www.reddit.com/r/MachineLearning/comments/8ekejd/training_a_simple_linear_regression_model_from/,lord-bazooka,1524576656,,0,1
1406,2018-4-24,2018,4,24,22,8eki6j,Plotting KNN with more than 3 features,https://www.reddit.com/r/MachineLearning/comments/8eki6j/plotting_knn_with_more_than_3_features/,e-hamza,1524577524,[removed],0,1
1407,2018-4-24,2018,4,24,22,8ekkkn,Machine learning in Cricket,https://www.reddit.com/r/MachineLearning/comments/8ekkkn/machine_learning_in_cricket/,charizard_me,1524578097,[removed],0,1
1408,2018-4-24,2018,4,24,23,8ekmqy,Scientists plan huge European AI hub to compete with US,https://www.reddit.com/r/MachineLearning/comments/8ekmqy/scientists_plan_huge_european_ai_hub_to_compete/,skervim,1524578621,,124,269
1409,2018-4-24,2018,4,24,23,8ekq68,"We made a platform to get your palm read accurately by trained artificial intelligence! Give it a go, reviews and feedback are welcome :)",https://www.reddit.com/r/MachineLearning/comments/8ekq68/we_made_a_platform_to_get_your_palm_read/,readmypalm,1524579401,,0,0
1410,2018-4-24,2018,4,24,23,8ekqfc,[D] Training a Simple Linear Regression Model From Scratch,https://www.reddit.com/r/MachineLearning/comments/8ekqfc/d_training_a_simple_linear_regression_model_from/,lord-bazooka,1524579455,,0,0
1411,2018-4-24,2018,4,24,23,8ekv5j,[1804.08198] A neural interlingua for multilingual machine translation,https://www.reddit.com/r/MachineLearning/comments/8ekv5j/180408198_a_neural_interlingua_for_multilingual/,question99,1524580526,,0,1
1412,2018-4-24,2018,4,24,23,8ekxrn,SOTA in compressing networks?,https://www.reddit.com/r/MachineLearning/comments/8ekxrn/sota_in_compressing_networks/,adagrad,1524581118,[removed],0,1
1413,2018-4-24,2018,4,24,23,8ekz55,"[P] ModelChimp: Platform for tracking, sharing and collaborating on your machine learning models",https://www.reddit.com/r/MachineLearning/comments/8ekz55/p_modelchimp_platform_for_tracking_sharing_and/,samzer,1524581430,,5,11
1414,2018-4-24,2018,4,24,23,8ekzx6,Tensorflow for Manufacturing Quality Control,https://www.reddit.com/r/MachineLearning/comments/8ekzx6/tensorflow_for_manufacturing_quality_control/,johnmountain,1524581595,,0,1
1415,2018-4-25,2018,4,25,0,8el970,Moving to Luxembourg | European Moving - International Removals,https://www.reddit.com/r/MachineLearning/comments/8el970/moving_to_luxembourg_european_moving/,JanetteMossu337,1524583597,,0,1
1416,2018-4-25,2018,4,25,0,8ele5m,[R] Black-box Adversarial Attacks with Limited Queries and Information,https://www.reddit.com/r/MachineLearning/comments/8ele5m/r_blackbox_adversarial_attacks_with_limited/,anishathalye,1524584646,,1,7
1417,2018-4-25,2018,4,25,0,8elib8,Visual Domain Adaptation Challenge 2018,https://www.reddit.com/r/MachineLearning/comments/8elib8/visual_domain_adaptation_challenge_2018/,nkaushik1,1524585528,[removed],0,1
1418,2018-4-25,2018,4,25,1,8ell0s,Someone to learn ML/DL together,https://www.reddit.com/r/MachineLearning/comments/8ell0s/someone_to_learn_mldl_together/,xtreamtim987,1524586087,[removed],0,1
1419,2018-4-25,2018,4,25,1,8elmd8,[D] Anyone having trouble reading a particular paper ? Post it here and we'll help figure out any parts you are stuck on | Anyone having trouble finding papers on a particular concept ? Post it here and we'll help you find papers on that topic [ROUND 2],https://www.reddit.com/r/MachineLearning/comments/8elmd8/d_anyone_having_trouble_reading_a_particular/,BatmantoshReturns,1524586370,"This is a Round 2 of the paper help and paper find threads I posted in the previous weeks

https://www.reddit.com/r/MachineLearning/comments/8b4vi0/d_anyone_having_trouble_reading_a_particular/ 

https://www.reddit.com/r/MachineLearning/comments/8bwuyg/d_anyone_having_trouble_finding_papers_on_a/ 

I made a read-only subreddit to cataloge the main threads from these posts for easy look up

https://www.reddit.com/r/MLPapersQandA/

I decided to combine the two types of threads since they're pretty similar in concept. 

I'll only be answering questions that were submitted within 24 hours of this being posted (9:30 am PST). Other people will be answering questions too like last time, but since posts are only on the front page for about a day, if you don't post a question within 24 hours you'll probably have to wait until Round 3 of this, which will happen in 2-3 weeks. To follow tentative dates, you can check this subreddit I use to catalog the topics discussed in my paperHelp/paperFind/paperWrite posts.

I'll only be answering questions that follow the format below. The purpose of this format is to minimize the time it takes to answer a question, maximizing the number of questions that'll be answered. The idea is that if someone who knows the answer reads your post, they should at least know what your asking for without having to open the paper. There are likely experts who pass by this thread, who may be too limited on time to open a paper link, but would be willing to spend a minute or two to answer a question.  


-----

FORMAT FOR HELP ON A PARTICULAR PAPER 

Title:

Link to Paper:

Summary in your own words of what this paper is about, and what exactly are you stuck on:

Additional info to speed up understanding/ finding answers. For example, if there's an equation whose components are explained through out the paper, make a mini glossary of said equation:  

What attempts have you made so far to figure out the question: 

Your best guess to what's the answer: 

(optional) any additional info or resources to help answer your question (will increase chance of getting your question answered): 

----

FORMAT FOR FINDING PAPERS ON A PARTICULAR TOPIC 

Description of the concept you want to find papers on: 

Any papers you found so far about your concept or close to your concept:

All the search queries you have tried so far in trying to find papers for that concept: 

(optional) any additional info or resources to help find papers  (will increase chance of getting your question answered): 

----

Feel free to piggyback on any threads to ask your own questions, just follow the corresponding formats above. 
",94,115
1420,2018-4-25,2018,4,25,1,8elo5n,[D] SOTA in compressing networks?,https://www.reddit.com/r/MachineLearning/comments/8elo5n/d_sota_in_compressing_networks/,adagrad,1524586758,"What are people doing for network compression these days? I am interested both in pruning a pre-trained network and training from scratch, with an eye toward using these networks on embedded devices.
",5,15
1421,2018-4-25,2018,4,25,2,8em184,"[R] 2nd Workshop on Neural Abstract Machines &amp; Program Induction @ ICML, IJCAI/ECAI, AAMAS",https://www.reddit.com/r/MachineLearning/comments/8em184/r_2nd_workshop_on_neural_abstract_machines/,_rockt,1524589455,,1,11
1422,2018-4-25,2018,4,25,2,8em3vm,This kid makes videos about Tensorflow and big questions of Machine Learning. I am already a huge fan.,https://www.reddit.com/r/MachineLearning/comments/8em3vm/this_kid_makes_videos_about_tensorflow_and_big/,hill-jayman,1524590004,,0,0
1423,2018-4-25,2018,4,25,2,8em4e6,[R][ICLR 2018] Understanding Short-Horizon Bias in Stochastic Meta-Optimization,https://www.reddit.com/r/MachineLearning/comments/8em4e6/riclr_2018_understanding_shorthorizon_bias_in/,downtownslim,1524590104,,0,10
1424,2018-4-25,2018,4,25,2,8em6v8,[D]This kid makes videos about Tensorflow and big questions of AI. I am already a huge fan.,https://www.reddit.com/r/MachineLearning/comments/8em6v8/dthis_kid_makes_videos_about_tensorflow_and_big/,hill-jayman,1524590642,"This little boy is amazing. Check him out:

[https://www.youtube.com/watch?v=h5iLZGHYMts](https://www.youtube.com/watch?v=h5iLZGHYMts)",6,0
1425,2018-4-25,2018,4,25,3,8emjn4,"Want to see software doing something similar to Human-like ""seeing""  then watch Pearlnaturalvision on FB or Youtube (V5.3 or V4) since I can't post it here.",https://www.reddit.com/r/MachineLearning/comments/8emjn4/want_to_see_software_doing_something_similar_to/,Pearlnv,1524593253,[removed],0,1
1426,2018-4-25,2018,4,25,3,8emx94,Can LSTM/CNN perform good in less corpus?,https://www.reddit.com/r/MachineLearning/comments/8emx94/can_lstmcnn_perform_good_in_less_corpus/,deepankar27,1524596037,[removed],0,1
1427,2018-4-25,2018,4,25,4,8emzno,"""You Are Your Photographs: Detecting Multiple Identities of Vendors in the Darknet Marketplaces"", Wang et al 2018",https://www.reddit.com/r/MachineLearning/comments/8emzno/you_are_your_photographs_detecting_multiple/,gwern,1524596541,,0,1
1428,2018-4-25,2018,4,25,4,8en4hl,[Project] Organize experiments and automate ML workflow - Looking for beta users,https://www.reddit.com/r/MachineLearning/comments/8en4hl/project_organize_experiments_and_automate_ml/,StillSilc,1524597543,[removed],0,1
1429,2018-4-25,2018,4,25,4,8en7r4,The Fall of RNNs and LSTMs,https://www.reddit.com/r/MachineLearning/comments/8en7r4/the_fall_of_rnns_and_lstms/,gagejustins,1524598230,,0,1
1430,2018-4-25,2018,4,25,4,8endb6,How to cluster product names,https://www.reddit.com/r/MachineLearning/comments/8endb6/how_to_cluster_product_names/,atinesh229,1524599383,[removed],0,1
1431,2018-4-25,2018,4,25,5,8ennkl,Audio Classification : A Convolutional Neural Network Approach,https://www.reddit.com/r/MachineLearning/comments/8ennkl/audio_classification_a_convolutional_neural/,myouness,1524601562,,0,1
1432,2018-4-25,2018,4,25,6,8enxaf,PyTorch 0.4.0 released,https://www.reddit.com/r/MachineLearning/comments/8enxaf/pytorch_040_released/,pjansson,1524603632,,0,1
1433,2018-4-25,2018,4,25,6,8eo154,"[N] PyTorch v0.4: Windows support, zero-dimensional Tensors, Tensor-Variable merge, CuDNN 7.1 and more",https://www.reddit.com/r/MachineLearning/comments/8eo154/n_pytorch_v04_windows_support_zerodimensional/,panzerex,1524604449,"Tensor/Variable merge specifically is pretty big for me!

More: https://github.com/pytorch/pytorch/releases/tag/v0.4.0",77,250
1434,2018-4-25,2018,4,25,6,8eo8hf,[Q] Mobile options,https://www.reddit.com/r/MachineLearning/comments/8eo8hf/q_mobile_options/,arif_sohaib,1524606123,[removed],0,1
1435,2018-4-25,2018,4,25,6,8eo9dh,OpenSeq2Seq v0.2: Toolkit for Distributed and Mixed-Precision Training of Sequence-to-Sequence Models,https://www.reddit.com/r/MachineLearning/comments/8eo9dh/openseq2seq_v02_toolkit_for_distributed_and/,gizcard,1524606331,,0,1
1436,2018-4-25,2018,4,25,6,8eoa71,[R] A neural interlingua for multilingual machine translation,https://www.reddit.com/r/MachineLearning/comments/8eoa71/r_a_neural_interlingua_for_multilingual_machine/,question99,1524606501,,0,8
1437,2018-4-25,2018,4,25,7,8eodbl,"So i m a 3rd year computer science graduate student, and am fascinated by the concept of artificial intelligence and machine learning and am keen on learning both of them.",https://www.reddit.com/r/MachineLearning/comments/8eodbl/so_i_m_a_3rd_year_computer_science_graduate/,Jaxusking,1524607236,[removed],0,1
1438,2018-4-25,2018,4,25,7,8eok7g,[D] How resistant is CNN towards invertable (one-to-one) transformations made to input ?,https://www.reddit.com/r/MachineLearning/comments/8eok7g/d_how_resistant_is_cnn_towards_invertable/,Santoshr93,1524608877,"I was working on a Markov model in one of my project for time series data prediction and thought of giving CNN a try for it. accorting to [this paper](https://arxiv.org/pdf/1506.00327.pdf) time series data can be converted to images which can then theoretically be fed into CNN. How ever these transformations to time series data does not seem to be invertable (with one to one map). 

So this led me to the question, in general, how resistant are CNN to me applying a transformation to the initial set of test data (basically scrambling the data but still 100% retrievable since it can be mapped back to the original image ), where the transformation is one-to-one? 

I googled, but could not find any answer !

Thanks in advance ! 

PS: am a theoretical physics student, which makes me no expert in ML, so i understand this might trivial or obvious question !",7,2
1439,2018-4-25,2018,4,25,7,8eonvn,[D] PyTorch 0.4.0 Migration Guide,https://www.reddit.com/r/MachineLearning/comments/8eonvn/d_pytorch_040_migration_guide/,[deleted],1524609779,[deleted],0,1
1440,2018-4-25,2018,4,25,7,8eoo2u,[D] PyTorch v0.4 Migration Guide,https://www.reddit.com/r/MachineLearning/comments/8eoo2u/d_pytorch_v04_migration_guide/,sksq9,1524609829,,0,16
1441,2018-4-25,2018,4,25,8,8ep130,[D] How does autograd work?,https://www.reddit.com/r/MachineLearning/comments/8ep130/d_how_does_autograd_work/,ConfuciusBateman,1524612674,"I'm looking into various automatic differentiation implementations, and I'm curious as to how the python package autograd works, or what the main algorithm at play is. For reverse mode autodiff I've mostly seen Wengert lists used - is some version of this concept used in the autograd package?

In general I understand this approach to automatic differentiation of decomposing a function into primitive operations, but from an implementation standpoint I am curious as to how this decomposition occurs. The example in autograd uses a `tanh` function defined in regular python, so I imagine the package must have some way of breaking the python up into these kinds of primitive operations? Or maybe autograd doesn't use that approach?

 ",7,15
1442,2018-4-25,2018,4,25,8,8ep2p6,OpenSeq2Seq: New Toolkit for Distributed and Mixed-Precision Training of Sequence-to-Sequence Models,https://www.reddit.com/r/MachineLearning/comments/8ep2p6/openseq2seq_new_toolkit_for_distributed_and/,gizcard,1524613044,,0,1
1443,2018-4-25,2018,4,25,8,8ep4eb,[N] New Petuum &amp; CMU Paper Identifies Statistical Correlation Among Deep Generative Models,https://www.reddit.com/r/MachineLearning/comments/8ep4eb/n_new_petuum_cmu_paper_identifies_statistical/,gwen0927,1524613473,,0,1
1444,2018-4-25,2018,4,25,10,8eppdc,Why ILSVRC server is too slow?,https://www.reddit.com/r/MachineLearning/comments/8eppdc/why_ilsvrc_server_is_too_slow/,wodnjs116,1524618860,[removed],0,1
1445,2018-4-25,2018,4,25,10,8epxmj,Image Inpainting for Irregular Holes Using Partial Convolutions,https://www.reddit.com/r/MachineLearning/comments/8epxmj/image_inpainting_for_irregular_holes_using/,realyuvallevental,1524621073,,0,1
1446,2018-4-25,2018,4,25,11,8eq1i6,"Rotary Piling Rig, Squeezing Under Reamer, Diaphragm Wall Grab China Supplier",https://www.reddit.com/r/MachineLearning/comments/8eq1i6/rotary_piling_rig_squeezing_under_reamer/,xcmgreman,1524622094,,0,1
1447,2018-4-25,2018,4,25,11,8eq92m,Where to start,https://www.reddit.com/r/MachineLearning/comments/8eq92m/where_to_start/,alc3mist,1524624098,[removed],0,1
1448,2018-4-25,2018,4,25,12,8eqg4e,"We know AI can learn to play games. Imagine if an alien, who has no language or understanding of movements in common with you, holds a game controller, and you try to play the game through them.",https://www.reddit.com/r/MachineLearning/comments/8eqg4e/we_know_ai_can_learn_to_play_games_imagine_if_an/,[deleted],1524626055,,0,1
1449,2018-4-25,2018,4,25,12,8eqgix,"[D] We know AI can learn to play games. Imagine if an alien, who has no language or understanding of movements in common with you, holds a game controller, and you try to play the game through them",https://www.reddit.com/r/MachineLearning/comments/8eqgix/d_we_know_ai_can_learn_to_play_games_imagine_if/,BenRayfield,1524626171,"In a simple case, imagine an AI and you are playing the first mario together, but only the AI can push buttons and see your actions, and only you can see the screen. You move a more limited controller, such as 1 dimension of mouse/joystick movement or a single button, trying to teach the AI to move in the game depending on what you do. If you can evolve a simple language or basic statistical connection to the AI that doesnt overfit but allows you to describe to the AI new things it should do and things it should stop doing, to direct its learning, then you might win the game that the AI is blind to. I believe any 2 parts of a Human brain will do a similar thing with eachother, but this kind of interaction seems missing from AI theory.",2,0
1450,2018-4-25,2018,4,25,12,8eqj5q,[D] In-Depth review of TRPO(Trust Region Policy Optimization) research paper (Deep Reinforcement Learning).,https://www.reddit.com/r/MachineLearning/comments/8eqj5q/d_indepth_review_of_trpotrust_region_policy/,[deleted],1524626895,[deleted],0,1
1451,2018-4-25,2018,4,25,13,8eqr3v,[R] In-Depth review of TRPO(Trust Region Policy Optimization) research paper (Deep Reinforcement Learning).,https://www.reddit.com/r/MachineLearning/comments/8eqr3v/r_indepth_review_of_trpotrust_region_policy/,jaleyhd,1524629130,,6,20
1452,2018-4-25,2018,4,25,13,8eqxx0,[R] Realistic Evaluation of Deep Semi-Supervised Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/8eqxx0/r_realistic_evaluation_of_deep_semisupervised/,farmingvillein,1524631164,"Thought this was interesting--we all want the free lunch of leveraging unsupervised, although this suggests the lunch isn't as great as previously reported.

One piece I was confused on / would love further thoughts.  They write:

""P.6 Realistically Small Validation Sets. An unusual artefact
of the way artificial SSL datasets are created is that
often the validation set (data used for tuning hyperparameters
and not model parameters) is significantly larger than
the training set. For example, the standard SVHN (Netzer
et al., 2011) dataset has a validation set of roughly 7,000
labeled examples. Many papers that evaluate SSL methods
on SVHN use only 1,000 labels from the training dataset
but retain the full validation set. The validation set is thus
over seven times bigger than the training set. Of course,
in real-world applications, this large validation set would
instead be used as the training set. This issue was pointed
out, but not addressed, in (Rasmus et al., 2015). The primary
issue with this approach is that any objective values
(e.g. accuracy) used for hyperparameter tuning would be
significantly noisier across runs due to the smaller sample
size resulting from using a realistically small validation set.
In these settings, extensive hyperparameter tuning may be
somewhat futile due to an excessively small collection of
held-out data to measure performance on. In many cases,
even using cross-validation may be insufficient and additionally
incurs a substantial computational cost.""

On first pass this makes sense--however, if keeping more data in the validation set leads to better training results...wouldn't that be the correct choice in ""real-world applications""?",13,7
1453,2018-4-25,2018,4,25,14,8er6c3,[D] Lessons from My First Two Years of AI Research,https://www.reddit.com/r/MachineLearning/comments/8er6c3/d_lessons_from_my_first_two_years_of_ai_research/,hardmaru,1524633869,,22,603
1454,2018-4-25,2018,4,25,14,8era3v,Hot Topics in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8era3v/hot_topics_in_machine_learning/,WriteMyThesis,1524635214,,0,1
1455,2018-4-25,2018,4,25,15,8erdni,[R] New Petuum &amp; CMU Paper Identifies Statistical Correlation Among Deep Generative Models,https://www.reddit.com/r/MachineLearning/comments/8erdni/r_new_petuum_cmu_paper_identifies_statistical/,[deleted],1524636462,[deleted],0,1
1456,2018-4-25,2018,4,25,15,8erlst,What Makes Naive Bayes Classification So Naive? | How Does Naive Bayes Classifier Work,https://www.reddit.com/r/MachineLearning/comments/8erlst/what_makes_naive_bayes_classification_so_naive/,LearningFromData,1524639443,,0,1
1457,2018-4-25,2018,4,25,16,8ers45,[D] What are your favorite libraries for image data augmentation? How do you use them?,https://www.reddit.com/r/MachineLearning/comments/8ers45/d_what_are_your_favorite_libraries_for_image_data/,ME_PhD,1524641752,,5,14
1458,2018-4-25,2018,4,25,16,8erub3,Tooder: Smart Flashcards for Curious Kids From Montessorium,https://www.reddit.com/r/MachineLearning/comments/8erub3/tooder_smart_flashcards_for_curious_kids_from/,jnaneshnayak,1524642770,,1,1
1459,2018-4-25,2018,4,25,17,8erxpl,Free eBook: Artificial Intelligence with Python [PDF],https://www.reddit.com/r/MachineLearning/comments/8erxpl/free_ebook_artificial_intelligence_with_python_pdf/,PacktStaff,1524644067,,0,1
1460,2018-4-25,2018,4,25,17,8eryms,Best Udacity/Non-Udacity course for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8eryms/best_udacitynonudacity_course_for_machine_learning/,sithavi,1524644459,[removed],0,1
1461,2018-4-25,2018,4,25,17,8es0vp,Is there a way to implement hierarchical recurrent layers in keras?,https://www.reddit.com/r/MachineLearning/comments/8es0vp/is_there_a_way_to_implement_hierarchical/,raff7,1524645360,[removed],0,1
1462,2018-4-25,2018,4,25,18,8esd0o,"Can anyone point me to a Undirected, Temporal (non static) graph dataset?",https://www.reddit.com/r/MachineLearning/comments/8esd0o/can_anyone_point_me_to_a_undirected_temporal_non/,prakharagarwal,1524650160,[removed],0,1
1463,2018-4-25,2018,4,25,19,8esgnb,isuzu worldwide parts manual,https://www.reddit.com/r/MachineLearning/comments/8esgnb/isuzu_worldwide_parts_manual/,Mypremiummanual,1524651492,,0,1
1464,2018-4-25,2018,4,25,19,8esikv,case ih service manual,https://www.reddit.com/r/MachineLearning/comments/8esikv/case_ih_service_manual/,Mypremiummanual,1524652200,,0,1
1465,2018-4-25,2018,4,25,19,8eskil,Machine Learning Open Source of the Month (v.Apr 2018),https://www.reddit.com/r/MachineLearning/comments/8eskil/machine_learning_open_source_of_the_month_vapr/,[deleted],1524652899,[deleted],0,1
1466,2018-4-25,2018,4,25,19,8eskv8,[P] Machine Learning Open Source of the Month (v.Apr 2018),https://www.reddit.com/r/MachineLearning/comments/8eskv8/p_machine_learning_open_source_of_the_month_vapr/,[deleted],1524653007,[deleted],0,1
1467,2018-4-25,2018,4,25,19,8esmef,[P] Machine Learning Open Source of the Month (v.Apr 2018),https://www.reddit.com/r/MachineLearning/comments/8esmef/p_machine_learning_open_source_of_the_month_vapr/,[deleted],1524653568,[deleted],0,1
1468,2018-4-25,2018,4,25,20,8eso6m,[P] Machine Learning Open Source of the Month (v.Apr 2018),https://www.reddit.com/r/MachineLearning/comments/8eso6m/p_machine_learning_open_source_of_the_month_vapr/,mylife-uxdesign,1524654173,,0,1
1469,2018-4-25,2018,4,25,20,8esphj,[R] How to Use Statistics to Identify Outliers in Data,https://www.reddit.com/r/MachineLearning/comments/8esphj/r_how_to_use_statistics_to_identify_outliers_in/,jackblun,1524654578,,0,1
1470,2018-4-25,2018,4,25,20,8ess27,[D] Deep Learning and a New Programming Paradigm,https://www.reddit.com/r/MachineLearning/comments/8ess27/d_deep_learning_and_a_new_programming_paradigm/,pablo_gomez,1524655365,,0,3
1471,2018-4-25,2018,4,25,20,8esvhx,Review prediction using an embedding in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8esvhx/review_prediction_using_an_embedding_in_tensorflow/,davidhhmack,1524656427,,0,1
1472,2018-4-25,2018,4,25,20,8esvxl,[P] BeatGAN - Generating Drum Loops via GANs,https://www.reddit.com/r/MachineLearning/comments/8esvxl/p_beatgan_generating_drum_loops_via_gans/,[deleted],1524656565,[deleted],0,1
1473,2018-4-25,2018,4,25,20,8esw0w,[N] Asynchronous and scalable hyperparameters tuning,https://www.reddit.com/r/MachineLearning/comments/8esw0w/n_asynchronous_and_scalable_hyperparameters_tuning/,mmourafiq,1524656596,,1,3
1474,2018-4-25,2018,4,25,20,8esy1s,[P] BeatGAN - Generating Drum Loops via GANs,https://www.reddit.com/r/MachineLearning/comments/8esy1s/p_beatgan_generating_drum_loops_via_gans/,[deleted],1524657194,[deleted],0,1
1475,2018-4-25,2018,4,25,21,8et0el,[P] BeatGAN - Generating Drum Loops via GANs,https://www.reddit.com/r/MachineLearning/comments/8et0el/p_beatgan_generating_drum_loops_via_gans/,[deleted],1524657861,[deleted],0,1
1476,2018-4-25,2018,4,25,21,8et4b5,[P] BeatGAN - Generating Drum Loops via GANs,https://www.reddit.com/r/MachineLearning/comments/8et4b5/p_beatgan_generating_drum_loops_via_gans/,11nk11,1524658927,,1,18
1477,2018-4-25,2018,4,25,21,8et5wy,[D] The lifecycle of machine learning models in mobile apps.,https://www.reddit.com/r/MachineLearning/comments/8et5wy/d_the_lifecycle_of_machine_learning_models_in/,jamesonatfritz,1524659358,,1,11
1478,2018-4-25,2018,4,25,21,8et98q,Recommendation engine with additional information about targets,https://www.reddit.com/r/MachineLearning/comments/8et98q/recommendation_engine_with_additional_information/,PoleOnTheRock,1524660263,[removed],0,1
1479,2018-4-25,2018,4,25,21,8et9pq,Frying Machine for Peanut,https://www.reddit.com/r/MachineLearning/comments/8et9pq/frying_machine_for_peanut/,lgsherry,1524660388,,1,1
1480,2018-4-25,2018,4,25,22,8etcyi,A peer-to-peer knowledge-base platform inspired by neural networks.,https://www.reddit.com/r/MachineLearning/comments/8etcyi/a_peertopeer_knowledgebase_platform_inspired_by/,moshestv,1524661229,,0,1
1481,2018-4-25,2018,4,25,22,8eterc,Top Trends in Artificial Intelligence and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8eterc/top_trends_in_artificial_intelligence_and_machine/,fullstackanalytics1,1524661674,,0,1
1482,2018-4-25,2018,4,25,22,8etje4,[D] Actor Critic Algorithm why we can share convolution part?,https://www.reddit.com/r/MachineLearning/comments/8etje4/d_actor_critic_algorithm_why_we_can_share/,mlenthousiast_,1524662805,"Hi,

I'm currently trying to implement an Actor Critic algorithm with Tensorflow but I'm a little bit lost.

In some illustrations we can see that the constitutional part can be shared between the two networks (actor and critic)
[Here] (https://cdn-images-1.medium.com/max/1600/1*YtnGhtSAMnnHSL8PvS7t_w.png)

What I understand is that actor parameters are improved by the actor gradient.

Critic parameters are improved by the critic gradient.

But who's network (actor or critic) update the weights of the convolution part ?
Thanks !",4,3
1483,2018-4-25,2018,4,25,22,8etlru,where to start learning machine learning.,https://www.reddit.com/r/MachineLearning/comments/8etlru/where_to_start_learning_machine_learning/,psmrustham,1524663404,[removed],0,1
1484,2018-4-25,2018,4,25,22,8etm09,[P] I used Tensorflow to create these songs based on Final Fantasy soundtracks.,https://www.reddit.com/r/MachineLearning/comments/8etm09/p_i_used_tensorflow_to_create_these_songs_based/,aviel08,1524663459,,10,41
1485,2018-4-25,2018,4,25,22,8etr0w,Datafiniti is revolutionizing online webdata game using #machinelearning approaches &amp; automating data extraction process,https://www.reddit.com/r/MachineLearning/comments/8etr0w/datafiniti_is_revolutionizing_online_webdata_game/,FusionAnalyticsWorld,1524664715,,0,1
1486,2018-4-26,2018,4,26,0,8eu7cg,[D] Can a convnet see things that humans cannot?,https://www.reddit.com/r/MachineLearning/comments/8eu7cg/d_can_a_convnet_see_things_that_humans_cannot/,tilenkranjc,1524668400,"I recently started to dig deep into image analysis with neural networks and one of the projects I'm on right now is a prediction of the bone fracture risk in osteoporosis by looking at the X-ray image. This is not really used in medicine to predict fracture risk, so I would say it is quite impossible for a radiologist to assess the risk by just interpreting the X-ray. My first results in this project show the same - image analysis does no better prediction by looking at regular risk factors (alcohol intake, smoking, body weight, certain drugs, age, etc). I need to also mention, that such X-ray images are used to assess bone mineral density, which somehow can be used to predict bone fracture, although not perfectly. Bone mineral density is calculated as the average pixel intensity in a certain region of the bone.
So, the question is - can a convnet see things that humans cannot? Can it be trained to see things that are impossible to interpret by humans? If yes, what would be the examples of it?

(Note: when I talk about X-ray, I actually mean DXA imaging, which stands for Dual X-ray Absorptiometry. This is a subtype of X-ray imaging, used to assess bone mineral density.)",14,0
1487,2018-4-26,2018,4,26,0,8eu8ik,[D] Today Rachel Thomas implies OpenAI being sexist,https://www.reddit.com/r/MachineLearning/comments/8eu8ik/d_today_rachel_thomas_implies_openai_being_sexist/,SpiritualAlternative,1524668641,"It seems the board of @OpenAI consists of 5 white men. 

Diversity in AI is a crucial issue, particularly for OpenAI since they have so many resources/so much influence.



https://twitter.com/math_rachel/status/988905272591634432?s=21",12,0
1488,2018-4-26,2018,4,26,0,8eu92w,AI or ML Research Paper partners,https://www.reddit.com/r/MachineLearning/comments/8eu92w/ai_or_ml_research_paper_partners/,tiger287,1524668764,[removed],0,1
1489,2018-4-26,2018,4,26,0,8eukx9,ML for medical imaging conferences in Europe?,https://www.reddit.com/r/MachineLearning/comments/8eukx9/ml_for_medical_imaging_conferences_in_europe/,domoson,1524671264,[removed],0,1
1490,2018-4-26,2018,4,26,0,8eun6q,"Simple Questions Thread April 25, 2018",https://www.reddit.com/r/MachineLearning/comments/8eun6q/simple_questions_thread_april_25_2018/,AutoModerator,1524671741,[removed],0,1
1491,2018-4-26,2018,4,26,1,8eupch,What's the best way to deal with graph data?,https://www.reddit.com/r/MachineLearning/comments/8eupch/whats_the_best_way_to_deal_with_graph_data/,Pafnouti,1524672196,[removed],0,1
1492,2018-4-26,2018,4,26,1,8euxy9,Is there any recent research on learning set functions from data?,https://www.reddit.com/r/MachineLearning/comments/8euxy9/is_there_any_recent_research_on_learning_set/,regularized,1524673967,[removed],0,1
1493,2018-4-26,2018,4,26,2,8ev8ps,"[N] PyTorch Releases Major Update, Now Officially Supports Windows",https://www.reddit.com/r/MachineLearning/comments/8ev8ps/n_pytorch_releases_major_update_now_officially/,gwen0927,1524676202,,0,1
1494,2018-4-26,2018,4,26,2,8ev90k,Rice U. turns deep-learning AI loose on software development,https://www.reddit.com/r/MachineLearning/comments/8ev90k/rice_u_turns_deeplearning_ai_loose_on_software/,vijaymurali,1524676259,,1,1
1495,2018-4-26,2018,4,26,2,8evcba,[D] Automatic pipelines for Computer Vision competitions,https://www.reddit.com/r/MachineLearning/comments/8evcba/d_automatic_pipelines_for_computer_vision/,t897349817,1524676954,"I'm participating in a Computer Vision competition and I want to automate my entire training and evaluation pipeline, including hyperparameter optimization and the creation of ensembles.

I checked out the most famous tools for this, but none seem to fit the full pipeline that I described. Here's what I tried:

* **Hyperopt**: Very easy to setup and works well for tuning hyperparameter, but that's it. No automation of pipelines nor ensamble creation.

* **Xcessiv**: Similar to what I want, but the [walkthrough](http://xcessiv.readthedocs.io/en/stable/walkthrough.html) says that I need to define the dataset as a function that returns a tuple. This is unfeasible for huge amounts of data.

* **tpot** also requires the sklearn interface and doesn't do ensembles.

* **auto_ml**: the data ""must either be a pandas DataFrame, or a list filled with python dictionaries."" But how to deal with images?

Does anyone know any tool or method that can be used for my case?",5,5
1496,2018-4-26,2018,4,26,2,8evj53,Would a PhD implementing these ML algorithms be considered a PhD in Machine learning?,https://www.reddit.com/r/MachineLearning/comments/8evj53/would_a_phd_implementing_these_ml_algorithms_be/,FullYorker,1524678406,[removed],0,1
1497,2018-4-26,2018,4,26,2,8evldn,Is there an example implementation of a CNN on a 3D image over time (so 4D) in python? Specifically I'm working with fMRI data.,https://www.reddit.com/r/MachineLearning/comments/8evldn/is_there_an_example_implementation_of_a_cnn_on_a/,aBowlofSpaghetti,1524678870,[removed],0,1
1498,2018-4-26,2018,4,26,3,8evo0y,[R] [1804.07754] Learning Semantic Textual Similarity from Conversations,https://www.reddit.com/r/MachineLearning/comments/8evo0y/r_180407754_learning_semantic_textual_similarity/,danielcer,1524679408,,2,6
1499,2018-4-26,2018,4,26,3,8evowq,Getting better video quality using deep learning,https://www.reddit.com/r/MachineLearning/comments/8evowq/getting_better_video_quality_using_deep_learning/,MutatingNeutrinos,1524679576,,0,1
1500,2018-4-26,2018,4,26,3,8ew2ub,[D] I met Geoff Hinton,https://www.reddit.com/r/MachineLearning/comments/8ew2ub/d_i_met_geoff_hinton/,[deleted],1524682465,[deleted],1,0
1501,2018-4-26,2018,4,26,4,8ewj35,Using Word2Vec for Better Embeddings of Categorical Features,https://www.reddit.com/r/MachineLearning/comments/8ewj35/using_word2vec_for_better_embeddings_of/,nadavbar,1524685976,,0,2
1502,2018-4-26,2018,4,26,5,8ewsmv,[R] Evolving Mario Levels in the Latent Space of a DCGAN (PDF),https://www.reddit.com/r/MachineLearning/comments/8ewsmv/r_evolving_mario_levels_in_the_latent_space_of_a/,wei_jok,1524688015,,0,39
1503,2018-4-26,2018,4,26,5,8ewwo5,Help with finite central difference?,https://www.reddit.com/r/MachineLearning/comments/8ewwo5/help_with_finite_central_difference/,5ponsky,1524688866,[removed],0,1
1504,2018-4-26,2018,4,26,6,8ex2kq,Better video quality through deep learning,https://www.reddit.com/r/MachineLearning/comments/8ex2kq/better_video_quality_through_deep_learning/,MutatingNeutrinos,1524690110,,0,1
1505,2018-4-26,2018,4,26,6,8ex8us,[D] Deep Learning models for prediction of time to failure (especially industrial equipment),https://www.reddit.com/r/MachineLearning/comments/8ex8us/d_deep_learning_models_for_prediction_of_time_to/,AndriPi,1524691483,"I'm looking for Deep Learning models for the prediction of time to failure for industrial equipment. The input is a multivariate time series, or multivariate _sequence_, thus I thought of RNNs. I've been using https://github.com/ragulpr/wtte-rnn/ with some success, but I had issues with missing data. Are there other frameworks/architectures to solve this problem? It doesn't necessarily have to be a RNN.",19,7
1506,2018-4-26,2018,4,26,6,8exedi,[R] Is there any recent research on learning set functions from data?,https://www.reddit.com/r/MachineLearning/comments/8exedi/r_is_there_any_recent_research_on_learning_set/,regularized,1524692674,"I was looking for how to learn set functions from data. Can you point out some relevant papers on this?

",3,6
1507,2018-4-26,2018,4,26,6,8exelg,[D] A package which efficiently applies any function to a pandas dataframe or series in the fastest available manner,https://www.reddit.com/r/MachineLearning/comments/8exelg/d_a_package_which_efficiently_applies_any/,_alphamaximus_,1524692731,,0,1
1508,2018-4-26,2018,4,26,6,8exhao,Best case of ML applied to education?,https://www.reddit.com/r/MachineLearning/comments/8exhao/best_case_of_ml_applied_to_education/,groshretro,1524693339,[removed],0,1
1509,2018-4-26,2018,4,26,6,8exht8,[D] Stochastic Regularization for Non-Stationary Modeling?,https://www.reddit.com/r/MachineLearning/comments/8exht8/d_stochastic_regularization_for_nonstationary/,alexmlamb,1524693451,"Let's say that I have data that's coming from a stream, where the distribution changes over time (i.e. as I collect more points).  Let's also say that I care about data efficiency and learning as quickly as possible.  RL is a motivating example for me, but I think it applies more generally.  

Now let's say that on this type of data, a noisy/stochastic regularizer, like dropping a fraction of the visible units, would normally work well.  

In the non-stationary case, it seems like there's a weakness in applying a stochastic regularizer like this, because you're losing information about data which won't be as relevant in the future (due to non-stationarity).  

For the usual classification setup, it's not an issue to regularize as much as possible, at least from a data efficiency point of view, because the same data points can always be visited later in training and they'll have the same relevance.  ",2,8
1510,2018-4-26,2018,4,26,8,8ey00u,Suggested Raspberry PI OS for Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8ey00u/suggested_raspberry_pi_os_for_tensorflow/,deep_learning_algo,1524697713,[removed],0,1
1511,2018-4-26,2018,4,26,8,8ey1fz,[P] BeatGAN part 2 - Soundcloud Playlist of Beats Generated by my Drum Loop AI,https://www.reddit.com/r/MachineLearning/comments/8ey1fz/p_beatgan_part_2_soundcloud_playlist_of_beats/,[deleted],1524698074,[deleted],0,1
1512,2018-4-26,2018,4,26,8,8ey1om,[P] BeatGAN part 2 - Soundcloud Playlist of Beats Generated by my Drum Loop AI,https://www.reddit.com/r/MachineLearning/comments/8ey1om/p_beatgan_part_2_soundcloud_playlist_of_beats/,11nk11,1524698139,,10,44
1513,2018-4-26,2018,4,26,8,8ey1zu,MusicGAN (generated songs from a pop style dataset),https://www.reddit.com/r/MachineLearning/comments/8ey1zu/musicgan_generated_songs_from_a_pop_style_dataset/,tunestar2018,1524698224,,0,1
1514,2018-4-26,2018,4,26,8,8ey5lq,"Amazon AWS SageMaker, anomaly detection, via Random Cut Forest Algorithm, just released",https://www.reddit.com/r/MachineLearning/comments/8ey5lq/amazon_aws_sagemaker_anomaly_detection_via_random/,julito_power,1524699114,,0,1
1515,2018-4-26,2018,4,26,8,8ey8id,Google AI/ML Strategy Clashing With The Ideal Open Standardized AI Vision.,https://www.reddit.com/r/MachineLearning/comments/8ey8id/google_aiml_strategy_clashing_with_the_ideal_open/,TheOSM,1524699821,[removed],0,1
1516,2018-4-26,2018,4,26,9,8eynm5,What are the flaws of machine learning that AGI can overcome?,https://www.reddit.com/r/MachineLearning/comments/8eynm5/what_are_the_flaws_of_machine_learning_that_agi/,AigoToken,1524703630,[removed],0,0
1517,2018-4-26,2018,4,26,12,8eziar,[R] OpenAI Meta-Learning and Self-Play (Ilya Sutskever),https://www.reddit.com/r/MachineLearning/comments/8eziar/r_openai_metalearning_and_selfplay_ilya_sutskever/,downtownslim,1524711781,,19,198
1518,2018-4-26,2018,4,26,12,8ezjff,[R] Teach Machine to Comprehend Text and Answer Question with Tensorflow - Part I,https://www.reddit.com/r/MachineLearning/comments/8ezjff/r_teach_machine_to_comprehend_text_and_answer/,h_xiao,1524712085,,0,4
1519,2018-4-26,2018,4,26,12,8ezjo7,Small Scale Peanut Butter Production Line For Sale,https://www.reddit.com/r/MachineLearning/comments/8ezjo7/small_scale_peanut_butter_production_line_for_sale/,Machineprices,1524712151,,1,1
1520,2018-4-26,2018,4,26,13,8ezw9k,[R] Survey: How do you trace neural network instabilities (when training diverges)?,https://www.reddit.com/r/MachineLearning/comments/8ezw9k/r_survey_how_do_you_trace_neural_network/,FirstTimeResearcher,1524715917,"How do others trace the source of a diverging neural network? Usually, it takes some number of iterations before the accuracy plummets to chance or a NaN starts propagating through the updates.",7,6
1521,2018-4-26,2018,4,26,13,8ezzks,Is Learning ML a Waste of Time Carrer Wise?,https://www.reddit.com/r/MachineLearning/comments/8ezzks/is_learning_ml_a_waste_of_time_carrer_wise/,dumdeedup,1524716919,[removed],0,1
1522,2018-4-26,2018,4,26,14,8f05p7,[D] Is Understanding Machine Learning: From Theory to Algorithms good book for learning statistical machine learning?,https://www.reddit.com/r/MachineLearning/comments/8f05p7/d_is_understanding_machine_learning_from_theory/,[deleted],1524718932,[deleted],0,1
1523,2018-4-26,2018,4,26,14,8f05y1,[D] Is Understanding Machine Learning: From Theory to Algorithms a good book for learning statistical machine learning?,https://www.reddit.com/r/MachineLearning/comments/8f05y1/d_is_understanding_machine_learning_from_theory/,upulbandara,1524719019,https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf,13,9
1524,2018-4-26,2018,4,26,14,8f0cvg,Math+CS vs Statistics+CS major for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8f0cvg/mathcs_vs_statisticscs_major_for_machine_learning/,randomquestions345,1524721364,[removed],0,1
1525,2018-4-26,2018,4,26,14,8f0d5v,[R] Sampling-free Uncertainty Estimation in Gated Recurrent Units with Exponential Families,https://www.reddit.com/r/MachineLearning/comments/8f0d5v/r_samplingfree_uncertainty_estimation_in_gated/,undefdev,1524721455,,0,4
1526,2018-4-26,2018,4,26,17,8f16i3,Do you want to increase your automotive sales and customer connect? Read our 3 minute blog to get it done. Upload your FAQ and build your bot in 10 mins.,https://www.reddit.com/r/MachineLearning/comments/8f16i3/do_you_want_to_increase_your_automotive_sales_and/,parousiakhan,1524732649,,0,1
1527,2018-4-26,2018,4,26,17,8f170c,[D] Would metalearning work for training generative models with no direct inputs?,https://www.reddit.com/r/MachineLearning/comments/8f170c/d_would_metalearning_work_for_training_generative/,abstractcontrol,1524732843,"By metalearning, I mean the [first order optimization methods](https://arxiv.org/abs/1803.02999) like FOMAML and Reptile. For a while I've been thinking that few shot learning tasks are not really enough to distinguish optimization based approaches from model based metalearning approaches given that RNNs can do them just as well. And there is the ever present question of what would you get if you combine the two.

To that end, it might be interesting to try out training a autoencoder not by optimizing the reconstruction loss, but just by switching the labels and the inputs. If my understanding of what meta-optimization is doing, then it might be plausible that inputs could be omitted entirely and the network would still do useful learning.

Would this kind of task be a good match for meta-optimization approaches?

This question was inspired by some of the recent papers I read that claim the brain to be doing Bayesian inference rather than maximum likelihood estimation. In [this talk](https://www.youtube.com/watch?v=d6hXF3EMv_E&amp;index=4&amp;list=PLgKuh-lKre115020ug_gdmRroIfiQsPL4&amp;t=0s) Asja Fisher claims that one update of a energy based model approximates backpropagation. As that is true for a single step of meta-optimization as well, then it would be only natural to wonder if multiple steps of meta-optimization would optimize for inference.",0,3
1528,2018-4-26,2018,4,26,18,8f1a5j,Do you want to increase your automotive sales and customer connect? Read our 3 minute blog to get it done. Upload your FAQ and build your bot in 10 mins.,https://www.reddit.com/r/MachineLearning/comments/8f1a5j/do_you_want_to_increase_your_automotive_sales_and/,parousiakhan,1524734077,,0,1
1529,2018-4-26,2018,4,26,18,8f1gph,Why Do Neural Networks Need An Activation Function? (by Computer Vision Specialist),https://www.reddit.com/r/MachineLearning/comments/8f1gph/why_do_neural_networks_need_an_activation/,Batareika_1,1524736643,,0,1
1530,2018-4-26,2018,4,26,19,8f1jk5,IBM Watson - relating a sentence to a topic,https://www.reddit.com/r/MachineLearning/comments/8f1jk5/ibm_watson_relating_a_sentence_to_a_topic/,GrapeyApey,1524737676,[removed],0,1
1531,2018-4-26,2018,4,26,19,8f1odo,Can ML solve the problem of existence and are there any steps taken in this direction?,https://www.reddit.com/r/MachineLearning/comments/8f1odo/can_ml_solve_the_problem_of_existence_and_are/,nishankatwork,1524739437,[removed],0,1
1532,2018-4-26,2018,4,26,20,8f1wp9,WHY IS AN UPDATE NEEDED IN THE WAY KIDS LEARN?,https://www.reddit.com/r/MachineLearning/comments/8f1wp9/why_is_an_update_needed_in_the_way_kids_learn/,nutanshukla,1524742172,,0,1
1533,2018-4-26,2018,4,26,20,8f1ygs,Commercial Use Sesame Tahini Grinding Production Line For Sale,https://www.reddit.com/r/MachineLearning/comments/8f1ygs/commercial_use_sesame_tahini_grinding_production/,Machineprices,1524742716,,1,1
1534,2018-4-26,2018,4,26,20,8f210o,Chicken Wings Frying Machine,https://www.reddit.com/r/MachineLearning/comments/8f210o/chicken_wings_frying_machine/,lgsherry,1524743509,,1,1
1535,2018-4-26,2018,4,26,20,8f217y,Smooth Peanut Butter Production Line For Sale,https://www.reddit.com/r/MachineLearning/comments/8f217y/smooth_peanut_butter_production_line_for_sale/,Machineprices,1524743567,,1,1
1536,2018-4-26,2018,4,26,20,8f21cz,Aligning different text information to a tabular format using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8f21cz/aligning_different_text_information_to_a_tabular/,highonexposure,1524743604,[removed],0,1
1537,2018-4-26,2018,4,26,21,8f24vs,"Machine Learning, the booming career option shaping the job market",https://www.reddit.com/r/MachineLearning/comments/8f24vs/machine_learning_the_booming_career_option/,SayaniBan,1524744596,,1,1
1538,2018-4-26,2018,4,26,21,8f2927,"[R] Deep Learning for Head CT scans: 9 Emergency Findings, Validation on ~22k scans, &gt;0.9 AUCs, Publicly Available Dataset",https://www.reddit.com/r/MachineLearning/comments/8f2927/r_deep_learning_for_head_ct_scans_9_emergency/,saucysassy,1524745760,,11,88
1539,2018-4-26,2018,4,26,21,8f292j,[R] Phrase-Based &amp; Neural Unsupervised Machine Translation,https://www.reddit.com/r/MachineLearning/comments/8f292j/r_phrasebased_neural_unsupervised_machine/,visarga,1524745763,,0,2
1540,2018-4-26,2018,4,26,21,8f2dz4,Project recommendations for a beginner,https://www.reddit.com/r/MachineLearning/comments/8f2dz4/project_recommendations_for_a_beginner/,theneerex,1524747111,[removed],0,1
1541,2018-4-26,2018,4,26,21,8f2fsd,how to deal with action space of varying size in reinforcment learning,https://www.reddit.com/r/MachineLearning/comments/8f2fsd/how_to_deal_with_action_space_of_varying_size_in/,harstraxx,1524747566,[removed],1,1
1542,2018-4-26,2018,4,26,22,8f2g6k,[D] Benchmarking Google's TPUv2 against Nvidia's V100 on ResNet-50,https://www.reddit.com/r/MachineLearning/comments/8f2g6k/d_benchmarking_googles_tpuv2_against_nvidias_v100/,henningpeters,1524747668,,16,174
1543,2018-4-26,2018,4,26,22,8f2nra,[P] How I trained a language detection AI in 20 minutes with a 97% accuracy,https://www.reddit.com/r/MachineLearning/comments/8f2nra/p_how_i_trained_a_language_detection_ai_in_20/,thetall0ne1,1524749488,,1,0
1544,2018-4-26,2018,4,26,23,8f36b6,New A.I. application can write its own code,https://www.reddit.com/r/MachineLearning/comments/8f36b6/new_ai_application_can_write_its_own_code/,FastPop,1524753795,,0,1
1545,2018-4-26,2018,4,26,23,8f36v8,"[N] Weekly Machine Learning Opensource Roundup  Apr. 26, 2018",https://www.reddit.com/r/MachineLearning/comments/8f36v8/n_weekly_machine_learning_opensource_roundup_apr/,stkim1,1524753925,,0,1
1546,2018-4-26,2018,4,26,23,8f38hh,Human like vision,https://www.reddit.com/r/MachineLearning/comments/8f38hh/human_like_vision/,moshe501,1524754301,[removed],0,1
1547,2018-4-27,2018,4,27,0,8f3hxh,Building Convolutional Neural Network using NumPy from Scratch,https://www.reddit.com/r/MachineLearning/comments/8f3hxh/building_convolutional_neural_network_using_numpy/,zindarod,1524756360,,0,1
1548,2018-4-27,2018,4,27,0,8f3mwk,"[D] Why Extreme Learning Machine was publicly trashed, but no one points finger at Denoising Autoencoder?",https://www.reddit.com/r/MachineLearning/comments/8f3mwk/d_why_extreme_learning_machine_was_publicly/,trash_robotics,1524757427,"Hi everyone, I am new to machine learning research and there is something confusing me, as I read LeCun's comments on Extreme Learning Machine
https://www.facebook.com/yann.lecun/posts/10152872571572143

It seems all points are valid. But is Denoising Autoencoder any smarter than that? Two ideas seem rather similar. Randomness in weights vs randomness in inputs.

""But you will never see them beat records on complex tasks, such as ImageNet or speech recognition."" -- LeCun    
Well, there is no such record for Denoising Autoencoder either. Isn't it a double standard?",19,3
1549,2018-4-27,2018,4,27,0,8f3p5q,[R] Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models,https://www.reddit.com/r/MachineLearning/comments/8f3p5q/r_seq2seqvis_a_visual_debugging_tool_for/,Valedra,1524757892,,1,13
1550,2018-4-27,2018,4,27,1,8f42ni,[R] Boltzmann Encoded Adversarial Machines,https://www.reddit.com/r/MachineLearning/comments/8f42ni/r_boltzmann_encoded_adversarial_machines/,LeanderKu,1524760703,,16,32
1551,2018-4-27,2018,4,27,2,8f4b1k,Fake Doge Real Cate Much Wow,https://www.reddit.com/r/MachineLearning/comments/8f4b1k/fake_doge_real_cate_much_wow/,[deleted],1524762450,[deleted],0,1
1552,2018-4-27,2018,4,27,2,8f4dzr,[P] Adversarial Doge - Boundary Attack samples,https://www.reddit.com/r/MachineLearning/comments/8f4dzr/p_adversarial_doge_boundary_attack_samples/,greentfrapp,1524763055,,0,6
1553,2018-4-27,2018,4,27,2,8f4fi5,Automatic Hyperparameter Optimization,https://www.reddit.com/r/MachineLearning/comments/8f4fi5/automatic_hyperparameter_optimization/,mourinhoxyz,1524763377,[removed],0,1
1554,2018-4-27,2018,4,27,3,8f4tdc,[R] Multi-objective Architecture Search for CNNs,https://www.reddit.com/r/MachineLearning/comments/8f4tdc/r_multiobjective_architecture_search_for_cnns/,frisbee_81,1524766237,,2,8
1555,2018-4-27,2018,4,27,3,8f4xkw,[N] Introducing Swift For TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8f4xkw/n_introducing_swift_for_tensorflow/,backupcortex,1524767098,,13,61
1556,2018-4-27,2018,4,27,3,8f50cg,"""Objectification"" in Machine Learning",https://www.reddit.com/r/MachineLearning/comments/8f50cg/objectification_in_machine_learning/,BNielson,1524767685,[removed],0,1
1557,2018-4-27,2018,4,27,4,8f5b7u,Where can I find regional crop yield data?,https://www.reddit.com/r/MachineLearning/comments/8f5b7u/where_can_i_find_regional_crop_yield_data/,vapegod420,1524770018,[removed],0,1
1558,2018-4-27,2018,4,27,4,8f5dh2,OCR using ANN giving inaccurate results.,https://www.reddit.com/r/MachineLearning/comments/8f5dh2/ocr_using_ann_giving_inaccurate_results/,karkibigyan,1524770521,[removed],0,1
1559,2018-4-27,2018,4,27,4,8f5g1g,[D] Papers on the effectiveness of DL,https://www.reddit.com/r/MachineLearning/comments/8f5g1g/d_papers_on_the_effectiveness_of_dl/,sneezophile,1524771097,"How far does the mathematical understanding of the performance of DL go? 

I get for example the intuition that more layers gets you more complex features but what is the mathematical basis of that? Why don't 3 layer MLPs, being universal function approximators, perform equally well?",9,0
1560,2018-4-27,2018,4,27,4,8f5g71,[N] A Request for FAT* and FATML to Change Their Names to Promote Greater Inclusivity,https://www.reddit.com/r/MachineLearning/comments/8f5g71/n_a_request_for_fat_and_fatml_to_change_their/,wrongzebragas,1524771129,,2,0
1561,2018-4-27,2018,4,27,5,8f5ri2,Papers on human action recognition?,https://www.reddit.com/r/MachineLearning/comments/8f5ri2/papers_on_human_action_recognition/,jirukulapati,1524773570,[removed],0,1
1562,2018-4-27,2018,4,27,5,8f5vyh,Making 1M Click Predictions per Second using AWS - AdRoll,https://www.reddit.com/r/MachineLearning/comments/8f5vyh/making_1m_click_predictions_per_second_using_aws/,letmeitellyou,1524774533,,0,1
1563,2018-4-27,2018,4,27,5,8f5vzw,DeepCode cleans your code with the power of AI,https://www.reddit.com/r/MachineLearning/comments/8f5vzw/deepcode_cleans_your_code_with_the_power_of_ai/,[deleted],1524774543,[deleted],0,1
1564,2018-4-27,2018,4,27,6,8f6ctm,[D] Master in Data Science/Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8f6ctm/d_master_in_data_scienceartificial_intelligence/,__bee,1524778307,"I am software engineer, with 5 years experience. I am already getting involved on Data Science projects.  I have a bachelor degree. I am thinking of doing a Master's in Data Science/AI.  Those who did it. Was it rewarding ?.

I think it would be way very expensive to get a Master's in the USA/Europe in a good program. Does it worth it when I graduate. In order to boost my career, what do you guys think of doing a Master's degree in Artificial Intelligence ?. Or, should I spend time at  more at work \(industry\) without making this break. ",10,2
1565,2018-4-27,2018,4,27,6,8f6hqn,[N] Google Brain is expanding to Tokyo,https://www.reddit.com/r/MachineLearning/comments/8f6hqn/n_google_brain_is_expanding_to_tokyo/,baylearn,1524779430,,66,230
1566,2018-4-27,2018,4,27,7,8f6m8p,[R][1803.08493] Context is Everything: Finding Meaning Statistically in Semantic Spaces. (A simple and explicit measure of a word's importance in context).,https://www.reddit.com/r/MachineLearning/comments/8f6m8p/r180308493_context_is_everything_finding_meaning/,BatmantoshReturns,1524780469,,28,39
1567,2018-4-27,2018,4,27,10,8f7ru1,neural network based handwriting keyboard (python with tensorflow),https://www.reddit.com/r/MachineLearning/comments/8f7ru1/neural_network_based_handwriting_keyboard_python/,idan0405,1524790958,,0,1
1568,2018-4-27,2018,4,27,12,8f8pju,[D] How to compare two neural networks fairly?,https://www.reddit.com/r/MachineLearning/comments/8f8pju/d_how_to_compare_two_neural_networks_fairly/,eurus-yu,1524800463,"Hey guys I am really confused about how to compare two neural networks. For example I have a network A and a network B, and I want to know which one is better at classification. Should I keep all the training parameters (lr scheduling, weight decay and other things) same or should I search for different sets of params for two networks? I mean the optimal set of params may be different but it's very expensive to do grid search. So what should I do here?",22,10
1569,2018-4-27,2018,4,27,12,8f8rp1,My Final Capstone Presentation: Using various ML algorithms to predict interest level based on brain scan data,https://www.reddit.com/r/MachineLearning/comments/8f8rp1/my_final_capstone_presentation_using_various_ml/,Aedificatus,1524801099,,0,1
1570,2018-4-27,2018,4,27,13,8f8wmd,[D] Is there any research in using ML to make sense of brain wave data?,https://www.reddit.com/r/MachineLearning/comments/8f8wmd/d_is_there_any_research_in_using_ml_to_make_sense/,swegmesterflex,1524802574,"I've always dreamed of working with neuroprosthetics and ML together when I'm older but now that I'm actually reading papers I can't find anything with both of these things used in tandem. I don't know any of the technical words so it wouldn't be surprising if I'm just not searching up the right things. Or maybe I'm just naive and there is no reason to bring the two together. Anyhow, does anyone know if there is research being done on this? If so, where and how would one find it?",9,7
1571,2018-4-27,2018,4,27,13,8f8y48,We have to retrain the model if there is small change in dataset or database ?,https://www.reddit.com/r/MachineLearning/comments/8f8y48/we_have_to_retrain_the_model_if_there_is_small/,aswiniloukya,1524803020,[removed],0,1
1572,2018-4-27,2018,4,27,14,8f98z1,[D] Best method to extract numerical data from product descriptions?,https://www.reddit.com/r/MachineLearning/comments/8f98z1/d_best_method_to_extract_numerical_data_from/,rowanobrian,1524806515,"Hi, 
I will start with example.

input .................output(can divide it into 'size' and 'unit')

'xyz 5g uit'.....................5 g

'foo 5x6MLmnop'............30 ml

'bar 6ml foo 20ml'..........26ml

'qwer 3 yuio x3'.............9 pieces

and similar other input to give output like above. the input does vary a lot, but mostly a human can make out the output correctly, but by normal NLP techniques, I am unable to think of a method to solve this.

Tried: 

* simple regex. it worked for 70% cases. but some cases do have complicated structure, and accomodating everything in regex isnt feasible.

* (thinking of) convolutional net: as it could be helpful in capturing the unit as well (g,ml etc) along with multiplication factors (x6 etc). but not very sure how to create word vecs

* (suggest me) can i use recurrent nets? ",6,5
1573,2018-4-27,2018,4,27,14,8f9aj4,About to start a masters. I have worked on visual saliency before. I'm considering working on the broader attention problem. Thoughts?,https://www.reddit.com/r/MachineLearning/comments/8f9aj4/about_to_start_a_masters_i_have_worked_on_visual/,perilo,1524807049,[removed],0,1
1574,2018-4-27,2018,4,27,14,8f9dvm,[R][UberAI] Measuring the Intrinsic Dimension of Objective Landscapes,https://www.reddit.com/r/MachineLearning/comments/8f9dvm/ruberai_measuring_the_intrinsic_dimension_of/,downtownslim,1524808200,,46,350
1575,2018-4-27,2018,4,27,15,8f9kgy,"""Zero-Shot"" Super-Resolution using Deep Internal Learning (ZSSR) - Official code released",https://www.reddit.com/r/MachineLearning/comments/8f9kgy/zeroshot_superresolution_using_deep_internal/,assafsho,1524810584,[removed],0,1
1576,2018-4-27,2018,4,27,15,8f9loo,[P] Is this loss?: A TensorFlow Lite classifier app for Loss.jpg,https://www.reddit.com/r/MachineLearning/comments/8f9loo/p_is_this_loss_a_tensorflow_lite_classifier_app/,isthisloss_app,1524811035,"I built this app over a week as a way to learn how to use TensorFlow with Mobilenets and to get some experience with Google Play (and partly as a dare). It's written in Java, as I wasn't able to find a Kotlin API for TFLite. It was built with Bazel.

I'm pretty satisfied with the actual detector's performance, although I expect I could improve the UI a little bit. It's a weird UX, as you want it to be as simple and fast as possible (loss/notloss) but you also want it to have some sort of recognizability. I would love to hear your thoughts.

https://play.google.com/store/apps/details?id=party.eigenloss.android.isthisloss",8,33
1577,2018-4-27,2018,4,27,15,8f9nl1,Why can we not use on-policy algorithms with HER?,https://www.reddit.com/r/MachineLearning/comments/8f9nl1/why_can_we_not_use_onpolicy_algorithms_with_her/,arjoonn,1524811709,[removed],0,1
1578,2018-4-27,2018,4,27,16,8f9se8,Benzinga Fintech Awards 2018 - Best Use of AI or Machine Learning :),https://www.reddit.com/r/MachineLearning/comments/8f9se8/benzinga_fintech_awards_2018_best_use_of_ai_or/,[deleted],1524813398,[deleted],0,1
1579,2018-4-27,2018,4,27,16,8f9u61,[N] Benzinga Fintech Award 2018 - Best Use of AI or Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8f9u61/n_benzinga_fintech_award_2018_best_use_of_ai_or/,olive_er,1524814062,,0,0
1580,2018-4-27,2018,4,27,16,8f9x6z,[D] Applying Machine/Deep Learning to High Dimensional Data,https://www.reddit.com/r/MachineLearning/comments/8f9x6z/d_applying_machinedeep_learning_to_high/,naturesenshi,1524815255,"Hi everyone, 

I am quite a novice to ML/DL and am looking wanting to build a model which can learn from multiple 3D matrix data sources with varying rows. Can the dimensions be retained when inputting the values into a model? If not how could I input these so that a model can learn the relationship between them? I would like to explore these options in Chainer/Tensorflow but don't know where to find the answers.

Grateful for any advice. Thanks!",4,6
1581,2018-4-27,2018,4,27,16,8f9xxj,Getting a PhD in ML/AI,https://www.reddit.com/r/MachineLearning/comments/8f9xxj/getting_a_phd_in_mlai/,jimmymvp,1524815562,[removed],0,1
1582,2018-4-27,2018,4,27,17,8f9z6m,ep 19 Automation #coworking #blockchain,https://www.reddit.com/r/MachineLearning/comments/8f9z6m/ep_19_automation_coworking_blockchain/,MLcoworking,1524816060,,1,1
1583,2018-4-27,2018,4,27,17,8fa09d,"[N] Insight expands to Canada, launching Artificial Intelligence and Data Science Fellows Programs",https://www.reddit.com/r/MachineLearning/comments/8fa09d/n_insight_expands_to_canada_launching_artificial/,molode,1524816480,,0,1
1584,2018-4-27,2018,4,27,17,8fa34d,[R] Mobile Machine Learning Using TensorFlow Lite [Videos],https://www.reddit.com/r/MachineLearning/comments/8fa34d/r_mobile_machine_learning_using_tensorflow_lite/,digitalson,1524817666,,0,1
1585,2018-4-27,2018,4,27,18,8fadd9,Bayou AI system now completes Java code for Java devs.,https://www.reddit.com/r/MachineLearning/comments/8fadd9/bayou_ai_system_now_completes_java_code_for_java/,jayakamonty,1524821710,,0,1
1586,2018-4-27,2018,4,27,18,8fah7d,[D] Why conv nets not called correlation nets ?,https://www.reddit.com/r/MachineLearning/comments/8fah7d/d_why_conv_nets_not_called_correlation_nets/,fu_2016,1524823198,Why are convolutional neural networks not called correlation neural networks ? Isnt the function that they implement correlation not convolution ? I understand that they are equivalent I am just curious if there's any historical context to all of this. Follow-up question would be that why do two notations exist when they are strictly equivalent ? Are there cases where one is better over the other ?,15,19
1587,2018-4-27,2018,4,27,19,8faqxp,Text Analytics for unknown feature(bag of words),https://www.reddit.com/r/MachineLearning/comments/8faqxp/text_analytics_for_unknown_featurebag_of_words/,mosrihari,1524826583,[removed],0,1
1588,2018-4-27,2018,4,27,20,8fat5v,Janome sewing machines,https://www.reddit.com/r/MachineLearning/comments/8fat5v/janome_sewing_machines/,psmccouk,1524827263,[removed],0,1
1589,2018-4-27,2018,4,27,20,8fayo1,case repair manual,https://www.reddit.com/r/MachineLearning/comments/8fayo1/case_repair_manual/,Mypremiummanual,1524829032,,0,1
1590,2018-4-27,2018,4,27,20,8fazi7,[D] ML/DL online coding test?,https://www.reddit.com/r/MachineLearning/comments/8fazi7/d_mldl_online_coding_test/,cbsudux,1524829300,"I have an online coding test coming up for a DL internship.

What kind of questions can I expect?

PS: If you have experience with DL online coding tests, could you please share them?",3,5
1591,2018-4-27,2018,4,27,21,8fbcel,[P]Tooder- Smart Flashcards for Curious Kids,https://www.reddit.com/r/MachineLearning/comments/8fbcel/ptooder_smart_flashcards_for_curious_kids/,jnaneshnayak,1524833049,,2,0
1592,2018-4-27,2018,4,27,22,8fbik4,Potato Chips Frying Machine Sale,https://www.reddit.com/r/MachineLearning/comments/8fbik4/potato_chips_frying_machine_sale/,lgsherry,1524834626,,1,1
1593,2018-4-27,2018,4,27,22,8fbp4s,[p] pytorch implementation of Get To The Point: Summarization with Pointer-Generator Networks,https://www.reddit.com/r/MachineLearning/comments/8fbp4s/p_pytorch_implementation_of_get_to_the_point/,atulkum,1524836250,,4,14
1594,2018-4-27,2018,4,27,23,8fbusj,Data Augmentation | How to use Deep Learning when you have Limited Data,https://www.reddit.com/r/MachineLearning/comments/8fbusj/data_augmentation_how_to_use_deep_learning_when/,nolan_chris,1524837646,,1,9
1595,2018-4-27,2018,4,27,23,8fbx16,[D] Sign language interpreter - help !,https://www.reddit.com/r/MachineLearning/comments/8fbx16/d_sign_language_interpreter_help/,adarsh1021,1524838156,"Hey guys! I am trying to build a sign language interpreter for a college project. 
So the idea is to translate sign language to text/speech in real-time.
So basically the video input has to be segmented to actions in sign-language, which can then be classified.
Any ideas on where to start or how to go about it ? 
",5,6
1596,2018-4-27,2018,4,27,23,8fc077,[R] The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/8fc077/r_the_best_of_both_worlds_combining_recent/,ofirpress,1524838846,,5,17
1597,2018-4-27,2018,4,27,23,8fc7by,[D] The Top 5 Best-Paying Companies for Machine Learning Scientists,https://www.reddit.com/r/MachineLearning/comments/8fc7by/d_the_top_5_bestpaying_companies_for_machine/,mlnsports,1524840492,,0,4
1598,2018-4-28,2018,4,28,0,8fcbhu,[1608.02025] Boundary-based MWE[multiword expression] segmentation with text partitioning [2017],https://www.reddit.com/r/MachineLearning/comments/8fcbhu/160802025_boundarybased_mwemultiword_expression/,AforAnonymous,1524841412,,1,1
1599,2018-4-28,2018,4,28,0,8fcgik,[D] Weight decay vs. L2 regularization,https://www.reddit.com/r/MachineLearning/comments/8fcgik/d_weight_decay_vs_l2_regularization/,bbabenko,1524842441,,10,58
1600,2018-4-28,2018,4,28,0,8fcp2t,DeepCode cleans your code with the power of AI,https://www.reddit.com/r/MachineLearning/comments/8fcp2t/deepcode_cleans_your_code_with_the_power_of_ai/,SYGZ95,1524844275,,0,1
1601,2018-4-28,2018,4,28,1,8fcsj5,[R] TDM: From Model-Free to Model-Based Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8fcsj5/r_tdm_from_modelfree_to_modelbased_deep/,gdny,1524845032,,9,78
1602,2018-4-28,2018,4,28,1,8fcynn,[D] What are you using these days for hyperparameter optimization?,https://www.reddit.com/r/MachineLearning/comments/8fcynn/d_what_are_you_using_these_days_for/,ballsandbutts,1524846349,"What tools and methods are you currently using in your work/hobby/study with ML? I'm especially interested in flexible tools that support a variety of methods and can be distributed across machines in a customizable way.

It seems like tools like Spearmint and Hyperopt were popular for a while, but more recent tools seem to be focused on all-in-one cloud integration platforms (e.g. google's AutoML). How have your experiences been with these services?",29,42
1603,2018-4-28,2018,4,28,1,8fd12d,Artificial life simulation.,https://www.reddit.com/r/MachineLearning/comments/8fd12d/artificial_life_simulation/,Thomas-Arys,1524846874,,0,1
1604,2018-4-28,2018,4,28,2,8fd8bi,[R] Time series forecasts and volatility measures as predictors of post-surgical death and kidney injury,https://www.reddit.com/r/MachineLearning/comments/8fd8bi/r_time_series_forecasts_and_volatility_measures/,sugarhilldt2,1524848448,,2,0
1605,2018-4-28,2018,4,28,2,8fdeyx,Can I Train a ResNet without L2 Regularization?,https://www.reddit.com/r/MachineLearning/comments/8fdeyx/can_i_train_a_resnet_without_l2_regularization/,SSuryansh,1524849870,[removed],0,1
1606,2018-4-28,2018,4,28,2,8fdf2r,[R] GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,https://www.reddit.com/r/MachineLearning/comments/8fdf2r/r_glue_a_multitask_benchmark_and_analysis/,danielcer,1524849901,,0,14
1607,2018-4-28,2018,4,28,4,8fea00,AI Weekly 27 April 2018,https://www.reddit.com/r/MachineLearning/comments/8fea00/ai_weekly_27_april_2018/,TomekB,1524856729,,0,1
1608,2018-4-28,2018,4,28,4,8fefno,neural network based handwriting keyboard (python with tensorflow),https://www.reddit.com/r/MachineLearning/comments/8fefno/neural_network_based_handwriting_keyboard_python/,idan0405,1524858034,,0,1
1609,2018-4-28,2018,4,28,4,8fegl4,"[D] Use output of unsupervised method as input for semi-supervised method and still be comparable to ""traditional"" methods?",https://www.reddit.com/r/MachineLearning/comments/8fegl4/d_use_output_of_unsupervised_method_as_input_for/,creiser,1524858255,"I am developing a clustering algorithm. My algorithm does not put every data point into a cluster. There are on purpose some data points that are not assigned to any cluster.  My current approach is to use a semi\-supervised algorithm which gets as input the labels generated by the clustering algorithm to assign a category to the rest of the data points. Naturally the overall system would still remain fully unsupervised.

Do you think it would be still fair to compare it with a ""traditional"" method that assigns a cluster to each data point right from the beginning?

Do you know about any papers that do exactly that?",19,7
1610,2018-4-28,2018,4,28,4,8fehfa,[R] Neural-Guided Deductive Search: A best of both worlds approach to program synthesis,https://www.reddit.com/r/MachineLearning/comments/8fehfa/r_neuralguided_deductive_search_a_best_of_both/,skiminok,1524858449,,1,13
1611,2018-4-28,2018,4,28,5,8femmy,images search,https://www.reddit.com/r/MachineLearning/comments/8femmy/images_search/,sam_081,1524859667,[removed],0,1
1612,2018-4-28,2018,4,28,5,8fer3c,Towards fairness in ML with adversarial networks,https://www.reddit.com/r/MachineLearning/comments/8fer3c/towards_fairness_in_ml_with_adversarial_networks/,[deleted],1524860707,[deleted],0,1
1613,2018-4-28,2018,4,28,6,8ff3my,[P] Towards fairness in ML with adversarial networks,https://www.reddit.com/r/MachineLearning/comments/8ff3my/p_towards_fairness_in_ml_with_adversarial_networks/,equialgo,1524863685,,3,22
1614,2018-4-28,2018,4,28,6,8ff9uv,Text Classification API,https://www.reddit.com/r/MachineLearning/comments/8ff9uv/text_classification_api/,Sharp_Dot,1524865245,[removed],0,1
1615,2018-4-28,2018,4,28,8,8ffteg,"[R] Mini-workshop: The Future of Random Projections II, 1pm-4pm, May 2nd, 2018, Paris, France",https://www.reddit.com/r/MachineLearning/comments/8ffteg/r_miniworkshop_the_future_of_random_projections/,compsens,1524870438,,1,2
1616,2018-4-28,2018,4,28,8,8fg4kz,[D] Why should there be more than 1 best input device?,https://www.reddit.com/r/MachineLearning/comments/8fg4kz/d_why_should_there_be_more_than_1_best_input/,[deleted],1524873517,[deleted],0,0
1617,2018-4-28,2018,4,28,12,8fhc1k,[N] Google Boosting its AI Research in Tokyo,https://www.reddit.com/r/MachineLearning/comments/8fhc1k/n_google_boosting_its_ai_research_in_tokyo/,trcytony,1524886248,,0,1
1618,2018-4-28,2018,4,28,12,8fhdrd,"[R] A Dataset of Peer Reviews (PeerRead): ACL, NIPS and ICLR",https://www.reddit.com/r/MachineLearning/comments/8fhdrd/r_a_dataset_of_peer_reviews_peerread_acl_nips_and/,downtownslim,1524886815,,4,68
1619,2018-4-28,2018,4,28,14,8fi0qd,[N] Tensorflow 1.8 has been released,https://www.reddit.com/r/MachineLearning/comments/8fi0qd/n_tensorflow_18_has_been_released/,backupcortex,1524894699,,43,232
1620,2018-4-28,2018,4,28,15,8fi3y0,How to analyse performance of a predictive model,https://www.reddit.com/r/MachineLearning/comments/8fi3y0/how_to_analyse_performance_of_a_predictive_model/,atinesh229,1524895885,[removed],0,1
1621,2018-4-28,2018,4,28,15,8fi6zk,mozilla/DeepSpeech - A TensorFlow implementation of Baidu's DeepSpeech architecture.,https://www.reddit.com/r/MachineLearning/comments/8fi6zk/mozilladeepspeech_a_tensorflow_implementation_of/,stephentt-me,1524897087,,0,1
1622,2018-4-28,2018,4,28,16,8fid4e,[R] Machine Learning. What's Next?,https://www.reddit.com/r/MachineLearning/comments/8fid4e/r_machine_learning_whats_next/,digitalson,1524899556,,0,1
1623,2018-4-28,2018,4,28,16,8fif60,[R] Artificial intelligence may be more humane than people,https://www.reddit.com/r/MachineLearning/comments/8fif60/r_artificial_intelligence_may_be_more_humane_than/,janemoz,1524900440,,0,1
1624,2018-4-28,2018,4,28,16,8fifjb,[R] From genomic data to precision medicine via machine learning,https://www.reddit.com/r/MachineLearning/comments/8fifjb/r_from_genomic_data_to_precision_medicine_via/,jackblun,1524900596,,0,1
1625,2018-4-28,2018,4,28,18,8fitlw,What does this paper exactly suggest?,https://www.reddit.com/r/MachineLearning/comments/8fitlw/what_does_this_paper_exactly_suggest/,goabiaryan,1524907046,[removed],0,1
1626,2018-4-28,2018,4,28,19,8fj0ue,[R] Choosing the Right Metric for Evaluating Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/8fj0ue/r_choosing_the_right_metric_for_evaluating/,molode,1524910350,,0,1
1627,2018-4-28,2018,4,28,19,8fj2cx,[R] How to Use Correlation to Understand the Relationship Between Variables,https://www.reddit.com/r/MachineLearning/comments/8fj2cx/r_how_to_use_correlation_to_understand_the/,polllyyy,1524910971,,0,1
1628,2018-4-28,2018,4,28,19,8fj3ac,[R] Optimal Coupon Targeting for Grocery Items: an Instacart Case Study,https://www.reddit.com/r/MachineLearning/comments/8fj3ac/r_optimal_coupon_targeting_for_grocery_items_an/,chris_shpak,1524911401,,0,1
1629,2018-4-28,2018,4,28,19,8fj4za,Pumpkin Seed Dehulling Machine|Melon Seeds Shelling Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8fj4za/pumpkin_seed_dehulling_machinemelon_seeds/,Machineprices,1524912158,,1,1
1630,2018-4-28,2018,4,28,21,8fjk04,Non For Profit,https://www.reddit.com/r/MachineLearning/comments/8fjk04/non_for_profit/,Shagggggeeee,1524918104,[removed],0,1
1631,2018-4-28,2018,4,28,21,8fjlth,Join Expert Webinar on Artificial Intelligence &amp; Deep Learning. #free Register Now!,https://www.reddit.com/r/MachineLearning/comments/8fjlth/join_expert_webinar_on_artificial_intelligence/,poojagandhi456,1524918774,,0,1
1632,2018-4-28,2018,4,28,21,8fjq4c,YouTube Says Computers Are Catching Problem Videos,https://www.reddit.com/r/MachineLearning/comments/8fjq4c/youtube_says_computers_are_catching_problem_videos/,jonfla,1524920308,,0,1
1633,2018-4-28,2018,4,28,23,8fk8cx,[R] Deep Thermal Imaging: Deep Learning + Thermal Imaging for Material Recognition - Very interesting,https://www.reddit.com/r/MachineLearning/comments/8fk8cx/r_deep_thermal_imaging_deep_learning_thermal/,BrianOcor,1524925897,,4,6
1634,2018-4-28,2018,4,28,23,8fkd1h,Need advice on a possible career change from biotech to machine learning/AI.,https://www.reddit.com/r/MachineLearning/comments/8fkd1h/need_advice_on_a_possible_career_change_from/,MyPenisIsaWMD,1524927201,[removed],0,1
1635,2018-4-29,2018,4,29,0,8fkhjb,[D] Why can't a simple 1-cell RNN simulate exponential moving average?,https://www.reddit.com/r/MachineLearning/comments/8fkhjb/d_why_cant_a_simple_1cell_rnn_simulate/,Icko_,1524928405,"By exponential moving average I mean:


mu_t = alpha\*x_t + (1-alpha)\*mu_t-1,

 where mu is the exponential moving average. It seems like a simple 1 cell RNN should be able to easily and exactly approximate this. As you can see in [ this gist however](https://gist.github.com/HristoBuyukliev/678152c504f5e917887c2fb1ea52778e) it very much does not. The closest thing I could get it to learn was some sort of random walk - i.e. predicting the previous value of x. Even this behaviour is very rare and unstable. 

I tried using more layers/units (even though that's not the point), different learning rates, optimizers, rolled vs. unrolled version, different activations and initializations. Not only is not the RNN not able to learn this simple function, but it often performs *very* poorly - e.g. the input data is between -10, +10, and it predicts values between 0 and -400. Also, the activation is linear, so it should be very difficult/impossible to get stuck in local minima?

Can anyone explain to me what is happening and how to fix it?",20,19
1636,2018-4-29,2018,4,29,0,8fkok3,Lesser know / undiscovered application of ML?,https://www.reddit.com/r/MachineLearning/comments/8fkok3/lesser_know_undiscovered_application_of_ml/,Ragnarokk_,1524930257,[removed],0,1
1637,2018-4-29,2018,4,29,2,8fl7a9,Need some logical assistance in grouping by or pivoting a dataframe in order to merge with another.,https://www.reddit.com/r/MachineLearning/comments/8fl7a9/need_some_logical_assistance_in_grouping_by_or/,anonadado,1524935096,[removed],0,1
1638,2018-4-29,2018,4,29,3,8fllhm,Which GTX 1080 Ti is better for deep learning ?,https://www.reddit.com/r/MachineLearning/comments/8fllhm/which_gtx_1080_ti_is_better_for_deep_learning/,r3535t,1524938720,[removed],0,1
1639,2018-4-29,2018,4,29,3,8flpdl,Would you upsample an image using deconvolution into 1 channel or more ?,https://www.reddit.com/r/MachineLearning/comments/8flpdl/would_you_upsample_an_image_using_deconvolution/,falmasri,1524939714,[removed],0,1
1640,2018-4-29,2018,4,29,3,8flv3y,Predicting probability y = 1 in sequential data,https://www.reddit.com/r/MachineLearning/comments/8flv3y/predicting_probability_y_1_in_sequential_data/,Eagleway,1524941166,[removed],0,1
1641,2018-4-29,2018,4,29,4,8fm0w2,"Why doesn't MCTS save all rollout trajectories, and instead expands nodes one-by-one? Just memory?",https://www.reddit.com/r/MachineLearning/comments/8fm0w2/why_doesnt_mcts_save_all_rollout_trajectories_and/,burlapScholar,1524942641,[removed],0,1
1642,2018-4-29,2018,4,29,5,8fmkft,Latent input size for generative adversarial network?,https://www.reddit.com/r/MachineLearning/comments/8fmkft/latent_input_size_for_generative_adversarial/,quietearthus,1524947769,[removed],0,1
1643,2018-4-29,2018,4,29,5,8fmlq4,Embedded deep learning resource request?,https://www.reddit.com/r/MachineLearning/comments/8fmlq4/embedded_deep_learning_resource_request/,endofline786,1524948115,[removed],0,1
1644,2018-4-29,2018,4,29,5,8fmm5g,Binary Classification: good at predicting negative class but bad at predicting positive class,https://www.reddit.com/r/MachineLearning/comments/8fmm5g/binary_classification_good_at_predicting_negative/,davidldy,1524948240,[removed],0,1
1645,2018-4-29,2018,4,29,6,8fmq8e,Pandas Question: What if the column you are trying to merge on has duplicate values that you absolutely need?,https://www.reddit.com/r/MachineLearning/comments/8fmq8e/pandas_question_what_if_the_column_you_are_trying/,anonadado,1524949353,[removed],0,1
1646,2018-4-29,2018,4,29,6,8fmtr9,[D] Statement on Nature Machine Intelligence,https://www.reddit.com/r/MachineLearning/comments/8fmtr9/d_statement_on_nature_machine_intelligence/,hardmaru,1524950293,,61,292
1647,2018-4-29,2018,4,29,7,8fn4ly,[R] DeepMind papers at ICLR 2018,https://www.reddit.com/r/MachineLearning/comments/8fn4ly/r_deepmind_papers_at_iclr_2018/,shaunlgs,1524953239,,9,31
1648,2018-4-29,2018,4,29,8,8fnr6y,[D] Has anyone used CapsuleNets in generative models?,https://www.reddit.com/r/MachineLearning/comments/8fnr6y/d_has_anyone_used_capsulenets_in_generative_models/,kylepob,1524959740,"I'm particularly curious about whether anyone has found ""unconventional"" (i.e., not classification) use cases for CapsuleNets such as for image generation. I have also wondered if CapsuleNets have value for regression tasks (such as image segmentation). ",4,7
1649,2018-4-29,2018,4,29,9,8fnxnw,"Implementing PEGASOS: Primal Estimated sub-GrAdient SOlver for SVM, using it for sentiment classification and switching to Logistic Regression Objective by changing the loss function (in Python)",https://www.reddit.com/r/MachineLearning/comments/8fnxnw/implementing_pegasos_primal_estimated_subgradient/,SandipanDeyUMBC,1524961558,,0,1
1650,2018-4-29,2018,4,29,11,8foj9g,[D] Where to begin?,https://www.reddit.com/r/MachineLearning/comments/8foj9g/d_where_to_begin/,gghjjhgfddfggff,1524968283,"Hello all. I am interested in beginning to study machine learning. I know my linear algebra. I've worked with a handful of programming languages. I'm most comfortable with C++ and lisp but can make do with whatever provided I have access to good documentation. I am most comfortable working with console based applications in a GNU/Linux environment.

Where should I begin? Is there a book everyone should read to start out? Like an SICP of AI? And/or a particular piece of software I should play around with? Thanks.",8,0
1651,2018-4-29,2018,4,29,13,8fp28g,Any good tutorial of LSTM with word2vec for text classification in pytorch?,https://www.reddit.com/r/MachineLearning/comments/8fp28g/any_good_tutorial_of_lstm_with_word2vec_for_text/,[deleted],1524974568,,0,1
1652,2018-4-29,2018,4,29,14,8fpei7,[P] Easily Requesting and Provisioning AWS GPU Spot Instances for Deep Learning using Terraform,https://www.reddit.com/r/MachineLearning/comments/8fpei7/p_easily_requesting_and_provisioning_aws_gpu_spot/,[deleted],1524978983,[deleted],0,1
1653,2018-4-29,2018,4,29,14,8fpfzw,[D] Windows vs linux for machine learning,https://www.reddit.com/r/MachineLearning/comments/8fpfzw/d_windows_vs_linux_for_machine_learning/,advaithjai,1524979544,"Hi guys, I am a beginner in machine learning and I'm just getting started with deep learning using tensorflow. Should I use windows or Linux for installing tensorflow? And how does the performance compare? ",38,8
1654,2018-4-29,2018,4,29,14,8fpjlq,Automated Provisioning of AWS Spot Instances for GPU-based Deep Learning Workloads on the Cloud,https://www.reddit.com/r/MachineLearning/comments/8fpjlq/automated_provisioning_of_aws_spot_instances_for/,[deleted],1524980954,,0,1
1655,2018-4-29,2018,4,29,14,8fpl0c,Terraform + AWS: Fully Automated Provisioning of AWS Spot Instances for GPU-based Deep Learning Workloads,https://www.reddit.com/r/MachineLearning/comments/8fpl0c/terraform_aws_fully_automated_provisioning_of_aws/,[deleted],1524981569,,0,1
1656,2018-4-29,2018,4,29,15,8fpmmr,[P] Terraform + AWS: Fully Automated Provisioning of AWS Spot Instances for GPU-based Deep Learning Workloads,https://www.reddit.com/r/MachineLearning/comments/8fpmmr/p_terraform_aws_fully_automated_provisioning_of/,[deleted],1524982227,[deleted],0,1
1657,2018-4-29,2018,4,29,15,8fpomd,[P] Terraform + AWS: Fully Automated Provisioning of AWS Spot Instances for GPU-based Deep Learning Workloads,https://www.reddit.com/r/MachineLearning/comments/8fpomd/p_terraform_aws_fully_automated_provisioning_of/,brownmamba94,1524983026,,3,9
1658,2018-4-29,2018,4,29,15,8fpq8m,Indian Police Traces 3000 Missing Children Using Facial Recognition System,https://www.reddit.com/r/MachineLearning/comments/8fpq8m/indian_police_traces_3000_missing_children_using/,analyticsinsight,1524983687,,0,1
1659,2018-4-29,2018,4,29,15,8fptgu,Does sklearn in python a good thing?,https://www.reddit.com/r/MachineLearning/comments/8fptgu/does_sklearn_in_python_a_good_thing/,itsrandeep,1524985064,[removed],0,1
1660,2018-4-29,2018,4,29,16,8fq0vx,"Will adding an ""other"" category help prevent adversarial attacks?",https://www.reddit.com/r/MachineLearning/comments/8fq0vx/will_adding_an_other_category_help_prevent/,phizaz,1524988491,[removed],0,1
1661,2018-4-29,2018,4,29,16,8fq0ze,"[D] What are examples ""alternative"" sequence models?",https://www.reddit.com/r/MachineLearning/comments/8fq0ze/d_what_are_examples_alternative_sequence_models/,[deleted],1524988540,[deleted],0,1
1662,2018-4-29,2018,4,29,17,8fq2af,Look what I've got[humour?],https://www.reddit.com/r/MachineLearning/comments/8fq2af/look_what_ive_gothumour/,trrahul,1524989134,,0,1
1663,2018-4-29,2018,4,29,17,8fq2cp,"[D] What are examples of ""alternative"" sequence models?",https://www.reddit.com/r/MachineLearning/comments/8fq2cp/d_what_are_examples_of_alternative_sequence_models/,Akiiino,1524989165,"Transformer, I'd say, is quite different from regular models; off the top of my head I can also name WaveNet. What other interesting models do you know of? I'd love to read up on this topic.",5,17
1664,2018-4-29,2018,4,29,18,8fqb0a,Why is Z-dimension for generator in GANs usually 100?,https://www.reddit.com/r/MachineLearning/comments/8fqb0a/why_is_zdimension_for_generator_in_gans_usually/,[deleted],1524993231,,0,1
1665,2018-4-29,2018,4,29,18,8fqcfv,[D] Why is Z-dimension for GANs usually 100?,https://www.reddit.com/r/MachineLearning/comments/8fqcfv/d_why_is_zdimension_for_gans_usually_100/,gstark0,1524993921,"I'm playing around with GANs, I've got a question which I can't find answer for. Why is Z-dimension (random vector noise) for GANs usually 100? I saw a lot of GitHub projects and online tutorials, seems like the random vector has always the size of 100. Is it confirmed that it gives the best results? What if I changed that to e.g 1000? How does it affect the generated images?",19,34
1666,2018-4-29,2018,4,29,19,8fqlef,Buying less than $2000 computer for machine learning,https://www.reddit.com/r/MachineLearning/comments/8fqlef/buying_less_than_2000_computer_for_machine/,UserWithComputer,1524998146,[removed],0,1
1667,2018-4-29,2018,4,29,20,8fqr32,[R] Measuring the Intrinsic Dimension of Objective Landscapes,https://www.reddit.com/r/MachineLearning/comments/8fqr32/r_measuring_the_intrinsic_dimension_of_objective/,[deleted],1525000664,[deleted],0,1
1668,2018-4-29,2018,4,29,22,8frfps,"How to perform transfer learning on a pre trained convolutional neural network, when the new image dataset is small but quite different from the previous dataset on which the cnn was trained on?",https://www.reddit.com/r/MachineLearning/comments/8frfps/how_to_perform_transfer_learning_on_a_pre_trained/,ritabratamaiti,1525009841,[removed],0,1
1669,2018-4-29,2018,4,29,23,8frpct,Credit Score model - data from the kaggle give me some credit competition,https://www.reddit.com/r/MachineLearning/comments/8frpct/credit_score_model_data_from_the_kaggle_give_me/,idoZeh37,1525012650,,0,1
1670,2018-4-30,2018,4,30,0,8fry8i,Building a Content-Based Search Engine IV: Earth Mover's Distance,https://www.reddit.com/r/MachineLearning/comments/8fry8i/building_a_contentbased_search_engine_iv_earth/,deepideas,1525015089,,0,1
1671,2018-4-30,2018,4,30,2,8fst0u,Can we solve Turing machine's Halting problem by machine learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/8fst0u/can_we_solve_turing_machines_halting_problem_by/,ajeenkkya,1525022917,[removed],0,1
1672,2018-4-30,2018,4,30,2,8fsvev,Opinions on Multi-agent Machine Learning Book?,https://www.reddit.com/r/MachineLearning/comments/8fsvev/opinions_on_multiagent_machine_learning_book/,Julep13,1525023500,[removed],0,1
1673,2018-4-30,2018,4,30,2,8fszac,Can one publish a research paper in machine learning while working in a startup company?,https://www.reddit.com/r/MachineLearning/comments/8fszac/can_one_publish_a_research_paper_in_machine/,keyurparalkar,1525024451,[removed],0,1
1674,2018-4-30,2018,4,30,3,8ft2i1,Should I post my problem to ALE or Gym?,https://www.reddit.com/r/MachineLearning/comments/8ft2i1/should_i_post_my_problem_to_ale_or_gym/,yazriel0,1525025230,[removed],1,1
1675,2018-4-30,2018,4,30,3,8ft9zr,[D] Can recurrent neural networks perform similar functions as Kalman filters?,https://www.reddit.com/r/MachineLearning/comments/8ft9zr/d_can_recurrent_neural_networks_perform_similar/,interstellarhighway,1525027029,"I've read that RNNs are particularly well suited for time series predictions, especially equipped with LSTM units that can learn from past data and estimate dependence between instants.   

This makes me wonder: can RNNs perform estimation like conventional Kalman filters do? For example, in the case of an IMU, typically Kalman filters predict the orientations given raw data from the individual sensors. Would the RNN be able to learn the mapping between raw IMU data and filtered orientations, and predict for future timesteps? If so, it brings me to my second question: would they also be able to 'learn' the parameters that model the IMU: such as bias, noise etc.?",14,74
1676,2018-4-30,2018,4,30,3,8ftefg,[D] How do you handle hyper parameter optimization?,https://www.reddit.com/r/MachineLearning/comments/8ftefg/d_how_do_you_handle_hyper_parameter_optimization/,iamiamwhoami,1525028100,,8,1
1677,2018-4-30,2018,4,30,3,8ftfhw,[D] Image sequence generation with VAE and RNN.,https://www.reddit.com/r/MachineLearning/comments/8ftfhw/d_image_sequence_generation_with_vae_and_rnn/,gabegabe6,1525028374,"[Github](https://github.com/gaborvecsei/Image-Sequence-Generation-With-VAE-and-RNN)

I wanted to do a quick experiment with image sequence generation.

I thought it is a good idea to hook up a VAE with an RNN to generate new images. But as I saw, it does not generate any meaningful.

This is how the generated sequence looks like: [GIF](https://github.com/gaborvecsei/Image-Sequence-Generation-With-VAE-and-RNN/raw/master/art/generated_image_sequence.gif)
It is almost static.

How would you try to fix this? Or am I approaching from a wrong side?",14,13
1678,2018-4-30,2018,4,30,4,8ftpmo,"[P] Job board exclusively for Remote Jobs in Machine Learning, Deep Learning and Data Science",https://www.reddit.com/r/MachineLearning/comments/8ftpmo/p_job_board_exclusively_for_remote_jobs_in/,Sig_Luna,1525030800,,28,327
1679,2018-4-30,2018,4,30,4,8ftrxy,[D] what are some resources this community would recommend to get a good understanding of ML models?,https://www.reddit.com/r/MachineLearning/comments/8ftrxy/d_what_are_some_resources_this_community_would/,cohenoshri,1525031365,,4,0
1680,2018-4-30,2018,4,30,6,8fukjo,[D] Gomoku/Omok/Renju Game Dataset,https://www.reddit.com/r/MachineLearning/comments/8fukjo/d_gomokuomokrenju_game_dataset/,karmically,1525038275,,1,4
1681,2018-4-30,2018,4,30,7,8fuogc,"[D] What is the closest thing we have today to a ""General theory of Intelligence""?",https://www.reddit.com/r/MachineLearning/comments/8fuogc/d_what_is_the_closest_thing_we_have_today_to_a/,sanity,1525039287,[removed],0,1
1682,2018-4-30,2018,4,30,7,8fuoz3,"Federated Learning, Kotlin and Android",https://www.reddit.com/r/MachineLearning/comments/8fuoz3/federated_learning_kotlin_and_android/,mccorby72,1525039414,,0,1
1683,2018-4-30,2018,4,30,7,8fuv24,"[D] Does ""t-SNE applied to single cell data"" deserve a patent?",https://www.reddit.com/r/MachineLearning/comments/8fuv24/d_does_tsne_applied_to_single_cell_data_deserve_a/,lmcinnes,1525040981,,15,23
1684,2018-4-30,2018,4,30,8,8fvcit,[D] 12 Useful Things to Know about Machine Learning  Towards Data Science,https://www.reddit.com/r/MachineLearning/comments/8fvcit/d_12_useful_things_to_know_about_machine_learning/,_alphamaximus_,1525045628,,0,1
1685,2018-4-30,2018,4,30,9,8fvoca,"[D] If you didn't have any graduate work in math, statistics, or computer science - how would you go about getting a job in AI research?",https://www.reddit.com/r/MachineLearning/comments/8fvoca/d_if_you_didnt_have_any_graduate_work_in_math/,R_E_G_U_L_A_R,1525048842,"I feel a bit silly posting this here, so I hope it's OK. I'm coming to you guys because I don't really have anyone else. I'm in an odd situation, and I would very much appreciate anyone taking the time to read this and think about it. 

I have a Ph.D in experimental psychology. I went into psychology because I want to understand how people work. However, after about a year of my Ph.D, I started working at a startup and discovered programming; I fell in love. And later, I realized that the quote left on Feynman's blackboard - ""What I cannot create, I do not understand"" is incredibly true of people. I found Silver's lectures on RL and everything clicked into place. All the programming and math with all the neuroscience I love. *This is what I want to do for the rest of my life.*

But, I already have one Ph.D. I've self-taught my way a decently far way. I can program most RNN variants from scratch and in tensorflow, I can read a paper and implement it - I mostly stick to biologically plausible models out of Bengio's lab - and work through Sutton's book. I work as a data scientist. Aside from that, my strength has always been in creativity - I take things and change them, or do something entirely different. It's made me a good psychological scientist (I finished my PhD in less than three years, got published in my field's top journal, etc), and I'm sure I would do well in AI research.

The problem is that I have a job that pays well and a new family, and cleverness and creativity are not enough in a field with as much depth and challenge as this; excellence is not at all a part-time affair. I've tried waking up at 4 for some time and doing a few hours of work before work, I've taken Coursera courses and bought books (e.g. PGMs by Daphne Koller), but... to get a job in this area, you have to publish, you have to know people, and you have to have the strong sort of foundation earned through a decade of work in universities. I would say I lack that foundation - in complex calculus, in proofs, in probability - and I lack real concrete proof that I can produce paper-worthy work. Both those things deserve and require a great amount of time that my life does not currently allow. You also maybe need to know people in the field, and ... that is difficult. My life up to this point has not crossed with computer scientists or mathematicians. I have to cold email, and so far that hasn't gone well. The only person to respond was Robert Sutton who replied *immediately* and scheduled a call the next day, then wasn't there for the call and never responded again (I get the feeling he's one of those incredibly energetic and inevitably overcommitted people who has ten thousand people clamoring for his time). I guess I miss having a mentor.

In short: I love what you guys do, and I would really love to do it too. I'm just afraid it will take a large leap, and I don't want to put my family's well-being at too much risk for a personal want. 

If you were in my position, what would you do? Save up enough to take a year off, and quit the job? Go back to school? Try desperately to create in your spare time? I'm 31 now, and I feel like the feel is moving so quickly I'm just never going to catch up and contribute to this wonderful field. 



",21,11
1686,2018-4-30,2018,4,30,10,8fw4g0,Google CEO: A.I. is more important than fire or electricity,https://www.reddit.com/r/MachineLearning/comments/8fw4g0/google_ceo_ai_is_more_important_than_fire_or/,SYGZ95,1525053465,,1,1
1687,2018-4-30,2018,4,30,11,8fwg0b,[P] Implementation of QANet with PyTorch,https://www.reddit.com/r/MachineLearning/comments/8fwg0b/p_implementation_of_qanet_with_pytorch/,monoidz,1525056895,"Link: https://github.com/hengruo/QANet-pytorch

Welcome any feedback or contributions! Thanks!",1,12
1688,2018-4-30,2018,4,30,12,8fwqr0,Building Scikit-Learn Pipelines With Pandas DataFrames,https://www.reddit.com/r/MachineLearning/comments/8fwqr0/building_scikitlearn_pipelines_with_pandas/,ramhiser,1525060160,,0,1
1689,2018-4-30,2018,4,30,13,8fx2k5,What are some examples of deep learning being used for incomplete information games?,https://www.reddit.com/r/MachineLearning/comments/8fx2k5/what_are_some_examples_of_deep_learning_being/,PimpMagician,1525064014,[removed],0,1
1690,2018-4-30,2018,4,30,14,8fx709,Google at ICLR 2018,https://www.reddit.com/r/MachineLearning/comments/8fx709/google_at_iclr_2018/,circuithunter,1525065609,,0,1
1691,2018-4-30,2018,4,30,14,8fx7lo,[D] Google Publications at ICLR 2018,https://www.reddit.com/r/MachineLearning/comments/8fx7lo/d_google_publications_at_iclr_2018/,baylearn,1525065840,,2,32
1692,2018-4-30,2018,4,30,15,8fxg0n,1- ,https://www.reddit.com/r/MachineLearning/comments/8fxg0n/1_/,Woodworking94,1525069064,,0,1
1693,2018-4-30,2018,4,30,15,8fxjl2,[D] The relationship between necessity of regularization techniques and parameter budget relative to dataset size,https://www.reddit.com/r/MachineLearning/comments/8fxjl2/d_the_relationship_between_necessity_of/,HigherTopoi,1525070468,"Let's say there is a fixed size of dataset. One can theoretically apply a NN with the parameter budget just right for this size of the dataset without having to rely on any regularization technique. However, in reality we have to rely on regularization techniques (unless the dataset is too large), which means that the NN we use tends to be slightly overparametrized. Is this because it's easier to adjust the hyperparameters of the regularization techniques than the parameter size? Or is it because slightly overparametrized NN with reg. techniques has a better generalization capability due to some theoretical reason? How do we decide a given dataset is so large that we shouldn't use any reg. technique? Transformer paper used dropout even though WMT 2014 En-Fr dataset is so large. Is it resource-dependent, i.e. if you have enough GPU memory, is it recommended to use reg. techniques and more than enough parameters? 
 

",0,1
1694,2018-4-30,2018,4,30,15,8fxkvi,Does anyone use Bernoulli or other distributions as prior for training Variational Autoencoder(VAE)?,https://www.reddit.com/r/MachineLearning/comments/8fxkvi/does_anyone_use_bernoulli_or_other_distributions/,leewk92,1525070988,[removed],0,1
1695,2018-4-30,2018,4,30,15,8fxlmr,Suggestions for resources/reading for a specific summer project,https://www.reddit.com/r/MachineLearning/comments/8fxlmr/suggestions_for_resourcesreading_for_a_specific/,itBlimp1,1525071283,"I'm a college freshman going on sophomore who is planning on doing an ML project over the summer. I'm still deciding between making an AI for a computer game that I wrote or making a drawing to graph* generator that (I think) would use image recognition. Based on what I've researched so far, I'm thinking about using a neural network since it seems both effective and begginer friendly (compared to everything else). What are some good resources to begin learning the essential theory and implementation behind them? I'm planning on going back and rewatching 3Blue1Browns videos just to start.


*graph in the mathematical sense (edges and vertices) ",0,1
1696,2018-4-30,2018,4,30,16,8fxupv,[D] Need Recommendations for Training Models.,https://www.reddit.com/r/MachineLearning/comments/8fxupv/d_need_recommendations_for_training_models/,GrandmasterMochizuki,1525074971,"I am currently pursuing my Master's thesis and recently finished writing code for my model and successfully trained it on my local machine.

Now, I need to get started with some serious experiments and hence need a lot of computation power. What setup would you recommend for me? I was thinking of using one of the clouds.  Is anybody cloud service giving free GPUs for students doing ML-research?",3,4
1697,2018-4-30,2018,4,30,17,8fxz0x,Demo and Tutorial of python Neuro Evolution for ML beginners.,https://www.reddit.com/r/MachineLearning/comments/8fxz0x/demo_and_tutorial_of_python_neuro_evolution_for/,FitMachineLearning,1525076849,,0,1
1698,2018-4-30,2018,4,30,17,8fy35q,Can neural network learn orthogonal basis functions?,https://www.reddit.com/r/MachineLearning/comments/8fy35q/can_neural_network_learn_orthogonal_basis/,alayaMatrix,1525078670,[removed],0,1
1699,2018-4-30,2018,4,30,18,8fy3oc,[D] Comparing model performance on different image datasets,https://www.reddit.com/r/MachineLearning/comments/8fy3oc/d_comparing_model_performance_on_different_image/,ahmed_shariff,1525078892,"The distribution of a dataset generally has an impact on the resulting model performance. Other than the model accuracy, is there a metric to use to compare image datasets?",3,2
1700,2018-4-30,2018,4,30,18,8fy9j2,Is my Principal Component Analysis implementation correct?,https://www.reddit.com/r/MachineLearning/comments/8fy9j2/is_my_principal_component_analysis_implementation/,Ozzah,1525081335,[removed],0,1
1701,2018-4-30,2018,4,30,18,8fya5z,[P] Feedback on my neural net API for my written-from-scratch tensor library (x-post /r/neuralnetworks),https://www.reddit.com/r/MachineLearning/comments/8fya5z/p_feedback_on_my_neural_net_api_for_my/,Karyo_Ten,1525081588,"Hey, I've been working for a bit more than a year on my own tensor library from scratch (first commit on April 13, 2017).

What started as a hobby and curiosity project to learn more about linear algebra, machine learning, deep learning and a young programming language called Nim became a huge evening time sink.

After implementing Numpy-like ndarrays, Torch/Tensorflow like primitives, I just finalised the first part of my high-level API which hopefully takes the best from Keras and PyTorch.

Id like your feedback on that. Quick note on Nim, it is a strongly typed language, hence why you see f32/float32 from time to time.

For example, declaring a two-layers NN currently is like this:

    # ##################################################################
    # Environment variables
    
    # N is batch size; D_in is input dimension;
    # H is hidden dimension; D_out is output dimension.
    let (N, D_in, H, D_out) = (64, 1000, 100, 10)
    
    # Create the autograd context that will hold the computational graph
    let ctx = newContext Tensor[float32]
    
    # Create random Tensors to hold inputs and outputs, and wrap them in Variables.
    let
      x = ctx.variable(randomTensor[float32](N, D_in, 1'f32))
      y = randomTensor[float32](N, D_out, 1'f32)
    
    # ##################################################################
    # Define the model.
    
    network ctx, TwoLayersNet:
      layers:
        fc1: Linear(D_in, H)
        fc2: Linear(H, D_out)
      forward x:
        x.fc1.relu.fc2
    
    let
      model = ctx.init(TwoLayersNet)
      optim = model.optimizerSGD(learning_rate = 1e-4'f32)
    
    # ##################################################################
    # Training
    
    for t in 0 ..&lt; 500:
      let
        y_pred = model.forward(x)
        loss = mse_loss(y_pred, y)
    
      echo &amp;""Epoch {t}: loss {loss.value[0]}""
    
      loss.backprop()
      optim.update()
This is a port of Jcjohnson PyTorch example: https://github.com/jcjohnson/pytorch-examples#pytorch-autograd.

3 examples are available directly in my repo: https://github.com/mratsim/Arraymancer/tree/master/examples.

A MNIST simple convnet with 2 conv layers, 1 hidden layer and automatic shape inference would be like this:

    randomize(42) # Random seed for reproducibility
    
    let
      ctx = newContext Tensor[float32] # Autograd/neural network graph
      n = 32                           # Batch size
    
    let
      x_train = read_mnist_images(""build/train-images.idx3-ubyte"").astype(float32) / 255'f32
      X_train = ctx.variable x_train.unsqueeze(1) # Change shape from [N, H, W] to [N, C, H, W], with C = 1
    
      y_train = read_mnist_labels(""build/train-labels.idx1-ubyte"").astype(int)
    
      x_test = read_mnist_images(""build/t10k-images.idx3-ubyte"").astype(float32) / 255'f32
      X_test = ctx.variable x_test.unsqueeze(1) Change shape from [N, H, W] to [N, C, H, W], with C = 1
      y_test = read_mnist_labels(""build/t10k-labels.idx1-ubyte"").astype(int)
    
    network ctx, DemoNet:
      layers:
        x:          Input([1, 28, 28])
        cv1:        Conv2D(x.out_shape, 20, 5, 5)
        mp1:        MaxPool2D(cv1.out_shape, (2,2), (0,0), (2,2))
        cv2:        Conv2D(mp1.out_shape, 50, 5, 5)
        mp2:        MaxPool2D(cv2.out_shape, (2,2), (0,0), (2,2))
        hidden:     Linear(mp2.out_shape.flatten, 500)
        classifier: Linear(500, 10)
      forward x:
        x.cv1.relu.mp1.cv2.relu.mp2.flatten.hidden.relu.classifier
    
    let model = ctx.init(DemoNet)
    let optim = model.optimizerSGD(learning_rate = 0.01'f32)
    
    . &lt; Training loop &gt; 
    
So what I would like to know is:

   - What are your main grips with the current neural networks library?
   - If you could do it yourself what syntax would you prefer to use for which use cases?
   - What do you think of my network declaration section?
",4,7
1702,2018-4-30,2018,4,30,18,8fyaig,"3-years Funded PhD position on Machine Learning and Sleep at Imperial College London,UK",https://www.reddit.com/r/MachineLearning/comments/8fyaig/3years_funded_phd_position_on_machine_learning/,giorgiogilestro,1525081715,,0,1
1703,2018-4-30,2018,4,30,18,8fyapl,Generic time series classification: LSTM vs boosted Decision Trees + time series feature extraction?,https://www.reddit.com/r/MachineLearning/comments/8fyapl/generic_time_series_classification_lstm_vs/,bonjarno65,1525081772,"Hi all -

I have to maintain and develop multiple models to classify time series data. Right now the procedure to develop a new classifier is:

1) assemble a training set of 20K time series examples for class ""A"" and 1-5K time series examples for class ""B"" (or as many class ""B"" examples as possible).

2) Extract thousands of different time series features using a time series feature extraction package. Manually engineer some time series features (this takes time and domain specific knowledge!).

3) Use different algorithms to determine feature importances - grab only the 200-500 most important features.

4) train decision tree model on most important time series features using cross validation + bagging.

5) Deploy model to real time data streams and evaluate results.

The issue with this procedure is that often I have to come up with time series features by hand in step 2 above. I have to do clever, domain knowledge specific feature engineering manually.

Would using an LSTM instead save some time in this process or are there other issues that arise that make building an LSTM classifier take about the same amount of time?",0,1
1704,2018-4-30,2018,4,30,19,8fyhbc,"We showed you how to send simple messages in our last video. Here is the next video in our series, designed to help you get the most out of Engati. Build functional bots with rich user experience flows using the Send Carousel node. Click the video below to find out how.",https://www.reddit.com/r/MachineLearning/comments/8fyhbc/we_showed_you_how_to_send_simple_messages_in_our/,parousiakhan,1525084329,,0,1
1705,2018-4-30,2018,4,30,19,8fyhsf,Relationship between generalization ability of linear classifier and parameters of probability distribution.,https://www.reddit.com/r/MachineLearning/comments/8fyhsf/relationship_between_generalization_ability_of/,Estarabim,1525084513,[removed],0,1
1706,2018-4-30,2018,4,30,21,8fz0ti,Product-Pad Printing Machines in india | Pad Printing Machines in haryana | Pad Printing Machines in ncr,https://www.reddit.com/r/MachineLearning/comments/8fz0ti/productpad_printing_machines_in_india_pad/,cindymoond,1525090838,,0,1
1707,2018-4-30,2018,4,30,21,8fz4z7,"[N] PyTorch 0.4.0, Google Brain Tokyo, QuickNLP, Multilingual NLU, PeerRead dataset, PyTorch GAN, ML Openness, SGD Earth, DL for Alzheimers Detection,",https://www.reddit.com/r/MachineLearning/comments/8fz4z7/n_pytorch_040_google_brain_tokyo_quicknlp/,omarsar,1525092023,,0,1
1708,2018-4-30,2018,4,30,22,8fzbb4,[D] Does anyone else in industry feel like this?,https://www.reddit.com/r/MachineLearning/comments/8fzbb4/d_does_anyone_else_in_industry_feel_like_this/,shayben,1525093717,,3,0
1709,2018-4-30,2018,4,30,22,8fzcta,[D] Gensim Survey 2018 | RARE Technologies,https://www.reddit.com/r/MachineLearning/comments/8fzcta/d_gensim_survey_2018_rare_technologies/,pmigdal,1525094115,,0,10
1710,2018-4-30,2018,4,30,22,8fzf9d,Revealed: how bookies use AI to keep gamblers hooked | Technology,https://www.reddit.com/r/MachineLearning/comments/8fzf9d/revealed_how_bookies_use_ai_to_keep_gamblers/,keyurparalkar,1525094756,,0,1
1711,2018-4-30,2018,4,30,22,8fzj0f,Pytorch implementation of Deep Learning for Physical Processes,https://www.reddit.com/r/MachineLearning/comments/8fzj0f/pytorch_implementation_of_deep_learning_for/,ChocoMoi,1525095734,,1,1
1712,2018-4-30,2018,4,30,22,8fzkwc,[R] Detecting Sarcasm with Deep Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8fzkwc/r_detecting_sarcasm_with_deep_convolutional/,omarsar,1525096240,,88,555
1713,2018-4-30,2018,4,30,22,8fzl6s,[D] Introduction to Deep Q-learning with SynapticJS &amp; ConvNetJS - build a connect 4 AI,https://www.reddit.com/r/MachineLearning/comments/8fzl6s/d_introduction_to_deep_qlearning_with_synapticjs/,serdnaxela,1525096310,,3,10
1714,2018-4-30,2018,4,30,23,8fzn4y,[D] How do you structure your experimentation cycles?,https://www.reddit.com/r/MachineLearning/comments/8fzn4y/d_how_do_you_structure_your_experimentation_cycles/,TheNewFake,1525096817,"I have limited compute. What do you do after you write out code for your idea and when the networks are training? Usually, the next thing I want to try is dependant on the result of the current run. There generally isnt a lot of housekeeping needed with code or anything


Other than just reading papers or browsing reddit/twitter when idle, are there any tips to make the most of a Deep Learning work week?",2,18
1715,2018-4-30,2018,4,30,23,8fzqle,The Coding Train 6.1: Introduction to TensorFlow.js - Intelligence and Learning,https://www.reddit.com/r/MachineLearning/comments/8fzqle/the_coding_train_61_introduction_to_tensorflowjs/,utopiah,1525097613,,0,2
1716,2018-4-30,2018,4,30,23,8fzr01,Trick AI with optical illusions,https://www.reddit.com/r/MachineLearning/comments/8fzr01/trick_ai_with_optical_illusions/,kokobannana,1525097712,,0,1
1717,2018-4-30,2018,4,30,23,8fzsv0,I want to learn Machine Learning. Where do I start? or where do I go after I complete Andrew Ng's course on Coursera?,https://www.reddit.com/r/MachineLearning/comments/8fzsv0/i_want_to_learn_machine_learning_where_do_i_start/,ajays97,1525098144,[removed],0,1
