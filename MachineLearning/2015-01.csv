,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2015-1-1,2015,1,1,9,2qyusn,Free Code Camp is Now Open Source,https://www.reddit.com/r/MachineLearning/comments/2qyusn/free_code_camp_is_now_open_source/,FreeCodeCamp,1420071903,,0,0
1,2015-1-1,2015,1,1,11,2qz36s,AIXI,https://www.reddit.com/r/MachineLearning/comments/2qz36s/aixi/,[deleted],1420077927,"Does anyone know the relative computational requirements to achieve similar predictive performance using Monte Carlo AIXI algorithims vs nerual nets or SVMs or other machine learning methods?

Does anyone think that AIXI may take over the machine learning field if quantum computing is perfected?  It seems to me that the only advantage of not using AIXI is to save computational resources, but with quantum computing that may be unececessary.",2,0
2,2015-1-1,2015,1,1,14,2qzibe,Measuring human performance on standard image classification tasks,https://www.reddit.com/r/MachineLearning/comments/2qzibe/measuring_human_performance_on_standard_image/,rcparts,1420090180,,7,10
3,2015-1-2,2015,1,2,1,2r0gu6,How did you get good at ML?,https://www.reddit.com/r/MachineLearning/comments/2r0gu6/how_did_you_get_good_at_ml/,Nixonite,1420128137,"I feel like practice is making me better at it, but I'm at a serious grinding portion of my journey into this subject.

I've been reading Intro to Statistical Learning from the beginning and I'm just over 100 pages in, and on the side I've been using ""Building Machine Learning Systems in Python"" for practice since I much prefer python over R. 

I even have a data set that I personally scraped from scratch, and I'm starting to feel like this whole ""getting the data is 85% of the work"" is a lie. Getting the data was the easy part for me, this ML business is tricky stuff.

Does anyone know of an even simpler way to get into all of this? 

My current knowledge is of regression (I have practiced simple linear regression, and a little bit of polynomial regression, and I have only read about multilinear regression) and just a tad bit of K-means through my reading of ISL. 

Can someone here tell me about how they ""got good"" at ML? Am I just struggling or is this normal? My reading has finally reached the beginning of classification but I don't feel like I have everything quite understood yet because I haven't practiced enough. Should I try and continue to read a bit, practice a bit and slowly grind my way through or did you find that reading a lot and then practicing a lot was a better method? i.e. do the reading first, then the practice instead of trying both simultaneously. 

For programming, it was easier and more interesting to learn by doing instead of by reading. I can understand the math but like any other math book, it's slow and can get rather boring quickly. I suppose I just want to develop ""ML maturity"" if that's a term, analogical to ""mathematical maturity.""

The good thing is that I have noticed some progress already, but ONLY through practicing with code. Reading the book alone doesn't give me nearly as well of an understanding of the material, even if the graphs and resulting code is presented in front of me. I can read the code and understand it, but it's not quite the same as being able to do it from scratch on my own when I see fit.",49,33
4,2015-1-2,2015,1,2,1,2r0gxu,Google's Quoc Le on Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2r0gxu/googles_quoc_le_on_deep_learning/,SoundsSerious,1420128230,,0,13
5,2015-1-2,2015,1,2,3,2r0u4u,Learning Information Geometry,https://www.reddit.com/r/MachineLearning/comments/2r0u4u/learning_information_geometry/,InfinityCoffee,1420137009,"I have recently become interested in this field, but sadly my graduate studies haven't covered manifolds, so I am feeling a bit out of my depth. I think I am starting to understand the basics of manifolds, but transferring that understanding to manifolds of probability distributions is non-trivial. 

I am particularly interested in the ""naturalness"" of the Fisher metric. Given a parametric family, why is this the best choice of metric on the manifold? If this metric really is the most natural choice under some criteria, is a path integral over a geodesic then the most natural choice of distance measure, and if it is, how does it compare to e.g. Kullback-Leibler? It would also seem to me that the distance would then be hugely dependent on the choice of manifold, since the Fisher matrix/metric is intrinsically defined by way of parameters.  

What introductory material would you advise for people with some knowledge of real analysis, but no formal knowledge of manifolds and a particular interest in the statistical aspects?",14,9
6,2015-1-2,2015,1,2,4,2r108p,Must read papers on CNNs and RNNs?,https://www.reddit.com/r/MachineLearning/comments/2r108p/must_read_papers_on_cnns_and_rnns/,jaythejet,1420140549,"Hi guys.

I'm been looking at recent developments in Neural Networks and my attention got caught by Convolutional Neural Nets and Recurrent Neural Nets.

I've found some material online about how some companies like Google use them for things like scene recognition or Baidu using CNNs for speech recognition.

Nonetheless, I'd like to have a deeper understanding of CNNs and RNNs, starting from basics and going into details. Are there essential, MUST READ papers on either of these types of nets that I may be missing out?

Thanks in advance",5,17
7,2015-1-2,2015,1,2,6,2r1csh,A Definition of Intelligence,https://www.reddit.com/r/MachineLearning/comments/2r1csh/a_definition_of_intelligence/,jostmey,1420147728,,11,0
8,2015-1-2,2015,1,2,8,2r1qiv,Q: Name of this deep learning labeling tool,https://www.reddit.com/r/MachineLearning/comments/2r1qiv/q_name_of_this_deep_learning_labeling_tool/,is4junk,1420155545,I was watching this ted talk [Jeremy Howard: The wonderful and terrifying implications of computers that can learn](https://www.youtube.com/watch?v=t4kyRyKyOpo&amp;channel=TEDtalksDirector) and at the 13:20 mark it showed a graphical labeling tool.  Does anyone know the name of it?  Is there an equivalent way to do it in python? ,3,3
9,2015-1-2,2015,1,2,9,2r1x30,Can anyone recommend a state-of-the-art system for text-regression? Or a powerful standard approach?,https://www.reddit.com/r/MachineLearning/comments/2r1x30/can_anyone_recommend_a_stateoftheart_system_for/,[deleted],1420159400,"The most commonly mentioned standard is Naive Bayes with bag-of-words, but it is better suited for classification. Is there a good modern approach for predicting continuous values from documents with continuous labels? 

I can think of lots of ideas but I have no idea which might be more standard or have the easiest to use available implementations. Support Vector Regression? Generalized additive model? Linear regression on logged tf-idf counts? Almost all the neural network/deep learning examples I can find are based on image classification problems.

Thank!",6,1
10,2015-1-2,2015,1,2,11,2r287t,What are the pitfalls of ML?,https://www.reddit.com/r/MachineLearning/comments/2r287t/what_are_the_pitfalls_of_ml/,uber_kerbonaut,1420166039,"Is there a good resource that you know of which gives a basic overview of the various pitfalls that a practitioner of ML must be aware of?

I'm thinking about the variance-bias trade off, overfitting, and the multiple comparisons problem. Are there more like this?",6,2
11,2015-1-2,2015,1,2,20,2r3d7i,[Question] Behavioural and sentiment analysis,https://www.reddit.com/r/MachineLearning/comments/2r3d7i/question_behavioural_and_sentiment_analysis/,__Julia,1420198260,"Self-learner here. I'm trying to learn things around data-driven sentiment analysis. Is there any good book/paper that I need to check, there are a lot of hype around.

What is the state of ssentiment analysis and behavioura analysis today ? 

What are the different models that are trending today, and what the skills needed. From what I read, there are two main ways to do applied sentiment analysis. Through text analysis (NLP) and computer vision (face analysis) ?. ",1,3
12,2015-1-2,2015,1,2,22,2r3k5u,"[Question] Is there a difference between ""Predicting"", ""preventing"", and ""Forecasting"" in ML",https://www.reddit.com/r/MachineLearning/comments/2r3k5u/question_is_there_a_difference_between_predicting/,_learningCS,1420205206,,6,10
13,2015-1-3,2015,1,3,3,2r4c8i,Self-Stabilisation in Hierarchical Temporal Memory,https://www.reddit.com/r/MachineLearning/comments/2r4c8i/selfstabilisation_in_hierarchical_temporal_memory/,fergbyrne,1420222432,,11,7
14,2015-1-3,2015,1,3,3,2r4g61,"Data Elixir, #16: AI use cases; learning Deep Learning; data viz tools and keynotes",https://www.reddit.com/r/MachineLearning/comments/2r4g61/data_elixir_16_ai_use_cases_learning_deep/,lonriesberg,1420224419,,0,1
15,2015-1-3,2015,1,3,4,2r4i4z,Training relatively deep networks without equal training examples,https://www.reddit.com/r/MachineLearning/comments/2r4i4z/training_relatively_deep_networks_without_equal/,blkorcut,1420225394,"Hey guys,

I am training a sort of deep network for an NLP task (sentiment analysis). There's a word embedding layer, a recurrent layer, and an output layer. What I am running in to is that, because I have more positive examples than negative, after training the network labels everything as positive.

Is there some secret sauce that makes deep networks not heavily biased like this? I'm using SGD with momentum.",5,2
16,2015-1-3,2015,1,3,5,2r4qan,[Question] How do I get started on Machine translation?,https://www.reddit.com/r/MachineLearning/comments/2r4qan/question_how_do_i_get_started_on_machine/,naive_babes,1420229377,"I want to get quickly started coding some basic machine translation software, just to get a feel for it. More depth of knowledge can follow later. 

What's a guide or primer I can use? ",4,1
17,2015-1-3,2015,1,3,7,2r55lz,Region CNN question,https://www.reddit.com/r/MachineLearning/comments/2r55lz/region_cnn_question/,spurious_recollectio,1420236950,"I'm trying to setup a multimodal network based on one of the recent image annotations paper (in particular http://cs.stanford.edu/people/karpathy/deepimagesent/) and I have a few questions.

1. They preprocess their images using a region CNN which requires a way to generate subject-indepdentdent bounding boxes for the image.  Karpathy et al reference a rCNN paper (1311.2524) which uses selective search (from ""Selective Search for Object Recognition"") for which I believe there is only a matlab implementation available.  I would like to do everything in python if possible (I don't have matlab) so I was wondering if anyone knows of python implementation of something similar.  It looks like openCV has some primitive ways of segmenting images but I was hoping there might be something more capable.  

2. I have my own CNN code and would like to train on some reasonable training set but it seems like it would take a long time to train on imagenet.  I might try to use the OxfordNet if I can adapt it to my code (I'm not using caffe) but I was wondering if there was something in between e.g. cifar-100 and imagenet that I could use to train on.  Alternatively is there a state-of-the-art CNN architecture that can train on a single (gtx 970 4 GB) gpu in a day or two?  I don't need to get very high performance, i'm looking for a proof of principle implementation.",11,2
18,2015-1-3,2015,1,3,7,2r59ix,"A list of awesome Deep Learning tutorials, projects and communities.",https://www.reddit.com/r/MachineLearning/comments/2r59ix/a_list_of_awesome_deep_learning_tutorials/,bbracket,1420238942,,0,0
19,2015-1-3,2015,1,3,8,2r5cuq,"TalkingMachines: a new podcast featuring interviews with Geoff Hinton, Yann Lecun, Yoshua Bengio and lots more!",https://www.reddit.com/r/MachineLearning/comments/2r5cuq/talkingmachines_a_new_podcast_featuring/,jsnoek,1420240614,,25,99
20,2015-1-3,2015,1,3,8,2r5d09,Canonical RNN training set,https://www.reddit.com/r/MachineLearning/comments/2r5d09/canonical_rnn_training_set/,spurious_recollectio,1420240698,"As I mentioned in another post I'd like to setup a multimodal network along the lines of Karpathy et al (1412.2306) but to do this I first want to implement and bidirectional RNN and maybe even LSTM (for a different multimodal implementation).  I was wondering if there is a good a canonical dataset on which to test any implementation I write?  Ideally this would be something that requires little preprocessing (so probably not speech), can be trained relatively quickly but is not entirely trivial.",9,7
21,2015-1-3,2015,1,3,10,2r5s5s,Famous cases of overfitting?,https://www.reddit.com/r/MachineLearning/comments/2r5s5s/famous_cases_of_overfitting/,[deleted],1420249020,"I'm still pretty much a beginner, yet I frequently find myself explaining some ML concepts to people with roughly zero background.

In order to make the concept of overfitting relevant, can you think of famous cases, say, in science or business that qualify as overfitting and had disastrous effects?",13,18
22,2015-1-3,2015,1,3,17,2r6te3,What is your experience with Support Vector Regression?,https://www.reddit.com/r/MachineLearning/comments/2r6te3/what_is_your_experience_with_support_vector/,rasbt,1420273250,"Hi,

in the past, I have been working with classification rather regression models and don't have much experience with the latter. However, when I was looking for materials -- introductory learning material as well as applications -- I found that linear regression ordinary least squares (often ridge or lasso) is used quite often. 

However, I stumbled upon Support Vector Regression with linear, polynomial, and RBF kernels and find the idea quite attractive. Of course, it eventually comes down to the dataset, the features selection, and whether the features have a linear relationship or not.

Right now, my dataset is still quite too small to really test and compare models (feature selection as well as regression algos), but I just want to prepare myself for the upcoming months since I am growing the dataset  over the weeks (it is for sports prediction).

So, I would appreciate it to just hear your opinion and experience with linear regression and if you have any good learning material, I would be happy if you could share it here! 

Also, how would I best compare the performance of the different models (esp. with regard to overfitting)?
In my case I have a multidimensional dataset with &gt; 3 dependent variables. 

After splitting the dataset into training and test set (optionally using cross validation), is something like the R^2 between predicted values vs. ground truth values appropriate? Or are there better metrics?
",6,5
23,2015-1-4,2015,1,4,2,2r7qwd,A quick review of the Paris Machine Learning Meetup in 2014 (and a little bit earlier),https://www.reddit.com/r/MachineLearning/comments/2r7qwd/a_quick_review_of_the_paris_machine_learning/,compsens,1420304619,,0,1
24,2015-1-4,2015,1,4,2,2r7t79,Upgrading ML / gaming box: any reason to *not* get GeForce GTX 980?,https://www.reddit.com/r/MachineLearning/comments/2r7t79/upgrading_ml_gaming_box_any_reason_to_not_get/,jaba0,1420305917,"Hi folks,

I've got a 3 year old Windows (and Linux) PC that I'm using for VR development, machine learning research, and photo-scanning (photos to 3d point-clouds).

I've pretty much decided to get a GeForce GTX980, but I was wondering if anyone has any reason to *not* get one. I.e. I'm looking for falsification, not confirmation :).

Current machine stats:
* i7 2600K @ 3.4 GHz (4 cores with HT)
* 16 GB RAM
* AMD 6950 GPU
* 128 GB SSD
* 1TB HDD",35,11
25,2015-1-4,2015,1,4,2,2r7tqr,MATLAB Neural Network Autonomous Car,https://www.reddit.com/r/MachineLearning/comments/2r7tqr/matlab_neural_network_autonomous_car/,uzunyusuf,1420306233,,13,16
26,2015-1-4,2015,1,4,4,2r88we,Robot learns to use tools by watching YouTube videos,https://www.reddit.com/r/MachineLearning/comments/2r88we/robot_learns_to_use_tools_by_watching_youtube/,Smallpaul,1420314609,,3,45
27,2015-1-4,2015,1,4,5,2r8ciw,Question about crossover in genetic algorithm,https://www.reddit.com/r/MachineLearning/comments/2r8ciw/question_about_crossover_in_genetic_algorithm/,gumbel_distro,1420316538,"Hi,

I'm trying to estimate the parameters of a model using the method of indirect inference (Gourieroux, Monfort 1992) and would like to do so using a genetic algorithm. 

The idea of the indirect inference method is to use the model you want to estimate (which may be very complicated and have an untractable likelihood function for example) to simulate some data (by choosing some initial values for your parameters). 

Then, you estimate a very simple model (such as a linear regression model) on both your true data and your simulated data. You compare the distance between your two vector of parameters, and if this distance is small, you stop, if not, you update your vector of parameters (that you obtained for the simulated data) and use the updated value to re-simulate data. You then re-estimate the simple model on this new simulated data set and compare the distance to the vector of parameters obtained with the simple regression on the real data again and so on.

What I'd like to do, is randomly draw 1000 (or more) candidate vectors and compute the distance. Then, only select the 5% of vectors with the smallest distance and then use these vectors to breed a new generation of vectors. This would be the update step. Using these new vectors, I'd simulate data, compare the distances, select yet again 5% etc. 

Now my question: I know very little about GAs, but to create a new generation, wouldn't it suffice to simply draw vectors from say, a multivariate normal distribution, with mu equal to the mean of my 5% best vectors and a good choice for the variance-covariance matrix? The drawn vectors would inherit characteristics from their parents in that way, and since it's random, the mutation step would be taken care of also. The problem I see is if my 5% best candidates are actually very bad and I'd get stuck with a shitty population that only have shitty kids.

Does this make sense? And if not, I'd really appreciate some literature on GA when the parameters are real valued. I found this paper that may be what I'm looking for: http://www.complex-systems.com/abstracts/v09_i06_a01.html but I'd like to know if my idea could work and if not, why. 

Thanks a lot!",12,2
28,2015-1-4,2015,1,4,8,2r8w8a,Where are the ICLR 2015 submissions?,https://www.reddit.com/r/MachineLearning/comments/2r8w8a/where_are_the_iclr_2015_submissions/,rantana,1420326975,They don't seem to be showing up on http://openreview.net/ this year. It seemed like putting them up on OpenReview worked great last year. Seeing the review publicly was super useful. Anyone have an idea of where the submissions are being collected this year?,5,4
29,2015-1-4,2015,1,4,11,2r9isj,"""Machine Learning in Action"" Chapter7-adaboost R-project code",https://www.reddit.com/r/MachineLearning/comments/2r9isj/machine_learning_in_action_chapter7adaboost/,pureice_li,1420339892,"The chinese post and code in engilsh version could be download in the bottom of the post.
http://pureice.github.io/blog/2015/01/01/MLinAction&amp;R7.html",0,7
30,2015-1-4,2015,1,4,18,2ragka,Saving water!!! Steam car wash machine--using steam to clean the heavy mud,https://www.reddit.com/r/MachineLearning/comments/2ragka/saving_water_steam_car_wash_machineusing_steam_to/,zzaixcarwash,1420365093,,1,0
31,2015-1-4,2015,1,4,21,2ran7f,"Yoshua Bengio's keynote from AGI-14, on how to get rid of back-prop, among other things",https://www.reddit.com/r/MachineLearning/comments/2ran7f/yoshua_bengios_keynote_from_agi14_on_how_to_get/,lars_,1420373335,,11,43
32,2015-1-5,2015,1,5,2,2rbaue,Resources to learn face recognition techniques?,https://www.reddit.com/r/MachineLearning/comments/2rbaue/resources_to_learn_face_recognition_techniques/,HumbleNoob,1420392734,"I want to classify certain features in faces, compare and recognize them in other set of images.

OpenCV haar cascades are inefficient in recognising faces, so I was not able to extract features.Can you please recommend resources to learn about effective face recognition techniques for the above problem.

P.S- Thanks in advance.",3,0
33,2015-1-5,2015,1,5,5,2rbvr9,Good tool for mining social networks and the web,https://www.reddit.com/r/MachineLearning/comments/2rbvr9/good_tool_for_mining_social_networks_and_the_web/,bernardosgr,1420403903,"Hi there, Ive been using Nutch (trying to) but I'm not totally sure it's what I'm looking for. It handles the crawling/storage part but not the rest I'm looking for... I know for my purposes there are other tools like OpenNLP that could eventually do the trick

Does anyone know of a good tool/framework/set of tools that can crawl both generic websites/social networks/forums/message boards and then filter the crawled data (parse the data for relevant information and discard the irrelevant), allowing for indexing and searching/parsing with NLP and machine learning (human-assisted) on the side?

Besides, it would have to be real-time... LOL I know I'm asking for a behemoth but the tools I listed do most of this work (Nutch, Solr and OpenNLP) ",2,0
34,2015-1-5,2015,1,5,6,2rc3ae,I wrote a program that learns to play tic-tac-toe,https://www.reddit.com/r/MachineLearning/comments/2rc3ae/i_wrote_a_program_that_learns_to_play_tictactoe/,[deleted],1420407689,"This is going to be very ""basic"" for most of you, but I haven't yet taken a formal course on Machine Learning or worked on ML in any way - so this is pretty special for me. I have a pretty extensive background in mathematics and programming, but never had a chance to learn ML. I currently have a few weeks free which I will be using to learn ML. 

So anyway, [In this lecture](https://www.youtube.com/watch?v=UzxYlbK2c7E) - which I'm yet to finish - Andrew Ng mentions one of the pioneers of ML (or, after a bit of googling, AI), Arthur Samuel, and how he wrote a program that ""learns"" to play checkers. So I thought, why not start there - and wrote a bit of code that learns to play tic-tac-toe.

I have kept the code [here](http://codetidy.com/5973/). Pretty basic stuff - a class that implements the game of tic-tac-toe, and keep a ""probability array"" of possible next ""plays"" all initialized at 1. Then if a particular play begets a win, the weight of that play will be incremented by 1, hence making it more likely to be played. Similarly, it increments a play by 1/2 if it ends in a draw.

It is trained by choosing a random next play, based on it's weight in the probability array, and not uniformly over the array - so we can explore further down the tree. 

Here's the output of a comp v comp game, where the computer chooses the best strategy, after training the code for 1000 games:

    0 | 0 | 0
    0 | 0 | 0
    0 | 0 | 0
    
    0 | 0 | 0
    0 | 0 | 0
    0 | 0 | 1
    
    0 | 0 | 0
    0 | 2 | 0
    0 | 0 | 1
        
    0 | 0 | 0
    0 | 2 | 1
    0 | 0 | 1
    
    0 | 0 | 2
    0 | 2 | 1
    0 | 0 | 1
    
    0 | 0 | 2
    0 | 2 | 1
    0 | 1 | 1
    
    0 | 0 | 2
    0 | 2 | 1
    2 | 1 | 1


And this is what happens when two veterans (100 * 3^9 games) play the game:
    
    0 | 0 | 0
    0 | 0 | 0
    0 | 0 | 0
    
    0 | 0 | 0
    0 | 1 | 0
    0 | 0 | 0
    
    2 | 0 | 0
    0 | 1 | 0
    0 | 0 | 0
    
    2 | 0 | 1
    0 | 1 | 0
    0 | 0 | 0
    
    2 | 0 | 1
    0 | 1 | 0
    2 | 0 | 0
    
    2 | 0 | 1
    1 | 1 | 0
    2 | 0 | 0
    
    2 | 0 | 1
    1 | 1 | 2
    2 | 0 | 0
    
    2 | 0 | 1
    1 | 1 | 2
    2 | 1 | 0
    
    2 | 2 | 1
    1 | 1 | 2
    2 | 1 | 0
    
    2 | 2 | 1
    1 | 1 | 2
    2 | 1 | 1

And this is what happens when Player 1 plays the second best strategy and Player 2 plays the best strategy. 

    0 | 0 | 0
    0 | 0 | 0
    0 | 0 | 0
    
    0 | 0 | 0
    1 | 0 | 0
    0 | 0 | 0
    
    0 | 0 | 0
    1 | 2 | 0
    0 | 0 | 0
    
    0 | 0 | 0
    1 | 2 | 0
    0 | 1 | 0
    
    0 | 0 | 0
    1 | 2 | 0
    2 | 1 | 0
    
    0 | 0 | 0
    1 | 2 | 1
    2 | 1 | 0
    
    0 | 0 | 2
    1 | 2 | 1
    2 | 1 | 0
    
I will be following the above lecture series for the rest of the way - and will also look to you guys for guidance. Please post any suggestions you have for a beginner.",0,0
35,2015-1-5,2015,1,5,9,2rcm3k,Are there any publicly available database of structured information about everyday objects?,https://www.reddit.com/r/MachineLearning/comments/2rcm3k/are_there_any_publicly_available_database_of/,like_the_boss,1420418160,"I'm trying to find a database of structured information about everyday objects. For example, it might have an entry for table, capturing the facts that a table:

 - made of wood
 - is composed of a top and legs
 - is used for eating food off
 - etc

Ideally, it would not be in natural language, but rather structured with relations like 'hasColor', 'isUsedFor' etc, so that it is easy say to query objects of a certain color or for a certain purpose etc.

I looked at openCyc, but it seemed to be bizarrely detailed about very obscure things, having entries like 'abyssal plain' and 'the Taylor Allerdice High School'. I'm looking for something that concentrates on everyday things like pencils, matches, rulers, cupboards, cats, dogs etc.

I realize that a comprehensive database would be prohibitively large, but I've struggled to find anything at all. Very grateful for any help!

**EDIT**

Thank you for the great replies so far. I will respond to each individually, but from the replies, it is clear that it would be useful if I said more about what I'm trying to do, and it seems like a better idea to put the information up here once, rather than spread across several responses.

Basically, I am fascinated by the human ability to master novel subject areas: a human can go from a child knowing nothing (or at least possessing only certain innate knowledge) to understanding biotechnology, or banking or law enforcement. This ability, combined with the biological fact that the brain is a collection of neurons, each fairly simple in itself, is clear evidence that it is possible for a computer (provided we define computer broadly enough to include brains) to master novel concepts and subjects.

I am trying to replicate human intelligence on a silicon-based computer, and given the above, I believe that it should be possible. The approach I am taking is this. I believe there must be a set of concepts and processes that form a kind of 'base' set, upon which more complex knowledge and processes are built. I don't see how it can be otherwise. A child cannot be born knowing nothing at all, but also cannot be born knowing about biotechnology. Therefore the complex concepts of the modern world must be constructible using the base set that a child is born with, or at least develops innately. If we can identify that base set, and the algorithms human brains use to build more complex concepts, it should be possible to replicate that base set and algorithms on a silicon computer.

The first hurdle I see is getting a base set of structured information into a computer. A child might see a black cat, and when an adult points at it and says ""cat"", the child can guess heuristically that the adult is telling the child that 'cat' is the name for that object. When the adult points at lots of black objects, and says 'black', the child can guess that the adult is giving it the name for the color that all those objects have. However, it's hard for a silicon computer to get going. How can it know what 'cat' or 'black' mean? However, I believe the problem is surmountable, by identifying a base set of concepts that interlock, so that even though the computer may have no eyes with which to identify cats in the outside world, it has a concept cat, knows that it is in the class of animals, that it has the color black, and so on. It can also know, from a dictionary, how to build more complex concepts from the simple ones it knows about. Similarly, I think that if a young child became blind after a small amount of experience of the world, it could still develop concepts of more complex things simply by explanations by people in terms that it already understood.

So a long answer, but that's what I'm trying to do.


**EDIT 2**

/u/squirreltalk asked:
&gt; I think I still need more clarification on what your goal is. Is it scientific -- are you attempting to model human knowledge and use thereof? Or technological -- do you want a system that is useful, if not psychologically plausible?

Well, both actually. The human approach to understanding, predicting and controlling our environment is clearly very powerful and works. Perhaps I'm naive, but I have the view that anything the brain can do, a silicon computer can too (forgetting consciousness, which I think is a red-herring, and most likely to be an implementation detail). I am therefore taking the view that by modelling closely the way that humans learn and develop new concepts, we can develop a useful technology that can do the same thing.

I would love to see a computer being asked ""How can I make money?"" and it automatically goes on google to find out, does some searches, comes up with some answers, and not because it has been programmed to do this, but because it has come to understand what money is and what making money means. If a person can do this, what are the barriers preventing a computer from doing it? I'm sure that a child of 5 who was cut off from perceiving the world, but could still receive linguistic communications (eg could still hear speech), would be able to develop useful knowledge of the world in areas it had no prior knowledge of. Surely, then, the same must be true of a computer. If a computer can be given the concepts that a 5-year-old has, the computer must surely be able to derive the concepts that a 25-year-old has, given appropriate linguistic input, if it uses the same mechanisms that a human uses to develop from a 5-year-old into a 25-year-old?",12,9
36,2015-1-5,2015,1,5,11,2rcxtw,Illusions for robots,https://www.reddit.com/r/MachineLearning/comments/2rcxtw/illusions_for_robots/,MachinesLikeUs,1420424579,,0,1
37,2015-1-5,2015,1,5,11,2rcyn1,ML vs optimization,https://www.reddit.com/r/MachineLearning/comments/2rcyn1/ml_vs_optimization/,longestPath,1420425011,"I'm a bit confused about how ML relates to optimizationm. Are all ML algorithms also optimization algorithms?

What objective function is optimized by a decision tree classifier? (e.g.  http://en.m.wikipedia.org/wiki/C4.5_algorithm )Or more precisely how do you specify/describe the objective function of a DT learner? 

Apologies for the naive question.",17,4
38,2015-1-5,2015,1,5,13,2rdbht,Simple Description of Collapsed Variational Bayesian Inference?,https://www.reddit.com/r/MachineLearning/comments/2rdbht/simple_description_of_collapsed_variational/,nomad42184,1420432290,"Hi all,

  I'm trying to understand the major differences between Variational Bayes and Collapsed Variational Bayes (or the CVB0 variant) --- specifically in the setting of online inference.  Is there a simpler introduction to this topic than the original CVB paper?  Also, is there a good description of how to apply CVB in the online setting?  What is the major different e.g. between the update one might make using a ""traditional"" online learning algorithm (e.g. online-em, online-vb, stochastic variational inference) vs. the update one might make using online-collapsed-vb?",4,3
39,2015-1-5,2015,1,5,15,2rdlfr,Good ways to present classifier Performance? (DataViz),https://www.reddit.com/r/MachineLearning/comments/2rdlfr/good_ways_to_present_classifier_performance/,ddofer,1420438295,"I'm working on writing up the performance of a feature extraction method I made, for an academic article. 
I want to present it in a nice way, are there any good visualizations or plots for this? (That are easily usable?). 

I'm a python n00b. (Using scikit learn. I've heard Seaborn is good, and matplot; And box plots? (dummy classifier performance vs my method's CV score?)).
Thanks!",4,0
40,2015-1-5,2015,1,5,16,2rdrte,Help wanted: Learning path for machine learning,https://www.reddit.com/r/MachineLearning/comments/2rdrte/help_wanted_learning_path_for_machine_learning/,rajnp,1420442933,,5,0
41,2015-1-5,2015,1,5,16,2rdtk7,Heavy Vehicle course,https://www.reddit.com/r/MachineLearning/comments/2rdtk7/heavy_vehicle_course/,rosman_ferrie,1420444453,,0,1
42,2015-1-5,2015,1,5,18,2rdylv,EWP Training,https://www.reddit.com/r/MachineLearning/comments/2rdylv/ewp_training/,rosman_ferrie,1420449384,,0,1
43,2015-1-5,2015,1,5,19,2re3vg,"Talking Machines: ML podcast series; first episode featuring LeCun, Bengio, Hinton, Murphy",https://www.reddit.com/r/MachineLearning/comments/2re3vg/talking_machines_ml_podcast_series_first_episode/,Barbas,1420454958,,5,55
44,2015-1-5,2015,1,5,23,2rei2t,Machine Learning Methods for Computer Security: A summary,https://www.reddit.com/r/MachineLearning/comments/2rei2t/machine_learning_methods_for_computer_security_a/,galapag0,1420467610,,2,3
45,2015-1-5,2015,1,5,23,2reiff,Bishop Pattern Recognition too theoretical?,https://www.reddit.com/r/MachineLearning/comments/2reiff/bishop_pattern_recognition_too_theoretical/,isolar_x7,1420467862,"I recently acquired ""Pattern Recognition and Machine Learning (Information Science and Statistics)"" by Bishop. However after finishing Andrew's Ngac Coursera's intro video I get the feeling that the textbook is more theory oriented than actual practical oriented. I might be wrong  as I'm still halfway through chapter 2.

What are y'all thoughts on this?

Edit:
I'm sorry I didn't articulate my problem well. I rather than ""too theoretical"" I actually meant ""statistical heavy"" and does not have a lot of practice examples/algorithms. Which I understand why it doesn't have them. 

The purpose of this thread was to know if you guys use a companion text/video/etc... while you were working out Bishop's text.",14,1
46,2015-1-6,2015,1,6,0,2renl1,CNN with Torch7 - speed and example code?,https://www.reddit.com/r/MachineLearning/comments/2renl1/cnn_with_torch7_speed_and_example_code/,[deleted],1420471256,"I'm trying to get started using convolutional neural networks, so I've been playing with a number of frameworks in different languages (C++, python/Theano, Torch7). 

I like the simple style of Torch code, although the documentation is pretty sparse. Does anyone know of any tutorial/example code for modern convnets? The best I've found so far is https://github.com/nagadomi/kaggle-cifar10-torch7.

Also, while I've been able to get similar results and comparable speed between C++ and Theano implementations, my Torch attempts seem to take around 1.5-2X as long per epoch, and also use more GPU RAM, even with the same convolution backend (cuda-convnet).

Do people generally see equivalent performance from Torch?",2,0
47,2015-1-6,2015,1,6,0,2reoyx,Machine-Learning Maestro Michael Jordan on the Delusions of Big Data and Other Huge Engineering Efforts,https://www.reddit.com/r/MachineLearning/comments/2reoyx/machinelearning_maestro_michael_jordan_on_the/,[deleted],1420472053,,1,0
48,2015-1-6,2015,1,6,0,2req52,Dropout enables efficient optimization of a non-convex regularization penalty,https://www.reddit.com/r/MachineLearning/comments/2req52/dropout_enables_efficient_optimization_of_a/,bnd3,1420472758,,0,2
49,2015-1-6,2015,1,6,1,2res6i,Is Word Sense Disambiguation (WSD) worthwhile for Latent Dirichlet Allocation (LDA)?,https://www.reddit.com/r/MachineLearning/comments/2res6i/is_word_sense_disambiguation_wsd_worthwhile_for/,[deleted],1420473900,"I am working on a project involving LDA on a small text corpus and my advisor seems dead-set on word sense disambiguation as a pre-processing step. My reasoning for not wanting to do it (other than it would just be a pain) is that it isn't necessary because LDA already captures words in context to form topics, and thus different sense of a textual ""word"" (e.g. *patient* in a doctor's office vs. someone being *patient*) would be captured in their respective contexts. Adding a WSD step would just overcomplicate things.

I should add that the data being used is medical and already has a very limited vocabulary to begin with, which severely restricts the possibility of ambiguous word-senses.

Is my reasoning sound? or am I overlooking something?",2,0
50,2015-1-6,2015,1,6,1,2resw1,Can I apply machine learning to this problem?,https://www.reddit.com/r/MachineLearning/comments/2resw1/can_i_apply_machine_learning_to_this_problem/,Bob312312,1420474282,"
So imagine you have a system where you can make 5 measurements which return numerical values. The measurements correspond to weighted averages. The populations for these averages will be the same for each measurement but then weightings with will vary. 

Since we know what the weightings are we can produce lots of data by making random populations.

Note you can use all 5 measurements to work out the populations and it is not necessary to return a complete set i.e. I'm happy if we only account for 60% of the population.

So my question is can you use a machine learning algorithm to calculate the populations from the measurements? If so which would be the best and how would you go about this?

Or do you think there is a better way to do this? 

Thanks
bob312312",4,0
51,2015-1-6,2015,1,6,3,2rfaqc,Renting GPU Instances in the Cloud,https://www.reddit.com/r/MachineLearning/comments/2rfaqc/renting_gpu_instances_in_the_cloud/,awiltschko,1420483385,"Amazon EC2 provides a g2.2xlarge instance, which sports a middle-of-the-road card, with 4GB onboard RAM and 1.5K CUDA cores. The higher end cards are twice that, and for training really big neural networks, having 2 or 4 of them in the same machine is becoming a necessity. Is there any cloud service, like EC2 or DigitalOcean, which lets me rent a serious GPU rig by the hour?",20,15
52,2015-1-6,2015,1,6,4,2rfgrt,Everyday my machine and I learn something new. Data and knowledge are awesome. #machinelearning #education #science,https://www.reddit.com/r/MachineLearning/comments/2rfgrt/everyday_my_machine_and_i_learn_something_new/,[deleted],1420486276,,1,0
53,2015-1-6,2015,1,6,5,2rfpts,Autoencoding RNN?,https://www.reddit.com/r/MachineLearning/comments/2rfpts/autoencoding_rnn/,bge0,1420490402,"Is there a way to autoencode LSTMs? In my mind i figure that the contextual information added to the signal will provide some form of varying error during say an L2 loss. Is there any way around this? Any current research?



Autoencoders generally take a vector of x of size N and do the following:

* h = f(Wx+b)  --&gt;Encode
* y = g(W'x+b) --&gt; Decode [assume that W' = transpose(W) for simple regularization]
* MSE(y-x) = Estimate of how well the signal has been reconstructed.



In the case of a simple RNN the vector x is generally augmented as x = [x | h(t-1), h(t-2) ...].
Thus the MSE of the reconstruction between the new y &amp; x will be variadic. ",7,2
54,2015-1-6,2015,1,6,6,2rfxw4,Using Python to optimize a currency trading strategy,https://www.reddit.com/r/MachineLearning/comments/2rfxw4/using_python_to_optimize_a_currency_trading/,hernamesbarbara,1420494095,,2,4
55,2015-1-6,2015,1,6,7,2rg6fs,Classification of names?,https://www.reddit.com/r/MachineLearning/comments/2rg6fs/classification_of_names/,dogweather,1420497929,"I'm interested in the problem of input being a name, and the output being a category. E.g.;

* a person's full name -&gt; etymological origin
* a restaurant's name -&gt; type of cuisine

Anyone heard of this being done? Could a standard neural net simulator library handle this?",2,0
56,2015-1-6,2015,1,6,8,2rgadh,Beating Online Poker with ML?,https://www.reddit.com/r/MachineLearning/comments/2rgadh/beating_online_poker_with_ml/,[deleted],1420499760,"I would like to know how applicable ML would be to beat Online Poker?
1. Yes its possible to beat, so no general gambling discussion please.
2. interestingly there is no GTO strategy established, because the decision tree is extremely complex.
3. Lets say No Limit Holdem, 6 Handed 
4. Millions of played hands available for data, with that it would also be possible to construct exploitive strategies for the AI.

Any Ideas how hard that problem is?",16,11
57,2015-1-6,2015,1,6,11,2rgvht,"Elon Musk, early investor in DeepMind and Vicarious, is doing AMA atm. He also said this:",https://www.reddit.com/r/MachineLearning/comments/2rgvht/elon_musk_early_investor_in_deepmind_and/,[deleted],1420510189,"[http://i.imgur.com/sL0uqqW.jpg](http://i.imgur.com/sL0uqqW.jpg) So I'm trying to ""sneaky"" get some info about what ML/AI capabilities he saw that are not exposed to mere mortals. I have asked the question:

*""You are an early investor in AI startups like DeepMind and Vicarious. What was the most amazing demonstration of an AI capabilities you have seen so far?""*

If you like to know the answer - please upvote it:) I will delete this thread in few hours from here :D https://www.reddit.com/r/IAmA/comments/2rgsan/i_am_elon_musk_ceocto_of_a_rocket_company_ama/cnfq4l8",10,6
58,2015-1-6,2015,1,6,12,2rh1m1,"Announcement: Mneumonese now has it's own subreddit. To celebrate the occasion, here is a quick look at how Mneumonese does emotion words. : Mneumonese",https://www.reddit.com/r/MachineLearning/comments/2rh1m1/announcement_mneumonese_now_has_its_own_subreddit/,justonium,1420513330,,2,0
59,2015-1-6,2015,1,6,12,2rh44u,Machine Learning School in Austin,https://www.reddit.com/r/MachineLearning/comments/2rh44u/machine_learning_school_in_austin/,tabacof,1420514602,"Is there anyone else that is gonna participate to MLSS in Austin? 

I will be arriving at the Drifter Jack Hostel tomorrow, I hope to see someone from this sub there!",6,2
60,2015-1-6,2015,1,6,13,2rhbgk,Two guns steam car wash machine-two workers wash cars at the same time,https://www.reddit.com/r/MachineLearning/comments/2rhbgk/two_guns_steam_car_wash_machinetwo_workers_wash/,zzaixcarwash,1420518484,,1,0
61,2015-1-6,2015,1,6,14,2rhik5,Where might you recommend finding interesting traing and test data sets for a classification problem?,https://www.reddit.com/r/MachineLearning/comments/2rhik5/where_might_you_recommend_finding_interesting/,UpOnCloud9,1420522487,"I'd like a nice set of data to apply supervised learning methods to, but I don't know where the best place to get such data. I'm really into dogs/pets and nature if that helps.",5,0
62,2015-1-6,2015,1,6,22,2rifnc,How do you program a decision tree?,https://www.reddit.com/r/MachineLearning/comments/2rifnc/how_do_you_program_a_decision_tree/,FestivalPillow,1420550774,"I understand what a decision tree is in theory, but how exactly would one go about implementing it?

If I am programming in lets say Java or some OO language, is it just a series of if/else statements in one class, or should there be multiple objects like node class and branch class and whatnot?

I'm kind of confused about the best way to implement it... if anyone could shed some light, or pass on any useful links, i'd really appreciate it. 

Thanks guys. ",3,1
63,2015-1-7,2015,1,7,0,2riqbw,Good learning material for stochastic gradient descent in the non-convex setting?,https://www.reddit.com/r/MachineLearning/comments/2riqbw/good_learning_material_for_stochastic_gradient/,InfinityCoffee,1420557717,"Do you guys know of a good overview of stochastic gradient descent and other gradient-based optimization algorithms? Most of the material I can find deals with the convex case, and since I am working on a variational problem I am in the non-convex paradigm. Is Leon Bottou's work the go-to resource? It seems to come up often as a reference.  

What are some interesting variants of SGD? I know of natural gradient descent, but are there stochastic parallels to e.g. conjugate gradient methods and the like? 

Finally, most arguments for why SGD is beneficial (aside from its generality) seem to hinge on speed considerations. I sort of recall hearing that SGD is more likely to converge to a global minimum, is this  a proven statement? ",12,11
64,2015-1-7,2015,1,7,2,2rj2jr,Machine Learning for highlighting a particular structure in an image?,https://www.reddit.com/r/MachineLearning/comments/2rj2jr/machine_learning_for_highlighting_a_particular/,antidense,1420564085,"I have about a 100 MRI image slices across different people in which 30 I've highlighted a particular structure as a separate image mask.  Is there a machine learning algorithm that can learn how to do this and apply it to the rest?  I'm more interested in reproducibility than accuracy, but I'm not sure if I have enough of a training size.  I do have access to matlab if that helps.",12,1
65,2015-1-7,2015,1,7,3,2rjarn,You need an Algorithm Not a Data Scientist for Scalable Ads Buying/Serving!,https://www.reddit.com/r/MachineLearning/comments/2rjarn/you_need_an_algorithm_not_a_data_scientist_for/,kjahan,1420567966,,1,0
66,2015-1-7,2015,1,7,4,2rjn3h,[Question] Finding the most relevant predictors (features) to build predictive model,https://www.reddit.com/r/MachineLearning/comments/2rjn3h/question_finding_the_most_relevant_predictors/,__Julia,1420573617,"I am building a predictive model using CART.  

I use features (X1,X2, .. X20) and Y as a target. 

How can I decide which are the most relevant predictors (filtering correlated and features with less influence ), because when I select 3-features randomly I got different results. 
",2,2
67,2015-1-7,2015,1,7,5,2rjvui,LSTM-RNN Benchmarks,https://www.reddit.com/r/MachineLearning/comments/2rjvui/lstmrnn_benchmarks/,alexmlamb,1420577558,,15,7
68,2015-1-7,2015,1,7,6,2rk271,The Perilous World of Machine Learning for Fun and Profit: Pipeline Jungles and Hidden Feedback Loops,https://www.reddit.com/r/MachineLearning/comments/2rk271/the_perilous_world_of_machine_learning_for_fun/,cavedave,1420580337,,10,40
69,2015-1-7,2015,1,7,7,2rkb5z,Good deep learning project for class,https://www.reddit.com/r/MachineLearning/comments/2rkb5z/good_deep_learning_project_for_class/,0xA1,1420584408,"Hey guys, I just started a graduate class on deep learning and I've done some light ANN training stuff for past classes. Part of this class requires us to pick a project and implement a deep learning algorithm for it. 

I would love to hear your suggestions on some interesting things I could implement for a class project on deep learning. The class is roughly 10 weeks long so it would have to be something doable within this period of time. We are allowed to use basically any language and any package we want, so it's quite an open ended project. ",22,15
70,2015-1-7,2015,1,7,9,2rkne3,Cost function that correlates well with lift,https://www.reddit.com/r/MachineLearning/comments/2rkne3/cost_function_that_correlates_well_with_lift/,binge_learner,1420590262,"Hi everyone,
Is there any cost function that correlates well with the lift that a model gives ? Or is there a way to optimize directly for the lift ?
It's for a highly unbalanced binary classification problem (the kind you typically find in marketing).
Thanks in advance for your answers.

Amine.
",2,0
71,2015-1-7,2015,1,7,12,2rlb4q,"65 new external resources and articles about data science, big data, machine learning, R - January 6",https://www.reddit.com/r/MachineLearning/comments/2rlb4q/65_new_external_resources_and_articles_about_data/,urinec,1420602260,,0,1
72,2015-1-7,2015,1,7,14,2rlllp,"Can I do machine learning/data mining stuff without being a ""data scientist?""",https://www.reddit.com/r/MachineLearning/comments/2rlllp/can_i_do_machine_learningdata_mining_stuff/,dtgee8,1420608133,"I enjoy machine learning/data mining, but too often I see job listings with a need for a data mining skillset with the label ""data scientist."" I personally wouldn't find myself being a data scientist, as this job title requires a very broad skillset which would eat up a lot of my time trying to learning. I'd rather specialize in one specific skill (data mining) and apply it than to try to master many skills. Moreover, being a data scientist requires good presentation skills, which I particularly dread because I'm naturally shy and I'm not very good at it.

Basically what I want to ask is, is there a career other than a data scientist that focuses mainly on machine learning/data mining? I want to be the one that builds a system, just a non-practical simple example, that spits out a user's most likely to be said phrase given all messages he's ever typed. In this case, I don't exactly need to be the one presenting and helping to make decisions for management by analyzing a bunch of data and predicting what's going to happen next. I just need to be the one that programs this specific task and make sure it works fairly well.

TL;DR:
I think aspiring to become a data scientist would ruin my work/life balance based on the vast amount of skills needed and the time required to learn those skills. Is there an alternative career which focuses solely on machine learning/data mining without an intensive presentation/report/decision making requirement to upper management?

Also, I'm not planning to go for a Masters degree, as I'm really tired of academia and would favor work experience. However, I did take some statistics courses for my minor and am familiar with some of the concepts. Will I be anle to find a job in this field without having a PhD or Masters degree?",5,0
73,2015-1-7,2015,1,7,17,2rlz64,[Question] Fast sparse matrix libraries for ML tasks in Java?,https://www.reddit.com/r/MachineLearning/comments/2rlz64/question_fast_sparse_matrix_libraries_for_ml/,mattrepl,1420617758,"For those of you who implement ML methods that require sparse matrices, is there a library you'd recommend? Though I'm looking for a lib that supports Java, any library using native code is a candidate.

The library needs to support large matrices (10^7 x 10^7), support basic linear algebra operations (products, transpose, etc.), and compile to native code that can be wrapped as a Java lib.

I'm currently using a pure-Java lib [(Vectorz) in Clojure](https://github.com/mikera/vectorz-clj) and the performance isn't there. I've spent some time profiling and improving the library, but my hunch is it will never be comparable to native code. I'd like to find a few candidates to benchmark and test this hunch.

The most promising library I've come across is [Eigen](http://eigen.tuxfamily.org) (C++). There's an incomplete [Java wrapper for it](https://github.com/hughperkins/jeigen).

In case anyone is curious, I'm working with graphs (1M nodes, 10M edges) and term vectors (10M dimensions). Thanks in advance for any recommendations.",6,0
74,2015-1-7,2015,1,7,20,2rmcp2,Custom splitting method/criterion for a random forest- what are my options?,https://www.reddit.com/r/MachineLearning/comments/2rmcp2/custom_splitting_methodcriterion_for_a_random/,[deleted],1420631011,"Hello, I would like to use a regression forest but with my own function to decide on which of the randomly sampled parameters to split on. Since I prefer python, I wanted to use sklearn, but the implemented regressiontree method uses 'mse' (mean squared error) as criterion and I can't see a way to put in my custom method.

Do you know of any libraries/implementations where I can use a custom splitting criterion?",3,1
75,2015-1-7,2015,1,7,21,2rmfx7,Why remove duplicate samples?,https://www.reddit.com/r/MachineLearning/comments/2rmfx7/why_remove_duplicate_samples/,ddofer,1420634017,"I'm working on a sequence classification project; in which we take a set of proteins, extract overlapping Windows from them, then extract features and classify the Windows. (Thus, each window is a sample to be classified).

I had an argument with a colleague about removing identical, or highly similar sequences/Windows. 
He argued that we should keep all the Windows/samples, including identical ones, since the reappearance of certain Windows many times over is indicative of the ""real world"" situation.
I argued that we should remove all identical Windows, and also Windows (and maybe also at the whole protein level) that are almost identical/redundant (e.g have a 90% identical sequence).

(Currently, about a fifth of our samples are identical, (the dataset is quite imbalanced, with about 100,000 samples overall).

So, whose right, and what's the basis for removing duplicates?


My argument is based on concerns over being able to present it as a good predictive tool, tested on as ""hard"" a dataset as possible. Furthermore, I see cv as being unreliable when identical data can potentially appear in the train and test set. (Although I suppose this could be addressed with ""sample weight"").
Thanks!",6,1
76,2015-1-7,2015,1,7,22,2rmieb,Nvidia's demo of real-time object recognition using deep learning,https://www.reddit.com/r/MachineLearning/comments/2rmieb/nvidias_demo_of_realtime_object_recognition_using/,vkhuc,1420636159,,23,78
77,2015-1-8,2015,1,8,0,2rmvra,How to build a hotel review analyzer with MonkeyLearn and Kimono,https://www.reddit.com/r/MachineLearning/comments/2rmvra/how_to_build_a_hotel_review_analyzer_with/,wildcodegowrong,1420644768,,0,1
78,2015-1-8,2015,1,8,1,2rn0ka,"Advice structure extracted from 20,000 natural language reviews",https://www.reddit.com/r/MachineLearning/comments/2rn0ka/advice_structure_extracted_from_20000_natural/,RatherGet,1420647316,,0,9
79,2015-1-8,2015,1,8,6,2ro7sl,Stanford statistical learning online course taught by Hastie &amp; Tibshirani starting soon (Jan 20th),https://www.reddit.com/r/MachineLearning/comments/2ro7sl/stanford_statistical_learning_online_course/,aprstar,1420667116,,23,83
80,2015-1-8,2015,1,8,7,2rocqc,Help getting started with imagenet,https://www.reddit.com/r/MachineLearning/comments/2rocqc/help_getting_started_with_imagenet/,spurious_recollectio,1420669304,"I'm trying to train a ""grown up"" CNN to do classification but maybe as a bonus also localization, etc...  I have my own python NN library building on cudarray and cuDNN so that's my backend and I have a GTX 970 card with 4 gb ram.  

I'm having problems getting started because (a) I just found out the imagenet dataset is not readily available (its apparently open to researchers but I'm not sure I qualify) and (b) I'm trying to find an architecture that will fit on my card.  The original alexnet was designed for two GPUs so I was considering overfeat or oxfordnet but the former does not seem to specify what kind of machines they trained on or training time (and the latter is a bit intimidating).  Can anyone recommend the best architecture to use for given my setup.  I'm not expecting to match state of the art systems but something alex-net quality would be nice.  Also, if imagenet is a hassle to get a hold of (the URLs are freely available but it would mean downloading 1m images) is there an alternative beefy dataset?  I also wouldn't mind trying something a bit simpler before doing for the gold and glory of imagenet (but I've already played with cifar-10 and cifar-100 doesn't seem much more interesting).

As a final follow up I have considered just downloading oxfordnet and porting it (i.e. the net specification) to my code but its in caffe format and I haven't been able to find the documentation explaining that format.
",20,3
81,2015-1-8,2015,1,8,8,2rohzf,What is the state-of-the-art for AI that learns about causality in an environment?,https://www.reddit.com/r/MachineLearning/comments/2rohzf/what_is_the_stateoftheart_for_ai_that_learns/,like_the_boss,1420671738,"I'm interested in writing software that can make deductions (actually probably the wrong word - maybe 'inductions' is more like it) - about causality in the environment. For example, if a brown object made of wood floats, and a brown stone sinks, the software can figure out that the probable cause of the wood floating is the fact it's wood, rather than the fact it's brown, because a brown stone sinks. 

Of course, this is not logic, in the sense of inevitable conclusions from premises, but rather applying what is empirically above chance in the world, because certain properties of objects (being made of wood) tend to correlate with other properties of objects (floating). I'm sure there's other heuristics that can be applied.

Before I get too deeply into it, I'd be very grateful if anyone can tell me what projects have been looking into it, or even what the area is called in AI?

Many thanks!",2,4
82,2015-1-8,2015,1,8,9,2roqz4,Continuous HTM Hierarchy and Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/2roqz4/continuous_htm_hierarchy_and_reinforcement/,CireNeikual,1420676069,,3,10
83,2015-1-8,2015,1,8,11,2rp5hu,Machine learning best practices we've learned from hundreds of competitions - Ben Hamner,https://www.reddit.com/r/MachineLearning/comments/2rp5hu/machine_learning_best_practices_weve_learned_from/,[deleted],1420683369,,0,25
84,2015-1-8,2015,1,8,11,2rp656,Steam car wash machine--good car wash equipment,https://www.reddit.com/r/MachineLearning/comments/2rp656/steam_car_wash_machinegood_car_wash_equipment/,zzaixcarwash,1420683708,,0,1
85,2015-1-8,2015,1,8,13,2rpj3v,Anyone know what is happening with this course?,https://www.reddit.com/r/MachineLearning/comments/2rpj3v/anyone_know_what_is_happening_with_this_course/,lsamc,1420690451,,6,6
86,2015-1-8,2015,1,8,15,2rpxsx,Has anyone created netcdf files for RNNLIB?,https://www.reddit.com/r/MachineLearning/comments/2rpxsx/has_anyone_created_netcdf_files_for_rnnlib/,pretz,1420699329,"I have managed to compile rnnlib, but I can't run the examples that come with it because I get an error building the netcdf files (""can't safely cast type"" or something). It seems that the example script loads in the sample images as a single 1 by K vector (k &gt; 200000), but I don't see how the RNN knows how the feature vectors are laid out in there.

I want to create my own netcdf files with my own data sequences, but I have no idea how rnnlib expects them to be laid out. 

Lets say I have 1000 sequences of size 7 by N where N varies from 30 to 400 (the sequence lengths i.e. number of feature vectors) and 7 is the number of dimensions for each feature vector. How should the netcdf file look to train the network? I have 1 label per feature vector.

Any help or pointers would be appreciated.",4,1
87,2015-1-8,2015,1,8,17,2rq5mr,Skills needed for machine learning job,https://www.reddit.com/r/MachineLearning/comments/2rq5mr/skills_needed_for_machine_learning_job/,[deleted],1420705693,,3,0
88,2015-1-8,2015,1,8,17,2rq721,Dr. Tom Murphy VII's ongoing computer program that learns to play NES games,https://www.reddit.com/r/MachineLearning/comments/2rq721/dr_tom_murphy_viis_ongoing_computer_program_that/,Davkilla101,1420707049,"Hello everyone,

So I recently stumbled across Dr. Murphy's program, which as the title states, learns how to play NES games. I actually downloaded a copy and have been watching the AI work for the past couple of hours, I found it to be quite interesting hence why I am showing this to you all.

Video 1: https://www.youtube.com/watch?v=xOCurBYI_gY

Video 2: https://www.youtube.com/watch?v=YGJHR9Ovszs

Video 3: https://www.youtube.com/watch?v=Q-WgQcnessA

Link to Program: http://tom7.org/mario/

And finally his Papers: http://www.cs.cmu.edu/~tom7/papers/

Hopefully this will prove to be as interesting to you all as it was to me.

**Edit:** Correcting spacing issues",7,22
89,2015-1-8,2015,1,8,22,2rqr1a,k-Sparse Autoencoders (2013),https://www.reddit.com/r/MachineLearning/comments/2rqr1a/ksparse_autoencoders_2013/,galapag0,1420725417,,3,4
90,2015-1-8,2015,1,8,23,2rqsju,Nvidia's CES 2015 presentation of real-time object recognition using deep learning [video],https://www.reddit.com/r/MachineLearning/comments/2rqsju/nvidias_ces_2015_presentation_of_realtime_object/,[deleted],1420726425,,0,0
91,2015-1-8,2015,1,8,23,2rqv7x,Which MOOCs,https://www.reddit.com/r/MachineLearning/comments/2rqv7x/which_moocs/,NicolasGuacamole,1420728126,"It seems as though there are quite a few of Machine Learning / data science / statistics MOOCs starting soon. I'm aware of Andrew Ng's course naturally, and have looked briefly at others, but as there are so many I'm at a loss of which ones would be the most worthwhile to take.

Anyone who has done any of these courses, which ones would you recommend? If you have done multiple ones could you put them in order of importance.",24,12
92,2015-1-9,2015,1,9,1,2rr9ut,Can artificial neural network contain edges pointing backwards?,https://www.reddit.com/r/MachineLearning/comments/2rr9ut/can_artificial_neural_network_contain_edges/,redditmat,1420735954,Assume multiple hidden layers. Normally layers are linked to each other in one direction. Has anyone done that? Is it useful? ,5,4
93,2015-1-9,2015,1,9,2,2rrc68,No need to panic  artificial intelligence has yet to create a doomsday machine,https://www.reddit.com/r/MachineLearning/comments/2rrc68/no_need_to_panic_artificial_intelligence_has_yet/,MachinesLikeUs,1420736998,,0,1
94,2015-1-9,2015,1,9,2,2rre1x,See how a leading food service company in the UK is using Azure ML to predict customers shopping lists even before they shop,https://www.reddit.com/r/MachineLearning/comments/2rre1x/see_how_a_leading_food_service_company_in_the_uk/,MLBlogTeam,1420737840,,0,0
95,2015-1-9,2015,1,9,3,2rrjkl,Using machine learning to identify misuse of defiantly,https://www.reddit.com/r/MachineLearning/comments/2rrjkl/using_machine_learning_to_identify_misuse_of/,defiantlee,1420740438,,5,25
96,2015-1-9,2015,1,9,5,2rs0hk,Dato Joins New Wave of Machine Learning Startups,https://www.reddit.com/r/MachineLearning/comments/2rs0hk/dato_joins_new_wave_of_machine_learning_startups/,[deleted],1420748119,,0,2
97,2015-1-9,2015,1,9,5,2rs3nj,Quasi-Monte Carlo Feature Maps for Shift-Invariant Kernels (x-post r/CompressiveSensing ),https://www.reddit.com/r/MachineLearning/comments/2rs3nj/quasimonte_carlo_feature_maps_for_shiftinvariant/,compsens,1420749573,,0,1
98,2015-1-9,2015,1,9,6,2rs9c4,"Take this online robotics course alongside students taking the course here at UVM (Jan to May, 2015)",https://www.reddit.com/r/MachineLearning/comments/2rs9c4/take_this_online_robotics_course_alongside/,DrJosh,1420752044,,1,12
99,2015-1-9,2015,1,9,7,2rshn1,12-Week Data Science Bootcamp,https://www.reddit.com/r/MachineLearning/comments/2rshn1/12week_data_science_bootcamp/,nycdatascience,1420755779,"""Considering a career as Data Scientist? Apply to our 12-Week Data Science Bootcamp and learn beginner &amp; intermediate levels of Data Science with R, Python &amp; Hadoop! You will get 9 weeks of training, 2 weeks hands-on project training mentored by top Chief Data Scientists in NYC and abundant opportunity to interview with our 300+ hiring partners! Go to http://nycdatascience.com/bootcamp/#apply  to learn more about this exciting program! Financial Aid &amp; Scholarships available, limited spots available. 
Deadline to Apply: January 15th 11:59PM""",3,0
100,2015-1-9,2015,1,9,8,2rsnj1,Neural Network Illustrated  Step by Step,https://www.reddit.com/r/MachineLearning/comments/2rsnj1/neural_network_illustrated_step_by_step/,Tech-Effigy,1420758565,,10,18
101,2015-1-9,2015,1,9,9,2rt114,Machine Learning research / resources in spanish,https://www.reddit.com/r/MachineLearning/comments/2rt114/machine_learning_research_resources_in_spanish/,PokerPirate,1420765185,"I'm trying to practice my spanish, so I'd like to read some machine learning research papers written in spanish.  I have four questions on how to find resources:

1. What conferences / journals should I be looking for?  

2. What about Spanish books on advanced ML topics?  

3. Are the trends in Spanish ML research similar to those in English?

4. What are the famous universities / professors in latin american countries?",1,0
102,2015-1-9,2015,1,9,12,2rti4c,Statistical and causal approaches to machine learning,https://www.reddit.com/r/MachineLearning/comments/2rti4c/statistical_and_causal_approaches_to_machine/,c5000,1420774003,,0,5
103,2015-1-9,2015,1,9,22,2ruqio,Machine Learning Technology - Swimming and Athletics,https://www.reddit.com/r/MachineLearning/comments/2ruqio/machine_learning_technology_swimming_and_athletics/,ddingman,1420808973,,0,3
104,2015-1-10,2015,1,10,1,2rv8zb,Join the free Machine Learning course on Coursera starting Jan 19th,https://www.reddit.com/r/MachineLearning/comments/2rv8zb/join_the_free_machine_learning_course_on_coursera/,lundmikkel,1420820178,,42,77
105,2015-1-10,2015,1,10,1,2rvbpo,"Can somebody suggest me a good M.S program in Canada for CS-Machine Learning besides McGill, Waterloo, Toronto, ubc?",https://www.reddit.com/r/MachineLearning/comments/2rvbpo/can_somebody_suggest_me_a_good_ms_program_in/,[deleted],1420821469,My background is undergrad in Mathematics with CS and physics minor from the US. Also have some actuarial exams passed.,4,0
106,2015-1-10,2015,1,10,2,2rvhrf,Is there anybody here familiar with Adaptive Resonance Theory (ART)?,https://www.reddit.com/r/MachineLearning/comments/2rvhrf/is_there_anybody_here_familiar_with_adaptive/,bananabanga,1420824294,"I'm supposed to code it for a project, based on some articles and textual material that professor gave my, but I can't find anything  to help me with the code. I would appreciate any help.",7,0
107,2015-1-10,2015,1,10,3,2rvn1z,"Predictive Analytics book authors, Val Fontama &amp; Wee Hyong Tok, share perspectives on data science",https://www.reddit.com/r/MachineLearning/comments/2rvn1z/predictive_analytics_book_authors_val_fontama_wee/,MLBlogTeam,1420826771,,0,0
108,2015-1-10,2015,1,10,4,2rw0ea,Python Packages For Data Mining,https://www.reddit.com/r/MachineLearning/comments/2rw0ea/python_packages_for_data_mining/,futureisdata,1420832942,,1,0
109,2015-1-10,2015,1,10,5,2rw6bq,Machine learning with wearable sensors,https://www.reddit.com/r/MachineLearning/comments/2rw6bq/machine_learning_with_wearable_sensors/,efavdb,1420835741,,0,3
110,2015-1-10,2015,1,10,5,2rw7n0,Shallow Extreme Learning Machines versus Deep Neural Networks (x-post r/CompressiveSensing),https://www.reddit.com/r/MachineLearning/comments/2rw7n0/shallow_extreme_learning_machines_versus_deep/,compsens,1420836376,,3,9
111,2015-1-10,2015,1,10,6,2rwfgt,1/2 to 2/3 papers accepted at NIPS would be rejected if reviewed second time,https://www.reddit.com/r/MachineLearning/comments/2rwfgt/12_to_23_papers_accepted_at_nips_would_be/,teodorz,1420839941,,2,19
112,2015-1-10,2015,1,10,7,2rwkn5,BrainCard: Facial Recognition Demo (people/expressions/actions),https://www.reddit.com/r/MachineLearning/comments/2rwkn5/braincard_facial_recognition_demo/,[deleted],1420842333,,0,1
113,2015-1-10,2015,1,10,10,2rx3tr,tf-idf over a book's chapters,https://www.reddit.com/r/MachineLearning/comments/2rx3tr/tfidf_over_a_books_chapters/,[deleted],1420852372,"I've been doing a lot of googling but can't quite find a satisfactory answer.

If I treat a book as a corpus (say, 60k words divided in 5 chapters), and each chapter as a document, are the tf-idf scores I get for each chapter significant?

I've actually tried and I get semi-useful results, but I'd like to know what you think before spending more time on this.

Yes, I'm a beginner.",4,0
114,2015-1-10,2015,1,10,22,2ryn68,Unable to solve simple problem with Logistic Regression,https://www.reddit.com/r/MachineLearning/comments/2ryn68/unable_to_solve_simple_problem_with_logistic/,strealm,1420897730,"I'm trying to make a simple example with SciKit's LogisticRegression. 
Data is synthetically generated according to rule:
 
    if feature1 &lt; 5 and feature2 &gt; 100 and feature3 &gt; 20:
      label = 'yes'
    else:
      label = 'no'

Problem is that I can't reach 0 error on training set. Is there any theoretical or practical explanation for this or should I keep looking for bugs?

Rule seems rather easy to solve with single hyperplane. I tried different things (normalization, absurd C and tolerance values, ...)  but error is fixed at about 2% or it grows for very small C (as expected). If the rule is composed of more then one feature I can't bring error to 0.
If any other clarification or code is needed, please ask.",8,13
115,2015-1-11,2015,1,11,3,2rzcs9,[X-post from /r/kickstarter] The BrainCard - Neural network technology for makers/robotics/drones/data mining/pattern recognition.,https://www.reddit.com/r/MachineLearning/comments/2rzcs9/xpost_from_rkickstarter_the_braincard_neural/,ej159,1420914093,"""I am part of a team that recently launched the BrainCard - a maker/home brew electronics platform powered by a neural network chip with 1024 artificial neurons that up until now had only been used in industrial and research applications.

It works with just about any other platform from Arduino to Raspberry Pi and enables them to add cognition; the ability to recognize and instantly recall patterns/images/data from a live stream.

We're looking at launching neural network technology into the mainstream via this Indiegogo and have a roadmap full of other 'things' powered by the same neuromorphic chips and more - we'll be bringing demo's of the technology to the Indiegogo page throughout the campaign.

I welcome any constructive questions/feedback/input.

[http://igg.me/at/braincard](http://igg.me/at/braincard)""
",3,0
116,2015-1-11,2015,1,11,4,2rzmj4,3 new Adaptive SGD papers in ICLR 2015,https://www.reddit.com/r/MachineLearning/comments/2rzmj4/3_new_adaptive_sgd_papers_in_iclr_2015/,[deleted],1420919125,"http://arxiv.org/abs/1412.6980

http://arxiv.org/abs/1412.7419

http://arxiv.org/abs/1412.6599

The results look pretty impressive. One of the papers trains a 16-layer network! Unfortunately, they all use different benchmarks, so it's hard to see which of the approaches is truly SOTA.",24,36
117,2015-1-11,2015,1,11,8,2s0bqo,Implementing a Weighted Majority Rule Ensemble Classifier in Scikit-learn,https://www.reddit.com/r/MachineLearning/comments/2s0bqo/implementing_a_weighted_majority_rule_ensemble/,rasbt,1420932525,,4,4
118,2015-1-11,2015,1,11,10,2s0m1l,Helpful HMM slides,https://www.reddit.com/r/MachineLearning/comments/2s0m1l/helpful_hmm_slides/,UTD_Vagrant,1420938364,,0,1
119,2015-1-11,2015,1,11,15,2s1e8z,Pandas tears.. large data set and memory issues?,https://www.reddit.com/r/MachineLearning/comments/2s1e8z/pandas_tears_large_data_set_and_memory_issues/,nameBrandon,1420956094,"I'm just trying a simple pd.read_csv on a ~12GB .csv file, and it made Pandas cry.. all kinds of weird memory errors in iPython, so I tried it straight from the console and get the same issue.

All I'm trying to do is to load the training set, and take a smaller (random, w/o replacement) subset of it for further analysis. I can't even get the file to load right now.

Is Pandas not the right choice for this? I didn't start with R because I thought Python might handle the larger size better, but this doesn't seem to be the case.

Any suggestions? The laptop has 16GB of ram, but obviously the OS and other stuff is eating up a good portion.

I did try the low_memory=False option but it didn't appear to do anything. FWIW, the data set doesn't have that many columns (maybe 30), it's just a lot of records.
",16,2
120,2015-1-11,2015,1,11,19,2s1vad,Data Science 45min Intros,https://www.reddit.com/r/MachineLearning/comments/2s1vad/data_science_45min_intros/,Qawba,1420973398,,7,58
121,2015-1-11,2015,1,11,22,2s23id,Angry Birds AI Competition,https://www.reddit.com/r/MachineLearning/comments/2s23id/angry_birds_ai_competition/,a545a,1420982744,,2,17
122,2015-1-12,2015,1,12,1,2s2han,Tutorial - Basics of Image processing and feature extraction using Python,https://www.reddit.com/r/MachineLearning/comments/2s2han/tutorial_basics_of_image_processing_and_feature/,kunalj101,1420993197,,0,0
123,2015-1-12,2015,1,12,2,2s2mi9,Looking for help selecting appropriate algorithm,https://www.reddit.com/r/MachineLearning/comments/2s2mi9/looking_for_help_selecting_appropriate_algorithm/,sprocket,1420996135,"I'm looking for some guidance in selecting an appropriate algorithm for matching records in two large datasets I have.  Both datasets contain first/middle/last name information, plus address/city/state/zipcode information.  What I would like to be able to do it calculate some sort of confidence score that indicates whether a record from dataset A is likely to be the same as a record from dataset B.

In doing some research, I came across the SimHash (http://www2007.org/papers/paper215.pdf) algorithm, which appears to be a good candidate for what I'd like to do - is this an appropriate algorithm, in this case?  I'm unclear as to whether or not I have enough text to generate good matches.

Edit: Just to clarify the original post, Dataset A is ~ 5 million records and is stored in a database.  We receive updates in the form of Dataset B on a monthly basis, and whose data is formatted differently (it's hand-entered, so there may be slight variations in spelling, and inconsistencies (ie. abbreviations in addresses, hyphens/no hyphens, etc)).  Simhash seems ideal for indexing Dataset A, as we can pre-compute a field in the database for easy lookups when updating with Dataset B.",1,0
124,2015-1-12,2015,1,12,5,2s37ki,Research Priorities for Artificial Intelligence: An Open Letter,https://www.reddit.com/r/MachineLearning/comments/2s37ki/research_priorities_for_artificial_intelligence/,[deleted],1421007088,,1,0
125,2015-1-12,2015,1,12,8,2s3ss0,2 min video of adaptive Extreme Learning Machine controlling gasoline engine combustion in real-time using Linux on a Raspberry Pi,https://www.reddit.com/r/MachineLearning/comments/2s3ss0/2_min_video_of_adaptive_extreme_learning_machine/,findx2,1421017551,,10,45
126,2015-1-12,2015,1,12,8,2s3ssu,Move Evaluation in Go Using Deep Convolutional Neural Networks [PDF],https://www.reddit.com/r/MachineLearning/comments/2s3ssu/move_evaluation_in_go_using_deep_convolutional/,alexjc,1421017564,,0,3
127,2015-1-12,2015,1,12,8,2s3v78,Where can I find Internships for Machine Learning ?,https://www.reddit.com/r/MachineLearning/comments/2s3v78/where_can_i_find_internships_for_machine_learning/,devllved,1421018786,"I have proficient programming experiences with Java,Python,Clojure.( I worked for two years as a programmer,full stack, after graduation.) 

Now I am back in a bad grad school program for various reasons, and I am basically on my own. I am  self studying machine learning and NLP related topics, so I am looking for internship opportunities.
I live in Urumqi,China.I am fluent in  both Chinese and Uyghur. My English is pretty good , I think :D. I have 30hours each week, and I am willing to work on the weekends in case 30hours are not enough.

I still have certain classes to take here,so relocation is not an option for me now.  I am aiming for remote internships.

In case you are interested , I can PM you my resume.
Thanks
",6,0
128,2015-1-12,2015,1,12,8,2s3vr2,Invitation to Participate in Artificial General Intelligence conference (AGI-15) (x-post /r/agi),https://www.reddit.com/r/MachineLearning/comments/2s3vr2/invitation_to_participate_in_artificial_general/,JordiBieger,1421019103,,0,1
129,2015-1-12,2015,1,12,14,2s50k4,Meet the market shapers,https://www.reddit.com/r/MachineLearning/comments/2s50k4/meet_the_market_shapers/,vkodati79,1421042105,,0,0
130,2015-1-12,2015,1,12,16,2s59th,What Do You Need To Know About Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/2s59th/what_do_you_need_to_know_about_deep_learning/,33rdsquare,1421049438,,0,2
131,2015-1-12,2015,1,12,21,2s5qe2,An easygoing introduction to Bayesian decision theory,https://www.reddit.com/r/MachineLearning/comments/2s5qe2/an_easygoing_introduction_to_bayesian_decision/,rasmusab,1421065583,,1,70
132,2015-1-12,2015,1,12,22,2s5uj8,It's all about Data: Big Data Analytics Trends to Watch Out for in 2015,https://www.reddit.com/r/MachineLearning/comments/2s5uj8/its_all_about_data_big_data_analytics_trends_to/,ananyaswami,1421068900,,2,0
133,2015-1-13,2015,1,13,0,2s683f,"Human intelligence is withering as computers do more, but theres a solution",https://www.reddit.com/r/MachineLearning/comments/2s683f/human_intelligence_is_withering_as_computers_do/,vaschr,1421077273,,1,0
134,2015-1-13,2015,1,13,4,2s732g,Support Vector Machines - A wonderful lecture by MIT professor Patrick Winston,https://www.reddit.com/r/MachineLearning/comments/2s732g/support_vector_machines_a_wonderful_lecture_by/,Eagle-Eye-Smith,1421091800,,4,96
135,2015-1-13,2015,1,13,12,2s8rv0,Extreme Learning Machine: Learning Without Iterative Tuning (video lecture),https://www.reddit.com/r/MachineLearning/comments/2s8rv0/extreme_learning_machine_learning_without/,[deleted],1421120482,,11,5
136,2015-1-13,2015,1,13,13,2s8za4,Neural Network Language Models?,https://www.reddit.com/r/MachineLearning/comments/2s8za4/neural_network_language_models/,FuschiaKnight,1421124661,"Hey, there!

Undergraduate here that is interested in Natural Language Processing. Up until now, I've mostly been using Machine Learning classifiers as black boxes for NLP tasks, but for my senior thesis, I'd like to work on something a bit more ML-based.

My current interest is that I'd like to learn about neural nets. Last semester, I had to give a presentation about Mikolov's ""Distributed Representations of Words and Their Compositionalities."" http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf . I did my best on the paper, and the results were interesting enough but the methods were obviously over my head. I mention this just because it's my current goal of something I'd really like to be able to understand (as well as anyone else does, I suppose) over the next few months.

In the past few weeks, I've gone through Ng's Coursera course for Machine Learning and I feel pretty comfortable with the basics of ML concepts. I've also investigated some other resources for trying to better understand Neural Nets. I found Nielsen's work-in-progress book VERY helpful http://neuralnetworksanddeeplearning.com/. The biggest breakthrough/realization that I had was when I realized that backpropogation is just a Dynamic Programming algorithm that memoizes partial derivatives (and I can't believe none of these resources just said that upfront).

I've also tried Geoffrey Hinton's Coursera course and Hugo Larochelle's youtube videos, but I personally didn't find those as helpful. I got about halfway through Hinton's course and maybe 10 videos into Larochelle's.

If you're still reading by now, thanks! Does anyone have any suggestions on where to look next in order to better understand how to build a neural net that can learn a distributed representation for a language model? I'm quite comfortable with simple n-gram models with smoothing, but any time I find a paper from a google search involving ""neural network"" and ""language model"", all of the papers I find are still over my head. Are there any easy-to-understand NN models that I can start with, or do I need to jump into knowing how Recurrent NNs work (which I currently don't really understand)? I'd love to read any relevant papers, but I just can't figure out where to begin so that I can understand what's going on.",24,23
137,2015-1-13,2015,1,13,15,2s98jq,Direction on Multi Touch Attribution for Non-Digital Media,https://www.reddit.com/r/MachineLearning/comments/2s98jq/direction_on_multi_touch_attribution_for/,Iwdst,1421130412,After doing some research on ml problems I've come across the Multi Touch Attribution problem which looks like something good to put on my resume. I read vaguely somewhere that HMMs can be used but can't seem to get a sense on how exactly. Hoping the gurus on this sub could help out,0,0
138,2015-1-13,2015,1,13,16,2s9byb,[Questions] What advanced math underlies the creation of new types of neural networks?,https://www.reddit.com/r/MachineLearning/comments/2s9byb/questions_what_advanced_math_underlies_the/,3DSkid,1421132907,"There are SVMs, RBMs, HMMs, Autoencoders, ConvNets, CRFs, and more.  Are the creation of these networks just the result of extensive customization, or is there an underlying set of mathematical principles governing why they work well?

Put another way, let's say I want to create a novel type of neural network for a novel dataset.  Do I need to just try a bunch of currently known networks and tweak them to get better performance, or can I directly observe information about the data and create a structure likely to yield good results?  If so, how do I get the intuition to create this structure for my net?  ",3,0
139,2015-1-13,2015,1,13,17,2s9goy,"Lisbon Machine Learning School (LXMLS) Guide Lab (102 pages), July 2014",https://www.reddit.com/r/MachineLearning/comments/2s9goy/lisbon_machine_learning_school_lxmls_guide_lab/,[deleted],1421136949,,0,1
140,2015-1-13,2015,1,13,18,2s9ka5,Navigating the Semantic Horizon using Relative Neighborhood Graphs,https://www.reddit.com/r/MachineLearning/comments/2s9ka5/navigating_the_semantic_horizon_using_relative/,HerrKanin,1421140341,,0,6
141,2015-1-13,2015,1,13,21,2s9x6a,Best approach for unstructured data,https://www.reddit.com/r/MachineLearning/comments/2s9x6a/best_approach_for_unstructured_data/,harsh_scindia,1421152513,"Hello,
       I am working as a intern in software develpment company the assignment given to us is to creat Maching Learning code which will parse a string of 300-400 characters which does not consist of either formal or natural language the type of string is:

LON CO MAN AF FRA RAHUL M250.00AF MAN CO LON RAHUL M 250.00 GBP 500.00 END

where the three letter code is citycode and 2 letter alphanumeric is airline code and RAHUL is farebasis and all alphabets followed by a decimal number are surcharges the rules to be followed are from the pdf below page no 74 onwards.
i would like to know if  any of the current ML libraries will be of help &amp;  how should i train the libraries to understand this type of vocabulary

http://www.avia-centr.ru/book/IATA/Ticketing%20Handbook%2039_2007_eng.pdf


",7,0
142,2015-1-14,2015,1,14,0,2saap3,Scala Data Pipelines for Music Recommendations at Spotify,https://www.reddit.com/r/MachineLearning/comments/2saap3/scala_data_pipelines_for_music_recommendations_at/,mrchrisjohnson,1421161570,,0,1
143,2015-1-14,2015,1,14,2,2sarmm,"Hanna Wallach shares her views on addressing fairness, accountability, and transparency in Machine Learning",https://www.reddit.com/r/MachineLearning/comments/2sarmm/hanna_wallach_shares_her_views_on_addressing/,[deleted],1421169564,,1,0
144,2015-1-14,2015,1,14,4,2sba2v,Feedly + Machine Learning prioritization of articles by content/title?,https://www.reddit.com/r/MachineLearning/comments/2sba2v/feedly_machine_learning_prioritization_of/,charlesbukowksi,1421177811,"Feedly and other reader sites are fantastic but invariably large blogs pollute your listings with hundreds of posts a week.   This can be time-consuming to sift through.  But if you're like me you've noticed patterns in the articles you actually click/pocket/read.  I'm sure headline writers are uniquely aware of such patterns, in any case it had me thinking such an issue could be resolved by machine learning.

An algorithm could pick up on the keywords in titles and articles which you tend to click.  As well as the ones you tend to skip.

This information could then be used to not only recommend unsubscribed blogs and articles but to prioritize your reader listings by ""likeness"" rather than date published.  Reddit is great because it outsources this to users, but this would be different in that it would be personalized AND dynamic.

So, my question: is there anything like that available and, if not, what technical challenges would this present?  Is it feasible?  Or do you think it's too niche to be worth while?
",14,1
145,2015-1-14,2015,1,14,7,2sc00w,Winning Angry Birds AI,https://www.reddit.com/r/MachineLearning/comments/2sc00w/winning_angry_birds_ai/,vougester,1421188814,,16,68
146,2015-1-14,2015,1,14,8,2sc94p,Predicting when a resource will run out?,https://www.reddit.com/r/MachineLearning/comments/2sc94p/predicting_when_a_resource_will_run_out/,Flipper3,1421192891,"I am trying to figure out what approach would be best for predicting when a resource will run out or be low and needs to be repleneished?
For example, let's say I have a salt shaker at a restaurant and am able to tell the amount of salt left in the shaker (by weight, mass, count, or whatever means is best). How could I use this data shown over time to predict when it will be empty and will need to be filled back up?
I need to be able to see that the shaker may get used more on weekends, or maybe during summer months, so taking time into account is pretty important.
I have been thinking about using a neural network with cos(time) or sin(time) as a time input variable, but I feel stumped as in my machine learning class two semesters ago we covered identification problems more than these kinds of problems.",1,0
147,2015-1-14,2015,1,14,9,2scc3x,Experienced researchers/machine learners how did you break the catch-22 of machine learning research?,https://www.reddit.com/r/MachineLearning/comments/2scc3x/experienced_researchersmachine_learners_how_did/,newMachinist,1421194248,"This is the application period for internships/summer internships in the college. However, coming from an industrial background (Software developer) I find myself in a very strange position. There are plenty of ml/data science internships but almost every one needs prior research experience in the field, in short to get an internship/research position you need an internship/research position. The second semester of the Masters course has started just now, thus I do not have much feathers in my cap from an research oriented ml perspective except from one data analysis project I did for a company in my first semester. 
So how did every one else here got a research position/internship when they were just starting out in this field?
Another loosely related problem is of choosing the field. Most of the research in ML revolvs around bioinformatics, neuroinformatics or computer vision. I understand computer vision a bit but have not much exposure to either biology or neuroscience, does that hinder my efforts of getting an internship? Lastly what can I do to increase my chances of getting a good internship in ML?",8,2
148,2015-1-14,2015,1,14,10,2sckfi,Thermal modification wood processing technology,https://www.reddit.com/r/MachineLearning/comments/2sckfi/thermal_modification_wood_processing_technology/,xinan2015,1421198183,,0,0
149,2015-1-14,2015,1,14,10,2sclpj,Method For Improving Compressor Housing Crack,https://www.reddit.com/r/MachineLearning/comments/2sclpj/method_for_improving_compressor_housing_crack/,awintur,1421198796,,0,0
150,2015-1-14,2015,1,14,14,2sdb6d,Machine Learning Interviews - complete list of questions asked. These presentations will be helpful for those who prepare for Machine Learning Interviews.,https://www.reddit.com/r/MachineLearning/comments/2sdb6d/machine_learning_interviews_complete_list_of/,thegameCRM,1421211608,,3,11
151,2015-1-14,2015,1,14,14,2sdbki,Method For Improving Compressor Housing Crack,https://www.reddit.com/r/MachineLearning/comments/2sdbki/method_for_improving_compressor_housing_crack/,hanjoy1,1421211810,,0,1
152,2015-1-14,2015,1,14,14,2sdc6e,Random Bits Regression: a Strong General Predictor,https://www.reddit.com/r/MachineLearning/comments/2sdc6e/random_bits_regression_a_strong_general_predictor/,godspeed_china,1421212136,"Hi All,
  I have developed a predictor that is generally strong on various dataset. I will be happy if you try it and give me some feedbacks.
  The basic idea is that we first randomly generate many (10^5) intermediate/derived features by combining the original features. And then use regularized regression to predict the outcome.
  It is faster and more accurate than most existing methods.
  software: http://sourceforge.net/projects/rbr/
  paper: http://arxiv.org/abs/1501.02990",12,7
153,2015-1-14,2015,1,14,14,2sdg0v,"Resources for Web Content Mining, Information Retrieval, Analytics?",https://www.reddit.com/r/MachineLearning/comments/2sdg0v/resources_for_web_content_mining_information/,[deleted],1421214437,"I recently completed some formidable web content retrieval tasks as part of a job application. I'm hungry for more challenges, problem sets, classes, groups, etc.

I realize there's a lot more that goes into data science but for the time being I'm more interested in the ""web/database exploration, linguistics, forming search query strategy, text analysis"" side of things rather than get too deep into statistical analysis.",0,0
154,2015-1-14,2015,1,14,19,2sdyp8,kompresorw,https://www.reddit.com/r/MachineLearning/comments/2sdyp8/kompresorw/,verisf,1421230027,,0,1
155,2015-1-14,2015,1,14,22,2seb4b,Great course on Supervised Learning provided by Udacity - First of a 3 part course about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2seb4b/great_course_on_supervised_learning_provided_by/,tendaz,1421241295,,5,7
156,2015-1-14,2015,1,14,23,2sejae,[1412.5335] Ensemble of Generative and Discriminative Techniques for Sentiment Analysis of Movie Reviews,https://www.reddit.com/r/MachineLearning/comments/2sejae/14125335_ensemble_of_generative_and/,improbabble,1421246708,,1,3
157,2015-1-15,2015,1,15,0,2serjx,Outlook: Getting ahead in 2015 with Big Data Analytics,https://www.reddit.com/r/MachineLearning/comments/2serjx/outlook_getting_ahead_in_2015_with_big_data/,naireshma,1421250973,,0,0
158,2015-1-15,2015,1,15,1,2seuyz,command-line documentation for mahout?,https://www.reddit.com/r/MachineLearning/comments/2seuyz/commandline_documentation_for_mahout/,[deleted],1421252613,"I'm running mahout on EMR for some pretty basic stuff (recommendations, clustering) and I could do most of what I needed to do by looking at the brief tutorials that are online, but I think life might be easier with a complete list of what the command line options are.  I checked google &amp; stack exchange and didn't find anything, and the mahout apache site has very little in the way of documentation.

Anyone seen something like this?  I saw that there was a jira ticket to create a manpage, but the servers that EMR stands up doesn't have that and I'm not even sure that it ever got done.

My hope was to be able to use mahout without having to use java/maven, just the basic command-line options that you have available by default when you stand up an EMR cluster.

Thanks!",0,0
159,2015-1-15,2015,1,15,1,2sew6w,"Reddit , i need some advices about the subject for a Machine Learning project",https://www.reddit.com/r/MachineLearning/comments/2sew6w/reddit_i_need_some_advices_about_the_subject_for/,Bshow,1421253156,"I'm attending course of AI at my university and for the final exam we have to code a little program about one subject of the couse.We had an introduction in Machine Learning during the final weeks of class so i opted for doing the project about that.However i would like to find a project a little ""out on the box"" , like something with a minimum application.I don't have the knowledge yet to find something so if someone of you wanna help i'd really appreciate it.",2,0
160,2015-1-15,2015,1,15,1,2sezbx,ChaLearn Automatic Machine Learning Challenge (AutoML),https://www.reddit.com/r/MachineLearning/comments/2sezbx/chalearn_automatic_machine_learning_challenge/,galapag0,1421254644,,0,5
161,2015-1-15,2015,1,15,2,2sf106,Award-winning NIPS paper brings precision to sampling Methods used in statistics &amp; ML,https://www.reddit.com/r/MachineLearning/comments/2sf106/awardwinning_nips_paper_brings_precision_to/,MLBlogTeam,1421255400,,0,1
162,2015-1-15,2015,1,15,2,2sf2eh,Computer-based personality judgments are more accurate than those made by humans [pdf],https://www.reddit.com/r/MachineLearning/comments/2sf2eh/computerbased_personality_judgments_are_more/,jonathan881,1421256032,,1,5
163,2015-1-15,2015,1,15,2,2sf33q,"Robotics, Machine Learning, Artificial Intelligence Research?",https://www.reddit.com/r/MachineLearning/comments/2sf33q/robotics_machine_learning_artificial_intelligence/,[deleted],1421256333,"After years of not knowing what the heck I actually wanted to do with my life, I'll finally start my CS BS major next fall at ETH Zuerich, which is the hardest, but also the best University in my country.

(Even though I'm still extremely insecure whether I should rather have applied in ""Machine Engineering"" or ""Information Technology and Electrical Engineering"")

Let's say I want to be at the forefront of Artificial Intelligence Research, Machine Learning Algorithms, Robotics and all that crazy shit; is my assumption correct that I should specialise in Visual Computing &amp; Machine Learning in my Bachelor and Master and strive for the PhD?

What should I expect on such a path?",3,1
164,2015-1-15,2015,1,15,2,2sf48a,Created this learning path to learn data science on Python. Do let me know any suggestions / feedback,https://www.reddit.com/r/MachineLearning/comments/2sf48a/created_this_learning_path_to_learn_data_science/,kunalj101,1421256836,,7,54
165,2015-1-15,2015,1,15,2,2sf6xs,A brief introduction to Gaussian Processes,https://www.reddit.com/r/MachineLearning/comments/2sf6xs/a_brief_introduction_to_gaussian_processes/,aprstar,1421258123,,0,9
166,2015-1-15,2015,1,15,3,2sfe0r,Numerical Optimization Video Lectures - Primer Course for Machine Learning. Taught by a renowned Professor in clear manner.,https://www.reddit.com/r/MachineLearning/comments/2sfe0r/numerical_optimization_video_lectures_primer/,thegameCRM,1421261360,,1,1
167,2015-1-15,2015,1,15,4,2sfjtw,Anyone know of any DBN code in Torch7?,https://www.reddit.com/r/MachineLearning/comments/2sfjtw/anyone_know_of_any_dbn_code_in_torch7/,0ttr,1421264018,"new to torch7, looking to see if anyone had published code for DBN with pretraining.   I do see some RBM code that I could perhaps stack.  It looks like there's some DBN code in python/theano, but I'm somewhat surprised I can't find any for torch7, or is it easier to DIY than I think.   It does look like it's easy to stack networks and do softmax so maybe I just need to DIY or am I not sufficiently equating stacked auto-encoders with DBNs?   ",0,1
168,2015-1-15,2015,1,15,5,2sfsw1,Google announces new translation capabilities,https://www.reddit.com/r/MachineLearning/comments/2sfsw1/google_announces_new_translation_capabilities/,siblbombs,1421267931,,1,5
169,2015-1-15,2015,1,15,6,2sfzrw,"Free Machine Learning Labor! Or, ""What are your feelings about Kaggle and similar sites?""",https://www.reddit.com/r/MachineLearning/comments/2sfzrw/free_machine_learning_labor_or_what_are_your/,thatguydr,1421270909,"This was prompted by the post by ChaLearn today here in /r/MachineLearning. They're offering a pittance to create a 100% fully automated machine learning system.

I hate this.

I hate that there are hundreds or thousands of people out there willing to solve problems for $500 (or less!) that you reasonably could get $5k, $20k, or even more to solve. I hate that so many people in this field have fallen for the norm of ""oh but it's EXPOSURE!"" on jobs that won't pay you what you're worth. This is how the entertainment business works, because in entertainment, you have a glut of supply, and people are willing to do ANYTHING to get their names out. In machine learning, we have a glut of demand!

I really don't like it when smart people fail to value themselves. I don't like companies using Kaggle as a proxy for experience, not because it's a poor proxy, but because it creates an artificial scarcity (of ""judge-able competitions to be won"") in a field where supply is far, far less than demand.

I could be in a minority, though. What are your thoughts on Kaggle and similar websites? Exploitative or useful? And what are your thoughts on the self-valuation of people in machine learning?",34,41
170,2015-1-15,2015,1,15,6,2sg0p4,Baidu now has best ImageNet classification with 5.98% error (Beating out GoogLeNet for #1),https://www.reddit.com/r/MachineLearning/comments/2sg0p4/baidu_now_has_best_imagenet_classification_with/,[deleted],1421271286,,0,1
171,2015-1-15,2015,1,15,7,2sg6c2,Machine Learning Open Source Software,https://www.reddit.com/r/MachineLearning/comments/2sg6c2/machine_learning_open_source_software/,rouma7,1421273826,,0,9
172,2015-1-15,2015,1,15,7,2sgae0,A Brief Overview of Deep Learning - blog post by Ilya Sutskever,https://www.reddit.com/r/MachineLearning/comments/2sgae0/a_brief_overview_of_deep_learning_blog_post_by/,benanne,1421275628,,5,26
173,2015-1-15,2015,1,15,8,2sgh3a,Which ML MOOC do you recommend?,https://www.reddit.com/r/MachineLearning/comments/2sgh3a/which_ml_mooc_do_you_recommend/,abstractmath,1421278838,"So far, I have encountered [Andrew Ng's Coursera course](https://www.coursera.org/course/ml) and [Yaser Abu-Mostafa's edX course](https://www.edx.org/course/learning-data-caltechx-cs1156x#.VLb8SorF83A). Which do you recommend, and why?

Thank you to all responders!",6,1
174,2015-1-15,2015,1,15,9,2sgo0j,NeuralNet Training Time,https://www.reddit.com/r/MachineLearning/comments/2sgo0j/neuralnet_training_time/,chrico031,1421282117,"I'm training a Neural Net in R using the neuralnet package and am wondering what has the most effect on training time.

Assume I have a dataset consisting of 22 IVs and 1 Binary Response Variable that has 2,000 rows of data, and another dataset of 22 IVs and 1 Binary Response Variable that has 22,000 rows of data.

Will the dataset of 22,000 rows take 11x as long to train as the dataset with 2,000 rows of data? Or is number of Variables and Hidden Layer Nodes the major factor in training time?",3,2
175,2015-1-15,2015,1,15,10,2sgxdr,Training my HMM seems to be too random,https://www.reddit.com/r/MachineLearning/comments/2sgxdr/training_my_hmm_seems_to_be_too_random/,purpleladydragons,1421286964,"Hi guys, I tried implementing a hidden markov model and it seems to work so far from testing it on a simple vowel &amp; consonant classifier. However, I'm initializing the matrices with random values, each time with a different seed which seems to have a large effect on the end result.

Running the program multiple times reveals very different results: sometimes a satisfactory local maximum is found very quickly, and other times, the model takes very long just to reach an unsatisfactory local maximum.

My understanding is that I'm working with larger dimensions here so hill climbing can run into this kind of local maximum issue pretty commonly. However, I'm more concerned with the slow progress part. Is there a general practice for detecting when a model's training is too slow? ",1,1
176,2015-1-15,2015,1,15,13,2shgnr,Deep Image: Scaling up Image Recognition,https://www.reddit.com/r/MachineLearning/comments/2shgnr/deep_image_scaling_up_image_recognition/,jcasper,1421297230,,7,19
177,2015-1-15,2015,1,15,18,2si2vk,Using NER to extract airport codes and airline codes using any NLP library?,https://www.reddit.com/r/MachineLearning/comments/2si2vk/using_ner_to_extract_airport_codes_and_airline/,harsh_scindia,1421315647,"I would like to extract Airport Codes &amp; Airline Codes from a string. Airport/City Codes are 3 letter alpha codes. Airline Codes are 2 letter alpha &amp; alpha numeric codes.

Example for airline codes

AA == American Airlines.

Airport codes

JFK == John F. Kennedy International Airport

LGA == LaGuardia Airport

I have a list of all the airport codes and airline codes in the world. the type of string that i want to extract is like.

JFKAAX/BOSAACHIM100.00Q9USMEXQ125.00YLEE/CH30500.00ENDROE0.56893458

there is an ambiguity because KAA can also be identifed as an airport. Which is a valid airport code.

How can i use NER to extract the two items. If NER is not suitable is there any other way.",6,1
178,2015-1-15,2015,1,15,21,2siadl,Baidu built a supercomputer for deep learning,https://www.reddit.com/r/MachineLearning/comments/2siadl/baidu_built_a_supercomputer_for_deep_learning/,igor_subbotin,1421323282,,0,14
179,2015-1-15,2015,1,15,21,2sicyi,Percepto - computer vision for drones,https://www.reddit.com/r/MachineLearning/comments/2sicyi/percepto_computer_vision_for_drones/,ravivraz,1421325639,"Hi all
I am computer vision developer and a product manager in a really cool start-up called Percepto. Our product is a drone add-on that enables computer vision developers to easily create drone applications.
We believe that computer vision holds the potential to redefine drone capabilities and make them safer, easier to use and more versatile. We also believe that open source development is the fastest way to achieve this.
We are trying to better understand which features are more valuable for computer vision developers like you. Would you mind taking 5 minutes answering a short questionaaire?
 link - http://goo.gl/forms/vQEXnDB0gi
We would really appreciate your feedback on Percepto.
Thoughts &amp; ideas are also always welcome
",0,1
180,2015-1-15,2015,1,15,23,2sikmx,Looking for example/starter Python code for partial_fit and generators,https://www.reddit.com/r/MachineLearning/comments/2sikmx/looking_for_examplestarter_python_code_for/,nameBrandon,1421331321,"I've got a pretty large dataset (~40MM records / 5GB) in csv format.

I've gotten as far as writing a generator to read lines from the file and dump them out via print() in chunks of 10. 

I'm looking for a bit more explanation of how I can rip out a mix of categorical and continuous variables from the file chunks and pass them to an estimator method via partial_fit. I'm currently looking at SGD (Classification) but any example is fine. Obviously I want to use larger chunks but I'm just using 10 lines as it's easy to debug and watch the process.

I've seen the Reuters sklearn out-of-core example and others, and I'm still learning a lot of the basics of Python so some of it was a bit over my head. For example, one code used the FeatureHasher function, and I kind of get the concept, but not sure when it is, or is not appropriate (obviously categorical data, but why FeatureHasher vs OneHotEncoder, etc..).

If anyone has a link to any example code (even psuedo-code would be great) that just demonstrates this at a very basic level I would very much appreciate a link.

",1,2
181,2015-1-16,2015,1,16,0,2sivfn,A growing list of free and open-source datasets,https://www.reddit.com/r/MachineLearning/comments/2sivfn/a_growing_list_of_free_and_opensource_datasets/,[deleted],1421337321,,0,1
182,2015-1-16,2015,1,16,0,2sivi8,A growing list of free and open-source datasets,https://www.reddit.com/r/MachineLearning/comments/2sivi8/a_growing_list_of_free_and_opensource_datasets/,rasbt,1421337354,,16,77
183,2015-1-16,2015,1,16,2,2sj8bu,Running R in Parallel (the easy way),https://www.reddit.com/r/MachineLearning/comments/2sj8bu/running_r_in_parallel_the_easy_way/,hernamesbarbara,1421343460,,0,3
184,2015-1-16,2015,1,16,2,2sj9s7,we'll use ml/ai in 20 years the way we use cars and cell phones now,https://www.reddit.com/r/MachineLearning/comments/2sj9s7/well_use_mlai_in_20_years_the_way_we_use_cars_and/,theGameGamer,1421344157,"in the sense that we'll all have a highly personal ml/ai tool that we can apply to a wide variety of problems we encounter in our lives. Does everyone feel this is more or less likely to be the case?

Note, I am not promoting this view, I just want to start a discussion!",3,0
185,2015-1-16,2015,1,16,4,2sjmgh,What exactly is deep learning? Here's a concise introductory article to the field.,https://www.reddit.com/r/MachineLearning/comments/2sjmgh/what_exactly_is_deep_learning_heres_a_concise/,robotbugs,1421349852,,1,12
186,2015-1-16,2015,1,16,5,2sjv2z,"Slides of Paris Machine Learning Meetup #5 Season 2, Time Series and FinTech, Adversarial Algos (Video is in French)",https://www.reddit.com/r/MachineLearning/comments/2sjv2z/slides_of_paris_machine_learning_meetup_5_season/,compsens,1421353627,,0,4
187,2015-1-16,2015,1,16,5,2sjz8r,How can I pass time series data into a sklearn classifier using pandas?,https://www.reddit.com/r/MachineLearning/comments/2sjz8r/how_can_i_pass_time_series_data_into_a_sklearn/,timetoprocrastinate,1421355428,"I apologize if this question is not appropriate for this sub. I have been making predictive models using scikit-learn for a few months now, and each time the data is organized in a way where each column is a feature, and each row is a sample.

However now I have a multivariate time series classification problem using data from a gyroscope/accelerometer, where each row is simply a single millisecond in time, so the whole sample is something like a 1000x10 matrix (1000ms of data, with 10 features). How can I label these samples for my training set (usually the label is the last column of the row, but now there are 1000 rows in each sample). For context, I am trying to take the sensor data and classify movements such as ""walking"" or ""running"". Similarly, how can I make a training set with all this data, since concatenating all the samples will make it appear to the classifier that there is one continuous series that jumps from the end of each sample to the start of the next one. 

I assume there is a simple solution to this, such as making each sample an array of arrays and counting that as just one row, but I can not figure out what that would actually look like using pandas/python, and it's very frustrating! Any help is greatly appreciated, thanks!",7,1
188,2015-1-16,2015,1,16,7,2skbic,Talking deep nets with Ilya Sutskever - Talking Machines Episode 2 is up!,https://www.reddit.com/r/MachineLearning/comments/2skbic/talking_deep_nets_with_ilya_sutskever_talking/,jsnoek,1421360969,,7,46
189,2015-1-16,2015,1,16,9,2skrhc,"From drone imagery to Vegetation Base Maps, classifying Namibias savannahs",https://www.reddit.com/r/MachineLearning/comments/2skrhc/from_drone_imagery_to_vegetation_base_maps/,[deleted],1421368723,,0,1
190,2015-1-16,2015,1,16,9,2skrtd,"From drone imagery to Vegetation Base Maps, classifying Namibias savannahs",https://www.reddit.com/r/MachineLearning/comments/2skrtd/from_drone_imagery_to_vegetation_base_maps/,keghn,1421368879,,0,4
191,2015-1-16,2015,1,16,10,2skul7,Logarithmic reduction of mutation rate in a fitness-based genetic learning algorithm,https://www.reddit.com/r/MachineLearning/comments/2skul7/logarithmic_reduction_of_mutation_rate_in_a/,Russian-Assassin,1421370283,"I wrote a program in Java that simulates little box creatures with joints and a neural net brain. It evolves them using a fitness function (distance moved to the right) and gives pretty nice results within a few to a few hundred generations.

However, I have noticed that with one of the creatures, occasionally it will evolve into a kind of jumping motion and occasionally it will evolve into a much quicker shaking motion (like hexbugs). Once it has evolved into one, it will not evolve into the other.

I think that the jumping variation is a local minima and the vibrating one is the global minimum. Due to the fact that my mutation rate is static along with all the other parameters, using a low mutation rate will cause it to become stuck in local minima and using a high mutation rate will cause it to become unstable and occasionally fall out of a minimum.

I want to implement a logarithmic reduction of the mutation rate but I am still a beginner and I don't know exactly how it should work. Specifically, at what mutation rate should it start and should it change depending on the fitness rate as well as the generation?

All help is appreciated!",5,1
192,2015-1-16,2015,1,16,10,2skuyi,Explain how to use/interpret Neural Networks ..?,https://www.reddit.com/r/MachineLearning/comments/2skuyi/explain_how_to_useinterpret_neural_networks/,watersign,1421370479,"Hi,
So im relatively familar with decision trees, logistic regression, svm, bayes nets, and have been reading about ANN. Apparently they are the best thing since sliced bread...I have no idea how to use them or interpret them though and I know i'm not alone. I use decision trees at work and they are easy to use for the most part but ANN confuse me. Help? ",10,0
193,2015-1-16,2015,1,16,14,2sllyw,"Yoshua Bengio via +Hugo Larochelle , ""The papers for ICLR 2015 are now open for discussion! (this requires an ICLR 2015 CMT account, which you can sign up for if you don't have one already...)""",https://www.reddit.com/r/MachineLearning/comments/2sllyw/yoshua_bengio_via_hugo_larochelle_the_papers_for/,test3545,1421385155,,0,8
194,2015-1-16,2015,1,16,14,2sloz9,A few questions about Restricted Boltzmann Machines,https://www.reddit.com/r/MachineLearning/comments/2sloz9/a_few_questions_about_restricted_boltzmann/,mr_yogurt,1421387080,"I've been having difficulty understanding RBMs, and I'd like some questions answered. All I can really comprehend so far is that they can be used to generate data, but that's about it.

1. How is an RBM used to generate data?
2. Wikipedia describes RBMs as being able to learn a probability distribution over a set of inputs. My understanding of this is that you can give a trained RBM an input, and it can try to predict the likelyhood of this input happening. Is that correct? If so, how does one actually get this value?
3. Can an RBM be used for sequences of inputs?
4. Where might I be able to find an explanation of RBMs that doesn't require a degree in mathematics?

Sorry about the awkward AMAish format, I couldn't find a good way to put these questions.",3,2
195,2015-1-16,2015,1,16,16,2slwtj,Envelope Making Machine  Smarter Way to Making Envelope,https://www.reddit.com/r/MachineLearning/comments/2slwtj/envelope_making_machine_smarter_way_to_making/,timesoftrade,1421392924,,1,1
196,2015-1-16,2015,1,16,20,2smd74,DeepWalk: Online Learning of Social Representations [open source implementation],https://www.reddit.com/r/MachineLearning/comments/2smd74/deepwalk_online_learning_of_social/,galapag0,1421409416,,1,17
197,2015-1-16,2015,1,16,23,2smo39,"SO: C++ OpenCV SVM Predict Not Working - Don't know if this is an acceptable post, but I'm desperate",https://www.reddit.com/r/MachineLearning/comments/2smo39/so_c_opencv_svm_predict_not_working_dont_know_if/,[deleted],1421417953,,0,0
198,2015-1-17,2015,1,17,1,2sn0ob,Visualizing Representations: Deep Learning and Human Beings,https://www.reddit.com/r/MachineLearning/comments/2sn0ob/visualizing_representations_deep_learning_and/,iori42,1421424706,,11,64
199,2015-1-17,2015,1,17,2,2sn8j6,"Facebook open sources tools for bigger, faster deep learning models",https://www.reddit.com/r/MachineLearning/comments/2sn8j6/facebook_open_sources_tools_for_bigger_faster/,igor_subbotin,1421428443,,1,3
200,2015-1-17,2015,1,17,2,2sn93y,Genetic algorithm walkers,https://www.reddit.com/r/MachineLearning/comments/2sn93y/genetic_algorithm_walkers/,igor_subbotin,1421428720,,4,10
201,2015-1-17,2015,1,17,2,2sn953,"Channel 9 Video on orchestrating data pipelines, transforming raw data into trusted data assets using Data Factory",https://www.reddit.com/r/MachineLearning/comments/2sn953/channel_9_video_on_orchestrating_data_pipelines/,MLBlogTeam,1421428737,,0,1
202,2015-1-17,2015,1,17,4,2snom8,"Meet RoboCORE: An upcoming robotics system, Let your personal robot come to life and equip it with heartbeat by using these modern hardware, Have a look..",https://www.reddit.com/r/MachineLearning/comments/2snom8/meet_robocore_an_upcoming_robotics_system_let/,jahaidali5,1421435967,,3,0
203,2015-1-17,2015,1,17,4,2snr58,Facebook open sources deep-learning modules for Torch,https://www.reddit.com/r/MachineLearning/comments/2snr58/facebook_open_sources_deeplearning_modules_for/,iori42,1421437148,,1,29
204,2015-1-17,2015,1,17,6,2so1pw,Help regarding training !,https://www.reddit.com/r/MachineLearning/comments/2so1pw/help_regarding_training/,[deleted],1421442078,"Say we have a dataset (dataset-1) in which each data point belongs to a class (class-1, you can say these are anomalies). Now we have an unlabeled test dataset (dataset-2) which contains data points belonging to class-1 among many others.

What are different ways to train over dataset-1 to identify the data points belonging to class-1 in the unlabeled data (identifying anomalies similar to class-1 in dataset-2)?

Edit:- I already tried using GMM and giving it a likelihood threshold, I needed some more one-class classification algorithms I can model over the data.",8,1
205,2015-1-17,2015,1,17,10,2soze8,Can Scipy's minimum function optimize the value of a class data member?,https://www.reddit.com/r/MachineLearning/comments/2soze8/can_scipys_minimum_function_optimize_the_value_of/,Russell016,1421459491,"I'm working on a ANN, and got it working on simple AND/XOR problems using gradient descent, but I am finding it much more difficult to find the optimal weights for more complex problems. My solution was to use Scipy's minimum function instead, but I am having some trouble.

My ANN is a class, and when ANN object is created, weights are created upon initialization as the data member self.__weights, this is useful because I don't actually have to pass a weights parameter into any of the methods used on the class, and it worked in my earlier non-Scipy using implementation.

I use the self.__weights as the initial guess for the minimum function, and pass in the other arguments(input data, the correct output values) needed to make the function work. But it seems, that the optimizer keeps passing the weights into the methods(Cost Function/FeedForward/Backprop) as a parameter when there is no need to since it can be called with self.__weights. For instance, when my FeedForward method is called, it passes in the weights, and states that the input isn't of the correct size, this is because the weights were passed in instead. And the input data is passed into the minimum's optional 'arg=' parameter.

So, all explanation done, must the value to be optimized actually be a parameter of the methods being used to optimized it, and not just a class data member that can be called from anywhere within in the class? I've tried to find examples using a class they pass in there 'weights' or other value to be optimized depending on there use, not a data member of the class.



This is code a snippet is located in my train method. It's parameters are input_data and target.

    opt_theta = minimize(self.CostFunction,x0=self.__weights,args = (input_data,target),method='Newton-CG',jac=   self.Weight_Grad)       
    print(opt_theta)
    self.__weights = opt_theta.x 

self.CostFunction and self.Weight_Grad both take those same two parameters. Both of these latter two functions use a Feedforward method to get the output of the network, and do there respective task with that info. Whenever I call the minimize function it seems it passes self.__weights into self.CostFunction as the input_data parameter, which then gets passed into the FeedForward method as input and I get an error. IF i print the ""input"" passed into Feedforward it is the value of self.__weights. This is how I know self.__weights is getting passed in as a parameter when it shouldn't.

So, I thought I would create a ""dummy""? parameter to pass the the self.weights value into for all of the methods('self.CostFunction,'self.Weight_Grad,Feedforward) and an error did not occur but there was no change in the weights or the output. What do I need to do to get self.weights to update.

Here are the methods in case it helps:

def Feedforward(self,input):

        #Code to take self.__weights and convert to list of matrices. 
        weight_matrix_list = []
        prev_val = 0


        for i in range(len(self.__weight_sizes)):
            curr_w_size = self.__weight_sizes[i]
            weight_count = curr_w_size[0]*curr_w_size[1]
            matrix_elements = self.__weights[prev_val:prev_val+weight_count]
            weight_matrix_list.append(matrix_elements.reshape(curr_w_size))


        self.__input_cases = np.shape(input)[0]

        #Empty list to hold the output of every layer.
        output_list = []
        #Appends the output of the the 1st input layer.
        output_list.append(input)

        for i in range(self.__layers-1):
            if i == 0:

                print(self.__input_cases)
                print(input)
                X = np.concatenate((np.ones((self.__input_cases,1)),input),1)

                output = self.sigmoid(np.dot(X,weight_matrix_list[0].T))
                output_list.append(output)
            else:
                output = self.sigmoid(np.dot(np.concatenate((np.ones((self.__input_cases,1)),output),1),weight_matrix_list[i].T))                 
                output_list.append(output)


        return output_list

    def CostFunction(self,input_data,target,error_func=1):
        """"""Gives the cost of using a particular weight matrix 
        based off of the input and targeted output""""""
        print(""Cost"")
        #Run the network to get output using current theta matrices.
        output = self.Feedforward(input_data)[-1]


        #Determines number of input/training examples
        m = np.shape(input_data)[0]

        #####Allows user to choose Cost Functions.##### 

        #
        #Log Based Error Function
        #
        if error_func == 0:
            error = np.multiply(-target,np.log(output))-np.multiply((1-target),np.log(1-output))
            total_error = np.sum(np.sum(error))
        #    
        #Squared Error Cost Function
        #
        elif error_func == 1:
            error = (target - output)**2
            total_error = (1/(2*m)) * np.sum(np.sum(error))

        return total_error

    def Weight_Grad(self,input_data,target):
        print('Grad')
        weight_matrix_list = []
        prev_val = 0

        for i in range(len(self.__weight_sizes)):
            curr_w_size = self.__weight_sizes[i]
            weight_count = curr_w_size[0]*curr_w_size[1]
            matrix_elements = self.__weights[prev_val:prev_val+weight_count]
            weight_matrix_list.append(matrix_elements.reshape(curr_w_size))        

        output_list = self.Feedforward(theta,input_data)

        #Finds the Deltas for Each Layer
        # 
        deltas = []
        for i in range(self.__layers - 1):
            #Finds Error Delta for the last layer
            if i == 0:

                error = (target-output_list[-1])

                error_delta = -1*np.multiply(error,np.multiply(output_list[-1],(1-output_list[-1])))
                deltas.append(error_delta)
            #Finds Error Delta for the hidden layers   
            else:
                #Weight matrices have bias values removed
                error_delta = np.multiply(np.dot(deltas[-1],weight_matrix_list[-i][:,1:]),output_list[-i-1]*(1-output_list[-i-1]))
                deltas.append(error_delta)

        #
        #Finds the Deltas for each Weight Matrix
        #
        Weight_Delta_List = []
        deltas.reverse()
        for i in range(len(weight_matrix_list)):

            current_weight_delta = (1/self.__input_cases) * np.dot(deltas[i].T,np.concatenate((np.ones((self.__input_cases,1)),output_list[i]),1))
            Weight_Delta_List.append(current_weight_delta)




        #
        #Converts Weight Delta List to a single vector
        #        
        Weight_Delta_Vector = np.array([])
        for i in range(len(Weight_Delta_List)):
            Weight_Delta_Vector = np.concatenate((Weight_Delta_Vector,Weight_Delta_List[i].flatten()))
        print(""WDV Shape:"",np.shape(Weight_Delta_Vector))
        return Weight_Delta_Vector

    def Train(self,input_data,target):           

        opt_theta = minimize(self.CostFunction,x0=self.__weights,args = (input_data,target),method='Newton-CG',jac= self.Weight_Grad)       
        print(opt_theta)
        self.__weights = opt_theta.x

        print(""Done"")",2,0
206,2015-1-17,2015,1,17,11,2sp1nx,Looking for Feedback on my Machine Learning Curriculum,https://www.reddit.com/r/MachineLearning/comments/2sp1nx/looking_for_feedback_on_my_machine_learning/,EngineeredEdge,1421460866,"Hello /r/MachineLearning !

I recently finished Andrew Ng's Machine Learning course on Coursera, and now i want to dive deeper into the subject. I have a degree in engineering and four years of professional trading (finance) experience. Most of my educational goals would be directed in that area, but really I'm interested in all aspects of machine learning and data science.

Potential Refresher Coursers (it's been awhile and I really want to dive into math):

* [MIT's Open Courseware Linear Algebra Course](http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/)
* [MIT's Intro to Probability through edX](https://www.edx.org/course/introduction-probability-science-mitx-6-041x-0)

Main Course:

* [Statistical Learning hosted through Stanford](https://class.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about)
* [Andrew Ng's Stanford course on Machine Learning](http://see.stanford.edu/see/courseinfo.aspx?coll=348ca38a-3a6d-4052-937d-cb017338d7b1)
* [Abu-Mostafa's CalTech course Learning From data](https://work.caltech.edu/telecourse.html)
* [Tom Mitchell's Machine Learning at Carnegie Mellon](http://www.cs.cmu.edu/~tom/10701_sp11/)
* [Probabilistic Graphical Models through Coursera](https://www.coursera.org/course/pgm)

Textbooks to use in conjunction with the courses:

* [The Elements of Statistical Learning](http://web.stanford.edu/~hastie/local.ftp/Springer/OLD/ESLII_print4.pdf)
* [Bishop's Pattern Recognition and Machine Learning](http://www.rmki.kfki.hu/~banmi/elte/Bishop%20-%20Pattern%20Recognition%20and%20Machine%20Learning.pdf)
* [Probabilistic Graphical Models](http://pgm.stanford.edu/) 

I also have Duda's ""Pattern Classification,"" Kevin Murphy's ""Machine Learning: A Probabilistic Perspective,"" and Sutton's ""Reinforcement Learning: An Introduction"", but I am not sure how these should fit into my curriculum. Also, I'm lacking Abu-Mostafa's book ""Learning from Data""- for those familiar, how much am I missing?

Auxiliary Courses:

* [MIT's The Analytics Edge hosted through edX](https://www.edx.org/course/analytics-edge-mitx-15-071x-0#.VLnDdCvF9ZA)
* [Udacity's Intro to Machine Learning](https://www.udacity.com/course/ud120)

Note: I'm alread a quarter way through the Udacity course. It's basically a walkthrough tutorial for python's sklearn. For future student's, I'd recommend taking it in conjuction with Andrew Ng's Coursera machine learning course.

So now to my questions for you guys! Any feedback is greatly appreciated, but I have a few specific questions in mind.

1. How much material overlaps between the courses? My understanding is at least PGM is apart from the rest.
1. Am I taking these in the right order?
1. Are there any courses that I should add to my curriculum?
1. Are there any books that I should add?
1. Any other advice for me before I embark on this journey?

Finally, if anyone is interested in being a study partner send me a PM!

Thank you!!!",13,8
207,2015-1-17,2015,1,17,16,2sps17,[PICS] I have a sensor in my body that measures sugar but is inaccurate for various reasons. I also have a blood meter that is accurate. I want to process the sensor data so a) the inaccuracies are 'corrected' by the blood test data points and b) predicted future blood sugar crashes. How do I do it?,https://www.reddit.com/r/MachineLearning/comments/2sps17/pics_i_have_a_sensor_in_my_body_that_measures/,[deleted],1421478927,"I'm interested in any feedback or brainstorming ideas at all. I'm not familiar with machine learning, but I do want to manage my diabetes better with science.

PICS: http://imgur.com/a/GVN6c

The data: http://i.imgur.com/N2DOCfq.png

Y-axis is blood sugar level, X-axis is time, the red dots are blood tests, the green lines are the processed sensor data (sorry theres two green lines because I'm running two different algorithms to process the data to compare them). The unprocessed sensor data is similar, and measured every 5 minutes.

One algorithm simply multiplies and adds a number to every point the sensor transmits to make the sensor graph line up better with the blood tests.

The second algorithm is proprietary to a $600 medical device, so I don't know what it's doing, I'm just able to extract the post-processed data from it.

(Credit for the watch software and cloud sync goes to the team at https://www.facebook.com/groups/cgminthecloud , credit for the receiver box goes to the team at https://github.com/StephenBlackWasAlreadyTaken/DexDrip , and credit for the sensor goes to the team at Dexcom Inc.)",9,10
208,2015-1-17,2015,1,17,18,2sq03z,"Tech Master Engineering - Envelope Making Machine, Vadodara, Gujarat, India",https://www.reddit.com/r/MachineLearning/comments/2sq03z/tech_master_engineering_envelope_making_machine/,timesoftrade,1421487677,,1,0
209,2015-1-17,2015,1,17,21,2sq90n,Google Search Will Be Your Next Brain,https://www.reddit.com/r/MachineLearning/comments/2sq90n/google_search_will_be_your_next_brain/,clbam8,1421498208,,0,7
210,2015-1-17,2015,1,17,22,2sqbdl,The Deep Mind of Demis Hassabis,https://www.reddit.com/r/MachineLearning/comments/2sqbdl/the_deep_mind_of_demis_hassabis/,mrprint,1421500554,,11,44
211,2015-1-18,2015,1,18,0,2sqlnu,"Edge.org Annual Question 2015: What Do You Think About Machines That Think? [122,100 words]",https://www.reddit.com/r/MachineLearning/comments/2sqlnu/edgeorg_annual_question_2015_what_do_you_think/,DrJosh,1421508718,,4,2
212,2015-1-18,2015,1,18,8,2ss1n1,Convolutional Neural Net Question: how to determine the number of feature maps?,https://www.reddit.com/r/MachineLearning/comments/2ss1n1/convolutional_neural_net_question_how_to/,cafedude,1421536712,"I've been doing a lot of reading on Conv Nets and even some playing using Julia's Mocha.jl package (which looks a lot like Caffe, but you  can play with it in the Julia REPL). 

In a Conv net, Convolution layers are followed by ""feature map"" layers. What I'm wondering is how does one determine how many feature maps a network needs to have to solve some particular problem?  Is there any science to this or is it more art?
I can see that if you're trying to make a classification at least that last layer should have number of feature maps == number of classes (unless you've got a fully connected MLP at the top of the network, I suppose).

In my case, I 'm not doing a classification so much as trying to come up with a value for every pixel in an image - a regression (though, I suppose this could be seen as a classification where the classes are from 0 to 255). ",12,8
213,2015-1-18,2015,1,18,10,2ssfy2,Neural Networks in my hand?,https://www.reddit.com/r/MachineLearning/comments/2ssfy2/neural_networks_in_my_hand/,Smallpaul,1421544895,"Are there any consumer apps that have pre-trained or dynamically trained neural networks which run completely on a single desktop computer or smartphone? 

Related: What is the practical smallest amount of memory necessary for a useful neural network app?",12,1
214,2015-1-18,2015,1,18,17,2stgch,Boston Machine Learning Meetup Content,https://www.reddit.com/r/MachineLearning/comments/2stgch/boston_machine_learning_meetup_content/,gwulfs,1421571562,,2,12
215,2015-1-18,2015,1,18,18,2stgp4,Man vs AI: Ethics and the Future of Machines,https://www.reddit.com/r/MachineLearning/comments/2stgp4/man_vs_ai_ethics_and_the_future_of_machines/,clbam8,1421571963,,0,0
216,2015-1-18,2015,1,18,19,2stk7z,Principal Component Analysis in 3 Simple Steps,https://www.reddit.com/r/MachineLearning/comments/2stk7z/principal_component_analysis_in_3_simple_steps/,igor_subbotin,1421576255,,10,31
217,2015-1-18,2015,1,18,22,2stusl,I'm learning about Artifical Neural Networks and Deep Learning and I've tried to explain it in my words.,https://www.reddit.com/r/MachineLearning/comments/2stusl/im_learning_about_artifical_neural_networks_and/,YahooGuys,1421588174,,0,0
218,2015-1-19,2015,1,19,2,2sudlo,Am I Naive about ML and DL?,https://www.reddit.com/r/MachineLearning/comments/2sudlo/am_i_naive_about_ml_and_dl/,pulse303,1421601229,"Im really excited about the developments in ML and Deep learning in the recent years. 
I started the Ng coursera course and Im looking forward to read some books and master more MOOC courses on the topic.

My goal is to understand enough about ML and DL to find an application in the future and bootstrap an startup.

But Im starting to doubt it, it seems that the computational power that is needed and the Data sets make only feasible for well established companies. 

So my general question is, are we in ML in a similar situation like in the 2000s (dawn of the Internet) where vast CS and Web knowledge opened many opportunities for startups.

Or am I wrong in comparing those moments in history?",6,3
219,2015-1-19,2015,1,19,2,2suh54,Teaching Deep Convolutional Neural Networks to Play Go,https://www.reddit.com/r/MachineLearning/comments/2suh54/teaching_deep_convolutional_neural_networks_to/,alexeyr,1421603099,,1,30
220,2015-1-19,2015,1,19,6,2sv86m,Move Evaluation in Go Using Deep Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2sv86m/move_evaluation_in_go_using_deep_convolutional/,alexeyr,1421616922,,2,5
221,2015-1-19,2015,1,19,9,2svqta,Can't decide what problem to solve in my MS thesis (Computer vision/ML/DL),https://www.reddit.com/r/MachineLearning/comments/2svqta/cant_decide_what_problem_to_solve_in_my_ms_thesis/,mkurnikov,1421626850,"
I'd like to write thesis in ML for my MS. But I have a problem with choosing a task.  

For my Bachelors I've completed task in Document Image Categorization. Done some computer vision stuff there. 
My background: work experience with java/python, a few attempts to solve kaggle problems, Ng's course, about a half of mmds.org book, a few tutorials in deeplearning.net, a couple of stats/ML/signals/imageprocessing classes in the university. In order to enter MS program, I've written essay in image classification using ML and DL.

My first guess is to do some work in Computer Vision+ML+DL. But as far as I know, a majority of research in that field now consists of attempts to win ImageNet competition. I simply don't have enough computing resources to compete. 
Am I missing some really interesting tasks in Computer Vision? Maybe someone could point me to a really exciting problem to solve?  

And, it's also possible for me to change the field of choice. I think of the research in the sentiment analysis, but it will require a lot of work to learn nlp practically from scratch. Is it reasonable? 

P.S. this is my first post on reddit, should I crosspost it to /r/computervision ? 
P.P.S sorry for my English
",5,1
222,2015-1-19,2015,1,19,11,2sw683,How should I prepare for an onsite interview (with Google) in Machine Learning and Artificial Intelligence (software engineering)?,https://www.reddit.com/r/MachineLearning/comments/2sw683/how_should_i_prepare_for_an_onsite_interview_with/,[deleted],1421635295,"So I may get lucky enough to do some interviews in Machine Learning and Artificial Intelligence with Google for a software engineering role. I've never had interviews in those fields, but I am fortunate enough to be working with Machine Learning and NLP at my current job. I only had a CS fundamentals interviews before, but nothing in ML and AI so I am looking into what kind of material I should refresh and learn and what kinds of problems I may actually be asked onsite. The job would be some kind of a junior role in software engineering with an emphasis on ML and AI. 

A little background: I have a Masters in math with a CS minor. I never took ML or AI courses at college and I've only been learning these things at work so far. 

The things that I do know include:

* Perceptron (and the update rule)
* how to derive a support vector machine from a perceptron
* linear regression
* logistic regression
* basics of neural networks (I have yet to learn the back propagation algorithm)
* clustering methods (k-means and nearest neighbor)
* Naive Bayes 
* N-grams and how to use 3 and 2-grams to make a language model

non-ML stuff:

* Linear Algebra (specifically when a matrix is regular/singular)
* Probability and conditional probability
* My statistics is very rusty, but I could talk about distributions (but would have a hard time deriving mean and variance for a particular distribution)
* anything from CS fundamentals will be easy for me

Any feedback helps! ",20,30
223,2015-1-19,2015,1,19,19,2sxazb,This is how you can become employable in the Big Data industry,https://www.reddit.com/r/MachineLearning/comments/2sxazb/this_is_how_you_can_become_employable_in_the_big/,praptiyer,1421664508,,0,0
224,2015-1-19,2015,1,19,21,2sxj66,theano/torch7 LSTM implementation,https://www.reddit.com/r/MachineLearning/comments/2sxj66/theanotorch7_lstm_implementation/,ticcky,1421672359,"Is there a good LSTM implementation in Theano or Torch7?

I'm aware of [1] but it is very application specific. I'm looking for a library-like implementation.

[1] https://github.com/wojciechz/learning_to_execute/",4,0
225,2015-1-19,2015,1,19,22,2sxme9,Beginner advice - books,https://www.reddit.com/r/MachineLearning/comments/2sxme9/beginner_advice_books/,TelyX,1421674876,"Backstory :) I'm 16, and looking to dive right into learning Machine Learning and Artificial Intelligence. I have little prior knowledge except for the very basics that I've looked into in the last couple of weeks (starting from defining AI properly and understanding ML). But I don't intend on staying like this; I want to go deeper into the field and I need your advice on some of the best beginner - intermediate books on ML and AI. Whatever books that you have come across that you feel will help me at this point or later, that may have helped you as well. Preferably free material or ones that are affordably priced (e.g. below or between $50 - $100). But if you feel that there are some that may not fall into that range but are extremely useful books with great content, please enlighten me. I will be looking into enrolling in online courses at sites like Udacity, Coursera and Standford. But of course books are the best learning material. I am extremely appreciative for absolutely any help you provide. Thank you so much in advance!",11,0
226,2015-1-20,2015,1,20,0,2sxyto,Features for Bone Structures Classification,https://www.reddit.com/r/MachineLearning/comments/2sxyto/features_for_bone_structures_classification/,perticas_catalin,1421682790,,0,0
227,2015-1-20,2015,1,20,1,2sy204,Loading data in Torch (is a mess),https://www.reddit.com/r/MachineLearning/comments/2sy204/loading_data_in_torch_is_a_mess/,fml_zyz,1421684416,,12,10
228,2015-1-20,2015,1,20,2,2sy9vk,"Videos and Slides: Workshop on Sensing and Analysis of High-Dimensional Data (SAHD), London 2014",https://www.reddit.com/r/MachineLearning/comments/2sy9vk/videos_and_slides_workshop_on_sensing_and/,compsens,1421688106,,0,3
229,2015-1-20,2015,1,20,2,2syb25,Big Data Scoop: Mphasis partners with Aureus Analytics to provide Big Data analytics Solutions,https://www.reddit.com/r/MachineLearning/comments/2syb25/big_data_scoop_mphasis_partners_with_aureus/,ananyaswami,1421688648,,0,0
230,2015-1-20,2015,1,20,3,2symyp,Extracting text from an image using Ocropus (OCR with LSTM neural networks),https://www.reddit.com/r/MachineLearning/comments/2symyp/extracting_text_from_an_image_using_ocropus_ocr/,cypherx,1421693888,,0,10
231,2015-1-20,2015,1,20,4,2syv9p,Life after Ng's and Hinton's MOOCs,https://www.reddit.com/r/MachineLearning/comments/2syv9p/life_after_ngs_and_hintons_moocs/,elanmart,1421697396,"Hi,

I've recently finished both these popular MOOCs on Coursera. Since then I've been playing around with ML mainly using scikit-learn.

I'd like to learn more about the subject, however, and my ultimate goal is to study mostly Deep Learning
I've tried to read Murphy's text, but my math/stats skills are definitely too low.

**Now, here's my plan**:

1a.) http://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/

2a.) http://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/

3a.) http://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/

4a.) http://projects.iq.harvard.edu/stat110/home

5a.) Murphy: Machine Learning, a Probabilistic Perspective.

and  simultaneously:

1b.) Do all scikit-learn tutorials (apply to Kaggle competitions)

2b.) Do all Theano tutorials


**Once done with all the above:**

1c.) Study Deep Learning


**I've got few questions however:**

1.) Is there any point in studying from Murphy's book if I do not have solutions manual for problem sets?

2.) Is Stat 110 necessary to study Murphy's book? If not, then is it at leas helpful?

3.) Do I need to know Murphy's text if I want to do serious Deep Learning? Or it's a waste of time and I should study DL papers instead?

Thanks in advance for any tips!",11,17
232,2015-1-20,2015,1,20,5,2sz3hl,A Deep Dive into Recurrent Neural Nets,https://www.reddit.com/r/MachineLearning/comments/2sz3hl/a_deep_dive_into_recurrent_neural_nets/,Atcold,1421700880,,34,54
233,2015-1-20,2015,1,20,6,2sz9a1,Efficiently Using Generatable Data for ML,https://www.reddit.com/r/MachineLearning/comments/2sz9a1/efficiently_using_generatable_data_for_ml/,Muirbequ,1421703414,"This is coming from someone new to ML. The data I am currently working with is capable of being generated on the fly. However, the time taken to generate even a single data point is quite long since the problem is a search problem basically requiring brute force. Are there any techniques or design patterns which would be able to take advantage of this scenario? For example, to query only the most information rich data points to minimize generation time?",1,3
234,2015-1-20,2015,1,20,8,2szk8v,Coursera Machine Learning Session Now Open,https://www.reddit.com/r/MachineLearning/comments/2szk8v/coursera_machine_learning_session_now_open/,03BBx3,1421708489,"Here is the link. It was posted a few months back, so I can't post it as a link. 
https://www.coursera.org/course/ml",12,10
235,2015-1-20,2015,1,20,8,2szqn1,A clustering algorithm was (surprisingly) published in Science a while ago. Evidently its extremely effective.,https://www.reddit.com/r/MachineLearning/comments/2szqn1/a_clustering_algorithm_was_surprisingly_published/,TheCaterpillar,1421711475,,9,11
236,2015-1-20,2015,1,20,10,2t02sg,Gentleman Machine Learning Researchers?,https://www.reddit.com/r/MachineLearning/comments/2t02sg/gentleman_machine_learning_researchers/,wonkypedia,1421717536,"I have an MS with a concentration in machine learning, and have worked in various capacities in the industry for the past few years, doing machine learning and data mining. I find I'm kind of tired of it. 

It pays brilliantly, but usually it turns out i'm using very simple models that will just work, and  not really playing with data or experimenting or learning any new things on the job (except on my own time). What really excites me is nice new problems I can attack from scratch, and experiment with whatever fascinates me. 

I'm planning some time off (six months, say) to focus on some other things in my life, but i was wondering what sort of options are there for someone who wants to do some independent research.

there's a lot of data, and a lot of cheap infrastructure, and no shortage of problems. so has anyone done anything of this sort? How far have you gotten if you have? I ask because I am trying to establish some goals for myself before i take off, and was wondering about realistic plans. 

and fwiw, joining grad school is not an option for me at this point, so I'm not considering that. ",9,2
237,2015-1-20,2015,1,20,15,2t0w6z,LSTM question,https://www.reddit.com/r/MachineLearning/comments/2t0w6z/lstm_question/,[deleted],1421733703,"LSTM cells, why everyne seems to be using tanh fr input/output - why nt t use ReLU? Or even smething like mxut activation? And why sigmid for gtes, ok tht one could be becuse activation shuld be clse to 0 or 1... But have ReLU been tried?",0,1
238,2015-1-20,2015,1,20,15,2t0zxb,K-means clustering is not a free lunch (x-post /r/statistics),https://www.reddit.com/r/MachineLearning/comments/2t0zxb/kmeans_clustering_is_not_a_free_lunch_xpost/,carmichael561,1421736307,,31,67
239,2015-1-20,2015,1,20,16,2t11kq,Excellent Machine Learning Course Offered by Stanford Professor Andrew Ng Online,https://www.reddit.com/r/MachineLearning/comments/2t11kq/excellent_machine_learning_course_offered_by/,Impulse1989,1421737584,,0,1
240,2015-1-20,2015,1,20,16,2t12ea,Excellent online Machine Learning Course Offered by Stanford Professor Andrew Ng! Check out..,https://www.reddit.com/r/MachineLearning/comments/2t12ea/excellent_online_machine_learning_course_offered/,thegameCRM,1421738254,,0,1
241,2015-1-20,2015,1,20,16,2t13hj,Excellent online Machine Learning Course Offered by Stanford Professor Andrew Ng! Check out..,https://www.reddit.com/r/MachineLearning/comments/2t13hj/excellent_online_machine_learning_course_offered/,thegameCRM1,1421739141,,0,0
242,2015-1-20,2015,1,20,18,2t1b1i,Learn how to program in R and how to use R for effective data analysis with this excellent free online course,https://www.reddit.com/r/MachineLearning/comments/2t1b1i/learn_how_to_program_in_r_and_how_to_use_r_for/,thegameCRM2,1421746128,,0,0
243,2015-1-20,2015,1,20,19,2t1eni,flexo printing slotting machine,https://www.reddit.com/r/MachineLearning/comments/2t1eni/flexo_printing_slotting_machine/,ramylemon,1421749557,,0,0
244,2015-1-20,2015,1,20,20,2t1ixe,Top Five Best Uses of Laminating Machine for You,https://www.reddit.com/r/MachineLearning/comments/2t1ixe/top_five_best_uses_of_laminating_machine_for_you/,ramylemon,1421753675,,1,0
245,2015-1-20,2015,1,20,21,2t1mg8,Computers Are Learning How To Treat Cancer And Diabetes By Playing Poker And Atari,https://www.reddit.com/r/MachineLearning/comments/2t1mg8/computers_are_learning_how_to_treat_cancer_and/,[deleted],1421756950,,0,0
246,2015-1-20,2015,1,20,22,2t1rsp,LSTM question,https://www.reddit.com/r/MachineLearning/comments/2t1rsp/lstm_question/,test3545,1421761153,"LSTM cells, why everyne seems to be using tanh fr input/output - why nt t use ReLU?

And why sigmid for gtes, ok tht one could be becuse activation shuld be clse to 0 or 1... But have ReLU been tried?",3,3
247,2015-1-21,2015,1,21,1,2t26k5,Data Science Use Cases,https://www.reddit.com/r/MachineLearning/comments/2t26k5/data_science_use_cases/,vkhuc,1421769764,,0,14
248,2015-1-21,2015,1,21,2,2t2ejh,What do I need to cluster a billion tweets?,https://www.reddit.com/r/MachineLearning/comments/2t2ejh/what_do_i_need_to_cluster_a_billion_tweets/,kpotash,1421773556,"Without knowing anything about clustering, I've been using black boxes (gensim, python) which consume short sentences (tweets in this case) and cluster them. With gensim, using LSI, 50k tweets are placed in 100 clusters in roughly 4 minutes. This needs to be scaled to a billion tweets. Is this feasible, can the time be estimated, which clustering algorithm could be chosen for this task, and for that matter, where can one learn about the state of the art in clustering?",10,3
249,2015-1-21,2015,1,21,2,2t2ivb,Dr. Pig demo shows Azure ML in an unexpected place - Chinese pig farms!,https://www.reddit.com/r/MachineLearning/comments/2t2ivb/dr_pig_demo_shows_azure_ml_in_an_unexpected_place/,MLBlogTeam,1421775520,,0,1
250,2015-1-21,2015,1,21,3,2t2t0t,"Easter Egg in the General Index of Max Kuhn's Book ""Applied Predictive Modeling""",https://www.reddit.com/r/MachineLearning/comments/2t2t0t/easter_egg_in_the_general_index_of_max_kuhns_book/,Stevo15025,1421779996,,12,65
251,2015-1-21,2015,1,21,4,2t2wfd,Looking for open problems in Machine Learning / Computer Vision / Image Processing (for MS degree project),https://www.reddit.com/r/MachineLearning/comments/2t2wfd/looking_for_open_problems_in_machine_learning/,bashuk,1421781490,"Hi /r/machinelearning,

I'm new to Reddit and this is my first post, so please let me know if I'm doing anything wrong.

I'm currently working on my master's degree in applied mathematics, and I have to do a project which is somehow related to the field. Beside this limitation, I am free to do pretty much anything I want  this can be either some very abstract math research, or just a smart program, or even both. I decided to go with something related to ML (maybe computer vision or image processing), because these fields always attracted me  seems like some kind of magic.

As soon as I had made this decision, I faced two problems. First one is lack of knowledge. In the university we have a lot of math, but almost nothing related to computer science. That's why I am currently taking some ML-related courses on Coursera, and also that's how I found Reddit  it seems to be very useful source of information.

The second problem is a good topic for a project, and that's why I need your help. I don't want to spend my time doing something that is already done; I would really like to try and make something new. Something useful, something related to the fields listed above. Do you have an idea of any interesting problem that are not solved yet? Any ideas are welcome!

Also, I would be happy to get any general recommendations.",8,5
252,2015-1-21,2015,1,21,9,2t45q3,Low precision arithmetic for deep learning,https://www.reddit.com/r/MachineLearning/comments/2t45q3/low_precision_arithmetic_for_deep_learning/,jcasper,1421800868,,7,6
253,2015-1-21,2015,1,21,13,2t50jv,Die Cutting Machine Classifications,https://www.reddit.com/r/MachineLearning/comments/2t50jv/die_cutting_machine_classifications/,ramylemon,1421816118,,0,0
254,2015-1-21,2015,1,21,15,2t5bth,To research find the best aluminum cutting machine,https://www.reddit.com/r/MachineLearning/comments/2t5bth/to_research_find_the_best_aluminum_cutting_machine/,Alisonmelia,1421823210,,1,1
255,2015-1-21,2015,1,21,16,2t5d8z,Paper Bags and Plastic Bags Making Machine,https://www.reddit.com/r/MachineLearning/comments/2t5d8z/paper_bags_and_plastic_bags_making_machine/,flexispace,1421824256,,0,1
256,2015-1-21,2015,1,21,16,2t5e7w,Kernel PCA and its connections to other dimension-reduction algorithms,https://www.reddit.com/r/MachineLearning/comments/2t5e7w/kernel_pca_and_its_connections_to_other/,shriphani,1421825012,,15,3
257,2015-1-21,2015,1,21,18,2t5lm9,Cognitive Biomimicry with objects and data,https://www.reddit.com/r/MachineLearning/comments/2t5lm9/cognitive_biomimicry_with_objects_and_data/,biomimic,1421831749,,0,1
258,2015-1-21,2015,1,21,19,2t5ozk,What ever happened with the evolutionary algorithm on a FGPA?,https://www.reddit.com/r/MachineLearning/comments/2t5ozk/what_ever_happened_with_the_evolutionary/,TheFacistEye,1421835091,"I was reading up on Dr. Adrian Thompson work with a 10x10 logic gate FGPA (*Field-Programmable Gate Array*) in which he used an evolutionary algorithm to let the chip teach its self how to discern the difference between a 1kHz tone and a 10KHz tone. 

I thought it was amazing but there didn't seem to be much going on after that, what happened to that research? Has there been any new breakthroughs on that front? Any replications of his initial findings? I thought it would have been big news in the field and there would have been a bigger fuss. Was there something wrong with his implementation or did it have a limited scope for what it could do?

**Article**: http://www.damninteresting.com/on-the-origin-of-circuits/

**Paper**: http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=6691182CC83AE8577D7C44EB9D847DA1?doi=10.1.1.50.9691&amp;rep=rep1&amp;type=pdf",9,28
259,2015-1-21,2015,1,21,20,2t5tlr,[VIDEO] 'Learning Quantum Mechanics : Machines versus Humans' - An awesome talk on the future of high-performance machine learning,https://www.reddit.com/r/MachineLearning/comments/2t5tlr/video_learning_quantum_mechanics_machines_versus/,chackaz,1421839699,,0,1
260,2015-1-22,2015,1,22,2,2t6r2v,Typical Internship Salary?,https://www.reddit.com/r/MachineLearning/comments/2t6r2v/typical_internship_salary/,doki_pen,1421860105,"What is the typical internship salary for an ML Internship at Microsoft, Facebook, Google, etc.. What would be the expectation at a smaller start up compared to those companies.",7,0
261,2015-1-22,2015,1,22,4,2t79sx,Scalability! But at what COST?,https://www.reddit.com/r/MachineLearning/comments/2t79sx/scalability_but_at_what_cost/,improbabble,1421868360,,1,1
262,2015-1-22,2015,1,22,4,2t7b0h,Why isn't ICLR 2015 on OpenReview? CMT is terrible!,https://www.reddit.com/r/MachineLearning/comments/2t7b0h/why_isnt_iclr_2015_on_openreview_cmt_is_terrible/,fml_zyz,1421868872,"&gt; This year we will be using CMT's public commenting mechanism, so to participate you must log in to the ICLR 2015 CMT site:
&gt; https://cmt.research.microsoft.com/ICLR2015/Protected/PublicComment.aspx
&gt; If you don't already have a CMT account, please request one.

Does anyone know why ICLR isn't on OpenReview this year? The comments were extremely valuable on OpenReview and were visible without creating an account. I have a feeling ICLR will be a lot less visible this year to the rest of the public.

Here's ICLR 2014 page on OpenReview: http://openreview.net/venue/iclr2014
All the discussion is public and response threads are similar to Reddit which makes it easier to follow who the post is in response to.",5,3
263,2015-1-22,2015,1,22,5,2t7ezl,Lab Rat Race: an exercise in genetic algorithms [x-post /r/genetic_algorithms],https://www.reddit.com/r/MachineLearning/comments/2t7ezl/lab_rat_race_an_exercise_in_genetic_algorithms/,mbue,1421870613,,2,29
264,2015-1-22,2015,1,22,5,2t7gmm,Microsoft HoloLens - Transform your world with holograms,https://www.reddit.com/r/MachineLearning/comments/2t7gmm/microsoft_hololens_transform_your_world_with/,uzunyusuf,1421871311,,3,0
265,2015-1-22,2015,1,22,5,2t7kzt,Machine Learning Thomas Mitchell vs. Peter A. Flach,https://www.reddit.com/r/MachineLearning/comments/2t7kzt/machine_learning_thomas_mitchell_vs_peter_a_flach/,RustyJosh,1421873209,"I am wrapping up Machine Learning by Peter A. Flach and am looking for the next book I should move on to.

I have heard good things about Machine Learning by Thomas Mitchell, but  am worried it is too similar. Has anyone read both books and can offer some insight?

Thanks",1,0
266,2015-1-22,2015,1,22,8,2t8325,Using Windows for ML work environment,https://www.reddit.com/r/MachineLearning/comments/2t8325/using_windows_for_ml_work_environment/,sputknick,1421881225,"Lately I've been really impressed with what Microsoft is coming out with and considering switching from a Macbook Air to a Windows machine for my next upgrade. Anyone here do ML work on Windows? Right now I am working with python libraries, mostly in Ipython. In the near future I would like to start dabbling in Nupic. Are there any drawbacks to using Windows?",7,0
267,2015-1-22,2015,1,22,9,2t8d5r,Machine learning for facial recognition,https://www.reddit.com/r/MachineLearning/comments/2t8d5r/machine_learning_for_facial_recognition/,[deleted],1421885804,,1,0
268,2015-1-22,2015,1,22,10,2t8kyl,Machine learning for facial recognition,https://www.reddit.com/r/MachineLearning/comments/2t8kyl/machine_learning_for_facial_recognition/,efavdb,1421889448,,6,14
269,2015-1-22,2015,1,22,10,2t8lx9,"the so called ""random bits regression"" is interesting",https://www.reddit.com/r/MachineLearning/comments/2t8lx9/the_so_called_random_bits_regression_is/,happystat,1421889905,"I found this recent paper http://arxiv.org/abs/1501.02990
It is similar to Extreme Learning Machine (ELM), but with a much larger number of hidden units which leads to better and stable prediction. And the speed is impressive to me. Anyone tried that yet?",4,0
270,2015-1-22,2015,1,22,14,2t9cst,Library for Benchmarking Algorithms,https://www.reddit.com/r/MachineLearning/comments/2t9cst/library_for_benchmarking_algorithms/,Muirbequ,1421903953,"Is there any easy way of queuing various algorithms (and their parameters) for benchmarking purposes? If not, is there a package (preferably for python) that would allow me to implement this?

For example, to run various depths of neural nets and save them so that their performance can be compared, since they take longer to run than other algorithms.",0,3
271,2015-1-22,2015,1,22,15,2t9jkt,Implementing a Principal Component Analysis (PCA) in Python step by step,https://www.reddit.com/r/MachineLearning/comments/2t9jkt/implementing_a_principal_component_analysis_pca/,TacosBuenos,1421908331,,4,15
272,2015-1-22,2015,1,22,20,2ta2to,Ex-cell-o Lapping Machine Maintenance Manual,https://www.reddit.com/r/MachineLearning/comments/2ta2to/excello_lapping_machine_maintenance_manual/,industrialmanual,1421926075,,0,0
273,2015-1-22,2015,1,22,22,2tab4x,Building and deploying large-scale machine learning pipelines,https://www.reddit.com/r/MachineLearning/comments/2tab4x/building_and_deploying_largescale_machine/,pica_foices,1421933381,,0,29
274,2015-1-22,2015,1,22,23,2tadze,"Disjunctive Normal Networks -- ""state-of-the art classification accuracy and fast training times""",https://www.reddit.com/r/MachineLearning/comments/2tadze/disjunctive_normal_networks_stateofthe_art/,improbabble,1421935323,,12,14
275,2015-1-23,2015,1,23,1,2tavgm,Machine learning tools in Docker,https://www.reddit.com/r/MachineLearning/comments/2tavgm/machine_learning_tools_in_docker/,futureisdata,1421944768,,5,9
276,2015-1-23,2015,1,23,2,2tb5l7,"Building model with data, and then the same data but reversed?",https://www.reddit.com/r/MachineLearning/comments/2tb5l7/building_model_with_data_and_then_the_same_data/,nameBrandon,1421949540,"I couldn't really come up with a more clear title, so let me explain a bit. Like I'm sure many of us will do, I want to use ML to build my 2015 NCAA basketball bracket.

Let's say this is my data set..

Team1 __ Team2 __ Team1_Score __ Team2_Score __ Team1_PPG __Team2_PPG etc..

I'm going to skip the model for predicting a binary outcome as I think I have a handle on that, I'm more focused on generating a game score for each match.

So rather than having two predictors (Team1_Score and Team2_Score), I was thinking about just doubling the data set, with the 2nd half being  the first half, but reversed so that Team1=Team2 along with the scores being flipped, as well as the statistics (in this example, just points per game). This way I only have one predictor (Team1_Score, for example) and for each game I have two lines of data, one where the original Team1_Score was being predicted, and then the flipped/reversed line of data where Team1 and Team2 swap places. 

Does this make sense, or has anyone done this? I think it may depend on the algorithm used as to how well it works out (the initial plan is SVM), but I'm just curious. I've just about got the data I need in one place, so I planned on trying it out anyways, but thought I'd check in here first and see what the general feeling was around doing this.

",6,2
277,2015-1-23,2015,1,23,4,2tbi6m,Numerical linear algebra/ML projects,https://www.reddit.com/r/MachineLearning/comments/2tbi6m/numerical_linear_algebraml_projects/,poundcakejumpsuit,1421955238,"I have a few months to learn something cool. I'm pretty decent at MATLAB and NLA, is there a cool idea I should look into to build? It can be something ambitious, I've been looking at rank selection and some spectral stuff, but I'm not married to either.",3,3
278,2015-1-23,2015,1,23,7,2tc8bx,Mixed messages from Deepmind?,https://www.reddit.com/r/MachineLearning/comments/2tc8bx/mixed_messages_from_deepmind/,RushAndAPush,1421966842,"Hi. Since this subreddit is comprised of Machine Learning experts I thought I would bring up some of the mixed messages about progress in the future regarding AI. 

However, in this [video](https://www.youtube.com/watch?v=2WIk1B1eZiE), Shane Legg (Who has always been pretty optimistic) appears to have not changed his opinion on when AI will come about, judging my the peoples reaction.

In the article [The Deep Mind of Demis Hassabis](https://medium.com/backchannel/the-deep-mind-of-demis-hassabis-156112890d8a), he claims its possible that AI could become dangerous within 5 - 10 years. 

But when I read this [article](http://edge.org/response-detail/26258) it seemed to have have a slightly less optimistic tone. 

Example below:

&gt; ""While difficult, we think these problems can be overcome, but that it will take a generation of talented researchers equipped with plentiful computational resources and inspired by insights from machine learning and systems neuroscience. While this is likely to disappoint the most optimistic observers, it will give this community some time to come to grips with the many subtle safety and ethical questions that will arise.""

Am I over-thinking this or is there a legitimate gulf between what they tell the media and what they really believe?  ",34,9
279,2015-1-23,2015,1,23,11,2tcxgh,"Suggestion for MS in ML or a related course (IR, DM/TM) at an European university. Which ones are known the filed?",https://www.reddit.com/r/MachineLearning/comments/2tcxgh/suggestion_for_ms_in_ml_or_a_related_course_ir/,[deleted],1421979072,"I want to do my MS in ML (information retrieval; text mining being my other core interests) from Europe. Which ones are better ones in machine learning.

I may not get into an A+ tier university (or let's just say the ranked ones; I was rejected from both ETH and EPFL last year) as my profile is not A+ I reckon. But I would still like to know such options. 

I am willing to take a loan if the job prospects are decent in that country. But as of now I am just looking for information on good universities in this field and I'll worry about monetary arrangements later.


**PS**. I would probably not apply to a university which has a high GRE requirement as I have a meagrely 149/170 in Verbal (Quant: 168/170) from last year and I am afraid I am not willing to take that (pointless *imho*) test again. 

One of the reasons why I don't want to try for North America besides I am really fascinated by European culture and landscape since I was a kid (but this maybe beside the point). 

I had tried *Erasmus Mundus* last year and had gotten into all the programmes I had applied to except one. But I didn't win the scholarship at any university (maybe my work exp. and they assumed I have the money, or simply I was outdone by others) and those universities were not as good (ranking 300-500 usually) where a huge education loan would make any sense.",11,3
280,2015-1-23,2015,1,23,12,2td39u,"Training a neural network on a ""baby"" or ""developmental"" dataset before exposing it to ""real"" training set?",https://www.reddit.com/r/MachineLearning/comments/2td39u/training_a_neural_network_on_a_baby_or/,TissueReligion,1421982113,"BACK IN MY DAY, human babies weren't expected to tie the image of an elephant to the text for an elephant until they'd already had several years of associating elephants to emotions, and sounds, and big curly red letter E's before learning the text.

Are there interesting papers you guys know of where people start the initial training of their datasets on ""easy"" data (think sesame street), but avoid overtraining?",16,1
281,2015-1-23,2015,1,23,12,2td691,Are autoencoders used for compression?,https://www.reddit.com/r/MachineLearning/comments/2td691/are_autoencoders_used_for_compression/,strayadvice,1421983667,"I'd imagine autoencoders, single-layered or multi-layered, could be used for compression if noisy reconstruction is not an issue. Are they commonly used for compression though? Why or why not?",14,8
282,2015-1-23,2015,1,23,15,2tdo6m,Processing data with neural network.,https://www.reddit.com/r/MachineLearning/comments/2tdo6m/processing_data_with_neural_network/,Ammaro,1421994172,"I have created a neural network implementation in Java. I have tested it against simple problems like xor, and it works. Now, I want to test it against real datasets like iris, etc. My problem is I don't know how to make a general puropse input processor for my implementation. 

My current implementation of the neural network has the following  signature:
    float[] feedforward(float []input_data)
where every element in input_data is an input attribute in a data set and every element of the input_data should be between 0 and 1.
It returns the output of the neural network, which is also between 0 and 1.

Does anybody knows a java library that is able to process different data types and give returns values between 0 and 1, so I can feed it to my network? 

PS: English is not my first language, so sorry for grammar and spelling.",8,0
283,2015-1-23,2015,1,23,19,2te5rt,Buy Best Quality Grinding Polishing Machine,https://www.reddit.com/r/MachineLearning/comments/2te5rt/buy_best_quality_grinding_polishing_machine/,AptexWeb,1422010390,,1,0
284,2015-1-23,2015,1,23,20,2te844,Is missing data actually missing?,https://www.reddit.com/r/MachineLearning/comments/2te844/is_missing_data_actually_missing/,[deleted],1422012737,,0,1
285,2015-1-23,2015,1,23,21,2ted86,Text feature extraction (tf-idf)  Part I,https://www.reddit.com/r/MachineLearning/comments/2ted86/text_feature_extraction_tfidf_part_i/,perone,1422017392,,5,10
286,2015-1-23,2015,1,23,22,2tee05,When is missing data a valid state?,https://www.reddit.com/r/MachineLearning/comments/2tee05/when_is_missing_data_a_valid_state/,chocogato,1422018036,,1,4
287,2015-1-24,2015,1,24,1,2tezj5,"Microsoft to acquire Revolution Analytics, a leading provider of software and services for R",https://www.reddit.com/r/MachineLearning/comments/2tezj5/microsoft_to_acquire_revolution_analytics_a/,MLBlogTeam,1422030644,,0,0
288,2015-1-24,2015,1,24,2,2tf84f,NVIDIA CES 2015 press conference: Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2tf84f/nvidia_ces_2015_press_conference_deep_learning/,pateras,1422034746,,0,16
289,2015-1-24,2015,1,24,10,2tgy5c,Reading club: Neural Machine Translation by Jointly Learning to Align and Translate (mlpapers xpost),https://www.reddit.com/r/MachineLearning/comments/2tgy5c/reading_club_neural_machine_translation_by/,Mylos,1422063747,,0,8
290,2015-1-24,2015,1,24,10,2tgyln,Prototype Machine Learning and Natural Language Processing Code With Us - (Sign Up),https://www.reddit.com/r/MachineLearning/comments/2tgyln/prototype_machine_learning_and_natural_language/,mercurialkitten,1422064008,,2,20
291,2015-1-24,2015,1,24,13,2thdk1,Data Elixir #19: What Do You Think About Machines That Think?,https://www.reddit.com/r/MachineLearning/comments/2thdk1/data_elixir_19_what_do_you_think_about_machines/,lonriesberg,1422072727,,0,0
292,2015-1-24,2015,1,24,18,2ti1dl,Computational Theory of Mind (CTM),https://www.reddit.com/r/MachineLearning/comments/2ti1dl/computational_theory_of_mind_ctm/,biomimic,1422091792,,13,10
293,2015-1-24,2015,1,24,18,2ti2k7,System and method for summarizing search results,https://www.reddit.com/r/MachineLearning/comments/2ti2k7/system_and_method_for_summarizing_search_results/,[deleted],1422093243,,0,1
294,2015-1-24,2015,1,24,19,2ti39c,System and method for generating a relationship network,https://www.reddit.com/r/MachineLearning/comments/2ti39c/system_and_method_for_generating_a_relationship/,biomimic,1422094032,,0,0
295,2015-1-24,2015,1,24,23,2tiixb,Would it be possible to analyse text on the political spectrum using machine learning?,https://www.reddit.com/r/MachineLearning/comments/2tiixb/would_it_be_possible_to_analyse_text_on_the/,Ajnin123,1422110149,"Hi all,  
I'm quite new to this concept of machine learning, but I was just curious (as mentioned in the title) if you could use human feedback and prebuilt mechanisms (like those in http://www.politicalcompass.org/) to detect where on the political spectrum you could place text. This could have a wide range of uses, for example analysing peoples speeches, analysing the media, or generally analysing textual based data. Would anyone know where I could do further research into this?  
Thanks,  
Aj.

EDIT: An interesting read on [political spectrum analysis](https://en.wikipedia.org/wiki/Political_spectrum)",10,0
296,2015-1-24,2015,1,24,23,2tijr4,non-image recognition machine learning,https://www.reddit.com/r/MachineLearning/comments/2tijr4/nonimage_recognition_machine_learning/,jstrong,1422110794,"Machine learning is a new field for me, and I've been diving into it and trying a lot of the algorithms in Python. One thing I've noticed is that the majority of articles here and elsewhere in describing techniques (especially neural networks) are about classifying images. 

In Andrew Ng's Coursera course, in describing situations where a huge amount of data might boost accuracy, he divides machine learning problems into two categories with the question: would a human be able to readily understand the answer from the data? To broaden my point, it seems like most the articles I read are about situations where it's very easy for a human to give the answer for the data, but the problem is getting a computer to automate it. 

My question today is: I'm interested in problems that are not readily answerable for a human looking at the data: namely predicting human behavior (choices) from data about their previous choices. Are there any resources more tailored to that problem domain? Are there approaches that work better in situations like that? I know state of the art accuracy for image classification is 6 percent error rate. What's state of the art accuracy for whether someone will buy something, how they'll vote, etc? Are there algorithms better suited to ""complex"" problems? 

Thanks for any insight you can provide! ",29,10
297,2015-1-25,2015,1,25,4,2tjbax,Career transition advice needed.,https://www.reddit.com/r/MachineLearning/comments/2tjbax/career_transition_advice_needed/,totolipton,1422126031,"Hi everyone. I am currently in the process of finding a new career and am in need of some advice. A little bit about myself: about 6 month ago I graduated with a PhD in applied math doing research in Ocean acoustic. Upon graduation I immediately found a job doing ocean acoustic research in a government lab. As a PhD student, I was already tired of my graduate research, and this job just proved that I did not enjoy the field of ocean acoustic research. I became interested in the field of machine learning and would like to make a career transition. 

I would say my programming ability is equivalent someone with a bachelor in CS but no industrial experience. I used mostly Matlab for my research. I learned some basic c++, python, java in my spare time, and used swift to write 2 apps on the apple app store. I learned some theory about Genetic algorithm, feed forward neural network, and some unsupervised learning technique such as self-organizing map, Isotop, t-sne.  My ideal job would be a research position in companies such as google or facebook, or companies that uses machine learning method for financial applications/other interesting applications. 

My question to you is the following: In your opinion, 

1. what skills do you think Im lacking, and in what order should I focus my time on acquiring them? 

2. If you were a recruiter, how would you view someone who came from the field of applied mathematics? 

3. Do you have any advice for me in my new job search? Any comment would be appreciated.

Thanks.


Edit: Thanks guy I have to say now I'm convinced this is a very hot field. Just a day after this post I already got several request for CVs. Thanks for all your input.
",8,2
298,2015-1-25,2015,1,25,6,2tjwqi,A bunch of new machine learning resources,https://www.reddit.com/r/MachineLearning/comments/2tjwqi/a_bunch_of_new_machine_learning_resources/,vincentg64,1422136595,,0,2
299,2015-1-25,2015,1,25,22,2tm006,Artificial Intelligence Machines,https://www.reddit.com/r/MachineLearning/comments/2tm006/artificial_intelligence_machines/,airoboty,1422191417,,0,1
300,2015-1-26,2015,1,26,2,2tmqi0,possible to have a working and useful neural net ten hours from now and how?,https://www.reddit.com/r/MachineLearning/comments/2tmqi0/possible_to_have_a_working_and_useful_neural_net/,programmerish,1422208615,"i guess im just wondering whats the most practical way to start tinkering with machine learning in a way that can be immediately useful, doesn't have to be limited to neural nets


edit: this is a related, but definitely not identical post
http://www.reddit.com/r/MachineLearning/comments/1aqcrh/best_ml_package_in_python/",13,0
301,2015-1-26,2015,1,26,6,2tnisq,"Analysing CPU load, Network activity etc.",https://www.reddit.com/r/MachineLearning/comments/2tnisq/analysing_cpu_load_network_activity_etc/,alexgmcm,1422222042,"I'm currently interested in unsupervised anomaly-detection and data visualisation for time-series data.

As I'm particularly interested in applications to CPU loads and network traffic I realised that I could get good practice (and fun data and insights into myself) by gathering data from my own computer.

This would include the CPU load, bandwidth usage etc. with respect to time.

I found [RRDTool](http://oss.oetiker.ch/rrdtool/index.en.html) as an interesting way to store the data and access it and with some more digging I found [this list](http://www.thegeekstuff.com/2011/12/linux-performance-monitoring-tools/) which is ideal for me as a linux user.

Does anyone know any other tools?

Also any advice on sequential unsupervised anomaly detection would be greatly appreciated. I am currently reading the anomaly-based intrusion detection literature as it is a similar problem.

In terms of the problem I am actually aiming to solve although I may be able to get a labelled dataset but then as it is just ""normal"" data and ""problematic"" data (i.e. when the system had problems) it is hard to see how useful this would be as one can assume the statistical properties of the ""normal"" data would be similar (i.e. it would form one cluster), but the problematic data could have many, many different classes of problems (and potentially novel ones could appear during the online analysis) and so really I can only look for times when the data is _not_ like the normal data rather than when it is similar to the problematic one?

I suppose I could train an autoencoder on the normal data and then use the reconstruction error as an indicator of how normal the data is - but I have no idea how efficient or even feasible that is, I'm worried I've just been reading too much about neural nets and thus everything starts to look like a nail for my neural net hammer.",1,3
302,2015-1-26,2015,1,26,8,2tnvnw,What do you dislike about your machine learning job?,https://www.reddit.com/r/MachineLearning/comments/2tnvnw/what_do_you_dislike_about_your_machine_learning/,elamo,1422228240,"Machine learning and related work sounds very interesting from an outside perspective. I've read some posts on this sub and watched a few lectures from Coursera, but I know that I still don't know much. 

So... what about your job or experiences have you not liked? What are the issues with getting into the field? The people? The places? The money? Variability? I'm curious to hear any and all gripes. ",57,67
303,2015-1-26,2015,1,26,11,2tohl7,Where can i find videos of NIPS2014,https://www.reddit.com/r/MachineLearning/comments/2tohl7/where_can_i_find_videos_of_nips2014/,matrix2596,1422239424,"Hi, I was able to find videos of some NIPS 2013 conference but can onyone help me find videos of [NIPS 2014](http://nips.cc/Conferences/2014/)
",2,12
304,2015-1-26,2015,1,26,12,2toq59,best independent way to monetize machine learning skill other than kaggle?,https://www.reddit.com/r/MachineLearning/comments/2toq59/best_independent_way_to_monetize_machine_learning/,theGameGamer,1422244053,"excluding for example, all jobs and freelance opportunities",9,0
305,2015-1-26,2015,1,26,14,2tp28f,Any advice on how to prevent overfitting with h2o deep learning?,https://www.reddit.com/r/MachineLearning/comments/2tp28f/any_advice_on_how_to_prevent_overfitting_with_h2o/,tjorriemorrie,1422251260,"This is what I have: [image](http://imgur.com/nHUunYO) It's really silly how that gets to 0% error. I am very new to deep learning and h2o, and was wondering if any advice can be given on how prevent this from happening.",8,0
306,2015-1-26,2015,1,26,19,2tpj2f,Java online timeseries forecast algorithm and library,https://www.reddit.com/r/MachineLearning/comments/2tpj2f/java_online_timeseries_forecast_algorithm_and/,[deleted],1422267203,"As a machine learning beginner, i want to know, are there any Java online timeseries forecast algorithm and librarys? thanks.",0,1
307,2015-1-26,2015,1,26,22,2tpw33,ML using SVM when features are mixed of string and integer values.,https://www.reddit.com/r/MachineLearning/comments/2tpw33/ml_using_svm_when_features_are_mixed_of_string/,ashmish2,1422279793,"I am doing some research analysis of the data which is mix of some string values and integer. I want to know general ways of using them together and normalizing the data. 

[Edit]
Just to give example. DNS has TTL (integer), domain name (string) etc. Now it can be used together for some purpose with SVM classification. Idea is there can be case where you end up having feature that are not of same data type. I am wondering what are the approaches take in that case. ",8,2
308,2015-1-27,2015,1,27,1,2tqc0g,Which MOOC? Andrew Ng on Coursera or StatLearning on Stanford online?,https://www.reddit.com/r/MachineLearning/comments/2tqc0g/which_mooc_andrew_ng_on_coursera_or_statlearning/,wodenokoto,1422288723,"Which MOOC do you guys recommend I follow?

Statistical Learning using R on Standord online (https://statlearning.class.stanford.edu/)

Or Andrew Ng machine learning course on Coursera (https://class.coursera.org/ml-008) using Matlab

I have both R and Matlab on my machine, but I don't really have any experience in them, though I have some experience using Python and sklearn for machine learning.

Both started a week ago, but are only at linear regression, so it is not too late to jump on board :)
",11,13
309,2015-1-27,2015,1,27,1,2tqh28,Visualizing DBSCAN Clustering,https://www.reddit.com/r/MachineLearning/comments/2tqh28/visualizing_dbscan_clustering/,naftaliharris,1422291103,,0,13
310,2015-1-27,2015,1,27,2,2tqp4f,How to Hire Your First Data Scientist,https://www.reddit.com/r/MachineLearning/comments/2tqp4f/how_to_hire_your_first_data_scientist/,yseam,1422294702,"So our company, yseam.com does a lot of contracting work for various companies involving data science and machine learning. A lot of our team is still on tons of headhunter mailing lists and recruiter emails. Within the last few weeks, we have gotten a ton of calls about positions saying ""need PhD in Data Science and must use SPSS, SAS, etc"" in said positions. Not sure it's really their fault, so we wrote this primer for hiring managers on how to hire the first Data Scientist at any company. Hope this falls within the realm of an acceptable post. If not, I apologize. link: http://www.yseam.com/blog/RS.html",26,34
311,2015-1-27,2015,1,27,4,2tr588,Beginner question: Disjoint outcomes in multiple-entry competitions,https://www.reddit.com/r/MachineLearning/comments/2tr588/beginner_question_disjoint_outcomes_in/,cubby13579,1422301627,"Hi everyone,

I'm working on a problem such that there is a winner in a competition, and I'd like to determine the probability of each outcome.  However, there are more than 2 entries (there CAN be, I suppose).  My questions is, how does one adjust probabilities in such an event so that the probabilities sum to one?  Or can we disregard the constraint and chalk it up to error?

A flat answer to the question would be welcomed, but I'd also love to see the topic discussed in some depth if there is an article or link that would relate.  I have a relatively strong background in math and statistics, however I am just discovering machine learning.

Thanks!",2,0
312,2015-1-27,2015,1,27,6,2trnxg,Why are machine learning startups bought?,https://www.reddit.com/r/MachineLearning/comments/2trnxg/why_are_machine_learning_startups_bought/,[deleted],1422309537,"Countless startups with a focus on ML have been bought over the past few years, do you know in which proportions the following is the case?

- talent acquisition (a.k.a., 'acquihire')
- patent acquisition (the startup had desirable ML patents)
- customer/user base acquisition

ETA: of course, in most cases, it would be a mix of factors.",11,0
313,2015-1-27,2015,1,27,7,2trpzh,What makes a good training set?,https://www.reddit.com/r/MachineLearning/comments/2trpzh/what_makes_a_good_training_set/,seymour1_research,1422310415,"Hey all, long time lurker, first time poster.

I just finished a MS with a focus in Machine Learning, and one of the things I learned in my thesis research is that this field has a lot of people grabbing data from private sources, but nobody shares it with others due to profit incentives. As a result, I've seen lots of overgeneralization, comparisons of algorithms from different distributions, etc. etc.

For my Ph.D. research, I'd like to create a good dataset with measurable qualities for academic researchers in my field. I have some ideas for qualities that are good- e.g. diversity, representivity, and correct labels, and I have ways to measure those qualities, but:

* Are there any papers on the more abstract question of what makes a good dataset for general ML research?

* If you could have any dataset for training you wanted in your field, what qualities would it have?",5,4
314,2015-1-27,2015,1,27,9,2tsbia,Optimizing neural networks for word vectors on GPU,https://www.reddit.com/r/MachineLearning/comments/2tsbia/optimizing_neural_networks_for_word_vectors_on_gpu/,tetramarek,1422320299,"I've implemented some neural nets for text processing and got them running on a GPU. Now, while the actual matrix multiplication part is much faster, my overall implementation is actually a bit slower on the GPU than CPU. This seems to be because of how I handle the input layer.

The input consists of several words. Each word is represented as a vector, and they are all optimized during the training. I can think of two options for handling this:

1. Represent each input word as a V-dimensional vector (V being the vocabulary size), full of zeros, with a 1 in the correct position, and multiply this with the matrix of word vectors. This will get the correct vector from the matrix. The GPU is optimized for matrix multiplications, but because the word vector matrix is 100000x200, it is still a massive multiplication for just one word.

2. Read the vector directly from the matrix and copy it into the input layer. This is what I'm doing now, but it's very slow. Probably because it doesn't make use of the GPU capabilities, and actually has to copy values from the GPU to CPU and then back.

I think I'm starting to understand why everyone in image recognition is using GPUs, but not so much going on in NLP. While there's a limited number of pixels with real values, words form a very large pool of discrete features, and it seems harder to efficiently fit that on a GPU. 

Has anyone found a good way of handling this? ",7,4
315,2015-1-27,2015,1,27,13,2tsykn,So you want to build a data science team?,https://www.reddit.com/r/MachineLearning/comments/2tsykn/so_you_want_to_build_a_data_science_team/,cheetooos,1422331455,,0,0
316,2015-1-27,2015,1,27,14,2tt5xq,"Next.ML Boston Machine Learning Workshops &amp; Case Studies / Microsoft NERD Center / April 27, 2015",https://www.reddit.com/r/MachineLearning/comments/2tt5xq/nextml_boston_machine_learning_workshops_case/,[deleted],1422335504,,0,7
317,2015-1-27,2015,1,27,17,2ttmvw,How do you guys choose the appropriate ML algorithm?,https://www.reddit.com/r/MachineLearning/comments/2ttmvw/how_do_you_guys_choose_the_appropriate_ml/,selectorate_theory,1422347635,"I've just taken a grad-level ML course, in which we discussed a whole bunches of method. We talk about which method is good in which theoretical scenarios (e.g. a radial kernel is good when data is not linearly separable but arranged in rings).

But how on Earth do we choose ML algorithm in real scenarios, when we do not know the true data generating process? Everyone says ""get to know your data"", but in high-dimensional data what exactly does this mean? For example, in 2-D I can plot my data to see if it's linearly separable, but not in higher dimension.

When I asked my prof about this (e.g. choosing algorithm, tuning parameters, kernel, etc.) the answer is ""cross validation."" However, doesn't this mean that our choice of tuning parameters and is being ""overfitted"" to the test set? How do we know that this choice of parameters and kernel will perform well given future data?",21,12
318,2015-1-27,2015,1,27,17,2ttmww,Kaggle | Reviewing the American Epilepsy Society Seizure Prediction Challenge,https://www.reddit.com/r/MachineLearning/comments/2ttmww/kaggle_reviewing_the_american_epilepsy_society/,clbam8,1422347669,,1,30
319,2015-1-27,2015,1,27,17,2ttn63,Datatau: Machine Learning news,https://www.reddit.com/r/MachineLearning/comments/2ttn63/datatau_machine_learning_news/,biomimic,1422347902,,0,4
320,2015-1-27,2015,1,27,18,2ttq4g,Recurrent Generative Adversarial Networks?,https://www.reddit.com/r/MachineLearning/comments/2ttq4g/recurrent_generative_adversarial_networks/,CreativePunch,1422350748,"Hi all,

I have read and implemented the following paper about Generative Adversarial Networks: http://arxiv.org/abs/1406.2661

Though I have been trying to apply the same technique using LSTM units on a temporal dataset having not so much success so far.

Using LSTM as both discriminator and generator I notice that the discriminator probably collapses too fast to a solution, the generator does not seem to move away from random noise at all. I have tried many different amounts of hidden units ranging from ridiculously small to ridiculously many.

So has any research been done by anyone else in this area or does anyone have any suggestions that could push me in the right direction?

Thanks!",7,4
321,2015-1-27,2015,1,27,18,2ttqzm,Basic Speech Recognition using MFCC and HMM,https://www.reddit.com/r/MachineLearning/comments/2ttqzm/basic_speech_recognition_using_mfcc_and_hmm/,obsoletelearner,1422351588,"This may a bit trivial to most of you reading this but please bear with me. I read many articles on this but i just do not understand how i have to proceed. 


I'm trying to build a basic Speech recognition system using the MFCC features to the HMM , I'm using the data available [here](https://dl.dropboxusercontent.com/u/15378192/audio.tar.gz). I'm using Matlab to do this. 

So far i have extracted the MFCC vectors from the speech files using [this library](http://labrosa.ee.columbia.edu/matlab/rastamat/). What i do not i understand is how do i use these features for HMM.


Can you please explain how do i train the HMM. I'm using the hmm implementation found in matlab. Please do not refer me to other libraries as i am actually trying to understand how hmm's work.

- How do i initialize the transition and emission matrices? 

- I'm supposing each state emits a particular phoneme in the word, So to train the HMM how are we supposed to pass the MFCC vectors? 


- What are the steps i should take to train the HMM? 


The matlab implementation functions of the HMM are given [here](http://in.mathworks.com/help/stats/hidden-markov-models-hmm.html?searchHighlight=HMM#f8261)",18,4
322,2015-1-27,2015,1,27,18,2ttr16,error bounds on performance metric with scikit-learn,https://www.reddit.com/r/MachineLearning/comments/2ttr16/error_bounds_on_performance_metric_with/,pl47,1422351631,"Hi All,


I would like to calculate error bounds on the performance metric for a regression problem.  

So say that I've trained BDT and RF and I apply it to my test set and RF give me MSE = 0.34222 and BDT gives me a MSE = 0.34122  

I would like to have error bars on the MSE estimates so I can get some idea of how significant one method works better than another. So i'm looking to a bootstrap/jack-knife/CV error estimate on the performance metric. I've been digging in the documentation but with no luck.  And I think I remember once seeing something like that in some Notebook. 

If not I'll have to write it myself. Any help is much appreciated. 

  ",2,2
323,2015-1-27,2015,1,27,22,2tu53k,Update with 408 recent papers to Deeplearning.University,https://www.reddit.com/r/MachineLearning/comments/2tu53k/update_with_408_recent_papers_to/,atveit,1422364468,,0,0
324,2015-1-27,2015,1,27,23,2tu980,"I just turned down a book offer to write ""adaptive systems"" - uncommon story inside",https://www.reddit.com/r/MachineLearning/comments/2tu980/i_just_turned_down_a_book_offer_to_write_adaptive/,LMR_adrian,1422367370,"*I'm an adaptive systems consultant (machine learning, data science, adaptive structures - that sort of thing), and I work almost exclusively for small startup companies trying to establish a product; think ""we want to make an app that predicts when my flight will actually board, and we need someone to do the machine learning part for us"".*

Two months ago I was contacted by a fairly large tech publisher; I had a few of their books already so I definitely took notice when I got the first email in my inbox. I was *so* sure that it was one of my friends just yanking my chain with a 10$ domain purchase and a fake email account, that my initial reply was very sterile, and only questioned where the referral came from, then why they were reaching out to me.

*For a little more background, I have a high school diploma and about a decade of work experience - I don't write papers or books, I don't do conferences, I don't blog - I don't even have facebook or twitter. If it wasn't for this reddit account to share development about a side game project, I pretty much wouldn't even exist on the internet other than by word of mouth.*

After a couple more emails they sent me an account for their publishing website with elevated credentials to read some of their other books for free (obviously seems legit at this point), and asked to set up a call. Finally I get someone on the phone and eventually find out: ""we have someone on staff who does nothing but find interesting people to write books, so congratulations you are interesting!"". Some used car salesmanship and invasive questions later - and someone apparently found my stack overflow account which led to my email address.

Within a few more minutes we were talking about a book index, advances, a formal proposal, timelines, contracts and target audiences. Having *never* so much as considered writing a book before, I was very much in the dark to all the numbers and standard practices involved. We scheduled a second call after I had some time to do a lot of googling.

**Tech book authors make on average between $1000-$25000 depending on a lot of factors - which is paid out over one year to three years, equating to virtually slave labour wages. So you probably wouldn't want to write a book for the money. In a nutshell it's an ongoing battle for tech publishers to find someone to write high quality books for them, for what is basically no pay. Books apparently make a great business card: ""oh yeah I wrote the book on it!"", but with no shortage of work, and no surplus of time I politely turned the offer down.**

I've never actually heard of my particular situation happening before - but then I'm not at all active in the community, so then who could I have heard it from? 

**So /r/MachineLearning... has this ever happened to anyone else, and what did you do?** I'm still not entirely sure what to make of it all, other than being pretty flattered - and getting into some pretty interesting conversations with a publisher.",6,9
325,2015-1-27,2015,1,27,23,2tu9ct,Don't use Bandit Algorithms - they probably won't work for you,https://www.reddit.com/r/MachineLearning/comments/2tu9ct/dont_use_bandit_algorithms_they_probably_wont/,stucchio,1422367466,,2,20
326,2015-1-27,2015,1,27,23,2tubxz,The Landscape of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2tubxz/the_landscape_of_deep_learning/,[deleted],1422369028,,0,8
327,2015-1-27,2015,1,27,23,2tuc1j,How to build a Content based Image Retrieval engine using Imagenet features,https://www.reddit.com/r/MachineLearning/comments/2tuc1j/how_to_build_a_content_based_image_retrieval/,shuggiefisher,1422369103,,0,0
328,2015-1-28,2015,1,28,0,2tuizc,How to Build a Predictive Model using Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2tuizc/how_to_build_a_predictive_model_using_azure/,futureisdata,1422372744,,0,0
329,2015-1-28,2015,1,28,0,2tujab,Forecasting beer consumption with sklearn,https://www.reddit.com/r/MachineLearning/comments/2tujab/forecasting_beer_consumption_with_sklearn/,cavedave,1422372895,,0,1
330,2015-1-28,2015,1,28,2,2tv0fc,Non-CS background to ML jobs?,https://www.reddit.com/r/MachineLearning/comments/2tv0fc/noncs_background_to_ml_jobs/,gfe44,1422380571,"Hi, I'm currently a sophomore studying engineering physics / applied physics. I've done mostly computational work so far (intern over the summer and work with a professor on computational astrophysics), and I'm interested in potentially going into an ML jobs and/or graduate school for CS. I've taken some core CS classes, i.e. data structures, algorithms, etc. I have a pretty strong math background from all the physics classes as well. I can't really switch majors to CS since I'm pretty deep into the major, however, I do have a decent amount of flexibility in the remainder of the major. I wanted to know if there were any non-CS people who broke into ML jobs. Lastly, if I do apply to ML graduate school, will my lack of a CS background hurt? For ML, is the CS part more important than the math?",8,0
331,2015-1-28,2015,1,28,3,2tv82e,English version of Cauchy's Gradient Descent paper,https://www.reddit.com/r/MachineLearning/comments/2tv82e/english_version_of_cauchys_gradient_descent_paper/,tttthomasssss,1422383755,"I'm looking for an english translation of Cauchy's original Gradient Descent paper (""Mthode gnrale pour la rsolution des systmes d'quations simultanes""). 

Has anyone come across a translation of this paper?",1,0
332,2015-1-28,2015,1,28,4,2tvjv2,Providence: Machine Learning At Stack Exchange,https://www.reddit.com/r/MachineLearning/comments/2tvjv2/providence_machine_learning_at_stack_exchange/,burntorangestartup,1422388674,,0,33
333,2015-1-28,2015,1,28,9,2twow4,"BigML 2015 Winter Release and Webinar: Sample Service, G-means, Projects, Labs and More!",https://www.reddit.com/r/MachineLearning/comments/2twow4/bigml_2015_winter_release_and_webinar_sample/,czuriaga,1422406366,,0,1
334,2015-1-28,2015,1,28,10,2twsys,Need help thinking up a Masters Project,https://www.reddit.com/r/MachineLearning/comments/2twsys/need_help_thinking_up_a_masters_project/,datshitberacyst,1422408239,"Hi Guys!

I'm currently a graduate student, and I've just been given a (semi) free license by my advisor to come up with a project involving apache mahout and machine learning. I'm looking to you guys in hopes that you might have some ideas for features that are lacking in mahout that I could implement for my project.

I have a some amount of experience in text mining, and an extensive amount of big data experience.

Thank you for your help!!",11,2
335,2015-1-28,2015,1,28,15,2txrzh,Question: What type of neural network is suitable for simulating brain of virtual organism?,https://www.reddit.com/r/MachineLearning/comments/2txrzh/question_what_type_of_neural_network_is_suitable/,Maximus-CZ,1422426467,"A while ago I was experimenting with evolving virtual creatures using neural network + genetic algorithm, but that didnt go well (simulation speed was too slow, mainly because bad programming habbits of creatures, not neural network). I used Feedforward neural network and now I can see it isnt exactly right choice for this kind of application (creatures have no memory, etc.)

I would like to try again, start from scratch, and I would like to perform better than before. However, I dont know what neural network architecture to select.

The task for is to surive. I dont have any objective aside than observing interesting patterns of behaviour that can evolve. Basically I would like to ""seed"" the world with some properties with creatures that can exploit those (food, temperature, danger) and such. Everything very basically modeled, in flat 2D.

What I need (each part is actually question):

* Possibility of memory: Should I study more about memory cells, or is using correct NN architecture (like Reccurent NN) enough? What will be main differencies?
* Possibility of mutations: I would like to not only mutate weihts in network, but also possibility of adding weights / neurons into ""black box"". I plan to use genetic algorithm, so cross mutations + random mutations.
* Easy programming: I plan on not using any assets and to write my NN from ground in order to learn. I would preffer more easy neural networks than others. (While Im writing this, I realize there might not be difference)



What I dont need:

* Quick computation: I think that 90% of CPU time will be used on other things of controling my creatures, than on computing NN. (as I am terrible programmer)
* Training: I will use genetic algorithm to train, so I dont need typical training methods to train NN. I can use types of NN where training part is very CPU intense, as I will drop this part out.




I am looking at possible types of NN and I think some type of Recurrent network would be suitable, but cant really pick a winner, since I only ever worked with Feedforward type, and I will need to learn about the type you will reccomend before I start writing it. I would like to learn just the one you will suggest instead of learn pros/cons of all, since I think It would set me back for too long.


Question is: What is the type of NN that you think would suit this best?",7,0
336,2015-1-28,2015,1,28,16,2txyge,Finding songs from a web page,https://www.reddit.com/r/MachineLearning/comments/2txyge/finding_songs_from_a_web_page/,izumiandrew1,1422431394,"Hi Guys

I am hoping this is the right subreddit to ask such a question. I want to make a chrome extension that can take any website which has a list of songs, identify the songs and artists, and make a playlist out of them. For this, I am looking for some library that given a webpage or some data, gives back a list of songs-artist pairs.

This is a long shot but hoping someone knows the answer to this. Thanks!",1,0
337,2015-1-28,2015,1,28,18,2ty3q8,"A curated list of AI courses, books, video lectures and papers",https://www.reddit.com/r/MachineLearning/comments/2ty3q8/a_curated_list_of_ai_courses_books_video_lectures/,owainl,1422436351,,5,52
338,2015-1-28,2015,1,28,18,2ty5kx,High precision products with Wolftech PVC window machine,https://www.reddit.com/r/MachineLearning/comments/2ty5kx/high_precision_products_with_wolftech_pvc_window/,Alisonmelia,1422438202,,1,1
339,2015-1-28,2015,1,28,19,2tya74,Cretaing matrix for Soccer predictions,https://www.reddit.com/r/MachineLearning/comments/2tya74/cretaing_matrix_for_soccer_predictions/,rawcuban77,1422442740,"i am trying to create a matrix from which i could make a predictor for soccer games.....win or not......im doing it fow my own purposes,i just started machine learning, and i do it in R. So my first question is: what are the main factors that have influence if team will win or not independent from opposite team? Where can i get some datasets? just please dont laugh if the question is stupid.....
Ill be glad for any suggestions how to do it,or improve it.....",11,3
340,2015-1-28,2015,1,28,21,2tyfqg,"""If computers becomes sentient, we won't know it...""",https://www.reddit.com/r/MachineLearning/comments/2tyfqg/if_computers_becomes_sentient_we_wont_know_it/,[deleted],1422447863,,0,0
341,2015-1-29,2015,1,29,1,2tz38r,Slides (in English) of tonight's Paris Machine Learning Meetup on Data Science for Non-Profits,https://www.reddit.com/r/MachineLearning/comments/2tz38r/slides_in_english_of_tonights_paris_machine/,compsens,1422461810,,0,7
342,2015-1-29,2015,1,29,2,2tze33,A new R package for creating ensembles of caret models,https://www.reddit.com/r/MachineLearning/comments/2tze33/a_new_r_package_for_creating_ensembles_of_caret/,pandemik,1422466678,,1,9
343,2015-1-29,2015,1,29,3,2tzhhf,Google's Word2Vec to enable whole new classes of products that never existed,https://www.reddit.com/r/MachineLearning/comments/2tzhhf/googles_word2vec_to_enable_whole_new_classes_of/,biomimic,1422468222,,4,0
344,2015-1-29,2015,1,29,3,2tzlev,Object tracking,https://www.reddit.com/r/MachineLearning/comments/2tzlev/object_tracking/,no_porner,1422469943,"To solve the non-grid object tracking, we mainly exploit contour based tracking methods such as those based on level set techniques. But the level set techniques are very slow, which makes the tracking methods based on level set far away from real-time. Another difficulty of using level set for tracking is that when the target to be tracked are very similar to the background, the contour obtained by level set will cover some background regions. To improve the performance of tracking non-grid objects based on level set, we have to reduce the computation complexities of level set methods and also improve the accuracy of level set by exploiting the discrimination information between the target and its background.
Can anyone give me some ideas on how to proceed to solve the problem and achieve good object tracking?",0,1
345,2015-1-29,2015,1,29,7,2u0h46,"Looking to choose a major, help?",https://www.reddit.com/r/MachineLearning/comments/2u0h46/looking_to_choose_a_major_help/,xenon68,1422483631,"I'm a 17 year old that's extremely interested in neuromorphic engineering (such as the IBM chip), applying neurology concepts, AI, machine learning, computer vision, etc...

My goal is to contribute and hopefully create something from this research, to help humanity. I don't know if that makes any sense, but I don't want a career just for the sake of supporting myself, I would like to contribute to humanity on the long run. 

I'm considering a bachelor in Computer Science with a specialization in Bioinformatics. I kind of want to do a dual degree in biology and computer science but where will that get me?

I was hoping for a neurology/engineering/programming domain. The closest thing I found to this was biomedical engineering, but that doesn't have as much of the programming side to it, and how would I transition into AI research with that? 

Any input, even if it's irrelevant to what I just said, is appreciated. Thank you for your time, hope to see some responses. ",5,0
346,2015-1-29,2015,1,29,9,2u0unv,AskML: Where do you get your daily Machine Learning news?,https://www.reddit.com/r/MachineLearning/comments/2u0unv/askml_where_do_you_get_your_daily_machine/,bkkb,1422489711,"Outside of /r/MachineLearning, where do you get your fix of daily ML (and dare I say it, ""data science"") news?

Lately, I've been reading the abstracts of the latest papers in [the arXiv](http://arxiv.org/) and read a few social news sites like [Hacker News](https://news.ycombinator.com/) and [Data Tau](http://www.datatau.com/) to look for novel interesting applications.  What do you do?",9,24
347,2015-1-29,2015,1,29,9,2u11m4,"""AI has fallen in love with statistics """,https://www.reddit.com/r/MachineLearning/comments/2u11m4/ai_has_fallen_in_love_with_statistics/,[deleted],1422493127,"I've recently watched a video (link at the bellow) discussing the future development of AI and a critique of the current advancements. What stood out the most for me was the speaker's comment about statistics domination the AI fields. Is it safe to assume he refers to machine learning? 

https://www.youtube.com/watch?v=C-vbQdPi8Ww
 ",27,0
348,2015-1-29,2015,1,29,10,2u13ee,(Deep Learnings Deep Flaws)s Deep Flaws,https://www.reddit.com/r/MachineLearning/comments/2u13ee/deep_learnings_deep_flawss_deep_flaws/,[deleted],1422494003,,3,0
349,2015-1-29,2015,1,29,14,2u1wbg,support vectors in text analytics,https://www.reddit.com/r/MachineLearning/comments/2u1wbg/support_vectors_in_text_analytics/,new2machinelearning,1422509223,"Hi folks .. i am beginning to harness scikit's svm to perform some news analytics. While going through their tutorials they perform a classification (using linear SVM) on a dataset called 20 news group. I chose 4 categories and finally input a 2257 x 35843 sparse matrix (after performing tf-idf on it) into the svm. I was curious to find out how many support vectors the fit had and wanted to use these support vectors to glean more info about the data set in general. Turns out it has ~165k features (in a sparse matrix) as support vectors !! i couldn't wrap my head around the number here ..if my understanding is correct, the support vectors are those features that abut the hyperplane separating the classes , but it seems to be taking like 50% of the feature set as support .. is this normal in text classification ? my concern is that i would be feeding in 1000's of news articles (relating to a single topic) to perform sentiment analysis and i would like to know which words lean towards a particular sentiment (support vectors ? ) ..but if the algo is going to give me this huge number, even after i perform a chi2 test for ""x"" important features i still might not get the words that we humans intuitively ID as being positive or negative ..

apologies for the long question but i wanted to be as detailed as possible ..hope it makes sense and any pointers will be deeply appreciated.

Regards, vikram",3,1
350,2015-1-29,2015,1,29,16,2u24m3,"ROSS is built upon Watson, IBM's cognitive computer. Almost all of the legal information that you rely on is unstructured datait is in the form of text, and not neatly situated in the rows and columns of a database.",https://www.reddit.com/r/MachineLearning/comments/2u24m3/ross_is_built_upon_watson_ibms_cognitive_computer/,biomimic,1422514879,,8,24
351,2015-1-29,2015,1,29,17,2u28yu,I need an introductory video about machine learning. What should I see?,https://www.reddit.com/r/MachineLearning/comments/2u28yu/i_need_an_introductory_video_about_machine/,worldshapers,1422518574,Hi I'm looking for an interesting 15-20 minutes video about machine-learning. I would love if it was directed to programmers but any suggestions would be nice.,1,0
352,2015-1-29,2015,1,29,22,2u2s7e,"is it fair to consider Deep learning as a target by itself, at least for the moment ?",https://www.reddit.com/r/MachineLearning/comments/2u2s7e/is_it_fair_to_consider_deep_learning_as_a_target/,hadyelsahar,1422537003,"as a researcher working in a specific topic for example text processing, at the same time showing a bit interest in deep learning, is it fair to target deep learning by itself rather than the problems themselves ? 

taking in to consideration that world need some time to map all the existing models into deep learning.

and how does this apply to a context of a PhD thesis ",1,0
353,2015-1-29,2015,1,29,23,2u2x77,3 months into my first ML job - and I have questions.,https://www.reddit.com/r/MachineLearning/comments/2u2x77/3_months_into_my_first_ml_job_and_i_have_questions/,DucksHaveLowAPM,1422540486,"Hi everyone,  
I have some programming background and 3 months ago I've landed a ML job in the financial world. We are finishing my first project which was a classification problem. The team is new and small with only the manager having a good couple years of experience in the field (other people are mathematicians / programmers with 1-2 years of experience). So I want to ask you for some advices.  
I can learn programming on my own (my main skills are C# and R). I also finished Andrews Ng coursera course and first 7 parts of Data Science specialization from Johns Hopkins University (and I think most of the topics were covered too briefly) and I'm in the process of reading ""An Introduction to Statistical Learning"".  
And I'm kind of lost.  
I have a good perspective that there is a mountain of learning in front of me, and I know one thing I lack - I don't know how to approach the data. I know what are p values, t-tests, PCA and why having correlated variables in your model is bad. But I have no statistical sense of how to sink my teeth into the numbers I'm given, or when something should raise my alarm bells. Sure I can generate a bunch of graphs, and colour them by model classifier, but that doesn't speak to me that much. How can I learn that?  
I had some good ideas for building model variables from raw data but I would also appreciate some advice on how to make is something more than hit-or-miss process guided by someone with knowledge of the field we are trying to model.  
Is there a way to distinguish what are good candidates for variables to use for dividing the main dataset into different segments?  
What is a good signal to stop one approach and move into different like decide to use different algorithm?  
Also what would you recommend to learn next?
Thanks in advance.",12,10
354,2015-1-29,2015,1,29,23,2u2zjv,Common Sense Problems and Learning about Machine Learning - Talking Machines Episode 3,https://www.reddit.com/r/MachineLearning/comments/2u2zjv/common_sense_problems_and_learning_about_machine/,iori42,1422541853,,2,30
355,2015-1-30,2015,1,30,0,2u33m3,Carlos Guestrin on the early days of GraphLab and the evolution of GraphLab Create,https://www.reddit.com/r/MachineLearning/comments/2u33m3/carlos_guestrin_on_the_early_days_of_graphlab_and/,gradientflow,1422544114,,0,7
356,2015-1-30,2015,1,30,0,2u36qq,(Deep Learnings Deep Flaws)s Deep Flaws,https://www.reddit.com/r/MachineLearning/comments/2u36qq/deep_learnings_deep_flawss_deep_flaws/,vkhuc,1422545718,,11,9
357,2015-1-30,2015,1,30,0,2u39gu,IDE that properly typesets math,https://www.reddit.com/r/MachineLearning/comments/2u39gu/ide_that_properly_typesets_math/,mostly_complaints,1422547046,"I'm sure many of you have to deal with equations and math in your programming on a daily basis. I know the very idea of this will offend programming purists, but does anyone know of an IDE that will typeset math in my code inline? For example, the Latex in my Python Sphynx docstrings, or better yet in my Theano functions (I suspect this second one is likely not possible)? 

I assume that when you double click the typeset math you could edit it, or something similar.",4,3
358,2015-1-30,2015,1,30,0,2u39nj,can i hear things using my computer microphone and ml that i cant with my own ears ?,https://www.reddit.com/r/MachineLearning/comments/2u39nj/can_i_hear_things_using_my_computer_microphone/,programmingselenium,1422547141,"for example, that someone has just started cooking several rooms away, or that the neighbors have just woken up, etc etc?",3,2
359,2015-1-30,2015,1,30,1,2u3e17,A Statistical View of Deep Learning (I): Recursive GLMs,https://www.reddit.com/r/MachineLearning/comments/2u3e17/a_statistical_view_of_deep_learning_i_recursive/,iori42,1422549111,,7,11
360,2015-1-30,2015,1,30,1,2u3e4v,Using cell signaling networks to design better ANNs,https://www.reddit.com/r/MachineLearning/comments/2u3e4v/using_cell_signaling_networks_to_design_better/,osazuwa,1422549162,"Artificial neural networks are inspired by biological neural networks.  

There is a similar class of biological network called cell signal transduction networks.  It is how cells sense and respond to cues from the environment, for example a microbial cell detecting and moving toward a food source, or one of your cells sensing injury and inflaming itself.  In these networks, nodes are intracellular proteins and edges are biochemical interactions between them.  The input is a extracellular cue (eg. a hormone or growth factor) and the response is a cellular decision (eg. proliferate/do nothing), which often means some gene in the DNA is activated. 

In ANNs, we tend to work with generic network topologies, such as multilayer perceptrons.  We do not use the actual topologies evolved in the brain, nor use the evolved dynamics of signal processing in the brain to inform the selection of weights and activation functions -- at least I have not heard of this.  

I suspect because it is probably damn hard to map out the circuits of the brain in this fashion.  But with current bioinformatics technology, it is not so hard to map out the signaling networks in a cell.  

What do people here think about mimicking these topologies and network dynamics in designing ANNs?  My intuition: such topologies could be useful when signals are coming from a noisy environment and it is important to accurately detect certain events that occur rarely --eg. harmful network activity, terrorist activity.  

Edit: I have heard of some biomimetic approaches before, for example with [intrusion detection systems modeled after the human immune system](http://link.springer.com/article/10.1007/s11047-006-9026-4#page-1).  However, though these models look at immune cells, from what I saw they never specifically modeled the signaling network topology of these cells in a network-based classifier.  ",0,1
361,2015-1-30,2015,1,30,1,2u3f5l,"Can we have a regular ""Simple Questions Thread""?",https://www.reddit.com/r/MachineLearning/comments/2u3f5l/can_we_have_a_regular_simple_questions_thread/,cubby13579,1422549606,"I recently asked a simple question here, and I did get one answer which was basically what I was looking for.  But generally it was just downvoted and ignored.  I understand that a lot of people come here to talk about upper level concepts, new research, etc... and don't want to have to sift through simple questions. 

But there's 32,000 subscribers.  Surely you don't all have PhDs... The sidebar is packed with info on self teaching.  And that's all great.  But sometimes you need feedback.  Or you want to try to apply something you learned in a MOOC to another problem, and can't figure it out by yourself.  And then you can use google to find similar problems.  But even still, it can be difficult to find the answer you need.

In theory, questions would range from ""How do I do X in Y language""? , ""How does X methodology get from point A to point B?"", ""What would be the best way to address X problem?"", etc...

If there was a weekly thread, it wouldn't really bother anyone, but maybe it would be helpful.  I for one would use it all the time, at least for the foreseeable future.",36,76
362,2015-1-30,2015,1,30,2,2u3msy,Neural Networks coadaptation problem,https://www.reddit.com/r/MachineLearning/comments/2u3msy/neural_networks_coadaptation_problem/,MAS313,1422552923,Dropout proposed by Hinton is said to prevent co-adaptation. My question is on co-adaptation. How can I measure the coadaptation that occurs in a MLP that does not use a drop out? ,1,1
363,2015-1-30,2015,1,30,2,2u3pp5,Questions about Backpropagation,https://www.reddit.com/r/MachineLearning/comments/2u3pp5/questions_about_backpropagation/,[deleted],1422554260,,0,1
364,2015-1-30,2015,1,30,4,2u469j,On Eigenfaces: Creating ghost-like images from a set of faces.,https://www.reddit.com/r/MachineLearning/comments/2u469j/on_eigenfaces_creating_ghostlike_images_from_a/,rbneedly,1422561485,,3,6
365,2015-1-30,2015,1,30,5,2u4c7r,Video tutorial on the math behind PCA,https://www.reddit.com/r/MachineLearning/comments/2u4c7r/video_tutorial_on_the_math_behind_pca/,algomanic,1422564091,,3,4
366,2015-1-30,2015,1,30,5,2u4cf3,"would it be foolish to try to write software that writes functions in response to a query, input output pairs, and existing code?",https://www.reddit.com/r/MachineLearning/comments/2u4cf3/would_it_be_foolish_to_try_to_write_software_that/,programmerish,1422564182,I'm finding this useful to anyone interested: http://dces.essex.ac.uk/staff/rpoli/gp-field-guide/A_Field_Guide_to_Genetic_Programming.pdf,3,1
367,2015-1-30,2015,1,30,9,2u57ga,Mostly theoretical ML course by Shai Ben-David of Waterloo (video playlist),https://www.reddit.com/r/MachineLearning/comments/2u57ga/mostly_theoretical_ml_course_by_shai_bendavid_of/,xamdam,1422578683,,3,11
368,2015-1-30,2015,1,30,12,2u5pqf,LLVM Adds Options To Do Fuzz Testing (/r/programming/),https://www.reddit.com/r/MachineLearning/comments/2u5pqf/llvm_adds_options_to_do_fuzz_testing_rprogramming/,bboyjkang,1422587882,,0,1
369,2015-1-30,2015,1,30,13,2u5w6z,How do you self-study?,https://www.reddit.com/r/MachineLearning/comments/2u5w6z/how_do_you_selfstudy/,dsocma,1422591325,,13,8
370,2015-1-30,2015,1,30,13,2u5yks,A star with robot navigation,https://www.reddit.com/r/MachineLearning/comments/2u5yks/a_star_with_robot_navigation/,faust_1706,1422592708,"So I am trying to get a robot to navigate through a field of traffic cones. I am getting data of where obstacles are via LIDAR. It gives me an array of polar coordinates to the first object in the same plane as the ""camera"". The gap is .25 degrees. with 1mm precision. I have an a* program that works with it, but it yields paths that the robot cannot fit through because it is too big. Is there an easy solution to this?",1,0
371,2015-1-30,2015,1,30,14,2u64oy,"The Demise of Homo Sapiens by AI, My Theory",https://www.reddit.com/r/MachineLearning/comments/2u64oy/the_demise_of_homo_sapiens_by_ai_my_theory/,[deleted],1422596330,"The military is more and more dependent on artificial intelligence to function. Since missiles can hit you in a matter of seconds, it's not really fast enough for a human to react and engage that one target, let alone the salvo you will be getting from the air, land, sea etc. all at the same time. Programs are written to detect the targets, assess the targets, and engage the targets based on which are the most dangerous.

Technology and artificial intelligence will continue to improve and one can expect that the military will always get the best stuff first.
While in the civilian sector there may be movements to limit the power of artificial intelligence in order that we don't lose control to something so powerful we cannot comprehend it, and I can even see that spilling into the military sector, the main problem will be the next big war.

The nature of war dictates certain selection pressures on different systems and to different degrees than in peacetime. In the next war, the faction with the best AIs will likely win. The reason is that the side with the best AI will be able to out think and out react and out maneuver everyone else. At that point, all the factions that tried to limit AI power during peacetime will be moot because those factions will likely not survive.

I believe it is through this, that AI will push through the ceiling that humans will try to impose and from that point on, we will be at the mercy of something we cannot possibly hope to understand or catch up to.

This does not necessarily mean that we will be destroyed. It will mean that we will essentially lose control and are at the mercy of the AI.

The only way I can see around this right now is if we augment human intelligence so that it is competitive with artificial intelligence. What I mean is some sort of neural chip or something that will significantly enhance our mental abilities. If we cannot out compete artificial intelligence, which will move forward due to our laziness (in peacetime), and our military requirements in times of war, we are fucked.",3,0
372,2015-1-30,2015,1,30,15,2u68d6,Question from a beginner regarding features and SVM,https://www.reddit.com/r/MachineLearning/comments/2u68d6/question_from_a_beginner_regarding_features_and/,neurone214,1422598864,"Hey everyone.  I'm new at this stuff and have been reading Learning with Kernels to get up to speed.  In the meantime I've been working with some classification problems that have arisen in my work, which, not coincidentally, was the motivation for me to get into SVM.  I've worked with Bayesian methods for classification before, and I say this in case you notice me drawing from that in any erroneous way. 

So, I have a bunch of variables associated with two states of a system.  We know for theoretical reasons related to the underlying problem that interactions amongst these variables are important in terms of predicting these states. I'm trying to use SVM with these variables and their respective 2-way interactions to see if I can predict the states on a set of training data as well as on some test data.  

Anyway, I found that when I use all the variables and their respective interactions, I can only get about 60% accuracy on my test data.  When I look at the variables and their interactions, I see that some VERY obviously follow the two states I'm trying to predict.  When I get rid of the other variables/interactions, then try to fit the model, I can get above 90% accuracy on the test data.  

So, this is awesome! But, it doesn't feel kosher.  

Anyway, because I'm very new at this I was hoping that someone could maybe talk a little bit about why the non-informative variables carry enough weight in the model to hamper the fit and if there are any techniques I can do to condition my variables/interactions before fitting a model in the future.  

That's all -- thanks in advance! 

",8,5
373,2015-1-30,2015,1,30,19,2u6pwy,Deep Learning for Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/2u6pwy/deep_learning_for_natural_language_processing/,atveit,1422614692,,0,20
374,2015-1-30,2015,1,30,21,2u6wyb,New to deep learning? Here are 4 easy lessons from Google,https://www.reddit.com/r/MachineLearning/comments/2u6wyb/new_to_deep_learning_here_are_4_easy_lessons_from/,igor_subbotin,1422621278,,0,10
375,2015-1-30,2015,1,30,22,2u70hf,Advice for applying Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2u70hf/advice_for_applying_machine_learning/,iori42,1422624242,,0,3
376,2015-1-30,2015,1,30,23,2u73xx,"Friday's ""Simple Questions Thread"" - 20150130",https://www.reddit.com/r/MachineLearning/comments/2u73xx/fridays_simple_questions_thread_20150130/,seabass,1422626662,"Because, why not. Rather than discuss it, let's try it out. If it sucks, then we won't have it again. :)",57,42
377,2015-1-31,2015,1,31,1,2u7kdp,Applied machine learning term projects using open data from the city of Montreal,https://www.reddit.com/r/MachineLearning/comments/2u7kdp/applied_machine_learning_term_projects_using_open/,pierrelux,1422635319,,2,8
378,2015-1-31,2015,1,31,1,2u7ner,A Hierarchical Bayesian Drive-Survival Model of the NFL,https://www.reddit.com/r/MachineLearning/comments/2u7ner/a_hierarchical_bayesian_drivesurvival_model_of/,TraptInaCommentFctry,1422636717,,1,1
379,2015-1-31,2015,1,31,2,2u7p4k,Auto-encoder papers and open source softwares,https://www.reddit.com/r/MachineLearning/comments/2u7p4k/autoencoder_papers_and_open_source_softwares/,ernsthowe,1422637515,"Hi, everyone! I am a ML beginner. 
What I want to do is to learn an invariant and compact image representation with the Auto-encoder. So, I want to read some classical and latest papers. I googled but I still can't find the useful information. Maybe I am too superficial to know what is the key point and which paper is worthful. 
Is there anybody who can recommend some papers and open source softwares about the Auto-encoder for meThanks a lot!",2,0
380,2015-1-31,2015,1,31,6,2u8ong,Deep learning - linear models by Nando de Freitas,https://www.reddit.com/r/MachineLearning/comments/2u8ong/deep_learning_linear_models_by_nando_de_freitas/,JackieForien,1422654000,,4,10
381,2015-1-31,2015,1,31,9,2u99hz,Difference between books? Pattern Recognition | ESL,https://www.reddit.com/r/MachineLearning/comments/2u99hz/difference_between_books_pattern_recognition_esl/,Nixonite,1422664552,"Hello everyone,

So I have a bit of money to spend on a ML book and I'm wondering which book to get, the Bishop book Pattern Recognition or the Tibshirani book ESL?

I currently have the Introduction to Statistical Learning (ISL) book by Tibshirani but this is the most advanced material I have looked at regarding ML. I don't feel like I'm learning too much from it since the math is kind of lacking, so I'm trying to step it up a bit with Pattern Recognition or ESL. 

Anyway, do you prefer one over the other and why?

Would you consider one to be more terse than the other?

Oh and this is somewhat of a side note, but would you consider these books to be comprehensive? What I mean by that is, would you consider these books to give a solid explanation of each, and after a careful reading of them would you say that a person would be competent in ML algorithms/techniques/theory? I don't feel this way towards ISL so I'm hoping that the next book I get will be comprehensive. ",11,1
382,2015-1-31,2015,1,31,12,2u9qpy,Nice visualization of Predictive Models in R clustered by tag similarity,https://www.reddit.com/r/MachineLearning/comments/2u9qpy/nice_visualization_of_predictive_models_in_r/,[deleted],1422674418,,1,14
383,2015-1-31,2015,1,31,15,2ua9pb,"[Question] if i am developing web application, How can I avoid re-trainming the ML model every time",https://www.reddit.com/r/MachineLearning/comments/2ua9pb/question_if_i_am_developing_web_application_how/,[deleted],1422687207,"I am developing a web app with django. Part of system is predicting score of a game. In the back end, I trained the machine learning model and got good accuracy. 

Question is: 

How can I avoid restraining the model every time the user enter his option to get the prediction ( I don't wanna re train the model everyrtime the user request a result ), is there any wat to freeze the model ? What are my option if I need to retrain it every time, let s say every week. Is there any best practice's to learn here. 

",5,0
