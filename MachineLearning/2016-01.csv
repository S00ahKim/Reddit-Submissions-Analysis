,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2016-1-1,2016,1,1,11,3yz9dx,What do I need to build apps with Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/3yz9dx/what_do_i_need_to_build_apps_with_tensorflow/,Whitey_Knightey,1451615085,"I am a CS student and I think it would look great to have some ML projects in my portfolio alongside my more traditional stuff. The thing is, the only Linux computer I have is a dinosaur. I bought a compute for 56 CAD from a local repair shop, installed Ubuntu on it, and I haven't done much with it since. I don't even think that I would be able to use a modern graphics card on it. It's from the Windows XP era and was designed for Windows XP. 

Will I be able to do serious machine learning tasks on my Windows computer with Docker and Tensorflow? I have an i7. I cannot use my GPU with Docker enabled Tensorflow on Windows. About how much would it cost me to buy or build a Linux computer for machine learning purposes? I would like to build a pong app like this: https://www.youtube.com/watch?v=NE_KKM0e38s. I already have experience with pygame, but I don't have any experience with Tensorflow. ",8,0
1,2016-1-1,2016,1,1,12,3yzgt6,"Introducing Guesstimate, a Spreadsheet for Things That Arent Certain",https://www.reddit.com/r/MachineLearning/comments/3yzgt6/introducing_guesstimate_a_spreadsheet_for_things/,blowjobtransistor,1451620080,,9,18
2,2016-1-1,2016,1,1,14,3yznfl,Finally have a K20 server to start deep learning prototyping and research! But which framework to use?,https://www.reddit.com/r/MachineLearning/comments/3yznfl/finally_have_a_k20_server_to_start_deep_learning/,poporing88,1451624779,"I have no time to fully review all the frameworks available but I should be able to do the following:
1. Fine-tuning by changing the optimization function at the top layer
2. Design a Siamese network (also fine-tuning)
3. Python/Matlab Interface
4. Easily visualize each layer and use it as features.

I am guessing CAFFE can do this. I just need some confirmation. But I also want a flexible framework if I want to change some parts of the deep model. I am also thinking about TensorFlow if it would be a more valuable skill in the future? Thanks in advance for your insights!",8,0
3,2016-1-1,2016,1,1,14,3yzod0,Custom dictionary creation by training on a corpus as the dictionary input for standard mispelling checker ?,https://www.reddit.com/r/MachineLearning/comments/3yzod0/custom_dictionary_creation_by_training_on_a/,angellistQu,1451625373,"Is there any quick and dirty way to do this? I want to train on a large corpus to create a large dictionary of words (so that slang and things like tl;dr are included), then use that dictionary in a standard spellchecking algorithm. ",4,1
4,2016-1-1,2016,1,1,20,3z0d47,CDBN Deep Learning for Audio Data,https://www.reddit.com/r/MachineLearning/comments/3z0d47/cdbn_deep_learning_for_audio_data/,MrDaniel123,1451646902,"Hello,

I am trying to replicate....

http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for-audio-classification-using-convolutional-deep-belief-networks.pdf

I have a CDBN......

https://github.com/yusugomori/DeepLearning/blob/master/python/CDBN.py

A python script to create spectrograms from MP3.....

http://stackoverflow.com/questions/15311853/plot-spectogram-from-mp3

So it's looking like the tools are coming together, pre-processing seems ok in making a spectrogram and applying PCA.  I am a little unclear on how to train layer, by layer...

""First, we extracted the spectrogram from each utterance of the TIMIT training data [13]. The spec-trogram had a 20 ms window size with 10 ms overlaps. The spectrogram was further processed using PCA whitening (with 80 components) to reduce the dimensionality. We then trained 300 first-layer bases with a filter length (n W ) of 6 and a max-pooling ratio (local neighborhood size) of 3. We further trained 300 second-layer bases using the max-pooled first-layer activations as input, again with a filter length of 6 and a max-pooling ratio of 3.""

Do you have code or examples explaining this process more clearly, for practical implementation.
",0,10
5,2016-1-1,2016,1,1,20,3z0ec7,How I Learned To Code Neural Networks,https://www.reddit.com/r/MachineLearning/comments/3z0ec7/how_i_learned_to_code_neural_networks/,mrborgen86,1451648180,,36,204
6,2016-1-1,2016,1,1,23,3z0oli,Hal Varian: Machine Learning and Econometrics,https://www.reddit.com/r/MachineLearning/comments/3z0oli/hal_varian_machine_learning_and_econometrics/,antontarasenko,1451657070,,0,11
7,2016-1-2,2016,1,2,1,3z151y,Are you considering writing a blogpost/tutorial on neural networks? Because neural networks are like burritos.,https://www.reddit.com/r/MachineLearning/comments/3z151y/are_you_considering_writing_a_blogposttutorial_on/,bluecoffee,1451667148,,15,11
8,2016-1-2,2016,1,2,2,3z1906,How to accelerate AI progress by 6X,https://www.reddit.com/r/MachineLearning/comments/3z1906/how_to_accelerate_ai_progress_by_6x/,maxtility,1451669114,,5,9
9,2016-1-2,2016,1,2,2,3z19wy,How to apply Machine Learning to Chemistry?,https://www.reddit.com/r/MachineLearning/comments/3z19wy/how_to_apply_machine_learning_to_chemistry/,MusicIsLife1995,1451669523,I just realized I have another Chemistry class to take at University. However Chemistry is pretty boring to me. How can I apply Machine Learning to the study?,6,0
10,2016-1-2,2016,1,2,3,3z1hed,How do you determine whether you're overfitting when using random forest and other tree models?,https://www.reddit.com/r/MachineLearning/comments/3z1hed/how_do_you_determine_whether_youre_overfitting/,maruchanr,1451672836,"In general, I think of overfitting as occurring when there is a gap between the train set accuracy and the test set accuracy, ie training error is lower than our approximation of generalization error via the test error.

When using RF, you aren't provided a ""train set"" accuracy. If you try to fit your model on your train set, you'll get a false ~100% accuracy. We could do CV, but CV error represents another form of test error as far as I know. So how to tell whether you are overfitting your data without knowing your training error?

EDIT: My question is a little more general than tuning hyperparameters. For example, how can I determine something like whether I have too many features and need to do dimensionality reduction?",7,0
11,2016-1-2,2016,1,2,3,3z1ljv,Complete guide to outlier detection in R,https://www.reddit.com/r/MachineLearning/comments/3z1ljv/complete_guide_to_outlier_detection_in_r/,selva86,1451674674,,0,5
12,2016-1-2,2016,1,2,4,3z1nzm,[Help] How Get better Random Numbers?,https://www.reddit.com/r/MachineLearning/comments/3z1nzm/help_how_get_better_random_numbers/,[deleted],1451675792,[deleted],3,1
13,2016-1-2,2016,1,2,5,3z1w4i,GPU based training of CRFs,https://www.reddit.com/r/MachineLearning/comments/3z1w4i/gpu_based_training_of_crfs/,Ebusr,1451679621,"I am looking for a fast way to train a fully connected CRF (with loopy belief propagation inference), preferably with a GPU. Is there a good software library? 

I am currently using the UGM toolkit for matlab, which has mex implementations but no GPU.",2,1
14,2016-1-2,2016,1,2,9,3z2tp9,The Brain vs. Deep Learning: Computational Complexity,https://www.reddit.com/r/MachineLearning/comments/3z2tp9/the_brain_vs_deep_learning_computational/,[deleted],1451694179,[deleted],0,1
15,2016-1-2,2016,1,2,9,3z2tx1,Anyone know of a good tutorial for coding RNNs?,https://www.reddit.com/r/MachineLearning/comments/3z2tx1/anyone_know_of_a_good_tutorial_for_coding_rnns/,brains_bourbon_beer,1451694293,"I'm using torch, and have installed the rnn extension of the nn package, but example code (for just simple fully recurrent nets, not lstm / gru/ fancy stuff that example code exists for) or a tutorial would be super helpful! I'm open to different language slash framework if you guys think something different would be better. 

I'm trying to implement a fully recurrent neural network that's essentially a replicate of what's done in this: http://m.jneurosci.org/content/18/1/399.abstract paper. It's a delayed match to sample task, and a simple fully recurrent net with 10-40 hidden units, 3 input units, and 3 output units. 

I'm sure I can struggle through figuring out the code, but if someone knows of a good tutorial it would be faster!! ",8,8
16,2016-1-2,2016,1,2,10,3z2z4o,Why 2015 Was a Breakthrough Year in Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/3z2z4o/why_2015_was_a_breakthrough_year_in_artificial/,mercadoviagens,1451696709,,0,0
17,2016-1-2,2016,1,2,10,3z35hl,Request: Python Implementation of Machine March Madness,https://www.reddit.com/r/MachineLearning/comments/3z35hl/request_python_implementation_of_machine_march/,slaw07,1451699762,"I'm looking for a good place to start for building my own NCAA March Madness predictor. Can anybody recommend open source repos to build off of? Preferably utilizing Pomeroy data and more. I've come across several papers but haven't been able to track down any successful code that also offers probabilities for winning as demonstrated by FiveThirtyEight:

http://fivethirtyeight.com/interactives/march-madness-predictions-2015/#mens",2,0
18,2016-1-2,2016,1,2,13,3z3rpl,Most important CNN papers from the past few years?,https://www.reddit.com/r/MachineLearning/comments/3z3rpl/most_important_cnn_papers_from_the_past_few_years/,letoseldon,1451710711,"I've read a few important papers (like the original AlexNet paper) but given all the activity in this field over the past few years I feel like I'm probably missing on a few ""must-read"" papers. Which ones would you recommend? ",3,7
19,2016-1-2,2016,1,2,14,3z3x27,A huge collection of shuttle weaving in Bangladesh.,https://www.reddit.com/r/MachineLearning/comments/3z3x27/a_huge_collection_of_shuttle_weaving_in_bangladesh/,sharmintex,1451713443,,0,1
20,2016-1-2,2016,1,2,16,3z466l,Machine learning and mp4 video files,https://www.reddit.com/r/MachineLearning/comments/3z466l/machine_learning_and_mp4_video_files/,steve4699,1451718576,"I have a bunch of mp4 video files that I would like to use Machine learning to categorize.  Knowing nothing about ML except in high level, is this something that can be done?  If so, are there any software out there that does this, or does this have to be hand-crafted?  If this has to be created from scratch is there possibly a tutorial that deals with ML and image detection or video files?
",2,0
21,2016-1-2,2016,1,2,17,3z4b38,Deep belief network with tensorflow,https://www.reddit.com/r/MachineLearning/comments/3z4b38/deep_belief_network_with_tensorflow/,ycyoon,1451721649,"Does tensorflow have an implematation for DBNs?
I can't find an example for DBNs.",7,0
22,2016-1-2,2016,1,2,17,3z4exw,TensorFlow - Programming model and concepts,https://www.reddit.com/r/MachineLearning/comments/3z4exw/tensorflow_programming_model_and_concepts/,redgansai,1451724302,,0,1
23,2016-1-2,2016,1,2,19,3z4pi6,Looking for MUSICAL DATASET with SAME note played by different instruments!,https://www.reddit.com/r/MachineLearning/comments/3z4pi6/looking_for_musical_dataset_with_same_note_played/,mmeendez,1451732092,"Urgently needing a dataset to train and test my NN! The perfect dataset would contain more than 100 audios (format doesn't care) which the same note is played (imagine C5) by multiple instruments. An instrument can be repeated, I mean, a guitar can appear more than once if and only if it is not exactly the same guitar. Any similar dataset will be welcomed! Thanks ",10,8
24,2016-1-2,2016,1,2,20,3z4ty2,TensorFlow White Paper Notes,https://www.reddit.com/r/MachineLearning/comments/3z4ty2/tensorflow_white_paper_notes/,TheTwigMaster,1451735675,,10,80
25,2016-1-2,2016,1,2,22,3z546o,"Advice, what jobs/postdoc do after a Bioinformatics, ML, image processing PhD",https://www.reddit.com/r/MachineLearning/comments/3z546o/advice_what_jobspostdoc_do_after_a_bioinformatics/,WillyWonk1964,1451742733,"Hi,

I'm in the final year of a PhD programme, in which I have been working on a set of projects to solve image processing and recognition problems in a biological context. Usually involving analysis of microscope images, to extract cell morphological information and analyse different cell populations. 

Over the course of this PhD, I have used techniques from machine learning and image processing, algorithms for pattern analysis and object detection. I have experience in applying these techniques to a range of problems.

As I reach the end of the PhD, I am wondering what kind of opportunities maybe available for jobs/postdoc. I feel a bit secluded in the academic environment, and am not sure in what other scenarios my skills maybe applicable. 

My background has been all academic, from a BSc in Natural Science (mainly physics) , followed by an MSc in Computer Science, and then onto the PhD. I am interested in both post-docs or industry in the UK or abroad, just depending on the specifics of the company/institute/position.

Advice on what kind of jobs/post-docs to look into would be much appreciated, along with things to be doing in my last year that may improve my general employment prospects. Lastly, I have a bit of an inferiority complex about having learnt how to use many different methods, but not really taking the time to fully understand the mathematics/statistics behind them. I guess, I feel like a bit of a jack of all trades master of none kind of thing.


Thanks",1,1
26,2016-1-3,2016,1,3,0,3z5e41,David Dalrymple on Differentiable Programming and ML,https://www.reddit.com/r/MachineLearning/comments/3z5e41/david_dalrymple_on_differentiable_programming_and/,egrefen,1451748332,,5,25
27,2016-1-3,2016,1,3,0,3z5f6s,A RNN that Learns Its Own Configuration,https://www.reddit.com/r/MachineLearning/comments/3z5f6s/a_rnn_that_learns_its_own_configuration/,[deleted],1451748879,[deleted],0,1
28,2016-1-3,2016,1,3,2,3z5r17,Datumbox Machine Learning Framework 0.6.1 Released,https://www.reddit.com/r/MachineLearning/comments/3z5r17/datumbox_machine_learning_framework_061_released/,datumbox,1451754142,,0,0
29,2016-1-3,2016,1,3,3,3z6045,Two New Deep Reinforcement Learning papers from Google DeepMind at Jan 1!,https://www.reddit.com/r/MachineLearning/comments/3z6045/two_new_deep_reinforcement_learning_papers_from/,YigitDemirag,1451757796,"1st paper: http://arxiv.org/abs/1512.04860
2nd paper: http://arxiv.org/abs/1509.06461 

EDIT: It seems both paper posted in early Dec, but accepted recently..",3,0
30,2016-1-3,2016,1,3,4,3z6arp,Strategies and Principles of Distributed Machine Learning on Big Data [paper from authors of Petuum framework http://petuum.github.io/ ],https://www.reddit.com/r/MachineLearning/comments/3z6arp/strategies_and_principles_of_distributed_machine/,muktabh,1451762209,,1,11
31,2016-1-3,2016,1,3,7,3z762o,Will be possible to develop a Learning maching to try to predict tennis matches with RapidMiner?,https://www.reddit.com/r/MachineLearning/comments/3z762o/will_be_possible_to_develop_a_learning_maching_to/,machineLearningNovic,1451775572,"Hi,
I've got tons of data with a lot of info about tennis matches of the last 5 years.

I would like to create a Machine Learning and train it with the data from 2011-2014 and then test it with 2015 data.

Is this possible? The info in the datasets is a little confusing. Is this possible with RapidMiner?

Thanks.",0,0
32,2016-1-3,2016,1,3,9,3z7gcf,Stacked denoising autoencoders: cannot reproduce the filters,https://www.reddit.com/r/MachineLearning/comments/3z7gcf/stacked_denoising_autoencoders_cannot_reproduce/,redst4r,1451779726,"Hi guys,

Recently I got interested in autoencoders and came across the following ""classical"" paper from J. Bengio's lab:
[Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion](http://jmlr.org/papers/volume11/vincent10a/vincent10a.pdf)

I wanted to implement it myself in lasagne, but quickly realized that I got very different results even for their most simple examples.

E.g. they use a linear undercomplete (50 hidden units) linear autoencoder on this natural image dataset (12x12 patches)(http://redwood.berkeley.edu/bruno/sparsenet/) and find that the filters of the AE look like blob detectors. 
Mine dont :(

Same for their next example, using an overcomplete (200units) linear denoising AE. They get gabor like edge detectors, I get some apparently random filters. 

So I suspect I did something wrong here. Would be great if anyone could help me out here and point out my mistake.
[Here's](https://github.com/redst4r/stacked_denoising_autoencoders/blob/master/sdae.ipynb) my code.

",5,2
33,2016-1-3,2016,1,3,9,3z7h58,Differentiable Programming,https://www.reddit.com/r/MachineLearning/comments/3z7h58/differentiable_programming/,[deleted],1451780057,[deleted],0,1
34,2016-1-3,2016,1,3,9,3z7ini,NN research at universities,https://www.reddit.com/r/MachineLearning/comments/3z7ini/nn_research_at_universities/,[deleted],1451780668,[deleted],2,0
35,2016-1-3,2016,1,3,10,3z7v0b,Can you code Machine Learning in VBA?,https://www.reddit.com/r/MachineLearning/comments/3z7v0b/can_you_code_machine_learning_in_vba/,world_leader16,1451785995,How can I get started implementing machine learning in VBA code?,13,0
36,2016-1-3,2016,1,3,11,3z80lw,The OpenAI Research Team will be doing an AMA in /r/MachineLearning on January 9,https://www.reddit.com/r/MachineLearning/comments/3z80lw/the_openai_research_team_will_be_doing_an_ama_in/,olaf_nij,1451788566,"Starting off the new year with another AMA announcement! The [OpenAI](https://openai.com/) Research Team will be stopping by /r/MachineLearning on January 9 for an AMA.

A thread will be created before the official AMA time for those who won't be able to attend on that day.",23,280
37,2016-1-3,2016,1,3,14,3z8lbe,Video resources for machine learning,https://www.reddit.com/r/MachineLearning/comments/3z8lbe/video_resources_for_machine_learning/,[deleted],1451798160,[deleted],0,0
38,2016-1-3,2016,1,3,14,3z8ohr,Using Recurrent Neural Nets with Deeplearning4j,https://www.reddit.com/r/MachineLearning/comments/3z8ohr/using_recurrent_neural_nets_with_deeplearning4j/,vonnik,1451799670,,0,0
39,2016-1-3,2016,1,3,16,3z8yhz,I made a Ctrl+F like Chrome extension which gives fuzzy matches using word vectors (GloVe/Word2Vec),https://www.reddit.com/r/MachineLearning/comments/3z8yhz/i_made_a_ctrlf_like_chrome_extension_which_gives/,ijkilchenko,1451805341,"[Link to download/install the extension in the Chrome Web Store](https://chrome.google.com/webstore/detail/fuzbal/lidjpicdkcgjdkgifmmpalkibjeppdof) &lt;- you need this link as I chose to not publicly list a beta version just yet. 

[Link to project on GitHub](https://github.com/ijkilchenko/Fuzbal)

**Summary**

So here's the idea. Ctrl+F in Chrome is great for exact matches and it would be even better to add some fuzzy matches to that list. We can attempt to add some matches based on close spelling (using string edit distance) and also find related words using [Stanford's GloVe](http://nlp.stanford.edu/projects/glove/) or [Google's Word2Vec](https://code.google.com/p/word2vec/). If you're unfamiliar with the last two projects, I'll summarize. We take a corpus (like Wikipedia or a collection of books) and run a machine learning algorithm to try to map each word in the vocabulary of the corpus to an n-dimensional vector in R^n such that the if the (Euclidean) distance between any two vectors is small, then the words are somehow related (they are often used interchangeably in sentences or just often seen together). 

So that's what the extension does. I tried to mimic how Ctrl+F in Chrome behaves and added these fuzzy matches to any search results. As an added bonus, you can use regular expressions, too! 

**Questions**

Since this is a machine learning subreddit, I'll try to predict some questions. 

**Q**: When is the actual training of the word vectors done?  
**A**: Never! I only use the final output of the machine learning algorithms and, in fact, I didn't even do the training myself. I downloaded pre-trained vectors and only kept top 18 thousand most frequent words seen in the English language. 

**Q**: How are the results ranked?  
**A**: Results are ranked using string edit-distance so that exact results appear at the top and longer results appear on the bottom. 

**More Info**

Feel free to use the extension as I am making final code changes to hopefully release version 1. Also feel free to ask questions here or, if you see an issue, open an issue on GitHub. Thanks! ",14,126
40,2016-1-3,2016,1,3,17,3z97a1,K-means when some data is missing?,https://www.reddit.com/r/MachineLearning/comments/3z97a1/kmeans_when_some_data_is_missing/,shakedzy,1451811497,"Hi all,
I'm have a large data-set, and I though of applying K-means on it in order to find some segments. But, some of the data is missing (NA values in R). On each row of the data there can be different values that are missing.
Any idea how I can still use K-means? Or is there an alternative in this case?
Thanks!",10,2
41,2016-1-3,2016,1,3,18,3z982d,Attention and Memory in Deep Learning and NLP,https://www.reddit.com/r/MachineLearning/comments/3z982d/attention_and_memory_in_deep_learning_and_nlp/,pogopuschel_,1451812137,,16,16
42,2016-1-3,2016,1,3,20,3z9jue,'No module named tensorflow' error when trying to run tensorflow,https://www.reddit.com/r/MachineLearning/comments/3z9jue/no_module_named_tensorflow_error_when_trying_to/,AwesomeDaveSome,1451821767,"I am currently trying to install Tensorflow on Ubuntu 15.10.

I had already some python libraries installed, so I used the suggested pip installation on the Tensorflow website, worked with no errors. When I now try to test it (just import tensorflow as tf, then do some stuff with it), the error 'No module named tensorflow' comes up.

I googled this, I found out the following things, but can't fix them, somehow, any help would be appreciated:
First I ran:

    python -c 'import sys; print (sys.path)'

This gave the result that no tensorflow things were in my pythonpath. I checked, the tensorflow libraries are under /usr/local/lib/python2.7/dist-packages

There are loads of directories, including one named tensorflow, but also some other ones, also some files, such as six.py

I ran

    export PYTHONPATH=/usr/local/lib/python2.7/dist-packages/tensorflow:$PYTHONPATH

also the same with no /tensorflow added after the /dist-packages. Now, both of those paths show up when I run the other command. However, still, if I try to run it, I get the no module found error.

I read in another reddit post that the tensorflow/init.py file should be included in the list I get from the first command. It does already include the /tensorflow path, and that directory would contain the init file, but I did not add it to the list seperately. Should I add everything from the dist-packages directory individually?

Edit: I seem to mess with some reddit formatting, the init file has underscores before and after it, if I try to display that, it becomes bold.",4,0
43,2016-1-4,2016,1,4,1,3za8xj,Looking for a research buddy,https://www.reddit.com/r/MachineLearning/comments/3za8xj/looking_for_a_research_buddy/,michal_sustr,1451837058,"This might be a longshot, but I'll try it anyway :) I'm looking for someone who is interested in ML research and would like to work with me, training neural networks and playing with some ideas. I have access to some nice hardware that we can use.

I'm currently finishing my Master studies (Artificial Intelligence) and I've found that the best way for me to learn is to have periods of introverted immersion into a problem and then talking about it with someone who works on it as well to share ideas. I get demotivated if I work on something by myself for longer time without feedback. Currently I don't have someone to do this with about neural networks, so that's why I thought about using reddit to find someone remotely :-) I believe it will be beneficial for both parties to help each other progress, so drop me a message telling something about yourself if you're interested and can spend at least 10 hours per week on this. Thanks! :)",25,39
44,2016-1-4,2016,1,4,1,3zaalg,Getting started with Regression and Decision Trees,https://www.reddit.com/r/MachineLearning/comments/3zaalg/getting_started_with_regression_and_decision_trees/,DrLegend,1451837852,,0,25
45,2016-1-4,2016,1,4,2,3zam92,DCGAN (Deep Convolutional GAN) in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/3zam92/dcgan_deep_convolutional_gan_in_tensorflow/,carpedm20,1451842920,,1,16
46,2016-1-4,2016,1,4,3,3zar21,DeepDriving approach to autonomous vehicles,https://www.reddit.com/r/MachineLearning/comments/3zar21/deepdriving_approach_to_autonomous_vehicles/,[deleted],1451844824,[deleted],0,2
47,2016-1-4,2016,1,4,3,3zaszh,Does anyone do marketing and data science? Help please?,https://www.reddit.com/r/MachineLearning/comments/3zaszh/does_anyone_do_marketing_and_data_science_help/,jennifercqcq,1451845603,"I graduated in may, 2015 with Mechanical Engineering degree. I do growth hacking(digital marketing) now. I realize data science and machine learning is the hot trend for marketing world. I've taken some online courses about model building and had so much fun! 

I was hoping someone who has similar background and give me some tips about what skills I should focus as well as some insights. 

I know you are all busy, but can you please help me? I will write you a hand-written thank-you letter to ya :)",3,0
48,2016-1-4,2016,1,4,4,3zaz6z,Best model for data with numbers and strings?,https://www.reddit.com/r/MachineLearning/comments/3zaz6z/best_model_for_data_with_numbers_and_strings/,shakedzy,1451848077,"Hi,
Let's say I have a data constructed of both numbers and strings, for example: each sample is the a customer on my website, holding the amount of purchased goods and the country he's from.

What is the best model to predict the number of items that a future customer will buy given his country?

I thought about a NN, but I will need about 200 nodes just for all countries, and this is probably even less efficient when their are many more different types. 

Any ideas on how to approach this?
Thanks!",3,0
49,2016-1-4,2016,1,4,4,3zb0yh,The Spiral Library - basic reverse AD on the GPU.,https://www.reddit.com/r/MachineLearning/comments/3zb0yh/the_spiral_library_basic_reverse_ad_on_the_gpu/,abstractcontrol,1451848769,,1,1
50,2016-1-4,2016,1,4,4,3zb44w,Torch code for breaking captcha,https://www.reddit.com/r/MachineLearning/comments/3zb44w/torch_code_for_breaking_captcha/,matrix2596,1451850014,,0,3
51,2016-1-4,2016,1,4,4,3zb4ne,Basic question about dimensionality reduction,https://www.reddit.com/r/MachineLearning/comments/3zb4ne/basic_question_about_dimensionality_reduction/,maruchanr,1451850219,"I am combining feature selection and PCA for dimensionality reduction, with the resulting feature set being fed into a random forest.

Do I apply the transformation on the entire dataset, then use that data for the RF? Or do I split into train/test sets first, then fit the transformation on the train set, then apply the random forest?",4,4
52,2016-1-4,2016,1,4,6,3zbjyz,Anomaly Detection in R,https://www.reddit.com/r/MachineLearning/comments/3zbjyz/anomaly_detection_in_r/,pabcc,1451856155,,3,4
53,2016-1-4,2016,1,4,6,3zblbr,What are the most desirable options/features of a neural network architecture?,https://www.reddit.com/r/MachineLearning/comments/3zblbr/what_are_the_most_desirable_optionsfeatures_of_a/,smarro,1451856686,"I'm trying to compare a custom neural network architecture with other existing ones. I'm quite new to the CS field and I'm looking for desirable properties and/or applications of neural networks(especially recurrent architectures). For example, some transfer functions are more appreciated than others because they are nonlinear, differentiable, monotonic... What about neural networks instead?

Thank you in advance.",2,0
54,2016-1-4,2016,1,4,7,3zbq3w,How to learn machine learning from scratch?,https://www.reddit.com/r/MachineLearning/comments/3zbq3w/how_to_learn_machine_learning_from_scratch/,Nagashitw,1451858570,"I have a computer science degree, so i have basic knowledge of Mathematics (might need some polishing tho) and some programming languages: C, C++, C#, Python, Javascript.

Additional information: I'm currently taking a CS Master's Degree at my university (kinda all arround, not focusing on a particular subject) and i'm thinking about making a ML thesis next year.",8,0
55,2016-1-4,2016,1,4,7,3zbsrt,Machine learning internships in HS?,https://www.reddit.com/r/MachineLearning/comments/3zbsrt/machine_learning_internships_in_hs/,n-d-j,1451859649,"Hi everyone,

I will be a rising junior this summer and I have absolutely no idea if/where I could apply for a machine learning internship position. Does anyone have any recomendations?",15,0
56,2016-1-4,2016,1,4,7,3zbtfm,Iteration process of constructing a DNN,https://www.reddit.com/r/MachineLearning/comments/3zbtfm/iteration_process_of_constructing_a_dnn/,pedromnasc,1451859921,"Hi everyone,

i have a question about how the iteration process for constructing a DNN happens. I mean, how is the number of layers chosen? How to choose the learning rate? How to choose the mini-batch size? How the structure of layers is chosen? Do you use the entire available training set since the beginning of the iteration process? Do you apply regularization since the beginning (L1, L2, dropout,...)? Or only think about regularization in the end?  Could someone give a reference of the iteration process or give some examples? It can be given using deep CNNs. 
I know that experience is very important, but a would appreciate some guidelines.",8,5
57,2016-1-4,2016,1,4,7,3zbvez,How much faster is a truncated singular value decomposition?,https://www.reddit.com/r/MachineLearning/comments/3zbvez/how_much_faster_is_a_truncated_singular_value/,cypherx,1451860702,,8,11
58,2016-1-4,2016,1,4,7,3zbwfd,Thoughts on: Feature Extraction: Foundations and Applications?,https://www.reddit.com/r/MachineLearning/comments/3zbwfd/thoughts_on_feature_extraction_foundations_and/,DucksHaveLowAPM,1451861097,"Hi  
I came across a book: http://www.amazon.com/Feature-Extraction-Foundations-Applications-Fuzziness/dp/3540354875 but it isn't cheap and I can't find any opinions about it. Is it good? Is it still relevant? Can I find that information someplace else?

Thanks in advance.",2,0
59,2016-1-4,2016,1,4,8,3zc1ll,Xeon vs 5960x?,https://www.reddit.com/r/MachineLearning/comments/3zc1ll/xeon_vs_5960x/,Ilikethebestthing,1451863143,"I am building a rig for deep learning, but also do some machine learning applications. Is it worth using dual xeons over a 5960x? The rig will be mainly used for neural nets (going to use 4 gpus), but I may use it for other things.   ",13,2
60,2016-1-4,2016,1,4,8,3zc5ia,Is there a nn layer architecture that can deal with variable sized input?,https://www.reddit.com/r/MachineLearning/comments/3zc5ia/is_there_a_nn_layer_architecture_that_can_deal/,[deleted],1451864793,[deleted],1,2
61,2016-1-4,2016,1,4,9,3zceo8,Non-machine learning entrepreneur looking to buy a coffee or drink for an expert in NYC and learn about your passions.,https://www.reddit.com/r/MachineLearning/comments/3zceo8/nonmachine_learning_entrepreneur_looking_to_buy_a/,moosigny,1451868551,"hi there- long shot, i know. i'm an entrepeneur living in NYC and i'm interested in learning more about ML. but i really do need a ELI5 version. i do very well one-on-one. i'd love to meet someone/anyone based in NYC that would be willing to meet and just chat about your passions and interests in this space. I have almost zero baseline for this stuff but i'm very interested.

please PM me. can meet pretty much anywhere any time. and thanks so much in advance....

",7,0
62,2016-1-4,2016,1,4,9,3zceot,Reinforcement Learning Neural Turing Machines (paper+code),https://www.reddit.com/r/MachineLearning/comments/3zceot/reinforcement_learning_neural_turing_machines/,[deleted],1451868556,[deleted],0,1
63,2016-1-4,2016,1,4,9,3zcfe8,Seeking feedback on dataset introduction pages,https://www.reddit.com/r/MachineLearning/comments/3zcfe8/seeking_feedback_on_dataset_introduction_pages/,Jxieeducation,1451868834,"Hi everyone,

There are a ton of great datasets out there. However, sometimes their about / introduction pages don't do them justice.

So I am trying to figure out a good template. [sample](https://github.com/jxieeducation/Quick-Hackathon-Side-Project-Experiments-2016/blob/master/dataset-profile/iris/iris_v1.md). 

I would really appreciate some feedback on how the about page for a dataset can be better! Thanks so much!
",1,0
64,2016-1-4,2016,1,4,10,3zcgco,Speech recognition with an autoencoder .,https://www.reddit.com/r/MachineLearning/comments/3zcgco/speech_recognition_with_an_autoencoder/,coldiefoldie,1451869223,"Hello people,

I'm doing a project that would do speech recognition (either recognize if a phoneme is a syllable or a vowel or print the phonemes that were recognized) with an autoencoder. I'm using the mocha-timit dataset for training.

What I basically did for training is this:

1. Read the frames of the nist file.

2. Segment the frames in windows of size 256 w/ overlap of 96. Then I put all the windows in a matrix of size *Nx256* where *N* is the number of sliding windows. I also compute the *MFC* coefficients (13, to be exact) for each window, and place them in a matrix too.
The code for what I have written above can be seen here:
https://www.dropbox.com/s/d17fn2iyjkkswu6/SavingDataMatrices.py?dl=0

3. I have a one layer *Autoencoder* (for now) which has an input of the size of one window (256), 50 neurons in the hidden layer, and 256 neurons for output. 

Here is the code for the *Autoencoder*: https://www.dropbox.com/s/0yky5xi0a5lspws/Autoencoder.py?dl=0

My questions are the following:

1. When I *standardize* the dataset (the matrix) I get a bigger error rate than when I just leave it as is. Why does this happen and how should I continue (use standardization or leave it as it is?)

2. After I have layer-wise trained the Autoencoder with one or two additional layers in the unsupervised phase, will I even need the MFC coefficients for the classification phase? The sample rate of the audio files is 16 kHz, if a phoneme is found from 0.51 to 0.61, that's like ~2300 frames, how will my autoencoder recognize the phoneme when the input is 256 neurons (frames)?

Thanks for helping :)",0,2
65,2016-1-4,2016,1,4,14,3zdgi7,"When a neural net solves for y = x*x, does it require ""learning"" how multiplication and polynomials work, or are multiplication and polynomials pre-trained via the structure of a neural network?",https://www.reddit.com/r/MachineLearning/comments/3zdgi7/when_a_neural_net_solves_for_y_xx_does_it_require/,dig9900,1451885442,,22,26
66,2016-1-4,2016,1,4,17,3ze0br,Machine Learning Stock Market and Chaos,https://www.reddit.com/r/MachineLearning/comments/3ze0br/machine_learning_stock_market_and_chaos/,Brett_Kelly,1451897027,,3,0
67,2016-1-4,2016,1,4,18,3ze696,NIPS 2015 Tutorial: Monte Carlo Inference Methods,https://www.reddit.com/r/MachineLearning/comments/3ze696/nips_2015_tutorial_monte_carlo_inference_methods/,captcompile,1451900839,,0,7
68,2016-1-4,2016,1,4,19,3ze9iy,Is there a publicly available corpus of children's books for nlp research? (this would provide a simplified nlp R&amp;D arena),https://www.reddit.com/r/MachineLearning/comments/3ze9iy/is_there_a_publicly_available_corpus_of_childrens/,polytop3,1451902965,"Hi All,

I was wondering if there was a corpus based on children's books available. I feel like that would be a much more simplified nlp arena vs traditional corpora (such as wikipedia, brown, etc).

In addition to being a more ""tractable"" data set (yet still containing the nuances of language); this would also cut down on nlp iteration time.

For example, I would like to create ""thought vectors"" using an encoder decoder LSTM framework. To derive good ""thought vectors"" for sentences, takes a lot of training data. However, if we stuck to children's books where sentences are simpler/shorter, it may be possible to generate good thought vectors with less data, and in less time.",8,3
69,2016-1-4,2016,1,4,19,3ze9qt,Bidirectional-RNN example with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/3ze9qt/bidirectionalrnn_example_with_tensorflow/,malleus17,1451903127,,6,13
70,2016-1-4,2016,1,4,19,3zeatt,What is the best learning algorithm for highly structured data?,https://www.reddit.com/r/MachineLearning/comments/3zeatt/what_is_the_best_learning_algorithm_for_highly/,ycyoon,1451903898,"What is the best learning algorithm for highly structured data such as ""Titanic : Machine Learning from Disaster"" from kaggle?
",0,0
71,2016-1-4,2016,1,4,19,3zebed,"20% off tickets to upcoming Deep Learning Summits in San Francisco, Boston, London &amp; Singapore (includes Startup/Student passes)",https://www.reddit.com/r/MachineLearning/comments/3zebed/20_off_tickets_to_upcoming_deep_learning_summits/,reworksophie,1451904255,,0,1
72,2016-1-4,2016,1,4,21,3zeiz9,[MachineLearning] Base profiles unmarried women age 23 online. The base is available only 2 hours. ID:idgng,https://www.reddit.com/r/MachineLearning/comments/3zeiz9/machinelearning_base_profiles_unmarried_women_age/,drovsub80473,1451908995,,2,0
73,2016-1-4,2016,1,4,22,3zeok3,Image detection: from pictures to cartoons,https://www.reddit.com/r/MachineLearning/comments/3zeok3/image_detection_from_pictures_to_cartoons/,mcostalba,1451912462,"A net trained on real pictures to detect cats, would be able to detect (without additional train) also cartoons and silhouettes of cats? There is some reference to this?
IMO this is interesting because it means the net is able to abstract out the essence of the objects it was trained on.
",8,0
74,2016-1-4,2016,1,4,22,3zeoto,Is there active research going on in theoretical machine learning?,https://www.reddit.com/r/MachineLearning/comments/3zeoto/is_there_active_research_going_on_in_theoretical/,bluezink,1451912607,Both inside and outside of academia?,2,0
75,2016-1-4,2016,1,4,22,3zeq9i,Free machine learning app for the blind identifies objects and colors without internet.,https://www.reddit.com/r/MachineLearning/comments/3zeq9i/free_machine_learning_app_for_the_blind/,[deleted],1451913429,[deleted],0,1
76,2016-1-4,2016,1,4,22,3zeqsa,Deep Learning with Python: An introduction to the Keras library,https://www.reddit.com/r/MachineLearning/comments/3zeqsa/deep_learning_with_python_an_introduction_to_the/,preinventedwheel,1451913703,,0,10
77,2016-1-4,2016,1,4,22,3zesoy,"Ta krma eleme,konkasr ve beton santrali imalat",https://www.reddit.com/r/MachineLearning/comments/3zesoy/ta_krma_elemekonkasr_ve_beton_santrali_imalat/,generalmakina,1451914690,,3,0
78,2016-1-4,2016,1,4,22,3zet6i,Free machine learning app identifies almost any object and colors without using the internet.,https://www.reddit.com/r/MachineLearning/comments/3zet6i/free_machine_learning_app_identifies_almost_any/,Paradigm_shifting,1451914907,,32,222
79,2016-1-4,2016,1,4,23,3zezx2,Tool to Accelerate Convolutional Neural Networks by Decomposition,https://www.reddit.com/r/MachineLearning/comments/3zezx2/tool_to_accelerate_convolutional_neural_networks/,antinucleon,1451918165,,2,4
80,2016-1-4,2016,1,4,23,3zf2hm,"Anyone Do or Doing Udacity's Machine Learning ""Nanodegree""?",https://www.reddit.com/r/MachineLearning/comments/3zf2hm/anyone_do_or_doing_udacitys_machine_learning/,AndreNowzick,1451919360,"I'm looking to get into machine learning, implementing it (currently a full stack javascript developer) &amp; hopefully build a career in it. Don't know much besides the actual science behind machine learning  all I know is that machine learning sounds cool as heck. I have a degree in math, biology (neuroscience courses taken), and economics, &amp; starting Georgia Tech's online Master's in Computer Science this Spring 2016. 

From: https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009

**The program says that program graduates will be able to:**

*Analyze the class and complexity of a given problem, and identify an appropriate algorithm and/or tools to apply towards solving it (e.g. gesture recognition, robot control).*

*Design an intelligent system that can act on the basis of input data towards optimizing some desired goal metric, with minimal supervision from a human.*

*Analyze the performance of an intelligent algorithm / system and present key metrics (such as accuracy, recall, computing time, etc. as appropriate) in an easy-to-understand and visually appealing form Handle the entire machine learning pipeline, from data to system:*

*Gather, clean, and process large data sets to prepare them for analysis*

*Develop multiple models to describe the data in those sets, validate those models, and compare those models according to standard metrics*

*Convert the data model into a live system that can process and reach conclusions on real data*

*Optimize the system based on real-world constraints, such as desired accuracy, efficiency, resource availability, and real-time responsiveness*

*Deploy the system in a live environment, such as an autonomous car, a recommender system, or a personal assistant.*

Udacity says that it will take **about 450500 hours to complete the program** so it sounds pretty immersive. I think the program is relatively new so I'm guessing not many people have completed it. 

Are there any other programs that might be worth looking into? I have trouble learning on my own without some guidance, and generally I find textbooks hard to read if I don't know what I'm doing. ",15,5
81,2016-1-5,2016,1,5,0,3zfb5r,Engine ODBC Code and Paccident,https://www.reddit.com/r/MachineLearning/comments/3zfb5r/engine_odbc_code_and_paccident/,surfer_brett,1451922978,"Previously posted to askStatistics 
I have the following data set... and drawing a blank on how to analyze in SAS. I have a list of engine ODBC codes as well as age of car. For each entry of engine ODBC (abc, abd, xyz, etc.) code as well as age of car (age of car is categorical in this case as it's a range, 0-2, 2-4, 4-8, &gt;8 yrs) I've got count data for how many times that code has shown up as well as if it showed up how many times it was related to an accident. 
I'm looking for combinations of code and age that yield the highest percentage of having been in an accident, and the right set of statistics to show that. 
I had thought about a Poisson regression but the model doesn't seem to converge (I believe its because there are a large number of combinations of factors that have no accident relationships).
The only other tool in my tool box is just the straight proportions of accidental/all codes for each combination that exists and a confidence interval around that. Then I'd like some sort of scoring statistic between the two (probability and confidence around that probability) which would allow me to prioritize the investigation of new codes. 
I'm wondering what the appropriate type of regression on the set looking for these factors and levels.  Any thoughts on how to get started? 
ETA: If a Poisson regression had worked out cleanly, I would have taken ODBC codes and Ages with the highest Odds Ratios to investigate first in the future.",0,0
82,2016-1-5,2016,1,5,0,3zfb8z,Reinforcement Learning Neural Turing Machines (paper+code),https://www.reddit.com/r/MachineLearning/comments/3zfb8z/reinforcement_learning_neural_turing_machines/,samim23,1451923014,,2,18
83,2016-1-5,2016,1,5,3,3zfxza,Using pre-trained models,https://www.reddit.com/r/MachineLearning/comments/3zfxza/using_pretrained_models/,MarcoROG-SG,1451931910,"I've seen many people that in their projects tend to use ""famous"" architectures (like Inception network) already trained, so importing pre-existing and pre-trained weights.
My question is: where to find such models?
In which format are they usually? ",4,1
84,2016-1-5,2016,1,5,3,3zfzlo,Facebook's Data Science Timeline - DataEDGE 2013,https://www.reddit.com/r/MachineLearning/comments/3zfzlo/facebooks_data_science_timeline_dataedge_2013/,virtualjd2015,1451932503,,0,2
85,2016-1-5,2016,1,5,5,3zgdqt,Implementing Peephole Design in Skip Connections Between Stacked RNNs,https://www.reddit.com/r/MachineLearning/comments/3zgdqt/implementing_peephole_design_in_skip_connections/,[deleted],1451937754,[deleted],0,1
86,2016-1-5,2016,1,5,5,3zgfdy,"Is admissions into MS Statistics programs getting increasingly difficult due to the popularization of ""data science""?",https://www.reddit.com/r/MachineLearning/comments/3zgfdy/is_admissions_into_ms_statistics_programs_getting/,jl5892389621,1451938395,,8,0
87,2016-1-5,2016,1,5,5,3zgliw,metaphor with word2vec,https://www.reddit.com/r/MachineLearning/comments/3zgliw/metaphor_with_word2vec/,swampsofjersey,1451940640,has anyone come across any interesting work done on metaphor with word2vec (or doc2vec) tools? I'm doing some research on the topic and figured I might query the readers here.,9,5
88,2016-1-5,2016,1,5,6,3zgrci,Pos Tagging,https://www.reddit.com/r/MachineLearning/comments/3zgrci/pos_tagging/,WilliamWallace,1451942856,What are common datasets used for POS Tagging today? A brief literature review returns mostly older papers.,1,2
89,2016-1-5,2016,1,5,6,3zgrq6,Suggestions for online training image recognition?,https://www.reddit.com/r/MachineLearning/comments/3zgrq6/suggestions_for_online_training_image_recognition/,st553,1451943017,"Hi all,

Many of the libraries I've looked at for image recognition involve offline training a neural net (mnist or cifar datasets are popular examples). But Im wondering if anyone has any experience training a model online with the ability to add new classes?

Ideally, I'd like to train a model on an existing set of images and labels. But, I'd like to be able to input new images/labels over time without retraining the model from scratch. 

thanks for any tips",3,2
90,2016-1-5,2016,1,5,6,3zgsy8,Advice about analyzing Neural Network performance,https://www.reddit.com/r/MachineLearning/comments/3zgsy8/advice_about_analyzing_neural_network_performance/,slow_one,1451943466,"I'm starting to use the Matlab Neural Network Toolbox to classify some data.  
I believe I have my code training and classifying data properly.  My question is on how to tell if the results are ""good"" or not.  
I can look at the error histogram and see that most of my samples are bunched around the ""Zero Error"" line... and when looking at the graph of my ""Train"", ""Validation"" and ""Test"" data, they seem to follow and converge on each other.  I also don't really know how to compare these results with a slightly different set of data to see/ compare results between two different networks.  

I've found [this](http://www.mathworks.com/help/nnet/ug/analyze-neural-network-performance-after-training.html) link, but is the linear regression *really* the way to do this?  What does the ""R"" value mean, really (yes, I see that if R = 1, then there is an exact relationship between outputs and targets... so I want R as close as possible to 1 as I can get?)

So I guess my questions are:  

* How do I tell what the overall performance is (ie, how ***""good""*** the network is)?  
* How do I compare two different sets of training data/ two different networks to see which is ***""better""***?  
* Is comparing R values (from the regression between outputs and targets) the method to do this analysis?

Thank you",11,3
91,2016-1-5,2016,1,5,7,3zh0sf,10 Amazing Facts You Should Know About Internet of Things,https://www.reddit.com/r/MachineLearning/comments/3zh0sf/10_amazing_facts_you_should_know_about_internet/,shugert,1451946416,,0,0
92,2016-1-5,2016,1,5,8,3zh7s4,Tried the image classification app with pretty funny results,https://www.reddit.com/r/MachineLearning/comments/3zh7s4/tried_the_image_classification_app_with_pretty/,heltok,1451949136,,2,11
93,2016-1-5,2016,1,5,8,3zhc3z,Does anybody know of a Human Chat Dataset?,https://www.reddit.com/r/MachineLearning/comments/3zhc3z/does_anybody_know_of_a_human_chat_dataset/,butWhoWasBee,1451950847,"Does anybody know of any free conversational datasets, preferably real conversations between humans as opposed to artificial ones. ",5,3
94,2016-1-5,2016,1,5,9,3zhl5w,Anyone interested in Fantasy Football (soccer)? QA tool,https://www.reddit.com/r/MachineLearning/comments/3zhl5w/anyone_interested_in_fantasy_football_soccer_qa/,fantasyfootballfix,1451954337,,3,1
95,2016-1-5,2016,1,5,10,3zhpdn,To what extent are Kaggle competitions determined by variance?,https://www.reddit.com/r/MachineLearning/comments/3zhpdn/to_what_extent_are_kaggle_competitions_determined/,westsideworld,1451956083,"With the very close scores on the leaderboards of a number of the Kaggle competitions, I was curious how much of the private leaderboard results are determined by variance in the test set?

I noticed that for some competitions the differences in final scores are very narrow among the top spots, and sometimes remain narrow for a large number of entries.",6,6
96,2016-1-5,2016,1,5,11,3zi435,[1601.00318] A Unified Approach for Learning the Parameters of Sum-Product Networks,https://www.reddit.com/r/MachineLearning/comments/3zi435/160100318_a_unified_approach_for_learning_the/,Calumnusa,1451962065,,0,5
97,2016-1-5,2016,1,5,13,3zig60,"Statistical Learning with Sparsity [Textbook by Hastie, Tibshirani, and Wainwright]",https://www.reddit.com/r/MachineLearning/comments/3zig60/statistical_learning_with_sparsity_textbook_by/,carmichael561,1451967207,,9,64
98,2016-1-5,2016,1,5,13,3zihvk,Simultaneously fitting two functions,https://www.reddit.com/r/MachineLearning/comments/3zihvk/simultaneously_fitting_two_functions/,PR_SRK_LKP,1451968016,"Hello,

Cross posted to /r/statistics.

I'm looking for a bit of insight on how to simultaneously fit two functions to experimental data.  My general approach is to define a suitable cost function (least squares) and then minimize that cost function by iteratively adjusting model parameters (using gradient decent).  This approach was developed by Andrew Ng in his [Machine Learning](http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning) course to fit one function to a set of data.  I would like to make sure that I'm correctly generalizing this approach to simultaneously fit two functions.  

Sorry for hand writing most of the content.....hope it is readable.

[Link to Solution Description](http://imgur.com/a/3nbMF)

My questions:

* Is there a better way to define the cost function for fitting two equations?

* Is it necessary to use feature scaling to keep the order of Y-residual and Z-residual terms comparable in size.  Example: I would imagine some scaling must be required if (lets say) Y data is all on the order of 1 and Z data is all on the order of 100. 

* What is the most simple (or most correct) way to implement feature scaling for this type of problem?

This is the first time I've tried to regress a more complex system.  I'm excited because the approach seems very general (i.e., define a suitable cost function and minimize that cost function using gradient decent).  Any insight, tips, or tricks Reddit has for me are greatly appreciated!!!

Thanks in advance for the help!

JT",4,3
99,2016-1-5,2016,1,5,14,3zimdu,Full NVIDIA Press Event from CES 2016,https://www.reddit.com/r/MachineLearning/comments/3zimdu/full_nvidia_press_event_from_ces_2016/,RogerMexico,1451970061,,1,8
100,2016-1-5,2016,1,5,14,3zimyn,Feedback for sklearn neural network?,https://www.reddit.com/r/MachineLearning/comments/3zimyn/feedback_for_sklearn_neural_network/,Lt_Snuffles,1451970315,"I have seen lot of tutorial of neural network implemented in python. However, none of them are using [sklearn neural network ](http://scikit-learn.org/dev/modules/neural_networks_supervised.html#classification). What is the reason? Does this version have any issues?",3,1
101,2016-1-5,2016,1,5,15,3ziuyx,Is there a efficient (computationally) ConvNet for ImageNet?,https://www.reddit.com/r/MachineLearning/comments/3ziuyx/is_there_a_efficient_computationally_convnet_for/,feedthecreed,1451974198,"I'm seeing a lot of mobile devices (mainly phones) which seem to be running surprisingly good object recognition locally. Is there a **small ConvNet** that gets VGG/GoogleNet-like performance available somewhere?

I don't really care as much about going from a 3% -&gt; 7% error rate on ImageNet if the network is 100x faster to run. Has anyone released the parameters/architecture for a ConvNet that has a chance to run on embedded devices that don't have massive GPUs?",1,1
102,2016-1-5,2016,1,5,15,3zixdw,Microsoft ML Face API Implementation,https://www.reddit.com/r/MachineLearning/comments/3zixdw/microsoft_ml_face_api_implementation/,[deleted],1451975504,[deleted],0,0
103,2016-1-5,2016,1,5,16,3zj4gf,ELI5 Receiver Operating Characteristic?,https://www.reddit.com/r/MachineLearning/comments/3zj4gf/eli5_receiver_operating_characteristic/,Gay_Hat_On_Nun,1451979256,"Could someone give me an explanation of a Receiver Operating Characteristic in regards to how validates binary classifiers? I've taken a look at the Wikipedia page but I'm a bit confused on the basic essence of the concept. Also, what specifically differentiates this from Area Under the Curve?",10,3
104,2016-1-5,2016,1,5,17,3zjccj,[AMA Request] Alex Smola,https://www.reddit.com/r/MachineLearning/comments/3zjccj/ama_request_alex_smola/,titusnicolae,1451983893,,0,20
105,2016-1-5,2016,1,5,18,3zjfzy,What happened to Active Learning?,https://www.reddit.com/r/MachineLearning/comments/3zjfzy/what_happened_to_active_learning/,xristos_forokolomvos,1451986133,"I've been doing some reading for my MSc Thesis and Active Learning seems to be quite effective for reducing the labeling costs. Also, they way I see it, it would really help ML-based smartphone applications to not bug their users every now and then. What do you think?
",19,24
106,2016-1-5,2016,1,5,19,3zjnob,Breaking reddit captcha with 96% accuracy using deep learning(torch code),https://www.reddit.com/r/MachineLearning/comments/3zjnob/breaking_reddit_captcha_with_96_accuracy_using/,matrix2596,1451990541,https://deepmlblog.wordpress.com/2016/01/05/breaking-reddit-captcha-with-96-accuracy/,0,3
107,2016-1-5,2016,1,5,19,3zjoyi,DEEPImagine - Interactive tool to modify your face coming soon.,https://www.reddit.com/r/MachineLearning/comments/3zjoyi/deepimagine_interactive_tool_to_modify_your_face/,wildtales,1451991380,,11,33
108,2016-1-5,2016,1,5,20,3zjqzv,Can a g2.xlarge EC2 instance stream CSGO?,https://www.reddit.com/r/MachineLearning/comments/3zjqzv/can_a_g2xlarge_ec2_instance_stream_csgo/,Figuringoutlifeman,1451992745,[removed],0,0
109,2016-1-5,2016,1,5,21,3zjzkh,Regression task with convolution neural networks,https://www.reddit.com/r/MachineLearning/comments/3zjzkh/regression_task_with_convolution_neural_networks/,keidouleyoucee,1451997807,"I have two questions, a specific one and a general one. 

-- **specific question** --

* Situation:

So I have implemented and tested a convolutional network to predict music tags. The whole system is quite similar to one I had for genre classification except it's regression problem, and the old one worked properly. Therefore I don't think using 2d convnet on STFT or CQT kind of makes sense. 
Currently I have n-dim topic vector for each clip of songs (that might have flaws). Preprocessing the topic is one of the issues I have, but here let's say there are n-dim (n: 3-20) topic vector that should be learned. The elements of the vectors are bounded in [0,1].

* My system: - All layers with ReLU except the last one

    + ((3,3) Convolutional layer + (2,2) MP + Dropout) * num_layer // where num_layer in [4,5,6],
    + Flatten
    + Fully-connected layers with dropout or L1 regulariser
    + output layer with linear activation units.
and loss function is MSE/RMSE. Everything is based on Keras.

* My problem:

The networks converge and then it predicts very, very small vector, almost zero, 1e-2, 1e-3, or even less. So the loss converges to the mean of the label values squared.
First of all I'm worrying the preprocessing of labels, but still, if the data is something can't be learned properly, then the network is supposed to learn to predict the mean of labels to minimise MSE. 

Is there any noticeable issue in my system? I've tried few modifications but really have no idea which one to fix first. I also visualised the convolution layer features (but not the FC layers), which turned out to remain almost the same as it was initiated. What's happening might be only FC layers adapting to predict zero vectors. 


-- **general question** --

There are tons of materials on deep learning with classification but not so many on regression. I've searched few as below.

[cs231n](http://cs231n.github.io/neural-networks-2/) says:
&gt; ""It is important to note that the L2 loss is much harder to optimize than a more stable loss such as Softmax.""
&gt; ""use the L2 but be careful: For example, the L2 is more fragile and applying dropout in the network (especially in the layer right before the L2 loss) is not a great idea.""
which I'm not sure why. 

[Sander](http://benanne.github.io/2014/08/05/spotify-cnns.html) says
&gt; ""Dropout is used in the dense layers for regularization.""
for his successful CNN that learns latent features of music. 

[People in Quora](https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound) says
&gt;  ""to use the proper cost function (MSE) and adapt the network to provide a continous output (this normally means removing the softmax in the output)""
which is I'm doing.

For these things I'd appreciate any help on understanding these. I understand why I should use MSE, I agree that MSE can be unstable because it can be affected by outliers too much, but why not Dropout? Is there anything you'd like to add on these advices? 

All suggestions are welcomed.

(+EDIT: with 24 songs and regularisation/dropout removed I checked it overfits, which means the basic structure makes sense. However it took about 8K epochs to get loss &lt;0.1, it seems bit too slow. Probably because the network is redundant?)

(+EDIT: I modified my networks to
- use LReLU or PReLU for better gradient flowing
- add codes to monitor distributions of the neurons in FC layers
- use binary crossentropy instead of RMSE
- add batch normalization layers for every layers

and combinations of these seems to fix my problem, still long way to go though. Also I'm not sure which of them were the most critical yet. Thanks for the all helps!
",22,3
110,2016-1-5,2016,1,5,23,3zkf1t,Creating an A.I bot from facebook conversations and progressive learning.,https://www.reddit.com/r/MachineLearning/comments/3zkf1t/creating_an_ai_bot_from_facebook_conversations/,whorganicpenistry,1452005008,"I'm using (for a start) me and my girlfriend's facebook messages to teach my bot how to respond. Apart from my bot telling me I'm an asshole for no reason, what other disadvantages would using facebook messages result in?

Also, I am using Python3 to write my bot, as Java would be too long and inefficient, is Python an adequate programming language?

This is my first time on this sub, I read the sidebar and I hope my post is within the guidelines, thank you.",8,7
111,2016-1-6,2016,1,6,0,3zkhp6,SHPED: The Stereo Human Pose Estimation Dataset,https://www.reddit.com/r/MachineLearning/comments/3zkhp6/shped_the_stereo_human_pose_estimation_dataset/,miloq,1452006146,,0,1
112,2016-1-6,2016,1,6,0,3zkhz8,"AskML: If your paper is accepted to a conference, do you have to attend it for the paper to be published?",https://www.reddit.com/r/MachineLearning/comments/3zkhz8/askml_if_your_paper_is_accepted_to_a_conference/,555x,1452006260,,13,1
113,2016-1-6,2016,1,6,0,3zkiln,10 More lessons learned from building real-life Machine Learning systems  Part I,https://www.reddit.com/r/MachineLearning/comments/3zkiln/10_more_lessons_learned_from_building_reallife/,mttd,1452006538,,0,2
114,2016-1-6,2016,1,6,0,3zklzw,"5 More arXiv Deep Learning Papers, Explained",https://www.reddit.com/r/MachineLearning/comments/3zklzw/5_more_arxiv_deep_learning_papers_explained/,mmmayo13,1452007861,,10,22
115,2016-1-6,2016,1,6,0,3zko78,Nvidia PX 2 and DriveNet,https://www.reddit.com/r/MachineLearning/comments/3zko78/nvidia_px_2_and_drivenet/,asymptotics,1452008699,"The Drive PX 2 seems like an [insanely powerful](http://www.theverge.com/2016/1/4/10712634/nvidia-drive-px2-self-driving-car-supercomputer-announces-ces-2016) GPU for real-time deep learning in cars, but one thing that really stood out for me at the CES keynote was DriveNet.  They showed the ability to do robust object recognition in snowy conditions with apparently just a camera (since they only show images as inputs to their network). 

Has this been demonstrated before, in real time? Inclement weather conditions are a major roadblock toward autonomous cars. ",6,4
116,2016-1-6,2016,1,6,1,3zksod,Has anyone successfully implemented AUROC as a loss function for Theano/Lasagne/Keras?,https://www.reddit.com/r/MachineLearning/comments/3zksod/has_anyone_successfully_implemented_auroc_as_a/,nharada,1452010325,"I have a binary classification problem where we expect very low AUROC values (in the range of 0.6-0.75) and I'd like to try optimizing the AUROC directly instead of using binary cross-entropy loss. Has anyone managed to get this to work? I use Keras but I'm willing to dive into the underlying Theano.

On a related note, is this even a good idea? AUROC and error rate are related but it's not necessarily ideal to optimize error rate especially with uneven distributions [1]. However, cross-entropy loss takes probability into account so one would assume it is implicitly optimizing AUROC.

I've found a few papers [2,3] on calculating gradients of the AUROC function, so I think it's doable. However, the implementation would be a big undertaking for something that might not help me at all.

1. http://papers.nips.cc/paper/2518-auc-optimization-vs-error-rate-minimization.pdf
2. http://www.machinelearning.org/proceedings/icml2004/papers/132.pdf
3. http://wwwis.win.tue.nl/~tcalders/pubs/CALDERSPKDD07.pdf",9,2
117,2016-1-6,2016,1,6,1,3zktrm,Choosing a Learning Algorithm for Instance Clustering/Classification,https://www.reddit.com/r/MachineLearning/comments/3zktrm/choosing_a_learning_algorithm_for_instance/,eggnaramoose,1452010721,"First off, I tried to do a quick search of the subreddit and couldn't find any posts that fully answered my question. If there was a recent post like this I apologize.

**TL;DR:** I am trying to find an algorithm that will take instances, I have about 50,000 right now, with about seven integer-valued attributes and cluster them into 2 or 3 groups. The groups represent good, mediocre, and bad instances.

**More Info**
            
Let me back up for a minute and explain the goal of the clustering and classification. Each instance in the dataset is a set of actions which can teach me how to better set up the environment in which the actions occur. 

For example, assume the environment is a level of a video game, and the playback of the player playing the level is the instance. If the player in the level tries to click on an object that does not have an event attached, I would add 1 to the attribute action called, uneventful click. Then when I look at this instance I know that if a player had many uneventful clicks on the same item in the level, that I should probably make that item seem less interactive. I know that if I have an instance with many (10+) uneventful clicks that it is a good instance, while a bad instance would have 1 or less uneventful clicks.

What I do not want to do is look through all 50,000+ instances to look for potential design edits. I would rather develop some sort of learning algorithm that can go through and sort these instances with a decently high level of accuracy.

I also want to be able to classify new instances after they are added to the dataset (i.e. new player finishes the level).

If anyone has any ideas as to what algorithms are best suited for a problem like this, please let me know! 

Thank you!

**EDIT:** I have already implemented a K-Means algorithm that works decently well, but sometimes I am ending up with 1 cluster instead of 2 or 3. Also the results are not always as accurate as I am hoping (about 55% misclassified).",10,0
118,2016-1-6,2016,1,6,1,3zky7j,Train 100+ layers in MNIST using residual neural networks,https://www.reddit.com/r/MachineLearning/comments/3zky7j/train_100_layers_in_mnist_using_residual_neural/,matrix2596,1452012314,,0,1
119,2016-1-6,2016,1,6,3,3zli5i,A 'Brief' History of Neural Nets and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/3zli5i/a_brief_history_of_neural_nets_and_deep_learning/,regalalgorithm,1452019449,,0,14
120,2016-1-6,2016,1,6,4,3zlpr0,What are the most cutting edge things possible with Deep Learning ?,https://www.reddit.com/r/MachineLearning/comments/3zlpr0/what_are_the_most_cutting_edge_things_possible/,Silversparro,1452022061,"We have tried Image Captioning, Speech Recognition, Video to text, Deep Mind's Atari player etc.

What is the most cutting edge application possible as of now using Deep learning ?",4,0
121,2016-1-6,2016,1,6,4,3zlrn4,[1512.09327] Distributed Bayesian Learning with Stochastic Natural-gradient Expectation Propagation and the Posterior Server,https://www.reddit.com/r/MachineLearning/comments/3zlrn4/151209327_distributed_bayesian_learning_with/,Calumnusa,1452022714,,0,5
122,2016-1-6,2016,1,6,4,3zlts6,Poisson in LDA,https://www.reddit.com/r/MachineLearning/comments/3zlts6/poisson_in_lda/,LGTVProblems,1452023421,"In the LDA paper by Blei, the first thing said is:

    LDA assumes the following generative process for each document w in a corpus D:

    1. Choose N  Poisson().

I'm guessing that N is the number of words in the document. But why is it a Poisson distribution? And what is .",5,2
123,2016-1-6,2016,1,6,5,3zlxbe,Best way to include the meaning of text in my text classifier? Latent Semantic Analysis? other options?,https://www.reddit.com/r/MachineLearning/comments/3zlxbe/best_way_to_include_the_meaning_of_text_in_my/,textClassy,1452024627,"So far I've made a fairly useful text classifier based on numerical characteristics of text like word length, sentence length, parts of speech, named entity recognition. What is the best way to further improve my classifier by incorporating the meaning of the text in question? ",1,2
124,2016-1-6,2016,1,6,5,3zm21p,[AMA Request] Richard S. Sutton,https://www.reddit.com/r/MachineLearning/comments/3zm21p/ama_request_richard_s_sutton/,pierrelux,1452026336,"Richard Sutton is largely responsible for developing the ideas behind temporal difference learning (which led to Q-learning), the eligibility traces mechanism, the actor-critic architecture and policy gradient methods. He also co-authored the seminal book ""Reinforcement Learning: An Introduction"" with Andrew Barto. David Silver is one of this PhD student. ",2,67
125,2016-1-6,2016,1,6,6,3zm9am,Yann LeCun: Teaching Machines to Understand Us,https://www.reddit.com/r/MachineLearning/comments/3zm9am/yann_lecun_teaching_machines_to_understand_us/,thedarkseid,1452028859,,2,3
126,2016-1-6,2016,1,6,6,3zm9tt,Efficient Deep Feature Learning and Extraction via StochasticNets,https://www.reddit.com/r/MachineLearning/comments/3zm9tt/efficient_deep_feature_learning_and_extraction/,andrewbarto28,1452029050,,1,4
127,2016-1-6,2016,1,6,6,3zmf3o,Online machine learning course study group?,https://www.reddit.com/r/MachineLearning/comments/3zmf3o/online_machine_learning_course_study_group/,i_still_use_ie,1452030894,"Hi! Newcomer to this subreddit who is interested in machine learning. I recently started an online introductory course for machine learning offered by Caltech and was wondering if there were people in the sub who would be interested in forming a weekly study group to bounce ideas and help each other learn and stay motivated.

[Course](https://work.caltech.edu/telecourse.html)

EDIT: Just created a private subreddit, [/r/mlstudygroup/](https://www.reddit.com/r/mlstudygroup/) for the study group. Feel free to PM me and ask me to join!

EDIT2: Also please PM me your e-mail and I will happily add you to our Slack channel, which will be our main source of collboration.",7,3
128,2016-1-6,2016,1,6,7,3zmggy,What to do when training error is decoupled from the last layer?,https://www.reddit.com/r/MachineLearning/comments/3zmggy/what_to_do_when_training_error_is_decoupled_from/,[deleted],1452031377,[deleted],1,2
129,2016-1-6,2016,1,6,8,3zmspz,"EasyTensorflow - Enabling simple building, training, and testing of tensorflow-based neural networks.",https://www.reddit.com/r/MachineLearning/comments/3zmspz/easytensorflow_enabling_simple_building_training/,etf_throwaway,1452035630,,0,0
130,2016-1-6,2016,1,6,10,3znb3i,AI is the next revolution.,https://www.reddit.com/r/MachineLearning/comments/3znb3i/ai_is_the_next_revolution/,bahidev,1452042510,,0,0
131,2016-1-6,2016,1,6,10,3znex1,[MachineLearning] My name is Kiara! I want sex! HELP ME!!!,https://www.reddit.com/r/MachineLearning/comments/3znex1/machinelearning_my_name_is_kiara_i_want_sex_help/,quenant20232,1452043957,,0,0
132,2016-1-6,2016,1,6,11,3znr5c,Solomonoff's Induction in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/3znr5c/solomonoffs_induction_in_machine_learning/,warriortux,1452048745,"Hello,

I was trying to get familiar with Solomonoff's Induction and its Universal Priors. I am wondering whether the Universal Priors can help determine priors in various Probabilistic Machine Learning Algorithms like Latent Dirichlet Allocation? Also, are there any other applications of Solomonoff's Induction in Machine Learning?",6,7
133,2016-1-6,2016,1,6,11,3znrls,TensorFlow is Terrific  A Sober Take on Deep Learning Acceleration,https://www.reddit.com/r/MachineLearning/comments/3znrls/tensorflow_is_terrific_a_sober_take_on_deep/,SuperFX,1452048950,,25,109
134,2016-1-6,2016,1,6,12,3znsml,"""The Future of Consulting: Augmenting Human Intelligence"" #artificialintelligence #machinelearning by Eric L. Miley - @ericmileymba",https://www.reddit.com/r/MachineLearning/comments/3znsml/the_future_of_consulting_augmenting_human/,ericmileymba,1452049370,,0,0
135,2016-1-6,2016,1,6,12,3znul9,Newbie in Neural prog: which OS and HW to choose?,https://www.reddit.com/r/MachineLearning/comments/3znul9/newbie_in_neural_prog_which_os_and_hw_to_choose/,borodatyj,1452050196,"I started to learn basic neural nets concepts and was confused which OS to take for running **python** apps?

1. I have a lot of experience in Unix but I don't want to have a Linux as a host system at my home PC - which Hypervisor,Paravisor soft(Docker, VmWare,VirtualBox) do I need to run for better performance under Windows 10 Host?

2. Do I really need a CUDA-enabled graphic card for running TensorFlow framework code or I can live with my stock integrated Intel core-i5 video?
",6,0
136,2016-1-6,2016,1,6,12,3zo0jk,Installing TensorFlow on an AWS EC2 Instance with GPU Support,https://www.reddit.com/r/MachineLearning/comments/3zo0jk/installing_tensorflow_on_an_aws_ec2_instance_with/,ramhiser,1452052578,,2,8
137,2016-1-6,2016,1,6,13,3zo5xc,My RBM and Backprop implementation in Haskell,https://www.reddit.com/r/MachineLearning/comments/3zo5xc/my_rbm_and_backprop_implementation_in_haskell/,aeyakovenko,1452054785,"I've been trying to understand the contrastive divergence training of RBMs and back-propagation for NNs, so I implemented them in Haskell, and it [works!](https://github.com/aeyakovenko/rbm/blob/master/results/rbm1.gif)  Take a look at [https://github.com/aeyakovenko/rbm](https://github.com/aeyakovenko/rbm).  I would love some feedback.",2,8
138,2016-1-6,2016,1,6,14,3zobcj,Active Learning and Machine Learning in Neuroscience,https://www.reddit.com/r/MachineLearning/comments/3zobcj/active_learning_and_machine_learning_in/,[deleted],1452057077,[deleted],0,1
139,2016-1-6,2016,1,6,14,3zobhy,[TalkingMachines] Active Learning and Machine Learning in Neuroscience,https://www.reddit.com/r/MachineLearning/comments/3zobhy/talkingmachines_active_learning_and_machine/,downtownslim,1452057141,,0,3
140,2016-1-6,2016,1,6,14,3zod8u,what is the bleeding edge of semantic analysis of passages?,https://www.reddit.com/r/MachineLearning/comments/3zod8u/what_is_the_bleeding_edge_of_semantic_analysis_of/,textClassy,1452057916,[removed],0,2
141,2016-1-6,2016,1,6,14,3zodz8,Hashing Feature,https://www.reddit.com/r/MachineLearning/comments/3zodz8/hashing_feature/,Jxieeducation,1452058239,,0,5
142,2016-1-6,2016,1,6,15,3zom1h,"In NLP, how can i measure the parlance between 2 corpora?",https://www.reddit.com/r/MachineLearning/comments/3zom1h/in_nlp_how_can_i_measure_the_parlance_between_2/,yhg0112,1452061955,"hello,

i'm working on NLP with RNNs with various parlances,

and i want to check the differences between the parlance of the result generated from my model and the parlance of my training corpus. 

what would be the efficient measure in this case? 

currently, i'm thinking of cross entropy between the word distributions.

any idea will be welcomed and thankful.",6,0
143,2016-1-6,2016,1,6,16,3zoqhw,Growing Pains for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/3zoqhw/growing_pains_for_deep_learning/,muktabh,1452064374,,0,1
144,2016-1-6,2016,1,6,17,3zoz8w,Char-rnn for super mario levels,https://www.reddit.com/r/MachineLearning/comments/3zoz8w/charrnn_for_super_mario_levels/,x2342,1452069642,,11,36
145,2016-1-6,2016,1,6,17,3zp0sm,Thoughts on Oversampling,https://www.reddit.com/r/MachineLearning/comments/3zp0sm/thoughts_on_oversampling/,xristos_forokolomvos,1452070603,"For a project I'm working on, one of my classes has very few examples. I have tried penalizing the majority class in many ways but it is still pretty dominant. Would you recommend Oversampling? I was thinking of writing an implementation of ADASYN (Adaptive Synthetic Approach for Imbalanced Learning http://bit.ly/22KgAnP) in Python in compliance with the scikit-learn format as I am already familiar with it. Any thoughts / comments?",0,1
146,2016-1-6,2016,1,6,18,3zp20v,How to correctly train RNNs for sequence classification?,https://www.reddit.com/r/MachineLearning/comments/3zp20v/how_to_correctly_train_rnns_for_sequence/,farmmantis,1452071458,"I am trying to build a classifier for time series where i give a number of features to the classifier at each time step and it predicts the output. In my data, the class at a timestep is influenced by classes that have appeared previously. For this reason, ive been trying out rnns (specifically lstms in tensorflow) to try and incorporate some of that temporal goodness in the model. I have minimal experience with NNs and feel I understand the general structure of LSTMs but am still a bit confused by backpropagation through time.

Say I have a number of example series in my training set.
Question 1: Do I need to reset the memory of the network between training with each series? Or do you just pump all the data through and let the model decide what the start and end of a series looks like?

Question 2: Assuming I'm not using truncated BPTT or mini-batch training, is it correct to say that with each timesteps features i put in, the error gradients for all the previous timesteps need to be summed to update the cell states and, therefore, need to be stored or accumulated in some way during training? Im struggling to see in the tensorflow documentation how this works

Question 3: If batches are used for training, should they be constructed as
[t1, t2, t3, t4], [t5, t6, t7, t8]
or
[t1, t2, t3, t4], [t2, t3, t4, t5]
?
The reason i ask is that, as far as i understand, you need the error gradients for t1-t4 to calculate the error gradient for t5. (Not sure if i can assume whatever framework im using does that).",2,3
147,2016-1-6,2016,1,6,19,3zpb0g,Machine Learning Certification | Machine Learning with R Courses,https://www.reddit.com/r/MachineLearning/comments/3zpb0g/machine_learning_certification_machine_learning/,jatingoel,1452077113,,0,1
148,2016-1-6,2016,1,6,21,3zpjx7,Object detection/localization on cpu?,https://www.reddit.com/r/MachineLearning/comments/3zpjx7/object_detectionlocalization_on_cpu/,infstudent,1452082730,"I am a cs student trying to learn a bit about deep vision. In particular I am interested in object detection/localization, and I'd like to play around with open source code in this area.

I found the code for faster R-CNN (https://github.com/ShaoqingRen/faster_rcnn). Unfortunately a GPU seems be required, which I currently don't have. Does anyone know of open source code for object localization (based on a trained neural network) that uses only a cpu?",6,0
149,2016-1-6,2016,1,6,21,3zpkna,PC Build for machine learning and data mining,https://www.reddit.com/r/MachineLearning/comments/3zpkna/pc_build_for_machine_learning_and_data_mining/,new_build,1452083152,"I need to perform local CPU heavy number crunching, multi threaded with large datasets but &lt; 100GB. Python and MATLAB mostly. So I want the best processor I can get with &gt;32GB RAM, &gt;250 SSD, entry level graphics card for now (will upgrade when more GPU processing required - but at minimum want to run two large monitors. I also want at least 2 USB 3.0 ports.

Bufget: 700

So the question is to self build or not. Never attempted to before, but up for the challenge. However I have found the following pre-builts:

http://www.amazon.co.uk/6th-Gen-I7-powerful-Graphics/dp/B016MY1KS8/ref=sr_1_4?s=computers&amp;ie=UTF8&amp;qid=1452078160&amp;sr=1-4&amp;keywords=intel+Core+I7-6700K+PC

http://www.amazon.co.uk/SA51B-8-Quad-Core-Processor-Motherboard-Multimedia/dp/B016YHHC5I/ref=sr_1_56?s=computers&amp;ie=UTF8&amp;qid=1452078313&amp;sr=1-56&amp;keywords=intel+Core+I7-6700K+PC

http://www.amazon.co.uk/Freshtech-Z97X-Game-Motherboard-Vengeance-Performance/dp/B012X1EGGM/ref=sr_1_17?s=computers&amp;ie=UTF8&amp;qid=1452079170&amp;sr=1-17&amp;keywords=i7-4790k+pc+ssd

Has anyone bought a great computer recently that you'd recommend? 

What would I lose out on buying one of the above rather than self building? 

What is the best processor/cost tradeoff? I'd like to build ASAP so not worth waiting for next gen processors unless it's likely to be in next few weeks.

Many thanks!

",20,0
150,2016-1-6,2016,1,6,21,3zpo99,Advanced Outlier detection with R (gives more ideas),https://www.reddit.com/r/MachineLearning/comments/3zpo99/advanced_outlier_detection_with_r_gives_more_ideas/,selva86,1452085093,,0,1
151,2016-1-6,2016,1,6,23,3zq1cn,What type of job should a fresh graduate (B.S.) get?,https://www.reddit.com/r/MachineLearning/comments/3zq1cn/what_type_of_job_should_a_fresh_graduate_bs_get/,TheFlyingDrildo,1452091282,"So I've recently graduated from college with a degree in Biomathematics.  I'd like to get into the field of machine learning, but it seems like every job I look at requires an M.S. at least and preferably a PhD.  I'd like to spend a couple years in industry before I go on to pursue higher education in ML, but I'm really clueless to what type of relevant jobs would be available to someone with only a bachelors.  Even a few jobs I've seen at IBM and whatnot with a minimum of bachelors usually want some x plus years handling NLP, Hadoop experience, etc...  

My programming knowledge at the moment is pretty limited to just coding the models that I needed in college for simulation and some basic linear regression and NN stuff in python, although I have a decent grasp on the theory behind a diverse range of ML algorithms.  I'm working on learning TensorFlow at the moment.  So what type of jobs should someone with my limited experience and education look for if they want to get into this field?  I'm okay with stuff that may not be directly related but will give me applicable knowledge that I can use to get into the field.  Given my degree, I have a bit of a biological/medical lean, but I'm very flexible.  Could anyone give me some suggestions?",3,0
152,2016-1-7,2016,1,7,2,3zqnqt,Deep Learning in Action | Learning an Algorithm [talk by Prof. Jrgen Schmidhuber ],https://www.reddit.com/r/MachineLearning/comments/3zqnqt/deep_learning_in_action_learning_an_algorithm/,muktabh,1452099676,,5,73
153,2016-1-7,2016,1,7,2,3zqoub,Natural Language Processing with Spark on Reddit Comments,https://www.reddit.com/r/MachineLearning/comments/3zqoub/natural_language_processing_with_spark_on_reddit/,dbunkerx,1452100029,,0,2
154,2016-1-7,2016,1,7,2,3zqrys,Miniln 18 r den hurtige vej til penge,https://www.reddit.com/r/MachineLearning/comments/3zqrys/miniln_18_r_den_hurtige_vej_til_penge/,alysonocampoebv,1452101114,,0,1
155,2016-1-7,2016,1,7,2,3zqwbc,Where do Support Vector Machines perform badly?,https://www.reddit.com/r/MachineLearning/comments/3zqwbc/where_do_support_vector_machines_perform_badly/,StepW,1452102555,"Hey! I'm a student who has a university assignment related to SVMs, and in this assignment I am required to attempt running an SVM implementation on data sets that ""expose the strengths and weaknesses of the method"".

I've been doing some research on SVMs and all I find are claims about how state-of-the-art they are, how well they perform, and how sound their theoretical basis is. Beyond being complex and difficult to interpret, I haven't actually found anything regarding scenarios where SVM classification would perform *badly*.

This is where I'm a little stuck. If anyone could help me outline the disadvantages of SVM and shed some light on what kind of data sets SVM would perform poorly in, then that'd be super.

Thanks!",21,15
156,2016-1-7,2016,1,7,2,3zqxu4,Computer model matches humans at predicting how objects move,https://www.reddit.com/r/MachineLearning/comments/3zqxu4/computer_model_matches_humans_at_predicting_how/,stellabot,1452103046,,0,1
157,2016-1-7,2016,1,7,3,3zr7gi,Curriculum Learning In Seq2Seq Models (Scheduled Sampling),https://www.reddit.com/r/MachineLearning/comments/3zr7gi/curriculum_learning_in_seq2seq_models_scheduled/,LeavesBreathe,1452106326,"Hey everyone, 

About 6 months ago, Google reported better results with [scheduled sampling](http://arxiv.org/pdf/1506.03099v3.pdf). The idea looks promising, but there are a few concerns I have.

For normal models, we use E = 1, and use ground truth inputs during decoding. The idea in this paper is to slowly replace these ground truths with generated outputs. This allows the model to recover from making mistakes and not get completely derailed. 

If you notice table 3, they report that starting with a E of 0.25 and ending with E at 0.00 yields the best results. 

How can this possibly be? Wouldn't you think that starting E = 1 and ending at E = 0 would yield the fastest convergence and the lowest testing loss?

Additionally:

- For a linear decay of E, you need to calculate a slope based upon how many epochs you predict it will take your model to converge. If that is the case, how would you predict convergence given that scheduled sampling reportedly decreases convergence time. 

- Has anyone tried inverse sigmoid or exponential decay? I feel that linear would be the safest way to go, but the authors do use inverse sigmoid in some experiments.

Thanks!",0,2
158,2016-1-7,2016,1,7,4,3zr9dz,Internship References in DataMining/ML,https://www.reddit.com/r/MachineLearning/comments/3zr9dz/internship_references_in_dataminingml/,Vainsingr,1452107004,[removed],0,0
159,2016-1-7,2016,1,7,4,3zrefo,"Is it an accurate statement: Natural Language Understanding has been ""somewhat neglected""",https://www.reddit.com/r/MachineLearning/comments/3zrefo/is_it_an_accurate_statement_natural_language/,textClassy,1452108889,http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41117.pdf,3,0
160,2016-1-7,2016,1,7,4,3zreu0,Can anyone explain the Sandblaster L-BFGS?,https://www.reddit.com/r/MachineLearning/comments/3zreu0/can_anyone_explain_the_sandblaster_lbfgs/,Alpha-Cygni,1452109031,"I'm having trouble wrapping my head around the Sandblaster L-BFGS. How often is the entire parameter vector in the same shared memory? What exactly is the purpose of the parameter server? And the coordinator?

Here's the diagram: https://imgur.com/3wmv19x

Here's a link to the original paper: http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf",2,5
161,2016-1-7,2016,1,7,4,3zrf7x,Learning to Segment Object Candidates,https://www.reddit.com/r/MachineLearning/comments/3zrf7x/learning_to_segment_object_candidates/,mcostalba,1452109173,,2,7
162,2016-1-7,2016,1,7,4,3zrfra,Getting started with Machine Learning for a new project,https://www.reddit.com/r/MachineLearning/comments/3zrfra/getting_started_with_machine_learning_for_a_new/,mortalife,1452109366,[removed],3,0
163,2016-1-7,2016,1,7,4,3zrg4v,Automatic Statistician,https://www.reddit.com/r/MachineLearning/comments/3zrg4v/automatic_statistician/,pilooch,1452109503,,3,1
164,2016-1-7,2016,1,7,5,3zrjfv,Startups Promise to Supercharge Deep Learning | MIT Technology Review,https://www.reddit.com/r/MachineLearning/comments/3zrjfv/startups_promise_to_supercharge_deep_learning_mit/,svillafe,1452110728,,0,0
165,2016-1-7,2016,1,7,5,3zroxh,Deep Grammar - a neural net based grammar checker,https://www.reddit.com/r/MachineLearning/comments/3zroxh/deep_grammar_a_neural_net_based_grammar_checker/,SirGolan,1452112686,,9,7
166,2016-1-7,2016,1,7,6,3zruuj,"How would our lives change, if we were able to create a human level general A.I.?",https://www.reddit.com/r/MachineLearning/comments/3zruuj/how_would_our_lives_change_if_we_were_able_to/,christoph_s,1452114740,[removed],9,1
167,2016-1-7,2016,1,7,6,3zrvzf,is there one place I can go to see all machine learning papers? Arxiv catchup maybe?,https://www.reddit.com/r/MachineLearning/comments/3zrvzf/is_there_one_place_i_can_go_to_see_all_machine/,textClassy,1452115128,"http://arxiv.org/catchup
I'm not sure for arxiv catchup would have all of them though ",1,1
168,2016-1-7,2016,1,7,7,3zsb8d,Simple dataset for training Recurrent Neural Network?,https://www.reddit.com/r/MachineLearning/comments/3zsb8d/simple_dataset_for_training_recurrent_neural/,jostmey,1452120177,"I want to code an example of an LSTM neural network from scratch in Julia, like my other examples ([link](https://github.com/jostmey/DeepNeuralClassifier), [link](https://github.com/jostmey/RestrictedBoltzmannMachine)). Can anyone recommend a dataset? I want to be able to run the code on just a CPU, so I don't want to use a dataset that requires lots of parameters. It would be great if I didn't have to resort to using Word2Vec, as this would just add another layer of code.

Thanks!

P.S. Anyone know of any job openings in the Dallas Forth-Worth Area?",6,4
169,2016-1-7,2016,1,7,8,3zsj3x,minimizing MSE in code,https://www.reddit.com/r/MachineLearning/comments/3zsj3x/minimizing_mse_in_code/,teling,1452123086,[removed],2,0
170,2016-1-7,2016,1,7,8,3zsnjn,Master's/MSc Statement of Purpose advice,https://www.reddit.com/r/MachineLearning/comments/3zsnjn/mastersmsc_statement_of_purpose_advice/,[deleted],1452124654,[removed],3,0
171,2016-1-7,2016,1,7,9,3zspco,Why More Bytes Wont Make Your Model Stronger,https://www.reddit.com/r/MachineLearning/comments/3zspco/why_more_bytes_wont_make_your_model_stronger/,blowjobtransistor,1452125303,,4,10
172,2016-1-7,2016,1,7,10,3zt6op,Driving a Car with NeoRL,https://www.reddit.com/r/MachineLearning/comments/3zt6op/driving_a_car_with_neorl/,CireNeikual,1452131782,,15,5
173,2016-1-7,2016,1,7,16,3zujbo,How hard is it to code a RNN for text generation?,https://www.reddit.com/r/MachineLearning/comments/3zujbo/how_hard_is_it_to_code_a_rnn_for_text_generation/,xristos_forokolomvos,1452153283,"I've been working on an idea for a web application on my mind and figured this is the place to ask! I'm gonna need a model that can be trained given some text input (e.g. from one author/poet) and produce texts that are 'convincing enough'. I know there are a lot of out-of-the-box models out there, but what is the workflow you would suggest? 

Are any pre-trained text generation models significantly better than others?

Thanks in advance!",9,0
174,2016-1-7,2016,1,7,18,3zuqde,Machine Learning Specialist: How they can help small businesses?,https://www.reddit.com/r/MachineLearning/comments/3zuqde/machine_learning_specialist_how_they_can_help/,[deleted],1452157780,[deleted],0,1
175,2016-1-7,2016,1,7,18,3zutqb,2 in 1 shrink packing machine,https://www.reddit.com/r/MachineLearning/comments/3zutqb/2_in_1_shrink_packing_machine/,dongfengpacking,1452159849,,1,1
176,2016-1-7,2016,1,7,18,3zutzr,Resources for feature engineering on sound samples,https://www.reddit.com/r/MachineLearning/comments/3zutzr/resources_for_feature_engineering_on_sound_samples/,xbelt,1452160001,"Hi all,

I am currently preparing for a masters thesis and was wondering if any of you could point me to some good papers/book or other scientific material regarding feature engineering on sound samples. The main goal is obviously to extract meaningful features from sound samples.
Thank you :D",3,1
177,2016-1-7,2016,1,7,19,3zuz0d,Automatic stretch wrapping machine,https://www.reddit.com/r/MachineLearning/comments/3zuz0d/automatic_stretch_wrapping_machine/,dongfengpacking,1452163124,,1,1
178,2016-1-7,2016,1,7,20,3zv115,2 heads paste filling machine with conveyor,https://www.reddit.com/r/MachineLearning/comments/3zv115/2_heads_paste_filling_machine_with_conveyor/,dongfengpacking,1452164422,,1,1
179,2016-1-7,2016,1,7,20,3zv4fk,Genetic Algorithms in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/3zv4fk/genetic_algorithms_in_machine_learning/,XalosXandrez,1452166476,"How come one never sees genetic algorithms (GAs) discussed in a machine learning class? Why do I not see either GAs or evolutionary algorithms or neuro-evolution discussed in NIPS/ICML? 

Why do they have their own conference? (http://gecco-2016.sigevo.org/index.html/HomePage) 

What happened? I'd like to know more about this community.",59,66
180,2016-1-7,2016,1,7,21,3zv7rf,PyThor: Python meets R,https://www.reddit.com/r/MachineLearning/comments/3zv7rf/pythor_python_meets_r/,nipun_batra,1452168449,,0,1
181,2016-1-7,2016,1,7,23,3zvrma,Neural Network Sort,https://www.reddit.com/r/MachineLearning/comments/3zvrma/neural_network_sort/,primaryobjects,1452178202,,3,1
182,2016-1-8,2016,1,8,0,3zvuge,Encrypted Data for Efficient Markets - An MNIST for The Stock Market,https://www.reddit.com/r/MachineLearning/comments/3zvuge/encrypted_data_for_efficient_markets_an_mnist_for/,richardcraib,1452179394,,37,12
183,2016-1-8,2016,1,8,0,3zvwog,Understanding LSTM Networks,https://www.reddit.com/r/MachineLearning/comments/3zvwog/understanding_lstm_networks/,Dawny33,1452180283,,0,16
184,2016-1-8,2016,1,8,1,3zw29g,how do i get an intuition for CNNs?,https://www.reddit.com/r/MachineLearning/comments/3zw29g/how_do_i_get_an_intuition_for_cnns/,textClassy,1452182408,[removed],4,1
185,2016-1-8,2016,1,8,1,3zw31j,A sophisticated new vision system for the ISS's robotic helper,https://www.reddit.com/r/MachineLearning/comments/3zw31j/a_sophisticated_new_vision_system_for_the_isss/,[deleted],1452182711,[deleted],0,1
186,2016-1-8,2016,1,8,1,3zw4ki,"Toyota AI Team Hires James Kuffner from Google Robotics, Will Have Rodney Brooks as Adviser",https://www.reddit.com/r/MachineLearning/comments/3zw4ki/toyota_ai_team_hires_james_kuffner_from_google/,InaneMembrane,1452183257,,0,1
187,2016-1-8,2016,1,8,1,3zw4p6,9 free Machine learning datasets,https://www.reddit.com/r/MachineLearning/comments/3zw4p6/9_free_machine_learning_datasets/,TomasKenwood,1452183309,,4,7
188,2016-1-8,2016,1,8,2,3zwcb5,Famous authors datasets,https://www.reddit.com/r/MachineLearning/comments/3zwcb5/famous_authors_datasets/,xristos_forokolomvos,1452186086,[removed],1,0
189,2016-1-8,2016,1,8,2,3zwcuw,what is the state of the art in text classification?,https://www.reddit.com/r/MachineLearning/comments/3zwcuw/what_is_the_state_of_the_art_in_text/,textClassy,1452186292,,7,2
190,2016-1-8,2016,1,8,2,3zwe33,[MachineLearning] Base profiles unmarried age 21+ online. The base is available only 2 hours.,https://www.reddit.com/r/MachineLearning/comments/3zwe33/machinelearning_base_profiles_unmarried_age_21/,renro11558,1452186733,,0,0
191,2016-1-8,2016,1,8,2,3zwh1r,ML libraries for MatLab?,https://www.reddit.com/r/MachineLearning/comments/3zwh1r/ml_libraries_for_matlab/,shakedzy,1452187791,"Hi all!
I'm kind of torn apart between R and MatLab. Personally, I prefer MatLab over R, but R has a major advantage - its packages.
So I was wondering: are there any good ML libraries for MatLab that I can use? Stuff like NN, SVM, K-means, Reinforcement, etc..?
Thanks! ",8,0
192,2016-1-8,2016,1,8,2,3zwlpm,ELI5 Gaussian processes?,https://www.reddit.com/r/MachineLearning/comments/3zwlpm/eli5_gaussian_processes/,radarsat1,1452189406,"Hi, one machine learning model I am struggling to understand is Gaussian processes.  I sort of get what they are, functions of probability over time (or some domain), but apart from that I am having a hard time understanding how they are represented, how they are trained, and what kind of problems they are good for. If I understand correctly there is conceptual connection with Markov models, which I sort of get, as they are like them but continuous in their concept of state -- sort of.  I'm really not sure.  Can anyone ELI5?  Maybe give an example of what and how they are used for modeling, analysis, and prediction?  (As compared to other methods..)",30,17
193,2016-1-8,2016,1,8,2,3zwlu6,"Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism",https://www.reddit.com/r/MachineLearning/comments/3zwlu6/multiway_multilingual_neural_machine_translation/,cesarsalgado,1452189449,,0,5
194,2016-1-8,2016,1,8,3,3zwpe1,Alternatives/Supplements to Tensorboard?,https://www.reddit.com/r/MachineLearning/comments/3zwpe1/alternativessupplements_to_tensorboard/,HelmsmanRobertson,1452190656,"I guess my search skillz have failed me, as I _know_ someone posted a link to a github project that was meant to supplement Tensorboard. Now, for the life of me, I cannot find it. Does anyone know what it was, or have any other suggestions?",1,1
195,2016-1-8,2016,1,8,3,3zwv4s,Applications for AI thinking,https://www.reddit.com/r/MachineLearning/comments/3zwv4s/applications_for_ai_thinking/,canttouchmypingas,1452192613,[removed],0,0
196,2016-1-8,2016,1,8,4,3zwxyr,Popular science book on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/3zwxyr/popular_science_book_on_machine_learning/,sothz,1452193581,"I'm looking for a popular science type book on Machine Learning (or maybe just on modern AI topics in general) - something on the easy reading side of the spectrum rather than a textbook - any recommendations?  (I couldn't see anything obvious in the FAQ resources section, but apologies if I missed it)",2,0
197,2016-1-8,2016,1,8,5,3zxefc,Using Rulefit,https://www.reddit.com/r/MachineLearning/comments/3zxefc/using_rulefit/,SPBLuke,1452199302,"I am about to start a college project using Jerome Friedman's Rulefit which involves Rule Based Learning Ensembles.

The project involved making binary classification and regression on house prices.

There is very little information on this method on the internet other than Friedman's webpage.

http://statweb.stanford.edu/~jhf/R-RuleFit.html

I was wondering if anyone had any experience with this method and could give tips/advice?",2,1
198,2016-1-8,2016,1,8,6,3zxlfn,Should I continue to try and learn Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/3zxlfn/should_i_continue_to_try_and_learn_machine/,NeedToRegisterQuick,1452201721,[removed],2,0
199,2016-1-8,2016,1,8,6,3zxovg,will intermediate steps like POS tagging become less important in NLP as deep learning becomes increasingly used?,https://www.reddit.com/r/MachineLearning/comments/3zxovg/will_intermediate_steps_like_pos_tagging_become/,textClassy,1452202913,some reference slides to give background if people want background: http://ronan.collobert.com/pub/matos/2009_tutorial_nips.pdf,3,1
200,2016-1-8,2016,1,8,7,3zxtrm,Dan Does Data: Theano Installation and Basics,https://www.reddit.com/r/MachineLearning/comments/3zxtrm/dan_does_data_theano_installation_and_basics/,vanboxel,1452204630,,0,0
201,2016-1-8,2016,1,8,7,3zxxk0,Trolling faces.ethz.ch,https://www.reddit.com/r/MachineLearning/comments/3zxxk0/trolling_facesethzch/,themoosemind,1452205962,[removed],1,0
202,2016-1-8,2016,1,8,7,3zxy2z,When the Central Limit Theorem don't apply?,https://www.reddit.com/r/MachineLearning/comments/3zxy2z/when_the_central_limit_theorem_dont_apply/,shakedzy,1452206147,"Hi!
So, according to CLT, given enough data, I should expect to see a Gaussian behavior. This is of course not always true, and there are well described cases if this in statistics literature.
But, from your experience, when data about users fails to obey CLT, what does it usually indicate?",5,0
203,2016-1-8,2016,1,8,7,3zy0fa,Recommender System - Binary Ratings without explicit dislike?,https://www.reddit.com/r/MachineLearning/comments/3zy0fa/recommender_system_binary_ratings_without/,Acterveld,1452206937,"Hi,

I'm currently looking into developing a system in which media from various sources is collected, with the notion that the media collected for each user is media they 'like'. This results in a set of n users, each with their own respective set of m liked items.

Most papers on recommender systems I find either require explicit ratings, or work within a binary domain with likes and dislikes.

How would I go about making recommendations based mainly on what is in a users preferred / liked set, without information on what they dislike?

Thanks.",9,5
204,2016-1-8,2016,1,8,8,3zy4a1,"The Relevance of Machine Learning to Digital Video Creation, Consumption, and Monetization",https://www.reddit.com/r/MachineLearning/comments/3zy4a1/the_relevance_of_machine_learning_to_digital/,joebrilliant,1452208255,,0,1
205,2016-1-8,2016,1,8,10,3zypa7,Apple Buys Artificial-Intelligence Startup Emotient,https://www.reddit.com/r/MachineLearning/comments/3zypa7/apple_buys_artificialintelligence_startup_emotient/,j_lyf,1452216133,,11,34
206,2016-1-8,2016,1,8,11,3zz37v,"In a CNN how do each of the feature extractors (filters) train themselves to detect different features, when they get the same input ?",https://www.reddit.com/r/MachineLearning/comments/3zz37v/in_a_cnn_how_do_each_of_the_feature_extractors/,manjunaths,1452221449,"Sorry if this is a stupid question. In a CNN in the convolution layer, there are multiple feature extractors (filters) and neuron weights are the filter coefficients. The neuron weights are trained.

From [this](http://cs231n.github.io/convolutional-networks/#pool) from the 4th moving diagram when you click on [convolutional layer](http://cs231n.github.io/convolutional-networks/#conv), we see that the filters get the same inputs when training. When the inputs are the same to a neuron and the expected output (supervised learning) is the same. How does each feature extractor evolve to detect different features ? i.e., how is each filter a different filter ?

I tried looking at various tutorials and courses and skimmed through some papers and none of them seem to answer this question. Or maybe I am just being dense.

Can anyone please help me here ?

Thanks for reading.",3,3
207,2016-1-8,2016,1,8,12,3zz7xo,Videos and Slides for Stanford CS231n: Convolutional Neural Networks for Visual Recognition,https://www.reddit.com/r/MachineLearning/comments/3zz7xo/videos_and_slides_for_stanford_cs231n/,evc123,1452223343,,1,55
208,2016-1-8,2016,1,8,12,3zz8dk,Video intro of GPUCC: open source clang-based re-implementation of CUDA nvcc + cuFFT / cuBLAS / cuDNN by Google,https://www.reddit.com/r/MachineLearning/comments/3zz8dk/video_intro_of_gpucc_open_source_clangbased/,SuperFX,1452223520,,7,17
209,2016-1-8,2016,1,8,14,3zzojg,RNNs for questionnaire generation,https://www.reddit.com/r/MachineLearning/comments/3zzojg/rnns_for_questionnaire_generation/,utkarshsimha,1452230530,[removed],1,0
210,2016-1-8,2016,1,8,14,3zzp3q,Vacuum packing machine DZ 400A,https://www.reddit.com/r/MachineLearning/comments/3zzp3q/vacuum_packing_machine_dz_400a/,dongfengpacking,1452230770,,1,1
211,2016-1-8,2016,1,8,14,3zzpbf,LSTM Speed Benchmarks,https://www.reddit.com/r/MachineLearning/comments/3zzpbf/lstm_speed_benchmarks/,anonDogeLover,1452230865,I'm looking for comparisons of deep learning frameworks that include LSTMs. I need to run an LSTM on a massive dataset and need to know which will offer the absolute fastest implementation. Any advice or recommended reading/resources?,1,0
212,2016-1-8,2016,1,8,14,3zzpfs,is there a good way to find angel investors who are knowledgable about machine learning?,https://www.reddit.com/r/MachineLearning/comments/3zzpfs/is_there_a_good_way_to_find_angel_investors_who/,startupGuydude,1452230919,[removed],0,0
213,2016-1-8,2016,1,8,14,3zzryx,(Part II): Deep Reinforcement Learning with Neon,https://www.reddit.com/r/MachineLearning/comments/3zzryx/part_ii_deep_reinforcement_learning_with_neon/,downtownslim,1452232086,,0,8
214,2016-1-8,2016,1,8,14,3zzsl4,PAC learning theory primer,https://www.reddit.com/r/MachineLearning/comments/3zzsl4/pac_learning_theory_primer/,[deleted],1452232399,[deleted],0,1
215,2016-1-8,2016,1,8,15,3zzva2,Coding machine HP 1100,https://www.reddit.com/r/MachineLearning/comments/3zzva2/coding_machine_hp_1100/,dongfengpacking,1452233729,,1,1
216,2016-1-8,2016,1,8,15,3zzzet,metal caps locking machine SMC 980,https://www.reddit.com/r/MachineLearning/comments/3zzzet/metal_caps_locking_machine_smc_980/,dongfengpacking,1452235869,,1,1
217,2016-1-8,2016,1,8,16,400431,induction sealing machine MIS 500,https://www.reddit.com/r/MachineLearning/comments/400431/induction_sealing_machine_mis_500/,dongfengpacking,1452238490,,1,1
218,2016-1-8,2016,1,8,16,4004v3,Auestion about Autoencoders in UFLDL,https://www.reddit.com/r/MachineLearning/comments/4004v3/auestion_about_autoencoders_in_ufldl/,ningyu,1452238910,"hi all, I'm reading UFLDL and I have a question about Autoencoders.

 That is when the dataset is too large to store in memory then we need to do forward propagation twice.  I don't know what's the difference when we do forward propagation twice. 

Could you please explain in more detail?  Thanks!!

Sorry the title is wrong but I haven't find a way to correct it. So if there is such method please tell me . 

Thanks!
The paragraph in the tutorial is below:


 If your data is too large to fit in memory, you may have to scan through your examples computing a forward pass on each to accumulate (sum up) the activations and compute ^i (discarding the result of each forward pass after you have taken its activations a(2)i into account for computing ^i). Then after having computed ^i, youd have to redo the forward pass for each example so that you can do backpropagation on that example. In this latter case, you would end up computing a forward pass twice on each example in your training set, making it computationally less efficient.",1,0
219,2016-1-8,2016,1,8,17,4007ma,Colorizing Black and White photos with deep learning,https://www.reddit.com/r/MachineLearning/comments/4007ma/colorizing_black_and_white_photos_with_deep/,oneweirdkerneltrick,1452240588,,42,351
220,2016-1-8,2016,1,8,17,40099m,FLOPS/$,https://www.reddit.com/r/MachineLearning/comments/40099m/flops/,IgorAce,1452241705,"Today I read about nvidia's $10k super computer meant for self driving carrs: http://techcrunch.com/2016/01/04/nvidia-announces-new-drive-px-2-supercomputer-in-a-lunchbox-for-self-driving-cars/

Then I looked up the cheapest the stats of some powerful graphics cards, and found the radeon 295x2: https://en.wikipedia.org/wiki/AMD_Radeon_Rx_200_series#Radeon_R9_295X2

Nvidia's car ai box performs 8 tFLOPS, but the graphics card does 11.5 tFLOPS... are all flops not equal? You can build a 1k computer with that card and outperform this 10k ""supercomputer"" - what is nvidia's angle?",8,0
221,2016-1-8,2016,1,8,19,400jyy,Is it necessary to normalize the data again after extracting the data from Autoencoder?,https://www.reddit.com/r/MachineLearning/comments/400jyy/is_it_necessary_to_normalize_the_data_again_after/,vinodrajendran001,1452248493,"I used Autoencoder for pre-training the data, for which I normalize the input data and pass into Autoencoder. As a result autoencoder will end up in reducing the number of features (say from 2100 to 128 features).

Now I want to use the output of autoencoder(128 features) for a prediction task. For which, I want to pass the output of autoencoder into a fully feed network.

My question is do I need to Normalize the data again before passing into fully feed network?",4,2
222,2016-1-8,2016,1,8,19,400kxn,Genetic algorithms are not global optimization methods,https://www.reddit.com/r/MachineLearning/comments/400kxn/genetic_algorithms_are_not_global_optimization/,AnvaMiba,1452249102,"I've seen multiple times, in [this](https://www.reddit.com/r/MachineLearning/comments/3zv4fk/genetic_algorithms_in_machine_learning/) recent thread and elsewhere, the claim that genetic algorithms perform global optimization, or at least are less likely to be stuck in bad local optima than gradient-based optimization.

I think this is wrong: genetic algorithms are local optimization methods which essentially consist of a Monte Carlo approximation of gradient-based optimization.

Sexual reproduction (crossover) can sometimes help to escape some kinds of local optima, but it may also consistently fail to advance the optimization proces if the population has already converged to a single local optimum (in which case the offspring is still in the same optimum) or to different local optima (in which case the offspring can be so much worse than the parent that it's immediately culled by the selection process).

It may be argued that in most kinds of genetic algorithms the local optima are metastable, and given enough time the process hits (arbitrarily close to) a global optimum with probability one. This is true but not particularly interesting.  
Gradient descent with random restarts, gradient descent with random noise ([SGLD](http://www.icml-2011.org/papers/398_icmlpaper.pdf)) or even naive random search also have this property. This doesn't make them efficient global optimization methods for most non-trivial optimization problems.  
Moreover, with all these local optimization methods, including GAs, even if you reach a global optimum you have no way to tell (unless you have some domain-specific way of recognizing global optima).

This does not mean that genetic algorithms can't be practically useful, but it shall be noted that they are subject to many of the same issues of other local optimization methods. That is, they will not perform well if the objective function is too rough w.r.t. the solution topology (resulting in many bad local optima) or too flat (resulting in plateaus where process can get lost).

",3,3
223,2016-1-8,2016,1,8,19,400kyf,"Nvidia GPU + CoreOS + Docker + TensorFlow = A Fast, Flexible, Deep Learning Platform",https://www.reddit.com/r/MachineLearning/comments/400kyf/nvidia_gpu_coreos_docker_tensorflow_a_fast/,viklas76,1452249115,,12,26
224,2016-1-8,2016,1,8,21,400ugv,"Machine Learning Summer School '16 in Cadiz, Spain: applications close in 1 week!",https://www.reddit.com/r/MachineLearning/comments/400ugv/machine_learning_summer_school_16_in_cadiz_spain/,musically_ut,1452255047,,0,5
225,2016-1-8,2016,1,8,21,400vcm,Automatic Capsule Filling Machine,https://www.reddit.com/r/MachineLearning/comments/400vcm/automatic_capsule_filling_machine/,Anchormark1,1452255553,,0,1
226,2016-1-8,2016,1,8,21,400y4c,"How would I train a neural network like this? All legs (D, E, F) can act as input and output.",https://www.reddit.com/r/MachineLearning/comments/400y4c/how_would_i_train_a_neural_network_like_this_all/,[deleted],1452257116,[deleted],9,0
227,2016-1-8,2016,1,8,22,4010ep,Recurrent Memory Network for Language Modeling,https://www.reddit.com/r/MachineLearning/comments/4010ep/recurrent_memory_network_for_language_modeling/,SuperFX,1452258426,,3,6
228,2016-1-8,2016,1,8,22,40115t,What is the future of sentiment analysis?,https://www.reddit.com/r/MachineLearning/comments/40115t/what_is_the_future_of_sentiment_analysis/,alivenotions,1452258873,,0,0
229,2016-1-8,2016,1,8,22,4013xc,Convolutional Shape Encoder,https://www.reddit.com/r/MachineLearning/comments/4013xc/convolutional_shape_encoder/,basedgodel,1452260319,,6,17
230,2016-1-9,2016,1,9,0,401kox,Chainer has been added to the popular convnet-benchmarks,https://www.reddit.com/r/MachineLearning/comments/401kox/chainer_has_been_added_to_the_popular/,cesarsalgado,1452267673,,1,11
231,2016-1-9,2016,1,9,0,401l1f,"Review of ""Adversarial Autoencoders"" [ICLR submission]. Summary: something like ""Moment Matching Autoencoders"" may work just as well and would be much simpler.",https://www.reddit.com/r/MachineLearning/comments/401l1f/review_of_adversarial_autoencoders_iclr/,fhuszar,1452267798,,6,17
232,2016-1-9,2016,1,9,0,401mj0,List of companies hiring for deep learning,https://www.reddit.com/r/MachineLearning/comments/401mj0/list_of_companies_hiring_for_deep_learning/,letoseldon,1452268382,"The question ""what companies are hiring interns/full time for deep learning"" pops up here from time to time, and the usual companies are well known (Google, Facebook, Microsoft Research, etc.) but I thought we might compile a more complete list of companies doing vision, NLP, speech recognition, etc.

There's NVidia and Mobileye in automotive (and also the big car manufacturers like Ford).

There's Vicarious and OpenAI which are more research-oriented.

What other companies do you guys know of?",6,4
233,2016-1-9,2016,1,9,1,401run,Machine Learning Libraries in Go Language,https://www.reddit.com/r/MachineLearning/comments/401run/machine_learning_libraries_in_go_language/,virtualjd2015,1452270525,,0,1
234,2016-1-9,2016,1,9,1,401s1k,Efficient Manifold Learning/ Non-linear Dimensionality Reduction Technique,https://www.reddit.com/r/MachineLearning/comments/401s1k/efficient_manifold_learning_nonlinear/,SnowRipple,1452270599,"Hey,

    I am looking for a fairly efficient (when it comes to a big number of samples) Manifold Learning technique. I was using PCA for now but it's linear (I am working with python). I was trying LLE,Isomap,t-sne, spectral embedding but with 100k+ samples I am running out of memory and even after couple days I can't get any results. 

Are there some out-of-sample extensions of these methods implemented in python(or other language)?

I am trying to use random forests with SVD now but results are so so..

Please help,",9,1
235,2016-1-9,2016,1,9,2,401x3o,What are the coolest ML applications in genomic sciences?,https://www.reddit.com/r/MachineLearning/comments/401x3o/what_are_the_coolest_ml_applications_in_genomic/,AleksanderRousing,1452272447,"In your opinion, what are the coolest ML applications in genomic sciences?

A friend who is running a biotech start up has invited me to chat with them about whether or not ML could be useful for them. They're engineering new organisms to produce useful chemicals, but other than that, I don't know much about them.
Since I'm not familiar with ML applications in that field, I thought it could be cool to start with checking out the applications that you dear redditors find most inspiring. So what are they?",8,10
236,2016-1-9,2016,1,9,2,4020ek,State of the art (Dec/2015) natural language processing &amp; natural language generation,https://www.reddit.com/r/MachineLearning/comments/4020ek/state_of_the_art_dec2015_natural_language/,canttouchmypingas,1452273595,"http://arxiv.org/abs/1506.05869 Google did it first (we know) , then the more interesting improvements:

http://arxiv.org/abs/1511.03729 This is an algorithm which better models language semantics in context (helps Google's model) 

http://arxiv.org/abs/1510.08565 This is a conversation model with attention with intention (more human like)

http://arxiv.org/abs/1510.03055 This is showing how using MMI over seq2seq generates more relevant results for sentence generation. 

http://arxiv.org/abs/1511.06440 This improved supervised learning cost functions drastically. 

http://arxiv.org/abs/1512.08301 Another new type of network outperforming rnn's and lstm's.

I recommend you look up neural random access memory, and neural gpu's. There's another conversation model not on arxiv that came out last year. Look into LDM's. 

http://www.sciencedirect.com/science/article/pii/S1877050915036613 This executive function for natural language generation architecture seems to work well also.

I've found others for natural language generation, but not tuned to conversation. There is also a language generation backbone that came out in December by the Chinese, but it seems to be at the point of research where I have no idea what the hell is going on.",14,32
237,2016-1-9,2016,1,9,2,4022ny,Large collection of ML and AI notes,https://www.reddit.com/r/MachineLearning/comments/4022ny/large_collection_of_ml_and_ai_notes/,don_chow,1452274356,,1,15
238,2016-1-9,2016,1,9,2,4023ao,"There is an unexpected effect of neuromorphic learning wireless brain scanner - On touching your brain, you learn to tunnel back into it.",https://www.reddit.com/r/MachineLearning/comments/4023ao/there_is_an_unexpected_effect_of_neuromorphic/,[deleted],1452274575,[removed],4,0
239,2016-1-9,2016,1,9,3,402cyd,Johns Hopkins University Data Science Team doing AMA on January 11th!,https://www.reddit.com/r/MachineLearning/comments/402cyd/johns_hopkins_university_data_science_team_doing/,xIAmSpartacusx,1452277962,"JHU's Data Science Team and creators of the Coursera Data Science Specialization (Brian Caffo, Roger Peng, and Jeff Leek) will be conducting an AMA at 3pm EST Monday over at /r/IAmA! 

Just wanted to let everyone know and hope you all can join us!",3,20
240,2016-1-9,2016,1,9,3,402g7m,Overlooked skills that data scientists need to cultivate,https://www.reddit.com/r/MachineLearning/comments/402g7m/overlooked_skills_that_data_scientists_need_to/,shugert,1452279076,,1,0
241,2016-1-9,2016,1,9,5,4030lk,Machine Learning for Obstacle Avoidance,https://www.reddit.com/r/MachineLearning/comments/4030lk/machine_learning_for_obstacle_avoidance/,awesomeniket,1452286335,"Hi All, I was wondering if anyone here has worked with obstacle avoidance. I am currently working with force field but I know there is better technology out there. I want to incorporate learning to make better intelligent decisions. Clearly supervised learning is the way to go. I have looked up several papers but I am not sure where to start. [This](http://www.cs.cornell.edu/~asaxena/rccar/icml_obstacleavoidance.pdf) paper has been cited a lot but uses a monocular camera. I am using Kinect in a ROS environment. I was hoping to get some guidance from the sages of r/machinelearning. Thanks :)",0,2
242,2016-1-9,2016,1,9,6,4033g9,Are neural networks more effective for datasets with missing values compared with other ML methods?,https://www.reddit.com/r/MachineLearning/comments/4033g9/are_neural_networks_more_effective_for_datasets/,sleepicat,1452287356,Do missing values need to be replaced with some value (like a mean or median) or can a neural network take the dataset with missing values (NaN or None) as is?  Or is it a matter of having a large enough dataset that the missing values can be treated as noise?,2,3
243,2016-1-9,2016,1,9,8,403nhh,GPU-Trained System Understands Movies through Question-Answering (arxiv),https://www.reddit.com/r/MachineLearning/comments/403nhh/gputrained_system_understands_movies_through/,OilofOregano,1452294900,,1,22
244,2016-1-9,2016,1,9,11,404ce4,Powder filling machine,https://www.reddit.com/r/MachineLearning/comments/404ce4/powder_filling_machine/,dongfengpacking,1452305376,,1,1
245,2016-1-9,2016,1,9,11,404f15,Basics Of Artificial Intelligence | Apply Big Analytics,https://www.reddit.com/r/MachineLearning/comments/404f15/basics_of_artificial_intelligence_apply_big/,ApplyBigAnalytics,1452306557,,1,1
246,2016-1-9,2016,1,9,11,404fyb,Manual Sealing Cap machine MSC 110,https://www.reddit.com/r/MachineLearning/comments/404fyb/manual_sealing_cap_machine_msc_110/,dongfengpacking,1452306976,,1,1
247,2016-1-9,2016,1,9,12,404jlp,Semi automatic sealing cap machine SSC 110,https://www.reddit.com/r/MachineLearning/comments/404jlp/semi_automatic_sealing_cap_machine_ssc_110/,dongfengpacking,1452308573,,1,1
248,2016-1-9,2016,1,9,13,404r9m,AMA: the OpenAI Research Team,https://www.reddit.com/r/MachineLearning/comments/404r9m/ama_the_openai_research_team/,IlyaSutskever,1452312107,"The OpenAI research team will be answering your questions.

We are (our usernames are):  Andrej Karpathy (badmephisto), Durk Kingma (dpkingma), Greg Brockman (thegdb), Ilya Sutskever (IlyaSutskever), John Schulman (johnschulman), Vicki Cheung (vicki-openai), Wojciech Zaremba (wojzaremba).


Looking forward to your questions! ",296,373
249,2016-1-9,2016,1,9,14,4053iv,That moment when your weka decision model results are too good to be true!!!,https://www.reddit.com/r/MachineLearning/comments/4053iv/that_moment_when_your_weka_decision_model_results/,surangak,1452317863,"I have the great misfortune of reporting that my machine learning work is producing results that are TOO good to be true..

I'm working with a very imbalanced dataset that's 300 rows by 3000 columns. Initially, the data, including the results class were all binary.  Using weka I did infogain attribute eval to pick the best features, and then did 10 fold cross validation and SMOTE to boost and analyze the results. Of course, this gave me very weak results. 

So, I decided to add in some more data which were numeric and categorical. At this point, thanks to the new data, my dataset was 300 rows by 7000 columns.

Now when I perform the same analysis with SMOTE (100%) my results read..

Correctly Classified Instances         300              100      %
Incorrectly Classified Instances         0                0      %

And this confusion matrix

   a   b   &lt;-- classified as
  279   0 |   a = n
   0    21 |   b = p

*** scratches head ***
*** Looks very worried ***
*** Is it because of my use of info gain with numerical and categorical data? it cant be, because I still get 100% results using chf attribute eval***",4,0
250,2016-1-9,2016,1,9,15,405aks,[MachineLearning] My ex-girlfriend cheated on me with a friend and I decided to post a link on its page with erotic pictures,https://www.reddit.com/r/MachineLearning/comments/405aks/machinelearning_my_exgirlfriend_cheated_on_me/,nesun60813,1452321557,,0,0
251,2016-1-9,2016,1,9,15,405cry,aluminium pressure die casting,https://www.reddit.com/r/MachineLearning/comments/405cry/aluminium_pressure_die_casting/,Adityashah1,1452322785,,0,0
252,2016-1-9,2016,1,9,16,405fon,Need advice: Building Heroku of Autonomous Intelligence,https://www.reddit.com/r/MachineLearning/comments/405fon/need_advice_building_heroku_of_autonomous/,ctwiz,1452324591,"I'm building Playa (http://getplaya.com/) which will serve as the network to connect contracts, transactions, services, and intelligence to robotic and device agents. We're interested to work with people/hobbyists/scientists/engineers in the field, and would really appreciate your advice/input.

If you decide to help us out we'll add you on our contributors page or something if you'd like. We're just trying to build future stuff and would like your input.

I just finished the first touches on the service provisioning and device client libraries. It's a only a coincidence it went live on Blade Runner's Roy Batty's Birthday. :P

My background is in Comp Chem/EE+Robotics, and I'm currently working out of Palo Alto, CA. ",8,0
253,2016-1-9,2016,1,9,16,405hsp,aluminium gravity die casting,https://www.reddit.com/r/MachineLearning/comments/405hsp/aluminium_gravity_die_casting/,Adityashah1,1452325933,,0,0
254,2016-1-9,2016,1,9,18,405o39,aluminium die casting permanent mold casting,https://www.reddit.com/r/MachineLearning/comments/405o39/aluminium_die_casting_permanent_mold_casting/,Adityashah1,1452330266,,0,0
255,2016-1-9,2016,1,9,18,405pz4,A Simple Technique To Learn Hard Stuff (e.g. Machine Learning),https://www.reddit.com/r/MachineLearning/comments/405pz4/a_simple_technique_to_learn_hard_stuff_eg_machine/,mrborgen86,1452331622,,0,1
256,2016-1-9,2016,1,9,19,405ube,Convolutional Neural Networks Basics,https://www.reddit.com/r/MachineLearning/comments/405ube/convolutional_neural_networks_basics/,deepakksingla93,1452334713,,0,0
257,2016-1-9,2016,1,9,20,405yo1,Reason for performance drops during training of RNN?,https://www.reddit.com/r/MachineLearning/comments/405yo1/reason_for_performance_drops_during_training_of/,thorgas,1452337869,"Does someone by any chance recognize [this bahavior](https://i.imgur.com/Wig18kv.jpg) during the training of a recurrent neural network?

UPDATE: I use Keras (Theano based) and my model contains a GRU Layers, 1 Merge Layer and 2 Dense Layers. I'm trying to classify if two sequences have similar properties. This training phase was conducted with a batch size of 256.
(adam is the optimizer I use and binary_crossentropy the loss function)

SOLUTION: Enable gradient clipping (clipnorm/clipvalue) parameters for the optimizer.",9,6
258,2016-1-9,2016,1,9,21,4063dr,sheet music feature representation for LSTM networks,https://www.reddit.com/r/MachineLearning/comments/4063dr/sheet_music_feature_representation_for_lstm/,Pryther,1452341483,"Hi! I have a pretty extensive dataset of monophonic sheet music in musicXML, and I've been meaning to train an LSTM on this dataset for some sequence generation. Nothing scientific, just for fun to see what the network can produce from this dataset. I have a question about the representation of notes for the LSTM.

In the simplest case, a note has a duration and a pitch. This can get a little more complicated (if, for example, I want to indicate where barlines are for the network, tied notes, etc.). How can I properly represent the multiple features of each note in the sequence for the network?

The 'simple' way is just making a very long vector representing all possible combinations as an element, but some notes in the dataset will not be represented often(for example, common notes with uncommon durations), while these notes may be actually very normal. It seems to me the network will be too biased to common combinations, while that might matter less in the dataset.

My first thought to split these is to make the input vector have duration and pitch as information seperately. So for example, a dataset with 3 different pitches and 2 durations would have an input vector of 5 elements, where the first three represent the pitch and the last two the duration. Is this common practice? or are there objections to this method? Are there other ways to go about this?

Any help would be appreciated!

edit: Just to clarify, I am looking for a method of learning sequences where events have multiple features (or, that is what the question boils down to in my mind). Is there any good literature on this?",25,8
259,2016-1-9,2016,1,9,22,40680m,Why isn't CNNs with hinge loss popular? Can we call it a Deep SVM?,https://www.reddit.com/r/MachineLearning/comments/40680m/why_isnt_cnns_with_hinge_loss_popular_can_we_call/,andrewbarto28,1452344841,,11,8
260,2016-1-9,2016,1,9,22,4068m3,MUSIO: A Deep Learning based Chatbot Getting Smarter,https://www.reddit.com/r/MachineLearning/comments/4068m3/musio_a_deep_learning_based_chatbot_getting/,cesarsalgado,1452345255,,1,2
261,2016-1-9,2016,1,9,23,406gvy,Continuous HMM library/Tool for continuous gesture recognition,https://www.reddit.com/r/MachineLearning/comments/406gvy/continuous_hmm_librarytool_for_continuous_gesture/,kahrabji08,1452350034,"There are many HMM tools, but most of them only support discrete density HMM (like Matlab). even the tools that support continuous density HMM can only be used for discontinuous gesture recognition. Am looking for a tool or library that has continuous density hmm function that I can use for continuous gesture recognition. specifically I want to use it for sign language recognition.

Am currently using Georgia Gesture Toolkit (G2TK), but it's old and difficult to use tool. I hope someone will introduce me to a better one.

Thanks",7,7
262,2016-1-10,2016,1,10,1,406y0r,IBM Watson APIs hold key to broader cognitive computing use,https://www.reddit.com/r/MachineLearning/comments/406y0r/ibm_watson_apis_hold_key_to_broader_cognitive/,yourbasicgeek,1452357770,,0,0
263,2016-1-10,2016,1,10,5,407uc9,RBM trained with persistent states and written from scratch in Julia -- 98% on MNIST without fine-tuning,https://www.reddit.com/r/MachineLearning/comments/407uc9/rbm_trained_with_persistent_states_and_written/,jostmey,1452370224,,2,4
264,2016-1-10,2016,1,10,5,407xj4,Hunting for Malware with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/407xj4/hunting_for_malware_with_machine_learning/,Jaycee3Emma,1452371459,,2,12
265,2016-1-10,2016,1,10,6,4082yn,RNN Batch Normalization for GRU/LSTM,https://www.reddit.com/r/MachineLearning/comments/4082yn/rnn_batch_normalization_for_grulstm/,alrojo,1452373546,"The Deep Speech 2 article ( http://arxiv.org/abs/1512.02595 ) presents BN(Batch Normalization) for RNN's(Recurrent Neural Networks). The article uses GRU's(Gated Recurrent Units) for their final model, however, only the vanilla RNN's have the math elaborated (equation 8, section 3.2, bottom of page 6).

How would you extend this to GRU's/LSTM's? My thoughts are to remove the bias units and replace the linear combination of the input, x*w, in every gate/cell with BN(x*w).",14,7
266,2016-1-10,2016,1,10,7,408icw,[MachineLearning] A young girl depraved for the most sophisticated men. 18+,https://www.reddit.com/r/MachineLearning/comments/408icw/machinelearning_a_young_girl_depraved_for_the/,trigid94385,1452379603,,0,1
267,2016-1-10,2016,1,10,7,408jal,Computational requirements of state of the art models,https://www.reddit.com/r/MachineLearning/comments/408jal/computational_requirements_of_state_of_the_art/,MarcoROG-SG,1452379976,"So, I'm quite new to the field and I haven't really worked with huge state of the art networks.
I was wondering what is the computational cost (FLOP) to forward propagate an example in something like AlexNet or Inception network.
Can anyone provide some data or an estimation?

EDIT :I was wondering for example, how much it would take me to forward propagate a minibatch of 256 images on different architectures considering I have a certain graphics card, I know it's really guesstimating, but I just was wondering if it would be milliseconds, seconds or minutes",12,0
268,2016-1-10,2016,1,10,8,408rfc,Questions to Ask When Applying Deep Learning,https://www.reddit.com/r/MachineLearning/comments/408rfc/questions_to_ask_when_applying_deep_learning/,vonnik,1452382936,,0,0
269,2016-1-10,2016,1,10,9,408wmi,Predicting GPS coordinates + timestamp; anything out of the box?,https://www.reddit.com/r/MachineLearning/comments/408wmi/predicting_gps_coordinates_timestamp_anything_out/,chiisana,1452385018,"I'm collecting some location trajectory data in hopes to predict destination and time to arrival for future data points. I've tried to poke around with AWS Machine Learning and H2O.ai, but it seems like the prediction engines can only predict one column of result. If I want to predict 3 data points (timestamp, lat, and lng), do I need to train 3 models with the same dataset, and run through evaluation 3 times (once for timestamp, once for lat, and once for lng), or is there any out of the box solution that could do this kind of prediction?",3,1
270,2016-1-10,2016,1,10,9,408x97,[1512.04407] We Are Humor Beings: Understanding and Predicting Visual Humor,https://www.reddit.com/r/MachineLearning/comments/408x97/151204407_we_are_humor_beings_understanding_and/,downtownslim,1452385262,,3,12
271,2016-1-10,2016,1,10,9,408y8h,Is there anything like photoshop's content-aware fill for texturing 3D objects?,https://www.reddit.com/r/MachineLearning/comments/408y8h/is_there_anything_like_photoshops_contentaware/,DCarrier,1452385680,"I'm working on an Orbiter mod for Homestuck, and it has pictures of the planets, but they only show one side. I'm wondering if there's any way I can take a flat 2D image and use something like content-aware fill to cover a curved surface. I've seen something where someone took a small texture and used that to make a larger one, but it was still flat. I'd like something on a sphere. And it would be interesting to have it for arbitrary surfaces.",2,3
272,2016-1-10,2016,1,10,11,409e45,related reading,https://www.reddit.com/r/MachineLearning/comments/409e45/related_reading/,cupermason,1452392206,[removed],0,0
273,2016-1-10,2016,1,10,11,409g9y,How/where to get started?,https://www.reddit.com/r/MachineLearning/comments/409g9y/howwhere_to_get_started/,[deleted],1452393182,[removed],2,1
274,2016-1-10,2016,1,10,11,409hfo,Hardware?,https://www.reddit.com/r/MachineLearning/comments/409hfo/hardware/,[deleted],1452393659,[deleted],0,0
275,2016-1-10,2016,1,10,11,409iy8,Hardware?,https://www.reddit.com/r/MachineLearning/comments/409iy8/hardware/,Ozanize,1452394349,[removed],2,1
276,2016-1-10,2016,1,10,12,409nmc,Internship interviews?,https://www.reddit.com/r/MachineLearning/comments/409nmc/internship_interviews/,[deleted],1452396348,[removed],1,0
277,2016-1-10,2016,1,10,15,40a7pe,knives tttion! It's nt  Dtig-sit! This is srch prtnrs fr S withut cmmitnt!,https://www.reddit.com/r/MachineLearning/comments/40a7pe/knives_tttion_its_nt__dtigsit_this_is/,elgasdumb22892,1452407269,,0,1
278,2016-1-10,2016,1,10,18,40aol5,Feasibility of applying deep reinforcment learning to clash of clans,https://www.reddit.com/r/MachineLearning/comments/40aol5/feasibility_of_applying_deep_reinforcment/,vanquish46,1452418072,"Hi,

So in with the DeepMind video games the maps are usually always the same, unlike Clash bases which can very widely. Additionally, while the controls are simple in that you mainly just need to drop troops (then their AI takes over), there can be 10-40+ troops to drop depending on the type of attack. An attack lasts 3.5 minutes in real time.

For initial training data I would take war replays from youtube (the largest source), my own attacks and those from my clan wars. I would then set up a private Clash server so I could use many accounts without the actual leveling time. Then I could create or scrape good bases for the learning agents to attack against many times using a few set army compositions. The idea is for the trained agent to be able to take a base and decide which type of army composition is best to use, and ideally where to place troops to make that happen. 

Is it feasible to do this with one GPU? What about four? I have some experience using CNNs for computer vision, but not sure what the boundaries are of learning games.",9,7
279,2016-1-10,2016,1,10,20,40axfn,Are the programming assignments from Andrew Ng's course hard?,https://www.reddit.com/r/MachineLearning/comments/40axfn/are_the_programming_assignments_from_andrew_ngs/,[deleted],1452424194,[removed],11,9
280,2016-1-10,2016,1,10,23,40bi3v,Curious about how to achieve the result of this auto-encoder [Twitter] ?,https://www.reddit.com/r/MachineLearning/comments/40bi3v/curious_about_how_to_achieve_the_result_of_this/,veinpy,1452436580,"I've tried denoising auto-encoder and contractive auto-encoder (both have single hidden layer) for swiss roll dataset.
But none of them could achieve such result twitted by Josh Fass(https://twitter.com/maxentile/status/566037837016227840).
Could someone lead a instruction about it? 
",0,3
281,2016-1-11,2016,1,11,0,40bmct,[Question] Cascaded Random Forest (Baumann et.al.),https://www.reddit.com/r/MachineLearning/comments/40bmct/question_cascaded_random_forest_baumann_etal/,rv77ax,1452438703,"For anyone whose familiar with [Cascaded Random Forests](http://mpeg.tnt.uni-hannover.de/papers/data/977/scia2013_baumann.pdf)[1], I would like your help. I have readed the paper for several times, searched on internet, but still can't grasp the idea of how the algorithm works with **multiclass** classification.

Here is the algorithm that they describe it in their papers : http://i.imgur.com/C97khoB.png?1

Given input,

    S: maximum number of stages
    T: maximum number of tree in each stage
    mintp: threshold for true positive rate
    mintn: threshold for true negative rate

algorithm,

    for 0 &lt;= s &lt; S {
        for 0 &lt;= t &lt; T {
            train single tree
            if (TPs,t &gt; mintp AND TNs,t &gt; mintn)
                stage completed
        }
        calculate weigth w = exp(fmeasure)
        delete true negatives
        refill with false-positives
    }

My questions,

* How do one compute TN from Random Forest? AFAIK, TN = 1 - FP rate. Does not TP = TN? If it so why they need two parameter not just one?
* ~~What would happened if TP &lt; mintp and.or TN &lt; mintn? Does the tree need to rebuild again?~~ Currently, I assume that the algorithm said ""add new tree to the stage until it reached the threshold."", but what happened when maximum trees has reached but TP and TN still below threshold?
* ""delete true negatives"" what to delete? Samples? Stage? Tree?
* ""refill with false-positivies""? I think this answer can be answered if above question is known.

I really appreciate your help. Thank you in advances.

[1] Baumann, Florian, et al. ""Cascaded Random Forest for Fast Object Detection."" Image Analysis. Springer Berlin Heidelberg, 2013. 131-142.",2,13
282,2016-1-11,2016,1,11,1,40bzam,From Simple Regression to Multiple Regression with Decision Trees,https://www.reddit.com/r/MachineLearning/comments/40bzam/from_simple_regression_to_multiple_regression/,DrLegend,1452444184,,0,22
283,2016-1-11,2016,1,11,2,40c2gt,Common Pitfalls of Machine Learning in Production,https://www.reddit.com/r/MachineLearning/comments/40c2gt/common_pitfalls_of_machine_learning_in_production/,virtualjd2015,1452445419,,0,1
284,2016-1-11,2016,1,11,2,40c65e,Trying to learn ML for a specific task but not sure in what direction to move forward?,https://www.reddit.com/r/MachineLearning/comments/40c65e/trying_to_learn_ml_for_a_specific_task_but_not/,shemer77,1452446772,[removed],3,0
285,2016-1-11,2016,1,11,2,40c8yw,[seq2seq] Is bucketing just a Tensorflow quirk? How to choose bucket sizes?,https://www.reddit.com/r/MachineLearning/comments/40c8yw/seq2seq_is_bucketing_just_a_tensorflow_quirk_how/,rhaps0dy4,1452447780,"I have not been able to find info on bucketing other than [Tensorflow Docs](https://www.tensorflow.org/versions/master/tutorials/seq2seq/index.html#bucketing-and-padding). At first glance, it seems unlikely that it's a quirk of the library. You are going to have to pad some sequences if you use minibatches at all. However, if you sort sequences by size and build minibatches in that order, you can minimize the number of pad symbols.

Is having a fixed number of buckets with fixed sizes just a quirk of the Tensorflow API? If not, how to go around it? If so, how to choose optimal, or close to optimal (minimize padding symbols), bucket sizes? Is having a reasonably good bucket size even worth the trouble?

Thank you.",8,9
286,2016-1-11,2016,1,11,3,40chqi,Convolutional Neural Net for Image Classification on CIFAR-10 dataset using Torch,https://www.reddit.com/r/MachineLearning/comments/40chqi/convolutional_neural_net_for_image_classification/,deepakksingla93,1452450994,,5,9
287,2016-1-11,2016,1,11,4,40cto9,Peering into the black box,https://www.reddit.com/r/MachineLearning/comments/40cto9/peering_into_the_black_box/,singhgurjeet,1452455290,,1,0
288,2016-1-11,2016,1,11,5,40d4y7,End-To-End Memory Networks for question-answering tasks with demo,https://www.reddit.com/r/MachineLearning/comments/40d4y7/endtoend_memory_networks_for_questionanswering/,vkhuc,1452459196,,0,7
289,2016-1-11,2016,1,11,6,40d6qp,Tackle the real problem in current machine learning research!,https://www.reddit.com/r/MachineLearning/comments/40d6qp/tackle_the_real_problem_in_current_machine/,redditkeyone,1452459852,[removed],2,1
290,2016-1-11,2016,1,11,7,40dqe5,Tackle the real problem in current machine learning research!,https://www.reddit.com/r/MachineLearning/comments/40dqe5/tackle_the_real_problem_in_current_machine/,redditkeyone,1452466707,"Hey,
I'm really new in the field of machine learning and I am just getting started.

After a bunch of reading, I am realizing that algorithms are mostly public and available for everyone.....
The most important thing seems to be the dataset.s...

So what do we need????
My suggestion is to have an algorithm that is not only capable of distinguishing good data from bad data but also turning bad data into good. 

The algorithm should also be able to link that data to the right algorithm without being said which one it belongs to (unsupervised)

Maybe i am misinformed and there is such an algorithm. In that case I will be glad, if someone post a link to such a paper.",2,0
291,2016-1-11,2016,1,11,8,40dv5v,how do researchers find and understand the very large volume of machine learning papers that are relevant to any given thing they might be working on?,https://www.reddit.com/r/MachineLearning/comments/40dv5v/how_do_researchers_find_and_understand_the_very/,textClassy,1452468415,Machine learning researchers that is,22,45
292,2016-1-11,2016,1,11,8,40e0gn,Advantages of Logistic vs Linear Regression for Classification,https://www.reddit.com/r/MachineLearning/comments/40e0gn/advantages_of_logistic_vs_linear_regression_for/,max_moroz,1452470320,"Many courses claim logistic regression is a better approach for binary classification than linear (for example, [Andrew Ng](https://www.coursera.org/learn/machine-learning/lecture/wlPeP/classification) - around 5 min and [Hastie](https://s3-us-west-1.amazonaws.com/prod-edx/StatLearning/Videos-mp4/StatsLearning+Lect6a+110613.mp4) - around 8 min). But in every case, the argument is based on a toy example where logistic regression works better; of course, it's easy to construct the opposite examples.

Let's say I need to do binary classification and only care about the accuracy of predictions (so no need for probabilities). Either logistic or linear regression can be trained on my training data set, and then used (with a threshold of 0.5) to predict the class.

The only difference between the two is the form of the cost function: for linear regression, it's MSE of the weighted sum of the features, for logistic it's log-loss of the sigmoid of the weighted sum of the features. I suppose from the no free lunch theorem, there is no way to say which classifier is better without some assumptions about the test data set.

So what about typical datasets that makes the second cost function generally more attractive than the first?",10,5
293,2016-1-11,2016,1,11,9,40e4ku,Jupyter Notebook 4.1 released,https://www.reddit.com/r/MachineLearning/comments/40e4ku/jupyter_notebook_41_released/,Eazu,1452471817,,0,4
294,2016-1-11,2016,1,11,11,40eo38,"[MachineLearning] Fight your database his girlfriend, can you change it to another!",https://www.reddit.com/r/MachineLearning/comments/40eo38/machinelearning_fight_your_database_his/,quina58496,1452479757,,0,0
295,2016-1-11,2016,1,11,12,40euwk,what is the lowest risk highest probability path to revenue as an independent machine learning business?,https://www.reddit.com/r/MachineLearning/comments/40euwk/what_is_the_lowest_risk_highest_probability_path/,[deleted],1452482766,[deleted],5,0
296,2016-1-11,2016,1,11,13,40f6et,[Image] - The Most In - Demand Skills for Data Scientist in 2016,https://www.reddit.com/r/MachineLearning/comments/40f6et/image_the_most_in_demand_skills_for_data/,john_philip,1452487926,,9,9
297,2016-1-11,2016,1,11,15,40fhdx,Is pretraining used in state of the art approach to image classification?,https://www.reddit.com/r/MachineLearning/comments/40fhdx/is_pretraining_used_in_state_of_the_art_approach/,[deleted],1452493372,[deleted],3,1
298,2016-1-11,2016,1,11,18,40g4xu,Tackling Set Covering via Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/40g4xu/tackling_set_covering_via_reinforcement_learning/,utxeee,1452505882,"I have been wondering if I could tackle the Set Cover problem via machine learning algorithms, more precisely, by using Reinforcement Learning.

According to my on-going research, I have found that the standard approach for solving this problem is to call on Integer Programming techniques.

Yet, I would like to hear from you about if is it feasible to use RL for solving set covering problem or should I definitely drop this approach?

Note that I do not intend to come up with state of the art results but rather try a new approach to an widely known problem.",9,4
299,2016-1-11,2016,1,11,20,40gcun,Mean absolute error not going down in fully feed forward network,https://www.reddit.com/r/MachineLearning/comments/40gcun/mean_absolute_error_not_going_down_in_fully_feed/,vinodrajendran001,1452510653,"I am trying to  build a prediction model, initially I did Variational Autoencoder and reduced the features from 2100 to 64.

Now having (5000 X 64) samples for training and  (2000 X 64) for testing with that I tried to build a Fully feed forward or MLP network, but as a result  when my mean absolute error reaches 161 it's not going down. I tried varying all hyper-parameters and also the hidden layers but no use.

Can anyone suggest what would be the reason and How I can overcome this problem?",6,0
300,2016-1-11,2016,1,11,20,40gcvd,Introducing Spark Datasets,https://www.reddit.com/r/MachineLearning/comments/40gcvd/introducing_spark_datasets/,[deleted],1452510668,[deleted],0,2
301,2016-1-11,2016,1,11,21,40gj9h,You are all fucking stupid and i hate you all,https://www.reddit.com/r/MachineLearning/comments/40gj9h/you_are_all_fucking_stupid_and_i_hate_you_all/,_violentacrez_,1452514631,[removed],43,0
302,2016-1-11,2016,1,11,22,40gt86,"PSA: Hasti &amp; Tibshirani's free course ""Statistical Learning"" hosted on Stanford Online begins Tuesday (the authors of free book ""The Elements of Statistical Learning"" recommended in the FAQ)",https://www.reddit.com/r/MachineLearning/comments/40gt86/psa_hasti_tibshiranis_free_course_statistical/,henny_mac,1452519981,,22,126
303,2016-1-11,2016,1,11,23,40gvle,Article on Sentiment Analysis using R,https://www.reddit.com/r/MachineLearning/comments/40gvle/article_on_sentiment_analysis_using_r/,padmajatamada,1452521062,,0,0
304,2016-1-11,2016,1,11,23,40h3bo,How difficult is it to reach human-level classification of images?,https://www.reddit.com/r/MachineLearning/comments/40h3bo/how_difficult_is_it_to_reach_humanlevel/,jg8610,1452524381,"In particular, with the advent of significant success in deep learning, is this primarily a data/computing power problem, rather than algorithmic?

And, finally, what are some 'hard' problems that we're still bad at classifying - e.g. watching a video of an accident and saying who's 'fault' it is.",2,1
305,2016-1-12,2016,1,12,0,40h44r,is it a good idea to start a business in machine learning?,https://www.reddit.com/r/MachineLearning/comments/40h44r/is_it_a_good_idea_to_start_a_business_in_machine/,[deleted],1452524692,[deleted],2,0
306,2016-1-12,2016,1,12,0,40h7jy,"The Machine Learning Summer School 2016, applications open until 20th of January",https://www.reddit.com/r/MachineLearning/comments/40h7jy/the_machine_learning_summer_school_2016/,titusnicolae,1452525966,,0,0
307,2016-1-12,2016,1,12,0,40hcg5,Great review papers for neural networks topics?,https://www.reddit.com/r/MachineLearning/comments/40hcg5/great_review_papers_for_neural_networks_topics/,[deleted],1452527774,[deleted],2,0
308,2016-1-12,2016,1,12,1,40hdf9,Training Neural Networks to Generate Crappy Amazon Products,https://www.reddit.com/r/MachineLearning/comments/40hdf9/training_neural_networks_to_generate_crappy/,fatcatz,1452528128,,3,17
309,2016-1-12,2016,1,12,1,40hkz7,Emergent Chip Vastly Accelerates Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/40hkz7/emergent_chip_vastly_accelerates_deep_neural/,dharma-1,1452530819,,6,44
310,2016-1-12,2016,1,12,1,40hluu,"""Recognizing and Localizing Endagered Right Whale with Extremely Deep Neural Networks""",https://www.reddit.com/r/MachineLearning/comments/40hluu/recognizing_and_localizing_endagered_right_whale/,gwern,1452531134,,22,57
311,2016-1-12,2016,1,12,2,40hnhf,An introduction to deep learning with Neural Designer 2.0.,https://www.reddit.com/r/MachineLearning/comments/40hnhf/an_introduction_to_deep_learning_with_neural/,Sergiointelnics,1452531692,,0,5
312,2016-1-12,2016,1,12,2,40hnje,[Beginner's Question] Understanding Deep Learning,https://www.reddit.com/r/MachineLearning/comments/40hnje/beginners_question_understanding_deep_learning/,Kiuhnm,1452531713,"I know nothing about Representation Theory and Lie Groups, but it seems that those branches of mathematics are becoming quite relevant to understanding why and how Deep Learning work.

Do you think learning that stuff is worth the effort?

Thank you!",4,4
313,2016-1-12,2016,1,12,2,40hq1e,Best classifier/framework for real-time multiclass classification of a diverse array of texts?,https://www.reddit.com/r/MachineLearning/comments/40hq1e/best_classifierframework_for_realtime_multiclass/,MWL987,1452532595,"I'm a novice when it comes to machine learning.  My only exposure thus far has been with Keras and building a few very simple LSTM models.

I'm writing a Python application that receives text files as input.  The input can be anything from source code (in a wide array of languages), log files, chat logs, personal correspondence, tweets, random writing, etc.

I'm looking for a way to classify the inputs in real-time, based on a training set that I've hand-labeled.  Each input will only need one label.  What would be the best model to use for this task?  I'm currently looking into naive Bayes and similar classifiers that are often leveraged for spam filtering.  Relatedly, are there any existing Python frameworks that might be useful?

Also, as a second task, I'd like to extract non-regular features from the inputs.  For a lot of the feature extractions I'm using regexes, but I'd like to be able to train a model that could extract features that aren't captured by the regexes.  For example, in a large block of text like a story there'll be embedded one or more types of features like tweets, mathematical formulas, etc. that I'd like to extract based on a training set of labeled examples.  What model could best accomplish this task (preferably in real-time, or else as a batch process) for n types?

Any advice would be greatly appreciated.  Thanks!",1,1
314,2016-1-12,2016,1,12,2,40hqw4,"[ thedivision ] You Can Fun With ature Wmen Now! Full nonymity. NO PAYMENT, NO CADRS! She Writ Yu First!",https://www.reddit.com/r/MachineLearning/comments/40hqw4/thedivision_you_can_fun_with_ature_wmen_now/,elhomen23654,1452532872,,0,1
315,2016-1-12,2016,1,12,2,40hsxm,[Intuitevely] I always read about NNs get stuck in local minimum. Can't we do something to 'shake them out of it' and continue searching for a better minimum?,https://www.reddit.com/r/MachineLearning/comments/40hsxm/intuitevely_i_always_read_about_nns_get_stuck_in/,xristos_forokolomvos,1452533520,title,6,0
316,2016-1-12,2016,1,12,2,40hvqg,sklearn svc behavior,https://www.reddit.com/r/MachineLearning/comments/40hvqg/sklearn_svc_behavior/,FutureIsMine,1452534435,"Training an SVC ovr classifier with an rbf kernel. There are 900,000 samples with 7 features and 39 categories that a given sample can belong to, the data has been scaled to a m =1 and std = 1.  Im noticing that the svm runs for a long time, several hours even and here is the print out Im getting. 

    [LibSVM]............................................................................
    Warning: using -h 0 may be faster
     *.......... (lots and lots of dots omitted)
    Warning: using -h 0 may be faster
From the printout I wonder why is it not generating how well the svm did after iterations, and what is the typical training time of an SVC using an rbf kernel. I get the sense that the answer will differ along a great deal of factors. 
",5,2
317,2016-1-12,2016,1,12,3,40hy6c,The Machine Learning Landscape,https://www.reddit.com/r/MachineLearning/comments/40hy6c/the_machine_learning_landscape/,nyike,1452535250,,0,2
318,2016-1-12,2016,1,12,3,40hz7y,Convolutional hypercolumns in Python,https://www.reddit.com/r/MachineLearning/comments/40hz7y/convolutional_hypercolumns_in_python/,perone,1452535587,,3,20
319,2016-1-12,2016,1,12,3,40i6vw,"Anyone working on hardware (FPGA, ASIC) implementations of Neural Nets?",https://www.reddit.com/r/MachineLearning/comments/40i6vw/anyone_working_on_hardware_fpga_asic/,KG7ULQ,1452538086,"I did some work on implementing an SVM in FPGA 10 years ago. There were several optimizations that I found to shrink the gate count (pre-calculating some lookup tables, for example. Also reducing the number of significant bits while still achieving acceptable classification accuracy). Last year I was involved in a project to implement a NN in an FPGA and was able to use some of the same methods and techniques. It seems like there's a lot of room for optimization when implementing NNs in hardware directly which can reduce power consumption significantly as compared to GPU or CPU while also increasing performance.

Anyway, I'm looking for an ML niche and given my hardware background and knowledge of logic synthesis, etc. this might be a good area for me to focus on.",2,2
320,2016-1-12,2016,1,12,3,40i74s,[MachineLearning] Ex-girlfriend fucks with everyone! I even found it online sex dating.,https://www.reddit.com/r/MachineLearning/comments/40i74s/machinelearning_exgirlfriend_fucks_with_everyone/,svilov47625,1452538169,,0,1
321,2016-1-12,2016,1,12,4,40iapu,why don't abstracts contain more detail about the results?,https://www.reddit.com/r/MachineLearning/comments/40iapu/why_dont_abstracts_contain_more_detail_about_the/,textClassy,1452539354,I find I usually get a good idea of the general area and approach of the paper. Adding a few more sentences about the results would be very useful for readers of many papers.,4,0
322,2016-1-12,2016,1,12,4,40ijq7,Founders of JHU Coursera Data Science AMA starting at 3PM.,https://www.reddit.com/r/MachineLearning/comments/40ijq7/founders_of_jhu_coursera_data_science_ama/,t_rex_tullis,1452542332,,0,3
323,2016-1-12,2016,1,12,5,40io1d,How to use MXNet as a (almost) full function Torch front-end,https://www.reddit.com/r/MachineLearning/comments/40io1d/how_to_use_mxnet_as_a_almost_full_function_torch/,antinucleon,1452543733,,2,5
324,2016-1-12,2016,1,12,5,40ip0v,What machine-learning algorithm should I use ?,https://www.reddit.com/r/MachineLearning/comments/40ip0v/what_machinelearning_algorithm_should_i_use/,[deleted],1452544064,[deleted],0,1
325,2016-1-12,2016,1,12,5,40iqzt,Which algorithm for regression problem on 3D images,https://www.reddit.com/r/MachineLearning/comments/40iqzt/which_algorithm_for_regression_problem_on_3d/,stringerbell78,1452544706,"Hey guys,

here is the setup. My data consist of around N&gt;10000 data (which are 3D images of variable size) and the goal is to predict a scalar value. I have a little bit of knowledge in machine learning although i am very far for being an expert. This problem changes from what I usually know and encounter since :

- The number of features for each of the N data varies. It is equal to the number of voxel (a pixel in 3D) which is the product of the dimension on each axis and is not constant.
- Still I want the alhorithm to be able to ""relate"" between different images each voxel that are closely located. Since I am not sure it is clear, let me explain. Normally for standard algorithm I know (such as random forest, SVM etc...) it will look at each data will have the same number of feature and the feature p of data i is supposed to correspond to feature p of data j. It the setup I want that the algorithm not to look at 'p' but to look at the position (x,y,z) of each point.

Most of machine learning algorithm (convNet for example) working on images use deep learning but I fear that it would not be relevant since:
- it tries to predict a class (such as recognize a cat etc...) whereas I try to predict a value
- it does not really take physical position information as additional input. It will look independently at all the images.

But I am sure that this topic has already been covered in the litterature so I would be happy for any paper/sources/link that talks about similar topic. Also I am working with scikit learn so if there is already working algorithm implemented there it would be perfect :)

Thanks in advance for your help",0,0
326,2016-1-12,2016,1,12,6,40ixam,Element-wise multiplication by a fixed vector in Caffe?,https://www.reddit.com/r/MachineLearning/comments/40ixam/elementwise_multiplication_by_a_fixed_vector_in/,anonDogeLover,1452546795,"I need to create a convnet that multiplies the output of a certain fc layer by a constant vector known in advance. For example, I might have a 4096 dimensional fc6 layer that I want multiplied by a 4096 vector that never changes. It seems like I would use EltwiseLayer for this, but I haven't seen any clear examples of its range of use, especially how to multiply by a static vector.",4,2
327,2016-1-12,2016,1,12,7,40jetm,"Tried PCA Regression, Neural Networks, and Random Forests - all converge on wrong answers. What am I doing wrong?",https://www.reddit.com/r/MachineLearning/comments/40jetm/tried_pca_regression_neural_networks_and_random/,Meowso,1452552839,"I've got a regression problem I'm working on, multiple binary inputs, single continuous output. I've been trying different methods on it, but they all predict a suspiciously similar number (Something like: output1 = 0.0367, output2 = 0.0376, output3 = 0.0345, ... despite the actual target looking something like (0.15, 0.04, 0.05 . . . )). Thich makes me suspect there's something wrong with how I processed the data set. 

Any ideas on what I can do? I didn't normalize the input data, since they were binary. I'm using R packages, namely pls, neuralnet, and randomForest. Thanks in advance for any advice you can give. ",5,2
328,2016-1-12,2016,1,12,8,40jhgm,A curve of machine learning's state of art through years?,https://www.reddit.com/r/MachineLearning/comments/40jhgm/a_curve_of_machine_learnings_state_of_art_through/,Yax42,1452553752,"The state of art of machine learning has been improved a lot this year, but I'm having some difficulties to really understand the magnitude of those progresses. So I was wondering if a curve of the state of art of machine learning through years has ever been done (or anything that would help me improve my understanding)",6,9
329,2016-1-12,2016,1,12,8,40ji55,Question about problems and data sets related to sustainability and climate change,https://www.reddit.com/r/MachineLearning/comments/40ji55/question_about_problems_and_data_sets_related_to/,[deleted],1452553994,[deleted],0,1
330,2016-1-12,2016,1,12,8,40jltp,"Making a text classifier for short texts: Is it likely that a tfidf naive bayes classifier added to a random forest that contains 15 non semantic features (word length, POS, etc) would be incapable of improving performance?",https://www.reddit.com/r/MachineLearning/comments/40jltp/making_a_text_classifier_for_short_texts_is_it/,textClassy,1452555414,I tried this out and it didn't improve performance at all which surprised me. It may be because the texts are so short. Is there a way I can get the naive bayes classifier to classify things only in ways that would add information to the random forest classifier? I don't want to put the tfidf features into the random forest directly because I think it would be too slow,5,1
331,2016-1-12,2016,1,12,8,40jn6l,Great tutorial on hyperopt-sklearn.,https://www.reddit.com/r/MachineLearning/comments/40jn6l/great_tutorial_on_hyperoptsklearn/,bishopxi,1452555949,,0,3
332,2016-1-12,2016,1,12,8,40jo80,Data Mining News To Map Global Inequality,https://www.reddit.com/r/MachineLearning/comments/40jo80/data_mining_news_to_map_global_inequality/,shugert,1452556363,,0,1
333,2016-1-12,2016,1,12,9,40jvn4,Searching for AGI research buddies,https://www.reddit.com/r/MachineLearning/comments/40jvn4/searching_for_agi_research_buddies/,aivoke,1452559166,"TL;DR: Searching for ambitious, friendly and communicative people to learn and exchange on what concepts of (not only limited to) Deep Learning can be used to approximate human level intelligence. Supposed to be a ""private"" research on this topic. However, documentation and publishing of resources is intended as a result of this endeavour.


Hey everyone,
I am very interested in understanding concepts like Deep Learning and I am also interested in human level intelligence. At the moment I am doing some research on my own in order to learn about those topics and to relate them to how they are/can be biologically plausible (for example I am currently reading ""Towards Biologically Plausible Deep Learning"" http://arxiv.org/abs/1502.04156). To improve my understanding I have started documenting my progress. So far I have about 25 pages written in LaTeX with proofs, figures and a custom TikZ template for neural networks. To improve this process I am searching for people with a similar interest and enough energy to exchange and contribute on a regular basis. The major goal is twofold: to improve ones understanding on those topics as far as possible, and secondly to publish some of those results/own explanations in some way s.t. other people can benefit from them, too.


About me: I have written my B.Sc. thesis on General Game Playing and I am doing my M.Sc. in CS with an emphasis on security in Germany. I have finished reading Michael Nielsen's book on Deep Learning and have, after a lot of work, finally understood Backpropagation in detail. One of my next areas of interests would be Reinforcement Learning and looking into the work and results of DeepMind.


Please feel free to contact me via pm if you are an ambitious and goal-oriented person with similar interests and if you are ok with using voice communication to exchange knowledge and ideas :).",0,6
334,2016-1-12,2016,1,12,10,40jz10,list of best places to find inspiration for making classifiers and regressors for your problem,https://www.reddit.com/r/MachineLearning/comments/40jz10/list_of_best_places_to_find_inspiration_for/,textClassy,1452560406,"not in any order:
github, arxiv, http://www.arxiv-sanity.com/, kaggle, http://stats.stackexchange.com/, http://cs.stackexchange.com/, google scholar, google search queries


this is everything I've found so far, does anyone else have any high quality additions?

",1,0
335,2016-1-12,2016,1,12,10,40k2b4,Computer worms!,https://www.reddit.com/r/MachineLearning/comments/40k2b4/computer_worms/,hixidom,1452561549,"I was describing to a friend recently how I imagine AI taking off:

""...In theory, I imagine an algorithm which applies many mutated offspring of itself over the internet in some application. Offspring which are not subsequently able to produce more mutated offspring (or can't do so fast enough) will not survive. The end result is something like a virus which pervades the internet. The strategy of creating mutated offspring or of attaining resources over the internet will be the focus of [perhaps] a reinforcement learning algorithm. Reinforcement learning allows an individual algorithm to learn from it's environment so that it can better meet it's innate goals, while the innate goals themselves evolve through the mutated reproduction process...""

My friend informed me that my idea sounds like a type of computer worm. I wasn't previously familiar with the idea of computer worms, but I looked it up and I thought it was a really beautiful concept: A life form fighting for computer resources while spreading itself, like a more progressive manifestation of the A-life simulation Tierra.

So I was very surprised to read the wikipedia page on Computer Worms, which goes on to describe that both governments and developer communities always consider computer worms to be ""malware"". Is this just a manifestation of people's fear that biological life will one day be surpassed? Do we really think general AI can prosper without the freedom to compete for resources currently reserved for humans?

Please share your opinion on this matter. I don't think I can be convinced that computer worms (or any form of life, for that matter) are inherently evil, but maybe others have additional ideas for how superhuman AI should be allowed to manifest itself and propagate.",3,0
336,2016-1-12,2016,1,12,10,40k8np,How to implement conv layer backprop() method using convolution function for stride &gt; 1.,https://www.reddit.com/r/MachineLearning/comments/40k8np/how_to_implement_conv_layer_backprop_method_using/,andrewbarto28,1452563861,"I know that for strides = 1 I just need to transpose the kernel. But for a kernel of size 3 and stride = 2, it seems that some input neurons are connected to one output neuron and other input neurons are connected to 2. How can I solve this problem?",1,2
337,2016-1-12,2016,1,12,11,40kh35,great summary of deep learning,https://www.reddit.com/r/MachineLearning/comments/40kh35/great_summary_of_deep_learning/,oneweirdkerneltrick,1452567097,,73,499
338,2016-1-12,2016,1,12,12,40kpvc,[NNs] Is reinforcement learning the only way to deal with blackbox error evaluation?,https://www.reddit.com/r/MachineLearning/comments/40kpvc/nns_is_reinforcement_learning_the_only_way_to/,[deleted],1452570527,[deleted],1,1
339,2016-1-12,2016,1,12,14,40l26r,"""The simplified LSTM has significantly fewer parameters than the vanilla LSTM, but achieves similar performance in both objective and subjective evaluations.""",https://www.reddit.com/r/MachineLearning/comments/40l26r/the_simplified_lstm_has_significantly_fewer/,downtownslim,1452575791,,5,7
340,2016-1-12,2016,1,12,14,40l3r0,Anyone heard about these folks Gamalon? (http://gamalon.com/),https://www.reddit.com/r/MachineLearning/comments/40l3r0/anyone_heard_about_these_folks_gamalon/,machdude,1452576486,"Reading up on probabilistic programming and ran into this company's website, has anyone heard anything about them. Seems to be pretty cool [link](http://gamalon.com/).",3,3
341,2016-1-12,2016,1,12,15,40lb3z,First wb-srvice whre mtur fmle loking fmiliarity hr snd mssage first N PYMENTS and anther trsh!!!,https://www.reddit.com/r/MachineLearning/comments/40lb3z/first_wbsrvice_whre_mtur_fmle_loking/,elelmur93611,1452580007,,0,0
342,2016-1-12,2016,1,12,15,40lb42,What shall I know?,https://www.reddit.com/r/MachineLearning/comments/40lb42/what_shall_i_know/,GopiM,1452580009,"Hey GUyz,
I am an 18 years old kid...and got a great interest in AI...I am good with coding(C, C++, JAVA, Python etc) &amp; algorithms. I want to know more about AI and how to develop it. Can you just guide me what are basic requirements before getting into the field of AI.  ",2,0
343,2016-1-12,2016,1,12,15,40lcaz,Does the Kuka Table Tennis robot use machine learning?,https://www.reddit.com/r/MachineLearning/comments/40lcaz/does_the_kuka_table_tennis_robot_use_machine/,themoosemind,1452580620,"I am currently preparing a presentation which aims to give the audience an impression of what machine learning can / cannot do. I remembered http://www.kuka-timoboll.com/ and I've just seen https://www.youtube.com/watch?v=lv6op2HHIuM - Now I wonder if they use machine learning at all.

Does anybody know if there is information available what was used to train the robot?

To clarify: My question is NOT about the glasses-video, but about the table tennis video (https://www.youtube.com/watch?v=tIIJME8-au8).",6,1
344,2016-1-12,2016,1,12,15,40ldq6,Generative Adversarial Networks for Text,https://www.reddit.com/r/MachineLearning/comments/40ldq6/generative_adversarial_networks_for_text/,WilliamWallace,1452581351,What are some papers where Generative Adversarial Networks have been applied to NLP models? I see plenty for images.,22,15
345,2016-1-12,2016,1,12,15,40lebs,when do we have enough data?,https://www.reddit.com/r/MachineLearning/comments/40lebs/when_do_we_have_enough_data/,machdude,1452581689,when data collection is expensive and yet we have several factors how do we decide when we have enough data to regress. Should it be based on model fit? statistical tests on the input data? dimensionality reduction?,2,1
346,2016-1-12,2016,1,12,17,40lq8q,Our paper on unsupervised speech recognition on a small-vocabulary task,https://www.reddit.com/r/MachineLearning/comments/40lq8q/our_paper_on_unsupervised_speech_recognition_on_a/,kamperh,1452588745,,0,7
347,2016-1-12,2016,1,12,18,40lry5,Why can model complexity vary when we don't change the number of model parameters?,https://www.reddit.com/r/MachineLearning/comments/40lry5/why_can_model_complexity_vary_when_we_dont_change/,max_moroz,1452589836,"Reducing k in the kNN, or variance in the RBF kernel, or increasing d in the polynomial kernel all lead to more ""complex"" decision boundaries (in the sense of lower bias and higher variance). I can see how it happens in each example, but I still have the feeling that it's a little strange since we're not increasing the number of free parameters available to the training process - at least not explicitly.

Is there any more intuition to this that might explain why complexity can increase as we vary those hyperparameters? Where's the increase in the effective degrees of freedom come from?

Edit: just thought that maybe these hyperparameters are, in some non-obvious way, related to regularization?",3,3
348,2016-1-12,2016,1,12,19,40lzg9,"Paper(s) on ""automatic song generation from lyrics""",https://www.reddit.com/r/MachineLearning/comments/40lzg9/papers_on_automatic_song_generation_from_lyrics/,koormoosh,1452594955,I am sure this must have been tried/done already by someone from the deep learning community but cannot find any paper/tool related to it. Will be very surprised to know if it hasn't been done yet! Your inputs are much appreciated :),5,1
349,2016-1-12,2016,1,12,19,40lzuk,I implemented a module in python for oversampling skewed datasets. Would love to hear your thoughts on it!,https://www.reddit.com/r/MachineLearning/comments/40lzuk/i_implemented_a_module_in_python_for_oversampling/,xristos_forokolomvos,1452595215,"It is an implementation of the ADASYN algorithm (link to paper: bit.ly/22KgAnP ) and is designed to work along the scikit-learn API. It also includes oversampling for multi-class problems. I ran into the need of an oversampling module that focuses more on examples that are harder to classify, and I said, what the heck... I will implement it on my own. 

Feel free to use it in your projects and if you find any bugs just open an issue, I will be glad to help.

EDIT: forgot the link: https://github.com/stavskal/ADASYN",10,5
350,2016-1-12,2016,1,12,20,40m2gq,Vc dimension decision tree,https://www.reddit.com/r/MachineLearning/comments/40m2gq/vc_dimension_decision_tree/,WoutV_,1452597019,"Hi guys. I'm currently studying for my machine learning exam, and I'm going through old questions. One of them is ""given data consisting of 10 boolean values, what is the VC dimension of the hypothesis set of decision trees with depth 2 or less."" and I'm quite lost on how to solve it. Could you be so kind to provide me with a guide towards the solution? :) 

Thanks ",0,0
351,2016-1-12,2016,1,12,21,40mbec,GFG High Efficient Fluid-Bed Dryer,https://www.reddit.com/r/MachineLearning/comments/40mbec/gfg_high_efficient_fluidbed_dryer/,njsfspraydryer,1452602857,[removed],0,0
352,2016-1-12,2016,1,12,22,40mh6z,Seldon is hiring a data scientist for open source and applied ML projects,https://www.reddit.com/r/MachineLearning/comments/40mh6z/seldon_is_hiring_a_data_scientist_for_open_source/,ahousley,1452606201,,1,0
353,2016-1-12,2016,1,12,23,40mnd8,Convolutional operation doubt,https://www.reddit.com/r/MachineLearning/comments/40mnd8/convolutional_operation_doubt/,fariax,1452609314,"Hello!

I didn't find any paper/tutorial that explains how the convolution in one input with 3 dimensions (ex. Image in RGB) is done.

For example, when I write in keras:
    model.add(Convolution2D(nFilters, height, width))

It will generate 3*nFilters of feature maps?!",2,0
354,2016-1-12,2016,1,12,23,40mofv,Fast policy lookup for real-time RL???,https://www.reddit.com/r/MachineLearning/comments/40mofv/fast_policy_lookup_for_realtime_rl/,gogogadgetlegz,1452609836,"What are the best practices for fast policy lookup in continuous state/continuous action reinforcement learning?  Assume the learning happens off-policy in batch.  What kind of data structure should be created from this learning?

I'm assuming the state/action spaces are somewhat smooth, so perhaps a first step would be locality sensitive hashing to a policy set that fits in RAM.  Then what???

The application might be drone racing for example.",2,1
355,2016-1-13,2016,1,13,0,40mrcf,Adaptive Machine Learning Vision Algorithms,https://www.reddit.com/r/MachineLearning/comments/40mrcf/adaptive_machine_learning_vision_algorithms/,virtualjd2015,1452611185,,0,1
356,2016-1-13,2016,1,13,0,40mycp,Meet the 26-Year-Old Hacker Who Built a Self-Driving Car... in His Garage,https://www.reddit.com/r/MachineLearning/comments/40mycp/meet_the_26yearold_hacker_who_built_a_selfdriving/,bahidev,1452614164,,2,0
357,2016-1-13,2016,1,13,1,40n0ti,"Any good explanations of the formal proof and intuition behind the ""Vanishing Gradients"" problem in RNNs?",https://www.reddit.com/r/MachineLearning/comments/40n0ti/any_good_explanations_of_the_formal_proof_and/,[deleted],1452615146,[deleted],13,8
358,2016-1-13,2016,1,13,1,40n2ge,[need some advice] Deciphering old handwriting. where to start? age-old family documents...,https://www.reddit.com/r/MachineLearning/comments/40n2ge/need_some_advice_deciphering_old_handwriting/,exocortex,1452615801,"Hey /r/machinelearning

I am completely new to the whole topic. I listened to a long podcast explaining a lot of things in neuronal networks (in german though).

6 months ago my grandmother died, leaving behind a house filled with old documents. Sometimes even older than herself. She worked in a newspaper and documented seemingly everything. I was planing on taking a little time of myself, and scanning everything i find. I am especially interested in some diaries of my grandfather whom I never got to know. He was born 1903 and died one year before my birth. But he seemed to have an interesting life. He ran away from home at around 10 years, worked in Dresden in a printershop and later went to spain. He stayed there even during the 2nd world war and became a newspaper correspondent. Later he also was a chief editor of a small newspaper. My grandmother could recount the whole history of newspapers created after WW2. Unfortunately my brain never was spongy enough to take in all the names and dates during the 3hour long lessons. I guess a lot of information is lost now with her gone.

But I am still very much interested in making sense of the documented elements. Lot's of letters of collegues and friends in spain and in the newspaper. And many images also (maybe). There seems to be at least one photo-album of some grand-grand grandfather of mine who was also crazily enthuisiasticly running through the french country during WW1. There are pictures with some french chateaus. and stuff. well back to topic...

 But my first idea was that i wan to to read the diaries. But they are written in [Stterlin](https://en.wikipedia.org/wiki/S%C3%BCtterlin) which I cannot read. (It can also be another one like 'deutsche Kursivschrift' - I have no Idea). When I heard the podcast about recent developements in MachineLearning, I thought, maybe this would be a great application of that. I have no Idea about the whole field of Machine Learning, but Maybe other people would be interested in this also. Maybe even some historians would be interested in this also. (There are tons of other interesting things, but I want to start somewhere).

So what would you do, if you had a bunch of diaries of a person you want to know more of?
My idea would be to first scan everything and somehow (I have to learn a lot) train a model or use a model already trained on deciphering Stterlin OR training a model on deciphering my grandfather's stterlin (maybe there's significant difference between several person's handwriting when it comes to digitizing it.

So If you have any advice for my how to get started, please let me know!
If you are interested in this yourself (maybe you are working on projects that are similar) let me also know! I am not planning on hiding any possible knowledge gained from the world.

thank you!

/u/exocortex



",6,6
359,2016-1-13,2016,1,13,1,40n4ti,Is there any tool for visualizing CNNs architecture?,https://www.reddit.com/r/MachineLearning/comments/40n4ti/is_there_any_tool_for_visualizing_cnns/,GeneralIntelligence,1452616695,"I am looking for some tool for simple architecture visualization for my reports/papers, something, that could produce results similar to http://cs231n.github.io/assets/cnn/cnn.jpeg. I tried searching, but with no luck; is there some tool I could use?",6,6
360,2016-1-13,2016,1,13,3,40noim,Why is boosting unpopular in deep learning?,https://www.reddit.com/r/MachineLearning/comments/40noim/why_is_boosting_unpopular_in_deep_learning/,singularai,1452623424,"This is mostly a survey for those who may have used boosting before deep learning came along (boosting is a strategy where incorrectly classified examples are up-sampled and the learner is retrained)

It seemed to be a very popular trick for traditional machine learning algorithms, but I've never seen it tried w.r.t. deep learning and therefore assume it doesn't work very well. Could someone who has tried boosting comment?

One theory is that boosting is somewhat susceptible to incorrectly labeled data, and the datasets we use in deep learning are simply not as high of quality:

"""""" (https://en.wikipedia.org/wiki/Boosting_(machine_learning)#criticism)
In 2008 Phillip Long (at Google) and Rocco A. Servedio (Columbia University) published a paper[10] at the 25th International Conference for Machine Learning suggesting that many of these algorithms are probably flawed. They conclude that ""convex potential boosters cannot withstand random classification noise,"" thus making the applicability of such algorithms for real world, noisy data sets questionable. The paper shows that if any non-zero fraction of the training data is mis-labeled, the boosting algorithm tries extremely hard to correctly classify these training examples, and fails to produce a model with accuracy better than 1/2.
""""""
",16,16
361,2016-1-13,2016,1,13,3,40nqkh,Which CNN papers visualize the learned features?,https://www.reddit.com/r/MachineLearning/comments/40nqkh/which_cnn_papers_visualize_the_learned_features/,themoosemind,1452624135,"I thought I have seen quite a couple of papers which learned CNN (Convolutional Neural Network) features similar to [1]. Especially for MNIST, if I remember correctly. Often with the claim that you can see how it learned edge detectors. However, I can currently not find the papers. Do you know some papers which visualize learned CNN features?

[1] Vondrick, Carl, et al. ""Hoggles: Visualizing object detection features."" Computer Vision (ICCV), 2013 IEEE International Conference on. IEEE, 2013. [Online] http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6751109",2,0
362,2016-1-13,2016,1,13,3,40nrs1,"Efficient Neural Network, Implemented in Python (NumPy)",https://www.reddit.com/r/MachineLearning/comments/40nrs1/efficient_neural_network_implemented_in_python/,jorgenkg,1452624563,,0,0
363,2016-1-13,2016,1,13,4,40nzgh,Togelius: Why video games are essential for inventing artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/40nzgh/togelius_why_video_games_are_essential_for/,togelius,1452627324,,15,33
364,2016-1-13,2016,1,13,5,40o88g,Show ML: R in Visual Studio - sneak peek,https://www.reddit.com/r/MachineLearning/comments/40o88g/show_ml_r_in_visual_studio_sneak_peek/,smortaz,1452630347,,29,23
365,2016-1-13,2016,1,13,5,40odr8,BilBOWA: Fast Bilingual Distributed Representations without Word Alignments,https://www.reddit.com/r/MachineLearning/comments/40odr8/bilbowa_fast_bilingual_distributed/,maverik_k,1452632241,"The section 6.2 ""describes"" experiments on word translation task. Paper, however, is rather vague about the BilBOWA settings used to achieve the state of the art results.

Default BilBOWA settings were no good, as the resulting embeddings would exhibit problems with hubness (some words in the embedded space were similar to far too many other words). On top of that,  words that had low frequencies in the  parallel corpora but high frequency in the monolingual corpora, would have low cosine similarity with their counterparts in the other language. Words that were frequent in parallel corpora would have high cosine similarity with the words co-occurring in the parallel sentences. 

I tried to contact the main author  to find out what parameter values he used in his experiments, but had no luck with receiving an answer... 

Has anyone managed to reproduce their results? If so, what parameter values for 
-sample, 
-adagrad,  
-xling-lambda,
-epochs,  
-min-count

would be suggested? 

Best, 
MK",3,3
366,2016-1-13,2016,1,13,8,40p085,how many people in the world are spending more than ten hours per week doing machine learning?,https://www.reddit.com/r/MachineLearning/comments/40p085/how_many_people_in_the_world_are_spending_more/,textClassy,1452640050,[removed],2,0
367,2016-1-13,2016,1,13,9,40pas5,Generate poetry from images using convolutional and recurrent neural networks [x/coolgithubprojects],https://www.reddit.com/r/MachineLearning/comments/40pas5/generate_poetry_from_images_using_convolutional/,[deleted],1452644122,[deleted],0,1
368,2016-1-13,2016,1,13,10,40pnz1,Artificial Startup Style: Neural art about startup fashion,https://www.reddit.com/r/MachineLearning/comments/40pnz1/artificial_startup_style_neural_art_about_startup/,jeffksmithjr,1452649278,,0,5
369,2016-1-13,2016,1,13,14,40ql9g,Big Sur expected release date?,https://www.reddit.com/r/MachineLearning/comments/40ql9g/big_sur_expected_release_date/,CheeriosRDonutSeeds,1452663025,"I was wondering if there was any news surrounding the November unveiling of Facebook's plan of open-sourcing Big Sur. Is that still on the cards, and does anyone know when we should expect it?

Link for those that want the reference: https://code.facebook.com/posts/1687861518126048/facebook-to-open-source-ai-hardware-design/",4,5
370,2016-1-13,2016,1,13,14,40qlir,LOL!! here's the new advance useless machine...................,https://www.reddit.com/r/MachineLearning/comments/40qlir/lol_heres_the_new_advance_useless_machine/,Yougez,1452663146,,0,1
371,2016-1-13,2016,1,13,14,40qn0i,49 schools are getting this 3D carving machine for free,https://www.reddit.com/r/MachineLearning/comments/40qn0i/49_schools_are_getting_this_3d_carving_machine/,Geneeniks,1452663817,,0,1
372,2016-1-13,2016,1,13,15,40qpgz,Good literature review for big data?,https://www.reddit.com/r/MachineLearning/comments/40qpgz/good_literature_review_for_big_data/,augustus2010,1452664966,[removed],3,1
373,2016-1-13,2016,1,13,15,40qr8t,FPGA Implementation of a Pulse Density Neural Network With Learning Ability Using Simultaneous Perturbation,https://www.reddit.com/r/MachineLearning/comments/40qr8t/fpga_implementation_of_a_pulse_density_neural/,blowjobtransistor,1452665875,,0,7
374,2016-1-13,2016,1,13,15,40qrj9,My initial Deep Feelings about Deep Learning,https://www.reddit.com/r/MachineLearning/comments/40qrj9/my_initial_deep_feelings_about_deep_learning/,carlos_argueta,1452666015,,33,1
375,2016-1-13,2016,1,13,17,40r4q9,What is Machine Learning and how it is Remaking Our World?,https://www.reddit.com/r/MachineLearning/comments/40r4q9/what_is_machine_learning_and_how_it_is_remaking/,ManishaNM,1452673571,,0,1
376,2016-1-13,2016,1,13,17,40r676,Literature on the differential geometry of neural networks,https://www.reddit.com/r/MachineLearning/comments/40r676/literature_on_the_differential_geometry_of_neural/,yoshiK,1452674444,"I realized recently that the layers of neural networks are smooth mappings of open subsets of vector spaces, so there should be a differential geometry of neural networks. For example I wonder what the pull back of the volume element of the output layer looks like, at least for a suitable notion of pull back. However, I did not find any papers about this and probably lack the right keywords for Google scholar. So can anybody give me a reference or at least the right keywords to start hunting relevant papers? ",17,58
377,2016-1-13,2016,1,13,19,40ric1,Error for multiple outputs?,https://www.reddit.com/r/MachineLearning/comments/40ric1/error_for_multiple_outputs/,Iceri,1452681531,"I'm trying to construct a neural network and was wondering how to go about calculating the error of a neural network with multiple outputs. Any help is appreciated.

EDIT
Thank you for the replies. They have helped me a lot :)",5,1
378,2016-1-13,2016,1,13,21,40rs1q,WSO2 BIGDATAGAME: prediction system for the big Football games,https://www.reddit.com/r/MachineLearning/comments/40rs1q/wso2_bigdatagame_prediction_system_for_the_big/,upulbandara,1452687544,,2,2
379,2016-1-14,2016,1,14,0,40sdn6,How to implement nearest neighbour lookup in a point cloud?,https://www.reddit.com/r/MachineLearning/comments/40sdn6/how_to_implement_nearest_neighbour_lookup_in_a/,londons_explorer,1452697384,"If I have a 1000 dimensional point cloud containing a million points and I want to find out which point is closest to an input, I can calculate the cosine distance between the input point and each one in the cloud and return the smallest.

If I now want to do that for each of a million inputs, it should be easy, requiring no more memory than the inputs, points and outputs, however in all ML frameworks I've found (eg. tensorflow) the intermediate step (ie. the distances from every input to every point) has to be stored, which for 1M * 1M it obviously isn't practical.

Has anyone solved problems of this type before?   Will I have to go write my own Op?

",8,5
380,2016-1-14,2016,1,14,2,40t0og,Multiagent Cooperation and Competition with Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/40t0og/multiagent_cooperation_and_competition_with_deep/,MetricSpade007,1452705887,,6,11
381,2016-1-14,2016,1,14,3,40tfc4,What is considered a hyperparameter,https://www.reddit.com/r/MachineLearning/comments/40tfc4/what_is_considered_a_hyperparameter/,max_moroz,1452710752,"Is any variable that affects the classifier chosen by the learner but that is neither fixed in advance (for some reason) nor determined during training considered a ""hyperameter""?

If so, then all of these are hyperparameters - does it sound about right?

* the optimization algorithm (e.g., GD vs quasi-Newton) used to train a given classifier?
* the activation function in the hidden layer of an ANN (relu or logistic or tanh)?
* the choice of the number of hidden layers and neurons in each layer of an ANN?
* the choice of the evaluation function for an ANN (MSE or cross-entropy)?
* the distribution used to generate initial weights?
* the actual initial weights?
* the type of kernel in SVM (gaussian, polynomial, etc.)?
* the choice of learner to use, if that decision isn't made in advance?

If the above are not all hyperparameters, then what is a good definition of one?",11,14
382,2016-1-14,2016,1,14,4,40tiro,The Unreasonable Reputation of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/40tiro/the_unreasonable_reputation_of_neural_networks/,insperatum,1452711896,,69,74
383,2016-1-14,2016,1,14,4,40tjfh,[SKlearn]Does the fit function find weights?,https://www.reddit.com/r/MachineLearning/comments/40tjfh/sklearndoes_the_fit_function_find_weights/,FutureIsMine,1452712106,"Does the fit function of say an svm, log reg, ANN, other training algos, find the weights or does one need to run an algo like gradient descent to find good fitting params? ",3,0
384,2016-1-14,2016,1,14,4,40tppb,Basic Reasoning with Tensor Product Representations (Smolensky and Microsoft Research),https://www.reddit.com/r/MachineLearning/comments/40tppb/basic_reasoning_with_tensor_product/,InaneMembrane,1452714004,,3,12
385,2016-1-14,2016,1,14,4,40tqlo,Any good references to start a literature survey on Machine Learning/Data Mining Applications for Smart Grids?,https://www.reddit.com/r/MachineLearning/comments/40tqlo/any_good_references_to_start_a_literature_survey/,buy_some_wow,1452714239,"I spent a quite a bit of time on actively researching on this topic and found out that there are a few major research areas like Demand Forecasting, Renewable Energy Supply forecasting, Anomaly Detection in customer usage patterns, etc. Is there anyone here that is currently engaged on this type of research and can provide the 'must read' literature on this topic?

Thanks",2,0
386,2016-1-14,2016,1,14,6,40u94n,hi. there is my implementation of Word2Vec using c#,https://www.reddit.com/r/MachineLearning/comments/40u94n/hi_there_is_my_implementation_of_word2vec_using_c/,eabdullin,1452720599,,2,24
387,2016-1-14,2016,1,14,7,40umym,Convolutional autoencoder - simple explanation please:) Why deconcolutions and unpooling?,https://www.reddit.com/r/MachineLearning/comments/40umym/convolutional_autoencoder_simple_explanation/,SnowRipple,1452725642,"Hi,

   I am trying to understand how convolutional autoencoders work, but apart dense papers I can't find simple example.

   Why reconstruction must involve deconvolutions and unpooiling? Can't we do it like in vanilla autoencoder?

Many thanks,
P",3,5
388,2016-1-14,2016,1,14,8,40ups0,"ELI25: ""We are attempting to replace symbols by vectors so we can replace logic by algebra."" - Yann LeCunn",https://www.reddit.com/r/MachineLearning/comments/40ups0/eli25_we_are_attempting_to_replace_symbols_by/,[deleted],1452726674,[deleted],1,1
389,2016-1-14,2016,1,14,8,40urfy,"ELI25: ""We are attempting to replace symbols by vectors so we can replace logic by algebra."" - Yann LeCun",https://www.reddit.com/r/MachineLearning/comments/40urfy/eli25_we_are_attempting_to_replace_symbols_by/,YourWelcomeOrMine,1452727288,"At the NYU AI conference, Yann LeCun said the above quote. I don't completely understand it. Can someone explain it to me?",18,16
390,2016-1-14,2016,1,14,9,40uy10,How do you keep track of the progress of a machine learning project ?,https://www.reddit.com/r/MachineLearning/comments/40uy10/how_do_you_keep_track_of_the_progress_of_a/,[deleted],1452729693,[removed],1,2
391,2016-1-14,2016,1,14,10,40v9mu,What is Neural Network used in word2vec for?,https://www.reddit.com/r/MachineLearning/comments/40v9mu/what_is_neural_network_used_in_word2vec_for/,basil_tomato,1452734548,"I was reading up on word vectors, and I think I understand the cost function and why it is advantageous to use Stochastic Gradient Descent. However then I realised that neural network comes into the mix, and I wasn't quite sure why this is or what advantage it provides.  
I mean, couldn't I just learn my vectors using SGD? Why would one need a neural network?  

",3,0
392,2016-1-14,2016,1,14,10,40vf9y,What is the limit of RNN/LSTM when applied to time series? Is it capable of determining anomalies preceding events?,https://www.reddit.com/r/MachineLearning/comments/40vf9y/what_is_the_limit_of_rnnlstm_when_applied_to_time/,trevinstein,1452736795,"I'm trying to figure out the limits of RNNs when applied to time series. The goal is forecasting, but what is forcasted is irrelevant, any future information about the time series forecasted with some decent probability is good.




Suppose the time series contains anomalies (irregularities in the structure of the data, not measurement errors) which influence the time series shortly thereafter. Would an RNN be able to identify these anomalies when it makes forecasting decisions?




What about lasting factors, some measurements which are slow to change but which influence the behavior of a time series. Example: When Feature12 is &lt;X the time series is much more likely to oscillate than when Feature12 is &gt;Y, but when Feature12 is anything else influence is undefined.




Deep neural networks seem to engineer features on their own, at least for images. If I make my RNN deep enough will it engineer features capable of discerning what I noted above?




And should I be using convolution filters for time series?

",10,11
393,2016-1-14,2016,1,14,11,40vfqu,How to start training any model on an audio input?,https://www.reddit.com/r/MachineLearning/comments/40vfqu/how_to_start_training_any_model_on_an_audio_input/,koormoosh,1452736983,"This sounds very basic, but to start training a model on audio files, how should I proceed? Meaning what is the input format and how can I convert an audio file to an input? Is there any standard widely accepted way of doing it and is there any open-source tool that can be used?",5,4
394,2016-1-14,2016,1,14,11,40vlaf,Re-implementation of Adversarial Training for Image Generation in Tensorflow - iPython notebook,https://www.reddit.com/r/MachineLearning/comments/40vlaf/reimplementation_of_adversarial_training_for/,nivwusquorum,1452739251,,15,13
395,2016-1-14,2016,1,14,12,40vwid,My miserable failure on training ConvNet for regression,https://www.reddit.com/r/MachineLearning/comments/40vwid/my_miserable_failure_on_training_convnet_for/,keidouleyoucee,1452743798,"Please excuse me on posting another question on same task - but for last eight days I checked everything I can think of on this new problem and  now I'm like a dead ReLU. Briefly, my network is designed for a regression task with music signal, 2d convnet, prelu, l2-regularisation (or dropouts, but not together) + fully-connected layers, and an output layer w/ or w/o sigmoid. Output values range in [0, 1]. The model is built as the pseudocode below using Keras. 

    model = Sequential()
    for i in range(5):
        if i ==0:
            model.add(Convolution2D(input_shape=(1, height, width))) # with or without l2 regularisation 
        else:
            model.add(Convolution2D()) # with or without l2 regularisation 
        model.add(BatchNormalization())
        model.add(PReLU())
        model.add(MaxPooling2D()) # it has 4-6 conv layers.
    # then,
    model.add(Flatten())
    # now fully-connected layers
    for j in range(2):
        model.add(Dense(128)) # with or without l2 regularisation
        model.add(BatchNormalization())
        model.add(PReLU()) # 
    # then,
    model.add(Dense(output_dimension, activation='sigmoid')) # target values is continuous in [0,1]
    # then compile with mse and optimisers 


What I see after training is that the model quickly converges and then predicts the means of each dimension - as if the inputs and targets are not correlated at all. I had some limitations on checking the data by myself (i.e. listening to the signal and check if the labels make sense) but will do this soon. So far, I checked by

* check average change rates of the weights per layer. With ReLU and not-BN, I had dying ReLU problem (which was the reason I posted before). It once seemed okay with BN. 
* turning on/off BatchNormalization
* using L1 or L2 with wide range of coefficients. (even 1e-9 to 1.0)
* different loss function - mse, mae, binary_crossentropy, 

* visualising convnet features showed kernels with almost all filled with some arbitrary value. Along the all layers, they are just not capturing certain shapes.

I must be making a terrible mistake if not two. What would it be?

PS. I also posted it on [keras issue](https://github.com/fchollet/keras/issues/1462) with little more things, which could be more about Keras. 
",13,1
396,2016-1-14,2016,1,14,13,40w0ub,Library for Convolutional Recurrent Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/40w0ub/library_for_convolutional_recurrent_neural/,mibo12,1452745725,"Are there any libraries out there that implement neural networks that are both Recurrent (lstm) AND convolutional? Is there something preventing these two properties from being combined? (if I'm desperately mislead please let me know) My research into CURRENNT, PyBrain and RNNlib didn't yield the most promising answers, but I might just be missing something. Thanks guys! 

P.S. Love the subreddit. You guys rock",10,0
397,2016-1-14,2016,1,14,14,40w82o,Does anyone have experience with NuPIC?,https://www.reddit.com/r/MachineLearning/comments/40w82o/does_anyone_have_experience_with_nupic/,Whitey_Knightey,1452749038,"I am looking for machine learning software for Windows. I am just a beginner and I haven't finished Heaton Research's books on neural networks yet. 

Would I be able to use NuPIC to build an AI that plays pong against a rule based system? ",1,0
398,2016-1-14,2016,1,14,15,40wedc,Variational Inference: A Review for Statisticians [David Blei is first author],https://www.reddit.com/r/MachineLearning/comments/40wedc/variational_inference_a_review_for_statisticians/,muktabh,1452752121,,0,18
399,2016-1-14,2016,1,14,16,40wjz9,anhui yawei 30t1250 4+1axes DA52S system CNC PRESS BRAKE,https://www.reddit.com/r/MachineLearning/comments/40wjz9/anhui_yawei_30t1250_41axes_da52s_system_cnc_press/,louisfubin,1452755347,,0,1
400,2016-1-14,2016,1,14,16,40wlsk,ANHUI YAWEI 400t6000 E200P CNC HYDRAYLIC TORSION BAR TYPE BENDING MACHINE,https://www.reddit.com/r/MachineLearning/comments/40wlsk/anhui_yawei_400t6000_e200p_cnc_hydraylic_torsion/,louisfubin,1452756470,,0,1
401,2016-1-14,2016,1,14,16,40wnur,Help: Lip reading using deep learning,https://www.reddit.com/r/MachineLearning/comments/40wnur/help_lip_reading_using_deep_learning/,matrix2596,1452757756,"I want to do a project where I want to output text from lip reading mostly for fun. For this I can create data set using maybe movies where we have video and text alignment. I can break the problem in the following steps:
1. Create dataset of video with text 
2. Create lip localization algorithm
3. Deep learning magic?

Can anyone point out how to use deep learning (word vector, CNN , RNN etc) to achieve this.",2,0
402,2016-1-14,2016,1,14,17,40wt2i,Classifying unevenly distributed data.,https://www.reddit.com/r/MachineLearning/comments/40wt2i/classifying_unevenly_distributed_data/,FutureIsMine,1452761298,"There is a data set of 1 million entries, with 52 categories that a given event can be placed in. Category 3 is found 45% of the time, cat 1 is around 15% and cat 3 around 10%. The rest are distributed into the remaining 49 categories. An svm gets around 30%, a knn will get either 29% or can't even fit the data. Plotting the predictions, I notice that the SVM and the knn both will grasp the shape of the data, but 80% of predictions fall into cat 3, so its mostly choosing the most common category and is failing to grasp the other ones. What is a good approach to this kind of situation. ",4,0
403,2016-1-14,2016,1,14,17,40wu09,Is Google using captchas on Google Scholar to improve its training corpus for image recognition?,https://www.reddit.com/r/MachineLearning/comments/40wu09/is_google_using_captchas_on_google_scholar_to/,sflicht,1452761917,"Perhaps you've noticed recently that Google Scholar now has a captcha that asks the user to prove he or she is not a robot by tagging things like street signs or construction vehicles in a few images. Is this because they actually have a problem with spammers scraping Google Scholar results? That's kind of hard to believe. Moreover, the captcha seems to demand more responses than is typical. I can only conclude that this is actually an experiment to try to improve the training corpus for some of Google's internal image recognition algorithms.

Do others agree? Is this sort of thing ethical?",12,3
404,2016-1-14,2016,1,14,18,40wume,In R can we use ML models to predict future values using n.ahead,https://www.reddit.com/r/MachineLearning/comments/40wume/in_r_can_we_use_ml_models_to_predict_future/,mlstingr,1452762347,"I use both classification (Knn,naive) and regression(lm,svr) methodology to my ML. I have created models using these algorithms and successfully tested with my testing sets. Is it wise to predict future values using ML models.
#####R Code#######
model=svm(y~,...) #or lm(),knn() models etc##
--------------------------------

fin=predict(model,n.ahead=""100"")
---------------

when i used svm() with n.ahead i got some predictions. Do you think those results are garbage value or from my model itself.
",0,0
405,2016-1-14,2016,1,14,19,40x18z,Hybrid DNN for Voice Modulation-HELP!,https://www.reddit.com/r/MachineLearning/comments/40x18z/hybrid_dnn_for_voice_modulationhelp/,8queens,1452766746,I'm starting a research project to train a NN to learn how to modulate voice using audiobooks and ebooks. Anyone knows how they could be used together?,5,0
406,2016-1-14,2016,1,14,19,40x261,Upscaling grainy images of celebrities using deep convolutional generative adversarial networks (DCGANs),https://www.reddit.com/r/MachineLearning/comments/40x261/upscaling_grainy_images_of_celebrities_using_deep/,[deleted],1452767366,[deleted],0,1
407,2016-1-14,2016,1,14,19,40x3wj,Enhancing grainy images of celebrities using generative adversarial networks,https://www.reddit.com/r/MachineLearning/comments/40x3wj/enhancing_grainy_images_of_celebrities_using/,mike_sj,1452768460,,43,173
408,2016-1-14,2016,1,14,20,40x954,Coding own CNL in TF,https://www.reddit.com/r/MachineLearning/comments/40x954/coding_own_cnl_in_tf/,Gamareth,1452771903,"I just started using TensorFlow and I really love it so far. After experimenting with simple linear and logarithmic regression, I would like to code my own convolutional neural network now. The tutorials are great and I understand how to build the model with multiple layers, but how can I train my own model with my own images. Tutorials only show how to use preprocessed data like CIFAR-10 or ImageNet. Anyone got a tutorial on how to include my own data?",1,0
409,2016-1-14,2016,1,14,22,40xiy3,[Seq2Seq] Deciding Scheduled Sampling Curve -- Curriculum Learning,https://www.reddit.com/r/MachineLearning/comments/40xiy3/seq2seq_deciding_scheduled_sampling_curve/,LeavesBreathe,1452777652,"Hey everyone, 

I posted this a few weeks ago, but because of the holidays, didn't get any comments. About 6 months ago, Google reported better results with [scheduled sampling](http://arxiv.org/pdf/1506.03099v3.pdf). The idea looks promising, but there are a few concerns I have.

For normal models, we use E = 1, and use ground truth inputs during decoding. The idea in this paper is to slowly replace these ground truths with generated outputs. This allows the model to recover from making mistakes and not get completely derailed. 

If you notice table 3, they report that starting with a E of 0.25 and ending with E at 0.00 yields the best results. 

How can this possibly be? Wouldn't you think that starting E = 1 and ending at E = 0 would yield the fastest convergence and the lowest testing loss?

I have ran a network from E = 1 to E = 0 with very little gain. I will try a starting E = 0.25 next, but I'm just trying to understand why this would be better?

Additionally:

- For a linear decay of E, you need to calculate a slope based upon how many epochs you predict it will take your model to converge. If that is the case, how would you predict convergence given that scheduled sampling reportedly decreases convergence time. 

- Has anyone tried inverse sigmoid or exponential decay? I feel that linear would be the safest way to go, but the authors do use inverse sigmoid in some experiments.

Thanks!",6,5
410,2016-1-15,2016,1,15,0,40y47s,Yahoo Releases the Largest-ever Machine Learning Dataset for Researchers,https://www.reddit.com/r/MachineLearning/comments/40y47s/yahoo_releases_the_largestever_machine_learning/,siddharth-agrawal,1452786491,,10,230
411,2016-1-15,2016,1,15,1,40y9v1,Yahoo releases 13.5TB Webscope data set for machine learning researchers,https://www.reddit.com/r/MachineLearning/comments/40y9v1/yahoo_releases_135tb_webscope_data_set_for/,tsutomun,1452788578,,0,6
412,2016-1-15,2016,1,15,1,40ye53,"Free Event: Teaching computers to see with Renat Gataullin (500px) 11:30 a.m. in the Stewart Library, Fields Institute on Tuesday, January 26, 2016 (Toronto)",https://www.reddit.com/r/MachineLearning/comments/40ye53/free_event_teaching_computers_to_see_with_renat/,FieldsInstitute,1452790127,"I think this will be live streamed as well for those who aren't in Toronto!

Event:

The recent advancements in Machine Learning fuelled by large amounts of data and cheap computational power have opened interesting opportunities for innovation in the consumer product space. Renat Gataullin will talk about challenges and applications of Machine Learning at 500px.

Renat Gataullin is a Director of R&amp;D at 500px. They apply Machine Learning for building recommendation systems, image discovery and search. Renat has extensive experience in software development from his years at Samsung and Blackberry, as well as working at several early stage startups.

11:30 a.m. in the Stewart Library, Fields Institute on Tuesday, January 26, 2016

Registration is required for this event. [See webpage for details](http://www.fields.utoronto.ca/programs/cim/15-16/lunchseminar/)",0,0
413,2016-1-15,2016,1,15,2,40yg9k,Fast Open Source CPU/GPU Implementation of CTC from Baidu,https://www.reddit.com/r/MachineLearning/comments/40yg9k/fast_open_source_cpugpu_implementation_of_ctc/,ekelsen,1452790919,,33,44
414,2016-1-15,2016,1,15,2,40yhjn,Microsoft Neural Net Shows Deep Learning Can Get Way Deeper,https://www.reddit.com/r/MachineLearning/comments/40yhjn/microsoft_neural_net_shows_deep_learning_can_get/,vonnik,1452791374,,9,29
415,2016-1-15,2016,1,15,3,40ytp4,Baidu Releases New Deep Learning Open Source Code 'Warp-CTC',https://www.reddit.com/r/MachineLearning/comments/40ytp4/baidu_releases_new_deep_learning_open_source_code/,reworksophie,1452795572,,0,2
416,2016-1-15,2016,1,15,4,40z2tj,Yahoo Releases the Largest-ever Machine Learning Dataset for Researchers,https://www.reddit.com/r/MachineLearning/comments/40z2tj/yahoo_releases_the_largestever_machine_learning/,[deleted],1452798686,[deleted],0,0
417,2016-1-15,2016,1,15,5,40zfkx,"Interview with Adam Coates, Director of Baidu's Silicon Valley AI Lab - talking Warp-CTC, Deep Speech 2 &amp; more",https://www.reddit.com/r/MachineLearning/comments/40zfkx/interview_with_adam_coates_director_of_baidus/,reworksophie,1452803099,,0,1
418,2016-1-15,2016,1,15,5,40zg7p,Fibonacci clock for time inputs,https://www.reddit.com/r/MachineLearning/comments/40zg7p/fibonacci_clock_for_time_inputs/,Mr-Yellow,1452803314,"Haven't seen this come up, a few have had similar ideas but used slowly oscillating pre-set periods (6 hours, 1 day, 1 week etc) rather than multiple short oscillations on different timers, so figure I'd share.

The beats in sin/cos pairs of repeating timers based on Fibonacci sequence gives a small number of inputs which can represent much longer periods than their individual oscillations.

https://jsfiddle.net/MrYellow/b21e5bqy/",2,1
419,2016-1-15,2016,1,15,5,40zjtz,POS-tagging with an RNN?,https://www.reddit.com/r/MachineLearning/comments/40zjtz/postagging_with_an_rnn/,spurious_recollectio,1452804656,"I'm experimenting with using an RNN (seq-2-seq) architecture to do some NLP tasks.  I previously used a linear chain CRF to do postagging and it works very well (trains in ~20 min and gets 99% accuracy).  My motivation for switching to an RNN is that i want to also do more complex tasks that I don't think the CRF can handle (and I want to do them all with the same model).

To my surprise (and annoyance) I'm having a hard time getting my seq2seq RNN architecture to approach my _linear_ CRFs performance.  My initial guess would have been that an RNN is overkill for this tasks so I was surprised that it could not overfit the data. 

Has anyone tried POS-tagging with an RNN?  If so mind sharing your experience.  One concern is that since the RNN is all custom-written code there might be some problem with my implementation (which is why I'm asking if others tried something similar).",8,6
420,2016-1-15,2016,1,15,5,40zl2t,"mxnet can visualize the computation graphs of CNNs. Here are their provided models side by side! (lenet, vgg, alexnet, googlenet, inception-v3, inception-bn)",https://www.reddit.com/r/MachineLearning/comments/40zl2t/mxnet_can_visualize_the_computation_graphs_of/,ieee8023,1452805097,,13,40
421,2016-1-15,2016,1,15,6,40zp22,Artificial Intelligence in the 1960s,https://www.reddit.com/r/MachineLearning/comments/40zp22/artificial_intelligence_in_the_1960s/,digitalbro,1452806555,,3,10
422,2016-1-15,2016,1,15,6,40zp6w,What is model-based machine learning?,https://www.reddit.com/r/MachineLearning/comments/40zp6w/what_is_modelbased_machine_learning/,elisebreda,1452806608,,0,2
423,2016-1-15,2016,1,15,6,40zr05,AskReddit: Do you have any references/advices about feature engineering/selection that you could share?,https://www.reddit.com/r/MachineLearning/comments/40zr05/askreddit_do_you_have_any_referencesadvices_about/,AlfonzoKaizerKok,1452807254,"I can't seem to find many references on this. I realise that feature engineering is very much domain specific, but I'm wondering if you could share some general principles?

I've come across this [paper](http://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf) by Isabelle Guyon, this set of [slides](https://www.cs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/slides.pdf) and this [discussion](https://www.quora.com/MLconf-2015-Seattle/What-are-some-best-practices-in-Feature-Engineering).",0,5
424,2016-1-15,2016,1,15,7,410097,Deeplearning4j Developer Guide,https://www.reddit.com/r/MachineLearning/comments/410097/deeplearning4j_developer_guide/,vonnik,1452810524,,0,3
425,2016-1-15,2016,1,15,7,4100eg,DeepStyle Computing Gram Matrix with Minibatches,https://www.reddit.com/r/MachineLearning/comments/4100eg/deepstyle_computing_gram_matrix_with_minibatches/,[deleted],1452810583,[deleted],1,1
426,2016-1-15,2016,1,15,8,410a0v,A Complete Tutorial to Learn Data Science with Python from Scratch,https://www.reddit.com/r/MachineLearning/comments/410a0v/a_complete_tutorial_to_learn_data_science_with/,PyBet,1452814120,,0,7
427,2016-1-15,2016,1,15,9,410la5,Journal paper in ML,https://www.reddit.com/r/MachineLearning/comments/410la5/journal_paper_in_ml/,[deleted],1452818497,[deleted],0,1
428,2016-1-15,2016,1,15,9,410lr2,Have anyone implemented skip-thoughts vectors using TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/410lr2/have_anyone_implemented_skipthoughts_vectors/,fm1410,1452818699,"I was wondering if anyone have implemented skip-thought vectors using TF. The original code was written in Theano. https://github.com/ryankiros/skip-thoughts. Also, I was wondering if we could have any improvement in performance using TF instead of Theano.",6,6
429,2016-1-15,2016,1,15,9,410m4p,[1508.01084] Deep Convolutional Networks are Hierarchical Kernel Machines,https://www.reddit.com/r/MachineLearning/comments/410m4p/150801084_deep_convolutional_networks_are/,eaturbrainz,1452818847,,1,10
430,2016-1-15,2016,1,15,10,410tdi,GPU size requirements for speech recognition,https://www.reddit.com/r/MachineLearning/comments/410tdi/gpu_size_requirements_for_speech_recognition/,NerdalNetwork,1452821733,"Baidu [just released code](https://github.com/baidu-research/warp-ctc) for their ctc implementation that was referenced in their [Deep Speech 2 paper](http://arxiv.org/abs/1512.02595). On the readme, it says that they 
&gt; Benchmarked on a single NVIDIA Titan X GPU

and in the paper (section 4.3) they say that

&gt; TitanX GPUs include 12GB of GDDR5 RAM, and sometimes very deep networks can exceed the GPU memory capacity when processing long utterances.

Can reasonably competitive speech recognition be done with less than 12GB without slowing training down too much? I'm looking to pick up either a 980 Ti or Titan X and was leaning towards the 980 Ti, but I'd like to do more work with speech recognition and I wouldn't want to handicap myself with a card that doesn't have enough memory.

I was also going to look into trying out what's implemented in [End-to-End Attention-based Large Vocabulary Speech Recognition](http://arxiv.org/abs/1508.04395v1). Does anyone have any notion of the size requirements for this?

I have some experience working with CNN's but I have 0 experience when it comes to speech recognition using RNNs, so I apologize if this is a noobish question.",5,2
431,2016-1-15,2016,1,15,11,4110yv,Install TensorFlow in a SageMathCloud instance,https://www.reddit.com/r/MachineLearning/comments/4110yv/install_tensorflow_in_a_sagemathcloud_instance/,vanboxel,1452824878,,0,1
432,2016-1-15,2016,1,15,13,411g6t,Activation functions that have normalized output,https://www.reddit.com/r/MachineLearning/comments/411g6t/activation_functions_that_have_normalized_output/,avacadoplant,1452831355,"I've noticed that if I put spread batch norms liberally through my network, including after ReLUs that training is faster. What is the point of having ReLUs that output only positive values if they're just going to be whitened anyway? Does anyone use activation (arctan?) that output values centered at zero?

pointers to papers is appreciated ",3,1
433,2016-1-15,2016,1,15,16,4124d2,"Code for the paper ""Binding by Reconstruction Clustering""",https://www.reddit.com/r/MachineLearning/comments/4124d2/code_for_the_paper_binding_by_reconstruction/,[deleted],1452843673,[deleted],0,7
434,2016-1-15,2016,1,15,18,412eqn,A Machine Learning Framework for spoken dialog classification,https://www.reddit.com/r/MachineLearning/comments/412eqn/a_machine_learning_framework_for_spoken_dialog/,alpyhp,1452850323,,0,1
435,2016-1-15,2016,1,15,18,412evi,Bayesian Logistic Regression with PyMC3,https://www.reddit.com/r/MachineLearning/comments/412evi/bayesian_logistic_regression_with_pymc3/,cast42,1452850399,,4,28
436,2016-1-15,2016,1,15,19,412jeo,How to use ML methods to detect hand gesture patterns?,https://www.reddit.com/r/MachineLearning/comments/412jeo/how_to_use_ml_methods_to_detect_hand_gesture/,shapul,1452853196,"I am trying to understand what would be the best strategies to detect specific hand gestures captured by some sensors. The question came to my mind when I was looking at the YouTube demos of [Google Soli](https://www.youtube.com/watch?v=czJfcgvQcNA) system.


So imagine that I have a set of sensors recording data at 1000 Hz and we want to detect a specific hand motion patterns. The exact measured quantities (radar, acceleration, etc.) is not important.


Obviously we need a set of recorded patterns to train a classifier. However, there are several challenges: 


1. The exact start and end of a pattern cannot be specified very accurately. There could be 10s or 100s of milliseconds gap before or after each pattern in training set. The gap cannot be eliminated since deciding the start/end events is somewhat subjective.
2. Each time a person performs the desired movement pattern, she/he could do it a bit slower or faster so the duration of the pattern we look for as well as those we have in the training set are not exactly known and could vary quite a lot.
3. There could be a large variability on how different people perform the same pattern. So besides the positive cases in the training set, a large number of various negative cases should be included.
4. We are dealing with collecting a dataset from human movements. It is not easy to collect data from a large population so in the end, the training set is going to be rather small. Thus the selection of ML methods available to use might be quite limited.
5. Some patterns demoed in Soli videos are very complex: e.g. they involve turning an imaginary knob in the air. So the system should detect in real-time the gesture to grab the knob, and then the progression of gesture as the user turns his wrist to the left or right. How such complex activities could be classified?

I am thinking that the general approach could involve a sliding window: let's say the average length of the desired pattern is about 500 samples. So we feed the samples 1..500 to the classifier and see if the pattern is detected or not. Then we feed samples 2..501 and then samples 3..502, etc. This approach might work but I feel it will be quite problematic in view of the issues above. Also the classifier should be damn accurate to work as such since there is very little difference between the 1..500 and 2..501 inputs: a small false-positive rate will be blown up a lot using this method.  

To resolve the issues 2 and 4, we might need to produce a lot of replications of the samples in the training set, each time shrinking or expanding them a little bit so that we can produce lots of variations out of small number of real measurements. More variations including inserting gaps of varying length before and after each training sample might help with issue 1.

As for issue 5, I have no clear idea.

I am trying to collect some data using an accelerometer attached to my hand and train a classifier using RF or SVM to learn about this process. However, I am honestly baffled by the above issues. Any hint or advice is welcome.",23,8
437,2016-1-15,2016,1,15,19,412koi,Question on computing features in image classification using bag of visual words,https://www.reddit.com/r/MachineLearning/comments/412koi/question_on_computing_features_in_image/,StepW,1452853990,"Hey! I'm working on an assignment regarding image classification, and in it we're given ready-made code for extraction of image features (using SIFT) and bag of visual words. Using the resulting vocabulary we'd then have to implement classification using multiple different methods, like k-NN, SVMs, etc.

There's one thing I noticed in the ready-made code which struck me as odd. The SIFT features were computed twice... once to build the vocabulary of visual words, and once again to compute the visual word histograms of each image. The only difference between the SIFT computations is that, for the vocabulary, a less dense SIFT feature extraction was performed (it was computed with a larger pixel step size between each descriptor).

Usually what I do is compute all the SIFT features at the start and then use those to compute both the vocabulary and the histograms, so seeing this made me wonder... Is there any advantage to computing SIFT twice like that? I ran some tests, computing SIFT features just once for both the vocabulary and histograms, and I didn't see any noticeable improvements in classification accuracy.

If someone could shed light on this, that'd be fantastic. Thanks!",0,0
438,2016-1-15,2016,1,15,21,412wpp,Predicting rare events; how to prevent machine learning algorithms from always picking the default class?,https://www.reddit.com/r/MachineLearning/comments/412wpp/predicting_rare_events_how_to_prevent_machine/,polytop3,1452861247,"Hi All,

Let's say I have a binary classification problem (to keep things simple), with two class labels: zero and one.

Let's say the zero class dominates (and is associated with 99% of the data). Most machine learning algorithms will learn to predict zero all the time, since that achieves 99% accuracy. However, it is very important to me to be able to predict the ones.

How can we prevent this degenerate behavior where only zeros are predicted?",7,10
439,2016-1-15,2016,1,15,21,412x6w,Anthony Goldbloom's tips for winning Kaggle competitions,https://www.reddit.com/r/MachineLearning/comments/412x6w/anthony_goldblooms_tips_for_winning_kaggle/,jmethvin88,1452861507,,35,38
440,2016-1-15,2016,1,15,23,413blz,Baidus Artificial Intelligence Team Releases Key Deep-Learning Code,https://www.reddit.com/r/MachineLearning/comments/413blz/baidus_artificial_intelligence_team_releases_key/,GrabAHamLincoln,1452868498,,13,39
441,2016-1-16,2016,1,16,1,413ruc,Scaling Semantic Search beyond 100 million CVs and jobs with Elasticsearch,https://www.reddit.com/r/MachineLearning/comments/413ruc/scaling_semantic_search_beyond_100_million_cvs/,grumpybusinesscat,1452875067,,0,4
442,2016-1-16,2016,1,16,2,413zhp,"A self contained resource for ML, in particular neutral networks?",https://www.reddit.com/r/MachineLearning/comments/413zhp/a_self_contained_resource_for_ml_in_particular/,EatShihtzu,1452877814,"Hello ladies and gents. I'm a frustrated former theoretical physicist trying to gain a rigorous understanding of neural networks. I have a background in quantum field theory with plenty of esoteric mathematics (with a PhD to boot), but I find the oft-quoted resources (Andrew Ng's course, etc.) lack the rigor I'm comfortable with. I found Bishop's text ""ML and Pattern Recognition"" to be exactly what I want, but it's too encyclopedic; I don't have time to read ~800 pages. Is there something along the lines of a review article y'all could recommend? Less pictures, more math, with no ""plug your data into this scikit-learn black box, who cares about the theory"" focus? Cheers.",9,1
443,2016-1-16,2016,1,16,2,4146tl,Why there is a n-1 in sample variance.,https://www.reddit.com/r/MachineLearning/comments/4146tl/why_there_is_a_n1_in_sample_variance/,cynml,1452880495,,5,0
444,2016-1-16,2016,1,16,3,41498h,"Resources for getting started in Text Generation, JVM or Node based",https://www.reddit.com/r/MachineLearning/comments/41498h/resources_for_getting_started_in_text_generation/,infomofo,1452881333,"I've been really intrigued by the articles on Text Generation, for example, [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/), and [Generating Magic cards using deep, recurrent neural networks](http://www.mtgsalvation.com/forums/creativity/custom-card-creation/612057-generating-magic-cards-using-deep-recurrent-neural).  

I'm a programmer and I have some experience with ML techniques, but always more of the statistical nature and not Text Generation.  I've worked with mahout, spark, Incanter, and R.  

Does anyone have any tips on getting started? I don't know Python, so my preference would be to find a JVM or node library.  My use case is I would like to train a model on a corpus of text and then use that to generate similar chains of text.  If there are out of the box solutions for this already, even better.",1,0
445,2016-1-16,2016,1,16,3,414fyh,Question regarding convolutions and filters,https://www.reddit.com/r/MachineLearning/comments/414fyh/question_regarding_convolutions_and_filters/,AwesomeDaveSome,1452883620,"I'm currently trying to learn stuff about machine learning for a semester project at college. I'd like to write an image recognition neural net. I've been studying some tutorials/reading up in general. Currently, I'm working through the cifar-10 tutorial in tensorflow (my professor wants us to use tensorflow). I have a question regarding convolutions that I've not found an answer to yet, even though I've searched quite a long time:

when choosing my filters, I have to set the size, the amounts of channels in the output, and the entries of the filter.

For neither of those, I can really see how one would go about deciding what to choose. For the size, I understand that you'll want a filter that is smaller than the whole image. Smaller is probably better, but for example in the cifar tutorial, they use a 5x5 filter, even though they could use a 3x3 filter. Why?

For the entries, I understand that there are certain matrices associated with certain convolutions (edge detection, blurring and so on). But for example again in the cifar-10 tutorial, they seem to use matrices with random entries. Why is that/how did they come up with that?

And for the channels, I have no idea how to choose how many one would like to have.",4,1
446,2016-1-16,2016,1,16,4,414ib1,Why (almost) only mathematical functions are used for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/414ib1/why_almost_only_mathematical_functions_are_used/,vomad,1452884405,After developing software for more than a decade I am diving into Machine Learning and I am somehow surprised that almost all Machine Learning algorithms are mathematical functions. I wonder why other kinds of knowledge representation did not succeed. For example there was rule systems in Prolog or knowledge representation as graphs. Little did I know that knowledge about so many domains that don't deal with numbers will be represented by mathematical functions and numerical values of parameters. Did mainly the mathematical community research in Machine Learning and therefore dominate this field or is mathematics such an universal mean of describing the world?,10,0
447,2016-1-16,2016,1,16,4,414koe,How We Approached The Allen A.I. Challenge on Kaggle,https://www.reddit.com/r/MachineLearning/comments/414koe/how_we_approached_the_allen_ai_challenge_on_kaggle/,brooke-torres,1452885138,,1,19
448,2016-1-16,2016,1,16,4,414ltf,random forests (SI),https://www.reddit.com/r/MachineLearning/comments/414ltf/random_forests_si/,thepielibrary,1452885564,[removed],2,0
449,2016-1-16,2016,1,16,4,414mjd,Data-pipelining using UNIX microservices,https://www.reddit.com/r/MachineLearning/comments/414mjd/datapipelining_using_unix_microservices/,[deleted],1452885842,[deleted],0,0
450,2016-1-16,2016,1,16,4,414nbz,"How to pick trajectory phases for low-energy transfers using ""intelligent"" algorithms",https://www.reddit.com/r/MachineLearning/comments/414nbz/how_to_pick_trajectory_phases_for_lowenergy/,Seijuro__Hiko,1452886121,"Firstly, I'm new to this subreddit so apologies if this post isn't appropriate!
My research work entails optimization of spacecraft trajectories. The test problem is fairly simple: transfer from some orbit around the earth to some orbit around the moon.
There's obviously a few ways to do that, some more efficient in terms of fuel, some more efficient in terms of time.

You can: use an impulsive burn, use a low-thrust trajectory, use ""invariant manifolds"" (for those unfamiliar, just imagine this is a free-energy trajectory, so if you can use this intelligently it'll save you some fuel at the cost of time)
I've been writing an optimization library that uses a GA to optimize this problem for a specific set of phases. i.e: coast around the earth, impulsive burn to a manifold, capture burn to get on manifold, impulsive burn towards moon, capture burn to get into orbit around the moon.
What's important to take away here is that the path is decided a priori.
What I'm trying to accomplish is letting a GA or some algorithm come up with new ""paths"" so as to create NEW possible trajectories.

One of the issues with this is that it can pick a series of phases that don't actually get it to the moon, and if I proceed heuristically this is more likely than picking a series that DO get to the moon.
I was wondering if there are any machine learning schema that deal with intelligent path planning like this.
Thanks for any advice!",2,1
451,2016-1-16,2016,1,16,5,414ud8,Does there exist an Algorithm to convert an RNN into a Feedforward Network?,https://www.reddit.com/r/MachineLearning/comments/414ud8/does_there_exist_an_algorithm_to_convert_an_rnn/,Akyu,1452888527,"In [this lecture](https://www.youtube.com/watch?v=1cO4R_H4Kww) (37:18) by Giulio Tononi (which is largely unrelated to Machine Learning, but still fascinating to watch if you have the time) he presents two neural networks, a recurrent network and a feedfoward network, which have equivalent input/output behavior.

I had never really considered this before, so I wondered if there was a generalized algorithm to do such a conversion. The immediate comparison that comes to mind is the Powerset construction, which can be used to convert a non-deterministic finite state automaton into a deterministic finite state automaton. Does an algorithm like this exist for converting RNNs to Feedfoward nets?

I am also curious whether the example presented in the video is a special case, or if this convertibility is a property of all RNNs. Even if it were a general property of RNNs, I suspect it would only be feasible on relatively small RNNs, but it still may be useful for certain applications. ",4,1
452,2016-1-16,2016,1,16,5,414v1e,Live Q&amp;A session with Yoshua Bengio on Quora,https://www.reddit.com/r/MachineLearning/comments/414v1e/live_qa_session_with_yoshua_bengio_on_quora/,futrawo,1452888760,,3,11
453,2016-1-16,2016,1,16,5,4151d5,Quora session with Yoshua Bengio,https://www.reddit.com/r/MachineLearning/comments/4151d5/quora_session_with_yoshua_bengio/,code2hell,1452891062,,2,1
454,2016-1-16,2016,1,16,7,415do6,A personal assistant who schedules meetings for you | x.ai,https://www.reddit.com/r/MachineLearning/comments/415do6/a_personal_assistant_who_schedules_meetings_for/,nerdquadrat,1452895711,,3,0
455,2016-1-16,2016,1,16,7,415he9,News article Q&amp;A Dataset,https://www.reddit.com/r/MachineLearning/comments/415he9/news_article_qa_dataset/,[deleted],1452897147,[deleted],0,1
456,2016-1-16,2016,1,16,7,415ifo,am I missing something or does Random Forest have major advantages?,https://www.reddit.com/r/MachineLearning/comments/415ifo/am_i_missing_something_or_does_random_forest_have/,[deleted],1452897548,[deleted],1,0
457,2016-1-16,2016,1,16,10,41691t,Evolving Wind Turbine Blades,https://www.reddit.com/r/MachineLearning/comments/41691t/evolving_wind_turbine_blades/,St_OP_to_u_chin_me,1452908351,,39,166
458,2016-1-16,2016,1,16,12,416lcf,Training Recurrent Neural Networks by Diffusion,https://www.reddit.com/r/MachineLearning/comments/416lcf/training_recurrent_neural_networks_by_diffusion/,SuperFX,1452914035,,15,12
459,2016-1-16,2016,1,16,14,4172t9,"""The Scream"" + Trump + Tensorflow (sorry about the small size, upload limits....)",https://www.reddit.com/r/MachineLearning/comments/4172t9/the_scream_trump_tensorflow_sorry_about_the_small/,nfmcclure,1452922762,,1,0
460,2016-1-16,2016,1,16,18,417re3,A guide to Nelder-Mead Optimization,https://www.reddit.com/r/MachineLearning/comments/417re3/a_guide_to_neldermead_optimization/,sachinrjoglekar,1452938040,,3,12
461,2016-1-16,2016,1,16,19,417voh,Announcing the Machine Learning Quora Sessions Series,https://www.reddit.com/r/MachineLearning/comments/417voh/announcing_the_machine_learning_quora_sessions/,thvasilo,1452940818,,1,3
462,2016-1-16,2016,1,16,19,417wqu,On policy vs. off policy in RL,https://www.reddit.com/r/MachineLearning/comments/417wqu/on_policy_vs_off_policy_in_rl/,abstractcontrol,1452941502,"I am wondering what more experienced practitioners think about the differences between various related algorithms in reinforcement learning. Having gone through an extreme RL marathon in the last two weeks, I have a decent grasp of what they do in the tabular case at least, but I find myself confused which of the many algorithms are better or worse.

With function approximators like neural nets, Q learning in particular seems to be extremely popular compared to TD learning and Sarsa. Why is that?",16,4
463,2016-1-16,2016,1,16,20,417yi1,"IndiaHacks: Machine Learning | Programming challenges in January, 2016 on HackerEarth",https://www.reddit.com/r/MachineLearning/comments/417yi1/indiahacks_machine_learning_programming/,Sharath123,1452942688,,0,2
464,2016-1-16,2016,1,16,20,4183j5,"Bach, Leonardo, Cancer and the Search for the Master Algorithm - A short summary of the Paris Machine Learning Meetup (#5 Season 3) -",https://www.reddit.com/r/MachineLearning/comments/4183j5/bach_leonardo_cancer_and_the_search_for_the/,compsens,1452945346,,10,1
465,2016-1-16,2016,1,16,23,418koq,Math MOOCs for ML,https://www.reddit.com/r/MachineLearning/comments/418koq/math_moocs_for_ml/,[deleted],1452953872,[deleted],1,0
466,2016-1-17,2016,1,17,2,419e5a,Voynich Manuscript: word vectors and t-SNE visualization of some patterns,https://www.reddit.com/r/MachineLearning/comments/419e5a/voynich_manuscript_word_vectors_and_tsne/,perone,1452966597,,23,141
467,2016-1-17,2016,1,17,3,419jgp,"I was informed that a minimum of 70 high-resolution images are required for facial recognition, with around 100 needed for real person identification. Why can I not find any libraries that align with this?",https://www.reddit.com/r/MachineLearning/comments/419jgp/i_was_informed_that_a_minimum_of_70/,Rich700000000000,1452968646,"Originally, I was informed that for basic facial recognition, you needed a minimum of 70 images of the subject, all of which had to be at least a 1200x1200 resolution. For professional identification systems or real-time video, one would require a minimum of 100 images at around 1500x1500 resolution each. And to me, this made perfect sense. 

However, it seems that I was misinformed, because it turns out that the opposite is true: Something as simple a making HAAR-cascade requires thousands upon thousands of images to recognise something as simple as a logo,or a fruit. And video systems such as OpenCV or [CLandmark](http://cmp.felk.cvut.cz/~uricamic/clandmark/index.php?page=usecases) are capable of extracting faces from video less than 720p. 


I feel as though I'm missing a key component of information. What is causing this disparity?",30,9
468,2016-1-17,2016,1,17,4,419puq,Building a learning system to parse recipes ingredients. Need advice on platform choices.,https://www.reddit.com/r/MachineLearning/comments/419puq/building_a_learning_system_to_parse_recipes/,cherianthomas,1452971048,"Hello redditors,  
I am planning to build a recipe parsing mechanism that tags different parts of an ingredient
Example:  
**9 grams Garlic (1 very large clove), roughly chopped into**  
quantity, unit, subject, modifiers etc.  
Recipe authors often end up writing these in their style like  
**Handful coriander leaves, finely chopped**  
Etc.  
[Nytimes did some work around this]( http://open.blogs.nytimes.com/2015/04/09/extracting-structured-data-from-recipes-using-conditional-random-fields/?_r=2) - Extremely good read
 
What I am trying to do is predict the ingredient structure (structured prediction problem).
Ive been looking into NLTK, specifically the structured prediction.
 
Am I in the right direction? Whats my right choice of toolkit library for structured prediction?
My criteria revolve around how good and adopted the toolkit is and ability to get other machine-learning experts chip help me in forums like this. ",5,3
469,2016-1-17,2016,1,17,4,419rbl,Large-Scale Language Classification,https://www.reddit.com/r/MachineLearning/comments/419rbl/largescale_language_classification/,vonnik,1452971630,,2,0
470,2016-1-17,2016,1,17,4,419tmb,"Machine Learning Trading, Stock Market, and Chaos",https://www.reddit.com/r/MachineLearning/comments/419tmb/machine_learning_trading_stock_market_and_chaos/,Barry_Bird,1452972467,,2,1
471,2016-1-17,2016,1,17,4,419v51,Examples for deductive inference machine learning?,https://www.reddit.com/r/MachineLearning/comments/419v51/examples_for_deductive_inference_machine_learning/,themoosemind,1452972976,"I took a machine learning course at my university where the teacher described the machine learning algorithms by different properties. One of them was ""type of inference"" which is either ""inductive"" or ""deductive"" in his scheme.

We had a lot of inductive inference algorithms: k-means clustering, k-nearest neighbors, SVMs, decision trees, case based reasoning, neural networks, version space algorithm.

However, we only had one deductive example (""Erklrungsbasierte Generalisierung"" - it's German and means something like ""Explanation-based generalization""), but I didn't quite understand it.

Do you know examples of machine learning algorithms which use deductive inference?",3,0
472,2016-1-17,2016,1,17,6,41ag1o,Explanation of Keras Layers,https://www.reddit.com/r/MachineLearning/comments/41ag1o/explanation_of_keras_layers/,SexHaver2003,1452980612,"I'm trying to learn to use Keras with Theano as a backend, I've looked at the tutorials on Keras.io and it gives a short explanation of each type of layer and I've looked at example of code on Kaggle. But I can't seem to find any reasoning as to why the layers are used the way they are or why they are in any particular order.

If anyone has an some code example with any explanation of why they are using the layers they are, it would be much appreciated.

Thanks in advance. ",3,0
473,2016-1-17,2016,1,17,8,41awpq,Stay up to date with Artificial Intelligence developments on your facebook feed,https://www.reddit.com/r/MachineLearning/comments/41awpq/stay_up_to_date_with_artificial_intelligence/,TenshiS,1452987015,,0,0
474,2016-1-17,2016,1,17,11,41bokd,Is there a way to build a NN that can identify new classes?,https://www.reddit.com/r/MachineLearning/comments/41bokd/is_there_a_way_to_build_a_nn_that_can_identify/,mathnstats,1452999053,"Forgive me if this is a silly question, I'm fairly new to neural networks.

Is it possible to create a NN such that if it is given data that don't correspond to the classes it was trained on, it could identify them as such without lumping them into a single ""unknown"" class?

For instance, if I trained it to classify dogs, cats, and fish given their physiological traits and then gave it the features that correspond to a zebra and a monkey, is there a type of NN that could identify them as not only different from what it has learned, but that the zebra and monkey are also different from each other?",4,1
475,2016-1-17,2016,1,17,14,41c687,Why do data transformations affect performance of tree-based models?,https://www.reddit.com/r/MachineLearning/comments/41c687/why_do_data_transformations_affect_performance_of/,maruchanr,1453007491,"Based on the principle behind RFs and GBMs, standardizing / transformation by taking the difference from the mean for a dataset shouldn't make any difference as the trees are still split in the same way. Yet empirically it does improve performance in some cases, why is this?",5,4
476,2016-1-17,2016,1,17,17,41crmv,Starting off with Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/41crmv/starting_off_with_machine_learning/,rishabh96b,1453020463,[removed],4,0
477,2016-1-17,2016,1,17,22,41dhi3,Pizzafire: how to quickly apply a Neural Algorithm of Artistic Style to video using distributed computing on many AWS machines.,https://www.reddit.com/r/MachineLearning/comments/41dhi3/pizzafire_how_to_quickly_apply_a_neural_algorithm/,Cortexelus,1453037127,,10,12
478,2016-1-17,2016,1,17,22,41dij6,Is there any domain where Bayesian Networks outperform neural networks?,https://www.reddit.com/r/MachineLearning/comments/41dij6/is_there_any_domain_where_bayesian_networks/,themoosemind,1453037614,,54,92
479,2016-1-17,2016,1,17,23,41dm2i,Introduction to Machine learning,https://www.reddit.com/r/MachineLearning/comments/41dm2i/introduction_to_machine_learning/,underflow404,1453039239,,6,61
480,2016-1-17,2016,1,17,23,41dt29,Advice using Neuroph to detect poker cards,https://www.reddit.com/r/MachineLearning/comments/41dt29/advice_using_neuroph_to_detect_poker_cards/,e711,1453042295,"So I'm trying to train a neural network using Neuroph where the input is 52 png images of poker cards and I want to be able to clip the screen where the same card would exist and determine in SW what it is.

It turns out that the input cards are perfectly detectable but if I clip the screen and get some extra pixels on the edge then the detection doesn't work very well. 

I've messed around with the number of neurons in my training without success and was wondering if anyone had any advice on some parameters I should use? Learning rate? Momentum? # of neurons?

Thanks!",2,0
481,2016-1-18,2016,1,18,0,41e1wo,"Which whale is it, anyway? Face recognition for right whales using deep learning",https://www.reddit.com/r/MachineLearning/comments/41e1wo/which_whale_is_it_anyway_face_recognition_for/,benanne,1453046031,,15,25
482,2016-1-18,2016,1,18,1,41e3s4,MyMe - The First AI Wearable Device,https://www.reddit.com/r/MachineLearning/comments/41e3s4/myme_the_first_ai_wearable_device/,amitm02,1453046800,,3,3
483,2016-1-18,2016,1,18,1,41e41a,Getting started: Implementing your own k-nearest neighbour algorithm using Python,https://www.reddit.com/r/MachineLearning/comments/41e41a/getting_started_implementing_your_own_knearest/,DrLegend,1453046913,,0,5
484,2016-1-18,2016,1,18,1,41e8w8,Which dataset to use when selecting attributes?,https://www.reddit.com/r/MachineLearning/comments/41e8w8/which_dataset_to_use_when_selecting_attributes/,rePAN6517,1453048967,Is it safe to use the entire dataset (train + test) when running attribute selection algorithms like InfoGain?  Or should it be limited to just the training dataset?,3,0
485,2016-1-18,2016,1,18,2,41edc7,is there a need for a basic/default feature extractor and trainer that people can upload a few thousand training examples to so that they can quickly and easily find out what some of the most important features are,https://www.reddit.com/r/MachineLearning/comments/41edc7/is_there_a_need_for_a_basicdefault_feature/,[deleted],1453050675,[deleted],1,0
486,2016-1-18,2016,1,18,2,41eiik,IBM Watson Analytics vs. Microsoft Azure Machine Learning (Part 1),https://www.reddit.com/r/MachineLearning/comments/41eiik/ibm_watson_analytics_vs_microsoft_azure_machine/,Datasaur,1453052599,,0,0
487,2016-1-18,2016,1,18,4,41evb6,Machine learning helps discover the most luminous supernova in history,https://www.reddit.com/r/MachineLearning/comments/41evb6/machine_learning_helps_discover_the_most_luminous/,BooglarizeYou,1453057355,,0,9
488,2016-1-18,2016,1,18,5,41f9tr,Good online 'Classification machine learning system' tutorials with code examples?,https://www.reddit.com/r/MachineLearning/comments/41f9tr/good_online_classification_machine_learning/,jonab12,1453062666,"Hello

I'm having problems searching for online tutorials in ML with systems where we seek a yes-or-no prediction. Nick McCrea did a good example [here](http://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer) but didn't go in depth which I want to know",1,0
489,2016-1-18,2016,1,18,7,41fwlh,What Is Machine Intelligence Vs. Machine Learning Vs. Deep Learning Vs. Artificial Intelligence (AI)?,https://www.reddit.com/r/MachineLearning/comments/41fwlh/what_is_machine_intelligence_vs_machine_learning/,thedarkseid,1453070915,,3,0
490,2016-1-18,2016,1,18,8,41g54i,Jrgen Schmidhuber - AI: Big Expectations @ DLD Conference,https://www.reddit.com/r/MachineLearning/comments/41g54i/jrgen_schmidhuber_ai_big_expectations_dld/,tevlon,1453074157,,22,19
491,2016-1-18,2016,1,18,10,41gljh,Are quant firms looking for machine learning PhDs?,https://www.reddit.com/r/MachineLearning/comments/41gljh/are_quant_firms_looking_for_machine_learning_phds/,just_learning_,1453080619,I am interested in working for a trading firm and doing quantiative analysis? Do people in this part of industry hold machine learning PhDs? I have also heard from some people that an Applied Stats degree is more desired due to the approach statisticians take? Any ideas on why this would be or the difference between the two?,4,0
492,2016-1-18,2016,1,18,10,41gn3n,Decision Process to select Statistics and Machine Learning techniques,https://www.reddit.com/r/MachineLearning/comments/41gn3n/decision_process_to_select_statistics_and_machine/,kunjaan,1453081237,,12,56
493,2016-1-18,2016,1,18,13,41hesc,"word2vec, LDA, and introducing a new hybrid algorithm: lda2vec",https://www.reddit.com/r/MachineLearning/comments/41hesc/word2vec_lda_and_introducing_a_new_hybrid/,juxtaposicion,1453092953,,0,1
494,2016-1-18,2016,1,18,14,41hi63,"word2vec, LDA, and introducing a new hybrid algorithm: lda2vec",https://www.reddit.com/r/MachineLearning/comments/41hi63/word2vec_lda_and_introducing_a_new_hybrid/,pilooch,1453094500,,1,2
495,2016-1-18,2016,1,18,15,41hqsj,Show Me The Faces: Collecting Faces With Emotional Expression for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/41hqsj/show_me_the_faces_collecting_faces_with_emotional/,carlos_argueta,1453098792,,8,6
496,2016-1-18,2016,1,18,16,41hyou,Semi-Automatic sleeve wrapping machineBZS 6040,https://www.reddit.com/r/MachineLearning/comments/41hyou/semiautomatic_sleeve_wrapping_machinebzs_6040/,dongfengpacking,1453103057,,1,1
497,2016-1-18,2016,1,18,18,41i72t,Time-series with RNN - how to deal with attributes that span entire sequences?,https://www.reddit.com/r/MachineLearning/comments/41i72t/timeseries_with_rnn_how_to_deal_with_attributes/,DrCrypto,1453108081,"Hello everyone,

I am currently trying to train recurrent neural networks for time-series forecasting, and I'm having trouble figuring out how to **properly** deal with attributes that stay constant over each series.

For instance, let's say I am trying to learn, for a person born between 1950 and 1970, the 30-element sequence of their yearly income between the years 1985 and 2014.
Let's also suppose the attributes I have access to are:

* for some of them, **relative to the person and invariant over time**: their year of birth (can indicate how early they started to work), the net value of their parents they year they were born (can indicate how much help they got in their education and professional start)

* for the others, **fluctuating every year**: the average income in their living area, the inflation rate

In my actual problem, I am trying to predict sequences of 128 elements based on 3 attributes that are *constant over each sequence* and 10 attributes that actually vary over time. In particular, just like in the example I gave, the static attributes seem to be of direct importance (at least intuitively), while the varying attributes' impact is less clear.

My initial thought was to treat all the attributes the same and just train the RNN with sequences of 13-element vectors, 3 of which being static. I actually get quite satisfying predictions on my problem, but is it really good practice to mix static and varying parameters together?

Another idea I got was to construct new learning parameters combining the static and varying attributes, however I couldn't think of a function that would make sense. I guess my second question would be: should I, and how can I build attributes whose physical interpretation is not clear but would still help the time-series forecasting?

Thank you in advance for your help,",7,13
498,2016-1-18,2016,1,18,18,41ib7z,Fluid Bed Dryer a Great Process to Manufacture | Anchormark,https://www.reddit.com/r/MachineLearning/comments/41ib7z/fluid_bed_dryer_a_great_process_to_manufacture/,Anchormark1,1453110705,,0,1
499,2016-1-18,2016,1,18,20,41iifz,Machine Learning is the new C++. Trading based on ML,https://www.reddit.com/r/MachineLearning/comments/41iifz/machine_learning_is_the_new_c_trading_based_on_ml/,Brett_Kelly,1453115229,"Machine Learning is the new C++.

Trading based on ML: 

http://www.elitetrader.com/et/index.php?threads/machine-learning-is-the-new-c.291856/page-6",1,0
500,2016-1-18,2016,1,18,20,41iig8,General recipes for detecting Gradients Vanishing/Exploding and Weights saturated,https://www.reddit.com/r/MachineLearning/comments/41iig8/general_recipes_for_detecting_gradients/,trungnt13,1453115232,"I only can think of several simple strategies for this issue.

For Gradients Vanishing/Exploding:

* NaN in gradient (obviously)
* Extreme big gradient which can be addressed by norm re-scale
* When 0.25 percentile of gradients value close to 0+epsilon

For Weights saturated:

* 0.25 percentile of weights values close to 0+epsilon
* 0.75 percentile of weights values &gt; threshold

&gt; Most of value here is just heuristic, I cannot find any general algorithm to detecting this phenomenon without real human involve.",5,8
501,2016-1-18,2016,1,18,20,41ilxm,ML techniques for implementing a dynamic priority queue?,https://www.reddit.com/r/MachineLearning/comments/41ilxm/ml_techniques_for_implementing_a_dynamic_priority/,burn_in_flames,1453117355,"I have a problem I am trying to solve and was wondering if there are appropriate machine learning techniques which would be worth investigating. 

Basically the problem is this, I have a call queue where each customer in the queue was promised that their call would be handled within x minutes. Where x is dependent on the customer profile and how urgent the call is. I want to implement a priority queue whereby the number of times we break this promise is minimized. This means that each time a call can be handled the most important call needs to be determined. 

A simple priority queue can be used but only once the new priorities are calculated. I was considering using a fuzzy logic approach to calculate the priorities based on different inputs, but was wondering if there are other machine learning techniques which will learn the rules themselves rather than relying on expert knowledge, perhaps a NN, or something along those lines. This way the algorithm can improve it's rules as more calls come in, and more data is acquired. 

The current data which is associated with each call is:
How long the call has been on hold
The maximum desired hold time of the call (based on customer info)
How important the call is (1  not urgent, 5  very urgent)
Calls current queue position

As an output I was thinking either:
1) A new queue, with all the calls reordered appropriately, or
2) A delta value of how many places to move the call up or down in the queue

Any suggestions on machine learning techniques, or similar problems which might be of use to study or feedback on alternative ways to approach this problem would be greatly appreciated.
",1,0
502,2016-1-18,2016,1,18,21,41iqb2,What is The Importance of Compressor Valves?,https://www.reddit.com/r/MachineLearning/comments/41iqb2/what_is_the_importance_of_compressor_valves/,Sl-Engineering,1453119828,[removed],0,1
503,2016-1-18,2016,1,18,21,41isnt,Using Data to Look at how campaign contributions and past voting habits affect gun legislation [OC],https://www.reddit.com/r/MachineLearning/comments/41isnt/using_data_to_look_at_how_campaign_contributions/,DontVoteForMe,1453121096,,0,0
504,2016-1-18,2016,1,18,21,41ist0,Deep learning tutorial on MNIST data using TensorFlow,https://www.reddit.com/r/MachineLearning/comments/41ist0/deep_learning_tutorial_on_mnist_data_using/,kakauandme,1453121176,,3,3
505,2016-1-18,2016,1,18,23,41j9dy,"Have been using AWS G.2 tier with Torch / CUDA / Python. It is very expensive. Need a shared environment, can anyone suggest an alternative?",https://www.reddit.com/r/MachineLearning/comments/41j9dy/have_been_using_aws_g2_tier_with_torch_cuda/,Visibleone,1453129055,,31,31
506,2016-1-19,2016,1,19,0,41jc17,Which classifiers are suitable for churn analysis?,https://www.reddit.com/r/MachineLearning/comments/41jc17/which_classifiers_are_suitable_for_churn_analysis/,EpicPies,1453130138,"Hello there,

I am still learning the Big Data Science-track.. and I have some questions concerning the churn behaviour of customers (be it in a bank, or a telephone company). I have acquired a data-set where I see the behaviour of customers over time, which products they have, etc, etc. (a lt of features, which I still have to select/prune etc.)

However, I am wondering what kind of effect my choice of classifiers will have on the outcome. I would like to use some Tree-based methods and, maybe some logistic regression/naive bayes... But those methods do not incorporate this 'time' variable, as far as I know. 
Thus, if I would use these methods to classify customers, that means that I assume some sort of 'time independence' in the behaviour of customers, right?
Do any of you know how 'correct' my answers will be, if you can say anything like that at all... 

If it is a significant difference, what time-serie dependent classifiers would you use? Would you recommend Hidden Markov Model, or Multi-layer perceptron neural network? (I got these names from https://www.quora.com/What-are-some-time-series-classification-methods )


But most of all I am curious about the implication of using a 'static'/time-independent machine learner to this kind of data. (And also if this is the correct conclusion that I've drawn from my knowledge on these classifiers at the moment).

edit: thanks for all the answer guys :) I'll try to respond to all of you individually",10,0
507,2016-1-19,2016,1,19,3,41kc18,God is a cube - AI programming puzzle game,https://www.reddit.com/r/MachineLearning/comments/41kc18/god_is_a_cube_ai_programming_puzzle_game/,hockiklocki,1453143120,,0,0
508,2016-1-19,2016,1,19,3,41kd55,Submit your machine learning projects,https://www.reddit.com/r/MachineLearning/comments/41kd55/submit_your_machine_learning_projects/,rajzop,1453143481,,0,0
509,2016-1-19,2016,1,19,3,41kd6a,Why is a simple recurrent neural network with an identity recurrent matrix difficult to train?,https://www.reddit.com/r/MachineLearning/comments/41kd6a/why_is_a_simple_recurrent_neural_network_with_an/,logrech,1453143491,"I'm referring to this paper: 
http://arxiv.org/pdf/1412.7753v2.pdf 

On page 3, they talk about a simple recurrent network architecture in which the recurrent matrix is equal to identity. 

After the equation, they write: ""This solution leads to a model which cannot be trained efficiently. Indeed the gradient of the recurrent matrix would never vanish which would require propagation of the gradients up to the beginning of the training set."" 

This is confusing to me. 

From what I understand, with this kind of an architecture, the term
st/sk where 1 &lt; k &lt;= t in BPTT would always be equal to one. In normal RNN's st/sk goes to 0 which is where the vanishing gradient problem arises. I understand this, but I don't understand why their presented architecture (namely one with the recurrent matrix equal to identity) makes the network difficult to train. 

I assume when they say ""would require propagation of the gradients up to the beginning of the training set"" they mean using full BPTT rather than truncated BPTT, but this shouldn't be a problem because the gradients don't vanish? ",8,3
510,2016-1-19,2016,1,19,4,41kh21,Is there a basic go to tool for click prediction?,https://www.reddit.com/r/MachineLearning/comments/41kh21/is_there_a_basic_go_to_tool_for_click_prediction/,textClassy,1453144816,,2,0
511,2016-1-19,2016,1,19,4,41kh7g,Deep learning reinforcement - Papers,https://www.reddit.com/r/MachineLearning/comments/41kh7g/deep_learning_reinforcement_papers/,joshdotai,1453144868,,2,0
512,2016-1-19,2016,1,19,4,41kne0,Bayesian Network vs Bayesian Inference vs Naives Bayes Vs Bayesian Regression?,https://www.reddit.com/r/MachineLearning/comments/41kne0/bayesian_network_vs_bayesian_inference_vs_naives/,bot_cereal,1453146868,What are their difference? and what types of the problem are they good for?,3,0
513,2016-1-19,2016,1,19,6,41l8qx,LSTM with high dimensional inputs,https://www.reddit.com/r/MachineLearning/comments/41l8qx/lstm_with_high_dimensional_inputs/,anonDogeLover,1453153900,"I have a sequence dataset where each item in the sequence is a 40,000 dimensional vector. Is it practical to run a model with such a large-dimensional input space? Any examples? Thanks.",18,0
514,2016-1-19,2016,1,19,7,41lcj8,LSTMs with arbitrary sequence outputs,https://www.reddit.com/r/MachineLearning/comments/41lcj8/lstms_with_arbitrary_sequence_outputs/,anonDogeLover,1453155238,"Is it possible/common to predict sequences other than the input sequence with LSTMs? For example, suppose you have sentences where each word is already vectorized, and you want to translate back to the original word. Since the input/output sequences are aligned, wouldn't tasks like this work fine?",7,0
515,2016-1-19,2016,1,19,7,41le9g,Selecting instagram images for training?,https://www.reddit.com/r/MachineLearning/comments/41le9g/selecting_instagram_images_for_training/,djc1000,1453155858,Are there any good articles on strategies for selecting images for training an NN?  ,4,0
516,2016-1-19,2016,1,19,8,41lowi,Remember the experimental google chatbot 6 months ago? Why haven't anybody yet create a usable chatbot out of that?,https://www.reddit.com/r/MachineLearning/comments/41lowi/remember_the_experimental_google_chatbot_6_months/,Yax42,1453159653,"Remember this http://www.cnet.com/news/the-meaning-of-life-according-to-google-chatbot-ai/ ? Well it was 6 months ago and it was just experimental, still it seemed extremly neat and exciting to me. Why no actual new-gen chatbot came out yet?",7,5
517,2016-1-19,2016,1,19,8,41lqq9,Can I machine Learning?,https://www.reddit.com/r/MachineLearning/comments/41lqq9/can_i_machine_learning/,[deleted],1453160344,[deleted],0,1
518,2016-1-19,2016,1,19,9,41luif,"GPU Based Browser BLAS, Request for Feedback",https://www.reddit.com/r/MachineLearning/comments/41luif/gpu_based_browser_blas_request_for_feedback/,waylonflinn,1453161717,,30,71
519,2016-1-19,2016,1,19,10,41m69j,Voynich Manuscript: word vectors and t-SNE visualization of some patterns,https://www.reddit.com/r/MachineLearning/comments/41m69j/voynich_manuscript_word_vectors_and_tsne/,[deleted],1453166335,[deleted],2,0
520,2016-1-19,2016,1,19,11,41metm,[1601.04033] Faster Asynchronous SGD,https://www.reddit.com/r/MachineLearning/comments/41metm/160104033_faster_asynchronous_sgd/,downtownslim,1453169792,,1,6
521,2016-1-19,2016,1,19,11,41mk92,Realtime OCR,https://www.reddit.com/r/MachineLearning/comments/41mk92/realtime_ocr/,Mr_Life_Styles,1453172025,"What kind of steps are necessary to go from a trained neural network that recognizes handwriting to something like this?

https://www.youtube.com/watch?v=c7swRRLlYEo",1,0
522,2016-1-19,2016,1,19,14,41n2of,Has anyone built a usable sc-lstm on word-level prediction in Lua?,https://www.reddit.com/r/MachineLearning/comments/41n2of/has_anyone_built_a_usable_sclstm_on_wordlevel/,Visibleone,1453180043,Edit: Semantically Conditioned LSTM found in this paper http://mi.eng.cam.ac.uk/~sjy/papers/wgms15.pdf,2,0
523,2016-1-19,2016,1,19,14,41n4mu,Labeling machine,https://www.reddit.com/r/MachineLearning/comments/41n4mu/labeling_machine/,dongfengpacking,1453180973,,1,1
524,2016-1-19,2016,1,19,17,41noqv,Classify text into multiple categories.,https://www.reddit.com/r/MachineLearning/comments/41noqv/classify_text_into_multiple_categories/,n00bto1337,1453192100,"I have a text like, 

    ""India, officially the Republic of India is a country in South Asia.""

I need it to be able to give me,

    Country: India
    Region: South Asia

Whatever I found on scikit's documentation, it was able to classify it into one category, for example I could train this on two classifier to check whether a country is present or region is present, but I want it to tell me which feature it is picking up, bit like NLTK's most informative features, for each classification.
How do I do this?",3,0
525,2016-1-19,2016,1,19,17,41nrm7,"Granulation Equipment | Fluid Bed Dryer, R&amp;D Equipments",https://www.reddit.com/r/MachineLearning/comments/41nrm7/granulation_equipment_fluid_bed_dryer_rd/,Anchormark1,1453193851,,0,1
526,2016-1-19,2016,1,19,18,41nsr9,8th layer in Caffe's AlexNet clone?,https://www.reddit.com/r/MachineLearning/comments/41nsr9/8th_layer_in_caffes_alexnet_clone/,anonDogeLover,1453194559,Does anyone know what the fc8 layer does in Caffe's AlexNet clone (CaffeNet)? This layer is not in the original paper.,4,0
527,2016-1-19,2016,1,19,19,41o2i6,How to run Octave on Nvidia GPU?,https://www.reddit.com/r/MachineLearning/comments/41o2i6/how_to_run_octave_on_nvidia_gpu/,Mr__Christian_Grey,1453200336,Can we run Octave on Nvidia GPU?,2,3
528,2016-1-19,2016,1,19,20,41o600,Learning to cluster points using CNN,https://www.reddit.com/r/MachineLearning/comments/41o600/learning_to_cluster_points_using_cnn/,luliby,1453202215,"Hi, I don't know if this is a trivial question or not, but is there a way to train a cnn network to learn how to cluster points in 2D plane ? In other words, given an image with random 2D points along with the groundtruth data with says which point belongs to which cluster. Can a network learn how to cluster points in a given (test) image ? Maybe by learning distance features or whatever ? Thanks.",4,0
529,2016-1-19,2016,1,19,20,41o63b,"Call: Machine Learning Internship at Adobe Research, San Jose, CA",https://www.reddit.com/r/MachineLearning/comments/41o63b/call_machine_learning_internship_at_adobe/,pabloesm,1453202256,,0,0
530,2016-1-19,2016,1,19,20,41o99y,OpenFace 0.2.0: Higher accuracy and halved execution time.,https://www.reddit.com/r/MachineLearning/comments/41o99y/openface_020_higher_accuracy_and_halved_execution/,bdamos,1453203871,,17,147
531,2016-1-19,2016,1,19,23,41osnt,Training Recurrent Neural Networks by Diffusion [arXiv],https://www.reddit.com/r/MachineLearning/comments/41osnt/training_recurrent_neural_networks_by_diffusion/,petrux,1453212319,,1,8
532,2016-1-19,2016,1,19,23,41ouj0,SimpleDS: A Simple Deep Reinforcement Learning Dialogue System,https://www.reddit.com/r/MachineLearning/comments/41ouj0/simpleds_a_simple_deep_reinforcement_learning/,InaneMembrane,1453212994,,1,5
533,2016-1-19,2016,1,19,23,41ozv1,A recurrent neural network with the scripts for every episode of friends and it learned to generate new scenes,https://www.reddit.com/r/MachineLearning/comments/41ozv1/a_recurrent_neural_network_with_the_scripts_for/,julian88888888,1453215030,,13,41
534,2016-1-20,2016,1,20,1,41pcqe,nBLAS - Node.js C++ bindings for all BLAS routines,https://www.reddit.com/r/MachineLearning/comments/41pcqe/nblas_nodejs_c_bindings_for_all_blas_routines/,mateogianolio,1453220434,,2,3
535,2016-1-20,2016,1,20,2,41pjtq,pystruct: Structured learning framework for python,https://www.reddit.com/r/MachineLearning/comments/41pjtq/pystruct_structured_learning_framework_for_python/,tandim12,1453222891,,1,6
536,2016-1-20,2016,1,20,2,41posw,Organizing My Emails With A Neural Net,https://www.reddit.com/r/MachineLearning/comments/41posw/organizing_my_emails_with_a_neural_net/,regalalgorithm,1453224533,,5,1
537,2016-1-20,2016,1,20,2,41pquo,What is the best way to select a threshold that best separates two gaussians with unequal variances? (histogram link in text),https://www.reddit.com/r/MachineLearning/comments/41pquo/what_is_the_best_way_to_select_a_threshold_that/,forever_erratic,1453225217,"Hello,

I'm doing some image processing and would like to be able to automatically choose a threshold for data similar to that in the link:

http://imgur.com/4zNsn3j

By eye, I would choose a threshold around 50.

Typical image analysis thresholding using Otsu's method doesn't work, because there are more data in the first peak than in the second. I can fit two gaussians to this data and get reasonable means and variances, and I would like to use these to find the threshold that best separates the gaussians. Is there an established method to do this? 

Or does someone have a different suggestion?

Thanks!
",7,0
538,2016-1-20,2016,1,20,2,41pthf,"What is an example of a SVM kernel, where one implicitly uses an infinity-dimensional space?",https://www.reddit.com/r/MachineLearning/comments/41pthf/what_is_an_example_of_a_svm_kernel_where_one/,themoosemind,1453226111,,3,0
539,2016-1-20,2016,1,20,2,41ptoa,"""Pre-training"" RNNs by extreme overfitting to small fraction of complete dataset?",https://www.reddit.com/r/MachineLearning/comments/41ptoa/pretraining_rnns_by_extreme_overfitting_to_small/,harponen,1453226172,"Recently I've tested some of my more slowly training RNNs by first training with a small subset of training data and basically overfitting the s**t out of it and then continuing the training with the full dataset. Seems to be working fine (and it's in fact not too far from the idea of curriculum learning).

Can anyone enlighten me if this is a good idea or a bad one in terms of the quality of the local minimum?

EDIT: to be more specific, I'm not expecting the model to train any faster, the idea of initially using a small dataset would just be to see if the initializations are good and only then training with the full dataset.",27,2
540,2016-1-20,2016,1,20,4,41qf2g,Is Face Recognition (NOT detection) currently possible with neural networks?,https://www.reddit.com/r/MachineLearning/comments/41qf2g/is_face_recognition_not_detection_currently/,MysteriousArtifact,1453233451,"The task:

* Given a single face, pull the closest match from a database of facial images.

Facial detection (""is there a face in the picture?"") has been thoroughly solved, but is there any current connectionist/network method of identifying a specific face? From my limited knowledge, it would seem almost impossible to train such a network, because the network would need to learn to classify an arbitrary image into a ridiculous number of categories representing each person in the database. Either that, or you'd have to train a whole network to recognize just a single person, and run the image through that.

Any good options, or is this unsolved territory?",17,0
541,2016-1-20,2016,1,20,6,41qyiz,Tensorflow seq2seq model getting low perplexity but unsatisfying results,https://www.reddit.com/r/MachineLearning/comments/41qyiz/tensorflow_seq2seq_model_getting_low_perplexity/,thecodingmonk,1453240355,"I'm trying to train a model with Tensorflow seq2seq implementation but I'm having some issues with its performance (not speed, but accuracy). The dataset is very simple and consists of 2.5 million example sentences (and their corresponding output sentences) and a small vocabulary size both in input (145) and in output (8). Given the small vocabulary size I thought the number examples, even if it is not that high, would more than appropriate, but the model still performs badly. I tried using 2 layers of 128 and 256 units (all the other parameters are set with the default in Tensorflow seq2seq example), and during training perplexity reaches 1.0 after just 500-800 iterations, but the output of the model is still wrong too many times. What should I look into to improve the performance? Quality/quantity of data? Model settings?
",7,4
542,2016-1-20,2016,1,20,8,41rd55,Larger than memory classification using Scikit Flow and Dask Dataframe,https://www.reddit.com/r/MachineLearning/comments/41rd55/larger_than_memory_classification_using_scikit/,tandim12,1453245458,,2,5
543,2016-1-20,2016,1,20,8,41ri9o,OpenFace: Free and open source face recognition with deep neural networks,https://www.reddit.com/r/MachineLearning/comments/41ri9o/openface_free_and_open_source_face_recognition/,Datasaur,1453247322,,0,15
544,2016-1-20,2016,1,20,9,41rn9d,Ask ML: how does Torch manage its memory?,https://www.reddit.com/r/MachineLearning/comments/41rn9d/ask_ml_how_does_torch_manage_its_memory/,[deleted],1453249176,[deleted],0,1
545,2016-1-20,2016,1,20,9,41rq33,Was SGD proven to be generally better than other optimization algorithms for determing weights in neural networks?,https://www.reddit.com/r/MachineLearning/comments/41rq33/was_sgd_proven_to_be_generally_better_than_other/,thecity2,1453250246,"Seems almost universal now that stochastic gradient descent is the ""go to"" algorithm used for optimization (via backpropagation) of neural networks. How much work was done in the past (and how long ago?) to examine alternatives, such as SA, PSO, GA? Have these been re-visited with newer/faster hardware?

How significant a problem is global optimization, in general, and how does SGD not run into issues with reaching local minima before a globally optimal solution is found?

Especially for smaller datasets, I would think these other optimization algos might be of some benefit? Curious to learn more!",9,3
546,2016-1-20,2016,1,20,10,41rw84,Recognizing *that* there's a face (not whose face is it) whats the smallest footprint implementation of that?,https://www.reddit.com/r/MachineLearning/comments/41rw84/recognizing_that_theres_a_face_not_whose_face_is/,utunga,1453252567,"Hi /r/MachineLearning! Impressive work by OpenFace and the like but my requirement is (in a mobile app) simply recognizing that there *is* a face in the frame, and where it is (ie pin point the nose). Do you know of any existing implementations for this much simpler task? Preferably something already tuned for performance and/or small memory footprint etc? I'm finding that whenever I google for this I keep finding full fledged face recognition stuff, so any links or suggestions much appreciated.",4,0
547,2016-1-20,2016,1,20,10,41rwin,DanDoesData: Deep MultiLayer Perceptron tutorial with Theano,https://www.reddit.com/r/MachineLearning/comments/41rwin/dandoesdata_deep_multilayer_perceptron_tutorial/,vanboxel,1453252681,,0,2
548,2016-1-20,2016,1,20,10,41s2iw,Yoshua Bengio's Quora Session,https://www.reddit.com/r/MachineLearning/comments/41s2iw/yoshua_bengios_quora_session/,QuoraSessions,1453255035,,0,32
549,2016-1-20,2016,1,20,12,41si28,[Idea] Data Preprocessing for semantic word embedding models.,https://www.reddit.com/r/MachineLearning/comments/41si28/idea_data_preprocessing_for_semantic_word/,cuban_CIFAR,1453261239,"Read into word2vec today. This is very exciting stuff and its been around for quite a while now.
 
I have this idea for attracting words into separate clusters in our embedding space by doing the following.   
  
""This is a sentence from corpus a"" becomes   
""#cat_a This #cat_a is #cat_a a #cat_a sentence #cat_a from #cat_a corpus #cat_a a""  
  
Likewise:  

""This is a sentence from corpus b"" becomes   
""#cat_b This #cat_b is #cat_b a #cat_b sentence #cat_b from #cat_b corpus #cat_a b""  
  
This should cause a massive disturbance in the spatial distribution of our embedding model by introducing bias that favors separation of data. Intuition being that #cat_b is never going occur with #cat_a 
  
Its not likely anyone has experimented with this, so I wont ask for pointers, but after reading into OpenFace , I've realized that they're doing some sort of clustering in embedded space as well that might resemble my idea.   
  
Any thoughts?",3,0
550,2016-1-20,2016,1,20,14,41sul3,Detecting Outliers In High Dimensional Data Sets,https://www.reddit.com/r/MachineLearning/comments/41sul3/detecting_outliers_in_high_dimensional_data_sets/,shahroom,1453266639,,0,30
551,2016-1-20,2016,1,20,16,41ta81,Semi-Automatic Filling Machine - How they are Different from Automatic Filling Machine,https://www.reddit.com/r/MachineLearning/comments/41ta81/semiautomatic_filling_machine_how_they_are/,sonusinternational,1453274325,,0,1
552,2016-1-20,2016,1,20,16,41tbs0,"Fluid Bed Dryer, Pharma Machinery | Anchormark.com",https://www.reddit.com/r/MachineLearning/comments/41tbs0/fluid_bed_dryer_pharma_machinery_anchormarkcom/,Anchormark1,1453275200,,0,1
553,2016-1-20,2016,1,20,17,41tj8h,An overview of gradient descent optimization algorithms,https://www.reddit.com/r/MachineLearning/comments/41tj8h/an_overview_of_gradient_descent_optimization/,iori42,1453279800,,0,36
554,2016-1-20,2016,1,20,18,41tmty,Anomaly Detection in machine log data,https://www.reddit.com/r/MachineLearning/comments/41tmty/anomaly_detection_in_machine_log_data/,EugSeverinho,1453282269,"Hi guys, i am doing a masters thesis in anomaly detection and i have a question:

How can i find the 'distance' between two events in log-data? Events in this dataset consists of messages that a software system sends to a central maintenance database. I find it hard to find the actual features of this messages and thus compare two (or more) data entries. Do you guys have some good sources that tackle the problems i described?",3,0
555,2016-1-20,2016,1,20,18,41tocb,LUNA16 - pulmonary lung nodule detection challenge,https://www.reddit.com/r/MachineLearning/comments/41tocb/luna16_pulmonary_lung_nodule_detection_challenge/,arnaudsetio,1453283266,"Dear /r/MachineLearning,
 
We are glad to invite you to participate in the upcoming nodule detection challenge **LUNA16**! This challenge focuses on a **large scale evaluation of automatic nodule detection algorithms** using LIDC-IDRI database.

Lung cancer is the leading cause of cancer-related death worldwide. Screening high risk individuals for lung cancer with low dose CT scans is now being implemented in the United States and other countries are expected to follow soon. LUNA16 is a precursor of the upcoming high-profile Coding4Cancer challenge, which invites coders to create the best computer algorithm to identify a person as having lung cancer based on one or multiple low-dose CT images. To be able to solve the Coding4Cancer challenge, and detect lung cancer in an early stage, pulmonary nodules, the early manifestation of lung cancers, have to be located. LUNA16 represents the possibility to compare developed and under-development CAD systems.

For more information and registration, visit the LUNA16 website!

http://luna16.grand-challenge.org/",1,31
556,2016-1-20,2016,1,20,21,41u47y,Upgrades Exiting Bulk Handling Material Machines with Modern Ones,https://www.reddit.com/r/MachineLearning/comments/41u47y/upgrades_exiting_bulk_handling_material_machines/,[deleted],1453292702,[deleted],0,1
557,2016-1-20,2016,1,20,21,41u4nr,Introduction to Semi-Supervised Learning with Ladder Networks,https://www.reddit.com/r/MachineLearning/comments/41u4nr/introduction_to_semisupervised_learning_with/,Foxtr0t,1453292942,,6,89
558,2016-1-21,2016,1,21,0,41up76,what's the simplest but most bad ass tool for topic modeling?,https://www.reddit.com/r/MachineLearning/comments/41up76/whats_the_simplest_but_most_bad_ass_tool_for/,textClassy,1453302215,"I'm willing to add a bunch of complexity if its worth it in improved classification accuracy ... I'm trying to find the right return on complexity I guess ... my best option so far is python's lda module. Also, does anyone have recommendations for a professor to read a lot of on this besides Blei?",3,0
559,2016-1-21,2016,1,21,0,41uqt2,Machine learning for artists,https://www.reddit.com/r/MachineLearning/comments/41uqt2/machine_learning_for_artists/,tsutomun,1453302842,,0,1
560,2016-1-21,2016,1,21,0,41urac,Why my denoising autoencoder reconstruct always my input when I train it with a single MNIST sample and very bad parameters?,https://www.reddit.com/r/MachineLearning/comments/41urac/why_my_denoising_autoencoder_reconstruct_always/,leoguti85,1453303015,"Im testing my denoising autoencoder implementation on Tensorflow and I use a single MNIST sample to reconstruct the input. When I train the network  with gradient descent and very bad parameters (few iterations, ""big"" learning rate, etc).. the reconstruction is quite similar to the output, and dont see the impact the bad tunning on the network. Thank you.
",0,0
561,2016-1-21,2016,1,21,0,41urvd,"In neural nets, is it better to concat/merge before or after activation?",https://www.reddit.com/r/MachineLearning/comments/41urvd/in_neural_nets_is_it_better_to_concatmerge_before/,cesarsalgado,1453303246,,2,0
562,2016-1-21,2016,1,21,0,41ux92,[1601.04920] Understanding Deep Convolutional Networks,https://www.reddit.com/r/MachineLearning/comments/41ux92/160104920_understanding_deep_convolutional/,siddharth-agrawal,1453305223,,8,10
563,2016-1-21,2016,1,21,0,41uy18,Train NN to remember x-y data pairs,https://www.reddit.com/r/MachineLearning/comments/41uy18/train_nn_to_remember_xy_data_pairs/,poule_st,1453305515,"Hello!
I'm new in MachineLearning so I apologize if my question doesn't make any sense. :/
I need to store many data pairs (x,y) but I'm not allowed to store it in database table which would be the easiest solution so is it possible to train neural network so when ever I ask it for ""x"" it returns it's ""y"" pair? NN would have to store thousands of (x,y) pairs.
Thanks!",7,0
564,2016-1-21,2016,1,21,1,41v2ka,[1601.04589] Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis,https://www.reddit.com/r/MachineLearning/comments/41v2ka/160104589_combining_markov_random_fields_and/,Ameren,1453307185,,14,24
565,2016-1-21,2016,1,21,3,41vlbn,Machine learning for marketers,https://www.reddit.com/r/MachineLearning/comments/41vlbn/machine_learning_for_marketers/,manda_auror,1453314175,[removed],0,1
566,2016-1-21,2016,1,21,4,41vvn3,Introducing Kaggle Datasets,https://www.reddit.com/r/MachineLearning/comments/41vvn3/introducing_kaggle_datasets/,steven2358,1453317643,,1,13
567,2016-1-21,2016,1,21,5,41w5tg,PN-Net: Conjoined Triple Deep Network for Learning Local Image Descriptors,https://www.reddit.com/r/MachineLearning/comments/41w5tg/pnnet_conjoined_triple_deep_network_for_learning/,alxndrkalinin,1453321176,,0,0
568,2016-1-21,2016,1,21,6,41wf9g,Article : Towards Artificial General Intelligence,https://www.reddit.com/r/MachineLearning/comments/41wf9g/article_towards_artificial_general_intelligence/,apsarath,1453324665,,7,0
569,2016-1-21,2016,1,21,6,41wfwu,Theano vs Tensorflow as a beginner,https://www.reddit.com/r/MachineLearning/comments/41wfwu/theano_vs_tensorflow_as_a_beginner/,Tandorator,1453324909,"Me and a friend want to build some simple applications using neural networks. We are mainly interested in LSTM's, but not exclusively. We are doing okay on the theory part of nn's, but we struggle with the implementation of it in python. We are both mathematicians, so we we definitely lack some programming skills since we only have experience with matlab and little with python. We started using tensorflow and we have been struggling through their tutorials, and we find that it is not very clearly documented for programming amateurs like us. Would it be wise to switch to Theano? Some googling gave me the impression that Theano is more mature and better documented. I had an easier time to find tutorials and example code aswell. 
Our reasoning for starting with Tensorflow  is because we are new and have to learn the machine learning api from scratch anyway, so we chose tensorflow since it is newer (and because we are google fanboys, I guess).

Thanks for your advice! ",22,8
570,2016-1-21,2016,1,21,6,41wm0g,Best linear regression solver for memory,https://www.reddit.com/r/MachineLearning/comments/41wm0g/best_linear_regression_solver_for_memory/,anonDogeLover,1453327052,"Which solver uses the least amount of memory for sklearn's ridge regression model? I have more features than datapoints. 9000 features works fine but 30,000+ maxes my memory and my PC freezes.

Also, which is the fastest?",5,0
571,2016-1-21,2016,1,21,7,41wrlk,Machine Learning Data Sets and my Master's Thesis,https://www.reddit.com/r/MachineLearning/comments/41wrlk/machine_learning_data_sets_and_my_masters_thesis/,Eidbanger,1453329134,"I am a M.S. Comp Sci student and want to do my project/thesis on machine learning. I was thinking of applying a learning algorithm to an interesting data set (such as CT scans of lung cancer patients) such as in the [LUNA challenge](https://www.reddit.com/r/MachineLearning/comments/41tocb/luna16_pulmonary_lung_nodule_detection_challenge/). I am also interested in security applications as well, but biggest fear is do something that has already been done before.

In my [post in r/cscareerquestions](https://www.reddit.com/r/cscareerquestions/comments/41srbg/masters_thesis_domain_set_advice_machine_learning/) I was given a few suggestions for what I can do. My previous suggestion of applying a predictive learning algorithm on fantasy sports was deemed ""unsexy"" by my adviser.

So my questions are:

* Are there any interesting data sets that I could run learning algorithms on for my master's project?

* If I decide to do a thesis, what areas of machine learning are the newest and up-coming research oriented?

**TL;DR** Need topic for a machine learning related Master's thesis/project.

Thanks. ",7,0
572,2016-1-21,2016,1,21,8,41x10b,"ML training: Coursera Specialization, or Udacity Nanodegree?",https://www.reddit.com/r/MachineLearning/comments/41x10b/ml_training_coursera_specialization_or_udacity/,lefnire,1453332685,"Hello you brainiacs! I've just finished Andrew Ng's famous Coursera course &amp; I'm hooked. I want to go all in; but for long-winded reasons around residence-transience I won't attending university. So I'd like to take one of these MOOCs-style ""micro degrees""; that is, a series of related/sequential courses rather than disjoint a la carte courses. 

Unless I'm missing other big ones (do tell!) I've narrowed it down to [Cousera's Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning) vs [Udacity's Machine Learning Engineer Nanodegree](https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009). Udacity's is certainly much more expensive, but I'd be willing if it's superior. My primary goal is getting into industry, Silicon-Valley-style. In particular, if any tech giants prefer one over the other that'd be an important decision point. Though if one were much superior educationally, that'd trump. 'Course, I don't want to be too selfish, so if there's a general pros/cons breakdown that could help someone who stumbles upon this thread - [mathematical](http://images6.fanpop.com/image/photos/36200000/Adventure-Time-With-Finn-and-Jake-image-adventure-time-with-finn-and-jake-36211266-786-1017.png)!

Thanks much in advance.",4,0
573,2016-1-21,2016,1,21,11,41xuei,Deep learning free course on Udacity - Built by Google,https://www.reddit.com/r/MachineLearning/comments/41xuei/deep_learning_free_course_on_udacity_built_by/,clbam8,1453344112,,43,287
574,2016-1-21,2016,1,21,12,41y4u7,How can i calculate computing power requirements of neural network?,https://www.reddit.com/r/MachineLearning/comments/41y4u7/how_can_i_calculate_computing_power_requirements/,darkconfidantislife,1453348471,"Hi guys! I have a question. How do i calculate the computing power requirements of my neural network? I'm thinking to calculate the flops, do i need to worry about the number of connections?
Thanks in advance guys",15,0
575,2016-1-21,2016,1,21,13,41y6zx,Would you recommend any specific python APIs for building a recommender engine?,https://www.reddit.com/r/MachineLearning/comments/41y6zx/would_you_recommend_any_specific_python_apis_for/,[deleted],1453349374,[deleted],0,0
576,2016-1-21,2016,1,21,13,41y8sm,does anyone have experience with using R analyzing google analytics data?,https://www.reddit.com/r/MachineLearning/comments/41y8sm/does_anyone_have_experience_with_using_r/,jennifercqcq,1453350126," I am a data analyst and doing a lot of analysis on web traffic. I know using R to analyze the traffic is the new trend. Does anyone have experience? can you share some resources for me to learn?

Thank you so much",0,0
577,2016-1-21,2016,1,21,14,41yh32,Project ideas in machine learning?,https://www.reddit.com/r/MachineLearning/comments/41yh32/project_ideas_in_machine_learning/,lifieemodd,1453353738,"I am just starting to get my feet wet in machine learning and have just completed Andrew Ng's Machine Learning course. I am looking for ideas/problems to work on which will take me deep into machine learning and could also be a good candidate for a bachelor's thesis project (worth 30 credits). Any ideas/links/research papers I can refer to?

Thanks for providing some direction!",9,3
578,2016-1-21,2016,1,21,15,41yqeq,Can dropout reduce training error?,https://www.reddit.com/r/MachineLearning/comments/41yqeq/can_dropout_reduce_training_error/,yield22,1453358187,"Dropout is known for reducing generalization error, acting like a regularizer, it seems to me dropout would increase training error. Is it possible (in which cases) that dropout reduces both training error and test error? (by training error, I mean measured without dropout during forward pass, kinda like using training data as validation set and measure its performance)",6,0
579,2016-1-21,2016,1,21,17,41z4iw,KBOC: Keystroke Biometrics Ongoing Competition,https://www.reddit.com/r/MachineLearning/comments/41z4iw/kboc_keystroke_biometrics_ongoing_competition/,aythamimm,1453366626,"Keystroke Biometrics Ongoing Competition (KBOC), an official IEEE BTAS 2016 competition organized by the ATVS Biometric Recognition Group exploiting the BEAT Platform. No need to be an expert on Keystroke Biometrics to stand out, researchers and practitioners in other fields including general machine learning and pattern recognition are more than welcome. More info: https://sites.google.com/site/btas16kboc/",0,0
580,2016-1-21,2016,1,21,18,41z5fb,DeepLearning for Laptop. Is this a good config?,https://www.reddit.com/r/MachineLearning/comments/41z5fb/deeplearning_for_laptop_is_this_a_good_config/,koormoosh,1453367235,"Typo in the title: DeepLearning ""on"" Laptop

I know that the general opinion is against using laptops for DNN, but can you guys share your opinions on the following configuration, it is an Alienware 15 r2 laptop:
 
Intel Core i7-6820HK (Quad-Core, 8MB Cache, Dynamically Overclocked up to 4.4GHz)

16GB Dual Channel DDR4 2133MHz (8GBx2)

1TB PCIe SSD (Boot) + 1TB 7200RPM SATA 6Gb/s (Storage)

NVIDIA GeForce GTX 980M with 8GB GDDR5 

And how  about adding the ""Alienware Graphics Amplifier""?",29,4
581,2016-1-21,2016,1,21,18,41z69a,"Correlation based feature selection, unequal feature length",https://www.reddit.com/r/MachineLearning/comments/41z69a/correlation_based_feature_selection_unequal/,Janderhungrige,1453367774,"Dear machine learners,  

I (matlab user) am building the feature matrix to use the CFS with. But I have features of different size. I got different long and short term features form an ECG. The long term features are calculated over the whole data (several hours), the short term features over windows of several minutes. Therefore, I have in the extreme only one value for the long term feature and thousands for the short term feature.   
To calculate the correlation, the length need to be equal.  

Also, the length of my classes are different.  If  I am correct, I also need the same length for each class for the Pearson product-momentum.


Thanks for your help in advance. 
Yours Jan ",5,0
582,2016-1-21,2016,1,21,21,41znlp,Predict parsing grammar from data,https://www.reddit.com/r/MachineLearning/comments/41znlp/predict_parsing_grammar_from_data/,mikhailkudinov,1453377804,"Hi, everyone! 
Does anyone know relevant parapers for the following problem:

Assume we have reasonably documented API for a service. If we have a grammar (say, CMU Phoenix) we can provide communication with a service by means of natural language so that sentences are mapped onto function calls. We would like to contruct such gramamar automatically from API description. Is there something on this topic?
",0,0
583,2016-1-21,2016,1,21,21,41zpru,Reducing False Positives in Face Recognition,https://www.reddit.com/r/MachineLearning/comments/41zpru/reducing_false_positives_in_face_recognition/,rafaspadilha,1453378799,"Hey guys, so I'm working on a Face Recognition project aimed to authenticate a person to use a single-user system (such as a smartphone). In a scenario like this, I would like to have the least false positives as possible (I don't mind asking the registered user to take another picture, but I can't allow an unregistered user to be allowed to use the target system).

I'm using a linear-SVM on top of my features that trained with pair of feature vectors. I feed the SVM with two FV and it answers if they are the same user or not. One of the FVs comes from the person trying to be authenticated and the other is fetched from a pool of FVs that belongs to the registered user.

So my mean precision is about 75% (1 false positive per 3 true positives) and my recall is about 98% (almost no false negatives).

I've done a grid search in my parameters using the [F-score](https://en.wikipedia.org/wiki/F1_score) (F-2, in order to give more importance to precision and not to recall), and chose the best parameters to maximize my F-2.

Do you guys know other ways to reduce the number of false positives? Or maybe have any tip on what I should be doing?",7,0
584,2016-1-21,2016,1,21,23,4204dx,"Are there ML applications for sound recognition, particularly music?",https://www.reddit.com/r/MachineLearning/comments/4204dx/are_there_ml_applications_for_sound_recognition/,jokoon,1453385602,"Everyone knows big concerts sometimes have big lighting sets to give more ambiance to them. Colors and light synchronization seem to change depending on the song, except it's often poorly done, since it's mostly manual.

Is it possible for ML to recognize a melody, a note that is repeating over time, an instrument? My goal would be to wire those different signals into a machine and choose what effect to give them (a flash on screen, some light, some oscilloscope, some color) depending from their intensity and rhythm. Everyone knows those weird video effect on media players, but they don't seem to have much sense in them.

So for example, each time the drum is hit, it generates a signal, evertyime the guitar is hit, it generates a signal, with its note and intensity, all of this on a track, a little like a midi file.

I'm not sure if this can be done with what speech recognition does, since music includes many many more types of sound than voice.


EDIT: i want to make it clear that what interests me the most is separating a song into several different tracks: one for the guitar, one for the drums, one for the harmonica, one for the piano, one for the electronic beats. Since the rhythm isn't always perfect and can vary, I want to separate those first. I think it's mostly the work of a timed signal filter: for example if the drums and guitar play at the same time, their signals are mangled, so I want to ""unmangle"" them. For that I might need to have a filter which I can tune over time to precisely cut what i want.",5,5
585,2016-1-21,2016,1,21,23,420612,Python Library to do Symbolic Non-Linear Model Fitting (Levenberg Marquardt),https://www.reddit.com/r/MachineLearning/comments/420612/python_library_to_do_symbolic_nonlinear_model/,soulslicer0,1453386332,"Basically,

I would like to know if there exists a library in python that lets me input in a matrix as such perhaps:

-PosA = [XChanging YChanging ZChanging]

-PosB = [XChanging YChanging ZChanging]

-PosB = [A Transform Matrix]*PosB

Basically, I want to know if there is a python library that can estimate the transform matrix above given a set of PosA and PosB data points. I would like it to be represented as a matrix as such, but just to indicate that the XYZ values are changing, maybe an array of sorts. Then it would apply Levenberg Marquardt/Gradient Descent and solve for the transform matrix.

Does such a library exist? I know matlab has fitnlm but I have to explicitly give it a straight line equation instead of matrix form.",2,0
586,2016-1-21,2016,1,21,23,4209s4,How do I perform clustering on words based on their meaning?,https://www.reddit.com/r/MachineLearning/comments/4209s4/how_do_i_perform_clustering_on_words_based_on/,n00bto1337,1453387820,"Is it possible to cluster words based on how similar they are in meaning to each other, or how similar they are to a particular category? For example, if I have a category, Sports, I want all words like football, goal, strike, etc. to fall under that cluster. How do I do that?",8,0
587,2016-1-22,2016,1,22,0,420cd2,Advice needed! Biostatistics MSc grad wanting to pursue a PhD in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/420cd2/advice_needed_biostatistics_msc_grad_wanting_to/,soenuedo,1453388847,"Hi all,

I recently graduated with a MSc in Biostatistics from the University of Toronto, and am currently taking some time to consider my options for a PhD while working as a statistical analyst in academia. ML and data science are (broadly speaking) two areas that I am very interested in.

A little bit about myself: I come from an unconventional background, with a Bachelor's in Pathobiology/Biochemistry. I was able to take a few CS/Stats/Math courses during my undergrad, and luckily enough, was accepted into the Msc Biostats program. I did well in my Masters, and felt that I was able to make leaps in my statistical/mathematical knowledge in a very short amount of time. I consider myself a pretty fast learner capable of learning independently. 

My goal: I would like to pursue a PhD in Machine Learning (more applied, less theoretical) in a good university/under a good supervisor in USA/Canada (I am Canadian). One area that I'd like to apply ML in is global health. I love learning at a high level and I do feel a PhD is what I want to pursue.

My question: For someone like me who has very limited ties to the ML community, how can I make myself competitive for PhD applications in top schools? I understand that it will likely take some time to build up a strong application, but in the meantime, what are some common tools/skills (programming languages, softwares, etc) that I can learn to hopefully accelerate the process? What are some things I can do to make myself stand out in a crowd of very, very talented and smart individuals?

Really appreciate any advice you may have!",3,0
588,2016-1-22,2016,1,22,0,420iw9,Analyzing 50k fonts using deep neural networks,https://www.reddit.com/r/MachineLearning/comments/420iw9/analyzing_50k_fonts_using_deep_neural_networks/,alxndrkalinin,1453391222,,23,179
589,2016-1-22,2016,1,22,0,420kom,Talla Sells Virtual Assistants for the Workplace as AI Startups Focus,https://www.reddit.com/r/MachineLearning/comments/420kom/talla_sells_virtual_assistants_for_the_workplace/,brooke-torres,1453391872,,0,0
590,2016-1-22,2016,1,22,1,420nvu,Learn to do Sentiment Analysis with the bag-of-words,https://www.reddit.com/r/MachineLearning/comments/420nvu/learn_to_do_sentiment_analysis_with_the_bagofwords/,ataspinar,1453393013,,0,3
591,2016-1-22,2016,1,22,1,420sjj,In need of Datasets for credit card fraud detection using anamoly detection,https://www.reddit.com/r/MachineLearning/comments/420sjj/in_need_of_datasets_for_credit_card_fraud/,[deleted],1453394582,[deleted],0,0
592,2016-1-22,2016,1,22,1,420th7,breaking neuraltalk - or how far away we are from human level image captioning,https://www.reddit.com/r/MachineLearning/comments/420th7/breaking_neuraltalk_or_how_far_away_we_are_from/,toisanji,1453394893,,1,0
593,2016-1-22,2016,1,22,2,420zqz,"Does anyone know of good datasets to try out Anamoly Detection Algorithms on? Maybe in Credit Card fraud or malicious activities, terrorism",https://www.reddit.com/r/MachineLearning/comments/420zqz/does_anyone_know_of_good_datasets_to_try_out/,Daniel6789123,1453397048,"I'm doing a thesis on Anamoly Detection and I'm trying to test out a few of my new theoretical analysis' validity. Could you please share some information of any datasets you know of in this regard?

Thank You

PS: I made a post before without giving much details and it got downvoted, but, honestly, I quite didn't get a hang of reddit quickly. Sorry, and I've deleted that post.",7,7
594,2016-1-22,2016,1,22,2,4212v6,"My ex - whore, nickname: Samantha118. Search can be registered",https://www.reddit.com/r/MachineLearning/comments/4212v6/my_ex_whore_nickname_samantha118_search_can_be/,batamasan,1453398089,,0,1
595,2016-1-22,2016,1,22,3,421b7v,Is there such thing as a software that can learn how to automatically carry out tasks for you on a computer?,https://www.reddit.com/r/MachineLearning/comments/421b7v/is_there_such_thing_as_a_software_that_can_learn/,HHughes12,1453401113,[removed],2,0
596,2016-1-22,2016,1,22,3,421ev6,Learning About Deep Learning!,https://www.reddit.com/r/MachineLearning/comments/421ev6/learning_about_deep_learning/,amplifier_khan,1453402411,,0,0
597,2016-1-22,2016,1,22,6,4222jz,how complicated is topic modeling as far as machine learning concepts go?,https://www.reddit.com/r/MachineLearning/comments/4222jz/how_complicated_is_topic_modeling_as_far_as/,textClassy,1453410811,"After spending a week or so, it looks significantly more complicated than some of the basic learning algorithms but probably less complicated than deep learning, is this more or less accurate?",2,0
598,2016-1-22,2016,1,22,6,4222z7,Procedures for publishing ML papers while working at a tech start-up?,https://www.reddit.com/r/MachineLearning/comments/4222z7/procedures_for_publishing_ml_papers_while_working/,sleepicat,1453410957,"What are the typical procedures that tech employees go through in order to receive approval to publish a paper on their work?  I'm asking mainly with regard to IP considerations.

Does anyone know what the publication procedures are at larger R&amp;D tech groups, such as Google, FB, Microsoft, etc.?

Do employees ask permission prior to writing the first draft, or do they wait until they're almost ready to submit a manuscript before seeking official company approval?  

",1,0
599,2016-1-22,2016,1,22,6,4223tx,What does the roadmap look like for a complete beginner to building a practical ML solution?,https://www.reddit.com/r/MachineLearning/comments/4223tx/what_does_the_roadmap_look_like_for_a_complete/,1mike12,1453411262,"I know it's a dumb title, but when I first got started in software, one thing I wished I had was a rough roadmap of how long it took to get to one skillset to another, and what cool stuff you could build with said skills. Years later as a working developer, I like being able to explain to friends of mine asking the same questions. 

I think ML is a little different given that what you already know, especially in math, greatly affects your timeline. Googling turned up nothing, maybe there's already a good writeup?

If not, say I took engineering probability, linear algebra, algorithms and know how to program. From knowing bupkiss, how long would it take for me to be able to get good enough to make a simple classifier? 1 year of study?


Thanks!",9,0
600,2016-1-22,2016,1,22,6,4226ba,Hey boys I'm Nelly and I'm looking for a sex partner.. HELP ME!,https://www.reddit.com/r/MachineLearning/comments/4226ba/hey_boys_im_nelly_and_im_looking_for_a_sex/,kabiphabo1978,1453412124,,0,1
601,2016-1-22,2016,1,22,7,422grh,I want to mine Goodreads book reviews to see: In which category of books are top-rated comments on the top-rated books most likely to be negative? [Python],https://www.reddit.com/r/MachineLearning/comments/422grh/i_want_to_mine_goodreads_book_reviews_to_see_in/,[deleted],1453415801,[deleted],1,0
602,2016-1-22,2016,1,22,11,423gjk,NBA player judging system,https://www.reddit.com/r/MachineLearning/comments/423gjk/nba_player_judging_system/,CrazyEggy,1453429735,"I'm thinking of a project that develop a judging system that after tons of games learning on the result data of the game (for example rebound, score, assist, turnover and so on), it can learn the ability that determine to different position (Center Forward Guard like that), which is the most important behavior they should make and what's the most relevant coefficients to the game winning and rating the player based on this ability correctly, at least on the data level.
I'm new to the Machine learning area and only looked some online courses video. Could anyone give me some advice on what method to use so I can learn deeper on that aspect? I'm currently thinking of Semi-Supervised Learning, is that a right direction? Thanks.",2,0
603,2016-1-22,2016,1,22,11,423jgz,looking for machine learning algorithms that could potentially be applied to a simple problem,https://www.reddit.com/r/MachineLearning/comments/423jgz/looking_for_machine_learning_algorithms_that/,wtfisthat69,1453430926,"idea: a robot that massages your calves and thighs to ease  knots you have in your muscles. basically an automated foam roller (http://breakingmuscle.com/mobility-recovery/what-is-a-foam-roller-how-do-i-use-it-and-why-does-it-hurt). 

details: there are sensors that detect where the knot is and how your muscle is responding to the machine, and there are actuators that do the massaging. there is also a system that can take input from the user on whether something felt good or bad, or if the user wants the machine to move in a specific way, or alter pressure in a specific area, etc. and we want the machine to learn and personalize to the user. 


what are some algorithms that can be applied here? preferably ones that are 'cheap' computationally. 


(background: i'm going to a brain storming session with a bunch of programmers but i don't know much about machine learning) -- thanks in advance",2,0
604,2016-1-22,2016,1,22,12,423nht,Career pathway into machine learning research for a pure math PhD ?,https://www.reddit.com/r/MachineLearning/comments/423nht/career_pathway_into_machine_learning_research_for/,maxmoo,1453432603,"I did my PhD in Pure Math (Arithmetic Geometry), and after deciding I didn't want to try for a career in academia, I've been working as a data scientist in a large+ tech company for the last 2 years, mostly working in Python, Hive/Spark, AWS and SQL. I like my work and I've got really good career prospects as a Data Scientist/Data Engineer, but I'd love to move into something where I can use my Math background a bit more. Does anyone have ideas for a career path I could try that would lead more to the cutting edge of Machine Learning/AI, while still having an engineering aspect? I enjoy working as part of a team, and I don't want to do another PhD ... is it worth trying to get on a research grant even though my PhD isn't in Computer Science? Or are there industry jobs I should be looking at?",6,0
605,2016-1-22,2016,1,22,12,423r6e,Speech Recognition: Utilizing MFCC values,https://www.reddit.com/r/MachineLearning/comments/423r6e/speech_recognition_utilizing_mfcc_values/,poincare101,1453434185,[removed],0,1
606,2016-1-22,2016,1,22,13,423yy8,K-means: what do you do with stale centroids,https://www.reddit.com/r/MachineLearning/comments/423yy8/kmeans_what_do_you_do_with_stale_centroids/,0xA1,1453437522,"So I'm running k-means and I've come to this situation where after a few iterations, some of my centroids will no longer be the closest centroid for any point in my dataset. Thus I'm calling that stale. I'm currently just skipping over these centroids on the subsequent iterations because I think that they don't actually represent the data well anymore. However I wanted to see what everyone else would do when you have stale centroids like this.",4,0
607,2016-1-22,2016,1,22,14,42449v,Wire straightening machine Ahmedabad,https://www.reddit.com/r/MachineLearning/comments/42449v/wire_straightening_machine_ahmedabad/,veermachine,1453440006,,0,0
608,2016-1-22,2016,1,22,14,4245p7,Recurring Prediction Model,https://www.reddit.com/r/MachineLearning/comments/4245p7/recurring_prediction_model/,starkiller1990,1453440708,"Hi guys,
Just want some advice, I am trying to design a pipeline for a prediction model for Customer Churn.
What I aim to do is, come up with a list of customers ranked by their likelihood to churn. The problem I have is how to design this so It can be run every month.
I want to avoid using the same data I have to build the model to also use in a testing set which is a big no no.
Here are my ideas but i am having trouble articulating the pipeline:
Start of next month: Extract a Dataset of current customers. End of next month: Flag the customers from the above set who churned.
Now I want to use that set as a train set, but obliviously I can't use the whole set to build the model, and I need a validation to internally validate the model.
I thought I could sample that set, use the sample to train a model, then predict on the remainder.
I then extract another list of customers at the start of the following month and repeat the process.
Is it silly to constantly train a new model? I want to have it dynamically change to include any time varying variables and thought it would be easier to do monthly evaluations on high important variables etc.
thanks for any input into this.",0,0
609,2016-1-22,2016,1,22,16,424huw,Realistic ML / data science projects for practice,https://www.reddit.com/r/MachineLearning/comments/424huw/realistic_ml_data_science_projects_for_practice/,max_moroz,1453446978,"What are good real-life machine learning projects to analyze / practice on?

There's plenty of great Kaggle and KDD Cup projects, but they are all focused exclusively on the very technical side of machine learning - getting a high evaluation score. 

I'm looking for something similar, but with a much more realistic setup, kinda like similar to what the article [Machine Learning Isn't Kaggle Competitions](http://jvns.ca/blog/2014/06/19/machine-learning-isnt-kaggle-competitions/) talks about.

In other words, instead of evaluation metrics, the project would state business goals; some data may be provided, other data can be collected; etc. Ideally, I'd still like to be able to read about others' attempts at solving it on blogs/forums.",5,7
610,2016-1-22,2016,1,22,17,424rmj,Cheating? - Crossvalidation/test splits,https://www.reddit.com/r/MachineLearning/comments/424rmj/cheating_crossvalidationtest_splits/,alrojo,1453452876,"I have a question regarding the use of cross validation/test splits - and if it is considered ""cheating"" in deep learning?

Say I have a dataset of x = 5000 examples.

I do a Cross-validation/test split of the x = 5000 examples, such that:

A= x[1-1000], B =  x[1001-2000], C = x[2001-3000], D = x[3001-4000], E = x[4001-5000]

Say I do the train/valid/test split as follows and train models on the train split using the validation split for early stopping and hyper-parameter optimization.

train/valid/test

1 = ABC / D / E

2 = BCD / E / A

3 = CDE / A / B

4 = DEA / B / C

5 = EAB / C / D

Then I average the test performance over the five splits.

Essentially doing this I can indirectly optimize on my test set, e.g. in the third split the validation set is ""A"" which is the same as the test split in the second split.

What is your opinion?",5,3
611,2016-1-22,2016,1,22,20,4253hf,"David and Goliath, or I Trying to Beat Microsoft at Facial Emotion Detection",https://www.reddit.com/r/MachineLearning/comments/4253hf/david_and_goliath_or_i_trying_to_beat_microsoft/,carlos_argueta,1453461311,,2,0
612,2016-1-22,2016,1,22,21,425dfa,Neural nets: How Regular Expressions brought about Deep Learning,https://www.reddit.com/r/MachineLearning/comments/425dfa/neural_nets_how_regular_expressions_brought_about/,jmethvin88,1453466801,,2,0
613,2016-1-22,2016,1,22,22,425miz,Information extraction for text data - ideas,https://www.reddit.com/r/MachineLearning/comments/425miz/information_extraction_for_text_data_ideas/,warmsnail,1453471105,"TLDR: Need cool ideas for interesting information and patterns I can find in text data (posts, comments) crawled from Facebook. 

Long story: I have at my disposal a pipeline for crawling, updating, storing and processing data (tokenization, lemmatization, POS tagging) from any Facebook website (part of a uni project). I would like find some interesting patterns in the data (patterns which undoubtedly are there :D ) and visualize them in a cool way. 
So far the top idea is to assign emotions to extracted keyphrases (using tf-df) using SVM. The rudimentary version of it is actually already implemented and the corpus is (so far) the stuff crawled from a popular news portal page. The results are not good but I didn't put much time into optimization and annotation of the data. 

I thought I'd throw the idea out here, in case anyone knows of something cool to find. 
-Creating a psychological profile of random users that continuously post based on the words they use? 
-Text comprehension?
-Emotion/sentiment analysis?

Thanks guys :)",4,1
614,2016-1-23,2016,1,23,0,425zk9,Deep learning server with seamless indexing into Elasticsearch,https://www.reddit.com/r/MachineLearning/comments/425zk9/deep_learning_server_with_seamless_indexing_into/,pilooch,1453476474,,0,5
615,2016-1-23,2016,1,23,0,4264bn,"Updated MNIST, CIFAR-10, CIFAR-100, SHVN, and other benchmark scores (includes ICLR 2015, 2016, CVPR 2015, 2016, etc papers)",https://www.reddit.com/r/MachineLearning/comments/4264bn/updated_mnist_cifar10_cifar100_shvn_and_other/,IndieAILab,1453478218,,12,93
616,2016-1-23,2016,1,23,2,426nie,The GTL-Gate (GeneralTrainableLogic),https://www.reddit.com/r/MachineLearning/comments/426nie/the_gtlgate_generaltrainablelogic/,Sschwenk,1453484957,"Hi there,

Yesterday I had the idea to ""fusion"" the boolean logic with machine learning.
The result of that thought could be downloaded as .pdf here:

https://drive.google.com/file/d/0B9wyQszv17eUbTFjdWJ3akQ0UlE/view?usp=sharing

My question is how does a trainable circuit out of these parts have to be wired up to be able to perform every possible calculation with n-bits input and n-bits output but has a minimal numbers of gatters?",3,7
617,2016-1-23,2016,1,23,2,426odn,Could Twitch Chat Be Used As A Dataset?,https://www.reddit.com/r/MachineLearning/comments/426odn/could_twitch_chat_be_used_as_a_dataset/,Science6745,1453485256,"My thinking is Twitch, on the popular channels, can have thousands of people commenting on what is happening in the stream all at the same time.

Could the chat be used in some way to interpret what is happening in the stream and could this be used in machine learning?

I am a complete layman on this topic but I have a keen interest and I think there might be some value to this idea.

Would love to hear peoples thoughts.",12,3
618,2016-1-23,2016,1,23,3,426q0t,Robot Control with Distributed Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/426q0t/robot_control_with_distributed_deep_reinforcement/,truri,1453485810,,13,113
619,2016-1-23,2016,1,23,3,426wu6,A better course for beginners than Andrew Ngs Coursera?,https://www.reddit.com/r/MachineLearning/comments/426wu6/a_better_course_for_beginners_than_andrew_ngs/,DeapSoup,1453488167,"Hello everyone,

I have taken up Machine Learning around a week ago, starting with the Coursera course provided by Andrew Ng. Are there other courses which help me learn faster? What courses should I take after having completed this one (Would Udacity's Deep Learning be a good choice?)? Thank you in advance! ",11,7
620,2016-1-23,2016,1,23,4,4275qv,Poking At Causation (with some observations on backpropagation),https://www.reddit.com/r/MachineLearning/comments/4275qv/poking_at_causation_with_some_observations_on/,Curuinor,1453491415,,1,0
621,2016-1-23,2016,1,23,4,4278d5,What are typical semantic segmentation pipelines?,https://www.reddit.com/r/MachineLearning/comments/4278d5/what_are_typical_semantic_segmentation_pipelines/,themoosemind,1453492349,"Semantic segmentation means you have a pixel-image, and you want to have a class label (e.g. cat / dog / sky / street / plant / ...) for every single pixel.

I think a typical pipeline looks like this:

[Imgur](http://i.imgur.com/usCqV0i.png)

1. Preprocessing / Feature extraction
2. For training only: Data augmentation
3. Extracting windows (image patches)
4. Classifying those windows
5. Post-processing (e.g. morphological operations to get a more consistent segmentation)

However, I'm not too sure about it. Are there other typical pipelines?

I have read the [FCNN paper](http://arxiv.org/abs/1411.4038) a while ago, but it seems to basically hide the sliding window in a convolution (clever approach, but still similar).

CRFs seem to be different. They seem to assign a random variable for every pixel and not use a sliding window.

Is there more?",3,2
622,2016-1-23,2016,1,23,7,4280kb,Machine Learning Can Predict Game of Thrones Betrayals,https://www.reddit.com/r/MachineLearning/comments/4280kb/machine_learning_can_predict_game_of_thrones/,incognito6,1453502343,,0,1
623,2016-1-23,2016,1,23,8,4289jn,Google just released a free Deep Learning with TensorFlow course on Udacity,https://www.reddit.com/r/MachineLearning/comments/4289jn/google_just_released_a_free_deep_learning_with/,[deleted],1453505870,[deleted],0,15
624,2016-1-23,2016,1,23,8,428cqy,"""none of these"" class in a cnn",https://www.reddit.com/r/MachineLearning/comments/428cqy/none_of_these_class_in_a_cnn/,mikos,1453507171,"DNN newbie here...
I am using a CNN to classify various objects (10 classes) and with the well curated training set I am getting decent results (80-90%+) top 3 accuracy. However it seems to find some class if I submit an image which is *not* in the  10 classes with similar confidence level. How can I filter out such false positives?

I remember reading somewhere creating a ""none_of_these"" class based on random crops from the training sets regions which do not contain the object of interest. Has anyone tried this approach? or better approaches?",3,4
625,2016-1-23,2016,1,23,9,428d5q,Scikit vs Tensor/Theano,https://www.reddit.com/r/MachineLearning/comments/428d5q/scikit_vs_tensortheano/,SirMadALot,1453507336,"Hello everyone.

I'm currently working on a project that has some Data Mining requirements. So far all my work has been around cleaning data with pandas, but now I need to move to the Data Mining phase.

I've always thought about using scikit-learn for that. However, since Tensor Flow came out, I'm not sure what tool should I use. 

Is there any advantage in using TensorFlow/Theano over scikit-learn besides the distributed computation capabilities that they provide?",13,12
626,2016-1-23,2016,1,23,12,4299hw,Whats the most advanced way AIs learn from eachother across the Internet?,https://www.reddit.com/r/MachineLearning/comments/4299hw/whats_the_most_advanced_way_ais_learn_from/,BenRayfield,1453521390,,13,0
627,2016-1-23,2016,1,23,14,429l8m,Handwritten Digit Recognition in C++ [Source Code in Description],https://www.reddit.com/r/MachineLearning/comments/429l8m/handwritten_digit_recognition_in_c_source_code_in/,Weihua99,1453527192,,1,5
628,2016-1-23,2016,1,23,15,429td4,The Three Cultures of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/429td4/the_three_cultures_of_machine_learning/,Articulated-rage,1453531819,,14,168
629,2016-1-23,2016,1,23,18,42aaex,"Lottery, do you think I will loose my time?",https://www.reddit.com/r/MachineLearning/comments/42aaex/lottery_do_you_think_i_will_loose_my_time/,Eildosa,1453542603,"Hi,

I'm a JAVAEE/Python dev with no knownledge of machine leaning.
I intend to take this course : https://www.udemy.com/from-0-1-machine-learning/ to run what I'll be doing on old lottery results.

I've got 12 years of data on a website, I'll extract them on a CSV with a web crawler I'll make.

Maybe the machine used for the lotery have small mechanical issue that can lead to repetitive pattern.

Do you thinks it's useless?

Worst cased scenario : I'll know how machine learning works.",14,0
630,2016-1-23,2016,1,23,21,42alu9,Predicting Trigonometric Waves few steps ahead with LSTMs in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/42alu9/predicting_trigonometric_waves_few_steps_ahead/,[deleted],1453550595,[deleted],1,1
631,2016-1-23,2016,1,23,21,42amdw,Deploying a CNN on Android - which deep learning framework do you recommend?,https://www.reddit.com/r/MachineLearning/comments/42amdw/deploying_a_cnn_on_android_which_deep_learning/,Dr_Vlad,1453550987,"Hey,

I want to train a CNN on a workstation, then use the model in an Android app. Caffe, Torch, Tensorflow, Deeplearning4j seem to be the ways to go, as ports to Android are available:

* Caffe - https://github.com/sh1r0/caffe-android-lib
* Torch7 - https://github.com/soumith/torch-android
* Tensorflow - https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android
* Deeplearning4j - written in java

I'm proficient in Theano and have no experience in any of the above. Which one would you recommend in terms of performance on Android and ease to learn&amp;use? I'd be grateful for any tips or hints you are willing to share regarding running deep learning on Android.

My CNN will solve a slightly harder MNIST-like task (so it will be nowhere as big as nets for ImageNet). Besides standard building blocks it'd be great to use residual connections for accuracy improvements. I'm also considering using dark knowledge and/or Deep Compression for reducing model's size and increasing its processing speed, if required for efficient smartphone performance.

Thank you :-)",3,1
632,2016-1-23,2016,1,23,22,42art9,Data Science conferences?,https://www.reddit.com/r/MachineLearning/comments/42art9/data_science_conferences/,Dawny33,1453554403,,0,0
633,2016-1-23,2016,1,23,23,42b06y,Predicting Trigonometric Waves few steps ahead with LSTMs in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/42b06y/predicting_trigonometric_waves_few_steps_ahead/,[deleted],1453559140,[deleted],1,0
634,2016-1-23,2016,1,23,23,42b39s,Alibaba Teams With Nvidia in $1 Billion Bet on Cloud Computing and Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/42b39s/alibaba_teams_with_nvidia_in_1_billion_bet_on/,lokator9,1453560573,,15,56
635,2016-1-24,2016,1,24,0,42bcpk,When to add? When to multiply?,https://www.reddit.com/r/MachineLearning/comments/42bcpk/when_to_add_when_to_multiply/,gogogadgetlegz,1453564679,"Can anyone shed light onto when we should sum things together (sum of weak learners) and when we should multiply (product of experts)?

An intuitive understanding is evading me.

Thanks!",3,9
636,2016-1-24,2016,1,24,2,42bv66,Starting an ML project. Looking for a little bit of guidance.,https://www.reddit.com/r/MachineLearning/comments/42bv66/starting_an_ml_project_looking_for_a_little_bit/,jredwards,1453571767,"I'm looking to start a machine learning project both because I have a problem to solve and because I want to explore ML a bit. I'm hoping someone can give me a little bit of a guidance into which techniques I should be researching.

I have a dataset of names and addresses that I'm trying to match against. There may be multiple names and addresses associated with a single entity, and the dataset has about a million entities. All of this is stored in a relational database. Also, I promise that this is nothing sinister, not even advertising.

I'm trying to match incoming entities against this data. I have a set of confirmed matches that I could use as a training set.

I've solved this problem with an algorithmic approach in the past, simply filtering on matching elements, but I'd like to build a more robust system. The goal, of course, is to increase match rates while reducing false positives.

I'm hoping someone who's more familiar with the space could give me some quick suggestions as to which techniques I should learn more about and which are probably a waste of my time or not applicable.

This will almost certainly be a python project, if that makes a difference. I'd also prefer not to use a different database unless it's an intermediate step, as the dataset is not static and can't be easily moved.",3,2
637,2016-1-24,2016,1,24,4,42c717,How important is it to take physics if I am interested in machine learning research?,https://www.reddit.com/r/MachineLearning/comments/42c717/how_important_is_it_to_take_physics_if_i_am/,numbersloth,1453576152,I am currently a math/CS dual major. How important is taking a couple physics classes? Would I not benefit more from taking more mathematics classes?,10,7
638,2016-1-24,2016,1,24,4,42cagp,Microsoft's Mimicker Alarm app for Android uses Machine Learning,https://www.reddit.com/r/MachineLearning/comments/42cagp/microsofts_mimicker_alarm_app_for_android_uses/,geeksnewslab,1453577413,,0,1
639,2016-1-24,2016,1,24,5,42chub,Neural Network Design (eBook),https://www.reddit.com/r/MachineLearning/comments/42chub/neural_network_design_ebook/,vonnik,1453580108,,2,4
640,2016-1-24,2016,1,24,6,42cxi2,Deep network on a machine with low CPU power (NAO robot)?,https://www.reddit.com/r/MachineLearning/comments/42cxi2/deep_network_on_a_machine_with_low_cpu_power_nao/,aifra,1453585893,"I would try to implement a Convolutional Neural Network for visual object recognition. The main problem is that this algorithm should work on a NAO robot that has very low performance (a single core cpu and no video card). 

I know that the main load is in the training step. So if I train the network offline, on a PC, and then load it into the robot should be feasible, right? Does anyone tried to implement something similar for a low performance system? Which library did you use?

Thanks!",32,27
641,2016-1-24,2016,1,24,8,42dgsa,I generated Reddit comments using Character-level Recurrent Neural Networks (x-post /r/SubredditSimMeta),https://www.reddit.com/r/MachineLearning/comments/42dgsa/i_generated_reddit_comments_using_characterlevel/,EthanMacdonald,1453593239,,16,15
642,2016-1-24,2016,1,24,9,42dj2e,Data-Mining using Names,https://www.reddit.com/r/MachineLearning/comments/42dj2e/datamining_using_names/,pacmanisfun,1453594147,,0,4
643,2016-1-24,2016,1,24,9,42dkia,What's a good reference on statistical algorithms? (x-post from /r/statistics),https://www.reddit.com/r/MachineLearning/comments/42dkia/whats_a_good_reference_on_statistical_algorithms/,achompas,1453594706,,0,1
644,2016-1-24,2016,1,24,9,42dp7l,The joys of offline data collection - including some thoughts on machine learning following my experiences doing manual reef life surveys,https://www.reddit.com/r/MachineLearning/comments/42dp7l/the_joys_of_offline_data_collection_including/,yanirse,1453596586,,4,5
645,2016-1-24,2016,1,24,9,42dpr3,What's a real-world example where MCMC might be the only option?,https://www.reddit.com/r/MachineLearning/comments/42dpr3/whats_a_realworld_example_where_mcmc_might_be_the/,bourbondog,1453596805,"I understand the basic principles of Markov Chain Monte Carlo methods (Gibbs sampling to be specific) - however I can't think of a reason why they'll be useful.

One example I can think of: there's a 2D distribution but you only know about 10% of the points on the 2D grid. If you want to sample at the rest of the 90% locations, you could use MCMC. But I'm stuck here - why can't I use k-nearest or linear interpolation to produce those samples?",5,3
646,2016-1-24,2016,1,24,11,42e558,A good starter computer for ML?,https://www.reddit.com/r/MachineLearning/comments/42e558/a_good_starter_computer_for_ml/,23495872345,1453603428,"Hi, I've been experimenting with machine learning in Python and Lua, but I'm running into some hardware limitations on my current machine and it's clear that I need a decent GPU.  I would like to invest in a fairly serious computer.  I see lots of gaming machines on craigslist, such as the one below which has a Titan X and an i7 extreme.  Does this look like a good choice for machine learning?

https://orlando.craigslist.org/sys/5409599024.html

Also, is it fair to expect a used computer like this one to be significantly discounted?  The cost of this computer is not very far from the cost of its components, brand new, on newegg.  But I'm not sure how much labor goes into this sort of build.

Thanks for any advice.  I am quite new to ML and hardware generally, and I don't want to make a wrong move.",6,2
647,2016-1-24,2016,1,24,12,42edl9,Need some advices on my master thesis,https://www.reddit.com/r/MachineLearning/comments/42edl9/need_some_advices_on_my_master_thesis/,[deleted],1453607393,[deleted],4,0
648,2016-1-24,2016,1,24,12,42eejj,Suggestions for text based services,https://www.reddit.com/r/MachineLearning/comments/42eejj/suggestions_for_text_based_services/,yacob_uk,1453607859,"This might not be the right sub, having read the sub for a while, I'm braced for the potential backlash...

I work in a national library. I get very involved in projects that are looking to automate the basic human stuff, and having made some in roads into the automated collection of digital content that's in scope for the collections, I'm really keen to look at one of the next bottlenecks. 

Indexing. Indexing in library terms is the process of taking a text item (e.g. an article) and reducing it in two ways. A summary and associations to the formally managed controlled vocabulary we call ""subject headings"". 

Having watched the growth of text summary services, we want to run a small project to test the current automated keyword extraction capabilities and compare them to the sort of summary we make in the human world. The basic idea here is to get a sense of how mature these tools are, and to see if there are viable candidates that we could use to free our humans up for the more tricky / subjective stuff like assigning subject headings. 

I have a few python libraries / modules that purport to extract the salient keywords, and even with these tools (the ones I have are generally built by the library sector) I'm getting a sense that we're jumping on this to soon. 

This sits a little uncomfortably with me as I've been reading quite a bit about the automatic generation of news articles and can see what the tldr bot (for example) can do. 

I'd hate to be throwing the baby out with the bath water because I didn't look at the right tools...

I have management buy in for time, but as happens with these things, I'd need to form a much stronger case for actually spending money on a service (like autotldr).  

Any pointers towards viable tech or write-ups appreciated, and if any of you want to get involved from an academic angle I'd be happy to assist from my side. 

The two tools I've been poking are:

https://www.airpair.com/nlp/keyword-extraction-tutorial and 
http://blog.kbresearch.nl/2016/01/11/from-keyword-search-to-concept-mining/

I have heaps of content I could be working with, some of them are large &amp; consistent enough to potentially be viable for a trained network that might do this work.",2,4
649,2016-1-24,2016,1,24,17,42f6ey,Deep Learning Glossary,https://www.reddit.com/r/MachineLearning/comments/42f6ey/deep_learning_glossary/,pogopuschel_,1453623460,,1,106
650,2016-1-24,2016,1,24,18,42fdas,About Camera Calibration.,https://www.reddit.com/r/MachineLearning/comments/42fdas/about_camera_calibration/,r0bby_wang,1453629510,"My program.
clc;
%Gen CWorld and CImage points
FOV  = 9;
foc  = 50;
u0   = 20.0;
v0   = 30.0; 
dx   = 1;
dy   = 1;


ptNum  = 1;
d2r    = pi / 180;

GWorld_Vector = 100;

GWorld  = zeros(169, 3);
GCamera = zeros(169, 3);
GImage  = zeros(169, 2);

GR_Mat  = [ 1 0 0; 0 1 0; 0 0 1];
GT_Mat  = [0 0 0]';

for f_deg = -3 : 0.5 : 3 
    for p_deg = -3 : 0.5 : 3 

        GWorld(ptNum, 1) = GWorld_Vector * cos( f_deg * d2r) * sin( p_deg * d2r );
        GWorld(ptNum, 2) = GWorld_Vector * sin( f_deg * d2r);
        GWorld(ptNum, 3) = GWorld_Vector * cos( f_deg * d2r) * cos( p_deg * d2r );

        GCamera(ptNum, 1) = GR_Mat(1,1) * GWorld(ptNum, 1) + GR_Mat(1,2) * GWorld(ptNum, 2) + 
                                            GR_Mat(1,3) * GWorld(ptNum, 3) + GT_Mat(1,1);
        GCamera(ptNum, 2) = GR_Mat(2,1) * GWorld(ptNum, 1) + GR_Mat(2,2) * GWorld(ptNum, 2) + 
                                            GR_Mat(2,3) * GWorld(ptNum, 3) + GT_Mat(2,1);
        GCamera(ptNum, 3) = GR_Mat(3,1) * GWorld(ptNum, 1) + GR_Mat(3,2) * GWorld(ptNum, 2) +
                                            GR_Mat(3,3) * GWorld(ptNum, 3) + GT_Mat(3,1);       
        GImage(ptNum, 1)  = foc * GCamera(ptNum, 1) / ( GCamera(ptNum, 3)* dx ) + u0;
        GImage(ptNum, 2)  = foc * GCamera(ptNum, 2) / ( GCamera(ptNum, 3)* dy ) + v0;           
        ptNum = ptNum + 1;
    end;
end;
--------------------------------------------------------------------------------------------------------------------------------------------------This is a simulation results.-&gt;
M_mat =

   -0.6299   -0.0000   -0.2520    0.0000
    0.0000   -0.6299   -0.3779    0.0000
    0.0000   -0.0000   -0.0126    0.0000


m34 =

   79.3788


R_mat =

   -1.0000    0.0000    0.0000
    0.0000   -1.0000   -0.0000


T_mat =

  -31.7515  -47.6273   79.3788
//T

P =

   50.0000         0   20.0000         0
         0   50.0000   30.0000         0
         0         0    1.0000         0


Why T Mat is not zeros? ",3,0
651,2016-1-24,2016,1,24,21,42fojf,Is it possible to create an AI clone of Dr. Who using Deep Learning? or any other fictional character,https://www.reddit.com/r/MachineLearning/comments/42fojf/is_it_possible_to_create_an_ai_clone_of_dr_who/,neuralconcept,1453638072,"The idea of generating an equivalent artificial agent of any person through their interactions with the real world is not a new idea in literature. For example in the sci-fi serie Caprica a virtual agent was created based on all existing records about a person. That idea could be moved to a fiction characters, if we have enough information on how a person speaks and how it interacts with other characters, it could be generated an equivalent model to this character. The information, that we have in a book about character is usually small and complex to transfer to a models. Furthermore the television series and movies, full of dialogues among characters could generate primitive models of conversation. One of these early BOTs generated based on dialogs from movies can be seen in http://arxiv.org/pdf/1506.05869.pdf (July 2015). This paper present a model generated through an algorithm based on deeplearning seq2seq getting meaningful answers. One of the problems is the training method, thousands of thousands of dialogues from diferents characters without any relation and context. My point is this, why not train with only one character dialogues. Dr. Who is one of the oldest television characters and the hero of many of us. The aim would be to generate an equivalent to Doctor model, based on all the dialogues of his years of issue.

I have  generated a model using Seq2Seq with Tensorflow in order to try this aproach, 

And you can see here some answers of AI Dr. Who:

Person: what is your name ?	Doctor: i don't know .
Person: are you the doctor ?	Doctor: yes , i know .
Person: What's that noise ?	Doctor: what noise ?
Person: (wearing the sunglasses) So what was it ? Your ghost.	Doctor:i can't be surprised.
Person: Why did they only come out at night ?	Doctor: what 's that ?
Person: What will happen to them ?	Doctor: i 'll know.
Person: What do I do now?	Doctor: i 'm going to get back to the tardis .
Person: I do. You keep going. You have to. Take it from me, there is a whole world out there. A galaxy, a life. What would O'Donnell have wanted ?	Doctor: yes .
Person: What will UNIT do with the ghosts ?	Doctor: i don't know.
Person: Here's what I don't understand. You did change the future. You stopped the Fisher King from returning .	Doctor: well , i 'm not sure . i 'm delighted to hear . i 'm delighted to hear .
Person: And saying the chamber will open ?	Doctor: very well .
Person: Smart.	Doctor: i'm sorry .
Person: How do you mean ?	Doctor: cataclysm . 

I  understand that is necessary to improve the model but it is a first approach, so I can say I have my own Dr. Who in my computer :-)

What do you think  is it possible? 

All code and my experiments are  in https://github.com/neuralconcept/DrWhoAI
",0,0
652,2016-1-24,2016,1,24,23,42g203,Predicting Trigonometric Waves few steps ahead with LSTMs in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/42g203/predicting_trigonometric_waves_few_steps_ahead/,sachinrjoglekar,1453646113,,8,3
653,2016-1-24,2016,1,24,23,42g30k,Hi! I'm starting to do DeepLearning research and I have 3 months for literature review. Need advice.,https://www.reddit.com/r/MachineLearning/comments/42g30k/hi_im_starting_to_do_deeplearning_research_and_i/,newbiethrownaway,1453646608,"I know basics (e.g. stacked RBM, how it's trained...etc). But I have never coded anything of the sort before. Would you guys give me a general direction / papers I should read?  What about applications?

I heard terms like the ones below that I have not looked into yet but could be relevant. 

- LSTM?
- Batch normalization
- Attention?

Also, which language / platform is the most efficient, in terms of code writing time OR training time. I'm proficient in Matlab but no experience with Theano. My goal is to code an existing deep network myself during this time.

Thank you so much for your help in advance!",8,0
654,2016-1-24,2016,1,24,23,42g3cn,How can I find the optimal window size for a running average on a time-series dataset?,https://www.reddit.com/r/MachineLearning/comments/42g3cn/how_can_i_find_the_optimal_window_size_for_a/,sanity,1453646767,"I have a time series dataset with large fluctuations in the data.  I want an automatic way to determine the optimal window size, large enough that it smooths out the low-level fluctuations, but not so large that it obscures high-level variations.

I'm thinking some kind of cross-validation-like technique, but I'm not sure exactly how to do this.

Or perhaps there is a well established approach for this that I'm unaware of?",5,0
655,2016-1-25,2016,1,25,0,42g7vo,Amazon Machine Learning: use cases and a real example in Python,https://www.reddit.com/r/MachineLearning/comments/42g7vo/amazon_machine_learning_use_cases_and_a_real/,[deleted],1453649000,[deleted],0,0
656,2016-1-25,2016,1,25,1,42gipr,Is it only more computing power why we can now train deeper networks?,https://www.reddit.com/r/MachineLearning/comments/42gipr/is_it_only_more_computing_power_why_we_can_now/,themoosemind,1453653532,"I keep hearing that it is mainly more computing power (GPUs) and more data (Internet) why we can now train much deeper networks today than before 2000.

Were there also algorithmic changes?

I can currently think of ReLU activation (Krizhevsky: [ImageNet Classification with Deep Convolutional Neural Networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), 2012) and Dropout Training as two new ideas which I think improved the quality quite a lot (are there numbers how much it improved the quality?).

Are there other widespread algorithmic changes (not talking about the very recent [Deep Residual Learning for Image Classification](http://arxiv.org/abs/1512.03385) which brought ""Deep"" to a whole new level) which happened after 2000 and which helped to train deeper networks?",8,5
657,2016-1-25,2016,1,25,3,42gwn0,How to handle numbers in a sentences with neural nets,https://www.reddit.com/r/MachineLearning/comments/42gwn0/how_to_handle_numbers_in_a_sentences_with_neural/,[deleted],1453659012,[deleted],0,1
658,2016-1-25,2016,1,25,3,42gwqy,Training a classifier to predict antidepressant response,https://www.reddit.com/r/MachineLearning/comments/42gwqy/training_a_classifier_to_predict_antidepressant/,achekroud,1453659053,,5,6
659,2016-1-25,2016,1,25,3,42gyb7,How to extract numbers from sentences and use them as input for a neural net?,https://www.reddit.com/r/MachineLearning/comments/42gyb7/how_to_extract_numbers_from_sentences_and_use/,h3wang,1453659615,"I want to extract the actual numbers and use them, not convert them into a label (e.g. converting a '1234' to 'NUMBER' and treat it as a word in the vocabulary). I haven't figured out a way to handel numbers with word embeddings.
The goal is to make the model to be able to answer questions like: "" what's 10 plus 10? ""
Any ideas?",3,2
660,2016-1-25,2016,1,25,3,42gzjn,Batch Normalization When Stochastic Testing,https://www.reddit.com/r/MachineLearning/comments/42gzjn/batch_normalization_when_stochastic_testing/,HenryJia,1453660055,"Hey guys,

How does batch normalization work when you're running the network stochastically in forward propagation mode?

When you're training you can use minibatches to get a minibatch mean and standard deviation but what happens when you're testing/using the network stochastically?",2,2
661,2016-1-25,2016,1,25,3,42h2xh,Discussing training of LSTM encoder-decoder networks for seq-to-seq learning,https://www.reddit.com/r/MachineLearning/comments/42h2xh/discussing_training_of_lstm_encoderdecoder/,syncoPete,1453661244,"I am training an encoder-decoder network for generative sequence to sequence learning. The implementation is fairly vanilla, and I believe it's correct, as the same code skeleton has been used in various example packages for Torch. It is more or less identical in spirit to the one implemented in the Element Research Torch packages for recurrent networks:

https://github.com/Element-Research/rnn/blob/master/examples/encoder-decoder-coupling.lua



I believe the number of parameters in my model is substantial enough to learn to exactly map a small number of sequences. At the beginning of training on a small dataset of 20 sequence pairs, things look promising:

&gt;Question:  can you call me ?	

&gt; Answer:  &lt;go&gt; okay . i cant promise anything but they say it works wonders . ill keep you posted on the outcome . &lt;eos&gt;
	
&gt; Prediction:  okay . i cant promise . i cant promise . i cant promise . 

However, after many more epochs (and, somehow, a much lower aggregate loss) things go haywire:

&gt; Question:  can you call me ?
	
&gt; Answer:  &lt;go&gt; okay . i cant promise anything but they say it works wonders . ill keep you posted on the outcome . &lt;eos&gt;
	
&gt; Prediction:  okay i okay i okay i okay i okay i okay i okay i okay i okay 

Any intuition of what's going on here? This tendency towards repetition seems very strange to me.",16,7
662,2016-1-25,2016,1,25,3,42h4fz,"[1601.04811] Coverage-based Neural Machine Translation --- let's feed attention mechanism ""coverage vector"" so NMT knows what it did not attended yet, as result ""coverage based NMT achieves significant improvements in terms of alignment and translation quality over NMT without coverage"".",https://www.reddit.com/r/MachineLearning/comments/42h4fz/160104811_coveragebased_neural_machine/,derRoller,1453661784,,8,20
663,2016-1-25,2016,1,25,5,42hgvf,Is there a good rule of thumb for the correct number of topics in LDA?,https://www.reddit.com/r/MachineLearning/comments/42hgvf/is_there_a_good_rule_of_thumb_for_the_correct/,textClassy,1453666080,,2,1
664,2016-1-25,2016,1,25,5,42hpdz,Man uses recurrent neural network to generate new episodes of 'Friends',https://www.reddit.com/r/MachineLearning/comments/42hpdz/man_uses_recurrent_neural_network_to_generate_new/,[deleted],1453669086,[deleted],17,14
665,2016-1-25,2016,1,25,6,42hrls,Neural Style experimentation on laptop?,https://www.reddit.com/r/MachineLearning/comments/42hrls/neural_style_experimentation_on_laptop/,xristos_forokolomvos,1453669899,"I want to mess around with neural style for some pictures of mine but I'm stuck on a 3GB RAM laptop with no special GPU. Is there any lightweight implementation that can run on CPU with low memory requirements?

I don't know if I'm asking for too much here but any guidelines would be helprful!",3,0
666,2016-1-25,2016,1,25,6,42hvpn,"Hey, I'm Nelly and I'm wanting a nice fuck... Only for real men!",https://www.reddit.com/r/MachineLearning/comments/42hvpn/hey_im_nelly_and_im_wanting_a_nice_fuck_only_for/,joicoscountrec197494,1453671354,,0,0
667,2016-1-25,2016,1,25,7,42i0ox,Microsoft ML Emotions API,https://www.reddit.com/r/MachineLearning/comments/42i0ox/microsoft_ml_emotions_api/,[deleted],1453672996,[deleted],0,2
668,2016-1-25,2016,1,25,7,42i2gr,Sentiment analysis on bag of words?,https://www.reddit.com/r/MachineLearning/comments/42i2gr/sentiment_analysis_on_bag_of_words/,dartly,1453674058,"Say you're given a set of documents in the form of bag of words features, and you want to do binary SA classification on them. What are some good models to try on this kind of problem? For reference, a tuned random forest achieves around 65% accuracy. I've heard that SVMs, logistic regression, and naive bayes work well, but I'm only getting around 60% out of them. What other models are good, and what are some other things I can do to improve classification accuracy?",8,0
669,2016-1-25,2016,1,25,8,42ic2y,Does anyone know where to download the MNIST database?,https://www.reddit.com/r/MachineLearning/comments/42ic2y/does_anyone_know_where_to_download_the_mnist/,hackthat,1453677513,"Everywhere links me to http://yann.lecun.com/exdb/mnist/ but this seems to be down for some reason.
Thanks!  I just found this sub and am looking into learning some of these techniques so I'm installing tensorflow. Specifically I'm looking at how to categorize some time traces for a research project. ",4,4
670,2016-1-25,2016,1,25,8,42if45,Interviewing a senior Data Scientist @ HP about Data Science (part-1),https://www.reddit.com/r/MachineLearning/comments/42if45/interviewing_a_senior_data_scientist_hp_about/,lawrencejones617,1453678648,,0,1
671,2016-1-25,2016,1,25,8,42ih2o,How would you make a program that finds abstract word associations?,https://www.reddit.com/r/MachineLearning/comments/42ih2o/how_would_you_make_a_program_that_finds_abstract/,raymestalez,1453679361,"Hi! I am facing an interesting problem, and I want to ask for your advice.

How would you go about writing a program that finds abstract associations between words?

Like if you input ""balloon"" it would output things like ""birthday"", ""blimp"", ""red"", ""soap bubble"", etc. Not synonyms, but the sort of connections human would make.

Is that even possible?  I'd appreciate any hints and ideas.",8,4
672,2016-1-25,2016,1,25,9,42iiz4,$28M challenge to figure out why brains are so good at learning,https://www.reddit.com/r/MachineLearning/comments/42iiz4/28m_challenge_to_figure_out_why_brains_are_so/,badhri,1453680070,,6,9
673,2016-1-25,2016,1,25,9,42imw5,what are some good features to extract from LDA for text classification?,https://www.reddit.com/r/MachineLearning/comments/42imw5/what_are_some_good_features_to_extract_from_lda/,textClassy,1453681521,,1,1
674,2016-1-25,2016,1,25,9,42ip80,Has anyone tried using deep learning techniques on physical systems?,https://www.reddit.com/r/MachineLearning/comments/42ip80/has_anyone_tried_using_deep_learning_techniques/,bourbondog,1453682391,"Until now, I've only heard people use deep learning on text, images and audio. Has someone tried using deep learning to ""learn"" systems we already have mathematical equations for?

For example, we could run simulations for a simple physical model containing [an external force and spring some springs](http://umdberg.pbworks.com/f/1316964534/Ball%26SpringModelPushing.jpg). This should generate enough data for deep learning. Then have a learning algorithm figure out the behaviour of this system.

So generating data and verifying its accuracy is easy. Has someone done something like this? Can the model learned by the deep network be generalized to other physical models? ",12,3
675,2016-1-25,2016,1,25,10,42iw04,Bridging the Gap between Stochastic Gradient MCMC and Stochastic Optimization (better results than RMSprop and Adam),https://www.reddit.com/r/MachineLearning/comments/42iw04/bridging_the_gap_between_stochastic_gradient_mcmc/,m000pan,1453685060,,13,27
676,2016-1-25,2016,1,25,10,42iyde,Question: Could we train machine learning algorithms in sports to convert simple 2D images from real life games into virtual reality 3D environmental scenes? The algorithm would be trained to model players based on multiangular 2d camera input and a perfect model of the game (hence machine learning),https://www.reddit.com/r/MachineLearning/comments/42iyde/question_could_we_train_machine_learning/,alvinoo,1453685964,Answer would be really appreciated folks! ,1,1
677,2016-1-25,2016,1,25,11,42j71s,No GPUs at home: is Deep Learning over the free tier of Amazon Web Services (AWS) a solution?,https://www.reddit.com/r/MachineLearning/comments/42j71s/no_gpus_at_home_is_deep_learning_over_the_free/,transhumanist_,1453689497,"I am still in my undergrad on EE, though I have been studying by myself ML and now DL for about a year now. I came across the problem that my machine is not very capable of training not-so-deep networks in an effective time, was wondering if AWS could solve this problem.

So, I have a couple of questions for you fellow redditors:

* Is there a better (free) way other than AWS to study deep learning?

* Do you recommend any tutorials on how to set up and use AWS for such tasks? 

The thing is that I don't have a clue on where to start, I only know that they offer computers with good GPUs for free to use for some time, but I know nearly nothing of how to access and use services such as AWS for applications like studying DL...

*BTW, my setup is a simple retina 2012 macbook pro with a NVIDIA GeForce GT 650M 1024 MB GPU, every time I try to run a program over it  (CUDA on MATLAB, for instance) either the performance drops or it just doesn't work due to the lack of graphics memory*


Thanks a lot!

",16,3
678,2016-1-25,2016,1,25,11,42j83g,Are there equation discovery systems (like Eureqa) which can be effectively applied to many-dimensional problems (like MNIST)?,https://www.reddit.com/r/MachineLearning/comments/42j83g/are_there_equation_discovery_systems_like_eureqa/,fuckinghelldad,1453689923,,0,1
679,2016-1-25,2016,1,25,13,42jlip,Anyone know the fastest way to partition the Imagenet ILSVRC 2012 validation dataset by animals only?,https://www.reddit.com/r/MachineLearning/comments/42jlip/anyone_know_the_fastest_way_to_partition_the/,[deleted],1453695534,[deleted],2,0
680,2016-1-25,2016,1,25,15,42k4kf,Global Radio Frequency (RF) Test Equipment Consumption 2016 Market Research Report,https://www.reddit.com/r/MachineLearning/comments/42k4kf/global_radio_frequency_rf_test_equipment/,naincyjorge,1453704324,,0,1
681,2016-1-25,2016,1,25,18,42kman,Machine Learning: The High-Interest Credit Card of Technical Debt [PDF],https://www.reddit.com/r/MachineLearning/comments/42kman/machine_learning_the_highinterest_credit_card_of/,alexeyr,1453714819,,0,22
682,2016-1-25,2016,1,25,19,42ksu9,The Three Cultures of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/42ksu9/the_three_cultures_of_machine_learning/,[deleted],1453718957,[deleted],2,0
683,2016-1-25,2016,1,25,21,42l3hr,test resources (testresources) on about.me,https://www.reddit.com/r/MachineLearning/comments/42l3hr/test_resources_testresources_on_aboutme/,testresources01,1453725197,,0,0
684,2016-1-25,2016,1,25,22,42l776,u go mobility (u.gomobility) on about.me,https://www.reddit.com/r/MachineLearning/comments/42l776/u_go_mobility_ugomobility_on_aboutme/,ugomobility,1453726814,,0,0
685,2016-1-25,2016,1,25,22,42lb2n,Question about tensorflow/cifar10,https://www.reddit.com/r/MachineLearning/comments/42lb2n/question_about_tensorflowcifar10/,AwesomeDaveSome,1453728302,"Hi guys,

I'm currently learning tensorflow. I'm working on the Cifar-10 tutorial. I'm a bit confused and wanted to check whether I'm understanding correctly how I would prepare data myself to train the model. Here's what I think I should do, I'd appreciate any feedback:


First, convert the images to a numpy array of shape height x length x channels (3 for RGB image). I'm unsure what I'd do with the labels, actually...

Let's say I call the final file foobar
Then, I could use read_cifar10(foobar) to read in the image in my code. In the code, the individual images are then arranged in batches the way tensorflow wants all to receive them.

Is this correct? If I want to read in more than 1 image, what will I write instead of foobar, let's say the files are called foobar1 and 2?",3,1
686,2016-1-25,2016,1,25,22,42legi,Setting bounds for NN output,https://www.reddit.com/r/MachineLearning/comments/42legi/setting_bounds_for_nn_output/,danhardman,1453729504,"I want to use a neural network to predict a continuous output. The current range of the desired output in my training data essentially `0 to 60`, but that could possibly increase. However, I'm not sure how to produce similar outputs with the NN. At the moment it only outputs values in the range of `-1 to 1`.

If it helps, the library I'm using for this is https://github.com/NOX73/go-neural and the Activation function is located here: https://github.com/NOX73/go-neural/blob/master/activation_func.go",7,1
687,2016-1-25,2016,1,25,23,42lhyf,"Microsoft releases CNTK, its open source deep learning toolkit, on GitHub",https://www.reddit.com/r/MachineLearning/comments/42lhyf/microsoft_releases_cntk_its_open_source_deep/,[deleted],1453730807,[deleted],0,1
688,2016-1-25,2016,1,25,23,42lir3,Generative adversarial autoencoder in Theano (code for the celebrity face reconstruction from a week ago),https://www.reddit.com/r/MachineLearning/comments/42lir3/generative_adversarial_autoencoder_in_theano_code/,mike_sj,1453731090,,0,19
689,2016-1-25,2016,1,25,23,42ljoo,"Microsoft releases CNTK, its open source deep learning toolkit, on GitHub",https://www.reddit.com/r/MachineLearning/comments/42ljoo/microsoft_releases_cntk_its_open_source_deep/,racoonear,1453731423,,39,185
690,2016-1-25,2016,1,25,23,42lle4,Does it make sense to use softmax right after tanh layer,https://www.reddit.com/r/MachineLearning/comments/42lle4/does_it_make_sense_to_use_softmax_right_after/,zibenmoka,1453732042,"Hello, 

I cannot get any results that make sense (using tensorflow) on MNIST. The architecture I use is:

- input layer 
- middle layer of 50 neurons with tanh activation 
- softmax layer 

+ I optimize cross-entropy error function. 

The very basic tensorflow code I use: 

    import tensorflow.examples.tutorials.mnist.input_data
    mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)
    import tensorflow as tf
    
    x = tf.placeholder(tf.float32, [None, 784])
    W = tf.Variable(tf.zeros([784, 50]))
    b = tf.Variable(tf.zeros([50]))

    W1 = tf.Variable(tf.zeros([50, 10])) 
    b1 = tf.Variable(tf.zeros([50]))

    middle = tf.nn.tanh(tf.matmul(x, W) + b)    
    middle_out = tf.nn.tanh(tf.matmul(middle, W1) + b1)
    y = tf.nn.softmax(middle_out)

    y_ = tf.placeholder(tf.float32, [None, 10])
    cross_entropy = -tf.reduce_sum(y_*tf.log(y))
    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)  
    
    init = tf.initialize_all_variables()
    sess = tf.Session()
    sess.run(init)   

    for i in range(1000):
      batch_xs, batch_ys = mnist.train.next_batch(100)
      sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})

somehow I get 0.1 performance all the time. What do I do wrong and why? Is this because middle_out is from range [-1,1] and so it makes no sense using softmax on top of it? 
",15,1
691,2016-1-26,2016,1,26,0,42m1f9,Can't get text generation (with Keras) to work,https://www.reddit.com/r/MachineLearning/comments/42m1f9/cant_get_text_generation_with_keras_to_work/,d07RiV,1453737385,"I'm trying to teach a simple RNN model to generate text, as described in http://karpathy.github.io/2015/05/21/rnn-effectiveness/

I'm using Python/Keras, and decided to stick with SimpleRNN for now (will try LTSM later). I'm breaking up the input text (~4.5M of Shakespeare) into 500 character sequences, so my training set is a (9000,500,67) matrix, with 9000 samples, 500 characters in each sample, and each character encoded by a 67-element indicator vector (alphabet size). The output is the same but each sequence is shifted by one character to the left.

Here's my model:

    model = Sequential()
    model.add(SimpleRNN(512, return_sequences=True, input_shape=(None, cset.length)) # cset.length = 67
    model.add(SimpleRNN(512, return_sequences=True))
    model.add(TimeDistributedDense(cset.length))
    model.add(Activation('softmax'))

    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

    model.fit(X, y, batch_size=64, nb_epoch=1)

It takes about an hour to train on the entire input once.

Then I try to generate some sample text by starting with a whitespace, feeding it to the model, choosing the next character, running it through the model again, etc (I have to run the whole text generated so far because it doesn't remember the previous state). However, I always end up with random garbage.

Looking at various samples, it seems that my code is very similar, but they manage to produce reasonable text after much less training. For instance, [this](https://gist.github.com/karpathy/d4dee566867f8291f086) code does not use any RNN libraries and does all the math on numpy matrices, and after a few minutes it outputs something that looks like text.

Am I doing something wrong here? I'm completely lost :(

Here's a full code that I'm using: http://pastebin.com/kMFmnVaN",4,0
692,2016-1-26,2016,1,26,1,42m4nm,"Right Relevance : Influencers, Articles and Conversations",https://www.reddit.com/r/MachineLearning/comments/42m4nm/right_relevance_influencers_articles_and/,GaryThomson10,1453738448,,0,1
693,2016-1-26,2016,1,26,1,42m5wg,Intel Deep Learning Framework (IDLF),https://www.reddit.com/r/MachineLearning/comments/42m5wg/intel_deep_learning_framework_idlf/,mttd,1453738809,,5,9
694,2016-1-26,2016,1,26,1,42m6xw,Deep Learning is Easy - Learn Something Harder [inFERENCe],https://www.reddit.com/r/MachineLearning/comments/42m6xw/deep_learning_is_easy_learn_something_harder/,fhuszar,1453739119,,38,51
695,2016-1-26,2016,1,26,1,42m75q,"An Advanced Self-Learning, Predictive Algorithm For Everyone",https://www.reddit.com/r/MachineLearning/comments/42m75q/an_advanced_selflearning_predictive_algorithm_for/,[deleted],1453739183,[deleted],0,1
696,2016-1-26,2016,1,26,1,42m9f5,"An Advanced Self-Learning, Predictive Algorithm For Everyone",https://www.reddit.com/r/MachineLearning/comments/42m9f5/an_advanced_selflearning_predictive_algorithm_for/,WilliamTYates,1453739823,,1,0
697,2016-1-26,2016,1,26,1,42m9pa,Medical-App for ocular problems using machine learning.,https://www.reddit.com/r/MachineLearning/comments/42m9pa/medicalapp_for_ocular_problems_using_machine/,pappine,1453739906,"Okay, so here goes, not sure whether this is the best place to post this but I need some help. I've worked in the Ocular Health del of a prominent Government Hospital in Delhi, India. From its Reach in Programs and Community ophthalmology Trips there were two things I was able to gauge:
1) Ocular problems and hygiene are BIG time issues- which people do not even know about till they are forced to come into the camp.
2) Communication regarding the same is also weak.
Now i am thinking of working on a project for the same. There are many Youngsters who have mid-range smartphones. What I want to know is wether Image Processing/ Machine learning can help a basic Bachelors in Sciences/ Nursing or a very basically trained person to just come close to diagnosis and help in Data Collection or to impart communication for the same. Is there an app/ A way to make an app?
What I want to go ahead with is a solution which imparts both knowledge/ communication regarding ocular problems, an easy method for collection of data and a means of increasing employment. 
P.S: First Reddit post. Please be Kind :)",0,0
698,2016-1-26,2016,1,26,2,42mkmr,"Jobs: PhD studentships and Postdocs, Fellowship program at IBM Research related to data science for social good",https://www.reddit.com/r/MachineLearning/comments/42mkmr/jobs_phd_studentships_and_postdocs_fellowship/,compsens,1453743243,,0,3
699,2016-1-26,2016,1,26,2,42mlkg,Deep Learning with Spark and TensorFlow,https://www.reddit.com/r/MachineLearning/comments/42mlkg/deep_learning_with_spark_and_tensorflow/,alxndrkalinin,1453743510,,2,4
700,2016-1-26,2016,1,26,5,42nisn,DanDoesData: Microsoft CNTK Installation and Basics,https://www.reddit.com/r/MachineLearning/comments/42nisn/dandoesdata_microsoft_cntk_installation_and_basics/,vanboxel,1453753713,,0,5
701,2016-1-26,2016,1,26,5,42njnk,Machine Learning vs Econometrics (Impact Evaluation),https://www.reddit.com/r/MachineLearning/comments/42njnk/machine_learning_vs_econometrics_impact_evaluation/,cuchoi,1453753990,"Is there a guide to know which one to use for each problem? I have read some papers that argue that Machine Learning works for ""prediction"" while Econometrics for ""finding the causal impact"".  

I know what each one of them can do by each one, but the are some scenarios where I do not know which one is better. For example, if I want to predict the performance of students in a course and rank them, what approach would you recommend?

Thanks!",12,0
702,2016-1-26,2016,1,26,5,42nnpe,Why do I never see dropout applied in convolutional layers?,https://www.reddit.com/r/MachineLearning/comments/42nnpe/why_do_i_never_see_dropout_applied_in/,avacadoplant,1453755282,"Whenever I look at code for models that use dropout, it's only applied to fully connected layers. example https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/mnist/convolutional.py#L220

But the dropout paper https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf
seems to suggest applying it to all hidden layers with 0.5 probability and 0.8 probability to input layers.",11,10
703,2016-1-26,2016,1,26,6,42ny98,ELI5 ... The softmax algorithm,https://www.reddit.com/r/MachineLearning/comments/42ny98/eli5_the_softmax_algorithm/,Tbone_chop,1453758456,"Can someone please walk me thru an example.  Let's say my data is [3, 1.2, .55]

What would be the result of the softmax algo in this case.  And how is it arrived at (step by step)  My understanding could be so wrong that this question doesn't even make sense.",8,1
704,2016-1-26,2016,1,26,7,42o5mh,Examples of companies making money by using machine learning?,https://www.reddit.com/r/MachineLearning/comments/42o5mh/examples_of_companies_making_money_by_using/,aotdsyndrome,1453760738,"I'm interested in learning about successful applications of machine learning to drive significant profit at large scale (be it part of the product like Spotify, or part of the sales system Amazon). 

Bonus points for original suggestions!",6,3
705,2016-1-26,2016,1,26,7,42o5u2,Implementing your own spam filter in Python,https://www.reddit.com/r/MachineLearning/comments/42o5u2/implementing_your_own_spam_filter_in_python/,DrLegend,1453760806,,0,3
706,2016-1-26,2016,1,26,8,42ok91,Bayesian probabilistic matrix factorization and horses races,https://www.reddit.com/r/MachineLearning/comments/42ok91/bayesian_probabilistic_matrix_factorization_and/,Eildosa,1453765553,"Hi,

so I was looking into horse races prediction and Bayesian probabilistic matrix factorization seems to be what I need.

I'm finding information about BPMF and PMF, are they the same or does Bayesian changes something?

Would any of you have a good course on BPMF? I'm having trouble finding material about it.
I've never been good with theoretical material, I need examples, implementation in any language with a real life scenario will do (horse races or not)

Thanks.",3,2
707,2016-1-26,2016,1,26,8,42okn9,What Next?,https://www.reddit.com/r/MachineLearning/comments/42okn9/what_next/,[deleted],1453765695,[deleted],0,1
708,2016-1-26,2016,1,26,9,42ongw,"Marvin Minsky, Pioneer in Artificial Intelligence, Dies at 88",https://www.reddit.com/r/MachineLearning/comments/42ongw/marvin_minsky_pioneer_in_artificial_intelligence/,vonnik,1453766679,,29,318
709,2016-1-26,2016,1,26,9,42oqk4,10 Misconceptions about Neural Networks,https://www.reddit.com/r/MachineLearning/comments/42oqk4/10_misconceptions_about_neural_networks/,naught101,1453767786,,13,6
710,2016-1-26,2016,1,26,9,42ovgu,Natural Language Processing with PySpark (github repo in comments),https://www.reddit.com/r/MachineLearning/comments/42ovgu/natural_language_processing_with_pyspark_github/,dreyco,1453769524,,1,2
711,2016-1-26,2016,1,26,9,42owbi,Speech recognition benchmarks?,https://www.reddit.com/r/MachineLearning/comments/42owbi/speech_recognition_benchmarks/,adagrad,1453769826,"What are the most prominent speech benchmarks and what are the state of the art algorithms? I've read that CNNs have made a lot of headway, but just from looking at current consumer products, it seems like there's a ways to go.",3,4
712,2016-1-26,2016,1,26,10,42oxyc,When you just a beginner and already at the top of the leaderboards,https://www.reddit.com/r/MachineLearning/comments/42oxyc/when_you_just_a_beginner_and_already_at_the_top/,discointhenunnery,1453770431,,85,255
713,2016-1-26,2016,1,26,11,42paep,Why dropping learning rate 10 times give so good results compared with exponential decrease?,https://www.reddit.com/r/MachineLearning/comments/42paep/why_dropping_learning_rate_10_times_give_so_good/,sdemyanov,1453774974,"I am training a CNN on some dataset. I tried two strategies: 
1) train with a constant learning rate (0.01 in my case) until the accuracy stops increasing (say, 300k iterations), then drop the learning rate 10 times, and train for 10k iterations more.
2) multiply learning rate on 0.99 every 1300 iterations, such that 0.99^(300k/1.3k) = 0.1, i.e. after 300k iterations we train with the same learning rate (0.001) as in the first case. 

I have found that the first method gives much higher accuracy, and I don't have an explanation for that. Here are my plots of loss functions and accuracy (http://imgur.com/a/MsSVl). Could anybody explain what is going on?",9,5
714,2016-1-26,2016,1,26,12,42pgob,MiniNeoRL,https://www.reddit.com/r/MachineLearning/comments/42pgob/minineorl/,CireNeikual,1453777283,,2,6
715,2016-1-26,2016,1,26,13,42pra3,Training NN on an unbalanced data?,https://www.reddit.com/r/MachineLearning/comments/42pra3/training_nn_on_an_unbalanced_data/,arkanath,1453781340,"I am a beginner with neural networks and I am using the scikit-learn MLPClassifier python library for this. I have a hugely unbalanced dataset (the dataset is artificially constructed in some sense). At first, I was using SVM with random sampling to ensure balancing but the results were not good. I then used the ""balanced"" weights for SVM as provided by scikitlearn and the results were good this time. However, for NN, I can't figure out a way to work with unbalanced data. How should I approach this?",4,7
716,2016-1-26,2016,1,26,13,42ptde,Wire straightening machine,https://www.reddit.com/r/MachineLearning/comments/42ptde/wire_straightening_machine/,veermachine,1453782194,,0,1
717,2016-1-26,2016,1,26,14,42q6r5,Tensorflow models don't fit when defining forward pass in a function,https://www.reddit.com/r/MachineLearning/comments/42q6r5/tensorflow_models_dont_fit_when_defining_forward/,napsternxg,1453787981,"This is a very naive question but one I am struggling with. I am training a model using MNIST on tensorflow. 

What I am trying to do is to wrap the forward pass in a function so that I don't have to write all the computation again for inference. 

However, with my implementation of forward pass in the function, the model doesn't learn and the validation accuracy stays put at: 9%. Without using the forward function approach, my model learns normally and I achieve a validation accuracy around 92%. 

I tried playing with tf.named_scope but it didn't help. What I believe the issue is that that in each call of the forward function the Weights and biases are getting reset because these variables are defined in the function. However, a similar approach works in the official example in the tensorflow repo at: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py#L46

Can someone suggest what am I doing wrong ? I am new to tensorflow so finding this a bit confusing. 

Here is my full code:


	batch_size = 100
	n_hidden = 1024
	L2_weight = 0.5e-3


	def forward(tf_X):
		""""""
		assert tf.shape(tf_X)[1] == image_size*image_size,\
			""Training data not of correct shape. Each input should be of shape: %s"" % (image_size*image_size)
		""""""
		with tf.name_scope('hidden1'):
			weights = tf.Variable(tf.truncated_normal([image_size*image_size, n_hidden]), name=""weights"")
			biases = tf.Variable(tf.zeros([n_hidden]), name=""biases"")
			z01 = tf.matmul(tf_X, weights) + biases
			hidden1 = tf.nn.relu(z01)
			l2_reg_01 = tf.nn.l2_loss(weights)
		with tf.name_scope('z12'):
			weights = tf.Variable(tf.truncated_normal([n_hidden, num_labels]), name=""weights"")
			biases = tf.Variable(tf.zeros([num_labels]), name=""biases"")
			z12 = tf.matmul(hidden1, weights) + biases
			l2_reg_12 = tf.nn.l2_loss(weights)
		return z12, l2_reg_01+l2_reg_12

	# Define loss
	def get_loss(z12, l2_loss, tf_Y):
		""""""
		assert tf.shape(tf_X)[1] == image_size*image_size,\
			""Training data not of correct shape. got %s require %s"" % (tf.shape(tf_X)[1], image_size*image_size)
		assert tf.shape(tf_Y)[1] == num_labels,\
			""Training data not of correct shape. got %s require %s"" % (tf.shape(tf_Y)[1], num_labels)
		""""""
		loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(z12, tf_training_labels))
		total_loss = loss #+ L2_weight*l2_loss
		return total_loss

	# Define the network graph
	graph = tf.Graph()
	with graph.as_default():
		#tf_training_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size*image_size))
		#tf_training_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))
		tf_training_dataset = tf.placeholder(tf.float32) # Should have shape (batch_size, image_size*image_size)
		tf_training_labels = tf.placeholder(tf.float32) # Should have shape (batch_size, num_labels)
		tf_valid_dataset = tf.constant(valid_dataset)
		tf_test_dataset = tf.constant(test_dataset)
		
		# Define network parameters
		""""""
		weights_01 = tf.Variable(tf.truncated_normal([image_size*image_size, n_hidden]))
		weights_12 = tf.Variable(tf.truncated_normal([n_hidden, num_labels]))
		biases_01 = tf.Variable(tf.zeros([n_hidden]))
		biases_12 = tf.Variable(tf.zeros([num_labels]))
		""""""
		
		# Define network operations
		""""""
		z01 = tf.matmul(tf_training_dataset, weights_01) + biases_01
		h1 = tf.nn.relu(z01)
		z_12 = tf.matmul(h1, weights_12) + biases_12
		""""""
		
		# Optimize the loss
		""""""
		loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(z_12, tf_training_labels))
		regularized_loss = tf.nn.l2_loss(weights_01) + tf.nn.l2_loss(weights_12)
		total_loss = loss + L2_weight*regularized_loss
		""""""
		z12, l2_loss = forward(tf_training_dataset)
		total_loss = get_loss(z12, l2_loss, tf_training_labels)
		optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(total_loss)
		
		# Predictions using the model:
		""""""
		train_predictions = tf.nn.softmax(z_12)
		valid_scores = tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_01) + biases_01), weights_12) + biases_12
		test_scores = tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_01) + biases_01), weights_12) + biases_12
		valid_predictions = tf.nn.softmax(valid_scores)
		test_predictions = tf.nn.softmax(test_scores)
		""""""
		train_predictions, _l2 = forward(tf_training_dataset)
		valid_predictions, _l2 = forward(tf_valid_dataset)
		test_predictions, _l2 = forward(tf_test_dataset)
		
		
		
	# train the model
	num_steps = 3001
	batch_size = 100
	with tf.Session(graph=graph) as session:
		tf.initialize_all_variables().run()
		print ""Initialized, using batch size: %s"" % batch_size
		for step in xrange(num_steps):
			idx = np.random.randint(train_dataset.shape[0], size=batch_size)
			#offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
			# Generate a minibatch.
			batch_data = train_dataset[idx]
			batch_labels = train_labels[idx]
			#batch_data = train_dataset[offset:(offset + batch_size), :]
			#batch_labels = train_labels[offset:(offset + batch_size), :]
			feed_dict = {tf_training_dataset : batch_data, tf_training_labels : batch_labels}
			_, l, predictions = session.run([optimizer, total_loss, train_predictions], feed_dict=feed_dict)
			if (step % 500 == 0):
				batch_size += 100
				print ""Updated batch size: %s"" % batch_size
				print ""Minibatch loss at step"", step, "":"", l
				print ""Minibatch accuracy: %.1f%%"" % accuracy(predictions, batch_labels)
				print ""Validation accuracy: %.1f%%"" % accuracy(valid_predictions.eval(), valid_labels)
		print ""Test accuracy: %.1f%%"" % accuracy(test_predictions.eval(), test_labels)
			
		

Here is the full output, I get:

	Initialized, using batch size: 100
	Updated batch size: 200
	Minibatch loss at step 0 : 351.273
	Minibatch accuracy: 5.0%
	Validation accuracy: 8.7%
	Updated batch size: 300
	Minibatch loss at step 500 : 19.3078
	Minibatch accuracy: 12.5%
	Validation accuracy: 8.7%
	Updated batch size: 400
	Minibatch loss at step 1000 : 4.44503
	Minibatch accuracy: 9.3%
	Validation accuracy: 8.7%
	Updated batch size: 500
	Minibatch loss at step 1500 : 7.71385
	Minibatch accuracy: 13.2%
	Validation accuracy: 8.7%
	Updated batch size: 600
	Minibatch loss at step 2000 : 2.21557
	Minibatch accuracy: 11.8%
	Validation accuracy: 8.7%
",2,1
718,2016-1-26,2016,1,26,15,42q8d4,[Question] I am getting: 'numpy.int64' object is not callable,https://www.reddit.com/r/MachineLearning/comments/42q8d4/question_i_am_getting_numpyint64_object_is_not/,findingalife,1453788768,"My app will take a picture of a digit and send it to the server. The server will take that image and run it through a neural network. The neural network will output a digit.

Here is my neural network:

     class Network(object):
    
    def __init__(self, sizes):
        self.num_layer = len(sizes)
        self.sizes = sizes
        self.biases = [np.random.randn(y,1) for y in sizes [1:]]
        self.weights = [np.random.randn(y,x) for x, y in zip(sizes[:-1], sizes[1:])]
    
    def feedforward(self, a):
        for b, w in zip(self.biases, self.weights):
            print(b)
            print(w)
            a = sigmoid(np.dot(w, a) + b)
        return a 
    
    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data = None):
       
        list_training_data = list(training_data)
        if test_data: 
            list_test_Data = list(test_data)
            n_test = len(list_test_Data)
        n = len(list_training_data)
        for j in range(epochs):
            random.shuffle(list_training_data)
            mini_batches = [list_training_data[k:k+mini_batch_size]for k in range(0,n,mini_batch_size)]
            for mini_batch in mini_batches:
                self.update_mini_batch(mini_batch,eta)
            if test_data:
                evulate = self.evaluate(list_test_Data);
                print(""Epoch{0}:{1}/{2}"" .format( j, evulate, n_test))
            else:
                print(""Epoch {0} complete"". format(j))
                
    def backdrop(self, x, y):
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        activation = x
        activations = [x]
        zs = []
        for b, w in zip(self.biases, self.weights):
            z = np.dot(w, activation) + b
            zs.append(z)
            activation = sigmoid(z)
            activations.append(activation)
        delta = self.cost_derivative(activations[-1], y) * \
            sigmoid_prime(zs[-1])
        nabla_b[-1] = delta
        nabla_w[-1] = np.dot(delta, activations[-1-1].transpose())
        return (nabla_b, nabla_w)
                
    def update_mini_batch(self, mini_batch, eta):
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backdrop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [w-(eta/len(mini_batch))*nw
                        for w ,nw in zip(self.weights, nabla_w)]
        self.biases = [b - (eta/len(mini_batch))*nb
                        for b, nb in zip(self.biases, nabla_b)]
    
    def evaluate(self, test_data):
        test_results = [(np.argmax(self.feedforward(x)), y)for (x, y) in test_data]
        final = sum(int(x==y)for (x,y) in test_results)
        return final
    
    def cost_derivative(self, output_activatoins, y):
        return (output_activatoins - y)
        
    def sigmoid(z):
       return 1.0/(1.0 + np.exp(-z))

    def sigmoid_prime(z):
       return sigmoid(z)*(1-sigmoid(z))

When I run this alone it works perfectly fine. However when I take a picture and send that picture through a server and have it go through the nerual network I get an error.

     C:/Users/name/Desktop/server.py:91: RuntimeWarning: underflow encountered in exp np.getter()
     ERROR:__main__:Exception on / [POST]
     Traceback (most recent call last):
      File ""C:\Users\name\Downloads\WinPython-64bit-3.4.3.7\python-3.4.3.amd64\lib\site-packages\flask\app.py"", line 1817, in wsgi_app
      response = self.full_dispatch_request()
      File ""C:\Users\name\Downloads\WinPython-64bit-3.4.3.7\python-3.4.3.amd64\lib\site-packages\flask\app.py"", line 1478, in full_dispatch_request
      response = self.make_response(rv)
      File ""C:\Users\name\Downloads\WinPython-64bit-3.4.3.7\python-3.4.3.amd64\lib\site-packages\flask\app.py"", line 1577, in make_response
      rv = self.response_class.force_type(rv, request.environ)
      File ""C:\Users\name\Downloads\WinPython-64bit-3.4.3.7\python-3.4.3.amd64\lib\site-packages\werkzeug\wrappers.py"", line 847, in force_type
      response = BaseResponse(*_run_wsgi_app(response, environ))
      File ""C:\Users\name\Downloads\WinPython-64bit-3.4.3.7\python-3.4.3.amd64\lib\site-packages\werkzeug\test.py"", line 871, in run_wsgi_app
     app_rv = app(environ, start_response)
     TypeError: 'numpy.int64' object is not callable

I can't seem to solve this. Remember when i run this without the server it works fine. When I run i through the server I get this error",0,0
719,2016-1-26,2016,1,26,15,42q9wu,Emotion recognition AI,https://www.reddit.com/r/MachineLearning/comments/42q9wu/emotion_recognition_ai/,[deleted],1453789508,[deleted],0,1
720,2016-1-26,2016,1,26,15,42qbsk,[x-post /r/neuroscience] Harvard is trying to build an AI as fast as the human brain,https://www.reddit.com/r/MachineLearning/comments/42qbsk/xpost_rneuroscience_harvard_is_trying_to_build_an/,code_kansas,1453790400,,1,0
721,2016-1-26,2016,1,26,17,42qltk,3D Visualization of a Convolutional Neural Network,https://www.reddit.com/r/MachineLearning/comments/42qltk/3d_visualization_of_a_convolutional_neural_network/,smith2008,1453796250,,30,112
722,2016-1-26,2016,1,26,17,42qnp9,[1601.06759] Pixel Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/42qnp9/160106759_pixel_recurrent_neural_networks/,pranv,1453797413,,13,33
723,2016-1-26,2016,1,26,18,42qrv5,please join machine learning group on slack,https://www.reddit.com/r/MachineLearning/comments/42qrv5/please_join_machine_learning_group_on_slack/,foxlog,1453800226,[removed],0,0
724,2016-1-26,2016,1,26,18,42qtj9,machine learning communication on Slack,https://www.reddit.com/r/MachineLearning/comments/42qtj9/machine_learning_communication_on_slack/,foxlog,1453801294,,5,0
725,2016-1-26,2016,1,26,19,42qzpq,Good collection across services of machine learning algorithms.,https://www.reddit.com/r/MachineLearning/comments/42qzpq/good_collection_across_services_of_machine/,parvbhullar,1453805293,,0,1
726,2016-1-26,2016,1,26,20,42r3p1,Listen just 40 seconds of this lecture on Neural Networks,https://www.reddit.com/r/MachineLearning/comments/42r3p1/listen_just_40_seconds_of_this_lecture_on_neural/,i_bobr,1453807876,,10,18
727,2016-1-26,2016,1,26,21,42rc88,My pussy! for MachineLearning,https://www.reddit.com/r/MachineLearning/comments/42rc88/my_pussy_for_machinelearning/,salzmelaver,1453812936,,0,0
728,2016-1-26,2016,1,26,22,42rh39,Can I suspend my laptop while Matlab is doing some processing?,https://www.reddit.com/r/MachineLearning/comments/42rh39/can_i_suspend_my_laptop_while_matlab_is_doing/,bourbondog,1453815298,"Couldn't think of a more relevant sub to post this to.

I've been running some training for the over 12 hours and was wondering if it's safe to suspend my laptop to take my laptop somewhere else.

It's been running kmeans for over 12 hours now (a single command) and I don't want to give up my progress. Any suggestions on how to handle this?",7,0
729,2016-1-27,2016,1,27,0,42s2ab,Kdnuggets List of 20 Hottest Research Papers in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/42s2ab/kdnuggets_list_of_20_hottest_research_papers_in/,[deleted],1453823313,[deleted],0,1
730,2016-1-27,2016,1,27,1,42s56w,KDNuggets list of 20 hottest research papers in Computer Vision,https://www.reddit.com/r/MachineLearning/comments/42s56w/kdnuggets_list_of_20_hottest_research_papers_in/,Paige_Roberts,1453824270,,0,3
731,2016-1-27,2016,1,27,1,42sbey,"Implementing ""LSTM: A Search Space Odyssey""",https://www.reddit.com/r/MachineLearning/comments/42sbey/implementing_lstm_a_search_space_odyssey/,jimfleming,1453826246,,2,18
732,2016-1-27,2016,1,27,2,42sfr9,"Is Python really becoming the ""Machine Learning language""?",https://www.reddit.com/r/MachineLearning/comments/42sfr9/is_python_really_becoming_the_machine_learning/,Hex4869,1453827632,"I'm taking this course where they are using Python to implement machine learning algorithms and other things. They justify the use of Python by saying ""that's the direction the field is going.""

But is this really true? Because I absolutely hate this language. I hate it so much. I used to think Matlab was stupid, but this is taking it to a whole new level. I really don't wish to see another line of python code after I'm done with this course. I'm a C and C++ programmer. Matlab is okay, although slow; Python, however, I just hate it with a passion. 

Am I really stuck with Python for the next few years?",28,0
733,2016-1-27,2016,1,27,2,42smav,Making a meaningful sentence from a given set of words,https://www.reddit.com/r/MachineLearning/comments/42smav/making_a_meaningful_sentence_from_a_given_set_of/,Anik3th,1453829696,"I am working on a program that needs to create a sentence that is grammatically correct from given set of words. Here I will be passing an input of a list of strings to the program and my output should be a meaningful sentence made with those words, and a few other words that are necessary. Eg.

Input: {'You' , 'House' , 'Beautiful'}
Output: 'Your house is beautiful' (or) 'you house is beautiful' 
Input: {'Father' , 'Love' , 'Child'}
Output: 'The father loves the child'
How do I implement this with NLTK and(or) Machine Learning?

Any suggestions as to how I should go about this? I'm ready to even the most wildest ideas. Thanks! :)",11,4
734,2016-1-27,2016,1,27,3,42srkr,Autoencoding Beyond Pixels Using a Learned Similarity Metric [GitXiv],https://www.reddit.com/r/MachineLearning/comments/42srkr/autoencoding_beyond_pixels_using_a_learned/,alxndrkalinin,1453831378,,0,17
735,2016-1-27,2016,1,27,3,42sw2w,MSRA - Deep residual learning,https://www.reddit.com/r/MachineLearning/comments/42sw2w/msra_deep_residual_learning/,syamjam,1453832838,,0,18
736,2016-1-27,2016,1,27,3,42t1kh,Summary: NIPS 2015 workshop on non-convex optimization,https://www.reddit.com/r/MachineLearning/comments/42t1kh/summary_nips_2015_workshop_on_nonconvex/,iidealized,1453834582,,0,24
737,2016-1-27,2016,1,27,4,42t6at,Some Tips for Debugging in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/42t6at/some_tips_for_debugging_in_deep_learning/,amplifier_khan,1453836176,,4,8
738,2016-1-27,2016,1,27,5,42tfjw,Bitwise Neural Networks,https://www.reddit.com/r/MachineLearning/comments/42tfjw/bitwise_neural_networks/,InaneMembrane,1453839157,,36,84
739,2016-1-27,2016,1,27,6,42tuhx,Offline Cursive Handwriting Recognition in Python,https://www.reddit.com/r/MachineLearning/comments/42tuhx/offline_cursive_handwriting_recognition_in_python/,dataism,1453844036,"What I have: images of letters and digits (NIST &amp; MNIST datasets basically)

What I need to predict: Images of cursive handwriting

What I am trying to avoid: a separate letter-by-letter segmentation (image preprocessing) step + CNN

What I want to do: CNN + LSTM (or something of that nature)

Where I am stuck: I can train CNNs for separate images but couldn't sort it out how to add RNN to the end. So what exactly do I feed to RNN after the CNN step? For targets, should I use IAM handwriting database (pros: natural handwriting, cons: not too much data, only english), or try to generate fake targets from my single letter images by concatenation and random transformations (I can generate lots of data with this way)?

Some clarification:
Offline meaning from images, not from pen strokes data.
Cursive meaning letters can be connected and overlapping etc.
I would prefer keras or lasagne.",2,3
740,2016-1-27,2016,1,27,7,42tzmq,DeepMind Q&amp;A Dataset,https://www.reddit.com/r/MachineLearning/comments/42tzmq/deepmind_qa_dataset/,iidealized,1453845642,,4,6
741,2016-1-27,2016,1,27,7,42u4o3,Importance of dropout and its connection with L2 regularization,https://www.reddit.com/r/MachineLearning/comments/42u4o3/importance_of_dropout_and_its_connection_with_l2/,napsternxg,1453847311,"Is dropout always effective, and where should it be used in the network layers. 

- Should input units be dropped out ? 
- Should only outputs from hidden units be dropped out?
- OUTPUT units should never be dropped out, right ?

What is the effect of having a model in which I use dropout on certain layers and for other layer weights I use L2 regularization ?


I did some experiments on the notMNIST data used in the Udacity course on Deep Learning using Tensorflow. I found that using L2 regulaization gave the best accuracy on the test set and the accuracy when using dropout or dropout + L2 reg was less that the networks with no regularization. 

Also, is dropout a useful technique when fitting models on small data sets, (say 60k or 100k examples) ?",1,1
742,2016-1-27,2016,1,27,7,42u8k8,Upsampling in convolutional networks,https://www.reddit.com/r/MachineLearning/comments/42u8k8/upsampling_in_convolutional_networks/,[deleted],1453848608,[deleted],0,2
743,2016-1-27,2016,1,27,8,42ufac,NVIDIA Blog: How GPUs and Deep Learning Help Scientists Save Threatened Avian Populations,https://www.reddit.com/r/MachineLearning/comments/42ufac/nvidia_blog_how_gpus_and_deep_learning_help/,kleinsound,1453851004,,0,2
744,2016-1-27,2016,1,27,10,42uurz,Distributed Learning in Torch | Twitter Blogs,https://www.reddit.com/r/MachineLearning/comments/42uurz/distributed_learning_in_torch_twitter_blogs/,mttd,1453856534,,0,16
745,2016-1-27,2016,1,27,11,42v7yw,Site Likely Contains Sexually Explicit Photos Of Someone You Know! Biggest in the world service for sseex!! ID:dgadatiaatoadnagl,https://www.reddit.com/r/MachineLearning/comments/42v7yw/site_likely_contains_sexually_explicit_photos_of/,nihatanree,1453861406,,0,1
746,2016-1-27,2016,1,27,11,42v8ng,Wonder how long this result will stay...,https://www.reddit.com/r/MachineLearning/comments/42v8ng/wonder_how_long_this_result_will_stay/,j1395010,1453861675,,7,8
747,2016-1-27,2016,1,27,11,42vcom,Machine Learning Study Group,https://www.reddit.com/r/MachineLearning/comments/42vcom/machine_learning_study_group/,realistic_hologram,1453863163,"Hey everyone, I'm looking for study partners for learning machine learning. I'm a relative newbie to ML but studying every day and was hoping some people would be interested in sharing tips and keeping each other motivated. I've created a slack chat, so if you're interested you can PM you email and I'll send you an invite.

Also if there's already a study group that's looking to add more people feel free make a post about it here or send me a PM.",6,5
748,2016-1-27,2016,1,27,14,42vwhh,"Dont Feed Me, Teach Me How to Fish - or How Deep Learning is not Bringing Machine Learning to the Masses.",https://www.reddit.com/r/MachineLearning/comments/42vwhh/dont_feed_me_teach_me_how_to_fish_or_how_deep/,carlos_argueta,1453871326,,4,0
749,2016-1-27,2016,1,27,15,42w5nj,What Problems Need To Be Avoided For a Healthy Lubrication?,https://www.reddit.com/r/MachineLearning/comments/42w5nj/what_problems_need_to_be_avoided_for_a_healthy/,jackerfrinandis,1453875453,,0,1
750,2016-1-27,2016,1,27,18,42wo5q,'Neural Enquirer': now this fully neural system can learn to query tables with natural language,https://www.reddit.com/r/MachineLearning/comments/42wo5q/neural_enquirer_now_this_fully_neural_system_can/,perceptionLuz,1453885476,,9,29
751,2016-1-27,2016,1,27,19,42wy97,Looking for papers on biological models of backprop,https://www.reddit.com/r/MachineLearning/comments/42wy97/looking_for_papers_on_biological_models_of/,oderi,1453891386,"Hi guys, ML newbie here.

Stephen Howard a few months ago made a mention (in the Exponential Medicine conference) of some recent indications that backprop might be biologically plausible. I watched Hinton's mid-2015 Cambridge lecture on the matter but am not a mathematician and am looking for stuff with more grounding in biology on a more - dare I say it - conceptual level.

Any input is appreciated.

Thanks!",8,3
752,2016-1-27,2016,1,27,19,42wya3,Is it possible to implement seq2set or set2set mappings with encoder decoder architectures?,https://www.reddit.com/r/MachineLearning/comments/42wya3/is_it_possible_to_implement_seq2set_or_set2set/,polytop3,1453891398,"I know seq2seq (sequence to sequence) mapping is possible and has gained quite a bit of traction (with applications in machine translation for example).

However, has anyone tried, or is it even possible, to conduct seq2set (sequence to set) or set2set (set to set) mappings with encoder decoder architectures?

(Where in a set, order doesn't matter). E.g. for seq2set mappings, the following are all equivalent:

A B C --&gt; D E

A B C --&gt; E D

and in set2set mappings the following are all equivalent:

A B C --&gt; D E

A C B --&gt; E D

C B A --&gt; E D

A C B --&gt; D E

etc ...",3,10
753,2016-1-27,2016,1,27,22,42xjzk,"My dear cheated on me! Here are pictures of her, masturbate ...!",https://www.reddit.com/r/MachineLearning/comments/42xjzk/my_dear_cheated_on_me_here_are_pictures_of_her/,dpasarhaso,1453902801,,0,0
754,2016-1-27,2016,1,27,23,42xoia,What is the difference between SVR and SVC ?,https://www.reddit.com/r/MachineLearning/comments/42xoia/what_is_the_difference_between_svr_and_svc/,nex_jeb,1453904687,,3,0
755,2016-1-28,2016,1,28,0,42xv0f,Neural networks for information extraction?,https://www.reddit.com/r/MachineLearning/comments/42xv0f/neural_networks_for_information_extraction/,maruchanr,1453907318,I haven't seen much in the way of CNN/RNN applications for this specific NLP task despite searching around...anyone know of code samples or papers dealing with this?,1,7
756,2016-1-28,2016,1,28,0,42xwvl,What type of article do you prefer about machine learning ?,https://www.reddit.com/r/MachineLearning/comments/42xwvl/what_type_of_article_do_you_prefer_about_machine/,theflofly,1453908033,"Hello guys/girls,

I have a M.S in software engineering and I began to study seriously machine learning since 6/8 months. Once I will be ready I will began to write about machine learning and I was wondering what type of article do you prefer ?

This kind ""How the L2 regularization works?"" where there will be some maths or this kind ""How I predict the ESL Counter Strike winner"" where it is rather a concrete application of a machine learning algorithm.",4,1
757,2016-1-28,2016,1,28,0,42xwz0,GitHub - Microsoft/CNTK: Computational Network Toolkit (CNTK),https://www.reddit.com/r/MachineLearning/comments/42xwz0/github_microsoftcntk_computational_network/,luffy_straw,1453908069,,0,11
758,2016-1-28,2016,1,28,0,42xy6u,Machine Learning Meets Economics,https://www.reddit.com/r/MachineLearning/comments/42xy6u/machine_learning_meets_economics/,nkruchten,1453908525,,0,18
759,2016-1-28,2016,1,28,0,42xzj5,"I really like the idea of ""Declaring your Champion"" in the new champselect. My idea for an improvement on it's implementation",https://www.reddit.com/r/MachineLearning/comments/42xzj5/i_really_like_the_idea_of_declaring_your_champion/,[deleted],1453908976,[deleted],4,0
760,2016-1-28,2016,1,28,1,42y5b8,Neural Network training leads to distributed representations?,https://www.reddit.com/r/MachineLearning/comments/42y5b8/neural_network_training_leads_to_distributed/,XalosXandrez,1453911027,"Distributed representations form good features for large-scale ML systems. They are awesome.

Deep neural network training for large datasets seem to work well. It also seems to lead to distributed representations (or something very similar).

Is there any understanding of why this should even be true? i.e; why should neural network training lead to features which are distributed representations even when we don't explicitly ask for it. (in the form of sparsity of features, perhaps)

Or is this completely obvious / trivial somehow?",2,1
761,2016-1-28,2016,1,28,1,42yb8j,Stock Market Forecast: Creating a Model for Chaos Mapping and Predictions,https://www.reddit.com/r/MachineLearning/comments/42yb8j/stock_market_forecast_creating_a_model_for_chaos/,JohnMcNamara1949,1453913014,,5,0
762,2016-1-28,2016,1,28,2,42yfy0,A Few Useful Things to Know about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/42yfy0/a_few_useful_things_to_know_about_machine_learning/,shagunsodhani,1453914596,,0,15
763,2016-1-28,2016,1,28,2,42ymo8,The computer that mastered Go. Nature video on deepmind's Alpha GO.,https://www.reddit.com/r/MachineLearning/comments/42ymo8/the_computer_that_mastered_go_nature_video_on/,samim23,1453916740,,270,530
764,2016-1-28,2016,1,28,2,42yp8f,Mastering the game of Go with deep neural networks and tree search,https://www.reddit.com/r/MachineLearning/comments/42yp8f/mastering_the_game_of_go_with_deep_neural/,deeprnn,1453917591,,18,67
765,2016-1-28,2016,1,28,3,42yrji,AlphaGo: using machine learning to master the ancient game of Go,https://www.reddit.com/r/MachineLearning/comments/42yrji/alphago_using_machine_learning_to_master_the/,cryptoz,1453918331,,0,29
766,2016-1-28,2016,1,28,3,42ysde,Recommender Systems  Its Not All About the Accuracy,https://www.reddit.com/r/MachineLearning/comments/42ysde/recommender_systems_its_not_all_about_the_accuracy/,amplifier_khan,1453918596,,0,2
767,2016-1-28,2016,1,28,3,42yszd,Google achieves AI 'breakthrough' by beating Go champion,https://www.reddit.com/r/MachineLearning/comments/42yszd/google_achieves_ai_breakthrough_by_beating_go/,slabofguinness,1453918795,,2,8
768,2016-1-28,2016,1,28,3,42yt1l,AlphaGo: using machine learning to master the ancient game of Go,https://www.reddit.com/r/MachineLearning/comments/42yt1l/alphago_using_machine_learning_to_master_the/,cast42,1453918813,,1,4
769,2016-1-28,2016,1,28,3,42ytdx,[PDF] Mastering the Game of Go with Deep Neural Networks and Tree Search,https://www.reddit.com/r/MachineLearning/comments/42ytdx/pdf_mastering_the_game_of_go_with_deep_neural/,alexjc,1453918924,,5,50
770,2016-1-28,2016,1,28,3,42ywxw,"In a Huge Breakthrough, Googles AI Beats a Top Player at the Game of Go",https://www.reddit.com/r/MachineLearning/comments/42ywxw/in_a_huge_breakthrough_googles_ai_beats_a_top/,vonnik,1453920035,,1,3
771,2016-1-28,2016,1,28,3,42yx3n,Google Deepmind Deep-learning software defeats human professional Go player for first time,https://www.reddit.com/r/MachineLearning/comments/42yx3n/google_deepmind_deeplearning_software_defeats/,urish,1453920085,,3,18
772,2016-1-28,2016,1,28,3,42yya0,Google just beat Facebook in a race to AI milestone,https://www.reddit.com/r/MachineLearning/comments/42yya0/google_just_beat_facebook_in_a_race_to_ai/,code2hell,1453920451,,2,4
773,2016-1-28,2016,1,28,4,42z1bz,Jesus the entire front page is about go,https://www.reddit.com/r/MachineLearning/comments/42z1bz/jesus_the_entire_front_page_is_about_go/,sdsfs23fs,1453921435,Can we give it a rest already?,2,0
774,2016-1-28,2016,1,28,4,42z41d,Cytomine: Collaborative open-source web software for analysis of multi-gigapixel images using machine learning,https://www.reddit.com/r/MachineLearning/comments/42z41d/cytomine_collaborative_opensource_web_software/,rmaree,1453922271,,0,9
775,2016-1-28,2016,1,28,4,42z4s5,Looking for paper: Vanilla RNNs as good as LSTM,https://www.reddit.com/r/MachineLearning/comments/42z4s5/looking_for_paper_vanilla_rnns_as_good_as_lstm/,pjreddie,1453922504,I'm looking for a paper I thought I saw a while back about how to get as good of performance with vanilla RNNs as with LSTMs. Does anyone know what this paper was? Or am I just crazy and making this up? Thanks!,8,3
776,2016-1-28,2016,1,28,4,42z7to,Batch Norm vs Dropout,https://www.reddit.com/r/MachineLearning/comments/42z7to/batch_norm_vs_dropout/,[deleted],1453923488,[deleted],2,7
777,2016-1-28,2016,1,28,7,42zzq3,Why publish in Nature instead of JMLR or any?,https://www.reddit.com/r/MachineLearning/comments/42zzq3/why_publish_in_nature_instead_of_jmlr_or_any/,mr_robot_elliot,1453932442,"I do not understand why papers from Deepmind are being published in Nature, isn't that why every big scientist [resigned](https://en.wikipedia.org/wiki/Machine_Learning_(journal)) from Machine learning Journal to start JMLR? Am i missing something here?I think it is important for everyone to realize that Machine learning rapidly evolved because of openness otherwise it would have been like any other research area. 

Disclaimer: I do like their papers i dont mean to be against their work. ",14,10
778,2016-1-28,2016,1,28,7,4303uv,Who wants to see an AI Go tournament? Facebook's Darkforest vs. DeepMinds AlphaGo.,https://www.reddit.com/r/MachineLearning/comments/4303uv/who_wants_to_see_an_ai_go_tournament_facebooks/,[deleted],1453933819,[deleted],0,1
779,2016-1-28,2016,1,28,7,4307fl,Numpy and Theano Bindings for Baidu's warp-ctc,https://www.reddit.com/r/MachineLearning/comments/4307fl/numpy_and_theano_bindings_for_baidus_warpctc/,sherjilozair,1453934980,,0,10
780,2016-1-28,2016,1,28,8,430elz,"My YouTube channel on Python programming (specialized in ML, DBMS, BigData, HPC)",https://www.reddit.com/r/MachineLearning/comments/430elz/my_youtube_channel_on_python_programming/,snazrul,1453937570,,2,3
781,2016-1-28,2016,1,28,9,430o5y,What kind of algorithms can categorize shapes?,https://www.reddit.com/r/MachineLearning/comments/430o5y/what_kind_of_algorithms_can_categorize_shapes/,heliodor,1453941049,"IBM Watson's Visual Recognition product is quite capable at categorizing images into two categories. For example, distinguishing between pictures of a tennis player in the process of serving versus all other poses. What kind of algorithms are used for such things? Is it simply a very good convolutional neural network? Do they feed a neural network the results of image processing techniques, such as histogram of gradients (HOG)?

I realize many man-hours have gone into developing their tool. Are there any relatively straightforward ways of achieving decent results for such a problem? Even 60% would be meaningful.",7,5
782,2016-1-28,2016,1,28,10,430tqt,What kind of error function when using bag-of-word vector as the target?,https://www.reddit.com/r/MachineLearning/comments/430tqt/what_kind_of_error_function_when_using_bagofword/,[deleted],1453943124,[deleted],0,1
783,2016-1-28,2016,1,28,10,430vez,What kind of error function when target is bag-of-word vector?,https://www.reddit.com/r/MachineLearning/comments/430vez/what_kind_of_error_function_when_target_is/,rescue11,1453943763,What kind of error function can I use if the training target are bag-of-word vectors that are very sparse? ,2,2
784,2016-1-28,2016,1,28,10,430zl8,Best way to recommend products and how to classify?,https://www.reddit.com/r/MachineLearning/comments/430zl8/best_way_to_recommend_products_and_how_to_classify/,FR_STARMER,1453945381,"So I need to recommend products to users that use an application over time. The idea is, the more the person uses it, the more they products they recieve that reflect their interest. I am familiar with recommender systems, but they require a decent amount of users on the platform, especially if the product pool is 10,000+ which is the goal of my project.

A friend told me that you can vectorize all the products based on attributes and then calculate an average vector of a user and recommend products that way. What is the best way to vectorize products, which categories, and how does one vectorize a pool of 10,000+ products?

Thanks!",0,4
785,2016-1-28,2016,1,28,11,4314ve,"Machine Learning: An In-Depth, Non-Technical Guide - Part 1",https://www.reddit.com/r/MachineLearning/comments/4314ve/machine_learning_an_indepth_nontechnical_guide/,innoarchitech,1453947406,,0,0
786,2016-1-28,2016,1,28,11,4318ax,Are humans dethroned in Go? AI experts Stuart Russell and Francesca Rossi shared their take on this exciting development with us.,https://www.reddit.com/r/MachineLearning/comments/4318ax/are_humans_dethroned_in_go_ai_experts_stuart/,FLIxrisk,1453948718,,5,30
787,2016-1-28,2016,1,28,13,431n45,Using homemade NN package for CNN,https://www.reddit.com/r/MachineLearning/comments/431n45/using_homemade_nn_package_for_cnn/,hixidom,1453954520,"Hi Folks.

I've written a package in C for NN application and training using backpropagation. Now I want to find the simplest way of extending this package for application and training of CNNs. My idea for how to do this is shown in [this diagram](http://imgur.com/ut4kUMO). As shown, each filter layer in a CNN can be thought of as a 2-layer NN (1 input and 1 output layer) applied to many small partially-degenerate sets of inputs, with the result of each application being used as the inputs to the next layer up (be it another filter layer or simply the inputs of a standard NN). So, multiple instances of a 2-layer NN applied to a special formatting of the original data stream constitute a filter layer.

My uncertainty comes when considering how backpropagation is applied to this system of nested NNs. I can easily apply backpropagation to each of the 2-layer NN instances to obtain a delta for each filter stride, but then how do I feed these deltas to the next layer up? If it's the first layer of a standard NN, then the next layer up expects standard inputs rather than deltas of a lower row. Backpropagation of the first layer of the standard NN starts with taking the difference of actual inputs and target inputs. So my question is if I pass the deltas as ""actual inputs"" to the backpropagation procedure of a standard NN, then what should I pass as targets? I imagine the targets should be 0, since the NN is considered fully-trained when the deltas are 0.

If anyone could verify that my logic is sound, I would really appreciate it.
Thank you!",3,1
788,2016-1-28,2016,1,28,14,431vip,Basic question on the loss function in reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/431vip/basic_question_on_the_loss_function_in/,[deleted],1453958192,[deleted],0,1
789,2016-1-28,2016,1,28,14,431y6a,Which GoogLeNet Layers are good for feature extraction?,https://www.reddit.com/r/MachineLearning/comments/431y6a/which_googlenet_layers_are_good_for_feature/,anonDogeLover,1453959436,,8,6
790,2016-1-28,2016,1,28,15,4323hc,Used Fiber Laser,https://www.reddit.com/r/MachineLearning/comments/4323hc/used_fiber_laser/,mooremachinetools,1453962054,[removed],0,0
791,2016-1-28,2016,1,28,15,4324pd,Baykal Press Brake,https://www.reddit.com/r/MachineLearning/comments/4324pd/baykal_press_brake/,mooremachinetools,1453962715,[removed],0,1
792,2016-1-28,2016,1,28,16,4329g9,"Global and Chinese Triple Offset Butterfly Valve Industry, 2010-2020",https://www.reddit.com/r/MachineLearning/comments/4329g9/global_and_chinese_triple_offset_butterfly_valve/,aiden_12,1453965468,[removed],0,1
793,2016-1-28,2016,1,28,16,4329jx,Angle Roll,https://www.reddit.com/r/MachineLearning/comments/4329jx/angle_roll/,mooremachinetools,1453965534,[removed],0,1
794,2016-1-28,2016,1,28,16,432cv1,Hydraulic 4 Roll,https://www.reddit.com/r/MachineLearning/comments/432cv1/hydraulic_4_roll/,mooremachinetools,1453967556,[removed],0,0
795,2016-1-28,2016,1,28,17,432hht,Depth of the human neural network,https://www.reddit.com/r/MachineLearning/comments/432hht/depth_of_the_human_neural_network/,gabriel1983,1453970523,"Is is appropriate to ask what the depth of the human biological neutral network is?

And if it is appropriate to ask, then what is the answer? :)",11,3
796,2016-1-28,2016,1,28,18,432mcx,Discover the Global activated carbon filter consumption 2016 market research report,https://www.reddit.com/r/MachineLearning/comments/432mcx/discover_the_global_activated_carbon_filter/,naincyjorge,1453973764,,0,1
797,2016-1-28,2016,1,28,18,432noo,Global intrusion prevention system industry for 2016 illuminated by new report,https://www.reddit.com/r/MachineLearning/comments/432noo/global_intrusion_prevention_system_industry_for/,naincyjorge,1453974651,,0,1
798,2016-1-28,2016,1,28,20,432vc1,A youtube playlist of Neural Network tutorials.,https://www.reddit.com/r/MachineLearning/comments/432vc1/a_youtube_playlist_of_neural_network_tutorials/,TylerBlackett,1453979563,,0,80
799,2016-1-28,2016,1,28,20,432vdv,No Go: Facebook fails to spoil Google's big AI day,https://www.reddit.com/r/MachineLearning/comments/432vdv/no_go_facebook_fails_to_spoil_googles_big_ai_day/,egrefen,1453979589,,23,10
800,2016-1-28,2016,1,28,20,432vny,How we can say that Contractive AE and Denoising AE are algorithms for dimensionality reduction?,https://www.reddit.com/r/MachineLearning/comments/432vny/how_we_can_say_that_contractive_ae_and_denoising/,vinodrajendran001,1453979763,"Why Contractive AE and Denoising AEs are having greater hidden units than input unit?
The purpose of AE is to the reduce the input size on a set of data.
But then why CAE and DAE are having higher hidden units? aren't it violating the AE principle.
Reference:
videos from Hugo Larochelle
[1] Neural networks [6.7] : Autoencoder - contractive autoencoder
[2]Neural networks [6.6] : Autoencoder - denoising autoencoder",5,1
801,2016-1-28,2016,1,28,20,432yv7,How do LSTM's solve the vanishing gradient problem?,https://www.reddit.com/r/MachineLearning/comments/432yv7/how_do_lstms_solve_the_vanishing_gradient_problem/,zosoyyz,1453981745,"I can see how LSTM's solve the problem of the state propagating cleanly, but how are the gates themselves not affected by the vanishing gradient problem? It seems to me that they have the problem of the standard rnn cell, but they guard the state inside.

Am I missing some trivial insight?

Thanks",10,0
802,2016-1-28,2016,1,28,20,432zgc,Question: Methods for real-time article recommendation based on topic tags,https://www.reddit.com/r/MachineLearning/comments/432zgc/question_methods_for_realtime_article/,burn_in_flames,1453982059,"Hi,

I have a dataset of articles which are tagged with different topics/skills and I need to recommend an article to an editor who has the appropriate knowledge to review and edit the article. Each editor has a rating of 0 - 5 for each skill, and the articles just have a binary mapping of whether that skill/topic applies to the article. Editors request a new article at which time the most suitable article for that editor is chosen from the set of articles which need review. Editors then review the article and rate the article according to how well it matched their skill set and how difficult the subject matter was. So even if it matched their skill set they could mark it as above their level of expertise.

There are a few subtleties to the whole system:

1) New articles are being added the whole time
2) An editor can only edit one article at a time, and when they have been assigned the article no other editor can get it.
3) From pressing the button to receiving the article needs to be ""real-time"" or very low latency.
4) New topics and skills get added often (let's say once a day so that vector is always growing.)
5) We want to recommend the best case to an editor based on their skills and the topics of the article. But we also want to assign articles which are not too hard or too easy to the editor. So even though their skills match we need to maintain a difficulty distribution.

I considered the following possibilites as solutions, but am interested to hear if anyone else has some interesting suggestions or ideas. I am hoping to build and release this as an open source module once I get it working.

Solution 1: Train a NN for each editor to predict the ""difficulty"" and ""appropriateness"" of an atricle to an engineer, where the inputs are the binary vector of topics and the integer (0-5) vector of skills level for the editor. Then when the editor asks for a new article we run all the current articles through their NN and determine which one will be best. This solution seems computationally expensive and over complicated. I also don't like it as everytime new topics are added we need to rescale and retrain the NN.

Solution 2: Some for of recommendation engine to match and editor to an article. This will provide a list of all the current articles on the stack which match the editor, and how well they are suited to the editor. I am not sure what recommendation scheme to use for this, and what the matrix would look like as it is more complex than the always mentioned move to user recommender where it is just a single rating and the rows are just a user ID and coumns just a movie ID. I do like the approach in the sense that it can be event driven and the recommendations can be calculated everytime a new article comes in, thus when an editor is available we already know the list of best articles for them which are on the queue. I am not sure how long/computationally comples this would be. Perhaps articles would come in every 5 minutes and thus we cannot have the recommender taking 6 minutes to generate that solution table.

Any insights, discussions, articles, or alternative formulations would be greatly appreciated.

Thanks :)",0,4
803,2016-1-28,2016,1,28,21,43316m,I propose a Go match between Facebook and Google AIs.,https://www.reddit.com/r/MachineLearning/comments/43316m/i_propose_a_go_match_between_facebook_and_google/,validated1,1453983070,"https://www.facebook.com/zuck/videos/vb.4/10102619979032811/?type=2&amp;theater

http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html
",11,14
804,2016-1-29,2016,1,29,0,433nbu,IBMs Concept Recognition Platform - Brainstorm Use Case Ideas,https://www.reddit.com/r/MachineLearning/comments/433nbu/ibms_concept_recognition_platform_brainstorm_use/,gmo517,1453993564,"IBM's new concept recognition system. Input a text and ask for any ""concept"" and the output will be specific terms that relate to that concept from the text. Examples: input medical reports from testing a new drug and search for the concept: ""symptoms"". The output will be all the symptoms from the reports. Another example is inputting a turkish history book and asking to find all the ""turkish cities"". You can also control the degree to which your results relate to your concept. 

I just wanted to make a brainstorming post because I know there are people from many backgrounds here, so what else do you guys think this can be used for?

TL;DR: IBM's platform where you can input text and search for a general concept, and algorithm will extract all the specific terms related to your concept from the text. What are some uses for this type of application?",0,2
805,2016-1-29,2016,1,29,0,433oms,Bigger MNIST dataset?,https://www.reddit.com/r/MachineLearning/comments/433oms/bigger_mnist_dataset/,MarcoROG-SG,1453994081,"Hello!
I'm looking for a bigger MNIST dataset.
I know there are sets like InfiMnist and MNIST8M, however they're far too big (14GB) and they won't fit into my RAM.
Is there some middle option? Like 500 thousand examples, or around 2-4GB data?
Thanks for your help

PS: I already considered using a subset of MNIST 8M but I can't find a way to properly loading it without getting a crash.",9,0
806,2016-1-29,2016,1,29,0,433pbm,Using Python's scikit-learn library to achieve &gt;98% classification accuracy on the MNIST digits dataset.,https://www.reddit.com/r/MachineLearning/comments/433pbm/using_pythons_scikitlearn_library_to_achieve_98/,jrmontag,1453994357,,11,44
807,2016-1-29,2016,1,29,0,433sm1,Are there any public data sets which give attributes for clothing/ electronics items?,https://www.reddit.com/r/MachineLearning/comments/433sm1/are_there_any_public_data_sets_which_give/,n00bto1337,1453995634,"I wanted to train my model for it to recognize different clothes, or electronics items, basically things which I most frequently buy. Are there any data sets which would give me some attributes on which to compare such items? In image or text format?",0,2
808,2016-1-29,2016,1,29,0,433ud6,Google Vision API: Image Analysis as a Service,https://www.reddit.com/r/MachineLearning/comments/433ud6/google_vision_api_image_analysis_as_a_service/,caligolae,1453996308,,11,74
809,2016-1-29,2016,1,29,2,4346af,An opportunity to take part in current research in the field of Artificial Intelligence.,https://www.reddit.com/r/MachineLearning/comments/4346af/an_opportunity_to_take_part_in_current_research/,MathiasLoewe,1454000566,"I am currently making research in the field of Artificial Intelligence, and at the moment I'm trying to increase the efficiency of machine and human collaboration when evolving a learning behavior. For this purpose, I need some users who have no knowledge of the project to see if their intuition alone is enough to guide evolution towards the correct learning behavior that takes a computer alone many thousand attempts to evolve.

If you are interested, please carefully read the whole manual from here http://www.mathiasloewe.com/user_guide.pdf

In the manual, you will also find a link to the program itself. Sadly, it only works on Windows. It takes approximately 45 minutes to complete and you are very welcome to evolve more than one solution, since it often takes a little time to learn which behaviors are promising steppingstones towards the solution.

Thank you for taking time to help science discover the opportunities for a human-computer collaboration when evolving advanced behaviors.

All the best,
Mathias",1,0
810,2016-1-29,2016,1,29,2,4348m6,How can adding more features make my Random Forest classification accuracy lower?,https://www.reddit.com/r/MachineLearning/comments/4348m6/how_can_adding_more_features_make_my_random/,textClassy,1454001363,This doesn't make sense to me because these features could always just be assigned 0 feature importance ... but instead they are not and the accuracy goes down ... ,7,6
811,2016-1-29,2016,1,29,2,434c7a,Why were so many Computer Scientists surprised by Deep Minds Go performance?,https://www.reddit.com/r/MachineLearning/comments/434c7a/why_were_so_many_computer_scientists_surprised_by/,mirror_truth,1454002624,"In many of the articles I've read about this recent victory of Google's, quoted scientists thought we were in the ballpark of 10 years before this happening.

Otherwise, I've seen others who didn't give a prediction but are still surprised at the victory.

I understand why it is considered one, because of the combinatorial explosion of possible moves meant the algorithm couldn't brute force a solution.

But why does it seem to have been so surprising that it happened in such a short time scale? Sorry if this is the wrong place for this question.",29,26
812,2016-1-29,2016,1,29,3,434jxt,Layer Pre-training for Convnets in Keras,https://www.reddit.com/r/MachineLearning/comments/434jxt/layer_pretraining_for_convnets_in_keras/,isaacgerg,1454005283,"I am trying to do layerwise pretraining of a convnet in Keras.  However, I see 2 ways to do it.  I'm trying to figure out which is better, or if there is another alternative I am missing.

For the explanations below, assume my input is 100 x 100 and the first layer is 8 x 7 x 7  (e.g. 8, 7x7 filters)

For the first method, after the input layer passes through the convolutions, I have 8 images now.  Each one of those images I then pass through a single (de)convolutional filter and then add the results to reconstruct the input.  The problem with this is that Keras fans out its convnets so I would need to run parallel paths -- can Keras do this?

For the second method, after the input layer passes through the convolutions, I have 8 images now just as the first method.  Then, I pass them into a large dense network that is 100*100, and then reshape to (100, 100) for the reconstruction.  The problem with this method is that there are too many parameters and it may not train my constitutional filters because of the vanishing gradient issue.  i.e. If the dense layers encode all the information instead of the convolution filter.

Or, is there something another alternative?

**EDIT**  Fixed description of second method.",0,3
813,2016-1-29,2016,1,29,3,434k4x,r/MachineLearning on Slack,https://www.reddit.com/r/MachineLearning/comments/434k4x/rmachinelearning_on_slack/,thvasilo,1454005348,"A lot of awesome projects are getting posted in this sub constantly and there's always people looking to collaborate, so I thought that creating a Slack channel where people can meet, talk, team up and ask questions would be useful to a lot of people.

If that sounds interesting you can get an **[invite here](https://r-machinelearning-slack.herokuapp.com/)** (provided the Heroku app works as expected).

If that doesn't work send me a PM with the email and name you want to use and I'll send you an invite.

The URL is: https://reddit-ml.slack.com.

Cheers and happy collaborating!
",4,16
814,2016-1-29,2016,1,29,3,434lph,This Article Was Written By A Machine,https://www.reddit.com/r/MachineLearning/comments/434lph/this_article_was_written_by_a_machine/,[deleted],1454005885,[deleted],4,0
815,2016-1-29,2016,1,29,3,434n40,"What are some interesting results in statistical learning theory, relevant to deep learning?",https://www.reddit.com/r/MachineLearning/comments/434n40/what_are_some_interesting_results_in_statistical/,insperatum,1454006376,"I'd like to be able to think more clearly about what I can theoretically expect from the kinds of models and tasks that are fashionable right now.

As an example, is there any principled way to reason about how the sample complexity might change as a function of:

* The size of the network (depth, number of parameters, ...)
* The size of the task output (e.g. number of classes)
* The proportion of labelled vs. unlabelled data",3,1
816,2016-1-29,2016,1,29,3,434oc0,Recommendations for Geographic (city) classification?,https://www.reddit.com/r/MachineLearning/comments/434oc0/recommendations_for_geographic_city_classification/,jorthonormal,1454006814,"Hi.  I'm curious if someone could recommend a learning algorithm for a problem I'm trying to solve.  Given N pairs (lat,lon) representing locations of people, and a list of US cities with one (lat, lon) and square mile data, I want a rule that assigns a person to a city.

Currently, I'm thinking of creating a distance function d(person's location, city location, city size), then saying that a person is in a city if the city is the closest one to them.  The problem I'm having is that I can't get a smooth error term with this approach (I want to use stochastic gradient descent.)

If anybody has a direction they can point me in, I'd very much appreciate it!",2,1
817,2016-1-29,2016,1,29,4,434s98,Estimated strength of AlphaGo with respect to the Dan ranking system,https://www.reddit.com/r/MachineLearning/comments/434s98/estimated_strength_of_alphago_with_respect_to_the/,[deleted],1454008138,[deleted],0,4
818,2016-1-29,2016,1,29,4,434u2c,Helpful to relocate to NY or SF on own to apply for jobs?,https://www.reddit.com/r/MachineLearning/comments/434u2c/helpful_to_relocate_to_ny_or_sf_on_own_to_apply/,[deleted],1454008786,[deleted],1,0
819,2016-1-29,2016,1,29,5,4359ck,Using Docker to Build an IPython-driven Spark Deployment,https://www.reddit.com/r/MachineLearning/comments/4359ck/using_docker_to_build_an_ipythondriven_spark/,amplifier_khan,1454014104,,1,5
820,2016-1-29,2016,1,29,6,435c30,Please rate my coloring job,https://www.reddit.com/r/MachineLearning/comments/435c30/please_rate_my_coloring_job/,brockl33,1454015050,[removed],1,0
821,2016-1-29,2016,1,29,8,4361tn,does anyone use rnnlib or currennt libraries for RNN training?,https://www.reddit.com/r/MachineLearning/comments/4361tn/does_anyone_use_rnnlib_or_currennt_libraries_for/,aleph_two,1454024315,"or you prefer something other?

what is currently the best choice to embed into production if you need to work with rnn? ideally with easy integration with c++ code.",17,3
822,2016-1-29,2016,1,29,9,436anx,Using R to analyze web traffic?,https://www.reddit.com/r/MachineLearning/comments/436anx/using_r_to_analyze_web_traffic/,kailovesdata,1454027677,"Has anyone had experience with using R analyzing data on Google Analytics? 

I am a tech marketer and I believe this is the new trend. However, I can barely find resources on Google. 
Does anyone have good tutorial? or maybe can help me with authenticating R with GOOGLE Analytics? 

I am a new college graduate, and I have so much passion for this. Please help me. I will send whoever helps me hand-written post cards I got from China",10,3
823,2016-1-29,2016,1,29,9,436e3h,"""Recent advances in deep learning"" - Stanford Seminar - Oriol Vinyals of Google",https://www.reddit.com/r/MachineLearning/comments/436e3h/recent_advances_in_deep_learning_stanford_seminar/,mttd,1454029030,,5,43
824,2016-1-29,2016,1,29,10,436naf,Adult Service For Sex! ) Find Your Love to night! my saa,https://www.reddit.com/r/MachineLearning/comments/436naf/adult_service_for_sex_find_your_love_to_night_my/,nfesnotuasu,1454032793,,1,0
825,2016-1-29,2016,1,29,12,436yzc,Go Board Evaluation with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/436yzc/go_board_evaluation_with_tensorflow/,ScoobySnackPack,1454037687,,4,23
826,2016-1-29,2016,1,29,14,437jr9,Suggestions for introductory problems and datasets to explain Machine Learning concepts to Social Scientists,https://www.reddit.com/r/MachineLearning/comments/437jr9/suggestions_for_introductory_problems_and/,napsternxg,1454047124,"I will be giving a workshop to a group of social scientists in few days, and I wanted to know if there are any interesting social problems (whose real data is available), on which we can apply basic machine learning techniques: Classification and Clustering.

Till now, I am thinking of including an example of name gender prediction using the US SSN dataset. However, I am unable to find any interesting dataset which is small (~1k instances) and demonstrates the principles of machine learning clearly (importance of clustering, classification). 

Most participants are assumed to be aware of Linear regression but not logistic regression, decision trees and clustering methods. 

I don't want to explain the concepts using Iris data set or Boston housing prices as these are mostly examples for individuals from statistics or computer vision background. 

Are there data sets on human behavior classification or linguistic clustering?

Any suggestions are greatly appreciated.",1,0
827,2016-1-29,2016,1,29,15,437qop,Deep Learning Courses,https://www.reddit.com/r/MachineLearning/comments/437qop/deep_learning_courses/,brotherrain,1454050646,,17,113
828,2016-1-29,2016,1,29,16,437v0m,Supervised Term Weighting in R,https://www.reddit.com/r/MachineLearning/comments/437v0m/supervised_term_weighting_in_r/,[deleted],1454053140,[deleted],0,0
829,2016-1-29,2016,1,29,17,437z3k,"Hints for establishing a good training process, with focus on database creation",https://www.reddit.com/r/MachineLearning/comments/437z3k/hints_for_establishing_a_good_training_process/,choffmann,1454055874,"I was wondering if there is a rule of thumb for different problems in machine learning (considering just the dataset not the approach itself). 

For example, assuming the feature extractor and classifier is known to work well in this case, what kind of problems could lead to a bad detection rate (low true positive rate (TPR))? Otherwise what kind of problems in the dataset leads to a high false positive rate (FPR)? 

**Low TPR**
Case 1: I would think that I trained the classifier on a dataset which is too small, especially the positive set is too small? Hence its overfits and does not generalize well?
-&gt; Increase pos. dataset

**High FPR**
Case 2: I would expect the negative training is too small or does not generalize very well (samples are too similar)?
-&gt; Bootstrapping or other techniques to improve negative training set.

Is this reasoning correct or/and are there any other reasons you can think of?
Also, where can I find resources on how to establish a good training process (training/validation/testing) with focus on the database?

Thanks in advance",0,0
830,2016-1-29,2016,1,29,17,438195,Curated list of advanced machine learning resources,https://www.reddit.com/r/MachineLearning/comments/438195/curated_list_of_advanced_machine_learning/,[deleted],1454057293,[deleted],0,1
831,2016-1-29,2016,1,29,17,4381jo,Has DeepMind Really Passed 'Go'?,https://www.reddit.com/r/MachineLearning/comments/4381jo/has_deepmind_really_passed_go/,vikkamath,1454057503,,7,0
832,2016-1-29,2016,1,29,18,43847w,best introduction to causal inference?,https://www.reddit.com/r/MachineLearning/comments/43847w/best_introduction_to_causal_inference/,bhmoz,1454059319,"What would you recommend to get familiar with causal inference? not something in depth but mains ideas and basic methods. 

Something by Bernhard Schlkopf? Judea Pearl? Or the JMLR introduction to causal inference by Peter Spirtes (2010)?

Are there many flavours of causal inference? or is there a consensus?

Thank you",6,2
833,2016-1-29,2016,1,29,19,438a0l,Is noise-contrastive estimation (still) a thing?,https://www.reddit.com/r/MachineLearning/comments/438a0l/is_noisecontrastive_estimation_still_a_thing/,pannous,1454063311,[removed],0,1
834,2016-1-29,2016,1,29,21,438koe,A Beginners Guide to word2vec AKA Whats the Opposite of Canada?,https://www.reddit.com/r/MachineLearning/comments/438koe/a_beginners_guide_to_word2vec_aka_whats_the/,andyakesson,1454070121,,7,0
835,2016-1-29,2016,1,29,21,438kpf,Visual Search using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/438kpf/visual_search_using_tensorflow/,[deleted],1454070143,[deleted],0,3
836,2016-1-30,2016,1,30,0,4398l7,Challenge people worldwide by coding bots in awesome games. Anyone doing competitions there?,https://www.reddit.com/r/MachineLearning/comments/4398l7/challenge_people_worldwide_by_coding_bots_in/,char27,1454081295,,0,30
837,2016-1-30,2016,1,30,1,439iwq,How big is your data? and is your machine learning?,https://www.reddit.com/r/MachineLearning/comments/439iwq/how_big_is_your_data_and_is_your_machine_learning/,KatieContract,1454085043,,0,1
838,2016-1-30,2016,1,30,2,439rk9,"Machine Learning: An In-Depth, Non-Technical Guide - Part 1",https://www.reddit.com/r/MachineLearning/comments/439rk9/machine_learning_an_indepth_nontechnical_guide/,innoarchitech,1454087992,,0,0
839,2016-1-30,2016,1,30,2,439vp3,"Hybrid systems for vision, speech, etc.",https://www.reddit.com/r/MachineLearning/comments/439vp3/hybrid_systems_for_vision_speech_etc/,[deleted],1454089430,[deleted],1,0
840,2016-1-30,2016,1,30,2,439vrd,Have you ever successfully used ML to solve a practical problem for yourself?,https://www.reddit.com/r/MachineLearning/comments/439vrd/have_you_ever_successfully_used_ml_to_solve_a/,sleepicat,1454089453,"I'm wondering if anyone has used ML for personal projects like studying your spending habits, designing a recipe, investing for retirement, finding a job or date, etc. ",109,111
841,2016-1-30,2016,1,30,3,439ys1,Need some suggestions re: configuring an autoencoder,https://www.reddit.com/r/MachineLearning/comments/439ys1/need_some_suggestions_re_configuring_an/,sanity,1454090528,"I'm using [DJ4J](http://deeplearning4j.org/deepautoencoder.html) and I'm trying to use an autoencoder to take words and turn them into 2D vectors.

I'm using one-hot encoding for the words, which can be a maximum of 8 characters, which means that I have 26*8=208 input neurons for my autoencoder.  I'm using about 80000 words as a training set.

Starting from the example (linked above), this is my configuration (if the syntax looks a little weird it's because it is [Kotlin](https://kotlinlang.org/) - but should be easy to understand):

    val inputLayerSize = maxWordLength * 26
    val layer1Size = (inputLayerSize * 1.25).toInt()
    val conf = NeuralNetConfiguration.Builder()
        .seed(123)
        .iterations(10)
        .optimizationAlgo(OptimizationAlgorithm.LINE_GRADIENT_DESCENT)
            .learningRate(0.1)
        .list(12)
            // Encoding
        .layer(0, RBM.Builder().nIn(inputLayerSize).nOut(layer1Size).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(1, RBM.Builder().nIn(layer1Size).nOut(100).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(2, RBM.Builder().nIn(100).nOut(40).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(3, RBM.Builder().nIn(40).nOut(10).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(4, RBM.Builder().nIn(10).nOut(5).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(5, RBM.Builder().nIn(5).nOut(2).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            // Decoding
            .layer(6, RBM.Builder().nIn(2).nOut(5).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(7, RBM.Builder().nIn(5).nOut(10).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(8, RBM.Builder().nIn(10).nOut(40).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(9, RBM.Builder().nIn(40).nOut(100).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(10, RBM.Builder().nIn(100).nOut(layer1Size).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build())
            .layer(11, OutputLayer.Builder(LossFunctions.LossFunction.RMSE_XENT).nIn(layer1Size).nOut(inputLayerSize).build())
            .pretrain(true).backprop(true).build()
    val model = MultiLayerNetwork(conf)

I've tried stochastic and line gradient descent, and a wide range of learning rates, from 0.1 right down to 0.000000001, with batch sizes ranging from 20 up to 10000, but here is the type of result I'm seeing:

    11:53:18.344 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 0 is 115.35
    11:53:18.489 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 1 is 114.85
    11:53:18.554 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 2 is 117.65
    11:53:18.605 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 3 is 116.85
    11:53:18.655 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 4 is 116.4
    11:53:18.736 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 5 is 115.8
    11:53:18.806 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 6 is 116.5
    11:53:18.859 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 7 is 119.15
    11:53:18.921 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 8 is 118.15
    11:53:19.010 [main] INFO  o.d.o.l.ScoreIterationListener - Score at iteration 9 is 121.75

I feel like I'm stumbling around in the dark trying to find a configuration that works.  I would appreciate any suggestions about what I should try.  

I'd also appreciate it if someone could ELI5 exactly what success will look like once I've found a good configuration.",11,0
842,2016-1-30,2016,1,30,3,43a1t3,Classification in geospatial/time series data,https://www.reddit.com/r/MachineLearning/comments/43a1t3/classification_in_geospatialtime_series_data/,FutureIsMine,1454091553,"I've recently been stumped by a classification problem where there are 1 million data points. The data consists of a date, time stamp, and geolocation coordinates. I have tried using Logistical Regression which gets about 22% accuracy, KNN which gets anywhere from 23-29% accuracy, and lastly Random Forest gets 31% accuracy. I have yet to try an SVM since the training time is enormous.  Im wondering what are some good approaches to these types of problems, and what kind of learning algorithms/techniques produce good results with data that has both a temporal and a geolocation component? 

EDIT: I realize that I have not included all the details of the problem, here is the safe info given to csong27

There are 52 different products that are offered by a firm (think very large conglomerate), and what they are trying to do is given a geographic region, and a given date/time what kind of product do you expect was sold. For example Your given a data point from Brooklyn, New York, (the data is in geographic coordinates) and the date/time is 12/5/12 14:52:33, based on that info, what product do you predict was sold.",4,0
843,2016-1-30,2016,1,30,3,43a3f6,Recognizing correct code,https://www.reddit.com/r/MachineLearning/comments/43a3f6/recognizing_correct_code/,reidhoch,1454092084,,1,3
844,2016-1-30,2016,1,30,3,43a8rq,Autotagging with a predefined set of concepts,https://www.reddit.com/r/MachineLearning/comments/43a8rq/autotagging_with_a_predefined_set_of_concepts/,LovesDogs_CatsRokay,1454093844,"Not sure if this is the best place to ask, let me know if I should post this elsewhere. I'm wondering if anyone can recommend some sort of API that can be used to generate tag suggestions for content based on a pre-defined set of tags?

My company has a digital library of documents relating to the US economy. The want to create a list of subject headings and then automate a process to suggest possible subjects from that list for each document in the database.

Any suggestions or pointers on where to look would be great! Thank you!",6,0
845,2016-1-30,2016,1,30,4,43adkq,Predicting spatiotemporal data (non-video)?,https://www.reddit.com/r/MachineLearning/comments/43adkq/predicting_spatiotemporal_data_nonvideo/,knite,1454095449,"Note: ML rookie, I've been learning like crazy, but there's a long way to go and this field is changing rapidly...

It seems like the vast majority of beginner and intermediate ML resources focus on stateless classification tasks, almost always image-based.

I'm working on a thorny problem I'd like to tackle with ML. The domain-specific details aren't interesting, so here's a analogous problem:

I have temperature sensors in cities around the United States, one per city but not every city has one. Each city is in a region - East Coast, Midwest, etc. Temperature readings are collected at different intervals - I might get a reading from Chicago once a week, and a reading from Miami once a month. Readings are received in regional groupings: ""Midwest: Chicago 50, Indianapolis 45, ..."". Data set is relatively small: several dozen regions, several hundred total cities, each city has 100-200 readings at most.

Temperatures have seasonal variation, and have long term trends - in this hypothetical world, some cities are getting hotter over time and others are getting colder. I thought about turning this into a stock trading analogy, but that has too much baggage.

How can I code this as an ML problem? My goal is to represent the state of the world and feed in new data as it arrives, so I can always ask ""Give me your best guess for the current temperature of all the cities in the Pacific Northwest"".

The simplest way I can think of to encode this problem is: [region_id, [[city1_id, city1_temp], [city2_id, city2_temp]], or perhaps separating city IDs and temps into two separate arrays (zero-padded so they're the same length, because of different reporting frequencies).

I have a ton of additional data - latitude and longitude, date of measurement, etc. But in the end, all I care about is a best guess on the state of the world at this moment, preferably with a confidence/credibility interval attached.

It looks like there are ways to tackle this problem with stats (ARIMA?), but my hope is that an ML model will learn, for example, that Chicago and Cleveland temps are related, so as new data comes in showing the Chicago temp dropping, the network ""knows"" that it's winter, and predicts lower temps for Cleveland, even if Cleveland hasn't reported in for a while.
",2,0
846,2016-1-30,2016,1,30,4,43ag1o,Is there a minimum corpus size for LDA,https://www.reddit.com/r/MachineLearning/comments/43ag1o/is_there_a_minimum_corpus_size_for_lda/,textClassy,1454096291,In terms of words and/or documents? I have trouble finding a good rule of thumb for this anywhere online. ,2,0
847,2016-1-30,2016,1,30,4,43agul,A Deep Net that Suggests Emojis for Your Images [xpost /r/deeplearning],https://www.reddit.com/r/MachineLearning/comments/43agul/a_deep_net_that_suggests_emojis_for_your_images/,louk83,1454096551,,1,8
848,2016-1-30,2016,1,30,5,43ao51,AI Researcher Yoshua Bengio Says Machines Wont Become Dangerously Smart Anytime Soon | MIT Technology Review,https://www.reddit.com/r/MachineLearning/comments/43ao51/ai_researcher_yoshua_bengio_says_machines_wont/,[deleted],1454099121,[deleted],8,0
849,2016-1-30,2016,1,30,5,43appy,New Talking Machines episode : OpenAI and Gaussian Processes,https://www.reddit.com/r/MachineLearning/comments/43appy/new_talking_machines_episode_openai_and_gaussian/,Barbas,1454099669,,2,16
850,2016-1-30,2016,1,30,5,43asms,Feature engineering,https://www.reddit.com/r/MachineLearning/comments/43asms/feature_engineering/,ofigue,1454100706,"Hi, I 'd like to get much deeper in this topic for the importance it has in machine learning. Maybe suggestions of some links.
Thanks in adavance",2,0
851,2016-1-30,2016,1,30,5,43ast4,D3 in Jupyter + video + slides,https://www.reddit.com/r/MachineLearning/comments/43ast4/d3_in_jupyter_video_slides/,lokator9,1454100775,,1,9
852,2016-1-30,2016,1,30,6,43ay70,Is there a practical guide to getting the most out of gensim anywhere?,https://www.reddit.com/r/MachineLearning/comments/43ay70/is_there_a_practical_guide_to_getting_the_most/,[deleted],1454102720,[deleted],0,1
853,2016-1-30,2016,1,30,6,43b3bm,How to apply AI to play computer games?,https://www.reddit.com/r/MachineLearning/comments/43b3bm/how_to_apply_ai_to_play_computer_games/,Modchip1990,1454104563,"I have built a q-learning algorithm to play pacman, smart taxi, and gridworld. Unfortunately, all these games came conveniently from my professor in python files ready for me to edit and apply to the game. 

How would I apply these same methods to other computer games? Could be computer games, online games, pygames, etc. I literally would be happy applying these algorithms to anything else. I am just not sure how I go about programming the agent to act, and getting rewards without seeing the source code?

I saw an interview with Demis Hassabis where he said his algos would ""see"" the pixels of the screen to learn to play Atari? That seems extremely complicated...

Not asking for a specific answer as I'm sure it's nuanced, but if someone could please point me in the right direction that would be great and if I'm in the wrong subreddit, I apologize.
Thanks!",6,2
854,2016-1-30,2016,1,30,7,43bby4,"Training word prediction NN on gaming community posts [Beginner, Exercise]",https://www.reddit.com/r/MachineLearning/comments/43bby4/training_word_prediction_nn_on_gaming_community/,GATORGILL,1454107752,,3,6
855,2016-1-30,2016,1,30,7,43bc02,Deep learning that finds you a dress,https://www.reddit.com/r/MachineLearning/comments/43bc02/deep_learning_that_finds_you_a_dress/,ignorant314,1454107770,,0,3
856,2016-1-30,2016,1,30,8,43bi1z,Anyone know of a good tutorial on HMMs?,https://www.reddit.com/r/MachineLearning/comments/43bi1z/anyone_know_of_a_good_tutorial_on_hmms/,Nixonite,1454110116,"So I've read this one 

http://di.ubi.pt/~jpaulo/competence/tutorials/hmm-tutorial-1.pdf

But I still don't feel like I understand the point of it. Does anyone have something like a Python coded tutorial of a simple but real data set example for the application of HMMs? Maybe like an ipython notebook?

I'd really appreciate any input!",8,15
857,2016-1-30,2016,1,30,11,43c4e6,when should I use LDA vs doc2vec as an input to my text classifier?,https://www.reddit.com/r/MachineLearning/comments/43c4e6/when_should_i_use_lda_vs_doc2vec_as_an_input_to/,textClassy,1454119303,,2,1
858,2016-1-30,2016,1,30,11,43c6xg,Googles Go Victory Is Just a Glimpse of How Powerful AI Will Be,https://www.reddit.com/r/MachineLearning/comments/43c6xg/googles_go_victory_is_just_a_glimpse_of_how/,vonnik,1454120468,,1,0
859,2016-1-30,2016,1,30,11,43cbun,More Epochs VS More Data in a given time period,https://www.reddit.com/r/MachineLearning/comments/43cbun/more_epochs_vs_more_data_in_a_given_time_period/,butWhoWasBee,1454122730,"Let's say you had an infinite supply of data for a given problem (e.g. problem is guessing the next character and you have an infinite library of books)

For a given amount of training time using backprop to train a NN, would one epoch using as much data as possible outperform more epochs on a given subset of data? Would we expect 1 epoch on 100 books worth of text to beat 10 epochs on the same 10 books of text? 

I understand this may vary with the problem, so I welcome any practical advice. 


",5,3
860,2016-1-30,2016,1,30,13,43cpvn,This Site Likelyy Contains-s Sexually Expliciit Photos- Of Someone You Know! my aada,https://www.reddit.com/r/MachineLearning/comments/43cpvn/this_site_likelyy_containss_sexually_expliciit/,thucorredgsupp,1454129618,,0,0
861,2016-1-30,2016,1,30,14,43cqyk,"Pneumatics and Hydraulics: Importance, Comparison and a Few Differences",https://www.reddit.com/r/MachineLearning/comments/43cqyk/pneumatics_and_hydraulics_importance_comparison/,jackerfrinandis,1454130169,,0,1
862,2016-1-30,2016,1,30,15,43czif,"Hey everyone, I'm looking for fellow casual data hobbyists who want to team up to enter some Kaggle competitions",https://www.reddit.com/r/MachineLearning/comments/43czif/hey_everyone_im_looking_for_fellow_casual_data/,itchybumbum,1454134779,"I've always been interested in entering some of them but it would be much more fun/motivating to do so as a team. If you're interested please let me know!

I'm a young (24) engineer who dabbles in statistics and data analysis (R, Pandas, excel) all the time! PM or comment, thanks!",16,5
863,2016-1-30,2016,1,30,16,43d8wn,"NOAA Right Whale Recognition, Winners' Interview: 1st place, deepsense.io",https://www.reddit.com/r/MachineLearning/comments/43d8wn/noaa_right_whale_recognition_winners_interview/,lokator9,1454140661,,7,39
864,2016-1-30,2016,1,30,17,43de38,Which is the best software library for deep learning?,https://www.reddit.com/r/MachineLearning/comments/43de38/which_is_the_best_software_library_for_deep/,Mr__Christian_Grey,1454144256,,3,0
865,2016-1-30,2016,1,30,19,43dn9y,Which gpu for deep learning?,https://www.reddit.com/r/MachineLearning/comments/43dn9y/which_gpu_for_deep_learning/,Jadeyard,1454150934,"For experimenting, is a geforce 980 still good? Do you need a specific gpu for cudnn v4 ?

Edit: not looking for two years old posts that I already read, but instead for a verification that the information is still up to date.",18,12
866,2016-1-30,2016,1,30,20,43dr7i,Learn Machine Learning with R | Certification Course Video,https://www.reddit.com/r/MachineLearning/comments/43dr7i/learn_machine_learning_with_r_certification/,jatingoel,1454153748,,0,1
867,2016-1-30,2016,1,30,20,43dsa1,"Data science jobs easy to find, tough to fill",https://www.reddit.com/r/MachineLearning/comments/43dsa1/data_science_jobs_easy_to_find_tough_to_fill/,jatingoel,1454154434,,0,1
868,2016-1-30,2016,1,30,21,43dtk0,Microsoft quietly unwraps a big-data analytics platform based on R,https://www.reddit.com/r/MachineLearning/comments/43dtk0/microsoft_quietly_unwraps_a_bigdata_analytics/,jatingoel,1454155240,,0,1
869,2016-1-30,2016,1,30,21,43dv8q,Conference explores the collision between neuroscience and machine learning,https://www.reddit.com/r/MachineLearning/comments/43dv8q/conference_explores_the_collision_between/,jatingoel,1454156279,,0,1
870,2016-1-30,2016,1,30,23,43ecnw,Please suggest good beginner tutorials (or papers which can be read as starting points) for Neural Nets with Attention,https://www.reddit.com/r/MachineLearning/comments/43ecnw/please_suggest_good_beginner_tutorials_or_papers/,muktabh,1454165679,,6,7
871,2016-1-31,2016,1,31,1,43em22,ThIs Site Likelyy Containss Sexuallly Expliciit Photos Of Someoone You Know! my iad,https://www.reddit.com/r/MachineLearning/comments/43em22/this_site_likelyy_containss_sexuallly_expliciit/,japicraylawn,1454169810,,1,0
872,2016-1-31,2016,1,31,1,43ermr,google deepmind attacks Go and AlphaGo attacks top human! AI highlights &amp; topnotch links last 6mo,https://www.reddit.com/r/MachineLearning/comments/43ermr/google_deepmind_attacks_go_and_alphago_attacks/,vznvzn,1454172037,,0,0
873,2016-1-31,2016,1,31,2,43evfx,Andrew Ng Live Quora Session,https://www.reddit.com/r/MachineLearning/comments/43evfx/andrew_ng_live_quora_session/,abstractcontrol,1454173552,,11,27
874,2016-1-31,2016,1,31,2,43ezo5,What is Artificial Intelligence ?,https://www.reddit.com/r/MachineLearning/comments/43ezo5/what_is_artificial_intelligence/,rautsan,1454175170,,0,1
875,2016-1-31,2016,1,31,3,43f7sm,Fine-tuning semantic segmentation,https://www.reddit.com/r/MachineLearning/comments/43f7sm/finetuning_semantic_segmentation/,ienaplissken,1454178203,"Let's say we would like to realize a CNN-based model for semantic segmentation of custom classes. Red peppers, horses and hats.

What's the most promising path? 
Is it better to simply take a good image classification model (Inception, VGG, etc.) and make it fully convolutional, or start from a semantic segmentation model (e.g. [this one](https://gist.github.com/longjon/1bf3aa1e0b8e788d7e1d#file-readme-md)) and re-train it with custom data?",4,3
876,2016-1-31,2016,1,31,3,43f9eb,What about transforming autoencoders allows them to learn pose parameters?,https://www.reddit.com/r/MachineLearning/comments/43f9eb/what_about_transforming_autoencoders_allows_them/,cysc,1454178751,"I submitted the following to stats.stackexchange.com and got no response. Hoping I'll get more of a response here:

After reading several papers on transforming autoencoders and looking through an implementation on github I'm curious what it is that enables them (and not standard autoencoders) to learn pose parameters:

[Original paper](http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf)

[Github](https://github.com/yingzha/Transforming-Autoencoders)

The only major technical difference that sticks out to me between transforming autoencoders and standard autoencoders is that the bottleneck layers in the transforming autoencoder are linear instead of sigmoid (or any other saturating type). That seems to me like the most reasonable answer since it makes it easier to pass scalars instead of binary probabilities across the bottleneck.

While another apparent difference is that transforming autoencoders separate the task into isolated ""capsules"" to create the reconstruction, this shouldn't be much different from simply weighing the predictions of multiple standard autoencoders.

The paper mentions feeding in the pose parameters of the training data as additional input, but also mentions that this is not necessary and is only done to speed the learning process. So the model is capable of learning pose parameters through some other means.

Is the linearity of the bottleneck layers enough by itself for back-propagation to use it for pose parameters? Or is there another component that is responsible for this?",0,7
877,2016-1-31,2016,1,31,4,43fl90,Synopsis of top Go professional's analysis of Google's Deepmind's Go AI,https://www.reddit.com/r/MachineLearning/comments/43fl90/synopsis_of_top_go_professionals_analysis_of/,NFB42,1454183126,"Hi there. Earlier this month I had [a discussion](https://www.reddit.com/r/hearthstone/comments/3zdibn/intelligent_agents_for_hearthstone/cylnbf2) over on /r/hearthstone with /u/yetipirate about Computer Go. Then the news hit this week of the first Go AI to beat a human professional.

We had some more discussion then, and I made a synopsis of [this video](https://www.youtube.com/watch?v=NHRHUHW6HQE), where the US Go Association has Myungwan Kim, 9-Dan Pro, analyse the games between the AlphaGo AI and human professional Fan Hui, 2-Dan Pro. (FTR: Professional go ranks start at 1-Dan and go up to 9-Dan, but rather than the absolute top 9-Dan is more like the beginning of grandmastery. The best players in the world are like 9-Dan+++++. Lee Sedol, which AlphaGo will challenge next this March, is at this latter level.)

/u/yetipirate suggested this synopsis might interest some people here as well, since it digests the salient points of a two hour video with lots of Go jargon into a more manageable post. So hence I'm posting it here, I hope you all enjoy it. Feel free to ask me any questions about Go, but I'm not that strong myself so ymmv. Anyway without further ado:

**In General:**

The match has been big news in East-Asia as well. The thing which most shocked all the professionals was that AlphaGo played so much like a human player. Their first impressions were that it's as if this was a human playing, not a computer.

Since how a human plays is, obviously, pretty well known, they decided that they'll focus commentary mostly on those cases where AlphaGo doesn't play like a human.

The first thing that Myungwan Kim noted was that AlphaGo has a Japanese playstyle (this is especially interesting because among the three traditional Go powerhouses, China, Korea, and Japan, the Japanese have been the weakest in international competitions for the past several decades). The commentators don't know, but they suspect it is that the original human data set was biased towards Japanese playstyles.

Myungwan Kim also makes a comment about one of the lines continually repeated in the coverage of Computer Go. The line that ""if you ask a top Go player why they like a certain move, they'll often say 'it felt right'"". Myungwan Kim wanted to add that just because it's based on intuition, doesn't mean there's no logic behind it at all. Top Go players aren't just guessing what are good moves, they have a real and complicated rational understanding about what specific moves are doing. Even if the final decision might come down to which move feels the best, it's not as simple as top pro's just doing a random move and saying 'I felt like it'.

**The Games:**

In the **first game** both sides played very passively in the opening. Leisurely and gentle they say.

Myungwan Kim finds that AlphaGo has a weakness here, it doesn't seem to understand the value of taking and holding initiative. Complicated to explain, but at its core it's about doing moves which force your opponent to use their turn to react to your move over doing moves which might be equally valuable to you, but leave your opponent free to do whatever they want on their turn.

Important, Myungwan Kim says because of this that the first game Fan Hui was winning in the opening. He says this was the only game Fan Hui was winning after the opening. He estimates Fan Hui was about 10 points ahead, and can't see white getting back even 5 points coming out of that opening. Myungwan Kim offers some alternate moves for AlphaGo which would still have Fan Hui in the lead, but would've given AlphaGo better opportunities to comeback.

Conclusion from the opening: AlphaGo lost because it didn't understand the value of initiative.

Myungwan Kim later points to one huge mistake by Fan Hui in the midgame that lost him the game. I can't go into detail here because, as characteristic of top-level Go, it's the difference of placing one stone one space higher. But Myungwan Kim says that while Fan Hui made other small mistakes, this one move is the big one which let AlphaGo come back from losing the opening.

Final conclusion from game one: Aside from not understanding initiative. Myungwan Kim says AlphaGo betrays itself as a computer in that it sometimes it goes too far in mimicking standard professional play and does the most common move instead of the most optimal move. In other words, it's extremely book smart, but at times fails to notice when it should be ignoring the books because the specific situation in the game makes the less standard move the most optimal one instead. (A bit cliche imo, but Myungwan Kim says ""AlphaGo is not creative"".) They think that might really hurt AlphaGo in the game against Lee Sedol.

**Game 2**, they note Fan Hui really played too aggressively, as he noted in his own post-match interview. Myungwan Kim says he can really see Fan Hui wasn't playing his best game, but was trying to test AlphaGo to see if it could be tricked into making exploitable mistakes.

Myungwan Kim says Fan Hui actually put up a really good fight. After the opening it should've been over for Fan Hui, but AlphaGo almost allowed Fan Hui to get back in the game.

**Game 3** is similar to the fifth game, though Fan Hui played better in the beginning here. Myungwan Kim notes several moves by AlphaGo which are top professional moves. He notes some moves by Fan Hui which he thinks hints that Fan Hui might be a bit out of practice when it comes to playing professional level games (he says it's the kind of move you do if too used to playing teaching games against amateurs). Fan Hui lost because he played over-aggressive and left too many holes in his defence as a result.

On the **fifth game**, Myungwan Kim says AlphaGo was winning from the beginning here. They marvel at some of AlphaGo's moves here, but they're not sure whether AlphaGo really knew what it was doing or if it just got 'lucky' somehow.

Myungwan Kim points out AlphaGo made a huge mistake early in this game, but was saved because not long after Fan Hui made an equally huge mistake. But this is an example where he thinks a real grandmaster like Lee Sedol would not have allowed AlphaGo to get away with the kind of mistake it made there.

**AlphaGo's Strengths and Weaknesses:**

Myungwan Kim lists AlphaGo's strengths:

 * It's not afraid of 'Ko'. 'Ko' is too complex a concept to explain succinctly, for an attempt [see my post here](https://www.reddit.com/r/MachineLearning/comments/43fl90/synopsis_of_top_go_professionals_analysis_of/czi7swh). They marvel at some of AlphaGo's moves surrounding a 'Ko' situation, but aren't sure if AlphaGo really knew what it was doing or just got lucky that it worked out.

 * Reading might be AlphaGo's strength. As in, cases where it comes down to very straightforward fights and moves it's very strong at choosing the right moves.

Myungwan Kim lists AlphaGo's weaknesses:

 * Doesn't understand initiative, as explained earlier.

 * At times too obsessed with following common patterns, when the specific situation might require creative deviation from those patterns. Also explained earlier.

 * It doesn't understand 'Aji'. 'Aji' is difficult to explain, but it refers to the amount of uncertainty remaining in a specific grouping of white and black stones. (Usually, it's about the chance that a group of stones which is 'death' might become alive and vice versa as a result of things happening elsewhere on the board.) You can also put this differently as: AlphaGo lacks proper long-term thinking.

 * Myungwan Kim thinks AlphaGo has difficulty, or even doesn't at all, evaluating the value of specific stones. It's good at making moves which directly gain territory for itself, but tends to miss moves which reduce the value of the opponent's stones.

 * It can make really high level moves at times, but it doesn't understand those moves. Which it displays by making the right moves at the wrong time.

More generally Myungwan Kim thinks a weakness of AlphaGo is its insularity. He really stresses that human pro's become much stronger when they discuss and analyse their games with other pro's. And because AlphaGo primarily plays against itself the quality of the feedback it gets on its play is too one-note, which leaves holes in its plays whereas human pro's getting feedback from many other human pro's end up with more robust and stronger playstyles. He really thinks to progress past its current level AlphaGo needs to play more with top human pro's rather than just itself. Right now, Myungwan Kim en most pro's he knows don't feel threatened by AlphaGo. They also talk about how AlphaGo can be useful for human pro's to study and become stronger, which can make AlphaGo stronger in turn. (This last paragraph is imo all just Myungwan Kim musing based on his understanding of how AlphaGo was designed more than evaluating its plays themselves, so that's why I didn't list it as a bullet point.)

In general, I get the sense from Myungwan Kim's explanations that he thinks AlphaGo is stronger at the more concrete parts of Go play, such as territory and life-or-death, and weaker at the more vague concepts, such as influence and uncertainty.

**[word limit hit, final part below]**",133,520
878,2016-1-31,2016,1,31,4,43flq4,How to Check Hypotheses with Bootstrap and Apache Spark,https://www.reddit.com/r/MachineLearning/comments/43flq4/how_to_check_hypotheses_with_bootstrap_and_apache/,themisterdj,1454183299,,4,16
879,2016-1-31,2016,1,31,5,43fq2z,Part time ML jobs?,https://www.reddit.com/r/MachineLearning/comments/43fq2z/part_time_ml_jobs/,sensitiveinfomax,1454184930,"i have a masters degree and have worked ML/NLP/Data science jobs in several big companies over the past 5-6 years. i don't see a PhD in my future.

i love working on researchy problems in the industry, but my experience so far has been of longish hours, and lots of hard work. most of the impactful work seems to happen at small startups and the workload in those places are not exactly 9 to 5. so far that's been okay. 

but eventually i want to transition into a more chilled out schedule. i have a lot of other goals I've been ignoring and what i want is to eventually work only four days a week or less.  

what kinds of career paths exist in ML/DS that allow for such a schedule? which companies accommodate such flexible availability? 

I've also considered entrepreneurship, but every startup owner i know seems to go on about long hours.",4,13
880,2016-1-31,2016,1,31,5,43fw8s,Simple seq2seq example in TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/43fw8s/simple_seq2seq_example_in_tensorflow/,deep_rabbit,1454187169,"Does anyone have code they'd be willing to share for a dead-simple sequence to sequence model built in Tensorflow?

I have spent a long time slamming my head against [their translation tutorial](https://www.tensorflow.org/versions/master/tutorials/seq2seq/index.html). Unfortunately, it's a really complex model to try to learn from, full of bells and whistles:

* sampled word embeddings

* bucketing

* attention

* a huge (20GB) training corpus.

It works as written, and it's probably close to state of the art for machine translation models, which is impressive in its own right... but I think they made a pretty serious misstep in designing their documentation by holding out something this complex as the one and only sequence-to-sequence tutorial. It's really hard to digest all of these features at once when you're new to their platform, picking your way through the code one line at a time. Their [sequence to sequence library](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py) supports much simpler models out of the box, but the tutorial skips all of those methods and starts with the weapons-grade high-octane model, which is not at all helpful when you're trying to understand the basics of the platform.

The ideal tutorial would be code for a simple model that takes a constant-length string of tokens as input and targets its output to another constant-length string of tokens. The training data would just be two lists of strings, trained at the character level. A single bucket size, no attention, no word embeddings, just one sequence mapped directly to another sequence. Even if the data is toy data, I just want to see how to construct the training loop and the sampling loop without having to surmount all of the extra optimizations and features simultaneously.

Can anyone suggest a good starting point for this? If anyone has such a model (or has the know-how to put one together in a few minutes), could you push it to github and point me to it?

And by the way, if anyone feels similarly stuck with the Tensorflow basic sequence predictor model, I cannot recommend highly enough /u/sherjilozair 's [TensorFlow char-rnn model](https://github.com/sherjilozair/char-rnn-tensorflow). It is simple and elegant, the code is clear, and it is a much better place to start to understand RNNs in Tensorflow than anything that comes as part of the official documentation. I'm super grateful to /u/sherjilozair for putting it together and making it available.",5,4
881,2016-1-31,2016,1,31,6,43g08x,Optimizing a complex non-differentiable loss function,https://www.reddit.com/r/MachineLearning/comments/43g08x/optimizing_a_complex_nondifferentiable_loss/,mlthrowaway5,1454188613,"I'm trying to train a neural net to optimize my own custom loss function. However, my loss function is pretty complicated - for example, one part of it relies on POS tagging. Therefore it is also not differentiable.

I have thought about replacing the non-differentiable ""parts"" of the function with neural nets (for example, the POS tagger (currently coreNLP) could be replaced by an existing neural net, which is differentiable) but that would seem pretty complicated. I've seen a Keras example that does this, though. 

What other options do I have?

(P.S. If it matters, I'll probably be using Theano/Keras)",6,2
882,2016-1-31,2016,1,31,6,43g2vp,Has anyone heard back from Google Brain Residency Program?,https://www.reddit.com/r/MachineLearning/comments/43g2vp/has_anyone_heard_back_from_google_brain_residency/,JamesVanDerButt,1454189620,Got notification mid January that app process had closed and interviews are supposed to be conducted in February. Has anyone heard back about an interview? ,11,8
883,2016-1-31,2016,1,31,7,43g7jl,Multi-layer and Bidirectional RNN/LSTM Available in tensorflow/skflow,https://www.reddit.com/r/MachineLearning/comments/43g7jl/multilayer_and_bidirectional_rnnlstm_available_in/,[deleted],1454192087,[deleted],0,1
884,2016-1-31,2016,1,31,8,43glj1,Subreddit clustering,https://www.reddit.com/r/MachineLearning/comments/43glj1/subreddit_clustering/,LowLanding,1454197459,"I'm looking to cluster subreddits in to even smaller ""communities"" by doing some unsupervised learning.

Here's my plan of attack:

* Take the latest S submissions (for a specified subreddit) from the reddit data dump on BigQuery (# of submissions to be determined - performance impact)
* Build a matrix of all users who commented on a submission. ie: users on the Y axis, submissions on the X and a 0/1 value if they commented on that submission.
* Upon getting the data in a usable form, I will build an n*n symmetric matrix (n: user). Element at the i-th row and j-th column being the distance between the i-th and j-th users. My initial thought for distance is to just sum the amount of common submissions users have commented on.
* Now that I have essentially a ""distance"" matrix for a user to all other users under consideration, perform a hierarchical clustering.

I have light experience with Scikit-learn and was going to use that. I'm incredibly new to ML so any feedback, tips, resources or help towards helping me do what I outlined would be awesome!",0,2
885,2016-1-31,2016,1,31,8,43gnsn,Cannot generalize a simple feed forward ANN problem,https://www.reddit.com/r/MachineLearning/comments/43gnsn/cannot_generalize_a_simple_feed_forward_ann/,wweber,1454198298,"I'm trying to use a regular feed forward neural network to classify content into various content ratings, e.g. G, PG, PG-13, and R, based on tags on the content. For example, a book/movie/whatever with the tags ""disney"" and ""educational"" might be rated G, and something with the tags ""boobs"" and ""sex"" might be rated R. Note that these tags would be in no particular order, and they aren't part of a larger text.

I've had success on individual samples, with a trained network getting &gt;95% accuracy, but it is always over-fitted. No matter what I do, I can't get over 50-60% success on a separate sample.

Here's my workflow:

- The top few thousand tags for each rating (not overlapping) are taken
- The network input is a vector of these tags, with a 1 indicating the tag is present, and a 0 indicating it is absent, on each piece of content
- A random sample of content is taken from the database (equal amounts of each rating). Each item is guaranteed to have at least one of the considered tags
- k-fold cross validation is performed. For each fold:
  - The data set is shuffled, and is split 90/10 randomly into the training and validation set
  - The network is repeatedly trained on the training set, until the error on the validation set begins increasing instead of decreasing
- The network is then tested on another sample.

The network looks like:

    inputs (tag boolean vector) -&gt; sigmoid hidden layer -&gt; softmax output into a 4-vector

Are there any different ways to approach this problem to increase the generalization? Changing the number of hidden nodes/layers doesn't affect this much.",7,2
886,2016-1-31,2016,1,31,10,43h2w0,what's the best doc2vec tutorial?,https://www.reddit.com/r/MachineLearning/comments/43h2w0/whats_the_best_doc2vec_tutorial/,textClassy,1454204440,there seem to be several but none of them is particularly good for getting started ... ,2,2
887,2016-1-31,2016,1,31,10,43h3zd,List of high-quality open datasets in public domains,https://www.reddit.com/r/MachineLearning/comments/43h3zd/list_of_highquality_open_datasets_in_public/,vonnik,1454204871,,2,57
888,2016-1-31,2016,1,31,15,43i394,Best OpenCL deep neural network framework?,https://www.reddit.com/r/MachineLearning/comments/43i394/best_opencl_deep_neural_network_framework/,darkconfidantislife,1454221979,"Hey there guys! I am looking for a deep neural network framework for OpenCL (ARM Mali GPU).
Thanks guys!",13,4
889,2016-1-31,2016,1,31,15,43i3j0,Is there any task where deep neural nets fail or can't do as well as other algorithms?,https://www.reddit.com/r/MachineLearning/comments/43i3j0/is_there_any_task_where_deep_neural_nets_fail_or/,Professional_123,1454222159,I'm just curious. I feel like deep learning is getting too much hype.,7,5
890,2016-1-31,2016,1,31,17,43ib26,Why don't we use gaussian density to preprocess machine learning data per default?,https://www.reddit.com/r/MachineLearning/comments/43ib26/why_dont_we_use_gaussian_density_to_preprocess/,JustSomeAccount456,1454227221,"If we have like 3 classes in classification, why dont we map every of our X inputs to its probability of belonging to one of these classes using the gaussian density?

I mean, we would get X*3 input dimensions (in the worst case), but shouldnt the NN have a simpler time learning from probabilities then from raw data?

Thanks in advance!",6,5
891,2016-1-31,2016,1,31,19,43imbv,Project Template for Data Science/Analysis : Python,https://www.reddit.com/r/MachineLearning/comments/43imbv/project_template_for_data_scienceanalysis_python/,[deleted],1454235960,[deleted],0,0
892,2016-1-31,2016,1,31,22,43j2wy,"TOP SECRET: Newly declassified documents on evaluating models based on predictive accuracy - Statistical Modeling, Causal Inference, and Social Science",https://www.reddit.com/r/MachineLearning/comments/43j2wy/top_secret_newly_declassified_documents_on/,mttd,1454247619,,6,0
893,2016-1-31,2016,1,31,22,43j4yf,Mfcc frames to phoneme alignment in TIMIT data,https://www.reddit.com/r/MachineLearning/comments/43j4yf/mfcc_frames_to_phoneme_alignment_in_timit_data/,rangslr1,1454248684,"Hi, I am trying a simple phoneme classification task using MLP with MFCC as my input features. Using a 25 ms frame with a 10ms frame shift, I have managed to generate the MFCC features. Now my problem is how do I tag the the frames to the phonemes. Sure, in TIMIT  the start and stop time of each phoneme is provided but overall the tagging seems incoherent. Lets say there is a phoneme 'h#',  according to the start and stop time and taking the frame size and shift into consideration, around 10.5 frames should be assign to this phoneme. But how do I assign the 0.5 frame. Should I just round up the number of frames  assign to phone 'h#' to 10. Is there a better way to do this ? ",13,8
894,2016-1-31,2016,1,31,23,43j8r1,Base proofiles unmarried women old 18 online. The base is availaable only 2 hours. khm..odaa,https://www.reddit.com/r/MachineLearning/comments/43j8r1/base_proofiles_unmarried_women_old_18_online_the/,reseraden,1454250695,,0,1
