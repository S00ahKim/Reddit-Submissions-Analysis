,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2014-2-1,2014,2,1,22,1wq5fu,Best Toroidal Winding Machines,https://www.reddit.com/r/MachineLearning/comments/1wq5fu/best_toroidal_winding_machines/,uday02,1391262203,,0,1
1,2014-2-2,2014,2,2,15,1wsfkc,"Dear MachineLearning, I've Been Drinking...",https://www.reddit.com/r/MachineLearning/comments/1wsfkc/dear_machinelearning_ive_been_drinking/,monobarreller,1391321934,"So as I said I've been drinking a bit and I had an idea.  Maybe it's been done already or perhaps not, but I've been studying how to build a compiler lately and I was wondering if it would be an interesting idea to pursue designing a language specifically designed to facilitate the various fields of machine learning.  And if it were the case that a real need would be fulfilled by designing said language, what would people want?  What would folks like emphasized?  There are tons of languages out there but would the field of machine learning truly benefit from a tailor made language, especially one made with direct input from those in the field of machine learning?  Heck, would it be a good idea to make it open to the pubic in terms of design?  Like I said I'm a little tipsy and about to pass out but I would love to see some feedback in terms of this idea.",30,0
2,2014-2-2,2014,2,2,16,1wsjx8,Bad Bayes: an example of why you need hold-out testing,https://www.reddit.com/r/MachineLearning/comments/1wsjx8/bad_bayes_an_example_of_why_you_need_holdout/,alexeyr,1391326231,,3,4
3,2014-2-2,2014,2,2,20,1wsuck,An interesting read for this sub: Could advanced machine learning put data scientists out of the business? [Quora],https://www.reddit.com/r/MachineLearning/comments/1wsuck/an_interesting_read_for_this_sub_could_advanced/,egrefen,1391340366,,12,8
4,2014-2-3,2014,2,3,2,1wte2l,Demo: Word2vec deep learning on GoogleNews,https://www.reddit.com/r/MachineLearning/comments/1wte2l/demo_word2vec_deep_learning_on_googlenews/,piskvorky,1391360471,,1,37
5,2014-2-3,2014,2,3,3,1wtnyj,"Big Debates, Successes, and Failures in Artificial Intelligence (UW course)",https://www.reddit.com/r/MachineLearning/comments/1wtnyj/big_debates_successes_and_failures_in_artificial/,urish,1391366716,,3,8
6,2014-2-3,2014,2,3,4,1wtsz1,What could I use to solve this problem?,https://www.reddit.com/r/MachineLearning/comments/1wtsz1/what_could_i_use_to_solve_this_problem/,lsumnler,1391369643,"I have access to survey data at work that contains a verbatim field (comments) by survey takers.  I would like to analyse these comments and pull the following information;
    1.  any positive or negative comments.
    2.  if any specific individual (employee) was named.
    3.  group comment by department.
Comment may not contain reference to all 3.

I can code in python, have a basic understanding of statistics, and I am motivated because otherwise I have to read through these and group them by hand on a weekly basis.",6,1
7,2014-2-3,2014,2,3,4,1wtuu5,Is Google Cornering the Market on Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/1wtuu5/is_google_cornering_the_market_on_deep_learning/,solarpoweredbiscuit,1391370744,,0,3
8,2014-2-3,2014,2,3,4,1wtuvz,Using Mathematica to implement ML Algorithms?,https://www.reddit.com/r/MachineLearning/comments/1wtuvz/using_mathematica_to_implement_ml_algorithms/,eaparnell,1391370778,Has anyone had success using Mathematica to implement common ML algorithms? And would you recommend it over an implementation in python?,8,1
9,2014-2-3,2014,2,3,7,1wuccq,"Beginner, willing to learn and learn how to learn.",https://www.reddit.com/r/MachineLearning/comments/1wuccq/beginner_willing_to_learn_and_learn_how_to_learn/,[deleted],1391381221,"OK, so here I am, a regular guy with alot of wasted time in the past. Not especially bright, with a modest working memory capacity and a lacking self control. Not that young either. 
Should that stop me from learning about machine/statistical learning? No fucking way, I don't give up that easily. 

So here's what I did... I grabbed a book called ""An Introduction to Statistical Learning"", written by Hastie et. al. It's definitely not math-heavy (actually there's almost no math), which I suppose is not that great, but I'm thinking it's not that bad for an intro book. 
Was that a good call? 

I do know a little bit of probability theory, statistics, matrix algebra, graph theory, and some basic optimization principles (I'm not familiar with proofs, just basic concepts; I understand what is  overfitting/underfitting, what's gradient descent, bias-variance trade-off, conditional probability, Dijkstra's algorithm etc.). 

I am able to code a thing or two in Python and I'm trying to learn R. Should I stick to that? 

Maybe I should put it this way - what is the shortest path from this point in time, to the one where I'm able to say that I consider myself to be data scientist/machine learning expert? What would be my optimal strategy (topics to learn about) and my optimal tactic (books, online courses...)? 
I don't want to learn it quickly, I want to learn it thoroughly. Just don't want to waste my time on things that won't be of any use. 

Dealing with data makes me happy so learning won't be a problem, but if you guys could teach me how to learn, I'd appreciate it alot.",11,11
10,2014-2-3,2014,2,3,9,1wunll,"In WEKA, is there a difference between the decision table classifier and a single decision tree (not a decision tree in random forest, but a stand alone decision tree)?",https://www.reddit.com/r/MachineLearning/comments/1wunll/in_weka_is_there_a_difference_between_the/,[deleted],1391389075,,3,0
11,2014-2-3,2014,2,3,11,1wuv51,Seeking recommendations for 3-5 example applications of various statistical learning/data mining/machine learning approaches,https://www.reddit.com/r/MachineLearning/comments/1wuv51/seeking_recommendations_for_35_example/,sleepicat,1391394141,"I've been studying various statistical learning approaches, but can't say I have a firm grasp on when a particular approach is appropriate or how to tell the story from beginning to end when applying a particular method.  So I'm trying to compile various sample case studies (complete with code in either R or Python) for various approaches. 

A few I'd like to understand better are logistic regression, linear discriminant analysis, decision trees, support vector machines, k-means clustering, naive Bayes, hierarchical clustering, text analysis, principal component analysis, etc. 

Can you recommend some good examples of how these methods are used?  They could be academic papers, blog articles, books, etc. ",5,2
12,2014-2-3,2014,2,3,19,1wvu56,How to build your own Facebook Sentiment Analysis Tool,https://www.reddit.com/r/MachineLearning/comments/1wvu56/how_to_build_your_own_facebook_sentiment_analysis/,datumbox,1391423558,,3,5
13,2014-2-3,2014,2,3,21,1wvzv4,etcML: Stanford scientists put free text-analysis tool on the web,https://www.reddit.com/r/MachineLearning/comments/1wvzv4/etcml_stanford_scientists_put_free_textanalysis/,egrefen,1391430835,,3,57
14,2014-2-4,2014,2,4,2,1wwl37,ML / statistics / Linear algebra recommandations,https://www.reddit.com/r/MachineLearning/comments/1wwl37/ml_statistics_linear_algebra_recommandations/,FtYoU,1391447345,"Hi Everyone !
I am desperately looking for the right textbook / course that will fit my needs.
I am looking for a good linear algebra text that will find application in statistics and/or ML.
Basically that's what I did :
Linear algebra :
- MIT courses ( not really deep, expose basic concepts without too much digging)
- Read Linear algebra done right ( Loved this book, cause it is theoretical and easily understandable )
- Read a large variety of Linear algebra book but all of them expose theorem, proof and move on

Machine learning :
- NG courses on coursera and standford ( unfortunately not really deep, for example at standford he write some linear algebra formula without proving them which is a fundamental mistake at this point, he suppose student are going to figure the formulas out by themselves. ) But anyway the content is not really deep, some concept fall out of nowhere. 
- Statistical learning. That's a good one but once again too many "" The proof goes beyond of this book "" So frustrating ...

Finally I took the Linear dynamical system course from standford. I really liked it, it introduced some major concept in a very friendly way, BUT STILL no really deep mathematical explanations.

I guess what I am looking for is formulas and concept used in statistics and machine learning which comes with the full Linear algebra theory.
'With all my readings I managed to get down the linear regression problem from bottom to top.

I was wondering what are your recommendations on that topic. I'm starting to get really tired of buying book that I stop to read half way, and my constant looking around.

I know books and courses depends higly on the reader profile, so this is my profile :
I absolutely love all mathematical concept as long as you introduce them with enough explanations, no "" the proof is beyond this book"" or "" I'm not going to show you a proof of this "".
I am more interested about linear algebra than calculus, as LA if understood well generalize a lot.
A good book in linear algebra that explain even the basic concept ( eigendecomposition, SVD, vector space subspace ) is good to take as long as theorem are not thrown away in your face.
My perfect book or course will be a statistical / ML book that will go into awfully long Linear algebra details.

I'm starting to take the standford course Convex optimization but i'm not sure about it. Since courses take a long time to process ( and in my case really long time cause I try to prove everything on paper ), I would like your input on it too.

Thank you all !",14,3
15,2014-2-4,2014,2,4,7,1wxlw9,Academic Torrents - research papers and datasets available for legal torrenting,https://www.reddit.com/r/MachineLearning/comments/1wxlw9/academic_torrents_research_papers_and_datasets/,jmelesky,1391468080,,4,68
16,2014-2-4,2014,2,4,13,1wyhap,How to easily train object detectors for faces and other semi-rigid objects in a few seconds,https://www.reddit.com/r/MachineLearning/comments/1wyhap/how_to_easily_train_object_detectors_for_faces/,davis685,1391486852,,4,19
17,2014-2-5,2014,2,5,0,1wzond,Stanford researchers create recommendation system that explicitly models user expertise,https://www.reddit.com/r/MachineLearning/comments/1wzond/stanford_researchers_create_recommendation_system/,rrenaud,1391527904,,4,34
18,2014-2-5,2014,2,5,1,1wzv2p,I need some help finding features (xpost from /r/computervision),https://www.reddit.com/r/MachineLearning/comments/1wzv2p/i_need_some_help_finding_features_xpost_from/,Rich6031-5,1391531849,"I posted this on /r/computervision, but thought I might get some help here also.

Here are samples of my images: [http://imgur.com/a/FDw3A#0](http://imgur.com/a/FDw3A#0)

All the images look like that. It is a high speed industrial packaging printer, and I've processed the raw images to get what you see above.

I now need to identify the character. Just turning the images into a binary array representing the pixels and passing the data to a Random Forrest classifier is getting me about 49% recognition right now.  As I understand it, it will be a better use of my time to do feature engineering instead of changing classification algorithms.

I've tried Haralick, Local Binary Patterns, Threshold Adjancency Statistics, and Zernike all without increased performance.  SURF and SIFT are really out due to patents (also I believe the main advantage of these are scaling and rotation invariance) which I don't realy need.
 
**EDIT:** [Confusion Matrix](http://imgur.com/FNqFaKQ)

",12,9
19,2014-2-5,2014,2,5,3,1x06q9,Sample size selection for record linking on 5 billion documents,https://www.reddit.com/r/MachineLearning/comments/1x06q9/sample_size_selection_for_record_linking_on_5/,iwantedthisusername,1391538483,"Hey all,
I'm currently working on a record linkage task involving unstructured strings against a structured database. We're using elastic search as a base tool and then a host of ML techniques to make the system perform better. I'm curious as to how large our sample would need to be to be representative of the 5 billion strings that need to be processed. 

My thoughts are that we could use scikit learn to turn the strings into tokens and see the distribution of those tokens. My thought is, as more strings are loaded in, the distribution of the more common tokens will stabilize. Eventually, new tokens that are found will amount to less than 1% of the tokens that have been found so far, and at that point we should be able to say that however many strings that have been loaded in is a good representative example of the variation in the data.

What do you guys think? Any other ideas?

http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction",0,6
20,2014-2-5,2014,2,5,12,1x1pij,Suggestions for interesting problem/project to apply Statistical Pattern Recognition (supervised learning) - Could be something you would find useful,https://www.reddit.com/r/MachineLearning/comments/1x1pij/suggestions_for_interesting_problemproject_to/,rasbt,1391569386,"I am really lacking a cool idea for project that can be solved by applying Statistical Pattern Recognition - supervised learning with class labels (no clustering). If you have any ideas I'd be happy if you could share them with me.
I am looking for something that can be done within ~ 2-4 months. Right now, I am passionately studying Statistical Pattern Recognition and I am looking for some application that really excites me. 
Ideally, something useful of course, because I'd be happy to share it with other people as an open source project on GitHub in the end.
I tried brain storming, but all I could came up with was old hat - something that has been solved before... Protein fold prediction, protein secondary structure prediction, handwriting recognition. Also ""Google"" hasn't provided me with anything useful...

I am looking forward to your suggestions!

About my background: I am working in the field of Biochemistry w. focus on Protein Science, so if you have any suggestions related to it (maybe something that you would find useful) this would be great. But also ideas from completely unrelated fields are very welcome!
",14,6
21,2014-2-5,2014,2,5,14,1x23pt,Interdisciplinary applications of machine learning,https://www.reddit.com/r/MachineLearning/comments/1x23pt/interdisciplinary_applications_of_machine_learning/,matrix2596,1391578285,I would like to know in which areas of other disciplines machine learning is used.  I heard ML is used in bio-informatics and nueroscience. Are there any other fields like these which you think can benefit from machine learning in the next 10 years. I am particularly interested to know how a undergrad with machine learning exposure can contribute in these other fields while doing Phd.,17,14
22,2014-2-5,2014,2,5,17,1x2hqq,Seeking for a Masters project idea in ML,https://www.reddit.com/r/MachineLearning/comments/1x2hqq/seeking_for_a_masters_project_idea_in_ml/,kau_mad,1391590697,"As my research project for the Masters degree I hope to do something on Machine Learning. I have done few courses on Machine Learning and have few experiences with Kaggle competitions.

I have an interest in Deep Learning approaches and went through myriads of open data sources available. But still I couldn't fix on a concrete research idea to work on for next 10 months.

Anyone have suggestions to follow?",8,4
23,2014-2-6,2014,2,6,0,1x3953,One-Step-Ahead Prediction of Pseudorandom Number Generator,https://www.reddit.com/r/MachineLearning/comments/1x3953/onestepahead_prediction_of_pseudorandom_number/,chiggy1881,1391615876,"Hi guys, I've heard of machine learning before (and have a base knowledge) but have no idea how to go about using it to tackle my problem.  Assume I have a bad pseudorandom number generator that has an underlying trend.  Given n-1 previous observations, what methods would I use to predict the nth observation?  Further, how do I assess whether the prediction was correct and change my model for the next observation?

What tools do I use?  How do I asses the resulting model and improve upon it?  In the end I actually don't need to predict the exact value of the subsequent observation, but predict it within a threshold, i.e., ""will the next value be &gt;50?  &gt;90?  Does this turn it into an easier classification problem?

Thanks!",3,2
24,2014-2-6,2014,2,6,3,1x3nfl,DeepDive: analyze your data in depth,https://www.reddit.com/r/MachineLearning/comments/1x3nfl/deepdive_analyze_your_data_in_depth/,petrux,1391623706,,1,21
25,2014-2-6,2014,2,6,5,1x45jg,Python script: Pull Tweets from discrete time period?,https://www.reddit.com/r/MachineLearning/comments/1x45jg/python_script_pull_tweets_from_discrete_time/,Li54,1391633312,"Has anyone written python code to pull all Tweets from a discrete time period, of, say several hours // know where to find this? ",3,2
26,2014-2-6,2014,2,6,11,1x53x6,Machine learning with variable features,https://www.reddit.com/r/MachineLearning/comments/1x53x6/machine_learning_with_variable_features/,jeff3yan,1391652492,"I'm relatively new to the machine learning field and I've been experimenting with sklearn under Python. What I'm wondering, is there any way to create an incrementally trained model that can handle data sets with highly variable features?

This is mainly for analyzing web logs, with features that vary between numerical, text and categorical.

From what I've seen so far, most of the models are quite sensitive to feature drift over time and require inputs consisting of fixed, predictably sized vectors.",9,2
27,2014-2-6,2014,2,6,21,1x6aoj,Research question in validation type study,https://www.reddit.com/r/MachineLearning/comments/1x6aoj/research_question_in_validation_type_study/,Rym_,1391689645,"Hey there Reddit,

I'm working om my master thesis which as of yet is taking way too much time. My study centers around a model which uses a relatively unknown method to predict mortality of ICU patients. The model has already been created by someone else (or actually, a bunch of different people over different studies) and I'm going to take that model, a. test if the results of the  previous researcher hold up in a different dataset, b. change some aspects of the model in terms of how it deals with the dataset (splitting of obersvations in training / testing and dealing with the point-in-time aspect of the observations) and c. combine a yet-to-be-collected dataset with 4 other datasets from different hospitals around the world in order to create a more robust model.

I'm having GREAT difficulty however translating the work which I want to / am going to do to proper research questions. As a whole the writing of my lit study / proposal / thesis is taking ages and I i have a mentor who is quite busy.

What are research questions in validation studies? or is just ""what is the external validity of the model"" enough? also how do i differentiate between my research questions when it comes to external validity of the model as-is (Trained/tested with a single dataset) and what I want to do (train/test a model with multiple datasets) or isn't there a difference?

Hope you can help!

tl;dr: Going to validate and improve an existing predictive model and cannot seem to find proper research questions.",2,3
28,2014-2-6,2014,2,6,23,1x6kup,Multi-view Learning with Categorical and Continuous Variables?,https://www.reddit.com/r/MachineLearning/comments/1x6kup/multiview_learning_with_categorical_and/,Omega037,1391698774,"I am working on building a robust binary classifier from a data set of around 40,000 samples and for each sample, there are two feature sets.  

One feature vector is a set of around 15 related continuous variables which every sample has, and the other feature vector is a set of around 70 categorical variables which the sample may or may not have an entry for at all.

My current approach is to use a combination of domain knowledge and associative rule learning on the categorical variables to form a list of penalize and reward rules.  These rules are used either as a preprocess (classify around 10% of the sample that meet strong rules) or a post process (weight the probability score output by a Random Forest or SVM model generated on the continuous data).

Does anyone have some other approaches I might try?",1,7
29,2014-2-7,2014,2,7,5,1x7j8w,machine learning algorithm that does the same thing as the buckingham pi theorem,https://www.reddit.com/r/MachineLearning/comments/1x7j8w/machine_learning_algorithm_that_does_the_same/,[deleted],1391718676,"I have sets of data , that I have to establish linear trends between.Dimensional analysis was recommended as one way of going about it.I was wondering if there was a better algorithmic way to go about it?

--------------------------------------------------------------------------------------------------------------------
prior :edit -&gt; I'm not sure if this question is logically sound , but here goes ...
I have  5 sets of data , and I am supposed to show some sort of trend between one the five and the 'force data'(6th set of data) , and was asked to dimensional analysis in form of the buckingham pi theroem.I was wondering f there was a machine learning algorithm that could accomplish the same for me.",9,0
30,2014-2-7,2014,2,7,10,1x8gvc,Causal Entropic Forces [PDF],https://www.reddit.com/r/MachineLearning/comments/1x8gvc/causal_entropic_forces_pdf/,galapag0,1391737844,,3,18
31,2014-2-7,2014,2,7,10,1x8hk1,Question about computing Bayes Error - with or without loss function?,https://www.reddit.com/r/MachineLearning/comments/1x8hk1/question_about_computing_bayes_error_with_or/,rasbt,1391738281,"I am new to Bayesian Decision Theory and don't understand the following concept:

So from what I understood, the Bayes error is used to report the performance of a Bayes classifier in terms of the probability of making and error. From the conditional error probabilities (I uploaded the equations as images in hope they are helpful to explain what I am referring to)



![conditional error](http://sebastianraschka.com/_my_resources/images/equations/cond_error.png)


we can obtain the total probability of making an error (the probability to mis-classify).


![error](http://sebastianraschka.com/_my_resources/images/equations/error.png)


Now, if my Bayes classifier was designed to minimize the overall risk, I have a loss function that gives penalties to certain decisions. 

![conditional risk]
(http://sebastianraschka.com/_my_resources/images/equations/cond_risk.png)
![overall risk](http://sebastianraschka.com/_my_resources/images/equations/overall_risk.png)

So, if my classifier includes such a loss function when I optimize my classifier for minimum overall risk, shouldn't be the Bayes error also include the loss function term?

Hope you can help me here, because I think I am missing something here ...



EDIT:

I'll try to express my problem using an 2D-classification problem:

Let's assume I have two pdfs (e.g., p(x|c1) and p(x|c2) ) with slight overlap. And mis-classifying a pattern as c2 where it truly belongs to c1 is more costly than vice-versa.

In this case I would assign a higher loss to ""classify pattern x as c1 when it is truly c2"" than ""classify pattern x as c2 when it is truly c1"" in order to calculate and minimize the overall risk.

I would therefore increase the probability to classify a pattern x as c2 over c1 due to the minimum risk optimization. Isn't this something I have to also include in p(error)?",7,2
32,2014-2-7,2014,2,7,13,1x8yjp,"Hi /r/MachineLearning, what do you use?",https://www.reddit.com/r/MachineLearning/comments/1x8yjp/hi_rmachinelearning_what_do_you_use/,iyer_in_exile,1391749047,"What language/framework do you use? I have been using Python as my primary language so far, but was wondering if I ought to make a switch to something else.

What do you use, and why? If it helps, I've been programming for awhile, but am fairly new to ML.",29,12
33,2014-2-7,2014,2,7,17,1x9dc8,The Daily Random Forest Prayer,https://www.reddit.com/r/MachineLearning/comments/1x9dc8/the_daily_random_forest_prayer/,[deleted],1391763013,,0,1
34,2014-2-7,2014,2,7,23,1x9w8f,Brothers use data mining to predict the final Olympic medal counts at Sochi,https://www.reddit.com/r/MachineLearning/comments/1x9w8f/brothers_use_data_mining_to_predict_the_final/,[deleted],1391784796,,11,19
35,2014-2-8,2014,2,8,5,1xavvt,Free Sports Stats API's Anyone?,https://www.reddit.com/r/MachineLearning/comments/1xavvt/free_sports_stats_apis_anyone/,duggym122,1391806598,"Does anyone know of any free/public API's out there that return sports standings/game stats for the NHL, or NFL (NBA, MLS, and college football/basketball accepted as well)? I'm totally comfortable applying for a developer key if necessary.

I am writing a program that takes in game stats and predicts several betting lines. As-is, it only works for hockey and the data needs to be manually entered, but I am working on updating my code to include different profile builders for different sports.

I want to keep going with hockey to prove my next phase since my code works pretty well (80% accuracy on two of the 9 betting lines I predict, average of 75% if you don't include my win/loss predictor which I never got above 61%). ",12,8
36,2014-2-8,2014,2,8,12,1xbw11,Parallels between machine learning / statistical learning theory and traditional learning theories?,https://www.reddit.com/r/MachineLearning/comments/1xbw11/parallels_between_machine_learning_statistical/,[deleted],1391830758,"In reading through machine learning / statistical learning theory literature the emphasis seems to be on minimal development of the philosophical justification and maximal focus on the mathematical machinery. Similarly in traditional learning (Behaviorism, Cognitivism, Constructivism, Humanism) literature there's is plenty of focus on the philosophical justification and case studies.

Is there any well know literature drawing parallels between these two camps or for example, extending traditional learning directly to machine learning/statistical learning theory?",5,8
37,2014-2-8,2014,2,8,16,1xccbq,what does r/machinelearning make of topological data analysis?,https://www.reddit.com/r/MachineLearning/comments/1xccbq/what_does_rmachinelearning_make_of_topological/,delverine,1391845150,I ask as i dont see much commentary here...,15,13
38,2014-2-8,2014,2,8,22,1xcscm,care to share the folder-structure you are using for organization of different projects?,https://www.reddit.com/r/MachineLearning/comments/1xcscm/care_to_share_the_folderstructure_you_are_using/,[deleted],1391867516,"Basically I have a problem which is more related to the internal structure of different ML/stats projects rather than ML per se.

I have quite a few different projects. which are always under ~/Projects/project1/ ~/Projects/project2/ etc.

For consistency I like all of the project dirs having the same structure, like ""inputs"", ""outputs"", ""meta"", ""src"". Or something very similar.

But here is the problem - ideally I would like outputs being produced by doing something to a subset of inputs. However many times I need to save intermediate results to outputs (since they take a long time to compute) and then use those. So the flow starts to go from outputs to outputs. (which irks me a little, because every time I change something it becomes harder to track which parts need to be redone.

In addition I like doing some kind of presentation/graphics/description of the results each time I finish some part. And I am having trouble deciding where to put those. One idea is associate every output folder with some kind of result - which makes the individual folders of outputs more complicated and unique. Another possibility is having a separate folder like ""results"". But computing something in output and then having to do something in a different folder for ""presentation"" also bothers me a little. And what's worse is that ""results"" folder get's cluttered really fast in practice, if the project is running for a longer period of time.

So this is my rant and some minor issues which for some reason effect the productivity of what I do. It seems important yet I can find no literature or any suggestions to formally address these things.

Can someone with a similar situation share how they are organizing their work and what works/does not work in practice?

Or better yet - suggest some literature (if there is any) addressing this?

**EDIT:** Seems like this thread quickly got nowhere, I guess people are not into these kinds of things. I will just quickly share some of the resources that I found useful for anyone who might stumble over this post in the future:

http://arkitus.com/patterns-for-research-in-machine-learning/

https://news.ycombinator.com/item?id=4384317

http://stats.stackexchange.com/questions/2910/how-to-efficiently-manage-a-statistical-analysis-project

http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1000424

http://www.theexclusive.org/2012/08/principles-of-research-code.html",4,0
39,2014-2-9,2014,2,9,1,1xd1f6,"Free Software for Text Analysis, Text Mining, Text Analytics",https://www.reddit.com/r/MachineLearning/comments/1xd1f6/free_software_for_text_analysis_text_mining_text/,johnt1234,1391875885,,0,1
40,2014-2-9,2014,2,9,1,1xd3p0,BigML is Machine Learning for everyone,https://www.reddit.com/r/MachineLearning/comments/1xd3p0/bigml_is_machine_learning_for_everyone/,mhausenblas,1391877602,,0,0
41,2014-2-9,2014,2,9,1,1xd41b,Alternatives to XM2VTS dataset for Audio Video recognition,https://www.reddit.com/r/MachineLearning/comments/1xd41b/alternatives_to_xm2vts_dataset_for_audio_video/,[deleted],1391877846,"Hi guyz,
I am trying to implement the paper http://www.ncbi.nlm.nih.gov/pubmed/23757540 to learn more about machine learning but it uses XM2VTS dataset for speaker-independent audio-visual speech recognition. which is not free and as currently I neither belong to academia nor have much funds I am stuck .. Can someone please help me find some open source data set that I can use...",0,8
42,2014-2-9,2014,2,9,7,1xdxbu,Learning Ordered Representations with Nested Dropout,https://www.reddit.com/r/MachineLearning/comments/1xdxbu/learning_ordered_representations_with_nested/,rrenaud,1391897382,,1,2
43,2014-2-9,2014,2,9,9,1xec6e,Good entry points to reinforcement learning literature?,https://www.reddit.com/r/MachineLearning/comments/1xec6e/good_entry_points_to_reinforcement_learning/,rcwll,1391907496,"I realize that there is a reinforcement learning subreddit, but it looks pretty dead, so I figured I'd try here first. 

I haven't really touched reinforcement learning since an intro class in grad school, and am trying to get caught up to speed on what's current in the field these days.  I've read through Powell's ""Approximate Dynamic Programming"" and re-read the Sutton and Barto book, so I feel like I've got a decent handle on the broad strokes, but they're also both high-level and semi-introductory books, are both a few years old, and are widely-cited enough that looking up papers that reference them isn't really informative.  

So given that, can anyone suggest the major groups/authors/conferences to pay attention to, point me to what the major open problems are, and suggest any specific 'must-read' papers from the last few years?  I'm specifically interested in nonparametric approaches and POMDPs, if that helps narrow it down a bit.  

Thanks in advance!",6,13
44,2014-2-9,2014,2,9,10,1xecoj,Benchmarking EC2 for Deep Learning in Python,https://www.reddit.com/r/MachineLearning/comments/1xecoj/benchmarking_ec2_for_deep_learning_in_python/,ZF2uPxnUfdHdxf2U,1391907823,,3,16
45,2014-2-9,2014,2,9,12,1xepfv,What is a good criterion in selecting Neural Network models?,https://www.reddit.com/r/MachineLearning/comments/1xepfv/what_is_a_good_criterion_in_selecting_neural/,bushcat89,1391917269,"I'm currently doing a project on selecting the best learning algorithm to predict automobile prices from data on classified advertisements.I tried out couple of algorithms from scikit-learn and got some good R^2 values.Then I tried neural networks from pybrain and neurolab and I wasn't able to get the R^2 value above 0,even got negative values most of the time (I calculated the R^2 using the metrics module in scikit).So got a couple of questions,hope you guys would be able to help

*is R^2 a good criterion when trying to find the prediction accuracy of neural networks or non-linear models?

*What would be a good method/process to compare different learning algorithms and find the model with the best predictive ability?

",1,1
46,2014-2-9,2014,2,9,19,1xfdbs,The Computational Complexity of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1xfdbs/the_computational_complexity_of_machine_learning/,[deleted],1391942787,,2,18
47,2014-2-10,2014,2,10,4,1xgc8k,Learning with data of different reliability,https://www.reddit.com/r/MachineLearning/comments/1xgc8k/learning_with_data_of_different_reliability/,noel330,1391974345,"I have a binary classification problem where I have data of different degrees of reliability. I have one data set, on the order of 500 samples, which I believe to be perfectly reliable. I have another data set, on the order of 5,000 samples which I would estimate to be 95% reliable, with the 5% error not distributed uniformly (I believe it will be biased towards some types of errors, but I do not know which types these are). Finally I have an unlabeled set of data on the order of 50,000 samples. I am currently using an SVM on the smallest data set in order to classify the data.

Are there any good techniques for dealing with this? I have looked at semi-supervised learning for the unlabeled data set, but the decision boundary lies in a high density region (Two trained humans asked to label samples might not place the boundary in the exact same place, but would be able to give a nearly identical ranking of samples, from most like Class 0 to least like Class 0). The simplest solution would be to weight the perfect data more and use the larger set as well, choosing the weights via cross validation, but I'm not sure if there's a better solution.",1,3
48,2014-2-10,2014,2,10,10,1xha3y,How does gradient descent know which values to pick next?,https://www.reddit.com/r/MachineLearning/comments/1xha3y/how_does_gradient_descent_know_which_values_to/,mangaprincess,1391994968,"Hi all. I'm a beginner, and was confused on how Gradient Descent (SGD) knows what parameter values to pick on the next iteration if convergence has not been achieved. 

I'm aware of the update rule (the formula with the partial derivative and the learning rate), but am still confused on how it chooses the parameter value to plug into the formula.

My guess was that the cost function is plotted, and it picks values along the curve, but am unsure about this. Thanks!

**edit:** thanks everyone for your answers!",12,6
49,2014-2-10,2014,2,10,12,1xhlmq,Hyper-parameter estimation on confidence bounded losses?,https://www.reddit.com/r/MachineLearning/comments/1xhlmq/hyperparameter_estimation_on_confidence_bounded/,Derpscientist,1392002352,"I'm searching hyperparameters using TPE methods on a small dataset. The loss function for the hyperparameter search is the mean of my accuracy metric over the K-Folded training set.

The standard deviation of the accuracy metric for a given parameter is high, no matter how I cross-validate or how much I slide the percentage of the training data used in fitting the algorithm.

I'm okay with the noise, there is bootstrap-reproducible accuracy for some hyperparameter combinations. In fact the standard deviation is relatively stable as well.

My natural inclination is to define loss

    loss=mean - norm.ppf(.99)*std

But then I'm reminded that the current generation of contextual bandits work, in a very similar setting by chasing the **upper** confidence bound of some model parameterized by ""experts"" or function approximation.

Should I ignore the standard deviation altogether?",4,3
50,2014-2-10,2014,2,10,15,1xhzki,Harvesting and Analyzing Tweets | School of Data,https://www.reddit.com/r/MachineLearning/comments/1xhzki/harvesting_and_analyzing_tweets_school_of_data/,imsome1,1392012256,,2,7
51,2014-2-10,2014,2,10,16,1xi545,Natural language processing in Python,https://www.reddit.com/r/MachineLearning/comments/1xi545/natural_language_processing_in_python/,shogun333,1392017349,"I want to be able to take a whole bunch of text, say, individual blog posts, and pick out the few keywords that describe that post. Think something like automatic tagging.

I am quite familiar with Python. Should I use scikit learn or the Natural Language Processing toolkit (NLTK)?

Also, any suggestions on what to read? The only thing I can think of at this point is just trying to follow some of the tutorials/reference documentation and see how I go.",4,3
52,2014-2-10,2014,2,10,22,1ximqf,"Paris Machine Learning Meetup #8: Finding a needle in a Haystack, Beyond SGD, Analyser Wikipedia, Kolibree, Winning Kaggle ""Dogs vs Cats""",https://www.reddit.com/r/MachineLearning/comments/1ximqf/paris_machine_learning_meetup_8_finding_a_needle/,compsens,1392039056,,0,2
53,2014-2-10,2014,2,10,22,1xinnv,Good algorithms for network learning from categorical time series data?,https://www.reddit.com/r/MachineLearning/comments/1xinnv/good_algorithms_for_network_learning_from/,[deleted],1392039924,"Suppose a number of persons give Likert responses to [;p;] items on a questionnaire, repeating on a number of time points. I want to show what item-response [;j;] at time [;t;] best explains a change in item-response [;k;] at time [;t+1;]. 

One solution I've come across involves fitting a large number of vector-auto-regressive models to the data, pick the model that fits the best/does not violate model assumptions and then calculate which item-response [Granger-causes](http://en.wikipedia.org/wiki/Granger_causality) another item-response.

I suspect this is not the best way to do it, one reason being the use of [;p;]-values (even though Bonferroni corrections were applied). Does anyone have an idea on how to tackle this problme?",2,3
54,2014-2-11,2014,2,11,3,1xjcoa,Naive Bayes classification for large data sets,https://www.reddit.com/r/MachineLearning/comments/1xjcoa/naive_bayes_classification_for_large_data_sets/,lumengxi,1392056659,,0,2
55,2014-2-11,2014,2,11,3,1xjcxc,ELI5-What is Deep learning?,https://www.reddit.com/r/MachineLearning/comments/1xjcxc/eli5what_is_deep_learning/,chchan,1392056806,"My understanding so far for this is just as set of Neural network algorithms. What makes them different than something like gradient decent or Support vector machines?  (other than time it takes or memory usage)

Are there any algorithms for deep learning available for python?",28,45
56,2014-2-11,2014,2,11,3,1xjf1g,"Free Software for Text Analysis, NLP, Clutering, etc., on Text Corpora?",https://www.reddit.com/r/MachineLearning/comments/1xjf1g/free_software_for_text_analysis_nlp_clutering_etc/,pyongjangjim,1392058036,"Hello r/machinelearning,

I'm putting together a report on some company documents, including a couple of text corpora that I'd like to do some statistical / ML analyses on.

Can you guys recommend software to help on this task? Thanks!",2,0
57,2014-2-11,2014,2,11,4,1xjh94,Shout out from Bill Gates,https://www.reddit.com/r/MachineLearning/comments/1xjh94/shout_out_from_bill_gates/,dhammack,1392059338,,13,8
58,2014-2-11,2014,2,11,6,1xjtxm,Predicting Olympic medal counts per country,https://www.reddit.com/r/MachineLearning/comments/1xjtxm/predicting_olympic_medal_counts_per_country/,cavedave,1392066400,,1,8
59,2014-2-11,2014,2,11,7,1xk04o,Could someone help me understand the difference between a linear classifier and a linear threshold function?,https://www.reddit.com/r/MachineLearning/comments/1xk04o/could_someone_help_me_understand_the_difference/,dorik,1392069625,,0,1
60,2014-2-11,2014,2,11,12,1xkuye,Choosing Grad School?,https://www.reddit.com/r/MachineLearning/comments/1xkuye/choosing_grad_school/,Shopler,1392087615,"When deciding on a Grad school is it better to consider the overall ranking of an institution or on the ranking of the faculty itself? 

I ask this because I live down under (Australia) and some universities rank fairly well in terms of Computer Science faculties, and similar areas, (namely ANU and Melbourne) but they don't do as well in overall rankings in comparison to some US options (which could be costly to do through international programs).

Thanks.

Note: For masters.",6,6
61,2014-2-11,2014,2,11,13,1xl66c,Looking for small perturbations in time series data,https://www.reddit.com/r/MachineLearning/comments/1xl66c/looking_for_small_perturbations_in_time_series/,sasaram,1392094637,"Hi, I am looking for ideas from the ML community. I am trying to discover small perturbations conditioned on one feature space of a multi dimensional time series data .

Perturbations are significant deviations from the normal behavior in the multidimensional Random variables time series. It must exclude noise which is periodic.",3,1
62,2014-2-11,2014,2,11,21,1xlwj6,The Netflix Tech Blog: Distributed Neural Networks with GPUs in the AWS Cloud,https://www.reddit.com/r/MachineLearning/comments/1xlwj6/the_netflix_tech_blog_distributed_neural_networks/,movie_suggestor,1392121971,,19,65
63,2014-2-11,2014,2,11,22,1xlz9r,Is there an exhaustive list of machine learning conferences over the next year?,https://www.reddit.com/r/MachineLearning/comments/1xlz9r/is_there_an_exhaustive_list_of_machine_learning/,Knux-,1392124802,"As part of a scholarship I have for my undergraduate studies, I get a travel stipend, and I would like to use it to go to a few conferences. I am a mathematics undergrad who is slowly but surely learning machine learning with hopes of going to grad school to study ML further in computer science. 

Anyway, I've searched around, and while I have been able to find a few conferences, I feel like there is probably a large list somewhere, which would make thing easier. I only have until next spring to ""use"" my travel stipend. 

Also, if you have similar information for any AI or game AI-related conferences, I will take that too. 

As far as specializations go, I am basically interested in anything except for medical/bioinformatics applications. NLP and deep learning are my ""main interests"" right now (not that I am anything but a novice in either). ",8,1
64,2014-2-11,2014,2,11,23,1xm3fj,The Epic Story of Maximum Likelihood,https://www.reddit.com/r/MachineLearning/comments/1xm3fj/the_epic_story_of_maximum_likelihood/,datumbox,1392128334,,0,2
65,2014-2-12,2014,2,12,0,1xm78n,[Request] Causal Entropic Forces - code!,https://www.reddit.com/r/MachineLearning/comments/1xm78n/request_causal_entropic_forces_code/,Jakeytk,1392131014,"Hi all,

I've seen recently how Prof. Wissner-Gross' paper on Causal Entropic Forces: http://www.alexwg.org/publications/PhysRevLett_110-168702.pdf has taken off, suggesting a way in which a system may become intelligent.

Regardless of what people think of this, I wondered, has anyone got a working code for any of the examples in his paper?

Naturally, he hasn't been giving away example code (bad scholarship!) but I'd really like to play about with it. If you have Matlab... even better :P

Many thanks, - J",8,1
66,2014-2-12,2014,2,12,0,1xmaal,Using 3rd party data with Pylearn2 [OC],https://www.reddit.com/r/MachineLearning/comments/1xmaal/using_3rd_party_data_with_pylearn2_oc/,ian_goodfellow,1392133061,,10,12
67,2014-2-12,2014,2,12,2,1xmjt9,Using ReliefF to predict the class of the next number returned by PRNG.,https://www.reddit.com/r/MachineLearning/comments/1xmjt9/using_relieff_to_predict_the_class_of_the_next/,chiggy1881,1392138724,"I'd like to duplicate the results achieved in this paper http://lkm.fri.uni-lj.si/rmarko/papers/Savicky08-AAI.pdf (page 9) using ReliefF to predict the class of the next number given to me by a PRNG.  The problem is I'm completely new to R.  I see that in the Core package there's a function that will ""evaluate attributes"" using ReliefF, but after attributes have been evaluated, how do I use this to predict the next class?  Further, how do I incorporate what I've received into the model so that I can predict the n+2 class?

Working code would be greatly appreciated.",0,0
68,2014-2-12,2014,2,12,6,1xnens,"Machine Learning on Coursera starting March 3, 2014. Anyone want to join with me?",https://www.reddit.com/r/MachineLearning/comments/1xnens/machine_learning_on_coursera_starting_march_3/,Valgor,1392155588,"I took an AI course in college, but I'm pretty noobish about machine learning.  Looking for anyone wanting to join with me, so we could learn together.  Maybe make a subreddit just for us?  Link:  https://www.coursera.org/course/ml

Edit: seems be enough interest, so I made /r/MLCoursera.  Please join!",13,12
69,2014-2-12,2014,2,12,7,1xnifr,Why were particular clusters formed?,https://www.reddit.com/r/MachineLearning/comments/1xnifr/why_were_particular_clusters_formed/,jeff3yan,1392157688,"I'm using scikit in Python for some high-dimensional clustering. Clustering algorithms such as KMeans or DBSCAN spit out a bunch of clusters and I can intuitively see why they were grouped together. 

However, is there any way to formally determine why the algorithm selected particular clusters i.e. highlight the features that were the most common.",3,0
70,2014-2-12,2014,2,12,9,1xnwb6,How to track multiple objects across time using only proximity matrices?,https://www.reddit.com/r/MachineLearning/comments/1xnwb6/how_to_track_multiple_objects_across_time_using/,NotAHomeworkQuestion,1392165718,"So I've got ~1000 objects where at different time points I'm able to generate a proximity matrix between them. I don't have access to the actual locations of these objects, just the proximity between each pair. Also, this proximity isn't Euclidean, it's based on a heuristic so that it is in [0,1] (1 being right on top of each other, 0 being ""extremely far away""). Since these measurements are very noisy, I'd like to smooth these proximity estimates across time (again, I have one proximity matrix per time point). I've done some googling around but haven't found anything that really makes use of proximity matrices rather than the actual positions. Would anyone be so kind as to make recommendations or point me in the direction of resources regarding methods that do this? Thanks!",1,3
71,2014-2-12,2014,2,12,9,1xnwis,Is there a good video tutorial on recurrent neural networks ?,https://www.reddit.com/r/MachineLearning/comments/1xnwis/is_there_a_good_video_tutorial_on_recurrent/,sasaram,1392165853,"I have been looking around here and there for a good video lecture on recurrent neural nets (google tech talk has one but not explanatory only introductory). Cannot find one, even though lecture slides are available. A video lecture or book chapter will be great. Anybody know ?",2,9
72,2014-2-12,2014,2,12,11,1xo7rq,Need advice for job interview,https://www.reddit.com/r/MachineLearning/comments/1xo7rq/need_advice_for_job_interview/,ambassador_pineapple,1392172408,"Hello folks!  I have an interview coming up for a data scientist position.  I graduated with a masters in mathematics in December and this job is my dream job.  This company is one of the biggest in the world of financial data.

In order to nail this final interview, I want do a simple project or two, do a report and take it with me to show the interviewers my initiative.  I want to find some simple data sets to do basic supervised learning stuff (clean up, regression, cross validation, prediction, etc.).  Does anyone have any tips they can share with me?

Thanks!",7,1
73,2014-2-12,2014,2,12,13,1xol0f,Deep learning might make your Netflix recommendations a lot better,https://www.reddit.com/r/MachineLearning/comments/1xol0f/deep_learning_might_make_your_netflix/,rajkumarselvaraj,1392180528,,0,0
74,2014-2-12,2014,2,12,19,1xp5n2,Positive Displacement Pump,https://www.reddit.com/r/MachineLearning/comments/1xp5n2/positive_displacement_pump/,jessicperson,1392200296,,0,1
75,2014-2-12,2014,2,12,22,1xpdse,What kind of features can you extract from a single time series to use it with neural networks?,https://www.reddit.com/r/MachineLearning/comments/1xpdse/what_kind_of_features_can_you_extract_from_a/,zanzilove,1392210329,"I'm new to ML, and I'm trying to get my head around feature extraction... So if I have a time series of &gt;1000 numbers, what kind of features I can extract from it to help improve a neural network prediction?",6,3
76,2014-2-13,2014,2,13,0,1xpr5j,State of the Art repository for various datasets,https://www.reddit.com/r/MachineLearning/comments/1xpr5j/state_of_the_art_repository_for_various_datasets/,exellentpossum,1392220532,,4,55
77,2014-2-13,2014,2,13,8,1xr3a6,TED | An equation for intelligence by Alex Wissner-Gross,https://www.reddit.com/r/MachineLearning/comments/1xr3a6/ted_an_equation_for_intelligence_by_alex/,[deleted],1392247405,,0,0
78,2014-2-13,2014,2,13,8,1xr4pb,Methods to determine parameters for Support Vector Machines with RBF kernel other than grid search and cross validation.,https://www.reddit.com/r/MachineLearning/comments/1xr4pb/methods_to_determine_parameters_for_support/,chchan,1392248234,"I am using python scikit learn to work with SVM with an RBF kernel.

Is there a good way to solve for the Complexity cost (C value) and gamma when using an RBF kernel other than grid search then looking for the best score or cross validation?
The reason why I am asking is because grid search seems kind of brute force and memory intensive.

Also when you have a large data sets you should scale everything (either between 0 and 1 or 1 and -1) I guess this is to prevent skewing of results. Is there a preference on which scale 0,1 or 1,-1? (I use 0,1 but I am just wondering.)",9,3
79,2014-2-13,2014,2,13,9,1xr7r2,Inside the wacky world of weird data: What's getting crunched,https://www.reddit.com/r/MachineLearning/comments/1xr7r2/inside_the_wacky_world_of_weird_data_whats/,duckandcover,1392250067,,0,1
80,2014-2-13,2014,2,13,9,1xranu,Using copyrighted images to train and algorithm?,https://www.reddit.com/r/MachineLearning/comments/1xranu/using_copyrighted_images_to_train_and_algorithm/,[deleted],1392251812,"Is it legal to use copyrighted images to train a learning algorithm? Assuming you don't publicly display the photos. 

If it isn't legal, then how often does this issue actually come up in practice? I mean how would someone know if you used copyrighted photos for training?

Thanks /r/ml!

edit: should be 'an algorithm' in the title",6,5
81,2014-2-13,2014,2,13,12,1xroy7,Undergraduate research ideas,https://www.reddit.com/r/MachineLearning/comments/1xroy7/undergraduate_research_ideas/,[deleted],1392260459,"Hello, I am a second-year math student, and I have the opportunity to do research in ML with a professor at my school.

He told me that I could think of a problem I'd like to research and we would work on it together. This is the first research experience I've ever had, and I don't know what sort of project would suit my background. 

As for my background, I have taken Linear Algebra, Calc 3, and studied probability and statistics on my own. I can also program (decently) in Python and C.

Anyway, I just wanted to know if anyone has some suggestions for some research ideas that would be accessible for me, because a lot of the work being done seems too advanced. Thanks in advance for your help.",0,1
82,2014-2-13,2014,2,13,13,1xs09a,Predicting time data.,https://www.reddit.com/r/MachineLearning/comments/1xs09a/predicting_time_data/,feeling_luckier,1392267570,"total mlnoob here. Trying to get a grasp on neural networks using a paper that predicted horse race times.

My - limited - understanding is that the historical time based outcomes are used to train the nn must be mapped to a sigmoid function. The nn returns a value, for given inputs, that must be turned back into 'time' through this mapping.

Can someone here give me some pointers on working with time (a continuous value) as the output? 

*to further expand what I've read, the 'results' values are mapped to a normal function with mean 0 &amp; sd of 1. One small concern around this is a the data bunching around faster times, with a long right tail with slower values, as one would expect with any race data and similar to what income data looks like.",0,0
83,2014-2-13,2014,2,13,22,1xsu14,Bayesian Model Averaging with a finite set of models coming from different spaces (classes),https://www.reddit.com/r/MachineLearning/comments/1xsu14/bayesian_model_averaging_with_a_finite_set_of/,alejape,1392298793,"I have L Latent Dirichlet allocation models (different #topics), K mixture of dirichlet models (different #centers) and N counting grid models (different Grid/Window size).
K,L and N is finite (= ~10).


I must perform classification on some BOW data. 

Intuition says that different classes are better modeled by different models and I wanted to figure out a way to select/average the model for each class.

Does anyone know if it is possible? Anyone attempted it? Suggestions?",0,2
84,2014-2-13,2014,2,13,22,1xsu5h,Presentations made at Paris Machine Learning Meetup #8,https://www.reddit.com/r/MachineLearning/comments/1xsu5h/presentations_made_at_paris_machine_learning/,compsens,1392298916,,0,9
85,2014-2-13,2014,2,13,23,1xsx9n,Data sets to 'practise' with while studying machine learning?,https://www.reddit.com/r/MachineLearning/comments/1xsx9n/data_sets_to_practise_with_while_studying_machine/,[deleted],1392301493,"I took a machine learning course this year which covered a lot of different algorithms and techniques, but only involved coursework to implement one or two of them. I think it would be helpful to implement some more, and to a greater variety of data sets, to reinforce my understanding of the algorithms and the differences between them.

Is anyone aware of any good data sets freely available online that would be good for this kind of thing?",12,13
86,2014-2-14,2014,2,14,1,1xtb25,Generating a final logistic regression model from bagging,https://www.reddit.com/r/MachineLearning/comments/1xtb25/generating_a_final_logistic_regression_model_from/,blahface99,1392310117,"So I'm using bagging to generate N bootstrapped samples. Then training N logistic regression classifiers. Each N classifier outputs some probability of being in a binary class. I average their predictions to get a final prediction.

My question is if taking the average of the N sets of regression coefficients and using them in a new logistic classifier to output a final probability is the same as averaging the  output of the N classifiers.",2,0
87,2014-2-14,2014,2,14,4,1xtrv6,Constrained optimization in Pylearn2 [OC],https://www.reddit.com/r/MachineLearning/comments/1xtrv6/constrained_optimization_in_pylearn2_oc/,ian_goodfellow,1392319368,,7,13
88,2014-2-14,2014,2,14,5,1xtzd1,Graph theory - is it of any use in machine learning?,https://www.reddit.com/r/MachineLearning/comments/1xtzd1/graph_theory_is_it_of_any_use_in_machine_learning/,nomotus,1392323409,"I am aware of probabilistic graphical models, but somehow I don't see alot of graph theory in that area of ML... don't know if there is any other useful application of graph theory? 
Actually, what I'm asking is this: is graph theory worth learning if one is interested in statistical/machine learning? Is analysis of complex networks intertwined with ML? Or am I going  to waste my time? :/",27,14
89,2014-2-14,2014,2,14,11,1xuzpd,Gradient Descent Question,https://www.reddit.com/r/MachineLearning/comments/1xuzpd/gradient_descent_question/,mydickisgigantic,1392343846,"Hi, so I am pretty new to ML and for my first project, my teacher wanted me to learn the basics of linear regression using stochastic gradient descent. My question is this: when you are updating each new theta, how do you calculate alpha, the learning rate?",10,0
90,2014-2-14,2014,2,14,17,1xvscq,Automatic Toroidal Coil Winding Machines in India,https://www.reddit.com/r/MachineLearning/comments/1xvscq/automatic_toroidal_coil_winding_machines_in_india/,uday02,1392365176,,0,1
91,2014-2-14,2014,2,14,18,1xvwjs,Why do Kernel functions had to be positive semi-definite?,https://www.reddit.com/r/MachineLearning/comments/1xvwjs/why_do_kernel_functions_had_to_be_positive/,realAnalysisHalp,1392370481,"In my machine learning class, my professor explained that a kernel function must be symmetric and psd. I understand that kernels represent the inner product of the feature vectors in some Hilbert space, so they need to be symmetric because inner product is symmetric, but I am having trouble understanding why do they need to be positive semi-definite.",9,12
92,2014-2-14,2014,2,14,18,1xvwn5,Faster and even better K-means based on Kohonen Learning Procedure,https://www.reddit.com/r/MachineLearning/comments/1xvwn5/faster_and_even_better_kmeans_based_on_kohonen/,erogol,1392370631,,0,0
93,2014-2-14,2014,2,14,23,1xwcx4,ML research for undergraduates,https://www.reddit.com/r/MachineLearning/comments/1xwcx4/ml_research_for_undergraduates/,[deleted],1392388649,"Hello, I am an applied math student and I have the opportunity to do machine learning research this semester. The reason I am posting is that I don't know what sort of problems will be accessible for me, given my background. 

I have some experience in programming (Python, C), and I've taken Linear Algebra, Multivariable Calc, and studied probability/statistics on my own. But I have no background in data structures and algorithms (I recently picked up Aho's 'The Design and Analysis of Algorithms' from the library to teach myself).

Natural language processing and machine learning applied to games (Chess, Go) seem like interesting and somewhat accessible areas to me. But the professor I'll be working with is more interested in theoretical research. (He said I'd do better in theoretical research because of my math background.) 

I've looked up papers on arxiv and elsewhere, and a lot of the work is over my head. I don't know what's right for me. By the way, I'm meeting with my professor today to ask him these questions, but I'm posting now because I want to have some ideas going in.

So what do you think would be a suitable problem or project for me to work on? Thanks in advance for your help -- I appreciate it.",1,5
94,2014-2-15,2014,2,15,1,1xwog1,Win-Vector Blog  Unprincipled Component Analysis,https://www.reddit.com/r/MachineLearning/comments/1xwog1/winvector_blog_unprincipled_component_analysis/,dtelad11,1392395697,,1,8
95,2014-2-15,2014,2,15,2,1xwwyu,"Beginner, distance measurements, knn",https://www.reddit.com/r/MachineLearning/comments/1xwwyu/beginner_distance_measurements_knn/,[deleted],1392400425,"Hi everyone, new to this sort of thing, but really find it fascinating. I know this isn't exactly a q/a type sub, but perhaps you all could give me some advice on the best place to answer questions like this the one below.

I've worked my way through part of Programming Collective Intelligence and I wanted to get started with some implementation to make the ideas stick. I have a dataset of items that I would like to find the nearest neighbors for and I'm not sure if I'm taking the right approach. I figure something fun to model would be American whiskey, give some real world messy/incomplete data and its a bit of a hobby of mine. 

Each whiskey can have the following features for now, though I want to continue on using this to learn and pull in some others like location, etc.

(mashbill percentages, add up to 100, sometimes known)
rye_percent
corn_percent
barley_percent
wheat_percent

age (sometimes known)

alcohol_percent (always known)
distiller (always known)


I've implemented the pearson squared distance formula. 
From what I understand:

For categorical data, ie the distiller, I need to use dummy variables, replacing it with 1 if it matches and 0 otherwise.

For age and alcohol percent I need to normalize, where all values are between 0-1.

For the mashbill percentages I would normalize as well. Should I use a different approach since they're associated with each other?

Sparseness of the data-set, if the age, or mashbill components aren't there, is it best to replace with the min, median, mean, or is this where it gets into just trying it out and seeing what works best.


Thanks!",3,2
96,2014-2-15,2014,2,15,3,1xwzps,AHaH ComputingFrom Metastable Switches to Attractors to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1xwzps/ahah_computingfrom_metastable_switches_to/,010011000111,1392402051,,5,7
97,2014-2-15,2014,2,15,4,1xx4s0,Try my topic tracking website,https://www.reddit.com/r/MachineLearning/comments/1xx4s0/try_my_topic_tracking_website/,asfarley,1392404954,"Hi, I've finished the basic functionality for a topic-tracking website and I'm looking for some user feedback. 

http://dev.rsearch.ca

The target user is someone who, for whatever reason, regularly Googles/searches for some particular term to see if the results have changed. This is quite general but some applications might be PR firms, or researchers trying to stay up-to-date with related research.

There's a free user account. The idea is: you sign up and enter a topic and just wait for the emails to roll in when new related words are found. 

I would appreciate any feedback whatsoever. Thanks!
",5,5
98,2014-2-15,2014,2,15,4,1xx7rv,Momentum in Pylearn2 [OC],https://www.reddit.com/r/MachineLearning/comments/1xx7rv/momentum_in_pylearn2_oc/,ian_goodfellow,1392406684,,0,7
99,2014-2-15,2014,2,15,5,1xxfjs,"Spectral Clustering Intuition While looking around for a good tutorial on spectral clustering, I noticed that a lot of tutorials had a lot formulas and such, whereas I felt spectral clustering is best explain visually.",https://www.reddit.com/r/MachineLearning/comments/1xxfjs/spectral_clustering_intuition_while_looking/,sasaram,1392411222,,9,24
100,2014-2-15,2014,2,15,6,1xxhji,"Spotify, Netflix, Google, Cloudera and many more are speaking at MLconf NYC on 4/11. Early-bird tickets end in 50m. Discount link for redditors.",https://www.reddit.com/r/MachineLearning/comments/1xxhji/spotify_netflix_google_cloudera_and_many_more_are/,[deleted],1392412350,,0,1
101,2014-2-15,2014,2,15,7,1xxmht,Recommended way to start learning ANNs with python pyBrain.,https://www.reddit.com/r/MachineLearning/comments/1xxmht/recommended_way_to_start_learning_anns_with/,chchan,1392415221,"I am familiar with most machine learning algorithms and want to pick up a better understanding of Neural Networks and setting them up in python using pyBrain.

Are there any good books/ intros to subjects like Self Organizing maps, Feed Forward Neural Networks, Boltzmann Machines, Autoencoder, Recurrent neural network.

Also are there any tutorial on Python pybrain library of implementations?

So I want to get an understanding up to the point were I am able to understand how to implement Deep learning for problem solving and understand research papers.

So far my math background is time series analysis, statistics (regression analysis, kind of weak in probability theory and bayesian since I learn it myself),  linear algebra, vector calculus and differential equation (needs refreshing since I have not used both of them in a while)",3,0
102,2014-2-15,2014,2,15,7,1xxoc5,"Netflix, Google, Spotify, Cloudera and many more speaking at MLconf NYC on 4/11. Discount link for Redditors",https://www.reddit.com/r/MachineLearning/comments/1xxoc5/netflix_google_spotify_cloudera_and_many_more/,shonburton,1392416314,,5,0
103,2014-2-15,2014,2,15,8,1xxsni,Mining of Massive Datasets [500+ page PDF from Stanford],https://www.reddit.com/r/MachineLearning/comments/1xxsni/mining_of_massive_datasets_500_page_pdf_from/,carmichael561,1392418927,,0,8
104,2014-2-15,2014,2,15,22,1xzasl,Evolution is a special kind of (machine) learning,https://www.reddit.com/r/MachineLearning/comments/1xzasl/evolution_is_a_special_kind_of_machine_learning/,alexeyr,1392472057,,0,50
105,2014-2-16,2014,2,16,3,1xzxv9,Named Entity Recognition using stanford nlp core on parallel computing [Implementation Help],https://www.reddit.com/r/MachineLearning/comments/1xzxv9/named_entity_recognition_using_stanford_nlp_core/,heaven__,1392489826,"Hi 
I need to implement the above, so far I have tried using Stanford NLP core and got it working on default settings. If i try to change the settings the server doesnt run, it error's out so I didnt really mess around with it its doing its job on default setup.

Language  = Python 

Lib = jsonrpclib,  [robert Elwell's python extension](https://github.com/relwell/stanford-corenlp-python)

I got the parser running to process the data on a single core, but i want to implement it on multiple cores. I tried Ipython for it, still learning about it and playing with it, though I have my doubts that its the best way to do this because I tried some sample testing it didn't work very efficiently but it could just be my implementation. 

My prime target is processing 100 articles per second and the way I am doing it is not working, could you guys suggest ways to improve my performance.

Current performance = 7-15sec/article on local machine.
  
sorry for being a little gibberish. :) 
thank you. ",2,4
106,2014-2-16,2014,2,16,5,1y071r,Completely New to machine learning,https://www.reddit.com/r/MachineLearning/comments/1y071r/completely_new_to_machine_learning/,suryagram,1392495691,,7,1
107,2014-2-16,2014,2,16,5,1y08ig,Full Bayesian formula in Naive Bayes for probability estimates?,https://www.reddit.com/r/MachineLearning/comments/1y08ig/full_bayesian_formula_in_naive_bayes_for/,kezalb,1392496631,"I am hoping to utilize Naive Bayes for classification. I understand that the denominator can be dropped because it will be the same for all (both in my case) classes. However, this seems quite limiting, as the output is simply the most likely class, but lacks a probability estimate.

I would like to create a tool where the business user may set a confidence threshold ad hoc. This would be useful because different use cases will have different precision and recall requirements. So, the business user could rank the examples according to confidence and take either the n most likely or those above x likelihood.

However, I am not finding any papers utilizing this approach. Is there some limitation I am not seeing? Are the results of naive Bayes when using the full formula somehow not ""real"" probabilities anyway? Do I not need the denominator for what I want? Is the denominator dropped simply for computational efficiency?

Thanks in advance for any insight!
",4,1
108,2014-2-16,2014,2,16,8,1y0nef,Flappy Bird hack using Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/1y0nef/flappy_bird_hack_using_reinforcement_learning/,RockDiesel,1392506246,,20,149
109,2014-2-16,2014,2,16,12,1y16cz,Current state of face classification?,https://www.reddit.com/r/MachineLearning/comments/1y16cz/current_state_of_face_classification/,[deleted],1392519878,"Hello Community.

I just wanted to ask what is the current state of real-world face classification systems? I am not into the field much, but after talking with a few people the opinions ranged from real-world face classification being difficult to it being no longer relevant or difficult (since the re-birth of deep architectures).

So what is the current state of this problem? I read some papers, but there are so many of them that I am not even sure whom to trust.

Thanks a lot for your time.",6,5
110,2014-2-17,2014,2,17,8,1y3gkt,Anyone want to talk about their work?,https://www.reddit.com/r/MachineLearning/comments/1y3gkt/anyone_want_to_talk_about_their_work/,Deviationisnormal,1392591731,"Hi there. I'm a researcher out of the department of media and information studies at a research institution in the midwest. I'm working on an ethnographic project about machine learning with a particular focus on the practitioners of such techniques. Much of the research in my department has focused on user perceptions, and I would like to balance our perspective by talking to people who actually make these things happen. If you want more details or are willing to talk to me please send a PM!",2,19
111,2014-2-17,2014,2,17,9,1y3o6z,Pylearn2 Setup,https://www.reddit.com/r/MachineLearning/comments/1y3o6z/pylearn2_setup/,[deleted],1392596666,"More of a technical question:

I'm doing the first Quick-start example for pylearn, and I'm wondering whcih folder I should be working in: The one downloaded from github, or the one created after installation?

It seems like the downloaded one is the one that contains the ""cifar_grbm_smd.yaml"" file. Also, which ""scripts"" folder should I add to my PATH, the downloaded one, or the installed one?",0,0
112,2014-2-17,2014,2,17,11,1y3xcq,Combining Bag of Words With Other Features?,https://www.reddit.com/r/MachineLearning/comments/1y3xcq/combining_bag_of_words_with_other_features/,[deleted],1392602541,"Second post. I'm working on system that does some quick classification based on item content and characteristics, giving me a list of nearest neighbors and farthest neighbors using pearson squared distance.

I'd like to expand my little toy system and also have it take reviews online into account. Seems like a good fit for the basic bag-of-words approach I've learned about so far, but I'm having trouble figuring out how to combine this with the other features.

Should I look at including each word from the bag-of-words as a feature itself, and weighting them lightly compared to the content features, or should I think about calculating the bag-of-words distance separately and then have that distance as a feature?

Also, any advice on this? I tend to learn best starting from a practical side and then digging into the more expansive theory based stuff later, but I seem to be having a tough time with ML/Datascience doing that, but perhaps I'm looking the wrong place.",8,3
113,2014-2-17,2014,2,17,14,1y4f27,"Free Text Mining, Text Analytics Books",https://www.reddit.com/r/MachineLearning/comments/1y4f27/free_text_mining_text_analytics_books/,johnt1234,1392614306,,0,1
114,2014-2-17,2014,2,17,23,1y5af1,"Metacademy: a package manager for knowledge ""built around an interconnected web of concepts, each annotated with a short description, a set of learning goals, a rough time estimate, and pointers to learning resources""",https://www.reddit.com/r/MachineLearning/comments/1y5af1/metacademy_a_package_manager_for_knowledge_built/,urish,1392646483,,3,66
115,2014-2-17,2014,2,17,23,1y5ci1,Regularization of nnets - Dropout vs. all else,https://www.reddit.com/r/MachineLearning/comments/1y5ci1/regularization_of_nnets_dropout_vs_all_else/,ml_man,1392648350,"I know that for image recognition and other visual learning tasks dropout (with max col norm) is a very effective form of regularization and has the extra benefit of being simple to implement and understand.

I am interested in economic time series, where there is much more noise. Is dropout still the most competitive form of regularization or does L1/L2 perform better or even more complicated higher order methods which penalize curvature to induce smoothness in the function learnt by the network?",7,8
116,2014-2-18,2014,2,18,2,1y5qu1,Question about learning vector representations via semi-supervised learning (in neural nets),https://www.reddit.com/r/MachineLearning/comments/1y5qu1/question_about_learning_vector_representations/,[deleted],1392657888,"In [Socher &amp; Manning's Deep Learning for NLP tutorial](http://nlp.stanford.edu/courses/NAACL2013/NAACL2013-Socher-Manning-DeepLearning.pdf) they give a description of a simple feed-forward network with one hidden layer (slide 49), which is able to learn features that are (to some extent) context-aware. 
 
The idea, briefly, is this: given a sequence of symbols where context matters, concatenate the vector representations of these symbols into a vector x. Make a copy of the sequence, randomly change one of the symbols to corrupt the context, and concatenate those representations to make x_hat. For each input vector, compute a scalar score by doing one feed-forward pass and taking the dot product with an arbitrary vector. (At least I think it's arbitrary, they make no mention of it anywhere, input here is welcome). The score of x is S(x), and for x_hat it's S(x_hat).
 
Features are then learnt by optimizing a hinge loss: J = max(0, 1 - S(x) + S(x_hat))
 
I'm trying to implement it from the slides for a related toy problem, but I'm curious about a few things: when you back-propagate unlabeled information, why would you also change the network weights? Aren't we purely interested in learning features that make S(x) &gt; S(x_hat) by some margin? 
 
The next step in the process is back-propagating label information into the representations by using a softmax output layer. Again, what is the point of also changing the weights if we only care about representations? Wouldn't we purely want to optimize representation vectors to result in correct classification, and then do weight learning separately at some later time? 
 
Thanks a bunch. Semi-supervised learning is one of the coolest ideas I've heard about in a while. ",0,2
117,2014-2-18,2014,2,18,8,1y6rhz,Advice on predicting events,https://www.reddit.com/r/MachineLearning/comments/1y6rhz/advice_on_predicting_events/,hannibaldon,1392678744,"Hey guys. Machine learning n00b here. Let's say I have a bunch of time series (say from Jan 1 1990 to Dec 31 2013) and a bunch of events that occurred at various dates during that time frame. How do I predict the probability of an event happening at any point.

For example, my time series data might be World Bank economic data (yearly inflation, gdp etc) and I want to predict economic crises. 

Or my time series might be weather data (daily rainfall, temperature etc) and I want to predict floods or storms etc.

Thanks!",2,0
118,2014-2-18,2014,2,18,13,1y7qdp,"Deep Learning Pioneer, Yoshua Bengio will be doing an AMA in /r/MachineLearning on Feb. 24 1PM EST",https://www.reddit.com/r/MachineLearning/comments/1y7qdp/deep_learning_pioneer_yoshua_bengio_will_be_doing/,olaf_nij,1392699244,"Universit de Montral Professor Yoshua Bengio will be visiting /r/MachineLearning for an AMA on February 24 at 1 PM EST. 

Special thanks to Ian Goodfellow for helping to arrange this.

If the /r/MachineLearning community would like more of these, let us know!",19,170
119,2014-2-18,2014,2,18,18,1y88my,Looking for good resources for absolute beginner.,https://www.reddit.com/r/MachineLearning/comments/1y88my/looking_for_good_resources_for_absolute_beginner/,IDigressALot,1392715224,"Hi, i am a python programmer and i have been interested in machine leaning for quite a while, **but I am very confused about it since, every study material I come across start from a ""level 1"". I have been unable to find any material which starts with ""level 0""**. I recently came across this subreddit and figured, I can count on fellow redittors. Thanks and looking forward to your replies. Please comment if you have any questions you wanna ask me, I will try to reply as soon as possible.",4,4
120,2014-2-18,2014,2,18,20,1y8fgp,"Deep Learning creating jobs in Apps, wearable tech and robotics",https://www.reddit.com/r/MachineLearning/comments/1y8fgp/deep_learning_creating_jobs_in_apps_wearable_tech/,uavster,1392722781,,0,0
121,2014-2-18,2014,2,18,23,1y8tqj,"Automatic Summarization and the word ""very""",https://www.reddit.com/r/MachineLearning/comments/1y8tqj/automatic_summarization_and_the_word_very/,pasmod,1392735458,,0,0
122,2014-2-19,2014,2,19,4,1y9o9l,Data Analysis steps,https://www.reddit.com/r/MachineLearning/comments/1y9o9l/data_analysis_steps/,SureshGorakala,1392752581,,0,1
123,2014-2-19,2014,2,19,5,1y9u6c,"Is it a good approach to get started with machine learning by choosing to do a project, with no background? : /r/datascience",https://www.reddit.com/r/MachineLearning/comments/1y9u6c/is_it_a_good_approach_to_get_started_with_machine/,channikhabra,1392755628,,5,4
124,2014-2-19,2014,2,19,14,1ybf5r,How to read the book Machine Learning by Kevin Murphy,https://www.reddit.com/r/MachineLearning/comments/1ybf5r/how_to_read_the_book_machine_learning_by_kevin/,matrix2596,1392786922,"I am trying to study the [book](http://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020) on my own and it seems quite a steep learning curve.  Please  suggest a way of studying that would help? Can you please point me to resources to read before embarking on this book? Found this [metaacademy](http://www.metacademy.org/roadmaps/rgrosse/bayesian_machine_learning) but doesnt give pre reqs.

EDIT: Sorry I havent been clear.",9,5
125,2014-2-19,2014,2,19,20,1yc2gi,The Elements of Statistical Learning,https://www.reddit.com/r/MachineLearning/comments/1yc2gi/the_elements_of_statistical_learning/,jonathan881,1392809444,,5,34
126,2014-2-20,2014,2,20,2,1ycums,How can I rate the similarity of two series of points?,https://www.reddit.com/r/MachineLearning/comments/1ycums/how_can_i_rate_the_similarity_of_two_series_of/,projector,1392829948,"I have a collection of series of 2D points, like these http://imgur.com/taQpWxh

How can I compare series and measure the distance between them?

I've found [this answer](http://stats.stackexchange.com/questions/12902/comparison-of-time-series-sets) on the stats stack exchange but am interested in alternative or simpler ways to do this.",7,0
127,2014-2-20,2014,2,20,3,1yd14j,"Machine learning helps us find ""hidden people"" in social networks.",https://www.reddit.com/r/MachineLearning/comments/1yd14j/machine_learning_helps_us_find_hidden_people_in/,DrJosh,1392833456,,3,3
128,2014-2-20,2014,2,20,3,1yd1ej,I thought people here might like to see the answer to the question I just posted to Brian Krzanich from Intel.,https://www.reddit.com/r/MachineLearning/comments/1yd1ej/i_thought_people_here_might_like_to_see_the/,[deleted],1392833603,,0,0
129,2014-2-20,2014,2,20,7,1ydvcd,The perplexity of a probabilistic model.,https://www.reddit.com/r/MachineLearning/comments/1ydvcd/the_perplexity_of_a_probabilistic_model/,qkdhfjdjdhd,1392849844,,5,3
130,2014-2-20,2014,2,20,12,1yerlv,"The minority report: Chicago's new police computer predicts crimes, but is it racist?",https://www.reddit.com/r/MachineLearning/comments/1yerlv/the_minority_report_chicagos_new_police_computer/,code_and_theory,1392868148,,41,20
131,2014-2-20,2014,2,20,16,1yf90k,Experience with temporal difference learning or TD-Gammon?,https://www.reddit.com/r/MachineLearning/comments/1yf90k/experience_with_temporal_difference_learning_or/,hetong_007,1392880411,"According to [this tutorial](http://modelai.gettysburg.edu/2013/tdgammon/pa4.pdf), I [implemented the algorithm](https://github.com/hetong007/TD_ConnectFour) of temporal difference learning on [Connect Four](http://en.wikipedia.org/wiki/Connect_Four), because the rules of Connect Four are easy to implement. But my neural net is **not** being trained properly. The original paper by Tesauro [could be found here](http://neumre-2011-projekt.googlecode.com/svn-history/r37/trunk/literatura/tesauro1995temporal.pdf). 

Here's my setup and the problem:

The input is a vector of length 43, i.e. status of the 6-times-7 board and the next player. The output layer has 3 neurons standing for the chance of ""the first player will win"", ""this game will be a draw"", and ""the second player will win"" respectively. After randomly initialize the weight, this net will play a game with itself, then learn from this game.

According to the original learning algorithm, we will just focus on decreasing the difference between two *ply*s, and decrease the difference between the prediction and the true outcome of this game only in the end. The last step indicates the proper direction to train the weight. However, After about 100 games, I find out that the output values look like [0.99,0.05,0.99], i.e., in order to decrease the difference between two *ply*s, the neural net chose to **fix its output** and ignore the last outcome. I thought this was caused by insufficient training, but the output will still fix to the [1,0,1] even after thousands of games.

I think there could be some reasons:

* I am doing it in a totally wrong way
* I chose a wrong game to play(connect four)
* I need to tune parameters
* The tutorial is misleading
* I need to increase the penalty of the last step


* Or , in the paper [*Why did TD-Gammon Work?*](http://foogammonz.googlecode.com/svn/trunk/Why_did_TD_Gammon_work.pdf) by Jordan B. Pollack &amp; Alan D. Blair:
&gt; It (Tesauro's TD-Gammon) has not led to similar impressive breakthroughs in temporal difference learning for other applications or even other games.

Does anybody has experiences on this topic? Thanks.
",5,2
132,2014-2-20,2014,2,20,17,1yfdms,Process of Setting ZW Electric Pump Series in Industry,https://www.reddit.com/r/MachineLearning/comments/1yfdms/process_of_setting_zw_electric_pump_series_in/,marcosesteban1,1392885416,,0,1
133,2014-2-21,2014,2,21,0,1yg1n7,"Problem: given a map of some region, find specific structures",https://www.reddit.com/r/MachineLearning/comments/1yg1n7/problem_given_a_map_of_some_region_find_specific/,[deleted],1392909498,"Suppose you're given a map and you need to find if there are any structures of a specific kind anywhere on the map. How feasible is this at the moment? I've tried searching through some computer vision journals but my expertise in this area is exactly zero. 

Any links to relevant references are greatly appreciated!",10,9
134,2014-2-21,2014,2,21,3,1ygocf,Yelp updates and extends their academic dataset. Dataset Challenge Round 3 open now to students in US/CAN.,https://www.reddit.com/r/MachineLearning/comments/1ygocf/yelp_updates_and_extends_their_academic_dataset/,Zephyr314,1392922591,,1,4
135,2014-2-21,2014,2,21,5,1ygvxv,Looking for HMM library that can handle dynamic emission probabilities,https://www.reddit.com/r/MachineLearning/comments/1ygvxv/looking_for_hmm_library_that_can_handle_dynamic/,NotAHomeworkQuestion,1392926744,"So I've got a system where at each point in time the emission and transition probabilities are different. I've got a method that estimates these already, I'd just like to throw them into an HMM library without having to take the time to code my own. However, the Matlab and SciKitLearn HMM tools both seem to assume static probs. Does anyone have a suggestion for one that allows changing probs? Thanks!",3,5
136,2014-2-21,2014,2,21,5,1ygxkm,Looking for a place to start,https://www.reddit.com/r/MachineLearning/comments/1ygxkm/looking_for_a_place_to_start/,djfried,1392927588,I'm currently in an Artificial Intelligence course at University and some friends and I opted to do an optional assignment on machine learning.  The basis of this assignment is that we are given a test set .csv file which consists of thousands of rows and about 300 columns. All of the columns consist of binary number sets and some have decimal numbers with the last column being a Boolean. We need to be able to find the most true rows on the evaluation set in order to get the extra credit. While we have learned some concepts in the course we haven't encountered anything this big and our professor is not going to offer any help until after we have submitted.  We were looking into using weka since we are all pretty fluent in java but we aren't really sure what to do with it. We are open to any and all help or resources that you can suggest. I promise to repost and let you all know how it goes!  ,4,3
137,2014-2-21,2014,2,21,5,1ygygc,/r/ml how do you store your data?,https://www.reddit.com/r/MachineLearning/comments/1ygygc/rml_how_do_you_store_your_data/,ikyr9999,1392928091,"I'm working on a project that is scraping live data every day which I intend to use it for ML after it grows enough. The raw data (as is) has a complex structure (lists within lists within lists) and for starters i'm saving it in json.
My question is, what format for saving data is most recommended for ml?",18,10
138,2014-2-21,2014,2,21,6,1yh6gf,How do I learn how to make novel algorithms?,https://www.reddit.com/r/MachineLearning/comments/1yh6gf/how_do_i_learn_how_to_make_novel_algorithms/,alexgmcm,1392932336,"I noticed that some jobs desire the candidate to be able to produce novel machine learning algorithms.

Although I have some grasp of the theory behind Machine Learning as I've taken courses on it, I still wouldn't have a clue as how to design algorithms. I mean I understand Max. Likelihood, Naive Bayes, the derivation of the EM algorithm via Jensen's inequality, inference in belief networks etc.

So I have more understanding of the theory than some who just use a bag of libraries to crunch data. But it seems a huge chasm from going from some mathematical understanding to formulating your own methods!?",6,13
139,2014-2-21,2014,2,21,7,1yhem8,Why is this neural network not working?,https://www.reddit.com/r/MachineLearning/comments/1yhem8/why_is_this_neural_network_not_working/,Plazmotech,1392936725,"I wrote a Neural Network interface.

Currently I'm making a simple mock-up dataset, in which it's supposed to model the probability in which I will buy coffee.

There are two inputs, Tiredness level (an integer from 110), and money in my pocket in dollars.

There are 5 hidden layers.

The output is the probability I will buy coffee, from 110. 

---

I'm attempting to make the network learn that the more tired I am, and the more money I have in my pocket, the more likely I am to buy coffee. That is, until the money in my pocket is less than $5, as I cannot afford coffee then.

Here is my dataset. The format is i,i=o

    10,10=10
    10,8=9
    10,5=8
    10,3=0
    10,0=0
    8,10=9
    8,8=7
    8,5=5
    8,3=0
    8,0=0
    5,10=8
    5,8=5
    5,5=2
    5,3=0
    5,0=0
    3,10=7
    3,8=3
    3,5=0
    3,3=0
    3,0=0
    0,10=6
    0,8=1
    0,5=0
    0,3=0
    0,0=0
    
From this dataset I created a training set of 2000 datapoints, which are essentially just a copy of the dataset over and over.

Learning Rate: 0.001
momentum: 0.99
max epochs: 100

The output of error is 

    ([8.481614326157052, 9.1778977041744252, 9.1173908181709926, 8.4620478776465475, 7.4755607395183423, 8.4250094018388086, 7.558054030458119, 8.6465403858822878, 9.0289304494838287, 8.6824054024597146, 8.5938658591577166, 8.4959333518901037, 8.3887658561914655, 8.0005677831674085, 10.180491288231561, 8.1279863949339966, 7.93245506000705, 8.6586414558593692, 7.8302759161369995, 9.1129975194822688, 9.1991448660178197, 8.2699536574502126, 7.9792364145251966, 8.3860963269013826, 7.9526752399728755, 7.9840027572268211], [13.875419918831762, 13.273001771554529, 6.5852520162330279, 7.6232273733885583, 7.6051010835927748, 11.227572309967643, 8.534444868855946, 6.5835672281546325, 7.0967655932224254, 7.6759543371446064, 7.0075166151122437, 8.9576686691476297, 10.479403927344199, 17.354178203550845, 7.4176237160927849, 9.2336295736552341, 6.9993602421628927, 9.4145760467322859, 7.3932594282445212, 7.5229495671835593, 7.4000991604975432, 7.7768514465740353, 9.2068866704367256, 7.4479117920270745, 8.3853339273668741, 9.1687984807995857, 8.7605200065964954])

However, the output is

    Enter inputs seperated by commas
    &gt; 10,10
    3.34575322135
    &gt; 10,5
    3.34575322135
    &gt; 8,4
    3.34575322135

What is wrong? I can easily create logic gates, and such. But more complex things like this fail.",7,0
140,2014-2-21,2014,2,21,8,1yhj8j,The intuition behind conditional Gaussian distributions.,https://www.reddit.com/r/MachineLearning/comments/1yhj8j/the_intuition_behind_conditional_gaussian/,qkdhfjdjdhd,1392939457,,1,33
141,2014-2-21,2014,2,21,12,1yi7pf,Feeding Infinity - Applied Supervised Learning for Malware Detection,https://www.reddit.com/r/MachineLearning/comments/1yi7pf/feeding_infinity_applied_supervised_learning_for/,abacabadba,1392954286,,0,0
142,2014-2-21,2014,2,21,13,1yi95m,What I most wish I'd known as an undergrad: Go to public talks!,https://www.reddit.com/r/MachineLearning/comments/1yi95m/what_i_most_wish_id_known_as_an_undergrad_go_to/,justonium,1392955205,"Your university likely has many public talks relevant to your research interests. Go to them. Many of them may be over your head, but if you go, you are exposing yourself to the language of your field; If you are trying to join an academic community, it is important that you observe members of that community communicating their research to each other, and public lectures hosted at your university are a great way for you to do this.

Also, I think that **the most underrated part of the lecture is the time after the professor finishes taking questions from the audience, when audience members come to the front to converse with the professor one on one.** This is usually the most important part of the lecture to me. Even if I don't have anything to say, I go up and listen to the professor talk to people. The lecture hall setting with the audience doesn't make it easy for the audience to provide the professor the same kind of real time feedback that one on one conversation does, and as a result, it's harder to convey information in lecture format than to a responsive listener.

And another thing: don't restrict yourself to the talks that you think are relevant to your research. Go to all types of talks, and you might be surprised how much overlap there is between all fields of academic research.",9,17
143,2014-2-22,2014,2,22,0,1yjhtp,Statlect: A 'digital textbook' on statistics.,https://www.reddit.com/r/MachineLearning/comments/1yjhtp/statlect_a_digital_textbook_on_statistics/,alexgmcm,1392996926,,4,21
144,2014-2-22,2014,2,22,0,1yji8j,Machine Learning with big data,https://www.reddit.com/r/MachineLearning/comments/1yji8j/machine_learning_with_big_data/,matrix2596,1392997195,"I have heard this is the revolution of big data and how with help of analytics this is going to be a game changer. But I dont see any libraries which provide machine learning algorithms on big data. Most of the recent applied research areas are on single machines (i guess). Does big data help in machine learning and are there any good libraries and successful applications of machine learning on big data? 
P.S: I am only worried that many big data applications are not easily accessible with libraries or platforms (eg deep learning or Big data Graphical models). I have heard of MLLib on spark btw but its not mature enough.",1,0
145,2014-2-22,2014,2,22,3,1yjxa8,The hidden challenge of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1yjxa8/the_hidden_challenge_of_machine_learning/,tryolabs_feco,1393006043,,0,0
146,2014-2-22,2014,2,22,4,1yk6di,Random Forest using one variable,https://www.reddit.com/r/MachineLearning/comments/1yk6di/random_forest_using_one_variable/,mtnchkn,1393011170,"I was using a forward sequential variable selection method to determine an optimal group of variables to classify an outcome by minimizing the misclassification error rate of generated random forests. Sometimes instead of a group of variables, only a single variable would be selected. It should also be noted that the data was pretty weak looking at each variable alone. 

Can someone with a deeper conceptual understanding of random forest than me please explain what a random forest using one variable is doing? Since it is one variable, it is hard for me to see how the random forest can achieve a better sens/spec than that single variable can ever achieve alone (which it does). 

Thanks for the help.",6,2
147,2014-2-22,2014,2,22,6,1ykidk,Python Tools for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1ykidk/python_tools_for_machine_learning/,bugra,1393017909,,2,60
148,2014-2-22,2014,2,22,9,1yl2ys,SAS Regression - Offset with log or natural log?,https://www.reddit.com/r/MachineLearning/comments/1yl2ys/sas_regression_offset_with_log_or_natural_log/,MJ420Rx,1393030472,"I am attempting to builds some count regression models to compare healthcare utilization between cases and controls with different follow-up times.


I was told by our lead statistician that I should offset with the log base 10 years to adjust for different follow up times. But in every example I've seen the offset option is equal to natural log of years.


Which is the correct method?


Please note: In SAS New_variable = log(old_variable) automatically uses natural log (for log base 10 the command is n = log10(x)).


Thanks in advance for the help.
",2,0
149,2014-2-22,2014,2,22,9,1yl30q,Visualising the Q-function for the RL Flappy Bird hack (link in text),https://www.reddit.com/r/MachineLearning/comments/1yl30q/visualising_the_qfunction_for_the_rl_flappy_bird/,rcwll,1393030505,"(Link to album)[http://imgur.com/a/mlLbb].  

After reading [the original post](http://www.reddit.com/r/MachineLearning/comments/1y0nef/flappy_bird_hack_using_reinforcement_learning/) I went ahead and bodged a version of the TD-lambda learning rule into the same javascript framework (technically a strictly on-greedy-policy version of [Watkin's Q-lambda](http://webdocs.cs.ualberta.ca/~sutton/book/ebook/node78.html) rule, so not strictly TD-lambda), and took a look at the results of that compared to the results of the original model.

Short version is that the Q-lambda rule learns a lot faster with the right parameters (a lambda of about 0.5 seems to do really well, and a but under still does ok) and performs abysmally with the wrong parameters (much over 0.5).  The scoring is the same as in the original implementation (+1 for every frame of life, -1000 for death) so a score of -945 corresponds to just falling to your death, -730 corresponds to passing the first pipe, and then it's another 200 or so per pipe after that.  I've only got 1 trial for each rule in the top plot, but a lambda of 0.5 reliably gets to well over 1000 pipes passed in under 150 games.

Below that are three plots showing a few different views of the learned Q function for different learning rules; top to bottom are: the original Q-learning with alpha=0.7, Q-lambda with lambda=0.5, and Q-lambda with lambda=0.7.  The leftmost in each is the greedy policy; red means do nothing, green means click/jump, and black is 'nothing learned' and will default to 'do nothing'. Next is the difference in score between clicking and not clicking.  Third is the score for 'clicks' in each state, and last is the score for 'do nothing' in each state.  Important note: because of the way coordinates get stored, the bird actually moves from right to left across these (see the outline of the pipe on the left).  

It's interesting to compare the Q-learning with Q-lambda; things that jumped out at me:

1. they both sort of settle on the same general strategy (cruise just below the pipe edge, and then hop over it when you get close)
2. the eligibility traces in the Q-lambda rule let it update values in a much broader space; it's actually managed to assign positive scores to 'do nothing' in a noticeably larger range above the lip of the pipe.  The standard Q-learning can only back out one step at a time, so it ends up taking longer to fill out the space.
3. The Q-learning has learned a lot more negative values for clicking than the Q-lambda (at least the 'good' Q-lambda one), especially right up against the lower pipe.  The slow backout means that it gets itself into unwinnable positions a lot more readily, resulting in it getting a lot of experience about what not to do, that it then takes a while to learn from, since it can only back out one step from where it's most recently visited.

The bottom-most plot I find curious; this shows the Q-function for lambda=0.7 in Q-lambda learning.  When you run it, the bird crashes a few times, and then around the 10th or 11th game, suddenly decides that the top of the board is the best place to be, and never seems to learn to come down from there (I've run it for ~1000 games, and never had it get past the first pipe).  Once in a long while it will decide to drop to its death, but it never seems to try clicking mid-drop.  Looking at the plot, it's clearly learned that what it's doing isn't working, since the scores are all red in the two rightmost visualisations, and looking at the difference it seems like the scores are roughly balanced until it gets close to the pipe, but then for some reason it seems to think that clicking is on balance less negative than not clicking.

The high lambda may be making it ""overthink"" cause and effect, and so update traces that aren't actually relevant, perhaps?  I'm still not satisfied with the answer.

At any rate, hope someone finds it interesting.",4,14
150,2014-2-22,2014,2,22,15,1ylvsi,Stuck on A/V Feature extraction and decision fusion,https://www.reddit.com/r/MachineLearning/comments/1ylvsi/stuck_on_av_feature_extraction_and_decision_fusion/,[deleted],1393052297,"Hi,
In my journey to implement Audio-Video Speech recognition, I have successfully seperated audio and video stream using Xuggle, recognize speech using sphinx .. but I am stuck when the paper talks about feature extraction from audio and video.. then classifying it and finally doing decision fusion to improve the accuracy.. What tools(preferably Java libs) should I use to do this. I am trying to implement: http://www.ncbi.nlm.nih.gov/pubmed/23757540  Guys at http://lts5srv2.epfl.ch/~estellers/AVASR/AVASR_index.html have done something similar but there is no information about methodologies. Would OpeIMAJ suffice?",0,1
151,2014-2-23,2014,2,23,1,1ymp8b,Dnyann En Hzl Tel Bkm Makinas,https://www.reddit.com/r/MachineLearning/comments/1ymp8b/dnyann_en_hzl_tel_bkm_makinas/,mesutyakar,1393085873,,0,0
152,2014-2-23,2014,2,23,14,1yom7u,Question about classifiers &amp; ROC curves,https://www.reddit.com/r/MachineLearning/comments/1yom7u/question_about_classifiers_roc_curves/,stonerbobo,1393133557,"I've been reading about ROC curves - they are plots of true positive rate of a classifier vs. the false positive rate. 

I'm wondering whether increasing the TPR will always increase the FPR (i.e the ROC curve will be increasing)? It definitely would for any kind of smooth classifier that we ""discretize"" by some kind of threshold, but is that true for all kinds of classifiers?

Also, to combat this problem, are there classifiers that output YES/NO/DONT KNOW. In that case, you could increase TPR without increasing FPR if you had two independent tests for an instance being true or not.

that was a long ramble, so thank you for reading through! any answers or pointers to where i can learn about this are much appreciated.",5,8
153,2014-2-24,2014,2,24,5,1yq819,Active learning is semi-supervised genetic algorithms. I think I found a way to make it better,https://www.reddit.com/r/MachineLearning/comments/1yq819/active_learning_is_semisupervised_genetic/,larsga,1393186235,,0,0
154,2014-2-24,2014,2,24,5,1yqaxk,Training Deep Learning Models in a Browser: Andrej Karpathy Interview,https://www.reddit.com/r/MachineLearning/comments/1yqaxk/training_deep_learning_models_in_a_browser_andrej/,hrb1979,1393187901,,6,13
155,2014-2-24,2014,2,24,6,1yqgvd,Classification with NARX models?,https://www.reddit.com/r/MachineLearning/comments/1yqgvd/classification_with_narx_models/,[deleted],1393191408,"Hi everyone.

I'm using NARX (non-linear autoregressive exogenous input) recurrent neural networks to model a non-linear time series. The network is trained to predict the next future value from some previous ones as well as the previous values of another (or several other) time series. I really like the model and it works well for the data I'm predicting, but I'd like to implement it in a probabilistic framework, for example an HMM where the emissions are generated by a NARX model rather than a probability distribution.

My main question is: is there an established way to derive a probability or something that can readily be used as a probability that a certain value in a time series was generated by a particular NARX network given some previous values? There's probably something that's been used before in regression problems, but I'm probably missing something. :(

Thanks!",0,1
156,2014-2-24,2014,2,24,13,1yrmpp,The joy of small data,https://www.reddit.com/r/MachineLearning/comments/1yrmpp/the_joy_of_small_data/,dickingaround,1393216691,,6,22
157,2014-2-24,2014,2,24,14,1yrotn,Having trouble writing code in python for backpropagation algorithm. How do I approach this?,https://www.reddit.com/r/MachineLearning/comments/1yrotn/having_trouble_writing_code_in_python_for/,VortexK,1393218014,"So I'm working on implementing the backpropagation training technique using Python but I have trouble going from the algorithm provided in class to actual code that works. I'm getting very confused when I have multiple classes, getters, and setters doing many things. Can anyone point me to some example backpropagation code so I can imitate and learn what's happening at every stage?",3,4
158,2014-2-24,2014,2,24,14,1yrqyn,What Do Data Scientists See?,https://www.reddit.com/r/MachineLearning/comments/1yrqyn/what_do_data_scientists_see/,[deleted],1393219381,,0,0
159,2014-2-24,2014,2,24,17,1ys2uj,Neuromorphic computing,https://www.reddit.com/r/MachineLearning/comments/1ys2uj/neuromorphic_computing/,[deleted],1393229025,,0,2
160,2014-2-24,2014,2,24,20,1ysbyb,Data Envelopment Analysis Tutorial,https://www.reddit.com/r/MachineLearning/comments/1ysbyb/data_envelopment_analysis_tutorial/,datumbox,1393239935,,0,2
161,2014-2-24,2014,2,24,20,1yscai,Is ML all about statistical regressions at its core?,https://www.reddit.com/r/MachineLearning/comments/1yscai/is_ml_all_about_statistical_regressions_at_its/,[deleted],1393240374,"For the past several months I've been interested in some Machine Learning and I can't help but notice that nomatter what kind of learning algorithm I'm using - at its core lies a simple polynomial or logistic regression. Today I went back to the most basic definition that I could find:

""Machine learning, a branch of artificial intelligence, concerns the construction and study of systems that can learn from data.""

The fact that we're creating mathematical hypotheses based on data ALWAYS means that you're doing some kind of statistical regression ?

If I'm wrong, can you please provide an example where this doesn't hold true.",31,5
162,2014-2-24,2014,2,24,21,1ysfc8,Tips needed - 6 month machine learning + algorithms study plan.,https://www.reddit.com/r/MachineLearning/comments/1ysfc8/tips_needed_6_month_machine_learning_algorithms/,[deleted],1393243781,"Hi guys,

I plan to look for a new job in 6 months time, and am planning a 6 month preparation for it. I need to brush up on my algorithm skills and machine learning knowledge. I plan to dedicate around 2 - 3 hours a day for this, starting tomorrow.

This is my planned list of things to read/watch :

**Machine learning** :
Caltech Machine learning,
UBC Undergraduate Machine learning,
UBC graduate machine learning,
Stanford CS 229.


**Algorithms** :
6.042 Mathematics for computer science,
MIT 6.006,
Stanford CS161 from open classroom.


I would like to get some tips from someone who has done something similar. Suggestions on alternative courses, how to stay on track and maintaining a schedule are totally welcome.",8,5
163,2014-2-24,2014,2,24,22,1ysit4,Automatic keyword extraction from individual documents,https://www.reddit.com/r/MachineLearning/comments/1ysit4/automatic_keyword_extraction_from_individual/,pasmod,1393247363,,0,4
164,2014-2-24,2014,2,24,23,1yso6a,Machine Learning and Predictive Analytics Foster Growth,https://www.reddit.com/r/MachineLearning/comments/1yso6a/machine_learning_and_predictive_analytics_foster/,NotEltonJohn,1393252074,,0,0
165,2014-2-25,2014,2,25,0,1ysry1,AMA: Yoshua Bengio,https://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio/,ian_goodfellow,1393254802,"Yoshua Bengio ( http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html ) is one of the machine learning professors who led the deep learning renaissance of 2006, along with Geoff Hinton and Yann LeCun. His research work focuses on advancing machine learning to the point that it can be used to solve artificial intelligence applications. He is one of the last deep learning professors to remain completely in academia, after several other deep learning professors have joined companies such as Google and Facebook.

Yoshua will answer your questions on **Thursday from 1-2PM EST**. I am one of his grad students and I am creating this thread in advance so that people who are not able to go online at that time can post questions ahead of time. I'll post a verification from my Google+ account in the comments, and Yoshua will post a verification of his username on Thursday.",215,204
166,2014-2-25,2014,2,25,1,1yszty,Need some help narrowing down algorithms,https://www.reddit.com/r/MachineLearning/comments/1yszty/need_some_help_narrowing_down_algorithms/,jGuy91,1393259852,"I am currently working on a project that needs an algorithm for matching/prediction. Essentially, I need to match two people together somewhat similar to a dating site. I have very minimal experience with machine learning and data mining. For a college project, I used opencv to detect cars entering an image. This was done using a Haar classifier, so I can't use the same approach for this. I find myself lost in the woods at the moment and just need a point in the right direction to get me started. 

Thanks for any help offered.




",4,2
167,2014-2-25,2014,2,25,4,1ytieb,Yoshua Bengio AMA rescheduled to Thursday from 1-2PM EST,https://www.reddit.com/r/MachineLearning/comments/1ytieb/yoshua_bengio_ama_rescheduled_to_thursday_from/,olaf_nij,1393270372,"Small communication mixup. On the bright side, there's more time to post questions if you can't make it to the live event. So far, preAMA-ing seems to be working well.",0,5
168,2014-2-25,2014,2,25,13,1yv5ge,The Joy of Small Data - Solved (Thanks! KDE did well on my data set :),https://www.reddit.com/r/MachineLearning/comments/1yv5ge/the_joy_of_small_data_solved_thanks_kde_did_well/,dickingaround,1393303279,,3,9
169,2014-2-25,2014,2,25,13,1yv5ri,Machine Learning Career Advice For An Old Man,https://www.reddit.com/r/MachineLearning/comments/1yv5ri/machine_learning_career_advice_for_an_old_man/,adambeh,1393303477,"Hi I am after some career advice from people who work in the data science/machine learning industry. 

I am in my early 30s and looking to make a career change. I have an electronic engineering degree with a focus on signal processing. I worked out of uni for a couple of years in electronic design before getting a job in the electrical infrastructure industry. I am interested in changing to a career working with data in particular driving data based decision making in the electrical infrastructure industry. 

To make the career change I am currently considering studying a Graduate Diploma in Statistics followed by a Master of Computer Science in Machine Learning. 

I have a couple of concerns regarding my current plan that I was hoping for some advice on. 

1. Considering my age and time spent out of the data science field, will I have a significant disadvantage in the job market once I have completed my study as compared to a younger graduate.
2. Is the course of study proposed the best way to achieve my goals.

Thanks for you time in advance. 
    ",7,4
170,2014-2-25,2014,2,25,17,1yvlav,Deciding on math courses and a discussion on the importance of analysis in ML,https://www.reddit.com/r/MachineLearning/comments/1yvlav/deciding_on_math_courses_and_a_discussion_on_the/,Knux-,1393316039,"My apologies if this is the wrong subreddit. 

I am an undergraduate math major who would like to pursue a graduate degree in computer science, but most importantly I would like to study machine learning, and I have been independently for about half a year. 

I have 1 more year of undergraduate studies left, and I can't decide which classes will benefit me the most. Next semester, I will be taking advanced applied linear algebra (a grad course) and either intermediate real analysis or chaos/nonlinear dynamics (after a few Google searches, I couldn't figure out if this would be relevant, though I did find [this](http://www.cs.toronto.edu/~rsalakhu/papers/dynamic.pdf)), and cryptography (a separate interest). The next semester I plan on taking topology and stochastic processes.  

My question is this: if you could pick any advanced math courses to help with where machine learning is and where it is going, what would you take? Learning math is a lot easier for me when I know that I will be using it eventually. I have been studying measure theory independently with a professor over the last semester, so I am worried that intermediate real analysis will be boring to me (not because it is easy, but because it will be irrelevant to ML) -- are there topics in analysis I should study independently other than measure theory? I haven't encountered enough higher level ML literature/articles that actively involve analysis, even though I am told that it comes up (and it makes sense that it would, given the optimization-based nature of ML and analysis's relation to probability theory).  

Anyway, I figure that this thread can serve two purposes: 1) To discuss which math classes are important in ML/higher level ML (besides basic linear algebra, calculus, and probability) and 2) To discuss the importance of analysis in ML 

Thanks in advance. ",8,6
171,2014-2-25,2014,2,25,20,1yvv0r,Centroid-based Summarization of Multiple Documents,https://www.reddit.com/r/MachineLearning/comments/1yvv0r/centroidbased_summarization_of_multiple_documents/,pasmod,1393328659,,0,3
172,2014-2-25,2014,2,25,23,1yw6te,AskML: LAPD Crime Prediction Approach/Algorithm,https://www.reddit.com/r/MachineLearning/comments/1yw6te/askml_lapd_crime_prediction_approachalgorithm/,aidan_morgan,1393339292,"Does anybody have any details (or educated theories) about how the algorithm that is helping determine potential crime ""hotspots"" in LA works?

It's referred to in many news sites, but there isn't a lot of detail. For example here: 

http://www.technologyreview.com/news/428354/la-cops-embrace-crime-predicting-algorithm/",5,6
173,2014-2-26,2014,2,26,7,1yxlc7,SEC is hiring machine learning experts,https://www.reddit.com/r/MachineLearning/comments/1yxlc7/sec_is_hiring_machine_learning_experts/,jeferyan,1393367555,,11,28
174,2014-2-26,2014,2,26,9,1yxz62,Can anyone give feedback on an approach to online HTML document classification?,https://www.reddit.com/r/MachineLearning/comments/1yxz62/can_anyone_give_feedback_on_an_approach_to_online/,Dschinghis,1393375302,"**TL;DR - If you have operational experience implementing a distributed, online document classification system on a potentially unbounded and constantly growing dataset, care to validate my approach and/or suggest improvements?**

I'd like to sanity-check my approach to solving a fairly large-scale, supervised online document classification problem. The app I've been working on has the following characteristics and goals:

* App crawls websites, stores HTML data
* A document model is produced from each page crawled, based on the non-markup text content of the page
* A classifier provides a relevancy prediction of the crawled HTML content, indicating the likely relevance to our client's core business, along with some kind of accuracy scale to indicate degree of relevance
* Subset of pages crawled from unrecognized domains are presented to users for eventual review, wherein they manually extract relevant features and record the supervised relevancy classification
* Review data is fed back into the ML algorithm which should learn from the supervised classifications and hopefully improve accuracy over time

Constraints: 

* Potentially large set of documents (still in testing and we have over 2 million pages, this will explode once we turn the whole pipeline on full-time) to classify
* ML process needs to be parallelizable, i.e. multiple machines will potentially be handling the learning _and_ prediction steps of the pipeline
* Updating the prediction model shouldn't require access to the entire corpus at once; it's possible to have the whole thing (or subset) available for initial training, but over time the additions to the corpus dataset will be streamed into the pipeline
* Latency is a concern, though we have some wiggle-room here; a few seconds for prediction is acceptable, and that has to include transforming raw HTML content into an appropriate document model
* Most importantly, updating the predictive model should require as little specialized developer interaction as possible; the app is intended to be a turn-key solution for our client, they have very-little in-house development capability, and we don't want to be on the hook for completely retraining their predictive models every month or two

So far, I've considered:

* Solr running on dedicated node + lucene classification API
* VW running on dedicated node in daemon mode performing online updates to the predictor model
* Cloud-based classification service like Alchemy API, et al

The cloud-based stuff is nice because we're a very small shop developing this app, and having a ""magic classification box"" would cut down on engineering and deployment overhead. However, they don't provide enough control/visibility into the classification process, as well as being too expensive.

Solr seems like a good approach, but we're wary of the complexity involved in setting up, administering, scaling, and interacting with the Solr stack. We don't currently want or need the ability to search the crawled data, so it seems like a lot of unnecessary overhead just for a binary text classification task. Assuming it scales, though, this approach does neatly solve the parallelization issue (each pipeline node can query the Solr server for both updates and predictions).

VW seems like it would be ideal for this application, but I'm not sure I'm ""doing it right"". Official documentation seems pretty sparse, and I've read lots of blog/forum/mailing-list posts which offer wildly varying approaches.

To wit:

1. If I run VW in daemon mode, will it handle concurrent streaming updates to the predictor? Can I use the same running daemon for both update and prediction operations?
2. If I use the daemon mode, do I just need to write plain ASCII-formatted examples to the socket daemon socket? Will unicode data work? How do read response data back?
3. Because I don't have a full corpus available, I can't do TF-IDF weighting. Some VW examples I've seen suggest that this isn't necessary. Stemming and stopwords seem like useful pre-processing steps to produce the document model, but apparently VW can do n-grams automatically. What would seem a likely effective document model for an arbitrary website based solely on the content and URL?
4. If I want VW to update the final predictor in a streaming, online fashion, what's the proper VW command-line invocation? They just added the ```--save_resume``` feature, does that do what I want?

Ultimately, the predictions don't have to be extremely precise (both false pos/neg predictions are fine to a degree), but we need the system to scale as the corpus grows and be pretty low-maintenance in the long run. 

If anyone out there has any insight about how best to implement a system like this, I'd very much appreciate it. Does Solr or VW make more sense here? Or something else? If VW is the way to go, can anyone provide a specific example demonstrating how to best process and format an HTML document into a valid VW example, train the predictor using VW daemon, and then perform a classification prediction (returning the classification along with some kind of accuracy metric) using VW? That would be incredibly helpful.",1,10
175,2014-2-26,2014,2,26,22,1yzjfy,Yoshua Bengio - Deep Learning of Representations: Looking Forward,https://www.reddit.com/r/MachineLearning/comments/1yzjfy/yoshua_bengio_deep_learning_of_representations/,zdwiel,1393421397,,0,6
176,2014-2-27,2014,2,27,0,1yzty3,Functional (semi technical) role in ML?,https://www.reddit.com/r/MachineLearning/comments/1yzty3/functional_semi_technical_role_in_ml/,cybernev,1393428788,"I have a Computer Science background and have taken up some Coursera classes on ML and have played around a bit but I am not very comfortable pursuing projects on my own which require coding. I am a Business Analyst (semi technical) by profession. 

I want to pursue further in ML professionally but I am not sure if there are Business Analyst or other semi-technical roles in ML. Are there? ",3,6
177,2014-2-27,2014,2,27,1,1yzxkq,Combining baseline predictor as in Netflix prize solution,https://www.reddit.com/r/MachineLearning/comments/1yzxkq/combining_baseline_predictor_as_in_netflix_prize/,srinathsmn,1393430924,"I've been reading few papers on how Netflix prize was won. One of the methods used by the winning team was to split the user-movie rating into various bias. For example, the movie rating by an user would be broken down into average rating of all movies + user bias + movie bias + user-movie interaction. I'm just wondering how this kind of split would solve the duplication of bias as in user-movie bias would definitely contain a part of user bias. The other question is, lets assume that the original rating for movie X from a Person Y was 4. Let the average rating across movie be 3. Let assume that Y always rate +1 more than average (across all movies) and X was always rated +1 more than average. Now if we would combine we would get a rating of &gt;= 5 (assuming user-movie interaction to be positive). How could we handle these kinds of scenarios?",3,8
178,2014-2-27,2014,2,27,3,1z09xj,"Free Online Machine Learning Course from Stanford begins on March 3rd, 2014",https://www.reddit.com/r/MachineLearning/comments/1z09xj/free_online_machine_learning_course_from_stanford/,furrytoothpick,1393437775,,19,79
179,2014-2-27,2014,2,27,8,1z17zm,Making sense of Data - free class from Google starts March 18 2014,https://www.reddit.com/r/MachineLearning/comments/1z17zm/making_sense_of_data_free_class_from_google/,cybernev,1393455791,,2,0
180,2014-2-27,2014,2,27,9,1z1ess,(X-post /r/robotics) Q-learning robot foosball,https://www.reddit.com/r/MachineLearning/comments/1z1ess/xpost_rrobotics_qlearning_robot_foosball/,somesaba,1393459651,,0,13
181,2014-2-27,2014,2,27,10,1z1o8f,How are LSTM filters (in/mem/out) set?,https://www.reddit.com/r/MachineLearning/comments/1z1o8f/how_are_lstm_filters_inmemout_set/,technotheist,1393465284,"Howdy, just a quick question on LSTM networks.
I understand pretty much how they work, except for every explanation or video lecture I've seen, they either gloss over or don't explain how the filters are set.
One lecture I saw said that the filters are usually binary (or the memory filter is), but still did not explain how that filter was set to 1 or 0.
Can someone please explain this to me?",4,10
182,2014-2-27,2014,2,27,10,1z1oob,Spark 0.9.0 released,https://www.reddit.com/r/MachineLearning/comments/1z1oob/spark_090_released/,turnersr,1393465563,,9,32
183,2014-2-27,2014,2,27,19,1z2qr9,Find Out Best Purlin Roll Forming Machine and Equipment in Chenqi,https://www.reddit.com/r/MachineLearning/comments/1z2qr9/find_out_best_purlin_roll_forming_machine_and/,shlytemple,1393496318,,0,1
184,2014-2-28,2014,2,28,2,1z3ok2,Supply and Demand Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1z3ok2/supply_and_demand_machine_learning/,Captain_Filmer,1393523160,"So I have a time series set of data and I need to be able to forecast out in the future, however the data is highly reliant on what we asked for (the number) and the rates associated with that number.  There are over 240,000 unique combinations that this data applies to.  Does anyone have any experience with this type of data, or any recommendations on what to check out in order to help with the forecasting?  Reference Forecasting seemed like my best bet so far, but I wasn't sure if there was some other algorithm that may prove useful.",6,9
185,2014-2-28,2014,2,28,16,1z5x29,Best Distribution Transformer Coil Winding Machines,https://www.reddit.com/r/MachineLearning/comments/1z5x29/best_distribution_transformer_coil_winding/,uday02,1393573644,,0,1
