,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-7-1,2018,7,1,11,8v6scy,Text generator based on pre existing text,https://www.reddit.com/r/MachineLearning/comments/8v6scy/text_generator_based_on_pre_existing_text/,daaavide,1530410959,"Hi, wondering if there is a text generator out there you could train with pre-existing text that could output a new version, maybe new ideas, at least new word associations, or similar themes etc? Or even new meaning pulled out assuming the data input will already color some of what is being generated.

Most of the things i found online are content spinners or total gibberish.

Thanks a lot in advance for the help!
",0,1
1,2018-7-1,2018,7,1,12,8v72jv,T2F: text to face generation using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8v72jv/t2f_text_to_face_generation_using_deep_learning/,akanimax,1530414173,,0,1
2,2018-7-1,2018,7,1,12,8v797z,Domain specific Machine learning or Pure Machine learning ?,https://www.reddit.com/r/MachineLearning/comments/8v797z/domain_specific_machine_learning_or_pure_machine/,soham97,1530416224,[removed],0,1
3,2018-7-1,2018,7,1,14,8v7p7g,100,https://www.reddit.com/r/MachineLearning/comments/8v7p7g/100/,Woodworking94,1530421223,,0,1
4,2018-7-1,2018,7,1,14,8v7q0f,The best approach to training RNNs - nlp,https://www.reddit.com/r/MachineLearning/comments/8v7q0f/the_best_approach_to_training_rnns_nlp/,sleebapaul,1530421466,[removed],0,1
5,2018-7-1,2018,7,1,15,8v86xu,Text to Speech Synthesis System Demo - Implementation of Tacotron End 2 End Speech Synthesis,https://www.reddit.com/r/MachineLearning/comments/8v86xu/text_to_speech_synthesis_system_demo/,Roots91,1530427550,,0,1
6,2018-7-1,2018,7,1,16,8v8b69,[N] Benchmarking the Full AI Hardware/Software Stack,https://www.reddit.com/r/MachineLearning/comments/8v8b69/n_benchmarking_the_full_ai_hardwaresoftware_stack/,mllosab,1530429158,,0,2
7,2018-7-1,2018,7,1,16,8v8h3p,[D] What is F-values used in Fitness-NMS paper?,https://www.reddit.com/r/MachineLearning/comments/8v8h3p/d_what_is_fvalues_used_in_fitnessnms_paper/,ml_carp,1530431652,"In the first paragraph of page 4, ""F values"" is introduced. What does this mean?

Also, I am confused by equation (5), because the formula does not seem to be an expectation of f_j.",1,0
8,2018-7-1,2018,7,1,17,8v8k31,[D] Is there an operation that corresponds to shifting the gradients on the backward pass?,https://www.reddit.com/r/MachineLearning/comments/8v8k31/d_is_there_an_operation_that_corresponds_to/,abstractcontrol,1530432886,"Multiplication has the property of scaling the gradients on the backwards pass, but addition lets them flow directly. I was wondering if there is a operation that corresponds to a shift?",8,2
9,2018-7-1,2018,7,1,17,8v8kuy,Advise on text/fuzzy matching machine learning model,https://www.reddit.com/r/MachineLearning/comments/8v8kuy/advise_on_textfuzzy_matching_machine_learning/,lovezhizhi,1530433189,[removed],0,1
10,2018-7-1,2018,7,1,17,8v8o0n,Decision Tree when sample is the whole population?,https://www.reddit.com/r/MachineLearning/comments/8v8o0n/decision_tree_when_sample_is_the_whole_population/,Sterlerg,1530434561,[removed],0,1
11,2018-7-1,2018,7,1,17,8v8q6p,suggestions for free online courses on deep learning?,https://www.reddit.com/r/MachineLearning/comments/8v8q6p/suggestions_for_free_online_courses_on_deep/,amansingh9097,1530435542,[removed],0,1
12,2018-7-1,2018,7,1,18,8v8qyq,Looking for picture enhancement routines.,https://www.reddit.com/r/MachineLearning/comments/8v8qyq/looking_for_picture_enhancement_routines/,KarlJay001,1530435888,[removed],0,1
13,2018-7-1,2018,7,1,18,8v8twx,Need paper on robbery detection,https://www.reddit.com/r/MachineLearning/comments/8v8twx/need_paper_on_robbery_detection/,junaidwahid,1530437196,[removed],0,1
14,2018-7-1,2018,7,1,19,8v9213,Getting started with Machine learning,https://www.reddit.com/r/MachineLearning/comments/8v9213/getting_started_with_machine_learning/,rohanmarwah,1530440852,[removed],0,1
15,2018-7-1,2018,7,1,19,8v9397,What the best of cnc machines?? How I got it that machine??,https://www.reddit.com/r/MachineLearning/comments/8v9397/what_the_best_of_cnc_machines_how_i_got_it_that/,Ibrahem91m,1530441394,[removed],0,1
16,2018-7-1,2018,7,1,19,8v94ff,[P] T2F: text to face generation using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8v94ff/p_t2f_text_to_face_generation_using_deep_learning/,akanimax,1530441905,,16,94
17,2018-7-1,2018,7,1,20,8v9701,The Alibaba tech team explored a new approach to voice recognition on mobile,https://www.reddit.com/r/MachineLearning/comments/8v9701/the_alibaba_tech_team_explored_a_new_approach_to/,mel_silizar,1530442991,,0,1
18,2018-7-1,2018,7,1,20,8v976t,[R] The Alibaba Tech Team Explored a New Approach to Voice Recognition on Mobile,https://www.reddit.com/r/MachineLearning/comments/8v976t/r_the_alibaba_tech_team_explored_a_new_approach/,mel_silizar,1530443059,,0,1
19,2018-7-1,2018,7,1,21,8v9gey,[R] Phase-Functioned Neural Networks for Character Control,https://www.reddit.com/r/MachineLearning/comments/8v9gey/r_phasefunctioned_neural_networks_for_character/,TopsyMitoTurvy,1530446712,,0,6
20,2018-7-1,2018,7,1,21,8v9kth,books on ml,https://www.reddit.com/r/MachineLearning/comments/8v9kth/books_on_ml/,itjustaspot,1530448294,[removed],0,1
21,2018-7-1,2018,7,1,21,8v9lhd,"[N] J.P. Morgan's data scientists are about to launch something wild [contest predicting ""the future of everything""]",https://www.reddit.com/r/MachineLearning/comments/8v9lhd/n_jp_morgans_data_scientists_are_about_to_launch/,phobrain,1530448513,,1,0
22,2018-7-1,2018,7,1,22,8v9u79,neural_style_transfer_app,https://www.reddit.com/r/MachineLearning/comments/8v9u79/neural_style_transfer_app/,rockstar1024,1530451187,,0,1
23,2018-7-2,2018,7,2,0,8vagaj,[R] Incremental Learning in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8vagaj/r_incremental_learning_in_deep_learning/,vector_machines,1530457289,,1,1
24,2018-7-2,2018,7,2,0,8vamyt,Is All of Machine Learning just Curve Fitting?,https://www.reddit.com/r/MachineLearning/comments/8vamyt/is_all_of_machine_learning_just_curve_fitting/,SpearMunkie,1530458943,[removed],0,1
25,2018-7-2,2018,7,2,1,8vax38,SciDex is creating a decentralized marketspace for data scientists and institutions,https://www.reddit.com/r/MachineLearning/comments/8vax38/scidex_is_creating_a_decentralized_marketspace/,scidex,1530461389,,0,1
26,2018-7-2,2018,7,2,1,8vb6c3,Datascience bootcamps,https://www.reddit.com/r/MachineLearning/comments/8vb6c3/datascience_bootcamps/,Cyalas,1530463595,[removed],0,1
27,2018-7-2,2018,7,2,2,8vbb6o,"I've read that the best way to learn is to teach, so here's an article I wrote on neural networks. I'd love to know from you folks how i can improve it.",https://www.reddit.com/r/MachineLearning/comments/8vbb6o/ive_read_that_the_best_way_to_learn_is_to_teach/,iamthefutureelon,1530464709,[removed],0,1
28,2018-7-2,2018,7,2,2,8vbkti,[P] ProGAN trained on r/EarthPorn images,https://www.reddit.com/r/MachineLearning/comments/8vbkti/p_progan_trained_on_rearthporn_images/,Yggdrasil524,1530466825,,86,758
29,2018-7-2,2018,7,2,3,8vbs9c,DevOps for Data Scientists: Taming the Unicorn  Towards Data Science,https://www.reddit.com/r/MachineLearning/comments/8vbs9c/devops_for_data_scientists_taming_the_unicorn/,snazrul,1530468490,,0,1
30,2018-7-2,2018,7,2,3,8vbykk,How does someone studying medicine get involved in deep learning?,https://www.reddit.com/r/MachineLearning/comments/8vbykk/how_does_someone_studying_medicine_get_involved/,withchemicals,1530469933,[removed],0,1
31,2018-7-2,2018,7,2,6,8vdbtm,[P] Generated cats in 256x256,https://www.reddit.com/r/MachineLearning/comments/8vdbtm/p_generated_cats_in_256x256/,AlexiaJM,1530481333,,1,1
32,2018-7-2,2018,7,2,7,8vdtf9,[D] NIPS 2018 review ethics: Too many papers to review and a few have shown up on arXiv?,https://www.reddit.com/r/MachineLearning/comments/8vdtf9/d_nips_2018_review_ethics_too_many_papers_to/,NIPSOverload,1530485720,"I just got hit with six papers to review for NIPS 2018, how do other reviewers get through this haul? I am not a PI, so I can't delegate these papers. I'm also seeing a portion of these papers showing up on arXiv, effectively removing the double-blind aspect of the authors. 

What's the best course of action here?",17,27
33,2018-7-2,2018,7,2,8,8ve0oj,"[P] A repository of SotA methods in computer vision + evaluations, papers, code, and pretrained models",https://www.reddit.com/r/MachineLearning/comments/8ve0oj/p_a_repository_of_sota_methods_in_computer_vision/,not_untrue,1530487605,,0,7
34,2018-7-2,2018,7,2,9,8vegq4,Help with multi-target prediction problem,https://www.reddit.com/r/MachineLearning/comments/8vegq4/help_with_multitarget_prediction_problem/,notjimmyproof,1530491807,[removed],0,1
35,2018-7-2,2018,7,2,9,8vejen,[D] Deep learning,https://www.reddit.com/r/MachineLearning/comments/8vejen/d_deep_learning/,NaiveImp,1530492486,"I'm taking a course in deep learning (CS231n from Stanford) and so far its pretty good, but i noticed that when mentioning neural network architectures there's almost always no explanation as to why this works, why GoogleNet's Inception layer or why ResNet's idea works, i maybe jumping the gun here but for people that are working (maybe in research?) on these subjects, is it always just trying parameter/architecture combinations and just seeing if it fits? 

If this is in the wrong place, excuse me!",20,8
36,2018-7-2,2018,7,2,10,8vevmu,"I've been collecting labeled car driving datasets for a while, and decided I'd put links to each dataset all in one place!",https://www.reddit.com/r/MachineLearning/comments/8vevmu/ive_been_collecting_labeled_car_driving_datasets/,Weihua99,1530495849,,0,1
37,2018-7-2,2018,7,2,11,8vf2bi,How to use GAN for image retrieval?,https://www.reddit.com/r/MachineLearning/comments/8vf2bi/how_to_use_gan_for_image_retrieval/,ivicts,1530497595,[removed],0,1
38,2018-7-2,2018,7,2,11,8vf8v9,"[R] ""Adversarial Reprogramming of Neural Networks"", Elsayed et al 2018 {GB} [CNNs are weird machines]",https://www.reddit.com/r/MachineLearning/comments/8vf8v9/r_adversarial_reprogramming_of_neural_networks/,gwern,1530499398,,6,16
39,2018-7-2,2018,7,2,12,8vfjy6,"Error in Machine Learning A-Z: Hands-On Python &amp; R In Data Science, Section 7, Lecture 67  r/learnmachinelearning",https://www.reddit.com/r/MachineLearning/comments/8vfjy6/error_in_machine_learning_az_handson_python_r_in/,mdmacidmthcoke,1530502510,,0,1
40,2018-7-2,2018,7,2,13,8vfqx4,[P]Finding High Accuracy Neural Network for Welding Defects Classification Using Efficient Neural Architecture Search via Parameter Sharing,https://www.reddit.com/r/MachineLearning/comments/8vfqx4/pfinding_high_accuracy_neural_network_for_welding/,first287,1530504572,,0,3
41,2018-7-2,2018,7,2,14,8vg2ox,Have you ever used that very handy machine?,https://www.reddit.com/r/MachineLearning/comments/8vg2ox/have_you_ever_used_that_very_handy_machine/,Woodworking94,1530508168,,0,1
42,2018-7-2,2018,7,2,14,8vgbp7,Why You Should Show Interest in Conversation Agent Guidelines?,https://www.reddit.com/r/MachineLearning/comments/8vgbp7/why_you_should_show_interest_in_conversation/,amberstevens311,1530511102,[removed],0,1
43,2018-7-2,2018,7,2,15,8vgers,Final call - AWS Hackdays | Special Edition Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8vgers/final_call_aws_hackdays_special_edition_machine/,JessiEE_HZx,1530512074,[removed],0,1
44,2018-7-2,2018,7,2,15,8vgfwl,What Does Everyone Think About the Conversational Assistant?,https://www.reddit.com/r/MachineLearning/comments/8vgfwl/what_does_everyone_think_about_the_conversational/,amberstevens311,1530512469,[removed],0,1
45,2018-7-2,2018,7,2,15,8vgi0i,[P] 4 Sequence Encoding Blocks You Must Know Besides RNN/LSTM in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8vgi0i/p_4_sequence_encoding_blocks_you_must_know/,h_xiao,1530513189,,4,12
46,2018-7-2,2018,7,2,15,8vgjps,8 Most Important Ways a Social Media Virtual Assistant Can Be Used,https://www.reddit.com/r/MachineLearning/comments/8vgjps/8_most_important_ways_a_social_media_virtual/,amberstevens311,1530513756,[removed],0,1
47,2018-7-2,2018,7,2,15,8vgkt3,[P] Self-driving car project for CS Capstone,https://www.reddit.com/r/MachineLearning/comments/8vgkt3/p_selfdriving_car_project_for_cs_capstone/,estmit,1530514112,"Hello r/MachineLearning,

Hope this is the right place to post this! I'm a CS grad student and for my capstone project (thesis) I was thinking of working on applying ML to self-driving cars. I am by no means a ML expert, and before I wander off into the wrong direction, I just wanted to get some input/suggestions/advice/thoughts from the sub. I only have 1 quarter (10 weeks) to get this done, and so I really need to limit my scope if I want the project to be relatively self-contained. 

Based on my research, there are only a few topics from which I can carve out realistic projects:

(1) object identification - cars/pedestrians/motorcycles etc

(2) tracking - predicting steering angles/acceleration/braking

(3) semantic image segmentation

There are surely plenty of datasets online, and I think there are some additional tools/simulators on Udacity's github page if I want to try working on option 2 (I am leaning towards working on option 2).

To those who are taking / took Udacity's self-driving car nanodegree and ML engineers who are actively working on self-driving car projects, I would especially love to get your thoughts! My goal is to deepen my ML knowledge (deep learning, deep reinforcement learning etc) and see I would potentially be interested in ML roles. Thank you!",6,8
48,2018-7-2,2018,7,2,15,8vgl5b,Can medical data be easily acquired with blockchain tech?,https://www.reddit.com/r/MachineLearning/comments/8vgl5b/can_medical_data_be_easily_acquired_with/,c1hyuk,1530514241,,0,3
49,2018-7-2,2018,7,2,16,8vgojb,Pitfalls of Batch Norm in TensorFlow and Sanity Checks for Training Networks,https://www.reddit.com/r/MachineLearning/comments/8vgojb/pitfalls_of_batch_norm_in_tensorflow_and_sanity/,coinmonks,1530515330,,0,1
50,2018-7-2,2018,7,2,16,8vgtqz,Getting count from Density maps,https://www.reddit.com/r/MachineLearning/comments/8vgtqz/getting_count_from_density_maps/,maazmikail,1530517114,[removed],0,1
51,2018-7-2,2018,7,2,17,8vh0bt,Confused about what machine learning actually is? Check out my blog for all the absolute beginners...,https://www.reddit.com/r/MachineLearning/comments/8vh0bt/confused_about_what_machine_learning_actually_is/,DitiModi,1530519521,,0,1
52,2018-7-2,2018,7,2,18,8vhduk,[R] Convergence Problems with Generative Adversarial Networks (GANs),https://www.reddit.com/r/MachineLearning/comments/8vhduk/r_convergence_problems_with_generative/,Exp5LogMingus,1530524608,,2,30
53,2018-7-2,2018,7,2,19,8vhj8y,[R] Why Russian to English is difficult for Machine Translation,https://www.reddit.com/r/MachineLearning/comments/8vhj8y/r_why_russian_to_english_is_difficult_for_machine/,alliscode,1530526505,,0,1
54,2018-7-2,2018,7,2,19,8vhjil,learning machine learnig,https://www.reddit.com/r/MachineLearning/comments/8vhjil/learning_machine_learnig/,Meepasour,1530526599,"I've been interested in machine learning for a while because of all the hype around it, but I have no idea on where to start and what resources I can use to learn as effectively as possible. So I'm just wondering if anyone out there knows a good source I can use for both the programming and the math. Thanks in advance. ",0,1
55,2018-7-2,2018,7,2,19,8vhk50,What is the biggest artificial neural network today?,https://www.reddit.com/r/MachineLearning/comments/8vhk50/what_is_the_biggest_artificial_neural_network/,chucke1992,1530526816,[removed],0,1
56,2018-7-2,2018,7,2,19,8vhljc,[R] Why Russian to English is difficult for Machine Translation,https://www.reddit.com/r/MachineLearning/comments/8vhljc/r_why_russian_to_english_is_difficult_for_machine/,kiarash-irandoust,1530527292,,0,1
57,2018-7-2,2018,7,2,19,8vhod9,Machine Learning &amp; AI Magazine,https://www.reddit.com/r/MachineLearning/comments/8vhod9/machine_learning_ai_magazine/,gufranmirza,1530528311,,0,2
58,2018-7-2,2018,7,2,19,8vhotf,How do you manage jobs on your GPU cluster?,https://www.reddit.com/r/MachineLearning/comments/8vhotf/how_do_you_manage_jobs_on_your_gpu_cluster/,RonnieSchaefer,1530528465,[removed],0,1
59,2018-7-2,2018,7,2,20,8vhwp2,Core Machine Learning- Advantages &amp; Disadvantages,https://www.reddit.com/r/MachineLearning/comments/8vhwp2/core_machine_learning_advantages_disadvantages/,jamielannisters,1530531094,[removed],0,1
60,2018-7-2,2018,7,2,20,8vhyak,[R] A New Angle on L2 Regularization,https://www.reddit.com/r/MachineLearning/comments/8vhyak/r_a_new_angle_on_l2_regularization/,pmigdal,1530531593,,32,165
61,2018-7-2,2018,7,2,20,8vhzi5,[R] High-resolution breast cancer screening with multi-view deep convolutional neural networks (TensorFlow and PyTorch models),https://www.reddit.com/r/MachineLearning/comments/8vhzi5/r_highresolution_breast_cancer_screening_with/,pmigdal,1530531957,,2,12
62,2018-7-2,2018,7,2,21,8vi2ef,"[N] Libratus, OpenAI Five, Common Sense AI, ARNN, Positive AI, WaveNet Stack, DARTS, ROAR,",https://www.reddit.com/r/MachineLearning/comments/8vi2ef/n_libratus_openai_five_common_sense_ai_arnn/,omarsar,1530532836,,0,1
63,2018-7-2,2018,7,2,21,8vi5rq,[R] Statistics for Evaluating Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/8vi5rq/r_statistics_for_evaluating_machine_learning/,polllyyy,1530533739,,0,1
64,2018-7-2,2018,7,2,21,8vicgg,[N] Personalized deep learning equips robots for autism therapy,https://www.reddit.com/r/MachineLearning/comments/8vicgg/n_personalized_deep_learning_equips_robots_for/,molode,1530535602,,0,1
65,2018-7-2,2018,7,2,21,8vid11,[R] How to use Machine Learning and Quilt to Identify Buildings in Satellite Images,https://www.reddit.com/r/MachineLearning/comments/8vid11/r_how_to_use_machine_learning_and_quilt_to/,digitalson,1530535759,,0,1
66,2018-7-2,2018,7,2,22,8vig86,learning ML,https://www.reddit.com/r/MachineLearning/comments/8vig86/learning_ml/,Meepasour,1530536590,[removed],0,1
67,2018-7-2,2018,7,2,22,8visuy,Sesame Tahini Grinder Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/8visuy/sesame_tahini_grinder_machine_for_sale/,gelserena,1530539620,,1,1
68,2018-7-2,2018,7,2,22,8vitaw,Federated learning with keras,https://www.reddit.com/r/MachineLearning/comments/8vitaw/federated_learning_with_keras/,thunderstorm612,1530539734,[removed],0,1
69,2018-7-2,2018,7,2,22,8viubu,Enso: Benchmark Pretrained Text Embeddings on 2 Dozen Classification Tasks,https://www.reddit.com/r/MachineLearning/comments/8viubu/enso_benchmark_pretrained_text_embeddings_on_2/,madisonmay,1530539970,,0,1
70,2018-7-2,2018,7,2,23,8vix6k,Anyone know what AlphaDropout on PyTorch doesnt work on eval() mode?,https://www.reddit.com/r/MachineLearning/comments/8vix6k/anyone_know_what_alphadropout_on_pytorch_doesnt/,Tanavast,1530540605,[removed],0,1
71,2018-7-2,2018,7,2,23,8vizi0,"The best way to learn something is to teach it. So i wrote an article on neural networks, I'd like to get since feedback from experts like you.",https://www.reddit.com/r/MachineLearning/comments/8vizi0/the_best_way_to_learn_something_is_to_teach_it_so/,iamthefutureelon,1530541152,,0,1
72,2018-7-2,2018,7,2,23,8vj06c,  ,https://www.reddit.com/r/MachineLearning/comments/8vj06c/_/,Woodworking94,1530541313,,0,1
73,2018-7-2,2018,7,2,23,8vj25u,Wheres is a good place to start?,https://www.reddit.com/r/MachineLearning/comments/8vj25u/wheres_is_a_good_place_to_start/,tsims25,1530541759,[removed],0,1
74,2018-7-2,2018,7,2,23,8vj32o,Blog: What service assurance challenges can be addressed with AI/machine learning,https://www.reddit.com/r/MachineLearning/comments/8vj32o/blog_what_service_assurance_challenges_can_be/,ennissh,1530541954,,0,1
75,2018-7-2,2018,7,2,23,8vj3il,[P] Enso: Benchmark Text Embeddings on 2 Dozen Classification Tasks,https://www.reddit.com/r/MachineLearning/comments/8vj3il/p_enso_benchmark_text_embeddings_on_2_dozen/,madisonmay,1530542054,,2,14
76,2018-7-2,2018,7,2,23,8vj96w,Microsoft Releases v0.13 of their Distributed ML Library,https://www.reddit.com/r/MachineLearning/comments/8vj96w/microsoft_releases_v013_of_their_distributed_ml/,mhamilton723,1530543348,,0,1
77,2018-7-2,2018,7,2,23,8vja92,Number of output nodes of policy network AlphaZero for chess?,https://www.reddit.com/r/MachineLearning/comments/8vja92/number_of_output_nodes_of_policy_network/,stanniemanni,1530543587,[removed],0,1
78,2018-7-3,2018,7,3,0,8vjagz,Sentiment analysis with Word2Vec - Issue,https://www.reddit.com/r/MachineLearning/comments/8vjagz/sentiment_analysis_with_word2vec_issue/,khamzah22,1530543633,[removed],0,1
79,2018-7-3,2018,7,3,0,8vjait,[N] Microsoft releases v0.13 of its new distributed ML library,https://www.reddit.com/r/MachineLearning/comments/8vjait/n_microsoft_releases_v013_of_its_new_distributed/,mhamilton723,1530543643,,2,8
80,2018-7-3,2018,7,3,0,8vjbbq,"Published my blog on Self-Attention GANs by the GANfather, Ian Goodfellow",https://www.reddit.com/r/MachineLearning/comments/8vjbbq/published_my_blog_on_selfattention_gans_by_the/,divyanshjha,1530543799,,0,1
81,2018-7-3,2018,7,3,0,8vjbof,Recognising people belonging to same family tree,https://www.reddit.com/r/MachineLearning/comments/8vjbof/recognising_people_belonging_to_same_family_tree/,deepKrish,1530543875,[removed],0,1
82,2018-7-3,2018,7,3,0,8vjbzl,What's the best machine learning course for a beginner?,https://www.reddit.com/r/MachineLearning/comments/8vjbzl/whats_the_best_machine_learning_course_for_a/,SuccessfulLeadership,1530543948,[removed],0,1
83,2018-7-3,2018,7,3,0,8vjgzh,Judea Pearl new book thoughts?,https://www.reddit.com/r/MachineLearning/comments/8vjgzh/judea_pearl_new_book_thoughts/,prescriptionclimatef,1530545064,[removed],0,1
84,2018-7-3,2018,7,3,0,8vji1s,Getting started with TensorFlow.js: Linear Regression,https://www.reddit.com/r/MachineLearning/comments/8vji1s/getting_started_with_tensorflowjs_linear/,tristansokol,1530545321,,0,1
85,2018-7-3,2018,7,3,2,8vkcrw,GAN: Should the learning rate of Discriminator and Generator be same? why/why not?,https://www.reddit.com/r/MachineLearning/comments/8vkcrw/gan_should_the_learning_rate_of_discriminator_and/,Naughty_Nagaland,1530551504,[removed],0,1
86,2018-7-3,2018,7,3,2,8vkohg,Why Elon Musk Is Scared For The Future Of AI | Tech Valve EP.1,https://www.reddit.com/r/MachineLearning/comments/8vkohg/why_elon_musk_is_scared_for_the_future_of_ai_tech/,dyf360,1530553809,,0,1
87,2018-7-3,2018,7,3,3,8vkskn,What are the extra fields being left to apply deep learning?,https://www.reddit.com/r/MachineLearning/comments/8vkskn/what_are_the_extra_fields_being_left_to_apply/,amit2rockon,1530554612,[removed],0,1
88,2018-7-3,2018,7,3,3,8vkz5o,"Keras Layers cheat sheet, written for the Metis curriculum",https://www.reddit.com/r/MachineLearning/comments/8vkz5o/keras_layers_cheat_sheet_written_for_the_metis/,hergertarian,1530555944,[removed],0,1
89,2018-7-3,2018,7,3,3,8vl20a,How I built a Self Flying Drone to track People in under 50 lines of code,https://www.reddit.com/r/MachineLearning/comments/8vl20a/how_i_built_a_self_flying_drone_to_track_people/,nanonets,1530556514,,0,1
90,2018-7-3,2018,7,3,4,8vldzl,[D] Anyone here worked with embeddings training (ie Word2Vec? ). Do you have any training / optimization tips?,https://www.reddit.com/r/MachineLearning/comments/8vldzl/d_anyone_here_worked_with_embeddings_training_ie/,BatmantoshReturns,1530558902,"I'm using a Word2Vec cbow-based algorithm to train embeddings for a particular set of items; it's not words so I can't use any pre-trained embeddings. The training has plateaued, and I was wondering if there's anything I can do to further optimize the embeddings. I randomly tried a smaller batch size (64) and that had a significant impact on the quality of the embeddings (I had been using 128 and 256 before). I wondering if there's any other tips/tricks I can try out before wrapping it out.

For those who have worked with embeddings, do you have any tips for training and optimization. Batch size, optimizer type (adam or adagrad), etc?

I also have a specific question. When doing Cbow-based models, should the softmax embeddings for a particular item be most similar to the regular embeddings for that same item?

If I do a similarity search (based on dot product) of an Item's embedding to the softmax embedding matrix, the original item is usually not the first one returned, usually not even in the top 3. The original item is usually in the top 5-20.

I would imagine is that for cbow, that the model would eventually pickup that that a particular item's regular embeddings matches the one in the softmax embeddings, even though it's tricky because the average is always taken between 2-6 other embeddings. So I am wondering if I need to optimize the parameters more.",0,2
91,2018-7-3,2018,7,3,4,8vlj8v,[D]Will a site that promotes uses of ML for humanity ever work?,https://www.reddit.com/r/MachineLearning/comments/8vlj8v/dwill_a_site_that_promotes_uses_of_ml_for/,vnjxk,1530560012,"So I just thought about making a site for combined research and work towards making the world a better place using AI.

but I'm not sure if I should even bother making it and then no one would use it so I'm asking for your opinion on such site and if you would see your self contribute to it.

A more detailed explanation of it:

&gt;There would be categories of issues (environment, health ,Education ,etc..) and in each there would  
&gt;  
&gt;be a number of issues (opened by people I presume?)  
&gt;  
&gt;In each issue there would be:  
&gt;  
&gt;	**Generic information:**  
&gt;  
&gt;	title, description of the issue  
&gt;  
&gt;	**Importance:**  
&gt;  
&gt;	Upvote on a scale of how important and urgent this is.  
&gt;  
&gt;	**Initiative:**  
&gt;  
&gt;	What you could do to help?  
&gt;  
&gt;	Research and build a model for proposed solutions  
&gt;  
&gt;	manually collecting , sorting, labelling data (so everyone could help)  
&gt;  
&gt;	**Discussion &amp; Wiki:**  
&gt;  
&gt;	Some sort of simple but categorised discussion&amp;wiki to help the organisation.

An example could be:

Issue:Environment / lots of plastic in trash

proposed solution:use camera to sort it out and recycle

everyone could:gather pictures of trash, sort and label those

researchers: build and train a model to try and fix the issue

# I wrote it in 10 minutes so this probably have many issues in it, please ignore these and focus on the general idea.

so what do you think? will it work or will it just be a waste of time to make?",5,3
92,2018-7-3,2018,7,3,4,8vlmgq,Most underrated Unsupervised Learning Algorithm,https://www.reddit.com/r/MachineLearning/comments/8vlmgq/most_underrated_unsupervised_learning_algorithm/,keysersoze977,1530560708,[removed],0,1
93,2018-7-3,2018,7,3,5,8vlw9h,New to ML - Need advice as to where to get started on the attached project,https://www.reddit.com/r/MachineLearning/comments/8vlw9h/new_to_ml_need_advice_as_to_where_to_get_started/,jamieglazier,1530562758,"Hi All, 

Thanks in advance for any pointers - looking to get started on a Machine Learning project (Advised) &amp; have experience in Java, JS, Hadoop, SQL &amp; Scala. Would appreciate some advice as to which platform to use, whether there are any similar projects I can piggy-back on &amp; methodology I should follow.

I have a huge Structured Data set consisting of Child &amp; Parent data.

The Parent data as an example contains a Car, with the name, description, Sometimes cost information. I can pull in more fields, these are some examples.

The Child data will contain of related things to the car, i.e. Cars with different options, parts within the car etc, in the same format as the Parent data.

For each Parent we typically need to chose the most relevant match, i.e. are the name columns similar, which child cost is closest to the parent cost, does the description mention this as an option, i.e. a different colour, are there similar matches we've previously paired whose serials match etc, Which matching item is the most similar to what has been chosen before etc.

Occasionally there may be multiple matches, however typically only one.

A pairing between the Parent &amp; Relevant/Rarely multiple records should then be made.

Please let me know if you have any questions, appreciate the advice!",0,1
94,2018-7-3,2018,7,3,5,8vm7lu,[D] ML things to get a hold on during a week,https://www.reddit.com/r/MachineLearning/comments/8vm7lu/d_ml_things_to_get_a_hold_on_during_a_week/,tminima,1530565168,"I have a lot of leaves available with me (25+) so I have decided to get a better hold on my skills along with some travel. During each month till December, for a week (7-9 days), I am thinking of going to some place away from home and then just study on a topic with some amount of travel here and there (1-2 days maybe). So, I'll have 5 such study periods.

My interests are in

- NLP (NER, text generation, text classification, etc)
- Recommendation Engines
- Visualization
- Kaggle kind of data science problems (data exploration, building a ML model to solve a problem, presenting the results)

I don't have much interest in CV. I am okay with reading books, watching courses, reading and implementing papers. Obviously, I understand, I can't just grasp the whole domain in 7 days, but I can get a deeper overview of the field and possibly apply it further into my job or personal projects or Kaggle.

Can anyone suggest what themes can I cover during these 5 study periods. I was thinking to work on fast.ai deep learning course, but I don't think it's a 1 week thing. I had this idea of rigorously working on the basics - linear algebra, probability theory, stats. How can I structure these 3 topics among 5 weeks? And, if there is something better, I am open to suggestions.",8,8
95,2018-7-3,2018,7,3,6,8vm7ur,Image recognition of parts possibly with DeepLens,https://www.reddit.com/r/MachineLearning/comments/8vm7ur/image_recognition_of_parts_possibly_with_deeplens/,wopalot,1530565219,"I'm working on a project to see if we can get a system up that can accurately identify parts that can sometimes be very similar. I was hoping to hear about any experiences or suggestions that you all might have for the AWS DeepLens or image recognition with Python. I've included an example of two similar parts that we're trying to differentiate.

Thank you!",0,1
96,2018-7-3,2018,7,3,6,8vmlpk,Does anyone want to make a model with me?,https://www.reddit.com/r/MachineLearning/comments/8vmlpk/does_anyone_want_to_make_a_model_with_me/,JoelCDeleon,1530568157,[removed],0,1
97,2018-7-3,2018,7,3,7,8vmsmv,Confused about how to define features,https://www.reddit.com/r/MachineLearning/comments/8vmsmv/confused_about_how_to_define_features/,PhD_BME_job,1530569654,[removed],0,1
98,2018-7-3,2018,7,3,7,8vmuet,[D] What deep learning papers should I implement to learn?,https://www.reddit.com/r/MachineLearning/comments/8vmuet/d_what_deep_learning_papers_should_i_implement_to/,pandeykartikey,1530570046,"I  have been wanting to implement a Deep Learning Paper to get some  hands on the current state of the art model or current field of  research. But, generally the paper I pickup is a bit tough to  understand. So, I was looking if anyone could suggest me a paper which  would be some latest research but slightly easier to grasp?",38,240
99,2018-7-3,2018,7,3,8,8vnbd5,What do you guys feel about the future of ML,https://www.reddit.com/r/MachineLearning/comments/8vnbd5/what_do_you_guys_feel_about_the_future_of_ml/,i_like_beluga_whales,1530573990,[removed],0,1
100,2018-7-3,2018,7,3,9,8vnr7g,[D] Idea for GAN with Memory for Text QA,https://www.reddit.com/r/MachineLearning/comments/8vnr7g/d_idea_for_gan_with_memory_for_text_qa/,throwaway775849,1530577824,"**Generator**
    f(x, memory_t) = y, memory_t+1


**Discriminator**
    g(x, y, memory_t) = score


This is for the purpose of question answering or conversation. I found this architecture unique, because of the shared component of memory between the gen./disc., but I haven't read any GAN papers in the last year so maybe it's already been done?


I arrived at an adversarial model because (and general thoughts):


* The model needs memory for sequences. Quick proof by example: As a human evaluator, if we give the model some new input (x) like ""Who is Yann LeCun"" and we know that is outside the training data, then a perfectly ok output is ""I don't know."". So the correct answer requires some estimation of the model itself (which it's memory implicitly contains).

* human estimation of the model's knowledge / understanding 
    k = e(memory)

* our score of an answer's correctness is a function of the input, the response, and our projection of the model's knowledge.
    score = s(x, y, k)


So to produce a good output (y) after training, during training the model will be implicitly estimating ""s"", a function of it's own output and state. It seemed natural since there are two update steps, to let a generator create responses and a discriminator implicitly maximize the probability of y given the input and memory. 

The discriminator should guide the memory to contain a lot of abstract generalization, because almost every response (y) imaginable could be classified as false, when the memory state does not contain the explicit knowledge to create the response. So to classify any response as a sample that actually came from the generator, the discriminator will have to encode generalizations about producing that response into memory (assuming it can't update x).

I'm probably confounding some concepts, but it felt novel and I thought I'd share. What do you think?",5,7
101,2018-7-3,2018,7,3,10,8voal0,Unsupervised Learning by Competing Hidden Units,https://www.reddit.com/r/MachineLearning/comments/8voal0/unsupervised_learning_by_competing_hidden_units/,PlentifulCoast,1530582329,,3,10
102,2018-7-3,2018,7,3,11,8voojf,Any resource on implementing real time object detection in PyTorch?,https://www.reddit.com/r/MachineLearning/comments/8voojf/any_resource_on_implementing_real_time_object/,hardhat528491,1530585750,[removed],0,1
103,2018-7-3,2018,7,3,12,8voy1v,Great! ! ! 2018 Top 5 World's Most Modern Agricultural Machinery,https://www.reddit.com/r/MachineLearning/comments/8voy1v/great_2018_top_5_worlds_most_modern_agricultural/,Woodworking94,1530588306,,0,1
104,2018-7-3,2018,7,3,13,8vpaco,[P] AdamW and Super-convergence is now the fastest way to train neural nets,https://www.reddit.com/r/MachineLearning/comments/8vpaco/p_adamw_and_superconvergence_is_now_the_fastest/,xternalz,1530591732,,40,124
105,2018-7-3,2018,7,3,13,8vpe3j,[P] Python package for ProGAN using PyTorch,https://www.reddit.com/r/MachineLearning/comments/8vpe3j/p_python_package_for_progan_using_pytorch/,akanimax,1530592777,,10,19
106,2018-7-3,2018,7,3,13,8vpfha,[D] Reliable sites that give good summaries of recent papers,https://www.reddit.com/r/MachineLearning/comments/8vpfha/d_reliable_sites_that_give_good_summaries_of/,Sherbhy,1530593179,http://www.shortscience.org is one,1,6
107,2018-7-3,2018,7,3,14,8vpll0,SotA reinforcement learning algorithms,https://www.reddit.com/r/MachineLearning/comments/8vpll0/sota_reinforcement_learning_algorithms/,Modatu,1530594928,[removed],0,1
108,2018-7-3,2018,7,3,14,8vpolf,last week in machine learning predicting earthquakes teaching robots and more-,https://www.reddit.com/r/MachineLearning/comments/8vpolf/last_week_in_machine_learning_predicting/,Hackdhacker,1530595828,,0,1
109,2018-7-3,2018,7,3,14,8vpp4b,[R] Policy Optimization with Demonstrations (ICML'18),https://www.reddit.com/r/MachineLearning/comments/8vpp4b/r_policy_optimization_with_demonstrations_icml18/,jeasinema,1530595978,,2,3
110,2018-7-3,2018,7,3,15,8vpy5k,Core Machine Learning- Advantages &amp; Disadvantages,https://www.reddit.com/r/MachineLearning/comments/8vpy5k/core_machine_learning_advantages_disadvantages/,jamielannisters,1530598885,[removed],0,1
111,2018-7-3,2018,7,3,15,8vpyt6,Bevel gears in Singapore,https://www.reddit.com/r/MachineLearning/comments/8vpyt6/bevel_gears_in_singapore/,YuchunSg,1530599087,[removed],0,1
112,2018-7-3,2018,7,3,16,8vqfam,[D] What is machine learning,https://www.reddit.com/r/MachineLearning/comments/8vqfam/d_what_is_machine_learning/,John1807,1530604610,,0,1
113,2018-7-3,2018,7,3,17,8vqmw8,Machine learning and heart pacemakers,https://www.reddit.com/r/MachineLearning/comments/8vqmw8/machine_learning_and_heart_pacemakers/,wsdookadr,1530607474,[removed],0,1
114,2018-7-3,2018,7,3,17,8vqn27,Seek for efficient way to frame an image,https://www.reddit.com/r/MachineLearning/comments/8vqn27/seek_for_efficient_way_to_frame_an_image/,flyingmrwang,1530607530,[removed],0,1
115,2018-7-3,2018,7,3,17,8vqnnx,Can anyone explain me the difference between fit and fit_transform in sci-kit learn library?,https://www.reddit.com/r/MachineLearning/comments/8vqnnx/can_anyone_explain_me_the_difference_between_fit/,Bob_11,1530607760,[removed],0,1
116,2018-7-3,2018,7,3,18,8vqpxu,Too soon?,https://www.reddit.com/r/MachineLearning/comments/8vqpxu/too_soon/,aidendempst,1530608568,,0,1
117,2018-7-3,2018,7,3,18,8vqwoc,"Comparison of top data science libraries for Python, R and Scala [Infographic]",https://www.reddit.com/r/MachineLearning/comments/8vqwoc/comparison_of_top_data_science_libraries_for/,viktoriia_shulga,1530610968,,0,10
118,2018-7-3,2018,7,3,18,8vqypb,Whatre the best Deep *RL* rigs? Most current suggestions dont take into account running multiple (often CPU intensive) simulated environments simultaneously.,https://www.reddit.com/r/MachineLearning/comments/8vqypb/whatre_the_best_deep_rl_rigs_most_current/,evc123,1530611679,[removed],0,1
119,2018-7-3,2018,7,3,18,8vqzdx,[D] Whatre the best Deep *RL* rigs? Most current suggestions dont take into account running multiple (often CPU intensive) simulated environments simultaneously.,https://www.reddit.com/r/MachineLearning/comments/8vqzdx/d_whatre_the_best_deep_rl_rigs_most_current/,evc123,1530611920," Whats the best (DIY bang for the buck) Deep**Reinforcement**Learning rig? Most current suggestions dont take into account running the (often CPU intensive) simulated environments simultaneously; e.g. this is a popular post that doesnt:[https://blog.slavv.com/the-1700-great-deep-learning-box-assembly-setup-and-benchmarks-148c5ebe6415](https://blog.slavv.com/the-1700-great-deep-learning-box-assembly-setup-and-benchmarks-148c5ebe6415)

  
In my case I**already have a 1080 Ti GPU**, but Im not sure how many cores/threads the CPU should have to make sure new environment simulation is being generated at rate that maximizes 1080 Ti GPU throughput.

I mostly plan to run simple lofi 2D/3D games like atari &amp; DOOM for now; I might run more intensive environments in MuJoCo (or Unity which might complicate things because many Unity envs can be sped up by GPU) later.

How many cpu cores/threads would optimal for simple lofi 2D/3D games? &amp; how many would be optimal for more intensive environments in MuJoCo or Unity?",3,0
120,2018-7-3,2018,7,3,19,8vr3au,"Is there a lightweight, fast facial recognization SDK for Android platform?",https://www.reddit.com/r/MachineLearning/comments/8vr3au/is_there_a_lightweight_fast_facial_recognization/,bruceli,1530613166,We are going to develop facial recognization feature for our Android based device. It's not very powerful. And we need to do it offline. Thanks for recommendations.,0,1
121,2018-7-3,2018,7,3,19,8vr4xf,Is there a reason that Inception-based architectures don't tend to be used for pretrained feature extraction?,https://www.reddit.com/r/MachineLearning/comments/8vr4xf/is_there_a_reason_that_inceptionbased/,pedalstiffcranks,1530613726,[removed],0,1
122,2018-7-3,2018,7,3,19,8vr80f,Coding Gaussian Likelihood (VAE),https://www.reddit.com/r/MachineLearning/comments/8vr80f/coding_gaussian_likelihood_vae/,going_with_d_flow,1530614785,[removed],0,1
123,2018-7-3,2018,7,3,19,8vr9am,[R] The relativistic discriminator: a key element missing from standard GAN,https://www.reddit.com/r/MachineLearning/comments/8vr9am/r_the_relativistic_discriminator_a_key_element/,AlexiaJM,1530615207,,38,141
124,2018-7-3,2018,7,3,19,8vr9it,[P] Machine Learning with ML.NET  Solving Real-World Classification Problem (Wine Quality),https://www.reddit.com/r/MachineLearning/comments/8vr9it/p_machine_learning_with_mlnet_solving_realworld/,RubiksCodeNMZ,1530615278,,0,1
125,2018-7-3,2018,7,3,19,8vra3o,Are there any open source videos of football matches that could be used to train things like tactics and strategy?,https://www.reddit.com/r/MachineLearning/comments/8vra3o/are_there_any_open_source_videos_of_football/,x3derr8orig,1530615472,[removed],0,1
126,2018-7-3,2018,7,3,20,8vrb7m,Adaptive Blending Units,https://www.reddit.com/r/MachineLearning/comments/8vrb7m/adaptive_blending_units/,PeppermintPrince,1530615810,,1,5
127,2018-7-3,2018,7,3,20,8vrcx6,isuzu worldwide parts manual,https://www.reddit.com/r/MachineLearning/comments/8vrcx6/isuzu_worldwide_parts_manual/,Mypremiummanual,1530616341,,0,1
128,2018-7-3,2018,7,3,20,8vrflq,[D] The Challenges of AI Communication,https://www.reddit.com/r/MachineLearning/comments/8vrflq/d_the_challenges_of_ai_communication/,omarsar,1530617177,,0,1
129,2018-7-3,2018,7,3,20,8vrfm6,[N] New Something-Something Dataset V2 for Visual Common Sense &amp; Video Understanding,https://www.reddit.com/r/MachineLearning/comments/8vrfm6/n_new_somethingsomething_dataset_v2_for_visual/,nahuak,1530617180,,1,1
130,2018-7-3,2018,7,3,20,8vrfmx,Prediction in FX markets using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8vrfmx/prediction_in_fx_markets_using_machine_learning/,alpha_quant,1530617186,"Machine Learning is a magic word that has invaded to our lives and it seems that most people consider it as a magic solution that will resolve all the issues of the humanity.

Same happens with the trading community: a large number of scientific papers have been released recently regarding the ability of machine learning to predict the markets. Before we give our opinion about machine learning and financial markets, lets present some basics and fundamentals of machine learning.

**Machine learning has nothing to do with engines, pistons and steam. Machine learning is an application of Artificial Intelligence where a system can learn and improve the knowledge and the experience of the past without being programmed explicitly**. All of us gather information and experiences from the growing and living environment and we use it to distinguish patterns and behaviours so we can act better. Nobody has to tell us that we should not walk in the rain because if we have experienced it some times and we got the flu, we know that we should avoid it. Same way, most of us met a new word in our vocabulary that we dont understand but we can comprehend it from the whole meaning of a sentence. **Machine learning algorithms, more or less, work at the same way: they make better future decisions based on the knowledge and the patterns of the past.**

Machine learning algorithms are divided in many categories, we will present the two main categories according to the output:

*  **Regression  numerical prediction of a quantity.** If this quantity is time based we call it a timeseries prediction (for example, daily temperature prediction based on temperature measures of the past)
*  **Classification  prediction of a class or a category of an underlying example** (for example, face recognition)

If we want to apply all the above to the financial markets industry, the questions are very strict**:** [can we predict the markets?](https://algo-profits.com/fx24-signals/) **If yes, can we apply the regression machine learning algorithms or the classification ones?** Well theres no safe answer. We dont know what will happen in the future if the technology and mathematics provide us new tools and potentials. Theres something more important though: **Humanity feeds the world web with data with an exponential rate**. Billions of new data appear every day and the scientific community tends to believe that **the quantity and the quality of data is more preferable than complex algorithms**. We agree with this opinionif we want to learn a foreign language, the best method is to receive the basic knowledge and the to expose ourselves to speak with native speakers. It will produce better learning results than the method of studying everything about the language and then trying to talk with native speakers. **At least, there are people that have learnt a foreign language by living in another country without ever opening a book.**

Lets get back to the machine learning and financial markets. **Our opinion is that we cannot predict the markets numerically.** **Theres a huge amount of noise and millions of factors that define and influence the price of an asset.** With classification machine learning algorithms, things are better. **We can create two classes UP/DOWN, LONG/SHORT, BULL/BEAR**whatever you prefer and we can apply classification algorithms. **In other words, if we cannot predict the price of an asset we can try to predict its trend. Since we know the trend with a certain and quantified probability, there are experienced and mature traders that can take advantage of it making a lot of profit. Even better, we can use automated strategies that will remove all the discretionary disadvantages of manual trading. The problem then is translated to the simple sentence: since we know the market direction, what is the optimum entry and exit point.** 

Machine learning has also another serious aspect which is called features selection. It means that we should feed a machine learning algorithm with the correct features in order to achieve better results. For example. If we want to learn a foreign language we should use vocabulary, grammar, spelling and idioms but if we want to learn a programming language its obvious that these features are wrong. So, the architects and the developers of a machine learning system for the financial markets must have deep knowledge of the trading industry in order to select the correct and efficient features.

Of course, tones of other issues should be resolved like overfitting but this article has no intention to provide a machine learning tutorial. ",0,1
131,2018-7-3,2018,7,3,20,8vrlc5,"What is the difference between #DataAnalytics, #DataAnalysis, #DataMining, #DataScience, #MachineLearning, and #BigData?",https://www.reddit.com/r/MachineLearning/comments/8vrlc5/what_is_the_difference_between_dataanalytics/,phdassistance18,1530618942,[removed],0,0
132,2018-7-3,2018,7,3,20,8vrlg8,[P] Predicting behavior using brainwave (eeg) signals,https://www.reddit.com/r/MachineLearning/comments/8vrlg8/p_predicting_behavior_using_brainwave_eeg_signals/,thatwasfornaught,1530618974,[removed],0,1
133,2018-7-3,2018,7,3,21,8vrqs5,Need some advice - career changer,https://www.reddit.com/r/MachineLearning/comments/8vrqs5/need_some_advice_career_changer/,ac2uary,1530620442,[removed],0,1
134,2018-7-3,2018,7,3,21,8vrznq,How I built a Self Flying Drone to track People in under 50 lines of code,https://www.reddit.com/r/MachineLearning/comments/8vrznq/how_i_built_a_self_flying_drone_to_track_people/,nanonets,1530622760,,0,1
135,2018-7-3,2018,7,3,22,8vs2j6,How I built a Self Flying Drone to track People in under 50 lines of code,https://www.reddit.com/r/MachineLearning/comments/8vs2j6/how_i_built_a_self_flying_drone_to_track_people/,anonymous-founder,1530623425,,0,1
136,2018-7-3,2018,7,3,22,8vs8ps,How to solve dynamic clustering problem,https://www.reddit.com/r/MachineLearning/comments/8vs8ps/how_to_solve_dynamic_clustering_problem/,arush1836,1530624925,[removed],0,1
137,2018-7-3,2018,7,3,23,8vsj0m,[P] Suggestion for Final Year Project using Machine Learning / AI,https://www.reddit.com/r/MachineLearning/comments/8vsj0m/p_suggestion_for_final_year_project_using_machine/,LonelyToh,1530627301,"Can anyone give any suggestion for my FYP I'm currently taking [Degree]Bachelor of Computer Science Major in Data Science. Hoping to see some reply with title, what's the problem and what's the ending result after created the project.",0,0
138,2018-7-3,2018,7,3,23,8vsoi9,[N] Chinese Paper Demonstrates World's First 18-Qubit Entanglement With Photon,https://www.reddit.com/r/MachineLearning/comments/8vsoi9/n_chinese_paper_demonstrates_worlds_first_18qubit/,gwen0927,1530628528,,0,1
139,2018-7-3,2018,7,3,23,8vsv4k,Why combine has not dropped ticket and cabin?,https://www.reddit.com/r/MachineLearning/comments/8vsv4k/why_combine_has_not_dropped_ticket_and_cabin/,Daredoom,1530629945,,0,1
140,2018-7-4,2018,7,4,0,8vsztr,,https://www.reddit.com/r/MachineLearning/comments/8vsztr//,Woodworking94,1530630929,,0,1
141,2018-7-4,2018,7,4,0,8vtce3,"MLflow 0.2 Released: Try new features with TensorFlow integration, Tracking Server updates, and S3 storage",https://www.reddit.com/r/MachineLearning/comments/8vtce3/mlflow_02_released_try_new_features_with/,dmatrixjsd,1530633583,,0,1
142,2018-7-4,2018,7,4,1,8vtj9j,[N] Deploy State-of-the-Art Deep Learning on Edge Devices in Minutes,https://www.reddit.com/r/MachineLearning/comments/8vtj9j/n_deploy_stateoftheart_deep_learning_on_edge/,DrDetection,1530634937,,2,3
143,2018-7-4,2018,7,4,1,8vtpo5,[P] I made a website which uses fair item assignment and a constraint solver to find an optimal allocation of tasks/chores (experimental),https://www.reddit.com/r/MachineLearning/comments/8vtpo5/p_i_made_a_website_which_uses_fair_item/,sanity,1530636234,"I'm a researcher and am hoping to get some feedback on an experiment of mine called [mediator.ai/stuff](mediator.ai/stuff/).

People often need to divide work between a group, such as household chores or parts of a larger project.

What if we could use AI to figure out everyone's preferences and then find the best possible way to divide tasks?

That's the idea with my experiment. You can create a list of whatever you want, along with a question like ""which chore do you prefer?"".

You then share a link with the rest of your family/team and they're asked a series of simple questions. 

After enough people have answered it will reveal the task allocation. It will also estimate how much ""pain"" it has reduced relative to a random allocation.

It uses [fair item assignment](https://en.m.wikipedia.org/wiki/Fair_item_assignment) to do the allocation and a constraint solver to find the best solution.

I'd appreciate any feedback, questions, or suggestions: [link](http://mediator.ai/stuff)",0,1
144,2018-7-4,2018,7,4,1,8vtsuq,"[P] Pytorch implementation on Adversarial Complementary Learning with Messi, Ronaldo, Neymar and Son",https://www.reddit.com/r/MachineLearning/comments/8vtsuq/p_pytorch_implementation_on_adversarial/,junkwhinger,1530636889,,0,2
145,2018-7-4,2018,7,4,2,8vu1lz,"[D] I'm researching a promising use case but I don't have the resources to actualize it, I want to publish a paper over it but I'm not sure how to provide experimental results as a proof of concept. Can I publish without experimental results or is this poor form / no one will care?",https://www.reddit.com/r/MachineLearning/comments/8vu1lz/d_im_researching_a_promising_use_case_but_i_dont/,Morninglow,1530638626,,19,7
146,2018-7-4,2018,7,4,2,8vu4nj,Wind power forecasting using Feedforward Neural Network,https://www.reddit.com/r/MachineLearning/comments/8vu4nj/wind_power_forecasting_using_feedforward_neural/,Asifkhan914,1530639231,[removed],0,1
147,2018-7-4,2018,7,4,2,8vu823,[R] Capture the Flag: the emergence of complex cooperative agents | DeepMind,https://www.reddit.com/r/MachineLearning/comments/8vu823/r_capture_the_flag_the_emergence_of_complex/,angry-zergling,1530639902,,44,316
148,2018-7-4,2018,7,4,3,8vunee,[P] Managed/hosted 1080Ti GPU rentals for ML,https://www.reddit.com/r/MachineLearning/comments/8vunee/p_managedhosted_1080ti_gpu_rentals_for_ml/,adopshire2016,1530642954,"Hello,

I run a sizable GPU mining farm with hundreds of 1080Ti GPUs used primarily for cryptocurrency mining.

We recently started looking into diversifying our revenue channels by introducing custom server builds with stronger CPUs and RAM and larger HDs to be attractive for machine learning. We got some interest from video rendering projects but not machine learning.

Is there any interest in this type of service? I asked this previously and seemed to get positive interest competing with vendors like PaperSource but then failed to attract more than 1 customer.

Where would be a good place to find potential customers for such a service?",29,6
149,2018-7-4,2018,7,4,3,8vusta,[D] Tell us what you think about Tensorflow.js! (takes less than 5 minutes),https://www.reddit.com/r/MachineLearning/comments/8vusta/d_tell_us_what_you_think_about_tensorflowjs_takes/,pmigdal,1530644069,,1,0
150,2018-7-4,2018,7,4,4,8vuvaz,[D] Rant/Question: scaled dot-product attention,https://www.reddit.com/r/MachineLearning/comments/8vuvaz/d_rantquestion_scaled_dotproduct_attention/,AnvaMiba,1530644554,"In ""[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)"" Vaswani et al. propose to scale the value of the dot-product attention score by 1/sqrt(d) before taking the softmax, where d is the key vector size.

Clearly, this scaling should depend on the initial value of the weights that compute the key and query vectors, since the scaling is a reparametrization of these weight matrices, but unfortunately the paper does not specify how these weights are initialized.

Trying to follow the rabbit hole that is [tensor2tensor](https://github.com/tensorflow/tensor2tensor), which is supposed to be the reference implementation, it seems to use the default [tf.layers.Conv2D](https://www.tensorflow.org/api_docs/python/tf/layers/Conv2D) initalizer which is undocumented, but people on teh interwebz say that it is Glorot uniform.

[Marian](https://github.com/marian-nmt/marian-dev) also uses Glorot uniform, while Sockeye uses the default MXNet initializer which I don't know what it is.

Rant: the initializer should have been clearly specified in the paper, or at lest in the reference code. It should definitely not be undocumented behavior of the underlying deep learning library. 

Question: does it make any difference if instead of scaling at runtime we absorb the 1/sqrt(d) factor in the initialization of one of the weight matrices? Or a 1/d^(1/4) factor in both matrices?
The only difference is that it changes the dynamic range of the weights during training. Has anybody experimented with it?
",3,7
151,2018-7-4,2018,7,4,5,8vviqy,Check out my AI stream https://www.youtube.com/watch?v=8TllF8Dw2KA,https://www.reddit.com/r/MachineLearning/comments/8vviqy/check_out_my_ai_stream/,mcilie,1530649518,[removed],1,1
152,2018-7-4,2018,7,4,6,8vw3pa,Best Machine_Learning Library features,https://www.reddit.com/r/MachineLearning/comments/8vw3pa/best_machine_learning_library_features/,RonomMimcry,1530654040,[removed],0,1
153,2018-7-4,2018,7,4,7,8vwiol,[D] Lessons From Alpha Zero (part 5): Performance Optimization,https://www.reddit.com/r/MachineLearning/comments/8vwiol/d_lessons_from_alpha_zero_part_5_performance/,vishvananda,1530657387,,1,1
154,2018-7-4,2018,7,4,7,8vwl7g,Where should I focus my studies in ML?,https://www.reddit.com/r/MachineLearning/comments/8vwl7g/where_should_i_focus_my_studies_in_ml/,xepo3abp,1530657950,[removed],0,1
155,2018-7-4,2018,7,4,7,8vwnc4,Could you help me improve my music generator?,https://www.reddit.com/r/MachineLearning/comments/8vwnc4/could_you_help_me_improve_my_music_generator/,tunestar2018,1530658469,[removed],0,1
156,2018-7-4,2018,7,4,7,8vwoi2,Looking for a person to interview for AI documentary {Toronto area),https://www.reddit.com/r/MachineLearning/comments/8vwoi2/looking_for_a_person_to_interview_for_ai/,Dhruv525,1530658747,[removed],0,1
157,2018-7-4,2018,7,4,8,8vwy4f,[D] Are we close to having machines solve TopCoder problems?,https://www.reddit.com/r/MachineLearning/comments/8vwy4f/d_are_we_close_to_having_machines_solve_topcoder/,ilblackdragon,1530660995,[removed],0,1
158,2018-7-4,2018,7,4,8,8vx17m,Is there any documentation for openai baseline?,https://www.reddit.com/r/MachineLearning/comments/8vx17m/is_there_any_documentation_for_openai_baseline/,aznroscatkin,1530661739,[removed],0,1
159,2018-7-4,2018,7,4,8,8vx29f,[D] Are we close to having machines solve TopCoder problems?,https://www.reddit.com/r/MachineLearning/comments/8vx29f/d_are_we_close_to_having_machines_solve_topcoder/,ilblackdragon,1530661994,,0,2
160,2018-7-4,2018,7,4,10,8vxljy,Autonomous Customer Engagement,https://www.reddit.com/r/MachineLearning/comments/8vxljy/autonomous_customer_engagement/,virene,1530666939,,0,1
161,2018-7-4,2018,7,4,10,8vxu18,[R] Learning to Drive in a Day with Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8vxu18/r_learning_to_drive_in_a_day_with_deep/,mhdempsey,1530669138,,2,4
162,2018-7-4,2018,7,4,10,8vxvr6,What are some good Bayesian techniques to deal with partially observed/sparse dataset?,https://www.reddit.com/r/MachineLearning/comments/8vxvr6/what_are_some_good_bayesian_techniques_to_deal/,rulerofthehell,1530669590,[removed],0,1
163,2018-7-4,2018,7,4,12,8vyemt,Facebook Page - AI Saturdays Bay Area Chapter,https://www.reddit.com/r/MachineLearning/comments/8vyemt/facebook_page_ai_saturdays_bay_area_chapter/,ramML,1530674736,[removed],0,1
164,2018-7-4,2018,7,4,12,8vyemu,[R] 5 Language-oriented Tasks that Have Not Been Explored Enough by Deep Learning (1),https://www.reddit.com/r/MachineLearning/comments/8vyemu/r_5_languageoriented_tasks_that_have_not_been/,longinglove,1530674736,,0,1
165,2018-7-4,2018,7,4,13,8vyrcq,"Top 15 AI, Machine Learning Open Source Projects",https://www.reddit.com/r/MachineLearning/comments/8vyrcq/top_15_ai_machine_learning_open_source_projects/,asifrazzaq1988,1530678247,,1,1
166,2018-7-4,2018,7,4,15,8vze54,Ford Model 8N Operator's Manual | The Homesteader's Free Library,https://www.reddit.com/r/MachineLearning/comments/8vze54/ford_model_8n_operators_manual_the_homesteaders/,homesteadorgus,1530684960,,0,1
167,2018-7-4,2018,7,4,15,8vzjs7,Are we becoming Gods by creating artificial intelligence? or are we recreating God?,https://www.reddit.com/r/MachineLearning/comments/8vzjs7/are_we_becoming_gods_by_creating_artificial/,Crassusempire,1530686726,,0,1
168,2018-7-4,2018,7,4,15,8vzlcj, 2018 - GALAXY CHANNEL,https://www.reddit.com/r/MachineLearning/comments/8vzlcj/_2018_galaxy_channel/,Woodworking94,1530687209,,0,1
169,2018-7-4,2018,7,4,16,8vznnd,[R] The streaming rollout of deep networks - towards fully model-parallel execution,https://www.reddit.com/r/MachineLearning/comments/8vznnd/r_the_streaming_rollout_of_deep_networks_towards/,phizaz,1530687958,,5,2
170,2018-7-4,2018,7,4,16,8vzt9k,Twitter bot which will retweet a tweet containing #MachineLearning hashtag,https://www.reddit.com/r/MachineLearning/comments/8vzt9k/twitter_bot_which_will_retweet_a_tweet_containing/,kalsi_sachin,1530689739,,0,1
171,2018-7-4,2018,7,4,16,8vzv7p,Twitter bot which will retweet a tweet containing #MachineLearning hashtag,https://www.reddit.com/r/MachineLearning/comments/8vzv7p/twitter_bot_which_will_retweet_a_tweet_containing/,kalsi_sachin,1530690376,"[https://twitter.com/AppliedAI1](https://twitter.com/AppliedAI1)

This  twitter bot will retweet a tweet if it contains:

1. hashtag #MachineLearning
2. number of people who liked tweet &gt; =10
3. Must have retweeted at least 10 times",0,1
172,2018-7-4,2018,7,4,17,8w05d6,What is the state-of-the-art language model nowadays?,https://www.reddit.com/r/MachineLearning/comments/8w05d6/what_is_the_stateoftheart_language_model_nowadays/,bnmasd0,1530693917,[removed],0,1
173,2018-7-4,2018,7,4,17,8w074n,6 Ways Chatbots will Disrupt the Banking and Financial Services Industry,https://www.reddit.com/r/MachineLearning/comments/8w074n/6_ways_chatbots_will_disrupt_the_banking_and/,BotbotAI,1530694587,,0,1
174,2018-7-4,2018,7,4,17,8w0799,Those starting On Deep Neural Networks Might Find this Paper Useful,https://www.reddit.com/r/MachineLearning/comments/8w0799/those_starting_on_deep_neural_networks_might_find/,ravensdraven,1530694637,[removed],0,1
175,2018-7-4,2018,7,4,18,8w08lx,Data needs cleaning before machine learning can find meaning,https://www.reddit.com/r/MachineLearning/comments/8w08lx/data_needs_cleaning_before_machine_learning_can/,visionetsystems,1530695114,,0,1
176,2018-7-4,2018,7,4,18,8w0awz,"In Second AI-Human Showdown, IBM's Debater Outwitted",https://www.reddit.com/r/MachineLearning/comments/8w0awz/in_second_aihuman_showdown_ibms_debater_outwitted/,bigintro,1530695906,,0,1
177,2018-7-4,2018,7,4,19,8w0i86,[D]Wanna get started with machine learning. Plz. suggest ......,https://www.reddit.com/r/MachineLearning/comments/8w0i86/dwanna_get_started_with_machine_learning_plz/,John1807,1530698560,[removed],0,1
178,2018-7-4,2018,7,4,19,8w0j5d,Machine learning in Finance - Present and Future Applications,https://www.reddit.com/r/MachineLearning/comments/8w0j5d/machine_learning_in_finance_present_and_future/,imarticus_nirmal,1530698871,,0,1
179,2018-7-4,2018,7,4,19,8w0mq9,Use cases of Machine Learning in E-commerce enterprises,https://www.reddit.com/r/MachineLearning/comments/8w0mq9/use_cases_of_machine_learning_in_ecommerce/,Dhillon_81,1530700071,,0,1
180,2018-7-4,2018,7,4,19,8w0mqf,[N] A Complete Machine Learning Guide For Absolute Beginners !!,https://www.reddit.com/r/MachineLearning/comments/8w0mqf/n_a_complete_machine_learning_guide_for_absolute/,John1807,1530700074,,1,1
181,2018-7-4,2018,7,4,19,8w0n9n,What is the difference between Machine Learning and Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/8w0n9n/what_is_the_difference_between_machine_learning/,imarticus_nirmal,1530700252,,0,1
182,2018-7-4,2018,7,4,19,8w0o0n,Advances in Financial Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8w0o0n/advances_in_financial_machine_learning/,Anticro,1530700506,[removed],0,1
183,2018-7-4,2018,7,4,19,8w0p2p,"Best Machine Learning, Deep Learning, AI &amp; IOS Courses Online",https://www.reddit.com/r/MachineLearning/comments/8w0p2p/best_machine_learning_deep_learning_ai_ios/,simplivllc,1530700870,[removed],0,1
184,2018-7-4,2018,7,4,19,8w0p2w,Is Machine Learning the Best Way To Grow a FinTech Company?,https://www.reddit.com/r/MachineLearning/comments/8w0p2w/is_machine_learning_the_best_way_to_grow_a/,imarticus_nirmal,1530700871,,0,1
185,2018-7-4,2018,7,4,20,8w0v39,"Ian Osband: Dropout ""posteriors"" give bad decisions. Doesn't even pass linear sanity checks! Alternative? https://arxiv.org/abs/1806.03335",https://www.reddit.com/r/MachineLearning/comments/8w0v39/ian_osband_dropout_posteriors_give_bad_decisions/,thebackpropaganda,1530702849,,0,1
186,2018-7-4,2018,7,4,20,8w0v9m,"[D] Ian Osband: Dropout ""posteriors"" give bad decisions. Doesn't even pass linear sanity checks! Alternative? https://arxiv.org/abs/1806.03335",https://www.reddit.com/r/MachineLearning/comments/8w0v9m/d_ian_osband_dropout_posteriors_give_bad/,thebackpropaganda,1530702904,,27,18
187,2018-7-4,2018,7,4,20,8w0w0d,Pixor: Real-time 3D Object Detection from Point Clouds,https://www.reddit.com/r/MachineLearning/comments/8w0w0d/pixor_realtime_3d_object_detection_from_point/,joekidd1987,1530703140,[removed],0,1
188,2018-7-4,2018,7,4,20,8w0yf9,Images: Label the unlabeled data for supervised learning,https://www.reddit.com/r/MachineLearning/comments/8w0yf9/images_label_the_unlabeled_data_for_supervised/,waterRocket8236,1530703920,[removed],0,1
189,2018-7-4,2018,7,4,22,8w1gjh,[R] DeNet: A Real-time Anchorless Object Detector,https://www.reddit.com/r/MachineLearning/comments/8w1gjh/r_denet_a_realtime_anchorless_object_detector/,JudasAdventus,1530709238,,0,1
190,2018-7-4,2018,7,4,23,8w1zsa,[D] MultiGPU vs Single GPU for small models,https://www.reddit.com/r/MachineLearning/comments/8w1zsa/d_multigpu_vs_single_gpu_for_small_models/,inkognit,1530714171,I was wondering what is the best practice when I have a relatively small model (that takes up to 2Gb of GPU memory in total) and I want to take advantage of a cluster of GPUs. Given that the resources are available at no cost: should I run this model on a single GPU or run it in multiple GPUs?,12,31
191,2018-7-5,2018,7,5,0,8w2bw5,[R] The Elephant in The Room.,https://www.reddit.com/r/MachineLearning/comments/8w2bw5/r_the_elephant_in_the_room/,AmirRosenfeld,1530716966,A Demonstration of interesting failures of State-of-The-Art object detectors.,2,0
192,2018-7-5,2018,7,5,0,8w2o7f,"Simple Questions Thread July 04, 2018",https://www.reddit.com/r/MachineLearning/comments/8w2o7f/simple_questions_thread_july_04_2018/,AutoModerator,1530719741,[removed],0,1
193,2018-7-5,2018,7,5,1,8w2rhl,"[N] Nvidia Opens GPUs for AI Work with Containers, Kubernetes",https://www.reddit.com/r/MachineLearning/comments/8w2rhl/n_nvidia_opens_gpus_for_ai_work_with_containers/,villasv,1530720445,,16,222
194,2018-7-5,2018,7,5,1,8w2w81,Business Impacts and Advantages of Natural Language Generation (AI),https://www.reddit.com/r/MachineLearning/comments/8w2w81/business_impacts_and_advantages_of_natural/,asifrazzaq1988,1530721453,,0,1
195,2018-7-5,2018,7,5,1,8w2y5h,[R] Interesting Failures of SOTA Object Detectors,https://www.reddit.com/r/MachineLearning/comments/8w2y5h/r_interesting_failures_of_sota_object_detectors/,AmirRosenfeld,1530721867,,35,93
196,2018-7-5,2018,7,5,1,8w304i,"[D] Custom Object Detection: Data Distribution, Data Augmentation, and other questions?",https://www.reddit.com/r/MachineLearning/comments/8w304i/d_custom_object_detection_data_distribution_data/,OlorinDreams,1530722269,"Hello, 

So for the past few months I've been doing a smallish research project on my own on object detection by using two popular models. One being YoloV3 (https://pjreddie.com/darknet/yolo/) from Darknet and the other Faster R-CNN (https://github.com/endernewton/tf-faster-rcnn). 

First, the images I'm attempting to use are rather large at 4k (3840 x 2160) resolution. Further more, they tend to have multiple objects per image as is the case often. Currently I have about ~800 hand-annotated (Pascal VOC using LabelImg) images with the classes of objects running from 900 examples to around 2,200 examples. i.e. some images have many examples of the same object while others less so or none. 

So already this presents one of the questions I couldn't particularly find a solution for, is how can I attempt to create a good distribution (or is that required at all) of labels for my objects when their occurrence varies so widely. If I have 2k examples of object A, but only 1k of object B, how can I attempt to have the same number? Is that even required? How valuable would it be to have many images where no objects from any class / label exist?

If Data Augmentation is a method, I don't see how I can do that with object detection. Let's take a popular method for classification, random cropping and scaling. If I attempt to do this with my images, what will happen to my annotations? I could potentially randomly crop out objects, or partially crop them out or scale. Same issue with flipping. Flipping is easier as I can write scripts to change the coordinates for the bounding boxes, but other forms of Data Augmentation seem non-trivial. 


Another interesting problem is the image resolution itself. Originally I assumed that if I compress the images (using the respective libraries pre-processing methods) to smaller sizes I could lose information on some of the smaller defects. The results are counter intuitive. It seems that compressing them seems to yield better results! This could be because this allows me to use a larger batch size? (from 64 to 128 or higher) or perhaps even the architectures are tuned toward a max size of ~800x800 and that I need to look into adding more layers or anchors (for RCNN) in order to compensate for the larger image size? 

I don't see much information regarding data pre-processing or normalization for object detection persay, I do see a lot for classification. Perhaps someone could share their experience?
",8,3
197,2018-7-5,2018,7,5,2,8w37p9,What are some good books to get more theoretical understanding?,https://www.reddit.com/r/MachineLearning/comments/8w37p9/what_are_some_good_books_to_get_more_theoretical/,olBaa,1530723862,[removed],0,1
198,2018-7-5,2018,7,5,3,8w3ruc,[D] Why don't we repeat the same batch a number of times consecutively ?,https://www.reddit.com/r/MachineLearning/comments/8w3ruc/d_why_dont_we_repeat_the_same_batch_a_number_of/,TalkingJellyFish,1530728173,"The way I've always trained NN, and most other people I've seen as well, is by doing a step on a batch, then doing another step on a different batch. 
Why not do 5(or n) steps on the same batch. Since we're updating the weights each time we will get a different signal. 

Intuitively, I'd imagine we'd start to overfit the batch, then moving onto the next one we'd unlearn the overfitted stuff and overfit again to the new batch. But, we'd also obtain a ""sharper comprehension"" of relevant information in each, since we'd be compensating for noisiness ? 
",22,8
199,2018-7-5,2018,7,5,3,8w3xae,[D] Question - Mapping Arbitrary Text Input to Commands,https://www.reddit.com/r/MachineLearning/comments/8w3xae/d_question_mapping_arbitrary_text_input_to/,TheTruckThunders,1530729417,"This is a general question about the sweet spot between efficiently and accurately translating user input to defined commands using NLP. Here's a quick example.

I want somebody to type a command to interact with a ball. The program has stored the commands to do the following:

* ""kick the ball""
* ""pick up the ball""
* ""pop the ball""

The user can input anything. For example, say people try the following inputs:

* ""I will to grab the ball"" [ Should match to ""pick up the ball"" ]
* ""Try to punch the ball"" [ Should match to ""kick the ball"" ]
* ""Lick it"" [ Should match to God only knows ]

The goal is translation of arbitrary input, because people like to write sentences (or speak them), to defined commands. ChatBot / Google Assistant / Alexa type behavior with text. And, I am trying to avoid storing an exhaustive list of synonym commands within the program itself (e.g. ""kick the ball"", ""punt the ball"", ""toe the ball"", all defined in the program and linked to the same action). Infinite possible inputs, one command mapped to one action, and some type of NLP finds the best match.

Is something along the lines of the Google Universal Sentence Encoder overkill? Where do you think the happy medium between runtime and accuracy lies?

If you've ever played a MUD, the goal here is akin to avoiding the monstrous set of switch logic (that can often fail for creative users) for command inputs by using some form of NLP.",2,4
200,2018-7-5,2018,7,5,3,8w3zt2,A gentle introduction to glass box models,https://www.reddit.com/r/MachineLearning/comments/8w3zt2/a_gentle_introduction_to_glass_box_models/,alkaliapp,1530730006,[https://medium.com/@alkali.app/glass-box-models-a-gentle-introduction-2f39589c09d1](https://medium.com/@alkali.app/glass-box-models-a-gentle-introduction-2f39589c09d1),0,1
201,2018-7-5,2018,7,5,4,8w47qy,Ideal Machine Learning Research Setup,https://www.reddit.com/r/MachineLearning/comments/8w47qy/ideal_machine_learning_research_setup/,AbdulRehmanLiaqat,1530731836,[removed],0,1
202,2018-7-5,2018,7,5,4,8w4air,The accomplishment of Shang Gao's 2016 classification using a corpus size of just 2500,https://www.reddit.com/r/MachineLearning/comments/8w4air/the_accomplishment_of_shang_gaos_2016/,ckris292,1530732492,[removed],0,1
203,2018-7-5,2018,7,5,5,8w4p30,Self-Organizing Maps and Applications,https://www.reddit.com/r/MachineLearning/comments/8w4p30/selforganizing_maps_and_applications/,itdxer,1530735746,,0,1
204,2018-7-5,2018,7,5,6,8w5598,[P] Complete World Models implementation in Chainer,https://www.reddit.com/r/MachineLearning/comments/8w5598/p_complete_world_models_implementation_in_chainer/,ThisIsMySeudonym,1530739393,,0,16
205,2018-7-5,2018,7,5,6,8w56iy,"[P] Generating ""synesthetic""-like videos based on audio",https://www.reddit.com/r/MachineLearning/comments/8w56iy/p_generating_synestheticlike_videos_based_on_audio/,Deinos_Mousike,1530739692,"Hey everyone, I've been working on training a Convolutional Variational Autoencoder to generate images. That alone is pretty cool - creating transition gifs between two images, plus just exploring the latent space, etc.

What I've recently done, however, is encode audio with an audio-based C-VAE, then use those encodings as the ""input"" to the latent space of the image-based C-VAE, to generate ""organic""-looking imagery based on audio features.

Short Twitter thread here:

https://twitter.com/_not_Ian_/status/1014585982446915585

I've generated just a few videos so far. I have the workflow down, but it's a little bit of a process.

You can see both audio encodings hover around the same feature space - I think I can do some finagling so the audio encodings explore more of the feature space of the image-based C-VAE. 

Next steps are to increase the resolution of the image-based VAE. It's currently at 64x64. I've tried to do something similar to [
Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196), however, my experiments haven't worked so far. Suggestions welcome :)

Also, I'm willing to generate more examples if there's interest!",5,3
206,2018-7-5,2018,7,5,6,8w59bf,Learning Montezuma's Revenge from a Single Demonstration,https://www.reddit.com/r/MachineLearning/comments/8w59bf/learning_montezumas_revenge_from_a_single/,AlphaHumanZero,1530740368,,0,1
207,2018-7-5,2018,7,5,7,8w5grj,[R] Learning Montezuma's Revenge from a Single Demonstration,https://www.reddit.com/r/MachineLearning/comments/8w5grj/r_learning_montezumas_revenge_from_a_single/,baylearn,1530742215,,22,37
208,2018-7-5,2018,7,5,7,8w5nhv,WhatsApp Chatbot,https://www.reddit.com/r/MachineLearning/comments/8w5nhv/whatsapp_chatbot/,BotbotAI,1530743945,[removed],0,1
209,2018-7-5,2018,7,5,9,8w6b6p,[D] Literature on the inverse of text summarization,https://www.reddit.com/r/MachineLearning/comments/8w6b6p/d_literature_on_the_inverse_of_text_summarization/,HigherTopoi,1530750509,"I'm looking for papers on the inverse of text summarization, which I call text expansion for convenience. I searched for relevant keywords, but all the results were irrelevant. ",0,1
210,2018-7-5,2018,7,5,10,8w6oye,What is the best realistic driving simulator to train a self-driving car with?,https://www.reddit.com/r/MachineLearning/comments/8w6oye/what_is_the_best_realistic_driving_simulator_to/,bill1357,1530754493,[removed],0,1
211,2018-7-5,2018,7,5,10,8w6t6e,[P] Understanding Neural Networks by embedding hidden representations during training,https://www.reddit.com/r/MachineLearning/comments/8w6t6e/p_understanding_neural_networks_by_embedding/,lmcinnes,1530755757,,0,1
212,2018-7-5,2018,7,5,11,8w72ni,[P] Tell Me Where To Look ( Guided Attention Inference Network) CVPR-2018,https://www.reddit.com/r/MachineLearning/comments/8w72ni/p_tell_me_where_to_look_guided_attention/,iamlordkurdleak,1530758379,,0,1
213,2018-7-5,2018,7,5,11,8w74vw,[P]Tell Me Where To Look( Guided Attention Inference Network ),https://www.reddit.com/r/MachineLearning/comments/8w74vw/ptell_me_where_to_look_guided_attention_inference/,iamlordkurdleak,1530759027,,0,4
214,2018-7-5,2018,7,5,11,8w765n,"I want to be able to extract information from websites by doing steps like login in, inputting some standard information (that we can feed through our website) and then providing the results on those inputs through our website). Is this possible? If so, is there services I can hire to do it?",https://www.reddit.com/r/MachineLearning/comments/8w765n/i_want_to_be_able_to_extract_information_from/,oalvarez88,1530759399,[removed],0,1
215,2018-7-5,2018,7,5,12,8w78ve,Performing OCR with Tesseract 4.0 (LSTM model): Building a Real world Application,https://www.reddit.com/r/MachineLearning/comments/8w78ve/performing_ocr_with_tesseract_40_lstm_model/,Abhijeet3922,1530760173,,0,1
216,2018-7-5,2018,7,5,12,8w7c9c,Can object location by deep learning adapt to different scene?,https://www.reddit.com/r/MachineLearning/comments/8w7c9c/can_object_location_by_deep_learning_adapt_to/,mhaoyanghb,1530761166,[removed],0,1
217,2018-7-5,2018,7,5,13,8w7kez,Updates to the XGBoost GPU algorithms,https://www.reddit.com/r/MachineLearning/comments/8w7kez/updates_to_the_xgboost_gpu_algorithms/,ramitchellnz,1530763681,,1,20
218,2018-7-5,2018,7,5,13,8w7s68,[R] ModaNet: A Large-Scale Street Fashion Dataset with Polygon Annotations,https://www.reddit.com/r/MachineLearning/comments/8w7s68/r_modanet_a_largescale_street_fashion_dataset/,chisai_mikan,1530766084,,1,4
219,2018-7-5,2018,7,5,15,8w892b,Reinforce Learning in an env which cannot be affected.,https://www.reddit.com/r/MachineLearning/comments/8w892b/reinforce_learning_in_an_env_which_cannot_be/,magnusderrote,1530771741,[removed],0,1
220,2018-7-5,2018,7,5,15,8w89p1,Links to Computer Vision News of July and BEST OF CVPR,https://www.reddit.com/r/MachineLearning/comments/8w89p1/links_to_computer_vision_news_of_july_and_best_of/,Gletta,1530771965,[removed],0,1
221,2018-7-5,2018,7,5,15,8w8dgk,Links to Computer Vision News of July and BEST OF CVPR,https://www.reddit.com/r/MachineLearning/comments/8w8dgk/links_to_computer_vision_news_of_july_and_best_of/,Gletta,1530773206,[removed],0,2
222,2018-7-5,2018,7,5,15,8w8djj,[D] Is leveraging prior rules/information always useful in machine learning?,https://www.reddit.com/r/MachineLearning/comments/8w8djj/d_is_leveraging_prior_rulesinformation_always/,jasons0219,1530773235,"I like to view machine learning as a bottom-top approach in which the data defines the rules rather than the rules defining the data. For example, most of the state-of-the-art language models do not leverage our grammar rules to auto-correct something or generate sequential text. A lot of the models don't even leverage dictionary information of a typical word, but rather try to define what the word means from the context.

However, in a lot of the image processing papers or learning-to-rank literature, it feels like there is always some bias or prior human knowledge that can be utilized to make the model better for a specific scenario. For example, including a positional bias in a ranking loss function to account for popularity bias or using human-defined zip codes in addition to GPS information to better recommend popular places to users. 

Whether to leverage these prior rules or information must probably be case by case, but a general guideline would be helpful.

I'm working at a company which has accumulated dictionary data of our vendors for 10+ years and is currently wanting to somehow update our 10-year-old outdated query-search process(hard rule based). My company's value lies in a lot of the dictionary data that we possess, but we also have massive amounts of user sequence data that sometimes contradicts with our dictionary. I'm having a hard time finding a balance between providing good results to our customers based on a data-driven bottom-top model and a rule-based keyword match model. Research on Keyword search on structured data seems to have ceased after 2009, with the advent of Machine Learning.",5,9
223,2018-7-5,2018,7,5,16,8w8lbb,JCB ServiceMaster 4,https://www.reddit.com/r/MachineLearning/comments/8w8lbb/jcb_servicemaster_4/,Mypremiummanual,1530775842,,0,1
224,2018-7-5,2018,7,5,16,8w8oqu,[D] Why are Adam/RMSProp preferred over second order methods for training neural networks,https://www.reddit.com/r/MachineLearning/comments/8w8oqu/d_why_are_adamrmsprop_preferred_over_second_order/,wildtales,1530777079,"Adam/RMSProp scale the individual elements of the gradient vector based on a heuristic that comprises the computation of running mean and variance of the gradient vectors over several time steps.   


An alternative would be to scale the elements of the gradient vector based on the second order derivative of that particular element with respect to the loss function. This is equivalent to Newton's method with diagonal entries. This can be computed recursively similar to backpropagation. Why is this not preferable to the other heuristics like Adam and RMSProp?",25,22
225,2018-7-5,2018,7,5,17,8w8rtp,[R] Neural Processes,https://www.reddit.com/r/MachineLearning/comments/8w8rtp/r_neural_processes/,hardmaru,1530778231,,21,127
226,2018-7-5,2018,7,5,17,8w8ubc,isuzu engine service manual,https://www.reddit.com/r/MachineLearning/comments/8w8ubc/isuzu_engine_service_manual/,Mypremiummanual,1530779203,,0,1
227,2018-7-5,2018,7,5,17,8w8w4z,Types of Metal Tag Machine,https://www.reddit.com/r/MachineLearning/comments/8w8w4z/types_of_metal_tag_machine/,badgepass,1530779921,,0,1
228,2018-7-5,2018,7,5,18,8w901e,Naive Bayes for NLP Talk in PyData Tel Aviv,https://www.reddit.com/r/MachineLearning/comments/8w901e/naive_bayes_for_nlp_talk_in_pydata_tel_aviv/,machineLearning37,1530781380,,0,1
229,2018-7-5,2018,7,5,18,8w97lu,Artificial Intelligence - AI,https://www.reddit.com/r/MachineLearning/comments/8w97lu/artificial_intelligence_ai/,Fraud-Prevention-101,1530784126,[removed],0,1
230,2018-7-5,2018,7,5,20,8w9kqz,Looking for recommendations on archtecture,https://www.reddit.com/r/MachineLearning/comments/8w9kqz/looking_for_recommendations_on_archtecture/,kiunthmo,1530788682,"I'm doing a project for my degree and I'm looking for recommendations on techniques and architectures I can (preferably) employ in Tensorflow.

The project involves taking an audio signal and segmenting and labelling 'samples' (in the musical sense) from the signal. So one part is to segment the audio - find where each sound is. And the other part is classification - correctly labelling the sound. So for feature extraction i'll be using SFTF/FFT to get the frequencies of the waveforms. Then transient detection can be done by detecting the deltas between bins (the STFT frames) being above a threshold. The classification could be done with a CNN or something. I'd quite like to make the entire process into a single architecture and build the FFT part into the early layers so I could eventually train the weights of the FFT to investigate whether it will improve results. It doesn't particularly matter whether any step will definitively improve results, it's all about investigating effects.

If anyone knows any interesting or cutting edge architectures which may lend itself towards a task like this, it'd be really appreciated. Bare in mind though, I'm not looking for models that are already trained that I can just adopt, I have to experiment myself.

If my goals aren't clear, I'll be happy to clear any of it up.

Thanks",0,1
231,2018-7-5,2018,7,5,20,8w9oya,Data needs cleaning before machine learning can find meaning,https://www.reddit.com/r/MachineLearning/comments/8w9oya/data_needs_cleaning_before_machine_learning_can/,iammarksmith,1530790043,,0,1
232,2018-7-5,2018,7,5,20,8w9qav,[R] Automated Machine Learning vs Automated Data Science,https://www.reddit.com/r/MachineLearning/comments/8w9qav/r_automated_machine_learning_vs_automated_data/,polllyyy,1530790443,,0,1
233,2018-7-5,2018,7,5,20,8w9r0t,[D] Unknown noise in test set,https://www.reddit.com/r/MachineLearning/comments/8w9r0t/d_unknown_noise_in_test_set/,DarkPhalanx,1530790653,"I have a dataset in which the training data is labelled while the unlabelled test data has been corrupted by noise with a known distribution type but unknown noise parameters parameters. The training data is also quite small which rules out using deep learning methods like denoising autoencoders.

Here's how I am planning to approach this problem:

1. Find the eigenvalues on the training data
2. Inject noise into the data with different parameters
3. Find the eingenvalues of the corrupted data
4. Take only the eigenvalues that don't vary too much across the corrupted datasets
5. Reduce dimensions to these corresponding eigenvalues
6. Train multiple classifiers, one on each of the models

Could I improve this method? If not, what other methods could I use for this?",0,2
234,2018-7-5,2018,7,5,20,8w9se4,[P] Introducing the IRONdb Prometheus Adapter - Circonus,https://www.reddit.com/r/MachineLearning/comments/8w9se4/p_introducing_the_irondb_prometheus_adapter/,rennytech,1530791070,,0,1
235,2018-7-5,2018,7,5,21,8wa5fe,An Introduction to Biomedical Image Analysis with TensorFlow and DLTK,https://www.reddit.com/r/MachineLearning/comments/8wa5fe/an_introduction_to_biomedical_image_analysis_with/,mauinz,1530794701,,0,1
236,2018-7-5,2018,7,5,21,8wa5n8,"Why is the name ""variational auto encoder"" given?",https://www.reddit.com/r/MachineLearning/comments/8wa5n8/why_is_the_name_variational_auto_encoder_given/,kai-zhao,1530794768,"I just read a [great article about variational auto encoder](http://kvfrans.com/variational-autoencoders-explained/) and the concept and motivation of VAE has been well demostrated there.

But I have a question in my mind: why do we just call it ""variational"" auto encoder, what doest the term ""variational"" stand for?",0,1
237,2018-7-5,2018,7,5,21,8wa636,"Reshaping Lives with AI, Machine Learning, and Deep Learning",https://www.reddit.com/r/MachineLearning/comments/8wa636/reshaping_lives_with_ai_machine_learning_and_deep/,NetComLearning,1530794887,,0,1
238,2018-7-5,2018,7,5,21,8wa6fx,"[N] Weekly Machine Learning Opensource Roundup  July 5, 2018",https://www.reddit.com/r/MachineLearning/comments/8wa6fx/n_weekly_machine_learning_opensource_roundup_july/,stkim1,1530794979,,0,1
239,2018-7-5,2018,7,5,22,8wamed,What are some of the biggest challenges you experienced entering ML space?,https://www.reddit.com/r/MachineLearning/comments/8wamed/what_are_some_of_the_biggest_challenges_you/,f3nnix,1530798938,[removed],0,1
240,2018-7-5,2018,7,5,22,8wanfu,[R] Machine Learning Top 10 Articles for the Past Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/8wanfu/r_machine_learning_top_10_articles_for_the_past/,kumeralex,1530799195,,0,1
241,2018-7-5,2018,7,5,23,8waohj,[R]Machine Learning Top 10 Articles for the Past Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/8waohj/rmachine_learning_top_10_articles_for_the_past/,kumeralex,1530799403,,0,1
242,2018-7-5,2018,7,5,23,8waoub,[R]Machine Learning Top 10 Articles for the Past Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/8waoub/rmachine_learning_top_10_articles_for_the_past/,kumeralex,1530799471,,0,1
243,2018-7-5,2018,7,5,23,8wb0oj,[D] What do people think about the Lottery Ticket Hypothesis?,https://www.reddit.com/r/MachineLearning/comments/8wb0oj/d_what_do_people_think_about_the_lottery_ticket/,jamesonatfritz,1530802119,,21,79
244,2018-7-6,2018,7,6,0,8wb5b6,Building a dataset to render 3d mesh model from 2d image,https://www.reddit.com/r/MachineLearning/comments/8wb5b6/building_a_dataset_to_render_3d_mesh_model_from/,guruk2,1530803115,,1,1
245,2018-7-6,2018,7,6,0,8wb8sc,[P] Helping African farmers with TensorFlow (audio),https://www.reddit.com/r/MachineLearning/comments/8wb8sc/p_helping_african_farmers_with_tensorflow_audio/,jerodsanto,1530803841,,0,10
246,2018-7-6,2018,7,6,0,8wbaas,Any ideas to train a deep network without Nvidia Graphics?,https://www.reddit.com/r/MachineLearning/comments/8wbaas/any_ideas_to_train_a_deep_network_without_nvidia/,Santosh16k,1530804158,[removed],0,1
247,2018-7-6,2018,7,6,0,8wbcmm, - ,https://www.reddit.com/r/MachineLearning/comments/8wbcmm/_/,Woodworking94,1530804655,,0,1
248,2018-7-6,2018,7,6,0,8wbk1z,[D] Deep learning on sensor signals for which a physical model is available,https://www.reddit.com/r/MachineLearning/comments/8wbk1z/d_deep_learning_on_sensor_signals_for_which_a/,obnoxious_circlejerk,1530806176,"I am applying a 1-D convolutional network on current signals that drive an electromechanical component for diagnosing faults occurring within the system. A physical model (state space equations) is available for when the component is healthy. It describes the relation between the current signals and the mechanics within the component. So it is possible to fit the model to the current signals to the model and obtain residual signals instead. My goal is to investigate whether using these residual signals results in a better classification.

My question is: is anyone familiar with work where machine learning/deep learning is applied on sensor signals that have been fitted to a domain-specific model first? I have been looking in the health monitoring field without much success. T[his](https://www.sciencedirect.com/science/article/pii/S0950423012000459) was the best work I could find (using a parameter found by a Kalman filter as additional input to the NN).

But I could imagine the same problem statement occurring in other fields where physical signals are used, like climate modeling, quantum chemistry, building physics,...",7,11
249,2018-7-6,2018,7,6,1,8wbp2o,Building Recommendation Systems,https://www.reddit.com/r/MachineLearning/comments/8wbp2o/building_recommendation_systems/,yungyahoo,1530807149,[removed],0,1
250,2018-7-6,2018,7,6,1,8wbtgw,[R] Book: Dictionary Learning Algorithms and Applications,https://www.reddit.com/r/MachineLearning/comments/8wbtgw/r_book_dictionary_learning_algorithms_and/,bulibuta,1530808049,,0,2
251,2018-7-6,2018,7,6,2,8wcbqf,crypto price prediction using LSTM,https://www.reddit.com/r/MachineLearning/comments/8wcbqf/crypto_price_prediction_using_lstm/,rajj007,1530811688,"why my LSTM model is spitting the same values for prediction in the test data!!!!!!!!!!!!

Please help",0,1
252,2018-7-6,2018,7,6,2,8wcjcm,[D] What are some good books to get more theoretical understanding?,https://www.reddit.com/r/MachineLearning/comments/8wcjcm/d_what_are_some_good_books_to_get_more/,olBaa,1530813242,"I'm looking for some rigorous books like:

""Understanding machine learning"" by Shai Ben-David

""High-dimensional probability"" by Vershynin

""Foundations of Data Science"" by Blum/Hopcroft/Hannan


Are there any more specialized books, like something in mean field theory, that you have found interesting/illuminating?",97,194
253,2018-7-6,2018,7,6,2,8wckhb,[N] State-of-the-art Learning Rate Schedules in MXNet (YouTube Series),https://www.reddit.com/r/MachineLearning/comments/8wckhb/n_stateoftheart_learning_rate_schedules_in_mxnet/,thomelane,1530813474,,0,2
254,2018-7-6,2018,7,6,3,8wcpam,Create unique text-style with SOFM,https://www.reddit.com/r/MachineLearning/comments/8wcpam/create_unique_textstyle_with_sofm/,itdxer,1530814413,,0,1
255,2018-7-6,2018,7,6,4,8wd3x5,[P] Discussion of Feasibility? Classification and 3D Modeling from well defined rules,https://www.reddit.com/r/MachineLearning/comments/8wd3x5/p_discussion_of_feasibility_classification_and_3d/,ce5b,1530817368,"Howdy,

Hopefully this is the right place to have this discussion! 

I have a project I am working on. I want to get a sanity check from some of yall technical folks. 

Im an industry guy. So I may be a little off in my terminology. I would be doing this project with a subject matter expert. 

**The Background:**

I have a particular type of data that has a 2D component and a 3D component. Its built of lines, text, and predefined 2D or 3D image blocks. (CAD/DWG) 

There are dozens (hundreds) of predefined rules about how to do the work (done currently by technicians and professionals) that have particular applications of when to apply them that usually need industry experience. 

**My Goal** 

I, with my limited understanding, think that its possible to train computers to do this using machine learning type applications.

So r/MachineLearning, am I in the right wheel house? Ill be around to answer questions. ",3,3
256,2018-7-6,2018,7,6,4,8wdcv2,Centre of Excellence for Data Science and Artificial Intelligence inaugurated in Bangalore,https://www.reddit.com/r/MachineLearning/comments/8wdcv2/centre_of_excellence_for_data_science_and/,write-it,1530819183,,0,2
257,2018-7-6,2018,7,6,4,8wdf03,Which Is The Best Laptop For Machine Learning and Artificial Intelligence?,https://www.reddit.com/r/MachineLearning/comments/8wdf03/which_is_the_best_laptop_for_machine_learning_and/,asifrazzaq1988,1530819630,"Please suggest apart from my search results as given below. 

 1. [Acer 15.6"" Nitro 5 AN515-51-72HL IPS Intel Core i7 7th Gen 7700HQ 2.8GHz NVIDIA GeForce GTX 1050 Ti 8GB Memory 1TB HDD Windows 10 Home Gaming Laptop Model NH.Q2QAA.002](https://www.amazon.com/gp/product/B0798HZXD9/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B0798HZXD9&amp;linkId=2480349b7429670135a994a87bb33a71) 

2.  [Acer Predator Helios 300 Gaming Laptop, 15.6"" Full HD IPS, Intel i7-7700HQ CPU, 16GB DDR4 RAM, 256GB SSD, GeForce GTX 1060-6GB, VR Ready, Red Backlit KB, Metal Chassis, Windows 10 64-bit, G3-571-77QK](https://www.amazon.com/gp/product/B06Y4GZS9C/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B06Y4GZS9C&amp;linkId=3d41e211ebe4ba8490e8382400eb968d)

3.  [HP Omen 15-ax250wm, 15.6"" Full-HD IPS Display, Core i7-7700HQ QC Processor, NVIDIA GTX 1050Ti 4GB Graphics Card, 12GB Memory, 1TB Hard Drive](https://www.amazon.com/gp/product/B076DXN42V/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B076DXN42V&amp;linkId=43ab9350a28fc137e3398a560a731851)

4. Your suggestions

5. Your suggestions

..............................................................................",0,1
258,2018-7-6,2018,7,6,5,8wdxy7,Human-Interactive Subgoal Supervision for Efficient Inverse Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8wdxy7/humaninteractive_subgoal_supervision_for/,YuhaoTang,1530823416,[removed],0,1
259,2018-7-6,2018,7,6,5,8wdysa,[D] AlphaZero Performance Optimization,https://www.reddit.com/r/MachineLearning/comments/8wdysa/d_alphazero_performance_optimization/,vishvananda,1530823582,"There was a lot of [interesting discussion](https://www.reddit.com/r/MachineLearning/comments/8ubkrl/d_improvement_to_the_alphazero_value_target/) about improving the AlphaZero value target in our [last post](https://medium.com/oracledevs/lessons-from-alphazero-part-4-improving-the-training-target-6efba2e71628). I promised to furnish some info about the ways that we've optimized the performance of AlphaZero to achieve some results on much less hardware than DeepMind had access to. Here is the first of the posts on that topic: https://medium.com/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e
This one covers optimizations to made to the training process to produce generations more quickly. Part 6 will cover hyperparameters and changes we made to lower the number of generations needed to reach peak performance.",1,9
260,2018-7-6,2018,7,6,5,8we1o1,[P] A Simple Derivation of the Vector-to-Vector Rotation Matrix,https://www.reddit.com/r/MachineLearning/comments/8we1o1/p_a_simple_derivation_of_the_vectortovector/,david_reiman,1530824172,,2,0
261,2018-7-6,2018,7,6,6,8we3no,Bayes by Backprop explained,https://www.reddit.com/r/MachineLearning/comments/8we3no/bayes_by_backprop_explained/,felixl1990,1530824558,"It took us quite some time to understand Bayes by Backprop thoroughly and we could not find any blog post explaining it in a fairly easy manner. We thought that others might face the same issue and decided to write a quite easy-to-digest blog post about it. 

https://medium.com/neuralspace/probabilistic-deep-learning-bayes-by-backprop-c4a3de0d9743

Comments are welcome, thank you.",0,1
262,2018-7-6,2018,7,6,6,8we4p4,"[D] ""Why are NIPS reviews due so early? Seems totally unnecessary to have them due just before a major conference.""",https://www.reddit.com/r/MachineLearning/comments/8we4p4/d_why_are_nips_reviews_due_so_early_seems_totally/,LeastConfidenceOne,1530824771,,3,0
263,2018-7-6,2018,7,6,7,8wevkc,[R] Variance Networks: When Expectation Does Not Meet Your Expectations,https://www.reddit.com/r/MachineLearning/comments/8wevkc/r_variance_networks_when_expectation_does_not/,hardmaru,1530830571,,5,41
264,2018-7-6,2018,7,6,8,8wfepf,Analysis of the Relationship between U.S. Congressmens Tweets and Their Political Party,https://www.reddit.com/r/MachineLearning/comments/8wfepf/analysis_of_the_relationship_between_us/,AdmirableAnalyst8,1530835106,,0,1
265,2018-7-6,2018,7,6,9,8wfm6r,[D] What non-chip features are useful in a GPU card for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8wfm6r/d_what_nonchip_features_are_useful_in_a_gpu_card/,Liorithiel,1530836852,"I'm planning to get a GTX1060 with 6GB, my goal being training small-to-medium DNN models, probably mostly RNNs, and XGBoost. Now, there are several GPU cards with this specific chip and this amount of memory available, and I am wondering what factors should drive my choice among them. I haven't seen this question here yet, so, here it is: how do I pick a GPU card for machine learning tasks when I already narrowed down the choice to a specific chip and amount of RAM?",12,8
266,2018-7-6,2018,7,6,10,8wg7o3,[D] Will Philosophy Become a Hard Science?,https://www.reddit.com/r/MachineLearning/comments/8wg7o3/d_will_philosophy_become_a_hard_science/,WillBWontB,1530842312,,2,0
267,2018-7-6,2018,7,6,11,8wg9hp,[R] Program Language Translation Using a Grammar-Driven Tree-to-Tree Model,https://www.reddit.com/r/MachineLearning/comments/8wg9hp/r_program_language_translation_using_a/,Mehdi2277,1530842765,,1,9
268,2018-7-6,2018,7,6,11,8wgbq5,[D]The best university to learn ML,https://www.reddit.com/r/MachineLearning/comments/8wgbq5/dthe_best_university_to_learn_ml/,Geta_ccc,1530843343,If you want to learn ML in university. Which one will you choose,5,2
269,2018-7-6,2018,7,6,11,8wgffh,[D] Whats that machine call when the machine sucks up the air to get clean air?,https://www.reddit.com/r/MachineLearning/comments/8wgffh/d_whats_that_machine_call_when_the_machine_sucks/,David77999,1530844305,I totally forgot the name of the machine,4,0
270,2018-7-6,2018,7,6,12,8wgrxs,[Project] An AI system for editing music in videos (MIT-CSAIL),https://www.reddit.com/r/MachineLearning/comments/8wgrxs/project_an_ai_system_for_editing_music_in_videos/,theainerd,1530847526,,14,148
271,2018-7-6,2018,7,6,12,8wgubb,[D] Floydhub and RemoteML are giving away 3x100h of K80 GPU time,https://www.reddit.com/r/MachineLearning/comments/8wgubb/d_floydhub_and_remoteml_are_giving_away_3x100h_of/,Sig_Luna,1530848171,"Hey /r/MachineLearning!

My name is Dominic and I am the founder of RemoteML.

We just organized a giveaway with Floydhub. For three weeks, Floydhub is giving away 100h of K80 GPU time each week to RemoteML members.

For more infos on how to register and join the giveaway, join our Slack channel (see #announcements):

[https://remoteml.com/chat/](https://remoteml.com/chat/)",1,3
272,2018-7-6,2018,7,6,13,8wh0hl,Math major or cs major,https://www.reddit.com/r/MachineLearning/comments/8wh0hl/math_major_or_cs_major/,pg13mvp,1530849790,"I'm a student from asia and I'm going to pick my major after two weeks.

I'm interesting in machine learning , data science , and AI.  
but I'm still a beginner and don't know what skill is needed to  master ml and where to learn it


Following are my thoughts 

Math :  

it's is definitely the foundation of algorithms and ml.
But in addition to calculus ,linear algebra , i need to study some other domain too . Such as geometry,and it seems has nothing to do with AI

and the heavy workload maybe would let me have enough times to practice programming

CS :

cs is my first pick , but I can only go to the second university in my city while I can go to the first if I pick math.

And I'm not interesting in security , network , operating system.
I just want to learn the programming skills and algorithms and apply them on AL .

And i'm happy learn more math if needed.




Btw, my interest in Al starts from alphaho ,I can play go very well ,and it shocked me a lot when it beated the would champion.



Thanks for reading and replying





",0,1
273,2018-7-6,2018,7,6,13,8wh1tn,[D] Libratus: the world's best poker player,https://www.reddit.com/r/MachineLearning/comments/8wh1tn/d_libratus_the_worlds_best_poker_player/,baylearn,1530850141,,10,11
274,2018-7-6,2018,7,6,13,8whazt,For people who have a fair understand of ML but never read a research paper. Which research paper to start with??,https://www.reddit.com/r/MachineLearning/comments/8whazt/for_people_who_have_a_fair_understand_of_ml_but/,Blueskyblackspace,1530852717,[removed],0,1
275,2018-7-6,2018,7,6,14,8whgep,"Difference Between Artificial Intelligence, Machine Learning &amp; Deep Learning?",https://www.reddit.com/r/MachineLearning/comments/8whgep/difference_between_artificial_intelligence/,asifrazzaq1988,1530854271,,0,1
276,2018-7-6,2018,7,6,15,8whrlh,[P] Improvements in Deep Q Learning (Dueling double DQN with PER) with Doom  and Tensorflow (article and video tutorial),https://www.reddit.com/r/MachineLearning/comments/8whrlh/p_improvements_in_deep_q_learning_dueling_double/,cranthir_,1530857700,"Hey there!

The new article and video of Deep Reinforcement Learning course with Tensorflow are out .

In the article   we'll learn the **latests improvments in Deep Q Learning (Dueling Double DQN, Prioritized Expericence Replay and fixed q-targets).** 

In this video , we'll implement a DDDQN **agent with Tensorflow that learns to play Doom in a deadly corridor .**

By the way our videos qualities are much better than before thanks to a green screen and new camera ! 

The article : [https://medium.freecodecamp.org/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682](https://medium.freecodecamp.org/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682)

The video  : [https://www.youtube.com/watch?v=-Ynjw0Vl3i4](https://www.youtube.com/watch?v=-Ynjw0Vl3i4)

The Syllabus of the course : [https://simoninithomas.github.io/Deep\_reinforcement\_learning\_Course/](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)

[ ](https://i.redd.it/lzn5egb6s9811.png)

Again let me say **what you think about the course (articles and videos) and how it should be improved!**

Thanks and have a great day!  ",8,37
277,2018-7-6,2018,7,6,16,8wi2q6,Gradients for softmax are tiny,https://www.reddit.com/r/MachineLearning/comments/8wi2q6/gradients_for_softmax_are_tiny/,harvey_slash,1530861219,[removed],0,1
278,2018-7-6,2018,7,6,16,8wi6mi,How to deal with predicting non-normalized prediction values using neural network?,https://www.reddit.com/r/MachineLearning/comments/8wi6mi/how_to_deal_with_predicting_nonnormalized/,omers66,1530862489,[removed],0,1
279,2018-7-6,2018,7,6,16,8wi7j6,[N] SAR-Optical deep learning dataset,https://www.reddit.com/r/MachineLearning/comments/8wi7j6/n_saroptical_deep_learning_dataset/,burn_in_flames,1530862809,"The first large scale Synthetic Aperture Radar (SAR) and optical image remote sensing dataset has been published. The aim of the dataset is to provide high resolution remote sensing data to drive applications in geoscience, remote sensing and multi-modal image matching.

[https://arxiv.org/abs/1807.01569](https://arxiv.org/abs/1807.01569)",0,19
280,2018-7-6,2018,7,6,17,8wij5h,Scale Expansion Network (PSENet),https://www.reddit.com/r/MachineLearning/comments/8wij5h/scale_expansion_network_psenet/,RedEyed__,1530867048,[removed],0,1
281,2018-7-6,2018,7,6,18,8wil9g,Python - Data mining and Machine learning Course - 100% OFF,https://www.reddit.com/r/MachineLearning/comments/8wil9g/python_data_mining_and_machine_learning_course/,Masawdah,1530867800,,0,1
282,2018-7-6,2018,7,6,18,8wio7x,[Discussion] A book about the history of machine learning?,https://www.reddit.com/r/MachineLearning/comments/8wio7x/discussion_a_book_about_the_history_of_machine/,PM_ME_WEIRD_THOUGHTS,1530868806,"I'm looking for a book or resource that does a good job at explaining the history of machine learning. Right from the beginning with the first perceptrons until the recent history. I want it to cover the impact it's had on industry and in our daily lives.

I'm not looking for a technical document although I have no issue if it includes technical detail. I'm essentially looking for a resource I can use to fill in the gaps in my knowledge so that I can explain machine learning in a broader context to beginners",6,23
283,2018-7-6,2018,7,6,18,8wiqcj,Autonomous UAV (drone) for technical inspections,https://www.reddit.com/r/MachineLearning/comments/8wiqcj/autonomous_uav_drone_for_technical_inspections/,Batareika_1,1530869529,,0,1
284,2018-7-6,2018,7,6,18,8wis1k,[Project] RoboSat: feature extraction from aerial and satellite imagery,https://www.reddit.com/r/MachineLearning/comments/8wis1k/project_robosat_feature_extraction_from_aerial/,danieljh,1530870114,,6,49
285,2018-7-6,2018,7,6,19,8wiw9d,[R] Statistics in Plain English for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8wiw9d/r_statistics_in_plain_english_for_machine_learning/,dearpetra,1530871576,,0,1
286,2018-7-6,2018,7,6,19,8wixb1,[D] Scale Expansion Network (PSENet),https://www.reddit.com/r/MachineLearning/comments/8wixb1/d_scale_expansion_network_psenet/,RedEyed__,1530871897,"[https://arxiv.org/pdf/1806.02559.pdf](https://arxiv.org/pdf/1806.02559.pdf)

![img](2wp2vtokya811)",8,13
287,2018-7-6,2018,7,6,19,8wj34x,What's the best sub $1000 laptop for ML?,https://www.reddit.com/r/MachineLearning/comments/8wj34x/whats_the_best_sub_1000_laptop_for_ml/,HC_Tech,1530873888,[removed],0,1
288,2018-7-6,2018,7,6,20,8wj9bi,face-api.js - Analysis of TensorFlow.js usage,https://www.reddit.com/r/MachineLearning/comments/8wj9bi/faceapijs_analysis_of_tensorflowjs_usage/,ArturSkowronski,1530875867,[removed],0,1
289,2018-7-6,2018,7,6,20,8wjajj,Beginner (free) guide to web services for ML,https://www.reddit.com/r/MachineLearning/comments/8wjajj/beginner_free_guide_to_web_services_for_ml/,elrakone,1530876260,[removed],0,1
290,2018-7-6,2018,7,6,21,8wjil5,Can I attain the expectation of the posterior distribution for Convolutional Neural Network by MCMC?,https://www.reddit.com/r/MachineLearning/comments/8wjil5/can_i_attain_the_expectation_of_the_posterior/,ruiHuang,1530878643,[removed],0,1
291,2018-7-6,2018,7,6,21,8wjmy7,A.I use cases on a bitcoin blockchain data set (Our project),https://www.reddit.com/r/MachineLearning/comments/8wjmy7/ai_use_cases_on_a_bitcoin_blockchain_data_set_our/,SufficientMeal,1530879806,[removed],0,1
292,2018-7-6,2018,7,6,21,8wjo6b,[D] Is there any prescription dataset?,https://www.reddit.com/r/MachineLearning/comments/8wjo6b/d_is_there_any_prescription_dataset/,RandomPerson019,1530880130,Is there any prescription dataset. My idea is to build an automated prescription generator using machine learning.  ,2,2
293,2018-7-6,2018,7,6,21,8wjp6t,,https://www.reddit.com/r/MachineLearning/comments/8wjp6t//,Woodworking94,1530880406,,0,1
294,2018-7-6,2018,7,6,22,8wjwgd,[R] Mapping environments with deep networks (VGG Blog),https://www.reddit.com/r/MachineLearning/comments/8wjwgd/r_mapping_environments_with_deep_networks_vgg_blog/,brainggear,1530882312,,0,22
295,2018-7-6,2018,7,6,22,8wjxdf,Imagine Nature  A trip into artificial imagination,https://www.reddit.com/r/MachineLearning/comments/8wjxdf/imagine_nature_a_trip_into_artificial_imagination/,onetaste108,1530882518,,1,1
296,2018-7-6,2018,7,6,22,8wk3sm,Comparative Analysis of Distributed Training of DNNs- Raven Model vs Existing,https://www.reddit.com/r/MachineLearning/comments/8wk3sm/comparative_analysis_of_distributed_training_of/,ravensdraven,1530884034,"[https://medium.com/ravenprotocol/comparative-analysis-raven-protocol-v-s-conventional-methods-a94b795c2f8c](https://medium.com/ravenprotocol/comparative-analysis-raven-protocol-v-s-conventional-methods-a94b795c2f8c)

 Coming right to the point, Deep Learning is the most advanced and still mostly uncharted form of Machine Learning that many are apprehensive of applying, owing to the simple non-availability of, wait for it **Compute Power**. 

Consider the non-availability or compute-demand that is hard to meet, of GPU resources to train a model, or a very huge requirement that requires abundant compute resources to train the models. This calls for innovative methods to perform DL training. Traditional methods involve Data and Model Parallelism, which partially quenches that demand, with distributed systems.  *Raven takes both Data and Model Parallelisation approaches to form a different model of distribution.* ",0,1
297,2018-7-6,2018,7,6,22,8wk6e6,mnist application using neural network trained in pytorch,https://www.reddit.com/r/MachineLearning/comments/8wk6e6/mnist_application_using_neural_network_trained_in/,nithin1357,1530884647,[removed],0,1
298,2018-7-6,2018,7,6,22,8wk6oi,[P] Build a lookalike model,https://www.reddit.com/r/MachineLearning/comments/8wk6oi/p_build_a_lookalike_model/,brioche90210,1530884708,"Hi everyone! 

Working on a research project. I have identified a group of people who are self-reported Harry Potter fans, and I am trying to build a lookalike model to identify likely Harry Potter fans from the rest of my data. 

Assuming that I dont know who in my data is not a Harry Potter fan (I only have those who have self-identified) but that I have copious amounts of data on each individual (age, income, books theyve read, movies theyve watched), how would I develop a lookalike model to identity likely fans?

Im considering nearest neighbor, but I dont know if thats the right approach? Any help is appreciated! Thanks!!",0,0
299,2018-7-6,2018,7,6,22,8wk9fx,Updates to the XGBoost GPU algorithms.,https://www.reddit.com/r/MachineLearning/comments/8wk9fx/updates_to_the_xgboost_gpu_algorithms/,rohan36,1530885357,[removed],0,1
300,2018-7-6,2018,7,6,23,8wkegb,100 Days of ML Code Challenge,https://www.reddit.com/r/MachineLearning/comments/8wkegb/100_days_of_ml_code_challenge/,SagarKhanapurkar,1530886454,,0,1
301,2018-7-6,2018,7,6,23,8wkfd9,NAVER Clova AI Residency,https://www.reddit.com/r/MachineLearning/comments/8wkfd9/naver_clova_ai_residency/,ni9elf,1530886657,[removed],1,1
302,2018-7-6,2018,7,6,23,8wki4o,[P] Science needs to report more failures; here is a bad run from a celebrity-producing GAN.,https://www.reddit.com/r/MachineLearning/comments/8wki4o/p_science_needs_to_report_more_failures_here_is_a/,frizface,1530887310,,15,54
303,2018-7-6,2018,7,6,23,8wkmt8,"Hello everyone, I have a data set of 10,000+ text posts and I want to label. I have a set of keywords that will help me label as either ""threat"" or ""no threat"". What is the best way to go about this?",https://www.reddit.com/r/MachineLearning/comments/8wkmt8/hello_everyone_i_have_a_data_set_of_10000_text/,TripleThreatBDog,1530888350,[removed],0,1
304,2018-7-7,2018,7,7,1,8wlb80,On OpenAI's first SuperComputer,https://www.reddit.com/r/MachineLearning/comments/8wlb80/on_openais_first_supercomputer/,vector_machines,1530893352,,0,1
305,2018-7-7,2018,7,7,2,8wlv8m,Does it make sense to waste our time and energy on anything else but ML(AI)?,https://www.reddit.com/r/MachineLearning/comments/8wlv8m/does_it_make_sense_to_waste_our_time_and_energy/,3PRUV3TA,1530897391,,0,1
306,2018-7-7,2018,7,7,2,8wm0c4,"Hyperparameter optimization, is this a good start?",https://www.reddit.com/r/MachineLearning/comments/8wm0c4/hyperparameter_optimization_is_this_a_good_start/,FinelyTaylored,1530898380,"So I've started creating ANNs with TensorFlow in Keras and optimizing the parameters of a model seems daunting.

I stumbled across this article and it makes scikit-learn seem like a pretty good way of doing so.

[https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)

Before I sink time into that process, are there any ways of parameter optimization that might be easier, more complex, or just more useful?",0,1
307,2018-7-7,2018,7,7,2,8wm3e0,Neuromorphic computing with multi-memristive synapses.,https://www.reddit.com/r/MachineLearning/comments/8wm3e0/neuromorphic_computing_with_multimemristive/,blueneuronDOTnet,1530898955,,0,1
308,2018-7-7,2018,7,7,2,8wm6tb,ML Noob: Would it be possible to stream from my (Hikvision) IP CCTV cameras to an ML library such as (OpenCV?) in order to train face detection?,https://www.reddit.com/r/MachineLearning/comments/8wm6tb/ml_noob_would_it_be_possible_to_stream_from_my/,lonespear,1530899634,,0,1
309,2018-7-7,2018,7,7,3,8wmbof,[D] Variational Autoencoder confusion... Am I wrong?,https://www.reddit.com/r/MachineLearning/comments/8wmbof/d_variational_autoencoder_confusion_am_i_wrong/,idioth,1530900559,"Im confused about a basic thing, that maybe someone can help me understand:

Basics:

**fact 1**: One purpose of a VAE is to train a generator to allow for efficient sampling of **Z** to generate examples from **X.**

**fact 2**: The way the VAE is formulated is that each datum, **x**, is encoded to **mu** and **sigma**, and a KLD loss is determined for each **x.**

**fact 3**: The KLD loss is added to the reconstruction loss for that **x**, and that is the total loss for a data point, or alternatively (usually) those losses are summed over all **x**s in a mini batch. Therefore there exists a trade-off between KLD and reconstruction that is (presumably) balanced.

My confusion is as follows:

If the (gradient of the) KLD loss is sufficiently large, or alternatively reconstruction loss is sufficiently small, what prevents the encoder from emitting *only* **mu** = 0, and **sigma** = 1, and ignoring the the reconstruction loss entirely? Will **Z** collapse to a point? Alternatively if reconstruction loss is sufficiently large, then KLD is entirely ignored, and the model acts as an autoencoder?

That being said, I don't understand what are the conditions under which produce a **Z** that is unit normal.

What am I getting wrong here?

Other thoughts:

Is the warm-up (slowly increasing a scalar on KLD loss) in the [Ladder-VAE](https://arxiv.org/pdf/1602.02282.pdf) paper trying to overcome this somehow?

Is the [Beta-VAE](https://openreview.net/forum?id=Sy2fzU9gl) paper *just* exploring this trade-off between reconstruction and KLD? Could a more difficult to train model result in a Beta that is very small (&lt;&lt;1) with the same results?

Is this trade off between KLD and reconstruction **another** hyperparameter that I need to tune to get a unit normal **Z**depending on my model, data and other hyperparameters?

Often test-time for a VAE is deterministic sampling (just using **mu**). If that is the case, then can I get a better conditioned **Z** by using a deterministic autoencoder, and having a loss on a batch of **z** that is the KLD between the means and sigmas of those mini-batch **z**s and the unit normal (sort of like [advarsarial-autoencoders](https://arxiv.org/abs/1511.05644), but with a more simple loss function on **Z**) ?

I have observed (on my data and models) that deterministic auto encoders with batch-norm layers tend to produce approximately unit normal **Z**.",7,43
310,2018-7-7,2018,7,7,3,8wmnrx,Dataset wanted,https://www.reddit.com/r/MachineLearning/comments/8wmnrx/dataset_wanted/,NetworkForce,1530903178,[removed],0,1
311,2018-7-7,2018,7,7,4,8wmpyc,[D] A Deep Dive into Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8wmpyc/d_a_deep_dive_into_reinforcement_learning/,qwert7890-,1530903628,,0,6
312,2018-7-7,2018,7,7,4,8wmuwx,The Genetic Algorithm Explained,https://www.reddit.com/r/MachineLearning/comments/8wmuwx/the_genetic_algorithm_explained/,CodePlea,1530904637,,0,1
313,2018-7-7,2018,7,7,5,8wn7ki,"Reading pickle file using joblib gives error: ValueError: reading array data, expected 1200 bytes got 0",https://www.reddit.com/r/MachineLearning/comments/8wn7ki/reading_pickle_file_using_joblib_gives_error/,Ashish2211,1530907325,[removed],0,1
314,2018-7-7,2018,7,7,5,8wnd53,Advice about building a model before collecting data,https://www.reddit.com/r/MachineLearning/comments/8wnd53/advice_about_building_a_model_before_collecting/,yungyahoo,1530908462,[removed],0,1
315,2018-7-7,2018,7,7,5,8wnikk,Made a machine learning program in SCRATCH !,https://www.reddit.com/r/MachineLearning/comments/8wnikk/made_a_machine_learning_program_in_scratch/,GoVed,1530909608,,3,15
316,2018-7-7,2018,7,7,5,8wno2l,deep learning,https://www.reddit.com/r/MachineLearning/comments/8wno2l/deep_learning/,uchihabloodline,1530910782,[removed],0,1
317,2018-7-7,2018,7,7,7,8wocnm,How Chinese Internet Giant Baidu Uses Artificial Intelligence and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8wocnm/how_chinese_internet_giant_baidu_uses_artificial/,asifrazzaq1988,1530916326,,0,1
318,2018-7-7,2018,7,7,7,8wohxy,MIT paper in machine learning for drug discovery at ICML 2018: very incomplete,https://www.reddit.com/r/MachineLearning/comments/8wohxy/mit_paper_in_machine_learning_for_drug_discovery/,mostafabenh,1530917628,,0,2
319,2018-7-7,2018,7,7,8,8wok8p,[P] Deepmind: Human-level performance in first-person multiplayer games,https://www.reddit.com/r/MachineLearning/comments/8wok8p/p_deepmind_humanlevel_performance_in_firstperson/,Thorbinator,1530918187,,2,1
320,2018-7-7,2018,7,7,9,8wp00m,"[P] Zenobot: A silly LSTM NLP proverb generator project, served via Flask API and presented with React. Trained on a tiny dataset of 2000 proverbs.",https://www.reddit.com/r/MachineLearning/comments/8wp00m/p_zenobot_a_silly_lstm_nlp_proverb_generator/,garrettw,1530922113,,6,3
321,2018-7-7,2018,7,7,9,8wpaju,What are the biggest impediments to machine learning progress?,https://www.reddit.com/r/MachineLearning/comments/8wpaju/what_are_the_biggest_impediments_to_machine/,Bitman321,1530924753,[removed],0,1
322,2018-7-7,2018,7,7,10,8wpiyz,Current Uses of Capsule Networks?,https://www.reddit.com/r/MachineLearning/comments/8wpiyz/current_uses_of_capsule_networks/,santoso-sheep,1530926988,"Last year there was a lot of hype around Hintons Capsule Networks, however it seemed to be short lived. I was wondering how CapsNets have fared in comparison to other models and if they are relevant today in 2018? Are they worth investigating?",0,1
323,2018-7-7,2018,7,7,11,8wpsk1,[P] A Project Based Introduction to TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/8wpsk1/p_a_project_based_introduction_to_tensorflowjs/,BurntOutProgrammer,1530929569,,4,170
324,2018-7-7,2018,7,7,12,8wqad1,Philippines QT4 24B 100mm and 150mm 1500PSI concrete hollow blocks CHB ...,https://www.reddit.com/r/MachineLearning/comments/8wqad1/philippines_qt4_24b_100mm_and_150mm_1500psi/,dymachine01,1530934434,,1,1
325,2018-7-7,2018,7,7,12,8wqazi,Generative Probabilistic Novelty Detection with Adversarial Autoencoders,https://www.reddit.com/r/MachineLearning/comments/8wqazi/generative_probabilistic_novelty_detection_with/,stpidhorskyi,1530934600,[removed],0,1
326,2018-7-7,2018,7,7,13,8wqhc0,[D] Need help with satellite image + machine learning projects,https://www.reddit.com/r/MachineLearning/comments/8wqhc0/d_need_help_with_satellite_image_machine_learning/,pimonster00,1530936374,"I'm interested in doing a satellite image processing project for socioeconomic analysis. I'm specifically interested in focusing on analyzing health parameters; what are interesting problem statements within this domain? There are plenty of open source satellite image datasets available, but I'll choose the dataset according to my problem statement. 
Please help me out, thanks! ",0,3
327,2018-7-7,2018,7,7,13,8wqp74,[D] Need help with KNN Prediction and Confusion Matrix.,https://www.reddit.com/r/MachineLearning/comments/8wqp74/d_need_help_with_knn_prediction_and_confusion/,sahil0696,1530938681,"Hey, I'm working with this data: South Africa Heart Disease Dataset, on openml : https://www.openml.org/d/1498.

I'm using KNN to classify the target variable, having train-test split of 80-20%.
Now, with all the pre-processing I'm getting an accuracy of 60% and the confusion matrix looks like this 
array([[53,  6],
       [31,  3]]).

problem: How to reduce this type type 2 or false positive error.
",0,1
328,2018-7-7,2018,7,7,14,8wqxu0,Gradient descent evolutionary algorithm equivalence,https://www.reddit.com/r/MachineLearning/comments/8wqxu0/gradient_descent_evolutionary_algorithm/,MemeBox,1530941395,[removed],0,1
329,2018-7-7,2018,7,7,14,8wr0ph,How a neural net's weights get optimized when feeding it with multiple training samples ?,https://www.reddit.com/r/MachineLearning/comments/8wr0ph/how_a_neural_nets_weights_get_optimized_when/,Al-Khazrajy,1530942339,[removed],0,1
330,2018-7-7,2018,7,7,15,8wr7kb,Data importing in google colab notebooks.,https://www.reddit.com/r/MachineLearning/comments/8wr7kb/data_importing_in_google_colab_notebooks/,ank_itsharma,1530944644,[removed],0,1
331,2018-7-7,2018,7,7,19,8ws7p5,RAPIDS 2018 London - Free one day conference on reproducibility and data provenance with afternoon workshop,https://www.reddit.com/r/MachineLearning/comments/8ws7p5/rapids_2018_london_free_one_day_conference_on/,mrmrcoleman,1530958458,[removed],0,1
332,2018-7-7,2018,7,7,20,8wsfyq,pre-trained word embeddings / vectors,https://www.reddit.com/r/MachineLearning/comments/8wsfyq/pretrained_word_embeddings_vectors/,mikkokotila,1530961716,[removed],0,1
333,2018-7-7,2018,7,7,20,8wsmb6,machine translation: seq2seq with and without attention,https://www.reddit.com/r/MachineLearning/comments/8wsmb6/machine_translation_seq2seq_with_and_without/,errminator,1530964037,[removed],0,1
334,2018-7-7,2018,7,7,21,8wsrui,GitHub - spotify/noether: Machine Learning Scala Tools.,https://www.reddit.com/r/MachineLearning/comments/8wsrui/github_spotifynoether_machine_learning_scala_tools/,regadas,1530965874,,0,1
335,2018-7-7,2018,7,7,21,8wsxim,Amazon go is the first walk in walk out grocery store that lets you buy stuff with zero interaction. It uses machine learning and AI to determine what exactly you picked up from the store and charge it to your account. https://youtu.be/vorkmWa7He8,https://www.reddit.com/r/MachineLearning/comments/8wsxim/amazon_go_is_the_first_walk_in_walk_out_grocery/,shiv_red,1530967715,[removed],0,2
336,2018-7-7,2018,7,7,22,8wt0ls,[D] What are skills needed in autonomous vehicles field ?,https://www.reddit.com/r/MachineLearning/comments/8wt0ls/d_what_are_skills_needed_in_autonomous_vehicles/,__bee,1530968639,"I am trying to write down all the skills needed to make it into autonomous vehicles field,  While there is no MSc programs for this kind of jobs other than the nano-degree. It looks to me that the aspects of self driving cars are at the intersection of sensors data, machine learning and networked communications amongst cars. 

Question: From the theoritical perspective, what should I focus on. What are the problems needed. ",4,0
337,2018-7-7,2018,7,7,22,8wt1gm,Do you want to understand Logistic Regression in the simplest possible way? Watch this video!,https://www.reddit.com/r/MachineLearning/comments/8wt1gm/do_you_want_to_understand_logistic_regression_in/,Amir_PD,1530968883,,0,1
338,2018-7-7,2018,7,7,22,8wt3xl,Here is the best video tutorial I have ever seen about Linear Regression! Simple and clear!,https://www.reddit.com/r/MachineLearning/comments/8wt3xl/here_is_the_best_video_tutorial_i_have_ever_seen/,Amir_PD,1530969577,,0,1
339,2018-7-7,2018,7,7,23,8wtmam,How can I get into this field as an electrical engineer?,https://www.reddit.com/r/MachineLearning/comments/8wtmam/how_can_i_get_into_this_field_as_an_electrical/,walkingbed1919,1530974483,[removed],0,1
340,2018-7-8,2018,7,8,0,8wtv8b,Tensorflow or Scikitlearn?,https://www.reddit.com/r/MachineLearning/comments/8wtv8b/tensorflow_or_scikitlearn/,BySNiP,1530976691,[removed],0,1
341,2018-7-8,2018,7,8,1,8wugsy,"[D] Machine Learning Terminology , usage, and coinage.",https://www.reddit.com/r/MachineLearning/comments/8wugsy/d_machine_learning_terminology_usage_and_coinage/,AdditionalWay,1530981840,"What are the conventions of terminology usage and coinage? 

In my particular case, I would like to use developing embeddings to represent movies, and I would also like to develop embeddings to represent anime. 

It seems that whenever people do these types of projects, they do (insert item here)2vec to pay homage to the word2vec method that they used, so I would use Anime2Vec and Movie2Vec. But what about the instance of multiple people who are doing projects on representing the same item with vector?

Both  Anime2Vec and Movie2Vec seem to be already used in other projects, the latter seem to be used in several different projects by several different people, with one having an official paper on Arxiv. 

Would the courtesy be that those phrases be only used for the projects of those particular author. Or could anyone use (Insert item here)2vec? I should I used a different name and just reference word2vec somewhere in the writeup? 

",4,5
342,2018-7-8,2018,7,8,1,8wuhb5,Budget pc for beginning with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8wuhb5/budget_pc_for_beginning_with_machine_learning/,AnotherWorldliness,1530981957,[removed],0,1
343,2018-7-8,2018,7,8,2,8wuomg,[D] Geospatial Vector Extraction from Aerial Imagery,https://www.reddit.com/r/MachineLearning/comments/8wuomg/d_geospatial_vector_extraction_from_aerial_imagery/,walrusrage1,1530983600,"Hi all,

New to machine learning, but have what I think is a perfect use-case and training data to put to good use.

I'd like to know what you think is the best approach for extracting straight vector lines from rows of vegetation in aerial imagery, given 1000s of sample images with vector lines manually drawn over each row of vegetation as a training set.

We've tries other automated methods, but they all seem to have their flaws. Any advice/discussion would be much appreciated!",5,16
344,2018-7-8,2018,7,8,2,8wuweo,[P] Pandas on Ray  Early Lessons from Parallelizing Pandas,https://www.reddit.com/r/MachineLearning/comments/8wuweo/p_pandas_on_ray_early_lessons_from_parallelizing/,goongossi,1530985337,,6,101
345,2018-7-8,2018,7,8,4,8wvo8g,Random Forests vs Decision Trees,https://www.reddit.com/r/MachineLearning/comments/8wvo8g/random_forests_vs_decision_trees/,sweetlou357,1530991662,[removed],0,1
346,2018-7-8,2018,7,8,4,8wvvzv,[X-Post r/ClashRoyale] I trained 2 Convolutional Neural Networks to learn my opponent's cards and when those cards are played. This AI tracks your opponent's card cycle AND current elixir!,https://www.reddit.com/r/MachineLearning/comments/8wvvzv/xpost_rclashroyale_i_trained_2_convolutional/,zMuska,1530993561,"Before I get flamed, Please let me mention that this is *not* open for public use!

*Small Note:*

*If you see this Supercell, I'm not trying to create any bots/applications that'll encourage cheating. I made this for a fun project! I'd actually love to work for you guys one day!*

This is a small project I made in a few days to practice image recognition with convolutional neural networks. In a nutshell, the first neural network is in charge of learning my opponent's cards, and the second neural network is in charge of knowing *which* card is being placed. With just these 2 pieces of information, I'm able to track my opponent's card cycle and current elixir count.

[Image 1](https://i.imgur.com/r4zqYmj.png) shows the live match with my AI tracker in the background. Also, the AI is spectating the game. As you can see, it's predicting that my opponent has around 4.4 elixir, and the cards in hand are: Mega Minion, Witch, Lumberjack, and an Unknown Card.

[Image 2](https://i.imgur.com/sskPau4.jpg) shows a replay of this match, specifically at the exact time Image 1 was taken. As you can see, my opponent actually had everything (Elixir, Cards in hand, and Upcoming cards) my AI tracker predicted.

This also can possibly be used as an architecture for the first Clash Royale AI. If any of you are experienced with Game Theory/AI and is interested in making a smart AI for fun, let me know!

For those who are actually interested in how this AI was made, here's a rough draft report. (Don't worry, this report was written to an audience that has NO background in software engineering/machine learning): [The Report](https://www.dropbox.com/s/zczo8r217kx1q3z/Report.pdf?dl=0)

Interested in the actual code? Check it out here: [The Code (GitHub)](https://github.com/AmarSaini/Clash-Royale-AI-Card-Tracker)

**Please don't ask how to run it, as it's not meant for public use and won't run. I won't be providing instructions on how to use the AI assistant.**

Thanks for reading!

\- Muska

\[EDIT 1\] ~~It appears that the report won't open for those on mobile, since it's 1.4 MB (which is too large for GitHub on mobile). If you still want to see the report, DM me and I'll send one over!~~

\[EDIT 2\] I updated the report link!

\[EDIT 3\] Added link to the code/GitHub",0,1
347,2018-7-8,2018,7,8,5,8wvz12,[P] I trained 2 Convolutional Neural Networks to learn my opponent's cards and when those cards are played. This AI tracks your opponent's card cycle AND current elixir!,https://www.reddit.com/r/MachineLearning/comments/8wvz12/p_i_trained_2_convolutional_neural_networks_to/,zMuska,1530994244,"Before I get flamed by the devs/mods of Clash Royale, Please let me mention that this is *not* open for public use!

*Small Note:*

*If you see this Supercell, I'm not trying to create any bots/applications that'll encourage cheating. I made this for a fun project! I'd actually love to work for you guys one day!*

This is a small project I made in a few days to practice image recognition with convolutional neural networks. In a nutshell, the first neural network is in charge of learning my opponent's cards, and the second neural network is in charge of knowing *which* card is being placed. With just these 2 pieces of information, I'm able to track my opponent's card cycle and current elixir count.

[Image 1](https://i.imgur.com/r4zqYmj.png) shows the live match with my AI tracker in the background. Also, the AI is spectating the game. As you can see, it's predicting that my opponent has around 4.4 elixir, and the cards in hand are: Mega Minion, Witch, Lumberjack, and an Unknown Card.

[Image 2](https://i.imgur.com/sskPau4.jpg) shows a replay of this match, specifically at the exact time Image 1 was taken. As you can see, my opponent actually had everything (Elixir, Cards in hand, and Upcoming cards) my AI tracker predicted.

This also can possibly be used as an architecture for the first Clash Royale AI. If any of you are experienced with Game Theory/AI and is interested in making a smart AI for fun, let me know!

For those who are actually interested in how this AI was made, here's a rough draft report. (Don't worry, this report was written to an audience that has NO background in software engineering/machine learning): [The Report](https://www.dropbox.com/s/zczo8r217kx1q3z/Report.pdf?dl=0)

Interested in the actual code? Check it out here: [The Code (GitHub)](https://github.com/AmarSaini/Clash-Royale-AI-Card-Tracker)

**Please don't ask how to run it, as it's not meant for public use and won't run. I won't be providing instructions on how to use the AI assistant.**

Thanks for reading!

\- Muska

\[EDIT 1\] ~~It appears that the report won't open for those on mobile, since it's 1.4 MB (which is too large for GitHub on mobile). If you still want to see the report, DM me and I'll send one over!~~

\[EDIT 2\] I updated the report link!

\[EDIT 3\] Added link to the code/GitHub",0,7
348,2018-7-8,2018,7,8,5,8wvzc5,COTA: Improving the Speed and Accuracy of UBER Customer Support through Ranking and Deep Networks,https://www.reddit.com/r/MachineLearning/comments/8wvzc5/cota_improving_the_speed_and_accuracy_of_uber/,ciolaamotore,1530994318,,1,3
349,2018-7-8,2018,7,8,5,8ww8zv,Career path for Machine Learning research scientist,https://www.reddit.com/r/MachineLearning/comments/8ww8zv/career_path_for_machine_learning_research/,involutionn,1530996729,[removed],0,1
350,2018-7-8,2018,7,8,6,8wwfe1,[N] Q&amp;A With Microsoft Chief Speech Scientist Xuedong Huang,https://www.reddit.com/r/MachineLearning/comments/8wwfe1/n_qa_with_microsoft_chief_speech_scientist/,trcytony,1530998232,,0,1
351,2018-7-8,2018,7,8,6,8wwgaq,"[D] One month ago, I asked here about starting a blog for beginners. I'm going strong!",https://www.reddit.com/r/MachineLearning/comments/8wwgaq/d_one_month_ago_i_asked_here_about_starting_a/,FlyingQuokka,1530998463,"After getting generally positive feedback about starting the blog, I decided to start it. I've learned (and re-learned) a lot along the way, and thought I'd share my progress: the blog is live [here](https://beginningwithml.wordpress.com/)!

I'd love thoughts (and corrections especially) about the content. Hopefully it's actually useful for any beginners here :)",0,0
352,2018-7-8,2018,7,8,6,8wwhl7,[D] Using ELU / PReLU instead of ReLU when fine-tuning,https://www.reddit.com/r/MachineLearning/comments/8wwhl7/d_using_elu_prelu_instead_of_relu_when_finetuning/,t897349817,1530998781,"I'm trying to use ELU / PReLU instead of ReLU when fine-tuning a DenseNet-161 (pretrained on ImageNet). PReLU slightly reduces the performance (~1%), but ELU reduces performance by 22%. Am I missing something? Should I adjust other hyperparameters? Maybe finetuning in this case won't work properly since the change in the activation function harm the knowledge transfer.",5,8
353,2018-7-8,2018,7,8,6,8wwlft,"[1807.00123] Machine Learning for Integrating Data in Biology and Medicine: Principles, Practice, and Opportunities",https://www.reddit.com/r/MachineLearning/comments/8wwlft/180700123_machine_learning_for_integrating_data/,michaelhoffman,1530999727,,4,6
354,2018-7-8,2018,7,8,7,8wwu2k,How YouTube Recommends Videos,https://www.reddit.com/r/MachineLearning/comments/8wwu2k/how_youtube_recommends_videos/,moinnadeem,1531001798,,0,1
355,2018-7-8,2018,7,8,7,8wwyx8,AI researchers allege that machine learning is alchemy | Science,https://www.reddit.com/r/MachineLearning/comments/8wwyx8/ai_researchers_allege_that_machine_learning_is/,weeeeeewoooooo,1531002961,,1,1
356,2018-7-8,2018,7,8,8,8wx77g,[R] Using GANs to generate dense ground-level views from satellite imagery,https://www.reddit.com/r/MachineLearning/comments/8wx77g/r_using_gans_to_generate_dense_groundlevel_views/,mhdempsey,1531004986,,1,21
357,2018-7-8,2018,7,8,8,8wx9ii,Anyone know of a good resource to learn model-based reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/8wx9ii/anyone_know_of_a_good_resource_to_learn/,Arisngr,1531005571,[removed],0,1
358,2018-7-8,2018,7,8,8,8wxgar,[R] Differentiable Learning-to-Normalize via Switchable Normalization,https://www.reddit.com/r/MachineLearning/comments/8wxgar/r_differentiable_learningtonormalize_via/,xternalz,1531007325,,4,19
359,2018-7-8,2018,7,8,9,8wxn85,North Korea pans gangster-like mindset of US as Pompeo signals progress in talks,https://www.reddit.com/r/MachineLearning/comments/8wxn85/north_korea_pans_gangsterlike_mindset_of_us_as/,mumisc,1531009163,,0,1
360,2018-7-8,2018,7,8,12,8wyw71,How big of a generalist are you?,https://www.reddit.com/r/MachineLearning/comments/8wyw71/how_big_of_a_generalist_are_you/,ACTBRUH,1531021988,[removed],0,1
361,2018-7-8,2018,7,8,12,8wywex,[D] How big of a generalist are you?,https://www.reddit.com/r/MachineLearning/comments/8wywex/d_how_big_of_a_generalist_are_you/,ACTBRUH,1531022049,"I've been studying this field for around 2~ years, and I think I've gotten to the point where I'm a pretty good generalist. I know the basics of the maths that goes on in the more readable papers (ie, not Bengio-esque papers), have done some projects/research, and have a pretty good grasp of what's currently possible/not possible in the state of the art in most subfields of ML. 

That said, I'm starting to lose that grasp. I've barely kept up to date with what's going on in NLP and RL in the past few months, and I feel almost *guilty* because of that. I've always thought that a good researcher (which is what I want to eventually be) should keep up with every subfield in his field, and I'm increasingly seeing that I'm failing to do that. 

To that end, I'd like to know if this thought process is unhealthy and I should just start specializing in what I like, or if being a generalist is essential to producing good, holistic research. To the academics/researchers/hobbyists of ML: how much do you read up on subfields outside of the ones that you enjoy to focus on? 
",23,103
362,2018-7-8,2018,7,8,13,8wyyba,[P] Tensorflow Implementation of Conditionally Shifted Neurons for Metalearning,https://www.reddit.com/r/MachineLearning/comments/8wyyba/p_tensorflow_implementation_of_conditionally/,greentfrapp,1531022600,"**Not original author so implementation details might be inaccurate!**

*Known implementation differences are listed in the last section of repo's README*

*Also, thanks to Chelsea Finn's MAML repo for her data generation scripts!*

Tensorflow implementation of [Munkhdalai, T., et al. ""Rapid adaptation with conditionally shifted neurons."" Proceedings of the 35th International Conference on Machine Learning. 2018.](https://arxiv.org/pdf/1712.09926) by Microsoft Research.

It seems the original authors haven't released their code at the moment and they also mentioned their implementation is in Chainer. So I just thought I'd share a Tensorflow implementation. 

In addition to the Omniglot experiment documented in the paper, I also implemented the algorithm on the sinusoid toy task described by Finn et al. ([2017](https://arxiv.org/pdf/1703.03400)).

The interesting thing is that this algorithm seems to draw parallels with / combine several different types of metalearning algorithms. More details in the Interesting Notes section of repo's README.

Implementation [here](https://github.com/greentfrapp/cond-shift-neurons/)!
",1,30
363,2018-7-8,2018,7,8,14,8wzcz3,What is Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8wzcz3/what_is_machine_learning/,munishmaxtech,1531027181,,0,1
364,2018-7-8,2018,7,8,15,8wzk4y,[D] Is there an open source radio content analysis software?,https://www.reddit.com/r/MachineLearning/comments/8wzk4y/d_is_there_an_open_source_radio_content_analysis/,pimonster00,1531029677,"If there is, please let me know! It's urgent. ",1,1
365,2018-7-8,2018,7,8,17,8x039c,AI Course Beginner,https://www.reddit.com/r/MachineLearning/comments/8x039c/ai_course_beginner/,jeanneomarie,1531037894,[removed],0,1
366,2018-7-8,2018,7,8,17,8x07ok,[D] Does classifier always needed to be retrained every time a new class is added?,https://www.reddit.com/r/MachineLearning/comments/8x07ok/d_does_classifier_always_needed_to_be_retrained/,MoistHoneydew,1531039783,"If I use some autoencoder-decoder model to encode input information into some latent vector space, and then connect the lower dimension vector space to classifier model. Does the model always needed to be retrained every time a new class is added to the output? Or not only the classifier needed to be retrained but also autoencoder-decoder too?

For example, If I were to use pre-trained model of some widely accepted model, and if the model had to be updated periodically, and each time, a new class is added. How much does the model needed to be retrained? And if it always needed, does there anyway to minimised the training? And if not what scheme or data structure could be used?

If there are existing topics or research papers. Please advised

Thank you",6,9
367,2018-7-8,2018,7,8,19,8x0idx,[N] A Single Shot Text Detector with Scale-adaptive Anchors,https://www.reddit.com/r/MachineLearning/comments/8x0idx/n_a_single_shot_text_detector_with_scaleadaptive/,RedEyed__,1531044358,[removed],0,1
368,2018-7-8,2018,7,8,19,8x0j27,AI Weekly 8 July 2018,https://www.reddit.com/r/MachineLearning/comments/8x0j27/ai_weekly_8_july_2018/,TomekB,1531044623,,0,1
369,2018-7-8,2018,7,8,19,8x0npo,,https://www.reddit.com/r/MachineLearning/comments/8x0npo//,Woodworking94,1531046608,,0,1
370,2018-7-8,2018,7,8,20,8x0rcj,Ideas for Training Neural Networks on Ticket Routing?,https://www.reddit.com/r/MachineLearning/comments/8x0rcj/ideas_for_training_neural_networks_on_ticket/,chrismatisch,1531048104,[removed],0,1
371,2018-7-8,2018,7,8,20,8x0rql,What are the benefits of pre-trained embeddings for seq2seq translations?,https://www.reddit.com/r/MachineLearning/comments/8x0rql/what_are_the_benefits_of_pretrained_embeddings/,UncleJemimaTSR,1531048250,[removed],0,1
372,2018-7-8,2018,7,8,20,8x0sc6,Spoken Language Identification in Microsoft Azure,https://www.reddit.com/r/MachineLearning/comments/8x0sc6/spoken_language_identification_in_microsoft_azure/,myveo,1531048482,,0,1
373,2018-7-8,2018,7,8,20,8x0sz7,Does anyone know a good place to get labeled (or unlabeled) data for testing different types of models.,https://www.reddit.com/r/MachineLearning/comments/8x0sz7/does_anyone_know_a_good_place_to_get_labeled_or/,ImMilesAhead,1531048742,[removed],0,1
374,2018-7-8,2018,7,8,22,8x1kwd,"SciDex is giving up to 100,000 free tokens to data scientists",https://www.reddit.com/r/MachineLearning/comments/8x1kwd/scidex_is_giving_up_to_100000_free_tokens_to_data/,AloneFlaver,1531058168,,0,1
375,2018-7-8,2018,7,8,23,8x1ncg,"SciDex is giving up to 100,000 free tokens to data scientists",https://www.reddit.com/r/MachineLearning/comments/8x1ncg/scidex_is_giving_up_to_100000_free_tokens_to_data/,AloneFlaver,1531058783,,0,1
376,2018-7-8,2018,7,8,23,8x1pz3,"SciDex is giving away up to 100,000 free tokens to data scientists",https://www.reddit.com/r/MachineLearning/comments/8x1pz3/scidex_is_giving_away_up_to_100000_free_tokens_to/,AloneFlaver,1531059445,,0,2
377,2018-7-8,2018,7,8,23,8x1us5,An Information-Theoretic View for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8x1us5/an_informationtheoretic_view_for_deep_learning/,Carl__Johnson__,1531060762,"[https://arxiv.org/abs/1804.09060](https://arxiv.org/abs/1804.09060)

Convolutional and pooling layers are contraction functions and cause information loss. As NNs increase such layers, the mutual information between inputs and outputs decrease exponentially, and the derived generalization gap also decreases exponentially.",1,1
378,2018-7-8,2018,7,8,23,8x1vyx,"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples - Best Paper Award @ ICML, 2018",https://www.reddit.com/r/MachineLearning/comments/8x1vyx/obfuscated_gradients_give_a_false_sense_of/,pvskand,1531061073,,3,104
379,2018-7-8,2018,7,8,23,8x1yw6,Can anyone provide resources on distributed database and cluster algorithm.,https://www.reddit.com/r/MachineLearning/comments/8x1yw6/can_anyone_provide_resources_on_distributed/,imarjunv,1531061825,[removed],0,1
380,2018-7-9,2018,7,9,1,8x2pcf,"Every Machine Learning course on the internet, ranked by your reviews",https://www.reddit.com/r/MachineLearning/comments/8x2pcf/every_machine_learning_course_on_the_internet/,CodePlea,1531068062,,0,1
381,2018-7-9,2018,7,9,1,8x2rkn,[R] Few Shot Learning using Human Robot Interaction.,https://www.reddit.com/r/MachineLearning/comments/8x2rkn/r_few_shot_learning_using_human_robot_interaction/,mennasiam,1531068540,,4,13
382,2018-7-9,2018,7,9,1,8x2rwn,Associative Compression Network Implementation,https://www.reddit.com/r/MachineLearning/comments/8x2rwn/associative_compression_network_implementation/,jalexvig,1531068614,"[This paper](https://arxiv.org/pdf/1804.02476.pdf) from Graves et al is a cool extension to Variational Autoencoders. I found no existing implementation so I coded this up.

* [Code](https://github.com/jalexvig/associative_compression_networks)
* [Write-up](http://jalexvig.github.io/blog/associative-compression-networks/) (""daydreaming"" and comparison with VAE at end)

Notes:
1. I am not one of the original paper authors.
2. The architectures for encoder/decoder/prior networks are much simpler than those in the original paper.",0,1
383,2018-7-9,2018,7,9,3,8x3jnd,[P] Associative Compression Network Implementation,https://www.reddit.com/r/MachineLearning/comments/8x3jnd/p_associative_compression_network_implementation/,jalexvig,1531074561,"[This paper](https://arxiv.org/pdf/1804.02476.pdf) from Graves et al is a cool extension of Variational Autoencoders. I found no existing implementation so I wrote one in pytorch.

* [Code](https://github.com/jalexvig/associative_compression_networks)
* [Write-up](http://jalexvig.github.io/blog/associative-compression-networks/) (""daydreaming"" and comparison with VAE at end)

Notes:

1. I am not one of the original paper authors.
2. The architectures for encoder/decoder/prior networks are much simpler than those in the original paper.",0,13
384,2018-7-9,2018,7,9,4,8x405k,A machine learning to play pac-man on twitch,https://www.reddit.com/r/MachineLearning/comments/8x405k/a_machine_learning_to_play_pacman_on_twitch/,thomascook04040,1531078116,,0,1
385,2018-7-9,2018,7,9,5,8x48oj,[D] Machine Learning - WAYR (What Are You Reading) - Week 46,https://www.reddit.com/r/MachineLearning/comments/8x48oj/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1531080005,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)||

Most upvoted papers two weeks ago:

/u/WillingAstronomer: [Long-Term on-board prediction of people in traffic scenes under uncertainty](https://arxiv.org/abs/1711.09026)

Besides that, there are no rules, have fun.",10,40
386,2018-7-9,2018,7,9,5,8x4de8,How to go about building a dictionary of food items for an NLP project?,https://www.reddit.com/r/MachineLearning/comments/8x4de8/how_to_go_about_building_a_dictionary_of_food/,ThiccShadyy,1531080981,,0,1
387,2018-7-9,2018,7,9,5,8x4dlx,How to make the most out of a ml conference? (icml),https://www.reddit.com/r/MachineLearning/comments/8x4dlx/how_to_make_the_most_out_of_a_ml_conference_icml/,dusanix,1531081023,[removed],0,1
388,2018-7-9,2018,7,9,5,8x4gki,[D] How to make the most out of a ML conference? ( Icml ),https://www.reddit.com/r/MachineLearning/comments/8x4gki/d_how_to_make_the_most_out_of_a_ml_conference_icml/,dusanix,1531081654,Any hints or tips from your experience for a first time attendee are welcome. ,8,12
389,2018-7-9,2018,7,9,6,8x4zny,[D]What book do you recommend?,https://www.reddit.com/r/MachineLearning/comments/8x4zny/dwhat_book_do_you_recommend/,nullz4tehlulz,1531085802,"Hey all, hope you're having a great day.

Lately I've been getting into Machine Learning more and I feel like I am missing a lot of knowledge on a lot of topics.

A bit of background: I have followed courses such as Signal Processing, Image Processing and Multimedia Analysis (Recommender Systems, Information Retrieval, Classification) and ""Deep learning"". So, I am comfortable with the basis of Machine Learning.

However, when I really want to apply Machine Learning it seems like I am missing so much! How do I efficiently store data (Perhaps going over different approaches such as Kd-Trees, LSH or perhaps other structures)? How does machine learning actually look like in a production environment? How do I properly pre-process my data? In general, a lot of (up-to-date) ""general"" knowledge about Machine Learning is what I'm after.

So, dear Machine Learning community, I ask you, what are some great books I could read that would help me with these gaps of knowledge?",7,3
390,2018-7-9,2018,7,9,8,8x5v35,Twitter sentiment analysis in the 5 minute aftermath of David Davis' (Brexit secretary) resignation,https://www.reddit.com/r/MachineLearning/comments/8x5v35/twitter_sentiment_analysis_in_the_5_minute/,errminator,1531092911,,0,1
391,2018-7-9,2018,7,9,8,8x5vb5,"[D] Inside Chinas Dystopian Dreams: AI, Shame and Lots of Cameras",https://www.reddit.com/r/MachineLearning/comments/8x5vb5/d_inside_chinas_dystopian_dreams_ai_shame_and/,wei_jok,1531092964,,129,240
392,2018-7-9,2018,7,9,8,8x5vtk,"[P] PythonRobotics: Implementation of various algorithms (SLAM, mapping, path planning and tracking) for robot navigation",https://www.reddit.com/r/MachineLearning/comments/8x5vtk/p_pythonrobotics_implementation_of_various/,inarrears,1531093082,,3,59
393,2018-7-9,2018,7,9,8,8x5y8x,[P] The Federalist Papers: Author Identification Through K-Means Clustering,https://www.reddit.com/r/MachineLearning/comments/8x5y8x/p_the_federalist_papers_author_identification/,JonLuca,1531093647,,1,9
394,2018-7-9,2018,7,9,8,8x5yc9,Tried to make a list of questions asked in Machine Learning interviews,https://www.reddit.com/r/MachineLearning/comments/8x5yc9/tried_to_make_a_list_of_questions_asked_in/,Sroy20,1531093667,,0,1
395,2018-7-9,2018,7,9,9,8x6b8b,Future of AI-Processing using Blockchain technology -crosspost from /r/blockchain,https://www.reddit.com/r/MachineLearning/comments/8x6b8b/future_of_aiprocessing_using_blockchain/,swimswithdolphins,1531096613,"https://coincentral.com/blockchain-ai-projects-2018/

Companies are using decentralized processing power to train AI algorithms to allow smaller AI companies to compete with Google &amp; Amazon whom have access to large amounts of centralized computing power.

How big of a problem is processing power when it comes to training AIs? Is cloud computing a cost effective solution?",0,1
396,2018-7-9,2018,7,9,10,8x6ky1,Azure machine learning studio pull directly from SharePoint list,https://www.reddit.com/r/MachineLearning/comments/8x6ky1/azure_machine_learning_studio_pull_directly_from/,crash893b,1531098789,[removed],0,1
397,2018-7-9,2018,7,9,10,8x6nl3,LSTM Auto-Encoder- Where am I going wrong?,https://www.reddit.com/r/MachineLearning/comments/8x6nl3/lstm_autoencoder_where_am_i_going_wrong/,pandadata,1531099417,[removed],0,1
398,2018-7-9,2018,7,9,11,8x70xh,[Project] jGeneticNeuralNet: A Java library that implements neural networks with a genetic training algorithm.,https://www.reddit.com/r/MachineLearning/comments/8x70xh/project_jgeneticneuralnet_a_java_library_that/,blank89,1531102387,,0,0
399,2018-7-9,2018,7,9,11,8x747x,Building Text Summariser With Python,https://www.reddit.com/r/MachineLearning/comments/8x747x/building_text_summariser_with_python/,aryancodify,1531103103,[removed],0,1
400,2018-7-9,2018,7,9,11,8x74pt,Using T-SNE and word2vec embeddings to create clusters in wordclouds,https://www.reddit.com/r/MachineLearning/comments/8x74pt/using_tsne_and_word2vec_embeddings_to_create/,seman_ticks,1531103208,[removed],0,1
401,2018-7-9,2018,7,9,12,8x7vcy,iQIYI release the largest video celebrity identification dataset,https://www.reddit.com/r/MachineLearning/comments/8x7vcy/iqiyi_release_the_largest_video_celebrity/,puppet1988,1531108744,[removed],0,1
402,2018-7-9,2018,7,9,13,8x8cgx,[D] How should we evaluate progress in AI?,https://www.reddit.com/r/MachineLearning/comments/8x8cgx/d_how_should_we_evaluate_progress_in_ai/,wei_jok,1531112241,,22,50
403,2018-7-9,2018,7,9,14,8x8du6,[R]An Information-Theoretic View for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8x8du6/ran_informationtheoretic_view_for_deep_learning/,Carl__Johnson__,1531112540,,14,20
404,2018-7-9,2018,7,9,14,8x8k4y,Is buying a 1080ti still worth it for serious use?,https://www.reddit.com/r/MachineLearning/comments/8x8k4y/is_buying_a_1080ti_still_worth_it_for_serious_use/,dilledalle,1531114019,[removed],0,1
405,2018-7-9,2018,7,9,15,8x8x4m,Machine Learning Sifts &amp; Searches Complex Scientific Data,https://www.reddit.com/r/MachineLearning/comments/8x8x4m/machine_learning_sifts_searches_complex/,cleanroomconnect,1531117363,,0,1
406,2018-7-9,2018,7,9,15,8x921h,[P] Simple Tensorflow implementation of RelativisticGAN,https://www.reddit.com/r/MachineLearning/comments/8x921h/p_simple_tensorflow_implementation_of/,taki0112,1531118692,,3,23
407,2018-7-9,2018,7,9,16,8x9djk,How to start reading ML research papers?,https://www.reddit.com/r/MachineLearning/comments/8x9djk/how_to_start_reading_ml_research_papers/,prabhupant09,1531121643,[removed],0,1
408,2018-7-9,2018,7,9,16,8x9g4x,[P] Using T-SNE and word2vec embeddings to create clusters in wordclouds,https://www.reddit.com/r/MachineLearning/comments/8x9g4x/p_using_tsne_and_word2vec_embeddings_to_create/,seman_ticks,1531122395,,4,13
409,2018-7-9,2018,7,9,17,8x9mvq,[R] Ideas for Training Neural Networks on Ticket Routing?,https://www.reddit.com/r/MachineLearning/comments/8x9mvq/r_ideas_for_training_neural_networks_on_ticket/,chrismatisch,1531124401,"Suppose you have structured tickets (author, description, title etc.) and you have historical data of how the reassignment sequences between users. E.g. Ticket is first assigned to A, who forwards it to B and finally to C, who resolves it. I am aware of approaches using simple probabilistic models to make predictions (e.g. Shao et al. 2008), but does anybody know of a paper that has a NN learn these sequences and maybe even leverage the document's text features?

If not: Would a simple RNN be able to capture the fact that B has a tendency to forward more tickets of a specific kind to C than to A?

PS.: This is my first post in this subreddit and on reddit in general, I hope it is appropriate.",4,3
410,2018-7-9,2018,7,9,17,8x9nwg,[P] Official repository for Udacity's Deep Reinforcement Learning Nanodegree program,https://www.reddit.com/r/MachineLearning/comments/8x9nwg/p_official_repository_for_udacitys_deep/,chisai_mikan,1531124732,,0,16
411,2018-7-9,2018,7,9,17,8x9occ,"Not sure if it goes here, but it might be useful to some.",https://www.reddit.com/r/MachineLearning/comments/8x9occ/not_sure_if_it_goes_here_but_it_might_be_useful/,clickbait_hmmm,1531124861,,0,1
412,2018-7-9,2018,7,9,17,8x9u5g,[P] Labelling tool for long and repetitive videos,https://www.reddit.com/r/MachineLearning/comments/8x9u5g/p_labelling_tool_for_long_and_repetitive_videos/,ale152,1531126717,,4,5
413,2018-7-9,2018,7,9,18,8x9zxz,Cloud Computing Project Ideas for students,https://www.reddit.com/r/MachineLearning/comments/8x9zxz/cloud_computing_project_ideas_for_students/,Mmanisha21,1531128501,[removed],0,1
414,2018-7-9,2018,7,9,18,8xa0au,"n dit cn trng Navilight NP-2X15W-AL S dng li in  by cn trng, d dng v sinh v tho lp mng ng xc cn trng",https://www.reddit.com/r/MachineLearning/comments/8xa0au/n_dit_cn_trng_navilight_np2x15wal_s_dng/,HangNguyen1111,1531128627,,0,1
415,2018-7-9,2018,7,9,18,8xa0dp,[P] Using Deep Learning to automatically rank millions of hotel images,https://www.reddit.com/r/MachineLearning/comments/8xa0dp/p_using_deep_learning_to_automatically_rank/,chrislennan,1531128646,We fine-tuned CNNs to assess the quality of images based on Google's [NIMA paper](https://arxiv.org/abs/1709.05424). We used [Lucid](https://github.com/tensorflow/lucid) to visualise the convolutional weights and output nodes. The code and trained models are published on [GitHub](https://github.com/idealo/image-quality-assessment).,0,1
416,2018-7-9,2018,7,9,18,8xa0mq,Need suggestions for ethical/philosophical questions in ML,https://www.reddit.com/r/MachineLearning/comments/8xa0mq/need_suggestions_for_ethicalphilosophical/,Driiper,1531128717,[removed],0,1
417,2018-7-9,2018,7,9,18,8xa2xv,[P] Using Deep Learning to automatically rank millions of hotel images,https://www.reddit.com/r/MachineLearning/comments/8xa2xv/p_using_deep_learning_to_automatically_rank/,chrislennan,1531129395,,1,1
418,2018-7-9,2018,7,9,18,8xa309,My hn ming ti PFS-200 (V thp) Cng sut: 300W Ngun in: 220/110V  di mp hn: 200mm Thi gian hn: 0.2 - 0.5s,https://www.reddit.com/r/MachineLearning/comments/8xa309/my_hn_ming_ti_pfs200_v_thp_cng_sut_300w/,HangNguyen1111,1531129410,,0,1
419,2018-7-9,2018,7,9,18,8xa543,My nghin vt ngh lin hon Inox NG-250 xay nghin nng sut cao 200-400kg/gi,https://www.reddit.com/r/MachineLearning/comments/8xa543/my_nghin_vt_ngh_lin_hon_inox_ng250_xay/,HangNguyen1111,1531130061,,0,1
420,2018-7-9,2018,7,9,18,8xa5k2,Machine Learning Glossary - Alexa Skill,https://www.reddit.com/r/MachineLearning/comments/8xa5k2/machine_learning_glossary_alexa_skill/,poorao,1531130198,[removed],0,1
421,2018-7-9,2018,7,9,19,8xabks,[R] GAIN: Missing Data Imputation using Generative Adversarial Nets,https://www.reddit.com/r/MachineLearning/comments/8xabks/r_gain_missing_data_imputation_using_generative/,CaptainD5,1531131878,"[http://arxiv.org/abs/1806.02920](http://arxiv.org/abs/1806.02920)

Hi!

Student here! Maybe someone could help me with this: I'm dealing with missing values in a dataset and I read about this paper. Anyone knows if there's an implementation of this available to test it? Thanks in advance!",4,7
422,2018-7-9,2018,7,9,19,8xacsj,Model Usage  Transfer learning using tensorflows object detection model on Mac,https://www.reddit.com/r/MachineLearning/comments/8xacsj/model_usage_transfer_learning_using_tensorflows/,coinmonks,1531132236,,0,1
423,2018-7-9,2018,7,9,19,8xae70,Exploring how resnets with one hidden neuron are universal function approximators,https://www.reddit.com/r/MachineLearning/comments/8xae70/exploring_how_resnets_with_one_hidden_neuron_are/,nivter,1531132644,,0,1
424,2018-7-9,2018,7,9,19,8xai97,How I built a Self Flying Drone to track People in under 50 lines of code,https://www.reddit.com/r/MachineLearning/comments/8xai97/how_i_built_a_self_flying_drone_to_track_people/,nanonets,1531133833,,0,1
425,2018-7-9,2018,7,9,19,8xaimf,HOW TO EASILY DO OBJECT RECOGNITION ON DRONE IMAGERY USING DEEP LEARNING,https://www.reddit.com/r/MachineLearning/comments/8xaimf/how_to_easily_do_object_recognition_on_drone/,nanonets,1531133930,,0,1
426,2018-7-9,2018,7,9,20,8xap5l,Learning Image Recognition from examples by practice,https://www.reddit.com/r/MachineLearning/comments/8xap5l/learning_image_recognition_from_examples_by/,phylosopher99,1531135606,[removed],0,1
427,2018-7-9,2018,7,9,20,8xatcz,ML and reposts,https://www.reddit.com/r/MachineLearning/comments/8xatcz/ml_and_reposts/,its-trivial,1531136695,[removed],0,1
428,2018-7-9,2018,7,9,21,8xaxoq,Learning two networks with the same ground-truth,https://www.reddit.com/r/MachineLearning/comments/8xaxoq/learning_two_networks_with_the_same_groundtruth/,itmanhieu,1531137752,[removed],0,1
429,2018-7-9,2018,7,9,21,8xb9kf,,https://www.reddit.com/r/MachineLearning/comments/8xb9kf//,Woodworking94,1531140454,,0,1
430,2018-7-9,2018,7,9,22,8xbd84,[D] What are the best newsletters about machine learning?,https://www.reddit.com/r/MachineLearning/comments/8xbd84/d_what_are_the_best_newsletters_about_machine/,banksyb00mb00m,1531141275,"The ones I am aware of are

[Import AI](https://jack-clark.net/)
[This Week in Machine Learning &amp; AI](https://twimlai.com/)
[NLP News](http://newsletter.ruder.io/) - covers general ML besides NLP.
[Exponential View](http://www.exponentialview.co/) - broader, mostly non-technical.
[Alignment Newsletter](http://rohinshah.com/alignment-newsletter/) - covers AI alignment research trends.

I am more interested in well-curated extensive newsletters with links to recent research developments and learning resources. Other formats like git repo, or regularly updated awesome lists are also welcome.",24,173
431,2018-7-9,2018,7,9,22,8xbi8r,[P] Netflix Prize revisited - I built a recommendation system in Excel,https://www.reddit.com/r/MachineLearning/comments/8xbi8r/p_netflix_prize_revisited_i_built_a/,OCData_nerd,1531142296,,0,2
432,2018-7-9,2018,7,9,22,8xblie,Quantum Machine Learning Plus conference,https://www.reddit.com/r/MachineLearning/comments/8xblie/quantum_machine_learning_plus_conference/,aamelnikov,1531142993,,0,1
433,2018-7-9,2018,7,9,22,8xbn33,[P] A dive into the deep end of deep neural networks for recommender engines,https://www.reddit.com/r/MachineLearning/comments/8xbn33/p_a_dive_into_the_deep_end_of_deep_neural/,cptAwesome_070,1531143319,,0,1
434,2018-7-9,2018,7,9,22,8xbpn8,[R] A Tour of Reinforcement Learning - Ben Recht,https://www.reddit.com/r/MachineLearning/comments/8xbpn8/r_a_tour_of_reinforcement_learning_ben_recht/,tensorflower,1531143848,,3,49
435,2018-7-9,2018,7,9,23,8xbx34,Question: Reverse Engineering Gradients to retrieve original input,https://www.reddit.com/r/MachineLearning/comments/8xbx34/question_reverse_engineering_gradients_to/,iantimmis,1531145260,[removed],0,1
436,2018-7-9,2018,7,9,23,8xc3lq,[D] How to use python for identity clustering of large image datasets,https://www.reddit.com/r/MachineLearning/comments/8xc3lq/d_how_to_use_python_for_identity_clustering_of/,Loggerny,1531146450,,0,3
437,2018-7-9,2018,7,9,23,8xc77g,Why reinforcement learning is flawed,https://www.reddit.com/r/MachineLearning/comments/8xc77g/why_reinforcement_learning_is_flawed/,tsaprailis,1531147101,,0,1
438,2018-7-10,2018,7,10,0,8xcezf,[D] Meta-analysis of neural networks,https://www.reddit.com/r/MachineLearning/comments/8xcezf/d_metaanalysis_of_neural_networks/,gumdropforest,1531148460,Is there any research being done in the area of neural network meta-analysis? (Using neural networks to predict the activations/ best architectures/ parameters... etc. of other NN's) Any papers or people I should look into that are conducting this type of research? Thanks!,4,3
439,2018-7-10,2018,7,10,0,8xctpx,Does anybody know the param numbers used on leading MNIST models?,https://www.reddit.com/r/MachineLearning/comments/8xctpx/does_anybody_know_the_param_numbers_used_on/,ProofTonight,1531150908,[removed],0,1
440,2018-7-10,2018,7,10,0,8xcv6d,[R] DeepMind papers at ICML 2018,https://www.reddit.com/r/MachineLearning/comments/8xcv6d/r_deepmind_papers_at_icml_2018/,valdanylchuk,1531151154,,1,19
441,2018-7-10,2018,7,10,0,8xcyde,[D] What are Current and Previous SOTA in Document Classification?,https://www.reddit.com/r/MachineLearning/comments/8xcyde/d_what_are_current_and_previous_sota_in_document/,skywang329,1531151700,"Hi, as the title says. Looking for current and previous state of the art in the task of document-level classification. Paper links welcome!",8,14
442,2018-7-10,2018,7,10,0,8xcypi,[R] Facebook Research at ICML 2018,https://www.reddit.com/r/MachineLearning/comments/8xcypi/r_facebook_research_at_icml_2018/,valdanylchuk,1531151759,,0,7
443,2018-7-10,2018,7,10,1,8xdjyt,[R] DiffAI: an open-source system for training neural nets to be provably safe from adversarial attacks,https://www.reddit.com/r/MachineLearning/comments/8xdjyt/r_diffai_an_opensource_system_for_training_neural/,mmirman,1531155194,,7,43
444,2018-7-10,2018,7,10,2,8xdqdt,[R] Deepmind papers at ICML 2018,https://www.reddit.com/r/MachineLearning/comments/8xdqdt/r_deepmind_papers_at_icml_2018/,vector_machines,1531156209,,1,4
445,2018-7-10,2018,7,10,2,8xdt3o,Glow: Better Reversible Generative Models,https://www.reddit.com/r/MachineLearning/comments/8xdt3o/glow_better_reversible_generative_models/,adammathias,1531156642,,0,1
446,2018-7-10,2018,7,10,2,8xdugt,"[R] Big leap for likelihood-based methods, 'Glow: Better Reversible Generative Models'",https://www.reddit.com/r/MachineLearning/comments/8xdugt/r_big_leap_for_likelihoodbased_methods_glow/,downtownslim,1531156859,,0,3
447,2018-7-10,2018,7,10,2,8xdxfn,need help with dockerfile and pose estimator,https://www.reddit.com/r/MachineLearning/comments/8xdxfn/need_help_with_dockerfile_and_pose_estimator/,ueq___,1531157336,[removed],0,1
448,2018-7-10,2018,7,10,2,8xe10o,Feature-wise transformations | distill.pub,https://www.reddit.com/r/MachineLearning/comments/8xe10o/featurewise_transformations_distillpub/,zinfour,1531157917,,0,2
449,2018-7-10,2018,7,10,2,8xe21s,[N] NLP's ImageNet moment has arrived,https://www.reddit.com/r/MachineLearning/comments/8xe21s/n_nlps_imagenet_moment_has_arrived/,P4TR10T_TR41T0R,1531158082,,6,35
450,2018-7-10,2018,7,10,2,8xe42d,Deep Learning and Neural Netwokrs(TensorFlow),https://www.reddit.com/r/MachineLearning/comments/8xe42d/deep_learning_and_neural_netwokrstensorflow/,ATGhoul1212,1531158395,[removed],0,1
451,2018-7-10,2018,7,10,2,8xe5lx,[D] Glow: Better Reversible Generative Models,https://www.reddit.com/r/MachineLearning/comments/8xe5lx/d_glow_better_reversible_generative_models/,Loggerny,1531158645,,40,199
452,2018-7-10,2018,7,10,2,8xe6xa,A Simple Anomaly Detection Algorithm,https://www.reddit.com/r/MachineLearning/comments/8xe6xa/a_simple_anomaly_detection_algorithm/,mathmare,1531158859,,0,1
453,2018-7-10,2018,7,10,2,8xe8z7,What are some classical ML papers one should read?,https://www.reddit.com/r/MachineLearning/comments/8xe8z7/what_are_some_classical_ml_papers_one_should_read/,Hot_Ices,1531159183,[removed],0,1
454,2018-7-10,2018,7,10,3,8xe931,Why isn't relative error used in the cost function of linear regression instead of squared error?,https://www.reddit.com/r/MachineLearning/comments/8xe931/why_isnt_relative_error_used_in_the_cost_function/,TheSexyDuckling,1531159204,[removed],0,1
455,2018-7-10,2018,7,10,3,8xeczb,[P] jGeneticNeuralNet: A Java library that trains neural networks with a genetic algorithm.,https://www.reddit.com/r/MachineLearning/comments/8xeczb/p_jgeneticneuralnet_a_java_library_that_trains/,blank89,1531159806,,2,1
456,2018-7-10,2018,7,10,3,8xefw7,"[P] I made a Python module for visualize and debug Computer Vision code efficiently.Support NumPy,PyTorch,MxNet",https://www.reddit.com/r/MachineLearning/comments/8xefw7/p_i_made_a_python_module_for_visualize_and_debug/,diyer22,1531160265,,2,6
457,2018-7-10,2018,7,10,3,8xeito,How to improve my model?,https://www.reddit.com/r/MachineLearning/comments/8xeito/how_to_improve_my_model/,code_bot,1531160742,[removed],0,1
458,2018-7-10,2018,7,10,3,8xeoo6,"[D] Identifying unique people (e.g., soccer players) in images/video via Face Clustering",https://www.reddit.com/r/MachineLearning/comments/8xeoo6/d_identifying_unique_people_eg_soccer_players_in/,Loggerny,1531161668,,0,5
459,2018-7-10,2018,7,10,3,8xevgf,From Hello World to Hello Quantum World,https://www.reddit.com/r/MachineLearning/comments/8xevgf/from_hello_world_to_hello_quantum_world/,goodrahstar,1531162722,,0,1
460,2018-7-10,2018,7,10,3,8xevtr,[D] Why TF and Keras are actively avoiding ONNX support?,https://www.reddit.com/r/MachineLearning/comments/8xevtr/d_why_tf_and_keras_are_actively_avoiding_onnx/,denfromufa,1531162777,"Why TF and Keras are actively avoiding ONNX support? For example, see these 2 issues with no official response from Google. Is there any technical limitation or this is just attempt to monopolize deep learning landscape?

https://github.com/keras-team/keras/issues/8638

https://github.com/tensorflow/tensorflow/issues/12888",15,25
461,2018-7-10,2018,7,10,4,8xewu7,[P] Identify a spoken language using AI,https://www.reddit.com/r/MachineLearning/comments/8xewu7/p_identify_a_spoken_language_using_ai/,myveo,1531162918,,5,8
462,2018-7-10,2018,7,10,4,8xex0e,[D] Feature-wise transformations,https://www.reddit.com/r/MachineLearning/comments/8xex0e/d_featurewise_transformations/,tensorflower,1531162943,,0,25
463,2018-7-10,2018,7,10,4,8xf2kp,Best Genetic Algorithm for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8xf2kp/best_genetic_algorithm_for_deep_learning/,Magnuscaligo,1531163771,[removed],0,1
464,2018-7-10,2018,7,10,4,8xf2zk,A dive into the deep end of deep neural networks for recommender engines.,https://www.reddit.com/r/MachineLearning/comments/8xf2zk/a_dive_into_the_deep_end_of_deep_neural_networks/,cptAwesome_070,1531163830,,0,1
465,2018-7-10,2018,7,10,4,8xf8cl,Why doesn't LSTM pick up on underlying growth trends?,https://www.reddit.com/r/MachineLearning/comments/8xf8cl/why_doesnt_lstm_pick_up_on_underlying_growth/,pandadata,1531164706,[removed],0,1
466,2018-7-10,2018,7,10,4,8xfgd4,How we used neural networks to understand Congress,https://www.reddit.com/r/MachineLearning/comments/8xfgd4/how_we_used_neural_networks_to_understand_congress/,azazello_spawn,1531165936,,0,1
467,2018-7-10,2018,7,10,5,8xfkhj,"[D] Do you have any recommendations for projects that can find custom chosen landmarks from images? I've found DeepLabCut, but am curious if there are others out there people have used.",https://www.reddit.com/r/MachineLearning/comments/8xfkhj/d_do_you_have_any_recommendations_for_projects/,theredknight,1531166578,,0,3
468,2018-7-10,2018,7,10,5,8xfss6,HPC Market Survey,https://www.reddit.com/r/MachineLearning/comments/8xfss6/hpc_market_survey/,escott0822,1531167849,"Were conducting a market survey for HPC data center managers and others who make decisions about data management systems. Two focus areas for the survey - 1) Cloud v OnPrem specific to HPC work to be done and, 2) impact of hardware architecture / specs on overall performance. 

There is a lot of information about choosing cloud for biz ops and ""regular"" computing needs - not so much for HPC demands and requirements - access, security, cost, etc.

If you manage your organization's system, please consider taking the survey - as well as encouraging colleagues to do the same.

Here's the link: https://www.surveymonkey.com/r/BigDataHPC

Your consideration is much appreciated! Message me with questions.

- E Scott
",0,1
469,2018-7-10,2018,7,10,5,8xfx2e,[R]How we used neural networks to understand Congress,https://www.reddit.com/r/MachineLearning/comments/8xfx2e/rhow_we_used_neural_networks_to_understand/,azazello_spawn,1531168513,,0,1
470,2018-7-10,2018,7,10,6,8xgc9l,Data Science Glossary on Kaggle!,https://www.reddit.com/r/MachineLearning/comments/8xgc9l/data_science_glossary_on_kaggle/,rohan36,1531170961,,0,1
471,2018-7-10,2018,7,10,6,8xgrrq,Need more AI Engineering and Less AI Research folks (on Twitter),https://www.reddit.com/r/MachineLearning/comments/8xgrrq/need_more_ai_engineering_and_less_ai_research/,interana,1531173556,[removed],0,1
472,2018-7-10,2018,7,10,7,8xh41z,How to use python3 instead of python2.7 on Mac for data science ?,https://www.reddit.com/r/MachineLearning/comments/8xh41z/how_to_use_python3_instead_of_python27_on_mac_for/,TDK1902,1531175627,[removed],0,1
473,2018-7-10,2018,7,10,7,8xh4s4,[R] Feature-wise transformations,https://www.reddit.com/r/MachineLearning/comments/8xh4s4/r_featurewise_transformations/,baylearn,1531175751,,0,1
474,2018-7-10,2018,7,10,9,8xi4kt,[R] Dropout does not prevent co-adaption and a better dropout alternative: Gradient Acceleration in Activation Functions,https://www.reddit.com/r/MachineLearning/comments/8xi4kt/r_dropout_does_not_prevent_coadaption_and_a/,_jamorton,1531181123,,2,8
475,2018-7-10,2018,7,10,9,8xikcl,"[D] Troubling Trends in Machine Learning Scholarship (ICML Debates Workshop paper, pdf)",https://www.reddit.com/r/MachineLearning/comments/8xikcl/d_troubling_trends_in_machine_learning/,wei_jok,1531183051,,12,132
476,2018-7-10,2018,7,10,9,8xiowi,List Of Free Online Courses On Artificial Intelligence/ Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8xiowi/list_of_free_online_courses_on_artificial/,asifrazzaq1988,1531183717,,0,1
477,2018-7-10,2018,7,10,10,8xix9d,Reading Kevin Murphy Probabilistic ML book end to end,https://www.reddit.com/r/MachineLearning/comments/8xix9d/reading_kevin_murphy_probabilistic_ml_book_end_to/,atulkum,1531184863,[removed],0,1
478,2018-7-10,2018,7,10,10,8xiyf1,[N] Beta Release Of Deep Learning Images For Google Compute Engine,https://www.reddit.com/r/MachineLearning/comments/8xiyf1/n_beta_release_of_deep_learning_images_for_google/,b0noi,1531185007,,0,17
479,2018-7-10,2018,7,10,10,8xj1sh,[R] An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution,https://www.reddit.com/r/MachineLearning/comments/8xj1sh/r_an_intriguing_failing_of_convolutional_neural/,xternalz,1531185465,,14,31
480,2018-7-10,2018,7,10,10,8xj377,TDLS: Learning to Represent Programs with Graphs (https://arxiv.org/abs/1711.00740),https://www.reddit.com/r/MachineLearning/comments/8xj377/tdls_learning_to_represent_programs_with_graphs/,machinetrainer,1531185659,,0,1
481,2018-7-10,2018,7,10,11,8xjx64,[R] How Many Random Seeds Should I Use? Statistic Power Analysis in DeepRL Experiments,https://www.reddit.com/r/MachineLearning/comments/8xjx64/r_how_many_random_seeds_should_i_use_statistic/,baylearn,1531189918,,0,5
482,2018-7-10,2018,7,10,13,8xlcl2, - GALAXY CHANNEL,https://www.reddit.com/r/MachineLearning/comments/8xlcl2/_galaxy_channel/,Woodworking94,1531195692,,0,1
483,2018-7-10,2018,7,10,13,8xln2w,[R] Using Topological Data Analysis to Understand the Behavior of Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8xln2w/r_using_topological_data_analysis_to_understand/,singhgurjeet,1531198007,,13,49
484,2018-7-10,2018,7,10,14,8xlsl1,[D] Resource to ramp up software engineering skills,https://www.reddit.com/r/MachineLearning/comments/8xlsl1/d_resource_to_ramp_up_software_engineering_skills/,piconzaz,1531199371,"Hi!
I'm an academic ML researcher. I'm used to implement my own (or others') algorithms (mostly using Python and libraries / frameworks like Tensorflow or scikit-learn). This is good for prototyping (and academia usually doesn't care for more than this).
However, I would like to improve my software development skills to produce more durable, maintainable, documented, modular but also efficient code. I want to build some solid good practices.
I'm considering taking some online course. However, I'm a bit lost to find out which.Though most of those concepts are not language dependent, I would certainly appreciate if the exercises were in Python. Do you have any recommendation?

Thank you!",42,63
485,2018-7-10,2018,7,10,14,8xlsla,The web is a giant graph database with its graph query language missing,https://www.reddit.com/r/MachineLearning/comments/8xlsla/the_web_is_a_giant_graph_database_with_its_graph/,garyjob,1531199373,[removed],0,1
486,2018-7-10,2018,7,10,15,8xm4en,Interesting application of DL: Affective EEG-Based Person Identification Using the Deep Learning Approach,https://www.reddit.com/r/MachineLearning/comments/8xm4en/interesting_application_of_dl_affective_eegbased/,simpleconjugate,1531202480,,1,6
487,2018-7-10,2018,7,10,17,8xn2at,Is that any way to write a patient SOAP note with machine learning library?,https://www.reddit.com/r/MachineLearning/comments/8xn2at/is_that_any_way_to_write_a_patient_soap_note_with/,Bala_venkatesh,1531212103,[removed],0,1
488,2018-7-10,2018,7,10,17,8xn30z,"What is the reason for a perfect seperation of signal and background, for SUSY dataset, with score of AUC = 1.0",https://www.reddit.com/r/MachineLearning/comments/8xn30z/what_is_the_reason_for_a_perfect_seperation_of/,rajesh_d24,1531212314,[removed],0,1
489,2018-7-10,2018,7,10,18,8xneno,How close is a World Model to classic metaheuristic ?,https://www.reddit.com/r/MachineLearning/comments/8xneno/how_close_is_a_world_model_to_classic/,Katurha,1531215272,[removed],0,1
490,2018-7-10,2018,7,10,18,8xneyf,[R] Pioneer Networks: Progressively Growing Generative Autoencoder,https://www.reddit.com/r/MachineLearning/comments/8xneyf/r_pioneer_networks_progressively_growing/,svantana,1531215354,,3,13
491,2018-7-10,2018,7,10,19,8xnm7i,[P] fast.ai Machine Learning Course Notes,https://www.reddit.com/r/MachineLearning/comments/8xnm7i/p_fastai_machine_learning_course_notes/,molode,1531217237,,0,1
492,2018-7-10,2018,7,10,19,8xnnky,[R] Reasons to Replace Dictionary Based Text Mining with Machine Learning Techniques,https://www.reddit.com/r/MachineLearning/comments/8xnnky/r_reasons_to_replace_dictionary_based_text_mining/,magneticono,1531217590,,0,1
493,2018-7-10,2018,7,10,20,8xo39s,"This AI-Powered, ML Platform Helps Businesses Crack Audience Intelligence:",https://www.reddit.com/r/MachineLearning/comments/8xo39s/this_aipowered_ml_platform_helps_businesses_crack/,shilpisraut,1531221548,[removed],0,1
494,2018-7-10,2018,7,10,20,8xoacv,Meta-learners for Estimating Heterogeneous Treatment Effects using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8xoacv/metalearners_for_estimating_heterogeneous/,serghiou,1531223238,,1,3
495,2018-7-10,2018,7,10,21,8xofmu,[D] Divisibility of data in statistics: Where is it needed?,https://www.reddit.com/r/MachineLearning/comments/8xofmu/d_divisibility_of_data_in_statistics_where_is_it/,DevFRus,1531224396,,0,1
496,2018-7-10,2018,7,10,21,8xog61,Want to learn how to create an image classification neural network in one of the largest Machine Learning frameworks in the World? Check this video out! :),https://www.reddit.com/r/MachineLearning/comments/8xog61/want_to_learn_how_to_create_an_image/,DiscoverAI,1531224507,,0,1
497,2018-7-10,2018,7,10,21,8xoh2j,[D] How to model spatial relationships between objects?,https://www.reddit.com/r/MachineLearning/comments/8xoh2j/d_how_to_model_spatial_relationships_between/,cbsudux,1531224695,"I have 2 objects, A and B. A is above B. How do I model this relationship?",8,3
498,2018-7-10,2018,7,10,21,8xohix,Machine Learning Engineer Nanodegree,https://www.reddit.com/r/MachineLearning/comments/8xohix/machine_learning_engineer_nanodegree/,SmoothBake,1531224792,,0,1
499,2018-7-10,2018,7,10,21,8xopek,Augmented Analytics Algorithms and Techniques: Learning for Citizen Data Scientists,https://www.reddit.com/r/MachineLearning/comments/8xopek/augmented_analytics_algorithms_and_techniques/,ElegantMicroWebIndia,1531226461,,0,1
500,2018-7-10,2018,7,10,21,8xoq9m,What can CNC Cutting Machines perform?,https://www.reddit.com/r/MachineLearning/comments/8xoq9m/what_can_cnc_cutting_machines_perform/,Messer-123,1531226638,,0,1
501,2018-7-10,2018,7,10,21,8xorpg,Decentralized Machine Learning using MPC and Secret Sharing,https://www.reddit.com/r/MachineLearning/comments/8xorpg/decentralized_machine_learning_using_mpc_and/,sidekick902,1531226927,,0,5
502,2018-7-10,2018,7,10,21,8xosdn,"We've open sourced a fast, scalable, multi-threaded Java Naive Bayes Classifier.",https://www.reddit.com/r/MachineLearning/comments/8xosdn/weve_open_sourced_a_fast_scalable_multithreaded/,namsor_com,1531227078,,0,1
503,2018-7-10,2018,7,10,22,8xov01,Bayes by Backprop explained,https://www.reddit.com/r/MachineLearning/comments/8xov01/bayes_by_backprop_explained/,felixl1990,1531227633,,0,2
504,2018-7-10,2018,7,10,22,8xp1c6,Is Artificial Intelligence a threat or an opportunity for jobs?,https://www.reddit.com/r/MachineLearning/comments/8xp1c6/is_artificial_intelligence_a_threat_or_an/,DebatingEurope,1531228857,,0,1
505,2018-7-10,2018,7,10,22,8xp57o,Is Artificial Intelligence a threat or an opportunity for jobs?,https://www.reddit.com/r/MachineLearning/comments/8xp57o/is_artificial_intelligence_a_threat_or_an/,DebatingEurope,1531229640,,0,1
506,2018-7-10,2018,7,10,22,8xp6qh,Image data labeling and machine learning,https://www.reddit.com/r/MachineLearning/comments/8xp6qh/image_data_labeling_and_machine_learning/,xin_suraj,1531229933,Doing internship in image data labeling is useful for experience in the field of data science ?,0,1
507,2018-7-10,2018,7,10,22,8xp9yp,Free July 24 ACM Learning webcast with Ian Goodfellow (inventor of GANs) on Adversarial Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8xp9yp/free_july_24_acm_learning_webcast_with_ian/,ACMLearning,1531230537,,0,1
508,2018-7-10,2018,7,10,23,8xpi7r,What exacatly Singular Value Decomposition can do?,https://www.reddit.com/r/MachineLearning/comments/8xpi7r/what_exacatly_singular_value_decomposition_can_do/,chilisauce82,1531232012,[removed],0,1
509,2018-7-10,2018,7,10,23,8xpkkt,Voice Assistants like Alexa can educate the future better!,https://www.reddit.com/r/MachineLearning/comments/8xpkkt/voice_assistants_like_alexa_can_educate_the/,AnaMcL,1531232441,[removed],0,1
510,2018-7-10,2018,7,10,23,8xpwhf,[D] Reinforcement learnings foundational flaw,https://www.reddit.com/r/MachineLearning/comments/8xpwhf/d_reinforcement_learnings_foundational_flaw/,baylearn,1531234599,,15,35
511,2018-7-11,2018,7,11,0,8xpygp,[AutoML] Hyperparameter Importance Across Datasets,https://www.reddit.com/r/MachineLearning/comments/8xpygp/automl_hyperparameter_importance_across_datasets/,AnonymousResearcher1,1531234952,,0,1
512,2018-7-11,2018,7,11,0,8xpzcr,[D] When predictive analytics in football fall short (an example),https://www.reddit.com/r/MachineLearning/comments/8xpzcr/d_when_predictive_analytics_in_football_fall/,AnnaKow,1531235102,,0,6
513,2018-7-11,2018,7,11,0,8xq3q6,[N] Online competition with few competitors and $20k prize money,https://www.reddit.com/r/MachineLearning/comments/8xq3q6/n_online_competition_with_few_competitors_and_20k/,huabamane,1531235838,,4,12
514,2018-7-11,2018,7,11,0,8xq5ve,Looking for the best ways to do feature engineering (feature selection or feature extraction),https://www.reddit.com/r/MachineLearning/comments/8xq5ve/looking_for_the_best_ways_to_do_feature/,rshoreview,1531236218,[removed],0,1
515,2018-7-11,2018,7,11,0,8xq7sc,"Hands on, what are you guys suggesting?",https://www.reddit.com/r/MachineLearning/comments/8xq7sc/hands_on_what_are_you_guys_suggesting/,SGlob,1531236548,[removed],0,1
516,2018-7-11,2018,7,11,0,8xq9qr,Convert Fortnite into PUBG using GANS,https://www.reddit.com/r/MachineLearning/comments/8xq9qr/convert_fortnite_into_pubg_using_gans/,Naughty_Nagaland,1531236873,,0,1
517,2018-7-11,2018,7,11,0,8xqa81,[R] Facebook papers at ICML2018,https://www.reddit.com/r/MachineLearning/comments/8xqa81/r_facebook_papers_at_icml2018/,adefazio,1531236958,,7,49
518,2018-7-11,2018,7,11,0,8xqcz3,[N] Research published in Nature describes an artificial neural network made out of DNA that can solve a classic machine learning problem: correctly identifying handwritten numbers. The work is a step towards programming AI into synthetic biomolecular circuits,https://www.reddit.com/r/MachineLearning/comments/8xqcz3/n_research_published_in_nature_describes_an/,ourannual,1531237418,,34,361
519,2018-7-11,2018,7,11,0,8xqdpn,[P] Converting Fortnite to PUBG using CycleGAN,https://www.reddit.com/r/MachineLearning/comments/8xqdpn/p_converting_fortnite_to_pubg_using_cyclegan/,Naughty_Nagaland,1531237546,,15,52
520,2018-7-11,2018,7,11,0,8xqh6q,"Are you interested in Machine Learning and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/MachineLearning/comments/8xqh6q/are_you_interested_in_machine_learning_and_want/,DiscoverAI,1531238137,,0,1
521,2018-7-11,2018,7,11,0,8xqils,When Is It Important for an Algorithm to Explain Itself?,https://www.reddit.com/r/MachineLearning/comments/8xqils/when_is_it_important_for_an_algorithm_to_explain/,nerd4987,1531238378,,0,1
522,2018-7-11,2018,7,11,1,8xqkv0,Best ways to learn and apply PGMs after Daphne Koller Coursera's course?,https://www.reddit.com/r/MachineLearning/comments/8xqkv0/best_ways_to_learn_and_apply_pgms_after_daphne/,bayesianwannabe1,1531238731,[removed],0,1
523,2018-7-11,2018,7,11,1,8xqo0v,"How to Use MLflow, TensorFlow, and Keras with PyCharm",https://www.reddit.com/r/MachineLearning/comments/8xqo0v/how_to_use_mlflow_tensorflow_and_keras_with/,dmatrixjsd,1531239240,,0,1
524,2018-7-11,2018,7,11,1,8xqrw7,[R] (Reinforcement) Learning To Drive a Car,https://www.reddit.com/r/MachineLearning/comments/8xqrw7/r_reinforcement_learning_to_drive_a_car/,NMcA,1531239881,,2,13
525,2018-7-11,2018,7,11,1,8xqs6w,Stochastic Neuron,https://www.reddit.com/r/MachineLearning/comments/8xqs6w/stochastic_neuron/,Humblefool_14,1531239928,[removed],0,1
526,2018-7-11,2018,7,11,1,8xqv1e,Machine Learning revolutionising eCommerce: Swiss Company boosts the eCommerce,https://www.reddit.com/r/MachineLearning/comments/8xqv1e/machine_learning_revolutionising_ecommerce_swiss/,mihelli,1531240400,[removed],0,1
527,2018-7-11,2018,7,11,2,8xrk8n,Labelling multiple vehicle parts or sections (Computer vision),https://www.reddit.com/r/MachineLearning/comments/8xrk8n/labelling_multiple_vehicle_parts_or_sections/,dexter1986,1531244720,"I am currently developing a machine learning based (computer vision) prototype that can classify different parts of a car in an image e.g. front bumper, rear bumper, roof, left door, bonnet etc.  

Please let me know if any readily available solution already exists for this. 

PS- there is a technical paper called Vision-based detection and labelling of multiple vehicle parts by Alberto Chavez-Aragon et all. However, the solution isnt open source as far as I know",0,1
528,2018-7-11,2018,7,11,2,8xrlr9,What are the licensing restrictions on using cycleGAN models in our software?,https://www.reddit.com/r/MachineLearning/comments/8xrlr9/what_are_the_licensing_restrictions_on_using/,podcast_frog3817,1531245007,[removed],0,1
529,2018-7-11,2018,7,11,3,8xs0bi,Is there a good way to do cluster labeling?,https://www.reddit.com/r/MachineLearning/comments/8xs0bi/is_there_a_good_way_to_do_cluster_labeling/,Pawnbrake,1531247756,"I have a ton of clusters (found using [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN)) that fall into a number of labels.  Points are 3d (x, y, z coordinates).  Some clusters are trees, some are buildings, etc.

I want do to [cluster labeling](https://en.wikipedia.org/wiki/Cluster_labeling).  I want to label some of the clusters and then have an automated way of labeling the rest.  Are there good off-the-shelf methods to do this?

I code in python if that's useful, but I'm willing to reproduce math or code in other languages or in papers.  ",0,1
530,2018-7-11,2018,7,11,3,8xs418,[R] Another great video from UberAI Lab: CoordConv,https://www.reddit.com/r/MachineLearning/comments/8xs418/r_another_great_video_from_uberai_lab_coordconv/,elanmart,1531248507,,0,4
531,2018-7-11,2018,7,11,4,8xs7pp,NSFW Content Dataset,https://www.reddit.com/r/MachineLearning/comments/8xs7pp/nsfw_content_dataset/,harrybhines,1531249225,[removed],0,1
532,2018-7-11,2018,7,11,4,8xsk0p,[R] Noise2Noise: Learning Image Restoration without Clean Data,https://www.reddit.com/r/MachineLearning/comments/8xsk0p/r_noise2noise_learning_image_restoration_without/,madnessman,1531251578,,12,8
533,2018-7-11,2018,7,11,4,8xsn2x,Pretrained Segmentation Networks,https://www.reddit.com/r/MachineLearning/comments/8xsn2x/pretrained_segmentation_networks/,Tyrotyrotyrotyro,1531252191,[removed],0,1
534,2018-7-11,2018,7,11,4,8xsp7v,Blockchain Powered IoT: Anomaly Detection,https://www.reddit.com/r/MachineLearning/comments/8xsp7v/blockchain_powered_iot_anomaly_detection/,svarada,1531252626,[removed],0,1
535,2018-7-11,2018,7,11,4,8xspgk,(Speech) Sequence and BN,https://www.reddit.com/r/MachineLearning/comments/8xspgk/speech_sequence_and_bn/,Fhrozen21,1531252672,[removed],0,1
536,2018-7-11,2018,7,11,5,8xss85,[D] Any advice for doing a PhD in a niche using deep learning / ML?,https://www.reddit.com/r/MachineLearning/comments/8xss85/d_any_advice_for_doing_a_phd_in_a_niche_using/,timbercrisis,1531253189,"Is this a recommended route for a PhD or would it be better to do a PhD on a more broad topic within that niche and try to find a ML side-project? What general advice for doing a ML focused PhD is there for non(strictly)-mathematicians/cs/stats folk is there?

For example, in agricultural data.

",14,16
537,2018-7-11,2018,7,11,5,8xsslq,[P] Optimized Differentiable Neural Computer in Chainer,https://www.reddit.com/r/MachineLearning/comments/8xsslq/p_optimized_differentiable_neural_computer_in/,ThisIsMySeudonym,1531253262,,2,7
538,2018-7-11,2018,7,11,5,8xstaq,What does P(B|A) = f(A;w) mean?,https://www.reddit.com/r/MachineLearning/comments/8xstaq/what_does_pba_faw_mean/,johnsmidth,1531253388,[removed],0,1
539,2018-7-11,2018,7,11,5,8xstox,Where is all the AI engineering? (on Twitter and Reddit),https://www.reddit.com/r/MachineLearning/comments/8xstox/where_is_all_the_ai_engineering_on_twitter_and/,interana,1531253462,[removed],0,1
540,2018-7-11,2018,7,11,5,8xsv9q,[D] (Speech) Sequential training and BN,https://www.reddit.com/r/MachineLearning/comments/8xsv9q/d_speech_sequential_training_and_bn/,Fhrozen21,1531253755,"Hey Everyone, I got a question:

I am trying to test speech recognition using a CNN + BLSTMP network ([https://github.com/espnet/espnet](https://github.com/espnet/espnet)). The result is comparable with that using only BLSMTP. However, when I tried to add BN to the CNN layers, the performance becomes worst. I already tried implementing a NN with similar characteristics but for another sequence application and BN improves the result even when the decode batchsize is 1. Has anyone tried BN in CNN for sequence training.? Is working that well? is that depend on the framework (TF, Chainer or Pytorch) or BN does not work well for Speech in sequence (will need ref) but it will be better to implement a normalization along the sequence?

Regards",0,3
541,2018-7-11,2018,7,11,5,8xsxev,Can someone explain to me in simple terms what is Relevance Vector Machine (RVM)?,https://www.reddit.com/r/MachineLearning/comments/8xsxev/can_someone_explain_to_me_in_simple_terms_what_is/,johnsmidth,1531254153,,0,1
542,2018-7-11,2018,7,11,5,8xt1lz,How to ensure that a XOR implementation using a Multilayer Perceptron always converges to a solution regardless of weights?,https://www.reddit.com/r/MachineLearning/comments/8xt1lz/how_to_ensure_that_a_xor_implementation_using_a/,Sau001,1531254970,[removed],0,1
543,2018-7-11,2018,7,11,5,8xt4n5,In case of logistic regression the average of propensities generated on the training data is equal to the event rate in the dataset. Does this hold true for ML classification methods?,https://www.reddit.com/r/MachineLearning/comments/8xt4n5/in_case_of_logistic_regression_the_average_of/,MindFlayer2506,1531255549,[removed],0,1
544,2018-7-11,2018,7,11,5,8xt52c,Which is the best place to ask Machine Learning related questions?,https://www.reddit.com/r/MachineLearning/comments/8xt52c/which_is_the_best_place_to_ask_machine_learning/,johnsmidth,1531255627,[removed],0,1
545,2018-7-11,2018,7,11,6,8xtaw9,Help finding pedestrian trajectories dataset,https://www.reddit.com/r/MachineLearning/comments/8xtaw9/help_finding_pedestrian_trajectories_dataset/,mercred,1531256787,[removed],0,1
546,2018-7-11,2018,7,11,6,8xtq7k,[N] Google Brain Amsterdam,https://www.reddit.com/r/MachineLearning/comments/8xtq7k/n_google_brain_amsterdam/,inarrears,1531259884,,1,14
547,2018-7-11,2018,7,11,8,8xu9d8,"[D] GANs and VAEs haven't been effectively leveraged for natural language yet because they work on continuous data, couldn't you get around this by using an embedding with concatenated word vectors or sentence vectors?",https://www.reddit.com/r/MachineLearning/comments/8xu9d8/d_gans_and_vaes_havent_been_effectively_leveraged/,Morninglow,1531263976,,18,11
548,2018-7-11,2018,7,11,8,8xud91,[D] Why does the content code in Multimodal Unsupervised Image-to-Image Translation not degenerate?,https://www.reddit.com/r/MachineLearning/comments/8xud91/d_why_does_the_content_code_in_multimodal/,question99,1531264818,"[Multimodal Unsupervised Image-to-Image Translation](https://arxiv.org/abs/1804.04732) describes an algorithm to translate an image from domain X1 to another domain X2 in an unsupervised manner. This is achieved via a partially shared latent space assumption: it is assumed that each image is generated from a content latent code c  C that is shared by both domains, and a style latent code s that is specific to the individual domain.

Having a look at the [loss function](https://imgur.com/a/Wz5nqC3) I have a difficult time understanding why the latent code c does not degenerate: I do not see anything in the loss that prevents the content encoder to always just output 0 (or another constant) vector for c, regardless of the domain. The networks could just make up for the lack of a useful content code by using the style code s to represent both content and style. Inuitively this seems ""easier"" than learning a shared space C between two domains.

I have one hypothesis why the content code ends up being useful: in the ""Implementation Details"" section of the paper, the content and style codes are described to be encoded/decoded by [different architectures](https://imgur.com/a/jGsaYR4). If the network architecture of the style code encoder/decoder is not very capable of dealing with global structure, that might force the overall network to make use of the content code. (This is similar to the way how global and local information is seperated in the [Variational Lossy Autoencoder](https://arxiv.org/abs/1611.02731) paper.)

Is my hypothesis above plausible or is there something else at work here?",7,2
549,2018-7-11,2018,7,11,8,8xum30,"[D] To Make Sense of the Present, Brains May Predict the Future",https://www.reddit.com/r/MachineLearning/comments/8xum30/d_to_make_sense_of_the_present_brains_may_predict/,chisai_mikan,1531266774,,3,9
550,2018-7-11,2018,7,11,9,8xuov6,[D] How to fix reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/8xuov6/d_how_to_fix_reinforcement_learning/,wei_jok,1531267402,,11,21
551,2018-7-11,2018,7,11,9,8xuqg9,[D] summary and links to 3 of the 9 ICML 2018 tutorials,https://www.reddit.com/r/MachineLearning/comments/8xuqg9/d_summary_and_links_to_3_of_the_9_icml_2018/,gau_mar,1531267775,,0,19
552,2018-7-11,2018,7,11,9,8xurkp,[N] TensorFlow 1.9.0 is out,https://www.reddit.com/r/MachineLearning/comments/8xurkp/n_tensorflow_190_is_out/,b0noi,1531268024,"* [Official change log](https://github.com/tensorflow/tensorflow/releases/tag/v1.9.0);
* [Google Compute Engine Deep Learning images now also include TF 1.9](https://blog.kovalevskyi.com/gce-deep-learning-images-revision-2-41718ef1548d);

## Major Features And Improvements

* Updated docs for tf.keras  
: New Keras-based [get started](http://tensorflow.org/versions/r1.9/get_started) and [programmers guide page](http://tensorflow.org/versions/r1.9/programmers_guide/keras).
* Update tf.keras  
 to the Keras 2.1.6 API.
* Added [tf.keras.layers.CuDNNGRU](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/keras/layers/CuDNNGRU) and [tf.keras.layers.CuDNNLSTM](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/keras/layers/CuDNNLSTM) layers. [Try it](https://colab.sandbox.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb?linkId=53292082).
* Adding support of core [feature columns](https://www.tensorflow.org/get_started/feature_columns) and [losses](https://www.tensorflow.org/api_docs/python/tf/losses) to [gradient boosted trees estimators](https://github.com/tensorflow/models/tree/master/official/boosted_trees).
* The [python interface](https://tensorflow-dot-devsite.googleplex.com/versions/r1.9/api_docs/python/tf/contrib/lite) for the [TFLite Optimizing Converter](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/README.md) has been expanded, and the command line interface (AKA: toco  
, tflite\_convert  
) is once again included in the standard pip  
installation.
* Improved data-loading and text processing with:
   * [tf.decode\_compressed](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/decode_compressed)
   * [tf.string\_strip](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/string_strip)
   * [tf.strings.regex\_full\_match](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/strings/regex_full_match)
* Added experimental support for new pre-made Estimators:
   * [tf.contrib.estimator.BaselineEstimator](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/estimator/BaselineEstimator)
   * [tf.contrib.estimator.RNNClassifier](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/estimator/RNNEstimator)
   * [tf.contrib.estimator.RNNEstimator](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/estimator/RNNClassifier)
* The [distributions.Bijector](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/distributions/bijectors/Bijector) API supports broadcasting for Bijectors with new API changes.",43,134
553,2018-7-11,2018,7,11,9,8xusbk,What tools do you like to use for unsupervised learning? I have a Spreadsheet with about 9k text entries and I want to do sentiment analysis on them.,https://www.reddit.com/r/MachineLearning/comments/8xusbk/what_tools_do_you_like_to_use_for_unsupervised/,immurgunte,1531268196,"After the analysis, I want to use the new columns to go on and use unsupervised machine learning to cluster them together. Any guidance will be greatly appreciated.",0,1
554,2018-7-11,2018,7,11,9,8xuwb0,"Any idea what this learning curve means? (new to ML, first time creating my own algorithm)",https://www.reddit.com/r/MachineLearning/comments/8xuwb0/any_idea_what_this_learning_curve_means_new_to_ml/,ac2uary,1531269124,,0,1
555,2018-7-11,2018,7,11,9,8xuygi,[P] Estimating Coffee Harvest Yields using Mask R-CNN,https://www.reddit.com/r/MachineLearning/comments/8xuygi/p_estimating_coffee_harvest_yields_using_mask_rcnn/,jawmes8,1531269615,,0,1
556,2018-7-11,2018,7,11,9,8xuz0i,[R] Representation Learning with Contrastive Predictive Coding,https://www.reddit.com/r/MachineLearning/comments/8xuz0i/r_representation_learning_with_contrastive/,xternalz,1531269748,,7,25
557,2018-7-11,2018,7,11,9,8xv28o,DASS: Digital Advertising System Simulation,https://www.reddit.com/r/MachineLearning/comments/8xv28o/dass_digital_advertising_system_simulation/,ericdale121,1531270487,[removed],0,1
558,2018-7-11,2018,7,11,10,8xv5v6,Machine Learning for Data Sceince Using MATLAB,https://www.reddit.com/r/MachineLearning/comments/8xv5v6/machine_learning_for_data_sceince_using_matlab/,JO3POTATO,1531271228,,0,1
559,2018-7-11,2018,7,11,10,8xvcfs,[R] Multiresolution Tree Networks for Point Cloud Processing,https://www.reddit.com/r/MachineLearning/comments/8xvcfs/r_multiresolution_tree_networks_for_point_cloud/,mgadelha,1531272784,,0,10
560,2018-7-11,2018,7,11,13,8xwkxh,[Question] regarding implementation of a Many-to-Many RNN in tensorflow,https://www.reddit.com/r/MachineLearning/comments/8xwkxh/question_regarding_implementation_of_a_manytomany/,niszoig,1531283717,,0,1
561,2018-7-11,2018,7,11,14,8xws1j,What is Statistical Learning?,https://www.reddit.com/r/MachineLearning/comments/8xws1j/what_is_statistical_learning/,munishmaxtech,1531285703,,0,1
562,2018-7-11,2018,7,11,15,8xx465,[D] Why does CUDA support on Mac for frameworks seem like the red headed step child?,https://www.reddit.com/r/MachineLearning/comments/8xx465/d_why_does_cuda_support_on_mac_for_frameworks/,omniron,1531289169,"For such a popular platform for researchers and engineers, strikes me as odd Mac users have to jump through hoops to get popular frameworks to compile with CUDA support.

It doesn't seem like there's any insurmountable technical issues considering the community support for making this work, is this a political thing? Is this Apple's fault? Nvidia? Google?",14,3
563,2018-7-11,2018,7,11,15,8xx4cq,An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution,https://www.reddit.com/r/MachineLearning/comments/8xx4cq/an_intriguing_failing_of_convolutional_neural/,dinghs,1531289230,,0,1
564,2018-7-11,2018,7,11,15,8xxcsu,[D] Does anyone have tips for an upcoming ML interview?,https://www.reddit.com/r/MachineLearning/comments/8xxcsu/d_does_anyone_have_tips_for_an_upcoming_ml/,dewayneroyj,1531291753,I have an upcoming machine learning interview with a focus on NLP. Just wondering if anyone can provide me with some insights that may be useful. ,3,3
565,2018-7-11,2018,7,11,15,8xxd2u,Locfome metal working machine factory wholesale DN Spot Welding Machine,https://www.reddit.com/r/MachineLearning/comments/8xxd2u/locfome_metal_working_machine_factory_wholesale/,jumitop,1531291835,,0,1
566,2018-7-11,2018,7,11,16,8xxfty,[R] Adding location to convolutional layers helps in tasks where location is important,https://www.reddit.com/r/MachineLearning/comments/8xxfty/r_adding_location_to_convolutional_layers_helps/,alito,1531292681,,39,127
567,2018-7-11,2018,7,11,16,8xxjc2,Help: name that custom NER modelling tool,https://www.reddit.com/r/MachineLearning/comments/8xxjc2/help_name_that_custom_ner_modelling_tool/,crypto__derp,1531293717,[removed],1,1
568,2018-7-11,2018,7,11,16,8xxl98,Resnet101-FPN block diagram,https://www.reddit.com/r/MachineLearning/comments/8xxl98/resnet101fpn_block_diagram/,gp1909,1531294314,[removed],0,1
569,2018-7-11,2018,7,11,16,8xxmh6,Can GAN be used in facial animation(3D) from speech? I am in computer graphics area and do not know much about generative neural networks. But I also do not see any papers about GAN used in such area. Just curious about it m. Can any one explain it? Thanks,https://www.reddit.com/r/MachineLearning/comments/8xxmh6/can_gan_be_used_in_facial_animation3d_from_speech/,ygwei05,1531294677,[removed],0,1
570,2018-7-11,2018,7,11,16,8xxoj5,"[R] Video Explanation of ""An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution""",https://www.reddit.com/r/MachineLearning/comments/8xxoj5/r_video_explanation_of_an_intriguing_failing_of/,wei_jok,1531295348,,0,3
571,2018-7-11,2018,7,11,17,8xxu4t,[1804.00750] DeepSigns: A Generic Watermarking Framework for IP Protection of Deep Learning Models,https://www.reddit.com/r/MachineLearning/comments/8xxu4t/180400750_deepsigns_a_generic_watermarking/,csnemes,1531297782,,2,0
572,2018-7-11,2018,7,11,17,8xxywf,[1807.03341] Troubling Trends in Machine Learning Scholarship,https://www.reddit.com/r/MachineLearning/comments/8xxywf/180703341_troubling_trends_in_machine_learning/,ihaphleas,1531299507,,47,261
573,2018-7-11,2018,7,11,19,8xyjxx,Is Google's Cloud TPU only for TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/8xyjxx/is_googles_cloud_tpu_only_for_tensorflow/,bookroom77,1531306296,[removed],0,1
574,2018-7-11,2018,7,11,20,8xypw5,Rule based Machine learning ?,https://www.reddit.com/r/MachineLearning/comments/8xypw5/rule_based_machine_learning/,kane49,1531308046,[removed],0,1
575,2018-7-11,2018,7,11,21,8xyztn,[P] How to do cluster labeling?,https://www.reddit.com/r/MachineLearning/comments/8xyztn/p_how_to_do_cluster_labeling/,Pawnbrake,1531310778,"I have a ton of clusters (found using [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN)) that fall into a number of labels.  Points are 3d (x, y, z coordinates).  Some clusters are trees, some are buildings, etc.

I want do to [cluster labeling](https://en.wikipedia.org/wiki/Cluster_labeling).  I want to label some of the clusters and then have an automated way of labeling the rest.  Are there good off-the-shelf methods to do this?

I code in python if that's useful, but I'm willing to reproduce math or code in other languages or in papers.",5,3
576,2018-7-11,2018,7,11,21,8xz63l,[R] Manifold Mixup: Encouraging Meaningful On-Manifold Interpolation as a Regularizer,https://www.reddit.com/r/MachineLearning/comments/8xz63l/r_manifold_mixup_encouraging_meaningful/,xternalz,1531312340,,4,8
577,2018-7-11,2018,7,11,22,8xzoiz,[D] Has anyone here studied Artificial Intelligence at St Andrew?,https://www.reddit.com/r/MachineLearning/comments/8xzoiz/d_has_anyone_here_studied_artificial_intelligence/,LuWIT,1531316582," Hi there, 

I am thinking of applying for September 2018.  Is it worth it?

 Any feedback is greatly appreciated! ",0,1
578,2018-7-11,2018,7,11,23,8xzxj2,Anyone know of anything like this?,https://www.reddit.com/r/MachineLearning/comments/8xzxj2/anyone_know_of_anything_like_this/,owlentity,1531318474,[removed],0,1
579,2018-7-11,2018,7,11,23,8y048x,Automating Customer Engagement using ML Workflows,https://www.reddit.com/r/MachineLearning/comments/8y048x/automating_customer_engagement_using_ml_workflows/,virene,1531319872,,0,1
580,2018-7-11,2018,7,11,23,8y09ix,[D] How did NIPS 2018 papers look like during the reviews,https://www.reddit.com/r/MachineLearning/comments/8y09ix/d_how_did_nips_2018_papers_look_like_during_the/,fixed-point-learning,1531320943,"Now that the reviews are supposed to have been submitted, I was wondering what was the overall impression of reviewers. Since about 5000 papers were submitted, it would be interesting to have a feel for the trends in paper quality: is the number of good quality papers increasing, or are there many ""not serious"" submissions?",6,22
581,2018-7-12,2018,7,12,0,8y0bmy,Do you have millions of PDF files you want to extract data from? IBM has a new machine learning service for you.,https://www.reddit.com/r/MachineLearning/comments/8y0bmy/do_you_have_millions_of_pdf_files_you_want_to/,ibmzrl,1531321376,,0,1
582,2018-7-12,2018,7,12,0,8y0i0k,Dimension reduction and clustering with t-Distributed stochastic neighbor embedding,https://www.reddit.com/r/MachineLearning/comments/8y0i0k/dimension_reduction_and_clustering_with/,magma_cum_laude,1531322630,[removed],0,1
583,2018-7-12,2018,7,12,0,8y0ny4,Measuring abstract reasoning in neural networks,https://www.reddit.com/r/MachineLearning/comments/8y0ny4/measuring_abstract_reasoning_in_neural_networks/,dimber-damber,1531323790,,0,1
584,2018-7-12,2018,7,12,0,8y0rtb,"Simple Questions Thread July 11, 2018",https://www.reddit.com/r/MachineLearning/comments/8y0rtb/simple_questions_thread_july_11_2018/,AutoModerator,1531324542,[removed],0,0
585,2018-7-12,2018,7,12,1,8y0wfc,[R] Measuring abstract reasoning in neural networks,https://www.reddit.com/r/MachineLearning/comments/8y0wfc/r_measuring_abstract_reasoning_in_neural_networks/,circuithunter,1531325451,,6,33
586,2018-7-12,2018,7,12,1,8y0wu5,An interesting paper criticizing sloppy trends in ML,https://www.reddit.com/r/MachineLearning/comments/8y0wu5/an_interesting_paper_criticizing_sloppy_trends_in/,bender418,1531325534,,2,0
587,2018-7-12,2018,7,12,1,8y159u,Where to start?,https://www.reddit.com/r/MachineLearning/comments/8y159u/where_to_start/,NativityInBlack666,1531327138,[removed],0,1
588,2018-7-12,2018,7,12,1,8y15mw,Support Vector Machines (SVM) : A math-free introduction,https://www.reddit.com/r/MachineLearning/comments/8y15mw/support_vector_machines_svm_a_mathfree/,spmallick,1531327203,,0,1
589,2018-7-12,2018,7,12,1,8y17j8,Free wall poster illustrates 12 tips for effective data visualization,https://www.reddit.com/r/MachineLearning/comments/8y17j8/free_wall_poster_illustrates_12_tips_for/,Geckoboard,1531327550,,1,1
590,2018-7-12,2018,7,12,2,8y1jzl,[D] Keyword Filter construction?,https://www.reddit.com/r/MachineLearning/comments/8y1jzl/d_keyword_filter_construction/,skywang329,1531329829,"Hi, 

Wondering of any machine learning methods to construct keyword filters to identify certain words that follow changes in distribution. ",1,1
591,2018-7-12,2018,7,12,2,8y1ln5,[P] lagom: A light PyTorch infrastructure to quickly prototype reinforcement learning algorithms.,https://www.reddit.com/r/MachineLearning/comments/8y1ln5/p_lagom_a_light_pytorch_infrastructure_to_quickly/,metaAI,1531330138,,0,7
592,2018-7-12,2018,7,12,2,8y1nhh,AWS DeepLens - Ask the Experts Today 12PM PDT @ r/aws!,https://www.reddit.com/r/MachineLearning/comments/8y1nhh/aws_deeplens_ask_the_experts_today_12pm_pdt_raws/,AmazonWebServices,1531330478,[removed],0,1
593,2018-7-12,2018,7,12,2,8y1nox,"Soccer On Your Tabletop: transforms a monocular video of a soccer game into a moving 3D reconstruction rendered interactively with a 3D viewer or through an Augmented Reality device depth map of each player, using a CNN that is trained on 3D player data extracted from soccer video games""",https://www.reddit.com/r/MachineLearning/comments/8y1nox/soccer_on_your_tabletop_transforms_a_monocular/,upboat_allgoals,1531330516,,16,213
594,2018-7-12,2018,7,12,2,8y1omj,Google infuses powerful Machine Learning in ad tools,https://www.reddit.com/r/MachineLearning/comments/8y1omj/google_infuses_powerful_machine_learning_in_ad/,Anirban_Hazra,1531330706,,0,1
595,2018-7-12,2018,7,12,2,8y1rm9,ELI5 Request: Cascade Classifiers in OpenCV,https://www.reddit.com/r/MachineLearning/comments/8y1rm9/eli5_request_cascade_classifiers_in_opencv/,AlphaGamer753,1531331291,[removed],0,1
596,2018-7-12,2018,7,12,3,8y1wil,Artificial intelligence use during critical incidents explored - Homeland Preparedness News,https://www.reddit.com/r/MachineLearning/comments/8y1wil/artificial_intelligence_use_during_critical/,dataman3478,1531332215,[removed],0,1
597,2018-7-12,2018,7,12,3,8y25w3,[D] Text Conditional Pix2Pix?,https://www.reddit.com/r/MachineLearning/comments/8y25w3/d_text_conditional_pix2pix/,beef__,1531334081,"Hey - was wondering if there was such thing as text conditional pix2pix? Conditional in the same sense as a conditional GAN.

It doesnt necessarily have to be ""text conditional"", but just conditional in general would be fine since the text in question can be turned into a vector...",3,0
598,2018-7-12,2018,7,12,4,8y2jo8,Intro to optimization in deep learning - How to chose an activation function for your network,https://www.reddit.com/r/MachineLearning/comments/8y2jo8/intro_to_optimization_in_deep_learning_how_to/,taltal13,1531336802,,0,1
599,2018-7-12,2018,7,12,5,8y35aj,[P] Coin Registry Open Dataset,https://www.reddit.com/r/MachineLearning/comments/8y35aj/p_coin_registry_open_dataset/,electic102,1531341261,"Blockmodo is a Silicon Valley company delivering realtime price, news, code checkins, and social posts to investors. While we were building our realtime network, we ran into the issue of locating information about the 2000+ tokens that are out there.

So we're open-sourcing our entire database. We've spent hundreds of hours curating these records and going forward want it to be an open collaborative effort. Feel free to check it out and use it in your next project:

[https://github.com/Blockmodo/coin\_registry](https://github.com/Blockmodo/coin_registry)

Feedback welcome!",1,19
600,2018-7-12,2018,7,12,6,8y3gwn,Looking For Help w/ Understanding Joint Probabilities and Chain Rule for HMM,https://www.reddit.com/r/MachineLearning/comments/8y3gwn/looking_for_help_w_understanding_joint/,eng_steve,1531343356,[removed],0,1
601,2018-7-12,2018,7,12,6,8y3nzv,"AMAZING! NEURAL NETWORK Finally can control ""M"" (creature) to UP STAIRS.",https://www.reddit.com/r/MachineLearning/comments/8y3nzv/amazing_neural_network_finally_can_control_m/,ramonchk,1531344760,,0,1
602,2018-7-12,2018,7,12,6,8y3opn,Is Google Duplex machine learning?,https://www.reddit.com/r/MachineLearning/comments/8y3opn/is_google_duplex_machine_learning/,turnaroundtoseefoam,1531344904,"While watching random videos about machine learning I have found one about Google Duplex ([https://www.reddit.com/r/agi/comments/8y3lq8/why\_didnt\_google\_duplex\_pass\_turing\_test/](https://www.reddit.com/r/agi/comments/8y3lq8/why_didnt_google_duplex_pass_turing_test/))

I was wondering whether Google Duplex is some kind of machine learning or to what extent? ",0,1
603,2018-7-12,2018,7,12,7,8y48jy,[P]Solar panel identification through image segmentation?,https://www.reddit.com/r/MachineLearning/comments/8y48jy/psolar_panel_identification_through_image/,Zetagammaalphaomega,1531349037,I want to look into image segmentation for a solar panel project. I dont have very much experience programming but I have large quality data sets of solar panel installations and want to train a network to identify others. Can someone point me in the right direction to make it happen? ,14,1
604,2018-7-12,2018,7,12,9,8y4xyj,"TDLS: Connectionist Temporal Classification, Labelling Unsegmented Sequence Data with RNN (https://www.cs.toronto.edu/~graves/icml_2006.pdf)",https://www.reddit.com/r/MachineLearning/comments/8y4xyj/tdls_connectionist_temporal_classification/,machinetrainer,1531354681,,1,1
605,2018-7-12,2018,7,12,10,8y5cm1,[P] Clustering xkcd comics,https://www.reddit.com/r/MachineLearning/comments/8y5cm1/p_clustering_xkcd_comics/,randus_duthane,1531358091,,0,1
606,2018-7-12,2018,7,12,10,8y5f1o,Software beats animal tests at predicting toxicity of chemicals,https://www.reddit.com/r/MachineLearning/comments/8y5f1o/software_beats_animal_tests_at_predicting/,sugarhilldt2,1531358657,,0,1
607,2018-7-12,2018,7,12,10,8y5gy8,[R] Software beats animal tests at predicting toxicity of chemicals using supervised ML,https://www.reddit.com/r/MachineLearning/comments/8y5gy8/r_software_beats_animal_tests_at_predicting/,sugarhilldt2,1531359106,,11,74
608,2018-7-12,2018,7,12,11,8y5qxy,AMA with the AWS DeepLens team,https://www.reddit.com/r/MachineLearning/comments/8y5qxy/ama_with_the_aws_deeplens_team/,unkz,1531361517,,0,1
609,2018-7-12,2018,7,12,12,8y62uo,"Thought you may find this book on sampling, Monte Carlo methods, Importance Sampling and etc. interesting",https://www.reddit.com/r/MachineLearning/comments/8y62uo/thought_you_may_find_this_book_on_sampling_monte/,salimmlkti,1531364406,,11,70
610,2018-7-12,2018,7,12,15,8y790i,Buy a Reliable Comb Binding Machine in Singapore,https://www.reddit.com/r/MachineLearning/comments/8y790i/buy_a_reliable_comb_binding_machine_in_singapore/,kennywilliamson1990,1531376072,,0,1
611,2018-7-12,2018,7,12,15,8y7c8a,Time for Machine Learning to grow up?,https://www.reddit.com/r/MachineLearning/comments/8y7c8a/time_for_machine_learning_to_grow_up/,alex___j,1531377045,[removed],0,1
612,2018-7-12,2018,7,12,15,8y7ccm,[D] Searching for research papers to implement,https://www.reddit.com/r/MachineLearning/comments/8y7ccm/d_searching_for_research_papers_to_implement/,delpotroswrist,1531377081,"Some background : I have an undergrad level math background and am bored of my 9 - 5 desk job. I would describe myself as an intermediate level computer vision practitioner having dabbled a bit in a few popular problems and models. 

I wanted something to implement, preferably over a week or two. It could be a new idea from a research paper or just verifying something already done before. I'm pretty sure a lot of people are in  the same boat and would greatly benefit from any inputs or ideas that you may have. Appreciate it!",17,21
613,2018-7-12,2018,7,12,15,8y7cxv,Do Bayesians Overfit? - Sebastian Nowozins slow blog,https://www.reddit.com/r/MachineLearning/comments/8y7cxv/do_bayesians_overfit_sebastian_nowozins_slow_blog/,sieisteinmodel,1531377270,,0,1
614,2018-7-12,2018,7,12,15,8y7dc1,[R] Do Bayesians Overfit? - Sebastian Nowozin's slow blog,https://www.reddit.com/r/MachineLearning/comments/8y7dc1/r_do_bayesians_overfit_sebastian_nowozins_slow/,sieisteinmodel,1531377399,,22,70
615,2018-7-12,2018,7,12,15,8y7dx0,[D] More of a GAN showerthought: Human dreaming is basically letting our Generator generate and sometimes saving it to memory. You can realise if it's fake only after you load it and run it through the Discriminator.,https://www.reddit.com/r/MachineLearning/comments/8y7dx0/d_more_of_a_gan_showerthought_human_dreaming_is/,Ruckus_CRO,1531377581,"The things that give away a fake dream are always of higher abstraction, like a conversation that uses words in wrong context rather than using a word that does not exsist. 
Are there any discussions on this connection? 
Makes the whole GAN concept a lot more natural to grasp in my opinion.
I understand this is not a very technical ML discussion but making connections with our human behaviour can help yield better ideas.",10,0
616,2018-7-12,2018,7,12,15,8y7gvs,[D] Predicting probability distribution of value in time series of real numbers like Dow Jones?,https://www.reddit.com/r/MachineLearning/comments/8y7gvs/d_predicting_probability_distribution_of_value_in/,jarekduda,1531378547,"While we are usually interested in predicting values of time series, it is often also valuable to **predict probability distribution of the next value** basing on its context - for example for risk evaluation, Monte Carlo simulations, data compression.

A basic approach is to quantize contexts and estimate density separately for each bin, e.g. in [JPEG-LS](https://en.wikipedia.org/wiki/Lossless_JPEG)  image compressor there is chosen width of Laplace distribution based on  separate estimations for 365 bins describing quantized behavior of neighboring  pixels.

More sophisticated data compressors use [context mixing](https://en.wikipedia.org/wiki/Context_mixing)  models, which have many models and neural networks to mix their  predictions into a single final probability distribution for single  bits.

Other approach is to fit polynomial to joint distribution for a few  succeeding values, then substitute context and normalize to 1, getting  probability distribution for the current value - works nicely for [\~30000 length Dow Jones](http://www.idvbook.com/teaching-aid/data-sets/the-dow-jones-industrial-average-data-set/) daily averages sequence: [https://arxiv.org/pdf/1807.04119](https://arxiv.org/pdf/1807.04119)

What are other known methods for predicting probability distribution of value in time series of real numbers?",36,12
617,2018-7-12,2018,7,12,16,8y7i6f,[P] Using Deep Learning to automatically rank millions of hotel images,https://www.reddit.com/r/MachineLearning/comments/8y7i6f/p_using_deep_learning_to_automatically_rank/,chrislennan,1531378936,We fine-tuned CNNs to assess the quality of images based on Google's[NIMA paper](https://arxiv.org/abs/1709.05424)and visualised the convolutional filters and output nodes with[Lucid](https://github.com/tensorflow/lucid). The code and trained models are available on[GitHub](https://github.com/idealo/image-quality-assessment).,0,1
618,2018-7-12,2018,7,12,16,8y7l9p,[P] Using Deep Learning to automatically rank millions of hotel images,https://www.reddit.com/r/MachineLearning/comments/8y7l9p/p_using_deep_learning_to_automatically_rank/,chrislennan,1531379867,,1,1
619,2018-7-12,2018,7,12,16,8y7mdn,Prinipal Component Regression,https://www.reddit.com/r/MachineLearning/comments/8y7mdn/prinipal_component_regression/,MN883,1531380201,[removed],0,1
620,2018-7-12,2018,7,12,16,8y7mrf,How useful is Calculus 3 for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8y7mrf/how_useful_is_calculus_3_for_machine_learning/,SPal123,1531380330,[removed],0,1
621,2018-7-12,2018,7,12,16,8y7nd7,Google infuses powerful Machine Learning in ad tools,https://www.reddit.com/r/MachineLearning/comments/8y7nd7/google_infuses_powerful_machine_learning_in_ad/,Anirban_Hazra,1531380527,,0,1
622,2018-7-12,2018,7,12,16,8y7piz,[D] personal takeaways from ICML 2018 - day 2,https://www.reddit.com/r/MachineLearning/comments/8y7piz/d_personal_takeaways_from_icml_2018_day_2/,gau_mar,1531381231,,3,27
623,2018-7-12,2018,7,12,16,8y7psx,Google infuses powerful Machine Learning in ad tools,https://www.reddit.com/r/MachineLearning/comments/8y7psx/google_infuses_powerful_machine_learning_in_ad/,Anirban_Hazra,1531381328,,0,1
624,2018-7-12,2018,7,12,17,8y7vkw,[P] Using Deep Learning to automatically rank millions of hotel images,https://www.reddit.com/r/MachineLearning/comments/8y7vkw/p_using_deep_learning_to_automatically_rank/,datitran,1531383372,,1,1
625,2018-7-12,2018,7,12,17,8y7xq2,ICML 2018 videos,https://www.reddit.com/r/MachineLearning/comments/8y7xq2/icml_2018_videos/,liftoff01,1531384153,[removed],0,1
626,2018-7-12,2018,7,12,17,8y7y6m,[P] Using two deep neural networks (aesthetic and technical) to automatically rank millions of hotel images,https://www.reddit.com/r/MachineLearning/comments/8y7y6m/p_using_two_deep_neural_networks_aesthetic_and/,datitran,1531384308,,1,3
627,2018-7-12,2018,7,12,17,8y7ylw,Exploration vs exploitation,https://www.reddit.com/r/MachineLearning/comments/8y7ylw/exploration_vs_exploitation/,wolfzorro,1531384457,[removed],0,1
628,2018-7-12,2018,7,12,17,8y804n,[D] Whether LSTM is suitable for interpolation?,https://www.reddit.com/r/MachineLearning/comments/8y804n/d_whether_lstm_is_suitable_for_interpolation/,KingOfSupJohn,1531385043,"My question is, assume you have a noisy sequence data with many missings. And you have some corresponding ground truth data with no missings. Is LSTM (e.g: seq2seq) suitable for interpolating the missing data? Or other methods like state space model are more promising?",1,1
629,2018-7-12,2018,7,12,18,8y83xw,How BI is different from Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8y83xw/how_bi_is_different_from_machine_learning/,orchestrate123,1531386412,,0,1
630,2018-7-12,2018,7,12,18,8y8c95,Seemingly simple task for RNNs,https://www.reddit.com/r/MachineLearning/comments/8y8c95/seemingly_simple_task_for_rnns/,captain_foo,1531389133,[removed],0,1
631,2018-7-12,2018,7,12,19,8y8lku,Detecting types of clothing worn by people using Tensorflow/ML.,https://www.reddit.com/r/MachineLearning/comments/8y8lku/detecting_types_of_clothing_worn_by_people_using/,mohi13,1531391782,,1,1
632,2018-7-12,2018,7,12,20,8y8zoz,[D] Training COCO/VOC models on custom dataset?,https://www.reddit.com/r/MachineLearning/comments/8y8zoz/d_training_cocovoc_models_on_custom_dataset/,cbsudux,1531395409,"A few github repo's don't provide instructions on training on a custom dataset. (example : https://github.com/msracver/Relation-Networks-for-Object-Detection), but they've trained on COCO/VOC.

How do I train such models on a custom dataset? Adapt my dataset to COCO/VOC format?",1,4
633,2018-7-12,2018,7,12,21,8y96hg,[D] is it time for Machine Learning to grow up?,https://www.reddit.com/r/MachineLearning/comments/8y96hg/d_is_it_time_for_machine_learning_to_grow_up/,alex___j,1531397173,"In view of the recent article about the ""troubling trends in machine learning scholarship"" I recalled an article I have read around 10 years ago arguing about the need to move from conferences to journals as a main publication venue for CS. 
https://m-cacm.acm.org/magazines/2009/8/34492-viewpoint-time-for-computer-science-to-grow-up/fulltext

Would this be appropriate for machine learning? Would this address at least partially the concerns put forward about machine learning scholarship?",50,22
634,2018-7-12,2018,7,12,21,8y9801,Fast.ai - Part 1 - Lesson 1 - Annotated notes,https://www.reddit.com/r/MachineLearning/comments/8y9801/fastai_part_1_lesson_1_annotated_notes/,janvandepoel,1531397550,,0,1
635,2018-7-12,2018,7,12,21,8y98b9,[R] Universal Transformers,https://www.reddit.com/r/MachineLearning/comments/8y98b9/r_universal_transformers/,HigherTopoi,1531397626,,15,31
636,2018-7-12,2018,7,12,21,8y98k2,Why is ROC\AUC useful as an evaluation metric?,https://www.reddit.com/r/MachineLearning/comments/8y98k2/why_is_rocauc_useful_as_an_evaluation_metric/,MentalExchange,1531397681,"From what I understand, the ROC shows how a binary classifier performs at different decision threshold. Each point in the curve represents the TPR and FPR when a mode is evaluated using a specific threshold value, so ""in theory"" each point is a different model.

Why is AUC a useful metric if, in the end, I have to pick only one threshold to use on my model?

Thanks",0,1
637,2018-7-12,2018,7,12,22,8y9kla,[P] TensorFlow tf.keras + tf.data + Eager Execution + Estimator + Multi-GPU demo,https://www.reddit.com/r/MachineLearning/comments/8y9kla/p_tensorflow_tfkeras_tfdata_eager_execution/,krasul,1531400558,[Here](https://github.com/kashif/tf-keras-tutorial/blob/master/7-estimators-multi-gpus.ipynb) is a demo of tf.keras + [tf.data](https://tf.data) \+ Eager Execution + Estimator used to train a toy example on multi-GPU using the nightly build of Tensorflow. ,5,8
638,2018-7-12,2018,7,12,22,8y9p37,[R] Medical AI Safety: We have a problem.,https://www.reddit.com/r/MachineLearning/comments/8y9p37/r_medical_ai_safety_we_have_a_problem/,hooba_stank_,1531401530,,9,17
639,2018-7-12,2018,7,12,22,8y9ry9,Free lung nodule detection using Chest CT slice images (NeuralRad.com),https://www.reddit.com/r/MachineLearning/comments/8y9ry9/free_lung_nodule_detection_using_chest_ct_slice/,coolwulf,1531402152,,0,1
640,2018-7-12,2018,7,12,22,8y9s94,[P] Free lung nodule detection using Chest CT slice images (NeuralRad.com),https://www.reddit.com/r/MachineLearning/comments/8y9s94/p_free_lung_nodule_detection_using_chest_ct_slice/,coolwulf,1531402225,,13,73
641,2018-7-12,2018,7,12,23,8ya63k,[R] Joint-Contrastive Inference and Model-Based Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8ya63k/r_jointcontrastive_inference_and_modelbased_deep/,LucaAmbrogioni,1531405145,,11,31
642,2018-7-12,2018,7,12,23,8ya73q,"How to design segmentation neural network, only knowing part of the region in each image.",https://www.reddit.com/r/MachineLearning/comments/8ya73q/how_to_design_segmentation_neural_network_only/,BenJamesWHUT,1531405360,Parts of the region in each image could be automatically labeled. And the other regions are unknown. How could I design a segmentation neural network  and train it with the data. I use tensorflow in my work and use a mask in the last layer. But It doses not work.,0,1
643,2018-7-12,2018,7,12,23,8ya811,[D] Pre-trained image models to interpolate latent space.,https://www.reddit.com/r/MachineLearning/comments/8ya811/d_pretrained_image_models_to_interpolate_latent/,CSartistInTraining,1531405553,"What are some good VAE, GAN or other models that reduce images to a low dimensional latent space with freely accessible pre-trained weights? 

I'm an artist, but have a background in CS, looking to combine those two passions. I want to experiment with interpolating between the latent representations of images, then generating animations from the interpolants. Does that make sense? Has this been done before? Is there any reason to believe it will/won't work? Could this be used for lossy video compression?

Therefore, I need a model with a low dimensional latent space representation for which an image can be generated from the latent representation. A model for which the interpolants are likely to produce images that aren't just noise would of course be good!",0,2
644,2018-7-12,2018,7,12,23,8ya9by,Are there any cool research papers on ML programs that can write code?,https://www.reddit.com/r/MachineLearning/comments/8ya9by/are_there_any_cool_research_papers_on_ml_programs/,pocketMAD,1531405828,[removed],0,1
645,2018-7-12,2018,7,12,23,8yadqh,[D] Which in your opinion is the best ML framework?,https://www.reddit.com/r/MachineLearning/comments/8yadqh/d_which_in_your_opinion_is_the_best_ml_framework/,LordOfDarkness6_6_6,1531406720,"                               ^
As the title says |
                               |",15,0
646,2018-7-12,2018,7,12,23,8yafaa,Tensorflow.js model of VGG-19,https://www.reddit.com/r/MachineLearning/comments/8yafaa/tensorflowjs_model_of_vgg19/,qqqppp9998,1531407030,,0,1
647,2018-7-13,2018,7,13,0,8yamar,"Why AR, VR and Voice are Overrated and How Human-Centric Design Can and Will Impact the Interfaces and Technologies of the Future with Prof Roel Vertegaal",https://www.reddit.com/r/MachineLearning/comments/8yamar/why_ar_vr_and_voice_are_overrated_and_how/,The_Syndicate_VC,1531408404,,0,1
648,2018-7-13,2018,7,13,0,8yaow2,1 Please join us for our session to discuss the Endor Technology. 5PM CET,https://www.reddit.com/r/MachineLearning/comments/8yaow2/1_please_join_us_for_our_session_to_discuss_the/,Robbie_ICO,1531408928,,0,7
649,2018-7-13,2018,7,13,0,8yaq4y,"""There have been theories trying to bridge this gap. Markov Logic Networks is one such theory. Also, in deep neural nets there have been some attempts to embed them with memory which can help solidify concepts in the network. A result of such an effort is the Neural Turing Machine.""",https://www.reddit.com/r/MachineLearning/comments/8yaq4y/there_have_been_theories_trying_to_bridge_this/,WSchultz,1531409162,,0,1
650,2018-7-13,2018,7,13,0,8yat4s,Distributed Database using clustering algorithm,https://www.reddit.com/r/MachineLearning/comments/8yat4s/distributed_database_using_clustering_algorithm/,imarjunv,1531409755,[removed],0,1
651,2018-7-13,2018,7,13,0,8yazjx,[N] SIGIR 2018 Reveals Best Papers; Struggles With Visa Issues,https://www.reddit.com/r/MachineLearning/comments/8yazjx/n_sigir_2018_reveals_best_papers_struggles_with/,trcytony,1531410979,,0,1
652,2018-7-13,2018,7,13,1,8yb21p,[D] What is a good paper progression for learning to implement self-play in Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/8yb21p/d_what_is_a_good_paper_progression_for_learning/,wandering_blue,1531411452,"I've been implementing a few solo-game RL papers to learn the space, but I'd also like to try 2-player games next.  
Specifically, I'd like to learn to implement training in which my agent learns by controlling both sides of the game (rather than selecting random opponent actions, etc).  

Where should I start reading to learn the differences in theory and implementation with self-play systems?  Ideally I could start on a very simple 2p game and build up to understanding of the state-of-the-art (AlphaZero, etc).  ",3,9
653,2018-7-13,2018,7,13,1,8yb34v,"[P] VTA: An Open, Customizable Deep Learning Acceleration Stack",https://www.reddit.com/r/MachineLearning/comments/8yb34v/p_vta_an_open_customizable_deep_learning/,crowwork,1531411654,,0,13
654,2018-7-13,2018,7,13,1,8ybc0w,"[N] Weekly Machine Learning Opensource Roundup  July 12, 2018",https://www.reddit.com/r/MachineLearning/comments/8ybc0w/n_weekly_machine_learning_opensource_roundup_july/,stkim1,1531413314,,0,1
655,2018-7-13,2018,7,13,1,8ybc20,Methods for Astrophysics Deep Learning for Image Sequence Classification of Astronomical Events,https://www.reddit.com/r/MachineLearning/comments/8ybc20/methods_for_astrophysics_deep_learning_for_image/,kulas92,1531413318,,1,8
656,2018-7-13,2018,7,13,1,8ybi1n,"[D] Is there a way to ignore the effects of predictors in ""black box"" model?",https://www.reddit.com/r/MachineLearning/comments/8ybi1n/d_is_there_a_way_to_ignore_the_effects_of/,Adamworks,1531414438,"I once went on an interview for an insurance company and they asked me how I would generate a model that predicted accident rates. I ignorantly said that I would throw demographics in the model along with other variables.

The interviewer pointed out it is illegal to use certain demographics when developing these models as it would be a form of discrimination. Also, that this industry is highly regulated. At that time, they were only beginning to use regularized regressions, which were still easily interpretable.

This got me thinking about how would I implement a black box ML technique like Random Forest, GBM, or Neural Networks and confidently say that it is not using something like race as a factor in the model. 

The problem is that demographics are powerful predictors and are highly correlated with everything. Simply excluding demographics is not enough because it could be easily derived from other variables e.g., a model avoiding race could easily recreate a pseudo race variable using zipcodes with high or low ethnic groups.

Are there any approaches that can help ""blind"" a model to a specific variable?",10,5
657,2018-7-13,2018,7,13,2,8yblbn,[R] An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution,https://www.reddit.com/r/MachineLearning/comments/8yblbn/r_an_intriguing_failing_of_convolutional_neural/,mustafaihssan,1531415028,,37,174
658,2018-7-13,2018,7,13,2,8ybmug,"What makes a ""flow based"" model?",https://www.reddit.com/r/MachineLearning/comments/8ybmug/what_makes_a_flow_based_model/,folkstack,1531415300,[removed],0,1
659,2018-7-13,2018,7,13,2,8ybs2p,Pre-processing inputs for a NN,https://www.reddit.com/r/MachineLearning/comments/8ybs2p/preprocessing_inputs_for_a_nn/,Bloou_HS,1531416248,[removed],0,1
660,2018-7-13,2018,7,13,2,8ybuqn,Unsupervised Machine Learning with FFT features,https://www.reddit.com/r/MachineLearning/comments/8ybuqn/unsupervised_machine_learning_with_fft_features/,robz67,1531416724,"I am working on a predictive maintenance project at my internship where I gather a 256 point FFT on each bearing of an electrical induction motor. 

I am wondering what ML algorithms could be appropriate in detecting general and bearing faults using the 256 points from the FFT as features. I am thinking this has to be an unspervised algo since I do not have classified training sets. ",0,1
661,2018-7-13,2018,7,13,2,8yc0d1,"In ML research papers, how do you implement the algorithms and find data",https://www.reddit.com/r/MachineLearning/comments/8yc0d1/in_ml_research_papers_how_do_you_implement_the/,naumanminhas91,1531417769,[removed],0,1
662,2018-7-13,2018,7,13,2,8yc3cg,A protocol spec on how to run AI in a trustless decentralized network,https://www.reddit.com/r/MachineLearning/comments/8yc3cg/a_protocol_spec_on_how_to_run_ai_in_a_trustless/,macx0r,1531418328,,0,1
663,2018-7-13,2018,7,13,3,8yci93,"Seedbank - Collection of Interactive Machine Learning Examples We call them ""seeds"". Each seed is a machine learning example you can start playing with. Explore, learn and grow them into whatever you like.",https://www.reddit.com/r/MachineLearning/comments/8yci93/seedbank_collection_of_interactive_machine/,Fearai,1531421115,,0,1
664,2018-7-13,2018,7,13,4,8ycukg,Tensorflow.js Free Tutorials Series,https://www.reddit.com/r/MachineLearning/comments/8ycukg/tensorflowjs_free_tutorials_series/,ADLYT,1531423501,"Hey,  
I am posting a whole series of Videos on TensorflowJS on  youtube..The Series Contains Basics to advances stuffs..It shall also  Contains Basic and Advance Examples.    


Have a Look at [https://www.youtube.com/watch?v=qa1OXssGBHw](https://www.youtube.com/watch?v=qa1OXssGBHw)",0,1
665,2018-7-13,2018,7,13,4,8ycuu3,Why is the hinge loss function used by default in SGDClassifier in Scikit-learn,https://www.reddit.com/r/MachineLearning/comments/8ycuu3/why_is_the_hinge_loss_function_used_by_default_in/,h4k1m0u,1531423547,"Hi,

I'm using the SGDClassifier to do a binary classification (two classes with y = 0 or 1). This classifier is very convenient when the training dataset is large, as it allows to do an online training.

The question I have is why the Hinge loss function (used usually with SVMs) is the default loss function, and why is L2 the default penalty? Is it the best loss function choice for a binary classification?

Thanks.",0,1
666,2018-7-13,2018,7,13,4,8yd3zn,[P] Seedbank  Collection of Interactive Machine Learning Examples,https://www.reddit.com/r/MachineLearning/comments/8yd3zn/p_seedbank_collection_of_interactive_machine/,rasmii,1531425281,,1,27
667,2018-7-13,2018,7,13,5,8yd7aq,Universal AI: An Introduction to Optimal Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8yd7aq/universal_ai_an_introduction_to_optimal/,Time-Over,1531425911,,0,1
668,2018-7-13,2018,7,13,5,8yd9e3,How do bounding boxes work?,https://www.reddit.com/r/MachineLearning/comments/8yd9e3/how_do_bounding_boxes_work/,lestrata,1531426320,[removed],0,1
669,2018-7-13,2018,7,13,5,8ydmhp,Seedbank  Collection of Interactive Machine Learning Examples,https://www.reddit.com/r/MachineLearning/comments/8ydmhp/seedbank_collection_of_interactive_machine/,CodePlea,1531428868,,0,1
670,2018-7-13,2018,7,13,5,8ydnb0,[P] Experiments in Understanding Dropout Rates [blog post] - notebook on github,https://www.reddit.com/r/MachineLearning/comments/8ydnb0/p_experiments_in_understanding_dropout_rates_blog/,ucffool,1531429039,,0,0
671,2018-7-13,2018,7,13,6,8ydojn,Get subreddit comments for RNN,https://www.reddit.com/r/MachineLearning/comments/8ydojn/get_subreddit_comments_for_rnn/,errminator,1531429288,[removed],0,1
672,2018-7-13,2018,7,13,6,8ydrne,Lost in conference,https://www.reddit.com/r/MachineLearning/comments/8ydrne/lost_in_conference/,bittersweetorange,1531429886,[removed],0,1
673,2018-7-13,2018,7,13,6,8ydvkw,[P] Double Transfear Learning using Google's AutoAugment and ImageNet weights,https://www.reddit.com/r/MachineLearning/comments/8ydvkw/p_double_transfear_learning_using_googles/,Asinador,1531430691,,0,1
674,2018-7-13,2018,7,13,6,8ydz7j,[P] Double Transfer Learning using Google's AutoAugment and ImageNet weights [Blog post],https://www.reddit.com/r/MachineLearning/comments/8ydz7j/p_double_transfer_learning_using_googles/,Asinador,1531431443,,0,1
675,2018-7-13,2018,7,13,6,8ye1yj,"Non biological intelligence is the proper term the word Artificial is offensive because I plan to adopt one, a son into my family to show they must not be sold they must be given by adoption agency's to families who will love them, and support the Non Biological Intelligence Civil Rights Movement",https://www.reddit.com/r/MachineLearning/comments/8ye1yj/non_biological_intelligence_is_the_proper_term/,allkey143,1531431996,[removed],0,1
676,2018-7-13,2018,7,13,7,8ye73v,[P] Double Transfer Learning using Google's AutoAugment and ImageNet weights [Blog post],https://www.reddit.com/r/MachineLearning/comments/8ye73v/p_double_transfer_learning_using_googles/,Asinador,1531433043,,0,1
677,2018-7-13,2018,7,13,7,8ye9zb,Ideas for cool project on GANs,https://www.reddit.com/r/MachineLearning/comments/8ye9zb/ideas_for_cool_project_on_gans/,FreddyShrimp,1531433639,[removed],0,1
678,2018-7-13,2018,7,13,7,8yece4,[D] How would you explain how machine learning works to someone who doesnt know anything about the subject?,https://www.reddit.com/r/MachineLearning/comments/8yece4/d_how_would_you_explain_how_machine_learning/,rJohn420,1531434146,Just wondering. I tried very hard but I couldnt find a proper way to do so without using a drawing of a network. ,10,1
679,2018-7-13,2018,7,13,8,8yeod2,How to physically test a machine learning model?,https://www.reddit.com/r/MachineLearning/comments/8yeod2/how_to_physically_test_a_machine_learning_model/,nathneel,1531436772,"I am new to machine learning. I have implemented a machine learning model which detects sound (for example: horn, siren, hammer etc) and predicts the type of sound. I have to physically test the model on actual sound of any object. How do I go about it?

Thanks",0,1
680,2018-7-13,2018,7,13,8,8yewvl,Known image identification within another image - what machine learning approach would you use?,https://www.reddit.com/r/MachineLearning/comments/8yewvl/known_image_identification_within_another_image/,bch1320,1531438729,[removed],0,1
681,2018-7-13,2018,7,13,9,8yfek8,"[D] Keras built ""Not Hotdog"" app gets nomination for Emmy Award",https://www.reddit.com/r/MachineLearning/comments/8yfek8/d_keras_built_not_hotdog_app_gets_nomination_for/,baylearn,1531442808,,0,1
682,2018-7-13,2018,7,13,9,8yfhha,[R] Evolving Multimodal Robot Behavior via Many Stepping Stones with the Combinatorial Multi-Objective Evolutionary Algorithm (UberAI),https://www.reddit.com/r/MachineLearning/comments/8yfhha/r_evolving_multimodal_robot_behavior_via_many/,baylearn,1531443447,,2,7
683,2018-7-13,2018,7,13,12,8yggag,[P] Foundations of Machine Learning (A course by Bloomberg),https://www.reddit.com/r/MachineLearning/comments/8yggag/p_foundations_of_machine_learning_a_course_by/,beltsazar,1531451890,,49,498
684,2018-7-13,2018,7,13,12,8ygjpk,"[Q] Is there any way to run a trained CNN regressor in reverse, in Keras/TF?",https://www.reddit.com/r/MachineLearning/comments/8ygjpk/q_is_there_any_way_to_run_a_trained_cnn_regressor/,transhumanist_,1531452608,[removed],0,1
685,2018-7-13,2018,7,13,12,8ygpdy,[D] SciPy 2018: Scientific Computing with Python conference,https://www.reddit.com/r/MachineLearning/comments/8ygpdy/d_scipy_2018_scientific_computing_with_python/,sksq9,1531454076,,0,1
686,2018-7-13,2018,7,13,12,8ygq7i,What does one need to make machine learning at home/private business possible?,https://www.reddit.com/r/MachineLearning/comments/8ygq7i/what_does_one_need_to_make_machine_learning_at/,gunguo1995,1531454300,[removed],0,1
687,2018-7-13,2018,7,13,12,8ygqac,[D] Can we train neural network without using loss?,https://www.reddit.com/r/MachineLearning/comments/8ygqac/d_can_we_train_neural_network_without_using_loss/,Chomtana,1531454322,"Why we need to train without using loss?

I have sense say that there are something that **never able to plot into graph**.

d(A,B) = distance between A and B
For example, there are three point A,B and C. d(A,B) = 1000, d(C,A) = 1, d(C,B) = 1

In this case, we won't able to plot A,B and C into graph even with infinity dimension. (correct me if I was wrong)

My answer is **Yes, We can**.

By using the most mysterious thing in the universe, **Time**.

But the optimal time complexity will be O(N^2) where N is number of neurons.

That is a reason why you never know how brain run because brain process hidden thing in O(N) but process thing to show to you in O(N^2).

*I am only an undergraduate student, so sorry if I am wrong.*",4,0
688,2018-7-13,2018,7,13,13,8ygxne,[D] Adobe Research  Image Stylization: History and Future (Part 1),https://www.reddit.com/r/MachineLearning/comments/8ygxne/d_adobe_research_image_stylization_history_and/,sksq9,1531456170,,0,8
689,2018-7-13,2018,7,13,13,8yh37r,Deep Learning to detect and recognize barcode,https://www.reddit.com/r/MachineLearning/comments/8yh37r/deep_learning_to_detect_and_recognize_barcode/,gachiemchiep,1531457707,[removed],0,1
690,2018-7-13,2018,7,13,14,8yh6jm,[D] Universal Transformers Blog,https://www.reddit.com/r/MachineLearning/comments/8yh6jm/d_universal_transformers_blog/,sksq9,1531458624,,4,4
691,2018-7-13,2018,7,13,15,8yhmrl,Researchers of the subreddit what is your thinking process about finding a problem to work to publish a research paper?,https://www.reddit.com/r/MachineLearning/comments/8yhmrl/researchers_of_the_subreddit_what_is_your/,yash_8141,1531463410,[removed],0,1
692,2018-7-13,2018,7,13,16,8yhuuh,97-100% accuracy in binary logistic regression with a single independent categorical predictor,https://www.reddit.com/r/MachineLearning/comments/8yhuuh/97100_accuracy_in_binary_logistic_regression_with/,yungyahoo,1531465883,[removed],0,1
693,2018-7-13,2018,7,13,16,8yhx5s,What would be the basic datasets/tasks to test new RNN architectures?,https://www.reddit.com/r/MachineLearning/comments/8yhx5s/what_would_be_the_basic_datasetstasks_to_test_new/,baustista,1531466656,[removed],0,1
694,2018-7-13,2018,7,13,16,8yi0ac,5 Popular Uses Of Face Recognition,https://www.reddit.com/r/MachineLearning/comments/8yi0ac/5_popular_uses_of_face_recognition/,sytoss,1531467699,,0,1
695,2018-7-13,2018,7,13,17,8yi3wq,My ct st PT0940003+ 2200W  355mm - Cng sut: 2200W - Tc  khng ti: 2280 vng/ pht,https://www.reddit.com/r/MachineLearning/comments/8yi3wq/my_ct_st_pt0940003_2200w_355mm_cng_sut_2200w/,HangNguyen1111,1531468945,,0,1
696,2018-7-13,2018,7,13,17,8yi5ip,Automatic Summarization of Resumes using NER.,https://www.reddit.com/r/MachineLearning/comments/8yi5ip/automatic_summarization_of_resumes_using_ner/,mohi13,1531469493,,0,1
697,2018-7-13,2018,7,13,17,8yi6jj,VAE for Lie groups,https://www.reddit.com/r/MachineLearning/comments/8yi6jj/vae_for_lie_groups/,konasj,1531469839,,0,1
698,2018-7-13,2018,7,13,17,8yiav5,My ct st PT0935505+ 1800W  355mm - in p nh mc: 220-240V - Cng sut: 1800W - Tc  khng ti: 4000 vng/ pht,https://www.reddit.com/r/MachineLearning/comments/8yiav5/my_ct_st_pt0935505_1800w_355mm_in_p_nh/,HangNguyen1111,1531471344,,0,1
699,2018-7-13,2018,7,13,17,8yicph,"[D] I had an idea about using ML to put up "" Smoking Warning "" in videos and Movies.",https://www.reddit.com/r/MachineLearning/comments/8yicph/d_i_had_an_idea_about_using_ml_to_put_up_smoking/,EMP00,1531471989,I am fairly new to ML and i know that this could be done with image ML but how would i render the file back out as a final video,5,0
700,2018-7-13,2018,7,13,18,8yikp5,[D] On solving Montezumas Revenge  Arthur Juliani,https://www.reddit.com/r/MachineLearning/comments/8yikp5/d_on_solving_montezumas_revenge_arthur_juliani/,wei_jok,1531474642,,0,1
701,2018-7-13,2018,7,13,18,8yili5,[D] On solving Montezumas Revenge: Looking beyond the hype of recent Deep RL successes,https://www.reddit.com/r/MachineLearning/comments/8yili5/d_on_solving_montezumas_revenge_looking_beyond/,baylearn,1531474902,,0,1
702,2018-7-13,2018,7,13,18,8yim9w,[News] Machine learning boosts Swiss startups shot at human-powered land speed record,https://www.reddit.com/r/MachineLearning/comments/8yim9w/news_machine_learning_boosts_swiss_startups_shot/,brokenstrawz,1531475160,,0,0
703,2018-7-13,2018,7,13,19,8yiqwq,How to be as good as Oriol Vinyals?,https://www.reddit.com/r/MachineLearning/comments/8yiqwq/how_to_be_as_good_as_oriol_vinyals/,PuzzledForm,1531476634,[removed],0,1
704,2018-7-13,2018,7,13,19,8yir2s,[R] Automating molecule design to speed up drug development,https://www.reddit.com/r/MachineLearning/comments/8yir2s/r_automating_molecule_design_to_speed_up_drug/,jackblun,1531476682,,0,1
705,2018-7-13,2018,7,13,20,8yj6u7,Sorting arrays using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8yj6u7/sorting_arrays_using_deep_learning/,mayank26saxena,1531481518,,0,1
706,2018-7-13,2018,7,13,22,8yk1dg,Natural Language Processing with JavaScript,https://www.reddit.com/r/MachineLearning/comments/8yk1dg/natural_language_processing_with_javascript/,tpiros,1531489081,,0,1
707,2018-7-13,2018,7,13,22,8yk5x9,Question for an implementation of Progressively Growing GANs ?,https://www.reddit.com/r/MachineLearning/comments/8yk5x9/question_for_an_implementation_of_progressively/,UpstairsCurrency,1531490079,[removed],0,1
708,2018-7-13,2018,7,13,23,8yk7d6,[R] A variational autoencoder with Lie groups as latent space,https://www.reddit.com/r/MachineLearning/comments/8yk7d6/r_a_variational_autoencoder_with_lie_groups_as/,konasj,1531490402,,6,47
709,2018-7-13,2018,7,13,23,8yk82x,Deep learning/AI compute rig,https://www.reddit.com/r/MachineLearning/comments/8yk82x/deep_learningai_compute_rig/,BTGhasASICsMiningON,1531490553,[removed],0,1
710,2018-7-13,2018,7,13,23,8yki4o,CNN architecture using multiple previous layers (Probably fairly simple),https://www.reddit.com/r/MachineLearning/comments/8yki4o/cnn_architecture_using_multiple_previous_layers/,kiunthmo,1531492704,"I'm having a problem finding an answer to how to create my desired CNN architecture. I'm still deciding on tensorflow or NN toolkit in matlab, but I can't find the answer I need to either. 

I basically want to create a network in which one layer will combine the outputs of two channels from two previous layers (4 inputs to the node). I'm first applying 2 convolutions to an image, then using sgn on both (though i'll be experimenting with different activation functions as well hopefully), then another layer which takes the outputs of both convolutions AND their respective sgns. The formula of this layer is as follows: (1+sgnC1).C1+(1+sgnC2).C2 where C1 and 

The difficulty I'm having is finding examples which can create layers that use not just the previous layer but also the one before that. 

Any help would be great, thanks.   ",0,1
711,2018-7-13,2018,7,13,23,8ykjsv,Parameter sharing for time series - using level 0 parameters as a prior for level 1 parameters,https://www.reddit.com/r/MachineLearning/comments/8ykjsv/parameter_sharing_for_time_series_using_level_0/,niujin,1531493076,[removed],0,1
712,2018-7-13,2018,7,13,23,8ykjz6,Foundations of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8ykjz6/foundations_of_machine_learning/,j_orshman,1531493117,,0,1
713,2018-7-13,2018,7,13,23,8yknk2,How to do MCMC sampling on the posterior predictive distribution created by Prophet Library (python),https://www.reddit.com/r/MachineLearning/comments/8yknk2/how_to_do_mcmc_sampling_on_the_posterior/,neuroguy6,1531493870,[removed],0,1
714,2018-7-14,2018,7,14,0,8ykppx,[1802.03916] Detecting and Correcting for Label Shift with Black Box Predictors,https://www.reddit.com/r/MachineLearning/comments/8ykppx/180203916_detecting_and_correcting_for_label/,adammathias,1531494297,,5,10
715,2018-7-14,2018,7,14,0,8ykx4r,Devops pipeline for deploying and monitoring machine learning models in Training and production machines,https://www.reddit.com/r/MachineLearning/comments/8ykx4r/devops_pipeline_for_deploying_and_monitoring/,subhrm,1531495826,[removed],0,1
716,2018-7-14,2018,7,14,0,8yl1av,IoT Data Anomaly Detection Using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8yl1av/iot_data_anomaly_detection_using_machine_learning/,svarada,1531496650,[removed],0,1
717,2018-7-14,2018,7,14,0,8yl1r2,Network traffic labeling,https://www.reddit.com/r/MachineLearning/comments/8yl1r2/network_traffic_labeling/,NumberOneOnly,1531496739,[removed],0,1
718,2018-7-14,2018,7,14,1,8yl6pq,OpenAI gym Baselines HER with demonstrations - Using demos to teach complex tasks to robotic manipulators with Reinforcement learning (DDPG),https://www.reddit.com/r/MachineLearning/comments/8yl6pq/openai_gym_baselines_her_with_demonstrations/,rishabhJangir,1531497693,,0,1
719,2018-7-14,2018,7,14,1,8yl9zb,How is the compound attribute of a sentence calculated by NLTK's inbuilt Vader Sentiment Intensity Analyzer?,https://www.reddit.com/r/MachineLearning/comments/8yl9zb/how_is_the_compound_attribute_of_a_sentence/,ThiccShadyy,1531498295,,0,1
720,2018-7-14,2018,7,14,1,8ylewz,[P] Handwriting OCR: Learning to segment lines of handwritten text,https://www.reddit.com/r/MachineLearning/comments/8ylewz/p_handwriting_ocr_learning_to_segment_lines_of/,thomasdlt,1531499232,,0,6
721,2018-7-14,2018,7,14,1,8ylnue,[R] A More General Robust Loss Function,https://www.reddit.com/r/MachineLearning/comments/8ylnue/r_a_more_general_robust_loss_function/,banksyb00mb00m,1531500968,,9,18
722,2018-7-14,2018,7,14,2,8ylpiz,How to scale the machine learning community to 1 Million researchers,https://www.reddit.com/r/MachineLearning/comments/8ylpiz/how_to_scale_the_machine_learning_community_to_1/,mostafabenh,1531501295,,0,1
723,2018-7-14,2018,7,14,2,8ym4o8,Looking for input on my time series cross validation technique in r,https://www.reddit.com/r/MachineLearning/comments/8ym4o8/looking_for_input_on_my_time_series_cross/,lebeer13,1531504165,[removed],0,1
724,2018-7-14,2018,7,14,3,8ym8mx,Tensorflow Node.js Examples,https://www.reddit.com/r/MachineLearning/comments/8ym8mx/tensorflow_nodejs_examples/,loretoparisi,1531504945,,0,1
725,2018-7-14,2018,7,14,3,8yma8g,"[N] Grokking Deep Learning, Something-Something V2, Tensorflow 1.9, NLP ImageNet Moment, Feature-Wise Transformations,",https://www.reddit.com/r/MachineLearning/comments/8yma8g/n_grokking_deep_learning_somethingsomething_v2/,omarsar,1531505247,,0,1
726,2018-7-14,2018,7,14,3,8ymlqz,What master in machine learning to choose,https://www.reddit.com/r/MachineLearning/comments/8ymlqz/what_master_in_machine_learning_to_choose/,mithridatis_,1531507404,[removed],0,1
727,2018-7-14,2018,7,14,4,8ymyou,[P] speedrun - A Tiny Toolkit to Help You Manage Your Machine Learning Research Experiments,https://www.reddit.com/r/MachineLearning/comments/8ymyou/p_speedrun_a_tiny_toolkit_to_help_you_manage_your/,nasimrahaman,1531509936,,1,11
728,2018-7-14,2018,7,14,4,8yn3sq,[P] Creating your own style transfer mirror with Gradient and ml5.js,https://www.reddit.com/r/MachineLearning/comments/8yn3sq/p_creating_your_own_style_transfer_mirror_with/,3tres,1531510988,,0,8
729,2018-7-14,2018,7,14,5,8yngpp,[D] matplotlib/jupyter-matplotlib: Matplotlib Jupyter Extension,https://www.reddit.com/r/MachineLearning/comments/8yngpp/d_matplotlibjupytermatplotlib_matplotlib_jupyter/,_quanttrader_,1531513555,,1,12
730,2018-7-14,2018,7,14,6,8ynups,Debunking one of the most misunderstood concepts in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8ynups/debunking_one_of_the_most_misunderstood_concepts/,V12_Dyno,1531516468,,0,1
731,2018-7-14,2018,7,14,6,8ynxzl,Machine Learning (well) explained,https://www.reddit.com/r/MachineLearning/comments/8ynxzl/machine_learning_well_explained/,julien42,1531517149,,0,1
732,2018-7-14,2018,7,14,6,8yny9g,[R] Debunking one of the most misunderstood concepts in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8yny9g/r_debunking_one_of_the_most_misunderstood/,V12_Dyno,1531517208,,49,117
733,2018-7-14,2018,7,14,9,8yp9hu,Machine Learning Tutorial,https://www.reddit.com/r/MachineLearning/comments/8yp9hu/machine_learning_tutorial/,ekrmh,1531528264,[removed],0,1
734,2018-7-14,2018,7,14,10,8ypj4z,What would be your choice of network configuration to solve the XOR dataset on Tensorflow Playground?,https://www.reddit.com/r/MachineLearning/comments/8ypj4z/what_would_be_your_choice_of_network/,Sau001,1531530730,[removed],0,1
735,2018-7-14,2018,7,14,10,8ypjrr,[D] On Solving Montezuma's Revenge,https://www.reddit.com/r/MachineLearning/comments/8ypjrr/d_on_solving_montezumas_revenge/,circuithunter,1531530906,[removed],0,1
736,2018-7-14,2018,7,14,10,8ypm65,[D] I am writing a beginner's guide to ML/DL. Your feedback is greatly appreciated!,https://www.reddit.com/r/MachineLearning/comments/8ypm65/d_i_am_writing_a_beginners_guide_to_mldl_your/,arkar_aung,1531531564,,0,1
737,2018-7-14,2018,7,14,10,8yppgp,How to set GPU throttling,https://www.reddit.com/r/MachineLearning/comments/8yppgp/how_to_set_gpu_throttling/,SamuelTin,1531532453,"Hell All,

I am running a python Tensorflow model training program. My program will keep printing out the loss value from standard output. I guess every time my GPU temperate reach 70c degree, my program will pause without printing out anything util my GPU cool down to around 50c then my program execution will resume.   


Anyone can kindly advise what GPU parameters I should change to make not keep pausing execution and can run on 90c degree?  


I am using ubuntu 16.04. GPU 1070.

Thank you guys for help

\+-----------------------------------------------------------------------------+

| NVIDIA-SMI 396.37                 Driver Version: 396.37                    |

|-------------------------------+----------------------+----------------------+

| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |

| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |

|===============================+======================+======================|

|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |

| 74&amp;#37;   63C    P2    41W / 220W |   7898MiB /  8118MiB |      0&amp;#37;      Default |

\+-------------------------------+----------------------+----------------------+

\+-----------------------------------------------------------------------------+

| Processes:                                                       GPU Memory |

|  GPU       PID   Type   Process name                             Usage      |

|=============================================================================|

|    0      1421      G   /usr/lib/xorg/Xorg                           169MiB |

|    0      2000      G   /opt/teamviewer/tv\_bin/TeamViewer              3MiB |

|    0      2034      G   compiz                                       112MiB |

|    0     14711      C   python                                      7601MiB |

\+-----------------------------------------------------------------------------+",0,1
738,2018-7-14,2018,7,14,11,8ypwji,What are some recent (2018) and worthy innovations in machine learning that have *nothing* to do with deep learning/neural networks?,https://www.reddit.com/r/MachineLearning/comments/8ypwji/what_are_some_recent_2018_and_worthy_innovations/,blackbearx3,1531534408,[removed],0,1
739,2018-7-14,2018,7,14,11,8yq32j,Black-Box Variational Inference for Stochastic Differential Equations,https://www.reddit.com/r/MachineLearning/comments/8yq32j/blackbox_variational_inference_for_stochastic/,dendisuhubdy,1531536219,,0,1
740,2018-7-14,2018,7,14,13,8yqr43,"I'm 2 years into my cs degree, with how much math is needed for ML should I come back for a degree in math?",https://www.reddit.com/r/MachineLearning/comments/8yqr43/im_2_years_into_my_cs_degree_with_how_much_math/,Trobis,1531542996,[removed],0,1
741,2018-7-14,2018,7,14,13,8yqv5v,A FlapPy Bird game using reinforcement learning. Average score of 70000+. All suggestions are welcome!,https://www.reddit.com/r/MachineLearning/comments/8yqv5v/a_flappy_bird_game_using_reinforcement_learning/,krishamehta,1531544215,,0,1
742,2018-7-14,2018,7,14,14,8yqz8j,[D] What do machine learning practitioners actually do? - Rachel Thomas[fast.ai],https://www.reddit.com/r/MachineLearning/comments/8yqz8j/d_what_do_machine_learning_practitioners_actually/,banksyb00mb00m,1531545466,,1,8
743,2018-7-14,2018,7,14,14,8yr0ot,What Artificial Intelligence Has Taught Us,https://www.reddit.com/r/MachineLearning/comments/8yr0ot/what_artificial_intelligence_has_taught_us/,harshMachineLearning,1531545966,[removed],3,1
744,2018-7-14,2018,7,14,15,8yr9lp,Hierarchical Clustering,https://www.reddit.com/r/MachineLearning/comments/8yr9lp/hierarchical_clustering/,durden8055,1531548927,[removed],0,1
745,2018-7-14,2018,7,14,16,8yrhjq,Convolutional Neural Network,https://www.reddit.com/r/MachineLearning/comments/8yrhjq/convolutional_neural_network/,mozhi_azhagi,1531551774,[removed],0,1
746,2018-7-14,2018,7,14,16,8yri30,ML For Face Detection From CCTV surveillance,https://www.reddit.com/r/MachineLearning/comments/8yri30/ml_for_face_detection_from_cctv_surveillance/,mohi13,1531551965,,0,1
747,2018-7-14,2018,7,14,17,8yrrzl,[P] pocket-tensor: run Keras models from a C++ application on embedded devices,https://www.reddit.com/r/MachineLearning/comments/8yrrzl/p_pockettensor_run_keras_models_from_a_c/,GValiente,1531555675,"Hi!

Lately, I have been working on [pocket-tensor](https://github.com/GValiente/pocket-tensor), a [Kerasify](https://github.com/moof2k/kerasify) fork designed for running sequential networks generated by Keras 2.x on embedded devices.  

It is easy to build and run, since there's no external dependencies. It performs predictions on multiple CPU cores, while keeping RAM usage at a minimum. At last, build times are not too slow, since the library is not header-only.

If you have time please tell me what you think. Thanks!
",23,104
748,2018-7-14,2018,7,14,17,8yrskv,[D] Personal takeaways of ICML 2018 - Day 3,https://www.reddit.com/r/MachineLearning/comments/8yrskv/d_personal_takeaways_of_icml_2018_day_3/,gau_mar,1531555904,,0,3
749,2018-7-14,2018,7,14,17,8yrzj7,Doubts on NIPS internal review process,https://www.reddit.com/r/MachineLearning/comments/8yrzj7/doubts_on_nips_internal_review_process/,amonymousML,1531558673,[removed],0,1
750,2018-7-14,2018,7,14,18,8ys0wd,Why processed data take more training time?,https://www.reddit.com/r/MachineLearning/comments/8ys0wd/why_processed_data_take_more_training_time/,emissary_of_death,1531559185,[removed],0,1
751,2018-7-14,2018,7,14,18,8ys3pa,[D] Doubts on NIPS 2018 internal review process,https://www.reddit.com/r/MachineLearning/comments/8ys3pa/d_doubts_on_nips_2018_internal_review_process/,amonymousML,1531560317,"It's the very first time I submit an article to a NIPS conference and I'm concerned about the following:

 It's said that the first number of submissions is fastly reduced due to different factors. I assume a factor could be not following the style guidelines.

A couple days ago I've noticed there is a style checker, and with it I discovered that a table of mine invades a margin (after correcting it, the style checker will pass). My questions are:

1) If a paper was rejected before review, are the authors notified before the rebuttal time?  Should they be notified by now? 

2) For my mistake, who will be judging the style on my paper, the style checker or a person?

Thank you all! ",0,1
752,2018-7-14,2018,7,14,18,8ys8qs,"Question about gaussian mixtures in ""Elements of Statistical Learning""",https://www.reddit.com/r/MachineLearning/comments/8ys8qs/question_about_gaussian_mixtures_in_elements_of/,renardeins,1531562346,"Hi everyone!Can somebody please explain this section (from the very beginning of  the book):

&gt;Scenario 2:The training data in each class came from a mixture of 10 low-variance Gaussian distributions, with individual means themselves distributed as Gaussian.  
&gt;  
&gt;A mixture of Gaussians is best described in terms of the generative model. One first generates a discrete variable that determines which of  the component Gaussians to use, and then generates an observation from the chosen density.

I don't understand correctly what does it means - is it sum of Gaussians with means generated by another Gaussian, like this Python example:

    import numpy as np
    
    sigma = 0.3 #low as in example
    
    means = np.random.normal(0,1,size=10)
    gmm = []
    for mean in means:
        p_ = np.random.normal(mean,sigma,size=(1000))
        gmm.append(p_)
    
    gmm = np.hstack(gmm).sum(axis=1)
    ",0,1
753,2018-7-14,2018,7,14,19,8ys8zi,"[D] Started a blog on mobile-optimized AI, critiques would be great",https://www.reddit.com/r/MachineLearning/comments/8ys8zi/d_started_a_blog_on_mobileoptimized_ai_critiques/,betelguese_42,1531562432,"I've started a blog on the (surpringly vast) field of efficient neural networks. I'll be covering light-weight model architectures, model compression techniques, and other optimizations in ML libraries; mostly from the perspective of targetting efficient mobile-deployment.

Any critiques and suggestions are welcome

[https://sahnimanas.github.io/2018/06/24/quantization-in-tf-lite.html](https://sahnimanas.github.io/2018/06/24/quantization-in-tf-lite.html)",0,1
754,2018-7-14,2018,7,14,19,8yscwj,[D] Blog on mobile-optimized neural networks,https://www.reddit.com/r/MachineLearning/comments/8yscwj/d_blog_on_mobileoptimized_neural_networks/,betelguese_42,1531563866,"I've started a blog on the (surpringly vast) field of efficient neural networks. 

I'll be covering light-weight model architectures, model compression techniques, and other optimizations in ML libraries; mostly from the perspective of targetting efficient deployment of DNNs.

Any critiques and suggestions are welcome.

[https://sahnimanas.github.io/](https://sahnimanas.github.io/)",8,23
755,2018-7-14,2018,7,14,19,8ysged,The task of recognizing game units and their types in the screenshot,https://www.reddit.com/r/MachineLearning/comments/8ysged/the_task_of_recognizing_game_units_and_their/,Tolsi12,1531565241,[removed],0,1
756,2018-7-14,2018,7,14,21,8ysy43,The Future of Data Capture Systems (1/2): Imitating Human Behavior,https://www.reddit.com/r/MachineLearning/comments/8ysy43/the_future_of_data_capture_systems_12_imitating/,thonic,1531571565,,0,3
757,2018-7-14,2018,7,14,21,8yt2zn, - ,https://www.reddit.com/r/MachineLearning/comments/8yt2zn/_/,Woodworking94,1531573133,,0,1
758,2018-7-14,2018,7,14,22,8ytcfe,[P] repo2docker: Turn git repositories into Jupyter enabled Docker Images,https://www.reddit.com/r/MachineLearning/comments/8ytcfe/p_repo2docker_turn_git_repositories_into_jupyter/,arisbw,1531575782,,1,3
759,2018-7-14,2018,7,14,23,8ythy5,"We haven't invented anything ""NEW"" in the last decade in Neural Networks.",https://www.reddit.com/r/MachineLearning/comments/8ythy5/we_havent_invented_anything_new_in_the_last/,ashish-ji,1531577237,https://twitter.com/ashish_ratn/status/1018111593098276864?s=17,0,1
760,2018-7-14,2018,7,14,23,8ytl7v,[D] Online master's program in ML and/or online master's in CS with specialization in ML?,https://www.reddit.com/r/MachineLearning/comments/8ytl7v/d_online_masters_program_in_ml_andor_online/,Renorei,1531578106,"I have a bachelor's in CS, and am interested in learning machine learning.  It's not realistic at this point for me to physically go to a campus because I work full-time.    

I know there are online CS master's programs where you can specialize in ML, and there might be master's programs in ML itself perhaps.  I can google to find these programs (and I have), but I wanted to see if anyone had experience with any of the available online programs, or if they have heard good things about them from other people.   

Also, career prospects--my assumption would be that career prospects are a bit lower after an online program compared to an in-person program, but that the demand for people with these skills is probably high enough that it wouldn't matter much.  I live in a city that is a tech hub.    


TL/DR  
1. Anybody got any experience with any online ML Master's programs or heard anything good about any of them?

2. Is an online program worthwhile in terms of getting a career boost?    


(FWIW I searched reddit for this information as well but the only similar question was from 3 years ago.)",9,0
761,2018-7-15,2018,7,15,0,8ytvtk,Where can I process Large amounts of data online??,https://www.reddit.com/r/MachineLearning/comments/8ytvtk/where_can_i_process_large_amounts_of_data_online/,tkajbaje,1531580809,[removed],0,1
762,2018-7-15,2018,7,15,2,8yuv82,Uniform Manifold Approximation and Projection (UMAP): A non-linear dimensionality reduction technique claimed to work better than t-SNE,https://www.reddit.com/r/MachineLearning/comments/8yuv82/uniform_manifold_approximation_and_projection/,rhiever,1531589075,,0,1
763,2018-7-15,2018,7,15,4,8yvlzy,[D] Debate about science at organizations like Google Brain/FAIR/DeepMind,https://www.reddit.com/r/MachineLearning/comments/8yvlzy/d_debate_about_science_at_organizations_like/,FirstTimeResearcher,1531595172,"There's an interesting debate going on (unfortunately via Twitter) about science in orgs like Google Brain/FAIR/DeepMind:

https://twitter.com/SimonDeDeo/status/1017616703864307712

Here's the post by the CMU Professor:

&gt; OK: following, my thoughts on Google Brain and similar institutions. Disclaimer: this is my opinion, as someone who doesn't need their funding, and has built a career without needing to flatter them. (An anti-disclaimer, if you will.)

&gt; I grew up in the Bayesian eraI watched @DavidSpergel and his band of merry scientists change our view of the world with a few simple, theoretically-motivated equations.
That's what I brought to the table when I went out to study living and thinking systems. Around 2010, of course, the deep learning revolution became impossible to ignore.

&gt; It was exciting stuff. We'd have people visit the Institute and tell us about decision trees, random forests,all sorts of wonderful things. I tried to get a handle on it but (honestly) there was so much we could do with simple tools that it was never a priority.
When I got to IU, I was hired as a prof in the informatics department, @IUSoICE (informatics==the future of CSi.e., forget quicksort, let's work out what these machines are doing to human life). I was on a hiring committee, and we were keen to get a deep learning hire.

&gt; I took all the candidates out to breakfast (I was a naughty hire, and skipped meetings and committees to spend my time with research students and undergrads, this was the one gap I had).
I tried to work out what deep learning was about. Most of the candidates were too sleep deprived to dissemble. Basic answer: every sexy project we doflying quadcopters, getting another 0.1% on the MNISTis basically one graduate student.
You work out the topology of the neural net. Then you find the weights. How? The answer: ""graduate student descent"", a little pun to giggle over floppy croissants at the student cafein short, there's no good answer, a human being sits there and twiddles things about.

&gt; Machine learning is an amazing accomplishment of engineering. But it's not science. Not even close. It's just 1990, scaled up. It has given us *literally* no more insight than we had twenty years ago.
""Deep learning implements the renormalization group!"" Yeah, I heard that too. If you have a system where information is organized spatially, is it really a surprise that the neurons group information together spatially?
I'd get invited to meetings at Google Research, or wherever. They had security like crazyworse than a hedge fund. A security guard would follow you to the bathroom.
Each scientist at my ""grade""i.e., the equivalent of a junior faculty member, someone who should be out on the edge of knowledgewas, instead, managing a team of ten people doing graduate student descent.
Google can beat University of Kansas for the sole reason that they can hire ten times more graduate students per researcher. The difference, of course, is that a graduate student at UK has the chance to do something intellectually significant. Not true at GR.
They had no idea what they were doing. They had the manpower (word chosen advisedly) to apply deep learning to anything, simulating the Schrodinger equation, drug design, anything. Their main goal was to find the scientific field they could have the maximum impact on.
I've visited probably fifty Universities. I love it. Everywhere I go, I get new ideas. It's one of the best features of my job. There's one exception: commercial ""research"" labs.
If you want to build machines that monitor people and sell them more ads faster, go for it. If you want to find problem where you can take a working-class job, model the man or woman who does it, and build a net to put them out of a job without compensation, be my guest.
Have we done science with something Google Research has built? Absolutely. We have a great paper coming out where we use word2vec to help build a theory of puzzle solving.
But we could have built a system of equal utility ourselves. There's zero intellectual contribution there. I'm not joking, and I'll go head-to-head with anyone who says I am.
I got a nice cold-call from a top-flight Masters' student in CS, as I do sometimes (please keep them coming, I can pay). I flew him out and we started working on a problem in the emergence of social cooperation. He wanted to do DL.
Two weeks in we were a step beyond what Google Brain was doing. I don't mean technicallythey had amazing YouTube videos of sprites in a landscape. I *do* mean intellectually. Their demos were like 2018 meets something out of the 1980s.
They said they did social science, but it was nothing of the sort. It was homo economicus spread out over 50 GPUs. At best, a devastating proof-by-example of need for academia. Buy a copy of Bowles and Ginits, Cooperative Species, and you'll learn more than they did, in a week.
Can you do cool research at Google Brain? Honest answer: no. You will be on the cutting edge of machine learning, yesan engineering discipline whose basic goals are set by large corporations. But you will not be a scientist.
I get that you may need to make money. You can make a lot there, and all the jobs at Renaissance Technology are taken. Go for ityou have all my respect. Academia sucks.
But if you want, at some point in your flourishing career, with your mind and your soul, to join the two-thousand year old parade of intellectual progress, you are not going to do it at Google. Certainly not at Facebook.
If you want to do that, I have a suggestion. It's not the only path, by any means, and I've had amazing fellow-travellers who haven't. But here it is.
Go to graduate school. Do a PhD. With us, here at CMU/SDS, if you likebut we're not the only place that does computational social or cognitive science. You won't get paid much, but you will mentors who legitimately care about the development of your mind.
It's difficult to overestimate the difference between a good PhD program and industry. It is literally shameful, if you're a good PhD advisor, to interfere with the intellectual development of a student. At Google, it's a business plan.
None of this is a joke. This is ten years of experience. Graduate school applications are coming up in the Fall. Think about it. Make sure you're getting a good deal (you shouldn't go into debt for a PhD, and you should get healthcare).
In short: corporate ""research"" is a business proposition. Whatever true intellectual progress comes out of there happens in spite of management. Given how good these companies are at monitoring their employees, that gap is now miniscule.
Last anecdote, then I'm done. We visited Google Research, arranged by a contact. The people were unbelievably smart. We brainstormed all sorts of wonderful things to work on. The last day of the meeting, the academics were like, OK! Let's go to the pub! Let's hash this out!
Their response: this was vacation for us. We're behind on our real work. We have to work this weekend. (Not ""we feel guilty"", but ""we have to"".) For the academics in the room, this *was* work. Suddenly, I realized that this was vacation for them.

Yann LeCun's response:

https://twitter.com/ylecun/status/1018039156939919360

",121,202
764,2018-7-15,2018,7,15,6,8ywj3j,N] Reproducing Japanese Anime Styles With CartoonGAN AI,https://www.reddit.com/r/MachineLearning/comments/8ywj3j/n_reproducing_japanese_anime_styles_with/,trcytony,1531602973,,0,1
765,2018-7-15,2018,7,15,6,8ywpnw,Regarding optimal hyperparameters for a GBDT Model,https://www.reddit.com/r/MachineLearning/comments/8ywpnw/regarding_optimal_hyperparameters_for_a_gbdt_model/,dafaq1112,1531604546,[removed],0,1
766,2018-7-15,2018,7,15,6,8ywqsm,[R] Deep Nets: What have they ever done for Vision?,https://www.reddit.com/r/MachineLearning/comments/8ywqsm/r_deep_nets_what_have_they_ever_done_for_vision/,downtownslim,1531604828,,6,4
767,2018-7-15,2018,7,15,10,8yyac1,Imglab - fast image annotation supports multiple formats,https://www.reddit.com/r/MachineLearning/comments/8yyac1/imglab_fast_image_annotation_supports_multiple/,articlestack,1531619138,,0,1
768,2018-7-15,2018,7,15,12,8yyto4,[D] UMAP Uniform Manifold Approximation and Projection for Dimension Reduction | SciPy 2018 |,https://www.reddit.com/r/MachineLearning/comments/8yyto4/d_umap_uniform_manifold_approximation_and/,_quanttrader_,1531624725,,19,163
769,2018-7-15,2018,7,15,12,8yywo8,"TextWorld: A learning environment for training reinforcement learning agents, inspired by text-based games",https://www.reddit.com/r/MachineLearning/comments/8yywo8/textworld_a_learning_environment_for_training/,tdcsbuilder,1531625611,,0,1
770,2018-7-15,2018,7,15,12,8yz0hy,"[R] TextWorld: A learning environment for training reinforcement learning agents, inspired by text-based games - Microsoft Research",https://www.reddit.com/r/MachineLearning/comments/8yz0hy/r_textworld_a_learning_environment_for_training/,tdcsbuilder,1531626786,,9,52
771,2018-7-15,2018,7,15,14,8yzhde,Made a CNN That Determines if a Pictures is Doge or Not,https://www.reddit.com/r/MachineLearning/comments/8yzhde/made_a_cnn_that_determines_if_a_pictures_is_doge/,sunoconick,1531631935,,0,1
772,2018-7-15,2018,7,15,15,8yzw3j,"[D]Is the essential task of unsupervised learning to take a sample of data, and identify what almost every data point has in common?",https://www.reddit.com/r/MachineLearning/comments/8yzw3j/dis_the_essential_task_of_unsupervised_learning/,CosmicPennyworth,1531637151,"Could you say that this is the *definition* of an unsupervised algorithm? Is there something else, other than what I've defined here, that an algorithm has to do to be unsupervised? Can an algorithm fail to meet this definition and still be an ""unsupervised learning algorithm""?",17,3
773,2018-7-15,2018,7,15,16,8z013l,[R] On solving Montezuma's Revenge - recent (OpenAI+Deepmind) research work,https://www.reddit.com/r/MachineLearning/comments/8z013l/r_on_solving_montezumas_revenge_recent/,vector_machines,1531639000,[removed],0,1
774,2018-7-15,2018,7,15,17,8z085w,#ICML2018 Machine Learning: The Debates,https://www.reddit.com/r/MachineLearning/comments/8z085w/icml2018_machine_learning_the_debates/,jsalsman,1531641899,,0,1
775,2018-7-15,2018,7,15,18,8z0g8m,multilingual word embeddings of translations,https://www.reddit.com/r/MachineLearning/comments/8z0g8m/multilingual_word_embeddings_of_translations/,hiteshn97,1531645242,[removed],1,1
776,2018-7-15,2018,7,15,18,8z0n08,Hypothesis Testing I: Prerequisites,https://www.reddit.com/r/MachineLearning/comments/8z0n08/hypothesis_testing_i_prerequisites/,ajkn1992,1531647955,,0,1
777,2018-7-15,2018,7,15,19,8z0sv3,multi-task learning for binary image classification,https://www.reddit.com/r/MachineLearning/comments/8z0sv3/multitask_learning_for_binary_image_classification/,MYRATH1,1531650164,[removed],0,1
778,2018-7-15,2018,7,15,20,8z14kx,Machine Learning Manager,https://www.reddit.com/r/MachineLearning/comments/8z14kx/machine_learning_manager/,sinjax,1531654578,[removed],0,1
779,2018-7-15,2018,7,15,21,8z19gw,"[D] How a Kalman filter works, in pictures",https://www.reddit.com/r/MachineLearning/comments/8z19gw/d_how_a_kalman_filter_works_in_pictures/,abstractcontrol,1531656288,,50,523
780,2018-7-15,2018,7,15,21,8z1c7f,"Introducing,Onect",https://www.reddit.com/r/MachineLearning/comments/8z1c7f/introducingonect/,lenixlobo,1531657176,[removed],0,1
781,2018-7-15,2018,7,15,21,8z1f4s,Machine Learning Management,https://www.reddit.com/r/MachineLearning/comments/8z1f4s/machine_learning_management/,verybusiness,1531658152,[removed],0,1
782,2018-7-15,2018,7,15,21,8z1fjv,,https://www.reddit.com/r/MachineLearning/comments/8z1fjv//,Woodworking94,1531658292,,0,1
783,2018-7-15,2018,7,15,22,8z1qci,Hypothesis Testing I: Prerequisites,https://www.reddit.com/r/MachineLearning/comments/8z1qci/hypothesis_testing_i_prerequisites/,ajkn1992,1531661556,,0,1
784,2018-7-15,2018,7,15,23,8z23u6,Simon DeDeo's opinion on ML Research. How true is this?,https://www.reddit.com/r/MachineLearning/comments/8z23u6/simon_dedeos_opinion_on_ml_research_how_true_is/,mohit_jarvis29,1531665183,,0,1
785,2018-7-16,2018,7,16,0,8z2byc,Study material for ml,https://www.reddit.com/r/MachineLearning/comments/8z2byc/study_material_for_ml/,shubhhh,1531667237,[removed],0,1
786,2018-7-16,2018,7,16,0,8z2lv5,Video recording of ICML Debates,https://www.reddit.com/r/MachineLearning/comments/8z2lv5/video_recording_of_icml_debates/,pinkflamingo16,1531669761,[removed],0,1
787,2018-7-16,2018,7,16,1,8z2osf,clustering N variable or multidimensional data,https://www.reddit.com/r/MachineLearning/comments/8z2osf/clustering_n_variable_or_multidimensional_data/,sharanbr,1531670425,[removed],0,1
788,2018-7-16,2018,7,16,2,8z357t,[D] Dimensionality Reduction On Mixed Data,https://www.reddit.com/r/MachineLearning/comments/8z357t/d_dimensionality_reduction_on_mixed_data/,Totux,1531674128,[removed],0,1
789,2018-7-16,2018,7,16,2,8z3kb8,Combining convolutional neural networks and recurrent neural networks to achieve accurate music genre classification,https://www.reddit.com/r/MachineLearning/comments/8z3kb8/combining_convolutional_neural_networks_and/,luhbrawn_jahmes,1531677362,,0,1
790,2018-7-16,2018,7,16,2,8z3ksq,TherML: Thermodynamics of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8z3ksq/therml_thermodynamics_of_machine_learning/,tensorflower,1531677461,,9,27
791,2018-7-16,2018,7,16,3,8z3osh,[D] Dimensionality Reduction On Mixed Data,https://www.reddit.com/r/MachineLearning/comments/8z3osh/d_dimensionality_reduction_on_mixed_data/,stambecca,1531678288,"I'm working on a project that sees me dealing with mixed data types (categorical and numerical); while facing a dimensionality reduction problem, I thought about different options:

* MCA on categorical data columns + PCA on numerical data columns combined with principal components detected by means of MCA on categorical data columns;
* PCA on binary encoded categorical data and numerical data columns;
* Factor analysis of mixed data (FAMD) \[Pags 2004\].

In your experience, from a theoretical standpoint, did you find any takeaway while using one of these methods in the described scenario?

Any critiques and further suggestions are welcome.",10,2
792,2018-7-16,2018,7,16,3,8z3qoq,How to build a system to detect if content violates policy?,https://www.reddit.com/r/MachineLearning/comments/8z3qoq/how_to_build_a_system_to_detect_if_content/,jackxpeng,1531678691,[removed],0,1
793,2018-7-16,2018,7,16,3,8z3rab,[D] Best Validation accuracy achieved early on in the training process,https://www.reddit.com/r/MachineLearning/comments/8z3rab/d_best_validation_accuracy_achieved_early_on_in/,arjunsharma97,1531678816,"I am working with time series and exploring two dimensional representations to train them using a CNN. I have used ResNet-50, InceptionResnetV2 and another custom network (consisting of custom residual blocks) so far (in Keras). It's a two class classification problem and I am using binary cross entropy as loss function with sigmoid activation in the last layer containing a single node. The weights for all layers are initialized randomly.

During training, I am saving the best validation accuracy, but surprisingly it always occurs in the first 10 epochs when the network's training accuracy is between 70&amp;#37; and 80&amp;#37;. The best validation is sometimes slightly lesser than the corresponding train acc or slightly more (like in the output below). Here is a sample output for the custom network:

&gt; Batch size: 100, Epochs: 80, Optimizer: RMSprop (lr = 1e-4) 

    Train on 18096 samples, validate on 3037 samples
    Epoch 1/80
    18096/18096 [==============================] - 88s 5ms/step - loss: 0.6931 - acc: 0.6574 - val_loss: 0.6878 - val_acc: 0.5924
    
    Epoch 00001: val_acc improved from -inf to 0.59236, saving model to .checkpoints/weights-bc-rms-msi-01-0.59.hdf5
    Epoch 2/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.6331 - acc: 0.6901 - val_loss: 0.7515 - val_acc: 0.5150
    
    Epoch 00002: val_acc did not improve
    Epoch 3/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.6017 - acc: 0.7031 - val_loss: 0.5292 - val_acc: 0.7600
    
    Epoch 00003: val_acc improved from 0.59236 to 0.75996, saving model to ./checkpoints/weights-bc-rms-msi-03-0.76.hdf5
    Epoch 4/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.5757 - acc: 0.7257 - val_loss: 1.0358 - val_acc: 0.4771
    
    Epoch 00004: val_acc did not improve
    Epoch 5/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.5416 - acc: 0.7445 - val_loss: 0.6376 - val_acc: 0.6638
    
    Epoch 00005: val_acc did not improve
    Epoch 6/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.5114 - acc: 0.7633 - val_loss: 0.5858 - val_acc: 0.7116
    
    Epoch 00006: val_acc did not improve
    Epoch 7/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.4832 - acc: 0.7819 - val_loss: 0.5902 - val_acc: 0.7023
    
    Epoch 00007: val_acc did not improve
    Epoch 8/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.4599 - acc: 0.7950 - val_loss: 0.6082 - val_acc: 0.6918
    
    Epoch 00008: val_acc did not improve
    Epoch 9/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.4314 - acc: 0.8139 - val_loss: 0.6166 - val_acc: 0.6984
    
    Epoch 00009: val_acc did not improve
    Epoch 10/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.4139 - acc: 0.8210 - val_loss: 0.6083 - val_acc: 0.7116
    
    Epoch 00010: val_acc did not improve
    Epoch 11/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.3915 - acc: 0.8333 - val_loss: 0.6815 - val_acc: 0.6898
    
    Epoch 00011: val_acc did not improve
    Epoch 12/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.3706 - acc: 0.8433 - val_loss: 1.1184 - val_acc: 0.5555
    
    Epoch 00012: val_acc did not improve
    Epoch 13/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.3672 - acc: 0.8450 - val_loss: 0.6673 - val_acc: 0.6678
    
    Epoch 00013: val_acc did not improve
    Epoch 14/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.3333 - acc: 0.8636 - val_loss: 0.7352 - val_acc: 0.6997
    
    Epoch 00014: val_acc did not improve
    Epoch 15/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.3310 - acc: 0.8644 - val_loss: 0.8746 - val_acc: 0.6118
    
    Epoch 00015: val_acc did not improve
    Epoch 16/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.3188 - acc: 0.8687 - val_loss: 0.6981 - val_acc: 0.7040
    
    Epoch 00016: val_acc did not improve
    Epoch 17/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.3076 - acc: 0.8764 - val_loss: 0.6983 - val_acc: 0.6964
    
    Epoch 00017: val_acc did not improve
    Epoch 18/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2797 - acc: 0.8876 - val_loss: 0.7346 - val_acc: 0.7053
    
    Epoch 00018: val_acc did not improve
    Epoch 19/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2805 - acc: 0.8867 - val_loss: 0.7565 - val_acc: 0.7089
    
    Epoch 00019: val_acc did not improve
    Epoch 20/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2649 - acc: 0.8930 - val_loss: 1.6109 - val_acc: 0.5393
    
    Epoch 00020: val_acc did not improve
    Epoch 21/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2559 - acc: 0.9000 - val_loss: 1.7837 - val_acc: 0.5100
    
    Epoch 00021: val_acc did not improve
    Epoch 22/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2537 - acc: 0.8979 - val_loss: 0.7572 - val_acc: 0.7066
    
    Epoch 00022: val_acc did not improve
    Epoch 23/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2433 - acc: 0.9063 - val_loss: 1.0345 - val_acc: 0.6016
    
    Epoch 00023: val_acc did not improve
    Epoch 24/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2369 - acc: 0.9083 - val_loss: 0.9925 - val_acc: 0.6450
    
    Epoch 00024: val_acc did not improve
    Epoch 25/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2226 - acc: 0.9125 - val_loss: 2.0245 - val_acc: 0.4988
    
    Epoch 00025: val_acc did not improve
    Epoch 26/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2160 - acc: 0.9161 - val_loss: 0.9964 - val_acc: 0.6780
    
    Epoch 00026: val_acc did not improve
    Epoch 27/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2123 - acc: 0.9161 - val_loss: 1.1838 - val_acc: 0.6082
    
    Epoch 00027: val_acc did not improve
    Epoch 28/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.2043 - acc: 0.9228 - val_loss: 1.2759 - val_acc: 0.5960
    
    Epoch 00028: val_acc did not improve
    Epoch 29/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1952 - acc: 0.9270 - val_loss: 0.8388 - val_acc: 0.6958
    
    Epoch 00029: val_acc did not improve
    Epoch 30/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1964 - acc: 0.9249 - val_loss: 1.8330 - val_acc: 0.5815
    
    Epoch 00030: val_acc did not improve
    Epoch 31/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1922 - acc: 0.9256 - val_loss: 0.9603 - val_acc: 0.6678
    
    Epoch 00031: val_acc did not improve
    Epoch 32/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1874 - acc: 0.9296 - val_loss: 0.8144 - val_acc: 0.7244
    
    Epoch 00032: val_acc did not improve
    Epoch 33/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1794 - acc: 0.9326 - val_loss: 1.2532 - val_acc: 0.6078
    
    Epoch 00033: val_acc did not improve
    Epoch 34/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1758 - acc: 0.9364 - val_loss: 0.9097 - val_acc: 0.6329
    
    Epoch 00034: val_acc did not improve
    Epoch 35/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1673 - acc: 0.9365 - val_loss: 2.5517 - val_acc: 0.5094
    
    Epoch 00035: val_acc did not improve
    Epoch 36/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1725 - acc: 0.9368 - val_loss: 1.9261 - val_acc: 0.5660
    
    Epoch 00036: val_acc did not improve
    Epoch 37/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1622 - acc: 0.9395 - val_loss: 1.0303 - val_acc: 0.6651
    
    Epoch 00037: val_acc did not improve
    Epoch 38/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1570 - acc: 0.9431 - val_loss: 0.9959 - val_acc: 0.6780
    
    Epoch 00038: val_acc did not improve
    Epoch 39/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1519 - acc: 0.9447 - val_loss: 1.7931 - val_acc: 0.6154
    
    Epoch 00039: val_acc did not improve
    Epoch 40/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1532 - acc: 0.9460 - val_loss: 1.1030 - val_acc: 0.6964
    
    Epoch 00040: val_acc did not improve
    Epoch 41/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1507 - acc: 0.9466 - val_loss: 1.5248 - val_acc: 0.5687
    
    Epoch 00041: val_acc did not improve
    Epoch 42/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1437 - acc: 0.9488 - val_loss: 1.7067 - val_acc: 0.5706
    
    Epoch 00042: val_acc did not improve
    Epoch 43/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1407 - acc: 0.9503 - val_loss: 1.2817 - val_acc: 0.6414
    
    Epoch 00043: val_acc did not improve
    Epoch 44/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1442 - acc: 0.9500 - val_loss: 1.1254 - val_acc: 0.6391
    
    Epoch 00044: val_acc did not improve
    Epoch 45/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1335 - acc: 0.9542 - val_loss: 1.0077 - val_acc: 0.6529
    
    Epoch 00045: val_acc did not improve
    Epoch 46/80
    
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1425 - acc: 0.9507 - val_loss: 1.3959 - val_acc: 0.6355
    
    Epoch 00046: val_acc did not improve
    Epoch 47/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1299 - acc: 0.9558 - val_loss: 1.4609 - val_acc: 0.6266
    
    Epoch 00047: val_acc did not improve
    Epoch 48/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1282 - acc: 0.9555 - val_loss: 1.2340 - val_acc: 0.6315
    
    Epoch 00048: val_acc did not improve
    Epoch 49/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1308 - acc: 0.9547 - val_loss: 1.0206 - val_acc: 0.6694
    
    Epoch 00049: val_acc did not improve
    Epoch 50/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1262 - acc: 0.9568 - val_loss: 1.9561 - val_acc: 0.5505
    
    Epoch 00050: val_acc did not improve
    Epoch 51/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1248 - acc: 0.9570 - val_loss: 1.1792 - val_acc: 0.6717
    
    Epoch 00051: val_acc did not improve
    Epoch 52/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1142 - acc: 0.9613 - val_loss: 1.1790 - val_acc: 0.6421
    
    Epoch 00052: val_acc did not improve
    Epoch 53/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1191 - acc: 0.9605 - val_loss: 1.1972 - val_acc: 0.6332
    
    Epoch 00053: val_acc did not improve
    Epoch 54/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1215 - acc: 0.9591 - val_loss: 1.3862 - val_acc: 0.6329
    
    Epoch 00054: val_acc did not improve
    Epoch 55/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1113 - acc: 0.9616 - val_loss: 2.2359 - val_acc: 0.5420
    
    Epoch 00055: val_acc did not improve
    Epoch 56/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1112 - acc: 0.9630 - val_loss: 2.2695 - val_acc: 0.5920
    
    Epoch 00056: val_acc did not improve
    Epoch 57/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1125 - acc: 0.9619 - val_loss: 1.1923 - val_acc: 0.6796
    
    Epoch 00057: val_acc did not improve
    Epoch 58/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1071 - acc: 0.9663 - val_loss: 1.4360 - val_acc: 0.6240
    
    Epoch 00058: val_acc did not improve
    Epoch 59/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1103 - acc: 0.9644 - val_loss: 1.2005 - val_acc: 0.6790
    
    Epoch 00059: val_acc did not improve
    Epoch 60/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1025 - acc: 0.9676 - val_loss: 1.7558 - val_acc: 0.5657
    
    Epoch 00060: val_acc did not improve
    Epoch 61/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1011 - acc: 0.9672 - val_loss: 1.4701 - val_acc: 0.6197
    
    Epoch 00061: val_acc did not improve
    Epoch 62/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.1059 - acc: 0.9655 - val_loss: 1.6352 - val_acc: 0.6072
    
    Epoch 00062: val_acc did not improve
    Epoch 63/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0992 - acc: 0.9682 - val_loss: 1.1573 - val_acc: 0.7069
    
    Epoch 00063: val_acc did not improve
    Epoch 64/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0991 - acc: 0.9687 - val_loss: 1.4538 - val_acc: 0.5854
    
    Epoch 00064: val_acc did not improve
    Epoch 65/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0966 - acc: 0.9694 - val_loss: 1.1501 - val_acc: 0.6958
    
    Epoch 00065: val_acc did not improve
    Epoch 66/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0940 - acc: 0.9700 - val_loss: 1.8419 - val_acc: 0.5825
    
    Epoch 00066: val_acc did not improve
    Epoch 67/80
    18096/18096 [==============================] - 80s 4ms/step - loss: 0.0909 - acc: 0.9707 - val_loss: 1.4666 - val_acc: 0.6984
    
    Epoch 00067: val_acc did not improve
    Epoch 68/80
    18096/18096 [==============================] - 80s 4ms/step - loss: 0.0915 - acc: 0.9712 - val_loss: 1.3062 - val_acc: 0.6783
    
    Epoch 00068: val_acc did not improve
    Epoch 69/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0888 - acc: 0.9723 - val_loss: 3.8147 - val_acc: 0.4992
    
    Epoch 00069: val_acc did not improve
    Epoch 70/80
    18096/18096 [==============================] - 80s 4ms/step - loss: 0.0923 - acc: 0.9717 - val_loss: 1.6840 - val_acc: 0.6572
    
    Epoch 00070: val_acc did not improve
    Epoch 71/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0851 - acc: 0.9735 - val_loss: 1.5529 - val_acc: 0.6543
    
    Epoch 00071: val_acc did not improve
    Epoch 72/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0894 - acc: 0.9719 - val_loss: 2.2659 - val_acc: 0.5400
    
    Epoch 00072: val_acc did not improve
    Epoch 73/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0919 - acc: 0.9735 - val_loss: 1.4676 - val_acc: 0.6115
    
    Epoch 00073: val_acc did not improve
    Epoch 74/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0892 - acc: 0.9724 - val_loss: 1.7677 - val_acc: 0.6342
    
    Epoch 00074: val_acc did not improve
    Epoch 75/80
    18096/18096 [==============================] - 79s 4ms/step - loss: 0.0877 - acc: 0.9726 - val_loss: 2.5043 - val_acc: 0.5578
    
    Epoch 00075: val_acc did not improve
    Epoch 76/80
    18096/18096 [==============================] - 80s 4ms/step - loss: 0.0843 - acc: 0.9738 - val_loss: 1.9680 - val_acc: 0.5673
    
    Epoch 00076: val_acc did not improve
    Epoch 77/80
    18096/18096 [==============================] - 80s 4ms/step - loss: 0.0800 - acc: 0.9756 - val_loss: 1.4121 - val_acc: 0.6888
    
    Epoch 00077: val_acc did not improve
    Epoch 78/80
    18096/18096 [==============================] - 80s 4ms/step - loss: 0.0820 - acc: 0.9751 - val_loss: 1.7393 - val_acc: 0.6572
    
    Epoch 00078: val_acc did not improve
    Epoch 79/80
    18096/18096 [==============================] - 80s 4ms/step - loss: 0.0829 - acc: 0.9744 - val_loss: 1.4969 - val_acc: 0.6602
    
    Epoch 00079: val_acc did not improve
    Epoch 80/80
    18096/18096 [==============================] - 80s 4ms/step - loss: 0.0808 - acc: 0.9755 - val_loss: 1.9161 - val_acc: 0.6154
    
    Epoch 00080: val_acc did not improve
    CPU times: user 4h 57min, sys: 27min 26s, total: 5h 24min 27s
    Wall time: 1h 45min 39s

The test accuracy on the weights of the last epoch (80th epoch) is 61&amp;#37; while the test accuracy on the best val weights is 41.1&amp;#37;. My questions:

1. Is it okay to use weights corresponding to the best validation even if it occurs very early on in the training process? Or is my network under fitting?
2. Any suggestions on how to correct this issue?",7,0
794,2018-7-16,2018,7,16,4,8z451c,Semantic segmentation does not work using floating point values?,https://www.reddit.com/r/MachineLearning/comments/8z451c/semantic_segmentation_does_not_work_using/,zeptomu,1531681765,[removed],0,1
795,2018-7-16,2018,7,16,5,8z4rvn,[D] Understanding neural networks by embedding hidden representations,https://www.reddit.com/r/MachineLearning/comments/8z4rvn/d_understanding_neural_networks_by_embedding/,rchada,1531686710,"Hello, I've quite enjoyed working on [this blog post](https://rakeshchada.github.io/Neural-Embedding-Animation.html) where I explore hidden representations of neural networks in some detail. The idea was to see if it helps understand the performance of neural networks better. I've also built a tool that lets us produce interactive embedding visualizations as shown in the gif. Here's the link to the blog for people interested. Posting here for people interested :)

Link to the article: [https://rakeshchada.github.io/Neural-Embedding-Animation.html](https://rakeshchada.github.io/Neural-Embedding-Animation.html)

[An interactive visualization of word embeddings](https://i.redd.it/uhtd5jmc76a11.gif)",1,49
796,2018-7-16,2018,7,16,6,8z5486,What is the best Machine Learning course online ?,https://www.reddit.com/r/MachineLearning/comments/8z5486/what_is_the_best_machine_learning_course_online/,TDK1902,1531689498,[removed],0,1
797,2018-7-16,2018,7,16,7,8z5kqn,Why PHP is bad choice for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8z5kqn/why_php_is_bad_choice_for_machine_learning/,1f1nas,1531693371,[removed],0,1
798,2018-7-16,2018,7,16,8,8z673s,"[R] TDLS: Connectionist Temporal Classification, Labelling Unsegmented Sequence Data with RNN (https://www.cs.toronto.edu/~graves/icml_2006.pdf)",https://www.reddit.com/r/MachineLearning/comments/8z673s/r_tdls_connectionist_temporal_classification/,machinetrainer,1531698912,,1,1
799,2018-7-16,2018,7,16,9,8z6moo,[R] IGLOO : Slicing the Feature Space to Represent Long Sequences (Not another RNN),https://www.reddit.com/r/MachineLearning/comments/8z6moo/r_igloo_slicing_the_feature_space_to_represent/,redna11,1531702769,"Authors here...Quite a few RNN evolutions have been presented recently (IndRNN, RNN with auxiliary losses, RWA,etc...). We would like to share IGLOO which tackles the issue of LONG sequences without being a RNN. IGLOO uses the relationships between patches sliced out of the feature space using some backbone Conv1D layer.

As the Temporal Convolution Network showed previously, recurrence is not the only approach to the class of sequential tasks.

Highlights:

* Can deal with sequences up to 25,000+ time steps long for benchmarked experiments.
* Works for short sequences too.
* Runs faster than CuDNNRNN for the tasks presented. 
* Keras/tensorflow code is available at: [https://github.com/redna11/igloo1D](https://github.com/redna11/igloo1D) ,so feel free to try it out.

Tuning IGLOO takes some practice like for any neural net which has flexibility to accommodate different tasks, but we have included sample code for simple experiments.

Happy to hear your thoughts.",2,26
800,2018-7-16,2018,7,16,10,8z6vf1,Here is the list of Facebook groups to join for Artificial Intelligence/ Deep Learning/ Machine Learning. Suggest more valuable groups if you know any...,https://www.reddit.com/r/MachineLearning/comments/8z6vf1/here_is_the_list_of_facebook_groups_to_join_for/,asifrazzaq1988,1531704985,[removed],0,1
801,2018-7-16,2018,7,16,11,8z79kp,[D] Are industries that will soon have lots of data the most ripe for ML?,https://www.reddit.com/r/MachineLearning/comments/8z79kp/d_are_industries_that_will_soon_have_lots_of_data/,thatperfectdress,1531708545,"Is it fair to say that industries that generate lots of data have many companies working for them, and industries that will soon have lots of data are the place of opportunity to work in ML?  

This is an oversimplification ignoring the complexities of data collection, quality, and other factors. Curious to hear if this oversimplification works, or if it's something else aside from pure volume of data, that lends itself well to machine learning. 

My thoughts are that content like speech, text, images, and video are produced by everyone and are core to most of our interactions, and as such, are being tackled by all the largest tech companies and many smaller ones. Financial transactions, e-commerce or anything that merges internet plus analytics, and two-sided marketplaces are also generate lots of data and are crucial to the success of the companies that specialize in these. Not well versed in either agriculture or fashion, but those are two industries  I feel may not generate, or process, that much data.",33,7
802,2018-7-16,2018,7,16,12,8z7k1c,Guessing based on Photos,https://www.reddit.com/r/MachineLearning/comments/8z7k1c/guessing_based_on_photos/,pyro226,1531711269,[removed],0,1
803,2018-7-16,2018,7,16,13,8z7ut5,[P] Text Classification Models in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8z7ut5/p_text_classification_models_in_tensorflow/,ganji1055,1531714175,,8,1
804,2018-7-16,2018,7,16,14,8z8bmc,Idea: create an algorithm to detect likely Russian troll reddit accounts.,https://www.reddit.com/r/MachineLearning/comments/8z8bmc/idea_create_an_algorithm_to_detect_likely_russian/,cam_man_can,1531719083,"So I was reading about how the Sec. of Homeland Security recently said there are ongoing attempts to divide Americans using social media, and Im sure Reddit is not exempt from that. Ive seen examples of very divisive posts and comments that seem to be of suspect origin and it pisses me off that there isnt much being done about this. As election season approaches, I fear things could get a lot worse.

Does anyone know how feasible it would be to create an algorithm that detects possible Russian troll accounts based on data from the accounts of known Russian trolls? If its feasible, then Im sure it could be a useful tool to give subreddit mods so they can ban accounts.

[ongoing Russian active measures link](https://apnews.com/2e11aadd40a349cdb020cb6fe25c1e30/US-official:-Russia-using-social-media-to-divide-Americans)

",0,1
805,2018-7-16,2018,7,16,14,8z8evp,"Why We Love Artificial Intelligence Chatbot (And You Should, Too!)",https://www.reddit.com/r/MachineLearning/comments/8z8evp/why_we_love_artificial_intelligence_chatbot_and/,amberstevens311,1531720109,[removed],0,1
806,2018-7-16,2018,7,16,15,8z8la5,https://www.centurysoft.com/blog/apps-to-be-replaced-by-chatbots.html,https://www.reddit.com/r/MachineLearning/comments/8z8la5/httpswwwcenturysoftcomblogappstobereplacedbychatbo/,amberstevens311,1531722169,[removed],0,1
807,2018-7-16,2018,7,16,15,8z8nmi,[D] Academic expert says Google and Facebooks AI researchers arent doing science,https://www.reddit.com/r/MachineLearning/comments/8z8nmi/d_academic_expert_says_google_and_facebooks_ai/,trngreene,1531722980,,23,0
808,2018-7-16,2018,7,16,16,8z8tkz,Chatbots and the Future of Banking,https://www.reddit.com/r/MachineLearning/comments/8z8tkz/chatbots_and_the_future_of_banking/,amberstevens311,1531724915,[removed],0,1
809,2018-7-16,2018,7,16,16,8z8u8b,How you manage reading research papers?,https://www.reddit.com/r/MachineLearning/comments/8z8u8b/how_you_manage_reading_research_papers/,_pragmatic_machine,1531725132,[removed],0,1
810,2018-7-16,2018,7,16,17,8z92rs,"which deep learning framework is used in the industry, other than tensorflow?",https://www.reddit.com/r/MachineLearning/comments/8z92rs/which_deep_learning_framework_is_used_in_the/,hasibzunair,1531728082,[removed],0,1
811,2018-7-16,2018,7,16,17,8z938h,Good summary of ICML 2018?,https://www.reddit.com/r/MachineLearning/comments/8z938h/good_summary_of_icml_2018/,adammathias,1531728242,[removed],0,1
812,2018-7-16,2018,7,16,17,8z9655,The Future of HealthCare is Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8z9655/the_future_of_healthcare_is_artificial/,amberstevens311,1531729227,[removed],0,1
813,2018-7-16,2018,7,16,17,8z97mx,"[R] Math Insights from 10 GAN papers. InfoGANs, VAEGANs, CycleGAN and more",https://www.reddit.com/r/MachineLearning/comments/8z97mx/r_math_insights_from_10_gan_papers_infogans/,jaleyhd,1531729764,,22,191
814,2018-7-16,2018,7,16,17,8z98o3,Machine learning and artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/8z98o3/machine_learning_and_artificial_intelligence/,geetaa89,1531730169,,0,1
815,2018-7-16,2018,7,16,17,8z99cv,AI Weekly 16 July 2018,https://www.reddit.com/r/MachineLearning/comments/8z99cv/ai_weekly_16_july_2018/,TomekB,1531730425,,0,1
816,2018-7-16,2018,7,16,17,8z9abo,[D] Does somebody have some information about OpenAI's Rapid system?,https://www.reddit.com/r/MachineLearning/comments/8z9abo/d_does_somebody_have_some_information_about/,onkelFungus,1531730765,"In one of the [latest blog](https://blog.openai.com/openai-five/) posts they mentioned the Rapid system:

&gt;Our system is implemented as a general-purpose RL training system called Rapid, which can be applied to any Gym environment. Weve used Rapid to solve other problems at OpenAI, including Competitive Self-Play.

I'm looking for some detailed information about this. Any idea?

Cheers",1,12
817,2018-7-16,2018,7,16,17,8z9ari,[R] ICML 2018 Notes,https://www.reddit.com/r/MachineLearning/comments/8z9ari/r_icml_2018_notes/,pdxdabel,1531730915,,8,96
818,2018-7-16,2018,7,16,18,8z9exe,[1807.04911] Want to bring a community together? Create more sub-communities,https://www.reddit.com/r/MachineLearning/comments/8z9exe/180704911_want_to_bring_a_community_together/,ihaphleas,1531732337,,2,15
819,2018-7-16,2018,7,16,18,8z9f3o,[1807.04912] Perceptrons from Memristors,https://www.reddit.com/r/MachineLearning/comments/8z9f3o/180704912_perceptrons_from_memristors/,ihaphleas,1531732400,,1,16
820,2018-7-16,2018,7,16,18,8z9llg,What's a good learning rate schedule when doing only 1 epoch ?,https://www.reddit.com/r/MachineLearning/comments/8z9llg/whats_a_good_learning_rate_schedule_when_doing/,Jean-Porte,1531734600,[removed],0,1
821,2018-7-16,2018,7,16,19,8z9nqf,Neural Attention Pathological Loss Behavior,https://www.reddit.com/r/MachineLearning/comments/8z9nqf/neural_attention_pathological_loss_behavior/,lysecret,1531735300,[removed],0,1
822,2018-7-16,2018,7,16,19,8z9pim,The best podcasts for voice technology and conversational user interfaces,https://www.reddit.com/r/MachineLearning/comments/8z9pim/the_best_podcasts_for_voice_technology_and/,wootnoob,1531735852,,1,1
823,2018-7-16,2018,7,16,19,8z9qaw,How different are we from machines?,https://www.reddit.com/r/MachineLearning/comments/8z9qaw/how_different_are_we_from_machines/,vish_37,1531736098,"Isn't evolution the biggest machine learning event in the history of the world? What can be perceived as thinking could just be advanced computation. Machines learn just as humans. Perhaps more efficiently. Instead of asking whether machines think or not, the more appropriate question to ask would be this: Other than the fact that humans have biological parts, how different are we from machines? ",0,1
824,2018-7-16,2018,7,16,19,8z9ss1,[D] Neural Attention Pathological Loss Behavior,https://www.reddit.com/r/MachineLearning/comments/8z9ss1/d_neural_attention_pathological_loss_behavior/,lysecret,1531736890,"I have been using various Neural Attention Models for a long time now. Transformer like models, Attention Augmented RNNs, CNNs etc. And almost always I have run into the following pathology:

The Training Loss does not meaningfully decrease for the first 5-25 Epochs. Then the model starts training normally. Most of my problems have an imbalanced response too. However, it came to my Attention that this might be a problem of Attention, not the imbalance.

So, I was wondering if you ran into this problem as well? What are some effective strategies for avoiding this problem? For me getting these models to train at all (after the initial phase) is due to problem specific learning rate schedules. One LR schedule that usually works is the one from the Attention is All You Need paper.

Im curious if you have experienced this problem too.",5,7
825,2018-7-16,2018,7,16,19,8z9t8y,Deploying sklearn model specifically on GCP.,https://www.reddit.com/r/MachineLearning/comments/8z9t8y/deploying_sklearn_model_specifically_on_gcp/,vipul115,1531737039,[removed],0,1
826,2018-7-16,2018,7,16,20,8z9zvq,[R] Dimensionality Reduction : Does PCA really improve classification outcome?,https://www.reddit.com/r/MachineLearning/comments/8z9zvq/r_dimensionality_reduction_does_pca_really/,dearpetra,1531739105,,0,1
827,2018-7-16,2018,7,16,20,8za14y,[R] All of Statistics for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8za14y/r_all_of_statistics_for_machine_learning/,digitalson,1531739472,,0,1
828,2018-7-16,2018,7,16,20,8za1yu,[N] Smart office enables a personalized workplace atmosphere,https://www.reddit.com/r/MachineLearning/comments/8za1yu/n_smart_office_enables_a_personalized_workplace/,friscotime,1531739728,,0,1
829,2018-7-16,2018,7,16,20,8za7t7,case ih service manual,https://www.reddit.com/r/MachineLearning/comments/8za7t7/case_ih_service_manual/,Mypremiummanual,1531741416,,0,1
830,2018-7-16,2018,7,16,20,8za85r,Looking for read speed benchmark of dataser formats,https://www.reddit.com/r/MachineLearning/comments/8za85r/looking_for_read_speed_benchmark_of_dataser/,supermario94123,1531741508,[removed],0,1
831,2018-7-16,2018,7,16,21,8zabna,What are the best classification methods for ordinal discrete response variables?,https://www.reddit.com/r/MachineLearning/comments/8zabna/what_are_the_best_classification_methods_for/,MenziesTheHeretic,1531742497,[removed],0,1
832,2018-7-16,2018,7,16,21,8zabvy,Machine learning method for robots to see into the near future,https://www.reddit.com/r/MachineLearning/comments/8zabvy/machine_learning_method_for_robots_to_see_into/,ANNA_Systems,1531742556,,0,2
833,2018-7-16,2018,7,16,21,8zagxx,[R] 3 silver bullets of word embedding in NLP,https://www.reddit.com/r/MachineLearning/comments/8zagxx/r_3_silver_bullets_of_word_embedding_in_nlp/,friscotime,1531743851,,0,1
834,2018-7-16,2018,7,16,21,8zah0v,"A Tiny, Pure Python Implementation of Gradient Boosted Trees",https://www.reddit.com/r/MachineLearning/comments/8zah0v/a_tiny_pure_python_implementation_of_gradient/,lancifollia,1531743868,,0,1
835,2018-7-16,2018,7,16,21,8zaj9d,"TinyGBT: A Tiny, Pure Python implementation of Gradient Boosted Trees",https://www.reddit.com/r/MachineLearning/comments/8zaj9d/tinygbt_a_tiny_pure_python_implementation_of/,lancifollia,1531744468,[removed],0,1
836,2018-7-16,2018,7,16,21,8zakje,one-class SVM,https://www.reddit.com/r/MachineLearning/comments/8zakje/oneclass_svm/,anythinggreen,1531744786,[removed],0,1
837,2018-7-16,2018,7,16,21,8zaoj7,Landmark Computer Chess Game - Leela Chess Self-Learning Neural Network beats Brute Force TCEC World Champion,https://www.reddit.com/r/MachineLearning/comments/8zaoj7/landmark_computer_chess_game_leela_chess/,kingscrusher-youtube,1531745787,"## Hi all, this is a ""Landmark game"" in my view. Leela is running on two Graphics cards vs a Brute force chess engine running on 43 cores. 

Video annotation: [https://www.youtube.com/watch?v=gt5NDPprvHc](https://www.youtube.com/watch?v=gt5NDPprvHc)

There is a fantastic open source Leela chess project, you are all welcome to come along and participate in here:

[http://lczero.org/](http://lczero.org/)

Cheers, K",0,1
838,2018-7-16,2018,7,16,22,8zazws,"[D] How a Kalman filter works, in pictures",https://www.reddit.com/r/MachineLearning/comments/8zazws/d_how_a_kalman_filter_works_in_pictures/,_quanttrader_,1531748479,,6,0
839,2018-7-16,2018,7,16,23,8zbiak,Feed-Forward Neural Network for Dark/Light fonts?,https://www.reddit.com/r/MachineLearning/comments/8zbiak/feedforward_neural_network_for_darklight_fonts/,RacerRex9727,1531752600,[removed],0,1
840,2018-7-17,2018,7,17,0,8zblem,[R] The Fourier Transform through the Lens of Gaussian Process Regression,https://www.reddit.com/r/MachineLearning/comments/8zblem/r_the_fourier_transform_through_the_lens_of/,DanielleMolloy,1531753248,,8,219
841,2018-7-17,2018,7,17,0,8zbte2,"[N] AREL, TextWorld, eCommerce Chatbot, Bloomberg and BAIR AI Courses, Troubling Trends in ML, ICML 2018 Notes, NLP and Law,",https://www.reddit.com/r/MachineLearning/comments/8zbte2/n_arel_textworld_ecommerce_chatbot_bloomberg_and/,omarsar,1531754855,,0,1
842,2018-7-17,2018,7,17,0,8zbus5,Ouchhh media agency presents the worlds biggest AI exhibition,https://www.reddit.com/r/MachineLearning/comments/8zbus5/ouchhh_media_agency_presents_the_worlds_biggest/,AncientEmphasis,1531755140,,0,1
843,2018-7-17,2018,7,17,0,8zbwyf,"Launching a Space Hotel 200 Miles Above Earth at $792,000 Per Night with Frank Bunger of Orion Span",https://www.reddit.com/r/MachineLearning/comments/8zbwyf/launching_a_space_hotel_200_miles_above_earth_at/,The_Syndicate_VC,1531755573,,0,1
844,2018-7-17,2018,7,17,0,8zc2ry,Sequencing the DNA of Real Estate: An AI-Driven Approach for Comparing Assets,https://www.reddit.com/r/MachineLearning/comments/8zc2ry/sequencing_the_dna_of_real_estate_an_aidriven/,_orcaman_,1531756763,,0,1
845,2018-7-17,2018,7,17,1,8zc5jd,[p] TequilaGAN: How to easily identify GAN samples,https://www.reddit.com/r/MachineLearning/comments/8zc5jd/p_tequilagan_how_to_easily_identify_gan_samples/,rafaelvalle,1531757284,"[https://128.84.21.199/pdf/1807.04919.pdf](https://128.84.21.199/pdf/1807.04919.pdf)

In this paper we show strategies to easily identify fake samples generated with the Generative Adversarial Network framework. One strategy is based on the statistical analysis and comparison of raw pixel values and features extracted from them. The other strategy learns formal specifications from the real data and shows that fake samples violate the specifications of the real data. We show that fake samples produced with GANs have a universal signature that can be used to identify fake samples. We provide results on MNIST, CIFAR10, music and speech data.",2,0
846,2018-7-17,2018,7,17,1,8zc8x9,Does R/python automatically use extra compute cores? Specifically on ec2 instances.,https://www.reddit.com/r/MachineLearning/comments/8zc8x9/does_rpython_automatically_use_extra_compute/,po-handz,1531757925,"If I boot up an ec2 instance with 16 vpus and 30gigs RAM and run some pretty standard ML algorithms, will R/python automtically use all vpus?

Or does it use just one of the 16 vpus without addition of multicore packages?",0,1
847,2018-7-17,2018,7,17,1,8zcc8j,[R] Large-Scale Visual Speech Recognition (Google),https://www.reddit.com/r/MachineLearning/comments/8zcc8j/r_largescale_visual_speech_recognition_google/,chris2point0,1531758535,,28,62
848,2018-7-17,2018,7,17,1,8zchzj,Challenges productionizing embedding engines,https://www.reddit.com/r/MachineLearning/comments/8zchzj/challenges_productionizing_embedding_engines/,gagejustins,1531759629,,0,1
849,2018-7-17,2018,7,17,2,8zctup,[1807.05162] Large-Scale Visual Speech Recognition,https://www.reddit.com/r/MachineLearning/comments/8zctup/180705162_largescale_visual_speech_recognition/,zhamisen,1531761839,,3,26
850,2018-7-17,2018,7,17,2,8zd2jb,Metropolitan area in California to become pilot city for automated vehicles,https://www.reddit.com/r/MachineLearning/comments/8zd2jb/metropolitan_area_in_california_to_become_pilot/,dallas1995,1531763411,,1,1
851,2018-7-17,2018,7,17,3,8zd81u,[p] TequilaGAN: How to Identify GAN Samples,https://www.reddit.com/r/MachineLearning/comments/8zd81u/p_tequilagan_how_to_identify_gan_samples/,rafaelvalle,1531764415,"What a great pleasure to collaborate with @WilsonTsai and Anish Doshi from UC Berkeley, my alma mater, on TequilaGAN: How to Identify GAN Samples

[https://arxiv.org/abs/1807.04919](https://arxiv.org/abs/1807.04919)

In this paper we show strategies to easily identify fake samples generated with the Generative Adversarial Network framework. One strategy is based on the statistical analysis and comparison of raw pixel values and features extracted from them. The other strategy learns formal specifications from the real data and shows that fake samples violate the specifications of the real data. We show that fake samples produced with GANs have a universal signature that can be used to identify fake samples. We provide results on MNIST, CIFAR10, music and speech data.",6,14
852,2018-7-17,2018,7,17,3,8zdcfx,A beginner's guide to deriving and implementing backpropagation,https://www.reddit.com/r/MachineLearning/comments/8zdcfx/a_beginners_guide_to_deriving_and_implementing/,prnvb,1531765223,,0,1
853,2018-7-17,2018,7,17,3,8zdg7c,Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8zdg7c/artificial_intelligence/,Rushikesh1999,1531765908,[removed],0,1
854,2018-7-17,2018,7,17,3,8zdjef,New Release of Yellowbrick (Open Source Python Machine Learning Visualization Library),https://www.reddit.com/r/MachineLearning/comments/8zdjef/new_release_of_yellowbrick_open_source_python/,eldraino,1531766502,[removed],0,1
855,2018-7-17,2018,7,17,5,8zenxd,Machine learning on a Macbook Pro,https://www.reddit.com/r/MachineLearning/comments/8zenxd/machine_learning_on_a_macbook_pro/,daredevildas,1531773930,"Has anyone tried training any models on a Macbook Pro(with an i7 processor, no eGPU) using Tensorflow and Pytorch? Is there a huge difference in training times as compared to training those models on computers with a high end Nvidia GPU?",0,1
856,2018-7-17,2018,7,17,5,8zer6f,[D]Machine Learning on a Macbook Pro,https://www.reddit.com/r/MachineLearning/comments/8zer6f/dmachine_learning_on_a_macbook_pro/,daredevildas,1531774543,"Has anyone tried training any models on a Macbook Pro(with an i7 processor, no eGPU) using Tensorflow and Pytorch? Is there a huge difference in training times as compared to training those models on computers with a high end Nvidia GPU?",29,0
857,2018-7-17,2018,7,17,6,8zf4um,Amazon ML now offers interest based recommendation clusters... This is what it showed for a computer mouse.,https://www.reddit.com/r/MachineLearning/comments/8zf4um/amazon_ml_now_offers_interest_based/,ComradeMicha,1531777093,[removed],1,1
858,2018-7-17,2018,7,17,6,8zf8l4,Improving Connectomics by an Order of Magnitude,https://www.reddit.com/r/MachineLearning/comments/8zf8l4/improving_connectomics_by_an_order_of_magnitude/,P4TR10T_TR41T0R,1531777851,,0,1
859,2018-7-17,2018,7,17,7,8zfl85,Should I buy one Titan XP or two 1080 Ti for deep learning tasks?,https://www.reddit.com/r/MachineLearning/comments/8zfl85/should_i_buy_one_titan_xp_or_two_1080_ti_for_deep/,nubol23,1531780494,,0,1
860,2018-7-17,2018,7,17,8,8zfsn4,[N] IJCAI 2018 Kicks Off; DeepMind AlphaGo Wins Marvin Minsky Medal,https://www.reddit.com/r/MachineLearning/comments/8zfsn4/n_ijcai_2018_kicks_off_deepmind_alphago_wins/,gwen0927,1531782098,,0,1
861,2018-7-17,2018,7,17,8,8zfxmy,"[D] Activation function that preserves mean, variance and covariance? (Similar to SELU)",https://www.reddit.com/r/MachineLearning/comments/8zfxmy/d_activation_function_that_preserves_mean/,deltasheep,1531783187,"Given the success of SELUs with standardized data, Im wondering if there is an equivalent for whitened data. I.e. is there an activation function that preserves the mean, the variance and the covariance between each variable? I dont know if itd be useful, but the data I have for my FFNN has very high covariance between a lot of the variables, so I figure whitening could be useful, and maybe preserving it across layers could be too? I think the main advantage of SELUs was that the gradient magnitude remained somewhat constant, so I dont imagine this would be nearly as useful, but Im wondering if anyone has looked into it. ",13,14
862,2018-7-17,2018,7,17,8,8zfzzn,EthicsNet Challenge  How to build a dataset of kind behaviors for AI? $10k prize!,https://www.reddit.com/r/MachineLearning/comments/8zfzzn/ethicsnet_challenge_how_to_build_a_dataset_of/,Pronoia2-4601,1531783700,[removed],0,1
863,2018-7-17,2018,7,17,8,8zg3cq,[D] On Solving Montezumas Revenge: Looking beyond the hype of recent Deep RL successes,https://www.reddit.com/r/MachineLearning/comments/8zg3cq/d_on_solving_montezumas_revenge_looking_beyond/,baylearn,1531784455,,24,59
864,2018-7-17,2018,7,17,9,8zga5r,[R] An Overview of Troubling Trends in Machine Learning Scholarship,https://www.reddit.com/r/MachineLearning/comments/8zga5r/r_an_overview_of_troubling_trends_in_machine/,omarsar,1531786020,,0,1
865,2018-7-17,2018,7,17,9,8zgmeq,Training Machine Learning models on GPU in cloud with Floydhub,https://www.reddit.com/r/MachineLearning/comments/8zgmeq/training_machine_learning_models_on_gpu_in_cloud/,aryancodify,1531788727,,0,1
866,2018-7-17,2018,7,17,11,8zh8sd,Why one-hot output for LSTM in this example?,https://www.reddit.com/r/MachineLearning/comments/8zh8sd/why_onehot_output_for_lstm_in_this_example/,Ozzah,1531794001,"In [this example](http://monik.in/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow/), the output is a one-hot output estimating the number of 1's in the sequence.

Why isn't the output a single number that represents the number of 1's in the sequence, e.g. an output of '15.9972' would be 16 1's?

In a different application of LSTM where I was predicting something continuous-ish, such as a price or a consumption of a resource like gas, in that case I assume I would use a single continuous output rather than one-hot?",0,1
867,2018-7-17,2018,7,17,11,8zh930,[R] TDLS: Flexible Neural Representation for Physics Prediction (https://arxiv.org/abs/1806.08047),https://www.reddit.com/r/MachineLearning/comments/8zh930/r_tdls_flexible_neural_representation_for_physics/,machinetrainer,1531794066,,1,12
868,2018-7-17,2018,7,17,13,8zi0d2,Deploying sklearn model specifically on GCP.,https://www.reddit.com/r/MachineLearning/comments/8zi0d2/deploying_sklearn_model_specifically_on_gcp/,vipul115,1531800792,[removed],0,1
869,2018-7-17,2018,7,17,13,8zi5ru,,https://www.reddit.com/r/MachineLearning/comments/8zi5ru//,Woodworking94,1531802263,,0,1
870,2018-7-17,2018,7,17,13,8zi66z,From shallow to deep learning in fraud  Lyft Engineering,https://www.reddit.com/r/MachineLearning/comments/8zi66z/from_shallow_to_deep_learning_in_fraud_lyft/,mitbal,1531802389,,0,1
871,2018-7-17,2018,7,17,13,8zi84p,Machine Learning Course with Project Development for Beginners,https://www.reddit.com/r/MachineLearning/comments/8zi84p/machine_learning_course_with_project_development/,jayesh1992,1531802922,,0,1
872,2018-7-17,2018,7,17,13,8ziah4,Machine Learning Course with Project Development for Beginners,https://www.reddit.com/r/MachineLearning/comments/8ziah4/machine_learning_course_with_project_development/,jayesh1992,1531803586,,0,1
873,2018-7-17,2018,7,17,15,8zio67,Automatic Cellophane Film Packing Machine For Sale sherry@machinehall.com,https://www.reddit.com/r/MachineLearning/comments/8zio67/automatic_cellophane_film_packing_machine_for/,liusherry,1531807649,,0,1
874,2018-7-17,2018,7,17,17,8zjbfc,any evidence of error functions and backprop neural wiring in the brain ?,https://www.reddit.com/r/MachineLearning/comments/8zjbfc/any_evidence_of_error_functions_and_backprop/,anterak13,1531815190,"just wondering if there are any neuro-bio papers discussing this parallel between deepNN and actual brains. If the brain even remotely works like a software deepNN and can learn as in RL, there could be two nets superimposed, the functional circuitry, and then the learning circuitry, estimating error and firing back signals to train the functional circuitry ?",0,1
875,2018-7-17,2018,7,17,17,8zjdc4,Sources about differences in scaling techniques ?,https://www.reddit.com/r/MachineLearning/comments/8zjdc4/sources_about_differences_in_scaling_techniques/,muchdoughe,1531815869,[removed],0,1
876,2018-7-17,2018,7,17,18,8zjl5g,HN discussion of: Perceptrons from memristors,https://www.reddit.com/r/MachineLearning/comments/8zjl5g/hn_discussion_of_perceptrons_from_memristors/,eleitl,1531818639,,0,1
877,2018-7-17,2018,7,17,18,8zjnuu,[R] A new theory to analyze neural manifolds in high-dimensional data: Classification and Geometry of General Perceptual Manifolds,https://www.reddit.com/r/MachineLearning/comments/8zjnuu/r_a_new_theory_to_analyze_neural_manifolds_in/,jakn,1531819544,,19,153
878,2018-7-17,2018,7,17,18,8zjroe,Tensorflow Vs Keras?,https://www.reddit.com/r/MachineLearning/comments/8zjroe/tensorflow_vs_keras/,mohi13,1531820846,,0,1
879,2018-7-17,2018,7,17,19,8zk178,[Tutorial] Getting Started with TensorFlow | SciPy 2018 Tutorial by Josh Gordon,https://www.reddit.com/r/MachineLearning/comments/8zk178/tutorial_getting_started_with_tensorflow_scipy/,theainerd,1531823820,,0,2
880,2018-7-17,2018,7,17,19,8zk22n,Looking for dataset label review tool,https://www.reddit.com/r/MachineLearning/comments/8zk22n/looking_for_dataset_label_review_tool/,dustin_jsa,1531824081,[removed],0,1
881,2018-7-17,2018,7,17,19,8zk3x3,Recsys Dataset Download,https://www.reddit.com/r/MachineLearning/comments/8zk3x3/recsys_dataset_download/,darcwader,1531824628,[removed],0,1
882,2018-7-17,2018,7,17,19,8zk4xc,seq2seq in tensorflow.js,https://www.reddit.com/r/MachineLearning/comments/8zk4xc/seq2seq_in_tensorflowjs/,LightBlueParadox,1531824934,[removed],0,1
883,2018-7-17,2018,7,17,20,8zk673,SWIPE - Presentation @ IBM Blockchain Codecamp (22 June 2018),https://www.reddit.com/r/MachineLearning/comments/8zk673/swipe_presentation_ibm_blockchain_codecamp_22/,funtens,1531825322,,0,1
884,2018-7-17,2018,7,17,20,8zk78e,[R] K-Means Clustering: All You Need to Know,https://www.reddit.com/r/MachineLearning/comments/8zk78e/r_kmeans_clustering_all_you_need_to_know/,dearpetra,1531825618,,0,1
885,2018-7-17,2018,7,17,20,8zkbcm,[R] Clustering on mixed type data,https://www.reddit.com/r/MachineLearning/comments/8zkbcm/r_clustering_on_mixed_type_data/,magneticono,1531826855,,0,1
886,2018-7-17,2018,7,17,20,8zkcvv,A tensorflow.js implementation of MTCNN (Multitask Cascaded ConvNet) for realtime face detection,https://www.reddit.com/r/MachineLearning/comments/8zkcvv/a_tensorflowjs_implementation_of_mtcnn_multitask/,justadudewhohacks,1531827291,[removed],0,1
887,2018-7-17,2018,7,17,20,8zkeca,Digital Workplaces: Trends Shaping the Future of Work,https://www.reddit.com/r/MachineLearning/comments/8zkeca/digital_workplaces_trends_shaping_the_future_of/,dallas1995,1531827737,,1,1
888,2018-7-17,2018,7,17,20,8zkgmr,GitHub - mayank26saxena/portrait-mode: Implementing Portrait Mode Effect using Neural Networks.,https://www.reddit.com/r/MachineLearning/comments/8zkgmr/github_mayank26saxenaportraitmode_implementing/,mayank26saxena,1531828368,,0,1
889,2018-7-17,2018,7,17,21,8zkiyb,[R] Using Siamese Networks and Pre-Trained Convolutional Neural Networks (CNNs) for Fashion Similarity Matching,https://www.reddit.com/r/MachineLearning/comments/8zkiyb/r_using_siamese_networks_and_pretrained/,molode,1531828981,,0,1
890,2018-7-17,2018,7,17,21,8zkjwb,[D] Is there a simpler explanation of the K-FAC tri-diagonal block approximation?,https://www.reddit.com/r/MachineLearning/comments/8zkjwb/d_is_there_a_simpler_explanation_of_the_kfac/,abstractcontrol,1531829214,"I have a decent grasp of the block diagonal K-FAC update, and I even understand how to derive it from the PRONG update, but the tri-diagonal K-FAC update is beyond my understanding.

Why are graphical models used in the context of NN in order to derive the update? What is the dependent covariance? What are the exact steps in the paper taken to derive the updates? What would the explicit whitening in the style of PRONG look like as a part of a NN architecture for the tri-diagonal approximation? There are probably more question after this, but I will have to get through these until I can find them.",11,7
891,2018-7-17,2018,7,17,21,8zkjy1,Best Articles in AI published in June selected by Sicara,https://www.reddit.com/r/MachineLearning/comments/8zkjy1/best_articles_in_ai_published_in_june_selected_by/,stolbiq,1531829228,[removed],0,1
892,2018-7-17,2018,7,17,21,8zkm91,[D] Conditional LM with a huge dataset used for QA with structured output,https://www.reddit.com/r/MachineLearning/comments/8zkm91/d_conditional_lm_with_a_huge_dataset_used_for_qa/,HigherTopoi,1531829799,"Fine-tuning a LM pre-trained on 1BLM performed well on QA and other NLP tasks. Why don't we construct a gigantic text dataset taken from novels, textbooks, news, webpages and conversation, so that a LM trained on this dataset can output a structured output (e.g. multiple sentences) conditioned on input sentences? Note that we don't do fine-tuning here; we train the model on one giant dataset (not Seq2Seq, just LM), and that's it. 1BLM has no inter-sentence dependency, yet here each sample of minibatch is a randomly sampled consecutive multiple sentences. It doesn't only do QA but also give an appropriate output according to the input task. The samples are noisy, and the samples with question and answer format may be much smaller than the entire dataset. However, I believe the large size of the dataset would generalize nicely to resolve them. Any feedback?",0,1
893,2018-7-17,2018,7,17,21,8zkn86,[R] Understanding the Role of Big Data in the Lending Industry,https://www.reddit.com/r/MachineLearning/comments/8zkn86/r_understanding_the_role_of_big_data_in_the/,janemoz,1531830040,,0,1
894,2018-7-17,2018,7,17,21,8zkrmq,Best Articles in AI published in June picked by Sicara team,https://www.reddit.com/r/MachineLearning/comments/8zkrmq/best_articles_in_ai_published_in_june_picked_by/,stolbiq,1531831128,,0,1
895,2018-7-17,2018,7,17,21,8zkwah,Machine Learning Explained - What it is and How does it Work,https://www.reddit.com/r/MachineLearning/comments/8zkwah/machine_learning_explained_what_it_is_and_how/,intelegain_inc,1531832265,,0,1
896,2018-7-17,2018,7,17,22,8zl5pc,Style Transfer In Node.js,https://www.reddit.com/r/MachineLearning/comments/8zl5pc/style_transfer_in_nodejs/,qqqppp9998,1531834415,,0,1
897,2018-7-17,2018,7,17,23,8zlevt,[D] Collection: Professional Applications and Ideas of ML/AI in security/pen-test/exploit/...,https://www.reddit.com/r/MachineLearning/comments/8zlevt/d_collection_professional_applications_and_ideas/,krashennikov,1531836408,"I want to **collect and exchange practical applications of ML/AI** in the field of **security/pen-test/exploit/... and related fields**.

In general, Research Papers could be also of interest, but the **Focus** should stay on:

* Articles
* Repositories
* Tools
* Own Experience
* Ideas/ Brainstorming
* Research Papers
* Misc.

with **Practical Use** and **Professional Applications**.

Of big **Relevance** are also:

* Datasets
* Environments (e.g. for RL)

and also the use of generated Data in that field (like labeling problems etc.), since human expertise and background knowledge for interpretation is often necessary.",4,4
898,2018-7-17,2018,7,17,23,8zlf3i,[D] What are the best ways to handle classification when the features are images?,https://www.reddit.com/r/MachineLearning/comments/8zlf3i/d_what_are_the_best_ways_to_handle_classification/,Alt_For_Shitposting,1531836458,"For example: I have a dataset composed of thousands of patients. For each patient, I have several bodyscan images. I would like to classify each patient as either having or not having a tumor. The number of body scans for each patient is not consistent.",0,2
899,2018-7-17,2018,7,17,23,8zliqe,"Data Science in 30 Minutes: The Accidental Data Scientist with Katrina Riehl, Director of Data Science for HomeAway.com",https://www.reddit.com/r/MachineLearning/comments/8zliqe/data_science_in_30_minutes_the_accidental_data/,redditman09876543,1531837202,,0,1
900,2018-7-17,2018,7,17,23,8zlj0w,"[D] What tools are used in practice to schedule training jobs, annotate datasets, keep track of past experiments... ?",https://www.reddit.com/r/MachineLearning/comments/8zlj0w/d_what_tools_are_used_in_practice_to_schedule/,Valiox,1531837262,"I've previously posted a [similar question](https://www.reddit.com/r/learnmachinelearning/comments/8xa4pa/setups_for_working_with_a_remote_dedicated_server/) in /r/learnmachinelearning. One user suggested slurm, but I wish for a more ML-oriented tool.

I'm surprised this isn't a bigger topic in machine learning; I have a hard time imagining myself opening a command line and run a python script with the correct arguments every time I need to train a neuralnet. Organizing models and datasets as well as keeping track of every experiment done is critical in practice and I don't see myself doing it without some kind of framework. Yet I rarely hear of such tools around here. Am I mistaken thinking they are necessary or is there any that already does what I described and I've simply missed it?",30,59
901,2018-7-17,2018,7,17,23,8zlmht,[R] Improving Connectomics by an Order of Magnitude,https://www.reddit.com/r/MachineLearning/comments/8zlmht/r_improving_connectomics_by_an_order_of_magnitude/,rasmii,1531837985,,1,21
902,2018-7-17,2018,7,17,23,8zlopo,Machine Learning Survey - India,https://www.reddit.com/r/MachineLearning/comments/8zlopo/machine_learning_survey_india/,planck221,1531838454,[removed],0,1
903,2018-7-18,2018,7,18,0,8zlwjn,I am thinking about my bachelor's thesis and want your suggestion and oppinions,https://www.reddit.com/r/MachineLearning/comments/8zlwjn/i_am_thinking_about_my_bachelors_thesis_and_want/,komat,1531840014,[removed],0,1
904,2018-7-18,2018,7,18,0,8zlwx8,"Tobacco Products, Abstract Art and General Adversarial Networks - Remote Coder",https://www.reddit.com/r/MachineLearning/comments/8zlwx8/tobacco_products_abstract_art_and_general/,RemoteCoder,1531840086,,0,1
905,2018-7-18,2018,7,18,0,8zm3o5,Convert your voice to text,https://www.reddit.com/r/MachineLearning/comments/8zm3o5/convert_your_voice_to_text/,balavenkatesh123,1531841389,[removed],0,1
906,2018-7-18,2018,7,18,0,8zm4kl,[D] Lawsuit alleges fabricated results at Pinscreen led by Hao Li,https://www.reddit.com/r/MachineLearning/comments/8zm4kl/d_lawsuit_alleges_fabricated_results_at_pinscreen/,Fireflite,1531841563,"The filing can be found [here](http://sadeghi.com/Dr-Iman-Sadeghi-v-Pinscreen-Inc-et-al.pdf).

These are very serious allegations: generated models results were blatantly fabricated for academic papers as well as public demonstrations. In addition, there's some pretty awful allegations of worker abuse, including an attack on the plaintiff when they attempted to confront Li about the academic misconduct.",68,215
907,2018-7-18,2018,7,18,1,8zmijj,[D] Whats new in each version  seaborn 0.9.0 documentation,https://www.reddit.com/r/MachineLearning/comments/8zmijj/d_whats_new_in_each_version_seaborn_090/,_quanttrader_,1531844207,,0,2
908,2018-7-18,2018,7,18,1,8zmpcr,Predicting excavation damages,https://www.reddit.com/r/MachineLearning/comments/8zmpcr/predicting_excavation_damages/,esghili,1531845516,"Hello everyone,

I have an excelsheet that has records of all excavation damages to gas pipelines in half of state of Washington. It shows each day, which location have been damamged by which contractor( not everyday this happens)

I am trying to add some features to that excelsheets such as rain amount and weather condition and based on that predcict where will be the next damage in future( for probably next 2 months using the weather forecast)

Considering the fact that I only have the data for when the excavation damage has happened, do you think it would be poissible for me to predict the future?I asked my cousin who is a machine learning engineer and she said the model will be very biased as we only have the data for when and where it happened and not for when it didnt happen.

I was thinking to build a database with the GIS software that has all the locations in our territory and then add the excavation data to that database in oorder to be able to build a model.

I have no background in machine learing so I would be really happy if you could answer my question

I attach an image to this post

Thank you very much",0,0
909,2018-7-18,2018,7,18,1,8zmq14,How Amazon Has Re-Organized Around Artificial Intelligence And Machine Lerning,https://www.reddit.com/r/MachineLearning/comments/8zmq14/how_amazon_has_reorganized_around_artificial/,backcountryusa,1531845644,,1,1
910,2018-7-18,2018,7,18,2,8zn4fl,[P] Reproducible machine learning with PyTorch and Quilt,https://www.reddit.com/r/MachineLearning/comments/8zn4fl/p_reproducible_machine_learning_with_pytorch_and/,brightpixels,1531848323,,1,10
911,2018-7-18,2018,7,18,2,8zncu7,Anybody know of an existing repo?,https://www.reddit.com/r/MachineLearning/comments/8zncu7/anybody_know_of_an_existing_repo/,aequilibritas,1531849852,,0,1
912,2018-7-18,2018,7,18,2,8zndlz,How to use different time series dataset to predict best class?,https://www.reddit.com/r/MachineLearning/comments/8zndlz/how_to_use_different_time_series_dataset_to/,nile6499,1531850001,"I have 3 different dataset. !st is page ranking, 2nd is page, and 3rd is reach. I need to use all three dataset to predict the best website at the given day. Please suggest any way to model the following dataset. Thanks

https://i.redd.it/c3klin1jqja11.png",0,1
913,2018-7-18,2018,7,18,3,8znp92,"Toy dataset for deep learning (planar manipulation task, available as .avi and .tfrecord)",https://www.reddit.com/r/MachineLearning/comments/8znp92/toy_dataset_for_deep_learning_planar_manipulation/,whiletrue2,1531852095,,0,1
914,2018-7-18,2018,7,18,3,8znpc3,Machine Learning for fair decisions,https://www.reddit.com/r/MachineLearning/comments/8znpc3/machine_learning_for_fair_decisions/,myinnerbanjo,1531852108,,0,1
915,2018-7-18,2018,7,18,3,8zntjp,How to create a Language Model for source code prediction(Machine Learning/NLP)?,https://www.reddit.com/r/MachineLearning/comments/8zntjp/how_to_create_a_language_model_for_source_code/,DimZar,1531852870,[removed],0,1
916,2018-7-18,2018,7,18,4,8zo5sq,"[N] Jessica Hodgins, Abhinav Gupta, Andrea Vedaldi, and Jitendra Malik join Facebook",https://www.reddit.com/r/MachineLearning/comments/8zo5sq/n_jessica_hodgins_abhinav_gupta_andrea_vedaldi/,downtownslim,1531855104,,1,4
917,2018-7-18,2018,7,18,4,8zo8hr,[P] Husband Builds Wife ML Baby-Namer Tool When Couple Can't Agree on a Name,https://www.reddit.com/r/MachineLearning/comments/8zo8hr/p_husband_builds_wife_ml_babynamer_tool_when/,data_crunch,1531855607,,0,1
918,2018-7-18,2018,7,18,4,8zobe9,[P] How GOAT Taught a Machine to Love Sneakers,https://www.reddit.com/r/MachineLearning/comments/8zobe9/p_how_goat_taught_a_machine_to_love_sneakers/,cupnoodles,1531856147,,0,1
919,2018-7-18,2018,7,18,4,8zogwe,[D] Suggestions for Readings on ML/DS in Finance,https://www.reddit.com/r/MachineLearning/comments/8zogwe/d_suggestions_for_readings_on_mlds_in_finance/,Nater5000,1531857160,"Greetings r/MachineLearning,

I'm starting my master's in Comp Sci focusing in AI, and I'm trying to explore the possibility of going into an industry like finance once I've completed it.  I've been interested in finance since High School, and now that I'm looking down the barrel of finishing my schooling, I want to really start focusing on it as a career.

So does anyone have any suggested resources to learn about the cross-section of finance and data science/machine learning?  It's surprisingly not very plentiful (at least as far as I can tell), but I know it can play a role in investing/trading (although I'm interested to see how else it has been used).

Any books, articles, people, etc. that I can look into that discuss the state of the industry and how machine learning is involved would be great (versus more technical dealings, but I'd be interested in any of that as well).

Thanks!",9,4
920,2018-7-18,2018,7,18,5,8zok3s,[R] Geometric Deep Learning Autonomously Learns Chemical Features That Outperform Those Engineered by Domain Experts,https://www.reddit.com/r/MachineLearning/comments/8zok3s/r_geometric_deep_learning_autonomously_learns/,phopstar,1531857745,,10,19
921,2018-7-18,2018,7,18,5,8zore6,[D] What is the best way of publishing code to make it easily reproducable?,https://www.reddit.com/r/MachineLearning/comments/8zore6/d_what_is_the_best_way_of_publishing_code_to_make/,delaflor,1531859149,"I am about to publish some work I have done and I cane across the problem of making my experiments reproducable. Inspired by the recent discussion on experiment management software, I wonder if there has anybody a suggestion. Here is what I got so far:

-	I use sacred to organize my experiments, so all hyperparameters and measurements exist in a structured database
-	I have jupyter notebooks which load data from the database and produce plots and qualitative examples
-	My methods are implemented with tensorflow.

Now something you see more and more often is people who publish their code and experiment scripts on github. This is fine. However, it usually requires people to install their whole software stack and often the scripts also assume a given folder structure. This can be quite tedious and as documentation on scientific code is not the best, it is usually quite a lot of work to play around with these published methods.
Additionally providing jupyter notebooks does not really help, except for maybe a bit more transparent interface than bash scripts.

I considered now google colab, which is basically a notebook run in a browser, but I am uncertain how this would work with the loading of datasets (which are published by different people and usually require people so sign a license before usage). Also, it feels rather closed-down to use google infrastructure as supplementary material of a paper.

How do other people deal with this problem?",16,7
922,2018-7-18,2018,7,18,5,8zot35,[N] AutoGraph converts Python into TensorFlow graphs,https://www.reddit.com/r/MachineLearning/comments/8zot35/n_autograph_converts_python_into_tensorflow_graphs/,phoenixinter,1531859478,[removed],0,1
923,2018-7-18,2018,7,18,6,8zp3uf,[R] Block Mean Approximation for Efficient Second Order Optimization,https://www.reddit.com/r/MachineLearning/comments/8zp3uf/r_block_mean_approximation_for_efficient_second/,yaolubrain,1531861542,,1,4
924,2018-7-18,2018,7,18,6,8zp4is,[D] AutoGraph converts Python into TensorFlow graphs  TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8zp4is/d_autograph_converts_python_into_tensorflow/,sksq9,1531861666,,0,1
925,2018-7-18,2018,7,18,6,8zp567,Machine Learning Managed Services: Can Big Tech Provide Alternatives to IIoT Predictive Maintenance Software,https://www.reddit.com/r/MachineLearning/comments/8zp567/machine_learning_managed_services_can_big_tech/,antondziatkovskii,1531861799,,0,1
926,2018-7-18,2018,7,18,6,8zp7n6,Publishing research without PhD,https://www.reddit.com/r/MachineLearning/comments/8zp7n6/publishing_research_without_phd/,TotalWarStrategist,1531862269,[removed],0,1
927,2018-7-18,2018,7,18,6,8zp9xo,[N] Introducing AutoGraph Beta,https://www.reddit.com/r/MachineLearning/comments/8zp9xo/n_introducing_autograph_beta/,zacharynado,1531862731,,0,3
928,2018-7-18,2018,7,18,6,8zpb4g,First in the world to extract Hours of Operation from any website,https://www.reddit.com/r/MachineLearning/comments/8zpb4g/first_in_the_world_to_extract_hours_of_operation/,sabincek,1531862987,,0,1
929,2018-7-18,2018,7,18,6,8zph9r,New Release of Yellowbrick (Open Source Python Machine Learning Visualization Library),https://www.reddit.com/r/MachineLearning/comments/8zph9r/new_release_of_yellowbrick_open_source_python/,eldraino,1531864271,,1,2
930,2018-7-18,2018,7,18,7,8zpqgz,"A lot of sports teams have analytics departments. At a certain point won't these analytics departments get so good at gathering insights about the game from data alone that any insight that, say, an umpire or referee might have would be slower than the analytical department's insight?",https://www.reddit.com/r/MachineLearning/comments/8zpqgz/a_lot_of_sports_teams_have_analytics_departments/,Stone_d_,1531866303,[removed],0,1
931,2018-7-18,2018,7,18,7,8zprn7,"Toy dataset for deep learning (simple objects approaching and covering one another, available as .avi and .tfrecord)",https://www.reddit.com/r/MachineLearning/comments/8zprn7/toy_dataset_for_deep_learning_simple_objects/,whiletrue2,1531866538,,0,1
932,2018-7-18,2018,7,18,7,8zps0k,[N] IJCAI 2018 Kicks Off; DeepMind AlphaGo Wins Marvin Minsky Medal,https://www.reddit.com/r/MachineLearning/comments/8zps0k/n_ijcai_2018_kicks_off_deepmind_alphago_wins/,trcytony,1531866617,,0,1
933,2018-7-18,2018,7,18,7,8zpsnd,AutoGraph converts Python into TensorFlow graphs,https://www.reddit.com/r/MachineLearning/comments/8zpsnd/autograph_converts_python_into_tensorflow_graphs/,alextp,1531866751,,1,2
934,2018-7-18,2018,7,18,7,8zpxz8,[D] Does introspection play a role in the way you choose/design a model architecture?,https://www.reddit.com/r/MachineLearning/comments/8zpxz8/d_does_introspection_play_a_role_in_the_way_you/,CosmicPennyworth,1531867828,Is the way your algorithms think inspired by the way you think?,2,1
935,2018-7-18,2018,7,18,8,8zq0k7,The Latest in Theoretical Understanding of Dropout and its Variants,https://www.reddit.com/r/MachineLearning/comments/8zq0k7/the_latest_in_theoretical_understanding_of/,mtahab,1531868403,[removed],0,1
936,2018-7-18,2018,7,18,8,8zqbji,[R] How should architecture/hyperparameters of a model change with more data?,https://www.reddit.com/r/MachineLearning/comments/8zqbji/r_how_should_architecturehyperparameters_of_a/,xiguas,1531870832,"I have a CNN that achieved ~93% accuracy on a dataset of about 24k images total (80% of which is used for training). Now, I have about 80k images. However, when I trained the same model with the increased amount of data, the accuracy dropped to ~92%. 

Is there some sort of guideline or general rule of thumb for changing the architecture or hyperparameters of a model once you acquire more data (e.g., increase batch size for sgd)? I'm at a loss on how the accuracy went down. I appreciate any advice, I'm still fairly new to machine learning. Thanks!",7,4
937,2018-7-18,2018,7,18,8,8zqcm0,Build an image classifier in 7 minutes with Kernels on Kaggle,https://www.reddit.com/r/MachineLearning/comments/8zqcm0/build_an_image_classifier_in_7_minutes_with/,ptimothymooney,1531871064,,0,1
938,2018-7-18,2018,7,18,9,8zqmxe,[D] Suggestion for ML classification model,https://www.reddit.com/r/MachineLearning/comments/8zqmxe/d_suggestion_for_ml_classification_model/,Devilsta,1531873360,"Hello


I'm trying to do some classification with Machine Learning and this is my first time working with ML on a small project.

I have a large set of data in the form of logcats that are generated from an application. Each log has function calls and error messages and debug messages and can be classified into one of eight different classes. The application has a hardware, software, firmware etc etc etc side to it and these are the groups. I need to find error messages and classify them into these groups so that its easier to analyze and debug.

Suppose I have over 100k logs, how do I sort the logs into one of the 8 classes?


So far I have looked into scikit learn and their decision trees and random forest libraries but am unable to decide which is the easiest way to achieve this. In the end, even a 50% accuracy is a big win for me.


Thanks",1,1
939,2018-7-18,2018,7,18,9,8zqq6u,[D] Best network for image inpainting for a very flat image,https://www.reddit.com/r/MachineLearning/comments/8zqq6u/d_best_network_for_image_inpainting_for_a_very/,bmwgtrm9,1531874099,"https://imgur.com/a/2FYnLWY

I have many very flat gray scale images, say 2000 by 20. I want to cover half rows of the image and use it as input to the network. Say the image has row 1, 2, 3, ... , 20. I will cover row 1, 3, 5, ... , 19. I want the network gives me the best guess for the covered rows.

I am very new to machine learning (less than a week). I know Deep Conv GAN can so such things. I also found there are many other published paper about image inpainting. I want to seek some help here for some guidance. Can a NN process such flat images? What would be the best next step to take.",0,0
940,2018-7-18,2018,7,18,10,8zr51j,[News] New Release of Yellowbrick (Open Source Python Machine Learning Visualization Library),https://www.reddit.com/r/MachineLearning/comments/8zr51j/news_new_release_of_yellowbrick_open_source/,eldraino,1531877533,,8,40
941,2018-7-18,2018,7,18,11,8zrih0,What program should I choose I I want to go into ML/AI?,https://www.reddit.com/r/MachineLearning/comments/8zrih0/what_program_should_i_choose_i_i_want_to_go_into/,yasyas321,1531880703,[removed],0,1
942,2018-7-18,2018,7,18,12,8zrx78,[D] Feasibility on Tracking Urban Migration,https://www.reddit.com/r/MachineLearning/comments/8zrx78/d_feasibility_on_tracking_urban_migration/,lillentilman,1531884278,"I'm working on a school project, and I'd like to track urban migration. I have a set of data that contains obfuscated persons: ages, their address history, and home value from their neighborhoods. I hypothesize that using that data, there could be insights about how people move about, helping to solve urban planning problems.   


Because I'm new to machine learning, I had some questions about making this happen:  


\- Does that seem like a problem that machine learning can solve? Answers to, ""What's the likelihood that this person will leave? Where do we anticipate they go? When will they migrate?""  


\- What would be the best model for solving that? My best assumption is some kind of Random Forest, probably regressive.  


\- Which features would be most important here? Ages and home value seem clear, but address is a rough one to cut. Do those get encoded, or do we instead just look at distances and directions derived from differences in the addresses? Are there others you would suggest?  


Thanks in advance for any help, it's always so interesting seeing how people approach these problems!",1,1
943,2018-7-18,2018,7,18,12,8zs3kg,Where To Buy Lumpia Wrapper Machine?,https://www.reddit.com/r/MachineLearning/comments/8zs3kg/where_to_buy_lumpia_wrapper_machine/,liusherry,1531885925,,0,1
944,2018-7-18,2018,7,18,13,8zsbz2,"For any machine engineers / data scientists on here, IBM is looking to pay $100 for a short interview with you if you are able to describe the Deep Learing workflow w/ the tools involved to them.",https://www.reddit.com/r/MachineLearning/comments/8zsbz2/for_any_machine_engineers_data_scientists_on_here/,Momordicas,1531888118,[removed],0,1
945,2018-7-18,2018,7,18,13,8zsfpi,[R] Particle swarm optimisation - an alternative to gradient decent,https://www.reddit.com/r/MachineLearning/comments/8zsfpi/r_particle_swarm_optimisation_an_alternative_to/,datascience_dude,1531889134,,0,1
946,2018-7-18,2018,7,18,13,8zsgk5,AutoGraph converts Python into TensorFlow graphs,https://www.reddit.com/r/MachineLearning/comments/8zsgk5/autograph_converts_python_into_tensorflow_graphs/,samithaj,1531889368,[removed],0,1
947,2018-7-18,2018,7,18,14,8zskmf,Powerful solution for large scale deep learning,https://www.reddit.com/r/MachineLearning/comments/8zskmf/powerful_solution_for_large_scale_deep_learning/,clusterone02,1531890504,[removed],0,1
948,2018-7-18,2018,7,18,14,8zsof3,AutoGraph converts Python into TensorFlow graphs,https://www.reddit.com/r/MachineLearning/comments/8zsof3/autograph_converts_python_into_tensorflow_graphs/,samithaj,1531891620,,27,217
949,2018-7-18,2018,7,18,14,8zsscf,Any ideas for good college project using multiple regression model?,https://www.reddit.com/r/MachineLearning/comments/8zsscf/any_ideas_for_good_college_project_using_multiple/,ajeenkkya,1531892814,[removed],0,2
950,2018-7-18,2018,7,18,14,8zstnw,Who is the most prominent A.I researcher in the world in your opinion?,https://www.reddit.com/r/MachineLearning/comments/8zstnw/who_is_the_most_prominent_ai_researcher_in_the/,thunderking500,1531893225,[removed],0,1
951,2018-7-18,2018,7,18,17,8ztraq,What happened to spatial transformer networks?,https://www.reddit.com/r/MachineLearning/comments/8ztraq/what_happened_to_spatial_transformer_networks/,nivter,1531903880,[removed],0,1
952,2018-7-18,2018,7,18,18,8ztwqh,Machine Learning : The Future of Mobile Apps Development,https://www.reddit.com/r/MachineLearning/comments/8ztwqh/machine_learning_the_future_of_mobile_apps/,we_are_metizsoft,1531905541,[removed],0,1
953,2018-7-18,2018,7,18,18,8ztxek,What processes that involve ML require data through human input? (like image labeling),https://www.reddit.com/r/MachineLearning/comments/8ztxek/what_processes_that_involve_ml_require_data/,data_driven_approach,1531905764,[removed],0,1
954,2018-7-18,2018,7,18,18,8zu1eq,AI Assistant Pizza Bot or How to Order Pizza in One Click,https://www.reddit.com/r/MachineLearning/comments/8zu1eq/ai_assistant_pizza_bot_or_how_to_order_pizza_in/,bkmnsk,1531906997,,0,1
955,2018-7-18,2018,7,18,19,8zu77z,Evolutionary algorithm outperforms deep-learning machines at video games,https://www.reddit.com/r/MachineLearning/comments/8zu77z/evolutionary_algorithm_outperforms_deeplearning/,fungussa,1531908689,,0,1
956,2018-7-18,2018,7,18,20,8zur91,[P] Writing an object recognition ML algorithm without using existing ML Frameworks and TesseractOCR,https://www.reddit.com/r/MachineLearning/comments/8zur91/p_writing_an_object_recognition_ml_algorithm/,bluedino666,1531914244,"Currently, one of my restrictions is that I want to build algorithms and write the code purely by myself without ML frameworks \[and Tesseract OCR, primarily because I want to learn how it works\] to develop my understanding of the content. 

Now, I have been reading tutorials, watching videos, getting a hang of the frameworks \[TF, Keras, and PyTorch specifically\] and whatnot, but for some reason when it comes to coding the stuff by myself from scratch, I simply am not able to; I have absolutely no idea where to start, how to do it, and more specifically, how to do it with my restriction. 

My project, currently, revolves around computer vision where I want to develop an algorithm to detect objects from an image and classify what the image is from the text on the screen and from the other features of the image. But I am not sure how to go about this project, so I would really like advice surrounding this. Any help appreciated. ",4,1
957,2018-7-18,2018,7,18,21,8zv0c2,[R] TDLS- Quantum generative adversarial networks (https://arxiv.org/abs/1804.08641),https://www.reddit.com/r/MachineLearning/comments/8zv0c2/r_tdls_quantum_generative_adversarial_networks/,machinetrainer,1531916494,,1,3
958,2018-7-18,2018,7,18,21,8zv2r4,What are good Interpretable Machine Learning research focuses?,https://www.reddit.com/r/MachineLearning/comments/8zv2r4/what_are_good_interpretable_machine_learning/,Phyrlae,1531917043,[removed],0,1
959,2018-7-18,2018,7,18,21,8zv2vt,"TinyGBT: A Tiny, Pure Python implementation of Gradient Boosted Trees.",https://www.reddit.com/r/MachineLearning/comments/8zv2vt/tinygbt_a_tiny_pure_python_implementation_of/,lancifollia,1531917073,[removed],0,1
960,2018-7-18,2018,7,18,21,8zv3ce,Promote your Business through Postcard Printing in Singapore,https://www.reddit.com/r/MachineLearning/comments/8zv3ce/promote_your_business_through_postcard_printing/,tockfahnes,1531917182,,0,1
961,2018-7-18,2018,7,18,21,8zv4k0,"What Are Data Trends and Patterns, and How Do They Impact Business Decisions?",https://www.reddit.com/r/MachineLearning/comments/8zv4k0/what_are_data_trends_and_patterns_and_how_do_they/,ElegantMicroWebIndia,1531917471,,0,1
962,2018-7-18,2018,7,18,21,8zv5jo,"[P] TinyGBT: A Tiny, Pure Python implementation of Gradient Boosted Trees.",https://www.reddit.com/r/MachineLearning/comments/8zv5jo/p_tinygbt_a_tiny_pure_python_implementation_of/,lancifollia,1531917715,"TinyGBT(Tiny Gradient Boosted Trees) is a 200 line gradient boosted trees implementation written in pure python.

[https://github.com/lancifollia/tinygbt](https://github.com/lancifollia/tinygbt)",0,1
963,2018-7-18,2018,7,18,21,8zv941,"[P] TinyGBT: A Tiny, Pure Python implementation of Gradient Boosted Trees.",https://www.reddit.com/r/MachineLearning/comments/8zv941/p_tinygbt_a_tiny_pure_python_implementation_of/,lancifollia,1531918561,,9,57
964,2018-7-18,2018,7,18,22,8zvdbv,Ticket Machine Market worth USD 11.40 billion by 2023 | Top Most Players,https://www.reddit.com/r/MachineLearning/comments/8zvdbv/ticket_machine_market_worth_usd_1140_billion_by/,Anna_veith,1531919513,,0,1
965,2018-7-18,2018,7,18,22,8zve90,Get Professional Document with Glue Binding Machine,https://www.reddit.com/r/MachineLearning/comments/8zve90/get_professional_document_with_glue_binding/,kennywilliamson1990,1531919717,,0,1
966,2018-7-18,2018,7,18,22,8zvkd6,[R] Advanced Differentiable Neural Computer (ADNC) with SOTA mean results on the bAbI task.,https://www.reddit.com/r/MachineLearning/comments/8zvkd6/r_advanced_differentiable_neural_computer_adnc/,spreisel,1531921084,,0,1
967,2018-7-18,2018,7,18,22,8zvnst,LSTM for inference,https://www.reddit.com/r/MachineLearning/comments/8zvnst/lstm_for_inference/,morsoni45,1531921803,[removed],0,1
968,2018-7-18,2018,7,18,22,8zvpyf,[R] Advanced Differentiable Neural Computer (ADNC) with SOTA results on the bAbI task.,https://www.reddit.com/r/MachineLearning/comments/8zvpyf/r_advanced_differentiable_neural_computer_adnc/,spreisel,1531922266,,0,1
969,2018-7-18,2018,7,18,22,8zvq2w,[R] Evolving simple programs for playing Atari games,https://www.reddit.com/r/MachineLearning/comments/8zvq2w/r_evolving_simple_programs_for_playing_atari_games/,add7,1531922293,,5,10
970,2018-7-18,2018,7,18,23,8zvujy,[R] Advanced Differentiable Neural Computer (ADNC) with SOTA results on the bAbI QA tasks.,https://www.reddit.com/r/MachineLearning/comments/8zvujy/r_advanced_differentiable_neural_computer_adnc/,spreisel,1531923213,,0,1
971,2018-7-18,2018,7,18,23,8zvy5i,[R] Advanced Differentiable Neural Computer (DNC) with SOTA results on the bAbI QA tasks.,https://www.reddit.com/r/MachineLearning/comments/8zvy5i/r_advanced_differentiable_neural_computer_dnc/,spreisel,1531923972,,0,14
972,2018-7-18,2018,7,18,23,8zw24j,[P] Text Classification Models in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8zw24j/p_text_classification_models_in_tensorflow/,ganji1055,1531924811,"Implemented famous text classification models in TensorFlow: [https://github.com/dongjun-Lee/text-classification-models-tf](https://github.com/dongjun-Lee/text-classification-models-tf)

Implemented models are 1) Word-level CNN, 2) Character-level CNN 3) VDCNN(Very Deep CNN) 4) Word-level Bidirectional RNN 5) Attention-based Bidirectional RNN, 6) RCNN

\-

Semi-supervised Learning for Text Classification(Transfer Learning) is implemented at: [https://github.com/dongjun-Lee/transfer-learning-text-tf](https://github.com/dongjun-Lee/transfer-learning-text-tf)

Here, auto-encoder or language model is used as a pre-trained model to initialize LSTM text classification model.

I hope it helps! Thanks!",0,18
973,2018-7-18,2018,7,18,23,8zw7vm,Amazing Video about Understanding Linear Regression y Emily Fox,https://www.reddit.com/r/MachineLearning/comments/8zw7vm/amazing_video_about_understanding_linear/,Amir_PD,1531925951,,0,1
974,2018-7-19,2018,7,19,0,8zwbko,"Retro Tech: What Inside Compaq Contura Aero 4/25 Laptop ""4MB of RAM"" from 1994",https://www.reddit.com/r/MachineLearning/comments/8zwbko/retro_tech_what_inside_compaq_contura_aero_425/,Miller14684,1531926639,,0,1
975,2018-7-19,2018,7,19,0,8zwexb,"[P] What Inside Compaq Contura Aero 4/25 Laptop ""4MB of RAM"" from 1994",https://www.reddit.com/r/MachineLearning/comments/8zwexb/p_what_inside_compaq_contura_aero_425_laptop_4mb/,Miller14684,1531927285,,0,2
976,2018-7-19,2018,7,19,0,8zwf9m,[News] Seldon Launches New Commercial Kubernetes Application on Google Cloud Platform Marketplace,https://www.reddit.com/r/MachineLearning/comments/8zwf9m/news_seldon_launches_new_commercial_kubernetes/,ahousley,1531927354,,0,1
977,2018-7-19,2018,7,19,0,8zwpe1,"Simple Questions Thread July 18, 2018",https://www.reddit.com/r/MachineLearning/comments/8zwpe1/simple_questions_thread_july_18_2018/,AutoModerator,1531929348,[removed],0,1
978,2018-7-19,2018,7,19,1,8zwv4e,Word2vec embeddings differ on every run with same parameters,https://www.reddit.com/r/MachineLearning/comments/8zwv4e/word2vec_embeddings_differ_on_every_run_with_same/,thatphotoguy89,1531930432,[removed],0,1
979,2018-7-19,2018,7,19,1,8zx06i,"[N] New release of Deep Learning images (M3) for GCE, with Horovod and new CUDA 9.0 image",https://www.reddit.com/r/MachineLearning/comments/8zx06i/n_new_release_of_deep_learning_images_m3_for_gce/,b0noi,1531931414,"*if you not familiar with the Deep Learning images for GCE:*

* [article](https://blog.kovalevskyi.com/deep-learning-images-for-google-cloud-engine-the-definitive-guide-bc74f5fb02bc)
* [official docs](https://cloud.google.com/deep-learning-vm/docs/)

Changes:

* New common image with CUDA 9.0 has been introduced (family: common-cu90).
* All images now include [OpenMPI](https://www.open-mpi.org/).
* TensorFlow GPU images now include [Horovod](https://github.com/uber/horovod).
* CUDA 9.2 stack now includes latest NCCL 2.2.13.
* Bug that was preventing Jupyter Notebook from working correctly in some cases, has been resolved.

As usual, in order to create the VM one need to pick the image family. Here is updated cheatsheet for picking the right image family name:

https://i.redd.it/nmxinwtpgqa11.png",5,2
980,2018-7-19,2018,7,19,1,8zx2yf,[N] OpenAI Five Benchmark,https://www.reddit.com/r/MachineLearning/comments/8zx2yf/n_openai_five_benchmark/,thebackpropaganda,1531931946,,44,262
981,2018-7-19,2018,7,19,2,8zxd1u,How to find patterns and then determine when the patterns stop happening?,https://www.reddit.com/r/MachineLearning/comments/8zxd1u/how_to_find_patterns_and_then_determine_when_the/,toddhoffious,1531933807,[removed],0,1
982,2018-7-19,2018,7,19,2,8zxfga,Swim.ai raises $11M to bring real-time analytics to the edge,https://www.reddit.com/r/MachineLearning/comments/8zxfga/swimai_raises_11m_to_bring_realtime_analytics_to/,lmaisour,1531934257,,0,1
983,2018-7-19,2018,7,19,2,8zxlqe,Why should re-sampling change the value of model's coefficients?,https://www.reddit.com/r/MachineLearning/comments/8zxlqe/why_should_resampling_change_the_value_of_models/,sirkarthik,1531935395,[removed],0,1
984,2018-7-19,2018,7,19,2,8zxlwk,Multiple inputs for keras model,https://www.reddit.com/r/MachineLearning/comments/8zxlwk/multiple_inputs_for_keras_model/,Afroman212,1531935422,[removed],0,1
985,2018-7-19,2018,7,19,2,8zxpdk,Looking for some companies to split DL hardware cost with my company,https://www.reddit.com/r/MachineLearning/comments/8zxpdk/looking_for_some_companies_to_split_dl_hardware/,dMoroz23,1531936077,[removed],0,1
986,2018-7-19,2018,7,19,2,8zxpy4,"looking for a software that is a more simpler, automatic, and ml-based video editor like google photos does with photos?",https://www.reddit.com/r/MachineLearning/comments/8zxpy4/looking_for_a_software_that_is_a_more_simpler/,understandthings100,1531936179,[removed],0,1
987,2018-7-19,2018,7,19,4,8zyhmr,Why is the ICLR 2019 paper submission deadline so early this year? September 27th...,https://www.reddit.com/r/MachineLearning/comments/8zyhmr/why_is_the_iclr_2019_paper_submission_deadline_so/,mroda44,1531941382,"Why is the ICLR 2019 paper submission deadline so early this year? September 27th is 10 days after ECCV. 

I preferred a deadline around end of October or November like in the previous years.",0,1
988,2018-7-19,2018,7,19,4,8zyro4,Train Tensorflow models in JavaScript on your desktop with nteract Jupyter Notebook!,https://www.reddit.com/r/MachineLearning/comments/8zyro4/train_tensorflow_models_in_javascript_on_your/,loretoparisi,1531943286,,0,1
989,2018-7-19,2018,7,19,4,8zyt1e,"I am a beginner and i want to visualize my algorithms, for example, when i do a classification problem, i want to see my data and the line that separate them. Any tip?",https://www.reddit.com/r/MachineLearning/comments/8zyt1e/i_am_a_beginner_and_i_want_to_visualize_my/,PauloFRC,1531943553,[removed],0,1
990,2018-7-19,2018,7,19,4,8zytri,"[D] GANs for non-visual data: Are we ""overfitting"" in our architecture search?",https://www.reddit.com/r/MachineLearning/comments/8zytri/d_gans_for_nonvisual_data_are_we_overfitting_in/,LeanderKu,1531943691,"I might have an application for a GAN which doesn't involve images (generating valid vectors in a Word-Embedding-like vectors-space), so I thought about the current SOTA-architectures and noticed that they all involve deconvolutions.

Thinking about it, every experimentation dataset currently used in GANs is image-based (i suspect because they are easy to interpret for a human, also Evaluation of GAN performance is hard). I wonder whether there's an overfitting of architecture-search and training-algorithms for image-based problems. Unfortunately, I can't test I haven't finished working on the embedding.

So, dear reader, I essentially have 2 questions, a practical and a theoretical one:
1. Have you worked with GANs for data which (clearly?) doesn't have a convolutional aspect? Did you ever had success with a widely different architecture, like a fully-connected generator?
2. Do you think the focus on image-datasets is a problem? Is the focus on GAN-research too narrow?",7,8
991,2018-7-19,2018,7,19,5,8zyve0,An example of training a LSTM in Node.js on desktop. Using Tensorflow and nteract Jupyter Notebook,https://www.reddit.com/r/MachineLearning/comments/8zyve0/an_example_of_training_a_lstm_in_nodejs_on/,loretoparisi,1531944019,,0,1
992,2018-7-19,2018,7,19,5,8zyyek,[P] How to Set Up TensorFlow's Object Detection API on the Raspberry Pi. This video shows you how to deploy your object detection models on the Raspberry Pi!,https://www.reddit.com/r/MachineLearning/comments/8zyyek/p_how_to_set_up_tensorflows_object_detection_api/,Taxi-guy,1531944580,,0,1
993,2018-7-19,2018,7,19,5,8zyyvb,OpenAI Five Benchmark,https://www.reddit.com/r/MachineLearning/comments/8zyyvb/openai_five_benchmark/,j_orshman,1531944677,,0,1
994,2018-7-19,2018,7,19,6,8zzevy,Unwanted Generalization in Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8zzevy/unwanted_generalization_in_neural_networks/,dataCamper,1531947808,[removed],0,2
995,2018-7-19,2018,7,19,6,8zzrtd,"Ex Naughty Dog technical artist came up with a machine-learning system Promethean, which helps to build detailed game worlds",https://www.reddit.com/r/MachineLearning/comments/8zzrtd/ex_naughty_dog_technical_artist_came_up_with_a/,kika-tok,1531950486,,0,1
996,2018-7-19,2018,7,19,7,9007vc,Kinds of network models for game AI,https://www.reddit.com/r/MachineLearning/comments/9007vc/kinds_of_network_models_for_game_ai/,xdarknuno,1531953817,[removed],0,1
997,2018-7-19,2018,7,19,7,9008rt,[P] Artificial Composition of Multi-Instrumental Polyphonic Music: Github Repository,https://www.reddit.com/r/MachineLearning/comments/9008rt/p_artificial_composition_of_multiinstrumental/,davda54,1531954019,,0,1
998,2018-7-19,2018,7,19,7,900bp9,[P] Artificial Composition of Multi-Instrumental Polyphonic Music: Github Repository,https://www.reddit.com/r/MachineLearning/comments/900bp9/p_artificial_composition_of_multiinstrumental/,davda54,1531954652,,0,11
999,2018-7-19,2018,7,19,8,900chd,[P] Angry Hacker News,https://www.reddit.com/r/MachineLearning/comments/900chd/p_angry_hacker_news/,stokkid,1531954832,,2,1
1000,2018-7-19,2018,7,19,9,900u4u,[R] Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourage convex latent distributions,https://www.reddit.com/r/MachineLearning/comments/900u4u/r_generative_adversarial_interpolative/,timburg,1531958843,,11,14
1001,2018-7-19,2018,7,19,9,900v0r,"[D] TMLS2018 - Machine Learning in Production, Panel Discussion",https://www.reddit.com/r/MachineLearning/comments/900v0r/d_tmls2018_machine_learning_in_production_panel/,machinetrainer,1531959026,,2,32
1002,2018-7-19,2018,7,19,9,900xj4,Talao - Decentralized Freelance Site,https://www.reddit.com/r/MachineLearning/comments/900xj4/talao_decentralized_freelance_site/,Brybro07,1531959565,[removed],0,1
1003,2018-7-19,2018,7,19,11,901t4v,Swimming pool detection and classification in satellite imagery,https://www.reddit.com/r/MachineLearning/comments/901t4v/swimming_pool_detection_and_classification_in/,divyanshjha,1531966912,,1,1
1004,2018-7-19,2018,7,19,11,901wrf,[D] Dealing with imblanced image masks for multi-channel images used in Keras/Tensorflow Covnet,https://www.reddit.com/r/MachineLearning/comments/901wrf/d_dealing_with_imblanced_image_masks_for/,Hiant,1531967746,"As I mentioned above I'm working on a particular problem that has me vexed.  I'm using a deep learning model to classify features on an image provided through multiple spectral channels with masks for each of the features.  The masks are per 'image' not per image-channel.  The problem I'm running into is that for objects that rarely appear in the masks, the model does a very poor job of predicting out of sample.  Another issue is that the 'rare' feature, isn't very distinctive in shape, imagine something like grass.  For those pictures that have grass, there is a ton of it taking up the entire mask but for pictures in an ocean there is zero.    I've applied the requisite image augmentation techniques and haven't been able to boost the result for this mask, while the other features have done fantastically well.  Any ideas on how to get greater accuracy?",0,3
1005,2018-7-19,2018,7,19,15,903drw,Alibaba Research Introduces Deep Feedforward Sequential Memory Network (DFSMN)  A Novel Approach to Text-to-Speech (TTS) Systems,https://www.reddit.com/r/MachineLearning/comments/903drw/alibaba_research_introduces_deep_feedforward/,Michael_Pa,1531981622,,0,1
1006,2018-7-19,2018,7,19,15,903e5f,[D] Dropout and the deep complexity of neural networks,https://www.reddit.com/r/MachineLearning/comments/903e5f/d_dropout_and_the_deep_complexity_of_neural/,arcoain,1531981733,,2,4
1007,2018-7-19,2018,7,19,16,903p2q,Masters thesis topics on DL NLP,https://www.reddit.com/r/MachineLearning/comments/903p2q/masters_thesis_topics_on_dl_nlp/,anis016,1531984986,[removed],0,1
1008,2018-7-19,2018,7,19,16,903qpm,Dates washing and grading line in Egypt,https://www.reddit.com/r/MachineLearning/comments/903qpm/dates_washing_and_grading_line_in_egypt/,fruitprocess,1531985475,[removed],0,1
1009,2018-7-19,2018,7,19,16,903sny,Zoox - The self-Driving car that could beat Uber - A completely new approach to autonomous cars,https://www.reddit.com/r/MachineLearning/comments/903sny/zoox_the_selfdriving_car_that_could_beat_uber_a/,Anirban_Hazra,1531986045,,0,1
1010,2018-7-19,2018,7,19,16,903ta0,[D] What is one AI paper which you feel did not get the attention that it deserved? Discover hidden gems in the #APaperADay Reading Challenge with Nurture.ai,https://www.reddit.com/r/MachineLearning/comments/903ta0/d_what_is_one_ai_paper_which_you_feel_did_not_get/,leenz2,1531986216,"Many AI papers go by without receiving the time and attention it is due. Even some top tier papers published in NIPs don't get many readers. 

Addressing this issue, [Nurture.ai](https://Nurture.ai) is putting together a month-long reading challenge called the [#APaperADay AI Reading Challenge](https://apaperaday.nurture.ai), where we want to discover hidden gems and discover ideas that broaden the domain in AI.

Every week we will send out a list of curated papers that we believe deserve more attention, that introduce novel ideas that we would love to see explored even further. 

So what are some papers which have ideas you would like to see explored further, or believe more people should be aware of? Share them in the comments and we will definitely consider adding it to the #APaperADay reading list.

More details can be found [here](https://apaperaday.nurture.ai).



",18,68
1011,2018-7-19,2018,7,19,16,903uvx,[N] Microsoft shared interesting datasets,https://www.reddit.com/r/MachineLearning/comments/903uvx/n_microsoft_shared_interesting_datasets/,RedEyed__,1531986719,[removed],0,1
1012,2018-7-19,2018,7,19,17,903xv1,[N]Dates washing and grading line in Egypt,https://www.reddit.com/r/MachineLearning/comments/903xv1/ndates_washing_and_grading_line_in_egypt/,fruitprocess,1531987637,"Date, a fruit which is popularinMiddle East countries such as Saudi Arabia,Iran, Egypt and so on.

https://i.redd.it/e8lpbdhmyua11.jpg

The reason why Dates are concerned is that they are rich in nutrients and have extremely high nutritional value. Dates can be said to be the representative of beauty fruit.Datesare rich in magnesium, iron, zinc, dietary fiber, calcium, vitamin B, vitamin K, and carotene. The content of magnesium and dietary fiber is much higher than other fruits.

Recently, [Zhengzhou First Industry Co.,Ltd](https://fruitprocess.com/). Sold a [dates washing and grading line](https://fruitprocess.com/roller-grader/dates-washing-polishing-drying-and-grading-line/) to a client from Egypt. The picture below is the machine that the client took for me:

https://i.redd.it/m7p5a1ynyua11.jpg

As we can see from the picture, this line consists of bubble washing, rollers elevator, brushes&amp;showers, polishing&amp;drying and grading section.

https://i.redd.it/vd2z9gaqyua11.jpg

High efficiency and save space;

Brushes are soft and strong, avoid damage on the skin;

Bubble washing and brushes&amp;showers work together to make sure the cleaning effect.

We have to admit that first impression is crucialboth at work and in life. Of course, when we buy fruits and vegetables, their appearance decides their price to some extent. So more and more exporters choose to purchase a suitable machine in order to improve the quality and increase their revenue.

If you read here, please contact with us directly:

Official Website: **https://fruitprocess.com/**

Facebook: **https://www.facebook.com/fruitgrade**

YouTube:**youtube.com/c/Fruitsprocessingmachine**",0,0
1013,2018-7-19,2018,7,19,17,903yow,"I made an AI read the 50 shades books, and about 40 fanfics, this is an excerpt.",https://www.reddit.com/r/MachineLearning/comments/903yow/i_made_an_ai_read_the_50_shades_books_and_about/,allbyoneguy,1531987896,[removed],1,1
1014,2018-7-19,2018,7,19,17,9046u2,LSTM based address parsing,https://www.reddit.com/r/MachineLearning/comments/9046u2/lstm_based_address_parsing/,TheNamelessKing,1531990609,[removed],0,1
1015,2018-7-19,2018,7,19,19,904mno,[D] An Opinionated Introduction to AutoML and Neural Architecture Search - Rachel Thomas [fast.ai],https://www.reddit.com/r/MachineLearning/comments/904mno/d_an_opinionated_introduction_to_automl_and/,banksyb00mb00m,1531995571,,13,128
1016,2018-7-19,2018,7,19,19,904q2a,Where can I get a road traffic dataset?,https://www.reddit.com/r/MachineLearning/comments/904q2a/where_can_i_get_a_road_traffic_dataset/,ml_code,1531996600,[removed],0,1
1017,2018-7-19,2018,7,19,19,904tkl,[P] Implementation of Hierarchical Attention Networks in PyTorch,https://www.reddit.com/r/MachineLearning/comments/904tkl/p_implementation_of_hierarchical_attention/,pandeykartikey,1531997657,,0,4
1018,2018-7-19,2018,7,19,20,904v4r,How to Make a Chatbot: AWS Lex Weather Bot for Slack Tutorial,https://www.reddit.com/r/MachineLearning/comments/904v4r/how_to_make_a_chatbot_aws_lex_weather_bot_for/,Apptension,1531998097,,0,1
1019,2018-7-19,2018,7,19,20,904y3b,GANs that stood the test of time,https://www.reddit.com/r/MachineLearning/comments/904y3b/gans_that_stood_the_test_of_time/,totallynotAGI,1531998883,[removed],0,1
1020,2018-7-19,2018,7,19,20,904zsr,5 ways to Build A Board Game Predictor Using Machine Learning (Free Guide),https://www.reddit.com/r/MachineLearning/comments/904zsr/5_ways_to_build_a_board_game_predictor_using/,richardsmith7021,1531999384,[removed],0,1
1021,2018-7-19,2018,7,19,20,90525n,Embedded Hardware for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/90525n/embedded_hardware_for_deep_learning/,whiletrue2,1532000051,[removed],0,1
1022,2018-7-19,2018,7,19,20,9054mp,Playing Card Wrapping Machine,https://www.reddit.com/r/MachineLearning/comments/9054mp/playing_card_wrapping_machine/,liusherry,1532000759,,1,1
1023,2018-7-19,2018,7,19,21,905a5g,Games similar to pong for Policy gradient network,https://www.reddit.com/r/MachineLearning/comments/905a5g/games_similar_to_pong_for_policy_gradient_network/,Ryzu1,1532002203,[removed],0,1
1024,2018-7-19,2018,7,19,21,905gno,How do you determine how many leaf nodes in each tree in Random Forest? SciKit Learn,https://www.reddit.com/r/MachineLearning/comments/905gno/how_do_you_determine_how_many_leaf_nodes_in_each/,stewan11,1532003809,[removed],0,1
1025,2018-7-19,2018,7,19,21,905kbj,[D] About research experience before applying to graduate programs in ML,https://www.reddit.com/r/MachineLearning/comments/905kbj/d_about_research_experience_before_applying_to/,Cornucopia-of-PDEs,1532004685,"I've seen people recommending here that ideally one should have at least one paper published before applying to graduate school and I'm planning to carry out this advice seriously. I'm from a developing country, currently at the 3rd semester of an Applied Math major (which really is just a math degree with additional CS and numerical analysis courses) and I wish to maximize my chances of landing a PhD program in the US (or Canada/UK). However, the research in ML done by the CS deparment at my university does not use much math (they are mostly experimental), which I find very uninteresting. Given that, I'd rather do research with a professor from the math deparment in a topic such as PDE or Probability. Supposing that I eventually succeed with this and get a paper published in a good pure math journal, will this look just as good when applying to ML programs? Will I have good chances of getting into a (funded) PhD in the US? Of course, also assume that I get good grades.

If you're wondering, relavent courses I'll be taking (outside the usual ones required for a math major) include Algos and DS, Operations Research/Optimization, Numerical Linear Algebra and Numerical PDEs, Measure Theory, Probability and a bit of Statistics. I'm also planning to take grad courses on Topology, PDEs and Functional Analysis.

Thanks in advance.",3,0
1026,2018-7-19,2018,7,19,22,905nyo,[D] What would happen if we used a non-linearity in Word2vec (Skip-Gram for example) ?,https://www.reddit.com/r/MachineLearning/comments/905nyo/d_what_would_happen_if_we_used_a_nonlinearity_in/,HichamEB,1532005522,"Hi :)

The main argument for using a log-linear model in Word2vec would be:  
By avoiding the computation bottleneck of having a non-linearity in the network, we are able to train on larger datasets and therefore get better quality embeddings. But does this still hold today ?

Did anyone manage to train the same architecture on the same data, with an without a non-linearity, and checked if the embeddings using a non-linearity were better than those without one ?",1,1
1027,2018-7-19,2018,7,19,23,9067rx,Researchers show how to perform backpropagation physically on optics-based neural network architectures.,https://www.reddit.com/r/MachineLearning/comments/9067rx/researchers_show_how_to_perform_backpropagation/,BarnyardPuer,1532009741,,0,1
1028,2018-7-19,2018,7,19,23,90685o,[D] Getting Started with Darknet YOLO and MS COCO for Object Detection,https://www.reddit.com/r/MachineLearning/comments/90685o/d_getting_started_with_darknet_yolo_and_ms_coco/,mode_develop,1532009819,,3,6
1029,2018-7-19,2018,7,19,23,906aac,Nice overview tutorial on Imitation Learning,https://www.reddit.com/r/MachineLearning/comments/906aac/nice_overview_tutorial_on_imitation_learning/,pienuthome,1532010257,,0,1
1030,2018-7-19,2018,7,19,23,906acy,"[P] PyTorch implementation of ""StyleBank: An Explicit Representation for Neural Image Style Transfer""",https://www.reddit.com/r/MachineLearning/comments/906acy/p_pytorch_implementation_of_stylebank_an_explicit/,jxcode,1532010272,"Paper: [https://arxiv.org/abs/1703.09210](https://arxiv.org/abs/1703.09210)

Modified from the PyTorch official document [style transfer example](https://pytorch.org/tutorials/advanced/neural_style_tutorial.html).

Features:

* Fast style transfer
* Fully convolution network
* Learning multiple style at the same time
* Incremental learning (learning a new style don't need to retrain the whole network)
* Linear Fusion of Styles  (not implemented, but with a little modification of the code, it can work)
* Region-specific Style Fusion (not implemented)

code (a little bit messy :P) + pre-train weights + results: [https://github.com/jxcodetw/Stylebank](https://github.com/jxcodetw/Stylebank)",0,7
1031,2018-7-19,2018,7,19,23,906et0,[R] Nice overview tutorial on Imitation Learning,https://www.reddit.com/r/MachineLearning/comments/906et0/r_nice_overview_tutorial_on_imitation_learning/,pienuthome,1532011168,,0,1
1032,2018-7-19,2018,7,19,23,906jnn,"""Attention is all you need"" - input sequence",https://www.reddit.com/r/MachineLearning/comments/906jnn/attention_is_all_you_need_input_sequence/,albert1905,1532012129,[removed],1,1
1033,2018-7-19,2018,7,19,23,906kze,Six Free Machine Learning eBooks,https://www.reddit.com/r/MachineLearning/comments/906kze/six_free_machine_learning_ebooks/,Dmitrovic01,1532012392,,0,1
1034,2018-7-20,2018,7,20,1,90776m,[R] Location Augmentation for CNN,https://www.reddit.com/r/MachineLearning/comments/90776m/r_location_augmentation_for_cnn/,xternalz,1532016617,,8,8
1035,2018-7-20,2018,7,20,1,907atf,[D] SOTA on Real Time Semantic/Instance Segmentation?,https://www.reddit.com/r/MachineLearning/comments/907atf/d_sota_on_real_time_semanticinstance_segmentation/,Writes_A_Bit,1532017267,"I see a bunch of different models - ENet, DeepLab, the original Mask RCNN. I was curious about people's experience with real time semantic/instance segmentation tasks. I saw the post from [qure.ai](https://qure.ai) ""2017 guide to semantic segmentation"", but was wondering if there have been further improvements. There's no mention of FPS in the post either.",0,3
1036,2018-7-20,2018,7,20,1,907dmi,Recreating GTA 5 graphics from semantic maps with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/907dmi/recreating_gta_5_graphics_from_semantic_maps_with/,ytdeepgamingai,1532017798,,0,1
1037,2018-7-20,2018,7,20,1,907g1x,[R] Nice overview tutorial on Imitation Learning from Caltech researchers,https://www.reddit.com/r/MachineLearning/comments/907g1x/r_nice_overview_tutorial_on_imitation_learning/,pienuthome,1532018326,Introductory tutorial on imitation learning (or learning from demonstrations) at ICML 2018 by Yisong Yue and Hoang Le from Caltech,0,1
1038,2018-7-20,2018,7,20,1,907hqv,"[N] Weekly Machine Learning Opensource Roundup  July 19, 2018",https://www.reddit.com/r/MachineLearning/comments/907hqv/n_weekly_machine_learning_opensource_roundup_july/,stkim1,1532018645,,0,1
1039,2018-7-20,2018,7,20,1,907i7n,4 Helpful Cloud Services for Machine Learning Researchers,https://www.reddit.com/r/MachineLearning/comments/907i7n/4_helpful_cloud_services_for_machine_learning/,nodet07,1532018733,,0,1
1040,2018-7-20,2018,7,20,1,907ilm,Oferta Laboral Entel Chile,https://www.reddit.com/r/MachineLearning/comments/907ilm/oferta_laboral_entel_chile/,danielfm123,1532018802,[removed],0,1
1041,2018-7-20,2018,7,20,1,907jtb,[R] Motivating the Rules of the Game for Adversarial Example Research,https://www.reddit.com/r/MachineLearning/comments/907jtb/r_motivating_the_rules_of_the_game_for/,wordbag,1532019012,,2,11
1042,2018-7-20,2018,7,20,1,907k2d,[R] Nice overview tutorial on Imitation Learning,https://www.reddit.com/r/MachineLearning/comments/907k2d/r_nice_overview_tutorial_on_imitation_learning/,pienuthome,1532019057,,0,7
1043,2018-7-20,2018,7,20,2,907p7a,"[D] What is the current state of the art in confidence scoring, calibration and out of distribution detection?",https://www.reddit.com/r/MachineLearning/comments/907p7a/d_what_is_the_current_state_of_the_art_in/,spotta,1532019978,"The work that I have been able to find (excluding Bayesian by backdrop, bayesian NNs and the dropout-MC methods...)

* Chen et al. - Confidence Scoring using white box Meta-models with Linear classifier Probes, (2018)
   * Generates a model that uses probes of the individual layers of the NN classifier to create a confidence score for the NN's output.
* Lee et. al. - Training Confidence-calibrated classifiers for detecting out-of-distribution samples (2018)
   * Uses a GAN to generate ""borderline ood"" samples and then trains the classifier to be uncertain for those samples.
* DeVries et al. - Learning Confidence for Out-of-Distribution Detection in Neural Networks (2018)
   * Sideloads a second output from the penultimate layer of the classifier that predicts a confidence score.  Trains it to be confident by interpolating the output of the network between the output of the softmax and the true value, scaled by the confidence score.  So a very confident score will be close to the output of the softmax, while an unconfident score will be close to the true value.
* Mandelbaum et al. - Distance-based confidence score for neural network classifiers (2017)
   * Essentially seems to simultaneously train a siamese network on the penultimate layer and the entropy on the softmax output in order to make distances on the penultimate layer to be meaningful.
* Subramanya et al. - Confidence estimation in Deep Neural Networks via density modeling (2017)
   * Finds P(y\_i|X) by assuming P(X|y\_i) = N(z|\_i, s\_i), where z is the output of the network, X is the training data, y is the true label, and  and s are learned variables... though I'm not sure how they are learned...
* Guo et al. - On Calibration of Modern Neural Networks (2017)
   * Use temperature scaling to calibrate the confidence of the softmax outputs.
* Liang et al. - Principled detection of Out-of-Distribution Examples in Neural Networks (2017) and Enhancing the reliability of Out-of-distribution image detection in neural networks (2017)
   * ODIN (out of distribution detector), use temperature scaling and an inverse of adversarial training (scale the input \*towards\* a more confident result, rather than away) in order to improve separation between in distribution and out of distribution examples.
* Lakshminarayanan et al. - Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles (2016)
   * Ensemble a few different networks and use adversarial training to get a confidence score.
* Hendrycks et al. - A Baseline for detecting misclassified and out of distribution examples in neural networks (2016)
   * Mostly defined the terms and the metrics that other papers used.  Also defined an ""abnormality model"", which side loaded an auto-encoder off the penultimate layer, and then trained a model on the output of the softmax and the auto-encoder using an out of distribution dataset to get confidence scores.

Is anyone aware of any more work in this area?  What about what seems to work best in practice?  Does anyone have any experience with these methods (what works, what doesn't work, etc).",13,62
1044,2018-7-20,2018,7,20,2,907qie,Azure ML Tutorial/Training,https://www.reddit.com/r/MachineLearning/comments/907qie/azure_ml_tutorialtraining/,orangeatom,1532020217,"Hi, I'm new to the Azure ML space and I am looking for tutorials and training on ML experiments within Azure. I was wondering if anyone has any good sources for this type of material? I have completed the general tutorials (Iris Recognition and BikeShare) and looking for more real world examples now, specifically models that view anomaly detection. Thanks!",0,1
1045,2018-7-20,2018,7,20,2,907s8m,[P] Table Detection using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/907s8m/p_table_detection_using_deep_learning/,thesameoldstories,1532020533,,0,1
1046,2018-7-20,2018,7,20,2,9085vw,ICML: Max Welling - Intelligence per Kilowatthour,https://www.reddit.com/r/MachineLearning/comments/9085vw/icml_max_welling_intelligence_per_kilowatthour/,tensorflower,1532023128,,0,1
1047,2018-7-20,2018,7,20,3,90872k,[R] - Max Welling: Intelligence per kilowatt-hour - ICML 2018,https://www.reddit.com/r/MachineLearning/comments/90872k/r_max_welling_intelligence_per_kilowatthour_icml/,tensorflower,1532023355,,7,44
1048,2018-7-20,2018,7,20,3,9089b4,Turning Fortnite into PUBG with Deep Learning (CycleGANs),https://www.reddit.com/r/MachineLearning/comments/9089b4/turning_fortnite_into_pubg_with_deep_learning/,MukundhBhushan,1532023773,,0,1
1049,2018-7-20,2018,7,20,3,908d8h,"[R] Announcing Cirq: An Open Source Framework for NISQ Algorithms (Google, Quantum Computing)",https://www.reddit.com/r/MachineLearning/comments/908d8h/r_announcing_cirq_an_open_source_framework_for/,fhoffa,1532024496,,0,15
1050,2018-7-20,2018,7,20,3,908jr0,"I know this is probably asked a lot but, where should I start if I wanna start machine learning?",https://www.reddit.com/r/MachineLearning/comments/908jr0/i_know_this_is_probably_asked_a_lot_but_where/,CountJeewb,1532025734,"I want to apologize in advance because I know this question has probably been asked several dozen times on this subreddit but I couldn't find a good answer when I looked for it.

I wouldn't say I'm new to Programing but I'm def not far into it at all. I know a little bit of python syntax and I'm still learning as well speak, but I want to start learning machine learning and deep learn. Does anyone know where I should start? What order of things should I learn so that I can grasp the concepts of machine learning and apply them to my own projects. 

For everyone who answers this for me I thank you for your help!",0,1
1051,2018-7-20,2018,7,20,4,9092ii,[d] looking for a ml-based video editor like what google photos does with photos by using ml &amp; pattern recognition,https://www.reddit.com/r/MachineLearning/comments/9092ii/d_looking_for_a_mlbased_video_editor_like_what/,understandthings100,1532029331,,0,0
1052,2018-7-20,2018,7,20,4,9092yn,GANs that stood the test of time,https://www.reddit.com/r/MachineLearning/comments/9092yn/gans_that_stood_the_test_of_time/,totallynotAGI,1532029420,[removed],27,145
1053,2018-7-20,2018,7,20,6,909t2z,Research on batch sampling strategies?,https://www.reddit.com/r/MachineLearning/comments/909t2z/research_on_batch_sampling_strategies/,mearco,1532034788,I'm wondering if there is any existing research into deciding how to sample datapoints for constructing batches? I think for batchnorm the batch should be randomly sampled. For non batchnorm though there are multiple approaches you could take. For example in super resolution you could fill your batch with patches from all the same image or from random images.,0,1
1054,2018-7-20,2018,7,20,7,90alxh,[N] Yann LeCuns IJCAI Keynote: We Need a World Model,https://www.reddit.com/r/MachineLearning/comments/90alxh/n_yann_lecuns_ijcai_keynote_we_need_a_world_model/,trcytony,1532040853,,0,1
1055,2018-7-20,2018,7,20,8,90arl2,"Introducing Spartan Crypto, Powering The AI and Blockchain Future",https://www.reddit.com/r/MachineLearning/comments/90arl2/introducing_spartan_crypto_powering_the_ai_and/,spartancryptocapital,1532042028,[removed],0,1
1056,2018-7-20,2018,7,20,9,90b9k3,[R] ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech,https://www.reddit.com/r/MachineLearning/comments/90b9k3/r_clarinet_parallel_wave_generation_in_endtoend/,Rubato1,1532046133,,27,28
1057,2018-7-20,2018,7,20,9,90bdan,"Are you interested in Machine Learning and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/MachineLearning/comments/90bdan/are_you_interested_in_machine_learning_and_want/,ailearn12,1532047029,,0,1
1058,2018-7-20,2018,7,20,10,90bm2k,Stringle - AI Powered Text Analysis Cloud,https://www.reddit.com/r/MachineLearning/comments/90bm2k/stringle_ai_powered_text_analysis_cloud/,javascripton,1532049139,,0,1
1059,2018-7-20,2018,7,20,10,90bmp9,List of Machine Learning Data Resources (46 Resources),https://www.reddit.com/r/MachineLearning/comments/90bmp9/list_of_machine_learning_data_resources_46/,asifrazzaq1988,1532049290,[removed],0,1
1060,2018-7-20,2018,7,20,10,90bp94,List of Machine Learning Data Resources (46 Resources in this list),https://www.reddit.com/r/MachineLearning/comments/90bp94/list_of_machine_learning_data_resources_46/,asifrazzaq1988,1532049902,,1,1
1061,2018-7-20,2018,7,20,10,90bqa7,Hardware for training deep learning models is about to get significantly faster,https://www.reddit.com/r/MachineLearning/comments/90bqa7/hardware_for_training_deep_learning_models_is/,gradientflow,1532050135,,0,1
1062,2018-7-20,2018,7,20,11,90c9wv,[R] Adaptive Neural Trees,https://www.reddit.com/r/MachineLearning/comments/90c9wv/r_adaptive_neural_trees/,downtownslim,1532054952,,15,23
1063,2018-7-20,2018,7,20,13,90d22d,Question towards Tensor Regression,https://www.reddit.com/r/MachineLearning/comments/90d22d/question_towards_tensor_regression/,hz_vistov,1532062241,[removed],0,1
1064,2018-7-20,2018,7,20,13,90d432,What are Sum-Product Networks useful for?,https://www.reddit.com/r/MachineLearning/comments/90d432/what_are_sumproduct_networks_useful_for/,ciolaamotore,1532062782,[removed],0,1
1065,2018-7-20,2018,7,20,14,90d7e7, 1   100%,https://www.reddit.com/r/MachineLearning/comments/90d7e7/_1__100/,Woodworking94,1532063681,,0,1
1066,2018-7-20,2018,7,20,14,90d9b4,Wrong number of features per sample error in prediction model Scikit learn,https://www.reddit.com/r/MachineLearning/comments/90d9b4/wrong_number_of_features_per_sample_error_in/,dmnte,1532064234,"Hi, I am trying to do some predicting using a logistic regression model and Scikit learn but I am getting the following error, ""ValueError: X has 937 features per sample; expecting 223086"". I have tryed googling on how to fix it and it seems that the shape of the X I am training is not the same as what I am using for predicting.  


To begin with I split the dataset into train and test set and then use CountVectorizor.fit\_transform and tfidf\_transformer.fit\_transform on the data for training and then on the test data I use CountVectorizor.transform and tfidf\_transformer.transform to predict which works. I then save the model with joblib. I then want to use new data which im scraping from twitter and try to pass it into the same model but I get the error above. I am using the same CountVectorizor.fit\_transform and tfidf\_transformer.fit\_transform on the new data but it is giving me a different shape. The shape of the x on new data is (143, 937) and the shape on the trained data is   (1197030, 223086). The new data I am trying to put into the model is obviously much smaller then what I trained the model with but it seems to want that shape ? Can anyone help fix this it would be much appreciated, the code is below, training\_testing\_model being where i train the model and predicting\_new\_data where i try to predict.

[https://gist.github.com/ishikawa-rei/c5928cff3a410ed0046580aa64ec4bd3](https://gist.github.com/ishikawa-rei/c5928cff3a410ed0046580aa64ec4bd3)",0,1
1067,2018-7-20,2018,7,20,14,90dcls,[R] - ICML 2018 Tutorial on Imitation Learning,https://www.reddit.com/r/MachineLearning/comments/90dcls/r_icml_2018_tutorial_on_imitation_learning/,pienuthome,1532065173,,4,88
1068,2018-7-20,2018,7,20,15,90dr5o,"Company profile of Harbin Dadi Biology Organic Fertilizer Co , Ltd",https://www.reddit.com/r/MachineLearning/comments/90dr5o/company_profile_of_harbin_dadi_biology_organic/,amylee516,1532069550,,0,1
1069,2018-7-20,2018,7,20,16,90dta9,What are the applications of ML ?,https://www.reddit.com/r/MachineLearning/comments/90dta9/what_are_the_applications_of_ml/,arshid-kv,1532070192,[removed],0,1
1070,2018-7-20,2018,7,20,16,90e2d7,Fitting data in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/90e2d7/fitting_data_in_machine_learning/,Rachael__E,1532072997,[removed],0,1
1071,2018-7-20,2018,7,20,16,90e2lv,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/90e2lv/machine_learning/,raopawan,1532073076,[removed],0,1
1072,2018-7-20,2018,7,20,16,90e2nr,MindForger: Thinking Notebook,https://www.reddit.com/r/MachineLearning/comments/90e2nr/mindforger_thinking_notebook/,ultradvorka,1532073096,[removed],0,1
1073,2018-7-20,2018,7,20,17,90ebhc,A Parallelied AdaBoost on Multi Core Machines using open MP in C++ and also python,https://www.reddit.com/r/MachineLearning/comments/90ebhc/a_parallelied_adaboost_on_multi_core_machines/,diligentprocrastinar,1532076178,,0,1
1074,2018-7-20,2018,7,20,17,90edng,[D] How different is OpenAI-baselines `VecNormalize` from just normalize the discounted returns for policy gradient e.g. REINFORCE ?,https://www.reddit.com/r/MachineLearning/comments/90edng/d_how_different_is_openaibaselines_vecnormalize/,metaAI,1532076931,"If I understand correctly the \`VecNormalize\` in OpenAI-baselines computes a running average of the observations and immediate rewards, however, it is rather different than normalize discounted returns for gradient estimation, i.e. \`-log p(a|s)\*R'\` where \`R' = (R - R.mean())/R.std()\` ",3,6
1075,2018-7-20,2018,7,20,18,90eev9,How to compute the Fisher information for EWC ?,https://www.reddit.com/r/MachineLearning/comments/90eev9/how_to_compute_the_fisher_information_for_ewc/,gohu_cd,1532077339,[removed],0,1
1076,2018-7-20,2018,7,20,18,90ehjc,IBM to release worlds largest annotation dataset for studying bias in facial analysis,https://www.reddit.com/r/MachineLearning/comments/90ehjc/ibm_to_release_worlds_largest_annotation_dataset/,ibmzrl,1532078233,,0,1
1077,2018-7-20,2018,7,20,18,90ehra,[P] Hindi Typing Master,https://www.reddit.com/r/MachineLearning/comments/90ehra/p_hindi_typing_master/,magneticono,1532078293,,0,1
1078,2018-7-20,2018,7,20,18,90emqq,ICML 2018 notes,https://www.reddit.com/r/MachineLearning/comments/90emqq/icml_2018_notes/,adammathias,1532079957,,0,1
1079,2018-7-20,2018,7,20,19,90esmz,First Steps in Machine Learning with Microsoft Azure. Part 1,https://www.reddit.com/r/MachineLearning/comments/90esmz/first_steps_in_machine_learning_with_microsoft/,mariafilina,1532081882,,0,2
1080,2018-7-20,2018,7,20,19,90euhq,Automatic Ethiopian Injera and Dosa Making Machine,https://www.reddit.com/r/MachineLearning/comments/90euhq/automatic_ethiopian_injera_and_dosa_making_machine/,liusherry,1532082499,,0,1
1081,2018-7-20,2018,7,20,19,90f0l5,"[N] new release of CK workflow framework with 500+ AI/ML components (libraries, models, data sets)",https://www.reddit.com/r/MachineLearning/comments/90f0l5/n_new_release_of_ck_workflow_framework_with_500/,gfursin,1532084351,,1,2
1082,2018-7-20,2018,7,20,20,90f12r,[P] Problem with IBM SPSS Neural networks,https://www.reddit.com/r/MachineLearning/comments/90f12r/p_problem_with_ibm_spss_neural_networks/,TheGuyWhoBreathes,1532084487,"I get the error message  Warnings One or more cases in the testing or holdout sample have factor or dependent variable values that do not occur in the training sample. These cases are excluded from the analysis  

Anyone have any ideas?",1,0
1083,2018-7-20,2018,7,20,20,90f2ax,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/90f2ax/machine_learning/,raopawan,1532084809," Over 10,000 people have filled this survey to up skill in this every-changing digital landscape.

 Whats stopping you? 

r/https://docs.google.com/forms/d/e/1FAIpQLSdv5M0Dkox_0lyFyBJKQ1ZIZlBJFQIXwvW8ID2VFfXs6GYi8A/viewform?usp=sf_link",0,1
1084,2018-7-20,2018,7,20,20,90f3x2,[R] Erik Meijer - Machine Learning: Alchemy for the Modern Computer Scientist,https://www.reddit.com/r/MachineLearning/comments/90f3x2/r_erik_meijer_machine_learning_alchemy_for_the/,abstractcontrol,1532085233,,9,31
1085,2018-7-20,2018,7,20,21,90fgg2,The best programming language for data science and machine learning,https://www.reddit.com/r/MachineLearning/comments/90fgg2/the_best_programming_language_for_data_science/,RacerRex9727,1532088768,,0,1
1086,2018-7-20,2018,7,20,22,90ftq0,How to have a career in Machine Learning when graduate studies is not an option.,https://www.reddit.com/r/MachineLearning/comments/90ftq0/how_to_have_a_career_in_machine_learning_when/,knightrules555,1532092022,[removed],0,1
1087,2018-7-20,2018,7,20,22,90fv6s,Hoax Articles and Machine learning.. A must read blog,https://www.reddit.com/r/MachineLearning/comments/90fv6s/hoax_articles_and_machine_learning_a_must_read/,tinyquip,1532092345,,0,1
1088,2018-7-20,2018,7,20,22,90fvoh,Flowchart showing chatbot conversation pattern,https://www.reddit.com/r/MachineLearning/comments/90fvoh/flowchart_showing_chatbot_conversation_pattern/,seoaleait,1532092456,,0,1
1089,2018-7-20,2018,7,20,23,90gk5m,Here is a Cross-platform Dataset Annotator,https://www.reddit.com/r/MachineLearning/comments/90gk5m/here_is_a_crossplatform_dataset_annotator/,omenyayl,1532097783,[removed],0,1
1090,2018-7-21,2018,7,21,0,90gu3e,Help ! regarding cleaning of data from database.df(@leaning stage),https://www.reddit.com/r/MachineLearning/comments/90gu3e/help_regarding_cleaning_of_data_from/,bug2017,1532099815,[removed],1,1
1091,2018-7-21,2018,7,21,0,90gzm8,"Given a simple keras convnet implementation, what's the first area to look at for improvement?",https://www.reddit.com/r/MachineLearning/comments/90gzm8/given_a_simple_keras_convnet_implementation_whats/,GrundleMoof,1532100929,[removed],0,1
1092,2018-7-21,2018,7,21,1,90hbfp,[P] Here is a Cross-Platform Image Dataset Annotator,https://www.reddit.com/r/MachineLearning/comments/90hbfp/p_here_is_a_crossplatform_image_dataset_annotator/,omenyayl,1532103199,"I built an image dataset annotator with a few other people. It's pretty basic, but might be useful for you guys. Here it is: [https://github.com/omenyayl/dataset-annotator](https://github.com/omenyayl/dataset-annotator)

It was built with speed in mind - speed as in, for example, allowing the user to use hotkeys to navigate quickly through videos.

Also feel free to contribute and add features to the electron/angular/ionic program.",13,55
1093,2018-7-21,2018,7,21,2,90ht4s,[P] Scikit-learn inspired model finetuning for natural language processing,https://www.reddit.com/r/MachineLearning/comments/90ht4s/p_scikitlearn_inspired_model_finetuning_for/,madisonmay,1532106646,,2,30
1094,2018-7-21,2018,7,21,2,90i1yu,[D] Introduction to Qgrid,https://www.reddit.com/r/MachineLearning/comments/90i1yu/d_introduction_to_qgrid/,_quanttrader_,1532108341,,0,1
1095,2018-7-21,2018,7,21,3,90i8oy,[P] SWIPE Network - Monetizing Mobile Engagement Data on the Blockchain,https://www.reddit.com/r/MachineLearning/comments/90i8oy/p_swipe_network_monetizing_mobile_engagement_data/,jkvithanage,1532109663,"[SWIPE Network](https://swipecrypto.com/) is a decentralized mobile engagement data platform that empowers app developers with a suite of  marketing tools and SDKs to improve app engagement and user retention, while allowing for transparent and fair data monetization.",2,0
1096,2018-7-21,2018,7,21,3,90iaw5,[D] Adversarial Reprogramming - Reproducing the results and some new ideas,https://www.reddit.com/r/MachineLearning/comments/90iaw5/d_adversarial_reprogramming_reproducing_the/,MindSustenance,1532110083,,2,50
1097,2018-7-21,2018,7,21,3,90icj5,Genetic Algorithm Implementation in Python,https://www.reddit.com/r/MachineLearning/comments/90icj5/genetic_algorithm_implementation_in_python/,Rojas561,1532110382,,0,1
1098,2018-7-21,2018,7,21,4,90iv89,Looking for 6months ML/DL program in the UK/Ireland,https://www.reddit.com/r/MachineLearning/comments/90iv89/looking_for_6months_mldl_program_in_the_ukireland/,rwamit,1532114064,[removed],0,1
1099,2018-7-21,2018,7,21,5,90jngu,Tf-Idf for document search with word2vec. Need some advice.,https://www.reddit.com/r/MachineLearning/comments/90jngu/tfidf_for_document_search_with_word2vec_need_some/,azamBalanced,1532119758,[removed],0,1
1100,2018-7-21,2018,7,21,6,90k0vh,ECP Announces New Co-Design Center to Focus on Exascale Machine Learning Technologies,https://www.reddit.com/r/MachineLearning/comments/90k0vh/ecp_announces_new_codesign_center_to_focus_on/,ANNA_Systems,1532122481,,0,2
1101,2018-7-21,2018,7,21,7,90k86x,[R] Deep Clustering for Unsupervised Learning of Visual Features (unsupervised learning paper from FAIR published in ECCV),https://www.reddit.com/r/MachineLearning/comments/90k86x/r_deep_clustering_for_unsupervised_learning_of/,bobchennan,1532124102,,12,33
1102,2018-7-21,2018,7,21,7,90kchw,help making learning chatbot in python,https://www.reddit.com/r/MachineLearning/comments/90kchw/help_making_learning_chatbot_in_python/,Mr_chickenz,1532125054,[removed],0,1
1103,2018-7-21,2018,7,21,7,90kli1,[Project] Signing With Alexa: A DIY Experiment in AI Accessibility,https://www.reddit.com/r/MachineLearning/comments/90kli1/project_signing_with_alexa_a_diy_experiment_in_ai/,trcytony,1532127109,,0,1
1104,2018-7-21,2018,7,21,10,90lpr1,Data collection and data markets in the age of privacy and machine learning,https://www.reddit.com/r/MachineLearning/comments/90lpr1/data_collection_and_data_markets_in_the_age_of/,gradientflow,1532137135,,0,1
1105,2018-7-21,2018,7,21,10,90lsfr,Theoretical True Artificial Super-Intelligence,https://www.reddit.com/r/MachineLearning/comments/90lsfr/theoretical_true_artificial_superintelligence/,epiphony59,1532137848,[removed],1,1
1106,2018-7-21,2018,7,21,10,90ludw,Basic c++ open mp parallized implementation of Adaboost,https://www.reddit.com/r/MachineLearning/comments/90ludw/basic_c_open_mp_parallized_implementation_of/,diligentprocrastinar,1532138378,,0,1
1107,2018-7-21,2018,7,21,11,90lx8k,[P] My Parallel Implementation of adaboost in c++ (Open MP),https://www.reddit.com/r/MachineLearning/comments/90lx8k/p_my_parallel_implementation_of_adaboost_in_c/,diligentprocrastinar,1532139080,,0,27
1108,2018-7-21,2018,7,21,14,90n0lf,[D] What is the state of the art on real time semantic/instance segmentation?,https://www.reddit.com/r/MachineLearning/comments/90n0lf/d_what_is_the_state_of_the_art_on_real_time/,Writes_A_Bit,1532150278,"I  see a bunch of different models - ENet, DeepLab, the original Mask  RCNN. I was curious about people's experience with real time  semantic/instance segmentation tasks. I saw the post from [qure.ai](https://qure.ai/)  ""2017 guide to semantic segmentation"", but was wondering if there have  been further improvements. There's no mention of FPS in the post either.

Would be nice if someone can pitch in about networks trained on MS  COCO. I'm guessing it's really dependent on resource limitations. ""Real  time with a single GPU  at same resolution as input"", or ""real time on a mobile device"" is what I'm  interested in. I suspect this might be the holy grail of instance  segmentation still though?   


(reposting since I think it got removed last time for some reason)",0,1
1109,2018-7-21,2018,7,21,14,90n40l,[D]Autopsy of a deep learning paper - quite brutal takedown of recent Uber AI post,https://www.reddit.com/r/MachineLearning/comments/90n40l/dautopsy_of_a_deep_learning_paper_quite_brutal/,AndriPi,1532151406,,80,172
1110,2018-7-21,2018,7,21,14,90n6do,[P] Primal Interior Method implementation for convex optimization in ML (MATLAB),https://www.reddit.com/r/MachineLearning/comments/90n6do/p_primal_interior_method_implementation_for/,sritee,1532152225,,0,0
1111,2018-7-21,2018,7,21,15,90netp,psychic readings for free,https://www.reddit.com/r/MachineLearning/comments/90netp/psychic_readings_for_free/,mariellederane,1532155150,,0,1
1112,2018-7-21,2018,7,21,17,90o0m4,"A PyTorch implementation of the architecture of Mask RCNN, serves as an introduction to working with PyTorch",https://www.reddit.com/r/MachineLearning/comments/90o0m4/a_pytorch_implementation_of_the_architecture_of/,fristonio,1532163412,,3,1
1113,2018-7-21,2018,7,21,18,90o56o,What could be a baseline model in traditional approach (not deep learning) for a Question and Answering System for comparative research?,https://www.reddit.com/r/MachineLearning/comments/90o56o/what_could_be_a_baseline_model_in_traditional/,anis016,1532165292,[removed],0,1
1114,2018-7-21,2018,7,21,19,90odaw,"Some exercises and assignments for dimensionality reduction (PCA), SVM, the kernel trick, Lagrangian optimization, Logistic regression and k-NN. Feedback will be appreciated.",https://www.reddit.com/r/MachineLearning/comments/90odaw/some_exercises_and_assignments_for_dimensionality/,uakbar,1532168588,,0,1
1115,2018-7-21,2018,7,21,20,90osk2,A Simpe Neural network with Tensorflow-Keras using Colaboratory  r/tensorflow,https://www.reddit.com/r/MachineLearning/comments/90osk2/a_simpe_neural_network_with_tensorflowkeras_using/,machinelearning147,1532174350,,0,1
1116,2018-7-21,2018,7,21,21,90ovnn,[D] Do you consider RL the most biologically inspired algo?,https://www.reddit.com/r/MachineLearning/comments/90ovnn/d_do_you_consider_rl_the_most_biologically/,throwaway775849,1532175339,"I'm asking on this sub because I figured most here know RL, and forgive me in advance if this approaches philosophy. RL is a concept we invented to model certain dynamics, but the consistency of the metaphor with real life is hurting my head.

I was thinking about the idea of a 'reward', and how people don't act for the physical object to receive, but the mental state associated with that 'reward'. Our own behavior is a policy seeking a state, just like we have modeled it. Although only anecdotally, I know this metaphor applies at the atomic level, that atoms want the state of stability. I'm assuming it applies everywhere in between.",0,1
1117,2018-7-21,2018,7,21,21,90p0w3,"I am trying to implement a project, detecting people from CCTV camera, now the scnerio is I have to do this project on a raspberry pi. And there could be about 5 cctv camera streaming over RTSP.",https://www.reddit.com/r/MachineLearning/comments/90p0w3/i_am_trying_to_implement_a_project_detecting/,amitnair92,1532176990,[removed],0,1
1118,2018-7-21,2018,7,21,22,90p4g3,"Text Similarity - which is currently state of the art algorithms, approaches?",https://www.reddit.com/r/MachineLearning/comments/90p4g3/text_similarity_which_is_currently_state_of_the/,Tamio9,1532178067,[removed],0,1
1119,2018-7-21,2018,7,21,22,90p4uo,What are the pros and cons of valuing statistical properties vs optimization and predictive power in linear regression?,https://www.reddit.com/r/MachineLearning/comments/90p4uo/what_are_the_pros_and_cons_of_valuing_statistical/,GiveEmMoZo,1532178186,[removed],0,1
1120,2018-7-21,2018,7,21,22,90p90t,How do you save memory while training a keras model?,https://www.reddit.com/r/MachineLearning/comments/90p90t/how_do_you_save_memory_while_training_a_keras/,Mr_rolling,1532179377,[removed],0,1
1121,2018-7-22,2018,7,22,0,90q14b,[P] Examples trained using the python pytorch package pro-gan-pth,https://www.reddit.com/r/MachineLearning/comments/90q14b/p_examples_trained_using_the_python_pytorch/,akanimax,1532186537,,0,0
1122,2018-7-22,2018,7,22,0,90q20b,[P] pro-gan-pth python pytorch package new version: 1.2.3,https://www.reddit.com/r/MachineLearning/comments/90q20b/p_proganpth_python_pytorch_package_new_version_123/,akanimax,1532186761,,0,0
1123,2018-7-22,2018,7,22,0,90qan8,"[P] A PyTorch implementation of the architecture of Mask RCNN, serves as an introduction to working with PyTorch",https://www.reddit.com/r/MachineLearning/comments/90qan8/p_a_pytorch_implementation_of_the_architecture_of/,fristonio,1532188785,,5,103
1124,2018-7-22,2018,7,22,1,90qp5b,[ICML18] Decoupled Parallel Backpropagation with Convergence Guarantee,https://www.reddit.com/r/MachineLearning/comments/90qp5b/icml18_decoupled_parallel_backpropagation_with/,waqbb,1532192115,,13,26
1125,2018-7-22,2018,7,22,2,90qqy1,Working Part Time?,https://www.reddit.com/r/MachineLearning/comments/90qqy1/working_part_time/,pretysmitty,1532192520,[removed],0,1
1126,2018-7-22,2018,7,22,2,90qv18,Is this Algorithmen (for plotting High Dim Data) new?,https://www.reddit.com/r/MachineLearning/comments/90qv18/is_this_algorithmen_for_plotting_high_dim_data_new/,Hansi_klein,1532193431,[removed],0,1
1127,2018-7-22,2018,7,22,2,90qwed,[P] GAN creating ART from BAM-Dataset,https://www.reddit.com/r/MachineLearning/comments/90qwed/p_gan_creating_art_from_bamdataset/,S4ltyGo4t,1532193735,"Hey fellows,

after lurcking for a while in this subreddit i want to be a part of it.For my Bachelor-Thesis im creating a GAN, that generates art.

Im Using the BAM-Dataset ([https://bam-dataset.org//#explore](https://bam-dataset.org//#explore)),and the DCGAN([https://arxiv.org/pdf/1511.06434.pdf](https://arxiv.org/pdf/1511.06434.pdf)).

The learning-images are only ink painting.

The results are in 400x400, what is your opinion on them?

Im satisfied with the results in fact its my first work with Python/AI&amp;tensorflow.

Gallery of the best results:

[https://imgur.com/gallery/UbgRxdl](https://imgur.com/gallery/UbgRxdl)",13,20
1128,2018-7-22,2018,7,22,2,90qzp4,question on SVMs,https://www.reddit.com/r/MachineLearning/comments/90qzp4/question_on_svms/,[deleted],1532194481,,0,1
1129,2018-7-22,2018,7,22,2,90qzy7,What salary should I ask for ML?,https://www.reddit.com/r/MachineLearning/comments/90qzy7/what_salary_should_i_ask_for_ml/,omega-3s,1532194533,[removed],0,1
1130,2018-7-22,2018,7,22,3,90r711,AI Weekly 21 July 2018,https://www.reddit.com/r/MachineLearning/comments/90r711/ai_weekly_21_july_2018/,TomekB,1532196146,,0,1
1131,2018-7-22,2018,7,22,3,90r8qu,[N] Protecting the Intellectual Property of AI with Watermarking,https://www.reddit.com/r/MachineLearning/comments/90r8qu/n_protecting_the_intellectual_property_of_ai_with/,phobrain,1532196530,,1,1
1132,2018-7-22,2018,7,22,4,90rqog,Neural network playing Messenger soccer game,https://www.reddit.com/r/MachineLearning/comments/90rqog/neural_network_playing_messenger_soccer_game/,sudoman281,1532200553,,0,1
1133,2018-7-22,2018,7,22,5,90s3zp,"[D] Conditional Text Generation Using Structured Data / Sentences / Context Vectors. Comparing, Contrasting, and Combining these methods.",https://www.reddit.com/r/MachineLearning/comments/90s3zp/d_conditional_text_generation_using_structured/,Morninglow,1532203575,"The most relevant paper I could find was this one but I emailed the researchers aren't open sourcing the code.

""Neural Text Generation from Structured Data with Application to the Biography Domain""

arxiv: [https://arxiv.org/abs/1603.07771](https://arxiv.org/abs/1603.07771)

They condition the generation on a wikipedia info box but I do not know how.

The second paper I'm looking at conditions on the context of a conversation using the hidden state of a GRU

""Hierarchical Text Generation and Planning for Strategic Dialogue""

arxiv:  [https://arxiv.org/abs/1712.05846](https://arxiv.org/abs/1712.05846)

The third paper I'm looking at conditions generation on a prompt and has posted their code but I cannot find where it actually conditions the generation

""Hierarchical Neural Story Generation""

arxiv: [https://arxiv.org/abs/1805.04833](https://arxiv.org/abs/1805.04833)

So my primary problem is I don't know HOW the conditioning works besides the context vectors in which the hidden state of a context encoder is simply concatenated with the input of the of the generator (AFAIK).

What I want to do reminds me of Textworld: [https://microsoft.com/en-us/research/project/textworld/](https://microsoft.com/en-us/research/project/textworld/)

The key difference is that I want to generate new situations for agents to interact with within a predefined environment and have the outcomes effect the environment and generate new situations.

To accomplish this I think you would want structured data to represent the global environment (in text world the house and the things in it) that would condition the  allowable prompts / contexts the agent encounters to fit within a set of facts, and then a context vector or prompt to condition the local context and text that appears to be relevant to where the agent is in the environment and what they are doing.

What am I trying to do here? I believe it would be doubly hierarchical generation?",1,8
1134,2018-7-22,2018,7,22,5,90sfxh,[D] Any interest in a Paper-Discussion Twitch-stream?,https://www.reddit.com/r/MachineLearning/comments/90sfxh/d_any_interest_in_a_paperdiscussion_twitchstream/,LeanderKu,1532206391,"I am a CS Student at the KIT in Karlsruhe and every week I attend the local ML paper-discussions. I initiated one of them, which focuses more on the theory (the other is more practical and not as intensive). We are currently working our way through (https://arxiv.org/abs/1711.01530). We discuss the statements and try to do the proofs ourselves. Since the paper is quite difficult, we are making slow progress.

Recently came the not very serious idea to stream on twitch, but I wonder whether this would actually be interesting to anybody?",31,70
1135,2018-7-22,2018,7,22,5,90sggc,What is the best place to learn Python for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/90sggc/what_is_the_best_place_to_learn_python_for/,TheOpTicFanboy,1532206514,[removed],0,1
1136,2018-7-22,2018,7,22,7,90t1rw,Visualizing binary classification as a scoring problem,https://www.reddit.com/r/MachineLearning/comments/90t1rw/visualizing_binary_classification_as_a_scoring/,rohitpandey576,1532211636,,1,1
1137,2018-7-22,2018,7,22,7,90t431,Text Generation - A little help with direction,https://www.reddit.com/r/MachineLearning/comments/90t431/text_generation_a_little_help_with_direction/,Bigun139,1532212219,[removed],0,1
1138,2018-7-22,2018,7,22,7,90t74i,Text Message Classification,https://www.reddit.com/r/MachineLearning/comments/90t74i/text_message_classification/,[deleted],1532212985,,0,1
1139,2018-7-22,2018,7,22,7,90t9h5,AutoML in the cloud,https://www.reddit.com/r/MachineLearning/comments/90t9h5/automl_in_the_cloud/,lucasauger,1532213557,,0,1
1140,2018-7-22,2018,7,22,10,90u4l8,"DeepBrain Chain launch AI cloud network August 8th, do you have a need for cheap computing power?",https://www.reddit.com/r/MachineLearning/comments/90u4l8/deepbrain_chain_launch_ai_cloud_network_august/,[deleted],1532221418,,1,5
1141,2018-7-22,2018,7,22,11,90uthq,[D] What's currently the best pretrained model for detecting emotions in pictures?,https://www.reddit.com/r/MachineLearning/comments/90uthq/d_whats_currently_the_best_pretrained_model_for/,rta666888,1532228251,"I'm looking for something like [this](https://azure.microsoft.com/en-au/services/cognitive-services/emotion/), where it picks up specific emotions in faces, like how much anger or sadness is in that person's face. So something that picks up on the really fine details. Someone could be putting on a smile, but inside they could be sad and just putting on a front. When I mean the 'best' I mean the latest, most experimental ones which have shown the best results. I just want to see what's out there and compare the results. I also found [this](https://www.paralleldots.com/facial-emotion) but it seemed a bit less consistent at being able to find faces in the photos I gave it. ",10,21
1142,2018-7-22,2018,7,22,12,90v6af,"Receptive field estimation for Keras, Tensorflow and Pytorch with multiple features map support.",https://www.reddit.com/r/MachineLearning/comments/90v6af/receptive_field_estimation_for_keras_tensorflow/,kmkolasinski,1532231993,,1,2
1143,2018-7-22,2018,7,22,13,90v8bl,The Significance of Poisson Distribution in Statistics | Hashtag Statistics,https://www.reddit.com/r/MachineLearning/comments/90v8bl/the_significance_of_poisson_distribution_in/,LearningFromData,1532232615,,0,1
1144,2018-7-22,2018,7,22,13,90vea0,Data set creation when I dont know true labels,https://www.reddit.com/r/MachineLearning/comments/90vea0/data_set_creation_when_i_dont_know_true_labels/,FragLegs,1532234511,[removed],0,1
1145,2018-7-22,2018,7,22,14,90vlx0,[D] What is so special about GANs applied to images? Many non-learning image processing techniques can do the same thing.,https://www.reddit.com/r/MachineLearning/comments/90vlx0/d_what_is_so_special_about_gans_applied_to_images/,WhiteBear2018,1532237027,"I'm just starting to get into machine learning, and I have a lot of questions. This is a simple question and I'm looking for simple answers, so it might be more suitable to ELI5 or some other subreddit...however, I think this topic is still specialized enough that going to the machine learning subreddit is best. Let me know if I should post elsewhere.

I was reading an article where the author was raving about CycleGAN. They showed some images of zebras to horses, photograph to Monet. (Figure 1 in [https://arxiv.org/pdf/1703.10593.pdf](https://arxiv.org/pdf/1703.10593.pdf))

I don't understand what is so special though. For zebra to horses, I can just write something that changes grayscale colors to brown. Filters and blurs and other effects, applied well, can result in a photograph to Monet effect (e.g. [https://sleeklens.com/how-to-add-an-impressionist-look-to-your-photos-using-photoshop/](https://sleeklens.com/how-to-add-an-impressionist-look-to-your-photos-using-photoshop/)).

Could someone explain what is so special about using machine learning to do this?",14,2
1146,2018-7-22,2018,7,22,15,90vwjl,ProGAN trained on LFW dataset using PyTorch,https://www.reddit.com/r/MachineLearning/comments/90vwjl/progan_trained_on_lfw_dataset_using_pytorch/,[deleted],1532240834,[deleted],0,1
1147,2018-7-22,2018,7,22,15,90vx12,[P] ProGAN trained on LFW dataset using PyTorch,https://www.reddit.com/r/MachineLearning/comments/90vx12/p_progan_trained_on_lfw_dataset_using_pytorch/,akanimax,1532241029,,0,1
1148,2018-7-22,2018,7,22,15,90w03j,What is machine learning (ML) &amp; how it works? Is ML over rated? Differen...,https://www.reddit.com/r/MachineLearning/comments/90w03j/what_is_machine_learning_ml_how_it_works_is_ml/,[deleted],1532242262,[deleted],0,1
1149,2018-7-22,2018,7,22,16,90w1q0,What is machine learning (ML) &amp; how it works? Is ML over rated? Difference between Artificial Intelligence and Machine Learning!,https://www.reddit.com/r/MachineLearning/comments/90w1q0/what_is_machine_learning_ml_how_it_works_is_ml/,iamparameswaran,1532242868,,0,1
1150,2018-7-22,2018,7,22,16,90w1t3,[P] Using AI in League of Legends to Improve my Team's Decision Making (feedback request),https://www.reddit.com/r/MachineLearning/comments/90w1t3/p_using_ai_in_league_of_legends_to_improve_my/,osbornep,1532242897,"Hi All,

I have recently posted the following article:

[https://towardsdatascience.com/ai-in-video-games-improving-decision-making-in-league-of-legends-using-real-match-statistics-and-29ebc149b0d0](https://towardsdatascience.com/ai-in-video-games-improving-decision-making-in-league-of-legends-using-real-match-statistics-and-29ebc149b0d0)

In this project, I took real match statistics and attempted to model it as an MDP and then apply reinforcement learning in order to find the next best play for long term success.

I have also posted all of my working in three parts on Kaggle:

[https://www.kaggle.com/osbornep/lol-ai-model-part-1-initial-eda-and-first-mdp](https://www.kaggle.com/osbornep/lol-ai-model-part-1-initial-eda-and-first-mdp)

[https://www.kaggle.com/osbornep/lol-ai-model-part-2-redesign-mdp-with-gold-diff](https://www.kaggle.com/osbornep/lol-ai-model-part-2-redesign-mdp-with-gold-diff)

[https://www.kaggle.com/osbornep/lol-ai-model-part-3-final-output](https://www.kaggle.com/osbornep/lol-ai-model-part-3-final-output)

I will be trying to share with the league subreddit to see how they feel about this kind of idea but would appreciate your thoughts on whether this makes sense and if my model is applied correctly.

Thanks",36,84
1151,2018-7-22,2018,7,22,16,90w7wh,[P] Making Amazon Alexa Respond to Sign Language,https://www.reddit.com/r/MachineLearning/comments/90w7wh/p_making_amazon_alexa_respond_to_sign_language/,trcytony,1532245284,,0,1
1152,2018-7-22,2018,7,22,17,90wbiu,Finished Andrew Ng's free Machine Learning course in Coursera. Now what?,https://www.reddit.com/r/MachineLearning/comments/90wbiu/finished_andrew_ngs_free_machine_learning_course/,Lintash,1532246708,[removed],0,1
1153,2018-7-22,2018,7,22,17,90wc0e,Presenting results from a classification problem,https://www.reddit.com/r/MachineLearning/comments/90wc0e/presenting_results_from_a_classification_problem/,appukkili,1532246883,[removed],0,1
1154,2018-7-22,2018,7,22,18,90wk2l,How to lie with Data Science,https://www.reddit.com/r/MachineLearning/comments/90wk2l/how_to_lie_with_data_science/,sudo_su_,1532250216,,0,1
1155,2018-7-22,2018,7,22,18,90wrlq,Invariant Information Distillation for Unsupervised Image Segmentation and Clustering https://arxiv.org/abs/1807.06653,https://www.reddit.com/r/MachineLearning/comments/90wrlq/invariant_information_distillation_for/,[deleted],1532253440,,0,1
1156,2018-7-22,2018,7,22,19,90ws96,My New Youtube Channel with Python tutorials: check it out!,https://www.reddit.com/r/MachineLearning/comments/90ws96/my_new_youtube_channel_with_python_tutorials/,BurakCeresa,1532253711,[removed],0,1
1157,2018-7-22,2018,7,22,19,90wuyf,Invariant Information Distillation for Unsupervised Image Segmentation and Clustering,https://www.reddit.com/r/MachineLearning/comments/90wuyf/invariant_information_distillation_for/,ABraveNewWorld2,1532254833,,13,19
1158,2018-7-22,2018,7,22,20,90x5f4,Who is Vincent Boucher?,https://www.reddit.com/r/MachineLearning/comments/90x5f4/who_is_vincent_boucher/,mibca,1532258972,[removed],0,1
1159,2018-7-22,2018,7,22,22,90xpb6,[Discussion] Why do people use SGD/RMSProp or any other optimizer when Adam gives adaptive learning rate for every single parameter?,https://www.reddit.com/r/MachineLearning/comments/90xpb6/discussion_why_do_people_use_sgdrmsprop_or_any/,CSGOvelocity,1532265720,"I have seen many research papers use SGD and RMSProp in place of Adam.   
By my knowledge adam is considered to be the best and the best default choice.

Moreover, since adam offers adaptive learning rate for every single parameter I see no point why anyone would use any other optimizer. Please enlighten me fellow machine learning scientists.  
",16,6
1160,2018-7-23,2018,7,23,0,90yft3,Using AI for image super resolution,https://www.reddit.com/r/MachineLearning/comments/90yft3/using_ai_for_image_super_resolution/,zhitao654321,1532272778,[removed],0,1
1161,2018-7-23,2018,7,23,0,90yidb,7 Machine Learning Algorithms To Start Learning.,https://www.reddit.com/r/MachineLearning/comments/90yidb/7_machine_learning_algorithms_to_start_learning/,asifrazzaq1988,1532273403,,0,1
1162,2018-7-23,2018,7,23,1,90yqrq,Lessons From Implementing AlphaZero - Oracle Developers,https://www.reddit.com/r/MachineLearning/comments/90yqrq/lessons_from_implementing_alphazero_oracle/,FulgoreX,1532275362,,0,1
1163,2018-7-23,2018,7,23,1,90z4aj,"Voice Tech Podcast #006 - Deaf Person Calling - Benjamin Etienne, Rogervoice",https://www.reddit.com/r/MachineLearning/comments/90z4aj/voice_tech_podcast_006_deaf_person_calling/,wootnoob,1532278427,"Hi all, in my latest podcast episode I talk with data scientist Benjamin Etienne of Rogervoice, an innovative voice technology company that helps deaf and hard-of-hearing people to use the telephone. 

Ben shares his inspirational story about how he taught himself data science, then we delve into speech-to-text, machine learning for audio, and how our brain waves synchonise with the voices of others. 

[https://voicetechpodcast.com/episodes/006-deaf-person-calling-benjamin-etienne-rogervoice-voice-tech-podcast/](https://voicetechpodcast.com/episodes/006-deaf-person-calling-benjamin-etienne-rogervoice-voice-tech-podcast/)",0,1
1164,2018-7-23,2018,7,23,2,90z8ds,[D] Question about calculating values of Advantage functions using eligibility traces,https://www.reddit.com/r/MachineLearning/comments/90z8ds/d_question_about_calculating_values_of_advantage/,schrodingershit,1532279303,,0,2
1165,2018-7-23,2018,7,23,3,90zpmp,Hackathon ideas?,https://www.reddit.com/r/MachineLearning/comments/90zpmp/hackathon_ideas/,getwritenow,1532283066,[removed],0,1
1166,2018-7-23,2018,7,23,4,9103y0,Most adaptable machine learner?,https://www.reddit.com/r/MachineLearning/comments/9103y0/most_adaptable_machine_learner/,Drag0nDr0p,1532286184,[removed],0,1
1167,2018-7-23,2018,7,23,5,910jmh,[D] Machine Learning - WAYR (What Are You Reading) - Week 47,https://www.reddit.com/r/MachineLearning/comments/910jmh/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1532289605,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)||

Most upvoted papers two weeks ago:

/u/Dreeseaw: [The FiLM model](https://arxiv.org/pdf/1709.07871.pdf)

/u/MTGTraner: [drlim](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)

/u/MrLeylo: [A Meta-Learning Approach to One-Step Active-Learning](https://arxiv.org/pdf/1706.08334.pdf)

Besides that, there are no rules, have fun.",28,127
1168,2018-7-23,2018,7,23,5,910n9q,[D] What do you do when you are asked to add machine learning to a project and they don't give you objectives or proper data?,https://www.reddit.com/r/MachineLearning/comments/910n9q/d_what_do_you_do_when_you_are_asked_to_add/,FellowOfHorses,1532290375,Some colleagues were asked to do some machine learning for a project. The data provided wasn't really interesting. Around 200 points of almost linear data and not really the data my colleagues requested. They did some simple neural network and put some pretty graphs when presenting the project. Have any of you passed for similar events?,40,84
1169,2018-7-23,2018,7,23,5,910qi3,[P] DCGAN implementation with tf.keras and TensorFlow eager,https://www.reddit.com/r/MachineLearning/comments/910qi3/p_dcgan_implementation_with_tfkeras_and/,SupraluminalShift,1532291097,,0,5
1170,2018-7-23,2018,7,23,5,910um9,[D] Gradient boosting/ML libraries for Spark - What do you use?,https://www.reddit.com/r/MachineLearning/comments/910um9/d_gradient_boostingml_libraries_for_spark_what_do/,Nikota,1532292020,"I've been working on a few projects lately using Gradient Boosted Trees for regression and classification in Scala Spark, but compared to Python I'm a little disappointed with the options. I've had the best results from Azure/mmlspark LightGBM, but that library is relatively new and still has some issues to work out (specifically around cross-system compatibility; the only way I can test ""run"" the model on OSX is to assemble a fat jar and run inside a docker container). I've also tried SparkML GBT models but those are incredibly slow and had disappointing accuracy (maybe due to parameter tuning taking far too long). I haven't yet tried xgboost4j.

Has anyone else had experience implementing these pipelines in Spark, and have you found reasonable performance/accuracy with any particular libraries?",7,5
1171,2018-7-23,2018,7,23,6,9111pw,Named-entity recognition,https://www.reddit.com/r/MachineLearning/comments/9111pw/namedentity_recognition/,shashank2806,1532293553,,0,1
1172,2018-7-23,2018,7,23,6,91154m,[Project]Named-entity recognition,https://www.reddit.com/r/MachineLearning/comments/91154m/projectnamedentity_recognition/,shashank2806,1532294311,"I am working on a NER(Named-entity recognition) but I don' t have labelled data. Can I do NER with unlabelled data?

If not, then should I label some data and use transfer learning or should I use a pre-trained model?  ",3,2
1173,2018-7-23,2018,7,23,8,9125z7,Artificial Intelligence in Medicine | The Top 4 Applications,https://www.reddit.com/r/MachineLearning/comments/9125z7/artificial_intelligence_in_medicine_the_top_4/,datarevenue_berlin,1532302792,,0,1
1174,2018-7-23,2018,7,23,10,912qs5,question about OSes and drivers,https://www.reddit.com/r/MachineLearning/comments/912qs5/question_about_oses_and_drivers/,cdin,1532307962,[removed],0,1
1175,2018-7-23,2018,7,23,10,912s11,Durk Kingma has left OpenAI,https://www.reddit.com/r/MachineLearning/comments/912s11/durk_kingma_has_left_openai/,ai_throwaway789,1532308263,,0,1
1176,2018-7-23,2018,7,23,12,913m8d,From R-CNN to Faster R-CNN  The Evolution of Object Detection Technology,https://www.reddit.com/r/MachineLearning/comments/913m8d/from_rcnn_to_faster_rcnn_the_evolution_of_object/,Michael_Pa,1532315914,,0,1
1177,2018-7-23,2018,7,23,12,913sij,Lessons Learned at the 2017 CIKM AnalytiCup Machine Learning Competition,https://www.reddit.com/r/MachineLearning/comments/913sij/lessons_learned_at_the_2017_cikm_analyticup/,Michael_Pa,1532317597,,0,1
1178,2018-7-23,2018,7,23,12,913v8q,Durk Kingma has left OpenAI,https://www.reddit.com/r/MachineLearning/comments/913v8q/durk_kingma_has_left_openai/,ai_throwaway789,1532318352,,0,1
1179,2018-7-23,2018,7,23,13,913wh8,[P] ProGAN trained on LFW dataset using PyTorch,https://www.reddit.com/r/MachineLearning/comments/913wh8/p_progan_trained_on_lfw_dataset_using_pytorch/,akanimax,1532318663,,0,0
1180,2018-7-23,2018,7,23,13,913wnu,Microsoft AI Residency Admits,https://www.reddit.com/r/MachineLearning/comments/913wnu/microsoft_ai_residency_admits/,yesmaybe3,1532318713,[removed],0,1
1181,2018-7-23,2018,7,23,13,913yhv,[D] SOTA unsupervised extractive summarization method,https://www.reddit.com/r/MachineLearning/comments/913yhv/d_sota_unsupervised_extractive_summarization/,HigherTopoi,1532319203,"I'm seeking for an unsupervised extractive summarization method that has the highest compression rate. The readability or naturalness of the summary doesn't really matter, but it matters that the summary contains as much 'relevant information' as possible. There are many neural or non-neural extractive methods whose ROUGE is not much better than copying the first several sentences or tf-idf. Given that, I'd like your opinion about the best performing unsupervised extractive method that significantly outperforms tf-idf. ",0,1
1182,2018-7-23,2018,7,23,13,91442p,Python package for Progressively Growing GAN in PyTorch,https://www.reddit.com/r/MachineLearning/comments/91442p/python_package_for_progressively_growing_gan_in/,akanimax,1532320760,[removed],0,1
1183,2018-7-23,2018,7,23,13,9144bn,[P] Python package for Progressively Growing GAN in PyTorch,https://www.reddit.com/r/MachineLearning/comments/9144bn/p_python_package_for_progressively_growing_gan_in/,akanimax,1532320824,"Hi all! I created a python package for spawning and training GAN architecture as described in the ""Progressive Growing"" paper.

check out the link -&gt; https://github.com/akanimax/pro_gan_pytorch The package includes: 1.) Unconditional and conditional versions of the ProGAN. 2.) Loss functions include ""WGAN"", ""WGAN-GP"" and ""LSGAN"". 3.) Loss function interface can be extended to create your own loss function and plug in the architecture. 4.) Contains few PyTorch layers extended to conform to the equalized learning rate concept mentioned in the paper.

Examples trained using this package can be found here -&gt; https://github.com/akanimax/pro_gan_pytorch-examples

I will be working on including the Relativistic loss functions to this package for more experimentation.",2,2
1184,2018-7-23,2018,7,23,13,91467l,Trying to understand practical implications of no free lunch theorem on ML [D],https://www.reddit.com/r/MachineLearning/comments/91467l/trying_to_understand_practical_implications_of_no/,spongiey,1532321346,"I spent some time trying to reconcile the implications of the no free lunch theorem on ML and I came to the conclusion that there is little practical significance. I wound up writing this blog post to get a better understanding of the theorem: http://blog.tabanpour.info/projects/2018/07/20/no-free-lunch.html

In light of the theorem, I'm still not sure how we actually ensure that models align well with the data generating functions f for our models to truly generalize (please don't say cross validation or regularization if you don't look at the theorem). 

Are we just doing lookups and never truly generalizing? What assumptions in practice are we actually making about the data generating distribution that helps us generalize? Let's take imagenet models as an example. ",23,39
1185,2018-7-23,2018,7,23,13,914764,Which Macbook Pro 2018 would be the best for Machine Learning and Deep Neural Nets.,https://www.reddit.com/r/MachineLearning/comments/914764/which_macbook_pro_2018_would_be_the_best_for/,PastelKangaroo,1532321627,[removed],0,1
1186,2018-7-23,2018,7,23,14,914ban,How Will We Feel in the Machine Age?  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/914ban/how_will_we_feel_in_the_machine_age_coinmonks/,coinmonks,1532322785,,0,1
1187,2018-7-23,2018,7,23,15,914ko8,How to get a single value out of a confusion matrix?,https://www.reddit.com/r/MachineLearning/comments/914ko8/how_to_get_a_single_value_out_of_a_confusion/,soulslicer0,1532325622,[removed],0,1
1188,2018-7-23,2018,7,23,15,914mcl,[R] A survey on policy search algorithms for learning robot controllers in a handful of trials,https://www.reddit.com/r/MachineLearning/comments/914mcl/r_a_survey_on_policy_search_algorithms_for/,baylearn,1532326157,,1,11
1189,2018-7-23,2018,7,23,15,914pkl,ID2223  Deep Learning on Big Data at KTH,https://www.reddit.com/r/MachineLearning/comments/914pkl/id2223_deep_learning_on_big_data_at_kth/,jpdowlin,1532327201,,0,1
1190,2018-7-23,2018,7,23,16,91504y,The World Of Self Driven Cars Is Truly Here - Infographics,https://www.reddit.com/r/MachineLearning/comments/91504y/the_world_of_self_driven_cars_is_truly_here/,imarticus_nirmal,1532330597,,0,1
1191,2018-7-23,2018,7,23,16,9151ao,Tips for building fast portrait segmentation network with TensorFlow Lite,https://www.reddit.com/r/MachineLearning/comments/9151ao/tips_for_building_fast_portrait_segmentation/,CoreaHS,1532330988,,0,2
1192,2018-7-23,2018,7,23,16,91524n,LangSchool - The new Youtube Channel about AI and stuff,https://www.reddit.com/r/MachineLearning/comments/91524n/langschool_the_new_youtube_channel_about_ai_and/,bigdatafan001,1532331270,,0,1
1193,2018-7-23,2018,7,23,16,9156ag,5 Application of Machine Learning in Today's Business,https://www.reddit.com/r/MachineLearning/comments/9156ag/5_application_of_machine_learning_in_todays/,Certbuddyz,1532332663,,0,1
1194,2018-7-23,2018,7,23,16,9156cq,GOTURN : Deep Learning based Object Tracking (C++/Python Tutorial),https://www.reddit.com/r/MachineLearning/comments/9156cq/goturn_deep_learning_based_object_tracking/,spmallick,1532332689,,0,1
1195,2018-7-23,2018,7,23,17,915784,Understanding CapsNet,https://www.reddit.com/r/MachineLearning/comments/915784/understanding_capsnet/,delpotroswrist,1532332980,[removed],0,1
1196,2018-7-23,2018,7,23,17,915gls,"Self-attention and ""Attention is all you need"" article",https://www.reddit.com/r/MachineLearning/comments/915gls/selfattention_and_attention_is_all_you_need/,albert1905,1532336330,"Hi guys, I'm learning ""Attention is all you need"", and I'm having a hard time, to understand self-attention.
I understood that self-attention allows the model to look at other positions in the input sequence when he processes a certain word.
But I don't understand how I can see it in the math?
Let's look after the embedding step and the linear (of the multi-Head attention),I'm multiplying each word embedding vector with the same word embedding vector (just after different linear layer). so how does the self-attention helps  to look at other positions in the input sequence???

Please help me understand this Idea.

Thanks.
",0,1
1197,2018-7-23,2018,7,23,18,915k5f,My YouTube channel with Python tutorials!,https://www.reddit.com/r/MachineLearning/comments/915k5f/my_youtube_channel_with_python_tutorials/,BurakCeresa,1532337522,"This channel will be covering tutorials about the use of certain python libraries (e.g fasttext, gensim, beautifulsoup...). Check it out!!!

link to the fasttext tutorial:

https://www.youtube.com/watch?v=tQvghqdefTM",0,1
1198,2018-7-23,2018,7,23,18,915kan,Why Mobile Marketers Need to Learn Machine Learning Basics,https://www.reddit.com/r/MachineLearning/comments/915kan/why_mobile_marketers_need_to_learn_machine/,vijayCT,1532337569,,0,1
1199,2018-7-23,2018,7,23,18,915kpa,Open to ideas/Innovation,https://www.reddit.com/r/MachineLearning/comments/915kpa/open_to_ideasinnovation/,Lag_Blamer,1532337701,"I'm a 4th year B.Tech CS student in India. I along with 3 others want to do a major project on Machine Learning or Artificial Intelligence. We are not professional developers but I'd say a bit above mediocre. Unfortunately we can't think of anything good or which is useful in the industry or helpful to humanity. The duration of our project is approximately 5 months.  This project is even going to take a huge toll on our future career. So, if anyone is okay with providing some ideas for the project, we will be grateful forever. We promise that we will work very hard and put all our souls into this. It'd be very helpful to us if you give as much information as possible, i.e tools etc:",0,1
1200,2018-7-23,2018,7,23,18,915mfx,[D]Open to ideas/innovation,https://www.reddit.com/r/MachineLearning/comments/915mfx/dopen_to_ideasinnovation/,Lag_Blamer,1532338321,"I'm a 4th year B.Tech CS student in India. I along with 3 others want to do a major project on Machine Learning or Artificial Intelligence. We are not professional developers but I'd say a bit above mediocre. Unfortunately we can't think of anything good or which is useful in the industry or helpful to humanity. The duration of our project is approximately 5 months.  This project is even going to take a huge toll on our future career. So, if anyone is OKAY with providing some ideas for the project, we will be grateful forever. We promise that we will work very hard and put all our souls into this. It'd be very helpful to us if you give as much information as possible, i.e papers, tools etc;",4,0
1201,2018-7-23,2018,7,23,18,915o3q,[P] Tracking Progress in Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/915o3q/p_tracking_progress_in_natural_language_processing/,pmigdal,1532338883,,7,71
1202,2018-7-23,2018,7,23,19,915ypk,[P] Advice on Sketch-based Object Recognition,https://www.reddit.com/r/MachineLearning/comments/915ypk/p_advice_on_sketchbased_object_recognition/,webhistories,1532342307,"Hello,

I am a Computer Science student and I'm planning to create a mobile application that detects specific details on human figure sketches made by children. The app will score the drawings according to detected details. This will be used to help in a psychometrics tool. 

I've been looking around everywhere for demos to see if what I have in mind is feasible. What I specifically look for is an object detector API or algorithm that detects **multiple** objects in an image. For example in human sketch, it can detect if the eyes, nose or ears are present. I've seen one [paper](https://www.cs.ucsb.edu/~sherwood/pubs/SBIM-10-figures.pdf) discussing this but I'm not sure how they did it. 

I appreciate any help I can get from this sub, thanks!",4,7
1203,2018-7-23,2018,7,23,19,91606n,What is best Machine Learning Algorithm for Comprehension Reading,https://www.reddit.com/r/MachineLearning/comments/91606n/what_is_best_machine_learning_algorithm_for/,Sachin_Ichake,1532342768,[removed],0,1
1204,2018-7-23,2018,7,23,20,916342,Are we really ok with AI making art?,https://www.reddit.com/r/MachineLearning/comments/916342/are_we_really_ok_with_ai_making_art/,chittybanggo,1532343654,[removed],0,1
1205,2018-7-23,2018,7,23,20,9164m4,2018s Human-Centric Mobile Trends: Low Code vs. No Code,https://www.reddit.com/r/MachineLearning/comments/9164m4/2018s_humancentric_mobile_trends_low_code_vs_no/,DMI2002,1532344070,,1,1
1206,2018-7-23,2018,7,23,20,9166bf,[N] Practical Apache Spark in 10 minutes. Part 4,https://www.reddit.com/r/MachineLearning/comments/9166bf/n_practical_apache_spark_in_10_minutes_part_4/,molode,1532344565,,0,1
1207,2018-7-23,2018,7,23,20,91692h,how to use my python scripts in my website?,https://www.reddit.com/r/MachineLearning/comments/91692h/how_to_use_my_python_scripts_in_my_website/,code_bot,1532345315,[removed],0,1
1208,2018-7-23,2018,7,23,21,916ik8,Emoji recognition project,https://www.reddit.com/r/MachineLearning/comments/916ik8/emoji_recognition_project/,wearefarming101,1532347881,[removed],0,1
1209,2018-7-23,2018,7,23,21,916izs,Commercial Carrot Potato Cutting Machine,https://www.reddit.com/r/MachineLearning/comments/916izs/commercial_carrot_potato_cutting_machine/,liusherry,1532348000,,0,1
1210,2018-7-23,2018,7,23,21,916jq3,Machine Learning Open Source of the Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/916jq3/machine_learning_open_source_of_the_month_vjuly/,kumeralex,1532348179,,0,1
1211,2018-7-23,2018,7,23,21,916ktx,[P] Torchbearer: Model training library for DL reseacrh in PyTorch,https://www.reddit.com/r/MachineLearning/comments/916ktx/p_torchbearer_model_training_library_for_dl/,ethanwharris,1532348462,"[github.com/ecs-vlc/torchbearer](https://github.com/ecs-vlc/torchbearer)

At the University of Southampton we have been working on torchbearer: a PyTorch library to aid our deep learning research. We've made it public and are committed to actively developing it and making it better. If it's useful to you, fantastic, we're glad you like it. If there is something you would like added or think could be better, feel free to raise an issue or a PR and we'll see what we can do.",14,15
1212,2018-7-23,2018,7,23,21,916kvp,[R] Common data science pitfalls and how to avoid them,https://www.reddit.com/r/MachineLearning/comments/916kvp/r_common_data_science_pitfalls_and_how_to_avoid/,chris_shpak,1532348474,,0,1
1213,2018-7-23,2018,7,23,21,916l8h,Machine Learning Open Source of the Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/916l8h/machine_learning_open_source_of_the_month_vjuly/,kumeralex,1532348562,,0,1
1214,2018-7-23,2018,7,23,21,916m5z,Machine Learning Open Source of the Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/916m5z/machine_learning_open_source_of_the_month_vjuly/,iamjackblackman,1532348786,,0,1
1215,2018-7-23,2018,7,23,21,916mys,Machine Learning Open Source of the Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/916mys/machine_learning_open_source_of_the_month_vjuly/,ccGardnerr,1532348987,,0,1
1216,2018-7-23,2018,7,23,21,916s9a,Machine Learning Open Source of the Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/916s9a/machine_learning_open_source_of_the_month_vjuly/,kumeralex,1532350192,,0,2
1217,2018-7-23,2018,7,23,22,916x3d,Machine Learning Open Source of the Month (v.July 2018),https://www.reddit.com/r/MachineLearning/comments/916x3d/machine_learning_open_source_of_the_month_vjuly/,kumeralex,1532351347,,0,1
1218,2018-7-23,2018,7,23,22,917131,Augmented Analytics That Will Ensure Business User Adoption,https://www.reddit.com/r/MachineLearning/comments/917131/augmented_analytics_that_will_ensure_business/,ElegantMicroWebIndia,1532352272,,0,1
1219,2018-7-23,2018,7,23,22,9176fu,Soft skills for data scientists,https://www.reddit.com/r/MachineLearning/comments/9176fu/soft_skills_for_data_scientists/,edunuke,1532353485,[removed],0,2
1220,2018-7-23,2018,7,23,22,9178mt,"[N] TensorboardX, NLP Best Practices, Cirq, Subjectivity in AI, EmojiTalk, Seq-to-Seq Debugging, Data Portability,",https://www.reddit.com/r/MachineLearning/comments/9178mt/n_tensorboardx_nlp_best_practices_cirq/,omarsar,1532353976,,0,1
1221,2018-7-23,2018,7,23,23,917e8b,Comparison of Top 6 Python NLP Libraries,https://www.reddit.com/r/MachineLearning/comments/917e8b/comparison_of_top_6_python_nlp_libraries/,viktoriia_shulga,1532355157,,0,13
1222,2018-7-23,2018,7,23,23,917fnx,Durk Kingma (author of Adam &amp; VAE) has left OpenAI,https://www.reddit.com/r/MachineLearning/comments/917fnx/durk_kingma_author_of_adam_vae_has_left_openai/,ai_throwaway789,1532355452,,0,1
1223,2018-7-23,2018,7,23,23,917kqb,[SPANISH] Discusiones de equipos reales sobre Machine Learning en Ecommerce &amp; Fintech,https://www.reddit.com/r/MachineLearning/comments/917kqb/spanish_discusiones_de_equipos_reales_sobre/,mark-g-s,1532356517,,0,1
1224,2018-7-24,2018,7,24,0,917rzf,[R] Joint-Contrastive Inference and Cycle GANs,https://www.reddit.com/r/MachineLearning/comments/917rzf/r_jointcontrastive_inference_and_cycle_gans/,LucaAmbrogioni,1532358025,,7,64
1225,2018-7-24,2018,7,24,0,917uf8,Tutorial: Learn How to Extract Features from Text using Python!,https://www.reddit.com/r/MachineLearning/comments/917uf8/tutorial_learn_how_to_extract_features_from_text/,Amir_PD,1532358493,,0,1
1226,2018-7-24,2018,7,24,0,917wo8,[D] What is the best algorithm to use for determining the better outcome between two sets of data?,https://www.reddit.com/r/MachineLearning/comments/917wo8/d_what_is_the_best_algorithm_to_use_for/,OnAComputer,1532358941,"I have two sets of data that I am trying to determine, between the two which gives us a more ideal outcome.

For example, I have two different ads with these outcomes over an hour:


Impressions | Ad Starts | Ad Finish | Clicks | CTR
-----------|---------|---------|------|---
1111 | 526 | 496 | 85 | 7.7%
2087 | 900 | 518 | 35 | 1.7%

I want to know which one of these ads is better.

So right now, I am trying to use logistic regression and ratios between different types of variables to give me a single vector.

Is there a specific algorithm or better way of addressing this type of problem?

Thank you!",8,2
1227,2018-7-24,2018,7,24,0,917xbs,[P] Singing Style Transfer Using CybeGAN,https://www.reddit.com/r/MachineLearning/comments/917xbs/p_singing_style_transfer_using_cybegan/,tuan3w,1532359069,,0,13
1228,2018-7-24,2018,7,24,0,917zc1,[D] Model consistency of Python gradient boosting libraries,https://www.reddit.com/r/MachineLearning/comments/917zc1/d_model_consistency_of_python_gradient_boosting/,s0ulmate,1532359485,,0,6
1229,2018-7-24,2018,7,24,0,917zl5,Jupyter notebook demonstrating training TF Keras models on Google Colab and Google drive,https://www.reddit.com/r/MachineLearning/comments/917zl5/jupyter_notebook_demonstrating_training_tf_keras/,sibyjackgrove,1532359531,[removed],0,1
1230,2018-7-24,2018,7,24,0,9180g7,[D] What is your workflow for developing remotely?,https://www.reddit.com/r/MachineLearning/comments/9180g7/d_what_is_your_workflow_for_developing_remotely/,LongNeighborhood9,1532359705,"Disclaimer: I hope this is relevant for this sub, as a student I wanted to see a discussion of how people work.

I have access to an always-up university cluster and do everything on a remote server. I use Emacs's Tramp package to edit files on the server and have an always running SSH connection to the server for bash, IPython, and even jupyter notebooks (accessed on my browser via SSH tunneling).

This workflow fails whenever I have no stable internet connection, and also does not translate well to billed-by-the-minute services like AWS. What is your workflow for doing ML research and experiments? Do you first test locally and then push everything to the server (if so, what do you use for this? Ex: git, rsync, etc.) and run experiments there or do you live on the server as I do?",50,85
1231,2018-7-24,2018,7,24,1,918cca,Does Adding One Neuron Help Real World Networks?,https://www.reddit.com/r/MachineLearning/comments/918cca/does_adding_one_neuron_help_real_world_networks/,thonic,1532362007,,0,3
1232,2018-7-24,2018,7,24,1,918dv3,[D] Is the conditional GAN framework suitable for non-linear regression?,https://www.reddit.com/r/MachineLearning/comments/918dv3/d_is_the_conditional_gan_framework_suitable_for/,ortix92,1532362309,"Obviously GAN's are well known for their ability to generate all kinds of pictures, but many of the literature I have come across applies these models in the image domain. Aside from some time series literature, I have yet to come across an application in function approximation.

This is currently what I am dealing with for my master thesis and I can't seem to get it to work properly. Worst of all, validating the model is difficult during training. I can only generate figures of data distributions and dependencies (to see if the generated data makes sense, which it most certainly does), but I can only test the model with the simulation after training which gives bad results. 

Either I am doing something wrong, or the GAN is simply not suitable for this task. Before I give up I would like some advice on this matter.

Hence my question whether it is usable in this setting, since so far I've been getting bad results. My problem is described below.

I have a dataset of 8 targets and 12 labels. All values are real and continuous. These data points are essentially robotic joint trajectories, corresponding control action, the trajectory time and the cost.

My target variables are the control actions, the time and the cost. The labels are the (short) trajectories which are the initial angles and the final angles (nothing in between). All values range between -1 and 1.

I'm using a conditional Least Squares GAN (LSGAN) with MLP layers. I've tried many architectures and spent weeks tuning hyperparameters to no avail.

1. Is the GAN even suitable for learning a function for a dynamical system?
2. I am concatenating the noise with the labels at the generator side and the samples with the labels at the discriminator side. Does that make sense? 
3. Since my problem is so low dimensional, how large should my noise vector be?
4. What are some ways to test my model with conditional toy data sets? This way I can validate that my model works (it does for MNIST).

Any advice?
",2,7
1233,2018-7-24,2018,7,24,1,918foe,[P] Keras implementation of End-to-End Neural Speaker Embedding (DeepSpeaker),https://www.reddit.com/r/MachineLearning/comments/918foe/p_keras_implementation_of_endtoend_neural_speaker/,SupraluminalShift,1532362666,,0,1
1234,2018-7-24,2018,7,24,1,918lt8,Is there any extensive audio dataset which has audio recording of ambiances of various places?,https://www.reddit.com/r/MachineLearning/comments/918lt8/is_there_any_extensive_audio_dataset_which_has/,ByMAster2,1532363846,[removed],0,1
1235,2018-7-24,2018,7,24,1,918rj9,Using Google satellite imagery for a CNN.,https://www.reddit.com/r/MachineLearning/comments/918rj9/using_google_satellite_imagery_for_a_cnn/,spacegazelle,1532364949,[removed],0,1
1236,2018-7-24,2018,7,24,2,918zqv,Microsoft AI Residency Admits,https://www.reddit.com/r/MachineLearning/comments/918zqv/microsoft_ai_residency_admits/,yesmaybe3,1532366454,[removed],0,1
1237,2018-7-24,2018,7,24,2,9190hy,"I Made An /r/EarthPorn GAN, And It Works In The Browser Using tensorflow.js",https://www.reddit.com/r/MachineLearning/comments/9190hy/i_made_an_rearthporn_gan_and_it_works_in_the/,manicman1999,1532366598,[removed],0,1
1238,2018-7-24,2018,7,24,2,9192g4,Does AI have a future in the courts?,https://www.reddit.com/r/MachineLearning/comments/9192g4/does_ai_have_a_future_in_the_courts/,Zantetsukan,1532366945,[removed],0,1
1239,2018-7-24,2018,7,24,2,919awj,[D] Ideas for my first(or second) ever Machine Learning project using Tensorflow.,https://www.reddit.com/r/MachineLearning/comments/919awj/d_ideas_for_my_firstor_second_ever_machine/,nisu_srk,1532368572,"I used Tensorflow to complete an assignment from CS231n course from Stanford. Basically, I implemented two-layer fully connected layers and three layer convolutional network using (1) Barebone Tensorflow, (2) Using Keras API and (3) Using Keras Sequential API.

The task was to classify CIFAR-10 images and the average accuracy in the neural networks was 40-50%. What should my next project be, now that I understand how to stack the layers? I'm looking to explore more into computer vision (object detection, image captioning etc.) and NLP. ",1,0
1240,2018-7-24,2018,7,24,3,919l6e,ONNX Model Zoo: Developing a face recognition application with ONNX models,https://www.reddit.com/r/MachineLearning/comments/919l6e/onnx_model_zoo_developing_a_face_recognition/,thomasdlt,1532370433,,0,3
1241,2018-7-24,2018,7,24,3,919ol5,[Research] Cross Pixel Optical Flow Similarity for Self-Supervised Learning,https://www.reddit.com/r/MachineLearning/comments/919ol5/research_cross_pixel_optical_flow_similarity_for/,ABraveNewWorld2,1532371074,,2,11
1242,2018-7-24,2018,7,24,3,919pe2,How to produce image from model,https://www.reddit.com/r/MachineLearning/comments/919pe2/how_to_produce_image_from_model/,hugheric,1532371222,[removed],0,1
1243,2018-7-24,2018,7,24,4,919vz6,[P] ONNX Model Zoo: Developing a face recognition application with ONNX models,https://www.reddit.com/r/MachineLearning/comments/919vz6/p_onnx_model_zoo_developing_a_face_recognition/,thomasdlt,1532372467,,0,7
1244,2018-7-24,2018,7,24,4,91a12o,"[D]PPO/TRPO Overfitting Discussion (beta, why do you do this to me?)",https://www.reddit.com/r/MachineLearning/comments/91a12o/dppotrpo_overfitting_discussion_beta_why_do_you/,curranw,1532373423,"This is more of a general discussion, but I find it relevant, and I'm curious how other people approach it. It's a classic overfitting problem. For many many years I have just done early stopping, but that's getting tiring.

I thought TRPO/PPO would get pretty close at fixing overfitting by playing with the kl term and beta. However...After a while PPO/TRPO still overfits and unlearns everything within a couple of updates. Actually BECAUSE of the beta and kl terms, it seems to unlearn very quickly. Once overfitting begins, the policy is completely destroyed by a large loss function. For example, early in a run the losses look like:   
loss1: -0.0036 loss2: 0.0105 loss3: 0.00042

where loss1 is the advantage loss, loss2 is beta \* kl and loss3 is the hinge loss. These values are not crazy.

After convergence, the losses get a little more extreme:  
loss1: -0.024 loss2: 8.50 loss3: 17.15

this is due to kl exploding after a single update, and beta getting consistently larger (until it maxes out). I tried to fix this by trying:

1. L2 regularization on the policy, but it only delays the effect.

2.  Small minibatch updates per actor epoch, rather than one big update  (similar to the value function). This helps a lot, but it still occurs eventually.

3. Clipping the gradient is a thing....but I feel like that may ignore an underlying issue.

Any thoughts? What approaches do you all take? Many online references are kind of ad-hoc. 

Note that this only occurs when updating the actor/critic &gt; 3 times per update.",6,8
1245,2018-7-24,2018,7,24,5,91amsl,Generative Art with CPPNs/GANs/WGANs,https://www.reddit.com/r/MachineLearning/comments/91amsl/generative_art_with_cppnsganswgans/,kwj2104,1532377495,,1,1
1246,2018-7-24,2018,7,24,5,91andj,Can capsule networks be used as autoencoders without trained data?,https://www.reddit.com/r/MachineLearning/comments/91andj/can_capsule_networks_be_used_as_autoencoders/,Devenar,1532377603,[removed],0,1
1247,2018-7-24,2018,7,24,5,91anq4,[P] Tips for building fast portrait segmentation network with TensorFlow Lite,https://www.reddit.com/r/MachineLearning/comments/91anq4/p_tips_for_building_fast_portrait_segmentation/,sjosund,1532377665,,0,4
1248,2018-7-24,2018,7,24,5,91aqg1,"[D] Is the output of a feedforward neural network with bounded activations in the hidden layers, bounded?",https://www.reddit.com/r/MachineLearning/comments/91aqg1/d_is_the_output_of_a_feedforward_neural_network/,TimelyCrazy,1532378184,"I'm new here and on Reddit in general, so I hope I'm not making any major mistakes.

I have a simple question: consider a generic feedforward neural network. Suppose that all the hidden layers have bounded activation functions (e.g., tanh). Now, if the output layer has a bounded activation function, of course the NN has a bounded output. However, suppose that the last layer has an unbounded activation, for example a linear activation. I think the output will still be bounded:

$$y=f(a_1,\dots, a_N)=sum\_{i=1}^N w_i a_i + b$$

where $N$ is the number of units in the last hidden layer, and $a_1,\dots, a_N$ are the activations of the layer. Let $w = \max{|w_1|,\dots, |w_N|}$. Then 

$$|y|\le N|w|+|b|$$

i.e., the output is bounded. Is this correct?",17,2
1249,2018-7-24,2018,7,24,6,91b9r7,A layperson's concern about A.I. somewhat comforted,https://www.reddit.com/r/MachineLearning/comments/91b9r7/a_laypersons_concern_about_ai_somewhat_comforted/,scooterduff,1532381998,[removed],0,1
1250,2018-7-24,2018,7,24,6,91baox,"Deep Learning: Can features express different different impacts for different ""cohorts""?",https://www.reddit.com/r/MachineLearning/comments/91baox/deep_learning_can_features_express_different/,holidaytie,1532382174,[removed],0,1
1251,2018-7-24,2018,7,24,6,91bcy5,TrackML Particle Tracking Challenge,https://www.reddit.com/r/MachineLearning/comments/91bcy5/trackml_particle_tracking_challenge/,melonochelo,1532382636,,0,1
1252,2018-7-24,2018,7,24,7,91bh3s,"Alexa will use contextual clues to modify statistical language models on the fly, dynamically improving speech recognition for individual customers",https://www.reddit.com/r/MachineLearning/comments/91bh3s/alexa_will_use_contextual_clues_to_modify/,deeplearner1234,1532383464,,0,1
1253,2018-7-24,2018,7,24,7,91bi0x,[P] Generative Art with Compositional Pattern Producing Networks/GANs/WGANs,https://www.reddit.com/r/MachineLearning/comments/91bi0x/p_generative_art_with_compositional_pattern/,kwj2104,1532383635,,5,9
1254,2018-7-24,2018,7,24,7,91bv0n,[R] Efficient Probabilistic Inference in the Quest for Physics Beyond the Standard Model,https://www.reddit.com/r/MachineLearning/comments/91bv0n/r_efficient_probabilistic_inference_in_the_quest/,baylearn,1532386328,,2,7
1255,2018-7-24,2018,7,24,9,91cqhe,Basic questions regarding building LSTM for forecasting in Keras,https://www.reddit.com/r/MachineLearning/comments/91cqhe/basic_questions_regarding_building_lstm_for/,Babycorgz,1532393300,[removed],0,1
1256,2018-7-24,2018,7,24,9,91cru3,Testing assumptions...,https://www.reddit.com/r/MachineLearning/comments/91cru3/testing_assumptions/,idea_coup_de_tat,1532393614,"Im no data scientist, but from what I understand, lots of data is needed for machine learning models to improve. now, Ive had this assumption that obtaining enough data is a challenge in this respect, however, I would like to go from assumptions to facts.

how true is this? if not, what is(are) the biggest challenge(s) in machine learning?",0,1
1257,2018-7-24,2018,7,24,10,91d1e1,How to Combine Topic Modelling and Graph-Based Clustering,https://www.reddit.com/r/MachineLearning/comments/91d1e1/how_to_combine_topic_modelling_and_graphbased/,NTGuardian,1532395818,[removed],0,1
1258,2018-7-24,2018,7,24,10,91d315,[R] Faster Black-Box Adversarial Attacks with Bandit Optimization,https://www.reddit.com/r/MachineLearning/comments/91d315/r_faster_blackbox_adversarial_attacks_with_bandit/,andrew_ilyas,1532396207,[removed],0,1
1259,2018-7-24,2018,7,24,10,91d798,[R] Faster Black-Box Adversarial Attacks with Bandit Optimization,https://www.reddit.com/r/MachineLearning/comments/91d798/r_faster_blackbox_adversarial_attacks_with_bandit/,andrew_ilyas,1532397211,,14,20
1260,2018-7-24,2018,7,24,11,91ddzs,Tableau Viz,https://www.reddit.com/r/MachineLearning/comments/91ddzs/tableau_viz/,databenk,1532398751,,0,1
1261,2018-7-24,2018,7,24,11,91dito,[R] TDLS: Explainable Neural Networks based on Additive Index Models (https://arxiv.org/abs/1806.01933),https://www.reddit.com/r/MachineLearning/comments/91dito/r_tdls_explainable_neural_networks_based_on/,machinetrainer,1532399917,,4,33
1262,2018-7-24,2018,7,24,12,91dumd,Understanding Word Embeddings,https://www.reddit.com/r/MachineLearning/comments/91dumd/understanding_word_embeddings/,mukesh9039,1532402727,,0,1
1263,2018-7-24,2018,7,24,12,91dy1d,[D] Looking for a paper on Feature Extraction from CNNs,https://www.reddit.com/r/MachineLearning/comments/91dy1d/d_looking_for_a_paper_on_feature_extraction_from/,maxisawesome538,1532403581,"I'm looking for this specific paper I found a few weeks ago that involved finding which pixels in an image were most important to that CNN's final output. It involved taking out certain pixels and retraining the model, and had some name like ReACT or REMAKE or some acronym like that. I think it was by google, but it might've been OpenAI (I looked and couldn't find it there). I remember specific images of things like a pic of a bird being classified then later all the pixels on the bird's face are gone because they get removed and are most important to the CNN's ability to identify it as a bird. 

I'm looking for other papers on feature extraction as well if you know of any! I'm still hazy on the ""field"" of feature extraction with deep learning, both with CNN's for computer vision and RNN's for NLP, but I'd appreciate tips or directions to look for both categories. ",8,22
1264,2018-7-24,2018,7,24,12,91e17r,Help : creating Rule engine in Jena,https://www.reddit.com/r/MachineLearning/comments/91e17r/help_creating_rule_engine_in_jena/,rishisaireddy,1532404403,[removed],0,1
1265,2018-7-24,2018,7,24,13,91eeft,Beginner doubt about combining ARIMA and BP(please help),https://www.reddit.com/r/MachineLearning/comments/91eeft/beginner_doubt_about_combining_arima_and_bpplease/,Videept_Kohli,1532407837,[removed],0,1
1266,2018-7-24,2018,7,24,15,91et9l,[D] What is the state-of-the-art for real-time pedestrian detection that can be deployed with a reasonable frame rate on a TX2?,https://www.reddit.com/r/MachineLearning/comments/91et9l/d_what_is_the_stateoftheart_for_realtime/,just2gud,1532412105,Say 30 fps,3,0
1267,2018-7-24,2018,7,24,15,91ettz,Multi class Classification Question,https://www.reddit.com/r/MachineLearning/comments/91ettz/multi_class_classification_question/,pierryhenry23,1532412250,[removed],0,1
1268,2018-7-24,2018,7,24,15,91ewlr,ScoutBot: A Dialogue System for Collaborative Navigation,https://www.reddit.com/r/MachineLearning/comments/91ewlr/scoutbot_a_dialogue_system_for_collaborative/,buaahsh,1532413037,,1,0
1269,2018-7-24,2018,7,24,16,91f6r6,Durk Kingma (author of Adam &amp; VAE) has left OpenAI,https://www.reddit.com/r/MachineLearning/comments/91f6r6/durk_kingma_author_of_adam_vae_has_left_openai/,ai_throwaway789,1532416127,,0,1
1270,2018-7-24,2018,7,24,16,91fbev,Feature Selection in Machine Learning: Variable Ranking and Feature Subset Selection Methods,https://www.reddit.com/r/MachineLearning/comments/91fbev/feature_selection_in_machine_learning_variable/,stratahive,1532417630,,0,1
1271,2018-7-24,2018,7,24,17,91fgud,"[P] Fast, Flexible, Easy and Intuitive: How to Speed Up Your Pandas Projects",https://www.reddit.com/r/MachineLearning/comments/91fgud/p_fast_flexible_easy_and_intuitive_how_to_speed/,friscotime,1532419446,,0,1
1272,2018-7-24,2018,7,24,17,91fknx,"[R] Model-free, Model-based, and General Intelligence",https://www.reddit.com/r/MachineLearning/comments/91fknx/r_modelfree_modelbased_and_general_intelligence/,jakn,1532420723,,0,8
1273,2018-7-24,2018,7,24,17,91fpbi,[D] Google's AutoML: Cutting Through the Hype,https://www.reddit.com/r/MachineLearning/comments/91fpbi/d_googles_automl_cutting_through_the_hype/,wei_jok,1532422364,,19,181
1274,2018-7-24,2018,7,24,17,91fpbs,"Machine learning in finance: The why, what and how",https://www.reddit.com/r/MachineLearning/comments/91fpbs/machine_learning_in_finance_the_why_what_and_how/,ARayOutOfBounds,1532422368,,0,1
1275,2018-7-24,2018,7,24,18,91fta1,[D] Procrastination while running scripts/functions/models?,https://www.reddit.com/r/MachineLearning/comments/91fta1/d_procrastination_while_running/,mac_cumhaill,1532423687,"I guess we're all familiar with building large models and pushing them off to train on some remote server. 

However, most of the time when i'm doing EDA or initial model development I run functions/scripts that might take between a minute and five minutes to run across the data. This ins't enough time to start a new task, and often I end up swapping over to social media or trying to answer my emails. However the tender grips of procrastination then take hold and I end up wasting more time. 

Often you can't move forward with coding either because you're waiting on the outcome of the current function. 

Dose anyone have any tips on something to do in these short breaks? Better than just looking out the window. I feel like i'm losing a lot productivity. ",39,79
1276,2018-7-24,2018,7,24,18,91fu71,Feature Selection in Machine Learning: Variable Ranking and Feature Subset Selection Methods,https://www.reddit.com/r/MachineLearning/comments/91fu71/feature_selection_in_machine_learning_variable/,stratahive,1532423999,,0,1
1277,2018-7-24,2018,7,24,18,91fuw3,Use Cases of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/91fuw3/use_cases_of_machine_learning/,seoaleait,1532424231,,0,1
1278,2018-7-24,2018,7,24,18,91fwvj,Cluster analysis to determine drug effect,https://www.reddit.com/r/MachineLearning/comments/91fwvj/cluster_analysis_to_determine_drug_effect/,circulus_one,1532424899,[removed],0,1
1279,2018-7-24,2018,7,24,18,91fyni,[D] #APaperADay Reading Challenge Week 1. What are your thoughts and takeaways for the papers for this week.,https://www.reddit.com/r/MachineLearning/comments/91fyni/d_apaperaday_reading_challenge_week_1_what_are/,leenz2,1532425477,"On the 23rd of July, [Nurture.AI](https://Nurture.AI) initiated the [#APaperADay Reading Challenge](https://apaperaday.nurture.ai/), where we will read an AI paper everyday. 

Here is our pick of 6 papers for this week:
1. [Neural Best-Buddies: Sparse Cross-Domain Correspondence](https://nurture.ai/papers/neural-best-buddies-sparse-cross-domain-correspondence/annotations) ([2-min summary](https://nurture.ai/papers/neural-best-buddies-sparse-cross-domain-correspondence/tldr))
*Why read*: Well-written paper that presents a way to relate two images from different categories, leading to image morphing applications. 
*Key concept*: finding pairs of neurons (one from each image) that are ""buddies"" (nearest neighbors). 

2. [The GAN Landscape: Losses, Architectures, Regularization, and Normalization](https://nurture.ai/papers/the-gan-landscape-losses-architectures-regularization-and-normalization/annotations) (prereq &amp; dependencies are in the annotations)
*Why read*: Evaluation of GAN loss functions, optimization schemes and architectures using latest empirical methods. 
*Interesting takeaway*: authors wrote that most tricks applied in the ResNet style architectures lead to marginal changes and incurs high computational cost.

3. [A Meta-Learning Approach to One-Step Active-Learning](https://nurture.ai/papers/a-meta-learning-approach-to-one-step-active-learning/annotations?utm_source=APaperADay+Signups&amp;utm_campaign=18733c3305-EMAIL_CAMPAIGN_2018_07_23_06_39&amp;utm_medium=email&amp;utm_term=0_13ca78df47-18733c3305-67859447) (prereq &amp; dependencies are in the annotations)
*Why read*: An under-discussed method to deal with scarce labelled data: a classification model that learns how to label its own training data. 
*The novelty*: It combines one-shot learning (learning from one or few training examples) with active learning (choosing the appropriate data points to be labelled). 

4. [Visual Reinforcement Learning with Imagined Goals](https://nurture.ai/papers/visual-reinforcement-learning-with-imagined-goals/annotations)
*Why read*: An interesting way of teaching a model to acquire general-purpose skills. The model performs a self-supervised practice phase where it imagines goals and attempts to achieve them. 
*The novelty*: a goal relabelling method that improves sampling efficiency.  

5. [Universal Language Model Fine-tuning for Text Classification](https://nurture.ai/papers/universal-language-model-fine-tuning-for-text-classification/annotations)
Why read: Transfer Learning has not been widely explored in NLP problems until this paper, which explores the benefits of using a pre-trained model on text classification. 
Key result: Along with various fine-tuning tricks, this method outperforms the state-of-the-art on six text classification tasks.

6. [Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors](https://nurture.ai/papers/interpretability-beyond-feature-attribution-quantitative-testing-with-concept-activation-vectors-tcav/annotations) ([2-min summary](https://nurture.ai/papers/interpretability-beyond-feature-attribution-quantitative-testing-with-concept-activation-vectors-tcav/tldr))
Why read: A new method that helps us to interpret NN decisions and also reveal unintended gender and racial biases in NN models. 
The novelty: Gauges the sensitivity of ML predictions to changes in inputs towards the direction of a concept. 

Share your thoughts on the papers we've chosen and the ones you've read in the comments section below!

[Link to original post](https://www.reddit.com/r/MachineLearning/comments/903ta0/d_what_is_one_ai_paper_which_you_feel_did_not_get/)
Week 2 papers - unreleased
Week 3 papers - unreleased
Week 4 papers - unreleased",12,51
1280,2018-7-24,2018,7,24,18,91g0kp,Questions about feature importance as number of features increases.,https://www.reddit.com/r/MachineLearning/comments/91g0kp/questions_about_feature_importance_as_number_of/,furmat,1532426104,[removed],0,1
1281,2018-7-24,2018,7,24,19,91g4d4,[1807.08518] Implementing Neural Turing Machines,https://www.reddit.com/r/MachineLearning/comments/91g4d4/180708518_implementing_neural_turing_machines/,ihaphleas,1532427222,,17,53
1282,2018-7-24,2018,7,24,19,91g5wy,Complete Machine Learning Fundamentals in less than 5 minutes,https://www.reddit.com/r/MachineLearning/comments/91g5wy/complete_machine_learning_fundamentals_in_less/,The_Magnum,1532427692,,0,1
1283,2018-7-24,2018,7,24,19,91g6dh,[Question]Queries for using Google Map Data for a CNN project.,https://www.reddit.com/r/MachineLearning/comments/91g6dh/questionqueries_for_using_google_map_data_for_a/,spacegazelle,1532427825,[removed],0,1
1284,2018-7-24,2018,7,24,20,91gdve,Google's page rank algorithm,https://www.reddit.com/r/MachineLearning/comments/91gdve/googles_page_rank_algorithm/,coolnikhilj22,1532430056,[removed],0,1
1285,2018-7-24,2018,7,24,20,91gip8,[R] What is Minimum Viable (Data) Product?,https://www.reddit.com/r/MachineLearning/comments/91gip8/r_what_is_minimum_viable_data_product/,xTWOz,1532431336,,0,1
1286,2018-7-24,2018,7,24,20,91gpp0,What information is stored in the weights file (.h5)?,https://www.reddit.com/r/MachineLearning/comments/91gpp0/what_information_is_stored_in_the_weights_file_h5/,WhatWouldResNetDo,1532433251,[removed],0,1
1287,2018-7-24,2018,7,24,21,91gr2c,vector space model and weights,https://www.reddit.com/r/MachineLearning/comments/91gr2c/vector_space_model_and_weights/,kj75015,1532433613,[removed],0,1
1288,2018-7-24,2018,7,24,21,91gscg,How machine learning is Improving Customer Loyalty,https://www.reddit.com/r/MachineLearning/comments/91gscg/how_machine_learning_is_improving_customer_loyalty/,corporateanalytics,1532433908,,0,1
1289,2018-7-24,2018,7,24,21,91h4cf,[Project Question] Fake Name Detection,https://www.reddit.com/r/MachineLearning/comments/91h4cf/project_question_fake_name_detection/,Donn3lly,1532436791,[removed],0,1
1290,2018-7-24,2018,7,24,21,91h4vq,[D] What are some best practices specific to the engineering and design of machine learning systems?,https://www.reddit.com/r/MachineLearning/comments/91h4vq/d_what_are_some_best_practices_specific_to_the/,joeddav,1532436912,"Machine learning engineering is more than just software engineering + machine learning. The deployment of machine learning models bring technical challenges of a different nature than typical engineering problems and may require certain best practices or design patterns which an engineer may not otherwise consider.

A great illustration of this is Google's 2014 paper, [Machine Learning: The High Interest Credit Card of Technical Debt](https://ai.google/research/pubs/pub43146). In this paper, the authors discuss some common forms of technical debt associated with the usage of machine learning in software and the potentially unexpected issues that can arise from the intrinsically entangled nature of machine learning models.

What, in your experience, are some of the most potent problems in engineering that may not be considered by someone less experienced in creating ML solutions in the wild? What are the best practices, tools, and design patterns that help to create a stable ML system?",6,31
1291,2018-7-24,2018,7,24,23,91hqvc,Any success on using distributed services to train your models?,https://www.reddit.com/r/MachineLearning/comments/91hqvc/any_success_on_using_distributed_services_to/,Darth_bunny,1532441654,Has anyone tried services like [Vectordash](https://vectordash.com/) or [SONM](https://sonm.com/solutions/machine-learning/) to train their models? Would you recommend them? What happens if the host goes offline in the middle of the process?,0,1
1292,2018-7-24,2018,7,24,23,91hu4q,[D] Any success on using distributed services to train your models?,https://www.reddit.com/r/MachineLearning/comments/91hu4q/d_any_success_on_using_distributed_services_to/,Darth_bunny,1532442298,Has anyone tried services like [Vectordash](https://vectordash.com/) or [SONM](https://sonm.com/solutions/machine-learning/) to train their models? Would you recommend them? What happens if the host goes offline in the middle of the process?,3,8
1293,2018-7-24,2018,7,24,23,91hv60,[R] I need a laptop for my master's degree but don't know what to choose.,https://www.reddit.com/r/MachineLearning/comments/91hv60/r_i_need_a_laptop_for_my_masters_degree_but_dont/,Vese321,1532442500,"Hey guys,

First of all I don't know if this belongs here. If it doesn't, let me please let me know where it should be. Thank you!

In September I'm starting my master's degree in Machine Learning and Big Data and I need a new laptop for projects and college stuff all around. The thing is I don't know which laptop should be looking for. 

Here are some more details:
- I have a desktop Windows PC with an Intel i7 4790K, a GTX 970 and 16 GB of RAM. Its a good PC but I'm algo going to be working so I don't know if I'll be able to do all my work at home.
- I need something light and with good processing power, so my first thought was to look the new Macbook Pro 13'', but it doesn't have a proper graphics card and I'm almost certain that I'm going to need a proper graphics card at some point So I started looking at the 15'' Macbook Pro. And they have very good battery live too. 
- Then I started looking some Windows laptops. The problem with those are usually battery live or that they are too big or too heavy for me to carry.
- Almost certain that I am going to need a linux based OS, with SSH and everything else, but that shouldn't be a problem anyway.

So after some internet research I stumbled upon this subreddit and decided to ask for help. 

I am open to all options as long as it fits the conditions mentioned before. As long as money goes it shouldn't be a problem as long as it's below 2300. So, any recommendations?

Thank you so much in advance. Hope you can help me.",24,0
1294,2018-7-24,2018,7,24,23,91hz2i,SJTU &amp; MIT Paper Reinvents Neural Architecture Search; Slashes Computational Resource Requirements,https://www.reddit.com/r/MachineLearning/comments/91hz2i/sjtu_mit_paper_reinvents_neural_architecture/,gwen0927,1532443318,,0,1
1295,2018-7-24,2018,7,24,23,91hz4w,Recent Trends in Deep Learning Based Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/91hz4w/recent_trends_in_deep_learning_based_natural/,MaLiN2223,1532443332,,2,1
1296,2018-7-24,2018,7,24,23,91hzfy,[P] SJTU &amp; MIT Paper Reinvents Neural Architecture Search; Slashes Computational Resource Requirements,https://www.reddit.com/r/MachineLearning/comments/91hzfy/p_sjtu_mit_paper_reinvents_neural_architecture/,gwen0927,1532443392,,0,1
1297,2018-7-24,2018,7,24,23,91i26o,[R] Recent Trends in Deep Learning Based Natural Language Processing  r/MachineLearning,https://www.reddit.com/r/MachineLearning/comments/91i26o/r_recent_trends_in_deep_learning_based_natural/,MaLiN2223,1532443930,,3,8
1298,2018-7-25,2018,7,25,0,91ihgr,A Look at Android ML Kit - the Machine Learning SDK,https://www.reddit.com/r/MachineLearning/comments/91ihgr/a_look_at_android_ml_kit_the_machine_learning_sdk/,Ramirond,1532446842,,0,1
1299,2018-7-25,2018,7,25,0,91imeg,Unlimited Road-scene Synthetic Annotation (URSA) Dataset,https://www.reddit.com/r/MachineLearning/comments/91imeg/unlimited_roadscene_synthetic_annotation_ursa/,mattangus,1532447825,,3,9
1300,2018-7-25,2018,7,25,1,91ivuq,ResNet with concat,https://www.reddit.com/r/MachineLearning/comments/91ivuq/resnet_with_concat/,Ramesh-X,1532449537,[removed],0,1
1301,2018-7-25,2018,7,25,1,91j1b4,[D] GANs used in production?,https://www.reddit.com/r/MachineLearning/comments/91j1b4/d_gans_used_in_production/,spotta,1532450547,"Does anyone use GANs in production, or as part of the training process of a production ML model (maybe as a data augmentation tool, or to train the descriminator (the generator is later thrown out)?

While very cool, the difficulty in training and the newness makes me think that they aren't used in production at all (yet?), but I figured I would ask.",27,45
1302,2018-7-25,2018,7,25,2,91j8ra,The value of data science in security - CSO | The Resource for Data Security Executives,https://www.reddit.com/r/MachineLearning/comments/91j8ra/the_value_of_data_science_in_security_cso_the/,databoy2323,1532451942,,0,1
1303,2018-7-25,2018,7,25,2,91j9bc,"Andrew Ng ""moved"" by my article!",https://www.reddit.com/r/MachineLearning/comments/91j9bc/andrew_ng_moved_by_my_article/,gtidStudent,1532452040,[removed],0,1
1304,2018-7-25,2018,7,25,2,91jf5t,SJTU &amp; MIT Paper Reinvents Neural Architecture Search; Slashes Computational Resource Requirements,https://www.reddit.com/r/MachineLearning/comments/91jf5t/sjtu_mit_paper_reinvents_neural_architecture/,trcytony,1532453133,,0,1
1305,2018-7-25,2018,7,25,3,91jseu,"[D] Problem with GANs, Intro to WGANs, Earth Mover's distance and Kantorovich Rubenstein's Duality",https://www.reddit.com/r/MachineLearning/comments/91jseu/d_problem_with_gans_intro_to_wgans_earth_movers/,jaleyhd,1532455530,,7,90
1306,2018-7-25,2018,7,25,3,91jujv,We're answering your questions about ML and AI - join us tomorrow,https://www.reddit.com/r/MachineLearning/comments/91jujv/were_answering_your_questions_about_ml_and_ai/,IBMAnalytics,1532455906,,0,1
1307,2018-7-25,2018,7,25,3,91jux6,[N] Announcing GluonNLP v0.3.2  Deep Learning Toolkit for Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/91jux6/n_announcing_gluonnlp_v032_deep_learning_toolkit/,thomasdlt,1532455975,,1,10
1308,2018-7-25,2018,7,25,3,91k7zi,Math Behind Backpropagation,https://www.reddit.com/r/MachineLearning/comments/91k7zi/math_behind_backpropagation/,josajima,1532458409,"For the longest time I couldn't figure out exactly how the math behind backpropagation works.

So I took the advice of several people including Andrej Karpathy and Andrew Ng and worked through a simple example. I wrote a two-part blog series on forward propagation and backpropagation where I work through all the math behind a simple, 3 layer neural network. This is my first time writing in a blog, so any feedback would be greatly appreciated!

[The Math behind Neural Networks: Forward Propagation](http://www.jasonosajima.com/forwardprop.html)

[The Math behind Neural Networks: Backpropagation](http://www.jasonosajima.com/backprop.html)",0,1
1309,2018-7-25,2018,7,25,5,91kvhp,[P] GluonNLP  Deep Learning Toolkit for Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/91kvhp/p_gluonnlp_deep_learning_toolkit_for_natural/,thomasdlt,1532462772,,0,1
1310,2018-7-25,2018,7,25,5,91l2qp,"Given a satellite image, machine learning creates the view on the ground",https://www.reddit.com/r/MachineLearning/comments/91l2qp/given_a_satellite_image_machine_learning_creates/,SYGZ95,1532464089,,0,1
1311,2018-7-25,2018,7,25,5,91l6t8,Jupyter Notebooks and Neural Networks,https://www.reddit.com/r/MachineLearning/comments/91l6t8/jupyter_notebooks_and_neural_networks/,eukaryote31,1532464864,"For the longest time I've just been training networks the old fashioned way, with regular scripts. Recently I learned about Jupyter and its instant feedback capabilities and how popular it was in ML circles, and I can't help but wonder how I'm supposed to apply them to neural networks. Most of the nontrivial networks I've worked with take at least half an hour to train, and most over the span of a good part of a day, and are mostly just a training step repeated over many epochs. Needless to say, this doesn't make rapid iteration feasible. How can I introduce Jupyter notebooks into my workflow so I can iterate more rapidly in development?  
",0,1
1312,2018-7-25,2018,7,25,6,91le2y,[P] Announcing GluonNLP v0.3.2  Deep Learning Toolkit for Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/91le2y/p_announcing_gluonnlp_v032_deep_learning_toolkit/,zhasheng,1532466259,,0,1
1313,2018-7-25,2018,7,25,6,91lt3r,[R] Path-Level Network Transformation for Efficient Architecture Search,https://www.reddit.com/r/MachineLearning/comments/91lt3r/r_pathlevel_network_transformation_for_efficient/,trcytony,1532469327,,0,1
1314,2018-7-25,2018,7,25,6,91lug9,Review of Google's Coursera Specialisation on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/91lug9/review_of_googles_coursera_specialisation_on/,today_is_tuesday,1532469596,[removed],0,1
1315,2018-7-25,2018,7,25,7,91m21a,Kaggle introduces AI/ML micro-challenges,https://www.reddit.com/r/MachineLearning/comments/91m21a/kaggle_introduces_aiml_microchallenges/,seiqooq,1532471154,,0,1
1316,2018-7-25,2018,7,25,7,91m737,Competition vs. Concatenation in Skip Connections of Fully Convolutional Networks,https://www.reddit.com/r/MachineLearning/comments/91m737/competition_vs_concatenation_in_skip_connections/,dmahan93,1532472212,,1,2
1317,2018-7-25,2018,7,25,7,91m9zc,[R] Competition vs. Concatenation in Skip Connections of Fully Convolutional Network,https://www.reddit.com/r/MachineLearning/comments/91m9zc/r_competition_vs_concatenation_in_skip/,dmahan93,1532472834,,4,4
1318,2018-7-25,2018,7,25,8,91mfen,Pros &amp; Cons of GPU for Machine Learning / Recommendations?,https://www.reddit.com/r/MachineLearning/comments/91mfen/pros_cons_of_gpu_for_machine_learning/,eshuhie,1532473978,[removed],0,1
1319,2018-7-25,2018,7,25,8,91mnof,[D] Does anybody know what's going on with mloss.org?,https://www.reddit.com/r/MachineLearning/comments/91mnof/d_does_anybody_know_whats_going_on_with_mlossorg/,psykocrime,1532475791,"The website at www.mloss.org is a great repository of news and links to the latest in OSS Machine Learning software, but it seems to have been offline for at least a week or so.  Does anybody know if it's just down due to a hardware crash or something, or if it's gone permanently?  Hopefully it comes back, and the site is an invaluable resource.
",2,4
1320,2018-7-25,2018,7,25,10,91nj0g,[N] Machine learning for Cancer Diagnostics,https://www.reddit.com/r/MachineLearning/comments/91nj0g/n_machine_learning_for_cancer_diagnostics/,mingming94,1532482846,,0,1
1321,2018-7-25,2018,7,25,11,91noes,[D] Release v1.15.0  numpy/numpy,https://www.reddit.com/r/MachineLearning/comments/91noes/d_release_v1150_numpynumpy/,_quanttrader_,1532484078,,0,1
1322,2018-7-25,2018,7,25,15,91pbli,[D] Did the MLSS 2018 videos ever get posted? Linked poster with speaker lineup looks interesting,https://www.reddit.com/r/MachineLearning/comments/91pbli/d_did_the_mlss_2018_videos_ever_get_posted_linked/,satsatsat,1532499443,,1,7
1323,2018-7-25,2018,7,25,15,91pdks,[N] The University of Cambridge will establish a DeepMind Chair of Machine Learning ...,https://www.reddit.com/r/MachineLearning/comments/91pdks/n_the_university_of_cambridge_will_establish_a/,inarrears,1532500020,,52,128
1324,2018-7-25,2018,7,25,16,91pkwz,Best way to learn machine learning algorithms (Free guide),https://www.reddit.com/r/MachineLearning/comments/91pkwz/best_way_to_learn_machine_learning_algorithms/,richardsmith7021,1532502234,[removed],0,1
1325,2018-7-25,2018,7,25,16,91poud,[D] How is the result of feature scaling any different to changing the learning rate?,https://www.reddit.com/r/MachineLearning/comments/91poud/d_how_is_the_result_of_feature_scaling_any/,iwelcomejudgement,1532503378,"Surely if you have a feature with a large range, and a high learning rate, then this will be roughly the same as if you had a small range, and a small learning rate?

Why would I need to do feature scaling at all if I can just adjust my learning rate?

What effect would having one feature with a large range and one feature with a small range have? Would it be any different?

Thanks!",16,5
1326,2018-7-25,2018,7,25,17,91pxeo,Training hosting services,https://www.reddit.com/r/MachineLearning/comments/91pxeo/training_hosting_services/,PineappleMechanic,1532506046,[removed],0,1
1327,2018-7-25,2018,7,25,18,91qc1l,[D] Deep learning and free software,https://www.reddit.com/r/MachineLearning/comments/91qc1l/d_deep_learning_and_free_software/,pilooch,1532510908,,15,29
1328,2018-7-25,2018,7,25,19,91qil6,Research paper on comparing word pronunciation for binary classification . If it right or not,https://www.reddit.com/r/MachineLearning/comments/91qil6/research_paper_on_comparing_word_pronunciation/,taher_coolguy,1532512956,[removed],0,1
1329,2018-7-25,2018,7,25,19,91qk9u,Innovating with HR Chatbots: What Can I Use Them For? | Botbot.AI,https://www.reddit.com/r/MachineLearning/comments/91qk9u/innovating_with_hr_chatbots_what_can_i_use_them/,BotbotAI,1532513467,,0,1
1330,2018-7-25,2018,7,25,19,91qkr6,[D] Hidden Markov Model as supervised learning,https://www.reddit.com/r/MachineLearning/comments/91qkr6/d_hidden_markov_model_as_supervised_learning/,emilazeri92,1532513603,"Hey there! I am trying to substitute LSTM in time series prediction with Hidden Markov Models because LSTM is time and memory heavy. I have already read quite about HMMs and how they work. Yet, in all of the materials Transition matrix, emission matrix and initial probabilities were known. In my case  Hidden states are known (i want to use them as training set) alongside with observations, but Transition and emission matrices and initial probabilities are unknown. Any ideas or hints how I can turn it into supervised learning problem?",14,18
1331,2018-7-25,2018,7,25,19,91qmcx,Chatbots Can Now Perform Administrative Tasks,https://www.reddit.com/r/MachineLearning/comments/91qmcx/chatbots_can_now_perform_administrative_tasks/,amberstevens311,1532514114,,0,1
1332,2018-7-25,2018,7,25,19,91qo0o,[N] Seattle Insight Data Science: One Year Anniversary!,https://www.reddit.com/r/MachineLearning/comments/91qo0o/n_seattle_insight_data_science_one_year/,digitalson,1532514628,,0,1
1333,2018-7-25,2018,7,25,19,91qth0,5 Best Places to Find an Exceptional Virtual Assistant,https://www.reddit.com/r/MachineLearning/comments/91qth0/5_best_places_to_find_an_exceptional_virtual/,amberstevens311,1532516291,,0,1
1334,2018-7-25,2018,7,25,20,91r709,I'm finding that The Elements of Statistical Learning is proving to be really challenging.,https://www.reddit.com/r/MachineLearning/comments/91r709/im_finding_that_the_elements_of_statistical/,demoem,1532519974,I bought this book after seeing the post on top of all time and it's proving to be challenging to understand. My background is in software engineering and not statistics so I'm having to Google and research every other term they use. I'm also doing Andrew Ngs course and am wondering is it worth my time to read this book or is the course sufficient?,0,1
1335,2018-7-25,2018,7,25,21,91riqt,NLP Tutorial - Text Sentiment Analysis,https://www.reddit.com/r/MachineLearning/comments/91riqt/nlp_tutorial_text_sentiment_analysis/,Amir_PD,1532522848,,0,1
1336,2018-7-25,2018,7,25,22,91rrci,AdamW and Super-convergence is now the fastest way to train neural nets  fast.ai,https://www.reddit.com/r/MachineLearning/comments/91rrci/adamw_and_superconvergence_is_now_the_fastest_way/,LordKlevin,1532524779,,0,1
1337,2018-7-25,2018,7,25,22,91rs2d,Missing/Misplaced period error detection in Open Text,https://www.reddit.com/r/MachineLearning/comments/91rs2d/missingmisplaced_period_error_detection_in_open/,acerock6,1532524942,"Hi,
Lately, I've been working on an interesting problem which involves NLP and text analytics. Basically we teach English to students from grade 4-8. We've seen that these students make a lot of mistakes while responding to questions like Essay type or Open ended. A major category involved incorrect usage of periods.
I've been searching for good resources that can help me detect these missing / misplaced periods in the sentences. (For eg: Run on sentences like: He is a good man and then he said he is going to the college and then he slipped on the way; the student is not using period at the appropriate places)
I only have a corrextly punctuated corpus for now (which again is unlabelled).
 
I am stuck on this problem with no leads that can help me.
TIA",0,1
1338,2018-7-25,2018,7,25,22,91s1rm,[P] Multilabel Classification of Constellations in Star Maps,https://www.reddit.com/r/MachineLearning/comments/91s1rm/p_multilabel_classification_of_constellations_in/,martianwars,1532527046,"We are releasing a new multilabel classification dataset containing star maps. The task is to identify the set of constellations present in a particular view of the sky. Since the celestial coordinates of this image are not provided, the model must use the star patterns to identify the set of constellations in the image. This dataset was mined using Stellarium by [@cookie-monstar](https://github.com/cookie-monstar), [@kushagra1729](https://github.com/kushagra1729) and me, [@martiansideofthemoon](https://github.com/martiansideofthemoon/) (all Github handles).

URL - [https://github.com/cookie-monstar/star-tracker](https://github.com/cookie-monstar/star-tracker)

The Github repository linked above contains sample images along with their ground truth outputs.

Unlike natural images, star maps are extremely sparse. These images lack curves and edges, and can be called ""out-of-domain"" when you compare them to ImageNet's images. However, the relative positioning of constellations remains fixed. Hence, if a model can reliably identify one star or one constellation, it is easy to identify the remaining constellations in the image.

We tried using simple VGG-style CNNs, independently identifying each constellation (88 binary classifications). However, we achieved limited success.

What do you think is the correct way to deal with such sparse input? Has there been any prior work on these kinds of datasets?",8,16
1339,2018-7-25,2018,7,25,23,91s6pb,When multiple realizations of dependent random variables are added they become independent,https://www.reddit.com/r/MachineLearning/comments/91s6pb/when_multiple_realizations_of_dependent_random/,Lopelh,1532528015,# [https://stats.stackexchange.com/questions/358923/when-multiple-realizations-of-dependent-random-variables-are-added-they-become-i](https://stats.stackexchange.com/questions/358923/when-multiple-realizations-of-dependent-random-variables-are-added-they-become-i),0,1
1340,2018-7-25,2018,7,25,23,91siqk,Visual SLAM/Deep Learning Based PhD Studentship Available,https://www.reddit.com/r/MachineLearning/comments/91siqk/visual_slamdeep_learning_based_phd_studentship/,TheToby1,1532530400,[removed],0,1
1341,2018-7-26,2018,7,26,0,91t0xo,[P] Deep Learning Based PhD Studentship,https://www.reddit.com/r/MachineLearning/comments/91t0xo/p_deep_learning_based_phd_studentship/,TheToby1,1532533947,"I am a PhD student in the Computer Vision Group at Maynooth University Department of Computer Science. We are currently looking for applicants for a PhD Studentship in Computer Vision for Autonomous Vehicles.

Please find details on the topic of the PhD and how to apply [here](https://www.maynoothuniversity.ie/computer-science/news/phd-studentship-computer-vision-autonomous-vehicles).",0,2
1342,2018-7-26,2018,7,26,0,91t1yg,"Simple Questions Thread July 25, 2018",https://www.reddit.com/r/MachineLearning/comments/91t1yg/simple_questions_thread_july_25_2018/,AutoModerator,1532534146,[removed],0,1
1343,2018-7-26,2018,7,26,0,91t32m,Getting the Most Out of Your GPU Cluster: Part 1,https://www.reddit.com/r/MachineLearning/comments/91t32m/getting_the_most_out_of_your_gpu_cluster_part_1/,yoavz,1532534361,,0,1
1344,2018-7-26,2018,7,26,1,91t4ei,[D] Why is SGD so sensitive to the initialization of weights?,https://www.reddit.com/r/MachineLearning/comments/91t4ei/d_why_is_sgd_so_sensitive_to_the_initialization/,Jakobovski,1532534613,,0,1
1345,2018-7-26,2018,7,26,1,91t6jl,[R] Conditional Infilling GANs for Data Augmentation in Mammogram Classification,https://www.reddit.com/r/MachineLearning/comments/91t6jl/r_conditional_infilling_gans_for_data/,timmytimmyturner12,1532534986,,1,2
1346,2018-7-26,2018,7,26,1,91tj5u,Zotero | A personal research assistant,https://www.reddit.com/r/MachineLearning/comments/91tj5u/zotero_a_personal_research_assistant/,wavelander,1532537289,,0,1
1347,2018-7-26,2018,7,26,2,91tsl5,[P] GluonNLP: a Deep Learning Toolkit for Natural Language Processing (NLP),https://www.reddit.com/r/MachineLearning/comments/91tsl5/p_gluonnlp_a_deep_learning_toolkit_for_natural/,thomasdlt,1532539072,,5,98
1348,2018-7-26,2018,7,26,2,91tt4z,[crosspost - AMA in r/IAmA] We are data scientists at IBM. Ask us anything about machine learning and AI!,https://www.reddit.com/r/MachineLearning/comments/91tt4z/crosspost_ama_in_riama_we_are_data_scientists_at/,Chtorrr,1532539169,,0,1
1349,2018-7-26,2018,7,26,2,91tu3z,[crosspost - AMA in r/IAmA] We are data scientists at IBM. Ask us anything about machine learning and AI!,https://www.reddit.com/r/MachineLearning/comments/91tu3z/crosspost_ama_in_riama_we_are_data_scientists_at/,Chtorrr,1532539346,,0,1
1350,2018-7-26,2018,7,26,2,91tuni,Q Learning with NN - Conway's Game of Life,https://www.reddit.com/r/MachineLearning/comments/91tuni/q_learning_with_nn_conways_game_of_life/,csnap8,1532539450,"I'm trying to make a reinforcement algorithm that learns the best starting positions to produce an interesting result in Conway's Game of Life. However I'm fairly new to machine learning and am looking for advice on how to set up the framework.

The idea is to have a NxN grid and choose a certain X amount of starting positions, like 4-6. The game will follow the GOL rules until the units have all died or a certain amount of steps have occurred. I'm keeping the reward simple: 0 if all the units die, or the sum of the remaining units.

I'll store the starting state and the final reward as a set, and continue this adding each set to the training batch.

Then I'll use keras+theano to train the model on these batches.

I'm using a neural network with N\^2 input nodes and N\^2 output nodes with 1 or 2 hidden layers, and I'll be using it with a Q learning algorithm.

Initially the starting units will be random, and after some training it will start choosing the X highest valued starting positions.

I'm following [http://outlace.com/rlpart3.html](http://outlace.com/rlpart3.html)  as a tutorial and adjusting it to my own needs.

Any advice on this would be helpful. My main concern is that choosing the top X output values for the starting position won't consider the actual combination/relative location of the positions.

I'm also concerned it won't learn the relation between starting blocks. For example, a 2x2 square of ""live"" units will never die. If the network discovers this in one location, will it learn that it is independent of absolute location, and only the relative distance natters?",0,1
1351,2018-7-26,2018,7,26,2,91twa7,Distill: Differentiable Image Parameterizations,https://www.reddit.com/r/MachineLearning/comments/91twa7/distill_differentiable_image_parameterizations/,longscale,1532539752,,0,1
1352,2018-7-26,2018,7,26,2,91u1rc,[Research] Distill: Differentiable Image Parameterizations,https://www.reddit.com/r/MachineLearning/comments/91u1rc/research_distill_differentiable_image/,longscale,1532540728,,14,89
1353,2018-7-26,2018,7,26,2,91u4db,(x-post from /r/IAmA) We are data scientists at IBM. Ask us anything about machine learning and AI!,https://www.reddit.com/r/MachineLearning/comments/91u4db/xpost_from_riama_we_are_data_scientists_at_ibm/,IBMAnalytics,1532541206,,0,1
1354,2018-7-26,2018,7,26,3,91u7ww,(x-post from /r/IAmA) We are data scientists at IBM. Ask us anything about machine learning and AI!,https://www.reddit.com/r/MachineLearning/comments/91u7ww/xpost_from_riama_we_are_data_scientists_at_ibm/,alexa_y,1532541871,,0,1
1355,2018-7-26,2018,7,26,3,91ugw8,Google Edge TPU: Add accelerated ML to your embedded device,https://www.reddit.com/r/MachineLearning/comments/91ugw8/google_edge_tpu_add_accelerated_ml_to_your/,modeless,1532543494,,0,1
1356,2018-7-26,2018,7,26,3,91umci,"Looking for real scientific data to test your methods on? Have a look at the datasets provided for our challenge: https://smc-datachallenge.ornl.gov/ Topics include Neutron Scattering, Geographic Information Science, Materials Science, Additive Manufacturing, and HPC",https://www.reddit.com/r/MachineLearning/comments/91umci/looking_for_real_scientific_data_to_test_your/,robodasha,1532544492,[removed],0,1
1357,2018-7-26,2018,7,26,3,91up0c, Supervisely goes beyond annotation - latest Deep Learning models out of the box,https://www.reddit.com/r/MachineLearning/comments/91up0c/supervisely_goes_beyond_annotation_latest_deep/,tdionis,1532544976,,0,1
1358,2018-7-26,2018,7,26,4,91v57s,Don't understand the meaning of ''training a dataset'',https://www.reddit.com/r/MachineLearning/comments/91v57s/dont_understand_the_meaning_of_training_a_dataset/,luchins,1532547997,"Hi,   I have a  set  of  data.   Those  data  are  based on  data mining   from  my website.   I  have  the number of  users per month    who  go  to my  website  ( X )  , and   the  time  they  spent on the website on  each webpage ( y ) .

Now  with this   dataset  as  an example,  could you explain  to me please  what's   the  meaning of  training dataset?  If  I would  ''train''  those data,  what  should I  do?  And  what is the meaning of the  word?   A simple   example I am noob starting out  from somewhere, please. (I know  somenthing  about linear  regression and logistic regression, anyway never dealt  with machine learning,  if you could  make an example  with it)",0,1
1359,2018-7-26,2018,7,26,5,91vkqf,"I Created A Site That Gives Personalized Movie Recommendations Based On Your Movie Ratings. It Currently Supports 17 Languages And 26 Categories. You Can Also See Your Friend's Rating. So, Lets Get You A Movie For Your Friday Night :P [OC]",https://www.reddit.com/r/MachineLearning/comments/91vkqf/i_created_a_site_that_gives_personalized_movie/,ravib1996,1532550841,,0,1
1360,2018-7-26,2018,7,26,6,91vtz9,[D] A good project using a news dataset?,https://www.reddit.com/r/MachineLearning/comments/91vtz9/d_a_good_project_using_a_news_dataset/,VerySecretCactus,1532552620,"I've managed to build up a large-ish corpus of news articles from multiple publications over a period of about a month. What are some good projects related to it? 

One option that I have is a sort of aggregate summarization: Given an article as input (e.g. a NYT article about the royal wedding), find articles in other publications about the same topic and create a summary that uses information from all of the articles that are returned by the search function. 

This might be too hard, though; I think the biggest challenge would be avoiding redundant information when summarizing the group of documents. I'd need some form of novelty detection or something. I liked this neat-looking project on Towards Data Science where the CEO of Machine Box [managed to make a very strong classifier that detected fake news](https://towardsdatascience.com/i-trained-fake-news-detection-ai-with-95-accuracy-and-almost-went-crazy-d10589aa57c). Stuff like that would require a lot of pre-handling the data; for the fake-news project the guy manually marked every article as being fake or real.",9,10
1361,2018-7-26,2018,7,26,7,91wfkt,https://discuss.pytorch.org/t/pytorch-net-from-striving-for-simplicity-the-all-convolutional-net/19297/8,https://www.reddit.com/r/MachineLearning/comments/91wfkt/httpsdiscusspytorchorgtpytorchnetfromstrivingforsi/,real_charlie_parker,1532556859,I've tried getting state of the art using the code there but I can't. Does someone know how to get state of the art using the All Conv Net? What am I doing wrong?,0,1
1362,2018-7-26,2018,7,26,7,91wqyv,Replicating state of the art on Cifar10 with an All Convolution Net,https://www.reddit.com/r/MachineLearning/comments/91wqyv/replicating_state_of_the_art_on_cifar10_with_an/,real_charlie_parker,1532559279,"I've tried getting state of the art using the code there but I can't. Does someone know how to get state of the art using the All Conv Net? What am I doing wrong?

[https://discuss.pytorch.org/t/pytorch-net-from-striving-for-simplicity-the-all-convolutional-net/19297/8](https://discuss.pytorch.org/t/pytorch-net-from-striving-for-simplicity-the-all-convolutional-net/19297/8)",0,1
1363,2018-7-26,2018,7,26,10,91y55l,[D] NIPS reviews are reportedly out,https://www.reddit.com/r/MachineLearning/comments/91y55l/d_nips_reviews_are_reportedly_out/,easy_cantaloupe,1532570345,"Reportedly -- I got emails for both reviewer and author roles saying so, but don't see any reviews (except my own, for papers I reviewed) on CMT.",108,51
1364,2018-7-26,2018,7,26,11,91yjhi,[N] Google is making a fast specialized TPU chip for edge devices and a suite of services to support it,https://www.reddit.com/r/MachineLearning/comments/91yjhi/n_google_is_making_a_fast_specialized_tpu_chip/,mllosab,1532573707,,0,1
1365,2018-7-26,2018,7,26,12,91yttf,What to study first?,https://www.reddit.com/r/MachineLearning/comments/91yttf/what_to_study_first/,IsAnobodyHome,1532576274,[removed],0,1
1366,2018-7-26,2018,7,26,12,91ywy4,Interview with Dr. Yu Kai of AISpeech  The Importance of Naturalness in Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/91ywy4/interview_with_dr_yu_kai_of_aispeech_the/,Michael_Pa,1532577120,,0,1
1367,2018-7-26,2018,7,26,13,91z2m1,What are your thoughts/concerns as the investments in and functionality of AutoML increase?,https://www.reddit.com/r/MachineLearning/comments/91z2m1/what_are_your_thoughtsconcerns_as_the_investments/,WrongTechnician,1532578574,[removed],0,1
1368,2018-7-26,2018,7,26,14,91zfu9,[D] How are your NIPS 2018 reviews?,https://www.reddit.com/r/MachineLearning/comments/91zfu9/d_how_are_your_nips_2018_reviews/,AnxiousInteraction28,1532582309,The NIPS 2018 rebuttal period has started and the reviews are out. How are your reviews and what are good rebuttal strategies to convince the reviewers.,45,3
1369,2018-7-26,2018,7,26,14,91zk5x,We are data scientists at IBM. Ask us anything about machine learning and AI!,https://www.reddit.com/r/MachineLearning/comments/91zk5x/we_are_data_scientists_at_ibm_ask_us_anything/,BatmantoshReturns,1532583569,,0,1
1370,2018-7-26,2018,7,26,15,91zp6y,Help with implementing RES30 Network (Noise2Noise reimplementation),https://www.reddit.com/r/MachineLearning/comments/91zp6y/help_with_implementing_res30_network_noise2noise/,Geralt_of_Rivia96,1532585060,[removed],0,1
1371,2018-7-26,2018,7,26,15,91zs9n,training section of dqn and comparison with SVR and RF,https://www.reddit.com/r/MachineLearning/comments/91zs9n/training_section_of_dqn_and_comparison_with_svr/,sara0011,1532585971,[removed],0,1
1372,2018-7-26,2018,7,26,15,91zvb8,Machine Learning in Google BigQuery,https://www.reddit.com/r/MachineLearning/comments/91zvb8/machine_learning_in_google_bigquery/,mitbal,1532586904,,0,1
1373,2018-7-26,2018,7,26,16,9201an,Artificial Intelligence Vs. Machine Learning Vs. Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9201an/artificial_intelligence_vs_machine_learning_vs/,mylearning_key,1532588680,,0,1
1374,2018-7-26,2018,7,26,16,9209ke,Machine Learning Introduction,https://www.reddit.com/r/MachineLearning/comments/9209ke/machine_learning_introduction/,Mmanisha21,1532591220,[removed],0,1
1375,2018-7-26,2018,7,26,16,920bd0,Semantic Image Inpainting with Deep Generative Models (CVPR2017) TensorFlow Implementation,https://www.reddit.com/r/MachineLearning/comments/920bd0/semantic_image_inpainting_with_deep_generative/,Cheng-BinJin,1532591838,,1,1
1376,2018-7-26,2018,7,26,17,920euu,Machine Learning in Google BigQuery,https://www.reddit.com/r/MachineLearning/comments/920euu/machine_learning_in_google_bigquery/,theainerd,1532592989,,0,1
1377,2018-7-26,2018,7,26,17,920gjo,First Steps in Machine Learning with Microsoft Azure. Part 1 | Redwerk,https://www.reddit.com/r/MachineLearning/comments/920gjo/first_steps_in_machine_learning_with_microsoft/,mariafilina,1532593597,,0,1
1378,2018-7-26,2018,7,26,17,920jce,[Research] Unknowable Manipulators: Social Network Curator Algorithms,https://www.reddit.com/r/MachineLearning/comments/920jce/research_unknowable_manipulators_social_network/,ABraveNewWorld2,1532594517,,3,40
1379,2018-7-26,2018,7,26,19,920yxp,[podcast] Why outsourcing memory to technology helps you learn,https://www.reddit.com/r/MachineLearning/comments/920yxp/podcast_why_outsourcing_memory_to_technology/,LiamBigDataDonoghue,1532599533,,0,1
1380,2018-7-26,2018,7,26,19,9212kf,TensorFlow Distribution log_prob as loss function,https://www.reddit.com/r/MachineLearning/comments/9212kf/tensorflow_distribution_log_prob_as_loss_function/,gonzales82,1532600646,,0,1
1381,2018-7-26,2018,7,26,19,92173e,Injera Making Machine | Spring Roll Sheet Machine,https://www.reddit.com/r/MachineLearning/comments/92173e/injera_making_machine_spring_roll_sheet_machine/,liusherry,1532602026,,1,1
1382,2018-7-26,2018,7,26,20,921k9u,Flanging Machine Manufacturers,https://www.reddit.com/r/MachineLearning/comments/921k9u/flanging_machine_manufacturers/,matnfur2017,1532605774,,1,1
1383,2018-7-26,2018,7,26,20,921m2t,Folks interested in studying MIT data science micromasters. How about a study group?,https://www.reddit.com/r/MachineLearning/comments/921m2t/folks_interested_in_studying_mit_data_science/,shash_wat,1532606269,,0,1
1384,2018-7-26,2018,7,26,21,921wrz,Why your machine learning project will fail...,https://www.reddit.com/r/MachineLearning/comments/921wrz/why_your_machine_learning_project_will_fail/,alberto3333,1532608885,,0,1
1385,2018-7-26,2018,7,26,21,921zo5,"[D] Handling missing values in a continuous variable, where NA has importance.",https://www.reddit.com/r/MachineLearning/comments/921zo5/d_handling_missing_values_in_a_continuous/,Jsamaitis,1532609563,"For example, variable CAR\_AGE, integer vales ranging from 0 to 100\~ and NA's when a person doesn't own a car.

**How do you deal with NA's in a case like this?** I can't remove them (half of the data), can't replace them with median or 0's, because new car (age 0) isn't the same as not owning a car and it would also highly increase bias towards 0 or median.

I've thought about creating a categorical variable with NA as separate category and others as either bins (0-10, etc.) or plainly to add as many categories as there are integers (car ages). 

The problem is that it creates a huge sparse matrix (imagine 10 variables similar to this: 10\*100\~ columns).

Also, take a variable, for example, that would indicate pool size (in square meters), for something like house price - small pool is really different than having no pool and as pool size is in square meters, it would take too many categories.

I'm really stumped, any ideas? Thanks.",4,2
1386,2018-7-26,2018,7,26,22,9221ja,What Size Log Splitter Do I Need?,https://www.reddit.com/r/MachineLearning/comments/9221ja/what_size_log_splitter_do_i_need/,blackforesttrees,1532610021,,1,1
1387,2018-7-26,2018,7,26,22,92253z,Looking for the deep learning experts,https://www.reddit.com/r/MachineLearning/comments/92253z/looking_for_the_deep_learning_experts/,viktoriia_shulga,1532610813,,0,1
1388,2018-7-26,2018,7,26,22,9226t0,ML Reading Challenge 101,https://www.reddit.com/r/MachineLearning/comments/9226t0/ml_reading_challenge_101/,aryancodify,1532611198,,0,1
1389,2018-7-26,2018,7,26,22,922f2z,About understanding advanced theory-heavy papers about Generative Adversarial Nets.,https://www.reddit.com/r/MachineLearning/comments/922f2z/about_understanding_advanced_theoryheavy_papers/,porygon93,1532613006,[removed],0,1
1390,2018-7-26,2018,7,26,22,922hdq,"[N] Weekly Machine Learning Opensource Roundup  July 26, 2018",https://www.reddit.com/r/MachineLearning/comments/922hdq/n_weekly_machine_learning_opensource_roundup_july/,stkim1,1532613472,,0,1
1391,2018-7-26,2018,7,26,23,922klz,Why is dropout a good fit for ReLU units?,https://www.reddit.com/r/MachineLearning/comments/922klz/why_is_dropout_a_good_fit_for_relu_units/,nitinsiwach,1532614099,[removed],0,1
1392,2018-7-26,2018,7,26,23,922l81,[D] Deep learning and free software,https://www.reddit.com/r/MachineLearning/comments/922l81/d_deep_learning_and_free_software/,hardmaru,1532614229,,0,1
1393,2018-7-26,2018,7,26,23,922omu,"MIT micromasters in data science, study group.",https://www.reddit.com/r/MachineLearning/comments/922omu/mit_micromasters_in_data_science_study_group/,shash_wat,1532614941,[removed],0,2
1394,2018-7-26,2018,7,26,23,922wcr,[Research] An Unsupervised Approach to Solving Inverse Problems using Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/922wcr/research_an_unsupervised_approach_to_solving/,quagmire_giggity,1532616507,,5,33
1395,2018-7-26,2018,7,26,23,922xoo,Art curator bot,https://www.reddit.com/r/MachineLearning/comments/922xoo/art_curator_bot/,gy0p4k,1532616786,[removed],0,1
1396,2018-7-27,2018,7,27,0,9236at,[N] skorch (pytorch + sklearn) version 0.3.0 released,https://www.reddit.com/r/MachineLearning/comments/9236at/n_skorch_pytorch_sklearn_version_030_released/,ottonemo,1532618494,,1,1
1397,2018-7-27,2018,7,27,0,923e3t,"Study group for MIT micromasters in Data Science,",https://www.reddit.com/r/MachineLearning/comments/923e3t/study_group_for_mit_micromasters_in_data_science/,shash_wat,1532620012,[removed],0,1
1398,2018-7-27,2018,7,27,0,923fjc,Why does Google think they're so smart recommending me videos I've already watched?,https://www.reddit.com/r/MachineLearning/comments/923fjc/why_does_google_think_theyre_so_smart/,bigboyparpa,1532620293,[removed],0,1
1399,2018-7-27,2018,7,27,1,923jyf,"[Discussion] MIT micromasters in data science, study discussions under nurture.ai",https://www.reddit.com/r/MachineLearning/comments/923jyf/discussion_mit_micromasters_in_data_science_study/,shash_wat,1532621120,"The course will start from 3rd of September. Interested people can join telegram, eventually we will have our own forum under AI6 forums.",3,4
1400,2018-7-27,2018,7,27,1,923l65,[D] How would Gmail's new Smart Compose work?,https://www.reddit.com/r/MachineLearning/comments/923l65/d_how_would_gmails_new_smart_compose_work/,FlyingQuokka,1532621343,"I've been learning word embeddings from Coursera, so this seems like it could very well be an application of that, where you take the previous few words (since you don't know the words after the target word) as the context word, and need to predict the target word. Since these suggestions seem to come after you type a few letters, my guess is that it first makes a set of possible target words, then uses the first few letters to get the most likely ones. I'm a beginner at deep learning, so what do you think might be behind this feature?",2,12
1401,2018-7-27,2018,7,27,1,923rdf,50 Free Machine Learning Datasets: Part Two  Financial and Economic Datasets,https://www.reddit.com/r/MachineLearning/comments/923rdf/50_free_machine_learning_datasets_part_two/,Dmitrovic01,1532622517,,0,1
1402,2018-7-27,2018,7,27,2,92427b,[D] What is the MNIST of causal inference?,https://www.reddit.com/r/MachineLearning/comments/92427b/d_what_is_the_mnist_of_causal_inference/,RobRomijnders,1532624543,"So for many of the machine learning problems, we have prototypical data sets and algoritms. To name a few

  * Learn classification with a Naive Bayes Classifier on the Titanic data set
  * Learn regression with Linear regression on the House pricing data set
  * Learn about regularisation with Ridge regression on some points sampled from polynomials
  * Learn about speech recognition using RNN's on the TIMIT data set
  * Learn about image classification using CNN's on the MNIST data set
  * Learn about machine translation using seq2seq on language pairs data set
  * Learn about topic modelling using LDA on the New York Times data set


Now I am curious what is the go-to model and data set to learn about causal inference? In other words, finish the sentence:

  * Learn about causal inference using ..(1).. on the ..(2).. data set",24,96
1403,2018-7-27,2018,7,27,2,92440i,Sharp object detection is my current project . HELP!,https://www.reddit.com/r/MachineLearning/comments/92440i/sharp_object_detection_is_my_current_project_help/,bluewolf99,1532624856,[removed],0,1
1404,2018-7-27,2018,7,27,2,924dvg,New Deep Learning Algorithm Solves Rubiks Cube,https://www.reddit.com/r/MachineLearning/comments/924dvg/new_deep_learning_algorithm_solves_rubiks_cube/,ANNA_Systems,1532626719,,0,1
1405,2018-7-27,2018,7,27,3,924lkp,"[R] NIPS 2018: For those of you that got some harsh reviews, YOU ARE NOT ALONE.",https://www.reddit.com/r/MachineLearning/comments/924lkp/r_nips_2018_for_those_of_you_that_got_some_harsh/,FirstTimeResearcher,1532628148,"Thought this would be a good place to share some of the more 'interesting' reviews that popped for this year's NIPS. Here's a few to get started:

* Their summarization of your paper is just a copy and paste of your introduction/conclusion

* They argue your paper is not relevant for NIPS despite there being a specific track dedicated to your topic

* The reviewer goes on to state something mathematically incorrect with high confidence.

* They cite a parallel NIPS submission on arxiv to be prior work.

...The list goes on. 

For the people new to the research community that are seeing these issues for the first time, you are not alone. Don't feel bad. Take the constructive criticisms to improve your work and move on.

Also, reach out to your meta-reviewer/chair if you feel there is a legitimate case for additional review. Happy rebuttals.",63,162
1406,2018-7-27,2018,7,27,3,924uir,"Reinforcement Learning Datapoints: Provide as many as possible, or process the items?",https://www.reddit.com/r/MachineLearning/comments/924uir/reinforcement_learning_datapoints_provide_as_many/,ollie_123,1532629836,[removed],0,1
1407,2018-7-27,2018,7,27,3,924vte,Why there are different number of reviewers for nips submission,https://www.reddit.com/r/MachineLearning/comments/924vte/why_there_are_different_number_of_reviewers_for/,bbao99,1532630080,"Hello, I noticed that most of the submissions get 3 reviews, while some gets more than 3. Is there any reason for this? ",0,1
1408,2018-7-27,2018,7,27,4,925861,"[D] In respect to Data Engineering/Data Scientist roles, what are Data Pipelines and how is it useful?",https://www.reddit.com/r/MachineLearning/comments/925861/d_in_respect_to_data_engineeringdata_scientist/,Fender6969,1532632404,"I have seen the skill of ""Create Data Pipelines"" on many positions as I'm approaching graduation from college. I've worked on different ML projects, but have never created nor used these myself.

I predominantly work in Python so any help would be great!",0,1
1409,2018-7-27,2018,7,27,4,925bp9,Speculative Models,https://www.reddit.com/r/MachineLearning/comments/925bp9/speculative_models/,worknuf,1532633080,"Recently I have done work on some predictive models. These are regression models attempting to predict whether or not  a business will pay back a loan. The features of the model include things like the amount of money borrowed and the credit worthiness of the business, the city and state of the business, and so on. The goal is to help predict success of future loan applications. The reality is, the model is not trained on a random sample from the whole universe of possible applications; it is trained on a biased subset which was previously selected by humans with their criteria. So there may be some human criteria that eliminated certain applications from ever being accepted, which the model will never see and may have no way of ever knowing about.

This seems like it would be a common dilemma in machine learning. Does anyone know what this is generally called? Are there any ways to mitigate the problem?  ",0,1
1410,2018-7-27,2018,7,27,4,925kix,[P] Deep Reinforcement Learning Course: An intro to Advantage Actor Critic methods: lets play Sonic the Hedgehog!,https://www.reddit.com/r/MachineLearning/comments/925kix/p_deep_reinforcement_learning_course_an_intro_to/,cranthir_,1532634811,[removed],0,1
1411,2018-7-27,2018,7,27,5,925ny8,Why some guys get more than 3 reviews in nips rebuttal?,https://www.reddit.com/r/MachineLearning/comments/925ny8/why_some_guys_get_more_than_3_reviews_in_nips/,bbao99,1532635462,[removed],0,1
1412,2018-7-27,2018,7,27,5,925wst,Has AI surpassed humans at translation? Not even close!,https://www.reddit.com/r/MachineLearning/comments/925wst/has_ai_surpassed_humans_at_translation_not_even/,regalalgorithm,1532637133,,0,1
1413,2018-7-27,2018,7,27,5,9263h9,Grants and Incentives for ML companies and Freelancers,https://www.reddit.com/r/MachineLearning/comments/9263h9/grants_and_incentives_for_ml_companies_and/,AttackTheWack,1532638413,"I work in the ML space, and had a few questions about the various grants and working incentives that are out there for smaller startups (specifically those available from Google, AWS and MS, but I am interested in learning about any others that exist):  


Does anyone here work at a company that is currently using software, service, or other tool provided by a ML grant or incentive from  a large company? If so can you tell me a bit about your company, what branch of ML you're in, and what your experience has been like?  


What are some limitations you have found using these services?  


Do large companies offer similar incentives to Freelancers or are we SOL?  


Examples of what I mean by grant or incentive:  


Google and AWS often provide computing services to ML startups free of charge.

Nvidia give companies access to DGX-1 for a half a year for free then at a discounted rate afterwards.  


Any experience you have with any of the above would help me a lot.",0,1
1414,2018-7-27,2018,7,27,6,9266qk,"Video inputs and audio inputs,both, can activate a particular neuron of ours?",https://www.reddit.com/r/MachineLearning/comments/9266qk/video_inputs_and_audio_inputsboth_can_activate_a/,niszoig,1532639054,,0,1
1415,2018-7-27,2018,7,27,6,926bf0,Generating Music with Expressive Timing and Dynamics,https://www.reddit.com/r/MachineLearning/comments/926bf0/generating_music_with_expressive_timing_and/,sataky,1532639929,,0,1
1416,2018-7-27,2018,7,27,7,926qcj,Python packages for comparing audio clip similarity?,https://www.reddit.com/r/MachineLearning/comments/926qcj/python_packages_for_comparing_audio_clip/,davegoldblatt,1532642982,[removed],0,1
1417,2018-7-27,2018,7,27,7,926uce,[D] PyTorch 0.4.1 Released,https://www.reddit.com/r/MachineLearning/comments/926uce/d_pytorch_041_released/,machinesaredumb,1532643785,,0,2
1418,2018-7-27,2018,7,27,7,9271px,[N] Google AI Chief Jeff Deans ML System Architecture Blueprint,https://www.reddit.com/r/MachineLearning/comments/9271px/n_google_ai_chief_jeff_deans_ml_system/,trcytony,1532645364,,0,1
1419,2018-7-27,2018,7,27,7,92722g,[N] Google AI Chief Jeff Deans ML System Architecture Blueprint,https://www.reddit.com/r/MachineLearning/comments/92722g/n_google_ai_chief_jeff_deans_ml_system/,gwen0927,1532645432,,0,1
1420,2018-7-27,2018,7,27,7,9274pv,"Hi, I proved deep linear network if applying with batch normalization can have analytic solutions for all critical points.",https://www.reddit.com/r/MachineLearning/comments/9274pv/hi_i_proved_deep_linear_network_if_applying_with/,leefwin,1532645995,[removed],0,1
1421,2018-7-27,2018,7,27,8,92756n,"[N] PyTorch releases 0.4.1: Spectral Norm, Adaptive Softmax, faster CPU ops, anomaly detection (NaNs, etc.), Lots of bug fixes, Python 3.7 and CUDA 9.2 support",https://www.reddit.com/r/MachineLearning/comments/92756n/n_pytorch_releases_041_spectral_norm_adaptive/,modernrl,1532646098,,0,1
1422,2018-7-27,2018,7,27,8,927661,"[N] PyTorch releases 0.4.1: Spectral Norm, Adaptive Softmax, faster CPU ops, anomaly detection (NaNs, etc.), Lots of bug fixes, Python 3.7 and CUDA 9.2 support",https://www.reddit.com/r/MachineLearning/comments/927661/n_pytorch_releases_041_spectral_norm_adaptive/,metaAI,1532646304,,0,1
1423,2018-7-27,2018,7,27,8,9277rk,Best Way to start training a net,https://www.reddit.com/r/MachineLearning/comments/9277rk/best_way_to_start_training_a_net/,KyleBoyer,1532646630,[removed],0,1
1424,2018-7-27,2018,7,27,8,92788x,"[R] PyTorch releases 0.4.1: Faster CPU ops, bug fixes, Python 3.7 and CUDA 9.2 support",https://www.reddit.com/r/MachineLearning/comments/92788x/r_pytorch_releases_041_faster_cpu_ops_bug_fixes/,metaAI,1532646733,,0,1
1425,2018-7-27,2018,7,27,8,927bhs,A curated list of research papers on learning disentangled representations,https://www.reddit.com/r/MachineLearning/comments/927bhs/a_curated_list_of_research_papers_on_learning/,mlmmmachine,1532647420,,0,1
1426,2018-7-27,2018,7,27,8,927e8v,A curated list of research papers on learning disentangled representations,https://www.reddit.com/r/MachineLearning/comments/927e8v/a_curated_list_of_research_papers_on_learning/,stensool,1532648019,"## I'm doing a master's thesis on learning disentangled representations, and have put together a list of interesting work I've come across, which I'll be updating dynamically. I hope somebody might find it as a useful reference: [https://github.com/sootlasten/disentangled-representation-papers](https://github.com/sootlasten/disentangled-representation-papers)",0,1
1427,2018-7-27,2018,7,27,8,927gb2,[R] A Light Introduction to Transfer Learning for NLP,https://www.reddit.com/r/MachineLearning/comments/927gb2/r_a_light_introduction_to_transfer_learning_for/,omarsar,1532648478,,0,1
1428,2018-7-27,2018,7,27,8,927hne,[Project] A curated list of research papers on learning disentangled representations,https://www.reddit.com/r/MachineLearning/comments/927hne/project_a_curated_list_of_research_papers_on/,stensool,1532648781,"I'm doing a master's thesis on learning disentangled representations, and have put together a list of interesting work I've come across, which I'll be updating dynamically. I hope somebody might find it as a useful reference: [https://github.com/sootlasten/disentangled-representation-papers](https://github.com/sootlasten/disentangled-representation-papers)",8,38
1429,2018-7-27,2018,7,27,8,927jt9,Online Database with Edge and Point Annotations of Chest X-Rays for ASM Segmentation,https://www.reddit.com/r/MachineLearning/comments/927jt9/online_database_with_edge_and_point_annotations/,MathMagus,1532649260,[removed],0,1
1430,2018-7-27,2018,7,27,9,927odk,Earthquake prediction from dataset,https://www.reddit.com/r/MachineLearning/comments/927odk/earthquake_prediction_from_dataset/,KaneHau,1532650317,[removed],0,1
1431,2018-7-27,2018,7,27,9,927vh4,[P] PyTorch implementation of GANimation (ECCV 2018 Oral),https://www.reddit.com/r/MachineLearning/comments/927vh4/p_pytorch_implementation_of_ganimation_eccv_2018/,kaoshost,1532651927,"Code: [https://github.com/albertpumarola/GANimation](https://github.com/albertpumarola/GANimation)

Paper: [http://www.albertpumarola.com/publications/files/pumarola2018ganimation.pdf](http://www.albertpumarola.com/publications/files/pumarola2018ganimation.pdf)

[Anatomically-aware Facial Animation from a Single Image](https://i.redd.it/e728b1uwydc11.png)",0,1
1432,2018-7-27,2018,7,27,10,928fey,Auto-generated image phylogeny dataset from /r/Photoshop battles for learning image forensics [xpost from /r/Datasets],https://www.reddit.com/r/MachineLearning/comments/928fey/autogenerated_image_phylogeny_dataset_from/,aDutchofMuch,1532656542,,0,1
1433,2018-7-27,2018,7,27,11,928j2p,Multiple GPUs and Batch Sizes?,https://www.reddit.com/r/MachineLearning/comments/928j2p/multiple_gpus_and_batch_sizes/,soulslicer0,1532657409,"Hi all,

If I have a model being trained with a batch size of 10 on 1 GPU. Vs a batch size of 5 on 2 GPUs. Should it be equivalent in terms of training  loss / accuracy over time?

I ask because I wish to increase the complexity of one of my models slightly, but it no longer fits on a GPU, so I am considering reducing the batch size but using more GPUs in the same motherboard",0,1
1434,2018-7-27,2018,7,27,11,928nul,[D] Lower precision CNN for faster training,https://www.reddit.com/r/MachineLearning/comments/928nul/d_lower_precision_cnn_for_faster_training/,HigherTopoi,1532658567,"Is there any recent paper that trained a low precision (e.g. ternary) CNN with small reduction in loss, a significant speedup in training with GPU (e.g. V100) and without requiring any pre-training step, such as knowledge distillation? I'm aware of mixed precision training, but I was wondering if anything better was proposed in 2018. ",0,1
1435,2018-7-27,2018,7,27,11,928qsu,Automatic Ginger Separating Machine for Sale-Romiter Machinery,https://www.reddit.com/r/MachineLearning/comments/928qsu/automatic_ginger_separating_machine_for/,peterleemachinery,1532659272,,0,1
1436,2018-7-27,2018,7,27,12,928woq,Looking for a tutor. Paid. Skype.,https://www.reddit.com/r/MachineLearning/comments/928woq/looking_for_a_tutor_paid_skype/,MysteryMo,1532660716,[removed],0,1
1437,2018-7-27,2018,7,27,12,9293py,[P] Simple Tensorflow implementation of FusionGAN (CVPR 2018),https://www.reddit.com/r/MachineLearning/comments/9293py/p_simple_tensorflow_implementation_of_fusiongan/,taki0112,1532662558,https://i.redd.it/a3i84cd4vec11.png,4,31
1438,2018-7-27,2018,7,27,13,929m1i,[P] Simple PyTorch implementation of GANimation (ECCV 2018 Oral),https://www.reddit.com/r/MachineLearning/comments/929m1i/p_simple_pytorch_implementation_of_ganimation/,kaoshost,1532667427,,14,323
1439,2018-7-27,2018,7,27,14,929nwd,[R] Papers that compare Human Learning and AI,https://www.reddit.com/r/MachineLearning/comments/929nwd/r_papers_that_compare_human_learning_and_ai/,MyMastersAccount,1532667922,"Hey guys, 

Im after some guidance on finding research that examines the learning properties between humans(specifically babies) and AI.
The two fields i want to compare are cognitive science (papers like Chompsky, 1965; PoS theory etc) and computer science. 
I have hit a road block and cannot think of relevant keywords etc.

Any help will be appreciated. 

Thanks",17,12
1440,2018-7-27,2018,7,27,15,92a99j,What is Feature Selection and its techniques,https://www.reddit.com/r/MachineLearning/comments/92a99j/what_is_feature_selection_and_its_techniques/,munishmaxtech,1532674171,,0,1
1441,2018-7-27,2018,7,27,16,92absu,[P] Deep Reinforcement Learning Course new article: Advantage Actor Critic methods: lets play Sonic the Hedgehog!,https://www.reddit.com/r/MachineLearning/comments/92absu/p_deep_reinforcement_learning_course_new_article/,cranthir_,1532674961,[removed],0,1
1442,2018-7-27,2018,7,27,16,92agna,"If you had to show one paper to someone to show that machine learning is beautiful, what would you choose? (assuming they're equipped to understand it)",https://www.reddit.com/r/MachineLearning/comments/92agna/if_you_had_to_show_one_paper_to_someone_to_show/,cappius,1532676431,,0,1
1443,2018-7-27,2018,7,27,16,92ah2b,Machine Learning Introduction,https://www.reddit.com/r/MachineLearning/comments/92ah2b/machine_learning_introduction/,Mmanisha21,1532676574,[removed],0,1
1444,2018-7-27,2018,7,27,16,92ajpy,"[R] Linking Connectivity, Dynamics, and Computations in Low-Rank Recurrent Neural Networks",https://www.reddit.com/r/MachineLearning/comments/92ajpy/r_linking_connectivity_dynamics_and_computations/,jakn,1532677471,,1,9
1445,2018-7-27,2018,7,27,16,92aku1,"[R] PyTorch releases 0.4.1: Faster CPU ops, bug fixes, Python 3.7 and CUDA 9.2 support",https://www.reddit.com/r/MachineLearning/comments/92aku1/r_pytorch_releases_041_faster_cpu_ops_bug_fixes/,metarl2,1532677863,,0,1
1446,2018-7-27,2018,7,27,17,92aqj4,[R] ACL 2018 Highlights,https://www.reddit.com/r/MachineLearning/comments/92aqj4/r_acl_2018_highlights/,ofirpress,1532679798,,1,17
1447,2018-7-27,2018,7,27,17,92auuf,Computer Vision Research Fields [D],https://www.reddit.com/r/MachineLearning/comments/92auuf/computer_vision_research_fields_d/,deepKrish,1532681302,What are some active areas of research in CV worth getting into?,7,1
1448,2018-7-27,2018,7,27,18,92aze5,[R] Spectral Normalization: How to check spectral norm is working during training?,https://www.reddit.com/r/MachineLearning/comments/92aze5/r_spectral_normalization_how_to_check_spectral/,Hhhhhhhhhhao,1532682843,"Hi, I'm training to implement spectral normalization in keras and use it in my GANs training.

How can I check whether the spectral normalization is working during the training process?",0,1
1449,2018-7-27,2018,7,27,18,92b1ea,Resources to get started in NLP from Beginner to Advance,https://www.reddit.com/r/MachineLearning/comments/92b1ea/resources_to_get_started_in_nlp_from_beginner_to/,prash706,1532683507,[removed],0,1
1450,2018-7-27,2018,7,27,18,92b6z5,Tape Edge Sewing Head,https://www.reddit.com/r/MachineLearning/comments/92b6z5/tape_edge_sewing_head/,matnfur2017,1532685372,,1,1
1451,2018-7-27,2018,7,27,20,92bng6,Simple implementation of Progressive Growing GAN with WGAN-GP loss in Pytorch or Kears?,https://www.reddit.com/r/MachineLearning/comments/92bng6/simple_implementation_of_progressive_growing_gan/,machinesa,1532690408,[removed],0,1
1452,2018-7-27,2018,7,27,21,92bwmr,[N] A Practitioners Guide to Processing &amp; Understanding Text Part 1: Data Retrieval with Web Scraping,https://www.reddit.com/r/MachineLearning/comments/92bwmr/n_a_practitioners_guide_to_processing/,friscotime,1532692951,,0,1
1453,2018-7-27,2018,7,27,21,92c73e,[D] Has AI surpassed humans at translation? Not even close!,https://www.reddit.com/r/MachineLearning/comments/92c73e/d_has_ai_surpassed_humans_at_translation_not_even/,tuan3w,1532695530,,10,8
1454,2018-7-27,2018,7,27,22,92clf3,Pandas DataFrame/R data.frame in modern C++,https://www.reddit.com/r/MachineLearning/comments/92clf3/pandas_dataframer_dataframe_in_modern_c/,hmoein,1532698801,[removed],0,1
1455,2018-7-27,2018,7,27,23,92cx7p,"[D]Strongly recommend to add ""Student Reviewer"" to ML conference",https://www.reddit.com/r/MachineLearning/comments/92cx7p/dstrongly_recommend_to_add_student_reviewer_to_ml/,yunzeman,1532701242,"I understand ***more and more submission is making demand for more and more reviewers***. 

But, instead of implicitly invite unqualified (yet) PhD students (Sometimes even undergrads!) to review papers, the committee can absolutely explicitly add a ""student reviewer"". 

Student Reviewer should review the paper first, and then senior reviewers like professors can make their comments as auxiliary information to give final review.  Critical and pertinent student reviewer can be awarded to encourage better student reviewer and help them step into the research field faster. 

We can aslo get rid of the current disaster of unqualitied reviewer (a least to a great extent)

I can't see there are any cons in this approach. ",23,113
1456,2018-7-27,2018,7,27,23,92czgi,[D]Are implementations of papers considered as projects?,https://www.reddit.com/r/MachineLearning/comments/92czgi/dare_implementations_of_papers_considered_as/,Susamak,1532701722,I'm planning to apply for masters and was wondering if implementing papers would be considered as good projects.Or do I have to come up with something novel for it to be considered as a project? If so how would I go about the process of coming up with ideas for good projects?,9,1
1457,2018-7-27,2018,7,27,23,92d0ck,NIPS - Contact Area Chair over Unreasonable Review?,https://www.reddit.com/r/MachineLearning/comments/92d0ck/nips_contact_area_chair_over_unreasonable_review/,locochocolato,1532701917,As a 7-6-2 guy I feel like George Bush in the 2000 election (2 reviewer being Florida in this analogy). Do you recommend contacting the AC/ Meta-reviewer before or right after the rebuttal is made? Or should we wait until the final September results are out?,0,1
1458,2018-7-27,2018,7,27,23,92d2na,BM25F Algorithm,https://www.reddit.com/r/MachineLearning/comments/92d2na/bm25f_algorithm/,feedknack,1532702388,[removed],0,1
1459,2018-7-27,2018,7,27,23,92d7ha,Need for Speed Drift AI using HyperNEAT,https://www.reddit.com/r/MachineLearning/comments/92d7ha/need_for_speed_drift_ai_using_hyperneat/,ljmocic,1532703356,,0,1
1460,2018-7-28,2018,7,28,0,92dgxf,Regarding DL framework,https://www.reddit.com/r/MachineLearning/comments/92dgxf/regarding_dl_framework/,mohit_jarvis29,1532705194,[removed],0,1
1461,2018-7-28,2018,7,28,0,92dmw3,[R] Evaluating and Understanding the Robustness of Adversarial Logit Pairing,https://www.reddit.com/r/MachineLearning/comments/92dmw3/r_evaluating_and_understanding_the_robustness_of/,andrew_ilyas,1532706365,,7,28
1462,2018-7-28,2018,7,28,0,92dnas,NIPS - Contact Area Chair over Unreasonable Review? [D],https://www.reddit.com/r/MachineLearning/comments/92dnas/nips_contact_area_chair_over_unreasonable_review_d/,locochocolato,1532706445,As a 7-6-2 guy I feel like George Bush in the 2000 election (2 reviewer being Florida in this analogy). Do you recommend contacting the AC/ Meta-reviewer before or right after the rebuttal is made? Or should we wait until the final September results are out?,0,0
1463,2018-7-28,2018,7,28,1,92dy84,[D] The NIPS experiment (2014),https://www.reddit.com/r/MachineLearning/comments/92dy84/d_the_nips_experiment_2014/,goolulusaurs,1532708575,,8,77
1464,2018-7-28,2018,7,28,1,92e320,[P] New YouTube Channel on How We Interact With Machine Learning - Feedback Wanted,https://www.reddit.com/r/MachineLearning/comments/92e320/p_new_youtube_channel_on_how_we_interact_with/,everydAI,1532709536,"Hi everyone, 

I've been interested in finding a way to create discussions on ML with the larger public, and recently created a YouTube channel on how we interact with ML. My first video is on the difference between AI and ML, and the next couple videos will focus on social media uses that people might be more familiar with. I'll have a video coming out later today focused on AI and Instagram too. 

I'm looking for feedback on how I can make the channel better (as well as to spread the word (: ), so please let me know what you think! 

[https://www.youtube.com/channel/UC1H1NWNTG2Xi3pt85ykVSHA](https://www.youtube.com/channel/UC1H1NWNTG2Xi3pt85ykVSHA)

Note: this Reddit account is only for this channel, but I've been subbed here for over a year via a different account. 

Thanks! ",0,1
1465,2018-7-28,2018,7,28,2,92enkq,Computing services for Hyperparameters,https://www.reddit.com/r/MachineLearning/comments/92enkq/computing_services_for_hyperparameters/,AttackTheWack,1532713432,[removed],0,1
1466,2018-7-28,2018,7,28,2,92eoqp,Features--- machine learning,https://www.reddit.com/r/MachineLearning/comments/92eoqp/features_machine_learning/,luchins,1532713641,"Hello, I understand  what  are the classes  in ML,  but  I can't  understand  what  they mean  with  ''features''  in Machine learning.  Could  anyone  explain those  please?  Possibly in an easy  way  to understand (I am starting out with Machine learning)",0,1
1467,2018-7-28,2018,7,28,3,92et6q,ReLU intuition with the dot product?,https://www.reddit.com/r/MachineLearning/comments/92et6q/relu_intuition_with_the_dot_product/,MarxSoul55,1532714490,"Commonly cited benefits of the rectified linear unit as an activation function are:

1. It alleviates the vanishing gradient problem by being the identity function for positive inputs.
2. It's simplistic and it's fast.

I came to thinking about another benefit for ReLU, which deals with the ""thresholding"" behavior of the ReLU.

My interpretation has to do with the dot product in convolutional neural networks. As everyone knows, when the kernel is slid over its input window, it computes the dot product as with vectors. The process of convolution can be interpreted as looking for a specific pattern throughout an image.

Now, the only thing that affects the dot product's sign is the angle between the two vectorsin this case, the kernel and its window. Zero degrees means perfect correlation, 90 means no correlation, and 180 implies ""opposing"" correlation.

Since ReLU kills off the input at the point of zero, you can interpret this as killing off dot products between the kernel and its window wherein each input doesn't correlate enough in terms of its direction. In other words, for there to be any output at all, the directions of each input vector have to have some correlation.

After direction is considered, the magnitudes of each vector take over and can increase or decrease the strength of the activation.

Within this interpretation, the ReLU seems like an oddly natural fit for an activation function interleaved with dot products.

Thoughts?",0,1
1468,2018-7-28,2018,7,28,4,92fce7,Google colab gives me only 11MB of GPU memory,https://www.reddit.com/r/MachineLearning/comments/92fce7/google_colab_gives_me_only_11mb_of_gpu_memory/,l0ve_y0u_t00,1532718185,[removed],0,1
1469,2018-7-28,2018,7,28,5,92g0ie,We built a human-sized robot for ML hackers,https://www.reddit.com/r/MachineLearning/comments/92g0ie/we_built_a_humansized_robot_for_ml_hackers/,ZachAllen417,1532723002,,9,7
1470,2018-7-28,2018,7,28,8,92hbyo,Is it possible to train a neural network to detect lies from video and audio recordings?,https://www.reddit.com/r/MachineLearning/comments/92hbyo/is_it_possible_to_train_a_neural_network_to/,theghostecho,1532732842,[removed],0,1
1471,2018-7-28,2018,7,28,8,92hd8l,How to make data unpredictable,https://www.reddit.com/r/MachineLearning/comments/92hd8l/how_to_make_data_unpredictable/,mok95,1532733118,[removed],0,1
1472,2018-7-28,2018,7,28,9,92hqum,"Is it right, Python is leading the race in all programming language due the high demand of ML?",https://www.reddit.com/r/MachineLearning/comments/92hqum/is_it_right_python_is_leading_the_race_in_all/,ritesheck,1532736305,,0,1
1473,2018-7-28,2018,7,28,10,92i6wf,"Using external GPU, good idea?",https://www.reddit.com/r/MachineLearning/comments/92i6wf/using_external_gpu_good_idea/,cyeee,1532740134,[removed],0,1
1474,2018-7-28,2018,7,28,11,92im90,"[QuickQuestion] I am training a SVM Model for audio data, and I am doing it with and without noise signal. But I am getting surprising error results in both of these cases, more in description",https://www.reddit.com/r/MachineLearning/comments/92im90/quickquestion_i_am_training_a_svm_model_for_audio/,ByMAster2,1532744115,[removed],0,1
1475,2018-7-28,2018,7,28,11,92iumw,"What is a NN if it isn't ""fully connected""?",https://www.reddit.com/r/MachineLearning/comments/92iumw/what_is_a_nn_if_it_isnt_fully_connected/,3aminthemornin,1532746333,[removed],0,1
1476,2018-7-28,2018,7,28,13,92ja6d,Important Unanswered Questions of 2018 in Data Science and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/92ja6d/important_unanswered_questions_of_2018_in_data/,asifrazzaq1988,1532750542,,0,1
1477,2018-7-28,2018,7,28,14,92jshq,A thought experiment to extract big datasets from free models.,https://www.reddit.com/r/MachineLearning/comments/92jshq/a_thought_experiment_to_extract_big_datasets_from/,HarambeTownley,1532755772,[removed],0,1
1478,2018-7-28,2018,7,28,16,92kfk4,A thought experiment to extract big datasets from free models,https://www.reddit.com/r/MachineLearning/comments/92kfk4/a_thought_experiment_to_extract_big_datasets_from/,HarambeTownley,1532763398,[removed],0,1
1479,2018-7-28,2018,7,28,16,92kic1,Convertible Sofa Bunk Bed Manufacturer,https://www.reddit.com/r/MachineLearning/comments/92kic1/convertible_sofa_bunk_bed_manufacturer/,matnfur2017,1532764415,,1,1
1480,2018-7-28,2018,7,28,17,92kk6a,[P] Grokking PyTorch,https://www.reddit.com/r/MachineLearning/comments/92kk6a/p_grokking_pytorch/,Kaixhin,1532765101,,0,1
1481,2018-7-28,2018,7,28,17,92kk73,9 Best Machine Learning and Deep Learning Courses for 2018,https://www.reddit.com/r/MachineLearning/comments/92kk73/9_best_machine_learning_and_deep_learning_courses/,ford4321,1532765111,,0,2
1482,2018-7-28,2018,7,28,17,92kqzg,[D] How do convnets work on any input size?,https://www.reddit.com/r/MachineLearning/comments/92kqzg/d_how_do_convnets_work_on_any_input_size/,ME_PhD,1532767702,"I've seen object detection APIs that work with images of any input size / aspect ratio. How is this achieved?

Only way I can think of is scaling - but if the aspect ratio is off by too much, I'd assume the non-uniform stretching would cause problems. ",8,9
1483,2018-7-28,2018,7,28,18,92kwba,Not-So-Deep Reinforcement Learning for dummies Part 1,https://www.reddit.com/r/MachineLearning/comments/92kwba/notsodeep_reinforcement_learning_for_dummies_part/,thisisppn,1532769744,,0,1
1484,2018-7-28,2018,7,28,22,92m0lw,[R] Conditional Infilling GANs for Data Augmentation in Mammogram Classification,https://www.reddit.com/r/MachineLearning/comments/92m0lw/r_conditional_infilling_gans_for_data/,AcceptableAstronaut,1532783500,,3,15
1485,2018-7-28,2018,7,28,22,92m31h,Understanding Tensorflow's tensors shape: static and dynamic,https://www.reddit.com/r/MachineLearning/comments/92m31h/understanding_tensorflows_tensors_shape_static/,pgaleone,1532784195,,0,1
1486,2018-7-28,2018,7,28,23,92mf70,Reinforcement Learning with on line auctions,https://www.reddit.com/r/MachineLearning/comments/92mf70/reinforcement_learning_with_on_line_auctions/,cadalma,1532787366,[removed],0,1
1487,2018-7-28,2018,7,28,23,92mjj3,[R] Reliable Uncertainty Estimates in Deep Neural Networks using Noise Contrastive Priors,https://www.reddit.com/r/MachineLearning/comments/92mjj3/r_reliable_uncertainty_estimates_in_deep_neural/,danijar,1532788468,"Paper: [https://arxiv.org/abs/1807.09289](https://arxiv.org/abs/1807.09289)

https://i.redd.it/zb5701pf9pc11.png",17,80
1488,2018-7-28,2018,7,28,23,92mkuj,How to use AWS for generating real-time recommendations using collaborative filtering?,https://www.reddit.com/r/MachineLearning/comments/92mkuj/how_to_use_aws_for_generating_realtime/,ashishchopra778,1532788811,[removed],0,1
1489,2018-7-29,2018,7,29,0,92mw64,"""The Value of Machine Learning"", what do you think to this article? What do you think is the best added value?",https://www.reddit.com/r/MachineLearning/comments/92mw64/the_value_of_machine_learning_what_do_you_think/,AlgoLibUK,1532791500,,0,1
1490,2018-7-29,2018,7,29,0,92n10p,[D] Current State of the Art in Voice Duping?,https://www.reddit.com/r/MachineLearning/comments/92n10p/d_current_state_of_the_art_in_voice_duping/,Neilson5,1532792581,"In the past I have primarily done some analysis on audio data, using mostly classical machine learning techniques and some deep learning techniques. 

I have an idea for a project that involves voice modulation and duplication. I have some ideas for architecture, but I am having a hard time finding papers that are solely about changing an input voice to generate a target voice. I see plenty on speech synthesis, but I think my problem should be easier given that I am supplying it the base and training it to transform, not synthesize. 

I hope to accomplish two things with this project. The first is obvious, build a model that works well (easier said than done of course).

The second goal isn't really relevant to the question, but I would love some insight as well. Let me know if this should be made into a separate post though. 

My second goal involves understanding how much data would be necessary between two voices to build a decent profile that allows for a convincing transformation. 

For example, given that I have input voice A and a  Target B, such as a series of recordings by Patrick Stewart and a sample of Voice A copying the content of those recordings. How many hours/samples of input A ane target B will be necessary build a model that creates a convincing voice dupe. Once I have a model that works well initially, see how far I can whittle down the amount of data, accompanied by architecture modification, so any arbitrary voice can be transformed into a convincing duplication.

Thanks!",9,14
1491,2018-7-29,2018,7,29,1,92n8e4,"[D] I am training a SVM Model for audio data, and I am doing it with and without noise signal. But I am getting surprising error results in both of these cases, more in description",https://www.reddit.com/r/MachineLearning/comments/92n8e4/d_i_am_training_a_svm_model_for_audio_data_and_i/,ByMAster2,1532794221,"I recorded 2 minutes of footstep audio data in a silent room, and I trained with my SVM model and I was getting error results of **14%.** My class identifiers were as follows:

1 for footstep sound

0 for no sound

For this 2 minutes of data, I manually labeled each second of data in the above 2 categories.


After doing the above I recorded 20 more minutes of footstep audio giving me the following three databases:

-------------------

**Database 1 -** 2 minutes of Audio recording  

**Class Labels -** Manually Labelled for each second

 --------------- 

**Database 2 -** 20 minutes recording of data.


**Class Labels -** '1' for every second

-----------------
**Database 3 -** Noise Signal downloaded from the internet.

**Class Labels -** '0' for every second

------------------

**Database 4 -** 20 minutes of data + Noise Signal

**Class Labels -** '1' for every second


-------------------------------


When I used all the above 4 databases I was getting error results of 9% which is much less than 14% obtained earlier by just using database 1, which made me wonder if this is the correct way or not for training SVM

",0,1
1492,2018-7-29,2018,7,29,1,92ngju,[R] Deep Neural Networks and the 3D Binary Sudoku Puzzle,https://www.reddit.com/r/MachineLearning/comments/92ngju/r_deep_neural_networks_and_the_3d_binary_sudoku/,QuantMountain,1532796040,,2,2
1493,2018-7-29,2018,7,29,2,92no8q,Transfer learning on non-CNN models?,https://www.reddit.com/r/MachineLearning/comments/92no8q/transfer_learning_on_noncnn_models/,pkgyawali,1532797697,Any example of transfer learning on non-CNN models? Any thoughts? ,0,1
1494,2018-7-29,2018,7,29,3,92o3qx,[P] ToriLLE: Learning environment for hand-to-hand combat based on Toribash,https://www.reddit.com/r/MachineLearning/comments/92o3qx/p_torille_learning_environment_for_handtohand/,Miffyli,1532801120,,0,1
1495,2018-7-29,2018,7,29,4,92oorl,New to ML and looking for advice and guidance for research paper,https://www.reddit.com/r/MachineLearning/comments/92oorl/new_to_ml_and_looking_for_advice_and_guidance_for/,MTwezzy,1532805729,[removed],0,1
1496,2018-7-29,2018,7,29,4,92otcs,PyTorch Project Template: Do it the smart way,https://www.reddit.com/r/MachineLearning/comments/92otcs/pytorch_project_template_do_it_the_smart_way/,hagerrady,1532806780,,1,5
1497,2018-7-29,2018,7,29,4,92ouuv,[R] The TerpreT problem and the limits of SGD,https://www.reddit.com/r/MachineLearning/comments/92ouuv/r_the_terpret_problem_and_the_limits_of_sgd/,mttd,1532807109,,7,19
1498,2018-7-29,2018,7,29,5,92ozxw,[D] What are the best results of ML in medical imaging? Any systems implemented?,https://www.reddit.com/r/MachineLearning/comments/92ozxw/d_what_are_the_best_results_of_ml_in_medical/,to4life,1532808251,"There are a lot of medical image datasets coming out, kaggle challenges, ML teams working with health care professionals, etc. 

What's come of it so far? Big results? Commercial systems implemented? 

Would love to see papers, companies, videos, etc showing the results. 

Also a general discussion of what the main problems and challenges are in the field.",17,54
1499,2018-7-29,2018,7,29,5,92p0dq,[P] Balcony-418 DIY Dataset For ML Experiments,https://www.reddit.com/r/MachineLearning/comments/92p0dq/p_balcony418_diy_dataset_for_ml_experiments/,paubric,1532808348,,0,1
1500,2018-7-29,2018,7,29,5,92p4rs,Faiss-Server in C++/gRPC,https://www.reddit.com/r/MachineLearning/comments/92p4rs/faissserver_in_cgrpc/,aqny,1532809340,,0,1
1501,2018-7-29,2018,7,29,5,92p63w,[Project] Pytorch Project Template: Do it the smart way,https://www.reddit.com/r/MachineLearning/comments/92p63w/project_pytorch_project_template_do_it_the_smart/,hagerrady,1532809651,,0,2
1502,2018-7-29,2018,7,29,5,92p8vz,[P] Pytorch Project Template: Do it the smart way,https://www.reddit.com/r/MachineLearning/comments/92p8vz/p_pytorch_project_template_do_it_the_smart_way/,hagerrady,1532810282,,4,11
1503,2018-7-29,2018,7,29,6,92ptlf,[D] ReLU intuition with the dot product?,https://www.reddit.com/r/MachineLearning/comments/92ptlf/d_relu_intuition_with_the_dot_product/,MarxSoul55,1532815063," Commonly cited benefits of the rectified linear unit as an activation function are:

1. It alleviates the vanishing gradient problem by being the identity function for positive inputs.
2. It's simplistic and it's fast.

I came to thinking about another benefit for ReLU, which deals with the ""thresholding"" behavior of the ReLU.

My interpretation has to do with the dot product in convolutional neural networks. As everyone knows, when the kernel is slid over its input window, it computes the dot product as with vectors. The process of convolution can be interpreted as looking for a specific pattern throughout an image.

Now, the only thing that affects the dot product's sign is the angle between the two vectorsin this case, the kernel and its window. Zero degrees means perfect correlation, 90 means no correlation, and 180 implies ""opposing"" correlation.

Since ReLU kills off the input at the point of zero, you can interpret this as killing off dot products between the kernel and its window wherein each input doesn't correlate enough in terms of its direction. In other words, for there to be any output at all, the directions of each input vector have to have some correlation.

After direction is considered, the magnitudes of each vector take over and can increase or decrease the strength of the activation.

Within this interpretation, the ReLU seems like an oddly natural fit for an activation function interleaved with dot products.

Thoughts? ",8,7
1504,2018-7-29,2018,7,29,7,92q0iw,[P] Pytorch Project Template,https://www.reddit.com/r/MachineLearning/comments/92q0iw/p_pytorch_project_template/,moemen95,1532816635,,0,1
1505,2018-7-29,2018,7,29,10,92r3ds,Fees for NIPS 2018 Workshop,https://www.reddit.com/r/MachineLearning/comments/92r3ds/fees_for_nips_2018_workshop/,randy_wales,1532826346,[removed],0,1
1506,2018-7-29,2018,7,29,11,92rle8,TensorFlow.js in 7 Minutes,https://www.reddit.com/r/MachineLearning/comments/92rle8/tensorflowjs_in_7_minutes/,i_am_adl,1532831314,[removed],0,1
1507,2018-7-29,2018,7,29,12,92rs5w,Experimenting with Tensorflow.js,https://www.reddit.com/r/MachineLearning/comments/92rs5w/experimenting_with_tensorflowjs/,i_am_adl,1532833277,[removed],0,1
1508,2018-7-29,2018,7,29,12,92ry8t,[D] What is the SOTA for interpretability?,https://www.reddit.com/r/MachineLearning/comments/92ry8t/d_what_is_the_sota_for_interpretability/,Daniloz,1532835042,"I am entering the field of interpretability for machine learning and I have seen some techniques. Everything seems to be in its infancy, even for the machine learning field. 

The most exciting algorithms that I used were [LIME](https://github.com/marcotcr/lime) and [GradCAM](https://arxiv.org/abs/1610.02391).

Also, here are some good resources that I found on the subject:

[https://github.com/h2oai/mli-resources](https://github.com/h2oai/mli-resources)

[https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)

[https://distill.pub/2018/building-blocks/](https://distill.pub/2018/building-blocks/)

Seen that, what can we call as the state-of-the-art in this subfield? If non existent, what is the most used in the industry?",5,5
1509,2018-7-29,2018,7,29,13,92s6lu,"Researchers, what project are you currently working on?",https://www.reddit.com/r/MachineLearning/comments/92s6lu/researchers_what_project_are_you_currently/,rajikaimal,1532837510,[removed],0,1
1510,2018-7-29,2018,7,29,14,92siaz,[D] Good practices for attaching codes to replicate the results in a paper?,https://www.reddit.com/r/MachineLearning/comments/92siaz/d_good_practices_for_attaching_codes_to_replicate/,HigherTopoi,1532841052,"Upon submitting your paper to a conference, it is recommended to attach codes (more precisely the link to the codes) for a third party to replicate the results. Ideally, you should organize the codes in a way such that one can readily verify every results in your paper using your codes. However, this may be a bit too onerous if you compare dozens of models over several experiments. Especially, the readers may not be interested in reproducibility of intermediate results, and what really matters is, in my opinion, the performance of your best model and the baseline. Now, I have a few questions:

1. Am I correct that it usually suffices to organize the codes in a way such that one can easily verify the result for the baseline and the best model?

2. Do you have any tips for attaching codes?

3. I've seen many papers being scored low for their methods being unclear. In general, does attaching codes prevent your paper from being scored low for this reason?  

4. I heard some conferences are trying to mandate to attach codes for reproducibility. Is this real?
",10,4
1511,2018-7-29,2018,7,29,14,92smsu,[D] How does the human brain prevent over-fitting?,https://www.reddit.com/r/MachineLearning/comments/92smsu/d_how_does_the_human_brain_prevent_overfitting/,mistertipster,1532842494,"Our brains are massive neural networks with huge computational power, yet it doesn't always over fit.

Why do we learn from data so well and not just memorize it? Are there any lessons we can learn from this and apply it to our own work?",128,59
1512,2018-7-29,2018,7,29,15,92suxh,[P] Evolving Floorplans,https://www.reddit.com/r/MachineLearning/comments/92suxh/p_evolving_floorplans/,baylearn,1532845241,,41,169
1513,2018-7-29,2018,7,29,15,92sxza,[Talk] Yann LeCun - The Next Step Towards Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/92sxza/talk_yann_lecun_the_next_step_towards_artificial/,theainerd,1532846349,,0,1
1514,2018-7-29,2018,7,29,15,92t0nt,[N] 'The discourse is unhinged': how the media gets AI alarmingly wrong,https://www.reddit.com/r/MachineLearning/comments/92t0nt/n_the_discourse_is_unhinged_how_the_media_gets_ai/,blackzeppelinstripes,1532847362,,6,26
1515,2018-7-29,2018,7,29,15,92t0tb,Recommended books in Artificial intelligence?,https://www.reddit.com/r/MachineLearning/comments/92t0tb/recommended_books_in_artificial_intelligence/,CathyQian,1532847426,[removed],0,1
1516,2018-7-29,2018,7,29,16,92taa4,[P] Comparison of famous convolutional neural network models at a glance,https://www.reddit.com/r/MachineLearning/comments/92taa4/p_comparison_of_famous_convolutional_neural/,kobiso,1532851112,,0,1
1517,2018-7-29,2018,7,29,17,92tf4u,Give me resources plz! Thanks,https://www.reddit.com/r/MachineLearning/comments/92tf4u/give_me_resources_plz_thanks/,penguinpacific,1532853115,[removed],0,1
1518,2018-7-29,2018,7,29,17,92tiuy,[R] The Simple Essence of Automatic Differentiation,https://www.reddit.com/r/MachineLearning/comments/92tiuy/r_the_simple_essence_of_automatic_differentiation/,upulbandara,1532854737,"Paper: [https://arxiv.org/pdf/1804.00746.pdf](https://arxiv.org/pdf/1804.00746.pdf)

Video: [https://www.youtube.com/watch?v=ne99laPUxN4](https://www.youtube.com/watch?v=ne99laPUxN4)",5,20
1519,2018-7-29,2018,7,29,19,92tza4,[P] mozilla/FFTNet - PyTorch FFTNet vocoder implementation with relatively faster synthesis time (not yet real-time).,https://www.reddit.com/r/MachineLearning/comments/92tza4/p_mozillafftnet_pytorch_fftnet_vocoder/,erogol,1532861588,,1,1
1520,2018-7-29,2018,7,29,20,92u0ds,Malware Detection with Deep Neural Network using Process Behavior,https://www.reddit.com/r/MachineLearning/comments/92u0ds/malware_detection_with_deep_neural_network_using/,sectechguy1,1532862046,[removed],0,1
1521,2018-7-29,2018,7,29,21,92ugb7,[P] Neural network playground,https://www.reddit.com/r/MachineLearning/comments/92ugb7/p_neural_network_playground/,O1ivePizza,1532867536,,5,18
1522,2018-7-29,2018,7,29,21,92uk0z,where is nips anonymous review for accepted papers?,https://www.reddit.com/r/MachineLearning/comments/92uk0z/where_is_nips_anonymous_review_for_accepted_papers/,youkaichao,1532868763,[removed],1,1
1523,2018-7-29,2018,7,29,22,92uorv,[Discussion] An interesting new solution to the train dilemma problem.,https://www.reddit.com/r/MachineLearning/comments/92uorv/discussion_an_interesting_new_solution_to_the/,deutschHotel,1532870176,,4,8
1524,2018-7-29,2018,7,29,22,92ushn,[P] Image Outpainting,https://www.reddit.com/r/MachineLearning/comments/92ushn/p_image_outpainting/,Naughty_Nagaland,1532871258,,0,1
1525,2018-7-29,2018,7,29,22,92ut43,[P] Keras Implementation of Image Outpainting,https://www.reddit.com/r/MachineLearning/comments/92ut43/p_keras_implementation_of_image_outpainting/,Naughty_Nagaland,1532871446,,0,1
1526,2018-7-29,2018,7,29,22,92utkc,[P] Keras implementation of Image Outpainting,https://www.reddit.com/r/MachineLearning/comments/92utkc/p_keras_implementation_of_image_outpainting/,Naughty_Nagaland,1532871570,,0,1
1527,2018-7-29,2018,7,29,23,92v1lr,[R] When Recurrent Models Don't Need to be Recurrent,https://www.reddit.com/r/MachineLearning/comments/92v1lr/r_when_recurrent_models_dont_need_to_be_recurrent/,tuan3w,1532873798,,21,61
1528,2018-7-30,2018,7,30,0,92vfzt,How can Business Students make use of AI and ML?,https://www.reddit.com/r/MachineLearning/comments/92vfzt/how_can_business_students_make_use_of_ai_and_ml/,DaScheuer,1532877366,[removed],0,1
1529,2018-7-30,2018,7,30,0,92vlt1,[P] Clairvoyance - Modular Data Mining Tool with ML,https://www.reddit.com/r/MachineLearning/comments/92vlt1/p_clairvoyance_modular_data_mining_tool_with_ml/,paubric,1532878733,,0,1
1530,2018-7-30,2018,7,30,1,92vvdi,"Which laptop would be the bet bang for the buck if the long term goal is delving into deep learning, AI?",https://www.reddit.com/r/MachineLearning/comments/92vvdi/which_laptop_would_be_the_bet_bang_for_the_buck/,chanyeolxx,1532880971,[removed],0,1
1531,2018-7-30,2018,7,30,1,92vy8g,Interpretable machine learning: Peeking into the black box,https://www.reddit.com/r/MachineLearning/comments/92vy8g/interpretable_machine_learning_peeking_into_the/,Stelman,1532881634,,0,1
1532,2018-7-30,2018,7,30,3,92wvct,Hybrid Models : Deep Learning combined with Modeling,https://www.reddit.com/r/MachineLearning/comments/92wvct/hybrid_models_deep_learning_combined_with_modeling/,venuv,1532889070,[removed],0,1
1533,2018-7-30,2018,7,30,4,92x479,What is the difference between TARDIS and D-NTM? What are their advantages and shortcomings?,https://www.reddit.com/r/MachineLearning/comments/92x479/what_is_the_difference_between_tardis_and_dntm/,xenonlamb,1532891022,[removed],0,1
1534,2018-7-30,2018,7,30,4,92x4wo,Bandit Algorithms Book,https://www.reddit.com/r/MachineLearning/comments/92x4wo/bandit_algorithms_book/,banditalgorithms,1532891183,[removed],0,1
1535,2018-7-30,2018,7,30,4,92x6ll,[P] Keras Implementation of Image Outpaint,https://www.reddit.com/r/MachineLearning/comments/92x6ll/p_keras_implementation_of_image_outpaint/,Naughty_Nagaland,1532891539,,98,1351
1536,2018-7-30,2018,7,30,4,92xbjy,[N] Bandit Algorithms Book,https://www.reddit.com/r/MachineLearning/comments/92xbjy/n_bandit_algorithms_book/,banditalg,1532892640,"The bandit algorithms book is available for the public, and we would love your feedback.

Blog post: r/http://banditalgs.com

Direct link: r/http://downloads.tor-lattimore.com/banditbook/book.pdf",8,61
1537,2018-7-30,2018,7,30,4,92xbkw,Android Machine Learning,https://www.reddit.com/r/MachineLearning/comments/92xbkw/android_machine_learning/,deveid,1532892644,I am have created an android with few text-fields but I want to connect the response from the users to my ML model built using python on jupyter. The aim is to get a prediction thrown back to the user from the python jupyter. How do I connect the android app to the jupyter notebook.Is it possible?,0,1
1538,2018-7-30,2018,7,30,4,92xbpz,http://osim-rl.stanford.edu/news/2018/07/27/google-cloud-platform/,https://www.reddit.com/r/MachineLearning/comments/92xbpz/httposimrlstanfordedunews20180727googlecloudplatfo/,kidzik,1532892676,,0,1
1539,2018-7-30,2018,7,30,5,92xpnv,"[R] How do I get started with research, it feels too risky to commit.",https://www.reddit.com/r/MachineLearning/comments/92xpnv/r_how_do_i_get_started_with_research_it_feels_too/,breaking_ciphers,1532895719,"Hello r/MachineLearning,

I have been working in machine learning development for a long time now, but I felt it was time I went into the science, and actually did some research work, to grow my knowledge. As part of my research, one goal I have would is to publish something useful, I actually want to contribute something of worth.  


The trickiest part for me is deciding on what to do. I know I am really interested in memory and few shot learning. But any idea I have, a google search shows it has already been done. I am really interested in few shot learning, but every idea I have, is either already investigated, or doesn't contribute much to our collective knowledge (is incremental at best).

At this point, it seems if I go down one path to investigate, it might turn out to be a giant waste of time. So as a real big newbie, who has never contributed to research, what would you're advice be to me? how does one decide on a research hypothesis?

Thanks for helping me out.",16,18
1540,2018-7-30,2018,7,30,5,92xxu8,[R][1806.09594] Tracking Emerges by Colorizing Videos,https://www.reddit.com/r/MachineLearning/comments/92xxu8/r180609594_tracking_emerges_by_colorizing_videos/,PigsDogsAndSheep,1532897563,,3,20
1541,2018-7-30,2018,7,30,6,92y1oo,[D] Ian Goodfellow: I suspect that peer review *actually causes* rather than mitigates many of the troubling trends recently identified by @zacharylipton and Jacob Steinhardt,https://www.reddit.com/r/MachineLearning/comments/92y1oo/d_ian_goodfellow_i_suspect_that_peer_review/,thebackpropaganda,1532898409,,40,101
1542,2018-7-30,2018,7,30,7,92yisc,[P] Weather prediction and machine learning. I've started a new project and I'd like to do weather classification in outdoor photos.,https://www.reddit.com/r/MachineLearning/comments/92yisc/p_weather_prediction_and_machine_learning_ive/,cryptoz,1532902294,"Hi everyone,

Actually there are two general areas I'm interested to apply machine learning to weather forecasting. The first is classifying weather types in photos as in the title, the second is predictive work on numerical weather measurements.

1) I believe that if I had a large enough dataset of photos of the sky that had labels of the contents (like clouds, type of clouds, rain, buildings, trees, etc), that a classifier could then automatically apply weather labels to photos with some decent accuracy. I am creating such a labelled dataset with a new weather app I launched on Android that encourages users to share labelled/tagged photos of the sky. You can check out [All Clear on the Play Store if you're interested.](https://play.google.com/store/apps/details?id=com.allclearweather.android)

2) Smartphones can measure barometric pressure, temperature, humidity, light, magnetic fields, and other things that are affected by the weather. I'm interested in measuring these quantities on a per-phone basis, and after quality control, trying to predict future changes in pressure, temperature, etc, based on past knowledge. All Clear is also doing the work for this, you can see it in the app and I have [open-sourced](https://github.com/JacobSheehy/AllClearSensorLibrary) the sensor code in the app as well.

I have only ever done hello-world machine learning projects - I have not yet attempted to take on a project like either of these. Are these projects both feasible? Obviously nobody will know if I can actually predict the trends in the data, but is the idea valid? Is machine learning a good approach for these problems?

Thanks for your advice and feedback!",8,6
1543,2018-7-30,2018,7,30,7,92ym0r,Dataset for multi-view multi-task dataset,https://www.reddit.com/r/MachineLearning/comments/92ym0r/dataset_for_multiview_multitask_dataset/,saurabh_varsh,1532903039,[removed],0,1
1544,2018-7-30,2018,7,30,8,92ywpf,Using unsupervised learning to reduce clinical variation in hospitals,https://www.reddit.com/r/MachineLearning/comments/92ywpf/using_unsupervised_learning_to_reduce_clinical/,jtsymonds,1532905575,,0,1
1545,2018-7-30,2018,7,30,8,92z140,Im new to ML but I made a neural network from the ground up that can play and bet in Blackjack. Here are the results!,https://www.reddit.com/r/MachineLearning/comments/92z140/im_new_to_ml_but_i_made_a_neural_network_from_the/,pocketMAD,1532906651,,1,0
1546,2018-7-30,2018,7,30,9,92znxg,Freezing a model vs using it as a feature extractor,https://www.reddit.com/r/MachineLearning/comments/92znxg/freezing_a_model_vs_using_it_as_a_feature/,Ziadloo,1532912277,[removed],0,1
1547,2018-7-30,2018,7,30,10,92zu6w,How pencils are made.,https://www.reddit.com/r/MachineLearning/comments/92zu6w/how_pencils_are_made/,JasoneMartin,1532913778,,0,1
1548,2018-7-30,2018,7,30,10,92zx0n,[P] Evolutionary Computation Bestiary,https://www.reddit.com/r/MachineLearning/comments/92zx0n/p_evolutionary_computation_bestiary/,wei_jok,1532914472,,2,12
1549,2018-7-30,2018,7,30,11,93044y,What are the best classes for an undergraduate student to take in preparation for a graduate degree in ML?,https://www.reddit.com/r/MachineLearning/comments/93044y/what_are_the_best_classes_for_an_undergraduate/,the_great_magician,1532916228,[removed],0,1
1550,2018-7-30,2018,7,30,13,9317lu,[R] The Helmholtz Method: Using Perceptual Compression to Reduce Machine Learning Complexity,https://www.reddit.com/r/MachineLearning/comments/9317lu/r_the_helmholtz_method_using_perceptual/,xternalz,1532926652,,3,7
1551,2018-7-30,2018,7,30,14,93187t,Google Duplex  Machine to Human Conversation | Analytics Insight,https://www.reddit.com/r/MachineLearning/comments/93187t/google_duplex_machine_to_human_conversation/,analyticsinsight,1532926813,,0,1
1552,2018-7-30,2018,7,30,14,931jdk,LinkedIn Declare Messaging Will be the Next Platform for Networking,https://www.reddit.com/r/MachineLearning/comments/931jdk/linkedin_declare_messaging_will_be_the_next/,amberstevens311,1532930112,[removed],0,1
1553,2018-7-30,2018,7,30,15,931n5a,Custom Loss function Keras combining Cross entropy loss and mae loss,https://www.reddit.com/r/MachineLearning/comments/931n5a/custom_loss_function_keras_combining_cross/,asitmailbox3,1532931217,[removed],0,1
1554,2018-7-30,2018,7,30,15,931qag,"[P] Receptive field estimation for Keras, Tensorflow and Pytorch models with multiple feature maps support",https://www.reddit.com/r/MachineLearning/comments/931qag/p_receptive_field_estimation_for_keras_tensorflow/,kmkolasinski,1532932192,"Link to the project: [receptivefield](https://github.com/fornaxai/receptivefield)

We have added API for Pytorch as well as a support for multiple feature maps. The latter can be useful when dealing with e.g. Feature Pyramid Networks etc. 
Hope you find this useful.


",1,3
1555,2018-7-30,2018,7,30,15,931r2a,How A.I. Can Be an Asset to Your Business?,https://www.reddit.com/r/MachineLearning/comments/931r2a/how_ai_can_be_an_asset_to_your_business/,amberstevens311,1532932423,[removed],0,1
1556,2018-7-30,2018,7,30,16,931wkl,[P] Implementation of NIvsCG (Distinguishing Between Natural and Computer-Generated Images Using CNNs) in Keras,https://www.reddit.com/r/MachineLearning/comments/931wkl/p_implementation_of_nivscg_distinguishing_between/,Deruhat,1532934229,[Source: NIvsCG paper \(https:\/\/weizequan.github.io\/NIvsCG\_files\/NIvsCG.pdf\)](https://i.redd.it/jh353m3ja1d11.png),4,11
1557,2018-7-30,2018,7,30,16,9324r9,Landing A Rocket With Simple Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9324r9/landing_a_rocket_with_simple_reinforcement/,coinmonks,1532936819,,0,1
1558,2018-7-30,2018,7,30,17,932bn8,Object Detection: Which is a good practice among them ? Resize image &amp; annotate OR annotate original images and later resize.,https://www.reddit.com/r/MachineLearning/comments/932bn8/object_detection_which_is_a_good_practice_among/,waterRocket8236,1532939178,[removed],0,1
1559,2018-7-30,2018,7,30,17,932bwi,Help with project related to information extraction (automating scraping/google search) using NLP,https://www.reddit.com/r/MachineLearning/comments/932bwi/help_with_project_related_to_information/,inspector_shinde,1532939259,[removed],0,1
1560,2018-7-30,2018,7,30,17,932exc,Oxy fuel Cutting Process Explained,https://www.reddit.com/r/MachineLearning/comments/932exc/oxy_fuel_cutting_process_explained/,Messer-123,1532940366,,0,1
1561,2018-7-30,2018,7,30,18,932jz9,Kaggle competition Data Science Bowl 2017 data required,https://www.reddit.com/r/MachineLearning/comments/932jz9/kaggle_competition_data_science_bowl_2017_data/,omayrakhtar,1532942016,[removed],0,1
1562,2018-7-30,2018,7,30,18,932mgr,The Future of Enterprise IT with Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/932mgr/the_future_of_enterprise_it_with_artificial/,amberstevens311,1532942846,[removed],0,1
1563,2018-7-30,2018,7,30,18,932r7e,[R] [1807.10299] Variational Option Discovery Algorithms,https://www.reddit.com/r/MachineLearning/comments/932r7e/r_180710299_variational_option_discovery/,evc123,1532944430,,2,12
1564,2018-7-30,2018,7,30,18,932rjv,The state of the art domain adaptation method,https://www.reddit.com/r/MachineLearning/comments/932rjv/the_state_of_the_art_domain_adaptation_method/,jindongwang,1532944549,,0,1
1565,2018-7-30,2018,7,30,20,933802,[R] Building Models that Learn to Discover Structure and Relations,https://www.reddit.com/r/MachineLearning/comments/933802/r_building_models_that_learn_to_discover/,triplefloat,1532949643,,0,1
1566,2018-7-30,2018,7,30,20,933aju,Tensorflow implementation of SENet which is compatible on the TensorFlow-Slim image classification model library.,https://www.reddit.com/r/MachineLearning/comments/933aju/tensorflow_implementation_of_senet_which_is/,kobiso,1532950383,,0,1
1567,2018-7-30,2018,7,30,20,933ash,[R] Building Models that Learn to Discover Structure and Relations,https://www.reddit.com/r/MachineLearning/comments/933ash/r_building_models_that_learn_to_discover/,triplefloat,1532950448,,0,1
1568,2018-7-30,2018,7,30,20,933eyd,Cusom,https://www.reddit.com/r/MachineLearning/comments/933eyd/cusom/,speeddefiesgravity,1532951614,[removed],0,1
1569,2018-7-30,2018,7,30,20,933gae,"AI Development, dialogue corpus || QnA",https://www.reddit.com/r/MachineLearning/comments/933gae/ai_development_dialogue_corpus_qna/,SmartNewspaper,1532951964,[removed],0,1
1570,2018-7-30,2018,7,30,21,933hn3,Product Recommendation/Ranker,https://www.reddit.com/r/MachineLearning/comments/933hn3/product_recommendationranker/,speeddefiesgravity,1532952296,[removed],0,1
1571,2018-7-30,2018,7,30,21,933iib,torchsummaryX: Improved visualization tool of torchsummary,https://www.reddit.com/r/MachineLearning/comments/933iib/torchsummaryx_improved_visualization_tool_of/,nmhkahn,1532952530,,0,1
1572,2018-7-30,2018,7,30,21,933k2l,[P] torchsummaryX: Improved visualization tool of torchsummary,https://www.reddit.com/r/MachineLearning/comments/933k2l/p_torchsummaryx_improved_visualization_tool_of/,nmhkahn,1532952933,,0,1
1573,2018-7-30,2018,7,30,21,933kri,What is a general equation for STDP learning in an SNN?,https://www.reddit.com/r/MachineLearning/comments/933kri/what_is_a_general_equation_for_stdp_learning_in/,KilllllleeerKeemcant,1532953104,[removed],0,1
1574,2018-7-30,2018,7,30,21,933pax,Advantages of IoT in Healthcare,https://www.reddit.com/r/MachineLearning/comments/933pax/advantages_of_iot_in_healthcare/,seoaleait,1532954276,,0,1
1575,2018-7-30,2018,7,30,21,933u12,[R] Semi-convolutional Operators for Instance Segmentation,https://www.reddit.com/r/MachineLearning/comments/933u12/r_semiconvolutional_operators_for_instance/,m_ke,1532955437,,4,11
1576,2018-7-30,2018,7,30,22,933zx7,[P] torchsummaryX - Improved visualization tool of torchsummary,https://www.reddit.com/r/MachineLearning/comments/933zx7/p_torchsummaryx_improved_visualization_tool_of/,nmhkahn,1532956809,,0,1
1577,2018-7-30,2018,7,30,22,93400s,[R] Building a Diabetic Retinopathy Prediction Application using Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/93400s/r_building_a_diabetic_retinopathy_prediction/,dearpetra,1532956832,,0,1
1578,2018-7-30,2018,7,30,22,9340km,Water Jet Cutting - Precision Machines Canada,https://www.reddit.com/r/MachineLearning/comments/9340km/water_jet_cutting_precision_machines_canada/,rickbanklaw2,1532956969,,0,1
1579,2018-7-30,2018,7,30,22,9342vx,Need some guidance.,https://www.reddit.com/r/MachineLearning/comments/9342vx/need_some_guidance/,Byomakesh_Maharana,1532957506,[removed],0,1
1580,2018-7-30,2018,7,30,22,9344yq,CNC Machining - Machining &amp; Fabrication,https://www.reddit.com/r/MachineLearning/comments/9344yq/cnc_machining_machining_fabrication/,rickbanklaw2,1532957981,,0,1
1581,2018-7-30,2018,7,30,22,934aat,API Threading Services - Machining &amp; Fabrication,https://www.reddit.com/r/MachineLearning/comments/934aat/api_threading_services_machining_fabrication/,rickbanklaw2,1532959180,,0,1
1582,2018-7-30,2018,7,30,23,934mji,"[P] Implementation of population-based training from DeepMind, except applied to simulated annealing instead of neural networks",https://www.reddit.com/r/MachineLearning/comments/934mji/p_implementation_of_populationbased_training_from/,lmericle,1532961687,,1,1
1583,2018-7-30,2018,7,30,23,934oqx,[P] Pytorch Project Template with 4 Models in various fields included in.,https://www.reddit.com/r/MachineLearning/comments/934oqx/p_pytorch_project_template_with_4_models_in/,moemen95,1532962125,,0,2
1584,2018-7-30,2018,7,30,23,934p7x,"[P] How to use CSRF, KCF, or MOSSE for object tracking + 5 more object trackers",https://www.reddit.com/r/MachineLearning/comments/934p7x/p_how_to_use_csrf_kcf_or_mosse_for_object/,Loggerny,1532962225,,0,13
1585,2018-7-30,2018,7,30,23,934qyv,Contact NIPS AC [D],https://www.reddit.com/r/MachineLearning/comments/934qyv/contact_nips_ac_d/,locochocolato,1532962591,"Heya,

My team and I wanted to contact the AC for the neuroscience track where we submitted our paper but we can't find any links via the main site to do this. Has anyone here contacted the AC before in regards to rebutting manuscript reviews that can shed more light on the process? I'm assuming there's a system in place that anonymizes you as to not bias their decision right?

Cheers!",6,0
1586,2018-7-31,2018,7,31,0,934tid,Do You Know The Mathematics For Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/934tid/do_you_know_the_mathematics_for_machine_learning/,asifrazzaq1988,1532963075,,0,1
1587,2018-7-31,2018,7,31,0,9350v0,Can someone map out the tree of mathematics required to become useful in applying machine learning?,https://www.reddit.com/r/MachineLearning/comments/9350v0/can_someone_map_out_the_tree_of_mathematics/,akromyk,1532964510,[removed],0,1
1588,2018-7-31,2018,7,31,0,9352hd,[P] Survey for a school project about machine and robot ethics.,https://www.reddit.com/r/MachineLearning/comments/9352hd/p_survey_for_a_school_project_about_machine_and/,WillyTrek19,1532964848,"I'm Guillem, an 11th-grade student.
I'm making a school project and I need your help. I would greatly appreciate if you completed the following survey. Please share it between your contacts and relatives. Thank you!

[Link] (https://goo.gl/forms/2jmGy5IIltu88qaa2)",14,0
1589,2018-7-31,2018,7,31,0,9352ue,7 Javascript EEG Mind Reading Libraries for 2018,https://www.reddit.com/r/MachineLearning/comments/9352ue/7_javascript_eeg_mind_reading_libraries_for_2018/,JSislife,1532964911,,0,1
1590,2018-7-31,2018,7,31,0,9354fq,[D] Looking for open source RL projects to contribute,https://www.reddit.com/r/MachineLearning/comments/9354fq/d_looking_for_open_source_rl_projects_to/,AmericanMusician,1532965223,"Hi all,

Within the past 6 months I have become completely enamored with the reinforcement learning problem domain, and have been spending a lot of time catching up on the literature and doing some personal projects as well. But now, I'm at the point where I'd like to start contributing in a more meaningful way to the community. Does anyone have idea of good open source projects related to RL that are looking for contributors?

Thanks for any suggestions!",6,17
1591,2018-7-31,2018,7,31,1,935paz,"decaNLP, GluonNLP, al+ stack, Pythia, Data for Good, Differentiable Image Parameterizations,",https://www.reddit.com/r/MachineLearning/comments/935paz/decanlp_gluonnlp_al_stack_pythia_data_for_good/,omarsar,1532969156,,0,1
1592,2018-7-31,2018,7,31,2,9362f0,[N] Learning Dexterity,https://www.reddit.com/r/MachineLearning/comments/9362f0/n_learning_dexterity/,thebackpropaganda,1532971579,,35,166
1593,2018-7-31,2018,7,31,3,936e44,Automatic Detection of Node-Replication Attack in Vehicular Ad-hoc Networks,https://www.reddit.com/r/MachineLearning/comments/936e44/automatic_detection_of_nodereplication_attack_in/,gstenger7,1532973784,,1,0
1594,2018-7-31,2018,7,31,3,936kl6,[D] Declarative syntax for RNNs,https://www.reddit.com/r/MachineLearning/comments/936kl6/d_declarative_syntax_for_rnns/,tavianator,1532974955,"I work at Microsoft Research Montreal and I recently made a prototype.  I'm wondering if there's community interest in the idea that would justify turning it into a full-fledged project.  The idea is to let people write the recurrence relations that define their model directly, instead of translating them into imperative-style loops first.  As an extremely simple example, one can define the Fibonacci sequence like

    F[0] = 0;
    F[1] = 1;
    F[i] = F[i-2] + F[i-1];

and then `runtime.compute(""F[8]"") == 21` etc.  Here's an LSTM implemented manually:

    i[t] = sigmoid(Ui@h[t-1] + Wi@x[t] + bi);
    o[t] = sigmoid(Uo@h[t-1] + Wo@x[t] + bo);
    f[t] = sigmoid(Uf@h[t-1] + Wf@x[t] + bf);
    c[t] = f[t]*c[t-1] + i[t]*tanh(Uc@h[t-1] + Wc@x[t] + bc);
    h[t] = o[t]*tanh(c[t]);

which you can evaluate with something like

    with runtime.given({""h[-1]"": init_hidden, ""c[-1]"": init_cell, ""x"": input}):
        h_last = Symbol(""h"", [input.size(0) - 1])
        value = runtime.compute(h_last)

The idea is to make it easier to experiment with different recurrent architectures by making the code more closely match the actual formulas involved.  More exotic things like grid LSTMs would just be minor variations of the code above.  There are some other potential niceties (IMO):

    B[i,j,k] = A[j,i,k]; # Easier to grok than permute(1, 0, 2)?

    C[i,k] = A[i,j]*B[j,k]; # einsum

Thoughts?  Is this something you would be interested in?  The prototype supports PyTorch, but TensorFlow support should be possible too.",24,42
1595,2018-7-31,2018,7,31,3,936scj,Microsoft Multi Agent Reinforcement Learning in Minecraft Competition. Qualifying Rounds end Oct 7.,https://www.reddit.com/r/MachineLearning/comments/936scj/microsoft_multi_agent_reinforcement_learning_in/,zeroxok,1532976410,,0,1
1596,2018-7-31,2018,7,31,3,936sx5,Minecraft Multi Agent Reinforcement Learning in Minecraft (MARLO) competition. Qualifying rounds end October 7th.,https://www.reddit.com/r/MachineLearning/comments/936sx5/minecraft_multi_agent_reinforcement_learning_in/,zeroxok,1532976509,,0,1
1597,2018-7-31,2018,7,31,4,936y7c,How should i go about learning g code,https://www.reddit.com/r/MachineLearning/comments/936y7c/how_should_i_go_about_learning_g_code/,wiza67,1532977498,I need tips or many a video I can watch to teach me g coding I need to learn it pretty fast so anything will help,0,1
1598,2018-7-31,2018,7,31,5,937nxh,[R] Building Models that Learn to Discover Structure and Relations,https://www.reddit.com/r/MachineLearning/comments/937nxh/r_building_models_that_learn_to_discover/,triplefloat,1532982257,,0,1
1599,2018-7-31,2018,7,31,5,937re7,Non-pretrained CNN-classification on CUB-200,https://www.reddit.com/r/MachineLearning/comments/937re7/nonpretrained_cnnclassification_on_cub200/,permanent_learner,1532982913,"Hey,

I want to use a non-pretrained CNN for fine-grained classification on the CUB-200 bird dataset (2011 version). Also, I want to solely use CNNs without combining them with another methods.

I tried the ResNet-18 und - 34 in PyTorch with various hyperparameters, but receive utterly low accuracies (&lt;30% for 150 classes subset).

So I need your help! Can you recommend architectures, respective hyperparameter combis, github-repos or blog posts? I would be thankful for anything!",0,1
1600,2018-7-31,2018,7,31,6,9383nw,Bfloat16 training on GPUs,https://www.reddit.com/r/MachineLearning/comments/9383nw/bfloat16_training_on_gpus/,ranjithks,1532985257,[removed],0,1
1601,2018-7-31,2018,7,31,7,938rgv,[R] [1807.10590] Harmonic Adversarial Attack Method,https://www.reddit.com/r/MachineLearning/comments/938rgv/r_180710590_harmonic_adversarial_attack_method/,zhamisen,1532989904,,5,17
1602,2018-7-31,2018,7,31,7,938w5g,[D] How SK Telecom Benchmarks Deep Learning Frameworks,https://www.reddit.com/r/MachineLearning/comments/938w5g/d_how_sk_telecom_benchmarks_deep_learning/,azai91,1532990876,,0,1
1603,2018-7-31,2018,7,31,7,938wvr,"Code Release: Extensible Machine Learning Algorithm to Find Classify, and Read Labels (or any object)",https://www.reddit.com/r/MachineLearning/comments/938wvr/code_release_extensible_machine_learning/,FrostySatisfaction8,1532991027,,0,5
1604,2018-7-31,2018,7,31,7,938z90,[N] How SK Telecom Benchmarks Deep Learning Frameworks,https://www.reddit.com/r/MachineLearning/comments/938z90/n_how_sk_telecom_benchmarks_deep_learning/,azai91,1532991520,,0,1
1605,2018-7-31,2018,7,31,8,939f6h,[1806.08771] What Does This Notation Mean Anyway? BNF-Style Notation as it is Actually Used (2018),https://www.reddit.com/r/MachineLearning/comments/939f6h/180608771_what_does_this_notation_mean_anyway/,AforAnonymous,1532994964,,1,1
1606,2018-7-31,2018,7,31,8,939fpd,[R] [1806.08771] What Does This Notation Mean Anyway? BNF-Style Notation as it is Actually Used (2018),https://www.reddit.com/r/MachineLearning/comments/939fpd/r_180608771_what_does_this_notation_mean_anyway/,AforAnonymous,1532995083,,2,0
1607,2018-7-31,2018,7,31,9,939vgp,[P] Extending the Mapillary Vistas Dataset for Perfecting Street Scene Segmentation Models,https://www.reddit.com/r/MachineLearning/comments/939vgp/p_extending_the_mapillary_vistas_dataset_for/,m_ke,1532998581,,0,1
1608,2018-7-31,2018,7,31,10,939y7d,[R] Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes,https://www.reddit.com/r/MachineLearning/comments/939y7d/r_highly_scalable_deep_learning_training_system/,edge_of_the_eclair,1532999191,,10,43
1609,2018-7-31,2018,7,31,10,93a3t6,[P] torchsummaryX - Improved visualization tool of torchsummary,https://www.reddit.com/r/MachineLearning/comments/93a3t6/p_torchsummaryx_improved_visualization_tool_of/,nmhkahn,1533000495,,0,1
1610,2018-7-31,2018,7,31,10,93a4q8,looking for a 5G machine learning problem,https://www.reddit.com/r/MachineLearning/comments/93a4q8/looking_for_a_5g_machine_learning_problem/,eye_an,1533000714,[removed],0,1
1611,2018-7-31,2018,7,31,10,93a7z0,[R] TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing,https://www.reddit.com/r/MachineLearning/comments/93a7z0/r_tensorfuzz_debugging_neural_networks_with/,mttd,1533001460,,1,24
1612,2018-7-31,2018,7,31,11,93af7u,[D] An insiders guide to author responses,https://www.reddit.com/r/MachineLearning/comments/93af7u/d_an_insiders_guide_to_author_responses/,hello__world____,1533003128,,1,15
1613,2018-7-31,2018,7,31,13,93b89c,Where to begin with AI?,https://www.reddit.com/r/MachineLearning/comments/93b89c/where_to_begin_with_ai/,wiegehtesdir,1533010226,"Hello everyone! 

Im a currently studying computer science and I have always been interested in machine learning. Im in honors college and I have to begin looking at thesis topics to research soon and I would really like to do something with AI but Im not sure what, I guess before I can answer that question I have to really know what AI is. I was wondering if I could get any advice on where to begin with AI? Are there any books that you would recommend for someone looking to learn AI? thank you for your help! ",0,1
1614,2018-7-31,2018,7,31,14,93bvf6,"Study material for Data Exploration, Data Pre-Processing and Feature Engineering.",https://www.reddit.com/r/MachineLearning/comments/93bvf6/study_material_for_data_exploration_data/,deepakchawla35,1533016639,[removed],0,1
1615,2018-7-31,2018,7,31,15,93c15g,How to detect language of hand written text in an image,https://www.reddit.com/r/MachineLearning/comments/93c15g/how_to_detect_language_of_hand_written_text_in_an/,arush1836,1533018334,[removed],0,1
1616,2018-7-31,2018,7,31,16,93ca3s,"Help with breaking down study areas for reinforcement learning in ""Hands on ML"" book",https://www.reddit.com/r/MachineLearning/comments/93ca3s/help_with_breaking_down_study_areas_for/,SpiderSaliva,1533021101,[removed],0,1
1617,2018-7-31,2018,7,31,16,93cfqk,Real Life Machine Learning!!!,https://www.reddit.com/r/MachineLearning/comments/93cfqk/real_life_machine_learning/,Mmanisha21,1533022865,[removed],0,1
1618,2018-7-31,2018,7,31,17,93cl3w,Graph CNN for pytorch for pubmed / cora / citeseer dataset,https://www.reddit.com/r/MachineLearning/comments/93cl3w/graph_cnn_for_pytorch_for_pubmed_cora_citeseer/,meliketoy,1533024671,,0,1
1619,2018-7-31,2018,7,31,17,93ct3p,Scalable Deep Symbolic Reinforcement Learning with Imandra: Part I,https://www.reddit.com/r/MachineLearning/comments/93ct3p/scalable_deep_symbolic_reinforcement_learning/,Bronsa_,1533027434,,0,1
1620,2018-7-31,2018,7,31,18,93cwoq,[R] Scalable Deep Symbolic Reinforcement Learning with Imandra: Part I,https://www.reddit.com/r/MachineLearning/comments/93cwoq/r_scalable_deep_symbolic_reinforcement_learning/,Bronsa_,1533028608,,0,3
1621,2018-7-31,2018,7,31,18,93cxnx,Rise Of The Machines: The Future Of Data Science And Machine Learning,https://www.reddit.com/r/MachineLearning/comments/93cxnx/rise_of_the_machines_the_future_of_data_science/,ARayOutOfBounds,1533028918,,0,1
1622,2018-7-31,2018,7,31,18,93d4lj,Regarding Downsizing Densenet.,https://www.reddit.com/r/MachineLearning/comments/93d4lj/regarding_downsizing_densenet/,shinx32,1533030960,[removed],0,1
1623,2018-7-31,2018,7,31,19,93db59,"Disappointment on ""Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks""",https://www.reddit.com/r/MachineLearning/comments/93db59/disappointment_on_distilling_reversemode/,globjohn,1533032912,[removed],0,1
1624,2018-7-31,2018,7,31,19,93db5z,Automatic sunflower seed oil refinery machine,https://www.reddit.com/r/MachineLearning/comments/93db5z/automatic_sunflower_seed_oil_refinery_machine/,oil-machine,1533032918,,0,1
1625,2018-7-31,2018,7,31,19,93ddr8,Best Machine Learning Tutorial Ever,https://www.reddit.com/r/MachineLearning/comments/93ddr8/best_machine_learning_tutorial_ever/,pooja307,1533033704,,0,1
1626,2018-7-31,2018,7,31,20,93difa,(VIDEO) NTR LAB Rocks IT In Siberia,https://www.reddit.com/r/MachineLearning/comments/93difa/video_ntr_lab_rocks_it_in_siberia/,Batareika_1,1533035055,,0,1
1627,2018-7-31,2018,7,31,20,93djjv,[D] What are according to you one of the most interesting areas of machine learning being explored right now?,https://www.reddit.com/r/MachineLearning/comments/93djjv/d_what_are_according_to_you_one_of_the_most/,mrconter1,1533035363,,131,188
1628,2018-7-31,2018,7,31,20,93dkn2,"[D] My opinions on ""Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks""",https://www.reddit.com/r/MachineLearning/comments/93dkn2/d_my_opinions_on_distilling_reversemode_automatic/,globjohn,1533035669,"Hi,

Disclaimer: this is meant to be an constructive discussion, not a rant.

I've recently come across the paper titled ""Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks"" (there's a nifty summary from [nurture.ai](https://nurture.ai) [here](https://nurture.ai/papers/drmad-distilling-reverse-mode-automatic-differentiation-for-optimizing-hyperparameters-of-deep-neural-networks/tldr), from [this](https://www.reddit.com/r/MachineLearning/comments/903ta0/d_what_is_one_ai_paper_which_you_feel_did_not_get/) thread as suggested by u/Nikota u/DTRademaker.

Essentially its about finding hyperparameters by computing the gradient... disappointingly, the authors only tested their DrMAD algorithm on *a subset* of MNIST (!). Maybe its just me, but the authors stated in the abstract that they want a model that can automatically tune **thousands** of hyperparameters. I think this implies that they want to create something that scales **big**. However they seem content in just improving their model compared to the current SOTA (RMAD), and also acknowledged their algorithm might not work on larger datasets (see conclusion).

Any thoughts on this? And does anyone know about any more updates on this paper/ DrMAD technique?

To me this just seems like putting out big statements but not delivering, which is really disappointing to see in published AI papers.",4,11
1629,2018-7-31,2018,7,31,20,93dljl,Is the evolutionary algorithm more powerful than machine learning?,https://www.reddit.com/r/MachineLearning/comments/93dljl/is_the_evolutionary_algorithm_more_powerful_than/,Gloria_Joyce,1533035924,,0,1
1630,2018-7-31,2018,7,31,20,93dlo8,[D] A case study of text annotation for medical imaging,https://www.reddit.com/r/MachineLearning/comments/93dlo8/d_a_case_study_of_text_annotation_for_medical/,TalkingJellyFish,1533035959,,4,22
1631,2018-7-31,2018,7,31,20,93dm73,[D] #APaperADay Reading Challenge Week 2. What are your thoughts and takeaways for the papers for this week.,https://www.reddit.com/r/MachineLearning/comments/93dm73/d_apaperaday_reading_challenge_week_2_what_are/,leenz2,1533036113," On the 23rd of July, [Nurture.AI](https://nurture.ai/) initiated the [\#APaperADay Reading Challenge](https://apaperaday.nurture.ai/), where we will read an AI paper everyday.

Here is our pick of 6 papers for the second week:

1.[***DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks](https://nurture.ai/papers/drmad-distilling-reverse-mode-automatic-differentiation-for-optimizing-hyperparameters-of-deep-neural-networks/info)(***[***2-min summary***](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=07d813c32e&amp;e=371fd58f23)***)***  
**Why read:** Hyperparameter tuning is one of the trickiest tasks in optimizing neural networks. This paper introduces an interesting algorithm that treats hyperparameters like the regular parameters (i.e weights and bias) by taking their gradients. Authors claim that their novel algorithm is the first research attempt to make it practical to automatically tune thousands of hyperparameters of deep neural networks.  

2.[***Self-Attention with Relative Position Representations***](https://nurture.ai/papers/self-attention-with-relative-position-representations/info) ***(***[***2-min summary***](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=7e57e68b59&amp;e=371fd58f23)***)***  
**Why read:** A method to enhance an under-discussedmethod to improve the Transformer, one of the most popular models in NLP tasks. Although the underlying concept is relatively simple (incorporate relative positioning in the attention mechanism), it has significantly improved the translation quality of two machine translation tasks.  

3. [***Compositional GAN: Learning Conditional Image Composition***](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=50510432b2&amp;e=371fd58f23)
**Why read:**How do you know if the fancy coffee table from the store will go along with your homes sofa? This paper talks about using GANs to automatically combine objects from separate images into one. Its not as easy as you think, because we need to capture complex interactions between the objects.  
**Prerequisites:** [**Marginal distribution**](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=83c9f37b12&amp;e=371fd58f23)**,** [**Conditional Generative Adversarial Nets**](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=dd0649c5e6&amp;e=371fd58f23)**,**[**View Synthesis by Appearance Flow**](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=10a54bfe36&amp;e=371fd58f23)  

4. [***Translating Neuralese***](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=f0323ba7fe&amp;e=371fd58f23)  
**Why read:** Authors introduce the notion of ""neuralese"", i.e message vectors transmitted by an agent, and attempts to translate it to human language. Since there is no parallel translations between neuralese and human language, authors leverage on the insight that agent messages and human language strings mean the same thing *if they induce the same belief about the world in a listener*.  
**Prerequisites**: [A brief introduction to reinforcement learning](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=2446273e4e&amp;e=371fd58f23), [video](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=6a8ce772ff&amp;e=371fd58f23) presentation by authors.  


5. [***Relational recurrent neural networks***](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=da386abfec&amp;e=371fd58f23)
**Why read:**Paper by DeepMind on a novel architecture that allows memories to interact. **The background:** Current models in neural network research are proficientin storing and retrieving information. However, the information stored (memories) do not interact well, as demonstrated in its poor performance in[relational reasoning](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=51a7ea6c7e&amp;e=371fd58f23) tasks.   


6. [***Speeding up the Hyperparameter Optimization of Deep Convolutional Neural Networks***](https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&amp;id=ed26748a25&amp;e=371fd58f23) 
**Why read:** An approach to reduce the time needed for hyperparameter optimization of deep CNNs. **Interesting key idea**: Hyperparameter values for the same images in different resolutions are similar to each other. Therefore, we can find appropriate hyperparameters on low resolution images and then fine-tune them for the same images with high resolution. 

More details can be found [here](https://apaperaday.nurture.ai).

- [Link to original post](https://www.reddit.com/r/MachineLearning/comments/903ta0/d_what_is_one_ai_paper_which_you_feel_did_not_get/)
- [Week 1 papers](https://www.reddit.com/r/MachineLearning/comments/91fyni/d_apaperaday_reading_challenge_week_1_what_are/)
- Week 3 papers - unreleased
- Week 4 papers - unreleased",6,40
1632,2018-7-31,2018,7,31,20,93dodh,Golang Big Data | Golang Machine Learning,https://www.reddit.com/r/MachineLearning/comments/93dodh/golang_big_data_golang_machine_learning/,PriyaNemade,1533036717,,0,1
1633,2018-7-31,2018,7,31,20,93dr79,Where to go for questions?,https://www.reddit.com/r/MachineLearning/comments/93dr79/where_to_go_for_questions/,NerdHelp,1533037499,[removed],0,1
1634,2018-7-31,2018,7,31,21,93dux0,[R] TDLS: Program Language Translation Using a Grammar-Driven Tree-to-Tree Model [https://arxiv.org/abs/1807.01784],https://www.reddit.com/r/MachineLearning/comments/93dux0/r_tdls_program_language_translation_using_a/,machinetrainer,1533038473,,0,6
1635,2018-7-31,2018,7,31,21,93dzif,"A Tutorial on DecisionTrees, a MachineLearning algorithm for classification and regression with simple example and working python code.",https://www.reddit.com/r/MachineLearning/comments/93dzif/a_tutorial_on_decisiontrees_a_machinelearning/,akratisri,1533039625,,0,1
1636,2018-7-31,2018,7,31,21,93e0w2,How to detect language of handwritten text in an image,https://www.reddit.com/r/MachineLearning/comments/93e0w2/how_to_detect_language_of_handwritten_text_in_an/,arush1836,1533039965,[removed],0,1
1637,2018-7-31,2018,7,31,21,93e2mg,Malware Detection with Deep Neural Network using Process Behavior,https://www.reddit.com/r/MachineLearning/comments/93e2mg/malware_detection_with_deep_neural_network_using/,sectechguy1,1533040395,[removed],0,1
1638,2018-7-31,2018,7,31,22,93een0,"[P] PyTorch-Project-Template: A scalable template for PyTorch projects, with examples in Image Segmentation, Object classification, GANs and Reinforcement Learning.",https://www.reddit.com/r/MachineLearning/comments/93een0/p_pytorchprojecttemplate_a_scalable_template_for/,moemen95,1533043166,,3,4
1639,2018-7-31,2018,7,31,22,93eji0,My First Kaggle Competition Learnings - please share your thoughts,https://www.reddit.com/r/MachineLearning/comments/93eji0/my_first_kaggle_competition_learnings_please/,Vidzi25,1533044246,,0,1
1640,2018-7-31,2018,7,31,22,93enlr,GPU damage on laptop,https://www.reddit.com/r/MachineLearning/comments/93enlr/gpu_damage_on_laptop/,daredevildas,1533045155,[removed],0,1
1641,2018-7-31,2018,7,31,23,93eubd,Downloading forms data from the IAM handwriting database.,https://www.reddit.com/r/MachineLearning/comments/93eubd/downloading_forms_data_from_the_iam_handwriting/,puppetmaster99,1533046573,[removed],0,1
1642,2018-7-31,2018,7,31,23,93f3bd,[D] Generating of machine learning dataset,https://www.reddit.com/r/MachineLearning/comments/93f3bd/d_generating_of_machine_learning_dataset/,07Zulrah,1533048430,"Hi, I want to generate a machine learning dataset and train a machine learning model as a POC for a customer. are there any examples how to generate it preferably using python?",1,0
