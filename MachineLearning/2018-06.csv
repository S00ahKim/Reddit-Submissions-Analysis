,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-6-1,2018,6,1,9,8nnn1i,Essential RSS Feeds for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8nnn1i/essential_rss_feeds_for_machine_learning/,-TURBOMAN-,1527813725,[removed],0,1
1,2018-6-1,2018,6,1,11,8noc6q,Hummus Grinding Machine With Factory Price For Sale,https://www.reddit.com/r/MachineLearning/comments/8noc6q/hummus_grinding_machine_with_factory_price_for/,Machineprices,1527820195,,1,1
2,2018-6-1,2018,6,1,11,8nodmj,"My hn ming ti dp chn F700 hn nhanh, gi r",https://www.reddit.com/r/MachineLearning/comments/8nodmj/my_hn_ming_ti_dp_chn_f700_hn_nhanh_gi_r/,HangNguyen1111,1527820561,,1,1
3,2018-6-1,2018,6,1,11,8nodn9,"[P] Need help with GAN, it is learning identity",https://www.reddit.com/r/MachineLearning/comments/8nodn9/p_need_help_with_gan_it_is_learning_identity/,yhindy,1527820566,"I'm trying to train a cycle\-consistent GAN to generate rotation of perspective for images, but it is only learning the identity. Does anyone have any ideas on how to modify the loss function or tune hyperparameters to avoid this? It seems like it is getting stuck in a local minimum. Thanks!",10,16
4,2018-6-1,2018,6,1,11,8noekb,New &amp; huge dataset,https://www.reddit.com/r/MachineLearning/comments/8noekb/new_huge_dataset/,itamblyn,1527820804,[removed],0,1
5,2018-6-1,2018,6,1,12,8not6u,[D] Rapid Prototyping of Interactive Data Science Workflows in Jupyter,https://www.reddit.com/r/MachineLearning/comments/8not6u/d_rapid_prototyping_of_interactive_data_science/,entoros,1527824552,,4,87
6,2018-6-1,2018,6,1,12,8novuf,#7motors,https://www.reddit.com/r/MachineLearning/comments/8novuf/7motors/,7motors,1527825347,,0,1
7,2018-6-1,2018,6,1,13,8np4rw,Attacks against machine learning  an overview,https://www.reddit.com/r/MachineLearning/comments/8np4rw/attacks_against_machine_learning_an_overview/,karlamar89,1527827717,,0,1
8,2018-6-1,2018,6,1,15,8npnnr,Machine Learning Course | Artificial Intelligence Course,https://www.reddit.com/r/MachineLearning/comments/8npnnr/machine_learning_course_artificial_intelligence/,nandiniravichandran,1527833370,,0,1
9,2018-6-1,2018,6,1,15,8nppk4,"Machine-Learning-Course,Artificial-Intelligence-Course",https://www.reddit.com/r/MachineLearning/comments/8nppk4/machinelearningcourseartificialintelligencecourse/,nandiniravichandran,1527833993,[removed],0,1
10,2018-6-1,2018,6,1,15,8npq8y,[N] Leaked Emails Show Google Expected Lucrative Military Drone AI Work to Grow Exponentially,https://www.reddit.com/r/MachineLearning/comments/8npq8y/n_leaked_emails_show_google_expected_lucrative/,baylearn,1527834225,,50,135
11,2018-6-1,2018,6,1,15,8nps3m,"Machine-Learning-Course,Artificial-Intelligence-Course",https://www.reddit.com/r/MachineLearning/comments/8nps3m/machinelearningcourseartificialintelligencecourse/,nandiniravichandran,1527834839,[removed],0,1
12,2018-6-1,2018,6,1,16,8npyvt,[R] Relative Natural Gradient for Learning Large Complex Models,https://www.reddit.com/r/MachineLearning/comments/8npyvt/r_relative_natural_gradient_for_learning_large/,abstractcontrol,1527837141,,1,7
13,2018-6-1,2018,6,1,16,8nq22m,Best choice for storing big data?,https://www.reddit.com/r/MachineLearning/comments/8nq22m/best_choice_for_storing_big_data/,ejmejm1,1527838283,"I've recently been wanting to change how I store my ML data so I can work with larger amounts of data (1-4 TB). I don't know much about the topic of storage though so I thought I'd bring it up here. I know many people use cloud solutions, but I feel like it would be easier to just keep it all local, am I wrong here? I was thinking about getting a 4 TB external HDD, but I don't know much about other options. Thoughts or recommendations?",0,1
14,2018-6-1,2018,6,1,16,8nq36k,[D] What is the best choice for storing big data,https://www.reddit.com/r/MachineLearning/comments/8nq36k/d_what_is_the_best_choice_for_storing_big_data/,ejmejm1,1527838706,"I've recently been wanting to change how I store my ML data so I can work with larger amounts of data (1-4 TB). I don't know much about the topic of storage though so I thought I'd bring it up here. I know many people use cloud solutions, but I feel like it would be easier to just keep it all local, am I wrong here? I was thinking about getting a 4 TB external HDD, but I don't know much about other options. Thoughts or recommendations?",5,0
15,2018-6-1,2018,6,1,16,8nq4v5,Machine Learning Course | Artificial Intelligence Course,https://www.reddit.com/r/MachineLearning/comments/8nq4v5/machine_learning_course_artificial_intelligence/,nandiniravichandran,1527839361,[removed],0,1
16,2018-6-1,2018,6,1,17,8nq9iz,Human learning,https://www.reddit.com/r/MachineLearning/comments/8nq9iz/human_learning/,shoeroof,1527841124,[removed],0,1
17,2018-6-1,2018,6,1,17,8nq9oi,"UDOO launched a Kickstarter campaign for a new SBC with Ryzen V1000 series SoCs called the UDOO BOLT. Has support for up to 32GB DDR4 ECC, USB-C ports, NVMe m.2 storage, and more.. all on a 4.7in board",https://www.reddit.com/r/MachineLearning/comments/8nq9oi/udoo_launched_a_kickstarter_campaign_for_a_new/,_DropBit_,1527841176,,0,1
18,2018-6-1,2018,6,1,17,8nqa9n,Composing Jazz Music using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8nqa9n/composing_jazz_music_using_deep_learning/,itss_shubham,1527841404,,0,1
19,2018-6-1,2018,6,1,18,8nqiet,Ways to improve on the model?,https://www.reddit.com/r/MachineLearning/comments/8nqiet/ways_to_improve_on_the_model/,forfunandpeanuts,1527844563,[removed],0,1
20,2018-6-1,2018,6,1,18,8nqjjx,"[P] Just released my latest video on tackling the sparse reward problem in DeepRL (Hindsight Experience Replay, Curiosity Driven Exploration, ...) Check it out!",https://www.reddit.com/r/MachineLearning/comments/8nqjjx/p_just_released_my_latest_video_on_tackling_the/,tr1pzz,1527844992,,0,1
21,2018-6-1,2018,6,1,18,8nqjxi,"[P] Just released my latest video on tackling the sparse reward problem in DeepRL. Discussing Hindsight Experience Replay, Curiosity Driven Exploration, etc.. Check it out!",https://www.reddit.com/r/MachineLearning/comments/8nqjxi/p_just_released_my_latest_video_on_tackling_the/,tr1pzz,1527845137,,5,133
22,2018-6-1,2018,6,1,18,8nql3n,What are the most Statistical models used in Demand forecasting ?,https://www.reddit.com/r/MachineLearning/comments/8nql3n/what_are_the_most_statistical_models_used_in/,zorroisreal,1527845586,,0,1
23,2018-6-1,2018,6,1,18,8nqnv0,Machine learning: Making it work in the real world,https://www.reddit.com/r/MachineLearning/comments/8nqnv0/machine_learning_making_it_work_in_the_real_world/,mr_j_b,1527846592,,0,1
24,2018-6-1,2018,6,1,18,8nqo0h,Using ML to detect digits in American Sign Language: Featured Dataset + Live Webcam Detection + Documentation + Argparse functionality,https://www.reddit.com/r/MachineLearning/comments/8nqo0h/using_ml_to_detect_digits_in_american_sign/,callMeSpacetime,1527846649,,0,1
25,2018-6-1,2018,6,1,19,8nqq8d,[D] There are over 300k users in the subreddit. I have a created a poll to see how do users rate their ML Capabilities. Just curious.,https://www.reddit.com/r/MachineLearning/comments/8nqq8d/d_there_are_over_300k_users_in_the_subreddit_i/,geek--god,1527847419,,36,172
26,2018-6-1,2018,6,1,19,8nqv9k,New edition of MLMAG,https://www.reddit.com/r/MachineLearning/comments/8nqv9k/new_edition_of_mlmag/,zofia_mlmag_co,1527849231,,0,1
27,2018-6-1,2018,6,1,19,8nqycg,"[N] MIT Adds Professional Education Programs in Machine Learning, AI",https://www.reddit.com/r/MachineLearning/comments/8nqycg/n_mit_adds_professional_education_programs_in/,janemoz,1527850297,,0,1
28,2018-6-1,2018,6,1,19,8nqzpj,New edition of MLMAG!!,https://www.reddit.com/r/MachineLearning/comments/8nqzpj/new_edition_of_mlmag/,zofia_mlmag_co,1527850769,[removed],0,1
29,2018-6-1,2018,6,1,20,8nr60n,How to incorporate meta data into text classification model?,https://www.reddit.com/r/MachineLearning/comments/8nr60n/how_to_incorporate_meta_data_into_text/,crashbundicoot,1527852783,[removed],0,1
30,2018-6-1,2018,6,1,20,8nr9oi,[D] How would you write on LinkedIn that you took four months to learn ML ?,https://www.reddit.com/r/MachineLearning/comments/8nr9oi/d_how_would_you_write_on_linkedin_that_you_took/,mx-pv,1527853896,"As the title suggest I took four month to learn ML. I got a job recently in the field in computer vision. I was before a junior software engineer. During those four months I met experts in the field, read books, followed courses, built a portfolio and passed several interviews.

Since I got the job I wanted I am updating my pdf CV. But I am not sure in which section to add this experience in LinkedIn. I want to add it in the ""Experience"" section, with the title ""Skill Acquisition"", describing what I wrote above.

The ""Company"" field is required in to fill up ""Experience"" but I was working on my own, without being paid or any company involved. And I don't want to write it in ""Education"" because I don't want to have a four months gap when you look at my experiences \(I already travelled after my studies\).

What would you do in my position ?

PS: I hope this is the appropriate subreddit to post this question. Sorry if not.",4,0
31,2018-6-1,2018,6,1,20,8nr9y0,What You Would Need To Become a Machine Learning Engineer?,https://www.reddit.com/r/MachineLearning/comments/8nr9y0/what_you_would_need_to_become_a_machine_learning/,imarticus_nirmal,1527853980,,0,1
32,2018-6-1,2018,6,1,21,8nrbmq,Looking Guidance for Machine learning project.,https://www.reddit.com/r/MachineLearning/comments/8nrbmq/looking_guidance_for_machine_learning_project/,Deepak1516,1527854469,[removed],0,1
33,2018-6-1,2018,6,1,21,8nrinw,CNN insights: What do convolutional neural networks learn about free text?,https://www.reddit.com/r/MachineLearning/comments/8nrinw/cnn_insights_what_do_convolutional_neural/,nlpster,1527856380,,0,1
34,2018-6-1,2018,6,1,21,8nrluy,[P] Comparing simple Reinforcement Learning bandits,https://www.reddit.com/r/MachineLearning/comments/8nrluy/p_comparing_simple_reinforcement_learning_bandits/,nondifferentiable,1527857262,,2,3
35,2018-6-1,2018,6,1,21,8nrm3b,[R] Is strong AI inevitable?,https://www.reddit.com/r/MachineLearning/comments/8nrm3b/r_is_strong_ai_inevitable/,dearpetra,1527857328,,0,1
36,2018-6-1,2018,6,1,21,8nrmqe,[R] A Gentle Introduction to Statistical Tolerance Intervals in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8nrmqe/r_a_gentle_introduction_to_statistical_tolerance/,digitalson,1527857503,,0,1
37,2018-6-1,2018,6,1,21,8nro2w,Undergraduate Publications,https://www.reddit.com/r/MachineLearning/comments/8nro2w/undergraduate_publications/,Tower11Archer,1527857885,[removed],0,1
38,2018-6-1,2018,6,1,22,8nrr1q,Decision Tree using Algorithm _ Using Python,https://www.reddit.com/r/MachineLearning/comments/8nrr1q/decision_tree_using_algorithm_using_python/,pooja307,1527858601,,0,1
39,2018-6-1,2018,6,1,22,8nrrhp,Should You Fear Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8nrrhp/should_you_fear_machine_learning/,imarticus_nirmal,1527858718,,0,1
40,2018-6-1,2018,6,1,22,8ns0hq,Collecting data on croud's reaction to a performance (in clubs),https://www.reddit.com/r/MachineLearning/comments/8ns0hq/collecting_data_on_crouds_reaction_to_a/,lamipaul,1527860938,[removed],0,1
41,2018-6-1,2018,6,1,23,8ns7vv,[N] UC Berkeley Open-Sources 100k Driving Video Database,https://www.reddit.com/r/MachineLearning/comments/8ns7vv/n_uc_berkeley_opensources_100k_driving_video/,gwen0927,1527862688,,17,491
42,2018-6-1,2018,6,1,23,8nsabx,[R] Deep Video Portraits - SIGGRAPH 2018,https://www.reddit.com/r/MachineLearning/comments/8nsabx/r_deep_video_portraits_siggraph_2018/,chris2point0,1527863362,,12,41
43,2018-6-1,2018,6,1,23,8nsbet,[P] Telling python from rattlesnake,https://www.reddit.com/r/MachineLearning/comments/8nsbet/p_telling_python_from_rattlesnake/,not_a_hypno_drone,1527863647,"Hello everyone,

I am learning deep convolutional networks and posted my first deep learning project, DeepSnakes, on github. This is a binary classification model to distinguish images containing python snakes from images containing rattlesnakes. There are three parts so far: Part 1 \- Logistic Regression, Part 2 \- Shallow NNs and Part 3 \- CNN and AlexNet. The dev set accuracy were respectively 65&amp;#37;, 70&amp;#37; and 90&amp;#37;.

What do you guys think? Any feedback is more than welcome.

Thanks.

[https://github.com/hermesribeiro/DeepSnakes](https://github.com/hermesribeiro/DeepSnakes)",0,2
44,2018-6-1,2018,6,1,23,8nsdoz,[D] Is there a neural network that can synthesize and reproduce an audio sample?,https://www.reddit.com/r/MachineLearning/comments/8nsdoz/d_is_there_a_neural_network_that_can_synthesize/,Riin_Satoshi,1527864240,"Is there a neural network that can exactly recreate a single specific audio sample? For example, I have a snare audio sample and I want a neural network to recreate that exact audio sample. 
If there is a research paper about this topic I would love to know more about it. ",9,3
45,2018-6-1,2018,6,1,23,8nse2h,[D] Inception Network and its version differences,https://www.reddit.com/r/MachineLearning/comments/8nse2h/d_inception_network_and_its_version_differences/,thatbrguy_,1527864334,,3,12
46,2018-6-2,2018,6,2,0,8nsk71,[D] K-fold for weight selection after black-box optimization?,https://www.reddit.com/r/MachineLearning/comments/8nsk71/d_kfold_for_weight_selection_after_blackbox/,DragonDK,1527865630,"Let's say I have a crazy loss function, where the derivative cannot be computed, and some black-box optimization method will find many local minima with about the same loss value, but with very different weights. What weights to choose for a general problem like this? I'm thinking k-fold cross-validation could be used, to make sure the weights are chosen with the least estimated out of sample error. But is this appropriate? Or will some unwanted bias be introduced?",0,1
47,2018-6-2,2018,6,2,0,8nsm24,Learning Resources,https://www.reddit.com/r/MachineLearning/comments/8nsm24/learning_resources/,Ben_09,1527865970,[removed],0,1
48,2018-6-2,2018,6,2,1,8nt2qq,Are there any implementations of Deep Q Networks for robotics environments in Open AI gym?,https://www.reddit.com/r/MachineLearning/comments/8nt2qq/are_there_any_implementations_of_deep_q_networks/,satwik_,1527869008,,0,1
49,2018-6-2,2018,6,2,1,8nt9ac,[D] Help understand linear regression equation,https://www.reddit.com/r/MachineLearning/comments/8nt9ac/d_help_understand_linear_regression_equation/,petenpatrol,1527870298,I am just beginning to learn machine learning and specifically linear regression. I understand that the equation m= ((avgX * avgY) - avgXY) / (avgX)^2 - avg(X^2) works but i dont quite understand why and what each of the components in this equation signify in terms of the line. Any help appreciated!,4,0
50,2018-6-2,2018,6,2,1,8nt9cf,Upcoming Webinar  Deep Reinforcement Learning in Robotics with NVIDIA Jetson,https://www.reddit.com/r/MachineLearning/comments/8nt9cf/upcoming_webinar_deep_reinforcement_learning_in/,nanobot_1000,1527870310,,0,1
51,2018-6-2,2018,6,2,1,8ntb2w,[D] How to deploy machine learning Docker containers in Google Cloud Platform,https://www.reddit.com/r/MachineLearning/comments/8ntb2w/d_how_to_deploy_machine_learning_docker/,thetall0ne1,1527870662,,0,1
52,2018-6-2,2018,6,2,1,8ntcjv,[P]How Optimistic Do You Want to Be? Bayesian Neural Network Regression with Prediction Errors,https://www.reddit.com/r/MachineLearning/comments/8ntcjv/phow_optimistic_do_you_want_to_be_bayesian_neural/,MountainHawk81,1527870979,,1,1
53,2018-6-2,2018,6,2,2,8ntjc8,"[D] AI has a public relations problem, and AI researchers should do something about it",https://www.reddit.com/r/MachineLearning/comments/8ntjc8/d_ai_has_a_public_relations_problem_and_ai/,regalalgorithm,1527872460,,7,0
54,2018-6-2,2018,6,2,2,8ntpu9,Making a UNITY app with TENSORFLOWSHARP for Android and IOS,https://www.reddit.com/r/MachineLearning/comments/8ntpu9/making_a_unity_app_with_tensorflowsharp_for/,sk8er8921,1527873761,,0,1
55,2018-6-2,2018,6,2,3,8nu1b9,Automatic Differentiation in 10 minutes with Julia,https://www.reddit.com/r/MachineLearning/comments/8nu1b9/automatic_differentiation_in_10_minutes_with_julia/,ChrisRackauckas,1527876116,,0,1
56,2018-6-2,2018,6,2,3,8nu1zh,Fake NIPS 2018 website,https://www.reddit.com/r/MachineLearning/comments/8nu1zh/fake_nips_2018_website/,planwithoutman,1527876253,[removed],9,48
57,2018-6-2,2018,6,2,4,8nujt7,One parameter is always enough,https://www.reddit.com/r/MachineLearning/comments/8nujt7/one_parameter_is_always_enough/,StockZookeepergame,1527879956,,0,1
58,2018-6-2,2018,6,2,4,8nuk1r,[R] Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8nuk1r/r_finepruning_defending_against_backdooring/,moyix,1527879999,,1,4
59,2018-6-2,2018,6,2,4,8nuxdr,[D] State of the art for unstructured (binary) data input sequence representation?,https://www.reddit.com/r/MachineLearning/comments/8nuxdr/d_state_of_the_art_for_unstructured_binary_data/,AoeAoe,1527882878,"I'm playing with the idea of writing supervised network flow classifier which takes binary input sequence (raw packets) and classifies packets by their type (ethernet, ip, tcp, rtmp, handshake).

I'm wondering what people use when working unstructured input data like this? Are there any unsupervised algorithms which can be used for feature detection on raw binary data?

I don't see too many good ways of representing this unstructured data without actually parsing it manually.",1,1
60,2018-6-2,2018,6,2,5,8nv6gx,How would you go about classifying the mood of a sentence? i.e. whether it's declarative / interrogative / etc. (x-post /r/LanguageTechnology),https://www.reddit.com/r/MachineLearning/comments/8nv6gx/how_would_you_go_about_classifying_the_mood_of_a/,cookieutilitymonster,1527884853,"Are there libraries that handle this? If not, what datasets \+ ML techniques would be the best hammer for this problem? Thanks guys.",0,1
61,2018-6-2,2018,6,2,5,8nv964,[D] A Large-scale Diverse Driving Video Database  The Berkeley Artificial Intelligence Research Blog,https://www.reddit.com/r/MachineLearning/comments/8nv964/d_a_largescale_diverse_driving_video_database_the/,sksq9,1527885443,,1,35
62,2018-6-2,2018,6,2,5,8nvb71,[P] Spell and ICLR Reproducibility,https://www.reddit.com/r/MachineLearning/comments/8nvb71/p_spell_and_iclr_reproducibility/,saksoz,1527885889,"I'd like to introduce the r/machinelearning community to [Spell](http://spell.run), which is a tool we built for easy remote execution and management of ML/DL jobs. We built the first version of Spell to be the easiest way to run code remotely - like the bash '&amp;' operator but for sending work to more powerful instances. Some key features

* Code doesn't need to be modified. It's very easy to pull something directly off github and run it
* Built around a remote filesystem, so you only have to upload data once
* Highly efficient and reliable enough to use routinely and build workflows with

We recently attended ICLR in Vancouver and used Spell to reproduce as much of the work presented in the orals as possible. Overall, we were able to run a number of the techniques by pulling the code from github and using the spell CLI

You can find the guides to running the code below. [Sign up for spell](http://web.spell.run/waitlist)and try along at home - we're approving accounts as they come in and including **$300 of free GPU time** to help you get started.
[AmbientGAN: Generative models from lossy measurements](https://medium.com/@spellrun/reproducing-iclr-ambientgan-generative-models-from-lossy-measurements-5288f97d373)
[Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality](https://medium.com/@spellrun/reproducing-iclr-characterizing-adversarial-subspaces-using-local-intrinsic-dimensionality-25069946c388)
[Training and Inference with Integers in Deep Neural Networks](https://medium.com/@spellrun/reproducing-iclr-training-and-inference-with-integers-in-deep-neural-networks-4d5e4679cdd0)
[Learning to Represent Programs with Graphs](https://medium.com/@spellrun/reproducing-iclr-learning-to-represent-programs-with-graphs-b64da9a49086)
[Neural Sketch Learning for Conditional Program Generation](https://medium.com/@spellrun/reproducing-iclr-neural-sketch-learning-for-conditional-program-generation-80e83eb7882)
[Wasserstein Auto-Encoders](https://medium.com/@spellrun/reproducing-iclr-wasserstein-auto-encoders-18f499914e47)
[On the insufficiency of existing momentum schemes for Stochastic Optimization](https://medium.com/@spellrun/reproducing-iclr-on-the-insufficiency-of-existing-momentum-schemes-for-stochastic-optimization-2a3d3bed913f)",0,4
63,2018-6-2,2018,6,2,5,8nvbdy,Automatic differentiation in 10 mins with Alan Edelman of MIT,https://www.reddit.com/r/MachineLearning/comments/8nvbdy/automatic_differentiation_in_10_mins_with_alan/,ViralBShah,1527885934,,0,1
64,2018-6-2,2018,6,2,5,8nvdix,[D] Introducing the ColumnTransformer: applying different transformations to different features in a scikit-learn pipeline | Joris Van den Bossche,https://www.reddit.com/r/MachineLearning/comments/8nvdix/d_introducing_the_columntransformer_applying/,_alphamaximus_,1527886417,,0,1
65,2018-6-2,2018,6,2,5,8nvdpw,[R] [1805.12152] There Is No Free Lunch In Adversarial Robustness (But There Are Unexpected Benefits) &lt;- adversarially trained CNNs have a meaningful image gradient,https://www.reddit.com/r/MachineLearning/comments/8nvdpw/r_180512152_there_is_no_free_lunch_in_adversarial/,SophisticatedBean,1527886459,,12,28
66,2018-6-2,2018,6,2,6,8nvpyb,Metrics for evaluating Unsupervised Anomaly Detection,https://www.reddit.com/r/MachineLearning/comments/8nvpyb/metrics_for_evaluating_unsupervised_anomaly/,kylepob,1527889184,[removed],0,1
67,2018-6-2,2018,6,2,6,8nvuje,[D] So Good They Can't Ignore You? Do Skills Trump Passion in the Quest for Work You Love?,https://www.reddit.com/r/MachineLearning/comments/8nvuje/d_so_good_they_cant_ignore_you_do_skills_trump/,sugarhilldt2,1527890267,"Someone suggested this book to me: [https://www.amazon.com/Good\-They\-Cant\-Ignore\-You/dp/1455509124](https://www.amazon.com/Good-They-Cant-Ignore-You/dp/1455509124)

The idea is simple: Passion is hard to come by early in your career, when you have little idea what work is like. What's more important is being good at whatever you do. If you become good at your job, no matter what it is, you can create a satisfying career path for yourself.   


What do you think? ",0,1
68,2018-6-2,2018,6,2,8,8nwaga,What are the most Suitable approach for Demand forecasting ?,https://www.reddit.com/r/MachineLearning/comments/8nwaga/what_are_the_most_suitable_approach_for_demand/,zorroisreal,1527894099,[removed],0,1
69,2018-6-2,2018,6,2,8,8nwjbp,Using recurrent neural networks to model errors in IMUs,https://www.reddit.com/r/MachineLearning/comments/8nwjbp/using_recurrent_neural_networks_to_model_errors/,interstellarhighway,1527896359,[removed],0,1
70,2018-6-2,2018,6,2,9,8nwt7z,[P] HELP! Preprocessing Medical Dataset (3DConvNet),https://www.reddit.com/r/MachineLearning/comments/8nwt7z/p_help_preprocessing_medical_dataset_3dconvnet/,alba_troz,1527898900,"Hello!

I'm working with the [LiTS Dataset](https://competitions.codalab.org/competitions/17094#participate) \(liver tumor\), which contains several CT Scans, each 512x512xN \(N layers, varying between 75 and 861 layers per file\). The code I used is in [this](https://github.com/albatroz95/thesis/blob/master/preprocess.py) repository, if you can give it a look I would appreciate it! I've been trying to preprocess the data in 2 ways.

First, I **resized the resolution** of the Dataset to \(128, 128\), as it reduces memory load and training time, which was successful for both CT volumes and respective masks.

Now I am trying to **normalize the number of layers** so each file would have N layers in the z axis. To do so, I used the following code:

    def chunks(l, n):
        """"""Yield successive n-sized chunks from l.""""""
        for i in range(0, len(l), n):
            yield l[i:i + n]
    
    
    def mean(a):
        return sum(a) / len(a)
    
    
        chunk_sizes = math.ceil(len(slices) / hm_slices)
    
        new_slices = []
        for slice_chunk in chunks(slices, chunk_sizes):
            slice_chunk = list(map(mean, zip(*slice_chunk)))
            new_slices.append(slice_chunk)

Where `slices` is a list with the original file's data, `hm_slices` represents the new value for N, `chunk_sizes` is the number of layers per chunk. So basically if the original file has 100 layers and I want to convert it to 20, it will be divided in 20 different chunks, each being computed by the mean of 5 adjacent layers.

It worked well with the original scans, but it was a mess with the segmented images. The problem is that although they have 3 integer classes, 0 for background, 1 for liver, and 2 for tumor, when they go through this algorithm the array comes back as floats due to the mean function being used. Also the binary function is useless because I have 3 classes. Any suggestions?

Thanks in advanced!",5,0
71,2018-6-2,2018,6,2,10,8nx371,[P] pytorch-0.4-yolov3 : Yet Another Implementation of Pytorch 0.4 and Yolov3,https://www.reddit.com/r/MachineLearning/comments/8nx371/p_pytorch04yolov3_yet_another_implementation_of/,Andy-yun,1527901598,"I am very pleased to have the opportunity to publish the my contribution to pytorch and yolov3 implementation as

[https://github.com/andy\-yun/pytorch\-0.4\-yolov3](https://github.com/andy-yun/pytorch-0.4-yolov3) 

This repository is actually forked from [https://github.com/marvis/pytorch\-yolo2](https://github.com/marvis/pytorch-yolo2)  and [https://github.com/marvis/pytorch\-yolo](https://github.com/marvis/pytorch-yolo2)3, but files and filenames are changed much. Therefore, I decided to release it separately. The codes support yolov2 and yolov3 configuration and dataparallel for multiple gpus and so on. Main difference is that output\(s\) of region layer and yolo layer is\(are\) enclosed to dictionary variables to support dataparallel. Some changes are applied to speed up and easy readings. If you are interested, please visit this repository.",0,4
72,2018-6-2,2018,6,2,10,8nx4vv,[P] Intro to Optimization in deep learning: Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/8nx4vv/p_intro_to_optimization_in_deep_learning_gradient/,taltal13,1527902037,,9,58
73,2018-6-2,2018,6,2,10,8nx66y,[R] [1805.12076] Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8nx66y/r_180512076_towards_understanding_the_role_of/,evc123,1527902388,,0,22
74,2018-6-2,2018,6,2,10,8nx6ej,[D] Does familiarity with machine learning make you less spiritual?,https://www.reddit.com/r/MachineLearning/comments/8nx6ej/d_does_familiarity_with_machine_learning_make_you/,Im_int,1527902448,"I grew up non-religious, but I used to think of the human mind as something mystical (as opposed to mechanistic). However, the more I learned in general, the less confident I became about the non-mechanistic nature of the mind. Studying machine learning was the last straw that made me convinced we are nothing but very complicated machines. I used to be fascinated by philosophical debates about the nature (illusion vs reality) of self-awareness, free will, etc, but with my present materialistic beliefs everything seems extremely trivial and not even worth the argument.

I wonder what your experience is like. Do you think the human mind is nothing but a complicated machine or do you believe it is more than that, and as a consequence we will never be able to create self-aware AI regardless of our technological level?",50,0
75,2018-6-2,2018,6,2,11,8nxhbd,[D] How do we extract features from an LSTM Language Model,https://www.reddit.com/r/MachineLearning/comments/8nxhbd/d_how_do_we_extract_features_from_an_lstm/,Faizann24,1527905503,"I recently read the ""Learning to generate reviews and discovering sentiment"" paper by OPENAI and found it to be super cool. But I could not understand how they are using the language model as feature extractor. Suppose we have 150 characters in a review, how do we extract features from these 150 characters when our input is 64 characters at a time.",1,1
76,2018-6-2,2018,6,2,11,8nxmdg,[N] Richard Socher announces new online class for deep learning and natural language processing.,https://www.reddit.com/r/MachineLearning/comments/8nxmdg/n_richard_socher_announces_new_online_class_for/,BatmantoshReturns,1527906972,,5,0
77,2018-6-2,2018,6,2,11,8nxobn,[P] Does matconvnet support the gtx 1050 ti? (for deep learning),https://www.reddit.com/r/MachineLearning/comments/8nxobn/p_does_matconvnet_support_the_gtx_1050_ti_for/,coldassturkey,1527907525,"Im finding it hard to find the information on this, but im sure its fine.
The gtx 1050 ti is listed as having a compute capability of 6.1.
Or if someone can point me to a list of supported GPUs for matconvnet that would be stellar! 
Cheers",3,0
78,2018-6-2,2018,6,2,11,8nxqmy,"Looking for papers about social media analysis using ML techniques, especially in twitter",https://www.reddit.com/r/MachineLearning/comments/8nxqmy/looking_for_papers_about_social_media_analysis/,vinicius978,1527908182,"I'm doing my final project to finally get my undergrad degree. The title is ""Classification of depressive profile tweets using Machine Learning techniques"". Is there someone here that studied and/or have been studying and has some interesting papers that can help me with my arguments? 

My current goal, for now, is to read these papers and keep searching for more interesting ones. Any help would be appreciated 

**Depressive Moods of Users Portrayed in Twitter**

[https://pdfs.semanticscholar.org/8dd5/8913bd343f4ef23b8437b24e152d3270cdaf.pdf](https://pdfs.semanticscholar.org/8dd5/8913bd343f4ef23b8437b24e152d3270cdaf.pdf)

**Evaluation datasets for Twitter sentiment analysis: a survey and a new dataset, the STS\-Gold**

[http://oro.open.ac.uk/40660/](http://oro.open.ac.uk/40660/)

**You Are What You Tweet: Analyzing Twitter for Public Health**

[http://www.cs.jhu.edu/\~mpaul/files/2011.icwsm.twitter\_health.pdf](http://www.cs.jhu.edu/~mpaul/files/2011.icwsm.twitter_health.pdf)

**Predicting Depression via Social Media**

[https://www.researchgate.net/publication/259948193\_Predicting\_Depression\_via\_Social\_Media](https://www.researchgate.net/publication/259948193_Predicting_Depression_via_Social_Media)",0,1
79,2018-6-2,2018,6,2,12,8nxrs9,Is it possible to use a 2D car simulator to train the brain of an actual miniature car?,https://www.reddit.com/r/MachineLearning/comments/8nxrs9/is_it_possible_to_use_a_2d_car_simulator_to_train/,zimmer550king,1527908540,[removed],0,1
80,2018-6-2,2018,6,2,12,8nxwd7,"Anyone read Elements of Causal Inference by Jonas Peters, etal",https://www.reddit.com/r/MachineLearning/comments/8nxwd7/anyone_read_elements_of_causal_inference_by_jonas/,UtJsbnm,1527909916,[removed],0,1
81,2018-6-2,2018,6,2,14,8nyg2l,[1805.15352] DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,https://www.reddit.com/r/MachineLearning/comments/8nyg2l/180515352_dialogwae_multimodal_response/,guxd,1527916409,[removed],0,1
82,2018-6-2,2018,6,2,14,8nyi0u,[1805.12352] DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,https://www.reddit.com/r/MachineLearning/comments/8nyi0u/180512352_dialogwae_multimodal_response/,guxd,1527917080,[removed],0,1
83,2018-6-2,2018,6,2,14,8nyjum,[1805.12352] DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,https://www.reddit.com/r/MachineLearning/comments/8nyjum/180512352_dialogwae_multimodal_response/,guxd,1527917714,,0,1
84,2018-6-2,2018,6,2,14,8nykb0,k-Nearest Neighbors Classifier from scratch,https://www.reddit.com/r/MachineLearning/comments/8nykb0/knearest_neighbors_classifier_from_scratch/,imHarin,1527917870,,1,1
85,2018-6-2,2018,6,2,15,8nyox9,Introduction to Logistic Regression by Shruti Kohli,https://www.reddit.com/r/MachineLearning/comments/8nyox9/introduction_to_logistic_regression_by_shruti/,shiv4nsh,1527919598,,0,1
86,2018-6-2,2018,6,2,15,8nyt21,Introduction to Logistic Regression by Aakarsha @ Internity Foundation,https://www.reddit.com/r/MachineLearning/comments/8nyt21/introduction_to_logistic_regression_by_aakarsha/,shiv4nsh,1527921112,,0,1
87,2018-6-2,2018,6,2,17,8nz77y,[R] Interpretation of the Outputs of Deep Learning Model Trained with Skin Cancer Dataset,https://www.reddit.com/r/MachineLearning/comments/8nz77y/r_interpretation_of_the_outputs_of_deep_learning/,whria78,1527927222,"Our manuscript, ""Interpretation of the Outputs of Deep Learning Model Trained with Skin Cancer Dataset"" was published as a letter article in the Journal of Investigative Dermatology today \([https://www.jidonline.org/article/S0022\-202X\(18\)31992\-4/fulltext](https://www.jidonline.org/article/S0022-202X(18)31992-4/fulltext)\).

**\&lt;The analyzing AUC is better than Top\-\(n\) accuracy when we have small and imbalanced training dataset\&gt;**

When we train a CNN model, we sometimes get a disappointing Top\-1 accuracy. I also had suffered this problem and I did not understand exactly what was wrong. When the early version of the 12DX paper \([https://www.jidonline.org/article/S0022\-202X\(18\)30111\-8/fulltext](https://www.jidonline.org/article/S0022-202X(18)30111-8/fulltext)\) was reviewed in JAMA dermatology 2 years ago, the biggest reason for rejection was low Top\-1 accuracy.

However, unlike general object recognition studies, it is very difficult to determine the results with Top\-1 accuracy, and it is important that the AUC value of ROC curve can be high even with a low Top\-1 accuracy. If you look carefully, most of medical AI researches have used the AUC rather than Top\-\(n\) accuracy.

Because of small and imbalanced training data in medical researches, the analysis of each class as Top\-\(n\) accuracy is inadequate \(but the mean value of Top\-\(n\) of all classes is meaningful\). Top\-\(n\) accuracy of each classes vary whenever we repeat training of CNN with an imbalanced dataset. Therefore, we should see the corrected value while using thresholds of each classes, that is the AUC value of ROC curve.

With good AUC results, we published ""12DX; Classification of the Clinical Images for Benign and Malignant Cutaneous Tumors Using a Deep Learning Algorithm"" \([https://www.jidonline.org/article/S0022\-202X\(18\)30111\-8/fulltext](https://www.jidonline.org/article/S0022-202X(18)30111-8/fulltext)\). However, there was a debate that our algorithm is not sensitive \(low top\-1 accuracy\) with ISIC dataset \(Automated Dermatological Diagnosis: Hype or Reality?; [https://www.jidonline.org/article/S0022\-202X\(18\)31991\-2/fulltext](https://www.jidonline.org/article/S0022-202X(18)31991-2/fulltext)\).

**\&lt;Classifying tumorous nodule is much difficult than determining whether it is malignant or not\&gt;**

There was an additional problem as well as the Top accuracy problem. When we analyze a clinical image, ""the problem of judging whether it is melanoma or not"" is easier than ""the problem of matching the type of cancer"".

Analyzing the output of the CNN is equivalent to solve ""the problem of matching the type of cancer"". Therefore we need to analyze the ratio of output, if we want to solvethe problem of judging ""whether cancer or not"".

We interpreted the ratio of melanoma output and nevus output rather than using melanoma output alone.

*RATIO \(Melanoma Index\) = melanoma output / \(melanoma output \+ nevus output\)*

The clinical image of skin cancer consists of a nodular lesion and a background. If you want to concentrate on only the lesion, we need to analyze it with RATIO as above to get more accurate results.

In the attached photograph \([https://i.imgur.com/jnZUavi.png](https://i.imgur.com/jnZUavi.png)\), \(b\) is ""matching what cancer is"" and \(a\) is judging ""whether it is cancer or not"". \(a\) is much better than \(b\). The AUC for diagnosing melanoma jumps from 0.69 to 0.91.

We made web\-DEMO \([http://dx.medicalphoto.org](http://dx.medicalphoto.org)\), and it possible to show what conclusions are coming up depending on the Top\-5 output and how it is interpreted.",11,25
88,2018-6-2,2018,6,2,19,8nzlvz,Generator loss converging to 0 very quickly,https://www.reddit.com/r/MachineLearning/comments/8nzlvz/generator_loss_converging_to_0_very_quickly/,wadhwasahil,1527933708,[removed],0,1
89,2018-6-2,2018,6,2,21,8o06xw, - GALAXY CHANNEL,https://www.reddit.com/r/MachineLearning/comments/8o06xw/_galaxy_channel/,Woodworking94,1527942122,,0,1
90,2018-6-2,2018,6,2,22,8o0j19,[N] Google Will Not Renew Project Maven Contract,https://www.reddit.com/r/MachineLearning/comments/8o0j19/n_google_will_not_renew_project_maven_contract/,undefdev,1527946009,,123,250
91,2018-6-2,2018,6,2,22,8o0ncz,What is it that makes it so hard to generate jokes?,https://www.reddit.com/r/MachineLearning/comments/8o0ncz/what_is_it_that_makes_it_so_hard_to_generate_jokes/,mrconter1,1527947256,[removed],0,1
92,2018-6-2,2018,6,2,23,8o0uyg,"Anyone attending IJCNN, WCCI 2018 at brazil? Let's connect",https://www.reddit.com/r/MachineLearning/comments/8o0uyg/anyone_attending_ijcnn_wcci_2018_at_brazil_lets/,saytosid,1527949593,[removed],0,1
93,2018-6-2,2018,6,2,23,8o0vaa,[bioinformatics research] choice between 2 internships with ML,https://www.reddit.com/r/MachineLearning/comments/8o0vaa/bioinformatics_research_choice_between_2/,feli_fourmi,1527949719,[removed],0,1
94,2018-6-2,2018,6,2,23,8o0wmp,I have 2 AUCs from the same data but 2 algorithms. How I determine if one of the AUCs is greater in a statistically signifant sense?,https://www.reddit.com/r/MachineLearning/comments/8o0wmp/i_have_2_aucs_from_the_same_data_but_2_algorithms/,idg101,1527950200,[removed],0,1
95,2018-6-3,2018,6,3,0,8o1254,"Parameters explanation of the ""measuring uncertainty"" method by Gal",https://www.reddit.com/r/MachineLearning/comments/8o1254/parameters_explanation_of_the_measuring/,heavyfranz,1527951712,[removed],0,1
96,2018-6-3,2018,6,3,1,8o1mow,Sentence classification over several features,https://www.reddit.com/r/MachineLearning/comments/8o1mow/sentence_classification_over_several_features/,thats-why-i,1527956213,"Hello all. I have a passing interest in machine learning and have been reading a lot of papers about NLP and sentence classification. From what I can understand, the process of classifying a sentence is typically done by turning the input sentence into a word vector and looking at frequency of words, placement relative to other words, etc...

I am wondering, though, what is the process for when there are several features of an input, i.e. multiple sentences (not necessarily in the same paragraph) that contribute to the eventual class? Perhaps like a row of tabular data that has some integers, some sentences, something like that.

Am I fundamentally misunderstanding something here? I have no formal teaching here, just really curious. Thanks for the help!",0,1
97,2018-6-3,2018,6,3,1,8o1q6f,Intel Open Sources NLP Architect,https://www.reddit.com/r/MachineLearning/comments/8o1q6f/intel_open_sources_nlp_architect/,joehillen,1527957086,,0,1
98,2018-6-3,2018,6,3,1,8o1r5s,Best way to get into ML/NLP for a CS,https://www.reddit.com/r/MachineLearning/comments/8o1r5s/best_way_to_get_into_mlnlp_for_a_cs/,Swaggarius,1527957332,[removed],0,1
99,2018-6-3,2018,6,3,2,8o23y8,AI Weekly 2 June 2018,https://www.reddit.com/r/MachineLearning/comments/8o23y8/ai_weekly_2_june_2018/,TomekB,1527960442,,0,1
100,2018-6-3,2018,6,3,2,8o27to,[N] Intel Open Sources NLP Architect,https://www.reddit.com/r/MachineLearning/comments/8o27to/n_intel_open_sources_nlp_architect/,joehillen,1527961359,,5,57
101,2018-6-3,2018,6,3,3,8o2ib1,Using research papers vs coming up with my own algorithm (xpost /r/datascience),https://www.reddit.com/r/MachineLearning/comments/8o2ib1/using_research_papers_vs_coming_up_with_my_own/,3shar5ever,1527963802,[removed],0,1
102,2018-6-3,2018,6,3,3,8o2k37,[D] Undergrad Math Course Selection Advice,https://www.reddit.com/r/MachineLearning/comments/8o2k37/d_undergrad_math_course_selection_advice/,soliciting_advice,1527964233,"Looking for course selection advice on my final semester of BA pure math program.

I have about 5 years of software development experience (web/mobile enterprise applications)
and recently went back to school full time to study math. I wanted to build a foundation for
better understanding ML/AI and take first steps towards transitioning my career into a research
oriented role in ML/AI.

So far I've completed 2 semesters Algebra, 2 semesters Real Analysis, Into to Complex Analysis,
Linear Models (regression), Number Theory and a smattering of basic CS courses taken during summer
semesters.

Fall 2018 will be my last semester before returning to industry. It's possible that I'll get
into a good grad school and do a masters in CS or Math, but more likely I'll just go back to
industry (maybe a concurrent part time masters in Math).

I'm trying to decide between taking pure math courses or more upper level stats.

I am definitely taking Graduate Linear Algebra and have room for about 2.5 more
math/stats/cs courses. The options are (all undergraduate level unless noted)

Topology,
Optimization,
Probability Models (focus on Markov Chains),
Design/Analysis of Experiments,
Graduate Soft Computing (applications of fuzzy sets)

What would you recomend I take and why?
",14,0
103,2018-6-3,2018,6,3,3,8o2lmd,[D] What do you make of this blog post?,https://www.reddit.com/r/MachineLearning/comments/8o2lmd/d_what_do_you_make_of_this_blog_post/,rahulsoibam,1527964601,[removed],0,1
104,2018-6-3,2018,6,3,3,8o2o5a,AI Winter is well on its way,https://www.reddit.com/r/MachineLearning/comments/8o2o5a/ai_winter_is_well_on_its_way/,rahulsoibam,1527965209,[https://blog.piekniewski.info/2018/05/28/ai\-winter\-is\-well\-on\-its\-way/](https://blog.piekniewski.info/2018/05/28/ai-winter-is-well-on-its-way/),0,1
105,2018-6-3,2018,6,3,4,8o2xkb,[D] PC build for ML/gaming,https://www.reddit.com/r/MachineLearning/comments/8o2xkb/d_pc_build_for_mlgaming/,arivar,1527967494,"Hi,

I am trying to build a PC that will mostly be used for ML, but some gaming sometimes. I live in Brazil, so I don't have all the hardware options available at reasonable prices. What do you think of the setup below ? Is there anything I should try to change?

Thanks



[PCPartPicker part list](https://ca.pcpartpicker.com/list/Y3c28Y) / [Price breakdown by merchant](https://ca.pcpartpicker.com/list/Y3c28Y/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [AMD - Ryzen 7 2700X 3.7GHz 8-Core Processor](https://ca.pcpartpicker.com/product/bddxFT/amd-ryzen-7-2700x-37ghz-8-core-processor-yd270xbgafbox) | $415.25 @ shopRBC
**Motherboard** | [Asus - ROG Crosshair VII Hero (Wi-Fi) ATX AM4 Motherboard](https://ca.pcpartpicker.com/product/bvdxFT/asus-rog-crosshair-vii-hero-wi-fi-atx-am4-motherboard-crosshair-vii-hero-wi-fi) | $360.99 @ Mike's Computer Shop
**Memory** | [Corsair - Dominator Platinum 32GB (2 x 16GB) DDR4-3000 Memory](https://ca.pcpartpicker.com/product/2VcMnQ/corsair-memory-cmd32gx4m2b3000c15) | $525.00 @ Amazon Canada
**Storage** | [Kingston - A1000 480GB M.2-2280 Solid State Drive](https://ca.pcpartpicker.com/product/3xTPxr/kingston-a1000-480gb-m2-2280-solid-state-drive-sa1000m8480g) | $179.99 @ PC-Canada
**Storage** | [Kingston - A1000 480GB M.2-2280 Solid State Drive](https://ca.pcpartpicker.com/product/3xTPxr/kingston-a1000-480gb-m2-2280-solid-state-drive-sa1000m8480g) | $179.99 @ PC-Canada
**Video Card** | [Asus - GeForce GTX 1080 Ti 11GB STRIX GAMING OC Video Card](https://ca.pcpartpicker.com/product/Z8cMnQ/asus-geforce-gtx-1080-ti-11gb-video-card-strix-gtx1080ti-o11g-gaming) (2-Way SLI) | $1101.99 @ PC-Canada
**Video Card** | [Asus - GeForce GTX 1080 Ti 11GB STRIX GAMING OC Video Card](https://ca.pcpartpicker.com/product/Z8cMnQ/asus-geforce-gtx-1080-ti-11gb-video-card-strix-gtx1080ti-o11g-gaming) (2-Way SLI) | $1101.99 @ PC-Canada
**Case** | [Cooler Master - MasterCase Pro 6 ATX Mid Tower Case](https://ca.pcpartpicker.com/product/3MH48d/cooler-master-mastercase-pro-6-atx-mid-tower-case-mcy-c6p2-kw5n) | $226.99 @ PC-Canada
**Power Supply** | [EVGA - 850W 80+ Gold Certified Semi-Modular ATX Power Supply](https://ca.pcpartpicker.com/product/2BcMnQ/evga-power-supply-210gq0850) | $157.98 @ Amazon Canada
| *Prices include shipping, taxes, rebates, and discounts* |
| **Total** | **$4250.17**
| Generated by [PCPartPicker](http://pcpartpicker.com) 2018-06-02 15:20 EDT-0400 |


",26,0
106,2018-6-3,2018,6,3,6,8o3vcu,Mind Mimic,https://www.reddit.com/r/MachineLearning/comments/8o3vcu/mind_mimic/,dsangle0002,1527976087,[removed],0,1
107,2018-6-3,2018,6,3,7,8o436w,Choosing the Optimal Way to Run an Image Recognition Software Application in Poor Network Conditions.,https://www.reddit.com/r/MachineLearning/comments/8o436w/choosing_the_optimal_way_to_run_an_image/,micknick9,1527978148,[removed],0,1
108,2018-6-3,2018,6,3,8,8o4hs6,Approximate the values of a matrix given a function built with a given base vector. (Anyone with Python and ML experience?),https://www.reddit.com/r/MachineLearning/comments/8o4hs6/approximate_the_values_of_a_matrix_given_a/,JDvzs,1527981917,,0,1
109,2018-6-3,2018,6,3,9,8o4ztu,A Course in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8o4ztu/a_course_in_machine_learning/,elguapo_r,1527986864,,0,4
110,2018-6-3,2018,6,3,10,8o555s,Fast.ai PyTorch Serverless API (w/ AWS Lambda),https://www.reddit.com/r/MachineLearning/comments/8o555s/fastai_pytorch_serverless_api_w_aws_lambda/,eRepublik887,1527988431,,0,1
111,2018-6-3,2018,6,3,10,8o55ry,Proof from Westworld that TensorFlow is the future...,https://www.reddit.com/r/MachineLearning/comments/8o55ry/proof_from_westworld_that_tensorflow_is_the_future/,ilikepancakez,1527988613,,1,1
112,2018-6-3,2018,6,3,11,8o5nsk,Updated the logo preparing for Pytorch 1.0!!,https://www.reddit.com/r/MachineLearning/comments/8o5nsk/updated_the_logo_preparing_for_pytorch_10/,Deepblue129,1527993859,,1,1
113,2018-6-3,2018,6,3,12,8o5tlh,VisDA 2017 : Self Ensembling for Visual Domain Adaptation,https://www.reddit.com/r/MachineLearning/comments/8o5tlh/visda_2017_self_ensembling_for_visual_domain/,sujitrrai,1527995594,[removed],0,1
114,2018-6-3,2018,6,3,13,8o6cg7,[R] Towards Reinforcement Learning Inspired By Humans Without Human Demonstrations,https://www.reddit.com/r/MachineLearning/comments/8o6cg7/r_towards_reinforcement_learning_inspired_by/,wei_jok,1528001436,,3,53
115,2018-6-3,2018,6,3,15,8o6tno, !,https://www.reddit.com/r/MachineLearning/comments/8o6tno//,Woodworking94,1528007684,,0,1
116,2018-6-3,2018,6,3,16,8o70jo,"[D] For model based reinforced learning, are there any existing methods for software to probe the environment and build its own model from scratch?",https://www.reddit.com/r/MachineLearning/comments/8o70jo/d_for_model_based_reinforced_learning_are_there/,NullAccountNameField,1528010462,,7,4
117,2018-6-3,2018,6,3,16,8o716z,Machine learning/deep learning roles with applications to climate change. x-post /r/deeplearning,https://www.reddit.com/r/MachineLearning/comments/8o716z/machine_learningdeep_learning_roles_with/,IcyCelebration,1528010722,"Hi all!

I am a graduate student in atmospheric and oceanic sciences researching climate variability and change. Due to personal reasons, I am planning to transition into the industry. I am specifically looking for deep learning/machine learning roles with applications to climate change/climate risk/renewable energy. Is anyone familiar with companies that offer such roles? [other than climate corporation] I have been searching online and networking offline for the last couple of weeks with no luck. Any help is greatly appreciated!",0,1
118,2018-6-3,2018,6,3,16,8o74db,"Learning to Explain (L2X) - faster than LIME/SHAP and claims better ""post-hoc"" accuracy",https://www.reddit.com/r/MachineLearning/comments/8o74db/learning_to_explain_l2x_faster_than_limeshap_and/,denfromufa,1528012123,,0,1
119,2018-6-3,2018,6,3,17,8o7a31,Machine learning/data science job scene in Montreal? Is it really same as the way media hype shows?,https://www.reddit.com/r/MachineLearning/comments/8o7a31/machine_learningdata_science_job_scene_in/,hmi2015,1528014642,[removed],0,1
120,2018-6-3,2018,6,3,18,8o7dve,[D] How long/complex to increase video quality of old tv show?,https://www.reddit.com/r/MachineLearning/comments/8o7dve/d_how_longcomplex_to_increase_video_quality_of/,sigi234,1528016405,"Hi,

i'm a software engineer and looking for an interesting ML project.

Right now i'm watching Star Trek DS9 (don't worry watching it, its not good go watch Voyager!) and thinking if there is a feasible way of enhancing its image quality.

My thoughts are, that it should be possible to generate a Network which detects reoccurring objects like characters and learns them in combination of time (like humans change over time). Than taking those representations, enrich them with High quality real live images of those actors.

Also using the same approach but without an time part to enrich the existing set with high quality pictures from Star Trek Discovery.

How complex would it be to build something like this up? Are existing tools already usable? Is there a basic flaw in my thinking?",21,31
121,2018-6-3,2018,6,3,18,8o7gl6,[1805.12352] DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,https://www.reddit.com/r/MachineLearning/comments/8o7gl6/180512352_dialogwae_multimodal_response/,guxd,1528017641,[removed],0,1
122,2018-6-3,2018,6,3,18,8o7iga,[P]Proximal Policy Optimization (PPO) implementation with documentation for Atari Breakout,https://www.reddit.com/r/MachineLearning/comments/8o7iga/pproximal_policy_optimization_ppo_implementation/,mlvpj,1528018489,,1,11
123,2018-6-3,2018,6,3,18,8o7jnl,[1805.12352] DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,https://www.reddit.com/r/MachineLearning/comments/8o7jnl/180512352_dialogwae_multimodal_response/,guxd,1528019000,"arXiv: [https://arxiv.org/abs/1805.12352](https://arxiv.org/abs/1805.12352)

Abstract:

Variational autoencoders \(VAEs\) have shown a promise in data\-driven conversation modeling. However, most VAE conversation models match the approximate posterior distribution over the latent variables to a simple prior such as standard normal distribution, thereby restricting the generated responses to a relatively simple \(e.g., single\-modal\) scope. In this paper, we propose DialogWAE, a conditional Wasserstein autoencoder \(WAE\) specially designed for dialogue modeling. Unlike VAEs that impose a simple distribution over the latent variables, DialogWAE models the distribution of data by training a GAN within the latent variable space. Specifically, our model samples from the prior and posterior distributions over the latent variables by transforming context\-dependent random noise using neural networks and minimizes the Wasserstein distance between the two distributions. We further develop a Gaussian mixture prior network to enrich the latent space. Experiments on two widely\-used datasets show that DialogWAE outperforms the state\-of\-the\-art approaches in generating more coherent, informative and diverse responses. ",0,1
124,2018-6-3,2018,6,3,19,8o7m57,DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,https://www.reddit.com/r/MachineLearning/comments/8o7m57/dialogwae_multimodal_response_generation_with/,guxd,1528020100,[removed],0,1
125,2018-6-3,2018,6,3,19,8o7mkt,[D] Is there an implementation of Neural Voice Cloning?,https://www.reddit.com/r/MachineLearning/comments/8o7mkt/d_is_there_an_implementation_of_neural_voice/,FlyingQuokka,1528020300,"I wanted to dive into GANs and found a really interesting paper: Arik et al. Is there an implementation of this model, maybe in TensorFlow/PyTorch?",9,40
126,2018-6-3,2018,6,3,19,8o7oq1,[P] HyperParameter Tuning Using Deeplearning4j,https://www.reddit.com/r/MachineLearning/comments/8o7oq1/p_hyperparameter_tuning_using_deeplearning4j/,EndyJBC,1528021271,,0,0
127,2018-6-3,2018,6,3,19,8o7qj8,Build Spec for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8o7qj8/build_spec_for_deep_learning/,AgileSpecific,1528022089,[removed],0,1
128,2018-6-3,2018,6,3,20,8o7yjw,,https://www.reddit.com/r/MachineLearning/comments/8o7yjw//,Woodworking94,1528025476,,0,1
129,2018-6-3,2018,6,3,20,8o80mm,[Complex Networks] How to compute the Planar Maximally Filtered Graph (PMFG),https://www.reddit.com/r/MachineLearning/comments/8o80mm/complex_networks_how_to_compute_the_planar/,gau_mar,1528026322,,0,1
130,2018-6-3,2018,6,3,21,8o846n,[D] What is the best implementation of neural style transfer in Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/8o846n/d_what_is_the_best_implementation_of_neural_style/,Pafnouti,1528027646,"There are tons of neural style transfer papers that came out over the past years, so there are a lot of different repos implementing them.  
 
I found this one: https://github.com/cysmith/neural-style-tf but it's citing a paper from 2016, I assume there has been progress since.  

Which one do you think works the best? That would be for some HD pictures containing people.",32,83
131,2018-6-3,2018,6,3,21,8o8ahc,One maxim for the stone door of your Machine Learning Laboratory :-),https://www.reddit.com/r/MachineLearning/comments/8o8ahc/one_maxim_for_the_stone_door_of_your_machine/,ftarlao,1528029902,,0,1
132,2018-6-3,2018,6,3,22,8o8fij,[D] Does anyone have any advice/experience doing ML consulting?,https://www.reddit.com/r/MachineLearning/comments/8o8fij/d_does_anyone_have_any_adviceexperience_doing_ml/,jer_pint,1528031488,"Ive been doing ML for some time now (master's degree in Computer Vision plus 1 year work experience). I find that my skills are not so much at innovating in the field, rather looking at state of the art and applying that to industry-specific needs. Ive essentially been doing consulting work up until now (drafting and showcasing proof of concepts to clients), however I've been doing it for a company as their full-time employee. I want to start doing this on my own dime.

Has anyone gone through a similar path? Part of me feels like getting more industry experience could be good, but part of me is very attracted to the independence and freedom consulting could give.

Any advice is helpful. For what it's worth, I have some savings that I could live off of for a few months, and no other real financial obligations.",39,49
133,2018-6-3,2018,6,3,22,8o8g9b,AI Chat-Bot for Productivity,https://www.reddit.com/r/MachineLearning/comments/8o8g9b/ai_chatbot_for_productivity/,rockstar1024,1528031713,,0,1
134,2018-6-3,2018,6,3,22,8o8p1x,How to get started in the industry without a ML/AI degree?,https://www.reddit.com/r/MachineLearning/comments/8o8p1x/how_to_get_started_in_the_industry_without_a_mlai/,ilikerum2,1528034362,[removed],0,1
135,2018-6-3,2018,6,3,23,8o8ury,List of world-renowned ML experts,https://www.reddit.com/r/MachineLearning/comments/8o8ury/list_of_worldrenowned_ml_experts/,TJ1,1528036069,"Who are top experts in machine learning? I am specially interested in those in academia, so if I have a question I can send an email and ask them. Do you know any of them personally? Are they approachable and do they answer emails?",0,1
136,2018-6-3,2018,6,3,23,8o8ymf,Are VAE or GANs good for unsupervised vs semisupervised anomaly detection in practice?,https://www.reddit.com/r/MachineLearning/comments/8o8ymf/are_vae_or_gans_good_for_unsupervised_vs/,wtc01,1528037354,[removed],0,1
137,2018-6-4,2018,6,4,0,8o9300,Can you tell a robot apart from a human? Real-Life Turing Test,https://www.reddit.com/r/MachineLearning/comments/8o9300/can_you_tell_a_robot_apart_from_a_human_reallife/,ashtonsix,1528038592,,0,1
138,2018-6-4,2018,6,4,0,8o94fl,Everything about Data Mining,https://www.reddit.com/r/MachineLearning/comments/8o94fl/everything_about_data_mining/,stuartown,1528038899,,0,1
139,2018-6-4,2018,6,4,0,8o98nw,Getting Started. Any tips?,https://www.reddit.com/r/MachineLearning/comments/8o98nw/getting_started_any_tips/,syncogon,1528039887,[removed],0,1
140,2018-6-4,2018,6,4,0,8o9fh4,What are your opinions on Neuro Evolution?,https://www.reddit.com/r/MachineLearning/comments/8o9fh4/what_are_your_opinions_on_neuro_evolution/,pmkiller,1528041429,[removed],0,1
141,2018-6-4,2018,6,4,2,8oa3nf,"[D] Would there be any benefit in a neural network that can change the layout, amount, and connections of its ""neurons""?",https://www.reddit.com/r/MachineLearning/comments/8oa3nf/d_would_there_be_any_benefit_in_a_neural_network/,2Punx2Furious,1528046720,"I was thinking about how the brain works, and recently I've seen [this chart of types of neural networks](https://cdn-images-1.medium.com/max/2000/1*cuTSPlTq0a_327iTPJyD-Q.png) so I wondered if there would be an advantage in making a neural network that works like an actual brain, having the ""neurons"" be created and purged/removed dynamically, and have the connections between them change on the fly, as well as their values.

Is there any existing neural network that does that?",43,26
142,2018-6-4,2018,6,4,3,8oanxk,CHALLENGE ON PERCEPTUAL SUPER RESOLUTION,https://www.reddit.com/r/MachineLearning/comments/8oanxk/challenge_on_perceptual_super_resolution/,roimehrez,1528051408,[removed],0,1
143,2018-6-4,2018,6,4,4,8oas65,perceptual super resolution,https://www.reddit.com/r/MachineLearning/comments/8oas65/perceptual_super_resolution/,roimehrez,1528052411,[removed],0,1
144,2018-6-4,2018,6,4,5,8oblcm,1-year Machine Learning master's programs in DACH countries?,https://www.reddit.com/r/MachineLearning/comments/8oblcm/1year_machine_learning_masters_programs_in_dach/,kirschblueten,1528059103,[removed],1,1
145,2018-6-4,2018,6,4,7,8oc4pu,Text Recogntion for UI Screenshots?,https://www.reddit.com/r/MachineLearning/comments/8oc4pu/text_recogntion_for_ui_screenshots/,stevenschmatz,1528063683,[removed],0,1
146,2018-6-4,2018,6,4,7,8occ6q,[N] Pushing the boundaries of human-computer interaction with neural interfaces,https://www.reddit.com/r/MachineLearning/comments/8occ6q/n_pushing_the_boundaries_of_humancomputer/,rtk25,1528065539,,16,96
147,2018-6-4,2018,6,4,8,8ocp47,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8ocp47/machine_learning/,viraldocks,1528068681,,0,1
148,2018-6-4,2018,6,4,9,8od4lb,Machine learning stream! (Programming a adversarial neural network in processing),https://www.reddit.com/r/MachineLearning/comments/8od4lb/machine_learning_stream_programming_a_adversarial/,Eyeballdude,1528072640,,0,1
149,2018-6-4,2018,6,4,11,8odtnt,[D] Looking for ideas to read gauge meter values,https://www.reddit.com/r/MachineLearning/comments/8odtnt/d_looking_for_ideas_to_read_gauge_meter_values/,artemwaleev,1528079220,"I want to read gauge meter values\( manometers, pressure meters and so on\) from images, and can't achieve good results.

My idea is to try find landmarks via CNN for start, end of scale, center of gauge and pointer landmarks, and try calculate percentage of gauge at least.

The error in this approach is smaller then trying to train CNN to predict raw percentage.

But I still don't know how to read actual value, maybe try to cut and recognize end scale area and then multiply...

Can someone suggest any different better ideas to accomplish this task?

https://i.redd.it/rj0fabky8w111.jpg",4,2
150,2018-6-4,2018,6,4,11,8odugs,online multiplayer deathmatch machine learning project? How hard is this?,https://www.reddit.com/r/MachineLearning/comments/8odugs/online_multiplayer_deathmatch_machine_learning/,python_noob_001,1528079442,[removed],0,1
151,2018-6-4,2018,6,4,11,8oe14s,"Started up a research blog for the random ideas I had, critiques would be great!",https://www.reddit.com/r/MachineLearning/comments/8oe14s/started_up_a_research_blog_for_the_random_ideas_i/,ACTBRUH,1528081168,[removed],0,1
152,2018-6-4,2018,6,4,12,8oe402,"[D] Started up a research blog for the random ideas I had, critiques would be great!",https://www.reddit.com/r/MachineLearning/comments/8oe402/d_started_up_a_research_blog_for_the_random_ideas/,ACTBRUH,1528081902,"Hey guys! I've been wanting to start a research blog for awhile now, but never really felt confident enough in my research ability (I'm almost entirely self-taught and have only been studying this for 1.5 years). Decided that the worst that can happen is that nobody reads it, so I spent the last week digging up an idea I had 6~ months back and turning it into a post!

Specifically, this post is about an idea I had for weakly-supervised image segmentation, which uses conditional thresholds derived from attention maps to segment out the object of interest. While there are some obvious flaws with the idea (can't segment out multiple objects, though I have an idea on how to fix that), since I don't have any intentions to publish it, I thought it'd be cool to write about it! Let me know what you think, I'm always looking to get better at writing:

https://scientificattempts.wordpress.com/2018/06/03/conditionally-thresholded-cnns-for-weakly-supervised-image-segmentation/

As a side note, this post doesn't include results for applicable datasets (like COCO), which'll come in the next post, though I do show a snapshot of its performance on a toy dataset like CIFAR-10.",15,41
153,2018-6-4,2018,6,4,12,8oe63j,"AI researchers at CMU are halting work on human-like machines b/c it still contains ""no magic.""",https://www.reddit.com/r/MachineLearning/comments/8oe63j/ai_researchers_at_cmu_are_halting_work_on/,taewoo,1528082498,,0,1
154,2018-6-4,2018,6,4,12,8oe6jn,Explanation of Posterior and Prior Distributions?,https://www.reddit.com/r/MachineLearning/comments/8oe6jn/explanation_of_posterior_and_prior_distributions/,Koalchemy,1528082626,[removed],0,1
155,2018-6-4,2018,6,4,12,8oed5l,My ct st thu lc cm tay RC 25 hot ng vi cng sut ln ti 1600W/1700W em n hiu sut lm vic nhanh chng v n nh,https://www.reddit.com/r/MachineLearning/comments/8oed5l/my_ct_st_thu_lc_cm_tay_rc_25_hot_ng_vi/,HangNguyen1111,1528084506,,1,1
156,2018-6-4,2018,6,4,13,8oefsw,"My o  m nng sn Wile 55 c kh nng o, kim tra 16 loi ht khc nhau",https://www.reddit.com/r/MachineLearning/comments/8oefsw/my_o__m_nng_sn_wile_55_c_kh_nng_o_kim/,HangNguyen1111,1528085287,,1,1
157,2018-6-4,2018,6,4,13,8oejgd,My nghin vt ngh lin hon NG-300 hot ng mnh m cho nng sut 150  300 kg/gi (20 kg / 1 m),https://www.reddit.com/r/MachineLearning/comments/8oejgd/my_nghin_vt_ngh_lin_hon_ng300_hot_ng/,HangNguyen1111,1528086360,,1,1
158,2018-6-4,2018,6,4,13,8oenf2,Advice on machine learning/GA,https://www.reddit.com/r/MachineLearning/comments/8oenf2/advice_on_machine_learningga/,Louis_F,1528087531,[removed],0,1
159,2018-6-4,2018,6,4,13,8oepi3,[D] Advice on machine learning/genetic algorithms,https://www.reddit.com/r/MachineLearning/comments/8oepi3/d_advice_on_machine_learninggenetic_algorithms/,Louis_F,1528088190,"I'm not new to programming \(4/5 years\), but I am new to machine learning/genetic algorithms.

I do not just want to learn how to program it but also in depth about how the algorithms work and how to correctly implement them, my very end goal being able to create a neural net that could teach itself to play\-for example\- Mario or something like that.

I am wondering if there are any great online resources or books that I could buy/view that would be a good start and get me going in this area, or any personal experience.

Thanks for any help.",14,7
160,2018-6-4,2018,6,4,15,8of66q,"n dit cn trng Navilight NP-2015 hot ng vi cng sut 36W, s dng li in  dit cn trng",https://www.reddit.com/r/MachineLearning/comments/8of66q/n_dit_cn_trng_navilight_np2015_hot_ng_vi/,HangNguyen1111,1528093759,,1,1
161,2018-6-4,2018,6,4,16,8offz9,NVIDIA Announces Jetson Xavier with 30 TOPS DL Performance,https://www.reddit.com/r/MachineLearning/comments/8offz9/nvidia_announces_jetson_xavier_with_30_tops_dl/,nanobot_1000,1528097341,,0,1
162,2018-6-4,2018,6,4,16,8ofgoy,Encoder returning same states for every input Keras seq2seq,https://www.reddit.com/r/MachineLearning/comments/8ofgoy/encoder_returning_same_states_for_every_input/,cronoz30,1528097603,[removed],0,1
163,2018-6-4,2018,6,4,16,8ofh1q,[R] Do CIFAR-10 Classifiers Generalize to CIFAR-10?,https://www.reddit.com/r/MachineLearning/comments/8ofh1q/r_do_cifar10_classifiers_generalize_to_cifar10/,HigherTopoi,1528097732,,19,143
164,2018-6-4,2018,6,4,17,8ofq0y,[D] Hidden Markov Model explained,https://www.reddit.com/r/MachineLearning/comments/8ofq0y/d_hidden_markov_model_explained/,RubioRick,1528101359,I'm looking for a intuitive explanation resource for Hidden Markov Models. Does anyone got any hint ?,6,36
165,2018-6-4,2018,6,4,17,8ofqz2,Build your perceptron from scratch,https://www.reddit.com/r/MachineLearning/comments/8ofqz2/build_your_perceptron_from_scratch/,smakosh,1528101739,,0,1
166,2018-6-4,2018,6,4,18,8og043,The Increasing Role of Natural Language Processing and Machine Learning in Financial Content Curation,https://www.reddit.com/r/MachineLearning/comments/8og043/the_increasing_role_of_natural_language/,mr_j_b,1528105231,,0,1
167,2018-6-4,2018,6,4,19,8og40i,New edition of MLMAG,https://www.reddit.com/r/MachineLearning/comments/8og40i/new_edition_of_mlmag/,zofia_mlmag_co,1528106695,[removed],0,1
168,2018-6-4,2018,6,4,19,8og5uy,[D] An example use of mixing manual and automatic differentiationWho needs loss functions?,https://www.reddit.com/r/MachineLearning/comments/8og5uy/d_an_example_use_of_mixing_manual_and_automatic/,grey--area,1528107346,,6,16
169,2018-6-4,2018,6,4,19,8ogbkr,Automatic Peanut Frying Processing Line,https://www.reddit.com/r/MachineLearning/comments/8ogbkr/automatic_peanut_frying_processing_line/,lgsherry,1528109376,,1,1
170,2018-6-4,2018,6,4,20,8oge50,WORKING OF CNC MACHINE SHAPING IN WOOD,https://www.reddit.com/r/MachineLearning/comments/8oge50/working_of_cnc_machine_shaping_in_wood/,Woodworking94,1528110216,,0,1
171,2018-6-4,2018,6,4,20,8ogj1e,Inverting Supervised Representations with Autoregressive Neural Density Models,https://www.reddit.com/r/MachineLearning/comments/8ogj1e/inverting_supervised_representations_with/,ctcn,1528111791,,1,5
172,2018-6-4,2018,6,4,20,8ogjks,[D] Which adversarial attacks (still) work on commercial products,https://www.reddit.com/r/MachineLearning/comments/8ogjks/d_which_adversarial_attacks_still_work_on/,harvey_slash,1528111960,"There are several research papers that show how attacks can be made on popular trained models to make it missclassify, e.g.: 

The commercial products that I have tested are: 

clarifai vision api , google vision api &amp; microsoft vision api 

1\) generating noise such that the probability of it being in 1 class is very high. This method failed with all 3 

2\) Adding noise to some  image such that this added image is of a different class. This method also failed. 

3\) the famous adversarial patch. The toaster patch that was made failed to make any of the above services missclassify unless the patch's size was greater than the original object. 

It looks like adding small adversarial noise is almost trivial to remove by just using jpeg compression \(even with high quality values like 95\). 

Are there any ways that actually work with such black box commercial products?Genetic algorithms are almost impossible because of the rate limit and huge IO time \(correct me if I am wrong about this\). 

 It would be great if somebody posted adversarial noise that can be tested to fail with the aforementioned services. ",2,2
173,2018-6-4,2018,6,4,20,8ogn8r,A Gentle Introduction to Estimation Statistics for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8ogn8r/a_gentle_introduction_to_estimation_statistics/,dearpetra,1528113070,,0,1
174,2018-6-4,2018,6,4,21,8ogs3e,[R] Best (and Free!!) Resources to understand Nuts and Bolts of Deep learning,https://www.reddit.com/r/MachineLearning/comments/8ogs3e/r_best_and_free_resources_to_understand_nuts_and/,janemoz,1528114418,,0,1
175,2018-6-4,2018,6,4,21,8ogx34,[D] A Brief Rant On How (NOT) To Analyse Gendered Behavioural Data...,https://www.reddit.com/r/MachineLearning/comments/8ogx34/d_a_brief_rant_on_how_not_to_analyse_gendered/,AlanZucconi,1528115805,,18,0
176,2018-6-4,2018,6,4,21,8oh0pu,[N] My ML classifier suggests Melania Trump isnt the likely author of her May 30th tweet after 20 days off the grid.,https://www.reddit.com/r/MachineLearning/comments/8oh0pu/n_my_ml_classifier_suggests_melania_trump_isnt/,didtrumptweetit,1528116767,,7,0
177,2018-6-4,2018,6,4,22,8ohew0,linselect: a package for fast feature selection in python,https://www.reddit.com/r/MachineLearning/comments/8ohew0/linselect_a_package_for_fast_feature_selection_in/,efavdb,1528120303,,2,5
178,2018-6-4,2018,6,4,23,8ohneo,Inferring Human Traits From Facebook Statuses,https://www.reddit.com/r/MachineLearning/comments/8ohneo/inferring_human_traits_from_facebook_statuses/,ML-drew,1528122242,,0,1
179,2018-6-4,2018,6,4,23,8ohpzu,[R] State of the art on Fine-grained Image Recognition (FGVC),https://www.reddit.com/r/MachineLearning/comments/8ohpzu/r_state_of_the_art_on_finegrained_image/,MrLeylo,1528122820,"Hello /r/MachineLearning! The goal of this thread is twofold, to share what I have found about FGVC state of the art and to take note of anyone who could correct me.

The challenge consists on classifying entities which differ in some small subtle local features contained in a big context (noisy for this classification task). There are some typical datasets for this task such as [CUB birds](http://www.vision.caltech.edu/visipedia/CUB-200.html) or [Stanford dogs](https://pdfs.semanticscholar.org/b5e3/beb791cc17cdaf131d5cca6ceb796226d832.pdf)

As far as I know, we could group the approaches for it between attention-driven and non-attention-driven.

For attention driven it could be interesting to read Fu et Al publications [RA-CNN](http://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf) and [MA-CNN](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf) (state of the art for attention-driven approaches, which basically learns features and groups them into multiple parts for further weighting and final classification). Kanth et Al propose a [more generic method](https://arxiv.org/pdf/1805.05389.pdf) which works for non-fine-grained image classification as well as for fine-grained (slightly lower result), while Cui proposes [an improvement](https://vision.cornell.edu/se3/wp-content/uploads/2018/03/FGVC_CVPR_2018.pdf). Finally, PAIRS is exposed as the non-attention-driven state of the art [approach](https://arxiv.org/pdf/1801.09057.pdf).

This is as far as I know. Feel free to correct me.

Furthermore, I use this thread to ask if anybody knows about some workshop/challenge where to apply it. I've been looking in typical conferences but I don't find any. Thank you in advanced!",1,11
180,2018-6-4,2018,6,4,23,8ohtsf,Here's how you can combine different ML-based forecasting techniques to get a 24-times faster prediction,https://www.reddit.com/r/MachineLearning/comments/8ohtsf/heres_how_you_can_combine_different_mlbased/,Victor_Stakh,1528123649,,0,1
181,2018-6-5,2018,6,5,0,8ohxby,[D] What are the best open source face recognition and search libraries?,https://www.reddit.com/r/MachineLearning/comments/8ohxby/d_what_are_the_best_open_source_face_recognition/,Coffenpaint,1528124428,"Hey!

I'm trying to make sense of the years of photos I have with friends. iOS has a feature that maps the faces of people in a photo and lets you search for other photos with a matching face.

Based on the libraries and implementations of algorithms, what would be the best way to remake this kind of feature?

I was thinking about using Amazon's Rekognition API and build our a ""collection"" of faces, but I feel like I could write this from existing open source software.

Any tips are appreciated!",2,1
182,2018-6-5,2018,6,5,0,8oi5l0,Literature on the use of trained ANNs in mathematical programming ?,https://www.reddit.com/r/MachineLearning/comments/8oi5l0/literature_on_the_use_of_trained_anns_in/,Catersu,1528126133,[removed],0,1
183,2018-6-5,2018,6,5,0,8oibj3,Chronicle of Big Data: A Technical Comedy,https://www.reddit.com/r/MachineLearning/comments/8oibj3/chronicle_of_big_data_a_technical_comedy/,srinath_perera,1528127332,,0,1
184,2018-6-5,2018,6,5,1,8oifrn,[P] counting bees on a rasp pi with a conv net,https://www.reddit.com/r/MachineLearning/comments/8oifrn/p_counting_bees_on_a_rasp_pi_with_a_conv_net/,Ksevio,1528128197,,20,205
185,2018-6-5,2018,6,5,1,8oighb,Can you suggest me the best model for prediction for the given data?,https://www.reddit.com/r/MachineLearning/comments/8oighb/can_you_suggest_me_the_best_model_for_prediction/,gokuafrica,1528128344,[removed],0,1
186,2018-6-5,2018,6,5,1,8oik0n,What is Kubeflow ? Machine Learning Meets Kubernetes,https://www.reddit.com/r/MachineLearning/comments/8oik0n/what_is_kubeflow_machine_learning_meets_kubernetes/,cpt_snowcrash,1528129023,,0,1
187,2018-6-5,2018,6,5,1,8oir7s,[P] Recurrent recommender systems (for Go),https://www.reddit.com/r/MachineLearning/comments/8oir7s/p_recurrent_recommender_systems_for_go/,voiruloo,1528130530,,0,5
188,2018-6-5,2018,6,5,2,8oj0aj,Machine learning to find optimal differential equations initial conditions,https://www.reddit.com/r/MachineLearning/comments/8oj0aj/machine_learning_to_find_optimal_differential/,firewall245,1528132368,"Hello, so for a problem we have been given, we have a system of 10 connected differential equations and a ""correct"" given output graph. We need to find the initial conditions that produce this correct given graph. 

Our cost function is the total difference of the expected vs the output graph. 

We have run into a wall though in trying to determine the machine learning algorithm to use, as its unclear what the changes in the initial conditions will cause in the total output. Anyone seen anything like this before?",0,1
189,2018-6-5,2018,6,5,3,8ojvji,"[P] How should I approach a binary classification task for time series (x,y positional data), using deep learning?",https://www.reddit.com/r/MachineLearning/comments/8ojvji/p_how_should_i_approach_a_binary_classification/,surf_book,1528138702,"So I have a sequence of positions on a 2D screen, representing where a participant is looking on a screen.

My current approach is to build rolling features (over the past 5 seconds) of the data, which look like this: 
{variance of position, average speed, variance of speed, time spent in fixations, variance of fixations}

(fixations are just low-velocity sequences of the eye position).

There exists such a feature vector for every timestamp in the recording, and there is a label 0 or 1 associated. (stressed/not stressed).

This is a standard supervised learning task, which can be fed into an SVM giving ~70% accuracy. I'm struggling to understand what the input vectors look like for an LSTM/ other deep learning approach - is it still the same kind of feature vector one would use?
Or could I also try feeding in the instantaneous x,y coordinates and expect it to extract the relationships?

I'm happy with my traditional ML classifiers such as SVM, trying to apply deep learning to achieve this same task!",2,0
190,2018-6-5,2018,6,5,4,8ojxw3,CreateML,https://www.reddit.com/r/MachineLearning/comments/8ojxw3/createml/,Faendol,1528139182,What does apple's new Create ML actually mean for machine learning?,0,1
191,2018-6-5,2018,6,5,4,8ok13t,[P] Magnitude: a python package for quickly loading/using vector embeddings,https://www.reddit.com/r/MachineLearning/comments/8ok13t/p_magnitude_a_python_package_for_quickly/,acsands13,1528139854,,7,57
192,2018-6-5,2018,6,5,4,8ok6j7,Lessons Learned from Debugging Data Problems in Computer Vision using NBA Data,https://www.reddit.com/r/MachineLearning/comments/8ok6j7/lessons_learned_from_debugging_data_problems_in/,PrinceJimmy26311,1528140923,,0,2
193,2018-6-5,2018,6,5,4,8ok7az,Vanilla RNN better than LSTM for trajectory prediction?,https://www.reddit.com/r/MachineLearning/comments/8ok7az/vanilla_rnn_better_than_lstm_for_trajectory/,hundley10,1528141073,[removed],0,1
194,2018-6-5,2018,6,5,4,8ok7yf,Machine Learning for Ecological Science &amp; Ecosystem Management - Thomas G. Dietterich [D],https://www.reddit.com/r/MachineLearning/comments/8ok7yf/machine_learning_for_ecological_science_ecosystem/,goolulusaurs,1528141199,,0,19
195,2018-6-5,2018,6,5,5,8okemp,Not sure whether I should put ML programming assignments up on github to show recruiters?,https://www.reddit.com/r/MachineLearning/comments/8okemp/not_sure_whether_i_should_put_ml_programming/,leviathan2142,1528142538,[removed],0,1
196,2018-6-5,2018,6,5,6,8ol0hv,Machine learning Project,https://www.reddit.com/r/MachineLearning/comments/8ol0hv/machine_learning_project/,junaidwahid,1528146902,[removed],0,1
197,2018-6-5,2018,6,5,6,8olaki,[R] Improving Deep Learning Performance with AutoAugment,https://www.reddit.com/r/MachineLearning/comments/8olaki/r_improving_deep_learning_performance_with/,wei_jok,1528149037,,24,134
198,2018-6-5,2018,6,5,6,8olbim,ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models,https://www.reddit.com/r/MachineLearning/comments/8olbim/activis_visual_exploration_of_industryscale_deep/,jempt0,1528149233,[removed],0,1
199,2018-6-5,2018,6,5,6,8olby8,Looking For Machine Learning for Social Good,https://www.reddit.com/r/MachineLearning/comments/8olby8/looking_for_machine_learning_for_social_good/,blanketNTea,1528149336,[removed],0,1
200,2018-6-5,2018,6,5,9,8omk9f,LSTM vs vanilla RNN for trajectory prediction?,https://www.reddit.com/r/MachineLearning/comments/8omk9f/lstm_vs_vanilla_rnn_for_trajectory_prediction/,hundley10,1528159709,[removed],0,1
201,2018-6-5,2018,6,5,9,8ommkl,[D] LSTM vs vanilla RNN for trajectory prediction?,https://www.reddit.com/r/MachineLearning/comments/8ommkl/d_lstm_vs_vanilla_rnn_for_trajectory_prediction/,hundley10,1528160246,"I'm trying to predict the trajectory of a bullet flying through air. For simplicity let's say the input parameters are velocity, mass and air density. Using a recurrent net, the new position and velocity of the bullet are computed every millisecond.

LSTMs are preferred over vanilla RNNs in almost every application I've seen, for obvious reasons. However, is trajectory prediction a case where an RNN might actually perform better than (or at least equal to) an LSTM? For each time step, the bullet's new position relies only on the input data and the position+velocity immediately preceding it... so is long-term memory even beneficial here? Or is it just a waste of resources?",5,0
202,2018-6-5,2018,6,5,9,8omn0u,[D] What is your setup for ML?,https://www.reddit.com/r/MachineLearning/comments/8omn0u/d_what_is_your_setup_for_ml/,TheJCR,1528160357,"1. Desktop or laptop? What model?


2. GPU?



3. Operating System?



4. Programming language?



5. Framework?




6. What kind of work/research do you do?
",77,101
203,2018-6-5,2018,6,5,12,8onokf,What is the best way to find and visualize stock correlation using python+Pandas+[Any other useful library]?,https://www.reddit.com/r/MachineLearning/comments/8onokf/what_is_the_best_way_to_find_and_visualize_stock/,ritabratamaiti,1528170018,[removed],0,1
204,2018-6-5,2018,6,5,12,8onrfr,What are proceedings and why are they published into books?,https://www.reddit.com/r/MachineLearning/comments/8onrfr/what_are_proceedings_and_why_are_they_published/,asian_merchant,1528170837,"I was browsing through some books in my uni's library and I saw a whole section of red books titled ""Proceedings for xxx conference year"". ",0,1
205,2018-6-5,2018,6,5,13,8onvxg,Comparing documents using neural network (or machine learning),https://www.reddit.com/r/MachineLearning/comments/8onvxg/comparing_documents_using_neural_network_or/,cuonglu,1528172106,[removed],0,1
206,2018-6-5,2018,6,5,13,8onxdw,Machine Learning Applications and its Uses In numerous Industries.,https://www.reddit.com/r/MachineLearning/comments/8onxdw/machine_learning_applications_and_its_uses_in/,VickeryChris10,1528172514,,0,1
207,2018-6-5,2018,6,5,13,8oo2fe,Which math skills are necesary for machine learning? I keep hearing probability and statistics but then other people claims its linear algebra and calculus,https://www.reddit.com/r/MachineLearning/comments/8oo2fe/which_math_skills_are_necesary_for_machine/,Shadownet1012,1528174042,[removed],0,1
208,2018-6-5,2018,6,5,14,8ooalu,DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,https://www.reddit.com/r/MachineLearning/comments/8ooalu/dialogwae_multimodal_response_generation_with/,RingoCatKeeper,1528176537,[removed],0,1
209,2018-6-5,2018,6,5,14,8oof3j,How to collect data for a market(food) forecasting ?,https://www.reddit.com/r/MachineLearning/comments/8oof3j/how_to_collect_data_for_a_marketfood_forecasting/,zorroisreal,1528177964,[removed],0,1
210,2018-6-5,2018,6,5,15,8ooiu5,Industry Practitioners: where have machine learning algorithms created the most economic value?,https://www.reddit.com/r/MachineLearning/comments/8ooiu5/industry_practitioners_where_have_machine/,Dizastr,1528179153,[removed],0,1
211,2018-6-5,2018,6,5,15,8ook5h,[D] Clustering Functions,https://www.reddit.com/r/MachineLearning/comments/8ook5h/d_clustering_functions/,anonymousTestPoster,1528179597,"What would people here recommend as a method to cluster groups of similar functions.

Let's say I have some incoming finite dimensional vectors (like a function paramterised discretely over some grid), and I know before-hand that there there will primarily be a few ""kinds""/groups of these functions coming through. What is the best way to group these sorts of inputs. Some quick thoughts I have are:

1. Naively run a simple clustering algorithm on these incoming vectors which could be 100 dimensional large (I believe naive clustering should start be ineffective at this point because of the large dimensionality)

2. Parameterise these functions by a GP, then run some kind of distance measuring metric (like a KL divergence) defined over these function spaces and cluster based on these KL divergence numbers.

3 .... Anything else you guys / girls are aware of or suggest.

Thanks!",2,1
212,2018-6-5,2018,6,5,17,8op2fc,"[R] [1806.01261] Relational inductive biases, deep learning, and graph networks",https://www.reddit.com/r/MachineLearning/comments/8op2fc/r_180601261_relational_inductive_biases_deep/,evc123,1528185919,,13,68
213,2018-6-5,2018,6,5,17,8op7b0,How AI chatbots Can Help With Your Marketing Progress?,https://www.reddit.com/r/MachineLearning/comments/8op7b0/how_ai_chatbots_can_help_with_your_marketing/,StevensAmber,1528187855,,0,1
214,2018-6-5,2018,6,5,17,8opa8m,Inverse One hot encoding from 3D array to 2 D array,https://www.reddit.com/r/MachineLearning/comments/8opa8m/inverse_one_hot_encoding_from_3d_array_to_2_d/,emnajaoua,1528189009,[removed],0,1
215,2018-6-5,2018,6,5,18,8opd9g,Maximum weight matching (MWM) for a predefined number of nodes,https://www.reddit.com/r/MachineLearning/comments/8opd9g/maximum_weight_matching_mwm_for_a_predefined/,creiser,1528190147,"Dear community,

I am given a weighted graph and want to find a set of edges such that every node is only incident to one edge and such that the sum of the selected edge weights is maximized. As far as I know this problem is generally referred to as maximum weight matching and there exist fast approximations for it: [https://web.eecs.umich.edu/\~pettie/papers/ApproxMWM\-JACM.pdf](https://web.eecs.umich.edu/~pettie/papers/ApproxMWM-JACM.pdf)

However, for my application it would be better if only a certain ratio of nodes is paired. It's more important for my application that the nodes that get paired have a high weight between them. Leaving some nodes unpaired is no big problem.

Currently, I sort the weights between nodes in descending order and always select the edge with the highest weight until I have paired a certain number of nodes. Of course I ensure that pairs of nodes are mutually exclusive. This is only a 1/2 approximation to the original problem and it's probably even worse for the modified problem.

Could you please suggest an algorithm for this issue or tell me how this problem is called?",0,1
216,2018-6-5,2018,6,5,18,8opdvp,KDE and KNN,https://www.reddit.com/r/MachineLearning/comments/8opdvp/kde_and_knn/,RubioRick,1528190379,[removed],0,1
217,2018-6-5,2018,6,5,18,8ope1g,[D] KNN vs KDE,https://www.reddit.com/r/MachineLearning/comments/8ope1g/d_knn_vs_kde/,RubioRick,1528190432,"I'm new in instance based learning and I'm trying to understand the main differences between Kernel Density Estimation and K-NN. What I understood is that , in KNN (suppose for K = 1), it is not important the distance between the new instance and the one NN , the algorithm will predict the output value of the NN even if it is very very far.

While with KDE do I take into account the distance with the elements that are nearest to the instance ? If there are no points in that portion of space will it predict something or nothing ?",1,0
218,2018-6-5,2018,6,5,18,8opijc,detecting if field is data or not,https://www.reddit.com/r/MachineLearning/comments/8opijc/detecting_if_field_is_data_or_not/,yerro73,1528192040,[removed],0,1
219,2018-6-5,2018,6,5,18,8opje2,[R] Multi-Modal Methods: Image Captioning (From Translation to Attention),https://www.reddit.com/r/MachineLearning/comments/8opje2/r_multimodal_methods_image_captioning_from/,nianhao,1528192363,,0,13
220,2018-6-5,2018,6,5,18,8opjxw,YoloV3 loss function,https://www.reddit.com/r/MachineLearning/comments/8opjxw/yolov3_loss_function/,heisenburgzero,1528192581,[removed],0,1
221,2018-6-5,2018,6,5,19,8opkyq,[D] please share the best ML + Cybersecurity research you saw in 2018,https://www.reddit.com/r/MachineLearning/comments/8opkyq/d_please_share_the_best_ml_cybersecurity_research/,alexander_polyakov,1528192925,,0,0
222,2018-6-5,2018,6,5,19,8opn4c,[D] Realtime Neural Voice Style Transfer Feasibility and Implications,https://www.reddit.com/r/MachineLearning/comments/8opn4c/d_realtime_neural_voice_style_transfer/,victor_lustig,1528193606,"Hey everyone,  


I'm currently trying to figure out under which constraints voice style transfer similar to this project is currently feasible in real time: [https://www.reddit.com/r/MachineLearning/comments/7a0wcv/](https://www.reddit.com/r/MachineLearning/comments/7a0wcv/)

If there is a good chance of success my project would be to develop a speech enhancement device \(SED\) for my brother, one of who's vocal cords has recently become paralyzed for some unknown reason. He is still able to talk, but of course it is more quiet, sounds coarse and takes more effort. Whenever he wants to shout at someone, he just has a friend shout it for him :D , so the need for a SED is not an absolute necessity but more like a ""nice to have"" kind of thing. I happen to have about 30 min of high quality audio recordings of him with his healthy voice, from when he made a small audio book for his girlfriend, that could be used as training data for the speech synthesis part. The spoken language is German. I have a couple of questions and assumptions, that I'd love to get feedback on by some of the more experienced people here:

* For the speech recognition part: Software that takes speech and extracts phonemes from it or other features such as vocoder parameters or Mel Cepstral Coefficients already exists, and hopefully would not need to be trained on every single new speaker?
* For the synthesis / enhancement part: It seems that only just very recently it becomes possible to make high quality speech synthesis run in real time on personal computers, let alone on mobile devices. Deep Voice looks interesting, since it claims to offer a tunable trade\-off between synthesis speed and audio quality. Also 30 min of training data seems to be at the bottom end of what is needed for creating a quality neural speech synthesizer?

When thinking about the implications of having a realtime voice style transfer device, I quickly realized that they'd be quite huge. Not only could it be used for deep fakes / identity theft kind of scenarios, but also for a great amount of useful applications such as audio restoration and eliminating even the worst kind of noises by basically re\-synthesizing the speech from scratch, while maintaining it's original melody and rhythm. Let me know what you think about that side of things as well!  


Cheers Victor",6,26
223,2018-6-5,2018,6,5,20,8opvsn,"[P] Introducing Spell - simple, remote GPU execution",https://www.reddit.com/r/MachineLearning/comments/8opvsn/p_introducing_spell_simple_remote_gpu_execution/,saksoz,1528196438,"Hi /r/machinelearning!

We're the authors of Spell, a tool for easily running ML/DL jobs remotely. As Deep Learning has grown we see engineers and researchers struggle to incorporate running on GPUs into their workflow. So we built Spell to be the easiest way to get code running elsewhere - like the bash '&amp;' operator but for remote machines. 

We'd love for you to try it out and give us your feedback! [Sign up](https://web.spell.run/waitlist) for an account and, for a limited time, get $300 in credits for GPU time. There's a waitlist, but we'll be approving accounts quickly

 Here are some of the features we really wanted and built into Spell:

* We don't want you to have to modify your code for it to run remotely. Particularly so it's easy to clone something off github and run it with one command

* Waiting for data to upload/move is one of the biggest time costs. So we built a single remote filesystem so you only need to upload data once. It's also a simple interface that everyone already understands
* Tools should be highly efficient and reliable. Machine learning needs more tools that are sturdy enough to use everyday and build whole pipelines around. So we spent a lot of time making sure our infrastructure is solid

There's plenty of [documentation](https://www.spell.run/docs), including a 30 second [quick start](https://www.spell.run/docs/quickstart/) and [guides](https://www.spell.run/docs/guides/) for running some common models. We also wrote a series of [medium posts](https://medium.com/@spellrun) where we reproduce as much of the work presented at ICLR as possible with a few commands.

Thanks for reading. Questions/feedback welcome!",8,10
224,2018-6-5,2018,6,5,20,8oq0q1,[R] Deep Reinforcement Learning to solve mainstream Machine Learning tasks,https://www.reddit.com/r/MachineLearning/comments/8oq0q1/r_deep_reinforcement_learning_to_solve_mainstream/,ashz8888,1528197903,"One of the reasons, Capsule Net was invented was to overcome one of the problems with CNN, related to Pooling operation that throws away too much useful information. CapsNets solve this issue by introducing EM based routing, however they still employ convolutional layer as the primary layer, which naively scans the entire image. As an another alternative, I thought of using an attention based scanning with deep reinforcement learning and recurrent layers, which can give image recognition a human like vision. Later however, I found out that this idea has already been proposed by [V. Mnih](https://arxiv.org/abs/1406.6247) in 2014. Although a bit disappointed, I was thrilled to see the progress that have been made in this direction since then and how RL approaches are progressively making their way into mainstream machine learning tasks. The attention based scanning has been found suitable for fine\-grained visual classification tasks with [RA\-CNN](http://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf), [online tracking](http://openaccess.thecvf.com/content_ICCV_2017/papers/Supancic_Tracking_as_Online_ICCV_2017_paper.pdf), and also finding applications in tasks where parameters are non\-differentiable and therefore cannot be learned directly via back\-propagation, such as in [ReasoNet](https://arxiv.org/abs/1609.05284): Learning to Stop Reading. I believe with the increasing fusion of RL with DL, we will be able to tackle challenges ahead of deep learning, a lot sooner than expected. I would like to encourage others to share their perspective on the progress that's being made in this direction or about the challenges faced by these approaches.",0,27
225,2018-6-5,2018,6,5,20,8oq5zo,[D] Same dropout probability for every dropout layer?,https://www.reddit.com/r/MachineLearning/comments/8oq5zo/d_same_dropout_probability_for_every_dropout_layer/,iamstillsleeping,1528199483,"Hello everyone,

assuming that you have a deep neural network with several droput layers. Would you set the dropout probability for every layer to the same value? I've seen this in some papers and I assume it is because this mininizes the hyperparameters which need to be optimized. 

What do you think about this?",3,0
226,2018-6-5,2018,6,5,21,8oqbh4,Learn R Programming Course  100% OFF,https://www.reddit.com/r/MachineLearning/comments/8oqbh4/learn_r_programming_course_100_off/,samiali123,1528200981,,0,1
227,2018-6-5,2018,6,5,21,8oqbuq,[N] Link to Computer Vision News of June,https://www.reddit.com/r/MachineLearning/comments/8oqbuq/n_link_to_computer_vision_news_of_june/,Gletta,1528201084,"Here is the June 2018 issue of **Computer Vision News**, the magazine of the algorithm community published by **RSIP Vision**: 46 pages worth reading about Computer Vision, Image Processing, **Deep Learning** and Artificial Intelligence. Technical reviews of new papers and technologies \(**with codes!**\), including a new project with Tufts Medical Center!** Free subscriptio**n at page 46.

[HTML5 version \(recommended\)](https://www.rsipvision.com/ComputerVisionNews-2018June/)   

[PDF version](http://www.rsipvision.com/computer-vision-news-2018-june-pdf/)

Enjoy!",1,8
228,2018-6-5,2018,6,5,21,8oqc59,Doctor-palatable descriptions of hip fractures,https://www.reddit.com/r/MachineLearning/comments/8oqc59/doctorpalatable_descriptions_of_hip_fractures/,alito,1528201153,,0,2
229,2018-6-5,2018,6,5,21,8oqd7i,[R] Wasserstein Variational Inference,https://www.reddit.com/r/MachineLearning/comments/8oqd7i/r_wasserstein_variational_inference/,DanielleMolloy,1528201443,,3,48
230,2018-6-5,2018,6,5,22,8oqqex,Best Single Slot GPU for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8oqqex/best_single_slot_gpu_for_machine_learning/,dank4tao,1528204780,[removed],0,1
231,2018-6-5,2018,6,5,22,8oqrfy,[P] CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages,https://www.reddit.com/r/MachineLearning/comments/8oqrfy/p_css10_a_collection_of_single_speaker_speech/,longinglove,1528205042,,7,186
232,2018-6-5,2018,6,5,22,8oqvt4,Which Laptop To Buy For Study?,https://www.reddit.com/r/MachineLearning/comments/8oqvt4/which_laptop_to_buy_for_study/,PRDrum5red,1528206069,[removed],0,1
233,2018-6-5,2018,6,5,23,8or2ok,[D] Is there any research on using different training methods with the same data set?,https://www.reddit.com/r/MachineLearning/comments/8or2ok/d_is_there_any_research_on_using_different/,giltwist,1528207611,"My background is in human learning (Curriculum &amp; Instruction).  A big portion of the research we do is trying to understand how best to teach a given thing (e.g. integer multiplication).  However, the main limitation of my field is that it is typically unethical to directly test learning methods on children, so we are stuck with quasi-experimental and descriptive studies for the most part.   About the most direct we can get is [this investigation that shows repeated quizzing is more effective than just longer studying](https://www.ncbi.nlm.nih.gov/pubmed/16507066).

My specific question is this: Is there any research on using different training methods with the same data set in a machine learning environment?  As a follow-up, if this research exists, is it specific to one specific machine learning configuration or does it seem to be universal across multiple set-ups?  More broadly, is there any sense in using machine learning as a sort of mouse model for studying human learning?",4,5
234,2018-6-5,2018,6,5,23,8or5am,Gradient Descent in Python,https://www.reddit.com/r/MachineLearning/comments/8or5am/gradient_descent_in_python/,rohan_joseph93,1528208167,,4,0
235,2018-6-5,2018,6,5,23,8orf27,I need images of particles in a cloud chamber for a classification problem. Is there anywhere I could find these?,https://www.reddit.com/r/MachineLearning/comments/8orf27/i_need_images_of_particles_in_a_cloud_chamber_for/,seal2434,1528210233,[removed],0,1
236,2018-6-6,2018,6,6,0,8orj0a,Help with simple NN and genetic algorithm,https://www.reddit.com/r/MachineLearning/comments/8orj0a/help_with_simple_nn_and_genetic_algorithm/,negado,1528211066,[removed],0,1
237,2018-6-6,2018,6,6,0,8ormki,"Office Coffee Machine Rentals, Across Australia | Pure Bean",https://www.reddit.com/r/MachineLearning/comments/8ormki/office_coffee_machine_rentals_across_australia/,gladisllguiller,1528211795,,0,1
238,2018-6-6,2018,6,6,0,8oru2y,"[D] Applicability of YOLO (v2) to Crowded Scenes, and Alternatives",https://www.reddit.com/r/MachineLearning/comments/8oru2y/d_applicability_of_yolo_v2_to_crowded_scenes_and/,cow_co,1528213364,"Hey guys. I want to build a computer vision tool, which will be doing face detection. I was considering using YOLO v2 for the task, but under further investigation I figured that if there are multiple faces within the same grid cell, YOLO will only be able to make a single prediction. 

My question is: is this a correct understanding? If so, what alternatives exist for doing this sort of task (i.e. single-class object detection)? Perhaps Faster-RCNN? Or maybe there are ways to modify YOLO to allow it to handle these cases?",4,4
239,2018-6-6,2018,6,6,0,8orvma,[P] Code2Pix - A Deep Learning Compiler for Graphical User Interfaces,https://www.reddit.com/r/MachineLearning/comments/8orvma/p_code2pix_a_deep_learning_compiler_for_graphical/,zeroxok,1528213669,,5,33
240,2018-6-6,2018,6,6,0,8orwhv,OCR ML/Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8orwhv/ocr_mldeep_learning/,thampan,1528213853,[removed],0,1
241,2018-6-6,2018,6,6,1,8os4fl,[P] Beating Adam optimizer with Stochastic Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/8os4fl/p_beating_adam_optimizer_with_stochastic_gradient/,kmkolasinski,1528215472,,19,50
242,2018-6-6,2018,6,6,1,8os4wq,Beginner question,https://www.reddit.com/r/MachineLearning/comments/8os4wq/beginner_question/,TomsCardoso,1528215566,[removed],0,1
243,2018-6-6,2018,6,6,1,8os5f8,Help?,https://www.reddit.com/r/MachineLearning/comments/8os5f8/help/,Foulgaz3,1528215672,[removed],0,1
244,2018-6-6,2018,6,6,1,8osdtj,"[Discussion] Are we heading towards another AI ""dead end""/winter?",https://www.reddit.com/r/MachineLearning/comments/8osdtj/discussion_are_we_heading_towards_another_ai_dead/,EpicRaids,1528217354,"I see so many articles about the incredible performance and rapid growth of deep learning, CNNs, etcs. At the same time I see so much optimism/terror about the future of an AGI. Are these two things really that related to eachother? Neural Nets are absolutely amazing, but they do not at all seem promising as a path to AGI.

Is it possible that we'll reach the end of the deep learning S curve and then go back to profound AI pessimism? Admittedly even deep learning has the power to fundamentally change our society (Chinese police state), but it seems nowhere near the impact of an AGI.

I'd love to hear what everyone else thinks about this, I'm not as up to date in this field as I want to be.",14,0
245,2018-6-6,2018,6,6,1,8osh32,"[P] Pytorch simple developing implementation of ""Discriminative Regularization for Generative Models"" [1602.03220]",https://www.reddit.com/r/MachineLearning/comments/8osh32/p_pytorch_simple_developing_implementation_of/,alfo5123,1528217976,,0,0
246,2018-6-6,2018,6,6,2,8osicz,When the bubble bursts - John Langford,https://www.reddit.com/r/MachineLearning/comments/8osicz/when_the_bubble_bursts_john_langford/,thebackpropaganda,1528218216,,0,1
247,2018-6-6,2018,6,6,2,8osisc,[D] When the bubble bursts - John Langford,https://www.reddit.com/r/MachineLearning/comments/8osisc/d_when_the_bubble_bursts_john_langford/,thebackpropaganda,1528218292,,17,17
248,2018-6-6,2018,6,6,3,8otbja,Spam Detection in Social Media??,https://www.reddit.com/r/MachineLearning/comments/8otbja/spam_detection_in_social_media/,curiouscoder_cc,1528223928,"As In Summers I want to do a project related to identification of spammers,trollers on the OSM\(online social media\) platforms. so of anyone want to suggest me dataset related to this or any idea or paper related??",0,1
249,2018-6-6,2018,6,6,3,8otd32,Free Webinar - How to Get Into Data Science,https://www.reddit.com/r/MachineLearning/comments/8otd32/free_webinar_how_to_get_into_data_science/,randylaosat,1528224252,,1,1
250,2018-6-6,2018,6,6,4,8oti9j,I don't understand anything about unsupervised learning,https://www.reddit.com/r/MachineLearning/comments/8oti9j/i_dont_understand_anything_about_unsupervised/,Eildosa,1528225294,[removed],0,1
251,2018-6-6,2018,6,6,4,8otr72,[D] Goodfellow/Bengio/Courville's Deep Learning: Interpretation of Predictions; Perspective Misconception,https://www.reddit.com/r/MachineLearning/comments/8otr72/d_goodfellowbengiocourvilles_deep_learning/,krashennikov,1528227042,"I am reading currently the mentioned book and I noticed some formulations, which in my understanding are not correct formulations of what is actually happening. I will explain.

Mostly, the Authors are referring to learning the model parameters as estimating the true data generating probability distribution like in chapter 5.5, 5.7, 5.10 and others. For example in 5.10,  p_model(y|x) is used to represent that models learned probability distribution in the cost function, under the assumption of normal distribution of p_model. Like in 5.5.1 Example in the derivation from ML to MSE, they make the assumption of normal distribution and derive their result by just saying that the predicted value y of the model is simply the mean. In a specific case, it is surely reasonable but not as a general argument.

In fact, what all those models are doing is transforming input values to output values, they are functions, mappings from input values to output values, not input values to functions. The models themselves are the functions. The models are not probability distributions, because they are not producing probabilities by default. And here we come to chapter 6.2.2 to different Output Units, where the Authors kind of 'undermine' what I said. I try to reformulate what I mean more mathematical explicit and general applicable than in the mentioned chapter.

There are different Output Units and functions, which allow us to transform the output values of our models and make them behave like probabilities. Those transformations make sure, that the produced values correspond to the axioms of probability theory. They are not probabilities in a semantic way, they just behave like those, just another transformation to another kind of values we want to work with (a topological perspective on that transformation is much more intuitive).

We can simulate a discrete probability distribution by having multiple sigmoid neurons for each value, which we then normalize and say, that those values are probabilities of the appearing of that discrete value.

For continuous values, we just don't predict a distribution, we always predicting a value.

The Authors are making this thing easy from the start of the book, by using the predicted value and put it into a normal distribution, and saying, that the model is actually learning to try estimating a probability distribution - what is not the case in general. That is the classical thinking of classic old school statisticians, especially all that normal distribution assumption approach. But this is not what actually happens when a machine or deep learning model has learned its parameters, it's much easier than this. 

That's why I think, that starting with that assumption as default and then describing and deriving cost functions etc. is a misconception and in some cases a wrong formulation of what is actually happening, also bad in terms of intuition.

I was interested in writing this post not to declare that the authors are wrong. I think and hope, that there might be other perspectives, maybe a meta-perspective or mental model of what a model is actually doing that is better than mine so I can correct, maybe I am missing something, would like to enrich my position on this with other competent views. Let's discuss!",9,4
252,2018-6-6,2018,6,6,4,8ots49,[D] What models are you using for scene classification?,https://www.reddit.com/r/MachineLearning/comments/8ots49/d_what_models_are_you_using_for_scene/,kag29,1528227223,"Greetings,

I want to build a scene classification model to recognize images from the Places356 dataset. There has been so much activity regarding face and object classification models, but very little regarding scene classification. MIT released this model, pretrained on Places365, for education purposes: [https://github.com/CSAILVision/places365](https://github.com/CSAILVision/places365). However, the model is not very accurate \(top 1 accuracy is about 50&amp;#37;\). There are other, similar repositiories, such as [https://github.com/GKalliatakis/Keras\-VGG16\-places365](https://github.com/GKalliatakis/Keras-VGG16-places365) and [https://github.com/IBM/MAX\-Places365\-CNN](https://github.com/IBM/MAX-Places365-CNN) which are based on the same model as the one used in the MIT repository.

I've seen people having great results with NasNet for image classification in general, so I thought about taking a NasNet CNN trained on ImageNet and retraining it on Places365 to make it work for scene classification. This had better results that the models listed above, but the top 1 accuracy is only about 60&amp;#37;. So, what have you all done to get better accuracy out of your scene classification models?",0,5
253,2018-6-6,2018,6,6,4,8ots61,[R] [1806.00553] Deep Curiosity Search: Intra-Life Exploration Improves Performance on Challenging Deep Reinforcement Learning Problems,https://www.reddit.com/r/MachineLearning/comments/8ots61/r_180600553_deep_curiosity_search_intralife/,lordzapharos,1528227233,,0,6
254,2018-6-6,2018,6,6,4,8ottw7,FastAI PyTorch Serverless API (w/ AWS Lambda),https://www.reddit.com/r/MachineLearning/comments/8ottw7/fastai_pytorch_serverless_api_w_aws_lambda/,lossii,1528227585,,0,0
255,2018-6-6,2018,6,6,4,8otyq3,"Defend democracy with ML, win a trip to Colombia and an interview with the press",https://www.reddit.com/r/MachineLearning/comments/8otyq3/defend_democracy_with_ml_win_a_trip_to_colombia/,JeffreyBenjaminBrown,1528228544,[removed],0,1
256,2018-6-6,2018,6,6,5,8ou2b8,"Researchers use artificial intelligence to identify, count, describe wild animals",https://www.reddit.com/r/MachineLearning/comments/8ou2b8/researchers_use_artificial_intelligence_to/,hungry_for_knowledge,1528229237,,0,1
257,2018-6-6,2018,6,6,5,8ou63b,Using ML for invoice prediction?,https://www.reddit.com/r/MachineLearning/comments/8ou63b/using_ml_for_invoice_prediction/,corribview,1528229976,[removed],0,1
258,2018-6-6,2018,6,6,5,8ou7e7,[R] CVPR 2018 Open Access Papers,https://www.reddit.com/r/MachineLearning/comments/8ou7e7/r_cvpr_2018_open_access_papers/,terrorlucid,1528230234,,1,12
259,2018-6-6,2018,6,6,5,8oua55,The AI winter is well on its way,https://www.reddit.com/r/MachineLearning/comments/8oua55/the_ai_winter_is_well_on_its_way/,espergrafs,1528230766,,0,1
260,2018-6-6,2018,6,6,7,8ov1m9,[P] Classifier-agnostic saliency map extraction code release [1805.08249],https://www.reddit.com/r/MachineLearning/comments/8ov1m9/p_classifieragnostic_saliency_map_extraction_code/,kzolna,1528236369,"github: [https://github.com/kondiz/casme](https://github.com/kondiz/casme)

arxiv: [https://arxiv.org/abs/1805.08249](https://arxiv.org/abs/1805.08249)",1,17
261,2018-6-6,2018,6,6,7,8ov4k5,Credit assignment in DL and RL workshop at ICML'18,https://www.reddit.com/r/MachineLearning/comments/8ov4k5/credit_assignment_in_dl_and_rl_workshop_at_icml18/,ankeshanand,1528236997,,0,1
262,2018-6-6,2018,6,6,8,8ovqa4,What instrumental investments I need to do?,https://www.reddit.com/r/MachineLearning/comments/8ovqa4/what_instrumental_investments_i_need_to_do/,tpaduan,1528241691,[removed],0,1
263,2018-6-6,2018,6,6,8,8ovuyk,Machine Learning Team,https://www.reddit.com/r/MachineLearning/comments/8ovuyk/machine_learning_team/,Dimar_Arist,1528242751,[removed],0,1
264,2018-6-6,2018,6,6,9,8ovx48,What happens if zero input and non-zero hidden states are presented to LSTM/GRU?,https://www.reddit.com/r/MachineLearning/comments/8ovx48/what_happens_if_zero_input_and_nonzero_hidden/,jnhwkim,1528243240,,1,1
265,2018-6-6,2018,6,6,9,8ovy9i,What is frequency encoding in feature engineering?,https://www.reddit.com/r/MachineLearning/comments/8ovy9i/what_is_frequency_encoding_in_feature_engineering/,siddhupiddu,1528243541,[removed],0,1
266,2018-6-6,2018,6,6,9,8owbhk,[D] What do you think of AI ruled worlds in video games?,https://www.reddit.com/r/MachineLearning/comments/8owbhk/d_what_do_you_think_of_ai_ruled_worlds_in_video/,themaraudergirl,1528246587,"What is your opinion on this subject? Do you think the machines and AI in games are accurate to those in reality?

Just with the intent of giving example for games about AI\-ruled worlds, Im dropping these links:

Detroit: Become Human \- [https://www.youtube.com/watch?v=YtPmIBqRwQU](https://www.youtube.com/watch?v=YtPmIBqRwQU)

ManMade \- [https://www.youtube.com/watch?v=wX0YMY\-QkV0](https://www.youtube.com/watch?v=wX0YMY-QkV0)",4,0
267,2018-6-6,2018,6,6,10,8owj8p,[R] Backdrop: Stochastic Backpropagation,https://www.reddit.com/r/MachineLearning/comments/8owj8p/r_backdrop_stochastic_backpropagation/,xternalz,1528248486,,2,12
268,2018-6-6,2018,6,6,10,8owmb3,[R] Blog - Continuous Approximations of Logical Functions,https://www.reddit.com/r/MachineLearning/comments/8owmb3/r_blog_continuous_approximations_of_logical/,calebh,1528249167,,2,0
269,2018-6-6,2018,6,6,10,8owmyf,Introducing MLflow: an Open Source Machine Learning Platform - The Databricks Blog,https://www.reddit.com/r/MachineLearning/comments/8owmyf/introducing_mlflow_an_open_source_machine/,alan_du,1528249299,,0,1
270,2018-6-6,2018,6,6,10,8owq0b,"Panel discussion on algorithmic bias and transparency by Cynthia Dwork, John Langford, Jure Leskovec, Jeanna Matthews. Moderated by Ricardo Baeza-Yates.",https://www.reddit.com/r/MachineLearning/comments/8owq0b/panel_discussion_on_algorithmic_bias_and/,ahmaurya,1528249985,,0,0
271,2018-6-6,2018,6,6,11,8owvdb,[P] How to Perform Dimensionality Reduction on Very Large Datasets,https://www.reddit.com/r/MachineLearning/comments/8owvdb/p_how_to_perform_dimensionality_reduction_on_very/,TheCartDriver,1528251231,"I am currently working on a project where I need to perform dimensionality reduction, but I have quite a lot of features (40000 per example). SVD isn't going to help me here, because I would have to create a 40000x40000 matrix, which is too large for me to handle unfortunately. 

I have looked into the NIPALS algorithm, and have found some information about random projection, but I have no idea where to start. Does anyone have any references or tips that I could use in order to successfully perform dimensionality reduction for my program?

Any input would be greatly appreciated. Thanks for taking the time to read this.",1,1
272,2018-6-6,2018,6,6,11,8owxy8,[R][1806.01603] On layer-level control of DNN training and its impact on generalization,https://www.reddit.com/r/MachineLearning/comments/8owxy8/r180601603_on_layerlevel_control_of_dnn_training/,evc123,1528251860,,16,22
273,2018-6-6,2018,6,6,11,8ox4a3,[D] How to Perform Dimensionality Reduction on Very Large Datasets,https://www.reddit.com/r/MachineLearning/comments/8ox4a3/d_how_to_perform_dimensionality_reduction_on_very/,TheCartDriver,1528253444,"I am currently working on a project where I need to perform dimensionality reduction, but I have quite a lot of features (40000 per example). SVD isn't going to help me here, because I would have to create a 40000x40000 matrix, which is too large for me to handle unfortunately. 

I have looked into the NIPALS algorithm, and have found some information about random projection, but I have no idea where to start. Does anyone have any references or tips that I could use in order to successfully perform dimensionality reduction for my program?

Any input would be greatly appreciated. Thanks for taking the time to read this.",14,6
274,2018-6-6,2018,6,6,11,8ox5m0,LSTMs Exploit Linguistic Attributes of Data,https://www.reddit.com/r/MachineLearning/comments/8ox5m0/lstms_exploit_linguistic_attributes_of_data/,gofor_,1528253769,[removed],0,1
275,2018-6-6,2018,6,6,12,8oxcz8,How does max leaf nodes decides the accuracy in a Decision Tree?,https://www.reddit.com/r/MachineLearning/comments/8oxcz8/how_does_max_leaf_nodes_decides_the_accuracy_in_a/,ATGhoul1212,1528255692,[removed],0,1
276,2018-6-6,2018,6,6,12,8oxfgn,https://www.reddit.com/r/speechrecognition/comments/8oupkq/when_did_machine_learning_first_begin_to_be_used/,https://www.reddit.com/r/MachineLearning/comments/8oxfgn/httpswwwredditcomrspeechrecognitioncomments8oupkqw/,quixotemoon,1528256369,[removed],0,1
277,2018-6-6,2018,6,6,13,8oxkt1,Everything you need to know about LSTM/GRU/ Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8oxkt1/everything_you_need_to_know_about_lstmgru/,vector_machines,1528257832,,0,1
278,2018-6-6,2018,6,6,13,8oxqkg,when did machine learning first begin to be used in speech recognition?,https://www.reddit.com/r/MachineLearning/comments/8oxqkg/when_did_machine_learning_first_begin_to_be_used/,quixotemoon,1528259420,"## (repost from r/speechrecognition)

I'm trying to write about the influence of ML on speech recognition, and I see that Hidden Markov Models were very influential in speech recognition as well as machine learning almost from the start. So when speech recognition started to take off in the 80s was that through machine learning practices?",0,1
279,2018-6-6,2018,6,6,14,8oxz0t,[P] SOD - An Embedded Computer Vision and Machine Learning Library,https://www.reddit.com/r/MachineLearning/comments/8oxz0t/p_sod_an_embedded_computer_vision_and_machine/,histoire_guy,1528261742,,7,95
280,2018-6-6,2018,6,6,14,8oy2j7,"Microsoft Dynamics Entirely Delivers Integrated, end-to-end access to all the Business Applications.",https://www.reddit.com/r/MachineLearning/comments/8oy2j7/microsoft_dynamics_entirely_delivers_integrated/,AffluentGlobal,1528262789,,0,1
281,2018-6-6,2018,6,6,14,8oy6ka,[D] Should the weights of its synapses and their number be the only feature of neuron?,https://www.reddit.com/r/MachineLearning/comments/8oy6ka/d_should_the_weights_of_its_synapses_and_their/,abstractcontrol,1528264057,"I do not have any suggestions to alternative neuron design. The way neurons are represented in neural nets seems overly simplistic - surely there must be some other function they could be doing other than affine scaling and summing of the inputs. And I do not even mean for them to integrate past inputs like in differentiable plasticity. Or the weight sharing and simultaneous processing of multiple inputs like in convolutional nets. Rather, what insight for the most basic component is missing assuming it is even missing?

This question at this point is not even in search of a solution, but in search of a criticism of the current design. ANNs neurons are widely regarded as being biologically implausible, but I've yet to see a criticism from a functional perspective.

Since it is mid-2018, there might be some interesting theories in hiding. Either way, it would be interesting to periodically bring up this question.",2,6
282,2018-6-6,2018,6,6,14,8oy7an,Predict hit songs using daily activities,https://www.reddit.com/r/MachineLearning/comments/8oy7an/predict_hit_songs_using_daily_activities/,li207,1528264291,"I want to make a ml model that predicts songs which will be top hits in a period of time, say two weeks.

**By top hits I mean songs that rank top N by daily views.**

The data I have is daily views of each track in the past, i.e., a list of *(date, song_id, views)*

In this problem, I plan to use LSTM or general RNN to do the prediction. The reasoning behind is there might be a pattern of how views change every day before it becomes a top song.

I'm wondering
* if LSTM/RNN is the best model, or there are already some other better models discovered
* are there existing researches/papers/studies on similar questions that I can refer to?",0,1
283,2018-6-6,2018,6,6,15,8oyebs,Adopt Machine Learning and Personalize Marketing Game Big Time,https://www.reddit.com/r/MachineLearning/comments/8oyebs/adopt_machine_learning_and_personalize_marketing/,dexlabanalytics,1528266566,,0,1
284,2018-6-6,2018,6,6,15,8oyhec,[D] Machine-Human Conversation Capabilities,https://www.reddit.com/r/MachineLearning/comments/8oyhec/d_machinehuman_conversation_capabilities/,HummusHu,1528267620,"Yo, so.

I've been thinking for some time on the AIs we see in movies, specifically JARVIS and FRIDAY from the MCU, and they always seem to be able to synthesize their own speech, something real\-life chat bots cant do.

From the limited research I did, many chat bots these days are CNN trained on a static set of conversation. Therefore, the more conversation there are in a data set, the more capable that chat bot is, and that's how many people operate. An example of this would be Chatterbot on GitHub: [https://github.com/gunthercox/ChatterBot](https://github.com/gunthercox/ChatterBot). However, this still limits the CNN to operating within the training set and whatever the CNN's generalization comes up with. Many of these chatbots fail when people attempt to have more elaborate conversations with them. 

Now look at their sci\-fi counterparts. They can not only converse/take orders from humans, like real life chatbots, but also synthesize their own speech and thoughts. The most prominent example I can find is the conversation JARVIS and Ultron had when Ultron was just created, [https://www.youtube.com/watch?v=LO8SpOT3Thc](https://www.youtube.com/watch?v=LO8SpOT3Thc). I just find it improbable that JARVIS's conversation was purely a result of generalization over a static training set. 

If this all seems silly, I do apologize but I am relatively new to machine learning and I am interested in trying my hands at creating a real\-life JARVIS that is more human than previous attempts. Any pointers to research, code on GitHub, or just advice/suggestion in general about anything that is related to this would be greatly appreciated.

Thanks in advance!",3,1
285,2018-6-6,2018,6,6,15,8oyi0c,"[N] 20BN's Gesture Recognition Game Demo ""Word Rain"" at ICLR 2018",https://www.reddit.com/r/MachineLearning/comments/8oyi0c/n_20bns_gesture_recognition_game_demo_word_rain/,nahuak,1528267825,,1,8
286,2018-6-6,2018,6,6,15,8oyjgs,eSIM Market is estimated to grow at a CAGR of 31.0% between 2018 and 2023,https://www.reddit.com/r/MachineLearning/comments/8oyjgs/esim_market_is_estimated_to_grow_at_a_cagr_of_310/,robertemma27,1528268319,[removed],0,1
287,2018-6-6,2018,6,6,16,8oyor6,Andrew Ng's CS229 or Coursera course on Machine Learning for a beginner?,https://www.reddit.com/r/MachineLearning/comments/8oyor6/andrew_ngs_cs229_or_coursera_course_on_machine/,sithavi,1528270045,[removed],0,1
288,2018-6-6,2018,6,6,17,8oyujx,[R] Relational recurrent neural networks (DeepMind),https://www.reddit.com/r/MachineLearning/comments/8oyujx/r_relational_recurrent_neural_networks_deepmind/,baylearn,1528272090,,5,57
289,2018-6-6,2018,6,6,17,8oyxl0,Examples/papers to show DNN may not be the best way to solve,https://www.reddit.com/r/MachineLearning/comments/8oyxl0/examplespapers_to_show_dnn_may_not_be_the_best/,victorram,1528273250,[removed],0,1
290,2018-6-6,2018,6,6,18,8oz4pl,Word2Vec worse than BoW,https://www.reddit.com/r/MachineLearning/comments/8oz4pl/word2vec_worse_than_bow/,Seiteshyru,1528275957,[removed],0,1
291,2018-6-6,2018,6,6,18,8oz63r,14th European Workshop on Reinforcement Learning (EWRL'18),https://www.reddit.com/r/MachineLearning/comments/8oz63r/14th_european_workshop_on_reinforcement_learning/,mseurin,1528276483,[removed],0,1
292,2018-6-6,2018,6,6,18,8oz68q,Parameter Tuning with GridSearchCV,https://www.reddit.com/r/MachineLearning/comments/8oz68q/parameter_tuning_with_gridsearchcv/,imHarin,1528276537,,2,0
293,2018-6-6,2018,6,6,18,8ozbyj,"Backwards-engineering prediction formula, XGBoost Decision Trees",https://www.reddit.com/r/MachineLearning/comments/8ozbyj/backwardsengineering_prediction_formula_xgboost/,McBlitzGordon,1528278602,[removed],0,1
294,2018-6-6,2018,6,6,18,8ozce5,A step-by-step guide to solve 90% of NLP problems,https://www.reddit.com/r/MachineLearning/comments/8ozce5/a_stepbystep_guide_to_solve_90_of_nlp_problems/,HAL8990,1528278755,,0,1
295,2018-6-6,2018,6,6,18,8ozck1,Data Science Classes in Pune,https://www.reddit.com/r/MachineLearning/comments/8ozck1/data_science_classes_in_pune/,Technogeekspune,1528278812,,0,1
296,2018-6-6,2018,6,6,18,8ozdcl,Neural Network Tutorial - Simplified for you,https://www.reddit.com/r/MachineLearning/comments/8ozdcl/neural_network_tutorial_simplified_for_you/,pooja307,1528279097,,0,1
297,2018-6-6,2018,6,6,19,8ozg7o,Feature Extraction From Text,https://www.reddit.com/r/MachineLearning/comments/8ozg7o/feature_extraction_from_text/,imHarin,1528280030,,0,0
298,2018-6-6,2018,6,6,19,8ozh86,[R] Producing human-style explanations for AI decisions that doctors actually trust.,https://www.reddit.com/r/MachineLearning/comments/8ozh86/r_producing_humanstyle_explanations_for_ai/,drlukeor,1528280366,,26,138
299,2018-6-6,2018,6,6,19,8ozjo7,[N] How to say No to Data Science Projects?,https://www.reddit.com/r/MachineLearning/comments/8ozjo7/n_how_to_say_no_to_data_science_projects/,digitalson,1528281194,,0,1
300,2018-6-6,2018,6,6,19,8ozl7y,[R] Chaos Is needed to keep us smart with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8ozl7y/r_chaos_is_needed_to_keep_us_smart_with_machine/,friscotime,1528281705,,0,1
301,2018-6-6,2018,6,6,19,8ozltp,[R] Three techniques to improve machine learning model performance with imbalanced datasets,https://www.reddit.com/r/MachineLearning/comments/8ozltp/r_three_techniques_to_improve_machine_learning/,janemoz,1528281914,,0,1
302,2018-6-6,2018,6,6,19,8oznnu,Deep learning or machine Learning,https://www.reddit.com/r/MachineLearning/comments/8oznnu/deep_learning_or_machine_learning/,zyxabcdef,1528282522,[removed],0,1
303,2018-6-6,2018,6,6,20,8ozp7s,[R] [1805.07091] Tropical Geometry of Deep Neural Networks (functions ReLU can compute are exactly tropical rational),https://www.reddit.com/r/MachineLearning/comments/8ozp7s/r_180507091_tropical_geometry_of_deep_neural/,fixpoint,1528282974,,2,12
304,2018-6-6,2018,6,6,20,8ozphf,"Autoencoder, variational autoencoder, vector-quantised VAE, and categorical VAE illustrated on MNIST in a notebook (TensorFlow)",https://www.reddit.com/r/MachineLearning/comments/8ozphf/autoencoder_variational_autoencoder/,kamperh,1528283056,,0,18
305,2018-6-6,2018,6,6,20,8ozys3,"14th European Workshop on Reinforcement Learning, October 1-3 2018, Lille, France",https://www.reddit.com/r/MachineLearning/comments/8ozys3/14th_european_workshop_on_reinforcement_learning/,mseurin,1528285846,[removed],3,1
306,2018-6-6,2018,6,6,20,8ozzsr,Reddit Blocked Users Log/Dataset,https://www.reddit.com/r/MachineLearning/comments/8ozzsr/reddit_blocked_users_logdataset/,gyanesh_anand,1528286145,[removed],0,1
307,2018-6-6,2018,6,6,21,8p02fh,[R] Deep Convolutional Neural Networks as Models of the Visual System: Q&amp;A,https://www.reddit.com/r/MachineLearning/comments/8p02fh/r_deep_convolutional_neural_networks_as_models_of/,DanielleMolloy,1528286851,,0,12
308,2018-6-6,2018,6,6,21,8p03jn,Stanford Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8p03jn/stanford_deep_learning/,stonedfox8,1528287149,[removed],0,1
309,2018-6-6,2018,6,6,21,8p09c1,Perturbative Neural Networks (PNN),https://www.reddit.com/r/MachineLearning/comments/8p09c1/perturbative_neural_networks_pnn/,dezzion,1528288652,,0,1
310,2018-6-6,2018,6,6,21,8p0aot,How to bridge the gap between old-school industries and sucessful ML implementations?,https://www.reddit.com/r/MachineLearning/comments/8p0aot/how_to_bridge_the_gap_between_oldschool/,qingke,1528289011,[removed],0,1
311,2018-6-6,2018,6,6,21,8p0d89,Almond Slivered Machine | Almond Strip Cutting Machine,https://www.reddit.com/r/MachineLearning/comments/8p0d89/almond_slivered_machine_almond_strip_cutting/,lgsherry,1528289672,,1,1
312,2018-6-6,2018,6,6,21,8p0dky,Neural Network learns Data Distribution!,https://www.reddit.com/r/MachineLearning/comments/8p0dky/neural_network_learns_data_distribution/,olpadkar,1528289767,,0,1
313,2018-6-6,2018,6,6,21,8p0e7a,[Discussion] How to bridge the gap between old-school industries and sucessful ML implementations?,https://www.reddit.com/r/MachineLearning/comments/8p0e7a/discussion_how_to_bridge_the_gap_between/,qingke,1528289926,"Fellow Machine Learners,

during my learning of ML, I was introduced by my non-CS teacher to IBMs SPSS Tool, which includes several modelling possibilities, including some ML Models like Neural Networks or K-Means clustering or more. The tool provides a possibility of creating e.g. a NN with a simple drag-and-drop, and visualizing and assessing it quite easily. I was impressed by its interface, although I could see some limitations in the complexity of the Models used.
On the other hand, the company I work for (old-school automotive OEM in Germany) is struggling to build a platform to provide a ML environment (Hadoop, TensorFlow) where our newly hired data analysts can do their magic. However, in my humble opinion, I would say that IBM SPSS would suffice for almost all of the current use-cases we could have. 
And in here, Im able to follow some of the research that is spearheading this field. The focus of research is always to breakthrough, but currently even basic ML is not used by our company.

My question to you guys and for discussion is: 
-	Generally speaking, I feel like that the industry (not software or e-commerce companies, real industrial companies) could really benefit by simply using off-the-shelf tools like SPSS, instead of trying to crack a nut with a sledgehammer and implement state-of-the-art algorithms and models. What do you think about it? What is your experience between the gap of the industry and the research?


I might be too nave regarding SPSS, or even too pessimist about the usage of ML in the industry. Im learning and working only a few months on this topic and am open for new opinions.
",3,4
314,2018-6-6,2018,6,6,22,8p0p7x,Nanjing University Team Introduces Multi-layered Gradient Boosting Decision Trees,https://www.reddit.com/r/MachineLearning/comments/8p0p7x/nanjing_university_team_introduces_multilayered/,gwen0927,1528292516,,0,1
315,2018-6-6,2018,6,6,22,8p0pgw,[R] Nanjing University Team Introduces Multi-layered Gradient Boosting Decision Trees,https://www.reddit.com/r/MachineLearning/comments/8p0pgw/r_nanjing_university_team_introduces_multilayered/,gwen0927,1528292574,,0,1
316,2018-6-6,2018,6,6,22,8p0rce,[D] Machine learning explained with gifs: style transfer,https://www.reddit.com/r/MachineLearning/comments/8p0rce/d_machine_learning_explained_with_gifs_style/,Paletton,1528293017,,2,14
317,2018-6-6,2018,6,6,23,8p0via,New AMD Vega Open Source ML Ecosystem - No lines of Cuda code required.,https://www.reddit.com/r/MachineLearning/comments/8p0via/new_amd_vega_open_source_ml_ecosystem_no_lines_of/,linkuei-teaparty,1528293957,,0,1
318,2018-6-6,2018,6,6,23,8p0yi8,[D] PhD proposal help for computational neuroscience,https://www.reddit.com/r/MachineLearning/comments/8p0yi8/d_phd_proposal_help_for_computational_neuroscience/,DuraCat,1528294599,"Hi guys, I dont know if this is allowed here but Im currently writing a proposal to start a PhD in computational neuroscience, I was wondering if any of you guys know of any good resources for detailed information on this topic or if any of you have done anything in this area and would be willing to discuss it. Cheers!",19,0
319,2018-6-6,2018,6,6,23,8p131q,[R] FAVI: Amortized variational inference with forward KL divergence.,https://www.reddit.com/r/MachineLearning/comments/8p131q/r_favi_amortized_variational_inference_with/,LucaAmbrogioni,1528295571,,1,10
320,2018-6-6,2018,6,6,23,8p13e1,"[D] What are all the different specific ""tasks"" in deep learning (object detection, sentiment classification etc.)?",https://www.reddit.com/r/MachineLearning/comments/8p13e1/d_what_are_all_the_different_specific_tasks_in/,skepticforest,1528295646,"I'm trying to curate a list of all the different phrases I come across that describe the task (or objective, I'm not sure what's the most accurate word) while reading papers. I've made the following list and I'd really like to know what I am missing.

**Computer vision**

Face/object detection &amp; recognition, image recognition, semantic segmentation, scene labeling, scene parsing, pose estimation, inpainting, style transfer

**NLP**

Word embedding, NLU, NLG, textual entailment, POS tagging, sentiment analysis, text classification, text/machine comprehension, question answering, machine translation, summarization, speech recognition, dialogue systems, relationship extraction, named entity recognition

**Image+text**

Visual/concept grounding, visual reasoning, visual QA, caption generation, text-to-image synthesis

**Other**

End-to-end learning, structured prediction, multi-task learning, transfer learning, seq2seq learning, multi-class prediction, meta-learning, one/few-shot learning, knowledge distillation
",2,0
321,2018-6-6,2018,6,6,23,8p13gr,Dedicated to all those researchers in fear of being scooped :),https://www.reddit.com/r/MachineLearning/comments/8p13gr/dedicated_to_all_those_researchers_in_fear_of/,_gmark_,1528295659,,0,1
322,2018-6-6,2018,6,6,23,8p166q,Person identification with unlabeled data,https://www.reddit.com/r/MachineLearning/comments/8p166q/person_identification_with_unlabeled_data/,royfeng123,1528296254,[removed],0,1
323,2018-6-6,2018,6,6,23,8p169l,[D] Dedicated to all those researchers in fear of being scooped :),https://www.reddit.com/r/MachineLearning/comments/8p169l/d_dedicated_to_all_those_researchers_in_fear_of/,_gmark_,1528296269,,123,1160
324,2018-6-6,2018,6,6,23,8p17zp,[D] The 7 NLP Techniques Machine Learners Should Know,https://www.reddit.com/r/MachineLearning/comments/8p17zp/d_the_7_nlp_techniques_machine_learners_should/,jamesonatfritz,1528296631,,1,0
325,2018-6-7,2018,6,7,0,8p1f9j,[R] A Neural Network model with Bidirectional Whitening,https://www.reddit.com/r/MachineLearning/comments/8p1f9j/r_a_neural_network_model_with_bidirectional/,abstractcontrol,1528298101,,0,2
326,2018-6-7,2018,6,7,0,8p1ip2,Fine tuning with contrastive loss trouble,https://www.reddit.com/r/MachineLearning/comments/8p1ip2/fine_tuning_with_contrastive_loss_trouble/,terrrp,1528298803,[removed],0,1
327,2018-6-7,2018,6,7,0,8p1irr,[R] Review of Recent Facebook AI's paper on Music Translation.,https://www.reddit.com/r/MachineLearning/comments/8p1irr/r_review_of_recent_facebook_ais_paper_on_music/,jaleyhd,1528298822,,0,4
328,2018-6-7,2018,6,7,0,8p1o8d,[R] Playing Atari with Six Neurons,https://www.reddit.com/r/MachineLearning/comments/8p1o8d/r_playing_atari_with_six_neurons/,hardmaru,1528299951,,23,44
329,2018-6-7,2018,6,7,0,8p1r5f,"Simple Questions Thread June 06, 2018",https://www.reddit.com/r/MachineLearning/comments/8p1r5f/simple_questions_thread_june_06_2018/,AutoModerator,1528300535,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",0,1
330,2018-6-7,2018,6,7,1,8p1zpn,Deep cooling,https://www.reddit.com/r/MachineLearning/comments/8p1zpn/deep_cooling/,ale152,1528302183,,0,1
331,2018-6-7,2018,6,7,1,8p1zwx,"[R] Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects",https://www.reddit.com/r/MachineLearning/comments/8p1zwx/r_sequential_attend_infer_repeat_generative/,akosiorek,1528302222,,0,9
332,2018-6-7,2018,6,7,1,8p270u,Java Client for OpenAI Gym HTTP Server,https://www.reddit.com/r/MachineLearning/comments/8p270u/java_client_for_openai_gym_http_server/,I_am_an_researcher,1528303574,,3,3
333,2018-6-7,2018,6,7,1,8p28sz,How we flew a drone to Monitor Construction projects in Africa using deep learning,https://www.reddit.com/r/MachineLearning/comments/8p28sz/how_we_flew_a_drone_to_monitor_construction/,nanonets,1528303910,,0,1
334,2018-6-7,2018,6,7,2,8p2d9t,Code/Paper to Identify if a Certain Object Exists in a Set of Images?,https://www.reddit.com/r/MachineLearning/comments/8p2d9t/codepaper_to_identify_if_a_certain_object_exists/,SmallBirb,1528304754,[removed],0,1
335,2018-6-7,2018,6,7,2,8p2p41,[P] FloydHub workspaces - easiest cloud IDE for deep learning,https://www.reddit.com/r/MachineLearning/comments/8p2p41/p_floydhub_workspaces_easiest_cloud_ide_for_deep/,narenst,1528306998,,13,14
336,2018-6-7,2018,6,7,3,8p2xgh,What's up with Numenta?,https://www.reddit.com/r/MachineLearning/comments/8p2xgh/whats_up_with_numenta/,VentoAureoGoldenWind,1528308646,[removed],0,1
337,2018-6-7,2018,6,7,3,8p31u0,"Forget DeepFakes, Deep Video Portraits are way better (and worse)",https://www.reddit.com/r/MachineLearning/comments/8p31u0/forget_deepfakes_deep_video_portraits_are_way/,Gabriela014,1528309516,,0,1
338,2018-6-7,2018,6,7,4,8p3i8w,Machine/Deep learning ideas for markers detection,https://www.reddit.com/r/MachineLearning/comments/8p3i8w/machinedeep_learning_ideas_for_markers_detection/,jaouadros,1528312782,[removed],0,1
339,2018-6-7,2018,6,7,4,8p3phn,"June 21st, Coffee with Clusterone Webinar: Build a Learning Lexicon from Streaming Text",https://www.reddit.com/r/MachineLearning/comments/8p3phn/june_21st_coffee_with_clusterone_webinar_build_a/,AI_underscore,1528314238,[removed],0,1
340,2018-6-7,2018,6,7,4,8p3ptj,Aerodynamic optimisation of aeroracing car using ML [P],https://www.reddit.com/r/MachineLearning/comments/8p3ptj/aerodynamic_optimisation_of_aeroracing_car_using/,fischele70,1528314291,"Hello guys, 
as the title implies, I'm searching the best shape for an aeroracing car(Formula 1 in schools), and I thought ""why shouldn't I give a machine a try?"". 
The only three problems are:
1. I'm a total noob at programming machine learning. 
Where can I get good literature to support my development of this project (if it would even be viable)(i've taken a look at the sidebar)
2. Is it possible to make an algorithm use my CAD and CFD software Autodesk Fusion 360 and CFD 2019? 
The bigger problem is CAD, since it has to randomly modify only parts of the car that are legal to modify, the CFD part could be hardcoded.
3. Where do I get the computation power, memory and storage for such a huge project (for free/cheap)? The CFD simulation alone takes 4GB of memory per run and about 30-40 minutes on my PC. If I wanted do do 500 iterations, it would take a week or longer. I've heard that you can acess quantum computers via internet with 12-15 QBits, could this be a soloution? Would it (technically) be possible to take the computers of my school and distribute the task to a lot of PCs?

I'm not quite sure if it even was legal to use the file generated by the algorithm in the competition, but it would be interesting for sure how it would turn out.",5,5
341,2018-6-7,2018,6,7,5,8p3ype,[D] Data science Bootcamp?,https://www.reddit.com/r/MachineLearning/comments/8p3ype/d_data_science_bootcamp/,mosef18,1528316070,"hey guys I recently graduated (undergrad) with a major in statistics and quantitative modelling and a minor in mathematics, I want to get into the machine learning/ data science field and was wondering if going to a Data science Bootcamp is a good idea? (and if not any other suggestions would be appreciated) (also sorry about grammar and spelling)",1,1
342,2018-6-7,2018,6,7,5,8p45mu,[P]NAACL2018 notes,https://www.reddit.com/r/MachineLearning/comments/8p45mu/pnaacl2018_notes/,mallcolmTucker,1528317457,[removed],0,1
343,2018-6-7,2018,6,7,5,8p46xk,Over-sampling vs under-sampling: Which to use and why?,https://www.reddit.com/r/MachineLearning/comments/8p46xk/oversampling_vs_undersampling_which_to_use_and_why/,NaN_01,1528317726,[removed],0,1
344,2018-6-7,2018,6,7,6,8p4fph,[D] Depth First Learning Launch,https://www.reddit.com/r/MachineLearning/comments/8p4fph/d_depth_first_learning_launch/,suryabhupa,1528319561,,2,13
345,2018-6-7,2018,6,7,7,8p4y9k,"""[D]"" Topic Modelling - Short texts",https://www.reddit.com/r/MachineLearning/comments/8p4y9k/d_topic_modelling_short_texts/,nikhildevnani,1528323644,"I have a large collection of short texts and I'm trying to segregate these texts into topics (which are unknown).
What could be a good way to do this? 

I'm not sure if LDA is the right way to do this given the size of the texts is limited to a few lines (read 100-500 words).

Any suggestions would be helpful.",0,1
346,2018-6-7,2018,6,7,7,8p50xm,"""[D]"" Topic modeling for small texts",https://www.reddit.com/r/MachineLearning/comments/8p50xm/d_topic_modeling_for_small_texts/,ml_newbie_101,1528324260,"I'm relatively new to this field and I'm trying to find common topics/trends among a large collection of short texts (read 100-500 words), what would be the best way to do this given the size of documents is so small. I tried using LDA but couldn't achieve meaningful relationship within the topics. Please suggest any methods that you can think.",7,7
347,2018-6-7,2018,6,7,8,8p5ano,Get push notification when your ML finishes one epoch,https://www.reddit.com/r/MachineLearning/comments/8p5ano/get_push_notification_when_your_ml_finishes_one/,MaaDoTaa,1528326455,[removed],0,1
348,2018-6-7,2018,6,7,8,8p5dux,MILA Professional Masters requirements,https://www.reddit.com/r/MachineLearning/comments/8p5dux/mila_professional_masters_requirements/,janissary2016,1528327200,[removed],0,1
349,2018-6-7,2018,6,7,9,8p5p57,[R] Learning to Follow Language Instructions with Adversarial Reward Induction,https://www.reddit.com/r/MachineLearning/comments/8p5p57/r_learning_to_follow_language_instructions_with/,egrefen,1528329920,,1,1
350,2018-6-7,2018,6,7,9,8p5p64,[R] Learning to Follow Language Instructions with Adversarial Reward Induction,https://www.reddit.com/r/MachineLearning/comments/8p5p64/r_learning_to_follow_language_instructions_with/,egrefen,1528329927,,0,1
351,2018-6-7,2018,6,7,9,8p5p6x,[R] Learning to Follow Language Instructions with Adversarial Reward Induction,https://www.reddit.com/r/MachineLearning/comments/8p5p6x/r_learning_to_follow_language_instructions_with/,egrefen,1528329934,,0,1
352,2018-6-7,2018,6,7,9,8p5tiz,Top 6 Opensource Machine Learning Frameworks &amp; Libraries,https://www.reddit.com/r/MachineLearning/comments/8p5tiz/top_6_opensource_machine_learning_frameworks/,cpt_snowcrash,1528330939,,0,1
353,2018-6-7,2018,6,7,9,8p62mt,[D] InfoGAN  Depth First Learning,https://www.reddit.com/r/MachineLearning/comments/8p62mt/d_infogan_depth_first_learning/,sksq9,1528333185,,1,18
354,2018-6-7,2018,6,7,10,8p66nw,[D] What is the problem of detecting a floor plane's angle and size called?,https://www.reddit.com/r/MachineLearning/comments/8p66nw/d_what_is_the_problem_of_detecting_a_floor_planes/,browngrammer,1528334188,"I'm trying to find papers that use CNNs to learn the angle and size of the floor plane from a image. Essentially the input is an image and the output is something like the pixel locations (X, Y) that correspond to a one inch square on the ground floor plane.
Unfortunately I'm not sure what this problem is called so it's hard to search for it. Does anyone know the name of the problem and/or if there are any papers or datasets related to it? ",8,3
355,2018-6-7,2018,6,7,10,8p6epy,"Surely, AI has not been exploited to their full potential in most business. But is it really promising more jobs? Old question but do yall think",https://www.reddit.com/r/MachineLearning/comments/8p6epy/surely_ai_has_not_been_exploited_to_their_full/,Platybelodon95,1528336249,,0,1
356,2018-6-7,2018,6,7,11,8p6h2j,"Simple Tensorflow implementation of ""Self-Attention GAN"" (Han Zhang, Ian Goodfellow)",https://www.reddit.com/r/MachineLearning/comments/8p6h2j/simple_tensorflow_implementation_of_selfattention/,taki0112,1528336835,[removed],0,1
357,2018-6-7,2018,6,7,11,8p6hjo,China In Race To Overtake U.S. Military in AI Warfare,https://www.reddit.com/r/MachineLearning/comments/8p6hjo/china_in_race_to_overtake_us_military_in_ai/,Jeebzus2014,1528336939,,0,1
358,2018-6-7,2018,6,7,11,8p6hnz,"Simple Tensorflow implementation of ""Self-Attention GAN"" (Han Zhang, Ian Goodfellow)",https://www.reddit.com/r/MachineLearning/comments/8p6hnz/simple_tensorflow_implementation_of_selfattention/,taki0112,1528336970,,1,1
359,2018-6-7,2018,6,7,11,8p6jwz,"Simple Tensorflow implementation of ""Self-Attention GAN"" (Han Zhang, Ian Goodfellow)",https://www.reddit.com/r/MachineLearning/comments/8p6jwz/simple_tensorflow_implementation_of_selfattention/,taki0112,1528337564,,1,1
360,2018-6-7,2018,6,7,11,8p6l20,"[P] Simple Tensorflow implementation of ""Self-Attention GAN"" (Han Zhang, Ian Goodfellow)",https://www.reddit.com/r/MachineLearning/comments/8p6l20/p_simple_tensorflow_implementation_of/,taki0112,1528337833,,3,54
361,2018-6-7,2018,6,7,11,8p6rka,[D] Formal,https://www.reddit.com/r/MachineLearning/comments/8p6rka/d_formal/,Prexeon,1528339487,"Hey there!  
For someone who's interested in the ways in which formal logical systems are deployed in AI\-related fields, in particular as models for machine  learning,  can anyone point:  
(a) a good introductory survey and  
(b) some good research on  applications of non\-monotonic logics (i.e. defeasible or plausible  reasoning) in machine learning?  


Thank you!",0,1
362,2018-6-7,2018,6,7,11,8p6u86,[D] Formal logic in ML,https://www.reddit.com/r/MachineLearning/comments/8p6u86/d_formal_logic_in_ml/,Prexeon,1528340182,"Hey there!  


For someone who's interested in the ways in which formal logical systems are deployed in AI\-related fields, in particular as models for machine  learning,  can anyone point:

(a) a good introductory survey and  
(b) some good research on  applications of non\-monotonic logics (i.e. defeasible or plausible  reasoning) in machine learning?  
Thank you!",3,8
363,2018-6-7,2018,6,7,14,8p7qkf,[P] Playing card detection with YOLOv3 trained on a generated dataset,https://www.reddit.com/r/MachineLearning/comments/8p7qkf/p_playing_card_detection_with_yolov3_trained_on_a/,geaxgx,1528349330,,0,1
364,2018-6-7,2018,6,7,15,8p84mr,"[D] How do I manage my expectations as a new researcher - or how to overcome ""researcher's writers blcok""? (please don't upvote)",https://www.reddit.com/r/MachineLearning/comments/8p84mr/d_how_do_i_manage_my_expectations_as_a_new/,nonstop_overachiever,1528353915,"I started a European PhD a few months ago . My supervisor is very ""hands-off"" and I essentially have full freedom pursuing anything I find interesting. It's very hard for me to settle on a project to work on since I keep reading the top papers and compare my ideas to the state-of-the-art. This results in me quickly dismissing anything idea I get as being low value, and it makes me sad to think about my PhD being filled with such work.

 Can you relate to this state? How did you overcome it?",30,49
365,2018-6-7,2018,6,7,15,8p85v1,How we Organized the Largest Machine Learning Competition of the Year,https://www.reddit.com/r/MachineLearning/comments/8p85v1/how_we_organized_the_largest_machine_learning/,kriss75,1528354295,,0,0
366,2018-6-7,2018,6,7,16,8p892f,Tenser Flow Rooftop Detection,https://www.reddit.com/r/MachineLearning/comments/8p892f/tenser_flow_rooftop_detection/,Leonidus6969,1528355298,[removed],0,1
367,2018-6-7,2018,6,7,16,8p8hkv,How can I collaborate in a ML proyect?,https://www.reddit.com/r/MachineLearning/comments/8p8hkv/how_can_i_collaborate_in_a_ml_proyect/,arch_dav,1528358033,[removed],0,1
368,2018-6-7,2018,6,7,17,8p8kx7,Remove bounding boxes for some detected objects,https://www.reddit.com/r/MachineLearning/comments/8p8kx7/remove_bounding_boxes_for_some_detected_objects/,5KAE,1528359214,[removed],0,1
369,2018-6-7,2018,6,7,17,8p8n80,[R] [1806.01610] Generative Reversible Networks,https://www.reddit.com/r/MachineLearning/comments/8p8n80/r_180601610_generative_reversible_networks/,robintibor,1528360085,,13,10
370,2018-6-7,2018,6,7,17,8p8qze,"News on Pipe Shaping Machine, Pipe Bending Machine, Pipe Cutting Machine",https://www.reddit.com/r/MachineLearning/comments/8p8qze/news_on_pipe_shaping_machine_pipe_bending_machine/,slsmachinery,1528361498,,0,1
371,2018-6-7,2018,6,7,18,8p8ujc,How AI will Change Us,https://www.reddit.com/r/MachineLearning/comments/8p8ujc/how_ai_will_change_us/,baDoxx,1528362763,,0,1
372,2018-6-7,2018,6,7,18,8p8x10,Curious mind wants to know.. is there any applications or papers related with person re-identification or recognition in bank.. if not that what kind of image processing application we can use in bank using deep learning.. thanks in advance to all experts..,https://www.reddit.com/r/MachineLearning/comments/8p8x10/curious_mind_wants_to_know_is_there_any/,kim_jung_un-007,1528363679,[removed],0,1
373,2018-6-7,2018,6,7,18,8p8xku,[D] MDP and Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8p8xku/d_mdp_and_reinforcement_learning/,RubioRick,1528363873,I am studying MDP and RL and I did not understand when we can consider MDP resolution a case of RL problem. I think that if my MDP model is fully observable my solution is simple to search the best action that maximizes my reward (is that a RL problem ? I think this is not). So when a MDP problem is a RL problem ? Is it when we don't know which are the states and the actions that we can do so we need to try and learn from our samples ?,4,0
374,2018-6-7,2018,6,7,18,8p8xst,[N] A new subreddit for anyone interested in audio models: r/AudioModels,https://www.reddit.com/r/MachineLearning/comments/8p8xst/n_a_new_subreddit_for_anyone_interested_in_audio/,fatchord,1528363952,,0,18
375,2018-6-7,2018,6,7,18,8p8xwn,Data Mining vs Machine Learning - Which Is Bettter?,https://www.reddit.com/r/MachineLearning/comments/8p8xwn/data_mining_vs_machine_learning_which_is_bettter/,kmisra96,1528363999,,0,1
376,2018-6-7,2018,6,7,19,8p932s,Need a solution to detect informal synonyms from a given piece of text when the word is given as input.,https://www.reddit.com/r/MachineLearning/comments/8p932s/need_a_solution_to_detect_informal_synonyms_from/,ReDevil1X,1528365782,[removed],0,1
377,2018-6-7,2018,6,7,19,8p96ma,[D] Distribution of Weights and Biases after training under different scenarios,https://www.reddit.com/r/MachineLearning/comments/8p96ma/d_distribution_of_weights_and_biases_after/,LeanderKu,1528366934,"I am searching for a publication that analyses the distribution of weights and biases after training under the impact of:
 - over/underparametrization
 - different regularizations
 - batchnorm
 - initialization
etc.
Any hints? Google and an arxive had a lot of results, but not what I am looking for.",0,6
378,2018-6-7,2018,6,7,19,8p99pq,[P] Playing hard exploration games by watching YouTube,https://www.reddit.com/r/MachineLearning/comments/8p99pq/p_playing_hard_exploration_games_by_watching/,vector_machines,1528367974,,0,2
379,2018-6-7,2018,6,7,19,8p9bud,[D] Data Science/ ML for Trading,https://www.reddit.com/r/MachineLearning/comments/8p9bud/d_data_science_ml_for_trading/,Unnam,1528368664,,2,0
380,2018-6-7,2018,6,7,19,8p9car,[P] Playing card detection with YOLOv3 trained on generated dataset,https://www.reddit.com/r/MachineLearning/comments/8p9car/p_playing_card_detection_with_yolov3_trained_on/,geaxart,1528368822,,106,865
381,2018-6-7,2018,6,7,19,8p9dh8,World is Fake.,https://www.reddit.com/r/MachineLearning/comments/8p9dh8/world_is_fake/,jasonlara2000,1528369198,[removed],1,1
382,2018-6-7,2018,6,7,20,8p9ebs,intel or amd cpu ???,https://www.reddit.com/r/MachineLearning/comments/8p9ebs/intel_or_amd_cpu/,pg13mvp,1528369442,[removed],0,1
383,2018-6-7,2018,6,7,20,8p9iap,[R] Understanding math intuition behind Facebook AI's Music Translation Model,https://www.reddit.com/r/MachineLearning/comments/8p9iap/r_understanding_math_intuition_behind_facebook/,jaleyhd,1528370648,,4,15
384,2018-6-7,2018,6,7,21,8p9x5e,Remove bounding boxes for some detected objects,https://www.reddit.com/r/MachineLearning/comments/8p9x5e/remove_bounding_boxes_for_some_detected_objects/,5KAE,1528374778,[removed],0,1
385,2018-6-7,2018,6,7,21,8pa10t,Industrial Peanut Frying Production Line for Sale,https://www.reddit.com/r/MachineLearning/comments/8pa10t/industrial_peanut_frying_production_line_for_sale/,lgsherry,1528375760,,1,1
386,2018-6-7,2018,6,7,21,8pa280,"[N] Weekly Machine Learning Opensource Roundup  June 7, 2018",https://www.reddit.com/r/MachineLearning/comments/8pa280/n_weekly_machine_learning_opensource_roundup_june/,stkim1,1528376059,,0,1
387,2018-6-7,2018,6,7,22,8pa7w7,What type of loss function for multiple softmax output (in setup of Variational Autoencoder architectures),https://www.reddit.com/r/MachineLearning/comments/8pa7w7/what_type_of_loss_function_for_multiple_softmax/,solingermuc,1528377395,[removed],0,1
388,2018-6-7,2018,6,7,22,8pa85e,ICML talk length,https://www.reddit.com/r/MachineLearning/comments/8pa85e/icml_talk_length/,reinforcemen,1528377455,[removed],0,1
389,2018-6-7,2018,6,7,22,8pa8et,Deep learning in recommender systems,https://www.reddit.com/r/MachineLearning/comments/8pa8et/deep_learning_in_recommender_systems/,kordikp,1528377520,,0,3
390,2018-6-7,2018,6,7,22,8paaic,The difference between machine learning and Artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/8paaic/the_difference_between_machine_learning_and/,marketresearchjsb,1528378035,,0,1
391,2018-6-7,2018,6,7,22,8pah0q,[P] Calling Tinn NN c library directly from python,https://www.reddit.com/r/MachineLearning/comments/8pah0q/p_calling_tinn_nn_c_library_directly_from_python/,bishopxi,1528379572,,0,2
392,2018-6-7,2018,6,7,23,8pal3s,[P] Deep RL for Playing Hard Exploration Games by watching Youtube (DeepMind),https://www.reddit.com/r/MachineLearning/comments/8pal3s/p_deep_rl_for_playing_hard_exploration_games_by/,vector_machines,1528380476,,2,4
393,2018-6-7,2018,6,7,23,8pat06,A question about feature normalization/scaling,https://www.reddit.com/r/MachineLearning/comments/8pat06/a_question_about_feature_normalizationscaling/,noitren,1528382217,[removed],0,1
394,2018-6-7,2018,6,7,23,8pau50,This article has successfully motivated 3 of my friends to start learning ML,https://www.reddit.com/r/MachineLearning/comments/8pau50/this_article_has_successfully_motivated_3_of_my/,GantMan,1528382469,,0,1
395,2018-6-7,2018,6,7,23,8paz4p,"[Python, App or Web] Sample ML solutions?",https://www.reddit.com/r/MachineLearning/comments/8paz4p/python_app_or_web_sample_ml_solutions/,theAppo,1528383557,"Hello everyone,

Do you have any repositories / websites that would have sample use cases of machine learning that can be presented as representative (i.e. download, configure, plug &amp; play under a scenario) ?

I'm trying to show ""art of possible"" with couple of working examples.

Thanks a lot in advance!",0,1
396,2018-6-8,2018,6,8,0,8pazso,Best neural network structure for handling variable length but non-sequential inputs?,https://www.reddit.com/r/MachineLearning/comments/8pazso/best_neural_network_structure_for_handling/,fiddlewin,1528383691,[removed],0,1
397,2018-6-8,2018,6,8,0,8pb1gz,Minimal character-based LSTM implementation,https://www.reddit.com/r/MachineLearning/comments/8pb1gz/minimal_characterbased_lstm_implementation/,iamkeyur,1528384028,,0,1
398,2018-6-8,2018,6,8,0,8pb51r,Learn Artificial Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8pb51r/learn_artificial_neural_networks/,aiexpert351,1528384755,,0,1
399,2018-6-8,2018,6,8,0,8pb6rd,Human Level AI,https://www.reddit.com/r/MachineLearning/comments/8pb6rd/human_level_ai/,baDoxx,1528385125,,0,1
400,2018-6-8,2018,6,8,1,8pbqbj,Help wanted. RR-index: domain independent index to quantify the research impact of a researcher,https://www.reddit.com/r/MachineLearning/comments/8pbqbj/help_wanted_rrindex_domain_independent_index_to/,f0112358f,1528389048,[removed],0,1
401,2018-6-8,2018,6,8,1,8pbtkq,[R] Learn Reinforcement Learning from scratch,https://www.reddit.com/r/MachineLearning/comments/8pbtkq/r_learn_reinforcement_learning_from_scratch/,e_ameisen,1528389680,,0,1
402,2018-6-8,2018,6,8,2,8pc5lf,[N] Scala Inference API now available in MXNet: including Object Detection example,https://www.reddit.com/r/MachineLearning/comments/8pc5lf/n_scala_inference_api_now_available_in_mxnet/,thomelane,1528392042,,0,5
403,2018-6-8,2018,6,8,2,8pcf2y,TextRay: Mining Clinical Reports to Gain a Broad Understanding of Chest X-rays,https://www.reddit.com/r/MachineLearning/comments/8pcf2y/textray_mining_clinical_reports_to_gain_a_broad/,jonilaserson,1528393958,,3,8
404,2018-6-8,2018,6,8,2,8pcf3c,Getting started in Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/8pcf3c/getting_started_in_natural_language_processing/,pipinstallme,1528393960,,0,1
405,2018-6-8,2018,6,8,2,8pcf4u,"[N] Do not try this at home: MIT fed an AI data from Reddit, and now it only thinks about murder",https://www.reddit.com/r/MachineLearning/comments/8pcf4u/n_do_not_try_this_at_home_mit_fed_an_ai_data_from/,phobrain,1528393969,,4,0
406,2018-6-8,2018,6,8,2,8pcftu,Help wanted. RR-index: domain independent index to quantify the research impact of a researcher,https://www.reddit.com/r/MachineLearning/comments/8pcftu/help_wanted_rrindex_domain_independent_index_to/,f0112358f,1528394098,[removed],0,1
407,2018-6-8,2018,6,8,3,8pcknk,[P] RR-index: domain independent index to quantify the research impact of a researcher,https://www.reddit.com/r/MachineLearning/comments/8pcknk/p_rrindex_domain_independent_index_to_quantify/,f0112358f,1528395030,"Open Science Organization (OSO) is a non\-profit which is building a decentralized platform for end\-to\-end scientific research.

[https://github.com/open\-science\-org/wiki/blob/master/OSO\_white\_paper.pdf](https://github.com/open-science-org/wiki/blob/master/OSO_white_paper.pdf)

We plan to distribute majority of the OSO tokens for free to the verified researchers and students. The amount of tokens distributed to a researcher will be proportional to his/her research contribution. For this, we need a research domain independent metric to quantify the research contribution. We perceive this as a domain independent universal ranking problem. Our Github page for this project is [https://github.com/open\-science\-org/RR\-index](https://github.com/open-science-org/RR-index). We plan to integrate RR\-index project to our another project called Unique Researcher Identity (URI) where we are creating a cryptography based universal identity of a researcher; [https://github.com/open\-science\-org/URI](https://github.com/open-science-org/URI). After that, we will distribute OSO tokens to the verified URIs in proportion to theirs RR\-indices.

We are looking for help to design RR\-index. It would be good if there are competing thoughts so that we can come up with a somewhat unbiased model. Are there any ML researchers interested in this and would like to contribute?",4,3
408,2018-6-8,2018,6,8,3,8pcl0p,Free floating a deep learning output?,https://www.reddit.com/r/MachineLearning/comments/8pcl0p/free_floating_a_deep_learning_output/,soulslicer0,1528395098,[removed],0,1
409,2018-6-8,2018,6,8,3,8pcnqo,Netflix Data Science Interview Questions,https://www.reddit.com/r/MachineLearning/comments/8pcnqo/netflix_data_science_interview_questions/,acingai,1528395634,,0,1
410,2018-6-8,2018,6,8,3,8pcqgj,[P] 3D Object Detection for Autonomous Driving using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8pcqgj/p_3d_object_detection_for_autonomous_driving/,dirac-hatt,1528396177,,4,5
411,2018-6-8,2018,6,8,3,8pcykb,[D] Actor Critic (DDPG) Diverging after Finding Solution,https://www.reddit.com/r/MachineLearning/comments/8pcykb/d_actor_critic_ddpg_diverging_after_finding/,MrDoOO,1528397822,"Hi All,

I was wondering what would cause an Actor / Critic RL method (DDPG in my case) to diverge after finding a solution. I am noticing that my implementation (which is exactly as described in [https://arxiv.org/abs/1509.02971](https://arxiv.org/abs/1509.02971)) finds a solution on a dummy problem that would be considered ""solved"", but then begins to unlearn this and totally diverges. Thoughts on why this may happen would be helpful. One thing to note is that my implementation does not diverge on a dummy problem when it is on\-policy (the policy that generated the data is the policy being optimized), but happens when I train off\-policy (on data generated by a random policy).",7,13
412,2018-6-8,2018,6,8,4,8pd4xv,Multi-,https://www.reddit.com/r/MachineLearning/comments/8pd4xv/multi/,Dooley-,1528399103,[removed],0,1
413,2018-6-8,2018,6,8,4,8pd5ew,I made a script that separates source code and output and makes your data generating projects 100% reproducable,https://www.reddit.com/r/MachineLearning/comments/8pd5ew/i_made_a_script_that_separates_source_code_and/,nielsrolf,1528399203,,0,1
414,2018-6-8,2018,6,8,4,8pd7z6,"Clustering within ""documents""",https://www.reddit.com/r/MachineLearning/comments/8pd7z6/clustering_within_documents/,Dooley-,1528399713,"Hello,

I have a question and could use some hints on the best way to proceed for my problem.
What I have is the following:
- a set of ""projects"" (each project is a training example). You may look at them as ""designs"" or ""products"". For each of these ""projects"", I have a series of ""components"" or ""parts"". The list of ""components"" is variable and can go all the way from 5 to 40. These ""components"" are currently grouped or matched by a human expert into ""categories"" or ""clusters"" which are not exclusive (a component may belong to several categories and a category usually contains several components). See below for example.

    Project Z

*                       | Cat A | Cat B | Cat C | Cat D |

*    component 1 |   [x]   |   [-]  |   [x]   |   [-]   |

*    component 2 |   [x]   |   [x]  |   [x]   |   [-]   |

*    component 3 |   [-]   |   [-]   |   [x]   |   [x]  |

*    component 5 |   [x]   |   [x]  |   [x]   |   [-]   |

*    component 6 |   [-]   |   [-]   |   [-]   |   [x]   |

I have:
- K projets (training dataset)

For each project:
- M components grouped into N soft clusters

My goal is to take a list of component (variable size) and generate the mapping shown above (variable size matrix where number of row equals the number of input components) and number of column needs to be found (varies between projects). Cat A, B, C have no specific meaning (cat A in project XX is unrelated to Cat A in project ZZ - just need to find the right groups of components)

I thought about splitting the problem in 2 steps (1st number of categories then assign components to categories). Issue is that each of these ""clusters"" are on a project basis and not for my whole dataset (not N categories for the whole dataset but rather K * N clusters with the goal being identifying the N cluster for a new unseen set of components)

Any ideas? Many thanks!

",0,1
415,2018-6-8,2018,6,8,5,8pdj32,"[P] Simple example how to use the TensorFlow Estimator API, how it integrates with other APIs such as the Dataset API, and how to use it to train your models on Google Cloud.",https://www.reddit.com/r/MachineLearning/comments/8pdj32/p_simple_example_how_to_use_the_tensorflow/,Xochipilli,1528401972,,0,7
416,2018-6-8,2018,6,8,5,8pdsow,[Discussion] Recommended survey papers,https://www.reddit.com/r/MachineLearning/comments/8pdsow/discussion_recommended_survey_papers/,Abdelhak96,1528403973,"What are some good survey papers you came across on specific topics in machine learning (SSL, Unsupervised DL,...)? ",2,18
417,2018-6-8,2018,6,8,5,8pdy5p,Crowdsourcing 101 with Figure Eight,https://www.reddit.com/r/MachineLearning/comments/8pdy5p/crowdsourcing_101_with_figure_eight/,martianwars,1528405085,,0,1
418,2018-6-8,2018,6,8,6,8pe0p6,[D] AI at Google: our principles,https://www.reddit.com/r/MachineLearning/comments/8pe0p6/d_ai_at_google_our_principles/,sksq9,1528405603,,17,40
419,2018-6-8,2018,6,8,6,8pe269,Recommending a word based off user input? Newbie help please.,https://www.reddit.com/r/MachineLearning/comments/8pe269/recommending_a_word_based_off_user_input_newbie/,cwinhall,1528405909,[removed],0,1
420,2018-6-8,2018,6,8,6,8pe29z,[P] Crowdsourcing 101 with Figure Eight,https://www.reddit.com/r/MachineLearning/comments/8pe29z/p_crowdsourcing_101_with_figure_eight/,martianwars,1528405937,,0,5
421,2018-6-8,2018,6,8,7,8pet5f,"Binary cross entropy is not symmetric for soft labels, why does it work so well for image-based autoencoders?",https://www.reddit.com/r/MachineLearning/comments/8pet5f/binary_cross_entropy_is_not_symmetric_for_soft/,sraschka,1528411952,[removed],0,1
422,2018-6-8,2018,6,8,8,8pew5m,[D] Looking for Advice on a Self-Driving Car Project,https://www.reddit.com/r/MachineLearning/comments/8pew5m/d_looking_for_advice_on_a_selfdriving_car_project/,Fufu008,1528412673,"My friend and I are planning on building a self driving RC sized car that would be able to drive to a bluetooth emitting waypoint. The way this would work is that there will be a Raspberry Pi mounted on top of the car, handling input and controlling the car's movements. Modules that would be installed on the car would be ultrasonic sensors to measure distance and wheel encoders to measure how fast the wheels are spinning. 

I was thinking of using NEAT on a separate machine to train a neural network to respond to these given inputs (the input sensors, wheel encoders, and bluetooth waypoint) and then porting the trained neural network to the Pi, but as I am sorely lacking in knowledge regarding machine learning, I have no idea whether this is an appropriate approach and would hugely appreciate advice on where to start. 

I probably didn't explain the project in detail enough for a detailed answer, so please ask if further specification is required for any useful advice to be given.

tldr: I want to build a self driving RC car that can get from Point A to Point B. Any advice on where to start on the software would be greatly appreciated.",3,0
423,2018-6-8,2018,6,8,9,8pfcne,"[D] Binary cross entropy is not symmetric for soft labels, why does it work so well for image-based autoencoders?",https://www.reddit.com/r/MachineLearning/comments/8pfcne/d_binary_cross_entropy_is_not_symmetric_for_soft/,sraschka,1528416822,"Binary cross entropy (BCE) is not symmetric when the target labels are not binary. I.e., imagine the common image\-autoencoder scenario where the pixels are normalized to range \[0, 1\]. In practice, one would commonly minimize either the pixel\-wise binary cross\-entropy between the predicted pixels and the original pixels or the pixel\-wise MSE. Pixel\-wise MSE makes sense because it's symmetric. However, for the BCE, we have different ""loss"" values depending on the magnitude of the prediction and the true labels. E.g., consider the following

| predicted value | true pixel value | BCE loss |
|-----------------|------------------|----------|
| 0.0             | 0.0              | 0.0      |
| 0.25            | 0.25             | 0.56     |
| 0.5             | 0.5              | 0.69     |
| 0.75            | 0.75             | 0.56     |
| 1.0             | 1.0              | 0.0      |

Note that with non-symmetric, I mean that even though the prediction matches the true pixel value, the loss can vary between 0.0 and 0.7, while the MSE would be (more intuitively) always zero in these cases.

Based on my experience, I find that BCE often works well for autoencoders, often the results look better than results obtained with MSE.

Any ideas what the reason could be for that?

My intuition would be that we don't perceive difference in very dark or very bright pixels that much, and human-perception-wise.",9,6
424,2018-6-8,2018,6,8,10,8pfoeh,100 Data Science Resources,https://www.reddit.com/r/MachineLearning/comments/8pfoeh/100_data_science_resources/,zindarod,1528419676,,0,1
425,2018-6-8,2018,6,8,11,8pg7s5,Titanic dataset on kaggle. Applying ML Process,https://www.reddit.com/r/MachineLearning/comments/8pg7s5/titanic_dataset_on_kaggle_applying_ml_process/,theprogrammingsteak,1528424503,[removed],0,1
426,2018-6-8,2018,6,8,12,8pgpx9,Data De-duplication in Image Search Services,https://www.reddit.com/r/MachineLearning/comments/8pgpx9/data_deduplication_in_image_search_services/,Michael_Pa,1528429150,,0,1
427,2018-6-8,2018,6,8,12,8pgu5p,Help making a chess playing system using deep CNN,https://www.reddit.com/r/MachineLearning/comments/8pgu5p/help_making_a_chess_playing_system_using_deep_cnn/,fr3dw4rd,1528430286,[removed],0,1
428,2018-6-8,2018,6,8,13,8pgw9o,Automated ML now opensource,https://www.reddit.com/r/MachineLearning/comments/8pgw9o/automated_ml_now_opensource/,AndresPaez,1528430815,[removed],0,1
429,2018-6-8,2018,6,8,13,8pgxl2,Sewage sludge fertilizer making machine/granulator machine/equipment,https://www.reddit.com/r/MachineLearning/comments/8pgxl2/sewage_sludge_fertilizer_making_machinegranulator/,amylee516,1528431154,,0,1
430,2018-6-8,2018,6,8,14,8phaq0,Training an LSTM using pre-trained word embedding to generate rap lyrics.,https://www.reddit.com/r/MachineLearning/comments/8phaq0/training_an_lstm_using_pretrained_word_embedding/,wilber-guy,1528434968,[removed],0,1
431,2018-6-8,2018,6,8,14,8phc7y,Question about training a neural network to think ahead.,https://www.reddit.com/r/MachineLearning/comments/8phc7y/question_about_training_a_neural_network_to_think/,mount_sumInt,1528435413,[removed],0,1
432,2018-6-8,2018,6,8,14,8phdta,Using an LSTM and word embeddings to try and generate rap lyrics,https://www.reddit.com/r/MachineLearning/comments/8phdta/using_an_lstm_and_word_embeddings_to_try_and/,wilber-guy,1528435913,[removed],0,1
433,2018-6-8,2018,6,8,15,8phjp3,[R][1806.02817] Probabilistic Model-Agnostic Meta-Learning,https://www.reddit.com/r/MachineLearning/comments/8phjp3/r180602817_probabilistic_modelagnostic/,evc123,1528437794,,1,10
434,2018-6-8,2018,6,8,16,8pi0re,An example of disaster paper in Science and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8pi0re/an_example_of_disaster_paper_in_science_and/,Professor_Entropy,1528443411,[removed],0,1
435,2018-6-8,2018,6,8,16,8pi2rs,[R] On the contribution of neural networks and word embeddings in Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/8pi2rs/r_on_the_contribution_of_neural_networks_and_word/,jackblun,1528444140,,0,1
436,2018-6-8,2018,6,8,17,8pi6qg,[D] One-vs-All Classification Using Logistic Regression,https://www.reddit.com/r/MachineLearning/comments/8pi6qg/d_onevsall_classification_using_logistic/,lord-bazooka,1528445640,,9,0
437,2018-6-8,2018,6,8,17,8pia8p,[D] Multi class Linearly Separable Dataset,https://www.reddit.com/r/MachineLearning/comments/8pia8p/d_multi_class_linearly_separable_dataset/,RubioRick,1528447025,"Given a dataset with a representation of 3 class in a 2D space:
[example](https://houxianxu.github.io/images/logisticRegression/4.png)

Can I say that these data are linearly separable ? If not , is it a good solution to apply a kernel like RBF to separate them ?
",3,2
438,2018-6-8,2018,6,8,17,8pia9f,difference btw gradient and stochastic gradient descent,https://www.reddit.com/r/MachineLearning/comments/8pia9f/difference_btw_gradient_and_stochastic_gradient/,chillpill_26,1528447033,[removed],0,1
439,2018-6-8,2018,6,8,18,8pig83,[P] Realtime tSNE Visualizations with TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/8pig83/p_realtime_tsne_visualizations_with_tensorflowjs/,pmigdal,1528449286,,5,126
440,2018-6-8,2018,6,8,18,8pihdh,A new speaker separation engine is in town :),https://www.reddit.com/r/MachineLearning/comments/8pihdh/a_new_speaker_separation_engine_is_in_town/,Vladislavlich,1528449696,,0,1
441,2018-6-8,2018,6,8,18,8pikc7,Does anyone know good Project definition on Machine Learning in IOT?,https://www.reddit.com/r/MachineLearning/comments/8pikc7/does_anyone_know_good_project_definition_on/,kunj17,1528450795,[removed],0,1
442,2018-6-8,2018,6,8,18,8pilo0,[R] Need ideas to write a meaningful research paper on Prostate Cancer detection using deep learning,https://www.reddit.com/r/MachineLearning/comments/8pilo0/r_need_ideas_to_write_a_meaningful_research_paper/,omayrakhtar,1528451267,"Hi - A few weeks ago I posted on reddit regarding suggestions on the same topic: https://www.reddit.com/r/MachineLearning/comments/8axh44/d_need_suggestions_on_creative_ways_to_approach/
This is the topic of my thesis. And I have conducted a great number of experiment including traditional image processing and machine learning, pre-trained deep networks, 2D CNN, 3D CNN, tried data augmentation, blending data modalities to enrich the data and etc, but none of these experiments yielded any significant results, primarily because of the scarcity of data and this being a multi-class classification problem. I have put in a lot of efforts into this but the results aren't very impressive, however, I am aiming to publish a paper in the following conference: http://www.tut.fi/euvip2018/index.html but I am not confident what could be an interesting approach to talk explain in the paper. A few titles that came to my mind were:
* Inefficacy of deeper networks on smaller datasets. (No dense layers with dense layers)
* Traditional machine learning methods performing as well as deep learning.
* Effects of data augmentation on learning of deep models. 

Please let me know if you need more information to make suggestions. ",8,3
443,2018-6-8,2018,6,8,18,8pin69,[D] Deep learning for video editing,https://www.reddit.com/r/MachineLearning/comments/8pin69/d_deep_learning_for_video_editing/,ocelot134,1528451830,"Hi! This is my first post on here, so please forgive me if i have the improper tag.. it would either be D or R

I am very keen to learn more about deep learning so that I could apply it towards the editing of videos.

i have been self-learning Python online in my free time, by trying to read ""automate the boring stuff"" and trying to following Youtube tutorials on fundamentals. I understand and follow along with the concept and big picture stuff. But by the end of the project, I feel I was just taken for the ride. I want to have projects of my own to show for it. 

If possible, i really want to work on something that is bigger than myself and be able to contribute my knowledge about video editing theory, even if its not on the programming side since im from film . I could test or something. It would be so good to have a mentor to guide me. I don't have a formal CS background, but I do have a background in film production

I think Id like to learn about computer vision, automation, and streamlining with Python so that I can be creating or helping to create an application or script for content creators or for things that VFX artists might use that are in moviemaking. 

I'd really love to speak to someone in that industry, or if I could get very specific directions on a roadmap to get me up to speed. I need to take to become competent at making as I have been kind of overwhelmed with all of the information on the internet. Thank you for your time!
",0,1
444,2018-6-8,2018,6,8,19,8pioga,Forecasting model,https://www.reddit.com/r/MachineLearning/comments/8pioga/forecasting_model/,wearefarming101,1528452283,[removed],0,1
445,2018-6-8,2018,6,8,19,8piruo,Amazon SageMaker Automatic Model Tuning: Using Machine Learning for Machine Learning | Amazon Web Services,https://www.reddit.com/r/MachineLearning/comments/8piruo/amazon_sagemaker_automatic_model_tuning_using/,ranman96734,1528453415,,0,1
446,2018-6-8,2018,6,8,19,8pisx4,Find the best PCB repairing services online to keep your machines secured,https://www.reddit.com/r/MachineLearning/comments/8pisx4/find_the_best_pcb_repairing_services_online_to/,melriya,1528453757,,0,1
447,2018-6-8,2018,6,8,19,8piu0x,Is there an inherent problem with generating coherent longer videos using GANs or is it just a matter of computer capacity?,https://www.reddit.com/r/MachineLearning/comments/8piu0x/is_there_an_inherent_problem_with_generating/,mrconter1,1528454125,[removed],0,1
448,2018-6-8,2018,6,8,19,8piuhs,Why isn't reinforcement learning used on multiple areas of learning?,https://www.reddit.com/r/MachineLearning/comments/8piuhs/why_isnt_reinforcement_learning_used_on_multiple/,Actuary1997,1528454297,[removed],0,1
449,2018-6-8,2018,6,8,19,8pivrv,[D] RepuX data marketplace.,https://www.reddit.com/r/MachineLearning/comments/8pivrv/d_repux_data_marketplace/,RepuX_on_Reddit,1528454736,"Hi guys. We're launching our decentralised data marketplace based on blockchain soon. 

In one of our use\-cases we want our data sources to provide raw data to potential buyers (being big data / ml specialists) so right now we're working on choosing plugins that would collect the unified datasets for them. 

We have our thoughts but are curious of your opinion on what kind of data preferably stored in some SaaS platform or a standalone application would you be interested in the most? As if you could get the same set of data form multiple users of the same platform what would that be?

Please exclude social networks, personal data, iot as we want to focus mostly on business/corporate area and as there are a few similar products like [datum.org](https://datum.org) that focus on personal data solely.

Thanks for any suggestions

 Marcin/RepuX",0,1
450,2018-6-8,2018,6,8,19,8pixho,[D] REPUX data marketplace,https://www.reddit.com/r/MachineLearning/comments/8pixho/d_repux_data_marketplace/,RepuX_on_Reddit,1528455339,"Hi guys. We're launching our decentralised data marketplace \- [https://repux.io](https://repux.io/) based on blockchain soon.

In one of our use\-cases we want our data sources to provide raw data to potential buyers (being big data / ml specialists) so right now we're working on choosing plugins that would collect the unified datasets for them.

We have our thoughts but are curious of your opinion on what kind of data preferably stored in some SaaS platform or a standalone application would you be interested in the most? As if you could get the same set of data form multiple users of the same platform what would that be?

Please exclude social networks, personal data, iot as we want to focus mostly on business/corporate area and as there are a few similar products  that focus on personal data solely.

Thanks for any suggestions

Marcin/RepuX",0,0
451,2018-6-8,2018,6,8,20,8pj0ij,[N] From Law to Data Science,https://www.reddit.com/r/MachineLearning/comments/8pj0ij/n_from_law_to_data_science/,dearpetra,1528456254,,0,1
452,2018-6-8,2018,6,8,20,8pj4vw,[R] Why Bigger Isnt Always Better When It Comes To AI,https://www.reddit.com/r/MachineLearning/comments/8pj4vw/r_why_bigger_isnt_always_better_when_it_comes_to/,polllyyy,1528457516,,0,1
453,2018-6-8,2018,6,8,20,8pj5tt,[R] Human Interpretable Machine Learning (Part 1)  The Need and Importance of Model Interpretation,https://www.reddit.com/r/MachineLearning/comments/8pj5tt/r_human_interpretable_machine_learning_part_1_the/,rennytech,1528457783,,0,9
454,2018-6-8,2018,6,8,21,8pjbre,[R] Equivalent-accuracy accelerated neural-network training using analogue memory,https://www.reddit.com/r/MachineLearning/comments/8pjbre/r_equivalentaccuracy_accelerated_neuralnetwork/,phobrain,1528459420,,7,8
455,2018-6-8,2018,6,8,21,8pjj30,Is this Research?,https://www.reddit.com/r/MachineLearning/comments/8pjj30/is_this_research/,captainskrra,1528461374,[removed],0,1
456,2018-6-8,2018,6,8,21,8pjja5,[R] I need help finding ML algorithms to research for location data,https://www.reddit.com/r/MachineLearning/comments/8pjja5/r_i_need_help_finding_ml_algorithms_to_research/,officeface,1528461422,"Hi all.  To give you some context - I'm from a maths background, but not too much ML beyond a statistical understanding of regression techniques and some unsupervised clustering/Markov Chains for reinforcement learning.

The situation: Suppose I have location data (for example the whereabouts of all the items in my house).  I want to do some learning on this data to understand where items are generally kept and therefore when items are out of place.  For example, if I misplace the remote I might get a notification when the remote has strayed too far from its general location.  I guess there would also be some clustering involved, e.g. items in the ""kitchen area"" would be categorised under ""kitchen utensils"" or ""food"", although not all items in the kitchen fit into these categories necessarily.  I also want a way of suggesting better storage locations for items that are frequently used far away from where they're kept (e.g. if I keep the torch in the downstairs cupboard but only ever use it in the top attic, why not move it closer to the attic?).

Could you suggest ML topics/areas/algorithms for me to research that might link closely with these ideas? It could be that I'm failing to search using the correct terminology but I'm struggling to get relevant material.",4,1
457,2018-6-8,2018,6,8,22,8pk15z,Human level Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8pk15z/human_level_artificial_intelligence/,baDoxx,1528465925,,0,1
458,2018-6-8,2018,6,8,23,8pk89d,How can Deep Q Learning be applied to scenarios with rewards only received in a final step?,https://www.reddit.com/r/MachineLearning/comments/8pk89d/how_can_deep_q_learning_be_applied_to_scenarios/,malusmax,1528467429,[removed],0,1
459,2018-6-8,2018,6,8,23,8pk8k9,[N] New dataset for generative models and challenge,https://www.reddit.com/r/MachineLearning/comments/8pk8k9/n_new_dataset_for_generative_models_and_challenge/,1o0ko,1528467489,"https://i.redd.it/ihv9fphhcs211.jpg

[https://fashion\-gen.com/](https://fashion-gen.com/)  


Challenge your knowledge of image generation by creating a model that can disrupt the fashion industry. Your design will be evaluated by both human and machine.

The winner with the best model will be given a **$2,000 CAD** prize.",2,12
460,2018-6-8,2018,6,8,23,8pkk8j,Top 20 Fastest Growing AI Startups,https://www.reddit.com/r/MachineLearning/comments/8pkk8j/top_20_fastest_growing_ai_startups/,cpt_snowcrash,1528469947,,0,1
461,2018-6-9,2018,6,9,0,8pko21,New audio samples from Lyrebird,https://www.reddit.com/r/MachineLearning/comments/8pko21/new_audio_samples_from_lyrebird/,adbrebs,1528470679,,0,2
462,2018-6-9,2018,6,9,0,8pkubq,How to easily automate Drone-based monitoring using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8pkubq/how_to_easily_automate_dronebased_monitoring/,nanonets,1528471961,,4,75
463,2018-6-9,2018,6,9,0,8pl1jd,Newbie's questions for Bayesian neural network,https://www.reddit.com/r/MachineLearning/comments/8pl1jd/newbies_questions_for_bayesian_neural_network/,shaowu_pan,1528473397,[removed],0,1
464,2018-6-9,2018,6,9,1,8pl55l,[N] TensorFlow 1.9.0-rc0 is available,https://www.reddit.com/r/MachineLearning/comments/8pl55l/n_tensorflow_190rc0_is_available/,olBaa,1528474087,,13,45
465,2018-6-9,2018,6,9,1,8pl9eq,[N] Nemesis'18 - 1st Workshop on Recent Advances in Adversarial Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8pl9eq/n_nemesis18_1st_workshop_on_recent_advances_in/,inane_blather,1528474915,,0,1
466,2018-6-9,2018,6,9,1,8plc0a,[D] Why giving your algorithm ALL THE FEATURES does not always work - Thomas Huijskens,https://www.reddit.com/r/MachineLearning/comments/8plc0a/d_why_giving_your_algorithm_all_the_features_does/,_alphamaximus_,1528475414,,0,1
467,2018-6-9,2018,6,9,2,8plp88,An Introduction to Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8plp88/an_introduction_to_neural_networks/,NicNic8,1528478070,,0,1
468,2018-6-9,2018,6,9,2,8plzmk,[D] Emotion control text-to-speech,https://www.reddit.com/r/MachineLearning/comments/8plzmk/d_emotion_control_texttospeech/,adbrebs,1528480213,,5,18
469,2018-6-9,2018,6,9,2,8pm1zq,[N] DeepMind: First major AI patent filings revealed,https://www.reddit.com/r/MachineLearning/comments/8pm1zq/n_deepmind_first_major_ai_patent_filings_revealed/,nnatlab,1528480683,,84,272
470,2018-6-9,2018,6,9,3,8pm7p6,"[D] Winning with Simple, even Linear, Models - Vincent D. Warmerdam",https://www.reddit.com/r/MachineLearning/comments/8pm7p6/d_winning_with_simple_even_linear_models_vincent/,_alphamaximus_,1528481804,,0,1
471,2018-6-9,2018,6,9,3,8pmaup,Semantic Relationships in Large Pieces of Text,https://www.reddit.com/r/MachineLearning/comments/8pmaup/semantic_relationships_in_large_pieces_of_text/,MachineLearner17,1528482454,[removed],0,1
472,2018-6-9,2018,6,9,4,8pmsx7,Fortnite locations based on rotations,https://www.reddit.com/r/MachineLearning/comments/8pmsx7/fortnite_locations_based_on_rotations/,Stone_d_,1528486125,[removed],0,1
473,2018-6-9,2018,6,9,4,8pmtdr,"I have a good background using R and Python programming language and want to start learning ML in biology , any help or link I could start with ??",https://www.reddit.com/r/MachineLearning/comments/8pmtdr/i_have_a_good_background_using_r_and_python/,almeldin,1528486223,,0,1
474,2018-6-9,2018,6,9,4,8pmtwu,"[D] ML Blog for beginners, thoughts?",https://www.reddit.com/r/MachineLearning/comments/8pmtwu/d_ml_blog_for_beginners_thoughts/,FlyingQuokka,1528486326,"I'm currently learning machine learning myself, and have done a couple of small projects using Naive Bayes and kNN. I was thinking of starting a blog/website for beginners where I explain my understanding of ML, and whenever I learn something new, I link the resource and explain it in my own words there, so that it's more accessible to beginners. 

Thoughts? Would you guys help with errata if I did start this?",16,0
475,2018-6-9,2018,6,9,4,8pmvhk,How to get confidence level on lstm mode?,https://www.reddit.com/r/MachineLearning/comments/8pmvhk/how_to_get_confidence_level_on_lstm_mode/,asnee0,1528486651,[removed],0,1
476,2018-6-9,2018,6,9,5,8pn3su,An implementation of a deep belief network,https://www.reddit.com/r/MachineLearning/comments/8pn3su/an_implementation_of_a_deep_belief_network/,Siddhartha10,1528488351,[removed],0,1
477,2018-6-9,2018,6,9,5,8pn6lm,[N] Humans Feared Smart Robots Over a Century Before Elon Musk et al Raised the Alarm,https://www.reddit.com/r/MachineLearning/comments/8pn6lm/n_humans_feared_smart_robots_over_a_century/,trcytony,1528488936,,0,1
478,2018-6-9,2018,6,9,5,8pn7r4,Training a neural network in phase-change memory beats GPUs,https://www.reddit.com/r/MachineLearning/comments/8pn7r4/training_a_neural_network_in_phasechange_memory/,georgeo,1528489166,,0,1
479,2018-6-9,2018,6,9,5,8pn89b,"Which programming language do you think the first ""strong AI"" will be written in?",https://www.reddit.com/r/MachineLearning/comments/8pn89b/which_programming_language_do_you_think_the_first/,insanelylogical,1528489276,,0,1
480,2018-6-9,2018,6,9,5,8pn8x4,Applying machine learning to artwork,https://www.reddit.com/r/MachineLearning/comments/8pn8x4/applying_machine_learning_to_artwork/,artro1,1528489418,"Im fairly experienced in general programming, but not machine learning. Im trying to develop algorithms to apply to artwork, similar to the app Prisma. Does anybody know where I would learn something like this? ",0,1
481,2018-6-9,2018,6,9,5,8pnbcr,Books or best material hands on of Caffe,https://www.reddit.com/r/MachineLearning/comments/8pnbcr/books_or_best_material_hands_on_of_caffe/,adnire,1528489925,"I'm recently join a new company, I have very good experience on DL using Tensorflow and/or Keras, in this new company they use Caffe, so I'm in the quest to learn Caffe, any book or material, I love the books of Packt but this time theres nothing on Caffe, so Here I'm asking for any tip.",0,1
482,2018-6-9,2018,6,9,6,8pno0a,[D] Machine Learning in Genomics career questions,https://www.reddit.com/r/MachineLearning/comments/8pno0a/d_machine_learning_in_genomics_career_questions/,curiousAIML,1528492614,"I come to reddit as usual in a time of personal conflict in search of honest advice. I have recently graduated reading Biochemistry. I managed to secure a position working for a leading genome sequencing company in a bioinformatics support role. I have some python experience, and am constantly working on improving this.

Through my own personal interests, I have been trying to self teach myself machine learning, to hopefully work in the field of machine learning in Genomics. My question is, to those in the field: Will a lack of any formal education hold me back? Should I return to education?  What is the best way to 'break out' in this field?   


If you think my post is better directed to another subreddit, please let me know.",4,6
483,2018-6-9,2018,6,9,6,8pnt6b,Machine Learning for Recommender systems,https://www.reddit.com/r/MachineLearning/comments/8pnt6b/machine_learning_for_recommender_systems/,kordikp,1528493740,,0,11
484,2018-6-9,2018,6,9,6,8pnxcs,Feel like I am out of the loop: What's with the Microsoft love/Google hate lately?,https://www.reddit.com/r/MachineLearning/comments/8pnxcs/feel_like_i_am_out_of_the_loop_whats_with_the/,ErtApfel,1528494654,[removed],0,1
485,2018-6-9,2018,6,9,7,8po3uy,Is there a way to search for projects based on datasets used?,https://www.reddit.com/r/MachineLearning/comments/8po3uy/is_there_a_way_to_search_for_projects_based_on/,inkplay_,1528496095,[removed],0,1
486,2018-6-9,2018,6,9,7,8poc3z,[R] Blog post on World Models for Sonic,https://www.reddit.com/r/MachineLearning/comments/8poc3z/r_blog_post_on_world_models_for_sonic/,_sulo,1528497985,,15,25
487,2018-6-9,2018,6,9,7,8poe50,[D] How does AR-Assisted Measurement work?,https://www.reddit.com/r/MachineLearning/comments/8poe50/d_how_does_arassisted_measurement_work/,parekhnish,1528498461,"Apple recently announced a new app called [Measure](https://venturebeat.com/2018/06/08/apples-ios-12-measure-app-is-good-enough-ai-assisted-ar-really-good-enough/), which measures dimensions of the object shown in the camera view. This led me down a rabbit\-hole where I discovered quite a few apps that did similar things.

But this seems to be an ill\-posed problem; depth cannot be measured using a single image! If the domain is pre\-defined, then depth estimation is possible and quite accurate (for example, [this project](http://cvl-demos.cs.nott.ac.uk/vrn/) allows 3D reconstruction of a face, since it is trained on facial image and model data). But for measuring the length of any arbitrary line in 3D space, a single image should not suffice!

So my inquiry is, how do these AR\-assisted measurement apps work under the hood?",7,6
488,2018-6-9,2018,6,9,8,8poqwf,[P] Intelligent Computer Interface Research,https://www.reddit.com/r/MachineLearning/comments/8poqwf/p_intelligent_computer_interface_research/,nateshep,1528501563,"Hello! 
I made a post [earlier this year](https://www.reddit.com/r/MachineLearning/comments/85lyjp/p_opportunity_to_assist_with_rl_research/) requesting help for my research project. With all the fantastic help I received, the paper is now completed. My paper entitled Intelligent Computer Interface is available at [this link](https://docs.google.com/document/d/1aNBuz6AemphvAmFaWkQFWymGF39TojJe29UIhg6q1pc/edit?usp=sharing). I welcome any feedback and/or comments. 

Additionally, the source code for my project is available on [my GitHub](https://github.com/nathanShepherd/Intelligent-Interface). ",0,5
489,2018-6-9,2018,6,9,9,8pouhh,Transformers for Speech Recognition?,https://www.reddit.com/r/MachineLearning/comments/8pouhh/transformers_for_speech_recognition/,firedragonxx9832,1528502499,[removed],0,1
490,2018-6-9,2018,6,9,9,8pp0uy,"Hott looking laptop for grad school computer science (Machine learning, data science, and computer vision applications)",https://www.reddit.com/r/MachineLearning/comments/8pp0uy/hott_looking_laptop_for_grad_school_computer/,reddittUndecidedEE,1528504121,[removed],0,1
491,2018-6-9,2018,6,9,10,8pp8vw,"Nvidia, IBM, and Oak Ridge National Laboratory launch world most powerful supercomputer for AI",https://www.reddit.com/r/MachineLearning/comments/8pp8vw/nvidia_ibm_and_oak_ridge_national_laboratory/,AX-BY-CZ,1528506235,,0,1
492,2018-6-9,2018,6,9,10,8ppaho,[R] Deep Reinforcement Learning for General Video Game AI,https://www.reddit.com/r/MachineLearning/comments/8ppaho/r_deep_reinforcement_learning_for_general_video/,wei_jok,1528506640,,0,10
493,2018-6-9,2018,6,9,11,8ppr7p,Active Learning in Recommender Systems Question,https://www.reddit.com/r/MachineLearning/comments/8ppr7p/active_learning_in_recommender_systems_question/,Akawe94,1528511466,[removed],0,1
494,2018-6-9,2018,6,9,11,8ppujn,[P] ml5.js: Friendly Machine Learning For The Web,https://www.reddit.com/r/MachineLearning/comments/8ppujn/p_ml5js_friendly_machine_learning_for_the_web/,chisai_mikan,1528512426,,0,2
495,2018-6-9,2018,6,9,12,8ppzni,Fast.ai part 2 - 2018 tips,https://www.reddit.com/r/MachineLearning/comments/8ppzni/fastai_part_2_2018_tips/,iyaja,1528513928,[removed],0,1
496,2018-6-9,2018,6,9,12,8pq7md,Free gpus for ML learning,https://www.reddit.com/r/MachineLearning/comments/8pq7md/free_gpus_for_ml_learning/,cbsandeep10,1528516260,[removed],0,1
497,2018-6-9,2018,6,9,13,8pqfid,MY CT ST NG KIM LOI 330 chnh hng ct st ng nhanh v mn,https://www.reddit.com/r/MachineLearning/comments/8pqfid/my_ct_st_ng_kim_loi_330_chnh_hng_ct_st/,HangNguyen1111,1528518746,,0,1
498,2018-6-9,2018,6,9,14,8pqtr7,"ml5js  Friendly Machine Learning For The Web. (Try the examples, very cool)",https://www.reddit.com/r/MachineLearning/comments/8pqtr7/ml5js_friendly_machine_learning_for_the_web_try/,UniversalDecentral,1528523769,,0,2
499,2018-6-9,2018,6,9,15,8pr064,[D] Question about Frequentist and Bayesian interpretation of Probability and MLE and MAP.,https://www.reddit.com/r/MachineLearning/comments/8pr064/d_question_about_frequentist_and_bayesian/,newperson77777777,1528526263,"So recently I have been reading about the difference between frequentist and bayesian interpretations of probability. I noticed that, generally, when we maximize the likelihood function (in the frequentist interpretation), we find the argmax of the data, given the parameters, to find the actual parameters of the distribution function for the data. However, the parameters found may not necessarily be the actual parameters. 

For example, given the data sample, a certain set of parameters may maximize your likelihood function, but this sample may be too small, so the parameters found may have deviated considerably from the actual parameters

Or a random set of parameters maximizes the likelihood function because it fits the noise really well but the region around this set of parameters has a very low likelihood, but there be another region of parameters which may have a much higher likelihood. In this case, the actual parameters may be in the other region. 

Are there any confidence estimates for the parameters (maybe that uses bootstrapping or something, Im not too sure)? Like confidence estimates for all parameters found in the model. Like for the above example, if we considered the region in which actual parameters reside, it may be more likely that the actual parameters reside in the second region rather than the first, if we considered the mean of the likelihood function of those regions. Is there analysis that considers confidence estimates for specific parameters that takes everything into account? I know for linear regression you may have p-values associated with coefficients which would suggest that certain coefficients may be more or less likely to be relevant to the regression. Also, I believe there are confidence intervals for the coefficients. Is this applicable to other ML models (both convex and non-convex)? For linear regression, I believe this may attribute a bayesian interpretation to the parameters because now you assume the coefficients are normally distributed, I believe, though Im not really sure.

Similarly, for the bayesian interpretation, we try to maximize the posterior probability of the parameters given the evidence. Similarly, we may find a set of parameters that is most likely, but another set of parameters are the actual parameters or another region is more likely to have the actual parameters. Are there any confidence estimates for the parameters? it seems in this case, we could clearly measure the probability of different regions much easier at least considering we consider the parameters as random variables (also, because the parameters are continuous, the actual probability for a specific set of parameters for the posterior distribution should be zero, right?), and thus we could create estimates and have a degree of confidence in our estimates of the parameters and thus proceed much more smoothly potentially. I dont know if analysis along these lines is used in practice.

Thanks for your help.",14,23
500,2018-6-9,2018,6,9,16,8prbgl,Need help sith machine learning project,https://www.reddit.com/r/MachineLearning/comments/8prbgl/need_help_sith_machine_learning_project/,ripConstantine,1528530735,[removed],0,1
501,2018-6-9,2018,6,9,17,8prhka,"[D] What good sources [papers, books, reports etc.] would you recommend to read on the actual impact of ML on the economy and society?",https://www.reddit.com/r/MachineLearning/comments/8prhka/d_what_good_sources_papers_books_reports_etc/,qamtam,1528533281,"Hey,

I'm making a little presentation on ML for my class. I'm mostly tech\-savvy and that is the main tone of the presentation, however I want to make a section on the actual impact of ML (what industries have already changed because of it, maybe what has changed in the society). I'm not that certain in these aspects, but I want to deepen my knowledge and make well\-informed presentation. I know I can google it, but recommendation from experts on the sources will probably make the presentation more valuable.",7,7
502,2018-6-9,2018,6,9,19,8prwmq,Annotating large documents into separate pieces,https://www.reddit.com/r/MachineLearning/comments/8prwmq/annotating_large_documents_into_separate_pieces/,echan00,1528539572,[removed],0,1
503,2018-6-9,2018,6,9,19,8ps0p5,[R] Are Genetic Models Better Than Random Sampling?,https://www.reddit.com/r/MachineLearning/comments/8ps0p5/r_are_genetic_models_better_than_random_sampling/,jackblun,1528541238,,0,1
504,2018-6-9,2018,6,9,20,8ps4aa,[N] The Big List of DS/ML Interview Resources,https://www.reddit.com/r/MachineLearning/comments/8ps4aa/n_the_big_list_of_dsml_interview_resources/,jackblun,1528542618,,0,1
505,2018-6-9,2018,6,9,20,8ps4nb,Introducing state of the art text classification with universal language models,https://www.reddit.com/r/MachineLearning/comments/8ps4nb/introducing_state_of_the_art_text_classification/,adammathias,1528542750,,0,1
506,2018-6-9,2018,6,9,20,8ps7d5,[R] Improving Medical Imaging Diagnostics Using Azure Machine Learning Package for Computer Vision,https://www.reddit.com/r/MachineLearning/comments/8ps7d5/r_improving_medical_imaging_diagnostics_using/,chris_shpak,1528543818,,0,1
507,2018-6-9,2018,6,9,20,8ps8ga,How to organize ML-models? Use of Studio.ML? Alternatives?,https://www.reddit.com/r/MachineLearning/comments/8ps8ga/how_to_organize_mlmodels_use_of_studioml/,Hakalulu,1528544231,[removed],0,1
508,2018-6-9,2018,6,9,21,8psftg,Question: good Hamloss test mean value.,https://www.reddit.com/r/MachineLearning/comments/8psftg/question_good_hamloss_test_mean_value/,ramgorur,1528546862,[removed],0,1
509,2018-6-9,2018,6,9,21,8psghc,[Project] Realtime Interactive Visualization of Convolutional Neural Networks in Unity (feedback strongly welcomed),https://www.reddit.com/r/MachineLearning/comments/8psghc/project_realtime_interactive_visualization_of/,stefsietz,1528547086,,54,593
510,2018-6-9,2018,6,9,21,8psip1,Chatbots were the next big thing: what happened?,https://www.reddit.com/r/MachineLearning/comments/8psip1/chatbots_were_the_next_big_thing_what_happened/,j_orshman,1528547873,,0,1
511,2018-6-9,2018,6,9,21,8psk5y,Tips for fast.ai course,https://www.reddit.com/r/MachineLearning/comments/8psk5y/tips_for_fastai_course/,iyaja,1528548320,[removed],1,1
512,2018-6-9,2018,6,9,21,8pskv3,Estimation of life expectancy,https://www.reddit.com/r/MachineLearning/comments/8pskv3/estimation_of_life_expectancy/,silentType-r,1528548550,[removed],0,1
513,2018-6-9,2018,6,9,22,8psnze,Probability and Statistics Graduate Level Course,https://www.reddit.com/r/MachineLearning/comments/8psnze/probability_and_statistics_graduate_level_course/,harshitgupta231199,1528549565,[removed],0,1
514,2018-6-9,2018,6,9,23,8pt7yp,[Project] Webapp for playing around with GloVe embeddings,https://www.reddit.com/r/MachineLearning/comments/8pt7yp/project_webapp_for_playing_around_with_glove/,hollowayaegis,1528555368,,3,7
515,2018-6-10,2018,6,10,0,8ptdgb,What is the best path to learn deep learning from scratch.,https://www.reddit.com/r/MachineLearning/comments/8ptdgb/what_is_the_best_path_to_learn_deep_learning_from/,metomezo,1528556784,[removed],0,1
516,2018-6-10,2018,6,10,0,8ptlat,[D] how much luck is involved in training a deep neural net?,https://www.reddit.com/r/MachineLearning/comments/8ptlat/d_how_much_luck_is_involved_in_training_a_deep/,jer_pint,1528558731,"I'm currently dabbling with some reinforcement learning problems using open-ai baselines. Obviously, each training run might be different (games are initialized with a probability distribution), however I'm learning over thousands of iterations so I expect some generalization. 

I've noticed that when keeping all parameters and hyper parameters constant, I get a wide variability in network performance from train to train. Is this expected? Does this mean that not only should I do hyper parameter search, but also for each set of parameters run training a statistically significant amount of times to infer if the network is optimal?",11,12
517,2018-6-10,2018,6,10,1,8ptral,"[P] Primer to Attention (Explaining 'Attention is All You Need') still WIP, feedback appreciated!",https://www.reddit.com/r/MachineLearning/comments/8ptral/p_primer_to_attention_explaining_attention_is_all/,greentfrapp,1528560205,,5,16
518,2018-6-10,2018,6,10,1,8ptxee,[Project] Image segmentation using deeplab,https://www.reddit.com/r/MachineLearning/comments/8ptxee/project_image_segmentation_using_deeplab/,Roots91,1528561672,,2,4
519,2018-6-10,2018,6,10,1,8pu47d,"[Project] Computation of Document Similarity Using Minhashing, LSH and Jaccard Distance",https://www.reddit.com/r/MachineLearning/comments/8pu47d/project_computation_of_document_similarity_using/,elemark,1528563305,,0,12
520,2018-6-10,2018,6,10,2,8pueko,Shunting inhibition neural network,https://www.reddit.com/r/MachineLearning/comments/8pueko/shunting_inhibition_neural_network/,bhupinderr8,1528565705,Any resource/thoughts related to the shunting inhibition neural network used for pattern recognition,0,1
521,2018-6-10,2018,6,10,2,8pujtm,AI Weekly 9 June 2018,https://www.reddit.com/r/MachineLearning/comments/8pujtm/ai_weekly_9_june_2018/,TomekB,1528566932,,0,1
522,2018-6-10,2018,6,10,3,8puov9,[N] Battlefield 1 is using experimental self-learning AI,https://www.reddit.com/r/MachineLearning/comments/8puov9/n_battlefield_1_is_using_experimental/,ImFranny,1528568099,,0,2
523,2018-6-10,2018,6,10,4,8pv112,Machine Learning and Signal Processing,https://www.reddit.com/r/MachineLearning/comments/8pv112/machine_learning_and_signal_processing/,Cyalas,1528570959,[removed],0,1
524,2018-6-10,2018,6,10,4,8pv7mn,Training a neural network in phase-change memory beats GPUs,https://www.reddit.com/r/MachineLearning/comments/8pv7mn/training_a_neural_network_in_phasechange_memory/,UnpredictableFetus,1528572444,,0,1
525,2018-6-10,2018,6,10,5,8pvg52,"[D] Question on blog post ""Autoencoding a single bit"" (Rui Shu)",https://www.reddit.com/r/MachineLearning/comments/8pvg52/d_question_on_blog_post_autoencoding_a_single_bit/,AloneStretch,1528574436,"In the previous reddit post about this blog,
https://www.reddit.com/r/MachineLearning/comments/5o2wro/p_autoencoding_a_single_bit_with_vae/

&gt; egrefen commented:
I found this article a little meh. It's clear that the VAE won't do anything in both of the datasets provided since you don't need the latent variable. Any trivial model will be able to perfectly estimate p(x) from the data, without needing a latent factor. It has nothing to do with the choice of prior or proposal distribution, and everything to do with the problem at hand not requiring additional expressivity.

&gt; The post is mistakenly set up to be about VAEs, but misses the point that latent variable models are not needed for the datasets provided full stop, regardless of the inference mechanism.

Can anyone explain this comment? I do not see it but really want to understand.

It seems to me (maybe wrong) that in the VAE two extreme cases or possible, or anything
in between them. 

1. The probability of *all* the data, p(x), is learned (or approximately learned), and the latent is not used.
That is what happened in the blog post. Taking account the autoencoder-like strucure,
it learned ""p(x=1|x=1)=0.5,  p(x=0|x=1) = 0.5"" which is a failure.

2. The network learns to predict the value of *each* data point individually, and the latent is required to do this.
If it is also able to shrink the variance, then the likelihood can be made very high, and exceed case #1.  I believe this is the expected and desired behaviour.
We want p(x=1|x=1) = 1.

Improving the likelihood/minimizing the NLL is a cost which favours case #2. However my interpretation was that in the particular example, the KL term completely outweigh this, for reasons I do not understand.",11,4
526,2018-6-10,2018,6,10,5,8pvk3y,Where To Go From Here?,https://www.reddit.com/r/MachineLearning/comments/8pvk3y/where_to_go_from_here/,OreGus,1528575362,[removed],0,1
527,2018-6-10,2018,6,10,5,8pvr23,[D] Which is more important: (i) good representation / basis or (ii) theory on how to provide more efficient parameter updates?,https://www.reddit.com/r/MachineLearning/comments/8pvr23/d_which_is_more_important_i_good_representation/,gratenewseveryone,1528577029,"The question is meant to be open\-ended, based on a general statement I heard a well known ml researcher make in a keynote talk.  The researcher's claim was that good representation is less important than having efficient parameter updates.  

I'm wondering what reddit thinks and why.  

Please vote with karma.",3,0
528,2018-6-10,2018,6,10,6,8pw6xk,Build Handwriting Recognizer With Neural Network &amp; Ship It To App Store,https://www.reddit.com/r/MachineLearning/comments/8pw6xk/build_handwriting_recognizer_with_neural_network/,melodyfs,1528581039,,2,0
529,2018-6-10,2018,6,10,7,8pw9lg,YOLO for Real-Time Food Detection,https://www.reddit.com/r/MachineLearning/comments/8pw9lg/yolo_for_realtime_food_detection/,btscheung,1528581719,[removed],0,1
530,2018-6-10,2018,6,10,7,8pwbi4,Data.gov: Open data provided by the U.S. government,https://www.reddit.com/r/MachineLearning/comments/8pwbi4/datagov_open_data_provided_by_the_us_government/,InsideAnalysis,1528582205,,0,1
531,2018-6-10,2018,6,10,7,8pwgh7,[D] Thoughts On ICLR 2018 and ICRA 2018,https://www.reddit.com/r/MachineLearning/comments/8pwgh7/d_thoughts_on_iclr_2018_and_icra_2018/,hardmaru,1528583509,,0,43
532,2018-6-10,2018,6,10,8,8pwrlr,[N] AMD Demos 7nm Vega GPU (32 GB of HBM2 memory),https://www.reddit.com/r/MachineLearning/comments/8pwrlr/n_amd_demos_7nm_vega_gpu_32_gb_of_hbm2_memory/,SkiddyX,1528586523,,24,41
533,2018-6-10,2018,6,10,8,8pwv2x,Image pre processing techniques for Keras CNN - Feature Extraction,https://www.reddit.com/r/MachineLearning/comments/8pwv2x/image_pre_processing_techniques_for_keras_cnn/,ChanceJuggernaut,1528587442,[removed],0,1
534,2018-6-10,2018,6,10,9,8px7r2,[R] A simple example for data augmentation of time-series data,https://www.reddit.com/r/MachineLearning/comments/8px7r2/r_a_simple_example_for_data_augmentation_of/,terryum,1528590797,,15,51
535,2018-6-10,2018,6,10,9,8px7uf,[P] Dimensionality reduction for time series data (with just 2 features)?,https://www.reddit.com/r/MachineLearning/comments/8px7uf/p_dimensionality_reduction_for_time_series_data/,surf_book,1528590825,"So I have time series data for a point that moves around (in the x,y plane). Which means I have only 2 raw features.

This means the information is mostly embedded in the time domain. Methods like PCA can reduce a large number of features to fewer; but what are the ways to do this for a time series data with so few features?

[This RNN autoencoder](https://github.com/RobRomijnders/AE_ts ""Github link"") seems to achieve something similar for a 1D ECG waveform, could someone explain this in further detail and the intuition? 

I'm imagining something like artificially creating a feature vector as long at each time step, which records all the time steps before it; and then doing PCA on these new columns. Is this correct?

Thank you! ",23,10
536,2018-6-10,2018,6,10,10,8pxi0n,Can machine learning and neural networks make Role playing games more interesting?,https://www.reddit.com/r/MachineLearning/comments/8pxi0n/can_machine_learning_and_neural_networks_make/,Darzin,1528593582,[removed],0,1
537,2018-6-10,2018,6,10,10,8pxmcu,[D] Results of Conditionally Thresholded CNN's for Weakly Supervised Segmentation,https://www.reddit.com/r/MachineLearning/comments/8pxmcu/d_results_of_conditionally_thresholded_cnns_for/,ACTBRUH,1528594869,"Theory I posted a week ago is here: https://scientificattempts.wordpress.com/2018/06/03/conditionally-thresholded-cnns-for-weakly-supervised-image-segmentation/

Here's the new post including the results of the experiment : https://scientificattempts.wordpress.com/2018/06/10/conditionally-thresholded-cnns-for-weakly-supervised-image-segmentation-results/

Unfortunately, the idea didn't work, but then again, that is the point of this blog, to talk about ALL of the random ideas I have, even if they don't turn out to work. Again, let me know if you have any criticisms/areas for improvement, I'd like to continue writing on this blog and would love to improve my writing. Suggestions for future posts would also be great!",0,19
538,2018-6-10,2018,6,10,10,8pxoek,[Suggestion] What are the hardware requirements for learning and experimenting Machine Learning / AI / Deep Learning ?,https://www.reddit.com/r/MachineLearning/comments/8pxoek/suggestion_what_are_the_hardware_requirements_for/,DronzerDribble,1528595464,[removed],0,1
539,2018-6-10,2018,6,10,12,8py66y,Question about Time Series Forecasting with RNN - Rstudio blogpost,https://www.reddit.com/r/MachineLearning/comments/8py66y/question_about_time_series_forecasting_with_rnn/,mr-datascientist,1528600759,,0,1
540,2018-6-10,2018,6,10,15,8pyz74,Can I have a real tutorial for q-learning,https://www.reddit.com/r/MachineLearning/comments/8pyz74/can_i_have_a_real_tutorial_for_qlearning/,Guyisntcool,1528610643,[removed],0,1
541,2018-6-10,2018,6,10,17,8pzkc9,"[D] We work with amazing every day people, like yourself; to help empower individuals to develop small but hugely impactful habits. Check out our book.",https://www.reddit.com/r/MachineLearning/comments/8pzkc9/d_we_work_with_amazing_every_day_people_like/,NanohabitsTeam2,1528619759,"We work with amazing every day people, like yourself; to help empower individuals to develop small but hugely impactful habits. Check out our book. [https://www.indiegogo.com/projects/nanohabit\-handbook\-small\-habits\-with\-big\-impacts\-books\-design/reft/18795506/upwork\-01](https://www.indiegogo.com/projects/nanohabit-handbook-small-habits-with-big-impacts-books-design/reft/18795506/upwork-01)",0,0
542,2018-6-10,2018,6,10,18,8pznye,1 ! - G.S ,https://www.reddit.com/r/MachineLearning/comments/8pznye/1_gs_/,Woodworking94,1528621436,,0,1
543,2018-6-10,2018,6,10,18,8pzsjk,Quick question about Artificial intelligence and where we currently stand in Human History.,https://www.reddit.com/r/MachineLearning/comments/8pzsjk/quick_question_about_artificial_intelligence_and/,TheRealGianniBrown,1528623509,"Over the years, I've seen people build companies and/or products that have changed the World. Whether it's the iPhone, Virtual Assistances, and even cars that drive themselves. But with all this technology that has been created and given to the public, it's hard to find someone who doesn't have an iPad or MacBook. It's impossible to find someone who doesn't have a Smartphone like iPhone, Android, etc.

But with everything that has been created, one of the most innovating World Changing inventions has to be Artificial intelligence. Whether it's Alexa, Cortana, Siri or one of the other Virtual Assistants, inventions like those has been World Changing. It doesn't even have to be a Virtual Assistant. Countless Websites, Companies, Apps and places like those has Artificial intelligence carry a lot of the work load also.

\*\*So my question is this...\*\*

This might sound like I'm trying to be funny or make a joke but I'm seriously wondering. With everything that has been created and improved upon with Artificial intelligence, how close are we to living in a World like that Will Smith movie, I, Robot,"" or even something like, ""*2001: A Space Odyssey."" ??*

Are we getting closer to living in a World like those where AI has become too smart and decides to ensalve us all? Or are we still MANY, MANY, MANY YEARS away from something like that even remotely happening? Should I have my bags packed and start building a bunker to be prepared because we're close and it could happen at any moment? 

\*\*Lastly...\*\*\*

Whether we're close or not, just so I can be prepared for it happen, if it does happen. What would your guys, ""go\-to sign,"" for when it finally happens?  What should I look for as a sign of it's happening? Like a specific event or moment to where when it happen, that's my signal to let me know shit's about to go down. Lol",0,1
544,2018-6-10,2018,6,10,20,8q04dl,DCGAN Generator Output is terrible?,https://www.reddit.com/r/MachineLearning/comments/8q04dl/dcgan_generator_output_is_terrible/,jfishersolutions,1528628705,,0,1
545,2018-6-10,2018,6,10,20,8q04em,Everything about machine learning,https://www.reddit.com/r/MachineLearning/comments/8q04em/everything_about_machine_learning/,stuartown,1528628715,,0,1
546,2018-6-10,2018,6,10,20,8q05ox,Distilling language,https://www.reddit.com/r/MachineLearning/comments/8q05ox/distilling_language/,rhys5584,1528629249,[removed],0,1
547,2018-6-10,2018,6,10,20,8q08wv,  - ,https://www.reddit.com/r/MachineLearning/comments/8q08wv/__/,Woodworking94,1528630580,,0,1
548,2018-6-10,2018,6,10,20,8q0acb,[R] Variational Implicit Processes,https://www.reddit.com/r/MachineLearning/comments/8q0acb/r_variational_implicit_processes/,undefdev,1528631158,,0,11
549,2018-6-10,2018,6,10,20,8q0bgr,[P] Learning Approximate Inference Networks for Structured Prediction (ICLR '18) - TensorFlow Implementation,https://www.reddit.com/r/MachineLearning/comments/8q0bgr/p_learning_approximate_inference_networks_for/,martianwars,1528631618,,4,64
550,2018-6-10,2018,6,10,23,8q14um,[P] Polyaxon  An open source platform for reproducible machine learning at scale,https://www.reddit.com/r/MachineLearning/comments/8q14um/p_polyaxon_an_open_source_platform_for/,j_orshman,1528640922,,0,3
551,2018-6-11,2018,6,11,0,8q1feh,Gaming the peer review system at NIPS'18,https://www.reddit.com/r/MachineLearning/comments/8q1feh/gaming_the_peer_review_system_at_nips18/,quagmire_giggity,1528643701,[removed],0,1
552,2018-6-11,2018,6,11,0,8q1k0b,Canine locomotion patterns fr games/simulations [SIGGRAPH],https://www.reddit.com/r/MachineLearning/comments/8q1k0b/canine_locomotion_patterns_fr_gamessimulations/,hockiklocki,1528644880,,1,1
553,2018-6-11,2018,6,11,0,8q1o1r,Automatic text classification,https://www.reddit.com/r/MachineLearning/comments/8q1o1r/automatic_text_classification/,Spain_iS_pain,1528645875,[removed],0,1
554,2018-6-11,2018,6,11,1,8q1rnu,I want to start learning Machine learning. So while I was looking for its courses i found 2 good sources to learn M.L. One is a cousera course by Andrew ng and other is Google's open M.L course. But i want to refer only one course among those two. So which one should i prefer Among those two??,https://www.reddit.com/r/MachineLearning/comments/8q1rnu/i_want_to_start_learning_machine_learning_so/,sriram1011,1528646781,,0,1
555,2018-6-11,2018,6,11,2,8q2f3i,Anyone familiar with brain.js ? How do you use date as input ?,https://www.reddit.com/r/MachineLearning/comments/8q2f3i/anyone_familiar_with_brainjs_how_do_you_use_date/,DoveLux,1528652475,[removed],0,1
556,2018-6-11,2018,6,11,3,8q2m8v,Basic Natural Gradients in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8q2m8v/basic_natural_gradients_in_tensorflow/,Azzu98,1528654116,,1,5
557,2018-6-11,2018,6,11,3,8q2op9,Some problems on Knowledge Graph representation learning,https://www.reddit.com/r/MachineLearning/comments/8q2op9/some_problems_on_knowledge_graph_representation/,entslscheia,1528654688,[removed],0,1
558,2018-6-11,2018,6,11,3,8q2rh5,Build a voice interface in three minutes with PORCUPiNE,https://www.reddit.com/r/MachineLearning/comments/8q2rh5/build_a_voice_interface_in_three_minutes_with/,alikenar,1528655335,,0,1
559,2018-6-11,2018,6,11,3,8q2yab,Need assistance on developing a Threat Prediction Algorithm,https://www.reddit.com/r/MachineLearning/comments/8q2yab/need_assistance_on_developing_a_threat_prediction/,VileMissile,1528656919,[removed],0,1
560,2018-6-11,2018,6,11,4,8q35za,[N] Recommender systems behind the scenes,https://www.reddit.com/r/MachineLearning/comments/8q35za/n_recommender_systems_behind_the_scenes/,khozzy,1528658711,,0,0
561,2018-6-11,2018,6,11,4,8q3cb4,[R] Why do deep convolutional networks generalize so poorly to small image transformations?,https://www.reddit.com/r/MachineLearning/comments/8q3cb4/r_why_do_deep_convolutional_networks_generalize/,_jamorton,1528660227,,31,180
562,2018-6-11,2018,6,11,4,8q3dvo,[P] Multivariate Data evaluation with power constraint,https://www.reddit.com/r/MachineLearning/comments/8q3dvo/p_multivariate_data_evaluation_with_power/,WolframVonEschenbach,1528660598,"Hi i want to test if it would be possible to do artifact detection and/or model order reduction on 19\-channel EEG data on an dedicated hardware with a cr2032 battery (so ultra low Power).

So far I would choose sequential PCA for the model order reduction and self organized Maps (or k means clustering) for the artifact detection.

Maybe someone more experienced than me could help me with some remaining questions or tell me if I am on the right track:

* Artifacts:
   * Can you detect artifacts in the time domain, even when they are in the frequency domain (I assume it is possible if you do something like sliding window and take some samples at once). 
   * is there an algorithm that has very low computation for the online evaluation.
   * I read somewhere that SOM is very outdated and nobody uses it anymore, is this correct?
* Compression:
   * I assume I need a data dependent compression technique. Is there a one with lower computational needs in the online phase than PCA.
   * is there any data on the power requirements of online and offline computation of PCA?

I will test the PCA and SOM on EEG data in python in the upcoming week so I will keep you updated if anyone is interested.",0,2
563,2018-6-11,2018,6,11,5,8q3g42,measuring data complexity,https://www.reddit.com/r/MachineLearning/comments/8q3g42/measuring_data_complexity/,mynameisvinn,1528661116,[removed],0,1
564,2018-6-11,2018,6,11,7,8q4aad,[D] Question about statement in Adversarial Autoencoders paper,https://www.reddit.com/r/MachineLearning/comments/8q4aad/d_question_about_statement_in_adversarial/,AloneStretch,1528668180,"In Makhzani et la.'s paper Adversarial Autoencoders [arxiv](https://arxiv.org/pdf/1511.05644.pdf)
Page 4 it says:
""However, no data points map to several local regions of the coding space indicating that the VAE may not have captured the data manifold as well as the adversarial autoencoder.

Can anyone explain better what this means?

Looking at the figure (2c), looking the red points for example, the red points are mostly in the middle,
but there are a few scattered elsewhere.  For figure (2a) which is the adversarial AE, I think I also
see red points scattered away from their main cluster.

But this may not be what is meant.  Does it mean a single data point has to map to several points in latent space?
If so, why is this a good thing for capturing the manifold?  And how could you ever see this on a plot such as Figure 2, that only shows the latent and not what data maps to which latent?
",3,2
565,2018-6-11,2018,6,11,7,8q4ip1,Exposing a Word2vec Model with a RESTful API Using Only a Jupyter Notebook (No Web-Development Skills Required!),https://www.reddit.com/r/MachineLearning/comments/8q4ip1/exposing_a_word2vec_model_with_a_restful_api/,tmthyjames,1528670190,,0,1
566,2018-6-11,2018,6,11,8,8q4y63,Power requirements for ML workstations.,https://www.reddit.com/r/MachineLearning/comments/8q4y63/power_requirements_for_ml_workstations/,linuxman1929,1528674116,[removed],0,1
567,2018-6-11,2018,6,11,9,8q58xm,"[D] In DNNs, since Softmax is a generalization for the logistic function (sigmoid), does it suffer from the vanishing gradient problem?",https://www.reddit.com/r/MachineLearning/comments/8q58xm/d_in_dnns_since_softmax_is_a_generalization_for/,adkyary,1528676935,"If yes, then why don't people talk about it?

If no, then should I use Softmax in place of sigmoid even for binary classification problems?",16,1
568,2018-6-11,2018,6,11,10,8q5krq,Recommended Comp Specs for ML,https://www.reddit.com/r/MachineLearning/comments/8q5krq/recommended_comp_specs_for_ml/,MagFraggins,1528680178,[removed],0,1
569,2018-6-11,2018,6,11,10,8q5o1c,[Question] What are some new ideas where ML is used to improve Academic learning?,https://www.reddit.com/r/MachineLearning/comments/8q5o1c/question_what_are_some_new_ideas_where_ml_is_used/,ThinScreen,1528681073,,0,1
570,2018-6-11,2018,6,11,10,8q5ppx,"I'm a ""gifted"" developer that learns better through conversation. I want to have a surface level conversation about ML",https://www.reddit.com/r/MachineLearning/comments/8q5ppx/im_a_gifted_developer_that_learns_better_through/,ActionMcJackson,1528681517,[removed],0,1
571,2018-6-11,2018,6,11,11,8q622t,"Commentary on the potential for, and limitations of, machine learning in #suicide #prediction.",https://www.reddit.com/r/MachineLearning/comments/8q622t/commentary_on_the_potential_for_and_limitations/,Science_Podcast,1528684865,,0,1
572,2018-6-11,2018,6,11,11,8q64eq,"Commentary on the potential for, and limitations of, machine learning in suicide prediction: Why predicting suicide is a difficult and complex challenge.",https://www.reddit.com/r/MachineLearning/comments/8q64eq/commentary_on_the_potential_for_and_limitations/,Science_Podcast,1528685478,,0,1
573,2018-6-11,2018,6,11,12,8q6b5d,[N] Talk: Building the Software 2.0 Stack by Andrej Karpathy,https://www.reddit.com/r/MachineLearning/comments/8q6b5d/n_talk_building_the_software_20_stack_by_andrej/,Daniloz,1528687171,,3,19
574,2018-6-11,2018,6,11,13,8q6o1d,nu bn ang c nhu cu mua t siu th th bn ng b qua nhng vn  v kch thc thit k sau. Bn hy xem ngay bi vit ny  cc bn c th la chn mt chic t siu th ph hp.,https://www.reddit.com/r/MachineLearning/comments/8q6o1d/nu_bn_ang_c_nhu_cu_mua_t_siu_th_th_bn/,hoangngan123,1528690699,,0,1
575,2018-6-11,2018,6,11,14,8q70as,DeepMinds Amazing Mix &amp; Match RL Technique,https://www.reddit.com/r/MachineLearning/comments/8q70as/deepminds_amazing_mix_match_rl_technique/,sagarsharma4244,1528694512,,0,1
576,2018-6-11,2018,6,11,14,8q749y,Inferring relevant features: from QFT to PCA,https://www.reddit.com/r/MachineLearning/comments/8q749y/inferring_relevant_features_from_qft_to_pca/,mhlr,1528695772,,0,1
577,2018-6-11,2018,6,11,14,8q75lv,How easy to set up egpu?,https://www.reddit.com/r/MachineLearning/comments/8q75lv/how_easy_to_set_up_egpu/,errminator,1528696221,[removed],0,1
578,2018-6-11,2018,6,11,14,8q762e,[R] Inferring relevant features: from QFT to PCA,https://www.reddit.com/r/MachineLearning/comments/8q762e/r_inferring_relevant_features_from_qft_to_pca/,mhlr,1528696372,,1,11
579,2018-6-11,2018,6,11,15,8q7ard,[D] What happened to u/arXiv_abstract_bot?,https://www.reddit.com/r/MachineLearning/comments/8q7ard/d_what_happened_to_uarxiv_abstract_bot/,mhlr,1528697898,About a year ago u/arXiv_abstract_bot used to add the abstract and authors to arxiv links. What happened to it? Can it be re\-enabled? I found it very useful.,5,37
580,2018-6-11,2018,6,11,15,8q7fng,How do I get started immediately?,https://www.reddit.com/r/MachineLearning/comments/8q7fng/how_do_i_get_started_immediately/,lifeform999,1528699515,[removed],0,1
581,2018-6-11,2018,6,11,16,8q7muh,In today's job market how important is getting a master's for a successful career as an machine learning engineer/data scientist ?,https://www.reddit.com/r/MachineLearning/comments/8q7muh/in_todays_job_market_how_important_is_getting_a/,chubbyunicorn47,1528701914,[removed],0,1
582,2018-6-11,2018,6,11,16,8q7sne,using ML and facial recognition to create an image filter,https://www.reddit.com/r/MachineLearning/comments/8q7sne/using_ml_and_facial_recognition_to_create_an/,EquivalentWestern,1528703994,"Hello everyone, 

How are you? I have been thinking about creating an application that would scan the webpages i visit for certain people, and then pixelate their faces wherever they appear! I have an intermediate level of understanding in ML, mainly scikit\-learn, and was hoping if there are other people out there who would like to join me on this project. 

Thank you for your time.",0,1
583,2018-6-11,2018,6,11,17,8q81og,Why log() in Inverse Document Frequency?,https://www.reddit.com/r/MachineLearning/comments/8q81og/why_log_in_inverse_document_frequency/,reallyserious,1528707469,[removed],0,1
584,2018-6-11,2018,6,11,18,8q85eh,Intro to evaluation metrics for predictive models and how to use them in Spark MLlib,https://www.reddit.com/r/MachineLearning/comments/8q85eh/intro_to_evaluation_metrics_for_predictive_models/,iosman,1528708852,,0,1
585,2018-6-11,2018,6,11,18,8q86as,ML for Personal Finance?,https://www.reddit.com/r/MachineLearning/comments/8q86as/ml_for_personal_finance/,pretysmitty,1528709175,Do any programs out there collect all of your inputs (income) and outputs (expenditures) and organize them according to different categories? How accurate are they for use?,0,1
586,2018-6-11,2018,6,11,18,8q86eh,Snippet to load and preprocess images in Keras to train a model (it does not need even normalize them),https://www.reddit.com/r/MachineLearning/comments/8q86eh/snippet_to_load_and_preprocess_images_in_keras_to/,ianholing,1528709209,[removed],1,1
587,2018-6-11,2018,6,11,18,8q88s2,[D]Can computer learn with another computer to mimic human behavior?,https://www.reddit.com/r/MachineLearning/comments/8q88s2/dcan_computer_learn_with_another_computer_to/,sanketvaria29,1528710063,Ok first of all may be i was not clear in my title. Let's say that with the help of neural networks if we tell an agent to learn playing chess with an human user it will probably learn how to beat human user eventually but everybody plays the game very differently so it will require lots of generations and we will need lots of human beings to actually play. Now let's consider this that as a game designer if i want an AI to be able beat human beings and i tell people online to play and if an agent tries to learn from it then probably people will never the play the game after its launch because they might have already played it when they were contributing in agent's training. So what if 2 agents compete each other? what does that will result? because now in this scenario both agents are learning from each other plus they are improving one by one but since none of them are human probably their behavior would be quite robotic. What do you guys think?,5,0
588,2018-6-11,2018,6,11,19,8q8bzo,[D] Data Driven (Machine Learning) Control - Steve Brunton,https://www.reddit.com/r/MachineLearning/comments/8q8bzo/d_data_driven_machine_learning_control_steve/,rbkillea,1528711214,,8,59
589,2018-6-11,2018,6,11,19,8q8caj,Simple web UI for ML algorithms?,https://www.reddit.com/r/MachineLearning/comments/8q8caj/simple_web_ui_for_ml_algorithms/,dr_charlesA,1528711315,[removed],0,1
590,2018-6-11,2018,6,11,19,8q8fx7,How Gradient descent works - Tutorial,https://www.reddit.com/r/MachineLearning/comments/8q8fx7/how_gradient_descent_works_tutorial/,crazy_boss_reloaded,1528712510,,0,1
591,2018-6-11,2018,6,11,19,8q8lce,HELP: Need idea for the Machine Learning Project,https://www.reddit.com/r/MachineLearning/comments/8q8lce/help_need_idea_for_the_machine_learning_project/,NammRoxo,1528714324,[removed],0,1
592,2018-6-11,2018,6,11,20,8q8pl3,Automatic Zelalem Injera Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8q8pl3/automatic_zelalem_injera_machine_for_sale/,lgsherry,1528715650,,1,1
593,2018-6-11,2018,6,11,20,8q8t7n,[D] Project approach for mitosis detection - Feedback welcome,https://www.reddit.com/r/MachineLearning/comments/8q8t7n/d_project_approach_for_mitosis_detection_feedback/,chrisk_,1528716749,"Hi There!

I'm currently working on a project for my master's studies on mitosis detection for which I got data from a hospital. Since I'm not very experienced in computer vision tasks (yet), I'd like to get some feedback from experienced people on how to tackle my problem. For those who are unfamiliar with mitosis detection - mitosis detection basically comprises the counting of dividing nuclei on hematoxylin &amp; eosin whole slide images (note: that's my very newbie definition as a non-medical practitioner. Sorry, if this is not exactly on point ;-) ). If you are familiar with the recent Data Science Bowl challenge on Kaggle, that's basically an extension of the task. You can find a very good explanation of the background from this link: http://tupac.tue-image.nl/node/2

**Objective**
So the objective of my project is, as I've already hinted, to detect mitoses on images that I got from a hospital.  There is already done work on mitosis detection in literature, however most of them don't cope with the problems and constraints I have in my project. Thus, I might just get some rough ideas but I'm not sure how to connect them in order to apply them on my problem setting.

**Dataset(s)**
Here's the thing: The dataset I got from the hospital is not 'ready-to-go' annotated. The only information I have is somewhat an arrow-annotation that indicates that near the head of the arrow is a mitosis. So the two options I have (and that I can come up with) are: 

- Annotating them further which is very time-consuming (depending on the annotation to do) and then train directly on this data
- Train on publicly available datasets and hope that the model generalizes well on the hospital data.

I did some screenshots of image crops and the annotations of the hospital data in following link, so that you can get a rough impression of the data: https://imgur.com/a/1YvRn8k

You can already notice that there's a lot of morphological-invariance of the mitosis (i.e. the shape of the mitosis) and also stain-invariance (i.e. the intensity of colours) between the slides. 

As for publicly available dataset, I have found the following:

- ICPR'12 Mitosis Detection Challenge: http://ludo17.free.fr/mitos_2012/download.html
  This dataset has the mitoses segmented, i.e. the vertices of a polygon are provided. Also it is relatively small (both in terms of slides and mitotic figures). Important to note: The stain and morphological invariance is not that distinct
- ICPR'14 Mitosis Detection Challenge: https://mitos-atypia-14.grand-challenge.org/home/
  This dataset has only the centroid of the mitosis annotated. There's also information on non-mitotic figures that could be detected as mitosis. The dataset is also larger then the ICPR'12. However, the variance is low.
- TUPAC Mitosis Detection Challenge: http://tupac.tue-image.nl/node/3
  This dataset has also only the centroid of the mitosis annotated. However, this dataset is much richer of 
  slide and mitosis variance and is also relatively large. 

Many papers that I've found work only with the first two datasets, however, as I've said, I don't think these datasets capture enough variance so that their work would be applicable on my dataset.

**Approaches/Ideas**

Due to the somewhat hard-constraints I have regarding the datasets, I was gathering about approaches and ideas how to tackle this problem. This includes on how to model this problem, i.e. do a segmentation or an object detection or maybe even only a classification. Since I only need to count the mitosis in an image, a simple integer as output could be sufficient but I think it would also be nice to locate them in any way. But I'm not sure which modelling approach would be feasible regarding the annotation of the datasets I have.

There's one approach that I've tried out so far (and failed miserably):

I made this problem a segmentation problem. For this, I used the out-of-the-box Mask-RCNN from matterport (https://github.com/matterport/Mask_RCNN) which was quite often used in the Data Science Bowl challenge and also has a sample of application in the DSB in the git. So my idea was to train a model on Mask-RCNN on the DSB data, since I thought the general appearance of the DSB data is a little similar to the mitosis data. Then used this model to do a transfer learning on the ICPR'12 dataset. But when applying the learned model on the ICPR'12 dataset it failed miserably on the hospital dataset as I get many false positives, especially in the cases where the colours are more intense like the one in the second screenshot.

A very simple, but naive and slow (and old) approach would be the one by Ciresan et al. [1]. They basically did a classification by training on positive and negative patches so that the model would predict whether there is a mitosis in the center of the patch or not. That implies that I would need to center every pixel of the slides (which are btw. roughly 4500x4500 for the hospital dataset) and run it through the network. However, I think it would be a good starter baseline as the approach is simple and there not much too much magic behind it that you need to tweak whatsoever. 

Nevertheless, I'm tempted to try some newer approaches that are available for object detection and instance/semantic segmentation. I believe, if the problem is modelled correctly, they would give better results. The obvious architectures are of course something like Faster-RCNN, Mask-RCNN, any kind of U-Net. However, I'm not sure how to make use of the datasets for this, especially the ones that only have the centroids. Is it for Mask-RCNN or U-Net sufficient to provide the centroid of an object as a label? Then I could throw everything together and see what's happening. Overall, I'm also not sure if a 1-class annotation is good in general or if I should provide more classes as annotation, for example another class for nuclei which of course appear in a huge number in the slides. 

And of course there are other tweaks that I thought about incorporating and that would maybe help the problem, for example Focal Loss, a sort of data augmentation like in [2] etc.


As for evaluation, the official metrics of the ICPR'12/ICPR'14 is appropriate in my opinion. They calculate F1-Score on the basis of the distance between the centroid of the prediction and the centroid if the ground truth. So if it's the predicted centroid is in range of x pixels from the ground truth centroid then it's a true positive otherwise false positive/negative. This is a flexible metric and can be applied to any annotation. But I'm of course open for any other suggestions.

So bottom-line: 

Sorry for the wall of text but I don't think I could have done a tl;dr version of my problem. As I said, I'm still unsure how to tackle this problem and besides trying out the Mask-RCNN approach, I'm also at the very beginning. I believe the most important question right now is: Can I work with the publicly available data or do I need to get more data? The latter would of course imply that I have to annotate my dataset further which costs a lot of time. I realize that this question cannot be answered beforehand and needs to be somewhat experimentally evaluated. If I was going to use only the public datasets which approach would you design? Is there a way you can think of to make it a segmentation task or at least an object detection task? 

I would be really glad to head some feedback from you guys. Thanks a lot for your time!


[1] http://people.idsia.ch/~ciresan/data/miccai2013.pdf

[2] https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10581/105810Z/H-and-E-stain-augmentation-improves-generalization-of-convolutional-networks/10.1117/12.2293048.short?SSO=1


",1,8
594,2018-6-11,2018,6,11,21,8q904z,Machine Learning Top 10 Articles for the Past Month (v.June 2018),https://www.reddit.com/r/MachineLearning/comments/8q904z/machine_learning_top_10_articles_for_the_past/,kumeralex,1528718787,,10,185
595,2018-6-11,2018,6,11,21,8q91xm,[P] Deep Learning for Videos: A 2018 Guide to Action Recognition,https://www.reddit.com/r/MachineLearning/comments/8q91xm/p_deep_learning_for_videos_a_2018_guide_to_action/,saucysassy,1528719259,,0,7
596,2018-6-11,2018,6,11,21,8q92bf,Generative adversarial networks with Julia,https://www.reddit.com/r/MachineLearning/comments/8q92bf/generative_adversarial_networks_with_julia/,elcric_krej,1528719366,,0,1
597,2018-6-11,2018,6,11,21,8q93p7,https://arxiv.org/abs/1805.12177,https://www.reddit.com/r/MachineLearning/comments/8q93p7/httpsarxivorgabs180512177/,j_orshman,1528719760,[removed],0,1
598,2018-6-11,2018,6,11,21,8q98qs,[N] Statistics and Data Science MicroMasters Program - MIT,https://www.reddit.com/r/MachineLearning/comments/8q98qs/n_statistics_and_data_science_micromasters/,upulbandara,1528721108,,3,1
599,2018-6-11,2018,6,11,21,8q99kr,Application specific machine learning resources,https://www.reddit.com/r/MachineLearning/comments/8q99kr/application_specific_machine_learning_resources/,PolitenessWeekIsOver,1528721311,[removed],0,1
600,2018-6-11,2018,6,11,21,8q9ae8,Is the Braess Paradox related to Dropout in Neural Nets ?,https://www.reddit.com/r/MachineLearning/comments/8q9ae8/is_the_braess_paradox_related_to_dropout_in/,themoderndayhercules,1528721540,,5,15
601,2018-6-11,2018,6,11,21,8q9bbr,JCB ServiceMaster 4,https://www.reddit.com/r/MachineLearning/comments/8q9bbr/jcb_servicemaster_4/,Mypremiummanual,1528721780,,0,1
602,2018-6-11,2018,6,11,22,8q9q50,[P] Data Augmentation for Semantic Segmentation with PyTorch and imgaug,https://www.reddit.com/r/MachineLearning/comments/8q9q50/p_data_augmentation_for_semantic_segmentation/,fabioperez,1528725492,,1,3
603,2018-6-11,2018,6,11,23,8q9s0s,Sign recognition using CNN in Keras and OpenCV,https://www.reddit.com/r/MachineLearning/comments/8q9s0s/sign_recognition_using_cnn_in_keras_and_opencv/,adarsh1021,1528725902,,0,1
604,2018-6-11,2018,6,11,23,8qa23l,Wine recommendation algorithm?,https://www.reddit.com/r/MachineLearning/comments/8qa23l/wine_recommendation_algorithm/,davethedingle,1528728198,[removed],0,1
605,2018-6-12,2018,6,12,0,8qa71j,Reinforcement Learning for huge state spaces but without Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/8qa71j/reinforcement_learning_for_huge_state_spaces_but/,koko_c,1528729253,[removed],0,1
606,2018-6-12,2018,6,12,0,8qa7b8,[R] Participate in research survey. Chance to win $50 Visa gift card.,https://www.reddit.com/r/MachineLearning/comments/8qa7b8/r_participate_in_research_survey_chance_to_win_50/,IBM_dpiorkowski,1528729307,"Our team at IBM Research is running a research study to understand the barriers that practitioners face when using machine learning, deep learning, and AI in the context of building models and/or software. We are looking for participants willing to take a 15\-30 minute survey to better understand these barriers. One lucky participant will win a **$50 gift card** at the end of the survey period. (See full terms and conditions [here](http://ai-survey.mybluemix.net/terms.html)).

This survey is anonymous. We know your privacy is important to you, and we are committed to protecting it. Your responses to this survey will be kept private and used only for the purposes of this study, research publications, and future IBM Research AI projects. All results are anonymized and confidential and reported results will be anonymized and in aggregate.

**To participate, click** [**here**](http://ai-survey.mybluemix.net/index.php/673946?lang=en)**.**

Thank you for your help. We very much appreciate your time and your input.",0,0
607,2018-6-12,2018,6,12,0,8qaelb,Is Google Duplex A Jump In Advancement For Humanity?,https://www.reddit.com/r/MachineLearning/comments/8qaelb/is_google_duplex_a_jump_in_advancement_for/,EmotionalGood,1528730836,[removed],0,1
608,2018-6-12,2018,6,12,0,8qah81,[P] Speech Recognition with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8qah81/p_speech_recognition_with_tensorflow/,tttttm,1528731377,,0,3
609,2018-6-12,2018,6,12,0,8qajg4,[Discussion] Gaming the peer review system at NIPS '18.,https://www.reddit.com/r/MachineLearning/comments/8qajg4/discussion_gaming_the_peer_review_system_at_nips/,quagmire_giggity,1528731820,"I recently heard (not a reviewer myself) that NIPS follows a bidding process for papers. While the original intent was to get the most interested reviewers for submissions, as always the reality is somewhat different. This has apparently led to people bidding for each others papers (finding authors via arxiv) or authors themselves exchanging paper IDs, resulting essentially a ""i'll scratch your back you scratch mine"". This will guarantee at least a single if not more positive review(s) in the process, which is a huge benefit over others who are not partaking in this process. Is this true? How widely is the system abused in your experience?
The AEs could technically step in to avoid such conflicts, but given the scale of NIPS, one can be sure that if someone bids strongly for a paper they are going to get to review it.",7,21
610,2018-6-12,2018,6,12,1,8qaqa1,[D] How would projected natural gradient work with differentiable plasticity?,https://www.reddit.com/r/MachineLearning/comments/8qaqa1/d_how_would_projected_natural_gradient_work_with/,abstractcontrol,1528733184,"Trying to work out the [BPRONG](https://arxiv.org/abs/1704.07147) updates is no problem as long as they are on the linear regime. I can extend the equations readily for vanilla recurrent nets and probably could for convolutional nets. Likewise for nets with skip connections.

Here a short explanation of the problem. 

    R (W U (z - c) + b) = R' (W' U' (z - c') + b'), for all z

`R` and `U`  are whitening matrices and `W` is the standard feedforward multiply. `z` is the input and `c` is the estimated mean of `z`. `W` and `b` are updated using SGD, and `R`,`U` and `c` are updated in an unsupervised fashion much like batch norm. After that last step, `W` and `b` need to be reprojected to `W'` and `b'` so that the function itself does not change. That is accomplished if the above equation is satisfied.

That can be done by setting `W' = R'^-1 R W U U'^-1` and `b' = R'^-1 (R W U c' - R W U c + R b)`. This is similar to how it is done in the paper, I've merely merged the forward and the backward updates. The method in the paper is not iterative and could be made a lot faster by updating the whitening matrix iteratively and doing the above updates without resorting to matrix inversion. The first could be done by taking the scheme for the update of the whitening matrix from the [EASS paper](https://www.semanticscholar.org/paper/Equivariant-adaptive-source-separation-Cardoso-Laheld/ca9fc6bb80d7fd89055f46d716aa8b6e2e377a5e) and the second using SGD or maybe some other convex optimization method.

How could the method be adapted to work when the update is something like from the [differentiable plasticity paper](https://arxiv.org/abs/1804.02464):

    x j (t) = o(sum (fun i -&gt; w i j * x i (t-1) + a i j * Hebb i j (t) x i (t - 1)))
    Hebb i j (t+1) = n * x i (t - 1) * x j (t) + (1 - n) * Hebb i j (t)

The issue is how to make sure that the function does not change after updating the whitening matrices and the centering vectors. When the linear matrix multiply is replaced by a nonlinear function that is no longer obvious.

    R (f (W, U (z - c)) + b) = R' (f (W', U' (z - c')) + b') for all z

The above can no longer be solved by setting `W' = R'^-1 R W U U'^-1`. Can anything be done here to solve this?

It might be plausible that BPRONG could work without reprojecting the weights after the unsupervised updates if they are smooth enough which could be the case if they are done iteratively, but that does not feel right though.",8,4
611,2018-6-12,2018,6,12,1,8qaqt4,[D] Applying pruning during training on a fully connected RNN?,https://www.reddit.com/r/MachineLearning/comments/8qaqt4/d_applying_pruning_during_training_on_a_fully/,mrconter1,1528733297,If a node value when under a certain threshold it would turn off. Could the network automatically find architectures such as CNN?,3,1
612,2018-6-12,2018,6,12,2,8qb2n2,[R] Deep Learning for Videos: A 2018 Guide to Action Recognition,https://www.reddit.com/r/MachineLearning/comments/8qb2n2/r_deep_learning_for_videos_a_2018_guide_to_action/,synaesthesisx,1528736928,,0,2
613,2018-6-12,2018,6,12,2,8qbg3l,[P] Tutorials on Sentiment Analysis using PyTorch and TorchText,https://www.reddit.com/r/MachineLearning/comments/8qbg3l/p_tutorials_on_sentiment_analysis_using_pytorch/,desku,1528739659,,0,5
614,2018-6-12,2018,6,12,3,8qbnuz,Apple CreateML vs Kaggle Competitions,https://www.reddit.com/r/MachineLearning/comments/8qbnuz/apple_createml_vs_kaggle_competitions/,TomekB,1528741266,,0,1
615,2018-6-12,2018,6,12,3,8qbos4,Excerpt from Tesla dataset,https://www.reddit.com/r/MachineLearning/comments/8qbos4/excerpt_from_tesla_dataset/,UnpredictableFetus,1528741472,,0,1
616,2018-6-12,2018,6,12,3,8qbq00,[P] Open Machine Learning Chat,https://www.reddit.com/r/MachineLearning/comments/8qbq00/p_open_machine_learning_chat/,Sig_Luna,1528741765,,0,1
617,2018-6-12,2018,6,12,4,8qbzom,[D] Improving Language Understanding with Unsupervised Learning,https://www.reddit.com/r/MachineLearning/comments/8qbzom/d_improving_language_understanding_with/,sksq9,1528743609,,19,137
618,2018-6-12,2018,6,12,4,8qc6rf,Challenges faced while training an AI to combat abuse,https://www.reddit.com/r/MachineLearning/comments/8qc6rf/challenges_faced_while_training_an_ai_to_combat/,lintujen_sukulainen,1528744967,,0,1
619,2018-6-12,2018,6,12,4,8qcadi,[R] Deep Curiosity Search: Intra-Life Exploration Improves Performance on Challenging Deep Reinforcement Learning Problems,https://www.reddit.com/r/MachineLearning/comments/8qcadi/r_deep_curiosity_search_intralife_exploration/,wei_jok,1528745686,,1,11
620,2018-6-12,2018,6,12,4,8qcan0,Anybody here has experience with RIDIT for ordinal categorical variables?,https://www.reddit.com/r/MachineLearning/comments/8qcan0/anybody_here_has_experience_with_ridit_for/,chief167,1528745734,[removed],0,1
621,2018-6-12,2018,6,12,4,8qcdy5,[D] Anybody here has experience with ordinal categorical features? Any insight on the RIDIT approach?,https://www.reddit.com/r/MachineLearning/comments/8qcdy5/d_anybody_here_has_experience_with_ordinal/,chief167,1528746361,"So today at work I came across some analyses from a few years ago: a PCA using RIDIT on a dataset with about 100 variables.

Most variables were answers from a customer questionnaire (to prevent fraud). These were answers such as 'agree, strongly agree, disagree, neutral, ...', so they had inherent ordering. The guy ( who is no longer a collegue, cant ask him about it) noted in a short accompanying powerpoint that using simple integer substitution wouldn't be correct for most of these cases, since the truth is more nuanced than that.

I however have never encountered RIDIT in my textbooks, and the topic of ordinal categorical variables as features is indeed something that I don't see widely discussed. Most texts go as far as 'categorical variables go into one\-hot encoding' or something like that.

So my question is, can anybody point to some insights on this technology, some case study or cool textbook? Or has it been 'replaced' with some modern variant of PCA? I currently have very low feeling with the results because I only have studied the wikipedia article and some random paper I found online, so no idea how to assess the quality.",3,1
622,2018-6-12,2018,6,12,4,8qce7c,General hough transform implementation for land detection,https://www.reddit.com/r/MachineLearning/comments/8qce7c/general_hough_transform_implementation_for_land/,[deleted],1528746407,,0,1
623,2018-6-12,2018,6,12,4,8qcgvv,"If You're In NYC June 15th, We'll Be Hosting A Roundtable Discussion About Auto-ML And Its Applications In Financial Services.",https://www.reddit.com/r/MachineLearning/comments/8qcgvv/if_youre_in_nyc_june_15th_well_be_hosting_a/,Project_Hydro,1528746947,,0,1
624,2018-6-12,2018,6,12,4,8qch93,[D] General hough transform implementation for lane detection,https://www.reddit.com/r/MachineLearning/comments/8qch93/d_general_hough_transform_implementation_for_lane/,janithwanni,1528747024,"Anyone know any good implementations of it for lane detection. I need to use it to detect curved lanes on a road.
Thanks in advance ",3,0
625,2018-6-12,2018,6,12,5,8qcrcy,Why the Future of Machine Learning is Tiny,https://www.reddit.com/r/MachineLearning/comments/8qcrcy/why_the_future_of_machine_learning_is_tiny/,cavedave,1528749036,,8,26
626,2018-6-12,2018,6,12,5,8qcu0o,Modelling temporal data with varying number of measurements for each timestep,https://www.reddit.com/r/MachineLearning/comments/8qcu0o/modelling_temporal_data_with_varying_number_of/,karlthefog,1528749569,[removed],0,1
627,2018-6-12,2018,6,12,6,8qd0ba,[N] ACL 2018 Announces Its Five Best Papers,https://www.reddit.com/r/MachineLearning/comments/8qd0ba/n_acl_2018_announces_its_five_best_papers/,trcytony,1528750838,,0,1
628,2018-6-12,2018,6,12,6,8qdbpn,[D] Modelling temporal data with varying number of measurements for each timestep,https://www.reddit.com/r/MachineLearning/comments/8qdbpn/d_modelling_temporal_data_with_varying_number_of/,karlthefog,1528753206,"I have a situation where the data come in as a temporal sequence X_0, X_1, ..., X_k, and for each timestep 0, 1, ..., k there can be N = 1 or more measurements M_i of fixed dimension D. A toy example would be weather measurements over a series of days and the M_i are temperature readings at random unknown times during the day. 

I was hoping to compress the M_i by first passing them through a feedforward network and then taking the average of the final layer for each timestep, and feed the resulting vectors as a sequence into an RNN. The output of the RNN would be a prediction based on the sequence.

Conceptually this all seems fine to me, in terms of being able to propagate the error back through the RNN and the FF/averaging network, though I'm not sure if any of the prominent packages support a variable length sequence within a variable length sequence, or if they do, how one would go about it.

Could anyone here point me in the right direction?
",5,9
629,2018-6-12,2018,6,12,10,8qert1,What is the job interview process for OpenAI fellowship? Also applicants could you briefly share your pre-fellowship credentials?,https://www.reddit.com/r/MachineLearning/comments/8qert1/what_is_the_job_interview_process_for_openai/,1nstantDeath,1528765517,[removed],0,1
630,2018-6-12,2018,6,12,10,8qez0n,[R] A Simple Method for Commonsense Reasoning,https://www.reddit.com/r/MachineLearning/comments/8qez0n/r_a_simple_method_for_commonsense_reasoning/,downtownslim,1528767231,,14,29
631,2018-6-12,2018,6,12,11,8qfe9v,The Best 25 Datasets for Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/8qfe9v/the_best_25_datasets_for_natural_language/,alnguyen22,1528770990,,2,8
632,2018-6-12,2018,6,12,12,8qflzr,What is Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8qflzr/what_is_artificial_intelligence/,cpt_snowcrash,1528772905,,0,1
633,2018-6-12,2018,6,12,12,8qfp09,I made a bot that uses rnn to make poems,https://www.reddit.com/r/MachineLearning/comments/8qfp09/i_made_a_bot_that_uses_rnn_to_make_poems/,slowking_0,1528773681,,0,1
634,2018-6-12,2018,6,12,13,8qg2ob,[DIscussion] Why are the prior and posteriors modelled as a Gaussian Distribution in Variational Autoencoders ?,https://www.reddit.com/r/MachineLearning/comments/8qg2ob/discussion_why_are_the_prior_and_posteriors/,amil123123,1528777442,"Hey

I just studied about variational autoencoders and more specifically the probability distribution based explanation from here [https://jaan.io/what\-is\-variational\-autoencoder\-vae\-tutorial/](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/) . I couldn't understand that we only have with us X so how can we assume P(Z) and Q(Z|X) to be Gaussian where X is data &amp; Z are latent features. 

Is the following intuition correct \-\- We have X and we want to find a model that is similar to P(X). Z is the factors that X depends on which we do not know about. So to find about P(Z) we use an encoder network but why then during test time we use P(Z) and not Q(Z|X) doesn't it represent more about the data ?",11,10
635,2018-6-12,2018,6,12,13,8qg8l9,Deep Learning for Electronic Health Records,https://www.reddit.com/r/MachineLearning/comments/8qg8l9/deep_learning_for_electronic_health_records/,chenmy17,1528779188,,0,1
636,2018-6-12,2018,6,12,15,8qgtz0,Machine Learning &amp; AI Trends in 2018  u/kmisra2014,https://www.reddit.com/r/MachineLearning/comments/8qgtz0/machine_learning_ai_trends_in_2018_ukmisra2014/,kmisra2014,1528785920,,0,1
637,2018-6-12,2018,6,12,16,8qh5zi,[D] 100 Times Faster Natural Language Processing in Python,https://www.reddit.com/r/MachineLearning/comments/8qh5zi/d_100_times_faster_natural_language_processing_in/,Thomjazz,1528790079,,0,1
638,2018-6-12,2018,6,12,16,8qh665,[D] 100 Times Faster Natural Language Processing in Python,https://www.reddit.com/r/MachineLearning/comments/8qh665/d_100_times_faster_natural_language_processing_in/,Thomjazz,1528790145,,0,5
639,2018-6-12,2018,6,12,16,8qh6qn,[P] Simple Tensorflow implementation of StarGAN (CVPR 2018 Oral),https://www.reddit.com/r/MachineLearning/comments/8qh6qn/p_simple_tensorflow_implementation_of_stargan/,taki0112,1528790356,"*Processing img jchka8621j311...*

*Processing img pto9s7621j311...*",0,1
640,2018-6-12,2018,6,12,17,8qh6wv,How to Use TensorBoard?  Medium,https://www.reddit.com/r/MachineLearning/comments/8qh6wv/how_to_use_tensorboard_medium/,Fewthp,1528790424,,0,1
641,2018-6-12,2018,6,12,17,8qh7e5,[P] Simple Tensorflow implementation of StarGAN (CVPR 2018 Oral),https://www.reddit.com/r/MachineLearning/comments/8qh7e5/p_simple_tensorflow_implementation_of_stargan/,taki0112,1528790599,,61,920
642,2018-6-12,2018,6,12,17,8qhch1,Naive Bayes Classifier - Simplified using Python,https://www.reddit.com/r/MachineLearning/comments/8qhch1/naive_bayes_classifier_simplified_using_python/,pooja307,1528792532,,0,1
643,2018-6-12,2018,6,12,17,8qhetv,Where does Machine Learning fit in Real Time Communication (ML in RTC)?,https://www.reddit.com/r/MachineLearning/comments/8qhetv/where_does_machine_learning_fit_in_real_time/,tsahil,1528793470,,0,1
644,2018-6-12,2018,6,12,18,8qhgk3,"Project CHARLOTTE, machine learning for the office",https://www.reddit.com/r/MachineLearning/comments/8qhgk3/project_charlotte_machine_learning_for_the_office/,QUZANG,1528794116,,0,1
645,2018-6-12,2018,6,12,18,8qhigz,"All about the GANs - almost 1,000 papers",https://www.reddit.com/r/MachineLearning/comments/8qhigz/all_about_the_gans_almost_1000_papers/,hollobit,1528794824,[removed],0,1
646,2018-6-12,2018,6,12,18,8qhjah,"[D] What is the state-of-art of using Neural Networks for Text Segmentation, lemmatization and NER",https://www.reddit.com/r/MachineLearning/comments/8qhjah/d_what_is_the_stateofart_of_using_neural_networks/,__Julia,1528795129,"I was reading this post on \[Kaggle\]([http://blog.kaggle.com/2018/02/07/a\-brief\-summary\-of\-the\-kaggle\-text\-normalization\-challenge/](http://blog.kaggle.com/2018/02/07/a-brief-summary-of-the-kaggle-text-normalization-challenge/)) on Text normalization. I did some research to see how Neural Networks, in general, are used for word Segmentation, lemmatization and NER. However, I found out that there are some efforts out there, but it is still not as effective as traditional methods. What is the state\-of\-art in this field, specially for other langauges ?",2,3
647,2018-6-12,2018,6,12,18,8qhq6u,How to test an Auto Machine Learning System? Any Guidelines?,https://www.reddit.com/r/MachineLearning/comments/8qhq6u/how_to_test_an_auto_machine_learning_system_any/,question2121,1528797591,[removed],0,1
648,2018-6-12,2018,6,12,19,8qhquz,Changing How Decentralisation of AI Worked So Far. Get ML Models trained without acquiring GPUs.,https://www.reddit.com/r/MachineLearning/comments/8qhquz/changing_how_decentralisation_of_ai_worked_so_far/,ravensdraven,1528797813,[removed],0,1
649,2018-6-12,2018,6,12,19,8qhrr1,Recognizing images using Tensorflow.JS in browser,https://www.reddit.com/r/MachineLearning/comments/8qhrr1/recognizing_images_using_tensorflowjs_in_browser/,gufranmirza,1528798100,,0,1
650,2018-6-12,2018,6,12,19,8qhryj,[D] How to make the outputs of a neural network normally distributed?,https://www.reddit.com/r/MachineLearning/comments/8qhryj/d_how_to_make_the_outputs_of_a_neural_network/,finspire13,1528798165,"Hi, I am building a neural network to score images. There is no explicit score but only image ranking in my dataset. So the network is trained with pair comparisons. The problem is that I want the score of images to be normally distributed. How can I add such 'prior' to the network? ",6,2
651,2018-6-12,2018,6,12,19,8qhs0t,[R] [1804.04438] Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs,https://www.reddit.com/r/MachineLearning/comments/8qhs0t/r_180404438_pooling_is_neither_necessary_nor/,circuithunter,1528798195,,16,27
652,2018-6-12,2018,6,12,19,8qhtx0,"Pre Engineered building systems are not only easy and cheap to assemble, but are easy to maintain. Read more on Pre Engineering: https://goo.gl/iuFSyL",https://www.reddit.com/r/MachineLearning/comments/8qhtx0/pre_engineered_building_systems_are_not_only_easy/,Supertech_India,1528798863,,0,1
653,2018-6-12,2018,6,12,19,8qhx1u,Fluency adjustable foreign speech synthesizer - Kim Jong-Un's English,https://www.reddit.com/r/MachineLearning/comments/8qhx1u/fluency_adjustable_foreign_speech_synthesizer_kim/,cyplus1,1528799935,[removed],0,1
654,2018-6-12,2018,6,12,19,8qhxay,[P] Fluency adjustable foreign speech synthesizer - Kim Jong-Un's English,https://www.reddit.com/r/MachineLearning/comments/8qhxay/p_fluency_adjustable_foreign_speech_synthesizer/,cyplus1,1528800018,"Neosapience has developed fluency adjustable foreign speech synthesizer
In the first part of the demo, Kim Jong-Un speaks English with Korean accent. In the second part, he speaks more fluently.

Please enjoy the historical summit and demo.
https://youtu.be/YF1iXrxwcLA
",0,8
655,2018-6-12,2018,6,12,19,8qhyib,detection of algorithmic trading,https://www.reddit.com/r/MachineLearning/comments/8qhyib/detection_of_algorithmic_trading/,evertonalex,1528800419,[removed],0,1
656,2018-6-12,2018,6,12,20,8qi28x,Course review: Knowledge Based AI systems,https://www.reddit.com/r/MachineLearning/comments/8qi28x/course_review_knowledge_based_ai_systems/,mohit_jarvis29,1528801596,[removed],0,1
657,2018-6-12,2018,6,12,20,8qi2q3, -- ,https://www.reddit.com/r/MachineLearning/comments/8qi2q3/__/,Woodworking94,1528801738,,0,1
658,2018-6-12,2018,6,12,20,8qi7n0,Any sources/definitions on NLP task of context reference?,https://www.reddit.com/r/MachineLearning/comments/8qi7n0/any_sourcesdefinitions_on_nlp_task_of_context/,adam614,1528803262,[removed],0,1
659,2018-6-12,2018,6,12,20,8qi8x7,On Intrinsic Rewards and Continual Learning,https://www.reddit.com/r/MachineLearning/comments/8qi8x7/on_intrinsic_rewards_and_continual_learning/,bhediyakadushmankobi,1528803646,,0,1
660,2018-6-12,2018,6,12,20,8qi9hu,Changing How Decentralized Artificial Intelligence Worked So Far,https://www.reddit.com/r/MachineLearning/comments/8qi9hu/changing_how_decentralized_artificial/,ravensdraven,1528803809,,0,1
661,2018-6-12,2018,6,12,20,8qi9xi,Tutorials on deep learning using tensorflow eager,https://www.reddit.com/r/MachineLearning/comments/8qi9xi/tutorials_on_deep_learning_using_tensorflow_eager/,madalinaaa,1528803957,,6,33
662,2018-6-12,2018,6,12,21,8qidbt,Automatic Electric Gyoza Making Machine For Sale sherry@machinehall.com,https://www.reddit.com/r/MachineLearning/comments/8qidbt/automatic_electric_gyoza_making_machine_for_sale/,lgsherry,1528804930,,1,1
663,2018-6-12,2018,6,12,21,8qiga4,Text Normalization using Memory Augmented Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8qiga4/text_normalization_using_memory_augmented_neural/,j_orshman,1528805726,,2,8
664,2018-6-12,2018,6,12,21,8qiiey,[Discussion] Recursive knowledge distillation of neural nets,https://www.reddit.com/r/MachineLearning/comments/8qiiey/discussion_recursive_knowledge_distillation_of/,anandaseelan,1528806320,"Is there any prior work on distilling deep nets recursively, wherein first a student with a reasonable capacity(size) is trained from a bigger teacher, in turn this student becomes the teacher and subsequently another smaller student is learnt from the first student and so on. Not sure if this would really work out that well, but could be interesting to see the actual gradual reduction in size vs accuracy drop at each stage of the change in teacher. Any pointers to previous work would be helpful!   ",4,3
665,2018-6-12,2018,6,12,21,8qindn,Back To The Future of Handwriting Recognition - GRAIL Text Recognizer,https://www.reddit.com/r/MachineLearning/comments/8qindn/back_to_the_future_of_handwriting_recognition/,j_orshman,1528807633,,0,1
666,2018-6-12,2018,6,12,21,8qioch,"Autopilot or automatic programming, which is harder?",https://www.reddit.com/r/MachineLearning/comments/8qioch/autopilot_or_automatic_programming_which_is_harder/,suntreerelax,1528807886,[removed],0,1
667,2018-6-12,2018,6,12,21,8qippl,Automatic Round Shape Coffee Pod Packing Machine,https://www.reddit.com/r/MachineLearning/comments/8qippl/automatic_round_shape_coffee_pod_packing_machine/,lgsherry,1528808234,,1,1
668,2018-6-12,2018,6,12,22,8qithc,Classification/Prediction based on Multivariate Time Series,https://www.reddit.com/r/MachineLearning/comments/8qithc/classificationprediction_based_on_multivariate/,yavarhusain,1528809153,[removed],0,1
669,2018-6-12,2018,6,12,22,8qixpy,"[R] The Natural Gradient by Analogy to Signal Whitening, and Recipes and Tricks for its Use",https://www.reddit.com/r/MachineLearning/comments/8qixpy/r_the_natural_gradient_by_analogy_to_signal/,abstractcontrol,1528810210,,0,10
670,2018-6-12,2018,6,12,22,8qizqs,Python Top 10 Articles for the Past Month (v.June 2018),https://www.reddit.com/r/MachineLearning/comments/8qizqs/python_top_10_articles_for_the_past_month_vjune/,jeremyisdev,1528810702,,0,1
671,2018-6-12,2018,6,12,23,8qje6y,[D] What are the state of the art methods/toolkits available for speech-to-text?,https://www.reddit.com/r/MachineLearning/comments/8qje6y/d_what_are_the_state_of_the_art_methodstoolkits/,snendroid-ai,1528813983,"I was going through some articles and found few popular titles for training and using (in production environment) speech\-to\-text model. Mozilla's [DeepSpeech](https://github.com/mozilla/DeepSpeech) looks like the top popular open sourced library, which also comes with [pre\-trained model](https://github.com/mozilla/DeepSpeech#getting-the-pre-trained-model). Mozilla provides collection of large [dataset](https://voice.mozilla.org/en/data) if anyone wants to re\-train the model. Still, I want to know if there are any other implementation I should look for before jumping right into this one. I'm also curios about any pros/cons of these libraries over SOTA services available from Google or IBM. 

Few other libraries/toolkits I'm looking at:

\- Kur: [deepgram/kur](https://github.com/deepgram/kur)

\- Kaldi: [http://kaldi\-asr.org/](http://kaldi-asr.org/)

\- CMUSphinx: [https://cmusphinx.github.io/](https://cmusphinx.github.io/)",9,5
672,2018-6-12,2018,6,12,23,8qjhum,Text Normalization using Memory Augmented Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8qjhum/text_normalization_using_memory_augmented_neural/,subho0406,1528814784,,0,1
673,2018-6-12,2018,6,12,23,8qjj4k,NLP- predict if a piece of text mentions a product,https://www.reddit.com/r/MachineLearning/comments/8qjj4k/nlp_predict_if_a_piece_of_text_mentions_a_product/,Kingslayer_97,1528815068,"I am trying to make a model which determines if a product is mentioned by a piece of unstructured text like tweets ,emails etc .Also prediction should also be made if any attribute or quality is mentioned about the produxt .I searched the internet and came across Stanford NER tagger.can someone tell if it's the right approach  and if yes what can I do to make it better
",0,1
674,2018-6-12,2018,6,12,23,8qjjz7,[P] Predicting English Pronunciations,https://www.reddit.com/r/MachineLearning/comments/8qjjz7/p_predicting_english_pronunciations/,reppic,1528815261,,8,6
675,2018-6-12,2018,6,12,23,8qjk14,Scaling vs. Normalization: Whats the difference?,https://www.reddit.com/r/MachineLearning/comments/8qjk14/scaling_vs_normalization_whats_the_difference/,imHarin,1528815273,,0,1
676,2018-6-12,2018,6,12,23,8qjlbb,Piksep: Organize your photos!,https://www.reddit.com/r/MachineLearning/comments/8qjlbb/piksep_organize_your_photos/,ankitshubham97,1528815546,[removed],0,1
677,2018-6-13,2018,6,13,0,8qjxzr,"[Hiring] Computer Vision Lead, Boston. $145K + benefits. Using C++ and OpenCV to build a makeup robot.",https://www.reddit.com/r/MachineLearning/comments/8qjxzr/hiring_computer_vision_lead_boston_145k_benefits/,EdmundWorks,1528818098,,0,1
678,2018-6-13,2018,6,13,1,8qk5sx,"[D] For those of you who work/hire for research jobs, is mentioning PhD plans a good idea?",https://www.reddit.com/r/MachineLearning/comments/8qk5sx/d_for_those_of_you_who_workhire_for_research_jobs/,skepticforest,1528819578,I'm currently graduating from an MS and plan to do a PhD after 1-2 years. I'm interviewing for research engineer positions and I don't plan on staying for more than 1 or 2 years. I'm absolutely clueless about how the industry works so I wanted advice from experienced employees/recruiters in the ML research industry on how to go about this? Should I mention that I won't be staying for too long?,11,13
679,2018-6-13,2018,6,13,1,8qkir9,[P] Free Course: Deep Reinforcement Learning with Tensorflow Video Version ,https://www.reddit.com/r/MachineLearning/comments/8qkir9/p_free_course_deep_reinforcement_learning_with/,cranthir_,1528822213," The syllabus of the course: [https://simoninithomas.github.io/Deep\_reinforcement\_learning\_Course/](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)

Hello everyone I have two awesome announcements today: 

\- First, I'm really excited to announce that **we published our first video version of the course on youtube** , videos will focus on the implementation part with Tensorflow** with new environment**s (OpenAI Taxi\-v2 , Space Invaders , Outrun  ...). One published per week  every Tuesday.

This first video focus on the implementation of Q\-learning agent that learns to play OpenAI Taxi\-v2  where she must **learn to take a passenger at a location and drop him off at another as fast as possible.**

\&gt;\&gt; This is our first video **so any feedback and advice is welcomed**** **!

**Q\-learning with Numpy and OpenAI Taxi**: [https://www.youtube.com/watch?v=q2ZOEFAaaI0](https://www.youtube.com/watch?v=q2ZOEFAaaI0)

\- Second our website has been improved, with the new calendar . I apologize for the delay in publishing the articles, **don't worry the course is back on track !**

Next week will be published :

 *Advantage Actor Critic (A2C)* article and implementation with tensorflow

 *Improvements in Deep Q Learning* (Dueling, Prioritized experiences ...) article and implementation with tensorflow

Again let me say what you think about the course (articles and videos) and **how it should be improved!**

Thanks for your help!

Have a great day!",2,45
680,2018-6-13,2018,6,13,2,8qkp5p,"Sentiment analysis on tweet data using bag of word models, recurrent neural networks, and convnets",https://www.reddit.com/r/MachineLearning/comments/8qkp5p/sentiment_analysis_on_tweet_data_using_bag_of/,ahmedbesbes,1528823448,,0,1
681,2018-6-13,2018,6,13,2,8qksbl,Predicting FIFA World Cup 2018 using Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/8qksbl/predicting_fifa_world_cup_2018_using_machine/,itsmuriuki,1528824064,,0,1
682,2018-6-13,2018,6,13,2,8qkvw2,Is there any source code for x-view object detection?,https://www.reddit.com/r/MachineLearning/comments/8qkvw2/is_there_any_source_code_for_xview_object/,_salman,1528824778,,0,1
683,2018-6-13,2018,6,13,2,8qkzfv,Best Program to use,https://www.reddit.com/r/MachineLearning/comments/8qkzfv/best_program_to_use/,dl1998,1528825477,[removed],0,1
684,2018-6-13,2018,6,13,2,8ql1lf,[R] Massively Parallel Video Networks (DeepMind),https://www.reddit.com/r/MachineLearning/comments/8ql1lf/r_massively_parallel_video_networks_deepmind/,baylearn,1528825927,,0,6
685,2018-6-13,2018,6,13,3,8ql70z,"Switching from Keras to PyTorch, LF suggestions!",https://www.reddit.com/r/MachineLearning/comments/8ql70z/switching_from_keras_to_pytorch_lf_suggestions/,JClub,1528827001,"Hi all! I am used to work with Keras (TF backend). It is really good when you want to build something more or less simple and really fast. 

However there are architectures that are not so easy to create with static computational graphs. Therefore, I want to get used to PyTorch since it is more versatile, imo. 

For those of you that already passed through the process of switching from Keras/TF to PyTorch, can you advice me of some tutorials to follow to better understand how to use the framework? By that I mean, I would like to have some default ways of defining models (ex: init, update and predict functions). Maybe some of you use even another abstraction like torchnet? 

I am looking for suggestions, thank you all in advance. ",0,1
686,2018-6-13,2018,6,13,3,8qliz5,Suggest new name for NIPS conference,https://www.reddit.com/r/MachineLearning/comments/8qliz5/suggest_new_name_for_nips_conference/,planwithoutman,1528829425,[removed],0,1
687,2018-6-13,2018,6,13,3,8qljoj,4 challenges for modern AI - William James,https://www.reddit.com/r/MachineLearning/comments/8qljoj/4_challenges_for_modern_ai_william_james/,aheirich,1528829574,[http://alumnus.caltech.edu/\~heirich/styled\-4/index.html](http://alumnus.caltech.edu/~heirich/styled-4/index.html),0,1
688,2018-6-13,2018,6,13,4,8qln64,Transformationally Identical and Invariant Convolutional Neural Networks through Symmetric Element Operators,https://www.reddit.com/r/MachineLearning/comments/8qln64/transformationally_identical_and_invariant/,SBENLO,1528830223,[removed],0,1
689,2018-6-13,2018,6,13,4,8qlo53,New name for NIPS?,https://www.reddit.com/r/MachineLearning/comments/8qlo53/new_name_for_nips/,ahmaurya,1528830415,,0,1
690,2018-6-13,2018,6,13,5,8qmde1,Reinforcement Q-Learning from Scratch in Python with OpenAI Gym,https://www.reddit.com/r/MachineLearning/comments/8qmde1/reinforcement_qlearning_from_scratch_in_python/,satwik_,1528835538,,0,2
691,2018-6-13,2018,6,13,5,8qmhmo,[D] Keys to compete against industry when in academia,https://www.reddit.com/r/MachineLearning/comments/8qmhmo/d_keys_to_compete_against_industry_when_in/,fixed-point-learning,1528836410,"It seems from published papers that state\-of\-the\-art results are always coming out from industry, and that makes sense because of the much stronger compute power typically available in companies vs. universities. Traditionally, it is somewhat expected that university researchers should focus more on ideas and concepts while industry researchers should consider large scale implementations. However, one observation at recent NIPS/ICML/ICLR/CVPR/etc.. papers reveals a common trend of showing off empirical results. This has haunted me several times and resulted in papers being rejected. It is just too hard to generate empirical results as awesome as those from industry. I hence focus on the more theoretical and algorithmic aspects, but it gets so frustrating when reviewers only critique the empirical results. My question is how to compete with industry in the era where empiricism is becoming so strong in machine learning?",36,71
692,2018-6-13,2018,6,13,5,8qmj1o,NIPS is considering a change of name,https://www.reddit.com/r/MachineLearning/comments/8qmj1o/nips_is_considering_a_change_of_name/,DanielleMolloy,1528836709,"Part of an e-mail that has been sent to previous attendees 2 hours ago: 

(quote)
""We now ask past NIPS participants, in particular yourself, to suggest potential new names for the conference. In a few weeks, we will conduct a second poll asking you about your opinion regarding a name change in general, and to rate some of the suggested new names. The executive board will then use all the collected material as input to come up with a final decision later this year.""
(end of quote)

Background:
https://en.wikipedia.org/wiki/Nip
https://www.google.de/search?tbm=isch&amp;q=nips
",0,1
693,2018-6-13,2018,6,13,5,8qmjl5,[N] NIPS is considering a change of name,https://www.reddit.com/r/MachineLearning/comments/8qmjl5/n_nips_is_considering_a_change_of_name/,DanielleMolloy,1528836812,"Part of an e-mail that has been sent to previous attendees 2 hours ago: 

(quote)
*We now ask past NIPS participants to suggest potential new names for the conference. In a few weeks, we will conduct a second poll asking you about your opinion regarding a name change in general, and to rate some of the suggested new names. The executive board will then use all the collected material as input to come up with a final decision later this year.*
(end of quote)


**Background**

https://en.wikipedia.org/wiki/Nip

https://www.google.de/search?tbm=isch&amp;q=nips
",1,2
694,2018-6-13,2018,6,13,6,8qmnh9,Projects to do while learning machine learning,https://www.reddit.com/r/MachineLearning/comments/8qmnh9/projects_to_do_while_learning_machine_learning/,imkonig,1528837579,"Hello,

As a computer engineer and a computer engineering masters student (actually some other field than ML), I started learning machine learning.

I am following the book of Ethem Alpaydin's Introduction to ML, which I find extremely useful so far. Although there are theoretical exercises on the book, I want to have hands\-on experience with a python framework or something like that.

But I don't know what I can implement with my current knowledge, and I need a list of assignments related to the topics, for example a Stanford course's assignments or sth like that.

Can you guide me which kind of projects to do while finishing the book? I am a backend developer right now, but I want to land to an ML job in the future.

The book's contents are organized like that:

[Contents Page](https://www.cmpe.boun.edu.tr/~ethem/i2ml3e/)",0,1
695,2018-6-13,2018,6,13,7,8qnfic,Machine learning summer,https://www.reddit.com/r/MachineLearning/comments/8qnfic/machine_learning_summer/,Pimp_Fada,1528843774,[removed],0,1
696,2018-6-13,2018,6,13,7,8qngsj,[LF Recommendation] On examples of CNNs implemented from scratch,https://www.reddit.com/r/MachineLearning/comments/8qngsj/lf_recommendation_on_examples_of_cnns_implemented/,seiqooq,1528844092,[removed],0,1
697,2018-6-13,2018,6,13,8,8qnjbq,[D] Ongoing work in computational creativity?,https://www.reddit.com/r/MachineLearning/comments/8qnjbq/d_ongoing_work_in_computational_creativity/,beef__,1528844686,"Was curious if there were any good papers in trying to get AI to come up with creative/novel approaches to the solving of a problem. Doesn't need to be exclusively neural net based - other types of ML are totally welcome.

I'd be interested in new and old papers alike - anyone have suggestions for papers? or authors that have worked a lot in this area?",3,6
698,2018-6-13,2018,6,13,8,8qnpfh,[N] Deep Learning Explained,https://www.reddit.com/r/MachineLearning/comments/8qnpfh/n_deep_learning_explained/,MarbleMan34,1528846157,,1,0
699,2018-6-13,2018,6,13,10,8qobx7,[D] Statistics - the rules of the game,https://www.reddit.com/r/MachineLearning/comments/8qobx7/d_statistics_the_rules_of_the_game/,Deeptree21,1528851790,,0,15
700,2018-6-13,2018,6,13,10,8qoef9,"[R] Relational inductive biases, deep learning, and graph networks (A graph neural network survey paper from DeepMind/Google Brain)",https://www.reddit.com/r/MachineLearning/comments/8qoef9/r_relational_inductive_biases_deep_learning_and/,programmerChilli,1528852408,,2,6
701,2018-6-13,2018,6,13,10,8qojx8,"The Difference Between Artificial Intelligence, Machine Learning, and Deep Learning",https://www.reddit.com/r/MachineLearning/comments/8qojx8/the_difference_between_artificial_intelligence/,VanillaMonster,1528853839,,0,1
702,2018-6-13,2018,6,13,10,8qolt8,[R] Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,https://www.reddit.com/r/MachineLearning/comments/8qolt8/r_transfer_learning_from_speaker_verification_to/,rustyryan,1528854339,"Paper: [https://arxiv.org/abs/1806.04558](https://arxiv.org/abs/1806.04558)

Samples: [https://google.github.io/tacotron/publications/speaker\_adaptation/index.html](https://google.github.io/tacotron/publications/speaker_adaptation/index.html)",1,19
703,2018-6-13,2018,6,13,10,8qomjs,Does it make sense to perform feature extraction before applying raw data to deep learning model?,https://www.reddit.com/r/MachineLearning/comments/8qomjs/does_it_make_sense_to_perform_feature_extraction/,pat_abh,1528854530,[removed],0,1
704,2018-6-13,2018,6,13,11,8qoxko,Multiple Loss Functions?,https://www.reddit.com/r/MachineLearning/comments/8qoxko/multiple_loss_functions/,wilber-guy,1528857371,[removed],0,1
705,2018-6-13,2018,6,13,12,8qp3at,[D] Machine Learning - WAYR (What Are You Reading) - Week 44,https://www.reddit.com/r/MachineLearning/comments/8qp3at/d_machine_learning_wayr_what_are_you_reading_week/,wassname,1528858895,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 31](https://www.reddit.com/r/MachineLearning/comments/6s0k1u/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 41](https://www.reddit.com/r/MachineLearning/comments/7tn2ax/d_machine_learning_wayr_what_are_you_reading_week/)|||
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 32](https://www.reddit.com/r/MachineLearning/comments/72ab5y/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 42](https://www.reddit.com/r/MachineLearning/comments/7wvjfk/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 33](https://www.reddit.com/r/MachineLearning/comments/75405d/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 43](https://www.reddit.com/r/MachineLearning/comments/807ex4/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 34](https://www.reddit.com/r/MachineLearning/comments/782js9/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 44](https://www.reddit.com/r/MachineLearning/comments/8aluhs/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 35](https://www.reddit.com/r/MachineLearning/comments/7b0av0/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 36](https://www.reddit.com/r/MachineLearning/comments/7e3fx6/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 37](https://www.reddit.com/r/MachineLearning/comments/7hcc2c/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|[Week 28](https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 38](https://www.reddit.com/r/MachineLearning/comments/7kgcqr/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|[Week 29](https://www.reddit.com/r/MachineLearning/comments/6m9l1v/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 39](https://www.reddit.com/r/MachineLearning/comments/7nayri/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 30](https://www.reddit.com/r/MachineLearning/comments/6p3ha7/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 40](https://www.reddit.com/r/MachineLearning/comments/7qel9p/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two months ago:

/u/Molag_Balls: ""Variance-based Gradient Compression for Efficient Distributed Deep Learning"" A [proposed ICLR paper](https://openreview.net/forum?id=rkEfPeZRb) on a method for reducing the need for communication between workers in a distributed training environment.

/u/theainerd: AndrewNgreleased the first 19 chapters of his book Machine Learning Yearning. It is focused not on teaching you ML algorithms, but on how to make ML algorithms work. [Machine Learning Yearning](http://www.mlyearning.org/)

Besides that, there are no rules, have fun.

Note: The WAYRB was great, please bring it back :)",49,103
706,2018-6-13,2018,6,13,12,8qp4yd,Machine Learning ROI: How to model the investment value of Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8qp4yd/machine_learning_roi_how_to_model_the_investment/,Ich_rauche_Gras,1528859342,,0,1
707,2018-6-13,2018,6,13,12,8qp9xq,"Authors from 2 ICML-accepted papers agreed for a Q &amp; A on a new QnA paper platform, ""Learning Longer-term Dependencies in RNNs with Auxiliary Losses"" and ""Towards Fast Computation of Certified Robustness for ReLU Networks""",https://www.reddit.com/r/MachineLearning/comments/8qp9xq/authors_from_2_icmlaccepted_papers_agreed_for_a_q/,BatmantoshReturns,1528860675,[removed],0,1
708,2018-6-13,2018,6,13,12,8qpb2f,"[D] Authors from 2 ICML-accepted papers agreed for a Q &amp; A on a new QnA paper platform, ""Learning Longer-term Dependencies in RNNs with Auxiliary Losses"" and ""Towards Fast Computation of Certified Robustness for ReLU Networks""",https://www.reddit.com/r/MachineLearning/comments/8qpb2f/d_authors_from_2_icmlaccepted_papers_agreed_for_a/,BatmantoshReturns,1528861000,"This is isn't me, it was deleted by the subreddit because it didn't have a [D] next the title, so I decided to repost it because this is a great thing for the authors to do

Original post

Good news! Authors of the ICML papers ""Learning Longer-term Dependencies in RNNs with Auxiliary Losses"" and ""Towards Fast Computation of Certified Robustness for ReLU Networks"" have agreed to answer questions directed to their papers on the Nurture.ai platform.

How do I post a question?

Click on the paper's link. Simply highlight any text on the paper - this will form a comment box, where you can post your questions.

https://i.redd.it/ex5hj0oycj011.png What is Nurture.ai?

It is an online platform created by AI learners like you. We were frustrated with our difficulties in efficiently keep up with the fast pace of AI research. We also wanted to push for more reproducibility and facilitate better understanding in AI papers. Therefore, we built the free Nurtue.ai platform to encourage online collaboration and exchange among an AI community. Nurture.ai is also the organiser of the NIPS 2017 challenge and AI Saturdays. To date, we have a strong community of over 2500 users ranging from PhD students, industry practitioners and self-learners. We believe in the value of helping learners worldwide to get more out of AI research. We hope you feel the same way too. You can:

Share your learning notes on Nurture.ai. Simply highlight any text in an arXiv preprint to annotate and start a discussion thread.

Contribute to community reviews on your favourite papers

Post and discuss code implementations Follow us on facebook and twitter. Note! We are NOT nature.ai. Yeah, it's the nurture versus nature question, ain't it?My team and I are working hard to optimise user experience on the platform, let us know how we can make your learning more enjoyable on Nurture.ai.",1,2
709,2018-6-13,2018,6,13,12,8qpdyo,Using Blender 3D open source and Apple CreateML for Image Classifier,https://www.reddit.com/r/MachineLearning/comments/8qpdyo/using_blender_3d_open_source_and_apple_createml/,enzyme69,1528861803,[removed],0,1
710,2018-6-13,2018,6,13,13,8qpg3m,A question about feature engineering,https://www.reddit.com/r/MachineLearning/comments/8qpg3m/a_question_about_feature_engineering/,old_enough_to_drink,1528862417,[removed],0,1
711,2018-6-13,2018,6,13,13,8qpoxd,La Ferrari California T,https://www.reddit.com/r/MachineLearning/comments/8qpoxd/la_ferrari_california_t/,psysic420,1528865026,,0,1
712,2018-6-13,2018,6,13,14,8qpy5m,[Project] MNIST sance,https://www.reddit.com/r/MachineLearning/comments/8qpy5m/project_mnist_sance/,kbrowne,1528867907,,11,4
713,2018-6-13,2018,6,13,15,8qq7sx,Google Updates Its Translate App With Offline Machine Learning Supporting 59 Languages,https://www.reddit.com/r/MachineLearning/comments/8qq7sx/google_updates_its_translate_app_with_offline/,cpt_snowcrash,1528871103,,0,1
714,2018-6-13,2018,6,13,15,8qq9y0,Special Purpose machine manufacturers in India,https://www.reddit.com/r/MachineLearning/comments/8qq9y0/special_purpose_machine_manufacturers_in_india/,cncindia,1528871822,,0,1
715,2018-6-13,2018,6,13,15,8qqaz0,QRNN vs LSTM. Why hasn't the QRNN settled in as a plausible replacement for LSTMs in recent research?,https://www.reddit.com/r/MachineLearning/comments/8qqaz0/qrnn_vs_lstm_why_hasnt_the_qrnn_settled_in_as_a/,wise_east,1528872184,[removed],0,1
716,2018-6-13,2018,6,13,15,8qqdd6,Round Shape Coffee Pod Packing Machine For Sale sherry@machinehall.com,https://www.reddit.com/r/MachineLearning/comments/8qqdd6/round_shape_coffee_pod_packing_machine_for_sale/,lgsherry,1528872988,,1,1
717,2018-6-13,2018,6,13,16,8qqh62,Machine Learning with Python,https://www.reddit.com/r/MachineLearning/comments/8qqh62/machine_learning_with_python/,Technogeekspune,1528874159,,0,1
718,2018-6-13,2018,6,13,16,8qqjgq,[D] Object detection papers that consider contextual information?,https://www.reddit.com/r/MachineLearning/comments/8qqjgq/d_object_detection_papers_that_consider/,cbsudux,1528874960,"I'm looking for papers that implement object detection that takes into account the neighboring objects to localize and classify the current object. 

My current detector makes bad predictions due to bad image quality. 
All my training images have the same objects in the same locations and I'm looking to leverage this.

Cheers!",8,10
719,2018-6-13,2018,6,13,16,8qqmkp,[R] Neural Best-Buddies: Sparse Cross-Domain Correspondence,https://www.reddit.com/r/MachineLearning/comments/8qqmkp/r_neural_bestbuddies_sparse_crossdomain/,hardmaru,1528876068,,3,16
720,2018-6-13,2018,6,13,16,8qqn5s,Tangled mess - Operator response included in model inputs,https://www.reddit.com/r/MachineLearning/comments/8qqn5s/tangled_mess_operator_response_included_in_model/,zuffler,1528876279,[removed],0,1
721,2018-6-13,2018,6,13,17,8qqqdg,[R] U-SegNet: Fully Convolutional Neural Network based Automated Brain tissue segmentation Tool,https://www.reddit.com/r/MachineLearning/comments/8qqqdg/r_usegnet_fully_convolutional_neural_network/,pulkitkumar95,1528877469,,0,2
722,2018-6-13,2018,6,13,17,8qqrd2,Wood defect recognition with machine vision,https://www.reddit.com/r/MachineLearning/comments/8qqrd2/wood_defect_recognition_with_machine_vision/,Schachi_99,1528877852,[removed],0,1
723,2018-6-13,2018,6,13,17,8qqseg,[d] Tangled mess - machine learning where operator response to forecast is included in current inputs,https://www.reddit.com/r/MachineLearning/comments/8qqseg/d_tangled_mess_machine_learning_where_operator/,zuffler,1528878231,"I wonder if someone can point me in the right direction.

I'm building a model that predicts whether A (bad outcome) will happen. Staff involved in managing A already have access to some information (report B) that helps them predict whether A will happen.

Suppose there is a big predictor of A, called X, that shows up on report B, staff respond to X, and this means that A doesn't happen. 

So now I have a situation where X reduces the probability of A.

I want to replace report B, but it's going to affect the response...

Basically my features and my response are tangled.

I need to work out a way to resolve this... But knowing what to Google would be a good start.",12,10
724,2018-6-13,2018,6,13,17,8qqwp3,Object Detection and batch normalization (size 1),https://www.reddit.com/r/MachineLearning/comments/8qqwp3/object_detection_and_batch_normalization_size_1/,scstech85,1528879942,[removed],0,1
725,2018-6-13,2018,6,13,17,8qqwuv,The M-Competitions and their far-reaching contributions to the Theory and Practice of Forecasting | The latest edition (M4) highlights that hybrid approaches and combinations of forecasting methods produce greater accuracy,https://www.reddit.com/r/MachineLearning/comments/8qqwuv/the_mcompetitions_and_their_farreaching/,spyrosmakridakis,1528880004,,0,1
726,2018-6-13,2018,6,13,18,8qqyid,"[D] embedding example, not word2vec",https://www.reddit.com/r/MachineLearning/comments/8qqyid/d_embedding_example_not_word2vec/,marksteve4,1528880618,Every tutorial I went through takes word2vec as an example for embedding. Are there other examples to demonstrate embedding?,17,26
727,2018-6-13,2018,6,13,18,8qr5zj,[P] Abstract Art with Machine Learning. Today I'm launching my ML blog and wrote my first post on CPPNs; included a JS-based pattern generator (using TensorFlowJS) so you can try making art yourself. ;-) what do you think?,https://www.reddit.com/r/MachineLearning/comments/8qr5zj/p_abstract_art_with_machine_learning_today_im/,greedypablo,1528883271,,36,207
728,2018-6-13,2018,6,13,19,8qrcpy,Overview and benchmark of traditional and deep learning models in text classification,https://www.reddit.com/r/MachineLearning/comments/8qrcpy/overview_and_benchmark_of_traditional_and_deep/,ahmedbesbes,1528885590,,0,1
729,2018-6-13,2018,6,13,20,8qriyf,[N] 5 Regression Loss Functions All Machine Learners Should Know,https://www.reddit.com/r/MachineLearning/comments/8qriyf/n_5_regression_loss_functions_all_machine/,molode,1528887661,,0,1
730,2018-6-13,2018,6,13,20,8qrj7f,[R] Know What You Don't Know: Unanswerable Questions for SQuAD,https://www.reddit.com/r/MachineLearning/comments/8qrj7f/r_know_what_you_dont_know_unanswerable_questions/,yamrzou,1528887735,,3,13
731,2018-6-13,2018,6,13,20,8qrlqj,Automatic Growbox,https://www.reddit.com/r/MachineLearning/comments/8qrlqj/automatic_growbox/,growmaster1989,1528888490,,1,1
732,2018-6-13,2018,6,13,20,8qrm0w,Secret identities wouldnt fool modern face recognition,https://www.reddit.com/r/MachineLearning/comments/8qrm0w/secret_identities_wouldnt_fool_modern_face/,chris_shpak,1528888579,,0,1
733,2018-6-13,2018,6,13,20,8qrqxc,[P] Racetrack environment for tabular RL,https://www.reddit.com/r/MachineLearning/comments/8qrqxc/p_racetrack_environment_for_tabular_rl/,nondifferentiable,1528890084,,1,6
734,2018-6-13,2018,6,13,20,8qrrcm,[D] Supervision targets provided by other component (creative sources of supervision),https://www.reddit.com/r/MachineLearning/comments/8qrrcm/d_supervision_targets_provided_by_other_component/,creiser,1528890213,"In traditional supervised learning systems targets are provided directly by human annotation in a convenient format like a one\-hot vector. However, consider the situation where a child sees a dog for the first time and while seeing it its mother says ""This is a dog."" The child is thus able to link the utterance ""dog"" and the appeareance of the dog he sees right now.

I am wondering about the requirements of a machine learning system that could deal with such a supervision signal. Probably lots of skills like language understanding and even reasoning is nessecary to link this information together. For the sake of simplicity imagine that the problem is somewhat easier and our system loosely consists of 3 components: audio classifier, image classifier and a mechanism that decides whether to use the output of a classifier as target for another classifier. Also let's assume that the components are based on neural networks.

In the ""dog"" scenario the following would happen: In the image classifier a new category ""dog"" is created: In the context of neural networks envision that a new output neuron x is added to our image classifier. Neuron x is magically trained to react to the visual appearance of the dog the child sees right now. Also in the audio classifier a new category belonging to the utterance ""dog"" is created, so we have another neuron y that reacts to utterance ""dog"" strongly. But even more importantly we also have to save that the utterance ""dog"" and the appearance of the dog is linked together, so there has to be saved somehow that x and y belong together. Now imagine that a couple of days later the child sees another dog but is not quite sure if this is also a dog. Luckily his mother is with him and tells him again ""This is a dog"". The audio classifier recognizes with high confidence the utterance ""dog"" so neuron y gets activated. Because neuron y is linked to neuron x, which is part of the image classifier, a mechanism decides that the new dog that the boy sees right now can be used to update the ""dog"" visual category. So the target for the image classifier is provided by the audio classifier.

This is only one very specific example of uncountable scenarios where it is neseecary that supervision is provided by ""the system itself"". A scenario like I described here is probably completely out of reach, but I am generally interested in examples where people used the output of one system as a target for another system. For example WaveNet uses a perceptual loss: As far as I understand when they generate audio they use another speech\-to\-text network to check whether the recognized phrase matches the phrase that is tried to be generated. Also GANs use a special source of supervision that is provided by another neural network, the discriminator.

I am sure a lot of people already thought about this and I wonder if you guys could point me to some related work. Also what are the most creative sources of supervision you ever came across?",4,1
735,2018-6-13,2018,6,13,20,8qrri5,Automatic Sugar Sachet Packing Machine Price,https://www.reddit.com/r/MachineLearning/comments/8qrri5/automatic_sugar_sachet_packing_machine_price/,lgsherry,1528890251,,1,1
736,2018-6-13,2018,6,13,21,8qs7zm,[D] Many opportunities for discrimination in deploying machine learning systems,https://www.reddit.com/r/MachineLearning/comments/8qs7zm/d_many_opportunities_for_discrimination_in/,sksq9,1528894781,,1,3
737,2018-6-13,2018,6,13,22,8qscql,Artificial intelligence senses people through walls - MIT,https://www.reddit.com/r/MachineLearning/comments/8qscql/artificial_intelligence_senses_people_through/,j_orshman,1528895912,,5,19
738,2018-6-13,2018,6,13,22,8qsi5u,"Predicting the ""final"" performance of a model based on the observed first performances?",https://www.reddit.com/r/MachineLearning/comments/8qsi5u/predicting_the_final_performance_of_a_model_based/,Zahlii,1528897293,[removed],0,1
739,2018-6-13,2018,6,13,23,8qsr5q,[R] How to Use Automatically Extracted Process Models as Sequence Models that are Visualizable and Interpretable and How This Compares to Existing Sequence Models such as RNN/LSTM/GRU,https://www.reddit.com/r/MachineLearning/comments/8qsr5q/r_how_to_use_automatically_extracted_process/,TaXxER,1528899323,,5,2
740,2018-6-13,2018,6,13,23,8qssgp,Text Detection from Images,https://www.reddit.com/r/MachineLearning/comments/8qssgp/text_detection_from_images/,vedparanjape,1528899639,[removed],0,1
741,2018-6-13,2018,6,13,23,8qst0i,Dank Learning: Generating Memes Using Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8qst0i/dank_learning_generating_memes_using_deep_neural/,j_orshman,1528899764,,8,12
742,2018-6-13,2018,6,13,23,8qsyu5,Evaluation of Machine Learning Model in production,https://www.reddit.com/r/MachineLearning/comments/8qsyu5/evaluation_of_machine_learning_model_in_production/,in_iam,1528901096,[removed],0,1
743,2018-6-14,2018,6,14,0,8qt3bt,TensorFlow.js  a practical guide,https://www.reddit.com/r/MachineLearning/comments/8qt3bt/tensorflowjs_a_practical_guide/,JayaYellowAnt,1528902085,,0,1
744,2018-6-14,2018,6,14,0,8qt67c,[D] Ethics and Diversity in AI,https://www.reddit.com/r/MachineLearning/comments/8qt67c/d_ethics_and_diversity_in_ai/,sinshallah,1528902669,,2,0
745,2018-6-14,2018,6,14,0,8qt6bz,"[Project] I made ModelZoo.co, a website for finding pretrained deep learning models",https://www.reddit.com/r/MachineLearning/comments/8qt6bz/project_i_made_modelzooco_a_website_for_finding/,kohjingyu,1528902696,,29,307
746,2018-6-14,2018,6,14,0,8qtecm,[R][1806.04594] Exponential Weights on the Hypercube in Polynomial Time,https://www.reddit.com/r/MachineLearning/comments/8qtecm/r180604594_exponential_weights_on_the_hypercube/,sudeepraja,1528904389,,1,3
747,2018-6-14,2018,6,14,0,8qtj0o,"Simple Questions Thread June 13, 2018",https://www.reddit.com/r/MachineLearning/comments/8qtj0o/simple_questions_thread_june_13_2018/,AutoModerator,1528905337,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",0,1
748,2018-6-14,2018,6,14,1,8qtlxo,Machine translation,https://www.reddit.com/r/MachineLearning/comments/8qtlxo/machine_translation/,Phratros,1528905925,[removed],0,1
749,2018-6-14,2018,6,14,1,8qtqa8,[N] Google AI is expanding to Africa,https://www.reddit.com/r/MachineLearning/comments/8qtqa8/n_google_ai_is_expanding_to_africa/,baylearn,1528906830,,17,117
750,2018-6-14,2018,6,14,1,8qtry1,[P] Train an RL agent to play custom levels of Sonic the Hedgehog with Transfer Learning (OpenAI Retro Contest 5th place),https://www.reddit.com/r/MachineLearning/comments/8qtry1/p_train_an_rl_agent_to_play_custom_levels_of/,chisai_mikan,1528907172,,2,57
751,2018-6-14,2018,6,14,1,8qtyb2,Clarification for word2vec generate_batch() implementation,https://www.reddit.com/r/MachineLearning/comments/8qtyb2/clarification_for_word2vec_generate_batch/,cckcamel,1528908505,"I have been trying to understand how it works to apply it to my test and dataset (I find that tensorflow code on github is too complex and not very straightforward).

I will be using a skip-gram model. This is the code that I wrote. I'd like a non cryptic explanation of what's going on and what I need to do to make this work.

    def generate_batch(self):
        inputs = []
        labels = []
        for i,phrase in enumerate(self.training_phrases): # training_phrases look like this: ['I like that cat', '...', ..]
            array_list = utils.skip_gram_tokenize(phrase) # This transforms a sentence into an array of arrays of numbers representing the sentence, ex. [[181, 152], [152, 165], [165, 208], [208, 41]]
            for array in array_list:
                inputs.append(array) # I noticed that this is useless, I could just do inputs = array_list

        return inputs, labels


This is where I am right now. From the `generate_batch()` that tensorflow provides on github, I can see that it returns  `inputs, labels` .

I assume that inputs is the array of skip grams, but what is labels? How do I generate them?

Also, I saw that it implements `batch_size`, how can I do that (I assume I have to split the data in smaller pieces, but how does that work? I put the data into an array?).

Regarding `batch_size`, what happens if the batch size is 16, but the data offers only 130 inputs? Do I do 8 regular batches and then a minibatch of 2 inputs?",0,1
752,2018-6-14,2018,6,14,1,8qu19m,[D] Clarification on word2vec generate_batch(),https://www.reddit.com/r/MachineLearning/comments/8qu19m/d_clarification_on_word2vec_generate_batch/,cckcamel,1528909105,"I have been trying to understand how it works to apply it to my test and dataset (I find that tensorflow code on github is too complex and not very straightforward).

I will be using a skip-gram model. This is the code that I wrote. I'd like a non cryptic explanation of what's going on and what I need to do to make this work.

    def generate_batch(self):
        inputs = []
        labels = []
        for i,phrase in enumerate(self.training_phrases): # training_phrases look like this: ['I like that cat', '...', ..]
            array_list = utils.skip_gram_tokenize(phrase) # This transforms a sentence into an array of arrays of numbers representing the sentence, ex. [[181, 152], [152, 165], [165, 208], [208, 41]]
            for array in array_list:
                inputs.append(array) # I noticed that this is useless, I could just do inputs = array_list

        return inputs, labels


This is where I am right now. From the `generate_batch()` that tensorflow provides on github, I can see that it returns  `inputs, labels` .

I assume that inputs is the array of skip grams, but what is labels? How do I generate them?

Also, I saw that it implements `batch_size`, how can I do that (I assume I have to split the data in smaller pieces, but how does that work? I put the data into an array?).

Regarding `batch_size`, what happens if the batch size is 16, but the data offers only 130 inputs? Do I do 8 regular batches and then a minibatch of 2 inputs?",0,0
753,2018-6-14,2018,6,14,2,8qu3k1,How to know if you're talking to a human or to a Google voice assistant,https://www.reddit.com/r/MachineLearning/comments/8qu3k1/how_to_know_if_youre_talking_to_a_human_or_to_a/,jezforsberg,1528909553,,0,1
754,2018-6-14,2018,6,14,2,8qu5lu,"To translate a text, do we really need machine learning? What are the specific reasons to use ML on translating a text instead of statistical computing?",https://www.reddit.com/r/MachineLearning/comments/8qu5lu/to_translate_a_text_do_we_really_need_machine/,donsuzadam,1528909966,[removed],0,1
755,2018-6-14,2018,6,14,2,8qua78,"[D] To translate a text, do we really need machine learning? What are the specific reasons to use ML on translating a text instead of statistical computing?",https://www.reddit.com/r/MachineLearning/comments/8qua78/d_to_translate_a_text_do_we_really_need_machine/,donsuzadam,1528910904,"Hello everyone,

I know it's not right place to ask this kind of questions but i think there are guys who can answer that question.

Machine learning translations provides high quality translation results, but i think, it's possible to translate texts with statistical calculations as well.

I just wonder if there are any specific reasons to do translations with ML. I think one of them is about processing large files, instead of parsing and calculating everything from scratch. This is not good idea. But that can be solved with different ways as well.

Why ML has very important role on that kind of job?

Before asking that, i worked on my personal project to solve if it's possible to translate sentences without ML, with statistical computing. And i wrote PHP function to do that. It reads file and calculates probability of words and sequences and returns a result of these scores. It looks like that, it really works with English-Turkish and English-French pairs. Even with small dataset.

Here is the link of repository : https://github.com/devcem/NMT-on-PHP

I really want to discuss that, please feel free to contact with me.",2,0
756,2018-6-14,2018,6,14,3,8qunw7,The Best of AI: New Articles Published This Month (January 2018),https://www.reddit.com/r/MachineLearning/comments/8qunw7/the_best_of_ai_new_articles_published_this_month/,TebbaVonMathenstein,1528913699,,0,2
757,2018-6-14,2018,6,14,3,8qur9e,Through-Wall Human Pose Estimation Using Radio Signals,https://www.reddit.com/r/MachineLearning/comments/8qur9e/throughwall_human_pose_estimation_using_radio/,chenmy17,1528914375,,7,33
758,2018-6-14,2018,6,14,3,8qus2n,use ml to remove product placements from images/video,https://www.reddit.com/r/MachineLearning/comments/8qus2n/use_ml_to_remove_product_placements_from/,21stio,1528914535,[removed],0,1
759,2018-6-14,2018,6,14,4,8qv2jo,Introduction To Deep Learning -- What Is Deep Learning And How Can I Study It?,https://www.reddit.com/r/MachineLearning/comments/8qv2jo/introduction_to_deep_learning_what_is_deep/,TebbaVonMathenstein,1528916636,,1,2
760,2018-6-14,2018,6,14,4,8qv3oq,unsupervised learning?,https://www.reddit.com/r/MachineLearning/comments/8qv3oq/unsupervised_learning/,dl1998,1528916876,[removed],0,1
761,2018-6-14,2018,6,14,4,8qvfnd,"[D][R] The 2018 Stanford cs231 Computer Vision class projects are now online, many were very impressive",https://www.reddit.com/r/MachineLearning/comments/8qvfnd/dr_the_2018_stanford_cs231_computer_vision_class/,BatmantoshReturns,1528919314,,0,2
762,2018-6-14,2018,6,14,5,8qvkv1,how start to Build a convnet from scratch (without Framewoks)?,https://www.reddit.com/r/MachineLearning/comments/8qvkv1/how_start_to_build_a_convnet_from_scratch_without/,adnire,1528920389,[removed],0,1
763,2018-6-14,2018,6,14,5,8qvsry,How do i implement machine learning?,https://www.reddit.com/r/MachineLearning/comments/8qvsry/how_do_i_implement_machine_learning/,BySNiP,1528922034,[removed],0,1
764,2018-6-14,2018,6,14,6,8qw4yc,[1806.03208] Prediction of the FIFA World Cup 2018 - A random forest approach with an emphasis on estimated team ability parameters,https://www.reddit.com/r/MachineLearning/comments/8qw4yc/180603208_prediction_of_the_fifa_world_cup_2018_a/,astroFizzics,1528924576,,9,5
765,2018-6-14,2018,6,14,6,8qw7do,"If You're in NYC June 19th, Join our Roundtable Discussion about Auto Machine Learning in Financial Services.",https://www.reddit.com/r/MachineLearning/comments/8qw7do/if_youre_in_nyc_june_19th_join_our_roundtable/,Project_Hydro,1528925096,,0,1
766,2018-6-14,2018,6,14,6,8qw7yb,Is it possible to use the ResNet50 model in a Siamese Network?,https://www.reddit.com/r/MachineLearning/comments/8qw7yb/is_it_possible_to_use_the_resnet50_model_in_a/,Cheesebro69,1528925216,I'm working on a project where I need to use the ResNet50 with a Siamese network. I know how to use both separately but my issue is how to combine.,0,1
767,2018-6-14,2018,6,14,6,8qw89w,[D] Interesting Research from MIT CSAIL,https://www.reddit.com/r/MachineLearning/comments/8qw89w/d_interesting_research_from_mit_csail/,vector_machines,1528925287,"
http://news.mit.edu/2018/artificial-intelligence-senses-people-through-walls-0612",0,1
768,2018-6-14,2018,6,14,8,8qwza9,Tensorflow.js and GA based creature simulation in Fermi paradox,https://www.reddit.com/r/MachineLearning/comments/8qwza9/tensorflowjs_and_ga_based_creature_simulation_in/,sarkarsh,1528931410,,5,21
769,2018-6-14,2018,6,14,8,8qx20c,Wave Computing Delivers First Silicon,https://www.reddit.com/r/MachineLearning/comments/8qx20c/wave_computing_delivers_first_silicon/,j_lyf,1528932060,,0,1
770,2018-6-14,2018,6,14,9,8qxf4h,Classification with F# ML.NET Models,https://www.reddit.com/r/MachineLearning/comments/8qxf4h/classification_with_f_mlnet_models/,darkjeepers,1528935376,,0,1
771,2018-6-14,2018,6,14,9,8qxgco,Combination of photo montage and style transfer,https://www.reddit.com/r/MachineLearning/comments/8qxgco/combination_of_photo_montage_and_style_transfer/,kh22l22,1528935697,,0,1
772,2018-6-14,2018,6,14,9,8qxlkg,[p] Combination of photo montage and style transfer for AI Artlier,https://www.reddit.com/r/MachineLearning/comments/8qxlkg/p_combination_of_photo_montage_and_style_transfer/,kh22l22,1528937016,,0,1
773,2018-6-14,2018,6,14,9,8qxn50,Reinforcement Learning - Tetris,https://www.reddit.com/r/MachineLearning/comments/8qxn50/reinforcement_learning_tetris/,Afronanny,1528937424,,0,1
774,2018-6-14,2018,6,14,9,8qxo9k,[P] Combination of photo montage and style transfer for AI artlier,https://www.reddit.com/r/MachineLearning/comments/8qxo9k/p_combination_of_photo_montage_and_style_transfer/,kh22l22,1528937710,,9,37
775,2018-6-14,2018,6,14,10,8qy3bo,I made reinforcement learning toy example with tensorflow js!,https://www.reddit.com/r/MachineLearning/comments/8qy3bo/i_made_reinforcement_learning_toy_example_with/,hulk-89,1528941585,,0,1
776,2018-6-14,2018,6,14,11,8qy8us,Modern techniques for chat bots?,https://www.reddit.com/r/MachineLearning/comments/8qy8us/modern_techniques_for_chat_bots/,Choco31415,1528942973,[removed],0,1
777,2018-6-14,2018,6,14,11,8qy95d,[P] RL example using tensorflow-js,https://www.reddit.com/r/MachineLearning/comments/8qy95d/p_rl_example_using_tensorflowjs/,hulk-89,1528943044,,0,2
778,2018-6-14,2018,6,14,12,8qyte8,"My buc ch t ng dng in 2 ng buc vi chc nng hin i, sn phm mi nht ch c ti Trng Pht",https://www.reddit.com/r/MachineLearning/comments/8qyte8/my_buc_ch_t_ng_dng_in_2_ng_buc_vi/,hoangngan123,1528948479,,0,1
779,2018-6-14,2018,6,14,12,8qyu93,Books for machine learning newbies?,https://www.reddit.com/r/MachineLearning/comments/8qyu93/books_for_machine_learning_newbies/,ghghyuyu,1528948746,[removed],0,1
780,2018-6-14,2018,6,14,13,8qyzos,ing Serious Math in Tensorflow: Quaternion averaging.,https://www.reddit.com/r/MachineLearning/comments/8qyzos/ing_serious_math_in_tensorflow_quaternion/,john_parkhill,1528950302,,0,1
781,2018-6-14,2018,6,14,13,8qz1qv,Doing Serious Math in Tensorflow: Quaternion averaging.,https://www.reddit.com/r/MachineLearning/comments/8qz1qv/doing_serious_math_in_tensorflow_quaternion/,john_parkhill,1528950932,,0,2
782,2018-6-14,2018,6,14,14,8qz7pp,50 Free Datasets for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8qz7pp/50_free_datasets_for_machine_learning/,alnguyen22,1528952743,,0,4
783,2018-6-14,2018,6,14,14,8qzepm,Detect face and gender using dlib and pre trained IMDB dataset,https://www.reddit.com/r/MachineLearning/comments/8qzepm/detect_face_and_gender_using_dlib_and_pre_trained/,anonwipq,1528955015,,4,6
784,2018-6-14,2018,6,14,15,8qzjie,Linear regression: find the value of a predictor that makes the outcome change to a desired value,https://www.reddit.com/r/MachineLearning/comments/8qzjie/linear_regression_find_the_value_of_a_predictor/,inspiralpatterns,1528956604,[removed],0,1
785,2018-6-14,2018,6,14,15,8qzmsh,Topmost Name Card Printing Services,https://www.reddit.com/r/MachineLearning/comments/8qzmsh/topmost_name_card_printing_services/,tockfahnes,1528957666,,0,1
786,2018-6-14,2018,6,14,15,8qzr6x,Multi language sentiment analysis,https://www.reddit.com/r/MachineLearning/comments/8qzr6x/multi_language_sentiment_analysis/,ThrowDC,1528959149,[removed],0,1
787,2018-6-14,2018,6,14,16,8qzvrs,[D] What models and experiments would you want to do if you had a DGX-2?,https://www.reddit.com/r/MachineLearning/comments/8qzvrs/d_what_models_and_experiments_would_you_want_to/,carlthome,1528960624,"With 512 GB VRAM, what type of model would be the first you tried? Is it just excessive or are there some SOTA DL models that would actually benefit from the unified memory?",15,9
788,2018-6-14,2018,6,14,16,8qzx13,ML to identify bald patches in hair loss patients,https://www.reddit.com/r/MachineLearning/comments/8qzx13/ml_to_identify_bald_patches_in_hair_loss_patients/,lakshaydulani,1528961065,[removed],0,1
789,2018-6-14,2018,6,14,16,8qzydo,[P] Speech Recognition with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8qzydo/p_speech_recognition_with_tensorflow/,tttttm,1528961535,,9,138
790,2018-6-14,2018,6,14,16,8r01a2,Computer buying decision,https://www.reddit.com/r/MachineLearning/comments/8r01a2/computer_buying_decision/,MajorTallgrass,1528962630,[removed],0,1
791,2018-6-14,2018,6,14,17,8r06gd,"QT4 24 semi automatic London brick making machine for Sri Lanka, cheap b...",https://www.reddit.com/r/MachineLearning/comments/8r06gd/qt4_24_semi_automatic_london_brick_making_machine/,dymachine01,1528964477,,1,1
792,2018-6-14,2018,6,14,17,8r0834,Phoenix BMW Mechanic,https://www.reddit.com/r/MachineLearning/comments/8r0834/phoenix_bmw_mechanic/,AliceHughes1,1528965094,,0,1
793,2018-6-14,2018,6,14,17,8r0b4f,"[R] Capturing and codifying Chinese text semantics using ""strokes"", as opposed to characters or radicals (Alibaba)",https://www.reddit.com/r/MachineLearning/comments/8r0b4f/r_capturing_and_codifying_chinese_text_semantics/,nianhao,1528966265,,0,8
794,2018-6-14,2018,6,14,17,8r0bs6,Object detection Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8r0bs6/object_detection_tensorflow/,exoticpandaOo,1528966560,[removed],0,1
795,2018-6-14,2018,6,14,18,8r0lvo,Starting out as a Machine Learning Data Analyst [Repost: /r/cscareerquestions],https://www.reddit.com/r/MachineLearning/comments/8r0lvo/starting_out_as_a_machine_learning_data_analyst/,Darnegar,1528970159,[removed],0,1
796,2018-6-14,2018,6,14,19,8r0njf,[D] How to preprocess multivariate time-series data,https://www.reddit.com/r/MachineLearning/comments/8r0njf/d_how_to_preprocess_multivariate_timeseries_data/,__bee,1528970734,"Hi all,

I am currently working on a project to forecast time\-series data. The data looks like this:

I have water usage in farms (on hourly basis for every part of the land). It's a very big farm, every big part contain some kind of plants. I divided the land to small squares. Furthermore I also have on top of that the weather data. Obviously, the hotter weather is, the more plants consume water. I have other information such wind, rain, type of plants on this square.. etc

In order to tackle the problem, I was thinking of treating every small square independently. Every square has 1 time\-series, with other related features that I can use. What would be a good way of preprocessing this? I want to train a LSTM that can predict the use of water. I was thinking of two choices:

1/ use multivariate time\-series data and somehow preprocess data to build multivariate LSTM

2/ process only timeseries and use the other features on the last layer (dense layer)

\*\*Question1\*\* What would be the best option, from the perspective of using LSTM the right way ?

The other thing I was thinking about is incorporating the inter\-related parts (the small cells). I assume that the cells that are near to each others have the same behaviour, so I started thinking of using CNN to capture the regional dependencies/similarities. 

\*\*Question2\*\* Does CNN\-LSTM make sense on this case ?

Thanks in advance for your time. ",17,27
797,2018-6-14,2018,6,14,19,8r0o74,n bt cn trng KTP 30S (keo dnh) Bng n chng v Phm vi : 75 m2 in p my : 220V 50Hz Quy cach (cm) : 29 x 47 x 9 Bng n : 2x 15w,https://www.reddit.com/r/MachineLearning/comments/8r0o74/n_bt_cn_trng_ktp_30s_keo_dnh_bng_n_chng/,HangNguyen1111,1528970939,,0,1
798,2018-6-14,2018,6,14,19,8r0onr,CourseEra certification,https://www.reddit.com/r/MachineLearning/comments/8r0onr/courseera_certification/,StonerStacks,1528971075,[removed],0,1
799,2018-6-14,2018,6,14,19,8r0q8r,50 Best Free Dataset for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8r0q8r/50_best_free_dataset_for_machine_learning/,j_orshman,1528971594,,0,1
800,2018-6-14,2018,6,14,19,8r0qbl,My hn ming ti PFS-400  di mp hn 400mm Chiu rng mp hn 2mm Thi gian dn 0.2-1.5s Trng lng 2.8kg Cng sut 600W,https://www.reddit.com/r/MachineLearning/comments/8r0qbl/my_hn_ming_ti_pfs400__di_mp_hn_400mm/,HangNguyen1111,1528971619,,0,1
801,2018-6-14,2018,6,14,19,8r0qr5,Model Zoo  Pretrained deep learning models,https://www.reddit.com/r/MachineLearning/comments/8r0qr5/model_zoo_pretrained_deep_learning_models/,j_orshman,1528971770,,0,1
802,2018-6-14,2018,6,14,19,8r0r73,Object detection Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8r0r73/object_detection_tensorflow/,exoticpandaOo,1528971920,[removed],0,1
803,2018-6-14,2018,6,14,19,8r0v1n,"[N] Awesome Machine Learning Podcast, feat. leaders like Kaggle's Anthony Goldbloom",https://www.reddit.com/r/MachineLearning/comments/8r0v1n/n_awesome_machine_learning_podcast_feat_leaders/,dearpetra,1528973197,,0,1
804,2018-6-14,2018,6,14,20,8r10wk,An Alternative to Deep Learning? Guide to Hierarchical Temporal Memory (HTM) for Unsupervised Learning,https://www.reddit.com/r/MachineLearning/comments/8r10wk/an_alternative_to_deep_learning_guide_to/,Wolf_of_Valyria,1528975016,,0,1
805,2018-6-14,2018,6,14,20,8r119x,Dates Seed Removing Machine In India,https://www.reddit.com/r/MachineLearning/comments/8r119x/dates_seed_removing_machine_in_india/,lgsherry,1528975140,,1,1
806,2018-6-14,2018,6,14,20,8r13q5,precision machined components in india,https://www.reddit.com/r/MachineLearning/comments/8r13q5/precision_machined_components_in_india/,mamathaindustries,1528975882,[removed],0,1
807,2018-6-14,2018,6,14,20,8r15yb,[1806.04793] A Connectome Based Hexagonal Lattice Convolutional Network Model of the Drosophila Visual System,https://www.reddit.com/r/MachineLearning/comments/8r15yb/180604793_a_connectome_based_hexagonal_lattice/,ihaphleas,1528976513,,4,15
808,2018-6-14,2018,6,14,21,8r1eq0,Parquet + Dask to handle huge data for TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8r1eq0/parquet_dask_to_handle_huge_data_for_tensorflow/,SquareBr4cket,1528978948,"I asked this question on StackOverflow [""Import huge non-image dataset in TensorFlow""](https://stackoverflow.com/q/50814066/4618605) and someone suggested to use Parquet &amp; Dask for manipulating the data and importing them on TensorFlow.

Supposedly dask.dataframe simulates a Pandas dataframe. However,  if you use it in a train_input_fn will it work with a file that is impossible to fit in memory? Will it maintain a connection to the source data file to be able to load data dynamically?

Have someone tried it? Please give me your insights!
",0,1
809,2018-6-14,2018,6,14,21,8r1ksu,[D] How to detect specific fields from OCRed documents?,https://www.reddit.com/r/MachineLearning/comments/8r1ksu/d_how_to_detect_specific_fields_from_ocred/,kalfasyan,1528980560,"Hi, I want to extract text (OCR) from relatively structured documents (scanned receipts) and assign them to relevant fields like ""Date"",""Address"",""Recipient"",""Cost of item #"" etc.

I know how I would go about for the OCR part to extract the text and there are various APIs for that, too. However, I am not sure how I would train a network (?) to detect which field is which and automatically assign them. I presume the text extraction will be kind of messy (depending on the scanned document) so the matching will be hard. What do you think? Any suggestions?",7,12
810,2018-6-14,2018,6,14,22,8r1ojz,[R] Bayesian Model-Agnostic Meta-Learning (Bayesian MAML),https://www.reddit.com/r/MachineLearning/comments/8r1ojz/r_bayesian_modelagnostic_metalearning_bayesian/,jaesik,1528981502,"Meta learning, which is being studied recently, shows good performance with a small amount of data, but it also increases the burden on uncertainty. We tried to solve this problem by solving meta learning as hierarchical Bayesian learning through variational inference.",0,1
811,2018-6-14,2018,6,14,22,8r1oxm,YARN and GPU Distribution for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8r1oxm/yarn_and_gpu_distribution_for_machine_learning/,dworms,1528981586,,1,1
812,2018-6-14,2018,6,14,22,8r1tl7,[D] Algorithms for sequential data analysis?,https://www.reddit.com/r/MachineLearning/comments/8r1tl7/d_algorithms_for_sequential_data_analysis/,justsomerandomoldguy,1528982723,I know that recurrent and convolutional neural networks are widely used for time series/sequential data. Are there any other commonly used algorithms designed to work with such input and achieve somewhat comparable results?,7,2
813,2018-6-14,2018,6,14,23,8r22rn,How MAchine Learning is making our World a Better Place and Its Just The Beginning,https://www.reddit.com/r/MachineLearning/comments/8r22rn/how_machine_learning_is_making_our_world_a_better/,gyansetu23,1528984899,,0,1
814,2018-6-14,2018,6,14,23,8r23l9,[R] Bayesian Model-Agnostic Meta-Learning (Bayesian MAML),https://www.reddit.com/r/MachineLearning/comments/8r23l9/r_bayesian_modelagnostic_metalearning_bayesian/,jaesik,1528985082,,5,15
815,2018-6-14,2018,6,14,23,8r26i7,"[N] Weekly Machine Learning Opensource Roundup  June 14, 2018",https://www.reddit.com/r/MachineLearning/comments/8r26i7/n_weekly_machine_learning_opensource_roundup_june/,stkim1,1528985722,,0,1
816,2018-6-14,2018,6,14,23,8r2dpl,SHAInet Version 2.2.0 released - Added an Evolution Strategies optimizer,https://www.reddit.com/r/MachineLearning/comments/8r2dpl/shainet_version_220_released_added_an_evolution/,bararchy,1528987326,,1,7
817,2018-6-14,2018,6,14,23,8r2f3b,https://arxiv.org/abs/1806.04171,https://www.reddit.com/r/MachineLearning/comments/8r2f3b/httpsarxivorgabs180604171/,bobchennan,1528987639,,0,1
818,2018-6-14,2018,6,14,23,8r2fri,"[R] Synthetic Depth-of-Field with a Single-Camera Mobile Phone (how Google's ""portrait mode"" works)",https://www.reddit.com/r/MachineLearning/comments/8r2fri/r_synthetic_depthoffield_with_a_singlecamera/,bobchennan,1528987784,,0,21
819,2018-6-14,2018,6,14,23,8r2idg,"[D] To learn a game, would you train by playing it or by watching footage of actual players?",https://www.reddit.com/r/MachineLearning/comments/8r2idg/d_to_learn_a_game_would_you_train_by_playing_it/,chub79,1528988351,I'm intrigued what would be the best approach for a model to learn how to play a game. ,11,10
820,2018-6-15,2018,6,15,0,8r2u1t,[P] PyTorch implementation of OpenAI's finetuned Transformer Language Model with a script to import the weights pre-trained by OpenAI,https://www.reddit.com/r/MachineLearning/comments/8r2u1t/p_pytorch_implementation_of_openais_finetuned/,Thomjazz,1528990832,,22,31
821,2018-6-15,2018,6,15,1,8r36tf,[N] ACL Best Paper: Tricky Stanford DataSet Adds Questions That Dont Have Answers,https://www.reddit.com/r/MachineLearning/comments/8r36tf/n_acl_best_paper_tricky_stanford_dataset_adds/,trcytony,1528993464,,0,1
822,2018-6-15,2018,6,15,1,8r3bir,Neural Image Stitching And Morphing Paper,https://www.reddit.com/r/MachineLearning/comments/8r3bir/neural_image_stitching_and_morphing_paper/,BL4CKvGHOST,1528994438,[removed],0,1
823,2018-6-15,2018,6,15,1,8r3ex6,RL environments compliant to the OpenAI Gym API aside from Locomotion and Atari?,https://www.reddit.com/r/MachineLearning/comments/8r3ex6/rl_environments_compliant_to_the_openai_gym_api/,malusmax,1528995140,[removed],0,1
824,2018-6-15,2018,6,15,1,8r3g2d,AI Nationalism,https://www.reddit.com/r/MachineLearning/comments/8r3g2d/ai_nationalism/,manux,1528995363,,1,1
825,2018-6-15,2018,6,15,2,8r3jy5,Natural Language to SQL converter,https://www.reddit.com/r/MachineLearning/comments/8r3jy5/natural_language_to_sql_converter/,JayaYellowAnt,1528996105,,0,1
826,2018-6-15,2018,6,15,2,8r3klt,Real time object detection with YOLO,https://www.reddit.com/r/MachineLearning/comments/8r3klt/real_time_object_detection_with_yolo/,HopelessVlad,1528996236,[removed],0,1
827,2018-6-15,2018,6,15,2,8r3myj,"17 Best Online Courses on Machine Learning, Deep Learning, AI and Big Data Analytics",https://www.reddit.com/r/MachineLearning/comments/8r3myj/17_best_online_courses_on_machine_learning_deep/,tanmoyray01,1528996685,,0,1
828,2018-6-15,2018,6,15,2,8r3vhl,"[D] Forgive me if this breaking any rules but I don't know where else to ask. Can someone speak to whether this is possible at all, or if this is 100% fake?",https://www.reddit.com/r/MachineLearning/comments/8r3vhl/d_forgive_me_if_this_breaking_any_rules_but_i/,about15rats,1528998363,,13,0
829,2018-6-15,2018,6,15,2,8r3yks,Data Sets and Challenge Statements Released for this year's Hack for the Sea,https://www.reddit.com/r/MachineLearning/comments/8r3yks/data_sets_and_challenge_statements_released_for/,aphelionz,1528998973,[removed],0,1
830,2018-6-15,2018,6,15,3,8r414x,[R] Neural scene representation and rendering,https://www.reddit.com/r/MachineLearning/comments/8r414x/r_neural_scene_representation_and_rendering/,jboyml,1528999886,,47,251
831,2018-6-15,2018,6,15,3,8r4cgv,A Simple CNN I Created to Tell Tiffany and Ivanka Trump Apart,https://www.reddit.com/r/MachineLearning/comments/8r4cgv/a_simple_cnn_i_created_to_tell_tiffany_and_ivanka/,RemoteCoder,1529002481,,0,1
832,2018-6-15,2018,6,15,3,8r4dap,[D] Learning to See - Ali Eslami (DeepMind),https://www.reddit.com/r/MachineLearning/comments/8r4dap/d_learning_to_see_ali_eslami_deepmind/,sinshallah,1529002656,,6,20
833,2018-6-15,2018,6,15,5,8r4zov,What approach you would suggest to track a small robot rover from a camera feed ?,https://www.reddit.com/r/MachineLearning/comments/8r4zov/what_approach_you_would_suggest_to_track_a_small/,throwawayfarway2,1529007218,"Given I can take a picture of the rover at start time, then I want to track that guy, as I point the camera to him. I have read about OpenCV's KFC tracker (not available on my platform), but I was wondering what you guys can suggest ?",0,1
834,2018-6-15,2018,6,15,5,8r52b0,Beginner question on handling missing data,https://www.reddit.com/r/MachineLearning/comments/8r52b0/beginner_question_on_handling_missing_data/,zerostyle,1529007756,"Beginner question for making predictions on using missing data with linear regression:

If I have a data set with 7 input fields, and I have a sample that I want to predict classification for that has only 4, 5, 6, etc of those fields, is it better to re-run the model with only those limited fields, or do I run prediction against the full data set and leave those values null?",0,1
835,2018-6-15,2018,6,15,5,8r52mr,[P] What approach you would suggest to track a small robot rover from a camera feed ?,https://www.reddit.com/r/MachineLearning/comments/8r52mr/p_what_approach_you_would_suggest_to_track_a/,throwawayfarway2,1529007819,"Given I can take a picture of the rover at start time, then I want to track that guy, as I point the camera to him. I have read about OpenCV's KFC tracker (not available on my platform), but I was wondering what you guys can suggest ?",4,1
836,2018-6-15,2018,6,15,5,8r574e,Mathematics of deep learning,https://www.reddit.com/r/MachineLearning/comments/8r574e/mathematics_of_deep_learning/,Actuary1997,1529008799,[removed],0,1
837,2018-6-15,2018,6,15,6,8r5f7w,[R] ACL Best Paper: Stanford Reading Comprehension DataSet Adds Questions That Dont Have Answers,https://www.reddit.com/r/MachineLearning/comments/8r5f7w/r_acl_best_paper_stanford_reading_comprehension/,trcytony,1529010512,,0,1
838,2018-6-15,2018,6,15,6,8r5rll,[P] Android app version of Dragonfire open-source virtual assistant is released,https://www.reddit.com/r/MachineLearning/comments/8r5rll/p_android_app_version_of_dragonfire_opensource/,mertyildiran,1529013274,,1,3
839,2018-6-15,2018,6,15,6,8r5s6y,[D] FCIS : Fully Convolutional Instance Aware segmentation Doubt,https://www.reddit.com/r/MachineLearning/comments/8r5s6y/d_fcis_fully_convolutional_instance_aware/,ShivamDuggal4,1529013420,"FCS outputs 2*c*(k^2) score maps, each score map belonging to a categories relative position. The 2 factor is for inside and outside score maps. Inside and Outside score maps were used to carry out both detection and segmentation simultaneously.
My doubt is what is the need of performing detection. In other words, I didn't understand the need of inside and outside score maps. 

For Bbox regression they had a sibling branch, and associated with it was a loss function, which is different from the 2*c*(k^2) score maps.

So, what is the need of inside and outside score maps, rather than just having C*(k^2) score maps for classification and instance segmentation?",3,3
840,2018-6-15,2018,6,15,7,8r5y9w,Implementing YOLO v3 in Tensorflow (TF-Slim),https://www.reddit.com/r/MachineLearning/comments/8r5y9w/implementing_yolo_v3_in_tensorflow_tfslim/,kiarash-irandoust,1529014772,,0,1
841,2018-6-15,2018,6,15,8,8r6i0h,[D] Implementation of Regularizing neural networks by penalizing Confident output distributions,https://www.reddit.com/r/MachineLearning/comments/8r6i0h/d_implementation_of_regularizing_neural_networks/,BenzeneHNO3,1529019582,"Paper: https://arxiv.org/pdf/1701.06548.pdf

Hi guys, I'm new to Keras and Tensorflow and was going through this paper. The basic idea being that adding entropy loss to the network helps in becoming the network less ""over-confident"". Can you help me implement this loss function in Keras/TF or point to an implementation? ",4,2
842,2018-6-15,2018,6,15,9,8r6xto,Mars@Home Chrome Extension - Labels photos from Unsplash.com in your browser using Tensorflow.js &amp; MobileNet,https://www.reddit.com/r/MachineLearning/comments/8r6xto/marshome_chrome_extension_labels_photos_from/,emadehsan,1529023743,,0,1
843,2018-6-15,2018,6,15,10,8r7bxc,[D] Question about sub-pixel convolution,https://www.reddit.com/r/MachineLearning/comments/8r7bxc/d_question_about_subpixel_convolution/,cdc143,1529027626,"Working my way through the paper here: [https://arxiv.org/abs/1609.07009](https://arxiv.org/abs/1609.07009)

The authors make the claim that this algorithm also works for cases where the kernel size &amp;#37; stride != 0, but I can't find much on how exactly this works.",0,2
844,2018-6-15,2018,6,15,10,8r7d15,"[P] Code available for ""Relation Networks for Object Detection"", accepted as Oral for CVPR 2018",https://www.reddit.com/r/MachineLearning/comments/8r7d15/p_code_available_for_relation_networks_for_object/,flyforlight,1529027934,,0,37
845,2018-6-15,2018,6,15,11,8r7efu,Amazons $249 DeepLens Machine Learning Camera is Available for Developers | Analytics Insight,https://www.reddit.com/r/MachineLearning/comments/8r7efu/amazons_249_deeplens_machine_learning_camera_is/,analyticsinsight,1529028287,,0,1
846,2018-6-15,2018,6,15,11,8r7fl2,"[R] How to Train 10,000-Layer Vanilla Convolutional Neural Networks?",https://www.reddit.com/r/MachineLearning/comments/8r7fl2/r_how_to_train_10000layer_vanilla_convolutional/,inarrears,1529028606,,16,49
847,2018-6-15,2018,6,15,11,8r7l4g,The process of 100-year-old wood sawing in the forest in close-up,https://www.reddit.com/r/MachineLearning/comments/8r7l4g/the_process_of_100yearold_wood_sawing_in_the/,Woodworking94,1529030121,,0,1
848,2018-6-15,2018,6,15,11,8r7mw1,[R] [1806.05236] Manifold Mixup: Encouraging Meaningful On-Manifold Interpolation as a Regularizer,https://www.reddit.com/r/MachineLearning/comments/8r7mw1/r_180605236_manifold_mixup_encouraging_meaningful/,alexmlamb,1529030624,,4,23
849,2018-6-15,2018,6,15,12,8r7sgc,Where can I get hand pose dataset recently?,https://www.reddit.com/r/MachineLearning/comments/8r7sgc/where_can_i_get_hand_pose_dataset_recently/,impet14,1529032202,[removed],0,1
850,2018-6-15,2018,6,15,12,8r7xk9,If anybody asked you to explain what is ML? How you are gonna explain to him in a creative way?,https://www.reddit.com/r/MachineLearning/comments/8r7xk9/if_anybody_asked_you_to_explain_what_is_ml_how/,Mohansrk123,1529033701,[removed],0,1
851,2018-6-15,2018,6,15,14,8r8kox,Corrugated Box Making | Rotary Die Cutting Machine Manufacturers Exporters,https://www.reddit.com/r/MachineLearning/comments/8r8kox/corrugated_box_making_rotary_die_cutting_machine/,idea_amritsar,1529040974,[removed],0,1
852,2018-6-15,2018,6,15,14,8r8le0,[P] robot riding a bicycle,https://www.reddit.com/r/MachineLearning/comments/8r8le0/p_robot_riding_a_bicycle/,wei_jok,1529041208,,45,593
853,2018-6-15,2018,6,15,16,8r928u,[D] Neural scene representation and rendering | DeepMind,https://www.reddit.com/r/MachineLearning/comments/8r928u/d_neural_scene_representation_and_rendering/,sksq9,1529046949,,1,2
854,2018-6-15,2018,6,15,16,8r94s5,[D] Twitter meets TensorFlow | Twitter Cortex,https://www.reddit.com/r/MachineLearning/comments/8r94s5/d_twitter_meets_tensorflow_twitter_cortex/,sksq9,1529047900,,5,7
855,2018-6-15,2018,6,15,16,8r97jx,[R] Self-Imitation Learning,https://www.reddit.com/r/MachineLearning/comments/8r97jx/r_selfimitation_learning/,jeasinema,1529048968,,4,11
856,2018-6-15,2018,6,15,16,8r993q,Hng dn lm h thng ti phun sng t ng,https://www.reddit.com/r/MachineLearning/comments/8r993q/hng_dn_lm_h_thng_ti_phun_sng_t_ng/,Mayphunsuongorg,1529049550,,0,1
857,2018-6-15,2018,6,15,17,8r9d1k,Need direction for Making a bot that can understand what user say and work accordingly,https://www.reddit.com/r/MachineLearning/comments/8r9d1k/need_direction_for_making_a_bot_that_can/,jgthedevil,1529051107,[removed],0,1
858,2018-6-15,2018,6,15,17,8r9ecu,Advice for new college student,https://www.reddit.com/r/MachineLearning/comments/8r9ecu/advice_for_new_college_student/,PilarScorpion,1529051667,[removed],0,1
859,2018-6-15,2018,6,15,18,8r9ojk,[D] Does anyone know of any interesting recent developments with regards to using AI in life sciences?,https://www.reddit.com/r/MachineLearning/comments/8r9ojk/d_does_anyone_know_of_any_interesting_recent/,DAJ1,1529055527,"Or, have any good suggestions of where to research it myself?",5,0
860,2018-6-15,2018,6,15,18,8r9ri7,Implementing YOLO v3 in Tensorflow (TF-Slim),https://www.reddit.com/r/MachineLearning/comments/8r9ri7/implementing_yolo_v3_in_tensorflow_tfslim/,Fewthp,1529056610,,0,3
861,2018-6-15,2018,6,15,19,8r9w6x,"ML ""Lab Notebook"" software?",https://www.reddit.com/r/MachineLearning/comments/8r9w6x/ml_lab_notebook_software/,JohnRezzi,1529058259,[removed],0,1
862,2018-6-15,2018,6,15,19,8r9yki,[R] Clinical natural language processing for predicting hospital readmission,https://www.reddit.com/r/MachineLearning/comments/8r9yki/r_clinical_natural_language_processing_for/,dearpetra,1529059126,,0,1
863,2018-6-15,2018,6,15,19,8r9yx5,[N] Webinar on Open Ended Survey Analysis using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8r9yx5/n_webinar_on_open_ended_survey_analysis_using/,molode,1529059258,,0,1
864,2018-6-15,2018,6,15,19,8r9z49,Is this video being react by and AI or is it just fake?,https://www.reddit.com/r/MachineLearning/comments/8r9z49/is_this_video_being_react_by_and_ai_or_is_it_just/,LOKSTED,1529059320,[removed],1,1
865,2018-6-15,2018,6,15,19,8ra1ut,[R] A Gentle Introduction to the Chi-Squared Test for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8ra1ut/r_a_gentle_introduction_to_the_chisquared_test/,digitalson,1529060267,,0,1
866,2018-6-15,2018,6,15,20,8ra978,700 kg/h Automatic Sesame Tahini Grinding Machine,https://www.reddit.com/r/MachineLearning/comments/8ra978/700_kgh_automatic_sesame_tahini_grinding_machine/,lgsherry,1529062587,,1,1
867,2018-6-15,2018,6,15,20,8ra9f0,Financial spreadsheet training data?,https://www.reddit.com/r/MachineLearning/comments/8ra9f0/financial_spreadsheet_training_data/,salkhan,1529062662,[removed],0,1
868,2018-6-15,2018,6,15,22,8raxfy,Google's Deepmind Can Create 3D Models From 2D Images Using Generative Query Network,https://www.reddit.com/r/MachineLearning/comments/8raxfy/googles_deepmind_can_create_3d_models_from_2d/,cpt_snowcrash,1529069201,,0,1
869,2018-6-15,2018,6,15,22,8rb52u,I made a GPU cluster and free website to help detecting and classifying breast mammogram lesions for general public,https://www.reddit.com/r/MachineLearning/comments/8rb52u/i_made_a_gpu_cluster_and_free_website_to_help/,coolwulf,1529071169,,0,1
870,2018-6-16,2018,6,16,0,8rbp1u,[D] A more focused community,https://www.reddit.com/r/MachineLearning/comments/8rbp1u/d_a_more_focused_community/,Cartesian_Currents,1529075565,"Recently a gif of  robot riding a bicycle with no context reached the top of the subreddit and in actuality it had nothing to do with machine learning. 

I think there should be a rule against posting this sort of content without a reference to a paper or repository. I think this is fair as it allows people to post interesting gifs, but makes sure there's some substance to it.

Additionally I feel that there's less focused discussion on papers/methods and a lot of individual questions when we should probably be promoting r/MLQuestions for that in most cases. ",44,153
871,2018-6-16,2018,6,16,0,8rbpay,[P] A simple variational autoencoder written entirely in Numpy/Cupy,https://www.reddit.com/r/MachineLearning/comments/8rbpay/p_a_simple_variational_autoencoder_written/,kwj2104,1529075625,,3,5
872,2018-6-16,2018,6,16,0,8rbqm3,tiny-yolo weight and cfg corresponding file,https://www.reddit.com/r/MachineLearning/comments/8rbqm3/tinyyolo_weight_and_cfg_corresponding_file/,Ankit-gupta2257074,1529075904,[removed],0,1
873,2018-6-16,2018,6,16,1,8rc251,"[OC] DreamBank Visualized - Using Sentence Vectors / Dimensionality Reduction to Visualize 26,000 Dream Transcriptions",https://www.reddit.com/r/MachineLearning/comments/8rc251/oc_dreambank_visualized_using_sentence_vectors/,josauder,1529078409,,1,1
874,2018-6-16,2018,6,16,1,8rc32i,[N]Launching the Wolfram Neural Net Repository,https://www.reddit.com/r/MachineLearning/comments/8rc32i/nlaunching_the_wolfram_neural_net_repository/,MountainHawk81,1529078592,,6,11
875,2018-6-16,2018,6,16,1,8rcb4x,[P] Learning to segment pages with Gluon on the IAM dataset for handwritten character recognition - x-post r/mxnet,https://www.reddit.com/r/MachineLearning/comments/8rcb4x/p_learning_to_segment_pages_with_gluon_on_the_iam/,thomasdlt,1529080334,,1,5
876,2018-6-16,2018,6,16,2,8rcl6j,What skills are required to move from a data analyst role to ML/ AI engineer apart from ML/ AI knowledge?,https://www.reddit.com/r/MachineLearning/comments/8rcl6j/what_skills_are_required_to_move_from_a_data/,dhrj,1529082487,"I am working as a data analyst consultant and want to move into ML/ AI developer roles. Current job duties include writing SQL/ python code to analyze data, Informatica mappings to clean and load data and talking to business users about requirements and training. I am comfortable with writing code and can optimize PL/SQL queries . I completed the AI nanodegree from Udacity and work on Kaggle projects, go through code from GitHub repositories to learn more. I am thinking about taking the AWS developer certification to learn the development side of things like building complete pipelines, CI/CD processes and using AWS services. I want to learn how to build and deploy models into production and having something more than just Jupyter notebooks on my Github will help with the job hunting process. Are there any must-have skills I am missing that I have to consider to move into a junior/mid level developer role? My plan is to get into a new job in Jan and want to start interviewing from Oct. Thanks!",0,1
877,2018-6-16,2018,6,16,2,8rcr3o,Finding Where's Waldo using Mask R-CNN,https://www.reddit.com/r/MachineLearning/comments/8rcr3o/finding_wheres_waldo_using_mask_rcnn/,alseambusher,1529083766,,0,1
878,2018-6-16,2018,6,16,2,8rcswt,"Birch  an imperative, object-oriented, universal probabilistic programming language capable of inference (C++)",https://www.reddit.com/r/MachineLearning/comments/8rcswt/birch_an_imperative_objectoriented_universal/,webdrone,1529084152,,0,1
879,2018-6-16,2018,6,16,2,8rcvdx,AI Weekly 15 June 2018,https://www.reddit.com/r/MachineLearning/comments/8rcvdx/ai_weekly_15_june_2018/,TomekB,1529084686,,0,1
880,2018-6-16,2018,6,16,3,8rd3q3,"A new paper on AI by Yann Lecun and his team on ""Unsupervisedly Learned Relational Graphs as Transferable Representations""",https://www.reddit.com/r/MachineLearning/comments/8rd3q3/a_new_paper_on_ai_by_yann_lecun_and_his_team_on/,specialistuser,1529086453,[removed],0,1
881,2018-6-16,2018,6,16,3,8rd5t2,Machine learning predicts World Cup winner,https://www.reddit.com/r/MachineLearning/comments/8rd5t2/machine_learning_predicts_world_cup_winner/,jonfla,1529086908,,0,1
882,2018-6-16,2018,6,16,3,8rd88f,DeepMind et al Paper Trumpets Graph Networks,https://www.reddit.com/r/MachineLearning/comments/8rd88f/deepmind_et_al_paper_trumpets_graph_networks/,gwen0927,1529087455,,0,1
883,2018-6-16,2018,6,16,3,8rd8j2,[N] DeepMind et al Paper Trumpets Graph Networks,https://www.reddit.com/r/MachineLearning/comments/8rd8j2/n_deepmind_et_al_paper_trumpets_graph_networks/,gwen0927,1529087523,,0,1
884,2018-6-16,2018,6,16,3,8rdd0i,"[R] It Takes Two Neurons To Ride a Bicycle (NIPS 2004 Demo, PDF link)",https://www.reddit.com/r/MachineLearning/comments/8rdd0i/r_it_takes_two_neurons_to_ride_a_bicycle_nips/,wei_jok,1529088504,,2,11
885,2018-6-16,2018,6,16,4,8rdm1v,"[D] PyData Ann Arbor: Leland McInnes | PCA, t-SNE, and UMAP: Modern Approaches to Dimension Reduction",https://www.reddit.com/r/MachineLearning/comments/8rdm1v/d_pydata_ann_arbor_leland_mcinnes_pca_tsne_and/,_alphamaximus_,1529090513,,0,1
886,2018-6-16,2018,6,16,4,8rdpwy,[P]I made a GPU cluster and free website to help detecting and classifying breast mammogram lesions for general public,https://www.reddit.com/r/MachineLearning/comments/8rdpwy/pi_made_a_gpu_cluster_and_free_website_to_help/,coolwulf,1529091412,,111,1046
887,2018-6-16,2018,6,16,5,8re3y8,[N] DeepMind et al Paper Trumpets Graph Networks,https://www.reddit.com/r/MachineLearning/comments/8re3y8/n_deepmind_et_al_paper_trumpets_graph_networks/,trcytony,1529094560,,0,1
888,2018-6-16,2018,6,16,5,8re53m,Correct way to compare Markov models and select the right order,https://www.reddit.com/r/MachineLearning/comments/8re53m/correct_way_to_compare_markov_models_and_select/,vrwip,1529094822,[removed],0,1
889,2018-6-16,2018,6,16,5,8re86s,"[P] Using Sentence Embeddings, T-SNE and Autoencoders to Visualize 26,000 Dreams",https://www.reddit.com/r/MachineLearning/comments/8re86s/p_using_sentence_embeddings_tsne_and_autoencoders/,josauder,1529095508,,3,17
890,2018-6-16,2018,6,16,6,8rem5p,[D] Better image translation with attention,https://www.reddit.com/r/MachineLearning/comments/8rem5p/d_better_image_translation_with_attention/,leehomyc,1529098774,,0,1
891,2018-6-16,2018,6,16,6,8reo07,"ImageNet experiment code for ""Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs"", CVPR 2018",https://www.reddit.com/r/MachineLearning/comments/8reo07/imagenet_experiment_code_for_zeroshot_recognition/,vegetarianstyle,1529099199,,0,1
892,2018-6-16,2018,6,16,6,8reqgo,Even Ted Lieu (D) calls Harvard Affirmative Action. The article in question is in the comments.,https://www.reddit.com/r/MachineLearning/comments/8reqgo/even_ted_lieu_d_calls_harvard_affirmative_action/,SuccessfulBasket,1529099760,,0,1
893,2018-6-16,2018,6,16,6,8reqib,[P] Computer Vision On Device | Android Tensorflow Lite simple application,https://www.reddit.com/r/MachineLearning/comments/8reqib/p_computer_vision_on_device_android_tensorflow/,TheOSM,1529099770,,0,6
894,2018-6-16,2018,6,16,6,8reqoe,Blockchain Meets Machine Learning and IoT - Power of Three,https://www.reddit.com/r/MachineLearning/comments/8reqoe/blockchain_meets_machine_learning_and_iot_power/,svarada,1529099813,[removed],0,1
895,2018-6-16,2018,6,16,7,8reri9,"ImageNet experiment code for ""Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs""",https://www.reddit.com/r/MachineLearning/comments/8reri9/imagenet_experiment_code_for_zeroshot_recognition/,vegetarianstyle,1529100020,[removed],0,1
896,2018-6-16,2018,6,16,8,8rfiwn,[D] Training deep learning models on a CPU,https://www.reddit.com/r/MachineLearning/comments/8rfiwn/d_training_deep_learning_models_on_a_cpu/,FlyingQuokka,1529107101,"I didn't really figure I'd need a GPU while buying my laptop: [link to specs here](https://support.hp.com/us-en/document/c04778881). As a result I end up having to (try to) train deep learning models on the CPU, which raises its temperature beyond 70 C. This worries me, so I can barely ever do real training.  

This was never an issue with machine learning, though maybe I've never done something big enough? Redditors with a CPU, what do you do?",1,1
897,2018-6-16,2018,6,16,9,8rfsvu,The Basics Of Ai explained -heres a video which helps to break down tough concepts in artificial intelligence for those who are new to it or arent that strong in the tech field.The sources for the information in the vid can be found in the description,https://www.reddit.com/r/MachineLearning/comments/8rfsvu/the_basics_of_ai_explained_heres_a_video_which/,TheScienceVerse,1529109820,,0,1
898,2018-6-16,2018,6,16,9,8rfu6k,"[P] ImageNet experiment code for ""Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs""",https://www.reddit.com/r/MachineLearning/comments/8rfu6k/p_imagenet_experiment_code_for_zeroshot/,vegetarianstyle,1529110199,[removed],0,1
899,2018-6-16,2018,6,16,9,8rfu9v,[D] High-dimensionality input sequence to convolutional network,https://www.reddit.com/r/MachineLearning/comments/8rfu9v/d_highdimensionality_input_sequence_to/,Zee2,1529110226,"Hi folks,

I'm currently working on a project where I am doing sequence-to-sequence prediction, and I'm evaluating several models of networks. For this particular instance, I'm evaluating the use of deep convolutional networks to predict a time series. My input series is a fixed-length sequence of vectors each with a length/""feature dimension"" of 16. 

I'm intending on using a 1-dimensional ""causal"" convolutional network, similar to that used in Google's famous WaveNet project. However, I'm still thinking about how to intelligently deal with the high dimensionality of my input. WaveNet, for instance, operates on simple single-value audio waveforms, whereas my input ""waveform"" has many independent channels.

Does anybody here have experience with this and Keras?

Thanks.",6,9
900,2018-6-16,2018,6,16,10,8rfx4l,"[P] ImageNet experiment code for ""Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs"" https://github.com/JudyYe/zero-shot-gcn",https://www.reddit.com/r/MachineLearning/comments/8rfx4l/p_imagenet_experiment_code_for_zeroshot/,vegetarianstyle,1529111035,,0,1
901,2018-6-16,2018,6,16,10,8rfz6r,"[P] ImageNet experiment code for ""Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs""",https://www.reddit.com/r/MachineLearning/comments/8rfz6r/p_imagenet_experiment_code_for_zeroshot/,vegetarianstyle,1529111642,,4,12
902,2018-6-16,2018,6,16,10,8rg02n,Can you recommend any ML paper/blogs for visual art detection?,https://www.reddit.com/r/MachineLearning/comments/8rg02n/can_you_recommend_any_ml_paperblogs_for_visual/,Loggerny,1529111889,,0,1
903,2018-6-16,2018,6,16,15,8rhkf8,Space Data Symposia June 25th - Texas Medical Center Innovation Institute,https://www.reddit.com/r/MachineLearning/comments/8rhkf8/space_data_symposia_june_25th_texas_medical/,QuantumAir,1529129675,[removed],0,1
904,2018-6-16,2018,6,16,16,8rhs5a,[R] Learning Real-World Robot Policies by Dreaming,https://www.reddit.com/r/MachineLearning/comments/8rhs5a/r_learning_realworld_robot_policies_by_dreaming/,baylearn,1529132771,,0,4
905,2018-6-16,2018,6,16,17,8ri7ew,TensorFlow implementation of Deep Q Learning,https://www.reddit.com/r/MachineLearning/comments/8ri7ew/tensorflow_implementation_of_deep_q_learning/,mlvpj,1529139387,,0,1
906,2018-6-16,2018,6,16,20,8rirmo,Glimpse of Machine learning,https://www.reddit.com/r/MachineLearning/comments/8rirmo/glimpse_of_machine_learning/,seoaleait,1529148218,,0,1
907,2018-6-16,2018,6,16,20,8riswv,[Jobs board] If you hire talent or look for jobs in the AI industry: https://nutech.io/,https://www.reddit.com/r/MachineLearning/comments/8riswv/jobs_board_if_you_hire_talent_or_look_for_jobs_in/,diolor,1529148741,[removed],0,1
908,2018-6-16,2018,6,16,20,8riu5t,High Grade Comb Binding Machine in Singapore,https://www.reddit.com/r/MachineLearning/comments/8riu5t/high_grade_comb_binding_machine_in_singapore/,kennywilliamson1990,1529149284,,0,1
909,2018-6-16,2018,6,16,22,8rj7nt,Tensorflow seq2seq Text Summarization.,https://www.reddit.com/r/MachineLearning/comments/8rj7nt/tensorflow_seq2seq_text_summarization/,ganji1055,1529154170,,0,57
910,2018-6-16,2018,6,16,22,8rj7z9,[D] Top 5 Programming Languages used For Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8rj7z9/d_top_5_programming_languages_used_for_machine/,TheLastLived,1529154273,,1,0
911,2018-6-16,2018,6,16,23,8rjim5,Neural networks tips and tricks,https://www.reddit.com/r/MachineLearning/comments/8rjim5/neural_networks_tips_and_tricks/,Stelman,1529157651,,0,1
912,2018-6-17,2018,6,17,0,8rjvrg,[P] Deep Q Learning Space Invaders  with Tensorflow (video tutorial),https://www.reddit.com/r/MachineLearning/comments/8rjvrg/p_deep_q_learning_space_invaders_with_tensorflow/,cranthir_,1529161291,"Hey there!

The second video of Deep Reinforcement Learning course with Tensorflow is out 

In this video we'll implement an \*\*Deep Q-learning agent with Tensorflow that learns to play Atari Space Invaders \*\* 

The video  : [https://www.youtube.com/watch?v=gCJyVX98KJ4](https://www.youtube.com/watch?v=gCJyVX98KJ4)

The notebook  : [https://github.com/simoninithomas/Deep\_reinforcement\_learning\_Course/tree/master/DQN/Space&amp;#37;20Invaders](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/tree/master/DQN/Space%20Invaders)

The article  : [https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8](https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8)

The Syllabus of the course : [https://simoninithomas.github.io/Deep\_reinforcement\_learning\_Course/](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)

*Processing gif lny1zmgtmd411...*

Again let me say \*\*what you think about the course (articles and videos) and how it should be improved\*\*!

Thanks for your help! ",1,57
913,2018-6-17,2018,6,17,0,8rjwm5,[N] UK report warns DeepMind Health could gain excessive monopoly power,https://www.reddit.com/r/MachineLearning/comments/8rjwm5/n_uk_report_warns_deepmind_health_could_gain/,phobrain,1529161510,,47,190
914,2018-6-17,2018,6,17,0,8rjyv1,Complete Panda Library commands in one page- Python for Data Science,https://www.reddit.com/r/MachineLearning/comments/8rjyv1/complete_panda_library_commands_in_one_page/,stuartown,1529162061,,0,1
915,2018-6-17,2018,6,17,3,8rlg6m,Degradation problem - resnet,https://www.reddit.com/r/MachineLearning/comments/8rlg6m/degradation_problem_resnet/,deepmariaaa,1529175463,[removed],0,1
916,2018-6-17,2018,6,17,5,8rm32y,What do business/enterprise types mean when the say AI? Because they love to say it!,https://www.reddit.com/r/MachineLearning/comments/8rm32y/what_do_businessenterprise_types_mean_when_the/,Jailteacher,1529181378,[removed],0,1
917,2018-6-17,2018,6,17,6,8rma04,Is the comparison made in Figure 1 of the A3C paper a little unfair?,https://www.reddit.com/r/MachineLearning/comments/8rma04/is_the_comparison_made_in_figure_1_of_the_a3c/,ADGEfficiency,1529183166,[removed],0,1
918,2018-6-17,2018,6,17,6,8rmklw,University Statistical Data Science Assignments/Project,https://www.reddit.com/r/MachineLearning/comments/8rmklw/university_statistical_data_science/,yqzr09,1529185948,,0,1
919,2018-6-17,2018,6,17,7,8rmmjo,Related to FRBM,https://www.reddit.com/r/MachineLearning/comments/8rmmjo/related_to_frbm/,Siddhartha10,1529186458,[removed],0,1
920,2018-6-17,2018,6,17,8,8rn6mk,Theoretically what is an Artificial Super Intelligence capable of ?,https://www.reddit.com/r/MachineLearning/comments/8rn6mk/theoretically_what_is_an_artificial_super/,Mewto1k,1529192104,[removed],0,1
921,2018-6-17,2018,6,17,9,8rndo6,"[D] Question on paper Learnable Explicit Density by Huang, Touati, Dinh, ..",https://www.reddit.com/r/MachineLearning/comments/8rndo6/d_question_on_paper_learnable_explicit_density_by/,AloneStretch,1529194178,"In the paper ""Learnable Explicit Density for Continuous Latent Space and Variational Inference"" it proposes the idea of idally setting the prior to be the aggregate approximate posterior q(z) (though this is not possible since q(z) is intractable).

This idea comes several times in the paper. On p.2, 

&gt; our goal is to tran an autoencoder as a generative model by keeping q(z)...close ot the prior),

earlier on p.2

&gt; set the prior to be p(z) = 1/k sum q(z_j|x_j)


I understand the ganeral goal, that q(z) should be close to the prior (and a problem iwth VAEs is that the KL term pulls q(z|x) rather than actually q(z)). The prior is used to ""shape"" the encoding.

My question: why is it a good goal to set the prior to be the approximate posterior?

I feel like in this case the prior has no role, it is just mimicing what would already happen if there was no regularization to a prior.
",8,3
922,2018-6-17,2018,6,17,9,8rnklc,array of variables as independent variable,https://www.reddit.com/r/MachineLearning/comments/8rnklc/array_of_variables_as_independent_variable/,juice_456,1529196266,[removed],0,1
923,2018-6-17,2018,6,17,9,8rnl07,Solving classification problems using Adjacency Matrix in GPU neural networks,https://www.reddit.com/r/MachineLearning/comments/8rnl07/solving_classification_problems_using_adjacency/,3droberto,1529196385,,0,1
924,2018-6-17,2018,6,17,9,8rnl8e,Eye In-Painting with Exemplar Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/8rnl8e/eye_inpainting_with_exemplar_generative/,zindarod,1529196447,,0,1
925,2018-6-17,2018,6,17,9,8rnnca,Stamping Press compact servo feeder ordered by UK automobile parts factory,https://www.reddit.com/r/MachineLearning/comments/8rnnca/stamping_press_compact_servo_feeder_ordered_by_uk/,ChinaDecoiler,1529197099,,0,1
926,2018-6-17,2018,6,17,11,8ro4rw,[D] Why fascism is so tempting -- and how your data could power it | Yuval Noah Harari,https://www.reddit.com/r/MachineLearning/comments/8ro4rw/d_why_fascism_is_so_tempting_and_how_your_data/,phobrain,1529202470,,4,0
927,2018-6-17,2018,6,17,11,8ro4zh,"Besides similarity, what other characteristics embedding have?",https://www.reddit.com/r/MachineLearning/comments/8ro4zh/besides_similarity_what_other_characteristics/,marksteve4,1529202531,[removed],0,1
928,2018-6-17,2018,6,17,11,8ro6cn,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/MachineLearning/comments/8ro6cn/are_you_interested_in_ai_and_want_to_start/,DiscoverAI,1529202987,,0,1
929,2018-6-17,2018,6,17,13,8romn6,Genetic Algorithm For Alert Scheduling,https://www.reddit.com/r/MachineLearning/comments/8romn6/genetic_algorithm_for_alert_scheduling/,Pawwa1996,1529208102,[removed],0,1
930,2018-6-17,2018,6,17,13,8ros3p,What should I see at CVPR?,https://www.reddit.com/r/MachineLearning/comments/8ros3p/what_should_i_see_at_cvpr/,cl194,1529209837,[removed],0,1
931,2018-6-17,2018,6,17,14,8rp3kr,"Hi! Want to learn ""machine learning "". Advice some books/courses about that, please.",https://www.reddit.com/r/MachineLearning/comments/8rp3kr/hi_want_to_learn_machine_learning_advice_some/,IIIKOMAROVAIII,1529213866,[removed],0,1
932,2018-6-17,2018,6,17,15,8rpexk,Genetic Algorithm For Alert Scheduling,https://www.reddit.com/r/MachineLearning/comments/8rpexk/genetic_algorithm_for_alert_scheduling/,Pawwa1996,1529218358,[removed],0,1
933,2018-6-17,2018,6,17,15,8rpfnl,Top 13 Most Asking Machine Learning interview Questions and Answers,https://www.reddit.com/r/MachineLearning/comments/8rpfnl/top_13_most_asking_machine_learning_interview/,Newzywiki,1529218644,[removed],0,1
934,2018-6-17,2018,6,17,16,8rphbp,[R] Autoregressive Quantile Networks for Generative Modeling. (Alternative to MLE+KL?),https://www.reddit.com/r/MachineLearning/comments/8rphbp/r_autoregressive_quantile_networks_for_generative/,angry-zergling,1529219337,,0,70
935,2018-6-17,2018,6,17,18,8rq27l,What are the most popular/state of the art ML algorithms being used right now?,https://www.reddit.com/r/MachineLearning/comments/8rq27l/what_are_the_most_popularstate_of_the_art_ml/,mongobongo23,1529229089,[removed],0,1
936,2018-6-17,2018,6,17,22,8rr17k,"Are you interested in Machine Learning and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/MachineLearning/comments/8rr17k/are_you_interested_in_machine_learning_and_want/,DiscoverAI,1529242305,,0,1
937,2018-6-17,2018,6,17,22,8rr2j9,[D] Data Scraping and Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8rr2j9/d_data_scraping_and_neural_networks/,zero_ethics,1529242662,"Supposedly you manage to scrape someone's else data, say the ones from a big coorporation without them being able to trace you. Assuming you make a product, a neural network that has been trained on their data and try to go commercial, doing something similar to theirs but better. If they notice you and they believe that you did exactly that, can they prove somehow that you infringed on any of their Terms of Service? Assuming again that they can't trace your scraping, and your neural net is not a generative, but discriminative one. ",24,72
938,2018-6-17,2018,6,17,23,8rrhee,Genetic Algorithm For Alert Scheduling,https://www.reddit.com/r/MachineLearning/comments/8rrhee/genetic_algorithm_for_alert_scheduling/,Pawwa1996,1529246789,[removed],0,1
939,2018-6-17,2018,6,17,23,8rrjee,[D] Global AI research centers have run machine learning models to predict World Cup winner,https://www.reddit.com/r/MachineLearning/comments/8rrjee/d_global_ai_research_centers_have_run_machine/,gwen0927,1529247314,,0,1
940,2018-6-17,2018,6,17,23,8rrkcy,"Are you interested in Machine Learning and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/MachineLearning/comments/8rrkcy/are_you_interested_in_machine_learning_and_want/,ailearn12,1529247561,,0,1
941,2018-6-18,2018,6,18,0,8rrr8k,Can someone explain zeros in initial value in tensorflow weights,https://www.reddit.com/r/MachineLearning/comments/8rrr8k/can_someone_explain_zeros_in_initial_value_in/,mikeyyg58,1529249338,[removed],0,1
942,2018-6-18,2018,6,18,1,8rs79z,I had a question about using code from GitHub.,https://www.reddit.com/r/MachineLearning/comments/8rs79z/i_had_a_question_about_using_code_from_github/,anshuman_kmr,1529253544,"I am currently working in an internship where I have been tasked with building a facial recognition system. So I was following the guidelines mentioned in [this](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78) article. But instead of going through exactly with what he had said, I instead went to FDDB websited, browsed the [results](http://vis-www.cs.umass.edu/fddb/results.html) page and found that an algorithm called SFD performs the best possible. I went to GitHub and I found the [official source code](https://github.com/sfzhang15/SFD). So what he has done was build his own neural network which is a version of the very popular [VGG 16](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) neural network. My plan was to use his  model in my code ( I don't intend to plagiarize his code) and see if I can make the thing work. But what I am kind of confused about is whether this is legal or not and whether there might be any issues in doing such a thing.",0,2
943,2018-6-18,2018,6,18,2,8rsimh,A from-scratch implementation of the Convolutional Neural Network. Useful for understanding the underlying mechanics of a CNN :),https://www.reddit.com/r/MachineLearning/comments/8rsimh/a_fromscratch_implementation_of_the_convolutional/,alemadrid11,1529256268,,0,1
944,2018-6-18,2018,6,18,2,8rsjed,"Tried BTC Prediction using LSTM, am I overfitting?",https://www.reddit.com/r/MachineLearning/comments/8rsjed/tried_btc_prediction_using_lstm_am_i_overfitting/,chintansh,1529256453,[removed],0,1
945,2018-6-18,2018,6,18,3,8rssbx,[D] Applying Reinforcement Learning in Besiege (A Physics Based Building Game),https://www.reddit.com/r/MachineLearning/comments/8rssbx/d_applying_reinforcement_learning_in_besiege_a/,eurus-yu,1529258573,"Hey, I am a huge fan of Besiege. In this game you can build very complex machines (cars, planes and even transformers) and control them. How ever, if you build a walker, manually control is very hard. So I want to apply reinforcement learning to this game. I have some questions.

Though I can use MOD to control blocks in this game, it seems that training will be very expansive. Is their a way to transfer knowledge from somewhere else?

I want my control algorithm to keep the walker stable, but i also want to use keys to make it move (left, right, forward, backward). What are the papers that I should read?(I am familar with 
 DL in computer vision and only know basic RL) ",2,4
946,2018-6-18,2018,6,18,4,8rt7xf,"Currently working as an Analyst in FinanceInterested in exploring a career in ML/AI, any advise for those of you who work in the field?",https://www.reddit.com/r/MachineLearning/comments/8rt7xf/currently_working_as_an_analyst_in/,anna_s3,1529262344,[removed],0,1
947,2018-6-18,2018,6,18,6,8ru16f,"[P] GPU-accelerated Deep Learning on Windows 10 native (supports Keras 2.1.6, TensorFlow 1.8.0, CNTK 2.5.1, MXNet 1.2.0 and PyTorch 0.4.0)",https://www.reddit.com/r/MachineLearning/comments/8ru16f/p_gpuaccelerated_deep_learning_on_windows_10/,tezcaML,1529269533,"If, and only if, you \*\*MUST\*\* run Windows 10 and still want decent performance running TensorFlow, PyTorch, or Keras with either TensorFlow, CNTK, or MXNet as a backend, the following guide may help. It provides detailed setup steps for GPU acceleration on Windows 10 \*\*in native mode\*\* -- no VMs, no Docker:

\[[https://github.com/philferriere/dlwin](https://github.com/philferriere/dlwin)\]([https://github.com/philferriere/dlwin](https://github.com/philferriere/dlwin))

The setup instructions and benchmarks were tested on the following hardware:

\* Intel Xeon E5-2630 v4 @ 2.20 GHz (1 processor, 10 cores total, 20 logical processors)

\* NVIDIA GeForce Titan X, 12GB RAM, (Driver version: 390.77 / Win 10 64)

\* NVIDIA GeForce GTX 1080 Ti, 11GB RAM (Driver version: 390.77 / Win 10 64)

The following tools/libraries are now used:

\* Visual Studio 2015 Community Edition Update 3 w. Windows Kit 10.0.10240.0 \[Used for its C/C++ compiler (not its IDE) and SDK\]

\* Anaconda 5.2.0 (64-bit) (Python 3.6 TF support / Python 2.7 no TF support) \[A Python distro that gives us NumPy, SciPy, and other scientific libraries\]

\* Keras 2.1.6 \[Used for deep learning on top of TensorFlow, CNTK, or MXNet\]

\* Tensorflow-gpu 1.8.0 \[Used to evaluate mathematical expressions on multi-dimensional arrays and may serve as a backend for Keras\]

\* CNTK-gpu 2.5.1 \[Used to evaluate mathematical expressions on multi-dimensional arrays and may serve as a backend for Keras\]

\* MXNet-cu90 1.2.0 \[Used to evaluate mathematical expressions on multi-dimensional arrays and may serve as a backend for Keras\]

\* PyTorch 0.4.0 \[Facebook AI Research (FAIR)'s answer to Google's Tensorflow, cannot be used as a Keras backend\]

\* CUDA 9.0.176 (64-bit) \[Used for its GPU math libraries, card driver, and CUDA compiler\]

\* cuDNN v7.0.4 (Nov 13, 2017) for CUDA 9.0 \[Used to run vastly faster convolution neural networks\]

Hope this helps!",7,0
948,2018-6-18,2018,6,18,6,8ru7jx,Retraining an object detection model on fewer classes,https://www.reddit.com/r/MachineLearning/comments/8ru7jx/retraining_an_object_detection_model_on_fewer/,--f4--,1529271109,[removed],0,1
949,2018-6-18,2018,6,18,6,8rue4t,"[D] What Machine Learning hypothesis are you curious about, but will probably never get around to testing and hoping someone else will eventually research it ?",https://www.reddit.com/r/MachineLearning/comments/8rue4t/d_what_machine_learning_hypothesis_are_you/,BatmantoshReturns,1529272759,,108,142
950,2018-6-18,2018,6,18,10,8rvivr,Alert/Alarm scheduling,https://www.reddit.com/r/MachineLearning/comments/8rvivr/alertalarm_scheduling/,Pawwa1996,1529283601,What is the suitable machine learning algorithms to scheduling Alerts/Alarms ?,0,1
951,2018-6-18,2018,6,18,10,8rvl24,[P] I made an engineering notebook to help stay organized in ML,https://www.reddit.com/r/MachineLearning/comments/8rvl24/p_i_made_an_engineering_notebook_to_help_stay/,mtbarta,1529284194,"[https://mtbarta.github.io/monocorpus/](https://mtbarta.github.io/monocorpus/)

This just hit MVP status (and still in active development). I'd love feedback on the idea.

How do you keep organized? I have a markdown file in git that has my notes in it, chronologically ordered. I jot down a lot of *hows* and *whys* that don't fit into issue trackers, and it's helped with very specific bugs that are unique to me and my team. I can go back and figure out how I ran something if I ever forget.

A list of current features:

* Full Text Search
* Chronological ordering of notes
* Title Filters
* Arxiv abstract importing
* KaTeX support
* Markdown support
* Image support (beta)

I'm looking for feedback. What's your development process? Does this not fit for some reason? Is there a feature you consider a must-have? How do you keep track of your work?",5,42
952,2018-6-18,2018,6,18,10,8rvqlv,Help with Rasa NLU,https://www.reddit.com/r/MachineLearning/comments/8rvqlv/help_with_rasa_nlu/,shitjustgotreal_3112,1529285766,[removed],0,1
953,2018-6-18,2018,6,18,11,8rvycq,[R] AI Researchers and the Digital AfterLife - Research Project,https://www.reddit.com/r/MachineLearning/comments/8rvycq/r_ai_researchers_and_the_digital_afterlife/,RothNathan,1529287894,"I am writing to this group to request your participation in a project. We would like to learn how individuals involved in AI research would like their digital footprints to be handled when they die.  I am doing this as  part of my Master's thesis at The Open University in Milton Keynes, England.   

  
Your participation in this research project is completely voluntary. You may decline altogether, or leave blank any questions you dont wish to answer. There are no known risks to participation beyond those encountered in everyday life. Your responses will remain confidential and anonymous. Data from this research will be kept under lock and key and reported only as a collective combined total. No one other than the researchers will know your individual answers.     
If you agree to participate in this project, please answer the questions on the survey as best you can. 

  
It is available here: [https://goo.gl/forms/d8OWpBfluFSmDu843](https://goo.gl/forms/d8OWpBfluFSmDu843) 

  
I'm happy to answer any questions on this project at : [nath.jroth@gmail.com](mailto:nath.jroth@gmail.com).  Information on the rights of human subjects in research is available through The Open University website at: http://www.open.ac.uk/research/ethics 

  
Thank you for your assistance. 

  
Sincerely,   
Nathan Roth   ",3,0
954,2018-6-18,2018,6,18,11,8rw0a4,[D] Seq2seq Training from short to long,https://www.reddit.com/r/MachineLearning/comments/8rw0a4/d_seq2seq_training_from_short_to_long/,maxisawesome538,1529288379,"I've seen several different places say that, when training an RNN and especially if you're using attention, if you train first on shorter sentences and later on longer sentences, you'll get better results.

 I understand why, but how do people execute this in practice? I'm fairly certain going strictly short -&gt; long in the exact order is not a great idea, so I'd love to be able to get an almost exact short to long ordering of my dataset.... is there an easy function or package in python that does this that I've overlooked? If not, how do people do it otherwise?",4,9
955,2018-6-18,2018,6,18,12,8rwaac,"Reinforcement Learning Guidance: Novelty, Uncertainty, Exploration, Long-term Memory",https://www.reddit.com/r/MachineLearning/comments/8rwaac/reinforcement_learning_guidance_novelty/,dcbaugher,1529291101,[removed],0,1
956,2018-6-18,2018,6,18,12,8rwdxh,"[D] Reinforcement Learning: Novelty, Uncertainty, Exploration, Unsupervised Categorization, and Long-term Memory",https://www.reddit.com/r/MachineLearning/comments/8rwdxh/d_reinforcement_learning_novelty_uncertainty/,dcbaugher,1529292127,"Hey all, Ive been thinking about RL for the past few months and I was curious to see if anyone here could give some guidance. Basically pointing me to papers or just a good dialogue would be much appreciated. Im not in school so I dont have much access to others interested in the field.


Uncertainty and exploration: Ive been tinkering with cartpole and using an e-greedy exploration method. But, I dont like fixed or pre-determined exploration rates because theyre just not realistic. One way Ive approached this differently is to increase the likelihood of exploration when the net is uncertain about with action to take. Ive implemented this by looking at the certainty conveyed by the softmax output; higher certainty is conveyed by a larger distance between outputs. Note that certainty doesnt entail accuracy, merely a large about of consistent training for the current state. This does work but my experience is that it takes longer to converge. Open to suggestions.

Novelty nets: Along the lines of thought above it would be nice if upon entering a state the agent knew if it had been there before. Easy enough for the finite case right, but not so for continuous spaces. Itd be great if this would be accomplished with a neural net, but my understanding is that its impossible. You can only update a net with new info via backprop and one cant train on data unseen. Which leads to my next line of thought...

Unsupervised categorization: If youve followed my previous two points this will make more sense. Its a given that learning good categories enables good RL, but most robust categorization methods seem to involve supervised learning. I attribute this to the fact that nets can learn to engineer better distance metrics than the ones classically used in unsupervised learning. It strikes me that in a similar way that people abandoned hand-engineer features for learning them the future of unsupervised learning methods will involve learning the best distance metrics for the data set at hand. BUT, Im not really sure where to start on this. If I could integrate a good unsupervised method that just so happened to have a way to judge classification uncertainty then I could address the novelty and exploration points above in one blow. This leads to my last thought...

Long-term memory: Robust unsupervised learning like that mentioned above would also enable a very compact form of memory storage, and storage in a way that doesnt depend on unraveling RNNs through time. We certainly retain memories bizarrely well. I remember things from both my childhood and yesterday, likely using the same retrieval methods. As Sutton has pointed out, What function approximation cant do, however, is augment the state representation with memories of past observations. I just feel like we need a better way to address long-term memories and its access. For example I can see a new scene that triggers an old memory, which is a scenario that maybe could be well approximated by an LSTM, but could it follow the memory down so to speak; one access triggering a related memory and so on until that linkage chain is exhausted and the useful memories assimilated. I think an unsupervised learning method could very well enable this by use of its learned relation methods.

Thanks to anyone who stuck with me, all thoughts welcome.",26,6
957,2018-6-18,2018,6,18,13,8rwopa,"[R] ""Sample-Efficient Deep RL with Generative Adversarial Tree Search,"" Azizzadenesheli et al.:",https://www.reddit.com/r/MachineLearning/comments/8rwopa/r_sampleefficient_deep_rl_with_generative/,vector_machines,1529295357,,0,10
958,2018-6-18,2018,6,18,14,8rx70w,The Future of HealthCare is Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8rx70w/the_future_of_healthcare_is_artificial/,amberstevens311,1529301267,[removed],0,1
959,2018-6-18,2018,6,18,15,8rxdje,Say Hello to the Arrival of Artificial Intelligence!,https://www.reddit.com/r/MachineLearning/comments/8rxdje/say_hello_to_the_arrival_of_artificial/,amberstevens311,1529303504,[removed],0,1
960,2018-6-18,2018,6,18,15,8rxi3b,Understanding The Human Process in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8rxi3b/understanding_the_human_process_in_machine/,Zeolearn,1529305144,,1,1
961,2018-6-18,2018,6,18,16,8rxjyx,Metacar: A reinforcement learning environment for self-driving cars in the browser.,https://www.reddit.com/r/MachineLearning/comments/8rxjyx/metacar_a_reinforcement_learning_environment_for/,thibo73800,1529305783,,0,1
962,2018-6-18,2018,6,18,16,8rxm2d,[P] Metacar: A reinforcement learning environment for self-driving cars in the browser.,https://www.reddit.com/r/MachineLearning/comments/8rxm2d/p_metacar_a_reinforcement_learning_environment/,thibo73800,1529306524,,0,1
963,2018-6-18,2018,6,18,16,8rxoc5,[D] What does the graphical model for a GAN look like?,https://www.reddit.com/r/MachineLearning/comments/8rxoc5/d_what_does_the_graphical_model_for_a_gan_look/,RobRomijnders,1529307300,"I like to think in terms of graphical models ([book](https://mitpress.mit.edu/books/probabilistic-graphical-models), [course](https://cs.stanford.edu/~ermon/cs228/index.html), [coursera](https://www.coursera.org/learn/probabilistic-graphical-models)). It helped me to understand models like neural nets, naive bayes classifier and the VAE. It also visualizes learning for me in terms of MAP inference, Variatonal inference and MCMC.

Over the last weeks, I have been wondering what the graphical model for the GAN looks like. Questions like: What are the conditional distributions, would it be directed or undirected?",5,11
964,2018-6-18,2018,6,18,16,8rxqrr,[N] Google reduces prices for it's Preemptible GPUs (~40%),https://www.reddit.com/r/MachineLearning/comments/8rxqrr/n_google_reduces_prices_for_its_preemptible_gpus/,svaisakh,1529308199,,27,225
965,2018-6-18,2018,6,18,16,8rxs74,[P] Metacar: A reinforcement learning environment for self-driving cars in the browser.,https://www.reddit.com/r/MachineLearning/comments/8rxs74/p_metacar_a_reinforcement_learning_environment/,thibo73800,1529308755,,0,7
966,2018-6-18,2018,6,18,17,8rxsnc,[R] IoT on AWS: Machine Learning Models and Dashboards from Sensor Data,https://www.reddit.com/r/MachineLearning/comments/8rxsnc/r_iot_on_aws_machine_learning_models_and/,jackblun,1529308916,,0,1
967,2018-6-18,2018,6,18,17,8rxvhy,"[P] Maintaining deep learning projects on Java (DL4J) here. Feel free to add your feedback, contributions or any suggestions. Just started sometime back, more to come :)",https://www.reddit.com/r/MachineLearning/comments/8rxvhy/p_maintaining_deep_learning_projects_on_java_dl4j/,EndyJBC,1529310023,,2,117
968,2018-6-18,2018,6,18,17,8rxx63,Free Online Sources To Learn AI,https://www.reddit.com/r/MachineLearning/comments/8rxx63/free_online_sources_to_learn_ai/,imHarin,1529310684,,0,1
969,2018-6-18,2018,6,18,17,8rxxfk,[R] Gengo.ai Debuts Service for Acquiring Advanced Multilingual Machine-Learning Training Data,https://www.reddit.com/r/MachineLearning/comments/8rxxfk/r_gengoai_debuts_service_for_acquiring_advanced/,dearpetra,1529310794,,0,1
970,2018-6-18,2018,6,18,17,8ry033,[R] Introducing Dask for Scalable Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8ry033/r_introducing_dask_for_scalable_machine_learning/,janemoz,1529311863,,0,1
971,2018-6-18,2018,6,18,18,8ry25a,[D] Labelling tool for video classification,https://www.reddit.com/r/MachineLearning/comments/8ry25a/d_labelling_tool_for_video_classification/,ale152,1529312645,"Hi! I'm looking for a labelling tool that allows me to classify short video sequences (\~4 seconds). In particular, do you know any tool that shows several videos (\~100) simultaneously, so that the user can simply click on them to produce a label? I only have two classes, one of which has much more examples than the other, that's why showing several videos simultaneously would save a lot of time!

Thank you",5,8
972,2018-6-18,2018,6,18,18,8ry57y,[P] OpenAI Retro Contest Report,https://www.reddit.com/r/MachineLearning/comments/8ry57y/p_openai_retro_contest_report/,evc123,1529313749,,0,20
973,2018-6-18,2018,6,18,18,8ry7ao,Vladimir Vapnik and a new model of learning,https://www.reddit.com/r/MachineLearning/comments/8ry7ao/vladimir_vapnik_and_a_new_model_of_learning/,Stelman,1529314483,,0,1
974,2018-6-18,2018,6,18,18,8ry8nc,[P] Baking Decision trees for an introduction to machine learning.,https://www.reddit.com/r/MachineLearning/comments/8ry8nc/p_baking_decision_trees_for_an_introduction_to/,psychicprogrammer,1529314977,,5,31
975,2018-6-18,2018,6,18,19,8rydfw,machine learning/deep learning and binary files,https://www.reddit.com/r/MachineLearning/comments/8rydfw/machine_learningdeep_learning_and_binary_files/,trysomethingdiferent,1529316656,[removed],0,1
976,2018-6-18,2018,6,18,19,8rylnd,What are the BEST theses about the field of modern Machine Learning/Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/8rylnd/what_are_the_best_theses_about_the_field_of/,porygon93,1529319432,[removed],0,1
977,2018-6-18,2018,6,18,20,8ryn93,"corrugated box making machine | corrugated box machine | paper carton box making machine | manufacturer, exporter and supplier of corrugated box making machine in amritsar",https://www.reddit.com/r/MachineLearning/comments/8ryn93/corrugated_box_making_machine_corrugated_box/,idea_amritsar,1529319914,[removed],0,1
978,2018-6-18,2018,6,18,21,8rz08o,Plasma Bevel Cutting Suited for your applications,https://www.reddit.com/r/MachineLearning/comments/8rz08o/plasma_bevel_cutting_suited_for_your_applications/,Messer-123,1529323806,,0,1
979,2018-6-18,2018,6,18,21,8rz0cv,[D] Max Welling is doing an AMA over in AskScience,https://www.reddit.com/r/MachineLearning/comments/8rz0cv/d_max_welling_is_doing_an_ama_over_in_askscience/,NicolasGuacamole,1529323831,,5,33
980,2018-6-18,2018,6,18,21,8rz117,"[N] ELMo, GLoMo, FloydHub Workspaces, AI Principles, NCRF++, TorchFold, AI Talent Report,",https://www.reddit.com/r/MachineLearning/comments/8rz117/n_elmo_glomo_floydhub_workspaces_ai_principles/,omarsar,1529324024,,0,1
981,2018-6-18,2018,6,18,21,8rza30,Which are the best video tutorials to understand the basics and methodologies for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8rza30/which_are_the_best_video_tutorials_to_understand/,abdush,1529326558,[removed],1,1
982,2018-6-18,2018,6,18,23,8rzvv0,Top 20 Python libraries for data science in 2018,https://www.reddit.com/r/MachineLearning/comments/8rzvv0/top_20_python_libraries_for_data_science_in_2018/,viktoriia_shulga,1529331802,,0,9
983,2018-6-19,2018,6,19,0,8s0fq4,"[P] A visual introduction to machine learning, Part II: Model Tuning and the Bias-Variance Tradeoff",https://www.reddit.com/r/MachineLearning/comments/8s0fq4/p_a_visual_introduction_to_machine_learning_part/,pmigdal,1529336072,,10,274
984,2018-6-19,2018,6,19,0,8s0ljz,[NEWS] Understanding Machine Learning Through Visualizations (Podcast),https://www.reddit.com/r/MachineLearning/comments/8s0ljz/news_understanding_machine_learning_through/,W1zK1dd,1529337342,Checkout the podcast!  [https://www.podcastinit.com/yellowbrick-with-bejnamin-bengfort-and-rebecca-bilbro-episode-166/](https://www.podcastinit.com/yellowbrick-with-bejnamin-bengfort-and-rebecca-bilbro-episode-166/),0,4
985,2018-6-19,2018,6,19,1,8s0oby,[P] Simple Preprocessing Steps for Text Classification,https://www.reddit.com/r/MachineLearning/comments/8s0oby/p_simple_preprocessing_steps_for_text/,HichamEB,1529337896,,1,2
986,2018-6-19,2018,6,19,1,8s0ps7,[D] Generate the work vectors for missing words based on context,https://www.reddit.com/r/MachineLearning/comments/8s0ps7/d_generate_the_work_vectors_for_missing_words/,SuccessfulBasket,1529338199,"Let's we are in restaurant domain.

I am saying, "" I need a   \_\_\_\_\_\_ with toppings""

  
A model needs to generate ""pizza"" in the dash.

How do we do that?",4,1
987,2018-6-19,2018,6,19,1,8s0rf5,"[D] Besides similarity, what other characteristics embedding have?",https://www.reddit.com/r/MachineLearning/comments/8s0rf5/d_besides_similarity_what_other_characteristics/,marksteve4,1529338531,Or it's just that. embedding is just representation of objects in the vector space such that similar objects are close to each other,4,7
988,2018-6-19,2018,6,19,1,8s0uu1,[D] resources to make journal-level artwork in ML,https://www.reddit.com/r/MachineLearning/comments/8s0uu1/d_resources_to_make_journallevel_artwork_in_ml/,insider_7,1529339273,"For those experienced in generating art-figures for journals, which software tools and resources do you recommend?

Assuming zero knowledge of design software.",4,4
989,2018-6-19,2018,6,19,1,8s0zam,[N] COLING 2018 Best papers announced,https://www.reddit.com/r/MachineLearning/comments/8s0zam/n_coling_2018_best_papers_announced/,leondz,1529340244,,0,15
990,2018-6-19,2018,6,19,2,8s16d8,Rare events in Logistic Regression?,https://www.reddit.com/r/MachineLearning/comments/8s16d8/rare_events_in_logistic_regression/,myairguitar,1529341703,[removed],0,1
991,2018-6-19,2018,6,19,2,8s1gt6,Data for Ml For Autonomous cars!!!,https://www.reddit.com/r/MachineLearning/comments/8s1gt6/data_for_ml_for_autonomous_cars/,brarbirender,1529343862,"Do Any companies like google,tesla etc provide data gathered from their autonomous's cars sensors to students for their school projects???",0,1
992,2018-6-19,2018,6,19,3,8s1pki,"GitHub - sjchoi86/choicenet: Implementation of ChoiceNet, a Robust Regression Method under Severe Noise",https://www.reddit.com/r/MachineLearning/comments/8s1pki/github_sjchoi86choicenet_implementation_of/,samchoi7,1529345671,,0,15
993,2018-6-19,2018,6,19,3,8s1q3q,The best AI vs Slitherlink puzzles,https://www.reddit.com/r/MachineLearning/comments/8s1q3q/the_best_ai_vs_slitherlink_puzzles/,mitkoofc,1529345791,"Hi, guys! If you are interested in Slitherlink puzzles and/or AI, you can go to my channel and check my video \`The best AI vs Slitherlink puzzles\` ([https://www.youtube.com/watch?v=wm9AHRPbkTo&amp;t=1s](https://www.youtube.com/watch?v=wm9AHRPbkTo&amp;t=1s)). There I show my bot called PuzzleBot, which I developed and specialised in solving such puzzles. It is extremely efficient and despite mimicking the human reasoning behind solving such puzzles, it is 5-10 THOUSAND TIMES FASTER THAN A HUMAN. I'd be really happy if you go check it out and if you like this video presentation, do not forget to like the video, leave a comment and subscribe to my channel for more videos like this one in the near future. :) ",0,1
994,2018-6-19,2018,6,19,3,8s1uh1,How to classify Knowledge Graph relationships in FastText,https://www.reddit.com/r/MachineLearning/comments/8s1uh1/how_to_classify_knowledge_graph_relationships_in/,Loggerny,1529346734,,0,1
995,2018-6-19,2018,6,19,3,8s1x2f,[P] Forums for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8s1x2f/p_forums_for_machine_learning/,JimmyJumpdrive,1529347294,"I'm a software engineer newish to machine learning, and had been looking around for a machine learning forum in a standard categorical forum format (like smf or phpbb), but have had trouble finding one. When I began learning programming, I started on an smf forum board and found it really convenient that all the resource and learning material I needed was all in one place. Whenever i needed help, i'd ask a question, a veteran member would usually get back to me and answer any following questions I had. I feel community forum boards also encourages seasoned developers to assist new developers in learning by answering questions and creating tutorials.

That being said, I've taken it upon myself to open a forum board dedicated to machine learning and wanted to see if it would pick up interest. If anyone's interested, i'm looking for seasoned developers for moderation and administration, and would like run some ML competitions once traffic picks up. If interested, you can find the forum boards at MachineLearningForums.com",1,0
996,2018-6-19,2018,6,19,3,8s1y7r,[R] Hierarchical Neural Story Generation (FAIR),https://www.reddit.com/r/MachineLearning/comments/8s1y7r/r_hierarchical_neural_story_generation_fair/,wei_jok,1529347537,,11,38
997,2018-6-19,2018,6,19,3,8s1zal,GFSOpt: Convenient hyperparameter optimization using an upper-bounding model (Python),https://www.reddit.com/r/MachineLearning/comments/8s1zal/gfsopt_convenient_hyperparameter_optimization/,tsorn,1529347756,,1,8
998,2018-6-19,2018,6,19,4,8s238g,[Book recommendation] Please help me pick a good book on introductory probability theory,https://www.reddit.com/r/MachineLearning/comments/8s238g/book_recommendation_please_help_me_pick_a_good/,dileepbn1,1529348588,[removed],0,1
999,2018-6-19,2018,6,19,4,8s24dm,[N] Full Stack Deep Learning | Hands-on program for developers familiar with the basics of deep learning,https://www.reddit.com/r/MachineLearning/comments/8s24dm/n_full_stack_deep_learning_handson_program_for/,sksq9,1529348813,,7,1
1000,2018-6-19,2018,6,19,4,8s27v9,How Ubcoin Market uses Machine Learning to filter contents,https://www.reddit.com/r/MachineLearning/comments/8s27v9/how_ubcoin_market_uses_machine_learning_to_filter/,Ubcoin,1529349649,,0,1
1001,2018-6-19,2018,6,19,4,8s2bum,"[P] Pytorch implementation of FactorVAE(Disentangling by Factorising, Kim et al)",https://www.reddit.com/r/MachineLearning/comments/8s2bum/p_pytorch_implementation_of/,1Konny,1529350457,[removed],0,1
1002,2018-6-19,2018,6,19,4,8s2cav,"Forge.AI - Veracity: Models, Methods, and Morals",https://www.reddit.com/r/MachineLearning/comments/8s2cav/forgeai_veracity_models_methods_and_morals/,jenniferlum,1529350549,,0,1
1003,2018-6-19,2018,6,19,5,8s2klf,DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars,https://www.reddit.com/r/MachineLearning/comments/8s2klf/deeptest_automated_testing_of/,PM_UR_LOSS_FUNCTIONS,1529352271,,2,8
1004,2018-6-19,2018,6,19,5,8s2lr4,Is there a way to know all the workshops a conference has?,https://www.reddit.com/r/MachineLearning/comments/8s2lr4/is_there_a_way_to_know_all_the_workshops_a/,nivm321,1529352511,[removed],0,1
1005,2018-6-19,2018,6,19,5,8s2oc7,Attacks Against Machine Learning  An Overview,https://www.reddit.com/r/MachineLearning/comments/8s2oc7/attacks_against_machine_learning_an_overview/,TebbaVonMathenstein,1529353018,,0,1
1006,2018-6-19,2018,6,19,5,8s2vp6,Student looking for advice: applicability of LSTM for predicting head movement?,https://www.reddit.com/r/MachineLearning/comments/8s2vp6/student_looking_for_advice_applicability_of_lstm/,theburritoeater,1529354559,"Hi, I am an undergraduate student at UMass Amherst working on a project where I am trying to stream VR video with better overall Quality of Expierence for the user by predicting where the user is going to have their head oriented (their Field of View) at a given frame, hopefully up to 2-3 seconds in advance.  

I am self taught when it comes to machine learning, so I wanted to come to the community to ask about the feasibility of my idea before possibly wasting my univeristy's and professor's time.  

I have a dataset of 60 people here watching 6 virtual reality videos, and their head positions in 3D frame-by-frame.  I then took each video, and produced a saliency map frame-by-frame to mark the ""most interesting"" parts of the video.

What I was wanting to do is use an LSTM, trained on *previous head positions* *and salient areas*, to be able to predict *where the user will look 2-3 seconds in advance*, given I have the saliency map of an arbritrary video as input.

Is this a feasibile problem?

Is an LSTM the first type of architecture I should be looking into if so?  I've done some research and some people **praise** LSTMs for their work on time sensitive information, but other people say time series specifically are not the best for LSTMs because they will look heavily on the previous time step for their prediction which can be a problem.

Just some additional information if anybody is curious as to why I want to produce this model:  If I know the user's head movement 2-3 seconds in advance, I can then use SVC video encoding to incrementally upgrade *certain* areas of the video, while keeping others at lower quality to meet bandwitdth requirements in the case that this VR video is being streamed over a network.  

Thanks for the time for reading my post!",0,1
1007,2018-6-19,2018,6,19,6,8s35s1,Day 1 experience - Journey to learn machine learning. Python over R?,https://www.reddit.com/r/MachineLearning/comments/8s35s1/day_1_experience_journey_to_learn_machine/,dadak5,1529356651,,0,1
1008,2018-6-19,2018,6,19,6,8s39g0,[N] NCRF Deep Learning Framework Improves Cancer Metastasis Detection,https://www.reddit.com/r/MachineLearning/comments/8s39g0/n_ncrf_deep_learning_framework_improves_cancer/,gwen0927,1529357432,,0,1
1009,2018-6-19,2018,6,19,7,8s3t98,[D] Toronto Deep Learning YouTube Series,https://www.reddit.com/r/MachineLearning/comments/8s3t98/d_toronto_deep_learning_youtube_series/,sksq9,1529361788,,1,10
1010,2018-6-19,2018,6,19,8,8s43cq,An open source dataset annotation tool,https://www.reddit.com/r/MachineLearning/comments/8s43cq/an_open_source_dataset_annotation_tool/,timkpaine,1529364161,,0,1
1011,2018-6-19,2018,6,19,9,8s4g2m,An open source tool for dataset annotation,https://www.reddit.com/r/MachineLearning/comments/8s4g2m/an_open_source_tool_for_dataset_annotation/,timkpaine,1529367259,,0,1
1012,2018-6-19,2018,6,19,11,8s57en,How to process images with different size in machine learning?,https://www.reddit.com/r/MachineLearning/comments/8s57en/how_to_process_images_with_different_size_in/,Frankie2019,1529374322,"I want to matchI have a photo (p) and a library of images(M).

I want to find similar images of p in M.

All the images in M have different sizes, so the process is more complicated to fixed sizes.

I notice that google has this function. What is the mechanism and algorithm for that?

I searched on the web. In deep learning, a CNN is used first followed by LSTM and then dense layer.

However, there are some problems.

First, the image sizes are assumed to be fixed. It is suggested to crop the images before processing. In reality, some important information may be lost due to improper crop. How to deal with variable sizes?

Second, this is a classification problem using training set. In reality, training samples of some classes are much fewer than the others. It may affect the accuracy. How to compare pairwise images, that is, compare every images in M to p and find the most similar one in M instead of doing classification?

Any examples on similar image processing?

Thank you very much.",0,1
1013,2018-6-19,2018,6,19,11,8s59w4,Commercial Use Peanut Butter Line,https://www.reddit.com/r/MachineLearning/comments/8s59w4/commercial_use_peanut_butter_line/,Machineprices,1529374981,[removed],1,1
1014,2018-6-19,2018,6,19,11,8s5err,Coconut Oil Press Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8s5err/coconut_oil_press_machine_for_sale/,Machineprices,1529376214,[removed],0,1
1015,2018-6-19,2018,6,19,11,8s5hme,Pomegranate Peeling Shelling Machine Manufacturer In China,https://www.reddit.com/r/MachineLearning/comments/8s5hme/pomegranate_peeling_shelling_machine_manufacturer/,Machineprices,1529376940,[removed],1,1
1016,2018-6-19,2018,6,19,12,8s5m9q,Average raw or binary,https://www.reddit.com/r/MachineLearning/comments/8s5m9q/average_raw_or_binary/,bbateman2011,1529378166,[removed],0,1
1017,2018-6-19,2018,6,19,12,8s5o5f,Use cases for transfer learning in deep neural networks,https://www.reddit.com/r/MachineLearning/comments/8s5o5f/use_cases_for_transfer_learning_in_deep_neural/,keoriprefecture,1529378685,[removed],0,1
1018,2018-6-19,2018,6,19,12,8s5pk0,Peanut Shelling And Stone Removing Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8s5pk0/peanut_shelling_and_stone_removing_machine_for/,Machineprices,1529379081,,1,1
1019,2018-6-19,2018,6,19,13,8s5zih,Transformationally Identical and Invariant Convolutional Neural Networks through Symmetric Element Operators,https://www.reddit.com/r/MachineLearning/comments/8s5zih/transformationally_identical_and_invariant/,SBENLO,1529381930,[removed],0,1
1020,2018-6-19,2018,6,19,15,8s6lb2,A transfer learning tutorial in Chinese. Are you interested in the English version?,https://www.reddit.com/r/MachineLearning/comments/8s6lb2/a_transfer_learning_tutorial_in_chinese_are_you/,jindongwang,1529388765,,0,1
1021,2018-6-19,2018,6,19,15,8s6mn1,Machine Learning Course | Artificial Intelligence Course,https://www.reddit.com/r/MachineLearning/comments/8s6mn1/machine_learning_course_artificial_intelligence/,nandiniravichandran,1529389202,,0,1
1022,2018-6-19,2018,6,19,15,8s6muw,http://www.machineprices.com/cutting-machine/peanut-chopping-cutting-machine.html,https://www.reddit.com/r/MachineLearning/comments/8s6muw/httpwwwmachinepricescomcuttingmachinepeanutchoppin/,Machineprices,1529389280,[removed],1,1
1023,2018-6-19,2018,6,19,15,8s6paz,RNN with Keras: Understanding computations,https://www.reddit.com/r/MachineLearning/comments/8s6paz/rnn_with_keras_understanding_computations/,ahstat0,1529390118,,1,1
1024,2018-6-19,2018,6,19,15,8s6qma,[N] Facebook Research open sources DensePose,https://www.reddit.com/r/MachineLearning/comments/8s6qma/n_facebook_research_open_sources_densepose/,Cubbee_wan,1529390565,,27,298
1025,2018-6-19,2018,6,19,16,8s6vbj,[D] Is there a way to know all the workshops a conference has?,https://www.reddit.com/r/MachineLearning/comments/8s6vbj/d_is_there_a_way_to_know_all_the_workshops_a/,nivm321,1529392131,"I was wondering if there is way to know as soon the workshops are announced (not when the conference's main website hosts the schedule, paper deadline is gone by then).

For example, I want to know all the workshops NIPS 2018 has.",7,3
1026,2018-6-19,2018,6,19,16,8s6vzt,Pretrained SuperPoint Network for SLAM,https://www.reddit.com/r/MachineLearning/comments/8s6vzt/pretrained_superpoint_network_for_slam/,Sirisian,1529392339,,0,1
1027,2018-6-19,2018,6,19,16,8s6w5y,[R] Pretrained SuperPoint Network for SLAM,https://www.reddit.com/r/MachineLearning/comments/8s6w5y/r_pretrained_superpoint_network_for_slam/,Sirisian,1529392391,,10,5
1028,2018-6-19,2018,6,19,16,8s7072,Why can autoencoders reconstruct a noisy image but they can't reconstruct a missing block without the help of a mask,https://www.reddit.com/r/MachineLearning/comments/8s7072/why_can_autoencoders_reconstruct_a_noisy_image/,SpeedOfSpin,1529393753,[removed],0,1
1029,2018-6-19,2018,6,19,16,8s71p4,Polynomial Regression As an Alternative to Neural Nets - NN *are* regression polynomials,https://www.reddit.com/r/MachineLearning/comments/8s71p4/polynomial_regression_as_an_alternative_to_neural/,statmlsn,1529394268,,43,23
1030,2018-6-19,2018,6,19,16,8s72y6,600 Experts in Artificial Intelligence Sign a Letter Calling for European Action,https://www.reddit.com/r/MachineLearning/comments/8s72y6/600_experts_in_artificial_intelligence_sign_a/,goudkoorts,1529394700,,0,1
1031,2018-6-19,2018,6,19,17,8s778t,[N] Spark Summit + AI 2018 from a Data Scientist perspective,https://www.reddit.com/r/MachineLearning/comments/8s778t/n_spark_summit_ai_2018_from_a_data_scientist/,rragundez,1529396306,,2,0
1032,2018-6-19,2018,6,19,17,8s7dm2,[P] Minimal tensorflow VAE implementation,https://www.reddit.com/r/MachineLearning/comments/8s7dm2/p_minimal_tensorflow_vae_implementation/,adler-j,1529398713,,15,8
1033,2018-6-19,2018,6,19,18,8s7hvk,Neural architecures for Sentence Classification,https://www.reddit.com/r/MachineLearning/comments/8s7hvk/neural_architecures_for_sentence_classification/,joker_28,1529400239,[removed],0,1
1034,2018-6-19,2018,6,19,19,8s7qhk,[D] Request for thesis idea,https://www.reddit.com/r/MachineLearning/comments/8s7qhk/d_request_for_thesis_idea/,skakabop,1529403354,"Hello everyone!

I'm currently doing my masters in Electronics and I want my thesis to be on a machine learning system. I've worked with multiple neural network architectures like MLP and RBF and have pretty good knowledge about CNNs, GANs and other machine/deep learning structures. I've been lurking for a long time.

I've done some research and projects about bioinformatics and optimization algorithms, maybe have a 1 or 2 paper coming up.

I need to decide on a project for my thesis, which is why I've opened this discussion.

I've some ideas revolving around GAN and music. Also, had my mind set on drones, balance and reinforcement learning for some time. But, I couldn't decide what to work on yet!

What are your opinions? I'm open to everything. Which methods, structures are hot currently?

Thanks!",15,0
1035,2018-6-19,2018,6,19,19,8s7quc,Is constrained Spatial Transformation possible?,https://www.reddit.com/r/MachineLearning/comments/8s7quc/is_constrained_spatial_transformation_possible/,codebuddha,1529403467,"Spatial transformation network allows a network to learn the 6 parameters according to which an input image/feature map is sheared, rotated, scaled or translated.

If the result of the transformation, or even the transformer matrix (comprising the 6 parameters), is knows, is it possible to infer the angle of rotation and ultimately constrain it to a certain range (for example. - 30 to +30)?",0,1
1036,2018-6-19,2018,6,19,19,8s7sp2,[P]Playing Atari with deep reinforcement learning - our approach,https://www.reddit.com/r/MachineLearning/comments/8s7sp2/pplaying_atari_with_deep_reinforcement_learning/,AnnaKow,1529404104,,0,0
1037,2018-6-19,2018,6,19,20,8s7y76, - ,https://www.reddit.com/r/MachineLearning/comments/8s7y76/_/,Woodworking94,1529406027,,0,1
1038,2018-6-19,2018,6,19,20,8s86u1,[R] State of the art Multimodal Sentiment Classification in Videos,https://www.reddit.com/r/MachineLearning/comments/8s86u1/r_state_of_the_art_multimodal_sentiment/,omarsar,1529408613,,0,1
1039,2018-6-19,2018,6,19,20,8s86z7,[R] cLPR: A 3D Dataset for learning pose and rotation,https://www.reddit.com/r/MachineLearning/comments/8s86z7/r_clpr_a_3d_dataset_for_learning_pose_and_rotation/,dearpetra,1529408653,,0,1
1040,2018-6-19,2018,6,19,20,8s889x,[R] Comprehensive Container-Based Service Monitoring with Kubernetes and Istio,https://www.reddit.com/r/MachineLearning/comments/8s889x/r_comprehensive_containerbased_service_monitoring/,molode,1529409020,,0,1
1041,2018-6-19,2018,6,19,20,8s89xy,[N] Machine learning: The next evolution in fraud defense,https://www.reddit.com/r/MachineLearning/comments/8s89xy/n_machine_learning_the_next_evolution_in_fraud/,digitalson,1529409467,,0,1
1042,2018-6-19,2018,6,19,21,8s8crm,Linear regression with Gaussian Features Question,https://www.reddit.com/r/MachineLearning/comments/8s8crm/linear_regression_with_gaussian_features_question/,salah3,1529410235,[removed],0,1
1043,2018-6-19,2018,6,19,21,8s8cry,IBM Unveils System That Debates With Humans,https://www.reddit.com/r/MachineLearning/comments/8s8cry/ibm_unveils_system_that_debates_with_humans/,j_orshman,1529410237,,0,1
1044,2018-6-19,2018,6,19,21,8s8e6r,Python Tools for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8s8e6r/python_tools_for_machine_learning/,birchyio,1529410626,,0,1
1045,2018-6-19,2018,6,19,21,8s8g44,Who wins the sentiment analysis task between 7 models? A benchmark of traditional and deep learning models,https://www.reddit.com/r/MachineLearning/comments/8s8g44/who_wins_the_sentiment_analysis_task_between_7/,ahmedbesbes,1529411156,,0,1
1046,2018-6-19,2018,6,19,21,8s8iiw,"[D] New to ML, where do I start?",https://www.reddit.com/r/MachineLearning/comments/8s8iiw/d_new_to_ml_where_do_i_start/,Fishrage_,1529411782,"Hi all,

I'm an SAP/JS developer who is new to machine learning and wanted to learn more about it.  Where do you recommend I begin without any relevant academic background or knowledge?

Cheers,

Fish",2,2
1047,2018-6-19,2018,6,19,21,8s8ipq,Using ML.NET  Introduction to Machine Learning and ML.NET,https://www.reddit.com/r/MachineLearning/comments/8s8ipq/using_mlnet_introduction_to_machine_learning_and/,RubiksCodeNMZ,1529411833,,0,1
1048,2018-6-19,2018,6,19,22,8s8scj,How Artificial Intelligence Can Help You Trade Cryptocurrency with Greatest Accuracy &amp;#8211; Eyelin,https://www.reddit.com/r/MachineLearning/comments/8s8scj/how_artificial_intelligence_can_help_you_trade/,sollegushwalex7,1529414262,,0,1
1049,2018-6-19,2018,6,19,22,8s8zol,Geometric Deep Learning Extension Library for PyTorch,https://www.reddit.com/r/MachineLearning/comments/8s8zol/geometric_deep_learning_extension_library_for/,shagunsodhani,1529416074,,0,1
1050,2018-6-19,2018,6,19,23,8s9geq,What is the 80/20 of Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8s9geq/what_is_the_8020_of_machine_learning/,blazecoolman,1529419864,[removed],0,1
1051,2018-6-19,2018,6,19,23,8s9i34,[D] Cloud TPU now offers preemptible pricing and global availability,https://www.reddit.com/r/MachineLearning/comments/8s9i34/d_cloud_tpu_now_offers_preemptible_pricing_and/,hydrodynamical_flow,1529420241,,10,22
1052,2018-6-20,2018,6,20,0,8s9ndc,How do I model sequences of instances using Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/8s9ndc/how_do_i_model_sequences_of_instances_using_deep/,yangzhou04,1529421353,[removed],0,1
1053,2018-6-20,2018,6,20,0,8s9y37,Chess environments for reinforcement learning.,https://www.reddit.com/r/MachineLearning/comments/8s9y37/chess_environments_for_reinforcement_learning/,Pawnbrake,1529423646,[removed],0,1
1054,2018-6-20,2018,6,20,0,8s9zu2,[P] Successful AR developer looking for CV partner on Retail AR,https://www.reddit.com/r/MachineLearning/comments/8s9zu2/p_successful_ar_developer_looking_for_cv_partner/,AndrewProjDent,1529423988,"Over the past year I've had a lot of success with my work in AR: I pioneered location-based AR with open-source library [ARKit+CoreLocation](https://github.com/ProjectDent/ARKit-CoreLocation), which became the most-starred ARKit project on GitHub, and along the way created some of the more notable AR demos, including [AR navigation](https://twitter.com/AndrewProjDent/status/888380207962443777) and [Bookstore AR](https://twitter.com/AndrewProjDent/status/958759429473734657). More recently, I've been working on integrating AR into indoor environments, and my recent [Retail AR](https://twitter.com/AndrewProjDent/status/981635577488519170) demo went viral, even being featured [on Mashable](https://mashable.com/2018/04/05/artificial-reality-retail-shopping-tool/).

My skills are in R&amp;Ding solutions to the technical and user experience challenges involved with AR, and being able to create compelling experiences from that.

CV is a key part of AR, especially when it comes to integrating with real-world environments, such as when recognising products in a store. I've spent a while learning CV, but it's clear that it's not an area where I'm effective, and I feel my time is wasted there. It'd be better for me to partner with someone who does CV really well.

I'm based in London, but open to working with anyone located anywhere in the world. If you're interested in working together, please drop me a message - Andrew@DentReality.com",0,0
1055,2018-6-20,2018,6,20,1,8sa281,[P] Chess environments for reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/8sa281/p_chess_environments_for_reinforcement_learning/,Pawnbrake,1529424463,"I want to try some reinforcement learning techniques (borrowed from AlphaZero, etc.) and so I need a chess environment in order to run games.

I code in python, so I found [python-chess](https://pypi.org/project/python-chess/) but unfortunately it is too slow to generate a large amount of games.  Playing 100 games with random moves (average length of \~400 moves for a random game) takes 8 seconds, which doesn't scale to higher orders of magnitude well.  My profiling shows that over 99.9&amp;#37; of the time taken is with the library as opposed to other code, so I can't optimize any further.

Is there already an existing chess environment that is faster than this in python?",13,1
1056,2018-6-20,2018,6,20,1,8sa85h,Reinforcement Learning with floating point action-space,https://www.reddit.com/r/MachineLearning/comments/8sa85h/reinforcement_learning_with_floating_point/,beautifulgraphs,1529425710,[removed],0,1
1057,2018-6-20,2018,6,20,1,8sa867,How do I convert my .mlmodel (CoreML models) to models that Tensorflow can read?,https://www.reddit.com/r/MachineLearning/comments/8sa867/how_do_i_convert_my_mlmodel_coreml_models_to/,aliprobro,1529425715,"I know there are lots of guides online about converting Tensorflow models to CoreML (.mlmodel) files, but what about the other way around?",0,1
1058,2018-6-20,2018,6,20,1,8sa9zl,"Average Student trying to get into ML Graduate School, Project?",https://www.reddit.com/r/MachineLearning/comments/8sa9zl/average_student_trying_to_get_into_ml_graduate/,jonboighini,1529426075,[removed],0,1
1059,2018-6-20,2018,6,20,1,8sac1b,[N] Nvidia releases libraries for fast image augmentation,https://www.reddit.com/r/MachineLearning/comments/8sac1b/n_nvidia_releases_libraries_for_fast_image/,Cubbee_wan,1529426516,,28,241
1060,2018-6-20,2018,6,20,1,8sad2t,"Discussion: dataset standardization, is it possible?",https://www.reddit.com/r/MachineLearning/comments/8sad2t/discussion_dataset_standardization_is_it_possible/,radaobc,1529426725,"I work at a startup as a machine learning engineer and I constantly find myself writing custom converters from the format used by some dataset I downloaded off the internet to the format consumed by whatever framework I'm using to train a model for a particular task (think CityScapes/DeepFashion/OpenImages -&gt; COCO/VOC format to train an object detector).

My question: is there any way to avoid repeating this conversion step over and over for each new dataset? Can we agree as a community to standardize a particular data format for a particular task? Can we have a sort of ONNX-like ecosystem for dataset portability? 

I foresee some difficulties enforcing such a standard but I feel the potential benefit outweighs this cost so I'm curious what the rest of the community thinks on this subject. And perhaps there is something out there already but I have not come across it yet.

",0,1
1061,2018-6-20,2018,6,20,1,8sagby,"[D] Dataset standardization, is it possible?",https://www.reddit.com/r/MachineLearning/comments/8sagby/d_dataset_standardization_is_it_possible/,radaobc,1529427391,"I work at a startup as a machine learning engineer and I constantly find myself writing custom converters from the format used by some dataset I downloaded off the internet to the format consumed by whatever framework I'm using to train a model for a particular task (think CityScapes/DeepFashion/OpenImages -&gt; COCO/VOC format to train an object detector).

My question: is there any way to avoid repeating this conversion step over and over for each new dataset? Can we agree as a community to standardize a particular data format for a particular task? Can we have a sort of ONNX-like ecosystem for dataset portability?

I foresee some difficulties enforcing such a standard but I feel the potential benefit outweighs this cost so I'm curious what the rest of the community thinks on this subject. And perhaps there is something out there already but I have not come across it yet.",9,25
1062,2018-6-20,2018,6,20,2,8sapcs,Help to develop novel association measure with t-SNE,https://www.reddit.com/r/MachineLearning/comments/8sapcs/help_to_develop_novel_association_measure_with/,theStatsStudent,1529429169,[removed],0,1
1063,2018-6-20,2018,6,20,3,8sazca,"""Reconstructing intelligible speech from the human auditory cortex"", Akbari et al 2018",https://www.reddit.com/r/MachineLearning/comments/8sazca/reconstructing_intelligible_speech_from_the_human/,gwern,1529431211,,0,1
1064,2018-6-20,2018,6,20,3,8sazgb,Role of HashTag in User's Online Personality || Social Network,https://www.reddit.com/r/MachineLearning/comments/8sazgb/role_of_hashtag_in_users_online_personality/,manishs3,1529431234,,0,1
1065,2018-6-20,2018,6,20,3,8sb0yt,Nvidias using deep learning to make 240 fps slow-mo out of 30 fps videos,https://www.reddit.com/r/MachineLearning/comments/8sb0yt/nvidias_using_deep_learning_to_make_240_fps/,TheHumanBiscuit,1529431531,,0,1
1066,2018-6-20,2018,6,20,3,8sb6hz,[P] Multi-GPU Framework Comparisons - DenseNet,https://www.reddit.com/r/MachineLearning/comments/8sb6hz/p_multigpu_framework_comparisons_densenet/,iliauk,1529432655,,0,3
1067,2018-6-20,2018,6,20,4,8sbhg6,Approaching a post-doc for collaboration/advice as an undergrad?,https://www.reddit.com/r/MachineLearning/comments/8sbhg6/approaching_a_postdoc_for_collaborationadvice_as/,Long_Audience,1529434894,[removed],0,1
1068,2018-6-20,2018,6,20,4,8sbiri,Machine Learning with R - Classifier | Niceguy Tech,https://www.reddit.com/r/MachineLearning/comments/8sbiri/machine_learning_with_r_classifier_niceguy_tech/,ivivek11,1529435150,,0,1
1069,2018-6-20,2018,6,20,4,8sbrxc,[D] Approaching a post-doc for collaboration/advice as an undergrad?,https://www.reddit.com/r/MachineLearning/comments/8sbrxc/d_approaching_a_postdoc_for_collaborationadvice/,Long_Audience,1529437051,"I've been working on a paper and came across a similar just-published paper. The person who wrote it is a phd (I'm an undergrad) at a different university. My in-progress work is similar but slightly more general than her's, and might be suitable for a follow-up. I'm thinking I might benefit from her advice and that maybe she might want to work with me.

Is it acceptable to approach a researcher from another group and ask them to collaborate? Or should I just ask for advice? Or do I just appropriately cite her prior work and try to publish? Note: I've never wrote a published before.

My ideal scenario is that she could be last author on the paper I'm working on. What wording do I use to ensure she knows I intend to give her authorship, and I'm not just seeking unsolicited advice?

Also, people around here seem to be very worried about being ""scooped"". Is that something that should concern me, considering I've never met her?",1,0
1070,2018-6-20,2018,6,20,5,8sc00b,[N] CVPR 2018 Kicks Off; Best Papers Announced  Synced  Medium,https://www.reddit.com/r/MachineLearning/comments/8sc00b/n_cvpr_2018_kicks_off_best_papers_announced/,trcytony,1529438734,,0,1
1071,2018-6-20,2018,6,20,5,8sc0gn,Simple ping pong game bot with tensorflow.js (bot vs. bot/user),https://www.reddit.com/r/MachineLearning/comments/8sc0gn/simple_ping_pong_game_bot_with_tensorflowjs_bot/,dimonikys_,1529438832,,0,1
1072,2018-6-20,2018,6,20,5,8sc36c,AI destroys puzzles 5-10 THOUSAND times faster than a human,https://www.reddit.com/r/MachineLearning/comments/8sc36c/ai_destroys_puzzles_510_thousand_times_faster/,mitkoofc,1529439378,[removed],0,1
1073,2018-6-20,2018,6,20,5,8sc7t8,Training PPO to self-drive with dense speed and lane reward. Inputs pixels fed through frozen pretrained MobileNet2 to 64x2x2 MLP. Full source @ https://bit.ly/ddppo,https://www.reddit.com/r/MachineLearning/comments/8sc7t8/training_ppo_to_selfdrive_with_dense_speed_and/,aiworld,1529440331,,0,1
1074,2018-6-20,2018,6,20,5,8sc7vn,Looking for team members for the call of code challenge 2018,https://www.reddit.com/r/MachineLearning/comments/8sc7vn/looking_for_team_members_for_the_call_of_code/,nouhill,1529440343,[removed],0,1
1075,2018-6-20,2018,6,20,6,8scqan,How to prevent VAE loss from getting stuck?,https://www.reddit.com/r/MachineLearning/comments/8scqan/how_to_prevent_vae_loss_from_getting_stuck/,sibyjackgrove,1529444254,[removed],0,1
1076,2018-6-20,2018,6,20,6,8scrmo,"[D] If a neural network is essentially an n-dimensional function approximater, then why can't it be simplified to exact mathematical equations afterwards?",https://www.reddit.com/r/MachineLearning/comments/8scrmo/d_if_a_neural_network_is_essentially_an/,Carcaso,1529444542,,21,0
1077,2018-6-20,2018,6,20,6,8scrta,[N] What its like to watch an IBM AI successfully debate humans,https://www.reddit.com/r/MachineLearning/comments/8scrta/n_what_its_like_to_watch_an_ibm_ai_successfully/,farmingvillein,1529444579,,4,0
1078,2018-6-20,2018,6,20,6,8scvh9,Why Elon Musk Is Against AI Development | Tech Valve EP.1,https://www.reddit.com/r/MachineLearning/comments/8scvh9/why_elon_musk_is_against_ai_development_tech/,dyf360,1529445355,,0,1
1079,2018-6-20,2018,6,20,7,8sd3vz,Anyone looking to partner with a CFA-credentialed hedge fund analyst to kick around ideas? [P],https://www.reddit.com/r/MachineLearning/comments/8sd3vz/anyone_looking_to_partner_with_a_cfacredentialed/,Keeppgoingg,1529447174,"Hey guys, I'm new here and hope this isn't against any unstated rules. I'm an analyst at a long-short equity hedge fund, specializing in fundamental analysis of mostly technology stocks. I work mostly with unstructured data such as conference transcripts and SEC filings, and figured that there is a lot of interesting things you can do with ML/AI. 

I'm still somewhat of a ""young guy"" but its too late for me to become a programmer (mainly because of the opportunity cost of giving up my current job). I'm curious if anyone here with a programming background would like to team up with me to explore cools things that could be done in the financial markets by combining our expertise. ",6,0
1080,2018-6-20,2018,6,20,7,8sda27,[P] Train your own ping pong bot on tensorflow.js (bot vs bot or user),https://www.reddit.com/r/MachineLearning/comments/8sda27/p_train_your_own_ping_pong_bot_on_tensorflowjs/,dimonikys_,1529448592,,8,6
1081,2018-6-20,2018,6,20,8,8sdf0d,Newbie with an idea -contract compliance tool,https://www.reddit.com/r/MachineLearning/comments/8sdf0d/newbie_with_an_idea_contract_compliance_tool/,aeliacc,1529449769,[removed],0,1
1082,2018-6-20,2018,6,20,8,8sdh7w,[Dyna Q] vs [Imagination-Augmented Agents for Deep Reinforcement Learning],https://www.reddit.com/r/MachineLearning/comments/8sdh7w/dyna_q_vs_imaginationaugmented_agents_for_deep/,randy_wales,1529450301,[removed],0,1
1083,2018-6-20,2018,6,20,8,8sdott,[R] NCRF Deep Learning Framework Improves Cancer Metastasis Detection,https://www.reddit.com/r/MachineLearning/comments/8sdott/r_ncrf_deep_learning_framework_improves_cancer/,trcytony,1529452201,,0,1
1084,2018-6-20,2018,6,20,9,8sdzz2,[P] How to Play on a Synthesizer [Casio VL-10] from (1980s),https://www.reddit.com/r/MachineLearning/comments/8sdzz2/p_how_to_play_on_a_synthesizer_casio_vl10_from/,mark-2019,1529454969,,0,0
1085,2018-6-20,2018,6,20,9,8se0j2,Google develops means for rendering 3D images based on small set of 2D images.,https://www.reddit.com/r/MachineLearning/comments/8se0j2/google_develops_means_for_rendering_3d_images/,Science_Podcast,1529455122,,0,1
1086,2018-6-20,2018,6,20,9,8se41z,Artificial life simulation.,https://www.reddit.com/r/MachineLearning/comments/8se41z/artificial_life_simulation/,Thomas-Arys,1529456053,,0,1
1087,2018-6-20,2018,6,20,10,8se5q2,[1806.06975] Towards Gene Expression Convolutions using Gene Interaction Graphs. A way to incorporate knowledge into a neural network using a graph of possible gene interactions to bias feature construction.,https://www.reddit.com/r/MachineLearning/comments/8se5q2/180606975_towards_gene_expression_convolutions/,ieee8023,1529456475,,0,8
1088,2018-6-20,2018,6,20,10,8se61t,[R] DropBack: Continuous Pruning During Training,https://www.reddit.com/r/MachineLearning/comments/8se61t/r_dropback_continuous_pruning_during_training/,Drtat,1529456556,,10,26
1089,2018-6-20,2018,6,20,10,8se9i7,"[D] Why do you think most, or at least half of accounting work done today hasn't been automated yet?",https://www.reddit.com/r/MachineLearning/comments/8se9i7/d_why_do_you_think_most_or_at_least_half_of/,Sedai01,1529457462,Is it because of regulations and old thinking and not because it could be done fairly easily with today's technology? ,0,1
1090,2018-6-20,2018,6,20,10,8se9og,Googles AutoML will change how businesses use Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8se9og/googles_automl_will_change_how_businesses_use/,VanillaMonster,1529457498,,0,1
1091,2018-6-20,2018,6,20,10,8seb31,[Q]Why is Caffe2's code so ugly compared to PyTorch?,https://www.reddit.com/r/MachineLearning/comments/8seb31/qwhy_is_caffe2s_code_so_ugly_compared_to_pytorch/,finallyifoundvalidUN,1529457864,,0,1
1092,2018-6-20,2018,6,20,10,8sedm6,[P] AI for prosthetics - Deep Reinforcement Learning Challenge @ NIPS 2018,https://www.reddit.com/r/MachineLearning/comments/8sedm6/p_ai_for_prosthetics_deep_reinforcement_learning/,kidzik,1529458540,,2,25
1093,2018-6-20,2018,6,20,11,8sejz1,Mirror networks  have I cracked the brain code?,https://www.reddit.com/r/MachineLearning/comments/8sejz1/mirror_networks_have_i_cracked_the_brain_code/,DeltruS,1529460202,[removed],0,1
1094,2018-6-20,2018,6,20,11,8senc9,[D] Mirror networks  have I cracked the brain code?,https://www.reddit.com/r/MachineLearning/comments/8senc9/d_mirror_networks_have_i_cracked_the_brain_code/,DeltruS,1529461088,"Algorithm:

1. Two or more randomly weighted neural networks receive the same input.

2. If they disagree on the output, use backpropogation on the odd one[s] out until the output number is the same as the the other network[s]. 

The goal is to have many different models agree with each-other. The output numbers being the same means the models agree on what it is seeing.  The outputs ""mirror"" each-other.  

After many rounds of backprop, this generates thousands of ""numbers"" which do not behave as numbers, but rather symbols that represent models/experiences.  

The numbers could then be used as causal logic. Like 1.557 + 1.665 -&gt; 4.234. This would create a causal spaggetti code. These would represent something like dog + hungry expression -&gt; dog will seek food.  This is because the network experienced seeing a hungry dog, and then saw it eating food, so the logic center would make the causal connection.  


It could also see that dogs don't always have a hungry expression before they eat food. This would represent a weakened connection on some hypergraph. Or a ""!-&gt;"" relation.   Or even a statistical relation.  


Eventually, after the network is fully trained and has few disagreements on what it is experiencing, the numbers could be paired with words, representing learning language.  For example you could input a few pictures of animals running and the numbers which result could be paired with the word/tag ""running"".  

As the mirror networks get more and more trained similar ""objects/groups/archtypes"" from the outside world will group together in their numbers, creating Venn diagram like structures, which are each represented by symbols pairs.  For example, nouns, cats, frisbees.  Every group has the same causal behaviour.   

If trained networks disagree on what they are seeing, the causal logic center can step in. And the correct model is chosen.  

The best part of this is that there is no ego and no doer. Pure awareness(experiencer) and intelligence(thinker). No possibility for a robot uprising.  

At the start, the network might see two completely different things and experience two similar numbers, but the glorious thing is that those numbers don't represent anything yet. As the neural networks start to differentiate, the separate ""objects"" start to emerge. Similar output numbers would mean similar things.  For example numbers 1.002 to 1.009 could be different types of dogs. 

Once you start labelling the output numbers, you can start labelling them with pictures that triggered the experiencer neurons. This completes the input-output loop. It allows for memory and lets something re-experience something by putting in the image for analysis by the mirror networks.  

This explains why babies do not have memories. What neurons represent what experience are constantly in flux.   A picture that triggered one group of neurons early on would trigger another group of neurons later on.  

Babies also do not learn basic concepts at the same time they learn words, they spend a very long time just trying to figure out what they are experiencing.  ",15,0
1095,2018-6-20,2018,6,20,11,8sewnt,[R] [1806.06927] Auto-Meta: Automated Gradient Based Meta Learner Search,https://www.reddit.com/r/MachineLearning/comments/8sewnt/r_180606927_autometa_automated_gradient_based/,ekzm0204,1529463509,,0,25
1096,2018-6-20,2018,6,20,12,8sf467,Maquina Laser CO2 Fraccionado ( Mdico CE y FDA ),https://www.reddit.com/r/MachineLearning/comments/8sf467/maquina_laser_co2_fraccionado_mdico_ce_y_fda/,toughinsist,1529465538,,0,1
1097,2018-6-20,2018,6,20,12,8sf7eq,why the hidden state of rnn become almost -1 or 1 in training,https://www.reddit.com/r/MachineLearning/comments/8sf7eq/why_the_hidden_state_of_rnn_become_almost_1_or_1/,ningyu,1529466420,[removed],0,1
1098,2018-6-20,2018,6,20,13,8sfb11,[R] On Accurate Evaluation of GANs for Language Generation,https://www.reddit.com/r/MachineLearning/comments/8sfb11/r_on_accurate_evaluation_of_gans_for_language/,HigherTopoi,1529467414,,1,2
1099,2018-6-20,2018,6,20,14,8sfn3w,[D] Help with project of utmost importance for human kind.,https://www.reddit.com/r/MachineLearning/comments/8sfn3w/d_help_with_project_of_utmost_importance_for/,itypewords,1529470963,"Im not a software engineer and I only have a superficial understanding of how machine learning works. Im hoping one of you can help. Id like to install a thermal FLIR camera above my bed, which is analyzed via machine learning to determine the position of 2 human bodies; statistically proving that one of them (my wife) takes up more bed surface real estate than the other (me) at any given time, with almost 100% certainty. Optional automatic nerf projectile triggered at subject when the agreed boundary of shared space is sufficiently violated. Thank you in advance, kind sirs.",3,7
1100,2018-6-20,2018,6,20,14,8sfxma,Looking for info on improving resolution for pics and video.,https://www.reddit.com/r/MachineLearning/comments/8sfxma/looking_for_info_on_improving_resolution_for_pics/,KarlJay001,1529474293,[removed],0,1
1101,2018-6-20,2018,6,20,14,8sfxr6,Our engineering strengths enable us to optimize complex building designs into efficient building solutions to suit our customers needs.,https://www.reddit.com/r/MachineLearning/comments/8sfxr6/our_engineering_strengths_enable_us_to_optimize/,Supertech_India,1529474342,,0,1
1102,2018-6-20,2018,6,20,15,8sfyww,[R] Unsupervised Image Translation with Self-Regularization and Attention,https://www.reddit.com/r/MachineLearning/comments/8sfyww/r_unsupervised_image_translation_with/,leehomyc,1529474687,,9,11
1103,2018-6-20,2018,6,20,16,8sg92p,i just took over my friends mind and whiteboard,https://www.reddit.com/r/MachineLearning/comments/8sg92p/i_just_took_over_my_friends_mind_and_whiteboard/,matthew9510,1529478056,,0,1
1104,2018-6-20,2018,6,20,16,8sg9j7,career point,https://www.reddit.com/r/MachineLearning/comments/8sg9j7/career_point/,ardour_,1529478193,[removed],0,1
1105,2018-6-20,2018,6,20,16,8sgeqf,"[D] Training a model in the face of noisy data; multi-level approach, cluster preprocessing, or simple average?",https://www.reddit.com/r/MachineLearning/comments/8sgeqf/d_training_a_model_in_the_face_of_noisy_data/,vrcurve,1529479934,"Say I have 1 million flowers, each of which have 1-10 petals. For each one of these flowers, I have 1000 participants tag a set of features. However, the features in this set are difficult to tag for humans, and while the majority of the data is accurate, some of the data is unreliable. There are also a small number of flowers that might be ""special cases"", i.e. might have mutations where the recorded data should point to one result, but actually (correctly) points to another result. All 1 million instances are correctly labeled by an oracle in addition to the 1000 human observations.

How do I go about training a model on such a dataset? Structurally speaking, I am not sure how to 'bundle' the 1000 observations per flower. I want to make sure that I am not simply predicting the petals on the flower for each observation, because any given observation could be incorrect, and any given flower has a small chance of being a mutant. I want to predict the number of petals on any given flower given all observations of the 1000 taggers, meaning that I essentially want to treat the bundle of 1000 observations per flower as a single observation, and train over 1 million training samples. 

The simplest naive way that I can think of doing this is to take an average per feature, perhaps also take into account standard deviation for applicable features. However, I feel as though there must be a more principled and effective way to approach this problem. The crux of the problem is that there may be multiple ""mutations"" or versions of a flower that all are valid instances of having n-petals, and training on a observation-by-observation basis throws valuable information about the existence of such mutations. This leads me to believe that perhaps I should do some kind of clustering based pre-processing step to cluster similar observations per petal-count pool, and produce a more granular label set that takes into account these mutations.

Please let me know if I'm not being clear... Thanks!",12,28
1106,2018-6-20,2018,6,20,16,8sggb3,Style Transfer for Adobe After effects is here!,https://www.reddit.com/r/MachineLearning/comments/8sggb3/style_transfer_for_adobe_after_effects_is_here/,Sugarbank-FX,1529480463,[removed],0,1
1107,2018-6-20,2018,6,20,16,8sgggc,"argmax talks: Sepp Hochreiter (Learn how he wants to kick deepmind from the market, overtake it and why Sutton's book is forbidden in his lab)",https://www.reddit.com/r/MachineLearning/comments/8sgggc/argmax_talks_sepp_hochreiter_learn_how_he_wants/,sieisteinmodel,1529480519,,0,1
1108,2018-6-20,2018,6,20,16,8sghfm,AI is coming into high school in China,https://www.reddit.com/r/MachineLearning/comments/8sghfm/ai_is_coming_into_high_school_in_china/,WM177155,1529480816,,0,1
1109,2018-6-20,2018,6,20,17,8sglim,Machine Learning using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8sglim/machine_learning_using_tensorflow/,prithvi45,1529482208,[removed],0,1
1110,2018-6-20,2018,6,20,18,8sgwog,How to form a dataset of images to train and test machine?,https://www.reddit.com/r/MachineLearning/comments/8sgwog/how_to_form_a_dataset_of_images_to_train_and_test/,Leonidus6969,1529486454,[removed],0,1
1111,2018-6-20,2018,6,20,18,8sgww8,Machine Vision New Trending Report in 2K18,https://www.reddit.com/r/MachineLearning/comments/8sgww8/machine_vision_new_trending_report_in_2k18/,pearlpeacock,1529486530,,0,1
1112,2018-6-20,2018,6,20,18,8sgydb,"Ive been reading about the abysmal false positive rates involving UK police use of facial recognition, up to 98% wrong. Why so inefficient??",https://www.reddit.com/r/MachineLearning/comments/8sgydb/ive_been_reading_about_the_abysmal_false_positive/,alphabet_street,1529487082,[removed],0,1
1113,2018-6-20,2018,6,20,18,8sgzdp,Transforming Standard Video Into Slow Motion with AI - NVIDIA,https://www.reddit.com/r/MachineLearning/comments/8sgzdp/transforming_standard_video_into_slow_motion_with/,ktkps,1529487467,,0,1
1114,2018-6-20,2018,6,20,18,8sh1ow,Machine Learning - Tutorial for Beginners,https://www.reddit.com/r/MachineLearning/comments/8sh1ow/machine_learning_tutorial_for_beginners/,pooja307,1529488293,,0,1
1115,2018-6-20,2018,6,20,19,8sh3cn,Keras quantization,https://www.reddit.com/r/MachineLearning/comments/8sh3cn/keras_quantization/,francesco_dalbi,1529488893,[removed],0,1
1116,2018-6-20,2018,6,20,19,8sh7gr,data labeling using simi-supervised learning,https://www.reddit.com/r/MachineLearning/comments/8sh7gr/data_labeling_using_simisupervised_learning/,ferdowsshahryar,1529490247,[removed],0,1
1117,2018-6-20,2018,6,20,20,8she4g,[N] Walmart Data Science Interview Questions  Acing the AI Interview,https://www.reddit.com/r/MachineLearning/comments/8she4g/n_walmart_data_science_interview_questions_acing/,dearpetra,1529492463,,0,1
1118,2018-6-20,2018,6,20,20,8shels,[R] Choosing the Right Metric for Evaluating Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/8shels/r_choosing_the_right_metric_for_evaluating/,molode,1529492596,,0,1
1119,2018-6-20,2018,6,20,20,8shg22,[R] Data Science Predicting The Future,https://www.reddit.com/r/MachineLearning/comments/8shg22/r_data_science_predicting_the_future/,polllyyy,1529493061,,0,1
1120,2018-6-20,2018,6,20,21,8shtrp,BigQueryReader | TensorFlow Python API r1.8,https://www.reddit.com/r/MachineLearning/comments/8shtrp/bigqueryreader_tensorflow_python_api_r18/,DrakeFrost,1529496941,[removed],0,1
1121,2018-6-20,2018,6,20,21,8shwhr,Machine Learning: The High Interest Credit Card of Technical Debt - Google AI,https://www.reddit.com/r/MachineLearning/comments/8shwhr/machine_learning_the_high_interest_credit_card_of/,j_orshman,1529497670,,0,1
1122,2018-6-20,2018,6,20,21,8si1iq,Comparison Between NC and CNC Machine's...,https://www.reddit.com/r/MachineLearning/comments/8si1iq/comparison_between_nc_and_cnc_machines/,rizzu0619,1529499071,,0,1
1123,2018-6-20,2018,6,20,22,8si3yx,Blog on machine learning &amp; artificial intelligence technology for monitoring,https://www.reddit.com/r/MachineLearning/comments/8si3yx/blog_on_machine_learning_artificial_intelligence/,ennissh,1529499685,,0,1
1124,2018-6-20,2018,6,20,22,8si76a,[R] Interactive Visual Grounding of Referring Expressions for Human-Robot Interaction,https://www.reddit.com/r/MachineLearning/comments/8si76a/r_interactive_visual_grounding_of_referring/,theprefab,1529500477,,0,2
1125,2018-6-20,2018,6,20,22,8sic66,Noise Filtering,https://www.reddit.com/r/MachineLearning/comments/8sic66/noise_filtering/,DonDenDen,1529501663,[removed],0,1
1126,2018-6-20,2018,6,20,22,8sicv9,AI-powered drones are now being used to monitor construction in Africa,https://www.reddit.com/r/MachineLearning/comments/8sicv9/aipowered_drones_are_now_being_used_to_monitor/,nanonets,1529501823,,0,1
1127,2018-6-20,2018,6,20,22,8sif3y,AI-powered drones are now being used to monitor construction in Africa,https://www.reddit.com/r/MachineLearning/comments/8sif3y/aipowered_drones_are_now_being_used_to_monitor/,nanonets,1529502333,,0,1
1128,2018-6-20,2018,6,20,22,8sifio,[N] 34% of ICML papers were accepted as long talks,https://www.reddit.com/r/MachineLearning/comments/8sifio/n_34_of_icml_papers_were_accepted_as_long_talks/,deeper_or_wider,1529502422,,0,0
1129,2018-6-20,2018,6,20,22,8sifuy,[D] Top 20 Python libraries for data science in 2018,https://www.reddit.com/r/MachineLearning/comments/8sifuy/d_top_20_python_libraries_for_data_science_in_2018/,s0ulmate,1529502494,,2,6
1130,2018-6-20,2018,6,20,22,8sihkb,[R] [1806.06259] Evaluation of sentence embeddings in downstream and linguistic probing tasks,https://www.reddit.com/r/MachineLearning/comments/8sihkb/r_180606259_evaluation_of_sentence_embeddings_in/,perone,1529502914,,4,23
1131,2018-6-20,2018,6,20,23,8sij9j,On Deep Tensor Networks and Non-Linearity,https://www.reddit.com/r/MachineLearning/comments/8sij9j/on_deep_tensor_networks_and_nonlinearity/,outlacedev,1529503290,,0,1
1132,2018-6-20,2018,6,20,23,8sik6v,Moviebox: CLI Machine Learning Movie Recommendation System,https://www.reddit.com/r/MachineLearning/comments/8sik6v/moviebox_cli_machine_learning_movie/,ohaiomasta,1529503477,,0,1
1133,2018-6-20,2018,6,20,23,8simlb,The Conversational Intelligence Challenge,https://www.reddit.com/r/MachineLearning/comments/8simlb/the_conversational_intelligence_challenge/,Moscow_Phystech,1529504018,[removed],0,1
1134,2018-6-20,2018,6,20,23,8sipxs,[D] Machine Learning models on the edge: mobile and IoT,https://www.reddit.com/r/MachineLearning/comments/8sipxs/d_machine_learning_models_on_the_edge_mobile_and/,jamesonatfritz,1529504809,,1,1
1135,2018-6-20,2018,6,20,23,8sipz7,[P] Moviebox: CLI Machine Learning Movie Recommendation System,https://www.reddit.com/r/MachineLearning/comments/8sipz7/p_moviebox_cli_machine_learning_movie/,ohaiomasta,1529504820,,3,20
1136,2018-6-20,2018,6,20,23,8siqb4,[Help] Implementing mobilenets_v1 from scratch in tensorflow,https://www.reddit.com/r/MachineLearning/comments/8siqb4/help_implementing_mobilenets_v1_from_scratch_in/,JoaoFLF,1529504890,"Hi,

A few days ago I decided to implement mobilenets\_v1 from scratch in tensorflow and use the stanford dogs dataset to test it. However I've been stuck in a few days with this problem:

Upon starting training, I noticed that the final softmax layer was predicting the same class for all instances in the batch.

After some debugging I found out as the convolutions got deeper and deeper, their values were becoming the same on all instances, reaching the final fully connected layer on that state.

I've tried multiple weight initialization techniques, different activation functions (relu, relu6 and leaky relu) but with no avail.

Has anyone encountered a similar problem?

You can find the notebook on this Colab [link](https://colab.research.google.com/drive/1LBKrWsn4Qo21ixtv4N2JUOkKMWkDLint) 

Thanks!",0,1
1137,2018-6-20,2018,6,20,23,8sit2f,[P] Help - Implementing mobilenets_v1 from scratch in tensorflow,https://www.reddit.com/r/MachineLearning/comments/8sit2f/p_help_implementing_mobilenets_v1_from_scratch_in/,JoaoFLF,1529505493,"Hi,

A few days ago I decided to implement mobilenets\_v1 from scratch in tensorflow and use the stanford dogs dataset to test it. However I've been stuck in a few days with this problem:

Upon starting training, I noticed that the final softmax layer was predicting the same class for all instances in the batch.

After some debugging I found out as the convolutions got deeper and deeper, their values were becoming the same on all instances, reaching the final fully connected layer on that state.

I've tried multiple weight initialization techniques, different activation functions (relu, relu6 and leaky relu) but with no avail.

Has anyone encountered a similar problem?

You can find the notebook on this Colab link 

Thanks!",2,0
1138,2018-6-20,2018,6,20,23,8sixek,[P] On Deep Tensor Networks and Nonlinearity,https://www.reddit.com/r/MachineLearning/comments/8sixek/p_on_deep_tensor_networks_and_nonlinearity/,outlacedev,1529506386,,16,29
1139,2018-6-20,2018,6,20,23,8siylv,5 Future Trends in Machine Learning and AI Technology,https://www.reddit.com/r/MachineLearning/comments/8siylv/5_future_trends_in_machine_learning_and_ai/,carolina_sar,1529506655,,0,1
1140,2018-6-21,2018,6,21,0,8sjck1,[P] Chainer implementation of OpenAI's finetuned Transformer Language Model with a script to import the weights pre-trained by OpenAI + reproduction of the SST experiment,https://www.reddit.com/r/MachineLearning/comments/8sjck1/p_chainer_implementation_of_openais_finetuned/,sushiai,1529509544,,0,25
1141,2018-6-21,2018,6,21,0,8sjez2,Will your job exist tomorrow or will you lose the battle to AI and Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8sjez2/will_your_job_exist_tomorrow_or_will_you_lose_the/,paulmsv,1529510039,,0,1
1142,2018-6-21,2018,6,21,0,8sjfjb,"Simple Questions Thread June 20, 2018",https://www.reddit.com/r/MachineLearning/comments/8sjfjb/simple_questions_thread_june_20_2018/,AutoModerator,1529510146,[removed],0,1
1143,2018-6-21,2018,6,21,1,8sjh7p,[D] What is a relationship between entropy of data distribution and generative model's performance?,https://www.reddit.com/r/MachineLearning/comments/8sjh7p/d_what_is_a_relationship_between_entropy_of_data/,HigherTopoi,1529510465,"Generative model can easily learn the distribution that is a pure noise (e.g. uniform distribution), since it suffices to feed a noise as its output. It's also easy if the entropy of the distribution is zero. I feel that it's nearly as easy if the entropy is nearly maximal or nearly zero. Then, under what condition on the entropy of the data distribution is it difficult for generative model to perform well? Is entropy not an appropriate measure for the difficulty? By performance of generative model, I mean the JSD (or KLD) of the model's outputs with the data distribution. The paper ""Exploring Generalization in Deep Learning"" proposed a complexity measure for NN's difficulty in learning a data distribution, but if I understand correctly, its analysis is not necessarily applicable to generative models. 
",7,5
1144,2018-6-21,2018,6,21,1,8sjjwl,created simple AForge.NET Visual Studio tutorials,https://www.reddit.com/r/MachineLearning/comments/8sjjwl/created_simple_aforgenet_visual_studio_tutorials/,mihaipruna,1529510985,[removed],0,1
1145,2018-6-21,2018,6,21,1,8sjqmm,Simple Solution to Feature Selection Problems,https://www.reddit.com/r/MachineLearning/comments/8sjqmm/simple_solution_to_feature_selection_problems/,psangrene,1529512352,,0,1
1146,2018-6-21,2018,6,21,1,8sjtit,[D] What ECE field should I master in if I'm also interested in machine learning?,https://www.reddit.com/r/MachineLearning/comments/8sjtit/d_what_ece_field_should_i_master_in_if_im_also/,Teen-Ninja-Turtle,1529512944,"The possibilities are in image processing or control engineering, or perhaps even something related to audio engineering seeing as I have an interest in linguistics as well (so maybe some natural language processing+audio circuits)

Maybe there is something I'm missing.",2,0
1147,2018-6-21,2018,6,21,1,8sjwnd,[D] Datashader Revealing the Structure of Genuinely Big Data | SciPy 2016 | James A Bednar,https://www.reddit.com/r/MachineLearning/comments/8sjwnd/d_datashader_revealing_the_structure_of_genuinely/,_alphamaximus_,1529513585,,0,1
1148,2018-6-21,2018,6,21,2,8sjzmq,[R] Neural Ordinary Differential Equations,https://www.reddit.com/r/MachineLearning/comments/8sjzmq/r_neural_ordinary_differential_equations/,chisai_mikan,1529514167,,10,54
1149,2018-6-21,2018,6,21,2,8sjzup,[R] Gated Path Planning Networks,https://www.reddit.com/r/MachineLearning/comments/8sjzup/r_gated_path_planning_networks/,inarrears,1529514207,,2,14
1150,2018-6-21,2018,6,21,2,8sk0b4,[R] Differentiable plasticity: training plastic neural networks with backpropagation (UberAI),https://www.reddit.com/r/MachineLearning/comments/8sk0b4/r_differentiable_plasticity_training_plastic/,baylearn,1529514290,,3,21
1151,2018-6-21,2018,6,21,2,8sk0i8,[R] Best paper award at #CVPR2018,https://www.reddit.com/r/MachineLearning/comments/8sk0i8/r_best_paper_award_at_cvpr2018/,vector_machines,1529514329,[removed],0,1
1152,2018-6-21,2018,6,21,2,8sk1mz,How improve my GAN algorithm?,https://www.reddit.com/r/MachineLearning/comments/8sk1mz/how_improve_my_gan_algorithm/,fabioibaf,1529514555,[removed],0,1
1153,2018-6-21,2018,6,21,2,8sk4cv,[P] CS230 projects (Spring 2018),https://www.reddit.com/r/MachineLearning/comments/8sk4cv/p_cs230_projects_spring_2018/,HrantKhachatrian,1529515090,,25,186
1154,2018-6-21,2018,6,21,2,8sk6ow,[R] Virtual Creatures Contest (GECCO 2018),https://www.reddit.com/r/MachineLearning/comments/8sk6ow/r_virtual_creatures_contest_gecco_2018/,wei_jok,1529515552,,1,22
1155,2018-6-21,2018,6,21,3,8skl81,Kaggle #1 Winning Approach for Image Classification Challenge,https://www.reddit.com/r/MachineLearning/comments/8skl81/kaggle_1_winning_approach_for_image/,KumarShridhar,1529518420,[removed],1,0
1156,2018-6-21,2018,6,21,3,8sklsk,How do u guide a beginner for excellence in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8sklsk/how_do_u_guide_a_beginner_for_excellence_in/,_-K1L4-_,1529518544,[removed],1,1
1157,2018-6-21,2018,6,21,3,8skois,[P] Kaggle #1 Winning Approach for Image Classification Challenge,https://www.reddit.com/r/MachineLearning/comments/8skois/p_kaggle_1_winning_approach_for_image/,KumarShridhar,1529519092,,28,118
1158,2018-6-21,2018,6,21,3,8skrh4,"Data Science in 30 Minutes: DataScience.com CEO, Ian Swanson",https://www.reddit.com/r/MachineLearning/comments/8skrh4/data_science_in_30_minutes_datasciencecom_ceo_ian/,dataman3478,1529519706,,1,1
1159,2018-6-21,2018,6,21,3,8skufq,Boxx: A tool-box For Efficient Debug in Computer Vision,https://www.reddit.com/r/MachineLearning/comments/8skufq/boxx_a_toolbox_for_efficient_debug_in_computer/,diyer22,1529520307,,1,1
1160,2018-6-21,2018,6,21,3,8skxzz,Boxx: A tool-box For Efficient Debug in Computer Vision,https://www.reddit.com/r/MachineLearning/comments/8skxzz/boxx_a_toolbox_for_efficient_debug_in_computer/,diyer22,1529521032,,1,1
1161,2018-6-21,2018,6,21,4,8sl10n,[p] boxx: A tool-box For Efficient Debug in Computer Vision,https://www.reddit.com/r/MachineLearning/comments/8sl10n/p_boxx_a_toolbox_for_efficient_debug_in_computer/,diyer22,1529521633,,1,3
1162,2018-6-21,2018,6,21,4,8sl83q,Does training data affect detection time?,https://www.reddit.com/r/MachineLearning/comments/8sl83q/does_training_data_affect_detection_time/,aadams9900,1529523111,[removed],1,1
1163,2018-6-21,2018,6,21,4,8sla14,Predicting the next Fibonacci number with Linear Regression in TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/8sla14/predicting_the_next_fibonacci_number_with_linear/,curiousily_,1529523513,,1,1
1164,2018-6-21,2018,6,21,4,8slad7,[P] Generating Commencement Speeches with Markov Chains,https://www.reddit.com/r/MachineLearning/comments/8slad7/p_generating_commencement_speeches_with_markov/,whatrocks,1529523584,,3,2
1165,2018-6-21,2018,6,21,4,8slddq,[D] Predicting the next Fibonacci number with Linear Regression in TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/8slddq/d_predicting_the_next_fibonacci_number_with/,curiousily_,1529524200,,2,0
1166,2018-6-21,2018,6,21,5,8slp9u,Is there an established method/order for how to tune hyper parameters when you include the seed as a HP? Once you find a convergent seed won't it no longer be convergent once you change another hyper parameter?,https://www.reddit.com/r/MachineLearning/comments/8slp9u/is_there_an_established_methodorder_for_how_to/,Morninglow,1529526620,"So previously I was under the impression that once you turn the hyper parameters it should converge for any seed but after a thread here the other day I was taught to treat the seed as a hyper parameter like the others. 

What I'm wondering is should the seed be the last thing I tweak? To me at least it seems like if a seed converges under this set of hyper parameters / model definition then it wouldn't converge as soon as you change another hyper parameter. 

In that case should I be trying to find an optimal set of hyper parameters across different seeds and once I have good behavior then I find the convergent seed?

On a similar note, is doing all of this by hand standard practice? I've heard of automatic hyper parameter tuning but I don't see it come up much. ",1,1
1167,2018-6-21,2018,6,21,5,8slq0d,On using interpolated style transfer to generate adversarial examples and the conundrum of the true label (CVPR workshop poster),https://www.reddit.com/r/MachineLearning/comments/8slq0d/on_using_interpolated_style_transfer_to_generate/,VinayUPrabhu,1529526768,,1,1
1168,2018-6-21,2018,6,21,5,8slsiv,[D] Method / Order of Hyper Parameter Tuning With the Seed as a Hyper Parameter.,https://www.reddit.com/r/MachineLearning/comments/8slsiv/d_method_order_of_hyper_parameter_tuning_with_the/,Morninglow,1529527295,"So previously I was under the impression that once you've tuned the hyper parameters it should converge for any seed (thinking that combination is the convergent solution) but after a thread here the other day I was taught to treat the seed as a hyper parameter like the others.

What I'm wondering is, should the seed be the last thing I tweak? To me at least it seems like if a seed converges under this set of hyper parameters / model definition then it wouldn't converge as soon as you change another hyper parameter.

In that case should I be trying to find an optimal set of hyper parameters across different seeds and once I have good behavior then I find the convergent seed?

On a similar note, is doing all of this by hand standard practice? I've heard of automatic hyper parameter tuning but I don't see it come up much.",6,0
1169,2018-6-21,2018,6,21,6,8sm0nw,New AI method increases the power of artificial neural networks (Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science),https://www.reddit.com/r/MachineLearning/comments/8sm0nw/new_ai_method_increases_the_power_of_artificial/,avturchin,1529528978,,1,1
1170,2018-6-21,2018,6,21,6,8sm6pq,I took over my friends mind and whiteboard last night. Alcohol helped,https://www.reddit.com/r/MachineLearning/comments/8sm6pq/i_took_over_my_friends_mind_and_whiteboard_last/,matthew9510,1529530255,,1,1
1171,2018-6-21,2018,6,21,6,8sm97p,[D] Deep (4-Layer) Neural Network from Scratch,https://www.reddit.com/r/MachineLearning/comments/8sm97p/d_deep_4layer_neural_network_from_scratch/,muratbas6,1529530784,"I'm 17 years old,high school student from Turkey.I started to learning machine learning with Andrew Ng's machine learning course.After this course I bought Sandro Skansi's ""Introduction to Deep Learning"" book. This book was understandable and easy.Here is the my neural network implementation, I don't use any ml-dl libraries. 
https://github.com/muratbas6/dnnet
How can I improve network? Any suggestions? Thx.",3,0
1172,2018-6-21,2018,6,21,6,8sm9ul,[N] Evil Software Du Jour: Google's Cocktail Party Algorithm (anti-hype opinion piece),https://www.reddit.com/r/MachineLearning/comments/8sm9ul/n_evil_software_du_jour_googles_cocktail_party/,regalalgorithm,1529530930,,0,2
1173,2018-6-21,2018,6,21,7,8smolk,[R] Cats to crazy quilts: On what constitutes a 'true label' and using style transfer to generate adversarial examples,https://www.reddit.com/r/MachineLearning/comments/8smolk/r_cats_to_crazy_quilts_on_what_constitutes_a_true/,VinayUPrabhu,1529534201,,0,6
1174,2018-6-21,2018,6,21,8,8smyy5,What's currently the frontier in Artificial General Intelligence?,https://www.reddit.com/r/MachineLearning/comments/8smyy5/whats_currently_the_frontier_in_artificial/,GrundleMoof,1529536665,[removed],1,1
1175,2018-6-21,2018,6,21,8,8sn0ci,RNN or Recurrent Neural Networks for Noobs. An exhaustive analysis,https://www.reddit.com/r/MachineLearning/comments/8sn0ci/rnn_or_recurrent_neural_networks_for_noobs_an/,debarko,1529537014,,1,1
1176,2018-6-21,2018,6,21,8,8sn4vq,Ignite | High Level Libray for PyTorch,https://www.reddit.com/r/MachineLearning/comments/8sn4vq/ignite_high_level_libray_for_pytorch/,sksq9,1529538120,,1,1
1177,2018-6-21,2018,6,21,8,8sn7sr,[R] The Natural Language Decathlon,https://www.reddit.com/r/MachineLearning/comments/8sn7sr/r_the_natural_language_decathlon/,aviniumau,1529538992,,0,20
1178,2018-6-21,2018,6,21,10,8snwj9,[P] Machine Learning Model Training and Serving Using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8snwj9/p_machine_learning_model_training_and_serving/,lewis_maxwellplus,1529545130,,2,1
1179,2018-6-21,2018,6,21,10,8snwrm,"Hey yall, whats a clever name for a Heavy Metal Machinery shop out in west Texas?",https://www.reddit.com/r/MachineLearning/comments/8snwrm/hey_yall_whats_a_clever_name_for_a_heavy_metal/,alpinemantx,1529545199,[removed],1,1
1180,2018-6-21,2018,6,21,11,8soayq,"New AI method gives full AI capability to inexpensive computers, and would make it possible in one to two years for supercomputers to utilize Artificial Neural Networks that quadratically exceed the possibilities of today's artificial neural networks.",https://www.reddit.com/r/MachineLearning/comments/8soayq/new_ai_method_gives_full_ai_capability_to/,gfhfghfghghdfhgfh656,1529548847,,1,1
1181,2018-6-21,2018,6,21,11,8sodta,Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science [R],https://www.reddit.com/r/MachineLearning/comments/8sodta/scalable_training_of_artificial_neural_networks/,gfhfghfghghdfhgfh656,1529549573,,9,18
1182,2018-6-21,2018,6,21,12,8soj6q,Action recognition performance drops when using ROI-Pooling,https://www.reddit.com/r/MachineLearning/comments/8soj6q/action_recognition_performance_drops_when_using/,__null__,1529550950,,1,1
1183,2018-6-21,2018,6,21,13,8soysi,Movie Credit Dataset,https://www.reddit.com/r/MachineLearning/comments/8soysi/movie_credit_dataset/,snehalg,1529555109,Does anyone know any dataset with movie pre/post credit images??,1,1
1184,2018-6-21,2018,6,21,13,8sp5ni,[D] Is there a program that you can feed a story to and it can put likelihood of fiction or nonfiction?,https://www.reddit.com/r/MachineLearning/comments/8sp5ni/d_is_there_a_program_that_you_can_feed_a_story_to/,coderedmedia,1529557137,"I often see stories on Reddit and Quora that are presented as a true story, but I doubt it because it reads like fiction. But I dont always know why my brain is telling me its false, I just *know*.

Has anyone fed a machine a bunch of fiction and nonfiction stories to learn the difference?

If not, how hard would it be for a complete novice to make one?",4,0
1185,2018-6-21,2018,6,21,14,8spfyk,Training a binary classifier using a text file,https://www.reddit.com/r/MachineLearning/comments/8spfyk/training_a_binary_classifier_using_a_text_file/,ThiccShadyy,1529560567,,1,1
1186,2018-6-21,2018,6,21,15,8spifi,Global Solar Shading Systems Market Research Report 2018,https://www.reddit.com/r/MachineLearning/comments/8spifi/global_solar_shading_systems_market_research/,tejashree23,1529561346,,1,1
1187,2018-6-21,2018,6,21,15,8spn8s,Which Pytorch usage is correct to optimize this network?,https://www.reddit.com/r/MachineLearning/comments/8spn8s/which_pytorch_usage_is_correct_to_optimize_this/,jindongwang,1529562901,[removed],1,1
1188,2018-6-21,2018,6,21,15,8sprp2,K How KNN Algorithm Works With Example - Machine Learning made Easy,https://www.reddit.com/r/MachineLearning/comments/8sprp2/k_how_knn_algorithm_works_with_example_machine/,pooja307,1529564340,,1,1
1189,2018-6-21,2018,6,21,16,8sptkw,Best Machine Learning Training in Delhi | Aedifico Tech,https://www.reddit.com/r/MachineLearning/comments/8sptkw/best_machine_learning_training_in_delhi_aedifico/,daisybose5,1529564910,[removed],1,1
1190,2018-6-21,2018,6,21,16,8spufp,KNN Algorithm Explained - Machine Learning Made Easy,https://www.reddit.com/r/MachineLearning/comments/8spufp/knn_algorithm_explained_machine_learning_made_easy/,pooja307,1529565203,,1,1
1191,2018-6-21,2018,6,21,16,8sq0jy,"RUDDER -- Reinforcement Learning algorithm that is ""exponentially faster than TD, MC, and MC Tree Search (MCTS)""",https://www.reddit.com/r/MachineLearning/comments/8sq0jy/rudder_reinforcement_learning_algorithm_that_is/,AdversarialDomain,1529567337,,110,333
1192,2018-6-21,2018,6,21,16,8sq1ec,Speech Recognition with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8sq1ec/speech_recognition_with_tensorflow/,tttttm,1529567657,,1,1
1193,2018-6-21,2018,6,21,16,8sq1nm,[P] Speech Recognition with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8sq1nm/p_speech_recognition_with_tensorflow/,tttttm,1529567735,,1,5
1194,2018-6-21,2018,6,21,17,8sq3xz,Learn Machine Learning using Tensorflow for Free,https://www.reddit.com/r/MachineLearning/comments/8sq3xz/learn_machine_learning_using_tensorflow_for_free/,prithvi45,1529568506,,1,1
1195,2018-6-21,2018,6,21,17,8sq6jh,Annotate occulted objects with a bounding box,https://www.reddit.com/r/MachineLearning/comments/8sq6jh/annotate_occulted_objects_with_a_bounding_box/,loose11,1529569463,[removed],1,1
1196,2018-6-21,2018,6,21,17,8sq7nd,Recommending Similar Artists,https://www.reddit.com/r/MachineLearning/comments/8sq7nd/recommending_similar_artists/,kaka8388,1529569872,[removed],1,1
1197,2018-6-21,2018,6,21,17,8sq7w2,Top Machine Learning Training in Delhi | Aedifico Tech,https://www.reddit.com/r/MachineLearning/comments/8sq7w2/top_machine_learning_training_in_delhi_aedifico/,daisybose5,1529569954,,1,1
1198,2018-6-21,2018,6,21,17,8sq930,Can I use sklearn randomforest method to calculate the feature importance then select some feature to input in LSTM model?,https://www.reddit.com/r/MachineLearning/comments/8sq930/can_i_use_sklearn_randomforest_method_to/,lxj0276,1529570423,[removed],1,1
1199,2018-6-21,2018,6,21,17,8sqarh,[D]Can I use sklearn randomforest method to calculate the feature importance then select some features to input in LSTM model?,https://www.reddit.com/r/MachineLearning/comments/8sqarh/dcan_i_use_sklearn_randomforest_method_to/,lxj0276,1529571056," Now my dataset have many many features,I want to select some very import features using sklearn randomforest method,then create new dataset by these features and input to my LSTM model. ",1,0
1200,2018-6-21,2018,6,21,18,8sqg3p,Web Design and Web Development Institutes in Delhi | Aedifico Tech,https://www.reddit.com/r/MachineLearning/comments/8sqg3p/web_design_and_web_development_institutes_in/,daisybose5,1529572939,[removed],1,1
1201,2018-6-21,2018,6,21,18,8sqjjv,[D] Can NNs output a function formula from a given set of points?,https://www.reddit.com/r/MachineLearning/comments/8sqjjv/d_can_nns_output_a_function_formula_from_a_given/,RealBrofessor,1529574145,"Recently I have been messing around with function approximation and tried to build a network to approximate my functions, it worked quite well.  
However, I stumbled upon a problem I couldn't quite figure out. Say I have function y=x^2, I would like to use points fulfilling this formula ( [1,1],[2,4],[3,9],...) and use them as inputs for my NN to obtain literally the formula itself.  
I don't know if that makes sense, simply I would like to feed some points into NN and get the literal function formula describing the points.  
I have read online that genetic programming might be better solution for this kind of problem, but is it possible to do with NNs? Is it even worth doing with NNs? ",5,1
1202,2018-6-21,2018,6,21,19,8sqocl,Relatively the best laptops for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8sqocl/relatively_the_best_laptops_for_machine_learning/,_guru007,1529575797,[removed],1,1
1203,2018-6-21,2018,6,21,19,8sqvm9,Buying and selling computing power for ML jobs on a spot market,https://www.reddit.com/r/MachineLearning/comments/8sqvm9/buying_and_selling_computing_power_for_ml_jobs_on/,sply,1529578232,,1,1
1204,2018-6-21,2018,6,21,19,8sqwan,Buying and selling computing power for ML jobs on a spot market,https://www.reddit.com/r/MachineLearning/comments/8sqwan/buying_and_selling_computing_power_for_ml_jobs_on/,kvechera,1529578456,,1,1
1205,2018-6-21,2018,6,21,20,8sr8cv,Machine Learning Course,https://www.reddit.com/r/MachineLearning/comments/8sr8cv/machine_learning_course/,nandiniravichandran,1529581950,,1,1
1206,2018-6-21,2018,6,21,20,8sr945,[R] Feature Transformers: Hidden Gems,https://www.reddit.com/r/MachineLearning/comments/8sr945/r_feature_transformers_hidden_gems/,dearpetra,1529582160,,0,1
1207,2018-6-21,2018,6,21,21,8sracy,Egg Roll Wrapper Making Machine,https://www.reddit.com/r/MachineLearning/comments/8sracy/egg_roll_wrapper_making_machine/,lgsherry,1529582493,,2,1
1208,2018-6-21,2018,6,21,21,8srdu8,Using Deep Learning to Help Pathologists Find Tumors,https://www.reddit.com/r/MachineLearning/comments/8srdu8/using_deep_learning_to_help_pathologists_find/,j_orshman,1529583444,,1,1
1209,2018-6-21,2018,6,21,21,8srjxt,Vending Machines,https://www.reddit.com/r/MachineLearning/comments/8srjxt/vending_machines/,AliceHughes1,1529585079,,1,1
1210,2018-6-21,2018,6,21,21,8srkft,"[N] Weekly Machine Learning Opensource Roundup  June 21, 2018",https://www.reddit.com/r/MachineLearning/comments/8srkft/n_weekly_machine_learning_opensource_roundup_june/,stkim1,1529585208,,0,1
1211,2018-6-21,2018,6,21,22,8srt7f,How Its Made? Drill bits. Raw Material and Manufacturing Process used in Industries.,https://www.reddit.com/r/MachineLearning/comments/8srt7f/how_its_made_drill_bits_raw_material_and/,maantechnoplus,1529587357,,1,1
1212,2018-6-21,2018,6,21,22,8sru88,Calculate probability of disease appearance,https://www.reddit.com/r/MachineLearning/comments/8sru88/calculate_probability_of_disease_appearance/,nyquist_karma,1529587607,[removed],1,1
1213,2018-6-21,2018,6,21,22,8srvoi,How Machine Learning Will Take Customer Experience to the Next Level,https://www.reddit.com/r/MachineLearning/comments/8srvoi/how_machine_learning_will_take_customer/,knexusgroup,1529587943,,1,1
1214,2018-6-21,2018,6,21,22,8ss1sh,How Machine Learning Will Take Customer Experience to the Next Level,https://www.reddit.com/r/MachineLearning/comments/8ss1sh/how_machine_learning_will_take_customer/,knexusgroup,1529589324,,1,1
1215,2018-6-21,2018,6,21,22,8ss2gw,Why we ran DeepVariant as a Nextflow pipeline over cloud.,https://www.reddit.com/r/MachineLearning/comments/8ss2gw/why_we_ran_deepvariant_as_a_nextflow_pipeline/,margarida-gsl,1529589478,,1,1
1216,2018-6-21,2018,6,21,23,8ss56l,MACHINE LEARNING IN FINANCE,https://www.reddit.com/r/MachineLearning/comments/8ss56l/machine_learning_in_finance/,alpha_quant,1529590080,"Machine learning (ML) is one of the most promising areas of innovation that companies from all sectors are recently seeking to explore. Companies ranging from the manufacturing sector to the robotics and mechanical engineering sector are increasingly using Artificial Intelligence (AI) and ML.  
Beyond that, the AI concept has extended its impact to the financial markets through machine learning. Over the last two decades, markets have become more dynamic and trading using ML algorithms is seemingly taking over from the traditional exchange-based trading. Hedge fund managers and traders alike are now focusing on developing programs that assist their daily trading business in an effort to increase returns. 

![img](qs69fxjq2d511)

 There is also a recent trend for banks and finance firms to ask for more data analysis skills and market knowledge. This is quite rational, since understanding the economics behind the data and the market is as important as developing complex technical solutions.  
It is also a fact that human beings cannot be excluded from trading. However, the size of data required for making a good trade are increasingly bigger. For this reason, it is inevitable that at some point in the near future machines will become increasingly prevalent over humans on this task. Machines have the ability to quickly analyze data, news and tweets, process earnings statements, scrape websites, and trade on all these instantaneously. This ability will provide an invaluable tool for traders, fundamental analysts, equity long-short managers and macro investors.  
Nevertheless, humans still retain an advantage on seeing the big picture. Machines are still not very good at spotting market turning points and making forecasts involving human responses such as those of politicians and central bankers, or anticipating how markets are going to move. In addition to this, the data required for predicting the markets are getting more and more complex.  
This is why data scientists are getting increasingly sought after nowadays. Before machine learning strategies can be implemented, data scientists and quantitative researchers need to acquire and analyze the data with the aim of deriving tradable positions and trends.  
This data analysis is extremely complex. Todays datasets are much bigger than yesterdays. They can include anything from data generated by individuals (social media posts, product reviews, announcements, search trends, etc.), to data generated by business processes (company data, commercial transactions, trades etc)  
These new forms of data need to be thoroughly analyzed before they can be used in a trading strategy. 

![img](hs1ct3lu2d511)

Machine learning includes many concepts such as supervised learning, unsupervised learning and deep and reinforcement learning.  
The purpose of supervised learning is to establish a relationship between two datasets and to use one dataset to forecast the other.  
The purpose of unsupervised learning is to train an artificial intelligence algorithm using information that is neither classified nor labelled and allowing the algorithm to act on that information without guidance.  
The purpose of deep learning is to use multi-layered neural networks to analyze a trend, while reinforcement learning uses algorithms to explore and find the most profitable trading strategies.  
As a result, the skills required for a data scientist is actually the same as for any other quantitative researchers. Existing buy side and sell side quants with backgrounds in computer science, statistics, maths, financial engineering, econometrics and natural sciences are continuously moving into this new field of expertise.

Apart from Machine Learning skills, expertise in software development is also a useful asset. Most of the Machine Learning methods and libraries are already there (e.g. in Python): you just need to know how to apply the existing models and be confident to modify them if required.

In general, the use of ML-based trading systems has started to make trading easier and more profitable. While these systems are common among both large hedge funds and smaller startups, third party trading software developers have also provided a new way for individual traders to get in the game.  
All the above have changed the way traders are doing their every day jobs. We are living in an era where making money in the stock market is not only a question of how experienced you are, but also of how powerful your trading tool is.",1,1
1217,2018-6-21,2018,6,21,23,8ss70s,Why we ran DeepVariant as a Nextflow pipeline over cloud.,https://www.reddit.com/r/MachineLearning/comments/8ss70s/why_we_ran_deepvariant_as_a_nextflow_pipeline/,margarida-gsl,1529590460,,1,1
1218,2018-6-21,2018,6,21,23,8ss88g,Generating ATARI images using Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/8ss88g/generating_atari_images_using_generative/,satwik_,1529590720,,1,1
1219,2018-6-21,2018,6,21,23,8ss8yb,[P] Generating Atari images using Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/8ss8yb/p_generating_atari_images_using_generative/,satwik_,1529590874,,1,0
1220,2018-6-21,2018,6,21,23,8ss9vn,MILA rebranded as Quebec Artificial Intelligence Institute,https://www.reddit.com/r/MachineLearning/comments/8ss9vn/mila_rebranded_as_quebec_artificial_intelligence/,shagunsodhani,1529591078,,1,1
1221,2018-6-21,2018,6,21,23,8ssaao,[N] MILA rebranded as Quebec Artificial Intelligence Institute,https://www.reddit.com/r/MachineLearning/comments/8ssaao/n_mila_rebranded_as_quebec_artificial/,shagunsodhani,1529591172,,4,17
1222,2018-6-21,2018,6,21,23,8ssbep,[D] How would you approach building a classifier model than can learn from user feedback?,https://www.reddit.com/r/MachineLearning/comments/8ssbep/d_how_would_you_approach_building_a_classifier/,ElCracker,1529591428,"Hello r/MachineLearning!  


I'm currently building an app which uses AWS Machine Learning service to predict how much will a user enjoy a movie based on their taste and the data about the movie. The predictions are ranging from 0 (terrible match, don't watch this movie) to 1 (it's amazing, you need to see it asap).  


What I would like to do is to allow the users to like/dislike my prediction and then feed this input back into the model so it can improve based on feedback from the users. I've been searching through the Web for the last 30 minutes and I couldn't find anything concrete.   


What are the approaches you'd recommend? Any useful links I should take a look at?",7,1
1223,2018-6-21,2018,6,21,23,8ssgoy,I am having hard time understanding Variational Autoencoders presumably because of missing background. What are the preliminaries?,https://www.reddit.com/r/MachineLearning/comments/8ssgoy/i_am_having_hard_time_understanding_variational/,porygon93,1529592547,[removed],1,1
1224,2018-6-22,2018,6,22,0,8sskc1,[Discussion] Does SMOTE or other class balancing techniques actually improve Area Under Precision-Recall?,https://www.reddit.com/r/MachineLearning/comments/8sskc1/discussion_does_smote_or_other_class_balancing/,eric_he,1529593293,"Hi all,

I've been working on a prediction problem with a fairly strong class imbalance using tree ensembles. I have no problems with too much or too little data, but I do read everywhere that addressing class imbalance improves predictive power.

However, most of the papers (including the \[paper\]([https://jair.org/index.php/jair/article/view/10302](https://jair.org/index.php/jair/article/view/10302)) for SMOTE) evaluate their performance in terms of benefits to the Area under the ROC curve (AuROC). This is not the best or most informative metric to use as the AuROC metric is sensitive to class imbalance. See \[this paper\]([https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/)) which explains why the Area under Precision-Recall (AuPR) metric is better in such situations. Essentially, AuROC is boosted when the classifier correctly predicts either a True Positive or a True Negative, which in cases of class imbalance can lead to drastic inflation of the score due to the True Negatives making up the majority of the dataset. The AuPR score only increases when the model correctly identifies a True Positive.

To address that, the SMOTE paper evaluates the AuROC on a separate balanced dataset each time it rebalances. However, the improvements to their AuROC score still derive from tradeoffs between precision and recall, making the benefits of the technique difficult to assess. (Moreover the AuROC benefits were marginal and susceptible to the multiple comparisons problem).

In my experience, using simple undersampling or oversampling techniques never changed my AuPR score, and only served to make me recalibrate my probability predictions. SMOTE, however, seems to be a fairly sophisticated technique and I have not seen it being questioned. Despite this, I can find no literature involving the AuPR metric. 

Am I understanding something incorrectly? Do any of you have any experience with SMOTE and evaluating SMOTE, or other class balancing techniques? Did SMOTE or other class balancing techniques improve your predictive power?

Thank you so much!",14,9
1225,2018-6-22,2018,6,22,0,8sslge,[P] Policy Gradients with Doom  and Tensorflow (tutorial),https://www.reddit.com/r/MachineLearning/comments/8sslge/p_policy_gradients_with_doom_and_tensorflow/,cranthir_,1529593509,"Hey there!

The third video of Deep Reinforcement Learning course with Tensorflow is out 

In this video we'll implement a **Policy Gradient agent with Tensorflow that learns to play Doom Deathmatch ** 

**The video**  : [https://www.youtube.com/watch?v=wLTQRuizVyE](https://www.youtube.com/watch?v=wLTQRuizVyE)

The Policy Gradient article   : [https://medium.freecodecamp.org/an-introduction-to-policy-gradients-with-cartpole-and-doom-495b5ef2207f](https://medium.freecodecamp.org/an-introduction-to-policy-gradients-with-cartpole-and-doom-495b5ef2207f)

The Implementation notebook    : [https://github.com/simoninithomas/Deep\_reinforcement\_learning\_Course/blob/master/Policy&amp;#37;20Gradients/Doom&amp;#37;20Deathmatch/Doom-deathmatch&amp;#37;20REINFORCE&amp;#37;20Monte&amp;#37;20Carlo&amp;#37;20Policy&amp;#37;20gradients.ipynb](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Policy%20Gradients/Doom%20Deathmatch/Doom-deathmatch%20REINFORCE%20Monte%20Carlo%20Policy%20gradients.ipynb)

**For my others videos about deep reinforcement learning,** the playlist : [https://www.youtube.com/watch?v=q2ZOEFAaaI0&amp;list=PLQLZ37V8CnUTdIoJJdvmmFoQJntZ9dp5Q](https://www.youtube.com/watch?v=q2ZOEFAaaI0&amp;list=PLQLZ37V8CnUTdIoJJdvmmFoQJntZ9dp5Q)

The Syllabus of the course: [https://simoninithomas.github.io/Deep\_reinforcement\_learning\_Course/](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/) 

*Processing img 2qgclm74dd511...*

Again let me say **what you think about the course (articles and videos) and how it should be improved!**

Thanks for your help! ",1,3
1226,2018-6-22,2018,6,22,0,8ssqhj,Q-Learning attaching the Environment to the AI? Possible/How?,https://www.reddit.com/r/MachineLearning/comments/8ssqhj/qlearning_attaching_the_environment_to_the_ai/,Jandevries101,1529594527,[removed],1,1
1227,2018-6-22,2018,6,22,1,8st66f,Bias detectives: the researchers striving to make algorithms fair,https://www.reddit.com/r/MachineLearning/comments/8st66f/bias_detectives_the_researchers_striving_to_make/,FortuitousAdroit,1529597692,,1,1
1228,2018-6-22,2018,6,22,1,8st6z2,[P] Tutorial: Training a smartcab in Python using Reinforcement Q learning,https://www.reddit.com/r/MachineLearning/comments/8st6z2/p_tutorial_training_a_smartcab_in_python_using/,satwik_,1529597843,,0,2
1229,2018-6-22,2018,6,22,1,8st7zv,[P] Using Clustering Algorithms to Analyze Golf Shots from the U.S. Open,https://www.reddit.com/r/MachineLearning/comments/8st7zv/p_using_clustering_algorithms_to_analyze_golf/,grassclip,1529598044,,0,3
1230,2018-6-22,2018,6,22,1,8stdee,Preparing a Machine Learning-Ready Dataset for Market Basket Analysis,https://www.reddit.com/r/MachineLearning/comments/8stdee/preparing_a_machine_learningready_dataset_for/,czuriaga,1529599161,,1,1
1231,2018-6-22,2018,6,22,1,8stdqj,[D] Smyte is being acquired by Twitter. Any alternative moderation/spam/safety services?,https://www.reddit.com/r/MachineLearning/comments/8stdqj/d_smyte_is_being_acquired_by_twitter_any/,Loggerny,1529599228,,1,2
1232,2018-6-22,2018,6,22,2,8stsm5,What college to attend,https://www.reddit.com/r/MachineLearning/comments/8stsm5/what_college_to_attend/,BL4CKvGHOST,1529602150,[removed],1,1
1233,2018-6-22,2018,6,22,2,8su123,[R] How Can Neural Network Similarity Help Us Understand Training and Generalization?,https://www.reddit.com/r/MachineLearning/comments/8su123/r_how_can_neural_network_similarity_help_us/,baylearn,1529603854,,3,11
1234,2018-6-22,2018,6,22,3,8su21o,"[P] Create ML Playgrounds for Chest X-rays, Movie Review Sentiment, Fruits, Flowers: Training classifiers as easy as creating sticker packs",https://www.reddit.com/r/MachineLearning/comments/8su21o/p_create_ml_playgrounds_for_chest_xrays_movie/,fratkabula,1529604056,,3,4
1235,2018-6-22,2018,6,22,3,8sue41,"[R] The recent paper out from Google, ""Scalable and accurate deep learning with electronic health records"", has an notable result in the supplement: regularized logistic regression essentially performs just as well as Deep Nets",https://www.reddit.com/r/MachineLearning/comments/8sue41/r_the_recent_paper_out_from_google_scalable_and/,feedthecreed,1529606467,,119,456
1236,2018-6-22,2018,6,22,3,8suf3g,Off-the-shelf networks vs. implementing algorithms from papers vs. creating your own algorithms (xpost /r/datascience),https://www.reddit.com/r/MachineLearning/comments/8suf3g/offtheshelf_networks_vs_implementing_algorithms/,3shar5ever,1529606667,[removed],1,1
1237,2018-6-22,2018,6,22,3,8sugk8,[P] How we leveraged a GAN and a ConvLSTM to go from League of Legends minimap frames to player coordinates,https://www.reddit.com/r/MachineLearning/comments/8sugk8/p_how_we_leveraged_a_gan_and_a_convlstm_to_go/,lfotofilter,1529606965,,16,12
1238,2018-6-22,2018,6,22,3,8suitp,NeuralRad Mammogram AI (Win X64) desktop version 1.3 released,https://www.reddit.com/r/MachineLearning/comments/8suitp/neuralrad_mammogram_ai_win_x64_desktop_version_13/,coolwulf,1529607420,[removed],1,1
1239,2018-6-22,2018,6,22,3,8sujbf,NeuralRad Mammogram AI (Win X64) desktop version 1.3 released,https://www.reddit.com/r/MachineLearning/comments/8sujbf/neuralrad_mammogram_ai_win_x64_desktop_version_13/,coolwulf,1529607515,[removed],1,1
1240,2018-6-22,2018,6,22,3,8sujn4,[P]NeuralRad Mammogram AI (Win X64) desktop version 1.3 released,https://www.reddit.com/r/MachineLearning/comments/8sujn4/pneuralrad_mammogram_ai_win_x64_desktop_version/,coolwulf,1529607584,"For details of the project, see my previous post.

[Release Notes]

    Better supports for dicom files from panels such as Fujifilm

    Options to not use normalization for dicom files.

    Options to not reverse b/w of the dicom image.

You can directly download it from http://NeuralRad.com for free.",5,10
1241,2018-6-22,2018,6,22,5,8sv5ja,[Question] How to compute MLE for softmax regression?,https://www.reddit.com/r/MachineLearning/comments/8sv5ja/question_how_to_compute_mle_for_softmax_regression/,FlyingQuokka,1529612132,[removed],1,1
1242,2018-6-22,2018,6,22,6,8svjlp,Neural Network Matlab toolbox,https://www.reddit.com/r/MachineLearning/comments/8svjlp/neural_network_matlab_toolbox/,N3ur0n15,1529615064,[removed],1,1
1243,2018-6-22,2018,6,22,6,8svklc,what should the Q matrix dimensions be in an open-like environment for Q-learning,https://www.reddit.com/r/MachineLearning/comments/8svklc/what_should_the_q_matrix_dimensions_be_in_an/,Teared_up,1529615291,[removed],1,1
1244,2018-6-22,2018,6,22,6,8svoj9,"[R] New CC0 Image Dataset on Kaggle: Polyhedral Dice (d4,d6,d8,d10,d12,d20) 16,000+ Images",https://www.reddit.com/r/MachineLearning/comments/8svoj9/r_new_cc0_image_dataset_on_kaggle_polyhedral_dice/,ucffool,1529616157,,7,36
1245,2018-6-22,2018,6,22,6,8svok2,Suggested CNN Frameworks for Object Detection in Satellite Imagery?,https://www.reddit.com/r/MachineLearning/comments/8svok2/suggested_cnn_frameworks_for_object_detection_in/,clifgray,1529616162,[removed],1,1
1246,2018-6-22,2018,6,22,6,8svrk6,[P] Suggested CNN Frameworks for Object Detection in Satellite Imagery?,https://www.reddit.com/r/MachineLearning/comments/8svrk6/p_suggested_cnn_frameworks_for_object_detection/,clifgray,1529616809,"I'm looking to detect boats in large satellite scenes of the ocean. I'm successfully applied [matterport's Mask-RCNN setup](https://github.com/matterport/Mask_RCNN) on small subsets of satellite imagery but it is way too slow to do huge images like WorldView. I'm looking for something fast that can do bounding boxes, is in python, and implemented in Keras. Any suggestions?

I've found a couple promising leads:

* You Only Look Twice, YOLO variant optimized for satellite imagery but built in C and not super well documented
 * Code: https://github.com/avanetten/yolt
 * Paper: https://arxiv.org/pdf/1805.09512.pdf
* RasterVision: a general python based framework for applying CNNs to satellite imagery, looks promising but nascent
 * Code: https://github.com/azavea/raster-vision
* This Kaggle competition has some promising info but at ~18 months old is somewhat outdated: 
 * Link: https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection

I may try to customize this implementation of [RetinaNet in Keras](https://github.com/fizyr/keras-retinanet) for satellite imagery following the suggestions from the YOLT paper but would love other suggestions!",7,6
1247,2018-6-22,2018,6,22,8,8swi9m,ML Programming Made [too much] Easy  Part 1,https://www.reddit.com/r/MachineLearning/comments/8swi9m/ml_programming_made_too_much_easy_part_1/,kiarash-irandoust,1529622812,,1,1
1248,2018-6-22,2018,6,22,8,8swsl6,How to apply machine learning to this stock valuation model?,https://www.reddit.com/r/MachineLearning/comments/8swsl6/how_to_apply_machine_learning_to_this_stock/,pnzlegend,1529625363,"[https://papers.ssrn.com/sol3/papers.cfm?abstract\_id=3177338](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3177338)

I came across this paper which describes a stock valuation model that the author says can be applied using machine learning. I am trying to build a machine learning stock investing program, can the methods in this paper be utilized and if so which programs do you recommend?",1,1
1249,2018-6-22,2018,6,22,8,8swt4x,"[D] I could only find one machine learning wikia and it seemed pretty dead, do you think the community could benefit from a comprehensive wiki for devs, researchers, and people getting into the field?",https://www.reddit.com/r/MachineLearning/comments/8swt4x/d_i_could_only_find_one_machine_learning_wikia/,Morninglow,1529625490,"So I've noticed the wikipedia articles for machine learning are useful for giving you an idea of a topic but there's not much detail, for someone like me at least I would find a dedicated wikia for machine learning to be very useful, for instance look at this article for DBN

[https://en.wikipedia.org/wiki/Deep\_belief\_network](https://en.wikipedia.org/wiki/Deep_belief_network)

Now compare it to the article for merge sort

[https://en.wikipedia.org/wiki/Merge\_sort](https://en.wikipedia.org/wiki/Merge_sort)

While learning to program I didn't use wikipedia as a source much because other reliable info (in more digestible format) was available, but for machine learning the sources can be very unreliable and sometimes hard to come by.

For a couple of examples, last semester I did a LSTM in numpy, all of the guides I could find were incomplete or wrong, focusing on the intuition and not the algorithms and code. One guide had a professional looking video to go along with it and with his code each back prop and feed forward took on average SEVENTY FOUR SECONDS. That is not what we should be teaching the kids. 

Recently I was trying to do a GAN in keras. I read the paper first and then looked through at least 10 implementations that all seemed wrong before learning in a comment thread keras was inflexible for this task and you needed to train it with tensorflow.

In the former case, a model definition and training algorithm in psuedo code like the merge sort article, and in the later case a note in the ""implementations"" section of an article would also have saved me a huge amount of time. 

Then there's the problem of dissemination of research, it seems like stumbling across the paper / method relevant to you requires too much luck. 

Then there's incomplete sources, research papers that leave out their model definitions, algorithms, data sets, and code. While it couldn't make up for what people leave out it could give you the accepted approach, corresponding data sets, and benchmarks against other methods. 

All in all it seems like we have a ton of information but it's scattered across the internet and difficult to access. ",21,35
1250,2018-6-22,2018,6,22,9,8swv4y,[R] How to apply machine learning to this stock valuation model?,https://www.reddit.com/r/MachineLearning/comments/8swv4y/r_how_to_apply_machine_learning_to_this_stock/,pnzlegend,1529626013,"[https://papers.ssrn.com/sol3/papers.cfm?abstract\_id=3177338](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3177338)

I came across this paper which describes a stock valuation model that the author says can be applied using machine learning. I am trying to build a machine learning stock investing program, can the methods in this paper be utilized and if so which programs do you recommend?",1,0
1251,2018-6-22,2018,6,22,10,8sxcwq,YouTube,https://www.reddit.com/r/MachineLearning/comments/8sxcwq/youtube/,YvetteDarleyv69,1529630664,,1,1
1252,2018-6-22,2018,6,22,11,8sxltr,Would it be possible to program an AI to predict and discover potentially unknown winning products for eCommerce?,https://www.reddit.com/r/MachineLearning/comments/8sxltr/would_it_be_possible_to_program_an_ai_to_predict/,BradJ,1529632877,[removed],1,1
1253,2018-6-22,2018,6,22,11,8sxox3,Is it feasible to construct an AI to predict and discovery potentially winning products for eCommerce?,https://www.reddit.com/r/MachineLearning/comments/8sxox3/is_it_feasible_to_construct_an_ai_to_predict_and/,BradJ,1529633817,[removed],1,1
1254,2018-6-22,2018,6,22,13,8syep6,Top 3 Machine Learning courses essential to become a Data Scientist,https://www.reddit.com/r/MachineLearning/comments/8syep6/top_3_machine_learning_courses_essential_to/,micahwilliams12,1529640640,,1,1
1255,2018-6-22,2018,6,22,13,8syfr0,Gay in computer vision?,https://www.reddit.com/r/MachineLearning/comments/8syfr0/gay_in_computer_vision/,gay_in_CV,1529640950,[removed],1,1
1256,2018-6-22,2018,6,22,13,8syhvl,[D] LGBT in computer vision,https://www.reddit.com/r/MachineLearning/comments/8syhvl/d_lgbt_in_computer_vision/,gay_in_CV,1529641556,,51,0
1257,2018-6-22,2018,6,22,14,8sysig,Visualization of different neural networks in 3D,https://www.reddit.com/r/MachineLearning/comments/8sysig/visualization_of_different_neural_networks_in_3d/,akshayagrwl827,1529644695,I just came across this video on YouTube and this looks amazing to me! ,1,1
1258,2018-6-22,2018,6,22,14,8syypu,CVPR Workshop on FIFA World Cup,https://www.reddit.com/r/MachineLearning/comments/8syypu/cvpr_workshop_on_fifa_world_cup/,ufoym,1529646686,,1,1
1259,2018-6-22,2018,6,22,16,8szd7k,[P] 95% test accuracy on MNIST where 90% of train labels are randomly shuffled.,https://www.reddit.com/r/MachineLearning/comments/8szd7k/p_95_test_accuracy_on_mnist_where_90_of_train/,samchoi7,1529651548,,0,1
1260,2018-6-22,2018,6,22,16,8szdjf,[P] ChoiceNet achieves 95% test accuracy where 90% of train labels are randomly shuffled.,https://www.reddit.com/r/MachineLearning/comments/8szdjf/p_choicenet_achieves_95_test_accuracy_where_90_of/,samchoi7,1529651665,,21,56
1261,2018-6-22,2018,6,22,16,8szfxs,ML Programming Made [too much] Easy,https://www.reddit.com/r/MachineLearning/comments/8szfxs/ml_programming_made_too_much_easy/,Fewthp,1529652507,,1,1
1262,2018-6-22,2018,6,22,16,8szjry,Puffed Cereal Bar Production Line For Sale|Peanut Chikki Making Machine Price,https://www.reddit.com/r/MachineLearning/comments/8szjry/puffed_cereal_bar_production_line_for_salepeanut/,Machineprices,1529653835,[removed],1,1
1263,2018-6-22,2018,6,22,17,8szlj9,Where to find Plant Specious Dataset For Semantic Plant leaf Segmentation?,https://www.reddit.com/r/MachineLearning/comments/8szlj9/where_to_find_plant_specious_dataset_for_semantic/,a_Israel,1529654458,[removed],1,1
1264,2018-6-22,2018,6,22,17,8szlvf,[P] Learning how to Protect Children Online: Detect child grooming in chat logs with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8szlvf/p_learning_how_to_protect_children_online_detect/,cpury,1529654577,,4,19
1265,2018-6-22,2018,6,22,17,8sznow,AI is everywhere,https://www.reddit.com/r/MachineLearning/comments/8sznow/ai_is_everywhere/,crazy_boss_reloaded,1529655245,,1,1
1266,2018-6-22,2018,6,22,18,8szz9q,Top 10 Applications of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8szz9q/top_10_applications_of_machine_learning/,pooja307,1529659571,,1,1
1267,2018-6-22,2018,6,22,18,8t00qw,Anyone used Leaflet package in R before?,https://www.reddit.com/r/MachineLearning/comments/8t00qw/anyone_used_leaflet_package_in_r_before/,deepmaniyar,1529660093,[removed],1,1
1268,2018-6-22,2018,6,22,18,8t02go,OpenMined,https://www.reddit.com/r/MachineLearning/comments/8t02go/openmined/,iamtrask,1529660679,,1,1
1269,2018-6-22,2018,6,22,18,8t02yt,"OpenMined - Open Source Federated Learning, Differential Privacy, and Cryptography (with PyTorch)",https://www.reddit.com/r/MachineLearning/comments/8t02yt/openmined_open_source_federated_learning/,iamtrask,1529660861,,1,1
1270,2018-6-22,2018,6,22,18,8t033v,"OpenMined - Open Source Federated Learning, Differential Privacy, and Cryptography (with PyTorch)",https://www.reddit.com/r/MachineLearning/comments/8t033v/openmined_open_source_federated_learning/,iamtrask,1529660914,,1,1
1271,2018-6-22,2018,6,22,19,8t05i1,"""[Project]"" Why my A3C with LSTM can not converge for CartPole-v0 ?",https://www.reddit.com/r/MachineLearning/comments/8t05i1/project_why_my_a3c_with_lstm_can_not_converge_for/,playhala,1529661763,"The codes and model description are shown in [https://github.com/convexsetgithub/myA3C](https://github.com/convexsetgithub/myA3C) . During the training, I report the reward for each batch, and the A3C without LSTM can get reward that converges to 200.

However, the reward of A3C with LSTM can converge to 200 with a moderately large variance. After the reward staying close to or on 200 for a  long time ('long' means you have seen reward 200 for many batches, and thought the model succeeded), the reward will suddenly decrease to a small value like 15, and then slowly converge to 200 for the next batches.  I observed such cases for several times even I keep training. 

Could you have any suggestion? 

BTW, I use LSTM in A3C, because based on some paper like CVPR 18 [https://arxiv.org/abs/1709.04595](https://arxiv.org/abs/1709.04595) and ICML 18 [https://arxiv.org/abs/1705.10561](https://arxiv.org/abs/1705.10561), LSTM can memorize the history states ,which can improve the A3C. ",10,1
1272,2018-6-22,2018,6,22,19,8t06xa,"Achieving Artificial Intelligence, Not Artificial Security",https://www.reddit.com/r/MachineLearning/comments/8t06xa/achieving_artificial_intelligence_not_artificial/,harry_0_0_7,1529662254,,1,1
1273,2018-6-22,2018,6,22,19,8t08p6,"[N] Achieving Artificial Intelligence, Not Artificial Security",https://www.reddit.com/r/MachineLearning/comments/8t08p6/n_achieving_artificial_intelligence_not/,harry_0_0_7,1529662856,,1,0
1274,2018-6-22,2018,6,22,19,8t0aa5,Cap Sealing Machines Manufacturers,https://www.reddit.com/r/MachineLearning/comments/8t0aa5/cap_sealing_machines_manufacturers/,tradeindia250,1529663392,,1,1
1275,2018-6-22,2018,6,22,19,8t0d4r,Best Machine Learning and Data Science Courses for 2018,https://www.reddit.com/r/MachineLearning/comments/8t0d4r/best_machine_learning_and_data_science_courses/,simplivllc,1529664380,[removed],1,1
1276,2018-6-22,2018,6,22,19,8t0dt6,[D] What are the current approaches to tackling an environment which has a huge discrete action space using deep RL?,https://www.reddit.com/r/MachineLearning/comments/8t0dt6/d_what_are_the_current_approaches_to_tackling_an/,harshitsikchi,1529664617,"[2015]Wolpertinger training method tries to solve this problem by mapping these discrete action spaces to a continuous space. Paper [https://arxiv.org/abs/1512.07679].
Any developments since then? Would Hierarchical Reinforcement learning help in this setting somehow?",2,3
1277,2018-6-22,2018,6,22,20,8t0fzi,Best Machine Learning and Data Science Courses for 2018,https://www.reddit.com/r/MachineLearning/comments/8t0fzi/best_machine_learning_and_data_science_courses/,simplivllc,1529665296,,1,1
1278,2018-6-22,2018,6,22,20,8t0gm6,[D] Yann is back with a teenage girl behavior,https://www.reddit.com/r/MachineLearning/comments/8t0gm6/d_yann_is_back_with_a_teenage_girl_behavior/,SuccessfulBasket,1529665486,,1,0
1279,2018-6-22,2018,6,22,20,8t0l40,[P] Papers with Code - the latest machine learning research (with code!),https://www.reddit.com/r/MachineLearning/comments/8t0l40/p_papers_with_code_the_latest_machine_learning/,rstoj,1529666862,,60,594
1280,2018-6-22,2018,6,22,20,8t0lg3,Estimation of univariate differential entropy,https://www.reddit.com/r/MachineLearning/comments/8t0lg3/estimation_of_univariate_differential_entropy/,BastiatF,1529666966,[removed],1,1
1281,2018-6-22,2018,6,22,20,8t0rmo,[R] Controlled Experiments in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8t0rmo/r_controlled_experiments_in_machine_learning/,dearpetra,1529668761,,0,1
1282,2018-6-22,2018,6,22,21,8t0u1z,Puffed Food Packing Machine | Beef Jerky Packing Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8t0u1z/puffed_food_packing_machine_beef_jerky_packing/,lgsherry,1529669428,,2,1
1283,2018-6-22,2018,6,22,21,8t11ib,[R]Turning Fortnite into PUBG with Deep Learning (CycleGAN),https://www.reddit.com/r/MachineLearning/comments/8t11ib/rturning_fortnite_into_pubg_with_deep_learning/,Yo_You_Not_You_you,1529671466,,17,73
1284,2018-6-22,2018,6,22,22,8t15n4,[R] Mathematical fundamentals of backprob in CNN,https://www.reddit.com/r/MachineLearning/comments/8t15n4/r_mathematical_fundamentals_of_backprob_in_cnn/,canitbechangedlater,1529672536,"Hallo everyone,
as the title says, i am desperately searching for a paper which covers the mathematical fundamentals of backprob (in a DCNN). I worked through [Deep Learning: An Introduction for Applied Mathematicians](https://arxiv.org/abs/1801.05894) and now i would like to build a CNN completely to really get every aspect. So far i got the FCC/perceptron with forward and backprob done. I am stuck on how to apply the backprob for e.g. weights in conv layers. A nice complex paper would be awesome, also pseudocode would be helpful. 

Thank you for your time,
best regards. ",1,0
1285,2018-6-22,2018,6,22,22,8t16n9,[1806.07243v2] Learning Conditioned Graph Structures for Interpretable Visual Question Answering,https://www.reddit.com/r/MachineLearning/comments/8t16n9/180607243v2_learning_conditioned_graph_structures/,willnorc,1529672782,,1,13
1286,2018-6-22,2018,6,22,22,8t17hi,[D] Best of AI: New Articles Published This Month (May 2018),https://www.reddit.com/r/MachineLearning/comments/8t17hi/d_best_of_ai_new_articles_published_this_month/,__yannickw__,1529672977,,0,1
1287,2018-6-22,2018,6,22,22,8t180b,[R] [1711.06006] Hindsight policy gradients (updated),https://www.reddit.com/r/MachineLearning/comments/8t180b/r_171106006_hindsight_policy_gradients_updated/,prauber,1529673093,,0,13
1288,2018-6-22,2018,6,22,22,8t1gwk,[D] Mathematical fundamentals of backprob in CNN,https://www.reddit.com/r/MachineLearning/comments/8t1gwk/d_mathematical_fundamentals_of_backprob_in_cnn/,canitbechangedlater,1529675362,"Hallo everyone,
as the title says, i am desperately searching for a paper which covers the mathematical fundamentals of backprob (in a DCNN). I worked through [Deep Learning: An Introduction for Applied Mathematicians](https://arxiv.org/abs/1801.05894) and now i would like to build a CNN completely to really get every aspect. So far i got the FCC/perceptron with forward and backprob done. I am stuck on how to apply the backprob for e.g. weights in conv layers. If anyone could provide me with a link or a direction to search, that would be cool.

Thank you for your time,
best regards. ",2,0
1289,2018-6-22,2018,6,22,22,8t1hn9,Anyone know of anything to clean up videos / picture files?,https://www.reddit.com/r/MachineLearning/comments/8t1hn9/anyone_know_of_anything_to_clean_up_videos/,KarlJay001,1529675566,"Looking for something that can clean up picture files and/or video files.  I've seen services, but I'm not finding anything I can run myself.",1,1
1290,2018-6-22,2018,6,22,23,8t1otw,Best approach for a ML newbie,https://www.reddit.com/r/MachineLearning/comments/8t1otw/best_approach_for_a_ml_newbie/,nopickles_,1529677219,[removed],1,1
1291,2018-6-23,2018,6,23,0,8t28ou,Starting a new ML blog looking for feedback,https://www.reddit.com/r/MachineLearning/comments/8t28ou/starting_a_new_ml_blog_looking_for_feedback/,shenkev,1529681463,[removed],1,1
1292,2018-6-23,2018,6,23,1,8t2hfw,[D] Parallelized Mutual Information based Feature Selection module.,https://www.reddit.com/r/MachineLearning/comments/8t2hfw/d_parallelized_mutual_information_based_feature/,_alphamaximus_,1529683372,,0,1
1293,2018-6-23,2018,6,23,1,8t2nii,[Project] Alkali: Build intelligent apps and understand data without knowing AI,https://www.reddit.com/r/MachineLearning/comments/8t2nii/project_alkali_build_intelligent_apps_and/,alkaliapp,1529684670,"Hi All,

We're building a new AI platform, Alkali, we're hoping people without much ML experience can use. We've written a medium article introducing Alkali, and figured this would be the an appropriate subreddit to post it on.

[https://medium.com/@alkali.app/introducing-alkali-86ecd02f4762](https://medium.com/@alkali.app/introducing-alkali-86ecd02f4762)

Let us know what you think! Thanks :)",0,0
1294,2018-6-23,2018,6,23,1,8t2q35,[D] Would people without an academic background benefit from reading papers?,https://www.reddit.com/r/MachineLearning/comments/8t2q35/d_would_people_without_an_academic_background/,Chrono803,1529685228,"Since machine learning and AI are hot items being researched these days and more and more people getting into this field, I was curious if it would be beneficial for people who are interested to read and try to keep up with research papers.",5,0
1295,2018-6-23,2018,6,23,1,8t2qlz,Simple explanation of a genetic algorithm,https://www.reddit.com/r/MachineLearning/comments/8t2qlz/simple_explanation_of_a_genetic_algorithm/,GenericRamblings,1529685336,,1,1
1296,2018-6-23,2018,6,23,1,8t2wjq,Announcing Keras-MXNet v2.2 - Model API support and more operators,https://www.reddit.com/r/MachineLearning/comments/8t2wjq/announcing_kerasmxnet_v22_model_api_support_and/,thomelane,1529686620,,1,1
1297,2018-6-23,2018,6,23,1,8t2wve,[N] Announcing Keras-MXNet v2.2 - Model API support and more operators,https://www.reddit.com/r/MachineLearning/comments/8t2wve/n_announcing_kerasmxnet_v22_model_api_support_and/,thomelane,1529686682,,0,11
1298,2018-6-23,2018,6,23,2,8t32fx,[R][Request] Legal issues related to AI,https://www.reddit.com/r/MachineLearning/comments/8t32fx/rrequest_legal_issues_related_to_ai/,PrettyMuchJudgeFudge,1529687838,"Hello everyone,

I am a law student and in couple of months I will start to write my optional mid-studies thesis. I would like to tackle problems in the field of AI from legal point of view, however I am suffering from general lack of thesis.

I am mostly looking for problems related to intellectual property, if not then secondly related to legal responsibility of AI (but no self-driving cars, it has been beaten to death already) and lastly about application of AI in judicial proceedings.

However I am opened to any suggestions you might have (facial recognition, ethical problems...). Anything that you feel that this field faces or might face in near future from legal point of view. Did you already ran into some related problems?

Feel free to make it as technical as possible, for what it's worth (honestly not much) since I am interested in this ""intersection"" I am familiar with some of the underlying concepts, can code in python and took several AP courses in maths and stats, so bring it on bois.

Thank you in advance for any suggestions or tips you might have for me, it would really help my studies.



Edit: I don't want to end up on /r/choosingbeggars but preferably it should be something ""new"" (hence the slefdriving cars) and preferably some really specific problems that I could form my thesis around. But of course any insight will be appreciated. And yes, you will get credit in the thesis.
",13,6
1299,2018-6-23,2018,6,23,2,8t37h3,"Deep learning: hey, where's my car?",https://www.reddit.com/r/MachineLearning/comments/8t37h3/deep_learning_hey_wheres_my_car/,cptAwesome_070,1529688913,,1,1
1300,2018-6-23,2018,6,23,2,8t3alc,"Anyone how to do Tfidf vectorizing, normalization and PCA on very large data sets (1.8 mm x 50k) without running into a memory error?",https://www.reddit.com/r/MachineLearning/comments/8t3alc/anyone_how_to_do_tfidf_vectorizing_normalization/,cam_man_can,1529689549,[removed],1,1
1301,2018-6-23,2018,6,23,3,8t3ftn,What are some recent machine learning success stories?,https://www.reddit.com/r/MachineLearning/comments/8t3ftn/what_are_some_recent_machine_learning_success/,amit2rockon,1529690645,[removed],1,1
1302,2018-6-23,2018,6,23,4,8t46fa,[D] What resources exist for building ones own server for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8t46fa/d_what_resources_exist_for_building_ones_own/,1vs,1529696372,"There are a number of resources for building a personal computer, usually for gaming. These are sites such as PC Parts Picker.

I'm sure many people here can relate to my situation:

&gt; I'm familiar with the purpose of each of the different parts of a personal computer, and I understand the advantages of a good Nvidia graphics card for ML. I have a good feeling for how CPU power, RAM, GPU power, etc. should scale (such that nothing bottlenecks one another). I am comfortable in building personal computers.
&gt; 
&gt; But I have no experience building a server, let alone one for machine learning, and yet I'm in a position where I need to build one.

To those who have built a server, what resources did you use? What advice do you have for others?",15,3
1303,2018-6-23,2018,6,23,5,8t4dlk,[Jobs board] If you hire talent or look for AI jobs: https://nutech.io/,https://www.reddit.com/r/MachineLearning/comments/8t4dlk/jobs_board_if_you_hire_talent_or_look_for_ai_jobs/,diolor,1529697970,,1,1
1304,2018-6-23,2018,6,23,5,8t4g35,[R] Fashion-Gen: The Generative Fashion Dataset and Challenge,https://www.reddit.com/r/MachineLearning/comments/8t4g35/r_fashiongen_the_generative_fashion_dataset_and/,baylearn,1529698526,,0,12
1305,2018-6-23,2018,6,23,5,8t4gum,Short clip of a discussion on ML in a podcast called Data Futurology https://www.datafuturology.com/podcast/1,https://www.reddit.com/r/MachineLearning/comments/8t4gum/short_clip_of_a_discussion_on_ml_in_a_podcast/,datafuturology,1529698690,,1,1
1306,2018-6-23,2018,6,23,6,8t4urk,Augmented Network Self Supervision,https://www.reddit.com/r/MachineLearning/comments/8t4urk/augmented_network_self_supervision/,618smartguy,1529701839,[removed],1,1
1307,2018-6-23,2018,6,23,6,8t4xlw,[Discussion] Augmented Network Self Supervision,https://www.reddit.com/r/MachineLearning/comments/8t4xlw/discussion_augmented_network_self_supervision/,618smartguy,1529702485,"ANSS for  short, this is the term I have been using to describe combining a NN  with some other algorithm, such as MCTS in the case of AlphaZero, in  order to enhance the performance of the net which in turn provides more  training data. It feels very much like the system is lifting itself up  by its bootstraps. Does anyone have any thoughts on this process, or  know of any research other than AlphaZero which uses this strategy?

Thanks!",2,8
1308,2018-6-23,2018,6,23,6,8t4z52,"[D] Should I develop object recognition, use an existing API or use a mix of several existing API ?",https://www.reddit.com/r/MachineLearning/comments/8t4z52/d_should_i_develop_object_recognition_use_an/,TrueMany,1529702848,"I'm beginning machine learning with the operational objective to be able to identify and classify 20+ objects categories in a 20' to 30' video (mainly consumer goods). 

I'm looking for advice regarding if I should build everything from scratch (tough challenge), choose one especially (and opinions differs regarding which one to choose), or what appears to be potential the best deal, use a mix of the top 3 object recognition to get the highest accuracy and precision.

Appreciate any help.",6,1
1309,2018-6-23,2018,6,23,6,8t51gt,Tool for predicting persuasive text?,https://www.reddit.com/r/MachineLearning/comments/8t51gt/tool_for_predicting_persuasive_text/,GrabAHamLincoln,1529703390,[removed],1,1
1310,2018-6-23,2018,6,23,7,8t5goz,[D] What makes a great data scientist? What skills are required? How to become a data science leader? Podcast discussion,https://www.reddit.com/r/MachineLearning/comments/8t5goz/d_what_makes_a_great_data_scientist_what_skills/,datafuturology,1529707093,"""Sharply insightful discussion b/n [**Eugene Dubossarsky**](https://www.linkedin.com/in/eugene-dubossarsky-09208a1/) &amp; [**Felipe Flores**](https://www.linkedin.com/in/felipefloresanalytics/) on Data Futurology regarding pressing existential topics in [**#datascience**](https://www.linkedin.com/feed/topic/?keywords=%23datascience) &amp; [**#machinelearning**](https://www.linkedin.com/feed/topic/?keywords=%23machinelearning). Worth a listen, especially for those who are either considering data science as a profession or hiring data scientists for the 1st time.   Eugene says things that will make many stakeholders in the DS community uncomfortable or defensive (myself included):  

\- The lack of depth many data scientists display 

\- The problem with IT owning DS 

\- The lack of understanding of DS from mgt teams 

\- The lack of rigor (e.g. most ppl see no diff b/n prediction &amp; causation) 

\- DS by &amp; large is not necessary for most orgs.  

In other words, things that need to be said."" Daniel, Listener Review

Listen to the full interview on [https://www.datafuturology.com/podcast/1](https://www.datafuturology.com/podcast/1)

[**Apple Podcasts**](https://itunes.apple.com/us/podcast/data-futurology/id1385051346?mt=2) **//** [**Google Podcasts**](https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zZmFiMDYwL3BvZGNhc3QvcnNz) **//** [**Android**](https://subscribeonandroid.com/anchor.fm/s/3fab060/podcast/rss) **//** [**Anchor**](https://anchor.fm/datafuturology) **//** [**Breaker**](https://www.breaker.audio/data-futurology) **//** [**Castbox**](https://castbox.fm/channel/id1287121) **//**[**Overcast**](https://overcast.fm/itunes1385051346/data-futurology) **//** [**Pocket Casts**](https://pca.st/lloi) **//**[**PodBean**](https://www.podbean.com/podcast-detail/zifvj-6c219/Data-Futurology-Podcast) **//** [**RadioPublic**](https://play.radiopublic.com/data-futurology-WDRrnA) **//** [**RSS Link**](https://anchor.fm/s/3fab060/podcast/rss)

Thank you so much, and enjoy the show!

[**LinkedIn**](https://www.linkedin.com/in/felipefloresanalytics/) **//** [**Twitter**](https://twitter.com/datafuturology) **//** [**Facebook**](https://www.facebook.com/datafuturology/) **//** [**Instagram**](https://www.instagram.com/datafuturology/?hl=en) **//** [**Official Site**](https://www.datafuturology.com/)",0,2
1311,2018-6-23,2018,6,23,8,8t5sw0,[R] Machine Learning and Radiogenomics: Lessons Learned and Future Directions,https://www.reddit.com/r/MachineLearning/comments/8t5sw0/r_machine_learning_and_radiogenomics_lessons/,john_kang,1529710149,"Hello, I am a physician scientist in radiation oncology and am the lead author on a review of machine learning applied to radiogenomics (predicting the response of tumor or normal tissue using genomic predictors) that I think is a appropriate mix of discussion about theory applied to practice.

While I know genomics is probably not everyone's specific area of interest, I did write a couple of sections that help explain some background on machine learning and how it differs from statistics (Section II), with heavy references to concepts Leo Breiman's ""Two Cultures"" paper from 2001. There is also discussion about common errors in both classical statistics and machine learning. Section I introduces radiogenomics. Section III has discussions about how ML can be applied to genomics and how to handle some challenges. Section IV discusses common ML models used in radiogenomics. Section V discusses how to improve ML in radiogenomics.

If you read any or all of it, let me know what you think!

[https://www.frontiersin.org/articles/10.3389/fonc.2018.00228/full](https://www.frontiersin.org/articles/10.3389/fonc.2018.00228/full)",2,13
1312,2018-6-23,2018,6,23,8,8t5xvv,[R] Meta Learning by the Baldwin Effect (DeepMind),https://www.reddit.com/r/MachineLearning/comments/8t5xvv/r_meta_learning_by_the_baldwin_effect_deepmind/,baylearn,1529711517,,1,4
1313,2018-6-23,2018,6,23,9,8t64i2,Getting started,https://www.reddit.com/r/MachineLearning/comments/8t64i2/getting_started/,MustavoA,1529713193,[removed],1,1
1314,2018-6-23,2018,6,23,9,8t67s7,Open AI Retro Contest Results,https://www.reddit.com/r/MachineLearning/comments/8t67s7/open_ai_retro_contest_results/,cosminro,1529714097,,1,1
1315,2018-6-23,2018,6,23,9,8t6852,[D] Open AI Retro Contest Results,https://www.reddit.com/r/MachineLearning/comments/8t6852/d_open_ai_retro_contest_results/,cosminro,1529714194,,0,1
1316,2018-6-23,2018,6,23,9,8t68h7,OpenAI retro contest results,https://www.reddit.com/r/MachineLearning/comments/8t68h7/openai_retro_contest_results/,cosminro,1529714295,,1,1
1317,2018-6-23,2018,6,23,9,8t68nf,[D] OpenAI retro contest results,https://www.reddit.com/r/MachineLearning/comments/8t68nf/d_openai_retro_contest_results/,cosminro,1529714347,,1,62
1318,2018-6-23,2018,6,23,10,8t6gtw,Is there any other deep-learning USB stick other than Movidius?,https://www.reddit.com/r/MachineLearning/comments/8t6gtw/is_there_any_other_deeplearning_usb_stick_other/,ekubya,1529716594,[removed],1,1
1319,2018-6-23,2018,6,23,10,8t6k7z,Looking for deep-learning USB stick other than Movidius?,https://www.reddit.com/r/MachineLearning/comments/8t6k7z/looking_for_deeplearning_usb_stick_other_than/,ekubya,1529717539,[removed],1,1
1320,2018-6-23,2018,6,23,10,8t6n65,[D] Properties of Weights in Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/8t6n65/d_properties_of_weights_in_neural_networks/,Nater5000,1529718370,"I've been looking at the weights for a neural net I built using numpy and scipy, and I noticed they're all very small in magnitude.  The model is pretty accurate, so I'm guessing the weights are fine, but it got me thinking about the kinds of ranges weights for a trained model might end up in.  

Do they typically follow some sort of distribution?  Or do different types of nets and architectures result in different properties for their weights?  And how do the properties of the weights in a neural net differ if it were trained on different weight initializations? 

I'm trying to test some of these questions out and look at pre-trained models, but I wasn't sure how much research or information is available on the subject",9,13
1321,2018-6-23,2018,6,23,12,8t7435,[D] New approximate nearest neighbor benchmarks from Erik Bernhardsson,https://www.reddit.com/r/MachineLearning/comments/8t7435/d_new_approximate_nearest_neighbor_benchmarks/,lmcinnes,1529723305,,7,52
1322,2018-6-23,2018,6,23,12,8t76ko,My ct st COS2100 Cng sut nh mc: 2100W ng knh dao:  355mm kch thc ct hnh ch nht: 110X130mm Kch thc ct rn: 58mm Kch thc ct rng: 110mm Tc  khng ti: 3900r / pht,https://www.reddit.com/r/MachineLearning/comments/8t76ko/my_ct_st_cos2100_cng_sut_nh_mc_2100w/,HangNguyen1111,1529724065,,1,1
1323,2018-6-23,2018,6,23,12,8t7dtl,"My ct st, dui st GT5-12",https://www.reddit.com/r/MachineLearning/comments/8t7dtl/my_ct_st_dui_st_gt512/,HangNguyen1111,1529726314,,1,1
1324,2018-6-23,2018,6,23,13,8t7g58,"My hn ming ti PFS-400 s dng cng sut 600W, hn nhanh mp hn c  di 400mm trong thi gian t 0.2 - 0.5s",https://www.reddit.com/r/MachineLearning/comments/8t7g58/my_hn_ming_ti_pfs400_s_dng_cng_sut_600w/,HangNguyen1111,1529727015,,1,1
1325,2018-6-23,2018,6,23,13,8t7or8,[P] Writing Kanji with a neural network,https://www.reddit.com/r/MachineLearning/comments/8t7or8/p_writing_kanji_with_a_neural_network/,pabloesm,1529729755,,17,142
1326,2018-6-23,2018,6,23,15,8t7zs5,Questions about resnet's layer response,https://www.reddit.com/r/MachineLearning/comments/8t7zs5/questions_about_resnets_layer_response/,372995411,1529733696,[removed],1,1
1327,2018-6-23,2018,6,23,15,8t86hf,[D] Is it necessary for a beginner to learn the mathematics and theory behind classical machine learning algorithms (svm for example) before learning theory for deep learning?,https://www.reddit.com/r/MachineLearning/comments/8t86hf/d_is_it_necessary_for_a_beginner_to_learn_the/,ImaginaryGas,1529736243,"I'm a CS student/programmer who specializes in GPU parallel programming. I want to study deep learning on a theoretical level because I think it goes well with my skillset, but I'm not sure if its a good idea to start with deep learning, or to go back to the basics (svms, naive bayes, etc). I covered these topics in a basic machine learning course a long time ago, but don't remember the theory and math very clearly. Is it necessary for me to go back and relearn the basic algorithms in detail, or can I just jump right into deep learning?",2,3
1328,2018-6-23,2018,6,23,18,8t8r1u,[D] RMSProp/Adagrad vs. L_1 regularization/rare features,https://www.reddit.com/r/MachineLearning/comments/8t8r1u/d_rmspropadagrad_vs_l_1_regularizationrare/,thenomadicmonad,1529744590,"Hi, I was refreshing on SGD extensions and wondered the following: RMSProp/Adagrad work by increasing the learning rate for sparse parameters/parameters with small gradients. However, would models not want to incorporate some 'rule based/exception' learning, in the sense that in the case of rare examples occurring, some set of neurons encoding that occurrence become active, and thence feeds into classification/prediction etc. One way of encoding this through a deep network would seem to be using some L_1 regularization for one subset of nodes (encouraging sparse activation) and L_2 regularization for others (encouraging some 'generalist' neurons for common behaviour) Yet, it seems to me that RMSProp/Adagrad would tend to destroy this 'contextual/sparse' activation by increasing the learning for sparse nodes, and hence forcing them to act in solving the general loss minimization instead of performing a specialized function. Is this an actual issue, and could one perhaps choose to use RMSProp/Adagrad with a subset of 'L_2 regularized neurons', while having another subset which uses a different gradient optimization along with L_1? Apologies for the noobie question, and looking forward to your replies! ",0,6
1329,2018-6-23,2018,6,23,18,8t8sm8,"applied statistics to machine learning, career advice please!",https://www.reddit.com/r/MachineLearning/comments/8t8sm8/applied_statistics_to_machine_learning_career/,newbornlife,1529745242,[removed],1,1
1330,2018-6-23,2018,6,23,18,8t8tic,AutoRec: One network for each training sample.  r/recommenders,https://www.reddit.com/r/MachineLearning/comments/8t8tic/autorec_one_network_for_each_training_sample/,utxeee,1529745620,,1,1
1331,2018-6-23,2018,6,23,18,8t8u1d,What Makes Naive Bayes Classification So Naive? | How Does Naive Bayes Classifier Work,https://www.reddit.com/r/MachineLearning/comments/8t8u1d/what_makes_naive_bayes_classification_so_naive/,LearningFromData,1529745862,,1,1
1332,2018-6-23,2018,6,23,18,8t8uxo,[D] AutoRec: One network for each training sample.  r/recommenders,https://www.reddit.com/r/MachineLearning/comments/8t8uxo/d_autorec_one_network_for_each_training_sample/,utxeee,1529746266,,0,11
1333,2018-6-23,2018,6,23,18,8t8xod,Peanut Bar Making Machine|Sesame Brittle Production Line For Sale,https://www.reddit.com/r/MachineLearning/comments/8t8xod/peanut_bar_making_machinesesame_brittle/,Machineprices,1529747449,"Peanut bar production line for sale: [http://www.gelgoogm.com/product/peanut-candy/peanut-bar-machine.html](http://www.gelgoogm.com/product/peanut-candy/peanut-bar-machine.html)

Get Price: Email|Skype: [cara@machinehall.com](mailto:cara@machinehall.com)  Whatsapp|Wechat|Phone: 008613015518550",2,1
1334,2018-6-23,2018,6,23,19,8t91af,http://www.machineprices.com/peeling-machine/dry-peanut-peeling-machine.html,https://www.reddit.com/r/MachineLearning/comments/8t91af/httpwwwmachinepricescompeelingmachinedrypeanutpeel/,Machineprices,1529748876,[removed],1,1
1335,2018-6-23,2018,6,23,20,8t9c36,15 Days to Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8t9c36/15_days_to_tensorflow/,tensor_assassin,1529753276,[removed],1,1
1336,2018-6-23,2018,6,23,20,8t9ea9,Tesnorflow code along,https://www.reddit.com/r/MachineLearning/comments/8t9ea9/tesnorflow_code_along/,tensor_assassin,1529754104,[removed],1,1
1337,2018-6-23,2018,6,23,21,8t9jyy,Some Simple Models of Neurons,https://www.reddit.com/r/MachineLearning/comments/8t9jyy/some_simple_models_of_neurons/,akshat_ng,1529756116,,1,1
1338,2018-6-23,2018,6,23,21,8t9mve,[D] Emergence of Locomotion Behaviours in Rich Environments,https://www.reddit.com/r/MachineLearning/comments/8t9mve/d_emergence_of_locomotion_behaviours_in_rich/,Mee5aeree4,1529757139,,0,3
1339,2018-6-23,2018,6,23,21,8t9p5n,[R] Finding learning paradigm that might help me in my research,https://www.reddit.com/r/MachineLearning/comments/8t9p5n/r_finding_learning_paradigm_that_might_help_me_in/,hydrodynamical_flow,1529757900,"So I have a computer vision dataset in a natural science domain (astrophysics), where I have two superclasses - objects of our interest (signal) and anything else (background). I can produce myriads of ground-truth labeled training examples for those two superclasses. But ultimately in order to get valuable physics knowledge, I need to divide my signal class into subclasses and here comes the problem. The only way to make training data for those two classes is via numerical simulations, but those insert a lot of noise into the model, for example, coming from inner workings of the model e.t.c.

The de-facto way how it is done now is that we take few models, simulate signals for subclasses and train our models directly on those data. But the question that always has bothered me is - can we use our knowledge of superclass signal vs background data to which we can assign ground-truth label in combination with simulated data? We have petabytes of those, generated by nature itself. 

What would be the learning paradigm that utilises those ideas called? Can you please provide some references for those? 

Thanks!",2,0
1340,2018-6-23,2018,6,23,22,8t9xm0,ANN: Matlab vs Python - Which one is best suited for beginners?,https://www.reddit.com/r/MachineLearning/comments/8t9xm0/ann_matlab_vs_python_which_one_is_best_suited_for/,kafka-esque24,1529760604,[removed],1,1
1341,2018-6-23,2018,6,23,22,8t9yb7,Can ML Help me?,https://www.reddit.com/r/MachineLearning/comments/8t9yb7/can_ml_help_me/,skye_9,1529760813,[removed],1,1
1342,2018-6-23,2018,6,23,22,8ta2ao,Is there a way to know the most accurate/fastest Machine learning model for a particular class of problem?,https://www.reddit.com/r/MachineLearning/comments/8ta2ao/is_there_a_way_to_know_the_most_accuratefastest/,simplan,1529761989,[removed],1,1
1343,2018-6-23,2018,6,23,23,8tad98,[D] By how much does beam search diminish the perplexity of a model?,https://www.reddit.com/r/MachineLearning/comments/8tad98/d_by_how_much_does_beam_search_diminish_the/,HigherTopoi,1529764978,"Let us define the perplexity of generated sequences to be the natural logarithm of cross-entropy between the test dataset and the generated sequences. This quantity is not equal to the perplexity of the language model, which uses its predictions instead of the generated sequences (they are slightly different). The former is probably smaller, but I'm not sure about how much the difference would be. If we know the amount of difference, then we can conclude the reduction of perplexity due to beam search. Unfortunately, calculating the former perplexity is intractable, so is there any way to approximate the difference between the former and the latter? One naive approach is to train a LM on generated sequences, but I doubt the result's numerical accuracy. Any thought?

For example, I have an autoencoder with discrete latent variable (of length slightly shorter than the input texts) that models the test dataset with log-ppl being 0.3. Then, on average the model assigns e^(-0.3) = 75% to the correct next token on test dataset. Doesn't this mean that beam search (or even greedy decoding) would bring the likelihood to nearly 100% (i.e. the net perplexity being 0), since the probability mass in this case is pretty much concentrated on the correct next tokens? Is such a drastic improvement in terms of perplexity limited to models with log-ppl near 0?

[1] Analyzing Uncertainty in Neural Machine Translation by Ott et. al.",0,8
1344,2018-6-23,2018,6,23,23,8tadts,M4 forecasting competition won by hybrid RNN and stats model,https://www.reddit.com/r/MachineLearning/comments/8tadts/m4_forecasting_competition_won_by_hybrid_rnn_and/,furiousnerd,1529765115,[removed],1,1
1345,2018-6-23,2018,6,23,23,8taf1n,Kaggle Debut with Java - DL4J Learning Curve,https://www.reddit.com/r/MachineLearning/comments/8taf1n/kaggle_debut_with_java_dl4j_learning_curve/,EndyJBC,1529765449,[removed],1,1
1346,2018-6-24,2018,6,24,0,8tahaj,[P] Kaggle Debut with Java - DL4J Learning Curve,https://www.reddit.com/r/MachineLearning/comments/8tahaj/p_kaggle_debut_with_java_dl4j_learning_curve/,EndyJBC,1529766053,"Just joined this [kaggle competition](https://www.kaggle.com/c/santander-value-prediction-challenge) so as to learn and work with a real world puzzle. Unlike fast prototyping using Python, I'm using Java here and worked on bit and pieces of data pre-processing so far. My purpose here is to learn and make it good shape using Java rather than winning. Going through kernels posted there at Kaggle &amp; here is my DL4J code if anyone interested to see: [SantanderValuePrediction](https://github.com/rahul-raj/Deeplearning4J/blob/master/src/main/java/SantanderValuePrediction.java)  
Appreciate if anyone could share their insights on the problem statement or if you have DL4J knowledgebase. ",7,9
1347,2018-6-24,2018,6,24,0,8tajvh,[D] Hybrid RNN model wins m4 forecasting competition,https://www.reddit.com/r/MachineLearning/comments/8tajvh/d_hybrid_rnn_model_wins_m4_forecasting_competition/,furiousnerd,1529766707,"Saw this in [r/statistics](https://www.reddit.com/r/statistics) and thought it was pretty interesting. M4 is a pretty well regarded time series forecasting competition that has previously been very stats oriented. The github for the models is here:[https://github.com/M4Competition/M4-methods](https://github.com/M4Competition/M4-methods)  
I have taken [u/true\_believer](https://www.reddit.com/user/true_believer) 's post below:

[https://www.m4.unic.ac.cy/the-m-competitions-and-their-far-reaching-contributions-to-the-theory-and-practice-of-forecasting/](https://www.m4.unic.ac.cy/the-m-competitions-and-their-far-reaching-contributions-to-the-theory-and-practice-of-forecasting/)

* The  combination of methods was the king of the M4. Of the 17 most accurate  methods, 12 were combinations of mostly statistical approaches.
* The  biggest surprise was a hybrid approach that utilised both statistical  and ML features. This method produced both the most accurate forecasts  and the most precise PIs, and was submitted by Slawek Smyl, a Data  Scientist at Uber Technologies. According to sMAPE, it was close to 10&amp;#37;  more accurate than the combination benchmark.
* The  second most accurate method was a combination of seven statistical  methods and an ML one, with the weights for the averaging calculated by  an ML algorithm that was trained to minimise the forecasting error  through holdout tests. This method was submitted jointly by Spains  University of A Corua and Australias Monash University.
* The  most accurate and second most accurate methods also achieved an amazing  success in specifying the 95&amp;#37; PIs correctly. These are the first  methods we are aware of that have done so, rather than underestimating  the uncertainty considerably.
* The  six pure ML methods that were submitted in the M4 all performed poorly,  with none of them being more accurate than Comb and only one being more  accurate than Nave2. This supports the findings of the latest PLOS ONE  paper by Makridakis, Spiliotis and Assimakopoulos.

Edit: A paper with preliminary results is now available at [https://www.sciencedirect.com/science/article/pii/S0169207018300785](https://www.sciencedirect.com/science/article/pii/S0169207018300785)",23,199
1348,2018-6-24,2018,6,24,0,8tandy,Multi-threaded learning control mechanism for neural networks,https://www.reddit.com/r/MachineLearning/comments/8tandy/multithreaded_learning_control_mechanism_for/,damarobe,1529767604,,1,1
1349,2018-6-24,2018,6,24,0,8tat1y,Linear Regression in Python,https://www.reddit.com/r/MachineLearning/comments/8tat1y/linear_regression_in_python/,sevtschook,1529769049,[removed],1,1
1350,2018-6-24,2018,6,24,1,8tavik,Why Russian to English is difficult for Machine Translation,https://www.reddit.com/r/MachineLearning/comments/8tavik/why_russian_to_english_is_difficult_for_machine/,kiarash-irandoust,1529769619,,1,1
1351,2018-6-24,2018,6,24,1,8tb231,Internship in ML,https://www.reddit.com/r/MachineLearning/comments/8tb231/internship_in_ml/,bkl_mkl,1529771195,[removed],1,1
1352,2018-6-24,2018,6,24,2,8tbdmh,[D] Handwriting OCR?,https://www.reddit.com/r/MachineLearning/comments/8tbdmh/d_handwriting_ocr/,firedragonxx9832,1529773974,"I'm wondering whether anybody knows of research done in handwriting recognition? I've seen some good work being done for OCR (street signs, storefronts ... etc.) but I'm struggling to find work done on handwriting recognition. 

I also haven't been able to find handwriting datasets of sufficient size/quality. However, surely this must exist for deep learning based OCR? ",16,4
1353,2018-6-24,2018,6,24,2,8tbe90,Tensorflow Eager Execution Mode - for python-like debugging (Video &amp; Git),https://www.reddit.com/r/MachineLearning/comments/8tbe90/tensorflow_eager_execution_mode_for_pythonlike/,AI-in-SpaceTech,1529774119,[removed],1,1
1354,2018-6-24,2018,6,24,2,8tbhig,[P] Tensorflow Eager Execution Mode - for python-like debugging (Video &amp; Git),https://www.reddit.com/r/MachineLearning/comments/8tbhig/p_tensorflow_eager_execution_mode_for_pythonlike/,AI-in-SpaceTech,1529774919,"Hello guys,

I  made a simple git tutorial (with video explanation) for easy debugging in Tensorflow, using 'Eager Execution Mode"".

If you want check it out here:

[https://www.youtube.com/watch?v=8\_LOEknpOtI](https://www.youtube.com/watch?v=8_LOEknpOtI)",1,9
1355,2018-6-24,2018,6,24,2,8tbnrl,My download's in Mac opens as a Code,https://www.reddit.com/r/MachineLearning/comments/8tbnrl/my_downloads_in_mac_opens_as_a_code/,zipbzop,1529776402,,1,1
1356,2018-6-24,2018,6,24,4,8tc6px,Data normalization,https://www.reddit.com/r/MachineLearning/comments/8tc6px/data_normalization/,soum16,1529781015,[removed],1,1
1357,2018-6-24,2018,6,24,4,8tc9ol,[Discussion] Feature scaling,https://www.reddit.com/r/MachineLearning/comments/8tc9ol/discussion_feature_scaling/,soum16,1529781771,"I have data coming from n different sources, where each source generates m data samples. The range of feature values coming from two different sources can be different. However, I would be performing training on the entire dataset. How is data preprocessed or how are features scaled in such cases? ",13,6
1358,2018-6-24,2018,6,24,4,8tchzx,Updating a Decision Tree With New Data,https://www.reddit.com/r/MachineLearning/comments/8tchzx/updating_a_decision_tree_with_new_data/,SirMyself,1529783898,[removed],1,1
1359,2018-6-24,2018,6,24,5,8tcmgi,I recently built (from scratch) my first successful Neural Network! It can successfully classify MNIST with ~96% accuracy.,https://www.reddit.com/r/MachineLearning/comments/8tcmgi/i_recently_built_from_scratch_my_first_successful/,award28,1529784978,,1,1
1360,2018-6-24,2018,6,24,5,8tcqli,Tensorflow estimator API Tutorial,https://www.reddit.com/r/MachineLearning/comments/8tcqli/tensorflow_estimator_api_tutorial/,tensor_assassin,1529786016,,1,1
1361,2018-6-24,2018,6,24,5,8tcv6t,[Project] I recently built (from scratch) my first successful Neural Network! It can successfully classify MNIST with ~96% accuracy.,https://www.reddit.com/r/MachineLearning/comments/8tcv6t/project_i_recently_built_from_scratch_my_first/,award28,1529787199,,1,1
1362,2018-6-24,2018,6,24,6,8td23c,[Advice] Deploying Machine Learning Models w Python and Flask,https://www.reddit.com/r/MachineLearning/comments/8td23c/advice_deploying_machine_learning_models_w_python/,CircuitBeast,1529788985,[removed],1,1
1363,2018-6-24,2018,6,24,6,8td396,I want to work in DS/ML without a graduate degree. How tough is the road ahead?,https://www.reddit.com/r/MachineLearning/comments/8td396/i_want_to_work_in_dsml_without_a_graduate_degree/,wordboyhere,1529789296,[removed],1,1
1364,2018-6-24,2018,6,24,6,8td6ai,[D] I want to work in DS/ML without a graduate degree. How tough is the road ahead?,https://www.reddit.com/r/MachineLearning/comments/8td6ai/d_i_want_to_work_in_dsml_without_a_graduate/,wordboyhere,1529790089,"I will be graduating with a B.S. in applied math/statistics next Spring. I'm doing a data analytics internship right now, using R/Python and am learning about NLP/LDA. I will take a machine learning course in the fall, and I have worked with SQL and Hadoop.

It seems like 75% of Data Science/Machine Learning job postings ask for or ""prefer"" a masters or PhD. However I believe I'll have many of the skills they are looking for. I've definitely worked with messy data, and I have taken classes on (and applied) Bayesian statistics, time series, etc. 

Is the MS/PhD credential a hard deal-breaker, or can I get someone to look at me without throwing away my resume?

My reason for not wanting to go to grad school: Depression, Anxiety, Stress, not being paid. ",15,7
1365,2018-6-24,2018,6,24,7,8tddaa,[D] What are the most underrated/unknown great resources in Machine Learning ?,https://www.reddit.com/r/MachineLearning/comments/8tddaa/d_what_are_the_most_underratedunknown_great/,BatmantoshReturns,1529791940,I think openreview.net is a very useful website where people can discuss a paper and interact with the author as well. ,26,20
1366,2018-6-24,2018,6,24,7,8tdgps,Need help Regarding Machine Learning Projects ideas,https://www.reddit.com/r/MachineLearning/comments/8tdgps/need_help_regarding_machine_learning_projects/,Abhi_puri98,1529792881,[removed],1,1
1367,2018-6-24,2018,6,24,9,8te48a,Machine learning project walkthroughs,https://www.reddit.com/r/MachineLearning/comments/8te48a/machine_learning_project_walkthroughs/,deepfiz,1529799579,[removed],1,1
1368,2018-6-24,2018,6,24,9,8te9rq,I am stuck on the part where you calculate the derivative of cost in respect to the target.,https://www.reddit.com/r/MachineLearning/comments/8te9rq/i_am_stuck_on_the_part_where_you_calculate_the/,ElonMuskIsAnAlien,1529801218,[removed],1,1
1369,2018-6-24,2018,6,24,10,8telai,[Discussion] Is there a consensus about 'Best Practices' for enterprise data architectures that facilitate machine learning and predictive analytics?,https://www.reddit.com/r/MachineLearning/comments/8telai/discussion_is_there_a_consensus_about_best/,Pop_Culture_Suicide,1529804738,"I'm not sure if this is a good discussion topic for the sub, but I searched for related posts here about my question and nothing popped out.  So I thought I'd throw this out there and see what happens.

Is there a consensus as to 'Best Practices' or general considerations one should make when thinking about how to use machine learning for predictive analytics and enterprise level decision support?  

I'm not necessarily referring to (but maybe) ad-hoc data scientist requests like:  go find some data, wrangle a dataset, train a model, and classify a prediction.  Often times, that sort of data doesn't persist (yes, I am making gross generalizations here).

What I'm wondering about is how an organization could approach its data architecture to make semantic connections across the various business entities and critical knowledge assets, avoid data integration problems, and exploit those assets to machine learning for various decision support activities.  

Is SOA-related data architectures the best practice here?  Maybe the Data Mart (master data management), or data lake approach?  What does this community think about graph databases for enterprise level analytics??  

Thanks!!",9,8
1370,2018-6-24,2018,6,24,11,8tev20,Ultra-low bit-rate audio for tiny podcasts with Codec2 and WaveNet decoders (1 hour = 1MB),https://www.reddit.com/r/MachineLearning/comments/8tev20/ultralow_bitrate_audio_for_tiny_podcasts_with/,gwern,1529807752,,2,1
1371,2018-6-24,2018,6,24,12,8tf8k8,[R] There Is No Free Lunch In Adversarial Robustness (But There Are Unexpected Benefits),https://www.reddit.com/r/MachineLearning/comments/8tf8k8/r_there_is_no_free_lunch_in_adversarial/,angry-zergling,1529811902,,5,14
1372,2018-6-24,2018,6,24,14,8tfn7c,Image preprocessing in R for classification,https://www.reddit.com/r/MachineLearning/comments/8tfn7c/image_preprocessing_in_r_for_classification/,Tahmid-,1529816484,[removed],1,1
1373,2018-6-24,2018,6,24,18,8tgpyc,[D] Advice on ML Engineering roles in SF,https://www.reddit.com/r/MachineLearning/comments/8tgpyc/d_advice_on_ml_engineering_roles_in_sf/,themathstudent,1529832006,"Hi all,

I just found out that I got rejected from a ML role with one of the big ML companies. I got rejected at the coding interview stage, without getting to the point where they ask me any ML related questions. I know this is bit of a whinge but I studied pretty hard for the past 6 months, spending money on training courses (leetcode + udemy), taking time off to study and doing my best to balance study and life. So its a little heartbreaking to know that a 40 minute coding test just stopped you from going further.

Anyway, the reason I'm quite adamant about being at a large company is that I really want a mentor in DL. I did do my PhD (in Bayesian ML) and worked in the data science space but I feel like there's still large gaps in my knowledge. The two areas I want to learn more about is DL in distributed settings (eg. with kubernetes) and reinforcement learning. The latter at least udacity seems to have a good course on it.

I know I only applied to one company, and I should apply for more. But thought I'd get people's input before going further. So here are my questions:

1. I know the coding interview is pretty standard, but are there well known ML companies that have something else instead? eg. A take home task, or questions on ML straightaway without the coding interview?

2. Have I got the wrong mindset only applying for big software companies (google, fb etc.?) Is it worth applying for startups in SF? I know there's a demand but will I meet a suitable mentor. Then there's the question of working hours and (low) salary when it comes to startups.

3. Do recruiters have a tougher standard for people living overseas considering its more expensive to hire them? Thinking mostly about relocation fees + sponsorship. &lt;- This might be more of a question for recruiters than this forum.",5,2
1374,2018-6-24,2018,6,24,19,8tgw0g,Detecting logos in images using ORB and MinHashing (OpenCV),https://www.reddit.com/r/MachineLearning/comments/8tgw0g/detecting_logos_in_images_using_orb_and/,sharmakushal2017,1529834765,,1,1
1375,2018-6-24,2018,6,24,19,8tgyg2,[P] Detecting logs in images using ORB and Bundle Min Hashing (OpenCV),https://www.reddit.com/r/MachineLearning/comments/8tgyg2/p_detecting_logs_in_images_using_orb_and_bundle/,sharmakushal2017,1529835822,,4,0
1376,2018-6-24,2018,6,24,19,8th3bl,Studying Machine Learning for electrical engineering(Power).,https://www.reddit.com/r/MachineLearning/comments/8th3bl/studying_machine_learning_for_electrical/,t_rex66,1529837976,[removed],1,1
1377,2018-6-24,2018,6,24,20,8th3rd,[P] MobileNet Image Classification with Keras - Video series,https://www.reddit.com/r/MachineLearning/comments/8th3rd/p_mobilenet_image_classification_with_keras_video/,blackHoleDetector,1529838151,"In this series, we learn about MobileNets, a class of light weight deep convolutional neural networks that are vastly smaller in size and faster in performance than many other widely known models, like VGG16 and GoogleNet. Well also learn how to work with MobileNets in code using Keras. Because of their small size, MobileNets are considered great deep learning models to be used on mobile devices or to run in browser applications.

- [Part 1 - Intro to MobileNet Image Classification with Keras](https://youtu.be/OO4HD-1wRN8)
- [Part 2 - Build a fine-tuned MobileNet model with Keras](https://youtu.be/4Tcqw5oIfIg)
- [Part 3 - Train a fine-tuned MobileNet model with Keras](https://youtu.be/-0Blng0Ww8c)
- [Part 4 - Build a sign language image classifier using MobileNets](https://youtu.be/FNqp4ZY0wDY)",8,36
1378,2018-6-24,2018,6,24,21,8the23,! CNC  ,https://www.reddit.com/r/MachineLearning/comments/8the23/_cnc_/,Woodworking94,1529841975,,1,1
1379,2018-6-24,2018,6,24,22,8thscu,Machine Learning Open Source Projects of the Month (v.June 2018),https://www.reddit.com/r/MachineLearning/comments/8thscu/machine_learning_open_source_projects_of_the/,kumeralex,1529846869,,1,1
1380,2018-6-24,2018,6,24,22,8thskp,Machine Learning Open Source Projects of the Month (v.June 2018),https://www.reddit.com/r/MachineLearning/comments/8thskp/machine_learning_open_source_projects_of_the/,kumeralex,1529846934,,1,1
1381,2018-6-24,2018,6,24,22,8thvui,[P]Machine Learning Open Source Projects of the Month (v.June 2018),https://www.reddit.com/r/MachineLearning/comments/8thvui/pmachine_learning_open_source_projects_of_the/,kumeralex,1529847950,,0,1
1382,2018-6-24,2018,6,24,22,8thvyp,[P] Machine Learning Open Source Projects of the Month (v.June 2018),https://www.reddit.com/r/MachineLearning/comments/8thvyp/p_machine_learning_open_source_projects_of_the/,kumeralex,1529847982,,4,183
1383,2018-6-24,2018,6,24,22,8thxsv,[D] Machine Learning MASSIVELY Undersold on Freelance Websites,https://www.reddit.com/r/MachineLearning/comments/8thxsv/d_machine_learning_massively_undersold_on/,ctznen,1529848550,"I wanted to start a discussion regarding the rates I am seeing fellow machine learning peoples post on freelance website, and frankly I think people post some absurdly low numbers; albeit with some more reasonable numbers. I am a research scientist at a top ten computer science university by day, but I have been spending the last ""240 minutes"" of my day trying to develop my own brand or start some sort of side hustle. This is all with support of my wife and son (to give some context). Personally, I think as a freelancer, I am worth at least 100$ an hour. I think that is on the low end of the spectrum, because while I have experience implementing many ML/DL models -- I'm new to freelancing.

In general, I have seen people commonly posting they charge 20-40 bucks an hour on UpWork. This number would be fine if you were an employee at some organization where they take on much of the overhead (you don't have to find work, they take on the financial responsibility of that)... but as freelancers we are operating on our own brand usually in our off time.

Let me explain why I think this is a bit crazy with a few bullet points.

* You are spending resources to find work (off hours, etc) UNPAID
* You are spending resources not investing in your own brand (working on your own startup, personal projects, reading textbooks)
* You are spending resources not doing the things you love (Hanging out with family, playing dark souls).
* ML takes a large time investment (heck even programming), and there is large demand
* ML has the potential to earn huge profits for companies
* There are operating costs (similar to resources i.e. electricity bill)
* You have to research constantly to stay at start of the art level
* Time is valuable, especially to someone who has the ability to develop ML models. You have to invest lots (FOR FREE).
* Not even including large expenses like insurance and taxes (if you are full time).

I think in general, there is a huge opportunity in the ML world. Charging 20-40 bucks an hour just doesn't capture the opportunity cost (in my opinion) of running your own brand. I think to capture your opportunity and operating costs, you could easily multiply the hourly rate you expect to receive at a large company (\~40?) and multiply that by 2.5-3.5. In fact, I think that's what large companies do because you cost more than just your take home. I think a more reasonable price range would be 100$(beginner-intermediate)-200$(expert) hourly (as high as that sounds). Frankly, I think it should be even more as I think working on personal projects or our own business would likely be a better long-term investment. It should take some serious cash to get us to spend time on some sponsors project.

Maybe this is preaching to the choir, or I am a lunatic expecting way too much money. I think the bottom line is that there are some machine learning peoples out really undercutting their skills, and I would be interested if this community has noticed any trends in this regard.",37,30
1384,2018-6-24,2018,6,24,23,8thytp,"[P] A searchable site that links machine learning papers on ArXiv with code, frameworks, and libraries used",https://www.reddit.com/r/MachineLearning/comments/8thytp/p_a_searchable_site_that_links_machine_learning/,julian88888888,1529848832,,0,0
1385,2018-6-24,2018,6,24,23,8ti3k3,[P] Application of neural style transfer from magenta to paintings,https://www.reddit.com/r/MachineLearning/comments/8ti3k3/p_application_of_neural_style_transfer_from/,gau_mar,1529850103,,0,2
1386,2018-6-24,2018,6,24,23,8ti9kp,Zero to Hero with Keras,https://www.reddit.com/r/MachineLearning/comments/8ti9kp/zero_to_hero_with_keras/,yboris,1529851725,,3,1
1387,2018-6-25,2018,6,25,1,8tir93,[R] How an LSTM Attention Model Views the 2013 U.S. Bond Market 'Taper Tantrum',https://www.reddit.com/r/MachineLearning/comments/8tir93/r_how_an_lstm_attention_model_views_the_2013_us/,QuantMountain,1529856291,,11,12
1388,2018-6-25,2018,6,25,1,8tivjk,The Data Science Gap - Kirill Eremenko,https://www.reddit.com/r/MachineLearning/comments/8tivjk/the_data_science_gap_kirill_eremenko/,Mr_Nomadic,1529857331,,1,1
1389,2018-6-25,2018,6,25,2,8tj60i,PageRank Algorithm- why some other webpage will point towards my webpage to increase rank of my webpage?,https://www.reddit.com/r/MachineLearning/comments/8tj60i/pagerank_algorithm_why_some_other_webpage_will/,AdityaKansal17,1529859814,[removed],1,1
1390,2018-6-25,2018,6,25,2,8tj8w8,PageRank Algo- why some webpage would point to my webpage as it increase the rank of my webpage compared to them?,https://www.reddit.com/r/MachineLearning/comments/8tj8w8/pagerank_algo_why_some_webpage_would_point_to_my/,AdityaKansal17,1529860475,[removed],1,1
1391,2018-6-25,2018,6,25,2,8tjcbh,Top 10 Machine Learning Open Source Projects of the Month (June 2018),https://www.reddit.com/r/MachineLearning/comments/8tjcbh/top_10_machine_learning_open_source_projects_of/,pbteja1998,1529861287,,1,1
1392,2018-6-25,2018,6,25,2,8tjhos,Help for Scala (Candidate Retrieval) project setup process,https://www.reddit.com/r/MachineLearning/comments/8tjhos/help_for_scala_candidate_retrieval_project_setup/,SeifGamal,1529862518,[removed],1,1
1393,2018-6-25,2018,6,25,3,8tjthu,Gaining insights in to neural networks using semantic segmentation of M2NIST images derived from the MNIST dataset.,https://www.reddit.com/r/MachineLearning/comments/8tjthu/gaining_insights_in_to_neural_networks_using/,farhanhubble,1529865297,,1,1
1394,2018-6-25,2018,6,25,3,8tju89,Polynomial Regression As an Alternative to Neural Nets,https://www.reddit.com/r/MachineLearning/comments/8tju89/polynomial_regression_as_an_alternative_to_neural/,iamkeyur,1529865473,,0,1
1395,2018-6-25,2018,6,25,3,8tjym0,A total noob interested in learning machine learning as free as possible,https://www.reddit.com/r/MachineLearning/comments/8tjym0/a_total_noob_interested_in_learning_machine/,WinstonWotse,1529866530,[removed],1,1
1396,2018-6-25,2018,6,25,3,8tjyp8,Tensorflow versus Matlabtoolbox - unexpected Results with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8tjyp8/tensorflow_versus_matlabtoolbox_unexpected/,GudenMoie,1529866557,,1,1
1397,2018-6-25,2018,6,25,4,8tkcg8,"Anybody here have insight into good choice of neural net architecture (num layers, node per layer and choice of activation function) for binary classification? Thanks",https://www.reddit.com/r/MachineLearning/comments/8tkcg8/anybody_here_have_insight_into_good_choice_of/,like-a-tomato,1529869732,[removed],1,1
1398,2018-6-25,2018,6,25,5,8tkimw,Hey just found a neural network stream on twitch of an ai learning the first level of pac man,https://www.reddit.com/r/MachineLearning/comments/8tkimw/hey_just_found_a_neural_network_stream_on_twitch/,thomascook04040,1529871150,,1,1
1399,2018-6-25,2018,6,25,5,8tkq1t,[D] Career advice about getting into ML,https://www.reddit.com/r/MachineLearning/comments/8tkq1t/d_career_advice_about_getting_into_ml/,ValuableSpecific,1529872874,"I am a seasoned software engineer with 10+ years of experienced. I had experience creating large software system in different capacity: as an individual contributor, as a tech lead, architect, and as a product owner. Currently I am an architect/product owner.

Some time ago, I got interested in ML and DL. I took a number of online courses both from MOOCs, and from more established educational institutions. I have a small portfolio of project related to this which demonstrate my knowledge of DL, Python, and related frameworks.

I have limited opportunities of advancing in this area on my current job, I can apply ML here and there, but nothing especially groundbreaking or interesting. 

So, I am thinking about more efficient ways about getting into ML, and especially ML research. Could you recommend me ways to get into this fields. I see a lot of positions for Research Engineers in places like OpenAI, Google Brain, Allen Institute of AI, etc. Could you recommend me applying there? Could you recommend me any other ways of getting into the field?

P.S. I have a degree in CS  from a math department of an East European university and currently located in US.",7,7
1400,2018-6-25,2018,6,25,6,8tkye2,What programing language should i use for Machine Learning? Java or C++?,https://www.reddit.com/r/MachineLearning/comments/8tkye2/what_programing_language_should_i_use_for_machine/,kecab,1529874831,[removed],1,1
1401,2018-6-25,2018,6,25,6,8tkyro,Rediscovering Semantic Segmentation,https://www.reddit.com/r/MachineLearning/comments/8tkyro/rediscovering_semantic_segmentation/,farhanhubble,1529874921,,1,1
1402,2018-6-25,2018,6,25,6,8tl1os,[P] Rediscovering Semantic Segmentation,https://www.reddit.com/r/MachineLearning/comments/8tl1os/p_rediscovering_semantic_segmentation/,farhanhubble,1529875613,,0,4
1403,2018-6-25,2018,6,25,6,8tl2qg,Best Test for Binary Variables,https://www.reddit.com/r/MachineLearning/comments/8tl2qg/best_test_for_binary_variables/,jhvu98,1529875852,[removed],1,1
1404,2018-6-25,2018,6,25,7,8tlbfj,Registering a transcript and its summary,https://www.reddit.com/r/MachineLearning/comments/8tlbfj/registering_a_transcript_and_its_summary/,sairegrefree,1529877872,[removed],1,1
1405,2018-6-25,2018,6,25,7,8tleke,What is Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8tleke/what_is_machine_learning/,adoptionvlog,1529878611,,1,1
1406,2018-6-25,2018,6,25,9,8tm3ua,Training neural nets with multiple labels on single input,https://www.reddit.com/r/MachineLearning/comments/8tm3ua/training_neural_nets_with_multiple_labels_on/,smndoo,1529885234,[removed],1,1
1407,2018-6-25,2018,6,25,10,8tmhqw,[D] Registering a transcript and its summary,https://www.reddit.com/r/MachineLearning/comments/8tmhqw/d_registering_a_transcript_and_its_summary/,sairegrefree,1529888785,"I have a bullet point summary and the transcript of a conversation between two person. Any idea on how find out which set of lines in the transcript that corresponds to a point in the summary?

Idea 1: Convert the point in the summary to a 'question' and use comprehension models.

Idea 2: Find matching key words in the transcript and use co-reference resolution and word matching to find other lines in the transcript to find all the relevant conversations.

Cons: Both comprehension and co-reference models/data sets do not work well in dialog transcripts.

Any new ideas or comments on my approaches?

\[post from [r/LanguageTechnology](https://www.reddit.com/r/LanguageTechnology)\]",1,10
1408,2018-6-25,2018,6,25,11,8tn2gj,[D] I want to reimplement the model from 'Hierarchical Neural Story Generation' in keras and tensorflow. Is this a terrible idea?,https://www.reddit.com/r/MachineLearning/comments/8tn2gj/d_i_want_to_reimplement_the_model_from/,Morninglow,1529894395,"link to paper [https://arxiv.org/abs/1805.04833](https://arxiv.org/abs/1805.04833)

link to code [https://github.com/pytorch/fairseq/tree/master/examples/stories](https://github.com/pytorch/fairseq/tree/master/examples/stories)

I haven't worked with pytorch so I would definitely have to learn it if I had a shot at translating it. From what I've looked at I think I would prefer to work in keras and tensorflow because I can make my code prettier. 

But is this even a good idea if I want to recreate and expand upon their results? Would I have to rewrite half the fairseq library? 

I read that differences in how things like math operations are implemented can have a pretty big impact. Not to mention the other larger implementation details that are all under the hood.  

I do have access to a proper cluster if that makes a difference.

Should I just suck it up and work in pytorch?",15,5
1409,2018-6-25,2018,6,25,13,8tnn79,[R] Six-Way EEG Event Classification Dataset w/ Dilated CNNs and Multi-Task Learning; A Comparison (Theory + Results + Code),https://www.reddit.com/r/MachineLearning/comments/8tnn79/r_sixway_eeg_event_classification_dataset_w/,ACTBRUH,1529900200,,4,5
1410,2018-6-25,2018,6,25,13,8tnnez,[D] Machine Learning - WAYR (What Are You Reading) - Week 45,https://www.reddit.com/r/MachineLearning/comments/8tnnez/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1529900263,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)||

Most upvoted papers two weeks ago:

/u/Molag_Balls: [proposed ICLR paper](https://openreview.net/forum?id=rkEfPeZRb)

/u/theainerd: [Machine Learning Yearning](http://www.mlyearning.org/)

/u/alfileres1: https://arxiv.org/abs/1605.00003

Besides that, there are no rules, have fun.",31,95
1411,2018-6-25,2018,6,25,13,8tnqt7,[D]Best research paper for beginners who understand terminology and concept but want to go even deeper in ML,https://www.reddit.com/r/MachineLearning/comments/8tnqt7/dbest_research_paper_for_beginners_who_understand/,samanshrestharay,1529901300,"The title pretty much says it all. In your opinion, what is the best research paper to read for better understanding of ML? So far, I have completed Andrew Ng's course and slowly making my way through Ian Goodfellow's book. Currently, I am doing fast.ai course as well. I am a senior undergraduate and have taken calculus III, intro to statistics and algorithms course. (No linear algebra yet). 

Let me know what you think. 
Thanks. ",2,10
1412,2018-6-25,2018,6,25,14,8to2p7,Pretrained CNN model for MRI Images?,https://www.reddit.com/r/MachineLearning/comments/8to2p7/pretrained_cnn_model_for_mri_images/,akshayagrwl827,1529905097,[removed],1,1
1413,2018-6-25,2018,6,25,14,8to2vt,How Its Made? Drill bits. Raw Material and Manufacturing Process used in Industries.,https://www.reddit.com/r/MachineLearning/comments/8to2vt/how_its_made_drill_bits_raw_material_and/,maantechnoplus,1529905154,,1,1
1414,2018-6-25,2018,6,25,14,8to548,A new Machine Learning Paradigm,https://www.reddit.com/r/MachineLearning/comments/8to548/a_new_machine_learning_paradigm/,rajesh_d24,1529905901,,1,1
1415,2018-6-25,2018,6,25,15,8to9q6,Enfajadora de celofn automtica para la venta,https://www.reddit.com/r/MachineLearning/comments/8to9q6/enfajadora_de_celofn_automtica_para_la_venta/,lgsherry,1529907467,,1,1
1416,2018-6-25,2018,6,25,15,8to9w8,Mean normalisation and Feature scaling.,https://www.reddit.com/r/MachineLearning/comments/8to9w8/mean_normalisation_and_feature_scaling/,deepakchawla35,1529907523,"Currently, I am working on multivariable regression problem data set and I came across a problem that my dataset have so many features with different features scale value and so google suggest me use mean normalization and feature scaling techniques but I don't understand which one we have to usemean normalization or feature scaling andwhy we are using mean normalization and feature scaling techniques simultaneously.?? and from where below formula derived .

x(i) = x(i) - mean(x) / std(x)",1,1
1417,2018-6-25,2018,6,25,15,8toczz,Machine Learning and New Radical Empiricism - Zavain Dar @ CogX 2018,https://www.reddit.com/r/MachineLearning/comments/8toczz/machine_learning_and_new_radical_empiricism/,banksyb00mb00m,1529908598,,1,1
1418,2018-6-25,2018,6,25,15,8tof8v,[D] Machine Learning and New Radical Empiricism - Zavain Dar @ CogX 2018,https://www.reddit.com/r/MachineLearning/comments/8tof8v/d_machine_learning_and_new_radical_empiricism/,banksyb00mb00m,1529909381,,7,16
1419,2018-6-25,2018,6,25,16,8tohk1,Social Network Analysis for finding User's Online Personality,https://www.reddit.com/r/MachineLearning/comments/8tohk1/social_network_analysis_for_finding_users_online/,manishs3,1529910191,,1,1
1420,2018-6-25,2018,6,25,16,8tomft,Social Network Analysis for finding User's Online Personality,https://www.reddit.com/r/MachineLearning/comments/8tomft/social_network_analysis_for_finding_users_online/,manishs3,1529911828,,1,1
1421,2018-6-25,2018,6,25,17,8tovju,Yemeni forces launch attack on Riyadh,https://www.reddit.com/r/MachineLearning/comments/8tovju/yemeni_forces_launch_attack_on_riyadh/,MichaelAmmoun,1529915214,,1,1
1422,2018-6-25,2018,6,25,20,8tpl2e,Google Pixel Portrait Mode,https://www.reddit.com/r/MachineLearning/comments/8tpl2e/google_pixel_portrait_mode/,georgegach,1529924418,[removed],1,1
1423,2018-6-25,2018,6,25,20,8tpltf,Can the following method be a substitute for the LSTM method?,https://www.reddit.com/r/MachineLearning/comments/8tpltf/can_the_following_method_be_a_substitute_for_the/,Sreram,1529924632,[removed],1,1
1424,2018-6-25,2018,6,25,20,8tpni1,[D][R] Synthetic DOF: Google Pixel Portrait Mode system research paper,https://www.reddit.com/r/MachineLearning/comments/8tpni1/dr_synthetic_dof_google_pixel_portrait_mode/,georgegach,1529925112,"*Processing img z038lz4pp4611...*

This is hands down the most significant innovation I have seen in mobile photography for a long time. The fact that combination of person segmentation + 1mm baseline dual-pixel hardware techs combined can produce such high quality result is just amazing.

From this point onward dual-camera configurations are pretty much obsolete. 

Tweet @arxivtrends: [https://twitter.com/arxivtrends/status/1011193443991916544](https://twitter.com/arxivtrends/status/1011193443991916544)

Paper: [https://arxiv.org/pdf/1806.04171.pdf](https://arxiv.org/pdf/1806.04171.pdf)

What do you guys think? Where is the room for improvement?",5,6
1425,2018-6-25,2018,6,25,20,8tpoon,"Significance of using LSTM cells, over non-differentiable alternatives.",https://www.reddit.com/r/MachineLearning/comments/8tpoon/significance_of_using_lstm_cells_over/,Sreram,1529925471,[removed],1,1
1426,2018-6-25,2018,6,25,20,8tps1r,How to use Docker to run this application,https://www.reddit.com/r/MachineLearning/comments/8tps1r/how_to_use_docker_to_run_this_application/,Leonidus6969,1529926446,[removed],1,1
1427,2018-6-25,2018,6,25,21,8tq6zk,A guide to deploying Machine/Deep Learning model(s) in Production.,https://www.reddit.com/r/MachineLearning/comments/8tq6zk/a_guide_to_deploying_machinedeep_learning_models/,maheshkkumar,1529930518,,1,1
1428,2018-6-25,2018,6,25,21,8tq81f,"MIT Study reveals how, when a synapse strengthens, its neighbors weaken",https://www.reddit.com/r/MachineLearning/comments/8tq81f/mit_study_reveals_how_when_a_synapse_strengthens/,j_orshman,1529930780,,94,586
1429,2018-6-25,2018,6,25,21,8tq9gw,A guide to deploying Machine/Deep Learning model(s) in Production.,https://www.reddit.com/r/MachineLearning/comments/8tq9gw/a_guide_to_deploying_machinedeep_learning_models/,maheshkkumar,1529931140,,1,1
1430,2018-6-25,2018,6,25,21,8tqa9x,[D] Is it common to add a term that gives more penalty to tokens with higher loss in NLP?,https://www.reddit.com/r/MachineLearning/comments/8tqa9x/d_is_it_common_to_add_a_term_that_gives_more/,HigherTopoi,1529931352,"For language modeling and seq2seq, the overall loss of a minibatch is a mean over the losses on tokens in target sequences in a minibatch. I've occasionally encountered with a certain characteristic distribution of losses in each target sequence: for a certain token, the error is significantly larger than on other target tokens, and these tokens dominantly contribute to the overall loss. This means that, as training progresses and most but a small number of tokens have a tiny loss, the overall loss is essentially equal to the fraction of the sum of losses on tokens with large loss over the number of all tokens. Since the number of tokens with large loss is much smaller than the number of all tokens in a minibatch, the gradient is small. In order to make the gradient large, we can add to the usual loss term the correction term that is the cross entropy over tokens with large loss only (the ones above a certain threshold). I haven't tested this loss. It this kind of technique well-known? If so, could you list some relevant references? Overfitting isn't an issue in my case. I'm not certain if this is a commonplace issue, but I'd like to at least fix it for my problem. 
",2,1
1431,2018-6-25,2018,6,25,22,8tqc7a,A guide to deploying Machine/Deep Learning model(s) in Production.,https://www.reddit.com/r/MachineLearning/comments/8tqc7a/a_guide_to_deploying_machinedeep_learning_models/,maheshkkumar,1529931817,,1,1
1432,2018-6-25,2018,6,25,22,8tqcm1,"[N] Song Lyric Toxicity, Commit Assistant, NLP Progress, DensePose, PyTorch Geometric,",https://www.reddit.com/r/MachineLearning/comments/8tqcm1/n_song_lyric_toxicity_commit_assistant_nlp/,omarsar,1529931925,,0,1
1433,2018-6-25,2018,6,25,22,8tqeov,[N] A guide to deploying Machine/Deep Learning model(s) in Production,https://www.reddit.com/r/MachineLearning/comments/8tqeov/n_a_guide_to_deploying_machinedeep_learning/,maheshkkumar,1529932422,,2,2
1434,2018-6-25,2018,6,25,22,8tqkpe,[R] Explaining math of GAN to teens,https://www.reddit.com/r/MachineLearning/comments/8tqkpe/r_explaining_math_of_gan_to_teens/,jaleyhd,1529933866,,0,2
1435,2018-6-25,2018,6,25,22,8tqmnq,"[P][N] Vespa, the open source big data serving engine adds ONNX support",https://www.reddit.com/r/MachineLearning/comments/8tqmnq/pn_vespa_the_open_source_big_data_serving_engine/,RealJon,1529934349,,0,2
1436,2018-6-25,2018,6,25,22,8tqmzm,[P] Human Pose matching and urban scene matching on Android,https://www.reddit.com/r/MachineLearning/comments/8tqmzm/p_human_pose_matching_and_urban_scene_matching_on/,gilbeckers,1529934435,,2,3
1437,2018-6-25,2018,6,25,22,8tqnmo,Neural Titanic: Using TensorFlow.js to Visualize Neural Network Predictions During Training on the Titanic Dataset.,https://www.reddit.com/r/MachineLearning/comments/8tqnmo/neural_titanic_using_tensorflowjs_to_visualize/,BurntOutProgrammer,1529934584,,1,1
1438,2018-6-25,2018,6,25,22,8tqph7,How to run Scala project (with dataset) needs heavy computations Online,https://www.reddit.com/r/MachineLearning/comments/8tqph7/how_to_run_scala_project_with_dataset_needs_heavy/,SeifGamal,1529935037,"I want to run a Scala project which uses dataset (\~ 1G)  Online as my PC can't do these computations 

The project link:  
[https://github.com/UKPLab/acl2017-non-factoid-qa/tree/master/Candidate-Retrieval](https://github.com/UKPLab/acl2017-non-factoid-qa/tree/master/Candidate-Retrieval)  


Is there a website to upload project &amp; dataset and run it?",1,1
1439,2018-6-25,2018,6,25,23,8tqqsk,[P] Neural Titanic: Using TensorFlow.js to Visualize Neural Network Predictions During Training on the Titanic Dataset.,https://www.reddit.com/r/MachineLearning/comments/8tqqsk/p_neural_titanic_using_tensorflowjs_to_visualize/,BurntOutProgrammer,1529935323,,0,1
1440,2018-6-25,2018,6,25,23,8tqtfb,[D] OpenAI Five: Dota 5v5,https://www.reddit.com/r/MachineLearning/comments/8tqtfb/d_openai_five_dota_5v5/,sksq9,1529935919,,1,5
1441,2018-6-25,2018,6,25,23,8tqyw7,"European Scientists and Engineers; The European Patent Office is hiring Patent Examiners. This includes Semiconductors, Electrical Engineering, and all things ICT. Be at the forefront of innovation and technology. Apply today!",https://www.reddit.com/r/MachineLearning/comments/8tqyw7/european_scientists_and_engineers_the_european/,AktorRecruitment,1529937143,,1,1
1442,2018-6-25,2018,6,25,23,8tr11j,[R] OpenAI Five,https://www.reddit.com/r/MachineLearning/comments/8tr11j/r_openai_five/,circuithunter,1529937629,,51,249
1443,2018-6-25,2018,6,25,23,8tr52s,[D] Cars detection from satellite imagery using RetinaNet,https://www.reddit.com/r/MachineLearning/comments/8tr52s/d_cars_detection_from_satellite_imagery_using/,Bo_Bibelo,1529938430,,0,1
1444,2018-6-25,2018,6,25,23,8tr57n,[D] Designing a short ML course for mid level managers,https://www.reddit.com/r/MachineLearning/comments/8tr57n/d_designing_a_short_ml_course_for_mid_level/,winstonl,1529938464,"I am working with a local university to design a short course for mid level managers. Specifically, I think our target students are:
- mid level people managers who have some influence over their teams (e.g. managers, senior managers, directors) 
- people who are interested in ML/AI and how that may impact their team, and want to learn more than just high level concepts.
- They may be from different industries but most likely banks, insurance, telecommunications and retail
- The course will be roughly 2 days, so approximately 15 hours of material in total.

There will be a large portion of ""lectures"", ranging from what ML is to specific use cases in different industries to help people see how others have been leveraging the technology, but I also want to make this more like a ""course"" than a conference. What I mean is that I don't want these people to come in, sit down, listen to a bunch of people talk and then go home. I want there to be some ""hands-on"" stuff as well.

I wonder if anyone has any good recommendations on 'hands-on' practices for this group of people. Something like deriving the backpropagation or code an image classifier obviously doesn't make sense, but ideally it should offer reasonable challenges to them as well.",3,7
1445,2018-6-26,2018,6,26,0,8trcg4,[R] Deep Orthogonal Representations: Fundamental Properties and Applications,https://www.reddit.com/r/MachineLearning/comments/8trcg4/r_deep_orthogonal_representations_fundamental/,satrock,1529940044,,0,1
1446,2018-6-26,2018,6,26,0,8trflm,Why did recursive autoencoders fall out of fashion?,https://www.reddit.com/r/MachineLearning/comments/8trflm/why_did_recursive_autoencoders_fall_out_of_fashion/,SoggyBathtub,1529940733,"I've been looking for a way to combine discrete and time series into the same format for a problem I'm working on. This led me to recursive autoencoders. This variant of the autoencoder takes a series of inputs of an fixed dimension and encodes it into a single output of the same dimension. As a result, you can feed the encoded data back into the autoencoder in a recursive fashion. 

My problem so far is that I can find very little information on these networks beyond what they are. There seems to be very few papers published after 2014 when they appear to have been mostly forgotten. Does anyone here have experience with this network, know where to find good resources or just have any clue why they aren't used much anymore?",16,7
1447,2018-6-26,2018,6,26,0,8trie1,Looking For New Means To Process Your Datasets? Join Our Live Webinar This Wednesday and Get Involved With Our Discussion!,https://www.reddit.com/r/MachineLearning/comments/8trie1/looking_for_new_means_to_process_your_datasets/,Project_Hydro,1529941317,,1,1
1448,2018-6-26,2018,6,26,0,8trkko,Need help finding Motivation,https://www.reddit.com/r/MachineLearning/comments/8trkko/need_help_finding_motivation/,niszoig,1529941770,"I started self studying Machine Learning one year back.Did the recommended MOOCs,read the important books and started a project which I think is a really cool application.

But right now I have got to a point where the actual Machine Learning part is done and I have to work on other aspects like making a GUI,Improving the UI, deployment to the server, writing a blog explaining in laymans terms.

Earlier I couldn't wait to get started on the project each day,but that is no longer the case.
I assume many of you veterans must have been through a similar situation at some point.I would appreciate any advice I could get!
Thank you
",6,4
1449,2018-6-26,2018,6,26,0,8trluj,Deel Troll Detector: Let's put deep learning to work for the good!,https://www.reddit.com/r/MachineLearning/comments/8trluj/deel_troll_detector_lets_put_deep_learning_to/,andriosr,1529942034,,0,0
1450,2018-6-26,2018,6,26,1,8trtzx,Is this the place to ask questions about code for a simple ml program.,https://www.reddit.com/r/MachineLearning/comments/8trtzx/is_this_the_place_to_ask_questions_about_code_for/,Zeno_3NHO,1529943674,2 inputs and one output,1,0
1451,2018-6-26,2018,6,26,1,8truoo,How Yelp uses machine learning to create Popular Dishes list,https://www.reddit.com/r/MachineLearning/comments/8truoo/how_yelp_uses_machine_learning_to_create_popular/,jonfla,1529943819,,0,1
1452,2018-6-26,2018,6,26,1,8trzkt,Evaluating the discriminator from a trained TF-GAN,https://www.reddit.com/r/MachineLearning/comments/8trzkt/evaluating_the_discriminator_from_a_trained_tfgan/,junhwikim,1529944802,"Does anyone know how to pull out the trained discriminator from a trained TFGAN, and evaluate it? I have .meta and .data files from which the model can be recovered.",0,2
1453,2018-6-26,2018,6,26,1,8ts0q5,[D] Where to apply loss for LSTM Classification problem?,https://www.reddit.com/r/MachineLearning/comments/8ts0q5/d_where_to_apply_loss_for_lstm_classification/,sauhaarda,1529945029,"For a audio classification problem I'm working on I'm using an LSTM at the end of my network to output predictions. I know that an LSTM will predict values at every time step. When training my classifier should I:
1. Only calculate loss based on prediction of LSTM in last time step?
2. Calculate loss equally across all time steps?
3. Calculate a ""weighted"" loss valuing the correctness of the later time steps over the predictions at earlier time steps?

If you could point me to some general resource for these kind of questions that would be appreciated as well as I couldn't find an answer just searching on Google.",2,2
1454,2018-6-26,2018,6,26,1,8ts2ns,Can you suggest a memory saving Conv RNN?,https://www.reddit.com/r/MachineLearning/comments/8ts2ns/can_you_suggest_a_memory_saving_conv_rnn/,Gemabo,1529945414,"I have this unconventional task, to classify video segments. so far nothing new... But each video segment has 100 frames, each frame is 4K resolution and every pixel counts (i.e. can't resize to normal size).

Even a strong GPU (12GB-16GB RAM) can't hold all the segment's frames when using a standard deep 3D convolutional network . Meaning, will not be able to train even with a ""batch"" of 1 segment without getting OOM. 

My &lt;not so good&gt; solution was to use a convolutional GRU and feed the network with one frame at a time, and let the hidden state aggregate what's important to save. Well, turns out it was a bad idea because even though the frames flow into the network one by one, during training, all the gradients of the hidden state must be saved for all the frames of all the segments in the batch, so basically I don't save any memory by going into RNN (while training).

Can you suggest an alternative approach? ",6,1
1455,2018-6-26,2018,6,26,2,8ts74x,Layoffs at Watson Health Reveal IBMs Problem with AI,https://www.reddit.com/r/MachineLearning/comments/8ts74x/layoffs_at_watson_health_reveal_ibms_problem_with/,writesaboutstats,1529946286,,0,4
1456,2018-6-26,2018,6,26,2,8ts9ey,OpenAI Five,https://www.reddit.com/r/MachineLearning/comments/8ts9ey/openai_five/,j_orshman,1529946744,,0,0
1457,2018-6-26,2018,6,26,3,8tssg4,[R] Flexible Neural Representation for Physics Prediction,https://www.reddit.com/r/MachineLearning/comments/8tssg4/r_flexible_neural_representation_for_physics/,mroda44,1529950569,,1,3
1458,2018-6-26,2018,6,26,3,8tstng,dynamic tsne,https://www.reddit.com/r/MachineLearning/comments/8tstng/dynamic_tsne/,C2H4Doublebond,1529950805,"Hi all,
Was wondering if anyone knows any R or python packages that allow dynamic tsne visualization? What I m trying to do is to demo how increasing the number of samples affect distribution. I understand the stochastic nature of tsne, but thought there maybe ways to make this work. Thanks!
",0,2
1459,2018-6-26,2018,6,26,3,8tt4qg,MetaBags: Bagged Meta-Decision Trees for Regression,https://www.reddit.com/r/MachineLearning/comments/8tt4qg/metabags_bagged_metadecision_trees_for_regression/,xristos_forokolomvos,1529953098,,1,4
1460,2018-6-26,2018,6,26,4,8tt5io,Training an LSTM network and sampling the resulting model in ml5.js,https://www.reddit.com/r/MachineLearning/comments/8tt5io/training_an_lstm_network_and_sampling_the/,3tres,1529953247,,1,1
1461,2018-6-26,2018,6,26,4,8tt7g8,[P] Training an LSTM network and sampling the resulting model in ml5.j,https://www.reddit.com/r/MachineLearning/comments/8tt7g8/p_training_an_lstm_network_and_sampling_the/,3tres,1529953625,,1,2
1462,2018-6-26,2018,6,26,4,8ttglc,Understanding the Technology of Machine Learning/AI,https://www.reddit.com/r/MachineLearning/comments/8ttglc/understanding_the_technology_of_machine_learningai/,ennissh,1529955531,,1,1
1463,2018-6-26,2018,6,26,5,8ttowh,WaveNet/Tacotron in other languages?,https://www.reddit.com/r/MachineLearning/comments/8ttowh/wavenettacotron_in_other_languages/,HerrDoktorDoktor,1529957271,"Let me start by saying that I am a complete ignorant in this field and therefore I have no idea of what the current limits of the technology are. That being said, I've recently become interested in Google's cloud-based text to speech services, but I was rather disappointed after finding that the only WaveNet voices that they offer are all English voices, and, being interested in a Spanish one, the basic service just was too low quality. So, I though about searching for replicators in the community. I'm perfectly aware of the acoustic aberrations and sound issues of independent development, but I've seen some results that would be perfectly acceptable, such as, for example, this: [https://keithito.github.io/audio-samples/](https://keithito.github.io/audio-samples/)

Now, the problem is that I've been unable to find anything but English, so I'll be very grateful if someone can point me in the right direction to a Spanish voice, or, if it doesn't exist, to someone interested in creating one. I don't know how attainable this would be, but I'm serious enough to be willing to spend *some* money in the process. So, I guess my question is: any Spaniards interested in WaveNet/Tacotron out there?",1,1
1464,2018-6-26,2018,6,26,5,8ttsm5,Intuition when to use Global Avergae pooling?,https://www.reddit.com/r/MachineLearning/comments/8ttsm5/intuition_when_to_use_global_avergae_pooling/,nile6499,1529958021,"I am still not sure when to Gloabl average pooling v/s Fully connected Network v/s Fully convolutional Network. If someone could explain me that would be awesome.

Thanks",1,1
1465,2018-6-26,2018,6,26,5,8ttz0t,ASK ML: What are some good examples of overfitting in the real world/human evolution?,https://www.reddit.com/r/MachineLearning/comments/8ttz0t/ask_ml_what_are_some_good_examples_of_overfitting/,lookingforsome1,1529959331,"Where people or cultures fixate on something that may not lend itself to long term progression, yet optimistic for a short term reward system? ",1,1
1466,2018-6-26,2018,6,26,6,8tu9zu,[P] A Self Attentive Sentence Embedding (Tensorflow Implementation),https://www.reddit.com/r/MachineLearning/comments/8tu9zu/p_a_self_attentive_sentence_embedding_tensorflow/,roomylee,1529961604,,1,0
1467,2018-6-26,2018,6,26,6,8tubkc,Countdown regression: The weatherman's tools make precise survival predictions! (with EHR data),https://www.reddit.com/r/MachineLearning/comments/8tubkc/countdown_regression_the_weathermans_tools_make/,avati,1529961936,,11,16
1468,2018-6-26,2018,6,26,7,8tupzy,My blog post about noise cancellation system made of machine learning. x-post from /r/DSP,https://www.reddit.com/r/MachineLearning/comments/8tupzy/my_blog_post_about_noise_cancellation_system_made/,Tarabah,1529965101,,1,1
1469,2018-6-26,2018,6,26,7,8tusyh,[R] My blog post about noise cancellation system made of machine learning x-post from /r/DSP,https://www.reddit.com/r/MachineLearning/comments/8tusyh/r_my_blog_post_about_noise_cancellation_system/,Tarabah,1529965798,,0,2
1470,2018-6-26,2018,6,26,7,8tuuhh,Easy A2C - A simple walk-through of A2C,https://www.reddit.com/r/MachineLearning/comments/8tuuhh/easy_a2c_a_simple_walkthrough_of_a2c/,Flag_Red,1529966162,,1,1
1471,2018-6-26,2018,6,26,7,8tuxcd,[P] Easy A2C - A simple walk-through of A2C,https://www.reddit.com/r/MachineLearning/comments/8tuxcd/p_easy_a2c_a_simple_walkthrough_of_a2c/,Flag_Red,1529966832,,0,1
1472,2018-6-26,2018,6,26,8,8tv7qv,What cloud services are you using for training? [Discussion],https://www.reddit.com/r/MachineLearning/comments/8tv7qv/what_cloud_services_are_you_using_for_training/,Moondra2017,1529969355,I'm wondering what are the best options for transfer learning with datasets of around 1 million images. ,17,16
1473,2018-6-26,2018,6,26,8,8tv9y1,The Future of AI: Redefining How We Imagine  Towards Data Science,https://www.reddit.com/r/MachineLearning/comments/8tv9y1/the_future_of_ai_redefining_how_we_imagine/,snazrul,1529969861,,1,1
1474,2018-6-26,2018,6,26,10,8tw5y2,"[P] seq2seq - Translating numbers from Chinese, English, French, Malay... Which one is the easiest?",https://www.reddit.com/r/MachineLearning/comments/8tw5y2/p_seq2seq_translating_numbers_from_chinese/,gau_mar,1529978169,,0,3
1475,2018-6-26,2018,6,26,11,8twji3,How you can learn AI.,https://www.reddit.com/r/MachineLearning/comments/8twji3/how_you_can_learn_ai/,kesh13,1529981681,,1,1
1476,2018-6-26,2018,6,26,12,8twn6z,AI with resources.,https://www.reddit.com/r/MachineLearning/comments/8twn6z/ai_with_resources/,kesh13,1529982612,,1,1
1477,2018-6-26,2018,6,26,12,8twquw,What techniques are there for recognizing irregular shapes within images?,https://www.reddit.com/r/MachineLearning/comments/8twquw/what_techniques_are_there_for_recognizing/,mammalian_magistrate,1529983595,[removed],1,1
1478,2018-6-26,2018,6,26,12,8twwgr,Math professor to industry?,https://www.reddit.com/r/MachineLearning/comments/8twwgr/math_professor_to_industry/,tweedlie,1529985115,[removed],1,1
1479,2018-6-26,2018,6,26,13,8txa0h,AI Expo Europe in Amsterdam - 27-28 June,https://www.reddit.com/r/MachineLearning/comments/8txa0h/ai_expo_europe_in_amsterdam_2728_june/,Batareika_1,1529988906,,1,1
1480,2018-6-26,2018,6,26,14,8txblt,A new ML model,https://www.reddit.com/r/MachineLearning/comments/8txblt/a_new_ml_model/,rajesh_d24,1529989368,,1,1
1481,2018-6-26,2018,6,26,14,8txfdi,OpenAI to compete against best team of DotA,https://www.reddit.com/r/MachineLearning/comments/8txfdi/openai_to_compete_against_best_team_of_dota/,renges,1529990529,,1,1
1482,2018-6-26,2018,6,26,14,8txff7,Machine learning and jurisprudence,https://www.reddit.com/r/MachineLearning/comments/8txff7/machine_learning_and_jurisprudence/,Limerick21,1529990540,[removed],1,1
1483,2018-6-26,2018,6,26,15,8txquz,FOMTEC FACTORY- Vertical Injection Molding Machine manufacturer since 1987,https://www.reddit.com/r/MachineLearning/comments/8txquz/fomtec_factory_vertical_injection_molding_machine/,Resa1272250240,1529994145,,1,1
1484,2018-6-26,2018,6,26,15,8txruy,"Tt tn tt v t trng by bnh kem knh cong, vi cht lng tt nht hin nay. Hy Click xem ngay",https://www.reddit.com/r/MachineLearning/comments/8txruy/tt_tn_tt_v_t_trng_by_bnh_kem_knh_cong/,hoangngan123,1529994446,,1,1
1485,2018-6-26,2018,6,26,15,8txu6o,Machine Learning with ML.NET  Solving Real-World Regression Problem (Bike Sharing Demands) | Rubik's Code,https://www.reddit.com/r/MachineLearning/comments/8txu6o/machine_learning_with_mlnet_solving_realworld/,RubiksCodeNMZ,1529995193,,1,1
1486,2018-6-26,2018,6,26,15,8txwp5,[N] Machine Learning with ML.NET  Solving Real-World Regression Problem (Bike Sharing Demands),https://www.reddit.com/r/MachineLearning/comments/8txwp5/n_machine_learning_with_mlnet_solving_realworld/,RubiksCodeNMZ,1529996015,,0,1
1487,2018-6-26,2018,6,26,15,8txxte,[R] Gradient Adversarial Training of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8txxte/r_gradient_adversarial_training_of_neural_networks/,Sirisian,1529996359,,2,18
1488,2018-6-26,2018,6,26,16,8ty2cf,Machine Learning with ML.NET  Solving Real-World Regression Problem (Bike Sharing Demands),https://www.reddit.com/r/MachineLearning/comments/8ty2cf/machine_learning_with_mlnet_solving_realworld/,RubiksCodeNMZ,1529997774,,1,1
1489,2018-6-26,2018,6,26,16,8ty6og,Increased demand for Pre Engineered building leading to hike in 11.63% CAGR.,https://www.reddit.com/r/MachineLearning/comments/8ty6og/increased_demand_for_pre_engineered_building/,Supertech_India,1529999202,[removed],1,1
1490,2018-6-26,2018,6,26,17,8ty9bx,Why Russian to English is difficult for Machine Translation,https://www.reddit.com/r/MachineLearning/comments/8ty9bx/why_russian_to_english_is_difficult_for_machine/,Fewthp,1530000194,,1,1
1491,2018-6-26,2018,6,26,17,8tygff,"Difference between models , regression",https://www.reddit.com/r/MachineLearning/comments/8tygff/difference_between_models_regression/,RubioRick,1530002862,[removed],1,1
1492,2018-6-26,2018,6,26,18,8tyipx,How RealtimeCRM built a business card reader using machine learning,https://www.reddit.com/r/MachineLearning/comments/8tyipx/how_realtimecrm_built_a_business_card_reader/,Mattrt123,1530003681,[removed],1,1
1493,2018-6-26,2018,6,26,18,8tykor,[P] Using deep learning to go from 2D to 3D photo editing,https://www.reddit.com/r/MachineLearning/comments/8tykor/p_using_deep_learning_to_go_from_2d_to_3d_photo/,buhmi,1530004384,,14,81
1494,2018-6-26,2018,6,26,18,8tylrq,Understanding Decision Tree And Decision Making  AiMantra  Medium,https://www.reddit.com/r/MachineLearning/comments/8tylrq/understanding_decision_tree_and_decision_making/,imHarin,1530004767,,1,1
1495,2018-6-26,2018,6,26,18,8tynn3,"Microsoft improves facial recognition technology to perform better across all skin tones and genders, develops machine learning best practices to combat bias and unfairness in AI",https://www.reddit.com/r/MachineLearning/comments/8tynn3/microsoft_improves_facial_recognition_technology/,myinnerbanjo,1530005462,,1,1
1496,2018-6-26,2018,6,26,18,8typmr,AI Has a Race Problem,https://www.reddit.com/r/MachineLearning/comments/8typmr/ai_has_a_race_problem/,myinnerbanjo,1530006185,,1,1
1497,2018-6-26,2018,6,26,18,8tyq8e,Tool to generate synthetic datasets,https://www.reddit.com/r/MachineLearning/comments/8tyq8e/tool_to_generate_synthetic_datasets/,giganu,1530006391,What are the best tools or libraries to generate realistic time series datasets for machine learning. Thanks,1,1
1498,2018-6-26,2018,6,26,18,8tyseh,My ct st COS2200D,https://www.reddit.com/r/MachineLearning/comments/8tyseh/my_ct_st_cos2200d/,HangNguyen1111,1530007178,,1,1
1499,2018-6-26,2018,6,26,19,8tyuas,"My o  m nng sn Wile 200 o nhanh, chnh xc",https://www.reddit.com/r/MachineLearning/comments/8tyuas/my_o__m_nng_sn_wile_200_o_nhanh_chnh_xc/,HangNguyen1111,1530007815,,1,1
1500,2018-6-26,2018,6,26,19,8tyvh4,[P] Machine Learning with ML.NET  Solving Real-World Regression Problem (Bike Sharing Demands),https://www.reddit.com/r/MachineLearning/comments/8tyvh4/p_machine_learning_with_mlnet_solving_realworld/,RubiksCodeNMZ,1530008182,,0,4
1501,2018-6-26,2018,6,26,19,8tyw1u,How to build a business card reader using Google Cloud Data APIs,https://www.reddit.com/r/MachineLearning/comments/8tyw1u/how_to_build_a_business_card_reader_using_google/,Mattrt123,1530008364,,1,1
1502,2018-6-26,2018,6,26,19,8tyw7o,"My nghin vt ngh lin hon inox NG-320 S dng ng c 3 - 7kw, 1pha hoc 3 pha cho nng sut: 150  300 kg/gi (20 kg / 1 m).",https://www.reddit.com/r/MachineLearning/comments/8tyw7o/my_nghin_vt_ngh_lin_hon_inox_ng320_s_dng/,HangNguyen1111,1530008419,,1,1
1503,2018-6-26,2018,6,26,19,8tyy67,My xay nghin ngh ti inox HMNT 02 C th nghin c khong 70kg n 90 kg ngh trong mt gi,https://www.reddit.com/r/MachineLearning/comments/8tyy67/my_xay_nghin_ngh_ti_inox_hmnt_02_c_th/,HangNguyen1111,1530009090,,1,1
1504,2018-6-26,2018,6,26,19,8tz1w0,[R] GUI-fying the Machine Learning Workflow: Towards Rapid Discovery of Viable Pipelines,https://www.reddit.com/r/MachineLearning/comments/8tz1w0/r_guifying_the_machine_learning_workflow_towards/,digitalson,1530010317,,0,1
1505,2018-6-26,2018,6,26,20,8tz4kk,STILL Steds Forklifts manual,https://www.reddit.com/r/MachineLearning/comments/8tz4kk/still_steds_forklifts_manual/,Mypremiummanual,1530011179,,1,1
1506,2018-6-26,2018,6,26,20,8tzb7m,[R] 10 Examples of How to Use Statistical Methods in a Machine Learning Project,https://www.reddit.com/r/MachineLearning/comments/8tzb7m/r_10_examples_of_how_to_use_statistical_methods/,molode,1530013132,,0,1
1507,2018-6-26,2018,6,26,22,8tztpi,Machine Learning Introduction by the European Space Agency,https://www.reddit.com/r/MachineLearning/comments/8tztpi/machine_learning_introduction_by_the_european/,alfileres1,1530018158,[removed],1,1
1508,2018-6-26,2018,6,26,22,8tzw8o,[P] Machine Learning Lectures at the European Space Agency (ESA) in 2018,https://www.reddit.com/r/MachineLearning/comments/8tzw8o/p_machine_learning_lectures_at_the_european_space/,alfileres1,1530018784,"In 2018, The European Space Agency (ESA) organized a series of 6 lectures on Machine Learning at the European Space Operations Centre (ESOC). This repository contains the lectures resources: presentations, notebooks and links to the videos (presentation and hands-on): [https://github.com/jmartinezheras/2018-MachineLearning-Lectures-ESA](https://github.com/jmartinezheras/2018-MachineLearning-Lectures-ESA) ",2,6
1509,2018-6-26,2018,6,26,22,8tzzf0,[R] DARTS: Differentiable Architecture Search,https://www.reddit.com/r/MachineLearning/comments/8tzzf0/r_darts_differentiable_architecture_search/,Icko_,1530019522,,13,30
1510,2018-6-26,2018,6,26,22,8u02u9,[Project] Beginner asking for advice on a 'game bot' project.,https://www.reddit.com/r/MachineLearning/comments/8u02u9/project_beginner_asking_for_advice_on_a_game_bot/,Thybert,1530020325,"TLDR; I understand this post is not of the level you guys are used to, but I hope you want to take the tome to help me. Im a ML noob that needs direction on how to train a NN for a Bejeweled style game. Ive looked into Q-Learning, RL and MCTS but am confused, mainly because of the nr of possible states for this game seems to be too big (64^8 possible grid positions). Am I interpreting above mentioned techniques in an uncorrect manner? What is your advice? What would be the best way to implement such a bot, and how could I learn to do so? 

Hi all,

**Background**
Im relatively new to the ML field; only started studying AI this year at uni. The stuff they teach at school is very theoretical and basic. I understand this is nescesarry, but I really want to get my hands dirty. Already did some work on the basic stuff like MNIST and spoken digits datasets, but I want to delve deeper in more sophistocated techniques. Got decent Python coding skills

**The Project**
I want to make a game bot for the android game ""Zookeeper Battle"" using deep learning. This game is like Bejeweled where you switch tiles in a grid to make combinations. 

**What I have**
- Win32api functions for controlling Windows (drags, clicks, etc)
- A way of recognizing the grid and turning it into a Numpy array representation
- A way of making moves using Win32api
- A basic main() function

**Where Im stuck**
Im basically stuck at 'the brain' of the bot: hoe to select *which* move should be carried out. How do I train a NN for such a game? Where do I start? If i use RL, I need to come up with a way of constructing a 'reward'. A thing that bugs me as well is the fact that the nr of states seems huge; 64^8 board positions which would lead to a policy table with an insane amount of rows. Or am I misinterpreting 'states'? Shouls I make a preselection of possible moved and go from there?

Ive got so many questions but am determined to make this work. And no, I would rather not try by starting with something easier. I think I tend to learn more from taking on something difficult right away.

Help/ideas/advice/resources would be greatly appreciated!",5,0
1511,2018-6-26,2018,6,26,23,8u0ae1,[D] Tensorflow: The Confusing Parts (by Google Brain resident),https://www.reddit.com/r/MachineLearning/comments/8u0ae1/d_tensorflow_the_confusing_parts_by_google_brain/,baylearn,1530022054,,97,389
1512,2018-6-26,2018,6,26,23,8u0blf,Deep Learning Models and Code for Pose Estimation,https://www.reddit.com/r/MachineLearning/comments/8u0blf/deep_learning_models_and_code_for_pose_estimation/,kohjingyu,1530022327,,1,1
1513,2018-6-26,2018,6,26,23,8u0c70,[D] Deep Learning Models and Code for Pose Estimation,https://www.reddit.com/r/MachineLearning/comments/8u0c70/d_deep_learning_models_and_code_for_pose/,kohjingyu,1530022448,,3,4
1514,2018-6-26,2018,6,26,23,8u0ceo,"Experience Software developer - Beginner in ML, asking for career advice",https://www.reddit.com/r/MachineLearning/comments/8u0ceo/experience_software_developer_beginner_in_ml/,Ao_Null,1530022493,[removed],1,1
1515,2018-6-26,2018,6,26,23,8u0kal,Free Web Seminar - Data Science in 30 Minutes: Why Big Data Needs Thick Data with Tricia Wang,https://www.reddit.com/r/MachineLearning/comments/8u0kal/free_web_seminar_data_science_in_30_minutes_why/,redditman09876543,1530024221,[removed],1,1
1516,2018-6-26,2018,6,26,23,8u0na3,will AI ever develop culture?,https://www.reddit.com/r/MachineLearning/comments/8u0na3/will_ai_ever_develop_culture/,JoachimOfFiore,1530024848,,1,1
1517,2018-6-26,2018,6,26,23,8u0nws,Categorical Data Comparison,https://www.reddit.com/r/MachineLearning/comments/8u0nws/categorical_data_comparison/,largecontainer95,1530024988,"Hi, I have two categorical data sets that I wish to compare. The data set consists of a probability reading vs. a letter reading. This image illustrates it with the red and green lines: https://imgur.com/a/Sf2OjOa

What suggestions do you have to compare the two data sets - the area overlap perhaps? Any other ideas? Thanks.",1,1
1518,2018-6-26,2018,6,26,23,8u0obe,BayArea! The AI Saturdays Meetup is Back at Santa Clara!,https://www.reddit.com/r/MachineLearning/comments/8u0obe/bayarea_the_ai_saturdays_meetup_is_back_at_santa/,ramML,1530025072,[removed],1,1
1519,2018-6-27,2018,6,27,0,8u0rcl,[N] BayArea AI Saturdays Meetup at Santa Clara,https://www.reddit.com/r/MachineLearning/comments/8u0rcl/n_bayarea_ai_saturdays_meetup_at_santa_clara/,ramML,1530025696,"Hey, guys

Looking forward to meet fellow ML Engineers/Enthusiasts/Researchers for an AI Saturdays session at Santa Clara!

More details: [https://www.meetup.com/AI-Saturdays-SF-Bay-Area-Chapter/events/dlxwvpyxkbsb/](https://www.meetup.com/AI-Saturdays-SF-Bay-Area-Chapter/events/dlxwvpyxkbsb/)",0,4
1520,2018-6-27,2018,6,27,0,8u0rfm,Neural Networks that Creates Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/8u0rfm/neural_networks_that_creates_neural_networks/,samer201001,1530025710,[removed],1,1
1521,2018-6-27,2018,6,27,0,8u0tr2,[Discussion] Categorical Data Comparison,https://www.reddit.com/r/MachineLearning/comments/8u0tr2/discussion_categorical_data_comparison/,largecontainer95,1530026196,"Hi, I have two categorical data sets that I wish to compare. The data set consists of a probability reading vs. a letter reading. This image illustrates it with the red and green lines: https://imgur.com/a/Sf2OjOa
What suggestions do you have to compare the two data sets - the area overlap perhaps? Any other ideas? Thanks.",1,0
1522,2018-6-27,2018,6,27,0,8u0upo,Tutorial: Convolutional Neural Nets Using Multi-Party Computation,https://www.reddit.com/r/MachineLearning/comments/8u0upo/tutorial_convolutional_neural_nets_using/,iamtrask,1530026405,,1,6
1523,2018-6-27,2018,6,27,0,8u0v01,Neural Networks that makes Neural Networks [Discussion],https://www.reddit.com/r/MachineLearning/comments/8u0v01/neural_networks_that_makes_neural_networks/,samer201001,1530026465,[removed],0,1
1524,2018-6-27,2018,6,27,0,8u0wxx,[R] ML Kit on iOS and how it performs against Core ML,https://www.reddit.com/r/MachineLearning/comments/8u0wxx/r_ml_kit_on_ios_and_how_it_performs_against_core/,bryant1410,1530026871,,0,2
1525,2018-6-27,2018,6,27,0,8u15eb,[P] Robust ML: A community-run reference for state-of-the-art adversarial example defenses,https://www.reddit.com/r/MachineLearning/comments/8u15eb/p_robust_ml_a_communityrun_reference_for/,anishathalye,1530028622,,9,30
1526,2018-6-27,2018,6,27,1,8u1c5e,Impala implementation from DeepMind,https://www.reddit.com/r/MachineLearning/comments/8u1c5e/impala_implementation_from_deepmind/,shagunsodhani,1530029964,,1,1
1527,2018-6-27,2018,6,27,1,8u1chu,[R] Impala implementation from DeepMind,https://www.reddit.com/r/MachineLearning/comments/8u1chu/r_impala_implementation_from_deepmind/,shagunsodhani,1530030038,,1,53
1528,2018-6-27,2018,6,27,1,8u1ek1,How is the ICARCV conference? Does anyone has any idea about how good it is?,https://www.reddit.com/r/MachineLearning/comments/8u1ek1/how_is_the_icarcv_conference_does_anyone_has_any/,ZER_0_NE,1530030462,[removed],1,1
1529,2018-6-27,2018,6,27,1,8u1li4,[P] Solving sparse-reward tasks with Curiosity,https://www.reddit.com/r/MachineLearning/comments/8u1li4/p_solving_sparsereward_tasks_with_curiosity/,wei_jok,1530031818,,1,15
1530,2018-6-27,2018,6,27,2,8u1xgc,"Here it goes! First blog on linear regression in the series of ""ML from scratch""! Please leave your comments/reactions down there :)",https://www.reddit.com/r/MachineLearning/comments/8u1xgc/here_it_goes_first_blog_on_linear_regression_in/,ankitshubham97,1530034179,,1,1
1531,2018-6-27,2018,6,27,3,8u2ezb,Singularity Universitys Pascal Finette on Why VCs Suck at SciFi Tech Investing and Why AI and Synthetic Biology are the Industries of the Future,https://www.reddit.com/r/MachineLearning/comments/8u2ezb/singularity_universitys_pascal_finette_on_why_vcs/,The_Syndicate_VC,1530037653,[removed],1,1
1532,2018-6-27,2018,6,27,4,8u2qt8,[D] What is the best way to handle images of varying dimentions that are to be passed to CNNs ?.,https://www.reddit.com/r/MachineLearning/comments/8u2qt8/d_what_is_the_best_way_to_handle_images_of/,infinitylogesh,1530040101,"My dataset/problem has images of extreme size differences - like 200 X 900 , 700 X 100 , 300 X 400 etc. What would be the best way to pre-process these images to fit the standard square dimensions (example - 299 x 299 ). Please note that I have already tried resizing with zero padding maintaining the aspect ratio. Kindle let me know if there are any other effective methods.",0,1
1533,2018-6-27,2018,6,27,4,8u2zy1,Building an Instagram Chatbot,https://www.reddit.com/r/MachineLearning/comments/8u2zy1/building_an_instagram_chatbot/,Boxxcar17,1530042026,,1,1
1534,2018-6-27,2018,6,27,4,8u32wa,[P] Building an Instagram Chatbot,https://www.reddit.com/r/MachineLearning/comments/8u32wa/p_building_an_instagram_chatbot/,Boxxcar17,1530042631,,5,2
1535,2018-6-27,2018,6,27,5,8u3i57,How do i convert my image to desired format for grabcut algorithm in opencv /Python 3,https://www.reddit.com/r/MachineLearning/comments/8u3i57/how_do_i_convert_my_image_to_desired_format_for/,code_bot,1530045634,,1,1
1536,2018-6-27,2018,6,27,6,8u3q5z,Msc Question,https://www.reddit.com/r/MachineLearning/comments/8u3q5z/msc_question/,LuWIT,1530047312,"Hello Reddit! I am looking for some career advice from you, the best 

I am an undergraduate in management, and for the last two years have been working on data analysis. I am interested in doing a Master in Artificial Intelligence and Machine Learning. I dont pick favourites with my countries, so Europe/USA/Canada/Australia any of them work for me. 

Now, I was confident in joining the master until I stumbled across reddit and started reading your masters recommendations. I feel I lack some strong mathematical background to join the fray, and seriously, I dont even know the professors you mention. Still, most masters entry  requirements are *low*. For example, I could apply to University of Edinburgh, since I meet the 60 credits in maths (even though  I am an undergrad in management). I have not lost touch with programming, but I would not consider myself an expert.

For those who are currently in a master (or have been) what do you think of the requirements? Do you think a strong mathematical and programming background is needed? Or did your master help you get to the required level?

In Advance, thank you

A panicking analyst",1,1
1537,2018-6-27,2018,6,27,6,8u3t15,Msc Question - Entry Requirements,https://www.reddit.com/r/MachineLearning/comments/8u3t15/msc_question_entry_requirements/,LuWIT,1530047911,[removed],1,1
1538,2018-6-27,2018,6,27,8,8u4xf8,I work in the healthcare industry as a SQL reporting monkey and I'm interested in starting a machine learning project in my current role...,https://www.reddit.com/r/MachineLearning/comments/8u4xf8/i_work_in_the_healthcare_industry_as_a_sql/,rekon32,1530057161,to predict member claims. What learning resource would you recommend to learn R and Machine Learning. I want to learn R over Python because my company policy is R for this type of work and I would like to follow it.,1,1
1539,2018-6-27,2018,6,27,8,8u4ygd,[D] Classifying objects using the *best* image patch,https://www.reddit.com/r/MachineLearning/comments/8u4ygd/d_classifying_objects_using_the_best_image_patch/,anonDogeLover,1530057423,"I'm looking for work that jointly learns the best image patch(s) to look at in an image and how to classify the image based on that patch(s), excluding the non-patch regions. Is there anything like that?",5,7
1540,2018-6-27,2018,6,27,13,8u6mkn,[P] A Clean Tool for Distributed Architecture Search (Ray Tune),https://www.reddit.com/r/MachineLearning/comments/8u6mkn/p_a_clean_tool_for_distributed_architecture/,rayspear,1530073122,,2,28
1541,2018-6-27,2018,6,27,13,8u6utw,"Kinh nghim t A n Z v mua t ng siu th vi cht lng tt nht, vi cc cch chn t ng sieu th",https://www.reddit.com/r/MachineLearning/comments/8u6utw/kinh_nghim_t_a_n_z_v_mua_t_ng_siu_th/,hoangngan123,1530075515,,1,1
1542,2018-6-27,2018,6,27,14,8u6wo4,[D] What are practical use cases for Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/8u6wo4/d_what_are_practical_use_cases_for_reinforcement/,Sig_Luna,1530076061,"Reinforcement Learning is very popular right now and some of the most popular research - see OpenAI 5 - is based around it.

But for what will RL be used practically in the future? Is it just the premise of AGI that makes this interesting?",35,32
1543,2018-6-27,2018,6,27,15,8u7d2r,Need some clarification on OpenAI's baseline RL algorithms,https://www.reddit.com/r/MachineLearning/comments/8u7d2r/need_some_clarification_on_openais_baseline_rl/,Far_East_Beast,1530081207,[removed],1,1
1544,2018-6-27,2018,6,27,15,8u7h5i,How I can make multiple different variations of one text using machine learning?,https://www.reddit.com/r/MachineLearning/comments/8u7h5i/how_i_can_make_multiple_different_variations_of/,UserWithComputer,1530082584,[removed],1,1
1545,2018-6-27,2018,6,27,16,8u7p70,There is now a backprop principle for deep learning on quantum computers,https://www.reddit.com/r/MachineLearning/comments/8u7p70/there_is_now_a_backprop_principle_for_deep/,Gigav3rd,1530085240,,13,43
1546,2018-6-27,2018,6,27,18,8u84ew,Automating company information search on Google (merger acquisitions) using NLP &amp; ML,https://www.reddit.com/r/MachineLearning/comments/8u84ew/automating_company_information_search_on_google/,inspector_shinde,1530090656,[removed],1,1
1547,2018-6-27,2018,6,27,18,8u88nv,[R] Evolutionary design of context-free attentional operators,https://www.reddit.com/r/MachineLearning/comments/8u88nv/r_evolutionary_design_of_contextfree_attentional/,molode,1530092101,,0,1
1548,2018-6-27,2018,6,27,18,8u8bgw,Machine Learning Course | Artificial Intelligence Course,https://www.reddit.com/r/MachineLearning/comments/8u8bgw/machine_learning_course_artificial_intelligence/,nandiniravichandran,1530093079,,1,1
1549,2018-6-27,2018,6,27,20,8u8ol7,UC Berkeley Open Sources Largest Self-Driving Dataset,https://www.reddit.com/r/MachineLearning/comments/8u8ol7/uc_berkeley_open_sources_largest_selfdriving/,bhediyakadushmankobi,1530097323,,13,524
1550,2018-6-27,2018,6,27,20,8u8oq2,Learn Mathematical Foundation For Machine Learning and AI,https://www.reddit.com/r/MachineLearning/comments/8u8oq2/learn_mathematical_foundation_for_machine/,KiranKiller,1530097367,,1,1
1551,2018-6-27,2018,6,27,21,8u94c6,How can I create an algorithm in Python that will compare to average values for a specific subset?,https://www.reddit.com/r/MachineLearning/comments/8u94c6/how_can_i_create_an_algorithm_in_python_that_will/,Xilc,1530101755,[removed],1,1
1552,2018-6-27,2018,6,27,21,8u95vv,Understanding The Human Process in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8u95vv/understanding_the_human_process_in_machine/,Zeolearn,1530102159,,1,1
1553,2018-6-27,2018,6,27,21,8u96d1,Legal Data Talent War Heats Up With Kennedys Hires,https://www.reddit.com/r/MachineLearning/comments/8u96d1/legal_data_talent_war_heats_up_with_kennedys_hires/,ArtificialLawyer,1530102293,,1,1
1554,2018-6-27,2018,6,27,21,8u96iw,Build your own antivirus using machine learning in just 5 minutes,https://www.reddit.com/r/MachineLearning/comments/8u96iw/build_your_own_antivirus_using_machine_learning/,sagar03d,1530102333,,1,1
1555,2018-6-27,2018,6,27,21,8u98rx,[D] How can I compare averages in a machine learning model for specific subsets?,https://www.reddit.com/r/MachineLearning/comments/8u98rx/d_how_can_i_compare_averages_in_a_machine/,Xilc,1530102929,"I'm programming in Python 3 with scikit-learn. I have sales data for different branch locations and each of them as metrics that are Aggregates basically that use location averages such as average revenue per day. So if a sales associate has a lower average revenue per day than another sales associate, they might be in the red while another sales associate who has more than the average arpd for the branch location might be in the black.



How do you create an algorithm that will compare averages for specific substance like branch locations? Could I have a column that has branch location numbers and feeds into it the arpd of every associate every month in order to create that average and then compare future entries to what that average is? I'm kind of confused",0,1
1556,2018-6-27,2018,6,27,21,8u9a25,Understanding The Human Process in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8u9a25/understanding_the_human_process_in_machine/,Zeolearn,1530103262,[removed],1,1
1557,2018-6-27,2018,6,27,22,8u9tpk,[News] Talking to Google Duplex: Googles human-like phone AI feels revolutionary,https://www.reddit.com/r/MachineLearning/comments/8u9tpk/news_talking_to_google_duplex_googles_humanlike/,tehdog,1530107903,,13,0
1558,2018-6-27,2018,6,27,23,8u9vk0,[P] The Illustrated Transformer -- a visual look of the mechanics of the model from Attention is All You Need,https://www.reddit.com/r/MachineLearning/comments/8u9vk0/p_the_illustrated_transformer_a_visual_look_of/,nortab,1530108318,,1,1
1559,2018-6-27,2018,6,27,23,8ua3ba,[P] How many relevances in information retrieval?,https://www.reddit.com/r/MachineLearning/comments/8ua3ba/p_how_many_relevances_in_information_retrieval/,villasv,1530110011,,1,2
1560,2018-6-27,2018,6,27,23,8ua63r,How to become a professional in AI and ML?,https://www.reddit.com/r/MachineLearning/comments/8ua63r/how_to_become_a_professional_in_ai_and_ml/,SuccessfulLeadership,1530110603,[removed],1,1
1561,2018-6-28,2018,6,28,0,8uae39,[P] Fast clustering techniques where you don't need to know k,https://www.reddit.com/r/MachineLearning/comments/8uae39/p_fast_clustering_techniques_where_you_dont_need/,Pawnbrake,1530112293,"[K-means](https://en.wikipedia.org/wiki/K-means_clustering) is the go-to fast clustering algorithm.  However, you need to know the k (the number of clusters) before you use k-means clustering.  

I have a large dataset that requires clustering.  What is a fast clustering algorithm that I can use where I do not have to know about k beforehand?  I am prioritizing speed over accuracy.  ",0,1
1562,2018-6-28,2018,6,28,0,8uaqwd,"Simple Questions Thread June 27, 2018",https://www.reddit.com/r/MachineLearning/comments/8uaqwd/simple_questions_thread_june_27_2018/,AutoModerator,1530114942,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",1,1
1563,2018-6-28,2018,6,28,1,8uau50,[D] Interactive semi-supervised learning?,https://www.reddit.com/r/MachineLearning/comments/8uau50/d_interactive_semisupervised_learning/,Valiox,1530115568,"Take a semi-supervised learning setting where I have 2k labeled samples and 100k unlabeled ones. Labels are created manually and it's time-consuming (e.g. the case of semantic segmentation). I can make tools to improve on the time it takes to make labels, but I also know that my currently trained model already yields somewhat correct outputs. Knowing this, I want to use my model to generate initial labels and improve them by hand. This should take less time than creating labels from scratch. I also want this to be in an online fashion, so that the model may improve as I go.

This approach seems very intuitive, and most people working in ML have probably already thought about it. However I don't see popular articles or paper that make use of this approach. I see the following drawbacks:

- Creation of a bias in the labels, especially complex ones. You're likely to accept labels created by the model as they are when they're sometimes partially correct.

- It's not easy to obtain a full sample efficiency: should older samples be seen in training more often than new ones? Issue of mode collapse.

- Improvements in the model become slower with higher orders in the amount of data, i.e. the model improves slower than the time you spend labeling is cut back. In other words, it doesn't scale for problems that require a lot of data.

And the attractive parts:

- Efficient manual labeling, potentially more so than specialized tools.

- ""Inside"" look at the performance of the model on unseen data (good for debugging).

- Good idea of how much data is needed to get good results, and when to stop.

I'm very interested in what you think about this. Your opinion on the legitimacy of the method, similar alternatives and existing research on the topic.
",8,12
1564,2018-6-28,2018,6,28,1,8uaxbj,Is this build good for who's new for machine learning ?,https://www.reddit.com/r/MachineLearning/comments/8uaxbj/is_this_build_good_for_whos_new_for_machine/,westdabestdb,1530116174,,1,1
1565,2018-6-28,2018,6,28,1,8ub9ub,Sound Clip Recognition,https://www.reddit.com/r/MachineLearning/comments/8ub9ub/sound_clip_recognition/,heloooza,1530118616,[removed],1,1
1566,2018-6-28,2018,6,28,2,8ubkrl,[D] Improvement to the AlphaZero Value Target,https://www.reddit.com/r/MachineLearning/comments/8ubkrl/d_improvement_to_the_alphazero_value_target/,vishvananda,1530120689,"Our team has done a reimplementation of the AlphaZero algorithm, and we have discovered quite a few tweaks that have improved either performance or training speed. We will be discussing more of them in the near future, but potentially the most interesting one is a modification to the training target for the neural network's value output.

The very brief overview is to train the network against the Q value from the simulations at each position in addition to the result of the game. I'm very curious if other implementations of the AlphaZero algorithm have experimented with something like this.

There is a more detailed explanation in our post on Medium: https://medium.com/oracledevs/lessons-from-alphazero-part-4-improving-the-training-target-6efba2e71628",18,30
1567,2018-6-28,2018,6,28,3,8uc9u5,"[N] Python eats away at R: Top Software for Analytics, Data Science, Machine Learning in 2018: Trends and Analysis - KDNuggets.com",https://www.reddit.com/r/MachineLearning/comments/8uc9u5/n_python_eats_away_at_r_top_software_for/,redditman09876543,1530125519,,19,33
1568,2018-6-28,2018,6,28,5,8ucvam,[N] Great In Depth Post About OpenFive (DOTA2 RL Agent) By OpenAI,https://www.reddit.com/r/MachineLearning/comments/8ucvam/n_great_in_depth_post_about_openfive_dota2_rl/,TebbaVonMathenstein,1530129867,,5,12
1569,2018-6-28,2018,6,28,5,8ud4to,Google AI: Self-Supervised Tracking via Video Colorization,https://www.reddit.com/r/MachineLearning/comments/8ud4to/google_ai_selfsupervised_tracking_via_video/,chenmy17,1530131839,,1,1
1570,2018-6-28,2018,6,28,5,8ud9of,[Discussion] Possible to train a Neural Network with another Neural Network that's capable of telling the difference between robot-output and human-output?,https://www.reddit.com/r/MachineLearning/comments/8ud9of/discussion_possible_to_train_a_neural_network/,nyxeka,1530132839,"Let's say I wanted speech synthesis, so I generate it using some cheap text-to-speech software.

Then I create a model (Model A) that can tell the difference between human speech and this cheap text-to-speech software 95% of the time.

Then I create another model, say Model B, that takes the cheap, synthesized voice and makes it sound human. It does this by using Model A to train - it changes a bit every training step until it gets a ""RESULT: HUMAN"" (1 instead of 0) from Model A every time it outputs something.

Then, say we do another model(C) that takes that(B) as input, and compares it to _real_ human speech again, and tells us which is which with high accuracy (if it's still possible?). Then we do another model (D) that takes model B as input, and trains using Model C until Model C also says it always sounds human.

Maybe we could do this a few more times, or have other models that are specifically designed to take human speech output from B or D and make it sound happy, sad, excited, etc... using the exact same method (would imagine this would be a spectrum (0-10), like a rainbow, one colour for each emotion, and the spectrum being an input to the final layer, maybe have some more spectrums for things like angry-happy, old, tired, young, male, female, etc...

I've thought up something to sort of test this using the mnist-tensorflow tutorial - it would take a 10-length array and output a 32x32 image and use the mnist digit analyzing model to train itself. Eventually would add sliders as an input to test ""hastily-written"" vs ""slowly written"" and ""hard to read"" vs ""easy to read"", and stuff like that, but would be a pain in the ass to sort all that without a bunch of help.

**TL,DR**: possible to train a neural network to notice the difference between human and robot output, and then use that to train another neural network until it generates output that the first NN always says is human?

Thoughts?",5,1
1571,2018-6-28,2018,6,28,5,8udaac,"Has anyone used Eager Execution, TensorFlow? Any thoughts?",https://www.reddit.com/r/MachineLearning/comments/8udaac/has_anyone_used_eager_execution_tensorflow_any/,ekubya,1530132973,[removed],1,1
1572,2018-6-28,2018,6,28,5,8uday2,#NLProc Reddit Reading Group,https://www.reddit.com/r/MachineLearning/comments/8uday2/nlproc_reddit_reading_group/,BabaRivers,1530133098,[removed],2,1
1573,2018-6-28,2018,6,28,6,8udcm0,[D] Common structure for reasoning by analogy (~ evolved independently) in birds and mammals,https://www.reddit.com/r/MachineLearning/comments/8udcm0/d_common_structure_for_reasoning_by_analogy/,phobrain,1530133441,"Is there a detailed comparison of common neural density structure
between the mammalian prefrontal cortex and birds' corresponding 'nidopallium caudolaterale'?  Both support reasoning by analogy for decision-making. Recent work seems to be mostly paywalled.

https://www.revolvy.com/main/index.php?s=Nidopallium

    The experiment sought to measure the densities of various
    neurotransmitter receptors in both the avian NCL and the
    human prefrontal cortex, using quantitative in-vitro receptor
    autoradiography.  It was found that the NCL contained lower
    absolute quantities of these neuronal receptors. However, 
    the experiment also revealed that the relative densities of 
    these receptors in both organisms were surprisingly similar.
    With this, there is the possible implication that the capability 
    for such sophisticated mental processes in these structures is
    reliant on the receptor architecture of the neurons which 
    comprise them.

Background: 
http://www.iflscience.com/plants-and-animals/crow-brains-reveal-secrets-their-intelligence/",0,0
1574,2018-6-28,2018,6,28,6,8uddyv,From binary to multi-class,https://www.reddit.com/r/MachineLearning/comments/8uddyv/from_binary_to_multiclass/,TotalTadpole,1530133737,[removed],1,1
1575,2018-6-28,2018,6,28,6,8udmgg,[D] Analysis of OpenAI's DOTA2 AI and what being superhuman actually means,https://www.reddit.com/r/MachineLearning/comments/8udmgg/d_analysis_of_openais_dota2_ai_and_what_being/,wei_jok,1530135521,,44,103
1576,2018-6-28,2018,6,28,7,8ue3mz,[N] IBM Builds the World's Largest Facial Image Dataset to Battle Bias in AI,https://www.reddit.com/r/MachineLearning/comments/8ue3mz/n_ibm_builds_the_worlds_largest_facial_image/,gwen0927,1530139352,,0,1
1577,2018-6-28,2018,6,28,8,8uek4f,Announcing Public Git Archive for Machine Learning on Code,https://www.reddit.com/r/MachineLearning/comments/8uek4f/announcing_public_git_archive_for_machine/,vcoisne,1530143297,,1,1
1578,2018-6-28,2018,6,28,9,8uevbw,[1806.07912] Resource-Efficient Neural Architect,https://www.reddit.com/r/MachineLearning/comments/8uevbw/180607912_resourceefficient_neural_architect/,Intelligent_Pass,1530146211,,1,5
1579,2018-6-28,2018,6,28,10,8uf1le,[R] Guided evolutionary strategies: escaping the curse of dimensionality in random search (Google Brain),https://www.reddit.com/r/MachineLearning/comments/8uf1le/r_guided_evolutionary_strategies_escaping_the/,inarrears,1530147731,,3,20
1580,2018-6-28,2018,6,28,10,8uf5j9,Looking for A good tutorial on using deep learning to solve medium-hard problem using TensorFlow library,https://www.reddit.com/r/MachineLearning/comments/8uf5j9/looking_for_a_good_tutorial_on_using_deep/,CathyQian,1530148715,[removed],1,1
1581,2018-6-28,2018,6,28,10,8uf8a9,DAE feel like they are not good enough to create practical networks but have just enough knowledge to know how much they are missing out?,https://www.reddit.com/r/MachineLearning/comments/8uf8a9/dae_feel_like_they_are_not_good_enough_to_create/,inkplay_,1530149440,[removed],1,1
1582,2018-6-28,2018,6,28,11,8ufo5o,[D] Backpropagation demo,https://www.reddit.com/r/MachineLearning/comments/8ufo5o/d_backpropagation_demo/,sksq9,1530153507,,0,1
1583,2018-6-28,2018,6,28,11,8ufoio, ? ? ?,https://www.reddit.com/r/MachineLearning/comments/8ufoio//,Woodworking94,1530153597,,1,1
1584,2018-6-28,2018,6,28,11,8ufshh,[D] Tutorial on Causal Inference and Counterfactual Reasoning,https://www.reddit.com/r/MachineLearning/comments/8ufshh/d_tutorial_on_causal_inference_and_counterfactual/,sksq9,1530154588,,1,43
1585,2018-6-28,2018,6,28,12,8ug1yh,image net site down,https://www.reddit.com/r/MachineLearning/comments/8ug1yh/image_net_site_down/,popsumbong,1530157057,"Hey. I'm trying to download the imagenet-1k but it looks their site is down and according to the source I read I need an image-net account to download the dataset. 

Is there an alternative place I could download the dataset from?",1,1
1586,2018-6-28,2018,6,28,12,8ug5p5,Major/Minor for using AI/data analytics in Finance,https://www.reddit.com/r/MachineLearning/comments/8ug5p5/majorminor_for_using_aidata_analytics_in_finance/,Scoop_of_Bryy,1530158049,"Hey guys, I'm currently a junior in college studying Finance and plan to minor in Computer Science. Im doing this with the goal to develop or at least be able to use/understand machine learning applications that analyze/ predict stock and crypto prices and trends. Am I setting myself up correctly for this? I heard going into MIS is also viable as well as statistics as they are good for data analytics. Looking for some recommendations ",1,1
1587,2018-6-28,2018,6,28,15,8ugrt1,Best Deep Learning Papers to get on the list to read,https://www.reddit.com/r/MachineLearning/comments/8ugrt1/best_deep_learning_papers_to_get_on_the_list_to/,asifrazzaq1988,1530165892,,2,1
1588,2018-6-28,2018,6,28,15,8ugyjc,XiaoMi/mace,https://www.reddit.com/r/MachineLearning/comments/8ugyjc/xiaomimace/,pilooch,1530168485,,1,1
1589,2018-6-28,2018,6,28,16,8uh2yz,"[P] The Illustrated Transformer - a visual look at the model from ""Attention is All You Need""",https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/,nortab,1530170113,,3,29
1590,2018-6-28,2018,6,28,17,8uhg3t,[D] Is applications of machine learning an academic area of research?,https://www.reddit.com/r/MachineLearning/comments/8uhg3t/d_is_applications_of_machine_learning_an_academic/,question_5040,1530174314,"Apologies if it's not a very clear title, by ""Applications"" I mean taking existing ML techniques and applying them to new areas. I thought I saw a Journal that concerned itself with this but I might of been wrong.

Thanks very much in advance.",4,1
1591,2018-6-28,2018,6,28,17,8uhgui,[P] How RealtimeCRM built a business card reader using machine learning,https://www.reddit.com/r/MachineLearning/comments/8uhgui/p_how_realtimecrm_built_a_business_card_reader/,Mattrt123,1530174633,,1,0
1592,2018-6-28,2018,6,28,18,8uhpak,[R] The challenge of realistic music generation: modelling raw audio at scale (discrete AE),https://www.reddit.com/r/MachineLearning/comments/8uhpak/r_the_challenge_of_realistic_music_generation/,Isnogud_,1530178207,,4,12
1593,2018-6-28,2018,6,28,18,8uhqol,[D] Keras vs Pytorch - in depth comparison of opposing approaches,https://www.reddit.com/r/MachineLearning/comments/8uhqol/d_keras_vs_pytorch_in_depth_comparison_of/,quantumlyrics,1530178768,,29,124
1594,2018-6-28,2018,6,28,19,8ui0xq,The role of machine learning and AI in accounting,https://www.reddit.com/r/MachineLearning/comments/8ui0xq/the_role_of_machine_learning_and_ai_in_accounting/,tektost01,1530181614,,1,1
1595,2018-6-28,2018,6,28,19,8ui2y0,"TensorFlow.js, Machine Learning and Flappy Bird: Frontend AI",https://www.reddit.com/r/MachineLearning/comments/8ui2y0/tensorflowjs_machine_learning_and_flappy_bird/,Apptension,1530182091,,1,1
1596,2018-6-28,2018,6,28,19,8ui5h1,"[P] TensorFlow.js, Machine Learning and Flappy Bird: Frontend AI Experiment",https://www.reddit.com/r/MachineLearning/comments/8ui5h1/p_tensorflowjs_machine_learning_and_flappy_bird/,Apptension,1530182689,,5,10
1597,2018-6-28,2018,6,28,19,8ui6c1,Machine learning,https://www.reddit.com/r/MachineLearning/comments/8ui6c1/machine_learning/,nandiniravichandran,1530182897,,1,1
1598,2018-6-28,2018,6,28,19,8ui90a,A framework to enable machine learning directly on hardware (Disney),https://www.reddit.com/r/MachineLearning/comments/8ui90a/a_framework_to_enable_machine_learning_directly/,nicolasap,1530183543,,1,1
1599,2018-6-28,2018,6,28,20,8uibp4,[Research] A framework to enable machine learning directly on hardware (Disney),https://www.reddit.com/r/MachineLearning/comments/8uibp4/research_a_framework_to_enable_machine_learning/,nicolasap,1530184172,,31,867
1600,2018-6-28,2018,6,28,20,8uidwm,,https://www.reddit.com/r/MachineLearning/comments/8uidwm//,Woodworking94,1530184680,,1,1
1601,2018-6-28,2018,6,28,20,8uiogc,Need Idea for project.,https://www.reddit.com/r/MachineLearning/comments/8uiogc/need_idea_for_project/,yugandhar123,1530187105,[removed],1,1
1602,2018-6-28,2018,6,28,21,8uiq0i,First Steps on Evolutionary Systems and Genetic Programming,https://www.reddit.com/r/MachineLearning/comments/8uiq0i/first_steps_on_evolutionary_systems_and_genetic/,gfrison,1530187441,,1,1
1603,2018-6-28,2018,6,28,21,8uirg7,Need Idea For Project,https://www.reddit.com/r/MachineLearning/comments/8uirg7/need_idea_for_project/,yugandhar123,1530187742," ""\[Project\]"" Want to implement what I learnt with some Image data based project using neural networks. 

Data scraping/mining is not a problem.",1,1
1604,2018-6-28,2018,6,28,21,8uis95,Magazine on Machine Learning and AI,https://www.reddit.com/r/MachineLearning/comments/8uis95/magazine_on_machine_learning_and_ai/,kesh13,1530187903,,1,1
1605,2018-6-28,2018,6,28,21,8uit7e,[P] Early steps with Genetic Programming and multi-objective problems,https://www.reddit.com/r/MachineLearning/comments/8uit7e/p_early_steps_with_genetic_programming_and/,gfrison,1530188092,,0,3
1606,2018-6-28,2018,6,28,21,8uiuzj,A nice introduction for beginners.,https://www.reddit.com/r/MachineLearning/comments/8uiuzj/a_nice_introduction_for_beginners/,Axlemax,1530188464,,1,1
1607,2018-6-28,2018,6,28,21,8uivvu,[N] An Algorithm to Detect Low Blood Pressure During Surgery,https://www.reddit.com/r/MachineLearning/comments/8uivvu/n_an_algorithm_to_detect_low_blood_pressure/,hooba_stank_,1530188646,,1,3
1608,2018-6-28,2018,6,28,21,8uiwjw,51 Job Interview Related Questions of Machine Learning (ML) and Artificial Intelligence (AI),https://www.reddit.com/r/MachineLearning/comments/8uiwjw/51_job_interview_related_questions_of_machine/,aaobihar,1530188787,,1,1
1609,2018-6-28,2018,6,28,22,8ujlch,Could a perceptual loss be introduced in NLP?,https://www.reddit.com/r/MachineLearning/comments/8ujlch/could_a_perceptual_loss_be_introduced_in_nlp/,steuhh,1530193849,[removed],1,1
1610,2018-6-28,2018,6,28,23,8ujpg0,"[N] Weekly Machine Learning Opensource Roundup  June 28, 2018",https://www.reddit.com/r/MachineLearning/comments/8ujpg0/n_weekly_machine_learning_opensource_roundup_june/,stkim1,1530194636,,0,1
1611,2018-6-28,2018,6,28,23,8ujw7b,RapidML library release,https://www.reddit.com/r/MachineLearning/comments/8ujw7b/rapidml_library_release/,mischief_23,1530195931,[removed],1,1
1612,2018-6-28,2018,6,28,23,8ujz8n,Distance learning for a MSc in ML with 2:2 in CS. Any good places?,https://www.reddit.com/r/MachineLearning/comments/8ujz8n/distance_learning_for_a_msc_in_ml_with_22_in_cs/,pas43,1530196536,"So I wanna do a MSc but I need to get a job at the same time. I don't want to pay xxxx and revive rubbish half-assed learning materials.

Anybody got any experience with this or know of someone who has had?

Who has good distance learning materials? And good online resources?

Any questions?

Thanks :)",1,1
1613,2018-6-28,2018,6,28,23,8ujzzx,RapidML,https://www.reddit.com/r/MachineLearning/comments/8ujzzx/rapidml/,mischief_23,1530196683,[removed],1,1
1614,2018-6-28,2018,6,28,23,8uk4gt,[D] Ideas or architectures for a classification problem?,https://www.reddit.com/r/MachineLearning/comments/8uk4gt/d_ideas_or_architectures_for_a_classification/,catosmandros,1530197516,"Hey guys, I'm facing a binary classification problem that I'm not really sure about how to confront.
 
The problem is rather simple to explain: Given the DOM tree of an HTML page, assign a label 0/1 to each node whether is relevant or not to our goal. Maybe could also be seen as a regression one, and assign a probability or likeness to each node, I don't know. Some examples of this could be product gallery extraction from online shops, article content extraction or ad removal.

I suppose that the information the classifier should take into account is: the content, type and attributes of the node together with its position inside the tree to decide if its relevant. 
 I've searched the literature, but I'm not really sure I've found anything relevant. This is not my area of expertise, so pardon me if I've missed some obvious paper or equivalence between problems.

Could anyone point me to prior work or suggest an idea about how to confront it? 

Many thanks in advance!",2,1
1615,2018-6-29,2018,6,29,0,8uk83i,How to get output of a neural network?,https://www.reddit.com/r/MachineLearning/comments/8uk83i/how_to_get_output_of_a_neural_network/,Dyljam1234,1530198206,[removed],1,1
1616,2018-6-29,2018,6,29,0,8ukh4d,Machine Learning Simplified in 4 Minutes  The Research Nest  Medium,https://www.reddit.com/r/MachineLearning/comments/8ukh4d/machine_learning_simplified_in_4_minutes_the/,Ashukr5876,1530199855,,1,1
1617,2018-6-29,2018,6,29,0,8ukooq,[N] IBM Builds the Worlds Largest Facial Image Dataset to Battle Bias in AI,https://www.reddit.com/r/MachineLearning/comments/8ukooq/n_ibm_builds_the_worlds_largest_facial_image/,trcytony,1530201247,,0,1
1618,2018-6-29,2018,6,29,1,8ukqou,How reproducible is deep learning?,https://www.reddit.com/r/MachineLearning/comments/8ukqou/how_reproducible_is_deep_learning/,PorcelainMelonWolf,1530201621,[removed],1,1
1619,2018-6-29,2018,6,29,1,8ukrsa,Why the house always wins? (Monte Carlo simulation),https://www.reddit.com/r/MachineLearning/comments/8ukrsa/why_the_house_always_wins_monte_carlo_simulation/,rohan_joseph93,1530201806,,1,1
1620,2018-6-29,2018,6,29,1,8ul7un,"Last week in Machine Learning: Predicting Earthquakes, Teaching Robots, and more!",https://www.reddit.com/r/MachineLearning/comments/8ul7un/last_week_in_machine_learning_predicting/,Hackdhacker,1530204731,,1,1
1621,2018-6-29,2018,6,29,1,8ul936,[Research] Why the house wins?,https://www.reddit.com/r/MachineLearning/comments/8ul936/research_why_the_house_wins/,rohan_joseph93,1530204952,,3,0
1622,2018-6-29,2018,6,29,2,8ulh2x,Best audio classification model,https://www.reddit.com/r/MachineLearning/comments/8ulh2x/best_audio_classification_model/,Cricco95,1530206280,[removed],1,1
1623,2018-6-29,2018,6,29,2,8ulniu,[R]This New Startup Helps Non-Techies Use Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8ulniu/rthis_new_startup_helps_nontechies_use_machine/,Amigoly,1530207369,,0,1
1624,2018-6-29,2018,6,29,2,8uloc3,Testing Vision APIs at once?,https://www.reddit.com/r/MachineLearning/comments/8uloc3/testing_vision_apis_at_once/,ekubya,1530207502,[removed],1,1
1625,2018-6-29,2018,6,29,2,8ulog2,What's the right choice for developing deep learning models? Cloud or on-prem infrastructure?,https://www.reddit.com/r/MachineLearning/comments/8ulog2/whats_the_right_choice_for_developing_deep/,DeeplyLearning,1530207517,[removed],1,1
1626,2018-6-29,2018,6,29,2,8ulrl7,[D] Choosing Your Deep Learning Infrastructure: The Cloud vs. On-Prem Debate,https://www.reddit.com/r/MachineLearning/comments/8ulrl7/d_choosing_your_deep_learning_infrastructure_the/,yoavz,1530208049,,12,2
1627,2018-6-29,2018,6,29,3,8ulw4o,Want to test more than Vision APIs at once.,https://www.reddit.com/r/MachineLearning/comments/8ulw4o/want_to_test_more_than_vision_apis_at_once/,ekubya,1530208944,[removed],1,1
1628,2018-6-29,2018,6,29,3,8um02c,Can anyone give me a link that shows me how to implement R-CNN for imge detection?,https://www.reddit.com/r/MachineLearning/comments/8um02c/can_anyone_give_me_a_link_that_shows_me_how_to/,Mastermind1600,1530209710,[removed],1,1
1629,2018-6-29,2018,6,29,3,8um19c,CreateML Lightning Talk from Brooklyn iOS and Swift Developers Meetup,https://www.reddit.com/r/MachineLearning/comments/8um19c/createml_lightning_talk_from_brooklyn_ios_and/,smallplanetapps,1530209943,,1,1
1630,2018-6-29,2018,6,29,4,8umsny,[R] Scalable Deep RL for Robot Grasping Task (Google Brain),https://www.reddit.com/r/MachineLearning/comments/8umsny/r_scalable_deep_rl_for_robot_grasping_task_google/,wei_jok,1530215493,,24,28
1631,2018-6-29,2018,6,29,5,8umz0t,[N] Reusable AI/ML workflows from the open ACM tournament on co-designing efficient software/hardware stack for deep learning,https://www.reddit.com/r/MachineLearning/comments/8umz0t/n_reusable_aiml_workflows_from_the_open_acm/,gtechmisc,1530216764,,1,2
1632,2018-6-29,2018,6,29,6,8uno18,DEWALT DCK277C2 20V MAX Compact Brushless Drill and Impact Combo Kit Is Now 70$ Off.,https://www.reddit.com/r/MachineLearning/comments/8uno18/dewalt_dck277c2_20v_max_compact_brushless_drill/,Shoulda2,1530222086,,1,1
1633,2018-6-29,2018,6,29,6,8unot3,I Ran an Instagram Chatbot... This is What Happened,https://www.reddit.com/r/MachineLearning/comments/8unot3/i_ran_an_instagram_chatbot_this_is_what_happened/,Boxxcar17,1530222259,,1,1
1634,2018-6-29,2018,6,29,6,8unqpf,Programming Innovations,https://www.reddit.com/r/MachineLearning/comments/8unqpf/programming_innovations/,SebastiaanEssen,1530222676,,1,1
1635,2018-6-29,2018,6,29,6,8unrka,[D] Running an Instagram Chatbot,https://www.reddit.com/r/MachineLearning/comments/8unrka/d_running_an_instagram_chatbot/,Boxxcar17,1530222859,,1,0
1636,2018-6-29,2018,6,29,8,8uof3m,Westworld is the ultimate machine learning,https://www.reddit.com/r/MachineLearning/comments/8uof3m/westworld_is_the_ultimate_machine_learning/,Kitty187,1530228359,Am I wrong or have I just figured out that westworld is a lesson in extreme machine learning? As in entirely possible and the only current road blocker is the lack of realistic AI bodies.,1,1
1637,2018-6-29,2018,6,29,8,8uolf1,[R] World Models with a Reservoir Computing Twist,https://www.reddit.com/r/MachineLearning/comments/8uolf1/r_world_models_with_a_reservoir_computing_twist/,baylearn,1530229929,,0,2
1638,2018-6-29,2018,6,29,9,8uoqtv,"ICML 2018 Best Papers: ""Obfuscated Gradients Give a False Sense of Security"" and ""Delayed Impact of Fair Machine Learning""",https://www.reddit.com/r/MachineLearning/comments/8uoqtv/icml_2018_best_papers_obfuscated_gradients_give_a/,anon20008267,1530231326,[removed],1,1
1639,2018-6-29,2018,6,29,9,8uovuj,"Spark: The Good, Bad, and Ugly for Data Science Work",https://www.reddit.com/r/MachineLearning/comments/8uovuj/spark_the_good_bad_and_ugly_for_data_science_work/,showeropera,1530232624,,1,1
1640,2018-6-29,2018,6,29,9,8uoynk,"[R] ICML 2018 Best Papers: ""Obfuscated Gradients Give a False Sense of Security"" and ""Delayed Impact of Fair Machine Learning""",https://www.reddit.com/r/MachineLearning/comments/8uoynk/r_icml_2018_best_papers_obfuscated_gradients_give/,anon20008267,1530233361,"the icml best paper awards are online

[https://icml.cc/Conferences/2018/Awards](https://icml.cc/Conferences/2018/Awards)

the  link isnt listed on the icml website yet but the page is public",2,33
1641,2018-6-29,2018,6,29,9,8up0tc,Microsoft Releases 125 million Building Footprints in the US as Open Data,https://www.reddit.com/r/MachineLearning/comments/8up0tc/microsoft_releases_125_million_building/,Bixbeat,1530233928,,1,1
1642,2018-6-29,2018,6,29,10,8up87m,I just started machine learning and has trained the MNIST model creating a neural network with three hidden layers using TensorFlow. I used the AdamOptimizer to reduce the cost function and got pretty good accuracy. Any suggestions for next project??,https://www.reddit.com/r/MachineLearning/comments/8up87m/i_just_started_machine_learning_and_has_trained/,av_no_one,1530235892,,1,1
1643,2018-6-29,2018,6,29,10,8upbh0,I just started Machine Learning and has trained MNIST model using TensorFlow creating three hidden layer. I used AdamOptimizer to reduce the cost function and got pretty good accuracy. Any suggestions for next project??,https://www.reddit.com/r/MachineLearning/comments/8upbh0/i_just_started_machine_learning_and_has_trained/,av_no_one,1530236732,,1,1
1644,2018-6-29,2018,6,29,10,8upe4c,I just started Machine Learning and has trained MNIST model using TensorFlow creating three hidden layer. I used AdamOptimizer to reduce the cost function and got pretty good accuracy.,https://www.reddit.com/r/MachineLearning/comments/8upe4c/i_just_started_machine_learning_and_has_trained/,av_no_one,1530237449,,1,1
1645,2018-6-29,2018,6,29,11,8uppqw,"Machine Learning Master Dilemma, Oxford MSc Statistical Science vs UCL MSc Machine Learning",https://www.reddit.com/r/MachineLearning/comments/8uppqw/machine_learning_master_dilemma_oxford_msc/,fooljames,1530240518,[removed],1,1
1646,2018-6-29,2018,6,29,12,8upsi3,[R] Reproducing World Models: Is training the recurrent network really needed ?,https://www.reddit.com/r/MachineLearning/comments/8upsi3/r_reproducing_world_models_is_training_the/,wei_jok,1530241283,,6,45
1647,2018-6-29,2018,6,29,12,8upsmd,"Machine Learning Master Dilemma, Oxford MSc Statistical Science vs UCL MSc Machine Learning",https://www.reddit.com/r/MachineLearning/comments/8upsmd/machine_learning_master_dilemma_oxford_msc/,fooljames,1530241315,[removed],1,1
1648,2018-6-29,2018,6,29,12,8upuvd,"[D] Machine Learning Master Dilemma, Oxford MSc Statistical Science vs UCL MSc Machine Learning",https://www.reddit.com/r/MachineLearning/comments/8upuvd/d_machine_learning_master_dilemma_oxford_msc/,fooljames,1530241918,"Hi everyone,

I graduated with a bachelor in Statistics and have been working as a data scientist for about 4 years after graduation.

This year, I decided to go to grad school and got accepted from two master programs in the UK,

[Oxford MSc Statistical Science](http://www.stats.ox.ac.uk/study-here/taught-postgraduate/msc-in-statistical-science/) and [UCL MSc Machine Learning](http://www.cs.ucl.ac.uk/prospective_students/msc_machine_learning/)

If my goal is to pursue a PhD in the field of Statistical Machine Learning in Europe, what do you think would be a better option in this case considering that I am an international student.

It would be super helpful for me to have opinions from you guys so that I can eventually make my decision. Thank you so much!",2,1
1649,2018-6-29,2018,6,29,12,8uq2i5, - ,https://www.reddit.com/r/MachineLearning/comments/8uq2i5/_/,Woodworking94,1530244096,,1,1
1650,2018-6-29,2018,6,29,13,8uq6k7,Speed up the training of a convolutional autoencoder,https://www.reddit.com/r/MachineLearning/comments/8uq6k7/speed_up_the_training_of_a_convolutional/,eemamedo,1530245222,[removed],1,1
1651,2018-6-29,2018,6,29,13,8uq8uo,[P] Speed up the training of the deep convolutional autoencoder,https://www.reddit.com/r/MachineLearning/comments/8uq8uo/p_speed_up_the_training_of_the_deep_convolutional/,eemamedo,1530245848,"I am trying to implement a convolutional autoencoder but unfortunately, training takes too much time. I built it using Keras and I use TF as backend. I am running the model on a school server that has 250 GB of RAM but it takes more than an hour to get the training done. Is there anything I can do to speed up the process? It is quite funny but my macbook Air shows a better time per epoch than a school server (88 sec vs. 150 sec)
",0,1
1652,2018-6-29,2018,6,29,13,8uqcvg,10 Best Laptop for Machine Learning Programming ( 2018 Update )-FavouriteBlog.com,https://www.reddit.com/r/MachineLearning/comments/8uqcvg/10_best_laptop_for_machine_learning_programming/,favouriteblog,1530247025,,2,1
1653,2018-6-29,2018,6,29,14,8uqp4m,Do publicly discussed sentiment analysis strategies seem unsatisfying to you?,https://www.reddit.com/r/MachineLearning/comments/8uqp4m/do_publicly_discussed_sentiment_analysis/,SignalEvidence,1530250735,[removed],0,1
1654,2018-6-29,2018,6,29,14,8uqpmf,Actor-Critic (A2C) so difficult to train....Please Help!,https://www.reddit.com/r/MachineLearning/comments/8uqpmf/actorcritic_a2c_so_difficult_to_trainplease_help/,randy_wales,1530250884,[removed],0,1
1655,2018-6-29,2018,6,29,15,8uqt6n,"""GAN"" &lt;-This word, How to read",https://www.reddit.com/r/MachineLearning/comments/8uqt6n/gan_this_word_how_to_read/,river_gang,1530252041,[removed],0,1
1656,2018-6-29,2018,6,29,16,8ur862,Blockchain GPUs Unchained: Running Neural Networks Without Hurting Mining Hash Rate,https://www.reddit.com/r/MachineLearning/comments/8ur862/blockchain_gpus_unchained_running_neural_networks/,adammathias,1530256822,,1,4
1657,2018-6-29,2018,6,29,17,8urhvp,"ROBOQI----When you're asleep, be quiet by your side and give your phone a steady and adequate battery.https://www.roboqi.com/  Click on the url and get a free one",https://www.reddit.com/r/MachineLearning/comments/8urhvp/roboqiwhen_youre_asleep_be_quiet_by_your_side_and/,roboqi,1530260304,,0,1
1658,2018-6-29,2018,6,29,17,8urjmh,ROBOQIwireless charger,https://www.reddit.com/r/MachineLearning/comments/8urjmh/roboqiwireless_charger/,roboqi,1530260986,,0,1
1659,2018-6-29,2018,6,29,18,8urxsh,Gesture recognition using Hidden Markov model,https://www.reddit.com/r/MachineLearning/comments/8urxsh/gesture_recognition_using_hidden_markov_model/,smileyash,1530266240,[removed],0,1
1660,2018-6-29,2018,6,29,19,8urzsq,ECOMI ECOSYSTEM WITH SECURE WALLET AND ECOMI ONE,https://www.reddit.com/r/MachineLearning/comments/8urzsq/ecomi_ecosystem_with_secure_wallet_and_ecomi_one/,Ceyebrity,1530266920,[removed],0,1
1661,2018-6-29,2018,6,29,19,8us7hf,Drum Nuts Roaster Machine/Peanut Roasting Machinery Price,https://www.reddit.com/r/MachineLearning/comments/8us7hf/drum_nuts_roaster_machinepeanut_roasting/,gelserena,1530269606,,1,1
1662,2018-6-29,2018,6,29,20,8us8sm,Is Machine Learning Really The Future? Everything You Should Know About! -Big Data Analytics News,https://www.reddit.com/r/MachineLearning/comments/8us8sm/is_machine_learning_really_the_future_everything/,Veerans,1530270030,,0,1
1663,2018-6-29,2018,6,29,20,8usg7x,Hemp Seed And Avocado Oil Press Machine,https://www.reddit.com/r/MachineLearning/comments/8usg7x/hemp_seed_and_avocado_oil_press_machine/,lgsherry,1530272314,,1,1
1664,2018-6-29,2018,6,29,20,8usgv0,Identifying dog breeds using Keras,https://www.reddit.com/r/MachineLearning/comments/8usgv0/identifying_dog_breeds_using_keras/,real_trizzaye,1530272530,,0,1
1665,2018-6-29,2018,6,29,20,8ushwi,I came across this online crash course on ML. It was quite helpful for my BIG DATA project and the duration was also not much long. More importantly they are providing a free certificate at the end as well. Online learning is great!,https://www.reddit.com/r/MachineLearning/comments/8ushwi/i_came_across_this_online_crash_course_on_ml_it/,Mmanisha21,1530272837,,2,3
1666,2018-6-29,2018,6,29,20,8usivi,[P] Identifying dog breeds using Keras,https://www.reddit.com/r/MachineLearning/comments/8usivi/p_identifying_dog_breeds_using_keras/,real_trizzaye,1530273136,,4,92
1667,2018-6-29,2018,6,29,20,8usjck,[Discussion] How reproducible is deep learning?,https://www.reddit.com/r/MachineLearning/comments/8usjck/discussion_how_reproducible_is_deep_learning/,PorcelainMelonWolf,1530273274,"I  have a rather naive question. If I were to use one of the popular  automatic differentiation packages to train a deep neural net, how  reproducible would my results be? Assuming I've set the seed and  controlled for any other obvious gotchas, would I be able to reproduce  the weights in a deep neural net exactly (to machine precision) on two successive training runs?

In a  traditional ML algorithm, the answer to that would be ""yes, obviously"".  But for deep neural nets, the computations are orders of magnitude  bigger, and run in parallel. I don't know enough about low-level  programming or the ISO float standard to guarantee that 1/ truncation  errors don't get propagated in a non-deterministic manner, and 2/ that  race conditions in a graphics card won't cause non-deterministic  behaviour in my training batch.

Anyone have thoughts? Thanks :)",44,55
1668,2018-6-29,2018,6,29,21,8usrxz,HyperE: Hyperbolic Embeddings for Entities,https://www.reddit.com/r/MachineLearning/comments/8usrxz/hypere_hyperbolic_embeddings_for_entities/,kluikens,1530275706,,0,1
1669,2018-6-29,2018,6,29,21,8ussxv,Viewing data in two dimension (2D) and create image file of data points,https://www.reddit.com/r/MachineLearning/comments/8ussxv/viewing_data_in_two_dimension_2d_and_create_image/,coolnikhilj22,1530275975,[removed],0,1
1670,2018-6-29,2018,6,29,22,8usyuq,Logistic regression with MLE vs LSE explained simple,https://www.reddit.com/r/MachineLearning/comments/8usyuq/logistic_regression_with_mle_vs_lse_explained/,victorram,1530277536,,2,14
1671,2018-6-29,2018,6,29,22,8ut1iy,10,https://www.reddit.com/r/MachineLearning/comments/8ut1iy/10/,Woodworking94,1530278182,,0,1
1672,2018-6-29,2018,6,29,22,8ut1wf,[D] Announcing the Criteo AI Lab - Criteo Labs (disclaimer: I work at Criteo),https://www.reddit.com/r/MachineLearning/comments/8ut1wf/d_announcing_the_criteo_ai_lab_criteo_labs/,theflofly,1530278265,,2,0
1673,2018-6-29,2018,6,29,22,8ut651,How to work with event data (diagnosis data) in ML,https://www.reddit.com/r/MachineLearning/comments/8ut651/how_to_work_with_event_data_diagnosis_data_in_ml/,anderl1980,1530279341,[removed],0,1
1674,2018-6-29,2018,6,29,23,8uth25,[P] Real-time model performance visualizations,https://www.reddit.com/r/MachineLearning/comments/8uth25/p_realtime_model_performance_visualizations/,Loggerny,1530281861,,1,1
1675,2018-6-30,2018,6,30,0,8utuke,PySHAC: Python Sequential Halving and Classification,https://www.reddit.com/r/MachineLearning/comments/8utuke/pyshac_python_sequential_halving_and/,amlaanb,1530284849,,0,1
1676,2018-6-30,2018,6,30,0,8utx7o,[D] Best open source Text to Speech networks?,https://www.reddit.com/r/MachineLearning/comments/8utx7o/d_best_open_source_text_to_speech_networks/,to4life,1530285417,"Hey guys, I'm looking to make an application that uses neural text to speech for my Python program. I'm not sure what open source SOTA is like, would love to get some reference repositories to check out, especially if they have demos. 

It would also be nice to have a model that can come with multiple voices :) 

Cheers",22,119
1677,2018-6-30,2018,6,30,1,8uu9em,The Matrix Calculus You Need for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8uu9em/the_matrix_calculus_you_need_for_deep_learning/,iamkeyur,1530288076,,0,1
1678,2018-6-30,2018,6,30,1,8uucpy,[D] Hong Kong Machine Learning Meetup for those in Hong Kong,https://www.reddit.com/r/MachineLearning/comments/8uucpy/d_hong_kong_machine_learning_meetup_for_those_in/,gau_mar,1530288752,,4,15
1679,2018-6-30,2018,6,30,1,8uuoc8,[D] Don't common sentiment analysis strategies seem unsatisfying?,https://www.reddit.com/r/MachineLearning/comments/8uuoc8/d_dont_common_sentiment_analysis_strategies_seem/,SignalEvidence,1530291209,"There's lots of great projects in Reddit in sentiment analysis, but almost all of the work I've seen focuses on individual posts, as if social media was simply a list of thumbs up and thumbs down about issues.

There's a lot more to a post that matters to its sentiment. For example context, where doesn't seem to much discussion. One very basic example where context is important is the following: a negative tweet or Reddit comment that itself is booing a negative comment is considered negative. Of course, the negative tweet may actually be counted ""in favor"" of the original topic.

The relevant fields in NLP would be [coreference](https://en.wikipedia.org/wiki/Coreference), and possibly other subfields involving semantics. Basically, these fields work on the very difficult task of disentangling the meaning behind sentences. They can be used to figure out what the participants were discussing. It's hard to find any of these techniques publicly used.

  
Another strategy of getting around the above issues are skillful ""hacks"" that rely on domain knowledge. One example of this is just using top level comments in Reddit. Maybe there is a universe of such tricks and techniques to get around the issues of context. But this doesn't seem satisfying and certainly discards useful information.

I'm someone who's worked in related and parallel domains in data science for years and this is my intuition. Does anyone else feel this way also?",9,38
1680,2018-6-30,2018,6,30,1,8uupfz,[P] WGAN trained on Earthporn images (interpolating in latent space),https://www.reddit.com/r/MachineLearning/comments/8uupfz/p_wgan_trained_on_earthporn_images_interpolating/,GamerMinion,1530291436,,13,13
1681,2018-6-30,2018,6,30,2,8uuvfe,Should I get this for ML,https://www.reddit.com/r/MachineLearning/comments/8uuvfe/should_i_get_this_for_ml/,hsdtester32763,1530292606,[removed],0,1
1682,2018-6-30,2018,6,30,2,8uuw7z,[P] Visualizing how a neural network classifies texts by paying attention to the right words (open-source Hierarchical Attention Network),https://www.reddit.com/r/MachineLearning/comments/8uuw7z/p_visualizing_how_a_neural_network_classifies/,helicalpen,1530292777,,6,34
1683,2018-6-30,2018,6,30,2,8uux45,[D] Intelligence is...,https://www.reddit.com/r/MachineLearning/comments/8uux45/d_intelligence_is/,JimmyJumpdrive,1530292962,"The philosophy behind creating AI seems to narrow down into one important question, ""What is Intelligence"". I have a theory based on another theory I wrote in r/MyTheoryIs. I called this theory ""[The perspective of everything](https://www.reddit.com/r/MyTheoryIs/comments/8utq2l/my_theory_of_the_perspective_of_everything/)"". It's my thoughts on science and god and the explanation of self-purpose and why the universe was created. I created this idea while thinking about the philosophy of what intelligence actually is, and based on my own theory I would like to imagine that ***Intelligence is the ability to hold a perspective*****.** The difference between us, intelligent life, and unintelligent life, is that we are able to pertain a perspective. We can hold an opinion and theorize why we're here. The ability to wonder such thoughts defines intelligence. Thoughts?",7,0
1684,2018-6-30,2018,6,30,3,8uvdtl,Self-Supervised Tracking via Video Colorization,https://www.reddit.com/r/MachineLearning/comments/8uvdtl/selfsupervised_tracking_via_video_colorization/,abcanthur,1530296376,[removed],0,1
1685,2018-6-30,2018,6,30,3,8uvihj,Fixing Voice Breakups with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8uvihj/fixing_voice_breakups_with_deep_learning/,adammathias,1530297354,,0,1
1686,2018-6-30,2018,6,30,3,8uvl3a,Question about how to find closest 'rephrasing' (i.e: return 'skin cancer' if the phrase 'cancer of the skin' is given) for medical document,https://www.reddit.com/r/MachineLearning/comments/8uvl3a/question_about_how_to_find_closest_rephrasing_ie/,PhitPhil,1530297933,[removed],0,1
1687,2018-6-30,2018,6,30,4,8uvr31,The Rise of Machine Learning and the Triumph of Learned Individuals: A Digital Milestone,https://www.reddit.com/r/MachineLearning/comments/8uvr31/the_rise_of_machine_learning_and_the_triumph_of/,vastlinks,1530299200,,0,1
1688,2018-6-30,2018,6,30,4,8uvw4m,Making Art with Growing Neural Gas,https://www.reddit.com/r/MachineLearning/comments/8uvw4m/making_art_with_growing_neural_gas/,itdxer,1530300296,,0,1
1689,2018-6-30,2018,6,30,4,8uw4lz,"Deep-learning-free Text and Sentence Embedding, Part 2",https://www.reddit.com/r/MachineLearning/comments/8uw4lz/deeplearningfree_text_and_sentence_embedding_part/,adammathias,1530302090,,0,1
1690,2018-6-30,2018,6,30,5,8uwe58,Where can I find a non-MNIST implementation of Capsule Networks for Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/8uwe58/where_can_i_find_a_nonmnist_implementation_of/,Devenar,1530304075,"Hello, this is my first post here. I'm mostly used to Stack Overflow posting guidelines, so let me know what I can do to improve my posts here, or if this isn't the right place for a post like this. (Thanks!)

It looks like there are a [lot](https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb) of [different](https://github.com/bourdakos1/capsule-networks) [implementations](https://github.com/llSourcell/capsule_networks/blob/master/capsLayer.py) of Capsule Networks in TensorFlow. However, most of these seem to be versions of [https://github.com/naturomics/CapsNet-Tensorflow](https://github.com/naturomics/CapsNet-Tensorflow).

My issue with naturomic's (Huadong Liao) implementation is that it's hard-coded specifically for MNIST.

For example, there are assert statements like assert caps1.get\_shape() == \[cfg.batch\_size, 1152, 8, 1\]  
 that only make sense if you're using a dataset with the same dimensions as MNIST.

Are there any implementations of Capsule Networks for TensorFlow that are more general?

If not, I'll try to go about making my own, probably by working from [naturomic's implementation](https://github.com/naturomics/CapsNet-Tensorflow) and replacing the MNIST constants with variables and editable properties.

 (Also [posted](https://www.reddit.com/r/neuralnetworks/comments/8uwa21/where_can_i_find_a_nonmnist_implementation_of/) on [r/neuralnetworks](https://www.reddit.com/r/neuralnetworks)) ",0,1
1691,2018-6-30,2018,6,30,6,8uwqeu,[D] Would you see this as the future of racing?,https://www.reddit.com/r/MachineLearning/comments/8uwqeu/d_would_you_see_this_as_the_future_of_racing/,Poepopdestoep,1530306792,"https://www.youtube.com/watch?time_continue=125&amp;v=PQmSUHhP3ug

First off, I don't know if this is the right place to post this, if so my apologies.

Look at the peak performance of the driver during this video. What about a car controlled by a very well trained AI? It would be years away in terms of development and hardware, but could hits be the [tool assisted speedruns](https://en.wikipedia.org/wiki/Tool-assisted_speedrun) of the future?",1,0
1692,2018-6-30,2018,6,30,6,8uww6z,[N] ICML 2018 Announces Best Paper Awards,https://www.reddit.com/r/MachineLearning/comments/8uww6z/n_icml_2018_announces_best_paper_awards/,trcytony,1530308081,,0,1
1693,2018-6-30,2018,6,30,7,8uxec1,Receiver Operating Characteristic Curves Explained (in Python),https://www.reddit.com/r/MachineLearning/comments/8uxec1/receiver_operating_characteristic_curves/,snazrul,1530312380,,0,1
1694,2018-6-30,2018,6,30,8,8uxj0h,Does anyone know good websites that list out popular ML algorithms and offer explanations?,https://www.reddit.com/r/MachineLearning/comments/8uxj0h/does_anyone_know_good_websites_that_list_out/,LEON0426,1530313525,"Hey guys,

I'm writing a report on ML algorithms and their uses for my undergrad Stats course.

Do anyone know good websites that talk about these?

I could always google them, but different websites offer different explanations, and for some of them, I doubt the validity.

Just looking for some professional, in-depth explanations.

Thanks in advance!",0,1
1695,2018-6-30,2018,6,30,10,8uyllv,[D] Any good resource on reproducible work on semantic understanding of videos using weakly supervised learning (or) unsupervised learning?,https://www.reddit.com/r/MachineLearning/comments/8uyllv/d_any_good_resource_on_reproducible_work_on/,arkar_aung,1530323986,,0,0
1696,2018-6-30,2018,6,30,12,8uz7gn,Is there a brand/logo/product-recognition.js (just like face-recognition.js for front-end use?),https://www.reddit.com/r/MachineLearning/comments/8uz7gn/is_there_a_brandlogoproductrecognitionjs_just/,jek-bao-choo,1530330453,[removed],0,1
1697,2018-6-30,2018,6,30,15,8uzwh0,Compost to organic fertilizer granules extruder/Granulation equipment,https://www.reddit.com/r/MachineLearning/comments/8uzwh0/compost_to_organic_fertilizer_granules/,amylee516,1530338680,,0,1
1698,2018-6-30,2018,6,30,17,8v0ll4,Suggested resources / things to review to strengthen my mathematical background before graduate studies,https://www.reddit.com/r/MachineLearning/comments/8v0ll4/suggested_resources_things_to_review_to/,csgradval,1530348589,[removed],0,1
1699,2018-6-30,2018,6,30,18,8v0p6i,T2F: Text to Face generation using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8v0p6i/t2f_text_to_face_generation_using_deep_learning/,akanimax,1530350146,,0,1
1700,2018-6-30,2018,6,30,18,8v0us1,Maths background needed for professional work in AI / NLP?,https://www.reddit.com/r/MachineLearning/comments/8v0us1/maths_background_needed_for_professional_work_in/,momslatin_dadsasian,1530352655,[removed],0,1
1701,2018-6-30,2018,6,30,19,8v0yns,[R] Evaluating Feature Importance Estimates (Google Brain),https://www.reddit.com/r/MachineLearning/comments/8v0yns/r_evaluating_feature_importance_estimates_google/,baylearn,1530354099,,19,70
1702,2018-6-30,2018,6,30,19,8v0znt,ML and Clash Royale.,https://www.reddit.com/r/MachineLearning/comments/8v0znt/ml_and_clash_royale/,pritendou,1530354539,[removed],0,1
1703,2018-6-30,2018,6,30,19,8v10je,AI to identify sudden price movements(rallies or declines) in a stock,https://www.reddit.com/r/MachineLearning/comments/8v10je/ai_to_identify_sudden_price_movementsrallies_or/,snmk195,1530354917,[removed],0,1
1704,2018-6-30,2018,6,30,19,8v11j9,T2F: Text to Face generation using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8v11j9/t2f_text_to_face_generation_using_deep_learning/,akanimax,1530355328,[removed],0,1
1705,2018-6-30,2018,6,30,20,8v14zj,"What's the relation between AlphaZero, Reinforcement learning and A*?",https://www.reddit.com/r/MachineLearning/comments/8v14zj/whats_the_relation_between_alphazero/,kokobannana,1530356720,,0,1
1706,2018-6-30,2018,6,30,20,8v15vy,[R] Procedural Level Generation Improves Generality of Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8v15vy/r_procedural_level_generation_improves_generality/,hardmaru,1530357039,,4,16
1707,2018-6-30,2018,6,30,21,8v1e1y,How to organise research code?,https://www.reddit.com/r/MachineLearning/comments/8v1e1y/how_to_organise_research_code/,funny1man2,1530360151,[removed],0,1
1708,2018-6-30,2018,6,30,21,8v1frr,[R] ResNet with one-neuron hidden layers is a Universal Approximator,https://www.reddit.com/r/MachineLearning/comments/8v1frr/r_resnet_with_oneneuron_hidden_layers_is_a/,wei_jok,1530360692,,7,24
1709,2018-6-30,2018,6,30,21,8v1fu7,[D] About GAN(Generative Adversarial Networks). How do you read this acronym?,https://www.reddit.com/r/MachineLearning/comments/8v1fu7/d_about_gangenerative_adversarial_networks_how_do/,river_gang,1530360717,"## hi, guys

I'm live in non-english speaking country.

It's not an important issue, But I wonder how to read this word. ""GAN""

How do you read it??

\[gn\] ??

\[gn\] ??",14,0
1710,2018-6-30,2018,6,30,21,8v1g6c,[D] Best way to organise research code?,https://www.reddit.com/r/MachineLearning/comments/8v1g6c/d_best_way_to_organise_research_code/,abhishek0318,1530360818,"I  am undergraduate student working on NLP using Deep Learning. I mostly use PyTorch. I wanted to know what is the best way to organise research  code.

I have tried using both Python scripts and Jupyter Noebooks. I find  using Jupyter Notebooks to be quick while writing and debugging code.  You can always see the shape of the tensors you are manipulating. You can check if the values appear right. Your plot appears in the same  place. You can interact with your model, check how it is performing on custom input, stop it while training, lower the learning rate, etc.

But writing python scripts has its own benefits. You save writing  redundant code for different experiments. For changing some line in a  function you don't have to change that function in all the experiments'  codes. You can also run these scripts directly through the command line.  

Please point out to some resources or give some advice on best coding  practices and how to organise code. If possible please link to some GitHub  repos where you think codes for different experiments is organised in an efficient manner. ",23,116
1711,2018-6-30,2018,6,30,21,8v1ioi,[R] Optimization theory of Hebbian/anti-Hebbian networks for PCA and whitening,https://www.reddit.com/r/MachineLearning/comments/8v1ioi/r_optimization_theory_of_hebbianantihebbian/,abstractcontrol,1530361656,,5,10
1712,2018-6-30,2018,6,30,21,8v1j8k,AI Weekly 29 June 2018,https://www.reddit.com/r/MachineLearning/comments/8v1j8k/ai_weekly_29_june_2018/,TomekB,1530361836,,0,1
1713,2018-6-30,2018,6,30,21,8v1ld6,How accurate are commercial/industry machine learning systems and how do they achieve it?,https://www.reddit.com/r/MachineLearning/comments/8v1ld6/how_accurate_are_commercialindustry_machine/,RandomPhysicist,1530362550,[removed],0,1
1714,2018-6-30,2018,6,30,21,8v1ll0,[R] Fully Connected Networks and Generative Neural Networks Applied to Sclera Segmentation,https://www.reddit.com/r/MachineLearning/comments/8v1ll0/r_fully_connected_networks_and_generative_neural/,ghostzin,1530362619,,2,2
1715,2018-6-30,2018,6,30,22,8v1qli,Are there any beginner to intermediate tutorials around for somebody who is average in mathematics?,https://www.reddit.com/r/MachineLearning/comments/8v1qli/are_there_any_beginner_to_intermediate_tutorials/,ML-newb,1530364161,[removed],0,1
1716,2018-6-30,2018,6,30,22,8v1uo4,State of AI report,https://www.reddit.com/r/MachineLearning/comments/8v1uo4/state_of_ai_report/,adammathias,1530365395,,0,1
1717,2018-6-30,2018,6,30,22,8v1vyu,[D] Is RNN vanishing gradient problem considered solved?,https://www.reddit.com/r/MachineLearning/comments/8v1vyu/d_is_rnn_vanishing_gradient_problem_considered/,radenML,1530365809,"Recently I come across a CVPR 2018 paper on IndRNN that claimed to able train 5000 layers deep RNN and still learn, and even beat LSTM (https://arxiv.org/abs/1803.04831)
Anyone here reproduced the results?",12,19
1718,2018-6-30,2018,6,30,23,8v2dn4,Questions about reading PRML,https://www.reddit.com/r/MachineLearning/comments/8v2dn4/questions_about_reading_prml/,NoSegfaultPlz,1530370750,[removed],0,1
