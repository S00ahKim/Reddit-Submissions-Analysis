,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2017-6-1,2017,6,1,12,6ek21p,[R] [1705.06366] Automatic Goal Generation for Reinforcement Learning Agents,https://www.reddit.com/r/MachineLearning/comments/6ek21p/r_170506366_automatic_goal_generation_for/,evc123,1496286536,,3,25
1,2017-6-1,2017,6,1,14,6eknpx,Explanation of AlphaGo by Karpathy,https://www.reddit.com/r/MachineLearning/comments/6eknpx/explanation_of_alphago_by_karpathy/,hoaphumanoid,1496293935,,0,1
2,2017-6-1,2017,6,1,14,6eksyr,Can anybody describe their experiences with platforms like Open AI and Deepmind?,https://www.reddit.com/r/MachineLearning/comments/6eksyr/can_anybody_describe_their_experiences_with/,legendsofevil,1496295975,[removed],0,1
3,2017-6-1,2017,6,1,16,6el4yw,Keras Implementation of Grounded RNNs,https://www.reddit.com/r/MachineLearning/comments/6el4yw/keras_implementation_of_grounded_rnns/,chvsp,1496300939,,0,1
4,2017-6-1,2017,6,1,16,6elacq,[R][1705.10461]The Numerics of GANs,https://www.reddit.com/r/MachineLearning/comments/6elacq/r170510461the_numerics_of_gans/,MarioYC,1496303415,,7,11
5,2017-6-1,2017,6,1,18,6ellom,[P] A TensorFlow Implementation of Tacotron: A Fully End-to-End Text-To-Speech Synthesis Model,https://www.reddit.com/r/MachineLearning/comments/6ellom/p_a_tensorflow_implementation_of_tacotron_a_fully/,longinglove,1496308713,,1,9
6,2017-6-1,2017,6,1,18,6elnku,Googles Tensorflow Lite is coming to Android!,https://www.reddit.com/r/MachineLearning/comments/6elnku/googles_tensorflow_lite_is_coming_to_android/,Cogbotter,1496309631,,0,1
7,2017-6-1,2017,6,1,18,6elodf,2D/3D convolution of matrices/tensors,https://www.reddit.com/r/MachineLearning/comments/6elodf/2d3d_convolution_of_matricestensors/,oqowa,1496310013,[removed],0,1
8,2017-6-1,2017,6,1,20,6em31b,Cheat Sheet of Machine Learning and Python (and Math) Cheat Sheets,https://www.reddit.com/r/MachineLearning/comments/6em31b/cheat_sheet_of_machine_learning_and_python_and/,RobbieStats,1496316119,,0,1
9,2017-6-1,2017,6,1,20,6em4id,[P] Pytorch implementation of Grad-CAM,https://www.reddit.com/r/MachineLearning/comments/6em4id/p_pytorch_implementation_of_gradcam/,jacobgil,1496316682,,0,15
10,2017-6-1,2017,6,1,21,6emaj6,[D] The effectiveness of DNC on natural language generation tasks.,https://www.reddit.com/r/MachineLearning/comments/6emaj6/d_the_effectiveness_of_dnc_on_natural_language/,agrawalamey,1496318638,"Hi, I have been trying to formulate a deep learning approach to generate stories from plot graphs. [Li et al.](http://www.cc.gatech.edu/~riedl/pubs/aaai13.pdf) has a good explanation of plot graphs. I essentially intend to try deep learning as a replacement for Document Structuring and Surface Realisation steps in a traditional story generation pipeline. The subway example from the DNC paper seems promising. Though DNC has excellent results on bAbl task I am unsure if DNC could produce long paragraphs as needed as required in the story generation task. Could a hierarchical RNN like approach work where the DNC generates topic vectors which would be decoded using LSTM/GRU or it would be too hard to train? ",0,14
11,2017-6-1,2017,6,1,21,6emcew,[P] Dog Lens | Recognize Dog Breeds right from a photograph!,https://www.reddit.com/r/MachineLearning/comments/6emcew/p_dog_lens_recognize_dog_breeds_right_from_a/,aniruddh1998,1496319292,,0,0
12,2017-6-1,2017,6,1,21,6emk6n,[R] AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6emk6n/r_ampnet_asynchronous_modelparallel_training_for/,visarga,1496321849,,1,13
13,2017-6-1,2017,6,1,22,6emmxc,[D] The machine learning paradox - O'Reilly Media,https://www.reddit.com/r/MachineLearning/comments/6emmxc/d_the_machine_learning_paradox_oreilly_media/,_alphamaximus_,1496322684,,1,0
14,2017-6-1,2017,6,1,22,6emoh5,[N] PyTorch on Windows,https://www.reddit.com/r/MachineLearning/comments/6emoh5/n_pytorch_on_windows/,flyingjam,1496323161,"Unfortunately, some of us end up with windows only platform restrictions, and for a while PyTorch hasn't had windows support, which is a bummer.

Recently, however, peterjc123 on github has managed to get a working windows build. I've tested it on 7 and 10 on an anaconda environment with 3.6.1, everything seems to work, including cuda support.

See https://github.com/pytorch/pytorch/issues/494 towards the end.

Hopefully his work will eventually be official adopted into the project, but hey, it works.",20,50
15,2017-6-1,2017,6,1,22,6emovl,[P] Code for Tensorflow Machine Learning Cookbook,https://www.reddit.com/r/MachineLearning/comments/6emovl/p_code_for_tensorflow_machine_learning_cookbook/,ibobriakov,1496323290,,0,1
16,2017-6-1,2017,6,1,23,6en54f,[R] From Instance Noise to Gradient Regularisation in GANs - notes on new arXiv paper by Roth et al.,https://www.reddit.com/r/MachineLearning/comments/6en54f/r_from_instance_noise_to_gradient_regularisation/,fhuszar,1496327827,,2,20
17,2017-6-1,2017,6,1,23,6en7dc,[Research] A Big Data Cheat Sheet: From Narrow AI to General AI,https://www.reddit.com/r/MachineLearning/comments/6en7dc/research_a_big_data_cheat_sheet_from_narrow_ai_to/,luba_belokon,1496328457,,10,17
18,2017-6-1,2017,6,1,23,6en8q4,SVI learning 15-component GMM with score function term in gradient estimator.,https://www.reddit.com/r/MachineLearning/comments/6en8q4/svi_learning_15component_gmm_with_score_function/,[deleted],1496328822,[deleted],0,1
19,2017-6-2,2017,6,2,0,6enb6u,[R] [1705.10929] Adversarial Generation of Natural Language,https://www.reddit.com/r/MachineLearning/comments/6enb6u/r_170510929_adversarial_generation_of_natural/,FalseAss,1496329456,,12,37
20,2017-6-2,2017,6,2,0,6engqj,[R] Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols,https://www.reddit.com/r/MachineLearning/comments/6engqj/r_emergence_of_language_with_multiagent_games/,[deleted],1496330878,[deleted],0,2
21,2017-6-2,2017,6,2,0,6enhuw,Tutorials for TensorFlow APIs the official documentation doesn't cover,https://www.reddit.com/r/MachineLearning/comments/6enhuw/tutorials_for_tensorflow_apis_the_official/,kwk236,1496331172,,0,1
22,2017-6-2,2017,6,2,2,6eo76g,[N] Wave Computing Targets Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6eo76g/n_wave_computing_targets_deep_learning/,darkconfidantislife,1496337353,,4,4
23,2017-6-2,2017,6,2,2,6eo79o,An Early Look at Startup Graphcores Deep Learning Chip,https://www.reddit.com/r/MachineLearning/comments/6eo79o/an_early_look_at_startup_graphcores_deep_learning/,[deleted],1496337377,[deleted],0,1
24,2017-6-2,2017,6,2,2,6eo7c0,[N] An Early Look at Startup Graphcores Deep Learning Chip,https://www.reddit.com/r/MachineLearning/comments/6eo7c0/n_an_early_look_at_startup_graphcores_deep/,darkconfidantislife,1496337394,,1,12
25,2017-6-2,2017,6,2,2,6eoc9j,Practical Neural Networks with Keras: Classifying Yelp Reviews,https://www.reddit.com/r/MachineLearning/comments/6eoc9j/practical_neural_networks_with_keras_classifying/,kylebythemile,1496338569,,0,1
26,2017-6-2,2017,6,2,2,6eoejy,[D]Recurrent Neural Networks for 3D models,https://www.reddit.com/r/MachineLearning/comments/6eoejy/drecurrent_neural_networks_for_3d_models/,sack_of_twigs,1496339121,"I've seen LSTM combined with a convolutional 2D network, I was wondering if there was a way to use LSTM with a convolutional 3D network? Sorry if this breaks the google rule, I've been searching for a while and couldn't find anything on it.",6,11
27,2017-6-2,2017,6,2,3,6eol7b,Question about image classifiers,https://www.reddit.com/r/MachineLearning/comments/6eol7b/question_about_image_classifiers/,cobalt_blade,1496340702,[removed],0,1
28,2017-6-2,2017,6,2,3,6eopfw,Can GANs be used to artificially increase a dataset to help train a classification model on?,https://www.reddit.com/r/MachineLearning/comments/6eopfw/can_gans_be_used_to_artificially_increase_a/,benjmcarr,1496341738,[removed],0,1
29,2017-6-2,2017,6,2,3,6eoq4l,[P] Visualizing TensorFlow Graphs in Jupyter Notebooks with and without TensorBoard,https://www.reddit.com/r/MachineLearning/comments/6eoq4l/p_visualizing_tensorflow_graphs_in_jupyter/,progfu,1496341909,,1,33
30,2017-6-2,2017,6,2,4,6ep478,[P] arXiv Paper to Python Implementation Screencast Series,https://www.reddit.com/r/MachineLearning/comments/6ep478/p_arxiv_paper_to_python_implementation_screencast/,[deleted],1496345341,[deleted],3,9
31,2017-6-2,2017,6,2,4,6ep4pl,Microsoft Releases CNTK 2.0 with keras support and speed gain over tensorflow,https://www.reddit.com/r/MachineLearning/comments/6ep4pl/microsoft_releases_cntk_20_with_keras_support_and/,[deleted],1496345466,[deleted],0,1
32,2017-6-2,2017,6,2,4,6ep878,Top 12 Computer Science Ph.D Fellowships,https://www.reddit.com/r/MachineLearning/comments/6ep878/top_12_computer_science_phd_fellowships/,RobbieStats,1496346300,,0,1
33,2017-6-2,2017,6,2,4,6ep9ld,Artificial Intelligence in Perspective,https://www.reddit.com/r/MachineLearning/comments/6ep9ld/artificial_intelligence_in_perspective/,towk22,1496346614,,0,1
34,2017-6-2,2017,6,2,5,6epcqh,Has anyone ever tried using a DNC that retrieves other DNCs rather than just stored information?,https://www.reddit.com/r/MachineLearning/comments/6epcqh/has_anyone_ever_tried_using_a_dnc_that_retrieves/,tinedsalmon,1496347340,[removed],0,1
35,2017-6-2,2017,6,2,5,6epj9r,"[x-post] Join the principal research scientist at the nonprofit behind Wikipedia at 5PM ET for a chat about AI, machine learning as-a-service and community dynamics.",https://www.reddit.com/r/MachineLearning/comments/6epj9r/xpost_join_the_principal_research_scientist_at/,melodykramer,1496348815,,0,2
36,2017-6-2,2017,6,2,5,6epkvd,What is the masters in (computational statistics &amp;) machine learning like at UCL,https://www.reddit.com/r/MachineLearning/comments/6epkvd/what_is_the_masters_in_computational_statistics/,zs01,1496349174,[removed],0,1
37,2017-6-2,2017,6,2,5,6eppra,[N] New Package for Building Keras Models in R,https://www.reddit.com/r/MachineLearning/comments/6eppra/n_new_package_for_building_keras_models_in_r/,[deleted],1496350343,[deleted],0,1
38,2017-6-2,2017,6,2,6,6epshd,[N] New Package for Building Keras Models in R,https://www.reddit.com/r/MachineLearning/comments/6epshd/n_new_package_for_building_keras_models_in_r/,fenixnuke,1496351000,,4,13
39,2017-6-2,2017,6,2,7,6eqbtd,[German] Paper Review: Semantic Analysis mit speziellen LSTMs,https://www.reddit.com/r/MachineLearning/comments/6eqbtd/german_paper_review_semantic_analysis_mit/,flezzfx,1496356033,,0,1
40,2017-6-2,2017,6,2,7,6eqfnd,CNC Machining,https://www.reddit.com/r/MachineLearning/comments/6eqfnd/cnc_machining/,jaffery0112,1496357085,,0,1
41,2017-6-2,2017,6,2,8,6eqjn0,"""Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks"", Katz et al 2017",https://www.reddit.com/r/MachineLearning/comments/6eqjn0/reluplex_an_efficient_smt_solver_for_verifying/,gwern,1496358184,,0,1
42,2017-6-2,2017,6,2,8,6eqtsj,iNaturalist 2017 Species Classification Challenge Writeup,https://www.reddit.com/r/MachineLearning/comments/6eqtsj/inaturalist_2017_species_classification_challenge/,fgvc2017,1496361125,,1,1
43,2017-6-2,2017,6,2,9,6er2k6,Further Linear Algebra Resources,https://www.reddit.com/r/MachineLearning/comments/6er2k6/further_linear_algebra_resources/,FiniteDelight,1496363765,[removed],0,1
44,2017-6-2,2017,6,2,9,6er46i,[D] Which Type Of Generative Network Should I Use?,https://www.reddit.com/r/MachineLearning/comments/6er46i/d_which_type_of_generative_network_should_i_use/,beef__,1496364270,"I just have a folder full of JPGs of faces, and I want to generate more of them - is there some network/project out there I can just train on the folder and use to easily generate more faces? None of the solutions out there seem too simple - they all focus on more complex issues/applications like inpainting, etc. I just need to generate more faces...",12,7
45,2017-6-2,2017,6,2,10,6er87w,[N] CNTK version 2.0 released! Featuring Keras!,https://www.reddit.com/r/MachineLearning/comments/6er87w/n_cntk_version_20_released_featuring_keras/,stellarburn,1496365548,,9,64
46,2017-6-2,2017,6,2,11,6erj8w,[D] Outlier detection for video?,https://www.reddit.com/r/MachineLearning/comments/6erj8w/d_outlier_detection_for_video/,underfitting,1496369098,"Is there any DL based methods for outlier detection for video? I want to detect criminal activities in large amount of video.
My idea is using some output vector of hidden layer of pretrained CNN. But I'm not sure this works best.


",1,5
47,2017-6-2,2017,6,2,11,6erky6,[R] Towards Consistency of Adversarial Training for Generative Models,https://www.reddit.com/r/MachineLearning/comments/6erky6/r_towards_consistency_of_adversarial_training_for/,adagrad,1496369664,,0,2
48,2017-6-2,2017,6,2,11,6ernyq,[D] Machine learning startups - Path from research to startup to acquisition,https://www.reddit.com/r/MachineLearning/comments/6ernyq/d_machine_learning_startups_path_from_research_to/,Pieranha,1496370689,"I guess a lot of us are curious about all of these startups popping up related to machine learning and deep learning. It seems that due to the fast-moving pace and high potential impact of this field that money is flowing towards startups at a rate that's causing the startup dynamics in this field to be quite different from other fields.

I've heard some stories, but it's hard to get a good idea of how the startup environment within machine learning really works. I would love to hear more (and hopefully others would too) about your experiences with doing a machine learning startup. In particular, I'd like to hear more about the following questions, but please feel free to add anything you think is relevant!

1. How long time did it take from the idea being conceived to the startup being founded and then to a potential acquisition (in case of aiming for an exit) or positive bottom line (in case of aiming for building a long-term company)?
2. What were the main obstacles holding you back from realizing your machine learning startup?
3. How do you balance research and building a startup? For instance, there seems to be a compromise between withholding information that competitors could use and publishing research before other academics invent something similar. This seems particularly relevant for anyone trying to balance both academia and a startup more or less at the same time.

Please make sure to mention anything that might make your situation different from others such as geographic location, influential co-founders or similar.",31,173
49,2017-6-2,2017,6,2,11,6erq3m,[R] DiracNets: Training Very Deep Neural Networks Without Skip-Connections,https://www.reddit.com/r/MachineLearning/comments/6erq3m/r_diracnets_training_very_deep_neural_networks/,xternalz,1496371441,,14,24
50,2017-6-2,2017,6,2,13,6es3dv,Is it too late to get into machine learning?,https://www.reddit.com/r/MachineLearning/comments/6es3dv/is_it_too_late_to_get_into_machine_learning/,tjasdfjj,1496376104,[removed],0,1
51,2017-6-2,2017,6,2,13,6es58c,[R] Google Brain's Magenta: Waybackprop (smarter backprop truncation for hierarchical RNNs),https://www.reddit.com/r/MachineLearning/comments/6es58c/r_google_brains_magenta_waybackprop_smarter/,cooijmanstim,1496376764,,12,26
52,2017-6-2,2017,6,2,14,6ese57,[N] Chainer version 2.0 released!,https://www.reddit.com/r/MachineLearning/comments/6ese57/n_chainer_version_20_released/,shoheihido,1496380151,,4,35
53,2017-6-2,2017,6,2,14,6esh1q,[D] Where should I go for help with Keras and TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/6esh1q/d_where_should_i_go_for_help_with_keras_and/,gill_bates,1496381362,"Research, I've discovered, is a much more isolated field than the workplace. When I had questions I would usually go ask a senior engineer, but nobody in my department works directly with Keras/Tensorflow. Should I:

* Post the question on StackOverflow?
* File an issue on Keras's Github repo?
* Visit some forums or Slack channels for support?

Not really sure what the standard course of action would be.
",2,0
54,2017-6-2,2017,6,2,14,6eskrr,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6eskrr/shot_blasting_machine/,Shot-blasting,1496382929,,0,1
55,2017-6-2,2017,6,2,14,6eskt7,Simple Downloader for Public Word Embeddings,https://www.reddit.com/r/MachineLearning/comments/6eskt7/simple_downloader_for_public_word_embeddings/,Hironsan,1496382943,,0,1
56,2017-6-2,2017,6,2,15,6esncg,"Bots take over jobs of 12,000 employees at Wipro(INDIA)",https://www.reddit.com/r/MachineLearning/comments/6esncg/bots_take_over_jobs_of_12000_employees_at/,hardikmakadia,1496384039,,0,1
57,2017-6-2,2017,6,2,16,6estt4,[R] Discovering Discrete Latent Topics with Neural Variational Inference,https://www.reddit.com/r/MachineLearning/comments/6estt4/r_discovering_discrete_latent_topics_with_neural/,egrefen,1496386870,,0,7
58,2017-6-2,2017,6,2,18,6etan1,Resources for neural networks and deep learning,https://www.reddit.com/r/MachineLearning/comments/6etan1/resources_for_neural_networks_and_deep_learning/,[deleted],1496395110,[removed],0,1
59,2017-6-2,2017,6,2,18,6etbww,[D] Resources for neural networks and deep learning,https://www.reddit.com/r/MachineLearning/comments/6etbww/d_resources_for_neural_networks_and_deep_learning/,elemark,1496395725,[removed],6,0
60,2017-6-2,2017,6,2,18,6eted7,[R] Learning Time-Efficient Deep Architectures with Budgeted Super Networks,https://www.reddit.com/r/MachineLearning/comments/6eted7/r_learning_timeefficient_deep_architectures_with/,ludc,1496396854,,0,9
61,2017-6-2,2017,6,2,19,6eti24,Tensorflow as a brain accelerator library?,https://www.reddit.com/r/MachineLearning/comments/6eti24/tensorflow_as_a_brain_accelerator_library/,ToplessTopmodel,1496398482,[removed],0,1
62,2017-6-2,2017,6,2,20,6ettn7,[1705.11040] End-to-end Differentiable Proving,https://www.reddit.com/r/MachineLearning/comments/6ettn7/170511040_endtoend_differentiable_proving/,jg8610,1496403376,,0,1
63,2017-6-2,2017,6,2,21,6eu436,[R] Learning Disentangled Representations with Semi-Supervised Deep Generative Models,https://www.reddit.com/r/MachineLearning/comments/6eu436/r_learning_disentangled_representations_with/,pauljasek,1496407106,,4,11
64,2017-6-2,2017,6,2,22,6eu8o2,"TPOT, the Python automated machine learning tool that uses genetic programming, has released v0.8. Now includes multiprocessing support, XGBoost, and the ability to optimize pipelines for any machine learning algorithm/transformer via a custom configuration interface.",https://www.reddit.com/r/MachineLearning/comments/6eu8o2/tpot_the_python_automated_machine_learning_tool/,[deleted],1496408633,[deleted],0,1
65,2017-6-2,2017,6,2,22,6eucss,TPOT v0.8 released: Python tool that automates machine learning using genetic programming,https://www.reddit.com/r/MachineLearning/comments/6eucss/tpot_v08_released_python_tool_that_automates/,[deleted],1496409934,[deleted],0,1
66,2017-6-2,2017,6,2,22,6euem0,Are there known bounds on the error of a neural network as a universal approximation as a function of the width of the hidden layer?,https://www.reddit.com/r/MachineLearning/comments/6euem0/are_there_known_bounds_on_the_error_of_a_neural/,[deleted],1496410509,[removed],0,1
67,2017-6-3,2017,6,3,1,6evasl,ShortScience.org User Survey! We are conducting a survey to quantify how much this project has increased reproducibility in research. We want to determine how much and where the impact of this project has been over the first year.,https://www.reddit.com/r/MachineLearning/comments/6evasl/shortscienceorg_user_survey_we_are_conducting_a/,ieee8023,1496419525,,0,1
68,2017-6-3,2017,6,3,1,6evhyh,[P] WebDNN: JS Library to run DL models in browser. Optimized WebASM+GPU implementation.,https://www.reddit.com/r/MachineLearning/comments/6evhyh/p_webdnn_js_library_to_run_dl_models_in_browser/,wei_jok,1496421468,,0,44
69,2017-6-3,2017,6,3,2,6evr8i,"Twitter Social Graph, PageRank score and Clustering algo based recommendation",https://www.reddit.com/r/MachineLearning/comments/6evr8i/twitter_social_graph_pagerank_score_and/,bliss_tree,1496423911,,0,1
70,2017-6-3,2017,6,3,3,6ew3j5,Automated Machine Learning Competition announced: Can AutoML beat humans on Kaggle?,https://www.reddit.com/r/MachineLearning/comments/6ew3j5/automated_machine_learning_competition_announced/,[deleted],1496427093,[deleted],0,1
71,2017-6-3,2017,6,3,3,6ew7q0,[R] Iterating through Siamese network designs,https://www.reddit.com/r/MachineLearning/comments/6ew7q0/r_iterating_through_siamese_network_designs/,amplifier_khan,1496428212,,0,1
72,2017-6-3,2017,6,3,3,6ewbvo,[D] Large scale character-level language modeling,https://www.reddit.com/r/MachineLearning/comments/6ewbvo/d_large_scale_characterlevel_language_modeling/,chitstudent,1496429321,"I'm curious if anyone has tried training character-level language models on datasets that are larger than the Hutter-prize dataset, and if they're useful at all. I tried recurrent highway networks (https://arxiv.org/abs/1607.03474) on the One Billion Word benchmark (it takes a whole 2 weeks to train a 100 million parameter model on a single TitanX) and the best model I have so far gets ~1.4 bits/char. I'm not aware of other benchmarks on this dataset for character-level LMs (maybe it's a bad idea to start with?)",6,6
73,2017-6-3,2017,6,3,3,6ewdz7,[R] Deep Forest: Towards an Alternative to Deep Neural Networks [code],https://www.reddit.com/r/MachineLearning/comments/6ewdz7/r_deep_forest_towards_an_alternative_to_deep/,bobchennan,1496429888,,24,50
74,2017-6-3,2017,6,3,4,6ewr1s,[N] Jeff wrote in IEEE Spectrum. What Intelligent Machines Need to Learn From the Neocortex,https://www.reddit.com/r/MachineLearning/comments/6ewr1s/n_jeff_wrote_in_ieee_spectrum_what_intelligent/,nocortex,1496433392,,16,12
75,2017-6-3,2017,6,3,5,6ewsgy,"[D] Thinc from spaCy - a ""no computational graph, just higher order functions"" framework",https://www.reddit.com/r/MachineLearning/comments/6ewsgy/d_thinc_from_spacy_a_no_computational_graph_just/,visarga,1496433798,,24,68
76,2017-6-3,2017,6,3,7,6exoba,[R] Constrained Policy Optimization,https://www.reddit.com/r/MachineLearning/comments/6exoba/r_constrained_policy_optimization/,tensor_every_day20,1496442836,,2,22
77,2017-6-3,2017,6,3,11,6eyr6a,The Evolution of Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/6eyr6a/the_evolution_of_gradient_descent/,funmaster11,1496455788,,0,1
78,2017-6-3,2017,6,3,11,6eyusl,[D] Literature on Tensor Networks,https://www.reddit.com/r/MachineLearning/comments/6eyusl/d_literature_on_tensor_networks/,oqowa,1496457122,"Hey guys, again as I said I'm a complete newbie, I'm trying to learn, but I find it a bit difficult to understand TNs like MPS, PEPS and etc. Can you recommend me anything for reading to understand all that stuff?",1,0
79,2017-6-3,2017,6,3,11,6eywfv,[R] Good Semi-supervised Learning that Requires a Bad GAN,https://www.reddit.com/r/MachineLearning/comments/6eywfv/r_good_semisupervised_learning_that_requires_a/,drlukeor,1496457704,,7,11
80,2017-6-3,2017,6,3,12,6ez3uj,"Grape Destemmer and Crusher Processing Equipment, wine producing",https://www.reddit.com/r/MachineLearning/comments/6ez3uj/grape_destemmer_and_crusher_processing_equipment/,LingxianMachinery,1496460540,,1,1
81,2017-6-3,2017,6,3,15,6ezrau,"[R] Andrej Karpathy: ""AlphaGo, in context""",https://www.reddit.com/r/MachineLearning/comments/6ezrau/r_andrej_karpathy_alphago_in_context/,downtownslim,1496470487,,39,131
82,2017-6-3,2017,6,3,15,6ezwjf,"[R] [1705.09675] Fisher GAN &lt;-- better inception scores, less compute overhead",https://www.reddit.com/r/MachineLearning/comments/6ezwjf/r_170509675_fisher_gan_better_inception_scores/,evc123,1496473132,,12,5
83,2017-6-3,2017,6,3,17,6f0676,Major ML Project,https://www.reddit.com/r/MachineLearning/comments/6f0676/major_ml_project/,[deleted],1496478329,[removed],0,1
84,2017-6-3,2017,6,3,18,6f0g7k,Deep Learning CNNs in Tensorflow with GPUs  Hacker Noon,https://www.reddit.com/r/MachineLearning/comments/6f0g7k/deep_learning_cnns_in_tensorflow_with_gpus_hacker/,pmz,1496483989,,0,1
85,2017-6-3,2017,6,3,20,6f0pqa,[D] - Data Labeling Software To Label Specific Pixels In An Image,https://www.reddit.com/r/MachineLearning/comments/6f0pqa/d_data_labeling_software_to_label_specific_pixels/,matt_hammond,1496488963,[removed],0,2
86,2017-6-3,2017,6,3,20,6f0tqu,[D] Is this correct implementation of AlexNet with TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/6f0tqu/d_is_this_correct_implementation_of_alexnet_with/,[deleted],1496490911,[deleted],8,1
87,2017-6-3,2017,6,3,21,6f0vdr,College plans,https://www.reddit.com/r/MachineLearning/comments/6f0vdr/college_plans/,apaar123,1496491628,[removed],0,1
88,2017-6-4,2017,6,4,0,6f1o6z,Fader Networks: Manipulating Images by Sliding Attributes,https://www.reddit.com/r/MachineLearning/comments/6f1o6z/fader_networks_manipulating_images_by_sliding/,guismay,1496502826,,0,1
89,2017-6-4,2017,6,4,0,6f1rhw,[D] Dask for deep learning?,https://www.reddit.com/r/MachineLearning/comments/6f1rhw/d_dask_for_deep_learning/,andyandy16,1496503910,"Dask is a Python library that provides ""flexible parallel computing library for analytic computing."" http://dask.pydata.org/en/latest/ 

 - Anyone tried using this for deep learning? Perhaps with an existing library (e.g. PyTorch, Keras,...)?",5,2
90,2017-6-4,2017,6,4,2,6f2hjs,Practical Neural Networks with Keras: Classifying Yelp Reviews,https://www.reddit.com/r/MachineLearning/comments/6f2hjs/practical_neural_networks_with_keras_classifying/,sixhobbits,1496512185,,1,1
91,2017-6-4,2017,6,4,2,6f2hwd,A multi-label SaaS for a team that doesn't have a machine learning expert?,https://www.reddit.com/r/MachineLearning/comments/6f2hwd/a_multilabel_saas_for_a_team_that_doesnt_have_a/,[deleted],1496512304,[removed],0,1
92,2017-6-4,2017,6,4,3,6f2lf8,[D] Question re Gan literature,https://www.reddit.com/r/MachineLearning/comments/6f2lf8/d_question_re_gan_literature/,Powlerbare,1496513379,"I don't really know if this is frowned upon but since I don't keep up to date with all the more recent gan literature I figure I will ask here.

Are there any gan frameworks where the generator is trained by producing a sample that is not only going to incur a large loss in the discriminator - but also be far from samples in the data distribution (i.e. maximize euclidean distance from some near neighbors) or with an orthogonality constraint between the generated sample and some samples from the data distribution.",2,4
93,2017-6-4,2017,6,4,4,6f2vfc,"Any JavaScript library that can be trained offline, and deployed to client-side for execution?",https://www.reddit.com/r/MachineLearning/comments/6f2vfc/any_javascript_library_that_can_be_trained/,staymanh,1496516508,[removed],0,1
94,2017-6-4,2017,6,4,5,6f3d7k,"[R] ""Deep Generative Adversarial Networks for Compressed Sensing Automates MRI"", Mardani et al 2017",https://www.reddit.com/r/MachineLearning/comments/6f3d7k/r_deep_generative_adversarial_networks_for/,gwern,1496522311,,13,15
95,2017-6-4,2017,6,4,5,6f3g0i,Can the ideas behind the VAE also be used for regression?,https://www.reddit.com/r/MachineLearning/comments/6f3g0i/can_the_ideas_behind_the_vae_also_be_used_for/,[deleted],1496523206,[removed],0,1
96,2017-6-4,2017,6,4,5,6f3gbq,"Hi ! For my master thesis ""AI in information science"" I'm looking for people who do tasks like indexing, classification or manage databasis (librarians, documentalists, etc. are welcome !). It's very quick, 21 questions, 4 minutes max.",https://www.reddit.com/r/MachineLearning/comments/6f3gbq/hi_for_my_master_thesis_ai_in_information_science/,[deleted],1496523309,[deleted],0,1
97,2017-6-4,2017,6,4,6,6f3i9v,[D]Can the ideas behind VAEs also be used for regular regression?,https://www.reddit.com/r/MachineLearning/comments/6f3i9v/dcan_the_ideas_behind_vaes_also_be_used_for/,maka89,1496523907,I was wondering if some of the ideas behind VAEs could be used for simple regression tasks as well? The hope being that it would provide some error estimates for the neural networks predictions. Like with Gaussian Process Regression,8,10
98,2017-6-4,2017,6,4,6,6f3mvr,How come we hear about OpenAI but not the Allen AI Institute?,https://www.reddit.com/r/MachineLearning/comments/6f3mvr/how_come_we_hear_about_openai_but_not_the_allen/,satsatsat,1496525441,[removed],0,1
99,2017-6-4,2017,6,4,7,6f42i9,"[D] Can someone explain what the ""Dirac"" tensor is in ""DiracNets?""",https://www.reddit.com/r/MachineLearning/comments/6f42i9/d_can_someone_explain_what_the_dirac_tensor_is_in/,darkconfidantislife,1496530431,"I'm talking about this paper: https://arxiv.org/abs/1706.00388

They define a special ""dirac tensor"", which doesn't appear to be the normal identity convolution kernel which is all zeroes except for 1 in the middle. Can someone explain what it is? ",9,30
100,2017-6-4,2017,6,4,8,6f47vt,Ideas for ML project at internship,https://www.reddit.com/r/MachineLearning/comments/6f47vt/ideas_for_ml_project_at_internship/,[deleted],1496532176,[removed],0,1
101,2017-6-4,2017,6,4,9,6f4fd4,[D] Openly sharing NIPS submissions?,https://www.reddit.com/r/MachineLearning/comments/6f4fd4/d_openly_sharing_nips_submissions/,NeuroBoss31,1496534753,"Despite NIPS being double-blind in reviews: It is ok to circulate an ArXiv version of a NIPS submission on say social networks, Reddit, etc...? Thoughts? Some colleagues and I are curious, since ArXiv officially makes the submission public to everyone, but should we insist on say posting it on Reddit? Or sharing it among other labs (and by accident sharing it to a potential reviewer)? I think posting it on Reddit is a great idea since it gives us public reviews (whether its bashing or praising the paper). This should also prepare us for the official reviews, and we can check for consistency in comments, holes or edges in our work.",5,4
102,2017-6-4,2017,6,4,10,6f4p9p,How is this not the most discussed paper in Computer Vision right now?!,https://www.reddit.com/r/MachineLearning/comments/6f4p9p/how_is_this_not_the_most_discussed_paper_in/,ML_UnifyID,1496538287,,0,1
103,2017-6-4,2017,6,4,13,6f5nzs,Does anyone know if AlphaGo has access to previous games while it is playing?,https://www.reddit.com/r/MachineLearning/comments/6f5nzs/does_anyone_know_if_alphago_has_access_to/,CarefreeCastle,1496551865,[removed],0,1
104,2017-6-4,2017,6,4,14,6f5rwt,[D] Deep Learning | Udacity - YouTube,https://www.reddit.com/r/MachineLearning/comments/6f5rwt/d_deep_learning_udacity_youtube/,[deleted],1496553576,[deleted],4,0
105,2017-6-4,2017,6,4,14,6f5vze,The Machine Intelligence Behind Google's Gboard,https://www.reddit.com/r/MachineLearning/comments/6f5vze/the_machine_intelligence_behind_googles_gboard/,shash747,1496555483,,0,1
106,2017-6-4,2017,6,4,15,6f5xa8,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6f5xa8/shot_blasting_machine/,Shot-blasting,1496556127,,1,1
107,2017-6-4,2017,6,4,15,6f5zwc,Neural Net giving same output for all inputs,https://www.reddit.com/r/MachineLearning/comments/6f5zwc/neural_net_giving_same_output_for_all_inputs/,BeastjungleNA,1496557432,[removed],0,1
108,2017-6-4,2017,6,4,17,6f6awu,Is it possible to combine a Denoising Autoencoder and Contractive Autoencoder?,https://www.reddit.com/r/MachineLearning/comments/6f6awu/is_it_possible_to_combine_a_denoising_autoencoder/,JamminJames921,1496563589,[removed],0,1
109,2017-6-4,2017,6,4,19,6f6n8g,[R] [1705.10201] Machine Learned Learning Machines,https://www.reddit.com/r/MachineLearning/comments/6f6n8g/r_170510201_machine_learned_learning_machines/,cbeak,1496570873,,15,13
110,2017-6-4,2017,6,4,20,6f6wwz,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6f6wwz/shot_blasting_machine/,Shot-blasting,1496576111,,0,1
111,2017-6-4,2017,6,4,23,6f7jxl,"[P] Visualizing the Latent Space of Vector Drawings from the Google QuickDraw Dataset with SketchRNN, PCA and t-SNE",https://www.reddit.com/r/MachineLearning/comments/6f7jxl/p_visualizing_the_latent_space_of_vector_drawings/,HeAintEvenStretchDoe,1496585966,,0,12
112,2017-6-4,2017,6,4,23,6f7kmx,[D] Statistical Learning Theory &amp; Math,https://www.reddit.com/r/MachineLearning/comments/6f7kmx/d_statistical_learning_theory_math/,Kiuhnm,1496586211,"As part of my preparation for doing research in AI/RL, I'm about to study Statistical Learning Theory. My main sources of material are:

1. [Statistical Learning Theory and Applications](http://www.mit.edu/~9.520/fall15/index.html)
2. [Statistical Machine Learning](http://www.stat.cmu.edu/~ryantibs/statml/)
3. [High Dimensional Probability](https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.html#) [free book]

I'm not a mathematician but a computer scientist so I took several courses about discrete math (combinatorics, generating functions, etc...), but only two about Analysis (*not* calculus).

My understanding is that to gain a proper understanding of probability and statistical learning theory I need to study Measure Theory and Functional Analysis.

Should I study both topic well ([Kolmogorov&amp;Fomin](https://www.amazon.com/Introductory-Analysis-Dover-Books-Mathematics/dp/0486612260) or [Serge Lang](https://www.amazon.com/Functional-Analysis-Graduate-Texts-Mathematics/dp/0387940014/)) or just focus on Functional Analysis without Measure Theory ([Kreyszig](https://www.amazon.com/Introductory-Functional-Analysis-Applications-Kreyszig/dp/0471504599/))?

While many practitioners claim that math is not so important in ML, many ML researchers know quite a lot of math. One researcher told me that he learned a lot of math early in his career but that, ultimately, he didn't use any of that stuff in his research. But how can he be so sure? Maybe his mathematical studies formed his way of thinking and he's using mathematical ideas without even realizing it.

What are your suggestions?",30,135
113,2017-6-4,2017,6,4,23,6f7ml1,[P] PyTorch implementation of Interpretable Explanations of Black Boxes by Meaningful Perturbation,https://www.reddit.com/r/MachineLearning/comments/6f7ml1/p_pytorch_implementation_of_interpretable/,jacobgil,1496586872,,1,15
114,2017-6-5,2017,6,5,2,6f8gtq,"[R] ""in the brain, such a representation is produced by an architecture similar to a hierarchical feedforward deep-network""",https://www.reddit.com/r/MachineLearning/comments/6f8gtq/r_in_the_brain_such_a_representation_is_produced/,downtownslim,1496596395,,2,27
115,2017-6-5,2017,6,5,3,6f8qfk,"AI limitations, repeatedly learn how to defeat itself",https://www.reddit.com/r/MachineLearning/comments/6f8qfk/ai_limitations_repeatedly_learn_how_to_defeat/,strojax,1496599257,[removed],0,1
116,2017-6-5,2017,6,5,3,6f8w4w,[D] You can probably use deep learning even if your data isn't that big,https://www.reddit.com/r/MachineLearning/comments/6f8w4w/d_you_can_probably_use_deep_learning_even_if_your/,beamsearch,1496600902,,23,104
117,2017-6-5,2017,6,5,4,6f9aph,Looking for hardware suggestions,https://www.reddit.com/r/MachineLearning/comments/6f9aph/looking_for_hardware_suggestions/,danilo_da_mosca,1496605186,[removed],0,1
118,2017-6-5,2017,6,5,5,6f9l0o,Revolutionary Discovery About the Human Brain Could Lead to Second-Gen AI,https://www.reddit.com/r/MachineLearning/comments/6f9l0o/revolutionary_discovery_about_the_human_brain/,johnmountain,1496608141,,0,1
119,2017-6-5,2017,6,5,5,6f9oc6,Free Auto Captcha Solver Service and Cheap Captcha Bypass Service Provider ~ Captcha Solutions,https://www.reddit.com/r/MachineLearning/comments/6f9oc6/free_auto_captcha_solver_service_and_cheap/,articlefr,1496609124,,0,1
120,2017-6-5,2017,6,5,7,6faed9,Optimal Reinforcement Learning state representation in card stacking game?,https://www.reddit.com/r/MachineLearning/comments/6faed9/optimal_reinforcement_learning_state/,SummitSnowStorm,1496617024,[removed],0,1
121,2017-6-5,2017,6,5,9,6fay97,[D] Test data for the Iris flower data set?,https://www.reddit.com/r/MachineLearning/comments/6fay97/d_test_data_for_the_iris_flower_data_set/,CocoaGeek,1496623409,"Hello there,

Anybody knows if there's some test data for the (famous) Iris Flower data set? I'll like to not have to randomly pick some of the data from the set to reserve for testing since it's sort of a small set already (150 in total).

Did some googling but came back empty handed. 

Thanks,",7,6
122,2017-6-5,2017,6,5,10,6fb1l5,RealNVP guide ?,https://www.reddit.com/r/MachineLearning/comments/6fb1l5/realnvp_guide/,ispamtechies,1496624515,[removed],0,1
123,2017-6-5,2017,6,5,10,6fb3cu,67 Questions with a Lyft Data Scientist,https://www.reddit.com/r/MachineLearning/comments/6fb3cu/67_questions_with_a_lyft_data_scientist/,funmaster11,1496625083,,0,1
124,2017-6-5,2017,6,5,10,6fb62y,Facial images can be linearly reconstructed using responses of ~ 200 cells,https://www.reddit.com/r/MachineLearning/comments/6fb62y/facial_images_can_be_linearly_reconstructed_using/,[deleted],1496626001,[removed],0,1
125,2017-6-5,2017,6,5,11,6fbeih,machine learning models for subscription service renewals,https://www.reddit.com/r/MachineLearning/comments/6fbeih/machine_learning_models_for_subscription_service/,sirohin,1496628829,[removed],0,1
126,2017-6-5,2017,6,5,11,6fbk2u,Teaching a course using deep learning. What GPU resources would you recommend?,https://www.reddit.com/r/MachineLearning/comments/6fbk2u/teaching_a_course_using_deep_learning_what_gpu/,kywang,1496630655,[removed],0,1
127,2017-6-5,2017,6,5,13,6fbzdx,[R] [1706.00527] Data Augmentation of Wearable Sensor Data,https://www.reddit.com/r/MachineLearning/comments/6fbzdx/r_170600527_data_augmentation_of_wearable_sensor/,terryum,1496636000,,15,55
128,2017-6-5,2017,6,5,13,6fc02w,"[D] Latent Factor Models, EM, and constructing statistical models",https://www.reddit.com/r/MachineLearning/comments/6fc02w/d_latent_factor_models_em_and_constructing/,millenniumpianist,1496636253,"Hi folks,

I realize this is outside of the usual scope of /r/machinelearning but I still think it's appropriate to post here. It's a ""help"" question in a sense, but it's not a simple one. So I believe it abides by subreddit policy.

 I've had this problem on a recommender system for a while ([here is a Stack Exchange post I made on it] (https://stats.stackexchange.com/questions/283414/using-the-em-algorithm-on-a-latent-factor-model-collaborative-filtering)) and haven't managed to get a good answer.

Specifically, my question stems from a desire to use EM on a latent factor modeling (i.e. a collaborative filtering algorithm) to infer missing genre information in the model. I do know the math behind EM (but not perfectly), and I have an intuition of how to use it in practice. Based on that intuition, I think in the E-step, I want to compute the likelihood that a movie without genre information falls into each of my 20 genres. And in the M-step, I want to optimize my model based on the best imputation of the missing values.

But now I realize that I have fundamental questions on how to apply EM that underly the confusion in my Stack Exchange post:

In a normal EM definition, you have your model parameters ****, your data **X**, and your missing/latent variables **Z**. I believe in my model, **** refers to the parameters of my latent factor model (, , , , ); **X** refers to the user/item ratings pairs; and **Z** refers to the genre information () that is missing for some movies -- for starters, is that the correct formulation?

And more importantly, I'm not sure how to construct the proper likelihood function, based on my latent factor model: **L(, X, Z) = P(X,Z|)**. I'm not even sure how to begin here. Any amount of guidance would be much appreciated.

Thanks!",11,2
129,2017-6-5,2017,6,5,13,6fc081,Software engineering book recommendations,https://www.reddit.com/r/MachineLearning/comments/6fc081/software_engineering_book_recommendations/,transhumanist_,1496636302,[removed],0,1
130,2017-6-5,2017,6,5,15,6fcf6y,what is the state of the art in classifying text into analytical/scholarly/high grade level vs not?,https://www.reddit.com/r/MachineLearning/comments/6fcf6y/what_is_the_state_of_the_art_in_classifying_text/,textClasss,1496642423,[removed],0,1
131,2017-6-5,2017,6,5,15,6fcgky,[D] what is the state of the art in classifying text into analytical/scholarly/high grade level vs not?,https://www.reddit.com/r/MachineLearning/comments/6fcgky/d_what_is_the_state_of_the_art_in_classifying/,textClasss,1496643030,"That's really all I have to ask, googling for classifying text into analytical vs not yields nothing.",1,0
132,2017-6-5,2017,6,5,15,6fcjdb,What is the stainless steel kneader?,https://www.reddit.com/r/MachineLearning/comments/6fcjdb/what_is_the_stainless_steel_kneader/,JCT_MACHINE,1496644294,,0,1
133,2017-6-5,2017,6,5,15,6fcltk,How NATO wants to use Artificial Intelligence in decision making,https://www.reddit.com/r/MachineLearning/comments/6fcltk/how_nato_wants_to_use_artificial_intelligence_in/,hardikmakadia,1496645480,,0,1
134,2017-6-5,2017,6,5,16,6fct8w,An Unsupervised Clustering Model with Temporal Context,https://www.reddit.com/r/MachineLearning/comments/6fct8w/an_unsupervised_clustering_model_with_temporal/,DuanneDames,1496649027,[removed],0,1
135,2017-6-5,2017,6,5,18,6fd4dp,What Are The Best Intelligent Chatbots or AI Chatbots Available Online?,https://www.reddit.com/r/MachineLearning/comments/6fd4dp/what_are_the_best_intelligent_chatbots_or_ai/,hardikmakadia,1496654811,,0,1
136,2017-6-5,2017,6,5,19,6fdby2,How Machine Learning Will Change the Concept of Customer Service,https://www.reddit.com/r/MachineLearning/comments/6fdby2/how_machine_learning_will_change_the_concept_of/,MariaLinsey,1496658322,,0,1
137,2017-6-5,2017,6,5,20,6fdifq,Automated Pallet Truck Market Research Report 2017,https://www.reddit.com/r/MachineLearning/comments/6fdifq/automated_pallet_truck_market_research_report_2017/,Reportsandmarkets,1496661096,,0,1
138,2017-6-5,2017,6,5,21,6fdquv,[D] My convolutional network for segmentation seems to generalize after training it on only one sample (python/keras code inside),https://www.reddit.com/r/MachineLearning/comments/6fdquv/d_my_convolutional_network_for_segmentation_seems/,DeepDeeperRIPgradien,1496664364,"Context: yesterday I shortly described a little toy experiment and some people were interested to see the code ( https://www.reddit.com/r/MachineLearning/comments/6f8w4w/d_you_can_probably_use_deep_learning_even_if_your/digl2u0/ )

**tl;dr** (for more information look at the repo linked below): I trained a convolutional network (U-net architecture) with 13 million parameters to segment a circle on a noisy image and training it on only one sample was enough to make the network able to segment circles of other sizes and location.

Just to be clear, I don't claim to have found anything novel, I'm just curious how people with more expertise would interpret this result since I for myself just expected the network to memorize the one training sample and as a result do bad on unseen samples. (Edit: ""My network"" was not worded well, I did not invent the architecture, it's (a modified version of?) the U-net architecture).

Repository: https://github.com/mdfwn/Segmentation-Experiment",4,20
139,2017-6-5,2017,6,5,21,6fdxj1,Bender: a framework to use Neural Networks on iOS,https://www.reddit.com/r/MachineLearning/comments/6fdxj1/bender_a_framework_to_use_neural_networks_on_ios/,bryant1410,1496666637,[removed],0,1
140,2017-6-5,2017,6,5,21,6fdz16,How the Internet Is Loosening Our Grip on the Truth,https://www.reddit.com/r/MachineLearning/comments/6fdz16/how_the_internet_is_loosening_our_grip_on_the/,stephenbhope,1496667165,,1,1
141,2017-6-5,2017,6,5,22,6fe0jn,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6fe0jn/shot_blasting_machine/,Shot-blasting,1496667682,,0,1
142,2017-6-5,2017,6,5,22,6fe3dw,[P] Bender: a framework to use Neural Networks on iOS on top of Metal,https://www.reddit.com/r/MachineLearning/comments/6fe3dw/p_bender_a_framework_to_use_neural_networks_on/,bryant1410,1496668579,,14,30
143,2017-6-5,2017,6,5,22,6fe5cy,"[P]WebDNN: fast JS library for running trained DL models in the browser. Compatible with models from Keras, Caffe",https://www.reddit.com/r/MachineLearning/comments/6fe5cy/pwebdnn_fast_js_library_for_running_trained_dl/,finallyifoundvalidUN,1496669223,,4,35
144,2017-6-5,2017,6,5,22,6fe6ir,[D] In depth look at the superhuman Stanford dermatology paper (Jan 17).,https://www.reddit.com/r/MachineLearning/comments/6fe6ir/d_in_depth_look_at_the_superhuman_stanford/,[deleted],1496669573,[deleted],0,1
145,2017-6-5,2017,6,5,22,6fe7qb,Do Tensorflow or Tensorboard provide a solution like Azure Machine Learning Studio?,https://www.reddit.com/r/MachineLearning/comments/6fe7qb/do_tensorflow_or_tensorboard_provide_a_solution/,tensorquery,1496669949,,0,1
146,2017-6-5,2017,6,5,22,6fe7s5,"What, in your opinion, are the top tier schools for a master's program?",https://www.reddit.com/r/MachineLearning/comments/6fe7s5/what_in_your_opinion_are_the_top_tier_schools_for/,cameronwhite1995,1496669964,[removed],0,1
147,2017-6-5,2017,6,5,22,6fe8dt,[D] In depth look at the superhuman Stanford dermatology paper (Jan 17).,https://www.reddit.com/r/MachineLearning/comments/6fe8dt/d_in_depth_look_at_the_superhuman_stanford/,drlukeor,1496670165,,7,27
148,2017-6-5,2017,6,5,23,6fecpk,[R] [1706.00550] On Unifying Deep Generative Models,https://www.reddit.com/r/MachineLearning/comments/6fecpk/r_170600550_on_unifying_deep_generative_models/,bobchennan,1496671462,,3,20
149,2017-6-5,2017,6,5,23,6fedrc,[D] Non-linearity and word embedding layer,https://www.reddit.com/r/MachineLearning/comments/6fedrc/d_nonlinearity_and_word_embedding_layer/,Pieranha,1496671751,Many NLP models use an embedding layer that is learned from scratch on their specific data. This is basically a fully-connected layer with giant weight matrix multiplied by a one-hot vector. For any other fully-connected layer one would alway apply a non-linearity. So why is there often no non-linearity applied after the embedding multiplication?,4,5
150,2017-6-5,2017,6,5,23,6fefjf,[R] [1706.00531] PixelGAN Autoencoders,https://www.reddit.com/r/MachineLearning/comments/6fefjf/r_170600531_pixelgan_autoencoders/,[deleted],1496672266,[deleted],0,1
151,2017-6-5,2017,6,5,23,6feiuo,[R] How does DeepMind do research?,https://www.reddit.com/r/MachineLearning/comments/6feiuo/r_how_does_deepmind_do_research/,rantana,1496673217,"How does DeepMind choose research topics to focus on?

Going through DeepMind's publication lists, their focus seems a bit more narrow than other labs. Yet they are probably one of the largest (if not the largest) research group with about 400 people (https://en.wikipedia.org/wiki/DeepMind) . 

For example, the have a great deal of work on generative models but no work on GANs. They also have a great deal of focus on Reinforcement Learning but not robotics. Compare this to places like OpenAI, Facebook, Google Brain who seem to dabble in a little of everything.",27,40
152,2017-6-6,2017,6,6,0,6feznz,[D] Is there PILCO code in Python ?,https://www.reddit.com/r/MachineLearning/comments/6feznz/d_is_there_pilco_code_in_python/,xingdongrobotics,1496677658,"We are working on a project related to PILCO, and really willing to know if there has already been publicly available code of PILCO in Python ?",3,3
153,2017-6-6,2017,6,6,1,6ff4mm,Masters in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6ff4mm/masters_in_machine_learning/,[deleted],1496678893,[removed],0,1
154,2017-6-6,2017,6,6,1,6ff6ku,[P] Anyone have experience with CNNs (convolutional neural nets) in Keras/Python? Would appreciate some help. (x-post from /r/datascience),https://www.reddit.com/r/MachineLearning/comments/6ff6ku/p_anyone_have_experience_with_cnns_convolutional/,riders994,1496679358,"Hi, I'm trying to set up a CNN in Keras, and I don't have much experience outside of simple NNs as far as the actual setup. I understand how the CNN is going to work on my data, but I need advice on how to set it up in Keras.

In my dataset, each datapoint is structured as follows. There are *n* columns, each of which is sensor data of people performing an action. There are 10 rows where each row is a single person's sensor data for that event. The label column is a score for how well they performed. Since each of their performances is related, each datapoint is a 10 by *n* matrix, and the label column for each data point is a 10 by 1 vector of scores.

Essentially, I want to set up my NN so that it treats:

Person | Sensor0 | Sensor1 | Sensor2 | Win
---|---|----|----|----
A | data | data | data | 0
B | data | data | data | 0
C | data | data | data | 0
D | data | data | data | 0
E | data | data | data | 0
F | data | data | data | 0
G | data | data | data | 0
H | data | data | data | 1
I | data | data | data | 0
J | data | data | data | 0

the same as:

Person | Sensor0 | Sensor1 | Sensor2 | Win
---|---|----|----|----
E | data | data | data | 0
C | data | data | data | 0
I | data | data | data | 0
F | data | data | data | 0
G | data | data | data | 0
H | data | data | data | 1
D | data | data | data | 0
B | data | data | data | 0
A | data | data | data | 0
F | data | data | data | 0

In my first layer (at the least), I want to set up convolutional neurons (I'm starting with 5, and moving on from there) so that each row shares weights amongst the observations, in such a way that the order I put the row in the datapoint doesn't matter (aside from it's correspondence with the label). Anyone know if this is possible? Otherwise I'll have to feed in each datapoint in all 10! orders, and I would prefer not to...

Any help is appreciated, thank you!",8,4
155,2017-6-6,2017,6,6,2,6ffpnp,"Implementing LASSO Regression with Coordinate Descent, Sub-Gradient of the L1 Penalty and Soft Thresholding in Python",https://www.reddit.com/r/MachineLearning/comments/6ffpnp/implementing_lasso_regression_with_coordinate/,SandipanDeyUMBC,1496684159,,0,1
156,2017-6-6,2017,6,6,2,6ffqbi,[P] Tensorflow implementation of Seq2seq using tf.contrib.seq2seq API (tf.1.2.rc1),https://www.reddit.com/r/MachineLearning/comments/6ffqbi/p_tensorflow_implementation_of_seq2seq_using/,uwanggood,1496684314,,0,1
157,2017-6-6,2017,6,6,3,6ffwr3,[R] Hyperparameter Optimization: A Spectral Approach,https://www.reddit.com/r/MachineLearning/comments/6ffwr3/r_hyperparameter_optimization_a_spectral_approach/,pauljasek,1496685935,,9,18
158,2017-6-6,2017,6,6,3,6fg24h,"[D] Early termination, loss, accuracy, or other?",https://www.reddit.com/r/MachineLearning/comments/6fg24h/d_early_termination_loss_accuracy_or_other/,BrokenGumdrop,1496687277,"For those of you who have early termination criteria for training your neural networks, how did you decide what to monitor?  My project has a binary classifier and I've been using loss on validation data. After a recent set of experiments where I increased the amount of data used in training vs testing, the performance went down, I'm starting to question the early stopping.  ",10,1
159,2017-6-6,2017,6,6,3,6fg7am,[P][D] Podcast advertisement scrubber,https://www.reddit.com/r/MachineLearning/comments/6fg7am/pd_podcast_advertisement_scrubber/,croofta,1496688561,"I'd like to build and train a model that can identify ad segments in podcasts. I've been learning about tensorflow from this tutorial https://www.tensorflow.org/tutorials/. It looks like this problem could be approached in a similar way to the way the MNIST problem was solved in the tutorials.

- Build a dataset of 5 second audio clips, marked as either 'entirely ad', or 'partial ad/no ad' 
- convert each clip into a large rank 1 vector (x), with each coordinate being a value of a sample
- the model has a rank two variable vector (W) containing the weights for not an ad / is an add, and another rank two variable vector (b) with the biases 
- so the model is as in the tutorial: y = tf.nn.softmax(tf.matmul(x, W) + b)
- could use same loss function / optimizer as in the tutorial as well

What do you think? Would that work? How would you go about it?
",1,1
160,2017-6-6,2017,6,6,3,6fg7px,Movie Recommendation with Bayesian,https://www.reddit.com/r/MachineLearning/comments/6fg7px/movie_recommendation_with_bayesian/,SandipanDeyUMBC,1496688675,,0,1
161,2017-6-6,2017,6,6,4,6fga6w,Distributed K-Means with R-Hadoop,https://www.reddit.com/r/MachineLearning/comments/6fga6w/distributed_kmeans_with_rhadoop/,SandipanDeyUMBC,1496689321,,0,1
162,2017-6-6,2017,6,6,4,6fgblm,How useful is the skill of writing complex neural networks from scratch in today's market?,https://www.reddit.com/r/MachineLearning/comments/6fgblm/how_useful_is_the_skill_of_writing_complex_neural/,ronsap123,1496689656,[removed],0,1
163,2017-6-6,2017,6,6,4,6fgi7l,[D] Which GAN achieves the highest quality generation?,https://www.reddit.com/r/MachineLearning/comments/6fgi7l/d_which_gan_achieves_the_highest_quality/,pauljasek,1496691319,"These days new GAN models are proposed nearly every day. With such a large amount to search through, I am afraid that I may have missed some of the best results.",4,3
164,2017-6-6,2017,6,6,4,6fgjk3,"[N] spaCy v2.0.0 alpha released! New neural network model (15 MB), multi-language NER, improved serialization (including pickle), better training API",https://www.reddit.com/r/MachineLearning/comments/6fgjk3/n_spacy_v200_alpha_released_new_neural_network/,syllogism_,1496691676,,0,63
165,2017-6-6,2017,6,6,4,6fgkih,Using PCA to Detect Outliers in Images,https://www.reddit.com/r/MachineLearning/comments/6fgkih/using_pca_to_detect_outliers_in_images/,SandipanDeyUMBC,1496691889,,0,1
166,2017-6-6,2017,6,6,5,6fgohz,Using PCA to represent digits in the eigen-digits space,https://www.reddit.com/r/MachineLearning/comments/6fgohz/using_pca_to_represent_digits_in_the_eigendigits/,SandipanDeyUMBC,1496692878,,0,1
167,2017-6-6,2017,6,6,5,6fgr00,Dataset Augmentation in Feature Space,https://www.reddit.com/r/MachineLearning/comments/6fgr00/dataset_augmentation_in_feature_space/,ark_aung,1496693480,,0,1
168,2017-6-6,2017,6,6,5,6fgr0o,Comparing GMM-EM soft clustering with KMeans hard clustering,https://www.reddit.com/r/MachineLearning/comments/6fgr0o/comparing_gmmem_soft_clustering_with_kmeans_hard/,SandipanDeyUMBC,1496693485,,0,1
169,2017-6-6,2017,6,6,5,6fgtkq,Training Backpropagation Neural Nets on the handwritten digits dataset,https://www.reddit.com/r/MachineLearning/comments/6fgtkq/training_backpropagation_neural_nets_on_the/,SandipanDeyUMBC,1496694128,,0,1
170,2017-6-6,2017,6,6,5,6fgwf4,Locality Sensitive Hashing Implementation for Approximate Fast Nearest Neighbor Search in R,https://www.reddit.com/r/MachineLearning/comments/6fgwf4/locality_sensitive_hashing_implementation_for/,SandipanDeyUMBC,1496694794,,0,1
171,2017-6-6,2017,6,6,5,6fh2az,What will Metal2 do for deep learning?,https://www.reddit.com/r/MachineLearning/comments/6fh2az/what_will_metal2_do_for_deep_learning/,venom310,1496696243,[removed],0,1
172,2017-6-6,2017,6,6,6,6fh4s5,[P] Conditional Generative Adversarial Network (cGAN) with MXNet R package,https://www.reddit.com/r/MachineLearning/comments/6fh4s5/p_conditional_generative_adversarial_network_cgan/,phunter_lau,1496696859,,1,9
173,2017-6-6,2017,6,6,6,6fh522,[N[ Apple Core ML,https://www.reddit.com/r/MachineLearning/comments/6fh522/n_apple_core_ml/,[deleted],1496696932,[deleted],0,1
174,2017-6-6,2017,6,6,6,6fh5ay,[N] Apple Core ML,https://www.reddit.com/r/MachineLearning/comments/6fh5ay/n_apple_core_ml/,clbam8,1496696997,,38,122
175,2017-6-6,2017,6,6,6,6fh9k9,[D] What are some techniques that can be used on this sort of image segmentation problem?,https://www.reddit.com/r/MachineLearning/comments/6fh9k9/d_what_are_some_techniques_that_can_be_used_on/,Paddapa,1496698115,"I have a set of images: some of them contain some relatively small artifact (think trademark / logo / etc...). For the images that do indeed contain these artifacts, a label pointing to the artifacts location is provided. The images with no artifacts contain to labels (no label implies no artifact).

I would like to train some sort of architecture that can take in a image and tell me if it thinks the provided image contains an artifact, and if so, where.

A CNN is an obvious candidate here, but I think the abundance of non-artifact pixels will cause trouble. Could someone please point me to some resources where similar types of problems have been addressed? Is there a name for this type of problem?",1,1
176,2017-6-6,2017,6,6,6,6fhd5i,Bias-Variance Trade-off  the impact of regularization on the Decision Boundary for the SVM and the Logistic Regression Classifier,https://www.reddit.com/r/MachineLearning/comments/6fhd5i/biasvariance_tradeoff_the_impact_of/,SandipanDeyUMBC,1496699094,,0,1
177,2017-6-6,2017,6,6,7,6fhhzq,Are there any libraries in python that implement C-LSTMs or AC-BLSTMs?,https://www.reddit.com/r/MachineLearning/comments/6fhhzq/are_there_any_libraries_in_python_that_implement/,[deleted],1496700366,[removed],0,1
178,2017-6-6,2017,6,6,7,6fhnyk,Summary of Variational Dropout Sparsifies Deep Neural Networks on ShortScience.org,https://www.reddit.com/r/MachineLearning/comments/6fhnyk/summary_of_variational_dropout_sparsifies_deep/,ieee8023,1496701975,,0,1
179,2017-6-6,2017,6,6,7,6fhpro,How to find all matches of a matrix inside a matrix?,https://www.reddit.com/r/MachineLearning/comments/6fhpro/how_to_find_all_matches_of_a_matrix_inside_a/,opensourceai,1496702490,[removed],0,1
180,2017-6-6,2017,6,6,7,6fhqw6,Learning Musical Style and Generating Musical Performances using LSTMs,https://www.reddit.com/r/MachineLearning/comments/6fhqw6/learning_musical_style_and_generating_musical/,[deleted],1496702806,[deleted],0,1
181,2017-6-6,2017,6,6,7,6fhr7w,[D] What are you currently working on?,https://www.reddit.com/r/MachineLearning/comments/6fhr7w/d_what_are_you_currently_working_on/,13utters,1496702892,,35,15
182,2017-6-6,2017,6,6,7,6fhtp9,[D] Are there any libraries in python that implement C-LSTMs or AC-BLSTMs?,https://www.reddit.com/r/MachineLearning/comments/6fhtp9/d_are_there_any_libraries_in_python_that/,Blix-,1496703582,"I'm reading [this paper](https://www.semanticscholar.org/paper/AC-BLSTM-Asymmetric-Convolutional-Bidirectional-LS-Liang-Zhang/3ab797635cde14746b58e8f4dbe9dce370d61719) and [this paper](https://www.semanticscholar.org/paper/A-C-LSTM-Neural-Network-for-Text-Classification-Zhou-Sun/10f62af29c3fc5e2572baddca559ffbfd6be8787) and I want to use their novel architectures, but I don't want to build them from scratch. I'm mainly interested in the AC-BLSTM. Are there any python or even java packages that have these pre-built?

I found this: https://github.com/ningshixian/AC-BLSTM/blob/master/model.py
But I haven't cross checked it with the original paper. I was looking for something more official",1,0
183,2017-6-6,2017,6,6,8,6fi1d0,"[D] Tensorflow I Love You, But You're Bringing Me Down",https://www.reddit.com/r/MachineLearning/comments/6fi1d0/d_tensorflow_i_love_you_but_youre_bringing_me_down/,nharada,1496705693,,31,58
184,2017-6-6,2017,6,6,8,6fi4dj,[D] How do you go about hyperparameter searching CNN architectures?,https://www.reddit.com/r/MachineLearning/comments/6fi4dj/d_how_do_you_go_about_hyperparameter_searching/,approximately_wrong,1496706593,"I've never been in a situation where careful optimization of CNN hyperparams was a top priority. But for users who have experience with performing hyperparameter search, what's your preferred approach for searching CNN architectures (Bayesian opt, random search, etc)? Do you include constraints such as the rate of receptive field increase? Do you keep the # layers fixed? I'm curious!",4,2
185,2017-6-6,2017,6,6,8,6fi60t,[R] [1706.00387] Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/6fi60t/r_170600387_interpolated_policy_gradient_merging/,evc123,1496707085,,6,8
186,2017-6-6,2017,6,6,11,6fiva1,[D] A Year in Google Brain Residency Program,https://www.reddit.com/r/MachineLearning/comments/6fiva1/d_a_year_in_google_brain_residency_program/,hardmaru,1496714773,,21,83
187,2017-6-6,2017,6,6,13,6fjj86,ML on Radeons and Apple's External Graphics Dev Kit,https://www.reddit.com/r/MachineLearning/comments/6fjj86/ml_on_radeons_and_apples_external_graphics_dev_kit/,skilless,1496722774,[removed],0,1
188,2017-6-6,2017,6,6,13,6fjkrb,[D] Contrastive max-margin loss implementation in Python using Keras.,https://www.reddit.com/r/MachineLearning/comments/6fjkrb/d_contrastive_maxmargin_loss_implementation_in/,bhatt_gaurav,1496723304,"Hi. I am trying to implement max-margin loss function for negative sampling. I haven't come across a clean implementation of such a loss in Keras. The way I interpret it is that we need to create batches of positive and negative/corrupt samples. Say, the batch size if 100, so it should have 50 positive and 50 negative samples. The loss function receives these individual batches and is implemented as

    def max_margin(y_true, y_pred):
        mid = y_pred.shape[0]/2
        y_pos = y_pred[:mid]
        y_neg = y_pred[mid:]
        return K.mean(K.maximum(0., 1. - y_pos + y_neg))
*Here, y_pred is the cost computed by the model and y_true are the actual lables.*

This implementation does not produce any meaningful results. Is there something that I am missing? 

There can be another solution to achieve max-margin like objective. We can create positive and negative samples and assign them labels as +1 and -1 and use **mean square error(MSE)** loss function instead, simply for classification. I feel that MSE would try to bring the score of positive samples close to +1 and negative samples would have a score that is near -1. Is this not analogous to contrastive max-margin?",1,2
189,2017-6-6,2017,6,6,14,6fjtxe,Variational Autoencoder,https://www.reddit.com/r/MachineLearning/comments/6fjtxe/variational_autoencoder/,[deleted],1496726854,[removed],0,1
190,2017-6-6,2017,6,6,14,6fjyft,Computing Closest Pairs and implementing Clustering methods for 2D datasets in Python,https://www.reddit.com/r/MachineLearning/comments/6fjyft/computing_closest_pairs_and_implementing/,SandipanDeyUMBC,1496728748,,0,1
191,2017-6-6,2017,6,6,15,6fk2i6,[R] [1706.01427] From DeepMind: A simple neural network module for relational reasoning,https://www.reddit.com/r/MachineLearning/comments/6fk2i6/r_170601427_from_deepmind_a_simple_neural_network/,tim_anglade,1496730481,,58,129
192,2017-6-6,2017,6,6,15,6fk4tw,Sand blasting machine,https://www.reddit.com/r/MachineLearning/comments/6fk4tw/sand_blasting_machine/,Shot-blasting,1496731509,,0,1
193,2017-6-6,2017,6,6,16,6fk80j,Implementing Radial Basis Function Classifier in R,https://www.reddit.com/r/MachineLearning/comments/6fk80j/implementing_radial_basis_function_classifier_in_r/,SandipanDeyUMBC,1496732946,,0,1
194,2017-6-6,2017,6,6,16,6fkdx5,What do you know about production of MS polymer adhesive?,https://www.reddit.com/r/MachineLearning/comments/6fkdx5/what_do_you_know_about_production_of_ms_polymer/,mixmachinery,1496735746,,0,1
195,2017-6-6,2017,6,6,18,6fkps7,How the Bayesian inference works,https://www.reddit.com/r/MachineLearning/comments/6fkps7/how_the_bayesian_inference_works/,lemurata,1496741521,,0,1
196,2017-6-6,2017,6,6,19,6fkths,"[D] At the Apple WWDC, Session 608 ""Using Metal 2 for Compute"" looks intriguing, and aimed at new primitives for GPU processing of NN. Hope that someone can attend and report on it",https://www.reddit.com/r/MachineLearning/comments/6fkths/d_at_the_apple_wwdc_session_608_using_metal_2_for/,[deleted],1496743329,[deleted],1,0
197,2017-6-6,2017,6,6,19,6fkxa9,The Future of Investment in AI Could Be Decided By AI Itself,https://www.reddit.com/r/MachineLearning/comments/6fkxa9/the_future_of_investment_in_ai_could_be_decided/,teamrework,1496744938,,0,1
198,2017-6-6,2017,6,6,19,6fl0yo,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6fl0yo/shot_blasting_machine/,Shot-blasting,1496746550,,0,1
199,2017-6-6,2017,6,6,19,6fl13o,[1706.00136] Scalable Generalized Linear Bandits: Online Computation and Hashing,https://www.reddit.com/r/MachineLearning/comments/6fl13o/170600136_scalable_generalized_linear_bandits/,deltakam,1496746607,,1,1
200,2017-6-6,2017,6,6,20,6fl40g,Some Machine Learning with Python,https://www.reddit.com/r/MachineLearning/comments/6fl40g/some_machine_learning_with_python/,SandipanDeyUMBC,1496747780,,0,1
201,2017-6-6,2017,6,6,20,6fl4f2,When do reLUs become worth it?,https://www.reddit.com/r/MachineLearning/comments/6fl4f2/when_do_relus_become_worth_it/,Evixum,1496747940,[removed],0,1
202,2017-6-6,2017,6,6,20,6fl7kv,[D] Single CPU and PCIe Switches vs Two Xeons,https://www.reddit.com/r/MachineLearning/comments/6fl7kv/d_single_cpu_and_pcie_switches_vs_two_xeons/,lungfish1234,1496749162,"I'm considering builidng a deep learning rig with four 1080 Tis.  I'll be using TensorFlow, and plan to distribute the workload as suggested here: https://www.tensorflow.org/tutorials/deep_cnn#training_a_model_using_multiple_gpu_cards .  Suppose I'm training a model with a large number of parameters, and hence will be sending a large amount of data between the CPU and GPUs.  Consider the two scenarios:

1. Using a single CPU with support for 40 PCIe lanes and a motherboard with support for four GPUs each using 16 lanes (using PCIe switches, like the ASUS X99-E WS).
2. Using two Xeons with support for 40 PCIe lanes each.

Would scenario 1. be noticibly slower than scenario 2.?",13,7
203,2017-6-6,2017,6,6,20,6fl8ce,[Discussion] A Research to Engineering Workflow (in Machine Learning),https://www.reddit.com/r/MachineLearning/comments/6fl8ce/discussion_a_research_to_engineering_workflow_in/,[deleted],1496749452,[deleted],0,1
204,2017-6-6,2017,6,6,20,6fl8n6,R.R. Donnelley Streamlines Logistics With Machine Learning - InformationWeek,https://www.reddit.com/r/MachineLearning/comments/6fl8n6/rr_donnelley_streamlines_logistics_with_machine/,mariamgiffin,1496749562,,0,1
205,2017-6-6,2017,6,6,20,6fl8z7,"Every time Apple said 'machine learning', we had a drink andsgd oh*][",https://www.reddit.com/r/MachineLearning/comments/6fl8z7/every_time_apple_said_machine_learning_we_had_a/,jesicafluker,1496749674,,0,1
206,2017-6-6,2017,6,6,20,6fl9cl,[R] Language Generation with Recurrent Generative Adversarial Networks without Pre-training [Tensorflow implementation in comments],https://www.reddit.com/r/MachineLearning/comments/6fl9cl/r_language_generation_with_recurrent_generative/,ofirpress,1496749817,,16,136
207,2017-6-6,2017,6,6,20,6fla81,[D] A Research to Engineering Workflow (in Machine Learning),https://www.reddit.com/r/MachineLearning/comments/6fla81/d_a_research_to_engineering_workflow_in_machine/,pabloesm,1496750144,,17,62
208,2017-6-6,2017,6,6,21,6flb5j,Applications of AI and Machine Learning in niche and emerging areas. Interesting read.,https://www.reddit.com/r/MachineLearning/comments/6flb5j/applications_of_ai_and_machine_learning_in_niche/,parth10,1496750510,,0,1
209,2017-6-6,2017,6,6,21,6fleg4,[R] Enhancement of an scheduling algorithm with ML,https://www.reddit.com/r/MachineLearning/comments/6fleg4/r_enhancement_of_an_scheduling_algorithm_with_ml/,Telvozzzar,1496751629,"Hello Folks,

so I'm pretty new to ML and TensorFlow in General but for my master thesis I'm trying to improve a scheduling algorithm I programmed. I went for tensorflow and installed jupyter for a start and implemented my first models for handwriting recognition. Basic stuff. 

The actual problem is that I have a 15 element input tensor (describing the scheduling scenario) and I want to generate a 4 element output tensor that gives me some parameters for my algorithm. I randomly generated a data set (labled as far as I understand) that contains input and output elements and connects them with a score which should be as low (good) as possible. 

So if I want to generate a model that gives me as good as possible output so that the algorithm can compute a schedule with the score as good as possible, how can I model a NN that in can be trained by this data later gives me good ouput for any scenario.

TL;DR:

I need a NN with 
Input = 15 element Tensor
Ouput = 4 element Tensor

Output will be used for Java scheduling algorithm. Schedule has Score (computed and normalized from missed deadlines, makespan and so on)

Training data has 3 tables (Input, Output, Score) and is generated randomly over the weekend.

I have no idea if this is clear enough, but any help is apreciated!

Thanks in advance and a good day

Telvozzzar",5,2
210,2017-6-6,2017,6,6,21,6flfpu,http://davidsbatista.net/blog/2017/04/01/document_classification/,https://www.reddit.com/r/MachineLearning/comments/6flfpu/httpdavidsbatistanetblog20170401document/,[deleted],1496752068,[removed],0,1
211,2017-6-6,2017,6,6,21,6flht1,"a simple example of multi-label document classification using ""classic"" methods, no neural network involved",https://www.reddit.com/r/MachineLearning/comments/6flht1/a_simple_example_of_multilabel_document/,fulltime_philosopher,1496752724,,0,1
212,2017-6-6,2017,6,6,21,6flkdk,IBM Watson Explainer 16 sec,https://www.reddit.com/r/MachineLearning/comments/6flkdk/ibm_watson_explainer_16_sec/,stephenbhope,1496753564,,1,1
213,2017-6-6,2017,6,6,21,6fllmf,[R] From DeepMind: Ensemble Bayesian Optimization,https://www.reddit.com/r/MachineLearning/comments/6fllmf/r_from_deepmind_ensemble_bayesian_optimization/,[deleted],1496753976,[deleted],4,4
214,2017-6-6,2017,6,6,22,6flmf3,Just made a Matching Networks implementation. Feedback would be awesome,https://www.reddit.com/r/MachineLearning/comments/6flmf3/just_made_a_matching_networks_implementation/,[deleted],1496754222,[deleted],0,1
215,2017-6-6,2017,6,6,22,6flo4r,Family Guy Full Episode - LIVE 24/7 - Family Guy Full Live HD,https://www.reddit.com/r/MachineLearning/comments/6flo4r/family_guy_full_episode_live_247_family_guy_full/,stephenbhope,1496754745,,1,1
216,2017-6-6,2017,6,6,22,6floj0,Just made a matching networks implementation for omniglot. It also supports FCE and achieves similar results to the paper.,https://www.reddit.com/r/MachineLearning/comments/6floj0/just_made_a_matching_networks_implementation_for/,[deleted],1496754863,[deleted],0,1
217,2017-6-6,2017,6,6,22,6flw7n,"[P] Matching Networks for Tensorflow Implementation, feedback is very welcome.",https://www.reddit.com/r/MachineLearning/comments/6flw7n/p_matching_networks_for_tensorflow_implementation/,AntreasAntoniou,1496757195,,3,2
218,2017-6-7,2017,6,7,0,6fmcmp,"Mainstream Machine Learning, from hype to how-to, Google Webinar.",https://www.reddit.com/r/MachineLearning/comments/6fmcmp/mainstream_machine_learning_from_hype_to_howto/,OWOX_BI,1496761623,[removed],0,1
219,2017-6-7,2017,6,7,0,6fmd1z,Image clustering with GMM-EM soft clustering in R,https://www.reddit.com/r/MachineLearning/comments/6fmd1z/image_clustering_with_gmmem_soft_clustering_in_r/,SandipanDeyUMBC,1496761730,,0,1
220,2017-6-7,2017,6,7,0,6fmibj,DeepLearning10: The 8x NVIDIA GTX 1080 Ti GPU Monster (Part 1),https://www.reddit.com/r/MachineLearning/comments/6fmibj/deeplearning10_the_8x_nvidia_gtx_1080_ti_gpu/,-SPOF,1496763115,,0,1
221,2017-6-7,2017,6,7,2,6fn5vg,"I want to apply machine learning with news, twitter and charts to predict the price of bitcoin.",https://www.reddit.com/r/MachineLearning/comments/6fn5vg/i_want_to_apply_machine_learning_with_news/,dnlslm9,1496768882,[removed],0,1
222,2017-6-7,2017,6,7,2,6fn7k4,"Article: In the future, any app built without machine learning technology will be considered a ""dumb application.""",https://www.reddit.com/r/MachineLearning/comments/6fn7k4/article_in_the_future_any_app_built_without/,alexa_y,1496769299,[removed],0,1
223,2017-6-7,2017,6,7,2,6fng0q,"Modeling Face Images with Nonnegative Matrix Factorization (NMF), Kmeans with Vector Quantization (VQ) and Singular Value Decompostion (SVD) in R",https://www.reddit.com/r/MachineLearning/comments/6fng0q/modeling_face_images_with_nonnegative_matrix/,SandipanDeyUMBC,1496771356,,0,1
224,2017-6-7,2017,6,7,2,6fngmw,DeepXplore and new ideas for verifying ML systems,https://www.reddit.com/r/MachineLearning/comments/6fngmw/deepxplore_and_new_ideas_for_verifying_ml_systems/,yoav_hollander,1496771523,,0,2
225,2017-6-7,2017,6,7,3,6fnnli,"[P] Code for ""On the Effects of Batch and Weight Normalization in Generative Adversarial Networks""",https://www.reddit.com/r/MachineLearning/comments/6fnnli/p_code_for_on_the_effects_of_batch_and_weight/,galapag0,1496773197,,7,13
226,2017-6-7,2017,6,7,4,6fny2w,[P] CRF-as-RNN: Lasagne/Theano Implementation (GPU-only),https://www.reddit.com/r/MachineLearning/comments/6fny2w/p_crfasrnn_lasagnetheano_implementation_gpuonly/,hapemask,1496775796,"As a side-project I've been working on a CRF-as-RNN layer for Lasagne, based on [this paper](https://arxiv.org/pdf/1502.03240.pdf). It allows you to add differentiable CRF inference as a layer to any fully-convolutional model that produces classification output whose resolution matches the input. It's particularly useful for semantic segmentation models, but can be used for any dense prediction task.

It's still somewhat of a WIP but it does work. I was able to successfully train a network with the CRF layer as a component.

Code can be found here: https://github.com/hapemask/crfrnn_layer

It includes a differentiable Theano op for high-dimensional Gaussian filtering on the GPU w/a permutohedral lattice as well. Hopefully someone will find it useful, let me know if it doesn't work on your machine. It runs about 2x slower in python2 vs python3 but I don't use python2 so I haven't been motivated to fix that yet.

This is my first attempt at writing a new layer for Lasagne or a new op for Theano, so if you have any experience with those and see something weird, please let me know!",6,8
227,2017-6-7,2017,6,7,4,6fnysr,[D] Follow-up of SGHMC ?,https://www.reddit.com/r/MachineLearning/comments/6fnysr/d_followup_of_sghmc/,xingdongrobotics,1496775972,Are there recent works as follow-ups of Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) ?,3,6
228,2017-6-7,2017,6,7,4,6fo8d0,Summary of Generative Temporal Models with Memory on ShortScience.org,https://www.reddit.com/r/MachineLearning/comments/6fo8d0/summary_of_generative_temporal_models_with_memory/,ieee8023,1496778325,,0,1
229,2017-6-7,2017,6,7,4,6fo8in,Summary of Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models on ShortScience.org,https://www.reddit.com/r/MachineLearning/comments/6fo8in/summary_of_batch_renormalization_towards_reducing/,ieee8023,1496778364,,0,1
230,2017-6-7,2017,6,7,4,6fo8sh,Could you guys please help me with this?,https://www.reddit.com/r/MachineLearning/comments/6fo8sh/could_you_guys_please_help_me_with_this/,HarambeTownley,1496778435,[removed],0,1
231,2017-6-7,2017,6,7,5,6focd0,Discovery of Temporal Neighborhoods through Discretization Methods and Markov Model,https://www.reddit.com/r/MachineLearning/comments/6focd0/discovery_of_temporal_neighborhoods_through/,SandipanDeyUMBC,1496779321,,0,1
232,2017-6-7,2017,6,7,5,6foi3g,Safe Crime Prediction - mitigating the Security vs Privacy tradeoff with Homomorphically Encrypted Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6foi3g/safe_crime_prediction_mitigating_the_security_vs/,iamtrask,1496780691,,0,1
233,2017-6-7,2017,6,7,6,6fp26f,Machine Learning Ideas for FinTech,https://www.reddit.com/r/MachineLearning/comments/6fp26f/machine_learning_ideas_for_fintech/,slavakurilyak,1496785903,,0,0
234,2017-6-7,2017,6,7,6,6fp2ch,Machine learning has become one of  if not the  main applications of artificial intelligence.,https://www.reddit.com/r/MachineLearning/comments/6fp2ch/machine_learning_has_become_one_of_if_not_the/,importiosharon,1496785948,,0,1
235,2017-6-7,2017,6,7,7,6fp95o,[P] tensorflow/cleverhans: a Python library to benchmark machine learning systems' vulnerability to adversarial examples,https://www.reddit.com/r/MachineLearning/comments/6fp95o/p_tensorflowcleverhans_a_python_library_to/,tim_anglade,1496787793,,3,6
236,2017-6-7,2017,6,7,8,6fplyh,Word Association Model,https://www.reddit.com/r/MachineLearning/comments/6fplyh/word_association_model/,thehamslammer,1496791404,[removed],0,1
237,2017-6-7,2017,6,7,9,6fq41p,"[D] Tensor decomposition for 4-, 5- dimensional",https://www.reddit.com/r/MachineLearning/comments/6fq41p/d_tensor_decomposition_for_4_5_dimensional/,oqowa,1496796932,"Hi guys, sorry for my ignorance, but I found only literature on how to decomposition for 3-dimensional tensor, but what about 4-, 5-, N-dimensinal tensors?",8,8
238,2017-6-7,2017,6,7,10,6fq758,Intel to Develop New Machine Learning and AI Platform for DARPA,https://www.reddit.com/r/MachineLearning/comments/6fq758/intel_to_develop_new_machine_learning_and_ai/,DijkstrasAlg,1496797866,,0,1
239,2017-6-7,2017,6,7,10,6fq9ez,List of CVPR17 accepted papers,https://www.reddit.com/r/MachineLearning/comments/6fq9ez/list_of_cvpr17_accepted_papers/,smith2017,1496798563,,0,1
240,2017-6-7,2017,6,7,10,6fqbw8,"In powder mixers industrial, what kinds of powder mixer design is for the detergent powder mixer?",https://www.reddit.com/r/MachineLearning/comments/6fqbw8/in_powder_mixers_industrial_what_kinds_of_powder/,JCT_MACHINE,1496799396,,0,1
241,2017-6-7,2017,6,7,12,6fqsd4,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6fqsd4/shot_blasting_machine/,Shot-blasting,1496804412,,0,1
242,2017-6-7,2017,6,7,12,6fqv8x,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6fqv8x/shot_blasting_machine/,Shot-blasting,1496805316,,0,1
243,2017-6-7,2017,6,7,12,6fqx4g,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6fqx4g/shot_blasting_machine/,Shot-blasting,1496805925,,1,1
244,2017-6-7,2017,6,7,13,6fr8wc,"Not sure if this is the right subreddit, but I am going for an interview tomorrow for becoming a data scientist. What salary should I be looking for?",https://www.reddit.com/r/MachineLearning/comments/6fr8wc/not_sure_if_this_is_the_right_subreddit_but_i_am/,[deleted],1496810132,[removed],0,1
245,2017-6-7,2017,6,7,13,6frail,[R] Counting Objects with Faster R-CNN,https://www.reddit.com/r/MachineLearning/comments/6frail/r_counting_objects_with_faster_rcnn/,adamw1pl,1496810749,,4,15
246,2017-6-7,2017,6,7,13,6frbvc,Getting a neural network to learn x*y,https://www.reddit.com/r/MachineLearning/comments/6frbvc/getting_a_neural_network_to_learn_xy/,jclancy_from_so,1496811291,[removed],0,1
247,2017-6-7,2017,6,7,14,6frfb5,[P] Portraits of Imaginary people. GANs at 4000x4000 pixel resolution.,https://www.reddit.com/r/MachineLearning/comments/6frfb5/p_portraits_of_imaginary_people_gans_at_4000x4000/,wei_jok,1496812654,,59,343
248,2017-6-7,2017,6,7,15,6frn9n,[R] Modeling Relational Data with Graph Convolutional Networks [new results on large-scale relational reasoning],https://www.reddit.com/r/MachineLearning/comments/6frn9n/r_modeling_relational_data_with_graph/,[deleted],1496815915,[deleted],0,1
249,2017-6-7,2017,6,7,15,6fro6v,Image recognition for beginners,https://www.reddit.com/r/MachineLearning/comments/6fro6v/image_recognition_for_beginners/,JitHu1306,1496816338,[removed],0,1
250,2017-6-7,2017,6,7,15,6frt7b,Object Detection in tensorflow,https://www.reddit.com/r/MachineLearning/comments/6frt7b/object_detection_in_tensorflow/,mind_juice,1496818459,[removed],0,1
251,2017-6-7,2017,6,7,16,6frzm2,Siraj Raval on the dangers of AI,https://www.reddit.com/r/MachineLearning/comments/6frzm2/siraj_raval_on_the_dangers_of_ai/,[deleted],1496821340,,0,1
252,2017-6-7,2017,6,7,16,6fs196,Free #DeepLearning webinar with LIME and #Keras (June 12),https://www.reddit.com/r/MachineLearning/comments/6fs196/free_deeplearning_webinar_with_lime_and_keras/,[deleted],1496822160,[deleted],0,1
253,2017-6-7,2017,6,7,18,6fsaiq,Unblackboxing the deep neural network black box- Part 2: Text - a free webinar (June 12),https://www.reddit.com/r/MachineLearning/comments/6fsaiq/unblackboxing_the_deep_neural_network_black_box/,annkov,1496826839,,0,1
254,2017-6-7,2017,6,7,18,6fsb0v,Fast interactive edge-to-photo reconstruction,https://www.reddit.com/r/MachineLearning/comments/6fsb0v/fast_interactive_edgetophoto_reconstruction/,nicolasap,1496827080,,0,1
255,2017-6-7,2017,6,7,19,6fsj4h,How to solve this kind of problem?,https://www.reddit.com/r/MachineLearning/comments/6fsj4h/how_to_solve_this_kind_of_problem/,AbhimanyuGrover,1496830703,[removed],0,1
256,2017-6-7,2017,6,7,20,6fsqww,[D] Why does ResNet have a 77 convolution in the first layer?,https://www.reddit.com/r/MachineLearning/comments/6fsqww/d_why_does_resnet_have_a_77_convolution_in_the/,cbeak,1496833995,And then immediately max pooling. Why not 33 as the rest of it?,5,12
257,2017-6-7,2017,6,7,20,6fsr6b,"[P] Self-Driving Truck in ETS2, trained via Reinforcement Learning",https://www.reddit.com/r/MachineLearning/comments/6fsr6b/p_selfdriving_truck_in_ets2_trained_via/,wychtl,1496834098,,8,45
258,2017-6-7,2017,6,7,20,6fswmw,[R] One-Sided Unsupervised Domain Mapping,https://www.reddit.com/r/MachineLearning/comments/6fswmw/r_onesided_unsupervised_domain_mapping/,sagiebenaim,1496836145,,3,22
259,2017-6-7,2017,6,7,22,6ftdw1,What do you use to make network architecture diagrams?,https://www.reddit.com/r/MachineLearning/comments/6ftdw1/what_do_you_use_to_make_network_architecture/,charred_bytes,1496841793,[removed],0,1
260,2017-6-7,2017,6,7,22,6fth8i,Hanger type shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6fth8i/hanger_type_shot_blasting_machine/,Shot-blasting,1496842825,,0,1
261,2017-6-7,2017,6,7,22,6fthwv,[D] What does the new iMac Pro mean for deep learning? (x-post /r/Apple),https://www.reddit.com/r/MachineLearning/comments/6fthwv/d_what_does_the_new_imac_pro_mean_for_deep/,laiktail,1496843044,"One of the shortcomings in previous Mac offerings is that its GPU has been lacking, meaning less power for computationally intensive AI stuff. Given the recent AMD Radeon Pro Vega announcement for iMac Pros, was wondering what the implications were for machine/deep learning when you compare them to e.g. GTX1080 or GTX1080Ti GPUs with PCs? Not knowing much about GPUs at all, how would you compare the Pro Vega with what's currently out there?
",5,0
262,2017-6-7,2017,6,7,22,6ftjhp,Markov Model for recurring banking transactions.,https://www.reddit.com/r/MachineLearning/comments/6ftjhp/markov_model_for_recurring_banking_transactions/,DylonDylonDylon,1496843502,[removed],0,1
263,2017-6-7,2017,6,7,23,6ftuad,Predicting how much time people have left to live using feature engineering and deep learning methods,https://www.reddit.com/r/MachineLearning/comments/6ftuad/predicting_how_much_time_people_have_left_to_live/,Matthieu_B,1496846461,,0,1
264,2017-6-7,2017,6,7,23,6ftx1n,[P]Glass | A set of vision-based computing capabilities | Real-time object recognition,https://www.reddit.com/r/MachineLearning/comments/6ftx1n/pglass_a_set_of_visionbased_computing/,aniruddh1998,1496847207,"Introducing Glass
Glass is a set of vision-based computing capabilities that allows your smartphone to understand what is in a photo. For instance, point your phone at an object and Glass will tell you what it is!

This advanced Augmented Reality tool can recognise whatever youre looking at and offer any essential information you require.
Impressive object recognition and real-time information

Glass goes a clear step by recognising a much greater range of objects, including natural stuff. Extra information such as breeds of dogs, flower species, etc would be implemented as the application grows.

Currently, Glass is available as a public BETA and can be downloaded from play store directly (https://play.google.com/store/apps/details?id=com.achandratre.glass).

Screenshots : http://imgur.com/a/h1AvL

Please note that the results may not be 100% accurate as the application is in its initial stages of development.

I'd appreciate if you share the word and provide a feedback on the Play Store Listing. 

Any issues can be directly reported on the github repository : http://github.com/C-Aniruddh/glass.",3,0
265,2017-6-7,2017,6,7,23,6ftxgx,[D] What's the coolest term in deep learning that you know?,https://www.reddit.com/r/MachineLearning/comments/6ftxgx/d_whats_the_coolest_term_in_deep_learning_that/,[deleted],1496847332,[removed],0,1
266,2017-6-8,2017,6,8,0,6fu4vo,[German] Machine Learning Meetups in Deutschland,https://www.reddit.com/r/MachineLearning/comments/6fu4vo/german_machine_learning_meetups_in_deutschland/,flezzfx,1496849205,,0,1
267,2017-6-8,2017,6,8,0,6fu7ht,[D] I'm A Law Prof with a Theory relevant to ML/Data Science about replacing Jurors in some cases with Algorithms. Thoughts? Read on (xpost r/datascience),https://www.reddit.com/r/MachineLearning/comments/6fu7ht/d_im_a_law_prof_with_a_theory_relevant_to_mldata/,[deleted],1496849896,[deleted],7,1
268,2017-6-8,2017,6,8,0,6fu8vx,[D] Uncertainty and deep learning,https://www.reddit.com/r/MachineLearning/comments/6fu8vx/d_uncertainty_and_deep_learning/,harmonium1,1496850268,"There has been some interesting recent work in Bayesian deep learning--building principled probabilistic models using deep networks (some interesting papers at the [NIPS workshop](http://bayesiandeeplearning.org/). 

Still, a lot of this works seems to be in parallel (rather than alongside) work trying to improve state-of-the-art results on a variety of tasks--outside of problems in NLP like topic modeling, the majority of modern deep learning methods do not start from probabilistic models and generally do not consider any notion of uncertainty.

Is there work that tries to do both--doing principled Bayesian deep learning on non-toy datasets to achieve SOTA results? ",5,12
269,2017-6-8,2017,6,8,0,6fub54,CRF++/Wapiti include category of entire sentence as feature for NER,https://www.reddit.com/r/MachineLearning/comments/6fub54/crfwapiti_include_category_of_entire_sentence_as/,iamjkdn,1496850860,[removed],0,1
270,2017-6-8,2017,6,8,0,6fubge,"Simple Questions Thread June 07, 2017",https://www.reddit.com/r/MachineLearning/comments/6fubge/simple_questions_thread_june_07_2017/,AutoModerator,1496850929,[removed],0,1
271,2017-6-8,2017,6,8,0,6fubug,[D] Fully-convolutional DAE for feature extraction.,https://www.reddit.com/r/MachineLearning/comments/6fubug/d_fullyconvolutional_dae_for_feature_extraction/,hyperqube12,1496851035,"I am working on a fully convolutional denoising autoencoder (DAE) for feature extraction. Basically the structure is 3 layers of convolution 2D and 3 layers of convolution_transpose 2D. One thing I am noticing is that there seems to be a limit to how accurate the DAE can reproduce it's input. This did not happen when I was using a DAE with just dense layers. 

Is this a result of the fact that convolution_transpose is not the inverse of the convolution operation ? 

Do you know any paper, research project, have any idea on how I can improve this DAE? ",8,1
272,2017-6-8,2017,6,8,1,6fulz6,[R] Learning Musical Style and Generating Musical Performances using LSTMs,https://www.reddit.com/r/MachineLearning/comments/6fulz6/r_learning_musical_style_and_generating_musical/,imalikshake,1496853620,,20,33
273,2017-6-8,2017,6,8,2,6fv0sg,Machine Learning PC Build questions,https://www.reddit.com/r/MachineLearning/comments/6fv0sg/machine_learning_pc_build_questions/,popsumbong,1496857275,[removed],0,1
274,2017-6-8,2017,6,8,2,6fv2tx,[P] Finding bad flamingo drawings with recurrent neural networks,https://www.reddit.com/r/MachineLearning/comments/6fv2tx/p_finding_bad_flamingo_drawings_with_recurrent/,halfeatenscone,1496857775,,4,26
275,2017-6-8,2017,6,8,3,6fvcfd,[D] Started out with Tensorflow and now PyTorch catching up. Should move efforts to switch to PyTorch?,https://www.reddit.com/r/MachineLearning/comments/6fvcfd/d_started_out_with_tensorflow_and_now_pytorch/,thebluebloo,1496860148,"A little background: I am still a bit new to both python and machine learning. I have spent about last 4-5 months learning about deep learning and python. I choose Tensorflow as my starting deep learning framework. Fast forward, I am trying to do a research project in college now and need to access pretty low level stuff in network like gradients etc.
Over discussions in internet, I have read multiple times that PyTorch is more suited for research work.

Having spent quite a lot of effort into learning Tensorflow (fast.ai course, Udacity course still going on and other miscellaneous sources) should I switch over to PyTorch and learn it instead?",10,9
276,2017-6-8,2017,6,8,4,6fvn7u,[D] Best way of testing statistical significant difference on benchmark datasets,https://www.reddit.com/r/MachineLearning/comments/6fvn7u/d_best_way_of_testing_statistical_significant/,Pieranha,1496862831,"Some benchmark datasets are quite small (particularly within NLP), making it important to test whether the difference between the new approach's results and the existing approach's results is statistically significant. There seems to be a lot of different ways to test the statistical significance and report the performance of the models, each one getting at a different aspect of uncertainty. Interestingly, this also seems to differ between communities. What method do you prefer to see papers use and why?

I think it's safe to assume that the benchmark datasets have already been split into a training set and test set as is often the case.",0,6
277,2017-6-8,2017,6,8,4,6fvvd7,[R] Retrosynthetic reaction prediction using neural sequence-to-sequence models,https://www.reddit.com/r/MachineLearning/comments/6fvvd7/r_retrosynthetic_reaction_prediction_using_neural/,jivatman,1496864894,,0,9
278,2017-6-8,2017,6,8,4,6fvxiy,A correspondence between thermodynamics and inference,https://www.reddit.com/r/MachineLearning/comments/6fvxiy/a_correspondence_between_thermodynamics_and/,[deleted],1496865452,[deleted],0,1
279,2017-6-8,2017,6,8,5,6fvz70,[R] Reproducibility in ML Workshop Open for Submissions,https://www.reddit.com/r/MachineLearning/comments/6fvz70/r_reproducibility_in_ml_workshop_open_for/,alexmlamb,1496865863,,2,11
280,2017-6-8,2017,6,8,5,6fw00r,[R] A correspondence between thermodynamics and inference,https://www.reddit.com/r/MachineLearning/comments/6fw00r/r_a_correspondence_between_thermodynamics_and/,cxhrndz,1496866082,,9,21
281,2017-6-8,2017,6,8,5,6fw7f5,CNN produces probabilities close to 0.5,https://www.reddit.com/r/MachineLearning/comments/6fw7f5/cnn_produces_probabilities_close_to_05/,youhealthy,1496867985,[removed],0,1
282,2017-6-8,2017,6,8,6,6fwkr9,Funny AI - The Wisdom in Japanese Back-Translation,https://www.reddit.com/r/MachineLearning/comments/6fwkr9/funny_ai_the_wisdom_in_japanese_backtranslation/,marcotrombetti,1496871493,,0,1
283,2017-6-8,2017,6,8,7,6fwym6,[R] TensorFlow: Analyze images of Scatter Plots to identify good vs bad plots?,https://www.reddit.com/r/MachineLearning/comments/6fwym6/r_tensorflow_analyze_images_of_scatter_plots_to/,ap2lazarus,1496875295,"Don't shoot, I'm new around here.

So I have a few thousands Scatter Plots in JPG format, and I'd like to identify which scatter plot images are what I would call ""good"" vs ""bad"".  I'm thinking if I could train the machine by manually identifying 50+ good graphs and 50+ bad graphs, would it then be able to go through the rest for me?

(Good would just mean I like the distribution of points on the plot that track a static target line, and bad would be a plot with a greater number of points directly on or near the X axis and very few along the static target line)

Is this something a relative n00b like myself, but with programming knowledge, should be able to easily accomplish?

Is TensorFlow the proper path I should take?

Is there an easier way?

Thanks! :)",3,0
284,2017-6-8,2017,6,8,8,6fxbcr,"Interactive tutorial: generative adversarial networks for beginners, with TensorFlow [P]",https://www.reddit.com/r/MachineLearning/comments/6fxbcr/interactive_tutorial_generative_adversarial/,jonbruner,1496879090,,33,225
285,2017-6-8,2017,6,8,10,6fxxlg,Brute-forcing neural net's hyperparameter space with hyperopt,https://www.reddit.com/r/MachineLearning/comments/6fxxlg/bruteforcing_neural_nets_hyperparameter_space/,GChe,1496886119,,0,1
286,2017-6-8,2017,6,8,11,6fy5jt,Any good papers on recognition of humans by their overall body and not just their faces?,https://www.reddit.com/r/MachineLearning/comments/6fy5jt/any_good_papers_on_recognition_of_humans_by_their/,Greendogo,1496888776,[removed],0,1
287,2017-6-8,2017,6,8,11,6fy8an,Understanding Machine Learning with Python (Pluralsight course free for 1 week),https://www.reddit.com/r/MachineLearning/comments/6fy8an/understanding_machine_learning_with_python/,[deleted],1496889701,[deleted],1,1
288,2017-6-8,2017,6,8,13,6fypoq,Pytorch implementation of wide-residual networks &amp; other CNNs,https://www.reddit.com/r/MachineLearning/comments/6fypoq/pytorch_implementation_of_wideresidual_networks/,meliketoy,1496895702,,0,1
289,2017-6-8,2017,6,8,13,6fysa3,Machine learning and political science,https://www.reddit.com/r/MachineLearning/comments/6fysa3/machine_learning_and_political_science/,tcush89,1496896651,[removed],0,1
290,2017-6-8,2017,6,8,13,6fyv6a,"Google quietly debuts Chatbase, a chatbot analytics platform",https://www.reddit.com/r/MachineLearning/comments/6fyv6a/google_quietly_debuts_chatbase_a_chatbot/,hardikmakadia,1496897790,,0,1
291,2017-6-8,2017,6,8,16,6fzeae,Flying in Simulator with Deep Q-Networks,https://www.reddit.com/r/MachineLearning/comments/6fzeae/flying_in_simulator_with_deep_qnetworks/,mad_rat_man,1496905589,,0,1
292,2017-6-8,2017,6,8,16,6fzfwf,[P] Flying in a Simulator with Deep Q-Networks,https://www.reddit.com/r/MachineLearning/comments/6fzfwf/p_flying_in_a_simulator_with_deep_qnetworks/,mad_rat_man,1496906290,,0,16
293,2017-6-8,2017,6,8,17,6fznbm,"[P] Conditional density estimation using Kernel Mixture Networks, theory + implementation in TF",https://www.reddit.com/r/MachineLearning/comments/6fznbm/p_conditional_density_estimation_using_kernel/,dzyl,1496909765,,8,29
294,2017-6-8,2017,6,8,17,6fznlc,Nobody tries to make a bot for Toribash 3d-fighting,https://www.reddit.com/r/MachineLearning/comments/6fznlc/nobody_tries_to_make_a_bot_for_toribash_3dfighting/,[deleted],1496909902,[removed],0,1
295,2017-6-8,2017,6,8,18,6fzw2p,"Where to start from, in order to built ML bot for Toribash 3D fighting.",https://www.reddit.com/r/MachineLearning/comments/6fzw2p/where_to_start_from_in_order_to_built_ml_bot_for/,[deleted],1496913879,[removed],0,1
296,2017-6-8,2017,6,8,18,6fzyrd,[D] How important are powers of two for GPU training?,https://www.reddit.com/r/MachineLearning/comments/6fzyrd/d_how_important_are_powers_of_two_for_gpu_training/,cbeak,1496915116,"If it is much more convenient to have input images of shape 2512513 rather than 2562563, should I go for it? Will the training be slowed down noticeably, or will it only be only be 1-2%?",2,6
297,2017-6-8,2017,6,8,19,6g03g8,[D] How to mine a proper dataset for Toribash AI bot?,https://www.reddit.com/r/MachineLearning/comments/6g03g8/d_how_to_mine_a_proper_dataset_for_toribash_ai_bot/,Mee5aeree4,1496917217,"An example video with the game interface:
https://www.youtube.com/watch?v=EPq7xIib_Cg

Toribash is a simulator of 3D fighting, freely available in Steam.

The game has an API in lua. You may perform any user input through it, as well as obtaining game environment configuration, and getting info about your tori location. Even more, it has a built-in metrics that shows a damage equivalence of your performance.

But I don't understand how to prepare a dataset for a neural net learning. Also, what kind of model to choose?
Evidently it wants some form of reinforcement learning.

Where to start from?",5,2
298,2017-6-8,2017,6,8,19,6g0639,2 arrays 11x11 - how to classify with a CNN?!?,https://www.reddit.com/r/MachineLearning/comments/6g0639/2_arrays_11x11_how_to_classify_with_a_cnn/,[deleted],1496918429,[removed],0,1
299,2017-6-8,2017,6,8,19,6g0794,[R]'Hashing' can eliminate more than 95 percent of computations,https://www.reddit.com/r/MachineLearning/comments/6g0794/rhashing_can_eliminate_more_than_95_percent_of/,finallyifoundvalidUN,1496918943,,30,42
300,2017-6-8,2017,6,8,20,6g0cc4,Training with INT8,https://www.reddit.com/r/MachineLearning/comments/6g0cc4/training_with_int8/,dharma-1,1496921044,[removed],0,1
301,2017-6-8,2017,6,8,20,6g0gjf,Distributed Tensorflow,https://www.reddit.com/r/MachineLearning/comments/6g0gjf/distributed_tensorflow/,[deleted],1496922717,[deleted],0,1
302,2017-6-8,2017,6,8,21,6g0iht,Image classification on text?,https://www.reddit.com/r/MachineLearning/comments/6g0iht/image_classification_on_text/,[deleted],1496923415,[removed],0,1
303,2017-6-8,2017,6,8,21,6g0mx5,Distributed Tensorflow,https://www.reddit.com/r/MachineLearning/comments/6g0mx5/distributed_tensorflow/,mhmichalski,1496924903,,0,1
304,2017-6-8,2017,6,8,21,6g0s2g,[D] Differential geometry in reinforcement learning ?,https://www.reddit.com/r/MachineLearning/comments/6g0s2g/d_differential_geometry_in_reinforcement_learning/,fixedrl,1496926679,Very curious to know if there are some works in reinforcement learning by applying differential geometry ?,5,19
305,2017-6-8,2017,6,8,22,6g0uhs,4K Style Transfer with Drone Footage,https://www.reddit.com/r/MachineLearning/comments/6g0uhs/4k_style_transfer_with_drone_footage/,[deleted],1496927438,[deleted],0,1
306,2017-6-8,2017,6,8,22,6g0v5h,Combining heuristics when ranking social network news feed items,https://www.reddit.com/r/MachineLearning/comments/6g0v5h/combining_heuristics_when_ranking_social_network/,[deleted],1496927655,[removed],0,1
307,2017-6-8,2017,6,8,22,6g0vbs,"[P] PyTorch implementation of ""Relational Networks"" even before DeepMind",https://www.reddit.com/r/MachineLearning/comments/6g0vbs/p_pytorch_implementation_of_relational_networks/,hiconcep,1496927709,,17,53
308,2017-6-8,2017,6,8,23,6g15kl,[D] A Gentle Intro to Distributed Tensorflow,https://www.reddit.com/r/MachineLearning/comments/6g15kl/d_a_gentle_intro_to_distributed_tensorflow/,ntenenz,1496930824,,2,1
309,2017-6-8,2017,6,8,23,6g15si,"[D] ELU vs. ReLU, any new benchmarks?",https://www.reddit.com/r/MachineLearning/comments/6g15si/d_elu_vs_relu_any_new_benchmarks/,carlthome,1496930881,"I heard from a friend at Spotify that experimented with a CNN-based recommender system that they got terrible performance with ELU in terms of both compute time and convergence, and that the network learned faster and easier by sticking with ReLU+batchnorm. 

ELU has been my non-linearity of choice for convolutional layers, but now I'm wondering if there are cases where ReLU is the better choice. When could that be the case? I suppose the extra parameters from batchnorm skews comparisons a bit (I believe he used both scaling and translation on top of biases) but how much more efficient are ReLUs in libraries such as TensorFlow, and is convergence different in your experience?",19,11
310,2017-6-8,2017,6,8,23,6g1808,urrent state of anomaly detection algorithms for time series,https://www.reddit.com/r/MachineLearning/comments/6g1808/urrent_state_of_anomaly_detection_algorithms_for/,[deleted],1496931488,[deleted],0,1
311,2017-6-8,2017,6,8,23,6g19il,A Vision for Making Deep Learning Simple - The Databricks Blog,https://www.reddit.com/r/MachineLearning/comments/6g19il/a_vision_for_making_deep_learning_simple_the/,[deleted],1496931922,[deleted],0,1
312,2017-6-8,2017,6,8,23,6g19vk,The Future of Manufacturing with Data Analytics and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6g19vk/the_future_of_manufacturing_with_data_analytics/,doverefrain,1496932024,,0,1
313,2017-6-8,2017,6,8,23,6g1a5o,Intel and DARPA look to AI and machine learning to boost graph analytics in big data - TechRepublic,https://www.reddit.com/r/MachineLearning/comments/6g1a5o/intel_and_darpa_look_to_ai_and_machine_learning/,lowellelbert,1496932107,,0,1
314,2017-6-8,2017,6,8,23,6g1aer,How Machine Learning is Taking Over Online Advertising,https://www.reddit.com/r/MachineLearning/comments/6g1aer/how_machine_learning_is_taking_over_online/,kingsleyelbert,1496932190,,0,1
315,2017-6-8,2017,6,8,23,6g1aq6,How AI And Machine Learning Are Helping Drive The GE Digital Transformation,https://www.reddit.com/r/MachineLearning/comments/6g1aq6/how_ai_and_machine_learning_are_helping_drive_the/,menendezefren,1496932286,,0,1
316,2017-6-8,2017,6,8,23,6g1avh,Automated Machine Learning competition announced: Can AutoML beat humans on Kaggle?,https://www.reddit.com/r/MachineLearning/comments/6g1avh/automated_machine_learning_competition_announced/,[deleted],1496932325,[deleted],0,1
317,2017-6-8,2017,6,8,23,6g1g21,[Project] A Vision for Making Deep Learning Simple - The Databricks Blog,https://www.reddit.com/r/MachineLearning/comments/6g1g21/project_a_vision_for_making_deep_learning_simple/,infstudent,1496933810,,1,15
318,2017-6-8,2017,6,8,23,6g1gkq,urrent state of anomaly detection algorithms for time series,https://www.reddit.com/r/MachineLearning/comments/6g1gkq/urrent_state_of_anomaly_detection_algorithms_for/,[deleted],1496933962,[deleted],0,1
319,2017-6-9,2017,6,9,0,6g1hrg,[R] urrent state of anomaly detection algorithms for time series,https://www.reddit.com/r/MachineLearning/comments/6g1hrg/r_urrent_state_of_anomaly_detection_algorithms/,luba_belokon,1496934263,,15,103
320,2017-6-9,2017,6,9,0,6g1hup,What are the best practices for Data Collection and Preparation: Curating labelled sensor data for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6g1hup/what_are_the_best_practices_for_data_collection/,Dizastr,1496934286,[removed],0,1
321,2017-6-9,2017,6,9,0,6g1mop,ML and Finance,https://www.reddit.com/r/MachineLearning/comments/6g1mop/ml_and_finance/,ub3rmen5h,1496935574,[removed],0,1
322,2017-6-9,2017,6,9,0,6g1osl,MMLSpark - Microsoft ML Library for Apache Spark,https://www.reddit.com/r/MachineLearning/comments/6g1osl/mmlspark_microsoft_ml_library_for_apache_spark/,[deleted],1496936178,[deleted],0,1
323,2017-6-9,2017,6,9,0,6g1qa4,how do i begin progrmamming machine learning,https://www.reddit.com/r/MachineLearning/comments/6g1qa4/how_do_i_begin_progrmamming_machine_learning/,dnlslm9,1496936554,[removed],0,1
324,2017-6-9,2017,6,9,1,6g1utx,Can someone help with a simple error.,https://www.reddit.com/r/MachineLearning/comments/6g1utx/can_someone_help_with_a_simple_error/,dnlslm9,1496937769,,1,1
325,2017-6-9,2017,6,9,2,6g2h1m,"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour",https://www.reddit.com/r/MachineLearning/comments/6g2h1m/accurate_large_minibatch_sgd_training_imagenet_in/,jiayq84,1496943517,,19,49
326,2017-6-9,2017,6,9,3,6g2t4z,"Question about scaling t-SNE (Python/Sklearn) to a dense matrix of ~150,000 X 4000",https://www.reddit.com/r/MachineLearning/comments/6g2t4z/question_about_scaling_tsne_pythonsklearn_to_a/,datavis,1496946479,[removed],0,1
327,2017-6-9,2017,6,9,3,6g2yhz,[D] Combining heuristics when ranking news feed items?,https://www.reddit.com/r/MachineLearning/comments/6g2yhz/d_combining_heuristics_when_ranking_news_feed/,sup6978,1496947840,"We have a news feed, and we want to surface items to the user based on a number of criteria. Certain items will be surfaced because of factor A, another because of factor B, and yet another because of factor C. We can create individual heuristics for each factor, but we then need to combine these heuristics in such a way that it promotes the best content considering each factor while still giving a mix of content from each factor.

Our naive approach is to load the top n from each factor, take the first of each, and make those the first 3 of the feed. Then take the 2nd from each feed and make that the second 3, and so on and so forth. Ideally, we would have some algorithm for more intelligently ranking these feed items - our first thought was to simply sum the three heuristics and pull the top items using the resulting combined score, but there are no guarantees that the heuristics are evenly-scaled (or are evenly-scaled for that particular user), which could result in one factor dominating over the others in the feed. Is there some more intelligent way of ranking these news feed items (akin to what Facebook does in its pseudo-chronological news feed)?

",1,1
328,2017-6-9,2017,6,9,3,6g2yj0,[D] Current status of latent variable generative models for text,https://www.reddit.com/r/MachineLearning/comments/6g2yj0/d_current_status_of_latent_variable_generative/,asobolev,1496947848,"Hello

I'm wondering that's the current status of generative modeling of textual data? I'm not interested in generative models for the sake of nice samples, but I'm looking for good latent representations that can be used in other tasks and/or in reconstruction as a way to condition on a sample to obtain similar ones.
",2,3
329,2017-6-9,2017,6,9,3,6g2yn0,"[R] Learning to Cooperate, Compete, and Communicate",https://www.reddit.com/r/MachineLearning/comments/6g2yn0/r_learning_to_cooperate_compete_and_communicate/,clbam8,1496947875,,11,40
330,2017-6-9,2017,6,9,3,6g2zgt,[R] Training ImageNet in 1 Hour on 256 GPUs with minibatches of 8192,https://www.reddit.com/r/MachineLearning/comments/6g2zgt/r_training_imagenet_in_1_hour_on_256_gpus_with/,clbam8,1496948084,,1,0
331,2017-6-9,2017,6,9,4,6g3757,[D] The Rise of the Machines (Kurzgesagt),https://www.reddit.com/r/MachineLearning/comments/6g3757/d_the_rise_of_the_machines_kurzgesagt/,elanmart,1496949977,,6,18
332,2017-6-9,2017,6,9,4,6g38bv,[P] Extracting input-to-output gradients from a Keras model,https://www.reddit.com/r/MachineLearning/comments/6g38bv/p_extracting_inputtooutput_gradients_from_a_keras/,thearn4,1496950268,"Hi, so I am coming from a background in linear algebra and traditional numerical gradient-based optimization, but excited by the advancements that have been made in deep learning. Especially with the tooling now available.

To get my feet wet a bit, I made a pretty simple NN model to do some non-linear regressions for me. I uploaded my jupyter notebookit as a gist [here](https://gist.github.com/thearn/be9f98c5c2a6f87068490808f374a07c) (renders properly on github), which is pretty short and to the point.

It just fits the 1D function y = (x - 5)^2 / 25. 

I know that Theano and Tensorflow are, at their core, graph based derivative (gradient) passing frameworks. And utilizing the gradients of loss functions with respect to weights for gradient step-based optimization are the main purpose of that. 

But what I'm trying to get sense of is if I have access to something that, given a trained model, can approximate derivatives of inputs with respect to the output layer for me (not the weights or loss function). So for this case, I would want y' = 2(x-5)/25.0 estimated via the network's derivative graph for me for an indicated value of the input x, in the network's currently trained state.

Do I have any options in either the Keras or Theano/TF backend APIs to do this, or do I need to do my own chain ruling somehow with the weights (or maybe adding my own non-trainable ""identity"" layers or something)? In my notebook, you can see me trying a few approaches based what I was able to find so far, but without a ton of success.",6,4
333,2017-6-9,2017,6,9,4,6g3dcy,Comparing Spectral partitioning / clustering (with Normalized Graph Laplacian) with KMeans Clustering in R,https://www.reddit.com/r/MachineLearning/comments/6g3dcy/comparing_spectral_partitioning_clustering_with/,SandipanDeyUMBC,1496951568,,0,1
334,2017-6-9,2017,6,9,5,6g3gzb,[D] Models and edge computing,https://www.reddit.com/r/MachineLearning/comments/6g3gzb/d_models_and_edge_computing/,wherehaus,1496952499,"Hi r/machinelearning! I posted this over at r/datascience as well, so apologies if its against the rules to post here also.

Given that Apple and Google have both provided libraries for evaluating models on devices themselves (i.e. TensorFlow Lite and coreML), I was wondering how frequently people find themselves pushing the prediction phase of data science out to the edge devices and when that happens, how do you deal with updating and monitoring these models without constant access to the devices themselves?",1,1
335,2017-6-9,2017,6,9,6,6g3yqm,DenseNet Segmentation (100-layer Tiramisu) vs Improved FCN. Any major differences?,https://www.reddit.com/r/MachineLearning/comments/6g3yqm/densenet_segmentation_100layer_tiramisu_vs/,TheOverGrad,1496957038,[removed],0,1
336,2017-6-9,2017,6,9,6,6g424l,Snomed Codes?,https://www.reddit.com/r/MachineLearning/comments/6g424l/snomed_codes/,dragonslikepi,1496957942,[removed],1,1
337,2017-6-9,2017,6,9,7,6g48hp,Identifying duplicate questions on Quora | Top 12% on Kaggle,https://www.reddit.com/r/MachineLearning/comments/6g48hp/identifying_duplicate_questions_on_quora_top_12/,shubh24,1496959648,,0,1
338,2017-6-9,2017,6,9,7,6g4esy,Tracking Physical Asset Movement with LSTMs,https://www.reddit.com/r/MachineLearning/comments/6g4esy/tracking_physical_asset_movement_with_lstms/,arshakn,1496961470,,0,1
339,2017-6-9,2017,6,9,10,6g5gb6,[D] An Adversarial Review of Adversarial Generation of Natural Language,https://www.reddit.com/r/MachineLearning/comments/6g5gb6/d_an_adversarial_review_of_adversarial_generation/,Mandrathax,1496973119,,69,253
340,2017-6-9,2017,6,9,12,6g5sqx,[R] Self-Normalizing Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6g5sqx/r_selfnormalizing_neural_networks/,[deleted],1496977253,[deleted],0,1
341,2017-6-9,2017,6,9,12,6g5tg1,[R] Self-Normalizing Neural Networks -&gt; improved ELU variant,https://www.reddit.com/r/MachineLearning/comments/6g5tg1/r_selfnormalizing_neural_networks_improved_elu/,xternalz,1496977471,,191,155
342,2017-6-9,2017,6,9,12,6g5yjh,"""[Discussion]"" How good is H2O?",https://www.reddit.com/r/MachineLearning/comments/6g5yjh/discussion_how_good_is_h2o/,Abhishtoo,1496979219,I read this article [Improving Zillows Zestimate with 36 Lines of Code](https://blog.dominodatalab.com/zillow-kaggle/) telling about how powerful and simple H2O is. I want to put this in context. How is it different from something like Scikit-learn? In what ways is it better? Thanks for your responses.,9,11
343,2017-6-9,2017,6,9,14,6g6f0r,Easily visualize embedding on tensorboard with thumbnail images and labels.,https://www.reddit.com/r/MachineLearning/comments/6g6f0r/easily_visualize_embedding_on_tensorboard_with/,sssseo,1496985260,,0,1
344,2017-6-9,2017,6,9,14,6g6hi8,Easily visualize cnn layer activations and filters on tensorboard.,https://www.reddit.com/r/MachineLearning/comments/6g6hi8/easily_visualize_cnn_layer_activations_and/,sssseo,1496986226,,0,1
345,2017-6-9,2017,6,9,15,6g6m7y,[D] Gene Kogan - Picasso's terminal; data science and AI in the visual arts,https://www.reddit.com/r/MachineLearning/comments/6g6m7y/d_gene_kogan_picassos_terminal_data_science_and/,_alphamaximus_,1496988139,,0,3
346,2017-6-9,2017,6,9,16,6g6yiu,mini oil expeller | mini oil extractor | oil press | oil mill | Om engin...,https://www.reddit.com/r/MachineLearning/comments/6g6yiu/mini_oil_expeller_mini_oil_extractor_oil_press/,omengineeringworks,1496993519,,0,1
347,2017-6-9,2017,6,9,18,6g7e2j,Scaling up the Automatic Statistician,https://www.reddit.com/r/MachineLearning/comments/6g7e2j/scaling_up_the_automatic_statistician/,[deleted],1497001056,[deleted],1,1
348,2017-6-9,2017,6,9,18,6g7gyd,[R] Scaling up the Automatic Statistician,https://www.reddit.com/r/MachineLearning/comments/6g7gyd/r_scaling_up_the_automatic_statistician/,scalablebayes,1497002310,"arXiv: https://arxiv.org/abs/1706.02524

Abstract: Automating statistical modelling is a challenging problem that has far-reaching implications for artificial intelligence. The Automatic Statistician employs a kernel search algorithm to provide a first step in this direction for regression problems. However this does not scale due to its O(N^3) running time for the model selection. This is undesirable not only because the average size of data sets is growing fast, but also because there is potentially more information in bigger data, implying a greater need for more expressive models that can discover finer structure. We propose Scalable Kernel Composition (SKC), a scalable kernel search algorithm, to encompass big data within the boundaries of automated statistical modelling.",2,14
349,2017-6-9,2017,6,9,20,6g7r1z,[N]Apple Announces Core ML: Machine Learning Capabilities on Apple Devices,https://www.reddit.com/r/MachineLearning/comments/6g7r1z/napple_announces_core_ml_machine_learning/,[deleted],1497006677,[deleted],0,0
350,2017-6-9,2017,6,9,20,6g7ugy,[N] Tensorflow Lite on Android phones,https://www.reddit.com/r/MachineLearning/comments/6g7ugy/n_tensorflow_lite_on_android_phones/,[deleted],1497008039,[deleted],0,0
351,2017-6-9,2017,6,9,20,6g7x95,Looking for list of relevant DL papers 16-17,https://www.reddit.com/r/MachineLearning/comments/6g7x95/looking_for_list_of_relevant_dl_papers_1617/,krallistic,1497009100,[removed],0,1
352,2017-6-9,2017,6,9,21,6g82uc,[D] Does nobody here do research on topics outside of Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/6g82uc/d_does_nobody_here_do_research_on_topics_outside/,Aqwis,1497011076,"I wrote my Master's thesis on graphical models, and I know that a bunch of papers are published within that field every year. I would think that at least as much research is done on tree-based methods, Gaussian processes, kernel methods, ensembling, clustering methods and other non-NN ML techniques.

Yet essentially zero research relating to anything other than Neural Networks is posted or discussed in /r/machinelearning. This wasn't the case a few years ago -- it seems to have happened gradually over the past two years or so. Why is this? I haven't seen anything that suggests neural networks are superior to other methods when applied to structured data (as opposed to unstructured data like images, sound and text).",100,176
353,2017-6-9,2017,6,9,21,6g88f1,How the advent of chatbots helps businesses grow big on revenues and achieve 100% customer satisfaction,https://www.reddit.com/r/MachineLearning/comments/6g88f1/how_the_advent_of_chatbots_helps_businesses_grow/,hardikmakadia,1497013034,,0,1
354,2017-6-9,2017,6,9,22,6g8jnw,Understand the concepts and mathematics behind Convolutinal Neural Networks and implement your own CNN in Python and Numpy,https://www.reddit.com/r/MachineLearning/comments/6g8jnw/understand_the_concepts_and_mathematics_behind/,flameroar,1497016504,,1,1
355,2017-6-9,2017,6,9,23,6g8q54,"[P] Unblackboxing the deep neural network black box - Part 2: Text (a free webinar, Jun 12)",https://www.reddit.com/r/MachineLearning/comments/6g8q54/p_unblackboxing_the_deep_neural_network_black_box/,pmigdal,1497018350,,0,0
356,2017-6-9,2017,6,9,23,6g8uxu,What OS is best for machine learning and why?,https://www.reddit.com/r/MachineLearning/comments/6g8uxu/what_os_is_best_for_machine_learning_and_why/,[deleted],1497019690,[removed],0,1
357,2017-6-10,2017,6,10,1,6g9o72,[D] Good introduction to time series for a machine learner?,https://www.reddit.com/r/MachineLearning/comments/6g9o72/d_good_introduction_to_time_series_for_a_machine/,Paddapa,1497027348,"I am finding that there is a bit of a gap when it comes to machine learning and time series. I am very interested in the later, but find that most ML texts don't really go into it. They cover classification and regression nicely, but I'm starting to notice that time series probably requires a whole other bag of tricks.

I'd rather understand a bit of theory before just taking my time series data and throwing it into some black box LSTM and hoping for the best. Can someone recommend some textbooks or other resources? How did you learn about time series?",8,8
358,2017-6-10,2017,6,10,2,6g9vgv,[R] Improved Anomaly Detection in Neural Networks (Liang et al),https://www.reddit.com/r/MachineLearning/comments/6g9vgv/r_improved_anomaly_detection_in_neural_networks/,howdygoop,1497029204,,0,6
359,2017-6-10,2017,6,10,2,6ga1fh,[D] The sparsity of sparsity in deep learning,https://www.reddit.com/r/MachineLearning/comments/6ga1fh/d_the_sparsity_of_sparsity_in_deep_learning/,yngvizzle,1497030669,"Hi all,

Sparsity and compressive sensing has seen a lot of applications in both machine learning and image processing, and it seems easy enough to use sparsity inducing algorithms in deep learning (especially for image and audio processing). Does anyone know why this is not done? 

In addition to this, almost all papers that mentions TV or L1 regularization use (sub)gradient descent based methods, not forward-backward splitting algorithms even though these have proven better convergence rates. 

I understand why you wouldn't use L1 for the kernels, but why do I not see any work on e.g. structured sparsity? Also, for visualization, why isn't e.g. total variation regularisation used more? 

The reason I'm asking is that I am thinking of implementing the FISTA algorithm and play around with sparsity-inducing regularisation and I would like to know if this is a complete waste of my time.

PS. Please excuse me if this is regarded a simple question, the questions in MLQuestions seemed more basic than this so I didn't know where to post.",7,7
360,2017-6-10,2017,6,10,2,6ga2qm,Spam or Ham of UCI dataset,https://www.reddit.com/r/MachineLearning/comments/6ga2qm/spam_or_ham_of_uci_dataset/,shravankumar147,1497031016,,0,1
361,2017-6-10,2017,6,10,3,6ga54f,Kaggle: SMS Spam Collection Dataset,https://www.reddit.com/r/MachineLearning/comments/6ga54f/kaggle_sms_spam_collection_dataset/,shravankumar147,1497031627,,0,1
362,2017-6-10,2017,6,10,3,6gacbg,Bayesian Additive Regression Trees (BART)?,https://www.reddit.com/r/MachineLearning/comments/6gacbg/bayesian_additive_regression_trees_bart/,wildernessez,1497033540,[removed],0,1
363,2017-6-10,2017,6,10,3,6gagn3,[R] Self-Normalizing Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6gagn3/r_selfnormalizing_neural_networks/,[deleted],1497034663,[removed],1,2
364,2017-6-10,2017,6,10,4,6gaj0d,Reporting Negative Results,https://www.reddit.com/r/MachineLearning/comments/6gaj0d/reporting_negative_results/,[deleted],1497035243,[removed],0,1
365,2017-6-10,2017,6,10,4,6gasde,C++ for machine learning?,https://www.reddit.com/r/MachineLearning/comments/6gasde/c_for_machine_learning/,tuncperpetua,1497037716,[removed],0,1
366,2017-6-10,2017,6,10,4,6gatgk,Bridgeport Series 1 Milling Machine working Trial,https://www.reddit.com/r/MachineLearning/comments/6gatgk/bridgeport_series_1_milling_machine_working_trial/,[deleted],1497038008,[deleted],0,1
367,2017-6-10,2017,6,10,5,6gb6ra,Complete Layman here - Quick question.,https://www.reddit.com/r/MachineLearning/comments/6gb6ra/complete_layman_here_quick_question/,nicholasfukuoka,1497041511,[removed],0,1
368,2017-6-10,2017,6,10,6,6gbbcn,"KMeans for Image Compression, PCA / MDS / SVD for Visualization in the reduced dimension",https://www.reddit.com/r/MachineLearning/comments/6gbbcn/kmeans_for_image_compression_pca_mds_svd_for/,SandipanDeyUMBC,1497042792,,0,1
369,2017-6-10,2017,6,10,6,6gbbwc,[D] Clarifications re Adversarial Review of Adversarial Learning of Nat Lang post,https://www.reddit.com/r/MachineLearning/comments/6gbbwc/d_clarifications_re_adversarial_review_of/,clbam8,1497042956,,0,14
370,2017-6-10,2017,6,10,6,6gbhjb,Docker for keras with cuda and opencv,https://www.reddit.com/r/MachineLearning/comments/6gbhjb/docker_for_keras_with_cuda_and_opencv/,gpp8pvirginia,1497044582,[removed],0,1
371,2017-6-10,2017,6,10,7,6gbrlq,[D] Combining Imagenet and MSCOCO,https://www.reddit.com/r/MachineLearning/comments/6gbrlq/d_combining_imagenet_and_mscoco/,Cock-tail,1497047507,"I am trying to use a pre-trained model(VGG16) as a first step, before appending my own architecture. VGG is freezed and used only for semantic information extraction, and only the new layers are being trained. Is it a good idea to use the MSCOCO dataset, when the weights of VGG are from Imagenet? It takes a bit too long to download the Imagenet dataset unfortunately.

Thanks.",1,2
372,2017-6-10,2017,6,10,8,6gc5wk,[D] State of the art models,https://www.reddit.com/r/MachineLearning/comments/6gc5wk/d_state_of_the_art_models/,tyrael71,1497051980,"Is there a resource that centralizes what SOTA is on all standard benchmark and datasets, across all types of problems (RL, NLP, CV, etc.), and if not would people like to help construct it? While I am sure researchers who specialise in a particular sub-field of ML already know what papers present the current best approaches in terms of performance, it would be helpful for people starting out their research career.",11,19
373,2017-6-10,2017,6,10,11,6gctqs,Is it hard to recognize keywords in spoken speech (Phonetic word spotting)?,https://www.reddit.com/r/MachineLearning/comments/6gctqs/is_it_hard_to_recognize_keywords_in_spoken_speech/,noobieberry,1497060288,[removed],0,1
374,2017-6-10,2017,6,10,11,6gcuzo,Transition to ML from EE,https://www.reddit.com/r/MachineLearning/comments/6gcuzo/transition_to_ml_from_ee/,CircuitBeast,1497060723,[removed],0,1
375,2017-6-10,2017,6,10,12,6gd41t,[R] PixelGAN Autoencoders,https://www.reddit.com/r/MachineLearning/comments/6gd41t/r_pixelgan_autoencoders/,downtownslim,1497064147,,1,7
376,2017-6-10,2017,6,10,12,6gd704,"[D] Tutorials and implementations for ""Self-normalizing networks""",https://www.reddit.com/r/MachineLearning/comments/6gd704/d_tutorials_and_implementations_for/,_alphamaximus_,1497065302,,16,74
377,2017-6-10,2017,6,10,12,6gdayt,[D] CNN output as features question,https://www.reddit.com/r/MachineLearning/comments/6gdayt/d_cnn_output_as_features_question/,alehx,1497066898,"Deep learning newbie here.

I have been trying to train a CNN with a somewhat small set (~1000) of train/test images (out of millions of images). Through a ton of trial and error I found that although data augmentation (10s of thousands of images) and regularization help a bit, I cannot overcome the overfitting issue on deep CNNs (eg Alexnet, Vgg). Not surprising, but I wanted to try it out. I'm a one man show and it is a very obscure dataset specific to a particular field. So increasing this to hundreds of thousands of images seems improbable.

Weirdly enough, I found that a shallow CNN (one convolutional layer and 3 fully connected layers) with a lot of dropout produces decent results (~levels out around 92% accuracy 85% recall validation set). However, this is not close to what I get with hand crafted features and xgboost or random forest (95% accuracy 93% recall on test set). Just for fun, I decided to pass the training images through the best CNN and use its class probabilities as a feature input into the GBT/RF. This increased their performance on the test set (98% accuracy 96% recall).

My question is.. am I stacking the deck here? Does this 3% increase on the test set mean anything? I almost see this as a small visual vs nonvisual ensemble. It seems as though these additional features increases accuracy by fixing some misclassifications for a couple of labels, whereas the other classes remain fairly unchanged in accuracy. 

If this is a poor approach, is there a better way? Perhaps using flattened output from the convolutional layer?",9,13
378,2017-6-10,2017,6,10,15,6gdsmw,How to go through the Deep Learning Book?,https://www.reddit.com/r/MachineLearning/comments/6gdsmw/how_to_go_through_the_deep_learning_book/,MusicIsLife1995,1497074707,[removed],0,1
379,2017-6-10,2017,6,10,15,6gdwxp,[D] does anyone know if reCaptcha trains AI's or is being used for that?,https://www.reddit.com/r/MachineLearning/comments/6gdwxp/d_does_anyone_know_if_recaptcha_trains_ais_or_is/,thisisrandomman,1497076873,"I mean, I feel like any AI could be trained to select the boxes just like we can, so I don't see it as being effective anymore, and because of this I feel like reCaptcha could just be training AI models.  
(a separate thought) If this were the case for just this one human action on the internet, why could it not eventually be used for all human actions on the internet. Like, use of Google or FB. Or really, any app. Would this be possible, either now or soon? It wouldn't have to train on one person. Hypothetically it could train on millions. ",6,0
380,2017-6-10,2017,6,10,16,6ge4dn,LeCun's reply to Goldberg's (and largely NLP community's) criticism of arXiv flag planting and attitudes in science,https://www.reddit.com/r/MachineLearning/comments/6ge4dn/lecuns_reply_to_goldbergs_and_largely_nlp/,[deleted],1497080870,[deleted],0,1
381,2017-6-10,2017,6,10,16,6ge4oj,[D] LeCun's reply to Goldberg's (and largely NLP community's) criticism of arXiv flag planting and attitudes in science,https://www.reddit.com/r/MachineLearning/comments/6ge4oj/d_lecuns_reply_to_goldbergs_and_largely_nlp/,nonap_,1497081052,,61,129
382,2017-6-10,2017,6,10,17,6ge8es,"The Evolution of Gradient Descent (stochastic, mini-batch, Nesterov)",https://www.reddit.com/r/MachineLearning/comments/6ge8es/the_evolution_of_gradient_descent_stochastic/,moschles,1497083221,,0,1
383,2017-6-10,2017,6,10,18,6gehp0,What is POS (Part of Speech) Tagging? How can I use it?,https://www.reddit.com/r/MachineLearning/comments/6gehp0/what_is_pos_part_of_speech_tagging_how_can_i_use/,maguirej160,1497088779,,0,1
384,2017-6-10,2017,6,10,21,6gf026,"[N] Demis Hassabis, Interviewed by BBC",https://www.reddit.com/r/MachineLearning/comments/6gf026/n_demis_hassabis_interviewed_by_bbc/,nocortex,1497097886,,9,8
385,2017-6-10,2017,6,10,21,6gf35c,[R] [1705.07269] Learning to Factor Policies and Action-Value Functions: Factored Action Space Representations for Deep Reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/6gf35c/r_170507269_learning_to_factor_policies_and/,evc123,1497099232,,0,4
386,2017-6-10,2017,6,10,22,6gfcd8,Music Genre Classification App in Django,https://www.reddit.com/r/MachineLearning/comments/6gfcd8/music_genre_classification_app_in_django/,[deleted],1497102903,[deleted],0,1
387,2017-6-10,2017,6,10,23,6gfjsl,[P] Exploring LSTMs,https://www.reddit.com/r/MachineLearning/comments/6gfjsl/p_exploring_lstms/,pmigdal,1497105546,,25,167
388,2017-6-11,2017,6,11,0,6gftns,[D] Author feedback for ACM Multimedia (2017) conference,https://www.reddit.com/r/MachineLearning/comments/6gftns/d_author_feedback_for_acm_multimedia_2017/,SSOctopus,1497108875,"Has anyone submitted a technical paper to the conference and received reviews? The [website](http://www.acmmm.org/2017/contribute/submission-deadlines/) says feedback is sent to authors June 8. I haven't heard back yet, wondering if there's a delay or if something went wrong in my submission.",2,1
389,2017-6-11,2017,6,11,5,6ghd35,Native Language Identification (NLI) competition,https://www.reddit.com/r/MachineLearning/comments/6ghd35/native_language_identification_nli_competition/,NLIST,1497126048,[removed],0,1
390,2017-6-11,2017,6,11,5,6ghjnk,Is C++ reasonable to code a machine learning algorithm?,https://www.reddit.com/r/MachineLearning/comments/6ghjnk/is_c_reasonable_to_code_a_machine_learning/,tuncperpetua,1497128080,[removed],0,1
391,2017-6-11,2017,6,11,6,6ghq3z,Applied Machine learning projects: Workshop/Demo Papers in Conferences Vs Personal practical blog posts,https://www.reddit.com/r/MachineLearning/comments/6ghq3z/applied_machine_learning_projects_workshopdemo/,[deleted],1497130136,[removed],0,1
392,2017-6-11,2017,6,11,6,6ght81,"GMM Inference using non EM, non Variational Inference?",https://www.reddit.com/r/MachineLearning/comments/6ght81/gmm_inference_using_non_em_non_variational/,[deleted],1497131145,[removed],0,1
393,2017-6-11,2017,6,11,7,6gi3bp,[R] [1706.00705] Streaming Bayesian inference: theoretical limits and mini-batch approximate message-passing,https://www.reddit.com/r/MachineLearning/comments/6gi3bp/r_170600705_streaming_bayesian_inference/,ipu0015,1497134518,,3,23
394,2017-6-11,2017,6,11,7,6gi4se,"[D] Stochastic Variational Inference: Why gradient of ELBO, not log (posterior) probability or",https://www.reddit.com/r/MachineLearning/comments/6gi4se/d_stochastic_variational_inference_why_gradient/,[deleted],1497134980,[deleted],0,1
395,2017-6-11,2017,6,11,8,6gi7f2,"[D] Stochastic Variational Inference: Why gradient of ELBO, not log (posterior) probability?",https://www.reddit.com/r/MachineLearning/comments/6gi7f2/d_stochastic_variational_inference_why_gradient/,VforVitamin,1497135875,"I'm studying inference techniques on a graphical model but it is pretty confusing to me that why we use ELBO as an objective function for stochastic optimization for inference.
I understand that the approximate model such as a model with mean-field approximation generates a simpler model, but the gradient of the approximated model doesn't seem less complex than the gradient of the posterior probability.
If both gradients have similar complexity, why use approximated model? However, I only see the stochastic optimization of ELBO, natural gradient, but not posterior probability directly.",9,2
396,2017-6-11,2017,6,11,12,6gjhgj,pix2code: Generating Code from a Graphical User Interface Screenshot,https://www.reddit.com/r/MachineLearning/comments/6gjhgj/pix2code_generating_code_from_a_graphical_user/,Underwhelming_Force,1497153276,,0,1
397,2017-6-11,2017,6,11,13,6gjpro,would like to share this results with you too,https://www.reddit.com/r/MachineLearning/comments/6gjpro/would_like_to_share_this_results_with_you_too/,Sportinger,1497156935,,0,1
398,2017-6-11,2017,6,11,17,6gke6a,[D] Requesting OpenAI to justify the grandiose claims they make and hype they create without much substance,https://www.reddit.com/r/MachineLearning/comments/6gke6a/d_requesting_openai_to_justify_the_grandiose/,nonap_,1497169808,"Quoting a [recent reddit comment](https://www.reddit.com/r/MachineLearning/comments/6g5gb6/d_an_adversarial_review_of_adversarial_generation/dinu02i/):

&gt; DeepMind and OpenAI are the biggest offenders of this flag planting with their blogging. Every new pre-print must have a blog post written about it, and these are then spread through these organization's PR machines. What ever happened to that unsupervised sentiment neuron that was all the buzz? I thought Evolutionary Strategies was supposed to overthrow RL as we know it? ES was called A New Direction for Artificial Intelligence? before it had been peer reviewed. These papers were rejected from ICML^. I'm not saying they are bad, and I'm not saying they shouldn't have posted to ArXiv. Just wait until the paper is accepted, then write the blog post.
EDIT: ^ Probably. Judging by formating and time of release.
EDIT2: My apologies to /u/alecradford . As he points out below, the RNN work was not submitted to ICML",84,98
399,2017-6-11,2017,6,11,20,6gkx20,Play with a neural network in browser?,https://www.reddit.com/r/MachineLearning/comments/6gkx20/play_with_a_neural_network_in_browser/,trance1st,1497180428,[removed],0,1
400,2017-6-11,2017,6,11,21,6gl5lp,Researchers decipher how faces are encoded in the brain,https://www.reddit.com/r/MachineLearning/comments/6gl5lp/researchers_decipher_how_faces_are_encoded_in_the/,[deleted],1497184570,[deleted],0,1
401,2017-6-11,2017,6,11,22,6glamu,Proceedings of the 2017 Benelux Conference on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6glamu/proceedings_of_the_2017_benelux_conference_on/,[deleted],1497186706,[deleted],0,1
402,2017-6-11,2017,6,11,22,6glb07,[R] Proceedings of the 2017 Benelux Conference on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6glb07/r_proceedings_of_the_2017_benelux_conference_on/,TaXxER,1497186867,,8,12
403,2017-6-11,2017,6,11,22,6glct0,Information science,https://www.reddit.com/r/MachineLearning/comments/6glct0/information_science/,apaar123,1497187557,[removed],0,1
404,2017-6-11,2017,6,11,23,6glq7h,[D] Compute the output of a 2D convolutional layer with a non-square kernel.,https://www.reddit.com/r/MachineLearning/comments/6glq7h/d_compute_the_output_of_a_2d_convolutional_layer/,[deleted],1497192399,[deleted],0,1
405,2017-6-12,2017,6,12,0,6glumb,[D] Figuring out the padding of the input for a fully convolutional autoencoder.,https://www.reddit.com/r/MachineLearning/comments/6glumb/d_figuring_out_the_padding_of_the_input_for_a/,hyperqube12,1497193857,,9,0
406,2017-6-12,2017,6,12,0,6gluq0,Is there any code online for Policy Gradient Methods for control including Natural Actor-Critic?,https://www.reddit.com/r/MachineLearning/comments/6gluq0/is_there_any_code_online_for_policy_gradient/,[deleted],1497193890,[removed],0,1
407,2017-6-12,2017,6,12,0,6glyr1,A (computational) linguistic farce in three acts,https://www.reddit.com/r/MachineLearning/comments/6glyr1/a_computational_linguistic_farce_in_three_acts/,Redditsez777,1497195212,,0,1
408,2017-6-12,2017,6,12,0,6gm1if,"[D] Fernando Pereira: All publication-based reputation systems have been gamed: different vulnerabilities, different attacks, but same objectives",https://www.reddit.com/r/MachineLearning/comments/6gm1if/d_fernando_pereira_all_publicationbased/,feedthecreed,1497196095,,10,45
409,2017-6-12,2017,6,12,0,6gm26z,[D] Is there any code online for Policy Gradient Methods for control including Natural Actor-Critic?,https://www.reddit.com/r/MachineLearning/comments/6gm26z/d_is_there_any_code_online_for_policy_gradient/,bbsome,1497196307,I'm just gazing a bit on the literature on Natural Gradients in RL and found the comparison in Jan Peters paper - Policy Gradient Methods for Robotics - very nice. I was wondering if there is any code lying around for applying all of those techniques to the same task? And do people know in what scenarios is Natural Gradient used in RL most often?,13,1
410,2017-6-12,2017,6,12,1,6gmchu,No Reference Image Quality Assessments,https://www.reddit.com/r/MachineLearning/comments/6gmchu/no_reference_image_quality_assessments/,mshuva,1497199373,[removed],0,1
411,2017-6-12,2017,6,12,2,6gmqno,"The Past, Present, and Future of Word Embeddings",https://www.reddit.com/r/MachineLearning/comments/6gmqno/the_past_present_and_future_of_word_embeddings/,Redditsez777,1497203540,,0,2
412,2017-6-12,2017,6,12,3,6gmsy5,Agar.io blobs trained through neuro-evolution in the browser,https://www.reddit.com/r/MachineLearning/comments/6gmsy5/agario_blobs_trained_through_neuroevolution_in/,wagenaartje,1497204197,,0,1
413,2017-6-12,2017,6,12,3,6gmv0j,Target-seeking neural agents trained through neuro-evolution,https://www.reddit.com/r/MachineLearning/comments/6gmv0j/targetseeking_neural_agents_trained_through/,wagenaartje,1497204794,,0,1
414,2017-6-12,2017,6,12,4,6gnc2z,Is it just me or deeplearning book by Ian seems a little bit hard and maths heavy ?,https://www.reddit.com/r/MachineLearning/comments/6gnc2z/is_it_just_me_or_deeplearning_book_by_ian_seems_a/,saurabhvyas3,1497209798,[removed],0,1
415,2017-6-12,2017,6,12,4,6gnc85,Applying Deep Learning To Real World Problems,https://www.reddit.com/r/MachineLearning/comments/6gnc85/applying_deep_learning_to_real_world_problems/,conradcreates,1497209836,,0,1
416,2017-6-12,2017,6,12,4,6gnf8z,[R] How would you approach this ML problem?,https://www.reddit.com/r/MachineLearning/comments/6gnf8z/r_how_would_you_approach_this_ml_problem/,[deleted],1497210720,[deleted],0,0
417,2017-6-12,2017,6,12,5,6gngwc,[D] Machine Learning - WAYR (What Are You Reading) - Week 27,https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1497211205,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|
|----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/asobolev: [Stochastic Gradient Descent as Approximate Bayesian Inference](https://arxiv.org/abs/1704.04289)

Besides that, there are no rules, have fun.",19,57
418,2017-6-12,2017,6,12,6,6go2n9,[P] Cheat Sheets for deep learning and machine learning,https://www.reddit.com/r/MachineLearning/comments/6go2n9/p_cheat_sheets_for_deep_learning_and_machine/,clbam8,1497217781,,14,612
419,2017-6-12,2017,6,12,8,6gogd8,Best Rowing Machines 2017,https://www.reddit.com/r/MachineLearning/comments/6gogd8/best_rowing_machines_2017/,joliettesirius,1497222013,,0,1
420,2017-6-12,2017,6,12,9,6goyh5,[R] Forward Thinking: Building and Training Neural Networks One Layer at a Time,https://www.reddit.com/r/MachineLearning/comments/6goyh5/r_forward_thinking_building_and_training_neural/,goodside,1497227844,,32,20
421,2017-6-12,2017,6,12,9,6gozu0,[P] A Quick and Overarching Tutorial on Sparse Matrices and their Compression Algorithms,https://www.reddit.com/r/MachineLearning/comments/6gozu0/p_a_quick_and_overarching_tutorial_on_sparse/,Dark_Element75,1497228315,,0,12
422,2017-6-12,2017,6,12,10,6gp88q,"Summary of ""A simple neural network module for relational reasoning"" on ShortScience.org",https://www.reddit.com/r/MachineLearning/comments/6gp88q/summary_of_a_simple_neural_network_module_for/,ieee8023,1497231193,,0,1
423,2017-6-12,2017,6,12,10,6gpa87,[R] Gated Orthogonal Recurrent Units: On Learning to Forget,https://www.reddit.com/r/MachineLearning/comments/6gpa87/r_gated_orthogonal_recurrent_units_on_learning_to/,xternalz,1497231922,,9,7
424,2017-6-12,2017,6,12,11,6gpi4g,If I follow this tutorial to train a ML model on my laptop can I pass the trained model to my raspberry pi and use it? https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/?utm_campaign=chrome_series_machinelearning_063016&amp;utm_source=gdev&amp;utm_medium=yt-desc#7,https://www.reddit.com/r/MachineLearning/comments/6gpi4g/if_i_follow_this_tutorial_to_train_a_ml_model_on/,tlalco,1497234651,[removed],0,1
425,2017-6-12,2017,6,12,12,6gpq35,[D] Deeplearning4j is the fox and the grape tastes very sour,https://www.reddit.com/r/MachineLearning/comments/6gpq35/d_deeplearning4j_is_the_fox_and_the_grape_tastes/,bbsome,1497237407,,13,0
426,2017-6-12,2017,6,12,12,6gprnx,[P] Neural Speech Recognition Using Modified Tacotron,https://www.reddit.com/r/MachineLearning/comments/6gprnx/p_neural_speech_recognition_using_modified/,longinglove,1497237967,,1,9
427,2017-6-12,2017,6,12,13,6gq0q6,"One year later, heres the state of the chatbot economy",https://www.reddit.com/r/MachineLearning/comments/6gq0q6/one_year_later_heres_the_state_of_the_chatbot/,hardikmakadia,1497241324,,0,1
428,2017-6-12,2017,6,12,13,6gq1eo,Trying to Understand terms used in YOLO9000 paper,https://www.reddit.com/r/MachineLearning/comments/6gq1eo/trying_to_understand_terms_used_in_yolo9000_paper/,datthnguyen,1497241595,[removed],0,1
429,2017-6-12,2017,6,12,14,6gqafi,[D] Deep Learning build Review/Feedback,https://www.reddit.com/r/MachineLearning/comments/6gqafi/d_deep_learning_build_reviewfeedback/,yik_yak_paddy_wack,1497245199,[removed],0,1
430,2017-6-12,2017,6,12,16,6gqrmk,a little help building logistic regression model?,https://www.reddit.com/r/MachineLearning/comments/6gqrmk/a_little_help_building_logistic_regression_model/,shaharsib,1497252568,[removed],0,1
431,2017-6-12,2017,6,12,16,6gqs0f,Nvidia DGX station beats the best DL rig you can build in performance per dollar if Nvidia's numbers were to be believed,https://www.reddit.com/r/MachineLearning/comments/6gqs0f/nvidia_dgx_station_beats_the_best_dl_rig_you_can/,[deleted],1497252733,[removed],0,1
432,2017-6-12,2017,6,12,17,6gqz25,[Q] Does it make sense to predict(regress) time series data with seq2seq?,https://www.reddit.com/r/MachineLearning/comments/6gqz25/q_does_it_make_sense_to_predictregress_time/,[deleted],1497256259,[removed],0,1
433,2017-6-12,2017,6,12,17,6gqzxl,Topics: popularity vs achievability,https://www.reddit.com/r/MachineLearning/comments/6gqzxl/topics_popularity_vs_achievability/,intensityCheck,1497256708,[removed],0,1
434,2017-6-12,2017,6,12,17,6gr0oh,[D]How to generate a nature sentence by input some isolate words,https://www.reddit.com/r/MachineLearning/comments/6gr0oh/dhow_to_generate_a_nature_sentence_by_input_some/,wjbianjason,1497257067,"To be specific,when I input some isolate words ,then the model generate one nature sentence which contains these input words.For example,I input ""girl white beautiful"",then generate this sentence ""that girl in white shirt looks beautiful"".I'm confused to solve this problem,so please anybody help me.",10,0
435,2017-6-12,2017,6,12,18,6gr2z8,[D] Nvidia DGX Station beats the best DL rig you can build in performance per dollar if Nvidia's numbers were to be believed,https://www.reddit.com/r/MachineLearning/comments/6gr2z8/d_nvidia_dgx_station_beats_the_best_dl_rig_you/,[deleted],1497258271,[deleted],16,6
436,2017-6-12,2017,6,12,18,6gr6c9,Weight Learning Algorithms in Machine Learning Classification Problem,https://www.reddit.com/r/MachineLearning/comments/6gr6c9/weight_learning_algorithms_in_machine_learning/,15MCS003,1497259904,[removed],0,1
437,2017-6-12,2017,6,12,20,6grmd3,[R][1706.01109] InfiniteBoost: building infinite ensembles with gradient descent,https://www.reddit.com/r/MachineLearning/comments/6grmd3/r170601109_infiniteboost_building_infinite/,arogozhnikov,1497266725,,10,14
438,2017-6-12,2017,6,12,21,6grw5b,Early access to deep learning book by Keras author,https://www.reddit.com/r/MachineLearning/comments/6grw5b/early_access_to_deep_learning_book_by_keras_author/,[deleted],1497270357,[deleted],0,1
439,2017-6-12,2017,6,12,21,6grw9t,[N] Early access to deep learning book by Keras author,https://www.reddit.com/r/MachineLearning/comments/6grw9t/n_early_access_to_deep_learning_book_by_keras/,Reiinakano,1497270408,,23,17
440,2017-6-12,2017,6,12,22,6gs81s,Automating Tinder using Convolutional Neural Networks and Face Classification [X-post /r/technology],https://www.reddit.com/r/MachineLearning/comments/6gs81s/automating_tinder_using_convolutional_neural/,oscaralsing,1497274285,,1,3
441,2017-6-12,2017,6,12,22,6gs9hh,Binary sequence RNN research?,https://www.reddit.com/r/MachineLearning/comments/6gs9hh/binary_sequence_rnn_research/,deltasheep1,1497274746,[removed],0,1
442,2017-6-12,2017,6,12,23,6gsjvj,The Hardware of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6gsjvj/the_hardware_of_deep_learning/,arshakn,1497277783,,0,1
443,2017-6-12,2017,6,12,23,6gsl0c,"[D] Amongst all the arguing going on, let's remember ""what we're doing here simply is not science. It's engineering""",https://www.reddit.com/r/MachineLearning/comments/6gsl0c/d_amongst_all_the_arguing_going_on_lets_remember/,rantana,1497278114,"As [this comment](https://www.reddit.com/r/MachineLearning/comments/6g5gb6/d_an_adversarial_review_of_adversarial_generation/dinyxju/) points out, we should remember:

&gt; I feel like part of the problem is that in a lot of ways what we're doing here simply is not science. It's engineering. And in engineering, you want people to be sharing ideas and interesting results as quickly and seamlessly as you can. Some won't go anywhere, and some won't rise to the level of journal publication, but that doesn't mean people won't benefit / get ideas from them.
It's not like you need to be a peer-reviewer to reproduce their results, in most cases. That's what's neat about the field: if you can rent an EC2 instance and write python, you can check many of the results for yourself.

The field is about building things to solve problems, the progress is defined by how well you solve these problems (some performance metric). I think once you view it from this perspective, you start seeing what the community values amidst all the hype and debate.",9,0
444,2017-6-12,2017,6,12,23,6gsmg9,Dual Masters,https://www.reddit.com/r/MachineLearning/comments/6gsmg9/dual_masters/,CircuitBeast,1497278524,[removed],0,1
445,2017-6-13,2017,6,13,0,6gt2j0,"[P] Machine, a machine learning IDE with instantaneous, visual feedback",https://www.reddit.com/r/MachineLearning/comments/6gt2j0/p_machine_a_machine_learning_ide_with/,FredrikNoren,1497282756,,63,364
446,2017-6-13,2017,6,13,0,6gt2nl,[R] Lost Relatives of the Gumbel Trick,https://www.reddit.com/r/MachineLearning/comments/6gt2nl/r_lost_relatives_of_the_gumbel_trick/,evc123,1497282795,,3,22
447,2017-6-13,2017,6,13,0,6gt2q8,Machine learning approach to classify music based on genres,https://www.reddit.com/r/MachineLearning/comments/6gt2q8/machine_learning_approach_to_classify_music_based/,l1feh4ck,1497282813,,0,1
448,2017-6-13,2017,6,13,1,6gt65z,[D] Does it make sense to predict(regress) time series data with seq2seq?,https://www.reddit.com/r/MachineLearning/comments/6gt65z/d_does_it_make_sense_to_predictregress_time/,0b01,1497283694,"For time series prediction such as this one[1], what is the point of using seq2seq? The input and output have the same semantics so why bother encode/decode at all?

[1] https://github.com/guillaume-chevalier/seq2seq-signal-prediction",4,4
449,2017-6-13,2017,6,13,2,6gtiq7,[P] Need good VAE for celebA baseline,https://www.reddit.com/r/MachineLearning/comments/6gtiq7/p_need_good_vae_for_celeba_baseline/,anonDogeLover,1497286882,Does anyone know of a good codebasem? (hopefully tensorflow or theano). It doesn't have to be pretrained. Something like /u/dribnet level results would be great.,1,2
450,2017-6-13,2017,6,13,2,6gtiyw,"A Growth Hack for Data Science Companies, via My Amazon-/Microsoft-/ VC-Praised Plan for Providing Many OPEN-DATA, High-Value Online Markets",https://www.reddit.com/r/MachineLearning/comments/6gtiyw/a_growth_hack_for_data_science_companies_via_my/,[deleted],1497286941,[deleted],0,1
451,2017-6-13,2017,6,13,2,6gtqus,Public Health Diagnoses Dataset,https://www.reddit.com/r/MachineLearning/comments/6gtqus/public_health_diagnoses_dataset/,dragonslikepi,1497288847,[removed],0,1
452,2017-6-13,2017,6,13,3,6gtzjb,Number of descriptors(features) to select,https://www.reddit.com/r/MachineLearning/comments/6gtzjb/number_of_descriptorsfeatures_to_select/,DefNotaZombie,1497290941,[removed],0,1
453,2017-6-13,2017,6,13,3,6gu16m,My first blog post ever - Introduction to text representation and similarity,https://www.reddit.com/r/MachineLearning/comments/6gu16m/my_first_blog_post_ever_introduction_to_text/,sudo_su_,1497291354,[removed],0,1
454,2017-6-13,2017,6,13,4,6gul47,"""Depthwise Separable Convolutions for Neural Machine Translation"", Kaiser et al 2017 [removing dilations from 1D convolutions while reducing parameter count]",https://www.reddit.com/r/MachineLearning/comments/6gul47/depthwise_separable_convolutions_for_neural/,gwern,1497296351,,0,1
455,2017-6-13,2017,6,13,6,6gv978,First blog post from me: a new trick for calculating Jacobian vector products,https://www.reddit.com/r/MachineLearning/comments/6gv978/first_blog_post_from_me_a_new_trick_for/,[deleted],1497302366,[deleted],1,2
456,2017-6-13,2017,6,13,6,6gvetx,MNIST Preprocessing Question,https://www.reddit.com/r/MachineLearning/comments/6gvetx/mnist_preprocessing_question/,[deleted],1497303855,[removed],0,1
457,2017-6-13,2017,6,13,6,6gvh6c,"[D] Does anyone know of a reasonably comprehensive index of different architecture tricks? Activation functions, layer types, etc?",https://www.reddit.com/r/MachineLearning/comments/6gvh6c/d_does_anyone_know_of_a_reasonably_comprehensive/,[deleted],1497304462,[deleted],2,11
458,2017-6-13,2017,6,13,7,6gvj0u,Tensor contraction layer,https://www.reddit.com/r/MachineLearning/comments/6gvj0u/tensor_contraction_layer/,[deleted],1497304951,[deleted],0,1
459,2017-6-13,2017,6,13,7,6gvkl2,Explaining Tensor Contraction Layer,https://www.reddit.com/r/MachineLearning/comments/6gvkl2/explaining_tensor_contraction_layer/,imanishshah,1497305368,[removed],0,1
460,2017-6-13,2017,6,13,7,6gvv0o,[R] First blog post: a new trick for calculating Jacobian vector products,https://www.reddit.com/r/MachineLearning/comments/6gvv0o/r_first_blog_post_a_new_trick_for_calculating/,j-towns,1497308280,,22,16
461,2017-6-13,2017,6,13,9,6gwamp,"Have questions on speaker recognition (specifically Gaussian Mixture Model-based approaches), looking for right place to ask",https://www.reddit.com/r/MachineLearning/comments/6gwamp/have_questions_on_speaker_recognition/,diskywhick,1497312979,[removed],0,1
462,2017-6-13,2017,6,13,9,6gwbxr,           ...,https://www.reddit.com/r/MachineLearning/comments/6gwbxr/_______/,videomachins,1497313362,,1,1
463,2017-6-13,2017,6,13,10,6gwjk9,How much does the dry powder mixer blender?,https://www.reddit.com/r/MachineLearning/comments/6gwjk9/how_much_does_the_dry_powder_mixer_blender/,JCT_MACHINE,1497315738,,0,1
464,2017-6-13,2017,6,13,10,6gwo5z,Adversarial Playground: A web-based Visualization of Evasion Algorithms,https://www.reddit.com/r/MachineLearning/comments/6gwo5z/adversarial_playground_a_webbased_visualization/,[deleted],1497317168,[deleted],0,1
465,2017-6-13,2017,6,13,10,6gwq89,[1706.03762] Attention Is All You Need &lt;-- Sota NMT; less compute,https://www.reddit.com/r/MachineLearning/comments/6gwq89/170603762_attention_is_all_you_need_sota_nmt_less/,[deleted],1497317804,[deleted],0,1
466,2017-6-13,2017,6,13,10,6gwq9b,[P] Adversarial Playground: A Web-based Visualization of Evasion Algorithms,https://www.reddit.com/r/MachineLearning/comments/6gwq9b/p_adversarial_playground_a_webbased_visualization/,apnorton,1497317812,,0,1
467,2017-6-13,2017,6,13,10,6gwqiw,[R] [1706.03762] Attention Is All You Need &lt;-- Sota NMT; less compute,https://www.reddit.com/r/MachineLearning/comments/6gwqiw/r_170603762_attention_is_all_you_need_sota_nmt/,evc123,1497317894,,58,67
468,2017-6-13,2017,6,13,11,6gwwl3,[P] Training BEGAN with a small face dataset,https://www.reddit.com/r/MachineLearning/comments/6gwwl3/p_training_began_with_a_small_face_dataset/,anonDogeLover,1497319821,"I'm training BEGAN with a small dataset of ~3500 faces, with much less variation than datasets like celebA. I've had some strange results. Most of the time, on each epoch the model will sample a single face many times. It looks good, but there is zero diversity, which seems possible, but it's strange that it changes epoch to epoch. Anyway, when I turn lambda way way up, I get good diversity, and the samples look fantastic, but they just never seem to learn hair. I don't mean that in the sense of normal BEGAN or VAE samples with blurry hair. I mean most people are bald or have only a little bit of hair on top. It feels like it's still a problem with forcing diversity, but I've maxed out the lambda parameter and I'm not sure what else to do. Any ideas?

Update: Don't know what's up with BEGAN, but DCGAN did fairly well (since the data has well-controlled variation), and improved-WGAN almost perfectly mastered the dataset.",10,5
469,2017-6-13,2017,6,13,11,6gx0c6,[Discussion]Variable length attention models,https://www.reddit.com/r/MachineLearning/comments/6gx0c6/discussionvariable_length_attention_models/,bronzestick,1497320934,"Has there been any work on tackling soft attention over variable length sequences? 

For example, consider the language modeling task where you are using a soft attention over all the previous words to predict the next word. Since the number of previous words change over time, we need to learn an attention model that can compute similarity and softmax scores over a varying sized set of hidden states. Just a hypothetical example.

The problem I am tackling is not language modeling but instead something like multi-sequence prediction, where the number of sequences vary over time and the sequences are dependent on each other.
So, in order to predict the next element in a specific sequence, I need to compute a soft attention over the hidden states of all the other sequences and use that as an input. But since the number of sequences vary, I need to learn a varying length attention model.

I think it is interesting to see how accurately it can learn attention (or softmax scores) with varying length.",5,7
470,2017-6-13,2017,6,13,11,6gx0ws,Developing in Tensorflow in a nutshell,https://www.reddit.com/r/MachineLearning/comments/6gx0ws/developing_in_tensorflow_in_a_nutshell/,[deleted],1497321102,[deleted],0,1
471,2017-6-13,2017,6,13,11,6gx2mw,Martin Arjovsky (WGAN) Interview by Alex Lamb,https://www.reddit.com/r/MachineLearning/comments/6gx2mw/martin_arjovsky_wgan_interview_by_alex_lamb/,[deleted],1497321662,[deleted],0,1
472,2017-6-13,2017,6,13,11,6gx2rx,[D] Martin Arjovsky (WGAN) Interview by Alex Lamb,https://www.reddit.com/r/MachineLearning/comments/6gx2rx/d_martin_arjovsky_wgan_interview_by_alex_lamb/,sherjilozair,1497321707,,19,42
473,2017-6-13,2017,6,13,11,6gx2w8,[D] Developing in Tensorflow in a nutshell,https://www.reddit.com/r/MachineLearning/comments/6gx2w8/d_developing_in_tensorflow_in_a_nutshell/,[deleted],1497321744,[deleted],6,28
474,2017-6-13,2017,6,13,11,6gx2zz,The Terrible Deep Learning List,https://www.reddit.com/r/MachineLearning/comments/6gx2zz/the_terrible_deep_learning_list/,[deleted],1497321776,[deleted],0,1
475,2017-6-13,2017,6,13,12,6gx72j,STR 1200 Strapping machine AMC,https://www.reddit.com/r/MachineLearning/comments/6gx72j/str_1200_strapping_machine_amc/,AMC_Andy,1497323082,,1,1
476,2017-6-13,2017,6,13,13,6gxixi,Global Chatbots Market projections worth of 6 Billion USD at 37% of CAGR by 2023,https://www.reddit.com/r/MachineLearning/comments/6gxixi/global_chatbots_market_projections_worth_of_6/,hardikmakadia,1497327067,,0,1
477,2017-6-13,2017,6,13,13,6gxqfv,Machine Learning - Predict Stock Prices using Regression,https://www.reddit.com/r/MachineLearning/comments/6gxqfv/machine_learning_predict_stock_prices_using/,nitinkarma,1497329612,,0,1
478,2017-6-13,2017,6,13,13,6gxqyn,[D] Nuno Castro - Ranking hotel images using deep learning,https://www.reddit.com/r/MachineLearning/comments/6gxqyn/d_nuno_castro_ranking_hotel_images_using_deep/,_alphamaximus_,1497329825,,0,0
479,2017-6-13,2017,6,13,14,6gxt73,[R] Benchmarking CNTK on Keras: is it Better at Deep Learning than TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/6gxt73/r_benchmarking_cntk_on_keras_is_it_better_at_deep/,ibobriakov,1497330676,,0,1
480,2017-6-13,2017,6,13,14,6gxu0w,GOAI: Open GPU-Accelerated Data Analytics,https://www.reddit.com/r/MachineLearning/comments/6gxu0w/goai_open_gpuaccelerated_data_analytics/,harrism,1497331012,,0,1
481,2017-6-13,2017,6,13,14,6gxuk5,[D] Variational Inference and Deep Learning: An Intuitive Introduction (by Alex Lamb),https://www.reddit.com/r/MachineLearning/comments/6gxuk5/d_variational_inference_and_deep_learning_an/,evc123,1497331212,,12,62
482,2017-6-13,2017,6,13,14,6gxvfn,What fields will be impacted by Machine Learning the most?,https://www.reddit.com/r/MachineLearning/comments/6gxvfn/what_fields_will_be_impacted_by_machine_learning/,MusicIsLife1995,1497331538,[removed],0,1
483,2017-6-13,2017,6,13,16,6gyedv,What is marble adhesive glue?,https://www.reddit.com/r/MachineLearning/comments/6gyedv/what_is_marble_adhesive_glue/,mixmachinery,1497339337,,0,1
484,2017-6-13,2017,6,13,16,6gyfyj,Tucker decomposition in Sandia Tensor Toolbox,https://www.reddit.com/r/MachineLearning/comments/6gyfyj/tucker_decomposition_in_sandia_tensor_toolbox/,[deleted],1497340095,[removed],0,1
485,2017-6-13,2017,6,13,17,6gylii,what is ambient isotopy?,https://www.reddit.com/r/MachineLearning/comments/6gylii/what_is_ambient_isotopy/,John_Smith111,1497342779,[removed],1,1
486,2017-6-13,2017,6,13,17,6gylx2,Facebook Trains ImageNet in 1 Hour,https://www.reddit.com/r/MachineLearning/comments/6gylx2/facebook_trains_imagenet_in_1_hour/,Dutchcheesehead,1497342974,,0,1
487,2017-6-13,2017,6,13,19,6gz0n7,"[Discussion] Classification of sentences into fact, opinion, inference etc.",https://www.reddit.com/r/MachineLearning/comments/6gz0n7/discussion_classification_of_sentences_into_fact/,NormalOne95,1497349719,"Sorry for posting it here (seems like the sub at [LanguageTechnology](https://www.reddit.com/r/LanguageTechnology/) is not so active). 

I am working on an NLP task. I was wondering if there is any prior research on classification of sentences into difference classes like opinion, fact, inference etc. I did find this [paper](http://acl-arc.comp.nus.edu.sg/archives/acl-arc-090501d4/data/pdf/anthology-PDF/W/W03/W03-1017.pdf) I could use but nothing concrete. 

Could anyone help?
",8,8
488,2017-6-13,2017,6,13,21,6gzi8g,Best Portable Table Saw,https://www.reddit.com/r/MachineLearning/comments/6gzi8g/best_portable_table_saw/,Rayumdan,1497356488,,0,1
489,2017-6-13,2017,6,13,21,6gzick,Classification on Compressed Images?,https://www.reddit.com/r/MachineLearning/comments/6gzick/classification_on_compressed_images/,[deleted],1497356529,[removed],0,1
490,2017-6-13,2017,6,13,21,6gzk0j,Machine Learning Versus Standard Techniques for Updating Searches for Systematic Reviews: A Diagnostic Accuracy Study | Annals of Internal Medicine,https://www.reddit.com/r/MachineLearning/comments/6gzk0j/machine_learning_versus_standard_techniques_for/,yettadufrene,1497357106,,0,1
491,2017-6-13,2017,6,13,21,6gzk2q,[D] Classification on Compressed Images?,https://www.reddit.com/r/MachineLearning/comments/6gzk2q/d_classification_on_compressed_images/,denvermaster,1497357128,Has anyone tried out feeding compressed images(say jpeg compressed image) as input to a deep neural network. As of now we clearly don't understand how the neural network does prediction. We know of some stuff like early layers detecting generic features (like edges) and later layers having more problem specific features. I can imagine this in context of images but may be it does not work on compressed images. I would like to know if there is any resource or attempt (say on MNIST) over the web.,19,8
492,2017-6-13,2017,6,13,21,6gzklr,How AI And Machine Learning Are Helping Drive The GE Digital Transformation,https://www.reddit.com/r/MachineLearning/comments/6gzklr/how_ai_and_machine_learning_are_helping_drive_the/,lanettetwyman,1497357292,,0,1
493,2017-6-13,2017,6,13,21,6gzkv6,What is machine learning?,https://www.reddit.com/r/MachineLearning/comments/6gzkv6/what_is_machine_learning/,jerilyntrost,1497357381,,0,1
494,2017-6-13,2017,6,13,22,6gzpj4,Zero to One  A Ton of Awe-Inspiring Deep Learning Demos with Code for Beginners,https://www.reddit.com/r/MachineLearning/comments/6gzpj4/zero_to_one_a_ton_of_aweinspiring_deep_learning/,[deleted],1497358869,[deleted],0,1
495,2017-6-13,2017,6,13,22,6gzqkn,Origo Maths Think Tank Review,https://www.reddit.com/r/MachineLearning/comments/6gzqkn/origo_maths_think_tank_review/,Freeland1234,1497359181,,0,0
496,2017-6-13,2017,6,13,22,6gzt9i,[R] VisualQA in Pytorch (with SOTA paper),https://www.reddit.com/r/MachineLearning/comments/6gzt9i/r_visualqa_in_pytorch_with_sota_paper/,Tamazy,1497359992,,3,21
497,2017-6-13,2017,6,13,23,6h01jk,[D] ML industry in the UK,https://www.reddit.com/r/MachineLearning/comments/6h01jk/d_ml_industry_in_the_uk/,erthare,1497362470,"I will be moving to the UK in about a year and I'm trying to understand what are the career options for a ML research there.

Can anyone share where in the UK are the industry centers (especially research ones) and what is their focus?",31,8
498,2017-6-13,2017,6,13,23,6h02x8,[R] From source to target and back: symmetric bi-directional adaptive GAN,https://www.reddit.com/r/MachineLearning/comments/6h02x8/r_from_source_to_target_and_back_symmetric/,engharat,1497362852,,0,2
499,2017-6-13,2017,6,13,23,6h04uy,Get Inside My Time Machine: A Quick Trip to the Stylometry Origin,https://www.reddit.com/r/MachineLearning/comments/6h04uy/get_inside_my_time_machine_a_quick_trip_to_the/,[deleted],1497363397,[deleted],0,1
500,2017-6-13,2017,6,13,23,6h069y,CortexNet: Robust Visual Temporal Representations,https://www.reddit.com/r/MachineLearning/comments/6h069y/cortexnet_robust_visual_temporal_representations/,tim_anglade,1497363795,,0,1
501,2017-6-13,2017,6,13,23,6h07de,[P] How to automate deep learning training with Kubernetes GPU-cluster,https://www.reddit.com/r/MachineLearning/comments/6h07de/p_how_to_automate_deep_learning_training_with/,fhoffa,1497364106,,1,36
502,2017-6-13,2017,6,13,23,6h097r,Apple Shares Source Code For Machine Learning Framework at WWDC 2017,https://www.reddit.com/r/MachineLearning/comments/6h097r/apple_shares_source_code_for_machine_learning/,christenharville,1497364599,,0,1
503,2017-6-13,2017,6,13,23,6h0cv6,Deep Learning Toolkit (DLTK) for Medical Imaging,https://www.reddit.com/r/MachineLearning/comments/6h0cv6/deep_learning_toolkit_dltk_for_medical_imaging/,[deleted],1497365612,[removed],0,1
504,2017-6-14,2017,6,14,0,6h0jrg,[P] Deep Learning Toolkit (DLTK) for Medical Imaging,https://www.reddit.com/r/MachineLearning/comments/6h0jrg/p_deep_learning_toolkit_dltk_for_medical_imaging/,mrajchl,1497367413,"Announcing the Deep Learning Tool Kit (DLTK) for Medical Imaging 

We are pleased to announce the release of the DLTK. DLTK is a neural networks toolkit written in python, on top of Tensorflow. Its modular architecture is closely inspired by Deepmind sonnet and it was developed to enable fast prototyping and ensure reproducibility in image analysis applications, with a particular focus on medical imaging. Its goal is to provide the community with state of the art methods and models and to accelerate research in this exciting field.

We provide example code and tutorials for 
- Image classification 
- Image segmentation 
- Generative adversarial networks
- Graph convolution networks
- Representation learning with autoencoders

Pypi:https://pypi.python.org/pypi/dltk/0.1
Documentation: https://dltk.github.io/
Source code: https://github.com/DLTK/DLTK
License: Apache v2.0

Follow us on Twitter @dltk_ !",11,72
505,2017-6-14,2017,6,14,0,6h0ke9,Existential Impasse [OC],https://www.reddit.com/r/MachineLearning/comments/6h0ke9/existential_impasse_oc/,robotaiandme,1497367580,,0,1
506,2017-6-14,2017,6,14,0,6h0l81,[P] ML notes: Why the log-likelihood ?,https://www.reddit.com/r/MachineLearning/comments/6h0l81/p_ml_notes_why_the_loglikelihood/,morgangiraud,1497367797,,22,31
507,2017-6-14,2017,6,14,0,6h0qz5,[R] Deep Reinforcement Learning from Human Preferences,https://www.reddit.com/r/MachineLearning/comments/6h0qz5/r_deep_reinforcement_learning_from_human/,pauljasek,1497369269,,20,53
508,2017-6-14,2017,6,14,1,6h0tjp,Hands-On Machine Learning and Big Data,https://www.reddit.com/r/MachineLearning/comments/6h0tjp/handson_machine_learning_and_big_data/,kalkaseer,1497369900,,0,1
509,2017-6-14,2017,6,14,1,6h0u2t,"[P] ImageNet: VGGNet, ResNet, Inception, and Xception with Keras",https://www.reddit.com/r/MachineLearning/comments/6h0u2t/p_imagenet_vggnet_resnet_inception_and_xception/,pmigdal,1497370033,,0,1
510,2017-6-14,2017,6,14,1,6h0ucg,Scaling Machine Learning to Modern Demands,https://www.reddit.com/r/MachineLearning/comments/6h0ucg/scaling_machine_learning_to_modern_demands/,[deleted],1497370100,[deleted],0,1
511,2017-6-14,2017,6,14,1,6h0wwj,[D] Scaling Machine Learning to Modern Demands,https://www.reddit.com/r/MachineLearning/comments/6h0wwj/d_scaling_machine_learning_to_modern_demands/,gregory_k,1497370698,,0,3
512,2017-6-14,2017,6,14,1,6h15p9,Debug Caffe with GDB on Ubuntu,https://www.reddit.com/r/MachineLearning/comments/6h15p9/debug_caffe_with_gdb_on_ubuntu/,zhaokai,1497372750,,0,1
513,2017-6-14,2017,6,14,1,6h167z,[D] Mini-batch Gibbs sampling?,https://www.reddit.com/r/MachineLearning/comments/6h167z/d_minibatch_gibbs_sampling/,bihaqo,1497372882,"Judging by the recent papers, classical MCMC methods doesn't work in mini-batch regime (e.g. [Welling et al 2011]).

But this paper [Griffiths et al 2004] (with 4000 citations) claims to do just that: use Gibbs sampling for LDA in a mini-batch manner and report excellent results.
&gt;We do this with an on-line version of the Gibbs sampler, using Eq. 5 to assign words to topics, but with counts that are computed from the subset of the words seen so far rather than the full data.

Am I missing something? Can you use Gibbs in a mini-batch way? Or are the results from the LDA paper not reproducible?

[Welling et al 2011] Welling, Max, and Yee W. Teh. ""Bayesian learning via stochastic gradient Langevin dynamics."" (ICML-11)

[Griffiths et al 2004] Griffiths, Thomas L., and Mark Steyvers. ""Finding scientific topics.""",2,14
514,2017-6-14,2017,6,14,1,6h16wr,How to practice the piano; the deep learning way,https://www.reddit.com/r/MachineLearning/comments/6h16wr/how_to_practice_the_piano_the_deep_learning_way/,kangmo,1497373051,,0,1
515,2017-6-14,2017,6,14,2,6h1bcw,ClojureCUDA - a Clojure library for parallel computations on the GPU with CUDA.,https://www.reddit.com/r/MachineLearning/comments/6h1bcw/clojurecuda_a_clojure_library_for_parallel/,dragandj,1497374093,,0,1
516,2017-6-14,2017,6,14,2,6h1jcr,How do you conduct literature survey for your research?,https://www.reddit.com/r/MachineLearning/comments/6h1jcr/how_do_you_conduct_literature_survey_for_your/,activatedgeek,1497376070,[removed],0,1
517,2017-6-14,2017,6,14,2,6h1kry,[D] Heuristics for Early Stopping,https://www.reddit.com/r/MachineLearning/comments/6h1kry/d_heuristics_for_early_stopping/,bronzestick,1497376404,"/r/ML : What do you use as a heuristic for early stopping?

In most of my models, the validation error always fluctuates a lot and I end up running the training until a large number of epochs and take the epoch at which the validation loss was the least. This necessarily wasn't the best model to choose at test time, but it is hard to pick one. But the whole advantage of early stopping is that we get to stop training early and save on training time, which I am losing out on as I am not sure when to stop.

What do you guys usually do? And what have you observed to work well, in practice?",23,26
518,2017-6-14,2017,6,14,2,6h1ku3,"ML experiment comparison view, email/slack notifications and more in AETROS version 2017.3. Went live today",https://www.reddit.com/r/MachineLearning/comments/6h1ku3/ml_experiment_comparison_view_emailslack/,[deleted],1497376418,[deleted],0,1
519,2017-6-14,2017,6,14,3,6h1md6,[D] Arxiv-Sanity down?,https://www.reddit.com/r/MachineLearning/comments/6h1md6/d_arxivsanity_down/,[deleted],1497376810,[deleted],1,1
520,2017-6-14,2017,6,14,3,6h1ngl,"[N] ML experiment comparison view, email/slack notifications and more in AETROS version 2017.3. Went live today",https://www.reddit.com/r/MachineLearning/comments/6h1ngl/n_ml_experiment_comparison_view_emailslack/,marcjschmidt,1497377045,,0,1
521,2017-6-14,2017,6,14,4,6h26ia,[D] LSTM/CNN applications in need of hardware acceleration?,https://www.reddit.com/r/MachineLearning/comments/6h26ia/d_lstmcnn_applications_in_need_of_hardware/,springbreak06,1497381656,"Hey /r/ML:
I'm currently scoping out a Master's thesis project in hardware acceleration of neural nets. Specifically, I'd like to take a network that someone has already developed and implement a portion (or all) of the processing in an FPGA in order to improve throughput and energy efficiency during inference. I've seen plenty of papers published in the last couple years that do just that for various types of networks, e.g. [ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA](https://arxiv.org/pdf/1612.00694v2.pdf). 

I've been on Arxiv Sanity for the past couple months trying to find an application in need of hardware acceleration, and some of the most interesting papers, like [this one](https://arxiv.org/pdf/1704.01194v1.pdf), have used an LSTM on top of a CNN for learning temporal relations of spatial features. If you've seen any other LSTM/CNN application begging to be implemented in hardware, I'd love to see it!",4,11
522,2017-6-14,2017,6,14,6,6h3483,How do you create a tensor from set of physical data?,https://www.reddit.com/r/MachineLearning/comments/6h3483/how_do_you_create_a_tensor_from_set_of_physical/,oqowa,1497390288,[removed],0,1
523,2017-6-14,2017,6,14,7,6h3a53,Optical deep learning,https://www.reddit.com/r/MachineLearning/comments/6h3a53/optical_deep_learning/,deepconvnet,1497391905,,0,1
524,2017-6-14,2017,6,14,8,6h3n7w,How can I get an entry level job on machine learning?,https://www.reddit.com/r/MachineLearning/comments/6h3n7w/how_can_i_get_an_entry_level_job_on_machine/,ribohe94,1497395694,[removed],0,1
525,2017-6-14,2017,6,14,10,6h49j1,[R] [1706.04156] Gradient descent GAN optimization is locally stable &lt;-- updates generator &amp; discriminator simultaneously,https://www.reddit.com/r/MachineLearning/comments/6h49j1/r_170604156_gradient_descent_gan_optimization_is/,evc123,1497402569,,7,27
526,2017-6-14,2017,6,14,10,6h4ahu,S  IC xe Spacy 2000,https://www.reddit.com/r/MachineLearning/comments/6h4ahu/s__ic_xe_spacy_2000/,khuongson93,1497402887,,1,1
527,2017-6-14,2017,6,14,10,6h4epr,[N] Pentagon and Congress debate bans on Chinese investment in US AI companies,https://www.reddit.com/r/MachineLearning/comments/6h4epr/n_pentagon_and_congress_debate_bans_on_chinese/,gwern,1497404200,,36,41
528,2017-6-14,2017,6,14,11,6h4tq4,SmoothGrad: New approach from Google to visualize classifier decisions.,https://www.reddit.com/r/MachineLearning/comments/6h4tq4/smoothgrad_new_approach_from_google_to_visualize/,Reiinakano,1497409068,,0,1
529,2017-6-14,2017,6,14,12,6h4w74,Pretrained Network for Semantic Segmentation,https://www.reddit.com/r/MachineLearning/comments/6h4w74/pretrained_network_for_semantic_segmentation/,Royalito,1497409903,[removed],0,1
530,2017-6-14,2017,6,14,12,6h4xrd,Podcast: The world desperately needs AI strategists. Heres how to become one.,https://www.reddit.com/r/MachineLearning/comments/6h4xrd/podcast_the_world_desperately_needs_ai/,[deleted],1497410429,[deleted],0,1
531,2017-6-14,2017,6,14,13,6h55td,[P] I trained a probabilistic model to predict new posts on Reddit most likely to make it to r/All.,https://www.reddit.com/r/MachineLearning/comments/6h55td/p_i_trained_a_probabilistic_model_to_predict_new/,[deleted],1497413297,[removed],0,1
532,2017-6-14,2017,6,14,16,6h5wzk,[R] [1706.03912] (From U. Iowa &amp; Snapchat) SEP-Nets: Small and Effective Pattern Networks,https://www.reddit.com/r/MachineLearning/comments/6h5wzk/r_170603912_from_u_iowa_snapchat_sepnets_small/,tim_anglade,1497424074,,1,13
533,2017-6-14,2017,6,14,16,6h5x7z,[D] Visual analysis and diagnostic tools to facilitate machine learning model selection.,https://www.reddit.com/r/MachineLearning/comments/6h5x7z/d_visual_analysis_and_diagnostic_tools_to/,_alphamaximus_,1497424172,,0,7
534,2017-6-14,2017,6,14,17,6h649f,"Brain goes up to 11 dimensions. ""We found a world that we had never imagined,"" says lead researcher, neuroscientist Henry Markram from the EPFL institute in Switzerland.",https://www.reddit.com/r/MachineLearning/comments/6h649f/brain_goes_up_to_11_dimensions_we_found_a_world/,rende,1497427426,,0,1
535,2017-6-14,2017,6,14,17,6h6611,[P] MNIST For ML Beginners: The Bayesian way,https://www.reddit.com/r/MachineLearning/comments/6h6611/p_mnist_for_ml_beginners_the_bayesian_way/,pmigdal,1497428337,,3,25
536,2017-6-14,2017,6,14,17,6h6ao0,"[N] NumPy receives first ever funding, thanks to Moore Foundation",https://www.reddit.com/r/MachineLearning/comments/6h6ao0/n_numpy_receives_first_ever_funding_thanks_to/,pp314159,1497430608,,46,698
537,2017-6-14,2017,6,14,18,6h6edt,What should I choose hierarchical agglomerative clustering or K-means?,https://www.reddit.com/r/MachineLearning/comments/6h6edt/what_should_i_choose_hierarchical_agglomerative/,justanotherintern_,1497432308,[removed],0,1
538,2017-6-14,2017,6,14,21,6h757y,[D] Multi-label image classification for training from large tagged dataset?,https://www.reddit.com/r/MachineLearning/comments/6h757y/d_multilabel_image_classification_for_training/,metrio,1497443048,"I'm looking into the feasibility of training an image classifier network. I have access to a dataset with somewhere around 1.1 million images, all of them hand-tagged; I can get the tags in JSON or XML.  

Is there a modern CNN project available that would take these images as a drop-in training source, and be useful for suggesting tags for future images?",3,2
539,2017-6-14,2017,6,14,21,6h75h2,[D] (Random Question) - Why has Matlab/Octave not been embraced by the Machine Learning community?,https://www.reddit.com/r/MachineLearning/comments/6h75h2/d_random_question_why_has_matlaboctave_not_been/,disco42,1497443126,I could be wrong but as an Octave user (indoctrinated with Matlab in uni) I get the impression that this language isn't commonly used in Machine Learning. I'm curious if there is a strong reason why the capabilities of Matlab/Octave hasn't lent itself to being a go to Machine Learning tool? Is it as simple as Matlab's proprietary model can't keep up and Octave is too immature to compete with the likes of Python?,47,7
540,2017-6-14,2017,6,14,22,6h7hrv,[D] Reducing Exposure Bias in Sequence Generation Via Differentiable Scheduled Sampling,https://www.reddit.com/r/MachineLearning/comments/6h7hrv/d_reducing_exposure_bias_in_sequence_generation/,nickshahml,1497447014,"Hey Guys,

A while back, the scheduled sampling [paper](https://arxiv.org/abs/1506.03099) was released. They showed how you could sample from the previous timestep t, feed that sample back into the embedding, and train the network on the next timestep t+1.

This limits exposure bias because you are training the network parts of its own generated sequence. They show that its best to do this in a curriculum learning fashion. 

The problem with this approach is that the sampling step is non-differentiable, and so the network has no way of knowing what caused it's input on timestep t+1. In reality, it was network's action on the previous timestep that caused this input.

To circumvent this problem, I wanted to run this proposal by you guys. Instead of sampling from the softmax distribution, you take the entire softmax distribution and multiply it by the embedding and apply reduce_sum:

    next_input_vector = reduce_sum(softmax_distribution * embedding)

In this way, the next input_vector is fully differentiable and weights the word embedding that the softmax distribution favors. You would still apply this in curriculum learning approach. Has anyone tried this/what are your thoughts?

",2,0
541,2017-6-14,2017,6,14,22,6h7irn,"Amazon Jeff Bezos on Artificial Intelligence(AI), Cashless Store, Self-Driving Cars and Donald Trump",https://www.reddit.com/r/MachineLearning/comments/6h7irn/amazon_jeff_bezos_on_artificial_intelligenceai/,scidem,1497447302,,0,1
542,2017-6-14,2017,6,14,23,6h7pjr,[R] Stylometric Analysis in Identifying Authorship,https://www.reddit.com/r/MachineLearning/comments/6h7pjr/r_stylometric_analysis_in_identifying_authorship/,vultrun,1497449257,,2,26
543,2017-6-14,2017,6,14,23,6h7rea,What should be the optimum number of for 10 million observations for kmeans clustering?,https://www.reddit.com/r/MachineLearning/comments/6h7rea/what_should_be_the_optimum_number_of_for_10/,rahul-01,1497449763,[removed],0,1
544,2017-6-15,2017,6,15,0,6h83w8,[N] Divide and conquer: Microsoft researchers master Ms. Pac-Man,https://www.reddit.com/r/MachineLearning/comments/6h83w8/n_divide_and_conquer_microsoft_researchers_master/,juharris,1497453137,,29,31
545,2017-6-15,2017,6,15,0,6h8e6a,"Simple Questions Thread June 14, 2017",https://www.reddit.com/r/MachineLearning/comments/6h8e6a/simple_questions_thread_june_14_2017/,AutoModerator,1497455736,[removed],0,1
546,2017-6-15,2017,6,15,1,6h8fud,[P] Playing a toy poker game with Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/6h8fud/p_playing_a_toy_poker_game_with_reinforcement/,ipullguard,1497456152,,0,1
547,2017-6-15,2017,6,15,1,6h8ha7,Non-chain Markov networks and CRF's in Infer.NET,https://www.reddit.com/r/MachineLearning/comments/6h8ha7/nonchain_markov_networks_and_crfs_in_infernet/,utkarshdvd,1497456497,[removed],0,1
548,2017-6-15,2017,6,15,1,6h8k33,"Guide to working in artificial intelligence policy and strategy - 80,000 Hours",https://www.reddit.com/r/MachineLearning/comments/6h8k33/guide_to_working_in_artificial_intelligence/,komencanto,1497457203,,0,1
549,2017-6-15,2017,6,15,1,6h8prj,General Game Playing with Schema Networks &lt;-- Vicarious takes on DeepMind,https://www.reddit.com/r/MachineLearning/comments/6h8prj/general_game_playing_with_schema_networks/,[deleted],1497458652,[deleted],0,1
550,2017-6-15,2017,6,15,1,6h8q4z,[R] General Game Playing with Schema Networks &lt;-- zero-shot RL generalization,https://www.reddit.com/r/MachineLearning/comments/6h8q4z/r_general_game_playing_with_schema_networks/,evc123,1497458752,,23,45
551,2017-6-15,2017,6,15,2,6h8vr9,Online Rest API for a CNN?,https://www.reddit.com/r/MachineLearning/comments/6h8vr9/online_rest_api_for_a_cnn/,tmsbn,1497460146,[removed],0,1
552,2017-6-15,2017,6,15,2,6h90lu,Is it good or bad to add data that might confuse your bot?,https://www.reddit.com/r/MachineLearning/comments/6h90lu/is_it_good_or_bad_to_add_data_that_might_confuse/,[deleted],1497461332,[removed],0,1
553,2017-6-15,2017,6,15,2,6h91xb,How do I approach this problem with machine learning?,https://www.reddit.com/r/MachineLearning/comments/6h91xb/how_do_i_approach_this_problem_with_machine/,Ravenclaw968,1497461653,[removed],0,1
554,2017-6-15,2017,6,15,2,6h93fd,Created a dataset for 1M near real-time stock market feed. Any idea for improvement or addition will help.,https://www.reddit.com/r/MachineLearning/comments/6h93fd/created_a_dataset_for_1m_near_realtime_stock/,[deleted],1497462024,[deleted],0,1
555,2017-6-15,2017,6,15,2,6h970x,[P] Created a dataset for 1M near real-time stock market feed. Any idea for improvement or addition will help.,https://www.reddit.com/r/MachineLearning/comments/6h970x/p_created_a_dataset_for_1m_near_realtime_stock/,[deleted],1497462898,,5,23
556,2017-6-15,2017,6,15,3,6h99l3,[D] State of Bayesian MCMC for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6h99l3/d_state_of_bayesian_mcmc_for_deep_learning/,bsn_nn,1497463531,"What is the state of Bayesian MCMC sampling for deep learning models? I've skimmed a few papers that apply hamiltonian monte carlo to estimate neural networks, but the ones that I've found seem to only apply HMC to small fully connected networks (e.g. in https://arxiv.org/pdf/1402.4102.pdf). Has anyone tried applying MCMC to CNNs with max-pooling and convolutional layers, e.g. on LeNet? Are there extra challenges to trying to apply MCMC to CNNs rather than fully connected NNs? I'm interested in this field (although I'm not an expert in either MCMC or DL) and wonder if anyone has a good summary of what's been done so far.",8,11
557,2017-6-15,2017,6,15,3,6h9aws,[D] Natural Language Database Interfaces: Natural language to SQL query Translation,https://www.reddit.com/r/MachineLearning/comments/6h9aws/d_natural_language_database_interfaces_natural/,shubham_ai,1497463861,"/r/MachineLarning , /r/LanguageTechnology - What model(s) have demonstrated good performance for english to SQL query translation?

Recent papers [ https://arxiv.org/abs/1703.10692 , http://www.vldb.org/pvldb/vol8/p73-li.pdf ], have mostly focused on rule based, grammar construction approaches... However, they have been focused on specific DBs and/or use user interaction.
There seem to be a dearth of good general models for a relatively old problem:

Does anyone know of good approaches/model ideas that have resulted in 'good' accuracy ? Any interesting papers on  the topic that is worth looking at ?
Links to available tools/libraries ?

Ideas, high-level approaches more than welcome ? :) 
Any help is appreciated. Thanks.",1,3
558,2017-6-15,2017,6,15,4,6h9ohr,[Discussion] Who does electronics and ML?,https://www.reddit.com/r/MachineLearning/comments/6h9ohr/discussion_who_does_electronics_and_ml/,fimari,1497467214,I'm searching for papers and people who are interested in PCB design supported by ML and I want to know if someone already tried to make an Autorouter based on neuronal networks and how it went.,5,8
559,2017-6-15,2017,6,15,4,6h9wy4,[R] Reinforcement learning for negotiation,https://www.reddit.com/r/MachineLearning/comments/6h9wy4/r_reinforcement_learning_for_negotiation/,hoaphumanoid,1497469364,,2,13
560,2017-6-15,2017,6,15,5,6ha6bg,"PickedMail, the first Inbox with personal AI! As you pick and unpick emails, your personal AI learns and adapts, eventually saving your time!",https://www.reddit.com/r/MachineLearning/comments/6ha6bg/pickedmail_the_first_inbox_with_personal_ai_as/,kddevelop,1497471744,,0,1
561,2017-6-15,2017,6,15,6,6hajia,Zero-shot translation from Google,https://www.reddit.com/r/MachineLearning/comments/6hajia/zeroshot_translation_from_google/,youngmadeof,1497475182,,0,1
562,2017-6-15,2017,6,15,6,6hakyl,"[P] A DJ Khaled themed object recognizer app using inception v3, iOS CoreML and Vision",https://www.reddit.com/r/MachineLearning/comments/6hakyl/p_a_dj_khaled_themed_object_recognizer_app_using/,polar_bare,1497475579,,1,0
563,2017-6-15,2017,6,15,6,6haowu,[D]: Understanding the definition of the problem depth in Deep Learning in Neural Networks: An Overview,https://www.reddit.com/r/MachineLearning/comments/6haowu/d_understanding_the_definition_of_the_problem/,ambodi,1497476656,"I am reading [Schmihubbers Deep Learning in Neural Networks: An Overview paper](https://arxiv.org/pdf/1404.7828.pdf) and I am failing to understand a definition. In page 6, he writes:

Suppose an episode and its event sequence (x1, . . . , xT) satisfy a computable criterion used to decide whether a given problem has been solved (e.g., total error E below some threshold). Then the set of used weights is called a solution to the problem, and the depth of the deepest CAP within the sequence is called the solution depth. There may be other solutions (yielding different event sequences) with different depths. Given some fixed NN topology, the smallest depth of any solution is called the problem depth. 
I tried to Google but I failed. This becomes crucial in the next page, where he argues that:

the problems of depth &gt; 10 will require very Deep Learning.

What does he mean by solution depth? 
",5,10
564,2017-6-15,2017,6,15,6,6hapho,Predictive Maintenance,https://www.reddit.com/r/MachineLearning/comments/6hapho/predictive_maintenance/,machiben,1497476803,[removed],0,1
565,2017-6-15,2017,6,15,6,6harvx,Can Machine Learn the Concept of Sine,https://www.reddit.com/r/MachineLearning/comments/6harvx/can_machine_learn_the_concept_of_sine/,yingxie3,1497477460,,0,1
566,2017-6-15,2017,6,15,7,6hatgz,Free Webinar Tomorrow: Machine Learning for Quantitative Finance using Python,https://www.reddit.com/r/MachineLearning/comments/6hatgz/free_webinar_tomorrow_machine_learning_for/,bestquant,1497477905,,0,1
567,2017-6-15,2017,6,15,7,6hatod,Using Machine Learning to create marketing segments,https://www.reddit.com/r/MachineLearning/comments/6hatod/using_machine_learning_to_create_marketing/,ggrant95,1497477956,[removed],0,1
568,2017-6-15,2017,6,15,8,6hb6r3,[R] [1706.03907] Deep Control - Replaces BatchNorm in ConvNets!,https://www.reddit.com/r/MachineLearning/comments/6hb6r3/r_170603907_deep_control_replaces_batchnorm_in/,darkconfidantislife,1497481622,,6,0
569,2017-6-15,2017,6,15,8,6hbc5p,Atari Learning Environment State-fuzzing,https://www.reddit.com/r/MachineLearning/comments/6hbc5p/atari_learning_environment_statefuzzing/,bobbyricky1,1497483239,[removed],0,1
570,2017-6-15,2017,6,15,8,6hbci1,Google releases pre-trained mobilenet models,https://www.reddit.com/r/MachineLearning/comments/6hbci1/google_releases_pretrained_mobilenet_models/,[deleted],1497483334,[deleted],0,1
571,2017-6-15,2017,6,15,8,6hbcy4,[R] CortexNet: a robust predictive deep neural network trained on videos,https://www.reddit.com/r/MachineLearning/comments/6hbcy4/r_cortexnet_a_robust_predictive_deep_neural/,pmigdal,1497483466,,11,17
572,2017-6-15,2017,6,15,9,6hbiu3,[D] Choosing a good learning rate,https://www.reddit.com/r/MachineLearning/comments/6hbiu3/d_choosing_a_good_learning_rate/,[deleted],1497485241,[deleted],15,3
573,2017-6-15,2017,6,15,9,6hblko,[N] Google releases imagenet pre-trained mobilenet (faster/more-accurate than alexnet) models,https://www.reddit.com/r/MachineLearning/comments/6hblko/n_google_releases_imagenet_pretrained_mobilenet/,[deleted],1497486031,[deleted],13,83
574,2017-6-15,2017,6,15,11,6hc8tg,[R] Automatically categorizing reddit submission into appropriate sub-reddit using Title text and Tensorflow,https://www.reddit.com/r/MachineLearning/comments/6hc8tg/r_automatically_categorizing_reddit_submission/,breakupnoob,1497493565,"After completing the online ML course and trying my hands on the some basic programs, I'm trying to get started on a real project now.

So just for fun I was wondering if it is possible to create a program that can automatically categorize any reddit submission (without looking at the sub-reddit) to appropriate sub-reddit.

One way I think to do it would be to download 50K submissions from 10 popular subreddits, then split each title using the nltk.tokenize and ntlk.stem and train my model. The labels would the sub-reddit to which the submission belongs.

I'll be using [this tutorial](https://www.youtube.com/watch?v=JeamFbHhmDo&amp;list=PLSPWNkAMSvv5DKeSVDbEbUKSsK4Z-GgiP&amp;index=8) as my guide to do it.

Please let me know if what you think about this project. Is my approach any good or is there a better way to do it?

**Update:** The first version is ready and working now! [Please see here](https://www.reddit.com/r/learnmachinelearning/comments/6hqd6o/p_automatic_reddit_categorizer_update_first/)",13,11
575,2017-6-15,2017,6,15,11,6hca5x,Hanging type shot blasting machine with wet type dust collector,https://www.reddit.com/r/MachineLearning/comments/6hca5x/hanging_type_shot_blasting_machine_with_wet_type/,Shot-blasting,1497494002,,1,1
576,2017-6-15,2017,6,15,12,6hcer9,Hanger Type Shot Blasting Machine Manufacturers,https://www.reddit.com/r/MachineLearning/comments/6hcer9/hanger_type_shot_blasting_machine_manufacturers/,Shot-blasting,1497495628,,1,1
577,2017-6-15,2017,6,15,12,6hclpw,Plug and Play Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/6hclpw/plug_and_play_machine_learning/,JacFlasche,1497498065,[removed],0,1
578,2017-6-15,2017,6,15,13,6hcx9f,SEARNN: Training RNNs with Global-Local Losses,https://www.reddit.com/r/MachineLearning/comments/6hcx9f/searnn_training_rnns_with_globallocal_losses/,weizier,1497502360,,0,1
579,2017-6-15,2017,6,15,14,6hczyk,[P] Neural Net Machine Learning Project (Java),https://www.reddit.com/r/MachineLearning/comments/6hczyk/p_neural_net_machine_learning_project_java/,Taffo,1497503425,"Hi Everyone! 

I recently just got into Machine Learning and decided to make my own Neural Net class (and also convolution neural net class, but that isn't quite done yet) in Java just to experiment with ML and see what I could do.  For me, it was a fun opportunity to learn more about Neural nets and try to figure out how they work.  As I was reading ML articles, it always felt like they glossed over how to do batch processing and it felt like even fewer articles described how to calculate the gradient in a batch learning model in a way that was understandable for someone who hasn't studied this area before.  Since it seemed like there weren't a ton of concrete examples from my searches, I thought maybe I'd post this here in case anyone else was curious.  I know I still have stuff to do on my project, but I'd appreciate any thoughts / constructive criticism on what could be done better / or ideas on what to do next!

This is my github of my NN if anyone would like to take a look:
https://github.com/darbyk/NeuralNet",11,1
580,2017-6-15,2017,6,15,14,6hd3ef,The effect of Batch Normalization layer in auto-encoder?,https://www.reddit.com/r/MachineLearning/comments/6hd3ef/the_effect_of_batch_normalization_layer_in/,xjwxjw,1497504770,[removed],0,1
581,2017-6-15,2017,6,15,15,6hd8pf,Reinforcement learning via XBox Games? Control the controller?,https://www.reddit.com/r/MachineLearning/comments/6hd8pf/reinforcement_learning_via_xbox_games_control_the/,stridera,1497506966,[removed],0,1
582,2017-6-15,2017,6,15,15,6hdbll,How about the resins blender for industrial designs?,https://www.reddit.com/r/MachineLearning/comments/6hdbll/how_about_the_resins_blender_for_industrial/,JCT_MACHINE,1497508223,,0,1
583,2017-6-15,2017,6,15,17,6hdqru,Using Cluster Analysis for Comprehensive Threat Detection,https://www.reddit.com/r/MachineLearning/comments/6hdqru/using_cluster_analysis_for_comprehensive_threat/,Cytegic_Nobot,1497515305,,0,1
584,2017-6-15,2017,6,15,18,6hdy5y,Machine Learning  A Buzzword in The Tech World!,https://www.reddit.com/r/MachineLearning/comments/6hdy5y/machine_learning_a_buzzword_in_the_tech_world/,TVSNext1,1497518861,,0,1
585,2017-6-15,2017,6,15,18,6he159,"[P]Keras implementation of ""A simple neural network module for relational reasoning"", beats SOTA on Cornell NLVR",https://www.reddit.com/r/MachineLearning/comments/6he159/pkeras_implementation_of_a_simple_neural_network/,phreeza,1497520233,,12,120
586,2017-6-15,2017,6,15,20,6hecqx,VIDEO PROOF! Pharmaceutical Companies Going BANKRUPT Because Of Supplement That Changes The Blood,https://www.reddit.com/r/MachineLearning/comments/6hecqx/video_proof_pharmaceutical_companies_going/,cameronbaltripu,1497525247,,0,1
587,2017-6-15,2017,6,15,20,6hedp2,[D] Best second language after Python for ML purposes,https://www.reddit.com/r/MachineLearning/comments/6hedp2/d_best_second_language_after_python_for_ml/,Laser_Plasma,1497525638,"I'm fairly comfortable with Python and I've been wanting to learn another language, and I've been wondering what language would be the best choice if my main interest is in machine learning/AI.",28,10
588,2017-6-15,2017,6,15,22,6hewcy,Machine Learning Jobs Profile and Salary Analysis,https://www.reddit.com/r/MachineLearning/comments/6hewcy/machine_learning_jobs_profile_and_salary_analysis/,pinterview1111,1497532199,,0,1
589,2017-6-15,2017,6,15,22,6hezy8,Riding the Wave of Machine Learning and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6hezy8/riding_the_wave_of_machine_learning_and_deep/,marlysdinger,1497533330,,0,1
590,2017-6-15,2017,6,15,22,6hf0ce,Mapping Dengue Fever Hazard with Machine Learning - Eos,https://www.reddit.com/r/MachineLearning/comments/6hf0ce/mapping_dengue_fever_hazard_with_machine_learning/,johnnaderryberry,1497533460,,0,1
591,2017-6-15,2017,6,15,22,6hf0o9,How Machine Learning Plus Predictive Analysis Boosts Business Performance - Environmental Leader,https://www.reddit.com/r/MachineLearning/comments/6hf0o9/how_machine_learning_plus_predictive_analysis/,aurademars,1497533555,,0,1
592,2017-6-15,2017,6,15,22,6hf0zi,How Machine Learning Can Drive Retail Sales  NewCo Shift,https://www.reddit.com/r/MachineLearning/comments/6hf0zi/how_machine_learning_can_drive_retail_sales_newco/,laverndeel,1497533664,,0,1
593,2017-6-15,2017,6,15,22,6hf13a,Sentiment analysis of Twitter tweets,https://www.reddit.com/r/MachineLearning/comments/6hf13a/sentiment_analysis_of_twitter_tweets/,[deleted],1497533701,[removed],0,1
594,2017-6-15,2017,6,15,22,6hf408,[D] Sentiment analysis of Twitter tweets,https://www.reddit.com/r/MachineLearning/comments/6hf408/d_sentiment_analysis_of_twitter_tweets/,OleWedel,1497534548,"What are some good papers on getting started with sentiment analysis of Twitter tweets? I would like to get an understanding of how to classify people's reaction to a tweet.

The idea is to follow tweets from organisations on Twitter. This way the initial tweets are at least coherent. They tweet something and I want to know: are people reacting positively, negatively or indifferent to it/spam/asking questions/etc? To do that I am thinking of doing sentiment analysis of the replies to that tweet.

So for example we have this initial [tweet](https://twitter.com/Twitter/status/875337970953224197). We can gather it is something about a new look from that (what part of Natural Language Processing is this called? PoS? NER? Can [SyntaxNet](https://research.googleblog.com/2017/03/an-upgrade-to-syntaxnet-new-models-and.html) be used?). Then I want to get an overall feel for the tweet. Are people reacting positively, negatively or indifferent/neutral/asking questions? How would one go about that and what are recommended papers to read regarding this?

Would it cost much to use Mechanical Turk to do the labelling? I could imagine it would be a requirement to have a lot of labelled tweets for it to work.

Also: could the same techniques easily be applied to Reddit submissions and comments you think?",8,21
595,2017-6-15,2017,6,15,23,6hf7pj,Make Pharma Great Again with Artificial Intelligence: some Challenges,https://www.reddit.com/r/MachineLearning/comments/6hf7pj/make_pharma_great_again_with_artificial/,mostafabenh,1497535663,,0,1
596,2017-6-16,2017,6,16,0,6hfjnw,15 working examples to get you started with Deep Learning without learning any of the math.,https://www.reddit.com/r/MachineLearning/comments/6hfjnw/15_working_examples_to_get_you_started_with_deep/,[deleted],1497538926,[deleted],0,1
597,2017-6-16,2017,6,16,0,6hfm8n,The Terrible Deep Learning List,https://www.reddit.com/r/MachineLearning/comments/6hfm8n/the_terrible_deep_learning_list/,[deleted],1497539585,[deleted],3,6
598,2017-6-16,2017,6,16,0,6hfmwj,"[N] A quick overview of Deep Learning on smartphones, putting recent Google MobileNet pre-trained models and Apple Core ML in context",https://www.reddit.com/r/MachineLearning/comments/6hfmwj/n_a_quick_overview_of_deep_learning_on/,[deleted],1497539745,[deleted],0,1
599,2017-6-16,2017,6,16,1,6hg2wl,A new easy-to-use open source project which contains tutorials on how to implement different models using TensorFLow.,https://www.reddit.com/r/MachineLearning/comments/6hg2wl/a_new_easytouse_open_source_project_which/,irsina,1497543902,,0,1
600,2017-6-16,2017,6,16,1,6hg5pf,DeepMind Research  Kinetics | DeepMind,https://www.reddit.com/r/MachineLearning/comments/6hg5pf/deepmind_research_kinetics_deepmind/,sanosukesagara,1497544575,,0,1
601,2017-6-16,2017,6,16,2,6hgcxu,Is there a consensus on what resources a beginner should reach out to when starting down this path?,https://www.reddit.com/r/MachineLearning/comments/6hgcxu/is_there_a_consensus_on_what_resources_a_beginner/,rjpj1998,1497546353,[removed],0,1
602,2017-6-16,2017,6,16,2,6hghgs,Multidimensional Even Split (Opposite of clustering)?,https://www.reddit.com/r/MachineLearning/comments/6hghgs/multidimensional_even_split_opposite_of_clustering/,isolar89,1497547469,[removed],0,1
603,2017-6-16,2017,6,16,2,6hgl7v,Sorting 2 Metric Tons of Lego,https://www.reddit.com/r/MachineLearning/comments/6hgl7v/sorting_2_metric_tons_of_lego/,[deleted],1497548380,[deleted],1,1
604,2017-6-16,2017,6,16,2,6hglmg,Sorting 2 Tons of Lego with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6hglmg/sorting_2_tons_of_lego_with_machine_learning/,alexeyr,1497548493,,1,1
605,2017-6-16,2017,6,16,3,6hgqs9,A man needs some help.,https://www.reddit.com/r/MachineLearning/comments/6hgqs9/a_man_needs_some_help/,deathma5tery,1497549781,[removed],0,1
606,2017-6-16,2017,6,16,3,6hgqv5,Supercharge your Computer Vision models with the TensorFlow Object Detection API,https://www.reddit.com/r/MachineLearning/comments/6hgqv5/supercharge_your_computer_vision_models_with_the/,phoenixinter,1497549804,,0,3
607,2017-6-16,2017,6,16,3,6hgy5f,Query regarding training of simple character level rnn,https://www.reddit.com/r/MachineLearning/comments/6hgy5f/query_regarding_training_of_simple_character/,saurabhvyas3,1497551634,"In character level rnn we have a sequence of characters , say three , for example oil and we predict the next character for example y as in oily , I am not able to understand why we would require the same number  of outputs as inputs that is 3 , why cant we have just one output denoting softmax probability / or any other probability of next character based on the input sequence , Also how would a training set of a character level rnn look like ? 

If i have text like "" this is a line "" , and if I want rnn window window of 2 will training set need to be of following form ?
x   |   y
1. th  |  hi
2. hi  | is

I am just a newbie trying to learn :) ",0,1
608,2017-6-16,2017,6,16,4,6hh9af,[D] implementation of cramer-GAN for celebA,https://www.reddit.com/r/MachineLearning/comments/6hh9af/d_implementation_of_cramergan_for_celeba/,anonDogeLover,1497554356,Does anyone know of a implementation of this that's ready for celebA or any 64x64 image dataset? I've already seen the jiamings code,1,3
609,2017-6-16,2017,6,16,4,6hhicy,machine learning on a stream of video games,https://www.reddit.com/r/MachineLearning/comments/6hhicy/machine_learning_on_a_stream_of_video_games/,cantdutchthis,1497556638,,0,1
610,2017-6-16,2017,6,16,5,6hhm9o,[D] Where can I find the best software today for enlarging photos?,https://www.reddit.com/r/MachineLearning/comments/6hhm9o/d_where_can_i_find_the_best_software_today_for/,mrconter1,1497557623,[removed],0,1
611,2017-6-16,2017,6,16,6,6hi5a4,[R] [1706.04223] Adversarially Regularized Autoencoders for Generating Discrete Structures,https://www.reddit.com/r/MachineLearning/comments/6hi5a4/r_170604223_adversarially_regularized/,evc123,1497562537,,29,13
612,2017-6-16,2017,6,16,6,6hi6vj,Feature Ranking/Selection  Optimal number,https://www.reddit.com/r/MachineLearning/comments/6hi6vj/feature_rankingselection_optimal_number/,ThibaudMIE,1497562972,[removed],0,1
613,2017-6-16,2017,6,16,6,6hi7j3,10 buzzwords to know about neural networks,https://www.reddit.com/r/MachineLearning/comments/6hi7j3/10_buzzwords_to_know_about_neural_networks/,[deleted],1497563161,[deleted],0,1
614,2017-6-16,2017,6,16,7,6hijgz,TensorFlow 1.2.0 is out!,https://www.reddit.com/r/MachineLearning/comments/6hijgz/tensorflow_120_is_out/,sbt_,1497566567,,0,1
615,2017-6-16,2017,6,16,7,6hikd6,Engineering Extreme Event Forecasting at Uber with RNNs,https://www.reddit.com/r/MachineLearning/comments/6hikd6/engineering_extreme_event_forecasting_at_uber/,satsatsat,1497566813,,0,1
616,2017-6-16,2017,6,16,8,6hirmq,[R] Introducing source-contrastive estimation,https://www.reddit.com/r/MachineLearning/comments/6hirmq/r_introducing_sourcecontrastive_estimation/,amplifier_khan,1497568970,,0,2
617,2017-6-16,2017,6,16,8,6hisam,Tensorflow 1.2 Released,https://www.reddit.com/r/MachineLearning/comments/6hisam/tensorflow_12_released/,[deleted],1497569198,[deleted],2,10
618,2017-6-16,2017,6,16,9,6hj327,[R] FreezeOut: Accelerate training by up to 20% by progressively freezing layers. Based on a reddit comment and a subsequent 96 hour science binge.,https://www.reddit.com/r/MachineLearning/comments/6hj327/r_freezeout_accelerate_training_by_up_to_20_by/,ajmooch,1497572520,,88,237
619,2017-6-16,2017,6,16,9,6hj68v,"[R] PyTorch Implementation of ""Principled Detection of Out-of-Distribution Examples in Neural Networks"" (UIUC, Cornell)",https://www.reddit.com/r/MachineLearning/comments/6hj68v/r_pytorch_implementation_of_principled_detection/,howdygoop,1497573358,,0,14
620,2017-6-16,2017,6,16,9,6hj8ht,[N] Supercharge your Computer Vision models with the TensorFlow Object Detection API,https://www.reddit.com/r/MachineLearning/comments/6hj8ht/n_supercharge_your_computer_vision_models_with/,[deleted],1497573902,[deleted],1,25
621,2017-6-16,2017,6,16,9,6hj8n9,[R] Learning Deep ResNet Blocks Sequentially using Boosting Theory,https://www.reddit.com/r/MachineLearning/comments/6hj8n9/r_learning_deep_resnet_blocks_sequentially_using/,xternalz,1497573937,,8,23
622,2017-6-16,2017,6,16,9,6hj9uq,Using neural networks to improve my paintings,https://www.reddit.com/r/MachineLearning/comments/6hj9uq/using_neural_networks_to_improve_my_paintings/,qrv3w,1497574216,,0,1
623,2017-6-16,2017,6,16,10,6hjfoe,[N] Tensorflow v1.2 Released,https://www.reddit.com/r/MachineLearning/comments/6hjfoe/n_tensorflow_v12_released/,ntenenz,1497576014,,15,74
624,2017-6-16,2017,6,16,10,6hjica,"[P]Chainer implementation of ""Attention Is All You Need""",https://www.reddit.com/r/MachineLearning/comments/6hjica/pchainer_implementation_of_attention_is_all_you/,sushiai,1497576898,"Hi, I'm working on implementing this paper, https://arxiv.org/pdf/1706.03762.pdf
Here's my code at this link: https://github.com/soskek/attention_is_all_you_need
These are the areas I'm still working on. Comments welcome!",3,13
625,2017-6-16,2017,6,16,10,6hjijp,[R] [1706.04638] Proximal Backpropagation,https://www.reddit.com/r/MachineLearning/comments/6hjijp/r_170604638_proximal_backpropagation/,SquirrelNine,1497576959,,1,12
626,2017-6-16,2017,6,16,10,6hjl5h,Deep Learning Promises to Bring Algorithmic Investing Smarts to the Rest of Us,https://www.reddit.com/r/MachineLearning/comments/6hjl5h/deep_learning_promises_to_bring_algorithmic/,bcaulfield,1497577833,,0,1
627,2017-6-16,2017,6,16,10,6hjlk4,[D] How does licensing work with regards to model architectures and other specific solutions/ideas in publicly-available research papers (arxiv)?,https://www.reddit.com/r/MachineLearning/comments/6hjlk4/d_how_does_licensing_work_with_regards_to_model/,pudjka,1497577973,Usually such information is not mentioned in the body of the text. Is it best (or even wise) to email the authors? Does the answer change if I were to attempt to ship a commercial product with an architecture that some team spent many hours working on?,5,6
628,2017-6-16,2017,6,16,10,6hjmbz,An Artificial Intelligence Developed Its Own Non-Human Language,https://www.reddit.com/r/MachineLearning/comments/6hjmbz/an_artificial_intelligence_developed_its_own/,dunkin1980,1497578238,,1,1
629,2017-6-16,2017,6,16,11,6hjoc4,[D] Medium is the new method! Has evaluation by image generation mislead researchers and driven GAN research off-track?,https://www.reddit.com/r/MachineLearning/comments/6hjoc4/d_medium_is_the_new_method_has_evaluation_by/,[deleted],1497578924,[deleted],9,18
630,2017-6-16,2017,6,16,11,6hjwlf,[P] Logical Poet,https://www.reddit.com/r/MachineLearning/comments/6hjwlf/p_logical_poet/,seominlee,1497581688,https://github.com/seominlee/Logical-Poet,14,0
631,2017-6-16,2017,6,16,12,6hk6ok,[D] Andrew Rowan - Bayesian Deep Learning with Edward (and a trick using Dropout),https://www.reddit.com/r/MachineLearning/comments/6hk6ok/d_andrew_rowan_bayesian_deep_learning_with_edward/,_alphamaximus_,1497585276,,0,9
632,2017-6-16,2017,6,16,13,6hkca2,[Q] How to get confidence interval from RNN?,https://www.reddit.com/r/MachineLearning/comments/6hkca2/q_how_to_get_confidence_interval_from_rnn/,0b01,1497587315,,0,1
633,2017-6-16,2017,6,16,13,6hkcgz,[D] What Can't Deep Learning Do?,https://www.reddit.com/r/MachineLearning/comments/6hkcgz/d_what_cant_deep_learning_do/,visarga,1497587376,,21,13
634,2017-6-16,2017,6,16,13,6hkgh3,Machine learning build help,https://www.reddit.com/r/MachineLearning/comments/6hkgh3/machine_learning_build_help/,[deleted],1497588943,[removed],0,1
635,2017-6-16,2017,6,16,14,6hkkom,Machine Learning build help,https://www.reddit.com/r/MachineLearning/comments/6hkkom/machine_learning_build_help/,deepmachine,1497590587,[removed],1,1
636,2017-6-16,2017,6,16,14,6hkmae,The world's first protein database for Machine Learning and AI,https://www.reddit.com/r/MachineLearning/comments/6hkmae/the_worlds_first_protein_database_for_machine/,alpine_photo,1497591262,,1,1
637,2017-6-16,2017,6,16,14,6hkp0n,Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6hkp0n/shot_blasting_machine/,Shot-blasting,1497592408,,1,1
638,2017-6-16,2017,6,16,15,6hkscg,Interesting/unusual way of using machine learning to study microbial ecology,https://www.reddit.com/r/MachineLearning/comments/6hkscg/interestingunusual_way_of_using_machine_learning/,benlibb,1497593849,,0,5
639,2017-6-16,2017,6,16,16,6hl25y,Computers are starting to reason like humans (paper by Google DeepMind),https://www.reddit.com/r/MachineLearning/comments/6hl25y/computers_are_starting_to_reason_like_humans/,arunshangarsri,1497598170,,0,1
640,2017-6-16,2017,6,16,16,6hl5gp,My machine learning posts,https://www.reddit.com/r/MachineLearning/comments/6hl5gp/my_machine_learning_posts/,alketcecaj,1497599722,,0,1
641,2017-6-16,2017,6,16,17,6hlcpa,[P] Saliency detection with convolutional autoencoder,https://www.reddit.com/r/MachineLearning/comments/6hlcpa/p_saliency_detection_with_convolutional/,[deleted],1497603272,[deleted],1,6
642,2017-6-16,2017,6,16,18,6hle26,Deep Learning on Azure M60 GPU,https://www.reddit.com/r/MachineLearning/comments/6hle26/deep_learning_on_azure_m60_gpu/,ds_88,1497603842,[removed],0,1
643,2017-6-16,2017,6,16,18,6hlh68,Deep Learning Modell output always the same Values,https://www.reddit.com/r/MachineLearning/comments/6hlh68/deep_learning_modell_output_always_the_same_values/,Losspost,1497605261,[removed],0,1
644,2017-6-16,2017,6,16,19,6hlol0,Backpropagation - Implementing multilayer neural networks through backpropagation using Java,https://www.reddit.com/r/MachineLearning/comments/6hlol0/backpropagation_implementing_multilayer_neural/,Jasonnor,1497608600,,0,1
645,2017-6-16,2017,6,16,19,6hlqr1,[R] Sobolev Training for Neural Networks [DeepMind],https://www.reddit.com/r/MachineLearning/comments/6hlqr1/r_sobolev_training_for_neural_networks_deepmind/,asobolev,1497609504,,4,36
646,2017-6-16,2017,6,16,20,6hlyz0,[D]my algorithm can make sentences give words,https://www.reddit.com/r/MachineLearning/comments/6hlyz0/dmy_algorithm_can_make_sentences_give_words/,godspeed_china,1497612887,"I make an algorithm that takes biomedical words (&lt;13) and make a sentence for you by brute force searching. one interesting experience here :  
doctor patients pain is that the great poor a  
------------------------------orignal sentence score:	-1803  
1:	that the great doctor is a poor pain patients  
------------------------------solved sentence score:	-1646  
",5,0
647,2017-6-16,2017,6,16,20,6hlz73,Optimized half precision gemm assembly kernels on AMD Fiji for deep learning,https://www.reddit.com/r/MachineLearning/comments/6hlz73/optimized_half_precision_gemm_assembly_kernels_on/,hyln9,1497612984,,0,1
648,2017-6-16,2017,6,16,21,6hm9tq,Artificial Intelligence | Machine Learning as a Service,https://www.reddit.com/r/MachineLearning/comments/6hm9tq/artificial_intelligence_machine_learning_as_a/,NehaSharma17,1497616874,,0,1
649,2017-6-16,2017,6,16,22,6hmgw5,[N] Google Released MobileNets: Efficient Pre-Trained Tensorflow Computer Vision Models,https://www.reddit.com/r/MachineLearning/comments/6hmgw5/n_google_released_mobilenets_efficient_pretrained/,Dutchcheesehead,1497619181,,0,10
650,2017-6-16,2017,6,16,23,6hmpa4,"Why is there a part ""scaling"" in this algorithm ?",https://www.reddit.com/r/MachineLearning/comments/6hmpa4/why_is_there_a_part_scaling_in_this_algorithm/,mxj7,1497621711,[removed],0,1
651,2017-6-16,2017,6,16,23,6hmpk8,[D] will wolf,https://www.reddit.com/r/MachineLearning/comments/6hmpk8/d_will_wolf/,[deleted],1497621788,[deleted],0,1
652,2017-6-16,2017,6,16,23,6hmpop,Data Preprocessing for Tensorflow Resources?,https://www.reddit.com/r/MachineLearning/comments/6hmpop/data_preprocessing_for_tensorflow_resources/,eh1221,1497621823,[removed],0,1
653,2017-6-16,2017,6,16,23,6hmpsh,Intro - The Math of Intelligence (New 3 Month Machine Learning Course),https://www.reddit.com/r/MachineLearning/comments/6hmpsh/intro_the_math_of_intelligence_new_3_month/,funmaster11,1497621850,,0,1
654,2017-6-16,2017,6,16,23,6hmuon,[D] Random Effects Neural Networks in Edward and Keras,https://www.reddit.com/r/MachineLearning/comments/6hmuon/d_random_effects_neural_networks_in_edward_and/,_alphamaximus_,1497623254,,0,24
655,2017-6-16,2017,6,16,23,6hmyzx,Is the KDD'99 dataset a clean dataset? And are there any newer datasets out there for this kind of intrusion classification?,https://www.reddit.com/r/MachineLearning/comments/6hmyzx/is_the_kdd99_dataset_a_clean_dataset_and_are/,Venne1138,1497624446,[removed],0,1
656,2017-6-16,2017,6,16,23,6hn101,What is the best way to contain data?,https://www.reddit.com/r/MachineLearning/comments/6hn101/what_is_the_best_way_to_contain_data/,subpanda101,1497625038,[removed],0,1
657,2017-6-17,2017,6,17,0,6hn63g,How can I submit a library for the community? (Python),https://www.reddit.com/r/MachineLearning/comments/6hn63g/how_can_i_submit_a_library_for_the_community/,[deleted],1497626415,[removed],0,1
658,2017-6-17,2017,6,17,0,6hn6wg,[N] DeepMind Open Source: Datasets,https://www.reddit.com/r/MachineLearning/comments/6hn6wg/n_deepmind_open_source_datasets/,pp314159,1497626628,,6,171
659,2017-6-17,2017,6,17,0,6hn7fr,"Can I get everyone to hand write the English alphabet 5 different times capitalized, lowercase, and cursive and the numbers 0-9 5 different times Then PM me a screen shot. I'm trying to learn machine learning. My goal is to get something to identify letters and numbers.",https://www.reddit.com/r/MachineLearning/comments/6hn7fr/can_i_get_everyone_to_hand_write_the_english/,truckerslife,1497626776,[removed],0,1
660,2017-6-17,2017,6,17,0,6hncz3,[R] Variational Approaches for Auto-Encoding Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/6hncz3/r_variational_approaches_for_autoencoding/,pauljasek,1497628197,,2,0
661,2017-6-17,2017,6,17,0,6hnekd,Short Interview: Jrgen Schmidhuber on Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/6hnekd/short_interview_jrgen_schmidhuber_on_artificial/,svmmvs,1497628646,,0,1
662,2017-6-17,2017,6,17,2,6hnyvp,[R] Optimization of Tree Ensembles,https://www.reddit.com/r/MachineLearning/comments/6hnyvp/r_optimization_of_tree_ensembles/,vvmisic0,1497633806,,5,6
663,2017-6-17,2017,6,17,2,6ho4r0,[D] Looking for tools to automatically tag audio sample libraries,https://www.reddit.com/r/MachineLearning/comments/6ho4r0/d_looking_for_tools_to_automatically_tag_audio/,AnonymousChimpanzee,1497635289,"Hello. 
First of all, I'm not sure if this post fits the rules. I'm just going to go ahead.


I have a huge audio library with audio samples of drums I gathered over the years and am looking for a tool with which I can automatically sort these samples. It would be awesome if it could distinguish loops from samples of instruments such as

* Claps
* Drums
* Hi Hats  
etc...

And, if possible, categorize  the loops into categories like

* house / club
* drum and base
* rock  
etc...

Does anyone know such a tool? I've tried Aural Probe but found it to be very inaccurate. Thanks in advance!",2,4
664,2017-6-17,2017,6,17,3,6ho7ud,[R] Deal or No Deal? End-to-End Learning for Negotiation Dialogues,https://www.reddit.com/r/MachineLearning/comments/6ho7ud/r_deal_or_no_deal_endtoend_learning_for/,jivatman,1497636071,,7,11
665,2017-6-17,2017,6,17,3,6hoi6u,"[D] For those of you that work in industry and use machine learning, what ML algorithms do you use and what do you use them for?",https://www.reddit.com/r/MachineLearning/comments/6hoi6u/d_for_those_of_you_that_work_in_industry_and_use/,Gurung11,1497638750,,35,46
666,2017-6-17,2017,6,17,3,6hol0v,Data Science Engineer,https://www.reddit.com/r/MachineLearning/comments/6hol0v/data_science_engineer/,pradeepkb,1497639513,,0,1
667,2017-6-17,2017,6,17,4,6hom09,[P] LSTM Lookback Issues,https://www.reddit.com/r/MachineLearning/comments/6hom09/p_lstm_lookback_issues/,mannmiss,1497639764,"I'm having a little bit of trouble understanding how to set up LSTM properly. 

In particular I'm confused on its ability to carry information to future iterations - how does one set how long it carries information (i.e. when it forgets?). If I'm using time-series data and I only want it to carry information as far as the last five samples, how would that be done?",21,3
668,2017-6-17,2017,6,17,4,6hott2,[D] How does the neuron count of state-of-the-art networks compare with biological brains?,https://www.reddit.com/r/MachineLearning/comments/6hott2/d_how_does_the_neuron_count_of_stateoftheart/,[deleted],1497641834,[deleted],6,1
669,2017-6-17,2017,6,17,5,6hp472,TFLearn Multiple Inputs,https://www.reddit.com/r/MachineLearning/comments/6hp472/tflearn_multiple_inputs/,[deleted],1497644670,[removed],0,1
670,2017-6-17,2017,6,17,5,6hp6ae,Can i use GAN to generate useful text?,https://www.reddit.com/r/MachineLearning/comments/6hp6ae/can_i_use_gan_to_generate_useful_text/,BossangeloCad,1497645215,[removed],0,1
671,2017-6-17,2017,6,17,5,6hpazx,I need help using word2vec in anaconda.,https://www.reddit.com/r/MachineLearning/comments/6hpazx/i_need_help_using_word2vec_in_anaconda/,Eccentress69,1497646518,[removed],0,1
672,2017-6-17,2017,6,17,8,6hq7h5,Tensorflow transfer learning tutorial,https://www.reddit.com/r/MachineLearning/comments/6hq7h5/tensorflow_transfer_learning_tutorial/,__The_Coder__,1497656288,,5,6
673,2017-6-17,2017,6,17,10,6hqnk0,[D] RNN's equivalent to MNIST?,https://www.reddit.com/r/MachineLearning/comments/6hqnk0/d_rnns_equivalent_to_mnist/,david-gpu,1497661714,"When playing with some ideas for convnets you may first test them on a toy dataset like MNIST so that you can get a quick turnaround time.

Is there an equivalent dataset for recurrent neural networks? The ideal would be something that can be trained in, say, one hour or less on one GPU. Natural languages seem far too complex for this quick training.",14,22
674,2017-6-17,2017,6,17,10,6hqtiq,[D] Choosing the Right Deep-RL Algorithm,https://www.reddit.com/r/MachineLearning/comments/6hqtiq/d_choosing_the_right_deeprl_algorithm/,j_mcm,1497663714,"Hello!

So my background isn't in Deep-RL, however, I have a good grasp on the concepts and enough skill programming to either write my own or sufficiently modify someone else's implementation of the latest and greatest DeepRL paper. That being said, how do I sort through the torrent of new papers showing the latest and greatest approaches when looking for an algorithm to apply to my robotics problem? It all seems a bit overwhelming... There's ACER, there's NEC, there's DQN and all of its variants, and so on. I don't want to spend soo much time trying to put together implementations of all these papers when I'll undoubtedly have to spend a lot of time fine-tuning hyperparameters for the one approach I'll end up fielding. I have half a mind to just choose the simplest to implement and hope for the best, but if I try to publish my results (application of Deep RL algorithm to a real-world robot) will it look naive to have implemented a DQN variant as opposed to the latest DeepRL algorithm? ",6,6
675,2017-6-17,2017,6,17,11,6hqyz5,Where can we find the proper blender mechanical design in China?,https://www.reddit.com/r/MachineLearning/comments/6hqyz5/where_can_we_find_the_proper_blender_mechanical/,JCT_MACHINE,1497665650,,0,1
676,2017-6-17,2017,6,17,11,6hr1qp,S  IC xe Piaggio Fly,https://www.reddit.com/r/MachineLearning/comments/6hr1qp/s__ic_xe_piaggio_fly/,khuongson93,1497666689,,1,1
677,2017-6-17,2017,6,17,11,6hr1t1,How to learn academic machine learning?,https://www.reddit.com/r/MachineLearning/comments/6hr1t1/how_to_learn_academic_machine_learning/,[deleted],1497666708,[removed],0,1
678,2017-6-17,2017,6,17,12,6hrdbj,[D] PyData Tel Aviv Meetup: Amir Balaish | Attention Models,https://www.reddit.com/r/MachineLearning/comments/6hrdbj/d_pydata_tel_aviv_meetup_amir_balaish_attention/,_alphamaximus_,1497671238,,0,5
679,2017-6-17,2017,6,17,13,6hri6l,Bo Hnh - Bo Hnh Electrolux Ti H Ni,https://www.reddit.com/r/MachineLearning/comments/6hri6l/bo_hnh_bo_hnh_electrolux_ti_h_ni/,nhatrang123,1497673157,,0,1
680,2017-6-17,2017,6,17,14,6hrt5g,[P] Visually searching Craigslist for very specific car sub-models using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/6hrt5g/p_visually_searching_craigslist_for_very_specific/,23f34ef32,1497677893,"I retrained inception v3 on two classes of images. One image is of a steering wheel without two buttons, and the other class of images is of the same steering wheel, but with the two buttons on the right side. (This is how you visually differentiate cars that have a specific vehicle option package that I'm looking for.) After retraining inception v3 on this data set, which contains 200+ images per class, I get a ~96% test accuracy. The issue I'm running into is that *any new image that I ask it to recognize, which should score very low for both categories, is confidently scored as one of the image categories.*

For example, if I train it on the two types of steering wheels that are exactly the same except one category/type has two buttons on the right. After training has finished, if I show inception an image of some other random thing, like a horse, it confidently scores it as one of the steering wheel categories!

The current issue is that there is no way to get insight as to why this is happening. How can you visually tell that the model has correctly learned that the *real* difference between the two steering wheel categories is presence or absence of the the two buttons on the right? 

",29,2
681,2017-6-17,2017,6,17,14,6hrtov,[P] Low loss but large amount of false positives?,https://www.reddit.com/r/MachineLearning/comments/6hrtov/p_low_loss_but_large_amount_of_false_positives/,etcetc0,1497678132,"I'm trying to classify data into two classes and my loss is less than 0.01 under both MSE and BCE. 

This seems contradictory to me that my performance on the training set is still so low - the ratio of true positives to false positives is at least 1:5 even when sweeping the threshold. Does this behavior mean my net is still not learning?",13,4
682,2017-6-17,2017,6,17,14,6hru0u,Top Tech Algos of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6hru0u/top_tech_algos_of_machine_learning/,kishorereddyr,1497678286,,0,1
683,2017-6-17,2017,6,17,14,6hrvgz,[D] What smaller datasets do people use for POC for GANs?,https://www.reddit.com/r/MachineLearning/comments/6hrvgz/d_what_smaller_datasets_do_people_use_for_poc_for/,bbsome,1497678929,I mean I just want to try something if it will work at all. Since GANs are anyway quite unstable I was wondering what do people use for initial validation? MNIST or is there some other dataset which is usually used for smaller set of experiments. E.g. I'm looking for something where usually GANs do converge and which won't take more than a day to train.,12,5
684,2017-6-17,2017,6,17,14,6hrvoz,Impact of Machine Learning On Workplace Productivity,https://www.reddit.com/r/MachineLearning/comments/6hrvoz/impact_of_machine_learning_on_workplace/,aurosys,1497679024,,0,1
685,2017-6-17,2017,6,17,15,6hrzlz,Do you know of interactive tools suitable for a visual educative demo of machine learning to children (10-14yrs) ?,https://www.reddit.com/r/MachineLearning/comments/6hrzlz/do_you_know_of_interactive_tools_suitable_for_a/,SimulatedAnnealing,1497680910,[removed],0,1
686,2017-6-17,2017,6,17,16,6hs3xb,"[R] Using deep learning to generate dinosaurs, dinosaurs X 19th century engravings of fruit ",https://www.reddit.com/r/MachineLearning/comments/6hs3xb/r_using_deep_learning_to_generate_dinosaurs/,finallyifoundvalidUN,1497683046,,16,690
687,2017-6-17,2017,6,17,16,6hs5r4,What is press brake?,https://www.reddit.com/r/MachineLearning/comments/6hs5r4/what_is_press_brake/,ishane1112,1497684004,[removed],0,1
688,2017-6-17,2017,6,17,18,6hsic5,K-Means Clustering of Rideshare providers leads to better performance; how an Austin startup can compete with the giants using machine learning [includes Git repo],https://www.reddit.com/r/MachineLearning/comments/6hsic5/kmeans_clustering_of_rideshare_providers_leads_to/,jcpuf,1497690932,,0,1
689,2017-6-17,2017,6,17,18,6hsjpn,Google DeepMind's paper presents a way to bridge the gap between generative adversarial networks and variational auto-encoders,https://www.reddit.com/r/MachineLearning/comments/6hsjpn/google_deepminds_paper_presents_a_way_to_bridge/,arunshangarsri,1497691646,,0,1
690,2017-6-17,2017,6,17,18,6hsli5,How to preserve voices of beloved people (e.g. parents)?,https://www.reddit.com/r/MachineLearning/comments/6hsli5/how_to_preserve_voices_of_beloved_people_eg/,meta96,1497692625,[removed],0,1
691,2017-6-17,2017,6,17,19,6hsnb0,[R] Stochastic Training of Neural Networks via Successive Convex Approximations,https://www.reddit.com/r/MachineLearning/comments/6hsnb0/r_stochastic_training_of_neural_networks_via/,scardax88,1497693653,,11,15
692,2017-6-17,2017,6,17,19,6hso7g,[D] How do people come up with all these crazy deep learning architectures?,https://www.reddit.com/r/MachineLearning/comments/6hso7g/d_how_do_people_come_up_with_all_these_crazy_deep/,Reiinakano,1497694112,"For the past few days, I've been reading TensorFlow source codes for some of the latest DL architectures (e.g. Tacotron, Wavenet) and the more I understand and visualize the architecture, the less sense it makes intuitively. 

For vanilla RNNs/LSTMs and ConvNets, it's quite easy to grasp *why* they would work well on time-series/image data. Very simple and elegant. But for these SOTA neural networks, I can't imagine why putting all these pieces (BN, highway networks, residuals, etc) together in this seemingly random way would even work.

Is there some kind of procedure people follow to compose these Frankenstein networks? Or just keep adding more layers and random stuff and hope the loss converges?",44,123
693,2017-6-17,2017,6,17,20,6hsuz3,Can we classify types of skin disease with CNN?,https://www.reddit.com/r/MachineLearning/comments/6hsuz3/can_we_classify_types_of_skin_disease_with_cnn/,seungyounshin,1497697635,[removed],0,1
694,2017-6-17,2017,6,17,23,6htsus,"[D] What Differs Humans, Machines, and Aliens",https://www.reddit.com/r/MachineLearning/comments/6htsus/d_what_differs_humans_machines_and_aliens/,frangky,1497711264,,3,8
695,2017-6-18,2017,6,18,0,6htumx,[D] How to extract concept / topic from a text?,https://www.reddit.com/r/MachineLearning/comments/6htumx/d_how_to_extract_concept_topic_from_a_text/,Simon_Ger,1497711842,"Hi guys,
my experience in the field of NLP is very limited. I use IBM Watson at the moment to extract the topic of text snippets (more or less 5 sentences and / or bullet points). Does anybody know what algorithm IBM uses or how you would normally approach such a problem (with and without domain knowledge)?
So far i tried the RAKE algorithm but the results were not as good as the Watson ones.

Thanks a lot in advance!",4,0
696,2017-6-18,2017,6,18,0,6htyy1,Why can't we just train a neural network to just pick the best model for a given input for a problem?,https://www.reddit.com/r/MachineLearning/comments/6htyy1/why_cant_we_just_train_a_neural_network_to_just/,deathma5tery,1497713224,[removed],0,1
697,2017-6-18,2017,6,18,0,6hu2uv,[D] What unsolved problem keeps you up at night?,https://www.reddit.com/r/MachineLearning/comments/6hu2uv/d_what_unsolved_problem_keeps_you_up_at_night/,xristaforante,1497714436,"I know researchers here are wary of getting sniped, so I'm not expecting specific ideas. I'm thinking of the crazy 'dream' ideas that you may have that aren't very approachable right now. I think differing perspectives are incredibly important given how 'monotone' the ML field is with NNs (or at least this sub; I'm not much of an insider really).

So, what's lurking at the back of your mind?",84,66
698,2017-6-18,2017,6,18,1,6hucy2,"machine learning practitioners: what is your opinion of courses like these, https://www.udemy.com/deeplearning/learn/v4/t/lecture/6820144?start=0 , that focus exclusively on building ML models and getting ""intuition"" for them but without the math?",https://www.reddit.com/r/MachineLearning/comments/6hucy2/machine_learning_practitioners_what_is_your/,[deleted],1497717496,[removed],0,1
699,2017-6-18,2017,6,18,1,6hudf9,"[N] Feeding Word2vec with tens of billions of items, what could possibly go wrong?",https://www.reddit.com/r/MachineLearning/comments/6hudf9/n_feeding_word2vec_with_tens_of_billions_of_items/,Agagla,1497717627,,1,31
700,2017-6-18,2017,6,18,1,6huf43,"machine learning practitioners: what is your opinion of courses like these that focus exclusively on building ML models and getting ""intuition"" for them but without the math?",https://www.reddit.com/r/MachineLearning/comments/6huf43/machine_learning_practitioners_what_is_your/,[deleted],1497718114,,0,1
701,2017-6-18,2017,6,18,2,6huk96,Summary of Independently Controllable Features on ShortScience.org by Hugo Larochelle,https://www.reddit.com/r/MachineLearning/comments/6huk96/summary_of_independently_controllable_features_on/,ieee8023,1497719638,,0,1
702,2017-6-18,2017,6,18,2,6huq6m,ML Project Manager tools,https://www.reddit.com/r/MachineLearning/comments/6huq6m/ml_project_manager_tools/,mark-g-s,1497721413,[removed],0,1
703,2017-6-18,2017,6,18,3,6hv0lt,When does ICLR 2018 get announced?,https://www.reddit.com/r/MachineLearning/comments/6hv0lt/when_does_iclr_2018_get_announced/,jonathanjoel123,1497724520,[removed],0,1
704,2017-6-18,2017,6,18,5,6hvhzq,[P] LSTM - How are the inputs connected?,https://www.reddit.com/r/MachineLearning/comments/6hvhzq/p_lstm_how_are_the_inputs_connected/,etcetc0,1497729986,"In this image: http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png we can see some LSTM nodes.

I'm confused on what X(t-1), X, and X(t+1) are.  Is the neural network shaped like this: http://i.imgur.com/npbCL2K.png

If so, how is any sequence data preserved if the LSTM nodes are receiving a linear combination of the inputs?",8,1
705,2017-6-18,2017,6,18,5,6hvklv,What consumer grade GPU is best suited for ML applications?,https://www.reddit.com/r/MachineLearning/comments/6hvklv/what_consumer_grade_gpu_is_best_suited_for_ml/,[deleted],1497730867,[removed],0,1
706,2017-6-18,2017,6,18,7,6hw62n,[P]Code &amp; Data now available for Phase-Functioned Neural Networks for Character Control!,https://www.reddit.com/r/MachineLearning/comments/6hw62n/pcode_data_now_available_for_phasefunctioned/,undefdev,1497737534,,3,62
707,2017-6-18,2017,6,18,7,6hwb1h,Deep Learning with TensorFlow in Python,https://www.reddit.com/r/MachineLearning/comments/6hwb1h/deep_learning_with_tensorflow_in_python/,SandipanDeyUMBC,1497739064,,0,1
708,2017-6-18,2017,6,18,8,6hwlge,Infinite Central Continuous Computer (ICCC),https://www.reddit.com/r/MachineLearning/comments/6hwlge/infinite_central_continuous_computer_iccc/,GodofHeaven,1497742581,[removed],0,1
709,2017-6-18,2017,6,18,10,6hx1fa,What is the best way to use history related to each training example as a feature for model,https://www.reddit.com/r/MachineLearning/comments/6hx1fa/what_is_the_best_way_to_use_history_related_to/,[deleted],1497748314,[removed],0,1
710,2017-6-18,2017,6,18,10,6hx4sw,[D] What is the best way to use history related to each training example as a feature for model,https://www.reddit.com/r/MachineLearning/comments/6hx4sw/d_what_is_the_best_way_to_use_history_related_to/,seanpuppy,1497749585,"Lets say I am trying to predict how well a player will do in a game, and have some reasonable set of features for each player that can be used as training data and can use this to preform a reasonably well preforming model. But how can I extend off of this to factor in player/opponent relationships? Since these kind of relationships are a function of many past games, quantifying this relationship will start with a matrix of sorts, and it is not immediately obvious to me how best to capture the information in the matrix and use it as a feature with my existing trainig data (each row is a vector of floats)

My initial thoughts are to experiment with existing statistics for how a team does against players like a given player, or have some aggregation of past performance for the player, and an aggregation for the team. For example Batting average vs given team for given player. I feel like this has potential but would be very limited by my ability to make good assumptions.

One last potential approach I have thought of is to use an ensemble learning approach with a general model, a model for the specific player, and a model for the opposing team (and potentially other models). The training data for the ensemble model would be the output from the general model, and the outputs for the player + team specific models.

Is this ensemble approach at all viable? are any of the other approaches I've mentioned worth looking into? What other approaches are there to encapsulating this sort of additional but complex information into a model?
",0,2
711,2017-6-18,2017,6,18,10,6hx5xj,DQN implementation learned things first but then diverged,https://www.reddit.com/r/MachineLearning/comments/6hx5xj/dqn_implementation_learned_things_first_but_then/,eddlie,1497750014,[removed],0,1
712,2017-6-18,2017,6,18,11,6hxg9o,Independently Controllable Features - Bengio et al.,https://www.reddit.com/r/MachineLearning/comments/6hxg9o/independently_controllable_features_bengio_et_al/,manux,1497753973,,1,1
713,2017-6-18,2017,6,18,15,6hy853,"What is the current best way to smoothly ""style transfer"" every frame of a video?",https://www.reddit.com/r/MachineLearning/comments/6hy853/what_is_the_current_best_way_to_smoothly_style/,PM_ME_CUTE_PUPPYS,1497765763,[removed],0,1
714,2017-6-18,2017,6,18,17,6hyon1,[P] Indexing Faces on Instagram - Searching Facial Features on Instagram,https://www.reddit.com/r/MachineLearning/comments/6hyon1/p_indexing_faces_on_instagram_searching_facial/,kendrick__,1497774986,,44,234
715,2017-6-18,2017,6,18,20,6hz9z5,A good mathematically rigorous introduction to ML?,https://www.reddit.com/r/MachineLearning/comments/6hz9z5/a_good_mathematically_rigorous_introduction_to_ml/,[deleted],1497786808,[removed],0,1
716,2017-6-18,2017,6,18,22,6hzm6d,MXNet implementation of Self-normalizing networks,https://www.reddit.com/r/MachineLearning/comments/6hzm6d/mxnet_implementation_of_selfnormalizing_networks/,Ldpe2G,1497792206,,0,1
717,2017-6-18,2017,6,18,22,6hzn1c,Azure NV6 instance (M60 GPU) for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6hzn1c/azure_nv6_instance_m60_gpu_for_deep_learning/,ds_88,1497792545,[removed],0,1
718,2017-6-18,2017,6,18,23,6hzsni,[P] Azure NV6 (M60 GPU) for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6hzsni/p_azure_nv6_m60_gpu_for_deep_learning/,ds_88,1497794676,"For an upcoming project we will be experimenting with Deep Learning approaches for NLP in an Azure environment (Amazon and Local are not an option right now).

Azure offers NC6 (K80) and NV6 (M60) instances, but due to region restrictions it might be that only the M60 will be available. It seems like the M60 will be great for Deep Learning, but I saw this quote on their website which suggests it may not be the best choice:

""In addition to the NC-Series, focused on compute, the NV-Series is focused more on visualization""

Can anyone confirm that the M60 is appropriate for Deep Learning?",9,6
719,2017-6-18,2017,6,18,23,6i00vs,Machine Learning - Image Content Analysis,https://www.reddit.com/r/MachineLearning/comments/6i00vs/machine_learning_image_content_analysis/,[deleted],1497797533,[deleted],0,1
720,2017-6-18,2017,6,18,23,6i01yp,[P] A TensorFlow Implementation of the Transformer: Attention Is All You Need,https://www.reddit.com/r/MachineLearning/comments/6i01yp/p_a_tensorflow_implementation_of_the_transformer/,longinglove,1497797906,,1,41
721,2017-6-19,2017,6,19,0,6i04e7,Differentiable Neural Computer - implementation and thoughts,https://www.reddit.com/r/MachineLearning/comments/6i04e7/differentiable_neural_computer_implementation_and/,totallynotAGI,1497798707,"Hey guys,

[Here is](https://github.com/bgavran/DNC) my implementation of DeepMind's [Differentiable Neural Computer.](https://deepmind.com/blog/differentiable-neural-computers/)

I tested it on copy and bAbI tasks and I've put up some visualizations of the learning progress together with some of my thoughts and questions about it.

Some key points:

* DNC almost always seems to work better than LSTM
* Memory operations seem to open up the black box of deep learning a little bit
* It's slow to train and seems to be more unstable
* Seems to be able to take bigger advantage of curriculum learning

I welcome any sort of feedback!",30,63
722,2017-6-19,2017,6,19,0,6i06tg,Machine Learning Tutorial by Simple Source Code (from Coursera University of Stanford),https://www.reddit.com/r/MachineLearning/comments/6i06tg/machine_learning_tutorial_by_simple_source_code/,Hassankashi,1497799496,[removed],0,1
723,2017-6-19,2017,6,19,0,6i0aua,A Glance At Q-Learning - Data Science Festival 2017,https://www.reddit.com/r/MachineLearning/comments/6i0aua/a_glance_at_qlearning_data_science_festival_2017/,ADGEfficiency,1497800830,,0,1
724,2017-6-19,2017,6,19,1,6i0n67,Machine learning summer schools for 2017(US)?,https://www.reddit.com/r/MachineLearning/comments/6i0n67/machine_learning_summer_schools_for_2017us/,ratzpew,1497804657,[removed],0,1
725,2017-6-19,2017,6,19,2,6i0r2y,[D] I have questionnaire data with fixed questions and free text answers. What unsupervised techniques would you recommend to create a fixed feature space for each question?,https://www.reddit.com/r/MachineLearning/comments/6i0r2y/d_i_have_questionnaire_data_with_fixed_questions/,Quasimoto3000,1497805871,"The number of training examples is very large - 30 million right now and will eventually grow to 200 million. 10 questions each with 2 - 3 sentences responses. The domain is health surveys from outpatient clinic visits. 

Happy to answer any other questions you might have.",6,2
726,2017-6-19,2017,6,19,2,6i0v8h,Sentiment analysis with Amazon reviews.,https://www.reddit.com/r/MachineLearning/comments/6i0v8h/sentiment_analysis_with_amazon_reviews/,dhanush_ramuk,1497807153,[removed],0,1
727,2017-6-19,2017,6,19,3,6i12yb,Whats the best Reinforcement Learning method for controlling a Robotic Arm?,https://www.reddit.com/r/MachineLearning/comments/6i12yb/whats_the_best_reinforcement_learning_method_for/,thuglife9001,1497809495,[removed],0,1
728,2017-6-19,2017,6,19,4,6i1d68,Deep learning for creative selfie editing,https://www.reddit.com/r/MachineLearning/comments/6i1d68/deep_learning_for_creative_selfie_editing/,throwaway801512,1497812620,[removed],0,1
729,2017-6-19,2017,6,19,4,6i1g6p,Temporally Efficient Deep Learning with Spikes,https://www.reddit.com/r/MachineLearning/comments/6i1g6p/temporally_efficient_deep_learning_with_spikes/,LordKlevin,1497813525,,0,1
730,2017-6-19,2017,6,19,4,6i1m8n,[P] Automatic Sub-Reddit Identifier By Parsing Reddit Titles - Fully working demo is ready now [Update],https://www.reddit.com/r/MachineLearning/comments/6i1m8n/p_automatic_subreddit_identifier_by_parsing/,breakupnoob,1497815316,"2-3 days ago [I asked for help](https://www.reddit.com/r/MachineLearning/comments/6hc8tg/r_automatically_categorizing_reddit_submission/) about creating a program that can automatically identify the correct sub-reddit category just by parsing the title.

I'm happy to say that I've been able to create the first fully working demo here:

http://45.63.93.79/?q=[your title here]

Some examples from front-page

http://45.63.93.79/?q=Swedish%20brewery%20names%20beer%20%27F***%20you%20I%27m%20Millwall%27%20in%20tribute%20to%20man%20who%20fought%20London%20Bridge%20attackers

http://45.63.93.79/?q=Donald%20Trump%20claims%20his%20approval%20rating%20is%20higher%20than%20Barack%20Obama%27s%20but%20data%20suggests%20opposite

http://45.63.93.79/?q=I%20drew%20a%20Bell%20Gargoyle!

http://45.63.93.79/?q=The%20Apple%20Watch%20feature%20I%20once%20thought%20was%20a%20throwaway%20novelty%20is%20now%20crucial%20to%20me.

http://45.63.93.79/?q=Maze%20generation%20code,%20inspired%20by%20working%20through%20Mazes%20for%20Programmers

I'm totally a noob but in the last 3 days I have learned a lot in creating this like SciKit, nltk, WSGI, Google Big Query, Google Datalabs, etc. Thanks everyone for the guidance in my last thread!

P.S. FYI it's running a temp server I've provisioned on $5/mo vultr.com server. 

P. P. S. I've only trained it for the following subreddits:

('programming', 'business', 'design', 'entertainment', 'science', 'security', 'worldnews', 'politics', 'mobile', 'startups', 'google', 'microsoft', 'bitcoin', 'facebook', 'amazon', 'movies', 'gadgets', 'technology', 'linux', 'gaming', 'apple', 'design', 'music' )",11,10
731,2017-6-19,2017,6,19,5,6i1qth,GANGogh: Creating Art with GANs,https://www.reddit.com/r/MachineLearning/comments/6i1qth/gangogh_creating_art_with_gans/,[deleted],1497816677,[deleted],0,1
732,2017-6-19,2017,6,19,5,6i1urr,[P] GANGogh: Creating Art with GANs,https://www.reddit.com/r/MachineLearning/comments/6i1urr/p_gangogh_creating_art_with_gans/,rukjones4,1497817867,,7,6
733,2017-6-19,2017,6,19,5,6i1vr5,[P] python-recsys (SVD) with implicit feedback rather than ratings (recommender systems).,https://www.reddit.com/r/MachineLearning/comments/6i1vr5/p_pythonrecsys_svd_with_implicit_feedback_rather/,faust111,1497818174,"I am building a simple recommender system using recsys libraries.

Rather than ""ratings data"" I simply have implicit feedback of sales for items for users. Is it as simple as making my rating ""1"" for items where a sale has occurred and using SVD as is? Or will that not work at all?

(Im a relative beginner here).

http://ocelma.net/software/python-recsys/build/html/quickstart.html",8,3
734,2017-6-19,2017,6,19,6,6i2amn,[D] What research papers optimize neural networks with sparse gradients?,https://www.reddit.com/r/MachineLearning/comments/6i2amn/d_what_research_papers_optimize_neural_networks/,deltasheep1,1497822736,"What papers are a must-read if I'm interested in how to optimize neural networks which are sparse (have many derivatives that are zero)?

Because of the chain rule, a zero derivative for a variable means that all of its children will have a zero derivative, so there's room to optimize--especially when using ReLU.",4,2
735,2017-6-19,2017,6,19,6,6i2bka,[D] How would you use ML to detect fake user information?,https://www.reddit.com/r/MachineLearning/comments/6i2bka/d_how_would_you_use_ml_to_detect_fake_user/,PotatoMudkip,1497823028,"I was wondering how one could use machine learning techniques to detect ""fake"" users based on the personal information they provide (names, phone number, address...). I think it is a very interesting subject, but I could hardly find any paper on the subject.
My first guess would be to go with classification methods and provide labeled examples (Mr Pika Pika with phone number 020 2020 2020 is obviously fake, etc), but I'm unsure how to deal with the textual features as the input to that -other than manually transforming each variable into a series of booleans through criteria such as ""repeated values in phone number""... which does not sound very robust or sustainable on the long term.
Any thoughts on the subject?",5,1
736,2017-6-19,2017,6,19,7,6i2gy6,Making use of derivative information for neural networks.,https://www.reddit.com/r/MachineLearning/comments/6i2gy6/making_use_of_derivative_information_for_neural/,[deleted],1497824731,[removed],0,1
737,2017-6-19,2017,6,19,7,6i2j5g,[D] Making use of derivative information for Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6i2j5g/d_making_use_of_derivative_information_for_neural/,maka89,1497825426,"Sometimes when designing a regression model for a function, say y(x), it can be useful to supply derivative data to the model, particularly if the number of datapoints is limited. This can often increase the accuracy of the y(x) prediction.

This has some application when making meta models for compuationally expensive simulations for instance(given that the simulation is of such a nature that it provides the derivative for free, which is true for some CFD simulations for instance).

In the Gaussian Process Regression framework one is able to make use of this type of information beautifully(See section 9.4 in [Rassmussen &amp; Williams](http://www.gaussianprocess.org/gpml/chapters/RW9.pdf) for an instructive figure of what I am talking about).

I would like to look into ways of making use of this type of information for neural networks as well. Does  anyone have any info or ideas on this?

I have made a prototype that seems to work to some extent for a simple 1D example.

Here is the [gist](https://gist.github.com/maka89/bea8cb58205c9c2a17d9caf03b01cdb4).

Here is the ""secret sauce"" of the code:


tmp=neuralnet(x)

tmp2=tf.gradients(tmp,x)[0]

prediction=tf.concat([tmp,tmp2],1)


So my idea is to make a NN that predicts y(x). Then concatenate an extra output that is the derivative of the neural network with respect to x. Then train the network.

Sorry for the long post. Would like some input and other ideas on this if anyone else is interested in this ""small-data"" problem :)
And don't hesitate to ask if this was confusing.",7,11
738,2017-6-19,2017,6,19,9,6i2ygx,[N] An AI Primer with Wojciech Zaremba @ YC Podcast,https://www.reddit.com/r/MachineLearning/comments/6i2ygx/n_an_ai_primer_with_wojciech_zaremba_yc_podcast/,sherjilozair,1497830464,,9,0
739,2017-6-19,2017,6,19,9,6i2zmu,What is the best way to use the Deep Learning book by Ian Goodfellow?,https://www.reddit.com/r/MachineLearning/comments/6i2zmu/what_is_the_best_way_to_use_the_deep_learning/,j_l13,1497830895,[removed],0,1
740,2017-6-19,2017,6,19,10,6i3d2f,what are some domains/applications for which researchers and/or industrial designers and/or users themselves have found that ML is a bad choice?,https://www.reddit.com/r/MachineLearning/comments/6i3d2f/what_are_some_domainsapplications_for_which/,woggabogga,1497835319,[removed],0,1
741,2017-6-19,2017,6,19,10,6i3g9q,[R] One Model To Learn Them All,https://www.reddit.com/r/MachineLearning/comments/6i3g9q/r_one_model_to_learn_them_all/,xternalz,1497836399,,43,30
742,2017-6-19,2017,6,19,13,6i47fj,Using 3D Convolutional Neural Networks for Speaker Verification,https://www.reddit.com/r/MachineLearning/comments/6i47fj/using_3d_convolutional_neural_networks_for/,irsina,1497846300,,0,1
743,2017-6-19,2017,6,19,14,6i4ipx,[P] A quick demo of practical deep OCR for scene text using CTPN + CRNN. Uses docker containers and guaranteed to run :D,https://www.reddit.com/r/MachineLearning/comments/6i4ipx/p_a_quick_demo_of_practical_deep_ocr_for_scene/,[deleted],1497850864,[deleted],0,1
744,2017-6-19,2017,6,19,15,6i4las,[P] Practical Deep OCR for scene text using CTPN + CRNN,https://www.reddit.com/r/MachineLearning/comments/6i4las/p_practical_deep_ocr_for_scene_text_using_ctpn/,[deleted],1497852020,[deleted],5,29
745,2017-6-19,2017,6,19,15,6i4o8t,Request: Logo-Net pretrained model and Logo-160 dataset (No longer available on website),https://www.reddit.com/r/MachineLearning/comments/6i4o8t/request_logonet_pretrained_model_and_logo160/,mind_juice,1497853271,[removed],0,1
746,2017-6-19,2017,6,19,17,6i544j,Protein data for AI and Deep Learning with Keras integration,https://www.reddit.com/r/MachineLearning/comments/6i544j/protein_data_for_ai_and_deep_learning_with_keras/,alpine_photo,1497860657,,0,1
747,2017-6-19,2017,6,19,17,6i55f7,A database of protein order and disorder for Machine Learning applications,https://www.reddit.com/r/MachineLearning/comments/6i55f7/a_database_of_protein_order_and_disorder_for/,alpine_photo,1497861279,,0,1
748,2017-6-19,2017,6,19,17,6i565d,Does single neural net with one input layer and oupt layer (no hidden layers) can draw non-linear condescension boundary,https://www.reddit.com/r/MachineLearning/comments/6i565d/does_single_neural_net_with_one_input_layer_and/,John_Smith111,1497861648,[removed],0,1
749,2017-6-19,2017,6,19,17,6i57nk,Tensorflow Object Detection API,https://www.reddit.com/r/MachineLearning/comments/6i57nk/tensorflow_object_detection_api/,[deleted],1497862402,[deleted],0,1
750,2017-6-19,2017,6,19,18,6i5931,Tensorflow Object Detection API released,https://www.reddit.com/r/MachineLearning/comments/6i5931/tensorflow_object_detection_api_released/,mind_juice,1497863092,,0,1
751,2017-6-19,2017,6,19,18,6i5a56,Reverse Image Search with Machine Learning and TensorFlow series,https://www.reddit.com/r/MachineLearning/comments/6i5a56/reverse_image_search_with_machine_learning_and/,tzuchinc,1497863556,,0,1
752,2017-6-19,2017,6,19,19,6i5if9,Facebook is Training AI bots to negotiate - Deal or no deal?,https://www.reddit.com/r/MachineLearning/comments/6i5if9/facebook_is_training_ai_bots_to_negotiate_deal_or/,sh_tomer,1497867300,,0,1
753,2017-6-19,2017,6,19,19,6i5maa,[D] CPU Max # of PCIe Lanes for a 4 GPU box,https://www.reddit.com/r/MachineLearning/comments/6i5maa/d_cpu_max_of_pcie_lanes_for_a_4_gpu_box/,[deleted],1497869018,[deleted],1,1
754,2017-6-19,2017,6,19,19,6i5oca,Beginning Machine Learning  A few Resources [Subjective],https://www.reddit.com/r/MachineLearning/comments/6i5oca/beginning_machine_learning_a_few_resources/,cristivlad,1497869904,,0,1
755,2017-6-19,2017,6,19,20,6i5wlj,Janitorial Service Las Vegas - YouTube,https://www.reddit.com/r/MachineLearning/comments/6i5wlj/janitorial_service_las_vegas_youtube/,tinabbdupreebbb,1497873079,,0,1
756,2017-6-19,2017,6,19,21,6i621g,Image Captioning,https://www.reddit.com/r/MachineLearning/comments/6i621g/image_captioning/,[deleted],1497874980,[deleted],0,1
757,2017-6-19,2017,6,19,21,6i6632,[P] Machine Learning for Image Content Analysis,https://www.reddit.com/r/MachineLearning/comments/6i6632/p_machine_learning_for_image_content_analysis/,[deleted],1497876362,[deleted],1,8
758,2017-6-19,2017,6,19,21,6i6669,Alternatives to Backprop -- looking for leads,https://www.reddit.com/r/MachineLearning/comments/6i6669/alternatives_to_backprop_looking_for_leads/,Schnidlauch,1497876388,[removed],0,1
759,2017-6-19,2017,6,19,22,6i6asi,Is Machine Learning the best way to make the most in Finance?,https://www.reddit.com/r/MachineLearning/comments/6i6asi/is_machine_learning_the_best_way_to_make_the_most/,hardikmakadia,1497877877,,0,1
760,2017-6-19,2017,6,19,22,6i6efh,[D] What are the real problem solving application of Elastic Weight Consolidation?,https://www.reddit.com/r/MachineLearning/comments/6i6efh/d_what_are_the_real_problem_solving_application/,commafighter,1497878991,"About six months back deepmind published [Overcoming catastrophic forgetting in neural networks](http://www.pnas.org/content/114/13/3521.full). This paper was in the news because they found a way (EWC) to prevent ""catastrophic forgetting"". But even after 6 months I didnt see any real life problems solved by EWC like GAN used to make images from scratch. Is their any example of using EWC in solving some problem or EWC is just a theoretical concept?",3,4
761,2017-6-19,2017,6,19,23,6i6w5a,[D] Visualization tricks for 3-dim input and 2-dim output,https://www.reddit.com/r/MachineLearning/comments/6i6w5a/d_visualization_tricks_for_3dim_input_and_2dim/,fixedrl,1497883985,"It is a RL setting, we have 2 dimensional input with 1 dimensional action (totally 3 dimension). The environment will generate 2 dimensional observations. We would like to visualize the behaviors of the environment. Can there be some good way to plot it, to be maximally informative. ",3,0
762,2017-6-20,2017,6,20,0,6i6z6f,Workflow question: we run jobs on a small amount of lab machines (~10) with GPUs. What tools are there to simplify this process? SCP + SSH isn't great.,https://www.reddit.com/r/MachineLearning/comments/6i6z6f/workflow_question_we_run_jobs_on_a_small_amount/,chris2point0,1497884749,[removed],0,1
763,2017-6-20,2017,6,20,0,6i71m0,"[D] Where are you with your career in ML? Alternatively, how many are you are developers and now getting into ML?",https://www.reddit.com/r/MachineLearning/comments/6i71m0/d_where_are_you_with_your_career_in_ml/,ed_at_work,1497885375,"I'm currently a full-stack web developer, on a quest to dive as deep into ML as my skills can take me. I'm wondering who comes from a similar background as me, and how far along are you. Has anyone self-taught and made the leap from full-stack stuff to ML stuff?

Alternatively, regardless of your background, how did you get into ML and where are you going with it?

Edit: Wow this definitely took off. Thanks for all the great responses. It's a bit encouraging as I've read some stories from people who seem to have been in my shoes. Best of luck to all of you in your careers!",139,144
764,2017-6-20,2017,6,20,0,6i7a4h,[R] Value-Decomposition Networks For Cooperative Multi-Agent Learning,https://www.reddit.com/r/MachineLearning/comments/6i7a4h/r_valuedecomposition_networks_for_cooperative/,pauljasek,1497887595,,0,8
765,2017-6-20,2017,6,20,2,6i7qck,[D] Using ANNs on small data  Deep Learning vs. Xgboost,https://www.reddit.com/r/MachineLearning/comments/6i7qck/d_using_anns_on_small_data_deep_learning_vs/,_alphamaximus_,1497891678,,22,50
766,2017-6-20,2017,6,20,2,6i7tax,Reinforcement learning and Trading,https://www.reddit.com/r/MachineLearning/comments/6i7tax/reinforcement_learning_and_trading/,operman18,1497892405,[removed],0,1
767,2017-6-20,2017,6,20,2,6i7za0,[P] Do Androids Dream Of Electric Sheep?,https://www.reddit.com/r/MachineLearning/comments/6i7za0/p_do_androids_dream_of_electric_sheep/,lopuhin,1497893841,,0,0
768,2017-6-20,2017,6,20,2,6i837q,Neural Network Simulator running in your browser will help you understand how artificial neural network works.,https://www.reddit.com/r/MachineLearning/comments/6i837q/neural_network_simulator_running_in_your_browser/,cpuheater,1497894813,,2,11
769,2017-6-20,2017,6,20,3,6i8bfl,Quaternion Denoising Encoder-Decoder for theme identification of Telephone Conversations,https://www.reddit.com/r/MachineLearning/comments/6i8bfl/quaternion_denoising_encoderdecoder_for_theme/,[deleted],1497896860,[deleted],0,1
770,2017-6-20,2017,6,20,3,6i8du2,[R] Quaternion Denoising Encoder-Decoder for theme identification of Telephone Conversations,https://www.reddit.com/r/MachineLearning/comments/6i8du2/r_quaternion_denoising_encoderdecoder_for_theme/,titouan_parcollet,1497897460,,8,2
771,2017-6-20,2017,6,20,3,6i8gre,Neurally Embedded Emojis,https://www.reddit.com/r/MachineLearning/comments/6i8gre/neurally_embedded_emojis/,cavaunpeu,1497898172,,0,1
772,2017-6-20,2017,6,20,3,6i8if0,[D] Seeking advice on ML tools,https://www.reddit.com/r/MachineLearning/comments/6i8if0/d_seeking_advice_on_ml_tools/,[deleted],1497898606,[deleted],1,0
773,2017-6-20,2017,6,20,4,6i8tdx,[R] VisualBackProp: efficient visualization of CNNs,https://www.reddit.com/r/MachineLearning/comments/6i8tdx/r_visualbackprop_efficient_visualization_of_cnns/,moyix,1497901313,,2,17
774,2017-6-20,2017,6,20,5,6i96rq,AI is the karma for humans.,https://www.reddit.com/r/MachineLearning/comments/6i96rq/ai_is_the_karma_for_humans/,techscouter,1497904639,,0,1
775,2017-6-20,2017,6,20,6,6i9ouj,Is anybody attending the Data Intelligence machine learning conference?,https://www.reddit.com/r/MachineLearning/comments/6i9ouj/is_anybody_attending_the_data_intelligence/,rashmiup13,1497909265,[removed],0,1
776,2017-6-20,2017,6,20,7,6i9rkf,"[N] ""Accelerating Deep Learning Research with the Tensor2Tensor Library""+trained translation model releases of: SliceNet, ByteNet, GNMT, Mixture-GNMT, Attention is all You Need",https://www.reddit.com/r/MachineLearning/comments/6i9rkf/n_accelerating_deep_learning_research_with_the/,gwern,1497910002,,19,48
777,2017-6-20,2017,6,20,7,6i9tcs,The KFC twitter employees know their machine learning,https://www.reddit.com/r/MachineLearning/comments/6i9tcs/the_kfc_twitter_employees_know_their_machine/,dumberthanrobots,1497910465,,0,0
778,2017-6-20,2017,6,20,8,6ia57p,Blockwork Technique,https://www.reddit.com/r/MachineLearning/comments/6ia57p/blockwork_technique/,gwenyosef,1497913823,,0,1
779,2017-6-20,2017,6,20,8,6ia5dz,"[R] ""An Overview of Multi-Task Learning in Deep Neural Networks"", Ruder 2017",https://www.reddit.com/r/MachineLearning/comments/6ia5dz/r_an_overview_of_multitask_learning_in_deep/,gwern,1497913872,,1,15
780,2017-6-20,2017,6,20,8,6ia7ig,Question,https://www.reddit.com/r/MachineLearning/comments/6ia7ig/question/,GangsterOfTime,1497914496,[removed],0,1
781,2017-6-20,2017,6,20,8,6ia8d6,[D] Making temporal data of a query into features,https://www.reddit.com/r/MachineLearning/comments/6ia8d6/d_making_temporal_data_of_a_query_into_features/,PotatoMudkip,1497914765,"I am working on a system that would be able to detect fake/automatic queries amongst all received queries. I wish to train a model on features based on the content of the query itself (probability of the name being fake, etc), but I also noticed that many of the received fake queries were submitted at regular interval (for instance, every 10 seconds). How could the time of the query be integrated into the input data's features to make use of this property?",1,2
782,2017-6-20,2017,6,20,9,6iagrl,"New to machine learning, curious if what I want is possible.",https://www.reddit.com/r/MachineLearning/comments/6iagrl/new_to_machine_learning_curious_if_what_i_want_is/,[deleted],1497917373,[removed],0,1
783,2017-6-20,2017,6,20,9,6iahvc,"Creating Music with NSynth, a WaveNet Autoencoder for Musical Sounds",https://www.reddit.com/r/MachineLearning/comments/6iahvc/creating_music_with_nsynth_a_wavenet_autoencoder/,[deleted],1497917665,[deleted],0,1
784,2017-6-20,2017,6,20,10,6iarm4,"isAlienware AW15R3-10881SLV Laptop (6th Generation i7, 16GB RAM, 256GB + 1TB HDD) NVIDIA GeForce GTX1070 good for data science?",https://www.reddit.com/r/MachineLearning/comments/6iarm4/isalienware_aw15r310881slv_laptop_6th_generation/,newbornking999,1497920638,[removed],0,1
785,2017-6-20,2017,6,20,10,6iatkv,[R] Learning Hierarchical Information Flow with Recurrent Neural Modules,https://www.reddit.com/r/MachineLearning/comments/6iatkv/r_learning_hierarchical_information_flow_with/,xternalz,1497921222,,5,22
786,2017-6-20,2017,6,20,10,6ib0o5,"[D] Those with related degrees, do you recommend taking taking math classes, signal processing classes, or database/algorithms classes as electives?",https://www.reddit.com/r/MachineLearning/comments/6ib0o5/d_those_with_related_degrees_do_you_recommend/,mfin23,1497923493,"Hey everyone!

I come from a biostatistics/bioengineering background, so I am very familiar with machine learning and programming in several languages including c++ and Python. I've decided to pursue a master's degree in data science to compliment the research I've recently found myself interested in. I have room for around 3-4 elective classes in my schedule and I'm a little torn. One option is to take several applied math classes including optimization, Markov chains, and stochastic processes. I could also take several signal processing classes including digital signal processing, image processing etc. The last option is to take advanced database and algorithms classes. 

Do you think that applied math classes, signal processing classes, or database/algorithms classes are more important for machine learning? I do intend to continue working with medical datasets, so I could see myself dealing with image recognition in the future. 

Thank you everyone for the help and guidance. ",22,8
787,2017-6-20,2017,6,20,11,6ib4k4,How can you used the horizontal ribbon blenders for sale?,https://www.reddit.com/r/MachineLearning/comments/6ib4k4/how_can_you_used_the_horizontal_ribbon_blenders/,JCT_MACHINE,1497924722,,0,1
788,2017-6-20,2017,6,20,13,6ibomz,question regarding applicability of a project to the currently abundant jobs in ML/deep learning/AI in tech,https://www.reddit.com/r/MachineLearning/comments/6ibomz/question_regarding_applicability_of_a_project_to/,eda2topnamejob,1497931574,[removed],0,1
789,2017-6-20,2017,6,20,13,6ibuxu,[N] NIPS 2017 Status Report: June 19th,https://www.reddit.com/r/MachineLearning/comments/6ibuxu/n_nips_2017_status_report_june_19th/,wordbag,1497933845,,4,25
790,2017-6-20,2017,6,20,14,6ibybl,Ducted Reverse Cycle Airconditioning,https://www.reddit.com/r/MachineLearning/comments/6ibybl/ducted_reverse_cycle_airconditioning/,gwenyosef,1497935130,,0,1
791,2017-6-20,2017,6,20,15,6ic9yc,Best Image Captioning Methods,https://www.reddit.com/r/MachineLearning/comments/6ic9yc/best_image_captioning_methods/,chvsp,1497939801,[removed],0,1
792,2017-6-20,2017,6,20,15,6icd29,[N] Call for Papers - Reproducibility in Machine Learning Workshop (ICML 2017),https://www.reddit.com/r/MachineLearning/comments/6icd29/n_call_for_papers_reproducibility_in_machine/,alexmlamb,1497941162,,7,18
793,2017-6-20,2017,6,20,17,6icnwf,[R] A Closer Look at Memorization in Deep Networks,https://www.reddit.com/r/MachineLearning/comments/6icnwf/r_a_closer_look_at_memorization_in_deep_networks/,hardmaru,1497946088,,11,82
794,2017-6-20,2017,6,20,18,6icyeq,Some notes on the Cramer GAN,https://www.reddit.com/r/MachineLearning/comments/6icyeq/some_notes_on_the_cramer_gan/,[deleted],1497950997,[removed],0,1
795,2017-6-20,2017,6,20,18,6id07y,Trading Using Machine Learning In Python,https://www.reddit.com/r/MachineLearning/comments/6id07y/trading_using_machine_learning_in_python/,NitinThapar,1497951832,,0,1
796,2017-6-20,2017,6,20,18,6id089,What are different possible techniques/tricks for training a model when limited data is available?,https://www.reddit.com/r/MachineLearning/comments/6id089/what_are_different_possible_techniquestricks_for/,satwik_,1497951837,[removed],0,1
797,2017-6-20,2017,6,20,18,6id1v2,Basic recommender system,https://www.reddit.com/r/MachineLearning/comments/6id1v2/basic_recommender_system/,niujin,1497952595,[removed],0,1
798,2017-6-20,2017,6,20,19,6id8kp,[D] Finding loop patterns in a dataset,https://www.reddit.com/r/MachineLearning/comments/6id8kp/d_finding_loop_patterns_in_a_dataset/,erikhhhh,1497955380,"Hi everyone!

My problem is that i have quite big amount of data about machines that tend to work super well for some time and then worse for a little and then super well again.

As every machine works a bit differently then I need to calculate the average loop length for every machine.

I'm having hard time to figure out, how should I tackle this problem. Maybe you can give me hints on how could I detect those loops. Thanks! ",8,4
799,2017-6-20,2017,6,20,19,6id8qc,[D] Training on ImageNet,https://www.reddit.com/r/MachineLearning/comments/6id8qc/d_training_on_imagenet/,Cock-tail,1497955444,"Hi. This is my first time training on a large-scale dataset like ImageNet. I am using a **cross-entropy** loss function, with the **Adam** optimizer, batch-size of 8(GPU limitations), on a pre-trained **VGG-16** network, with a few additions, on the task of colorizing images(mapping L input to a*b*). For now, I am trying my model on train1.txt with the validation data from val1.txt. I haven't completed 1 epoch yet, but the loss gets close to 0(0.01 now) and the training accuracy gets stuck at 0.10. Is something wrong with this?

A few notes:

* The VGG-16 network is freezed, and used only for the semantic information
* I popped the unnecessary FC layers from VGG, as well as blocks 4 and 5
* The new layers are appended to the pre-trained model, with some residual-like connections. Does Keras take care of this? Do I have to initialize the weights here?

I am also normalizing the LAB channels like this(Python 3), and the last activation function is a Sigmoid

    l_channel / 100,
    (a_channel + 86.185) / 184.439,
    (b_channel + 107.863) / 202.345);",4,1
800,2017-6-20,2017,6,20,19,6id9jr,[D] Some notes on the Cramer GAN,https://www.reddit.com/r/MachineLearning/comments/6id9jr/d_some_notes_on_the_cramer_gan/,arthurgretton,1497955801,"I've posted some thoughts on the Cramer GAN: https://medium.com/@arthur.gretton/notes-on-the-cramer-gan-752abd505c00

In brief: in dimensions greater than 1, the paper doesnt use the Cramer distance! In the GAN experiments of Section 5, it uses the energy distance. The model is therefore a generative moment matching network, using a particular kernel. Since the energy distance is an integral probability metric, the ""improved Wasserstein GAN"" training scheme proposed by Gulrajani et al. can be used to train input features to the kernel.

Overall, this is a good idea, and seems to give nice generator samples. Unfortunately, the Cramer GAN paper makes a problematic approximation, which means that the critic in this algorithm does not correctly compare the generator and reference (target) sample distributions: you can have a zero critic loss even with very different generator and reference distributions.",8,40
801,2017-6-20,2017,6,20,20,6ideen,Cross-Validation and Feature Selection,https://www.reddit.com/r/MachineLearning/comments/6ideen/crossvalidation_and_feature_selection/,[deleted],1497957752,[removed],0,1
802,2017-6-20,2017,6,20,20,6idhpc,"What ANN library to use for academic research, Theano or Tensorflow? Knowing that I will not use conventional ANN architectures.",https://www.reddit.com/r/MachineLearning/comments/6idhpc/what_ann_library_to_use_for_academic_research/,[deleted],1497958954,[removed],0,1
803,2017-6-20,2017,6,20,21,6idtlw,Google releases new TensorFlow Object Detection API,https://www.reddit.com/r/MachineLearning/comments/6idtlw/google_releases_new_tensorflow_object_detection/,[deleted],1497963088,[deleted],0,1
804,2017-6-20,2017,6,20,21,6idttp,[N] Google releases new TensorFlow Object Detection API,https://www.reddit.com/r/MachineLearning/comments/6idttp/n_google_releases_new_tensorflow_object_detection/,luba_belokon,1497963159,,8,137
805,2017-6-20,2017,6,20,22,6idzoa,Overfitting and Asking Ecological Questions with ML,https://www.reddit.com/r/MachineLearning/comments/6idzoa/overfitting_and_asking_ecological_questions_with/,danil_lee,1497965003,,0,1
806,2017-6-20,2017,6,20,23,6ieari,"[D] Concrete dropout, how to obtain Equation (3) on page 3",https://www.reddit.com/r/MachineLearning/comments/6ieari/d_concrete_dropout_how_to_obtain_equation_3_on/,fixedrl,1497968290,"In the paper [Concrete dropout](https://arxiv.org/abs/1705.07832), on page 3, how could we derive the Equation (3) ? Could someone help to point out the e.g. page in Yarin's PhD thesis if the derivation is there ?",2,3
807,2017-6-20,2017,6,20,23,6ieffo,[P] Getting ONET job titles from job descriptions,https://www.reddit.com/r/MachineLearning/comments/6ieffo/p_getting_onet_job_titles_from_job_descriptions/,throwawaysvs,1497969565,[removed],1,2
808,2017-6-21,2017,6,21,0,6iel3s,Putting (machine) learning and (artificial) intelligence to work,https://www.reddit.com/r/MachineLearning/comments/6iel3s/putting_machine_learning_and_artificial/,isabellhoulihan,1497971076,,0,1
809,2017-6-21,2017,6,21,0,6ielgx,How Dice Uses Machine Learning Technology to Reduce Recruiting Fraud,https://www.reddit.com/r/MachineLearning/comments/6ielgx/how_dice_uses_machine_learning_technology_to/,ionehobby,1497971158,,0,1
810,2017-6-21,2017,6,21,0,6ielqn,Machine Learning Is Helping Martech Lead the AI Revolution,https://www.reddit.com/r/MachineLearning/comments/6ielqn/machine_learning_is_helping_martech_lead_the_ai/,charlieherod,1497971224,,0,1
811,2017-6-21,2017,6,21,0,6ieq3h,"How did you go about learning Python libraries such as NumPy, Pandas, sklearn, matplotlib, tensorflow and etc?",https://www.reddit.com/r/MachineLearning/comments/6ieq3h/how_did_you_go_about_learning_python_libraries/,nichespace,1497972346,[removed],0,1
812,2017-6-21,2017,6,21,0,6ieqzg,"Data sets for supervised learning with Race, Sex, and other sensitive topics?",https://www.reddit.com/r/MachineLearning/comments/6ieqzg/data_sets_for_supervised_learning_with_race_sex/,celeryman35,1497972579,[removed],0,1
813,2017-6-21,2017,6,21,0,6ier9z,Learning Hierarchical Information Flow with Recurrent Neural Modules,https://www.reddit.com/r/MachineLearning/comments/6ier9z/learning_hierarchical_information_flow_with/,[deleted],1497972656,[deleted],0,1
814,2017-6-21,2017,6,21,0,6iet1i,Should I quit machine learning?,https://www.reddit.com/r/MachineLearning/comments/6iet1i/should_i_quit_machine_learning/,dannyeuu,1497973117,,0,1
815,2017-6-21,2017,6,21,1,6iezxt,Deep Learning in quantitative trading.,https://www.reddit.com/r/MachineLearning/comments/6iezxt/deep_learning_in_quantitative_trading/,qplum,1497974837,,0,1
816,2017-6-21,2017,6,21,1,6if26c,[N] NumFOCUS Adds Shogun Machine Learning Toolbox to Sponsored Projects,https://www.reddit.com/r/MachineLearning/comments/6if26c/n_numfocus_adds_shogun_machine_learning_toolbox/,pp314159,1497975379,,3,4
817,2017-6-21,2017,6,21,2,6ifiq9,Introducing the BAIR Blog,https://www.reddit.com/r/MachineLearning/comments/6ifiq9/introducing_the_bair_blog/,ch3njus,1497979451,,0,1
818,2017-6-21,2017,6,21,3,6ifszg,Results of my attempt to build a music genre classifier.,https://www.reddit.com/r/MachineLearning/comments/6ifszg/results_of_my_attempt_to_build_a_music_genre/,ritchie46,1497981921,,0,1
819,2017-6-21,2017,6,21,3,6iftki,Ken Goldberg's AUTOLAB Takes Robot Grasping to a New Level With Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6iftki/ken_goldbergs_autolab_takes_robot_grasping_to_a/,Chipdoc,1497982065,,0,1
820,2017-6-21,2017,6,21,3,6ifx1z,The first automated machine learning platform in public beta,https://www.reddit.com/r/MachineLearning/comments/6ifx1z/the_first_automated_machine_learning_platform_in/,curious_rv,1497982943,,0,1
821,2017-6-21,2017,6,21,3,6ig0iw,Is there a term for the difference between predicting text (supervised) with (the algorithm having) an understanding of NLP and predicteing text without an understandinf of NLP?,https://www.reddit.com/r/MachineLearning/comments/6ig0iw/is_there_a_term_for_the_difference_between/,[deleted],1497983833,[removed],0,1
822,2017-6-21,2017,6,21,3,6ig0lg,[P] Matrix Factorization in PyTorch,https://www.reddit.com/r/MachineLearning/comments/6ig0lg/p_matrix_factorization_in_pytorch/,benfred,1497983852,,0,16
823,2017-6-21,2017,6,21,3,6ig3yr,Is there a term for the difference between predicting text (supervised) with (the algorithm having) an understanding of NLP and predicting text without an understanding of NLP?,https://www.reddit.com/r/MachineLearning/comments/6ig3yr/is_there_a_term_for_the_difference_between/,theology_,1497984703,[removed],0,1
824,2017-6-21,2017,6,21,3,6ig4t3,EFF launches new project to track machine learning &amp; AI progress,https://www.reddit.com/r/MachineLearning/comments/6ig4t3/eff_launches_new_project_to_track_machine/,[deleted],1497984911,[deleted],0,2
825,2017-6-21,2017,6,21,4,6igfq0,Berkeley Artificial Intelligence Research now has a blog,https://www.reddit.com/r/MachineLearning/comments/6igfq0/berkeley_artificial_intelligence_research_now_has/,DanielSeita,1497987524,,0,1
826,2017-6-21,2017,6,21,5,6igz6n,[D]Reinforcement Learning: Why no deterministic policy gradient for discrete actions?,https://www.reddit.com/r/MachineLearning/comments/6igz6n/dreinforcement_learning_why_no_deterministic/,justheuristic,1497992303,[removed],0,1
827,2017-6-21,2017,6,21,6,6igzxl,Suggestions for personal home based deep learning workstation gig,https://www.reddit.com/r/MachineLearning/comments/6igzxl/suggestions_for_personal_home_based_deep_learning/,saurabhvyas3,1497992481,[removed],0,1
828,2017-6-21,2017,6,21,6,6ih0v3,how to get started in machine learning?,https://www.reddit.com/r/MachineLearning/comments/6ih0v3/how_to_get_started_in_machine_learning/,Calandracas666,1497992711,[removed],0,1
829,2017-6-21,2017,6,21,6,6ih8o2,[P] A Jupyter Notebook collecting the state of the art on numerous ML benchmarks,https://www.reddit.com/r/MachineLearning/comments/6ih8o2/p_a_jupyter_notebook_collecting_the_state_of_the/,pde,1497994759,,10,138
830,2017-6-21,2017,6,21,8,6ihung,Best Cabinet Makers and Designers,https://www.reddit.com/r/MachineLearning/comments/6ihung/best_cabinet_makers_and_designers/,gwenyosef,1498000792,,0,1
831,2017-6-21,2017,6,21,9,6ii8sk,Is Google AI better than the competition?,https://www.reddit.com/r/MachineLearning/comments/6ii8sk/is_google_ai_better_than_the_competition/,k4neki,1498004925,[removed],0,1
832,2017-6-21,2017,6,21,9,6iib9r,[N] Andrej Karpathy leaves OpenAI for Tesla ('Director of AI and Autopilot Vision'),https://www.reddit.com/r/MachineLearning/comments/6iib9r/n_andrej_karpathy_leaves_openai_for_tesla/,gwern,1498005660,,110,390
833,2017-6-21,2017,6,21,10,6iifr7,"[R] meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting, ""ICML 2017""",https://www.reddit.com/r/MachineLearning/comments/6iifr7/r_meprop_sparsified_back_propagation_for/,xternalz,1498007062,,22,15
834,2017-6-21,2017,6,21,10,6iin5q,[D] What are the latest developments in the theory of deep neural networks?,https://www.reddit.com/r/MachineLearning/comments/6iin5q/d_what_are_the_latest_developments_in_the_theory/,TheBillsFly,1498009370,"As the title states, I'm interested in the latest developments in the theory of deep neural networks, especially regarding some mathematical arguments and results based around that. My apologies if this is somewhat vague but I appreciate anything that I can get. DNN researchers seem to be far more focused on results, rather than theoretical details (to be fair, who can blame them - the results are spectacular), but I would like to know the state of theoretical deep learning research and perhaps join in the discussion. Thanks!

**Edit**: For anyone who is curious, some recent papers that I have found interesting are the following:

* [Provable Approximation Properties for Deep Neural Networks](https://arxiv.org/pdf/1509.07385.pdf) - The authors review some theoretical results on the approximation properties of networks and produce a result bounding the error of a sparse-connected 4-layer network that they construct
* [Deep Learning and the Information Bottleneck Principle](https://arxiv.org/pdf/1503.02406.pdf) - This result shows how information flows through a neural network
* [Towards Principled Methods for Training Generative Adversarial Networks](https://arxiv.org/pdf/1701.04862.pdf) - The w-GAN paper
* [Geometry of the Restricted Boltzmann Machine](https://pdfs.semanticscholar.org/1cae/0fa8d736553c6ad81223afb99f2906a4aeda.pdf) - I only glazed over this one, but it looks like the authors develop an understanding of the RBM from an algebraic geometry perspective",14,18
835,2017-6-21,2017,6,21,10,6iiouk,Water cooling for GPUs?,https://www.reddit.com/r/MachineLearning/comments/6iiouk/water_cooling_for_gpus/,AI_entrepreneur,1498009848,[removed],0,1
836,2017-6-21,2017,6,21,11,6iirik,Becoming a Research Engineer in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6iirik/becoming_a_research_engineer_in_machine_learning/,[deleted],1498010638,[removed],0,1
837,2017-6-21,2017,6,21,11,6iit2b,Electrical Rewiring,https://www.reddit.com/r/MachineLearning/comments/6iit2b/electrical_rewiring/,gwenyosef,1498011112,,0,1
838,2017-6-21,2017,6,21,11,6iixgt,What is your opinion on media articles sensationalizing AI or Deep Learning research?,https://www.reddit.com/r/MachineLearning/comments/6iixgt/what_is_your_opinion_on_media_articles/,JamminJames921,1498012413,[removed],0,1
839,2017-6-21,2017,6,21,12,6ijai4,How Do You Build A Machine Learning Classification Model That Adapts To Context Dependent Dates,https://www.reddit.com/r/MachineLearning/comments/6ijai4/how_do_you_build_a_machine_learning/,kyleb707,1498016398,[removed],0,1
840,2017-6-21,2017,6,21,13,6ijh6q,Learning to Reason with Neural Module Networks,https://www.reddit.com/r/MachineLearning/comments/6ijh6q/learning_to_reason_with_neural_module_networks/,[deleted],1498018613,[deleted],0,1
841,2017-6-21,2017,6,21,13,6iji0t,Proofread request?,https://www.reddit.com/r/MachineLearning/comments/6iji0t/proofread_request/,a1355632,1498018914,[removed],0,1
842,2017-6-21,2017,6,21,13,6ijjrd,53% of Marketers Plan To Adopt Artificial Intelligence In Two Years,https://www.reddit.com/r/MachineLearning/comments/6ijjrd/53_of_marketers_plan_to_adopt_artificial/,hardikmakadia,1498019512,,0,1
843,2017-6-21,2017,6,21,14,6ijpag,Carpentry Services,https://www.reddit.com/r/MachineLearning/comments/6ijpag/carpentry_services/,gwenyosef,1498021572,,0,1
844,2017-6-21,2017,6,21,14,6ijv5d,[R] Introducing the Berkeley AI Research Blog,https://www.reddit.com/r/MachineLearning/comments/6ijv5d/r_introducing_the_berkeley_ai_research_blog/,cbfinn,1498023735,,12,154
845,2017-6-21,2017,6,21,16,6ik9a2,What is the state of the art in text classification?,https://www.reddit.com/r/MachineLearning/comments/6ik9a2/what_is_the_state_of_the_art_in_text/,[deleted],1498029352,[removed],0,1
846,2017-6-21,2017,6,21,16,6ikcf6,[D] What is the state of the art in text classification?,https://www.reddit.com/r/MachineLearning/comments/6ikcf6/d_what_is_the_state_of_the_art_in_text/,jonej,1498030786,"I've seen implementations using both LSTMs, CNNs and NB-SVM (Naive Bayes SVM). What is currently considered best in terms of efficiency and accuracy  particularly for multi-class labelling?",10,11
847,2017-6-21,2017,6,21,16,6ikcl2,Wall Hangings Interior Designs,https://www.reddit.com/r/MachineLearning/comments/6ikcl2/wall_hangings_interior_designs/,gwenyosef,1498030861,,0,1
848,2017-6-21,2017,6,21,17,6ikf4e,What technique should I use?,https://www.reddit.com/r/MachineLearning/comments/6ikf4e/what_technique_should_i_use/,Pantofolaio,1498032039,[removed],0,1
849,2017-6-21,2017,6,21,17,6ikjxt,What is categorical crossentropy in keras?,https://www.reddit.com/r/MachineLearning/comments/6ikjxt/what_is_categorical_crossentropy_in_keras/,rjmessibarca,1498034359,[removed],0,1
850,2017-6-21,2017,6,21,17,6ikkay,"In a simple regression, which features are the most important (have the strongest relationship).",https://www.reddit.com/r/MachineLearning/comments/6ikkay/in_a_simple_regression_which_features_are_the/,[deleted],1498034534,[removed],0,1
851,2017-6-21,2017,6,21,17,6iklws,[P] In a regression which features are most important/have strongest relationship to dependent variable.,https://www.reddit.com/r/MachineLearning/comments/6iklws/p_in_a_regression_which_features_are_most/,faust111,1498035333,I have a data set and I want o figure out which features have the strongest relationship to my dependent variable. What would be the best way of going about this?,13,2
852,2017-6-21,2017,6,21,18,6iks48,Airbnb's Biggest Weapon Against Hotels: Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6iks48/airbnbs_biggest_weapon_against_hotels_machine/,hardikmakadia,1498038132,,0,1
853,2017-6-21,2017,6,21,18,6iktj5,difference between homeomorphism and homotopy?,https://www.reddit.com/r/MachineLearning/comments/6iktj5/difference_between_homeomorphism_and_homotopy/,John_Smith111,1498038763,[removed],0,1
854,2017-6-21,2017,6,21,20,6il5rk,[D] RNNs are not really Turing Complete in any practical way,https://www.reddit.com/r/MachineLearning/comments/6il5rk/d_rnns_are_not_really_turing_complete_in_any/,Kiuhnm,1498043770,"## Are RNNs Turing Complete?

I watched a talk about *RNNs* where the speaker claims that RNNs are not really *Turing Complete* (TC) because, according to him, the input is fed to the RNNs in a forced order and so the net can't control the tape. The speaker suggests that we would need Reinforcement Learning (to control the tape) to make RNNs Turing Complete.

This claim baffled me for several reasons. Mainly:

1. An RNN where we can ""control"" the order in which the input is presented to it is *NOT* an RNN.
2. Who says the tape must be external to the RNNs as the speaker seems to suggest?
3. If someone proved that RNNs are TC, then surely they managed to do it without *augmenting* RNNs in any way.

The speaker is pointing out the fact that expressibility != learnability, which is true for every sufficiently complex model, in practice. The problem is that his arguments are flawed.

I looked around and eventually stumbled on [a paper](http://binds.cs.umass.edu/papers/1992_Siegelmann_COLT.pdf) which proves that RNNs are indeed Turing Complete.

I skimmed through the paper and I spotted the *trick* pretty quickly.

The first thing I thought while watching the talk is that an RNN could memorize the input some way and then maintain an *internal tape*, thus invalidating the claim of the speaker. This would make the RNN Turing Complete in theory, but not in practice since the input/output vectors are usually ""small"" and making them ""large"" would be quite problematic.

Indeed, the paper seems to use the same idea. We have *Finite State Automata* (FSA) which have a finite number of states and can only remember the state they're in. Then we have *Push Down (Finite State) Automata* (PDA) which also have an infinite stack and, finally, *Turing Machines* (TM) which have an infinite tape.

The problem with the stack is that it limits the order in which one can access memory and so PDA are less powerful than TMs. It turns out, however, that if we allow the automaton to have *two stacks*, then it's as powerful as a TM. Moreover, these stacks need only contain *binary digits*.

Therefore, we just need to prove that for each PDA there exists an RNN with can emulate that PDA. We don't need to worry about learning. We just need to prove that there are some weights which do the trick.

The trick used in the paper is to encode each stack as a *rational number*. These kinds of encodings are very common in proofs about cardinality. The authors decide to encode a 0 as 1 and a 1 as 3 to simplify the update operations. So, a stack with the elements s1, s2, s3, ..., sn can be encoded as

    q(s) = sum_{i=1}^n (2 si + 1)/(4^i)

For instance, if s = 01101, then q(s) = 0.13313, written in base 4. The push and pop operations are easy:

    push(q, v) = q/4 + (2v + 1)/4 = q/4 + v/2 + 1/4
    pop(q, v) = 4q - 2v - 1

Note that we need to know the element we're about to pop (v), but that's not a problem. Note that q is a rational number, so the RNN just need to have rational weights.

The input/output vectors will have 3 elements:

1. state
2. first stack
3. second stack

That's it. The paper dives into many other technical details but I think this is the gist of it. This is essentially my idea of maintaining an *internal tape*.

## Are RNNs *really* Turing Complete?

We claim that real computers are TC even though they have finite memory because we can imagine adding extra memory when needed. The problem with RNNs is that we can't make input/output vectors bigger when needed because that would also make RNNs slower.

Therefore, I'm claiming that RNNs are not *really* TC for practical purposes. Now I'm going to look into Neural Differentiable Computers which, hopefully, solve this problem. I think the only way to achieve practical Turing Completeness is to be smart about effective computations.",23,29
855,2017-6-21,2017,6,21,21,6ilfp7,Our first recommendation engine in Soluto,https://www.reddit.com/r/MachineLearning/comments/6ilfp7/our_first_recommendation_engine_in_soluto/,AmirPupko,1498047373,,0,1
856,2017-6-21,2017,6,21,22,6iltyj,[P] Help creating ML algorithm that identifies flat file data types,https://www.reddit.com/r/MachineLearning/comments/6iltyj/p_help_creating_ml_algorithm_that_identifies_flat/,Fender6969,1498051913,"I'm quite new to ML and I have a project that I need to complete for an internship. 

The goal is to pass a flat file (CSV etc) and determine the format of the data in each column and identify the appropriate data type. 

Would love any help I can get! I will be developing in Python. ",6,0
857,2017-6-21,2017,6,21,22,6ilxi1,Using feedback to improve ML accuracy. Interested in your feedback on our applied ML approach in IoT.,https://www.reddit.com/r/MachineLearning/comments/6ilxi1/using_feedback_to_improve_ml_accuracy_interested/,BrightWolfIIoT,1498052986,,0,1
858,2017-6-21,2017,6,21,23,6im2r8,[R] From DeepMind: Grounded Language Learning in a Simulated 3D World,https://www.reddit.com/r/MachineLearning/comments/6im2r8/r_from_deepmind_grounded_language_learning_in_a/,pauljasek,1498054525,,19,13
859,2017-6-21,2017,6,21,23,6im55x,Tensorflow Implementation of Relation Networks and Sort-of-CLEVR,https://www.reddit.com/r/MachineLearning/comments/6im55x/tensorflow_implementation_of_relation_networks/,[deleted],1498055229,[deleted],0,1
860,2017-6-21,2017,6,21,23,6im62s,[D] 10 Data Science Podcasts You Need To be Listening To Right Now,https://www.reddit.com/r/MachineLearning/comments/6im62s/d_10_data_science_podcasts_you_need_to_be/,_alphamaximus_,1498055474,,0,5
861,2017-6-21,2017,6,21,23,6im98r,"[N] Yoshua Bengio and Microsoft: ""Inside Microsoft's AI Comeback""",https://www.reddit.com/r/MachineLearning/comments/6im98r/n_yoshua_bengio_and_microsoft_inside_microsofts/,gwern,1498056366,,22,7
862,2017-6-21,2017,6,21,23,6im9ts,"Predicting similarity scores for a dataset of ocean images, without any ground truth image.",https://www.reddit.com/r/MachineLearning/comments/6im9ts/predicting_similarity_scores_for_a_dataset_of/,zingerburg,1498056514,[removed],0,1
863,2017-6-22,2017,6,22,0,6imh4a,[News] Self Driving Car Learns Online and On-board on Raspberry Pi 3,https://www.reddit.com/r/MachineLearning/comments/6imh4a/news_self_driving_car_learns_online_and_onboard/,CireNeikual,1498058346,,22,180
864,2017-6-22,2017,6,22,0,6imh53,Video Games and Machine Learning @ICML2017 (Sydney),https://www.reddit.com/r/MachineLearning/comments/6imh53/video_games_and_machine_learning_icml2017_sydney/,snippyhollow,1498058353,,0,1
865,2017-6-22,2017,6,22,0,6impq1,"Simple Questions Thread June 21, 2017",https://www.reddit.com/r/MachineLearning/comments/6impq1/simple_questions_thread_june_21_2017/,AutoModerator,1498060529,[removed],0,1
866,2017-6-22,2017,6,22,1,6ims2n,[P] MultiModel: Multi-Task Machine Learning Across Domains,https://www.reddit.com/r/MachineLearning/comments/6ims2n/p_multimodel_multitask_machine_learning_across/,wei_jok,1498061104,,1,19
867,2017-6-22,2017,6,22,1,6in09j,You Don&amp;#039;t Need A PhD To Master Machine Learning &amp; Data Science - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6in09j/you_don039t_need_a_phd_to_master_machine_learning/,conradcreates,1498063203,,0,1
868,2017-6-22,2017,6,22,3,6innhc,[D] Do you know of any papers or projects that estimate body weight from a photo?,https://www.reddit.com/r/MachineLearning/comments/6innhc/d_do_you_know_of_any_papers_or_projects_that/,Maddhatta,1498068795,"I've found ""A computational approach to body mass index prediction from face images."", but I am having trouble finding any other similar projects / papers. Thank you.",20,13
869,2017-6-22,2017,6,22,3,6inny0,[P]Need soccer match data,https://www.reddit.com/r/MachineLearning/comments/6inny0/pneed_soccer_match_data/,bill_hatkins,1498068910,"I need player stats data which consists the assists, goals and other attributes of the player for every match and in aggregation. Further, I need team wise data based on similar attributes. Any suggestions for a source? ",4,0
870,2017-6-22,2017,6,22,3,6inuid,Predicting review scores (1-10). How to limit the regression output to this range?,https://www.reddit.com/r/MachineLearning/comments/6inuid/predicting_review_scores_110_how_to_limit_the/,[deleted],1498070538,[removed],0,1
871,2017-6-22,2017,6,22,4,6io4no,Machine Learning in High-Frequency Algorithmic Trading.,https://www.reddit.com/r/MachineLearning/comments/6io4no/machine_learning_in_highfrequency_algorithmic/,TempleRun99,1498073008,,0,1
872,2017-6-22,2017,6,22,4,6ioc9j,Improve Software Quality with AI and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6ioc9j/improve_software_quality_with_ai_and_machine/,codemonkeyai,1498074971,,0,1
873,2017-6-22,2017,6,22,5,6iogg1,UG090Z0A Underrulle Lower roller Takeuchi TB145 TB153 TB250 TB53 Rolka dolna,https://www.reddit.com/r/MachineLearning/comments/6iogg1/ug090z0a_underrulle_lower_roller_takeuchi_tb145/,BMash-pl,1498076015,,1,1
874,2017-6-22,2017,6,22,7,6ipaub,implementation of the keras frcnn,https://www.reddit.com/r/MachineLearning/comments/6ipaub/implementation_of_the_keras_frcnn/,SSS44,1498083994,[removed],0,1
875,2017-6-22,2017,6,22,8,6ipl3o,A Protocol for Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/6ipl3o/a_protocol_for_artificial_intelligence/,n_jai,1498086988,,0,1
876,2017-6-22,2017,6,22,8,6ipmhe,Paving Contractors and Asphalt Driveway,https://www.reddit.com/r/MachineLearning/comments/6ipmhe/paving_contractors_and_asphalt_driveway/,gwenyosef,1498087411,,0,1
877,2017-6-22,2017,6,22,9,6ipubp,[D] With Apple releasing CoreML they also demoed handwriting recognition in their Notes app. Any thoughts on what models they could potentially be using?,https://www.reddit.com/r/MachineLearning/comments/6ipubp/d_with_apple_releasing_coreml_they_also_demoed/,ink_golem,1498089774,,4,14
878,2017-6-22,2017,6,22,9,6iq5i8,[D] What are your favorite ways for dealing with class imbalance in data?,https://www.reddit.com/r/MachineLearning/comments/6iq5i8/d_what_are_your_favorite_ways_for_dealing_with/,Paddapa,1498093099,"In particular, I'm interested in the setting of training a convolutional neural net classifier. Data set has muuuuuuuch more of one class than the other.

I remember hearing/reading somewhere that Bayesian optimization can sometimes be used for this, but I don't know how. Any references or explanations of this?",25,37
879,2017-6-22,2017,6,22,10,6iq6kw,[R] MEC: Memory-efficient Convolution for Deep Neural Network,https://www.reddit.com/r/MachineLearning/comments/6iq6kw/r_mec_memoryefficient_convolution_for_deep_neural/,xternalz,1498093413,,4,51
880,2017-6-22,2017,6,22,10,6iqc10,[D] How do you keep your research thoughts organized?,https://www.reddit.com/r/MachineLearning/comments/6iqc10/d_how_do_you_keep_your_research_thoughts_organized/,godofprobability,1498095079,"Being a PhD student in Computer Vision, I am involved in a lot of research work. A typical week while working on a project spends in coming up with idea, brain-storming the idea, coding it, analyzing the results and planning improvements etc. Sometimes, a project moves so fast that it becomes difficult to keep track of exact trajectory of thoughts that lead me to present situation. 
To overcome this, I keep an ""org"" file in which I write what I am doing now, but I remove what I did in the past, just to keep things simpler/clearer. For each project, I make an org file with several sections like ""ideas"" (wild ideas that I come up with), ""experiments todo"" (pending experiments), ""observations"" (conclusions), ""problems""(problems with my approach) and ""meetings"" (details of meetings with my advisors). But this approach doesn't connect thoughts across time.

I am wondering how other people manage their ideas and keep track of their journey in the project. Please share ways in which you manage your thoughts.",20,13
881,2017-6-22,2017,6,22,11,6iqie0,Electrical Safety Switch,https://www.reddit.com/r/MachineLearning/comments/6iqie0/electrical_safety_switch/,gwenyosef,1498097064,,0,1
882,2017-6-22,2017,6,22,11,6iqjzo,How do you look about the chemical resins blender industry?,https://www.reddit.com/r/MachineLearning/comments/6iqjzo/how_do_you_look_about_the_chemical_resins_blender/,JCT_MACHINE,1498097583,,0,1
883,2017-6-22,2017,6,22,11,6iql84,[D] Convert from Normalized CieLAB to RGB,https://www.reddit.com/r/MachineLearning/comments/6iql84/d_convert_from_normalized_cielab_to_rgb/,Cock-tail,1498097965,"I am building a ConvNet to colorize B&amp;W images.
It basically maps the L dimension of the image to the ab dimensions.
An image is converted to the LAB color space, from RGB.
It is then Normalized like this:
    
    l_channel /= 100
    a_channel = (a_channel - a_channel.min()) / (a_channel.max() - a_channel.min())
    b_channel = (b_channel - b_channel.min()) / (b_channel.max() - b_channel.min())

The last activation function is a sigmoid, which results in a (224, 224, 2) tensor, with values between [0, 1], which are compared using the mean-squared-loss with the real normalized values(a (224, 224, 2) tensor representing the *ab* dimension) of the initial image.

It's all good until actual evaluation. The model colorizes well in the LAB space, but I have no idea how to map the generated image to the RGB space, because the values are normalized.

Should I change the architecture and just map to the actual values of *ab*?",3,0
884,2017-6-22,2017,6,22,11,6iqrwp,[Project] Project Idea - Color Sorting,https://www.reddit.com/r/MachineLearning/comments/6iqrwp/project_project_idea_color_sorting/,ece20,1498100043,"So I am a novice to machine learning. I was hoping to learn ML through a project where I would use ML take images of clothes and sort them into ""whites"", ""lights"", ""darks"". Is this something doable? Or am I biting more than I can chew",6,0
885,2017-6-22,2017,6,22,12,6ir11u,[D] Why is attention model worse than non-attention model?,https://www.reddit.com/r/MachineLearning/comments/6ir11u/d_why_is_attention_model_worse_than_nonattention/,0b01,1498103070,"I am using seq2seq to model the sine function. The source and target sequence each has 1000 time steps. Training parameters are exactly the same. Only difference is attention mechanism. Here are the loss functions:

http://imgur.com/a/JoUrp

So... why is the attentional model performing worse? Is it because the sequence is too easy and uniform?",7,0
886,2017-6-22,2017,6,22,13,6iragl,[D] Is there an API that lets OpenAI Universe plug into any game?,https://www.reddit.com/r/MachineLearning/comments/6iragl/d_is_there_an_api_that_lets_openai_universe_plug/,Abstractoid,1498106364,"Right now every game on the environments page says ""coming soon."" Is there a way I can either use universe or any other API to connect to a game that I own and try to make an unsupervised algorithm work on there? Like if I launch a game on my desktop, let's say Portal. Is there a way to have an algorithm connect to it and give it full (or maybe not quite full) access to the keyboard and mouse to play the game? Even if this involves playing a game with no rewards and full access to the menus, I think it would still be a nice thing to be able to work with. Is there anything out there already or should I work for a few months and post again with a [P] tag?",9,16
887,2017-6-22,2017,6,22,13,6irb5n,Alat Cetak Briket Manual,https://www.reddit.com/r/MachineLearning/comments/6irb5n/alat_cetak_briket_manual/,madanitec,1498106620,,0,1
888,2017-6-22,2017,6,22,14,6irepi,UPS Power Supply and Battery Backup,https://www.reddit.com/r/MachineLearning/comments/6irepi/ups_power_supply_and_battery_backup/,gwenyosef,1498107931,,0,1
889,2017-6-22,2017,6,22,14,6irj3g,AUTO CUTTING MACHINE,https://www.reddit.com/r/MachineLearning/comments/6irj3g/auto_cutting_machine/,ada2017,1498109612,,0,1
890,2017-6-22,2017,6,22,15,6irpkc,"""[R]"" SVCCA: Singular Vector Canonical Correlation Analysis for Deep Understanding and Improvement",https://www.reddit.com/r/MachineLearning/comments/6irpkc/r_svcca_singular_vector_canonical_correlation/,[deleted],1498112231,[deleted],0,1
891,2017-6-22,2017,6,22,15,6irr9g,[R] SVCCA: Singular Vector Canonical Correlation Analysis for Deep Understanding and Improvement,https://www.reddit.com/r/MachineLearning/comments/6irr9g/r_svcca_singular_vector_canonical_correlation/,mlenthusiast9,1498112964,,4,11
892,2017-6-22,2017,6,22,16,6irxih,[R] Grounded Language Learning in a Simulated 3D World,https://www.reddit.com/r/MachineLearning/comments/6irxih/r_grounded_language_learning_in_a_simulated_3d/,verveandfervor,1498115601,,1,8
893,2017-6-22,2017,6,22,16,6irygm,rotating disk filling and capping machine,https://www.reddit.com/r/MachineLearning/comments/6irygm/rotating_disk_filling_and_capping_machine/,hymachinery,1498116016,,1,1
894,2017-6-22,2017,6,22,16,6iryny,[NSFW] &gt;:},https://www.reddit.com/r/MachineLearning/comments/6iryny/nsfw/,[deleted],1498116113,[deleted],0,1
895,2017-6-22,2017,6,22,16,6is08s,"PET bottle filling machine, bottle filling and capping machine, mineral water plant",https://www.reddit.com/r/MachineLearning/comments/6is08s/pet_bottle_filling_machine_bottle_filling_and/,stevenwangfilling,1498116841,,0,1
896,2017-6-22,2017,6,22,16,6is2z3,Shower Repair Services,https://www.reddit.com/r/MachineLearning/comments/6is2z3/shower_repair_services/,gwenyosef,1498118150,,0,1
897,2017-6-22,2017,6,22,17,6is3qf,Microsoft Launches A Machine Learning And AI Powered Selfie App,https://www.reddit.com/r/MachineLearning/comments/6is3qf/microsoft_launches_a_machine_learning_and_ai/,digitalmarketingrobi,1498118531,,0,1
898,2017-6-22,2017,6,22,17,6is7g5,"If I'm doing research for a pattern recognition problem or classification problem, what can I do in progress?",https://www.reddit.com/r/MachineLearning/comments/6is7g5/if_im_doing_research_for_a_pattern_recognition/,Laurence-Lin,1498120353,[removed],0,1
899,2017-6-22,2017,6,22,17,6is9zz,[HELP] Generate a BayNet in R Language using a given dataset,https://www.reddit.com/r/MachineLearning/comments/6is9zz/help_generate_a_baynet_in_r_language_using_a/,[deleted],1498121640,[removed],0,1
900,2017-6-22,2017,6,22,17,6isa0b,AI-progress-metrics,https://www.reddit.com/r/MachineLearning/comments/6isa0b/aiprogressmetrics/,iamjessyuan,1498121645,,0,1
901,2017-6-22,2017,6,22,17,6isamz,[P] Project idea that includes Robot controller,https://www.reddit.com/r/MachineLearning/comments/6isamz/p_project_idea_that_includes_robot_controller/,[deleted],1498121947,[deleted],2,0
902,2017-6-22,2017,6,22,18,6isbuw,Help regarding Neural Networks implementation to estimate sub-glacial topography.,https://www.reddit.com/r/MachineLearning/comments/6isbuw/help_regarding_neural_networks_implementation_to/,hvb97,1498122473,[removed],0,1
903,2017-6-22,2017,6,22,19,6isiuw,How to Optimize Facebook Campaigns Based on Conversion Data,https://www.reddit.com/r/MachineLearning/comments/6isiuw/how_to_optimize_facebook_campaigns_based_on/,luba_belokon,1498125642,,0,1
904,2017-6-22,2017,6,22,19,6isl8e,Gas Hot Water System Repairs,https://www.reddit.com/r/MachineLearning/comments/6isl8e/gas_hot_water_system_repairs/,gwenyosef,1498126677,,0,1
905,2017-6-22,2017,6,22,20,6issae,[N]Envisioning the Future of Intelligent Applications,https://www.reddit.com/r/MachineLearning/comments/6issae/nenvisioning_the_future_of_intelligent/,digitalson,1498129606,,0,0
906,2017-6-22,2017,6,22,21,6it0vh,"[P] Car Simulator: fuzzy control system, genetic algorithm and PSO in JavaScript",https://www.reddit.com/r/MachineLearning/comments/6it0vh/p_car_simulator_fuzzy_control_system_genetic/,Jasonnor,1498132873,,2,0
907,2017-6-22,2017,6,22,21,6it4dv,Getting started with XGBoost,https://www.reddit.com/r/MachineLearning/comments/6it4dv/getting_started_with_xgboost/,DrLegend,1498134024,,0,1
908,2017-6-22,2017,6,22,21,6it9go,Deep learning for predictive maintenance with Long Short Term Memory Networks | Blog | Microsoft Azure,https://www.reddit.com/r/MachineLearning/comments/6it9go/deep_learning_for_predictive_maintenance_with/,steccami,1498135678,,0,1
909,2017-6-22,2017,6,22,22,6itbwb,Automating The Law: A Landscape of Legal A.I. Solutions - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6itbwb/automating_the_law_a_landscape_of_legal_ai/,conradcreates,1498136454,,0,1
910,2017-6-22,2017,6,22,22,6itcsu,Deep Learning With The Beast,https://www.reddit.com/r/MachineLearning/comments/6itcsu/deep_learning_with_the_beast/,[deleted],1498136722,[deleted],0,1
911,2017-6-22,2017,6,22,22,6itdxw,"[D] Intuitively, why DL model can't learn to transform into hyperbolic space if it's so much better?",https://www.reddit.com/r/MachineLearning/comments/6itdxw/d_intuitively_why_dl_model_cant_learn_to/,spring_stream,1498137057,"After reading https://medium.com/towards-data-science/facebook-research-just-published-an-awesome-paper-on-learning-hierarchical-representations-34e3d829ede7 and glancing through https://arxiv.org/pdf/1705.08039.pdf - I wonder why, if DL models are good at discovering structure behind the phenomena, can't they self-learn to use representation in hyperbolic space?

Or may be they do have such representation internally but we only train and query for embeddings in euclidian space and ignore more useful internal representations? ",14,31
912,2017-6-22,2017,6,22,22,6iteka,What is Disentangled learning,https://www.reddit.com/r/MachineLearning/comments/6iteka/what_is_disentangled_learning/,abhinonymous,1498137257,[removed],0,1
913,2017-6-22,2017,6,22,22,6itfgb,[D] Neural net architecture for multiscale time series?,https://www.reddit.com/r/MachineLearning/comments/6itfgb/d_neural_net_architecture_for_multiscale_time/,smthamazing,1498137550,"I have a time series data of a certain variable with values for each hour, on the duration of many months. I need to make an hourly prediction of that value for several months into the future. The value probably depends on the month, week, day of week and hour of the day.

I attempt to solve this problem using RNNs. But what would be the right architecture in this case? Are there any papers or articles?

Thanks! ",9,0
914,2017-6-22,2017,6,22,23,6itowo,Data Scientist Resume Projects,https://www.reddit.com/r/MachineLearning/comments/6itowo/data_scientist_resume_projects/,[deleted],1498140401,[deleted],0,1
915,2017-6-22,2017,6,22,23,6itrr7,[N] Data Scientist Resume Projects,https://www.reddit.com/r/MachineLearning/comments/6itrr7/n_data_scientist_resume_projects/,[deleted],1498141169,[deleted],0,2
916,2017-6-22,2017,6,22,23,6itv8e,[N] Data Scientist Resume Projects,https://www.reddit.com/r/MachineLearning/comments/6itv8e/n_data_scientist_resume_projects/,luba_belokon,1498142113,,3,8
917,2017-6-22,2017,6,22,23,6itxeb,Bayesian inference and ConvNets,https://www.reddit.com/r/MachineLearning/comments/6itxeb/bayesian_inference_and_convnets/,ankit0912,1498142692,[removed],0,1
918,2017-6-22,2017,6,22,23,6iu01m,Probabilistic programming from scratch,https://www.reddit.com/r/MachineLearning/comments/6iu01m/probabilistic_programming_from_scratch/,craeko,1498143361,,0,1
919,2017-6-23,2017,6,23,0,6iu168,The Biggest Shift in Supercomputing Since GPU Acceleration,https://www.reddit.com/r/MachineLearning/comments/6iu168/the_biggest_shift_in_supercomputing_since_gpu/,[deleted],1498143649,[deleted],0,1
920,2017-6-23,2017,6,23,0,6iu57s,[D] Class-conditioned convolutional neural networks,https://www.reddit.com/r/MachineLearning/comments/6iu57s/d_classconditioned_convolutional_neural_networks/,pauljasek,1498144645,Is anyone aware of work in which convolutional filters are generated based on a class and the output is a 1-d vector indicating whether the class was detected? Or something similar?,1,1
921,2017-6-23,2017,6,23,0,6iu5x5,Understanding The Limits Of Deep Learning - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6iu5x5/understanding_the_limits_of_deep_learning_topbots/,conradcreates,1498144825,,0,1
922,2017-6-23,2017,6,23,0,6iu7qp,[D] Bayesian Parameter Estimation and ConvNets,https://www.reddit.com/r/MachineLearning/comments/6iu7qp/d_bayesian_parameter_estimation_and_convnets/,ankit0912,1498145306,"I came across this (paper)[https://arxiv.org/pdf/1705.09558.pdf], which estimate the generator and discriminator parameters using a Bayesian approach with GANs. I was wondering if there have been any approaches to estimate the posterior probabilities of an image, say for a semantic segmentation problem. Any thoughts?",9,5
923,2017-6-23,2017,6,23,0,6iuadv,Creative AI on the iPhone: Generative Adversarial Networks with Apple's CoreML Tools (x-post from r/programming ),https://www.reddit.com/r/MachineLearning/comments/6iuadv/creative_ai_on_the_iphone_generative_adversarial/,Peanuts4MePlz,1498145969,,0,1
924,2017-6-23,2017,6,23,0,6iuc7k,Further Exploring Common Probabilistic Models,https://www.reddit.com/r/MachineLearning/comments/6iuc7k/further_exploring_common_probabilistic_models/,awhlop,1498146432,,0,1
925,2017-6-23,2017,6,23,1,6iuh80,Limitations of Natural Language Understanding in messy note-taking text?,https://www.reddit.com/r/MachineLearning/comments/6iuh80/limitations_of_natural_language_understanding_in/,vevsdvsd35,1498147679,[removed],0,1
926,2017-6-23,2017,6,23,1,6iuj8r,MNIST: How to eliminate False-Positives for scaled digits?,https://www.reddit.com/r/MachineLearning/comments/6iuj8r/mnist_how_to_eliminate_falsepositives_for_scaled/,AiTobs,1498148175,[removed],0,1
927,2017-6-23,2017,6,23,1,6iukrg,[N] Inferring Tweet Quality From Retweets,https://www.reddit.com/r/MachineLearning/comments/6iukrg/n_inferring_tweet_quality_from_retweets/,lalypopa123,1498148553,,1,34
928,2017-6-23,2017,6,23,2,6iuwct,An introduction to Support Vector Machines,https://www.reddit.com/r/MachineLearning/comments/6iuwct/an_introduction_to_support_vector_machines/,wildcodegowrong,1498151366,,0,1
929,2017-6-23,2017,6,23,2,6iv7ht,Salary -- how to negotiate?,https://www.reddit.com/r/MachineLearning/comments/6iv7ht/salary_how_to_negotiate/,phdsalary,1498154030,[removed],0,1
930,2017-6-23,2017,6,23,2,6iv8af,Can training labels be a pair of numbers?,https://www.reddit.com/r/MachineLearning/comments/6iv8af/can_training_labels_be_a_pair_of_numbers/,BeefJurky,1498154228,[removed],0,1
931,2017-6-23,2017,6,23,2,6iv8at,Demo App For Skin Cancer Multiple Skin Conditions Diagnosis in Real Time Using Tensorflow Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6iv8at/demo_app_for_skin_cancer_multiple_skin_conditions/,[deleted],1498154230,[deleted],0,1
932,2017-6-23,2017,6,23,3,6ivavs,5 Secrets Your Tweets Reveal About You - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6ivavs/5_secrets_your_tweets_reveal_about_you_topbots/,conradcreates,1498154840,,0,1
933,2017-6-23,2017,6,23,3,6ivj6f,[D] How to preprocess multivariate and multimodal time-series data,https://www.reddit.com/r/MachineLearning/comments/6ivj6f/d_how_to_preprocess_multivariate_and_multimodal/,ObserverAtNight,1498156878,"Hi all,

I am currently working on a project to classify time-series data. The data looks like this:

I have a glove that records pressure on my handpalm (64 cells spread across the palm, means 64 dimension of tactile data). Furthermore I also have on top of the glove bending sensors on the finger joints, 18 in numbers. Means here also 18 dimensions of data. 

So I basically have 2 time-series. The 64-dim tactile one and the 18-dim bending one. What would be a good way of preprocessing this? I want to train a LSTM that can classify different objects that one touches/explores. The Problem I have is that this are two different sensor values I get for the both modalities. Is there any way to connect them? First time working with time-series so I am not sure how to approach this. Thank you in advance.",7,18
934,2017-6-23,2017,6,23,4,6ivztx,Multi-Objective Problems: an introduction,https://www.reddit.com/r/MachineLearning/comments/6ivztx/multiobjective_problems_an_introduction/,[deleted],1498161055,[deleted],1,1
935,2017-6-23,2017,6,23,5,6iw8qo,Demo App For Skin Cancer Diagnosis in Real Time Using Tensorflow Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6iw8qo/demo_app_for_skin_cancer_diagnosis_in_real_time/,[deleted],1498163272,[deleted],0,1
936,2017-6-23,2017,6,23,5,6iwc0k,[D] Deep Learning in the web,https://www.reddit.com/r/MachineLearning/comments/6iwc0k/d_deep_learning_in_the_web/,Sig_Luna,1498164075,"Hello there,
I wanted to ask if there are any good resources about deploying deep learning models to the web.
I'm currently working on a few projects with Tensorflow and Keras (reg. Image analysis with CNNs) and I want to put the model on a  webapp (e.g. using Django) so everyone can try it.",2,4
937,2017-6-23,2017,6,23,5,6iwcn8,[R] Two-Stream Convolutional Networks for Dynamic Texture Synthesis,https://www.reddit.com/r/MachineLearning/comments/6iwcn8/r_twostream_convolutional_networks_for_dynamic/,tesfaldet,1498164236,,0,30
938,2017-6-23,2017,6,23,6,6iwov0,4 Approaches To Natural Language Processing &amp; Understanding - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6iwov0/4_approaches_to_natural_language_processing/,conradcreates,1498167125,,0,1
939,2017-6-23,2017,6,23,6,6iwtb4,Python Plotting for Exploratory Analysis,https://www.reddit.com/r/MachineLearning/comments/6iwtb4/python_plotting_for_exploratory_analysis/,cavedave,1498168270,,12,55
940,2017-6-23,2017,6,23,8,6ixbj6,[P]Demo App For Skin Cancer Diagnosis in Real Time Using Tensorflow Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6ixbj6/pdemo_app_for_skin_cancer_diagnosis_in_real_time/,deep2018,1498173376,,44,120
941,2017-6-23,2017,6,23,9,6ixny3,Resources for Updated Tensorflow Seq2Seq ML,https://www.reddit.com/r/MachineLearning/comments/6ixny3/resources_for_updated_tensorflow_seq2seq_ml/,nave01314,1498176981,[removed],0,1
942,2017-6-23,2017,6,23,10,6iy33x,A Professional Company Offers Sand Making Machines And Crushers - SeaSun Machinery,https://www.reddit.com/r/MachineLearning/comments/6iy33x/a_professional_company_offers_sand_making/,[deleted],1498181589,[deleted],0,1
943,2017-6-23,2017,6,23,11,6iyane,Bricklayer Tools,https://www.reddit.com/r/MachineLearning/comments/6iyane/bricklayer_tools/,gwenyosef,1498183959,,0,1
944,2017-6-23,2017,6,23,11,6iycs8,Machine solution for making plastic straw,https://www.reddit.com/r/MachineLearning/comments/6iycs8/machine_solution_for_making_plastic_straw/,Chengrufeng,1498184624,[removed],0,1
945,2017-6-23,2017,6,23,11,6iyevk,[D] Attention softmax values,https://www.reddit.com/r/MachineLearning/comments/6iyevk/d_attention_softmax_values/,bronzestick,1498185294,"How do you ensure that your model only attends to few values? Currently, when I use a soft attention model over a fixed length vector, it assigns almost the same softmax weight to each hidden state. 

I have tried tweaking the temperature so that the unnormalized scores are not close to each other (hence, resulting in varying softmax weights). But, is there a better way? Any works that deal with this issue?",7,3
946,2017-6-23,2017,6,23,12,6iyp0p,I'm looking to hire someone to create a 100% free machine learning course for all of Reddit,https://www.reddit.com/r/MachineLearning/comments/6iyp0p/im_looking_to_hire_someone_to_create_a_100_free/,[deleted],1498188586,[removed],0,1
947,2017-6-23,2017,6,23,13,6iz4au,Electrical Testing and Tagging,https://www.reddit.com/r/MachineLearning/comments/6iz4au/electrical_testing_and_tagging/,gwenyosef,1498193980,,0,1
948,2017-6-23,2017,6,23,14,6iz4dy,Why are Clockwork RNNs not used more?,https://www.reddit.com/r/MachineLearning/comments/6iz4dy/why_are_clockwork_rnns_not_used_more/,[deleted],1498194017,[removed],0,1
949,2017-6-23,2017,6,23,14,6iz5q4,Which model to use for image time series prediction?,https://www.reddit.com/r/MachineLearning/comments/6iz5q4/which_model_to_use_for_image_time_series/,beef__,1498194491,[removed],0,1
950,2017-6-23,2017,6,23,14,6iz6ea,Reservoir computing and Softmax,https://www.reddit.com/r/MachineLearning/comments/6iz6ea/reservoir_computing_and_softmax/,theoneandonlypatriot,1498194747,[removed],0,1
951,2017-6-23,2017,6,23,14,6iz881,[D] Why are Clockwork RNNs not used more?,https://www.reddit.com/r/MachineLearning/comments/6iz881/d_why_are_clockwork_rnns_not_used_more/,SkiddyX,1498195486,"I see people bring them up on this subreddit occasionally, but I don't really see any papers benchmark against them or attempts to improve them. Does anyone have any experience they would be willing to share?",18,29
952,2017-6-23,2017,6,23,14,6izb5v,Can someone clarify the differences between a conference tutorial and a conference workshop.,https://www.reddit.com/r/MachineLearning/comments/6izb5v/can_someone_clarify_the_differences_between_a/,[deleted],1498196680,[removed],0,1
953,2017-6-23,2017,6,23,14,6izde2,[R] Pixels to Graphs by Associative Embedding,https://www.reddit.com/r/MachineLearning/comments/6izde2/r_pixels_to_graphs_by_associative_embedding/,visarga,1498197580,,15,25
954,2017-6-23,2017,6,23,15,6izepc,[D] The Kaggle data science community is competing to improve airport security with AI,https://www.reddit.com/r/MachineLearning/comments/6izepc/d_the_kaggle_data_science_community_is_competing/,_alphamaximus_,1498198143,,1,0
955,2017-6-23,2017,6,23,16,6izne8,Deep Submodular Functions,https://www.reddit.com/r/MachineLearning/comments/6izne8/deep_submodular_functions/,wandering007,1498201856,,0,1
956,2017-6-23,2017,6,23,16,6iznrn,A Wavenet for Speech Denoising,https://www.reddit.com/r/MachineLearning/comments/6iznrn/a_wavenet_for_speech_denoising/,jordipons_bcn,1498202015,,0,1
957,2017-6-23,2017,6,23,17,6iztw4,[D] Implementation of Sequential Data GAN tested by concatenated MNIST data,https://www.reddit.com/r/MachineLearning/comments/6iztw4/d_implementation_of_sequential_data_gan_tested_by/,jaesik,1498204822,,3,9
958,2017-6-23,2017,6,23,17,6izyql,Whom/what to follow for Deep Learning in Biomedical Imaging?,https://www.reddit.com/r/MachineLearning/comments/6izyql/whomwhat_to_follow_for_deep_learning_in/,hmi2015,1498207158,[removed],0,1
959,2017-6-23,2017,6,23,19,6j0g6d,[N] 65 Free Data Science Resources for Beginners,https://www.reddit.com/r/MachineLearning/comments/6j0g6d/n_65_free_data_science_resources_for_beginners/,molode,1498215163,,0,0
960,2017-6-23,2017,6,23,19,6j0geo,[N] SQL WHERE clause | Data Analysis in SQL for beginners (ep2),https://www.reddit.com/r/MachineLearning/comments/6j0geo/n_sql_where_clause_data_analysis_in_sql_for/,digitalson,1498215271,,1,0
961,2017-6-23,2017,6,23,19,6j0gmv,[N] Gradient Boosting - the coolest kid on the machine learning block,https://www.reddit.com/r/MachineLearning/comments/6j0gmv/n_gradient_boosting_the_coolest_kid_on_the/,magneticono,1498215380,,0,0
962,2017-6-23,2017,6,23,19,6j0gwn,[N] Automate your Machine Learning in Python  TPOT and Genetic Algorithms,https://www.reddit.com/r/MachineLearning/comments/6j0gwn/n_automate_your_machine_learning_in_python_tpot/,friscotime,1498215504,,8,7
963,2017-6-23,2017,6,23,20,6j0hha,[N] 4 Big Ways Data Science is Transforming the FinTech Industry,https://www.reddit.com/r/MachineLearning/comments/6j0hha/n_4_big_ways_data_science_is_transforming_the/,awhlop,1498215747,,0,0
964,2017-6-23,2017,6,23,20,6j0hqh,[N] Slack Maestro: Helping users stay on topic,https://www.reddit.com/r/MachineLearning/comments/6j0hqh/n_slack_maestro_helping_users_stay_on_topic/,trumtra,1498215849,,0,12
965,2017-6-23,2017,6,23,20,6j0i54,[N] Exploring and visualising reef life survey data,https://www.reddit.com/r/MachineLearning/comments/6j0i54/n_exploring_and_visualising_reef_life_survey_data/,lalypopa123,1498216012,,0,15
966,2017-6-23,2017,6,23,20,6j0l2o,Heat Pump Hot Water System,https://www.reddit.com/r/MachineLearning/comments/6j0l2o/heat_pump_hot_water_system/,gwenyosef,1498217173,,0,1
967,2017-6-23,2017,6,23,21,6j0ww5,Today our planetary mixer shipped to Shenzhen--planetary mixer supplier,https://www.reddit.com/r/MachineLearning/comments/6j0ww5/today_our_planetary_mixer_shipped_to/,mixmachinery,1498221333,,0,1
968,2017-6-23,2017,6,23,21,6j10lh,"[P] Pruning deep neural networks and a PyTorch implementation of ""1611.06440 Pruning Convolutional Neural Networks for Resource Efficient Inference""",https://www.reddit.com/r/MachineLearning/comments/6j10lh/p_pruning_deep_neural_networks_and_a_pytorch/,jacobgil,1498222591,,2,61
969,2017-6-23,2017,6,23,22,6j17wb,[D] Mean Squared Error and R2 Score Diverge during training of a stacked ensemble,https://www.reddit.com/r/MachineLearning/comments/6j17wb/d_mean_squared_error_and_r2_score_diverge_during/,Delthc,1498224950,"Hello,

I am currently training a stacked regressor ensemble, consisting of Neural Network Regressors (1-2 layers, tanh-Activation in hidden, linear in output, inputs normalised to zero mean and unit variance).

The second ""stack layer"" (that means, these networks get the predictions of the first ""stack layer"" as inputs) has an average MSE that is quite above the MSE of the first layer's networks, however, the R^2 Scorer keeps improving, and so does the average real-value of all datasamples that had a prediction in the top 10%.

So, while the error per prediction seems to raise, the models ability to choose the ""top performers"" (in which I am interested) gets better tough.

The explanation I have is that perhaps the average prediction of the network moves further from the average of the real-values, but I cant see why the network - as it is trained using mean squared error as loss function - behaves like this..

So my 2 questions are: 
1) Does somebody have a hint for a perhaps better suited loss function?
2) Any idea why the networks behave in such a way after stacking?
",3,1
970,2017-6-23,2017,6,23,22,6j1bel,[N] Top 15 Python Libraries for Data Science in 2017,https://www.reddit.com/r/MachineLearning/comments/6j1bel/n_top_15_python_libraries_for_data_science_in_2017/,janemoz,1498226016,,1,1
971,2017-6-23,2017,6,23,23,6j1dom,"What are the known lower/upper bounds on a decision tree depth, based on the statistics labels / data?",https://www.reddit.com/r/MachineLearning/comments/6j1dom/what_are_the_known_lowerupper_bounds_on_a/,yuvval,1498226675,[removed],0,1
972,2017-6-23,2017,6,23,23,6j1jan,Dataset with false statements,https://www.reddit.com/r/MachineLearning/comments/6j1jan/dataset_with_false_statements/,[deleted],1498228259,[removed],0,1
973,2017-6-23,2017,6,23,23,6j1jlk,[D] False statement datasets ?,https://www.reddit.com/r/MachineLearning/comments/6j1jlk/d_false_statement_datasets/,Jean-Porte,1498228351,"Hello, where can I find a dataset with false sentences ? like ""sky is green"" ""tree are mammals"", etc ? General knowledge sentences are better. 
Fake news are related but aren't totally what I want (https://www.kaggle.com/mrisdal/fake-news )
Thanks",7,2
974,2017-6-24,2017,6,24,0,6j1r22,Best resource for ML and Data Science,https://www.reddit.com/r/MachineLearning/comments/6j1r22/best_resource_for_ml_and_data_science/,martainpeter,1498230387,[removed],0,1
975,2017-6-24,2017,6,24,0,6j1sh5,[R] [1706.07230] Gated-Attention Architectures for Task-Oriented Language Grounding,https://www.reddit.com/r/MachineLearning/comments/6j1sh5/r_170607230_gatedattention_architectures_for/,egrefen,1498230753,,1,13
976,2017-6-24,2017,6,24,1,6j28t9,[D] Why do people draw neural networks upside down?,https://www.reddit.com/r/MachineLearning/comments/6j28t9/d_why_do_people_draw_neural_networks_upside_down/,pmigdal,1498234928,"In English we read **from top to bottom**. Data flows (be it equations or flow charts) typically follow the same convention, so we can read articles in in a coherent way. Even **trees** (both data structures and decision trees), grow from their roots downwards (so, against their original biological metaphor).

However, in many neural architecture diagrams, this natural convention is broken, with data flowing **from bottom to top**, e.g.:

* [Dropout diagram](http://cs231n.github.io/assets/nn2/dropout.jpeg)
* modules in [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)
* [Visualizing CNN architectures side by side with mxnet](http://josephpcohen.com/w/visualizing-cnn-architectures-side-by-side-with-mxnet/)
* calling output layers as **top layers** (see `include_top` in https://keras.io/applications/)

Is there some reasoning for this counterintuitive (and potentially - counterproductive) convention?

(At least most of researchers write neural networks from left to right, consistent with English.)

EDIT: I meant **left to right** in the line above. A sign typo.",33,24
977,2017-6-24,2017,6,24,1,6j2agr,[P] mNeuron: A Matlab Plugin to Visualize Neurons from Deep Models,https://www.reddit.com/r/MachineLearning/comments/6j2agr/p_mneuron_a_matlab_plugin_to_visualize_neurons/,pmigdal,1498235338,,11,28
978,2017-6-24,2017,6,24,2,6j2i1z,7 Ways To Piss Off The A.I. Talent You&amp;#039;re Trying To Recruit - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6j2i1z/7_ways_to_piss_off_the_ai_talent_you039re_trying/,conradcreates,1498237254,,0,1
979,2017-6-24,2017,6,24,2,6j2j2a,"Selling ""Python Machine Learning""",https://www.reddit.com/r/MachineLearning/comments/6j2j2a/selling_python_machine_learning/,FSBR_Tommy,1498237481,[removed],1,1
980,2017-6-24,2017,6,24,2,6j2o99,"[D] In the Machine Learning field, who should be the last author in a paper? The senior supervisor?",https://www.reddit.com/r/MachineLearning/comments/6j2o99/d_in_the_machine_learning_field_who_should_be_the/,safetynet1,1498238787,,11,3
981,2017-6-24,2017,6,24,2,6j2szd,"Feel like my kappa is 'too' high, can i trust it?",https://www.reddit.com/r/MachineLearning/comments/6j2szd/feel_like_my_kappa_is_too_high_can_i_trust_it/,BossangeloCad,1498239979,[removed],0,1
982,2017-6-24,2017,6,24,2,6j2va5,An approach to reachability analysis for feed-forward ReLU neural networks,https://www.reddit.com/r/MachineLearning/comments/6j2va5/an_approach_to_reachability_analysis_for/,aranganathan,1498240527,,0,1
983,2017-6-24,2017,6,24,3,6j30uu,[D] Most performing way to run pytorch-CycleGAN on Google Cloud?,https://www.reddit.com/r/MachineLearning/comments/6j30uu/d_most_performing_way_to_run_pytorchcyclegan_on/,Philipp,1498241954,Hi! What would your ideas be for a good way to run https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix on Google Cloud? What are the steps involved? Or maybe another cloud or hosting service is much more suited? Thank you!,2,0
984,2017-6-24,2017,6,24,3,6j32o6,[P] Using Deep Learning to Reconstruct High-Resolution Audio,https://www.reddit.com/r/MachineLearning/comments/6j32o6/p_using_deep_learning_to_reconstruct/,e_ameisen,1498242414,,1,0
985,2017-6-24,2017,6,24,4,6j3d54,"Swift, Perfect and Tensorflow (X-Post from r/Tensorflow)",https://www.reddit.com/r/MachineLearning/comments/6j3d54/swift_perfect_and_tensorflow_xpost_from/,perfectlysoft,1498245124,[removed],0,1
986,2017-6-24,2017,6,24,4,6j3e28,Andrew Ng cryptically unveils new project: deeplearning.ai,https://www.reddit.com/r/MachineLearning/comments/6j3e28/andrew_ng_cryptically_unveils_new_project/,geebr,1498245365,,0,3
987,2017-6-24,2017,6,24,4,6j3f68,[D] Studying deep learning in depth?,https://www.reddit.com/r/MachineLearning/comments/6j3f68/d_studying_deep_learning_in_depth/,nivm321,1498245658,"*I know there is a separate subreddit for learning ML but this is a more advanced question suitable to be answered by experts.*

What and how aspiring deep learning researchers should study? I think even there are a lot of tutorials explaining CNNs, RNNs etc. the ones which teach the concrete math required for research are rare. It would benefit aspiring researchers if you can suggest some resources which teach things like backprop,gradients etc. from the root.
",9,5
988,2017-6-24,2017,6,24,4,6j3g92,[D] Some gradients abnormally big during training. Should I clip them?,https://www.reddit.com/r/MachineLearning/comments/6j3g92/d_some_gradients_abnormally_big_during_training/,crouching_dragon_420,1498245952,"Hi everyone, I have been training some image/video generation models with Wasserstein GAN recently and tried to mess around Tensorboard a little bit. During the course, I found out that a small percentage of gradients in some of my parameters are as big as in the 25.0 - 30.0 range. This happens consistently over 50k training steps even though all parameters was initialised with standard deviation as small as 0.02. It baffled me though, because there was no gradient exploding, the model was stable, loss went down steadily and the output was as expected. I trained another model with gradient norm clipped to 5 for each individual parameters and the output quality of the two models was basically the same. I find this strange because that kind of big gradients should cause some irregularity in the first model and should have some impacts but turned out it's not. Has anyone else been in the same situation? How did it affect your models (or not)? Would you recommend clipping them even though there's no noticeable effects in the output?",6,6
989,2017-6-24,2017,6,24,4,6j3k3c,[P] Andrew Ng's deeplearning.ai project,https://www.reddit.com/r/MachineLearning/comments/6j3k3c/p_andrew_ngs_deeplearningai_project/,wei_jok,1498246988,,10,0
990,2017-6-24,2017,6,24,4,6j3kjb,[P] Implementation of Sparse Variational Dropout,https://www.reddit.com/r/MachineLearning/comments/6j3kjb/p_implementation_of_sparse_variational_dropout/,arsashuha,1498247105,,4,52
991,2017-6-24,2017,6,24,4,6j3muv,"Could a machine learning algorithm theoretically be made ""perfect"" given enough training data?",https://www.reddit.com/r/MachineLearning/comments/6j3muv/could_a_machine_learning_algorithm_theoretically/,theology_,1498247714,[removed],0,1
992,2017-6-24,2017,6,24,4,6j3ntm,Has anyone been successful running Tensorflow's Object Detection API?,https://www.reddit.com/r/MachineLearning/comments/6j3ntm/has_anyone_been_successful_running_tensorflows/,AndrewKemendo,1498247969,[removed],0,1
993,2017-6-24,2017,6,24,5,6j3rz6,Andrew Ng's new project announced,https://www.reddit.com/r/MachineLearning/comments/6j3rz6/andrew_ngs_new_project_announced/,MaxTalanov,1498249114,,0,1
994,2017-6-24,2017,6,24,5,6j3vmz,https://www.deeplearning.ai/,https://www.reddit.com/r/MachineLearning/comments/6j3vmz/httpswwwdeeplearningai/,[deleted],1498250110,[deleted],0,1
995,2017-6-24,2017,6,24,6,6j43ml,Starting point for deriving trends/correlations,https://www.reddit.com/r/MachineLearning/comments/6j43ml/starting_point_for_deriving_trendscorrelations/,oqowa,1498252312,[removed],0,1
996,2017-6-24,2017,6,24,7,6j4g2q,Upsampling in tensorflow,https://www.reddit.com/r/MachineLearning/comments/6j4g2q/upsampling_in_tensorflow/,[deleted],1498255862,[removed],0,1
997,2017-6-24,2017,6,24,7,6j4o3x,Detection network or cropped classification network?,https://www.reddit.com/r/MachineLearning/comments/6j4o3x/detection_network_or_cropped_classification/,bw4sz,1498258301,[removed],0,1
998,2017-6-24,2017,6,24,7,6j4ouv,[D] Upsampling in tensorflow,https://www.reddit.com/r/MachineLearning/comments/6j4ouv/d_upsampling_in_tensorflow/,maka89,1498258530,"Hi. I want to do a simple upsampling in tensorflow. Sample tensor [None, N] to [None,2*N] by repeating values. Ie. [[1,2],[3,4],...] goes to [[1,1,2,2],[3,3,4,4],...].

Seems simple enough, but how do I implement it? 
Thanks.",2,0
999,2017-6-24,2017,6,24,7,6j4oza,[D] Why does clamping weights enforce lipschitz constant?,https://www.reddit.com/r/MachineLearning/comments/6j4oza/d_why_does_clamping_weights_enforce_lipschitz/,machinelearningthrow,1498258569,"I was reading the Wasserstein GAN paper, and was wondering why does clamping weights enforces lipschitz constant.",5,23
1000,2017-6-24,2017,6,24,8,6j4wwt,Intel is hosting a free AI event for students (starts at 5PM) and professional developers during the OReilly AI Conference on June 27th in NYC!,https://www.reddit.com/r/MachineLearning/comments/6j4wwt/intel_is_hosting_a_free_ai_event_for_students/,caitlinpav,1498261097,,0,1
1001,2017-6-24,2017,6,24,10,6j5i4c,"Notes from reading ""Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour""",https://www.reddit.com/r/MachineLearning/comments/6j5i4c/notes_from_reading_accurate_large_minibatch_sgd/,fnbr,1498268091,,0,1
1002,2017-6-24,2017,6,24,11,6j5ojv,[P] Learning Joint Multilingual Sentence Representations with Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/6j5ojv/p_learning_joint_multilingual_sentence/,fnbr,1498270394,,0,19
1003,2017-6-24,2017,6,24,12,6j5xtl,"[R] [1706.07068] CAN: Creative Adversarial Networks, Generating ""Art"" by Learning About Styles and Deviating from Style Norms &lt;-- outranks real art at top art fairs",https://www.reddit.com/r/MachineLearning/comments/6j5xtl/r_170607068_can_creative_adversarial_networks/,evc123,1498273745,,19,85
1004,2017-6-24,2017,6,24,13,6j6b07,Geology + ML?,https://www.reddit.com/r/MachineLearning/comments/6j6b07/geology_ml/,johnsonjohn139,1498278906,[removed],0,1
1005,2017-6-24,2017,6,24,13,6j6bg5,How did Amazon create Amazon Echo with no user contribution?,https://www.reddit.com/r/MachineLearning/comments/6j6bg5/how_did_amazon_create_amazon_echo_with_no_user/,lninja1,1498279082,[removed],0,1
1006,2017-6-24,2017,6,24,14,6j6l51,cranes,https://www.reddit.com/r/MachineLearning/comments/6j6l51/cranes/,ada2017,1498283217,,0,1
1007,2017-6-24,2017,6,24,15,6j6o6j,What is a adhesives mixer with paddle,https://www.reddit.com/r/MachineLearning/comments/6j6o6j/what_is_a_adhesives_mixer_with_paddle/,JCT_MACHINE,1498284598,,0,1
1008,2017-6-24,2017,6,24,17,6j71pi,[P] Keras-vis: Toolkit to perform guided backprop for neural network visualizations,https://www.reddit.com/r/MachineLearning/comments/6j71pi/p_kerasvis_toolkit_to_perform_guided_backprop_for/,pmigdal,1498291423,,11,96
1009,2017-6-24,2017,6,24,17,6j73r8,How plausible is this? Has this been done?,https://www.reddit.com/r/MachineLearning/comments/6j73r8/how_plausible_is_this_has_this_been_done/,0b01,1498292530,[removed],0,1
1010,2017-6-24,2017,6,24,18,6j7bsr,[D] my random idea,https://www.reddit.com/r/MachineLearning/comments/6j7bsr/d_my_random_idea/,0b01,1498296970,"I just started learning RNN so I have a noob question:
A Neural Network that generates programs:
define arbitrary o = f(i)

0. save i, o, f where f is a tokenized AST

1. train simple feedforward NN using i and o, parameterized by W

2. decode W using LSTM with bahdanau attention

The cool thing about this is the AST can learn its embedding. And all data is generated.

Would also be interesting to see how quines are represented in the embedding space.",3,0
1011,2017-6-24,2017,6,24,19,6j7hrt,How can this crap be published in JMLR?,https://www.reddit.com/r/MachineLearning/comments/6j7hrt/how_can_this_crap_be_published_in_jmlr/,[deleted],1498300138,[removed],0,1
1012,2017-6-24,2017,6,24,19,6j7i1p,The GAN World,https://www.reddit.com/r/MachineLearning/comments/6j7i1p/the_gan_world/,savan77,1498300280,,0,1
1013,2017-6-24,2017,6,24,19,6j7jjg,"Any thought on paper ""Knowledge Matters: Importance of Prior Information for Optimization""?",https://www.reddit.com/r/MachineLearning/comments/6j7jjg/any_thought_on_paper_knowledge_matters_importance/,[deleted],1498301072,[removed],0,1
1014,2017-6-24,2017,6,24,19,6j7ku5,"[D] Any thought on ""Knowledge Matters: Importance of Prior Information for Optimization""?",https://www.reddit.com/r/MachineLearning/comments/6j7ku5/d_any_thought_on_knowledge_matters_importance_of/,moron_network,1498301758,"This paper seems lacks of theoretical advance. I dont see solid experiments either. I am curious how it got published in JMLR.
http://www.jmlr.org/papers/volume17/gulchere16a/gulchere16a.pdf",2,0
1015,2017-6-24,2017,6,24,19,6j7l8a,Hamiltonian Monte Carlo explained,https://www.reddit.com/r/MachineLearning/comments/6j7l8a/hamiltonian_monte_carlo_explained/,[deleted],1498301990,[deleted],1,1
1016,2017-6-24,2017,6,24,20,6j7oy7,Suggestions for after Learning From Data?,https://www.reddit.com/r/MachineLearning/comments/6j7oy7/suggestions_for_after_learning_from_data/,vivoludo,1498303929,"After finishing the Caltech Learning from Data course, I'm having a lot of trouble finding a good resource to further my learning. I want to be able to keep up with the latest literature, but more importantly, I want to be able to use machine learning practically in a wide range of contexts. 

If anyone's taken Learning From Data already, could you please help me:

1. Should I watch Andrew Ng's Stanford lectures on youtube (not Coursera)? From what I understand, this and the Caltech course overlap a lot.
2. If not, are there any books you recommend? 
3. How did you get really good at implementing/using machine learning for real practical projects? Kaggle?
4. How much of the following post is satire? Would it do me good to follow it? 

https://www.reddit.com/r/MachineLearning/comments/5z8110/d_a_super_harsh_guide_to_machine_learning/ 

Thanks a lot!",1,8
1017,2017-6-24,2017,6,24,21,6j7xhr,[R] Convergence Analysis of Batch Normalization for Deep Neural Nets,https://www.reddit.com/r/MachineLearning/comments/6j7xhr/r_convergence_analysis_of_batch_normalization_for/,xternalz,1498307656,,1,18
1018,2017-6-24,2017,6,24,21,6j7ymk,[P] Implementation of Dirac Networks in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/6j7ymk/p_implementation_of_dirac_networks_in_tensorflow/,hardikbansal24,1498308111,,0,0
1019,2017-6-24,2017,6,24,21,6j7z6j,Variational Autoencoder: Why not balancing the losses?,https://www.reddit.com/r/MachineLearning/comments/6j7z6j/variational_autoencoder_why_not_balancing_the/,[deleted],1498308346,[removed],0,1
1020,2017-6-24,2017,6,24,22,6j8229,[D] GTX 1050ti vs GTX 1060 for Machine Learning Workstation,https://www.reddit.com/r/MachineLearning/comments/6j8229/d_gtx_1050ti_vs_gtx_1060_for_machine_learning/,lolcatbot010101,1498309518,"I am starting to delve into LSTMs and Convo nets, so I figured it might be a good idea to build a very basic machine learning workstation. I currently use AWS and Google compute engine, however I'd prefer having my own machine. A 1060 costs twice as  much as a 1050ti where I live. So which of the two should I buy?",23,0
1021,2017-6-24,2017,6,24,22,6j827a,World's Most Powerful Particle Collider Taps AI to Expose Hack Attacks - Scientific American,https://www.reddit.com/r/MachineLearning/comments/6j827a/worlds_most_powerful_particle_collider_taps_ai_to/,whatllmyusernamebe,1498309569,,0,1
1022,2017-6-24,2017,6,24,23,6j8crn,Googles new AI investment arm leads $10.5M round in Algorithmia machine-learning marketplace,https://www.reddit.com/r/MachineLearning/comments/6j8crn/googles_new_ai_investment_arm_leads_105m_round_in/,mcclintockelbert,1498313674,,0,1
1023,2017-6-24,2017,6,24,23,6j8d2q,The inextricable link between IoT and machine learning,https://www.reddit.com/r/MachineLearning/comments/6j8d2q/the_inextricable_link_between_iot_and_machine/,woodcockefren,1498313782,,0,1
1024,2017-6-24,2017,6,24,23,6j8j6m,C++ ML from scratch,https://www.reddit.com/r/MachineLearning/comments/6j8j6m/c_ml_from_scratch/,BigOneEyedPurpleEmu,1498315880,[removed],0,1
1025,2017-6-25,2017,6,25,0,6j8n86,[D] Why is SVM memory efficient?,https://www.reddit.com/r/MachineLearning/comments/6j8n86/d_why_is_svm_memory_efficient/,datavinci,1498317216,"Reason given on scikit learn documentation: Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient..... I dont understand this",14,4
1026,2017-6-25,2017,6,25,0,6j8pqs,The Man Who Helped Turn Toronto Into a Tech Hotbed,https://www.reddit.com/r/MachineLearning/comments/6j8pqs/the_man_who_helped_turn_toronto_into_a_tech_hotbed/,Rob,1498318049,,1,2
1027,2017-6-25,2017,6,25,0,6j8rmn,[P] Implementation of Age and Gender classification using caffe,https://www.reddit.com/r/MachineLearning/comments/6j8rmn/p_implementation_of_age_and_gender_classification/,the-fire-fist,1498318647,,4,0
1028,2017-6-25,2017,6,25,1,6j94al,[D] Did AlphaGo use an evaluation function with hand-selected features?,https://www.reddit.com/r/MachineLearning/comments/6j94al/d_did_alphago_use_an_evaluation_function_with/,Boris999,1498322556,"From my understanding of the AlphaGo paper ([link](https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf)) on pages 26 and 31, they use hand selected features for the network. However, [this](https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/) articles states:

&gt; that it involves a learning component instead of hand-crafted heuristics

Am I misunderstanding the paper or is the author of the article suggesting that the weights of the features are learnt, not the features themselves?",11,11
1029,2017-6-25,2017,6,25,1,6j95qg,Favourite parts of machine learning [question],https://www.reddit.com/r/MachineLearning/comments/6j95qg/favourite_parts_of_machine_learning_question/,birchtree02,1498322995,[removed],0,1
1030,2017-6-25,2017,6,25,2,6j9ied,Tensorflow: can not convert a float into a tensor?,https://www.reddit.com/r/MachineLearning/comments/6j9ied/tensorflow_can_not_convert_a_float_into_a_tensor/,mdlee6,1498326951,[removed],0,1
1031,2017-6-25,2017,6,25,3,6j9kym,[P] Recommending GitHub Repositories with Google BigQuery and the implicit library,https://www.reddit.com/r/MachineLearning/comments/6j9kym/p_recommending_github_repositories_with_google/,benfred,1498327720,,1,53
1032,2017-6-25,2017,6,25,3,6j9my1,"I'm not sure if this is the right sub, but I'm having trouble with a neural network I wrote.",https://www.reddit.com/r/MachineLearning/comments/6j9my1/im_not_sure_if_this_is_the_right_sub_but_im/,[deleted],1498328360,[removed],0,1
1033,2017-6-25,2017,6,25,4,6ja23l,Introduction to RANSAC,https://www.reddit.com/r/MachineLearning/comments/6ja23l/introduction_to_ransac/,activatedgeek,1498333047,,0,1
1034,2017-6-25,2017,6,25,6,6jai4r,"[D] Taking statistics on sum of a random set of RBM nodes, whats different in a well trained RBM vs a very overfit RBM?",https://www.reddit.com/r/MachineLearning/comments/6jai4r/d_taking_statistics_on_sum_of_a_random_set_of_rbm/,BenRayfield,1498338123,"When very overfit, I often see groups of nodes that duplicate eachothers values, so theres far more random sets of nodes with large stdDev.

This extends to conditionalChance like z=and(x,!y) happening more often than randomly. Many random sets include z and x and exclude y so would have bigger stdDev than would be expected randomly.

If all nodes in a layer have equal average, then a random set of them is likely to have a smaller stdDev.

The sum of encrypted bits is near certain to have a small stdDev.

A well trained rbm tends toward exponentially many possible vectors since theres patterns built on patterns such as object vision a few layers above edge detection. The same combination of edges can be matched even places its never been trained, if the individual edges were trained there. Possibilities of patterns multiplied by patterns... gets really big. 

Would a random set of nodes in a well trained RBM have lower stdDev than an overfit RBM?

If stdDev of a random set of nodes tells us anything about how overfit the RBM is, and random sets are unlikely to overlap useful feature vectors (since theres exponentially more random sets than useful features), then we might adjust stdDev of such random sets as a kind of norm.",2,0
1035,2017-6-25,2017,6,25,6,6jai7w,Semi-supervised Learning with Deep Generative Models,https://www.reddit.com/r/MachineLearning/comments/6jai7w/semisupervised_learning_with_deep_generative/,woner123,1498338151,[removed],0,1
1036,2017-6-25,2017,6,25,6,6jakke,"Deep learning text classifications (KATE, VAE, DocNADE, ParaVec, ...) is [still] no better than TF-IDF+SVM?",https://www.reddit.com/r/MachineLearning/comments/6jakke/deep_learning_text_classifications_kate_vae/,fnl,1498338902,[removed],0,1
1037,2017-6-25,2017,6,25,6,6jas97,[R] [1705.05665] Learning Image Relations with Contrast Association Networks,https://www.reddit.com/r/MachineLearning/comments/6jas97/r_170505665_learning_image_relations_with/,yaolubrain,1498341426,,0,8
1038,2017-6-25,2017,6,25,7,6jau55,"[D] GAN's producing more ""structured"" results when regarding artwork?",https://www.reddit.com/r/MachineLearning/comments/6jau55/d_gans_producing_more_structured_results_when/,beef__,1498342032,"So - for a while I've been experimenting with feeding GAN's huge datasets of artwork, and the results that I've been getting have been interesting, but they're missing the ""structure"" found in normal images/artwork (by 'structure' i mean the arrangement of objects in the paintings - the idea that the painting is composed of separate objects, and isn't just a big soup of color. The GAN doesnt seem to be picking this up). Here's an example:

http://imgur.com/a/ldMnm

They don't really look like anything... I tried the same thing with a huge corpus of landscape paintings I put together and here's the result;

http://imgur.com/a/2lFAT

The results with landscapes are a *little* bit better, but not by much. I think they turned out better because ~~all~~ most of the data follows the same pattern of land at the bottom, maybe trees or something in the middle, and sky at the top. It's easier for the network to learn to generate this since the pattern is simpler. 

I've been trying to generate different types of art using GANs by trying to force it to learn structure, as opposed to color, etc. through the following approach


1. feed the GAN simpler representations of the artwork (in this case, I'm using an edge detection algorithm to generate representations of the artwork that is purely structural - here's an example http://imgur.com/a/hXQcP ). The logic is that if i feed the GAN these representations that only contain structure, there won't be anything else for it to learn (unlike the GAN that i fed the full color artwork that only learned the patterns in color, shading, etc as opposed to structure/shapes - i guess because patterns in color are much more apparent to the network than those in structure/shape)


2. train a pix2pix implementation to go from edges to the artwork equivalent (i already have a huge dataset of nude paintings and their corresponding edges, so this won't be hard)


3. Have the GAN generate edges and run them through pix2pix to get nude-paintings with structure (hopefully).


The bad news is that training the GAN on edges results in something like this: http://imgur.com/a/mG1MS (you're looking at a batch of 64 images generated from the GAN at epoch ~7000). Obviously, generating edges from the paintings wasn't the right approach. My initial thought is to seek some other form of simplified representation of the paintings - maybe like a low resolution ""map"" of the objects in the paintings; perhaps use object segmentation to make a low-resolution flat color version of the paintings, and then train the GAN on those? this way the patterns of color and shading would be reduced to much, much simpler ones, and it might learn patterns of structure instead since there? 

The problem is just getting the GAN to learn structure, so if you guys know of any way I could simplify the input for the GAN to plug into step 1 of my approach instead of edges, that'd be cool, and any other ideas of how I could get the GAN to learn structure would be greatly appreciated. also I know my wording is pretty bad so please don't be afraid to ask what i mean about certain things in the comments.

**tl;dr GAN won't learn structure/arrangement of objects in paintings I feed it... I've tried some things but it's still not learning structure, only color. help**",20,24
1039,2017-6-25,2017,6,25,8,6jbc6r,[D] Having issues with semi-supervised GANs,https://www.reddit.com/r/MachineLearning/comments/6jbc6r/d_having_issues_with_semisupervised_gans/,zeromaxy,1498348203,"Hi everyone,

I've grown desperate for help so I might as well post here, I'm having issues with training semi-supervised GANs. I'm new to Deep Learning projects so I'm not as skillful in debugging which only adds to the pain that GANs already are to train.

Issues by number:

1) https://arxiv.org/pdf/1606.01583.pdf

I have trouble understanding and implementing this paper (with my implementation I keep getting discriminator loss: NaN and of course, mode collapse). 

So first thing I did here is get a batch of 100 mnist examples, 10 examples per class. Then I expanded the MNIST Labels adding an 11th class corresponding to FAKE and the values are set to zero on that 11th member of the vector. Changed the sigmoid from my working DCGAN code to Softmax with 11 nodes, first 10 being digits, 11th being FAKE.
Now for applying the algorithm, the trickiness starts as to understanding the author. He proposes combining 2 m sized batches, m of labeled data and m of generated data for training discriminator. You use the granular labels for supervised training.

I suppose the discriminator loss would look like the softmax_cross_entropy_with_logits?

discriminator_loss_supervised = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=D_logit_real_sample, labels=y))

And as for the unsupervised batches I suppose he figures that we sum the first 10 nodes of the softmax as they correspond to the REAL class in original GAN and act like we got a GAN on our hands?

discriminator_loss_unsupervised = -(tf.reduce_mean(tf.log(D_real_sample_real_prob))+tf.reduce_mean(tf.log(1 - D_gen_sample_real_prob)))

As stated in original GAN algorithm. Generator loss could either minimize:

generator_loss = -tf.reduce_mean(tf.log(D_gen_sample_real_prob))

or this:

generator_loss = tf.reduce_mean(tf.log(1 - D_gen_sample_real_prob))

I figure I must have either terrible understanding of the situation or I got a bug in my code but for the life of me I cannot find it. It doesn't help that GANs are pretty unforgiving with that high number of mode collapses.

Entire code can be found here - https://pastebin.com/67YcjKev

I borrowed plenty from other authors which I intend to reference in my project.

2) https://arxiv.org/pdf/1606.03498.pdf

Here I encounter similar issues. I use the same DCGAN I used above which worked for me. For generator training I use feature matching as described in the paper instead of those logs of probabilities, I match the conv features of generated and real samples, that means the input to the last, fully connected layer.

Again, although the discriminator losses are precisely stated in the paper, I feel like I'm missing something since I also get NaN as discriminator loss.

The code is actually the same for the losses barring generator loss. Entire code can be found here - https://pastebin.com/0iC9aQAk

I would greatly appreciate any kind of help.",2,0
1040,2017-6-25,2017,6,25,8,6jbdrl,GO NATURAL...,https://www.reddit.com/r/MachineLearning/comments/6jbdrl/go_natural/,012runkumar,1498348752,[removed],0,1
1041,2017-6-25,2017,6,25,9,6jbjtn,New York Times write about Dr. Hinton,https://www.reddit.com/r/MachineLearning/comments/6jbjtn/new_york_times_write_about_dr_hinton/,[deleted],1498350873,[deleted],0,1
1042,2017-6-25,2017,6,25,11,6jc05k,[D] Having trouble understanding the usage of Softmax for Convolutions(Pixel Classification),https://www.reddit.com/r/MachineLearning/comments/6jc05k/d_having_trouble_understanding_the_usage_of/,Cock-tail,1498357071,"I am trying to classify each pixel of an image in NR_BINS. The last layers of the network, which propagates the image, look like this:

    model = Conv2D(filters=NR_BINS,
                            kernel_size=(1, 1),
                            strides=(1, 1),
                            padding='valid',
                            name='block_conv4')(model)
    model = Reshape(target_shape=(NR_BINS, 224 * 224))(model)
    model = Permute((2, 1))(model)
    model = Activation('softmax', name='output_a_channel')(model)

The input image has the shape of (224, 224, 3). Thus, I get a shape of (None, 50176, NR_BINS) for the output. Is it okay to 
compile the model with the sparse_cross_entropy loss function? The generator function yields data with the shape of (None, 50172, 1) - why does it have to be only 1, and not NR_BINS for axis=2? What happens during the prediction phase? The output is still (50172, NR_BINS). So how do I know which bin is the one I should choose?",9,0
1043,2017-6-25,2017,6,25,12,6jcdf4,Solving Interview Problems with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6jcdf4/solving_interview_problems_with_deep_learning/,czhu12,1498362377,,0,1
1044,2017-6-25,2017,6,25,14,6jcrlc,What are the best works on dynamic neural nets?,https://www.reddit.com/r/MachineLearning/comments/6jcrlc/what_are_the_best_works_on_dynamic_neural_nets/,alirezasmr,1498368395,[removed],0,1
1045,2017-6-25,2017,6,25,16,6jd42e,Exploring Activation Functions for Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6jd42e/exploring_activation_functions_for_neural_networks/,sudo_su_,1498374686,,0,1
1046,2017-6-25,2017,6,25,18,6jdi87,"[R] Question about Positional Encodings used in ""Attention is all you need"" paper",https://www.reddit.com/r/MachineLearning/comments/6jdi87/r_question_about_positional_encodings_used_in/,metacurse,1498382979,"The paper uses novel positional encodings to give their transformer model a sense of position. However, I am confused about the formulation of the encodings. They take a vector of size d_model and fill it with a sine-like wave's amplitudes at each position. I say sine-like since they sample the sine at geometric intervals and not at linear intervals. 

Next, they say that
&gt; We chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset k, PE_pos+k can be represented as a linear function of PE_pos.

If you write down the math for PE_pos+k - PE_k, it doesn't look linear to me. What am I missing here?",5,8
1047,2017-6-25,2017,6,25,19,6jdr1f,How to identify sales leads using Microsoft Cognitive Services,https://www.reddit.com/r/MachineLearning/comments/6jdr1f/how_to_identify_sales_leads_using_microsoft/,maguirej160,1498387996,,0,1
1048,2017-6-25,2017,6,25,20,6jdsfu,Google lens turns your camera into image understandable AI,https://www.reddit.com/r/MachineLearning/comments/6jdsfu/google_lens_turns_your_camera_into_image/,redituserk,1498388736,,0,1
1049,2017-6-25,2017,6,25,20,6jdwu8,filling plugging sealing machine for e liquid gorilla bottle filling plu...,https://www.reddit.com/r/MachineLearning/comments/6jdwu8/filling_plugging_sealing_machine_for_e_liquid/,hymachinery,1498391091,,0,1
1050,2017-6-25,2017,6,25,21,6je46u,[D] About Conditional GAN: when to concatenate random noise z and class-label y?,https://www.reddit.com/r/MachineLearning/comments/6je46u/d_about_conditional_gan_when_to_concatenate/,shabeyyub,1498394264,"Hi,

I'm trying to build a MNIST [cGAN](https://arxiv.org/pdf/1411.1784.pdf) but I'm having a hard time trying to make it converge. I'm trying to follow the architecture they describe, however I'm not sure about this part:
&gt; In the generator net, (...) both z and y are mapped to hidden layers with ReLu activation, with layer sizes 200 and 1000 respectively, before both being mapped to
second, combined hidden ReLu layer of dimensionality 1200. We then have a final sigmoid unit
layer as our output for generating the 784-dimensional MNIST samples.

So, if I understand correctly, z and y are not concatenated at the input, but rather it is their respective hidden layers' activations that are being concatenated right? Something like:
`az = relu(z.dot(W1))`
`ay = relu(y.dot(W2))`
`ah = relu(concat(az, ay).dot(W3))`
Instead of `ah = relu(concat(z, y).dot(W3))`?

The thing that makes me doubt, is that all implementations of models that use Conditional GANs I've seen, don't bother themselves and just concatenate `z`and `y`. I would like to know if there is any particular reasons and which one of the two way should I use?

Thanks",4,4
1051,2017-6-25,2017,6,25,23,6jehk9,What other libraries are available for loading trained models on Android devices other than TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/6jehk9/what_other_libraries_are_available_for_loading/,[deleted],1498399648,[removed],0,1
1052,2017-6-25,2017,6,25,23,6jeimv,[D] Current state of the art in document similarity?,https://www.reddit.com/r/MachineLearning/comments/6jeimv/d_current_state_of_the_art_in_document_similarity/,2014mchidamb,1498400057,"What methods currently perform the best in assessing document similarity, as well as sentence similarity? Additionally, are there methods that can accurately determine similarity between two documents of very different length (i.e. a paragraph summary of a book and the book itself)?",25,58
1053,2017-6-25,2017,6,25,23,6jeovu,[D] Algorithms for 3D object classification,https://www.reddit.com/r/MachineLearning/comments/6jeovu/d_algorithms_for_3d_object_classification/,gessha,1498402216,"I'm working with data sets with 3/4 classes and each class has 100~200 examples. Each example is a volumetric representation of a 3D object. What algorithms apart from CNNs are good for this kind of data set and problem?

I've been trying to find papers on this type of classification but I've found very few and they are kind of unrelated. Links to papers are more than welcome. Thanks!",6,7
1054,2017-6-26,2017,6,26,0,6jeug0,Problem with cnn for regression task.,https://www.reddit.com/r/MachineLearning/comments/6jeug0/problem_with_cnn_for_regression_task/,[deleted],1498404071,[removed],0,1
1055,2017-6-26,2017,6,26,2,6jfejd,[D] Whats the highest nSAT that RBM can learn without learning any (n-1)SAT patterns?,https://www.reddit.com/r/MachineLearning/comments/6jfejd/d_whats_the_highest_nsat_that_rbm_can_learn/,[deleted],1498410248,[deleted],0,0
1056,2017-6-26,2017,6,26,3,6jg0q4,Advanced Machine Learning with Basic Excel,https://www.reddit.com/r/MachineLearning/comments/6jg0q4/advanced_machine_learning_with_basic_excel/,psangrene,1498416859,,0,1
1057,2017-6-26,2017,6,26,3,6jg18j,[Python] I created functions for ensembling models and generating Partial Dependency Plots for any function that has an ability to predict probabilities. How do I create a library for it?,https://www.reddit.com/r/MachineLearning/comments/6jg18j/python_i_created_functions_for_ensembling_models/,dingdong1111,1498417023,[removed],0,1
1058,2017-6-26,2017,6,26,5,6jgdva,[D] Machine Learning - WAYR (What Are You Reading) - Week 28,https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1498420806,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|
|----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/jvmancuso: [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)

/u/lmcinnes: [Clustering with t-SNE, provably](https://arxiv.org/abs/1706.02582)

/u/mind_juice: [VoxNet](http://www.dimatura.net/publications/voxnet_maturana_scherer_iros15.pdf)

Besides that, there are no rules, have fun.",28,53
1059,2017-6-26,2017,6,26,5,6jgh3o,"Realistically, how fast can you expect to learn ML to a professional profiecency?",https://www.reddit.com/r/MachineLearning/comments/6jgh3o/realistically_how_fast_can_you_expect_to_learn_ml/,ideapreneur,1498421742,[removed],0,1
1060,2017-6-26,2017,6,26,5,6jghwv,Understanding shot in the dark successes,https://www.reddit.com/r/MachineLearning/comments/6jghwv/understanding_shot_in_the_dark_successes/,blahsphemer_,1498421995,[removed],0,1
1061,2017-6-26,2017,6,26,6,6jh1k7,[P] Building a Real-Time Object Recognition App with Tensorflow and OpenCV (With nice multithread OpenCV -&gt; TF pipeline for efficient I/O),https://www.reddit.com/r/MachineLearning/comments/6jh1k7/p_building_a_realtime_object_recognition_app_with/,[deleted],1498427988,[deleted],0,121
1062,2017-6-26,2017,6,26,8,6jhede,"TensorFlow/TensorLayer implementation of ""Spatial Transformer Networks""",https://www.reddit.com/r/MachineLearning/comments/6jhede/tensorflowtensorlayer_implementation_of_spatial/,zsdh123,1498432049,,0,1
1063,2017-6-26,2017,6,26,8,6jhfb5,Lattice Boltzmann Fluid Flow Library written in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/6jhfb5/lattice_boltzmann_fluid_flow_library_written_in/,yoyosarian,1498432381,,0,1
1064,2017-6-26,2017,6,26,8,6jhhn8,Super Resolution GAN in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6jhhn8/super_resolution_gan_in_tensorflow/,zsdh123,1498433184,,8,16
1065,2017-6-26,2017,6,26,10,6ji1ed,Kitchen Remodeling,https://www.reddit.com/r/MachineLearning/comments/6ji1ed/kitchen_remodeling/,gwenyosef,1498439344,,0,1
1066,2017-6-26,2017,6,26,11,6jiem7,Stair Handrail and Railing,https://www.reddit.com/r/MachineLearning/comments/6jiem7/stair_handrail_and_railing/,gwenyosef,1498443788,,0,1
1067,2017-6-26,2017,6,26,12,6jin2u,Learning a similarity function w/o a fixed embedding,https://www.reddit.com/r/MachineLearning/comments/6jin2u/learning_a_similarity_function_wo_a_fixed/,bkj__,1498446802,[removed],0,1
1068,2017-6-26,2017,6,26,13,6jj0gl,"Creative Adversarial Network , simplified",https://www.reddit.com/r/MachineLearning/comments/6jj0gl/creative_adversarial_network_simplified/,harvey_slash,1498451875,,0,1
1069,2017-6-26,2017,6,26,14,6jj4nz,Baseboards,https://www.reddit.com/r/MachineLearning/comments/6jj4nz/baseboards/,gwenyosef,1498453619,,0,1
1070,2017-6-26,2017,6,26,14,6jj527,Is there any tree-based alternative to CNN?,https://www.reddit.com/r/MachineLearning/comments/6jj527/is_there_any_treebased_alternative_to_cnn/,RavlaAlvar,1498453768,[removed],0,1
1071,2017-6-26,2017,6,26,15,6jjegv,[P] MobileNets in Keras,https://www.reddit.com/r/MachineLearning/comments/6jjegv/p_mobilenets_in_keras/,haseox1,1498457752,,8,24
1072,2017-6-26,2017,6,26,15,6jjffp,"Shot blasting Room from Mayflay Machinery Co.,Ltd",https://www.reddit.com/r/MachineLearning/comments/6jjffp/shot_blasting_room_from_mayflay_machinery_coltd/,Shot-blasting,1498458192,,1,1
1073,2017-6-26,2017,6,26,15,6jjgcl,cranes production,https://www.reddit.com/r/MachineLearning/comments/6jjgcl/cranes_production/,ada2017,1498458613,,0,1
1074,2017-6-26,2017,6,26,15,6jjgrj,Would any of you brave hearts take a look at my question in stackoverflow?,https://www.reddit.com/r/MachineLearning/comments/6jjgrj/would_any_of_you_brave_hearts_take_a_look_at_my/,[deleted],1498458802,[deleted],0,1
1075,2017-6-26,2017,6,26,15,6jjgyf,Automatic Cap Unscrambling Fetching Single Head Screw Capping Machine fo...,https://www.reddit.com/r/MachineLearning/comments/6jjgyf/automatic_cap_unscrambling_fetching_single_head/,hymachinery,1498458901,,0,1
1076,2017-6-26,2017,6,26,16,6jjl53,Second Order Optimization - The Math of Intelligence #2,https://www.reddit.com/r/MachineLearning/comments/6jjl53/second_order_optimization_the_math_of/,funmaster11,1498460831,,0,1
1077,2017-6-26,2017,6,26,16,6jjoni,Cabinet Making,https://www.reddit.com/r/MachineLearning/comments/6jjoni/cabinet_making/,gwenyosef,1498462530,,0,1
1078,2017-6-26,2017,6,26,16,6jjq4x,[R] [1706.07503] Personalization in Goal-Oriented Dialog - new dialog AI dataset with speaker profiles/attributes,https://www.reddit.com/r/MachineLearning/comments/6jjq4x/r_170607503_personalization_in_goaloriented/,ckjoshi9,1498463254,,3,6
1079,2017-6-26,2017,6,26,17,6jjrk3,[D] Why Im Remaking OpenAI Universe,https://www.reddit.com/r/MachineLearning/comments/6jjrk3/d_why_im_remaking_openai_universe/,evc123,1498464001,,41,174
1080,2017-6-26,2017,6,26,17,6jjwja,TwentyBN releases the world's largest video dataset for teaching AI systems common sense about the real world.,https://www.reddit.com/r/MachineLearning/comments/6jjwja/twentybn_releases_the_worlds_largest_video/,erogol,1498466554,,0,1
1081,2017-6-26,2017,6,26,18,6jk17h,[N] Principal components analysis explained,https://www.reddit.com/r/MachineLearning/comments/6jk17h/n_principal_components_analysis_explained/,Sergiointelnics,1498468834,,3,0
1082,2017-6-26,2017,6,26,19,6jk6va,Private Building Certifiers,https://www.reddit.com/r/MachineLearning/comments/6jk6va/private_building_certifiers/,gwenyosef,1498471682,,0,1
1083,2017-6-26,2017,6,26,19,6jka96,Any advice for working on pitch identification from spectograms?,https://www.reddit.com/r/MachineLearning/comments/6jka96/any_advice_for_working_on_pitch_identification/,TheMoskowitz,1498473224,[removed],0,1
1084,2017-6-26,2017,6,26,20,6jkfrm,[N] Building a Custom Deep Learning Rig,https://www.reddit.com/r/MachineLearning/comments/6jkfrm/n_building_a_custom_deep_learning_rig/,magneticono,1498475634,,0,1
1085,2017-6-26,2017,6,26,20,6jkl6a,[N] Setting up your GPU TensorFlow platform  Manuel Snchez Hernndez,https://www.reddit.com/r/MachineLearning/comments/6jkl6a/n_setting_up_your_gpu_tensorflow_platform_manuel/,lalypopa123,1498477842,,5,0
1086,2017-6-26,2017,6,26,20,6jklnc,[N] Python vs R. Which language should you choose?,https://www.reddit.com/r/MachineLearning/comments/6jklnc/n_python_vs_r_which_language_should_you_choose/,jackblun,1498478008,,3,0
1087,2017-6-26,2017,6,26,20,6jklts,[N] My essential data science tools,https://www.reddit.com/r/MachineLearning/comments/6jklts/n_my_essential_data_science_tools/,dearpetra,1498478080,,0,8
1088,2017-6-26,2017,6,26,21,6jkmrj,[N] Relevnt launches a publisher-centric news app,https://www.reddit.com/r/MachineLearning/comments/6jkmrj/n_relevnt_launches_a_publishercentric_news_app/,magneticono,1498478418,,0,1
1089,2017-6-26,2017,6,26,21,6jknhq,[N] Profiting from Python &amp; Machine Learning in the Financial Markets,https://www.reddit.com/r/MachineLearning/comments/6jknhq/n_profiting_from_python_machine_learning_in_the/,awhlop,1498478657,,5,3
1090,2017-6-26,2017,6,26,21,6jkqfl,Open source TSDB that includes cluster functionality + no downtime,https://www.reddit.com/r/MachineLearning/comments/6jkqfl/open_source_tsdb_that_includes_cluster/,[deleted],1498479655,[deleted],0,1
1091,2017-6-26,2017,6,26,21,6jkqoj,[N] Sports Crunch Has Great News for Hockey Fans!,https://www.reddit.com/r/MachineLearning/comments/6jkqoj/n_sports_crunch_has_great_news_for_hockey_fans/,[deleted],1498479748,[deleted],0,1
1092,2017-6-26,2017,6,26,21,6jks9o,[P] How HBOs Silicon Valley built Not Hotdog with mobile TensorFlow &amp; Keras,https://www.reddit.com/r/MachineLearning/comments/6jks9o/p_how_hbos_silicon_valley_built_not_hotdog_with/,tim_anglade,1498480317,,67,447
1093,2017-6-26,2017,6,26,21,6jkt2h,[N] How to Remove Password Security from NSF File Manually?,https://www.reddit.com/r/MachineLearning/comments/6jkt2h/n_how_to_remove_password_security_from_nsf_file/,janemoz,1498480577,,0,1
1094,2017-6-26,2017,6,26,21,6jkwj3,How Chatbots can help Your Business Grow!,https://www.reddit.com/r/MachineLearning/comments/6jkwj3/how_chatbots_can_help_your_business_grow/,hardikmakadia,1498481760,,0,1
1095,2017-6-26,2017,6,26,22,6jl7qi,Machine learning with financial market data,https://www.reddit.com/r/MachineLearning/comments/6jl7qi/machine_learning_with_financial_market_data/,Eildosa,1498485316,[removed],0,1
1096,2017-6-26,2017,6,26,23,6jl8q8,The Combination of A.I. &amp; Blockchain Could Revolutionize These 10 Industries - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6jl8q8/the_combination_of_ai_blockchain_could/,conradcreates,1498485628,,0,1
1097,2017-6-26,2017,6,26,23,6jlcc9,Would it be useful to use buffer overflow as a nonlinearity?,https://www.reddit.com/r/MachineLearning/comments/6jlcc9/would_it_be_useful_to_use_buffer_overflow_as_a/,[deleted],1498486703,[removed],0,1
1098,2017-6-26,2017,6,26,23,6jldna,[D] Brendan Herger | Machine Learning Techniques for Class Imbalances &amp; Adversaries,https://www.reddit.com/r/MachineLearning/comments/6jldna/d_brendan_herger_machine_learning_techniques_for/,[deleted],1498487078,[deleted],0,1
1099,2017-6-26,2017,6,26,23,6jlesq,[P] Machine Learning for the Analysis of Text As Data,https://www.reddit.com/r/MachineLearning/comments/6jlesq/p_machine_learning_for_the_analysis_of_text_as/,jesueai,1498487420,,0,0
1100,2017-6-26,2017,6,26,23,6jljcn,14 Design Patterns To Improve Your Convolutional Neural Networks - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6jljcn/14_design_patterns_to_improve_your_convolutional/,conradcreates,1498488605,,0,1
1101,2017-6-27,2017,6,27,0,6jlljx,[N] Five Conditions to Identify Business Processes That Are Ready for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6jlljx/n_five_conditions_to_identify_business_processes/,molode,1498489204,,0,5
1102,2017-6-27,2017,6,27,0,6jlt6b,Novel Deep Atrous CNN Architecture for Sentiment Analysis  Tensorflow Implementation,https://www.reddit.com/r/MachineLearning/comments/6jlt6b/novel_deep_atrous_cnn_architecture_for_sentiment/,gvssvg,1498491173,,0,1
1103,2017-6-27,2017,6,27,0,6jlxfx,[P] Draw Together with a Neural Network,https://www.reddit.com/r/MachineLearning/comments/6jlxfx/p_draw_together_with_a_neural_network/,hardmaru,1498492306,,4,19
1104,2017-6-27,2017,6,27,1,6jma7t,Thinking of doing a machine learning PhD? Read this first. (Review of machine learning as a career.),https://www.reddit.com/r/MachineLearning/comments/6jma7t/thinking_of_doing_a_machine_learning_phd_read/,[deleted],1498495558,[deleted],0,1
1105,2017-6-27,2017,6,27,2,6jmdua,The Essential Landscape of Enterprise A.I. Companies - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6jmdua/the_essential_landscape_of_enterprise_ai/,conradcreates,1498496468,,0,1
1106,2017-6-27,2017,6,27,2,6jmijz,[D] What is the state of the art for chatbots right now?,https://www.reddit.com/r/MachineLearning/comments/6jmijz/d_what_is_the_state_of_the_art_for_chatbots_right/,Faizann24,1498497642,Which models are state-of-the-art for chatbots right now. ,5,10
1107,2017-6-27,2017,6,27,3,6jn3p9,Anyone landed Machine Learning NLP job with just online courses ?,https://www.reddit.com/r/MachineLearning/comments/6jn3p9/anyone_landed_machine_learning_nlp_job_with_just/,[deleted],1498502985,[removed],0,1
1108,2017-6-27,2017,6,27,3,6jn60e,Anyone landed Machine Learning NLP job with just online courses ?,https://www.reddit.com/r/MachineLearning/comments/6jn60e/anyone_landed_machine_learning_nlp_job_with_just/,bicepjai,1498503591,[removed],0,1
1109,2017-6-27,2017,6,27,5,6jnrwc,[D] Analyzing 3D Lidar with synced images,https://www.reddit.com/r/MachineLearning/comments/6jnrwc/d_analyzing_3d_lidar_with_synced_images/,justsomeriverbrooks,1498509161,"I'm trying to analyze a 3D Lidar point cloud that is synced with video data which together correspond to robotic actuator movements. I need to use a convolutional neural net for this, but am a bit lost on how to process the Lidar data in a reasonable way. Can anybody give me some direction on processing the point cloud, and what kind of converted format would be useful for a conv net?",14,2
1110,2017-6-27,2017,6,27,5,6jnuc7,Coding theory in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6jnuc7/coding_theory_in_machine_learning/,Rioghasarig,1498509792,[removed],0,1
1111,2017-6-27,2017,6,27,6,6jo2z9,[D] Would it be useful to use buffer overflow as a nonlinearity?,https://www.reddit.com/r/MachineLearning/comments/6jo2z9/d_would_it_be_useful_to_use_buffer_overflow_as_a/,[deleted],1498512035,[deleted],9,0
1112,2017-6-27,2017,6,27,6,6jo3s7,"Alan Watts on Technology and Progress, including Machine Learning generated imagery",https://www.reddit.com/r/MachineLearning/comments/6jo3s7/alan_watts_on_technology_and_progress_including/,DigitalSurrealism,1498512261,,0,1
1113,2017-6-27,2017,6,27,6,6jo4g2,"First official scoring on OpenAI gym for the atari game MsPackMan using...""Fractal AI""",https://www.reddit.com/r/MachineLearning/comments/6jo4g2/first_official_scoring_on_openai_gym_for_the/,Zeta36,1498512433,[removed],1,1
1114,2017-6-27,2017,6,27,6,6jo4mi,What are the best techniques for object recognition and labeling?,https://www.reddit.com/r/MachineLearning/comments/6jo4mi/what_are_the_best_techniques_for_object/,[deleted],1498512488,[removed],0,1
1115,2017-6-27,2017,6,27,6,6jo4wp,"Over 150 of the Best Machine Learning, NLP, and Python Tutorials Ive Found",https://www.reddit.com/r/MachineLearning/comments/6jo4wp/over_150_of_the_best_machine_learning_nlp_and/,red_simplex,1498512563,,0,1
1116,2017-6-27,2017,6,27,6,6joac4,The Rise of the Machines  Why Automation is Different this Time,https://www.reddit.com/r/MachineLearning/comments/6joac4/the_rise_of_the_machines_why_automation_is/,justwellbrock,1498514003,,0,1
1117,2017-6-27,2017,6,27,7,6jom3k,Cabinet Making and Bathroom Vanities,https://www.reddit.com/r/MachineLearning/comments/6jom3k/cabinet_making_and_bathroom_vanities/,gwenyosef,1498517342,,0,1
1118,2017-6-27,2017,6,27,8,6jor2b,Data Science and Machine Learning Without Mathematics,https://www.reddit.com/r/MachineLearning/comments/6jor2b/data_science_and_machine_learning_without/,psangrene,1498518813,,0,1
1119,2017-6-27,2017,6,27,8,6jorl1,How Intel Uses Economy Of Scale To Power A.I. For Good - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6jorl1/how_intel_uses_economy_of_scale_to_power_ai_for/,conradcreates,1498518968,,0,1
1120,2017-6-27,2017,6,27,8,6jowc3,Do you have suggestions for an interactive machine learning workshop game for non-technical participants?,https://www.reddit.com/r/MachineLearning/comments/6jowc3/do_you_have_suggestions_for_an_interactive/,onlyhugs,1498520399,[removed],0,1
1121,2017-6-27,2017,6,27,8,6jozu9,Machine Learning Nerf Sentry,https://www.reddit.com/r/MachineLearning/comments/6jozu9/machine_learning_nerf_sentry/,archmonkeymojo,1498521494,,1,1
1122,2017-6-27,2017,6,27,10,6jplzj,How can we choose a ideal resins paddle mixer for sale?,https://www.reddit.com/r/MachineLearning/comments/6jplzj/how_can_we_choose_a_ideal_resins_paddle_mixer_for/,JCT_MACHINE,1498528254,,0,1
1123,2017-6-27,2017,6,27,10,6jpneh,Please help us gather data in order to better train our machine learning algorithm to help reduce employment bias.,https://www.reddit.com/r/MachineLearning/comments/6jpneh/please_help_us_gather_data_in_order_to_better/,[deleted],1498528730,[removed],0,1
1124,2017-6-27,2017,6,27,11,6jposv,Bricklaying,https://www.reddit.com/r/MachineLearning/comments/6jposv/bricklaying/,gwenyosef,1498529151,,0,1
1125,2017-6-27,2017,6,27,11,6jppl8,[P] Please help us to gather data in order to better train our algorithm and help reduce employment bias.,https://www.reddit.com/r/MachineLearning/comments/6jppl8/p_please_help_us_to_gather_data_in_order_to/,Ayanowyn,1498529385,[removed],0,0
1126,2017-6-27,2017,6,27,11,6jpq47,[P] Neural Network Libraries by Sony,https://www.reddit.com/r/MachineLearning/comments/6jpq47/p_neural_network_libraries_by_sony/,hardmaru,1498529538,,10,5
1127,2017-6-27,2017,6,27,11,6jpuzb,Are Search Engines Fair? Auditing Search Engines for Differential Satisfaction,https://www.reddit.com/r/MachineLearning/comments/6jpuzb/are_search_engines_fair_auditing_search_engines/,algebraguy1122,1498531074,,0,1
1128,2017-6-27,2017,6,27,12,6jq1ht,"What can be done to prevent well intentioned idiots, criminals, businessmen, and anyone else in the black and or gray area from using predictive analytics to ruin lives?",https://www.reddit.com/r/MachineLearning/comments/6jq1ht/what_can_be_done_to_prevent_well_intentioned/,DullIsTheNewEdge,1498533176,[removed],0,1
1129,2017-6-27,2017,6,27,12,6jq4kq,Training Two Neural Networks Against Each Other?,https://www.reddit.com/r/MachineLearning/comments/6jq4kq/training_two_neural_networks_against_each_other/,GotMiIk,1498534185,[removed],0,1
1130,2017-6-27,2017,6,27,12,6jq5ts,[P] Advice on opening a file larger than your RAM,https://www.reddit.com/r/MachineLearning/comments/6jq5ts/p_advice_on_opening_a_file_larger_than_your_ram/,aadharna,1498534616,"First off, apologies if this is not the right place to put this. 

So, I'm about to start work on a personal project (This will be in Python b/c sklearn and tensorflow.). 

I have my data; I know how my data is structured; I have an idea for how to get the important bits of my data. The only issue is that the JSON file is much much larger than I can fit into my RAM. 

Amount of RAM in my computer -- 8GB

JSON file size -- 56GB

Any advice you can give me on this would be much appreciated. 

Cheers,

aadharna",19,0
1131,2017-6-27,2017,6,27,12,6jq9fo,"Based on how many samples I have, is there any limit on how many complex a neural network I can train for regression?",https://www.reddit.com/r/MachineLearning/comments/6jq9fo/based_on_how_many_samples_i_have_is_there_any/,ibraheemmoosa,1498535888,[removed],0,1
1132,2017-6-27,2017,6,27,14,6jqku9,Advantages of Hiring Professional Home Builders,https://www.reddit.com/r/MachineLearning/comments/6jqku9/advantages_of_hiring_professional_home_builders/,gwenyosef,1498539989,,0,1
1133,2017-6-27,2017,6,27,14,6jqq5r,[R] GANs Trained by a Two Time-Scale Update Rule Converge to a Nash Equilibrium,https://www.reddit.com/r/MachineLearning/comments/6jqq5r/r_gans_trained_by_a_two_timescale_update_rule/,NotAlphaGo,1498542079,,36,129
1134,2017-6-27,2017,6,27,15,6jqwnn,[D] Brendan Herger | Machine Learning Techniques for Class Imbalances &amp; Adversaries,https://www.reddit.com/r/MachineLearning/comments/6jqwnn/d_brendan_herger_machine_learning_techniques_for/,_alphamaximus_,1498544741,,1,3
1135,2017-6-27,2017,6,27,15,6jqyjm,Gaussian Mixture Model - JavaScript/Node.js Package for Unsupervised Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6jqyjm/gaussian_mixture_model_javascriptnodejs_package/,[deleted],1498545545,[deleted],0,1
1136,2017-6-27,2017,6,27,15,6jr0tc,"Can someone provide some context for the quote ""FNNs that perform well are typically shallow"" from the recent Self-Normalizing Neural Networks paper ?",https://www.reddit.com/r/MachineLearning/comments/6jr0tc/can_someone_provide_some_context_for_the_quote/,[deleted],1498546542,[removed],0,1
1137,2017-6-27,2017,6,27,16,6jr8f0,[P] Gaussian Mixture Model - JavaScript/Node.js Package for Unsupervised Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6jr8f0/p_gaussian_mixture_model_javascriptnodejs_package/,lukapopijac,1498549936,,4,7
1138,2017-6-27,2017,6,27,16,6jr91d,"[N] Deep Learning in Robotics, Sergey Levine",https://www.reddit.com/r/MachineLearning/comments/6jr91d/n_deep_learning_in_robotics_sergey_levine/,nocortex,1498550262,,2,20
1139,2017-6-27,2017,6,27,17,6jr9je,How uplift modeling works and what it is good for,https://www.reddit.com/r/MachineLearning/comments/6jr9je/how_uplift_modeling_works_and_what_it_is_good_for/,pdeburen,1498550507,,0,1
1140,2017-6-27,2017,6,27,17,6jr9jq,Oven Cleaner Service,https://www.reddit.com/r/MachineLearning/comments/6jr9jq/oven_cleaner_service/,gwenyosef,1498550510,,0,0
1141,2017-6-27,2017,6,27,17,6jrcuu,[R] Deep learning with coherent nanophotonic circuits,https://www.reddit.com/r/MachineLearning/comments/6jrcuu/r_deep_learning_with_coherent_nanophotonic/,[deleted],1498552181,[deleted],0,1
1142,2017-6-27,2017,6,27,17,6jrdzp,Can you do ML in Excel ? What is your opinion?,https://www.reddit.com/r/MachineLearning/comments/6jrdzp/can_you_do_ml_in_excel_what_is_your_opinion/,mattbolds,1498552742,,8,0
1143,2017-6-27,2017,6,27,17,6jre24,[R] Deep learning with coherent nanophotonic circuits,https://www.reddit.com/r/MachineLearning/comments/6jre24/r_deep_learning_with_coherent_nanophotonic/,BayesianPenguin,1498552779,,1,7
1144,2017-6-27,2017,6,27,18,6jritd,[Discussion] Read-through: Hyperparameter Optimization: A Spectral Approach,https://www.reddit.com/r/MachineLearning/comments/6jritd/discussion_readthrough_hyperparameter/,alexirpan,1498554910,,3,16
1145,2017-6-27,2017,6,27,18,6jrm77,"Sony open-souce NNabla, a deep learning library",https://www.reddit.com/r/MachineLearning/comments/6jrm77/sony_opensouce_nnabla_a_deep_learning_library/,[deleted],1498556479,[deleted],0,1
1146,2017-6-27,2017,6,27,18,6jrmus,[P] Using Evolution to find good DNN hyperparams.,https://www.reddit.com/r/MachineLearning/comments/6jrmus/p_using_evolution_to_find_good_dnn_hyperparams/,stafis,1498556809,"Hi all, 
I wrote a blogpost about evolving neural network architecures.
Blogpost: https://medium.com/@stathis/design-by-evolution-393e41863f98

TL;DR: Time to evolve! Im gonna give a basic example (in PyTorch) of using evolutionary algorithms to tune the hyper-parameters of a DNN.

and the pytorch implementation:
https://github.com/offbit/evo-design

This is not state of the art or anything, just a quick tutorial that scratches the surface of it. ",10,20
1147,2017-6-27,2017,6,27,18,6jrnli,Inter-Session Modeling for Session-Based Recommendation,https://www.reddit.com/r/MachineLearning/comments/6jrnli/intersession_modeling_for_sessionbased/,ruoccoma,1498557179,,0,1
1148,2017-6-27,2017,6,27,19,6jrvlu,[N] Clickstream Analysis and Data Mining Techniques 101: An Introduction,https://www.reddit.com/r/MachineLearning/comments/6jrvlu/n_clickstream_analysis_and_data_mining_techniques/,digitalson,1498560597,,0,1
1149,2017-6-27,2017,6,27,19,6jrvrh,automatic anti corrosive gravity javel bleach toilet cleaner bottle fill...,https://www.reddit.com/r/MachineLearning/comments/6jrvrh/automatic_anti_corrosive_gravity_javel_bleach/,hymachinery,1498560659,,0,1
1150,2017-6-27,2017,6,27,19,6jrw7j,[N] Niche Applications of Artificial Intelligence in healthcare,https://www.reddit.com/r/MachineLearning/comments/6jrw7j/n_niche_applications_of_artificial_intelligence/,awhlop,1498560857,,0,1
1151,2017-6-27,2017,6,27,20,6jryzs,[N] Dimensionality Reduction Algorithms: Strengths and Weaknesses,https://www.reddit.com/r/MachineLearning/comments/6jryzs/n_dimensionality_reduction_algorithms_strengths/,digitalson,1498561974,,0,1
1152,2017-6-27,2017,6,27,20,6jrz8w,"[N] SQL Database Errors, Causes and Prevention",https://www.reddit.com/r/MachineLearning/comments/6jrz8w/n_sql_database_errors_causes_and_prevention/,magneticono,1498562077,,0,1
1153,2017-6-27,2017,6,27,20,6js0qj,Would Deep Learning libraries (e.g. Keras/PyTorch) approximate the gradient to a non-differentiable loss function (e.g. Jaccard Index)?),https://www.reddit.com/r/MachineLearning/comments/6js0qj/would_deep_learning_libraries_eg_keraspytorch/,makeDLgr8again,1498562652,[removed],0,1
1154,2017-6-27,2017,6,27,20,6js11l,[N] MapD Open Sources GPU-Powered Database,https://www.reddit.com/r/MachineLearning/comments/6js11l/n_mapd_open_sources_gpupowered_database/,friscotime,1498562764,,9,33
1155,2017-6-27,2017,6,27,20,6js4c7,online bachelor's degree for ML?,https://www.reddit.com/r/MachineLearning/comments/6js4c7/online_bachelors_degree_for_ml/,newbornking999,1498564002,[removed],0,1
1156,2017-6-27,2017,6,27,20,6js6aj,Training a generative model on retrieval model conversations,https://www.reddit.com/r/MachineLearning/comments/6js6aj/training_a_generative_model_on_retrieval_model/,Clipstuh,1498564706,[removed],0,1
1157,2017-6-27,2017,6,27,21,6js6kr,[N] A Quick Guide to Identify Twitterbots Using AI,https://www.reddit.com/r/MachineLearning/comments/6js6kr/n_a_quick_guide_to_identify_twitterbots_using_ai/,molode,1498564809,,0,1
1158,2017-6-27,2017,6,27,21,6jsa6b,[P] My new plaything: SFWchk - Is it clean? Or is it pr0n? Let the A.I. decides!,https://www.reddit.com/r/MachineLearning/comments/6jsa6b/p_my_new_plaything_sfwchk_is_it_clean_or_is_it/,deefha,1498565896,"Hi all, I would like to introduce you my weekend freetime project: SFWchk is a dead simple &amp; user friendly content checker for offensive / adult images. Built on famous open_nsfw Caffe model just for fun :-) https://sfwchk.com",5,0
1159,2017-6-27,2017,6,27,21,6jsani,[N] The End of the Honeymoon: Falling Out of Love with quantstrat,https://www.reddit.com/r/MachineLearning/comments/6jsani/n_the_end_of_the_honeymoon_falling_out_of_love/,janemoz,1498566045,,0,1
1160,2017-6-27,2017,6,27,21,6jscyi,"[N] Ce soir, Paris Machine Learning meetup #10 Ending Season 4 : Large-Scale Video Classification, Community Detection, Code Mining, Maps, Load Monitoring and Cognitive. (Slides in English, Talks in French)",https://www.reddit.com/r/MachineLearning/comments/6jscyi/n_ce_soir_paris_machine_learning_meetup_10_ending/,compsens,1498566767,,0,0
1161,2017-6-27,2017,6,27,21,6jsfon,[N] Deep Learning intuition for a business user | Deeplearningtrack,https://www.reddit.com/r/MachineLearning/comments/6jsfon/n_deep_learning_intuition_for_a_business_user/,magneticono,1498567619,,0,1
1162,2017-6-27,2017,6,27,22,6jsif2,How 26 Top Marketing Executives Use Artificial Intelligence - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6jsif2/how_26_top_marketing_executives_use_artificial/,conradcreates,1498568453,,0,1
1163,2017-6-27,2017,6,27,23,6jszz5,Chatbots And Millennials: How Smart Brands Should Be Using Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/6jszz5/chatbots_and_millennials_how_smart_brands_should/,hardikmakadia,1498573383,,0,1
1164,2017-6-27,2017,6,27,23,6jt51z,DEEP LEARNING AND ROBOTICS CHALLENGE (by VW Group AI Research Lab),https://www.reddit.com/r/MachineLearning/comments/6jt51z/deep_learning_and_robotics_challenge_by_vw_group/,osdf,1498574761,,0,1
1165,2017-6-28,2017,6,28,0,6jth6y,Building recommendation engines using Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6jth6y/building_recommendation_engines_using_azure/,asthana86,1498577800,,0,1
1166,2017-6-28,2017,6,28,1,6jtwl8,[News] NVIDIA TensorRT 2 released,https://www.reddit.com/r/MachineLearning/comments/6jtwl8/news_nvidia_tensorrt_2_released/,[deleted],1498581567,[deleted],1,1
1167,2017-6-28,2017,6,28,2,6jucf4,[P] Neural image caption generator example in Keras.,https://www.reddit.com/r/MachineLearning/comments/6jucf4/p_neural_image_caption_generator_example_in_keras/,oarriaga,1498585267,,10,138
1168,2017-6-28,2017,6,28,2,6jugzm,MSc Software Engineering vs MSc Computer Science vs MSc Math/Statistics for 'Data Science / Machine Learning',https://www.reddit.com/r/MachineLearning/comments/6jugzm/msc_software_engineering_vs_msc_computer_science/,[deleted],1498586366,[removed],0,1
1169,2017-6-28,2017,6,28,3,6jui39,[N] Course: Deep Learning for Computer Vision with TensorFlow Santa Clara 2017,https://www.reddit.com/r/MachineLearning/comments/6jui39/n_course_deep_learning_for_computer_vision_with/,computervision,1498586618,,2,0
1170,2017-6-28,2017,6,28,3,6juv5s,Precision Gear Manufacturing on Koepfer 140 Gear Hobber,https://www.reddit.com/r/MachineLearning/comments/6juv5s/precision_gear_manufacturing_on_koepfer_140_gear/,trendingfacts,1498589720,,0,1
1171,2017-6-28,2017,6,28,4,6jvbfo,Releasing the Dexterity Network (Dex-Net) 2.0 Dataset for Deep Grasping,https://www.reddit.com/r/MachineLearning/comments/6jvbfo/releasing_the_dexterity_network_dexnet_20_dataset/,huazhe_xu,1498593561,,0,1
1172,2017-6-28,2017,6,28,5,6jvdhm,Freelancing in ML,https://www.reddit.com/r/MachineLearning/comments/6jvdhm/freelancing_in_ml/,jackdaniels79,1498594039,[removed],0,1
1173,2017-6-28,2017,6,28,5,6jvg0k,[D] ML/DL knowledge level for Google position,https://www.reddit.com/r/MachineLearning/comments/6jvg0k/d_mldl_knowledge_level_for_google_position/,SummitSnowStorm,1498594666,"What is the expected ML/ DL knowledge level for a ML Researcher position at Google or for passing the interview with flying colors? I ask out of curiosity, I would like to find out how high the level is compared to other AI research positions in other industries, such as automotive or finance.",35,28
1174,2017-6-28,2017,6,28,5,6jvhna,"[D] Recommendation for ""must read"" RL and DeepRL papers",https://www.reddit.com/r/MachineLearning/comments/6jvhna/d_recommendation_for_must_read_rl_and_deeprl/,dhruvramani,1498595069,,19,63
1175,2017-6-28,2017,6,28,5,6jvk4d,Trying to gauge research coming from an AI startup,https://www.reddit.com/r/MachineLearning/comments/6jvk4d/trying_to_gauge_research_coming_from_an_ai_startup/,townie92,1498595649,[removed],0,1
1176,2017-6-28,2017,6,28,5,6jvkkx,Difference Between Separable Convolution in Deep Learning and Image Processing,https://www.reddit.com/r/MachineLearning/comments/6jvkkx/difference_between_separable_convolution_in_deep/,imanishshah,1498595776,,0,1
1177,2017-6-28,2017,6,28,5,6jvp44,Draw together with a neural network.,https://www.reddit.com/r/MachineLearning/comments/6jvp44/draw_together_with_a_neural_network/,julian88888888,1498596885,,0,1
1178,2017-6-28,2017,6,28,6,6jw0pc,[D] Benchmarking Random Forest Implementations | Data Science Los Angeles,https://www.reddit.com/r/MachineLearning/comments/6jw0pc/d_benchmarking_random_forest_implementations_data/,_alphamaximus_,1498599849,,3,0
1179,2017-6-28,2017,6,28,7,6jwbl2,"So, how important are SELUs?",https://www.reddit.com/r/MachineLearning/comments/6jwbl2/so_how_important_are_selus/,[deleted],1498602764,[removed],0,1
1180,2017-6-28,2017,6,28,8,6jwok6,The 13 Competing Tribes In Artificial Intelligence - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6jwok6/the_13_competing_tribes_in_artificial/,conradcreates,1498606325,,0,1
1181,2017-6-28,2017,6,28,8,6jws4l,Is ML an oversaturated field?,https://www.reddit.com/r/MachineLearning/comments/6jws4l/is_ml_an_oversaturated_field/,[deleted],1498607375,[removed],0,1
1182,2017-6-28,2017,6,28,9,6jwxix,Door and Window Architrave,https://www.reddit.com/r/MachineLearning/comments/6jwxix/door_and_window_architrave/,gwenyosef,1498608978,,0,1
1183,2017-6-28,2017,6,28,9,6jx091,[D] Training on images from different datasets,https://www.reddit.com/r/MachineLearning/comments/6jx091/d_training_on_images_from_different_datasets/,waleedka,1498609754,"I came across this challenge while I'm training an object detection model (similar to Faster R-CNN) to recognize different instances and classes of objects. The classes I want to detect are not all available in one dataset, so I'm trying to combine multiple datasets to create a bigger dataset. Here is the challenge:

Assume dataset1 has classes: dog, cat, bird. And dataset2 has classes: car, airplane, ship. And let's say the model is currently processing an image from dataset1 which happens to have a cat and a car. Since this image is from dataset1, then only the cat is marked as a ground-truth object, and the car is not (i.e. background). This will cause the model to learn that shapes that look like a car are background. And when the model processes an image from dataset2 and it also has a cat and car, this time the car is marked as a ground truth object and the cat is background. So the model will learn that shapes that look like a cat are background. 

I couldn't find any established recommendations on how to handle this scenario. Has anyone here encountered this case? how did you solve it?",6,1
1184,2017-6-28,2017,6,28,9,6jx0wd,[D] Has anyone tried ReLU with a comparison point different than 0?,https://www.reddit.com/r/MachineLearning/comments/6jx0wd/d_has_anyone_tried_relu_with_a_comparison_point/,darkconfidantislife,1498609936,"Basically, instead of 0 replace it with some other hyperparameter?

Inspired by this paper: https://arxiv.org/abs/1706.08098 ",11,1
1185,2017-6-28,2017,6,28,9,6jx5mf,"CMU AI, Unifies Expertise Across Departments and Disciplines",https://www.reddit.com/r/MachineLearning/comments/6jx5mf/cmu_ai_unifies_expertise_across_departments_and/,shagunsodhani,1498611244,,0,1
1186,2017-6-28,2017,6,28,10,6jxes2,[R] [1706.08224] Do GANs actually learn the distribution? An empirical study,https://www.reddit.com/r/MachineLearning/comments/6jxes2/r_170608224_do_gans_actually_learn_the/,evc123,1498613864,,8,23
1187,2017-6-28,2017,6,28,10,6jxh5f,Subtracting information with adversarial networks,https://www.reddit.com/r/MachineLearning/comments/6jxh5f/subtracting_information_with_adversarial_networks/,[deleted],1498614588,[removed],0,1
1188,2017-6-28,2017,6,28,11,6jxku9,Timber Frame Houses Construction,https://www.reddit.com/r/MachineLearning/comments/6jxku9/timber_frame_houses_construction/,gwenyosef,1498615692,,0,1
1189,2017-6-28,2017,6,28,11,6jxlnv,"[P] Tensorflow implementation of Deepmind Interaction Networks for Learning about Objects, Relations and Physics",https://www.reddit.com/r/MachineLearning/comments/6jxlnv/p_tensorflow_implementation_of_deepmind/,jaesik,1498615944,,0,2
1190,2017-6-28,2017,6,28,11,6jxql6,[R] Gradient Episodic Memory for Continuum Learning (FAIR),https://www.reddit.com/r/MachineLearning/comments/6jxql6/r_gradient_episodic_memory_for_continuum_learning/,xternalz,1498617486,,0,6
1191,2017-6-28,2017,6,28,11,6jxsxa,[P] Training 2 NN's Against Eachother?,https://www.reddit.com/r/MachineLearning/comments/6jxsxa/p_training_2_nns_against_eachother/,GotMiIk,1498618198,"Hello,
I have been trying some more advanced neural network projects recently and was wondering if it would be possible to train two NN's against each other. Basically, what I wanted to do was train a NN to play connect four, but then I realized connect four is a 2 player game. So, I'm now wondering if its possible to play two against eachother. I would be using chips placed before loss as the ""success"" measure and to adjust the weights. Would this be possible or is it likely that they would get ""stuck"" somehow?

Thanks",27,3
1192,2017-6-28,2017,6,28,11,6jxtqo,[D] Subtracting information with adversarial networks,https://www.reddit.com/r/MachineLearning/comments/6jxtqo/d_subtracting_information_with_adversarial/,NichG,1498618442,"There's a paper [Censoring Representations with an Adversary](https://arxiv.org/abs/1511.05897) which shows that you can use adversarial networks to remove certain information from an intermediate layer. This was mostly from the point of view of removing all detectable correlations with the censored information (e.g. for privacy or legal purposes).

I have a problem that involves training a low-dimensional auto-regressive model to fill in missing fields in an astronomy dataset (so no legal or privacy concerns here). The model takes all fields as input, but the missing fields are masked out and the model is informed which fields are masked out, and then the probability distribution over each individual missing field is generated one at a time and sampled from to fill in that field. The issue we found is that the masking pattern itself is very informative about the missing values - what is and isn't masked comes from systematic observational biases. So when we perform the fill-in of missing fields in any particular order, the order we choose ends up biasing the distribution of the generated values.

My thought was to use the adversarial censoring trick to remove information about the mask pattern from the intermediate layer of the model. However, this not only removes information about the mask pattern, it removes anything which is correlated with the mask pattern in any way.

With x as the input, m as the mask, and y as the output: the adversarial trick asks for MI(y,m) = 0. But x contains information about y that is duplicated in m, so if the model exploits all of MI(x,y) then that means MI(y,m) &gt; 0 even if the information 'came from' x.

So I'm trying to figure out how to subtract out only the non-duplicated part of the information. That is to say, I should just use the adversary to ensure MI(y,m) &lt;= MI(x,m), rather than zero. Any ideas?",6,1
1193,2017-6-28,2017,6,28,13,6jy8z7,[D] Why Is NumPy Only Now Getting Funded?,https://www.reddit.com/r/MachineLearning/comments/6jy8z7/d_why_is_numpy_only_now_getting_funded/,_alphamaximus_,1498623472,,0,5
1194,2017-6-28,2017,6,28,13,6jy9p3,[D] Using RuleFit Ensemble Models Is About to Become Very Important,https://www.reddit.com/r/MachineLearning/comments/6jy9p3/d_using_rulefit_ensemble_models_is_about_to/,_alphamaximus_,1498623730,,0,2
1195,2017-6-28,2017,6,28,14,6jylxj,Cement Concrete Supplies,https://www.reddit.com/r/MachineLearning/comments/6jylxj/cement_concrete_supplies/,gwenyosef,1498628298,,0,1
1196,2017-6-28,2017,6,28,14,6jyohc,Large or Small minibatch size in NLP task for better generalization?,https://www.reddit.com/r/MachineLearning/comments/6jyohc/large_or_small_minibatch_size_in_nlp_task_for/,solobo1,1498629307,[removed],1,1
1197,2017-6-28,2017,6,28,15,6jyshl,[N] Andrew Ng joins Drive.ai board,https://www.reddit.com/r/MachineLearning/comments/6jyshl/n_andrew_ng_joins_driveai_board/,Dim25,1498630872,,37,89
1198,2017-6-28,2017,6,28,16,6jyyzm,[Research] Poincar Embeddings for Learning Hierarchical Representations,https://www.reddit.com/r/MachineLearning/comments/6jyyzm/research_poincar_embeddings_for_learning/,[deleted],1498633623,[deleted],0,1
1199,2017-6-28,2017,6,28,16,6jyz1x,[R] Poincar Embeddings for Learning Hierarchical Representations,https://www.reddit.com/r/MachineLearning/comments/6jyz1x/r_poincar_embeddings_for_learning_hierarchical/,olBaa,1498633646,,2,42
1200,2017-6-28,2017,6,28,16,6jz215,Automatic Front and Backside Double Sides Sticker Bottle Labeling Applic...,https://www.reddit.com/r/MachineLearning/comments/6jz215/automatic_front_and_backside_double_sides_sticker/,hymachinery,1498634951,,0,1
1201,2017-6-28,2017,6,28,16,6jz2ya,Github code of Kaggle Winner solution for the Youtube 8 million video,https://www.reddit.com/r/MachineLearning/comments/6jz2ya/github_code_of_kaggle_winner_solution_for_the/,datadoume,1498635351,,1,1
1202,2017-6-28,2017,6,28,16,6jz4xs,Concrete Removal Service,https://www.reddit.com/r/MachineLearning/comments/6jz4xs/concrete_removal_service/,gwenyosef,1498636290,,0,1
1203,2017-6-28,2017,6,28,16,6jz5f4,[P] Projected Gradient Descent for finding Max(Min) Eigenvalues,https://www.reddit.com/r/MachineLearning/comments/6jz5f4/p_projected_gradient_descent_for_finding_maxmin/,sudeepraja,1498636527,,7,0
1204,2017-6-28,2017,6,28,17,6jz90l,HEB Steel plate shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6jz90l/heb_steel_plate_shot_blasting_machine/,mayflayairblasting,1498638235,,1,1
1205,2017-6-28,2017,6,28,19,6jzofm,"Tunnel Boring Machine (TBM) Market market is comprehensively analyzed for Consumption, Growth, Trends, Top Manufacturers, Competitive Landscape, and Forecasts to 2022",https://www.reddit.com/r/MachineLearning/comments/6jzofm/tunnel_boring_machine_tbm_market_market_is/,jemfernandez,1498645285,,0,1
1206,2017-6-28,2017,6,28,19,6jzozx,Concreting,https://www.reddit.com/r/MachineLearning/comments/6jzozx/concreting/,gwenyosef,1498645526,,0,1
1207,2017-6-28,2017,6,28,20,6jztth,"TOPBOTS - The Best of Applied Artificial Intelligence, Machine Learning, Automation, Bots, Chatbots",https://www.reddit.com/r/MachineLearning/comments/6jztth/topbots_the_best_of_applied_artificial/,conradcreates,1498647615,,0,1
1208,2017-6-28,2017,6,28,20,6jzzdl,[N] Machine Learning in Science and Industry,https://www.reddit.com/r/MachineLearning/comments/6jzzdl/n_machine_learning_in_science_and_industry/,janemoz,1498649702,,0,1
1209,2017-6-28,2017,6,28,20,6k01jg,[N] How to install SQL Workbench for postgreSQL? (6 steps),https://www.reddit.com/r/MachineLearning/comments/6k01jg/n_how_to_install_sql_workbench_for_postgresql_6/,digitalson,1498650501,,0,1
1210,2017-6-28,2017,6,28,21,6k04a8,[N] The 5 Must Read Books For Every Data Scientist,https://www.reddit.com/r/MachineLearning/comments/6k04a8/n_the_5_must_read_books_for_every_data_scientist/,dearpetra,1498651470,,0,1
1211,2017-6-28,2017,6,28,21,6k08wq,"[N] Architecture of Giants: Data Stacks at Facebook, Netflix, Airbnb, and Pinterest",https://www.reddit.com/r/MachineLearning/comments/6k08wq/n_architecture_of_giants_data_stacks_at_facebook/,dearpetra,1498652944,,0,1
1212,2017-6-28,2017,6,28,21,6k09f8,[N] Are Our Customers Where They Should Be?,https://www.reddit.com/r/MachineLearning/comments/6k09f8/n_are_our_customers_where_they_should_be/,molode,1498653098,,0,1
1213,2017-6-28,2017,6,28,21,6k0anv,[N] Data Science &amp; Machine Learning Platforms for the Enterprise,https://www.reddit.com/r/MachineLearning/comments/6k0anv/n_data_science_machine_learning_platforms_for_the/,friscotime,1498653509,,0,1
1214,2017-6-28,2017,6,28,21,6k0cj5,[N] Reach Your Audience with Accessible and Inclusive Design,https://www.reddit.com/r/MachineLearning/comments/6k0cj5/n_reach_your_audience_with_accessible_and/,lalypopa123,1498654102,,0,1
1215,2017-6-28,2017,6,28,22,6k0jqk,[P] How to actually build a neural network from blocks? - with notMNIST in Keras [webinar],https://www.reddit.com/r/MachineLearning/comments/6k0jqk/p_how_to_actually_build_a_neural_network_from/,pmigdal,1498656311,,1,0
1216,2017-6-28,2017,6,28,22,6k0onc,[D] Why is prediction the essence of intelligence?,https://www.reddit.com/r/MachineLearning/comments/6k0onc/d_why_is_prediction_the_essence_of_intelligence/,[deleted],1498657719,[deleted],0,0
1217,2017-6-28,2017,6,28,23,6k10kw,What are some results and insights you have found by applying Machine Learning on application/system logs?,https://www.reddit.com/r/MachineLearning/comments/6k10kw/what_are_some_results_and_insights_you_have_found/,subhrm,1498661308,[removed],0,1
1218,2017-6-29,2017,6,29,0,6k14qg,Microsoft releases open-source library for deep learning on Spark,https://www.reddit.com/r/MachineLearning/comments/6k14qg/microsoft_releases_opensource_library_for_deep/,mhamilton723,1498662364,,0,3
1219,2017-6-29,2017,6,29,0,6k15qa,[R] [1704.04503] Improving Object Detection With One Line of Code,https://www.reddit.com/r/MachineLearning/comments/6k15qa/r_170404503_improving_object_detection_with_one/,LiteFatSushi,1498662633,,9,7
1220,2017-6-29,2017,6,29,0,6k17mm,Two ways to improve model accuracy and reduce training time -Explained,https://www.reddit.com/r/MachineLearning/comments/6k17mm/two_ways_to_improve_model_accuracy_and_reduce/,[deleted],1498663122,[deleted],0,1
1221,2017-6-29,2017,6,29,0,6k1gn7,"Simple Questions Thread June 28, 2017",https://www.reddit.com/r/MachineLearning/comments/6k1gn7/simple_questions_thread_june_28_2017/,AutoModerator,1498665331,[removed],0,1
1222,2017-6-29,2017,6,29,1,6k1r59,[R] Learning non-maximum suppression (for object detection),https://www.reddit.com/r/MachineLearning/comments/6k1r59/r_learning_nonmaximum_suppression_for_object/,your_loss_not_mine,1498667789,,0,2
1223,2017-6-29,2017,6,29,1,6k1vwz,[R] Dynamic routing in artificial neural networks (ICML2017),https://www.reddit.com/r/MachineLearning/comments/6k1vwz/r_dynamic_routing_in_artificial_neural_networks/,MasonicHedgehog,1498668945,,3,51
1224,2017-6-29,2017,6,29,2,6k20zp,Bits of Love: How AI Fills Our Human Need For Intimacy - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6k20zp/bits_of_love_how_ai_fills_our_human_need_for/,conradcreates,1498670163,,0,1
1225,2017-6-29,2017,6,29,2,6k21t4,Implementation of the DCGAN paper in Keras,https://www.reddit.com/r/MachineLearning/comments/6k21t4/implementation_of_the_dcgan_paper_in_keras/,yashkatariya,1498670348,,0,1
1226,2017-6-29,2017,6,29,2,6k21wc,Basics of Machine Learning Intuitions and Implementations - Demystified,https://www.reddit.com/r/MachineLearning/comments/6k21wc/basics_of_machine_learning_intuitions_and/,harsha0795,1498670371,,0,1
1227,2017-6-29,2017,6,29,2,6k24fz,Microsoft uses CNTK on Spark for snow leopard conservation,https://www.reddit.com/r/MachineLearning/comments/6k24fz/microsoft_uses_cntk_on_spark_for_snow_leopard/,mhamilton723,1498670982,,0,1
1228,2017-6-29,2017,6,29,2,6k2a3l,Recognizing Emotions using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6k2a3l/recognizing_emotions_using_machine_learning/,slavakurilyak,1498672325,,1,1
1229,2017-6-29,2017,6,29,3,6k2ch4,[D] Two ways to improve model accuracy and reduce training time -Explained,https://www.reddit.com/r/MachineLearning/comments/6k2ch4/d_two_ways_to_improve_model_accuracy_and_reduce/,harvey_slash,1498672884,,13,29
1230,2017-6-29,2017,6,29,3,6k2kst,Is TensorFlow Lite even released?,https://www.reddit.com/r/MachineLearning/comments/6k2kst/is_tensorflow_lite_even_released/,smalldata99,1498674850,[removed],0,1
1231,2017-6-29,2017,6,29,3,6k2o0y,Global Food Packaging Equipments Sales Market: HTF Market,https://www.reddit.com/r/MachineLearning/comments/6k2o0y/global_food_packaging_equipments_sales_market_htf/,wadiarobert9,1498675632,,0,1
1232,2017-6-29,2017,6,29,4,6k2sr8,[D] OpenAI open sources a high-performance Python library for robotic simulation,https://www.reddit.com/r/MachineLearning/comments/6k2sr8/d_openai_open_sources_a_highperformance_python/,cherls,1498676758,,27,282
1233,2017-6-29,2017,6,29,4,6k2vqs,A quick and intuitive explanation of gradient descent,https://www.reddit.com/r/MachineLearning/comments/6k2vqs/a_quick_and_intuitive_explanation_of_gradient/,Karlpy,1498677468,,0,1
1234,2017-6-29,2017,6,29,4,6k2xi9,Using Tensorflow and AI as a web development consultancy,https://www.reddit.com/r/MachineLearning/comments/6k2xi9/using_tensorflow_and_ai_as_a_web_development/,[deleted],1498677892,[deleted],0,1
1235,2017-6-29,2017,6,29,4,6k31o2,What Ive learned about neural network quantization [Discussion],https://www.reddit.com/r/MachineLearning/comments/6k31o2/what_ive_learned_about_neural_network/,[deleted],1498678921,[deleted],0,1
1236,2017-6-29,2017,6,29,4,6k34h5,[D] What Ive learned about neural network quantization,https://www.reddit.com/r/MachineLearning/comments/6k34h5/d_what_ive_learned_about_neural_network/,tfzb,1498679606,,0,1
1237,2017-6-29,2017,6,29,5,6k3748,[D] Zero to One  A Ton of Awe-Inspiring Deep Learning Demos with Code for Beginners,https://www.reddit.com/r/MachineLearning/comments/6k3748/d_zero_to_one_a_ton_of_aweinspiring_deep_learning/,tfzb,1498680224,,2,0
1238,2017-6-29,2017,6,29,5,6k3kfi,Machine Learning: A Probabilistic Perspective by Kevin Murphy,https://www.reddit.com/r/MachineLearning/comments/6k3kfi/machine_learning_a_probabilistic_perspective_by/,thecpshah,1498683535,[removed],0,1
1239,2017-6-29,2017,6,29,6,6k3kpm,Global Hydraulic Bearing Puller Sales Market: HTF Market,https://www.reddit.com/r/MachineLearning/comments/6k3kpm/global_hydraulic_bearing_puller_sales_market_htf/,wadiarobert9,1498683604,,0,1
1240,2017-6-29,2017,6,29,6,6k3s2z,Deep Learning without Backpropagation,https://www.reddit.com/r/MachineLearning/comments/6k3s2z/deep_learning_without_backpropagation/,iamtrask,1498685477,,0,1
1241,2017-6-29,2017,6,29,6,6k3wf3,Trial Run of a Turret Type Milling Machine (Make Bridgeport),https://www.reddit.com/r/MachineLearning/comments/6k3wf3/trial_run_of_a_turret_type_milling_machine_make/,trendingfacts,1498686564,,0,1
1242,2017-6-29,2017,6,29,7,6k40fw,[R] [1706.08224v1] Do GANs actually learn the distribution? An empirical study,https://www.reddit.com/r/MachineLearning/comments/6k40fw/r_170608224v1_do_gans_actually_learn_the/,[deleted],1498687578,[deleted],1,1
1243,2017-6-29,2017,6,29,7,6k43jy,How to customize a word embedding in python?,https://www.reddit.com/r/MachineLearning/comments/6k43jy/how_to_customize_a_word_embedding_in_python/,NickFlare,1498688423,[removed],0,1
1244,2017-6-29,2017,6,29,8,6k4bzj,Capital One Seals Tech Street Cred With Forays Into A.I. - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6k4bzj/capital_one_seals_tech_street_cred_with_forays/,conradcreates,1498690816,,0,1
1245,2017-6-29,2017,6,29,8,6k4d42,Bricklaying Construction,https://www.reddit.com/r/MachineLearning/comments/6k4d42/bricklaying_construction/,gwenyosef,1498691150,,0,1
1246,2017-6-29,2017,6,29,8,6k4fbk,Cleaning Services,https://www.reddit.com/r/MachineLearning/comments/6k4fbk/cleaning_services/,gwenyosef,1498691771,,0,1
1247,2017-6-29,2017,6,29,8,6k4ifd,Carpet Sanitising and Deodorising,https://www.reddit.com/r/MachineLearning/comments/6k4ifd/carpet_sanitising_and_deodorising/,gwenyosef,1498692715,,0,1
1248,2017-6-29,2017,6,29,9,6k4o4o,Concrete Cleaning How to,https://www.reddit.com/r/MachineLearning/comments/6k4o4o/concrete_cleaning_how_to/,gwenyosef,1498694441,,0,1
1249,2017-6-29,2017,6,29,9,6k4sqj,[Discussion] What is the purpose of noise in a Conditional GAN?,https://www.reddit.com/r/MachineLearning/comments/6k4sqj/discussion_what_is_the_purpose_of_noise_in_a/,nitred,1498695799,"I just implemented a [cGAN](https://arxiv.org/pdf/1411.1784.pdf) for generating MNIST data where I concatenated the noise (z) and the one-hot labels (y) as the input to the Generator.The results looked really promising within a few epochs and results were almost realistic within a 100 epochs.

Then after a bit of free flowing thought I wondered if removing the noise (z) entirely and only have the one-hot labels (y) as the input would convert the problem to supervised learning and I would have fast convergence and great looking results. However when I implemented this, the results looked promising for 5 epochs but then took a wrong turn and the results looked nothing like the MNIST data.

I understand that this defeats the purpose of the paper itself which tries alternatives to the one-to-one mapping of supervised learning.
&gt; A second issue is that much of the work to date has focused on learning one-to-one mappings from input to output. However, many interesting problems are more naturally thought of as a probabilistic one-to-many mapping.

But assuming that I don't mind having a one-to-one mapping, why doesn't conditioning the generator on only the labels (y) as input produce good results? What is the purpose of the noise (z)?

Note: In case you have a complaint that the way I concatenated the noise and labels initially was not part of the original architecture of the paper, here's an interesting discussion from a few days ago about something similar. [Link](https://www.reddit.com/r/MachineLearning/comments/6je46u/d_about_conditional_gan_when_to_concatenate/)

**EDIT**: Here's a [link](https://nitred.com/epochs.html) containing the output of the generator after a select few epochs. The link will be up only for a few days.",14,2
1250,2017-6-29,2017,6,29,9,6k4xxv,[P] A short Conditional DCGAN tensorflow implementation,https://www.reddit.com/r/MachineLearning/comments/6k4xxv/p_a_short_conditional_dcgan_tensorflow/,shabeyyub,1498697413,,0,1
1251,2017-6-29,2017,6,29,9,6k4yg2,Reinforcement Learning Examples (Added Advanced Examples),https://www.reddit.com/r/MachineLearning/comments/6k4yg2/reinforcement_learning_examples_added_advanced/,[deleted],1498697577,[deleted],0,1
1252,2017-6-29,2017,6,29,9,6k4zg1,[P] More Collection of Reinforcement Learning Examples. (We Added Advanced Examples),https://www.reddit.com/r/MachineLearning/comments/6k4zg1/p_more_collection_of_reinforcement_learning/,[deleted],1498697918,[deleted],1,1
1253,2017-6-29,2017,6,29,10,6k4zsn,The 12 Chinese Tech Companies You Should Know - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6k4zsn/the_12_chinese_tech_companies_you_should_know/,conradcreates,1498698015,,0,1
1254,2017-6-29,2017,6,29,10,6k50nj,[P] A Collection of Minimal RL Algorithms (now with advanced examples),https://www.reddit.com/r/MachineLearning/comments/6k50nj/p_a_collection_of_minimal_rl_algorithms_now_with/,kwk236,1498698277,,4,51
1255,2017-6-29,2017,6,29,10,6k58t6,AusPost trials machine learning to manage unpaid bills,https://www.reddit.com/r/MachineLearning/comments/6k58t6/auspost_trials_machine_learning_to_manage_unpaid/,killinghurts,1498700869,,0,1
1256,2017-6-29,2017,6,29,11,6k5b6h,Tutorial on face search?,https://www.reddit.com/r/MachineLearning/comments/6k5b6h/tutorial_on_face_search/,taewoo,1498701622,[removed],0,1
1257,2017-6-29,2017,6,29,12,6k5pmc,JCT blander machine can be role as paint production machine?,https://www.reddit.com/r/MachineLearning/comments/6k5pmc/jct_blander_machine_can_be_role_as_paint/,JCT_MACHINE,1498706284,,0,1
1258,2017-6-29,2017,6,29,13,6k64la,iMessage Spam Detection using CoreML,https://www.reddit.com/r/MachineLearning/comments/6k64la/imessage_spam_detection_using_coreml/,[deleted],1498711505,[deleted],0,1
1259,2017-6-29,2017,6,29,14,6k6cek,iMessage Spam Detection through CoreML,https://www.reddit.com/r/MachineLearning/comments/6k6cek/imessage_spam_detection_through_coreml/,halcyon64,1498714381,,0,1
1260,2017-6-29,2017,6,29,15,6k6m1q,Improved Technological Experience with Machine Learning!,https://www.reddit.com/r/MachineLearning/comments/6k6m1q/improved_technological_experience_with_machine/,madridsoftware123,1498718272,,0,1
1261,2017-6-29,2017,6,29,16,6k6pus,Logistic Regression - The Math of Intelligence (Week 2),https://www.reddit.com/r/MachineLearning/comments/6k6pus/logistic_regression_the_math_of_intelligence_week/,funmaster11,1498719895,,0,1
1262,2017-6-29,2017,6,29,16,6k6w7c,Continuous Signal Classification,https://www.reddit.com/r/MachineLearning/comments/6k6w7c/continuous_signal_classification/,[deleted],1498722726,[removed],0,1
1263,2017-6-29,2017,6,29,17,6k6xsg,[D] Continuous signal classification,https://www.reddit.com/r/MachineLearning/comments/6k6xsg/d_continuous_signal_classification/,melgor89,1498723496,"Recently I was reading some paper about Video Classification. Most of them have used popular opensourced database which are 'Frame-Based' classification or pre-segmented clips classification. I think that this idea is not applicable to all Continuous Signal Classification. 
Let me explain it better: We have a guy which show us 'Sign Language'. So firstly we need to see all trajectory of hand, then we can classify the 'sign'. And normally there are many sign is one sequence to create the sentence, where each sign can have different length. Or even worse, we want to automatically translate 'sign language' at film to text. 

This case is different from 'Frame-Based' recognition. And I was thinking that in such case we need to 2 algorithm:

1. Segment video that each clip contain all single sign. Remove clip where no sign occur.
2. Classify that sign

Am I right?
I was reading papers about gesture recognition and it look like that (segmentation of video was based on movement of hand)

Maybe you know how such problem is resolved at ""Lip Reading"" (as each word have different length) and ""Speech Recognition"" (as each word have different length)?
",6,2
1264,2017-6-29,2017,6,29,17,6k717t,"[P] VGG Deep Face Recognition (caffe, C++)",https://www.reddit.com/r/MachineLearning/comments/6k717t/p_vgg_deep_face_recognition_caffe_c/,the-fire-fist,1498725104,,0,4
1265,2017-6-29,2017,6,29,17,6k72k9,An AI Learning to play Flappy Bird using Evolution Strategies,https://www.reddit.com/r/MachineLearning/comments/6k72k9/an_ai_learning_to_play_flappy_bird_using/,johns93,1498725749,,1,1
1266,2017-6-29,2017,6,29,18,6k754r,[N] Monte Carlo Method in R (with worked examples),https://www.reddit.com/r/MachineLearning/comments/6k754r/n_monte_carlo_method_in_r_with_worked_examples/,digitalson,1498726928,,0,1
1267,2017-6-29,2017,6,29,18,6k760a,Designing an OCR System,https://www.reddit.com/r/MachineLearning/comments/6k760a/designing_an_ocr_system/,[deleted],1498727334,[removed],0,1
1268,2017-6-29,2017,6,29,18,6k7795,Denoising autoencoder output tensorflow,https://www.reddit.com/r/MachineLearning/comments/6k7795/denoising_autoencoder_output_tensorflow/,AlloraQuesto,1498727910,[removed],0,1
1269,2017-6-29,2017,6,29,18,6k79yr,[N] On Facebook News in the Philippines: Using topic modeling to find trends in online news coverage,https://www.reddit.com/r/MachineLearning/comments/6k79yr/n_on_facebook_news_in_the_philippines_using_topic/,trumtra,1498729192,,1,2
1270,2017-6-29,2017,6,29,19,6k7f2e,[N] 7 types of job profiles that makes you a Data Scientist,https://www.reddit.com/r/MachineLearning/comments/6k7f2e/n_7_types_of_job_profiles_that_makes_you_a_data/,magneticono,1498731414,,0,1
1271,2017-6-29,2017,6,29,19,6k7gew,[N] List of Free Must-Read Books for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6k7gew/n_list_of_free_mustread_books_for_machine_learning/,friscotime,1498731983,,0,1
1272,2017-6-29,2017,6,29,19,6k7ghs,Interpreting neurons in an LSTM network - How does a bi-di LSTM learn to transliterate text?,https://www.reddit.com/r/MachineLearning/comments/6k7ghs/interpreting_neurons_in_an_lstm_network_how_does/,adammathias,1498732019,,0,1
1273,2017-6-29,2017,6,29,19,6k7idf,Predicting Earthquakes with solar data - Help needed,https://www.reddit.com/r/MachineLearning/comments/6k7idf/predicting_earthquakes_with_solar_data_help_needed/,devils_advocaat,1498732840,,0,1
1274,2017-6-29,2017,6,29,19,6k7jev,[N] Predicting Churn without Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6k7jev/n_predicting_churn_without_machine_learning/,magneticono,1498733244,,0,1
1275,2017-6-29,2017,6,29,19,6k7kg1,[N] Feature importance and why its important,https://www.reddit.com/r/MachineLearning/comments/6k7kg1/n_feature_importance_and_why_its_important/,jackblun,1498733696,,0,1
1276,2017-6-29,2017,6,29,21,6k7wnb,"Input: 4 parameters, output:1 parameter. How to find the best fit function between them?",https://www.reddit.com/r/MachineLearning/comments/6k7wnb/input_4_parameters_output1_parameter_how_to_find/,oqowa,1498738213,[removed],0,1
1277,2017-6-29,2017,6,29,21,6k7xqc,New free speaker ID database with over 1000 speakers,https://www.reddit.com/r/MachineLearning/comments/6k7xqc/new_free_speaker_id_database_with_over_1000/,[deleted],1498738560,[deleted],0,1
1278,2017-6-29,2017,6,29,21,6k80ae,VoxCeleb: New free speaker ID dataset with over 1000 speakers,https://www.reddit.com/r/MachineLearning/comments/6k80ae/voxceleb_new_free_speaker_id_dataset_with_over/,ArshNags,1498739346,,2,2
1279,2017-6-29,2017,6,29,22,6k8f1j,Alternative Face v1.1,https://www.reddit.com/r/MachineLearning/comments/6k8f1j/alternative_face_v11/,cbeak,1498743857,,0,1
1280,2017-6-29,2017,6,29,22,6k8hil,"[1706.05087] Plan, Attend, Generate: Character-level Neural Machine Translation with Planning in the Decoder",https://www.reddit.com/r/MachineLearning/comments/6k8hil/170605087_plan_attend_generate_characterlevel/,AnvaMiba,1498744570,,1,1
1281,2017-6-29,2017,6,29,23,6k8q9j,[D] Interpreting neurons in an LSTM network,https://www.reddit.com/r/MachineLearning/comments/6k8q9j/d_interpreting_neurons_in_an_lstm_network/,HrantKhachatrian,1498746880,,0,141
1282,2017-6-29,2017,6,29,23,6k8qij,Question on nonlinear autoregressive network with exogenous inputs (NARX) modelling,https://www.reddit.com/r/MachineLearning/comments/6k8qij/question_on_nonlinear_autoregressive_network_with/,shine10101,1498746950,[removed],0,1
1283,2017-6-30,2017,6,30,0,6k8z9q,"Hedge Funds Look to Machine Learning, Crowdsourcing for Competitive Advantage",https://www.reddit.com/r/MachineLearning/comments/6k8z9q/hedge_funds_look_to_machine_learning/,bettytownsel,1498749205,,0,1
1284,2017-6-30,2017,6,30,0,6k91ie,[R] Anyone wants to register ICIP 2017 together?,https://www.reddit.com/r/MachineLearning/comments/6k91ie/r_anyone_wants_to_register_icip_2017_together/,leehomyc,1498749788,"It says one full registration can cover up to four papers (not necessarily have their name on the paper). I am wondering if anyone is interested in registering the paper together?

Thanks,",2,3
1285,2017-6-30,2017,6,30,0,6k97di,Why we use negative mining,https://www.reddit.com/r/MachineLearning/comments/6k97di/why_we_use_negative_mining/,cleverusername1000,1498751312,,0,1
1286,2017-6-30,2017,6,30,0,6k99tv,NIPS deadline spiking p2.16xlarge costs on AWS,https://www.reddit.com/r/MachineLearning/comments/6k99tv/nips_deadline_spiking_p216xlarge_costs_on_aws/,kayandand,1498751930,,0,1
1287,2017-6-30,2017,6,30,1,6k9c6t,What would be a good topic do an undergrad project on ML?,https://www.reddit.com/r/MachineLearning/comments/6k9c6t/what_would_be_a_good_topic_do_an_undergrad/,mesenkoha,1498752485,[removed],0,1
1288,2017-6-30,2017,6,30,1,6k9cal,Neural Networks from Scratch (in R),https://www.reddit.com/r/MachineLearning/comments/6k9cal/neural_networks_from_scratch_in_r/,hoaphumanoid,1498752508,,0,1
1289,2017-6-30,2017,6,30,1,6k9caw,"I just started a niche subreddit which relates to /ML, would anyone be interested in moderating with me?",https://www.reddit.com/r/MachineLearning/comments/6k9caw/i_just_started_a_niche_subreddit_which_relates_to/,onegazillion,1498752510,[removed],0,1
1290,2017-6-30,2017,6,30,1,6k9glk,[D] Tips for regression problem wanted,https://www.reddit.com/r/MachineLearning/comments/6k9glk/d_tips_for_regression_problem_wanted/,maka89,1498753572,"I want to do regression on a field based on its coordinates x,y,z. 

Problem is that I have only have measurements on a few x,y coordinates. But  there are several z measurements on each of these locations(But the number varies from location to location)

I want my model to have maximum predictive power on a new coordinate xn,yn. How do I make this happen?

 That is make my model be applicable to new x,y locations instead of trying to get high accuracy in the z-direction.
Looking to use neural nets or Gaussian Process Regression preferably. But if another method is more suitable, let me know 
",5,2
1291,2017-6-30,2017,6,30,1,6k9gy2,[D] Why Doesn't Google Amass All Chat Data to Train a Large Chatbot?,https://www.reddit.com/r/MachineLearning/comments/6k9gy2/d_why_doesnt_google_amass_all_chat_data_to_train/,nickshahml,1498753660,"I picked Google, but I also believe Microsoft/Apple/FB could do this as well. 

Why couldn't they go through these sources:

1. Youtube -- speech to text all audio
2. Podcasts -- speech to text all audio
3. Scrape all forum conversations (including reddit/twitter)
4. Any internal chat datasets between employees
5. (if you're Microsoft) use skype chat dataset
6. (if you're Apple) use iphone chat dataset (not sure what privacy policy is)
7. (if you're Google) use hangouts dataset
8. (if you're facebook), use fb messenger dataset

At this point, you would be looking at a minimum ~10gb of chat data. Now train a very, very large seq2seq model (or ""attention is all you need""). The hidden state size would be somewhere between 16k to 64k. 

Yes, there are problems with max likelihood and there have been some papers trying address text in the adversarial space. But you would think with this much data, it would still produce a very versatile chatbot. 

Its possible that this has already been tried and it doesn't perform well, but wouldn't you think they would publish an effort like this? Or at least release an API on it?",29,0
1292,2017-6-30,2017,6,30,1,6k9ibc,[D] Designing an OCR system,https://www.reddit.com/r/MachineLearning/comments/6k9ibc/d_designing_an_ocr_system/,Zerithious,1498753984,"I wish to design an OCR system to digitize scanned documents. The system will need to both segment the document to different elements, e.g. ""text"", ""image"", ""table"" and then perform OCR on text blocks.


This is my current proposal, is this overkill? please provide criticism.

1. For segmentation (dividing the document into ""blocks""), I want to do pixel-level semantic segmentation, I take my inspiration from [this](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf) article (""Fully Convolutional Networks for Semantic Segmentation"")


2. For the OCR system, I want to build something on the basis of [this](https://github.com/meijieru/crnn.pytorch) project. It was designed for scene text recognition so I'm unsure whether it is overkill for this black-on-white, finite-font-set problem.


As for training, I have the ability to generate random documents with random elements (blocks), font types/sizes, etc. so I'm not worried about data.",5,9
1293,2017-6-30,2017,6,30,1,6k9l3j,[D] ArXiv Sanity Preserver: do people use it? What would you change in it?,https://www.reddit.com/r/MachineLearning/comments/6k9l3j/d_arxiv_sanity_preserver_do_people_use_it_what/,Aerthisprime,1498754667,"I was recently introduced to http://www.arxiv-sanity.com/ and it seems like a great tool, mostly to save papers and more efficiently find other papers that might interest you.

I'm wondering if anyone has a sense of how widely it is in fact used by the community, and if not very widely why that is. What are its drawbacks compared to just using arXiv? I'm also puzzled as to why this tool does not seem to exist yet for other areas of arXiv, so any insight you might have would be appreciated.",26,43
1294,2017-6-30,2017,6,30,2,6k9ovm,5 Key Investment Opportunities For Data-Driven Healthcare - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6k9ovm/5_key_investment_opportunities_for_datadriven/,conradcreates,1498755639,,0,1
1295,2017-6-30,2017,6,30,2,6k9tty,[R] YellowFin and the Art of Momentum Tuning,https://www.reddit.com/r/MachineLearning/comments/6k9tty/r_yellowfin_and_the_art_of_momentum_tuning/,rilut,1498756817,,2,23
1296,2017-6-30,2017,6,30,2,6k9ulr,[R] Performance RNN: Generating Music with Expressive Timing and Dynamics,https://www.reddit.com/r/MachineLearning/comments/6k9ulr/r_performance_rnn_generating_music_with/,hardmaru,1498756996,,4,43
1297,2017-6-30,2017,6,30,3,6ka9i2,[R] [1706.08495] Uncertainty Decomposition in Bayesian Neural Networks with Latent Variables,https://www.reddit.com/r/MachineLearning/comments/6ka9i2/r_170608495_uncertainty_decomposition_in_bayesian/,sssub,1498760610,,0,25
1298,2017-6-30,2017,6,30,3,6kadaq,[R] Opportunities And Obstacles For Deep Learning In Biology And Medicine,https://www.reddit.com/r/MachineLearning/comments/6kadaq/r_opportunities_and_obstacles_for_deep_learning/,cbeak,1498761544,,1,22
1299,2017-6-30,2017,6,30,4,6kak0y,How to Ruin your Business with Data Science and Machine Learning [Recorded Webinar],https://www.reddit.com/r/MachineLearning/comments/6kak0y/how_to_ruin_your_business_with_data_science_and/,dreyco,1498763178,,0,1
1300,2017-6-30,2017,6,30,4,6kaq33,Question on just TESTING/RUNNING a keras based RCNN model on amazon EC2 instance,https://www.reddit.com/r/MachineLearning/comments/6kaq33/question_on_just_testingrunning_a_keras_based/,SSS44,1498764668,[removed],0,1
1301,2017-6-30,2017,6,30,4,6kav60,How to Visualize Your Recurrent Neural Network with Attention in Keras,https://www.reddit.com/r/MachineLearning/comments/6kav60/how_to_visualize_your_recurrent_neural_network/,[deleted],1498765893,[deleted],0,2
1302,2017-6-30,2017,6,30,5,6kb3cp,Using feature importance efficiently,https://www.reddit.com/r/MachineLearning/comments/6kb3cp/using_feature_importance_efficiently/,zegui7,1498767903,[removed],0,1
1303,2017-6-30,2017,6,30,5,6kb765,Does having sum and maximum cost function to One on the last map might make the network converge?,https://www.reddit.com/r/MachineLearning/comments/6kb765/does_having_sum_and_maximum_cost_function_to_one/,falmasri,1498768870,[removed],0,1
1304,2017-6-30,2017,6,30,5,6kba5c,[R] YellowFin and the Art of Momentum Tuning,https://www.reddit.com/r/MachineLearning/comments/6kba5c/r_yellowfin_and_the_art_of_momentum_tuning/,bbsome,1498769651,,0,3
1305,2017-6-30,2017,6,30,7,6kbuim,Medical diagnosis data for diagnosis recommendation system?,https://www.reddit.com/r/MachineLearning/comments/6kbuim/medical_diagnosis_data_for_diagnosis/,sachanganesh,1498775028,[removed],0,1
1306,2017-6-30,2017,6,30,7,6kbvd8,Please let me know if I am on the right track of being an NLP Expert,https://www.reddit.com/r/MachineLearning/comments/6kbvd8/please_let_me_know_if_i_am_on_the_right_track_of/,czechrepublic,1498775276,[removed],0,1
1307,2017-6-30,2017,6,30,7,6kbz5s,Online Learning Question,https://www.reddit.com/r/MachineLearning/comments/6kbz5s/online_learning_question/,bhavik3jain,1498776363,[removed],0,1
1308,2017-6-30,2017,6,30,8,6kc24a,"Smarter A.I. Means Safer, Speedier Networks - TOPBOTS",https://www.reddit.com/r/MachineLearning/comments/6kc24a/smarter_ai_means_safer_speedier_networks_topbots/,conradcreates,1498777217,,0,1
1309,2017-6-30,2017,6,30,8,6kc4ml,Concrete Cutting Services,https://www.reddit.com/r/MachineLearning/comments/6kc4ml/concrete_cutting_services/,gwenyosef,1498777961,,0,1
1310,2017-6-30,2017,6,30,8,6kc6nn,Concrete Formwork Construction,https://www.reddit.com/r/MachineLearning/comments/6kc6nn/concrete_formwork_construction/,gwenyosef,1498778560,,0,1
1311,2017-6-30,2017,6,30,8,6kc7py,"[D] Where does the query, keys, and values come from in Attention is all you need paper",https://www.reddit.com/r/MachineLearning/comments/6kc7py/d_where_does_the_query_keys_and_values_come_from/,FutureIsMine,1498778898,"Reading through the paper, Im not exactly sure how the query, keys, and values are all derived within the paper. I do understand that for the encoder, and the first layer in the decoder, they come from the original source, but how exactly do they look like (I do know its a vector). As in, is a single value selected for each word in the sentence and used as a query? ",9,13
1312,2017-6-30,2017,6,30,8,6kc8jo,Coloured Concrete Sealer Solutions,https://www.reddit.com/r/MachineLearning/comments/6kc8jo/coloured_concrete_sealer_solutions/,gwenyosef,1498779160,,0,1
1313,2017-6-30,2017,6,30,8,6kcb1t,Concrete Driveway Solutions,https://www.reddit.com/r/MachineLearning/comments/6kcb1t/concrete_driveway_solutions/,gwenyosef,1498779936,,0,1
1314,2017-6-30,2017,6,30,8,6kcbj5,"[P] Basic neural network Java implementation, which can train itself, for beginners to try out and learn how they work.",https://www.reddit.com/r/MachineLearning/comments/6kcbj5/p_basic_neural_network_java_implementation_which/,sebig3000,1498780073,,6,3
1315,2017-6-30,2017,6,30,8,6kcd70,Concrete Installation,https://www.reddit.com/r/MachineLearning/comments/6kcd70/concrete_installation/,gwenyosef,1498780611,,0,1
1316,2017-6-30,2017,6,30,9,6kcha7,Deep learning on Apache Spark and Apache Hadoop with Deeplearning4j,https://www.reddit.com/r/MachineLearning/comments/6kcha7/deep_learning_on_apache_spark_and_apache_hadoop/,blueeyes44,1498781880,,0,1
1317,2017-6-30,2017,6,30,9,6kcjxc,learning and associating in stages,https://www.reddit.com/r/MachineLearning/comments/6kcjxc/learning_and_associating_in_stages/,[deleted],1498782705,[removed],0,1
1318,2017-6-30,2017,6,30,9,6kcolh,"[P] Using keras-vis to debug self-driving model, toy example.",https://www.reddit.com/r/MachineLearning/comments/6kcolh/p_using_kerasvis_to_debug_selfdriving_model_toy/,raghakot,1498784241,,0,8
1319,2017-6-30,2017,6,30,10,6kcp4i,Apple CoreML now supports Keras 2 models,https://www.reddit.com/r/MachineLearning/comments/6kcp4i/apple_coreml_now_supports_keras_2_models/,[deleted],1498784417,[deleted],0,1
1320,2017-6-30,2017,6,30,10,6kcrdv,Apple CoreML now supports Keras 2 models,https://www.reddit.com/r/MachineLearning/comments/6kcrdv/apple_coreml_now_supports_keras_2_models/,tits_for_tots,1498785140,[removed],0,1
1321,2017-6-30,2017,6,30,11,6kd3c6,Machine Learning for Food Recognition with Android Demo,https://www.reddit.com/r/MachineLearning/comments/6kd3c6/machine_learning_for_food_recognition_with/,[deleted],1498788982,[deleted],0,1
1322,2017-6-30,2017,6,30,11,6kd5fb,Machine Learning for Food Recognition with Android Demo,https://www.reddit.com/r/MachineLearning/comments/6kd5fb/machine_learning_for_food_recognition_with/,sixthmass,1498789660,,0,1
1323,2017-6-30,2017,6,30,15,6ke9lo,[P] (Distributed) Tensorflow Implementation of PathNet: Evolution Channels Gradient Descent in Super Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6ke9lo/p_distributed_tensorflow_implementation_of/,jaesik,1498804581,,8,18
1324,2017-6-30,2017,6,30,15,6kec1f,[D] YellowFin: An automatic tuner for momentum SGD,https://www.reddit.com/r/MachineLearning/comments/6kec1f/d_yellowfin_an_automatic_tuner_for_momentum_sgd/,_alphamaximus_,1498805671,,29,83
1325,2017-6-30,2017,6,30,16,6keegm,[R] [1706.05374] Expected Policy Gradients &lt;-- less variance than Stochastic Policy Gradients,https://www.reddit.com/r/MachineLearning/comments/6keegm/r_170605374_expected_policy_gradients_less/,evc123,1498806696,,2,2
1326,2017-6-30,2017,6,30,16,6kejzq,Microsoft squeezed AI onto a Raspberry Pi,https://www.reddit.com/r/MachineLearning/comments/6kejzq/microsoft_squeezed_ai_onto_a_raspberry_pi/,steccami,1498809298,,0,1
1327,2017-6-30,2017,6,30,17,6ken3x,*newbie* Need help in choosing algorithm/technique for probabilstic output.,https://www.reddit.com/r/MachineLearning/comments/6ken3x/newbie_need_help_in_choosing_algorithmtechnique/,hookairs,1498810843,[removed],0,1
1328,2017-6-30,2017,6,30,19,6kf5ca,Machine Learning Beginner Advice,https://www.reddit.com/r/MachineLearning/comments/6kf5ca/machine_learning_beginner_advice/,tjm_adv,1498819362,[removed],0,1
1329,2017-6-30,2017,6,30,20,6kfgaq,Industrial Automation Companies,https://www.reddit.com/r/MachineLearning/comments/6kfgaq/industrial_automation_companies/,TaiCatherine,1498823815,,0,1
1330,2017-6-30,2017,6,30,21,6kfj6u,Machine Learning and Prediction in Medicine  Beyond the Peak of Inflated Expectations [paywall],https://www.reddit.com/r/MachineLearning/comments/6kfj6u/machine_learning_and_prediction_in_medicine/,imitationcheese,1498824786,,1,1
1331,2017-6-30,2017,6,30,21,6kfmuz,You Should Know These 20 Technology Leaders Driving China&amp;#039;s A.I. Revolution - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6kfmuz/you_should_know_these_20_technology_leaders/,conradcreates,1498826045,,0,1
1332,2017-6-30,2017,6,30,21,6kfpi1,Any opensource code for DL based text-to-speech generation ?,https://www.reddit.com/r/MachineLearning/comments/6kfpi1/any_opensource_code_for_dl_based_texttospeech/,smith2017,1498826937,[removed],0,1
1333,2017-6-30,2017,6,30,22,6kfw1v,NIPS reviewer policy this year?,https://www.reddit.com/r/MachineLearning/comments/6kfw1v/nips_reviewer_policy_this_year/,NeuroBoss31,1498829059,"Does anyone know how the NIPS reviews will be working this year? I recall that last year they have 3 volunteer reviewers per paper (generally graduate students), and 3 expert reviewers who were research scientists or professors. How many reviewers will each paper have this year? I don't recall seeing that volunteering to review this year was an option unless I missed it.",6,4
1334,2017-6-30,2017,6,30,22,6kfwkq,[D] Creative Adversarial Networks - Simplified,https://www.reddit.com/r/MachineLearning/comments/6kfwkq/d_creative_adversarial_networks_simplified/,harvey_slash,1498829220,,3,74
1335,2017-6-30,2017,6,30,22,6kg2a1,[D] How to Visualize Your Recurrent Neural Network with Attention in Keras,https://www.reddit.com/r/MachineLearning/comments/6kg2a1/d_how_to_visualize_your_recurrent_neural_network/,bryanr,1498830967,,1,61
1336,2017-6-30,2017,6,30,23,6kg32v,Remote Jobs in Artificial Intelligence and Data Science,https://www.reddit.com/r/MachineLearning/comments/6kg32v/remote_jobs_in_artificial_intelligence_and_data/,mostafabenh,1498831212,,0,1
1337,2017-6-30,2017,6,30,23,6kg6jk,A.I. Entrepreneurs Say Faux A.I. Hype Hurts Sales &amp; Marketing Efforts - TOPBOTS,https://www.reddit.com/r/MachineLearning/comments/6kg6jk/ai_entrepreneurs_say_faux_ai_hype_hurts_sales/,conradcreates,1498832166,,0,1
1338,2017-6-30,2017,6,30,23,6kg8oq,GPU Bandwidth - Important?,https://www.reddit.com/r/MachineLearning/comments/6kg8oq/gpu_bandwidth_important/,jleach_,1498832742,[removed],0,1
1339,2017-6-30,2017,6,30,23,6kgdqz,Functional programming for deep learning,https://www.reddit.com/r/MachineLearning/comments/6kgdqz/functional_programming_for_deep_learning/,yogthos,1498834191,,0,1
