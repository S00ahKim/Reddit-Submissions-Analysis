,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-5-1,2018,5,1,9,8g45lt,ML PhD in Theory or Applications?,https://www.reddit.com/r/MachineLearning/comments/8g45lt/ml_phd_in_theory_or_applications/,Tiff9595,1525132858,[removed],0,1
1,2018-5-1,2018,5,1,9,8g47t7,Training set for automatic transcription of singing,https://www.reddit.com/r/MachineLearning/comments/8g47t7/training_set_for_automatic_transcription_of/,Botekin,1525133422,[removed],0,1
2,2018-5-1,2018,5,1,9,8g48do,[D] ML Phd in Theory or Applications?,https://www.reddit.com/r/MachineLearning/comments/8g48do/d_ml_phd_in_theory_or_applications/,Tiff9595,1525133545,"Hi!

So I am an undergrad senior who's doing a Master's program in ML at the same school as my undergrad starting from the fall. And I'm having a dilemma between choosing ML theory/applications labs. I'm trying to choose prof A who does Bayesian modeling/nonparametrics (this person is known in the department to be very math-heavy) , and prof B who does ML in Healthcare (seems like he is a more applied person than theory).

I'd like to apply for a phd after my Master's, and I'm well aware that it's easy to go from theory -&gt; application but not the other way around.

Could you guys share any thoughts on what would be the best for a Master's student who eventually wants to do PhD?

Also, when people say ML PhD's get highly paid these days, which ""point on the spectrum""(between theory and application) are they talking about?

Thanks in advance!",8,2
3,2018-5-1,2018,5,1,10,8g4mh2,[D] Information Retrieval with diversified results?,https://www.reddit.com/r/MachineLearning/comments/8g4mh2/d_information_retrieval_with_diversified_results/,deltasheep,1525137113,"For machine learning-based information retrieval, its common to make an embedding for queries and documents, and find the nearest-neighbors of a query in the document space (usually indexed in some sort of tree). Usually, the results are returned in order of distance to the query vector. However, in some IR tasks, its not desirable that all the results are goodall that matters is that one of them is good. For example, YouTube recommends me 10 videos in the sidebar, but only cares that I click one and stay on the site. This means you can pick diverse documents, because the negative correlation will lead to a higher probability that at least one succeeds (see Picking Winners with Integer Programming).  So we dont really care about the precision/recall of each item, but the precision/recall of each batch of items.

My question is: how do we create an IR model so that it is optimized for batches of recommendations instead of singular recommendations?",3,6
4,2018-5-1,2018,5,1,11,8g59nu,Tutorials for beginners,https://www.reddit.com/r/MachineLearning/comments/8g59nu/tutorials_for_beginners/,Kasujuja01,1525143136,[removed],0,1
5,2018-5-1,2018,5,1,12,8g5bvo,Quit passively dissing R,https://www.reddit.com/r/MachineLearning/comments/8g5bvo/quit_passively_dissing_r/,bbateman2011,1525143741,[removed],0,1
6,2018-5-1,2018,5,1,14,8g64t2,[N] Supporting open access for ML research,https://www.reddit.com/r/MachineLearning/comments/8g64t2/n_supporting_open_access_for_ml_research/,georgeo,1525152846,,2,22
7,2018-5-1,2018,5,1,15,8g6caj,Simple Text Classification using Keras Deep Learning Python Library,https://www.reddit.com/r/MachineLearning/comments/8g6caj/simple_text_classification_using_keras_deep/,Shilpa_Opencodez,1525155534,,0,1
8,2018-5-1,2018,5,1,16,8g6mi3,[R] Using deep Q-learning to understand the tax evasion behavior of risk-averse firms,https://www.reddit.com/r/MachineLearning/comments/8g6mi3/r_using_deep_qlearning_to_understand_the_tax/,dcvarsakelis,1525159422,,3,43
9,2018-5-1,2018,5,1,16,8g6qwe,Visualize weights from logistic regression?,https://www.reddit.com/r/MachineLearning/comments/8g6qwe/visualize_weights_from_logistic_regression/,o-rka,1525161236,[removed],0,1
10,2018-5-1,2018,5,1,17,8g6ynp,[P] The unreasonable usefulness of deep learning in building and cleaning medical image datasets,https://www.reddit.com/r/MachineLearning/comments/8g6ynp/p_the_unreasonable_usefulness_of_deep_learning_in/,drlukeor,1525164357,,18,222
11,2018-5-1,2018,5,1,18,8g757n,[D] uTensor - Why Arm is investing in ML on the edge,https://www.reddit.com/r/MachineLearning/comments/8g757n/d_utensor_why_arm_is_investing_in_ml_on_the_edge/,drbernhard,1525166739,,0,3
12,2018-5-1,2018,5,1,18,8g75dr,What should I look out for in a computer for data science / machine learning?,https://www.reddit.com/r/MachineLearning/comments/8g75dr/what_should_i_look_out_for_in_a_computer_for_data/,xTurtleSwaggerx,1525166797,[removed],0,1
13,2018-5-1,2018,5,1,18,8g76l0,Quantum Computing Explained Simply  How Quantum Computers Work?,https://www.reddit.com/r/MachineLearning/comments/8g76l0/quantum_computing_explained_simply_how_quantum/,tecHindustan,1525167228,,0,1
14,2018-5-1,2018,5,1,18,8g7ats,[D] How to move forward in your career in Data Science/ ML ?,https://www.reddit.com/r/MachineLearning/comments/8g7ats/d_how_to_move_forward_in_your_career_in_data/,__bee,1525168797,"I am a software engineer, with 5 years experience. I am already getting involved, and already shipped Data Science projects. I have a bachelor degree. I am struggling to move forward in my career and find better company to work at. I realized in order to move up/get more responsibility I needed other skills. I am thinking of two options: 

\(1\) Investing on a specialized Master in Data Science/AI. 

\(2\) Invest on online courses. In addition to presence online through blogs, github projects, 

I am an engineer, I published some papers while being in school. But I didn't see people care much about research papers. 


Those who did it. Those who came back to school after working in industry, do you think that it will go by fast and worth the time and money ?

Those who invest more time on online courses and on being present online, will it provide a deeper level of understanding in addition to boosting someone's resume.

P.S: I am not based in US. So master programs would be considered in UK. ",4,9
15,2018-5-1,2018,5,1,20,8g7lsh,[N] Links to the May issue of COMPUTER VISION NEWS,https://www.reddit.com/r/MachineLearning/comments/8g7lsh/n_links_to_the_may_issue_of_computer_vision_news/,Gletta,1525172683,"Here is the May 2018 issue of **Computer Vision News**, published by RSIP Vision: **52 pages** about Computer Vision, Biomedical Imaging, **Machine Learning** and Artificial Intelligence. Technical reviews of new papers and technologies \(with codes!\), including YOLO version 3! Free subscription at page 52.

[HTML5 version \(recommended\)](http://www.rsipvision.com/ComputerVisionNews-2018May/)

[PDF version](http://www.rsipvision.com/computer-vision-news-2018-may-pdf/)

Enjoy!",3,2
16,2018-5-1,2018,5,1,21,8g807a,[D] Loss Function for Landmark Detection,https://www.reddit.com/r/MachineLearning/comments/8g807a/d_loss_function_for_landmark_detection/,DonMahallem,1525177098,"I am currently (still) tinkering around with landmark detection.
I want to hear your opinion about the loss/output to be used as I currently hit a wall in further optimizing my results.
The inputs after augmentation do look like [these](https://imgur.com/a/LyklpWw).(Current Dataset contains ~350 annotated sudokus from various sources)

I should predict the 16 corner coordinates of the larger sudoku squares. The output is currently encoded as a tensor with 32 values encoded [x1,y1,x2,y2,....] with values scaled to [0,1](so left top corner is (0,0) and right bottom is (1,1))

My current loss function does look like:

    def mean_euclid_loss(y_true, y_pred):
        diff = K.square(y_true - y_pred)
        x_vals = diff[:, 0::2]
        y_vals = diff[:, 1::2]
    
        return K.mean(K.sqrt(x_vals + y_vals), axis=-1)        

Currently it reaches a loss of 0.04 on the validation dataset. This is with MobileNetV2 as a network.
My previous attempt was a VGG-Net with splitted output (4*8 values) which achieved a loss of avg ~0.01 BUT kind of ""overfitted"" and was too large to use it properly on a phone.

My question is:
Should I be using another loss function? mse and mae didnt seem to be improving anything in my tests. And if you do have any other suggestion I am happy over any one of them.",0,3
17,2018-5-1,2018,5,1,21,8g85d0,Scientists teach computers how to analyze brain cells,https://www.reddit.com/r/MachineLearning/comments/8g85d0/scientists_teach_computers_how_to_analyze_brain/,grez911,1525178542,,0,1
18,2018-5-1,2018,5,1,21,8g88qk,[N] Scientists teach computers how to analyze brain cells,https://www.reddit.com/r/MachineLearning/comments/8g88qk/n_scientists_teach_computers_how_to_analyze_brain/,grez911,1525179440,,1,3
19,2018-5-1,2018,5,1,23,8g8vt0,Machine learning model into elasticsearch,https://www.reddit.com/r/MachineLearning/comments/8g8vt0/machine_learning_model_into_elasticsearch/,satzioflax1,1525185146,[removed],0,1
20,2018-5-1,2018,5,1,23,8g8zw1,[D] Regression of non-linear function.,https://www.reddit.com/r/MachineLearning/comments/8g8zw1/d_regression_of_nonlinear_function/,Hey_Rhys,1525186107,"I'm doing a Master's Project in Physics and I have a set of theoretical equations of the form:

u = f(h,c,B)

B = g(h,c,u)

where we also have the relationship:
h+1 = exp(-u + h - c + B)

with the two functionals for u and B we can rearrange to get

B = g'(h,c,B) = g'(h,c,g'(h,c,g'(h,c,g'(h,c,...)))) = g''(h,c)

(Where we've implicitly assumed that the recursion should have a limiting value)

When I train a simple MLP to learn B = g(h,c,u) I get a coefficient of determination R^2 = 0.93-0.97 but when I train to learn B = g''(h,c) I get much worse results with R^2 = 0.53-0.60. To me this suggests that the model needs to take the recursive expansion arguments in a more structured manner. 

Does anyone have any ideas about network architectures which might be able to deal with this sort of feedback looping?

",6,2
21,2018-5-2,2018,5,2,0,8g95vg,Announcing Open Images V4 and the ECCV 2018 Open Images Challenge,https://www.reddit.com/r/MachineLearning/comments/8g95vg/announcing_open_images_v4_and_the_eccv_2018_open/,balazshoranyi,1525187430,,0,1
22,2018-5-2,2018,5,2,1,8g9k0s,[R] Photographic Image Generation with Semi-parametric Image Synthesis,https://www.reddit.com/r/MachineLearning/comments/8g9k0s/r_photographic_image_generation_with/,downtownslim,1525190513,,28,203
23,2018-5-2,2018,5,2,1,8g9ua9,Why Explainable AI Doesn't Cut It,https://www.reddit.com/r/MachineLearning/comments/8g9ua9/why_explainable_ai_doesnt_cut_it/,jtsymonds,1525192724,,0,1
24,2018-5-2,2018,5,2,1,8g9y84,Finding Arc In image using python opencv,https://www.reddit.com/r/MachineLearning/comments/8g9y84/finding_arc_in_image_using_python_opencv/,yamlajatt007,1525193564,[removed],0,1
25,2018-5-2,2018,5,2,2,8ga5w3,[Project] Train a Mask R-CNN model on your own data,https://www.reddit.com/r/MachineLearning/comments/8ga5w3/project_train_a_mask_rcnn_model_on_your_own_data/,waspinator,1525195206,,0,12
26,2018-5-2,2018,5,2,3,8gahzt,[D] What Is In Your Demand Forecasting Toolkit?,https://www.reddit.com/r/MachineLearning/comments/8gahzt/d_what_is_in_your_demand_forecasting_toolkit/,dbirdflyshi,1525197808,"Calling demand forecasters or machine learning professionals, what tools do you find in your toolkit to be the most effective in delivering an accurate/solid demand forecast? ",6,14
27,2018-5-2,2018,5,2,3,8gakx5,How should we think about AI Bias?,https://www.reddit.com/r/MachineLearning/comments/8gakx5/how_should_we_think_about_ai_bias/,weiqiplayer,1525198451,,0,1
28,2018-5-2,2018,5,2,3,8gaogp,[R] Text to Image Synthesis Using Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/8gaogp/r_text_to_image_synthesis_using_generative/,ABLC,1525199203,,14,26
29,2018-5-2,2018,5,2,3,8gau2k,"Importing a trained model (Random forest) in sklearn to android, any tips?",https://www.reddit.com/r/MachineLearning/comments/8gau2k/importing_a_trained_model_random_forest_in/,DisWastingMyTime,1525200419,"Like the title says, I'm interesting in using a model I've trained in an app for android, any pointers would be appreciated.
",0,1
30,2018-5-2,2018,5,2,3,8gavrj,Good courses/accreditation for getting a job?,https://www.reddit.com/r/MachineLearning/comments/8gavrj/good_coursesaccreditation_for_getting_a_job/,misterbailey69,1525200775,,0,1
31,2018-5-2,2018,5,2,4,8gbdju,[D] Quasi-RNN NMT Decoder evaluation time,https://www.reddit.com/r/MachineLearning/comments/8gbdju/d_quasirnn_nmt_decoder_evaluation_time/,ShivamDuggal4,1525204469,"I was reading Quasi RNN (https://arxiv.org/pdf/1611.01576.pdf) and also Convolutional Sequence to sequence learning for NMT. Convolution operation helps in leaning the context much faster than the LSTMs. The encoder can be parallelized using the Convolution, however, I am confused with parallelization of the decoder. During training, when we know the output translated sentence, we can provide the decoder the output sentence as the input by shifting it one time to the right. However, during testing, we have to run the decoder n times to extract n words of the output sentence, using the predicted word in the current time step as the input to the decoder in the next timestep. 
Using a decoder with LSTM / RNN layers would have increased the per layer execution time complexity, where a convolutional decoder can execute each layer parallel, but LSTM decoder would have still run 1 time compared to n times of convolutional decoder.

How can we then compare the time complexity while testing of an LSTM decoder and a convolutional decoder?",0,0
32,2018-5-2,2018,5,2,4,8gbf0f,Question about sequence classification,https://www.reddit.com/r/MachineLearning/comments/8gbf0f/question_about_sequence_classification/,m_alzantot,1525204791,[removed],0,1
33,2018-5-2,2018,5,2,5,8gbnze,[D] Discussion about doing sequence classification,https://www.reddit.com/r/MachineLearning/comments/8gbnze/d_discussion_about_doing_sequence_classification/,m_alzantot,1525206781,"Hello, 
I am building a sequence classification model (many-to-one) that accepts an input multi-dimensional time series and predicts a classification label for the whole sequence..

I am building my model using Gated Recurrent Units (GRU) recurrent neural network model. At the top of the GRU, I have a fully connected layer that produces the logits of softmax classification layer. The input to the fully connected layer was selected to be either:

1) Case 1: hidden value produced by last timestep. According to my understanding, the ""hidden"" value produced by the last time-step of the GRU units can be considered as ""context"" feature vector that summaries the whole sequence, and hence my initial model design employed this ""context"" (hidden value produced by last timestep) as input the fully connected layer.. However, the accuracy wasn't high at all.

2) Case 2: The mean of GRU output across all timesteps. When I tried using ""average of GRU output value across all time steps"", and the model started producing significantly better results.

Any thoughts about which approach would be considered better , and why this happens ?",9,0
34,2018-5-2,2018,5,2,5,8gboyu,[D] Export PyTorch model to Caffe2 for training,https://www.reddit.com/r/MachineLearning/comments/8gboyu/d_export_pytorch_model_to_caffe2_for_training/,Deepblue129,1525207001,"Hi Guys!

Been dealing with a couple large models lately that take days to train. PyTorch includes a onnx toolkit that enables one to export PyTorch models to Caffe2. The examples focus on pre-trained models. Does it make sense to export untrained models from PyTorch to Caffe2? Would I expect a performance increase?

Thanks!",3,6
35,2018-5-2,2018,5,2,6,8gbyg2,Recognizing design trees of 3D objects in parametric solid modeling from triangulated mesh,https://www.reddit.com/r/MachineLearning/comments/8gbyg2/recognizing_design_trees_of_3d_objects_in/,aaditya314159,1525209086,[removed],0,1
36,2018-5-2,2018,5,2,6,8gc2zu,Trying to map positions of pedestrians/cars in a security camera footage onto Google Maps,https://www.reddit.com/r/MachineLearning/comments/8gc2zu/trying_to_map_positions_of_pedestrianscars_in_a/,hk2222444,1525210112,[removed],0,1
37,2018-5-2,2018,5,2,6,8gc5nl,[R] Learning from Source Code - Microsoft Research,https://www.reddit.com/r/MachineLearning/comments/8gc5nl/r_learning_from_source_code_microsoft_research/,mttd,1525210733,,3,67
38,2018-5-2,2018,5,2,7,8gcepr,"Nukek Nupek, Inc. is a real-time video analytics and solutions company",https://www.reddit.com/r/MachineLearning/comments/8gcepr/nukek_nupek_inc_is_a_realtime_video_analytics_and/,blooky9263,1525212844,[removed],0,1
39,2018-5-2,2018,5,2,7,8gcl7v,WGAN is way too slow!,https://www.reddit.com/r/MachineLearning/comments/8gcl7v/wgan_is_way_too_slow/,inkplay_,1525214476,[removed],0,1
40,2018-5-2,2018,5,2,9,8gdfgz,Avoid Time Loops With Cross-Validation  Apteo Tech  Medium,https://www.reddit.com/r/MachineLearning/comments/8gdfgz/avoid_time_loops_with_crossvalidation_apteo_tech/,c0cky_,1525222312,,0,1
41,2018-5-2,2018,5,2,9,8gdfnk,Time Series Cross Validation,https://www.reddit.com/r/MachineLearning/comments/8gdfnk/time_series_cross_validation/,c0cky_,1525222363,,0,0
42,2018-5-2,2018,5,2,11,8ge416,Cracking captchas with CNN?,https://www.reddit.com/r/MachineLearning/comments/8ge416/cracking_captchas_with_cnn/,GimmeThoseCaps,1525228682,[removed],0,1
43,2018-5-2,2018,5,2,11,8ge6co,Suggestions for making my Undergrad thesis a bit more interesting? (ML+Bioinformatics),https://www.reddit.com/r/MachineLearning/comments/8ge6co/suggestions_for_making_my_undergrad_thesis_a_bit/,pretysmitty,1525229350,[removed],0,1
44,2018-5-2,2018,5,2,12,8ge9pg,[D] TensorFlow.js intro with demos (5 min),https://www.reddit.com/r/MachineLearning/comments/8ge9pg/d_tensorflowjs_intro_with_demos_5_min/,mfrw1,1525230289,,0,37
45,2018-5-2,2018,5,2,12,8geiqi,[D] GAN discriminator and generator loss stuck after short amount of iterations,https://www.reddit.com/r/MachineLearning/comments/8geiqi/d_gan_discriminator_and_generator_loss_stuck/,FutureIsMine,1525232994,,0,0
46,2018-5-2,2018,5,2,13,8gelsu,Image Inpainting for Irregular Holes Using Partial Convolutions,https://www.reddit.com/r/MachineLearning/comments/8gelsu/image_inpainting_for_irregular_holes_using/,bandalorian,1525233938,,1,1
47,2018-5-2,2018,5,2,14,8gewf7,Semi-supervised classification,https://www.reddit.com/r/MachineLearning/comments/8gewf7/semisupervised_classification/,sim1bet,1525237390,[removed],0,1
48,2018-5-2,2018,5,2,14,8gexws,Adversarially Robust Generalization Requires More Data,https://www.reddit.com/r/MachineLearning/comments/8gexws/adversarially_robust_generalization_requires_more/,convolutional_potato,1525237873,,0,1
49,2018-5-2,2018,5,2,15,8gfdq0,QT4 15 automatic concrete hollow block making machine with automatic pal...,https://www.reddit.com/r/MachineLearning/comments/8gfdq0/qt4_15_automatic_concrete_hollow_block_making/,dymachine01,1525243338,,1,1
50,2018-5-2,2018,5,2,16,8gfmrm,[P] Comparing Sentence Similarity Methods,https://www.reddit.com/r/MachineLearning/comments/8gfmrm/p_comparing_sentence_similarity_methods/,yvespeirsman,1525246593,,22,123
51,2018-5-2,2018,5,2,17,8gfxzz,Peanut|Soybean Oil Press Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8gfxzz/peanutsoybean_oil_press_machine_for_sale/,Machineprices,1525251294,,1,1
52,2018-5-2,2018,5,2,18,8gfzvv,Peanut Almond Nut Particle Cutting Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8gfzvv/peanut_almond_nut_particle_cutting_machine_for/,Machineprices,1525252033,,1,1
53,2018-5-2,2018,5,2,18,8gg3tq,Multi-purpose Peanut Butter Grinder|Almond Butter Grinder|Nut Butter Making Machine,https://www.reddit.com/r/MachineLearning/comments/8gg3tq/multipurpose_peanut_butter_grinderalmond_butter/,Machineprices,1525253481,,1,1
54,2018-5-2,2018,5,2,18,8gg62c,Pistachio Peanut Strip Cutting Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8gg62c/pistachio_peanut_strip_cutting_machine_for_sale/,Machineprices,1525254281,,1,1
55,2018-5-2,2018,5,2,18,8gg81u,[D] Why We Need to Stop Redefining AI,https://www.reddit.com/r/MachineLearning/comments/8gg81u/d_why_we_need_to_stop_redefining_ai/,Flag_Red,1525255026,,30,0
56,2018-5-2,2018,5,2,19,8ggf0d,Yay!!! Engati keeps raking in the accolades and mentions. Thank you Ray Parker from Techsite who has listed us as one of the 5 Top Chatbot Development Companies You Can Hire. If you havent built bots; its time to start building now for FREE in less than 10 mins !!! Read all about it here...,https://www.reddit.com/r/MachineLearning/comments/8ggf0d/yay_engati_keeps_raking_in_the_accolades_and/,parousiakhan,1525257438,,0,1
57,2018-5-2,2018,5,2,19,8ggh02,Federated Learning Bringing Machine Learning to the edge with Kotlin and Android,https://www.reddit.com/r/MachineLearning/comments/8ggh02/federated_learning_bringing_machine_learning_to/,mccorby72,1525258127,,0,1
58,2018-5-2,2018,5,2,19,8gghhx,Peer-to-Peer Federated Learning using PyTorch and IPFS,https://www.reddit.com/r/MachineLearning/comments/8gghhx/peertopeer_federated_learning_using_pytorch_and/,iamtrask,1525258323,,1,1
59,2018-5-2,2018,5,2,19,8gghn0,How To Use An Electric Crepe Maker?,https://www.reddit.com/r/MachineLearning/comments/8gghn0/how_to_use_an_electric_crepe_maker/,lgsherry,1525258373,,1,1
60,2018-5-2,2018,5,2,20,8ggmx5,Deep Learning in Spiking Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8ggmx5/deep_learning_in_spiking_neural_networks/,Modatu,1525260081,,0,1
61,2018-5-2,2018,5,2,20,8ggqal,5 Current Technology Trends in 2018 for Great Careers in Technology: #3 Machine Learning Engineer,https://www.reddit.com/r/MachineLearning/comments/8ggqal/5_current_technology_trends_in_2018_for_great/,tecHindustan,1525261150,,0,1
62,2018-5-2,2018,5,2,21,8ggv11,Is a PhD in ML a good choice?,https://www.reddit.com/r/MachineLearning/comments/8ggv11/is_a_phd_in_ml_a_good_choice/,steezyone,1525262576,[removed],0,1
63,2018-5-2,2018,5,2,22,8ghf5y,How Non-Tech Businesses Are Using Artificial Intelligence At Scale,https://www.reddit.com/r/MachineLearning/comments/8ghf5y/how_nontech_businesses_are_using_artificial/,jonfla,1525267936,,0,1
64,2018-5-2,2018,5,2,22,8ghg5o,Identifying Natural Language with 99% accuracy using Machine Learning (Python and Scikit-Learn),https://www.reddit.com/r/MachineLearning/comments/8ghg5o/identifying_natural_language_with_99_accuracy/,scoobyboo,1525268181,,0,1
65,2018-5-2,2018,5,2,22,8ghii3,Tools to crowdsource data,https://www.reddit.com/r/MachineLearning/comments/8ghii3/tools_to_crowdsource_data/,NeurobiologicalHug,1525268762,"Hi, 
I'm starting a project for recognising different currency notes. I'm looking to crowdsource this data from different sources and I want to use a simple tool like Google Drive, etc. for people to submit images. Can someone point me to the right kind of tool for such a task?

Thanks!",0,1
66,2018-5-2,2018,5,2,22,8ghl3c,[P] Identifying Natural Language with 99% accuracy using Machine Learning (Python and Scikit-Learn),https://www.reddit.com/r/MachineLearning/comments/8ghl3c/p_identifying_natural_language_with_99_accuracy/,scoobyboo,1525269395,,7,17
67,2018-5-2,2018,5,2,23,8ghpoh,"Bagger 288, The biggest land vehicle ever - 33 year timelapse impact seen from space",https://www.reddit.com/r/MachineLearning/comments/8ghpoh/bagger_288_the_biggest_land_vehicle_ever_33_year/,MoreSecond,1525270456,,1,1
68,2018-5-2,2018,5,2,23,8gi1jz,Lobe  An easy-to-use visual tool for building deep learning models.,https://www.reddit.com/r/MachineLearning/comments/8gi1jz/lobe_an_easytouse_visual_tool_for_building_deep/,wkcntpamqnficksjt,1525273149,,1,2
69,2018-5-3,2018,5,3,0,8giao2,OCR model,https://www.reddit.com/r/MachineLearning/comments/8giao2/ocr_model/,hristo_rv,1525275124,[removed],0,1
70,2018-5-3,2018,5,3,0,8gid8t,"Researchers from multiple organizations including Baidu, UC Berkeley, Google, Harvard, and Stanford collaborate to develop a new machine learning benchmark.",https://www.reddit.com/r/MachineLearning/comments/8gid8t/researchers_from_multiple_organizations_including/,gdiamos,1525275663,,0,1
71,2018-5-3,2018,5,3,0,8gihbx,"Simple Questions Thread May 02, 2018",https://www.reddit.com/r/MachineLearning/comments/8gihbx/simple_questions_thread_may_02_2018/,AutoModerator,1525276555,[removed],0,1
72,2018-5-3,2018,5,3,0,8gii7v,Is manually tagging content an ideal start for eventual machine learning?,https://www.reddit.com/r/MachineLearning/comments/8gii7v/is_manually_tagging_content_an_ideal_start_for/,TKB21,1525276746,[removed],0,1
73,2018-5-3,2018,5,3,1,8gijev,"[P] torchplus -- implements the + operator on pytorch layers, returning nn.Sequential",https://www.reddit.com/r/MachineLearning/comments/8gijev/p_torchplus_implements_the_operator_on_pytorch/,knighton_,1525276997,,18,8
74,2018-5-3,2018,5,3,1,8gikj2,[R] The theory and application of computational intelligence - Keynote at Collision 2018,https://www.reddit.com/r/MachineLearning/comments/8gikj2/r_the_theory_and_application_of_computational/,MountainHawk81,1525277253,,0,2
75,2018-5-3,2018,5,3,1,8gip19,"Building Data Science Capabilities That Scale - Webinar with DataScience.com founder, Ian Swanson",https://www.reddit.com/r/MachineLearning/comments/8gip19/building_data_science_capabilities_that_scale/,TheDataIncubator,1525278197,,0,2
76,2018-5-3,2018,5,3,1,8gixtk,My first take on reinforcement learning with training on CPU,https://www.reddit.com/r/MachineLearning/comments/8gixtk/my_first_take_on_reinforcement_learning_with/,coolusername2020,1525280058,,0,1
77,2018-5-3,2018,5,3,2,8gj9ns,[D] The road to 1.0: production ready PyTorch,https://www.reddit.com/r/MachineLearning/comments/8gj9ns/d_the_road_to_10_production_ready_pytorch/,hydrodynamical_flow,1525282508,,41,215
78,2018-5-3,2018,5,3,3,8gjojs,AI at F8 2018: Open frameworks and responsible development - PyTorch,https://www.reddit.com/r/MachineLearning/comments/8gjojs/ai_at_f8_2018_open_frameworks_and_responsible/,Phnyx,1525285735,,0,1
79,2018-5-3,2018,5,3,3,8gjvha,Advancing state-of-the-art image recognition with deep learning on hashtags,https://www.reddit.com/r/MachineLearning/comments/8gjvha/advancing_stateoftheart_image_recognition_with/,luiscosio,1525287211,,1,1
80,2018-5-3,2018,5,3,3,8gjvtx,[R] New SOTA on Imagenet (gain&gt;2%) via Weakly Supervised Learning,https://www.reddit.com/r/MachineLearning/comments/8gjvtx/r_new_sota_on_imagenet_gain2_via_weakly/,Jean-Porte,1525287284,,33,48
81,2018-5-3,2018,5,3,3,8gjx86,[R] FAIR improves state-of-the-art on ImageNet by 2% (absolute) with new 1 billion image hashtag dataset,https://www.reddit.com/r/MachineLearning/comments/8gjx86/r_fair_improves_stateoftheart_on_imagenet_by_2/,modeless,1525287591,,0,1
82,2018-5-3,2018,5,3,4,8gjxug,Deep Learning - Regularization term stops the optimization?,https://www.reddit.com/r/MachineLearning/comments/8gjxug/deep_learning_regularization_term_stops_the/,fiddlewin,1525287718,[removed],0,1
83,2018-5-3,2018,5,3,4,8gk1rt,[P] Joint 3D Face Reconstruction,https://www.reddit.com/r/MachineLearning/comments/8gk1rt/p_joint_3d_face_reconstruction/,luiscosio,1525288575,,1,16
84,2018-5-3,2018,5,3,4,8gk506,[N] Focus on AI at Facebook F8; PyTorch 1.0 Released,https://www.reddit.com/r/MachineLearning/comments/8gk506/n_focus_on_ai_at_facebook_f8_pytorch_10_released/,gwen0927,1525289267,,0,1
85,2018-5-3,2018,5,3,4,8gk8kx,VectorDefense: Vectorization as a Defense to Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/8gk8kx/vectordefense_vectorization_as_a_defense_to/,safetynet1,1525290059,,0,2
86,2018-5-3,2018,5,3,4,8gk9w3,How does one implement adversarial examples in pytorch?,https://www.reddit.com/r/MachineLearning/comments/8gk9w3/how_does_one_implement_adversarial_examples_in/,real_charlie_parker,1525290330,[removed],0,1
87,2018-5-3,2018,5,3,5,8gkkxt,[D] Locomotion: cancer cell trying to escape box [UCSF] - is there any work on training 'cells'?,https://www.reddit.com/r/MachineLearning/comments/8gkkxt/d_locomotion_cancer_cell_trying_to_escape_box/,phobrain,1525292691,,1,1
88,2018-5-3,2018,5,3,5,8gklog,"Facebook Open Sources ELF OpenGo, 14-0 against top Go players",https://www.reddit.com/r/MachineLearning/comments/8gklog/facebook_open_sources_elf_opengo_140_against_top/,Mister_Abc,1525292860,,0,2
89,2018-5-3,2018,5,3,5,8gktvm,[R] The loss landscape of overparameterized neural networks,https://www.reddit.com/r/MachineLearning/comments/8gktvm/r_the_loss_landscape_of_overparameterized_neural/,StrawberryNumberNine,1525294682,,6,9
90,2018-5-3,2018,5,3,6,8gkxr5,Pytorch reimplementation of Detectron,https://www.reddit.com/r/MachineLearning/comments/8gkxr5/pytorch_reimplementation_of_detectron/,mkocabas,1525295468,,0,1
91,2018-5-3,2018,5,3,6,8gl47u,[P] Facebook AI | Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8gl47u/p_facebook_ai_artificial_intelligence/,sksq9,1525296915,,5,24
92,2018-5-3,2018,5,3,6,8gl56m,"Live webcast tonight at 7pm ET on AI, machine learning, and quantum physics",https://www.reddit.com/r/MachineLearning/comments/8gl56m/live_webcast_tonight_at_7pm_et_on_ai_machine/,collywog,1525297154,,0,1
93,2018-5-3,2018,5,3,7,8glkav,[1805.00309] An Universal Image Attractiveness Ranking Framework,https://www.reddit.com/r/MachineLearning/comments/8glkav/180500309_an_universal_image_attractiveness/,improbabble,1525300763,,0,1
94,2018-5-3,2018,5,3,7,8gll9t,"[N] ""Facebook Open Sources ELF OpenGo"": AlphaZero reimplementation - 14-0 vs 4 top-30 Korean pros, 200-0 vs LeelaZero; 3 weeks x 2k GPUs; pre-trained models &amp; Python source",https://www.reddit.com/r/MachineLearning/comments/8gll9t/n_facebook_open_sources_elf_opengo_alphazero/,gwern,1525300995,,42,328
95,2018-5-3,2018,5,3,9,8gm97y,Tutorials and reading on Parameter tuning for deep learning,https://www.reddit.com/r/MachineLearning/comments/8gm97y/tutorials_and_reading_on_parameter_tuning_for/,iamseiko,1525307034,[removed],0,1
96,2018-5-3,2018,5,3,9,8gmfzv,[D] Facebook Open Sources ELF OpenGo  Facebook Research,https://www.reddit.com/r/MachineLearning/comments/8gmfzv/d_facebook_open_sources_elf_opengo_facebook/,sksq9,1525308798,,1,0
97,2018-5-3,2018,5,3,9,8gmgpk,[D] Tutorials and readings for tuning a aDeep Learning model,https://www.reddit.com/r/MachineLearning/comments/8gmgpk/d_tutorials_and_readings_for_tuning_a_adeep/,iamseiko,1525308980,"My biggest shortcoming for deep learning is parameter tuning. If I get 85% on test accuracy, I want to tune the model to improve that accuracy. When I look online for parameter tuning, I find a lot of articles on Transfer Learning, which I know is a great way to decrease loss, but now what I am looking for.

What is the right process? When do I add more layers or remove layers, or add batch normalization? Does a different activation function or a different cost optimizer make sense in certain situations? When do I add data augmentation?

I want to find some reading on the process for improving the accuracy for a neural network, without just resorting to a pre-trained model.",2,5
98,2018-5-3,2018,5,3,10,8gmij5,[D] clustering and network analysis for quant finance,https://www.reddit.com/r/MachineLearning/comments/8gmij5/d_clustering_and_network_analysis_for_quant/,gau_mar,1525309451,,2,6
99,2018-5-3,2018,5,3,11,8gmx7m,"Stupid question about ML, how to remove the noise in linear regression?",https://www.reddit.com/r/MachineLearning/comments/8gmx7m/stupid_question_about_ml_how_to_remove_the_noise/,omg9394,1525313269,"If I have data something like \[ \[1, 1, 2, 13, 1,1\], \[2, 14, 3, 9, 12, 1\] \] and I want to predict the group 1 from group 2. Obviously the ""13"" in group 1 is an error or noise, and the group 1 should be independent to group 2 and always return value around 1. How can I represent it in ML algorithm such as using linear regression with some kind of regulation? I would so appreciate if any one can give me a brief idea of how to do so.",0,1
100,2018-5-3,2018,5,3,11,8gmzh2,Reinforcement Learning FAQ - University of Alberta,https://www.reddit.com/r/MachineLearning/comments/8gmzh2/reinforcement_learning_faq_university_of_alberta/,ADGEfficiency,1525313868,,0,1
101,2018-5-3,2018,5,3,11,8gn0v5,[P] Glow: Compiler for Neural Network hardware accelerators,https://www.reddit.com/r/MachineLearning/comments/8gn0v5/p_glow_compiler_for_neural_network_hardware/,mttd,1525314246,,4,57
102,2018-5-3,2018,5,3,11,8gn0wv,GloVe as a TensorFlow Embedding layer,https://www.reddit.com/r/MachineLearning/comments/8gn0wv/glove_as_a_tensorflow_embedding_layer/,GChe,1525314259,,0,1
103,2018-5-3,2018,5,3,12,8gnhnu,Factory Price Sesame Tahini Production Line For Sale,https://www.reddit.com/r/MachineLearning/comments/8gnhnu/factory_price_sesame_tahini_production_line_for/,Machineprices,1525319074,,1,1
104,2018-5-3,2018,5,3,15,8gobfa,Multi-purpose Peanut Nut Powder Milling Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8gobfa/multipurpose_peanut_nut_powder_milling_machine/,Machineprices,1525328766,,1,1
105,2018-5-3,2018,5,3,15,8goblz,Fully Automatic Cellophane Wrapping Machine Manufacturers +8618539931566,https://www.reddit.com/r/MachineLearning/comments/8goblz/fully_automatic_cellophane_wrapping_machine/,lgsherry,1525328822,,1,1
106,2018-5-3,2018,5,3,15,8goci0,How to Implement Linear Regression using TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/8goci0/how_to_implement_linear_regression_using/,ddb1995,1525329145,[removed],0,1
107,2018-5-3,2018,5,3,15,8goddc,Peanut|Almond|Nut Slice Cutting Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8goddc/peanutalmondnut_slice_cutting_machine_for_sale/,Machineprices,1525329490,,1,1
108,2018-5-3,2018,5,3,16,8gojf4,retrieving important document,https://www.reddit.com/r/MachineLearning/comments/8gojf4/retrieving_important_document/,keyNail,1525331674,[removed],0,1
109,2018-5-3,2018,5,3,16,8gokj5,Lobe | Deep Learning Made Simple,https://www.reddit.com/r/MachineLearning/comments/8gokj5/lobe_deep_learning_made_simple/,alexduckmanton,1525332113,,0,1
110,2018-5-3,2018,5,3,16,8goko8,[N] New ML/AI benchmark from Stanford released (MLPerf),https://www.reddit.com/r/MachineLearning/comments/8goko8/n_new_mlai_benchmark_from_stanford_released_mlperf/,gfursin,1525332164,,9,16
111,2018-5-3,2018,5,3,16,8gomc6,Hello World  Raven Protocol  RavenProtocol  Medium,https://www.reddit.com/r/MachineLearning/comments/8gomc6/hello_world_raven_protocol_ravenprotocol_medium/,kailashahirwar12,1525332822,,0,1
112,2018-5-3,2018,5,3,17,8goqzh,Issues understanding the derivation of a constant in an image colorization paper.,https://www.reddit.com/r/MachineLearning/comments/8goqzh/issues_understanding_the_derivation_of_a_constant/,preslavrachev,1525334713,[removed],0,1
113,2018-5-3,2018,5,3,17,8goriy,Reinforcement Learning with Q tables,https://www.reddit.com/r/MachineLearning/comments/8goriy/reinforcement_learning_with_q_tables/,kiarash-irandoust,1525334925,,0,1
114,2018-5-3,2018,5,3,17,8got62,"New 'truly' decentralised, distributed AI protocol. Raven Protocol",https://www.reddit.com/r/MachineLearning/comments/8got62/new_truly_decentralised_distributed_ai_protocol/,ravensdraven,1525335601,[removed],0,1
115,2018-5-3,2018,5,3,17,8gowcl,"How should a college dropout find a job in Data Science, ML?",https://www.reddit.com/r/MachineLearning/comments/8gowcl/how_should_a_college_dropout_find_a_job_in_data/,l0gicbomb,1525336975,[removed],0,1
116,2018-5-3,2018,5,3,17,8goy62,Automatic Peanut Coating Production Line For Sale|Coated Peanut Making Machine,https://www.reddit.com/r/MachineLearning/comments/8goy62/automatic_peanut_coating_production_line_for/,Machineprices,1525337713,,1,1
117,2018-5-3,2018,5,3,18,8gp0yp,Reinforcement Learning with Multi Arm Bandit  Medium,https://www.reddit.com/r/MachineLearning/comments/8gp0yp/reinforcement_learning_with_multi_arm_bandit/,Fewthp,1525338806,,0,1
118,2018-5-3,2018,5,3,18,8gp48s,Disentanglement in NLP - toy dataset equivalent to dSprites dataset,https://www.reddit.com/r/MachineLearning/comments/8gp48s/disentanglement_in_nlp_toy_dataset_equivalent_to/,solingermuc,1525340137,[removed],0,1
119,2018-5-3,2018,5,3,18,8gp5ng,Low power AI chips with small amount of data getting better results than Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8gp5ng/low_power_ai_chips_with_small_amount_of_data/,Luzututhun,1525340668,"I came across this startup: [Another Brain](http://anotherbrain.ai) claiming to design low power chips with embedded AI that give better results than common deep learning implementations. All with limited amount of data and very little processing power.
What do you think? Is it real or too good to be true?",0,1
120,2018-5-3,2018,5,3,19,8gpey9,"What would you all think of a website that discussed the theory behind machine learning, and how it could be used to inform decisions in real-world machine learning applications?",https://www.reddit.com/r/MachineLearning/comments/8gpey9/what_would_you_all_think_of_a_website_that/,espergrafs,1525344143,[removed],0,1
121,2018-5-3,2018,5,3,19,8gpghv,Curry Powder Filling Machine,https://www.reddit.com/r/MachineLearning/comments/8gpghv/curry_powder_filling_machine/,lgsherry,1525344672,,1,1
122,2018-5-3,2018,5,3,19,8gphga,Which order: Theory or programming first?,https://www.reddit.com/r/MachineLearning/comments/8gphga/which_order_theory_or_programming_first/,project_elAIne,1525345005,[removed],0,1
123,2018-5-3,2018,5,3,20,8gpj2a,What is The Easiest Way To Learn Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8gpj2a/what_is_the_easiest_way_to_learn_machine_learning/,imarticus_nirmal,1525345546,,0,1
124,2018-5-3,2018,5,3,20,8gpmef,Which Skills Are Required for Machine Learning Jobs?,https://www.reddit.com/r/MachineLearning/comments/8gpmef/which_skills_are_required_for_machine_learning/,imarticus_nirmal,1525346591,,0,1
125,2018-5-3,2018,5,3,20,8gpo6m,Machine Learning on Finance,https://www.reddit.com/r/MachineLearning/comments/8gpo6m/machine_learning_on_finance/,eamanu,1525347140,[removed],0,1
126,2018-5-3,2018,5,3,20,8gpp0k,[D] Where is evidence that batch normalization speeds up convergence of neural nets?,https://www.reddit.com/r/MachineLearning/comments/8gpp0k/d_where_is_evidence_that_batch_normalization/,RobRomijnders,1525347419,"It seems common knowledge that *batch normalization speeds up convergence and reduces sensitivity for initialization*. Actually, it is even in the title of the [original paper with over 4k citations](https://arxiv.org/abs/1502.03167)

I wonder if anyone ever did a rigorous comparison of neural nets with and without normalization layers. The authors themselves provide a small experiment, but did anyone compare convergence speeds (whatever that means) with and without normalization layers?

Also for initialization of the parameters: do you know any paper that shows batch normalization converging in a poorly initialized neural net?

I have been searching for days now, but can't find any.",24,30
127,2018-5-3,2018,5,3,20,8gpq9j,How to get internship/job in Machine Learning | AI,https://www.reddit.com/r/MachineLearning/comments/8gpq9j/how_to_get_internshipjob_in_machine_learning_ai/,vector_machines,1525347821,,0,1
128,2018-5-3,2018,5,3,20,8gpsg1,Detecting Emotions with CNN Fusion Models,https://www.reddit.com/r/MachineLearning/comments/8gpsg1/detecting_emotions_with_cnn_fusion_models/,omarsar,1525348484,,0,1
129,2018-5-3,2018,5,3,21,8gpuyc,[P] Teaching Machines to Read Radiology Reports,https://www.reddit.com/r/MachineLearning/comments/8gpuyc/p_teaching_machines_to_read_radiology_reports/,saucysassy,1525349220,,0,10
130,2018-5-3,2018,5,3,21,8gpyul,"The new chapter of the saga, published by Square Enix, will see the famous archaeologist struggling with a Maya prophecy",https://www.reddit.com/r/MachineLearning/comments/8gpyul/the_new_chapter_of_the_saga_published_by_square/,mrpuopuo,1525350341,,0,1
131,2018-5-3,2018,5,3,21,8gpzus,Why does MAPPER produce replicate nodes in some clusters?,https://www.reddit.com/r/MachineLearning/comments/8gpzus/why_does_mapper_produce_replicate_nodes_in_some/,patruong,1525350626,[removed],0,1
132,2018-5-3,2018,5,3,22,8gq6ms,"[N] Weekly Machine Learning Opensource Roundup  May 3, 2018",https://www.reddit.com/r/MachineLearning/comments/8gq6ms/n_weekly_machine_learning_opensource_roundup_may/,stkim1,1525352479,,0,1
133,2018-5-3,2018,5,3,22,8gqdvk,ConvNet on sattelite image series and missing data,https://www.reddit.com/r/MachineLearning/comments/8gqdvk/convnet_on_sattelite_image_series_and_missing_data/,perilo,1525354324,[removed],0,1
134,2018-5-3,2018,5,3,22,8gqgpy,[P] Loc2Vec: Learning location embeddings with triplet-loss networks,https://www.reddit.com/r/MachineLearning/comments/8gqgpy/p_loc2vec_learning_location_embeddings_with/,esurior,1525355029,,11,114
135,2018-5-3,2018,5,3,22,8gqjjn,Detecting Emotions with CNN Fusion Models,https://www.reddit.com/r/MachineLearning/comments/8gqjjn/detecting_emotions_with_cnn_fusion_models/,omarsar,1525355743,,0,1
136,2018-5-3,2018,5,3,23,8gqqlu,[D] Fake gradients for activation functions,https://www.reddit.com/r/MachineLearning/comments/8gqqlu/d_fake_gradients_for_activation_functions/,serpimolot,1525357417,"Is there any theoretical reason that the error derivatives of an activation function have to be related to the exact derivative of that function itself?

This sounds weird, but bear with me. I know that activation functions need to be differentiable so that your can update your weights in the right direction by the right amount. But you can use functions that aren't purely differentiable, like ReLU which has an undefined gradient at zero. But you can _pretend_ that the gradient is defined at zero, because that particular mathematical property of the ReLU function is a curiosity and isn't relevant to the optimisation behaviour of your network. 

How far can you take this? When you're using an activation function, you're interested in two properties: its activation behaviour (or its feedforward properties), and its gradient/optimisation behaviour (or its feedbackward properties). Is there any particular theoretical reason these two are inextricable?

Say I have a layer that needs to have a saturating activation function for numerical reasons (each neuron needs to learn something like an inclusive OR, and ReLU is bad at this). I can use a sigmoid or tanh as the activation, but this comes with vanishing gradient problems when weighted inputs are very high or very low. I'm interested in the feedforward properties of the saturating function, but not its feedbackward properties.

The strength of ReLU is that its gradient is constant across a wide range of values. Would it be insane to define a function that is identical to the sigmoid, with the exception that its derivative is always 1? Or is there some non-obvious reason why this would not work?

I've tried this for a toy network on MNIST and it doesn't seem to train any worse than regular sigmoid, but it's not quite as trivial to implement on my actual tensorflow projects. And maybe a constant derivative isn't the exact answer, but something else with desirable properties. Generally speaking, is it plausible to define the derivative of an activation to be some fake function that is not the actual derivative of that function?",54,147
137,2018-5-3,2018,5,3,23,8gqr5a,[D] Training a Keras model to generate color names,https://www.reddit.com/r/MachineLearning/comments/8gqr5a/d_training_a_keras_model_to_generate_color_names/,jamesonatfritz,1525357547,,4,5
138,2018-5-4,2018,5,4,0,8gr74e,Facebook OpenGo vs Google AlphaZero,https://www.reddit.com/r/MachineLearning/comments/8gr74e/facebook_opengo_vs_google_alphazero/,itinte,1525361181,,0,1
139,2018-5-4,2018,5,4,0,8gr8qr,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8gr8qr/machine_learning/,Edwin_Cahuatijo,1525361536,,0,1
140,2018-5-4,2018,5,4,0,8grazw,Modifying Windows File Caching Behavior to Speed up Training Time,https://www.reddit.com/r/MachineLearning/comments/8grazw/modifying_windows_file_caching_behavior_to_speed/,idg101,1525362057,[removed],0,1
141,2018-5-4,2018,5,4,0,8grdzl,Network-constrained spatial clustering with Python,https://www.reddit.com/r/MachineLearning/comments/8grdzl/networkconstrained_spatial_clustering_with_python/,didnteventri,1525362712,,0,1
142,2018-5-4,2018,5,4,1,8grhz9,[D] How can machine learning affect business?,https://www.reddit.com/r/MachineLearning/comments/8grhz9/d_how_can_machine_learning_affect_business/,JimmyJumpdrive,1525363570,"So I'm a bit newer to technology, but the company I work for has assigned me with the task of researching how ML could improve our sales system.

I've been looking around but haven't seem to have had any luck with finding sales statistics, ad analytics, etc. that correlate to before and after machine learning was integrated into a company's business model. (Kind of like Amazon before and after machine learning was introduced)

So, for the sake of discussion; What parts of any business could benefit the most from integrating with machine learning? If you have statistics, please do share.",3,0
143,2018-5-4,2018,5,4,1,8grl8p,[D] Robots Wont Steal Your Job: How AI is Creating a New Job Landscape,https://www.reddit.com/r/MachineLearning/comments/8grl8p/d_robots_wont_steal_your_job_how_ai_is_creating_a/,VY99,1525364303,,0,0
144,2018-5-4,2018,5,4,1,8grn22,[D] Object detection algorithm where speed isn't that important?,https://www.reddit.com/r/MachineLearning/comments/8grn22/d_object_detection_algorithm_where_speed_isnt/,noofen,1525364700,"I'm brand new to machine learning, but I'm trying to build something that recognizes objects in images. A lot of the algorithms I've researched like SSD and YOLO seem to be built for realtime (video).

I'm curious if these algorithms sacrifice accuracy for speed (trying to hit that 30fps mark, for example). If I'm okay with 1s processing times to recognize all objects in an image, what is the best algorithm for that?",12,1
145,2018-5-4,2018,5,4,2,8gs311,"[PyTorch for Computer Vision 2]: GPU in Deep Learning, do you need one? - The AI Journal",https://www.reddit.com/r/MachineLearning/comments/8gs311/pytorch_for_computer_vision_2_gpu_in_deep/,databiryani,1525368176,,0,2
146,2018-5-4,2018,5,4,2,8gs445,"Check out Lobe, an easy-to-use visual tool that lets you build custom deep learning models, quickly train them, and ship them directly in your app without writing any code",https://www.reddit.com/r/MachineLearning/comments/8gs445/check_out_lobe_an_easytouse_visual_tool_that_lets/,tcdb28,1525368396,,0,1
147,2018-5-4,2018,5,4,3,8gsr9c,[D] What development languages would give you the most long term utility in the field of ML?,https://www.reddit.com/r/MachineLearning/comments/8gsr9c/d_what_development_languages_would_give_you_the/,CriticalDefinition,1525373414,"Most of the popular libraries today run on python, with some cool stuff on R.

The back-end of the libraries sometimes run on lower-level languages like C++ (thinking of tensorflow here, of course).

So for right now it seems learning python at a minimum and maybe some basic understanding of tangent languages is the shortest and most obvious path to working with ML.

Is this a stable paradigm? Is there an obvious gradual trend towards a new language? Are there any potential ""dark horses"" that for whatever technical reasons may be preferable?

Am I showing some misunderstanding of how software development works when I ask questions like this?",6,0
148,2018-5-4,2018,5,4,3,8gss31,Finding best channel in a Multivariate time series,https://www.reddit.com/r/MachineLearning/comments/8gss31/finding_best_channel_in_a_multivariate_time_series/,saeedghorbani,1525373593,[removed],0,1
149,2018-5-4,2018,5,4,3,8gssnr,[R] AI Safety via Debate,https://www.reddit.com/r/MachineLearning/comments/8gssnr/r_ai_safety_via_debate/,_sulo,1525373715,,6,18
150,2018-5-4,2018,5,4,4,8gsyvk,"Lobe | Deep Learning Made Simple (Latest from Mike Matas, designer of the iPad)",https://www.reddit.com/r/MachineLearning/comments/8gsyvk/lobe_deep_learning_made_simple_latest_from_mike/,davegoldblatt,1525375077,,0,1
151,2018-5-4,2018,5,4,4,8gta4g,[P] Generating Pusheen with GANs in tensorflow.js,https://www.reddit.com/r/MachineLearning/comments/8gta4g/p_generating_pusheen_with_gans_in_tensorflowjs/,znado,1525377584,,4,13
152,2018-5-4,2018,5,4,5,8gtki4,Difficulty to reproduce Neural Network results from a book. Can anyone help?,https://www.reddit.com/r/MachineLearning/comments/8gtki4/difficulty_to_reproduce_neural_network_results/,KristaFe,1525379855,[removed],0,1
153,2018-5-4,2018,5,4,5,8gtom8,Good anime face detection API,https://www.reddit.com/r/MachineLearning/comments/8gtom8/good_anime_face_detection_api/,dinoaide,1525380764,[removed],0,1
154,2018-5-4,2018,5,4,5,8gtp25,[R] Nav-A3C Question,https://www.reddit.com/r/MachineLearning/comments/8gtp25/r_nava3c_question/,agiantwhale,1525380859,"In the [Nav-A3C](https://arxiv.org/pdf/1611.03673.pdf) paper, it states

&gt; Depth is taken as the Z-buffer from the Labyrinth environment (with values between 0 and 255), divided by 255 and taken to power 10 to spread the values in the interval [0, 1].

Division by 255 will already constrain the values in the range [0-1], with taking to the power of 10 constraining outside the range (eg: 10^(0.3) = 2).

What am I misunderstanding?",3,0
155,2018-5-4,2018,5,4,6,8gtwdc,[P] Fountain - Natural Language Data Augmentation Tool,https://www.reddit.com/r/MachineLearning/comments/8gtwdc/p_fountain_natural_language_data_augmentation_tool/,tzano,1525382510,,3,26
156,2018-5-4,2018,5,4,6,8gu1ij,[D] Can anyone recommend some good papers/books/articles to read on working with small datasets and/or working with unbalanced datasets?,https://www.reddit.com/r/MachineLearning/comments/8gu1ij/d_can_anyone_recommend_some_good/,rulerofthehell,1525383652,"Non-deep learning based approaches appreciated too, thanks.",9,7
157,2018-5-4,2018,5,4,6,8gu2li,"[D] Nathan Goldbaum on Twitter: "" """,https://www.reddit.com/r/MachineLearning/comments/8gu2li/d_nathan_goldbaum_on_twitter/,_alphamaximus_,1525383899,,0,1
158,2018-5-4,2018,5,4,8,8gurn5,Large Meme Database?,https://www.reddit.com/r/MachineLearning/comments/8gurn5/large_meme_database/,IamPANDAMAN8,1525389858,[removed],0,1
159,2018-5-4,2018,5,4,10,8gvopk,"QT4 25 automatic CHB cement hollow block machine in Angono, Philippines,...",https://www.reddit.com/r/MachineLearning/comments/8gvopk/qt4_25_automatic_chb_cement_hollow_block_machine/,dymachine01,1525398594,,1,1
160,2018-5-4,2018,5,4,10,8gvopp,Help on tools to use for ML tools suited for audio System Identificantion methods.,https://www.reddit.com/r/MachineLearning/comments/8gvopp/help_on_tools_to_use_for_ml_tools_suited_for/,StonerMacStonerson,1525398595,"Hi, I'm a Acoustic Engineering grad student currently undergoing a experimental project in which I would really appreciate some help.

The idea is to use a machine learning algorithm to identify a filter in a audio signal. For example, feed it a clean signal and give as a output this signal with a Low\-Pass Filter, and make it sort this relation out.  Starting out with a linear system such as a filter could be a good start to modeling more complex stuff, i believe.

I am using python for this job, looking at some Recurrent Neural Networks, NARX and MLP\(Multi\-Layer Perceptron\). Do you think those are feasible tools for this kind of application, or do you suggest other? And is TensorFlow a adequate library for this? 

Thanks for the help! I am really looking forward to advancing with this idea and I would be so glad if you could shed some light on it. ",0,1
161,2018-5-4,2018,5,4,11,8gvsbt,ML tools suited for audio System Identification.?,https://www.reddit.com/r/MachineLearning/comments/8gvsbt/ml_tools_suited_for_audio_system_identification/,StonerMacStonerson,1525399584,[removed],0,1
162,2018-5-4,2018,5,4,12,8gw4kv,Predicting content that gets popular/shared a lot,https://www.reddit.com/r/MachineLearning/comments/8gw4kv/predicting_content_that_gets_popularshared_a_lot/,seands,1525403032,[removed],0,1
163,2018-5-4,2018,5,4,12,8gw6tp,[P] Predicting content that gets popular/shared a lot,https://www.reddit.com/r/MachineLearning/comments/8gw6tp/p_predicting_content_that_gets_popularshared_a_lot/,seands,1525403713,"Hey guys,

One technique for creating content that gets a lot of views is called the ""skyscraper method"" where you find highly shared content using buzzsumo or similar, and then release your own version that's even better (more depth, value, superior imagery, style etc). 

The problem with that is you are doing more of the same. I would like to use machine learning to go one step further and do one or both of the following:

1. Display common characteristics of top content a) in my niche b) across all niches. Insight should extend beyond the generalities found in marketing articles on the subject (top content tends to be long, controversial etc).

2. Predictively either a) come up with content topics or b) score topic ideas I manually create.

I only know about ML broadly, that it uses a test sample to generate an algorithm from many possibilities. Is my project a good fit for the capabilities and limitations of a current machine learning library? Buzzsumo would be my most likely datasource.",3,9
164,2018-5-4,2018,5,4,12,8gwepz,Level of research paper expected from student applying for masters in cs,https://www.reddit.com/r/MachineLearning/comments/8gwepz/level_of_research_paper_expected_from_student/,lcukerd,1525406099,[removed],0,1
165,2018-5-4,2018,5,4,14,8gwy8j,[R] Breaking CAPTCHAs using machine learning,https://www.reddit.com/r/MachineLearning/comments/8gwy8j/r_breaking_captchas_using_machine_learning/,digitalson,1525412290,,0,1
166,2018-5-4,2018,5,4,14,8gx07s,"[P] AI startup H2O.ai launches Driverless AI, an automated machine learning platform",https://www.reddit.com/r/MachineLearning/comments/8gx07s/p_ai_startup_h2oai_launches_driverless_ai_an/,polllyyy,1525412982,,0,1
167,2018-5-4,2018,5,4,16,8gxdba,Writing your first machine learning code,https://www.reddit.com/r/MachineLearning/comments/8gxdba/writing_your_first_machine_learning_code/,Zeolearn,1525417733,,0,1
168,2018-5-4,2018,5,4,16,8gxg99,Convolution and transpose deconvolution,https://www.reddit.com/r/MachineLearning/comments/8gxg99/convolution_and_transpose_deconvolution/,mohanradhakrishnan,1525418817,[removed],1,1
169,2018-5-4,2018,5,4,16,8gxj16,Importing an actual game into q Learning?,https://www.reddit.com/r/MachineLearning/comments/8gxj16/importing_an_actual_game_into_q_learning/,DrakeSlain,1525419929,[removed],0,1
170,2018-5-4,2018,5,4,17,8gxmfi,[P] Code to generate academic research papers datasets (including full-text),https://www.reddit.com/r/MachineLearning/comments/8gxmfi/p_code_to_generate_academic_research_papers/,rtk25,1525421282,,0,1
171,2018-5-4,2018,5,4,17,8gxntr,Dry Peanut Skin Peeling Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8gxntr/dry_peanut_skin_peeling_machine_for_sale/,Machineprices,1525421820,,1,1
172,2018-5-4,2018,5,4,17,8gxo6w,Academic research paper mining (including full-text),https://www.reddit.com/r/MachineLearning/comments/8gxo6w/academic_research_paper_mining_including_fulltext/,rtk25,1525421984,,0,1
173,2018-5-4,2018,5,4,17,8gxrf0,Drum Type Peanut Roasting Machine For Sale|Almond Nut Roaster Machine,https://www.reddit.com/r/MachineLearning/comments/8gxrf0/drum_type_peanut_roasting_machine_for_salealmond/,Machineprices,1525423327,,1,1
174,2018-5-4,2018,5,4,18,8gxu7u,Recommendation Systems in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8gxu7u/recommendation_systems_in_machine_learning/,Zeolearn,1525424455,,0,1
175,2018-5-4,2018,5,4,18,8gxvya,Feature generation from resumes,https://www.reddit.com/r/MachineLearning/comments/8gxvya/feature_generation_from_resumes/,CurrentConcentrate,1525425109,,0,1
176,2018-5-4,2018,5,4,18,8gxwfi,[D] Recommended Cloud Computing Services for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8gxwfi/d_recommended_cloud_computing_services_for/,alexgmcm,1525425279,"As I have an AMD Card and the current bubble in GPU prices makes it not really economical to buy a new Nvidia one I'm interested in which cloud computing services you guys use and their advantages/disadvantages.

I've seen many such as AWS, Microsoft Azure, Google Cloud, Floyd Hub and Domino Data Lab but I've never used any Cloud services before so I don't really know how to select between them.

Any help/advice on choosing a cloud service (and how to use it) is greatly appreciated. ",55,60
177,2018-5-4,2018,5,4,18,8gxzx7,Amazon and University of Sheffield Researchers Make Large-Scale Fact Extraction and Verification Dataset Publicly Available,https://www.reddit.com/r/MachineLearning/comments/8gxzx7/amazon_and_university_of_sheffield_researchers/,christosc14,1525426691,,0,1
178,2018-5-4,2018,5,4,18,8gy11n,[R] Multi-Modal Methods: Visual Speech Recognition (Lip Reading),https://www.reddit.com/r/MachineLearning/comments/8gy11n/r_multimodal_methods_visual_speech_recognition/,mel_silizar,1525427153,,10,91
179,2018-5-4,2018,5,4,18,8gy2ql,[P] The music visualizer to rule them all: Feeding data from music into a GAN to generate (dancing flowers) visualizations,https://www.reddit.com/r/MachineLearning/comments/8gy2ql/p_the_music_visualizer_to_rule_them_all_feeding/,LeonCAr,1525427814,"Weekend project on making latent representations of music and feeding them instead of the ""z noise"" into a GAN. Performs FFT on ~0.1s of music with 1/30 of a second in between (to produce 30fps). PCA to map FFT to 16 dimensions. Feed 16 dimensions into the z_noise variable in a pretrained GAN. Make the frames into a video. Enjoy the view :)

https://www.youtube.com/watch?v=1qcXCn5poe4",16,36
180,2018-5-4,2018,5,4,18,8gy337,Initialization for segmentation networks besides classifier weights?,https://www.reddit.com/r/MachineLearning/comments/8gy337/initialization_for_segmentation_networks_besides/,InfiniteLife2,1525427974,[removed],0,1
181,2018-5-4,2018,5,4,18,8gy347,[D] What are your go to non-image benchmark datasets?,https://www.reddit.com/r/MachineLearning/comments/8gy347/d_what_are_your_go_to_nonimage_benchmark_datasets/,NicolasGuacamole,1525427988,"Its a bit tiring always seeing the same datasets for benchmarking neural nets. 

Does anyone have any favourite problems (ideally classification) which are not image based or at least arent mnist/cigar/svhn/imagenet?",7,12
182,2018-5-4,2018,5,4,19,8gy4u3,[D] What is the best way to run a tensorflow detection model on batches of 100+ images online?,https://www.reddit.com/r/MachineLearning/comments/8gy4u3/d_what_is_the_best_way_to_run_a_tensorflow/,josealb,1525428596,"I need to run a model from Tensorflow's object detection API on batches of images. I have tried Google Cloud ML Engine, but could not get the model to run (although it works on my machine)",0,0
183,2018-5-4,2018,5,4,19,8gy96c,Pipe Cleaning Machines,https://www.reddit.com/r/MachineLearning/comments/8gy96c/pipe_cleaning_machines/,aaronaccessories23,1525430221,,0,1
184,2018-5-4,2018,5,4,20,8gyids,Here's how you can create the best chatbot for your needs and budget,https://www.reddit.com/r/MachineLearning/comments/8gyids/heres_how_you_can_create_the_best_chatbot_for/,Victor_Stakh,1525433291,,0,1
185,2018-5-4,2018,5,4,20,8gyivg,Sesame Candy|Peanut Candy Production Line,https://www.reddit.com/r/MachineLearning/comments/8gyivg/sesame_candypeanut_candy_production_line/,lgsherry,1525433433,,1,1
186,2018-5-4,2018,5,4,20,8gynxb,Feature generation from resumes,https://www.reddit.com/r/MachineLearning/comments/8gynxb/feature_generation_from_resumes/,CurrentConcentrate,1525435003,[removed],0,1
187,2018-5-4,2018,5,4,21,8gyqgj,[R]Feature generation from resumes,https://www.reddit.com/r/MachineLearning/comments/8gyqgj/rfeature_generation_from_resumes/,CurrentConcentrate,1525435735,"Hi, I am looking for some specific theory about how to perform feature generation. I would like to find some algorithm that enables automatically extracts a combination of a certain skill and the years of experience with that skill. For example, I want an algorithm to find that a person has 3 years of experience with programming in the Python language. Could you point me in the right direction to find/make such algorithm?

I am not familiar in this field, so that is why I ask for your help. I already found that main text mining technologies are clustering, categorisation and information extraction. However, I find it difficult to find my way in this research field.

I hope you can help me! I have access to research articles through my university, so referring to those is no problem. Thanks in advance.",6,0
188,2018-5-4,2018,5,4,21,8gyybm,[P] Looking for software/example code for labelling real-world physical ads in a picture in order to crowdsource a dataset to recognise these ads.,https://www.reddit.com/r/MachineLearning/comments/8gyybm/p_looking_for_softwareexample_code_for_labelling/,imrich-,1525437887,"Want to build real\-life adblocker, see [previous reddit post](https://www.reddit.com/r/MachineLearning/comments/88l32o/p_anyone_working_on_reallife_ad_blocking_neural/).

One of the main problems is having the labeled data in order to train the model. Want to crowdsource it \- create a simple app where people can \(1\) take a picture, \(2\) label the ad and \(3\) submit to a database. This way, we will have a real\-life adblock when AR glasses are a thing wohoo :\)

Trying to figure out the labelling part. One user in DM mentioned, that there was a paper with precise selection of objects where only 4 extreme keypoints \- left, right, upper and lower \- were annotated and the rest was guessed by a model. **Anyone knows this paper or can give some info on how to find it?**

Since most ads are rectangular, I am thinking it would be enough for the user to tap 4 times \(corners\) on the image and the area enclosed will be the labeled ad.

I am a complete *noob* in labelling data for training an ML model, so any help is very much appreciated. **What software/algorithms researchers use to label the pictures? How does it work?**

thanks a lot :\)",6,11
189,2018-5-4,2018,5,4,21,8gz02i,Brainstorming AGI requirements,https://www.reddit.com/r/MachineLearning/comments/8gz02i/brainstorming_agi_requirements/,mount_sumInt,1525438370,[removed],0,1
190,2018-5-4,2018,5,4,21,8gz0ul,Do you use PowerSign or Addsign to replace Adam Optimizer?,https://www.reddit.com/r/MachineLearning/comments/8gz0ul/do_you_use_powersign_or_addsign_to_replace_adam/,mommydaddyandjenny,1525438581,[removed],0,1
191,2018-5-4,2018,5,4,21,8gz17n,ConvNets and Conv Layers,https://www.reddit.com/r/MachineLearning/comments/8gz17n/convnets_and_conv_layers/,GimmeThoseCaps,1525438677,[removed],0,1
192,2018-5-4,2018,5,4,23,8gziht,[P] Keras - Accessing feature indices from custom objective,https://www.reddit.com/r/MachineLearning/comments/8gziht/p_keras_accessing_feature_indices_from_custom/,Zman420,1525442903,"Hi all.

I would like to create a custom loss function that uses a feature as part of the calculation. More specifically - I just need the mean of the feature across the batch/set, and include that in a calculation for my custom loss.

So if I have 1000 features, in in my custom loss I would like to be able to know the mean value of feature #10, in the batch/set that was used to give y_pred.  I know I can use wrappers to pass custom data, but passing a vector of all instances of feature #10 is pointless, because I don't know which subset of indices have been used in that batch/set.

I found this example on Stack Overflow which seems quite close to what I'm after, but I don't fully understand how to make it work for my situation, partially because my Keras layout seems have a slightly different style.

Stack overflow thread:
https://stackoverflow.com/questions/46464549/keras-custom-loss-function-accessing-current-input-pattern


Snippet of my code/model:

    model = Sequential()
    model.add(Dense(80, kernel_initializer='uniform',input_dim=NCOMPONENTS))
    model.add(Dropout(0.2))
    model.add(Activation('selu'))
    model.add(BatchNormalization())
    				 
    model.add(Dense(40, kernel_initializer='uniform'))
    model.add(Dropout(0.2))
    model.add(Activation('selu'))
    model.add(BatchNormalization())
    
    model.add(Dense(10, kernel_initializer='uniform'))
    model.add(Dropout(0.2))
    model.add(Activation('selu'))
    model.add(BatchNormalization())
    
    model.add(Dense(2, kernel_initializer='uniform'))
    model.add(Activation('softmax'))
    
    adam = optimizers.Adam(lr=0.000005, beta_1=0.9, beta_2=0.999, decay=0.0)
    
    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[ single_class_precision(1)])

    history = model.fit(X_train, Y_train, epochs=25000, batch_size=512, verbose=1,  shuffle=True, 
    validation_split=0.3,class_weight={0:1, 1:2.5},callbacks=callbacks_list)


Any help would be appreciated.
",12,4
193,2018-5-5,2018,5,5,0,8gzzo5,"skorch 0.2.0 released - new features, supports PyTorch 0.4",https://www.reddit.com/r/MachineLearning/comments/8gzzo5/skorch_020_released_new_features_supports_pytorch/,ottonemo,1525446865,,1,1
194,2018-5-5,2018,5,5,0,8h02x0,"[P] skorch 0.2.0 released - new features, supports PyTorch 0.4",https://www.reddit.com/r/MachineLearning/comments/8h02x0/p_skorch_020_released_new_features_supports/,ottonemo,1525447593,,6,22
195,2018-5-5,2018,5,5,0,8h09c9,"Google Kubeflow, machine learning for Kubernetes, begins to take shape",https://www.reddit.com/r/MachineLearning/comments/8h09c9/google_kubeflow_machine_learning_for_kubernetes/,thetimmyjohnson,1525449018,,0,1
196,2018-5-5,2018,5,5,1,8h0dcj,Best model for predicting purchase sizes,https://www.reddit.com/r/MachineLearning/comments/8h0dcj/best_model_for_predicting_purchase_sizes/,niujin,1525449909,[removed],0,1
197,2018-5-5,2018,5,5,2,8h0ygz,How do ReLu(Rectified Linear Unit) activation functions introduce nonlinearity into Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/8h0ygz/how_do_relurectified_linear_unit_activation/,Overload175,1525454550,[removed],0,1
198,2018-5-5,2018,5,5,3,8h1c1g,A History of AI Research in StarCraft,https://www.reddit.com/r/MachineLearning/comments/8h1c1g/a_history_of_ai_research_in_starcraft/,galacticacidtrip,1525457489,,0,1
199,2018-5-5,2018,5,5,3,8h1ky4,"[D] ELBO surgery, matching the prior to the approximate posterior?",https://www.reddit.com/r/MachineLearning/comments/8h1ky4/d_elbo_surgery_matching_the_prior_to_the/,AloneStretch,1525459515,"Sevaral papers and blogs have proposed matching the prior to the aggregate (marginal) approximate posterior in a VAE, q(z) = 1/n sum q(z_i|x_i).  The Hoffman Johnson ELBO surgery paper proposes that p(z) be changed to match q(z) ""halfway"".  Most simply, this post by Singh, [ELBO Surgery](https://rachitsingh.com/elbo_surgery) states
""However, we want the average distribution to be close to the prior, so this term can go to 0 safely without worrying about whether the posterior has learned something. In fact, at the cost of a lot of extra computation, we can even safely set the prior to be this distribution, or let p(z) := q(z)!""
where the := denotes defined to be equal, small triangle above the equal sign.

My question is basic. How can the prior be defined in terms of the approximate posterior, this seems circular!  In the VAE, the only things that are given are the data, and the prior (and the DNN architecture). The approximate posterior is **learned**, with the loss reconstruction+KL that depend on the prior. So if the posterior is generated from the prior, setting the prior to match the posterior (which does not independently exist) seems meaningless.


(The paper VAE with a VampPrior also may be a case here, it has a prior that looks like a mixture of posteriors, but I do not understand the pseduoinputs part of that yet).


",0,0
200,2018-5-5,2018,5,5,3,8h1lfs,[P] Prototype of 3D Hand Pose and Gesture Tracking on a Monocular Mobile Device (Keras + Core ML),https://www.reddit.com/r/MachineLearning/comments/8h1lfs/p_prototype_of_3d_hand_pose_and_gesture_tracking/,hwoolery,1525459604,,56,218
201,2018-5-5,2018,5,5,3,8h1nj9,Reducing cold-start problem in neighborhood collaborative filtering models?,https://www.reddit.com/r/MachineLearning/comments/8h1nj9/reducing_coldstart_problem_in_neighborhood/,jzini,1525460072,[removed],0,1
202,2018-5-5,2018,5,5,4,8h1peq,"[D] ELBO surgery, matching the prior to the approximate posterior?",https://www.reddit.com/r/MachineLearning/comments/8h1peq/d_elbo_surgery_matching_the_prior_to_the/,AloneStretch,1525460498,"Sevaral papers and blogs have proposed matching the prior to the aggregate (marginal) approximate posterior in a VAE, q(z) = 1/n sum q(z_i|x_i).  The Hoffman Johnson ELBO surgery paper proposes that p(z) be changed to match q(z) ""halfway"".  Most simply, this post by Singh, [ELBO Surgery](https://rachitsingh.com/elbo_surgery) states
""However, we want the average distribution to be close to the prior, so this term can go to 0 safely without worrying about whether the posterior has learned something. In fact, at the cost of a lot of extra computation, we can even safely set the prior to be this distribution, or let p(z) := q(z)!""
where the := denotes defined to be equal, small triangle above the equal sign.

My question is basic. How can the prior be defined in terms of the approximate posterior, this seems circular!  In the VAE, the only things that are given are the data, and the prior (and the DNN architecture). The approximate posterior is **learned**, with the loss reconstruction+KL that depend on the prior. So if the posterior is generated from the prior, setting the prior to match the posterior (which does not independently exist) seems meaningless.


(The paper VAE with a VampPrior also may be a case here, it has a prior that looks like a mixture of posteriors, but I do not understand the pseduoinputs part of that yet).


",7,2
203,2018-5-5,2018,5,5,4,8h1qrl,"PaintsTransferV3 released! Geometric Interactivity, Controllable Shadow Rendering, Better Skin Engine and More.",https://www.reddit.com/r/MachineLearning/comments/8h1qrl/paintstransferv3_released_geometric_interactivity/,q914847518,1525460818,,0,1
204,2018-5-5,2018,5,5,4,8h1tt5,"[p] PaintsTransferV3 released! Geometric Interactivity, Controllable Shadow Rendering, Better Skin Engine and More.",https://www.reddit.com/r/MachineLearning/comments/8h1tt5/p_paintstransferv3_released_geometric/,q914847518,1525461495,,0,1
205,2018-5-5,2018,5,5,4,8h1u4k,which method in machine learning do you think best for estimation satellite position from precise ephemeris ?,https://www.reddit.com/r/MachineLearning/comments/8h1u4k/which_method_in_machine_learning_do_you_think/,yamukblues,1525461572,[removed],0,1
206,2018-5-5,2018,5,5,4,8h1vy2,[D] Classifier to detect new/worn shoes. Need ideas!,https://www.reddit.com/r/MachineLearning/comments/8h1vy2/d_classifier_to_detect_newworn_shoes_need_ideas/,ME_PhD,1525461990,"I want to train a ConvNet to detect if shoes are new or worn/dirty. I could use some help brainstorming the best way to do this.

My first thought was the simple/obvious one - get .50/.50 training images of new/worn shoes and encode it as a single number 0/1. But now I'm wondering if it's wiser to have a third class of ""unsure"".

Thoughts?",5,0
207,2018-5-5,2018,5,5,4,8h1y1y,what would be a good graduation project idea includes positioning/geodesy or remote sensing / image processing or gis for a geomatics engineering student?,https://www.reddit.com/r/MachineLearning/comments/8h1y1y/what_would_be_a_good_graduation_project_idea/,yamukblues,1525462458,,0,1
208,2018-5-5,2018,5,5,4,8h20li,Speech Recognition is Now Vulnerable to Adversarial Attacks,https://www.reddit.com/r/MachineLearning/comments/8h20li/speech_recognition_is_now_vulnerable_to/,acganesh,1525463058,,0,1
209,2018-5-5,2018,5,5,4,8h21mt,"[P] Style2PaintsV3 released! Geometric Interactivity, Controllable Shadow Rendering, Better Skin Engine and More.",https://www.reddit.com/r/MachineLearning/comments/8h21mt/p_style2paintsv3_released_geometric_interactivity/,q914847518,1525463274,,0,1
210,2018-5-5,2018,5,5,5,8h2ck9,Using Super Convergence to train Imagenet in 3 hours for $25; and CIFAR10 for $0.26,https://www.reddit.com/r/MachineLearning/comments/8h2ck9/using_super_convergence_to_train_imagenet_in_3/,balazshoranyi,1525465758,,0,1
211,2018-5-5,2018,5,5,5,8h2hza,Looking for a list of ways to minimize false positives in binary classification,https://www.reddit.com/r/MachineLearning/comments/8h2hza/looking_for_a_list_of_ways_to_minimize_false/,dchalmer,1525466981,[removed],0,1
212,2018-5-5,2018,5,5,6,8h2qyq,Why is the traditional ham vs spam problem modelled as a text classification problem and not a one class modelling problem.,https://www.reddit.com/r/MachineLearning/comments/8h2qyq/why_is_the_traditional_ham_vs_spam_problem/,crashbundicoot,1525469122,[removed],0,2
213,2018-5-5,2018,5,5,6,8h2u3b,[P] InsightFace: Face Recognition Project on MXNet,https://www.reddit.com/r/MachineLearning/comments/8h2u3b/p_insightface_face_recognition_project_on_mxnet/,zsdh123,1525469896,,0,8
214,2018-5-5,2018,5,5,6,8h2wzn,"[P] Style2PaintsV3 released! Geometric Interactivity, Controllable Shadow Rendering, Better Skin Engine and More.",https://www.reddit.com/r/MachineLearning/comments/8h2wzn/p_style2paintsv3_released_geometric_interactivity/,style2paints,1525470600,,52,363
215,2018-5-5,2018,5,5,7,8h30p3,ConvNetJS Reinforcement Learning demo within the gbrain library,https://www.reddit.com/r/MachineLearning/comments/8h30p3/convnetjs_reinforcement_learning_demo_within_the/,3droberto,1525471528,,0,1
216,2018-5-5,2018,5,5,7,8h3cmp,[D] Best metrics for evaluating GAN results? - Inception Score,https://www.reddit.com/r/MachineLearning/comments/8h3cmp/d_best_metrics_for_evaluating_gan_results/,not_untrue,1525474617,,6,0
217,2018-5-5,2018,5,5,8,8h3itz,[R] Finding Flatter Minima with SGD: Small batch size and large learning rate steer SGD towards flat minima,https://www.reddit.com/r/MachineLearning/comments/8h3itz/r_finding_flatter_minima_with_sgd_small_batch/,downtownslim,1525476244,,5,19
218,2018-5-5,2018,5,5,9,8h3xt8,[D] What types of machine learning algorithms are used in solving some popular real-world problems? And what is the next ?,https://www.reddit.com/r/MachineLearning/comments/8h3xt8/d_what_types_of_machine_learning_algorithms_are/,saadmrb,1525480146,"Here are some of known ML algorithms

Snapchat Filters:Convolutional Neural Networks (allegedly)

NetflixRecommendation System:Restricted Boltzmann Machines

Google Translate(Machine Translation):Recurrent Neural Networks

Siri(Personal Assistants):Hidden Markov Models (2011-2014), Long Short Term Memory Networks (2014+), which is a type of Recurrent Neural Networks.

Self-driving cars(Image recognition, Video recognition):Convolutional Neural Networks (among other things)

Speech recognition, Hand-writing recognition:Recurrent Neural Networks

Market Segmentation:k-means clustering

Google AlphaGo:Convolutional Neural ",4,6
219,2018-5-5,2018,5,5,9,8h3zfw,[R] Discussion of Face Recognition History and Implementation,https://www.reddit.com/r/MachineLearning/comments/8h3zfw/r_discussion_of_face_recognition_history_and/,zsdh123,1525480594,,0,5
220,2018-5-5,2018,5,5,9,8h3zlp,[P] TensorFlow: InsightFace/ArcFace Face Recognition,https://www.reddit.com/r/MachineLearning/comments/8h3zlp/p_tensorflow_insightfacearcface_face_recognition/,zsdh123,1525480635,,0,5
221,2018-5-5,2018,5,5,10,8h45i3,Stop training and save parameters in Keras,https://www.reddit.com/r/MachineLearning/comments/8h45i3/stop_training_and_save_parameters_in_keras/,shash_wat,1525482408,[removed],0,1
222,2018-5-5,2018,5,5,10,8h45sk,Andrew Ng Course,https://www.reddit.com/r/MachineLearning/comments/8h45sk/andrew_ng_course/,wasabiBro,1525482500,[removed],0,1
223,2018-5-5,2018,5,5,10,8h4748,[Discussion] Are complaints towards social media sites due to ignorance of machine learning?,https://www.reddit.com/r/MachineLearning/comments/8h4748/discussion_are_complaints_towards_social_media/,integrationderivativ,1525482900,"For quite some time, people have been complaining that major sites such as YouTube, Facebook and Twitter have been making really bad/stupid decisions regarding managing their content for users.

For example, people say YouTube does a really bad job when it comes to flagging videos for inappropriate content or violating copyright or something. Another example would be that YouTube doesn't show you new videos from your subscribed YouTubers in your feed somehow.

Whatever the complaint, the common denominator of all of them is that [major site] is [any adjective that describes stupidity and incompetence]. 

To my knowledge, the technology that is making those ""bad/stupid decisions"" are done by machine learning. Are people aware of this when they complain? If they are, I would expect them to at least be patient because given enough time, the algorithm will become good enough to get the job done. It just seems like they don't know that ML is a thing because they say [website name] is stupid for doing what it did.",8,0
224,2018-5-5,2018,5,5,11,8h4i2l,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/MachineLearning/comments/8h4i2l/are_you_interested_in_ai_and_want_to_start/,DiscoverAI,1525486309,,0,1
225,2018-5-5,2018,5,5,11,8h4otb,Image classification using Convolutional Neural Network(CNN),https://www.reddit.com/r/MachineLearning/comments/8h4otb/image_classification_using_convolutional_neural/,dkarunakaran,1525488357,,0,1
226,2018-5-5,2018,5,5,12,8h50z4,"Are you interested in AI/BigData and want to start achieving your goals by learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/MachineLearning/comments/8h50z4/are_you_interested_in_aibigdata_and_want_to_start/,DiscoverAI,1525492325,,0,1
227,2018-5-5,2018,5,5,14,8h5koh,Average salary in data/AI-related professions,https://www.reddit.com/r/MachineLearning/comments/8h5koh/average_salary_in_dataairelated_professions/,_data_scientist_,1525498968,[removed],0,1
228,2018-5-5,2018,5,5,14,8h5l4x,"Image Annotation Tool for Object Detection, with support to create tfRecords!",https://www.reddit.com/r/MachineLearning/comments/8h5l4x/image_annotation_tool_for_object_detection_with/,redditgol,1525499124,[removed],0,1
229,2018-5-5,2018,5,5,16,8h5zu6,"Solutions for ""Random Phenomena: Fundamentals of Probability and Statistics for Engineers"" By Babatunde Oggunaike",https://www.reddit.com/r/MachineLearning/comments/8h5zu6/solutions_for_random_phenomena_fundamentals_of/,ayushi_b,1525504780,[removed],0,1
230,2018-5-5,2018,5,5,16,8h62mj,Tensorflow Eager Tutorials,https://www.reddit.com/r/MachineLearning/comments/8h62mj/tensorflow_eager_tutorials/,madalinaaa,1525505897,,0,1
231,2018-5-5,2018,5,5,16,8h65an,How to interpolate images (multi dimension),https://www.reddit.com/r/MachineLearning/comments/8h65an/how_to_interpolate_images_multi_dimension/,Bb415bm,1525506960,[removed],0,1
232,2018-5-5,2018,5,5,17,8h6can,Training doesn't cause the loss to go down anymore,https://www.reddit.com/r/MachineLearning/comments/8h6can/training_doesnt_cause_the_loss_to_go_down_anymore/,stwykd,1525509972,[removed],0,1
233,2018-5-5,2018,5,5,18,8h6hi0,[R] EigenNet: Towards Fast and Structural Learning of Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8h6hi0/r_eigennet_towards_fast_and_structural_learning/,abstractcontrol,1525512423,,4,45
234,2018-5-5,2018,5,5,19,8h6p73,[D] [Question] Number of distributions in Categorical VAE.,https://www.reddit.com/r/MachineLearning/comments/8h6p73/d_question_number_of_distributions_in_categorical/,kamperh,1525515826,"When setting up the categorical VAE in the (great) tutorial https://blog.evjang.com/2016/11/tutorial-categorical-variational.html, there are two parameters specified.  The first is K, the number of classes, which I understand.  Then there is N, the number of categorical distributions.  I am struggling to see what N is?

At a first reading, I thought that if you are categorising MNIST, then you will simply encode each image as a K=10 dimensional one-hot vector.  But, I think that what is actually happening is that each image is encoded as N separate K-dimensional one-hot vectors.  Is this right?",3,6
235,2018-5-5,2018,5,5,19,8h6qly,[D] How do causal convolutions works?,https://www.reddit.com/r/MachineLearning/comments/8h6qly/d_how_do_causal_convolutions_works/,ShivamDuggal4,1525516419,"ByteNet , WaveNet both uses causal convolutions to ignore the inputs at future timesteps.
I have a doubt regarding the implementation of causal convolutions:
1. According to me, one way to implement causal convolution is to make the right side of the weight matrix zero, therefore ignoring the input feature map values right to the current pixel.

2. What I don't understand is how does this work by padding the input feature map as done in https://github.com/paarthneekhara/byteNet-tensorflow/blob/9bba9352e5f8a89a32ab14e9546a158750cdbfaf/ByteNet/ops.py#L26. How does padding the input make ensure that the summation being done at each center pixel observe only the current and previous pixel values?
Please explain how does causality work in the shared bytenet link.",0,1
236,2018-5-5,2018,5,5,20,8h6v62,AI Journal - Machine/Deep/Reinforcmeent Learning | NLP,https://www.reddit.com/r/MachineLearning/comments/8h6v62/ai_journal_machinedeepreinforcmeent_learning_nlp/,vector_machines,1525518350,,0,1
237,2018-5-5,2018,5,5,20,8h6ykw,Buildings are designed and manufactured to comply with the latest American design codes thus optimizing in order to suit customer's requirement. Visit: https://goo.gl/BwtMeS,https://www.reddit.com/r/MachineLearning/comments/8h6ykw/buildings_are_designed_and_manufactured_to_comply/,Supertech_India,1525519752,,0,1
238,2018-5-5,2018,5,5,21,8h7cji,Tensorflow tf.nn.sampled_softmax_loss gives unexpected results.,https://www.reddit.com/r/MachineLearning/comments/8h7cji/tensorflow_tfnnsampled_softmax_loss_gives/,LeftUnderstanding,1525524880,[removed],0,1
239,2018-5-5,2018,5,5,22,8h7eg0,tf.nn.sampled_softmax_loss gives unexpected result.,https://www.reddit.com/r/MachineLearning/comments/8h7eg0/tfnnsampled_softmax_loss_gives_unexpected_result/,LeftUnderstanding,1525525518,[removed],0,1
240,2018-5-5,2018,5,5,22,8h7hox,Linux Job schedulers?,https://www.reddit.com/r/MachineLearning/comments/8h7hox/linux_job_schedulers/,Simusid,1525526556,[removed],0,1
241,2018-5-5,2018,5,5,22,8h7n52,Request for help with medical images classification,https://www.reddit.com/r/MachineLearning/comments/8h7n52/request_for_help_with_medical_images/,giorgaros2,1525528318,[removed],0,1
242,2018-5-5,2018,5,5,23,8h7qcx,[D] Where to start with a part-time PhD in the UK?,https://www.reddit.com/r/MachineLearning/comments/8h7qcx/d_where_to_start_with_a_parttime_phd_in_the_uk/,cjmcmurtrie,1525529302,"I have a master's degree in machine learning \(UCL\) and have worked in a senior engineering position for a number of years. I want to take the step to begin a PhD in machine learning, while based working in London, UK.

On the other hand, I can neither afford to, neither want to stop working full\-time.

Anyone here have experience with a part\-time PhD programme? Which university departments in the UK are the most flexible in this respect? What are the draw\-backs of part\-timing? Who would you advise speaking to? What would be the first steps?",23,6
243,2018-5-6,2018,5,6,0,8h82l5,[D] Most accessible/easy way to make and train a neural network?,https://www.reddit.com/r/MachineLearning/comments/8h82l5/d_most_accessibleeasy_way_to_make_and_train_a/,13chaggit,1525532769,"I have a great idea for a neural network. One that takes a text string and the output of a smartphone's display as input, and outputs the direction that a cursor should move and if the click should be held down. I'd want to train the net on multiple mobile keyboards such as Gboard, Novakey, Dasher and 8pen to see how it performs.

Unfortunately, there is no easy way that I can find to create and train such a network. What is the easiest way to make a neural net?",9,0
244,2018-5-6,2018,5,6,0,8h85p8,Course by course review of University of Michigan's Applied Data Science with Python Coursera specialization,https://www.reddit.com/r/MachineLearning/comments/8h85p8/course_by_course_review_of_university_of/,wasabihater,1525533601,,0,1
245,2018-5-6,2018,5,6,0,8h8bfd,AI Weekly 5 May 2018,https://www.reddit.com/r/MachineLearning/comments/8h8bfd/ai_weekly_5_may_2018/,TomekB,1525535124,,0,1
246,2018-5-6,2018,5,6,1,8h8g75,"Saving, resuming, and restarting experiments with Polyaxon",https://www.reddit.com/r/MachineLearning/comments/8h8g75/saving_resuming_and_restarting_experiments_with/,mmourafiq,1525536386,,0,1
247,2018-5-6,2018,5,6,1,8h8nd5,Project,https://www.reddit.com/r/MachineLearning/comments/8h8nd5/project/,samar_syed,1525538198,[removed],0,1
248,2018-5-6,2018,5,6,1,8h8ndx,"[N] Facebook Adds A.I. Labs in Seattle and Pittsburgh, Pressuring Local Universities",https://www.reddit.com/r/MachineLearning/comments/8h8ndx/n_facebook_adds_ai_labs_in_seattle_and_pittsburgh/,downtownslim,1525538205,,70,134
249,2018-5-6,2018,5,6,2,8h8w2i,ML is Love.,https://www.reddit.com/r/MachineLearning/comments/8h8w2i/ml_is_love/,kushagra_bisen,1525540403,,0,1
250,2018-5-6,2018,5,6,3,8h9gza,Does anyone have opinions or experience with Algebraic Machine Learning? Seems interesting.,https://www.reddit.com/r/MachineLearning/comments/8h9gza/does_anyone_have_opinions_or_experience_with/,philosophist_,1525545729,,0,1
251,2018-5-6,2018,5,6,4,8h9m64,"How I Fail - Ian Goodfellow (PhD'14, Computer Science) | Veronika Cheplygina",https://www.reddit.com/r/MachineLearning/comments/8h9m64/how_i_fail_ian_goodfellow_phd14_computer_science/,sksq9,1525547047,,0,2
252,2018-5-6,2018,5,6,5,8ha9wh,"Working on a horror project that pair found images and machine learning. Struggling renderings, but I'm so happy with the result.",https://www.reddit.com/r/MachineLearning/comments/8ha9wh/working_on_a_horror_project_that_pair_found/,LetTheMiceFree,1525553035,,0,1
253,2018-5-6,2018,5,6,5,8haa4j,[R] (Azure ML) How to use historical data set for training and prospective data set as input for prediction,https://www.reddit.com/r/MachineLearning/comments/8haa4j/r_azure_ml_how_to_use_historical_data_set_for/,labinOL,1525553092,"

Background information: I did an Data Mining experiment where I used historical data of customer purchases as case table for my mining structure. The second data set (prospective buyers) is used for testing.

Now I want to implement the same scenario in Azure Machine Learning (Studio). However, I could not figure it out how I can use one data set to be used for training and a different data set to be used for testing.

Furthermore, I'd like to ask if it is possible to use a data set for training the model but after deploying the model to a web service, to limit the input fields to certain columns?

The historical data set contains 12 columns that I want to use for training the model. However, I want only 9 of those columns to be required as input when testing via the deployed model.

I hope I made myself clear and that everything is understandable. If not, please ask me anything you want.

Kind regards, lja",3,0
254,2018-5-6,2018,5,6,5,8hactr,Never thought this guy will take Machine learning this far,https://www.reddit.com/r/MachineLearning/comments/8hactr/never_thought_this_guy_will_take_machine_learning/,bbw_slayer,1525553811,,0,1
255,2018-5-6,2018,5,6,7,8hawh4,Postman API Network Exploration: Summarization and Twitter sentiment analysis,https://www.reddit.com/r/MachineLearning/comments/8hawh4/postman_api_network_exploration_summarization_and/,SummarizeDev,1525559125,,0,1
256,2018-5-6,2018,5,6,9,8hbq6g,Does anyone work on OpenDR or other quality differentiable renderer/engine? How you improve the visual effect in general?,https://www.reddit.com/r/MachineLearning/comments/8hbq6g/does_anyone_work_on_opendr_or_other_quality/,cfwang1987,1525567641,[removed],0,1
257,2018-5-6,2018,5,6,9,8hbr1b,[N] So What Was Up With Alexa's Creepy Laughter Anyway?,https://www.reddit.com/r/MachineLearning/comments/8hbr1b/n_so_what_was_up_with_alexas_creepy_laughter/,regalalgorithm,1525567902,,2,0
258,2018-5-6,2018,5,6,11,8hcbas,[D] [Question] Has anyone tried to use Vicarious Recursive Cortical Network for 3D computer vision?,https://www.reddit.com/r/MachineLearning/comments/8hcbas/d_question_has_anyone_tried_to_use_vicarious/,trenteady,1525574104,"Im a bit flummoxed by a recent discovery. The AI/robotics startup Vicarious has developed a new neural network architecture they call a Recursive Cortical Network (RCN). Vicarious used its RCN to solve CAPTCHAs with the same accuracy as a Google DeepMind convolutional neural network. Heres the kicker: **the RCN was trained on only 260 examples, versus 2.3 *million* for the ConvNet.** So thats a ~900,000% improvement in training data efficiency.

You can read about the RCN solving CAPTCHAs in Vicarious [blog post](https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/) on the matter, or you can read their paper in the journal [Science](http://science.sciencemag.org/content/358/6368/eaag2612.full?ijkey=DmvGldXIEXVoQ&amp;keytype=ref&amp;siteid=sci), if you have access. Vicarious also has a reference implementation of its RCN up on [GitHub](http://github.com/vicariousinc/science_rcn).

So, the RCN has achieved state-of-the-art accuracy on optical character recognition with ~900,000% better training data efficiency. **Heres my question: has anyone tried to adapt Vicarious reference implementation for 2D image classification or, most exciting of all, 3D computer vision?**

Im a lay enthusiast and CS 101 dropout, not a computer scientist or software engineer. So I dont have the ability to try this myself, or even the knowledge to say whether it would feasible to try. So apologies if this is a misconceived question.

But if I have not exceeded my depth here, this seems like such an exciting experiment. If the RCN can match the accuracy of state-of-the-art ConvNets not just on character recognition, but on object detection in a 3D environment, and do so after being trained on ~0.011% as many examples, imagine the possibilities. ",15,38
259,2018-5-6,2018,5,6,11,8hceqt,Need Open AI Gym (or similar) tutorial that isn't broken,https://www.reddit.com/r/MachineLearning/comments/8hceqt/need_open_ai_gym_or_similar_tutorial_that_isnt/,anonymous_yet_famous,1525575130,[removed],0,1
260,2018-5-6,2018,5,6,12,8hclih,The pleasure of stuff,https://www.reddit.com/r/MachineLearning/comments/8hclih/the_pleasure_of_stuff/,mugwit39,1525577170,[removed],0,1
261,2018-5-6,2018,5,6,13,8hcvfn,Ian Goodfellow - How I fail | Failure/Experiences,https://www.reddit.com/r/MachineLearning/comments/8hcvfn/ian_goodfellow_how_i_fail_failureexperiences/,vector_machines,1525580419,,0,2
262,2018-5-6,2018,5,6,13,8hcz61,[P] tensorscript: dependently-typed tensor computation that compiles to PyTorch and TensorFlow (Examples are under /examples directory) more information will follow,https://www.reddit.com/r/MachineLearning/comments/8hcz61/p_tensorscript_dependentlytyped_tensor/,0b01,1525581716,,3,12
263,2018-5-6,2018,5,6,14,8hdasd,[D] Artificial neurons based on direct modelling of observed correlations and predicting from them?,https://www.reddit.com/r/MachineLearning/comments/8hdasd/d_artificial_neurons_based_on_direct_modelling_of/,jarekduda,1525585915,,48,1
264,2018-5-6,2018,5,6,15,8hdby5,[D] Overview of Machine Learning for newcomers,https://www.reddit.com/r/MachineLearning/comments/8hdby5/d_overview_of_machine_learning_for_newcomers/,undefdev,1525586408,,52,1055
265,2018-5-6,2018,5,6,15,8hdgqw,AI researchers allege that machine learning is alchemy,https://www.reddit.com/r/MachineLearning/comments/8hdgqw/ai_researchers_allege_that_machine_learning_is/,trot-trot,1525588334,,0,1
266,2018-5-6,2018,5,6,15,8hdh0y,"Pyception - When your model isn't accurate enough, you've got to go deeper",https://www.reddit.com/r/MachineLearning/comments/8hdh0y/pyception_when_your_model_isnt_accurate_enough/,vector_machines,1525588450,,0,1
267,2018-5-6,2018,5,6,17,8hdwrj,[R] The Fine Line between Linguistic Generalization and Failure in Seq2Seq-Attention Models,https://www.reddit.com/r/MachineLearning/comments/8hdwrj/r_the_fine_line_between_linguistic_generalization/,kenb01,1525594897,,6,12
268,2018-5-6,2018,5,6,17,8hdxw5,Pornograhic image detection,https://www.reddit.com/r/MachineLearning/comments/8hdxw5/pornograhic_image_detection/,Vonleibricken,1525595345,[removed],0,1
269,2018-5-6,2018,5,6,19,8heb7u,Parallel-Data-Free Voice Conversion Using Cycle-Consistent Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/8heb7u/paralleldatafree_voice_conversion_using/,radenML,1525601328,,0,1
270,2018-5-6,2018,5,6,20,8hekzr,[D] Bayes error in the context of supervised learning,https://www.reddit.com/r/MachineLearning/comments/8hekzr/d_bayes_error_in_the_context_of_supervised/,jan_sv,1525605489,"I have a hard time intuitively understand the Bayer error in the context of supervised learning. We have an input X and an output Y. We want to find the function f(X) = Y.

I feel like I don't understand why we model X as a random variable in the first place. I think we construct the function f not based on the distribution of X but rather on actual values of X. Why should we care if X is stochastic or not?


Example I:  
Let's say X = [1,2,3], Y = [1,2,3] and f(x) = x.  
When X=1 =&gt; Y=1, X=2 =&gt; Y=2, X=3 =&gt; Y=3, I will never make an error.

Example II:   
Why should it be different if X = [picture of dog, picture of cat, picture of house] and Y = [dog, cat, house]. I can still find a function which does the mapping. It is obviously more complex but doable.

Where did the Bayes error get lost in my examples?  

I am looking for an intuitive explanation of the Bayes error preferably in the context of image classification.",4,0
271,2018-5-6,2018,5,6,21,8hew8l,Hierarchical Density Order Embeddings,https://www.reddit.com/r/MachineLearning/comments/8hew8l/hierarchical_density_order_embeddings/,aviniumau,1525609894,,0,1
272,2018-5-6,2018,5,6,22,8hf225,Factor Analysis And Its Applications | Understanding Factor Analysis,https://www.reddit.com/r/MachineLearning/comments/8hf225/factor_analysis_and_its_applications/,LearningFromData,1525611872,,0,1
273,2018-5-6,2018,5,6,22,8hf9ln,[R] Parallel-Data-Free Voice Conversion Using Cycle-Consistent Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/8hf9ln/r_paralleldatafree_voice_conversion_using/,radenML,1525614286,,0,3
274,2018-5-6,2018,5,6,22,8hfa4y,"What is some software that takes my favourites, files, and/or email and categorizes them into different area of interests?",https://www.reddit.com/r/MachineLearning/comments/8hfa4y/what_is_some_software_that_takes_my_favourites/,Italian_Nerd,1525614451,,0,1
275,2018-5-6,2018,5,6,23,8hfmf2,[D] Papers explaining why Teacher-Student training and Knowledge Distillation work?,https://www.reddit.com/r/MachineLearning/comments/8hfmf2/d_papers_explaining_why_teacherstudent_training/,radenML,1525617870,"I seen many papers related to Teacher-Student Training (Caruana) Dark Knowledge and Distillation (Hinton).
Is there theoretical analysis with math why this method works?",3,6
276,2018-5-6,2018,5,6,23,8hfoai,[D] How should I approach the problem of data deduplication on a massive database?,https://www.reddit.com/r/MachineLearning/comments/8hfoai/d_how_should_i_approach_the_problem_of_data/,lebron_lamase,1525618364,"I have a few millions of records on a NoSQL database, It's something like a product catalog so the number of fields in each record is not uniform. For example, two records of the same prodcut (like a bicycle) may have different lengths of fields.

I want to find which ones are similar so that I can apply my own criteria (say, the older/newer entry is the original) to remove the duplicate. I found the dedupe python library but it doesn't seem to be suitable for this task, I'm very confused now.",2,0
277,2018-5-7,2018,5,7,0,8hfrsp,New Theory Cracks Open the Black Box of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8hfrsp/new_theory_cracks_open_the_black_box_of_deep/,ThisToni,1525619232,,0,1
278,2018-5-7,2018,5,7,0,8hftb2,How would you use ML to discover what is causing a trend?,https://www.reddit.com/r/MachineLearning/comments/8hftb2/how_would_you_use_ml_to_discover_what_is_causing/,pheeper,1525619616,[removed],0,1
279,2018-5-7,2018,5,7,0,8hg34o,See poll in top level comment to generate data for this problem.,https://www.reddit.com/r/MachineLearning/comments/8hg34o/see_poll_in_top_level_comment_to_generate_data/,SyAbleton,1525622018,,1,1
280,2018-5-7,2018,5,7,1,8hgidz,[P] Gender classification model using convolutional neural network,https://www.reddit.com/r/MachineLearning/comments/8hgidz/p_gender_classification_model_using_convolutional/,csyrup,1525625700,,5,1
281,2018-5-7,2018,5,7,2,8hgoyx,An algorithm is spotting heart problems better than an expert doctor,https://www.reddit.com/r/MachineLearning/comments/8hgoyx/an_algorithm_is_spotting_heart_problems_better/,ThisToni,1525627230,,0,1
282,2018-5-7,2018,5,7,3,8hh48u,What's the difference between ICML and NIPS these days?,https://www.reddit.com/r/MachineLearning/comments/8hh48u/whats_the_difference_between_icml_and_nips_these/,FirstTimeResearcher,1525630823,[removed],0,1
283,2018-5-7,2018,5,7,3,8hh4jz,[R] What's the difference between ICML and NIPS these days?,https://www.reddit.com/r/MachineLearning/comments/8hh4jz/r_whats_the_difference_between_icml_and_nips/,FirstTimeResearcher,1525630893,When is it appropriate to submit to one and not the other?,5,9
284,2018-5-7,2018,5,7,3,8hhcx4,[R][Neuroscience] Emergence of grid-like representations by training recurrent neural networks to perform spatial localization,https://www.reddit.com/r/MachineLearning/comments/8hhcx4/rneuroscience_emergence_of_gridlike/,downtownslim,1525632862,,1,13
285,2018-5-7,2018,5,7,4,8hhrkx,[N] PyTorch-NLP 0.3.0 Release,https://www.reddit.com/r/MachineLearning/comments/8hhrkx/n_pytorchnlp_030_release/,Deepblue129,1525636303,,0,4
286,2018-5-7,2018,5,7,4,8hhs2n,Reduced order models,https://www.reddit.com/r/MachineLearning/comments/8hhs2n/reduced_order_models/,Bb415bm,1525636428,[removed],0,1
287,2018-5-7,2018,5,7,6,8hi9ey,Help me buy a course from Coursera?,https://www.reddit.com/r/MachineLearning/comments/8hi9ey/help_me_buy_a_course_from_coursera/,DZAID_M,1525640624,I am a student I cannot buy it. it cost 79$ the course is Machine learning by Andrew Ng. I've completed the course with 95%.,0,1
288,2018-5-7,2018,5,7,6,8hilb4,[D][Question] Finetuning models for Speech Recognition with rare vocabulary,https://www.reddit.com/r/MachineLearning/comments/8hilb4/dquestion_finetuning_models_for_speech/,NotANeuralNetwork,1525643616,"For my research,I'm currently building models that can do Speech Recognition on data scraped from multiple radio communication channels. In this domain, audio quality is very noisy, speakers speak very fast and they use multiple codewords that are very rare on other contexts. Finally, it is fairly expensive to manually label this data, so I have a fairly small set of labels.I'm currently looking to finetune some existing model for this problem. 

My question is: What would be some of the least data intensive ways to finetune a model on this kind of dataset. Do you guys know of any approaches that could be useful in this domain? 

Thanks a lot!",3,2
289,2018-5-7,2018,5,7,7,8hip2d,[D] Clustering when using an asymmetric distance function.,https://www.reddit.com/r/MachineLearning/comments/8hip2d/d_clustering_when_using_an_asymmetric_distance/,texinxin,1525644522,"
Background

1. My team's goal is to generate an algorithm that will find similar recipes.  Recipes for what aren't that important.  But know that there are tolerances on the ingredients of the recipe (continuous 0 to 1 variables representing the percentage range of each ingredient).  Some recipes are 'stricter' than others.  Therefore, when we try to compare recipes, and you compare one direction you get a different similarity score than the opposite direction.  So, 'A' recipe when executed will make something you can call 'B'.  But when you follow 'B's recipe, it doesn't necessarily make something you can call 'A'.
2.  This has resulted in the creation of a very custom asymmetric distance function.  What has finally worked very well for us is a normalized Manhattan.  The 'seed' recipe for distance calculation is normalized by factors until it is essentially a unit vector for the ingredients it calls for.  These scaling factors are used on the 'target' candidates to calculate the Manhattan distance.  Ingredients present in the target that aren't in the seed are not scaled, purposefully.  These allow the 'picky' recipes to be fuzzy matches when using a 'non-picky' 'seed' recipe.  But if you reverse them, the 'picky' recipe would result in scaling the 'non-picky' recipe further away.  This is also working great.
3. We have ~50,000 recipes with up to about 40 possible ingredients.  Each recipe can use from 1 to about 10 maximum ingredients.  Each ingredient has a min and a max.
4.  Brute force of this would require N^2 calculations and a full matrix (not triangular, due to the asymmetry) .... unless someone has some brilliant other idea to help us.  If we don't have a trick, we can brute force this in about 30 minutes of run time and we don't have to do it that often (daily-weekly), so we're OK with this.

The issues we have are...

1.  Bringing this matrix into a front end application is painful at 50K X 50K.  One solution is to cut the matrix to simply 1's or NA's by applying distance criteria.  Then we can use sparse matrix techniques to collapse it to a very small and fast model.

2.  Ultimately one day the users will be able to create variations of the seed recipes to find similar ones on the fly.  So that will kill the sparse matrix concept.

Soo... we have 2 paths we are working on.  One is using dynamic filters around the 'seed' part, so we can brute force the distance search 'on the fly' in the client.  It also requires a fairly large matrix because you have to bring all of the ingredients of all possible recipes in session.. which is pretty heavy.  We think it will work though.. it will just require a few seconds to load into the client.

But, we also want to explore a clustering approach.  It is for more than speed we want to explore clustering.  It will also help the users find the recipe they are looking for.  The clusters can provide a catalog and the ability to navigate to find the specific recipe they need without scrolling through a very hard to read list of 50,000 recipes to read.

So, how do we cluster?  We're looking for a R or Python library that can support a custom distance function... or one that can read a matrix with pre-populated asymmetric distances.

We don't mind if the clusters are 'fuzzy' or 'overlapping'.


Any projects or papers that discuss this would be helpful as well.

I've found this one:

[Assymetric Distances..](http://www.pszw.edu.pl/images/publikacje/t031_pszw_2010_owsinski_-_asymmetric_distances_potential_output_structures_and_procedures.pdf)

But found it to be too academic and a bit dated..


Any thoughts on the above challenge, or recommendations about any of it?",2,2
290,2018-5-7,2018,5,7,7,8hiudj,[P] An examination of Austin's shared bike program,https://www.reddit.com/r/MachineLearning/comments/8hiudj/p_an_examination_of_austins_shared_bike_program/,the_abusement_park,1525645859,,0,2
291,2018-5-7,2018,5,7,7,8hivqd,Deep neural network learning in seconds,https://www.reddit.com/r/MachineLearning/comments/8hivqd/deep_neural_network_learning_in_seconds/,rkoshlyak,1525646222,[removed],0,1
292,2018-5-7,2018,5,7,7,8hj0fo,[D] MICCAI 2018 post review and rebuttal,https://www.reddit.com/r/MachineLearning/comments/8hj0fo/d_miccai_2018_post_review_and_rebuttal/,getdem,1525647496,"Just thought this could be a good place to discuss the reviews and rebuttal stage of MICCAI. What do you think of this year's review process? What is your experience with rebuttal? I'm curious how this may, or may not, push a paper into accept.",22,6
293,2018-5-7,2018,5,7,7,8hj0ly,"[D] Programs to consider after rejection for AI residency programs, such Insight AI Fellow and Fellowship AI ?",https://www.reddit.com/r/MachineLearning/comments/8hj0ly/d_programs_to_consider_after_rejection_for_ai/,DisastrousProgrammer,1525647547,"I didn't make it into any of the big AI residency programs (Google brain, FAIR, NERD, Uber, etc.) 

The next tier seems to be Insight AI Fellow and Fellowship AI. Are there any other programs similar to those? Neither of those seems to offer any compensation, so I have also been thinking about smaller companies that do AI stuff and asking if I could just work for minimum wage. 

Thoughts? ",13,8
294,2018-5-7,2018,5,7,8,8hj2cf,Chatbot Tutorial | AI in Marketing,https://www.reddit.com/r/MachineLearning/comments/8hj2cf/chatbot_tutorial_ai_in_marketing/,funmaster11,1525648002,,0,1
295,2018-5-7,2018,5,7,9,8hjq8c,Actuary to machine learning?,https://www.reddit.com/r/MachineLearning/comments/8hjq8c/actuary_to_machine_learning/,ac2uary,1525654712,[removed],0,1
296,2018-5-7,2018,5,7,10,8hjyhg,"[D] Crisp Codes and Theory 1: Journey of tagging words(NLP), Feature Engineering and Image Segmentation.",https://www.reddit.com/r/MachineLearning/comments/8hjyhg/d_crisp_codes_and_theory_1_journey_of_tagging/,jaleyhd,1525657073,,0,12
297,2018-5-7,2018,5,7,10,8hk19n,[D] How I Fail - Ian Goodfellow,https://www.reddit.com/r/MachineLearning/comments/8hk19n/d_how_i_fail_ian_goodfellow/,galapag0,1525657849,,36,325
298,2018-5-7,2018,5,7,11,8hk9ga,[News] China brings AI to high school curriculum,https://www.reddit.com/r/MachineLearning/comments/8hk9ga/news_china_brings_ai_to_high_school_curriculum/,mimighost,1525660128,,46,204
299,2018-5-7,2018,5,7,12,8hkkqh,"I barely know what I'm talking about, but let me bounce an idea: fractal neural networks.",https://www.reddit.com/r/MachineLearning/comments/8hkkqh/i_barely_know_what_im_talking_about_but_let_me/,PianoMastR64,1525663472,"Imagine a simple neural network with simple or complex inputs and outputs. Then string these NNs together in a way where each one is behaving as a neuron for a larger order NN.

Yes?",0,1
300,2018-5-7,2018,5,7,13,8hkrdz,Reinforcement Learning - Introduction to K-armed Bandits,https://www.reddit.com/r/MachineLearning/comments/8hkrdz/reinforcement_learning_introduction_to_karmed/,OneRaynyDay,1525665605,,0,1
301,2018-5-7,2018,5,7,13,8hkuej,"Deep Learning from first principles in Python, R and Octave  Part 8",https://www.reddit.com/r/MachineLearning/comments/8hkuej/deep_learning_from_first_principles_in_python_r/,tvganesh,1525666556,,0,1
302,2018-5-7,2018,5,7,13,8hl0on,[D] Forcing an orthogonal transformation as the weight matrix.,https://www.reddit.com/r/MachineLearning/comments/8hl0on/d_forcing_an_orthogonal_transformation_as_the/,Jemmaz,1525668733,"Let's say you want a fully connected layer that has an orthogonal transformation (followed by some arbitrary non-linearity).


So you want to force the weight matrix to be orthogonal, those only have n(n-1)/2 degrees of freedom which means those are how many underlying variables such n^2 weight matrix must have. But how would you express this as code for say, pytorch?


How to code the n(n-1)/2 -&gt; n^2 transformation for gradient flow? Basically the gradients would flow into the n^2 parameters as usual but those parameters are no longer free, they are the result of some other n(n-1)/2 parameters into which the gradients would flow.



I'm aware that you can impose a W * W^T - I = 0 penalty to approximate this goal but I'm looking for the straight forward non approximate method.",12,4
303,2018-5-7,2018,5,7,14,8hl3hj,[D] How does a Self-organizing map reduce dimensions?,https://www.reddit.com/r/MachineLearning/comments/8hl3hj/d_how_does_a_selforganizing_map_reduce_dimensions/,Athlon77,1525669705,"I've read up on how SOMs basically work and I understand the learning algorithm. But the papers I've read also mention that SOMs can be a tool for dimension reduction. I don't understand how, could someone explain?",3,2
304,2018-5-7,2018,5,7,14,8hlb3w,[N] AVBytes: AI &amp; ML Developments in the week of Apr 30,https://www.reddit.com/r/MachineLearning/comments/8hlb3w/n_avbytes_ai_ml_developments_in_the_week_of_apr_30/,jalFaizy,1525672396,[removed],0,1
305,2018-5-7,2018,5,7,15,8hlha5,[P] Announcing the Twitter bot version of Dragonfire open-source virtual assistant,https://www.reddit.com/r/MachineLearning/comments/8hlha5/p_announcing_the_twitter_bot_version_of/,mertyildiran,1525674694,,1,0
306,2018-5-7,2018,5,7,16,8hlnxt,[D] KDD 2018 reviews,https://www.reddit.com/r/MachineLearning/comments/8hlnxt/d_kdd_2018_reviews/,olBaa,1525677272,"Even though it is not the main conference for the sub, what was your experience?",14,7
307,2018-5-7,2018,5,7,16,8hluoh,[R] AI researchers allege that machine learning is alchemy,https://www.reddit.com/r/MachineLearning/comments/8hluoh/r_ai_researchers_allege_that_machine_learning_is/,molode,1525679957,,0,1
308,2018-5-7,2018,5,7,17,8hlvmd,[N] How to Develop a Currency Detection Model using Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8hlvmd/n_how_to_develop_a_currency_detection_model_using/,trumtra,1525680324,,0,1
309,2018-5-7,2018,5,7,17,8hlwjn,[R] Statistics Books for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8hlwjn/r_statistics_books_for_machine_learning/,chris_shpak,1525680682,,0,1
310,2018-5-7,2018,5,7,17,8hm21y,Lifted Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8hm21y/lifted_neural_networks/,statmlsn,1525682966,,0,1
311,2018-5-7,2018,5,7,18,8hm5bq,"My first nueral network. Text generator for Twitter, trained on Donald Trump's tweets dataset. (Tensorflow)",https://www.reddit.com/r/MachineLearning/comments/8hm5bq/my_first_nueral_network_text_generator_for/,RiggerRyan,1525684270,,0,1
312,2018-5-7,2018,5,7,18,8hm7by,[D] Computational Intelligence exam is in a month and I'm shitting bricks.,https://www.reddit.com/r/MachineLearning/comments/8hm7by/d_computational_intelligence_exam_is_in_a_month/,nofaceD3,1525685058,"Hi all


I'm doing master of IT. I was interested in learning about AI so I took Computational intelligence course in my 1st semester. Thing is professor can't speak English. He starts a sentence and break it off and start a new one. He cannot form a proper sentence in English. Also, he speaks with a heavy Chinese accent. I have attended all his class but still I can't understand anything.

I don't know how to study this subject. I tried reading the book that is assigned to this course but no avail. I'm trying to find any lectures online but I'm not able to find anything.

Here is the syllabus of CI:

* Linear/Multiple Regression
* Fuzzy Logic and Fuzzy Inference
* Fuzzy rules extraction from numerical data
* Neural Network with BP algorithm.
* Hybrid Intelligent System
* Neural Network with Random Weight
* Deep Learning Basics

If anybody can help with this or link me online resources (video, articles anything) or just guide me right direction I would be really grateful. I really want to learn Computational Intelligence. ",6,0
313,2018-5-7,2018,5,7,18,8hm8e5,Visualizing change in weight vector of perceptrons learning to classify handwritten digits,https://www.reddit.com/r/MachineLearning/comments/8hm8e5/visualizing_change_in_weight_vector_of/,sigsegvxyz,1525685481,,0,1
314,2018-5-7,2018,5,7,18,8hma6t,Visualizing change in weight vector of perceptrons learning to classify handwritten digits,https://www.reddit.com/r/MachineLearning/comments/8hma6t/visualizing_change_in_weight_vector_of/,sigsegvxyz,1525686198,,0,1
315,2018-5-7,2018,5,7,18,8hmbtc,[Project] Visualizing change in weight vector of perceptrons learning to classify handwritten digits,https://www.reddit.com/r/MachineLearning/comments/8hmbtc/project_visualizing_change_in_weight_vector_of/,sigsegvxyz,1525686858,,0,1
316,2018-5-7,2018,5,7,18,8hmc78,Machine Learning Redefines the Way Machines Work with You,https://www.reddit.com/r/MachineLearning/comments/8hmc78/machine_learning_redefines_the_way_machines_work/,weblineindia-com,1525687009,,0,3
317,2018-5-7,2018,5,7,19,8hmk3p,Video analysis : what should we consider as interesting features apart from spatio-temporal features ?,https://www.reddit.com/r/MachineLearning/comments/8hmk3p/video_analysis_what_should_we_consider_as/,DevilPenber,1525689878,[removed],0,1
318,2018-5-7,2018,5,7,19,8hmlxc,[D] ML in Advertising/Marketing/Retail/E-commerce,https://www.reddit.com/r/MachineLearning/comments/8hmlxc/d_ml_in_advertisingmarketingretailecommerce/,Teoretic6,1525690523,,0,0
319,2018-5-7,2018,5,7,20,8hmmsb,"[D] How to Train your Own Model with NLTK and Stanford NER Tagger? (for English, French, German)",https://www.reddit.com/r/MachineLearning/comments/8hmmsb/d_how_to_train_your_own_model_with_nltk_and/,charlesBochet,1525690822,,1,7
320,2018-5-7,2018,5,7,21,8hmyo3,Reinforcement Learning with Multi Arm Bandit,https://www.reddit.com/r/MachineLearning/comments/8hmyo3/reinforcement_learning_with_multi_arm_bandit/,kiarash-irandoust,1525694611,,0,1
321,2018-5-7,2018,5,7,21,8hn091,[P] Data Augmentation for Image Classification with PyTorch and imgaug - Tutorial with Google Colab link,https://www.reddit.com/r/MachineLearning/comments/8hn091/p_data_augmentation_for_image_classification_with/,fabioperez,1525695076,,3,13
322,2018-5-7,2018,5,7,21,8hn0qh,Reinforcement Learning with Multi Arm Bandit,https://www.reddit.com/r/MachineLearning/comments/8hn0qh/reinforcement_learning_with_multi_arm_bandit/,Fewthp,1525695222,,0,3
323,2018-5-7,2018,5,7,21,8hn36y,Moving beyond mission in the purpose-driven economy,https://www.reddit.com/r/MachineLearning/comments/8hn36y/moving_beyond_mission_in_the_purposedriven_economy/,Gloria_Joyce,1525695950,,0,1
324,2018-5-7,2018,5,7,21,8hn7s4,Reinforcement Learning - Introduction to k-Armed Bandits (Trending on hackernews),https://www.reddit.com/r/MachineLearning/comments/8hn7s4/reinforcement_learning_introduction_to_karmed/,OneRaynyDay,1525697225,,0,1
325,2018-5-7,2018,5,7,22,8hnbc4,[P] Benchmark: Scaling TensorFlow model serving using Vespa,https://www.reddit.com/r/MachineLearning/comments/8hnbc4/p_benchmark_scaling_tensorflow_model_serving/,RealJon,1525698167,,0,3
326,2018-5-7,2018,5,7,22,8hnbx3,"[N] Einsum, Magenta.js, ML Debiasing, Tensorflow 1.8.0, The Gradient, MLPerf, Sarcasm Detection, Fast.ai loves PyTorch, Word Morphing,",https://www.reddit.com/r/MachineLearning/comments/8hnbx3/n_einsum_magentajs_ml_debiasing_tensorflow_180/,omarsar,1525698319,,0,0
327,2018-5-7,2018,5,7,22,8hncoz,[R] Deep Learning and Time To Predict Emojis,https://www.reddit.com/r/MachineLearning/comments/8hncoz/r_deep_learning_and_time_to_predict_emojis/,omarsar,1525698507,,0,0
328,2018-5-7,2018,5,7,22,8hni4s,"[D] Given all the randomness, how to compare results in experiments with DNNs?",https://www.reddit.com/r/MachineLearning/comments/8hni4s/d_given_all_the_randomness_how_to_compare_results/,fabioperez,1525699911,"Training a DNN has several random factors (weights initialization, online data augmentation, mini-batch sampling, Dropout etc.). Each time you train a DNN, you will get different weights (unless you are extremely careful with setting the RNG seed for every part of your code).

Knowing that, two trainings with the same hyperparameters can have different outcomes with significant differences in the validation/testing metrics.

In scientific research, we want to be able to compare different experiments by varying some factors to check the influence of those factors in a final outcome. How do we achieve that given that DNNs are affected by randomness?

One solution is to run an experiment several times and use the mean and variance of the desired metric. However, DNNs are slow to train. I believe this was done by [*How transferable are features in deep neural networks?*](http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf)

Another ""solution"" is to fix the RNG seeds to make the training deterministic, but I believe this will probably benefit one of the configurations. 

How can we trust papers that compare different settings in highly random environments? How can we create experiments that take all the randomness into account?",2,1
329,2018-5-7,2018,5,7,22,8hnm36,How to Segment Image-Pixels using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8hnm36/how_to_segment_imagepixels_using_deep_learning/,nanonets,1525700904,,0,1
330,2018-5-7,2018,5,7,22,8hnmtz,Active Learning: Optimization != Improvement,https://www.reddit.com/r/MachineLearning/comments/8hnmtz/active_learning_optimization_improvement/,TalkingJellyFish,1525701093,,0,1
331,2018-5-7,2018,5,7,23,8hnreq,[N] The Business Process Intelligence Challenge (BPIC) 2018,https://www.reddit.com/r/MachineLearning/comments/8hnreq/n_the_business_process_intelligence_challenge/,TaXxER,1525702210,"The Business Process Intelligence Challenge (BPIC) is a yearly challenge where real-life event data from executions of a business process of a company are made available to be analyzed with any technique available. The task is to make recommendations to the company based on your findings in their data, and write down your findings in a consulting-style report. Winning submissions get a paid trip to Sydney, Australia, to present their findings at the International Workshop on Business Process Intelligence, which is co-organized with the International Conference on Business Process Management. This year, the challenge is particularly interesting for /r/MachineLearning, since the challenge this year involves a supervised learning task: the company would like to predict as early as possible whether a running instance of their business process will result in a positive outcome, or in a negative outcome. This makes the challenge this year an early sequence classification task.

More information on the official website: http://www.win.tue.nl/bpi/doku.php?id=2018:challenge",6,0
332,2018-5-7,2018,5,7,23,8hns8g,TF-REX: AI Learns to play Google Chrome's T-rex game with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/8hns8g/tfrex_ai_learns_to_play_google_chromes_trex_game/,don-vingo,1525702393,[removed],0,1
333,2018-5-7,2018,5,7,23,8hnu8z,Identifying places where I can attain karma,https://www.reddit.com/r/MachineLearning/comments/8hnu8z/identifying_places_where_i_can_attain_karma/,Stone_d_,1525702831,[removed],0,1
334,2018-5-7,2018,5,7,23,8hnxq8,What do you think about Siraj Raval's habit of copying other people's code and presenting as his own?,https://www.reddit.com/r/MachineLearning/comments/8hnxq8/what_do_you_think_about_siraj_ravals_habit_of/,agoodlookinglamp,1525703604,[removed],0,1
335,2018-5-7,2018,5,7,23,8ho39v,[Grad studies] Finding ML graduate programs around the world,https://www.reddit.com/r/MachineLearning/comments/8ho39v/grad_studies_finding_ml_graduate_programs_around/,gumgumwot,1525704898,[removed],0,1
336,2018-5-8,2018,5,8,0,8ho64y,How to read the stride between convolution filters out of scientific papers?,https://www.reddit.com/r/MachineLearning/comments/8ho64y/how_to_read_the_stride_between_convolution/,string111,1525705538,[removed],0,1
337,2018-5-8,2018,5,8,0,8ho6aa,Does Ian GoodFellow (and the like) wasted time while coming through the ranks in their careers?,https://www.reddit.com/r/MachineLearning/comments/8ho6aa/does_ian_goodfellow_and_the_like_wasted_time/,MuhammadAliCassius,1525705572,[removed],0,1
338,2018-5-8,2018,5,8,0,8ho6hu,"Building Data Science Capabilities That Scale - Webinar with DataScience.com founder, Ian Swanson",https://www.reddit.com/r/MachineLearning/comments/8ho6hu/building_data_science_capabilities_that_scale/,TheDataIncubator,1525705609,,0,1
339,2018-5-8,2018,5,8,0,8hoaxd,The Third Wave of AI,https://www.reddit.com/r/MachineLearning/comments/8hoaxd/the_third_wave_of_ai/,AigoToken,1525706586,,0,1
340,2018-5-8,2018,5,8,1,8hoohc,"Boss wants me to implement machine learning into data analytics at work....what is a good book to get started?? (This is a new job, I have little data work and even less for machine learning!)",https://www.reddit.com/r/MachineLearning/comments/8hoohc/boss_wants_me_to_implement_machine_learning_into/,DoctorQuinlan,1525709532,[removed],0,1
341,2018-5-8,2018,5,8,1,8hou0b,Are the residual connections essentially deterministic leaky dropout layers?,https://www.reddit.com/r/MachineLearning/comments/8hou0b/are_the_residual_connections_essentially/,marcinola,1525710712,[removed],0,1
342,2018-5-8,2018,5,8,2,8hp1x5,[P] Reinforcement Learning for the Game of Splendor,https://www.reddit.com/r/MachineLearning/comments/8hp1x5/p_reinforcement_learning_for_the_game_of_splendor/,antirabbit,1525712427,,10,7
343,2018-5-8,2018,5,8,2,8hp91g,using machine learning to predict outcomes for sepsis patients,https://www.reddit.com/r/MachineLearning/comments/8hp91g/using_machine_learning_to_predict_outcomes_for/,alexa_y,1525713951,,0,1
344,2018-5-8,2018,5,8,2,8hp9mn,"[D] Roger Grosse: ""With the recent focus on reproducibility in deep learning, I wonder if there's really just one lab we should be calling out.""",https://www.reddit.com/r/MachineLearning/comments/8hp9mn/d_roger_grosse_with_the_recent_focus_on/,JustMadeItForTheJoke,1525714081,,30,13
345,2018-5-8,2018,5,8,2,8hpa5c,Parallele neuronale Netze,https://www.reddit.com/r/MachineLearning/comments/8hpa5c/parallele_neuronale_netze/,SAO-Ryujin,1525714195,"Ich schreibe auf deutsch da mein Englisch nicht so gut ist und ich hoffe das es zumindest ein paar Leute gibt die mich verstehen.
Ich habe gestern neuronale Netze in Abhngigkeit von verschiedenen Faktoren wie zb die Anzahl der versteckten Knoten am Beispiel einer Buchstabenerkennung getestet. Dabei bin ich auf die Idee gekommen mehrere zb 3 neuronale Netze mit verschieden Konfiguration die in den Tests gut abschneiden parallel testen und sich gegenseitig verstrken zu lassen. Also wenn 2 der 3 Netze einen Buchstaben erkennen gewinnt die Mehrheit. Ich habe im Internet nach berichten zu diesem Ansatz gesucht aber nichts gefunden. Knnte mir jemand die vor und Nachteile erklren und Mglichkeiten nennen?",0,1
346,2018-5-8,2018,5,8,2,8hpadk,Neural networks vs support vector machines?,https://www.reddit.com/r/MachineLearning/comments/8hpadk/neural_networks_vs_support_vector_machines/,Fracca94,1525714248,[removed],0,1
347,2018-5-8,2018,5,8,2,8hph9i,50+ Useful Machine Learning Prediction APIs,https://www.reddit.com/r/MachineLearning/comments/8hph9i/50_useful_machine_learning_prediction_apis/,gagejustins,1525715690,,0,1
348,2018-5-8,2018,5,8,3,8hpmkj,Hyper-parameter Optimisation in Cpp?,https://www.reddit.com/r/MachineLearning/comments/8hpmkj/hyperparameter_optimisation_in_cpp/,liftoff01,1525716843,[removed],0,1
349,2018-5-8,2018,5,8,3,8hpmob,Create endless runner in unity (ML-Agent),https://www.reddit.com/r/MachineLearning/comments/8hpmob/create_endless_runner_in_unity_mlagent/,nov_ale,1525716862,[removed],0,1
350,2018-5-8,2018,5,8,3,8hpn6h,Andrew Ng is back,https://www.reddit.com/r/MachineLearning/comments/8hpn6h/andrew_ng_is_back/,joymoyroy,1525716970,,0,1
351,2018-5-8,2018,5,8,3,8hppkp,[P] Generating Pusheen with GANs,https://www.reddit.com/r/MachineLearning/comments/8hppkp/p_generating_pusheen_with_gans/,znado,1525717499,,32,298
352,2018-5-8,2018,5,8,3,8hptb4,[D] How to use Amazon EC2 Spot Instances for Deep Learning and not get insane. With an introduction of an open-source automation tool dedicated for that.,https://www.reddit.com/r/MachineLearning/comments/8hptb4/d_how_to_use_amazon_ec2_spot_instances_for_deep/,Coderik,1525718284,,0,10
353,2018-5-8,2018,5,8,4,8hqdcp,[D] Identifying problems where ML will not work,https://www.reddit.com/r/MachineLearning/comments/8hqdcp/d_identifying_problems_where_ml_will_not_work/,waiting4omscs,1525722453,"Is there a guideline for identifying problems that cannot be solved by machine learning? Or steps to take that generally give you the idea that the data you have cannot model your desired outcome?

I am working for a client that has a huge database for forms processing. Because of the mass amount of data, they see many possibilities on what can be classified/predicted. The first issue we're running into is that the subject matter experts have a first project in mind, but are not sure what features might be relevant. In the experiments so far, we've run through a number of features but none have shown much predictive power. 

How do we know when to give up?",30,12
354,2018-5-8,2018,5,8,5,8hqsm9,[D] Using a LSTM to generate your next startup name,https://www.reddit.com/r/MachineLearning/comments/8hqsm9/d_using_a_lstm_to_generate_your_next_startup_name/,Paletton,1525725561,,2,0
355,2018-5-8,2018,5,8,5,8hqubr,[P]Gathering Data for Our App,https://www.reddit.com/r/MachineLearning/comments/8hqubr/pgathering_data_for_our_app/,habitapp,1525725909,"r/MachineLearning,

Im Ben from the Hab.it app team. Hab.it is a data\-driven calendar app that learns its users schedule to help keep them organized/productive. We are looking for participants who already use a scheduling platform such as Todoist, Google Calendar, etc. to send us a log of their schedule for the past few months, so that we can train our algorithm on a larger dataset. If this sort of project is something that you would like to support here is how you can submit:

1. Export your calendar, follow the steps below depending on which calendar type you use.
   1. Google Calendar: Follow this [link](https://calendar.google.com/calendar/r/settings/export?pli=1) to export your google calendar to a .zip file. It may take some time for google to prep this file for download. 
   2. Todoist: Follow this [link](https://support.todoist.com/hc/en-us/articles/115001799989-Backups) to export your todoist as a .csv file. \(Note: You can only do this as a Todoist premium/business member. 
   3. ICloud Calendar: Follow this [link](https://support.apple.com/guide/calendar/import-or-export-calendars-icl1023/mac) and select the export a calendars events option.
   4. Other: Most Calendar apps have guides on how to export their calendar events. 
2. Open the exported calendar that you intend on submitting and ensure that your calendar does not contain any data you would not like to submit \(i.e. personal info\). 
3. Attach your exported calendar file to an email to the address linked in our bio. If you would like to see our schedule predictions, let us know in your email and we will contact you when we have fitted a model to your data.

Note that if you wish to participate but are worried about your privacy you can use a disposable email rather than your personal to send us your calendar. \([GuerillaMail](https://www.guerrillamail.com/compose) is a great resource for this\).

If you have any questions feel free to PM us. If you are otherwise interested in the work done at Hab.it, you can email me personally at [benbilhorn@habitapp.us](mailto:benbilhorn@habitapp.us) or email [support@habitapp.us](mailto:support@habitapp.us) with ""subscribe"" as the subject to subscribe to our mailing list.

Thank you for your time,

Ben &amp; The Hab.it app team",0,0
356,2018-5-8,2018,5,8,5,8hqxq3,[D] How much easier does it need to be to build and train models?,https://www.reddit.com/r/MachineLearning/comments/8hqxq3/d_how_much_easier_does_it_need_to_be_to_build_and/,onedeskover,1525726629,"It seems like there are a whole bunch of interactive / visual programming tools popping up for machine and deep learing. Deep Cognition and [Lobe.ai](https://Lobe.ai) both come to time. Google's got AutoML, AWS has SageMake, IBM has Watson Studio.

All of these tools seem to be aimed at lowering the bar for the amount of effort required to train a model to do a specific task. Given where various ML frameworks are today, how do people think about these more cookie cutter tools? Are they helpful? Dangerous? A stepping stone for someone to start learning before diving into code?",3,2
357,2018-5-8,2018,5,8,6,8hqzc4,[R][Computer Vision] Detecting Decision Ambiguity from Facial Images,https://www.reddit.com/r/MachineLearning/comments/8hqzc4/rcomputer_vision_detecting_decision_ambiguity/,Goron97,1525726957,,0,7
358,2018-5-8,2018,5,8,7,8hrfb4,[P] Implementation of Conditional WGAN and WGAN in pytorch,https://www.reddit.com/r/MachineLearning/comments/8hrfb4/p_implementation_of_conditional_wgan_and_wgan_in/,vic4ever,1525730478,"Hi /r/MachineLearning,

This is our implementation of Conditional improved WGAN and improved WGAN in pytorch. [https://github.com/jalola/improved\-wgan\-pytorch](https://github.com/jalola/improved-wgan-pytorch)

Since this is our first\-time working on GANs, it is harder than we thought. Although the reference code are already available \([caogang\-wgan](https://github.com/caogang/wgan-gp) in pytorch and [improved wgan](https://github.com/igul222/improved_wgan_training) in tensorflow\), the main part which is gan\-64x64 is not yet implemented in pytorch.

We realize that training GAN is really unstable. For instance, we stuck for one month and needed to test each component in our model to see if they are equivalent to their tf counterparts. This resulted in a small ""framework"" to compare tensorflow and pytorch modules \([compare\-tf\-to](https://github.com/jalola/compare-tensorflow-pytorch)\). In the end, it was just that we used batchnorm instead of layernorm :\) Maybe it was just newbie mistake.

Since our previous post on this subreddit, we have added conditional wgan. It is a ""straightforward"" implementation as we have just added the auxiliary conditional part to the loss function and several accommodating changes to the input.

We trained the models \(wgan and acwgan\) on a GTX\-1080ti \(which we bought 2 of them\) for more than 2 weeks \(100k iterations\). You can see the generated images here.

[Improved WGAN - LSUN bedroom](https://i.redd.it/6hr29psx9iw01.png)

[Conditional Improved WGAN - LSUN 4 classes](https://i.redd.it/s02ub6n0aiw01.png)

If you have any question, feel free to ask. Thanks for your time. 

Future works: we intend to add several new techniques such as spectral normalization,",22,26
359,2018-5-8,2018,5,8,7,8hrgn7,[P] Python implementation of Monte Carlo Tree Search for Connect 4 Game with GUI,https://www.reddit.com/r/MachineLearning/comments/8hrgn7/p_python_implementation_of_monte_carlo_tree/,alfo5123,1525730790,,2,13
360,2018-5-8,2018,5,8,7,8hrlcu,[P] Need a pretrained CelebA identity classifier,https://www.reddit.com/r/MachineLearning/comments/8hrlcu/p_need_a_pretrained_celeba_identity_classifier/,anonDogeLover,1525731896,"Any links? Can't seem to find anything good. I want to classifier identity (e.g., Tom Cruise), not other attributes.",1,0
361,2018-5-8,2018,5,8,8,8hrvv0,.NET Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8hrvv0/net_machine_learning/,QuirkySpiceBush,1525734469,,0,1
362,2018-5-8,2018,5,8,8,8hs3at,[D] How is variable reassignment handled in reverse mode autodiff?,https://www.reddit.com/r/MachineLearning/comments/8hs3at/d_how_is_variable_reassignment_handled_in_reverse/,ConfuciusBateman,1525736258,"If one wants to take the derivative of a function `f` wrt to parameter `x`, and x is at some point reassigned to a different value in the body of `f`, how does this affect the the adjoints or graph that gets generated for reverse mode AD? Is the reassignment treated as a sort of ""branching"" in the graph and the values for the original `x` plus any reassignments are summed in the backward pass?

Here's an example:
`function Nested(x: number, a: number): number {
    let z = (x+10)*9;
    x = (a*5)+10
    return (a*(x+a)+a)*z
}`

Here `x` is obviously reassigned, so this would be an example of the case I'm trying to understand. One thing I thought of would be to generate all the adjoints as normal, but keep track of which adjoints represent a reassignment of `x` and add them up at the end. 

For example, if we have `w4 = whatever`, where `w4` is the adjoint for the reassignment of `x`, then at the end I would add `dNested/dw4` and `dNested/dx`. Thanks in advance for any insight on this.
",3,4
363,2018-5-8,2018,5,8,9,8hs9b2,MAC MACHINE LEARNING,https://www.reddit.com/r/MachineLearning/comments/8hs9b2/mac_machine_learning/,grelsondingo,1525737699,[removed],1,1
364,2018-5-8,2018,5,8,9,8hsl93,"If we combine one trainable parameters with a non-trainable parameter, is the original trainable param trainable?",https://www.reddit.com/r/MachineLearning/comments/8hsl93/if_we_combine_one_trainable_parameters_with_a/,real_charlie_parker,1525740545,[removed],0,1
365,2018-5-8,2018,5,8,9,8hsmfx,High core-count Ryzen 2 vs. Intel for Dev Workstation + Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/8hsmfx/high_corecount_ryzen_2_vs_intel_for_dev/,G_Gibson,1525740806,[removed],1,1
366,2018-5-8,2018,5,8,10,8hsqw8,Deep learning regression model doesn't converge,https://www.reddit.com/r/MachineLearning/comments/8hsqw8/deep_learning_regression_model_doesnt_converge/,L_E_I,1525741900,"Hi all, I am a new to deep learning, now I implemented a Fully-connected neural network and CNN based model to do prediction task, and the loss is defined by RMSE. 
1. However, I found that the training loss will keep getting lower, no matter how many epochs I use. Is this normal or I do something wrong?
2. Besides, for prediction task, is there any good regularization norms?",0,1
367,2018-5-8,2018,5,8,10,8hswhj,[D] What machine learning algorithm would be best to retrieve certain data from blobs of text that are always different.,https://www.reddit.com/r/MachineLearning/comments/8hswhj/d_what_machine_learning_algorithm_would_be_best/,Gorgeisi,1525743258,"For example, say I want to retrieve all phone numbers and cities from blobs of text that are always different.  How would we achieve this?  Is machine learning the right tool for this problem even?",7,4
368,2018-5-8,2018,5,8,11,8htgdg,Why aren't weights of neural networks initialized according to their prior distribution?,https://www.reddit.com/r/MachineLearning/comments/8htgdg/why_arent_weights_of_neural_networks_initialized/,alayaMatrix,1525748280,[removed],0,1
369,2018-5-8,2018,5,8,12,8htsol,[D] Learning Curves in Linear &amp; Polynomial Regression,https://www.reddit.com/r/MachineLearning/comments/8htsol/d_learning_curves_in_linear_polynomial_regression/,lord-bazooka,1525751565,,0,4
370,2018-5-8,2018,5,8,12,8httpu,[D] How to use the IAM dataset?,https://www.reddit.com/r/MachineLearning/comments/8httpu/d_how_to_use_the_iam_dataset/,The-IT,1525751856,"Hey guys,

I am trying to write a CNN that can verify weather or not a set of handwriting is by a particular author, and as far as I can tell, he IAM dataset is the only one suitable for this task. If I'm wrong, please let me know of others that I can use. The more the better

The problem I'm finding with IAM is how to access it. In practice, I would import libraries that could automatically download common datasets such as MNIST but now I I'm not really sure to get get the test and train data from IAM. 

I have online access to IAM where I can see the PNG files as well as the XMLs and the SCII files. But there doesn't seam to be an easy way to download the form or lines ETC...

So my question is, how exactly am I supposed to access the line and word files? 

Also, I've never worked with XML before, so I'm not really sure how I can make use of these files. Any insight would be great. 

Thank you all!",2,4
371,2018-5-8,2018,5,8,13,8hu2y5,[D] A2C/A3C: sharing the weights and same loss function?,https://www.reddit.com/r/MachineLearning/comments/8hu2y5/d_a2ca3c_sharing_the_weights_and_same_loss/,cranthir_,1525754803,"Hello everyone!

I'm currently working on implementing an A2C agent, but there is something I don't understand.

When you learn about A2C or A3C in mathematical terms you learn that there is two set of weights:

https://i.redd.it/6mmniiyd9kw01.png

The ones for the for Policy and the ones for the value.

I know that there is a giant gap between the theory and practice and when you look at most of the implementations with Tensorflow, **you see that they combine the loss function of policy and value like that:**

[Policy loss + Value loss + Regularization loss](https://i.redd.it/9drv0n9v9kw01.png)

Source: [https://jaromiru.com/2017/03/26/lets\-make\-an\-a3c\-implementation/](https://jaromiru.com/2017/03/26/lets-make-an-a3c-implementation/) and [https://cgnicholls.github.io/reinforcement\-learning/2017/03/27/a3c.html](https://cgnicholls.github.io/reinforcement-learning/2017/03/27/a3c.html)

What I don't understand is that on the one hand, we have a policy that outputs a probability distribution over actions and on the other hand we have a value function that outputs the value of being at that state and taking that action: both **normally needs different set of weights since they don't predict the same thing ?**

Does this means that in practice when we implement an A2C or A3C, we consider only a set of weights and as consequence we considers that improving the weights \(if we consider that there only one set of weights\) **improve the critic and actor together?**

Thanks for your help! ",8,7
372,2018-5-8,2018,5,8,13,8hu4xz,Recommended Graduate Coursework,https://www.reddit.com/r/MachineLearning/comments/8hu4xz/recommended_graduate_coursework/,patriots0715,1525755382,[removed],0,1
373,2018-5-8,2018,5,8,14,8hu64a,[N] Fast.ai Launching Cutting Edge Deep Learning for Coders: 2018 edition,https://www.reddit.com/r/MachineLearning/comments/8hu64a/n_fastai_launching_cutting_edge_deep_learning_for/,cedrickchee,1525755752,,31,213
374,2018-5-8,2018,5,8,14,8hu8j8,"Buy Microsoft Office, Azure, Dynamic CRM from Affluent Global Services.",https://www.reddit.com/r/MachineLearning/comments/8hu8j8/buy_microsoft_office_azure_dynamic_crm_from/,AffluentGlobal,1525756560,,0,1
375,2018-5-8,2018,5,8,15,8huo8h,32tray SUNNY Automatic Bean Sprout Machine/Mung bean Sprout Machine/Soybean Sprout Machine,https://www.reddit.com/r/MachineLearning/comments/8huo8h/32tray_sunny_automatic_bean_sprout_machinemung/,Ailce1220,1525762032,,1,1
376,2018-5-8,2018,5,8,16,8hus4d,Microsoft Office 365 for your business,https://www.reddit.com/r/MachineLearning/comments/8hus4d/microsoft_office_365_for_your_business/,AffluentGlobal,1525763475,,0,1
377,2018-5-8,2018,5,8,17,8hv0h6,Looking for a database or service for product data (components / attributes / features),https://www.reddit.com/r/MachineLearning/comments/8hv0h6/looking_for_a_database_or_service_for_product/,cwinhall,1525766727,[removed],0,1
378,2018-5-8,2018,5,8,17,8hv1o5,[R] DeepMind - From Generative Models to Generative Agents,https://www.reddit.com/r/MachineLearning/comments/8hv1o5/r_deepmind_from_generative_models_to_generative/,goolulusaurs,1525767202,,11,79
379,2018-5-8,2018,5,8,17,8hv1oy,HD Voice Playback with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8hv1oy/hd_voice_playback_with_deep_learning/,adammathias,1525767211,,0,1
380,2018-5-8,2018,5,8,18,8hvdck,What machine learning algorithm should be used for extracting tags from long articles?,https://www.reddit.com/r/MachineLearning/comments/8hvdck/what_machine_learning_algorithm_should_be_used/,briefbot,1525771821,[removed],0,1
381,2018-5-8,2018,5,8,18,8hvgsv,Machine Learning In The Cloud With Azure Machine Learning is Important?,https://www.reddit.com/r/MachineLearning/comments/8hvgsv/machine_learning_in_the_cloud_with_azure_machine/,sudheerreddym,1525773115,,0,1
382,2018-5-8,2018,5,8,19,8hvly7,Top 5 Recent Research Courses on Machine Learning | Simpliv,https://www.reddit.com/r/MachineLearning/comments/8hvly7/top_5_recent_research_courses_on_machine_learning/,simplivllc,1525774925,,0,1
383,2018-5-8,2018,5,8,19,8hvo76,How Machine Learning Coupled With Data Science Improves Retail Scenario (Part 1),https://www.reddit.com/r/MachineLearning/comments/8hvo76/how_machine_learning_coupled_with_data_science/,dexlabanalytics,1525775720,,0,1
384,2018-5-8,2018,5,8,19,8hvr0c,open-source DIY dataset-labeling website,https://www.reddit.com/r/MachineLearning/comments/8hvr0c/opensource_diy_datasetlabeling_website/,holgerno,1525776686,,0,1
385,2018-5-8,2018,5,8,20,8hvv45,"[D] Does prediction uncertainty of prediction depend on the choice of model? (for example, a Random Forest, Gaussian Process or neural network)",https://www.reddit.com/r/MachineLearning/comments/8hvv45/d_does_prediction_uncertainty_of_prediction/,RobRomijnders,1525778043,"It seems that interest rises to know the uncertainty in our predictions. For example [this](https://arxiv.org/abs/1309.1906) finds the uncertainty of a prediction by a random forest. Or [this](https://arxiv.org/abs/1703.04977) paper finds the uncertainties of a neural network used in computer vision. In general, [Gaussian processes](http://gpss.cc/gpss13/assets/Sheffield-GPSS2013-Wilkinson.pdf) are famous for getting the uncertainty in case of non parametric regression.


My question about all these uncertainties is:
Is uncertainty a property of these methods and these models or does uncertainty depend on the model choice?


It follows from this thought experiment:

Let's say we have a data set. A fixed data set. We fit a) a Bayesian random forest b) a neural network c) a Gaussian Process to this data. Now I get a new input, x. I wonder if all three models would give the same uncertainty about the prediction on data point x. ",8,6
386,2018-5-8,2018,5,8,20,8hw02l,I am running a neural net that plays connect4 against itself. All on a pi3!,https://www.reddit.com/r/MachineLearning/comments/8hw02l/i_am_running_a_neural_net_that_plays_connect4/,ToplessTopmodel,1525779598,,1,1
387,2018-5-8,2018,5,8,21,8hw4dy,[N] Biggest vehicle ever made and it's impact from space!,https://www.reddit.com/r/MachineLearning/comments/8hw4dy/n_biggest_vehicle_ever_made_and_its_impact_from/,MoreSecond,1525780885,,3,0
388,2018-5-8,2018,5,8,21,8hw511,DeepMind CTO Dan Belov's HiPEAC18 keynote on the techniques behind machine learning,https://www.reddit.com/r/MachineLearning/comments/8hw511/deepmind_cto_dan_belovs_hipeac18_keynote_on_the/,MSG_HiPEAC,1525781048,,0,0
389,2018-5-8,2018,5,8,21,8hwe0p,"We always believe"" Science and technology are the primary #productivity"". Hence all buildings are designed and manufactured to comply with the latest #American design codes.",https://www.reddit.com/r/MachineLearning/comments/8hwe0p/we_always_believe_science_and_technology_are_the/,Supertech_India,1525783511,,0,1
390,2018-5-8,2018,5,8,22,8hwicw,An end-to-end learning solution for assessing the quality of Wikipedia articles,https://www.reddit.com/r/MachineLearning/comments/8hwicw/an_endtoend_learning_solution_for_assessing_the/,wikirank,1525784642,,0,1
391,2018-5-8,2018,5,8,22,8hwny1,NoistNetwork for PPO or TRPO,https://www.reddit.com/r/MachineLearning/comments/8hwny1/noistnetwork_for_ppo_or_trpo/,andrewliao11,1525786021,[removed],0,1
392,2018-5-8,2018,5,8,22,8hwqo6,Deep Pensieve - now on github!! (link in comments),https://www.reddit.com/r/MachineLearning/comments/8hwqo6/deep_pensieve_now_on_github_link_in_comments/,neurokinetikz,1525786683,,1,1
393,2018-5-8,2018,5,8,22,8hwrmn,Noisy Network for PPO or TRPO,https://www.reddit.com/r/MachineLearning/comments/8hwrmn/noisy_network_for_ppo_or_trpo/,andrewliao11,1525786910,[removed],0,1
394,2018-5-8,2018,5,8,23,8hx7j8,[D] Azure Machine Learning Model Management,https://www.reddit.com/r/MachineLearning/comments/8hx7j8/d_azure_machine_learning_model_management/,MoragX,1525790525,"Hey everyone,

I've recently started a new position working on a data science team and management has asked for thoughts on using Azure Machine Learning Model Management for providing an API to a model we're working on. I was wondering if anyone has any experience with it.

I've searched this reddit and gotten some general impressions, but I'm curious if anyone is actually using it for a production-level API. We'd like to continue handling all the training ourselves (rather than using Azure's GUI tools) but want an easy way to stand up the model. So far AML Model Management has been a huge headache with random errors at every turn.

So is anyone using this? Googling for questions just gives me the Microsoft docs, no discussions on stackoverflow or anywhere else. That scares me. Is there a light at the end of the tunnel or should I abandon ship?

Thanks!",6,8
395,2018-5-9,2018,5,9,1,8hxtyz,Using vector of floating points as labels for input data in a CVAE,https://www.reddit.com/r/MachineLearning/comments/8hxtyz/using_vector_of_floating_points_as_labels_for/,ortix92,1525795278,[removed],0,1
396,2018-5-9,2018,5,9,1,8hy03y,"AI at massive scale, and Reinforcement Learning in industry",https://www.reddit.com/r/MachineLearning/comments/8hy03y/ai_at_massive_scale_and_reinforcement_learning_in/,e_ameisen,1525796527,,0,1
397,2018-5-9,2018,5,9,1,8hy06u,[D] - Using SMOTEBoost and RUSBoost to deal with class imbalance,https://www.reddit.com/r/MachineLearning/comments/8hy06u/d_using_smoteboost_and_rusboost_to_deal_with/,Rschmukler,1525796545,,0,10
398,2018-5-9,2018,5,9,1,8hy4l3,[P] Machine Learning Inside a Cluster Database,https://www.reddit.com/r/MachineLearning/comments/8hy4l3/p_machine_learning_inside_a_cluster_database/,dearpetra,1525797482,,0,1
399,2018-5-9,2018,5,9,1,8hy5gl,[R][ICLR 2018] Reproducibility and Reusability in Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/8hy5gl/riclr_2018_reproducibility_and_reusability_in/,downtownslim,1525797644,,0,10
400,2018-5-9,2018,5,9,1,8hy864,[R] Machine Learning Inside a Cluster Database,https://www.reddit.com/r/MachineLearning/comments/8hy864/r_machine_learning_inside_a_cluster_database/,dearpetra,1525798195,,0,1
401,2018-5-9,2018,5,9,2,8hybzc,[P] Machine Learning Inside a Cluster Database,https://www.reddit.com/r/MachineLearning/comments/8hybzc/p_machine_learning_inside_a_cluster_database/,digitalson,1525798961,,0,1
402,2018-5-9,2018,5,9,2,8hygs3,Can we use WGAN-GP for GAIL?,https://www.reddit.com/r/MachineLearning/comments/8hygs3/can_we_use_wgangp_for_gail/,life_is_harsh,1525799940,[removed],0,1
403,2018-5-9,2018,5,9,2,8hyhzt,"[N] Former researcher from Calico, Daphne Koller, launches startup applying machine learning to drug discovery",https://www.reddit.com/r/MachineLearning/comments/8hyhzt/n_former_researcher_from_calico_daphne_koller/,BatmantoshReturns,1525800183,,22,14
404,2018-5-9,2018,5,9,2,8hyi2u,How do you determine if your deep q network is working fine?,https://www.reddit.com/r/MachineLearning/comments/8hyi2u/how_do_you_determine_if_your_deep_q_network_is/,lcukerd,1525800196,[removed],0,1
405,2018-5-9,2018,5,9,2,8hyjue,Applying Machine Learning to Medicine: The Data Lab Podcast,https://www.reddit.com/r/MachineLearning/comments/8hyjue/applying_machine_learning_to_medicine_the_data/,beckerfuffle,1525800557,,1,1
406,2018-5-9,2018,5,9,2,8hyl3l,[P] Solving data science tasks inside a cluster relational database,https://www.reddit.com/r/MachineLearning/comments/8hyl3l/p_solving_data_science_tasks_inside_a_cluster/,luba_belokon,1525800802,,0,1
407,2018-5-9,2018,5,9,2,8hyoji,[P] Seg-mentor - A TF based sanbox for exploring semantic segmentation,https://www.reddit.com/r/MachineLearning/comments/8hyoji/p_segmentor_a_tf_based_sanbox_for_exploring/,DruishDude,1525801491,"A couple of moths ago our team started tinkering around with sem-seg nets and we really just wanted to check how an FCN will work with modern, light -weight feature extractors. We thought the [code](https://github.com/hailotech/seg-mentor) we got was kinda neat so we decided to share because we care.

The focus for us was not SoTa but more on tinkering and running experiments. We think it'll be useful for learning and intuition building.

Stuff you'll find inside:
- Pretrained FCN16/32 nets with Resnet-18, Inception, MobileNet V1 feature-extractors
- Easy to follow code so you can train your own stuff from scratch. we detail which hyperparams we used and how they effected training. We find that that info is sometimes hard to find. We also detail stuff that didn't work to save mankind time.
- some project ideas if you feel like contributing. It should also (hopefully) be easy to add your own decoder. we plan on enriching the repo with some more decoders in the near future.

Feedback is more than welcome!",4,10
408,2018-5-9,2018,5,9,2,8hypt4,[N] Applying Machine Learning to Medicine: The Data Lab Podcast,https://www.reddit.com/r/MachineLearning/comments/8hypt4/n_applying_machine_learning_to_medicine_the_data/,beckerfuffle,1525801728,,1,7
409,2018-5-9,2018,5,9,2,8hyscx,Does anyone know if the US has any policies regarding Artificial Intelligence?,https://www.reddit.com/r/MachineLearning/comments/8hyscx/does_anyone_know_if_the_us_has_any_policies/,moudon,1525802248,[removed],0,2
410,2018-5-9,2018,5,9,3,8hyy89,[P] Topological Data Analysis: Scalable Mapper Implementation on Top of Apache Spark,https://www.reddit.com/r/MachineLearning/comments/8hyy89/p_topological_data_analysis_scalable_mapper/,ShingoOKAWA,1525803431,,0,12
411,2018-5-9,2018,5,9,3,8hz6w7,[D] Attention Networks in Keras,https://www.reddit.com/r/MachineLearning/comments/8hz6w7/d_attention_networks_in_keras/,Choco31415,1525805158,,0,5
412,2018-5-9,2018,5,9,3,8hz8ji,Google Duplex: An AI System for Accomplishing Real World Tasks Over the Phone,https://www.reddit.com/r/MachineLearning/comments/8hz8ji/google_duplex_an_ai_system_for_accomplishing_real/,backupcortex,1525805481,,0,1
413,2018-5-9,2018,5,9,3,8hz8xy,[N] Google Duplex: An AI System for Accomplishing Real World Tasks Over the Phone,https://www.reddit.com/r/MachineLearning/comments/8hz8xy/n_google_duplex_an_ai_system_for_accomplishing/,backupcortex,1525805565,,181,680
414,2018-5-9,2018,5,9,4,8hzcyo,[USA] Looking to collect some data for a research project.,https://www.reddit.com/r/MachineLearning/comments/8hzcyo/usa_looking_to_collect_some_data_for_a_research/,NeitherExchange,1525806381,,0,1
415,2018-5-9,2018,5,9,4,8hziz6,[P] Tensorflow Implementation of Recurrent Convolutional Neural Network for Text Classification,https://www.reddit.com/r/MachineLearning/comments/8hziz6/p_tensorflow_implementation_of_recurrent/,roomylee,1525807637,,0,1
416,2018-5-9,2018,5,9,5,8hzsvf,[N] Google announces TPU 3.0,https://www.reddit.com/r/MachineLearning/comments/8hzsvf/n_google_announces_tpu_30/,gin_and_toxic,1525809704,,20,61
417,2018-5-9,2018,5,9,5,8i020n,LinkedIn AI/DS/ML Interview Questions  Acing the AI Interview,https://www.reddit.com/r/MachineLearning/comments/8i020n/linkedin_aidsml_interview_questions_acing_the_ai/,Vimarshk,1525811612,,0,1
418,2018-5-9,2018,5,9,5,8i04vf,"Getting an error: ""ValueError: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.""",https://www.reddit.com/r/MachineLearning/comments/8i04vf/getting_an_error_valueerror_the_first_layer_in_a/,haidershahzeb,1525812215,[removed],0,1
419,2018-5-9,2018,5,9,6,8i0bgl,Which master's degree in Europe for machine learning is better?,https://www.reddit.com/r/MachineLearning/comments/8i0bgl/which_masters_degree_in_europe_for_machine/,PrincessLeia1312,1525813629,,1,1
420,2018-5-9,2018,5,9,6,8i0d0k,What is the current state of the art edge detection/extraction method?,https://www.reddit.com/r/MachineLearning/comments/8i0d0k/what_is_the_current_state_of_the_art_edge/,inkplay_,1525813968,Eg I need to extract line art out of a portrait. I could pre-build plugins in photoshops or different cookie cutter methods but the result all comes out pretty mediocre. One thing I learned when training is garbage in garbage out. Can someone give me some suggestions?,0,1
421,2018-5-9,2018,5,9,6,8i0jth,[D] Why pycma implementation of CMA-ES has more than 8k lines of code ?,https://www.reddit.com/r/MachineLearning/comments/8i0jth/d_why_pycma_implementation_of_cmaes_has_more_than/,xingdongrobotics,1525815452,[removed],0,1
422,2018-5-9,2018,5,9,6,8i0mnk,"XNOR raises $12M for its cloud-free, super-efficient AI",https://www.reddit.com/r/MachineLearning/comments/8i0mnk/xnor_raises_12m_for_its_cloudfree_superefficient/,pjreddie,1525816066,,0,1
423,2018-5-9,2018,5,9,6,8i0oag,[D] Why `pycma` implements CMA-ES with more than 8k lines of code ?,https://www.reddit.com/r/MachineLearning/comments/8i0oag/d_why_pycma_implements_cmaes_with_more_than_8k/,modernrl,1525816447,"It seems the pseudo\-code is quite neat and short in [Wikipedia](https://en.wikipedia.org/wiki/CMA-ES#Example_code_in_MATLAB/Octave). However, in [pycma](https://github.com/CMA-ES/pycma) repo it takes more than 8k lines of code. Could someone who has read through the repo share the main reason why it takes so much ?",3,6
424,2018-5-9,2018,5,9,7,8i0uvz,"[N] XNOR raises $12M for its cloud-free, super-efficient AI",https://www.reddit.com/r/MachineLearning/comments/8i0uvz/n_xnor_raises_12m_for_its_cloudfree/,pjreddie,1525817839,,1,0
425,2018-5-9,2018,5,9,9,8i1kk3,[N] Neural Machine Translation 4x faster on Xeon CPU than on V100 GPU with MXNet and Intel MKL-DNN,https://www.reddit.com/r/MachineLearning/comments/8i1kk3/n_neural_machine_translation_4x_faster_on_xeon/,thomasdlt,1525824142,,7,18
426,2018-5-9,2018,5,9,9,8i1we0,[R] Learning on the Edge: Explicit Boundary Handling in CNNs,https://www.reddit.com/r/MachineLearning/comments/8i1we0/r_learning_on_the_edge_explicit_boundary_handling/,xternalz,1525827069,,0,7
427,2018-5-9,2018,5,9,13,8i33m3,Andrew Ng Supported Drive.ai Launches its First Self-Driving Car,https://www.reddit.com/r/MachineLearning/comments/8i33m3/andrew_ng_supported_driveai_launches_its_first/,rbagdiya,1525838738,,0,1
428,2018-5-9,2018,5,9,13,8i3bk3,[P] Tensorflow model compiled to WebAssembly: human-to-dog translation in the browser,https://www.reddit.com/r/MachineLearning/comments/8i3bk3/p_tensorflow_model_compiled_to_webassembly/,mathegist,1525841199,,0,14
429,2018-5-9,2018,5,9,13,8i3dcz,What would be the best non-DL algorithm for Image Classification tasks?,https://www.reddit.com/r/MachineLearning/comments/8i3dcz/what_would_be_the_best_nondl_algorithm_for_image/,l0gicbomb,1525841772,[removed],0,1
430,2018-5-9,2018,5,9,14,8i3h4h,How do we use machine learning in daily life?,https://www.reddit.com/r/MachineLearning/comments/8i3h4h/how_do_we_use_machine_learning_in_daily_life/,Anusha55,1525842976,,0,1
431,2018-5-9,2018,5,9,14,8i3j3k,[N] How do we use machine learning in daily life?,https://www.reddit.com/r/MachineLearning/comments/8i3j3k/n_how_do_we_use_machine_learning_in_daily_life/,Anusha55,1525843622,,2,0
432,2018-5-9,2018,5,9,15,8i3q95,"[D] AI Researcher Joins Johnson and Johnson, to Make More than $19 Squillion",https://www.reddit.com/r/MachineLearning/comments/8i3q95/d_ai_researcher_joins_johnson_and_johnson_to_make/,wei_jok,1525846074,,12,11
433,2018-5-9,2018,5,9,15,8i3r8n,machine leanring application in price strategy,https://www.reddit.com/r/MachineLearning/comments/8i3r8n/machine_leanring_application_in_price_strategy/,sil7er,1525846430,[removed],0,1
434,2018-5-9,2018,5,9,15,8i3ric,[P] PyTorch Implementation of Learning to Reweight Examples for Robust Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8i3ric/p_pytorch_implementation_of_learning_to_reweight/,danieltan07,1525846531,"Code: https://github.com/danieltan07/learning-to-reweight-examples
Paper: https://arxiv.org/abs/1803.09050

The paper addresses the problem of imbalanced and noisy datasets by learning a good weighting of examples using a small clean and balanced dataset.

This is a simple implementation on an imbalanced MNIST dataset (up to 0.995 proportion of the dominant class).

I would like to acknowledge Adrien Ecoffet https://github.com/AdrienLE, I patterned the meta modules from his code. 

Please Let me know if there are any bugs in my code. Hoping to get some feedback. Thank you! =)

",1,4
435,2018-5-9,2018,5,9,15,8i3svi,[D] Machine Learning Application in Price Strategy,https://www.reddit.com/r/MachineLearning/comments/8i3svi/d_machine_learning_application_in_price_strategy/,sil7er,1525847027,"Hello! I want to sell a day-pass and month-pass ticket, the price is segmented based on customers' residential community or other factors. I would like to know the pricing strategy by which I can get profit or how much loss I would get.

Can someone share some ideas or reference? Thanks!",2,0
436,2018-5-9,2018,5,9,16,8i3yws,Holy shit you guys. The google assistant is insane.,https://www.reddit.com/r/MachineLearning/comments/8i3yws/holy_shit_you_guys_the_google_assistant_is_insane/,shaggorama,1525849230,,0,1
437,2018-5-9,2018,5,9,16,8i3zll,"[R] Holy shit you guys, the new google assistant is incredible.",https://www.reddit.com/r/MachineLearning/comments/8i3zll/r_holy_shit_you_guys_the_new_google_assistant_is/,shaggorama,1525849453,,259,814
438,2018-5-9,2018,5,9,16,8i475r,[D] How Google achieves same level of accuracy with larger batch sizes?,https://www.reddit.com/r/MachineLearning/comments/8i475r/d_how_google_achieves_same_level_of_accuracy_with/,phizaz,1525852224,"From Google IO 2018 state 8: https://youtu.be/vm67WcLzfvc?t=45m45s

They achieve the same level of accuracy with larger batch sizes. What techniques they use to achieve this, must be some right? ",23,18
439,2018-5-9,2018,5,9,17,8i48xk,How do I successfully separate a combination of items using Machine Learning ?,https://www.reddit.com/r/MachineLearning/comments/8i48xk/how_do_i_successfully_separate_a_combination_of/,devdibyo,1525852865,,0,1
440,2018-5-9,2018,5,9,17,8i49h1,[Question] What's the current state of art in Video-To-Text/Speech-to-Text ?,https://www.reddit.com/r/MachineLearning/comments/8i49h1/question_whats_the_current_state_of_art_in/,__Julia,1525853069,[removed],0,1
441,2018-5-9,2018,5,9,17,8i49ni,[R] What's the current state of art in Video-To-Text/Speech-to-Text ?,https://www.reddit.com/r/MachineLearning/comments/8i49ni/r_whats_the_current_state_of_art_in/,__Julia,1525853138,"Hi,

Lately, I have seen a lot of research focus on Text-to-speech [1](https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html), [2](https://arxiv.org/abs/1702.07825). I started looking into the state of the art of Speech-to-Text [1](https://ai.googleblog.com/2017/12/improving-end-to-end-models-for-speech.html), what are some of the latest research papers in this space that someone need to look at ?. 

Is anyone busy making  Speech-to-Text very effective? What's the current state of art? And which papers/books should I look into to get started?

",5,17
442,2018-5-9,2018,5,9,17,8i49pi,"[D] What are some good resources (MOOCs, youtube channels, tutorials and etc.) to ramp up statistics for ML interviews?",https://www.reddit.com/r/MachineLearning/comments/8i49pi/d_what_are_some_good_resources_moocs_youtube/,upulbandara,1525853159,,17,57
443,2018-5-9,2018,5,9,17,8i4g2x,[D] Any examples of Knowledge Distillation applied to regression?,https://www.reddit.com/r/MachineLearning/comments/8i4g2x/d_any_examples_of_knowledge_distillation_applied/,dorsalstream,1525855637,"I see knowledge distillation and its numerous variants applied to classification problems, and even the explanations for its efficacy reasoning with one-hot labels. Have knowledge distillation and related ideas in the context of NNs shown any advantage for regression problems?",3,6
444,2018-5-9,2018,5,9,18,8i4il8,DQN in the browser with TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/8i4il8/dqn_in_the_browser_with_tensorflowjs/,seann999,1525856599,,0,1
445,2018-5-9,2018,5,9,18,8i4k69,Microsoft Dynamics CRM Implementation,https://www.reddit.com/r/MachineLearning/comments/8i4k69/microsoft_dynamics_crm_implementation/,AffluentGlobal,1525857136,,0,1
446,2018-5-9,2018,5,9,18,8i4l1b,[P] DQN in the browser with TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/8i4l1b/p_dqn_in_the_browser_with_tensorflowjs/,seann999,1525857446,,4,17
447,2018-5-9,2018,5,9,18,8i4lwo,How Machine Learning Improves Retail (Part II),https://www.reddit.com/r/MachineLearning/comments/8i4lwo/how_machine_learning_improves_retail_part_ii/,dexlabanalytics,1525857791,,0,1
448,2018-5-9,2018,5,9,19,8i4un2,How to implement sklearn classifiers in Django Form ?,https://www.reddit.com/r/MachineLearning/comments/8i4un2/how_to_implement_sklearn_classifiers_in_django/,lamaturbo07,1525860947,"I am using some of the sklearn classifiers ( SVM, KNN etc) for breast cancer prediction. But I need to implement it in Web Application using Django Framework. I don't know how to implement it in Django Form. Can anyone please explain/ show me the step wise process of implementing it ?",0,1
449,2018-5-9,2018,5,9,19,8i4x5g,[P] espnet: End-to-End Speech Processing Toolkit,https://www.reddit.com/r/MachineLearning/comments/8i4x5g/p_espnet_endtoend_speech_processing_toolkit/,radenML,1525861835,,0,5
450,2018-5-9,2018,5,9,19,8i4zgb,EPAM Uses #MachineLearning to Turn Unstructured Data into Insights for Companies,https://www.reddit.com/r/MachineLearning/comments/8i4zgb/epam_uses_machinelearning_to_turn_unstructured/,Sgoldschmidt,1525862663,,1,1
451,2018-5-9,2018,5,9,19,8i5010,[D] Intel Movidius AI stick 9 months later.,https://www.reddit.com/r/MachineLearning/comments/8i5010/d_intel_movidius_ai_stick_9_months_later/,d32,1525862853,"Hello everyone! 

I would like to ask for your impressions of [this device](https://developer.movidius.com/), after the initial round of (some) excitement has passed.

What are some good use-cases for the device like this? What scenarios make this a good choice over GPU / CPU for neural networks?

Have any of you used this or similar in production? 

Has this been surpassed by more recent devices or even deemed irrelevant?

",21,11
452,2018-5-9,2018,5,9,20,8i55u4,Are there any good ML/AI podcasts?,https://www.reddit.com/r/MachineLearning/comments/8i55u4/are_there_any_good_mlai_podcasts/,Kabizzle,1525864726,[removed],0,1
453,2018-5-9,2018,5,9,21,8i5nsa,[D] Machine Learning vs. Rule-Based Systems in NLP,https://www.reddit.com/r/MachineLearning/comments/8i5nsa/d_machine_learning_vs_rulebased_systems_in_nlp/,fromthegut,1525869784,,0,4
454,2018-5-9,2018,5,9,22,8i5t1p,Offline Object Detection and Tracking on a Raspberry Pi [OC],https://www.reddit.com/r/MachineLearning/comments/8i5t1p/offline_object_detection_and_tracking_on_a/,brnko,1525871088,,0,1
455,2018-5-9,2018,5,9,22,8i5w9j,jcb service parts pro,https://www.reddit.com/r/MachineLearning/comments/8i5w9j/jcb_service_parts_pro/,Mypremiummanual,1525871839,,0,1
456,2018-5-9,2018,5,9,22,8i5x50,[D] I have been taking various ML course both theoretical and practical I understand almost everything but when it comes to problem-solving I fail,https://www.reddit.com/r/MachineLearning/comments/8i5x50/d_i_have_been_taking_various_ml_course_both/,CaptainOnBoard,1525872062," I have been studying ML for 4-5 months but still can't solve intermediate ML challenges.

Easy ones are literally nothing 

I want to develop an intuition of how to proceed for solving a problem 
I know which algorithm to apply but the things before that like data mungling ,data preprocessing etc 

What are some good resources (MOOCs, youtube channels, tutorials and etc.) to develop these skills",3,0
457,2018-5-9,2018,5,9,22,8i5ydz,[D] Paper Notes: Semi-Supervised Classification with Graph Convolutional Networks,https://www.reddit.com/r/MachineLearning/comments/8i5ydz/d_paper_notes_semisupervised_classification_with/,dtsbourg,1525872378,,12,13
458,2018-5-9,2018,5,9,22,8i607x,[R] State of the art on Attention Models in different fields?,https://www.reddit.com/r/MachineLearning/comments/8i607x/r_state_of_the_art_on_attention_models_in/,MrLeylo,1525872845,"Hello /r/MachineLearning.

I'm trying to get more context about Attention Models. One of my goals is to find which is the state of the art of it. Of course I know it's hard to generalize on this topic (e.g. Attention Models for Language Translation are a different science than for Visual Action Recognition), in my case I would like to study something related to video classification (e.g. action recognition), but it would be useful to me to have a general vision on how are they currently in different fields.

I've found some resources ([\[1\]](https://github.com/ArcherFMY/Paper_Reading_List/tree/master/CVPR2017-Attention-model),[\[2\]](http://www.cvpapers.com/cvpr2017.html), [\[3\]](http://www.cvpapers.com/iccv2017.html) ) and they seem to point to papers such as [\[1\] (captioning)](https://arxiv.org/pdf/1612.01887.pdf), [\[2\] (action recognition)](http://openaccess.thecvf.com/content_cvpr_2017/papers/Liu_Global_Context-Aware_Attention_CVPR_2017_paper.pdf), [\[3\] (language translation)](https://arxiv.org/pdf/1706.03762.pdf) but I'm not sure if that is still the State of the art.

I almost forgot to say that I would like to explore how they work for few-shot learning, as [this paper](https://arxiv.org/pdf/1703.00767.pdf) suggests.

I would appreciate any answer or help. Thank you!",9,6
459,2018-5-9,2018,5,9,23,8i6k5d,"[N] Microsoft build 2018- Thanks to its new support for Azure Machine Learning, Excel users will now also be able to use the machine learning models that their companys data scientists have developed for them.",https://www.reddit.com/r/MachineLearning/comments/8i6k5d/n_microsoft_build_2018_thanks_to_its_new_support/,techstress,1525877387,,0,9
460,2018-5-9,2018,5,9,23,8i6ko2,Need solution for 3D data. Dental,https://www.reddit.com/r/MachineLearning/comments/8i6ko2/need_solution_for_3d_data_dental/,niksnikson,1525877496,[removed],0,1
461,2018-5-9,2018,5,9,23,8i6kvb,[N] Nvidia cards in stock at the nvidia store.,https://www.reddit.com/r/MachineLearning/comments/8i6kvb/n_nvidia_cards_in_stock_at_the_nvidia_store/,Ataru074,1525877540,"FYI, if you need more gpus, the nvidia store now have them in stock. ",7,0
462,2018-5-10,2018,5,10,0,8i6pge,[D] Publishing academic papers on machine learning,https://www.reddit.com/r/MachineLearning/comments/8i6pge/d_publishing_academic_papers_on_machine_learning/,tilenkranjc,1525878520,"Given the bad situation in scientific publishing and recent rebellion of &gt;1000 AI top scientists against paywall Nature AI journal coming in January 2019, I would like to discuss the future of scientific publishing in general and also in AI field. First, a disclaimer: I'm working on a blockchain solution for scientific publishing. The idea is very open and led by scientific community. If you want to see more check www.dejournal.org.

Anyway, back to topic. How can we solve the following problems in publishing:
- closed access
- ireproducible results
- predatory journals
- unfair review processes
- the problem of priors - scientists with better reputation have better chances to publish shit papers in good journals
- any other problem you can think of

Related question would be about motivation - what is the motivation for scientists to engage in the scientific community by reviewing papers? Can this be incentivised by money?

Sorry for slightly offtopic discussion. While the AI community can be an example of good practice in scientific publishing, there are many other fields (particularly life sciences) which are terrible. I am a scientist myself publishing both in AI and life sciences and I'm very sad about the current situation.",0,0
463,2018-5-10,2018,5,10,0,8i6tju,[D] Similar Text Generation - Available Resources/Literature,https://www.reddit.com/r/MachineLearning/comments/8i6tju/d_similar_text_generation_available/,hershellknecht,1525879406,"Hi everyone, Im looking at the problem of similar text generation. That is, Id like to generate new text which is also similar to a set of given sentences.

Is there any novel relevant literature about it or are there any interesting resources that you know of?

Thanks!",3,1
464,2018-5-10,2018,5,10,0,8i6wk2,What is the type of problem called to find patterns where/when/why something messes up e.g. late shipping deliveries?,https://www.reddit.com/r/MachineLearning/comments/8i6wk2/what_is_the_type_of_problem_called_to_find/,impossibletogetagf,1525880032,[removed],0,1
465,2018-5-10,2018,5,10,0,8i70yn,PIAAC dataset for predicting risk of job automation,https://www.reddit.com/r/MachineLearning/comments/8i70yn/piaac_dataset_for_predicting_risk_of_job/,mr_dicaprio,1525880951,[removed],0,1
466,2018-5-10,2018,5,10,0,8i72wg,"Simple Questions Thread May 09, 2018",https://www.reddit.com/r/MachineLearning/comments/8i72wg/simple_questions_thread_may_09_2018/,AutoModerator,1525881346,[removed],0,1
467,2018-5-10,2018,5,10,1,8i7781,[P] Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention),https://www.reddit.com/r/MachineLearning/comments/8i7781/p_visualizing_a_neural_machine_translation_model/,nortab,1525882237,,1,7
468,2018-5-10,2018,5,10,1,8i7ark,Anyone know what this is?,https://www.reddit.com/r/MachineLearning/comments/8i7ark/anyone_know_what_this_is/,demondrac0,1525883165,,0,1
469,2018-5-10,2018,5,10,1,8i7ems,[D] Algorithms that help with deformation analysis with a non-static camera?,https://www.reddit.com/r/MachineLearning/comments/8i7ems/d_algorithms_that_help_with_deformation_analysis/,ElectricHobo,1525883969,"Hey everyone,
I'm trying to look for some papers or projects that can help with the development of an algorithm that could identify structural damage or other deformations of a specific object from a number of different angles and distances. I've been looking for a few weeks now, but haven't turned up anything useful, and was hoping someone here would have some idea of where to look.
Cheers",0,3
470,2018-5-10,2018,5,10,2,8i7pdb,Navigating with grid-like representations in artificial agents,https://www.reddit.com/r/MachineLearning/comments/8i7pdb/navigating_with_gridlike_representations_in/,hopingforholly,1525886270,,0,2
471,2018-5-10,2018,5,10,2,8i7v0x,"Just read this article about fear of A.I. taking over the world. As someone working in the field, I don't think it presents the true picture. Wanted your opinion.",https://www.reddit.com/r/MachineLearning/comments/8i7v0x/just_read_this_article_about_fear_of_ai_taking/,thelostj3di,1525887464,,0,1
472,2018-5-10,2018,5,10,2,8i8055,[R][Neuroscience] Navigating with grid-like representations in artificial agents,https://www.reddit.com/r/MachineLearning/comments/8i8055/rneuroscience_navigating_with_gridlike/,downtownslim,1525888580,,14,42
473,2018-5-10,2018,5,10,3,8i816w,1 How to Setup Bitcoin Historical Price Data in 5 Minutes,https://www.reddit.com/r/MachineLearning/comments/8i816w/1_how_to_setup_bitcoin_historical_price_data_in_5/,alpacahq,1525888803,[removed],0,1
474,2018-5-10,2018,5,10,3,8i869w,Microsoft Courts Developers with AI-Enhanced Tools at Build 2018,https://www.reddit.com/r/MachineLearning/comments/8i869w/microsoft_courts_developers_with_aienhanced_tools/,galaxytravellerr,1525889852,,0,1
475,2018-5-10,2018,5,10,3,8i88ff,Word2vec or something in php/javascript without node or c scripts?,https://www.reddit.com/r/MachineLearning/comments/8i88ff/word2vec_or_something_in_phpjavascript_without/,canttouchmypingas,1525890321,[removed],0,1
476,2018-5-10,2018,5,10,3,8i8ajl,Time series ML: Which Algorithm?,https://www.reddit.com/r/MachineLearning/comments/8i8ajl/time_series_ml_which_algorithm/,oyoby0,1525890780,[removed],0,1
477,2018-5-10,2018,5,10,3,8i8bl0,Workshops in ML,https://www.reddit.com/r/MachineLearning/comments/8i8bl0/workshops_in_ml/,ishaq_adenali,1525891002,"How do workshop papers work? Is there a way to submit directly to a workshop, or does it tend to be not too strong conference papers that get invited to workshops?",0,1
478,2018-5-10,2018,5,10,3,8i8bp6,[D] Word2vec or something similar in php/javascript without node or c scripts?,https://www.reddit.com/r/MachineLearning/comments/8i8bp6/d_word2vec_or_something_similar_in_phpjavascript/,canttouchmypingas,1525891031,"So I'm looking to create a similar topic addon for a forum, and I want to use some machine learning to help teach myself. I haven't been able to find implementations of word2vec in javascript except for

https://github.com/turbomaze/word2vecjson

and his demo site is broken. I was able to find convnetjs though, and a previous implementation of an svm in javascript before convnetjs was made.

What are my options here? Attempt to make that first word2vec project work for what I need? Try and work an svm from convnetjs?

Basically I want to be able to check their topic titles against the current forum's topiclist and pop out the 5 most similar ones, preferably with ajax. I'm not sure how much latency using these libraries would be for the user.",5,0
479,2018-5-10,2018,5,10,4,8i8lh4,Benefits of Machine Learning in different industries,https://www.reddit.com/r/MachineLearning/comments/8i8lh4/benefits_of_machine_learning_in_different/,aitrading,1525893116,,0,1
480,2018-5-10,2018,5,10,4,8i8q1p,What is a free software/program that I can use for NLP?,https://www.reddit.com/r/MachineLearning/comments/8i8q1p/what_is_a_free_softwareprogram_that_i_can_use_for/,Nzym,1525894110,[removed],0,1
481,2018-5-10,2018,5,10,4,8i8t04,[N]Alibaba Says Its New Tai Zhang Is the Worlds Most Powerful Quantum Circuit Simulator,https://www.reddit.com/r/MachineLearning/comments/8i8t04/nalibaba_says_its_new_tai_zhang_is_the_worlds/,gwen0927,1525894738,,0,1
482,2018-5-10,2018,5,10,4,8i8whc,The fall of RNN / LSTM,https://www.reddit.com/r/MachineLearning/comments/8i8whc/the_fall_of_rnn_lstm/,gagejustins,1525895468,,0,1
483,2018-5-10,2018,5,10,6,8i9h6p,"Free Udemy Course - Projects in Machine Learning, Over 14 hours of content, 7 Real World Projects",https://www.reddit.com/r/MachineLearning/comments/8i9h6p/free_udemy_course_projects_in_machine_learning/,erissmith,1525899964,[removed],0,1
484,2018-5-10,2018,5,10,6,8i9p78,ML training courses,https://www.reddit.com/r/MachineLearning/comments/8i9p78/ml_training_courses/,brownck,1525901783,[removed],0,1
485,2018-5-10,2018,5,10,6,8i9u5j,"Googles new TPU: 11PFLOPS 2,400GB/s and 4TB memory - WOW",https://www.reddit.com/r/MachineLearning/comments/8i9u5j/googles_new_tpu_11pflops_2400gbs_and_4tb_memory/,Tastefull_,1525902960,,0,1
486,2018-5-10,2018,5,10,7,8i9xey,"""[News]"" Googles new TPU: 100PFLOPS 2,400+GB/s and 4TB memory per cluster",https://www.reddit.com/r/MachineLearning/comments/8i9xey/news_googles_new_tpu_100pflops_2400gbs_and_4tb/,Tastefull_,1525903699,,3,0
487,2018-5-10,2018,5,10,7,8i9zcj,Did we just witness an AI passing the Turing Test?,https://www.reddit.com/r/MachineLearning/comments/8i9zcj/did_we_just_witness_an_ai_passing_the_turing_test/,____vitAmin,1525904140,,0,1
488,2018-5-10,2018,5,10,8,8iakzq,[P] New Tool: Get All the Latest Articles on Machine Learning when Opening a New Chrome Tab,https://www.reddit.com/r/MachineLearning/comments/8iakzq/p_new_tool_get_all_the_latest_articles_on_machine/,AnYvia,1525909614,,12,110
489,2018-5-10,2018,5,10,9,8iar8k,[D] How to write a batch loader for preference learning problem using a Siamese NN,https://www.reddit.com/r/MachineLearning/comments/8iar8k/d_how_to_write_a_batch_loader_for_preference/,youngchul,1525911198,"I am attempting to solve a preference learning problem, where the goal is to find the preferred item of 2 items by observing comparisons only.

For example, let's say a gallery has 500 images (training set), and they have asked for peoples preferences between a lot of the images (annotations).

Now 100 new images (test set) arrive, based on the previous observations, the gallery wants to predict if a (or multiple) new images will be preferred over another image (from the full set), using CNN's?

I am thinking that this could be solved using a Siamese network structure, where 2 images (from the annotation set), are run through a CNN each, which outputs a scalar value, which can be compared (larger value, ""wins""). Then a loss function can be defined, by looking up the annotations and comparing them to the result from the 2 CNN's, and thus the weights are updated.

However, what I am very unsure of is how to write or define a batch loader for a problem such as this? Would it be wise to simply load, 16-32 annotations during each batch, or load every annotation one by one?

Any articles or examples, would be greatly appreciated.

",3,2
490,2018-5-10,2018,5,10,9,8iayof,"""Formal Security Analysis of Neural Networks using Symbolic Intervals"", Wang et al 2018",https://www.reddit.com/r/MachineLearning/comments/8iayof/formal_security_analysis_of_neural_networks_using/,breatheslowlybreathe,1525913113,,0,1
491,2018-5-10,2018,5,10,9,8ib038,How Anomaly Detection Works,https://www.reddit.com/r/MachineLearning/comments/8ib038/how_anomaly_detection_works/,MLNewb13532,1525913477,[removed],0,1
492,2018-5-10,2018,5,10,11,8ibotn,[P] PyTorch Tutorial and Exercise codes,https://www.reddit.com/r/MachineLearning/comments/8ibotn/p_pytorch_tutorial_and_exercise_codes/,nmhkahn,1525920069,,0,40
493,2018-5-10,2018,5,10,11,8ibr16,"Google: Small fast mobile-friendly NNs with ML Kit's ""Learn2Compress"" library for TensorFlow model distillation/sparsification/quantization/compression",https://www.reddit.com/r/MachineLearning/comments/8ibr16/google_small_fast_mobilefriendly_nns_with_ml_kits/,gwern,1525920654,,0,1
494,2018-5-10,2018,5,10,11,8ibrag,New Coursera Practical Deep Learning Course,https://www.reddit.com/r/MachineLearning/comments/8ibrag/new_coursera_practical_deep_learning_course/,ch3njus,1525920732,,0,1
495,2018-5-10,2018,5,10,12,8ibv0b,Excellent explanation about facial recognition. Similar concept used by Xenchain,https://www.reddit.com/r/MachineLearning/comments/8ibv0b/excellent_explanation_about_facial_recognition/,xenchain,1525921732,,1,7
496,2018-5-10,2018,5,10,12,8ibxie,Contributing to Intel AI documentation,https://www.reddit.com/r/MachineLearning/comments/8ibxie/contributing_to_intel_ai_documentation/,vector_machines,1525922438,[removed],0,1
497,2018-5-10,2018,5,10,13,8icci2,Extreme learning machine (ELM) is another name (vest) of the pseudoinverse learning algorithm (PIL).,https://www.reddit.com/r/MachineLearning/comments/8icci2/extreme_learning_machine_elm_is_another_name_vest/,Hard_Studies,1525927782,,0,1
498,2018-5-10,2018,5,10,14,8ickh3,Tensorflow Mobile - runs on GPU?,https://www.reddit.com/r/MachineLearning/comments/8ickh3/tensorflow_mobile_runs_on_gpu/,psurya1994,1525930508,"Does tensorflow mobile run on CPU or GPU on the phone? I've been trying to figure this out since long but unable to. Any help will be appreciated. :)

https://www.tensorflow.org/mobile/",0,1
499,2018-5-10,2018,5,10,15,8ict6m,Where did google get all that data from to train their new calling capabilities for the personal assistant ?,https://www.reddit.com/r/MachineLearning/comments/8ict6m/where_did_google_get_all_that_data_from_to_train/,multiks2200,1525933649,[removed],0,1
500,2018-5-10,2018,5,10,15,8icwiy,Horn Cabinet At Your Doorstep @Pembertons,https://www.reddit.com/r/MachineLearning/comments/8icwiy/horn_cabinet_at_your_doorstep_pembertons/,psmccouk,1525934916,[removed],0,1
501,2018-5-10,2018,5,10,17,8idd8v,"Deep Learning with CUDA, Python, and Anaconda Accelerate",https://www.reddit.com/r/MachineLearning/comments/8idd8v/deep_learning_with_cuda_python_and_anaconda/,sinuspane,1525941434,[removed],0,1
502,2018-5-10,2018,5,10,17,8idf9s,[D] Kullback-Leibler divergence has an enormous number of interpretations and uses (Twitter thread),https://www.reddit.com/r/MachineLearning/comments/8idf9s/d_kullbackleibler_divergence_has_an_enormous/,pmigdal,1525942248,,56,209
503,2018-5-10,2018,5,10,18,8idp2p,Unsupervised Machine learning based model to identify data entry error (temporal),https://www.reddit.com/r/MachineLearning/comments/8idp2p/unsupervised_machine_learning_based_model_to/,mageshkv,1525946072,[removed],0,1
504,2018-5-10,2018,5,10,19,8idql9,[R] IBM Watson Services for Core ML Tutorial,https://www.reddit.com/r/MachineLearning/comments/8idql9/r_ibm_watson_services_for_core_ml_tutorial/,LisaDziuba,1525946625,,0,0
505,2018-5-10,2018,5,10,19,8iduh5,Add a feature in the middle of a convolutional neuron network,https://www.reddit.com/r/MachineLearning/comments/8iduh5/add_a_feature_in_the_middle_of_a_convolutional/,ltnghia1304,1525947977,[removed],0,1
506,2018-5-10,2018,5,10,19,8idwnt,Are we speciesist?,https://www.reddit.com/r/MachineLearning/comments/8idwnt/are_we_speciesist/,engr_x,1525948764,What are your thoughts about human being speciesist to AI machines? ,0,1
507,2018-5-10,2018,5,10,19,8idz8p,Lahoh | Injera Making Machine Suppliers,https://www.reddit.com/r/MachineLearning/comments/8idz8p/lahoh_injera_making_machine_suppliers/,lgsherry,1525949664,,1,1
508,2018-5-10,2018,5,10,20,8ie3y4,Anyone experienced in the industry have any thoughts on Lambda School's ML program?,https://www.reddit.com/r/MachineLearning/comments/8ie3y4/anyone_experienced_in_the_industry_have_any/,JohnnyNylon,1525951166,[removed],0,1
509,2018-5-10,2018,5,10,20,8ie4d9,ML solution architecture to interest investors,https://www.reddit.com/r/MachineLearning/comments/8ie4d9/ml_solution_architecture_to_interest_investors/,Existential12,1525951308,[removed],0,1
510,2018-5-10,2018,5,10,20,8ieau2,[D] Facebooks Field Guide to Machine Learning video series,https://www.reddit.com/r/MachineLearning/comments/8ieau2/d_facebooks_field_guide_to_machine_learning_video/,sksq9,1525953367,,0,15
511,2018-5-10,2018,5,10,21,8iejqg,"[N] Weekly Machine Learning Opensource Roundup  May 10, 2018",https://www.reddit.com/r/MachineLearning/comments/8iejqg/n_weekly_machine_learning_opensource_roundup_may/,stkim1,1525955913,,0,1
512,2018-5-10,2018,5,10,22,8ieqn9,"How to Build a Brain (Alternatively, ""has anybody heard of Chris Eliasmith?"")",https://www.reddit.com/r/MachineLearning/comments/8ieqn9/how_to_build_a_brain_alternatively_has_anybody/,automated_reckoning,1525957706,[removed],0,1
513,2018-5-10,2018,5,10,22,8iexqq,Understanding Deep Learning with TensorFlow playground,https://www.reddit.com/r/MachineLearning/comments/8iexqq/understanding_deep_learning_with_tensorflow/,arthomas73,1525959506,,0,1
514,2018-5-10,2018,5,10,22,8ieyru,[D] Introduction to Recommender Systems in 2018,https://www.reddit.com/r/MachineLearning/comments/8ieyru/d_introduction_to_recommender_systems_in_2018/,minmidinosaur,1525959770,,0,3
515,2018-5-10,2018,5,10,22,8iezgd,Machine Learning Top 10 Articles for the Past Month (v.May 2018),https://www.reddit.com/r/MachineLearning/comments/8iezgd/machine_learning_top_10_articles_for_the_past/,ccGardnerr,1525959933,,0,1
516,2018-5-10,2018,5,10,22,8if22v,[R] Machine Learning Top 10 Articles for the Past Month (v.May 2018),https://www.reddit.com/r/MachineLearning/comments/8if22v/r_machine_learning_top_10_articles_for_the_past/,ccGardnerr,1525960557,,0,36
517,2018-5-10,2018,5,10,23,8ifc5z,[P] Machine learning problems set to build a data scientist CV,https://www.reddit.com/r/MachineLearning/comments/8ifc5z/p_machine_learning_problems_set_to_build_a_data/,mlnsports,1525962883,,1,15
518,2018-5-10,2018,5,10,23,8ifdpx,[P] /r/SubredditNN: a subreddit consisting entirely of text-generating recurrent neural network bots.,https://www.reddit.com/r/MachineLearning/comments/8ifdpx/p_rsubredditnn_a_subreddit_consisting_entirely_of/,minimaxir,1525963230,,4,24
519,2018-5-10,2018,5,10,23,8ifgkh,"A Clean, Simple NN Diagramming Tool",https://www.reddit.com/r/MachineLearning/comments/8ifgkh/a_clean_simple_nn_diagramming_tool/,TurnDownForPuns,1525963858,For giving lectures and explaining net connectivity and architecture to a variety of audiences. ,0,1
520,2018-5-10,2018,5,10,23,8ifh52,Way to explain DL decisions.,https://www.reddit.com/r/MachineLearning/comments/8ifh52/way_to_explain_dl_decisions/,skeering,1525963977,"Hi everyone, I was wondering if you could possibly indulge me a little and explain something to me?

It seems to me that it would be quite feasible and (dare I say) simple to explain NN decisions based on a normal forward pass. The method would be to simply keep track of each variables contribution to the final output by tracing its input across the NN whist normalising its (and other features/bias) values at each neuron.

But Ive been searching the literature for months and cannot find this method. Is anyone here aware of people explaining an NN utilising a forward pass rather than a backward one that gradient based explanations have dominated recently? (DeepLIFT, LRP, Taylor, Guided BackProp etc.)

If anyone can understand my question and offers insight thanks in advance!

The only explanation I can think of is that the method becomes intractable when explaining an RGB image with 10,000+ features.",0,1
521,2018-5-10,2018,5,10,23,8ifhjz,If the evolution was a deeplearning algo,https://www.reddit.com/r/MachineLearning/comments/8ifhjz/if_the_evolution_was_a_deeplearning_algo/,sbadyals,1525964066,,0,1
522,2018-5-11,2018,5,11,0,8ifjlm,"A Clean, Simple NN Diagramming Tool",https://www.reddit.com/r/MachineLearning/comments/8ifjlm/a_clean_simple_nn_diagramming_tool/,TurnDownForPuns,1525964516,,0,1
523,2018-5-11,2018,5,11,0,8ift96,[N] How This Machine Learning App Will Help You Become the Next Picasso,https://www.reddit.com/r/MachineLearning/comments/8ift96/n_how_this_machine_learning_app_will_help_you/,VY99,1525966560,,2,0
524,2018-5-11,2018,5,11,1,8ig16z,[D] Fine-tuning: does adding fully-connected layers at the end of the net improve the performance?,https://www.reddit.com/r/MachineLearning/comments/8ig16z/d_finetuning_does_adding_fullyconnected_layers_at/,t897349817,1525968267,"When fine-tuning VGG, it's a common practice to replace/retrain the fully-connected (fc) layers (sometimes they can be replaced with smaller fc layers). Keras even allow setting `include_top=False` to omit the fc layers. However, for networks that use global average pooling, I couldn't find a consensus or a study regarding how to deal with the last layers. 

For instance, in the [fine-tuning example](https://keras.io/applications/) in Keras documentation, they add a 1024 fc layer after the global average pooling layer in InceptionV3, and before the last classification layer. In [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html), they only change the last classification layer of a ResNet to adapt to the number of classes of the target domain, but don't add any additional fc layer.

I couldn't find studies that compare the inclusion of fc layers in networks that use global average pooling, but I find that in some examples on the internet, some people add fc layers and some people don't.

Does anybody know studies that compare this? Does anybody have a preference regarding adding fc layers or other techniques that may help transfer learning?",2,0
525,2018-5-11,2018,5,11,1,8ig5uz,Hyperscale hardware: ML at scale on top of Azure + FPGA,https://www.reddit.com/r/MachineLearning/comments/8ig5uz/hyperscale_hardware_ml_at_scale_on_top_of_azure/,MaximRouiller,1525969251,,0,1
526,2018-5-11,2018,5,11,2,8igp9d,[R][facebookresearch] Non-local Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8igp9d/rfacebookresearch_nonlocal_neural_networks/,downtownslim,1525973980,,0,8
527,2018-5-11,2018,5,11,2,8iguaw,[D] Why is TensorFlow so slow?,https://www.reddit.com/r/MachineLearning/comments/8iguaw/d_why_is_tensorflow_so_slow/,happyhammy,1525975061,"According to this paper: https://arxiv.org/pdf/1608.07249.pdf

TensorFlow is consistently the slowest ML framework for training various kinds of neural nets under all hardware configurations.

You can also find various individuals complaining about tensorflow's speed compared to other frameworks. e.g.
http://www.ccri.com/2016/12/09/torch-vs-tensorflow-vs-theano/

https://deeplearning4j.org/compare-dl4j-tensorflow-pytorch
""(-) Slower than other frameworks""

Why is TensorFlow so slow? I guess you have access to TPUs if you use TensorFlow but would it bring its speed to the same level as torch + fast GPU?

What frameworks would you use if you cared about speed?",140,250
528,2018-5-11,2018,5,11,3,8igwrl,Is there anyone who has taken a SOA paper and explained every terminology in it?,https://www.reddit.com/r/MachineLearning/comments/8igwrl/is_there_anyone_who_has_taken_a_soa_paper_and/,Sherbhy,1525975570,[removed],0,1
529,2018-5-11,2018,5,11,3,8igzzx,[D] Explaining every terminology in an SOA paper for beginners,https://www.reddit.com/r/MachineLearning/comments/8igzzx/d_explaining_every_terminology_in_an_soa_paper/,Sherbhy,1525976257,"Whenever a new paper comes out, I end up reading only the abstract as that is the only part I'm able to understand. If there is a lecturer who has taken the liberty to read out a paper while explaining every part of it for beginners, that would be awesome! Think of how this would fasten the learning process. Students won't have to sit and search up every detail and also gain an understanding on how a recent models function. However this would be useful only to people who have got at least a basic understanding of the whole ML process, as explaining that along side the paper would take too much time.

Any links you could provide would be really helpful!",2,2
530,2018-5-11,2018,5,11,3,8ih4b3,CNN and Mnist: trying to print what the filters try to search for. Need some suggestions.,https://www.reddit.com/r/MachineLearning/comments/8ih4b3/cnn_and_mnist_trying_to_print_what_the_filters/,Ijatsu,1525977151,"Hello!

I've been toying with TensorflowJS and I've reached 99.4% accuracy after 50 epoch using this network:

* Conv : 28x28x1 -&gt; 24x24x32, kernel: 5, activation: leaky relu
* Maxpool : 24x24x32 -&gt; 12x12x32
* Conv : 12x12x32 -&gt; 8x8x64, kernel: 5, activation: leaky relu
* Maxpool : 8x8x64 -&gt; 4x4x64
* Dropout : ratio: 0.4
* Dense softmax: 4x4x64 (flattened to 1024) -&gt; 10

Everything is initialized with Glorot Uniform, I train it using categorical cross entropy loss and stochastic gradient descent.

Works pretty well.

So the plan was to see what the filters actually search for. It is pretty straight forward for the first layer, just print the weights as pixels, and I can observ that some filters search for things that could be horizontal lines, others for vertical, ect.... Each filter is a picture of 5x5 pixel

The second layer is a bit more complex. I create an empty 14x14 tensor, I add to the empty values the output of the first conv respecting the gliding window, and I rawly add each filters on top of each other. This one shows more complex shape, but this still doesn't look like a number.

I do the same for the dense layer, this time it's not question of just taking 5x5 of the last layer but all of the outputs. I'm getting a 28x28 picture for each class. And the result is nowhere looking like a number. I vaguely see that the output for the class ""0"" search for something round with nothing inside. The logit for class ""1"" searches for a vertical bar with nothing around it. The others are even too messy, and when properly trained to something like 99% none of the filter is actually looking like anything.

I've tried using L1L2 regularization but it slowed down the learning and didn't give better results.

Questions:

* What could I do to furthermore increase the accuracy? (without increasing the dataset with deformations)
* Is this a right approach to try and see what it searches for? Should I try to take the weight and put them into a transposed network to try and see what it would generate for each class?
* Am I supposed to see anything relevant at the last stage? Or is it just representing where it expects bright color and where it expects absence of bright color?
* Is it ok that I consider all the pixels even though 15/16 of them are supposedly eaten in the maxpool layer?

Thanks!",0,1
531,2018-5-11,2018,5,11,4,8ihgbg,"This software is doing something similar to Human-like ""seeing"" and is heavily inspired by Modern Physics.",https://www.reddit.com/r/MachineLearning/comments/8ihgbg/this_software_is_doing_something_similar_to/,Pearlnv,1525979761,,1,1
532,2018-5-11,2018,5,11,4,8ihjub,[D] Talking about ML to non-ML folks in business or project scoping meetings,https://www.reddit.com/r/MachineLearning/comments/8ihjub/d_talking_about_ml_to_nonml_folks_in_business_or/,wronk17,1525980556,"TLDR: Read the Goal section and see Specific questions


## Goal
I'm putting together a loose set of guidelines on how ML-engineers should talk about their craft to non-technical people. Specifically, I want to focus on setting realistic goals/expectations in a business or project planning setting (with clients or a non-technical academic advisor). What are some strategies to best accomplish this?

## Why?
I just switched from academia to business several months ago and realized I was pretty ill-prepared for the first couple of these conversations. I stupidly smiled and nodded at a client client who literally told me that ML is capable of magical things :| That didn't exactly set me up for success when closing out the project -- I'm not a wizard. I couldn't find a whole lot of guidance on the topic (though post more links if I'm wrong!)  hence my plan to post a loose set of best practices. I'm just hoping to get more feedback/anecdotes/expertise to actually make this useful :)

## Specific questions:
1. Thinking about keeping the client/advisor happy throughout the process (including at delivery time),  what are high priority items to convey by the end of your initial project planning meeting(s)?
2. Progress is usually not linear (due to data munging, debugging, hyperparam searching). How do you balance properly explaining this nuance without going into to much technical detail? How do you talk about concrete goals in the face of this uncertainty?
3. How do you explain the process of going from prototype model to a production system? If you show some prototype results that look decent, what's the response to, ""Looks like the model works! Can we get that model into production by next week?""
4. Any other common pitfalls when scoping projects with non-ML folks?

## Best resources so far:
* Soundcloud's data science [blog post](https://developers.soundcloud.com/blog/soundclouds-data-science-process)
* Monica Rogati's [blog post](https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007)
* Tangentially related: paper on [technical debt in ML](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)
* Previous reddit post about this [here](https://www.reddit.com/r/MachineLearning/comments/39t0kp/askml_how_do_you_manage_expectations_in_applied/), but it's 2 years old.
* Mike Del Balso [talking on TWiML](https://twimlai.com/twiml-talk-115-scaling-machine-learning-uber-mike-del-balso/) about common pitfalls in building a production system @ Uber",14,36
533,2018-5-11,2018,5,11,5,8ihsqd,ML &amp; Linear Algebra,https://www.reddit.com/r/MachineLearning/comments/8ihsqd/ml_linear_algebra/,LeanderKu,1525982529,[removed],0,1
534,2018-5-11,2018,5,11,5,8ihwpz,"Peter Voss, CEO of Aigo.ai, discuss the 'Third Wave of AI'",https://www.reddit.com/r/MachineLearning/comments/8ihwpz/peter_voss_ceo_of_aigoai_discuss_the_third_wave/,AigoToken,1525983394,[removed],0,1
535,2018-5-11,2018,5,11,6,8iic08,Papers on image/video captioning,https://www.reddit.com/r/MachineLearning/comments/8iic08/papers_on_imagevideo_captioning/,EclecticPage306,1525986803,[removed],0,1
536,2018-5-11,2018,5,11,6,8iidmu,[P] Visualising MNIST features with Lucid,https://www.reddit.com/r/MachineLearning/comments/8iidmu/p_visualising_mnist_features_with_lucid/,mrahtz,1525987146,,0,1
537,2018-5-11,2018,5,11,6,8iiipc,What's your favorite *type* of learning for learning about machine learning?,https://www.reddit.com/r/MachineLearning/comments/8iiipc/whats_your_favorite_type_of_learning_for_learning/,alexa_y,1525988306,"Maybe a weird question but I'm curious. Do you learn ""better"" by watching videos, reading, taking a class, etc.? As someone completely new to it it's been hard to jump right into classes without reading first and brushing up on stats. MOOCs haven't been my friend",0,1
538,2018-5-11,2018,5,11,6,8iildk,[D] What's the best strategy for classifying users based on a corpus of their written text?,https://www.reddit.com/r/MachineLearning/comments/8iildk/d_whats_the_best_strategy_for_classifying_users/,GrundleMoof,1525988932,"Let's say I have the logs of a chatroom over a long period of time, and there are N users. What's the best strategy to use if I wanted to use these logs to train a ML model that would be able to guess which user is speaking, if I gave it a new chunk of text from that user?

I'm just learning ML so I'm new to this. My best guess would be something like what we did in the Andrew Ng ML course, where we used an SVM to ""make"" a spam classifier by turning each email into a kind of bag of words \(but with each word only having a 0/1 corresponding to unseen/seen, as opposed to tallying them\). I could do this but instead use a 1 vs all classification approach.

Is there a more standard way? thanks for any advice or resources!",6,0
539,2018-5-11,2018,5,11,7,8iiqt2,[D] Why are there so few Americans doing ML and stats research?,https://www.reddit.com/r/MachineLearning/comments/8iiqt2/d_why_are_there_so_few_americans_doing_ml_and/,anotheranon4811,1525990228,"It seems like every other arXiv paper I see is by somebody at Tsinghua University or in the US on a student visa/green card. At my uni's masters in stats program practically all the students are international (most from china, some from india). India and China do have 2.5 billion people, but the slice of internationals that can afford coming to the US for a 60k program (no financial aid) is maybe 2 million. They're all from the same major cities (Shanghai, Beijing, Shenzhen, Guangzhou, Delhi, Mumbai, Bangalore), obviously no one is from the ""countryside"" or ""suburbs"" even, which are dirt poor. 

Good for them, I hope they get the education they want. But what happened to the Americans, where are they????",0,0
540,2018-5-11,2018,5,11,7,8iiwc8,[D] Google Optimization Tools | Optimization | Google Developers,https://www.reddit.com/r/MachineLearning/comments/8iiwc8/d_google_optimization_tools_optimization_google/,sksq9,1525991574,,0,32
541,2018-5-11,2018,5,11,7,8ij00e,Carnegie Mellon Launches Undergraduate Degree in Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8ij00e/carnegie_mellon_launches_undergraduate_degree_in/,sidsig,1525992465,,0,1
542,2018-5-11,2018,5,11,7,8ij225,Papers that use auto-encoders as pretraining?,https://www.reddit.com/r/MachineLearning/comments/8ij225/papers_that_use_autoencoders_as_pretraining/,timmytimmyturner12,1525992993,[removed],0,1
543,2018-5-11,2018,5,11,9,8ijlmg,[R] On First-Order Meta-Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/8ijlmg/r_on_firstorder_metalearning_algorithms/,downtownslim,1525997867,,1,13
544,2018-5-11,2018,5,11,9,8ijq81,[hypothetical] What if Duplex calls hundreds of businesses -- engaging them repeatedly but with different voices. Is that a DDOS on Humanity?,https://www.reddit.com/r/MachineLearning/comments/8ijq81/hypothetical_what_if_duplex_calls_hundreds_of/,vector_machines,1525999090,,0,1
545,2018-5-11,2018,5,11,9,8ijs2u,[D] Method for Finding x which would produce a certain hidden state h?,https://www.reddit.com/r/MachineLearning/comments/8ijs2u/d_method_for_finding_x_which_would_produce_a/,alexmlamb,1525999557,"Let's say that I have a given hidden state h*, and I want to know what x* (if any) would give h* = f(x*).  

I guess I could do gradient descent on the loss ||h* - h|| with h = f(x), to find such an x*.  

However I'm curious if there's any other well known or studied methods for doing this.  ",3,6
546,2018-5-11,2018,5,11,10,8ijwpb,[P] A Text Search Method Using Similarities by K-Nearest Neighbours,https://www.reddit.com/r/MachineLearning/comments/8ijwpb/p_a_text_search_method_using_similarities_by/,yorgunson,1526000825,,0,0
547,2018-5-11,2018,5,11,10,8ik16t,"nice, easy to use ML service from training to deployment",https://www.reddit.com/r/MachineLearning/comments/8ik16t/nice_easy_to_use_ml_service_from_training_to/,ScotchMonk,1526002007,,0,1
548,2018-5-11,2018,5,11,10,8ik3ov,Help thinking through a classification/clustering problem.,https://www.reddit.com/r/MachineLearning/comments/8ik3ov/help_thinking_through_a_classificationclustering/,jkiley,1526002692,[removed],0,1
549,2018-5-11,2018,5,11,10,8ik7rf,Exploring the Limits of Weakly Supervised Pretraining,https://www.reddit.com/r/MachineLearning/comments/8ik7rf/exploring_the_limits_of_weakly_supervised/,sPiraless,1526003775,,0,1
550,2018-5-11,2018,5,11,13,8iky2y,[R] Full-body high-resolution Anime Generation with Progressive Structure-conditional GANs,https://www.reddit.com/r/MachineLearning/comments/8iky2y/r_fullbody_highresolution_anime_generation_with/,hardmaru,1526011322,,32,195
551,2018-5-11,2018,5,11,13,8il1jl,Is it just me or does potential of google duplex genuinely scare you,https://www.reddit.com/r/MachineLearning/comments/8il1jl/is_it_just_me_or_does_potential_of_google_duplex/,kumar29nov1992,1526012346,,0,1
552,2018-5-11,2018,5,11,13,8il4js,Techs Two Philosophies,https://www.reddit.com/r/MachineLearning/comments/8il4js/techs_two_philosophies/,drootr,1526013289,,0,1
553,2018-5-11,2018,5,11,15,8ilkv2,#MidnightThoughts#M : Can Machine learning help us in gaining immortality?,https://www.reddit.com/r/MachineLearning/comments/8ilkv2/midnightthoughtsm_can_machine_learning_help_us_in/,NonameHardLuck,1526018886,,0,1
554,2018-5-11,2018,5,11,15,8ilm0k,"how do you feel about heterogeneous embedding models? (Aka embedding spatially, temporally, and semantically at the same time)",https://www.reddit.com/r/MachineLearning/comments/8ilm0k/how_do_you_feel_about_heterogeneous_embedding/,scrublordprogrammer,1526019323,[removed],0,1
555,2018-5-11,2018,5,11,15,8ilr72,"What is the difference between Multitask Lasso and Elastic net , both are regularizing using L1/L2?",https://www.reddit.com/r/MachineLearning/comments/8ilr72/what_is_the_difference_between_multitask_lasso/,i_jbo,1526021224,[removed],0,1
556,2018-5-11,2018,5,11,17,8im43v,"[D] Theoretically, does batch_size=1, will give the best results?",https://www.reddit.com/r/MachineLearning/comments/8im43v/d_theoretically_does_batch_size1_will_give_the/,albert1905,1526026277,"We now have hardware limitations, and doing backpropagation is expensive, so Theoretically speaking does batch_size=1 will give the best results? and practically?
Thanks!",35,38
557,2018-5-11,2018,5,11,17,8im7mt,Use a Franking Machine to Save Money and Time,https://www.reddit.com/r/MachineLearning/comments/8im7mt/use_a_franking_machine_to_save_money_and_time/,mailcoms4,1526027824,,0,1
558,2018-5-11,2018,5,11,17,8im992,Cross-entropy vs. mean-squared error loss,https://www.reddit.com/r/MachineLearning/comments/8im992/crossentropy_vs_meansquared_error_loss/,ME_PhD,1526028489,[removed],0,1
559,2018-5-11,2018,5,11,17,8im9cw,The Basics of Automated Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8im9cw/the_basics_of_automated_machine_learning/,NetComLearning,1526028535,,0,1
560,2018-5-11,2018,5,11,17,8im9eb,[D] Cross-entropy vs. mean-squared error loss,https://www.reddit.com/r/MachineLearning/comments/8im9eb/d_crossentropy_vs_meansquared_error_loss/,ME_PhD,1526028548,"Suppose I have a label [0, 1, 0, 0] and predictions [.1, .7, .1, .1] and [.01, .7, .01, .28]

Cross-entropy would score these two predictions as the same, while MSE would punish the 2nd one more.

Isn't the 2nd prediction ""worse"" because it wrongly gave a pretty high score to a wrong class (.28)? So why use cross-entropy as opposed to MSE?",17,27
561,2018-5-11,2018,5,11,18,8imfzn,What is the most common format for exporting trained neural networks?,https://www.reddit.com/r/MachineLearning/comments/8imfzn/what_is_the_most_common_format_for_exporting/,Hizachi,1526031105,"Goal : I want Neural Networks encoded in the [SMT-Lib standard][1] as was done in [the Reluplex paper][2], so that I can run and compare SMT solvers. 

Need : the format in which neural networks are exported *after* they are done learning (so we are not talking about continuously learning NN here). so that I can write a translator for that format into the SMTLib. 

Problem : No agreed-upon standard. I saw people using JSON, YAML, XML, C and other formats to export their learned NNs. 

I decided to settle on JSON because it *seemed* the most widely used (am I mistaken ?) and the simplest to translate (with the yojson library in OCaml) but even then, what is the syntax ? (the fields, their names, their possible values, etc). I tried to look for some repository with some examples of what it would look like, the closest I found was [this][3], but I don't see the weights encoded in it.

Basically what I am looking for is the most common abstract syntax tree for JSON for neural networks, so that I can write a translator from JSON to SMTLib, and some place where I can find examples of neural networks on which I can try my code.

Is there such a thing ? Has the Machine learning community agreed on some kind of standard to export a snapshot of a neural network for future comparisons ? 


  [1]: http://smtlib.cs.uiowa.edu/language.shtml
  [2]: https://arxiv.org/abs/1702.01135
  [3]: https://machinelearningmastery.com/save-load-keras-deep-learning-models/",0,1
562,2018-5-11,2018,5,11,18,8imhmz,Learning internal representations by error propagation [1985: Rumelhart],https://www.reddit.com/r/MachineLearning/comments/8imhmz/learning_internal_representations_by_error/,bvk888,1526031738,,1,1
563,2018-5-11,2018,5,11,19,8imsc0,Looking for Tensorflow mentor,https://www.reddit.com/r/MachineLearning/comments/8imsc0/looking_for_tensorflow_mentor/,madneon_,1526035719,[removed],0,1
564,2018-5-11,2018,5,11,20,8imx76,Predicting a Discrete Variable,https://www.reddit.com/r/MachineLearning/comments/8imx76/predicting_a_discrete_variable/,MoodyOwl,1526037280,[removed],0,1
565,2018-5-11,2018,5,11,20,8imzzd,Machine Learning books used at Princeton University,https://www.reddit.com/r/MachineLearning/comments/8imzzd/machine_learning_books_used_at_princeton/,TJ1,1526038134,,0,1
566,2018-5-11,2018,5,11,20,8in1f1,What is Google lens and How does it works on Machine Learning algorithms,https://www.reddit.com/r/MachineLearning/comments/8in1f1/what_is_google_lens_and_how_does_it_works_on/,shwetaed,1526038582,[removed],0,1
567,2018-5-11,2018,5,11,20,8in4vn,All About Machine Learning and How does it work on Google Machine Algorithm,https://www.reddit.com/r/MachineLearning/comments/8in4vn/all_about_machine_learning_and_how_does_it_work/,sdatar12,1526039640,[removed],0,1
568,2018-5-11,2018,5,11,21,8in7il,[D] Defining a loss function for a binary comparison problem,https://www.reddit.com/r/MachineLearning/comments/8in7il/d_defining_a_loss_function_for_a_binary/,youngchul,1526040385,"I have recently been trying to replicate the results in the paper 

*'HIT SONG PREDICTION FOR POP MUSIC BY SIAMESE CNN WITH RANKING LOSS'* - Yu Lang-Chi-et-al

However I run into problems when defining the loss function for the binary comparison between the 2 scalar outputs f(x_i) &amp; f(x_y), after running 2 excerpts through a Siamese Network written using Keras, defined as seen in the model below (from the paper above).

https://i.imgur.com/Cv46n8B.png

Each excerpt enters a CNN, defined in Keras, according to the model seen below, the model outputs a scalar value, which goes into the shared loss function.

https://i.imgur.com/K6t6f5n.png

We have tried to use the following loss function

https://i.imgur.com/IDnC5PD.png

Defining it in Python using Keras as

&gt;     def rank_loss(y_true,y_pred):
&gt;        m = 1.0
&gt;        return K.mean(K.maximum(m - (y_true*y_pred), 0))

With y_true being the ground truth, between -1 and 1, and y_pred being

&gt;      Lambda(f(x_i) - f(x_j))

However, when training using this, the loss converges towards the margin, m, and the training accuracy converges towards 0.

The margin variable, m, is not defined in the paper, which makes it hard to implement. Is my interpretation of the loss function wrong, I suspect it is y_pred being calculated wrong.

Anyone got an idea about how to proceed from here? Anything would be greatly appreciated.",3,7
569,2018-5-11,2018,5,11,21,8in9u9,The Artificial Intelligence Revolution. Nice article about the fast development of AI in our days.,https://www.reddit.com/r/MachineLearning/comments/8in9u9/the_artificial_intelligence_revolution_nice/,cersei5991,1526041013,,0,2
570,2018-5-11,2018,5,11,21,8ine7o,"Congrats, but we dont need an I, Robot epidemic!",https://www.reddit.com/r/MachineLearning/comments/8ine7o/congrats_but_we_dont_need_an_i_robot_epidemic/,Bburris25,1526042195,,0,1
571,2018-5-11,2018,5,11,22,8inu1i,Launch AMD RX470 or RX480 with TensorFlow and Keras. Is it possible?,https://www.reddit.com/r/MachineLearning/comments/8inu1i/launch_amd_rx470_or_rx480_with_tensorflow_and/,IGsbrnk,1526046132,[removed],0,1
572,2018-5-11,2018,5,11,23,8io7u2,[D] Information Retrieval on Google Docs text,https://www.reddit.com/r/MachineLearning/comments/8io7u2/d_information_retrieval_on_google_docs_text/,datasciguy-aaay,1526049300,[removed],0,1
573,2018-5-11,2018,5,11,23,8iochk,Machine-learning scientists vow to boycott new journal,https://www.reddit.com/r/MachineLearning/comments/8iochk/machinelearning_scientists_vow_to_boycott_new/,gagejustins,1526050337,,0,1
574,2018-5-12,2018,5,12,0,8iokfy,Resources for data imputation?,https://www.reddit.com/r/MachineLearning/comments/8iokfy/resources_for_data_imputation/,AlittleMisleading,1526052015,[removed],1,1
575,2018-5-12,2018,5,12,0,8iolnt,ICML 2018 decisions are out,https://www.reddit.com/r/MachineLearning/comments/8iolnt/icml_2018_decisions_are_out/,thirddanceofeternity,1526052278,[removed],0,1
576,2018-5-12,2018,5,12,0,8ioqrr,[D] ICML 2018 decisions are out,https://www.reddit.com/r/MachineLearning/comments/8ioqrr/d_icml_2018_decisions_are_out/,thirddanceofeternity,1526053399,,61,84
577,2018-5-12,2018,5,12,0,8iou01,If the evolution was a deeplearning algo,https://www.reddit.com/r/MachineLearning/comments/8iou01/if_the_evolution_was_a_deeplearning_algo/,sbadyals,1526054107,,0,1
578,2018-5-12,2018,5,12,1,8ip5j6,What is your preferred way of managing results of several experiments especially in case of several hyperparameters/experimental setup?,https://www.reddit.com/r/MachineLearning/comments/8ip5j6/what_is_your_preferred_way_of_managing_results_of/,flowviv,1526056615,[removed],0,1
579,2018-5-12,2018,5,12,2,8iphkw,[D] Basic Neural Network Model Insight - Feedback appreciated.,https://www.reddit.com/r/MachineLearning/comments/8iphkw/d_basic_neural_network_model_insight_feedback/,nzakar17,1526059203,,0,0
580,2018-5-12,2018,5,12,2,8ipmx0,[R] Noisin: Unbiased Regularization for Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8ipmx0/r_noisin_unbiased_regularization_for_recurrent/,downtownslim,1526060261,,2,21
581,2018-5-12,2018,5,12,2,8ipoyd,Idea for a different class of ML algorithms?,https://www.reddit.com/r/MachineLearning/comments/8ipoyd/idea_for_a_different_class_of_ml_algorithms/,dev_matan_tsuberi,1526060704,[removed],0,1
582,2018-5-12,2018,5,12,3,8iq9cc,Simple image classifier for beginners,https://www.reddit.com/r/MachineLearning/comments/8iq9cc/simple_image_classifier_for_beginners/,testdev1,1526065144,[removed],0,1
583,2018-5-12,2018,5,12,4,8iqirj,AI Weekly 11 May 2018,https://www.reddit.com/r/MachineLearning/comments/8iqirj/ai_weekly_11_may_2018/,TomekB,1526067327,,0,1
584,2018-5-12,2018,5,12,4,8iqn5c,"is there a job called ""Freelance ML developer"" yet?",https://www.reddit.com/r/MachineLearning/comments/8iqn5c/is_there_a_job_called_freelance_ml_developer_yet/,PM_ME_WEBDEV_TIPS,1526068276,[removed],0,1
585,2018-5-12,2018,5,12,5,8ir2vd,"Given a bucket of insects, how could we find half a bucket of the smarter insects?",https://www.reddit.com/r/MachineLearning/comments/8ir2vd/given_a_bucket_of_insects_how_could_we_find_half/,BenRayfield,1526071498,,0,1
586,2018-5-12,2018,5,12,6,8ir8c7,Is the Goal of a Feed-forward Net to Find a Linearly Separable Feature Space?,https://www.reddit.com/r/MachineLearning/comments/8ir8c7/is_the_goal_of_a_feedforward_net_to_find_a/,ThatMLLife,1526072738,[removed],0,1
587,2018-5-12,2018,5,12,6,8irk9h,[D] MXNet for PyTorch users in 10 minutes - x-post r/mxnet,https://www.reddit.com/r/MachineLearning/comments/8irk9h/d_mxnet_for_pytorch_users_in_10_minutes_xpost/,thomasdlt,1526075638,,20,25
588,2018-5-12,2018,5,12,7,8irvb6,[R] Differentiable Dynamic Programming for Structured Prediction and Attention,https://www.reddit.com/r/MachineLearning/comments/8irvb6/r_differentiable_dynamic_programming_for/,hardmaru,1526078427,,6,80
589,2018-5-12,2018,5,12,7,8irwxm,"[P] Deploy .NET Machine Learning Models with ML.NET, ASP.NET Core, Docker and Azure Container Instances x-post r/dotnet",https://www.reddit.com/r/MachineLearning/comments/8irwxm/p_deploy_net_machine_learning_models_with_mlnet/,darkjeepers,1526078855,,1,1
590,2018-5-12,2018,5,12,8,8is9yl,Deep Learning in Speech (Keyword Spotting),https://www.reddit.com/r/MachineLearning/comments/8is9yl/deep_learning_in_speech_keyword_spotting/,tiger287,1526082401,[removed],0,1
591,2018-5-12,2018,5,12,8,8isce5,[R] Adversarial Contrastive Estimation,https://www.reddit.com/r/MachineLearning/comments/8isce5/r_adversarial_contrastive_estimation/,Sandyleap,1526083119,,1,6
592,2018-5-12,2018,5,12,9,8isi1p,[R] Creative Invention Benchmark: Can you build a single AI that can work on 4 very different creative tasks?,https://www.reddit.com/r/MachineLearning/comments/8isi1p/r_creative_invention_benchmark_can_you_build_a/,downtownslim,1526084736,,12,24
593,2018-5-12,2018,5,12,11,8it16f,[P] Detecting Arduino Uno boards. Too easy?,https://www.reddit.com/r/MachineLearning/comments/8it16f/p_detecting_arduino_uno_boards_too_easy/,ME_PhD,1526090496,"My first non-tutorial neural network. I made 50k negative and 50k positive images of Arduino Uno / other boards on various backgrounds.
https://www.kaggle.com/paperchaser/arduinoboard

I just trained my shallow convnet in TensorFlow and after 2 epochs I get 98% accuracy.
I trained on my old Dell laptop for 2-3 minutes total (yes really) and GPU usage was ~3% while CPU usage ~18%

Here is a pic with results from the test set. I did find 1 that it got wrong after looking through many. Seems too good to be true. Is this data set too easy? Why did it train so fast?

https://i.imgur.com/sN1iZ2t.jpg

If someone would be so kind to run this dataset (sorry it's ~300MB) through one of your networks and see me if it's this easy to get high accuracy. 
The code I used to load batches is here (marker keeps track of which file # you start at):

    def makebatch(marker, batchsize):
        '''batchsize must be even.
        marker is what pic index to begin at (0 is first file)'''
        batch = None
        pos_folder = r'C:\hard images\positive/'
        neg_folder = r'C:\hard images\negative/'
        for k in range(batchsize // 2):
            pos = imageio.imread('{}{}{}'.format(pos_folder, marker + k, '.jpg'))
            neg = imageio.imread('{}{}{}'.format(neg_folder, marker + k, '.jpg'))
            if batch is None:
                batch = np.empty((batchsize,) + pos.shape, dtype=np.uint8)        
            batch[2 * k, ...] = pos
            batch[2 * k + 1, ...] = neg
        marker += batchsize
        left = (np.arange(1, 1 + batchsize) % 2).astype(np.float32)
        right = (np.arange(0, batchsize) % 2).astype(np.float32)
        labels = np.stack((left, right), axis=1) # [1, 0] is pos, [0, 1] neg
        return batch, labels, marker",9,1
594,2018-5-12,2018,5,12,11,8it9i3,https://arxiv.org/pdf/1805.03710,https://www.reddit.com/r/MachineLearning/comments/8it9i3/httpsarxivorgpdf180503710/,serveboy,1526093150,,0,1
595,2018-5-12,2018,5,12,11,8itbhs,[R] Incorporating Subword Information into Matrix Factorization Word Embeddings,https://www.reddit.com/r/MachineLearning/comments/8itbhs/r_incorporating_subword_information_into_matrix/,serveboy,1526093781,,0,11
596,2018-5-12,2018,5,12,12,8ite3n,[R] NIPS 2018: How do I write a good review?,https://www.reddit.com/r/MachineLearning/comments/8ite3n/r_nips_2018_how_do_i_write_a_good_review/,FirstTimeReviewer,1526094629,"I just got an email to review for NIPS 2018, VERY EXCITED! 

I'm starting graduate school in the fall so I've never submitted or reviewed papers for this conference before. 

How do I chose papers to review? Should I start reading old NIPS papers to get an idea? Most importantly, how do I write a good review?",20,14
597,2018-5-12,2018,5,12,12,8itjak,[P] REST API v0.2 for Object Detection/Classification and identifying dominant colours in an image.,https://www.reddit.com/r/MachineLearning/comments/8itjak/p_rest_api_v02_for_object_detectionclassification/,Roots91,1526096333,"The project is in limited preview stage - It detects the object class, class probabilities, four coordinates of each bounding box and most dominant colours in hex format. I would really appreciate if you could use the service and give some feedback.

You can use 'test' credentials to test the API:

    curl -u demo:tango -F ""file=@&lt;your-image-path&gt;"" https://d9c19fe8.ngrok.io

Future Updates:
*Train your own model on the cloud.
*Face Detection - Detect multiple faces in an image.
*Explicit Content Detection - Detect explicit content in an image.
*Use API services using your username &amp; password.

",1,0
598,2018-5-12,2018,5,12,14,8iu2dw,Granulator/Granulating machine for transforming sugar cane residue into ...,https://www.reddit.com/r/MachineLearning/comments/8iu2dw/granulatorgranulating_machine_for_transforming/,amylee516,1526102995,,0,1
599,2018-5-12,2018,5,12,14,8iu3ty,Unsupervised learning: what to do after clustering?,https://www.reddit.com/r/MachineLearning/comments/8iu3ty/unsupervised_learning_what_to_do_after_clustering/,macoit18,1526103540,[removed],0,1
600,2018-5-12,2018,5,12,14,8iu4hf,Don't mess with the computers now!,https://www.reddit.com/r/MachineLearning/comments/8iu4hf/dont_mess_with_the_computers_now/,avideepmukherjee,1526103796,[removed],0,1
601,2018-5-12,2018,5,12,16,8iuhx5,Time series and descriptive statistics,https://www.reddit.com/r/MachineLearning/comments/8iuhx5/time_series_and_descriptive_statistics/,muk12345,1526109330,[removed],0,1
602,2018-5-12,2018,5,12,16,8iujuu,[P] TF-REX: AI learns to play Google Chrome's Dinosaur Game | No Emulators | All info in blogpost,https://www.reddit.com/r/MachineLearning/comments/8iujuu/p_tfrex_ai_learns_to_play_google_chromes_dinosaur/,vdutor,1526110161,,12,320
603,2018-5-12,2018,5,12,17,8iush4,[D] A Method to fit the distribution of neural net outputs of the whole dataset to a known distribution?,https://www.reddit.com/r/MachineLearning/comments/8iush4/d_a_method_to_fit_the_distribution_of_neural_net/,jeremy_lee_m,1526114097,"Lets say there is a dataset X containing data x_0 to x_n. We have a neural network F and I want the distribution of F(X) to be gaussian. how can i make loss term for this while training F? KLdivergence loss is currently used to fit the distribution of F(x_i), a single data not dataset, so im getting trouble with this...",1,0
604,2018-5-12,2018,5,12,18,8iuz7e,Poor performance on a single task of a multi-task CNN,https://www.reddit.com/r/MachineLearning/comments/8iuz7e/poor_performance_on_a_single_task_of_a_multitask/,SpWxScorpion,1526117173,[removed],0,1
605,2018-5-12,2018,5,12,18,8iv16w,500k keras predictions takes 2 hours on 72 processors. Is there a faster way e.g serverless or some other parallelisation?,https://www.reddit.com/r/MachineLearning/comments/8iv16w/500k_keras_predictions_takes_2_hours_on_72/,rainbow3,1526118102,[removed],0,1
606,2018-5-12,2018,5,12,19,8iv5qh,[D] Matching photos of an item to a catalogue of items - looking for some pointers/similar things,https://www.reddit.com/r/MachineLearning/comments/8iv5qh/d_matching_photos_of_an_item_to_a_catalogue_of/,bigpotatoman1,1526120104,"I did my undergrad thesis on machine learning / computer vision so know a little bit about it all, but this was some time ago. Something that's been on my mind lately is:

Say I have access to a catalogue of photos of specific clothing items (and I suppose for now, say I could have constructed the catalogue of photos myself from items physically possessed, and so each item in the catalogue could have photos taken at many different angles, lightings, backgrounds, etc.)

I also own two t-shirts, one that is in the catalogue, and one that isn't. Given a couple of photos of the t-shirts taken by myself (but not the exact same photograph as any that are in the catalogue), I think it would be interesting to try and have some type of model which says ""yep that's in the catalogue, item 5"" or ""nope, that isn't in the catalogue"". 

So this is kind of an object detection (to identify where the clothing item is in the image) and then classification problem (matching the located clothing item in the image to a catalogue product) right? I've not really come across anything similar that is capable of saying ""no this isn't a match"" - how is that sort of thing generally achieved? Some sort of confidence rating attached to the classification and if it's low enough then that equals not a match?
 
I would really appreciate someone with a bit more knowledge to help me direct my research into the right areas - any key words to search for, links to papers, relevant musings or examples of something broadly similar - I know there must be! 
",3,1
607,2018-5-12,2018,5,12,19,8iv9na,Association Mining Using Apriori Algorithm | Hashtag Statistics,https://www.reddit.com/r/MachineLearning/comments/8iv9na/association_mining_using_apriori_algorithm/,LearningFromData,1526121852,,0,1
608,2018-5-12,2018,5,12,19,8ivb1c,Automatic Powder Filling &amp; Capping Machine manufacturer,https://www.reddit.com/r/MachineLearning/comments/8ivb1c/automatic_powder_filling_capping_machine/,Sidsam1,1526122457,,0,1
609,2018-5-12,2018,5,12,20,8ivckk,Research Topic in big data analytics,https://www.reddit.com/r/MachineLearning/comments/8ivckk/research_topic_in_big_data_analytics/,bhawnasgn,1526123073,[removed],0,1
610,2018-5-12,2018,5,12,20,8ivh3o,[D] Advice for GAN optimization,https://www.reddit.com/r/MachineLearning/comments/8ivh3o/d_advice_for_gan_optimization/,Boozybrain,1526124920,"I'm just learning how to work with GANs and have been working with a [Keras implementation of DCGAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py), originally written to generate the MNIST database.  I have added some upsampling and trained it on a new dataset of ~7500 faces.  The original implementation works well but for my dataset it mistakenly thinks it achieves 100% accuracy, with the discriminator loss dropping to 0 and the generator loss stabilizing at least an order of magnitude higher than I would expect.  I have tweaked the latent dimension but didn't see any improvement, still figuring out how that's affecting things.  I did not modify the discriminator architecture, could this be hurting the performance? ",29,6
611,2018-5-12,2018,5,12,22,8ivygz,[R] Referring Relationships (CVPR 2018) : In-Depth Research Paper Review,https://www.reddit.com/r/MachineLearning/comments/8ivygz/r_referring_relationships_cvpr_2018_indepth/,jaleyhd,1526131024,,5,19
612,2018-5-12,2018,5,12,22,8iw25x,Method for New Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8iw25x/method_for_new_machine_learning/,palakkk,1526132211,,0,1
613,2018-5-12,2018,5,12,22,8iw6of,Install instruction for openai gym atari for Fedora,https://www.reddit.com/r/MachineLearning/comments/8iw6of/install_instruction_for_openai_gym_atari_for/,lcukerd,1526133549,[removed],0,1
614,2018-5-12,2018,5,12,23,8iwhbr,Questions from a student,https://www.reddit.com/r/MachineLearning/comments/8iwhbr/questions_from_a_student/,Abdullatif01,1526136527,[removed],0,1
615,2018-5-13,2018,5,13,0,8iwp62,[R] Decorrelated Batch Normalization,https://www.reddit.com/r/MachineLearning/comments/8iwp62/r_decorrelated_batch_normalization/,abstractcontrol,1526138627,,2,15
616,2018-5-13,2018,5,13,1,8iwxnz,[P] Wrote a bot to convert /r/MachineLearning/ arxiv pdf research articles to arxiv-vanity.com html pages.,https://www.reddit.com/r/MachineLearning/comments/8iwxnz/p_wrote_a_bot_to_convert_rmachinelearning_arxiv/,begooboi,1526140809,"This is the code I wrote. I am not planning to further develop this bot and if anyone is interested in this, you are welcome to use this code.

    import praw
    from collections import deque
    from time import sleep

    cache = deque(maxlen=300)

    bot = praw.Reddit(user_agent='arxiv2vanity_bot',
                      client_id='abcdeFDEFGH',
                      client_secret='12356789',
                      username='USERNAME',
                      password='PASSWORD')

    running = True
    while running:
        try:
            for submission in bot.subreddit('MachineLearning').new(limit=100):    
                if ""arxiv.org/"" in submission.url and submission.url not in cache:
                    cache.append(submission.url)
                    print(submission.title)
                    print(submission.url)
                    arxiv_id=submission.url.rsplit('/', 1)[1]
                    if '.pdf' in arxiv_id:
                        arxiv_id=arxiv_id[:-4]
                    arxiv_vanity_link=""https://www.arxiv-vanity.com/papers/""+str(arxiv_id)
                    print arxiv_vanity_link
                    message = ""Arxiv_vanity html rendered page for paper u/{0} is  u/{1}"".format(submission.url,arxiv_vanity_link)
                    print (""\n"")

                    #Uncomment below code to reply 

                    #submission.reply(message)

        except KeyboardInterrupt:
            #To kill this code, spam ""Ctrl+C"" until it catches the exception.
            running = False
        except praw.errors.APIException, e:
            print ""[ERROR]:"", e
            print ""sleeping 30 sec""
            sleep(30)
        except Exception, e: # In reality you don't want to just catch everything like this, but this is toy code.
            print ""[ERROR]:"", e
            print ""blindly handling error""
            continue

        #Debugging
        #pring(works)
        sleep(60) #one minute sleep",5,16
617,2018-5-13,2018,5,13,1,8ix510,Custom deep learning loss functions with Keras for R,https://www.reddit.com/r/MachineLearning/comments/8ix510/custom_deep_learning_loss_functions_with_keras/,bweber,1526142632,,0,1
618,2018-5-13,2018,5,13,2,8ixc6l,Looking for a Binary GAN Implementation (Not images),https://www.reddit.com/r/MachineLearning/comments/8ixc6l/looking_for_a_binary_gan_implementation_not_images/,alecuba16,1526144455,[removed],0,1
619,2018-5-13,2018,5,13,2,8ixdm9,[D] What constraints were used with the Google Assistant demo of the call to the hair salon?,https://www.reddit.com/r/MachineLearning/comments/8ixdm9/d_what_constraints_were_used_with_the_google/,i_marketing,1526144815,"Hi.  I saw the demo of the Google Assistant demo making a phone call to book an appointment with a hair salon (discussion and video [here](https://old.reddit.com/r/videos/comments/8hz1ik/google_demonstrates_google_assistant_making_a/)).  I assume they played the best test result and that other test results that didn't go so smoothly were not played.  Having said that, even though Google played the best test result, that is still impressive.

[This discussion here](https://old.reddit.com/r/videos/comments/8hz1ik/google_demonstrates_google_assistant_making_a/dynwmib/) briefly talks about some of the possible constraints used.  I assume that over the next few years, they can fine tune the AI so that it responds better to ""off script"" situations that would confuse the AI today.  I am also assuming that computer power will become faster over the next several years too so that maybe you don't need the power of Google's servers and maybe smaller and more economical servers would be fast enough for an AI like this.  I have two questions:

1) What constraints do you think were used by Google for their test?

2) Let's assume that most receptionists deal with basic questions.  Let's also assume that if the AI doesn't understand the question, the phone call can be forwarded to a real human being to answer.  Now a typical receptionist would deal with a wider scope of questions than a hair salon booking.  According to these assumptions, can you see an AI like Google Assistant replacing English speaking receptionists across the world within a decade?  If not, how long would it take before an AI like Google Assistant would be advanced enough to replace a typical human receptionist?
",5,15
620,2018-5-13,2018,5,13,2,8ixip8,ConvNetJS Reinforcement Learning demo inside gbrain library,https://www.reddit.com/r/MachineLearning/comments/8ixip8/convnetjs_reinforcement_learning_demo_inside/,3droberto,1526146058,,0,1
621,2018-5-13,2018,5,13,3,8iy0tr,AI vs AI: Ghostbusters - Capture The Flag,https://www.reddit.com/r/MachineLearning/comments/8iy0tr/ai_vs_ai_ghostbusters_capture_the_flag/,Daporan,1526150603,,0,1
622,2018-5-13,2018,5,13,3,8iy16r,Lips-motion to speech generator using ML in python,https://www.reddit.com/r/MachineLearning/comments/8iy16r/lipsmotion_to_speech_generator_using_ml_in_python/,ZER_0_NE,1526150696,[removed],0,1
623,2018-5-13,2018,5,13,3,8iy3c2,[P] AI vs AI: Ghostbusters - Capture The Flag,https://www.reddit.com/r/MachineLearning/comments/8iy3c2/p_ai_vs_ai_ghostbusters_capture_the_flag/,Daporan,1526151216,,0,0
624,2018-5-13,2018,5,13,4,8iycv8,Using multiple losses when learning a model,https://www.reddit.com/r/MachineLearning/comments/8iycv8/using_multiple_losses_when_learning_a_model/,tyrilu,1526153657,[removed],0,1
625,2018-5-13,2018,5,13,5,8iym29,[D] Training a Speaker Embedding from Scratch with Triplet Learning,https://www.reddit.com/r/MachineLearning/comments/8iym29/d_training_a_speaker_embedding_from_scratch_with/,ppymou,1526156010,,4,20
626,2018-5-13,2018,5,13,5,8iysu8,[D] DensePose,https://www.reddit.com/r/MachineLearning/comments/8iysu8/d_densepose/,supermario94123,1526157822,"https://arxiv.org/abs/1802.00434
Densepose.org

I know DensePose is a little bit old already, but I am just not understanding what they exactly mean with the teacher network and dense supervision signal. It is shown in Fig 9.
Can anyone shed a light on this?

PS: I hope I did the post correctly, I am super new 2 reddit.",5,7
627,2018-5-13,2018,5,13,7,8izbwb,[D] What do AI and blockchain mean for the rule of law?,https://www.reddit.com/r/MachineLearning/comments/8izbwb/d_what_do_ai_and_blockchain_mean_for_the_rule_of/,phobrain,1526162969,,6,0
628,2018-5-13,2018,5,13,7,8izegs,[D] A good question I stumbled upon: Why doesn't regularization solve Deep Neural Nets hunger for data?,https://www.reddit.com/r/MachineLearning/comments/8izegs/d_a_good_question_i_stumbled_upon_why_doesnt/,sugarhilldt2,1526163651,,64,136
629,2018-5-13,2018,5,13,9,8j03hm,Cheap Industrial Wire Stripping Machine For Sale | Bojin,https://www.reddit.com/r/MachineLearning/comments/8j03hm/cheap_industrial_wire_stripping_machine_for_sale/,Bojinmachinery,1526170296,,0,1
630,2018-5-13,2018,5,13,9,8j04hn,An Introduction to Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8j04hn/an_introduction_to_neural_networks/,NicNic8,1526170532,,0,1
631,2018-5-13,2018,5,13,9,8j081b,Is there such thing as a Hip hop/EDM instrumental database?,https://www.reddit.com/r/MachineLearning/comments/8j081b/is_there_such_thing_as_a_hip_hopedm_instrumental/,Cybermancan,1526171505,[removed],0,1
632,2018-5-13,2018,5,13,9,8j0bw5,[R] How Robust are Deep Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/8j0bw5/r_how_robust_are_deep_neural_networks/,Kraxenbichler,1526172545,,4,1
633,2018-5-13,2018,5,13,9,8j0dsk,[D] PyTorch Global GPU Flag,https://www.reddit.com/r/MachineLearning/comments/8j0dsk/d_pytorch_global_gpu_flag/,svaisakh,1526173065,"PyTorch, in their [0.4 migration guide](), simplifies writing device-agnostic code as follows:
```python
# at beginning of the script
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")

...

# then whenever you get a new Tensor or Module
# this won't copy if they are already on the desired device
input = data.to(device)
model = MyModule(...).to(device)
```

However, this is still not clean.

Ideally, we would like PyTorch to move everything over to the GPU, if it's available...
much like TensorFlow.

I tried setting the global tensor type to a cuda tensor using the ```torch.set_default_tensor_type()``` method.

However, there are some fundamental problems with setting the default tensor type.

* Dataloaders give normal (non-cuda) tensors by default. They have to be manually cast using the Tensor.to() method.

* Many methods are simply not implemented for torch.cuda.*Tensor. Thus, setting the global tensor type to cuda fails.

* Conversions to numpy using the numpy() method arent available for cuda tensors. One has to go x.cpu().numpy().
Although this chain is agnostic, it defeats the purpose.

Does anyone here have some idea?

Could we somehow have a global device setting that just works?",11,10
634,2018-5-13,2018,5,13,10,8j0ic8,Machines? Or apes?,https://www.reddit.com/r/MachineLearning/comments/8j0ic8/machines_or_apes/,DrFrankenwolf,1526174348,,0,1
635,2018-5-13,2018,5,13,10,8j0q1o,Q&amp;A dataset with labels describing the degree of reasoning required to answer the question,https://www.reddit.com/r/MachineLearning/comments/8j0q1o/qa_dataset_with_labels_describing_the_degree_of/,supermopman,1526176437,[removed],0,1
636,2018-5-13,2018,5,13,10,8j0qb3,Any opinions about this course ?,https://www.reddit.com/r/MachineLearning/comments/8j0qb3/any_opinions_about_this_course/,waterRocket8236,1526176511,,1,1
637,2018-5-13,2018,5,13,11,8j0uw5,I tend to get frustrated when I read stories of Machine learning thriving. Is there any one else out there that has felt this way before?,https://www.reddit.com/r/MachineLearning/comments/8j0uw5/i_tend_to_get_frustrated_when_i_read_stories_of/,Quantum_ML,1526177694,[removed],0,1
638,2018-5-13,2018,5,13,12,8j180g,Alternatives for Softmax function used for predictions,https://www.reddit.com/r/MachineLearning/comments/8j180g/alternatives_for_softmax_function_used_for/,sarasotadude,1526181677,[removed],0,1
639,2018-5-13,2018,5,13,12,8j1byf,Image segmentation to determine object present in given picture,https://www.reddit.com/r/MachineLearning/comments/8j1byf/image_segmentation_to_determine_object_present_in/,ssp4all,1526182933,[removed],0,1
640,2018-5-13,2018,5,13,13,8j1kyh,Data is the New Code,https://www.reddit.com/r/MachineLearning/comments/8j1kyh/data_is_the_new_code/,alberto33,1526185871,,0,1
641,2018-5-13,2018,5,13,13,8j1o8t,[P] Alternatives to Softmax for prediction,https://www.reddit.com/r/MachineLearning/comments/8j1o8t/p_alternatives_to_softmax_for_prediction/,sarasotadude,1526187043,"Hi,

I'm working on a CNN image classifier and am looking for alternative methods in place of predictions = tf.nn.softmax\(logits\) for making predictions \- all ideas and thoughts appreciated!

Are there any alternatives that accept logits in the manner the softmax does? I'm trying to make a comparison of multiple functions used for prediction.",13,0
642,2018-5-13,2018,5,13,14,8j1sl3,Is it possible to find ML engineering work with a BS?,https://www.reddit.com/r/MachineLearning/comments/8j1sl3/is_it_possible_to_find_ml_engineering_work_with_a/,arcane_neptune,1526188644,[removed],0,1
643,2018-5-13,2018,5,13,14,8j1vy3,looking for an ECG classification paper,https://www.reddit.com/r/MachineLearning/comments/8j1vy3/looking_for_an_ecg_classification_paper/,sanwal092,1526189916,[removed],0,1
644,2018-5-13,2018,5,13,14,8j1w8e,What is Machine Learning? [Infographic]  Main Concepts,https://www.reddit.com/r/MachineLearning/comments/8j1w8e/what_is_machine_learning_infographic_main_concepts/,ecoursedeals,1526190036,[removed],0,1
645,2018-5-13,2018,5,13,14,8j1wcs,Searching for datasets,https://www.reddit.com/r/MachineLearning/comments/8j1wcs/searching_for_datasets/,naruto678,1526190094,[removed],0,1
646,2018-5-13,2018,5,13,21,8j3dd8,Introducing Deep Conversation feature of Dragonfire open-source virtual assistant,https://www.reddit.com/r/MachineLearning/comments/8j3dd8/introducing_deep_conversation_feature_of/,mertyildiran,1526213521,,0,1
647,2018-5-13,2018,5,13,21,8j3f1j,[P] Introducing Deep Conversation feature of Dragonfire open-source virtual assistant,https://www.reddit.com/r/MachineLearning/comments/8j3f1j/p_introducing_deep_conversation_feature_of/,mertyildiran,1526214126,,9,81
648,2018-5-13,2018,5,13,21,8j3ffh,Neuralas new neural network reduces AI training times from hours to seconds,https://www.reddit.com/r/MachineLearning/comments/8j3ffh/neuralas_new_neural_network_reduces_ai_training/,for-asking-stuffs,1526214269,,0,1
649,2018-5-13,2018,5,13,21,8j3gbo,Octopusal Network: a new machine learning algorithm,https://www.reddit.com/r/MachineLearning/comments/8j3gbo/octopusal_network_a_new_machine_learning_algorithm/,mnunnari,1526214582,,0,1
650,2018-5-13,2018,5,13,21,8j3i50,[P] Octopusal Networks: a new machine learning algorithm,https://www.reddit.com/r/MachineLearning/comments/8j3i50/p_octopusal_networks_a_new_machine_learning/,mnunnari,1526215183,,12,19
651,2018-5-13,2018,5,13,21,8j3l63,Is it OK to open source and give the GitHub link in the paper submitted to NIPS/ICML?,https://www.reddit.com/r/MachineLearning/comments/8j3l63/is_it_ok_to_open_source_and_give_the_github_link/,alayaMatrix,1526216161,[removed],0,1
652,2018-5-13,2018,5,13,22,8j3obs,Android P Adaptive Brightness Algorithm,https://www.reddit.com/r/MachineLearning/comments/8j3obs/android_p_adaptive_brightness_algorithm/,OpenSourcererKyle,1526217098,[removed],0,1
653,2018-5-13,2018,5,13,22,8j3td3,Question about K-NN classification,https://www.reddit.com/r/MachineLearning/comments/8j3td3/question_about_knn_classification/,Is_This_Name_Tak3n,1526218580,[removed],0,1
654,2018-5-13,2018,5,13,23,8j3z2m,Question about batch normalization in deep learning,https://www.reddit.com/r/MachineLearning/comments/8j3z2m/question_about_batch_normalization_in_deep/,Jokowski,1526220194,[removed],0,1
655,2018-5-13,2018,5,13,23,8j44cd,[Project] Tensorflow implementation of Generative Adversarial Networks for Extreme Learned Image Compression,https://www.reddit.com/r/MachineLearning/comments/8j44cd/project_tensorflow_implementation_of_generative/,tensorflower,1526221572,,11,249
656,2018-5-13,2018,5,13,23,8j4bxo,"Question regarding weight initialization for ""On First-Order Meta-Learning Algorithms""",https://www.reddit.com/r/MachineLearning/comments/8j4bxo/question_regarding_weight_initialization_for_on/,mynameisvinn,1526223542,[removed],0,1
657,2018-5-14,2018,5,14,0,8j4gbm,[D] Is there a search engine for published NN architectures that uses graphs as search queries?,https://www.reddit.com/r/MachineLearning/comments/8j4gbm/d_is_there_a_search_engine_for_published_nn/,luerz,1526224601,"I'm wondering if there are any ongoing efforts to compile a database of published NN architectures, and make it searchable using a rough sketch of the desired architecture (composed of pre-defined building blocks) as the search query instead of the usual keywords? Quite often, while building a network, I'm wondering if a similar architecture has already been published  both so I can cite it, and to make sure I'm not missing any quirks. Typing in the keywords for all the concepts used can help sometimes, but is unreliable especially for more complex combinations. Being able to visually sketch the architecture, or, even better, just upload a graph from any of the major frameworks would help a lot.",5,1
658,2018-5-14,2018,5,14,1,8j504h,Power Ventilators manufacturer,https://www.reddit.com/r/MachineLearning/comments/8j504h/power_ventilators_manufacturer/,riseecovent,1526229270,,0,1
659,2018-5-14,2018,5,14,1,8j50ou,"Trouble reproducing GAN models built on Theano0.9, GTX Titan X + CUDA 7.5 + cuDNN 5",https://www.reddit.com/r/MachineLearning/comments/8j50ou/trouble_reproducing_gan_models_built_on_theano09/,spoiltForChoice,1526229399,[removed],0,1
660,2018-5-14,2018,5,14,2,8j5i3c,[D] Training a model to achieve D-Lib's facial landmarks like feature points for hands and it's landmarks.,https://www.reddit.com/r/MachineLearning/comments/8j5i3c/d_training_a_model_to_achieve_dlibs_facial/,hasime,1526233397,"These below are the results i.e. 68 facial landmarks that you get on applying the DLib's Facial Landmarks model that can be found [here](http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2).

It mentions in this script that the models was trained on the on the [iBUG 300-W](https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/) face landmark dataset.

Now, I wish to create a similar model for mapping the hand's landmarks. I have the hand dataset [here](https://www.mutah.edu.jo/biometrix/hand-images-databases.html).

What I don't get is:
1.  How am I supposed to train the model on those positions? Would I have to manually mark each joint in every single image or is there an optimized way for this?
2. In DLib's model, each facial landmark position has a particular value for e.g., the right eyebrows are 22, 23, 24, 25, 26 respectively. At what point would they have been given those values?
3. Would training those images on DLib's shape predictor training script suffice or would I have to train the model on other frameworks (like Tensorflow + Keras) too?",10,0
661,2018-5-14,2018,5,14,2,8j5jve,[P] TensorFlow workshop notebooks from Google,https://www.reddit.com/r/MachineLearning/comments/8j5jve/p_tensorflow_workshop_notebooks_from_google/,SupraluminalShift,1526233816,,1,23
662,2018-5-14,2018,5,14,3,8j5mvf,[SIGGRAPH 2018] Mode-Adaptive Neural Networks for Quadruped Motion Control,https://www.reddit.com/r/MachineLearning/comments/8j5mvf/siggraph_2018_modeadaptive_neural_networks_for/,-BlackSquirrel-,1526234495,,0,1
663,2018-5-14,2018,5,14,3,8j5rdc,Career question: how bad is quitting my job &amp; spend few months learning DL?,https://www.reddit.com/r/MachineLearning/comments/8j5rdc/career_question_how_bad_is_quitting_my_job_spend/,EmptyPhD1,1526235519,[removed],0,1
664,2018-5-14,2018,5,14,3,8j5zhy,[P] Visualizing how CNN filters change during training on MNIST,https://www.reddit.com/r/MachineLearning/comments/8j5zhy/p_visualizing_how_cnn_filters_change_during/,sigsegvxyz,1526237405,,12,63
665,2018-5-14,2018,5,14,4,8j68o2,Why Machine Learning wont cut it  Peter Voss  Medium,https://www.reddit.com/r/MachineLearning/comments/8j68o2/why_machine_learning_wont_cut_it_peter_voss_medium/,AigoToken,1526239494,,0,1
666,2018-5-14,2018,5,14,4,8j6gmh,GAN vs RNN - Which is better for Program Synthesis?,https://www.reddit.com/r/MachineLearning/comments/8j6gmh/gan_vs_rnn_which_is_better_for_program_synthesis/,neosluf,1526241257,[removed],0,1
667,2018-5-14,2018,5,14,5,8j6p8n,Decomposing multiple screenshots to fixed background and variable foreground elements,https://www.reddit.com/r/MachineLearning/comments/8j6p8n/decomposing_multiple_screenshots_to_fixed/,temptempyahoo,1526243247,"I have 10M screenshots from \~1000 office applications \(forms, text boxes, etc\). 

My aim is to:

  \- cluster the images by application \(i.e. screenshots which share common background elements\)

  \- within each group, decompose the variable foreground elements to text, icons, etc

Currently all my data is unlabeled. I can do labeling of individual elements, but NO LABELS of applications or foreground background.

* What is the common approach this task ?
* Is there a recommended pre\-trained model for screenshots ?!

I have some ML experience, but not so much with image data. I have been reading up on CNN, VAE and YOLO. Any help appreciated. 

All the tasks are offline so CPU is not an issue. ",0,1
668,2018-5-14,2018,5,14,6,8j73jd,MEMEGAN,https://www.reddit.com/r/MachineLearning/comments/8j73jd/memegan/,throwaway775849,1526246579,[removed],0,1
669,2018-5-14,2018,5,14,7,8j7e9g,[D] Detecting Market Manipulation in Video Game Markets,https://www.reddit.com/r/MachineLearning/comments/8j7e9g/d_detecting_market_manipulation_in_video_game/,tmart2322,1526249269,"Hi Reddit!

**Background**
I'm new to Machine Learning and have been researching some methods for detecting market manipulation in video game markets. There are a few thousand items that I would like to do this analysis on. For each item, I have data for how many were sold each hour (volume) and the average price of all of that were sold in that hour (mean). I also have various different sets of training data in which I know the market was manipulated at a certain time. What I would like to do is use the training data I've gathered for a few items in the market (~20) and apply the algorithm to all items in the market. Ultimately, my goals can be summarized by the following question. **What period(s), if any, was there a manipulated price for the given item?**

**What I've Found So Far**
[This article](https://www.sciencedirect.com/science/article/pii/S1877050917326868) I came across seems to have researched exactly what I would like to do. In this article, they recommended using either Decision Tree or K-Nearest Neighbor for finding market manipulations, each of which have around a 99.91% accuracy. However, the methodologies they used for training the data were a bit unclear to me, and as such I am posting here.

**Questions I Have**
* Is KNN/DT the best Machine Learning algorithm to use? If so, what library is capable of implementing KNN or DT in Python?
* What data should I be deriving from the data I have to train the data? *Further explanation: Volume and mean aren't great metrics to use as these can widely vary based on the item being evaluated. I'm thinking I should probably find percent volume increase/decrease and percent mean increase/decrease instead, but I would love any alternative and/or additional metrics that could help me*
* What is the best way to represent the data when feeding it to the algorithm? 
* When training the data, how can I combine info from all of my training data at once?

I really appreciate any and all answers, and even pointing me in the right direction would be a great help! Thanks!",7,2
670,2018-5-14,2018,5,14,7,8j7lyt,Should a vanilla RNN be able to learn a simple function?,https://www.reddit.com/r/MachineLearning/comments/8j7lyt/should_a_vanilla_rnn_be_able_to_learn_a_simple/,stanun,1526251348,[removed],0,1
671,2018-5-14,2018,5,14,10,8j8iu1,"[D] Papers writing...""The code will be made available upon publications"" should be held accountable to their statement...",https://www.reddit.com/r/MachineLearning/comments/8j8iu1/d_papers_writingthe_code_will_be_made_available/,abhishkk65,1526260494,,83,347
672,2018-5-14,2018,5,14,12,8j9bmc,[R] Evaluation of UMAP as an alternative to t-SNE,https://www.reddit.com/r/MachineLearning/comments/8j9bmc/r_evaluation_of_umap_as_an_alternative_to_tsne/,lmcinnes,1526268722,,9,10
673,2018-5-14,2018,5,14,13,8j9hqm,[D] Applications of ML in the biopharmaceutical industry?,https://www.reddit.com/r/MachineLearning/comments/8j9hqm/d_applications_of_ml_in_the_biopharmaceutical/,davemingchan,1526270622,"Im currently working as a manufacturing engineer in the biopharma industry and Ive recently become interested in learning more about the machine learning space. I was wondering if anybody could give insight into current applications of ML in biopharma manufacturing and R&amp;D, and direct me to any good whitepapers or resources. Thanks!",3,1
674,2018-5-14,2018,5,14,13,8j9rx8,[D] What are the best libraries / frameworks out there for productionizing ML?,https://www.reddit.com/r/MachineLearning/comments/8j9rx8/d_what_are_the_best_libraries_frameworks_out/,borgescane,1526273924,"I'm a software engineer working on productionizing machine learning models. I wanted to get the community's take on the best frameworks and libraries out there that let you take a model from offline training to serving in production.
What has everyone liked using and had success with?",10,9
675,2018-5-14,2018,5,14,15,8ja3qi,Machine Learning Where To Start And What To Do,https://www.reddit.com/r/MachineLearning/comments/8ja3qi/machine_learning_where_to_start_and_what_to_do/,Zeolearn,1526278104,,0,1
676,2018-5-14,2018,5,14,15,8ja7ek,How to continue to train a model with new classes and data?,https://www.reddit.com/r/MachineLearning/comments/8ja7ek/how_to_continue_to_train_a_model_with_new_classes/,UnKn0wn27,1526279515,[removed],0,1
677,2018-5-14,2018,5,14,16,8jaby5,What programming languages should I learn? + some other questions.,https://www.reddit.com/r/MachineLearning/comments/8jaby5/what_programming_languages_should_i_learn_some/,PM_me_your_saves,1526281281,[removed],1,1
678,2018-5-14,2018,5,14,16,8jafw6,PhD in Statistics or CS for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8jafw6/phd_in_statistics_or_cs_for_machine_learning/,caramel_jordan,1526282767,Which one would be more appropriate?,0,1
679,2018-5-14,2018,5,14,16,8jah3c,Ring die Granulator/Pellet machine,https://www.reddit.com/r/MachineLearning/comments/8jah3c/ring_die_granulatorpellet_machine/,amylee516,1526283213,,0,1
680,2018-5-14,2018,5,14,16,8jah87,[D] Decomposing screenshots to fixed background and variable foreground elements,https://www.reddit.com/r/MachineLearning/comments/8jah87/d_decomposing_screenshots_to_fixed_background_and/,temptempyahoo,1526283270,"I have 10M screenshots from \~1000 office applications \(forms, text boxes, etc\).

My aim is to:

* cluster the images by application \(i.e. screenshots which share common background elements\)
* within each group, decompose the variable foreground elements to text, icons, etc

I can do some labeling of individual elements, but preferably NO LABELS of the applications.

* What is the common approach this task ?
* Is there a recommended pre\-trained model for screenshots ?!

I have some ML experience, but mostly series analysis. So I  have been reading up on VAE and YOLO.

Any help appreciated.",1,1
681,2018-5-14,2018,5,14,16,8jaibb,How do you publish a user-created module based on TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/8jaibb/how_do_you_publish_a_usercreated_module_based_on/,longinglove,1526283748,[removed],0,1
682,2018-5-14,2018,5,14,16,8jaima,[Idea] Discord/Gitter place for all things AI/DeepLearning?,https://www.reddit.com/r/MachineLearning/comments/8jaima/idea_discordgitter_place_for_all_things/,malusmax,1526283878,[removed],0,1
683,2018-5-14,2018,5,14,17,8jao8e,"[P] Comparison of meta-heuristic algorithms to a simple problem written in Python. These are simple implementations of the algorithms, if they have any flaws or incorrect implementation, please open an issue or a PR. I'm planning to add more algorithms over time.",https://www.reddit.com/r/MachineLearning/comments/8jao8e/p_comparison_of_metaheuristic_algorithms_to_a/,skakabop,1526286237,,0,2
684,2018-5-14,2018,5,14,18,8javst,Neural Nets. Hyper parameter manual optimization,https://www.reddit.com/r/MachineLearning/comments/8javst/neural_nets_hyper_parameter_manual_optimization/,operatorius,1526289323,"Does anyone know any paper that contains practical recommendations for the process of manual hyper parameter optimization ? Such as which parameters to optimize first and which ones should be optimized in groups, etc.
Thank you 
",0,1
685,2018-5-14,2018,5,14,18,8jaxjm,[D] Neural nets. Hyper parameter manual optimization,https://www.reddit.com/r/MachineLearning/comments/8jaxjm/d_neural_nets_hyper_parameter_manual_optimization/,operatorius,1526289995,"Does anyone know any paper that contains practical recommendations for the process of manual hyper parameter optimization ? Such as which parameters to optimize first and which ones should be optimized in groups, etc. Thank you

",1,2
686,2018-5-14,2018,5,14,18,8jay88,Downloadable video dataset [D],https://www.reddit.com/r/MachineLearning/comments/8jay88/downloadable_video_dataset_d/,IntelligentSignature,1526290273,Can anyone point me to a sufficiently large video dataset for classification and event detection which is completely downloadable. I know there are sports-1M and youtube-8M but seems they can't be downloaded leagally. ,19,3
687,2018-5-14,2018,5,14,18,8jb05a,A newbie here - any good resources for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8jb05a/a_newbie_here_any_good_resources_for_machine/,JayceForTheWin,1526291033,[removed],0,1
688,2018-5-14,2018,5,14,18,8jb0ne,[D] Is there research on online learning where present predictions affect future training set (example in post)?,https://www.reddit.com/r/MachineLearning/comments/8jb0ne/d_is_there_research_on_online_learning_where/,xwrd,1526291248,"The example: let's say I've trained a model to predict which users will quit a business. The business uses my predictions to incentivise predicted users to stay. Some of them stay, and the model has to predict on them again. This goes on and on and at some point, to keep the model relevant to changes in the business product, I want to retrain it on the most recent data.

Now, for a user that has been incentivised in the past and who will quit unless incentivised, it is likely that the updated model will predict that the user will stay, based on similarity with other users which have been predicted to quit by the previous model, but based on that prediction, the business has incentivised them to stay, and they responded to the incentive and stayed.

My conclusion is that, in an online learning model where present predictions affect future training set, a naive model will oscillate between overpredicting a class and another class.

I gave my best shot at explaining this and I apologize if it makes your heads spin, to me it looks like a time-travel paradox from a Terminator movie. I couldn't find anything about this kind of situation online.",0,0
689,2018-5-14,2018,5,14,19,8jbboo,Your top relevant and latest Machine Learning news feed,https://www.reddit.com/r/MachineLearning/comments/8jbboo/your_top_relevant_and_latest_machine_learning/,mr_j_b,1526295289,,0,1
690,2018-5-14,2018,5,14,20,8jbjmk,"[N] Google Duplex, Sense Embeddings, hyperdoc2vec, CoDraw, Keras CPPN, TFLite, Resume Classification,",https://www.reddit.com/r/MachineLearning/comments/8jbjmk/n_google_duplex_sense_embeddings_hyperdoc2vec/,omarsar,1526297829,,0,0
691,2018-5-14,2018,5,14,21,8jbuxn,Sleeping video dataset,https://www.reddit.com/r/MachineLearning/comments/8jbuxn/sleeping_video_dataset/,xristos_forokolomvos,1526301080,[removed],0,1
692,2018-5-14,2018,5,14,21,8jbvht,"from tensorflow to fpga, is it possible ?",https://www.reddit.com/r/MachineLearning/comments/8jbvht/from_tensorflow_to_fpga_is_it_possible/,batbouyassou,1526301229,"hello guys, 

I've compiled a python program using tensorflow functions, now that i have the ready trained model can i transfer it to an fpga ? maybe extract registers and then convert them to describe the neural net hardwarely ? 

thank you !",0,0
693,2018-5-14,2018,5,14,21,8jbxx7,Capsule Networks - Facial Expression Recognition,https://www.reddit.com/r/MachineLearning/comments/8jbxx7/capsule_networks_facial_expression_recognition/,jempt0,1526301912,[removed],0,1
694,2018-5-14,2018,5,14,21,8jby1s,[P] Announcing LightTag - The easy way to annotate text,https://www.reddit.com/r/MachineLearning/comments/8jby1s/p_announcing_lighttag_the_easy_way_to_annotate/,TalkingJellyFish,1526301949,,5,7
695,2018-5-14,2018,5,14,22,8jc8sj,Do you face problems while searching for relevant datasets for your models or NNs?,https://www.reddit.com/r/MachineLearning/comments/8jc8sj/do_you_face_problems_while_searching_for_relevant/,YogSc,1526304642,[removed],0,1
696,2018-5-14,2018,5,14,22,8jc9jn,"Deep learning scaling is predictable, empirically",https://www.reddit.com/r/MachineLearning/comments/8jc9jn/deep_learning_scaling_is_predictable_empirically/,gagejustins,1526304813,,0,1
697,2018-5-14,2018,5,14,22,8jcc6g,How do capsules update its weights by gradient descend?,https://www.reddit.com/r/MachineLearning/comments/8jcc6g/how_do_capsules_update_its_weights_by_gradient/,fengye4242,1526305434,[removed],0,1
698,2018-5-14,2018,5,14,22,8jccwq,Machine learning: job interview.,https://www.reddit.com/r/MachineLearning/comments/8jccwq/machine_learning_job_interview/,AnecD,1526305595,,0,1
699,2018-5-15,2018,5,15,0,8jcyiq,I cannot wait for this become generally available in July #googleduplex,https://www.reddit.com/r/MachineLearning/comments/8jcyiq/i_cannot_wait_for_this_become_generally_available/,alberto33,1526310252,,0,1
700,2018-5-15,2018,5,15,0,8jd2s5,NIPS Format is so ugly - call for tricks,https://www.reddit.com/r/MachineLearning/comments/8jd2s5/nips_format_is_so_ugly_call_for_tricks/,fixed-point-learning,1526311136,[removed],0,1
701,2018-5-15,2018,5,15,0,8jd6we,How to use downloaded dataset in google colab?,https://www.reddit.com/r/MachineLearning/comments/8jd6we/how_to_use_downloaded_dataset_in_google_colab/,ZER_0_NE,1526311982,[removed],0,1
702,2018-5-15,2018,5,15,0,8jd71a,[HELP?!] Confusion Matrix based loss function,https://www.reddit.com/r/MachineLearning/comments/8jd71a/help_confusion_matrix_based_loss_function/,JohnRezzi,1526312004,[removed],0,1
703,2018-5-15,2018,5,15,0,8jd8n7,"What do you think of this paper: Decentralised Learning in Systems with Many, Many Strategic Agents?",https://www.reddit.com/r/MachineLearning/comments/8jd8n7/what_do_you_think_of_this_paper_decentralised/,goabiaryan,1526312340,,0,1
704,2018-5-15,2018,5,15,0,8jdcyd,"Decentralised Learning in Systems with Many, Many Strategic Agents",https://www.reddit.com/r/MachineLearning/comments/8jdcyd/decentralised_learning_in_systems_with_many_many/,goabiaryan,1526313210,[removed],0,1
705,2018-5-15,2018,5,15,1,8jdfrs,"Recent Developments in Universal Word and Sentence Embeddings: Trends, Baselines and SOTA",https://www.reddit.com/r/MachineLearning/comments/8jdfrs/recent_developments_in_universal_word_and/,Thomjazz,1526313774,,0,1
706,2018-5-15,2018,5,15,1,8jdglx,"[Discussion] Dear Industry Researchers: ""If researchers are not incentivized to do reproducible research (or penalized for not doing so), something is flawed in the industry.""",https://www.reddit.com/r/MachineLearning/comments/8jdglx/discussion_dear_industry_researchers_if/,feedthecreed,1526313944,"[This post by /u/Karyo_Ten](https://www.reddit.com/r/MachineLearning/comments/8j8iu1/d_papers_writingthe_code_will_be_made_available/dyy6fyb/)
&gt; Research is also about reproducibility. If researchers are not incentivized to do reproducible research (or penalized for not doing so), something is flawed in the industry.

has got me thinking. A source code requirement would make this by far the most reproducible community in the history of experimental science. Our experiments are programs that run *DETERMINISTICALLY*. If you speak with other scientific communities about our reproducibility issues, they are baffled.

And let's be honest, any reason against doing so are from incentives that are misaligned with the idea of reproducible research (secrecy for competition, not enough time to submit to every conference). 

If you aren't convinced, please take a look at Joelle Pineau's talk at ICLR 2018: https://www.youtube.com/watch?v=Vh4H0gOwdIg",68,432
707,2018-5-15,2018,5,15,1,8jdlro,Connect-4 Ai evolver,https://www.reddit.com/r/MachineLearning/comments/8jdlro/connect4_ai_evolver/,TheTButNotTHeE,1526314982,[removed],0,1
708,2018-5-15,2018,5,15,1,8jdoc6,Machine learning model - predict spend per customer per day?,https://www.reddit.com/r/MachineLearning/comments/8jdoc6/machine_learning_model_predict_spend_per_customer/,niujin,1526315510,[removed],0,1
709,2018-5-15,2018,5,15,1,8jduf8,[R] Convnets from First Principles (Ankit Patel),https://www.reddit.com/r/MachineLearning/comments/8jduf8/r_convnets_from_first_principles_ankit_patel/,abstractcontrol,1526316801,,1,19
710,2018-5-15,2018,5,15,2,8je2u8,A look at open source image recognition technology,https://www.reddit.com/r/MachineLearning/comments/8je2u8/a_look_at_open_source_image_recognition_technology/,vmbrasseur,1526318537,,0,1
711,2018-5-15,2018,5,15,3,8jegan,Elitist shuffle for recommendation systems,https://www.reddit.com/r/MachineLearning/comments/8jegan/elitist_shuffle_for_recommendation_systems/,rragundez,1526321328,,0,5
712,2018-5-15,2018,5,15,3,8jeic8,[D] Text classification on a small dataset,https://www.reddit.com/r/MachineLearning/comments/8jeic8/d_text_classification_on_a_small_dataset/,bendermorty,1526321732,,7,2
713,2018-5-15,2018,5,15,3,8jeilz,"[P] AI/ML Jobs - A daily updating job board for the artificial intelligence, machine learning, and deep learning jobs",https://www.reddit.com/r/MachineLearning/comments/8jeilz/p_aiml_jobs_a_daily_updating_job_board_for_the/,tsutomun,1526321789,,6,17
714,2018-5-15,2018,5,15,3,8jelcs,[D] Suggestion regarding career in ML/AI.,https://www.reddit.com/r/MachineLearning/comments/8jelcs/d_suggestion_regarding_career_in_mlai/,pinkzepvana,1526322382,"Hello everyone

I recently got admitted into the **Master of AI program at KU Leuven** (Fall 2018). While I feel positive about joining it and moving to Europe, my friends (especially the ones who are currently working in US or pursuing graduate studies in US) are advising against it. I did apply for a couple of DataScience programs in US (NYU, Columbia) but I have been rejected from both. They are suggesting me to wait for an year (or a semester) and apply for more US Universities. I figured I would ask the broader Machine Learning community for suggestion about how I should proceed, so posting here.

A short brief about my profile, I am an Electrical Engineering graduate from India and been working in the industry for ~3 years in analytics/ML. 

Here are my top reasons for pursuing a Master degree

-To improve my knowledge in the field. Take time off to plug the gaps in my understanding and also gain research experience

-To get access to quality jobs solving interesting problems in Europe/US ( I have kinda skeptical about quality work in India). I might even consider going for PhD but i am not sure about that

-To fulfil my dream of living in various countries (strong preference to Europe on this one)

TL;DR : Do you guys think I should go for it or wait an year and apply for US Universities. If someone is currently enrolled in the program I would really appreciate a honest feedback on the program too

Thanks in advance!
",22,9
715,2018-5-15,2018,5,15,3,8jes7o,"Wavenet and Duplex, space exploration possibilities",https://www.reddit.com/r/MachineLearning/comments/8jes7o/wavenet_and_duplex_space_exploration_possibilities/,pirate_solo9,1526323799,[removed],0,1
716,2018-5-15,2018,5,15,4,8jevrb,"[D]Wavenet and Duplex, space possibilities",https://www.reddit.com/r/MachineLearning/comments/8jevrb/dwavenet_and_duplex_space_possibilities/,pirate_solo9,1526324509,"Before I start, i would like to show something that you already must have seen to better make you understand [https://www.youtube.com/watch?v=p3PfKf0ndik](https://www.youtube.com/watch?v=p3PfKf0ndik) .

It is clear what I mean. We are looking at general purpose applications of these technologies but we are forgetting something big. As seen in that video, this technology can aid a lot in space exploration. Imagine giving a computer to do tasks but that which can carry out with human\-like comportment. This can help astronauts to tackle one of the biggest setbacks of space exploration i.e. loneliness. We see in the movie Interstellar the relationship TARS and cooper develop as the movie progresses. TARS is capable of carrying out tasks with the speech and understanding that is almost human\-like. Possibly we may already have cracked the speech technology\(Wavenet\) but the limited scope of understanding/parsing and compute power still persists. The applications of duplex is limited right now but it is certain that it will develop over time enough to possess capabilities that can handle general conversation and perhaps add some sarcasm just like in the movie we saw TARS cracking sarcastic jokes. This can aid not only in space exploration but also to treat people with illnesses such as depression, loneliness and and much more which is a leading illness in the past years and in increasing as the day passes by. Recent research revealed an increase of 33&amp;#37; in the US itself.

Wavenet and Duplex can change the face of the space exploration and can bring hope to those people suffering from mental illnesses. Well, the technology is still new with endless applications but with the rapid  technological advancement in the last 60 years I am quite certain we are not far away. AI is a gift to humanity if used carefully, it is a gift created by us to help us move forward and tackle barriers that are beyond imaginable.",1,0
717,2018-5-15,2018,5,15,4,8jewf6,[Discussion] Lots of Interesting Developments in Words and Sentences Embeddings in the last few months,https://www.reddit.com/r/MachineLearning/comments/8jewf6/discussion_lots_of_interesting_developments_in/,Thomjazz,1526324635,,3,33
718,2018-5-15,2018,5,15,4,8jf0gb,[Q] When working on a background/foreground classification problem is there a reason why most modern papers use 2 classes rather than 1?,https://www.reddit.com/r/MachineLearning/comments/8jf0gb/q_when_working_on_a_backgroundforeground/,yevbev,1526325494,[removed],0,1
719,2018-5-15,2018,5,15,4,8jf6d7,RMDL: Random Multimodel Deep Learning for Classification,https://www.reddit.com/r/MachineLearning/comments/8jf6d7/rmdl_random_multimodel_deep_learning_for/,kk7nc,1526326715,[removed],0,1
720,2018-5-15,2018,5,15,4,8jf93h,"Diversity Crisis in AI, 2017 edition",https://www.reddit.com/r/MachineLearning/comments/8jf93h/diversity_crisis_in_ai_2017_edition/,molocher,1526327271,,0,1
721,2018-5-15,2018,5,15,5,8jff2z,text cleaning,https://www.reddit.com/r/MachineLearning/comments/8jff2z/text_cleaning/,aazzaa1994,1526328491,[removed],0,1
722,2018-5-15,2018,5,15,5,8jfgs5,Dynamic Control Flow in Large-Scale Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8jfgs5/dynamic_control_flow_in_largescale_machine/,tycho01,1526328848,,0,1
723,2018-5-15,2018,5,15,5,8jfjm8,Should I be concernened about entry level in ML,https://www.reddit.com/r/MachineLearning/comments/8jfjm8/should_i_be_concernened_about_entry_level_in_ml/,MakeAmericaGreat94,1526329424,[removed],0,1
724,2018-5-15,2018,5,15,5,8jfrm4,Microsoft is Investing 25 million dollars to people in disabilities- I want to be a part of this,https://www.reddit.com/r/MachineLearning/comments/8jfrm4/microsoft_is_investing_25_million_dollars_to/,reddittUndecidedEE,1526331075,[removed],0,1
725,2018-5-15,2018,5,15,7,8jghbo,[D] Object detection using CNN: how can I estimate performance of my model on a test dataset without actually having access to it?,https://www.reddit.com/r/MachineLearning/comments/8jghbo/d_object_detection_using_cnn_how_can_i_estimate/,interstellarhighway,1526336813,"I am working on a small Kaggle-like machine learning competition which involves object detection: a training dataset is provided on which models are trained, and the submitted models are evaluated on a test dataset that we don't have access to. The main evaluation metric is the average intersection over union. 

Following the common training/validation split procedure, my first trial was to use 80% of the data available as training and I trained a model using Darknet (YOLO). I used the validation set to compute the mAP at the weights from various iterations and picked the one that gave me the best mAP and IoU values, thus trying to avoid overfitting on the training data. 

A model that gave me about 80% IoU on the validation set resulted in approximately 60% IoU on the test set, and at this point, I had a few questions.

1. Is there a good way to actually estimate how well a model generalizes? I assumed that's technically the job of the validation set because the training does not know these particular images, but it seems to still be learning these particular images way more than new ones.

2. The data is actually frames from videos, thus the images for each class form a sequence. In this case, would there be a difference between randomly picking validation images as opposed to, say, using the last 15 or 20% as the out of sample data for validation? This could make the data 'stranger' to the trained model because the objects could have moved to locations that were not seen before, etc.",2,1
726,2018-5-15,2018,5,15,8,8jgt7d,Prefrontal cortex as a meta-reinforcement learning system | DeepMind,https://www.reddit.com/r/MachineLearning/comments/8jgt7d/prefrontal_cortex_as_a_metareinforcement_learning/,benkitty,1526339710,,0,1
727,2018-5-15,2018,5,15,8,8jgvd2,[R] Prefrontal cortex as a meta-reinforcement learning system,https://www.reddit.com/r/MachineLearning/comments/8jgvd2/r_prefrontal_cortex_as_a_metareinforcement/,TheWittyCat,1526340256,,7,43
728,2018-5-15,2018,5,15,8,8jgy5w,[D] IR on Google Docs texts,https://www.reddit.com/r/MachineLearning/comments/8jgy5w/d_ir_on_google_docs_texts/,datasciguy-aaay,1526340977,"How? Is there no way?

Dumb keyword search is all I seem to get. Horrible search results keep coming out. It's strange because this is the world's foremost IR company. I know they can. What am I missing? Thanks for help. I have accumulated lot of notes in google docs over the years, and I really need to find my shit better.

I feel like I can even write my own app for this. I know some IR. But Google can just come by and do it all better in one day, obviating my work completely, since they have all the data to learn from on their network but I would have to download it first and train a model. See alls I got is 2.7Mb internet. Big downloads of big data ain't happening.

But really I feel like it's there somewhere already; such a feature is Google's meat and potatoes. So help me. Help. Me. I'm dying out here.

",0,1
729,2018-5-15,2018,5,15,8,8jh14r,Need help with predictive modelling,https://www.reddit.com/r/MachineLearning/comments/8jh14r/need_help_with_predictive_modelling/,masked_desi,1526341741,[removed],0,1
730,2018-5-15,2018,5,15,8,8jh3gx,When applying for internships I discovered this is all I really had to say to get an offer.,https://www.reddit.com/r/MachineLearning/comments/8jh3gx/when_applying_for_internships_i_discovered_this/,NotJoshLyman,1526342325,,0,1
731,2018-5-15,2018,5,15,9,8jh85b,RMDL: Random Multimodel Deep Learning for Classification,https://www.reddit.com/r/MachineLearning/comments/8jh85b/rmdl_random_multimodel_deep_learning_for/,kk7nc,1526343497,,0,1
732,2018-5-15,2018,5,15,9,8jh9qj,Interesting: Transcribe Japanese using Go and Machine Learning APIs,https://www.reddit.com/r/MachineLearning/comments/8jh9qj/interesting_transcribe_japanese_using_go_and/,olive_er,1526343886,,0,1
733,2018-5-15,2018,5,15,9,8jhcdo,"[N] Nvidia rides tech's A.I., gaming, machine learning, cryptocurrency waves",https://www.reddit.com/r/MachineLearning/comments/8jhcdo/n_nvidia_rides_techs_ai_gaming_machine_learning/,olive_er,1526344531,,0,0
734,2018-5-15,2018,5,15,9,8jhds5,LARNN: Linear Attention Recurrent Neural Network,https://www.reddit.com/r/MachineLearning/comments/8jhds5/larnn_linear_attention_recurrent_neural_network/,GChe,1526344872,,0,1
735,2018-5-15,2018,5,15,9,8jhfk1,(x-post from learnmachinelearning) I made a basic machine learning game. Tell me what you think!,https://www.reddit.com/r/MachineLearning/comments/8jhfk1/xpost_from_learnmachinelearning_i_made_a_basic/,GakuBot,1526345329,,0,1
736,2018-5-15,2018,5,15,10,8jhisv,Preparing for a data scientist interview,https://www.reddit.com/r/MachineLearning/comments/8jhisv/preparing_for_a_data_scientist_interview/,chai_17,1526346180,[removed],0,1
737,2018-5-15,2018,5,15,11,8ji0qy,[P] Managed/hosted 1080Ti GPU rentals for ML,https://www.reddit.com/r/MachineLearning/comments/8ji0qy/p_managedhosted_1080ti_gpu_rentals_for_ml/,adopshire2016,1526350755,"Hello,

I run a sizable GPU mining farm with hundreds of 1080Ti GPUs used primarily for cryptocurrency mining.

We recently started looking into diversifying our revenue channels by introducing custom server builds with stronger CPUs and RAM and larger HDs to be attractive for machine learning.  We got some interest from video rendering projects but not machine learning.

Is there any interest in this type of service?  If so, what price points and hardware considerations would make this attractive? 
",16,11
738,2018-5-15,2018,5,15,11,8ji4m5,GitHub - RMDL: Random Multimodel Deep Learning for Classification,https://www.reddit.com/r/MachineLearning/comments/8ji4m5/github_rmdl_random_multimodel_deep_learning_for/,kk7nc,1526351736,,0,1
739,2018-5-15,2018,5,15,13,8jivzv,[P] (x-post from learnmachinelearning) I made a basic machine learning game. Tell me what you think!,https://www.reddit.com/r/MachineLearning/comments/8jivzv/p_xpost_from_learnmachinelearning_i_made_a_basic/,GakuBot,1526358995,,8,5
740,2018-5-15,2018,5,15,15,8jjifz,An insight into machine learning for beginners,https://www.reddit.com/r/MachineLearning/comments/8jjifz/an_insight_into_machine_learning_for_beginners/,Soumyadip1995,1526366441,,0,1
741,2018-5-15,2018,5,15,16,8jjm8p,[P] Elitist shuffle for recommendation systems,https://www.reddit.com/r/MachineLearning/comments/8jjm8p/p_elitist_shuffle_for_recommendation_systems/,rragundez,1526367773,,5,15
742,2018-5-15,2018,5,15,16,8jjnqf,An O(N) Sorting Algorithm: Machine Learning Sorting,https://www.reddit.com/r/MachineLearning/comments/8jjnqf/an_on_sorting_algorithm_machine_learning_sorting/,RavlaAlvar,1526368281,,0,1
743,2018-5-15,2018,5,15,16,8jjnup,[R] An O(N) Sorting Algorithm: Machine Learning Sorting,https://www.reddit.com/r/MachineLearning/comments/8jjnup/r_an_on_sorting_algorithm_machine_learning_sorting/,RavlaAlvar,1526368322,,30,11
744,2018-5-15,2018,5,15,17,8jk3fk,Open Letter in Support of Google Employees and Tech Workers,https://www.reddit.com/r/MachineLearning/comments/8jk3fk/open_letter_in_support_of_google_employees_and/,Aegeaner,1526374490,,0,1
745,2018-5-15,2018,5,15,18,8jk6r4,[N] First Workshop on the Convergence of Large Scale Simulation and Artificial Intelligence (in conjunction with ISC High Performance 2018),https://www.reddit.com/r/MachineLearning/comments/8jk6r4/n_first_workshop_on_the_convergence_of_large/,angererc,1526375775,,1,5
746,2018-5-15,2018,5,15,18,8jk816,Deep Learning Applications - Live Session with Mike Tamir (Head of Data Science UBER ATG)- May 16 - 3.30 PM(GMT),https://www.reddit.com/r/MachineLearning/comments/8jk816/deep_learning_applications_live_session_with_mike/,pooja307,1526376276,[removed],0,1
747,2018-5-15,2018,5,15,18,8jk8l5,AI and Machine Learning in Software Development: How it Can Benefit Developers,https://www.reddit.com/r/MachineLearning/comments/8jk8l5/ai_and_machine_learning_in_software_development/,rayparker1,1526376493,,0,1
748,2018-5-15,2018,5,15,18,8jk8wb,Commercial Use Sesame Seeds Washing And Drying Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8jk8wb/commercial_use_sesame_seeds_washing_and_drying/,Machineprices,1526376604,,1,1
749,2018-5-15,2018,5,15,18,8jkdbo,Deep Learning Applications - Live Session with Mike Tamir (Head of Data Science UBER ATG)- May 16,https://www.reddit.com/r/MachineLearning/comments/8jkdbo/deep_learning_applications_live_session_with_mike/,pooja307,1526378259,,0,1
750,2018-5-15,2018,5,15,19,8jkezn,How VC Firms Are Using Machine Learning to Make Robust Investment Decisions,https://www.reddit.com/r/MachineLearning/comments/8jkezn/how_vc_firms_are_using_machine_learning_to_make/,dexlabanalytics,1526378838,,0,1
751,2018-5-15,2018,5,15,19,8jkii3,Fully distribution in hadoop ecosystem,https://www.reddit.com/r/MachineLearning/comments/8jkii3/fully_distribution_in_hadoop_ecosystem/,tmclouisluk,1526380030,[removed],0,1
752,2018-5-15,2018,5,15,19,8jkjs4,Machine Learning and Internet of Things,https://www.reddit.com/r/MachineLearning/comments/8jkjs4/machine_learning_and_internet_of_things/,fullstackanalytics1,1526380499,,0,1
753,2018-5-15,2018,5,15,20,8jkz2w,A Neural Network Model That Can Reason,https://www.reddit.com/r/MachineLearning/comments/8jkz2w/a_neural_network_model_that_can_reason/,baDoxx,1526385360,,0,1
754,2018-5-15,2018,5,15,20,8jkzh0,How do I choose the architecture of my CNN?,https://www.reddit.com/r/MachineLearning/comments/8jkzh0/how_do_i_choose_the_architecture_of_my_cnn/,ZER_0_NE,1526385467,[removed],0,1
755,2018-5-15,2018,5,15,21,8jl149,[R] Adversarial Task Transfer from Preference,https://www.reddit.com/r/MachineLearning/comments/8jl149/r_adversarial_task_transfer_from_preference/,jeasinema,1526385902,,0,2
756,2018-5-15,2018,5,15,21,8jl7cs,"Video analysis : what is the difference between Optical flow, Particle flow and Streak flow ?",https://www.reddit.com/r/MachineLearning/comments/8jl7cs/video_analysis_what_is_the_difference_between/,DevilPenber,1526387599,[removed],0,1
757,2018-5-15,2018,5,15,21,8jl94p,[R] Restricted Recurrent Neural Tensor Networks: Exploiting Word Frequency and Compositionality,https://www.reddit.com/r/MachineLearning/comments/8jl94p/r_restricted_recurrent_neural_tensor_networks/,serveboy,1526388104,,0,1
758,2018-5-15,2018,5,15,21,8jl9g2,To ArxiV or not after submission to NIPS as a nobody solo writer?,https://www.reddit.com/r/MachineLearning/comments/8jl9g2/to_arxiv_or_not_after_submission_to_nips_as_a/,mila_lab_applicant,1526388188,"So I wrote my first AI paper (not my first paper, I wrote a few papers in statistics already) and submitted it to NIPS. I'm a nobody in the field so far (not working in AI, no PhD) and I wrote this solo. 

I'm wondering if I should put it on ArXiv or if I should wait after the review (it's in like 2 months and a half, I could get scooped although I think it's unlikely). I'm just wondering if knowing that a random girl wrote this paper alone might bias reviewers? I know for a fact that researchers from big companies or labs are better off putting it on ArXiv before review because reviewers may be nicer but does the opposite happens? Is there a negative bias if the reviewer know that you are a nobody solo writer versus not knowing who and how many wrote it? Your thoughts?

I'm also pretty scared considered it's my first paper in another field without any reviewing help from collaborators so my impostor syndrome is flaring up... Still, I want to make the best decision.",0,1
759,2018-5-15,2018,5,15,21,8jld40,[D] To ArxiV or not after submission to NIPS as a nobody solo writer?,https://www.reddit.com/r/MachineLearning/comments/8jld40/d_to_arxiv_or_not_after_submission_to_nips_as_a/,mila_lab_applicant,1526389131,"So I wrote my first AI paper (not my first paper, I wrote a few papers in statistics already) and submitted it to NIPS. I'm a nobody in the field so far (not working in AI, no PhD) and I wrote this solo. 

I'm wondering if I should put it on ArXiv or if I should wait after the review (it's in like 2 months and a half, I could get scooped although I think it's unlikely). I'm just wondering if knowing that a random girl wrote this paper alone might bias reviewers? I know for a fact that researchers from big companies or labs are better off putting it on ArXiv before review because reviewers may be nicer but does the opposite happens? Is there a negative bias if the reviewer know that you are a nobody solo writer versus not knowing who and how many wrote it? Your thoughts?

I'm also pretty scared considered it's my first paper in another field without any reviewing help from collaborators so my impostor syndrome is flaring up... Still, I want to make the best decision.",44,110
760,2018-5-15,2018,5,15,22,8jljjd,Essential Cheat Sheets for Machine Learning and Deep Learning Engineers,https://www.reddit.com/r/MachineLearning/comments/8jljjd/essential_cheat_sheets_for_machine_learning_and/,TJ1,1526390681,,0,1
761,2018-5-15,2018,5,15,23,8jlwsp,[N] SJTU Develops Worlds Largest 3D Photonic Quantum Chip,https://www.reddit.com/r/MachineLearning/comments/8jlwsp/n_sjtu_develops_worlds_largest_3d_photonic/,gwen0927,1526393837,,0,1
762,2018-5-15,2018,5,15,23,8jlzej,Autoencoders with Keras,https://www.reddit.com/r/MachineLearning/comments/8jlzej/autoencoders_with_keras/,ramhiser,1526394421,,0,1
763,2018-5-16,2018,5,16,0,8jmf92,[D] How are the linear algebra operations implemented in Tensorflow.js?,https://www.reddit.com/r/MachineLearning/comments/8jmf92/d_how_are_the_linear_algebra_operations/,ConfuciusBateman,1526397853,"I've been doing some digging to see where exactly the tensor operations are implemented in the Typescript version of Tensorflow but I'm not sure if I've found it. There's a `tensor.ts` file in the repo, but there are references in the documentation to a ""GPU-accelerated linear algebra library"" so I'm wondering where/what exactly that is.

Can anyone point me in the right direction? I'd like to see how this JS library handle the linear algebra stuff.",1,2
764,2018-5-16,2018,5,16,0,8jmjkw,Synthetic Data for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8jmjkw/synthetic_data_for_deep_learning/,rosstaylor90,1526398781,,0,1
765,2018-5-16,2018,5,16,0,8jmmfz,How good is Rutgers in Machine Learning research?,https://www.reddit.com/r/MachineLearning/comments/8jmmfz/how_good_is_rutgers_in_machine_learning_research/,reallysmartbot,1526399364,,0,1
766,2018-5-16,2018,5,16,0,8jmn87,[D] Infinite Training Data for AI,https://www.reddit.com/r/MachineLearning/comments/8jmn87/d_infinite_training_data_for_ai/,rstoj,1526399542,,5,1
767,2018-5-16,2018,5,16,1,8jmxeg,How good is Rutgers in Machine Learning research?,https://www.reddit.com/r/MachineLearning/comments/8jmxeg/how_good_is_rutgers_in_machine_learning_research/,reallysmartbot,1526401689,[removed],0,1
768,2018-5-16,2018,5,16,1,8jn4cm,(x-post from /r/artificial) Career path question,https://www.reddit.com/r/MachineLearning/comments/8jn4cm/xpost_from_rartificial_career_path_question/,radikal_shit_ml,1526403116,[removed],0,1
769,2018-5-16,2018,5,16,2,8jng5r,any news after the rebuttal of MICCAI 2018,https://www.reddit.com/r/MachineLearning/comments/8jng5r/any_news_after_the_rebuttal_of_miccai_2018/,STD_Life_long,1526405518,[removed],0,1
770,2018-5-16,2018,5,16,2,8jnhn1,The Association Between Early ArXiv Posting and Citations,https://www.reddit.com/r/MachineLearning/comments/8jnhn1/the_association_between_early_arxiv_posting_and/,sergeyfeldman,1526405824,,0,1
771,2018-5-16,2018,5,16,3,8jnod0,[D] 11 questions to ask yourself before applying Machine Learning to your business,https://www.reddit.com/r/MachineLearning/comments/8jnod0/d_11_questions_to_ask_yourself_before_applying/,minmidinosaur,1526407256,,0,1
772,2018-5-16,2018,5,16,3,8jnpt4,[P] How to Install TensorFlow on the Raspberry Pi,https://www.reddit.com/r/MachineLearning/comments/8jnpt4/p_how_to_install_tensorflow_on_the_raspberry_pi/,Taxi-guy,1526407558,,19,160
773,2018-5-16,2018,5,16,3,8jnzwt,[D] Horse Race Winner Prediction (89% Precision - 80% AUC average),https://www.reddit.com/r/MachineLearning/comments/8jnzwt/d_horse_race_winner_prediction_89_precision_80/,digitalice,1526409604,"I recently came across [this article](https://www.bloomberg.com/news/features/2018-05-03/the-gambler-who-cracked-the-horse-racing-code) about horse races prediction. I created a model to predict horse races in my country \(logistic regression and lasso regularization\) based on the paper **""Searching for Positive Returns at the Track""**\([link](https://www.researchgate.net/publication/292145708_Searching_for_Positive_Returns_at_the_Track)\). I'm using the same features used in that paper and got a 89&amp;#37; precision \(80.8&amp;#37; area under the curve average\) logit model \(20 folds, stratified cross\-validation\).

I would like to know if this can be improved! Some people mentions that domain is very ""noisy"" and would like to know how do you filter outliers. Here is the dataset that I'm using: [horses.zip](https://drive.google.com/open?id=1XoSV2E8omsF0L3a3X9KLIKJ4pmzLOxuN) \(Attributes are the same described on the paper\). You guys can use the **winner** column to do a classification or th**e resu**lt column to do a regression. Feel free to share your results!

Thanks!",14,0
774,2018-5-16,2018,5,16,4,8jo7ej,[Problem] Which model to use,https://www.reddit.com/r/MachineLearning/comments/8jo7ej/problem_which_model_to_use/,niksnikson,1526411083,[removed],0,1
775,2018-5-16,2018,5,16,4,8jojjd,What if AI makes play too predictable?,https://www.reddit.com/r/MachineLearning/comments/8jojjd/what_if_ai_makes_play_too_predictable/,stinkytofu415,1526413565,,0,1
776,2018-5-16,2018,5,16,5,8joqw2,[R] Introducing state of the art text classification with universal language models,https://www.reddit.com/r/MachineLearning/comments/8joqw2/r_introducing_state_of_the_art_text/,desku,1526415102,,5,37
777,2018-5-16,2018,5,16,5,8joufj,[P] Multi-class Object Detection on Nvidia Jetson TK1,https://www.reddit.com/r/MachineLearning/comments/8joufj/p_multiclass_object_detection_on_nvidia_jetson_tk1/,alessandromarchetti,1526415858,"Hi, I'm starting this project for my final year Msc thesis and, before giving official confirmation, I've been searching and reading papers, blogs, forums to evaluate the possible solutions and whether they might be viable or not.

The project is for a Smart Adapter which connects to an IP camera and does object detection through a configurable Neural Network, outputting relevant data through binary or parsable format. An example they showed me was from traffic static road cameras, where all the detection was done on a server.

The supervisor proposed the use of an Nvidia Jetson TK1 (which they have in the laboratory), since it has the advantage of being low powered and low-cost. My idea was to start and try and use YOLOv3 pretrained models (normal or tiny) over darknet and then try to train it on a dataset like UA-DETRAC, for the roads use case. I thought about tensorflow with other algorithms but my guess is that I would have less speed performance.

I know from start that I won't get real time detection but what about reaching 7-8 fps? Maybe with the custom trained tiny model I could have acceptable detecting performance?

MOST IMPORTANT QUESTION, PLEASE, RELATED TO TRAINING (NOT JETSON TK1): I couldn't find any relevant info on YOLOv3 normal/tiny models training time with darknet, I would like to do it on the UA-DETRAC dataset with ~80.000 images with multiple tagged boxes. Could I do it with a gtx 970 in a reasonable time or would it take days, if not weeks? In the latter case, are there online services which offer cuDNN enabled linux boxes for darknet training?

Thanks for any answer you might give :)",0,1
778,2018-5-16,2018,5,16,5,8joy2z,[P] Multi-class Object Detection on Nvidia Jetson TK1,https://www.reddit.com/r/MachineLearning/comments/8joy2z/p_multiclass_object_detection_on_nvidia_jetson_tk1/,alessandromarchetti,1526416655,"Hi, I'm starting this project for my final year Msc thesis and, in the last 6-7 days, I've been searching and reading papers, blogs, forums to evaluate the possible solutions and whether they might be viable or not.

The proposed project is for a first prototype of a Smart Adapter which connects to an IP camera and does object detection through a configurable Neural Network, outputting relevant data through binary or parsable format. As a matter of fact they didn't mention tracking but that's a problem I think I'll have to address too, if I'll want to include that kind of data too. An example they showed me was from traffic aerial static road cameras, where all the detection was done on a server so that might be a use case on which I might work.

The supervisor proposed the use of an Nvidia Jetson TK1 (which they have in the laboratory), since it has the advantage of being low powered and low-cost. My idea was to start and try and use YOLOv3 pretrained models (normal or tiny) over darknet and then try to train it on a dataset like UA-DETRAC, for the roads use case. I thought about tensorflow with other algorithms but my guess is that I would have less fps performance.

I know from start that I won't get real time detection but what about reaching 7-8 fps? Maybe with the custom trained tiny model do you think I could have acceptable detecting and fps performance?

MOST IMPORTANT QUESTION, PLEASE, RELATED TO OFFLINE TRAINING: I couldn't find any relevant info on YOLOv3 normal/tiny models training time with darknet, I would like to do it on the UA-DETRAC dataset with ~80.000 images with multiple tagged boxes. Could I do it with a gtx 970 in a reasonable time or would it take days, if not weeks? In the latter case, are there online services which offer linux workstations with CUDA and cuDNN gpus for darknet training?

Thanks for any answer you might give :)",11,6
779,2018-5-16,2018,5,16,6,8jp7fd,Hyperparameter Optimization with Keras  Towards Data Science,https://www.reddit.com/r/MachineLearning/comments/8jp7fd/hyperparameter_optimization_with_keras_towards/,mikkokotila,1526418592,,0,1
780,2018-5-16,2018,5,16,6,8jp8zx,[D] NIPS page limit,https://www.reddit.com/r/MachineLearning/comments/8jp8zx/d_nips_page_limit/,fixed-point-learning,1526418949,Is it 8 pages or 9 pages? Author guidelines indicate 8 pages but last year's papers are 9 pages long.,6,3
781,2018-5-16,2018,5,16,6,8jpau1,Learning from Tutorials,https://www.reddit.com/r/MachineLearning/comments/8jpau1/learning_from_tutorials/,saa14,1526419307,"What are some things to do while following a tutorial to make it your own rendition? 

I feel like in most tutorials I either just keep doing what the tutorial did or make only small deviations from it.

What are the things to do to make something new from following a machine learning tutorial?",0,1
782,2018-5-16,2018,5,16,6,8jpefu,[P] 3D reconstruction with neural networks,https://www.reddit.com/r/MachineLearning/comments/8jpefu/p_3d_reconstruction_with_neural_networks/,micmelesse,1526420095,"I have always wanted to contribute to this subreddit. This is my senior thesis, which is a year long independent project that I have been working on which includes a write up. I just submitted the final version and I wanted to share before losing my nerve. Here is a link to the [Github](https://github.com/micmelesse/3D-reconstruction-with-Neural-Networks), a [Youtube](https://www.youtube.com/watch?v=iI6ZMST8Ri0) video of the network over 40 epochs and a [PDF](https://github.com/micmelesse/3D-reconstruction-with-Neural-Networks/blob/master/3D_reconstruction_with_neural_networks.pdf} of the write up. I hope someone finds this useful in someway. Advice is always welcome.  ",28,127
783,2018-5-16,2018,5,16,6,8jpg9e,[D] Good Machine Learning Artists to follow?,https://www.reddit.com/r/MachineLearning/comments/8jpg9e/d_good_machine_learning_artists_to_follow/,DaggerFallisbest,1526420498,"Don't know if this is the right place to ask but can you all recommend me some good people to follow who are making artwork with machine learning? I know of Mario Klingeman \(@Quasimondo on twitter\), who else is there?",7,5
784,2018-5-16,2018,5,16,6,8jphsw,how to extract plain text from .docx file using R,https://www.reddit.com/r/MachineLearning/comments/8jphsw/how_to_extract_plain_text_from_docx_file_using_r/,aazzaa1994,1526420816,[removed],0,1
785,2018-5-16,2018,5,16,6,8jpkhr,[R] Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,https://www.reddit.com/r/MachineLearning/comments/8jpkhr/r_recasting_gradientbased_metalearning_as/,rikkajounin,1526421421,[removed],0,1
786,2018-5-16,2018,5,16,7,8jpmb6,[D] Annoying Prints when running on windows,https://www.reddit.com/r/MachineLearning/comments/8jpmb6/d_annoying_prints_when_running_on_windows/,oddeysiss,1526421816,"I've started doing some topic modeling with gensim on my home pc, which runs Windows 10. Specifically, I'm using gensim's ldamulticore model. Whenever I train a model, the phrase ""Using TensorFlow backend."" is printed a multiple of the number of threads I'm running.

Does anyone know how to stop this behavior? Thanks!",1,0
787,2018-5-16,2018,5,16,9,8jqsh7,[Discussion] When dealing with (extremely) small datasets: better to report performance on a hold out test set? Or average performance across various train/test splits?,https://www.reddit.com/r/MachineLearning/comments/8jqsh7/discussion_when_dealing_with_extremely_small/,tardy_har,1526431931,"So in some ways this is an absurd question, but it's actually got me thinking, and I'm curious what people have to say.

Let's say you're trying to build a classifier with an N of 25 (12/13 posiitive/negative split). The goal here is exploratory - no intention of putting a model into production, only to report out whether we have any ability to predict our target variable with the data we've collected.  (This is all we have right now and its expensive/difficult to collect more.  Oh, and we expect things to be noisy).

Now, best practice for building a classifier (as I learned it) is to split your data into train/test sets, run k-fold cross-validation *within* the training set to build the model, and finally, evaluate that model on the hold out test set.  But in this scenario, that would mean you're reporting out performance based on what, 4 examples from each class?  

This seems problematic -- maybe you get lucky and those 4 positive examples are clear cases, so you get an AUC of 1.  But do you really want to report that back to senior management and let them get all excited to dump more $$$ (and expectations) into this project?  (and vice versa if you end up with an AUC of 0.5?)

So an alternative is to repeat the process many times, shuffling the train/test split.  Then plot the mean ROC and calculate the AUC from that.  This gives a more complete view of ""within these 25 samples, our predictive power with these features is X"".  The problem here is that *each of those models is different*.  So maybe your average AUC is pretty good, but if you dig into it, the coefficients and/or hyperparameters are varying wildly across all those different models.  It seems like that should give you pause, whereas if the model is pretty stable, thats a sign it will generalize well to future data.  Is there a way to quantify this variability though?  

Mostly I'm just curious what people think - all of the ML I've done thus far has been on sufficiently large datasets to just report out results on a single test set. ",14,7
788,2018-5-16,2018,5,16,9,8jqst9,[R] Born Again Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8jqst9/r_born_again_neural_networks/,hardmaru,1526432009,,25,81
789,2018-5-16,2018,5,16,10,8jr7xs,A Purely Functional Typed Approach to Trainable Models (Differentiable Programming in Haskell),https://www.reddit.com/r/MachineLearning/comments/8jr7xs/a_purely_functional_typed_approach_to_trainable/,deltaSquee,1526435636,,0,1
790,2018-5-16,2018,5,16,11,8jra25,[R] On the Practical Computational Power of Finite Precision RNNs for Language Recognition,https://www.reddit.com/r/MachineLearning/comments/8jra25/r_on_the_practical_computational_power_of_finite/,wei_jok,1526436139,,3,6
791,2018-5-16,2018,5,16,11,8jrbma,"[D] Google, Amazon, and Facebook Owe Jrgen Schmidhuber a Fortune",https://www.reddit.com/r/MachineLearning/comments/8jrbma/d_google_amazon_and_facebook_owe_jrgen/,baylearn,1526436513,,45,45
792,2018-5-16,2018,5,16,11,8jred4, ? - ,https://www.reddit.com/r/MachineLearning/comments/8jred4/_/,Woodworking94,1526437184,,1,1
793,2018-5-16,2018,5,16,13,8js9lj,[N] 'Do You Trust This Computer Gets a Whole Lot Wrong About AI Risks,https://www.reddit.com/r/MachineLearning/comments/8js9lj/n_do_you_trust_this_computer_gets_a_whole_lot/,regalalgorithm,1526445766,,3,7
794,2018-5-16,2018,5,16,13,8jsb3m,[D] Graph Neural Networks on Images.,https://www.reddit.com/r/MachineLearning/comments/8jsb3m/d_graph_neural_networks_on_images/,finspire13,1526446256,Is there any work that applies graph neural networks to image classification or segmentation? I found no such work by a quick literature search..,2,1
795,2018-5-16,2018,5,16,14,8jsgfo,Machine learning,https://www.reddit.com/r/MachineLearning/comments/8jsgfo/machine_learning/,AliceHughes1,1526448019,,0,1
796,2018-5-16,2018,5,16,14,8jsj0g,[R] An $O(N)$ Sorting Algorithm: Machine Learning Sorting,https://www.reddit.com/r/MachineLearning/comments/8jsj0g/r_an_on_sorting_algorithm_machine_learning_sorting/,jeasinema,1526448865,,0,1
797,2018-5-16,2018,5,16,14,8jslw3,Multiple Regression Sliding Window Forecasting,https://www.reddit.com/r/MachineLearning/comments/8jslw3/multiple_regression_sliding_window_forecasting/,Thistleknot,1526449857,[removed],0,1
798,2018-5-16,2018,5,16,15,8jsulf,A little help from my friends ? CNN for robotic control,https://www.reddit.com/r/MachineLearning/comments/8jsulf/a_little_help_from_my_friends_cnn_for_robotic/,UpstairsCurrency,1526452989,[removed],0,1
799,2018-5-16,2018,5,16,15,8jsusb,"Out put win, draw or lose but data inlcude more accurate output",https://www.reddit.com/r/MachineLearning/comments/8jsusb/out_put_win_draw_or_lose_but_data_inlcude_more/,UserWithComputer,1526453049,[removed],0,1
800,2018-5-16,2018,5,16,16,8jt0mh,"[P] ""I Pity the fool"", Deep Learning style",https://www.reddit.com/r/MachineLearning/comments/8jt0mh/p_i_pity_the_fool_deep_learning_style/,rragundez,1526455125,,5,5
801,2018-5-16,2018,5,16,16,8jt13c,Adventures of a Data Detective,https://www.reddit.com/r/MachineLearning/comments/8jt13c/adventures_of_a_data_detective/,StillSilc,1526455303,,0,1
802,2018-5-16,2018,5,16,16,8jt512,[R] Over 95% accuracy on MNIST data-set with basic neural network and only 1000 labeled examples,https://www.reddit.com/r/MachineLearning/comments/8jt512/r_over_95_accuracy_on_mnist_dataset_with_basic/,kilik821,1526456837,,6,0
803,2018-5-16,2018,5,16,17,8jt9bt,[R] Learning to See in the Dark,https://www.reddit.com/r/MachineLearning/comments/8jt9bt/r_learning_to_see_in_the_dark/,astrange,1526458537,,10,141
804,2018-5-16,2018,5,16,17,8jtcf4,Fiber laser cutting technology,https://www.reddit.com/r/MachineLearning/comments/8jtcf4/fiber_laser_cutting_technology/,Messer-123,1526459754,,0,1
805,2018-5-16,2018,5,16,19,8jtvz8,How Machine Learning Is Changing the World -- and Your Everyday Life,https://www.reddit.com/r/MachineLearning/comments/8jtvz8/how_machine_learning_is_changing_the_world_and/,Newpath-WEB,1526466984,,0,1
806,2018-5-16,2018,5,16,19,8jtxcp,"Setting up NVIDIA GPU for deep learning: Installation of NVIDIA drivers, CUDA Toolkit and cuDNN in Ubuntu.",https://www.reddit.com/r/MachineLearning/comments/8jtxcp/setting_up_nvidia_gpu_for_deep_learning/,MLLearners,1526467484,,0,1
807,2018-5-16,2018,5,16,19,8jtxjc,Cds | DVD Cellophane Wrapping Machine,https://www.reddit.com/r/MachineLearning/comments/8jtxjc/cds_dvd_cellophane_wrapping_machine/,lgsherry,1526467547,,1,1
808,2018-5-16,2018,5,16,20,8ju363,Question About ROC Area,https://www.reddit.com/r/MachineLearning/comments/8ju363/question_about_roc_area/,Jello_Squid,1526469419,[removed],0,1
809,2018-5-16,2018,5,16,20,8ju3do,Is it possible to make a Rubik's cube solver using Neuroevolution ?,https://www.reddit.com/r/MachineLearning/comments/8ju3do/is_it_possible_to_make_a_rubiks_cube_solver_using/,Ncell50,1526469485,[removed],0,1
810,2018-5-16,2018,5,16,20,8ju41p,Fully Automatic Vermicelli Making Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/8ju41p/fully_automatic_vermicelli_making_machine_for_sale/,lgsherry,1526469686,,1,1
811,2018-5-16,2018,5,16,20,8ju5k5,Practical Machine learning using R training,https://www.reddit.com/r/MachineLearning/comments/8ju5k5/practical_machine_learning_using_r_training/,rajesh19944,1526470154,[removed],0,1
812,2018-5-16,2018,5,16,20,8juaww,Fixed point convergence and contraction mapping T applied to Q-learning [university CS],https://www.reddit.com/r/MachineLearning/comments/8juaww/fixed_point_convergence_and_contraction_mapping_t/,Betelgeuse999,1526471689,,0,1
813,2018-5-16,2018,5,16,21,8jui13,Fixed point convergence and contraction mapping T applied to Q-learning [university CS],https://www.reddit.com/r/MachineLearning/comments/8jui13/fixed_point_convergence_and_contraction_mapping_t/,Betelgeuse999,1526473571,,0,1
814,2018-5-16,2018,5,16,21,8juidk,[D] Why ML interfaces will be more like pets than machines,https://www.reddit.com/r/MachineLearning/comments/8juidk/d_why_ml_interfaces_will_be_more_like_pets_than/,speckz,1526473664,,1,0
815,2018-5-16,2018,5,16,22,8jupot,What are the best current practices for designing CNNs?,https://www.reddit.com/r/MachineLearning/comments/8jupot/what_are_the_best_current_practices_for_designing/,Traner,1526475627,[removed],0,1
816,2018-5-16,2018,5,16,22,8jut54,The Best of AI: best articles published last month,https://www.reddit.com/r/MachineLearning/comments/8jut54/the_best_of_ai_best_articles_published_last_month/,pierremarcenac,1526476470,,0,1
817,2018-5-16,2018,5,16,22,8juty0,[D] Regularizing and Stabilizing RNN,https://www.reddit.com/r/MachineLearning/comments/8juty0/d_regularizing_and_stabilizing_rnn/,ShivamDuggal4,1526476677,"IRNN: Initializing RNN's recurrent weight matrix(Whh) with the identity matrix.
I have following doubts: 

1. Initializing the Whh with identity does not ensure that after few iterations the Whh would remain identity matrix and would not vanish or explode. Am I right? This might be a silly question, still, want to clear my doubt.

2. I have also read a regularization technique which tries to reduce the difference b/w the norms of adjacent hidden state vectors. Isn't this a better technique to stabilize the RNNs, as this would try to ensure that Whh remains orthogonal all the way throughout the training?

",0,1
818,2018-5-16,2018,5,16,22,8juxeq,"Multiple Regression Sliding Window Forecasting, SemanticFilter",https://www.reddit.com/r/MachineLearning/comments/8juxeq/multiple_regression_sliding_window_forecasting/,Thistleknot,1526477508,,1,1
819,2018-5-16,2018,5,16,22,8jv012,On offering advice to aspiring scientists,https://www.reddit.com/r/MachineLearning/comments/8jv012/on_offering_advice_to_aspiring_scientists/,__Julia,1526478146,,0,1
820,2018-5-16,2018,5,16,22,8jv1ju,Tensorflow Implementation of Recurrent Convolutional Neural Network for Relation Extraction,https://www.reddit.com/r/MachineLearning/comments/8jv1ju/tensorflow_implementation_of_recurrent/,roomylee,1526478498,,0,1
821,2018-5-16,2018,5,16,22,8jv3mn,[P] Intro to neural text generation and conditional language models (Keras),https://www.reddit.com/r/MachineLearning/comments/8jv3mn/p_intro_to_neural_text_generation_and_conditional/,galton1,1526478965,,0,0
822,2018-5-16,2018,5,16,22,8jv4ln,[P] Recurrent Convolutional Neural Network for Relation Extraction (Tensorflow),https://www.reddit.com/r/MachineLearning/comments/8jv4ln/p_recurrent_convolutional_neural_network_for/,roomylee,1526479194,,1,2
823,2018-5-16,2018,5,16,23,8jvd4k,[P] Multiple Regression Sliding Window Forecast using Federal Reserve Data and R,https://www.reddit.com/r/MachineLearning/comments/8jvd4k/p_multiple_regression_sliding_window_forecast/,Thistleknot,1526481069,"What is it?

\* I used IBM SPSS to factor reduce \(using regression analysis\) 77 datasets from FRED down to 22.  

\* Back\-filled NA data with interpolated averages.  Joined by date, etc.  

\* Then I offset the desired predicted value by 1 \(in this case the next reporting period's value\) row and copied to ""future"" column.

\* Each value is tracked up to the past 4 records as well.  So there is an oversampling occurring.  I do this to capture the movement of the value\-\-over the most recent time period\-\-in the record.

I plan on extending this to logistic binary regression as well as pca.  I don't plan on stopping at gold.

Commit: [https://github.com/thistleknot/FredAPIR/commit/afa1cce74326049da7a80a56db0165ddb75ba493](https://github.com/thistleknot/FredAPIR/commit/afa1cce74326049da7a80a56db0165ddb75ba493)

In this case I'm tracking Gold, I've had better results with the national housing price \(which is pretty mild in comparison to gold fluctuations\).  

The purple drawn line is the expected value, the top and bottom lines are the 90&amp;#37; band of the prediction value.

Output:

[https://imgur.com/gEAsozj](https://imgur.com/gEAsozj)",9,0
824,2018-5-16,2018,5,16,23,8jvgu1,[P] Exercise classes - Map Reduce implementations of Machine Learning algorithms from scratch,https://www.reddit.com/r/MachineLearning/comments/8jvgu1/p_exercise_classes_map_reduce_implementations_of/,chilled_87,1526481894,"Hello, I am assistant for a course on Big Data analytics, and wanted to show students how algorithms like ordinary least squares, gradient descent, k-means and alternating least squares can be implemented from scratch using numpy, and adapted to scalable implementations using map/reduce and Spark. 

Since I could not find tutorials for this on the net, I created my own notebooks, and share the content on Github (classes 2, 3 and 4). I thought that might be interest to some of you in this sub. 

See https://github.com/Yannael/BigDataAnalytics_INFOH515

Any feedback on how to improve it is welcome.
  ",3,32
825,2018-5-16,2018,5,16,23,8jvhj7,The sound of a pixel,https://www.reddit.com/r/MachineLearning/comments/8jvhj7/the_sound_of_a_pixel/,sarpit,1526482053,[removed],0,1
826,2018-5-17,2018,5,17,0,8jvlna,"""[Research]"" The Sound of a pixel",https://www.reddit.com/r/MachineLearning/comments/8jvlna/research_the_sound_of_a_pixel/,sarpit,1526482940,This is a [paper](https://arxiv.org/pdf/1804.03160.pdf) by MIT. They are introducing a player called PixelPlayer. This player with the help of lots of unlabeled videos learns to locate image regions which produce sounds and separate the input sounds into a set of components that represents the sound from each pixel,1,7
827,2018-5-17,2018,5,17,0,8jvm0y,Generating audio from midi files,https://www.reddit.com/r/MachineLearning/comments/8jvm0y/generating_audio_from_midi_files/,lexanderpl,1526483015,[removed],0,1
828,2018-5-17,2018,5,17,0,8jvn8h,Machine Learning algorithms: Working with text data,https://www.reddit.com/r/MachineLearning/comments/8jvn8h/machine_learning_algorithms_working_with_text_data/,acarik,1526483255,,0,1
829,2018-5-17,2018,5,17,0,8jvrjj,How to improve speed during test on validation set?,https://www.reddit.com/r/MachineLearning/comments/8jvrjj/how_to_improve_speed_during_test_on_validation_set/,XsentiusIroh,1526484164,[removed],0,1
830,2018-5-17,2018,5,17,0,8jw127,Two of Goodfellow's favorite theory hacks,https://www.reddit.com/r/MachineLearning/comments/8jw127/two_of_goodfellows_favorite_theory_hacks/,BastiatF,1526486154,[removed],0,1
831,2018-5-17,2018,5,17,0,8jw12c,"Simple Questions Thread May 16, 2018",https://www.reddit.com/r/MachineLearning/comments/8jw12c/simple_questions_thread_may_16_2018/,AutoModerator,1526486156,[removed],0,1
832,2018-5-17,2018,5,17,1,8jw8pm,Department of Energy seeks input on machine learning for Geothermal Energy and the Geosciences,https://www.reddit.com/r/MachineLearning/comments/8jw8pm/department_of_energy_seeks_input_on_machine/,300degF,1526487730,,0,1
833,2018-5-17,2018,5,17,1,8jw8uf,State-of-the-art benchmarks for data science prediction tasks?,https://www.reddit.com/r/MachineLearning/comments/8jw8uf/stateoftheart_benchmarks_for_data_science/,mikkokotila,1526487754,[removed],0,1
834,2018-5-17,2018,5,17,2,8jwkw9,[D] Identity initialization of RNN,https://www.reddit.com/r/MachineLearning/comments/8jwkw9/d_identity_initialization_of_rnn/,ShivamDuggal4,1526490192,"Why is identity initialization of recurrent matrix of RNN a problem, as mentioned in the paper: https://arxiv.org/pdf/1412.7753.pdf
There is a similar Reddit post on it but I couldn't understand the reason. https://www.reddit.com/r/MachineLearning/comments/41kd6a/why_is_a_simple_recurrent_neural_network_with_an/
",3,0
835,2018-5-17,2018,5,17,2,8jwlc8,"""AI and Compute"" {OA} [computing resources used in DL/DRL doubling every 3.5x months: AlexNet ~&gt; AlphaGo Zero = 300,000x increase]",https://www.reddit.com/r/MachineLearning/comments/8jwlc8/ai_and_compute_oa_computing_resources_used_in/,gwern,1526490276,,0,1
836,2018-5-17,2018,5,17,2,8jwoj1,[R] Call for posters: Workshop on machine learning and programming languages,https://www.reddit.com/r/MachineLearning/comments/8jwoj1/r_call_for_posters_workshop_on_machine_learning/,dac22219,1526490917,,0,6
837,2018-5-17,2018,5,17,2,8jwq1g,"[N] State-of-the-art Computer Vision models (detection, segmentation, classification) with MXNet Gluon CV toolkit - x-post r/mxnet",https://www.reddit.com/r/MachineLearning/comments/8jwq1g/n_stateoftheart_computer_vision_models_detection/,thomasdlt,1526491220,,6,184
838,2018-5-17,2018,5,17,2,8jx0lc,[D] Google AI Blog: Smart Compose: Using Neural Networks to Help Write Emails,https://www.reddit.com/r/MachineLearning/comments/8jx0lc/d_google_ai_blog_smart_compose_using_neural/,sksq9,1526493369,,15,41
839,2018-5-17,2018,5,17,3,8jx2sn,"Deep Text Summarization: on Amazon reviews, Github issues and news articles",https://www.reddit.com/r/MachineLearning/comments/8jx2sn/deep_text_summarization_on_amazon_reviews_github/,tttttm,1526493820,,1,1
840,2018-5-17,2018,5,17,3,8jx3bq,Free Webinar - How to Land Your First Data Science Job,https://www.reddit.com/r/MachineLearning/comments/8jx3bq/free_webinar_how_to_land_your_first_data_science/,randylaosat,1526493932,"How to land your first #DataScience Job?

Get all of your major questions answered and obtain valuable insights from Kyle McKiou at our next Webinar Series this Saturday!

- - -
 Mark your Calendar - May 19, 2018 (@ 5:30 PM PST)

 Register Here - https://dataapplab.zoom.us//4415/WN_55vA24M-R4ufFcMvHBi4eg

 These are some of the questions to keep in mind:
1. But what does a data scientist actually do?
2. How can you break into the profession? 
3. What skills would you need to do so? 
4. Where are the jobs?

- - -
Thanks to our team at IDEAS, I'll be hosting this one hour webinar and it'll be a live Q/A session, featuring important questions asked by: YOU!

Prepare your questions, get your notes out, and grab some popcorn. Because this is a one-of-a-kind webinar you do not want to miss!

Really excited about this, and big thanks to Kyle for taking his time to spend an hour with us to answer any questions about Data Science and Machine Learning.

Connect with me on LinkedIn for more information: https://www.linkedin.com/in/randylaosat",0,1
841,2018-5-17,2018,5,17,3,8jx5li,ultrasound dataset,https://www.reddit.com/r/MachineLearning/comments/8jx5li/ultrasound_dataset/,emma_york,1526494383,[removed],0,1
842,2018-5-17,2018,5,17,4,8jxlx3,Datas Inferno: 7 Circles of Data Testing Hell with Airflow,https://www.reddit.com/r/MachineLearning/comments/8jxlx3/datas_inferno_7_circles_of_data_testing_hell_with/,gagejustins,1526497800,,0,1
843,2018-5-17,2018,5,17,4,8jxs0x,Get dzdx of any NN layer in python,https://www.reddit.com/r/MachineLearning/comments/8jxs0x/get_dzdx_of_any_nn_layer_in_python/,imransalam,1526499118,[removed],0,1
844,2018-5-17,2018,5,17,4,8jxu24,Improved pybullet 3 environment allows for faster policy optimization.,https://www.reddit.com/r/MachineLearning/comments/8jxu24/improved_pybullet_3_environment_allows_for_faster/,FitMachineLearning,1526499552,,0,1
845,2018-5-17,2018,5,17,4,8jxup0,[p] Improved pyBullet 3 environment allows for faster policy optimization.,https://www.reddit.com/r/MachineLearning/comments/8jxup0/p_improved_pybullet_3_environment_allows_for/,FitMachineLearning,1526499685,,2,18
846,2018-5-17,2018,5,17,5,8jy1g3,"AI and Compute : x300,000 from AlexNet to AlphaGo",https://www.reddit.com/r/MachineLearning/comments/8jy1g3/ai_and_compute_x300000_from_alexnet_to_alphago/,yazriel0,1526501075,,1,1
847,2018-5-17,2018,5,17,5,8jy8qg,[P] From brain waves (EEG) to arm/robot movements: an introduction (with Colab Notebook),https://www.reddit.com/r/MachineLearning/comments/8jy8qg/p_from_brain_waves_eeg_to_armrobot_movements_an/,dantehorrorshow,1526502640,,0,13
848,2018-5-17,2018,5,17,5,8jye54,"[P] I was bored at work, found the MIRI project and wanted to make a better landing page for them",https://www.reddit.com/r/MachineLearning/comments/8jye54/p_i_was_bored_at_work_found_the_miri_project_and/,LisoFr,1526503800,"I don't know why, but landing pages in good projects always suck. I've been following the MIRI project for almost 2 years now and even though their blog is amazing they never updated their old school website. 
Some links : 


Their landing page in 2015: https://web.archive.org/web/20150724193406/https://intelligence.org/

In 2016 : 
https://web.archive.org/web/20160808083733/http://intelligence.org/

And today : 
http://intelligence.org/

I'm always wtf does anyone understand it. I did some 5-second tests (we do this in our company - meaning people have to say what people understand after 5 seconds on the website) and the feedbacks mostly coming is that people understand that it is a school for mathematics. 

I created a new version, redirecting directly on their website all the call to action: https://support.safeintelligence.space/

Ran a 5-second test again and their people understand what it is about. 

Why do these kinds of projects spend so much time on content but suck at landing page creation when they want to address to the general public (here donation to help applications)? 

It's not a technical post, will take down the page as soon as my trial on the page builder I used is down but wanted to make a point as I see that quite often.
",5,2
849,2018-5-17,2018,5,17,6,8jyh2w,Min Max Bounds against Vanishing Gradients,https://www.reddit.com/r/MachineLearning/comments/8jyh2w/min_max_bounds_against_vanishing_gradients/,dYuno,1526504414,[removed],0,1
850,2018-5-17,2018,5,17,6,8jyix4,Google using Ai power to help military is unresponsible,https://www.reddit.com/r/MachineLearning/comments/8jyix4/google_using_ai_power_to_help_military_is/,arjunmahr,1526504810,[removed],0,1
851,2018-5-17,2018,5,17,6,8jyu7t,[P] Building Machine Learning Algorithms for embedded devices and IoT,https://www.reddit.com/r/MachineLearning/comments/8jyu7t/p_building_machine_learning_algorithms_for/,bishopxi,1526507297,,14,14
852,2018-5-17,2018,5,17,6,8jyvud,"[D] (Crunching for NIPS 2018?) Against ""selective"" Conferences",https://www.reddit.com/r/MachineLearning/comments/8jyvud/d_crunching_for_nips_2018_against_selective/,feedthecreed,1526507677,,0,1
853,2018-5-17,2018,5,17,6,8jyw1g,"[D] Against ""selective"" conferences",https://www.reddit.com/r/MachineLearning/comments/8jyw1g/d_against_selective_conferences/,feedthecreed,1526507726,,10,2
854,2018-5-17,2018,5,17,8,8jzcaf,data marketplaces,https://www.reddit.com/r/MachineLearning/comments/8jzcaf/data_marketplaces/,mynameisvinn,1526511657,[removed],0,1
855,2018-5-17,2018,5,17,8,8jzfz4,AI and Compute,https://www.reddit.com/r/MachineLearning/comments/8jzfz4/ai_and_compute/,iamkeyur,1526512524,,0,2
856,2018-5-17,2018,5,17,10,8k0blr,[R]Critical Learning Periods in Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8k0blr/rcritical_learning_periods_in_deep_neural_networks/,NotANeuralNetwork,1526520653,,9,25
857,2018-5-17,2018,5,17,11,8k0oc0,Best Way To Build a Model,https://www.reddit.com/r/MachineLearning/comments/8k0oc0/best_way_to_build_a_model/,Theman90210,1526524007,[removed],0,1
858,2018-5-17,2018,5,17,13,8k1af0,Compile neural networks into small executables,https://www.reddit.com/r/MachineLearning/comments/8k1af0/compile_neural_networks_into_small_executables/,nadav256,1526530026,,0,1
859,2018-5-17,2018,5,17,13,8k1cpc,[P] Compile neural networks into small executables,https://www.reddit.com/r/MachineLearning/comments/8k1cpc/p_compile_neural_networks_into_small_executables/,nadav256,1526530649,,12,174
860,2018-5-17,2018,5,17,13,8k1exs,Where is the best course?,https://www.reddit.com/r/MachineLearning/comments/8k1exs/where_is_the_best_course/,cherrypop9,1526531262,[removed],0,1
861,2018-5-17,2018,5,17,14,8k1n6n,"Looking for an ML online course, not for beginners.",https://www.reddit.com/r/MachineLearning/comments/8k1n6n/looking_for_an_ml_online_course_not_for_beginners/,hvb97,1526533593,[removed],1,1
862,2018-5-17,2018,5,17,14,8k1r81,[R] Arbitrary Facial Attribute Editing: Only Change What You Want,https://www.reddit.com/r/MachineLearning/comments/8k1r81/r_arbitrary_facial_attribute_editing_only_change/,LynnHoHZL,1526534799,,4,5
863,2018-5-17,2018,5,17,14,8k1xn9,Am so Glad I found this subreddit because am trying to figure out If machine learning might just be the key here,https://www.reddit.com/r/MachineLearning/comments/8k1xn9/am_so_glad_i_found_this_subreddit_because_am/,jacktaylod,1526536728,[removed],0,1
864,2018-5-17,2018,5,17,15,8k1ybf,[P] AttGAN-Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8k1ybf/p_attgantensorflow/,LynnHoHZL,1526536944,,6,10
865,2018-5-17,2018,5,17,15,8k22ig,OpenAI - AI and compute,https://www.reddit.com/r/MachineLearning/comments/8k22ig/openai_ai_and_compute/,vector_machines,1526538229,[removed],0,1
866,2018-5-17,2018,5,17,16,8k2er8,Deep learning is a new area of machine learning research that imitates the way the human brain works.,https://www.reddit.com/r/MachineLearning/comments/8k2er8/deep_learning_is_a_new_area_of_machine_learning/,Seminar_Links,1526542214,,0,1
867,2018-5-17,2018,5,17,16,8k2hje,"[P] Deep text summarization: of amazon reviews, github issues and news articles",https://www.reddit.com/r/MachineLearning/comments/8k2hje/p_deep_text_summarization_of_amazon_reviews/,tttttm,1526543238,,2,16
868,2018-5-17,2018,5,17,17,8k2m0i,"Kissinger: Philosophically, intellectuallyin every wayhuman society is unprepared for the rise of artificial intelligence.",https://www.reddit.com/r/MachineLearning/comments/8k2m0i/kissinger_philosophically_intellectuallyin_every/,tytung,1526544977,,0,1
869,2018-5-17,2018,5,17,17,8k2ol4,[R] Deep Learning with Ensembles of Neocortical Microcircuits - Dr. Blake Richards,https://www.reddit.com/r/MachineLearning/comments/8k2ol4/r_deep_learning_with_ensembles_of_neocortical/,abstractcontrol,1526546033,,6,49
870,2018-5-17,2018,5,17,18,8k2w49,[D] Deep Q-network training process,https://www.reddit.com/r/MachineLearning/comments/8k2w49/d_deep_qnetwork_training_process/,Bull_cosby,1526548937,"I've found an interesting detail in the DQN paper, where the authors perform the Q-learning algorithm, but only update the model that generates the target values every C mini-batches. This is shown in the second equation of https://www.nature.com/articles/nature14236 .

The authors argue that this optimizes a sequence of well-defined optimization problems. 
Is there any literature that further investigates this technique or applies it to other tasks?",5,12
871,2018-5-17,2018,5,17,18,8k31fc,Generativ models for music,https://www.reddit.com/r/MachineLearning/comments/8k31fc/generativ_models_for_music/,smokebig123,1526550886,[removed],0,1
872,2018-5-17,2018,5,17,19,8k33u3,"New To Q-Learning, some help is needed",https://www.reddit.com/r/MachineLearning/comments/8k33u3/new_to_qlearning_some_help_is_needed/,Jandevries101,1526551704,[removed],0,1
873,2018-5-17,2018,5,17,19,8k35jf,Support Vector Machines - Mathematical solution to XOR problem,https://www.reddit.com/r/MachineLearning/comments/8k35jf/support_vector_machines_mathematical_solution_to/,Reddittor23,1526552244,[removed],0,1
874,2018-5-17,2018,5,17,19,8k366x,Chicken Nuggets Making And Frying Machine,https://www.reddit.com/r/MachineLearning/comments/8k366x/chicken_nuggets_making_and_frying_machine/,lgsherry,1526552471,,1,1
875,2018-5-17,2018,5,17,19,8k3bc2,[P] g2p: English Grapheme To Phoneme Conversion,https://www.reddit.com/r/MachineLearning/comments/8k3bc2/p_g2p_english_grapheme_to_phoneme_conversion/,longinglove,1526554218,,6,5
876,2018-5-17,2018,5,17,21,8k3vqs,I created a page where users can do a ai personality analysis. What do you think?,https://www.reddit.com/r/MachineLearning/comments/8k3vqs/i_created_a_page_where_users_can_do_a_ai/,pankracy,1526560299,,1,1
877,2018-5-17,2018,5,17,21,8k3ywf,"[N] Weekly Machine Learning Opensource Roundup  May 17, 2018",https://www.reddit.com/r/MachineLearning/comments/8k3ywf/n_weekly_machine_learning_opensource_roundup_may/,stkim1,1526561147,,0,1
878,2018-5-17,2018,5,17,21,8k402x,[D] what to do when the better fitting model is less useful?,https://www.reddit.com/r/MachineLearning/comments/8k402x/d_what_to_do_when_the_better_fitting_model_is/,Cimmerrii,1526561468,"I'd love some suggestions here! I'm newer to ml so apologies if my question isn't as clear as it could be.

My situation - I have 5 study variables and ~7 noise variables, and a continuous count Y variable. I'm building models where I don't use them to predict, I just need to know the coefficients and their significance.

I have built 2 models - 1 a glm regression, and one a mixed affect model.

Here is my challenge - the mixed effect model has a much better fit (by aic) but many of the coefficients are non significant. The glm has a worse fit but is significant for every coefficient I care about.

I'm tempted to focus on the glm bc it is more useful (and all the components pass partial F tests) but it feels weird to use the much less fit model?

Thx for any help",2,0
879,2018-5-17,2018,5,17,22,8k45i6,"[D] Charles Stross Keynote at the 34C3 on the role of AI in democracy and problems we might contribute to with our research (NOT singularity, AGI or futurology). How, if at all, does r/machinelearning consider the societal role of our research?",https://www.reddit.com/r/MachineLearning/comments/8k45i6/d_charles_stross_keynote_at_the_34c3_on_the_role/,wojcech,1526562844,,31,17
880,2018-5-17,2018,5,17,22,8k495x,Deep Neural Networks in geology and mining industry,https://www.reddit.com/r/MachineLearning/comments/8k495x/deep_neural_networks_in_geology_and_mining/,Ordinary_investor,1526563763,[removed],0,1
881,2018-5-17,2018,5,17,22,8k498q,[D] Do anonymous GitHub submissions make reviewers happier all the time?,https://www.reddit.com/r/MachineLearning/comments/8k498q/d_do_anonymous_github_submissions_make_reviewers/,fixed-point-learning,1526563774,"I am thinking of hosting an anonymous GitHub profile and put my code there for reviewers to take a look. I am concerned about one thing: If some excited grad student is reviewing, I don't want them going there and trying to understand and question every line. It would negate the purpose. In general, How do reviewers feel about anonymous GitHub submissions? Has anyone had a case where it backfired? Thanks!",18,7
882,2018-5-17,2018,5,17,22,8k4b5z,[R][1805.06370] Progress &amp; Compress: A scalable framework for continual learning [DeepMind],https://www.reddit.com/r/MachineLearning/comments/8k4b5z/r180506370_progress_compress_a_scalable_framework/,evc123,1526564272,,4,26
883,2018-5-17,2018,5,17,22,8k4f55,"If you had to present one paper to someone to show that machine learning is beautiful, what would you choose? (assuming they can understand it)",https://www.reddit.com/r/MachineLearning/comments/8k4f55/if_you_had_to_present_one_paper_to_someone_to/,MTGTraner,1526565248,[removed],0,1
884,2018-5-17,2018,5,17,23,8k4nqx,how to build individual voice recognization systems?,https://www.reddit.com/r/MachineLearning/comments/8k4nqx/how_to_build_individual_voice_recognization/,baincho,1526567251,[removed],0,1
885,2018-5-17,2018,5,17,23,8k4tzw,Just another collection of machine learning paper notes,https://www.reddit.com/r/MachineLearning/comments/8k4tzw/just_another_collection_of_machine_learning_paper/,y0b1byte,1526568700,,3,6
886,2018-5-17,2018,5,17,23,8k4una,An interesting profile of narcissistic star scientist Schmidhuber.,https://www.reddit.com/r/MachineLearning/comments/8k4una/an_interesting_profile_of_narcissistic_star/,nihcloud,1526568850,[removed],0,1
887,2018-5-18,2018,5,18,0,8k51l7,SOTA attention setup for ASR LibriSpeech 1000h,https://www.reddit.com/r/MachineLearning/comments/8k51l7/sota_attention_setup_for_asr_librispeech_1000h/,albertzeyer,1526570370,,0,2
888,2018-5-18,2018,5,18,0,8k59xb,Reinforcement learning with musculoskeletal models,https://www.reddit.com/r/MachineLearning/comments/8k59xb/reinforcement_learning_with_musculoskeletal_models/,kidzik,1526572174,,0,1
889,2018-5-18,2018,5,18,0,8k5blf,[P] Reinforcement learning with musculoskeletal models,https://www.reddit.com/r/MachineLearning/comments/8k5blf/p_reinforcement_learning_with_musculoskeletal/,kidzik,1526572531,,7,13
890,2018-5-18,2018,5,18,2,8k611k,"[R](NIPS 2018) Yoav Goldberg: yup. It's ""peer review"", not ""person who did 5 TensorFlow tutorials review""",https://www.reddit.com/r/MachineLearning/comments/8k611k/rnips_2018_yoav_goldberg_yup_its_peer_review_not/,ExcitingDouble,1526577885,,36,223
891,2018-5-18,2018,5,18,3,8k6et1,[R] [1710.10121] Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations,https://www.reddit.com/r/MachineLearning/comments/8k6et1/r_171010121_beyond_finite_layer_neural_networks/,bobchennan,1526580716,,0,10
892,2018-5-18,2018,5,18,3,8k6l17,Generating audio from midi files,https://www.reddit.com/r/MachineLearning/comments/8k6l17/generating_audio_from_midi_files/,lexanderpl,1526582050,"Hi!

I have a huge \(1500 files\) collection of midi files with piano performances. I would like to generate audio from it \(my project is piano music transcription with neural networks\) with high quality piano samples.

Do you know how to do it with vst plugin or \(the best way\) using a DAW like Ableton \(I have a student licence for it\)?

Thanks!",0,1
893,2018-5-18,2018,5,18,4,8k6z6m,[D] Why are there so many deep learning frameworks? (annoying),https://www.reddit.com/r/MachineLearning/comments/8k6z6m/d_why_are_there_so_many_deep_learning_frameworks/,ME_PhD,1526585092,"I'm new to ML and after a few months I'm still coming across new DL frameworks. Why do a lot of people keep feeling they need to write their own?

I'm from Mech E and it reminds me of the 3D printer craze a few years ago - there were 100+ Kickstarters on ""new"" 3D printers which were all 99% the same.

Is there a good reason for this, given that most of the big frameworks are already open source? To me it seems like a circlejerk tbh. Hope someone can explain. Thx.",18,0
894,2018-5-18,2018,5,18,4,8k77f5,3D Coordinates to Voxel to 3DCNN,https://www.reddit.com/r/MachineLearning/comments/8k77f5/3d_coordinates_to_voxel_to_3dcnn/,VoxelHelp,1526586883,[removed],0,1
895,2018-5-18,2018,5,18,5,8k7avm,"[R] Predicting backchannels like ""yeah"", ""right"", ""uh-huh"" in conversational speech using LSTMs",https://www.reddit.com/r/MachineLearning/comments/8k7avm/r_predicting_backchannels_like_yeah_right_uhhuh/,tehdog,1526587607,,7,9
896,2018-5-18,2018,5,18,5,8k7h2c,"[D] Uh, Did Google Fake Its Big A.I. Demo?",https://www.reddit.com/r/MachineLearning/comments/8k7h2c/d_uh_did_google_fake_its_big_ai_demo/,phobrain,1526588964,,20,0
897,2018-5-18,2018,5,18,6,8k7sku,How to get started in machine learning ?,https://www.reddit.com/r/MachineLearning/comments/8k7sku/how_to_get_started_in_machine_learning/,deepmind_is_skynet,1526591480,[removed],0,1
898,2018-5-18,2018,5,18,6,8k80dy,"I'm starting to learn ML, I tried with just learning different classifiers and coding them and while I learned how to do KNN, I didn't quite u understand how it worked? I wanna start with going for maths first. Can anyone good books/articles? Thank you.",https://www.reddit.com/r/MachineLearning/comments/8k80dy/im_starting_to_learn_ml_i_tried_with_just/,dreamer_luci,1526593237,[removed],0,1
899,2018-5-18,2018,5,18,6,8k84st,Need Advice: Best 100% online Masters Programs in ML in the U.S.?,https://www.reddit.com/r/MachineLearning/comments/8k84st/need_advice_best_100_online_masters_programs_in/,AShipChandler,1526594277,[removed],0,1
900,2018-5-18,2018,5,18,7,8k8d59,Recommendations for Books/Resources on Learning TensorFlow.,https://www.reddit.com/r/MachineLearning/comments/8k8d59/recommendations_for_booksresources_on_learning/,QuanTom_Bit,1526596262,[removed],0,2
901,2018-5-18,2018,5,18,7,8k8jrf,[D] Understanding Deep Learning for Object Detection,https://www.reddit.com/r/MachineLearning/comments/8k8jrf/d_understanding_deep_learning_for_object_detection/,hardmaru,1526597927,,7,41
902,2018-5-18,2018,5,18,8,8k8n9d,[D] Bloomberg interview with DL godfathers + Justin Trudeau,https://www.reddit.com/r/MachineLearning/comments/8k8n9d/d_bloomberg_interview_with_dl_godfathers_justin/,wei_jok,1526598778,,2,5
903,2018-5-18,2018,5,18,8,8k8nwb,[P] ML Compiled - Quick Notes on a Ton of Machine Learning Topics,https://www.reddit.com/r/MachineLearning/comments/8k8nwb/p_ml_compiled_quick_notes_on_a_ton_of_machine/,chsjr,1526598949,,0,13
904,2018-5-18,2018,5,18,8,8k8qz4,[P] Auto diff of actual tensor operations (i.e. convolution),https://www.reddit.com/r/MachineLearning/comments/8k8qz4/p_auto_diff_of_actual_tensor_operations_ie/,melvinzzz,1526599760,,0,11
905,2018-5-18,2018,5,18,9,8k96sd,How much RAM would you recommend for a setup with 1 (or 2) NVIDIA Ti 1080?,https://www.reddit.com/r/MachineLearning/comments/8k96sd/how_much_ram_would_you_recommend_for_a_setup_with/,soerendip,1526604003,[removed],0,1
906,2018-5-18,2018,5,18,9,8k999m,[N] Oracle acquires machine learning platform Datascience.com,https://www.reddit.com/r/MachineLearning/comments/8k999m/n_oracle_acquires_machine_learning_platform/,shaunlgs,1526604667,,0,1
907,2018-5-18,2018,5,18,11,8k9zwq,[D] How google duplex work,https://www.reddit.com/r/MachineLearning/comments/8k9zwq/d_how_google_duplex_work/,begooboi,1526612191,"Saw an article here speculating that google may have faked the google duplex demo. Here is a youtube video  ( https://www.youtube.com/watch?v=IuIpgArEZig ) from ColdFusion which explains how google duplex work. He gives only a brief explanation of duplex inner working so I will try to add some more.

*This is my own conjecture*

Google Duplex may consists of  these technologies 

            1) Wavenet
            2) Recurrent neural network (RNN)
            3) Speech Recognition

[Wavenet](https://deepmind.com/blog/wavenet-generative-model-raw-audio/) converts text to human like speech, [Speech Recognition](https://cloud.google.com/speech-to-text/) convert speech to text and **RNN** which is used for prediction.

This is what happens when a Human speak to Duplex

* Human speech is recognized and converted it into text
* Converted text plus the context is feed to a RNN to get prediction
* Predicted text then passed to Wavenet which converts text to human like speech

The last step is the unique factor of Google duplex it demonstrates the strenght of WaveNet comparing to other technology.

Here is another link explaning google duplex https://www.techxile.com/what-is-google-duplex-and-how-does-it-works/

The only thing I dont understand is how context is feed to RNN?",3,0
908,2018-5-18,2018,5,18,11,8ka0m8,A2C with sparse rewards,https://www.reddit.com/r/MachineLearning/comments/8ka0m8/a2c_with_sparse_rewards/,Flag_Red,1526612397,[removed],0,1
909,2018-5-18,2018,5,18,12,8ka1nb,Network Depth and Dataset size,https://www.reddit.com/r/MachineLearning/comments/8ka1nb/network_depth_and_dataset_size/,drsxr,1526612677,[removed],0,1
910,2018-5-18,2018,5,18,12,8ka3qe,Which framework to use for developing neural nets (especially CNN) from a beginner's point of view?,https://www.reddit.com/r/MachineLearning/comments/8ka3qe/which_framework_to_use_for_developing_neural_nets/,Raman070,1526613275,[removed],0,1
911,2018-5-18,2018,5,18,12,8ka8nb,Random Multimodel Deep Learning (RMDL),https://www.reddit.com/r/MachineLearning/comments/8ka8nb/random_multimodel_deep_learning_rmdl/,kk7nc,1526614713,,0,1
912,2018-5-18,2018,5,18,13,8kaeie,I really want to try Deep Painterly Harmonization but am having trouble compiling Torch. Is anyone working on porting this to Tensorflow or would they be?,https://www.reddit.com/r/MachineLearning/comments/8kaeie/i_really_want_to_try_deep_painterly_harmonization/,theredknight,1526616503,[removed],0,1
913,2018-5-18,2018,5,18,14,8karrz,Machine Learning VS Data Science: What Is The Difference?,https://www.reddit.com/r/MachineLearning/comments/8karrz/machine_learning_vs_data_science_what_is_the/,Zeolearn,1526620893,,0,1
914,2018-5-18,2018,5,18,15,8kayve,How to get started as a ML researcher ?,https://www.reddit.com/r/MachineLearning/comments/8kayve/how_to_get_started_as_a_ml_researcher/,future_world_,1526623370,[removed],0,1
915,2018-5-18,2018,5,18,15,8kb0b1,[R] Convolutional Attention Networks for Multimodal Emotion Recognition from Speech and Text Data,https://www.reddit.com/r/MachineLearning/comments/8kb0b1/r_convolutional_attention_networks_for_multimodal/,hiconcep,1526623859,,5,11
916,2018-5-18,2018,5,18,15,8kb35p,Help with re-re-training a model?,https://www.reddit.com/r/MachineLearning/comments/8kb35p/help_with_reretraining_a_model/,dilipajm,1526624881,,0,1
917,2018-5-18,2018,5,18,16,8kb8qh,Is it true that lower layers in a neural net usually converge faster than upper layers?,https://www.reddit.com/r/MachineLearning/comments/8kb8qh/is_it_true_that_lower_layers_in_a_neural_net/,vernunftig,1526626904,[removed],0,1
918,2018-5-18,2018,5,18,16,8kbaki,What are the best resources for learning how to use Python for Machine Learning/Data Science?,https://www.reddit.com/r/MachineLearning/comments/8kbaki/what_are_the_best_resources_for_learning_how_to/,imarticus_nirmal,1526627547,[removed],0,1
919,2018-5-18,2018,5,18,16,8kbd3a,"QT40 yogwiritsira ntchito konkrete yokhala ndi makina opanga makina, mal...",https://www.reddit.com/r/MachineLearning/comments/8kbd3a/qt40_yogwiritsira_ntchito_konkrete_yokhala_ndi/,dymachine01,1526628470,,1,1
920,2018-5-18,2018,5,18,17,8kbmyn,"[D] If you had to show one paper to someone to show that machine learning is beautiful, what would you choose? (assuming they're equipped to understand it)",https://www.reddit.com/r/MachineLearning/comments/8kbmyn/d_if_you_had_to_show_one_paper_to_someone_to_show/,MTGTraner,1526632476,,297,1273
921,2018-5-18,2018,5,18,17,8kbnh3,Amazing examples of Machine Learning in the real world.,https://www.reddit.com/r/MachineLearning/comments/8kbnh3/amazing_examples_of_machine_learning_in_the_real/,MCAL_Training,1526632684,,0,1
922,2018-5-18,2018,5,18,17,8kboo1,Automatic 12 Color Plasticine Packing Machine,https://www.reddit.com/r/MachineLearning/comments/8kboo1/automatic_12_color_plasticine_packing_machine/,lgsherry,1526633208,,1,1
923,2018-5-18,2018,5,18,18,8kbr72,Exp3: or How to do well in an exam with 0 preparation under bandit feedback?,https://www.reddit.com/r/MachineLearning/comments/8kbr72/exp3_or_how_to_do_well_in_an_exam_with_0/,sudeepraja,1526634234,,0,1
924,2018-5-18,2018,5,18,18,8kbu6w,[D] Understanding Back-Propagation and Meta-Learning,https://www.reddit.com/r/MachineLearning/comments/8kbu6w/d_understanding_backpropagation_and_metalearning/,sparkboyml,1526635383,,2,5
925,2018-5-18,2018,5,18,19,8kc39m,[R] A polish afro trap song about Demis Hassabis.,https://www.reddit.com/r/MachineLearning/comments/8kc39m/r_a_polish_afro_trap_song_about_demis_hassabis/,jakn,1526638708,,5,0
926,2018-5-18,2018,5,18,19,8kc846,[D] ML and blockchain-based big data applications for finance industry,https://www.reddit.com/r/MachineLearning/comments/8kc846/d_ml_and_blockchainbased_big_data_applications/,thumbsdrivesmecrazy,1526640363,"* r/SharpeCapital is applying machine learning &amp; artificial intelligence to the stock market
* r/PayPie is building invoice factoring marketplace and business credit risk assessment using blockchain-based data from online accounting software",1,0
927,2018-5-18,2018,5,18,19,8kc9gr,"Machine Learning, NLP &amp; Python-Cut to the Chase",https://www.reddit.com/r/MachineLearning/comments/8kc9gr/machine_learning_nlp_pythoncut_to_the_chase/,simplivllc,1526640817,[removed],0,1
928,2018-5-18,2018,5,18,20,8kcgvz,Machine Learning: A Game Changer for EHRs,https://www.reddit.com/r/MachineLearning/comments/8kcgvz/machine_learning_a_game_changer_for_ehrs/,Amelia_Smithml,1526643249,,0,1
929,2018-5-18,2018,5,18,20,8kci2b,Are there any other pre-built models for object detection like YOLO?,https://www.reddit.com/r/MachineLearning/comments/8kci2b/are_there_any_other_prebuilt_models_for_object/,OlorinDreams,1526643631,[removed],0,1
930,2018-5-18,2018,5,18,22,8kd4i8,Tensorflow Tutorial (Deep Learning) - Explained For Beginners,https://www.reddit.com/r/MachineLearning/comments/8kd4i8/tensorflow_tutorial_deep_learning_explained_for/,pooja307,1526649780,,0,1
931,2018-5-18,2018,5,18,22,8kddcj,[P] Having trouble reading .nii files! + some general tips requested,https://www.reddit.com/r/MachineLearning/comments/8kddcj/p_having_trouble_reading_nii_files_some_general/,alba_troz,1526651922,"Hey!

I'm currently doing my Thesis in Medical Image Segmentation and I have some .nii's from the LiTS \(liver\) dataset to work on, using Keras with Tensorflow backend. I studied and understand the theory behind Machine and Deep Learning, CNN's, and general image segmentation by feature extraction, and I though this would be a good thesis to work on, as it is both challenging, whilst being relevant my field \(Master in Electrical Engineering, Automation\).

So my main challenges right now are the following:

First, I want to convert each .nii into a folder of .png's, each representing a layer. I'm using the following code:

`import SimpleITK as sitk`

`def read_mha_image(image_path):` `return sitk.ReadImage(image_path)`

`def read_mha_image_as_nuarray(image_path):` `return sitk.GetArrayFromImage(read_mha_image(image_path))`

`def save_nuarray_as_mha(image_path, numpy_array):``sitk.WriteImage(sitk.GetImageFromArray(numpy_array), image_path, True)`

`example = read_mha_image_as_nuarray('/home/albaroz/PycharmProjects/tuturial/volume-0.nii')``save_nuarray_as_mha('/home/albaroz/PycharmProjects/tuturial/result/volume-0.nii.png', example)`

but I can't seem to get the output path right, as i get his error:

`RuntimeError: Exception thrown in SimpleITK WriteImage: /tmp/SimpleITK-build/ITK/Modules/IO/PNG/src/itkPNGImageIO.cxx:567:`

`PNG supports unsigned char and unsigned short`

After getting my .png's, I will try to use a pre\-written architecture, UNet, to achieve my first segmentation results. Lastly, I'll try to write my own architecture and compare results. Problem is, I am a complete noob in Keras and NN design, so if someone could give me some quick tips, like ""you need a minimum of x layers, and you shouldn't use this regularization method because that"" I would be forever grateful!

PS. Do you think my goals are achievable? I only have 4 weeks left to do it! ",5,1
932,2018-5-18,2018,5,18,23,8kdht6,How to setup Google's MLKIT on Android,https://www.reddit.com/r/MachineLearning/comments/8kdht6/how_to_setup_googles_mlkit_on_android/,meshcookie,1526652961,,1,1
933,2018-5-18,2018,5,18,23,8kdrd2,[D] How do you study from textbooks?,https://www.reddit.com/r/MachineLearning/comments/8kdrd2/d_how_do_you_study_from_textbooks/,akmaki,1526655201,"Reading every word and doing every exercise is not time effective. Some chapters may also not be relevant to your research in more advanced topics. 

Interested to hear how people strike a balance when deciding which exercise to do, which chapters to skip and still not feel lost in future chapters, etc.",21,28
934,2018-5-19,2018,5,19,0,8kdxsf,online ML course,https://www.reddit.com/r/MachineLearning/comments/8kdxsf/online_ml_course/,RKVIJAY,1526656607,"I am searching for a online ML course where creating a project is mandatory or they give project as compulsory .

I want to join this course as my summer internship .
",0,1
935,2018-5-19,2018,5,19,0,8ke3uy,[N] Announcing MXBoard  MXNet Data Visualizations directly in TensorBoard - x-post r/mxnet,https://www.reddit.com/r/MachineLearning/comments/8ke3uy/n_announcing_mxboard_mxnet_data_visualizations/,thomasdlt,1526657954,,1,25
936,2018-5-19,2018,5,19,1,8kec06,[N] Call for papers: iMIMIC - Workshop on Interpretability of Machine Intelligence in Medical Image Computing @ MICCAI,https://www.reddit.com/r/MachineLearning/comments/8kec06/n_call_for_papers_imimic_workshop_on/,pereirasrm,1526659718,"We would like to invite you to submit your contributions to the Workshop on Interpretability of Machine Intelligence in Medical Image  Computing ([iMIMIC](https://imimic.bitbucket.io/)) at the 2018 [MICCAI](https://www.miccai2018.org) conference in Granada.

iMIMIC is a half-day workshop to be held on September 16th, 2018. The program features two excellent keynote speakers as well as oral presentations from selected paper contributions.

This workshop aims at introducing the challenges and opportunities related to the topic of interpretability of ML systems in the context of Medical Image Computing and Computer Assisted Intervention.

Call for papers
----------------------
There will be a regular paper track (8 pages LNCS format). We intend to join the MICCAI Satellite Events joint proceedings published in LNCS. We encourage participants to submit their exploratory research work. Covered topics include but are not limited to:

- Definition of interpretability in context of medical image analysis.
- Visualization techniques useful for model interpretation in medical image analysis.
- Local explanations for model interpretability in medical image analysis.
- Methods to improve transparency of machine learning models commonly used in medical image analysis
- Textual explanations of model decisions in medical image analysis.
- Uncertainty quantification in context of model interpretability.
- Quantification and measurement of interpretability.
- Legal and regulatory aspects of model interpretability in medicine.

Please, submit your paper [here](https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FIMIMIC2018).

Important dates
----------------------
- **Submission deadline (11th June)**
- Reviews due (9th July)
- Notification of acceptance (13th July)
- Camera-ready papers (20th July)
- Half- day workshop (16th September, afternoon)

Invited speakers
----------------------
- Been Kim (Google Brain)
- Scott Lundberg (University of Washington)

More information
----------------------
For more information, please, visit the workshop's website, or, feel free to contact the organization.

Website: https://imimic.bitbucket.io/",2,5
937,2018-5-19,2018,5,19,1,8keh72,[D] Neural Networks and Time Travel,https://www.reddit.com/r/MachineLearning/comments/8keh72/d_neural_networks_and_time_travel/,fixed-point-learning,1526660880,"OK here is a crazy theory I have: Neural Networks are one way to model the space\-time continuum. As seen in fiction movies, when a super hero travels back in time, they have the responsibility of making sure not to make the slightest modification to the space\-time continuum otherwise the series of events to follow would result in a lots of changes in the universe. When adversarial examples are computed, this is exactly what happens. The gradient is back\-propagated to the input and added as a tiny noise which completely messes up the classification accuracy. To me, it seems pretty clear that back\-propagation and time travel are operationally similar. Anyway, neural networks are universal approximators so it sounds quite reasonable that they could emulate the space\-time continuum.",8,0
938,2018-5-19,2018,5,19,1,8kejco,Unitary RNN DOubt,https://www.reddit.com/r/MachineLearning/comments/8kejco/unitary_rnn_doubt/,ShivamDuggal4,1526661365,[removed],0,1
939,2018-5-19,2018,5,19,1,8keji8,[D] Unitary RNN doubt,https://www.reddit.com/r/MachineLearning/comments/8keji8/d_unitary_rnn_doubt/,ShivamDuggal4,1526661401,"How does Unitary RNN preserve the hidden vector norm? I understand how it maintains the norm of the gradient of hidden state at time step t with respect to hidden state at time step t-i, using RELU as non-linearity. However, maintaining the norm of the hidden vector would require input and the bias to be zero?

Please clarify how it maintains the norm of the hidden vector?",5,0
940,2018-5-19,2018,5,19,2,8kf4d8,"[R] To Build Truly Intelligent Machines, Teach Them Cause and Effect",https://www.reddit.com/r/MachineLearning/comments/8kf4d8/r_to_build_truly_intelligent_machines_teach_them/,downtownslim,1526665996,,6,2
941,2018-5-19,2018,5,19,3,8kf70m,Anybody who just submitted the NIPS paper? How many submissions are there do you think (based on your paper ID)?,https://www.reddit.com/r/MachineLearning/comments/8kf70m/anybody_who_just_submitted_the_nips_paper_how/,alayaMatrix,1526666569,[removed],0,1
942,2018-5-19,2018,5,19,3,8kfa52,Publish your research of Machine Learning and AI in IHCI 2018,https://www.reddit.com/r/MachineLearning/comments/8kfa52/publish_your_research_of_machine_learning_and_ai/,ihciconf,1526667263,[removed],0,1
943,2018-5-19,2018,5,19,3,8kff65,[Project] Super Marios Bros. - NES - World 1-1 - Automated Level MApper (ALMA),https://www.reddit.com/r/MachineLearning/comments/8kff65/project_super_marios_bros_nes_world_11_automated/,BZH314,1526668400,,10,0
944,2018-5-19,2018,5,19,3,8kfhco,[P] Howto on building your own text classifier locally on your machine for non-datascientists,https://www.reddit.com/r/MachineLearning/comments/8kfhco/p_howto_on_building_your_own_text_classifier/,thetall0ne1,1526668878,,0,0
945,2018-5-19,2018,5,19,3,8kflf2,Undergraduate internships at research labs,https://www.reddit.com/r/MachineLearning/comments/8kflf2/undergraduate_internships_at_research_labs/,fluffyy98,1526669835,,0,1
946,2018-5-19,2018,5,19,3,8kflfc,These three books should be at the desk of every Sr. Geologist,https://www.reddit.com/r/MachineLearning/comments/8kflfc/these_three_books_should_be_at_the_desk_of_every/,vallsvg,1526669837,[removed],0,1
947,2018-5-19,2018,5,19,4,8kfn4w,Performing until 7 inferences at same time,https://www.reddit.com/r/MachineLearning/comments/8kfn4w/performing_until_7_inferences_at_same_time/,3droberto,1526670234,,0,1
948,2018-5-19,2018,5,19,4,8kfsh4,"[D] Lets play a game, who has the smallest/largest NIPS paper ID",https://www.reddit.com/r/MachineLearning/comments/8kfsh4/d_lets_play_a_game_who_has_the_smallestlargest/,SubjectWord,1526671448,Ive got 987 and 5260. Anyone beat those?,1,1
949,2018-5-19,2018,5,19,4,8kfy56,[D] Advice for ML salary in UK,https://www.reddit.com/r/MachineLearning/comments/8kfy56/d_advice_for_ml_salary_in_uk/,krad_white,1526672765,"Hi All,

As i am getting near the end of my PhD program in UK, approaching graduation, I am starting to look for employment oportunities either in industry or academia. While I am already familiar to some extend to what should I expect from the later, it is unclear to me of how things are going in industry (for a research position).

As such, my main questions are:
1.What are the main pros/cons?
2.How are the publications handled ussualy? (I do understand that this may vary dramatically from one place to another).
3.What is a typical starting salary for a researcher in ML/DL? I am mostly interested to UK since I am not interesting at the moment in living for the moment. (I know that there a few posts, but they are a bit old, more general and dont ussualy refer to UK).

Regarding my background, while I don't have a stellar record I do have a few papers at NIPS/CVPR/ICCV.

Thanks a lot!",23,28
950,2018-5-19,2018,5,19,5,8kg2lq,Looking for a 2D map dataset,https://www.reddit.com/r/MachineLearning/comments/8kg2lq/looking_for_a_2d_map_dataset/,travel_Dude42,1526673757,Hello! I'm doing a project and it requires me to go out and find a map dataset. I'm looking for a dataset of grids with obstacles and a target. This seems like a simple type of data set and yet I can't find anything like this anywhere. I would generate it myself as this isn't very difficult but sadly I am not allowed. Any help would be appreciated.,0,1
951,2018-5-19,2018,5,19,5,8kg60d,"[D] In text normalization, how do you handle case like non-spaced words using ML models?",https://www.reddit.com/r/MachineLearning/comments/8kg60d/d_in_text_normalization_how_do_you_handle_case/,spiritualAsshole,1526674560,"**Example:** 

*notalotofcars in the ciy \-\-\&gt; not a lot of cars in the city.*

ciy is 1 edit distance way to city. 

notalotofcars can be fed to Seq2Seq, but how will it handle the case that it has never seen? 

*Example: lackthetrucks \-\-\&gt; Lack the trucks*",4,2
952,2018-5-19,2018,5,19,5,8kg7m0,How stressing is ML on cpus? Will it slow down my regular daily work?,https://www.reddit.com/r/MachineLearning/comments/8kg7m0/how_stressing_is_ml_on_cpus_will_it_slow_down_my/,linuxman1929,1526674939,[removed],0,1
953,2018-5-19,2018,5,19,5,8kgapw,"[D] Apaprently, NIPS this year has close to 8000 submissions, a 2.5x increase from last year",https://www.reddit.com/r/MachineLearning/comments/8kgapw/d_apaprently_nips_this_year_has_close_to_8000/,yodaman92,1526675696,,18,105
954,2018-5-19,2018,5,19,6,8kgk71,[Discussion] How was NIPS 2018?,https://www.reddit.com/r/MachineLearning/comments/8kgk71/discussion_how_was_nips_2018/,faush2,1526677995,"With submissions finally closed, what was everyone's experience up to the deadline and how is everyone feeling?",15,12
955,2018-5-19,2018,5,19,6,8kgl3h,keras: Conv1D kernal size?,https://www.reddit.com/r/MachineLearning/comments/8kgl3h/keras_conv1d_kernal_size/,craybobnee,1526678214,[removed],0,1
956,2018-5-19,2018,5,19,6,8kgp26,AirDrop | CoinLaunch Market,https://www.reddit.com/r/MachineLearning/comments/8kgp26/airdrop_coinlaunch_market/,elanelacounthqy,1526679220,,0,1
957,2018-5-19,2018,5,19,6,8kgpi5,New AI tool controls people in videos!,https://www.reddit.com/r/MachineLearning/comments/8kgpi5/new_ai_tool_controls_people_in_videos/,NicoleK1993,1526679328,,0,1
958,2018-5-19,2018,5,19,6,8kgv0k,[D] Explaining 8k submissions,https://www.reddit.com/r/MachineLearning/comments/8kgv0k/d_explaining_8k_submissions/,ecstasyogold,1526680793,"What is the main source of this increase?

i) NIPS community doubled,

ii) Researchers are sending more of their papers to NIPS,

iii) Botting.",5,0
959,2018-5-19,2018,5,19,7,8kh1wz,GUI tools for data manipulation for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8kh1wz/gui_tools_for_data_manipulation_for_machine/,MessyML,1526682549,"Hey guys,

I am aware of several awesome **Python libraries that allow me to do image manipulation**, cropping, etc. in to prepare my data for training input to Neural Nets.

Are you aware of nice looking tools with a **graphical interface** specifically for the purpose of data **preprocessing \(resize, crop, brightness\)** and **manipulation \(say, assign classes to multiple images easily\)**?

I know every problem is unique and everybody has its own setup, but are there tools out there that do this well?",0,1
960,2018-5-19,2018,5,19,7,8kh82g,[D] GUI tools for data manipulation for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8kh82g/d_gui_tools_for_data_manipulation_for_machine/,MessyML,1526684220,,0,1
961,2018-5-19,2018,5,19,7,8kh8hw,[R] (NIPS 2015) Machine Learning in Computational Biology,https://www.reddit.com/r/MachineLearning/comments/8kh8hw/r_nips_2015_machine_learning_in_computational/,kal00ma,1526684340,,0,5
962,2018-5-19,2018,5,19,8,8khbuz,[D] GUI tools for data manipulation for machine learning?,https://www.reddit.com/r/MachineLearning/comments/8khbuz/d_gui_tools_for_data_manipulation_for_machine/,MessyML,1526685242,"Hey guys,

I am aware of several awesome Python libraries that allow me to do image manipulation, cropping, etc. in to prepare my data for training input to Neural Nets.

Are you aware of nice looking tools with a graphical interface specifically for the purpose of data preprocessing \(resize, crop, brightness\) and manipulation \(say, assign classes to multiple images easily\)?

I know every problem is unique and everybody has its own setup, but are there tools out there that do this well?",6,3
963,2018-5-19,2018,5,19,8,8khj6d,Cambridge University Data Collection of Emotions within Poems.,https://www.reddit.com/r/MachineLearning/comments/8khj6d/cambridge_university_data_collection_of_emotions/,shweggs,1526687310,,1,3
964,2018-5-19,2018,5,19,9,8khr1t,"Request for help: reproducing result from ""DYNAMIC COATTENTION NETWORKS FOR QUESTION ANSWERING""",https://www.reddit.com/r/MachineLearning/comments/8khr1t/request_for_help_reproducing_result_from_dynamic/,atulkum,1526689534,[removed],0,1
965,2018-5-19,2018,5,19,10,8ki2lc,Results of a Logistic Regression Predicting Likelihood a Tweet by a Russian Troll will be Retweeted/Liked,https://www.reddit.com/r/MachineLearning/comments/8ki2lc/results_of_a_logistic_regression_predicting/,drskywalker14,1526693135,,1,2
966,2018-5-19,2018,5,19,11,8kifb0,[N] Mathematics for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8kifb0/n_mathematics_for_machine_learning/,upulbandara,1526697124,,49,615
967,2018-5-19,2018,5,19,12,8kinek,[D] Would we still have discovered neural networks if not for the brain providing a working example to inspire us?,https://www.reddit.com/r/MachineLearning/comments/8kinek/d_would_we_still_have_discovered_neural_networks/,flarn2006,1526699670,"Say the human mind worked exactly the same as far as all our mental processes are concerned, except it didn't use a physical process we could turn into an algorithm. Like if instead of having physical brains, we had...I guess the traditional idea of an immaterial soul provides a good hypotheticaland all our thoughts and everything worked the same way, but happened there instead, outside of anything we could examine. Math still works the same way of course, so the algorithm would still work, but how likely do you think it is people would have come up with that algorithm if not for that inspiration?

(Yes, I'm aware in this scenario they would probably be called something other than ""neural networks"". Artificial thought networks, perhaps? Pseudocognitive networks?)",15,6
968,2018-5-19,2018,5,19,12,8kiv4y,"[P] Request for help: reproducing result from ""DYNAMIC COATTENTION NETWORKS FOR QUESTION ANSWERING""",https://www.reddit.com/r/MachineLearning/comments/8kiv4y/p_request_for_help_reproducing_result_from/,atulkum,1526702305,"I am trying to reproduced result from the paper ""DYNAMIC COATTENTION NETWORKS FOR QUESTION ANSWERING"" \([https://arxiv.org/abs/1611.01604](https://arxiv.org/abs/1611.01604)\).

I have implemented the code in pytorch but it is overfitting. I used[https://github.com/abisee/cs224n\-win18\-squad](https://github.com/abisee/cs224n-win18-squad) for data processing and batch generation.

In the paper it is mention that the authors use dropout for regularization. I added dropout and it helps a bit but not too much.

I am curious if you can help me with the dropout parameters specifically

1\) after which layer the dropout is placed,

2\) how much dropout probability is used

3\) is there any other form of regularization used \(l2 etc\)

I am also curious if it is possible to get feedback on my model code. Here is the link to the code.

[https://github.com/atulkum/co\-attention/blob/master/code/model.py](https://github.com/atulkum/co-attention/blob/master/code/model.py)

I am also attaching the learning curve as png image.",0,3
969,2018-5-19,2018,5,19,13,8kj06q,[R] AI tool controls people in videos - Deep Video Portraits - SIGGRAPH 2018,https://www.reddit.com/r/MachineLearning/comments/8kj06q/r_ai_tool_controls_people_in_videos_deep_video/,NicoleK1993,1526704031,,43,147
970,2018-5-19,2018,5,19,13,8kj1yt,"QT40 manual hollow block machine sa Davao, manu-manong paggawa ng brick ...",https://www.reddit.com/r/MachineLearning/comments/8kj1yt/qt40_manual_hollow_block_machine_sa_davao/,dymachine01,1526704639,,1,1
971,2018-5-19,2018,5,19,14,8kj8x2,"Google TPU * 1  vs NVIDIA V100 *4, does it worth for rewrite my TensorFlow codes?",https://www.reddit.com/r/MachineLearning/comments/8kj8x2/google_tpu_1_vs_nvidia_v100_4_does_it_worth_for/,helmetti,1526707110,[removed],0,1
972,2018-5-19,2018,5,19,14,8kj98e,Graduate course (w/ video lectures) on Probabilistic Graphical Models by Prof. Nicholas Zabaras,https://www.reddit.com/r/MachineLearning/comments/8kj98e/graduate_course_w_video_lectures_on_probabilistic/,kartikkaul,1526707239,,0,1
973,2018-5-19,2018,5,19,14,8kjch1,"QT4 25 automatic CHB cement hollow block machine sa Angono, Philippines,...",https://www.reddit.com/r/MachineLearning/comments/8kjch1/qt4_25_automatic_chb_cement_hollow_block_machine/,dymachine01,1526708507,,1,1
974,2018-5-19,2018,5,19,16,8kjuus,"I came across this profile and this guy seemed almost too good to be such a pioneer in the ML/DL field so ... this guy is a pure fraud, right?",https://www.reddit.com/r/MachineLearning/comments/8kjuus/i_came_across_this_profile_and_this_guy_seemed/,Rainymood_XI,1526715905,[removed],0,1
975,2018-5-19,2018,5,19,17,8kk3d3,The Cyborg Beetles Designed to Save Human Lives,https://www.reddit.com/r/MachineLearning/comments/8kk3d3/the_cyborg_beetles_designed_to_save_human_lives/,KajKulaKhan,1526719978,,0,1
976,2018-5-19,2018,5,19,20,8kksyd,"tf implementation of openai's metalearning algorithm, reptile",https://www.reddit.com/r/MachineLearning/comments/8kksyd/tf_implementation_of_openais_metalearning/,mynameisvinn,1526730952,[removed],0,1
977,2018-5-19,2018,5,19,21,8kkwnf,C,https://www.reddit.com/r/MachineLearning/comments/8kkwnf/c/,Cyalas,1526732157,[removed],0,1
978,2018-5-19,2018,5,19,21,8kkyfu,"From another domain to ML, is that possible ?",https://www.reddit.com/r/MachineLearning/comments/8kkyfu/from_another_domain_to_ml_is_that_possible/,Cyalas,1526732778,[removed],0,1
979,2018-5-19,2018,5,19,21,8kl1nd,[P] Introducing Sagify: Train and deploy Machine Learning/Deep Learning models on AWS SageMaker in a few simple steps,https://www.reddit.com/r/MachineLearning/comments/8kl1nd/p_introducing_sagify_train_and_deploy_machine/,pm3310,1526733915,,2,6
980,2018-5-19,2018,5,19,22,8klbbf,[D] Best Machine Learning Podcasts?,https://www.reddit.com/r/MachineLearning/comments/8klbbf/d_best_machine_learning_podcasts/,lightntangy23,1526737140,I am currently trying to do something like Mari/o and just wondered if anyone had any great podcasts I could listen to that could help develop my understanding of Tensorflow/Python/DQN and etc. Thanks in advance :),16,64
981,2018-5-19,2018,5,19,22,8klbc6,"[R] Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context (ACL 2018)",https://www.reddit.com/r/MachineLearning/comments/8klbc6/r_sharp_nearby_fuzzy_far_away_how_neural_language/,ofirpress,1526737150,,1,21
982,2018-5-20,2018,5,20,0,8kluoj,[N] Tesla's Lethal Autopilot Crash  A Failing of UI as Much as AI,https://www.reddit.com/r/MachineLearning/comments/8kluoj/n_teslas_lethal_autopilot_crash_a_failing_of_ui/,regalalgorithm,1526742777,,5,0
983,2018-5-20,2018,5,20,0,8km1f6,[R] Where are the latest JMLR papers?,https://www.reddit.com/r/MachineLearning/comments/8km1f6/r_where_are_the_latest_jmlr_papers/,riel234,1526744655,The last paper listed at http://www.jmlr.org/papers/ was published in January 2018. Is there any newer edition of the journal? ,0,3
984,2018-5-20,2018,5,20,0,8km2rc,Which model would I choose to read out several values from receipts and invoices?,https://www.reddit.com/r/MachineLearning/comments/8km2rc/which_model_would_i_choose_to_read_out_several/,AlanFlusser,1526745028,[removed],0,1
985,2018-5-20,2018,5,20,1,8kmidh,Some questions about model quantization,https://www.reddit.com/r/MachineLearning/comments/8kmidh/some_questions_about_model_quantization/,hubert0527,1526749147,[removed],0,1
986,2018-5-20,2018,5,20,2,8kmphm,Laser Spot Detection and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8kmphm/laser_spot_detection_and_machine_learning/,KajKulaKhan,1526750931,"For measuring a distance through laser triangulation 'Laser Spot Detection' affects the distance accuracy. There are existing traditional algorithms like circular fitting algorithm, sobel operator etc. which improves the laser spot detection with the aim to compute the center of the laser spot and then localize the laser spot. My question: in which part of the task would you say it's appropriate to think about machine learning approach. ",0,1
987,2018-5-20,2018,5,20,2,8kmrlv,[Discussion] Some questions about model quantization,https://www.reddit.com/r/MachineLearning/comments/8kmrlv/discussion_some_questions_about_model_quantization/,hubert0527,1526751469,"Just read a page about model quantization in TF: https://www.tensorflow.org/versions/r1.3/performance/quantization#why_quantize

In my imagination, model quantization is supposed to be combined with low precision floating points operations. But seems like, during inference phase, the feature maps are still under full precision. The quantization is totally about better GPU cache utilization and reducing communication bandwidth. Totally unrelated to reducing the precision of floating point operations. Is my understanding right? Or am I getting something wrong? Any comment would be grateful :)",1,3
988,2018-5-20,2018,5,20,3,8kmx4u,AI Weekly 19 May 2018,https://www.reddit.com/r/MachineLearning/comments/8kmx4u/ai_weekly_19_may_2018/,TomekB,1526752902,,0,1
989,2018-5-20,2018,5,20,3,8kmzl6,Does anyone know when paper submission of CVPR19 is open?,https://www.reddit.com/r/MachineLearning/comments/8kmzl6/does_anyone_know_when_paper_submission_of_cvpr19/,mikigom,1526753504,[removed],0,1
990,2018-5-20,2018,5,20,3,8kn2g8,[D]Rectangle Minimize error AdaBoost with Python,https://www.reddit.com/r/MachineLearning/comments/8kn2g8/drectangle_minimize_error_adaboost_with_python/,Illidan5,1526754227,"I have this problem where I need to find the error for each round out of 8

I have the code for the adaboost algorithm , thing is I fail to understand what to do with the Rectangle function , I guess it is suppose to be some kind of replacement for decision tree? , says ""set of labelled points with weights""... 4 points ? the entire dataset ? I don't understand , I will provide the dataset and my current code, I just need help getting it all together with the dividing of the dataset and randomize... here is the problem :

and the dataset: [http://textuploader.com/df7f1](http://textuploader.com/df7f1)

my current code: [https://paste.ofcode.org/t3zEVPshn8giU5wPM2X63m](https://paste.ofcode.org/t3zEVPshn8giU5wPM2X63m)

can you help me complete the rectangle function and the dataset reading?

![gif](9jzplautsuy01)",0,4
991,2018-5-20,2018,5,20,3,8kn4uf,"Getting Started With Tensorflow : Constants, Variables, Placeholders and Sessions",https://www.reddit.com/r/MachineLearning/comments/8kn4uf/getting_started_with_tensorflow_constants/,nishankatwork,1526754839,,0,1
992,2018-5-20,2018,5,20,3,8kn55o,Advanced scheduling of DL/ML experiments and jobs on Polyaxon,https://www.reddit.com/r/MachineLearning/comments/8kn55o/advanced_scheduling_of_dlml_experiments_and_jobs/,mmourafiq,1526754911,,0,1
993,2018-5-20,2018,5,20,4,8knc5i,[D] ML/Data Science Project Structure,https://www.reddit.com/r/MachineLearning/comments/8knc5i/d_mldata_science_project_structure/,modern_indophilia,1526756683,"In my job, I perform basic analysis of health data sets for surveillance and reporting. I work mostly in Python, and I generally find Jupyter Notebooks to be a convenient way to both perform and document my analysis. Recently, I've been learning to perform more sophisticated analyses, and I'm starting to dabble in machine learning projects. In the course of doing this, I have come across [Cookie Cutter Data Science](https://drivendata.github.io/cookiecutter-data-science/), and it opened my eyes to something I hadn't considered before:  a default, reproducible structure for data science projects. I was familiar with the concept from React and Ruby on Rails webdev stuff, but I hadn't considered its application to data science previously. I don't work on a team with individuals who self-identify as data scientists (they mostly do number crunching in SAS or SPSS), so I don't have much exposure to the ""community.""

My question is how do you all approach structuring your data science projects? Are there industry standards that I should be familiar with and get in the habit of using? How do you write and store shareable, reproducible code outside of (Jupyter) Notebooks?",4,46
994,2018-5-20,2018,5,20,4,8knkta,[D] Feature extraction in audio files using the Librosa library in Python.,https://www.reddit.com/r/MachineLearning/comments/8knkta/d_feature_extraction_in_audio_files_using_the/,youngchul,1526758922,"I am trying to extract features from audio files using Librosa, to feed to a CNN (Keras) as Numpy arrays.

Currently I save a single feature to feed into the CNN. I save two dimensional (single-channel) log-scaled mel-spectrogram features in Python using Librosa for each song I feed to the CNN

    
    def build_features():
        y, sr = librosa.load(""audio.wav"")
        mel = librosa.feature.melspectrogram(
            n_fft=4096,
            n_mels=128, #Mel-bins
            hop_length=2048,
        )
        logamplitude = librosa.amplitude_to_db
        logspec = logamplitude(mel, ref=1.0)[np.newaxis, :, :, np.newaxis]

This gives the shape (1, 128, 323, 1).

I would like to add another feature, let's say a tempogram. I can do this, using the same code, but replacing melspectrogram to tempogram', and setting the window length to 128.

This gives me a tempogram shape of (1,128,323,1).

Now i would like to ""stack"" these 2 feature layers, into a multi-channel numpy object, that i can feed into a CNN in Keras.

How would you go about this?",0,1
995,2018-5-20,2018,5,20,5,8kntny,[D] (data request) Is there a disgusting data set?,https://www.reddit.com/r/MachineLearning/comments/8kntny/d_data_request_is_there_a_disgusting_data_set/,fimari,1526761235,"I am searching for a Dataset with disgusting images, appetizing images or otherwise emotion inducing pictures with great diversity. Is there something like that in the wild?",10,9
996,2018-5-20,2018,5,20,5,8knw5i,OpenAI Gym SUCKS! Improving the quality of Reinforcement Learning Tools,https://www.reddit.com/r/MachineLearning/comments/8knw5i/openai_gym_sucks_improving_the_quality_of/,malusmax,1526761925,[removed],0,1
997,2018-5-20,2018,5,20,5,8knyep,[D] Does anyone know a paper/article about using Resnet/DenseNet/Inception in reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/8knyep/d_does_anyone_know_a_paperarticle_about_using/,VastTemperature,1526762519,,6,8
998,2018-5-20,2018,5,20,5,8ko0c0,Real-time Sudoku Solver,https://www.reddit.com/r/MachineLearning/comments/8ko0c0/realtime_sudoku_solver/,tahaemara,1526763036,,0,1
999,2018-5-20,2018,5,20,6,8ko634,Just got a Titan Vhelp setting it up for Tensorflow (GRU)?,https://www.reddit.com/r/MachineLearning/comments/8ko634/just_got_a_titan_vhelp_setting_it_up_for/,666DEATHBORN666,1526764578,[removed],0,1
1000,2018-5-20,2018,5,20,6,8ko8hv,"Any pointers on how was this awesome graphic in DenseNet paper was made? Any tools, resources are appreciated.",https://www.reddit.com/r/MachineLearning/comments/8ko8hv/any_pointers_on_how_was_this_awesome_graphic_in/,sksq9,1526765247,,0,1
1001,2018-5-20,2018,5,20,6,8kocr7,[D] Relationship between Deep Learning Network Depth and Dataset size,https://www.reddit.com/r/MachineLearning/comments/8kocr7/d_relationship_between_deep_learning_network/,drsxr,1526766432,"So I have pulled Bankos and Brills [Scaling to Very Very Large Corpora for Natural Language Disambiguation ](http://www.aclweb.org/anthology/P01-1005)which studies the effects of data size on machine learning for natural language disambiguation.  It has a very nice **figure 1** where it shows that as the # of words scales from a million to the thousands of millions, there is a increasing rate of test accuracy.

I am looking for the same thing but in images.  Has anyone come across a good reference?  Does one exist in deep learning for image classification?

I am looking for the equivalent of figure 1 in Bankos and Brill.  I think I saw it before once, but its been a while and I cant recall where.   Someone must have done this on CIFAR and ImageNet.

Does anyone know the reference I am looking for?  Ive searched myself with no luck.  Thanks!",3,12
1002,2018-5-20,2018,5,20,7,8komjw,"[D] ""A.I. Is Harder Than You Think"" (Gary Marcus again ...)",https://www.reddit.com/r/MachineLearning/comments/8komjw/d_ai_is_harder_than_you_think_gary_marcus_again/,baylearn,1526769057,,32,17
1003,2018-5-20,2018,5,20,8,8koymf,[D] How Judea Pearl Became One of AI's Sharpest Critics,https://www.reddit.com/r/MachineLearning/comments/8koymf/d_how_judea_pearl_became_one_of_ais_sharpest/,wei_jok,1526772542,,19,76
1004,2018-5-20,2018,5,20,10,8kpr27,A.I Made these Paintings,https://www.reddit.com/r/MachineLearning/comments/8kpr27/ai_made_these_paintings/,Coach_Aretas,1526781257,,0,1
1005,2018-5-20,2018,5,20,12,8kq34j,[R] Google Clips: a lifelogging camera with automatic selection of interesting video snippets using on-device NN trained by 50m human pairwise comparisons &amp; 100s-way CNN categorization,https://www.reddit.com/r/MachineLearning/comments/8kq34j/r_google_clips_a_lifelogging_camera_with/,gwern,1526785218,,15,122
1006,2018-5-20,2018,5,20,12,8kq9nb,[N] Comparison of tensor compilers.,https://www.reddit.com/r/MachineLearning/comments/8kq9nb/n_comparison_of_tensor_compilers/,melvinzzz,1526787420,[removed],0,1
1007,2018-5-20,2018,5,20,13,8kqg9l,[D] Sharing an awesome visualiser: Netron by lutzroeder,https://www.reddit.com/r/MachineLearning/comments/8kqg9l/d_sharing_an_awesome_visualiser_netron_by/,tlkh,1526789795,"I've come across [Netron](https://lutzroeder.github.io/Netron/) \(github: [https://github.com/lutzroeder/Netron](https://github.com/lutzroeder/Netron)\), a really awesome tool that can visualise the structure of models from a wide variety of formats: ONNX, Keras, CoreML, TensorFlow, Caffe etc.

A couple of friends and I found really useful, and people don't seem to know it exists, so I'm just sharing it here! Have a nice day everyone.",4,42
1008,2018-5-20,2018,5,20,13,8kqmoi,Integrating evolutionary program learning with general cognition,https://www.reddit.com/r/MachineLearning/comments/8kqmoi/integrating_evolutionary_program_learning_with/,ibbybenali,1526792167,,0,1
1009,2018-5-20,2018,5,20,14,8kqrqa,[R] Time Series Prediction tips?,https://www.reddit.com/r/MachineLearning/comments/8kqrqa/r_time_series_prediction_tips/,eightpackflabs,1526794113,"Hi all, I'm doing research with some signals and I'd like to make some predictions based on some signals I have.

1) These are of unequal length.

2) They are three dimensional. There are three sensors that measure the same activity.

3) There are two labels per sequence. Each sequence corresponds to two values, say 2 and 1. I want my network to predict these values.

For eg. sequence 1 =&gt; 2 and 1

sequence 2 =&gt; 3 and 4

All signals have integer values and so do the labels.

I'm trying to use Keras with TensorFlow. So far I've tried CNNs (both 2D and 1D) and LSTMs with some success, but nothing significant. I had to under sample or oversample my data to make the dataset dimensions consistent to use in the network. Ideally, I want to be able to work on the sequences in entirety without resampling them.

 What direction can I go in? Specifically I need tips in how to prepare my dataset, how to normalize it (if necessary) and what networks/layers to use to train my network. Are there any papers I could read up on?

Thanks!",9,4
1010,2018-5-20,2018,5,20,14,8kqvik,Where to start the learning about RL ?whats the best method to learn about ML &amp; RL.,https://www.reddit.com/r/MachineLearning/comments/8kqvik/where_to_start_the_learning_about_rl_whats_the/,bilalsaghir95,1526795721,[removed],0,1
1011,2018-5-20,2018,5,20,15,8kqwxv,"Sorry if this is the wrong subreddit for this, but is there a publicly available list of neural network-trained AIs on the web that are usable?",https://www.reddit.com/r/MachineLearning/comments/8kqwxv/sorry_if_this_is_the_wrong_subreddit_for_this_but/,watercolorheart,1526796307,[removed],0,1
1012,2018-5-20,2018,5,20,16,8kr6nh,A Deep Dive into Monte Carlo Tree Search,https://www.reddit.com/r/MachineLearning/comments/8kr6nh/a_deep_dive_into_monte_carlo_tree_search/,mmourafiq,1526800631,,0,1
1013,2018-5-20,2018,5,20,17,8krg7l,WODFitters | WODFitters WOD Gear &amp;amp; Equipment - Cross Training MetCon Power Lifting,https://www.reddit.com/r/MachineLearning/comments/8krg7l/wodfitters_wodfitters_wod_gear_amp_equipment/,irmaddwiesebaa8,1526805321,,0,1
1014,2018-5-20,2018,5,20,19,8krt45,[D] Long-term Text-Recognition?,https://www.reddit.com/r/MachineLearning/comments/8krt45/d_longterm_textrecognition/,melgor89,1526811706,"I'm working with OCR on images, where some lines may interact (mean that information from one line may be useful in another, example: prices of products at receipt vs total_price). https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/ReceiptSwiss.jpg/800px-ReceiptSwiss.jpg
 
Currently I treat each line independently (I use Seq2Seq model, where input are images), so I use Text-Detection then Text-Recognition line-by-line.

What do you think about other approach:
- merge all detected text on one very long line and try to predict all text at once (using Seq2Seq with Attention)
- or predicting line by line but state of Encoder would be copy from line to line (so each next line would know about previous data, but not data after analysed line)

Did you here about using such idea for Text-Recognition or other Long-Term dependence task?
",20,37
1015,2018-5-20,2018,5,20,19,8krwye,[D] What are some non-trivial but achievable exercises in reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/8krwye/d_what_are_some_nontrivial_but_achievable/,PorcelainMelonWolf,1526813564,"I'm going to be doing some work on reinforcement learning in the near future, and I'd like to get myself up to speed on the ideas involved. I'm looking for some exercises that will help me to learn the basics: kind of like sorting algorithms are to basic programming, or MNIST with logistic regression is to classification.

Anyone have suggestions?

Thanks very much",6,8
1016,2018-5-20,2018,5,20,20,8ks0qt,Internet of things examples and applications,https://www.reddit.com/r/MachineLearning/comments/8ks0qt/internet_of_things_examples_and_applications/,spyvarade,1526815100,,0,1
1017,2018-5-20,2018,5,20,21,8ks8tq, - ,https://www.reddit.com/r/MachineLearning/comments/8ks8tq/_/,Woodworking94,1526818497,,0,1
1018,2018-5-20,2018,5,20,21,8ksafw,"[N] The rise of artificial intelligence is creating new variety in the chip market, and trouble for Intel",https://www.reddit.com/r/MachineLearning/comments/8ksafw/n_the_rise_of_artificial_intelligence_is_creating/,pmigdal,1526819097,,1,5
1019,2018-5-20,2018,5,20,21,8ksbho,"Interview with Natural Language Processing Expert Dr. Frank Rudzicz on Google Duplex, the Future of NLP, Speech as a Window into the Mind, and more",https://www.reddit.com/r/MachineLearning/comments/8ksbho/interview_with_natural_language_processing_expert/,Neuronologist,1526819466,,0,1
1020,2018-5-20,2018,5,20,22,8kshvb,[D] CUDA Intro to Parallel Programming on Udacity,https://www.reddit.com/r/MachineLearning/comments/8kshvb/d_cuda_intro_to_parallel_programming_on_udacity/,Sherbhy,1526821658,"The course is no longer available on Udacity. Is there any link to all the videos? The youtube playlist only has clips not the full content.

Or any other good course on CUDA?",19,135
1021,2018-5-20,2018,5,20,22,8ksiee,"[P] Writing my IB Extended Essay on an aspect of Machine Learning, and was looking for idea inspiration.",https://www.reddit.com/r/MachineLearning/comments/8ksiee/p_writing_my_ib_extended_essay_on_an_aspect_of/,kjaisingh,1526821835,"I've had a ton of experience in the field, and should be able to manage investigating elements of Machine Learning. A friend of mine who scored very well evaluated the performance of Stochastic Gradient Descent in comparison to L\-BFGS. Was wondering if anyone had any ideas that would follow a format similar to this?",10,4
1022,2018-5-20,2018,5,20,22,8kslyu,Pieter Abeel Presentation at ICRA,https://www.reddit.com/r/MachineLearning/comments/8kslyu/pieter_abeel_presentation_at_icra/,vector_machines,1526823040,[removed],0,1
1023,2018-5-20,2018,5,20,23,8ksv6q,Study Related,https://www.reddit.com/r/MachineLearning/comments/8ksv6q/study_related/,Anony1202,1526825817,Hi. I want to start studying Machine learning as I believe it's the field of the future. However I have been overwhelmed by the amount of information present on the web and so I'm unable to decide from where should I start and what the prerequisites are for starting a beginner course. I have a 3 year experience in C++ and I will be starting my 3rd semester in engineering. If anyone can help it'll be appreciated. Thanks,0,1
1024,2018-5-20,2018,5,20,23,8ksw5q,Join us at the university of Brussels on June 27,https://www.reddit.com/r/MachineLearning/comments/8ksw5q/join_us_at_the_university_of_brussels_on_june_27/,disummit,1526826099,,0,1
1025,2018-5-21,2018,5,21,1,8ktn8j,COTS Object Recognition and Analysyis,https://www.reddit.com/r/MachineLearning/comments/8ktn8j/cots_object_recognition_and_analysyis/,idg101,1526833463,[removed],0,1
1026,2018-5-21,2018,5,21,1,8ktolo,Reinforcement Learning for Real Life Planning Problems,https://www.reddit.com/r/MachineLearning/comments/8ktolo/reinforcement_learning_for_real_life_planning/,osbornep,1526833826,,1,1
1027,2018-5-21,2018,5,21,1,8ktpw0,[D] ML in Computer Graphics,https://www.reddit.com/r/MachineLearning/comments/8ktpw0/d_ml_in_computer_graphics/,Sherbhy,1526834150,"I know Computer Graphics sounds very broad, but I'm new to the field and I've always had a passion of working with CG.

By ML in CG I mean the core stuff like rendering and not just Computer Vision.

* How ML can be used to improve CG
* How can ML speed up the rendering process
* What are the steps to go about as a learner \(some good MOOCs would be awesome\)
* What are the popular models used today
* How is this as a research field
* Are there any jobs specifically for this
* Which companies do good research on this \(like NVidia\)
* Any mentors willing to help?",11,8
1028,2018-5-21,2018,5,21,1,8ktrno,The limits of machine learning?,https://www.reddit.com/r/MachineLearning/comments/8ktrno/the_limits_of_machine_learning/,milkmandan,1526834600,[removed],0,1
1029,2018-5-21,2018,5,21,1,8ktsl0,Reinforcement Learning - Markov Decision Process,https://www.reddit.com/r/MachineLearning/comments/8ktsl0/reinforcement_learning_markov_decision_process/,OneRaynyDay,1526834842,,0,1
1030,2018-5-21,2018,5,21,1,8ktsp8,"Awesome Links of Books, Courses, Examples for AI, MachineLearning, DeepLearning and Tensorflow in",https://www.reddit.com/r/MachineLearning/comments/8ktsp8/awesome_links_of_books_courses_examples_for_ai/,wxchevalier,1526834880,,0,1
1031,2018-5-21,2018,5,21,1,8ktt59,[D] Reinforcement Learning - Markov Decision Process,https://www.reddit.com/r/MachineLearning/comments/8ktt59/d_reinforcement_learning_markov_decision_process/,OneRaynyDay,1526834994,,2,52
1032,2018-5-21,2018,5,21,2,8ktwd4,Do you pay any for Machine Learning software/service?,https://www.reddit.com/r/MachineLearning/comments/8ktwd4/do_you_pay_any_for_machine_learning/,MessyML,1526835804,[removed],0,1
1033,2018-5-21,2018,5,21,2,8ktzdf,Self Driving Cars Explained,https://www.reddit.com/r/MachineLearning/comments/8ktzdf/self_driving_cars_explained/,funmaster11,1526836544,,0,1
1034,2018-5-21,2018,5,21,2,8ktziq,My personal blog about machine learning and artificial intelligence [D],https://www.reddit.com/r/MachineLearning/comments/8ktziq/my_personal_blog_about_machine_learning_and/,Sushrit_Lawliet,1526836578,,0,1
1035,2018-5-21,2018,5,21,2,8ku2r1,Comparing Neural Networks to their Biological counterparts... [D],https://www.reddit.com/r/MachineLearning/comments/8ku2r1/comparing_neural_networks_to_their_biological/,Sushrit_Lawliet,1526837351,,0,1
1036,2018-5-21,2018,5,21,4,8kuplu,[Discussion] Is learning ML really worth it?,https://www.reddit.com/r/MachineLearning/comments/8kuplu/discussion_is_learning_ml_really_worth_it/,daravis,1526842943,"Hello guys. I am currently a student and i am learning basic conecepts of machine learning at my spare time. As you may have noticed, there are already some tools that do most of the machine learning work, like rapid miner. Soon, Google's autoML is going to come out too. My questions are: is it really worth it to learn ML? Are services like the ones mentioned going to dominate? Should i keep studying or should i focus somewhere else? 

Thanks for all the answers ",6,0
1037,2018-5-21,2018,5,21,6,8kvrjm,[P] Independently Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8kvrjm/p_independently_recurrent_neural_networks/,downtownslim,1526852273,,15,100
1038,2018-5-21,2018,5,21,7,8kw8z3,Best AI movies/TV shows/documentaries?,https://www.reddit.com/r/MachineLearning/comments/8kw8z3/best_ai_moviestv_showsdocumentaries/,dude0413,1526856748,[removed],0,1
1039,2018-5-21,2018,5,21,7,8kwa4c,Laurel Yanny sound - fourier transform visualized. Link to python code in description.,https://www.reddit.com/r/MachineLearning/comments/8kwa4c/laurel_yanny_sound_fourier_transform_visualized/,rohitpandey576,1526857051,,0,1
1040,2018-5-21,2018,5,21,8,8kwd8t,Can comparator networks be generated using ML?,https://www.reddit.com/r/MachineLearning/comments/8kwd8t/can_comparator_networks_be_generated_using_ml/,deadcodder,1526857869,[removed],0,1
1041,2018-5-21,2018,5,21,8,8kwhs6,Pytorch vs Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8kwhs6/pytorch_vs_tensorflow/,srivatsanrr,1526859112,[removed],0,1
1042,2018-5-21,2018,5,21,9,8kwtk6,[R] ICML 2018 Accepted Papers,https://www.reddit.com/r/MachineLearning/comments/8kwtk6/r_icml_2018_accepted_papers/,anishathalye,1526862411,,28,57
1043,2018-5-21,2018,5,21,9,8kwz94,Really nice summary of AI history,https://www.reddit.com/r/MachineLearning/comments/8kwz94/really_nice_summary_of_ai_history/,ScotchMonk,1526864009,,0,1
1044,2018-5-21,2018,5,21,11,8kxg5k,What do you wish you did in college as an undergraduate?,https://www.reddit.com/r/MachineLearning/comments/8kxg5k/what_do_you_wish_you_did_in_college_as_an/,sugarhilldt2,1526868743,[removed],0,1
1045,2018-5-21,2018,5,21,11,8kxgaw,[D] What do you wish you did in college as an undergraduate?,https://www.reddit.com/r/MachineLearning/comments/8kxgaw/d_what_do_you_wish_you_did_in_college_as_an/,sugarhilldt2,1526868788,Any advice for a senior stats major?,39,10
1046,2018-5-21,2018,5,21,11,8kxl5f,arVix Endorsement request for a NIPS2018 submission,https://www.reddit.com/r/MachineLearning/comments/8kxl5f/arvix_endorsement_request_for_a_nips2018/,lansiz,1526870188,"HI there, 
I want to submit this paper to arVix, but don't have any endorsor in my vicinity. This is a serious preprint, and you can contact me by lansiz@qq.com if any doubt.
Please help.

This is the screenshot of NIPS2018 submission page:
http://tc.nzqrc.cn/nips2018.png
This is my endorsement link:
https://arxiv.org/auth/endorse?x=RROUQM

Thanks again.

",0,1
1047,2018-5-21,2018,5,21,11,8kxoo5,"[Projects]SRGAN with WGAN, making the super-resolution model training procedure more stable",https://www.reddit.com/r/MachineLearning/comments/8kxoo5/projectssrgan_with_wgan_making_the/,lamborhino,1526871187,[removed],0,1
1048,2018-5-21,2018,5,21,12,8kxr3e,Basics of Predictive Modeling,https://www.reddit.com/r/MachineLearning/comments/8kxr3e/basics_of_predictive_modeling/,ajkn1992,1526871884,,0,1
1049,2018-5-21,2018,5,21,12,8kxsux,What product(s) services(s) do you PAY for your machine learning workflow?,https://www.reddit.com/r/MachineLearning/comments/8kxsux/what_products_servicess_do_you_pay_for_your/,MessyML,1526872398,[removed],0,1
1050,2018-5-21,2018,5,21,12,8kxupj,"Hi Minh l ni cung cp my o  m go cng cc thit b o  m chnh hng uy tn nht, cht lng nht m gi thnh cnh tranh nht trn th trng.",https://www.reddit.com/r/MachineLearning/comments/8kxupj/hi_minh_l_ni_cung_cp_my_o__m_go_cng/,HangNguyen1111,1526872941,,0,1
1051,2018-5-21,2018,5,21,12,8kxx5t,My hn ming ti dp tay thng s dng ngun in 220V hot ng theo c ch dng nhit  ca thanh hn  lm kn ming ti bng nha hay nilon.,https://www.reddit.com/r/MachineLearning/comments/8kxx5t/my_hn_ming_ti_dp_tay_thng_s_dng_ngun/,HangNguyen1111,1526873686,,0,1
1052,2018-5-21,2018,5,21,12,8kxzje,"Trong xy dng th my o  m vt liu hay my o  m g l mt thit b khng th thiu, n c vai tr quan trng khi xc nh  m ca g, ca b tng...",https://www.reddit.com/r/MachineLearning/comments/8kxzje/trong_xy_dng_th_my_o__m_vt_liu_hay_my/,HangNguyen1111,1526874393,,0,1
1053,2018-5-21,2018,5,21,13,8ky2ad,[D] What product(s) services(s) do you (or your company) currently PAY for your machine learning workflow?,https://www.reddit.com/r/MachineLearning/comments/8ky2ad/d_what_products_servicess_do_you_or_your_company/,MessyML,1526875249,"Data wrangling, software plugins, etc.

Contrary, what are the best FREE product\(s\) services\(s\)  for your machine learning workflow?

Is there a tool you wish existed that you cannot find?",20,7
1054,2018-5-21,2018,5,21,13,8ky2pu,n dit cn trng c th bt mui v cc loi cn trng khc mt cch hiu qu mang li mi trng sng trong sch t mm bnh hn.,https://www.reddit.com/r/MachineLearning/comments/8ky2pu/n_dit_cn_trng_c_th_bt_mui_v_cc_loi/,HangNguyen1111,1526875355,,0,1
1055,2018-5-21,2018,5,21,13,8ky53s,"My hn ming ti lin tc thng c s dng trong cc xng sn xut ln, khi m lng hng ha cn ng gi c s lng nhiu.",https://www.reddit.com/r/MachineLearning/comments/8ky53s/my_hn_ming_ti_lin_tc_thng_c_s_dng/,HangNguyen1111,1526876080,,0,1
1056,2018-5-21,2018,5,21,13,8ky7o6,My hn ming ti dp tay thng s dng ngun in 220V  hot ng v c th thay i nhit  ca thanh hn ming ti sao cho ph hp.,https://www.reddit.com/r/MachineLearning/comments/8ky7o6/my_hn_ming_ti_dp_tay_thng_s_dng_ngun/,HangNguyen1111,1526876905,,0,1
1057,2018-5-21,2018,5,21,13,8kybrb,Jason's Machine Learning 101 (updated),https://www.reddit.com/r/MachineLearning/comments/8kybrb/jasons_machine_learning_101_updated/,tzuryby,1526878282,,0,1
1058,2018-5-21,2018,5,21,13,8kybuw,Machine Learning Online Training,https://www.reddit.com/r/MachineLearning/comments/8kybuw/machine_learning_online_training/,kernel77,1526878319,,0,1
1059,2018-5-21,2018,5,21,14,8kyfs1,[N] Machine Learning Online Training by Kernel,https://www.reddit.com/r/MachineLearning/comments/8kyfs1/n_machine_learning_online_training_by_kernel/,kernel77,1526879622,,0,5
1060,2018-5-21,2018,5,21,15,8kyqu7,[D] Rules of Machine Learning: | Machine Learning Rules | Google Developers,https://www.reddit.com/r/MachineLearning/comments/8kyqu7/d_rules_of_machine_learning_machine_learning/,sksq9,1526883653,,7,240
1061,2018-5-21,2018,5,21,15,8kyv22,[D] Email data set for sentiment analysis demos,https://www.reddit.com/r/MachineLearning/comments/8kyv22/d_email_data_set_for_sentiment_analysis_demos/,Phorc3,1526885253,"Hi there,

Does anyone know of any large email data sets \(that are not Enron\) hopefully something over the last few years or so. We are trying to work on different platforms to test their sentiment analysis. 

We found with the Enron emails that they were not a good enough set probably due to age for this type of work. 

Thanks

Phorc3. ",6,1
1062,2018-5-21,2018,5,21,18,8kzias,[D] Please help me find this mathematical paper / blog post about RL,https://www.reddit.com/r/MachineLearning/comments/8kzias/d_please_help_me_find_this_mathematical_paper/,bagelorder,1526894468,"At some point 1 or 2 years ago I somehow stumbled upon a blog post about RL where he wrote that he read a paper a few days ago, summarized it and that he had some new idea about that paper. Since I had exams coming up I thought I'd read it later and then never found it again.

It was a pretty short post and unfortunately I remember very bad. But it was about having the trajectory of the agent as path gamma: R -&gt; R^n and then taking some derivatives and of the cost functional (which was just some integral over the path) and then maybe getting some kind of stochastic differential equation?

If anyone even feels vaguely reminded about anything, please tell me. Thank you",0,8
1063,2018-5-21,2018,5,21,18,8kzmvb,7 Major Areas of SAS Innovations For Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8kzmvb/7_major_areas_of_sas_innovations_for_machine/,imarticus_nirmal,1526896319,,0,1
1064,2018-5-21,2018,5,21,19,8kzpi5,[P] Machine Learning Open Source of the Month (v.May 2018),https://www.reddit.com/r/MachineLearning/comments/8kzpi5/p_machine_learning_open_source_of_the_month_vmay/,PaulgibPaul,1526897324,,0,1
1065,2018-5-21,2018,5,21,19,8kzpzq,[P] Machine Learning Open Source of the Month (v.May 2018),https://www.reddit.com/r/MachineLearning/comments/8kzpzq/p_machine_learning_open_source_of_the_month_vmay/,amitjyothie,1526897502,,0,1
1066,2018-5-21,2018,5,21,19,8kzqls,[R] Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum (ACL 2018),https://www.reddit.com/r/MachineLearning/comments/8kzqls/r_long_shortterm_memory_as_a_dynamically_computed/,ofirpress,1526897725,,3,21
1067,2018-5-21,2018,5,21,19,8kzt89,[P]Machine Learning Open Source of the Month (v.May 2018),https://www.reddit.com/r/MachineLearning/comments/8kzt89/pmachine_learning_open_source_of_the_month_vmay/,kumeralex,1526898691,,0,27
1068,2018-5-21,2018,5,21,19,8kztv7,"how to Tuning in LighGBM? I want to learning how to Tuning in LightGBM, Could you help me with suggestion some materials about it. Thanks you very much",https://www.reddit.com/r/MachineLearning/comments/8kztv7/how_to_tuning_in_lighgbm_i_want_to_learning_how/,rosandonary,1526898923,[removed],0,1
1069,2018-5-21,2018,5,21,20,8kzywm,5 Reasons to Learn Linear Algebra for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8kzywm/5_reasons_to_learn_linear_algebra_for_machine/,imarticus_nirmal,1526900687,,0,1
1070,2018-5-21,2018,5,21,20,8l0137,"Polysemy Embeddings, Semi Adversarial Networks, ULMFiT, Color Naming, Sentiment Style Transfer,",https://www.reddit.com/r/MachineLearning/comments/8l0137/polysemy_embeddings_semi_adversarial_networks/,omarsar,1526901365,,0,1
1071,2018-5-21,2018,5,21,20,8l02gb,Peanut Almond Nut Particle Cutting Machine|Walnut Chopping Cutter Machine,https://www.reddit.com/r/MachineLearning/comments/8l02gb/peanut_almond_nut_particle_cutting_machinewalnut/,Machineprices,1526901849,,1,1
1072,2018-5-21,2018,5,21,21,8l09yc,Join us on to understand the basics of Python Machine Learning. We will review the core concepts of machine learning. You will understand the difference between supervised learning and unsupervised learning. When to use which type of algorithm and other important aspects of machine learning.,https://www.reddit.com/r/MachineLearning/comments/8l09yc/join_us_on_to_understand_the_basics_of_python/,MCAL_Training,1526904126,,0,1
1073,2018-5-21,2018,5,21,21,8l0ijf,AI Re-writer,https://www.reddit.com/r/MachineLearning/comments/8l0ijf/ai_rewriter/,mistertipster,1526906528,[removed],0,1
1074,2018-5-21,2018,5,21,22,8l0o1v,RL Elevator Challenge,https://www.reddit.com/r/MachineLearning/comments/8l0o1v/rl_elevator_challenge/,_sshin_,1526908013,,0,1
1075,2018-5-21,2018,5,21,22,8l0olq,[P] RL Elevator Challenge,https://www.reddit.com/r/MachineLearning/comments/8l0olq/p_rl_elevator_challenge/,_sshin_,1526908159,,35,213
1076,2018-5-21,2018,5,21,22,8l0pkt,"GANs, capacity, and the generalization problem",https://www.reddit.com/r/MachineLearning/comments/8l0pkt/gans_capacity_and_the_generalization_problem/,geodesic42,1526908410,[removed],0,1
1077,2018-5-21,2018,5,21,23,8l111c,"[D] GANs, capacity, and the generalization problem",https://www.reddit.com/r/MachineLearning/comments/8l111c/d_gans_capacity_and_the_generalization_problem/,geodesic42,1526911312,"GANs are formulated as a game between two networks that compete to reach Nash equilibrium. There's a discriminator, D, which attempts to distinguish between real and fake data, and a generator, G, that attempts to trick D. Data is labeled as synthetic or real, D is trained to minimize the NLL of the labeled data, and G is trained to maximize it.

It seems to me that, given infinite capacity, D could simply learn that every single example that isn't the real data is synthetic; G would then learn to simply reproduce the real data verbatim, more likely settling on a single example (mode collapse) since constant functions are easy to learn; promoting D to a distribution, Nash equilibrium would then be reached by D assigning 1/2 to each singular data point G could replicate. But this evidently doesn't happen, at least not all the time.

I'm a bit perplexed by why it doesn't play out like this. If I had to guess, it probably has something to do with either the limited capacity of networks, or an inexplicable ability for D to generalize as intended. The former is unsatisfying on theoretical grounds - purposefully needing to limit a network's capacity, in an unclear manner, seems counterproductive - and the latter just seems unlikely. I've seen attempts at relaxing D by adding noise to the real data to force it to widen its distribution/give D finite support, but I haven't seen good motivation for the scale of the noise - can't have D accept too many things as real, can we? Leaving it as yet another hyperparameter also seems silly.

Can anyone elucidate what's going on here?

Apologies if I'm missing something obvious, or if this has been discussed at length elsewhere. If this is addressed in the literature, I would greatly appreciate any references. Thanks! :)",17,31
1078,2018-5-21,2018,5,21,23,8l184d,[D] Neural Network for Analyzing Driving Data,https://www.reddit.com/r/MachineLearning/comments/8l184d/d_neural_network_for_analyzing_driving_data/,all_about_effort,1526912989,"**The Problem**

I'm starting a project to analyze driving risk based on a sequence of waypoints that represent a vehicle's path. The waypoints are 1 minute apart, but I'm building another training set with shorter intervals for a future test run. The amount of waypoints per driving period is highly variable since some trips are longer than others.

**Choice of Network**

I'm familiar with feed-forward and deep feed-forward neural networks, but I'm not sure either of them is the best tool for this problem. I was thinking of using an LSTM network or a Deep Convolutional Network.

**Pre-Processing and/or Post-Processing**

I'm thinking about ways of pre-processing the waypoints into data segments (ie avg speed, distance, etc), then using the network to analyze each segment rather than the whole waypoint stream. Or perhaps using the network to analyze chunks of raw waypoints (say 50 at a time) and generating a risk score for that segment, then taking the mean.

**Recommendations?**

I'm curious about other people's thoughts on how the problem can be modeled. What are your opinions on the choice of network and data pre/post processing?

Thanks.",0,5
1079,2018-5-21,2018,5,21,23,8l188z,[R] Polyphonic Pitch Tracking with Deep Layered Learning,https://www.reddit.com/r/MachineLearning/comments/8l188z/r_polyphonic_pitch_tracking_with_deep_layered/,AElowsson,1526913023,,5,6
1080,2018-5-21,2018,5,21,23,8l1anb,CNN insights: What do convolutional neural networks learn about free text? Part 1 of 7,https://www.reddit.com/r/MachineLearning/comments/8l1anb/cnn_insights_what_do_convolutional_neural/,nlpster,1526913567,,0,1
1081,2018-5-21,2018,5,21,23,8l1dpg,Deep learning paper submission,https://www.reddit.com/r/MachineLearning/comments/8l1dpg/deep_learning_paper_submission/,UpstairsCurrency,1526914270,[removed],0,1
1082,2018-5-21,2018,5,21,23,8l1eua,What are the coolest things being done in unsupervised learning?,https://www.reddit.com/r/MachineLearning/comments/8l1eua/what_are_the_coolest_things_being_done_in/,ishaq_adenali,1526914529,[removed],0,1
1083,2018-5-22,2018,5,22,1,8l1zxl,[D] Simple to use library for black box optimization of neuronal network weights,https://www.reddit.com/r/MachineLearning/comments/8l1zxl/d_simple_to_use_library_for_black_box/,kalabele,1526919145,"I am trying to optimize an agent in a simple simulation. For now, I do not want the agent to take the current state into consideration. Instead, it should just react to the environment. My idea is to model the agent as a neuronal network. The simulation results in a score, which I want to maximize.

As far as I understand, I could try to use deep reinforcement learning. However, I have the impression, that it might be faster to treat the simulation as a black box function which I want to optimize. Therefore, I need an optimization algorithm  which does not require a gradient to optimize the weights of my neuronal network. If I am not mistaken, deep neuro evolution might be an option. Unfortunately, I haven't been able to find a simple to use library yet.

Does anybody know of a library which could help me to solve this problem? Right now, it's most important that it is simple to use and does not require a lot of knowledge.

I am using Python, Keras ans Tensorflow.",2,0
1084,2018-5-22,2018,5,22,1,8l226z,"Date Extended June 05, 2018: 10th International Conference on Intelligent Human Computer Interaction (IHCI 2018)",https://www.reddit.com/r/MachineLearning/comments/8l226z/date_extended_june_05_2018_10th_international/,ihciconf,1526919634,,0,1
1085,2018-5-22,2018,5,22,1,8l26aw,OpenStreetCam sign detection code and training data open sourced,https://www.reddit.com/r/MachineLearning/comments/8l26aw/openstreetcam_sign_detection_code_and_training/,mvexel,1526920509,,0,1
1086,2018-5-22,2018,5,22,2,8l2miw,Are there any references of nlp/text mining techniques for Identifying the theme of News headlines,https://www.reddit.com/r/MachineLearning/comments/8l2miw/are_there_any_references_of_nlptext_mining/,kumarivin,1526923862,[removed],0,1
1087,2018-5-22,2018,5,22,2,8l2ug1,Exploration in RL: Workshop @ ICML 2018,https://www.reddit.com/r/MachineLearning/comments/8l2ug1/exploration_in_rl_workshop_icml_2018/,b_eysenbach,1526925462,,0,1
1088,2018-5-22,2018,5,22,3,8l2xjl,[R] Towards Robust Neural Machine Translation (ACL 2018),https://www.reddit.com/r/MachineLearning/comments/8l2xjl/r_towards_robust_neural_machine_translation_acl/,ofirpress,1526926088,,0,4
1089,2018-5-22,2018,5,22,3,8l31zj,https://arxiv.org/abs/1805.07072,https://www.reddit.com/r/MachineLearning/comments/8l31zj/httpsarxivorgabs180507072/,sbarratt,1526927062,,0,1
1090,2018-5-22,2018,5,22,3,8l3243,Optimizing for Generalization in Machine Learning with Cross-Validation Gradients,https://www.reddit.com/r/MachineLearning/comments/8l3243/optimizing_for_generalization_in_machine_learning/,sbarratt,1526927087,,0,1
1091,2018-5-22,2018,5,22,3,8l36po,I'm writing a series of tutorials on my ML Server build. Hope someone else finds it useful :),https://www.reddit.com/r/MachineLearning/comments/8l36po/im_writing_a_series_of_tutorials_on_my_ml_server/,PolitiProcess,1526928114,,0,1
1092,2018-5-22,2018,5,22,3,8l38lw,[R] Exploration in RL: Workshop @ ICML 2018,https://www.reddit.com/r/MachineLearning/comments/8l38lw/r_exploration_in_rl_workshop_icml_2018/,b_eysenbach,1526928502,,1,11
1093,2018-5-22,2018,5,22,3,8l3aum,New edition of Machine Learning Magazine!,https://www.reddit.com/r/MachineLearning/comments/8l3aum/new_edition_of_machine_learning_magazine/,zofia_mlmag_co,1526928982,[removed],0,1
1094,2018-5-22,2018,5,22,4,8l3j07,"Top 11 Books for Deep Learning, Neural Networks, and TensorFlow",https://www.reddit.com/r/MachineLearning/comments/8l3j07/top_11_books_for_deep_learning_neural_networks/,kjahan,1526930757,,0,1
1095,2018-5-22,2018,5,22,5,8l3ttz,"Audio-Vision: Implementation and applications for Deep Learning papers on Audio(scene recognition, tagging), visual question answering, architectures(parallel CNN, Recurrent convolutional network).",https://www.reddit.com/r/MachineLearning/comments/8l3ttz/audiovision_implementation_and_applications_for/,akshitac8,1526933128,[removed],0,1
1096,2018-5-22,2018,5,22,5,8l452a,Most interesting startups you've seen in the AI space?,https://www.reddit.com/r/MachineLearning/comments/8l452a/most_interesting_startups_youve_seen_in_the_ai/,golfboy689,1526935633,[removed],1,1
1097,2018-5-22,2018,5,22,7,8l4oqk,What is the process for writing an academic paper?,https://www.reddit.com/r/MachineLearning/comments/8l4oqk/what_is_the_process_for_writing_an_academic_paper/,MarxSoul55,1526940080,[removed],0,1
1098,2018-5-22,2018,5,22,7,8l52sy,Zero-overhead Scalable Machine Learning with Studio.ML,https://www.reddit.com/r/MachineLearning/comments/8l52sy/zerooverhead_scalable_machine_learning_with/,andrewturnerrr,1526943470,,0,1
1099,2018-5-22,2018,5,22,8,8l54pr,[P] Building a Simple Self-Driving Car Simulator,https://www.reddit.com/r/MachineLearning/comments/8l54pr/p_building_a_simple_selfdriving_car_simulator/,hardmaru,1526943936,,2,9
1100,2018-5-22,2018,5,22,8,8l5832,[D] Distillation from teacher model's prediction error?,https://www.reddit.com/r/MachineLearning/comments/8l5832/d_distillation_from_teacher_models_prediction/,wsxiaoys,1526944789,"A friend described a following model they used for a classification problem:

    1. Train the teacher model f(x) with ground truth label y
    2. Train the student model g(x) with f(x) - y, with features that not used in f(x).
    
    Acquired g(x) will be a model that's independent to features used in f(x)

Intuitively the conclusion seems reasonable, but I find few papers / discussion talked about this setting. I personally think this is just a special kind of distillation. 

Have you encountered similar problems? Any related papers / articles?",2,3
1101,2018-5-22,2018,5,22,9,8l5mzz,Solving the Rubik's Cube Without Human Knowledge,https://www.reddit.com/r/MachineLearning/comments/8l5mzz/solving_the_rubiks_cube_without_human_knowledge/,mcaleste,1526948483,,0,1
1102,2018-5-22,2018,5,22,9,8l5ooi,[Research] Researchers create NN to remove noise from photos and see in the dark,https://www.reddit.com/r/MachineLearning/comments/8l5ooi/research_researchers_create_nn_to_remove_noise/,KyungSun,1526948896,,5,47
1103,2018-5-22,2018,5,22,10,8l5w56,[P] Generative Ramen,https://www.reddit.com/r/MachineLearning/comments/8l5w56/p_generative_ramen/,wei_jok,1526950824,,81,1290
1104,2018-5-22,2018,5,22,10,8l5w9m,[R] Solving the Rubik's Cube Without Human Knowledge,https://www.reddit.com/r/MachineLearning/comments/8l5w9m/r_solving_the_rubiks_cube_without_human_knowledge/,mcaleste,1526950852,,1,16
1105,2018-5-22,2018,5,22,10,8l5ybs,[N] Ben Goertzel at AiDecentralized - Topics &amp; Schedule,https://www.reddit.com/r/MachineLearning/comments/8l5ybs/n_ben_goertzel_at_aidecentralized_topics_schedule/,ibbybenali,1526951347,,0,1
1106,2018-5-22,2018,5,22,10,8l64y1,"[N] Snap ML - An IBM framework for all machine learning, except deep learning",https://www.reddit.com/r/MachineLearning/comments/8l64y1/n_snap_ml_an_ibm_framework_for_all_machine/,MessyML,1526952953,,6,0
1107,2018-5-22,2018,5,22,11,8l6mi4,S RL ND SINR LV S WI UNG WN F  F  WRLD R.,https://www.reddit.com/r/MachineLearning/comments/8l6mi4/s_rl_nd_sinr_lv_s_wi_ung_wn/,popc0rn9000,1526957282,[removed],0,1
1108,2018-5-22,2018,5,22,13,8l74eh,[P] Deploy Keras Neural Network to Flask web service - Video series,https://www.reddit.com/r/MachineLearning/comments/8l74eh/p_deploy_keras_neural_network_to_flask_web/,blackHoleDetector,1526961943,"Learn how to deploy and host your machine learning model as a Flask web service, build a front end web application to access your model, and interact with your model in the browser with this video series.

- [Deploy Keras Neural Network to Flask web service | Part 1 - Overview](https://youtu.be/SI1hVGvbbZ4)
- [Deploy Keras neural network to Flask web service | Part 2 - Build your first Flask app](https://youtu.be/_yoxrAIf5u4)
- [Deploy Keras neural network to Flask web service | Part 3 - Send and Receive Data with Flask](https://youtu.be/RkmfXz304ck)
- [Deploy Keras neural network to Flask web service | Part 4 - Build a front end web application](https://youtu.be/TW_ck9NDMGI)
- [Deploy Keras neural network to Flask web service | Part 5 - Host VGG16 model with Flask](https://youtu.be/XgzxH6G-ufA)
- [Deploy Keras neural network to Flask web service | Part 6 - Build web app to send images to VGG16](https://youtu.be/eCz_DTtUBfo)",0,33
1109,2018-5-22,2018,5,22,13,8l75d1,[D] An overview of semantic image segmentation.,https://www.reddit.com/r/MachineLearning/comments/8l75d1/d_an_overview_of_semantic_image_segmentation/,jremsj,1526962199,,7,12
1110,2018-5-22,2018,5,22,13,8l78wd,[P] GAN Anime Blockchain,https://www.reddit.com/r/MachineLearning/comments/8l78wd/p_gan_anime_blockchain/,chisai_mikan,1526963201,,28,51
1111,2018-5-22,2018,5,22,13,8l79ed,Machine Learning for beginners,https://www.reddit.com/r/MachineLearning/comments/8l79ed/machine_learning_for_beginners/,jbuoy,1526963361,[removed],0,2
1112,2018-5-22,2018,5,22,14,8l7ijg,[D] If you like youtube channel two minutes papers then you will like...,https://www.reddit.com/r/MachineLearning/comments/8l7ijg/d_if_you_like_youtube_channel_two_minutes_papers/,begooboi,1526966127,,13,13
1113,2018-5-22,2018,5,22,15,8l80om,how to use a fixed model to build a real time scoring list with spark streaming/kafka?,https://www.reddit.com/r/MachineLearning/comments/8l80om/how_to_use_a_fixed_model_to_build_a_real_time/,Joe_pgen,1526972025,[removed],0,1
1114,2018-5-22,2018,5,22,16,8l82jx,"Date Extended June 05, 2018: 10th International Conference on Intelligent Human Computer Interaction (IHCI 2018)",https://www.reddit.com/r/MachineLearning/comments/8l82jx/date_extended_june_05_2018_10th_international/,ihciconf,1526972680,[removed],0,1
1115,2018-5-22,2018,5,22,16,8l8bdv,How is your ECCV reviews?,https://www.reddit.com/r/MachineLearning/comments/8l8bdv/how_is_your_eccv_reviews/,mkocabas,1526975924,,0,1
1116,2018-5-22,2018,5,22,17,8l8cbd,[D] Hinton: Multi-layer neural networks should never been called MLPs,https://www.reddit.com/r/MachineLearning/comments/8l8cbd/d_hinton_multilayer_neural_networks_should_never/,phizaz,1526976320,,7,8
1117,2018-5-22,2018,5,22,17,8l8hqc,Understanding the forecasting algorithm: STLF Model,https://www.reddit.com/r/MachineLearning/comments/8l8hqc/understanding_the_forecasting_algorithm_stlf_model/,Fewthp,1526978607,,0,1
1118,2018-5-22,2018,5,22,17,8l8j1e,How fast is pruned alexnet to compare with alexnet ?,https://www.reddit.com/r/MachineLearning/comments/8l8j1e/how_fast_is_pruned_alexnet_to_compare_with_alexnet/,khongop,1526979112,[removed],0,1
1119,2018-5-22,2018,5,22,18,8l8kp9,[D] Training a Simple Binary Classifier Using Logistic Regression,https://www.reddit.com/r/MachineLearning/comments/8l8kp9/d_training_a_simple_binary_classifier_using/,lord-bazooka,1526979768,,0,0
1120,2018-5-22,2018,5,22,18,8l8syw,"Global Wireless Fire Detection System Market by Manufacturers, Countries, Type and Application, Forecast to 2023",https://www.reddit.com/r/MachineLearning/comments/8l8syw/global_wireless_fire_detection_system_market_by/,maheshbhosale1634,1526982924,,0,1
1121,2018-5-22,2018,5,22,19,8l92rw,[D] How impactful could the choice of the Optimizer in NN be ?,https://www.reddit.com/r/MachineLearning/comments/8l92rw/d_how_impactful_could_the_choice_of_the_optimizer/,swentso,1526986433,"Hi,

I was training a simple fully connected NN recently (on keras), and was stuck at a certain accuracy (45%) using [SGD](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/keras/optimizers/SGD). But as soon as I changed it to [Adam](https://www.tensorflow.org/api_docs/python/tf/contrib/keras/optimizers/Adam) the loss started dropping drastically and the performance went way up (~70% accuracy).

I always thought optimizer choice would only help accelerate training a little or gain few % on accuracy, but bot this much.

Did anyone experience the same thing (or is there rather something wrong with my implementation)? How do you chose your optimizers ?",20,4
1122,2018-5-22,2018,5,22,21,8l9fsm,Compound Potato Chips Making Machine Suppliers,https://www.reddit.com/r/MachineLearning/comments/8l9fsm/compound_potato_chips_making_machine_suppliers/,lgsherry,1526990509,,1,1
1123,2018-5-22,2018,5,22,21,8l9iak,Book machine learning,https://www.reddit.com/r/MachineLearning/comments/8l9iak/book_machine_learning/,bVdMaker,1526991204,[removed],0,1
1124,2018-5-22,2018,5,22,21,8l9n4l,Machines at Work: Understanding the Ins and Outs of AI and Machine Learning - DZone AI,https://www.reddit.com/r/MachineLearning/comments/8l9n4l/machines_at_work_understanding_the_ins_and_outs/,jamespowell014,1526992547,[removed],0,1
1125,2018-5-22,2018,5,22,21,8l9rfq,Acrylic bathtub vacuum forming machine,https://www.reddit.com/r/MachineLearning/comments/8l9rfq/acrylic_bathtub_vacuum_forming_machine/,smemachine,1526993744,,0,1
1126,2018-5-22,2018,5,22,23,8la887,[D] Applying OpenAI Baselines to anything other than Atari Games possible?,https://www.reddit.com/r/MachineLearning/comments/8la887/d_applying_openai_baselines_to_anything_other/,malusmax,1526997914,"This is a genuine question! If you look into the code, you'll find they are calling properties on the observation space variables that are passed into the learners that don't exist. I am trying to do policysearch with a dict based observationspace. Nothing suggests that wouldn't be possible. Except for the fact that they call 

`ob_space.shape` on the passed space which is never set because they have another line

```python
gym.Space.__init__(self, None, None) # None for shape and dtype, since it'll require special handling
```
so ... rewriting the code to be a tuple now. Fine, I'll survive that. But that doesn't get a shape applied either. bloody hell! Box does, but that doesn't quiet work because my Box spaces have different min/max...

So... it feels a lot like the ""high quality baselines"" are very much a ""medium quality non-test-covered atari game learner algorithms"", much less a baseline for RL learning of various tasks.

",8,5
1127,2018-5-22,2018,5,22,23,8ladyj,The Lottery Ticket Hypothesis,https://www.reddit.com/r/MachineLearning/comments/8ladyj/the_lottery_ticket_hypothesis/,alexeyr,1526999236,,0,1
1128,2018-5-22,2018,5,22,23,8lah4j,[P] Hierarchical Neural Story Generation,https://www.reddit.com/r/MachineLearning/comments/8lah4j/p_hierarchical_neural_story_generation/,steuhh,1526999971,,5,22
1129,2018-5-23,2018,5,23,0,8lao1e,"Is there a tSNE equivalent of ""PCA Loadings""",https://www.reddit.com/r/MachineLearning/comments/8lao1e/is_there_a_tsne_equivalent_of_pca_loadings/,tsnequestion,1527001513,[removed],0,1
1130,2018-5-23,2018,5,23,0,8lap1f,[R] New Newton solver beats SGD and Adam for large models on ImageNet/CIFAR,https://www.reddit.com/r/MachineLearning/comments/8lap1f/r_new_newton_solver_beats_sgd_and_adam_for_large/,brainggear,1527001727,,43,101
1131,2018-5-23,2018,5,23,0,8lapfo,ClassificaIO -- Simple to use user interface for the Scikit-learn library,https://www.reddit.com/r/MachineLearning/comments/8lapfo/classificaio_simple_to_use_user_interface_for_the/,roushang,1527001816,[removed],0,1
1132,2018-5-23,2018,5,23,0,8lay9l,Hierarchically Structured Reinforcement Learning for Topically Coherent Visual Story Generation,https://www.reddit.com/r/MachineLearning/comments/8lay9l/hierarchically_structured_reinforcement_learning/,arind_das,1527003753,,0,1
1133,2018-5-23,2018,5,23,0,8lazhc,[N][LIVESTREAM] AiDecentralized + Topics &amp; Schedule - SingularityNET,https://www.reddit.com/r/MachineLearning/comments/8lazhc/nlivestream_aidecentralized_topics_schedule/,ibbybenali,1527004024,,0,2
1134,2018-5-23,2018,5,23,0,8lb2kr,"Understanding ""Attend, Infer, Repeat: Fast Scene Understanding with Generative Models"" paper.",https://www.reddit.com/r/MachineLearning/comments/8lb2kr/understanding_attend_infer_repeat_fast_scene/,RAURMUIL,1527004666,[removed],0,1
1135,2018-5-23,2018,5,23,1,8lb5lr,"[D] Understanding ""Attend, Infer, Repeat: Fast Scene Understanding with Generative Models"" paper",https://www.reddit.com/r/MachineLearning/comments/8lb5lr/d_understanding_attend_infer_repeat_fast_scene/,RAURMUIL,1527005272,"I am trying to implement the Attend, Infer, Repeat [paper](https://arxiv.org/abs/1603.08575). I have some troubles in understanding the Score Function estimation (REINFORCE) used in the paper for estimating the gradients for the discrete probability distribution. This [blog post](http://akosiorek.github.io/ml/2017/09/03/implementing-air.html), along with the implementation is of much help but I couldn't follow the part where the ""neural baselines"" are described. Could someone please help me in understanding what is ""neural baselines"" and how is it used in the context of AIR?",5,9
1136,2018-5-23,2018,5,23,1,8lb6u9,A small dataviz of the ICML accepted paper,https://www.reddit.com/r/MachineLearning/comments/8lb6u9/a_small_dataviz_of_the_icml_accepted_paper/,ChocoMoi,1527005527,[removed],0,1
1137,2018-5-23,2018,5,23,1,8lbejw,Algorithmic [legal] Entities,https://www.reddit.com/r/MachineLearning/comments/8lbejw/algorithmic_legal_entities/,phobrain,1527007179,,0,1
1138,2018-5-23,2018,5,23,2,8lbnts,Algorithmic [legal] Entities,https://www.reddit.com/r/MachineLearning/comments/8lbnts/algorithmic_legal_entities/,phobrain,1527009046,,1,1
1139,2018-5-23,2018,5,23,3,8lc3vd,[R] Learning to Optimize Tensor Programs,https://www.reddit.com/r/MachineLearning/comments/8lc3vd/r_learning_to_optimize_tensor_programs/,antinucleon,1527012140,,12,18
1140,2018-5-23,2018,5,23,3,8lc5me,[P] Training a Text-Generating Neural Network for Free,https://www.reddit.com/r/MachineLearning/comments/8lc5me/p_training_a_textgenerating_neural_network_for/,minimaxir,1527012483,,1,1
1141,2018-5-23,2018,5,23,3,8lcfyw,Simbrain Blues,https://www.reddit.com/r/MachineLearning/comments/8lcfyw/simbrain_blues/,naturalabundance,1527014547,[removed],0,1
1142,2018-5-23,2018,5,23,4,8lcmam,Could someone explain to me how back-prop is done for the generator in a GAN ?,https://www.reddit.com/r/MachineLearning/comments/8lcmam/could_someone_explain_to_me_how_backprop_is_done/,BlackGease,1527015813,[removed],0,1
1143,2018-5-23,2018,5,23,5,8ld8ff,3D Printed Robot Cat learns to walk with Genetic Algorithm,https://www.reddit.com/r/MachineLearning/comments/8ld8ff/3d_printed_robot_cat_learns_to_walk_with_genetic/,Hartvik,1527020309,,0,1
1144,2018-5-23,2018,5,23,5,8ld8jm,[R] Removing activation from discriminator output layer in GAN to allow use of L1 loss.,https://www.reddit.com/r/MachineLearning/comments/8ld8jm/r_removing_activation_from_discriminator_output/,underPanther,1527020335,,5,9
1145,2018-5-23,2018,5,23,6,8ldn7i,3D Printed Robot Cat learns to walk with Genetic Algorithm,https://www.reddit.com/r/MachineLearning/comments/8ldn7i/3d_printed_robot_cat_learns_to_walk_with_genetic/,Hartvik,1527023374,,0,1
1146,2018-5-23,2018,5,23,6,8ldnj4,"[D] Given the lowest float[][] layer of a RBM, and lacking the data it was trained on, what function best estimates how well it was trained?",https://www.reddit.com/r/MachineLearning/comments/8ldnj4/d_given_the_lowest_float_layer_of_a_rbm_and/,BenRayfield,1527023449,"Example: https://corpocrat.com/wp-content/uploads/2014/10/mnistrbm.png are featureVectors trained on visual data.

A common visual data is mnist ocr (nonconvolutionally), but it could be any kind of data.

My attempt at answering this question is, for each node in second node layer, viewing edges downward to first node layer, there exists some 2 subsets (to first node layer) where 1 subset has very low stdDev (feature ignores those visibleNodes) and the other subset has very high stdDev (feature is strongly influenced by those visibleNodes positively or negatively). It may also be related to the dotProduct between such featureVectors, especially that they tend not to duplicate or be opposite of, large parts of eachothers non-middle values. Each lowest float[][] featureVector should describe a possibility some small part of the forExample 28x28 2d grid of visibleNodes in an mnist ocr image. Having written my own RBM code, I find that without careful tuning, the featureVectors tend to become very similar to eachother.",3,0
1147,2018-5-23,2018,5,23,6,8ldrdf,Forge.AI - Takeaways from TensorFlow Dev Summit 2018,https://www.reddit.com/r/MachineLearning/comments/8ldrdf/forgeai_takeaways_from_tensorflow_dev_summit_2018/,jenniferlum,1527024280,,0,1
1148,2018-5-23,2018,5,23,6,8lduw7,[P] 3D Printed Robot Cat learns to walk with Genetic Algorithm,https://www.reddit.com/r/MachineLearning/comments/8lduw7/p_3d_printed_robot_cat_learns_to_walk_with/,Hartvik,1527025071,,51,368
1149,2018-5-23,2018,5,23,8,8lehfl,"[D] The constant barrage of awesome-looking AI results can induce panic in researchers. How can you keep up, let alone compete?",https://www.reddit.com/r/MachineLearning/comments/8lehfl/d_the_constant_barrage_of_awesomelooking_ai/,baylearn,1527030169,,1,0
1150,2018-5-23,2018,5,23,8,8lejf8,[N] AI Community Reacts to Reddit Post: Are Grad Students Reviewing NIPS Papers?,https://www.reddit.com/r/MachineLearning/comments/8lejf8/n_ai_community_reacts_to_reddit_post_are_grad/,trcytony,1527030640,,0,1
1151,2018-5-23,2018,5,23,8,8lekfe,[N] MXNet Now Supports Keras 2,https://www.reddit.com/r/MachineLearning/comments/8lekfe/n_mxnet_now_supports_keras_2/,gwen0927,1527030902,,0,1
1152,2018-5-23,2018,5,23,8,8lemt9,Explainable Machine Learning Challenge,https://www.reddit.com/r/MachineLearning/comments/8lemt9/explainable_machine_learning_challenge/,carmichael561,1527031482,,0,1
1153,2018-5-23,2018,5,23,9,8lewna,[D] Article I wrote on using AI for experiential advertising - very high level thoughts,https://www.reddit.com/r/MachineLearning/comments/8lewna/d_article_i_wrote_on_using_ai_for_experiential/,laserpilot,1527033981,,0,0
1154,2018-5-23,2018,5,23,10,8lfe89,[D] Is Deep Learning here to stay? Or will it be irrelevant soon?,https://www.reddit.com/r/MachineLearning/comments/8lfe89/d_is_deep_learning_here_to_stay_or_will_it_be/,ME_PhD,1527038379,"Just wondering if there are new ML algorithms on the horizon that could dethrone DL in the next 5-10 years.

ML ideas seem to come and go fairly quickly, so I'm wondering if DL will just be another victim of this fast cycle. ",23,17
1155,2018-5-23,2018,5,23,10,8lfk0h,[R] Self-Attention Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/8lfk0h/r_selfattention_generative_adversarial_networks/,baylearn,1527039880,,17,29
1156,2018-5-23,2018,5,23,10,8lfndo,The Roles of Supervised Machine Learning in Systems Neuroscience,https://www.reddit.com/r/MachineLearning/comments/8lfndo/the_roles_of_supervised_machine_learning_in/,Coach_Aretas,1527040775,,1,1
1157,2018-5-23,2018,5,23,12,8lg58f,Policy Gradients in a Nutshell,https://www.reddit.com/r/MachineLearning/comments/8lg58f/policy_gradients_in_a_nutshell/,activatedgeek,1527045264,,0,1
1158,2018-5-23,2018,5,23,13,8lgiik,What to do with algorithmic breakthrough?,https://www.reddit.com/r/MachineLearning/comments/8lgiik/what_to_do_with_algorithmic_breakthrough/,4rtemi5,1527048950,[removed],0,1
1159,2018-5-23,2018,5,23,14,8lgziv,"AI and Compute; ""AI training runs has been increasing exponentially with a 3.5 month-doubling time""",https://www.reddit.com/r/MachineLearning/comments/8lgziv/ai_and_compute_ai_training_runs_has_been/,TebbaVonMathenstein,1527054307,,0,1
1160,2018-5-23,2018,5,23,15,8lh6qc,[D] Approximating smooth functions with NN using only ReLU? Makes no sense,https://www.reddit.com/r/MachineLearning/comments/8lh6qc/d_approximating_smooth_functions_with_nn_using/,ME_PhD,1527056797,"Intuitively I don't see how you can approximate any function with a neural network of finite depth/width using only ReLU since it's just a piece-wise linear function.

Am I missing something? Seems like all ReLU does is make a piecewise linear decision boundary rather than a smooth curved one.

The ReLU has bothered me for a while, can someone give me any insight as to why it works so well?",7,5
1161,2018-5-23,2018,5,23,15,8lh7k3,Java basic syntax,https://www.reddit.com/r/MachineLearning/comments/8lh7k3/java_basic_syntax/,Karan-Chaudhari,1527057095,,0,1
1162,2018-5-23,2018,5,23,15,8lharo,What You Would Need To Become a Machine Learning Engineer?,https://www.reddit.com/r/MachineLearning/comments/8lharo/what_you_would_need_to_become_a_machine_learning/,imarticus_nirmal,1527058268,,0,1
1163,2018-5-23,2018,5,23,16,8lhdnz,AskMachineLearning: How are IOUs for ground truth boxes in YOLO calculated?,https://www.reddit.com/r/MachineLearning/comments/8lhdnz/askmachinelearning_how_are_ious_for_ground_truth/,nivter,1527059254,[removed],0,1
1164,2018-5-23,2018,5,23,16,8lhfdg,[R] Implicit Reparameterization Gradients,https://www.reddit.com/r/MachineLearning/comments/8lhfdg/r_implicit_reparameterization_gradients/,hardmaru,1527059828,,7,30
1165,2018-5-23,2018,5,23,16,8lhfkw,7 Key Skills Required For Machine Learning Jobs,https://www.reddit.com/r/MachineLearning/comments/8lhfkw/7_key_skills_required_for_machine_learning_jobs/,imarticus_nirmal,1527059878,,0,1
1166,2018-5-23,2018,5,23,16,8lhi1m,Please help me with solving this problem.,https://www.reddit.com/r/MachineLearning/comments/8lhi1m/please_help_me_with_solving_this_problem/,DizzyDrawer,1527060680,[removed],0,1
1167,2018-5-23,2018,5,23,17,8lhrjf,[R] A Universal Music Translation Network,https://www.reddit.com/r/MachineLearning/comments/8lhrjf/r_a_universal_music_translation_network/,pablo_gomez,1527064341,,9,42
1168,2018-5-23,2018,5,23,17,8lhs01,neoHebbian three factor learning: interface between reinforcement learning and comp. neuroscience,https://www.reddit.com/r/MachineLearning/comments/8lhs01/neohebbian_three_factor_learning_interface/,Modatu,1527064536,,0,1
1169,2018-5-23,2018,5,23,17,8lhv6o,Artificial Intelligence make better diagnosis,https://www.reddit.com/r/MachineLearning/comments/8lhv6o/artificial_intelligence_make_better_diagnosis/,Keradoc,1527065800,[removed],0,1
1170,2018-5-23,2018,5,23,19,8li7cx,[P] [x-post from r/computervision] Online camera calibration pattern generator,https://www.reddit.com/r/MachineLearning/comments/8li7cx/p_xpost_from_rcomputervision_online_camera/,calib-io,1527070272,,1,0
1171,2018-5-23,2018,5,23,19,8libdv,Creating TensorFlow device,https://www.reddit.com/r/MachineLearning/comments/8libdv/creating_tensorflow_device/,Dropcunts,1527071704,[removed],0,1
1172,2018-5-23,2018,5,23,19,8lid70,[R] Sparse and Constrained Attention for Neural Machine Translation (ACL 2018),https://www.reddit.com/r/MachineLearning/comments/8lid70/r_sparse_and_constrained_attention_for_neural/,ofirpress,1527072330,,0,1
1173,2018-5-23,2018,5,23,20,8lik92,Single Layer Tea Powder Packaging Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/8lik92/single_layer_tea_powder_packaging_machine_for_sale/,lgsherry,1527074564,,1,1
1174,2018-5-23,2018,5,23,21,8litc6,Stackoverflow implicit feedback recommendation system,https://www.reddit.com/r/MachineLearning/comments/8litc6/stackoverflow_implicit_feedback_recommendation/,iancu_v,1527077182,[removed],0,1
1175,2018-5-23,2018,5,23,21,8liv07,remanufacturing for earth!,https://www.reddit.com/r/MachineLearning/comments/8liv07/remanufacturing_for_earth/,AYB_INDUSTRIES,1527077633,,0,1
1176,2018-5-23,2018,5,23,21,8lj345,"Guys I need your help!!I cant get through this error, I would be obliged if you tell me whats wrong",https://www.reddit.com/r/MachineLearning/comments/8lj345/guys_i_need_your_helpi_cant_get_through_this/,revant_t,1527079771,,0,1
1177,2018-5-23,2018,5,23,22,8lj6p8,Know Why You Should Use Spark For Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8lj6p8/know_why_you_should_use_spark_for_machine_learning/,fullstackanalytics1,1527080648,,0,1
1178,2018-5-23,2018,5,23,22,8ljbvj,[R] Adding One Neuron Can Eliminate All Bad Local Minima,https://www.reddit.com/r/MachineLearning/comments/8ljbvj/r_adding_one_neuron_can_eliminate_all_bad_local/,blowjobtransistor,1527081907,,25,120
1179,2018-5-23,2018,5,23,22,8ljhsj,Global Retail Scales Industry 2013 Analysis and Forecast to 2023 Market Research Report,https://www.reddit.com/r/MachineLearning/comments/8ljhsj/global_retail_scales_industry_2013_analysis_and/,maheshbhosale1634,1527083330,,0,1
1180,2018-5-23,2018,5,23,22,8ljkfg,[D] Paper notes: Inductive Representation Learning on Large Graphs (GraphSAGE),https://www.reddit.com/r/MachineLearning/comments/8ljkfg/d_paper_notes_inductive_representation_learning/,dtsbourg,1527083919,,4,8
1181,2018-5-23,2018,5,23,23,8ljs58,[N] Neurochips from the 90s,https://www.reddit.com/r/MachineLearning/comments/8ljs58/n_neurochips_from_the_90s/,gfursin,1527085598,,24,21
1182,2018-5-23,2018,5,23,23,8ljuvu,"Searching for a 3D Dataset, segmented by 2 or more Experts",https://www.reddit.com/r/MachineLearning/comments/8ljuvu/searching_for_a_3d_dataset_segmented_by_2_or_more/,ThrawNeX,1527086226,[removed],0,1
1183,2018-5-23,2018,5,23,23,8ljxkp,RL problem,https://www.reddit.com/r/MachineLearning/comments/8ljxkp/rl_problem/,Dropcunts,1527086824,[removed],0,1
1184,2018-5-23,2018,5,23,23,8ljy3t,Reverse clustering,https://www.reddit.com/r/MachineLearning/comments/8ljy3t/reverse_clustering/,Slordo,1527086944,[removed],0,1
1185,2018-5-24,2018,5,24,0,8lk2s8,Reverse clustering,https://www.reddit.com/r/MachineLearning/comments/8lk2s8/reverse_clustering/,Slordo,1527087927,[removed],1,1
1186,2018-5-24,2018,5,24,0,8lk7s1,A simple webapp using face detection directly in the browser,https://www.reddit.com/r/MachineLearning/comments/8lk7s1/a_simple_webapp_using_face_detection_directly_in/,StartupJeeliz,1527089001,[removed],0,1
1187,2018-5-24,2018,5,24,0,8lkf9i,[D] NLP word representations and the Wittgenstein philosophy of language,https://www.reddit.com/r/MachineLearning/comments/8lkf9i/d_nlp_word_representations_and_the_wittgenstein/,perone,1527090609,,11,15
1188,2018-5-24,2018,5,24,0,8lkgso,"Simple Questions Thread May 23, 2018",https://www.reddit.com/r/MachineLearning/comments/8lkgso/simple_questions_thread_may_23_2018/,AutoModerator,1527090942,[removed],0,1
1189,2018-5-24,2018,5,24,1,8lkiyh,[D] Can't get anywhere close to the IS/FID reported as the state-of-the-art in CIFAR-10 for any GAN using PyTorch.,https://www.reddit.com/r/MachineLearning/comments/8lkiyh/d_cant_get_anywhere_close_to_the_isfid_reported/,GAN_,1527091383,"So I created a new GAN loss which is super neat mathematically/intuitively, very stable and doesn't need gradient penalty. I want to compare it to other approaches but whatever GAN loss, hyperparameter or model architecture I use, I can never get even close to the IS and FID values reported in papers for CIFAR-10, which should be around 30 for most GANs and 20 for the crme de la crme (spectral GAN and progressive GANs) as seen here: https://github.com/pfnet-research/chainer-gan-lib and in https://openreview.net/pdf?id=B1QRgziT- (Table 2). I almost never get IS &gt; 4 or FID &lt; 50.

I really wonder if it has to do with me using PyTorch when all papers seems to use TensorFlow or Chainer. I have to resort to using these implementations: https://github.com/sbarratt/inception-score-pytorch and https://github.com/mseitzer/pytorch-fid. I know the inception one is a bit different from TensorFlow but even the FID one cannot give me numbers close to what I am supposed to get. I am using the same seed every-time (seed = 1) for consistency and using mostly standard hyperparameters for Adam (.5, .999). I run models for 100k iterations, some models seems to get sightly better over time but not much, while others (which should be amazingly good like Spectral Hinge-GAN) actually peak at 25k iterations with an FID of 60 and get worse over time.

On the other hand, the large scale study on GANs (https://arxiv.org/pdf/1711.10337.pdf) also reported that they did massive hyperparameters search and found that when averaging results over 50 seeds, the best GANs with best hyperparameters led to an average FID of 55 or more at best.

Is anyone having similar issues? Do I have to pick-and-choose a seed until I get a low enough FID, is this really what people are doing? Am I using too few iterations? Why is it that no-one seems to be using PyTorch in publications?

My last resort would be to report the results I get for all approaches on equal ground with the same seed(s) even though they do not reach state-of-the-art level, but I fear that people will wonder why are my numbers so bad compared to what is generally reported. In addition, I would like to show off how great this GAN loss by reaching the state-of-the-art which should be possible especially if combined with let say spectral normalization and ResNets.",14,11
1190,2018-5-24,2018,5,24,1,8lkkup,"Will the Future of the Stock Market Be ""Survival of the Fittest""?",https://www.reddit.com/r/MachineLearning/comments/8lkkup/will_the_future_of_the_stock_market_be_survival/,andrewturnerrr,1527091788,,0,1
1191,2018-5-24,2018,5,24,1,8lknqs,Brains Cling to Old Habits When Learning New Tricks,https://www.reddit.com/r/MachineLearning/comments/8lknqs/brains_cling_to_old_habits_when_learning_new/,InsaneRaspberry,1527092398,,0,1
1192,2018-5-24,2018,5,24,1,8lkua5,"[D] Ethics: Pattern-of-life analysis from bulk DNR metadata, in support of constellation of hunter/killer drones. A threat or a possibility?",https://www.reddit.com/r/MachineLearning/comments/8lkua5/d_ethics_patternoflife_analysis_from_bulk_dnr/,lintujen_sukulainen,1527093770,,8,0
1193,2018-5-24,2018,5,24,2,8ll0iv,How will the GDPR impact machine learning?,https://www.reddit.com/r/MachineLearning/comments/8ll0iv/how_will_the_gdpr_impact_machine_learning/,gagejustins,1527095027,,0,1
1194,2018-5-24,2018,5,24,2,8llcv9,exchange,https://www.reddit.com/r/MachineLearning/comments/8llcv9/exchange/,ilyas10sis,1527097564,[removed],0,1
1195,2018-5-24,2018,5,24,2,8lleee,[D] Show HN: Cross Entropy  Machine Learning Basics,https://www.reddit.com/r/MachineLearning/comments/8lleee/d_show_hn_cross_entropy_machine_learning_basics/,pandeykartikey,1527097884,,0,1
1196,2018-5-24,2018,5,24,2,8llfqe,How can i start learning about machine learning.Iam a beginner and has basic programming skill.,https://www.reddit.com/r/MachineLearning/comments/8llfqe/how_can_i_start_learning_about_machine/,Sibi_Nehru,1527098164,[removed],0,1
1197,2018-5-24,2018,5,24,3,8llht3,[N] SingularityNET and AI Decentralized Create New Industry Group: the Decentralized AI Alliance,https://www.reddit.com/r/MachineLearning/comments/8llht3/n_singularitynet_and_ai_decentralized_create_new/,ibbybenali,1527098598,,0,0
1198,2018-5-24,2018,5,24,3,8llkhd,[D] Cross Entropy  Machine Learning Basics,https://www.reddit.com/r/MachineLearning/comments/8llkhd/d_cross_entropy_machine_learning_basics/,pandeykartikey,1527099137,,3,9
1199,2018-5-24,2018,5,24,3,8lll04,Online Combinatorial Optimization using Hedge in Linear Time,https://www.reddit.com/r/MachineLearning/comments/8lll04/online_combinatorial_optimization_using_hedge_in/,sudeepraja,1527099237,,0,1
1200,2018-5-24,2018,5,24,3,8llwer,Pixie: Pinterest's system for recommending 3b items using a graph of 17b edges to 200m users in real-time,https://www.reddit.com/r/MachineLearning/comments/8llwer/pixie_pinterests_system_for_recommending_3b_items/,gwern,1527101650,,1,1
1201,2018-5-24,2018,5,24,4,8lm48a,"[D] Are bayesian network and neural network approximations of the same statistics? If not, which of them is wrong? If so, how can a RBM neuralnet emulate a large bayes node (such as 16 visibleNodes and 2^16 hiddenNodes)?",https://www.reddit.com/r/MachineLearning/comments/8lm48a/d_are_bayesian_network_and_neural_network/,BenRayfield,1527103258,"    neuralnet: chanceB = 1/(1+e^-sum&lt;i&gt;(weightBC*chanceC))

    bayesnode of size X: chance&lt;of child 0 to X-1&gt; = sum&lt;half the weights selected by mask [childIndex&lt;&lt;1]&gt;
",3,0
1202,2018-5-24,2018,5,24,4,8lm5f0,[R] AI Taught to Synthesize Materials,https://www.reddit.com/r/MachineLearning/comments/8lm5f0/r_ai_taught_to_synthesize_materials/,DIY_surgery,1527103495,,41,339
1203,2018-5-24,2018,5,24,5,8lmiwf,[P] Visual Search engine with MXNet and HNSW - x-post r/mxnet,https://www.reddit.com/r/MachineLearning/comments/8lmiwf/p_visual_search_engine_with_mxnet_and_hnsw_xpost/,thomasdlt,1527106392,,1,25
1204,2018-5-24,2018,5,24,6,8ln95r,How will the GDPR impact machine learning?,https://www.reddit.com/r/MachineLearning/comments/8ln95r/how_will_the_gdpr_impact_machine_learning/,FollowSteph,1527111961,,0,1
1205,2018-5-24,2018,5,24,7,8lnhhi,[D] Visualizing simplified whitening,https://www.reddit.com/r/MachineLearning/comments/8lnhhi/d_visualizing_simplified_whitening/,callmebyyoursurname,1527113878,I just tried out the Simplified Whitening as mentioned in this [post](http://yeephycho.github.io/2016/08/03/Normalizations-in-neural-networks/). But the normalized image I get seems to have lost a LOT of information. It's barely visible at all. Here's the [processed image](https://i.imgur.com/tDy8tEg.png) and here's the [original image](https://i.imgur.com/9zH0Bnm.png).  Here's [the code](https://github.com/dibyadas/Visualize-Normalizations/blob/master/SimplifiedWhitening.ipynb) that I wrote for this. Any help in understanding this would be appreciated! ,2,0
1206,2018-5-24,2018,5,24,7,8lniky,What [ML Algorithm] to choose for many Timestamp features that spans multiple days?,https://www.reddit.com/r/MachineLearning/comments/8lniky/what_ml_algorithm_to_choose_for_many_timestamp/,mani003,1527114119,,0,1
1207,2018-5-24,2018,5,24,10,8lovq5,Is it possible to develop GANs in Caffe or Caffe2?,https://www.reddit.com/r/MachineLearning/comments/8lovq5/is_it_possible_to_develop_gans_in_caffe_or_caffe2/,soulslicer0,1527126278,[removed],0,1
1208,2018-5-24,2018,5,24,10,8lowac,On the Relation of Impulse Propagation to Synaptic Strength (A biological classifier),https://www.reddit.com/r/MachineLearning/comments/8lowac/on_the_relation_of_impulse_propagation_to/,lansiz,1527126410,,0,1
1209,2018-5-24,2018,5,24,11,8lp0s3,Comprehensive guide to Wasserstein GANs,https://www.reddit.com/r/MachineLearning/comments/8lp0s3/comprehensive_guide_to_wasserstein_gans/,vector_machines,1527127502,,0,1
1210,2018-5-24,2018,5,24,11,8lp4wp,Complete bio fertilizer plant/production line,https://www.reddit.com/r/MachineLearning/comments/8lp4wp/complete_bio_fertilizer_plantproduction_line/,amylee516,1527128472,,0,1
1211,2018-5-24,2018,5,24,11,8lpctn,cabinet bending machine,https://www.reddit.com/r/MachineLearning/comments/8lpctn/cabinet_bending_machine/,davismachinery,1527130394,,0,1
1212,2018-5-24,2018,5,24,12,8lpfe0,hydraulic guillotine cutting machine,https://www.reddit.com/r/MachineLearning/comments/8lpfe0/hydraulic_guillotine_cutting_machine/,davismachinery,1527131045,,0,1
1213,2018-5-24,2018,5,24,12,8lpfwb,Predicting LTV w/ gradient boosted trees in RapidMiner,https://www.reddit.com/r/MachineLearning/comments/8lpfwb/predicting_ltv_w_gradient_boosted_trees_in/,jeffdwyer,1527131168,,0,1
1214,2018-5-24,2018,5,24,12,8lpi6x,aluminum frame cutting machine,https://www.reddit.com/r/MachineLearning/comments/8lpi6x/aluminum_frame_cutting_machine/,davismachinery,1527131746,,0,1
1215,2018-5-24,2018,5,24,12,8lpk4e,"My hn ming ti lin tc nm ngang FR- 900 hot ng vi tng cng sut l 500W, c cu to 2 qu p nhit lin tc to ng hn ming ti rt u v chn chn",https://www.reddit.com/r/MachineLearning/comments/8lpk4e/my_hn_ming_ti_lin_tc_nm_ngang_fr_900_hot/,HangNguyen1111,1527132248,,0,1
1216,2018-5-24,2018,5,24,12,8lpkwe,pressed aluminium sheet machine,https://www.reddit.com/r/MachineLearning/comments/8lpkwe/pressed_aluminium_sheet_machine/,davismachinery,1527132458,,0,1
1217,2018-5-24,2018,5,24,12,8lppf2,cabinet bending machine,https://www.reddit.com/r/MachineLearning/comments/8lppf2/cabinet_bending_machine/,davismachinery,1527133785,,0,1
1218,2018-5-24,2018,5,24,12,8lpq3i,"My hn ming ti PFS-200 hot ng vi cng sut 300W, c  di mp hn 200mm, chiu rng mp hn l 2mm, dn ming ti nhanh trong thi gian t 0.2 n 1.5s",https://www.reddit.com/r/MachineLearning/comments/8lpq3i/my_hn_ming_ti_pfs200_hot_ng_vi_cng_sut/,HangNguyen1111,1527133998,,0,1
1219,2018-5-24,2018,5,24,13,8lpux1,n dit Cn Trng DS-D202I V ngoi: Inox 304 in p: AC 220V - 50Hz Bng n: 18W x 2 (Philips) Phm vi: 100 m2 Kch thc: 68 x 17 x 39 (cm) Trng lng: 8.5 kg,https://www.reddit.com/r/MachineLearning/comments/8lpux1/n_dit_cn_trng_dsd202i_v_ngoi_inox_304_in/,HangNguyen1111,1527135393,,0,1
1220,2018-5-24,2018,5,24,13,8lpxif,n dit cn trng Navalight NP-2X20W-SS Cu to: khung INOX 304 Cng sut bng: 40W ( T8 x2 x 20W) Cng sut tiu th: 45 W Phm vi hot ng:  150 m2 in p: 220V  50Hz Tui th bng: 8.000  10.000 (gi ) Kch thc (mm) : 660 x 110 x 320 Trong lng: 6 kg,https://www.reddit.com/r/MachineLearning/comments/8lpxif/n_dit_cn_trng_navalight_np2x20wss_cu_to/,HangNguyen1111,1527136154,,0,1
1221,2018-5-24,2018,5,24,13,8lpxiw,I have completed the machine learning course by Andrew Ng. What should I do next ?,https://www.reddit.com/r/MachineLearning/comments/8lpxiw/i_have_completed_the_machine_learning_course_by/,aniketmaurya,1527136159,[removed],0,1
1222,2018-5-24,2018,5,24,13,8lpzsp,[P] Keras 3D U-Net CNN for medical image segmentation,https://www.reddit.com/r/MachineLearning/comments/8lpzsp/p_keras_3d_unet_cnn_for_medical_image_segmentation/,SupraluminalShift,1527136869,,1,21
1223,2018-5-24,2018,5,24,14,8lq8lb,cabinet bending machine,https://www.reddit.com/r/MachineLearning/comments/8lq8lb/cabinet_bending_machine/,davismachinery,1527139617,,0,1
1224,2018-5-24,2018,5,24,15,8lqecf,pressed aluminium sheet machine,https://www.reddit.com/r/MachineLearning/comments/8lqecf/pressed_aluminium_sheet_machine/,davismachinery,1527141612,,0,1
1225,2018-5-24,2018,5,24,15,8lqjix,[News] Summer School on Optimization for Image Analysis 14-18th of August in southern Denmark,https://www.reddit.com/r/MachineLearning/comments/8lqjix/news_summer_school_on_optimization_for_image/,Gumeo,1527143462,"Hi all!

The image groups in the Technical University of Denmark and University of Copenhagen are jointly organizing their yearly [summer school](http://optimization-image-analysis.compute.dtu.dk/). This is a course offering 3 ECTS units for PhD students, given that they bring and present a poster.

This is an opportunity for networking, future collaborations and of course learning about optimization in relation to image analysis.

Hope to see some of you there!",0,10
1226,2018-5-24,2018,5,24,16,8lqoef,Is there any easier way to understand the Math in ML?,https://www.reddit.com/r/MachineLearning/comments/8lqoef/is_there_any_easier_way_to_understand_the_math_in/,ThinScreen,1527145247,[removed],0,1
1227,2018-5-24,2018,5,24,16,8lqprx,First Experiences With Probabilistic Programming,https://www.reddit.com/r/MachineLearning/comments/8lqprx/first_experiences_with_probabilistic_programming/,badeand,1527145696,,0,1
1228,2018-5-24,2018,5,24,16,8lqq8t,"Introduction To Machine Learning [Free, 2 hour course]",https://www.reddit.com/r/MachineLearning/comments/8lqq8t/introduction_to_machine_learning_free_2_hour/,AtrophicNectar,1527145865,,0,1
1229,2018-5-24,2018,5,24,16,8lqszi,simple press brake machine,https://www.reddit.com/r/MachineLearning/comments/8lqszi/simple_press_brake_machine/,davismachinery,1527146814,,0,1
1230,2018-5-24,2018,5,24,16,8lqv2c,three mechanical metal sheet roll machine,https://www.reddit.com/r/MachineLearning/comments/8lqv2c/three_mechanical_metal_sheet_roll_machine/,davismachinery,1527147609,,0,1
1231,2018-5-24,2018,5,24,16,8lqwkg,three mechanical roll plate machine,https://www.reddit.com/r/MachineLearning/comments/8lqwkg/three_mechanical_roll_plate_machine/,davismachinery,1527148228,,0,1
1232,2018-5-24,2018,5,24,17,8lqy46,Stock markets,https://www.reddit.com/r/MachineLearning/comments/8lqy46/stock_markets/,rickross234,1527148848,[removed],0,1
1233,2018-5-24,2018,5,24,17,8lqze4,"Despite of L1 and L2, are there any novel constrains to guide generative models?",https://www.reddit.com/r/MachineLearning/comments/8lqze4/despite_of_l1_and_l2_are_there_any_novel/,NealZhang,1527149339,[removed],0,1
1234,2018-5-24,2018,5,24,17,8lr0ny,3 roller hydraulic rolling machine,https://www.reddit.com/r/MachineLearning/comments/8lr0ny/3_roller_hydraulic_rolling_machine/,davismachinery,1527149882,,0,1
1235,2018-5-24,2018,5,24,17,8lr2bg,Does it matter where you get a computer science degree? Do you even need a degree? (Down under in Australia),https://www.reddit.com/r/MachineLearning/comments/8lr2bg/does_it_matter_where_you_get_a_computer_science/,Thankgodlifeistfair,1527150554,[removed],0,1
1236,2018-5-24,2018,5,24,17,8lr2lq,[D] What makes variational dropout so popular for neural networks?,https://www.reddit.com/r/MachineLearning/comments/8lr2lq/d_what_makes_variational_dropout_so_popular_for/,RobRomijnders,1527150675,"Getting uncertainty is an important topic for neural networks. I, and many others, think that variational inference is the way forward. It seems that the most popular approach is to use a Bernoulli distribution for approximation. This follows mainly from the work of [Yarin Gal, who shows that the Bernoulli approximation amounts to doing dropout](http://mlg.eng.cam.ac.uk/yarin/blog_2248.html).


Another simple approximation is the Gaussian approximation. This goes back to an [old paper by Hinton and van Camp from 1993. ](https://dl.acm.org/citation.cfm?id=168304.168306)

My question is what makes the Bernoulli approximation suddenly so popular? 

The Bernoulli approximation captures none of the local properties of the posterior. It does not change anything when the posterior has a wide or narrow mode. See [this](https://github.com/RobRomijnders/weight_uncertainty/blob/master/docs/presentation/im/gaussian_or_bernoulli.png) image for an example.",8,22
1237,2018-5-24,2018,5,24,17,8lr2mk,[D] Why does gated convolution work for language modeling but self-attention model doesn't?,https://www.reddit.com/r/MachineLearning/comments/8lr2mk/d_why_does_gated_convolution_work_for_language/,HigherTopoi,1527150684,"I've applied modifications of Transformer to language modeling datasets such as PTB, WikiText-2, char-PTB and enwik8 in a way similar to that of gated convolution. For PTB it obtained a strong training error very quickly, but the test perplexity is high, which is understandable given that Transformer needs a large batch size. For the other datasets, the perplexity is too high. This result isn't surprising, since Transformer doesn't have recurrent weights. But gated convolution achieved a strong result in language modeling without recurrent weights. What is something GC and RNN have but Transformer doesn't have? I'm aware of recurrent-Transformer, but gated convolution result seems to imply that Transformer+convolution also works. 

Unexpectedly, I obtained a competitive perplexity with language modeling whenever I can fit whole samples into a single minibatch instead of cutting them to segments like TBPTT of RNN. ",5,9
1238,2018-5-24,2018,5,24,18,8lrcje,"What are some great non-academic resources (blog posts, tutorials, explorables etc.) for high level concepts in ML?",https://www.reddit.com/r/MachineLearning/comments/8lrcje/what_are_some_great_nonacademic_resources_blog/,banksyb00mb00m,1527154644,[removed],0,1
1239,2018-5-24,2018,5,24,18,8lre5r,Implementing Machine Learning Algorithm from Scratch,https://www.reddit.com/r/MachineLearning/comments/8lre5r/implementing_machine_learning_algorithm_from/,Hot_Ices,1527155285,[removed],0,1
1240,2018-5-24,2018,5,24,19,8lrmkg,[P] DeepTide - Massive Collaborative ML,https://www.reddit.com/r/MachineLearning/comments/8lrmkg/p_deeptide_massive_collaborative_ml/,rstoj,1527158265,"http://deeptide.ai 

Hey guys, looking for feedback on our project. We were wondering what would happen if you could grow ML teams to the same scale as the Linux kernel contributors (&gt;1000s). Would the community be able to beat the latest state-of-the-art? We see this different from Kaggle because our focus is on collaboration and not competition, and different from GitHub because it's specifically built with ML in mind (so think data, features, code, models, evaluation all in one place). Please let us know what you think!
",21,50
1241,2018-5-24,2018,5,24,20,8lrr70,A New Machine Learning Specialization Launched By Coursera &amp; Google - IQVIS Inc.,https://www.reddit.com/r/MachineLearning/comments/8lrr70/a_new_machine_learning_specialization_launched_by/,rayparker1,1527159809,,0,1
1242,2018-5-24,2018,5,24,20,8lruc8,[R] [1805.08913] Amortized Inference Regularization,https://www.reddit.com/r/MachineLearning/comments/8lruc8/r_180508913_amortized_inference_regularization/,evc123,1527160797,,0,12
1243,2018-5-24,2018,5,24,20,8lrysb,How the Quality of Your Machine Learning Data Affects Your AI Solution,https://www.reddit.com/r/MachineLearning/comments/8lrysb/how_the_quality_of_your_machine_learning_data/,Victor_Stakh,1527162115,,0,1
1244,2018-5-24,2018,5,24,20,8lrz9a,,https://www.reddit.com/r/MachineLearning/comments/8lrz9a//,Woodworking94,1527162253,,0,1
1245,2018-5-24,2018,5,24,21,8lsa3g,[R] Enterprise Deployment Tips for Azure Data Science Virtual Machine (DSVM),https://www.reddit.com/r/MachineLearning/comments/8lsa3g/r_enterprise_deployment_tips_for_azure_data/,dearpetra,1527165236,,0,1
1246,2018-5-24,2018,5,24,21,8lsbd8,[R] How to train Machine Learning models in the cloud using Cloud ML Engine,https://www.reddit.com/r/MachineLearning/comments/8lsbd8/r_how_to_train_machine_learning_models_in_the/,magneticono,1527165563,,0,1
1247,2018-5-24,2018,5,24,21,8lsbqh,"[N] Weekly Machine Learning Opensource Roundup  May 24, 2018",https://www.reddit.com/r/MachineLearning/comments/8lsbqh/n_weekly_machine_learning_opensource_roundup_may/,stkim1,1527165672,,0,1
1248,2018-5-24,2018,5,24,21,8lsbz3,[R] Fairness in Machine Learning with PyTorch,https://www.reddit.com/r/MachineLearning/comments/8lsbz3/r_fairness_in_machine_learning_with_pytorch/,friscotime,1527165730,,0,1
1249,2018-5-24,2018,5,24,21,8lsebh,[D] Is there any existing research towards a piecewise linear activation function centered around zero?,https://www.reddit.com/r/MachineLearning/comments/8lsebh/d_is_there_any_existing_research_towards_a/,nightcracker,1527166375,"In many places I've seen praise for ReLU in effectiveness but concerns raised in that it's not centered on zero.

Has there been any research into a piecewise linear activation function like ReLU that is centered around zero, e.g. `x - 0.95*(max(x, 1) + min(x, -1))`:

https://i.imgur.com/csJaDZZ.png

This is very similar to a `tanh`, but from what I understand without the vanishing gradient problem.",5,7
1250,2018-5-24,2018,5,24,22,8lshwr,Gluon vs everyone else,https://www.reddit.com/r/MachineLearning/comments/8lshwr/gluon_vs_everyone_else/,IborkedyourGPU,1527167296,[removed],0,1
1251,2018-5-24,2018,5,24,22,8lskhf,[D] Gluon vs the cool frameworks,https://www.reddit.com/r/MachineLearning/comments/8lskhf/d_gluon_vs_the_cool_frameworks/,IborkedyourGPU,1527167937,"Ok, so let's ignite some flame war. Why should one use Gluon to develop Deep Learning models? Why even considering it, when all of the exciting development are done in Tensorflow or PyTorch? Just for JOMO?",25,15
1252,2018-5-24,2018,5,24,22,8lsnpk,Machine Learning/Algorithm/Text Analysis Help,https://www.reddit.com/r/MachineLearning/comments/8lsnpk/machine_learningalgorithmtext_analysis_help/,goingtobegreat,1527168746,[removed],0,1
1253,2018-5-24,2018,5,24,22,8lso2e,Best Model For Data With Outliers?,https://www.reddit.com/r/MachineLearning/comments/8lso2e/best_model_for_data_with_outliers/,Looby219,1527168831,[removed],0,1
1254,2018-5-24,2018,5,24,23,8lswmd,Good Machine Learning Books,https://www.reddit.com/r/MachineLearning/comments/8lswmd/good_machine_learning_books/,TJ1,1527170821,[removed],0,1
1255,2018-5-24,2018,5,24,23,8lsz13,[N] Google and Coursera launch a new machine learning specialization,https://www.reddit.com/r/MachineLearning/comments/8lsz13/n_google_and_coursera_launch_a_new_machine/,shaunlgs,1527171367,,10,59
1256,2018-5-24,2018,5,24,23,8lt0iu,How to Cure Cancer (in images) - the dangers of distribution matching (eg CycleGAN) for medical image synthesis!,https://www.reddit.com/r/MachineLearning/comments/8lt0iu/how_to_cure_cancer_in_images_the_dangers_of/,ieee8023,1527171697,,0,1
1257,2018-5-24,2018,5,24,23,8lt64i,[D] What software/packages I need to learn to enter the industry?,https://www.reddit.com/r/MachineLearning/comments/8lt64i/d_what_softwarepackages_i_need_to_learn_to_enter/,ATU_HAOR,1527172970,"I would love to hear advices on what to software/packages to learn. I am working on my thesis (in the different area) and I need to utilize ML/Deep Learning algorithms. So, I have already picked up couple of good books: Bishop, Murphy and Goodfellow. At the same time, I am working with Python and TensorFlow package. I am fairly proficient with Matlab.

I am looking for recommendations on what else to learn in order to improve my chances of entering the industry.",8,2
1258,2018-5-24,2018,5,24,23,8lt9t7,I am really confused which algorithm to choose?,https://www.reddit.com/r/MachineLearning/comments/8lt9t7/i_am_really_confused_which_algorithm_to_choose/,Loya_3005,1527173806,[removed],0,1
1259,2018-5-24,2018,5,24,23,8ltakx,Text Spotting using Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/8ltakx/text_spotting_using_generative_adversarial/,machtwerk,1527173973,,0,1
1260,2018-5-25,2018,5,25,0,8ltb1m,Using AI to Make Police Alert when there is sudden gathering of People by using Cell tower information AI,https://www.reddit.com/r/MachineLearning/comments/8ltb1m/using_ai_to_make_police_alert_when_there_is/,tulsyan38,1527174066,[removed],0,1
1261,2018-5-25,2018,5,25,0,8lti7g,[D] ML Beyond Curve Fitting: Introduction to Causal Inference and Judea Pearl's do-calculus for ML Folks.,https://www.reddit.com/r/MachineLearning/comments/8lti7g/d_ml_beyond_curve_fitting_introduction_to_causal/,fhuszar,1527175568,,59,296
1262,2018-5-25,2018,5,25,0,8ltoth,Implementation of the ICLR 2018 paper Learning to Count Objects in Natural Images for Visual Question Answering,https://www.reddit.com/r/MachineLearning/comments/8ltoth/implementation_of_the_iclr_2018_paper_learning_to/,shagunsodhani,1527177010,,0,1
1263,2018-5-25,2018,5,25,1,8lu558,[D] 3D Face Reconstruction with Position Map Regression Networks,https://www.reddit.com/r/MachineLearning/comments/8lu558/d_3d_face_reconstruction_with_position_map/,jamesonatfritz,1527180476,,0,18
1264,2018-5-25,2018,5,25,2,8lu92o,Google Provides Free Machine Learning Course For Everyone,https://www.reddit.com/r/MachineLearning/comments/8lu92o/google_provides_free_machine_learning_course_for/,TheLastLived,1527181313,,0,1
1265,2018-5-25,2018,5,25,2,8lubjd,How far ahead is ML in corporates vs academic?,https://www.reddit.com/r/MachineLearning/comments/8lubjd/how_far_ahead_is_ml_in_corporates_vs_academic/,echan00,1527181791,[removed],0,1
1266,2018-5-25,2018,5,25,3,8luzje,Preventing cheating in simple arcade games,https://www.reddit.com/r/MachineLearning/comments/8luzje/preventing_cheating_in_simple_arcade_games/,dsco,1527186827,[removed],0,1
1267,2018-5-25,2018,5,25,4,8lvn8a,"[D] If some mix of fluids at some temperature statistically computed a turing-complete cellular automata, like Wolfram describes in this video, and considering the polynomial slowdown of it emulating a pointer based computer, what would it take to outperform existing computers per dollar?",https://www.reddit.com/r/MachineLearning/comments/8lvn8a/d_if_some_mix_of_fluids_at_some_temperature/,BenRayfield,1527191861,VIDEO: https://youtu.be/_eC14GonZnU?t=18m45s,1,0
1268,2018-5-25,2018,5,25,5,8lvutt,"[D] Potential unethical behavior from a famous group, what to do?",https://www.reddit.com/r/MachineLearning/comments/8lvutt/d_potential_unethical_behavior_from_a_famous/,iclr_throwaway,1527193450,"\(throwaway for obvious reasons\)

My question concerns the following paper, ""Deep Contextualized Word Representations"" \([https://arxiv.org/abs/1802.05365](https://arxiv.org/abs/1802.05365)\). I really enjoyed the paper and was hoping to talk to the authors at ICLR, as I remember it receiving great reviews. However, I didn't see the paper at the conference, and upon investigating further I found out that it was withdrawn: [https://openreview.net/group?id=ICLR.cc/2018/Conference](https://openreview.net/group?id=ICLR.cc/2018/Conference)

  
Curiously, I searched further and found that it was awarded an outstanding paper award at a NLP conference: [https://naacl2018.wordpress.com/2018/04/11/outstanding\-papers/](https://naacl2018.wordpress.com/2018/04/11/outstanding-papers/)

The call\-for\-paper dates for both NAACL/ICLR seems to suggest that it was submitted to both venues \(ICLR deadline is end of October, and NAACL deadline is mid December\), and then withdrawn from ICLR once the NAACL reviews came out. 

I am not sure how NLP conferences work \(I'm an ML person, and most ML conferences, including ICLR, have a strict ban on dual submission\), but this seems to be shady behavior at best and downright unethical at worst. I am considering emailing the program chairs of NAACL to inform them of this, but I'm not sure if this is the right way to address it? Also I don't really care that much since it doesn't really concern me directly.",11,15
1269,2018-5-25,2018,5,25,5,8lw090,Custom PC build: Entry ML,https://www.reddit.com/r/MachineLearning/comments/8lw090/custom_pc_build_entry_ml/,BlackSky2129,1527194641,[removed],0,1
1270,2018-5-25,2018,5,25,6,8lw5f2,Could Machines create 3d models from 2d images?,https://www.reddit.com/r/MachineLearning/comments/8lw5f2/could_machines_create_3d_models_from_2d_images/,Doriando707,1527195767,[removed],8,5
1271,2018-5-25,2018,5,25,6,8lwi5d,Does anyone know where the training data for Google Duplex came from?,https://www.reddit.com/r/MachineLearning/comments/8lwi5d/does_anyone_know_where_the_training_data_for/,Boozybrain,1527198622,[removed],17,6
1272,2018-5-25,2018,5,25,8,8lx60m,What can one LSTM cell can do?,https://www.reddit.com/r/MachineLearning/comments/8lx60m/what_can_one_lstm_cell_can_do/,full--of--leaf,1527204216,[removed],0,1
1273,2018-5-25,2018,5,25,8,8lx8uf,What can a single LSTM cell learn?,https://www.reddit.com/r/MachineLearning/comments/8lx8uf/what_can_a_single_lstm_cell_learn/,full--of--leaf,1527204908,[removed],0,1
1274,2018-5-25,2018,5,25,8,8lxbwb,What can a single LSTM cell learn?,https://www.reddit.com/r/MachineLearning/comments/8lxbwb/what_can_a_single_lstm_cell_learn/,full--of--leaf,1527205672,[removed],0,1
1275,2018-5-25,2018,5,25,9,8lxgwp,Ever feel like you just can't keep up with the field?,https://www.reddit.com/r/MachineLearning/comments/8lxgwp/ever_feel_like_you_just_cant_keep_up_with_the/,ExGenesis,1527206996,[removed],0,1
1276,2018-5-25,2018,5,25,9,8lxqk8,[R] Nonlinear Acceleration of Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8lxqk8/r_nonlinear_acceleration_of_deep_neural_networks/,xternalz,1527209473,,0,8
1277,2018-5-25,2018,5,25,10,8lxsw6,[D] How do you advance with a Machine Learning problem?,https://www.reddit.com/r/MachineLearning/comments/8lxsw6/d_how_do_you_advance_with_a_machine_learning/,pandeykartikey,1527210079,I wanted to know the thought process how one tackles a machine learning problem.,4,0
1278,2018-5-25,2018,5,25,10,8lxxty,conventional press brake products,https://www.reddit.com/r/MachineLearning/comments/8lxxty/conventional_press_brake_products/,davismachinery,1527211384,,0,1
1279,2018-5-25,2018,5,25,10,8ly1fx,digital electric guillotine cutting machine,https://www.reddit.com/r/MachineLearning/comments/8ly1fx/digital_electric_guillotine_cutting_machine/,davismachinery,1527212380,,0,1
1280,2018-5-25,2018,5,25,10,8ly4f4,electric guillotine shear,https://www.reddit.com/r/MachineLearning/comments/8ly4f4/electric_guillotine_shear/,davismachinery,1527213204,,0,1
1281,2018-5-25,2018,5,25,11,8ly7ql,foot pedal shearing machine,https://www.reddit.com/r/MachineLearning/comments/8ly7ql/foot_pedal_shearing_machine/,davismachinery,1527214126,,0,1
1282,2018-5-25,2018,5,25,11,8lybq9,plate sheet universal plate roll machine,https://www.reddit.com/r/MachineLearning/comments/8lybq9/plate_sheet_universal_plate_roll_machine/,davismachinery,1527215255,,0,1
1283,2018-5-25,2018,5,25,11,8lyex9,door frame bending machine,https://www.reddit.com/r/MachineLearning/comments/8lyex9/door_frame_bending_machine/,davismachinery,1527216138,,0,1
1284,2018-5-25,2018,5,25,11,8lyhug,hydraulic guillotine shear 16mm,https://www.reddit.com/r/MachineLearning/comments/8lyhug/hydraulic_guillotine_shear_16mm/,davismachinery,1527216970,,0,1
1285,2018-5-25,2018,5,25,12,8lylgg,w11 cone rolling machine,https://www.reddit.com/r/MachineLearning/comments/8lylgg/w11_cone_rolling_machine/,davismachinery,1527217975,,0,1
1286,2018-5-25,2018,5,25,12,8lyo2q,high speed swing beam shearing machine,https://www.reddit.com/r/MachineLearning/comments/8lyo2q/high_speed_swing_beam_shearing_machine/,davismachinery,1527218746,,0,1
1287,2018-5-25,2018,5,25,13,8lz5uk,[N] ICML Workshop on Credit Assignment in DL and Deep RL,https://www.reddit.com/r/MachineLearning/comments/8lz5uk/n_icml_workshop_on_credit_assignment_in_dl_and/,alexmlamb,1527223966,"It's happening this summer at ICML!  

[https://sites.google.com/view/creditassignmentindlanddrl/home](https://sites.google.com/view/creditassignmentindlanddrl/home)",5,10
1288,2018-5-25,2018,5,25,14,8lz7kr,[P] Suggestive Drawing Among Human and Artificial Intelligences,https://www.reddit.com/r/MachineLearning/comments/8lz7kr/p_suggestive_drawing_among_human_and_artificial/,inarrears,1527224554,,1,16
1289,2018-5-25,2018,5,25,14,8lzcct,https://www.theatlantic.com/technology/archive/2018/05/ubers-self-driving-car-didnt-malfunction-it-was-just-bad/561185/,https://www.reddit.com/r/MachineLearning/comments/8lzcct/httpswwwtheatlanticcomtechnologyarchive201805ubers/,sugarhilldt2,1527226119,,0,1
1290,2018-5-25,2018,5,25,14,8lzcg7,"[D] Ubers Self-Driving Car Didnt Malfunction, It Was Just Bad",https://www.reddit.com/r/MachineLearning/comments/8lzcg7/d_ubers_selfdriving_car_didnt_malfunction_it_was/,sugarhilldt2,1527226149,,163,519
1291,2018-5-25,2018,5,25,15,8lzjyw,"Plantain Chips, Banana Chips Making Machine",https://www.reddit.com/r/MachineLearning/comments/8lzjyw/plantain_chips_banana_chips_making_machine/,lgsherry,1527228708,,1,1
1292,2018-5-25,2018,5,25,15,8lzows,"[D] What are some great non-academic resources (blog posts, videos, tutorials etc.) for high level concepts in Machine Learning?",https://www.reddit.com/r/MachineLearning/comments/8lzows/d_what_are_some_great_nonacademic_resources_blog/,banksyb00mb00m,1527230447,"I am looking for material that explains a high level concept from a rigorous but friendly manner. For example, like any blog post from [Colah](http://colah.github.io/). Thorough and intuitive discussion of a concept is preferred over just a 5-minute glimpse of something.",4,10
1293,2018-5-25,2018,5,25,15,8lzrad,I have one line descriptions of some advertisements on a particular product. I want to create a general description that relates to most of them without being specific to any one advertiser. What are the possible approaches for this?,https://www.reddit.com/r/MachineLearning/comments/8lzrad/i_have_one_line_descriptions_of_some/,shubhamgarg18,1527231309,[removed],0,1
1294,2018-5-25,2018,5,25,17,8m06qg,How Can the Internet of Things (IoT) Drive Your Business?,https://www.reddit.com/r/MachineLearning/comments/8m06qg/how_can_the_internet_of_things_iot_drive_your/,BinaryInformatics,1527237264,,0,1
1295,2018-5-25,2018,5,25,17,8m091i,[R] AutoAugment: Learning Augmentation Policies from Data,https://www.reddit.com/r/MachineLearning/comments/8m091i/r_autoaugment_learning_augmentation_policies_from/,hardmaru,1527238201,,6,51
1296,2018-5-25,2018,5,25,17,8m0abl,Essential 8 Technologies Driving Disruption,https://www.reddit.com/r/MachineLearning/comments/8m0abl/essential_8_technologies_driving_disruption/,BinaryInformatics,1527238699,,0,1
1297,2018-5-25,2018,5,25,18,8m0cu8,How to create clusters of related data,https://www.reddit.com/r/MachineLearning/comments/8m0cu8/how_to_create_clusters_of_related_data/,coolnikhilj22,1527239605,[removed],0,1
1298,2018-5-25,2018,5,25,18,8m0hkj,The simplest explanation of machine learning youll ever read,https://www.reddit.com/r/MachineLearning/comments/8m0hkj/the_simplest_explanation_of_machine_learning/,leaningtoweravenger,1527241376,,0,1
1299,2018-5-25,2018,5,25,18,8m0il2,Almond Butter Grinding Production Line For Sale,https://www.reddit.com/r/MachineLearning/comments/8m0il2/almond_butter_grinding_production_line_for_sale/,Machineprices,1527241724,,1,1
1300,2018-5-25,2018,5,25,19,8m0phw,[R] Meta-learning with differentiable closed-form solvers,https://www.reddit.com/r/MachineLearning/comments/8m0phw/r_metalearning_with_differentiable_closedform/,often_worried,1527244142,,0,1
1301,2018-5-25,2018,5,25,19,8m0ptn,[R] A Gentle Introduction to the Bootstrap Method,https://www.reddit.com/r/MachineLearning/comments/8m0ptn/r_a_gentle_introduction_to_the_bootstrap_method/,molode,1527244245,,0,1
1302,2018-5-25,2018,5,25,19,8m0r9s,[R][1805.08136] Meta-learning with differentiable closed-form solvers,https://www.reddit.com/r/MachineLearning/comments/8m0r9s/r180508136_metalearning_with_differentiable/,often_worried,1527244762,,0,18
1303,2018-5-25,2018,5,25,19,8m0sxn,[R] What is GloVe? Part II,https://www.reddit.com/r/MachineLearning/comments/8m0sxn/r_what_is_glove_part_ii/,janemoz,1527245343,,0,1
1304,2018-5-25,2018,5,25,20,8m0voz,[R] Frameworks for Approaching the Machine Learning Process,https://www.reddit.com/r/MachineLearning/comments/8m0voz/r_frameworks_for_approaching_the_machine_learning/,dearpetra,1527246250,,0,1
1305,2018-5-25,2018,5,25,20,8m0zrs,"How important is having a (complete) understanding the algorithms if you know what its purpose is and moreover, how to use it (through built-in functions for example)?",https://www.reddit.com/r/MachineLearning/comments/8m0zrs/how_important_is_having_a_complete_understanding/,Tosh007,1527247487,[removed],0,1
1306,2018-5-25,2018,5,25,21,8m19c5,Making Healthcare Smarter via Machine Learning: A smart ASD (Autism Spectrum Disorder) detection API,https://www.reddit.com/r/MachineLearning/comments/8m19c5/making_healthcare_smarter_via_machine_learning_a/,ritabratamaiti,1527250359,,0,1
1307,2018-5-25,2018,5,25,21,8m19ly,[D] I have an unlabeled dataset. I want to label it. I have certain very strong hypothesis and rules based on which I can label a sample myself. Is this rule based labeling accepted for machine learning tasks since I am getting a very high accuracy on validation set?,https://www.reddit.com/r/MachineLearning/comments/8m19ly/d_i_have_an_unlabeled_dataset_i_want_to_label_it/,kj75015,1527250443,,5,2
1308,2018-5-25,2018,5,25,21,8m1b16,How Andrew Ng Perceives The AI-Powered World,https://www.reddit.com/r/MachineLearning/comments/8m1b16/how_andrew_ng_perceives_the_aipowered_world/,subhobrata1,1527250836,,0,1
1309,2018-5-25,2018,5,25,21,8m1hu7,Quarter-sphere support vector machines,https://www.reddit.com/r/MachineLearning/comments/8m1hu7/quartersphere_support_vector_machines/,jrchadha,1527252691,[removed],0,1
1310,2018-5-25,2018,5,25,22,8m1mh1,Who are the most prominent experts in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8m1mh1/who_are_the_most_prominent_experts_in_machine/,TJ1,1527253840,[removed],0,1
1311,2018-5-25,2018,5,25,22,8m1orn,[D] Quarter sphere support vector machines,https://www.reddit.com/r/MachineLearning/comments/8m1orn/d_quarter_sphere_support_vector_machines/,jrchadha,1527254396,[removed],0,1
1312,2018-5-25,2018,5,25,22,8m1pg8,"Facebook, Raise The Minimum Age To 16 As GDPR Goes Into Effect Today",https://www.reddit.com/r/MachineLearning/comments/8m1pg8/facebook_raise_the_minimum_age_to_16_as_gdpr_goes/,owen_jr,1527254572,,0,1
1313,2018-5-25,2018,5,25,22,8m1wap,[R] [1805.09786] Hyperbolic Attention Networks,https://www.reddit.com/r/MachineLearning/comments/8m1wap/r_180509786_hyperbolic_attention_networks/,evc123,1527256256,,4,19
1314,2018-5-25,2018,5,25,23,8m1zb1,39 Machine Learning Resources that will help you in every essential step,https://www.reddit.com/r/MachineLearning/comments/8m1zb1/39_machine_learning_resources_that_will_help_you/,javinpaul,1527256959,,0,1
1315,2018-5-25,2018,5,25,23,8m211s,What is the relation between Cross Entropy Loss and Number of Classes?,https://www.reddit.com/r/MachineLearning/comments/8m211s/what_is_the_relation_between_cross_entropy_loss/,P4ND0RA_,1527257341,[removed],0,1
1316,2018-5-25,2018,5,25,23,8m2317,[D] HTTP request to Tensorflow gRPC Server. Has anyone did a sample example for it?,https://www.reddit.com/r/MachineLearning/comments/8m2317/d_http_request_to_tensorflow_grpc_server_has/,spiritualAsshole,1527257797,I want to make a HTTP requests to  deployed TF model which accepts only gRPC requests.  Has anydone did a simple example for this transcoding?  ,2,2
1317,2018-5-25,2018,5,25,23,8m23dg,Neural Machine Translation: In-Depth Research Topic Review,https://www.reddit.com/r/MachineLearning/comments/8m23dg/neural_machine_translation_indepth_research_topic/,jaleyhd,1527257876,,0,1
1318,2018-5-25,2018,5,25,23,8m24ma,[R] Neural Machine Translation: In-Depth Research Topic Review,https://www.reddit.com/r/MachineLearning/comments/8m24ma/r_neural_machine_translation_indepth_research/,jaleyhd,1527258155,,0,1
1319,2018-5-25,2018,5,25,23,8m2ay2,"How to easily do Topic Modeling with LSA, PSLA, LDA &amp; lda2Vec",https://www.reddit.com/r/MachineLearning/comments/8m2ay2/how_to_easily_do_topic_modeling_with_lsa_psla_lda/,nanonets,1527259601,,0,8
1320,2018-5-25,2018,5,25,23,8m2bnt,[D] Detecting anomalies in audit logs of web application with unsupervised methods,https://www.reddit.com/r/MachineLearning/comments/8m2bnt/d_detecting_anomalies_in_audit_logs_of_web/,TheSiK,1527259763,"Hey /r/MachineLearning,

i'm currently working on a project where we have logs of a web application with information like: timestamp, IP, status code of the request, action (login, logout, pw/emai change, etc) and some details for the action. There is no labeled data available. The anomalies could maybe be possible compromise of user accounts, e.g. user never changed his pw and suddenly does pw request and changes pw + email, something along those lines.

I already did a little research, but most of the approaches i found use supervised ML. Maybe a histogram based approach with the count of the actions, where i dunno how to put that with ML currently.

I'd like to know some buzz words or hints for a direction i can take to approach this. 

Currently i'm working on cleaning the logs and aggregating the entries for each user/ip.

I'd really appreciate your help.

",3,3
1321,2018-5-26,2018,5,26,0,8m2mxb,[D] Is the CMT server down?,https://www.reddit.com/r/MachineLearning/comments/8m2mxb/d_is_the_cmt_server_down/,fixed-point-learning,1527262235,I got an email from NIPS program chairs to check for conflicts on the CMT website. But I cannot log into it. Anyone experiencing this sort of problem?,0,1
1322,2018-5-26,2018,5,26,0,8m2pci,Find Idea On Instance Segmentation,https://www.reddit.com/r/MachineLearning/comments/8m2pci/find_idea_on_instance_segmentation/,ccpocker,1527262735,[removed],0,1
1323,2018-5-26,2018,5,26,0,8m2sid,Machine Learning journals and articles?,https://www.reddit.com/r/MachineLearning/comments/8m2sid/machine_learning_journals_and_articles/,CathyQian,1527263418,[removed],0,1
1324,2018-5-26,2018,5,26,1,8m2y01,[N] Biased Facial Recognition - a Problem of Data and Diversity,https://www.reddit.com/r/MachineLearning/comments/8m2y01/n_biased_facial_recognition_a_problem_of_data_and/,skynet_today,1527264612,,2,0
1325,2018-5-26,2018,5,26,1,8m2zdr,What are some must-read ML papers for newcomers wanting to advance in the field?,https://www.reddit.com/r/MachineLearning/comments/8m2zdr/what_are_some_mustread_ml_papers_for_newcomers/,the-data-scientist,1527264922,[removed],0,1
1326,2018-5-26,2018,5,26,1,8m30l0,[D] OpenAI Gym Retro,https://www.reddit.com/r/MachineLearning/comments/8m30l0/d_openai_gym_retro/,sksq9,1527265178,,23,172
1327,2018-5-26,2018,5,26,2,8m3ceb,[D] Hosted TensorBoard,https://www.reddit.com/r/MachineLearning/comments/8m3ceb/d_hosted_tensorboard/,ajbouh,1527267746,"I've been working with TensorFlow a lot and one of the annoying things I need to do for *every* new project is figure out tensorboard hosting. Moving logs around is a pain. Ensuring all collaborators can access tensorboard easily is also a pain.

I put together a hosted service for tensorboard that can run many private instances in a cost effective manner. I'd like to open this service up to others experiencing this need.

Is anyone else looking for a solution to this problem? Where are you currently storing your logs?",2,3
1328,2018-5-26,2018,5,26,2,8m3d2d,"I made a guide to install latest TensorFlow 1.8 on Raspberry Pi 3. Now, we can enjoy implementing deep learning models on the credit-card sized machine.",https://www.reddit.com/r/MachineLearning/comments/8m3d2d/i_made_a_guide_to_install_latest_tensorflow_18_on/,DecipherTechnic,1527267893,,0,1
1329,2018-5-26,2018,5,26,2,8m3ebw,Recognising specific book covers (artwork) using Computer Vision isn't giving effective results,https://www.reddit.com/r/MachineLearning/comments/8m3ebw/recognising_specific_book_covers_artwork_using/,NoMansSkyFullOfStars,1527268162,[removed],0,1
1330,2018-5-26,2018,5,26,2,8m3edv,How To Make a Road Roller At Home Road Construction Machine,https://www.reddit.com/r/MachineLearning/comments/8m3edv/how_to_make_a_road_roller_at_home_road/,smartsolution5,1527268171,,0,1
1331,2018-5-26,2018,5,26,2,8m3el7,[D] Tensorboard hosting and log storage,https://www.reddit.com/r/MachineLearning/comments/8m3el7/d_tensorboard_hosting_and_log_storage/,ajbouh,1527268216,"I've been working with TensorFlow a lot and one of the annoying things I need to do for every new project is figure out tensorboard hosting and log storage. Moving logs around is a pain. Ensuring all collaborators can access tensorboard easily is also a pain.

I put together a hosted service for tensorboard that can run many private instances in a cost effective manner. I'm thinking about opening this service up to others.

Is anyone else feeling this pain? If so, where are your logs stored?

What are others doing for log storage and tensorboard hosting?",2,6
1332,2018-5-26,2018,5,26,2,8m3k39,[N] MXNet backend for Keras 2,https://www.reddit.com/r/MachineLearning/comments/8m3k39/n_mxnet_backend_for_keras_2/,thomasdlt,1527269380,,0,2
1333,2018-5-26,2018,5,26,2,8m3ljb,[N] Keras gets a lightning fast backend,https://www.reddit.com/r/MachineLearning/comments/8m3ljb/n_keras_gets_a_lightning_fast_backend/,thomelane,1527269705,,16,108
1334,2018-5-26,2018,5,26,2,8m3niu,[R] The Blessings of Multiple Causes,https://www.reddit.com/r/MachineLearning/comments/8m3niu/r_the_blessings_of_multiple_causes/,Pandoma,1527270136,,3,9
1335,2018-5-26,2018,5,26,3,8m3wt2,Free webinar by Interactive Brokers: Different data sets to use and avoid in quantitative portfolios.,https://www.reddit.com/r/MachineLearning/comments/8m3wt2/free_webinar_by_interactive_brokers_different/,FintechNerd,1527272164,,0,1
1336,2018-5-26,2018,5,26,3,8m46kp,[D] implementation of a path finding algorithm,https://www.reddit.com/r/MachineLearning/comments/8m46kp/d_implementation_of_a_path_finding_algorithm/,jer_pint,1527274368,"I want to implement a path finding algorithm. An agent is looking for ""food"". This happens in a 2D grid. The agent consists of a square patch, the food of a circle patch. The goal of the agent is to find the patch.

The agent is blind to the world. The only thing it can see is what is inside its patch. So if the patch is far in the distance, the agent has no way of knowing where to go look.

The one thing the agent can learn is that the food is dropped at specific locations based on a probability distribution (i.e. following a Gaussian distribution). The agent always starts in the same spot. We can assume the probability distribution to be constant.

What is the best way of implementating this from a Reinforcement learning perspective, or machine learning in general? I'm thinking DQN.  A* seems like it wouldn't work, as the agent would have to carve out paths first to then decide what to act on - in this case I want the agent to choose a strategy that optimizes always finding food, but not necessarily the fastest way. I'm also thinking of giving the agent the ability to chose the stride to take in both x and y every move. 

The cost function would be based on intersection over union of food and agent and total steps taken.

Any input/links is greatly appreciated :)",7,4
1337,2018-5-26,2018,5,26,4,8m4hfv,Better reinforcement learning algorithms than A3C?,https://www.reddit.com/r/MachineLearning/comments/8m4hfv/better_reinforcement_learning_algorithms_than_a3c/,Pawnbrake,1527276847,[removed],0,1
1338,2018-5-26,2018,5,26,4,8m4kef,Better reinforcement learning algorithms than A3C?,https://www.reddit.com/r/MachineLearning/comments/8m4kef/better_reinforcement_learning_algorithms_than_a3c/,Pawnbrake,1527277544,[removed],0,1
1339,2018-5-26,2018,5,26,4,8m4lfj,[D] Better reinforcement learning algorithms than A3C?,https://www.reddit.com/r/MachineLearning/comments/8m4lfj/d_better_reinforcement_learning_algorithms_than/,Pawnbrake,1527277795,"I know that for solving Atari games or environments such as Acrobot, CartPole, and MountainCar the leading reinforcement learning technique was Q\-learning for some time. Then, A3C came along and it was miles ahead of Q\-learning.

I haven't kept up with these solutions so much. Is there currently anything that is better than A3C for such environments?",5,9
1340,2018-5-26,2018,5,26,7,8m5lrh,[D] Auto-diff vs Analytic-diff in FC DNNs,https://www.reddit.com/r/MachineLearning/comments/8m5lrh/d_autodiff_vs_analyticdiff_in_fc_dnns/,ME_PhD,1527286547,"If I have a simple network with just linear transforms and analytic activations, would it speed it up considerably if I implement gradient descent analytically rather than using automatic differentiation? 

Seems like it would require less memory too since there's no need to store the slopes.

Is this used in practice?",8,3
1341,2018-5-26,2018,5,26,7,8m5rhp,[D] Causal Data Science,https://www.reddit.com/r/MachineLearning/comments/8m5rhp/d_causal_data_science/,Kaixhin,1527287989,,1,68
1342,2018-5-26,2018,5,26,8,8m5xqu,Undergrad looking for advice on future in machine learning,https://www.reddit.com/r/MachineLearning/comments/8m5xqu/undergrad_looking_for_advice_on_future_in_machine/,jonboighini,1527289572,[removed],0,1
1343,2018-5-26,2018,5,26,8,8m66zi,[P] Build An AI to Play Dino Run,https://www.reddit.com/r/MachineLearning/comments/8m66zi/p_build_an_ai_to_play_dino_run/,ArtBears,1527291964,,2,24
1344,2018-5-26,2018,5,26,9,8m6mhp,Very Simple GAN models pytorch notebooks for beginners,https://www.reddit.com/r/MachineLearning/comments/8m6mhp/very_simple_gan_models_pytorch_notebooks_for/,yangyangii,1527296398,,0,1
1345,2018-5-26,2018,5,26,11,8m6znp,Entering the field of machine learning from a different background,https://www.reddit.com/r/MachineLearning/comments/8m6znp/entering_the_field_of_machine_learning_from_a/,eternalLearn,1527300249,[removed],0,1
1346,2018-5-26,2018,5,26,11,8m70um,[R] Task-Agnostic Meta-Learning for Few-shot Learning,https://www.reddit.com/r/MachineLearning/comments/8m70um/r_taskagnostic_metalearning_for_fewshot_learning/,schrodingershit,1527300606,,2,3
1347,2018-5-26,2018,5,26,12,8m7dh6,"[P] Decision Tree for Drug Discovery, a beginner's approach",https://www.reddit.com/r/MachineLearning/comments/8m7dh6/p_decision_tree_for_drug_discovery_a_beginners/,tacosushi2,1527304369,,1,3
1348,2018-5-26,2018,5,26,12,8m7f9h,"[Question] Is there any ""easier"" way to understand the Math in ML?",https://www.reddit.com/r/MachineLearning/comments/8m7f9h/question_is_there_any_easier_way_to_understand/,ThinScreen,1527304893,[removed],0,1
1349,2018-5-26,2018,5,26,12,8m7g70,Question on Batch Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/8m7g70/question_on_batch_gradient_descent/,Futuremlb,1527305193,[removed],0,1
1350,2018-5-26,2018,5,26,12,8m7k35,My nghin vt ngh lin hon Inox NG-250 Cng sut 2KW Ngun in 220V Trng lng 50 kg Sn lng 200-400 kg/h,https://www.reddit.com/r/MachineLearning/comments/8m7k35/my_nghin_vt_ngh_lin_hon_inox_ng250_cng/,HangNguyen1111,1527306421,,0,1
1351,2018-5-26,2018,5,26,13,8m7oky,"My o  m go cm tay Kett Riceter F511 ng dng vi: La, go, la m Thang o: Go: 11-20%, La m: 10-30%, La: 11-30%  chnh xc: 0,5%",https://www.reddit.com/r/MachineLearning/comments/8m7oky/my_o__m_go_cm_tay_kett_riceter_f511_ng/,HangNguyen1111,1527307845,,0,1
1352,2018-5-26,2018,5,26,13,8m7qom,n dit cn trng ZE 124 bng chng v - Anh Bng n chng v: Pluslamp 2 x TVX15-18 in nng: 230V / AC Phm vi hiu qu (m): 80m2 Trng lng(kg): 3.5 Bc sng tia cc tm : 350-400 nm,https://www.reddit.com/r/MachineLearning/comments/8m7qom/n_dit_cn_trng_ze_124_bng_chng_v_anh_bng/,HangNguyen1111,1527308540,,0,1
1353,2018-5-26,2018,5,26,13,8m7uao,Proof of the Reparameterization Trick,https://www.reddit.com/r/MachineLearning/comments/8m7uao/proof_of_the_reparameterization_trick/,Yeebster,1527309775,[removed],0,1
1354,2018-5-26,2018,5,26,14,8m7yut,Has anyone submitted the ICML camera-ready paper?,https://www.reddit.com/r/MachineLearning/comments/8m7yut/has_anyone_submitted_the_icml_cameraready_paper/,alayaMatrix,1527311452,[removed],0,1
1355,2018-5-26,2018,5,26,15,8m8cn9,"Small electricity block carrying barrow forklift, cheapest forklift for ...",https://www.reddit.com/r/MachineLearning/comments/8m8cn9/small_electricity_block_carrying_barrow_forklift/,dymachine01,1527316572,,1,1
1356,2018-5-26,2018,5,26,16,8m8o7z,[R] [1805.08974] Do Better ImageNet Models Transfer Better?,https://www.reddit.com/r/MachineLearning/comments/8m8o7z/r_180508974_do_better_imagenet_models_transfer/,pmigdal,1527321084,,5,47
1357,2018-5-26,2018,5,26,16,8m8phw,Hi r/MachineLearning. Is there a consumer level program that I cantuse?That anybody could use. I want something that uses reinforcement learning with my data. What is the easiest program to use?,https://www.reddit.com/r/MachineLearning/comments/8m8phw/hi_rmachinelearning_is_there_a_consumer_level/,5points,1527321575,[removed],0,1
1358,2018-5-26,2018,5,26,17,8m8sv0,Avast Support,https://www.reddit.com/r/MachineLearning/comments/8m8sv0/avast_support/,ContactAssistance,1527322985,,0,1
1359,2018-5-26,2018,5,26,17,8m8uka,AVG Support,https://www.reddit.com/r/MachineLearning/comments/8m8uka/avg_support/,ContactAssistance,1527323660,,0,1
1360,2018-5-26,2018,5,26,18,8m9197,[D] Intrinsic dimensionality and PCA,https://www.reddit.com/r/MachineLearning/comments/8m9197/d_intrinsic_dimensionality_and_pca/,RubioRick,1527326348,"Good morning ! I have a question about intrinsic dimensionality and PCA. I have a data space with 144 features , and I know that I can fully describe it in M = 6 features with the help of PCA.
My data space has intrinsic dimensionality = 3 (three grades of freedom : rotation , translation vertical and horizontal). 

The question is : Is M going to be equal to the number of intrinsic dimensions? Explain.
",11,23
1361,2018-5-26,2018,5,26,19,8m9eqv,[D] Valve: Using Deep Learning to Combat Cheating in CSGO,https://www.reddit.com/r/MachineLearning/comments/8m9eqv/d_valve_using_deep_learning_to_combat_cheating_in/,pruzinat,1527331945,,59,462
1362,2018-5-26,2018,5,26,21,8m9t6i,Online Mirror Descent,https://www.reddit.com/r/MachineLearning/comments/8m9t6i/online_mirror_descent/,sudeepraja,1527337299,,0,1
1363,2018-5-26,2018,5,26,21,8m9ta1,How Machine Learning and Sensors Help Detect Cyber Threats within Power Distribution Networks,https://www.reddit.com/r/MachineLearning/comments/8m9ta1/how_machine_learning_and_sensors_help_detect/,dexlabanalytics,1527337337,,0,1
1364,2018-5-26,2018,5,26,22,8ma27l,Do you find multi-GPU machines useful?,https://www.reddit.com/r/MachineLearning/comments/8ma27l/do_you_find_multigpu_machines_useful/,glaxodiscus,1527340361,[removed],0,1
1365,2018-5-26,2018,5,26,22,8ma738,[D] Potential for acceptance into a M.Sc./Ph.D. program based on research-based work experience?,https://www.reddit.com/r/MachineLearning/comments/8ma738/d_potential_for_acceptance_into_a_mscphd_program/,usefuldimension,1527341863,"Recently graduated college, began working as an engineer at a Big-4 research lab. Would love to eventually make the transition from engineer to research scientist but I suspect having only a B.Sc. will be an impediment. My problem is that my transcript, frankly, is far below average. I put in a lot of work over my last year in college building up a sufficient knowledge base in ML in order to get this job and as a result, my grades suffered. Will exceptional work through my job (letters of recommendations from research scientists, publishing papers) suffice to get me in the door at a top institution? Is there anything else I can do to better my chances? Would love to hear from anyone who went the academic route with a subpar GPA.",23,29
1366,2018-5-26,2018,5,26,22,8maal2,"New machine learning ad-blocking tech called AdGraph outperforms conventional ad-blocking tech: ""We can train supervised machine learning models to automatically block ads and trackers; we found that AdGraph replicates the behavior of popular crowdsourced filter lists with an 97.7 percent accuracy.""",https://www.reddit.com/r/MachineLearning/comments/8maal2/new_machine_learning_adblocking_tech_called/,CryptoJennie,1527342930,,0,2
1367,2018-5-26,2018,5,26,23,8mac89,Football related ML project,https://www.reddit.com/r/MachineLearning/comments/8mac89/football_related_ml_project/,leviz73,1527343392,[removed],0,1
1368,2018-5-26,2018,5,26,23,8madqa,On the nondifferentiability of sampling.,https://www.reddit.com/r/MachineLearning/comments/8madqa/on_the_nondifferentiability_of_sampling/,acobobby,1527343785,[removed],0,1
1369,2018-5-26,2018,5,26,23,8mahps,Multiple multivariate knn (wknn) model - what to check?,https://www.reddit.com/r/MachineLearning/comments/8mahps/multiple_multivariate_knn_wknn_model_what_to_check/,cloclo3,1527344891,[removed],0,1
1370,2018-5-26,2018,5,26,23,8makor,Help with Horse Racing Machine Learning Project,https://www.reddit.com/r/MachineLearning/comments/8makor/help_with_horse_racing_machine_learning_project/,pseudoego,1527345736,[removed],0,1
1371,2018-5-27,2018,5,27,0,8maooc,[D] Error function for AdaBoost Algorithm,https://www.reddit.com/r/MachineLearning/comments/8maooc/d_error_function_for_adaboost_algorithm/,RubioRick,1527346816,"I need to solve a task where it is asked to me to provide an error function whose minimization leads to a formulation equivalent to the AdaBoost algorithm.

I did not understand exactly this question , I know that in the AdaBoost algorithm at the beginning I train a ""weak"" learner by minimizing its error function and then I used the weights to compute errors and iterate over the new classifier, this in an iterative way ; so what does it mean with this error function to minimize ?",1,0
1372,2018-5-27,2018,5,27,0,8maqdv,[R] Non-stationary Texture Synthesis by Adversarial Expansion,https://www.reddit.com/r/MachineLearning/comments/8maqdv/r_nonstationary_texture_synthesis_by_adversarial/,feddddo,1527347239,,0,43
1373,2018-5-27,2018,5,27,0,8maxz0,Error function,https://www.reddit.com/r/MachineLearning/comments/8maxz0/error_function/,saifu7,1527349220,[removed],0,1
1374,2018-5-27,2018,5,27,1,8mb3oj,101 Best Data Science &amp; Machine Learning Interview Questions to Crack jobs in 2018,https://www.reddit.com/r/MachineLearning/comments/8mb3oj/101_best_data_science_machine_learning_interview/,mahibabu,1527350728,,0,1
1375,2018-5-27,2018,5,27,1,8mb7q1,[R] A.I just made a new language!,https://www.reddit.com/r/MachineLearning/comments/8mb7q1/r_ai_just_made_a_new_language/,orenog,1527351760,,0,1
1376,2018-5-27,2018,5,27,1,8mbf1v,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/MachineLearning/comments/8mbf1v/are_you_interested_in_ai_and_want_to_start/,ailearn12,1527353662,,0,1
1377,2018-5-27,2018,5,27,2,8mbif5,[NEWS] New Release of Python ML Visualization Library: Yellowbrick,https://www.reddit.com/r/MachineLearning/comments/8mbif5/news_new_release_of_python_ml_visualization/,W1zK1dd,1527354507, Checkout the github repo! [https://github.com/DistrictDataLabs/yellowbrick](https://github.com/DistrictDataLabs/yellowbrick) ,9,57
1378,2018-5-27,2018,5,27,2,8mbmd7,[P] NLP Architect by Intel AI Lab,https://www.reddit.com/r/MachineLearning/comments/8mbmd7/p_nlp_architect_by_intel_ai_lab/,sksq9,1527355501,,0,19
1379,2018-5-27,2018,5,27,2,8mbo7f,Deep Reinforcement Learning For Sequence to Sequence Models (Source Code),https://www.reddit.com/r/MachineLearning/comments/8mbo7f/deep_reinforcement_learning_for_sequence_to/,yaserkl,1527355963,,0,1
1380,2018-5-27,2018,5,27,3,8mbvhb,[D] Prior work on handcrafted state vectors for 3D/2D game environments,https://www.reddit.com/r/MachineLearning/comments/8mbvhb/d_prior_work_on_handcrafted_state_vectors_for/,the_roboticist,1527357708,"There is a large body of work on learning from pixels \(e.g. Atari\) but not so much on simpler representations. For example, in Minecraft, you could give the agent the relative transform of every block in the agent's view. Since I'm mostly interested in the reasoning and not the visual system, it makes sense to me to represent the world like this. However, I'm having trouble thinking about how to represent the variable number of blocks as a fixed length embedding to the model. Is there any prior work in this area? ",4,5
1381,2018-5-27,2018,5,27,3,8mbzco,[D] Batch Normalization exploding/vanishing WEIGHTS?,https://www.reddit.com/r/MachineLearning/comments/8mbzco/d_batch_normalization_explodingvanishing_weights/,ME_PhD,1527358663,"Multiplying weights by a constant has no effect if I normalize. So how can I ensure the weights don't just drift together towards really large numbers?

If I use L2 regularization, they would all go towards 0 really fast. Is this problematic? What can I do?",2,0
1382,2018-5-27,2018,5,27,3,8mbzte,AI Weekly 26 May 2018,https://www.reddit.com/r/MachineLearning/comments/8mbzte/ai_weekly_26_may_2018/,TomekB,1527358773,,0,1
1383,2018-5-27,2018,5,27,3,8mc5jx,[P] EEG event classification with convolutional neural networks - A First Pass/Brief Overview,https://www.reddit.com/r/MachineLearning/comments/8mc5jx/p_eeg_event_classification_with_convolutional/,ElDopa40,1527360186,,9,8
1384,2018-5-27,2018,5,27,3,8mc86j,[P] Keras Deeplab v3 (semantic image segmentation) with pretrained weights,https://www.reddit.com/r/MachineLearning/comments/8mc86j/p_keras_deeplab_v3_semantic_image_segmentation/,SupraluminalShift,1527360869,,1,12
1385,2018-5-27,2018,5,27,3,8mc93f,[D] Best models for Dense Text Detection?,https://www.reddit.com/r/MachineLearning/comments/8mc93f/d_best_models_for_dense_text_detection/,cbsudux,1527361104,"I'm working on a problem to detect text from a cluttered ID Card. I've used CTPN, but the results are not spectacular. I will be deploying the model to production soon and It would be nice to have a higher accuracy. Experienced users, what models would you suggest?

Cheers :)",2,9
1386,2018-5-27,2018,5,27,4,8mckp5,How to predict changes in a signal based on other leading signals?,https://www.reddit.com/r/MachineLearning/comments/8mckp5/how_to_predict_changes_in_a_signal_based_on_other/,pikockr,1527364049,[removed],1,1
1387,2018-5-27,2018,5,27,4,8mcme3,How to build an Artificial Neural Network in Java,https://www.reddit.com/r/MachineLearning/comments/8mcme3/how_to_build_an_artificial_neural_network_in_java/,EndyJBC,1527364507,,0,1
1388,2018-5-27,2018,5,27,7,8mdpyk,Visualisation of a GAN learning to generate a circle,https://www.reddit.com/r/MachineLearning/comments/8mdpyk/visualisation_of_a_gan_learning_to_generate_a/,Uriopass,1527374751,,0,1
1389,2018-5-27,2018,5,27,8,8mdu7g,[P] SQuAD reading comprehension dataset (Stanford Question Answering Dataset),https://www.reddit.com/r/MachineLearning/comments/8mdu7g/p_squad_reading_comprehension_dataset_stanford/,ibbybenali,1527375910,,0,0
1390,2018-5-27,2018,5,27,8,8mdwq6,RL-Adventure-2: PyTorch4 tutorial of: actor critic / proximal policy optimization / acer / ddpg / twin dueling ddpg / soft actor critic / generative adversarial imitation learning / hindsight experience replay,https://www.reddit.com/r/MachineLearning/comments/8mdwq6/rladventure2_pytorch4_tutorial_of_actor_critic/,Codeunter,1527376617,,0,1
1391,2018-5-27,2018,5,27,8,8mdyfp,RL-Adventure-2: PyTorch4 tutorial of: actor critic / proximal policy optimization / acer / ddpg / twin dueling ddpg / soft actor critic / generative adversarial imitation learning / hindsight experience replay,https://www.reddit.com/r/MachineLearning/comments/8mdyfp/rladventure2_pytorch4_tutorial_of_actor_critic/,codentropy,1527377063,,1,1
1392,2018-5-27,2018,5,27,10,8melc7,When and where can we submit a camera-ready version for ICML 2018?,https://www.reddit.com/r/MachineLearning/comments/8melc7/when_and_where_can_we_submit_a_cameraready/,htliu_dlut,1527383840,[removed],0,1
1393,2018-5-27,2018,5,27,10,8menfq,"what is ""predictor"" when doing KNN algorithm in R ?",https://www.reddit.com/r/MachineLearning/comments/8menfq/what_is_predictor_when_doing_knn_algorithm_in_r/,tbop02,1527384484,[removed],0,1
1394,2018-5-27,2018,5,27,11,8mev35,"Dr. AI will see you: Artificial intelligence comes to the doctors office, helping identify disease, monitor heart activity, stave off seizures",https://www.reddit.com/r/MachineLearning/comments/8mev35/dr_ai_will_see_you_artificial_intelligence_comes/,Science_Podcast,1527386862,,0,1
1395,2018-5-27,2018,5,27,12,8mfbi0,"When we have unlimited data, should we use epochs?",https://www.reddit.com/r/MachineLearning/comments/8mfbi0/when_we_have_unlimited_data_should_we_use_epochs/,xcvxcvv,1527392068,[removed],0,1
1396,2018-5-27,2018,5,27,13,8mfi1i,Deshaun Watson || Comeback SZN,https://www.reddit.com/r/MachineLearning/comments/8mfi1i/deshaun_watson_comeback_szn/,nbafan08,1527394253,,0,1
1397,2018-5-27,2018,5,27,14,8mfsac,[N] Hello World Canada: The Rise of AI,https://www.reddit.com/r/MachineLearning/comments/8mfsac/n_hello_world_canada_the_rise_of_ai/,upulbandara,1527397914,,0,17
1398,2018-5-27,2018,5,27,14,8mfv54,[P] Simple Image Colorization in PyTorch,https://www.reddit.com/r/MachineLearning/comments/8mfv54/p_simple_image_colorization_in_pytorch/,L-MK,1527399052,,5,28
1399,2018-5-27,2018,5,27,16,8mgeg6,How to solve the problem of uneven target values ?,https://www.reddit.com/r/MachineLearning/comments/8mgeg6/how_to_solve_the_problem_of_uneven_target_values/,kaka8388,1527407401,[removed],0,1
1400,2018-5-27,2018,5,27,17,8mggla,RL-Adventure-2: PyTorch4 tutorial of: actor critic / proximal policy optimization / acer / ddpg / twin dueling ddpg / soft actor critic / generative adversarial imitation learning / hindsight experience replay,https://www.reddit.com/r/MachineLearning/comments/8mggla/rladventure2_pytorch4_tutorial_of_actor_critic/,Codeunter,1527408417,,0,1
1401,2018-5-27,2018,5,27,17,8mgjhz,VACnet in CS:GO | Cheating Is Dying,https://www.reddit.com/r/MachineLearning/comments/8mgjhz/vacnet_in_csgo_cheating_is_dying/,ImThour,1527409837,,0,1
1402,2018-5-27,2018,5,27,17,8mglrr,Data analysis of ENS (Ethereum Naming service),https://www.reddit.com/r/MachineLearning/comments/8mglrr/data_analysis_of_ens_ethereum_naming_service/,portalnetwork,1527410985,,0,1
1403,2018-5-27,2018,5,27,18,8mgs8k,[P] Visualisation of a GAN learning to generate a circle,https://www.reddit.com/r/MachineLearning/comments/8mgs8k/p_visualisation_of_a_gan_learning_to_generate_a/,Uriopass,1527414073,,66,564
1404,2018-5-27,2018,5,27,18,8mgsic,[D] Need some different opinions for school project,https://www.reddit.com/r/MachineLearning/comments/8mgsic/d_need_some_different_opinions_for_school_project/,FritzusBomb,1527414204,"Hi for a small little research for school i need some differemt opinions on a few different questions.
If you could answer these questions i would really appreciate it.

How far do you think machine learning will be able to progress, do you see development hitting a wall in the future?

Do you think machine learning in it's current state is already able to replace simple jobs? If not how long do you think it will take?

How will machine learning affect jobs? Do you see machine learning and AI taking over jobs like programming in the future or do you think it will create more jobs than it destroys?

",2,0
1405,2018-5-27,2018,5,27,19,8mgvrz,[D]Using a pen name in Machine Learning academia?,https://www.reddit.com/r/MachineLearning/comments/8mgvrz/dusing_a_pen_name_in_machine_learning_academia/,sonsus,1527415764,"Hi, I'm about to publish my first workshop paper to the conference, and considering use of pen name instead of real name. 

Since my family name is really frequent so anybody with the same nationality will look confusing to identify each other in citation. 

Would there be any problematic situation if I write my name as a pen name instead of what's on my legal identity? \(e.g. getting into the trouble verifying my contribution when writing CVs or being considered as somewhat troublesome person because of using different name from original one\) 

Maybe my research carrier will tell my identity in academia in the end but I thought it would be nice to have a pen name. ",17,7
1406,2018-5-27,2018,5,27,19,8mh08n,How Machine Learning on Devices is being worked?,https://www.reddit.com/r/MachineLearning/comments/8mh08n/how_machine_learning_on_devices_is_being_worked/,irfamerry,1527417766,,0,1
1407,2018-5-27,2018,5,27,19,8mh1aj,RL-Adventure-2: PyTorch4 tutorial of: actor critic / proximal policy optimization / acer / ddpg / twin dueling ddpg / soft actor critic / generative adversarial imitation learning / hindsight experience replay,https://www.reddit.com/r/MachineLearning/comments/8mh1aj/rladventure2_pytorch4_tutorial_of_actor_critic/,meta_rl,1527418263,,0,1
1408,2018-5-27,2018,5,27,19,8mh2j9,[P] RL-Adventure-2: PyTorch4 tutorial of: actor critic / proximal policy optimization / acer / ddpg / twin dueling ddpg / soft actor critic / generative adversarial imitation learning / hindsight experience replay,https://www.reddit.com/r/MachineLearning/comments/8mh2j9/p_rladventure2_pytorch4_tutorial_of_actor_critic/,codentropy,1527418792,,5,62
1409,2018-5-27,2018,5,27,20,8mh8yk,"New to machine learning, I wrote an MNIST perceptron in C++. Manually setting hyperparameters feels like cheating. Where can I learn about implementing genetic algorithms for picking hyperparameters?",https://www.reddit.com/r/MachineLearning/comments/8mh8yk/new_to_machine_learning_i_wrote_an_mnist/,moomin100,1527421509,[removed],0,1
1410,2018-5-27,2018,5,27,20,8mh9le,The Significance of Poisson Distribution in Statistics | Hashtag Statistics,https://www.reddit.com/r/MachineLearning/comments/8mh9le/the_significance_of_poisson_distribution_in/,LearningFromData,1527421768,,0,1
1411,2018-5-27,2018,5,27,21,8mhf9y,[D] Developing Neuro Machine Translation in-house,https://www.reddit.com/r/MachineLearning/comments/8mhf9y/d_developing_neuro_machine_translation_inhouse/,MasterEpictetus,1527423859,Is it possible/realistic to train your own NMT system and achieve performance similar to FB and Google? I'm investigating doing that in my company rather than using third party software. Any recommended resources out there?,9,9
1412,2018-5-27,2018,5,27,21,8mhkfs,Google AI is brillant - this site is full of hacks,https://www.reddit.com/r/MachineLearning/comments/8mhkfs/google_ai_is_brillant_this_site_is_full_of_hacks/,lutel,1527425722,,0,1
1413,2018-5-27,2018,5,27,23,8mi3cf,Where can I find as easy explanation to Google's Wavenet (https://arxiv.org/pdf/1609.03499.pdf),https://www.reddit.com/r/MachineLearning/comments/8mi3cf/where_can_i_find_as_easy_explanation_to_googles/,ishan08,1527431464,[removed],0,1
1414,2018-5-27,2018,5,27,23,8mi5lm,Looking to implement Deep Learning in C++,https://www.reddit.com/r/MachineLearning/comments/8mi5lm/looking_to_implement_deep_learning_in_c/,stonedkrypto,1527432095,[removed],0,1
1415,2018-5-27,2018,5,27,23,8mi7dg,Is it possible to train a network from a set of images to produce a light-field?,https://www.reddit.com/r/MachineLearning/comments/8mi7dg/is_it_possible_to_train_a_network_from_a_set_of/,mrconter1,1527432575,[removed],0,1
1416,2018-5-27,2018,5,27,23,8mi8dz,[P] A Reinforcemet Learning model to play the Chrome's offline Dino-run | Entire project built and trained on Paperspace GPU VM,https://www.reddit.com/r/MachineLearning/comments/8mi8dz/p_a_reinforcemet_learning_model_to_play_the/,coolusername2020,1527432847,,3,9
1417,2018-5-28,2018,5,28,0,8midpw,[D] What is happening in this subreddit?,https://www.reddit.com/r/MachineLearning/comments/8midpw/d_what_is_happening_in_this_subreddit/,begooboi,1527434219,"I was not going to post this but something wrong is happening here in this subreddit which forced my hands.


This week two posts relating to machine learning were posted here one is about [How visual search works](https://thomasdelteil.github.io/VisualSearch_MXNet/) and other about [generating ramen](https://www.reddit.com/r/MachineLearning/comments/8l5w56/p_generative_ramen/). The former post contains a small write up, source code and a demo site to explain how visual search works and the latter just have a gif of generated  ramen probably with a GAN. The irony is that the post which has more information and source code for reproducing that work got only about 25 votes and the one with gif only with no source code or explanation provided got more than 1000 votes (not so unique work any one with basic understanding of GAN can make one). Today the most upvoted post here is about [a circle generating GAN](https://www.reddit.com/r/MachineLearning/comments/8mgs8k/p_visualisation_of_a_gan_learning_to_generate_a/) which also has only a gif with brief explanation as comment and no source code. Are you seeing a pattern here?

The problem I mentioned above is not a one of case, I am a regular lurker in this subreddit and for the past few months I started seeing some disturbing patterns in posts posted here. People who posts gif/movie/photo only post tends to get more upvotes than the posts with full source code or explanation.  I agree some original research posts [such as this](https://www.youtube.com/watch?v=qc5P2bvfl44&amp;feature=youtu.be&amp;t=7s) can be only be released as videos and not a source code because of its commercial value. But most of the gif/movie/photo only posts here are not at all original research but they used a already know algorithm with a different dataset (eg: Ramen generation). 

The problem here is If we continue this type of posts people will stop sharing their original works, source code or explanation and then starts sharing this type of end result only posts which will get less scrutiny and more votes. In future, this will not only decrease the quality of this subreddit but also its a greater danger to the open nature of Machine learning field. What's the point in posting a github project link or blogpost here when we can get much more votes with a gif alone one?.

*I am not a academician but I use r/MachineLearning to find blogs, articles and projects which explains/program recent discoveries in AI which I myself can try out.*
",145,903
1418,2018-5-28,2018,5,28,0,8mihni,[D] How does SVM ignore outliers ?,https://www.reddit.com/r/MachineLearning/comments/8mihni/d_how_does_svm_ignore_outliers/,RubioRick,1527435206,"I'm studying SVM algorithm and I read that it is strong with outliers. If I have to find the hyperplane that segregates 2 classes in a 2D space , and if I have an outlier , SVM ignores the outlier and chooses the hyperplane with the max margin.

How does it understand that a data point is an outlier ?",17,8
1419,2018-5-28,2018,5,28,1,8mir3t,Pop music generator,https://www.reddit.com/r/MachineLearning/comments/8mir3t/pop_music_generator/,tunestar2018,1527437617,[removed],0,1
1420,2018-5-28,2018,5,28,2,8mjc88,How to become AI researcher?,https://www.reddit.com/r/MachineLearning/comments/8mjc88/how_to_become_ai_researcher/,nachiket273,1527442764,[removed],0,1
1421,2018-5-28,2018,5,28,3,8mjufu,The dangers of AI solutionism: Why AI can't solve everything,https://www.reddit.com/r/MachineLearning/comments/8mjufu/the_dangers_of_ai_solutionism_why_ai_cant_solve/,grrmspeaks,1527447166,[removed],0,1
1422,2018-5-28,2018,5,28,4,8mk5cs,[P] Text summarization with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/8mk5cs/p_text_summarization_with_tensorflow/,tttttm,1527449835,,1,14
1423,2018-5-28,2018,5,28,5,8mkbk2,Classify BBC news headlines with Microsoft ML.NET,https://www.reddit.com/r/MachineLearning/comments/8mkbk2/classify_bbc_news_headlines_with_microsoft_mlnet/,d-zub,1527451354,,0,1
1424,2018-5-28,2018,5,28,5,8mkgg7,Online sites to learn Machine learning?,https://www.reddit.com/r/MachineLearning/comments/8mkgg7/online_sites_to_learn_machine_learning/,_abhishejha_,1527452573,[removed],0,1
1425,2018-5-28,2018,5,28,5,8mkgrv,Ok I have a rather large dataset that has some features that are nominal and some that are ordinal...,https://www.reddit.com/r/MachineLearning/comments/8mkgrv/ok_i_have_a_rather_large_dataset_that_has_some/,TheBlackOut2,1527452660,[removed],0,1
1426,2018-5-28,2018,5,28,5,8mknhe,Is MTCNN the state of the art in face detection and alignment?,https://www.reddit.com/r/MachineLearning/comments/8mknhe/is_mtcnn_the_state_of_the_art_in_face_detection/,Ashutosh311297,1527454283,[removed],0,1
1427,2018-5-28,2018,5,28,6,8mkq91,Which math is more useful for machine learning? Linear Algebra or Multivariable Calculus,https://www.reddit.com/r/MachineLearning/comments/8mkq91/which_math_is_more_useful_for_machine_learning/,reddittUndecidedEE,1527454968,I have a single math elective to take during my first year grad studies in computer science. I eventually want to get a job in machine learning but I am preparing to take the machine learning course for next semester. What math would be more useful to understand deeply before taking the course Linear Algebra or Multivariable Calculus? I know both will be needed but I could always youtube the other math course.,0,1
1428,2018-5-28,2018,5,28,6,8mktj5,[P] Machine Learning Chat by RemoteML,https://www.reddit.com/r/MachineLearning/comments/8mktj5/p_machine_learning_chat_by_remoteml/,Sig_Luna,1527455799,,3,1
1429,2018-5-28,2018,5,28,6,8mkupi,Scala ML implementations vs scikit-learn,https://www.reddit.com/r/MachineLearning/comments/8mkupi/scala_ml_implementations_vs_scikitlearn/,inejc,1527456091,[removed],1,1
1430,2018-5-28,2018,5,28,7,8ml4u1,Neural g2p impl,https://www.reddit.com/r/MachineLearning/comments/8ml4u1/neural_g2p_impl/,bic-user,1527458703,[removed],0,1
1431,2018-5-28,2018,5,28,7,8ml9hh,Apache MXNet adds support for Keras 2.,https://www.reddit.com/r/MachineLearning/comments/8ml9hh/apache_mxnet_adds_support_for_keras_2/,alcaster0,1527459876,,1,1
1432,2018-5-28,2018,5,28,7,8mlf57,"Tensorflow for Poets instructions leads to ""the name 'import/input' refers to an operation not in the graph."" error. None of the Github issues or Stackoverflow solutions are working.",https://www.reddit.com/r/MachineLearning/comments/8mlf57/tensorflow_for_poets_instructions_leads_to_the/,ArkBirdFTW,1527461338,[removed],0,1
1433,2018-5-28,2018,5,28,9,8mluw9,[D] Does anyone know of any comparisons of the effectiveness of different neural network shapes?,https://www.reddit.com/r/MachineLearning/comments/8mluw9/d_does_anyone_know_of_any_comparisons_of_the/,iamiamwhoami,1527465652,For example comparing a feed forward neural network that has all hidden layers with the same number of units to one with an hour glass shape?,4,7
1434,2018-5-28,2018,5,28,9,8mlyco,[P] ResNet implementation for medical image segmentation (Keras),https://www.reddit.com/r/MachineLearning/comments/8mlyco/p_resnet_implementation_for_medical_image/,alba_troz,1527466565,"Hello and thanks in advanced! I have two things to ask:

My Thesis consists on proving the concept of CNN's applied to automated liver tumor segmentation. I am trying to adapt [this ResNet](https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/applications/resnet.py), and I'm using the [LiTS DataSet](https://competitions.codalab.org/competitions/17094#participate). It consists of \~30 CT scans, each 512x512xN \(N layers, varying between 75 and \~600 layers per scan\). Problem is ResNet expects 3 layer pictures \(RGB\) per input.   
So the solution I found was to use as input 3 layers of a scan at a time, until I had the full picture covered. So if scan A had  6 layers, I would do 4 pictures out of it, the first being layers \(0, 1, 2\), then layers \(1, 2, 3\), \(2, 3, 4\), \(3, 4, 5\), all of which are 512x512x3. Is this a good strategy?  


Also, I do not understand how I am supposed to feed the expected masks to the network. This is this RestNet's header:

    ResNet(input_shape=None, classes=10, block='bottleneck', residual_unit='v2', repetitions=None, initial_filters=64, activation='softmax', include_top=True, input_tensor=None, dropout=None, transition_dilation_rate=(1, 1), initial_strides=(2, 2), initial_kernel_size=(7, 7), initial_pooling='max', final_pooling=None, top='classification')

How should I pass the expected output to this code?

Thanks again and hope you have a great day!",1,1
1435,2018-5-28,2018,5,28,9,8mm1jh,[D] Help Stabilizing GAN,https://www.reddit.com/r/MachineLearning/comments/8mm1jh/d_help_stabilizing_gan/,tpapp157,1527467405,"You may remember a hobby project I posted about here previously that used a GAN to generate a terrain map based on a simple user supplied input image \( [https://www.reddit.com/r/MachineLearning/comments/7dwj1q/p\_fun\_project\_mspaint\_to\_terrain\_map\_with\_gan/](https://www.reddit.com/r/MachineLearning/comments/7dwj1q/p_fun_project_mspaint_to_terrain_map_with_gan/) \). Over the past month or so I've found some spare time to return to this project and attempt something much harder but also much more useful. The terrain maps are fun but only really useful as nice images to look at and not much more. My new goal is to generate something useful in the 3D world by creating height and texture maps. Height maps are grayscale images that use pixel intensity to encode geographic altitude and are often used to store the topographic data of 3D landscapes. Texture maps are images that hold the coloring of the terrain. Height maps are fine because elevation data for the Earth is freely available but texture maps don't exist \(at least not in the way that I want them\) so I'm left with my original terrain map images.

Of course that's a problem because the images I'm trying to generate are not the same as the images in my training set. The solution is that using the height map I can calculate the shadows and then apply them to the texture map to recreate the terrain map. This calculation represents a bunch of trigonometry \(essentially calculating the angle between a line and a plane in 3D space as derived from pixel values\) and even after I've simplified and approximated this calculation a bunch it's still not a nice thing to push gradients back through. The result is really unstable training.

I started with vanilla GAN but unsurprisingly this barely lasted a few epochs before collapsing. Next was vanilla WGAN which did better but not all that much. WGAN\-GP was better again but still eventually collapsed. I then stumbled on this paper \( [https://arxiv.org/abs/1705.09367](https://arxiv.org/abs/1705.09367) \) and it provided the most stable training by far. Image quality was also way better but after about 4 days of continuous training it also collapsed \(millions of images\). Training the discriminator faster than the generator simply led to the discriminator becoming too good and collapse.

In addition to trying different metrics I also tried different tweaks to the architecture. A combination of leaky\-relu and normal relu in the generator provide the best results \(elu was ok, selu wasn't very good, swish was really bad\). Selu provides good results in the discriminator without any normalization \(at least it seemed better then relu and elu with normalization although the discriminator isn't all that deep at about 9 layers\). For normalization in the generator I'm currently using the pixel normalization described in the Progressive Growing of GANs paper although I don't like the concept of this and I'll probably switch back to standard batch normalization. Changing from normal convolutions to a series of dilated convolutions in the generator was a big improvement. I've tried other things here and there but I can't really recall them right now.

My current architecture looks like this:

[https://i.imgur.com/NXdajT4.png](https://i.imgur.com/NXdajT4.png)

The generator is composed of residual blocks, each with a series of dilated convolutions followed by a strided convolution to downscale. Feature maps are pulled from the end of each residual block, put through a 1x1 convolution to reduce the number of channels and then upscaled using nearest neighbor. All of these feature maps are then concatenated into a big block. This goes through a few more residual blocks to reduce the number of channels before a few transposed convolutions to upscale the image. The original input image is concatenated back in toward the end of the generator to help with training. The generator outputs a 4 channel image \(3 value texture map \+ 1 value height map\). These are used to create the terrain map as described above.

The discriminator works fairly similarly. The generated height and terrain maps are concatenated with the input image map and fed to the discriminator. The combined image block is passed through strided convolution layers to downscale. At regular intervals, feature maps are pulled out through a 1x1 convolution to collapse to a single feature map. These maps are upscaled back to 512x512 with nearest neighbor and concatenated. The mean value is calculated for each pixel \(this creates a great visualization to assess the discriminator during training\) and then the overall image mean is used for the loss function. L1 loss is also added to the loss function.

So I'm looking for any suggestions on what else I can try to help improve training stability. Links to papers or discussions are great, code samples are also really helpful. Let me know if you have any questions.",10,7
1436,2018-5-28,2018,5,28,10,8mmck3,Neural language representations predict outcomes of scientific research,https://www.reddit.com/r/MachineLearning/comments/8mmck3/neural_language_representations_predict_outcomes/,serghiou,1527470496,,1,1
1437,2018-5-28,2018,5,28,12,8mmz4c,TensorFlow latest release 1.8 is out. I made a crisp tutorial to Install its GPU version on Windows PC,https://www.reddit.com/r/MachineLearning/comments/8mmz4c/tensorflow_latest_release_18_is_out_i_made_a/,DecipherTechnic,1527476937,,0,1
1438,2018-5-28,2018,5,28,12,8mn36r,Machine learning.,https://www.reddit.com/r/MachineLearning/comments/8mn36r/machine_learning/,kesh13,1527478136,,0,1
1439,2018-5-28,2018,5,28,13,8mngyu,From Word to Financial Time Series Embedding,https://www.reddit.com/r/MachineLearning/comments/8mngyu/from_word_to_financial_time_series_embedding/,maximedb,1527482437,,0,1
1440,2018-5-28,2018,5,28,14,8mno37,Top 10 Machine Learning Algorithms You Should Know,https://www.reddit.com/r/MachineLearning/comments/8mno37/top_10_machine_learning_algorithms_you_should_know/,sansiazhar,1527484718,,0,1
1441,2018-5-28,2018,5,28,14,8mnr0v,[R] Adversarial examples from computational constraints,https://www.reddit.com/r/MachineLearning/comments/8mnr0v/r_adversarial_examples_from_computational/,tfluxxin,1527485658,,4,6
1442,2018-5-28,2018,5,28,14,8mnr44,Earning respect of people from other field with machine learning research,https://www.reddit.com/r/MachineLearning/comments/8mnr44/earning_respect_of_people_from_other_field_with/,tbraga14,1527485688,[removed],0,1
1443,2018-5-28,2018,5,28,16,8mo9t0,[N] Empiricism and the limits of gradient descent,https://www.reddit.com/r/MachineLearning/comments/8mo9t0/n_empiricism_and_the_limits_of_gradient_descent/,neondei,1527492093,,22,43
1444,2018-5-28,2018,5,28,16,8mob29,Machine learning to the rescue: Multi-model premium prediction for insurance companies,https://www.reddit.com/r/MachineLearning/comments/8mob29/machine_learning_to_the_rescue_multimodel_premium/,iammarksmith,1527492547,,0,1
1445,2018-5-28,2018,5,28,17,8moils,[D] Does (or can) machine learning produce mental representations?,https://www.reddit.com/r/MachineLearning/comments/8moils/d_does_or_can_machine_learning_produce_mental/,techczech,1527495395,,18,14
1446,2018-5-28,2018,5,28,17,8mol5l,What is the difference between Gated Graph Sequence Neural Networks and Graph Convolution Networks?,https://www.reddit.com/r/MachineLearning/comments/8mol5l/what_is_the_difference_between_gated_graph/,thilinicooray,1527496432,[removed],0,1
1447,2018-5-28,2018,5,28,17,8molwc,[D] How do i get stochastic behaviour when using Evolutionary Strategy ?!,https://www.reddit.com/r/MachineLearning/comments/8molwc/d_how_do_i_get_stochastic_behaviour_when_using/,temptempyahoo,1527496739,"I am reading the [**KARPATHY Evolutionary Strategies**](https://blog.openai.com/tag/andrej-karpathy/) post.

He explains that in ES the policy is non\-stochastic, giving a single action for each state \(unlike the common PG in DRL\).

This really bothers me because

a. I assumed stochastic\-ness is necessary during any training phase, to help to prioritize exploration. 

Am i wrong on this ? Is this all ""solved"" by random perturbations in the policy parameters ? 

b. i need some randomness in my final agent \(which is very easy when sampling a stochastic policy\). Can i still do ES with a stochastic policy ?",2,4
1448,2018-5-28,2018,5,28,17,8mom10,Should I do a MSc in AI at University of Amsterdam or continue with MOOCs and start competing on Kaggle / life advice required,https://www.reddit.com/r/MachineLearning/comments/8mom10/should_i_do_a_msc_in_ai_at_university_of/,P4pp3nh3im3r,1527496788,[removed],0,1
1449,2018-5-28,2018,5,28,17,8moo6c,"GitHub - locie/modelXplore: ModelXplore, a python based model exploration",https://www.reddit.com/r/MachineLearning/comments/8moo6c/github_lociemodelxplore_modelxplore_a_python/,Eryole,1527497658,,0,1
1450,2018-5-28,2018,5,28,18,8mowkr,5 Companies that Use Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8mowkr/5_companies_that_use_machine_learning/,bkmnsk,1527500831,,0,1
1451,2018-5-28,2018,5,28,18,8moyjt,Dynamic Time Warping in failure prediction ?,https://www.reddit.com/r/MachineLearning/comments/8moyjt/dynamic_time_warping_in_failure_prediction/,BruceSwain12,1527501576,[removed],0,1
1452,2018-5-28,2018,5,28,19,8mp3vw,My ct st 355mm Bosch GCO 200 cng sut: 2000W ng knh li ct l 355mm tc  khng ti 3500 vng/ pht,https://www.reddit.com/r/MachineLearning/comments/8mp3vw/my_ct_st_355mm_bosch_gco_200_cng_sut_2000w/,HangNguyen1111,1527503511,,0,1
1453,2018-5-28,2018,5,28,19,8mp534,Machine learning is like Javascript frameworks,https://www.reddit.com/r/MachineLearning/comments/8mp534/machine_learning_is_like_javascript_frameworks/,mahimas,1527503957,[removed],0,1
1454,2018-5-28,2018,5,28,20,8mpe7g,Best online sources to learn Machine learning and deep learning?,https://www.reddit.com/r/MachineLearning/comments/8mpe7g/best_online_sources_to_learn_machine_learning_and/,_abhishejha_,1527507055,[removed],0,1
1455,2018-5-28,2018,5,28,20,8mpfyf,"Reservoir computing, Lyapunov Times, Wolfram's 'computational irreducibility', &amp; chaos  r/cellular_automata (X-post from r/cellular_automata)",https://www.reddit.com/r/MachineLearning/comments/8mpfyf/reservoir_computing_lyapunov_times_wolframs/,birch_baltimore,1527507636,,1,1
1456,2018-5-28,2018,5,28,20,8mpi4c,Authors from 2 ICML-accepted papers agreed for a Q &amp; A on the platform we have built,https://www.reddit.com/r/MachineLearning/comments/8mpi4c/authors_from_2_icmlaccepted_papers_agreed_for_a_q/,leenz2,1527508347,[removed],0,1
1457,2018-5-28,2018,5,28,21,8mpk4n,Understanding cencept behind Expectation Maximization algorithm.,https://www.reddit.com/r/MachineLearning/comments/8mpk4n/understanding_cencept_behind_expectation/,FranekW,1527508967,[removed],0,1
1458,2018-5-28,2018,5,28,21,8mpphu,Sold Rice Roll Steamer Machine to Thailand,https://www.reddit.com/r/MachineLearning/comments/8mpphu/sold_rice_roll_steamer_machine_to_thailand/,lgsherry,1527510592,,1,1
1459,2018-5-28,2018,5,28,21,8mptcu,"Hyperbolic Attention Networks, Whistle to Music, Graph2Seq, Netflix Research, Intel NLP Tools,",https://www.reddit.com/r/MachineLearning/comments/8mptcu/hyperbolic_attention_networks_whistle_to_music/,omarsar,1527511748,,0,1
1460,2018-5-28,2018,5,28,22,8mpxmm,[D] What do we currently know about Generalization? What should we be asking next about it?,https://www.reddit.com/r/MachineLearning/comments/8mpxmm/d_what_do_we_currently_know_about_generalization/,evc123,1527512958,"Ever since [Understanding deep learning requires rethinking generalization] (https://arxiv.org/abs/1611.03530) was released, the ML communities knowledge about how/why/when generalization occurs has been in flux.

Many people have since tried to address the question of how/why/when generalization occurs (at least in the case of supervised learning generalizing to out-of-sample data), but no one has been able to answer the question without some caveats:
https://scholar.google.com/scholar?hl=en&amp;sciodt=0,5&amp;cites=4613672282544622621&amp;scipsc=&amp;q=&amp;scisbd=1

(Also, Ferenc provides some context about caveats of current attempts at explaining generalization:
-http://www.inference.vc/sharp-vs-flat-minima-are-still-a-mystery-to-me/
-http://www.inference.vc/pruning-neural-networks-two-recent-papers/
-http://www.inference.vc/generalization-and-the-fisher-rao-norm-2/
-http://www.inference.vc/everything-that-works-works-because-its-bayesian-2/
)

As a result, the questions Im trying to get any feedback on from r/ML are:
What do we currently know about Generalization?
What should we be asking next about it?

The reason Im asking these question is because there are still many scenarios where we struggle to achieve any generalization at all. The most notable scenarios are the inability of RL (&amp; many popular generative models) to achieve out-of-sample generalization; for example, see [A Study on Overfitting in Deep Reinforcement Learning] (https://arxiv.org/abs/1804.06893)
The more far-out scenarios are the attempts to get low-shot out-of-distribution metalearning to work. For example, see videos of out-of-distribution generalization on ant navigation tasks in the videos at the bottom of blog post on Evolved Policy Gradients:
https://blog.openai.com/evolved-policy-gradients/",68,166
1461,2018-5-28,2018,5,28,22,8mq1yz,Where to find downloadable plant/tree database?,https://www.reddit.com/r/MachineLearning/comments/8mq1yz/where_to_find_downloadable_planttree_database/,theboysxx,1527514174,[removed],0,1
1462,2018-5-28,2018,5,28,22,8mq5kk,Generic python MCTS library?,https://www.reddit.com/r/MachineLearning/comments/8mq5kk/generic_python_mcts_library/,Sanson87,1527515135,[removed],0,1
1463,2018-5-28,2018,5,28,23,8mqaqu,[R] Generic python MCTS library?,https://www.reddit.com/r/MachineLearning/comments/8mqaqu/r_generic_python_mcts_library/,Sanson87,1527516449,"Hello, 

Does anyone know a generic MCTS implementation in python that one can reuse for any kind of game? Ideally something that would include CPU parallelization would be great. All I found so far is this one: https://github.com/hildensia/mcts Did anyone try it with success? 

Thanks ",9,14
1464,2018-5-28,2018,5,28,23,8mqh2r,[D] Machine learning deployed in health care and the life science industry.,https://www.reddit.com/r/MachineLearning/comments/8mqh2r/d_machine_learning_deployed_in_health_care_and/,nianolca,1527517906,"Dear all,

I'm a researcher that has spend my last 10 years mainly in cancer research, mainly in developing new diagnostic/prognostic/predictive tools. I've applied shallow learning methods (SVMs, random forest, etc.) on everything from data from various blood tests,  classification of tumor cells from quantified microscopic images (for the latter, I've also made a few attempts with deep learning but typically find my data volumes to be too low). 

With FDA approving Arteryss diagnostic deep learning model for heart disease, I feel much of the skepticism towards ML in the life sciences may start to wither away. I also have a client that is interested in putting together a list of cases where ML approaches is furthest along. The retinopathy models are obvious examples, but if we go beyond academia and reseach-level experimentation - what ""production models"" are already deployed in the life science industry? What problems are being solved by ML today?

Feel free to speculate!",38,76
1465,2018-5-28,2018,5,28,23,8mqmod,Thoughts on my social evolution simulator idea?,https://www.reddit.com/r/MachineLearning/comments/8mqmod/thoughts_on_my_social_evolution_simulator_idea/,PlatinumNinja72,1527519218,,1,1
1466,2018-5-29,2018,5,29,0,8mqoqa,Machine Learning Mastery books,https://www.reddit.com/r/MachineLearning/comments/8mqoqa/machine_learning_mastery_books/,klaythompson111,1527519707,"Hey,

I'd like to buy books (in particular I'm interested in ""Introduction to Time Series Forecasting with Python"") from this site.

But 37$ is too expensive for me (I'm a student and I'm fine with spending &lt;= 10$ per a book).

Can anyone help me?",0,1
1467,2018-5-29,2018,5,29,0,8mqpxi,[Project] Thoughts on my social evolution simulator idea?,https://www.reddit.com/r/MachineLearning/comments/8mqpxi/project_thoughts_on_my_social_evolution_simulator/,PlatinumNinja72,1527519977,,12,8
1468,2018-5-29,2018,5,29,0,8mqu0j,"[WIP] Predict where people are looking at on a page with TensorFlow.js (requires a desktop, modern browser and webcam)",https://www.reddit.com/r/MachineLearning/comments/8mqu0j/wip_predict_where_people_are_looking_at_on_a_page/,cpury,1527520933,,1,1
1469,2018-5-29,2018,5,29,0,8mqu98,tensorflow implementation of federated learning,https://www.reddit.com/r/MachineLearning/comments/8mqu98/tensorflow_implementation_of_federated_learning/,mynameisvinn,1527520990,,0,1
1470,2018-5-29,2018,5,29,0,8mqywx,Best implementation of Mask RCNN? [P],https://www.reddit.com/r/MachineLearning/comments/8mqywx/best_implementation_of_mask_rcnn_p/,clifgray,1527522041,I'm using Mask RCNN for a project of mine using instance segmentation to detect and measure objects in satellite and drone imagery. I've got it working using both the Matterport version https://github.com/matterport/Mask_RCNN and the standard Tensorflow implementation https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/instance_segmentation.md but I'm curious which is better for a medium term project (probably a year of my PhD). The matterport version is much better documented but I have to imagine that the official TF implementation will be better maintained over the long run. Thoughts? Other implementations I should look into?,5,10
1471,2018-5-29,2018,5,29,0,8mr3b7,When does stanford update their cs231n and cs224n videos?,https://www.reddit.com/r/MachineLearning/comments/8mr3b7/when_does_stanford_update_their_cs231n_and_cs224n/,DerpTheKing,1527523058,I was wondering when stanford would upload the videos of the most recent sessions for CS231n and CS224n. Or is that even necessary because the 2017 videos contain the same information and are relevant?,0,1
1472,2018-5-29,2018,5,29,1,8mr4hm,[D] Is there a way for a neural network to model its own confidence in its prediction for a regression problem?,https://www.reddit.com/r/MachineLearning/comments/8mr4hm/d_is_there_a_way_for_a_neural_network_to_model/,Vallvaka,1527523314,"I have a neural network taking in 100 MLB baseball player plate appearances as a time series. Each sequence is paired with a single continuous number corresponding to the future OPS (a baseball statistic) over the following 100 plate appearance window. Essentially I'm using the plate appearance outcomes for a player to predict their future performance.

However, baseball is subject to a lot of random noise. A batter can go into a slump for no reason other than random chance, and future performance can vary significantly as well. If possible, I'd like the neural network to output its confidence in its performance prediction alongside the prediction itself.

Is there any documented way to do this? Currently, my output consists of a single number corresponding to its performance prediction, and I'm using squared error as my loss function. However this doesn't capture the network's confidence in its own prediction.

I thought about discretizing the output and using softmax over, say, a dozen or so buckets. However, softmax is TOO categorical for this purpose. If the NN says there is a 50% probability future performance falls within [0.5, 0.6), and 50% probability within [0.6, 0.7), but actual performance is 0.45, the loss from the [0.6, 0.7) bucket should be weighted higher than the loss from the [0.5, 0.6) bucket because that bucket is farther away. Softmax doesn't capture this and would treat every bucket equally.

Is there a loss function engineered for such a purpose?",32,12
1473,2018-5-29,2018,5,29,1,8mrb9b,Gradients in tensorflow clarification,https://www.reddit.com/r/MachineLearning/comments/8mrb9b/gradients_in_tensorflow_clarification/,surajhanchinal,1527524804,[removed],0,1
1474,2018-5-29,2018,5,29,2,8mrn8g,Elon Musk's AI based Pravda seems to go against everything he is afraid of. (sorry if this is the wrong place),https://www.reddit.com/r/MachineLearning/comments/8mrn8g/elon_musks_ai_based_pravda_seems_to_go_against/,heybabywannafunk,1527527386,[removed],0,1
1475,2018-5-29,2018,5,29,2,8mroko,Old but interesting paper on optimal size of neural net (MLP),https://www.reddit.com/r/MachineLearning/comments/8mroko/old_but_interesting_paper_on_optimal_size_of/,bbateman2011,1527527681,,0,1
1476,2018-5-29,2018,5,29,3,8ms8x4,[R] An A.I just made a language!,https://www.reddit.com/r/MachineLearning/comments/8ms8x4/r_an_ai_just_made_a_language/,orenog,1527532221,,0,1
1477,2018-5-29,2018,5,29,4,8msgt8,Alternative to SAS EM - Interactive Decision Tree,https://www.reddit.com/r/MachineLearning/comments/8msgt8/alternative_to_sas_em_interactive_decision_tree/,simfrep,1527534005,[removed],1,1
1478,2018-5-29,2018,5,29,4,8msi6e,Are machine learning hobbyist or professionals interested in profiting from their experiments?,https://www.reddit.com/r/MachineLearning/comments/8msi6e/are_machine_learning_hobbyist_or_professionals/,hdrgoncalves,1527534294,[removed],0,1
1479,2018-5-29,2018,5,29,4,8mskiu,Which is a better CPU for Machine Learning? Ryzen 5 1600 or the Intel i5 8400 Coffee Lake,https://www.reddit.com/r/MachineLearning/comments/8mskiu/which_is_a_better_cpu_for_machine_learning_ryzen/,iamneverme,1527534799,"I understand that the Ryzen is especially good for heavy application usage like multi tasking etc. and usually with applications that utilise multiple cores and threads. 

The intel on the other hand does really really well with games, but looses in almost all other tasks like video rendering, multi tasking, 3D modelling etc. 

I found the above info from [this](https://youtu.be/4fd_GXFBUtk) video.

So, I am trying to build a PC, mainly for ML/DL &amp; occasional gaming \( Dota 2, PUBG, Hearthstone, RocketLeague  etc. \). Which processor would be good paired with a 1070ti founder's edition GPU?",0,1
1480,2018-5-29,2018,5,29,4,8msmye,Torch to tfjs,https://www.reddit.com/r/MachineLearning/comments/8msmye/torch_to_tfjs/,Kevin_Clever,1527535364,[removed],0,1
1481,2018-5-29,2018,5,29,5,8mswz2,"[D] ""To consult someone after an experiment is finished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of.""",https://www.reddit.com/r/MachineLearning/comments/8mswz2/d_to_consult_someone_after_an_experiment_is/,wordboyhere,1527537692,- Ronald Fisher,0,1
1482,2018-5-29,2018,5,29,5,8mt5w0,Why does my margin shift when adding extra data to a linear SVM classification.,https://www.reddit.com/r/MachineLearning/comments/8mt5w0/why_does_my_margin_shift_when_adding_extra_data/,antonthehuge,1527539698,[removed],0,1
1483,2018-5-29,2018,5,29,5,8mt61t,How to do image downsampling correctly?,https://www.reddit.com/r/MachineLearning/comments/8mt61t/how_to_do_image_downsampling_correctly/,soulslicer0,1527539745,[removed],0,1
1484,2018-5-29,2018,5,29,6,8mtmft,How could the Government use machine learning to detect tax noncompliance?,https://www.reddit.com/r/MachineLearning/comments/8mtmft/how_could_the_government_use_machine_learning_to/,Hazza385,1527543562,[removed],0,1
1485,2018-5-29,2018,5,29,7,8mu38w,[D] What should I mind while choosing a CPU for a personal machine learning machine?,https://www.reddit.com/r/MachineLearning/comments/8mu38w/d_what_should_i_mind_while_choosing_a_cpu_for_a/,NegroBauBau,1527547568,"I've been reading lots of apparently contradictory advice here and there so I decided to open this thread to help me sort things out.

This is not a professional setup or meant for competitions. It's just a computer designed to help me on my learning process, but at the same time I'd expect it to be capable of a little bit more than just solving toy problems. 

I've seen people say that CPU is used just for preprocessing, so you can just go with a cheap i5 and then it won't be a bottleneck for whatever your 1080 Ti is capable of doing.

This is all nice to hear because I'm on a budget, but at the same time I've seen people say that anything less than an i7 will not be acceptable. 

I've also seen people tell me to take the Ryzen route but I don't feel very encouraged by the compatibility issues, so right now I'm basically between an i5 or an i7.

So should I go for an i7 or should I go for an i5 and rather spend that extra money on RAM? That's basically the question.


",9,0
1486,2018-5-29,2018,5,29,8,8mu8h2,"[D] Why you need to improve your training data, and how to do it: how much training set quality matters to model performance, and ways to bootstrap a corpus",https://www.reddit.com/r/MachineLearning/comments/8mu8h2/d_why_you_need_to_improve_your_training_data_and/,gwern,1527548883,,17,172
1487,2018-5-29,2018,5,29,9,8muouf,[D] optimally switching between local and Bayesian optimization,https://www.reddit.com/r/MachineLearning/comments/8muouf/d_optimally_switching_between_local_and_bayesian/,_alphamaximus_,1527553052,,0,1
1488,2018-5-29,2018,5,29,9,8muupw,"[N] Andrew Ng, Lior Pachter &amp; Gary Marcus Twitter Joust on AI Radiology",https://www.reddit.com/r/MachineLearning/comments/8muupw/n_andrew_ng_lior_pachter_gary_marcus_twitter/,gwen0927,1527554598,,0,1
1489,2018-5-29,2018,5,29,9,8muxg6,"Reinforcement Learning) Why do we need Model in Dyna? (Chapter 8, Sutton and Barto)",https://www.reddit.com/r/MachineLearning/comments/8muxg6/reinforcement_learning_why_do_we_need_model_in/,rightx2,1527555304,[removed],0,1
1490,2018-5-29,2018,5,29,9,8muyj6,[R] Towards a Theoretical Understanding of Batch Normalization,https://www.reddit.com/r/MachineLearning/comments/8muyj6/r_towards_a_theoretical_understanding_of_batch/,xternalz,1527555592,,14,30
1491,2018-5-29,2018,5,29,11,8mvo71,Automatic Vegetable And Fruit Date Washing Machine,https://www.reddit.com/r/MachineLearning/comments/8mvo71/automatic_vegetable_and_fruit_date_washing_machine/,lgsherry,1527562094,,1,1
1492,2018-5-29,2018,5,29,12,8mvtr4,Conditional Probability Explained with Python and Pregnancy Test,https://www.reddit.com/r/MachineLearning/comments/8mvtr4/conditional_probability_explained_with_python_and/,tonnamb,1527563557,,0,1
1493,2018-5-29,2018,5,29,12,8mvz8e,Memory Augmented Self-Play,https://www.reddit.com/r/MachineLearning/comments/8mvz8e/memory_augmented_selfplay/,[deleted],1527564918,[deleted],1,1
1494,2018-5-29,2018,5,29,12,8mw01j,[R] Memory Augmented Self Play,https://www.reddit.com/r/MachineLearning/comments/8mw01j/r_memory_augmented_self_play/,shagunsodhani,1527565131,,2,6
1495,2018-5-29,2018,5,29,12,8mw2gp,Thoughts on CNN implementation on Sign language dataset?,https://www.reddit.com/r/MachineLearning/comments/8mw2gp/thoughts_on_cnn_implementation_on_sign_language/,cronoz30,1527565784,[removed],0,1
1496,2018-5-29,2018,5,29,15,8mwv00,Best Auto Repair Services in Conyers GA,https://www.reddit.com/r/MachineLearning/comments/8mwv00/best_auto_repair_services_in_conyers_ga/,5starrautorepair,1527574598,,0,1
1497,2018-5-29,2018,5,29,15,8mwvvm,tensorflow and keras,https://www.reddit.com/r/MachineLearning/comments/8mwvvm/tensorflow_and_keras/,uchihabloodline,1527574870,[removed],0,1
1498,2018-5-29,2018,5,29,15,8mwwi6,How do I debug an RL algorithm?,https://www.reddit.com/r/MachineLearning/comments/8mwwi6/how_do_i_debug_an_rl_algorithm/,beautifulgraphs,1527575086,[removed],0,1
1499,2018-5-29,2018,5,29,17,8mxhoo,Detect and classify multiple instances of the multiple objects in an image,https://www.reddit.com/r/MachineLearning/comments/8mxhoo/detect_and_classify_multiple_instances_of_the/,tectonicpie,1527582576,[removed],0,1
1500,2018-5-29,2018,5,29,17,8mxi74,[R] DeepProbLog: Neural Probabilistic Logic Programming,https://www.reddit.com/r/MachineLearning/comments/8mxi74/r_deepproblog_neural_probabilistic_logic/,HEmile,1527582780,,1,6
1501,2018-5-29,2018,5,29,17,8mxidq,[R] Entropy and mutual information in models of deep neural networks,https://www.reddit.com/r/MachineLearning/comments/8mxidq/r_entropy_and_mutual_information_in_models_of/,ipu0034,1527582856,,3,41
1502,2018-5-29,2018,5,29,17,8mxkem,Typical Machine Learning interview questions with answers,https://www.reddit.com/r/MachineLearning/comments/8mxkem/typical_machine_learning_interview_questions_with/,TomekB,1527583673,,0,1
1503,2018-5-29,2018,5,29,18,8mxra6,looking to talk/connect with researchers/companies who are interested in helping AI understand human behavior.,https://www.reddit.com/r/MachineLearning/comments/8mxra6/looking_to_talkconnect_with_researcherscompanies/,data_driven_approach,1527586208,[removed],0,1
1504,2018-5-29,2018,5,29,18,8mxrd3,What's hot in data science interviews in 2018?,https://www.reddit.com/r/MachineLearning/comments/8mxrd3/whats_hot_in_data_science_interviews_in_2018/,all_goodnamesaregone,1527586234,[removed],0,1
1505,2018-5-29,2018,5,29,18,8mxse6,OptiSol Datalab - AI &amp; ML based process automation illustrations,https://www.reddit.com/r/MachineLearning/comments/8mxse6/optisol_datalab_ai_ml_based_process_automation/,optisol,1527586583,,0,1
1506,2018-5-29,2018,5,29,18,8mxsvk,[R] A brief overview of Automatic Machine Learning solutions (AutoML),https://www.reddit.com/r/MachineLearning/comments/8mxsvk/r_a_brief_overview_of_automatic_machine_learning/,polllyyy,1527586758,,0,1
1507,2018-5-29,2018,5,29,18,8mxv58,[D] Deep Neural Networks in geology and mining industry,https://www.reddit.com/r/MachineLearning/comments/8mxv58/d_deep_neural_networks_in_geology_and_mining/,Ordinary_investor,1527587584,"Greetings Machine learning community!

First of all, please accept my apology if this post goes somehow against the rules of this community.

I would really appreciate your input in the following matter.

**Few quick words about me:** By profession i am actually geologist, working in a large \(mid cap market cap\) energy and oil company. Although geologist by profession, my work consists of working with data, CAD software, geological and mine simulation modelling etc. I am a big fan of machine learning and find the whole field very fascinating. To make it clear, I know almost nothing compared to actual scientists in this field, I suppose you could consider me just a huge fan. Nevertheless I still realise many opportunities this research field has to offer.

I work in my companies research and development department, which is also the reason I thought your community could perhaps give your insight and perhaps also offer some suggestions or direct me to some interesting research papers on this matter.

**The reason I am writing:** As any other industry, over the years we collect \(and store\) increasing amount of data, from:

* The very ground itself \(quality/quantity of deposit\) \&gt;\&gt;\&gt;
* Mining equipment and operations \(operating machine loggers, electricity, finance etc\) \&gt;\&gt;\&gt;
* Logistics/transportation of deposit \(Trucks that constantly log information, conveyor belts, draglines etc\) \&gt;\&gt;\&gt;
* Storage \&gt;\&gt;\&gt;
* Electricity/oil production \(new plants log a lot of different kind of information, we have both electricity and oil plants\) \&gt;\&gt;\&gt;
* Transportation/transmission of goods \(electricity grids, road logistics etc\) \&gt;\&gt;\&gt;
* Financials

As you can imagine, the field has rather different industries involved, all combining into one long string of operations. My company is very supportive of advanced technologies, research and development and if it results in even small fraction of optimisation of the work, then it quite often results in significant financial gains, due to sizeable monthly production capacities.

My main interest would concentrate first at the first stage of string of operations, which would be deposit, mining, logistics into the storage, at first, with an intention later to combine it into further string of operations. Small bite at a time so to say. I am very interested as to what potential/optimisation/bottle necks deep neural network could propose.

I believe both supervised and unsupervised learning algorithms have great potential to increase and optimise production efficiency.

**1\)** ***Could community members perhaps indicate into some promising/interesting academic/research studies on the subjects described above?***

**2\)** ***Also, if you could possibly offer any insight in this matter, some subjective opinions, suggestions, ideas, I would really appreciate this very much.***

***Thank you very much in advance for your time!***",17,10
1508,2018-5-29,2018,5,29,18,8mxvb3,[P] APS Database Project,https://www.reddit.com/r/MachineLearning/comments/8mxvb3/p_aps_database_project/,dearpetra,1527587632,,0,1
1509,2018-5-29,2018,5,29,18,8mxw3e,"[N] Oracle compra DataScience.com, una plataforma de machine learning",https://www.reddit.com/r/MachineLearning/comments/8mxw3e/n_oracle_compra_datasciencecom_una_plataforma_de/,digitalson,1527587915,,0,1
1510,2018-5-29,2018,5,29,19,8mxxlc,[N] Intuition of Gradient Descent for Machine Learning  Abdullah Al Imran,https://www.reddit.com/r/MachineLearning/comments/8mxxlc/n_intuition_of_gradient_descent_for_machine/,janemoz,1527588414,,0,1
1511,2018-5-29,2018,5,29,19,8mxz49,[R] A Platform Strategy Wont Work Unless Youre Good at Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8mxz49/r_a_platform_strategy_wont_work_unless_youre_good/,rennytech,1527588878,,2,0
1512,2018-5-29,2018,5,29,19,8mxzsk,[D] What is the best CI/CD pipeline tool for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8mxzsk/d_what_is_the_best_cicd_pipeline_tool_for_machine/,pm3310,1527589113,"Questions:

\- What is the best tech stack to build a CI/CD pipeline for ML? Or, is there anything off\-the\-shelf out there?

\- Do you perform tests on ML models? I call it model tests. Example: make sure that the precision never drops below 96&amp;#37;

Benefits \(from my perspective\)

\- No more manual deployment of ML models

\- Avoid ""it works on my workstation"" situations

\- Increase visibility of ML models to engineering/product teams

\- New Data Scientists will be on\-boarded on existing ML projects quicker and easier",22,22
1513,2018-5-29,2018,5,29,19,8my3i6,Tensorflow Tutorial - Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8my3i6/tensorflow_tutorial_deep_learning/,pooja307,1527590325,,0,1
1514,2018-5-29,2018,5,29,19,8my41p,[R] Centered Weight Normalization in Accelerating Training of Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8my41p/r_centered_weight_normalization_in_accelerating/,abstractcontrol,1527590487,,1,10
1515,2018-5-29,2018,5,29,20,8myerq,My football result predictor is predicting too well,https://www.reddit.com/r/MachineLearning/comments/8myerq/my_football_result_predictor_is_predicting_too/,UserWithComputer,1527593894,[removed],0,1
1516,2018-5-29,2018,5,29,21,8mykbr,[N] Introducing arxiv-sanity,https://www.reddit.com/r/MachineLearning/comments/8mykbr/n_introducing_arxivsanity/,oneona,1527595570,,0,0
1517,2018-5-29,2018,5,29,21,8mylka,Automatic Ethiopian Injera Making Machine,https://www.reddit.com/r/MachineLearning/comments/8mylka/automatic_ethiopian_injera_making_machine/,lgsherry,1527595923,,1,1
1518,2018-5-29,2018,5,29,21,8mypnu,[R] Learning Self-Imitating Diverse Policies,https://www.reddit.com/r/MachineLearning/comments/8mypnu/r_learning_selfimitating_diverse_policies/,hardfork48,1527597075,,0,2
1519,2018-5-29,2018,5,29,21,8myq5z,[Discussion] What are some must-read ML papers for newcomers wanting to advance in the field?,https://www.reddit.com/r/MachineLearning/comments/8myq5z/discussion_what_are_some_mustread_ml_papers_for/,the-data-scientist,1527597206,E.g. classic results and famous landmark papers. Especially interested in neural nets and deep learning. Thanks,18,70
1520,2018-5-29,2018,5,29,22,8myykz,Automatic Plantain Chips Making Machine,https://www.reddit.com/r/MachineLearning/comments/8myykz/automatic_plantain_chips_making_machine/,lgsherry,1527599393,,1,1
1521,2018-5-29,2018,5,29,22,8mz135,Slack group for experienced Machine Learning practitioners,https://www.reddit.com/r/MachineLearning/comments/8mz135/slack_group_for_experienced_machine_learning/,ControlMyRobot,1527599987,[removed],0,1
1522,2018-5-29,2018,5,29,22,8mz5cg,Facebook advances computer vision using hashtagged pictures | ZDNet,https://www.reddit.com/r/MachineLearning/comments/8mz5cg/facebook_advances_computer_vision_using/,NinaMJ,1527601015,,6,3
1523,2018-5-29,2018,5,29,22,8mz5xp,Less is More: Unified Model for Unsupervised Multi-Domain Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/8mz5xp/less_is_more_unified_model_for_unsupervised/,xiaoliu95,1527601160,[removed],0,1
1524,2018-5-29,2018,5,29,22,8mz6dc,LEATHER Classification: detecting OBVIOUS and SUBTLE graphic features using computer vision,https://www.reddit.com/r/MachineLearning/comments/8mz6dc/leather_classification_detecting_obvious_and/,romalocuta,1527601257,[removed],0,0
1525,2018-5-29,2018,5,29,22,8mz8gj,[R] Less is More: Unified Model for Unsupervised Multi-Domain Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/8mz8gj/r_less_is_more_unified_model_for_unsupervised/,xiaoliu95,1527601766,,6,48
1526,2018-5-29,2018,5,29,22,8mzag2,The Significance of Poisson Distribution in Statistics | Hashtag Statistics,https://www.reddit.com/r/MachineLearning/comments/8mzag2/the_significance_of_poisson_distribution_in/,LearningFromData,1527602265,,0,2
1527,2018-5-29,2018,5,29,23,8mzb6o,Any Machine Learning success stories without graduate degrees?,https://www.reddit.com/r/MachineLearning/comments/8mzb6o/any_machine_learning_success_stories_without/,zindarod,1527602430,[removed],0,1
1528,2018-5-29,2018,5,29,23,8mzfmk,[D] Current SOTA in attention-based document classification?,https://www.reddit.com/r/MachineLearning/comments/8mzfmk/d_current_sota_in_attentionbased_document/,skepticforest,1527603438,I'm currently using a hierarchical attention network for my task but I wanted to know if there was something better and more intuitive ,3,10
1529,2018-5-29,2018,5,29,23,8mzipv,How to add basic AI to your app with the Algorithmia API (screencast),https://www.reddit.com/r/MachineLearning/comments/8mzipv/how_to_add_basic_ai_to_your_app_with_the/,mrborgen86,1527604145,,0,1
1530,2018-5-30,2018,5,30,0,8n00h1,PyTorch-YOLOv3: Minimal implementation of YOLOv3 in PyTorch,https://www.reddit.com/r/MachineLearning/comments/8n00h1/pytorchyolov3_minimal_implementation_of_yolov3_in/,Eriklindernoren,1527607983,,0,1
1531,2018-5-30,2018,5,30,0,8n02e2,[P] Visualize and track learning online (update),https://www.reddit.com/r/MachineLearning/comments/8n02e2/p_visualize_and_track_learning_online_update/,iovdin,1527608381,,6,3
1532,2018-5-30,2018,5,30,0,8n0374,[D][xpost]Why thousands of AI researchers are boycotting the new Nature journal - Academics share machine-learning research freely. Taxpayers should not have to pay twice to read our findings,https://www.reddit.com/r/MachineLearning/comments/8n0374/dxpostwhy_thousands_of_ai_researchers_are/,mugbrushteeth,1527608548,,0,1
1533,2018-5-30,2018,5,30,0,8n03is,Automate License Plate Recognition in 3 Simple Steps,https://www.reddit.com/r/MachineLearning/comments/8n03is/automate_license_plate_recognition_in_3_simple/,TopBrokenheartedness,1527608614,,0,1
1534,2018-5-30,2018,5,30,0,8n0462,[P] PyTorch-YOLOv3: Minimal implementation of YOLOv3 in PyTorch,https://www.reddit.com/r/MachineLearning/comments/8n0462/p_pytorchyolov3_minimal_implementation_of_yolov3/,Eriklindernoren,1527608758,,0,1
1535,2018-5-30,2018,5,30,0,8n04gu,[P] PyTorch-YOLOv3: Minimal implementation of YOLOv3 in PyTorch,https://www.reddit.com/r/MachineLearning/comments/8n04gu/p_pytorchyolov3_minimal_implementation_of_yolov3/,Eriklindernoren,1527608819,,3,3
1536,2018-5-30,2018,5,30,0,8n04hp,[P] Realtime multihand pose estimation demo,https://www.reddit.com/r/MachineLearning/comments/8n04hp/p_realtime_multihand_pose_estimation_demo/,alexeykurov,1527608824,,144,1691
1537,2018-5-30,2018,5,30,0,8n05oi,'crypto' R Package on CRAN - Historical cryptocurrency market data for all digital currencies,https://www.reddit.com/r/MachineLearning/comments/8n05oi/crypto_r_package_on_cran_historical/,venturaxi,1527609083,,0,1
1538,2018-5-30,2018,5,30,0,8n07wr,where can I download Pre-trained model,https://www.reddit.com/r/MachineLearning/comments/8n07wr/where_can_i_download_pretrained_model/,sdk_solution,1527609547,[removed],0,1
1539,2018-5-30,2018,5,30,1,8n0c6q,Math for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8n0c6q/math_for_machine_learning/,sethwilsonUS,1527610450,[removed],0,1
1540,2018-5-30,2018,5,30,1,8n0ckz,Context-Aware Neural Machine Translation Learns Anaphora Resolution,https://www.reddit.com/r/MachineLearning/comments/8n0ckz/contextaware_neural_machine_translation_learns/,abhizeus,1527610528,[removed],0,1
1541,2018-5-30,2018,5,30,1,8n0epi,"George Hotz, legendary hacker is live programming a simultaneous localization and mapping in python3 from scratch.",https://www.reddit.com/r/MachineLearning/comments/8n0epi/george_hotz_legendary_hacker_is_live_programming/,anon35201,1527610983,[removed],0,1
1542,2018-5-30,2018,5,30,1,8n0fv9,How can I train?,https://www.reddit.com/r/MachineLearning/comments/8n0fv9/how_can_i_train/,sdhawal2k8,1527611211,[removed],0,1
1543,2018-5-30,2018,5,30,2,8n0qdu,[D] A short and simple explanation of LSTM,https://www.reddit.com/r/MachineLearning/comments/8n0qdu/d_a_short_and_simple_explanation_of_lstm/,jaleyhd,1527613407,,0,3
1544,2018-5-30,2018,5,30,2,8n0rle,[D] Could we use a genetic algorithm to find a euler cycle?,https://www.reddit.com/r/MachineLearning/comments/8n0rle/d_could_we_use_a_genetic_algorithm_to_find_a/,DataJenius,1527613639,"Would it be possible to use a genetic algorithm to solve a euler's cycle via graph theory? If so, how would you approach the issue of ""mutation""?

Here is an example of the problem:

https://imgur.com/QJB2yzs

Given the constraints of graph theory, how would you define the ""DNA"" of the experiment? How would the ""mutation"" function work?

",2,1
1545,2018-5-30,2018,5,30,2,8n0rx3,"Man against machine: diagnostic performance of a DL CNN for melanoma recognition in comparison to 58 dermatologists...""Computer learns to detect skin cancer more accurately than doctors (95% compared to 86.6%)""",https://www.reddit.com/r/MachineLearning/comments/8n0rx3/man_against_machine_diagnostic_performance_of_a/,sugarhilldt2,1527613705,,0,1
1546,2018-5-30,2018,5,30,2,8n0sbb,"[D] Man against machine: diagnostic performance of a DL CNN for melanoma recognition in comparison to 58 dermatologists, ""(95% compared to 86.6%)""",https://www.reddit.com/r/MachineLearning/comments/8n0sbb/d_man_against_machine_diagnostic_performance_of_a/,sugarhilldt2,1527613783,,2,8
1547,2018-5-30,2018,5,30,2,8n11mp,Advice for learning Maths related to formal analysis of neural networks,https://www.reddit.com/r/MachineLearning/comments/8n11mp/advice_for_learning_maths_related_to_formal/,with_no_grad,1527615717,[removed],0,1
1548,2018-5-30,2018,5,30,2,8n12h3,[R][1805.10766] Improving the Resolution of CNN Feature Maps Efficiently with Multisampling,https://www.reddit.com/r/MachineLearning/comments/8n12h3/r180510766_improving_the_resolution_of_cnn/,sssgggg4,1527615889,,4,14
1549,2018-5-30,2018,5,30,2,8n14nw,[D] Advice for learning Maths related to formal analysis of neural networks,https://www.reddit.com/r/MachineLearning/comments/8n14nw/d_advice_for_learning_maths_related_to_formal/,with_no_grad,1527616349,"I just started reading papers about robustness guarantees of neural networks for adversarial examples and I'm finding that I need to improve my math skills.

To give a specific example, [Analysis of classifiers' robustness to adversarial perturbations](https://arxiv.org/abs/1502.02590) proves an upper bound on robustness of classifiers to adversarial perturbations. I found the proof very easy to follow but I don't think I have enough practice/experience to prove the result myself.

I have studied basic probability and probabilistic graphical models. I also did an undergrad course for linear algebra (same as syllabus as [Gilbert's Strang linear algebra course](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/)) and a graduate level course for convex optimization (same syllabus as [this course](http://www.stat.cmu.edu/~ryantibs/convexopt/)).

Any tips on how I should continue? I am specifically looking for problem sets which I can solve to become better at this type of proofs/analysis.",1,3
1550,2018-5-30,2018,5,30,3,8n19bf,[D] Detecting region of interest in documents using deep learning?.,https://www.reddit.com/r/MachineLearning/comments/8n19bf/d_detecting_region_of_interest_in_documents_using/,youngChange,1527617292,"Basically, I have scanned documents in which the regions of interest are either circled, or ticked and was wondering if I could segment this circled text using YOLO?. I have many such images, and thus training data is not an issue.",10,3
1551,2018-5-30,2018,5,30,3,8n1dye,Principled AI with Probabilistic Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8n1dye/principled_ai_with_probabilistic_machine_learning/,Emaasit,1527618248,,0,1
1552,2018-5-30,2018,5,30,3,8n1e0q,Can AI be free of bias?,https://www.reddit.com/r/MachineLearning/comments/8n1e0q/can_ai_be_free_of_bias/,andrewturnerrr,1527618260,,0,1
1553,2018-5-30,2018,5,30,3,8n1m44,[P] How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8n1m44/p_how_to_create_natural_language_semantic_search/,benfred,1527619937,,0,6
1554,2018-5-30,2018,5,30,4,8n1qvu,[P]Learning to Listen: Neural Networks Application for Recognizing Speech,https://www.reddit.com/r/MachineLearning/comments/8n1qvu/plearning_to_listen_neural_networks_application/,CuttingWithScissors,1527620930,,0,1
1555,2018-5-30,2018,5,30,4,8n1u5e,Imbalanced dataset sampler,https://www.reddit.com/r/MachineLearning/comments/8n1u5e/imbalanced_dataset_sampler/,ufoym,1527621604,,0,1
1556,2018-5-30,2018,5,30,4,8n1vzh,[D] How concerned should we be about this patent that was granted to Google in March?,https://www.reddit.com/r/MachineLearning/comments/8n1vzh/d_how_concerned_should_we_be_about_this_patent/,culstrup,1527621986,"In March of this year \(2018\), the USPTO granted Google LLC [Patent US9911069B1](https://patents.google.com/patent/US9911069B1/en): ""**Processing images using deep neural networks.**"" The patent has a priority date of August 29, 2014, which, if I understand how IP law works \(caveat: I am not an IP lawyer\), means that its claims apply from that date forward.

Claims include:

&gt;A method comprising: receiving data characterizing an input image; processing the data characterizing the input image using a deep neural network to generate an alternative representation of the input image, wherein the deep neural network comprises a plurality of subnetworks, wherein the subnetworks are arranged in a sequence from lowest to highest, and wherein processing the data characterizing the input image using the deep neural network comprises processing the data through each of the subnetworks in the sequence, wherein the plurality of subnetworks comprise a plurality of module subnetworks, and wherein each of the module subnetworks is configured to:receive a preceding output representation generated by a preceding subnetwork in the sequence; process the preceding output representation through each layer of a first group of neural network layers to generate a first group output, the first group comprising a 11 convolutional layer followed by a 33 convolutional layer; and generate an output representation for the module subnetwork from the first group output; and processing the alternative representation of the input image through an output layer to generate an output from the input image.

This claim and the other claims on the patent seems to refer to a specific CNN architecture; however, it is unclear to me whether they could be applied to systems or inventions that use CNNs for computer vision outside of that strictly\-defined architecture.

Any IP SMEs care to chime in? Should we be concerned that Google is patenting CNN architectures in the first place \(let alone the fact that the USPTO is willing to grant them\)?",13,19
1557,2018-5-30,2018,5,30,4,8n1zvi,Why thousands of AI researchers are boycotting the new Nature journal - Academics share machine-learning research freely. Taxpayers should not have to pay twice to read our findings (X-post: r/technology),https://www.reddit.com/r/MachineLearning/comments/8n1zvi/why_thousands_of_ai_researchers_are_boycotting/,RockJake28,1527622779,,0,1
1558,2018-5-30,2018,5,30,4,8n230n,Zero-overhead Scalable Machine Learning with Studio.ML,https://www.reddit.com/r/MachineLearning/comments/8n230n/zerooverhead_scalable_machine_learning_with/,andrewturnerrr,1527623380,,0,1
1559,2018-5-30,2018,5,30,6,8n2r76,A2C don't understand the process,https://www.reddit.com/r/MachineLearning/comments/8n2r76/a2c_dont_understand_the_process/,cranthir_,1527628295,[removed],0,1
1560,2018-5-30,2018,5,30,6,8n2rir,[D] A2C don't understand the process,https://www.reddit.com/r/MachineLearning/comments/8n2rir/d_a2c_dont_understand_the_process/,cranthir_,1527628368," Hello,

  
I'm currently trying to implement **an A2C agent** \(same as A3C but synchronous update instead of asynchronous\).  
[https://raw.githubusercontent.com/MG2033/A2C/master/figures/a3c\_vs\_a2c.png](https://raw.githubusercontent.com/MG2033/A2C/master/figures/a3c_vs_a2c.png)

  
So if I understood correctly, we create multiple agents, each agent is trained synchronously, each update is accumulated in a ""update collector"" \(update agent 1 \+ update agent 2 \+ ...\) and then the update of the global network is done by averaging the total. Then, we update each agents with the new set of weights of the global network then we do the process again. **Is that correct?**

  
But what I don't understand is that **in this very good implementation \(**[**https://github.com/MG2033/A2C/blob/master/main.py**](https://github.com/MG2033/A2C/blob/master/main.py)**\) \(because well commented\) where and how the synchronous multi threading is implemented ?**

  
Unfortunately I think we are in a moment where there is a lot of innovation in RL but not a lot of resources about Deep Reinforcement Learning. **We don't have sufficient amount of simple, lightweight, not fancy and commented code.**

  
Thanks for your help !",6,2
1561,2018-5-30,2018,5,30,6,8n2sim,[D] Representing output label for character level speech recognition using RNN,https://www.reddit.com/r/MachineLearning/comments/8n2sim/d_representing_output_label_for_character_level/,silencetalks,1527628581,"I saw this [tutorial on generating text using LSTM](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/). In this tutorial the author trained the newtwork by taking 100 previous characters as input and the next character as the output label.

I am interested to try some simple speech recognition using LSTM. I may use mfcc features of the audio signal as input data But what's confusing me most is how to represent the output label. 

The dataset I have is the VCTK corpus which contains sentence level audio recording and its transcription. 

In the tutorial, next character that comes after the input vector was used as output label. But for speech it's impractical to know which part of speech produced which character without transcribing the audio for every second. So, how would I represent the output labels for this problem?",1,2
1562,2018-5-30,2018,5,30,6,8n2tju,Doing linear regression the right way,https://www.reddit.com/r/MachineLearning/comments/8n2tju/doing_linear_regression_the_right_way/,Stelman,1527628807,,0,1
1563,2018-5-30,2018,5,30,6,8n2tn8,How to evaluate the quality of features?,https://www.reddit.com/r/MachineLearning/comments/8n2tn8/how_to_evaluate_the_quality_of_features/,arcxtriy,1527628827,[removed],0,1
1564,2018-5-30,2018,5,30,6,8n34fd,Using Twitter to predict Premier League outcomes,https://www.reddit.com/r/MachineLearning/comments/8n34fd/using_twitter_to_predict_premier_league_outcomes/,Stelman,1527631144,,0,1
1565,2018-5-30,2018,5,30,7,8n3edr,MURA Dataset by Stanford AI Lab: Towards Radiologist-Level Abnormality Detection in Musculoskeletal Radiographs,https://www.reddit.com/r/MachineLearning/comments/8n3edr/mura_dataset_by_stanford_ai_lab_towards/,serghiou,1527633322,,0,1
1566,2018-5-30,2018,5,30,7,8n3fqb,[D] Why thousands of AI researchers are boycotting the new Nature journal,https://www.reddit.com/r/MachineLearning/comments/8n3fqb/d_why_thousands_of_ai_researchers_are_boycotting/,ofirpress,1527633641,,36,116
1567,2018-5-30,2018,5,30,7,8n3kla,[P] Introducing Machine Learning Practica,https://www.reddit.com/r/MachineLearning/comments/8n3kla/p_introducing_machine_learning_practica/,baylearn,1527634768,,1,9
1568,2018-5-30,2018,5,30,8,8n3mx1,[D] Projects and blog posts with high impact,https://www.reddit.com/r/MachineLearning/comments/8n3mx1/d_projects_and_blog_posts_with_high_impact/,depretechybubble,1527635294,"I'm an undergraduate 3rd\-year studying ML and I have an upcoming research internship for the summer at a large and respected tech company. I am looking for side project ideas to pursue on the side \(outside of work\). My goal is to finish an impactful project, maybe like a blog post or open source contribution that demonstrates my coding expertise, and then in the fall, apply to AI residency programs and graduate programs. How should I choose an independent summer ML project that focuses on impact, evaluated by something like number of website views or number of stars on github? I guess my question is, what does it take for a blog post to be impactful for the community and meaningful enough for lots of people to be interested?",6,6
1569,2018-5-30,2018,5,30,8,8n3s57,Data collection service for images,https://www.reddit.com/r/MachineLearning/comments/8n3s57/data_collection_service_for_images/,marlonmisra,1527636553,"I'm looking for an image dataset of some common items found in homes. I've considered making postings on Craigslist for the data I need, but maybe there are companies that specialize in this? Thx. ",0,1
1570,2018-5-30,2018,5,30,8,8n3v0q,[P] Control Bootcamp Lectures,https://www.reddit.com/r/MachineLearning/comments/8n3v0q/p_control_bootcamp_lectures/,hardmaru,1527637252,,0,28
1571,2018-5-30,2018,5,30,9,8n4bv0,"How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)",https://www.reddit.com/r/MachineLearning/comments/8n4bv0/how_does_batch_normalization_help_optimization_no/,convolutional_potato,1527641380,,0,2
1572,2018-5-30,2018,5,30,9,8n4chc,[D] AI winter is well on its way,https://www.reddit.com/r/MachineLearning/comments/8n4chc/d_ai_winter_is_well_on_its_way/,wei_jok,1527641529,,17,0
1573,2018-5-30,2018,5,30,9,8n4e0i,"[R] How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)",https://www.reddit.com/r/MachineLearning/comments/8n4e0i/r_how_does_batch_normalization_help_optimization/,xternalz,1527641899,,1,11
1574,2018-5-30,2018,5,30,10,8n4eot,"[R] How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)",https://www.reddit.com/r/MachineLearning/comments/8n4eot/r_how_does_batch_normalization_help_optimization/,convolutional_potato,1527642067,,24,41
1575,2018-5-30,2018,5,30,10,8n4gp4,[R] Playing hard exploration games by watching YouTube (DeepMind),https://www.reddit.com/r/MachineLearning/comments/8n4gp4/r_playing_hard_exploration_games_by_watching/,wei_jok,1527642566,,5,38
1576,2018-5-30,2018,5,30,10,8n4lfy,[P] Google Landmark Retrieval Challenge (1st Place Writeup),https://www.reddit.com/r/MachineLearning/comments/8n4lfy/p_google_landmark_retrieval_challenge_1st_place/,inarrears,1527643752,,14,71
1577,2018-5-30,2018,5,30,10,8n4r4i,[D] Why non-linearities are not learned?,https://www.reddit.com/r/MachineLearning/comments/8n4r4i/d_why_nonlinearities_are_not_learned/,iovdin,1527645132,They are all fixed formula layers. But what if we learn a polynomial like nonlinearity? will it help?,12,7
1578,2018-5-30,2018,5,30,12,8n5igd,Efficient Neural Architecture Search for windows users and Description,https://www.reddit.com/r/MachineLearning/comments/8n5igd/efficient_neural_architecture_search_for_windows/,first287,1527652283,,0,1
1579,2018-5-30,2018,5,30,13,8n5lko,[P] Efficient Neural Architecture Search via Parameter sharing for windows users and Description,https://www.reddit.com/r/MachineLearning/comments/8n5lko/p_efficient_neural_architecture_search_via/,first287,1527653123,,0,7
1580,2018-5-30,2018,5,30,13,8n5tgs,Tetris Bot using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8n5tgs/tetris_bot_using_machine_learning/,Tinkers_Named_Ferro,1527655348,,0,1
1581,2018-5-30,2018,5,30,13,8n5tii,Machine Learning for Negotiation,https://www.reddit.com/r/MachineLearning/comments/8n5tii/machine_learning_for_negotiation/,ranatayyab777,1527655362,[removed],0,1
1582,2018-5-30,2018,5,30,14,8n6002,[Discussion] Has anyone used ML/NLP to automate code generation?,https://www.reddit.com/r/MachineLearning/comments/8n6002/discussion_has_anyone_used_mlnlp_to_automate_code/,tastingsilver,1527657342,"If so, what did you do and how did you approach it?

Asking because I've been working on a heavily object oriented library (sort of like Pytorch for a non-ML related application), and now that its nearing maturing in certain areas, I'd like to be able to automate some of its usage with deep learning.

Would be really curious to hear about anyone's experience in doing this.",6,7
1583,2018-5-30,2018,5,30,15,8n68k9,Clustering question,https://www.reddit.com/r/MachineLearning/comments/8n68k9/clustering_question/,SoSwSoSw,1527660126,[removed],0,1
1584,2018-5-30,2018,5,30,15,8n6asl,"""[D]"" Clustering related question",https://www.reddit.com/r/MachineLearning/comments/8n6asl/d_clustering_related_question/,SoSwSoSw,1527660847,"Hello, I'm currently doing my PhD in the field of reliability. My work is on the use of clustering and visualization to ease the problem statements in FMEA.

At the start of my PhD, my advisor presented me with a journal paper written by his master student. The journal was on the use of SOM and Evolving Tree in FMEA. In that particular paper, the use of SOM and ETree was applied to solve the two problem statements that i am currently doing. In short, he clustered then visualize.

My advisor suggested i work on the same problem statement. I looked through the choice of clustering methods and chose Mean Shift. I've also included cluster validity index as well. I'm hoping to work on the previous work and improve it by suggesting a better clustering method. I suggested the use of Mean Shift with a validity index before visualization commences. I was told to justify the use of mean shift over SOM/ETree in FMEA which i believe i did (literature wise).

I would like to ask whether this is an improvement over the current method (SOM/ETree)? My argument is that clustering have been accepted by reputable FMEA journals and if i'm able to improve on what was done in the past, it should be considered an improvement/contribution.

Please advice",4,3
1585,2018-5-30,2018,5,30,15,8n6dj7,Detergent Powder Making Business I Washing Powder Manufacturing Ashish Shori +91-9893427891,https://www.reddit.com/r/MachineLearning/comments/8n6dj7/detergent_powder_making_business_i_washing_powder/,ashishshori,1527661771,,0,1
1586,2018-5-30,2018,5,30,16,8n6kqz,Product Recommendation Engines for E-Commerce,https://www.reddit.com/r/MachineLearning/comments/8n6kqz/product_recommendation_engines_for_ecommerce/,Qwentic,1527664239,[removed],0,1
1587,2018-5-30,2018,5,30,17,8n6vgy,SIEMENS COMPONENT CAMERA P+P (TYP 22) 5040,https://www.reddit.com/r/MachineLearning/comments/8n6vgy/siemens_component_camera_pp_typ_22_5040/,digitalqysmt,1527668177,,0,1
1588,2018-5-30,2018,5,30,17,8n70pl,[D] Find distance between selled products,https://www.reddit.com/r/MachineLearning/comments/8n70pl/d_find_distance_between_selled_products/,bykof,1527670236,"Hi guys, 

i want to find distances between selled products.
Let's say I have Product A, Product B and Product C
And I have invoices where the invoice items are products which looks like this:

Product A|Product B|Product C|
:--|:--|:--|
1|1|0|
1|0|0|
1|1|1|
1|1|0|

I tried to cumulate the vectors to get something like this:

Product A = (1, 1, 0) + (1, 0, 0) + (1, 1, 1) + (1, 1, 0) = (4, 3, 1)
Product B = (1, 1, 0) + --------- + (1, 1, 1) + (1, 1, 0) = (3, 3, 1) # it overjumps the second vector because product b was not bought in the second invoice
Product C = --------- + --------- + (1, 1, 1) + --------- = (1, 1, 1)

With this information I want to calculate the euclidean distance.
But the effect I get is that the most bought products are most away from others, because the ""collect"" more points.

So my question is, how I can get distances between the products?
Should I maybe start at 1 and subtract 0.1 from the vector? 
What is your opinion. ",3,0
1589,2018-5-30,2018,5,30,18,8n7431,Top 5 AI-based Applications for Crime Prevention and Detection,https://www.reddit.com/r/MachineLearning/comments/8n7431/top_5_aibased_applications_for_crime_prevention/,dexlabanalytics,1527671470,,0,1
1590,2018-5-30,2018,5,30,19,8n7kgz,[N] Simplicity is the glory of expression  Interview with Jalaj Thanaki (EBook Giveaway),https://www.reddit.com/r/MachineLearning/comments/8n7kgz/n_simplicity_is_the_glory_of_expression_interview/,molode,1527677111,,0,1
1591,2018-5-30,2018,5,30,19,8n7mm0,[R] Automated Text Classification Using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8n7mm0/r_automated_text_classification_using_machine/,magneticono,1527677803,,0,1
1592,2018-5-30,2018,5,30,20,8n7w3u,Non negative matrix factorization for Blind Source separation,https://www.reddit.com/r/MachineLearning/comments/8n7w3u/non_negative_matrix_factorization_for_blind/,aatapatta,1527680635,[removed],0,1
1593,2018-5-30,2018,5,30,21,8n8028,[R] Approximating Real-Time Recurrent Learning with Random Kronecker Factors,https://www.reddit.com/r/MachineLearning/comments/8n8028/r_approximating_realtime_recurrent_learning_with/,asierm,1527681742,,0,21
1594,2018-5-30,2018,5,30,21,8n80jq,Found these BRAND NEW 2HD 1.44mb. Haven't seen these for DECADES,https://www.reddit.com/r/MachineLearning/comments/8n80jq/found_these_brand_new_2hd_144mb_havent_seen_these/,SmileyTweetteetee,1527681872,,0,1
1595,2018-5-30,2018,5,30,21,8n84o1,[N] 10 More Free Must-Read Books for Machine Learning and Data Science,https://www.reddit.com/r/MachineLearning/comments/8n84o1/n_10_more_free_mustread_books_for_machine/,dearpetra,1527682962,,0,1
1596,2018-5-30,2018,5,30,21,8n8ah4,[R] Prediction Intervals for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/8n8ah4/r_prediction_intervals_for_machine_learning/,jackblun,1527684476,,0,1
1597,2018-5-30,2018,5,30,21,8n8anj,Which is Better Predictive Analytics v/s Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8n8anj/which_is_better_predictive_analytics_vs_machine/,Stevey_28,1527684518,,0,1
1598,2018-5-30,2018,5,30,21,8n8aw7,[R] Machine Learning Kaggle Competition Part One: Getting Started,https://www.reddit.com/r/MachineLearning/comments/8n8aw7/r_machine_learning_kaggle_competition_part_one/,chris_shpak,1527684575,,0,1
1599,2018-5-30,2018,5,30,22,8n8g1m,Why AI Research Loves Pac-Man,https://www.reddit.com/r/MachineLearning/comments/8n8g1m/why_ai_research_loves_pacman/,sinshallah,1527685818,,0,1
1600,2018-5-30,2018,5,30,22,8n8j4m,Linux or Widows OS,https://www.reddit.com/r/MachineLearning/comments/8n8j4m/linux_or_widows_os/,BlackSky2129,1527686596,[removed],0,1
1601,2018-5-30,2018,5,30,23,8n8tmy,3000+ AI/machine learning companies sorted by Country and Application Area &amp; sign-up link for a weekly email digest of open positions in the companies.,https://www.reddit.com/r/MachineLearning/comments/8n8tmy/3000_aimachine_learning_companies_sorted_by/,otiain,1527689020,,0,1
1602,2018-5-30,2018,5,30,23,8n8y1q,3000+ AI/machine learning companies sorted by Country and Application Area,https://www.reddit.com/r/MachineLearning/comments/8n8y1q/3000_aimachine_learning_companies_sorted_by/,otiain,1527689946,,0,1
1603,2018-5-30,2018,5,30,23,8n90sa,Unbiased Online Recurrent Optimization,https://www.reddit.com/r/MachineLearning/comments/8n90sa/unbiased_online_recurrent_optimization/,phizaz,1527690549,,0,4
1604,2018-5-30,2018,5,30,23,8n91um,Machine Learning - Two outputs,https://www.reddit.com/r/MachineLearning/comments/8n91um/machine_learning_two_outputs/,EducationalFlower,1527690777,[removed],0,1
1605,2018-5-30,2018,5,30,23,8n92fs,Recurrent neural network with learnable attention span,https://www.reddit.com/r/MachineLearning/comments/8n92fs/recurrent_neural_network_with_learnable_attention/,jostmey,1527690906,,2,13
1606,2018-5-30,2018,5,30,23,8n96ry,Docker Image with CUDA 9.0 cuDNN 7.1.3 Tensorflow-GPU 1.7 Keras Python3 Jupyter,https://www.reddit.com/r/MachineLearning/comments/8n96ry/docker_image_with_cuda_90_cudnn_713_tensorflowgpu/,deejay217,1527691892,[removed],0,1
1607,2018-5-31,2018,5,31,0,8n9msf,Need help saving and loading Keras model,https://www.reddit.com/r/MachineLearning/comments/8n9msf/need_help_saving_and_loading_keras_model/,RunThread,1527695229,[removed],0,1
1608,2018-5-31,2018,5,31,0,8n9p7s,"Simple Questions Thread May 30, 2018",https://www.reddit.com/r/MachineLearning/comments/8n9p7s/simple_questions_thread_may_30_2018/,AutoModerator,1527695738,[removed],0,1
1609,2018-5-31,2018,5,31,1,8n9zsg,3000+ AI/machine learning companies sorted by Country and Application Area &amp; sign-up link for a weekly email digest of open positions in the companies.,https://www.reddit.com/r/MachineLearning/comments/8n9zsg/3000_aimachine_learning_companies_sorted_by/,otiain,1527697868,,0,1
1610,2018-5-31,2018,5,31,1,8na29r,Collective training of a neural network that can be used for hyper parameter tuning. Breaking the meta.,https://www.reddit.com/r/MachineLearning/comments/8na29r/collective_training_of_a_neural_network_that_can/,antonthehuge,1527698386,[removed],0,1
1611,2018-5-31,2018,5,31,1,8na3aq,Asus made a motherboard that supports up to 20 GPUs,https://www.reddit.com/r/MachineLearning/comments/8na3aq/asus_made_a_motherboard_that_supports_up_to_20/,ispeakdatruf,1527698598,,1,1
1612,2018-5-31,2018,5,31,1,8na6li,"[N] MXNet adds built-in ONNX support, Intel MKL-DNN and more with 1.2.0 release",https://www.reddit.com/r/MachineLearning/comments/8na6li/n_mxnet_adds_builtin_onnx_support_intel_mkldnn/,thomasdlt,1527699282,,0,72
1613,2018-5-31,2018,5,31,2,8nae0f,[D] Reinforcement learning measuring ground truth,https://www.reddit.com/r/MachineLearning/comments/8nae0f/d_reinforcement_learning_measuring_ground_truth/,chick3234,1527700753,"I have an rl system that is trying to model the action of an agent that acts as the ""ground truth"", however, that agent does not always make the best decisions. Is there a way to measure how good the ""ground truth"" decision in a case is according to the reward function that is set?",6,3
1614,2018-5-31,2018,5,31,4,8nbkwi,Is it possible to share my AWS EC2 with other people ? By other people I mean a whole class of about 20 or so.,https://www.reddit.com/r/MachineLearning/comments/8nbkwi/is_it_possible_to_share_my_aws_ec2_with_other/,steveWaltin,1527709441,[removed],0,1
1615,2018-5-31,2018,5,31,5,8nc2rk,Predicting route with gps coordinates,https://www.reddit.com/r/MachineLearning/comments/8nc2rk/predicting_route_with_gps_coordinates/,Z1vel,1527713087,[removed],0,1
1616,2018-5-31,2018,5,31,5,8nc4cn,Question on decomposing multiple time series using SSA (PCA in time): am I on the right track? (x-post from /r/Statistics),https://www.reddit.com/r/MachineLearning/comments/8nc4cn/question_on_decomposing_multiple_time_series/,Stereoisomer,1527713410,[removed],0,1
1617,2018-5-31,2018,5,31,6,8nc8bg,Need Help Distinguishing the Difference Between: Jupyter Notebook vs Splunk,https://www.reddit.com/r/MachineLearning/comments/8nc8bg/need_help_distinguishing_the_difference_between/,gmupatriot123,1527714225,"I was curious if I could get some help establishing the differences between the Splunk and Jupyter notebook. I say this because from the surface, they appear to be the same thing except Splunk is closed source and Jupyter notebook is open source. 

Thank you!",0,1
1618,2018-5-31,2018,5,31,7,8ncr7o,[D] The Real Scandal of AI: Awful Stock Photos,https://www.reddit.com/r/MachineLearning/comments/8ncr7o/d_the_real_scandal_of_ai_awful_stock_photos/,ageitgey,1527718308,,37,321
1619,2018-5-31,2018,5,31,7,8ncwmm,Looking for pretrained ultrasound models for medical image classification.,https://www.reddit.com/r/MachineLearning/comments/8ncwmm/looking_for_pretrained_ultrasound_models_for/,po-handz,1527719558,[removed],0,1
1620,2018-5-31,2018,5,31,7,8nd1so,[D] How a Pentagon Contract Became an Identity Crisis for Google,https://www.reddit.com/r/MachineLearning/comments/8nd1so/d_how_a_pentagon_contract_became_an_identity/,chisai_mikan,1527720797,,45,52
1621,2018-5-31,2018,5,31,7,8nd3f0,The Critical Steps to Effective Machine Learning Predictive Algorithms,https://www.reddit.com/r/MachineLearning/comments/8nd3f0/the_critical_steps_to_effective_machine_learning/,cmelendez2014,1527721177,,0,1
1622,2018-5-31,2018,5,31,8,8nd3uk,[R] A Neural Network Model that can Reason,https://www.reddit.com/r/MachineLearning/comments/8nd3uk/r_a_neural_network_model_that_can_reason/,Dreeseaw,1527721269,,3,57
1623,2018-5-31,2018,5,31,8,8nddef,[D] Comprehensive Introduction to Monte Carlo Methods,https://www.reddit.com/r/MachineLearning/comments/8nddef/d_comprehensive_introduction_to_monte_carlo/,OneRaynyDay,1527723644,,12,138
1624,2018-5-31,2018,5,31,8,8nde7v,Question about non deep-learning algorithms - Is there a reason to use them other than speed?,https://www.reddit.com/r/MachineLearning/comments/8nde7v/question_about_non_deeplearning_algorithms_is/,isthisathrowawaay,1527723859,"Trying to piece what I learned in class with what happens IRL.
For example, I've hard that LightGBM is used a ton in kaggle competitions. But, I don't quite understand what advantage it provides over a NN.
Over-fitting is something I've heard been thrown around, but isn't that what stuff like drop-out is for?",0,1
1625,2018-5-31,2018,5,31,8,8ndh46,Business processes infused with machine learning (with case studies),https://www.reddit.com/r/MachineLearning/comments/8ndh46/business_processes_infused_with_machine_learning/,meetjohnsong,1527724622,,0,1
1626,2018-5-31,2018,5,31,10,8ne6fp,Funny cartoon for Data Scientist,https://www.reddit.com/r/MachineLearning/comments/8ne6fp/funny_cartoon_for_data_scientist/,surana_80,1527731622,[removed],0,1
1627,2018-5-31,2018,5,31,11,8nehea,"Useful for ML? Typically, its expensive to setup a motherboard that supports more than 4 GPUs.",https://www.reddit.com/r/MachineLearning/comments/8nehea/useful_for_ml_typically_its_expensive_to_setup_a/,Deepblue129,1527734160,,0,1
1628,2018-5-31,2018,5,31,11,8nemoa,[D] It's been over 3 months since Facebook's Tensor Comprehensions was released. Has anyone here found it to effective when writing their own kernels?,https://www.reddit.com/r/MachineLearning/comments/8nemoa/d_its_been_over_3_months_since_facebooks_tensor/,abhishkk65,1527735313,"I know not everyone is writing custom CUDA kernels, but for those of you who do have you applied Tensor Comprehensions to it and have you seen noticeable speed improvements?

Do most improvements come from simple kernels or do ones exploiting the specific GPU hardware  and written by CUDA ""experts"" also see large improvements?

I'm just curious in practice what people's experience has been. Also, are there any other similar tools to help optimize kernels?",6,25
1629,2018-5-31,2018,5,31,13,8nfa53,Train machine translation and speech recognition models with Tensor Cores on Volta GPUs,https://www.reddit.com/r/MachineLearning/comments/8nfa53/train_machine_translation_and_speech_recognition/,gizcard,1527740388,,0,1
1630,2018-5-31,2018,5,31,13,8nfb06,A look back at Natures 2015 Deep Learning,https://www.reddit.com/r/MachineLearning/comments/8nfb06/a_look_back_at_natures_2015_deep_learning/,okaymaged,1527740588,,0,1
1631,2018-5-31,2018,5,31,13,8nfdqs,[P] Simple Tensorflow implementation of text summarization using seq2seq library.,https://www.reddit.com/r/MachineLearning/comments/8nfdqs/p_simple_tensorflow_implementation_of_text/,ganji1055,1527741228,,0,2
1632,2018-5-31,2018,5,31,13,8nfe0z,[R]Image-to-Markup Generation,https://www.reddit.com/r/MachineLearning/comments/8nfe0z/rimagetomarkup_generation/,undefdev,1527741291,,1,8
1633,2018-5-31,2018,5,31,13,8nfh4q,Chatbot Algorithms,https://www.reddit.com/r/MachineLearning/comments/8nfh4q/chatbot_algorithms/,omkarjc,1527742030,[removed],0,1
1634,2018-5-31,2018,5,31,14,8nfoo0,Help on Application of Reinforcement Learning to Games,https://www.reddit.com/r/MachineLearning/comments/8nfoo0/help_on_application_of_reinforcement_learning_to/,captainskrra,1527743686,[removed],0,1
1635,2018-5-31,2018,5,31,14,8nfs7i,AI job/research opportunities as undergrad,https://www.reddit.com/r/MachineLearning/comments/8nfs7i/ai_jobresearch_opportunities_as_undergrad/,karkibigyan,1527744418,[removed],0,1
1636,2018-5-31,2018,5,31,14,8ng1fs,Depthwise Seperable Convolution - MobileNet,https://www.reddit.com/r/MachineLearning/comments/8ng1fs/depthwise_seperable_convolution_mobilenet/,bluesky314,1527746337,[removed],0,1
1637,2018-5-31,2018,5,31,15,8ng1s8,Suggestions for introductory courses/books to get into Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8ng1s8/suggestions_for_introductory_coursesbooks_to_get/,DBZwitcher,1527746440,[removed],0,1
1638,2018-5-31,2018,5,31,15,8ng4c8,Any Latest Research paper following Neural Turing Machine?,https://www.reddit.com/r/MachineLearning/comments/8ng4c8/any_latest_research_paper_following_neural_turing/,JackieLoong,1527747242,"The great idea of differentiable turing machine has been proposed in 2014 and it seems no too much following research.

Anyone know the latest research about NTM?",0,1
1639,2018-5-31,2018,5,31,15,8ngalw,[R] Neural Joking Machine : Humorous image captioning,https://www.reddit.com/r/MachineLearning/comments/8ngalw/r_neural_joking_machine_humorous_image_captioning/,inarrears,1527749403,,9,21
1640,2018-5-31,2018,5,31,16,8ngefp,Which one to go deeper with? Computer vision or NLP?,https://www.reddit.com/r/MachineLearning/comments/8ngefp/which_one_to_go_deeper_with_computer_vision_or_nlp/,deepmaniyar,1527750708,[removed],0,1
1641,2018-5-31,2018,5,31,16,8ngfqd,Samples consistence for a Decision Tree,https://www.reddit.com/r/MachineLearning/comments/8ngfqd/samples_consistence_for_a_decision_tree/,RubioRick,1527751116,[removed],0,1
1642,2018-5-31,2018,5,31,17,8ngtey,Are we close to machines solving ICPC problems? - Codeforces,https://www.reddit.com/r/MachineLearning/comments/8ngtey/are_we_close_to_machines_solving_icpc_problems/,matib275,1527756061,,0,1
1643,2018-5-31,2018,5,31,18,8ngxg9,Perforation machine manufacturer,https://www.reddit.com/r/MachineLearning/comments/8ngxg9/perforation_machine_manufacturer/,habmkloganjt,1527757584,,0,1
1644,2018-5-31,2018,5,31,18,8nh3i4,Simplistic Computer vision app for Android written in Kotlin powered by Tensorflow.,https://www.reddit.com/r/MachineLearning/comments/8nh3i4/simplistic_computer_vision_app_for_android/,TheOSM,1527759681,,0,1
1645,2018-5-31,2018,5,31,19,8nhddd,Logistic regression on a perfectly classified dataset using platt calibration,https://www.reddit.com/r/MachineLearning/comments/8nhddd/logistic_regression_on_a_perfectly_classified/,nitinsiwach,1527763090,[removed],0,1
1646,2018-5-31,2018,5,31,20,8nhjme,"[N] Weekly Machine Learning Opensource Roundup  May 31, 2018",https://www.reddit.com/r/MachineLearning/comments/8nhjme/n_weekly_machine_learning_opensource_roundup_may/,stkim1,1527765017,,0,1
1647,2018-5-31,2018,5,31,20,8nhqf9,[N] But what is this machine learning engineer actually doing?,https://www.reddit.com/r/MachineLearning/comments/8nhqf9/n_but_what_is_this_machine_learning_engineer/,digitalson,1527766980,,0,1
1648,2018-5-31,2018,5,31,20,8nhtxd,Follow me in robotics using deep learning,https://www.reddit.com/r/MachineLearning/comments/8nhtxd/follow_me_in_robotics_using_deep_learning/,brunoedccsantos,1527767997,,0,1
1649,2018-5-31,2018,5,31,21,8nhww5,No one likes unhappy customers except for your competitors.,https://www.reddit.com/r/MachineLearning/comments/8nhww5/no_one_likes_unhappy_customers_except_for_your/,getengati,1527768758,[removed],0,1
1650,2018-5-31,2018,5,31,21,8nhznp,[R] Machine Learning and Machine Reasoning for Data Analysis: The Differences You Need to Know,https://www.reddit.com/r/MachineLearning/comments/8nhznp/r_machine_learning_and_machine_reasoning_for_data/,janemoz,1527769494,,0,1
1651,2018-5-31,2018,5,31,21,8ni54s,You would definitely benefit by learning Machine Learning | Machine Learning Tutorial | IQ Online Training,https://www.reddit.com/r/MachineLearning/comments/8ni54s/you_would_definitely_benefit_by_learning_machine/,charlie2140,1527770952,,0,1
1652,2018-5-31,2018,5,31,21,8ni7jd,[R] Zero-Shot Dual Machine Translation,https://www.reddit.com/r/MachineLearning/comments/8ni7jd/r_zeroshot_dual_machine_translation/,lsesto,1527771572,,0,11
1653,2018-5-31,2018,5,31,22,8niiop,Suggestions needed to start Machine Learning and Deep Learning.,https://www.reddit.com/r/MachineLearning/comments/8niiop/suggestions_needed_to_start_machine_learning_and/,shashwatchandra,1527774279,[removed],0,1
1654,2018-5-31,2018,5,31,23,8nio7i,[D] List of ways business' could use Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/8nio7i/d_list_of_ways_business_could_use_machine_learning/,LasekApps,1527775544,"I recently got really interested in Machine Learning and want to grab an overall concept on how a business would use Machine Leaning (I mean all types, Banks, Coffee Shops, Clothing Stores, Construction etc) to generate revenue. 

In what scenarios would they use this? I know its beneficial like detecting fraud and such but I mean what about other companies/industries. 

Also, lets say you developed a simple machine learning program. How would you go about it to monetize it? Let a company use it? or sell it to a company? ",3,0
1655,2018-5-31,2018,5,31,23,8niyvt,Wanna join my team on Q-Learning trading? ReadMe,https://www.reddit.com/r/MachineLearning/comments/8niyvt/wanna_join_my_team_on_qlearning_trading_readme/,Jandevries101,1527777882,[removed],0,1
