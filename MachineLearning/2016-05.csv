,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2016-5-1,2016,5,1,9,4h6xjs,Neural Networks Demystified (Intro video series),https://www.reddit.com/r/MachineLearning/comments/4h6xjs/neural_networks_demystified_intro_video_series/,elisee,1462061949,,23,96
1,2016-5-1,2016,5,1,9,4h6z5o,Thoughts on future Ai (Economy &amp; Jobs),https://www.reddit.com/r/MachineLearning/comments/4h6z5o/thoughts_on_future_ai_economy_jobs/,jorellano13,1462062656,"Hi Everyone, 

If you are on this thread, then you are what I believe are the people who see the future of Machine Learning (Ai) is coming fast upon us.The majority of the world I don't think is worried about it or don't care enough to see the greater implications of automation. 

I am happy that robots will help us, but what will the people who lose their jobs do when taxi services like Uber fully Automate their fleets? This applies to every sector, whether it is the textile industry &amp; 3d printing, any industry requiring human labor. will be automated and make more efficient, like an Amazon Warehouse. 

I am not too worried, I am the evil-guy programming robots bots to do the automating. But what does everyone else think? Are you ready to live in the future yet? Or do you think like the Horse &amp; buggy unions and choose to postpone the future of Ai by slowing it down via regulation?

",12,0
2,2016-5-1,2016,5,1,17,4h8c7w,Problems installing OpenAI gym on Mac,https://www.reddit.com/r/MachineLearning/comments/4h8c7w/problems_installing_openai_gym_on_mac/,[deleted],1462092037,[removed],0,1
3,2016-5-1,2016,5,1,17,4h8cvf,Orchestrations of Beethoven's Ode to Joy using styles from other songs,https://www.reddit.com/r/MachineLearning/comments/4h8cvf/orchestrations_of_beethovens_ode_to_joy_using/,MasterScrat,1462092589,,9,48
4,2016-5-1,2016,5,1,17,4h8cwb,Newbie to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/4h8cwb/newbie_to_machine_learning/,mlsar,1462092608,[removed],0,1
5,2016-5-1,2016,5,1,18,4h8dyi,Best book to learn Machine Learning and Data Science ?,https://www.reddit.com/r/MachineLearning/comments/4h8dyi/best_book_to_learn_machine_learning_and_data/,positv,1462093533,[removed],0,1
6,2016-5-1,2016,5,1,18,4h8emt,Where to start?,https://www.reddit.com/r/MachineLearning/comments/4h8emt/where_to_start/,tehtacolord,1462094072,[removed],1,0
7,2016-5-1,2016,5,1,19,4h8iby,I am learning advanced machine learning and would to build a machine learning library in python.Please help.,https://www.reddit.com/r/MachineLearning/comments/4h8iby/i_am_learning_advanced_machine_learning_and_would/,rohanpota,1462097167,"Need some resources like books,blogs etc. Like something on the lines of scikit learn.I just want build an ml lib to dig deeper into ml.Not trying ""reinvent the wheel""

Background about me:Have read Elements of statistical learning,Bishop ml and pattern recog,all of statistics larry wasserman,completed udacity nanodegree,cs229 and tom mitchell's online course on ml which was the most hardcore one.So I can pretty much write many algos down but want to implement as one complete package such scikit-learn.",8,0
8,2016-5-1,2016,5,1,19,4h8iv6,Chc nng v li ch iu ha cm bin Econavi,https://www.reddit.com/r/MachineLearning/comments/4h8iv6/chc_nng_v_li_ch_iu_ha_cm_bin_econavi/,vietquanit1988,1462097588,,0,0
9,2016-5-1,2016,5,1,22,4h93gh,Any multi-core ML library? (Python),https://www.reddit.com/r/MachineLearning/comments/4h93gh/any_multicore_ml_library_python/,gooeyn,1462110728,"Scikit learning is great for testing and learning but my company is shipping a project to production and we needed a multi-core SVM implementation, and I just can't find it!


Does anybody knows about a multi-core ML library? 

It's better if it's open source but paid libraries would do too
Preferably in Python but any language would be great

Thanks",5,0
10,2016-5-1,2016,5,1,23,4h96hm,Review of Game 5 of the Artificial Intelligence Match of the 21st Century: AlphaGo unfamiliar with common tesuji in ultimate moyo game,https://www.reddit.com/r/MachineLearning/comments/4h96hm/review_of_game_5_of_the_artificial_intelligence/,DeepLearningBob,1462112009,,1,11
11,2016-5-1,2016,5,1,23,4h99j4,When to expect having CUDA 7.5 supported on Ubuntu 16.04?,https://www.reddit.com/r/MachineLearning/comments/4h99j4/when_to_expect_having_cuda_75_supported_on_ubuntu/,koormoosh,1462113204,"At the moment the latest Ubuntu version supported by CUDA is 15.04, see [1]. Are there any news on when Ubuntu 16.04 will be supported, or is there a way around this to install Cuda 7.5 on 16.04 [no working solutions found].

[1] https://developer.nvidia.com/cuda-downloads",11,0
12,2016-5-2,2016,5,2,0,4h9n3o,"heavy equipment accidents caught on tape, concrete mixer truck accident,...",https://www.reddit.com/r/MachineLearning/comments/4h9n3o/heavy_equipment_accidents_caught_on_tape_concrete/,richardoros,1462117869,,0,1
13,2016-5-2,2016,5,2,1,4h9t35,Deep Q-learning applied to the board-game hex.,https://www.reddit.com/r/MachineLearning/comments/4h9t35/deep_qlearning_applied_to_the_boardgame_hex/,[deleted],1462119800,[removed],0,1
14,2016-5-2,2016,5,2,2,4ha1bh,Revealed: Google AI has access to huge haul of NHS patient data,https://www.reddit.com/r/MachineLearning/comments/4ha1bh/revealed_google_ai_has_access_to_huge_haul_of_nhs/,votadini_,1462122265,,0,0
15,2016-5-2,2016,5,2,2,4ha4si,Seq2Seq Guide (Chatbots and Machine Translation),https://www.reddit.com/r/MachineLearning/comments/4ha4si/seq2seq_guide_chatbots_and_machine_translation/,Jxieeducation,1462123262,,5,11
16,2016-5-2,2016,5,2,2,4ha54d,Twitter sentiment analysis? Available classified dataset for supervised learning?,https://www.reddit.com/r/MachineLearning/comments/4ha54d/twitter_sentiment_analysis_available_classified/,moronotron,1462123386,"Hey,

I want to play around with twitter sentiment analysis and my main hesitation is on obtaining a dataset that's been classified for supervised learning. Do you know if a decent one exists already, or would I have to create one myself (or use mechical turk)?

Thanks!",6,1
17,2016-5-2,2016,5,2,2,4ha9vs,Time Series package in Python?,https://www.reddit.com/r/MachineLearning/comments/4ha9vs/time_series_package_in_python/,coffeecoffeecoffeee,1462124683,"I love Python for predictive modeling and machine learning.  Notably, I like that virtually everything related to those things is in one package, scikit-learn.  If I want to do anything, it's probably in that package.

Meanwhile, there is a huge dearth of time series support.  Statsmodels has statsmodels.tsa, which is decent, but it isn't production ready.  It also doesn't allow you to incorporate important things like transfer functions, building ARCH and GARCH models, building nonlinear or multivariate time series or wavelets, or do anything outside of building basic ARIMA models.  It only recently got support for incorporating seasonality, but can't incorporate multiple seasonal patterns.  I find that if I want to do time series analysis in Python, I have to package hunt like I do in R.

Is there a comprehensive, production-ready time series package available in Python?  And if not, is someone working on one?  With Pandas's amazing built-in datetime support, it would be great if someone did.",29,53
18,2016-5-2,2016,5,2,2,4haa4e,"Is there a public available code and pre-trained model for some paper using CNN for semantic segmentation? (Theano,Torch,Tensorflow,mxnet,neon)",https://www.reddit.com/r/MachineLearning/comments/4haa4e/is_there_a_public_available_code_and_pretrained/,code2hell,1462124745,,6,10
19,2016-5-2,2016,5,2,3,4hadir,Amazon Mechanical Turk a new way for building complex Machine Learning datasets,https://www.reddit.com/r/MachineLearning/comments/4hadir/amazon_mechanical_turk_a_new_way_for_building/,[deleted],1462125711,[deleted],3,0
20,2016-5-2,2016,5,2,3,4haeq8,Machine Learning for Recommender Systems: A Beginners Guide [only 12$],https://www.reddit.com/r/MachineLearning/comments/4haeq8/machine_learning_for_recommender_systems_a/,techudemy,1462126031,,1,1
21,2016-5-2,2016,5,2,5,4hb983,Prof. Hinton's comments at the Stanford seminar,https://www.reddit.com/r/MachineLearning/comments/4hb983/prof_hintons_comments_at_the_stanford_seminar/,[deleted],1462133850,[removed],0,1
22,2016-5-2,2016,5,2,6,4hbui4,Datasets on Africa,https://www.reddit.com/r/MachineLearning/comments/4hbui4/datasets_on_africa/,curiousime,1462139475,"Where are best places/sources to get datasets on Africa, particularly Nigeria and Kenya.",1,0
23,2016-5-2,2016,5,2,7,4hc2pu,Extreme Style Machines: Using Random Neural Networks to Generate Textures,https://www.reddit.com/r/MachineLearning/comments/4hc2pu/extreme_style_machines_using_random_neural/,beneuro,1462141524,,23,147
24,2016-5-2,2016,5,2,7,4hc8m3,[1604.07097] Neurohex: A Deep Q-learning Hex Agent,https://www.reddit.com/r/MachineLearning/comments/4hc8m3/160407097_neurohex_a_deep_qlearning_hex_agent/,kenjyoung,1462143107,,1,4
25,2016-5-2,2016,5,2,8,4hchp6,Question about tensorflow word2vec implementation,https://www.reddit.com/r/MachineLearning/comments/4hchp6/question_about_tensorflow_word2vec_implementation/,word2vec123,1462145473,[removed],0,1
26,2016-5-2,2016,5,2,8,4hcike,What are the longest-running examples of network training that you know about?,https://www.reddit.com/r/MachineLearning/comments/4hcike/what_are_the_longestrunning_examples_of_network/,arunciblespoon,1462145718,"In last year's paper by Hinton et al on ""[Distilling the Knowledge in a Neural Network](http://www.cs.toronto.edu/~hinton/absps/distillation.pdf)"", the authors described what they referred to as the ""JFT dataset"" as follows (page 5):

&gt; JFT is an internal Google dataset that has 100 million labeled images with 15,000 labels. When we did this work, Google's baseline model for JFT was a deep convolutional neural network that had been *trained for about six months* using asynchronous stochastic gradient descent on a large number of cores.

Aside from AlphaGo, which was also trained over many months, what are some other examples of such long-running training exercises for neural networks, and what problems are those networks intended to solve?",5,0
27,2016-5-2,2016,5,2,8,4hcm3g,Is Machine Learning an Artificial Intelligence or Computational Intelligence subfield?,https://www.reddit.com/r/MachineLearning/comments/4hcm3g/is_machine_learning_an_artificial_intelligence_or/,fariax,1462146715,"I have some experience in Neural Networks and some others simple algorithms of Machine Learning.

What I understand:

- CI are bio-inspired algorithms like Neural Networks (brain), Particle Swarm Optimization (birds), Fish School Search (fish), Simulated Annealing (energy in physical systems), Genetic Algorithms (evolution), etc

- AI solve complex problems using algorithms that not necessarily are bio-inspired, like: KNN, A*, SVM, etc

Then I have some philosophical questions for you:

1. KNN is CI or AI? Why?
2. Neural Networks is CI or AI? Why?
3. Machine Learning is CI, AI or both? Why?",5,0
28,2016-5-2,2016,5,2,10,4hd2py,How useful is Real Analysis for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/4hd2py/how_useful_is_real_analysis_for_machine_learning/,JohnyWalkerRed,1462151192,I am beginning graduate studies in ML and was wondering if any of you have taken a course in Real Analysis and if it helped you in any way in understanding/applying ML. ,8,2
29,2016-5-2,2016,5,2,12,4he22v,"Looking for recommendation of text on Bayesian approaches to time-series, signal processing, anomaly detection",https://www.reddit.com/r/MachineLearning/comments/4he22v/looking_for_recommendation_of_text_on_bayesian/,djc1000,1462160720,"I'm looking for a recommendation for a good (e-?)book on Bayesian approaches to time-series analysis, signal processing, and anomaly detection.  Something with BUGS or JAGS or (best of all) STAN code examples would be greatly appreciated.  

Thanks much!",1,1
30,2016-5-2,2016,5,2,14,4hekdw,Is there too much hype?,https://www.reddit.com/r/MachineLearning/comments/4hekdw/is_there_too_much_hype/,[deleted],1462166154,[deleted],0,0
31,2016-5-2,2016,5,2,15,4heyvn,Understanding and fighting bullying with machine learning,https://www.reddit.com/r/MachineLearning/comments/4heyvn/understanding_and_fighting_bullying_with_machine/,TangerineX,1462170732,,1,2
32,2016-5-2,2016,5,2,17,4hfift,Deep Learning Humor,https://www.reddit.com/r/MachineLearning/comments/4hfift/deep_learning_humor/,gokstudio,1462177356,,4,2
33,2016-5-2,2016,5,2,17,4hfjtw,Hola: Identify real English Words with 64KB JS,https://www.reddit.com/r/MachineLearning/comments/4hfjtw/hola_identify_real_english_words_with_64kb_js/,ddofer,1462177830,,3,0
34,2016-5-2,2016,5,2,17,4hfjy4,Attributed graph datasets,https://www.reddit.com/r/MachineLearning/comments/4hfjy4/attributed_graph_datasets/,BornToBeBi,1462177893,"Are you aware of any graph datasets such that nodes have (preferably numeric) attributes? Most node-attributed graph datasets have binary/categorical attributes.

For example I am aware of http://liris.cnrs.fr/~mplantev/doku/doku.php?id=data_sets where:
Nodes: authors
Edges: co-authorship
Attributes: Number of publications in selected journals

I've been looking for something along the lines of a sensor network data but have trouble finding anything worthwhile. 
",1,0
35,2016-5-2,2016,5,2,18,4hfrnx,Using libFM MCMC -- what should test file be?,https://www.reddit.com/r/MachineLearning/comments/4hfrnx/using_libfm_mcmc_what_should_test_file_be/,[deleted],1462180520,[deleted],0,0
36,2016-5-2,2016,5,2,18,4hfsmb,Is there a Machine Learning Experiment Framework? (Python),https://www.reddit.com/r/MachineLearning/comments/4hfsmb/is_there_a_machine_learning_experiment_framework/,gorilla64,1462180807,"I was wondering if there is some sort of framework for machine learning to sumup and maybe visualize experimental results from a ML model. 
I always have this issue that when I train a model. I print the results to the terminal or a file and save some plots ect. I see several people have this issue. I was thinking about building a some sort of framework to save my result in a structured format and then use this to generate a results overview page, to look at the results and compare different models ect. Probably in a IPython Notebook or even a small web app.

Maybe there already is some solution to this. Do you know about any such project that solves my issue or helps me get started?",6,3
37,2016-5-2,2016,5,2,19,4hg5xv,[1604.08610] Artistic Style Transfer for Videos,https://www.reddit.com/r/MachineLearning/comments/4hg5xv/160408610_artistic_style_transfer_for_videos/,ajmooch,1462185144,,5,71
38,2016-5-2,2016,5,2,20,4hghtg,[Q] Playing around with recurrent neural networks,https://www.reddit.com/r/MachineLearning/comments/4hghtg/q_playing_around_with_recurrent_neural_networks/,TamisAchilles,1462188913,"So I'm playing around with RNN's for the first time. Although I have read lots of theory about RNN's, up to now I hadn't found a excuse to apply RNN's. 

I must say I find it rather easy to get going, I do however have one question. I'm training my RNN on fixed sized windowed sequences, yet I apply my RNN on arbitrary length sequences. And I initiate the hidden state when training on a window to zero.

I understand that the length of the training sequence limits the longterm dependencies that can be learned by the RNN, but I'm also wondering if there are any other negative consequences associated with using a fixed sized sequence window I am not aware of?",1,0
39,2016-5-2,2016,5,2,20,4hgim3,Keras Neural Networks to Win NVIDIA Titan X,https://www.reddit.com/r/MachineLearning/comments/4hgim3/keras_neural_networks_to_win_nvidia_titan_x/,abhisvnit,1462189155,,0,1
40,2016-5-2,2016,5,2,21,4hgqys,What do you think about using lazy properties to structure TensorFlow models? [x-post /r/tensorflow],https://www.reddit.com/r/MachineLearning/comments/4hgqys/what_do_you_think_about_using_lazy_properties_to/,danijar,1462191472,,3,3
41,2016-5-2,2016,5,2,21,4hgva1,What's the best way to read papers to prepare yourself for research?,https://www.reddit.com/r/MachineLearning/comments/4hgva1/whats_the_best_way_to_read_papers_to_prepare/,FourthHead,1462192646,"I just finished my first course (fairly rigorous and comprehensive) in machine learning and would like to write a research paper. I'm only an undergrad, so I've never written one before, nor do I have the familiarity with the field to be able to publish.

I thought a good way to address both these problems would be to read research papers for several months before I try my hand at a problem.

I was hoping for some advice for going about this; would the ideal way be to just sort arXiv by new and read anything that catches my interest? I've heard about Google Scholar but the results seem to be a lot broader and unfocused.

I have a solid understanding of the basics of a large chunk of the subfields in machine learning (neural networks, graphical models, Baysesian learning, inference algorithms, etc.) but haven't worked enough with them for my specific interests to be fleshed out. ",12,15
42,2016-5-2,2016,5,2,22,4hh2qv,ICLR-2016 Live Stream,https://www.reddit.com/r/MachineLearning/comments/4hh2qv/iclr2016_live_stream/,XalosXandrez,1462194517,,3,7
43,2016-5-2,2016,5,2,22,4hh3yb,Help regarding RNN using Keras,https://www.reddit.com/r/MachineLearning/comments/4hh3yb/help_regarding_rnn_using_keras/,Ran9om,1462194808,"Hi all, I am a newbie and got interested in RNN's. I have started working with Keras and am trying the [lstm_text_generation](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py) example. But the problem is that it is very slow. It took more than a day for it to begin with the second iteration. It would be great if anyone could help. My goal is to generate music (as a pet project). Just getting my hands dirty now.

- Should I try with another example which might be faster than text generation?
- Also, is there any other faster implementation of python based text generation example?

Thanks in advance!

Edit: What's with the downvotes? Is this the wrong subreddit to post this?",13,0
44,2016-5-3,2016,5,3,0,4hhvrh,ICLR live stream,https://www.reddit.com/r/MachineLearning/comments/4hhvrh/iclr_live_stream/,iclr2016,1462201626,,0,1
45,2016-5-3,2016,5,3,0,4hhzzp,How to test your lm and rpart models [R],https://www.reddit.com/r/MachineLearning/comments/4hhzzp/how_to_test_your_lm_and_rpart_models_r/,jeekiii,1462202881,"Hi, I'm very lost in my data analysis course, We had to do several models and test them, the knn model was very easy to test, but I've no idea how to test these models.",1,0
46,2016-5-3,2016,5,3,0,4hi5nb,"I am learning Python, need introduction books in Machine Learning for finance.",https://www.reddit.com/r/MachineLearning/comments/4hi5nb/i_am_learning_python_need_introduction_books_in/,[deleted],1462204120,[deleted],1,0
47,2016-5-3,2016,5,3,1,4hicc1,Pretrained NN for audio?,https://www.reddit.com/r/MachineLearning/comments/4hicc1/pretrained_nn_for_audio/,rgoliax,1462205585,Where can I find pretrained NN for audio channel? Like those for images on caffe model zoo.,3,4
48,2016-5-3,2016,5,3,1,4hif47,What happens when an RNN makes your startup commercial for you?,https://www.reddit.com/r/MachineLearning/comments/4hif47/what_happens_when_an_rnn_makes_your_startup/,joshdotai,1462206211,,0,0
49,2016-5-3,2016,5,3,1,4higl7,/r/MachineLearning hits 60K subscribers,https://www.reddit.com/r/MachineLearning/comments/4higl7/rmachinelearning_hits_60k_subscribers/,TrendingBot,1462206700,,19,30
50,2016-5-3,2016,5,3,1,4higx2,Your First ML App - Machine Learning for Hackers #1,https://www.reddit.com/r/MachineLearning/comments/4higx2/your_first_ml_app_machine_learning_for_hackers_1/,llSourcell,1462206810,,8,0
51,2016-5-3,2016,5,3,1,4hiibu,CPU/chipset for ML workstation,https://www.reddit.com/r/MachineLearning/comments/4hiibu/cpuchipset_for_ml_workstation/,spurious_recollectio,1462207300,"I'm thinking of building a new workstation for a variety of different ML tasks I do but I'm trying to do it on a budget.  I do some deep learning but also a fair amount of memory intensive data processing (parsing wikipedia, DB stuff, etc...) so I want to build something with at least 64 gb ram (plus room to grow to  ~128) as well as fast M2 disks.  I already have a 980 Ti I'll put in it and I will probably buy another one later.  I'd like to try to keep the cost of CPU + ram + mobotherboard + M2 drives to ~1500.   From what I can see the lower end X99 motherboards (e.g. X99-PRO) and haswell e (5820k) might make this possible (mobo and cpu ~300-400 each) but on various other threads I've seen recommendations for much more expensive components like the X99-E WS and 5930k (each over 500).

So I was wondering whether there was a good reason to prefer the higher end components.  Also, how does skylake compare or is it better to get a haswell-e because it supports more PCI-e lanes (for both the GPU and the M2)?

My apologies for not having researched this more before asking the question...

**EDIT:** 
to forestall many alternative suggestions please note that for budget reasons I'm pretty much limited to a consummer system (also I don't want AWS, etc...) so I'm really asking about whether the premium for a X99-E WS and 5930k is worth it over X99-PRO/DELUX and haswell 5820k given that I want to support a GPU and an M.2 and 64 GB ram (and to eventually upgrade by adding 1-2 more GPUs and another 64Gb ram).  Or alternatively if there's any reason to consider e.g. skylake.",23,9
52,2016-5-3,2016,5,3,1,4hikuj,"Demis Hassabis on adding memory to neural networks, the ""Neural Turing Machine""",https://www.reddit.com/r/MachineLearning/comments/4hikuj/demis_hassabis_on_adding_memory_to_neural/,5ives,1462208158,,5,21
53,2016-5-3,2016,5,3,2,4hiq06,School's in session  Nvidia's driverless system learns by watching,https://www.reddit.com/r/MachineLearning/comments/4hiq06/schools_in_session_nvidias_driverless_system/,noeatnosleep,1462209910,,1,4
54,2016-5-3,2016,5,3,3,4hj0g0,question about model setup for sales forecasting,https://www.reddit.com/r/MachineLearning/comments/4hj0g0/question_about_model_setup_for_sales_forecasting/,laser_goat,1462213526,"Please excuse my ignorance, this is my first real attempt at ML. Given a data set with individual transactions for multiple businesses including the date, total etc what is the best way (currently using google's prediction api) to set up a model where I can say, predict next month's sales for this one business. My data has a business ID but google seems to be inferring weird things about the id string. I got an nn working for a single business, but I want to put training data for all businesses in my data set.

EDIT: here's a sample training data record:

`9263.11,15,business1,15`

The columns are total sales, number of transactions, business id and month number
The month number is just the number of months from our starting point

So I want to ask: ""For `business1` what will the total sales be during month X?"" 
",5,0
55,2016-5-3,2016,5,3,3,4hj3sd,Functional AI image colorizer (web version),https://www.reddit.com/r/MachineLearning/comments/4hj3sd/functional_ai_image_colorizer_web_version/,colorizr,1462214689,,0,1
56,2016-5-3,2016,5,3,4,4hjguz,Very strange behavior of a Tensorflow Convnet - Diagnosis?,https://www.reddit.com/r/MachineLearning/comments/4hjguz/very_strange_behavior_of_a_tensorflow_convnet/,OneRaynyDay,1462219113,"Hi everyone,
I'm currently doing a project regarding medical videos, and I chose to sample discrete time samples(4 frames at once) from an irregular continuous time series to classify 4 classes.

I started with ~200 sample points labeled, and I data augmented them using 360 degrees rotation(10 degrees per stride), to yield 36x200, then I reflected it in 3 different orientations(L/R, U/D, L/R &amp; U/D) to get 200x36x3, and I also sampled 3 discrete time samples in  the given range of frames, so 200x36x3x3 ~= 80k data points.

I ran it through a 5 layer convnet with the architecture:
[CONV -&gt; RELU -&gt; POOL -&gt; DROPOUT] x 3 -&gt; FC -&gt; DROPOUT -&gt; FC -&gt; SOFTMAX

And this is the result. The results are absolutely terrible and gets stuck at around 50% accuracy. I've never seen such a bad performance by convnets and I'm not sure whether it's something I did wrong, or it's just that I don't have enough layers(Which I think is bogus since this same architecture can get &gt;75% on CIFAR-10), or maybe I screwed up the data-augmentation somehow. 

Some hyperparameters:

start_learning_rate = 1e-3

reg_rate = 8e-2 (l2 regularizer)

decay_steps = 1000

decay_rate = 0.95

global_step = tf.Variable(0, trainable=False)

batch_size = 128

dropout_prob = 0.7

The image of accuracy and architecture:
http://imgur.com/a/2mN5f

Here's also a dump of the loss for each iter (iterated 900 times):
http://pastebin.com/sMLr8AfT

---EDIT---
Many who tried to help told me to lower the regularization and here's the result:
I love how the accuracy decreases like the cost function... but yeah I don't think it's working :/
http://imgur.com/YiPwKSq",13,0
57,2016-5-3,2016,5,3,5,4hjksh,Random Indexing,https://www.reddit.com/r/MachineLearning/comments/4hjksh/random_indexing/,[deleted],1462220450,[deleted],0,3
58,2016-5-3,2016,5,3,5,4hjlr5,ICML 2016 Workshop on On-device Intelligence,https://www.reddit.com/r/MachineLearning/comments/4hjlr5/icml_2016_workshop_on_ondevice_intelligence/,virtualpotential,1462220777,,0,4
59,2016-5-3,2016,5,3,5,4hjof8,Data Science Humor - O'Reilly Spoofs,https://www.reddit.com/r/MachineLearning/comments/4hjof8/data_science_humor_oreilly_spoofs/,datasciencedojo,1462221688,,24,177
60,2016-5-3,2016,5,3,5,4hjri3,Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks -FAIR at ICLR 2016,https://www.reddit.com/r/MachineLearning/comments/4hjri3/towards_aicomplete_question_answering_a_set_of/,[deleted],1462222730,[deleted],0,0
61,2016-5-3,2016,5,3,5,4hjrkd,Facebook AI Research at ICLR 2016 | Blog | Research at Facebook,https://www.reddit.com/r/MachineLearning/comments/4hjrkd/facebook_ai_research_at_iclr_2016_blog_research/,[deleted],1462222751,[deleted],0,0
62,2016-5-3,2016,5,3,6,4hjsiy,Discovering governing equations from data: Sparse identification of nonlinear dynamics,https://www.reddit.com/r/MachineLearning/comments/4hjsiy/discovering_governing_equations_from_data_sparse/,eigensteve,1462223069,,0,1
63,2016-5-3,2016,5,3,6,4hju2b,What architecture would you use to join together a number of image blocks?,https://www.reddit.com/r/MachineLearning/comments/4hju2b/what_architecture_would_you_use_to_join_together/,nartmacl,1462223613,[removed],0,1
64,2016-5-3,2016,5,3,6,4hjwuc,Machine learning to discover dynamical systems,https://www.reddit.com/r/MachineLearning/comments/4hjwuc/machine_learning_to_discover_dynamical_systems/,eigensteve,1462224553,,0,1
65,2016-5-3,2016,5,3,7,4hkbh5,"A curated list of awesome TensorFlow experiments, libraries, and projects. Inspired by awesome-machine-learning.",https://www.reddit.com/r/MachineLearning/comments/4hkbh5/a_curated_list_of_awesome_tensorflow_experiments/,Toyjust,1462229958,,1,13
66,2016-5-3,2016,5,3,8,4hkbn4,A Friendly Introduction to Cross-Entropy Loss [OC],https://www.reddit.com/r/MachineLearning/comments/4hkbn4/a_friendly_introduction_to_crossentropy_loss_oc/,rd11235,1462230013,,10,36
67,2016-5-3,2016,5,3,9,4hkowf,Is Graph Theory a nice-to-have course to have?,https://www.reddit.com/r/MachineLearning/comments/4hkowf/is_graph_theory_a_nicetohave_course_to_have/,whoisthriller,1462235054,"mu uni offers a graph theory course, not sure whether it is worth learing. But I heard that grah theory is extreme useful for machine learning",1,0
68,2016-5-3,2016,5,3,9,4hkpeu,Silly question about generalization,https://www.reddit.com/r/MachineLearning/comments/4hkpeu/silly_question_about_generalization/,[deleted],1462235266,[deleted],0,1
69,2016-5-3,2016,5,3,9,4hkrdd,Is discrete mathematics a must subject to learn?,https://www.reddit.com/r/MachineLearning/comments/4hkrdd/is_discrete_mathematics_a_must_subject_to_learn/,whoisthriller,1462235982,"I heard that convex optimization is the most important course for ML, not sure whether discrete mathematics is also important too",3,0
70,2016-5-3,2016,5,3,12,4hletj,Voice Recognition for sleep-talking,https://www.reddit.com/r/MachineLearning/comments/4hletj/voice_recognition_for_sleeptalking/,covert_operator100,1462245619,"Sleep-talkers speak really softly and mumble.

This seems like the ultimate challenge for a voice recognition machine learning program.

I could also allow people who are curious to see what they say to not have to listen to 8 hours of mostly breathing.

What do you think of this application?",2,0
71,2016-5-3,2016,5,3,12,4hlgbg,"Research Papers that are ""must-read"" for ML?",https://www.reddit.com/r/MachineLearning/comments/4hlgbg/research_papers_that_are_mustread_for_ml/,bzsearch,1462246329,"Exactly what the title is stating. I'm looking for suggested papers that I should read to dive deeper into the world of ML. Paper suggestions can be on anything, as I haven't pinpointed my interest yet.

Please suggest away! ",9,5
72,2016-5-3,2016,5,3,12,4hlhyv,Looking for a Postdoctoral Researcher in Language Technology : LanguageTechnology,https://www.reddit.com/r/MachineLearning/comments/4hlhyv/looking_for_a_postdoctoral_researcher_in_language/,antmandan,1462247079,,0,0
73,2016-5-3,2016,5,3,13,4hlkok,"Gensim Guide - Word2Vec, Doc2Vec, LSI, LDA (performant python NLP library)",https://www.reddit.com/r/MachineLearning/comments/4hlkok/gensim_guide_word2vec_doc2vec_lsi_lda_performant/,Jxieeducation,1462248325,,6,20
74,2016-5-3,2016,5,3,13,4hlp1u,Is machine learning over-hyped and are employment opportunities at the risk of contracting?,https://www.reddit.com/r/MachineLearning/comments/4hlp1u/is_machine_learning_overhyped_and_are_employment/,jalligator,1462250440,"Someone asked last night if machine learning in general was over-hyped right now.  I've been wondering the same thing as I hope to enter the industry following a major career change.

So is ML over-hyped?  Will there be fewer ML jobs in the future?  

I personally doubt this.  I think that ML is the future and that ML is how computers will become even more valuable for humanity.

One thing I've realized is that learning ML is not something someone casually picks up, which should limit the supply of practitioners.  That said, I wonder how many each company needs.

But maybe future breakthroughs will occur which could propel the hype -- or utility -- further, making now a great time to enter the industry.
",6,0
75,2016-5-3,2016,5,3,15,4hm0ds,How to quantize neural networks with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/4hm0ds/how_to_quantize_neural_networks_with_tensorflow/,modeless,1462256529,,8,41
76,2016-5-3,2016,5,3,15,4hm340,Advice on how to identify recurring credit card transactions given at least several months of transaction history?,https://www.reddit.com/r/MachineLearning/comments/4hm340/advice_on_how_to_identify_recurring_credit_card/,[deleted],1462258191,[deleted],1,1
77,2016-5-3,2016,5,3,16,4hm6oo,Intuitive Approach To Machine Learning (With TensorFlow),https://www.reddit.com/r/MachineLearning/comments/4hm6oo/intuitive_approach_to_machine_learning_with/,kendrick__,1462260453,,19,23
78,2016-5-3,2016,5,3,16,4hm9kp,[Need help] Try to developp an OCR for receipt,https://www.reddit.com/r/MachineLearning/comments/4hm9kp/need_help_try_to_developp_an_ocr_for_receipt/,[deleted],1462262368,[deleted],0,0
79,2016-5-3,2016,5,3,17,4hmcla,Music transcription modelling and composition using deep learning (paper+code),https://www.reddit.com/r/MachineLearning/comments/4hmcla/music_transcription_modelling_and_composition/,samim23,1462264434,,0,1
80,2016-5-3,2016,5,3,17,4hmct6,Top machine learning conference on applications,https://www.reddit.com/r/MachineLearning/comments/4hmct6/top_machine_learning_conference_on_applications/,insider_7,1462264611,"Hi, I would like to know which is the best conference on ML applications, specifically ML from sensor systems.

Thank you!
",4,0
81,2016-5-3,2016,5,3,18,4hmgao,Dry Cleaning Machines Manufacturers In Ludhiana,https://www.reddit.com/r/MachineLearning/comments/4hmgao/dry_cleaning_machines_manufacturers_in_ludhiana/,Perccare,1462266966,,0,0
82,2016-5-3,2016,5,3,19,4hmkgb,Artistic Style Transfer for Videos (paper+code),https://www.reddit.com/r/MachineLearning/comments/4hmkgb/artistic_style_transfer_for_videos_papercode/,samim23,1462269803,,0,4
83,2016-5-3,2016,5,3,19,4hml3e,What causes Q-function to diverge and how to prevent it?,https://www.reddit.com/r/MachineLearning/comments/4hml3e/what_causes_qfunction_to_diverge_and_how_to/,ptitz,1462270234,"I'm working on a Q-learning/SARSA controller for a dynamical system. Both the states and actions are continuous. I'm using function approximation to store the value function. I'm using the common strategy of updating my function using Q(s,a):=Q(s,a)+alpha(r+gamma argmax(Q(s',a'))-Q(s,a)). The reward received at each step varies from -1 to 0, depending how close I am to my goal. At goal the terminal reward varies from 0 to +10, depending on how well ""on the spot"" I am. I'm also using decaying eligibility traces. It seems to be working more or less, untill my value function explodes into -Infinity at some point, which quickly spreads throughout my function approximator, destroying the whole thing. I've seen the problem mentioned in a few papers, but can't quite find anything about the underlying causes or solutions. Why is this happening and is there a way to solve it somehow?",14,7
84,2016-5-3,2016,5,3,19,4hmlzs,Rubber dispersion kneader mixing machine,https://www.reddit.com/r/MachineLearning/comments/4hmlzs/rubber_dispersion_kneader_mixing_machine/,mixmachinery,1462270833,,1,1
85,2016-5-3,2016,5,3,19,4hmm6y,Help with forecasting time series,https://www.reddit.com/r/MachineLearning/comments/4hmm6y/help_with_forecasting_time_series/,Lenox47,1462270956,"I will be working on predicting facebook pages performances over time. using different features collected like number of fans , number of daily posts , number of daily likes.

Any advice on where to begin would be very appreciated, I am already familiar with scikit learn and python.",5,1
86,2016-5-3,2016,5,3,20,4hmrvi,Implementing logistic regression classifier trained by gradient descent,https://www.reddit.com/r/MachineLearning/comments/4hmrvi/implementing_logistic_regression_classifier/,DrLegend,1462274364,,1,0
87,2016-5-3,2016,5,3,20,4hmttw,A Guide to Bayesian Statistics,https://www.reddit.com/r/MachineLearning/comments/4hmttw/a_guide_to_bayesian_statistics/,iamkeyur,1462275516,,0,12
88,2016-5-3,2016,5,3,21,4hmzus,"Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables",https://www.reddit.com/r/MachineLearning/comments/4hmzus/deep_convolutional_and_recurrent_models_for_human/,vitaminq,1462278497,,1,8
89,2016-5-3,2016,5,3,21,4hn32k,News in artificial intelligence and machine learning you should know about,https://www.reddit.com/r/MachineLearning/comments/4hn32k/news_in_artificial_intelligence_and_machine/,nb410,1462279826,,2,0
90,2016-5-3,2016,5,3,22,4hn4t7,Need to slice my data. How?,https://www.reddit.com/r/MachineLearning/comments/4hn4t7/need_to_slice_my_data_how/,dsfrust,1462280569,[removed],0,2
91,2016-5-3,2016,5,3,23,4hni25,How to add a L2 regularization penalty term to the cost function in multi-layer perceptrons with more than 1 hidden layer,https://www.reddit.com/r/MachineLearning/comments/4hni25/how_to_add_a_l2_regularization_penalty_term_to/,[deleted],1462285690,[deleted],1,0
92,2016-5-4,2016,5,4,1,4ho72x,Finding Similar Music using Matrix Factorization,https://www.reddit.com/r/MachineLearning/comments/4ho72x/finding_similar_music_using_matrix_factorization/,benfred,1462293715,,7,48
93,2016-5-4,2016,5,4,1,4ho92k,Creating a sentiment analysis model with Scrapy and MonkeyLearn,https://www.reddit.com/r/MachineLearning/comments/4ho92k/creating_a_sentiment_analysis_model_with_scrapy/,wildcodegowrong,1462294110,,0,0
94,2016-5-4,2016,5,4,2,4houc2,Marginalizing out missing features as an imputation strategy,https://www.reddit.com/r/MachineLearning/comments/4houc2/marginalizing_out_missing_features_as_an/,gr8ape,1462298380,"Had this idea (not necessarily an original idea, but useful for the task at hand):

I have a task where I need to learn f(x)-&gt;y, but sometimes I have x_k's that are missing. These x_k's are, a priori, very predictive features, so I want to leverage them as much as possible. But the issue is that these x_k's are also features that would NOT be ""exactly"" available at test time...

Here are a some basic strategies to impute, as it is called, the missing features:

- Dummy value like -1000 for tree-based models.

- Use the mean value for missing features (based on the non-missing ones of course).

- Adding an ""indicator feature"" that is True if the variable is missing, in hopes that the model will learn when to rely on the missing feature or not.


The idea I had was, lets train the model either with a dummy value or a mean-value imputation, and at test time, marginalize out that variable by averaging multiple predictions where the missing value is replaced by a range of values weighted by their marginal probability.

So if we have

- f(x_1, x_2) ~= E[y | x_1, x_2]

I would do in theory

- E[y | x_1] ~= sum ( f(x_1, x_2) * p(x_2) ) over {x_2 in X_2}

We could do this for a limited amount of points,  la numerical integration. Let me know if I explained this correctly...

I am wondering, is this correct? Am I missing something, does the p(x_2) actually depend on x_1, or can I simply use x_2's marginal distribution, which can be easily estimated if it is normal or exponential -like?",12,9
95,2016-5-4,2016,5,4,3,4hp9ss,Free trial GPU Cluster?,https://www.reddit.com/r/MachineLearning/comments/4hp9ss/free_trial_gpu_cluster/,llSourcell,1462301689,"Anyone know of a free way I could try out a GPU cluster? I'm trying to train my deep net to generate music in the style of Hans Zimmer. It blows my mind that I can't find a try-before-you-buy option for Cloud GPU computing on either AWS, Google Cloud Compute, or Microsoft Azure. ",23,8
96,2016-5-4,2016,5,4,4,4hpdrh,A Guide to Bayesian Statistics,https://www.reddit.com/r/MachineLearning/comments/4hpdrh/a_guide_to_bayesian_statistics/,josephd,1462302554,,0,0
97,2016-5-4,2016,5,4,4,4hpfi9,Easy yet impressive neural network projects,https://www.reddit.com/r/MachineLearning/comments/4hpfi9/easy_yet_impressive_neural_network_projects/,[deleted],1462302880,[deleted],0,0
98,2016-5-4,2016,5,4,4,4hphdt,Manuel Herranz: PangeaMT -- Empowering Users to Communicate Through MT. ...,https://www.reddit.com/r/MachineLearning/comments/4hphdt/manuel_herranz_pangeamt_empowering_users_to/,deenafeegley,1462303224,,0,1
99,2016-5-4,2016,5,4,4,4hpsre,"all I need is a GPU, why is AWS so hard to set up: any tips?",https://www.reddit.com/r/MachineLearning/comments/4hpsre/all_i_need_is_a_gpu_why_is_aws_so_hard_to_set_up/,mistergot,1462305572,"so im just running DCGAN-tensorflow on my computer right now through docker but my machine is CPU based. trying to generate usable images obviously takes too long. the alternative obviously is to move to the cloud but for some reason AWS has made everything so complex (i'm also pretty new to this stuff). I just need to run a docker container on a GPU for literally less than an hour. any advice?
",4,0
100,2016-5-4,2016,5,4,5,4hptl0,How do you curate your data and create datasets?,https://www.reddit.com/r/MachineLearning/comments/4hptl0/how_do_you_curate_your_data_and_create_datasets/,tutuca_,1462305742,"I'm really a newbie in the field but already know formatting the data sums up most of the work while doing anything with machine learning.

Nevertheless I'm curious about what your preferred workflow is. Does it depends on the problem you are facing? The algorithm?
Do you have a preferred library to work with the source data or you just dump everything into an array?

Also: where should I start digging into this particular topic?
",7,10
101,2016-5-4,2016,5,4,5,4hpuiy,Kaggle Interactive Python Tutorial on ML,https://www.reddit.com/r/MachineLearning/comments/4hpuiy/kaggle_interactive_python_tutorial_on_ml/,stearnsw,1462305942,,0,0
102,2016-5-4,2016,5,4,5,4hpvxh,Good Tutorial for Pattern Recognition in Sequences?,https://www.reddit.com/r/MachineLearning/comments/4hpvxh/good_tutorial_for_pattern_recognition_in_sequences/,DarthDovahkiin5,1462306213,,1,5
103,2016-5-4,2016,5,4,5,4hq56n,My path to OpenAI,https://www.reddit.com/r/MachineLearning/comments/4hq56n/my_path_to_openai/,confused00-,1462308055,,4,29
104,2016-5-4,2016,5,4,5,4hq64s,Edward: A library for deep generative models and inference,https://www.reddit.com/r/MachineLearning/comments/4hq64s/edward_a_library_for_deep_generative_models_and/,nil-,1462308267,,12,28
105,2016-5-4,2016,5,4,5,4hq7js,Kodak Computer to Plate Machine Belts,https://www.reddit.com/r/MachineLearning/comments/4hq7js/kodak_computer_to_plate_machine_belts/,alhaqtraders,1462308565,,0,1
106,2016-5-4,2016,5,4,5,4hq8is,RMSE vs correlation distance,https://www.reddit.com/r/MachineLearning/comments/4hq8is/rmse_vs_correlation_distance/,[deleted],1462308771,[deleted],2,0
107,2016-5-4,2016,5,4,6,4hqfy1,ICLR 2016 Code,https://www.reddit.com/r/MachineLearning/comments/4hqfy1/iclr_2016_code/,[deleted],1462310374,[deleted],0,0
108,2016-5-4,2016,5,4,6,4hqky8,How I got into the top 15 of a Kaggle competition in 2 days,https://www.reddit.com/r/MachineLearning/comments/4hqky8/how_i_got_into_the_top_15_of_a_kaggle_competition/,dataphysicist,1462311523,,1,14
109,2016-5-4,2016,5,4,7,4hqusk,LineByLine: Explaining TensorFlow's mnist.py,https://www.reddit.com/r/MachineLearning/comments/4hqusk/linebyline_explaining_tensorflows_mnistpy/,vanboxel,1462313588,,0,0
110,2016-5-4,2016,5,4,7,4hqvff,Is there any benefit to SVD after doc2vec?,https://www.reddit.com/r/MachineLearning/comments/4hqvff/is_there_any_benefit_to_svd_after_doc2vec/,slugsnot,1462313727,"I find it interesting that SVD can extract ""concepts"" via Latent Semantic Indexing using DF or TF-IDF. 


As an alternate method,


I apply Doc2Vec. I can get document vectors with many features (300 or so). I believe those features are just words, but I may be wrong. Even if they are not words, my question is this: Is there any sense to running SVD on these doc_vectors? Or are they already in their most meaningful form?",5,2
111,2016-5-4,2016,5,4,7,4hqwza,Andrej Karpathy forced to take down Stanford CS231n videos,https://www.reddit.com/r/MachineLearning/comments/4hqwza/andrej_karpathy_forced_to_take_down_stanford/,_bskaggs,1462314113,,230,493
112,2016-5-4,2016,5,4,7,4hr1v8,Code for all ICML 2016 papers,https://www.reddit.com/r/MachineLearning/comments/4hr1v8/code_for_all_icml_2016_papers/,[deleted],1462315210,[deleted],0,1
113,2016-5-4,2016,5,4,7,4hr38y,"PGE - Parallel Game Engine for AI, interfaces with the OpenAI Gym",https://www.reddit.com/r/MachineLearning/comments/4hr38y/pge_parallel_game_engine_for_ai_interfaces_with/,CireNeikual,1462315517,,1,3
114,2016-5-4,2016,5,4,10,4hs41f,Regression in matrix factorization?,https://www.reddit.com/r/MachineLearning/comments/4hs41f/regression_in_matrix_factorization/,[deleted],1462324081,[deleted],0,0
115,2016-5-4,2016,5,4,12,4hsnda,Probabilistic Programming for Anomaly Detection,https://www.reddit.com/r/MachineLearning/comments/4hsnda/probabilistic_programming_for_anomaly_detection/,iamkeyur,1462331625,,0,6
116,2016-5-4,2016,5,4,13,4ht09b,Comparing and Computing Performance Metrics in Cross-Validation  Imbalanced Class Problems and 3 Different Ways to Compute the F1 Score,https://www.reddit.com/r/MachineLearning/comments/4ht09b/comparing_and_computing_performance_metrics_in/,[deleted],1462337787,[deleted],0,1
117,2016-5-4,2016,5,4,14,4ht30x,What the difference between Model based reinforcement learning &amp; Model predictive control,https://www.reddit.com/r/MachineLearning/comments/4ht30x/what_the_difference_between_model_based/,erlilyu,1462339268,[removed],0,1
118,2016-5-4,2016,5,4,16,4htftc,ICLR 2016 papers code collection,https://www.reddit.com/r/MachineLearning/comments/4htftc/iclr_2016_papers_code_collection/,impairment,1462346904,,0,32
119,2016-5-4,2016,5,4,16,4htihj,Neural-Style transfer animation tests.,https://www.reddit.com/r/MachineLearning/comments/4htihj/neuralstyle_transfer_animation_tests/,lulu1315,1462348696,,2,0
120,2016-5-4,2016,5,4,17,4htj2d,Looking for commercial datasets of faces and speech annotated with emotions,https://www.reddit.com/r/MachineLearning/comments/4htj2d/looking_for_commercial_datasets_of_faces_and/,carlos_argueta,1462349109,[removed],0,0
121,2016-5-4,2016,5,4,17,4htmyx,Can someone explain Holographic Reduced Representations?,https://www.reddit.com/r/MachineLearning/comments/4htmyx/can_someone_explain_holographic_reduced/,vintermann,1462351808,"I'd like to understand these data structures that are used in Associative LSTMs, but I just don't get the papers I find. They just dive into the statistics and calculus (or worse, neuro-speak) before giving a clear description of the _operations_ of the data structure, and how it can be used in practice. With keys as long as the data it stores, this thing is already very confusing to me.

Help would be greatly appreciated!",3,8
122,2016-5-4,2016,5,4,17,4htn9w,DeepMind given access to London patient records for research,https://www.reddit.com/r/MachineLearning/comments/4htn9w/deepmind_given_access_to_london_patient_records/,T-zex,1462352065,,16,58
123,2016-5-4,2016,5,4,19,4htv5t,Best method for finding correlations,https://www.reddit.com/r/MachineLearning/comments/4htv5t/best_method_for_finding_correlations/,crunchthedata,1462357434,[removed],0,1
124,2016-5-4,2016,5,4,19,4htxba,How to crossover the parents when using a value encoding method in genetic algorithm?,https://www.reddit.com/r/MachineLearning/comments/4htxba/how_to_crossover_the_parents_when_using_a_value/,albertgao,1462358847,"Hi, help plz :(

There is phase in genetic algorithm where we should choose to crossover the chromosomes from parents to offspring.It is easy to do via binary form.

But what to do if we encodes the choromsomes using the value encoding?

Let's say one bit in my choromosomes is a DOUBLE type value, 0.99, its range is (0-1) since it will represente a probability.

How to crossover this DOUBLE number?

Convert to binary to crossover then convert back...?",9,0
125,2016-5-4,2016,5,4,20,4htz9h,workflow for speech/sound CNN?,https://www.reddit.com/r/MachineLearning/comments/4htz9h/workflow_for_speechsound_cnn/,hapliniste,1462359985,"Hi, I would like to try some things with audio (speech, music,...) but don't really know what to use for getting the data prepared.

I would like to use fully convolutional networks, so I want to transform data into spectrogram. What are some good software/workflow to prepare the data?

Also, if you have links to get started I'm interested :) I'm currently working with TF/Keras.

BTW, if someone can enlighten me on why there is so much audio networks based on RNN rather than CNN I would like to discuss it! I feel like the advantage of RNN is that it is more suited for ""unfinished"" sounds (like speech streaming). I think a CNN (maybe a la ResNet) followed by a LSTM with attention could work well.

Thank for reading!",6,0
126,2016-5-4,2016,5,4,20,4hu0uf,Neural networks and deep learning book by Michael Nielson,https://www.reddit.com/r/MachineLearning/comments/4hu0uf/neural_networks_and_deep_learning_book_by_michael/,ansible,1462360925,,5,12
127,2016-5-4,2016,5,4,23,4hum20,video lectures for Machine Learning for Artists @ NYU,https://www.reddit.com/r/MachineLearning/comments/4hum20/video_lectures_for_machine_learning_for_artists/,genekogan,1462370768,"video lectures and notes for ""Machine learning for artists,"" a 6-week course I taught at NYU's ITP program this Spring:

http://ml4a.github.io/classes/itp-S16

Includes applications of convolutional and recurrent neural nets, and some game AI/reinforcement learning. The goal is to highlight creative uses of AI but covers a fair amount of theory as well.

I was disappointed that Stanford took down the CS231n videos yesterday. They were a big help to making this course. I hope they bring them back up.

For fun, I made a 2min timelapse of all 6 lectures: https://vimeo.com/165294912",2,6
128,2016-5-4,2016,5,4,23,4hund3,The White House - Preparing for the Future of Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/4hund3/the_white_house_preparing_for_the_future_of/,jaemccall,1462371273,,8,2
129,2016-5-4,2016,5,4,23,4huo36,what is low dimensional manifold ?,https://www.reddit.com/r/MachineLearning/comments/4huo36/what_is_low_dimensional_manifold/,John_Smith111,1462371546,"hello all

could you provide me some intuition what is low dimensional manifold ?
",6,0
130,2016-5-4,2016,5,4,23,4husi0,Natural Language Processing Example,https://www.reddit.com/r/MachineLearning/comments/4husi0/natural_language_processing_example/,sudocaptain,1462373232,"I get a tremendous amount of email that I want to be able to index for different categories that comes in the content of the email, not subject. The format may vary. There are maybe 4 or 5 fields I'll be searching for in every email. I was wondering if anyone knew of any good natural langauge processing github examples that I can look at that would be a good starting off point that I can build off of. Thanks a lot!",4,8
131,2016-5-5,2016,5,5,0,4hux7e,"Trifecta: Python, Machine Learning, + Dueling Languages",https://www.reddit.com/r/MachineLearning/comments/4hux7e/trifecta_python_machine_learning_dueling_languages/,OpenDataSciCon,1462374907,,0,1
132,2016-5-5,2016,5,5,0,4hv0ce,Is tensorflow still slow for RNNs?,https://www.reddit.com/r/MachineLearning/comments/4hv0ce/is_tensorflow_still_slow_for_rnns/,SkiddyX,1462376045,"Just wondering if anyone has experience trying the newer versions of tensorflow for RNNs. I have heard rumors that it's super slow for RNNs *still*, is this true?",7,7
133,2016-5-5,2016,5,5,0,4hv1ha,I'm looking to get into machine learning and was debating self study or getting a degree - advice?,https://www.reddit.com/r/MachineLearning/comments/4hv1ha/im_looking_to_get_into_machine_learning_and_was/,th4ne,1462376445,"Hi, I have a GMAT score that's good until the end of this year and was thinking about applying for Rutgers MBA program in analytics.

http://www.business.rutgers.edu/part-time-mba/curriculum/aim

I know there are a lot of free resources to learn online, so I'm wondering what the MBA program might offer that MOOC's cant? (aside from networking potential and job placement). I've been hemming and hawing about this for a while now and figured I'd ask here. Thanks.",9,0
134,2016-5-5,2016,5,5,0,4hv3bw,9 Machine Learning lessons learned after a decade of development,https://www.reddit.com/r/MachineLearning/comments/4hv3bw/9_machine_learning_lessons_learned_after_a_decade/,tony_sf,1462377083,,0,0
135,2016-5-5,2016,5,5,1,4hvdgh,"Can you manually edit a decision tree in Python (using any package)? Can you change the feature(s), for instance, that a particular node uses?",https://www.reddit.com/r/MachineLearning/comments/4hvdgh/can_you_manually_edit_a_decision_tree_in_python/,slugsnot,1462380415,,0,1
136,2016-5-5,2016,5,5,2,4hvgyx,"LargeVis, a dimensionality-reduction algorithm with competitive performance vs. t-SNE",https://www.reddit.com/r/MachineLearning/comments/4hvgyx/largevis_a_dimensionalityreduction_algorithm_with/,[deleted],1462381558,[deleted],0,1
137,2016-5-5,2016,5,5,2,4hvhzp,convincing customers of the value of deep learning,https://www.reddit.com/r/MachineLearning/comments/4hvhzp/convincing_customers_of_the_value_of_deep_learning/,tony_sf,1462381894,,1,0
138,2016-5-5,2016,5,5,2,4hviph,Analysis of ISIS activity on Twitter,https://www.reddit.com/r/MachineLearning/comments/4hviph/analysis_of_isis_activity_on_twitter/,jabawack,1462382110,,4,2
139,2016-5-5,2016,5,5,2,4hvmq0,Using metadata and dummy variables in CNNs? [x-post with cs231n],https://www.reddit.com/r/MachineLearning/comments/4hvmq0/using_metadata_and_dummy_variables_in_cnns_xpost/,fullon604,1462383431,"For example, the timestamp or GPS on a photo would be helpful if i'm trying to better understand context. But I'm not sure that running that sort of flag-like data thru convolutional filters along with the photo itself makes any sense. Is there some better way to think about this? Should I feed an input vector containing such data directly into a higher layer in the net, after the graphical stuff has been through a few conv layers? or am i over-thinking it and just appending it to the image data works somehow?

If anybody can point me to models on github or tutorials that deal with this sort of thing i'd be appreciative.",2,1
140,2016-5-5,2016,5,5,2,4hvpwi,Taking the Scenic Route With Deep Learning,https://www.reddit.com/r/MachineLearning/comments/4hvpwi/taking_the_scenic_route_with_deep_learning/,reworksophie,1462384470,,0,1
141,2016-5-5,2016,5,5,2,4hvq0r,Googles Artificial Intelligence Engine Reads Romance Novels,https://www.reddit.com/r/MachineLearning/comments/4hvq0r/googles_artificial_intelligence_engine_reads/,colditzjb,1462384510,,2,0
142,2016-5-5,2016,5,5,2,4hvql7,"[1602.00370] Visualizing Large-scale and High-dimensional Data (introduces LargeVis, a t-SNE competitor)",https://www.reddit.com/r/MachineLearning/comments/4hvql7/160200370_visualizing_largescale_and/,dunnowhattoputhere,1462384719,,8,37
143,2016-5-5,2016,5,5,4,4hw41i,Machine learning problem I'm working on. Looking for advice,https://www.reddit.com/r/MachineLearning/comments/4hw41i/machine_learning_problem_im_working_on_looking/,FreakinGeese,1462389296,"I'm a sophomore in high school, and I want to *cough cough* speed up my homework. My classes with homework are chemistry, trig, comp sci, and Spanish. Chemistry homework is multiple choice questions online, taken from old regents exams. Since a list of PDFs (with answer keys) is available online, I plan to make a list of the exam questions and answers, and simply write a program to enter them into the website. Trig is written, with questions from a textbook. I plan to train a neural network to write in my handwriting, then write answers to the questions, extracting the question with standard nlp techniques and using the wordfram alpha api to solve them. Comp sci would be impossible but for the fact that my teacher put up an answer-checker, so I can simply use a genetic learning algorithm to write something that passes the tests. Finally, I can use word embedding to conjugate spanish verbs, and verifiy it's answers.

That's the plan at least. Any suggestions? Sorry if it's a long post.",33,0
144,2016-5-5,2016,5,5,4,4hw4x0,Self-Driving Car Access to Researchers,https://www.reddit.com/r/MachineLearning/comments/4hw4x0/selfdriving_car_access_to_researchers/,[deleted],1462389595,[deleted],0,0
145,2016-5-5,2016,5,5,5,4hwf1x,[1605.00064] Higher Order Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/4hwf1x/160500064_higher_order_recurrent_neural_networks/,InaneMembrane,1462393153,,19,10
146,2016-5-5,2016,5,5,5,4hwf7r,General Sequence Learning using Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/4hwf7r/general_sequence_learning_using_recurrent_neural/,shash273,1462393214,,1,9
147,2016-5-5,2016,5,5,6,4hwmtk,Cloud Computing/Desktop PC,https://www.reddit.com/r/MachineLearning/comments/4hwmtk/cloud_computingdesktop_pc/,OnlySongLyrics,1462395936,"Hi All,

I've been experimenting with Machine Learning for about a year now with scikit in Python. I'm getting good results, but I'm starting to hit a wall where some aspects, (especially my GridSearches) are taking 8-24 hours to complete on my laptop (i5 3320M/4 GB RAM). I've considered either AWS or just getting/building a PC devoted to running ML algorithms.

Any advice?

FYI - my background is Chemical Engineering, not CS. Sorry if I'm omitting some key info.",7,2
148,2016-5-5,2016,5,5,6,4hwn11,ICML 2016 Accepted Papers,https://www.reddit.com/r/MachineLearning/comments/4hwn11/icml_2016_accepted_papers/,notarowboat,1462396015,,8,101
149,2016-5-5,2016,5,5,6,4hwnud,Wind Tower Flange Industry Growing along with Smart Buildings Market!,https://www.reddit.com/r/MachineLearning/comments/4hwnud/wind_tower_flange_industry_growing_along_with/,tharunvicky,1462396306,,0,1
150,2016-5-5,2016,5,5,6,4hwos7,"Chatbot ""Tech Stack""question from non-technical n00b",https://www.reddit.com/r/MachineLearning/comments/4hwos7/chatbot_tech_stackquestion_from_nontechnical_n00b/,peek-a-boo_,1462396674,"I'm wondering if anyone could easily map out the ""tech stack"" used to build some of the chat bots we see today.  A simple example would be a Poncho or a Prompt.  A more complicated example would be an Msg.AI or an X.AI.  As someone with a non-dev background trying to understand/map this space, would be super helpful to get a basic sense of the various technologies at play here.

gracias",3,0
151,2016-5-5,2016,5,5,6,4hwth1,ML and Flow Maximization,https://www.reddit.com/r/MachineLearning/comments/4hwth1/ml_and_flow_maximization/,[deleted],1462398427,[removed],0,1
152,2016-5-5,2016,5,5,6,4hwu2y,Gradientzoo: Version and share your trained neural network models,https://www.reddit.com/r/MachineLearning/comments/4hwu2y/gradientzoo_version_and_share_your_trained_neural/,jeiting,1462398632,,0,4
153,2016-5-5,2016,5,5,6,4hwusf,Dynamic Capacity Networks,https://www.reddit.com/r/MachineLearning/comments/4hwusf/dynamic_capacity_networks/,modeless,1462398888,,0,0
154,2016-5-5,2016,5,5,7,4hwytr,Diabetes Prediction,https://www.reddit.com/r/MachineLearning/comments/4hwytr/diabetes_prediction/,techfreak123,1462400388,"Hey guys, I am looking to do a project on prediction of diabetes. But I am not able to find any proper data set. There is the Pima Indian diabetes dataset but it is old and everything is already performed on that dataset. Can you guys help me get a proper dataset with good number of attributes and instances related to diabetes? Thank you",1,1
155,2016-5-5,2016,5,5,11,4hxw3s,Gary Marcus edge.org convo: Is Big Data Taking Us Closer to the Deeper Questions in Artificial Intelligence?,https://www.reddit.com/r/MachineLearning/comments/4hxw3s/gary_marcus_edgeorg_convo_is_big_data_taking_us/,evc123,1462413842,,1,0
156,2016-5-5,2016,5,5,12,4hy7o1,A NLP powered tool to help simplify your writing.,https://www.reddit.com/r/MachineLearning/comments/4hy7o1/a_nlp_powered_tool_to_help_simplify_your_writing/,[deleted],1462419020,[deleted],3,1
157,2016-5-5,2016,5,5,13,4hycxp,Proof of Backpropogation Algorithim,https://www.reddit.com/r/MachineLearning/comments/4hycxp/proof_of_backpropogation_algorithim/,FutureIsMine,1462421672,"The backpropogation algorithim can be summed up as being: For the final layer as ErrorFinal = Yactual - Ypred. From there on, it would be weights * Error_of_previous_layer*derivative_Of_activation_function. What I'm having a hard time wrapping my head around is where does the next layer term come from in this equation? ",6,0
158,2016-5-5,2016,5,5,14,4hyj1d,"Beyond Images, The Race Towards Applying Machine Vision On Videos",https://www.reddit.com/r/MachineLearning/comments/4hyj1d/beyond_images_the_race_towards_applying_machine/,JoeyRob,1462424923,,0,1
159,2016-5-5,2016,5,5,14,4hynxf,The blaze of Rubber kneader dispersion machine,https://www.reddit.com/r/MachineLearning/comments/4hynxf/the_blaze_of_rubber_kneader_dispersion_machine/,mixmachinery,1462427895,,1,1
160,2016-5-5,2016,5,5,15,4hyp9i,L-Series Backhoe Portfolio with Powerful 710L,https://www.reddit.com/r/MachineLearning/comments/4hyp9i/lseries_backhoe_portfolio_with_powerful_710l/,whyps,1462428783,,0,1
161,2016-5-5,2016,5,5,15,4hyq8p,I-140 Direct Drive Impact Crusher,https://www.reddit.com/r/MachineLearning/comments/4hyq8p/i140_direct_drive_impact_crusher/,whyps,1462429421,,0,1
162,2016-5-5,2016,5,5,15,4hyr6k,Proportional Flow Valves,https://www.reddit.com/r/MachineLearning/comments/4hyr6k/proportional_flow_valves/,whyps,1462430040,,0,1
163,2016-5-5,2016,5,5,17,4hz05c,What is the state-of-the-art in generative models of natural images?,https://www.reddit.com/r/MachineLearning/comments/4hz05c/what_is_the_stateoftheart_in_generative_models_of/,anonDogeLover,1462436055,"I haven't been following the GAN literature very closely and I can't find any huge improvements over the initial work. Specifically, I am interested in (1) what is the current state-of-the-art, and (2) how big are the images that are generated in pixel dimensions?",9,4
164,2016-5-5,2016,5,5,18,4hz4fo,Train your TensorFlow Models on Rescale,https://www.reddit.com/r/MachineLearning/comments/4hz4fo/train_your_tensorflow_models_on_rescale/,pmigdal,1462439338,,1,0
165,2016-5-5,2016,5,5,18,4hz77g,A Review of Natural Language APIs For Bots,https://www.reddit.com/r/MachineLearning/comments/4hz77g/a_review_of_natural_language_apis_for_bots/,alexvitale,1462441394,,2,2
166,2016-5-5,2016,5,5,18,4hz7ey,Adjustable Feet: You Cannot Do Away with it,https://www.reddit.com/r/MachineLearning/comments/4hz7ey/adjustable_feet_you_cannot_do_away_with_it/,castormarts,1462441544,,0,0
167,2016-5-5,2016,5,5,20,4hzjmy,Introduction to Recurrent Networks in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/4hzjmy/introduction_to_recurrent_networks_in_tensorflow/,danijar,1462449087,,4,107
168,2016-5-5,2016,5,5,22,4i007u,Is there any software (open-source or otherwise) that can handle (audio) speech emotion recognition?,https://www.reddit.com/r/MachineLearning/comments/4i007u/is_there_any_software_opensource_or_otherwise/,relganz,1462456676,"On a potential project, I would need to extract something like tone or emotion from audio files (Mp3,Ogg) of people speaking.  For these files, we already have the written transcripts, and have already used NLP libraries with the text.  We figure that listening directly to the audio could provide extra information if it's feasibile to extract such features.  If anyone has tried this, I would really appreciate any advice.

Thanks",4,3
169,2016-5-5,2016,5,5,23,4i01e1,Alternative structures for character-level RNNs,https://www.reddit.com/r/MachineLearning/comments/4i01e1/alternative_structures_for_characterlevel_rnns/,vkhuc,1462457139,,1,9
170,2016-5-5,2016,5,5,23,4i03s1,Will Artificial Intelligence Stifle Our Creativity or Enhance It?,https://www.reddit.com/r/MachineLearning/comments/4i03s1/will_artificial_intelligence_stifle_our/,BigCloudTeam,1462458140,,4,0
171,2016-5-5,2016,5,5,23,4i08x7,Why it's time for CIOs to invest in machine learning,https://www.reddit.com/r/MachineLearning/comments/4i08x7/why_its_time_for_cios_to_invest_in_machine/,yourbasicgeek,1462460159,,0,0
172,2016-5-5,2016,5,5,23,4i090z,K-Means and Customer Profiling,https://www.reddit.com/r/MachineLearning/comments/4i090z/kmeans_and_customer_profiling/,happy_geek,1462460197,"Hi - I'm doing customer segmentation using K-Means clustering. Ive figured out optimal K using elbow method. Now I want to analyze the member features of each cluster to find their significance to that cluster and then tag those key features as a specific customer profile (ex: profile 1: price conscious, venture backed manufacturing companies with high debt to equity ratio, profile 2: price insensitive, large cap companies with global operations and medium debt to equity ratio, etc etc). Any specific techniques around this customer profiling of unstructured data? Any research you can point me to? Or do I need to combine with regression or something? thanks!",4,2
173,2016-5-6,2016,5,6,0,4i0aq0,Uber switching from surge pricing to machine learning,https://www.reddit.com/r/MachineLearning/comments/4i0aq0/uber_switching_from_surge_pricing_to_machine/,[deleted],1462460816,[deleted],1,1
174,2016-5-6,2016,5,6,0,4i0f3o,Video Recordings of the ICML'15 Deep Learning Workshop,https://www.reddit.com/r/MachineLearning/comments/4i0f3o/video_recordings_of_the_icml15_deep_learning/,dpkingma,1462462418,,10,59
175,2016-5-6,2016,5,6,1,4i0p94,char-rnn - Training Loss and Validation Loss,https://www.reddit.com/r/MachineLearning/comments/4i0p94/charrnn_training_loss_and_validation_loss/,drohack,1462466075,"(this post is in regards to using the open source neural network code by karpathy located [here](https://github.com/karpathy/char-rnn).)

If training loss &lt;&lt; validation loss, it is overfitting; if roughly training loss = validation loss, it is underfitting. Then ,what is the balanced situation? Is it training loss &gt; validation loss or training loss is lower but not much lower than validation loss? 

I have gotten my Training Loss &gt; Validation Loss by increasing the Dropout to &gt; 0.8 though that did cause the Validation Loss/Training Loss about twice as long (2x the epochs) to reach the minimum Validation Loss I could get.

I also have a follow-up. What is a good Validation Loss to get to for decent generation of data (I know this could be different for a given data set). No matter what variables I change I can't get my lowest Validation Loss &lt; 0.5. Most of the time the Validation Loss will get close to 0.5 then start going back up. This would suggest that I'm Overfitting if I'm not mistaken.

About my data:
I have a 1Mb text file (all magic cards stripped down to useful information in json format, you can view it [here](http://termbin.com/t3le)). I'd like to have a bigger data set, but this is already all the cards ever produced. When running with any given variables I get about 3million - 5million parameters. It also takes only about 15 - 20 epochs to get the Validation Loss to around 0.5 before it won't go any lower, or starts going back up. Each ""card"" is between 100 - 400 characters long. The cards have been pre-shuffled (mainly so like colored cards are not next to eachother).

The ""best"" run I've done is the following (lowest Validation Loss):

&gt; th train.lua -data_dir data/mtg/ -num_layers 3 -rnn_size 512 -seq_length 300 -train_frac 0.95 -val_frac 0.05 -max_epochs 20 -seed $RANDOM -batch_size 25 -eval_val_every 200 -dropout 0.5

This produced a final Validation Loss of 0.4969 after the full 20 epochs (with the previous 7 epochs all being around 0.5).

All of my test have been on the base data, meaning I haven not been running it with the -init_from command on previous runs. The few times I have tried this the Training Loss either goes out of whack right away, or it doesn't produce any better minimum Validation Loss. Would running from previous save locations help/be any different than running the code for longer? I have the time and power to run this over thousands of epochs. But so far that hasn't seemed to help.

It's hard to really tell if any of my .t7 files are any better than the rest as so far they're fairly comparable. And it's not as though the ""cards"" it produce are really that ""bad"". But there are some patterns that I would like to code to pick up on. Like when cards reference themselves, the generated code never produces a card that references it's own name (it'll put some other random name instead). Or cards with bulletin points have ""Chose one or both"" before them, but none of the generated cards with bulletin points have this.
I know this also has to do with the Temperature when sampling. I've found that anything with a Temperature below 0.5 only creates very rudimentary cards. And anything above 0.9 creates mostly gibberish. I've been generating all of my cards at 0.7.

&gt; th sample.lua -length 5000 -temperature 0.7 -primetext ""{\""Name\"":\""Storm Crow\"","" cv/lm_lstm_epoch20.00_0.4969.t7",7,0
176,2016-5-6,2016,5,6,1,4i0ryk,Parallelized Gaussian Mixture Model,https://www.reddit.com/r/MachineLearning/comments/4i0ryk/parallelized_gaussian_mixture_model/,anonDogeLover,1462467028,Does anyone know of a fast GMM implementation that can use multiple cpu cores or a GPU?,12,3
177,2016-5-6,2016,5,6,4,4i1g92,Autoencoder in Tenserflow ?,https://www.reddit.com/r/MachineLearning/comments/4i1g92/autoencoder_in_tenserflow/,Alirezag,1462475519,Does anyone know of a good example or implementation for Autoencoder in TensorFlow?,5,0
178,2016-5-6,2016,5,6,4,4i1lj7,What is dimension reduction &amp; feature selection / extraction? (including useful packages),https://www.reddit.com/r/MachineLearning/comments/4i1lj7/what_is_dimension_reduction_feature_selection/,terryum,1462477384,,1,0
179,2016-5-6,2016,5,6,5,4i1plu,"Only humans, not computers, can learn or predict",https://www.reddit.com/r/MachineLearning/comments/4i1plu/only_humans_not_computers_can_learn_or_predict/,speckz,1462478859,,18,0
180,2016-5-6,2016,5,6,7,4i2ax0,Accelerate Recommender Systems With GPUs,https://www.reddit.com/r/MachineLearning/comments/4i2ax0/accelerate_recommender_systems_with_gpus/,harrism,1462487063,,7,44
181,2016-5-6,2016,5,6,7,4i2e7z,Taming the Monster: A Fast and Simple Algorithm for Contextualized Bandits,https://www.reddit.com/r/MachineLearning/comments/4i2e7z/taming_the_monster_a_fast_and_simple_algorithm/,digitsman,1462488509,,5,25
182,2016-5-6,2016,5,6,11,4i35rh,Feature Selection: A Data Perspective,https://www.reddit.com/r/MachineLearning/comments/4i35rh/feature_selection_a_data_perspective/,murakamifanboy,1462500677,,1,22
183,2016-5-6,2016,5,6,11,4i38ot,pyLDAvis Guide - Visualizing LDA topics in 5 lines of code,https://www.reddit.com/r/MachineLearning/comments/4i38ot/pyldavis_guide_visualizing_lda_topics_in_5_lines/,[deleted],1462502024,[deleted],0,0
184,2016-5-6,2016,5,6,12,4i3dyl,I want to do object recognition in images. Where do I start?,https://www.reddit.com/r/MachineLearning/comments/4i3dyl/i_want_to_do_object_recognition_in_images_where/,MasterEpictetus,1462504515,"I would like to build a model that given an image would return the different objects/things contained in it, such as car, house, towel, chair, sky, ocean, pool, etc. I don't so much care about where they are in the image, I just wanna know they exist. 

1. Should I train my own model or should I use a pre-trained network? If pre-trained, which one?

2. What papers and network architectures should I look into?

3. What library should I use? (I'm familiar with Keras, is it good enough?)

4. What database should I use to train my model?

Thanks.",9,0
185,2016-5-6,2016,5,6,12,4i3f17,What methods exist to infer correlated noise in experimental results?,https://www.reddit.com/r/MachineLearning/comments/4i3f17/what_methods_exist_to_infer_correlated_noise_in/,[deleted],1462505067,[deleted],6,0
186,2016-5-6,2016,5,6,14,4i3sxr,Sutton's Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/4i3sxr/suttons_reinforcement_learning/,WilliamWallace,1462512577,How relevant is this book today? Is it worth investing the time to read through and understand it or are there better resources?,9,5
187,2016-5-6,2016,5,6,15,4i3z05,Machine Learning with Python Certification,https://www.reddit.com/r/MachineLearning/comments/4i3z05/machine_learning_with_python_certification/,ivyproschool,1462516376,,0,1
188,2016-5-6,2016,5,6,15,4i40jb,MACHINERY CENTRAL ASIA 2016,https://www.reddit.com/r/MachineLearning/comments/4i40jb/machinery_central_asia_2016/,whyps,1462517417,,0,1
189,2016-5-6,2016,5,6,17,4i48om,A new MIRI research program with a machine learning focus,https://www.reddit.com/r/MachineLearning/comments/4i48om/a_new_miri_research_program_with_a_machine/,stormforce7916,1462523328,,0,0
190,2016-5-6,2016,5,6,17,4i49gh,Where can i find datasets?,https://www.reddit.com/r/MachineLearning/comments/4i49gh/where_can_i_find_datasets/,snillerboy,1462523947,"Hi everyone, i am at the moment researching with new techniques of ML, so i am looking for datasets. It doesn't matter what data it is, or if its supervised or unsupervised. just datasets that can be used for ML :)

Is there a list or anything?
",9,7
191,2016-5-6,2016,5,6,17,4i4a6r,Machine Learning research topic,https://www.reddit.com/r/MachineLearning/comments/4i4a6r/machine_learning_research_topic/,iqra1804,1462524560,[removed],0,1
192,2016-5-6,2016,5,6,19,4i4j66,How I wrote an Automatic License Plate Recognition system with Python and a TensorFlow ConvNet [xpost /r/programming],https://www.reddit.com/r/MachineLearning/comments/4i4j66/how_i_wrote_an_automatic_license_plate/,kipi,1462530909,,17,153
193,2016-5-6,2016,5,6,19,4i4kc7,awesome ML- List of awesome ML links,https://www.reddit.com/r/MachineLearning/comments/4i4kc7/awesome_ml_list_of_awesome_ml_links/,[deleted],1462531683,[deleted],2,0
194,2016-5-6,2016,5,6,20,4i4m7b,Open AI Gym: What do you think about the Reinforcement Learning toolkit and its evaluation methods?,https://www.reddit.com/r/MachineLearning/comments/4i4m7b/open_ai_gym_what_do_you_think_about_the/,[deleted],1462532856,[deleted],19,15
195,2016-5-6,2016,5,6,22,4i4zo1,How do I optimize a model for better memory usage?,https://www.reddit.com/r/MachineLearning/comments/4i4zo1/how_do_i_optimize_a_model_for_better_memory_usage/,mln00b13,1462539971,"I am currently using [torrvision's CRFRNN](https://github.com/torrvision/crfasrnn) on CPU. For faster speed I used python's multiprocessing. However, each of my worker uses 5GB of memory, total 15GB of memory is being used. Any way I can minimize this? Can I use mmap in this somewhere?",7,0
196,2016-5-6,2016,5,6,22,4i51mk,Can someone go into more detail about how this music representation/classification system works?,https://www.reddit.com/r/MachineLearning/comments/4i51mk/can_someone_go_into_more_detail_about_how_this/,Rich700000000000,1462540862,"I was reading through the comments and stumbled upon this, by reddit user /u/gindc:


""*I actually do a couple of steps. I read the first minute of music and make it a mono 22 kHz wav file (using ffmpeg). I read that into numpy. That's 1,323,000 data points.*""

""*I reduce this dataset down to 3000 floats. The first 1000 floats are blocks of frequencies (from an FFT) across blocks of time (6 seconds per block). The second 1000 floats are just a straight average FFT of the entire music. That last 1000 floats are an FFT of the energy levels of the song (square of the amplitude). This give a representation of the beats in the music.*""

""*I then take the vector of 3000 floats and do a minmax scaler to normalize each column to values between 0 and 1.
Next I do a principle component analysis and reduce the data set to 500 floating points. And finally, I do a select K best algorithm to reduce the data set down to 100 values. So each song is represented by 100 floating point numbers.*""

""*I can use these values not only to score the music, but I can also use support vector classifiers to guess the musical genre.
It works incredibly well at scoring and predicting. I use the numpy, sklearn package and google's ""Neurallab"" package. But am going to try out TensorFlow tonight.*"" 

Can someone break this down for me? I'm a bit lost after the first step. How does each level work?",3,2
197,2016-5-6,2016,5,6,22,4i53dz,Why deep generative models are useful?,https://www.reddit.com/r/MachineLearning/comments/4i53dz/why_deep_generative_models_are_useful/,SnowRipple,1462541667,"I really like the work on generative models that is going on right now in the deep learning society. From what I understand there are two main approaches now: variational autoencoders and adversarial networks. Although the idea of being able to generate completely new  images based on the training set images is very appealing and tempting I wonder how much value it actually have? What are possible uses of deep generative models in relation to images?

The ones I came up with are:
 -&gt; Being able to model abnormalities/anomalies
-&gt; Being able to build a ""manifold"" of all images and query it as needed.
-&gt; No need to define similarity metric.
-&gt; No need to recompute the whole model for ""out of sample"" examples as with LLE,Isomap or other manifold learning techniques.

Could it be possible to use e.g.  VAE for segmentation in a unsupervised way? Is there a way that generative models can be useful for segmentation at all?

I am asking because I really want to work with these models however in my domain (medical imaging) segmentation is the most important task so I am trying to justify the use of VAE or Adversarial autoencoders.",4,14
198,2016-5-6,2016,5,6,22,4i56fq,Parameter ranges for sigmoid and polynomial kernel,https://www.reddit.com/r/MachineLearning/comments/4i56fq/parameter_ranges_for_sigmoid_and_polynomial_kernel/,Bohemian90,1462542941,"Hello

I would like to use a SVM classifier with a sigmoid and polynomial kernel.

The sigmoid kernel has the following form: tanh(gamma * u'*v + coef0)

The polynomial kernel has the following form: (gamma * u'*v + coef0)^degree

Which parameter ranges are resonable to try for gamma and coef0?",0,0
199,2016-5-6,2016,5,6,23,4i5cw7,What do you use for automatic speech segmentation?,https://www.reddit.com/r/MachineLearning/comments/4i5cw7/what_do_you_use_for_automatic_speech_segmentation/,timburg,1462545497,"Put in a wav and annotation, and get out phones and segmentation points. 

I've seen http://www.sppas.org/ and http://latlcui.unige.ch/phonetique/easyalign.php, althought easyalign doesn't seem to support english. ",2,2
200,2016-5-6,2016,5,6,23,4i5eh1,COLT 2016 Accepted Papers,https://www.reddit.com/r/MachineLearning/comments/4i5eh1/colt_2016_accepted_papers/,Hydreigon92,1462546097,,0,12
201,2016-5-7,2016,5,7,1,4i5ufw,"A curated list of awesome TensorFlow experiments, libraries, and projects; from computer vision to auto-generated classical music! Inspired by awesome-machine-learning.",https://www.reddit.com/r/MachineLearning/comments/4i5ufw/a_curated_list_of_awesome_tensorflow_experiments/,Toyjust,1462551847,,1,25
202,2016-5-7,2016,5,7,2,4i67cm,Calculus &amp; Backprop: from Beginner to Expert,https://www.reddit.com/r/MachineLearning/comments/4i67cm/calculus_backprop_from_beginner_to_expert/,Kiuhnm,1462556548,"# What to expect

This started as an answer to a question that was asked on this forum, but I got carried away and wrote a full-fledged tutorial! It took me 10+ hours to complete it, so I hope you'll find it useful. In particular, I hope it'll help beginners understand Backprop once and for all.

I should warn you that I don't believe that giving specific and ad hoc derivations of the backprop is any useful in the long run. Many popular tutorials and books choose this approach, which, I think, isn't helping. I strongly believe that abstraction and modularization are the right way to explain things, when possible.

If you took some calculus course, but you didn't develop an intuition for it, maybe this short tutorial is what you need.

# Starting from the start

For simplicity, we'll assume that our functions are differentiable at any point of their domain and that every scalar is a real number.

Let's say we have an R-&gt;R function h(x). Let's focus on a particular x and consider the portion of h around x, i.e. h restricted to the interval [x-dx, x+dx]. Let's call it h{x,dx}. If dx is big, h{x,dx} may have some curvature, but if we reduce dx more and more, h{x,dx} will become flatter and flatter.

The main idea of a derivative is that if dx is infinitesimally small (but not zero), then h is linear in [x-dx, x+dx]. If h is linear in that interval, then we must have h(x+dx) = h(x) + c dx, for some c. In other words, if dx &gt; 0 and c &gt; 0, we start from (x, h(x)) and when we move to the right by dx we go up by c dx, for some c.

It turns out that the slope c of the linear curve is h'(x), also written as dh/dx. This makes sense; in fact, if we call dh the change in h, we have:

    h(x+dx) = h(x) + h'(x) dx
    h(x+dx) - h(x) = h'(x) dx
    dh = h'(x) dx
    dh/dx = h'(x)

To make things rigorous, we should say that dh is really a function:

    dh(x;dx) = h'(x) dx
    
dh(x;dx) is the differential of h in x. dh(x;dx) is the best linear approximation to h(x+dx)-h(x) at the point x. Note that dh(x;dx) and h(x+dx)-h(x) are seen as functions of dx and not of x, which can be seen as a fixed parameter in this context.

We may say that dh(x;dx) is that function such that

    lim[dx-&gt;0] (h(x+dx)-h(x) - dh(x;dx))/dx = 0

also written as

    h(x+dx)-h(x) - dh(x;dx) = o(x)

The derivative of h at x is just dh(x;dx)/dx, which is the slope of the linear approximation dh.

But we are applied mathematicians so we just write dh and we don't care about what pure mathematicians say.

#Chain rule

Let's consider h = g(f(x)) at the point t. What's the change in h if we move from t to t+dx?

    df = f'(t) dx
    
(Note that I often write '=' instead of 'approximately equal' for convenience.)

So f changes by df. Now what's the change in g from f(t) to f(t)+df? That's right: if f is at t, then g is at f(t)!       [note: there are no factorials in this post :)]

    dg = g'(f(t)) df

So, if we change x by dx, f changes by df and, as a consequence, g changes by dg. By substituting, we have

    dg = g'(f(t)) df = g'(f(t)) f'(t) dx
    g'(x) = dg/dx = g'(f(t)) f'(t)

That's the chain rule. Pretty obvious, right?

Applied mathematicians like to write it like this:

    dg/dx = dg/df df/dx

dg/df is the derivative of g at f(t) with respect to f(t), so the entire f(t) is treated like a variable. In other words, dg/df = g'(f(t)). The dx/dy notation is a little dangerous because it might not be clear at which point the derivatives are evaluated if one isn't careful.

#Chain rule in R^n

If we are in R^n things get more complicated, but not by much. Let's say we have

    h(x_1, x_2) = g(f_1(x_1, x_2), f_2(x_1,x_2))

This means that h, g, f1 and f2 take two values and return one value. If we define f as a function which takes two values x1, x2 and returns two values f1(x1,x2), f2(x1,x2), then we can write:

    h(x_1, x_2) = g(f(x_1, x_2))

If we now define x = (x_1, x_2) as a 2d vector, we can write:

    h(x) = g(f(x))

Now we have partial derivatives @f/@x1, @f/@x2, etc., but almost nothing changes. If we change x1 then f changes and so g changes as well. Let's say we are at x = (t,u) and we change t and u by dt and du, respectively. For now, let's pretend that '@' = 'd':

    @f = f_{x_1}(t,u) @x_1

where the second term is the partial derivative at (t,u) of f with respect to x1. The partial derivative of a function with respect to a particular variable z is just the derivative of that function with respect to z if we pretend that the other variables are constant (say some fixed parameters). In other words, the partial derivative tells us by how much the function changes if we change one particular variable and keep all the other variables fixed. For instance,

    @(5 x^2 - x y^2)/@x = 10x - y^2                  [y^2 is just a constant, like 5]
    @(5 x^2 - x y^2)/@y = -2xy                          [now x is just a constant]

Let's get back to h(x) = g(f(x)) and remember that it's equivalent to

    h(x_1, x_2) = g(f_1(x_1, x_2), f_2(x_1,x_2))

A graph will help us see what changes what:

              g(y_1, y_2)
            /            \              Note:
           /              \             y_1 = f_1(x_1,x_2)
          /                \            y_2 = f_2(x_1,x_2)
    f_1(x_1, x_2)     f_2(x_1, x_2)
         \      \    /       /
          \       \/        /
           \     /  \      /
            \  /      \   / 
            x_1        x_2

So x1 changes both f1 and f2 which both change g. Since the changes are linear, they just add up. Basically, changing g by simultaneously changing f1 and f2, is like changing g by first changing f1 and then changing f2 (or first f2 and then f1). It's like saying that if you are at (0,0) and you want to reach (3,4) it doesn't matter if you first go to (3,0) or (0,4). The order doesn't matter and, moreover, the total change is just the sum of the individual changes.

Now let's compute @h/@x1 (u,t), i.e. how much h changes if we change x1 when we are at (u,t):

    @f_1 = f_1_{x_1}(u,t) @x_1
    @f_2 = f_2_{x_1}(u,t) @x_1
    @h = g_{y_1}(f_1(u,t),f_2(u,t)) @f_1 +
         g_{y_2}(f_1(u,t),f_2(u,t)) @f_2

As we can see, x1 modifies f1 and f2 which, together, modify g. Always note at which points the derivatives are calculated!

To get @h/@x1 we must substitute:

    @h = g_{y_1}(f_1(u,t),f_2(u,t)) @f_1 +
         g_{y_2}(f_1(u,t),f_2(u,t)) @f_2
       = g_{y_1}(f_1(u,t),f_2(u,t)) f_1_{x_1}(u,t) @x_1 +
         g_{y_2}(f_1(u,t),f_2(u,t)) f_2_{x_1}(u,t) @x_1
       = [g_{y_1}(f_1(u,t),f_2(u,t)) f_1_{x_1}(u,t) + 
          g_{y_2}(f_1(u,t),f_2(u,t)) f_2_{x_1}(u,t)] @x_1

Therefore:

    @h/@x_1 = [g_{y_1}(f_1(u,t),f_2(u,t)) f_1_{x_1}(u,t) + 
               g_{y_2}(f_1(u,t),f_2(u,t)) f_2_{x_1}(u,t)]

Let's rewrite it more concisely:

    @h/@x_1 = @g/@y_1 @y_1/@x_1 + @g/@y_2 @y_2/@x_1
    
Since h = g(y_1,y_2), we can also write

    @h/@x_1 = @h/@y_1 @y_1/@x_1 + @h/@y_2 @y_2/@x_1

There are many ways to write these expressions. Some people give the variables the same names of the functions they refer to. For instance, they write

    y = y(x)
    
which means that y is both a variable and a function of the variable/function x.

# Why backprop?

Now let's consider this graph:

          e
        /   \
      d_1   d_2
        \   /
          c
        /   \
      b_1   b_2
        \   /
          a

We want to compute de/da. Note that we don't write @e/@a. That's because 'e' can be seen as a function of the only 'a', thus we write de/da like we did in the 1D case (in fact, we *are* in the 1D case). However, note that 'e' is defined as a function which takes two values. It's the composition represented by the entire graph that's a function of the only 'a'.

We can see that there are 4 paths from 'a' to 'e', so 'a' influences 'e' in 4 ways and we have:

    de/da = path[a,b_1,c,d_1,e] + 
            path[a,b_1,c,d_2,e] + 
            path[a,b_2,c,d_1,e] + 
            path[a,b_2,c,d_2,e]
          = db_1/d_a @c/b_1 dd_1/dc @e/@d_1 +
            db_1/d_a @c/b_1 dd_1/dc @e/@d_2 +
            db_2/d_a @c/b_1 dd_1/dc @e/@d_1 +
            db_2/d_a @c/b_1 dd_1/dc @e/@d_2

Note that we sum paths and multiply along the paths. Let's examine one path:

    db_1/d_a @c/b_1 dd_1/dc @e/@d_1

This means that we change 'a' so we change b_1, so we change 'c', so we change d_1, and so we change 'e'.

Note that the number of paths is exponential wrt the length of the path. Every time we add a bifurcation the total number of paths doubles.

Computing the partial changes along the single paths is a waste of time because many computations are repeated. Let's simplify things.

Here's the stupid way again:

    de/da = path[a,b_1,c,d_1,e] + 
            path[a,b_1,c,d_2,e] + 
            path[a,b_2,c,d_1,e] + 
            path[a,b_2,c,d_2,e]

Here's the smart way:

    de/da = (path[a,b_1,c] + path[a,b_2,c]) * 
            (path[c,d_1,e] + path[c,d_2,e])

More explicitly:

    de/da = (path[a,b_1,c] + path[a,b_2,c]) * 
            (path[c,d_1,e] + path[c,d_2,e])
          = (db_1/da @c/@b_1 + db_2/da @c/@b_2) *
            (dd_1/dc @e/@d_1 + dd_2/dc @e/@d_2)

Note that this is just

    de/da = dc/da de/dc

# Backprop in action

Let's consider the same graph again:

          e
        /   \
      d_1   d_2
        \   /
          c
        /   \
      b_1   b_2
        \   /
          a

We want to evaluate de/da at a=3. During the forward phase, we compute the values of the variables (defined through functions which we omitted for more clarity):

          e              8        /\
        /   \          /   \     /  \
      d_1   d_2      -1     2     ||
        \   /          \   /      ||
          c              4        ||
        /   \          /   \      ||
      b_1   b_2       5     7     ||
        \   /          \   /      ||
          a              3        ||

---

Just to clarify, every variable in the graph depends directly on the variable(s) just below. For instance, c depends on b1 and b2, while b1 depends on a. In other words, there are some functions f and g such that

    c = f(b_1, b_2)
    b_1 = g(a)
    
We want to compute de/da(3) so we let a = 3. Now we must compute the values of all the other variables going up. I just put some arbitrary numbers in the graph to make things more concrete.

---

Now we perform the backward phase which is usually called backprop, short for backward propagation:

          e                             8                      ||
        /   \         @e/@d_1(-1,2)   /   \   @e/@d_2(-1,2)    ||
      d_1   d_2                     -1     2                   ||
        \   /              de/dc(4)   \   /   de/dc(4)         ||
          c                             4                      ||
        /   \          @e/@b_1(5,7)   /   \   @e/@b_2(5,7)     ||
      b_1   b_2                      5     7                   ||
        \   /              de/da(3)   \   /   de/da(3)        \  /
          a                             3                      \/

Let's examine block d_1 in detail:

    @e/@d_1(-1,2)
          |        input
          v  
     +---------+
     |         |
     |   d_1   |
     |         |
     +---------+
          |        output
          v
      de/dc(4)
     
During backprop, d1 receives @e/@d1(-1,2) in input and outputs de/dc(4). Here's how d1 does it:

    de/dc(4) = @e/@d_1(-1,2) dd_1/dc(4)

**Note:** in the expression above we're only considering the de/dc(4) coming from the left path (i.e. c&lt;-d_1&lt;-e), but in reality we should sum both the de/dc(4) to get the real ""de/dc(4)"". Unfortunately, I don't know how to make my notation more clear without coming up with some weird convention.
    
There's an important point to be made. We can write @e/@d1(-1,2) because 'e' can be seen as a function of d1 and d2 alone. de/dc(4) is also correct because 'e' can also be seen as a function of 'c'. We can't write @e/@d1(-1) because 'e' depends not only on d1 but also on d2. I'll explain this better in the next section.

It goes without saying--but I'm saying it anyway--that we're focusing on a single block because once we know how the forward/backward propagation works wrt a single block, then we know how it works wrt the entire graph. This is the modularization I was talking about in the *What to expect* section at the beginning. Libraries such as Theano and Tensorflow are based on this very modularization so it's important that you understand it very well.

# Backprop with blocks

Let's consider a more general case, now:

                 Note: z_0 = f(x_0,y_0,W_0)
                         q = all the input sent to L

     Forward phase                       Backward phase
                              
       .   .   .                     .          .          .
       .   .   .                     .          .          .
       .   .   .                     .          .          .
       |   |   |                     |          |          |
      z_0 z_0 z_0                @L/@z(q)    @L/@z(q)   @L/@z(q)
       ^   ^   ^                     |          |          |
       |   |   |                     +-------+  |  +-------+
       |   |   |                             |  |  |                  
       |   |   |                             v  v  v
    +-------------+                      +-------------+                
    |             |                      |             |
    |z = f(x,y,W) |&lt;---- W_0             |z = f(x,y,W) |----&gt; @L/@W(q)
    |             |                      |             |    
    +-------------+                      +-------------+                
          ^ ^                                  / \                    
         /   \                                /   \                   
        /     \                              v     v
      x_0     y_0                       @L/@x(q) @L/@y(q)

We are the block depicted above and we want to compute gradients/derivatives of the loss function L with respect to our inputs x, y and W (they're inputs in the forward phase). In particular, W is our parameter, but we can see it as a normal input. There's nothing special about it, except for the fact that it isn't computed from other values.

Note that the three z0 on the left are all equal, but the three @L/@z(q) on the right are all different because they come from different paths. In other words, z influences L indirectly by influencing three different blocks which it's connected to (not shown in the picture).

What's q? Why not just z0? The problem is that L may receive input from other blocks on other paths. The variable q represents all the input received by L. Since z0 influences L, it's clear that z0 influences the input q, but it may not completely determine it.

Let's say L = (...)k, where k is some input. If k = 0, then L = 0 as well and all the derivatives become 0, including @L/@x(q), @L/@y(q) and @L/@W(q)! So, all the input is important because it determines at which point the derivatives are computed.

We receive three instances of @L/@z(q), each of which measures, as you should know quite well by now, the increment in L when z is incremented from z0 to z0+eps for a little eps (the bigger the epsilon, the worse the estimate, unless there is no nonlinearity involved).

We, the block, know how z is computed from x0, y0 and W0 so we know how to determine how z changes when we move away from z0 = (x0,y0,W0). Here are the derivations:

    @L/@z(q) = sum of the three @L/@z(q) we received in input (from above)
            
    @L/@x(q) = @L/@z(q) @z/@x(x_0,y_0,W_0)
             = @L/@z(q) f_x(x_0,y_0,W_0)
    @L/@y(q) = @L/@z(q) @z/@y(x_0,y_0,W_0)
             = @L/@z(q) f_y(x_0,y_0,W_0)
    @L/@W(q) = @L/@z(q) @z/@W(x_0,y_0,W_0)
             = @L/@z(q) f_W(x_0,y_0,W_0)

Note that while @L/@x depends on q (all the input to L), @z/@x depends on x_0, y_0 and W_0, i.e. all the input to 'z'. Again--I'll never grow tired of saying it--@z/@x depends on all the inputs x_0, y_0, and W_0 because we need to compute the derivative wrt x at the point (x_0,y_0,W_0). It's the same old story: we need to consider all the input even if we're deriving just wrt a part of it.

So, the input from below tells us where we are (it was computed during the forward phase) and we compute the partial derivatives of f at *that* point with respect to the inputs. Once we know @L/@z and @z/@x (or y, W) we can compute @L/@x by multiplying them (BTW, note that it's as if @z canceled out).

# Generalization I

             q = all the input sent to L

       Forward phase            Backward phase
                              
             .                         .
             .                         .
             .                         .
             |                         |
      f(u_1,...,u_n)               @L/@z(q)
             ^                         |
             |                         v         
    +-----------------+       +-----------------+  
    |                 |       |                 |  
    |z = f(x_1,...x_n)|       |z = f(x_1,...x_n)|
    |                 |       |                 |  
    +-----------------+       +-----------------+  
       ^   ^  ...  ^            |     ...     |
       |   |  ...  |            v     ...     v
      u_1 u_2 ... u_n      @L/@x_1(q)    @L/@x_n(q)

One @L/@z is enough because we saw that if there are more than one we can just add them up.

The derivations are:

    @L/@x_i(q) = @L/@z(q) @z/@x_i(u_1,...,u_n)
               = @L/@z(q) f_{x_i}(u_1,...,u_n)

# Generalization I (vector form)

This is equivalent to the previous case but lists of scalars have been replaced with vectors. Vectors are indicated with a horizontal bar (but not always).

          q = all the input sent to L

       Forward phase       Backward phase
                                         
             .                    .      
             .                    .      
             .                    .      
             |_                   | 
            f(u)               @L/@z(q) 
             ^                    |
             |                    |      
             |                    v      
        +---------+          +---------+ 
        |      _  |          |      _  | 
        |z = f(x) |          |z = f(x) | 
        |         |          |         | 
        +---------+          +---------+ 
             ^                    |
             |                    |
             _                    v
             u                 @L/@x(q)
              
The derivations are:

                                  _ 
    @L/@x_i(q) = @L/@z(q) @z/@x_i(u)
                                  _
               = @L/@z(q) f_{x_i}(u)
                                                  
The gradient of L at q with respect to the vector x is defined as

    __     
    \/_x L(q) = [@L/@x_1(q)  ...  @L/@x_n(q)]^T        (column vector)

The derivation can thus be rewritten as

    __                   __     _
    \/_x L(q) = @L/@z(q) \/_x z(u)             (scalar times a column vector)

# Generalization II

Now z is a vector as well, i.e. f is an R^n-&gt;R^m function, or an m-dimensional vector of R^n-&gt;R functions.

          q = all the input sent to L

       Forward phase       Backward phase
                                         
             .                    .      
             .                    .      
             .                    .      
             |_               __  |  
            f(u)              \/_z L(q)
             ^                    |
             |                    |      
             |                    v      
        +---------+          +---------+ 
        |_     _  |          |_     _  | 
        |z = f(x) |          |z = f(x) | 
        |         |          |         | 
        +---------+          +---------+ 
             ^                    |
             |                    |
             _                __  v  
             u                \/_x L(q)

You should be pretty comfortable with this by now, but let's repeat what it means. Modifying u_i may modify every single z_j because f may use every single x_i to compute every single z_j. Then every z_j may modify L.

We can represent this with a graph:

          L
        / | \            This graph has
       /  .  \             2m edges
      /   .   \
    z_1  ...  z_m 
      \   .   /
       \  .  /
        \ | /  
         x_i
      
Now we can write the expression for @L/@x_i(q):

                                                   _
    @L/@x_i(q) = \sum_{j=1}^m @L/@z_j(q) @z_j/@x_i(u)
                  __            _      _
               = [\/_z L(q)]^T @z/@x_i(u)
                 
The term @z/@x_i(u) is a jacobian and is defined like this

            _               _                  _
    @z/@x_i(u) = [@z_1/@x_i(u)  ...  @z_m/@x_i(u)]^T     (column vector)
    
The Jacobian is a generalization of the gradient and it's, in general, the derivative of an R^n-&gt;R^m function. If a function f:R^n-&gt;R^m is differentiable at u, then f can be locally approximated by a linear function expressed by the Jacobian:

      _ __      _        _ _  __
    f(u+du) ~ f(u) + @f/@x(u) du

where ~ means ""approximately equal"". If f is linear, we get an equality, of course.
    
If f is R-&gt;R, this becomes

    f(u+du) ~ f(u) + f'(u) du
    
We haven't properly defined the (general) Jacobian yet. Let f(x) be an R^n-&gt;R^m differentiable function (at least at u). The Jacobian of f at u with respect to x is @f/@x(u) defined as

         _ _                    _
    [@f/@x(u)]_{i,j} = @f_i/x_j(u)
    
As we said before, f can be seen as a vector of R^n-&gt;R functions each of which takes x and returns a single coordinate of z = f(x). Therefore, @f/@x(u) is a matrix whose i-th row is the transpose of the gradient of f_i at u with respect to x:

         _ _            __       _
    [@f/@x(u)]_{i,.} = [\/_x f_i(u)]^T           (row vector)

To remember the definition of the Jacobian, note that with matrices the order is always rows-&gt;columns:

    1. If A is in R^{mxn} then A has m rows and n columns
    2. A_{i,j} is the element on the i-th row and j-th column
    3. @z/@x is the matrix where z moves vertically across rows and x moves horizontally across columns

The gradient, when it exists, is the transpose of the Jacobian. In fact, if f(x) is R^n-&gt;R then

    __     _        _ _
    \/_x f(u) = @f/@x(u)^T               (column vector)
    
Let's get back to our blocks now. We derived the following:

                                                   _
    @L/@x_i(q) = \sum_{j=1}^m @L/@z_j(q) @z_j/@x_i(u)
                  __            _      _
               = [\/_z L(q)]^T @z/@x_i(u)

The result is a scalar so we can transpose it without changing its value:

                   _      _     __     
    @L/@x_i(q) = [@z/@x_i(u)]^T \/_z L(q)
    
From this we get

    __            _  _ _     __     
    \/_x L(q) = [@z/@x(u)]^T \/_z L(q)

This formula works even when we're dealing with tensors X, U, and Z. The trick is to vectorize the tensors. For instance, consider the following 3-dimensional tensor:
                
    X_{1,.,.} = [1 2 3]
                [4 5 6]
                [7 8 9]

    X_{2,.,.} = [a b c]
                [d e f]
                [g h i]

We can vectorize X as follows:

    vec(X) = [1 2 3 4 5 6 7 8 9 a b c d e f g h i]
    
and so, for instance, vec(X)_{14} = X_{2,2,2}. Of course, all the tensors must be vectorized consistently or we'll get wrong results.

# Dynamic Programming

Although the algorithm is called backprop, which suggests that we retrace our steps, we can also use dynamic programming. That is, we can compute the derivatives recursively in a lazy way (i.e. only when needed) and save the already computed derivatives in a table lest we repeat computations.

For instance, consider this graph:

    L &lt;--- g &lt;--- W_1 ---&gt; h ---&gt; k
    ^                             ^
    |                             |
    b &lt;--- c &lt;--- W_2 ---&gt; j -----+
    ^      ^
    |      |
    f      e &lt;--- W_3
    ^
    |
    p

We only want to compute @L/@W_1, @L/@W_2 and @L/@W_3. I'll write the steps performed by a dynamic programming algorithm which computes the 3 derivatives. I'll use the following format:

    operation 1        &lt;--- op 1 calls recursively op 1a and op 1b
      operation 1a     
      operation 1b     &lt;--- op 1b calls rec. op 1b1 and op 1b2
        operation 1b1
        operation 1b2
    operation 2
    
Here's the graph again (for your convenience) and the steps, assuming that the ""forward"" phase has already taken place:

    [Note]
    In the code on the right:
      'A-&gt;B' means 'compute A and store it in B'
      'A&lt;-B' means 'read A from B'
                                         
    L &lt;--- g &lt;--- W_1 ---&gt; h ---&gt; k      @L/@W_1 -&gt; table[W_1]
    ^                             ^        @g/@W_1
    |                             |        @L/@g -&gt; table[g]
    b &lt;--- c &lt;--- W_2 ---&gt; j -----+      @L/@W_2 -&gt; table[W_2]
    ^      ^                               @c/@W_2
    |      |                               @L/@c -&gt; table[c]
    f      e &lt;--- W_3                        @b/@c
    ^                                        @L/@b -&gt; table[b]
    |                                    @L/@W_3 -&gt; table[W_3]
    p                                      @e/@W_3
                                           @L/@e
                                             @c/@e
                                             @L/@c &lt;- table[c]

Note that we don't visit every node of the graph and that we don't recompute @L/@c which is needed for both @L/@W_2 and @L/@W_3.

# Efficiency

Backprop is not optimum. In fact, computing derivatives over a graph is NP-complete because expressions can be simplified in non-obvious ways. For instance, s'(x) = s(x)(1 - s(x)), where s is the sigmoid function. Since s(x) = 1/(1 + exp(-x)), an algorithm might waste time computing and composing derivatives without coming up with the simplified expression I wrote above. This argument is only valid if the graph is analyzed once and then used many times to compute the derivatives.

There's another thing to be said about the efficiency of backprop or its dynamic programming variant described above. We saw that in general each block of the graph performs the following computation:

    __            _  _ _     __     
    \/_x L(q) = [@z/@x(u)]^T \/_z L(q)

This is a matrix-vector multiplication which returns another vector. So, in general, along a path x-&gt;a-&gt;b-&gt;...-&gt;y-&gt;z-&gt;L we have something like

    __                                    __
    \/_x L = @a/@x^T @b/@a^T ... @z/@y^T  \/_z L

Backprop computes this product from right to left (foldr):

    __                                       __
    \/_x L = (@a/@x^T (@b/@a^T ... (@z/@y^T  \/_z L)...))
    
If D is the maximum number of dimensions of the vectors involved and N is the number of matrix-vector multiplications, the whole product takes O(N D^2) time.

Computing the same product from left to right (foldl) would take O(N D^3) time because it would involve matrix-matrix multiplications.

So it seems that backprop does the right thing. But what happens if x is just a scalar and L a vector? The situation is reversed! Now we have a (row) vector on the left and all matrices on the right:
    
    @L/@x^T = @a/@x^T @b/@a^T ... @z/@y^T  @L/@z^T
    
Basically, you just need to rewrite the two gradients as Jacobians (remembering that they're one the transpose of the other) and the formula will hold even when L is a vector and x a scalar.

That's it. I hope you found this tutorial useful. Let me know if you find any mistakes or something is unclear.",39,213
203,2016-5-7,2016,5,7,3,4i6gbv,Was David Mackay's Cambridge site taken down?,https://www.reddit.com/r/MachineLearning/comments/4i6gbv/was_david_mackays_cambridge_site_taken_down/,[deleted],1462559833,[deleted],1,0
204,2016-5-7,2016,5,7,4,4i6mnr,Using Machine Learning to Predict Out-Of-Sample Performance of Trading Algorithms,https://www.reddit.com/r/MachineLearning/comments/4i6mnr/using_machine_learning_to_predict_outofsample/,DataRobotOfficial,1462562158,,0,1
205,2016-5-7,2016,5,7,6,4i79yc,Facebook makes AI to make AI,https://www.reddit.com/r/MachineLearning/comments/4i79yc/facebook_makes_ai_to_make_ai/,geemili,1462571025,,7,0
206,2016-5-7,2016,5,7,8,4i7ljj,Why do You Need an Alemite Grease Pump?,https://www.reddit.com/r/MachineLearning/comments/4i7ljj/why_do_you_need_an_alemite_grease_pump/,jackerfrinandis,1462575909,,0,1
207,2016-5-7,2016,5,7,8,4i7mky,Data munging and automation tools for healthcare.,https://www.reddit.com/r/MachineLearning/comments/4i7mky/data_munging_and_automation_tools_for_healthcare/,[deleted],1462576357,[deleted],1,0
208,2016-5-7,2016,5,7,9,4i7tno,A Machine Learning approach to writing a good GitHub README,https://www.reddit.com/r/MachineLearning/comments/4i7tno/a_machine_learning_approach_to_writing_a_good/,rhiever,1462579604,,0,0
209,2016-5-7,2016,5,7,9,4i7wl3,How does one infer the noise/error model given X measurements?,https://www.reddit.com/r/MachineLearning/comments/4i7wl3/how_does_one_infer_the_noiseerror_model_given_x/,Zeekawla99ii,1462580974,"What resources are available for applying inference/computational statistics to infer the underlying error/noise model, given X measurements from some apparatus? 

My idea is this: let's say we use some apparatus (e.g. a telescope, or a medical test) and we make X number of measurements simultaneously. The X measurements were taken at the same time t, and therefore should be biased in some manner (due to the test environment and so on.)

Assume there is some (unknown) stochastic process that governs instrument noise for each sample, and some (unknown) underlying model of the noise between each of the X simultaneous measurements. That is, if we repeat this experiment, the new measurement will continue to be biased by this spatial/temporal noise due to the instrument. 

Given thousands of repeated measurements, what methods exist in the literature to infer the noise/error model in this data? 

Latent variable models maybe? 
",11,0
210,2016-5-7,2016,5,7,9,4i7znr,Graphing Hypothesis with uni variate linear regression,https://www.reddit.com/r/MachineLearning/comments/4i7znr/graphing_hypothesis_with_uni_variate_linear/,ItsMeNotYouJustUs,1462582510,"Hello, I've been following the machine learning videos on coursera with Andrew ng as the instructor. I don't know any math beyond a high school level so this is a bit tricky. When he introduced the hypothesis function https://gyazo.com/573ff97d5efdfbc5110c46ed2f62614d
I didn't understand how he was graphing this and what the H theta (x) meant when it came to graphing. I've searched on the internet a lot and couldn't find a video explaining what this means at all. If anyone would like to point me in the right direction that would be greatly appreciated.

I just wanted to clarify real quick I'm only having trouble with the  X's I know theta's are variables and what not. I can't figure out for the life of my what the x at the end means? Does he want me to multiply it by the current X? In other words I guess, what does  the variable X represent?",3,0
211,2016-5-7,2016,5,7,11,4i8dd2,"GeForce GTX 1080: 9 Teraflops = 1.3x Titan X. 8GB, 320 GB/s, $599, May 27th.",https://www.reddit.com/r/MachineLearning/comments/4i8dd2/geforce_gtx_1080_9_teraflops_13x_titan_x_8gb_320/,modeless,1462589245,,69,176
212,2016-5-7,2016,5,7,12,4i8grj,Any open source implementations of Microsoft's Matchbox recommender?,https://www.reddit.com/r/MachineLearning/comments/4i8grj/any_open_source_implementations_of_microsofts/,[deleted],1462590970,[deleted],1,0
213,2016-5-7,2016,5,7,12,4i8kna,Is there anything like UIMA / GATE for images?,https://www.reddit.com/r/MachineLearning/comments/4i8kna/is_there_anything_like_uima_gate_for_images/,numorate,1462592981,cf https://uima.apache.org/ and  https://gate.ac.uk/,0,2
214,2016-5-7,2016,5,7,12,4i8l8o,Figuring out how many sides a polygon has,https://www.reddit.com/r/MachineLearning/comments/4i8l8o/figuring_out_how_many_sides_a_polygon_has/,pastaking,1462593294,"The challenge: Given many images of 2D polygons (can be concave or convex), use some machine learning technique to create a model to determine how many sides the polygon has.

For example, here are some 8 sided polygons: http://imgur.com/sB6hiJn

I've tried using logistic regression and a neural net, neither yields good results - but I'm a ML beginner - how would you guys approach this problem?

If anyone's interested in solving this, I'm happy to share the data / code to generate the data.",12,2
215,2016-5-7,2016,5,7,12,4i8ljc,"This Week in Machine Learning: May 6th, 2016",https://www.reddit.com/r/MachineLearning/comments/4i8ljc/this_week_in_machine_learning_may_6th_2016/,DavidAJoyner,1462593459,,1,0
216,2016-5-7,2016,5,7,13,4i8mb0,LL-551 Fully Automatic Wire Cut Strip Crimp Machine-Crimping Presses,https://www.reddit.com/r/MachineLearning/comments/4i8mb0/ll551_fully_automatic_wire_cut_strip_crimp/,yueyueniao1112,1462593868,,0,1
217,2016-5-7,2016,5,7,13,4i8pfj,Using RNN sequence to sequence learning for sorting sequences.,https://www.reddit.com/r/MachineLearning/comments/4i8pfj/using_rnn_sequence_to_sequence_learning_for/,shazzyj,1462595740,[removed],0,1
218,2016-5-7,2016,5,7,14,4i8wn4,IBM releases cloud platform for their 5 qubit universal instance,https://www.reddit.com/r/MachineLearning/comments/4i8wn4/ibm_releases_cloud_platform_for_their_5_qubit/,dmitry_ulyanov,1462600167,,0,2
219,2016-5-7,2016,5,7,14,4i8x0a,Concerning Collaborative Filtering and Content-based Recommendations,https://www.reddit.com/r/MachineLearning/comments/4i8x0a/concerning_collaborative_filtering_and/,[deleted],1462600398,[deleted],0,1
220,2016-5-7,2016,5,7,17,4i9bh4,Could we program a law-making ai?,https://www.reddit.com/r/MachineLearning/comments/4i9bh4/could_we_program_a_lawmaking_ai/,altegedanken,1462611198,"Hi, I'm new to this subreddit and kind of a noob in machine learning. But I'm curious: What would it take to program a law-making AI? 

Let's say I give the AI all kinds of statistics, existing laws, and so on  and so on. Then I pose the question if you should lower the taxes for the rich. Could an ai give me an an answer?",7,0
221,2016-5-7,2016,5,7,18,4i9g8x,MIXER - Sequence Level Training with Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/4i9g8x/mixer_sequence_level_training_with_recurrent/,pilooch,1462615081,,1,8
222,2016-5-7,2016,5,7,19,4i9hx4,Near Duplicate Detection using K-means?,https://www.reddit.com/r/MachineLearning/comments/4i9hx4/near_duplicate_detection_using_kmeans/,shadow12348,1462616334,"I'm looking to pursue a novel method of near duplicate detection. Shingling and hashing seems way too mainstream and blunt. There must be a smarter way of doing this. Any hints or ideas?

Is it possible to train a neural network to identify duplicate documents?

Will K-means clustering on a dataset of documents with a bunch of duplicates be worth investigating, to achieve this?

EDIT: I'm trying to basically try out a bunch of different ways to find duplicates and see what works best and maybe stumble upon something that hasn't been tried before. Shingling and hashing of course is the most common method which is why I posted here asking to see if someone's tried something else or has any ideas. Basically what I'm doing is filtering a massive archive of webpages crawled over time (HTML text mainly), so there are different languages, millions of duplicates/near-duplicates and would like to get some kind of cool way to filter this collection. I'm using Scala and Spark for this. 

Thanks in advance!",13,0
223,2016-5-7,2016,5,7,21,4i9vjb,Open-source Interactive Semi-Supervised Learning tool like in Jeremy Howard TEDx talk,https://www.reddit.com/r/MachineLearning/comments/4i9vjb/opensource_interactive_semisupervised_learning/,andyandy16,1462625625,,11,23
224,2016-5-7,2016,5,7,21,4i9vni,Video: Seldon @ Techstars Demo Day  open-source machine learning platform,https://www.reddit.com/r/MachineLearning/comments/4i9vni/video_seldon_techstars_demo_day_opensource/,ahousley,1462625671,,0,0
225,2016-5-7,2016,5,7,22,4i9xf4,Anyone ever heard of a reinforcement learning approach to a bioinformatics problem?,https://www.reddit.com/r/MachineLearning/comments/4i9xf4/anyone_ever_heard_of_a_reinforcement_learning/,osazuwa,1462626701,,4,0
226,2016-5-7,2016,5,7,23,4ia6ds,State of the art for improving classification accuracy using additional unlabelled training data?,https://www.reddit.com/r/MachineLearning/comments/4ia6ds/state_of_the_art_for_improving_classification/,hughperkins,1462631390,"State of the art for improving classification accuracy on labelled data, using additional unlabelled training data?  (eg I guess that GAN/LAPGAN, auto-encoders, sLDA, and stacked RBMs could be used for this?)

Edit: Thanks for your replies! :-)  The papers provided are very useful to me :-)  Note that it looks like there are two ways of interpreting this task:

1. The unlabelled samples fall into the exact same classes as the labelled data.  This is the case if we take eg cifar training data, and use 4000 labelled, and leave the other 46000 as unlabelled
2. The unlabelled data might or might not fall into the same classes.  For example, we could be testing on cifar, but provide some unlabelled images from a random google search, or from diverse imagenet categories.  This is clearly a harder task, but also more general

I'm interested in both of these tasks :-)",7,10
227,2016-5-8,2016,5,8,2,4iavyc,Using Graphframes for Social Recommendation,https://www.reddit.com/r/MachineLearning/comments/4iavyc/using_graphframes_for_social_recommendation/,mhfirooz,1462642397,,0,0
228,2016-5-8,2016,5,8,2,4iayx8,how the narmalization partion term is computed in gibbs sampling,https://www.reddit.com/r/MachineLearning/comments/4iayx8/how_the_narmalization_partion_term_is_computed_in/,John_Smith111,1462643589,"hello all

i read the gibbs distribution formula at http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf 
page7 

i would like to know how to compute the integral at the partion term ?

Thanks all",4,0
229,2016-5-8,2016,5,8,3,4ib167,"Train a convolutional net for smile detection in less than a minute (Keras, Jupyter Notebook)",https://www.reddit.com/r/MachineLearning/comments/4ib167/train_a_convolutional_net_for_smile_detection_in/,kcimc,1462644523,,14,93
230,2016-5-8,2016,5,8,3,4ib2oa,how the statistical relaxation works?,https://www.reddit.com/r/MachineLearning/comments/4ib2oa/how_the_statistical_relaxation_works/,John_Smith111,1462645124,[removed],1,0
231,2016-5-8,2016,5,8,4,4ib979,Logistic Regression explained with examples and code,https://www.reddit.com/r/MachineLearning/comments/4ib979/logistic_regression_explained_with_examples_and/,ataspinar,1462647802,,0,1
232,2016-5-8,2016,5,8,4,4iba8w,A good test of Google Deepmind would be whether it can beat top chess programs.,https://www.reddit.com/r/MachineLearning/comments/4iba8w/a_good_test_of_google_deepmind_would_be_whether/,ihaphleas,1462648232,,11,0
233,2016-5-8,2016,5,8,4,4ibh3x,LSTM/NTM Single Precision Doubts,https://www.reddit.com/r/MachineLearning/comments/4ibh3x/lstmntm_single_precision_doubts/,MindYarn,1462651194,"I am currently working on a task using a simplified task specific neural turing machine (NTM) like structure, controlled by LSTMs. I'm observing quite big performance difference between FP32 and FP64, where I measure a validation set error rate that drops from ~15% to ~13.5% when I switch from FP32 to FP64, and this is after quite a lot of tuning of the FP32 version, using ""adam"" as optimizer. During testing the nets are robust though, and could probably use even 8 bit representation.

The current consensus seems to be that FP32 is enough to train DNNs, and FP16 will also be good enough. But is this also true for RNN/LSTM? And if FP64 brings so much, wouldn't even higher precision theoretically give even better results? I have not been able to find any paper examining float precision importance for RNNs, anyone read something interesting? Any anecdotal observations? My current thought is that this must be related to vanishing gradient problems in the NTM memory.",16,8
234,2016-5-8,2016,5,8,5,4ibnjj,What is the difference in performance of GBR trees versus random forests regression?,https://www.reddit.com/r/MachineLearning/comments/4ibnjj/what_is_the_difference_in_performance_of_gbr/,Zeekawla99ii,1462653936,"It appears gradient boosted regression trees have done far better in several ML competitions. However, random forests regression normally works exceptionally well for virtually any problem. 

Are there any hard numbers regarding the performance between these two algorithms?",6,2
235,2016-5-8,2016,5,8,5,4ibofu,Which classifier to use?,https://www.reddit.com/r/MachineLearning/comments/4ibofu/which_classifier_to_use/,masm64,1462654306,"I have a course project that I need to finish. I'm using Weka 3.8 and I need to classify text. The result needs to be as accurate as possible. We received a train and a test .arff file. We need to train it with the train file of course, and then let it classify the test file. The professor uploaded a 100% accurate classification of the test file. We need to upload our own results and than the system compares the two files. For now I've been using a FilteredClassifier composed of SMO and StringToWordVector with Snowball stremmer, but I can't get a better accuracy than 65.9% for some reason (this is not the split accuracy, but the one I get when the system compares my results to the 100% accurate one). I can't figure out why.

The train.arff file: http://pastebin.com/QmpZ7znX
The test.arff is this: http://pastebin.com/tWwLT6Sr

My WEKA configuration:
http://imgur.com/a/xr6u9

He told us that there are some instances when in the .arff file some ingredients amongst the @data are seperated with ',' by accident and that there are words that occur frequently and that those might not help much. I don't know if this is important or not. Is there any way I could improve the classification accuracy? Am I even using the right classifier for the job? Thanks in advance!

",2,0
236,2016-5-8,2016,5,8,6,4ibuej,Cross-validation for big data: what is the best stratification strategy?,https://www.reddit.com/r/MachineLearning/comments/4ibuej/crossvalidation_for_big_data_what_is_the_best/,chupvl,1462656899,"Hello!
Need suggestions on the following: I have a big training set with ~2mln entities with ~200 binary labels per entity, in total around 16k labels. What is the best way to approach data stratification for supervised learning in a cross-validation manner? Ideally optimal density of the labels across folds...

I have several ideas in mind
1. Clustering by labels and selecting the representatives for every cluster. Issue - labels are sparse, thus a lot of NA.
2. Random sampling via scikit sklearn.cross_validation.StratifiedShuffleSplit",3,3
237,2016-5-8,2016,5,8,6,4ibv66,Questions thread #5 2016.05.07,https://www.reddit.com/r/MachineLearning/comments/4ibv66/questions_thread_5_20160507/,feedtheaimbot,1462657255,"[New thread](https://www.reddit.com/r/MachineLearning/comments/4kq3jx/questions_thread_6_20160523/)

**Please post your questions here instead of creating a new thread. Helps keep the sub clean. :) Encourage others who create new posts for questions to post here instead!**

Thread will stay alive until next one so keep posting after the date in the title. 

Thanks to everyone for answering questions in the previous thread!

Previous threads:

* [Questions thread #4 2016.04.22]
(https://www.reddit.com/r/MachineLearning/comments/4fytfp/questions_thread_4_20160422/)

* [Questions Thread #3 2016.04.07](https://www.reddit.com/r/MachineLearning/comments/4dthzx/questions_thread_3_20160407/)

* [Simple Questions Thread #2 + Meta - 2016.03.23](https://www.reddit.com/r/MachineLearning/comments/4bp1ck/simple_questions_thread_2_meta_20160323/)

* [Simple Questions Thread #1 - 2016.03.08](https://www.reddit.com/r/MachineLearning/comments/49k54u/simple_questions_thread_20160308/)",298,18
238,2016-5-8,2016,5,8,8,4ic9wq,"Beyond meat: The end of food as we know it, thanks to Machine Learning?",https://www.reddit.com/r/MachineLearning/comments/4ic9wq/beyond_meat_the_end_of_food_as_we_know_it_thanks/,[deleted],1462663922,[deleted],3,0
239,2016-5-8,2016,5,8,12,4id2kf,Thoughts? Would this be worth going? Anyone plan on attending? I've been wanting to find an in-person event/conference but wasn't sure about this one.,https://www.reddit.com/r/MachineLearning/comments/4id2kf/thoughts_would_this_be_worth_going_anyone_plan_on/,worldburger,1462677876,,5,0
240,2016-5-8,2016,5,8,12,4id2rr,What methods exist to categorize signal from noise? Red noise? Spatially correlated noise?,https://www.reddit.com/r/MachineLearning/comments/4id2rr/what_methods_exist_to_categorize_signal_from/,Zeekawla99ii,1462678000,"Let's say we are given measurements of some sort. 

In many cases, it is safe to assume that noise is white noise, serially uncorrelated, and zero mean with some finite variance. 

But in other cases, ""red noise"" exists such that the noise is correlated in time. What does one do in this case? Perhaps a Gaussian Process could be used?

What methods exist to characterize spatially-correlated noise?",0,2
241,2016-5-8,2016,5,8,13,4id71n,Why Implement Machine Learning Algorithms From Scratch?,https://www.reddit.com/r/MachineLearning/comments/4id71n/why_implement_machine_learning_algorithms_from/,[deleted],1462680354,[deleted],0,0
242,2016-5-8,2016,5,8,14,4idehc,DeepLIFT - Feature Importance of Neurons in NN,https://www.reddit.com/r/MachineLearning/comments/4idehc/deeplift_feature_importance_of_neurons_in_nn/,[deleted],1462684616,[deleted],3,10
243,2016-5-8,2016,5,8,14,4idey5,"Machine learning and food recipes, from patterns to procedural learning.",https://www.reddit.com/r/MachineLearning/comments/4idey5/machine_learning_and_food_recipes_from_patterns/,machdude,1462684895,"Does any one have any references that describe using any machine learning techniques to create cooking recipes. I use the recipes as an example but I am really interested in how to design algorithms that are able to understand how to create procedures (mix in, bake for 10mins, at the  same time prepare X). I am not even sure in what other fields aside from the culinary one this would be of use, but from the perspective of a learning problem this was intriguing to me.

Maybe this is more of unsupervised problem, it's not clear to me how to define a metric in this case or how to even test the algorithm

If anyone has any data sets of recipes that would be helpful.",6,2
244,2016-5-8,2016,5,8,14,4idigg,why we do not have explicite coordiantes of the low dimentional manifold data when we pull it up in high dimetional space,https://www.reddit.com/r/MachineLearning/comments/4idigg/why_we_do_not_have_explicite_coordiantes_of_the/,John_Smith111,1462687127,"hello all, 

in its lecuter Geoffry Hinton tell that he pulls up the low dimentional image data in high dimentional space and then dig low dimentional holes in that high dimentional space 
http://videolectures.net/mlss09uk_hinton_dbn/   
part 1 
50:37

the high dimetional space as far as i know are the extracted features.

Hinton also note that when we pull the data on high dimetional space we do not have the explicte coordinates of the low dimational data - 
http://videolectures.net/mlss09uk_hinton_dbn/#
part 2 
15:35

Why we do not have the explicite coordinate in that high dimetional space - is it the kernel trick or it is just because we use 
extracted features insted low dimentional data coordinates ?",7,0
245,2016-5-8,2016,5,8,22,4ieiwz,noob question on classifier prediction,https://www.reddit.com/r/MachineLearning/comments/4ieiwz/noob_question_on_classifier_prediction/,[deleted],1462713846,[removed],0,1
246,2016-5-8,2016,5,8,22,4iekc9,predicting new non-standardized data with classifier trained on standardized data,https://www.reddit.com/r/MachineLearning/comments/4iekc9/predicting_new_nonstandardized_data_with/,narudarurasya,1462714585,[removed],0,1
247,2016-5-9,2016,5,9,1,4if92b,How does one go about getting a career doing research in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/4if92b/how_does_one_go_about_getting_a_career_doing/,xxxblackspider,1462725866,I'm an undergrad double major in Actuarial Science and Computer Science. Is this a good basis to go on to grad school and get into Machine Learning? Do I need to go to grad school?,49,29
248,2016-5-9,2016,5,9,2,4ifbbv,How To Be A Deep Learning Ninja,https://www.reddit.com/r/MachineLearning/comments/4ifbbv/how_to_be_a_deep_learning_ninja/,abderhasan,1462726814,,0,1
249,2016-5-9,2016,5,9,3,4iftea,Why is the kernel trick only used in SVMs?,https://www.reddit.com/r/MachineLearning/comments/4iftea/why_is_the_kernel_trick_only_used_in_svms/,Icko_,1462733818,"I've only seen it mentioned in the context of SVM, and it seems like it could be useful in logistic regression too - e.g. [here](http://www.eric-kim.net/eric-kim-net/posts/1/imgs/data_2d_to_3d.png) it would make a dramatic difference. Why is that?",11,17
250,2016-5-9,2016,5,9,4,4ifz4v,what is random markov filed,https://www.reddit.com/r/MachineLearning/comments/4ifz4v/what_is_random_markov_filed/,John_Smith111,1462736044,"hello all

Could you provide some intuition what is random markov  field - what is it actually, why it is named ""field""  and how we use it?

Thanks all ",5,0
251,2016-5-9,2016,5,9,5,4ig6mq,Machine learning resources?,https://www.reddit.com/r/MachineLearning/comments/4ig6mq/machine_learning_resources/,Fasterup,1462739021,"Hi, 

Machine learning has taken my fancy and I have done some courses, and played around with it. I would like to learn more and keep up to date with developments. What are some key/good resources ( blogs , news, coding resources, or similar)  that I should read? 

",2,0
252,2016-5-9,2016,5,9,5,4igbdg,Build an AI Composer - ML for Hackers #2,https://www.reddit.com/r/MachineLearning/comments/4igbdg/build_an_ai_composer_ml_for_hackers_2/,llSourcell,1462740870,,26,79
253,2016-5-9,2016,5,9,6,4iggq0,[Career Advice] How do I make the best out of my ML Career?,https://www.reddit.com/r/MachineLearning/comments/4iggq0/career_advice_how_do_i_make_the_best_out_of_my_ml/,deepprocrastinating,1462743035,"First things first, thanks for your interest!

I'm at an important crossroads of my career, and I could use some advice. I'm wrapping up my Physics Bachelors at one of the top 30 colleges (Times/QS) for the subject. Until about a year, I was pretty sure a theoretical physicist was what I wanted to be, and I prepared accordingly (e.g. made it through Advanced Quantum Field Theory without losing my sanity). 

And then I found Hinton's course on neural networks. You see, I would read papers in theoretical physics, and more often than not, understand the core idea. But that's pretty much about it. But with machine learning, or deep learning in particular, it's different - I would read papers and have my own ideas, which I could (did) implement and get lucky. The prospect of working on the bleeding edge of a subject this important, it's exhilarating. It would have taken me years to get anywhere this close to the cutting edge in theoretical physics. Add to that: if you're not Level Ed Witten smart, it's hard to make any impact at all. And I've come to accept that - which is why I'm very seriously considering a career in ML. I still have my Masters in Physics to go, but I'm not sure where to go after that. 

So to my question: is there a way I could have one foot in physics and the other in ML/DL? So far, the only thing I see is quantum computing for machine learning, but am I missing something obvious? Also, I'd be very grateful for every nugget of wisdom you have for me. 

Thanks again!
",8,0
254,2016-5-9,2016,5,9,6,4igh15,Machine Learning Semi-Gods share their opinion on Singularity.,https://www.reddit.com/r/MachineLearning/comments/4igh15/machine_learning_semigods_share_their_opinion_on/,anuar_12,1462743160,,22,0
255,2016-5-9,2016,5,9,7,4igmnx,What's the best way to get started with GPUs?,https://www.reddit.com/r/MachineLearning/comments/4igmnx/whats_the_best_way_to_get_started_with_gpus/,JohnyWalkerRed,1462745534,Are there any books/resources that provide a good starting place? I am looking to apply neural networks/deep learning on them. Is it necessary to understand the detailed computer architecture of GPUs or is there an abstraction layer similar to distributed computing frameworks like Spark and Hadoop? I have a good understanding of C and low-level programming.,12,3
256,2016-5-9,2016,5,9,8,4ih05e,TPOT: A Python tool for automating machine learning,https://www.reddit.com/r/MachineLearning/comments/4ih05e/tpot_a_python_tool_for_automating_machine_learning/,[deleted],1462751450,[deleted],0,1
257,2016-5-9,2016,5,9,10,4ihedp,Visual QA Guide - Using Deep Learning to Answer Questions about Images,https://www.reddit.com/r/MachineLearning/comments/4ihedp/visual_qa_guide_using_deep_learning_to_answer/,Jxieeducation,1462757670,,5,5
258,2016-5-9,2016,5,9,10,4iheqt,What's the point of this tflearn library? Plagarism?,https://www.reddit.com/r/MachineLearning/comments/4iheqt/whats_the_point_of_this_tflearn_library_plagarism/,iloveredditit,1462757843,[removed],1,1
259,2016-5-9,2016,5,9,10,4ihhdj,Embedded system + machine learning,https://www.reddit.com/r/MachineLearning/comments/4ihhdj/embedded_system_machine_learning/,renanfonteles,1462759029,"I'm doing a project to detect (classify) human activities using a ARM cortex-m0 microcontroller (Freedom - KL25Z) with an accelerometer. I intend to predict the activity of the user using machine learning.

The problem is, the cortex-m0 is not capable of processing training or predicting algorithms, so I would probably have to collect the data, train it in my computer and then embed it somehow, which I don't really know how to do it.

I saw some post in the internet saying that you can generate a matrix of weights and embed it in a microcontroller, so it would be a straightforward function to predict something ,based on the data you providing for this function. Would it be the right way of doing ?

Anyway my question is, how could I embedded a classification algorithm in a microcontroller?

I hope you guys can help me and give some guidance, I'm kind of lost here.

Thank you in advance.",0,1
260,2016-5-9,2016,5,9,13,4ii0tl,"When I die, I'd like a chatbot to continue posting to social media as I would.",https://www.reddit.com/r/MachineLearning/comments/4ii0tl/when_i_die_id_like_a_chatbot_to_continue_posting/,TurtleTownie,1462767857,[removed],0,0
261,2016-5-9,2016,5,9,14,4ii8ov,Kaggle Walkthrough - Creating a Model,https://www.reddit.com/r/MachineLearning/comments/4ii8ov/kaggle_walkthrough_creating_a_model/,mrbrettromero,1462772048,,0,0
262,2016-5-9,2016,5,9,15,4iigi2,Question : is there any previous work of representing power of neural networks?,https://www.reddit.com/r/MachineLearning/comments/4iigi2/question_is_there_any_previous_work_of/,yhg0112,1462776715,"hello

i'm doing little research of the representation power of neural networks. i know that we can set a turing machine with RNN, but can we approximate or fit our networks in any classifying hyperplane?

For example, let our target function(hyperplane) is 
     g(x_1, x_2) = x_1 + x_2 
, for simplicity. I would label -1 if g(x_1', x_2') &lt; 0 or label 1 otherwise for the input data (x_1', x_2'). In this case where i know the exact target function, how can i fit my network to the target function? or is there any related previous work you know? any answer is very very welcome. 

thanks to all.",4,0
263,2016-5-9,2016,5,9,17,4iiql5,Text Captcha Decoder,https://www.reddit.com/r/MachineLearning/comments/4iiql5/text_captcha_decoder/,articlefr,1462783732,,0,1
264,2016-5-9,2016,5,9,19,4iiy9e,Quitting a PhD in ML,https://www.reddit.com/r/MachineLearning/comments/4iiy9e/quitting_a_phd_in_ml/,[deleted],1462789068,[removed],0,1
265,2016-5-9,2016,5,9,21,4ij8dw,TPOT: A Python tool for automating machine learning,https://www.reddit.com/r/MachineLearning/comments/4ij8dw/tpot_a_python_tool_for_automating_machine_learning/,rhiever,1462795236,,46,193
266,2016-5-9,2016,5,9,21,4ij8rf,Pedro Domingos on Machine Learning and the Master Algorithm (on the EconTalk podcast),https://www.reddit.com/r/MachineLearning/comments/4ij8rf/pedro_domingos_on_machine_learning_and_the_master/,brianbaq,1462795419,,0,0
267,2016-5-9,2016,5,9,21,4ij8zf,Is it possible to improve autoencoder mapping by incorporating human input?,https://www.reddit.com/r/MachineLearning/comments/4ij8zf/is_it_possible_to_improve_autoencoder_mapping_by/,SnowRipple,1462795536,"Let's say that I have an autoencoder that reduces dimensionality of image patches and embedds them into the same space. It does pretty good job but there are some mistakes (some patches does not belong to the created patches).

So i would like to use a human user that would mark these misclassified patches using labels which would say "" no this patch does not belong here, it belongs over there"". And the process would be repeated until mapping satisfactory to the user would be produced.

Is there a way to ""correct"" autoencoder somehow using labels? 

I know that siamese networks can produce a mapping based on similarity labels, would it be possible to do something similar with autoencoders?",1,0
268,2016-5-9,2016,5,9,21,4ijdfo,Tensorflow is winning,https://www.reddit.com/r/MachineLearning/comments/4ijdfo/tensorflow_is_winning/,mjhirn,1462797792,,56,51
269,2016-5-9,2016,5,9,21,4ije4c,Detecting the language of a tweet,https://www.reddit.com/r/MachineLearning/comments/4ije4c/detecting_the_language_of_a_tweet/,DrLegend,1462798111,,0,0
270,2016-5-9,2016,5,9,22,4ijhgz,Improving Naive Bayes classifier from contextual information,https://www.reddit.com/r/MachineLearning/comments/4ijhgz/improving_naive_bayes_classifier_from_contextual/,s2579006,1462799663,"Hello all,

I want to make a piece of software that can determine the overall sentiment of an article based on it's comments. 

To do this I trained a baseline naive bayes classifier with word count as features. The dataset was 200.000 tweets with a smiley in it {:(,:-(, etc}. This baseline classifier scores 73% accuracy,

Now I want to improve this classifier by retrieving features/information from the news article and the comments. Anyone have any idea how I can try this?

Thank you in advance!

Wouter Mostard",0,0
271,2016-5-9,2016,5,9,22,4ijioh,When will your job be replaced by AI? The man behind Deepmind's AI solving '100 Hat Riddle' discusses this and more.,https://www.reddit.com/r/MachineLearning/comments/4ijioh/when_will_your_job_be_replaced_by_ai_the_man/,Duffai,1462800213,,2,0
272,2016-5-9,2016,5,9,22,4ijj0n,How to implement a fullyconnected neural network from scratch in python,https://www.reddit.com/r/MachineLearning/comments/4ijj0n/how_to_implement_a_fullyconnected_neural_network/,Flowx08,1462800382,,0,1
273,2016-5-9,2016,5,9,22,4ijm0f,Understand what features impact most for each prediction,https://www.reddit.com/r/MachineLearning/comments/4ijm0f/understand_what_features_impact_most_for_each/,Gaploid,1462801651,"Hi all,
I`m a semi-noob in ML therefore sorry in advance for maybe a stupid question. Can somebody point me to methods/secret mechanic that can show me what features is impacting most for each prediction. I`m using Boosted decision trees and neural networks. I know there is classes such ""Permutation Feature Importance"" but they shows me the general weights for features for whole trained model but I need for each prediction. For example for row # 1 prediction was based because feature number 1,6,20 was in a right range. Prediction for Row # 2 based on 2,5,20 and etc.

Thanks in advance",1,0
274,2016-5-9,2016,5,9,23,4ijptx,New version (0.2) of the Deep Reinforcement library DeeR is now available,https://www.reddit.com/r/MachineLearning/comments/4ijptx/new_version_02_of_the_deep_reinforcement_library/,VinFL,1462803212,"Hi,

I would like to share with you that the new version of DeeR (0.2) is now available. It is a general deep reinforcement learning library and this version provides many new possibilities out of the box (prioritized experience replay, double Q-learning, etc). Many different environment examples are also provided (some of them using OpenAI gym). It is build with modularity in mind so that it can easily be adapted to any need.

You can find more informations here:

Documentation : [http://deer.readthedocs.io/en/master/](http://deer.readthedocs.io/en/master/)

Github repository : [https://github.com/VinF/deer](https://github.com/VinF/deer)

Any feedback is welcome!",5,8
275,2016-5-9,2016,5,9,23,4ijpvp,Future of AI V: The Singularians,https://www.reddit.com/r/MachineLearning/comments/4ijpvp/future_of_ai_v_the_singularians/,sieisteinmodel,1462803232,,9,0
276,2016-5-9,2016,5,9,23,4ijv8n,What is the relationship between clustering and association rule mining?,https://www.reddit.com/r/MachineLearning/comments/4ijv8n/what_is_the_relationship_between_clustering_and/,themoosemind,1462805292,,0,0
277,2016-5-9,2016,5,9,23,4ijww9,"Question about amount of perturbation while generating adversarial images with ""fast gradient sign method"" , Goodfellow et. al 2015",https://www.reddit.com/r/MachineLearning/comments/4ijww9/question_about_amount_of_perturbation_while/,deep_learner,1462805905,"In the [paper](http://arxiv.org/abs/1412.6572), in Fig 1, they use a very small multiplier, 0.007, to the sign of the gradient to achieve a high confidence misclassification. however when i coded it, i required large amounts of the multiplier (~  2.) to achieve  a low confidence misclassification. I am wondering what is the range of images they used, is it in the 0-255 range, -128 to 128 or 0-1?
EDIT:  they gave the 0.007 epsilon value, with a comment i couldn't understand: 'it is the magnitude of the least significant bit of an 8 bit representation for googlenet'. I didnt understand how to parse this.",4,6
278,2016-5-10,2016,5,10,0,4ijyal,Are Char-RNN's Generative or Discriminative Models?,https://www.reddit.com/r/MachineLearning/comments/4ijyal/are_charrnns_generative_or_discriminative_models/,shaunmbarry,1462806379,"I was reading over Block's [sequence generators](https://github.com/mila-udem/blocks/blob/master/blocks/bricks/sequence_generators.py), which seem to use RNN's with attention mechanisms to generate sequences. I'm not completely sure (I couldn't find any example of them being used), but they seem to be designed for training in a way where they will generate sequences, then calculate loss based on the generated sequence, rather than just predict the next character like Char-RNN.  For Char-RNN's they seem to be trained in a discriminative fashion, but they can be used to sample the next character in a sequence, then feed in a new string with the predicted/sampled character appended to the string. Thus, generating/synthesizing text. This is more of a general discussion than a single question. I need help in clarifying: 

* Is there a fundamental difference between learning a probability distribution and sampling from it (like Char-RNN), or is Char-RNN also somehow implicitly learning to become a generative model like an RBM? 

* Is there anything Char-RNN could not learn that a truly generative model would be able to?

* Is the sequence generator in Blocks generative? Would it be able to learn things that Char-RNN couldn't. 

Thanks.",5,0
279,2016-5-10,2016,5,10,2,4ikqhz,"Inline text editor ""autocomplete"" powered by torch-rnn",https://www.reddit.com/r/MachineLearning/comments/4ikqhz/inline_text_editor_autocomplete_powered_by/,robinsloan,1462816052,,10,26
280,2016-5-10,2016,5,10,3,4ikv1b,Neural Network Evolution Playground with Backprop NEAT,https://www.reddit.com/r/MachineLearning/comments/4ikv1b/neural_network_evolution_playground_with_backprop/,hardmaru,1462817571,,13,62
281,2016-5-10,2016,5,10,3,4ikzqh,How can I begin a career in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/4ikzqh/how_can_i_begin_a_career_in_machine_learning/,noobtubepython,1462819099,"I hope to one day work on the bleeding edge of AI.

AI/ML/DL/etc is going to change the world and I want to be part of it.",3,0
282,2016-5-10,2016,5,10,3,4il17n,MS from a bad univ. Chances for a Phd from good one.,https://www.reddit.com/r/MachineLearning/comments/4il17n/ms_from_a_bad_univ_chances_for_a_phd_from_good_one/,[deleted],1462819596,[deleted],9,0
283,2016-5-10,2016,5,10,4,4ilbgz,Unsupervised Learning Gone Wrong,https://www.reddit.com/r/MachineLearning/comments/4ilbgz/unsupervised_learning_gone_wrong/,[deleted],1462823005,,2,0
284,2016-5-10,2016,5,10,5,4ileww,Having some issues in R,https://www.reddit.com/r/MachineLearning/comments/4ileww/having_some_issues_in_r/,goldengun4,1462824145,"I am in a machine learning class and our final project is to analyze a dataset of our choice interpret it and present it to the class. 

Well I chose the adult dataset from uci. I have very basic knowledge and I've run a decision tree on it using C50. The next thing I want to try is nnet. I set everything up and I keep getting NAs introduced by coercion (arg 2).

I guess what my question is is A) what does this mean and B) how do I fix it.

A little background:
I nulled all columns except age, race, sex, and salary as they are not relevant to what I want to analyze.
When I run str(data) I get 32560 observations of 4 variables.

I've tried increasing the size of the hidden layer but when I do that I get an argument for too many weights. 

Currently I'm not at my computer but I will be in probably 5 hours or so but any help at all would be hugely appreciated. 

Thank you,

Zach",4,0
285,2016-5-10,2016,5,10,5,4ilgik,Deep Learning in the Cloud with NVIDIA DIGITS and Titan-X GPUs starting at $0.49 per hour,https://www.reddit.com/r/MachineLearning/comments/4ilgik/deep_learning_in_the_cloud_with_nvidia_digits_and/,mtweak,1462824696,,9,17
286,2016-5-10,2016,5,10,5,4ilgyh,Is there any theoretical justification for LSTM?,https://www.reddit.com/r/MachineLearning/comments/4ilgyh/is_there_any_theoretical_justification_for_lstm/,vernunftig,1462824845,"LSTM is very effective in practice, however the design of its structure seems very ad-hoc. Is there any theoretical justification for the effectiveness of LSTM, which explains the effectiveness of such RNN cells mathematically?",11,4
287,2016-5-10,2016,5,10,7,4im2ln,Studying Machine Learning: Theoretical or Applied?,https://www.reddit.com/r/MachineLearning/comments/4im2ln/studying_machine_learning_theoretical_or_applied/,LearningMachinesMsc,1462832192,"I've got offers for MSc in Machine Learning from Imperial College London and for MSc in Computational Statistics and Machine Learning at UCL.

I know Imperial is a more respected university (considered the MIT of UK) but I feel like the course is very theoretical whereas UCL is more applied. My undergraduate is in Mathematics and Economics so my computer science background is limited. It seems like Imperial assumes that I should know more CS than UCL.

1. For people working in Machine Learning/Data science what would you prefer: A person with very good theoretical understanding or someone who has experience with applied machine learning?

2. Imperial has a lot of emphasis of logic based learning while UCL has emphasis on statistics. UCL also has NLP module while Imperial does not. Is logic based learning widely used in industry? 

3. What are the main areas of Machine Learning that I should focus on for industry?

My main goals are to finish the MSc and work in machine learning/data science (although I will really consider a Phd if the MSc goes well).

Would really appreciate advice because I have to make a decision soon!

Links to the courses:
http://www.imperial.ac.uk/computing/prospective-students/courses/pg/specialist-degrees/ml/
http://www.cs.ucl.ac.uk/degrees/msc_csml/

Thanks!",1,0
288,2016-5-10,2016,5,10,7,4im4as,Intelligence Design Lab,https://www.reddit.com/r/MachineLearning/comments/4im4as/intelligence_design_lab/,GaryGaulin,1462832832,"I have a computer model some here might be interested in. It includes a navigation network I designed that is based upon the latest research on how our hippocampus and entorhinal cortex works. It learns how avoid getting zapped by an invisible (to it) shock zone that moves around the perimeter of its arena. Enjoy! 
http://intelligencegenerator.blogspot.com/",0,0
289,2016-5-10,2016,5,10,7,4im7bb,"I've been working on this app called Knoto for a while. Deeplearning app that uses facial recognition to assist in users in getting photos. We also tell you how many photos of you are on our network, and enable you to get them. Check out the video!",https://www.reddit.com/r/MachineLearning/comments/4im7bb/ive_been_working_on_this_app_called_knoto_for_a/,[deleted],1462833968,[deleted],1,1
290,2016-5-10,2016,5,10,8,4im9py,3 Steps to Maintaining Your Heavy Machinery!,https://www.reddit.com/r/MachineLearning/comments/4im9py/3_steps_to_maintaining_your_heavy_machinery/,jackerfrinandis,1462834878,,0,1
291,2016-5-10,2016,5,10,8,4imd7v,Simple explanations re transparency for different approaches?,https://www.reddit.com/r/MachineLearning/comments/4imd7v/simple_explanations_re_transparency_for_different/,gj_gj,1462836239,"I'm quite interested in the social effects of ML, but don't know a lot about ML specifics.

Are there any resources, papers etc that simply describe the transparency of different approaches. E.g. Bayesian approaches maybe you can see model (and then add constraints to stop, e.g. discrimination) vs. deep learning where things are more blackbox?


Any links much appreciated!",0,0
292,2016-5-10,2016,5,10,8,4imdb7,"Adversarial Machine Learning Conference Sep 10 / SF / fraud, security, AML and KYC",https://www.reddit.com/r/MachineLearning/comments/4imdb7/adversarial_machine_learning_conference_sep_10_sf/,[deleted],1462836278,[deleted],1,0
293,2016-5-10,2016,5,10,8,4imgj1,How to people usually wire together LSTM cells?,https://www.reddit.com/r/MachineLearning/comments/4imgj1/how_to_people_usually_wire_together_lstm_cells/,danijar,1462837501,"- I saw both cell outputs feeding back into the inputs of the same layer and only feeding updward to the next layer. Is one of these ways more common? 
- If having these recurrent connections outside the cells, why are LSTM networks still arranged in layers?
- Do outputs of higher layers feed into inputs of lower layers?",6,0
294,2016-5-10,2016,5,10,9,4imkvv,"(Call for Abstracts) Interdisciplinary ""Action and Anticipation for Visual Learning Workshop"", ECCV, Amsterdam, October 2016",https://www.reddit.com/r/MachineLearning/comments/4imkvv/call_for_abstracts_interdisciplinary_action_and/,dineshjayaraman,1462839238,,0,0
295,2016-5-10,2016,5,10,10,4imuov,A Framework for analysing Non-Convex Optimization.,https://www.reddit.com/r/MachineLearning/comments/4imuov/a_framework_for_analysing_nonconvex_optimization/,Hydreigon92,1462843178,,1,14
296,2016-5-10,2016,5,10,10,4imwvw,Not so deep machine learning video lectures?,https://www.reddit.com/r/MachineLearning/comments/4imwvw/not_so_deep_machine_learning_video_lectures/,feelosofee,1462844026,"Hi, I just wanted to ask if anyone happens to know video lectures about ML that are not too deep but at the same time will give you a good overview of ML problems, techniques and such.

This is a good example of what I mean: 

Introduction to Machine Learning - Pascal Vincent - http://videolectures.net/deeplearning2015_vincent_machine_learning/

Does anyone know more like this?

Thanks",2,0
297,2016-5-10,2016,5,10,11,4in8qk,Batch Norm LSTM -- Difficulty Replicating Results,https://www.reddit.com/r/MachineLearning/comments/4in8qk/batch_norm_lstm_difficulty_replicating_results/,LeavesBreathe,1462848799,"Hey Guys,

https://arxiv.org/pdf/1603.09025v4.pdf

Recently, this paper was published on how batch normalization can be used within an LSTM and the results are stunning. Really good work. 

However, I have been trying to replicate this paper in tensorflow, and it seems to severely degrade LSTM performance. Importantly, I've initialized Gamma Batch Norm Multiplier to 0.1. 

The authors write that it is important to keep separate batch norm stats for each timestep, which I have done. I was very careful to keep separate batch norm stats and separate gammas for Wx and Hx and Cell_State.

I wanted to ask if anyone else has successfully replicated good results from batch norming LSTMs. Its not that I want to discredit the authors -- I feel that I must be doing something wrong. ",7,14
298,2016-5-10,2016,5,10,12,4in9ub,"Neil Lawrence on Bostrom's ""Superintelligence""",https://www.reddit.com/r/MachineLearning/comments/4in9ub/neil_lawrence_on_bostroms_superintelligence/,[deleted],1462849267,[deleted],52,56
299,2016-5-10,2016,5,10,12,4inghb,"Noob question on how to best process data. Do I need to buy a server to crunch through my datasets? If not, then how should I go about this?",https://www.reddit.com/r/MachineLearning/comments/4inghb/noob_question_on_how_to_best_process_data_do_i/,bzsearch,1462852193,"Sorry for the noob question, but as the title states, I'm looking for alternative ways to process all of my data other than my personal machine.

Everything has become super slow, and it takes nights for me to run my code.

Help or advice?

Thanks!",8,0
300,2016-5-10,2016,5,10,13,4ink63,"Is ""true"" AI possible, but implausible?",https://www.reddit.com/r/MachineLearning/comments/4ink63/is_true_ai_possible_but_implausible/,[deleted],1462853971,[deleted],3,0
301,2016-5-10,2016,5,10,13,4inkfe,"Siri-creator shows off first public demo of Viv, the intelligent interface for everything",https://www.reddit.com/r/MachineLearning/comments/4inkfe/siricreator_shows_off_first_public_demo_of_viv/,ThePwnr,1462854098,,1,0
302,2016-5-10,2016,5,10,13,4inojs,Why is machine learning so shallow?,https://www.reddit.com/r/MachineLearning/comments/4inojs/why_is_machine_learning_so_shallow/,scientific_prodigy12,1462856253,"To start off, please ignore my username, it's completely sarcastic.

That being said, why is machine learning so incredibly shallow? Certainly not easy, but it seems like it's a lot less technical and deep that other fields. 

I took my first course (grad course, but I'm an undergrad) in it last semester. I knew nothing about it whatsoever going in, but came out of it with enough knowledge to read state of the art papers. No other field lets you do that. Not only that, but after 3 weeks of reading papers on my own time after the course, I was able to put a few ideas into a paper, which surprisingly got published (in a reputable journal too!)...

No other technical field would allow an undergrad to take his first course and immediately be able to not only read the state of the art, but also publish in it. It's ridiculous to the point of hilarity almost. I have a few friends who are majoring in math and after almost an entire undergrad of studying the field, they aren't even close to being able to publish ""real math"".

What gives, why is machine learning so shallow? I went in expecting Stochastic Differential Equations and functional analysis, but all I got out of that course was basic probability and linear algebra, plus a few derivatives thrown in.

I *should not* have been able to publish a paper after my first fucking course, this is absurd. I'm not even a math major, just a computer engineering one.",44,0
303,2016-5-10,2016,5,10,14,4inrih,Automatic summarization of source code functions - 1D Conv + Attention,https://www.reddit.com/r/MachineLearning/comments/4inrih/automatic_summarization_of_source_code_functions/,Jxieeducation,1462857805,,0,0
304,2016-5-10,2016,5,10,14,4intea,how to combine two probabilistic models' output?,https://www.reddit.com/r/MachineLearning/comments/4intea/how_to_combine_two_probabilistic_models_output/,koormoosh,1462858789,what sort of options do we have if we want to combine the outputs of two probabilistic models (i.e. two predictive probabilities P(Data|ModelA) and P(Data|ModelB) ) and return a valid probability.,9,2
305,2016-5-10,2016,5,10,15,4io0hz,Introducing FBLearner Flow: Facebook's AI backbone | Engineering Blog | Facebook Code,https://www.reddit.com/r/MachineLearning/comments/4io0hz/introducing_fblearner_flow_facebooks_ai_backbone/,sanosukesagara,1462862746,,1,41
306,2016-5-10,2016,5,10,16,4io2jl,feature engineering and over-fitting,https://www.reddit.com/r/MachineLearning/comments/4io2jl/feature_engineering_and_overfitting/,machdude,1462863975,"I was wondering when does feature engineering become over-fitting. Traditionaly we always refer to over-fitting in the context of dimensionality, but there should also be a concept for the feature definition themselves. All that work that goes into hand crafting a feature could lead to over-fitting. Secondly, how to we use cross-validation in this scenario since, we can't really look at only part of the data to design the features and then test on the rest, any thoughts?",4,1
307,2016-5-10,2016,5,10,17,4io915,Introducing FBLearner Flow: Facebook's AI backbone,https://www.reddit.com/r/MachineLearning/comments/4io915/introducing_fblearner_flow_facebooks_ai_backbone/,[deleted],1462868217,[deleted],0,1
308,2016-5-10,2016,5,10,18,4iofyu,An Introduction to Machine learning and TensorFlow,https://www.reddit.com/r/MachineLearning/comments/4iofyu/an_introduction_to_machine_learning_and_tensorflow/,bitmininfosys,1462872976,,0,1
309,2016-5-10,2016,5,10,19,4ion14,Rubber electric kneader machine,https://www.reddit.com/r/MachineLearning/comments/4ion14/rubber_electric_kneader_machine/,mixmachinery,1462877393,,1,1
310,2016-5-10,2016,5,10,21,4ip179,[1604.08772] Towards Conceptual Compression,https://www.reddit.com/r/MachineLearning/comments/4ip179/160408772_towards_conceptual_compression/,kgregor,1462884425,,8,59
311,2016-5-10,2016,5,10,22,4ip6j8,Creating synthetic dataset with known SVM parameters,https://www.reddit.com/r/MachineLearning/comments/4ip6j8/creating_synthetic_dataset_with_known_svm/,Bohemian850,1462886695,"Hi everybody

I want to create a synthetic dataset consisting of 2 classes and 3 features for testing a hyperparameter optimization technique for a SVM classifier with a RBF kernel. The hyperparameters are gamma and C (the cost).

I have created my current 3D synthetic dataset as follows:

1. I have created 10 based points for each class by sampling from a multivariate normal distribution with mean (1,0,0) and (0,1,0), respectively, and unit variance.

1. I have added more points to each class by picking a base point at random and then sampling a new point from a normal distribution with mean equal to the chosen base point and variance I/5.

It would be a very cool thing if I could determine the best C and gamma from the dataset (before running SVM), so that I can see if my optimization technique provides me the best parameters in the end.

Is there a possibility to calculate the best gamma and C parameter from the synthetic dataset described above?

Or else is there a way to create a synthetic dataset where the best gamma and C parameters are known?",1,4
312,2016-5-10,2016,5,10,22,4ip6qi,Brains or AI for content moderation,https://www.reddit.com/r/MachineLearning/comments/4ip6qi/brains_or_ai_for_content_moderation/,sotern,1462886780,,0,1
313,2016-5-10,2016,5,10,23,4ipcrg,What is the best method for predicting whether or not a student will show up to school the next day?,https://www.reddit.com/r/MachineLearning/comments/4ipcrg/what_is_the_best_method_for_predicting_whether_or/,jewsicle,1462889140,"I work in small school district that manages 16 schools with 5000+ students. I want to develop a model that will tell me how likely a student is to show up tomorrow, 2 days out, 3 days out,...,n days out using historical data. I have access to all student level information including attendance data and the type of absence/tardy. Any help you can provide is greatly appreciated.",9,0
314,2016-5-10,2016,5,10,23,4ipdt1,"Global and Chinese Spring Stand Market 2016: Industry Trends, Production, Sales, Demand, Supply, Analysis &amp; Forecast to 2021",https://www.reddit.com/r/MachineLearning/comments/4ipdt1/global_and_chinese_spring_stand_market_2016/,thomasmrs,1462889528,,0,1
315,2016-5-10,2016,5,10,23,4ipew8,Neural networks and deep learning,https://www.reddit.com/r/MachineLearning/comments/4ipew8/neural_networks_and_deep_learning/,Tech_Stocks_Investor,1462889904,,0,0
316,2016-5-10,2016,5,10,23,4ipj0k,Faster R-CNN features for Instance Search,https://www.reddit.com/r/MachineLearning/comments/4ipj0k/faster_rcnn_features_for_instance_search/,xavigiro,1462891404,,0,9
317,2016-5-10,2016,5,10,23,4ipjz0,ICML 2016,https://www.reddit.com/r/MachineLearning/comments/4ipjz0/icml_2016/,chrico031,1462891749,"Anyone else going to ICML this year?

Any interest in a meetup while there?",6,8
318,2016-5-11,2016,5,11,0,4ipmcr,Machine Learning Experts Gather in Boston,https://www.reddit.com/r/MachineLearning/comments/4ipmcr/machine_learning_experts_gather_in_boston/,reworksophie,1462892592,,0,1
319,2016-5-11,2016,5,11,0,4ipowj,How is deep learning being used in the financial sector?,https://www.reddit.com/r/MachineLearning/comments/4ipowj/how_is_deep_learning_being_used_in_the_financial/,reworksophie,1462893451,,0,1
320,2016-5-11,2016,5,11,0,4ipprd,How to use machine learning to find synonyms,https://www.reddit.com/r/MachineLearning/comments/4ipprd/how_to_use_machine_learning_to_find_synonyms/,nikhilbd,1462893735,,0,1
321,2016-5-11,2016,5,11,0,4ipq17,Machine learning is going mobile,https://www.reddit.com/r/MachineLearning/comments/4ipq17/machine_learning_is_going_mobile/,mtl1015,1462893821,,0,0
322,2016-5-11,2016,5,11,1,4iq2cz,"Replicating ""Asynchronous Methods for Deep Reinforcement Learning"" (http://arxiv.org/abs/1602.01783)",https://www.reddit.com/r/MachineLearning/comments/4iq2cz/replicating_asynchronous_methods_for_deep/,m000pan,1462898015,,0,19
323,2016-5-11,2016,5,11,1,4iq46w,Resetting LSTM States in Tensorflow char rnn,https://www.reddit.com/r/MachineLearning/comments/4iq46w/resetting_lstm_states_in_tensorflow_char_rnn/,haskkk,1462898643,"in this char rnn implemented in tensorflow (https://github.com/sherjilozair/char-rnn-tensorflow/blob/master/model.py) , the author 'primes' the rnn by seeding with a zero state, and then runs a priming text of 'The', however it looks like when they predict, they again seed with the same zero state. I would have expected the state used after priming  to be state from the prime run, in the list [state]. Why is this not the case? 

     def sample(self, sess, chars, vocab, num=200, prime='The ', sampling_type=1):
            state = self.cell.zero_state(1, tf.float32).eval()
            for char in prime[:-1]:
                x = np.zeros((1, 1))
                x[0, 0] = vocab[char]
                feed = {self.input_data: x, self.initial_state:state}
                [state] = sess.run([self.final_state], feed)
    
            def weighted_pick(weights):
                t = np.cumsum(weights)
                s = np.sum(weights)
                return(int(np.searchsorted(t, np.random.rand(1)*s)))
    
            ret = prime
            char = prime[-1]
            for n in range(num):
                x = np.zeros((1, 1))
                x[0, 0] = vocab[char]
                feed = {self.input_data: x, self.initial_state:state} #HERE
                [probs, state] = sess.run([self.probs, self.final_state], feed)
                p = probs[0]",3,4
324,2016-5-11,2016,5,11,1,4iq6ri,Research directions in deep learning,https://www.reddit.com/r/MachineLearning/comments/4iq6ri/research_directions_in_deep_learning/,[deleted],1462899527,[removed],0,1
325,2016-5-11,2016,5,11,2,4iq7ih,On Nested Models,https://www.reddit.com/r/MachineLearning/comments/4iq7ih/on_nested_models/,alexeyr,1462899772,,0,1
326,2016-5-11,2016,5,11,2,4iq8um,Mathematical deep learning research areas,https://www.reddit.com/r/MachineLearning/comments/4iq8um/mathematical_deep_learning_research_areas/,[deleted],1462900180,[removed],0,1
327,2016-5-11,2016,5,11,2,4iqa1c,Apache Spark Machine Learning Tutorial | MapR,https://www.reddit.com/r/MachineLearning/comments/4iqa1c/apache_spark_machine_learning_tutorial_mapr/,caroljmcdonald,1462900553,,2,0
328,2016-5-11,2016,5,11,2,4iqgv8,How to set up cuda (7.5 or other) for ubuntu 16.04 for Theano?,https://www.reddit.com/r/MachineLearning/comments/4iqgv8/how_to_set_up_cuda_75_or_other_for_ubuntu_1604/,SnowRipple,1462902794,"I spent last couple hours trying to install any cuda on ubuntu 16.04 and failed.

I installed something using:
 sudo apt-get install nvidia-cuda-toolkit

when I click ""nvcc -V"" I get:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Tue_Aug_11_14:27:32_CDT_2015
Cuda compilation tools, release 7.5, V7.5.17

So it seems that it installed something but there is nothing under /usr/local/ where I should copy cudnn files....",6,4
329,2016-5-11,2016,5,11,2,4iqgvh,"(Nature) Machine Learning and ""Materials Genomics:"" Industrial Phase Imminent with Growing Databases of Predictors, Materials, Rich Set of Targets",https://www.reddit.com/r/MachineLearning/comments/4iqgvh/nature_machine_learning_and_materials_genomics/,ckendall_salford,1462902798,,0,1
330,2016-5-11,2016,5,11,2,4iqhsn,Yann LeCun Deep Learning lectures at Collge de France 2016 (English Dubbed),https://www.reddit.com/r/MachineLearning/comments/4iqhsn/yann_lecun_deep_learning_lectures_at_collge_de/,geofflee,1462903114,,0,10
331,2016-5-11,2016,5,11,3,4iqk6p,Teaser Results? Understanding Deep Neural Networks by Synthetically Generating the Preferred Stimuli for Each of Their Neurons,https://www.reddit.com/r/MachineLearning/comments/4iqk6p/teaser_results_understanding_deep_neural_networks/,feedthecreed,1462903902,,5,17
332,2016-5-11,2016,5,11,4,4iquxp,How to calculate bits per character? (BPC),https://www.reddit.com/r/MachineLearning/comments/4iquxp/how_to_calculate_bits_per_character_bpc/,Flipper3,1462907452,"In one of Alex Graves' papers (and several other authors as well) utilize the term bits per character (BPC). The paper that I am referencing here is ""Generating Sequences with Recurrent Neural Networks"" (http://arxiv.org/abs/1308.0850).

In the paper he defines BPC as -log2 P(xt+1 | yt), which is defined in Section 3.1 and results are shown in Table 1.

How is this exactly calculated? When I have a recurrent neural network, such as a char-rnn, how do I calculate this probability? I am stumped on this and am wondering if anybody would be able to provide a simple example or help explain how to identify the probability once I get the prediction from a network.",4,0
333,2016-5-11,2016,5,11,4,4ir2er,"Swarm A.I. Correctly Predicts the Kentucky Derby, Accurately Picking all Four Horses of the Superfecta at 540 to 1 Odds",https://www.reddit.com/r/MachineLearning/comments/4ir2er/swarm_ai_correctly_predicts_the_kentucky_derby/,georgeo,1462909888,,10,0
334,2016-5-11,2016,5,11,5,4ir53e,"Facebook's ""Flow"" is an AI Factory of the Future",https://www.reddit.com/r/MachineLearning/comments/4ir53e/facebooks_flow_is_an_ai_factory_of_the_future/,[deleted],1462910797,[deleted],1,0
335,2016-5-11,2016,5,11,5,4ire1h,Datasets to practise on?,https://www.reddit.com/r/MachineLearning/comments/4ire1h/datasets_to_practise_on/,Fasterup,1462913780,"Hi,

Anyone know of any good and available datasets to practise/test different types of algorithms on? As a beginner that wants to practise I would be really happy to get my hands on some significant data.",5,0
336,2016-5-11,2016,5,11,6,4irhlk,IAEA computer vision challenge,https://www.reddit.com/r/MachineLearning/comments/4irhlk/iaea_computer_vision_challenge/,tttzof351,1462914986,,0,0
337,2016-5-11,2016,5,11,6,4irm1j,Artistic style transfer for videos,https://www.reddit.com/r/MachineLearning/comments/4irm1j/artistic_style_transfer_for_videos/,downtownslim,1462916537,,26,209
338,2016-5-11,2016,5,11,7,4irs9n,DanDoesData Caffe Installation and Basics,https://www.reddit.com/r/MachineLearning/comments/4irs9n/dandoesdata_caffe_installation_and_basics/,vanboxel,1462918790,,2,0
339,2016-5-11,2016,5,11,7,4iruex,The Controlled Natural Language of Randall Munroe's Thing Explainer [pdf],https://www.reddit.com/r/MachineLearning/comments/4iruex/the_controlled_natural_language_of_randall/,iamkeyur,1462919610,,0,2
340,2016-5-11,2016,5,11,8,4irzx5,"""J. Chung/K. Cho/Y. Bengio release code for character-level decoding (neural machine translation)! https://t.co/bOl4tklbkd""",https://www.reddit.com/r/MachineLearning/comments/4irzx5/j_chungk_choy_bengio_release_code_for/,andyandy16,1462921641,,2,24
341,2016-5-11,2016,5,11,8,4is338,Guidance and Overview of NIPS submission process,https://www.reddit.com/r/MachineLearning/comments/4is338/guidance_and_overview_of_nips_submission_process/,paulizt,1462922862,"I have a paper I wrote sometime back, and I want to submit it to NIPS. 

I am curious about the process of submission, review and acceptance. From the website, it was clear that one can submit before 20th through an online portal. Once submission is done and a reviewer(s?) is (are?) assigned, what happens next? Is there room for improvement of the manuscript? How big can the changes be if they are allowed? What if the reviewer fails to understand or appreciate some aspects of my work? Will I get a chance to explain or expand? Or is it straight out rejection? Can a poor paper be submitted, based on reviewer feedback improved and still get accepted?

I know it's a lot of questions but please help me out here !!",0,1
342,2016-5-11,2016,5,11,8,4is3oc,Amazon DSSTNE: Deep Scalable Sparse Tensor Network Engine,https://www.reddit.com/r/MachineLearning/comments/4is3oc/amazon_dsstne_deep_scalable_sparse_tensor_network/,[deleted],1462923082,[deleted],7,3
343,2016-5-11,2016,5,11,8,4is4fa,A lightweight C++ machine learning library for embedded electronics and robotics (x-post from /r/programming),https://www.reddit.com/r/MachineLearning/comments/4is4fa/a_lightweight_c_machine_learning_library_for/,nanogru,1462923363,,2,9
344,2016-5-11,2016,5,11,8,4is6tt,Not Just a Black Box: Learning Important Features Through Propagating Activation Differences,https://www.reddit.com/r/MachineLearning/comments/4is6tt/not_just_a_black_box_learning_important_features/,SuperFX,1462924293,,0,7
345,2016-5-11,2016,5,11,11,4ispya,"Amazon releases ""DSSTNE"", another neural network library",https://www.reddit.com/r/MachineLearning/comments/4ispya/amazon_releases_dsstne_another_neural_network/,vanboxel,1462932115,,35,48
346,2016-5-11,2016,5,11,12,4it62o,The Perceptron Algorithm,https://www.reddit.com/r/MachineLearning/comments/4it62o/the_perceptron_algorithm/,panwekar,1462939069,[removed],0,1
347,2016-5-11,2016,5,11,13,4it82k,TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems (arXiv),https://www.reddit.com/r/MachineLearning/comments/4it82k/tensorflow_largescale_machine_learning_on/,sbt_,1462940056,,0,0
348,2016-5-11,2016,5,11,13,4it8g7,What are some open problems in deep vision (for a project)?,https://www.reddit.com/r/MachineLearning/comments/4it8g7/what_are_some_open_problems_in_deep_vision_for_a/,karan_42,1462940230,"Hi

I have a few ideas in mind but was looking for other's views. Other than the standard set of problems (for example Classification, VQA etc), what are some new areas where there is a good scope for a research project?

Edit: 
My current experience: Sophomore Computer Science Student looking to do some useful research in deep vision. Good knowledge of ML and Shallow Vision.",11,0
349,2016-5-11,2016,5,11,13,4itc66,Panama Papers Database,https://www.reddit.com/r/MachineLearning/comments/4itc66/panama_papers_database/,IAmNotWizwazzle,1462942025,,0,2
350,2016-5-11,2016,5,11,16,4itqte,Haloong 800T Electric screw press transformed from double-disk friction ...,https://www.reddit.com/r/MachineLearning/comments/4itqte/haloong_800t_electric_screw_press_transformed/,[deleted],1462950238,[deleted],0,1
351,2016-5-11,2016,5,11,16,4ittl6,Haloong 800T Electric press transformed from double-disk friction press*,https://www.reddit.com/r/MachineLearning/comments/4ittl6/haloong_800t_electric_press_transformed_from/,Haloong,1462951938,,0,1
352,2016-5-11,2016,5,11,17,4ityhg,Backpropagation Through Time: What It Does and How to Do It (1990),https://www.reddit.com/r/MachineLearning/comments/4ityhg/backpropagation_through_time_what_it_does_and_how/,klihu,1462955075,,0,4
353,2016-5-11,2016,5,11,17,4itz4e,Convolutional Neural Networks &amp; number of filters (depth of the volume),https://www.reddit.com/r/MachineLearning/comments/4itz4e/convolutional_neural_networks_number_of_filters/,pgaleone,1462955469,"I'm studying how CNN works.
Intuitively: a convolution takes a volume as input, slides with some stride a window along each dimension of the volume, computes the convolution with a filter taken from a ""filter bank"".
This filter bank is a volume of learned filter.
The output of a convolution is an image with a lower dimension along x, and y and the same depth of the original. The output can be padded.

Am I right?

My question is: the number of filters in the filter bank how should be chosen?

Popular choices are 32, 64, ecc. Is there a particular reason or is still ""art""?

Should the number of filters chosen in function of the specific task? I guess that if I'm using a conv net to do a binary classification (eg: face vs non-face) the number of filters can be lower respect to a multi-class classification (eg: 1000 class of image net dataset).

Thank you",16,2
354,2016-5-11,2016,5,11,20,4iug31,Pretty fast word2vec with Numba,https://www.reddit.com/r/MachineLearning/comments/4iug31/pretty_fast_word2vec_with_numba/,pmigdal,1462965866,,0,7
355,2016-5-11,2016,5,11,20,4iugve,"Community Hangout 62 starts at 2pm EDT, 11am PDT, 8pm CET. We are discussing tech updates, community updates and our DAO proposal. #scala #etherum #bitcoin #blockchain",https://www.reddit.com/r/MachineLearning/comments/4iugve/community_hangout_62_starts_at_2pm_edt_11am_pdt/,SynereoMedia,1462966297,"Link to the hangout https://www.youtube.com/watch?v=Mp-L4Puj8HI I would like to invite everyone to be apart of this community call.

The community leaders are working on a DAO proposal, our team will inform the community about the details of this proposal.

Our intention is to decentralize the Daohub.org project as soon as possible and raise $3,000000 USD or community related projects. $1,500000 in Ethereum with the possibility of Synereo backing $1,500000 in Amps.

http://www.synereo.com Facebook:http://www.facebook.com/groups/1013726192055203/ 
Slack channel: http://www.synereonet.slack.com 
Twitter: http://twitter.com/synereo 
White Paper: http://www.synereo.com/whitepapers/synereo.pdf

Synereo is an open source, decentralized social network. It is an attention economy that rewards popular content and participation with crypto-currency. Content is promoted or advertised in a way that fairly rewards the content's creator and those who choose to engage with that content. An automatic and transparent reputation economy assures that you experience content relevant to you. The privacy of your communications and contacts is baked-in to the structure of the network. Synereo is modeled in -calculus and functionally programmed in Scala.

ethereum #bitcoin #blockchain #synereo",0,0
356,2016-5-11,2016,5,11,21,4ius1p,What constraints to use for weights in a weighted kernel?,https://www.reddit.com/r/MachineLearning/comments/4ius1p/what_constraints_to_use_for_weights_in_a_weighted/,MachineLearnerXP,1462971560,[removed],0,1
357,2016-5-11,2016,5,11,23,4iv1k4,[1605.01749] Rank Ordered Autoencoders,https://www.reddit.com/r/MachineLearning/comments/4iv1k4/160501749_rank_ordered_autoencoders/,pbertens,1462975380,,21,53
358,2016-5-11,2016,5,11,23,4iv4xt,Recommendation system based on word embedding.,https://www.reddit.com/r/MachineLearning/comments/4iv4xt/recommendation_system_based_on_word_embedding/,data_sagan,1462976601,"Thinking about writing my master thesis on this subject. Does any of you have any ideas/tips on for instance datasets (can I easily get a database with reviews from for instance TripAdvisor/Amazon) or should I build a webscraping tool myself. 
Also I'm wondering if it would be more convenient if the reviews for instance also include a star or number rating with the text to better predict and train the model or is this not a necessity? ",7,8
359,2016-5-12,2016,5,12,0,4ivdbi,"Essay: Which package does medium-data learning algorithm training better, H2O or Apache Spark?",https://www.reddit.com/r/MachineLearning/comments/4ivdbi/essay_which_package_does_mediumdata_learning/,datasciguy-aaay,1462979580,"Background: H2O is a major new analytics programming platform for machine learning applications using computer clusters.

Question:  Is h2o able to process datasets bigger than working memory?
 
Apparently not: 
The join algorithm needed more than a mere 100GB to complete the task and hence failed. Given that a common rule of thumb is 3x data size for working memory, to fail with 0.1x data size as working memory is very reasonable. Internally we refer to H2O as a fast calculator. Like R and Python it is in-memory.
Source: http://blog.h2o.ai/2016/05/red-herring-bites/

Oh my goodness!  Its a big nasty surprise because it means that the application code and the application developer are left to do it themselves regarding the out-of-core processing or virtualization of medium data and big data datasets.  In case you havent noticed, small data is not all we have to work on today.  We also have medium data, and we also have big data.  You may have heard about it (!).  Failure to virtualize out of core processing is just an inexcusable design flaw in 2016 for any newly developed analytics software packages that have high ambitions to be adopted by data scientists or machine learning application developers.  By contrast, good quality relational database servers like Oracle have been processing datasets larger than RAM easily since around 1985, and doing it well.  Yes, I said Oracle.  I said good quality because last time I checked, MySQL doesnt do a lot of things that a good RDBMS must do. Thats OK though theres a place for that package. The Apache web server used to be goofy like that too, but I digress.

But I imagine the protests already.  Lets say you bring a bias against Oracle for your own reasons, whatever, because maybe you were born too late or some junk. OK lets pretend for a moment its different which is a common way for people to verbalize that they think a comparison is unfair.  Lets say it is indeed unfair of me to hold this against H2O designers because of some claim that we shouldnt hold one type of server software to the same standards as another type of server software.  To be clear, Im not buying this premise at all, because computer science has solved such out-of-core problems at least as far back as 1985, and some good application developers evidently remembered to correctly apply their CS skills to their day jobs on software packages.  But lets go along with the bad argument anyway.  H2O is not a database.

Now consider the package SAS, which is centrally a data analysis and computational tool, not even a database server, which again also handles larger than RAM datasets and computations. SAS has been processing datasets larger than RAM easily since around 1985, and doing it well, and doing it so seamlessly, that the code for out-of-core analytics processing just never spills over into the application code. I dont like SAS because its too expensive for little guys, but the federal government likes it well enough.  I havent used SAS in a long while but man, it sure did something right. SAS runs on pretty big data even with little RAM by comparison, falling back to disk storage transparently and, most importantly, terminating correctly, with a correct answer from your calculation.

R fundamentally has a working set or out of core processing problem.  Base R is designed to assume that app developers writing apps in the R language, can just go load the entire data frame into RAM all at once. You dont get hurt by this problem on the built-in academic datasets but you sure do hit the problem fast once you move beyond the Iris and the Agewage datasets as useful as they are. Python too has a working set problem because Pandas has a working set problem, so its the same thing.  Pandas is the python equivalent of Rs built-in dataframe.  To work around these problems, as a data scientist you have to augment these systems with other packages or write the code yourself.  Workarounds for data of size medium and up commonly include tricks such as random subsampling, adding a good RDBMS or cute but helpful SQLite to your pipeline, using tools (toolz package) which stream the processing better in python, and even as far as partitioning your datasets by rows or by columns and then running learning algorithms on the sub-parts one at a time and combining the models back together at the end in some way such as by simple voting, simple averages or sophisticated layered machine learning ensemble techniques.  All this stuff just further complicates an already complicated application.  All I wanted to do was complete a single learning algorithm training session in the first place. But that one training session comletely crashed the computer and failed to terminate correctly before outputting the model I waited so long for.  Now I am stuck doing quite fancier things in my application code, but not even because I wanted it, or needed it, for my reproducible research results. Adding salt to the wound, I dont even know how many of my peers are actually going to comprehend my code now, damaging the reproducibility.

  So now we are in 2016 where we sit squarely in the age of big data, virtualization, deep learning, computer vision, and web logs and social media records of hundreds of gigabytes in size being completely typical and just the tip of the iceberg.  You cant even compete in a money-paying Kaggle competition with small data any more, because medium data is commonly the entry level of perfectly typical real world datasets.  Just a single month -- one month! -- of user comments in ascii text on Reddit is at 1.5 terabytes, and that was in May 2015, a year ago today. Yet here we go with H2O which is newly designed squarely for analytics in the age of big data, and I was really hoping to use it, yet H2O is apparently expecting users to purchase an amount of RAM that is as large as the dataset itself, or larger than it. 

Thats just not happening.  Worse, that is a losing design in our data climate. Anybodys purchases of RAM going forward are simply not going to keep up linearly with the data size we have to process. This 1.5 terabytes of reddit comments is raw data, meaning that I have not even created term vectors yet with a few thousands of numeric dimensions that I will need to add onto it, at least.  The prospect of buying some *multiple* of 1.5 terabytes of RAM (RAM I said!) just to finish processing at all, to get a final model, is a total non-starter.  Anyway a CUDA accelerator GPU board has at most 12 Gb of RAM so I dont get how thats being handled if cluster-aggregate and node-level main system RAM needs to be gigantic in comparison. An Nvidia GPU with 12GB RAM is the go-to device for deep learning algorithms currently.  I would expect that if the H2O system could process 12 Gb chunks of data at at time in GPU memory -- and H2O does seem to be able to do it although I dont know it with certainty yet -- then a similar technique as out-of-core on GPU could also be used for processing small chunks of data in main node memory and CPUs.

Didnt todays cutting edge package developers pass their traditional Comp Sci courses in college?  What is the deal with the current breed of scientific and numerical software package developers on the free software scene?  Dont computer science students even get exposure to other software like SAS during their entire university experience?  Why do users have to suffer simpleton (toy) software limitations camouflaged by, and mixed in with, high powered analytical code, that doesnt even meet the clear and present data size needs of todays datasets and databases? To be clear, there are indeed apparently some genuine cutting edge software ideas being excellently implemented in H2O as well as R and python and some other packages. The lure of using these new packages for their great aspects, just makes it all the more frustrating.  I cannot happily and profitably spend my or my employers time filling in the pot-holes that have no business being in the analytics software in the first place. I have to spend my days doing data science, not computer science.  The computer science people will need to get involved.

My next assessment is Apache Spark.  I shall go check if Spark has such a big data design guffaw too. Im hypothesizing that Spark does it right, actually.  Spark has MapReduce baked right in from the start, which is no guarantee I guess, but its a pretty good clue, that they expected to encounter big data.  I am no longer sure though unless I go verify it.  I received a big surprise, a big disappointment, on the H2O package, so I am going to find out what Spark does regarding out-of-core processing.  There can be no escaping or waffling when it comes to out of core processing in the age of big data.  We cannot just purchase more RAM to match our dataset one-for-one.  Data size is growing faster than our wallets, and there is no way to avoid this reality.  We have passed the singularity event of big data. There is no going back from here.  

As for me and my current Reddit natural language processing project, I cannot justify the use of H2Os cool bits from my Spark code, if I am just going to have to add lots of complex workaround code as well, just to get my model training to complete when I call out to H2Os machine learning routines.  I think I would just restrict my code to calling Sparks native MLLib if thats the case.",0,0
360,2016-5-12,2016,5,12,0,4ivkx2,"The Good, Bad, &amp; Ugly of TensorFlow",https://www.reddit.com/r/MachineLearning/comments/4ivkx2/the_good_bad_ugly_of_tensorflow/,madisonmay,1462982123,,9,93
361,2016-5-12,2016,5,12,1,4ivry2,Flowing your tensors,https://www.reddit.com/r/MachineLearning/comments/4ivry2/flowing_your_tensors/,EatShihtzu,1462984497,TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow  TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow TensorFlow,1,0
362,2016-5-12,2016,5,12,1,4ivt14,How do you manage/ virtualise your deep learning dev/test environment?,https://www.reddit.com/r/MachineLearning/comments/4ivt14/how_do_you_manage_virtualise_your_deep_learning/,jimduk,1462984842,"Hi - I feel like I'm wasting a lot of time in configuration/ install/ package management for deep learning and I'm looking for tips. Context is I use Tensorflow/Darknet on a dev laptop with Oracle VMs and a bare metal Kubuntu GTX970 for training. I expect to add more machines.  My time splits 50% between trying to get other people's github examples working and 50% on my own object localisation stuff.  My goal is to reduce the time I spend building/rebuilding environments which I'm not good at - I'm more Mathsy than Linuxy.  Cuda/Nvidia/Python/Tensorflow/Image Processing are given. This is small company stuff - 1-4 people

* 1 - For your machines with the Graphics Cards - how do you manage different Cuda installs - is it just separate directories for installs and updating path variables?
* 2 - Do you virtualise immediately above the Graphics card - (e.g. VM or Docker) or is that too much hassle ?
* 3  - What Linux do you use - do you stick on e.g Ubuntu 14.04 or 16.04 or use a lighter version ? (I use Kubuntu which works but e.g. isnt supported by Nvidia CUDA). What do you update when?
* 4  - Do you keep separate machines for separate purposes (e.g. dev/training/validation) ?
* 5  - Which version of Python ? ( I use 3 but  I think this is hurting me)  Do you virtualise Python (Docker/Virtual Env) ?Which protobuf, which opencv?
* 6  - How do you 'manage' your experiments - e.g. new VM/Docker with data copied in and envt set up, or just different folders, or github
* 7 - Any tips on managing Data - both test/training and models - e.g. stick it all on AWS, or stick it all on portable HDDs

Thanks",4,2
363,2016-5-12,2016,5,12,1,4ivueg,What's the point of using linear input projections with LSTMs?,https://www.reddit.com/r/MachineLearning/comments/4ivueg/whats_the_point_of_using_linear_input_projections/,SuperFX,1462985318,"What's the point of a linear input projection matrix for something like an LSTM? I.e. projecting the raw inputs (say a one-hot representation of words) to a lower-dimensional wordvec-type of representation, before it's fed into the LSTM. I'm asking because all the various gates of the LSTM do their own linear projection, and obviously any two matrix multiplies can be represented by just one (assuming dimensions agree), so what exactly is being gained?
I can identify a few possibilities. One, it's a single input projection instead of the three that would be used in the LSTM, so there's a sort of weight sharing there. Two, depending on the dimensionality of the input projection matrix, one can effectively impose additional low rank structure on the matrix that would otherwise arise in the various LSTM gates (i.e. we're saying that the mapping from raw inputs to LSTM gate must be decomposable in terms of two matrix multiplies that have low rank). And third, given that the overall problem is non-convex, then the addition of the input projection layer may change the optimization landscape.

None of the above increases the representational power of the network--in fact number two decreases it. So is that it? Or is there something that I'm missing?",6,6
364,2016-5-12,2016,5,12,3,4iw9zo,"XGBoost: Distributed Gradient Boosting in R, Python, and Julia",https://www.reddit.com/r/MachineLearning/comments/4iw9zo/xgboost_distributed_gradient_boosting_in_r_python/,carmichael561,1462990474,,0,9
365,2016-5-12,2016,5,12,3,4iwcyd,What is the state of the art on CIFAR-10 without data augmentation?,https://www.reddit.com/r/MachineLearning/comments/4iwcyd/what_is_the_state_of_the_art_on_cifar10_without/,wildtales,1462991459,What is the state of the art on CIFAR-10 without data augmentation?,13,1
366,2016-5-12,2016,5,12,4,4iwswf,"Spark 2.0 Technical Preview: Easier, Faster, and Smarter",https://www.reddit.com/r/MachineLearning/comments/4iwswf/spark_20_technical_preview_easier_faster_and/,based2,1462996727,,1,10
367,2016-5-12,2016,5,12,5,4iwv1j,Online neural doodle,https://www.reddit.com/r/MachineLearning/comments/4iwv1j/online_neural_doodle/,dmitry_ulyanov,1462997436,,8,26
368,2016-5-12,2016,5,12,5,4iwwmn,"If An Algorithm Wrote This, How Would You Know?",https://www.reddit.com/r/MachineLearning/comments/4iwwmn/if_an_algorithm_wrote_this_how_would_you_know/,SenseEnergy,1462997952,,5,0
369,2016-5-12,2016,5,12,5,4iwzm9,Reddit Inspired Study on How to Pose Questions.,https://www.reddit.com/r/MachineLearning/comments/4iwzm9/reddit_inspired_study_on_how_to_pose_questions/,feynmanmagic,1462998897,,1,0
370,2016-5-12,2016,5,12,5,4ix1pu,Lets Write a Pipeline - Machine Learning Recipes #4,https://www.reddit.com/r/MachineLearning/comments/4ix1pu/lets_write_a_pipeline_machine_learning_recipes_4/,Akatchi,1462999589,,2,0
371,2016-5-12,2016,5,12,6,4ix50t,Numenta releases work-in-progress book on HTM (Hierarchical Temporal Memory),https://www.reddit.com/r/MachineLearning/comments/4ix50t/numenta_releases_workinprogress_book_on_htm/,TheFaggetman,1463000686,,28,2
372,2016-5-12,2016,5,12,10,4iydrs,Using RNNs/Machine-learning to help you simplify your writing. (plus a suite of other writing tools...),https://www.reddit.com/r/MachineLearning/comments/4iydrs/using_rnnsmachinelearning_to_help_you_simplify/,[deleted],1463017522,[deleted],4,40
373,2016-5-12,2016,5,12,13,4iyytv,Document Embeddings via Convolution and K-Max operations,https://www.reddit.com/r/MachineLearning/comments/4iyytv/document_embeddings_via_convolution_and_kmax/,Jxieeducation,1463026562,,2,0
374,2016-5-12,2016,5,12,14,4iz8az,Prioritize the parameters?,https://www.reddit.com/r/MachineLearning/comments/4iz8az/prioritize_the_parameters/,bdafsi91,1463031425,"Hi, I have a function Y=f(X1,X2..,X10). I have both the features (Xs)and the output (Y). Is there a way I can decide which parameters affect the result (Y) more?  I want to decide on the top 5 parameters and then conduct more survey.

I thought of PCA, but it is not the same. 

Thanks.",2,1
375,2016-5-12,2016,5,12,14,4izaq1,"Swarm AI Correctly Predicts Kentucky Derby Superfecta, Turns $20 Into $11,000",https://www.reddit.com/r/MachineLearning/comments/4izaq1/swarm_ai_correctly_predicts_kentucky_derby/,Ralph1066,1463032690,,0,0
376,2016-5-12,2016,5,12,16,4izhxr,[1605.02688] Theano: A Python framework for fast computation of mathematical expressions,https://www.reddit.com/r/MachineLearning/comments/4izhxr/160502688_theano_a_python_framework_for_fast/,clbam8,1463036840,,7,45
377,2016-5-12,2016,5,12,16,4izmas,How to find a distributor of Rubber kneader machinery?,https://www.reddit.com/r/MachineLearning/comments/4izmas/how_to_find_a_distributor_of_rubber_kneader/,mixmachinery,1463039446,,1,1
378,2016-5-12,2016,5,12,18,4izwcz,3x3 convolution unit/filter on a 32x32 (unnormalized) image with a pad of 1 pixel per side,https://www.reddit.com/r/MachineLearning/comments/4izwcz/3x3_convolution_unitfilter_on_a_32x32/,[deleted],1463045949,[deleted],0,0
379,2016-5-12,2016,5,12,19,4j026n,Teach an AI to become a scientist,https://www.reddit.com/r/MachineLearning/comments/4j026n/teach_an_ai_to_become_a_scientist/,impacctt,1463049358,,0,0
380,2016-5-12,2016,5,12,21,4j0ck8,xgbmagic: for an easier time with xgboost,https://www.reddit.com/r/MachineLearning/comments/4j0ck8/xgbmagic_for_an_easier_time_with_xgboost/,idforkyourrepo,1463054830,,5,3
381,2016-5-12,2016,5,12,22,4j0kpc,Seldon brings machine learning to Kubernetes,https://www.reddit.com/r/MachineLearning/comments/4j0kpc/seldon_brings_machine_learning_to_kubernetes/,ahousley,1463058385,,0,0
382,2016-5-12,2016,5,12,22,4j0obk,Re: Generalized Additive Model: Is the GAM formalism designed to also incorporate MORE THAN ONE feature in each of the functions that are being added?,https://www.reddit.com/r/MachineLearning/comments/4j0obk/re_generalized_additive_model_is_the_gam/,datasciguy-aaay,1463059828,"GAM's design is commonly described by Tibshirani, et al, as including function terms in a final model, where each function inputs exactly one feature.  I would like to know if GAM is actually generalized further, and I just didn't notice yet. I can't seem to discern it for myself for sure when I review the GAM section in the textbook Elements of Statistical Learning.

Particularly, can many, rather than one, feature be input to each single function? 

My end goal is to pass ALL features into each function. However, should I go that way, I would like to know whether I would still then be behaving within the GAM formalism or did I violate some condition of GAM.

My really really end goal is to use this to create a processing infrastructure for automatic out-of-core processing on big data by partitioning the feature space into an ensemble of submodels.

Thanks if you know GAM and like to chat with me!",1,1
383,2016-5-12,2016,5,12,22,4j0sgi,"What worked better in your experience, training a set of learning algorithms on dataset partitioned by examples or by features.",https://www.reddit.com/r/MachineLearning/comments/4j0sgi/what_worked_better_in_your_experience_training_a/,datasciguy-aaay,1463061435,"If you have partitioned your training data explicitly, before feeding it to your learning algorithms, I would like to hear about your scheme and its results, even including what did not work well about it. Thank you for limiting your discussion tightly to the question that I posed if possible.

Ensembles, neural networks, stochastic gradient descent optimization, general additive models, all good.  I am ideally looking for feedback from people who can share experiences that are leading me toward maximally generalizable results applicable to all learning algorithms as much as possible.
",1,0
384,2016-5-12,2016,5,12,23,4j0u2z,In-depth Machine Learning Course w/ Python,https://www.reddit.com/r/MachineLearning/comments/4j0u2z/indepth_machine_learning_course_w_python/,sentdex,1463062047,"Hi there, my name is Harrison and I frequently do Python programming tutorials on [PythonProgramming.net](https://pythonprogramming.net) and [YouTube.com/sentdex](https://www.youtube.com/user/sentdex). 

I do my best to produce tutorials for beginner-intermediate programmers, mainly by making sure nothing is left to abstraction and hand waving. 

The most recent series is an in-depth machine learning course, aimed at breaking down the complex ML concepts that are typically just ""done for you"" in a hand-wavy fashion with packages and modules. 

The machine learning series is aimed at just about anyone with a basic understanding of Python programming and the willingness to learn. If you're confused about something we're doing, I can either help, or point you towards a tutorial that I've done already (I have about 1,000) to help.

The main structure for the course is to:

* Do a quick overview of the theory of each machine learning algorithm we cover.
* Show an application of that algorithm using a module, like scikit-learn, along with some real world data.
* Break down the algorithm and re-write it ourselves, **without machine learning modules**, in Python.

We're not rewriting the algorithms with the intention that we're going to actually produce something superior than what's available, but rather to learn more about how the algorithms actually work, so that we understand them better. I also see a lot of people are very keen to learn about deep-learning, but the learning curve to get to that point is quite challenging, since quite a bit of deep learning requires you to have a wholistic understanding of how things are actually working, and not just a high-level understanding of how to use a module. Hopefully this can help. 

At least for me personally, I have learned a lot by breaking the algorithms down, so I thought I would share that in my tutorials.

All tutorials are posted on **[PythonProgramming.net](https://pythonprogramming.net/machine-learning-tutorial-python-introduction/)** as well as **[YouTube](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)**, so you can follow along in video, text, or both forms, and the content is all free. 

We've done linear regression and K Nearest Neighbors so far, and have quite a long way to go still. We are going to be diving into the Support Vector Machine next, then clustering, neural networks and deep learning. Once we've made our way to deep learning, we're going to be working with TensorFlow.

If all that sounds interesting to you, come hang out and learn with us! 

I tend to release a couple videos a week. If you have suggestions/requests, feel free to share. 

Follow along with the text/video tutorials: on **[PythonProgramming.net](https://pythonprogramming.net/machine-learning-tutorial-python-introduction/)** or **[YouTube](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)** ",67,463
385,2016-5-12,2016,5,12,23,4j0zqe,What exercise can I do next?,https://www.reddit.com/r/MachineLearning/comments/4j0zqe/what_exercise_can_i_do_next/,JosephFenton,1463064115,"I'm in the process of learning more about machine learning (specifically reinforcement learning and neural networks). But I've reached roadblock. Any tips on where I can go from here?

So far I have:

1. Completed the python course on code academy
2. Read the following ebooks (which are excellent!)

On reinforcement learning: https://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html

On deep learning:
http://neuralnetworksanddeeplearning.com/

3. Implemented a very basic reinforcement learning algorithm in python to play tic-tac-toe (noughts and crosses). Based on MENACE (Matchbox Educable Naughts And Crosses Engine).

I'm not sure where to go from here - any tips of fun exercises I could do in Python similar to the tic-tac-toe game (I don't think I'm at a Kaggle level yet).

Thanks!",6,3
386,2016-5-12,2016,5,12,23,4j10np,Notes on Dilated Convolutions and Kronecker-Factored Convolutions,https://www.reddit.com/r/MachineLearning/comments/4j10np/notes_on_dilated_convolutions_and/,fhuszar,1463064454,,11,29
387,2016-5-13,2016,5,13,0,4j13zh,CV2Vec: A Neural Model For Candidate Similarity,https://www.reddit.com/r/MachineLearning/comments/4j13zh/cv2vec_a_neural_model_for_candidate_similarity/,Rob,1463065600,,2,2
388,2016-5-13,2016,5,13,0,4j15iy,Distributed machine learning with communication constraints,https://www.reddit.com/r/MachineLearning/comments/4j15iy/distributed_machine_learning_with_communication/,mttd,1463066114,,0,2
389,2016-5-13,2016,5,13,0,4j188x,Q: Partial Information Decomposition in Python,https://www.reddit.com/r/MachineLearning/comments/4j188x/q_partial_information_decomposition_in_python/,aleph__one,1463067070,"Is anybody aware of a PID implementation in Python/Numpy? Googled and didn't find anything, but I'm wondering if someone has done this yet. If nobody has, I'll have a crack at it and add to one of my repos, when time permits.

Paper for reference: http://arxiv.org/abs/1004.2515
Java version: https://github.com/jlizier/jpid",3,1
390,2016-5-13,2016,5,13,0,4j1ci3,How to create a recommender for recipes based on ingredients?,https://www.reddit.com/r/MachineLearning/comments/4j1ci3/how_to_create_a_recommender_for_recipes_based_on/,neyuh,1463068501,"I am trying to make a program that recommends recipes with similar ingredients as those that the user has (uploaded) himself.
I have no idea whether I need a recommender system (and which) or if I need another technique.

Do you have any ideas?",5,0
391,2016-5-13,2016,5,13,1,4j1k0j,MNIST database,https://www.reddit.com/r/MachineLearning/comments/4j1k0j/mnist_database/,linuxjava,1463071044,,0,0
392,2016-5-13,2016,5,13,2,4j1ol1,tensorflow is coming to ruby! - somatic blog,https://www.reddit.com/r/MachineLearning/comments/4j1ol1/tensorflow_is_coming_to_ruby_somatic_blog/,Toyjust,1463072590,,0,0
393,2016-5-13,2016,5,13,2,4j1vpl,Reference/Staple Books for the well informed beginner?,https://www.reddit.com/r/MachineLearning/comments/4j1vpl/referencestaple_books_for_the_well_informed/,creeky123,1463074984,"Hello all, I'm looking for a reference text to kick start my machine learning interest.

My background:

* BSc in Actuarial Science and Statistics + Fellow of SOA
* Working knowledge of statistical simulation methods, strong linear algebra &amp; multivariate statistics background
* Day job has me focused on MCMC for financial applications
* ~ 2 Years C++ professional background (mostly STL and prop methods).
* ~ 6 months self taught CUDA C++ (&amp; QT5) in windows env

My CUDA side project has been mostly applying cuda to some pretty basic time series analysis for the purpose of learning. I've been working recently on maximum likelihood estimation problems and model fitting for gaussian mixture models and ML started popping up all over the place in academic articles.

I'm hoping someone here might be able to recommend reference material for ML which is fitting with my background. I'm particularly interested in the work on predictive statistics; it feels a lot like bayesian inference.

Any suggestions would greatly appreciated!

Thanks
",6,0
394,2016-5-13,2016,5,13,2,4j1w2i,Text pre-processing basics with python pandas,https://www.reddit.com/r/MachineLearning/comments/4j1w2i/text_preprocessing_basics_with_python_pandas/,UVAnalytics,1463075105,,0,1
395,2016-5-13,2016,5,13,3,4j22i3,The Value of Scala for Improving Your Job Prospects,https://www.reddit.com/r/MachineLearning/comments/4j22i3/the_value_of_scala_for_improving_your_job/,[deleted],1463077255,[deleted],0,1
396,2016-5-13,2016,5,13,3,4j237u,Tensorflow for 1d spectra,https://www.reddit.com/r/MachineLearning/comments/4j237u/tensorflow_for_1d_spectra/,[deleted],1463077501,[removed],0,1
397,2016-5-13,2016,5,13,3,4j25k7,What are today's state of the art object recognition models and libraries?,https://www.reddit.com/r/MachineLearning/comments/4j25k7/what_are_todays_state_of_the_art_object/,SirDucky,1463078282,"Hey all,  I have a side project the includes an object recognition component.  I don't want to go push the bleeding edge, I just want to find a good library and apply it in the system.  Anyone know what the state of the art is these days?  I know there's awesome stuff going on with deep learning, but CV isn't my area of expertise.

Thanks in advance you beautiful bastards.",3,1
398,2016-5-13,2016,5,13,3,4j2931,"Talisman - A straightforward &amp; modular NLP, machine learning &amp; fuzzy matching library for JavaScript(x-post /r/javascript)",https://www.reddit.com/r/MachineLearning/comments/4j2931/talisman_a_straightforward_modular_nlp_machine/,datasci_,1463079491,,0,0
399,2016-5-13,2016,5,13,4,4j2bt8,Is online K-fold Cross Validation a thing?,https://www.reddit.com/r/MachineLearning/comments/4j2bt8/is_online_kfold_cross_validation_a_thing/,datasciguy-aaay,1463080420,"Is online CV a thing?  My dataset is not time series data.  Also, my example generating process is considered stationary. What if for example I have an online algorithm running, using a neural network algorithm design. After a lot of learning examples, I am done main learning so to speak. Now I want to do some K-fold cross validation, one CV example at a time! One example at a time is just like I did before!  Is it OK with you? Have you heard of this? Heres a funny thing about my online system:  I have a little secret to share with you.  I never really threw away my examples after I was done with them!  I actually still have them all! I did online learning, one example at a time, but no I did not throw them away, because I am weird that way I guess.  But now I can also do K-fold CV because I still have all the examples.  Right?  Let me change how I trained now. Let me go back in time and do it just a little differently this time.  I can look at one fold as the new data to predict, and train on the rest of the examples, and record the results, one example at a time.  In fact all along I could be training on different folds in sequential fold order as long as I knew what fold I was currently on, and as long as I was told when to begin and end CV processing on incoming examples, to be decoding but not encoding, rather than just learning the model parameters all the time.  Out of core execution on memory constrained computers is the reason behind all my madness.  My dataset is not time series data.  Also, my example generating process is considered stationary.",4,0
400,2016-5-13,2016,5,13,4,4j2caa,Announcing SyntaxNet: The Worlds Most Accurate Parser Goes Open Source [Google Research Blog],https://www.reddit.com/r/MachineLearning/comments/4j2caa/announcing_syntaxnet_the_worlds_most_accurate/,alxndrkalinin,1463080598,,30,153
401,2016-5-13,2016,5,13,4,4j2hb4,Sklearn Kernel Density estimation,https://www.reddit.com/r/MachineLearning/comments/4j2hb4/sklearn_kernel_density_estimation/,gr8ape,1463082357,"I am trying to use sklearn's kernel density estimation, for 1d data for now. Fitting ~150k points take a few moments, but scoring them takes waaay too much time (5-10 minutes). Any idea why that is or parameters I could change to make prediction faster? I dont understand how a 1d KDE can be so slow...",1,0
402,2016-5-13,2016,5,13,5,4j2lcp,"What's the difference between machine learning, statistics, and data mining? - SHARP SIGHT LABS",https://www.reddit.com/r/MachineLearning/comments/4j2lcp/whats_the_difference_between_machine_learning/,Ewen2016,1463083729,,2,0
403,2016-5-13,2016,5,13,5,4j2mwp,[Help] Making a device,https://www.reddit.com/r/MachineLearning/comments/4j2mwp/help_making_a_device/,Wemonster,1463084214,"Hi /r/MachineLearning!

First of all, i'm sorry if this is the wrong subreddit for asking this kind of questions.

The reason i am here is because i want to start a tiny project of logging sea-temperatures from a device, and transmit the data over to a database. Currently it is only in the planning stage and nothing is started. My concern is how I can build this device with products already available.

Here is what i need:

* Temperature sensor
* A transmitter that can send data to my database 

I probably need som sort of tiny motherboard to connect a digital temperature sensor to a data transmitter. My initial thought is that we can send the data over the mobile network, thus needing some sort of device that can hold a sim card and send data over the 3g network.

Perhaps i'm on the wrong path here? Then i would love to have some feedback, and i would absolutely love if someone out there have any suggestions to what products i can use.

In advance, thanks!

- Wemonster",5,0
404,2016-5-13,2016,5,13,6,4j2x9i,Titan-X GPUs in the cloud $0.49 / hour for deep learning and other GPU apps,https://www.reddit.com/r/MachineLearning/comments/4j2x9i/titanx_gpus_in_the_cloud_049_hour_for_deep/,midasan,1463087793,,0,2
405,2016-5-13,2016,5,13,7,4j382k,Finding serial numbers with a crawler &amp; simple perceptron [x-post from languagetechnology].,https://www.reddit.com/r/MachineLearning/comments/4j382k/finding_serial_numbers_with_a_crawler_simple/,keylime_light,1463091714,"So I am trying to crawl through a large number of websites and pull out serial numbers. This is proving challenging, since the serial numbers are not of any set length, have arbitrary spacing/character sets/punctuation inside them(dashes, etc), and are sometimes contained in downloadable static files such as excel sheets.
The solution I'm currently exploring is training a fairly simple single layer perceptron to decide if something 'looks' like a serial number or not. After removing all words that can be ruled out by more conventional means, I run the perceptron on everything remaining.
The problem I'm running into is how to vectorize the input. Since the input is of arbitrary length, a simple character -&gt; number mapping doesn't work. I'm not trying to vectorize the word based on its surrounding words, so using something like word2vec to create embeddings probably isn't going to help.
Any suggestions on how this could be done?",4,0
406,2016-5-13,2016,5,13,7,4j3ca0,Bijur Delimon  Understanding Your Business Needs!,https://www.reddit.com/r/MachineLearning/comments/4j3ca0/bijur_delimon_understanding_your_business_needs/,jackerfrinandis,1463093287,,0,1
407,2016-5-13,2016,5,13,8,4j3hcj,Announcing SyntaxNet: The Worlds Most Accurate Natural Language Parser,https://www.reddit.com/r/MachineLearning/comments/4j3hcj/announcing_syntaxnet_the_worlds_most_accurate/,iamkeyur,1463095172,,0,0
408,2016-5-13,2016,5,13,10,4j3xxn,Deeplearning/OCR for solving hand-written math equations.,https://www.reddit.com/r/MachineLearning/comments/4j3xxn/deeplearningocr_for_solving_handwritten_math/,antomisna,1463101819,,21,136
409,2016-5-13,2016,5,13,10,4j3yk9,Advanced Research Projects from DARPA's Pentagon Demo Day,https://www.reddit.com/r/MachineLearning/comments/4j3yk9/advanced_research_projects_from_darpas_pentagon/,dendisuhubdy,1463102077,,0,1
410,2016-5-13,2016,5,13,10,4j443u,Type of rubber kneader mixers,https://www.reddit.com/r/MachineLearning/comments/4j443u/type_of_rubber_kneader_mixers/,mixmachinery,1463104416,,1,1
411,2016-5-13,2016,5,13,11,4j472j,Regression: Test the goodness of the model - what do you call this method?,https://www.reddit.com/r/MachineLearning/comments/4j472j/regression_test_the_goodness_of_the_model_what_do/,bdafsi91,1463105576,"I have a training set, and I can create a model. But how to decide if it is good enough? This is what I did and please let me know if there's a name for this technique and how to improve (consider 100 samples):

Remove first sample from the set and predict the output based on a model using 99 samples.  Now compare the ""predicted output"" and the ""actual value"" and calculate an error. (The ""actual value"" is provided to you for all samples)

Now remove the 2nd sample, and do the same thing based on the rest of the 99 samples. 

You will end up with 100 error values. The average of these might be very close to 0, but their standard deviation will be high.

This is a metric for me to check the goodness of my model.

This method is something I just made up. Is there a name for this technique?

Thanks.",9,0
412,2016-5-13,2016,5,13,11,4j48pu,CNN with high instability in validation loss?,https://www.reddit.com/r/MachineLearning/comments/4j48pu/cnn_with_high_instability_in_validation_loss/,Eruditass,1463106298,"My validation loss per epoch jumps around a lot from epoch to epoch, though a low pass filtered version of it does seem to generally trend down.  The training loss is very smooth.

What does that signify?

Ideas:  

* Too small of a validation set (10%) 
* Not enough data for the problem complexity 
* Overfitting


Other details

* Reducing the learning rate reduces the variability.  Note that I am using an ""automatic"" learning rate optimizer (ADAM)
 * Does this mean its overfitting? Though the general trend of the validation loss is still going down.
* data has correlations
  * operating on single images from videos of people doing different actions (target classes), though the frames themselves are scrambled
  * validation data is created by selecting random people and all of their videos (same way as the test dataset)
  * a completely random validation dataset has a smooth loss, presumably because its seen other images of that video and person in the training set",7,2
413,2016-5-13,2016,5,13,12,4j4e5h,Document Modeling via GRUs (paper),https://www.reddit.com/r/MachineLearning/comments/4j4e5h/document_modeling_via_grus_paper/,Jxieeducation,1463108604,,0,3
414,2016-5-13,2016,5,13,13,4j4o13,Can you list PhD level books on machine learning?,https://www.reddit.com/r/MachineLearning/comments/4j4o13/can_you_list_phd_level_books_on_machine_learning/,Mr__Christian_Grey,1463113149,,12,0
415,2016-5-13,2016,5,13,14,4j4tsz,Skype/ ML,https://www.reddit.com/r/MachineLearning/comments/4j4tsz/skype_ml/,Need2Know10,1463116114,,4,0
416,2016-5-13,2016,5,13,14,4j4yb6,Best companies to apply for machine learning internships?,https://www.reddit.com/r/MachineLearning/comments/4j4yb6/best_companies_to_apply_for_machine_learning/,thak123,1463118622,,4,1
417,2016-5-13,2016,5,13,16,4j5a1g,SVRG - have anyone tried or reproduce results?,https://www.reddit.com/r/MachineLearning/comments/4j5a1g/svrg_have_anyone_tried_or_reproduce_results/,bbsome,1463125515,"In the paper for non convex [SVRG](http://arxiv.org/abs/1603.06160) they show some very nice theoretical results, however their experiments are limited to a very very tiny NNs, which are definitely not representable of the field. Have anyone tried this method or reproduce their results? What are you thoughts on this as well?",5,4
418,2016-5-13,2016,5,13,16,4j5a2z,"Laser Cutting Machine, Fiber Laser Marking Machine, Mini Cnc Router",https://www.reddit.com/r/MachineLearning/comments/4j5a2z/laser_cutting_machine_fiber_laser_marking_machine/,eastcnclaser,1463125545,,0,0
419,2016-5-13,2016,5,13,16,4j5az7,Dont invert that matrix (2010),https://www.reddit.com/r/MachineLearning/comments/4j5az7/dont_invert_that_matrix_2010/,pmigdal,1463126135,,13,7
420,2016-5-13,2016,5,13,17,4j5cub,PyData Paris CFP open until May 15h (x-post from /r/python),https://www.reddit.com/r/MachineLearning/comments/4j5cub/pydata_paris_cfp_open_until_may_15h_xpost_from/,sfermigier,1463127292,,1,2
421,2016-5-13,2016,5,13,18,4j5lo3,What counts as perception in ML?,https://www.reddit.com/r/MachineLearning/comments/4j5lo3/what_counts_as_perception_in_ml/,beaniebeanbean,1463132972,"This is either a stunningly basic question or a basic question that's actually stunningly complex. I'm interested in finding out what the measure of perception in machine learning is. When can you confirm that something is ""perceived,"" and how do you verify? Also, what count as the perceiving faculties/technologies of perception? So for e.g. if the human nose is a broad category of related perceiving tools for scent, what is the equivalent in machines? If helpful, I am specifically interested in geospatial imaging technologies or other technologies that play a direct role in generating climate, environmental data. 

All sources and tips much appreciated! Thank you! ",11,0
422,2016-5-13,2016,5,13,19,4j5p9o,What are some good Machine Learning resources?,https://www.reddit.com/r/MachineLearning/comments/4j5p9o/what_are_some_good_machine_learning_resources/,cloudgentleman,1463135112,"Hi /r/machinelearning,

Im interested in cloud computing and trying to learn how you can deploy ML models in the cloud. I regularly commute and use my smartphone to optimize my time and get the most out of it. Id like to share some interesting online material I collected with my research: its a first draft list of course, thats why Id like to know if anyone else has a better list or link to share. There are many online tools out there (Im experimenting with Udacity, Cloud Academy and Coursera), and an infinite amount of interesting blog posts. This is what I like so far:

- (course) - https://cloudacademy.com/amazon-web-services/amazon-machine-learning-course/
- (presentation) - https://www.youtube.com/watch?v=fdIDn3hr27k
- (blog post) - https://cloudplatform.googleblog.com/2016/03/Google-takes-Cloud-Machine-Learning-service-mainstream.html
- (blog post) - www.kdnuggets.com/2015/04/cloud-machine-learning-amazon-ibm-watson-microsoft-azure.html
- (course) - https://www.udacity.com/course/intro-to-machine-learning--ud120
- (blog post) - http://techcrunch.com/2016/03/23/google-launches-new-machine-learning-platform/
- (conference) - https://mediastream.cern.ch/MediaArchive/Video/Public2/weblecture-player/index.html?lecture=510372&amp;utm_campaign=Artificial%2BIntelligence%2BWeekly&amp;utm_medium=web&amp;utm_source=Artificial_Intelligence_Weekly_38&amp;year=2016#
- (blog post) - http://cloudacademy.com/blog/azure-machine-learning/
- (blog post) - http://www.infoworld.com/article/3039052/cloud-computing/how-ibm-google-microsoft-and-amazon-do-machine-learning-in-the-cloud.html
- (lab) - https://cloudacademy.com/amazon-web-services/labs/aws-machine-learning-human-activity-recognition-21/
- (blog post) - http://googleresearch.blogspot.it/2016/03/machine-learning-in-cloud-with.html
- (blog post) - http://cloudacademy.com/blog/introduction-to-amazon-machine-learning/
- (blog post) - https://cloudplatform.googleblog.com/2016/03/Google-takes-Cloud-Machine-Learning-service-mainstream.html
- (course) - https://www.edx.org/course/distributed-machine-learning-spark-uc-berkeleyx-cs120x
- (course) - https://www.coursera.org/learn/machine-learning
- (GitHub repository) - https://github.com/josephmisiti/awesome-machine-learning

Any other/more suggestions to go deep into the topic?",0,1
423,2016-5-13,2016,5,13,19,4j5qwx,IBM Research Lead Charts Scope of Watson AI Effort,https://www.reddit.com/r/MachineLearning/comments/4j5qwx/ibm_research_lead_charts_scope_of_watson_ai_effort/,[deleted],1463136140,[deleted],0,0
424,2016-5-13,2016,5,13,20,4j5xzz,An extension of scikit-learn for Least Squares Anomaly Detection,https://www.reddit.com/r/MachineLearning/comments/4j5xzz/an_extension_of_scikitlearn_for_least_squares/,galapag0,1463140109,,1,29
425,2016-5-13,2016,5,13,20,4j5ydv,Deep Neural Decision Forests,https://www.reddit.com/r/MachineLearning/comments/4j5ydv/deep_neural_decision_forests/,ConfChar,1463140289,[removed],0,1
426,2016-5-13,2016,5,13,23,4j6h1x,Upcoming machine learning Tech Talk: Apache SystemML,https://www.reddit.com/r/MachineLearning/comments/4j6h1x/upcoming_machine_learning_tech_talk_apache/,neilmack66,1463148450,,0,0
427,2016-5-13,2016,5,13,23,4j6kb2,What is the difference between artificial intelligence and machine learning?,https://www.reddit.com/r/MachineLearning/comments/4j6kb2/what_is_the_difference_between_artificial/,TheSharpeRatio,1463149675,"I often see the terms mixed in with each other but have also seen instances of people claiming that machine learning is not artificial intelligence.  I use machine learning in predictive analytics, but am not sure what really differentiates artificial intelligence from machine learning. 

Also, I apologize if this was already covered in a previous post.  I tried using search to find a similar question but could not find anything!",18,4
428,2016-5-13,2016,5,13,23,4j6neb,We built and trained a chatbot using Tensorflow and movie scripts,https://www.reddit.com/r/MachineLearning/comments/4j6neb/we_built_and_trained_a_chatbot_using_tensorflow/,joaopedroo,1463150824,"A couple of us here built a topic-based group texting app and thought it'd be fun to add a chatbot to find restaurants, where to get coffee, etc. We trained it on a lot of movie scripts and connected it to a bunch of APIs.

Love for you guys to test it out and give us some feedback. You can download it here:

https://itunes.apple.com/us/app/channelbox/id969850760

Once you are in the app, the chatbot is under the ""Channelbot"" channel. You can:

* ask for locations and phone numbers of any place (""where is xxx?""). The results are then deep-linked to call or maps.
* ask for definitions (""what is yyy?"")
* ask for places (""where is closest starbucks?"" or ""where can I get some good tacos nearby?"")
* or just simply converse with the chatbot. Be warned that the converse feature isn't that great yet as we haven't tuned it.

Love to hear areas of improvement from you all, so we can figure out how to further improve it. Thx!

",8,15
429,2016-5-14,2016,5,14,0,4j6txg,Easy TensorFlow Model Training on AWS,https://www.reddit.com/r/MachineLearning/comments/4j6txg/easy_tensorflow_model_training_on_aws/,mtweak,1463153157,,2,14
430,2016-5-14,2016,5,14,1,4j72ox,Machine learning meets economics: ICML 2016 workshop on online advertising,https://www.reddit.com/r/MachineLearning/comments/4j72ox/machine_learning_meets_economics_icml_2016/,sharat_sc,1463156222,,1,4
431,2016-5-14,2016,5,14,1,4j759j,Did anyone worked through TensorFlow's word2vec tutorial? I wonder how long it needs to train.,https://www.reddit.com/r/MachineLearning/comments/4j759j/did_anyone_worked_through_tensorflows_word2vec/,danijar,1463157138,,6,5
432,2016-5-14,2016,5,14,2,4j7dxc,"Google Open Sources Syntactic Parser, Parsey McParseface",https://www.reddit.com/r/MachineLearning/comments/4j7dxc/google_open_sources_syntactic_parser_parsey/,[deleted],1463160206,[deleted],2,0
433,2016-5-14,2016,5,14,2,4j7ft5,100 Machine Learning videos you can't find in Google,https://www.reddit.com/r/MachineLearning/comments/4j7ft5/100_machine_learning_videos_you_cant_find_in/,shonburton,1463160846,,36,368
434,2016-5-14,2016,5,14,3,4j7mh8,Videos for Stanford's CS224d No Longer Available - Deep Learning for Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/4j7mh8/videos_for_stanfords_cs224d_no_longer_available/,emzeq,1463163241,"We knew it was only a matter of time after Andrej took down his CS231n videos. Such a shame.  

http://cs224d.stanford.edu/syllabus.html",26,39
435,2016-5-14,2016,5,14,5,4j8ahy,Are External GPUs a good choice?,https://www.reddit.com/r/MachineLearning/comments/4j8ahy/are_external_gpus_a_good_choice/,Rich700000000000,1463172032,"I plan on devoting a bigger percentage of my time to machine learning research over the next few months, and so I'm going to need a better place to run code than my laptop. And I have neither the funds to spend 100 dollars a week on Ec2 instances, nor to build a giant server with TeslaK40's, I thought that the best solution would be to invest in an [external GPU](https://imgur.com/jLwsMgF).

They've been around for a while, and can range from [diy hodgepodges](https://i.imgur.com/01wvv4c.jpg) to [high grade professional hardware](https://www.akitio.com/media/com_hikashop/upload/akitio-thunder2-pcie-box-size_2101063609.jpg). They seem to be just what I need, but I wanted to get some advice before that big a purchase: 

1. Can I use an eGPU for deep learning?
2. What drivers do I need?
3. Are only some cards (780s but not 790s) supported?

Any advice would be appreciated.",25,6
436,2016-5-14,2016,5,14,6,4j8fxu,Time Series Data Scraping,https://www.reddit.com/r/MachineLearning/comments/4j8fxu/time_series_data_scraping/,aidanplenert,1463174067,"Hi,

Are there any tools for scraping time series from HTML pages? I am interested in crawling sites like Wikipedia (and possibly less structured sites) and searching for time series in the HTML and pulling it out. To do so, I would need to identify dates and then find structure in the data as a table.

Any existing tools or papers about research regarding this would be appreciated.

Thanks",0,0
437,2016-5-14,2016,5,14,6,4j8gbw,after alphago it struck me that humans are still dominant in bridge. is anybody working on a bridge bot that can compete at the highest levels of skill?,https://www.reddit.com/r/MachineLearning/comments/4j8gbw/after_alphago_it_struck_me_that_humans_are_still/,jbark55,1463174211,,6,0
438,2016-5-14,2016,5,14,7,4j8tt4,face-to-screen relationships: I would very appreciate your help regarding my thesis,https://www.reddit.com/r/MachineLearning/comments/4j8tt4/facetoscreen_relationships_i_would_very/,mantastg,1463179525,"Thank you all for the responses! Survey is closed.
-------------------------------------------------------
Hi everyone, 

Hope you are having a good weekend! I've read the forum guidelines so, hopefully, this post makes sense here:)

I wondered, if you would have time to help with my thesis project by filing out the survey at [https://www.survey-xact.dk/LinkCollector?key=C8M35V48C595](https://www.survey-xact.dk/LinkCollector?key=C8M35V48C595)

My thesis is about face-to-screen relationships and the information we see on the screens. I attempted to combine several sociological theories and scholarly articles in order to come up with some combinatory rules that would define what categories of information can be perceived as meaningful. Now, I need to collect some responses for the survey to describe the data analysis part. Therefore, I would very appreciate your help!:)

I have written a post on medium.com in order to elaborate a little bit on this project and theories that I rely on. Adding the link to the post, in case you would be interested to read it. [https://medium.com/@mantastg/face-to-screen-relationships-6a46343e7199#.n2tnirgs3](https://medium.com/@mantastg/face-to-screen-relationships-6a46343e7199#.n2tnirgs3)

I study sociology and am very interested in ML and AI technologies. Trying to learn about them little by little. 

Thank you very much in advance!",0,0
439,2016-5-14,2016,5,14,8,4j8zcq,This Week in Machine Learning: 13 May 2016,https://www.reddit.com/r/MachineLearning/comments/4j8zcq/this_week_in_machine_learning_13_may_2016/,[deleted],1463181823,[deleted],0,1
440,2016-5-14,2016,5,14,8,4j8zlm,This Week in Machine Learning: 13 May 2016,https://www.reddit.com/r/MachineLearning/comments/4j8zlm/this_week_in_machine_learning_13_may_2016/,DavidAJoyner,1463181929,,3,0
441,2016-5-14,2016,5,14,10,4j9dux,What do academics working in NLP really think about Google's Parsey Mcparseface?,https://www.reddit.com/r/MachineLearning/comments/4j9dux/what_do_academics_working_in_nlp_really_think/,Visibleone,1463188307,,28,45
442,2016-5-14,2016,5,14,16,4jajf8,Definition of low dimensional manifold,https://www.reddit.com/r/MachineLearning/comments/4jajf8/definition_of_low_dimensional_manifold/,John_Smith111,1463211667,"Hello 

Can someone share the definition of low dimensional manifold? 
How many dimensions are considered for low dimensional?
Some example of low dimensional manifold ?  ",7,1
443,2016-5-14,2016,5,14,16,4jajq2,Theano Windows Installation Guide,https://www.reddit.com/r/MachineLearning/comments/4jajq2/theano_windows_installation_guide/,abstractcontrol,1463211875,,24,17
444,2016-5-14,2016,5,14,16,4jajv0,Could a Neural Turing Machine be used to learn how to design better neural networks?,https://www.reddit.com/r/MachineLearning/comments/4jajv0/could_a_neural_turing_machine_be_used_to_learn/,visarga,1463211961,"In designing neural networks we compose various types of blocks, structures and hyperparameters. Can we design a system that automates the search for the optimal design? Maybe it can find surprising solutions. What would be the minimal neural net that learns a given task and also learns to improve itself (the minimal Gdel machine)? It would be as if we endowed neural nets with the power of procreation.
",6,6
445,2016-5-14,2016,5,14,19,4jawm3,Deep Learning vs Machine Learning vs Pattern Recognition,https://www.reddit.com/r/MachineLearning/comments/4jawm3/deep_learning_vs_machine_learning_vs_pattern/,_fraggle_,1463221374,,6,0
446,2016-5-14,2016,5,14,19,4jay5i,Heres what we built in our first year of open-source machine learning,https://www.reddit.com/r/MachineLearning/comments/4jay5i/heres_what_we_built_in_our_first_year_of/,ahousley,1463222539,,0,0
447,2016-5-15,2016,5,15,0,4jbq8w,Tweet2Vec (paper) and character language models,https://www.reddit.com/r/MachineLearning/comments/4jbq8w/tweet2vec_paper_and_character_language_models/,Jxieeducation,1463238218,,0,1
448,2016-5-15,2016,5,15,0,4jbqkc,Guide to setting up your machine for deep learning from scratch (Ubuntu),https://www.reddit.com/r/MachineLearning/comments/4jbqkc/guide_to_setting_up_your_machine_for_deep/,iluvmylife,1463238356,,28,218
449,2016-5-15,2016,5,15,0,4jbukz,"[Discussion] Can an LSTM without the ""large initial forget gate bias"" trick still learn to remember over large time steps?",https://www.reddit.com/r/MachineLearning/comments/4jbukz/discussion_can_an_lstm_without_the_large_initial/,[deleted],1463240117,[deleted],5,3
450,2016-5-15,2016,5,15,1,4jc4bt,"V Belt Types A, B, C, D, E",https://www.reddit.com/r/MachineLearning/comments/4jc4bt/v_belt_types_a_b_c_d_e/,alhaqtraders,1463244389,,3,0
451,2016-5-15,2016,5,15,1,4jc5um,Offset Printing Machine Belts for Printing Machinery,https://www.reddit.com/r/MachineLearning/comments/4jc5um/offset_printing_machine_belts_for_printing/,alhaqtraders,1463245025,,1,0
452,2016-5-15,2016,5,15,2,4jc9z6,"While training a bidirectional LSTM network for speech recognition, what is better, training in time domain or frequency domain?",https://www.reddit.com/r/MachineLearning/comments/4jc9z6/while_training_a_bidirectional_lstm_network_for/,rulerofthehell,1463246740,"I'm experimenting with bidirectional LSTM networks and want to train by feeding the network with raw audio samples, should I feed it with input parameters in time domain or transform them into frequency domain using DFT just like researchers did on this paper:
https://sites.google.com/site/anayebihomepage/cs224dfinalproject
What are the possible benefits of each of these methods? Which will be able to extract the most temporal patterns?",8,1
453,2016-5-15,2016,5,15,2,4jcejf,[NLPers] A bad optimizer is not a good thing.,https://www.reddit.com/r/MachineLearning/comments/4jcejf/nlpers_a_bad_optimizer_is_not_a_good_thing/,negazirana,1463248656,,18,21
454,2016-5-15,2016,5,15,3,4jck8m,How important is undergraduate prestige when trying to find a job related to machine learning?,https://www.reddit.com/r/MachineLearning/comments/4jck8m/how_important_is_undergraduate_prestige_when/,[deleted],1463250992,[deleted],20,0
455,2016-5-15,2016,5,15,7,4jdh09,Probability theory and machine learning questions?,https://www.reddit.com/r/MachineLearning/comments/4jdh09/probability_theory_and_machine_learning_questions/,Mr__Christian_Grey,1463265347,"I'm reading Kevin Murphy's book Machine Learning: A probabilistic Perspective and while I was reading I ran into few problems like in this Image(http://i.imgur.com/89IXaNv.png), in generative classifier, how do we get the right side of the equation when we input x, Y=c and theta into bayes formula? Can you please do step by step? and in this image(http://i.imgur.com/I28QsUm.png), in the figure, why did we subtract one? And what he mean by parameters, when he says we need 9 parameters to define it?",8,0
456,2016-5-15,2016,5,15,13,4jenkt,A dummy's guide to Deep Learning,https://www.reddit.com/r/MachineLearning/comments/4jenkt/a_dummys_guide_to_deep_learning/,kunchenguid,1463286259,,1,0
457,2016-5-15,2016,5,15,18,4jffvp,Machine learning Chat bot,https://www.reddit.com/r/MachineLearning/comments/4jffvp/machine_learning_chat_bot/,emanuelecesari,1463304912,Hello i am very New in machine learning i have already read some articol about ml now i want do develop a livechat bot to order pizza but i dont know witch tecnology i could use.. I read about tensor And watson is the most popular shoul i use it?or i can easy do without? ,2,0
458,2016-5-15,2016,5,15,23,4jg77d,Need Help Understanding Blocked Matrix Multiplication,https://www.reddit.com/r/MachineLearning/comments/4jg77d/need_help_understanding_blocked_matrix/,[deleted],1463320832,[deleted],0,0
459,2016-5-16,2016,5,16,1,4jgwfx,Building Autoencoders in Keras,https://www.reddit.com/r/MachineLearning/comments/4jgwfx/building_autoencoders_in_keras/,gwulfs,1463331184,,19,115
460,2016-5-16,2016,5,16,2,4jh0rs,(batter|pitcher)2vec - Jupyter notebook for learning distributed representations of MLB players.,https://www.reddit.com/r/MachineLearning/comments/4jh0rs/batterpitcher2vec_jupyter_notebook_for_learning/,[deleted],1463332887,[deleted],2,9
461,2016-5-16,2016,5,16,3,4jhay0,General Purpose Deep Learning Classifier open source project.,https://www.reddit.com/r/MachineLearning/comments/4jhay0/general_purpose_deep_learning_classifier_open/,Antreas_,1463337025,"Dear r/machinelearning friends,

Today I just wanted to share with you a project I've been working on with /u/entot.
The project aims to allow anyone to use deep learning to create classifiers or
regression models based on image recognition tasks. The name of the project is
DeepClassificationBot and includes all the tools one might need to build such a system.
From scrapers to get your images off google images, to model builders, trainers, data preprocessing,
deployment, and even modules to create your own twitter bot and deploy your model. We went as far
as to even add a section on how to deploy such a system on google compute engine. Please go ahead have
a look, and let us have your feedback. Oh and don't forget to check out our twitter bot @deepanimebot which can
give you the name of an anime show given an image of it. Have fun and happy training.

Regards, _Antreas

https://github.com/AntreasAntoniou/DeepClassificationBot
https://twitter.com/deepanimebot
 
",5,0
462,2016-5-16,2016,5,16,3,4jhe96,How to test classifier better than chance using k-fold cross-validation?,https://www.reddit.com/r/MachineLearning/comments/4jhe96/how_to_test_classifier_better_than_chance_using/,Brighteye,1463338314,"I have 400 units and 10 groups, and I'm classifying the units' group membership using a discriminant function analysis or linear discriminant analysis.

During cross-validation, I want to test that my solution is doing a better job at classifying them than chance (10%). I can get an error rate, but don't know how to statistically compare. With the hold-out approach, I can test it using Press' Q statistic or Maximum Chance Criterion. But with k-fold I don't think I can use this approach.

**Is there any way to test that my results from k-fold are better than chance?** Is the error rate just descriptive and no way to test?

Would appreciate any thoughts. Preferably the solution would be in R but I can do calculations by hand if it's a different formula.",1,0
463,2016-5-16,2016,5,16,5,4jhqo2,"Following a lecture on ANN, I'm a little confused about how to compute the output error for a neuron in the final layer. (x-post from /r/NeuralNetwork)",https://www.reddit.com/r/MachineLearning/comments/4jhqo2/following_a_lecture_on_ann_im_a_little_confused/,gromit190,1463342991,"Hey guys,

I've been following these online lecture videos, and I'm trying to write a small Java application to play around with ANN.

I've gotten a little stuck here: https://youtu.be/Ih5Mr93E-2c?t=54m20s

I can't wrap my head around how to compute the output error of a neuron in the final layer.

Lets say I have a neuron signal ""s"", an activation function ""f(x)"", a neuron output ""x"" which is the signal fed through the activation function ( i.e. x=f(s) ), and finally the derivative of the activation function f'(x). For this particular neuron, what is the equation to find the neuron output error ""delta""?

Here's a screenshot of the equation from the video:
http://i.imgur.com/wP4x6RF.png

Cheers",7,0
464,2016-5-16,2016,5,16,5,4jhuk4,"Expanding your machine learning toolkit: Randomized search, computational budgets, and new algorithms",https://www.reddit.com/r/MachineLearning/comments/4jhuk4/expanding_your_machine_learning_toolkit/,DrLegend,1463344434,,0,7
465,2016-5-16,2016,5,16,6,4ji0xe,An Introduction to Scientific Python (and a Bit of the Maths Behind It),https://www.reddit.com/r/MachineLearning/comments/4ji0xe/an_introduction_to_scientific_python_and_a_bit_of/,julian88888888,1463346953,,0,18
466,2016-5-16,2016,5,16,6,4ji238,Build a Game AI - ML for Hackers #3,https://www.reddit.com/r/MachineLearning/comments/4ji238/build_a_game_ai_ml_for_hackers_3/,[deleted],1463347414,[deleted],0,0
467,2016-5-16,2016,5,16,7,4jibb6,"For fun, I trained a RNN model to answer questions using the most poorly rated responses from /r/askreddit. Now it's a twitterbot! @auto_stoopidity",https://www.reddit.com/r/MachineLearning/comments/4jibb6/for_fun_i_trained_a_rnn_model_to_answer_questions/,lildeam0n,1463351077,,8,0
468,2016-5-16,2016,5,16,7,4jidz8,Top players on Kaggle,https://www.reddit.com/r/MachineLearning/comments/4jidz8/top_players_on_kaggle/,whoisthriller,1463352140,"Why the majority of top players on Kaggle are from CS/Eng background? It is very rare to see top players that are from Math/Statistics backgound. I thought a Math/Statistics degree should have the edge to data science, but it looks like not...",19,4
469,2016-5-16,2016,5,16,8,4jiixw,How do I train a DQN with a LSTM-layer?,https://www.reddit.com/r/MachineLearning/comments/4jiixw/how_do_i_train_a_dqn_with_a_lstmlayer/,ddfk1337,1463354310,"So in a paper from last year* an LSTM was added between the convolutional layers and the predicted Q-function. It does not say in the paper how one should train such a network. So I am wonder if there is any papers out there on the topic of training a CNN with LSTM on top or if any one has a good idea of how it could be done. 



*http://arxiv.org/pdf/1507.06527.pdf",3,0
470,2016-5-16,2016,5,16,13,4jjj0t,PlaNet - Photo Geolocation and Album Classification,https://www.reddit.com/r/MachineLearning/comments/4jjj0t/planet_photo_geolocation_and_album_classification/,Jxieeducation,1463371319,,0,0
471,2016-5-16,2016,5,16,17,4jk6w1,Statistics degree or CS degree for machine learning,https://www.reddit.com/r/MachineLearning/comments/4jk6w1/statistics_degree_or_cs_degree_for_machine/,whoisthriller,1463386505,which one is a better fit for machine learning?,15,1
472,2016-5-16,2016,5,16,17,4jk8tf,"Spark streaming, get x batch of window",https://www.reddit.com/r/MachineLearning/comments/4jk8tf/spark_streaming_get_x_batch_of_window/,Setheton,1463387833,"I'm using pyspark to do some operations on 2 incoming streams.
Also I do window operations on both streams.

    stream = ssc.  
    streamW = stream.window(100,1)

for example.
One of the operations requires me to look at a specific batch inside **streamW** , so for example if the window length is 100, I want to look at the batch that is number 3 of the window.
More specifically I want to look at the first batch (ie: the batch that in next time interval is going to be removed from the window ).
Just to be clear: I want to get the batch leaving the window

Any ideas how to accomplish this ?
",2,0
473,2016-5-16,2016,5,16,18,4jkdn3,Does there exist an implementation of cost sensitive neural networks?,https://www.reddit.com/r/MachineLearning/comments/4jkdn3/does_there_exist_an_implementation_of_cost/,[deleted],1463390993,[deleted],2,0
474,2016-5-16,2016,5,16,19,4jkhee,NN with Q-learning: which activation function with which cost function?,https://www.reddit.com/r/MachineLearning/comments/4jkhee/nn_with_qlearning_which_activation_function_with/,Ijatsu,1463393277,"Hello,

I've been messing around with Q-learning adapted with NN, after I read these two articles:

http://arxiv.org/pdf/1312.5602v1.pdf

https://www.cs.swarthmore.edu/~meeden/cs81/s12/papers/MarkStevePaper.pdf

I'm not yet ready to understand and implement conv NN so I just fooled around with normal NN. I've been told to use sigmoid as activation function and cross-entropy as cost function.

The problem is it doesn't seem to work well with Q-learning since I want my output to be a real number, using a probability output seem like a bad hack to me.

The papers I read seem to use the quadratic cost function but I have no detail about the activation function. I checked the github of someone who implemented all these and he seem to not use any activation function at all.

I've also been wondering if I shouldn't separate the reward in two in order to have a ""reward"" output and a ""punishment"" output, or have multiple kind of reward output... Just sort of translate my bit output into a binary number.


I'm not good at math so I don't really want to put a lot of work into designing and implementing something that isn't promising. What do reddit think about it?

Thanks!",19,6
475,2016-5-16,2016,5,16,20,4jkou3,Every little thing You Had to Find out about Paper Cutting Devices,https://www.reddit.com/r/MachineLearning/comments/4jkou3/every_little_thing_you_had_to_find_out_about/,metalshapeinnovation,1463397578,[removed],0,1
476,2016-5-16,2016,5,16,20,4jkt2u,Can someone please ELI5 inception modules as seen in GoogLeNet,https://www.reddit.com/r/MachineLearning/comments/4jkt2u/can_someone_please_eli5_inception_modules_as_seen/,niujin,1463399800,[removed],0,3
477,2016-5-16,2016,5,16,21,4jl0s8,"I'm struggling with math while I'm reading Machine learning: A probabilistic perspective like I'm confused about quantiles, inverse cdf etc. Could you recommend me a book that I should read first?",https://www.reddit.com/r/MachineLearning/comments/4jl0s8/im_struggling_with_math_while_im_reading_machine/,Mr__Christian_Grey,1463403433,,12,25
478,2016-5-16,2016,5,16,22,4jl30b,Moving from Academia to Industry,https://www.reddit.com/r/MachineLearning/comments/4jl30b/moving_from_academia_to_industry/,xristos_forokolomvos,1463404383,"Before one year I knew nothing about ML and Data Science. My first touch with ML was through Andrew Ng's course which I fell in love with and finished in two months. After completing many more relevant MOOCs and landing an internship, I finally got my first ML job. I'm feeling kinda lost because up until now I was only a student and it was never a prerequisite that my code runs in a product.

Here's where I need your help:

1. Any Machine Learning practitioners out here working in Python for their everyday tasks to point me towards resources on writing code ""the business way""? During this last year all my programming projects were pretty much personal, so tips / tricks to help me collaborate with other developers would be great.

2. From what I understood, I will be in the ""algorithm"" team where we design and hand it over to engineers to implement in the cloud. Any advises on best practices for scaling python ML code?

This sub has been a huge inspiration for me looking all the cool stuff you guys do and now I need your help to take my enthusiasm one step further :)",28,84
479,2016-5-17,2016,5,17,0,4jlr02,Keven Murphy's book or Christopher Bishop's book for finance student for financial modelling using machine learning?,https://www.reddit.com/r/MachineLearning/comments/4jlr02/keven_murphys_book_or_christopher_bishops_book/,Mr__Christian_Grey,1463413378,,1,0
480,2016-5-17,2016,5,17,2,4jm68i,What library should I be using for audio processing?,https://www.reddit.com/r/MachineLearning/comments/4jm68i/what_library_should_i_be_using_for_audio/,throwaway_sss,1463418853,"Hi,
 
I am trying to use TensorFlow to try and solve a task related to audio. Any recommendations on what library to use to process the audio file and have it in a format I can feed to an RNN for example? I have been only using TensorFlow for images, so I am a total noob here when it comes to audio. Any help would be greatly appreciated. Thank you",2,0
481,2016-5-17,2016,5,17,2,4jm96q,ELI5 multi class SVM gesture recognition,https://www.reddit.com/r/MachineLearning/comments/4jm96q/eli5_multi_class_svm_gesture_recognition/,74101108108101,1463419912,"I'm an interaction designer and I'm writing my Master's thesis about gesture recognition in modern HCI. As a designer, I have to write about 150 words about the functioning of multi class SVM for gesture recognition. Any help?
---
I get the very basics, but don't know if a whole traced image would be divided into a class, or just some 3D locations of parts of the hand?",0,0
482,2016-5-17,2016,5,17,3,4jmibi,Student Performance Prediction System.,https://www.reddit.com/r/MachineLearning/comments/4jmibi/student_performance_prediction_system/,dubcy,1463423098,[removed],0,1
483,2016-5-17,2016,5,17,4,4jmq45,Skipgram isnt Matrix Factorization,https://www.reddit.com/r/MachineLearning/comments/4jmq45/skipgram_isnt_matrix_factorization/,olBaa,1463425708,,8,30
484,2016-5-17,2016,5,17,4,4jms78,How to force a convolutional network to learn a specific feature?,https://www.reddit.com/r/MachineLearning/comments/4jms78/how_to_force_a_convolutional_network_to_learn_a/,sodeypunk,1463426380,"I am training a convolutional network to identify digits in an image. On several occasions, the network misidentifies a 3 as a 5. 

If you think about the differences in these two characters, the main difference is the top half of the 3 is backwards from the top half of the 5. Therefore, is there a way to help the network to concentrate on those features when training and predicting?

I have close to 1 million training data so data shouldnt be the problem either.",9,0
485,2016-5-17,2016,5,17,4,4jmvfr,Going Deeper Into Deep Learning With JavaCPP &amp; JavaCV,https://www.reddit.com/r/MachineLearning/comments/4jmvfr/going_deeper_into_deep_learning_with_javacpp/,vonnik,1463427439,,1,0
486,2016-5-17,2016,5,17,4,4jmwvh,What topics do you wish you studied?,https://www.reddit.com/r/MachineLearning/comments/4jmwvh/what_topics_do_you_wish_you_studied/,raza91,1463427914,"Do you feel you would have been better of studying more theoretical or applied ML topics? More logic? Statistics?

I'm asking because I been accepted onto two Machine Learning programs with fairly different course options. One has more coding/logic the other more statistics. In fact, I would really appreciate if any of you guys could have a quick look through the courses available and let me know which you think is better/more relevant!

1. Computer Science (Machine Learning)
http://www.imperial.ac.uk/computing/prospective-students/courses/pg/specialist-degrees/ml/

2. Computational Statistics and Machine Learning
http://www.cs.ucl.ac.uk/degrees/msc_csml/
(You may have to click on the course structure tab to see the courses)

Which of the two would you prefer to do? 

FYI: My undergrad was in Mathematics and Economics.

",14,0
487,2016-5-17,2016,5,17,6,4jncp2,"Prototyping git's word suggestion mechanism in Python in an afternoon, without being an IR expert",https://www.reddit.com/r/MachineLearning/comments/4jncp2/prototyping_gits_word_suggestion_mechanism_in/,detachead,1463433210,"I was wondering how hard can it be to create a simple mechanism like the word suggestion mechanism that git uses when you accidentally misspell a command.

Just to be clear, I don't propose any new method, I don't claim that I did something that outperforms any existing mechanism. I just wanted to see how well can the simplest thing I though of could perform. With some basic ML I got some quite encouraging results.

here is the repo https://github.com/PGryllos/word_similarity/

Anyone fond of providing some feedback to extend this afternoon journey is welcome.",2,0
488,2016-5-17,2016,5,17,6,4jngue,What is your development environment for ml?,https://www.reddit.com/r/MachineLearning/comments/4jngue/what_is_your_development_environment_for_ml/,realhamster,1463434606,"Was currently working on some neural networks on an AWS server, and was trying to get a good workflow for it.

Currently use the ipython notebook, which is really good for getting graphs, but really uncomfortable for writing code. Ideally id be able to write code on vim and get the results on my web browser from ipython notebook.

Anyone else try something like this, or some other dev environment that is good for ml?",32,6
489,2016-5-17,2016,5,17,7,4jnlnd,[1604.06915] On the Sample Complexity of End-to-end Training vs. Semantic Abstraction Training,https://www.reddit.com/r/MachineLearning/comments/4jnlnd/160406915_on_the_sample_complexity_of_endtoend/,aldole_chirale,1463436278,,5,7
490,2016-5-17,2016,5,17,7,4jnq45,Question regarding convergence proof for Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/4jnq45/question_regarding_convergence_proof_for/,question99,1463437973,"While reading the [Generative Adversarial Networks](http://arxiv.org/abs/1406.2661) paper I encountered [the following statement in section 4.2](http://imgur.com/NQqAz73): ""Proof. Consider V (G, D) = U(pg, D) as a function of pg as done in the above criterion. Note
that U(pg, D) is convex in pg.""

I don't understand why U(pg, D) is convex in pg. As far as I understand, pg is a probability distribution which in this case means that U(pg, D) is a function of many variables (the parameters of both pg and D combined). To say anything about the convexity of U(pg, D) we need to calculate the Hessian of U(pg, D), don't we? Or is there any other way that allows us to show the convexity of U(pg, D) in pg?",5,4
491,2016-5-17,2016,5,17,7,4jnr99,Build a Game AI using OpenAI's Gym &amp; Deep Q Learning,https://www.reddit.com/r/MachineLearning/comments/4jnr99/build_a_game_ai_using_openais_gym_deep_q_learning/,llSourcell,1463438401,,0,15
492,2016-5-17,2016,5,17,9,4joa03,"Google punts off variational autoencoder homotopies as ""poetry""",https://www.reddit.com/r/MachineLearning/comments/4joa03/google_punts_off_variational_autoencoder/,cjmcmurtrie,1463445452,,14,9
493,2016-5-17,2016,5,17,10,4jodyn,Older nvidia Tesla boards,https://www.reddit.com/r/MachineLearning/comments/4jodyn/older_nvidia_tesla_boards/,DeepRoast,1463447100,"You can find some nice boards on ebay for $100-$130 that use to be several $1k.

Are these still good for NN compared to regular consumer gaming GPU's ?

Something like this:
http://www.ebay.com/itm/NVIDIA-TESLA-M2090-SERVER-GPU-COMPUTING-CARD-/222113558332?hash=item33b6ffef3c:g:kAYAAOSwiYFXFoz5

I have a small AMD cluster now of 4 cards.  Wanting to get into nvidia and wondering if this is a good price per power.",12,4
494,2016-5-17,2016,5,17,10,4joh84,Association Rules: How do you put these into practice?,https://www.reddit.com/r/MachineLearning/comments/4joh84/association_rules_how_do_you_put_these_into/,question89,1463448428,"I've learned how to create product association rules.  so, I have alot of data on what products are being purchased together, etc at my company.

What are common ways people use these association rules to make business decisions?",1,0
495,2016-5-17,2016,5,17,11,4jot5h,The relationship between vector space modelling and support vector machines,https://www.reddit.com/r/MachineLearning/comments/4jot5h/the_relationship_between_vector_space_modelling/,MachineLearningNoob,1463453074,[removed],0,1
496,2016-5-17,2016,5,17,11,4jou3v,Is this an appropriate machine learning problem?,https://www.reddit.com/r/MachineLearning/comments/4jou3v/is_this_an_appropriate_machine_learning_problem/,harglefargins87,1463453507,[removed],1,1
497,2016-5-17,2016,5,17,12,4joxs7,Mojo CNN (C++),https://www.reddit.com/r/MachineLearning/comments/4joxs7/mojo_cnn_c/,gnawice,1463455100,"Just wanted to mention (another) github CNN package called mojo-cnn (https://github.com/gnawice/mojo-cnn).  It's small, portable, optimized for CPU deployment, and has no dependencies. 

",6,11
498,2016-5-17,2016,5,17,13,4jp51v,Need help understanding logic behind python code,https://www.reddit.com/r/MachineLearning/comments/4jp51v/need_help_understanding_logic_behind_python_code/,[deleted],1463458418,[removed],0,1
499,2016-5-17,2016,5,17,14,4jpgvk,What is the filters,https://www.reddit.com/r/MachineLearning/comments/4jpgvk/what_is_the_filters/,mixmachinery,1463464327,,0,1
500,2016-5-17,2016,5,17,15,4jpluv,Ranking (or learning from) tree-structured inputs with a neural network,https://www.reddit.com/r/MachineLearning/comments/4jpluv/ranking_or_learning_from_treestructured_inputs/,treeinput,1463466994,"Hi,

I've got an interesting problem and I don't seem to know how to solve it. 

I've got a data structure that is a tree-shaped structure. (It could even be a DAG, but I've not encountered one so far). It's a generic tree/graph - so there are n number of children and possibly n number of parents. So far I've not encountered any tree deeper than 15 levels. A node contains 3 or 4 fields of data (there are 4 different types of nodes)

The trees are mostly random (it's actually a representation of the user actions in a game). The task at hand is 

* to learn to either synthesise a ""best tree""
* or generate a lot of trees(there currently exists a method to generate valid trees, which is mainly used for testing but I would also like some input re using Q-networks to generate trees), and rank them

Assuming I do want to use a neural network, how would I input trees to the neural network? I know I can encode the nodes in a postorder array or something, but the heirarchy in the tree does encode information, no?

I've searched online for papers, however, Google seems to keep pointing me to recursive neural networks (not recurrent, which is the popular one), but papers on *recursive* NNs are scant and mostly deal with parsing test and generating trees. 

Anyone have any ideas to help me out?

Thanks",3,2
501,2016-5-17,2016,5,17,16,4jpqu6,How good is cmu sphinx for speech recognition?,https://www.reddit.com/r/MachineLearning/comments/4jpqu6/how_good_is_cmu_sphinx_for_speech_recognition/,mumbaimaari,1463469891,,5,0
502,2016-5-17,2016,5,17,17,4jpvg9,Testing analysis in predictive analytics: Receiver operating characteristic (ROC) curve analysis,https://www.reddit.com/r/MachineLearning/comments/4jpvg9/testing_analysis_in_predictive_analytics_receiver/,martinanalytics,1463472657,,0,0
503,2016-5-17,2016,5,17,19,4jq97l,"Inside Googles Quantum Computing Lab, Questing for the Perfect Computer",https://www.reddit.com/r/MachineLearning/comments/4jq97l/inside_googles_quantum_computing_lab_questing/,Louying,1463481288,,5,13
504,2016-5-17,2016,5,17,20,4jqiaj,Is Kevin Murphy's book collection of research papers?,https://www.reddit.com/r/MachineLearning/comments/4jqiaj/is_kevin_murphys_book_collection_of_research/,Mr__Christian_Grey,1463486034,"I'm currently doing Introduction to statistical learning and then I will dive into Pattern recognition and Machine learning. My question is if I plan to read murphy's book after Bishop's book, how should I read it? Should I read it from start to end or read only those chapters which I'm interested in? or Should I go for research papers then?",0,0
505,2016-5-17,2016,5,17,21,4jqj74,Predicting bounding boxes for text using cnn.,https://www.reddit.com/r/MachineLearning/comments/4jqj74/predicting_bounding_boxes_for_text_using_cnn/,cvikasreddy,1463486471,"I have images(100) of identity cards(manually taken so not of same size) and I need to extract the text in it and format accordingly.

I used tesseract to predict bounding boxes for each letter and am successful to some extent but some letters are not bounded(please open the link).

[http://i.imgur.com/USVKp6h.png](http://i.imgur.com/USVKp6h.png)

So, I have around 5000 bounding boxes in all images combined.

I want to train a cnn with the predicted boxes and obtain boxes for other letters.

Then after obtaining boxes for all letters, use other cnn to classify(predict) the letter. 

Can you please tell me how to train it so that the when testing, remaining letters are also bounded.

I will get some more images(~100) later.",0,0
506,2016-5-17,2016,5,17,21,4jqpdz,An interesting article on Jakob Foerster and the future of machine learning,https://www.reddit.com/r/MachineLearning/comments/4jqpdz/an_interesting_article_on_jakob_foerster_and_the/,Duffai,1463489069,,0,1
507,2016-5-17,2016,5,17,21,4jqpq5,Why Logistic Regression Uses a Sigmoid Function,https://www.reddit.com/r/MachineLearning/comments/4jqpq5/why_logistic_regression_uses_a_sigmoid_function/,pmigdal,1463489199,,16,1
508,2016-5-17,2016,5,17,21,4jqrlo,Biasing a network,https://www.reddit.com/r/MachineLearning/comments/4jqrlo/biasing_a_network/,Kiuhnm,1463489919,"I know of basically 4 ways to bias a network:

1. Penalization
2. Projection
3. Structural design
4. Reparametrization

Just to be clear we're on the same page, here are a few examples:

1. L2 or L1 regularization is an example of penalization.
2. If we update the parameter theta by SGD and then project it back to some space of allowable values (i.e. we choose the closest value in that space), we're doing projection.
3. Convolutional networks are an example of careful structural design to bias a network towards hierarchical representations.
4. Batch normalization is an example of reparametrization.

I read that the first attempts at normalizing minibatches (i.e. enforce zero mean and unit variance) involved penalization and projection. The problem with penalization was that it resulted in imperfect normalization, whereas the problem with projection was that it wasted a lot of time because the SGD repeatedly proposed updates that were almost completely undone by projection. Reparametrization turned out to be an elegant way to solve both problems.

So I thought *why don't we use reparametrization instead of penalization and projection everywhere?* I tried to replace L2 regularization with reparametrization this way:

    W_k &lt;- a_k W_k / ||W_k||

where k is the layer and a_k controls the norm of W_k. Of course, we also have to penalize the a_i in this case.

To my disappointment, it didn't work very well. The computation time increased significantly and I couldn't see any improvement over plain L2 regularization.

Any thoughts? What's your experience with reparametrization in general?",7,5
509,2016-5-17,2016,5,17,22,4jqxko,Cogitai: empowering machines to understand the world through their own experience,https://www.reddit.com/r/MachineLearning/comments/4jqxko/cogitai_empowering_machines_to_understand_the/,pierrelux,1463492250,,10,2
510,2016-5-17,2016,5,17,23,4jr1e8,AI learns and recreates Nobel-winning physics experiment,https://www.reddit.com/r/MachineLearning/comments/4jr1e8/ai_learns_and_recreates_nobelwinning_physics/,berlinjobguy,1463493620,,2,5
511,2016-5-17,2016,5,17,23,4jr3p0,Data Mining Algorithm,https://www.reddit.com/r/MachineLearning/comments/4jr3p0/data_mining_algorithm/,moglimo,1463494475,[removed],0,1
512,2016-5-17,2016,5,17,23,4jr6k2,Blackbox Challenge Neural Network,https://www.reddit.com/r/MachineLearning/comments/4jr6k2/blackbox_challenge_neural_network/,uapan,1463495541,"If anyone is interested I started on a submission for the challenge at www.blackboxchallenge.com. But, I will probably not spend any more time on it and anyone is welcome to use whatever part of it they like. You can find it at https://github.com/danielzak/blackboxchallenge

There is very little information about the challenge itself, and this solution does only seem to be a little better than random (if that) when I have left it to train for a few hours. But still, it might be a start for someone else. 

It would be great to see someone else improve on this or come back with ideas for improvement!",6,0
513,2016-5-18,2016,5,18,0,4jrdr9,Multi-Dimensional Scaling,https://www.reddit.com/r/MachineLearning/comments/4jrdr9/multidimensional_scaling/,[deleted],1463498039,[deleted],0,0
514,2016-5-18,2016,5,18,0,4jri09,[1605.04603] Improving the Neural Algorithm of Artistic Style,https://www.reddit.com/r/MachineLearning/comments/4jri09/160504603_improving_the_neural_algorithm_of/,alexjc,1463499462,,7,30
515,2016-5-18,2016,5,18,0,4jrlrg,Predicting on part of image based on other part.,https://www.reddit.com/r/MachineLearning/comments/4jrlrg/predicting_on_part_of_image_based_on_other_part/,cvikasreddy,1463500694,"I have images of identity cards(manually taken so not of same size) and I need to extract the text in it.

I used tesseract to predict bounding boxes for each letter and am successful to some extent but some letters are not bounded(please open the link).
http://i.imgur.com/USVKp6h.png

So, I have around 5000 bounding boxes in all images combined.

I want to train it so as to predict bounding boxes for remaining letters.

After predicting the bounding boxes I will try to classify the image into characters.

This is different from conventional machine learning problem where I donot have training and testing data separately. 

Edit1:Some more images http://i.imgur.com/VPL9zix.png , http://i.imgur.com/W3QW4KB.png
",4,0
516,2016-5-18,2016,5,18,1,4jrph8,Is Metaoptimize QA dead or just down?,https://www.reddit.com/r/MachineLearning/comments/4jrph8/is_metaoptimize_qa_dead_or_just_down/,[deleted],1463501960,[deleted],0,0
517,2016-5-18,2016,5,18,1,4jrqgq,Google attempting to patent deep neural network (LSTM) for machine translation,https://www.reddit.com/r/MachineLearning/comments/4jrqgq/google_attempting_to_patent_deep_neural_network/,shmageggy,1463502294,,45,94
518,2016-5-18,2016,5,18,1,4jruwo,"""Deep Learning""...is actually pretty shallow",https://www.reddit.com/r/MachineLearning/comments/4jruwo/deep_learningis_actually_pretty_shallow/,SenseEnergy,1463503728,,3,0
519,2016-5-18,2016,5,18,1,4jruzl,ICLR 2016 Takeaways,https://www.reddit.com/r/MachineLearning/comments/4jruzl/iclr_2016_takeaways/,madisonmay,1463503760,,0,36
520,2016-5-18,2016,5,18,2,4js32f,Great tutorial on how to train your own Inception image classifier with TensorFlow.,https://www.reddit.com/r/MachineLearning/comments/4js32f/great_tutorial_on_how_to_train_your_own_inception/,linuxjava,1463506351,,1,3
521,2016-5-18,2016,5,18,2,4js7hc,See how we generate client libraries for our machine learning system providing personalized recommendations as a service.,https://www.reddit.com/r/MachineLearning/comments/4js7hc/see_how_we_generate_client_libraries_for_our/,kordikp,1463507778,,0,1
522,2016-5-18,2016,5,18,3,4js8zc,CMS makes 300 TB of high-quality data from the LHC available to the public through CERN Open Data Portal,https://www.reddit.com/r/MachineLearning/comments/4js8zc/cms_makes_300_tb_of_highquality_data_from_the_lhc/,glg00,1463508242,,0,2
523,2016-5-18,2016,5,18,3,4jsh1l,What machine learning techniques are under appreciated or going to become more popular in the future?,https://www.reddit.com/r/MachineLearning/comments/4jsh1l/what_machine_learning_techniques_are_under/,0rangecoffee,1463510894,,40,27
524,2016-5-18,2016,5,18,4,4jsldz,[1605.04850] Video2GIF: Automatic Generation of Animated GIFs from Video,https://www.reddit.com/r/MachineLearning/comments/4jsldz/160504850_video2gif_automatic_generation_of/,alexjc,1463512398,,3,3
525,2016-5-18,2016,5,18,4,4jsta2,Comparison of deep learning software,https://www.reddit.com/r/MachineLearning/comments/4jsta2/comparison_of_deep_learning_software/,linuxjava,1463515170,,0,1
526,2016-5-18,2016,5,18,5,4jstld,Comprehensive list of datasets for machine learning research,https://www.reddit.com/r/MachineLearning/comments/4jstld/comprehensive_list_of_datasets_for_machine/,linuxjava,1463515275,,3,7
527,2016-5-18,2016,5,18,6,4jt6oy,Best Undergraduate Major for ML,https://www.reddit.com/r/MachineLearning/comments/4jt6oy/best_undergraduate_major_for_ml/,SamCryBaby202,1463519819,[removed],4,2
528,2016-5-18,2016,5,18,6,4jt6tq,I'm looking for a visualization of a single and multi layer perceptrons,https://www.reddit.com/r/MachineLearning/comments/4jt6tq/im_looking_for_a_visualization_of_a_single_and/,nameless_pattern,1463519868,"I want a animation that shows thickening lines to represent the weight of the connections as it solves prop logic operators AND, OR, XOR. preference for a web page that does it live. I know I've seen one and googled a lot, hoping you guys can help me out.",1,0
529,2016-5-18,2016,5,18,6,4jta6a,Can FC layers of VGGNet be removed with no performance downgrade ?,https://www.reddit.com/r/MachineLearning/comments/4jta6a/can_fc_layers_of_vggnet_be_removed_with_no/,Tamazy,1463521082,"In the awesome online courses of Stanford, [CS231](http://cs231n.github.io/convolutional-networks/), it is said that : 

&gt; A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M). Most of these parameters are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters.

I don't understand the last sentence, because when VGGNet is used as a features extractor, the penultimate FC layer gives the richest features on VOC2007/2012 or MIT67. Do you have any references ? 
",2,0
530,2016-5-18,2016,5,18,6,4jtdds,R script to take an H2o models weights and biases and send them through the NeuralNetTools olden variable importance function,https://www.reddit.com/r/MachineLearning/comments/4jtdds/r_script_to_take_an_h2o_models_weights_and_biases/,eristoddle,1463522232,,0,0
531,2016-5-18,2016,5,18,7,4jte1k,DanDoesData pycaffe basics,https://www.reddit.com/r/MachineLearning/comments/4jte1k/dandoesdata_pycaffe_basics/,vanboxel,1463522464,,1,0
532,2016-5-18,2016,5,18,7,4jtfgh,Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records,https://www.reddit.com/r/MachineLearning/comments/4jtfgh/deep_patient_an_unsupervised_representation_to/,beamsearch,1463522933,,10,12
533,2016-5-18,2016,5,18,8,4jtrro,Tensorflow Charnn output confustion.,https://www.reddit.com/r/MachineLearning/comments/4jtrro/tensorflow_charnn_output_confustion/,haskkk,1463527743,"  In this example of a character based RNN the /u/sherjilozair does the folling to the outputs:   
    
    outputs, last_state = seq2seq.rnn_decoder(inputs, self.initial_state, cell, loop_function=loop if infer else None, scope='rnnlm')
    output = tf.reshape(tf.concat(1, outputs), [-1, args.rnn_size])
    

in other examples, only the last output is used, such as  
    outputs = outputs[-1]
    
Why does the charnn not simply take the last element from the outputs? ",2,0
534,2016-5-18,2016,5,18,10,4ju6qh,Why does my association model find subgroups in a dataset when there shouldn't any?,https://www.reddit.com/r/MachineLearning/comments/4ju6qh/why_does_my_association_model_find_subgroups_in_a/,o_safadinho,1463533707,"&gt; I give a lot of information on the methods that I used to write my code. If you just want to read my question, skip to the quotes at the end.

I'm working on a project that has a goal of detecting sub populations in a group of patients. I thought this sounded like the perfect opportunity to use association rule mining as I'm currently taking a class on the subject.

I there are 42 variables in total. Of those, 20 are continuous and had to be discretized. For each variable, I used the [Freedman-Diaconis](https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule) rule to determine how many categories to divide a group into.

    
From there I used min-max normalization to transform my data and then I simply took the interger portion to get the final categorization.


I then also wrote a function that I used to combine this value with the variable name.

This was done to differentiate variables that have the same value, but appear in different columns. For example, having a value of 1 for variable x14 means something different from getting a value of 1 in variable x20. The string transform function would create 14x1 and 20x1 for the previously mentioned examples.

After this, I wrote everything to a file in basket format and I used the apriori package in [Orange](http://orange.biolab.si/) to see if there were any association rules.

Using this, technique I found quite a few association rules with my testing data.

&gt; THIS IS WHERE I HAVE A PROBLEM

When I read the notes for the training data, there is this note

&gt; ...That is, the only
reason for the differences among observed responses to the same treatment across patients is
random noise. Hence, there is NO meaningful subgroup for this dataset...

My question is, 
&gt; *why do I get multiple association rules that would imply that there are subgroups, when according to the notes I shouldn't see anything?*

I'm getting lift numbers that are above 2 as opposed to the 1 that you should expect if everything was random like the notes state.

    Supp Conf  Rule
     0.3  0.7  6x0 -&gt; trt1


Even though my code runs, I'm not getting results anywhere close to what should be expected. This leads me to believe that I messed something up, but I'm not sure what it is.",4,0
535,2016-5-18,2016,5,18,10,4ju9rw,Coursera/ML course: Buying MATLAB after the course,https://www.reddit.com/r/MachineLearning/comments/4ju9rw/courseraml_course_buying_matlab_after_the_course/,[deleted],1463534888,[deleted],7,0
536,2016-5-18,2016,5,18,11,4jufkq,Is there some readable stuff on cost functions?,https://www.reddit.com/r/MachineLearning/comments/4jufkq/is_there_some_readable_stuff_on_cost_functions/,Icko_,1463537200,"So, we've all used several cost functions, depending on the task, and made a few up, for a complicated problem. A good example of what I'm thinking of is the cost function of ladder networks - different cost function gives you a completely new algorithm. My question is, is there some literature on choosing/creating cost functions? ",5,8
537,2016-5-18,2016,5,18,11,4juldt,Deep learning for tabular data,https://www.reddit.com/r/MachineLearning/comments/4juldt/deep_learning_for_tabular_data/,MasterEpictetus,1463539574,"Neural networks are great for unstructured data, such as text, images, and sound. However, for tabular data, tree-based ensemble models work much better. They are also very versatile requiring little input pre-processing (e.g., no normalization). 

What is it about how neural networks work that limits their performance on tabular data (as apposed to trees)? Are there any attempts to address this limitation?

As an example application, I would like to train a single model on a mix of tabular, image and text data using backpropagation. Currently I have an ensemble of random forest + neural network which are trained separately. It would be great to have a single learning framework that is trained simultaneously on all three data sources.",8,0
538,2016-5-18,2016,5,18,13,4juvgd,Can machine learning be used to reduce the compute time of physical simulations?,https://www.reddit.com/r/MachineLearning/comments/4juvgd/can_machine_learning_be_used_to_reduce_the/,lovewillsetmefree,1463544161,,14,0
539,2016-5-18,2016,5,18,13,4juw5z,Cool deep learning / ML blogs?,https://www.reddit.com/r/MachineLearning/comments/4juw5z/cool_deep_learning_ml_blogs/,AlNejati,1463544486,"What are some of your favorite blogs/sites from ML researchers? Don't have to be big names, just people with interesting things to say. Feel free to pimp your own website (just as long as it fits the criterion of being interesting!)",27,101
540,2016-5-18,2016,5,18,14,4jv58m,RIP Gitxiv,https://www.reddit.com/r/MachineLearning/comments/4jv58m/rip_gitxiv/,Jxieeducation,1463548919,"http://gitxiv.com/

",1,0
541,2016-5-18,2016,5,18,17,4jvm02,Free ML eBook today only: Machine Learning with R,https://www.reddit.com/r/MachineLearning/comments/4jvm02/free_ml_ebook_today_only_machine_learning_with_r/,PacktStaff,1463558636,,6,19
542,2016-5-18,2016,5,18,17,4jvmjf,Will machine learning mean the end of coding?,https://www.reddit.com/r/MachineLearning/comments/4jvmjf/will_machine_learning_mean_the_end_of_coding/,GabriellaJ,1463558952,,5,0
543,2016-5-18,2016,5,18,17,4jvps1,Machine learning for tiny teams,https://www.reddit.com/r/MachineLearning/comments/4jvps1/machine_learning_for_tiny_teams/,exonarco,1463561079,,0,1
544,2016-5-18,2016,5,18,18,4jvsmi,How to deal with Features having high cardinality,https://www.reddit.com/r/MachineLearning/comments/4jvsmi/how_to_deal_with_features_having_high_cardinality/,ohanlom4,1463562855,"I am building a simple classification model for a client, the classification model is used for identifying negative or positive feedback on a ticketing system. The tickets have alot of categorical data with high cardinality and the data should be of significance in the model. Is there any standard ways of using these categories without creating hugely sparse data.",9,1
545,2016-5-18,2016,5,18,18,4jvsqz,Everything for you to begin your machine learning journey,https://www.reddit.com/r/MachineLearning/comments/4jvsqz/everything_for_you_to_begin_your_machine_learning/,Mishchandan,1463562939,,0,1
546,2016-5-18,2016,5,18,18,4jvttv,What are some good Machine learning apps,https://www.reddit.com/r/MachineLearning/comments/4jvttv/what_are_some_good_machine_learning_apps/,Mishchandan,1463563608,[removed],0,1
547,2016-5-18,2016,5,18,18,4jvwn2,How theano manages to calculate automatically gradient for negative log-likelihood?,https://www.reddit.com/r/MachineLearning/comments/4jvwn2/how_theano_manages_to_calculate_automatically/,JustARandomNoob165,1463565235,"I have been going through the tutorial http://deeplearning.net/tutorial/logreg.html and one thing I cannot understand is that how automatic differentiation works for such function negative_log_likelihood, where we have composition of 'mean', 'log' functions and matrix indexing? The part with matrix indexing( [T.arange(y.shape[0]), y] ) is the confusing as it is not clear how it can be linked to the derivative chain-rule. 

    def negative_log_likelihood(self, y):
        return -T.mean(T.log(self.p_y_x)[T.arange(y.shape[0]), y])",4,0
548,2016-5-18,2016,5,18,20,4jw4w3,How to classify in conv net,https://www.reddit.com/r/MachineLearning/comments/4jw4w3/how_to_classify_in_conv_net/,[deleted],1463569836,[removed],1,0
549,2016-5-18,2016,5,18,20,4jw6i9,Using external Nvidia external GPU's with Apple MacBook Air,https://www.reddit.com/r/MachineLearning/comments/4jw6i9/using_external_nvidia_external_gpus_with_apple/,ankscricholic,1463570700,"After developing an interest for deep learning and neural networks, I was looking around for the cheapest option for getting started. I was wondering if it is possible to just buy an external Nvidia graphics card to go along with my MacBook Air for deep learning puropose. I know about how important CUDA is for NN due to framework dependencies, so,  is there any way I can use Nvidia eGPU's on OSX? If yes, Which one should I buy? I would appreciate the help.",12,5
550,2016-5-18,2016,5,18,20,4jw7a1,"A curated list of R tutorials for Data Science, NLP and Machine Learning",https://www.reddit.com/r/MachineLearning/comments/4jw7a1/a_curated_list_of_r_tutorials_for_data_science/,hX3S,1463571101,,0,6
551,2016-5-18,2016,5,18,21,4jwe0a,"Amazon goes open source with machine-learning tech, competing with Google's TensorFlow - GeekWire",https://www.reddit.com/r/MachineLearning/comments/4jwe0a/amazon_goes_open_source_with_machinelearning_tech/,barrettabolt,1463574182,,0,0
552,2016-5-18,2016,5,18,22,4jwlzp,Predicting popularity of online content,https://www.reddit.com/r/MachineLearning/comments/4jwlzp/predicting_popularity_of_online_content/,Tooplooxified,1463577532,,0,1
553,2016-5-18,2016,5,18,22,4jwqd2,Is there any way to implement Neuro-Fuzzy systems in Python?,https://www.reddit.com/r/MachineLearning/comments/4jwqd2/is_there_any_way_to_implement_neurofuzzy_systems/,iCHAIT,1463579220,,7,1
554,2016-5-18,2016,5,18,23,4jwxs6,Variational Autoencoder for Feature Extraction,https://www.reddit.com/r/MachineLearning/comments/4jwxs6/variational_autoencoder_for_feature_extraction/,rogertrullo,1463581966,"I would like to ask if would it be possible (rather if it can make any sense) to use a variational autoencoder for feature extraction. I ask because for the encoding part we sample from a distribution, and then it means that the same sample can have a different encoding (Due to the stochastic nature in the sampling process). Thanks!",4,2
555,2016-5-18,2016,5,18,23,4jx0sy,understanding product of experts,https://www.reddit.com/r/MachineLearning/comments/4jx0sy/understanding_product_of_experts/,[deleted],1463583016,[deleted],0,1
556,2016-5-18,2016,5,18,23,4jx2di,Visualize a Neural Network for classifying handwriting,https://www.reddit.com/r/MachineLearning/comments/4jx2di/visualize_a_neural_network_for_classifying/,root_cause_,1463583555,,5,10
557,2016-5-19,2016,5,19,0,4jx35g,understanding product of experts of Hinton,https://www.reddit.com/r/MachineLearning/comments/4jx35g/understanding_product_of_experts_of_hinton/,[deleted],1463583814,[deleted],0,1
558,2016-5-19,2016,5,19,1,4jxhdz,Stupid Random Variable question?,https://www.reddit.com/r/MachineLearning/comments/4jxhdz/stupid_random_variable_question/,KrisSingh,1463588467,"D= {X1,X2,X3,......XN} how are all X random variables.As i understand RV take value randomly but that randomness is based on some probability.So if X1 can take infintiely many values can we just not denote D = X1 rather than using N RV. Here D is the set of data points",4,0
559,2016-5-19,2016,5,19,1,4jxiq6,Question Regarding using Ngram counts to train a Neural Language Model,https://www.reddit.com/r/MachineLearning/comments/4jxiq6/question_regarding_using_ngram_counts_to_train_a/,rushimg,1463588922,"Hello, I have a dataset containing Ngram counts and I want to use it to train a neural language model. The dataset contains the number of occurrences and I wanted to include these multiple occurrences in the training process but do want to include each individual occurrence as an example( due to this greatly increasing the data set size). Is there any way to include this information properly in the gradient update? In a classifier type model this information would be easy to include bc I could adjust the predicted score by the occurrence factor, but in a language model where it trains by predicting the next word, this would be much more difficult. Im using Torch7 .Thoughts? Thanks.  ",2,3
560,2016-5-19,2016,5,19,1,4jxmzk,what setup does redditors of /r/machinelearning use for deeplearning?,https://www.reddit.com/r/MachineLearning/comments/4jxmzk/what_setup_does_redditors_of_rmachinelearning_use/,mumbaimaari,1463590314,[removed],1,1
561,2016-5-19,2016,5,19,4,4jybzi,Google supercharges machine learning tasks with TPU custom chip,https://www.reddit.com/r/MachineLearning/comments/4jybzi/google_supercharges_machine_learning_tasks_with/,joey_meyer,1463598306,,89,253
562,2016-5-19,2016,5,19,4,4jydb3,Help with getting started with Ml for stock market predictions,https://www.reddit.com/r/MachineLearning/comments/4jydb3/help_with_getting_started_with_ml_for_stock/,giantwoodygrass,1463598738,[removed],0,1
563,2016-5-19,2016,5,19,4,4jyhay,How can I take advantage of the Title when vectorizing and predicting text documents?,https://www.reddit.com/r/MachineLearning/comments/4jyhay/how_can_i_take_advantage_of_the_title_when/,userfotis,1463600000,"Hey, guys first post here, just started using scikit and I am totally new to machine learning so I was wondering if you could help me. So, I have many articles in a csv (read with pandas), which have rowID, title, content and category and I am trying to train my classifiers (KNearestNeighbor and MultinomialNB) so that if a new article comes (without me knowing the category) my classifier could...classify it. I am supposed to take advantage of the article's title for better predictions. It is like, the titles' words are slightly more indicative-have more weight- on what the article is saying. How can I do that?(I can use count, tfidf and hashing vactorizer).

Thanks in advance.",4,0
564,2016-5-19,2016,5,19,4,4jyhoi,"New Google's messenger app Allo: RNN, LSTM, beam search, semi-supervised learning",https://www.reddit.com/r/MachineLearning/comments/4jyhoi/new_googles_messenger_app_allo_rnn_lstm_beam/,[deleted],1463600127,[deleted],0,1
565,2016-5-19,2016,5,19,4,4jyhwo,"New Google's messenger app Allo: RNN, LSTM, beam search, semi-supervised learning",https://www.reddit.com/r/MachineLearning/comments/4jyhwo/new_googles_messenger_app_allo_rnn_lstm_beam/,alxndrkalinin,1463600197,,12,37
566,2016-5-19,2016,5,19,5,4jyo0w,Deep Learning Displacing Traditional Supercomputing Approaches in Climate Research,https://www.reddit.com/r/MachineLearning/comments/4jyo0w/deep_learning_displacing_traditional/,[deleted],1463602189,[deleted],1,0
567,2016-5-19,2016,5,19,6,4jz1m2,Career Questions from a total beginner,https://www.reddit.com/r/MachineLearning/comments/4jz1m2/career_questions_from_a_total_beginner/,SamCryBaby202,1463606727,"Hello All, 
Currently I am a first year mathematics major at a pretty decent U.S school(UMD college park ).I am very interested to have a career in AI and ML.Since I am slightly older than the rest of students and want to make up for the time I did at other jobs I want to start learning about AI .The trouble is I am pretty clueless about where to start and what to read since Tech and Science has bit been my strong field for quite a long time and only now I have developed an acute interest in the field.Right now I have started learning Java since its the general programming language in my school but other than that I am pretty clueless.















",3,0
568,2016-5-19,2016,5,19,7,4jz8wb,A fresh look at Douglas Hofstadters COPYCAT with Brainfuck,https://www.reddit.com/r/MachineLearning/comments/4jz8wb/a_fresh_look_at_douglas_hofstadters_copycat_with/,[deleted],1463609247,[deleted],0,1
569,2016-5-19,2016,5,19,7,4jzcwt,Teaching a machine to play music,https://www.reddit.com/r/MachineLearning/comments/4jzcwt/teaching_a_machine_to_play_music/,wombat_cannonball,1463610647,"Has anyone tried to teach a computer to play music (moreso, generate a midi file) from a score?

It seems that you could get datasets easily for training this: input is an image of the score, output is the midi file.",1,0
570,2016-5-19,2016,5,19,7,4jzede,Oil Lubricator  How Crucial They Are For Your Machinery?,https://www.reddit.com/r/MachineLearning/comments/4jzede/oil_lubricator_how_crucial_they_are_for_your/,jackerfrinandis,1463611176,,0,1
571,2016-5-19,2016,5,19,10,4k06ao,Would automata and formal languages be useful?,https://www.reddit.com/r/MachineLearning/comments/4k06ao/would_automata_and_formal_languages_be_useful/,cogsbox,1463622448,An opportunity came up to take a automata and formal languages course. Would this be applicable to machine learning? Or should I not spend the time and $$ on the course?,10,0
572,2016-5-19,2016,5,19,12,4k0l06,Which questions to ask? Startup going into NLP,https://www.reddit.com/r/MachineLearning/comments/4k0l06/which_questions_to_ask_startup_going_into_nlp/,jvdalen,1463628440,"(should this be in the questions thread?)
I'm operations manager for a startup, and we are going into the field of DL (NLP). We have a CTO who is responsible for the tech decisions. My job is to make sure that the engineering team can do their job well, that management is out of the way, that resources are available, etc. 

Although I (sort of) have a CS background, I'm currently not feeling comfortable with my knowledge. I'm doing the intro ML course on Coursera, and trying to figure out which courses to do afterwards (currently considering Udacity's DeepLearning course). I won't be building any of the tech, just want to make sure that I understand enough to do my part. 

I'm trying to figure out what the most important considerations are, thus, what are the most important questions to ask? I hoped you could help pointing to questions I'm not considering? Probably a lot, but it's hard to know what you don't know... (I can find the answers myself, mostly!)

It are not per se technical questions, more managerial questions?
- Should we build our own servers, or host them externally? https://www.reddit.com/r/MachineLearning/comments/4jw6i9/using_external_nvidia_external_gpus_with_apple/
- Is it better to have 2 decent ML engineers, or 1 brilliant one?  
- Do we need to differentiate between engineers who know how to train/build/optimize, and who know how to scale, stabilize, test then?
- What to watch out for when hiring them? https://www.reddit.com/r/MachineLearning/comments/48xv11/hiring_an_nlp_ml_engineer_how_to_assess_skill/
- Does it make sense to save on computing power, so we can hire more ML engineers, or will they be waiting around, when spending only 5-10k on hardware/AWS per year. (My average laptop makes me waste a lot of time, doing the udacity exercises). 
- Is the cost of hardware in ""buying"" or ""running (watts)"" the hardware? 
- Which tools and platforms do we use? Should this be up to the engineers, or would that give us one-sided preferences? What are the most important variables for that decision? Size of the community supporting it, companies behind the tools, specialization (some are better for vision tasks, others for NLP, etc)

Thanks!",3,0
573,2016-5-19,2016,5,19,13,4k0vlo,About the derivation of the expression 1.69 of Bishop's PRML,https://www.reddit.com/r/MachineLearning/comments/4k0vlo/about_the_derivation_of_the_expression_169_of/,ur_oot,1463633597,"How the expression 1.69 is derived by performing analytically the integration in the expression 1.68? I'm not understanding this step. 

Please let me know how to solve this problem.
Reference:http://www.rmki.kfki.hu/~banmi/elte/Bishop%20-%20Pattern%20Recognition%20and%20Machine%20Learning.pdf",7,1
574,2016-5-19,2016,5,19,14,4k1142,Control Structures Loops in R,https://www.reddit.com/r/MachineLearning/comments/4k1142/control_structures_loops_in_r/,padmajatamada,1463636514,,1,0
575,2016-5-19,2016,5,19,14,4k12zy,How machine learning will transform hospitality | Information Age,https://www.reddit.com/r/MachineLearning/comments/4k12zy/how_machine_learning_will_transform_hospitality/,lyonbeavers,1463637565,,0,0
576,2016-5-19,2016,5,19,15,4k14ln,Calculus. No Linear Algebra? Someone please clear this for me.,https://www.reddit.com/r/MachineLearning/comments/4k14ln/calculus_no_linear_algebra_someone_please_clear/,capecamorin,1463638403,"[When engineers do peer into a deep **neural network**, what they see is an ocean of math: a massive, multilayer set of **calculus** problems](http://www.wired.com/2016/05/the-end-of-code/)",10,0
577,2016-5-19,2016,5,19,15,4k18tt,How to hack into a Mac and change the password - How to,https://www.reddit.com/r/MachineLearning/comments/4k18tt/how_to_hack_into_a_mac_and_change_the_password/,akerskearns,1463640716,,0,0
578,2016-5-19,2016,5,19,16,4k1b6c,Neural networks - Can they learn how to perform a process?,https://www.reddit.com/r/MachineLearning/comments/4k1b6c/neural_networks_can_they_learn_how_to_perform_a/,klop2031,1463642051,"Can we use neural networks to learn how to perform a task? I have seen the mari/o where the NN learns to play a game. But can Neural networks do something more meaningful such as write code?

If so how would one train the network? As in what would one pass in as a training set? Would it be just a set of instructions to perform?",9,8
579,2016-5-19,2016,5,19,17,4k1hk6,Theano implementation of Tree RNNs aka Recursive Neural Networks,https://www.reddit.com/r/MachineLearning/comments/4k1hk6/theano_implementation_of_tree_rnns_aka_recursive/,ofirnachum,1463645980,,0,12
580,2016-5-19,2016,5,19,17,4k1imt,Avenues for Crowdsourcing Training Data,https://www.reddit.com/r/MachineLearning/comments/4k1imt/avenues_for_crowdsourcing_training_data/,chewxy,1463646651,"I've got a little project going on at the moment, and I would like to generate some training data. The problem of course, is that the training data I would like to generate are from a very specific field. It's not like I can go to crowdflower (MechanicalTurk is not available for Aussies...) and request workers who know something about arrows and categories. 

Now usually you can get grad students to do the annotation of corpora and stuff, but I don't have any grad students. How do you guys generate domain-specific expert-level training data? Am I SOL?",0,0
581,2016-5-19,2016,5,19,17,4k1l8p,[1605.01636] Maximal Sparsity with Deep Networks?,https://www.reddit.com/r/MachineLearning/comments/4k1l8p/160501636_maximal_sparsity_with_deep_networks/,ChocoMoi,1463648361,,0,2
582,2016-5-19,2016,5,19,18,4k1mmt,"[Q] Dataset bias, autoencoder",https://www.reddit.com/r/MachineLearning/comments/4k1mmt/q_dataset_bias_autoencoder/,TamisAchilles,1463649241,"I have been thinking and playing around with autoencoders in the context of automated feature extraction from unlabeled data.

One problem is that autoencoders tend to learn a code such that they can reconstruct the largest amount of samples in the training set as possible. 

This means that if we would have a dataset of lets say 1000 images and we repeat one of the images, let's say an image of a car, 1000 times to create a 2000 sample size biased dataset, the autoencoder would learn features such that it could very precisely reconstruct the repeated car image at the cost of reconstructing the other images.

I wonder if there is some way we can mitigate this and force the autoencoder to come up with more general features without having to manually screen the samples in the training set?",13,2
583,2016-5-19,2016,5,19,18,4k1nei,How to Quantize Neural Networks with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/4k1nei/how_to_quantize_neural_networks_with_tensorflow/,[deleted],1463649725,[deleted],0,1
584,2016-5-19,2016,5,19,20,4k208j,ML for image completion with spare information,https://www.reddit.com/r/MachineLearning/comments/4k208j/ml_for_image_completion_with_spare_information/,[deleted],1463657439,[removed],0,1
585,2016-5-19,2016,5,19,21,4k23tc,Will Analog Computing and Neural Nets Power Innovation after Moore's Law? (2013),https://www.reddit.com/r/MachineLearning/comments/4k23tc/will_analog_computing_and_neural_nets_power/,dharma-1,1463659316,,0,0
586,2016-5-19,2016,5,19,21,4k25rw,kevin murphy ebook,https://www.reddit.com/r/MachineLearning/comments/4k25rw/kevin_murphy_ebook/,roar363,1463660210,[removed],5,0
587,2016-5-19,2016,5,19,21,4k26p9,Do we finally have real competition in the deep learning hardware space?,https://www.reddit.com/r/MachineLearning/comments/4k26p9/do_we_finally_have_real_competition_in_the_deep/,toisanji,1463660603,,1,0
588,2016-5-19,2016,5,19,21,4k26z5,Variable Sequence Lengths in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/4k26z5/variable_sequence_lengths_in_tensorflow/,danijar,1463660717,,9,4
589,2016-5-19,2016,5,19,21,4k2bqr,"Alternative derivation of the backprop algorithm, by Ben Recht",https://www.reddit.com/r/MachineLearning/comments/4k2bqr/alternative_derivation_of_the_backprop_algorithm/,urish,1463662702,,20,45
590,2016-5-19,2016,5,19,22,4k2fhh,Unsupervised Machine Learning Could Help Us Solve the Unsolvable,https://www.reddit.com/r/MachineLearning/comments/4k2fhh/unsupervised_machine_learning_could_help_us_solve/,herronlentz,1463664220,,3,0
591,2016-5-19,2016,5,19,22,4k2jlr,Isn't there already too many graduate students majoring in machine learning?,https://www.reddit.com/r/MachineLearning/comments/4k2jlr/isnt_there_already_too_many_graduate_students/,rafaminkim,1463665868,[removed],0,1
592,2016-5-19,2016,5,19,22,4k2kn9,Six lectures on technology and AI one has to listen from EconTalk and London School of Economics,https://www.reddit.com/r/MachineLearning/comments/4k2kn9/six_lectures_on_technology_and_ai_one_has_to/,Friends_of_AI,1463666283,[removed],0,1
593,2016-5-19,2016,5,19,23,4k2r39,General Purpose Machine Learning In Rust,https://www.reddit.com/r/MachineLearning/comments/4k2r39/general_purpose_machine_learning_in_rust/,SleepyCoder123,1463668707,,1,0
594,2016-5-20,2016,5,20,0,4k2ybn,Machine Learning Sorting Question,https://www.reddit.com/r/MachineLearning/comments/4k2ybn/machine_learning_sorting_question/,digital_bath,1463671190,"Beginner question--I'm familiar with Python / couple other programming languages but have never yet implemented an actual neural network though (think) I understand the basic premises of how they work.

I am currently working on a project where I would ideally create an algorithm that would categorize messages based on a response within a specific context (i.e. in response to ""Are you a golfer?"" the person responding ""I am a golfer"" ""I like golf"" ""Yes I am"" is sorted to category A while ""I hate golf"" ""No I'm not"" etc would be sorted into category B). Am I correct in thinking that a machine learning type project would be a reasonable way to complete this (i.e. train a network by categorizing 1,000s of reponses for it so that it can identify the underlying patterns and sort on its own)? Is there a much more efficient way to accomplish this type of NLP analysis?

Can anyone point me to resources that would be relevant to this type of task (and ideally usuable for a beginner)?

Thanks in advance for any and all help.",4,0
595,2016-5-20,2016,5,20,0,4k2z4y,Neural Network FAQs,https://www.reddit.com/r/MachineLearning/comments/4k2z4y/neural_network_faqs/,[deleted],1463671466,[deleted],1,0
596,2016-5-20,2016,5,20,0,4k33v1,Deep Q-network in TensorFlow and Gym,https://www.reddit.com/r/MachineLearning/comments/4k33v1/deep_qnetwork_in_tensorflow_and_gym/,carpedm20,1463673051,,1,78
597,2016-5-20,2016,5,20,1,4k37au,How is the Google Fellowship in Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/4k37au/how_is_the_google_fellowship_in_deep_learning/,[deleted],1463674160,[deleted],2,0
598,2016-5-20,2016,5,20,1,4k37zu,Getting actionable insights from reviews using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/4k37zu/getting_actionable_insights_from_reviews_using/,wildcodegowrong,1463674379,,0,0
599,2016-5-20,2016,5,20,1,4k3cqc,Are there any good papers about using HTML or CSS as features for a model?,https://www.reddit.com/r/MachineLearning/comments/4k3cqc/are_there_any_good_papers_about_using_html_or_css/,blueeyes44,1463675896,"We're seeking to classify websites not by their content, but by their structure, so less text extraction and more HTML parsing...",3,0
600,2016-5-20,2016,5,20,2,4k3i2n,Keras stateful LSTM - what am I missing?,https://www.reddit.com/r/MachineLearning/comments/4k3i2n/keras_stateful_lstm_what_am_i_missing/,EdmondRR,1463677654,"Let me quote directly the keras [FAQ](http://keras.io/getting-started/faq/#how-can-i-use-stateful-rnns) about stateful recurrent layers:

&gt;When using stateful RNNs, it is therefore assumed that:
&gt;
&gt;   - all batches have the same number of samples
&gt;   - If X1 and X2 are successive batches of samples, then X2[i] is the follow-up sequence to X1[i], for every i.

And also from the main [docs](http://keras.io/layers/recurrent/):
&gt;You can set RNN layers to be 'stateful', which means that the states computed for the samples in one batch will be reused as initial states for the samples in the next batch. This assumes a one-to-one mapping between samples in different successive batches.

Now, if I'm reading this right, given a list of 10 sequences [0,1,2,3,4,5,6,7,8,9] split into batches [0,1,2,3,4] and [5,6,7,8,9], does it mean that the model expects the couples of sequences (0,5), (1,6), (2,7), etc., to be one after the other?
It seems quite an unnatural thing to do, I'd expect the model to treat sequence 5 as the follow-up of sequence 4.
Am I missing something important here?
",6,5
601,2016-5-20,2016,5,20,2,4k3i4n,Convolution neural networks - Understanding layer input sizes/shapes,https://www.reddit.com/r/MachineLearning/comments/4k3i4n/convolution_neural_networks_understanding_layer/,klop2031,1463677674,"I am unsure about how input shape of each hidden convolutional layers should be.

Here is an example:

My input is an image 8 x 8 and my first convolution layer has a window size of 3x3 should the next layers input size look like 6x6? assuming no zero padding. Then if I do maxpooling of size 2x2 right after the first convolution  the next layer should look like 3 x 3? 

I was told that at the end of the network I should have a 1x1 pixel (hyper pixel) but I am unsure why we should have this.",3,0
602,2016-5-20,2016,5,20,2,4k3li6,"LargeVis (like t-SNE for big datasets) for R, implemented in C++",https://www.reddit.com/r/MachineLearning/comments/4k3li6/largevis_like_tsne_for_big_datasets_for_r/,djc1000,1463678792,,11,40
603,2016-5-20,2016,5,20,2,4k3loo,I suspect I have food allergies that cause GI distress. I have some data. How can I use Machine Learning to help figure it out?,https://www.reddit.com/r/MachineLearning/comments/4k3loo/i_suspect_i_have_food_allergies_that_cause_gi/,TummyML,1463678852,[removed],0,1
604,2016-5-20,2016,5,20,2,4k3qo8,Google Takes Unconventional Route with Homegrown Machine Learning Chip,https://www.reddit.com/r/MachineLearning/comments/4k3qo8/google_takes_unconventional_route_with_homegrown/,[deleted],1463680427,[deleted],28,47
605,2016-5-20,2016,5,20,2,4k3r4v,Best format for medical imaging dataset,https://www.reddit.com/r/MachineLearning/comments/4k3r4v/best_format_for_medical_imaging_dataset/,rogertrullo,1463680568,"Hi,
I am trying to use machine learning techniques for medical image data.
The data comes in a special format (Dicom or Nifti). I want to use 3D patches as my training samples. I would like to know what would be the best option if I want  for example read every patch in the data set in advance and store all of them in such a way  that I can use easily with TensorFlow for example?
Thanks!",3,0
606,2016-5-20,2016,5,20,3,4k427k,Generalizing from a few examples lies at the core of intelligence,https://www.reddit.com/r/MachineLearning/comments/4k427k/generalizing_from_a_few_examples_lies_at_the_core/,loretoparisi,1463684152,,0,1
607,2016-5-20,2016,5,20,3,4k42ad,Impressions about the webinar: Enabling Exploratory Analysis of Large Data with Apache Spark and R By Databricks company,https://www.reddit.com/r/MachineLearning/comments/4k42ad/impressions_about_the_webinar_enabling/,datasciguy-aaay,1463684180,"I watched the video Enabling Exploratory Analysis of Large Data with Apache Spark and R
By Databricks company (who writes most of Spark) today, and I overall feel Spark is one of the best products for distributed programming today for data science applications. Dont get too upset when I tell you what I did not like, because its a great product overall. I even hope to help it get even better with genuine and constructive ideas.

Two glaring problems appeared:
The Spark devs made users work in a different but similar to R markup and Rstudio and Knittr web based tool of their own making. In particular there was no way to export the document to Rmd or to just work with spark programming in RStudio.  The reason a data scientist works in R and Rmd and Knittr is to publish a research paper.  There is no way around it, I need to publish research papers. It looks like there is no recognition by the R spark team of what a data scientist needs to do, because there is no way to finish the document in RStudio which was started in the proprietary R Spark GUI.  The Spark R gui either needs to successfully imitate all the features for reproducible research reports which RStudio is providing to data scientists, or else the Spark R gui needs to be made to play nicely with the Rstudio/Knittr/Rmd system and enable two way workflow back and forth as we iterate over our reseach paper development.  Its an iterative workflow.  SparkR cant behave as its own tool on an island if it wants adoption by data scientists.  So let me underline what I want.  I need an add-in to enable Spark R stuff hosted in my main work environemnt which is RStudio, or, otherwise I need a correctly generated Rmd document file, which can be output as well as be input, from and to Spark R GUI to act as the go-between artifact as I repeatedly bounce between my two tools during project work iteration. I cannot just give up RStudio because it has a lot of capabilities that SparkR isnt giving me yet. SparkR is the new and subordinate player in this field and needs to behave more properly and as a good citizen according to accepted data science workflows.  SparkR GUI is not an island able to replace RStudio at this point, so please make some recognition of the reality here if you want adoption of RSpark by the data science community.

Secondly, the application programming interface of SparkR unfortunately requires the programmer to distinguish between R dataframe and Spark dataframe which are two different things, but despite this the API is also trying to hide the differences as if they can be abstracted away, which they cannot.  The API artifacts should be improved to clearly speak in terms of R dataframe and SparkDataFrame which are really two different things.  

The API is additionally confusing relational database concepts into the application code when it is not appropriately matching what is really going on.  First example of what I am talking about:  The createTempTable is actually producing a SparkDataFrame on the cluster rather than creating a temp table in a SQL RDBMS.  If programmers are supposed to keep it straight in their minds, then naming the API function more appropriately and more accurately would really make things simpler to remember.  Failed abstractions are really, really not helpful. The API needs to live in the truth of what it does. I am being told that the programmer needs to remember that there is both a genuine R dataframe, and there is also a SparkDataFrame (named unfortunately just DataFrame but in a different namespace it seems). In the demo the error message just said DataFrame and somehow the developer was supposed to figure out on his own that a Spark DataFrame was being referenced and not an R DataFrame.  If something is different then you should give it a different name in the software, so SparkDataFrame would be just fine, whereas DataFrame is not helpful to communicate bugs to me about Spark software since it is ambiguous with the R data.frame when you are workign in the R language.

The SparkR API design is also forcing the unhelpful and unnecessary inclusion of RDBMS language metaphors in too many places in the R application code whenever we have to program with distributed dataframes.  As a data scientist I am however, PERFECTLY happy programming with awareness of distributed dataframes and I feel no need nor desire whatsoever to needlessly or confusingly pretend to code with them as if these distributed SparkRDataFRame entities are either R dataframes or SQL tables.  Look, R programmers are not SQL programmers -- we are however dataframe lovers. Using the RDBMS jargon all around in the Spark R API is just wrongheaded. Nobody wants to work in  R code that continually pretends as if its an RDBMS.   RDBMS is a technology of fading usefulness and scale in the big data age.  R users are not some database people.  Rs main data structure is the dataframe, and thats what we want to program with.  Its espeically silly to program R with SQL syntax or keywords createTempTable when there is not even a SQL database in my whole pipeline.  Thats just plain confusing. If I want to create an R dataframe, I would like to use sytax which makes it clear, and if I want to create a distributed SparkRDataFrame then I would prefer to have synax which says exactly that.   Its like the Spark team never worked with an actual modern data scientist.  We are really not database people, believe it or not, so please dont make us write code that forces us to needlessly pretend to appear to be like some SQL developer from 1979. I would however very much love my code to work with the distributed SparkDataFrame and its not necessary and not even helpful to pretend SparkDataFrame is something which it is not.  Lets change the SparkR api and call a SparkDataFrame a SparkDataFrame everywhere we need to use it, such as to cause a collect() or other operation between R, SparkR, and some persistent data store like HDFS or filesystem or HBase or whatever. If I have to move data from a SparkDataFrame to some other part of my distributed system, I really want to use the correct terminology to keep it correct in my head, for simplicity. I laready have to keep it straight in my head, and the RDBMS mnemonic is just useless extra baggage to have to remember along with it.  The SQL metaphor has gone too far, because its not helping and you have to remember the different parts of the system anyway -- there is no abstraction possible so just give that up. We can handle the truth without failed abstractions to SQL databases that are just not even there in half the applications that will use SparkR.",0,0
608,2016-5-20,2016,5,20,4,4k44wo,[Question] Advice for image reconstitution [Imgur](http://i.imgur.com/NXxjtBu.png),https://www.reddit.com/r/MachineLearning/comments/4k44wo/question_advice_for_image_reconstitution/,Asterios_synap,1463685087,"Dear reddit users,
I am looking for an esay to use lib for image reconstitution. My problem is the following : Let say you have sevral hundred pictures of a specific object like a tea pot or a garden with a constant definition.
You get one picture with less than 10 percent of the pixel with a color and other pixels colors are unknown. From the data set I would like to simulate the color of the missing pixel.

 [Imgur](http://i.imgur.com/NXxjtBu.png)

I do not expect to get a realistic shape but somehting that give the good texture and a probable color for the unknown pixel knowing the other pixel.

Also I would like to add some soft information such as the color is more blue than yellow in a specific part or there is a gradient from white to black is another zone.
I did some moocs on machine learning and I am quite okay with r &amp; python. If someone can advise me some libs and existing algorithm, your help will be very appreciated.
Thank for your help redditors.
A.S",7,0
609,2016-5-20,2016,5,20,4,4k4bnz,Improvements of Random Search for Hyperparameter Optimization,https://www.reddit.com/r/MachineLearning/comments/4k4bnz/improvements_of_random_search_for_hyperparameter/,Bohemian90,1463687351,"Hello

Random search is one possibility for hyperparameter optimization in machine learning. I have applied random search to search for the best hyperparameters of a SVM classifier with a RBF kernel. Additional to the continuous Cost and gamma parameter, I have one discrete parameter and also an equality constraint over some parameters.

Now, I would like to develop random search further, e.g. through adaptive random search. That means for example adaptation of the search direction or of the search range.

Does somebody have an idea how this can be done or could reference to some existing work on this? Other ideas for improving random search are also welcome.",7,0
610,2016-5-20,2016,5,20,4,4k4bv0,Natural Language Processing with incomplete sentences and slightly disorganized text,https://www.reddit.com/r/MachineLearning/comments/4k4bv0/natural_language_processing_with_incomplete/,sudocaptain,1463687414,I'm trying to interpret a ton of emails but they are almost always coming in in incomplete sentences with little punctuation. I have about 5 things I'm looking for in every email. Does anyone have any advice for the best way to approach this?,6,0
611,2016-5-20,2016,5,20,5,4k4j5z,What can I do right now to get into NIPS?,https://www.reddit.com/r/MachineLearning/comments/4k4j5z/what_can_i_do_right_now_to_get_into_nips/,treebranchleaf,1463689838,"There's a conference called NIPS and I just saw their website https://nips.cc/ and it says the deadline is in less than 20 hours.  I realize that it's cutting it a bit close, but the website says it only has to be 8 pages which doesn't seem like that much.   I want to submit a paper, but I can't think of a topic.  Can someone help me?  What can I do that will get my paper into NIPS?  I saw that not all papers get accepted so I only want good ideas.  I don't know much about Machine Learning, but I just read the [wiki page](https://www.google.nl/?ion=1&amp;espv=2#q=mashine+learning+wiki) on it and it seems really interesting.

Edit: Serious replies only PLEASE",38,43
612,2016-5-20,2016,5,20,5,4k4jfy,"Peter Norvig Quora session on CS, AI, DeepLearning",https://www.reddit.com/r/MachineLearning/comments/4k4jfy/peter_norvig_quora_session_on_cs_ai_deeplearning/,petrux,1463689932,,3,55
613,2016-5-20,2016,5,20,6,4k4s5g,New crowd-sourced Machine Learning class from Stanford's Crowd Course Initiative,https://www.reddit.com/r/MachineLearning/comments/4k4s5g/new_crowdsourced_machine_learning_class_from/,whoeverwhatever,1463692716,,5,27
614,2016-5-20,2016,5,20,6,4k4saz,Train a model to generate X thing,https://www.reddit.com/r/MachineLearning/comments/4k4saz/train_a_model_to_generate_x_thing/,pokedata,1463692760,"Hi Reddit,

Recently I have seen many posts/articles about models being trained with the purpose of generate something, such as music, text, and so on.

My issue is that I do not have knowledge about the basic architecture of a system like that, or how it works. So I was wondering if someone could point me to the right direction so I can start learning about this; an article or a simple explanation here would be cool.

To give a clear example using the classic iris dataset, I would like to train a model capable of generating iris flowers. For example, let's say that after being trained, I test my model by sending as an input ""setosa"", and an ideal output would be something such as:
[sepal_length: 5.1, sepal_width: 3.6, petal_length: 1.3, petal_width: 0.2]

Thanks in advance. Feel free to ask me anything if I wasn't clear.

These are examples of projects that use machine learning to generate something:
Music generation: https://github.com/MattVitelli/GRUV
Text generation: https://github.com/karpathy/char-rnn
",3,0
615,2016-5-20,2016,5,20,9,4k5kiv,The Advance of Machine Intelligence in Medicine,https://www.reddit.com/r/MachineLearning/comments/4k5kiv/the_advance_of_machine_intelligence_in_medicine/,Aicial,1463703122,,1,0
616,2016-5-20,2016,5,20,9,4k5lz4,Build your own Deep Learning Box for less than $1.5k,https://www.reddit.com/r/MachineLearning/comments/4k5lz4/build_your_own_deep_learning_box_for_less_than_15k/,inxurgence,1463703717,,29,6
617,2016-5-20,2016,5,20,9,4k5rbj,"Hello guys, I have a problem here using two datasets",https://www.reddit.com/r/MachineLearning/comments/4k5rbj/hello_guys_i_have_a_problem_here_using_two/,redhotchiliguy,1463705962,"I got [this error](http://imgur.com/ZENWvNC) on Weka because the number of attributes on train dataset and on test set are different. They are different because in text classification is being used StringtoWordVector filter and it transforms tokens into attributes. How to solve this problem in weka?

Thanks in advance! ",0,0
618,2016-5-20,2016,5,20,10,4k5w4h,Great Resource - Convex Optimization (Stephen Boyd) PDF,https://www.reddit.com/r/MachineLearning/comments/4k5w4h/great_resource_convex_optimization_stephen_boyd/,Powlerbare,1463708014,,1,0
619,2016-5-20,2016,5,20,11,4k63sm,[Question] Which is better Theano or TensorFlow in this case?,https://www.reddit.com/r/MachineLearning/comments/4k63sm/question_which_is_better_theano_or_tensorflow_in/,y05f,1463711066,"I work on Evolutionary Artificial Neural Networks. I try to test new Models of EANN and I used to code them in C++ but it takes huge time to complete the code (too many lines).

I want to switch to Python since everyone is using it and it contains a lot of support in terms of ML libraries and tools. I find Theano and TensorFlow interesting and popular but i don't know which one suits my needs.

My needs are as follows: 

* Pre-defined **functions and tools** to construct any kind of ANNs
* **Freedom** to alter or modify learning algorithms 
*  **Speed** is important because EA will evolve many ANNs at the same time. Even if it will never get close to C++ speed but it suits me if I will not waste time on coding.

If I try to resume this in one question it will be : **Which ML library in Python gives you the maximum control and speed?**

[Edit1] By control I mean flexibility to modify and alter learning algorithms and NNs Architectures",6,0
620,2016-5-20,2016,5,20,12,4k6fuo,Can you read LMDB files into TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/4k6fuo/can_you_read_lmdb_files_into_tensorflow/,[deleted],1463716164,[deleted],0,0
621,2016-5-20,2016,5,20,13,4k6jzt,PyEvolve - Awesome Genetic Algorithm Tutorial,https://www.reddit.com/r/MachineLearning/comments/4k6jzt/pyevolve_awesome_genetic_algorithm_tutorial/,Jxieeducation,1463718082,,1,4
622,2016-5-20,2016,5,20,15,4k6w3l,Need people to work with.,https://www.reddit.com/r/MachineLearning/comments/4k6w3l/need_people_to_work_with/,pfrcks,1463724248,"Hi,
Didi Chuxing, the Chinese ride sharing app, has recently started the a Machine Learning challenge worth 100K.
It is a team based event, and I need some people with whom I can work with.
Anybody up for this?
[Link](http://research.xiaojukeji.com/competition/main.action?competitionId=DiTech2016)",4,0
623,2016-5-20,2016,5,20,16,4k7306,Kaggle Kobe Question,https://www.reddit.com/r/MachineLearning/comments/4k7306/kaggle_kobe_question/,KrisSingh,1463728102,"http://savvastjortjoglou.com/nba-shot-sharts.html
I found this great script and i thought i would share it with you all.just one little question how did the author arbitrarily choose that 10 units in the co-ordinate system is equal to 1 ft.I thought for 1 unit in our coordinate system should be equal 94/11 ft . as 94 is length of the basketball court and in our the fig length is 11 units so 1 unit is ....",0,0
624,2016-5-20,2016,5,20,16,4k7540,Has anyone here used GTX 1080 with Theano or TF yet?,https://www.reddit.com/r/MachineLearning/comments/4k7540/has_anyone_here_used_gtx_1080_with_theano_or_tf/,ithinkiwaspsycho,1463729330,[removed],2,2
625,2016-5-20,2016,5,20,17,4k787v,One-shot Learning with Memory-Augmented Neural Networks,https://www.reddit.com/r/MachineLearning/comments/4k787v/oneshot_learning_with_memoryaugmented_neural/,abstractcontrol,1463731266,,13,43
626,2016-5-20,2016,5,20,20,4k7rol,"This Week in Machine Learning, 20 May 2016",https://www.reddit.com/r/MachineLearning/comments/4k7rol/this_week_in_machine_learning_20_may_2016/,DavidAJoyner,1463743188,,6,3
627,2016-5-20,2016,5,20,20,4k7tdd,Matrix Calculus Explained,https://www.reddit.com/r/MachineLearning/comments/4k7tdd/matrix_calculus_explained/,Kiuhnm,1463744146,"[This](https://github.com/mtomassoli/papers/blob/master/matrixcalculus.pdf) is a little paper about *Matrix Calculus* I wrote a few years ago.

There are many tutorials about this subject, but many are just collections of formulas. If you also want the theory behind it and a cohesive treatment, then you should find my paper useful.

**But be warned**: it's not for the complete beginner! While I wouldn't call it *advanced*, it does require a certain *mathematical maturity*.

---

Edit: If you're not particularly interested in the theory, you can just look at the rules listed in section 4 and read section 6.",29,167
628,2016-5-20,2016,5,20,20,4k7tel,Possible to convert compact binary descriptors -&gt; real-valued vectors?,https://www.reddit.com/r/MachineLearning/comments/4k7tel/possible_to_convert_compact_binary_descriptors/,[deleted],1463744164,[deleted],1,2
629,2016-5-20,2016,5,20,20,4k7vco,[1604.02910v3] Deep Gate Recurrent Neural Network,https://www.reddit.com/r/MachineLearning/comments/4k7vco/160402910v3_deep_gate_recurrent_neural_network/,InaneMembrane,1463745214,,4,9
630,2016-5-20,2016,5,20,21,4k7xr5,Alphabet has developed a custom chip for running machine learning algorithms,https://www.reddit.com/r/MachineLearning/comments/4k7xr5/alphabet_has_developed_a_custom_chip_for_running/,whaleyharp,1463746360,,0,0
631,2016-5-20,2016,5,20,21,4k82b5,Testing non-monotonicity,https://www.reddit.com/r/MachineLearning/comments/4k82b5/testing_nonmonotonicity/,adwarakanath,1463748290,"Hi guys,

So we have this new data from large-scale neuronal recordings from monkeys where we show that in comparison to the structure of pairwise correlations (over distance) in early sensory areas where the correlations fall linearly as a function of distance, the correlation structure in the prefrontal cortex is not monotonically decreasing. In fact it decreases first and then increases and then decreases again. We found that this is mainly due to lateral connectivity between pyramidal neurons, and we've written up the paper and are about to submit it. One of our colleagues suggested that we explicitly show that the function is indeed non-monotonic. 

I was wondering if one could learn the degree of the polynomial that fits the function? I know it might be trivial because an (n+1)th degree polynomial contains all the n-degree polynomials anyway so we'd be over-fitting. 

But is there any other way one could test for non-monotonicity explicitly?

I'd be very grateful for any pointers.

Cheers",29,1
632,2016-5-20,2016,5,20,21,4k841b,Why don't we see more often oversampling techniques used in publications that deal with Imbalance Datasets?,https://www.reddit.com/r/MachineLearning/comments/4k841b/why_dont_we_see_more_often_oversampling/,xristos_forokolomvos,1463749086,"Are they not considered viable? 

Also, is it considered ""cheating"" to include artificially generated data in the test set? Are they only used in training?",2,0
633,2016-5-20,2016,5,20,22,4k8b59,"CNNs, overtrain the filters first?",https://www.reddit.com/r/MachineLearning/comments/4k8b59/cnns_overtrain_the_filters_first/,warppipe,1463752058,"I am running into some issues with validation accuracy rising soon after training beings. With aggressive dropout rates, the validation accuracy does drop, but asymptotes quickly (as does the training error). Inspecting the weights in the convolution filter, it doesn't seem to move all that far from the random initialization.

On the other hand, the weights in the conv layer if I let it overfit come out very structured, and are even interpretable in the domain I am working on. 

My thought was I could forget about rising validation error, train my conv filters, then reset the fully connected layer weights, keeping the conv layer weights static (use them as inputs). That way I get some useful filters that I can then use as a starting point to represent my input data.

Does this make sense? What other approaches might make sense? Thanks for any advice!",1,0
634,2016-5-20,2016,5,20,23,4k8klo,Deep Learning on the GPU in Windows (TDR settings etc.),https://www.reddit.com/r/MachineLearning/comments/4k8klo/deep_learning_on_the_gpu_in_windows_tdr_settings/,smltag,1463755709,[removed],0,1
635,2016-5-21,2016,5,21,0,4k8o3x,"Xavier Conort, former #1 Kaggler, shares his kaggle experience",https://www.reddit.com/r/MachineLearning/comments/4k8o3x/xavier_conort_former_1_kaggler_shares_his_kaggle/,DataScienceGame,1463756984,,7,2
636,2016-5-21,2016,5,21,0,4k8rfn,HTM School Episode 4: SDR Sets &amp; Unions,https://www.reddit.com/r/MachineLearning/comments/4k8rfn/htm_school_episode_4_sdr_sets_unions/,numenta,1463758218,,0,0
637,2016-5-21,2016,5,21,0,4k8sk9,Identify nerve structures in ultrasound images of the neck. New Kaggle competition,https://www.reddit.com/r/MachineLearning/comments/4k8sk9/identify_nerve_structures_in_ultrasound_images_of/,cavedave,1463758594,,8,9
638,2016-5-21,2016,5,21,1,4k937r,"When using SVD for dimensionality reduction, how do I reduce a new input vector using an existing SVD?",https://www.reddit.com/r/MachineLearning/comments/4k937r/when_using_svd_for_dimensionality_reduction_how/,sanity,1463762220,"I'm using SVD for a dimensionality reduction task for the purpose of anomaly detection.  Specifically I'm using the [Apache Commons implementation](http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math3/linear/SingularValueDecomposition.html).

Per the documentation:

&gt; The Singular Value Decomposition of matrix A is a set of three matrices: U,  and V such that A = U    VT. Let A be a m  n matrix, then U is a m  p orthogonal matrix,  is a p  p diagonal matrix with positive or null elements, V is a p  n orthogonal matrix (hence VT is also orthogonal) where p=min(m,n).

So I encode my input data such that each set of training attributes is encoded to a row in the matrix A.

I then do the SVD calculation, and now each row in U is a transformed vector of the equivalent row in A, I can then reduce the number of dimensions to x by taking the first x values in the row from U.

My question is this: Given a new training example that was not part of A, how can I use  and VT to find out what the corresponding transformed vector (ie. what would have been in the matrix U if it had been a row in A previously)?

Obviously I don't want to have to regenerate the SVD with a new A to do this.",4,6
639,2016-5-21,2016,5,21,1,4k93p7,"[LIVE NOW] Streaming from MLconf Seattle: Talks from Facebook, Uber Google, Dato and more!",https://www.reddit.com/r/MachineLearning/comments/4k93p7/live_now_streaming_from_mlconf_seattle_talks_from/,shonburton,1463762393,,1,0
640,2016-5-21,2016,5,21,1,4k94v4,Computational complexity of decision tree algorithms?,https://www.reddit.com/r/MachineLearning/comments/4k94v4/computational_complexity_of_decision_tree/,Baigoo365,1463762786,I want to analyse the complexity for a basic decision tree learning algorithm. All attributes are boolean and there are no missing values. Any references or resources to help me along the way?,1,0
641,2016-5-21,2016,5,21,1,4k96ye,How to Evaluate GPUs for ML,https://www.reddit.com/r/MachineLearning/comments/4k96ye/how_to_evaluate_gpus_for_ml/,RandomlyHitsButtons,1463763502,"I'm trying to put together a parts list for a computer for training deep convolutional neural nets and recurrent neural nets. I have zero familiarity with GPUs and could use some help with the evaluation criteria (i.e. figuring out what will fit my needs now and over the next year or two). What are the pros and cons of the following:

A GTX Titan
Two GTX 980 Tis in an SLI configuration
Wait for the GTX 1080 Ti or Pascal version of the Titan

There's no rush to build the machine right away as I won't have a lot of time to focus on using it until the beginning of September.",6,3
642,2016-5-21,2016,5,21,2,4k9b2g,Possible to detect cheating in Minecraft?,https://www.reddit.com/r/MachineLearning/comments/4k9b2g/possible_to_detect_cheating_in_minecraft/,ryan_the_leach,1463764852,"**How do I start experimenting with machine learning?**

(noting that Minecraft is written in Java, and runs on the JVM, so any solutions that can interface directly with that would help)

I had a random thought, I wonder if it would be possible to train a system to detect cheating as it happens in Minecraft, specifically ""xray"".

Xray is where the players use client side hacks, to gain an unfair advantage, they can see where Ores are ahead of time.

**Background**

Minecraft has a gridded world made of many blocks, one goal in the game is to gather Ores, mining. This is a tedious task that majority of players rarely enjoy.

The ores are scattered throughout the world, and can either be visible from caves / tunnels / surface or be hidden and have no air blocks surrounding them.

A popular method of cheating is to use ""Xray"" or ""Esp"" which gives a heads up display of where the ores are in the world.

This modifies player behaviour, as players cheating will generally dig diagonally rather then branch mine,get lucky more often by accidentally digging in the correct direction, dig straight down, as they can see where danger is below them (smart players either rarely do this, or do so in a manner that is safe) ""look"" through walls, instead of down tunnels / into space, not use torches to light tunnels, as they can modify the brightness on their client.

Moderators / admins of servers are aware of this, and will occasionally patrol watching players mine invisibly looking for these behaviours, smarter players will only xray when moderators or admins appear offline.

One common already existing method is to check statistically whether a player has a high Ore to Stone ratio, but the problem with this is 1. players arn't always ""mining"" they often build or explore. 2. An alternate mining strategy, ""caving"" has people explore caves at depths instead of mining, this allows smart players to cover a lot of ground quickly as the blocks don't need to be excavated. this can falsely trigger statistical methods of detection due to the lack of stone being mined.


Gathering data seems to be the hardest step, but I believe you could train it against whether a player has been banned or not, and for which reason.",11,5
643,2016-5-21,2016,5,21,2,4k9br8,Gaussian precision matrix symmetric proof?,https://www.reddit.com/r/MachineLearning/comments/4k9br8/gaussian_precision_matrix_symmetric_proof/,KrisSingh,1463765068,"Is this is the correct way https://www.youtube.com/watch?v=ycemW2P27x4 to prove that the precision matrix is symmetric .He assumes a hypothesis and that A is symmetric and actually uses the hypothesis in the last step to conclude that the initial hypothesis is true
",4,0
644,2016-5-21,2016,5,21,2,4k9cv9,"Udacity and Didi are holding a route-optimization ML competition with $100,000 prize",https://www.reddit.com/r/MachineLearning/comments/4k9cv9/udacity_and_didi_are_holding_a_routeoptimization/,andb,1463765439,,13,23
645,2016-5-21,2016,5,21,4,4k9wky,Seeking Postdocs for Deep Learning Research (including Deep Reinforcement Learning),https://www.reddit.com/r/MachineLearning/comments/4k9wky/seeking_postdocs_for_deep_learning_research/,[deleted],1463772061,[deleted],0,1
646,2016-5-21,2016,5,21,4,4k9www,Seeking Postdocs for Deep Learning Research (including Deep Reinforcement Learning),https://www.reddit.com/r/MachineLearning/comments/4k9www/seeking_postdocs_for_deep_learning_research/,jclune,1463772175,"Please share this with anyone who might be interested. 

A fully funded, two-year postdoc is available in Jeff Clunes lab in the computer science department at the University of Wyoming. The research will be on areas of mutual interest in deep neural networks/deep learning, including deep reinforcement learning (in simulation and/or with physical robots). The position is available immediately, but I am flexible regarding delayed starting dates. Experience with deep learning is a huge plus, but is not required if the applicant has a background in relevant fields (e.g. math, programming, computer science, or statistics) and a desire to learn about deep neural networks. 

The Evolving Artificial Intelligence lab (http://EvolvingAI.org) focuses on robotics and creating artificial intelligence in neural networks, either via deep learning or evolutionary algorithms. The lab is actively engaged in research. Just in the last two years, we have received an NSF CAREER award, participated in a cover article in Nature on robotics, produced the 63rd most talked about scientific paper worldwide in 2015, and our deep learning papers were awarded oral presentations (1-6% acceptance rates) at NIPS, CVPR, ICLR, and an ICML workshop. In that same time, we also produced six papers at GECCO, including a best paper award, and a cover article for PLoS Computational Biology with a Reddit AMA about it that over 42,000 people joined to ask 1000+ questions. Additionally, our work has been covered by almost every major international news outlet. 

Please see http://EvolvingAI.org for more information, including :
		Short video summaries of our work and talks: http://www.evolvingai.org/videos
		Our publications: http://www.evolvingai.org/publications
		Press coverage: http://www.evolvingai.org/press
		Info on living in Wyoming and being a part of our lab: http://www.evolvingai.org/join

If you are interested, please follow the instructions at http://www.evolvingai.org/join

The University of Wyoming is located in Laramie, a college town in the heart of the Rocky Mountain West. Nestled between two mountain ranges, Laramie has more than 300 days of sunshine a year and is home to year-round outdoor activities including hiking, camping, rock climbing, downhill skiing, cross-country skiing, fishing and mountain biking. Laramie is also near many of Colorado's major cities and university communities (e.g. Fort Collins, Boulder, and Denver).  

The University of Wyoming is an Affirmative Action/Equal Opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, pregnancy, sexual orientation, age, national origin, disability, marital, veteran or any other legally protected status.

Best regards,
Jeff Clune

Assistant Professor,Computer Science
Director,Evolving Artificial Intelligence Lab
University of Wyoming
jeffclune@uwyo.edu
jeffclune.com
",8,7
647,2016-5-21,2016,5,21,4,4ka0im,"Experiment with Self Organizing Maps, what do you think?",https://www.reddit.com/r/MachineLearning/comments/4ka0im/experiment_with_self_organizing_maps_what_do_you/,Flowx08,1463773411,[removed],0,1
648,2016-5-21,2016,5,21,4,4ka2vk,Computerphile about convolutional neural networks,https://www.reddit.com/r/MachineLearning/comments/4ka2vk/computerphile_about_convolutional_neural_networks/,[deleted],1463774272,[deleted],0,0
649,2016-5-21,2016,5,21,5,4ka51p,"I recently interviewed a psychology/neuroscience researcher about, among other things, how he uses machine learning and computational modeling in his work. I'd be grateful if you'd listen and provide some feedback.",https://www.reddit.com/r/MachineLearning/comments/4ka51p/i_recently_interviewed_a_psychologyneuroscience/,johnborghi,1463775030,,1,6
650,2016-5-21,2016,5,21,6,4kajjx,dynamic variety of neural network outputs,https://www.reddit.com/r/MachineLearning/comments/4kajjx/dynamic_variety_of_neural_network_outputs/,NexYY,1463780116,"After studying some academic papers about neural network recognition, plus trying some of them out myself, I do understand how you can train a network to give you a certain output on a defined set of output neurons depending on the input.

However I struggle to understand, how I can dynamically add output neurons. I've seen neural network applications, which where recognizing objects from images, however they set of classes to be recognized could always be increased. From my understanding this should not be possible, as the size of output neurons is fixed.",2,0
651,2016-5-21,2016,5,21,7,4kar62,National Security Agency and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/4kar62/national_security_agency_and_machine_learning/,Aicial,1463782927,,3,0
652,2016-5-21,2016,5,21,11,4kbmhl,How to Put RNN Layers Into Nueral Network Model,https://www.reddit.com/r/MachineLearning/comments/4kbmhl/how_to_put_rnn_layers_into_nueral_network_model/,wb14123,1463796201,,0,0
653,2016-5-21,2016,5,21,13,4kc5hf,Simple Evolutionary Optimization Can Rival Stochastic Gradient Descent in Neural Networks,https://www.reddit.com/r/MachineLearning/comments/4kc5hf/simple_evolutionary_optimization_can_rival/,hardmaru,1463805774,,19,3
654,2016-5-21,2016,5,21,13,4kc68j,awesome-2vec,https://www.reddit.com/r/MachineLearning/comments/4kc68j/awesome2vec/,aleph__one,1463806208,,0,0
655,2016-5-21,2016,5,21,15,4kcf7y,How do you organize your experiments?,https://www.reddit.com/r/MachineLearning/comments/4kcf7y/how_do_you_organize_your_experiments/,hazard02,1463811451,"How do you organize your experiments and results when doing either data science work or more fundamental research?

Do you store your results in a database? A physical lab notebook? Do you put your input and output files in source control?

I'm trying to figure out what best practices in this area are, or any ""productivity hacks"" that someone might have.",17,16
656,2016-5-21,2016,5,21,15,4kcj3j,ML algorithm for customer renewal,https://www.reddit.com/r/MachineLearning/comments/4kcj3j/ml_algorithm_for_customer_renewal/,tickmoh,1463813904,[removed],0,1
657,2016-5-21,2016,5,21,16,4kcl1q,A.I.,https://www.reddit.com/r/MachineLearning/comments/4kcl1q/ai/,jarvisx909,1463815234,"Anyone want to build an a.i. with me? Just something simple and functional and maybe we can cash it out to a tech company. Or we can start a tech company and get a think tank going to bring in some new ideas towards the use of a.i. in fields. In all honesty I already started, I want to build a sim for basic understanding of life and why we're here. (I know, that will take forever.)",14,0
658,2016-5-21,2016,5,21,16,4kcl7w,How to Create a Malevolent Artificial Intelligence | MIT Technology Review,https://www.reddit.com/r/MachineLearning/comments/4kcl7w/how_to_create_a_malevolent_artificial/,fungussa,1463815358,,7,0
659,2016-5-21,2016,5,21,17,4kcrqp,Looking for a machine learning teacher/mentor,https://www.reddit.com/r/MachineLearning/comments/4kcrqp/looking_for_a_machine_learning_teachermentor/,mrborgen86,1463819910,"Hi all!

I'm a front end developer and machine learning hobbyist who's gradually transitioning to doing ml at work as well.

I've been playing around with ml (various courses and personal projects) for about a year, and I'm currently going through the CS224 Deep Learning for NLP course at Stanford (online):

http://cs224d.stanford.edu/syllabus.html

I'm looking for a ml teacher or mentor, who can me with problems and concepts when I get stuck. I'm thinking on an hour-to-hour basis, over video chat. I'm not sure how much this would cost, but we'd have to find an hourly rate we both are pleased with.

I'm currently working my way through these assignments: http://cs224d.stanford.edu/assignment1/assignment1.pdf

While getting through most of it, I could really need help from someone with a deeper understanding of the math and the concepts in general from time to time.

I've written a little bit about my learning path previously. This might help you understand which level I'm at: https://medium.com/learning-new-stuff/how-to-learn-neural-networks-758b78f2736e#.n58am6ugz

If you're interested in this, please leave a message or send me a PM.",4,0
660,2016-5-21,2016,5,21,18,4kcvue,Traditional AI vs Modern AI,https://www.reddit.com/r/MachineLearning/comments/4kcvue/traditional_ai_vs_modern_ai/,perceptron01,1463822731,"Is there any room for traditional AI these days? By that I mean logic-based learning, formal reasoning, knowledge representation, Prolog-y stuff. I'm asking because my master's degree has a few courses on this, and I was wondering whether they are still relevant and useful to take.

*Didn't post in the questions thread cause I believe this is more a discussion-like question, rather than one with a straight answer.*",18,0
661,2016-5-21,2016,5,21,18,4kcw2q,Implementing the Skipgram Language Model. Can I sum the context words and train directly on that?,https://www.reddit.com/r/MachineLearning/comments/4kcw2q/implementing_the_skipgram_language_model_can_i/,danijar,1463822887,,1,0
662,2016-5-21,2016,5,21,19,4kd1qp,Good Code to learn from,https://www.reddit.com/r/MachineLearning/comments/4kd1qp/good_code_to_learn_from/,MeAlonePlz,1463826728,"Hey I just tried to submit my first Nips paper and towards the end in turned into a complete disaster. One reason was my horrible code that made it very inefficient when I tried to change simple things like the error measurement. 

So what I'm looking for is exeptionally well written code for a machine learning project (preferably theano/lasagne) that I can learn from how to structure my classes etc. 
",23,50
663,2016-5-21,2016,5,21,20,4kd7ik,"Best ML method for text ""phonetic transliteration"" from one language to another, similar to google typing tools.",https://www.reddit.com/r/MachineLearning/comments/4kd7ik/best_ml_method_for_text_phonetic_transliteration/,iamjbn,1463830453,[removed],0,1
664,2016-5-21,2016,5,21,21,4kde7p,Neural Gas Clock,https://www.reddit.com/r/MachineLearning/comments/4kde7p/neural_gas_clock/,[deleted],1463834277,[deleted],1,1
665,2016-5-21,2016,5,21,22,4kdh4m,New Chips by Google for Tensorflow will Help Advance the Field of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/4kdh4m/new_chips_by_google_for_tensorflow_will_help/,Toyjust,1463835796,,0,0
666,2016-5-22,2016,5,22,0,4kdzfw,A statistical interpretation of logistic regression,https://www.reddit.com/r/MachineLearning/comments/4kdzfw/a_statistical_interpretation_of_logistic/,sup6978,1463844013,,5,0
667,2016-5-22,2016,5,22,0,4kdzvm,Has anyone tried to mine all the types of analogies possible using word embeddings (word2vec)?,https://www.reddit.com/r/MachineLearning/comments/4kdzvm/has_anyone_tried_to_mine_all_the_types_of/,visarga,1463844204,"We know of a few types of word analogies, like ""France + capital = Paris"" and ""US + currency = dollar"", but has anyone tried to search for all the possible analogies that can be deducted by word2vec? 

They would have to find modifiers that have multiple matches, like ""word1 + modifier = word2"". An algorithm could be to cluster all the difference vectors (word1-word2, for all words) and select words that are close to the centers of dense clusters. Even if we don't find all modifiers, we can infer more by combining with ontologies/word net.

If we find all the types of analogy we could make a large test dataset to benchmark how capable are the various word embeddings of representing analogy. Also, by using the list of modifiers we could augment ontologies with new types of relationship between entities.
",1,0
668,2016-5-22,2016,5,22,1,4kea7u,New UC Berkeley Foundations of Data Science Online Textbook,https://www.reddit.com/r/MachineLearning/comments/4kea7u/new_uc_berkeley_foundations_of_data_science/,thecity2,1463848375,,9,86
669,2016-5-22,2016,5,22,1,4kedh3,"Need Devs for research on Machine Learning partnered with Ubuntu &amp; Microsoft! Giving away some really cool gadgets like iPhone, software licenses and conference tickets!",https://www.reddit.com/r/MachineLearning/comments/4kedh3/need_devs_for_research_on_machine_learning/,gkhdev,1463849615,,0,1
670,2016-5-22,2016,5,22,2,4kei88,CNN returning same output.,https://www.reddit.com/r/MachineLearning/comments/4kei88/cnn_returning_same_output/,theendofallend,1463851404,"Hello,
recently I try to train my own convolutional neural network to classify images. It works fine when I test it on small sized data (images of 10x10x1), but when I try to train it on real images(256x256x3), it seems to give me same answers regardless what is the input. I tried to normalize the input data, but the problems still persist. What is the problem that can cause this and how can I fix this?
Thanks",16,0
671,2016-5-22,2016,5,22,2,4kelka,Pure Maths or Applied for ML,https://www.reddit.com/r/MachineLearning/comments/4kelka/pure_maths_or_applied_for_ml/,aluminumginger,1463852632,"Hey so I'm 16 years old and I'm just about to finish O levels. Right now my subject choices for A levels are Pure Maths, Comp Sci and GMED (because it's fun and easy for me so I would appreciated keeping this subject). My teacher said if I go with Pure I would have more options but I would really like to understand most of the concepts in ML beforehand. What do you guys think? Should I choose Pure Maths or ditch it for Applied? What am I getting into if I choose each way? ",6,0
672,2016-5-22,2016,5,22,3,4kew2q,Best Database and format for storing experimental results.,https://www.reddit.com/r/MachineLearning/comments/4kew2q/best_database_and_format_for_storing_experimental/,bbsome,1463856615,"So following a recent [question](https://www.reddit.com/r/MachineLearning/comments/4kcf7y/how_do_you_organize_your_experiments/) here about how you organize your experiments, I started wondering what is the best DB and format for this. Consider you have the following  scenario:

You have one ""project"" where you run many executions over a grid of parameters. Each results, (for simplicity of my imagination) will be represent by a table, where rows are iterations (100K-1 million), columns are different metrics. Here we assume that based on the project the number of columns can be from 5-10 to 100 (Consider if you monitor each layer average/std activation, gradients etc...). In the end  you don't nessacarily want to plot a single metric from a single execution, but rather plot (or aggregate) metrics from different executions (e.g. you are interested in more than the ""best performing"" execution, but more of the overall beahaviour). 

In this setting I was wondering (as I saw a few projects with Mongo DB) is NoSQL better than an SQL tabled database? Is the SQL database gona be explicitly bad? I've haven't worked with DB too much, so maybe someone would have a better idea of how to structure this so that it is good. 

Anyway any suggestions, discussion are more than welcome. 

PS: The reason is that I can not use any open source tools such as the mentioned there [FGLab](https://kaixhin.github.io/FGLab/) as I'm using a cluster behind ssh, with no possibility for persistent client on the cluster, thus I might need to make my ad-hoc solution.",14,6
673,2016-5-22,2016,5,22,4,4kezjf,OpenCV or OpenDT for decision trees?,https://www.reddit.com/r/MachineLearning/comments/4kezjf/opencv_or_opendt_for_decision_trees/,YoungStellarObject,1463857971,"I have been working on a c++ project using decision trees for some time. We have been using OpenCV for the DT part, but since the code of 3.1 seems to be riddled with issues and is partially inaccessible, I am wondering if an alternative, especially OpenDT (or maybe waffles) would be worthwile. Any advice or experience?
(It's important that the licencing is pretty open.)
Thanks a bunch!

OpenCV: http://opencv.org/
OpenDT: http://opendt.sourceforge.net/",0,0
674,2016-5-22,2016,5,22,6,4kfic8,Uber's first self-driving car is here,https://www.reddit.com/r/MachineLearning/comments/4kfic8/ubers_first_selfdriving_car_is_here/,[deleted],1463865314,[deleted],0,0
675,2016-5-22,2016,5,22,6,4kfnzj,Why does a baby cry?,https://www.reddit.com/r/MachineLearning/comments/4kfnzj/why_does_a_baby_cry/,B1ood6od,1463867581,"Hey, hope I don't end up sounding like an idiot here (obvious start to something that will definitely make me sound like such). I have a fair amount of programming experience, and logic comes naturally to me (it should, shouldn't it?). I'm also going to father my first child in December. I'd like to make a baby monitor, probably using a CHIP that sends data to a server in the house. 

Something I'd like to apply to this is ""Why does a baby cry?"". I see this as a pretty decent question to toss towards machine learning, as you have self explanatory variables based off of time, age, etc. Question is, where's a good place to start developing? ",7,0
676,2016-5-22,2016,5,22,7,4kfrhr,"In this video between 21:30 and 22:00, Nando de Freitas says if you don't understand the probability of P(W=0)|S=0,R=1), you are lost, Does he mean to compute it by using marginalization and conditioning or does he mean to understand it intuitively?",https://www.reddit.com/r/MachineLearning/comments/4kfrhr/in_this_video_between_2130_and_2200_nando_de/,Mr__Christian_Grey,1463868963,,5,0
677,2016-5-22,2016,5,22,8,4kg3wj,Awesome resources for Kaggle Competition,https://www.reddit.com/r/MachineLearning/comments/4kg3wj/awesome_resources_for_kaggle_competition/,kkalyan3,1463874061,,0,1
678,2016-5-22,2016,5,22,9,4kg91a,Bill Gates-approved historian says AI will make some people totally useless,https://www.reddit.com/r/MachineLearning/comments/4kg91a/bill_gatesapproved_historian_says_ai_will_make/,dunkin1980,1463876303,,0,1
679,2016-5-22,2016,5,22,10,4kghj3,"ML Newbie, where should I start?",https://www.reddit.com/r/MachineLearning/comments/4kghj3/ml_newbie_where_should_i_start/,BlueMustache,1463880029,"Hello Reddit,
I am an avid Java programmer and love learning.
This summer I decided I wanted to make a Neural Network.
I have a lot of hardware and a lot of time. (Listed below.)
I wanted to make a Chatbot / AI that can help me do daily things, things that aren't programmed into it.
My AI will consist of two parts:

1. Front end interface / intent recognition

2. App / Api analysis

My thoughts are this. I say ""What is the origin address for the number ""512-XXX-XXX""? My AI then reads my intent using my voice recognition and lip reading from my Kinect as ""Looking for Postal Address"", ""Input is 512-XXX-XXX"". My AI will then look for an app or api on the internet that can fulfill those requirements. For example, it might grab the whitepages apk from google, and run it in a virtual machine. It would then recognize and use the app like a human would (recognizing how a human would use it and observing the used android class files), inputting the number and getting the address. The AI will meanwhile be capturing packets and analyzing them for a private api used in the app. Then the decompiler will recognize what is necessary to generate the authentication process every time. The AI will then add the api for future use to it's api list if the analysis is successful. What would be the best type of neural network for both intent recognition and heuristic app analysis? Also, what is the best tutorial for getting a fundamental understanding of neural networking and for implementing a GPU accelerated one in Java or C++, I'm flexible.
I have the hardware, time, and patience, please help me!
Thanks! 

**TLDR; What would be the best type of neural network for both intent recognition and heuristic app analysis?**
 
*Hardware Specs:*

Main Server (Consumer PC) - AMD 6-Core 3.5Ghz, 8GB DDR3 RAM, GTX 1080, Kinect v2 Sensor for Windows

Secondary Server - Intel Xeon Quad Core 2.93Ghz, 8GB RAM

Tertiary Server - Intel Xeon Quad Core 3.0Ghz, ??GB RAM (Just got it from my Dad's office)

Quaternary Server (Consumer PC) - Intel Dual Core 3.0Ghz, 8GB DDR2 RAM


P.S. I tried using lists, but the formatting wasn't working. Sorry.",6,0
680,2016-5-22,2016,5,22,15,4khgrw,Is it possible to implement a neural network that considers multiple agents with the same feature profiles simultaneously?,https://www.reddit.com/r/MachineLearning/comments/4khgrw/is_it_possible_to_implement_a_neural_network_that/,[deleted],1463898197,[deleted],0,1
681,2016-5-22,2016,5,22,15,4khi6b,I &lt;GRADIENT&gt; Stochastic Gradient Descent - T-shirt for SGD fanboys,https://www.reddit.com/r/MachineLearning/comments/4khi6b/i_gradient_stochastic_gradient_descent_tshirt_for/,nurikosan,1463899073,,0,1
682,2016-5-22,2016,5,22,15,4khiwh,How does NIPS2016 prevent adversarial reviewing?,https://www.reddit.com/r/MachineLearning/comments/4khiwh/how_does_nips2016_prevent_adversarial_reviewing/,AiseriousQ,1463899545,NIPS this year asks everyone who submits a paper to be a reviewer but let's admit it people would have incentive to review other submissions in the same area adversarially to boost their chance of acceptance.,0,1
683,2016-5-22,2016,5,22,17,4kht1t,[Hiring] PhD Research Fellow in Deep Reinforcement Learning and Bandit Algorithms (Annual Salary approx. 46 500 Euro),https://www.reddit.com/r/MachineLearning/comments/4kht1t/hiring_phd_research_fellow_in_deep_reinforcement/,olegranmo,1463906781,,24,10
684,2016-5-22,2016,5,22,18,4khxj5,seq2seq RNN in Tensor Flow: sampling without Teacher Forcing,https://www.reddit.com/r/MachineLearning/comments/4khxj5/seq2seq_rnn_in_tensor_flow_sampling_without/,peteykun,1463910104,"The [documentation](https://www.tensorflow.org/versions/r0.8/tutorials/seq2seq/index.html) for the seq2seq library in Tensorflow states in a matter-of-fact way that it is common to train with Teacher Forcing but test without:

    In many applications of sequence-to-sequence models the output of the decoder
    at time t is fed back and becomes the input of the decoder at time t+1. At test
    time, when decoding a sequence, this is how the sequence is constructed.
    During training, on the other hand, it is common to provide the correct input to
    the decoder at every time-step, even if the decoder made a mistake before.
    Functions in seq2seq.py support both modes using the feed_previous argument.

So far, I have called `embedding_rnn_seq2seq` with `feed_previous=False`, (i.e. the default) for use during training, wherein I explicitly provide a value of `decoder_inputs` to be used for training the model.

However, since the embedding is constructed *inside* of the `embedding_rnn_seq2seq` method, it does not make sense to simply construct another copy of the seq2seq model with the same encoder inputs, decoder inputs and LSTM cell while setting `feed_previous=True` for use during testing/validation (since the embeddings would not be copied).

I'm currently using an adapted version of [the code](https://www.reddit.com/r/MachineLearning/comments/43fw8s/simple_seq2seq_example_in_tensorflow/czi0ilp) by /u/sherjilozair, but since his model is a sequence autoencoder, the decoder input is the same as the encoder input, it is not applicable to my use case (decoder output =/= encoder output).

I could not find any examples where the library has been used to build such a model.   
Could someone please provide a simple example?",5,4
685,2016-5-22,2016,5,22,19,4khzs3,"How important is it for future Data Scientists, Machine Learners or current PhDs/students to know about HPC?",https://www.reddit.com/r/MachineLearning/comments/4khzs3/how_important_is_it_for_future_data_scientists/,siddkotwal,1463911702,"Watched a fun discussion here recently: 

https://www.youtube.com/watch?v=UbPqDEjr750

Where do MPI and Hadoop diverge? How beneficial will to be for someone aiming to become a Data Scientist to study HPC? 

Would love to hear perspectives of people from the industry or someone acquainted with real-world problems. ",10,0
686,2016-5-22,2016,5,22,19,4ki13r,"AI will create 'useless class' of human, predicts bestselling historian.",https://www.reddit.com/r/MachineLearning/comments/4ki13r/ai_will_create_useless_class_of_human_predicts/,[deleted],1463912590,[deleted],2,0
687,2016-5-22,2016,5,22,19,4ki3q2,Terrapattern: A machine learning project on identifying patterns on earth using satellite imagery. By Golan Levin (professor at carnegie mellon university).,https://www.reddit.com/r/MachineLearning/comments/4ki3q2/terrapattern_a_machine_learning_project_on/,dackdel,1463914309,,17,65
688,2016-5-22,2016,5,22,20,4ki8rk,We're a group of students developing this productivity app during a 28 hour hackathon. Click here to learn more,https://www.reddit.com/r/MachineLearning/comments/4ki8rk/were_a_group_of_students_developing_this/,Karlonion,1463917521,,2,0
689,2016-5-22,2016,5,22,22,4kijh3,What's your opinion on doing a PhD in Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/4kijh3/whats_your_opinion_on_doing_a_phd_in_deep_learning/,[deleted],1463923597,[removed],0,1
690,2016-5-23,2016,5,23,0,4kj48f,Are there problem types that machine learning would never be able to solve?,https://www.reddit.com/r/MachineLearning/comments/4kj48f/are_there_problem_types_that_machine_learning/,Lajamerr_Mittesdine,1463932609,"I'm pretty new to Machine Learning and I wanted to know the limits of it.

Are there problems that a human could solve or is solvable in general but that machine learning could never solve if given an infinite number of resources(storage, CPUs, ram, power, etc) , variables, accurate input data, proper classifications, and time?

My intuition is to say if all those criteria were met that the answer is no, there are no problems unsolvable, If a human can solve it, machine learning could solve it.

It's just due to limitations in resources, time, lack of accurate data, etc, that make it difficult to solve it in a realistic practical timeline.",11,0
691,2016-5-23,2016,5,23,1,4kj65q,How does NIPS2016 prevent adversarial reviewing?,https://www.reddit.com/r/MachineLearning/comments/4kj65q/how_does_nips2016_prevent_adversarial_reviewing/,AiseriousQ,1463933393,NIPS this year asks everyone who submits a paper to be a reviewer but let's admit it people would have incentive to review other submissions in the same area adversarially to boost their chance of acceptance,19,16
692,2016-5-23,2016,5,23,1,4kjbmg,Getting started with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/4kjbmg/getting_started_with_machine_learning/,Writes_A_Bit,1463935513,"I'm coming to this sub with some background work in Computer Vision/Image Processing.

I want to delve into CNNs for Computer Vision related tasks. 
I can handle coding in Python now. 

How do I go about it?

I know there are different libraries available like Torch, Caffe, TensorFlow, and I think OpenCV's own ML module. Which ones are best suited for someone who's exposure to ML comes from Andrew Ng's MATLAB/Octave based Coursera Course?
",1,0
693,2016-5-23,2016,5,23,2,4kjf5i,Publication dates of almost 15000 ML conference papers scrapped from IEEExplore,https://www.reddit.com/r/MachineLearning/comments/4kjf5i/publication_dates_of_almost_15000_ml_conference/,[deleted],1463936828,[deleted],0,1
694,2016-5-23,2016,5,23,3,4kjphu,[1605.05396] Generative Adversarial Text to Image Synthesis,https://www.reddit.com/r/MachineLearning/comments/4kjphu/160505396_generative_adversarial_text_to_image/,alexjc,1463940672,,14,40
695,2016-5-23,2016,5,23,5,4kkc0u,Thoughts on Machine Learning/AI Masters in the UK?,https://www.reddit.com/r/MachineLearning/comments/4kkc0u/thoughts_on_machine_learningai_masters_in_the_uk/,DAJ1,1463948979,"Hi! Sorry if it's the wrong place for this sort of thing but I was wondering if I could gauge your opinions on postgraduate courses in the UK? I'm currently sitting on offers for the three courses below but I'm unsure which to take; all the universities try and hype themselves up so it's hard to get an accurate picture of what they're really like.

The courses are:

* MSc Artificial Intelligence at Edinburgh.
* MSc Advanced Computing - Machine Learning, Data Mining and High Performance Computing at Bristol.
* MSc Artificial Intelligence at Manchester.

Any thoughts on these would be extremely useful, particularly if you're on, or recently graduated from, one of these courses.

Thanks :)",18,11
696,2016-5-23,2016,5,23,5,4kkfsn,Roger Schank on IBM Watson,https://www.reddit.com/r/MachineLearning/comments/4kkfsn/roger_schank_on_ibm_watson/,AnvaMiba,1463950322,"[LINK](http://www.rogerschank.com/fraudulent-claims-made-by-IBM-about-Watson-and-AI)

[Roger Schank](https://en.wikipedia.org/wiki/Roger_Schank) flat out calls Watson, or more specifically the way that IBM advertises Watson, a fraud.

His point is that Watson is essentially a ""word counter"" (which I interpret as an information retrieval system based on bag-of-words or bag-of-ngrams frequency statistics) not very different from Google search, incapable of any non-trivial reasoning, contrary to how IBM presents it in its advertising.

What do you think? Is this assessment of Watson's architecture and functionality and of IBM advertising practices accurate?
",55,81
697,2016-5-23,2016,5,23,6,4kkjzn,YouTube Engineering Blog: Using ML to optimize video transcoding settings,https://www.reddit.com/r/MachineLearning/comments/4kkjzn/youtube_engineering_blog_using_ml_to_optimize/,rndnum123,1463951903,,2,7
698,2016-5-23,2016,5,23,8,4kkzoq,Deep neutral network to predict age from blood sample,https://www.reddit.com/r/MachineLearning/comments/4kkzoq/deep_neutral_network_to_predict_age_from_blood/,warppipe,1463958046,,2,6
699,2016-5-23,2016,5,23,10,4klnrn,Build a Movie Recommender - Machine Learning for Hackers #4,https://www.reddit.com/r/MachineLearning/comments/4klnrn/build_a_movie_recommender_machine_learning_for/,[deleted],1463968124,[deleted],0,1
700,2016-5-23,2016,5,23,11,4klqq9,[1605.06431] Residual Networks are Exponential Ensembles of Relatively Shallow Networks,https://www.reddit.com/r/MachineLearning/comments/4klqq9/160506431_residual_networks_are_exponential/,r-sync,1463969382,,13,60
701,2016-5-23,2016,5,23,12,4kly92,why contrastive divergence should work?,https://www.reddit.com/r/MachineLearning/comments/4kly92/why_contrastive_divergence_should_work/,koormoosh,1463972633,"I am going over Hinton's contrastive divergence paper [http://www.cs.toronto.edu/~fritz/absps/tr00-004.pdf], the problem definition and the idea is clear but the paper doesn't really provide a mathematical proof of ""why replacing equilibrium samples, with the first step's samples should work?"" Is it fully based on experimental results, or I am missing something? There is a bit of explanation (and motivation) in the paragraphs above equation 5, which seems to be in that direction but then he doesn't really provide a proof. 

This is most probably a wrong conclusion, but to me it seems that he tried the idea of using the first step samples, and it just happened to work, hence he provided a semi-proof of why it worked. In an ideal universe, I was hoping to see a sound theoretical proof first and then see how it works in practice. The paper seems to be the other way around.",12,1
702,2016-5-23,2016,5,23,13,4km6hu,Automatic Metal Sheet Strip Straightener Machine - HS Thick Sheet Straightener Machine - HONGER,https://www.reddit.com/r/MachineLearning/comments/4km6hu/automatic_metal_sheet_strip_straightener_machine/,Dellachen,1463976333,,0,0
703,2016-5-23,2016,5,23,13,4km7u7,Top Uni's PhD-environment for AI Research,https://www.reddit.com/r/MachineLearning/comments/4km7u7/top_unis_phdenvironment_for_ai_research/,Mimrash,1463976954,[removed],0,1
704,2016-5-23,2016,5,23,13,4kmati,[1605.06450] Query-Efficient Imitation Learning for End-to-End Autonomous Driving,https://www.reddit.com/r/MachineLearning/comments/4kmati/160506450_queryefficient_imitation_learning_for/,clbam8,1463978322,,0,1
705,2016-5-23,2016,5,23,13,4kmcl7,Announcement: Post your Job Announcements to /r/MLjobs,https://www.reddit.com/r/MachineLearning/comments/4kmcl7/announcement_post_your_job_announcements_to/,BeatLeJuce,1463979182,[removed],0,1
706,2016-5-23,2016,5,23,13,4kmd18,Announcement: use /r/MLjobs for posts regarding jobs,https://www.reddit.com/r/MachineLearning/comments/4kmd18/announcement_use_rmljobs_for_posts_regarding_jobs/,BeatLeJuce,1463979405,"From time to time we, the moderators, get questions about whether it is okay to post job announcements up on this subreddit. And other times people just go ahead and post them. Most of these posts seem to be unwelcomed here. /u/loveofprofit [+2] was kind enough to set up /r/MLjobs , where people can post their ""we're hiring"" // ""I'm looking for a job"" kind of posts. From now on, all post of this kind will unceremonially be deleted here and people will be pointed to that new subreddit. That is all.",1,19
707,2016-5-23,2016,5,23,14,4kmg45,Having trouble understanding google's quote regarding the relationship between learning rate and batch size,https://www.reddit.com/r/MachineLearning/comments/4kmg45/having_trouble_understanding_googles_quote/,realhamster,1463980914,"In the bottom section of [this tensorflow tutorial](https://www.tensorflow.org/versions/r0.8/how_tos/image_retraining/index.html), under the Hyper-Parameters heading I found this quote:

&gt;The --train_batch_size controls how many images are examined during one training step, and because the learning rate is applied per batch you'll need to reduce it if you have larger batches to get the same overall effect.

Which is really confusing me. The way I see things, as we increase batch size our gradient will be more precise, so we can use a bigger learning rate cause we are more certain we are going towards the correct direction.

On the other hand, with smaller batch sizes our gradient will be noisier so a bigger learning rate will harm our convergence.

That is the way I originally thought about it, but it seems to be the opposite of what the quote is saying. So where am I wrong?",8,3
708,2016-5-23,2016,5,23,14,4kmk7f,How to choose the reactors?,https://www.reddit.com/r/MachineLearning/comments/4kmk7f/how_to_choose_the_reactors/,mixmachinery,1463983056,,1,1
709,2016-5-23,2016,5,23,16,4kmuda,UAI 2016 accepted papers,https://www.reddit.com/r/MachineLearning/comments/4kmuda/uai_2016_accepted_papers/,ciolaamotore,1463988629,,1,15
710,2016-5-23,2016,5,23,17,4kmzk9,NN model not learning?,https://www.reddit.com/r/MachineLearning/comments/4kmzk9/nn_model_not_learning/,zerogravity555,1463991894,"I tried to model a NN using softmax regression. After 999 iterations, I got error of about 0.02% for per data point, which i thought was good. But when I visualize the model on tensorboard, my cost function did not reach towards 0. And weights and bias histogram is confusing too. http://imgur.com/a/NFXul

I am a beginner so i probably made some silly mistake, is it because I did not use the correct cost function?

Here is my full code-

    'import tensorflow as tf
     import numpy as np
     import random

     lorange= 1
     hirange= 10
     amplitude= np.random.uniform(-10,10)
     t= 10
     random.seed()
     tau=np.random.uniform(lorange,hirange)


     x_node = tf.placeholder(tf.float32, (10,))
     y_node = tf.placeholder(tf.float32, (10,))

     W = tf.Variable(tf.truncated_normal([10,10], stddev= .1))
     b = tf.Variable(.1)

     y = tf.nn.softmax(tf.matmul(tf.reshape(x_node,[1,10]), W) + b)

     ##ADD SUMMARY

     W_hist = tf.histogram_summary(""weights"", W)
     b_hist = tf.histogram_summary(""biases"", b)
     y_hist = tf.histogram_summary(""y"", y)

     # Cost function sum((y_-y)**2)
     with tf.name_scope(""cost"") as scope:
        cost = tf.reduce_mean(tf.square(y_node-y))
        cost_sum = tf.scalar_summary(""cost"", cost)

     # Training using Gradient Descent to minimize cost
     with tf.name_scope(""train"") as scope:
       train_step = tf.train.GradientDescentOptimizer(0.00001).minimize(cost)

     sess = tf.InteractiveSession()

      # Merge all the summaries and write them out to logfile
     merged = tf.merge_all_summaries()
     writer = tf.train.SummaryWriter(""/tmp/mnist_logs_4"",  sess.graph_def)
     error = tf.reduce_sum(tf.abs(y - y_node))


     init = tf.initialize_all_variables()
     sess.run(init)

     steps = 1000

     for i in range(steps):
         xs = np.arange(t)
         ys = amplitude * np.exp(-xs / tau)

         feed = {x_node: xs, y_node: ys}
         sess.run(train_step, feed_dict=feed)
         print(""After %d iteration:"" % i)
         print(""W: %s"" % sess.run(W))
         print(""b: %s"" % sess.run(b))
         print('Total Error: ', error.eval(feed_dict={x_node: xs, y_node:ys}))
         # Record summary data, and the accuracy every 10 steps
         if i % 10 == 0:
           result = sess.run(merged, feed_dict=feed)
           writer.add_summary(result, i)",2,0
711,2016-5-23,2016,5,23,17,4kmzqg,Consequences of an Insightful Algorithm (slides),https://www.reddit.com/r/MachineLearning/comments/4kmzqg/consequences_of_an_insightful_algorithm_slides/,pmigdal,1463992004,,0,1
712,2016-5-23,2016,5,23,18,4kn4zo,Online tracking: A 1-million-site measurement and analysis,https://www.reddit.com/r/MachineLearning/comments/4kn4zo/online_tracking_a_1millionsite_measurement_and/,[deleted],1463995362,[deleted],0,0
713,2016-5-23,2016,5,23,19,4knekm,Deep neural estimator with wrong labels,https://www.reddit.com/r/MachineLearning/comments/4knekm/deep_neural_estimator_with_wrong_labels/,[deleted],1464001082,[deleted],5,1
714,2016-5-23,2016,5,23,21,4knqqw,[1605.06265] End-to-End Kernel Learning with Supervised Convolutional Kernel Networks,https://www.reddit.com/r/MachineLearning/comments/4knqqw/160506265_endtoend_kernel_learning_with/,ChocoMoi,1464007366,,0,15
715,2016-5-23,2016,5,23,22,4knxhu,Clever Gift Chat Bot!,https://www.reddit.com/r/MachineLearning/comments/4knxhu/clever_gift_chat_bot/,[deleted],1464010189,[deleted],0,1
716,2016-5-23,2016,5,23,22,4kny45,GT AutoRally: Aggressive Driving with MPPI Control Overview,https://www.reddit.com/r/MachineLearning/comments/4kny45/gt_autorally_aggressive_driving_with_mppi_control/,reidhoch,1464010428,,14,59
717,2016-5-23,2016,5,23,23,4ko5hj,Quick question about the FAQ,https://www.reddit.com/r/MachineLearning/comments/4ko5hj/quick_question_about_the_faq/,[deleted],1464013233,[deleted],0,0
718,2016-5-23,2016,5,23,23,4koahx,Dueling Deep Q-Networks (Torch Blog),https://www.reddit.com/r/MachineLearning/comments/4koahx/dueling_deep_qnetworks_torch_blog/,alxndrkalinin,1464014990,,0,5
719,2016-5-24,2016,5,24,0,4koew1,"[1605.06465] Swapout: Learning an ensemble of deep architectures (samples from dropout, ResNets, stochastic depth)",https://www.reddit.com/r/MachineLearning/comments/4koew1/160506465_swapout_learning_an_ensemble_of_deep/,andyandy16,1464016525,,8,14
720,2016-5-24,2016,5,24,2,4koyus,probability - How can we prove this equation using marginalization and conditioning?,https://www.reddit.com/r/MachineLearning/comments/4koyus/probability_how_can_we_prove_this_equation_using/,Mr__Christian_Grey,1464023141,,1,0
721,2016-5-24,2016,5,24,2,4kp1i4,Need some advice on using Singular Value Decomposition for anomaly detection,https://www.reddit.com/r/MachineLearning/comments/4kp1i4/need_some_advice_on_using_singular_value/,sanity,1464024009,"I'm using SVD to do dimensionality reduction on a set of input data (a combination of one-hot encoded categorical data, and numeric data).

My assumption is that the magnitude of the output vector (the row of U) can be used to determine how ""anomalous"" this piece of input data is relative to the rest of the input dataset.

My rationale is that input data rows that are more similar to the rest of the input dataset can be encoded in a smaller vector by SVD.

Is this a reasonable approach?",5,4
722,2016-5-24,2016,5,24,2,4kp3xa,Is object detection ignored?,https://www.reddit.com/r/MachineLearning/comments/4kp3xa/is_object_detection_ignored/,she89,1464024787,"Correct me, if I'm wrong. Most of NN models doesn't know which pixels make the object they recognize.",2,0
723,2016-5-24,2016,5,24,2,4kp658,TensorFlow Fizzbuzz,https://www.reddit.com/r/MachineLearning/comments/4kp658/tensorflow_fizzbuzz/,chrico031,1464025503,,116,517
724,2016-5-24,2016,5,24,3,4kp9yy,Evaluating Summarization Systems,https://www.reddit.com/r/MachineLearning/comments/4kp9yy/evaluating_summarization_systems/,julian88888888,1464026727,,0,5
725,2016-5-24,2016,5,24,3,4kpamc,Complete Guide to Parameter Tuning in XGBoost (with codes in Python),https://www.reddit.com/r/MachineLearning/comments/4kpamc/complete_guide_to_parameter_tuning_in_xgboost/,pmigdal,1464026924,,1,8
726,2016-5-24,2016,5,24,4,4kplst,DAOS and Lustre: Machine Learning on Intel's Supercomputing Platform,https://www.reddit.com/r/MachineLearning/comments/4kplst/daos_and_lustre_machine_learning_on_intels/,[deleted],1464030421,[deleted],0,2
727,2016-5-24,2016,5,24,4,4kprfh,Object oriented principles/best practices for machine learning?,https://www.reddit.com/r/MachineLearning/comments/4kprfh/object_oriented_principlesbest_practices_for/,cjmcmurtrie,1464032231,"We had quite a passionate debate about this today at work. Are there any good insights into the most useful object oriented principles/design patterns in machine learning?

One point of contention was whether the training behaviour during forward and backward propagation should be independent from a model's definition.

On the one side, it was argued that a sound abstraction is such that a model should be a self contained unit that knows two behaviours - forward and backward. Thus Trainer and Model are two independent abstractions, and any Model in theory should know how to train with any Trainer.

On the other side of the argument, some thought that the pattern of steps a model follows when training is a part of the model's design - for instance, it is possible to design a model that does a forward/backward pass through a right-forking decoder and then again through a left-forking decoder. This 'trainer' is particular to the design of that model, and should be an attribute of an instance of that model. Thus as part of a Model class, a Trainer method is inherited and written to define the training behaviour of Model.

Interested to hear other perspectives on this in particular, or more general ones on the subject.",11,2
728,2016-5-24,2016,5,24,5,4kpwub,"Adversarial validation, part one",https://www.reddit.com/r/MachineLearning/comments/4kpwub/adversarial_validation_part_one/,gwulfs,1464034036,,0,3
729,2016-5-24,2016,5,24,5,4kpztm,Lasagne vs Blocks for deep learning?,https://www.reddit.com/r/MachineLearning/comments/4kpztm/lasagne_vs_blocks_for_deep_learning/,shash273,1464035005,"How do these two libraries compare in terms of ease of use, implementation of common dl architectures, optimization routines etc?

I want to learn one of them in case some network needs to be coded up from scratch, which is difficult to handle with Keras.",5,2
730,2016-5-24,2016,5,24,5,4kq3jx,Questions thread #6 2016.05.23,https://www.reddit.com/r/MachineLearning/comments/4kq3jx/questions_thread_6_20160523/,feedtheaimbot,1464036216,"**Please post your questions here instead of creating a new thread. Helps keep the sub clean. :) Encourage others who create new posts for questions to post here instead!**

Thread will stay alive until next one so keep posting after the date in the title. 

Thanks to everyone for answering questions in the previous thread!

Previous threads:

* [Questions thread #5 2016.05.07]
(https://www.reddit.com/r/MachineLearning/comments/4ibv66/questions_thread_5_20160507/)

* [Questions thread #4 2016.04.22]
(https://www.reddit.com/r/MachineLearning/comments/4fytfp/questions_thread_4_20160422/)

* [Questions Thread #3 2016.04.07](https://www.reddit.com/r/MachineLearning/comments/4dthzx/questions_thread_3_20160407/)

* [Simple Questions Thread #2 + Meta - 2016.03.23](https://www.reddit.com/r/MachineLearning/comments/4bp1ck/simple_questions_thread_2_meta_20160323/)

* [Simple Questions Thread #1 - 2016.03.08](https://www.reddit.com/r/MachineLearning/comments/49k54u/simple_questions_thread_20160308/)",158,8
731,2016-5-24,2016,5,24,5,4kq3yy,Build a Recommender System using Amazon's new Deep Learning Library in 5 min,https://www.reddit.com/r/MachineLearning/comments/4kq3yy/build_a_recommender_system_using_amazons_new_deep/,llSourcell,1464036352,,3,3
732,2016-5-24,2016,5,24,6,4kqe5q,Why do deep CNN work worse than shallow ones?,https://www.reddit.com/r/MachineLearning/comments/4kqe5q/why_do_deep_cnn_work_worse_than_shallow_ones/,theendofallend,1464039832,"So I've been trying to train a CNN for the past couple days and I noticed during testing that when I reduce the number of layers in the CNN it works way better than deeper CNN. (I ran some simple test with a network with 0 layers (basically a simple NN) work way better than networks with 2+ layers(convolution+subsampling). When I try to run the network with some 10+ layers, it seems to not work at all. Does someone know why this is the case?

Edit: For those who are curious here's the net structure that I'm testing
cnn.layers = {

    struct('type', 'i',""size"",a) %input layer
    struct('type', 'c', 'outputmaps', 2, 'size', [3,3,3,2],""skip"",[1,1],""pad"",0) %convolution layer. size is the size of the Weights
    struct('type', 's','dim', [2,2]) %max sub sampling layer of 2x2
    struct('type', 'c', 'outputmaps', 2, 'size', [2,2,2,1],""skip"",[1,1],""pad"",0) 
    struct('type', 'c', 'outputmaps', 2, 'size', [3,3,1,1],""skip"",[1,1],""pad"",0) 
    struct('type', 'c', 'outputmaps', 2, 'size', [3,3,1,1],""skip"",[1,1],""pad"",0) 
    struct('type', 'c', 'outputmaps', 2, 'size', [3,3,1,1],""skip"",[1,1],""pad"",0) 
    % a final layer is also present where the output is multiplied by the output weight
    % I'm still troubleshooting the backpropagation algorithm,so it's possible that is where the problem lies
}

The size of 

Thet random input:
 
x(:,:,:,1)=rand(a);

 x(:,:,:,2)=rand(a);

 x(:,:,:,3)=rand(a); % 3 input examples

 x=normalize(x);

 y=round(rand(3,10));
",18,0
733,2016-5-24,2016,5,24,7,4kqmys,Anyone know anything about Google's Magenta?,https://www.reddit.com/r/MachineLearning/comments/4kqmys/anyone_know_anything_about_googles_magenta/,anonDogeLover,1464042978,I can't find anything useful on what method they are using to approach the problem. Is this anything more than a toy exercise to show off Tensorflow?,5,0
734,2016-5-24,2016,5,24,10,4krfj2,"BatchNorm - why is each batch normalized by the current mean/variance, instead of the running average?",https://www.reddit.com/r/MachineLearning/comments/4krfj2/batchnorm_why_is_each_batch_normalized_by_the/,throwaway0x459,1464053643,"See the title.  It would seem to make more sense to have a running average, learned from the data, and use that during training and testing.

The other approach (every training batch normalized by its own mean/variance, testing batches normalized by the running mean/variance) would seem to be overfitting during training.",6,1
735,2016-5-24,2016,5,24,11,4krl7w,Image Captioning with mRNN (paper),https://www.reddit.com/r/MachineLearning/comments/4krl7w/image_captioning_with_mrnn_paper/,Jxieeducation,1464055918,,0,0
736,2016-5-24,2016,5,24,11,4krp3w,Wide Residual Networks,https://www.reddit.com/r/MachineLearning/comments/4krp3w/wide_residual_networks/,malleus17,1464057524,,25,31
737,2016-5-24,2016,5,24,12,4krtgq,"Hitchhiker's Guide to Data Science, Machine Learning, R, Python",https://www.reddit.com/r/MachineLearning/comments/4krtgq/hitchhikers_guide_to_data_science_machine/,abdsc,1464059290,,2,27
738,2016-5-24,2016,5,24,12,4kru2d,Question about how do people train their networks.,https://www.reddit.com/r/MachineLearning/comments/4kru2d/question_about_how_do_people_train_their_networks/,adamlostguitar,1464059532,"Hi everyone,

I am not relatively new to machine learning, I work with relatively small datasets by using R and Python and it worked pretty well for me, but I am trying to move to a higher level with relatively more complex networks and datasets on my MacBook and I've never be able to wait for the results. I am not a hardware guy so this apparently is a pain in my butt and I need so advices.

My laptop uses Intel Iris GPU so when I used tensorflow I could not use CUDA to accelerate my GPU. I searched online and unfortunately I didn't find any helpful information to help to to solve this problem.

How do you train your networks? All of you have Linux computers or have a machine that you can control remotely? Did you encounter the same problem I am facing right now and how did you solve it?

Super thanks in advance.

Cheers",6,0
739,2016-5-24,2016,5,24,15,4ksf5p,[Noob alert] How many layers are there in the Tensorflow's Inception model?,https://www.reddit.com/r/MachineLearning/comments/4ksf5p/noob_alert_how_many_layers_are_there_in_the/,[deleted],1464069963,[removed],1,0
740,2016-5-24,2016,5,24,15,4ksgft,Lecture notes for RNN for cs231n(Stanford),https://www.reddit.com/r/MachineLearning/comments/4ksgft/lecture_notes_for_rnn_for_cs231nstanford/,wardroton,1464070706,"Hello,

Does anyone know where I can find lecture notes for RNN&amp;LSTM for the course: http://cs231n.github.io/ 

Thanks
",2,5
741,2016-5-24,2016,5,24,15,4ksghp,3 Hour Machine Learning Competition on 28th May - Invite,https://www.reddit.com/r/MachineLearning/comments/4ksghp/3_hour_machine_learning_competition_on_28th_may/,john_philip,1464070746,,0,5
742,2016-5-24,2016,5,24,15,4ksj2z,Vicarious AI - hype or not?,https://www.reddit.com/r/MachineLearning/comments/4ksj2z/vicarious_ai_hype_or_not/,captchadolphin,1464072463,[removed],0,1
743,2016-5-24,2016,5,24,16,4kskfq,Have there been any significant arguments that A.I. is limited in some way?,https://www.reddit.com/r/MachineLearning/comments/4kskfq/have_there_been_any_significant_arguments_that_ai/,KivishDwarf,1464073340,"Has there recently been any really good argument that computers or turing machines, etc, *can't* simulate intelligence like humans? I know that's a little vague, but I'm just wondering if anyone has given us any solid reason to think our A.I. aspirations can't be filled out with our usual models of computing.
Also, to clarify, any reasons not to believe machine intelligence is limited would be interesting, too.",27,0
744,2016-5-24,2016,5,24,16,4ksl46,[1605.06432] Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data,https://www.reddit.com/r/MachineLearning/comments/4ksl46/160506432_deep_variational_bayes_filters/,sieisteinmodel,1464073722,,2,17
745,2016-5-24,2016,5,24,16,4ksmmh,Any good resources for A.I/Machine Learning info?,https://www.reddit.com/r/MachineLearning/comments/4ksmmh/any_good_resources_for_aimachine_learning_info/,[deleted],1464074637,[deleted],0,0
746,2016-5-24,2016,5,24,16,4kso2u,Node parallelism in ANN,https://www.reddit.com/r/MachineLearning/comments/4kso2u/node_parallelism_in_ann/,dhanajitb,1464075532,[removed],0,1
747,2016-5-24,2016,5,24,18,4ksxlk,[1605.06640] Programming with a Differentiable Forth Interpreter,https://www.reddit.com/r/MachineLearning/comments/4ksxlk/160506640_programming_with_a_differentiable_forth/,_rockt,1464081666,,3,39
748,2016-5-24,2016,5,24,21,4ktg8o,Machine Learning application framework for industry,https://www.reddit.com/r/MachineLearning/comments/4ktg8o/machine_learning_application_framework_for/,xcfmv,1464091997,"Hello,

I have been searching for a general machine learning application framework for my research project, but have not found any that I am completely happy with.

The idea is having a framework that has customizable built-in data collection, preparation, storage components, supports to implement REST API/ RPC for querying the outputs or controlling the app.
I just need to implement those components once, then other time is to spend on building the algorithm block, which take inputs as prepared data, stores models or intermediary calculation result in a storage component, then exposes/returns the prediction results to outside world.

The framework should also allow me to implement my own algorithms (highly customizable) in Python and Java, and has built-in ML libraries ready to be used.

So far I have seen Prediction.io, H2O.ai, Apache mahout, apache spark, Google Tensorflow, Torch7. I just have a surface overview of those system, but it seems to me:
- Tensorflow and Torch7 are more for Deep learning things, I need a general framework for different applications.
- Prediction.io is the closest, however, custom algorithms can only implemented in Java and Scala.
- H2O.ai supports only Java as well.
- Mahout, Spark: not clear yet.

Anyone has experience with this please share with me. Thanks a lot.



",5,0
749,2016-5-24,2016,5,24,21,4kthg9,How fast can you expect to train a neural network?,https://www.reddit.com/r/MachineLearning/comments/4kthg9/how_fast_can_you_expect_to_train_a_neural_network/,The_Amp_Walrus,1464092485,"I'm writing a toy neural net library as a part of [Coursera's Neural Nets for Machine Learning](https://class.coursera.org/neuralnets-2012-001/lecture). I'm generally happy with it's correctness - probably some bugs floating around in there but it [seems to work](http://mattsegal.xyz/words/). My concern at the moment is its performance. I had no idea if its training speed is embarrassingly slow or as fast as my hardware allows. All computations are done with NumPy/python. I think most of the computations that can use matrices are appropriately vectorized.
  
Currently the network trains on ~370000 sets of three input words and one target word, using batches in the range of 100 to 3000 samples. The network has a hidden layer of 150 linear units, 200 logistic units then a softmax layer of 250 units.  One iteration over all the batches takes about 2 minutes.

The computer is an HP laptop with 8gb of RAM and a 64-bit AMD quad core processor that does 1.8GHz. The computations use all cores at 100%.

This may be a hard question to answer, but, do you thing I could do much better with my current hardware? If so, what are some areas to look at? Otherwise, what are some strategies for training a network faster? My GPU is buggered so I need to rent a cloud computer to make use of GPU processing. If I go down that path, are there any good tools or guides for getting a neural net to train quickly on the cloud? ",13,0
750,2016-5-24,2016,5,24,21,4ktmji,ML Matching Methods,https://www.reddit.com/r/MachineLearning/comments/4ktmji/ml_matching_methods/,stripedfish7,1464094490,"Hello r/MachineLearning
Just a question as to where I can get some more information about the following. Ive been thinking of situations that are slightly more complex than simple classification problems. Consider where the outcome or classes have information/attributes. For example, say we have people looking at houses that are for sale, we could use KNN/RF etc. to match people based on their attributes (income, occupation, marital status, age of kids, etc.) to houses they would be most likely to buy/view/whatever, but I see two problems with this:
 
* 1 we would be ignoring a huge amount of information via this method by not considering the traits of the house (cost, proximity to city center/school, type of house, the color of the house, etc.). 

* 2 If a new house becomes listed for sale, our model may not suggest it is an appropriate fit as there were no matches in our training set.

I assume there is a method that can take care of this but I am unsure of what exactly it is.

Id like to use this method for a school project in a biological setting. 

Can anyone point me towards where I can learn about such a method (from a theoretical background as well as an applications standpoint)? Thank you! 

* Originally posted to r/MLQuestions to no avail *",8,2
751,2016-5-24,2016,5,24,22,4ktqeu,[1605.07110] Deep Learning without Poor Local Minima (Mathematically proved powerful results!),https://www.reddit.com/r/MachineLearning/comments/4ktqeu/160507110_deep_learning_without_poor_local_minima/,andyandy16,1464096043,,51,131
752,2016-5-24,2016,5,24,22,4kttil,The future of mobility is starting now. Do you know where we are heading?,https://www.reddit.com/r/MachineLearning/comments/4kttil/the_future_of_mobility_is_starting_now_do_you/,sciencefictionfan05,1464097227,,0,0
753,2016-5-24,2016,5,24,22,4ktv75,Understanding Human-in-the-loop and how to implement it,https://www.reddit.com/r/MachineLearning/comments/4ktv75/understanding_humanintheloop_and_how_to_implement/,alexvitale,1464097891,,0,0
754,2016-5-25,2016,5,25,1,4kujp0,Autoencoding Blade Runner: Reconstructing films with artificial neural networks,https://www.reddit.com/r/MachineLearning/comments/4kujp0/autoencoding_blade_runner_reconstructing_films/,t_broad,1464106415,,15,46
755,2016-5-25,2016,5,25,1,4kum90,Infographic: 16 Genius Minds Whose Inventions Made Data Science Easier For Us,https://www.reddit.com/r/MachineLearning/comments/4kum90/infographic_16_genius_minds_whose_inventions_made/,PyBet,1464107230,,0,0
756,2016-5-25,2016,5,25,1,4kurd8,TensorLog: A Differentiable Deductive Database [code and paper],https://www.reddit.com/r/MachineLearning/comments/4kurd8/tensorlog_a_differentiable_deductive_database/,improbabble,1464108871,,1,25
757,2016-5-25,2016,5,25,2,4kv01d,Recommended way to generate features from text,https://www.reddit.com/r/MachineLearning/comments/4kv01d/recommended_way_to_generate_features_from_text/,MasterEpictetus,1464111651,I'd like to convert short documents (up to 1000 words) into a small number of features to be used later in classification. Doc2vec didn't work well from me as most documents are very short. I was wondering if there is a better way to do it which avoids a bag of words representation. ,19,9
758,2016-5-25,2016,5,25,2,4kv1j9,Automatic Generation of Rhythmic Nonsense Verse with LSTMs and Weighted Finite State Transducer Cascades,https://www.reddit.com/r/MachineLearning/comments/4kv1j9/automatic_generation_of_rhythmic_nonsense_verse/,Noddybear,1464112108,"Hi, I'm a MPhil student currently writing up my dissertation on the topic of automatic poetry generation. Using a generative phonetic-level LSTM trained on a vast corpus of poetry, and a discriminative WFST cascade to force rhythm, I'm getting pretty good results.
To evaluate, Ive put together a indistinguishability test between some real poetry and poetry generated by my model.
Can you tell Lewis Carroll (and others) from a computer? It would be great to get some feedback!

http://neuropoetry.herokuapp.com",10,0
759,2016-5-25,2016,5,25,3,4kvehq,R Tutorial by DrivenData &amp; DataCamp: Data Mining the Water Table,https://www.reddit.com/r/MachineLearning/comments/4kvehq/r_tutorial_by_drivendata_datacamp_data_mining_the/,stearnsw,1464116247,,1,0
760,2016-5-25,2016,5,25,4,4kvgzc,How do you deal with huge datasets?,https://www.reddit.com/r/MachineLearning/comments/4kvgzc/how_do_you_deal_with_huge_datasets/,[deleted],1464117052,"I have started exploring deep learning recently. I find that it takes too long to load images from disk and prepare mini-batches to feed into a neural network, which significantly increases the training time.

What are some recommended approaches to dealing with huge datasets with &gt; 100k images?

EDIT: is -&gt; are",10,1
761,2016-5-25,2016,5,25,4,4kvhmd,"One of the most valuable uses of machine learning/datascience I've seen - ""Your words may predict your future mental health""",https://www.reddit.com/r/MachineLearning/comments/4kvhmd/one_of_the_most_valuable_uses_of_machine/,andyandy16,1464117265,,0,1
762,2016-5-25,2016,5,25,4,4kvj0z,Explore the Galaxy of images with Cloud Vision API,https://www.reddit.com/r/MachineLearning/comments/4kvj0z/explore_the_galaxy_of_images_with_cloud_vision_api/,kazunori279,1464117721,,0,1
763,2016-5-25,2016,5,25,6,4kw8zq,Machine learning Python packages for Raspbian/Debian?,https://www.reddit.com/r/MachineLearning/comments/4kw8zq/machine_learning_python_packages_for/,iforgot120,1464126082,Sounds kinda crazy but are there any? Specifically for Raspbian. ,5,2
764,2016-5-25,2016,5,25,7,4kwdv2,DanDoesData: Building a font recognition dataset from Shakespeare,https://www.reddit.com/r/MachineLearning/comments/4kwdv2/dandoesdata_building_a_font_recognition_dataset/,vanboxel,1464127776,,0,0
765,2016-5-25,2016,5,25,7,4kwm1n,Google's Project Abacus kill password with machine learning,https://www.reddit.com/r/MachineLearning/comments/4kwm1n/googles_project_abacus_kill_password_with_machine/,RavlaAlvar,1464130760,,9,17
766,2016-5-25,2016,5,25,10,4kx823,[1605.07157] Unsupervised Learning for Physical Interaction through Video Prediction (Google Brain),https://www.reddit.com/r/MachineLearning/comments/4kx823/160507157_unsupervised_learning_for_physical/,InaneMembrane,1464139334,,1,38
767,2016-5-25,2016,5,25,10,4kx9q6,Is there a machine learning framework that allows me to modify built NN structure during training?,https://www.reddit.com/r/MachineLearning/comments/4kx9q6/is_there_a_machine_learning_framework_that_allows/,kkawabat,1464140000,"I don't know if this is common but, I'm trying to find a machine learning framework that allows me to add and remove layers on a neural network and change weights\cost function during training. 

I looked into tensorflow and theano but their frameworks makes it difficult to modify the structure of NN after compilation.",8,0
768,2016-5-25,2016,5,25,13,4kxwup,[1605.07277] Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples,https://www.reddit.com/r/MachineLearning/comments/4kxwup/160507277_transferability_in_machine_learning/,downtownslim,1464149934,,0,0
769,2016-5-25,2016,5,25,13,4kxy6p,How to avoid overfitting the literature?,https://www.reddit.com/r/MachineLearning/comments/4kxy6p/how_to_avoid_overfitting_the_literature/,NichG,1464150551,"Making a transition from physics to machine learning, and sitting down to write up my first machine learning paper, I'm struck by a bit of a problem.

Up to this point my process was - had an idea for an algorithm, implemented it, tried it on toy problems (it worked, okay), tried it on some real problems that have their own project lines going that probably each deserve a paper about the project itself and interesting stuff came out, great!

But now for those other projects, it'd be nice if they had something concrete to reference that had the details of this algorithm. Okay, no problem, I'll just write something up and put it on the arXiv so they can point to it and say 'yeah, we used that thing'. 

But here's the issue - I need a reference problem or two to validate the algorithm. I can make toy problems but it seems pretty bad to only have toy problems. Okay, fine, so I'll go find some other problem that has vaguely the right form, find a few benchmarks, run my thing on it, and report the results. But actually, I think I've just said something really problematic there - if I look long enough, I'm sure I could find some public dataset where my thing will outperform the current best benchmarks, because there are many different factors contributing to performance and so, just like fitting a model with lots of parameters, I could hunt around to find the perfect storm. Its worse when the algorithm is solving a less common sort of task, since there aren't even obvious workhorse benchmarks that everyone compares on.

So, how do you avoid overfitting the literature? How do you demonstrate an algorithm without the unspoken possibility that you just cherry-picked the perfect demonstration case? And are there standard ways to compare subjective results (such as in the case of unsupervised data exploration, for example) other than just picking a dataset and showing some kind of dimension-reduction or cluster plot?

Or, more directly, if you were to happen upon a paper or writeup describing some idea, what would you want to see included in that writeup to make the encounter most useful to you?",26,65
770,2016-5-25,2016,5,25,13,4ky0ki,Community detection and Caching,https://www.reddit.com/r/MachineLearning/comments/4ky0ki/community_detection_and_caching/,KrisSingh,1464151715,I want to cache in the internet with the assumption of caching at every node in the internet.I wanted to community detection based on 2 factors (cache content at each node + traffic pattern at each node) and i want to cache nodes that are far away spatially because i dont want to cache the same content close by.Do you know any such community detection paper all i have seen is they consider the spatial closeness.,0,1
771,2016-5-25,2016,5,25,15,4kyawl,MAXCAN F1600G gift printing machine,https://www.reddit.com/r/MachineLearning/comments/4kyawl/maxcan_f1600g_gift_printing_machine/,maxcanprintermachine,1464157043,,1,0
772,2016-5-25,2016,5,25,15,4kydwz,lstm example in tensorflow,https://www.reddit.com/r/MachineLearning/comments/4kydwz/lstm_example_in_tensorflow/,vinayakumarr,1464158629,[removed],0,1
773,2016-5-25,2016,5,25,17,4kym5n,CVPR 2016 sponsor list,https://www.reddit.com/r/MachineLearning/comments/4kym5n/cvpr_2016_sponsor_list/,steven2358,1464163646,,3,1
774,2016-5-25,2016,5,25,18,4kyr5s,Rule of thumb for resizing CNN with the number of classes?,https://www.reddit.com/r/MachineLearning/comments/4kyr5s/rule_of_thumb_for_resizing_cnn_with_the_number_of/,erogol,1464166900,"Given some working models like inception what is a rational way to set the model size regarding the number of classes.  It is clear to me that with a small number of classes but with the original inception model,  we are doomed by the overfitting.  I believe the reason is we exploit too much representational power given the classes.  

What are some reasonable tricks to make any state of art network working with your particular problem possibly much less number of classes.  ",1,0
775,2016-5-25,2016,5,25,18,4kys15,What is Vector-based machine learning?,https://www.reddit.com/r/MachineLearning/comments/4kys15/what_is_vectorbased_machine_learning/,siez_,1464167449,"My boss coined this term and want me to write something about it. 

I am familiar with the concept of machine learning (not familiar with deep stuff). 

I want a basic explanation so I can start my research about the topic. 

Thanks, 

Edit: It's Support vector machine, not Vector-based machine learning. ",12,0
776,2016-5-25,2016,5,25,20,4kz4nw,F6090 Maxcan Bottle Printing machine,https://www.reddit.com/r/MachineLearning/comments/4kz4nw/f6090_maxcan_bottle_printing_machine/,maxcanprintermachine,1464174981,,2,0
777,2016-5-25,2016,5,25,21,4kzb08,A comparison of GPU accelerators for deep learning (whitepaper),https://www.reddit.com/r/MachineLearning/comments/4kzb08/a_comparison_of_gpu_accelerators_for_deep/,MasterEpictetus,1464178051,,14,26
778,2016-5-25,2016,5,25,21,4kzcjc,Deep Learning without Poor Local Minima,https://www.reddit.com/r/MachineLearning/comments/4kzcjc/deep_learning_without_poor_local_minima/,kraakf,1464178727,,0,0
779,2016-5-25,2016,5,25,21,4kzcm4,Natural Language Interfaces and Humans behind it,https://www.reddit.com/r/MachineLearning/comments/4kzcm4/natural_language_interfaces_and_humans_behind_it/,CalmDaev,1464178766,,0,0
780,2016-5-25,2016,5,25,21,4kzdim,Learning to Remove Soft Shadows (with custom Random Forest),https://www.reddit.com/r/MachineLearning/comments/4kzdim/learning_to_remove_soft_shadows_with_custom/,pmigdal,1464179153,,0,2
781,2016-5-25,2016,5,25,21,4kzhdu,Software for identifying terms in documents (contracts),https://www.reddit.com/r/MachineLearning/comments/4kzhdu/software_for_identifying_terms_in_documents/,bymatthew,1464180822,"I'm looking into ML software that would look at contracts, identify specified terms (start date, length of time, fees payment terms, etc.) and populate that info in a database.  Is there a good software program that is designed for this kind of use?",3,0
782,2016-5-25,2016,5,25,22,4kziyb,Applying Adversarial Network To Natural Language Generation,https://www.reddit.com/r/MachineLearning/comments/4kziyb/applying_adversarial_network_to_natural_language/,LeavesBreathe,1464181473,"Hey Guys,

Lately, I have been trying to applying a adversarial network to generating sequences of words. Right now, I'm just trying to get a toy task to work eg(""learn learn learn learn learn pad pad pad pad"")

The problem is that the discriminator ends up just crushing the generator, and the generator can never beat it. I have tried:

* Changing learning rates (adam 0.0001 and beta2 0.005)
* Perturbing the generator's weights so it will settle on a different local min
* Changing RNN architecture (GRU, LSTM, Vanilla RNN)
* Different initializations

Currently, I have the generator produce a softmax distribution for each timestep which is fed directly to the discriminator. For the real data, I ""fake"" a softmax distribution where the selected word has a 50 to 80% and the other words are random noise all summing to 1.0 in the end. The generator always learns something. Specifically, its weights and outputs change but the generator always learns the repeat the wrong word. 

I know Goodfellow commented that applying adversarial is harder to NLP because words are not continuous real data. Rather, words are discrete. I'm thinking of instead of passing a softmax distribution, passing the embedding. On generation time, you could take the cosine closest distance from the embedding space to a word. In this way, each word is more like a continuous real data, where the embedding can be altered slightly. 

Don't mean to write a book, but I thought I would run all of this by you guys for feedback. Thoughts?",28,17
783,2016-5-25,2016,5,25,22,4kzmis,Learning to Communicate with Deep Multi-Agent Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/4kzmis/learning_to_communicate_with_deep_multiagent/,jakobnicolaus,1464182875,,3,23
784,2016-5-25,2016,5,25,23,4l00s5,Understanding Deep Dreams: an ELI5 on Convolutonal Neural Networks,https://www.reddit.com/r/MachineLearning/comments/4l00s5/understanding_deep_dreams_an_eli5_on_convolutonal/,AlanZucconi,1464187964,,16,38
785,2016-5-26,2016,5,26,0,4l0bnm,Simple Blackjack SGD Bot using only NumPy,https://www.reddit.com/r/MachineLearning/comments/4l0bnm/simple_blackjack_sgd_bot_using_only_numpy/,Staturecrane,1464191671,,0,8
786,2016-5-26,2016,5,26,1,4l0k0s,Food image recognition app released,https://www.reddit.com/r/MachineLearning/comments/4l0k0s/food_image_recognition_app_released/,[deleted],1464194414,[deleted],2,1
787,2016-5-26,2016,5,26,3,4l12e7,What hardware setup are you using for deep learning?,https://www.reddit.com/r/MachineLearning/comments/4l12e7/what_hardware_setup_are_you_using_for_deep/,jeiting,1464200398,"I just started on a project that is doing deep conv nets over a fairly large data set (73x144x1 images for now, once I have the basic pipeline setup up I want to train it on 146x288x10 ""images"", and I have a couple hundred thousand of them).

I'm currently using TensorFlow on my 2011 MacBook Air to build out and test some of my models. This is cumbersome for a number of reasons: it hogs my laptop, its pretty slow, doesn't use the GPU, don't have enough disk space etc. 

I'm thinking about getting access to some additional hardware, either building a machine or renting something.

My question for the community: What sort of hardware setup are you using to do your training? (renting, personal machine, academic access, not really interested in the specs per se but more just the setup)",7,1
788,2016-5-26,2016,5,26,3,4l1376,"Those of you using ML in production, what does your tech stack look like? [May 2016]",https://www.reddit.com/r/MachineLearning/comments/4l1376/those_of_you_using_ml_in_production_what_does/,nharada,1464200671,"Interested to see what the tech stacks look like for production machine learning workloads (not data science) at this time, May 2016. I'd love to hear the company/product if you're comfortable sharing but if not no worries.",66,126
789,2016-5-26,2016,5,26,3,4l138t,Masters Program Questions:Edinburgh or UCL,https://www.reddit.com/r/MachineLearning/comments/4l138t/masters_program_questionsedinburgh_or_ucl/,ArtlockScofield,1464200686,"I have two offers- MSc AI at University of Edinburgh and MSc Machine Learning UCL. I am an international candidate(non-EU) and while my leaning is more towards Edinburgh, I can't find any international candidate(non-EU) who finished the course and managed to land a good job in the field in UK. However, I saw many such cases from UCL, which makes me believe that UCL is safe choice. I am interested in application of machine learning to AI, especially computer vision and deep learning.
Edit: I will be taking out a loan to support myself, and hence the interest in safe choice.",8,0
790,2016-5-26,2016,5,26,3,4l13z1,Intuition behind using Noise Contrastive Divergence in Neural Language Models,https://www.reddit.com/r/MachineLearning/comments/4l13z1/intuition_behind_using_noise_contrastive/,koormoosh,1464200925,"I am going over this paper [https://www.cs.toronto.edu/~amnih/papers/ncelm.pdf] which uses NCE to avoid dealing with the normalization constant of a log bilinear model, when maximizing the likelihood. The problem is clear, but I don't understand what is the intuition behind changing the problem of maximum likelihood to the problem of binary classification. I can see below equation 12, the authors mention that the gradient of expectation of the mixture of data and noise sample, when number of noise samples goes to infinity recovers the formula of the maximum likelihood gradient. So, perhaps this is where the two problems become interchangeable. My question has two parts:

1)how equation 12 is the formula of the maximum likelihood gradient?

2) what is the intuition that the ratio of noise to actual samples is k to 1?",3,8
791,2016-5-26,2016,5,26,4,4l1hat,"Normalization Propagation: the new ""Batch Norm""? (generally more stable &amp; accurate)",https://www.reddit.com/r/MachineLearning/comments/4l1hat/normalization_propagation_the_new_batch_norm/,andyandy16,1464205411,,3,2
792,2016-5-26,2016,5,26,5,4l1qk5,"Which companies are actively investing into, developing, and/or progressing machine learning?",https://www.reddit.com/r/MachineLearning/comments/4l1qk5/which_companies_are_actively_investing_into/,newscrash,1464208600,And for what purposes? I know it's being used in everything from finance to genetics - would love to hear what other companies are putting machine learning to use on.,6,1
793,2016-5-26,2016,5,26,6,4l20u9,Auto-correction of numbers provided in survey responses?,https://www.reddit.com/r/MachineLearning/comments/4l20u9/autocorrection_of_numbers_provided_in_survey/,twackster,1464212361,"Hi, I'm not looking for a specific answer to this question, just a general direction or insight on the feasibility of my idea. I have very elementary experience with machine learning.

At my job we survey thousands of organizations every year asking them to fill out an online form where they state their payroll for one pay period. We then use various outlier detection techniques (measures of central tendency and percent change) to locate and manually correct abhorrent data provided by our respondents. This is extremely time consuming and resource intensive. The abhorrent data that we receive from our survey respondents have noticeable patterns, for example the same respondent makes the same mistakes every year, like doubling their pay. We also have common mistakes like the respondent including cents with the number without the decimal point; or providing yearly or quarterly pay instead of the pay for one pay period. 

At work I can pull every response that was manually corrected and it's corresponding original unedited data over several years. 

Is their any machine learning technique that I can explore that will allow me predict our manual correction of the data of responses that have been identified to be bad? I was thinking that one could train using the original response and the corrected response to find the patterns that we often notice that at my job. 

One challenge I see is that there are two issues going on, one is a string based problem such as the decimal being missing and another is a numeric problem such as the pay being doubled. I don't know if any of the R packages that do pattern recognition/prediction that can easily do this. 

Any suggestions or thoughts?
",2,0
794,2016-5-26,2016,5,26,7,4l25vg,Using Machine Learning for Batch Computing Scheduling,https://www.reddit.com/r/MachineLearning/comments/4l25vg/using_machine_learning_for_batch_computing/,bignum,1464214218,"Hi,
I've searched around the Internet for machine learning applications to scheduling, but so far I haven't found much relevant work in this specific area.

I've seen some papers dedicated to OS process scheduling, but only one or two relevant to batch farm computing scheduling.

I'm also a bit new to things like neural networks, which seem suited to things like image recognition, voice recognition, etc. But not necessarily time series data.

In this case, I'd like to ask if anyone has any experience using machine learning to predict, based on certain parameters, not only how long the batch computing job will take, how much memory it will use, how many cores it will use, etc. But also the usage patterns. For example, say a batch job initially uses 16GB of real memory for the first 20 minutes of runtime, but then its needs grow to 24GB, and then goes down to 8GB after an hour. 

If the batch scheduler could predict this behavior with high confidence based on the type of CPU core the job is running on, how much load the machine it landed on has, etc, it could dynamically schedule other jobs to fit into the available resources on the machine. Say the machine has 32GB of real memory. For the first 20 minutes it would have 16GB available, but it knows that after that it will only have 8GB available, so it would avoid landing a job that would use more than 8GB on that machine, at least until after the job starts using less memory again.

Is something like this possible with current technology? Is process information too stochastic for this to work? Any input is appreciated!

",0,1
795,2016-5-26,2016,5,26,7,4l29ey,Parallelized Narrow Scope NN or single Wider Scope NN,https://www.reddit.com/r/MachineLearning/comments/4l29ey/parallelized_narrow_scope_nn_or_single_wider/,Lajamerr_Mittesdine,1464215620,"Is it more efficient to have separate neural networks that are narrowly scoped but are looped in a cycle or a neural network in a wider scope that does everything all the narrow scoped tasks in one model.

By efficient I mean the training time, amount of data required, accuracy, etc.

Or is it a sort of trade-off.

The reason I ask is I think the future of personal assistant androids, is they will be connected to the Internet and if the owner gives a task they haven't done before, ""Wash the dishes."" It will transcribe the voice to text, ""understand"" the intent of the sentence(do a task) and if it doesn't know the task, it will search the online repository of chain linked narrowly scoped tasks and then download it and run it.

The chain would be like so,

1. Go through internal mapping bank of household and try to find a place that looks like a kitchen / dish sink / dish washer.

2a. If it finds no matches in the household(not mapped yet) it will ask the task giver to bring them to the area. 

2b. If it matches, goes to the area.

3. When in the area, it branches out to different ways to do the dishes depending on what it identifies. I.e. With dishwasher, without dishwasher, etc

I think the future is in defining narrowly scoped trained models, have a online repository and chain link them together for building up complex tasks.",3,1
796,2016-5-26,2016,5,26,8,4l2eh9,"Are there any other conferences like NIPS that care about AI, machine learning, neuroscience, and cognitive science so broadly?",https://www.reddit.com/r/MachineLearning/comments/4l2eh9/are_there_any_other_conferences_like_nips_that/,anonDogeLover,1464217628,,3,4
797,2016-5-26,2016,5,26,8,4l2g2r,Any pretrained CNNs for CIFAR?,https://www.reddit.com/r/MachineLearning/comments/4l2g2r/any_pretrained_cnns_for_cifar/,anonDogeLover,1464218254,Preferably in Caffe or Keras,3,0
798,2016-5-26,2016,5,26,10,4l2x08,Educational resources for a visual learner?,https://www.reddit.com/r/MachineLearning/comments/4l2x08/educational_resources_for_a_visual_learner/,Corm,1464225297,"I'm looking for good books/courses/anything in math/stats/machine-learning with a lot of good visuals. Good visual aids help me a ton.

I'm just trying to get a foothold with ML with the end goal of making a balancing quad walker robot. I have a cs background.

Paying for classes or textbooks is no problem. 

Edit: linear algebra is another bottleneck for ML I've run into ",4,1
799,2016-5-26,2016,5,26,12,4l3ej6,[1605.07683] Learning End-to-End Goal-Oriented Dialog,https://www.reddit.com/r/MachineLearning/comments/4l3ej6/160507683_learning_endtoend_goaloriented_dialog/,RushAndAPush,1464232567,,0,10
800,2016-5-26,2016,5,26,12,4l3i9t,"Southern California Machine Learning Symposium, May 20, 2016",https://www.reddit.com/r/MachineLearning/comments/4l3i9t/southern_california_machine_learning_symposium/,mttd,1464234263,,1,3
801,2016-5-26,2016,5,26,15,4l3zs0,Hardware-oriented Approximation of Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/4l3zs0/hardwareoriented_approximation_of_convolutional/,olBaa,1464243302,,4,6
802,2016-5-26,2016,5,26,15,4l40di,How to deploy machine learning infrastructure to Kubernetes,https://www.reddit.com/r/MachineLearning/comments/4l40di/how_to_deploy_machine_learning_infrastructure_to/,ahousley,1464243660,,0,0
803,2016-5-26,2016,5,26,16,4l44yx,A Computer Algorithm Does the Work of 85 Artists: Watch Starry Starwars: a Clip of Star Wars: Episode V in the Art Style of Vincent Van Gogh,https://www.reddit.com/r/MachineLearning/comments/4l44yx/a_computer_algorithm_does_the_work_of_85_artists/,alex_ml,1464246307,,4,2
804,2016-5-26,2016,5,26,19,4l4nbh,Where to start?,https://www.reddit.com/r/MachineLearning/comments/4l4nbh/where_to_start/,[deleted],1464257984,[deleted],2,0
805,2016-5-26,2016,5,26,20,4l4ug5,Deep Neural Networks Under Stress,https://www.reddit.com/r/MachineLearning/comments/4l4ug5/deep_neural_networks_under_stress/,MicaelCarvalho,1464262255,,5,41
806,2016-5-26,2016,5,26,21,4l4yea,Stochastic vs Deterministic Policy Gradients: what is the intuitive difference and motivation?,https://www.reddit.com/r/MachineLearning/comments/4l4yea/stochastic_vs_deterministic_policy_gradients_what/,nonap_,1464264198,"I couldn't understand what DPGs do exactly and how it's better than SPGs. How can determinism and expectation be together?

Can someone please clarify this intuitively?",2,5
807,2016-5-26,2016,5,26,23,4l5hy1,OpenAI Team Update,https://www.reddit.com/r/MachineLearning/comments/4l5hy1/openai_team_update/,perceptron01,1464272146,,0,0
808,2016-5-26,2016,5,26,23,4l5iwt,"[1605.07678] An Analysis of Deep Neural Network Models for Practical Applications (compares accuracy, memory, parameters, operations, time, power usage - great visualisations)",https://www.reddit.com/r/MachineLearning/comments/4l5iwt/160507678_an_analysis_of_deep_neural_network/,andyandy16,1464272489,,5,21
809,2016-5-26,2016,5,26,23,4l5pgh,Short Science - Community-sourced summaries of ML papers,https://www.reddit.com/r/MachineLearning/comments/4l5pgh/short_science_communitysourced_summaries_of_ml/,Barbas,1464274776,,2,26
810,2016-5-27,2016,5,27,0,4l5tsz,Alemite Grease Pump  For Better Lubrication Practices,https://www.reddit.com/r/MachineLearning/comments/4l5tsz/alemite_grease_pump_for_better_lubrication/,jackerfrinandis,1464276200,,0,1
811,2016-5-27,2016,5,27,0,4l5zhl,What about creating an ML engineering subreddit?,https://www.reddit.com/r/MachineLearning/comments/4l5zhl/what_about_creating_an_ml_engineering_subreddit/,Chobeat,1464278076,"I don't think there's anything out there yet so I would like to know if there could be interest for a subreddit about Machine Learning Engineering, to talk about dedicated software, good practices, design principles that may not be interesting for data scientists and researchers. 

There's a lot of work going on and the field is getting more clearly defined on a daily basis so I think it should deserve a dedicated space.
 ",16,27
812,2016-5-27,2016,5,27,1,4l68uv,Looking for a multinomial clustering algorithm,https://www.reddit.com/r/MachineLearning/comments/4l68uv/looking_for_a_multinomial_clustering_algorithm/,rmadcf,1464281217,"Dear all,

I have discrete count data (multinomial) with the following properties where I am looking for clusters which I would eventually like to use for inference of new data.

* dimensions / size of vocabulary: 8
* variables are not independent (dim 1 should be mutually exclusive with dim 4, dim 6 usually co-occurs with dim 7 etc.)
* there is no labeled data (supervised learning is out)
* however there is available domain knowledge and I do know that some ""cluster centroids"" or ""topics"" should exists around certain ratios of the variables (I know for sure that there should be around 18 clusters)
* I cannot use tf-idf because of the idf part. Tf transformation to a real-valued representation of ratios would be totally fine, if needed.

I thought that this problem lends itself well to topic modelling. So far I tried 

* HDP: failed miserably, did not yield meaningful ""topics""
* LDA: came up with much better topics but was very inconsistent between different runs of the training. Failed miserably during the inference step. (I think this was because the algorithm was not designed for cases where the expected number of topics was larger than the vocabulary size.) 

I have been looking into many alternative algorithms and I am a little lost. Algorithms such as k-means are designed for real-valued data and I haven't yet found any established unsupervised classification/clustering algorithms for multinomial or ratio data. I would therefore welcome any suggestions.

Thank you very much for your time and suggestions! I hope the question would also be helpful to others here.",0,1
813,2016-5-27,2016,5,27,2,4l6exh,Conceptnet Numberbatch: The best word embeddings you can download,https://www.reddit.com/r/MachineLearning/comments/4l6exh/conceptnet_numberbatch_the_best_word_embeddings/,rspeer,1464283351,,11,18
814,2016-5-27,2016,5,27,3,4l6pv2,"Advanced Natural Language Processing Tools for Bot Makers  LUIS, Wit.ai, Api.ai",https://www.reddit.com/r/MachineLearning/comments/4l6pv2/advanced_natural_language_processing_tools_for/,bogsformer,1464287097,,0,13
815,2016-5-27,2016,5,27,3,4l6rld,Visualize: how a Machine-Learning system interprets the grammatical structure of your sentences.,https://www.reddit.com/r/MachineLearning/comments/4l6rld/visualize_how_a_machinelearning_system_interprets/,[deleted],1464287673,[deleted],29,106
816,2016-5-27,2016,5,27,4,4l743x,Consumer reputation score,https://www.reddit.com/r/MachineLearning/comments/4l743x/consumer_reputation_score/,CaptainMeself,1464291877,"Hey Reddit,

I'm working on a machine learning problem that deals with predicting the reputation of a consumer. In this case, a consumer achieves a higher credit score if he/she has not defaulted on previous transactions and a lower one if he/she has had several previously failed transactions. Assuming I've sufficient historical data to work with that has labeled transactions for failure/success, what would be the class of machine learning techniques I should be looking into? I believe it could be a regression problem, but I'm not quite sure. Several research papers deal with estimating consumer credit risk but I'm uncertain if this is what I'm supposed to be looking at.",6,2
817,2016-5-27,2016,5,27,4,4l75ug,"[Beginners] How to write your first classifier, using scikit-learn - in 6 lines of code (Example by Google Developers)",https://www.reddit.com/r/MachineLearning/comments/4l75ug/beginners_how_to_write_your_first_classifier/,Monninho,1464292492,,3,0
818,2016-5-27,2016,5,27,5,4l7dpl,Top 200 machine learning companies from Alexa 1M,https://www.reddit.com/r/MachineLearning/comments/4l7dpl/top_200_machine_learning_companies_from_alexa_1m/,dim2500,1464295124,,1,0
819,2016-5-27,2016,5,27,5,4l7gb2,Substantial (~50%) speed loss on Titan X due to overheating? (TensorFlow),https://www.reddit.com/r/MachineLearning/comments/4l7gb2/substantial_50_speed_loss_on_titan_x_due_to/,SuperFX,1464296018,"Has anyone experienced very substantial speed degradation with Titan Xs on TensorFlow due to overheating? I have had identical runs vary by as much as 50% in speed and my only explanation is heating. These were done on different days (they take 12 hours on fast days, and up to 24 hours on slow days). It's a in a box with 8 Titan Xs in it, and all of them are running independent models. The temperature of the GPUs are in the high 70s or low 80s celsius, wattage does reach up to around 250W (capped), but mostly stays around 200, and fan speed is at most 40%. Utilization is often around 95% or 99%. Has anyone experienced something similar? I've seen [this](https://github.com/soumith/convnet-benchmarks/issues/71), but they're reporting very minor speed loss compared to what I'm seeing.",23,3
820,2016-5-27,2016,5,27,6,4l7ipj,Thinking about making a transition from a Biomedical Engineering background to a more machine learning focused PhD -- trying to understand what kind of a theory/implementation split I should be going for.,https://www.reddit.com/r/MachineLearning/comments/4l7ipj/thinking_about_making_a_transition_from_a/,TissueReligion,1464296886,"Hi!

So basically... I've spent the past several years of my life working in biology and biomedical engineering, but I've always felt very called by math and computer science.

I find biology interesting, however... academic jobs are absurdly competitive, and in industry... because biology is so fickle, and the whole point of industry is naturally to make money, the level of difficulty of the problems that most biotech companies I see are facing are not fundamental research questions. Its just slight optimizations on repeatedly validated work.

So... I'm planning on starting a PhD program in Fall of 2017, and I have the opportunity to do a computational only PhD, that might be sort of a... machine learning-y data science-y kind of gig.

But it would largely be implementation/analysis, probably no theory at all.

*I really want to work on important problems...*

I'm trying to get a feel for the extent that a mostly analysis/implementation PhD hinder my career goals after graduate schools.

Assuming I don't get an academic job, 1) is there much fundamental ML research being done in industry? (I read about google and facebook etc., but don't have a feel for the general market), and 2) would having done a mostly implementation-focused PhD pigeonhole me into some kind of implementation code monkey role?

If I had actually majored in math as an undergrad, I am fairly confident that by ability I could have handled a theoretical ML PhD (this is a vague impression of myself I have come to by being friends with a lot of graduate students), but as I am now I think its too much of a stretch...",3,6
821,2016-5-27,2016,5,27,6,4l7kej,data sparseness,https://www.reddit.com/r/MachineLearning/comments/4l7kej/data_sparseness/,ghamarbani,1464297529,why decision tree and random forest cannot handle data sparseness?,1,1
822,2016-5-27,2016,5,27,7,4l7rx1,Using Net2Net to speed up network training,https://www.reddit.com/r/MachineLearning/comments/4l7rx1/using_net2net_to_speed_up_network_training/,DanielSlater8,1464300343,,10,14
823,2016-5-27,2016,5,27,7,4l7xix,Q-learning agent with imperfect sensor reading,https://www.reddit.com/r/MachineLearning/comments/4l7xix/qlearning_agent_with_imperfect_sensor_reading/,ss428,1464302511,"Hi, Im currently working on a project related to reinforcement learning. 

The setting:
The agent (robot) does not have full information of the environment. 

The states are represented depending on five sensor readings. 

Each of the sensors can have reading in range between 0-8 (I have 5 sensors so 9^5 states).

3 available actions: move forward, turn left , turn right

Right now, I made a model that uses neural network (relu) to approximate Q(s,a). 

5 sensor readings are used as an input and 3 output neutrons are used to determine maximum action. 

Until here, everything works fine. 

Now I have to make this agent run with imperfect sensor readings. 

For example:


True sensor reading is [8 8 8 8 8],
and lets say that each sensor have error [0.0 0.9 0.0 0.0 0.0]  
*0.0 means 0% error

In this example, second sensor has 90% chance of having false reading. 

Due to the error, lets say the reading of the imperfect sensor becomes [8 4 8 8 8]

Now, I have to let the agent learn how to avoid obstacles in the environment using imperfect sensors.

Currently I startet reading about POMDP, but Im not sure if Im on the right track. 

If anyone could advise me where I should make a good start, Id appreciate it.",1,1
824,2016-5-27,2016,5,27,7,4l7z7y,"[Question] Detecting thin edges(wires, etc) in images (pixel wise classification)",https://www.reddit.com/r/MachineLearning/comments/4l7z7y/question_detecting_thin_edgeswires_etc_in_images/,mad_rat_man,1464303194,"(edit topic should have been semantic segmentation but you got that)
I am working on detecting thin wires/ power lines(single pixel/sub pixel width) in images. Earlier I was using fully convnets by Long, but I realized it was overkill for my task. A simple convnet of 2/3 layers with 7*7 filters - no pooling and stride 1 -  is working better (I have been varying the filter sizes - 7/3/13 etc and the width, but gist is 2/3 layers with stride 1 and no pooling is obviously better and don't know why I was using full convnets). 

My question is how should I get more context and eliminate false positives(clutter) (I ll do hard positive/negative mining, but currently trying to figure out what's the best architecture to handle this). I am experimenting with dilated convolutions. Things like inside outside nets or crfs won't be real time. Just asking for ideas on how to encode more context or other preprocessing I should do - something specific to very thin edges. 

Something like convolutional pose machines (https://arxiv.org/abs/1602.00134) might help, in that I feed the input image again and again after each layer, or maybe introduce a loss at each layer?

There has been work on boundary detection - https://arxiv.org/pdf/1412.1123.pdf and http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Shen_DeepContour_A_Deep_2015_CVPR_paper.pdf, but I guess it's again a more harder problem and not that fast. Any suggestions are welcome :)
",3,3
825,2016-5-27,2016,5,27,9,4l8buj,What are methods of transmitting models out of an analytics environment and into a real time system?,https://www.reddit.com/r/MachineLearning/comments/4l8buj/what_are_methods_of_transmitting_models_out_of_an/,0111001101110000,1464308557,"Currently we are using PMML, but that is not necessarily the best method.

* What other methods are there?

* Does the method support transformations?

I see the following possibilities,

* PMML using [JPMML](https://github.com/jpmml)
* SAS to Java code (as discussed [here](https://support.sas.com/documentation/onlinedoc/miner/em121/emcjscore.pdf))
* Hardcoding
* Protobuf - I don't know much about this, and any resources on building and executing would be appreciated.

Thanks!",0,1
826,2016-5-27,2016,5,27,10,4l8h4z,Strange training behaviour,https://www.reddit.com/r/MachineLearning/comments/4l8h4z/strange_training_behaviour/,[deleted],1464310856,[deleted],0,1
827,2016-5-27,2016,5,27,12,4l8vvw,Cameron Aaron TED Talk,https://www.reddit.com/r/MachineLearning/comments/4l8vvw/cameron_aaron_ted_talk/,[deleted],1464318425,,0,0
828,2016-5-27,2016,5,27,14,4l9add,Most Basic Ideas behind Dimensionality Reduction,https://www.reddit.com/r/MachineLearning/comments/4l9add/most_basic_ideas_behind_dimensionality_reduction/,Mirber,1464325529,,1,1
829,2016-5-27,2016,5,27,15,4l9m48,What is Vector based word classification?,https://www.reddit.com/r/MachineLearning/comments/4l9m48/what_is_vector_based_word_classification/,siez_,1464332336,"Thanks, 
",7,0
830,2016-5-27,2016,5,27,19,4la3tj,How is machine learning being used at Netflix?,https://www.reddit.com/r/MachineLearning/comments/4la3tj/how_is_machine_learning_being_used_at_netflix/,reworksophie,1464344030,,0,1
831,2016-5-27,2016,5,27,20,4la9zn,Has anyone considered batch normalization for a restricted Boltzmann machine?,https://www.reddit.com/r/MachineLearning/comments/4la9zn/has_anyone_considered_batch_normalization_for_a/,krish240574,1464347802,"I've rolled my own DBN, using restricted Boltzmann machines. I came across the batch normalization paper at http://arxiv.org/pdf/1502.03167.pdf and was considering implementing the same into the DBN. Has any one has experience with such an effort? I understand that the following would change: 1. A layer of BN(x) (BN - batch normalization) would get added between the linear and non-linear parts of each layer. 2. I would be training the DBN layer-wise, greedily, as usual. (using CD-1 or N, as preferred). 3. The backprop part would be pertaining to the BN, as in the paper. (The backprop for DBNs as earlier would not apply) 4. I would use moving averages over many mini-batches, as in the paper. Any opinions? Do comment, it would be nice to have fresh perspectives.",0,1
832,2016-5-27,2016,5,27,20,4lac5r,what will you do when you got whole internet text?,https://www.reddit.com/r/MachineLearning/comments/4lac5r/what_will_you_do_when_you_got_whole_internet_text/,godspeed_china,1464349108,"I downloaded common crawl whole internet text (11 TB). Ideally we can do many interesting analysises. For example can we discover drug trafficking network? Or can we discover some conspiracy stories? Or simply discover some association rules based on big data?  
Any ideas or room for imagination?",6,0
833,2016-5-27,2016,5,27,20,4ladal,Freeze Thaw Bayesian Optimization: anyone tried it?,https://www.reddit.com/r/MachineLearning/comments/4ladal/freeze_thaw_bayesian_optimization_anyone_tried_it/,L43,1464349720,"I've been playing around with automatic hyperparameterization for my NNs, and came across this paper: http://arxiv.org/abs/1406.3896 I was wondering if anyone had tried implementing it or something similar? It looks extremely powerful from what I understand it does, but I'm not sure I understand what exactly they are doing (I get the idea of BO, but it goes a bit beyond what I have looked at), so would appreciate any further materials (implementations, blog posts, anything!) related to the technique to help me get my head around it. Looking forward to an interesting discussion!
",4,22
834,2016-5-27,2016,5,27,21,4laknp,"Adversarial Machine Learning Conference Sep 10 / SF / fraud, security, AML and KYC",https://www.reddit.com/r/MachineLearning/comments/4laknp/adversarial_machine_learning_conference_sep_10_sf/,arshakn,1464353354,,1,0
835,2016-5-27,2016,5,27,22,4laqyn,Is it worth purchasing ML certificate on Coursera?,https://www.reddit.com/r/MachineLearning/comments/4laqyn/is_it_worth_purchasing_ml_certificate_on_coursera/,mefistofeli,1464356138,"I'm about to enroll in Andrew Ngs machine learning course, but i'm hesitating whether or not to buy certificate for 49$. I mean i don't have that much money to spend 49$ for nothing, but if it really helps  than i don't want to miss the opportunity...
So should i buy it? In what way can certificate help me? Do employers care about it?",39,29
836,2016-5-27,2016,5,27,23,4lb2t0,"This Week in Machine Learning, 27 May 2016",https://www.reddit.com/r/MachineLearning/comments/4lb2t0/this_week_in_machine_learning_27_may_2016/,DavidAJoyner,1464360710,,0,0
837,2016-5-28,2016,5,28,0,4lb50u,The International Conference on Learning Representations (ICLR) 2016 talks are now on http://videolectures.net,https://www.reddit.com/r/MachineLearning/comments/4lb50u/the_international_conference_on_learning/,andyandy16,1464361465,,1,66
838,2016-5-28,2016,5,28,1,4lbfyg,any thoughts and experience with Google Cloud Platform?,https://www.reddit.com/r/MachineLearning/comments/4lbfyg/any_thoughts_and_experience_with_google_cloud/,[deleted],1464365286,[deleted],0,4
839,2016-5-28,2016,5,28,1,4lbkrh,Terrapattern is the first open-access visual search engine for satellite maps,https://www.reddit.com/r/MachineLearning/comments/4lbkrh/terrapattern_is_the_first_openaccess_visual/,FuckApathy,1464366958,,1,41
840,2016-5-28,2016,5,28,1,4lbm1u,"A proposal for a NIPS Workshop or Symposium on ""Mapping Machine Learning to Hardware""",https://www.reddit.com/r/MachineLearning/comments/4lbm1u/a_proposal_for_a_nips_workshop_or_symposium_on/,compsens,1464367405,,0,7
841,2016-5-28,2016,5,28,2,4lbq9l,Binary classifier based on 2D profile/contour?,https://www.reddit.com/r/MachineLearning/comments/4lbq9l/binary_classifier_based_on_2d_profilecontour/,tefoodhaus,1464368887,"I have pictures of two types of objects that I'd like to make a classifier for. Their main difference is their shape. So I figured I could use openCV to get the contours for each image...but then what? How could I represent this in a way that I could feed into, say, an SVM? I thought about just feeding the raw pixels as an array but I'm worried that would actually learn is the location of the objects in the images (as opposed to their shape)",3,4
842,2016-5-28,2016,5,28,2,4lbque,I need ideas for analyzing a big database of phone calls,https://www.reddit.com/r/MachineLearning/comments/4lbque/i_need_ideas_for_analyzing_a_big_database_of/,giacuna,1464369079,"I have access to a big database of phone calls, with geolocation. I want to build something with economic value or find relationship between phone calls and socio-economic indicators. Any ideas?",4,2
843,2016-5-28,2016,5,28,2,4lbu88,Voxel-Based Variational Autoencoder Demonstration,https://www.reddit.com/r/MachineLearning/comments/4lbu88/voxelbased_variational_autoencoder_demonstration/,cuda_curious,1464370216,,27,80
844,2016-5-28,2016,5,28,2,4lbweq,"Why Threat Intelligence without Relevance Isn't Smart. Mark Seward, Security Solutions, Anomali",https://www.reddit.com/r/MachineLearning/comments/4lbweq/why_threat_intelligence_without_relevance_isnt/,cyberalien_,1464370964,,0,4
845,2016-5-28,2016,5,28,2,4lbwxx,Introducing our Hybrid lda2vec Algorithm,https://www.reddit.com/r/MachineLearning/comments/4lbwxx/introducing_our_hybrid_lda2vec_algorithm/,juxtaposicion,1464371139,,2,39
846,2016-5-28,2016,5,28,2,4lbyw6,Anyone know any good LSTM tutorials?,https://www.reddit.com/r/MachineLearning/comments/4lbyw6/anyone_know_any_good_lstm_tutorials/,ScarletEgret,1464371824,"I'm trying to find a good way to write a program that can play text adventures/interactive fiction, and actually understand the world, creating a model of the world on its own. I[ found a paper](http://arxiv.org/pdf/1506.08941) that sounds like it accomplishes exactly what I am trying to do. However, it makes use of Long/Short-Term Memory networks, or LSTMs, and I am having trouble understanding how they make use of these, and how they work in general.

I think I understand the basics of how both Feed-Forward and Recurrent neural networks work, and how they are trained using backpropagation, but I don't understand how LSTMs function or are trained compared to these others. I know the idea is that they add input, output, and forget gates in order to control what specific things the network remembers under certain circumstances, and in order to make sure backpropagation won't make the network forget what it learns from early experiences, but I don't understand what controls the gates. Does backpropagation change the bahavior of the gates at the same time as the memory network? Are there different gates controlling each individual neuron in the memory network? How does input affect what the gates do, once the network has been trained?

Does any of my question even make sense, or am I even more lost than I think I am?",4,6
847,2016-5-28,2016,5,28,2,4lbzat,is there anything in Andrew Ng's course that I would miss after doing the U of W course?,https://www.reddit.com/r/MachineLearning/comments/4lbzat/is_there_anything_in_andrew_ngs_course_that_i/,wrcwill,1464371966,"I'm about to do the specialization, and was wondering if there is anything I should check out in Andrew's course afterwards.

thanks!",6,4
848,2016-5-28,2016,5,28,3,4lbzgr,A Short Overview of Model-Fitting Methods in Machine Learning  Closed-Form vs. Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/4lbzgr/a_short_overview_of_modelfitting_methods_in/,sbt_,1464372016,,0,14
849,2016-5-28,2016,5,28,3,4lbzl8,How should I handle a lot of missing values in survey data composed of roughly 10k individual responses over 120 some odd questions?,https://www.reddit.com/r/MachineLearning/comments/4lbzl8/how_should_i_handle_a_lot_of_missing_values_in/,wgpubs,1464372058,"I'm new to ML (just so you know where I'm at).

Interested in applying ML to vast amounts of survey data in order to find correlations and make predictions (e.g., how a surveyed department's overall satisfaction is likely to fair 1, 3, 5 years out, or if this department improves on X questions, they are likely to see a bump of Y% in overall satisfaction next year, etc....).

Most surveys have a lot of questions (&gt; 100) and a lot of responses (&gt; 8k) ... and responses are not required to answer all questions and so there is a lot of missing values in the .csv file I'm looking at.  My question is:  How should I handle this?

I've read about imputation and while I'm certain I can't just delete rows with missing values, I'm not sure if I can just use the mean/median or even how that should be calculated.  Ideally, I'd like to keep them in there and just ignore them ... but I'm not sure if that is an option.

The format of the csv looks like this:

SurveyYear | ResponseId | ResponseStatus | Qst1 | Qst2 | Qst3| ... | Qst120 

Again, most users will only answer a handful of questions that are related, for example, to just the departments they interact with.  Thus, for many ""QstX"" columns, the value will be blank.",21,6
850,2016-5-28,2016,5,28,3,4lc3qm,Euclidean distance between word vectors in HIGHER DIM ie 500 AND 1000 DIM,https://www.reddit.com/r/MachineLearning/comments/4lc3qm/euclidean_distance_between_word_vectors_in_higher/,vishwani_gupta,1464373558,"I have word vectors from word2vec model in 500 dim and 1000dim 
I am computing euclidean distance between some example vectors in 500 and 1000 dim.
My prob is I have read papers about curse of dimensionality. BUt here the results are quite similar for both dimensions.
I computed euclidean distance between 1000 dim vectors.
distance beween girl and boy
18.1915241847
cosine btw girl and boy
0.785652955784
l1 distance beween girl and boy
18.1915241847
distance between girl and neither
35.549272401
cosine btw girl and neither
-0.0117403359958
distance between boy and neither
34.5523976193
cosine btw boy and neither
-0.0129663966118
distance between girl and charger
28.65625576
cosine btw girl and charger
0.119322070804
distance between either and neither
25.1379275604
cosine btw either and neither
0.357230346462



In 500 dim it is:
distance between girl and boy
13.9897543378
cosine btw girl and boy
0.864196148736
l1 distance between girl and boy
13.9897543378
distance between girl and neither
35.1385895164
cosine btw girl and neither
-0.000815672156041
distance between boy and neither
34.1677078497
cosine btw boy and neither
0.00703764567668
distance between girl and charger
27.689731876
cosine btw girl and charger
0.113056294897
distance between either and neither
0.0
cosine btw either and neither
1.0
Can someone explain why is it so???
I am super confused
Is it related to sparcity",0,1
851,2016-5-28,2016,5,28,5,4lcolp,ML engineering ressources,https://www.reddit.com/r/MachineLearning/comments/4lcolp/ml_engineering_ressources/,Monninho,1464381211,"Hey guys

I'm almost finished with Andrew Ngs course now. But somehow, I don't feel ready to solve reallife problems yet.

Are there any ressources (additional courses, books, blogs) that are about a engineering, or more hands-on approach on ML?",2,0
852,2016-5-28,2016,5,28,5,4lcqr7,"Data Set Selection (LaLoudouana, 2003)",https://www.reddit.com/r/MachineLearning/comments/4lcqr7/data_set_selection_laloudouana_2003/,[deleted],1464382026,[deleted],0,0
853,2016-5-28,2016,5,28,7,4ld6f6,modelling followers and following from a twitter dataset,https://www.reddit.com/r/MachineLearning/comments/4ld6f6/modelling_followers_and_following_from_a_twitter/,peterquid,1464388217,"I am new to machine learning

I will like to know how one can create a model or use an existing one to find causalities for number of followers or number of following from a twitter dataset based on other aspects of the twitter data",0,0
854,2016-5-28,2016,5,28,7,4ld7pr,Where do I start?,https://www.reddit.com/r/MachineLearning/comments/4ld7pr/where_do_i_start/,mp09,1464388794,"Hey reddit. I want to build a classifier for detecting fraud in medicine prescriptions. I do not have previously classified data, having to rely on prescriptions alone. Where do I start? Anything you can throw at me to help is welcome.",4,0
855,2016-5-28,2016,5,28,10,4ldqlx,Financial Datasets,https://www.reddit.com/r/MachineLearning/comments/4ldqlx/financial_datasets/,trolltollboy,1464397264,"Is there a place where I can get financial datasets of company's financial reports in bulk in a machine readable format? Any help would be appreciated. Any help would be appreciated, thanks. ",11,10
856,2016-5-28,2016,5,28,11,4le4hn,Super Mario as a String: Platformer Level Generation Via LSTMs,https://www.reddit.com/r/MachineLearning/comments/4le4hn/super_mario_as_a_string_platformer_level/,nagasgura,1464403907,,0,5
857,2016-5-28,2016,5,28,16,4lexdd,FractalNet: Ultra-Deep Neural Networks without Residuals,https://www.reddit.com/r/MachineLearning/comments/4lexdd/fractalnet_ultradeep_neural_networks_without/,x2342,1464420912,,23,55
858,2016-5-28,2016,5,28,18,4lf8n1,"Naomi Saphra on Twitter: ""What idiot called it ""deep learning hype"" and not ""backpropaganda""""",https://www.reddit.com/r/MachineLearning/comments/4lf8n1/naomi_saphra_on_twitter_what_idiot_called_it_deep/,pmigdal,1464429152,,45,408
859,2016-5-28,2016,5,28,19,4lfayd,Morphing Faces - variational autoencoder,https://www.reddit.com/r/MachineLearning/comments/4lfayd/morphing_faces_variational_autoencoder/,pmigdal,1464430922,,1,5
860,2016-5-28,2016,5,28,19,4lfc80,Design Data Pipeline in Hadoop (using Hive and Pig),https://www.reddit.com/r/MachineLearning/comments/4lfc80/design_data_pipeline_in_hadoop_using_hive_and_pig/,andalib_ansari,1464431853,[removed],0,1
861,2016-5-28,2016,5,28,20,4lfjjg,Question about Multivariate Mutual Information,https://www.reddit.com/r/MachineLearning/comments/4lfjjg/question_about_multivariate_mutual_information/,Kiuhnm,1464436783,"Since I keep seeing very superficial crash courses on Information Theory and very few people will find the time to learn Information Theory properly, I thought I would write something more through with a good balance between intuition (65%) and rigor (35%). (I'll post it here when it's ready!)

During my exploration (I'm 100% self-taught) I came across the concept of *multivariate mutual information* (MMU). The MMU for three variables is

    I(X;Y;Z)=I(X;Z)+I(Y;Z)-I(X,Y;Z).

Note that some authors call it *interaction* and change the sign of the expression where there are an odd number of variables.

The problem with MMU as defined above is that it can be negative!

Why don't we use something simpler and more interpretable instead? If mutual information between X and Y is just

    KL(p(x,y)||p(x)p(y)) = H(X)+H(Y)-H(X,Y),

why don't we define MMU as

    KL(p(x,y,z)||p(x)p(y)p(z)) = H(X)+H(Y)+H(Z)-H(X,Y,Z),

which is always non negative, as it should?

From a set theoretic point of view, this corresponds to ""counting"" overlaps between 2 variables *once* and overlaps between three variables *twice*, which doesn't seem undesirable to me: [diagram](http://s33.postimg.org/rjcwsba33/venn2.png).

Any comments? I'm out of my depth here...

---

#Edit
I also asked on /r/math and it seems that there are many definitions and no definition is better than the others. I guess any community has its own version of the *no free lunch* theorem. In particular, the one I proposed above is called *total correlation*.",2,4
862,2016-5-28,2016,5,28,21,4lfntv,Is the #hashtag Twitter's and Facebook's way to get users to label their data?,https://www.reddit.com/r/MachineLearning/comments/4lfntv/is_the_hashtag_twitters_and_facebooks_way_to_get/,xristos_forokolomvos,1464439333,"Come to think about it, it's like combining some social media trend with what is convenient for their ML engineers.",2,0
863,2016-5-28,2016,5,28,22,4lfvza,A good learning path for someone new to machine learning,https://www.reddit.com/r/MachineLearning/comments/4lfvza/a_good_learning_path_for_someone_new_to_machine/,hyperqube12,1464443591,"I'm just getting started with neural networks and machine learning. Currently, I'm going through this gentle introduction : [neuralnetworksanddeeplearning.com.](http://neuralnetworksanddeeplearning.com/chap1.html) 
What good books would you recommend after this (preferably something to go with Python and scikit-learn and Theano) ? ",5,0
864,2016-5-29,2016,5,29,1,4lgecr,What the regression equivalent of MNIST?,https://www.reddit.com/r/MachineLearning/comments/4lgecr/what_the_regression_equivalent_of_mnist/,[deleted],1464451989,[deleted],0,1
865,2016-5-29,2016,5,29,1,4lgejq,What dataset is the equivalent of MNIST for regression?,https://www.reddit.com/r/MachineLearning/comments/4lgejq/what_dataset_is_the_equivalent_of_mnist_for/,jostmey,1464452077,"What dataset if any is widely used for regression type problems (continuous value for the label, as opposed to discrete)? Is there such a dataset that serves as a standard?

Thanks",5,6
866,2016-5-29,2016,5,29,2,4lgm61,What ML techniques would be most applicable to network attack identification?,https://www.reddit.com/r/MachineLearning/comments/4lgm61/what_ml_techniques_would_be_most_applicable_to/,shuklaswag,1464455319,"Suppose I am trying to build a model that receives logs from some large cloud network system, either in realtime or periodically. 
What techniques would be most applicable in this situation? I imagine clustering would be useful to identify ""normal"" network traffic data as opposed to ""abnormal"" data - probably something like K-means? ",5,4
867,2016-5-29,2016,5,29,3,4lh0t3,Machine Learning Internships in UK/EU?,https://www.reddit.com/r/MachineLearning/comments/4lh0t3/machine_learning_internships_in_ukeu/,cvmlwe,1464461484,"I've noticed that there's been [a thread](https://www.reddit.com/r/MachineLearning/comments/2gmse3/best_companies_to_apply_for_machine_learning/) last year about this, and it had some success, so I dare to try to ask again -- anyone knows of any summer internships in UK (or EU) that are still looking to hire for machine learning positions?

I realise there's also https://www.reddit.com/r/MLjobs but it has 99 subscribers and 2 posts, so I thought I could try my luck here.",8,3
868,2016-5-29,2016,5,29,5,4lhgcd,Great Article on How to Feature Scaling,https://www.reddit.com/r/MachineLearning/comments/4lhgcd/great_article_on_how_to_feature_scaling/,drcrook,1464468037,,2,1
869,2016-5-29,2016,5,29,7,4lhrfj,FP16 performance on GTX 1080 is artificially limited to 1/64th the FP32 rate,https://www.reddit.com/r/MachineLearning/comments/4lhrfj/fp16_performance_on_gtx_1080_is_artificially/,[deleted],1464472931,[deleted],47,100
870,2016-5-29,2016,5,29,9,4li7yx,Vector Calculus,https://www.reddit.com/r/MachineLearning/comments/4li7yx/vector_calculus/,chaser999,1464480243,"I am having a lot of problem when differentiating equations involving vectors. Can you provide some links(book/website) from which can I get what is actually going on. Here I am referring to the case 
(i) when we do dy/dx and x is a vector y is a scalar
(II) when we do dy/dx and y is a vector",9,5
871,2016-5-29,2016,5,29,9,4liazy,"Really simple question about what we mean by ""Two-Layer Network""",https://www.reddit.com/r/MachineLearning/comments/4liazy/really_simple_question_about_what_we_mean_by/,[deleted],1464481669,[deleted],2,0
872,2016-5-29,2016,5,29,10,4lik23,Convolution autoencoder in Keras,https://www.reddit.com/r/MachineLearning/comments/4lik23/convolution_autoencoder_in_keras/,planaria123,1464486082,"
Hi All,

I've been experimenting with autoencoders for reconstructing input images.  Had good success with MNIST digits.  Now wanting to try CIFAR10 images.

Below is the network I've coded up. 

In this network below, I've experimented with:
* number of filters (64, 32, 16, 8)
* weight initialization for the Conv layers.
* activation functions in the decoding layers.
* overall depth of the network.
* Sometimes I get nan's for loss.  More recently, this example below returns negative values for loss and has a great deal of trouble converging to anything (accuracies are only about 0.003! after 100 epochs and loss is large negative value).

Some other details:
* Training set is only 100 images
* Running on my Macbook pro (El Capitan)
* Theano backend
* Using cpu (not gpu)
* Keras 1.0.3
* Theano 0.8.2
* .theanorc:
 [global]
floatX=float64  (I've tried both float32 and float64)
device=cpu
optimizer=fast_run  (fast_compile tends to create NANs)
mode=FAST_RUN
exception_verbosity=high

```sh
input_img = Input(shape=(3, 32, 32))

#Encoding layers
x = Convolution2D(16, 3, 3, input_shape=(3, 32, 32), activation='relu', border_mode='same')(input_img)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
x = MaxPooling2D((2, 2), border_mode='same')(x)

#Decoding layers
x = Convolution2D(8, 3, 3, activation='sigmoid', border_mode='same')(x)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(8, 3, 3, activation='sigmoid', border_mode='same')(x)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(16, 3, 3, activation='sigmoid', border_mode='same')(x)
x = UpSampling2D((2, 2))(x)
decoded = Convolution2D(3, 3, 3, activation='sigmoid', border_mode='same')(x)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
adam = Adam()
autoencoder.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])
```


Here is my fitting and the first 2 epochs:
```sh
autoencoder.fit(x_train, x_train, nb_epoch=2,  batch_size=20, #128, shuffle=True, verbose=1,  validation_data=(x_test, x_test))

Train on 100 samples, validate on 20 samples
Epoch 1/2 loss: -10.1022 - acc: 0.0515 - val_loss: -49.2346 - val_acc: 0.0464
Epoch 2/2 loss: -67.9034 - acc: 0.0470 - val_loss: -111.7369 - val_acc: 0.0464
```


The fitting moves very little from what you see above (even after a few hundred epochs).  Also, the negative loss values (based on log loss) trouble me since I believe the value should be &gt; 0.

Finally, visualizing what the network predicts shows blank images.  

Any suggestions would be most appreciated!

Thanks in advance,
Mark
",0,0
873,2016-5-29,2016,5,29,11,4liqck,ML for economic planning?,https://www.reddit.com/r/MachineLearning/comments/4liqck/ml_for_economic_planning/,[deleted],1464489186,[deleted],4,0
874,2016-5-29,2016,5,29,13,4lj7lq,Question about Batch Normalization,https://www.reddit.com/r/MachineLearning/comments/4lj7lq/question_about_batch_normalization/,cb_hanson,1464497988,"I'm training a deep network and am experimenting with using batch normalization. From reading the Ioffe and Szegedy paper, it seems that it's a solution for the saturation problem experienced by activation functions like the sigmoid.

My question is does using batch normalization make sense for Rectified Linear Units (ReLUs), which already are one solution to the saturation problem? I seem to be getting slightly better results using batch normalization with ReLUs, but wanted to understand if combining the two makes sense conceptually and whether other researchers have used them together.",8,4
875,2016-5-29,2016,5,29,14,4ljbmh,Slides - TensorFlow Tutorial,https://www.reddit.com/r/MachineLearning/comments/4ljbmh/slides_tensorflow_tutorial/,[deleted],1464500423,[deleted],0,0
876,2016-5-29,2016,5,29,15,4ljejn,Slides - TensorFlow Tutorial with Examples,https://www.reddit.com/r/MachineLearning/comments/4ljejn/slides_tensorflow_tutorial_with_examples/,terryum,1464502187,,0,3
877,2016-5-29,2016,5,29,19,4ljyvw,Deep learning Image Classification on Pascal Voc Dataset using Caffe,https://www.reddit.com/r/MachineLearning/comments/4ljyvw/deep_learning_image_classification_on_pascal_voc/,mustafaihssan,1464517664,,11,37
878,2016-5-29,2016,5,29,21,4lk9r0,AlphaGo vs. Lee Sedol -- the AI match of the 21st century: post-match reactions and price giving,https://www.reddit.com/r/MachineLearning/comments/4lk9r0/alphago_vs_lee_sedol_the_ai_match_of_the_21st/,DeepLearningBob,1464525273,,1,0
879,2016-5-30,2016,5,30,1,4ll0vn,"Formulation of Adversarial ML: Fraud, Security, AML",https://www.reddit.com/r/MachineLearning/comments/4ll0vn/formulation_of_adversarial_ml_fraud_security_aml/,arshakn,1464538709,,0,0
880,2016-5-30,2016,5,30,1,4ll1n2,Best ML Libraries/Cards for Workstation/Hobbyist,https://www.reddit.com/r/MachineLearning/comments/4ll1n2/best_ml_librariescards_for_workstationhobbyist/,Tiramisuu2,1464539004,"I'm building a hobbyiest workstation for ML and data mining: dual 8 core e5 2670's, 128 GB, couple of the Xeon Phi mic cards.

Obviously cuda based libraries would require me to sell the intel cards and buy gpu's so where does that leave me for mature open source ML libraries?

Card wise Budget is limited so cheap cards that will work is a critical part of the equation.  Please don't bother saying buy 4-8 Titan X's, 1080's gtx 980 ti's etc.  I'm willing to consider swapping cards in the $200 range but other than the 7970 haven't seen a potentially better value than the Xeon Phi's.

",16,1
881,2016-5-30,2016,5,30,2,4ll9bu,[ICML2016] Ask a Workshop Anything: Deep Learning Workshop Session 1,https://www.reddit.com/r/MachineLearning/comments/4ll9bu/icml2016_ask_a_workshop_anything_deep_learning/,[deleted],1464541991,[deleted],0,1
882,2016-5-30,2016,5,30,2,4lla16,[ICML2016] Ask a Workshop Anything: Deep Learning Workshop Session 1: The Small Data Regime,https://www.reddit.com/r/MachineLearning/comments/4lla16/icml2016_ask_a_workshop_anything_deep_learning/,olaf_nij,1464542280,"I'm very excited to announce /r/MachineLearning is trying a new AMA format in collaboration with the organizers of the [Deep Learning Workshop at ICML 2016](https://sites.google.com/site/dlworkshop16/): 

In this years ICML Deep Learning Workshop, we depart from previous years formats and experiment with a completely new format. The workshop will be split into two sessions, each consisting of a set of invited talks followed by a panel discussion. By organizing the workshop in this manner we aim to promote focused discussions that dive deep into important areas and also increase interaction between speakers and the audience. 

**The first (morning) session of the workshop aims at answering the question What is deep learning in the small data regime?** Under this broad theme, more specific questions may include Does unsupervised learning have a central role in this?, What else is essential when dealing with high sample complexity but low resource? and even more radical ones such as Should deep learning be replaced with an alternative in the small data regime?

We will have the following world-renowned experts in this session:

* Harri Valpola, Curious AI Company
* Leon Bottou, Facebook AI
* Joelle Pineau, McGill University
* Nina Balcan, CMU
* Anima Anandkumar, UC Irvine

In order to maximize the outreach of the workshop, we would like to ask your participation! We will collect your questions, comments and discussions prior to the workshop, share them with our invited speakers and ask them to consider your thoughts in preparing their talks as well as the panel discussion. In contrast to our previous AMAs, responses to your questions will be answered with presentations by our experts and shared online.

Post your questions for **Session 1** here, we'll be collecting questions until June 15.",25,90
883,2016-5-30,2016,5,30,2,4llakh,[ICML2016] Ask a Workshop Anything: Deep Learning Workshop Session 2: Simulation-based Learning,https://www.reddit.com/r/MachineLearning/comments/4llakh/icml2016_ask_a_workshop_anything_deep_learning/,olaf_nij,1464542488,"I'm very excited to announce /r/MachineLearning is trying a new AMA format in collaboration with the organizers of the [Deep Learning Workshop at ICML 2016](https://sites.google.com/site/dlworkshop16/):

In this years ICML Deep Learning Workshop, we depart from previous years formats and experiment with a completely new format. The workshop will be split into two sessions, each consisting of a set of invited talks followed by a panel discussion. By organizing the workshop in this manner we aim to promote focused discussions that dive deep into important areas and also increase interaction between speakers and the audience. 

**The second (afternoon) session of the workshop aims at answering the question ""What does simulation-based learning bring to the table?""** Under this broad theme, more specific questions may include How transferrable is the knowledge learned from a simulation to the real world?"", ""Are simulated environments the way to achieve machine intelligence?"" and ""How important is it for agents to simulate the world in their minds? Even more radical ones will also be discussed, such as Does simulation-based learning have anything to do in making progress toward artificial intelligence?

We will have the following world-renowned experts in this session:

* Raia Hadsell, Google DeepMind
* Pieter Abbeel, UC Berkeley &amp; OpenAI
* Gary Marcus, NYU &amp; Geometric Intelligence
* Marco Baroni, University of Trento
* Sanja Fidler, University of Toronto

In order to maximize the outreach of the workshop, we would like to ask your participation! We will collect your questions, comments and discussions prior to the workshop, share them with our invited speakers and ask them to consider your thoughts in preparing their talks as well as the panel discussion. In contrast to our previous AMAs, responses to your questions will be answered with presentations by our experts and shared online.

Post your questions for **Session 2** here, we'll be collecting questions until June 15.",21,42
884,2016-5-30,2016,5,30,4,4lltpk,Questions on experience in getting your work published,https://www.reddit.com/r/MachineLearning/comments/4lltpk/questions_on_experience_in_getting_your_work/,EdwardRaff,1464550037,"I'm sure some of you recognize me as that annoying jerk face who won't shut his face about Java and ML, but if I haven't worn out my welcome I was hoping to get some people's feedback on getting stuff published. 

Some general questions I'd love to get other people's opinions / thoughts on:

* How do you deal with reviewers being overly negative about your work? Both in terms of a response and not letting it ruin your weekend

* If you've ever done a transition: how do you go about learning where to potentially publish? I have a lot of experience reading Machine Learning papers, which helped me get an idea about the various venues. I'm now doing research in applying Machine Learning to malware. Maybe KDD or JMLR would be *ok* for a really good paper on application, but I'm feeling daunted on learning about the venues for my new sub-discipline. When I read ML stuff on my own there was no time constraint, but now that I'm preparing stuff to submit I'm feeling a bit intimidated. 

* Workshops / Conferences / Journals. I've gotten some mixed feedback on this one. One of my coworkers talked about how his advisors plan was: get initial results, submit to workshop. Improve results, submit follow up to conference. Finish the work and make it conclusive, submit to journal. My advisor is a bit happy go lucky about it. If it's long, submit to a journal, if it's short, to a conference - and workshops just kinda whenever?  Do you tend to write work with the thought in mind that ""I'm going to submit this to a journal / conference""? 

* Working to specific venues: Do people tend to start work with a particular destination in mind? My gut reaction was to do the work and find it a home when done, and adjust the details of what I discuss toward the interests of the venue. Though it seems some have a preference to start work with a destination in mind and adjust their experiments / work toward what that destination likes. 

* Industry conferences? My situation is a little odd since I'm doing my PhD part time while working full time. I'm sure my work would love something submitted to Strata as a talk, but does that have any bearing on my PhD? Would submitting a talk to something that's really higher level like that impede submitting finished work to a conference/journal? 

",14,13
885,2016-5-30,2016,5,30,8,4lmt1t,"Advice greatly appreciated , don't even know where to start",https://www.reddit.com/r/MachineLearning/comments/4lmt1t/advice_greatly_appreciated_dont_even_know_where/,[deleted],1464564330,[deleted],5,3
886,2016-5-30,2016,5,30,9,4lmyy8,Basics of Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/4lmyy8/basics_of_gradient_descent/,drcrook,1464566882,,0,1
887,2016-5-30,2016,5,30,9,4ln0iv,How circuses contributed to Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/4ln0iv/how_circuses_contributed_to_artificial/,Aicial,1464567638,,0,1
888,2016-5-30,2016,5,30,9,4ln2rh,Opinions on implementing dropout in RNN/LSTMs?,https://www.reddit.com/r/MachineLearning/comments/4ln2rh/opinions_on_implementing_dropout_in_rnnlstms/,IndividualCarnival,1464568657,"I'm getting some practice with RNN and LSTMs right now, and honestly I'm a little afraid of overfitting; It just feels a lot harder to avoid with these models over CNNs or vanilla NNs. I'm thinking of adding some dropout, but I'm having some trouble figuring out how and where:

For now I'm working with one hidden layer since I don't expect my data to be bigger than perhaps 1.5 MBs of characters. I'm just looking for some opinions on where dropout should be implemented Please correct me if I'm approaching dropout improperly with RNN/LSTMs.

My preliminary basic idea was to add dropout on the hidden states (maybe @ 0.5 to safely begin with? I can cross validate the HP likely), leaving the LSTM cell states as is. This dropout would be applied after solving for next hidden state (given the previous hidden and cell state), so effectively at each timestep. Is that a reasonable appoach for dropout or should I put the dropout layer in a lower level of the next state calculation?

Any advice would be really appreciated! Thanks",4,0
889,2016-5-30,2016,5,30,11,4lniga,"""Weight Sharing"" in non-NN algorithms?",https://www.reddit.com/r/MachineLearning/comments/4lniga/weight_sharing_in_nonnn_algorithms/,hazard02,1464575724,Weight sharing is of course a key technique in neural networks. Are there any non-NN machine learning that have something that's analogous? ,5,0
890,2016-5-30,2016,5,30,12,4lnnj6,Build an AI Artist - Machine Learning for Hackers #5,https://www.reddit.com/r/MachineLearning/comments/4lnnj6/build_an_ai_artist_machine_learning_for_hackers_5/,[deleted],1464577941,[deleted],0,3
891,2016-5-30,2016,5,30,13,4lo09i,CUDA 8 RC Available!,https://www.reddit.com/r/MachineLearning/comments/4lo09i/cuda_8_rc_available/,malleus17,1464584005,,7,6
892,2016-5-30,2016,5,30,14,4lo2cv,sklearn-evaluation - The cool kids way to evaluate scikit-learn models,https://www.reddit.com/r/MachineLearning/comments/4lo2cv/sklearnevaluation_the_cool_kids_way_to_evaluate/,edublancas,1464585092,,2,1
893,2016-5-30,2016,5,30,14,4lo4f5,DARPA seeks mathematical framework to characterize fundamental limits of learning,https://www.reddit.com/r/MachineLearning/comments/4lo4f5/darpa_seeks_mathematical_framework_to/,Buck-Nasty,1464586131,,21,94
894,2016-5-30,2016,5,30,16,4loe1o,How crazy is this plan?,https://www.reddit.com/r/MachineLearning/comments/4loe1o/how_crazy_is_this_plan/,nmaxcom,1464591816,"So here's the deal, bear with me.

I have access to a **humongous amounts** of (safely anonymized) medical data with plenty of variables that I'd love to process and, as expected, try to draw conclusions, patterns and all that good stuff. Not only is the sheer amount of patients that gets this scary (I could always use a smaller set) but the amount of variables that are registered. Tiny relationships that I really want to know how much of an influence each of them have and in what ways.

I'm not trying to be the man of the year, I know this is not a novel idea at all, that plenty of really smart people is working on this etc. I just think it'd be really fun to fiddle with this and a great motivation to learn ML, big data... It's a ""*I have no idea but let's totally not sleep and do this thing*"" kind of plan. I love those, right?

I'm good at CS and programming in general, decent at math and lately more close to JavaScript but I could get back some C# or even C++. I own a relatively powerful setup (not pro or lab-grade), usually work on Mac but either Linux or Windows are fine too.

Now please help me out here and change those responsible ""*you're an idiot, start small, this is too big*"" answers and go along with the thread. I've been wanting to dive into this like a maniac for a long time and finally I have enough time in my hands.

I've googled a bit and so far I see two roads:

1. **The hard way:** use AWS machine service or similar like Google's tensorflow etc. Learn it, fight with the API, cry, and see how far can I get.
2. **The $%""&amp; harder way**: learn R or F#, current libraries, the whole freaking science, ninja math... And cry even more and see how far can I get.

As you can see I'm all ears. Experienced people, noobs... What do we have? How can I go about doing this? Is #2 even a possibility? If I can get the results I want with #1 I'll be happy and will put off #2 for next time.

Thank you people!",23,1
895,2016-5-30,2016,5,30,16,4logvj,PE Pipe Extrusion Line,https://www.reddit.com/r/MachineLearning/comments/4logvj/pe_pipe_extrusion_line/,Ritagao,1464593502,,1,0
896,2016-5-30,2016,5,30,16,4lojmx,Why NLL of RNN locally increase with Adam optimizer?,https://www.reddit.com/r/MachineLearning/comments/4lojmx/why_nll_of_rnn_locally_increase_with_adam/,gmkim90,1464595194,"Hi !
I use adam optimizer (provided in torch7 optim package) to train Hierarchical RNN (architecture similar with https://arxiv.org/pdf/1507.04808.pdf)  for tasks similar with language model  (Adam paper: https://arxiv.org/pdf/1412.6980.pdf)

However, training loss (i.e. negative log-likelihood) locally increase (for few epochs). Since each epoch process many data (2813 minibatches), cause should not be stochasticity.

I observed learned weight have sparse large weight value. (i.e. +- 13~15) And I conjecture this is due to the term used in denominator in final update vector. If this value is so small in some dimension, this can produce very high weight value in some dimension (i.e. divide by zero error). This thread can be prevented by adding small constant (epsilon = 1e-8) to denominator, but I think default epsilon value is not large enough to prevent numerical unstability.

Anyone suffer from locally increase of loss with adam optimizer?  Anyone who can share how to tune the parameter of optimizer?",0,0
897,2016-5-30,2016,5,30,17,4lol13,What is the benefit of adamax over adam?,https://www.reddit.com/r/MachineLearning/comments/4lol13/what_is_the_benefit_of_adamax_over_adam/,gmkim90,1464596012,"Hi !
I wonder what is the benefit of adamax over adam.
(See paper: https://arxiv.org/pdf/1412.6980.pdf)

In paper, Adamax is introduced as special case of adam where its seconod-order moment v0 is replaced by infinite-order moment.

What is the benefit of using infinite-order moment instead of second moment in optimization?
",2,9
898,2016-5-30,2016,5,30,17,4lomv1,Dimensionality Reduction Intuitions: Why we take Eigenvectors of the Similarity Matrix?,https://www.reddit.com/r/MachineLearning/comments/4lomv1/dimensionality_reduction_intuitions_why_we_take/,Mirber,1464597212,,6,16
899,2016-5-30,2016,5,30,18,4lor8m,Looking for some NLP algorithm that can give a semantic distance between 2 sentences,https://www.reddit.com/r/MachineLearning/comments/4lor8m/looking_for_some_nlp_algorithm_that_can_give_a/,deepaurorasky,1464600043,"Does there exist an algorithm that can give one a ""semantic distance"" between 2 sentences/paragraphs? I'm a beginner to NLP, but I've studied neural networks in detail in the past however I'm getting lost in all the latest NLP + NN literature.

In a simpler case of calculating the semantic distance between 2 words, would word2vec be suitable? My gut feelings (I'm still working through word2vec literature) says that although skipgram and CBOW are used for prediction, some part would be suitable enough to give me a vector representation of each word - from which I can then calculate some distance measure. 

If word2vec results in a vector rep of a word, then my gut feelings once again tell me that paragraph2vec might be suitable for my semantic distance between sentences.

I read somewhere in the word2vec Tensorflow docs about paragraph2vec however my brief reading suggests the results were not reproducible. Anyone have experience with paragraph2vec? Is it even suitable? Still going to delve into the literature properly over the next day but figured I'd throw the question this way in case anyone can stop me wasting time down the wrong paths.

I also feel like I might be missing the necessary NLP technical terms to search for the algorithm I am looking for. Sorry for being an NLP noob! Any guidance would be appreciated",6,5
900,2016-5-30,2016,5,30,18,4lorgb,"Does anyone have solutions to the coursera course ""Machine Learning Foundations: A Case Study Approach"" (University of Washtington)",https://www.reddit.com/r/MachineLearning/comments/4lorgb/does_anyone_have_solutions_to_the_coursera_course/,mathemagicianus,1464600183,[removed],0,0
901,2016-5-30,2016,5,30,19,4lozli,Incorporating Nesterov Momentum into Adam,https://www.reddit.com/r/MachineLearning/comments/4lozli/incorporating_nesterov_momentum_into_adam/,larseidnes,1464605175,,5,9
902,2016-5-30,2016,5,30,19,4lp0db,Secretive startup Magic Leap says its working on AI for robotics,https://www.reddit.com/r/MachineLearning/comments/4lp0db/secretive_startup_magic_leap_says_its_working_on/,thejamgroup,1464605657,,1,1
903,2016-5-30,2016,5,30,20,4lp1dw,"Mixture Density Networks with Edward, Keras and TensorFlow.",https://www.reddit.com/r/MachineLearning/comments/4lp1dw/mixture_density_networks_with_edward_keras_and/,pl47,1464606250,,0,9
904,2016-5-30,2016,5,30,20,4lp4m1,The water storage tanks,https://www.reddit.com/r/MachineLearning/comments/4lp4m1/the_water_storage_tanks/,mixmachinery,1464608071,,1,1
905,2016-5-30,2016,5,30,21,4lp9oi,"AI that will steal our jobs - Collection of models for source code generation, verification, and source code understanding.",https://www.reddit.com/r/MachineLearning/comments/4lp9oi/ai_that_will_steal_our_jobs_collection_of_models/,[deleted],1464610751,[deleted],0,0
906,2016-5-30,2016,5,30,23,4lppj2,Native implementation of neural network using numpy. (good for beginners),https://www.reddit.com/r/MachineLearning/comments/4lppj2/native_implementation_of_neural_network_using/,[deleted],1464617864,[deleted],0,0
907,2016-5-30,2016,5,30,23,4lpw1c,How to start working on social networks?,https://www.reddit.com/r/MachineLearning/comments/4lpw1c/how_to_start_working_on_social_networks/,davoodm93,1464620375,"Hello,
I want to work on influence maximization, how can I start? 
Thanks",0,0
908,2016-5-31,2016,5,31,0,4lpzb8,Flappy Bird Bot - Q-Learning AI,https://www.reddit.com/r/MachineLearning/comments/4lpzb8/flappy_bird_bot_qlearning_ai/,ccmlacc,1464621538,,32,170
909,2016-5-31,2016,5,31,0,4lq00i,[1605.08535] Deep API Learning,https://www.reddit.com/r/MachineLearning/comments/4lq00i/160508535_deep_api_learning/,RushAndAPush,1464621786,,0,17
910,2016-5-31,2016,5,31,0,4lq0qb,An ANN-based computer vision application that solves algebraic expressions,https://www.reddit.com/r/MachineLearning/comments/4lq0qb/an_annbased_computer_vision_application_that/,rhiever,1464622049,,2,28
911,2016-5-31,2016,5,31,0,4lq0wz,New TensorFlow paper: [1605.08695] A system for large-scale machine learning,https://www.reddit.com/r/MachineLearning/comments/4lq0wz/new_tensorflow_paper_160508695_a_system_for/,andyandy16,1464622113,,6,18
912,2016-5-31,2016,5,31,1,4lq701,"Yann LeCun's letter to CVPR chair after bad reviews on a Vision System that ""learnt"" features &amp; reviews",https://www.reddit.com/r/MachineLearning/comments/4lq701/yann_lecuns_letter_to_cvpr_chair_after_bad/,metacurse,1464624268,,20,38
913,2016-5-31,2016,5,31,2,4lqld0,How do you keep track of where your ideas come from?,https://www.reddit.com/r/MachineLearning/comments/4lqld0/how_do_you_keep_track_of_where_your_ideas_come/,omniron,1464629293,"For people who do published research, when writing a publication, how do you remember all the papers you read that inspired your research?

I end up reading a lot of abstracts and papers that lead to avenues of thinking and investigation, when it comes time to write anything up, I can't fathom being able to remember all the papers that were the inspiration. ",9,9
914,2016-5-31,2016,5,31,2,4lqohd,"Data Science &amp; Machine Learning Encyclopedia - 4,000 Entries",https://www.reddit.com/r/MachineLearning/comments/4lqohd/data_science_machine_learning_encyclopedia_4000/,abdsc,1464630365,,0,1
915,2016-5-31,2016,5,31,2,4lqqpy,Porting a model from Theano to TensorFlow,https://www.reddit.com/r/MachineLearning/comments/4lqqpy/porting_a_model_from_theano_to_tensorflow/,acornalert,1464631164,,0,4
916,2016-5-31,2016,5,31,3,4lqrdb,Topic Models with Expanding Topics (Beyond LDA),https://www.reddit.com/r/MachineLearning/comments/4lqrdb/topic_models_with_expanding_topics_beyond_lda/,aleph__one,1464631396,"Wondering what anyone is doing wrt topic models that have a potentially ever-increasing number of topics? Namely, what methods have you tried to automatically create new topics to an already-running system?

Quite familiar with LDA and related methods, and I'm wondering if anyone has remarks on more recent approaches. With LDA you of course are stuck with a fixed number of 'topics'. Flipboard seems to have solved this rather nicely, and I've always been curious what they did (or rather what Zite did).",4,3
917,2016-5-31,2016,5,31,3,4lqx1t,A Survey of Deep Learning Techniques Applied to Trading,https://www.reddit.com/r/MachineLearning/comments/4lqx1t/a_survey_of_deep_learning_techniques_applied_to/,gfh1,1464633393,,10,10
918,2016-5-31,2016,5,31,3,4lqzet,Call for papers: Special session on Machine Learning for Autonomous Driving at ITSC 2016,https://www.reddit.com/r/MachineLearning/comments/4lqzet/call_for_papers_special_session_on_machine/,ysenthilece,1464634199,,0,0
919,2016-5-31,2016,5,31,4,4lr6su,Machine Learning for Scientific Datasets,https://www.reddit.com/r/MachineLearning/comments/4lr6su/machine_learning_for_scientific_datasets/,rbharath,1464636774,,1,5
920,2016-5-31,2016,5,31,4,4lra9i,What does it mean to maximally activate a convolutional layer?,https://www.reddit.com/r/MachineLearning/comments/4lra9i/what_does_it_mean_to_maximally_activate_a/,WilliamWallace,1464637982,"Say I have a batch of 16 48x48x3 images, and I convolve over this with a filter of [3,3,3,64] (3x3 perceptive field, 3 in put channel, 64 output channel) and a stride of [1,1,1,1]. With SAME padding, my result is going to have dimensions [16, 48, 48, 64]. From this, how would I decide which of the 16 is maximally activating each of the 64 filter maps?",0,0
921,2016-5-31,2016,5,31,5,4lre6q,Every awesome project I have seen this year is in Torch. Then why is TensorFlow getting so much buzz? Can someone please explain?,https://www.reddit.com/r/MachineLearning/comments/4lre6q/every_awesome_project_i_have_seen_this_year_is_in/,[deleted],1464639402,[deleted],5,0
922,2016-5-31,2016,5,31,9,4lsgn0,Would it be worth buying the ML certificate at Coursera?,https://www.reddit.com/r/MachineLearning/comments/4lsgn0/would_it_be_worth_buying_the_ml_certificate_at/,[deleted],1464654017,[deleted],5,0
923,2016-5-31,2016,5,31,9,4lsk9q,[1605.08478] Model-Free Imitation Learning with Policy Optimization,https://www.reddit.com/r/MachineLearning/comments/4lsk9q/160508478_modelfree_imitation_learning_with/,johnschulman,1464655468,,3,12
924,2016-5-31,2016,5,31,9,4lslbe,PhD in Biomedical/Clinical Informatics with Machine Learning skills,https://www.reddit.com/r/MachineLearning/comments/4lslbe/phd_in_biomedicalclinical_informatics_with/,kt_bme,1464655884,"Can anyone please guide me through process of transitioning from a developer and DBA in Microsoft Technology stack with 7 years of exp. I have a biomedical bachelors and comp. science Masters. However, there seems to be a hug gap in landing an admission into PhD program. What are steps to be tsken so that what I work during 9-5 would help me build my resume strong for Phd. I have been thinking applied ML jobs wit potential employers to sponsor Phd would be possible option but its all wild goose chase. PLease advise.",0,0
925,2016-5-31,2016,5,31,9,4lslgw,Keras question: How do you use the advanced activations in the functional API?,https://www.reddit.com/r/MachineLearning/comments/4lslgw/keras_question_how_do_you_use_the_advanced/,cb_hanson,1464655940,"In the examples, they show how the basic activations (relu, sigmoid, linear, etc) can be specified as follows:

x = Dense(64, activation='relu')(x)

x = Dense(64, activation='relu')(x)

x = Dense(64, activation='relu')(x)

to create a stack of relu's. How do you use one of the advanced activations such as PReLUs with the functional API? I haven't been able to find an example that shows this.",6,0
926,2016-5-31,2016,5,31,10,4lsr7l,CS courses for ML,https://www.reddit.com/r/MachineLearning/comments/4lsr7l/cs_courses_for_ml/,whoisthriller,1464658248,"Hi guys, I'm considering to do a master of computer science, I want to do machine learning, could you give your opnions towards courses below:

1.Microprocessors and Interfacing(ISA, interrupts and I/O interfacing, serial communication, timers etc, prerequisite to operating system )

2.Digital Circuits and Systems (more EE stuff, can it be useful to CS/ML?)

3.Distributed Systems

4.Computer Architecture(pipelined RISC machines,memory subsystem, I/O, and system level interconnect)

5.Theory of Computation(Turing Machines, computability, Complexity: run time, space, too theoretical?)

6.Design &amp; Analysis of Algorithms

7.Advanced and Parallel Algorithms (Spatial, semi-structured and multi-dimensional data storage and manipulation techniques, non Von-Neumann techniques, advanced and parallel algorithmic techniques, can it useful for ML?)

8.Parameterized and Exact Computation( NP-hard problems, branching, colour coding, iterative compression, and kernelization)

9.Artificial Intelligence (not relevant to ML?too theoretical?)

10.Knowledge Representation and Reasoning(AI Logics, Probablilistic Reasoning, Constraints)

(11). Information Retrieval and Web Search

Thank you very much

",4,0
927,2016-5-31,2016,5,31,11,4lt2k3,Build an AI Artist - ML for Hackers #5,https://www.reddit.com/r/MachineLearning/comments/4lt2k3/build_an_ai_artist_ml_for_hackers_5/,llSourcell,1464662906,,15,5
928,2016-5-31,2016,5,31,13,4ltd9d,"Do we need to average gradient if their weights are shared in several different data? (e.g. RNN, CNN)",https://www.reddit.com/r/MachineLearning/comments/4ltd9d/do_we_need_to_average_gradient_if_their_weights/,gmkim90,1464667352,"Hi all 
As I stated in title, do we need to scale gradient if their weights are shared in several different data?

For example, suppose RNN Language model learn sentences with different length. Assume that loss function is sum of negative log-likelihood of total words in dataset. Weights of RNN are shared (or unfolded) across words in each sentence. Each shared weights produce gradient when error is back-propagate through time.

My question is, do we need to average each gradient produced by shared weights? (If we consider RNN process different length sequence at every time, this is not just simply issue of learning rate scailing.)

Also, for CNN, assume it is used for processing sequence data (or we can call it Time-delay neural network). Similarly, each shared weights produce its own gradient. Do we need to average them?",1,0
929,2016-5-31,2016,5,31,14,4ltriq,Causal Neural Paradox,https://www.reddit.com/r/MachineLearning/comments/4ltriq/causal_neural_paradox/,unibrain,1464674108,[removed],0,1
930,2016-5-31,2016,5,31,15,4ltsoe,"[1605.09128] Control of Memory, Active Perception, and Action in Minecraft",https://www.reddit.com/r/MachineLearning/comments/4ltsoe/160509128_control_of_memory_active_perception_and/,InaneMembrane,1464674732,,4,22
931,2016-5-31,2016,5,31,15,4ltu9o,Recipe ingredients tagger using CRF,https://www.reddit.com/r/MachineLearning/comments/4ltu9o/recipe_ingredients_tagger_using_crf/,[deleted],1464675543,[deleted],0,0
932,2016-5-31,2016,5,31,15,4ltvvc,Some interesting applications of machine learning in different fields,https://www.reddit.com/r/MachineLearning/comments/4ltvvc/some_interesting_applications_of_machine_learning/,datameer,1464676381,,0,1
933,2016-5-31,2016,5,31,15,4ltw3c,PP Helix Hose (for Toilet) Machine,https://www.reddit.com/r/MachineLearning/comments/4ltw3c/pp_helix_hose_for_toilet_machine/,Ritagao,1464676503,,0,0
934,2016-5-31,2016,5,31,15,4ltwkx,Call for paper: The 14th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2016),https://www.reddit.com/r/MachineLearning/comments/4ltwkx/call_for_paper_the_14th_pacific_rim_international/,PRICAI2016,1464676760,"------------------------------------
Call for PRICAI 2016 Workshop Papers
------------------------------------
Published in a series of LNCS/LNAI as post-proceedings

http://aiat.in.th/pricai2016workshop/


The Workshops in 14th Pacific Rim International Conference on Artificial Intelligence (PRICAI-WORKSHOP 2016)
August 22-26, 2016,
Phuket, Thailand

http://aiat.in.th/pricai2016workshop/

Six workshops in PRICAI 2016 are listed below.

PeHealth 2016: Workshop on eHealth Mining
I3A 2016: Workshop on Image, Information, and Intelligent Applications
AIED 2016: Workshop on Artificial Intelligence for Educational Applications
AI4T 2016: Workshop on Artificial Intelligence for Tourism
IWEC 2016: 7th International Workshop on Empathic Computing)
RSAI 2016: Research Student Symposium on the Artificial Intelligence and Applications

---------------
Paper Submission
---------------
The following steps show how to submit a paper for reviewing.
1. Login to system as an author. ( If you don't have an account yet, please register. )
2. Click 'Submit a New Paper' and complete the form.

---------------
Important Dates
---------------
June 03, 2016           Paper Submission
June 17, 2016           Acceptance Notification
June 24, 2016           Early Registration
June 24, 2016           Camera-Ready Submission
August 2226, 2016      Conference Period


-------------------------------------",0,0
935,2016-5-31,2016,5,31,15,4ltylh,Let's learn about high shear dispersing mixer,https://www.reddit.com/r/MachineLearning/comments/4ltylh/lets_learn_about_high_shear_dispersing_mixer/,mixmachinery,1464677817,,1,1
936,2016-5-31,2016,5,31,16,4ltyzm,[1605.07427] Hierarchical Memory Networks,https://www.reddit.com/r/MachineLearning/comments/4ltyzm/160507427_hierarchical_memory_networks/,downtownslim,1464678027,,5,19
937,2016-5-31,2016,5,31,18,4lufsj,To what extent is NMF dependent on the distribution of data it is supplied?,https://www.reddit.com/r/MachineLearning/comments/4lufsj/to_what_extent_is_nmf_dependent_on_the/,IWantMyReshi,1464687856,"I am wondering if anyone is aware on the effect that using NMF on data which is distributed in different ways, for example a dataset demonstrating beta-divergence, or a normal distribution.",3,1
938,2016-5-31,2016,5,31,18,4lugg5,Questions about machine learning,https://www.reddit.com/r/MachineLearning/comments/4lugg5/questions_about_machine_learning/,insider_7,1464688237,"Why do we need the last layer #nodes = #classes? 
Why softmax classifier for multiclass and sigmoid for binary classification?
What is the difference between multiclass and one vs all?
How to define dense neurons before the softmax classifier?
On what depends how many dense networks do we need before the softmax layer in a Convolutional Neural Network?
Are loss and accuracy complementary to each other?
What is the effect of the batch size in the training procedure?
Are larger batch sizes better if we can afford it?",7,0
939,2016-5-31,2016,5,31,19,4lul0x,Question About Random Searching,https://www.reddit.com/r/MachineLearning/comments/4lul0x/question_about_random_searching/,MaxOLG,1464690817,"Hi there! I'm an AI student, and I'm currently experiencing some difficulties with random search terminology.

In my studies, I have encountered the definition of ""random sampling"" as sampling ""several random points in the feasible region."" This is also the same definition given to a purely-random search.

Further down, the definition for a random search is changed into something resembling more a random walk. This method described is as picking an initial candidate, and randomly moving to a neighbor, keeping track of the best solution.

So, my question is; which definition of random searching is more widely-accepted? Thanks!

PS I can't really provide the sources of my definitions as they are my course notes, sorry!",1,0
940,2016-5-31,2016,5,31,20,4lupgk,"Could someone tell me what is ""Absolute Relevance"" and ""Relative Relevance"" is, in relation to text analysis?",https://www.reddit.com/r/MachineLearning/comments/4lupgk/could_someone_tell_me_what_is_absolute_relevance/,[deleted],1464693191,[deleted],0,0
941,2016-5-31,2016,5,31,21,4luzl1,Ask ML : how much data do I need for my classification task?,https://www.reddit.com/r/MachineLearning/comments/4luzl1/ask_ml_how_much_data_do_i_need_for_my/,vijucat,1464698116,"Given a number of columns and rows in my data, is it enough for my classification (or regression) task, or do I have to collect more? How much data do I need in order to give the modeling method a decent chance at achieving a good fit? Does this depend on the modeling method being used (lasso vs. boosted trees using xgboost, for example)?

Also, does it depend on how much is p &gt;&gt; n?

I found this : ""The Model Complexity Myth"" (https://jakevdp.github.io/blog/2015/07/06/model-complexity-myth/), which I am reading, but I was wondering if there are well-established academic results or practitioners' thumb rules in this space.

Thank you in advance!",9,0
942,2016-5-31,2016,5,31,22,4lvbcl,Introducing our Hybrid lda2vec Algorithm,https://www.reddit.com/r/MachineLearning/comments/4lvbcl/introducing_our_hybrid_lda2vec_algorithm/,cavedave,1464702979,,1,58
943,2016-5-31,2016,5,31,23,4lvc9m,[1605.08803] Density estimation using Real NVP,https://www.reddit.com/r/MachineLearning/comments/4lvc9m/160508803_density_estimation_using_real_nvp/,sidsig,1464703333,,15,20
