,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-8-1,2018,8,1,10,93kp87,Trained DQN to play pikachu volleyball,https://www.reddit.com/r/MachineLearning/comments/93kp87/trained_dqn_to_play_pikachu_volleyball/,lyusungwon,1533088408,[removed],0,1
1,2018-8-1,2018,8,1,10,93kqqd,Ubuntu 16.04 or 18.04 for newbie getting into machine learning?,https://www.reddit.com/r/MachineLearning/comments/93kqqd/ubuntu_1604_or_1804_for_newbie_getting_into/,michael-chiang-mc5,1533088760,[removed],0,1
2,2018-8-1,2018,8,1,11,93krv5,[P] Trained DQN to play Pikachu Volleyball!,https://www.reddit.com/r/MachineLearning/comments/93krv5/p_trained_dqn_to_play_pikachu_volleyball/,lyusungwon,1533089009,"Hi! I trained DQN to play my favorite game pikachu volleyball as a sub-project. I trained upto 21 days with a single GPU. I just uploaded a video on youtube and I'd really appreciate your feedback. Thank you.

[https://www.youtube.com/watch?v=vSkLegIUD98](https://www.youtube.com/watch?v=vSkLegIUD98)",23,35
3,2018-8-1,2018,8,1,11,93l5i7,[P] torchsummaryX: Improved visualization tool of torchsummary,https://www.reddit.com/r/MachineLearning/comments/93l5i7/p_torchsummaryx_improved_visualization_tool_of/,nmhkahn,1533092161,,0,1
4,2018-8-1,2018,8,1,12,93lbyq,"[R] "" The Devil of Face Recognition is in the Noise"", Wang et al 2018 {Sensetime} [severe label noise in face datasets; cleaning reduces sample need to 1/5th size]",https://www.reddit.com/r/MachineLearning/comments/93lbyq/r_the_devil_of_face_recognition_is_in_the_noise/,gwern,1533093682,,19,52
5,2018-8-1,2018,8,1,13,93lwsn,An article describing how you can use uncertainty estimates to interpret your models.,https://www.reddit.com/r/MachineLearning/comments/93lwsn/an_article_describing_how_you_can_use_uncertainty/,yoelzeldes,1533098716,,0,1
6,2018-8-1,2018,8,1,14,93m2xc,[N] New Release of Google Compute Engine DeepLearning Images. Now with PyTorch 0.4.1 + CUDA 9.2,https://www.reddit.com/r/MachineLearning/comments/93m2xc/n_new_release_of_google_compute_engine/,b0noi,1533100376,,0,41
7,2018-8-1,2018,8,1,14,93m6cs,[R] Faster Convergence &amp; Generalization in DNNs,https://www.reddit.com/r/MachineLearning/comments/93m6cs/r_faster_convergence_generalization_in_dnns/,HigherTopoi,1533101333,,29,24
8,2018-8-1,2018,8,1,14,93mbnj,[R] Count-Based Exploration with the Successor Representation,https://www.reddit.com/r/MachineLearning/comments/93mbnj/r_countbased_exploration_with_the_successor/,HigherTopoi,1533102781,,1,21
9,2018-8-1,2018,8,1,17,93n1bu,'The discourse is unhinged': how the media gets AI alarmingly wrong | Technology | The Guardian,https://www.reddit.com/r/MachineLearning/comments/93n1bu/the_discourse_is_unhinged_how_the_media_gets_ai/,RidgeRegressor,1533110523,,0,1
10,2018-8-1,2018,8,1,17,93n7eh,How to use LSTM Net for text generation?,https://www.reddit.com/r/MachineLearning/comments/93n7eh/how_to_use_lstm_net_for_text_generation/,blake_sanie,1533112555,[removed],0,1
11,2018-8-1,2018,8,1,17,93nad7,"Join our global free demo session of our online Python Machine Learning Training on August 9, 2018.",https://www.reddit.com/r/MachineLearning/comments/93nad7/join_our_global_free_demo_session_of_our_online/,MCAL_Training,1533113583,,0,1
12,2018-8-1,2018,8,1,17,93nafh,Weird accuracy improvement by multiple small epochs training,https://www.reddit.com/r/MachineLearning/comments/93nafh/weird_accuracy_improvement_by_multiple_small/,secsilm,1533113604,[removed],0,1
13,2018-8-1,2018,8,1,18,93nczq,"Speech recognition algos used in Alexa, Siri, Google Assistant, Cortana",https://www.reddit.com/r/MachineLearning/comments/93nczq/speech_recognition_algos_used_in_alexa_siri/,bookroom77,1533114453,[removed],0,1
14,2018-8-1,2018,8,1,18,93njss,How innovative manufacturers can make use of AR in the age of smart manufacturing [Webinar],https://www.reddit.com/r/MachineLearning/comments/93njss/how_innovative_manufacturers_can_make_use_of_ar/,sam-Ideas2IT,1533116569,,0,1
15,2018-8-1,2018,8,1,19,93nn0e,"Understanding paper ""NORMALIZED DIRECTION-PRESERVING ADAM"".",https://www.reddit.com/r/MachineLearning/comments/93nn0e/understanding_paper_normalized/,tanisha_bhayani,1533117654,"I am reading the following paper: ""NORMALIZED DIRECTION-PRESERVING ADAM"", and I am trying to understand this particular paragraph: ""First, in some scenarios, DNNs trained with Adam generalize worse than that trained with stochastic gradient descent (SGD) (Wilson et al., 2017). Zhang et al. (2017) demonstrate that overparameterized DNNs are capable of memorizing the entire dataset, no matter if it is natural data or meaningless noise data, and thus suggest much of the generalization power of DNNs comes from the training algorithm, e.g., SGD and its variants. It coincides with another recent work (Wilson et al., 2017), which shows that simple SGD often yields better generalization performance than adaptive gradient methods, such as Adam. As pointed out by the latter, the difference in the generalization performance may result from the different directions of updates. Specifically, for each hidden unit, the SGD update of its input weight vector can only lie in the span of all possible input vectors, which, however, is not the case for Adam due to the individually adapted learning rates. We refer to this problem as the direction missing problem.""

Any help would be appreciated.",0,1
16,2018-8-1,2018,8,1,19,93nqqf,[P] Punctuation Restoration With Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/93nqqf/p_punctuation_restoration_with_recurrent_neural/,sataky,1533118770,,3,24
17,2018-8-1,2018,8,1,19,93nrh2,How machine reorganise floor-plans!,https://www.reddit.com/r/MachineLearning/comments/93nrh2/how_machine_reorganise_floorplans/,hugoric,1533119000,,0,1
18,2018-8-1,2018,8,1,19,93nuk7,[R] All-Optical Machine Learning Using Diffractive Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/93nuk7/r_alloptical_machine_learning_using_diffractive/,hooba_stank_,1533119970,"Paper:

https://arxiv.org/abs/1804.08711


Paywalled Science article:

http://science.sciencemag.org/content/early/2018/07/25/science.aat8084

Techcrunch article:

https://techcrunch.com/2018/07/26/this-3d-printed-ai-construct-analyzes-by-bending-light/
",84,46
19,2018-8-1,2018,8,1,20,93oars,"Understanding Titanic Dataset with H2Os AutoML, DALEX, and lares library",https://www.reddit.com/r/MachineLearning/comments/93oars/understanding_titanic_dataset_with_h2os_automl/,klo99,1533124533,,0,1
20,2018-8-1,2018,8,1,23,93p7dh,Startups: How to progressively build your product to incorporate machine learning....,https://www.reddit.com/r/MachineLearning/comments/93p7dh/startups_how_to_progressively_build_your_product/,R47billion,1533132080,,0,1
21,2018-8-1,2018,8,1,23,93phys,Can GANs be perceived as Metaheuristic algorithms?,https://www.reddit.com/r/MachineLearning/comments/93phys/can_gans_be_perceived_as_metaheuristic_algorithms/,MrTroll420,1533134183,[removed],0,1
22,2018-8-1,2018,8,1,23,93pk8j,A New Device Can Hear Your Thoughts  Future Human,https://www.reddit.com/r/MachineLearning/comments/93pk8j/a_new_device_can_hear_your_thoughts_future_human/,Lition_io,1533134610,,0,1
23,2018-8-1,2018,8,1,23,93poq2,"How to predict when I will run out of inventory given past order history, inventory, and ""stock outs""?",https://www.reddit.com/r/MachineLearning/comments/93poq2/how_to_predict_when_i_will_run_out_of_inventory/,k_j0,1533135507,[removed],0,1
24,2018-8-2,2018,8,2,0,93pqjx,"Demo, Code, and Blog Post for an in-browser neural net capable of beating humans at Rock Paper Scissors (keras, tensorflow.js)",https://www.reddit.com/r/MachineLearning/comments/93pqjx/demo_code_and_blog_post_for_an_inbrowser_neural/,Tenoke,1533135856,,0,1
25,2018-8-2,2018,8,2,0,93pvy5,Stochastic gradient descent diverging,https://www.reddit.com/r/MachineLearning/comments/93pvy5/stochastic_gradient_descent_diverging/,bluesky314,1533136863,[removed],0,1
26,2018-8-2,2018,8,2,0,93q4ja,How to correct selection bias,https://www.reddit.com/r/MachineLearning/comments/93q4ja/how_to_correct_selection_bias/,akelleh,1533138498,,0,1
27,2018-8-2,2018,8,2,0,93q6wp,"Simple Questions Thread August 01, 2018",https://www.reddit.com/r/MachineLearning/comments/93q6wp/simple_questions_thread_august_01_2018/,AutoModerator,1533138938,[removed],0,1
28,2018-8-2,2018,8,2,1,93qg1v,2018 Fields Medal and Nevanlinna Prize Winners,https://www.reddit.com/r/MachineLearning/comments/93qg1v/2018_fields_medal_and_nevanlinna_prize_winners/,banksyb00mb00m,1533140611,,0,1
29,2018-8-2,2018,8,2,1,93qio6,Meeting new people,https://www.reddit.com/r/MachineLearning/comments/93qio6/meeting_new_people/,Nekruz,1533141099,[removed],0,1
30,2018-8-2,2018,8,2,1,93qml1,Top 20 Amazing Machine Learning Tools To Try Right Now,https://www.reddit.com/r/MachineLearning/comments/93qml1/top_20_amazing_machine_learning_tools_to_try/,mlcrunch,1533141810,,0,1
31,2018-8-2,2018,8,2,1,93qnsx,New connections,https://www.reddit.com/r/MachineLearning/comments/93qnsx/new_connections/,Nekruz,1533142025,[removed],0,1
32,2018-8-2,2018,8,2,1,93qpws,[R] AlphaGo Zero implementation and discussion blog post,https://www.reddit.com/r/MachineLearning/comments/93qpws/r_alphago_zero_implementation_and_discussion_blog/,_sulo,1533142421,,20,213
33,2018-8-2,2018,8,2,2,93qv5s,"If ML is easy, will it ever get harder?",https://www.reddit.com/r/MachineLearning/comments/93qv5s/if_ml_is_easy_will_it_ever_get_harder/,Royalty1702,1533143345,"I'm starting to get into Machine Learning and, according to many people online, ML is very easy to learn, which disappoints me in a way because I was hoping that it was actually going to be challenging field. So, I was wondering that if ML is so easy for people, will it ever get harder as time goes on?",0,1
34,2018-8-2,2018,8,2,2,93r2me,[N] Tencent ML Team Trains ImageNet In Record Four Minutes,https://www.reddit.com/r/MachineLearning/comments/93r2me/n_tencent_ml_team_trains_imagenet_in_record_four/,trcytony,1533144667,,0,1
35,2018-8-2,2018,8,2,4,93s2ly,Model building with random forest,https://www.reddit.com/r/MachineLearning/comments/93s2ly/model_building_with_random_forest/,rishisaireddy,1533151265,[removed],0,1
36,2018-8-2,2018,8,2,4,93s9bm,[D] Deploying a machine learning model to the cloud using AWS Lambda - Dr. Benjamin Weigel,https://www.reddit.com/r/MachineLearning/comments/93s9bm/d_deploying_a_machine_learning_model_to_the_cloud/,_quanttrader_,1533152506,,0,1
37,2018-8-2,2018,8,2,4,93sbhn,[P] We built an Autonomous beach cleaning robot using ML,https://www.reddit.com/r/MachineLearning/comments/93sbhn/p_we_built_an_autonomous_beach_cleaning_robot/,sritee,1533152910,,1,1
38,2018-8-2,2018,8,2,4,93seko,which machine learning algorithm to use to sort IDs ???,https://www.reddit.com/r/MachineLearning/comments/93seko/which_machine_learning_algorithm_to_use_to_sort/,diptamh,1533153502,I have 6 columns of data and one of the column is Id. Each Id corresponds to 5 datas. which type of neural network algorithm can i use to sort the Ids depending on the data. I need to sort the Id in such a way that the most favorable Id will have the best combination of  datas.,0,1
39,2018-8-2,2018,8,2,4,93sep8,[R] Reinforcement Learning Summer School (RLSS 2017) notes,https://www.reddit.com/r/MachineLearning/comments/93sep8/r_reinforcement_learning_summer_school_rlss_2017/,y0b1byte,1533153521,,0,1
40,2018-8-2,2018,8,2,5,93skd3,Most active application area?,https://www.reddit.com/r/MachineLearning/comments/93skd3/most_active_application_area/,DirkMai,1533154552,"Hi All, what is the most active and promising area of ML applications?  Thank you Dirk",0,1
41,2018-8-2,2018,8,2,6,93t75s,"[D] Building vocab including train, valid and test data",https://www.reddit.com/r/MachineLearning/comments/93t75s/d_building_vocab_including_train_valid_and_test/,CorrectRent,1533158793,"Is it faithful to build vocab for training using the train, valid and test data? I have seen some implementations doing it.  They use it with pre-trained embedding.",14,1
42,2018-8-2,2018,8,2,6,93tfii,"[P] Real-Time Fraud Detection with LightGBM, Flask, Websockets and a visualization in javascript",https://www.reddit.com/r/MachineLearning/comments/93tfii/p_realtime_fraud_detection_with_lightgbm_flask/,hoaphumanoid,1533160444,,0,1
43,2018-8-2,2018,8,2,7,93tw2n,A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence (1955) (PDF),https://www.reddit.com/r/MachineLearning/comments/93tw2n/a_proposal_for_the_dartmouth_summer_research/,wei_jok,1533163862,,9,40
44,2018-8-2,2018,8,2,8,93u8bt,What happened to Modular Neural Networks? Does anyone have more reading regarding this topic?,https://www.reddit.com/r/MachineLearning/comments/93u8bt/what_happened_to_modular_neural_networks_does/,harshsikka123,1533166540,[removed],0,1
45,2018-8-2,2018,8,2,9,93ufpb,[P] Credit Card Fraud / Anomaly Detection with Keras,https://www.reddit.com/r/MachineLearning/comments/93ufpb/p_credit_card_fraud_anomaly_detection_with_keras/,sophuslie_,1533168219,"Hi,

I'm working on a personal project for fun and was going to test out different models for this Kaggle competition: [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud).

I built two models, one in pure Tensorflow (for practice with NN architecture) and one in Keras just to familiarize myself with it more. However, I seem to run into the same sort of problems. Here's a link for my Keras one: [Keras CC Fraud Detection](https://github.com/stochasticats/credit-card-fraud-detection/blob/master/Untitled.ipynb).

I tend to get a very high accuracy very quickly, 1 epoch. After I evaluated the model on my test sets, I then ran some tests just to see how it's working, so I separated my test set into one with all fraud and the other will all the normal transactions, yet all three scores are exactly the same. The other odd thing is that the percent of transactions that are fraudulent is \~0.17%, while the accuracy score is  99.9369306237%, which adds to slightly above 100%. To me this is quite dubious and makes me think there is something deeply wrong.

My initial thoughts are that since fraudulent transactions are such a tiny subset of the overall set, it's basically just labelling everything as a normal and this will still give a high accuracy!

What's the best way to deal with this sort of problem? I would also like to ask for some tips in general with neural networks and how my overall process is? You can check out the data exploration and tensorflow build here: [link](https://github.com/stochasticats/credit-card-fraud-detection/blob/master/Data%20Analysis%20and%20Prediction%20of%20Credit%20Card%20Fraud.ipynb)",18,44
46,2018-8-2,2018,8,2,9,93uhp7,Learning Math for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/93uhp7/learning_math_for_machine_learning/,krtcl,1533168689,,0,1
47,2018-8-2,2018,8,2,9,93uka6,TTS-Cube: An open-source end-2-end speech synthesis system,https://www.reddit.com/r/MachineLearning/comments/93uka6/ttscube_an_opensource_end2end_speech_synthesis/,Rick_grin,1533169264,"The website has some pretty good audio samples available. These are not in English, and I believe these might be in Romanian given the author's Nationality, (feel free to correct me if I am wrong). The site also links to the Github page for anyone interested.",0,1
48,2018-8-2,2018,8,2,12,93vrc0,NLP's ImageNet moment has arrived - Sebastian Ruder,https://www.reddit.com/r/MachineLearning/comments/93vrc0/nlps_imagenet_moment_has_arrived_sebastian_ruder/,edutainment123,1533180070,,1,1
49,2018-8-2,2018,8,2,12,93vu9e,Free JupyterLab instances with 1080Ti,https://www.reddit.com/r/MachineLearning/comments/93vu9e/free_jupyterlab_instances_with_1080ti/,whitezl0,1533180820,[removed],0,1
50,2018-8-2,2018,8,2,13,93w1ey,Is LSTM faster than SVM?,https://www.reddit.com/r/MachineLearning/comments/93w1ey/is_lstm_faster_than_svm/,Kshikhar9,1533182674,[removed],0,1
51,2018-8-2,2018,8,2,14,93wm4n,A Beginners Guide to AI/ML  Machine Learning for Humans,https://www.reddit.com/r/MachineLearning/comments/93wm4n/a_beginners_guide_to_aiml_machine_learning_for/,jvipin,1533188369,,0,1
52,2018-8-2,2018,8,2,14,93wnun,"Weapons of Math Destruction, Ethical Matrix, Nate Silver and more Highlights from the Data Science Leaders Summit",https://www.reddit.com/r/MachineLearning/comments/93wnun/weapons_of_math_destruction_ethical_matrix_nate/,jitendra_mudhol,1533188874,,0,1
53,2018-8-2,2018,8,2,15,93wtjf,[R] Effective Parallel Corpus Mining using Bilingual Sentence Embeddings,https://www.reddit.com/r/MachineLearning/comments/93wtjf/r_effective_parallel_corpus_mining_using/,danielcer,1533190609,,1,16
54,2018-8-2,2018,8,2,15,93wubo,Joint Call For Papers Law x Technology: Transforming the face of the Law,https://www.reddit.com/r/MachineLearning/comments/93wubo/joint_call_for_papers_law_x_technology/,Cknight_M,1533190860,[removed],0,1
55,2018-8-2,2018,8,2,16,93x2zr,"Multiple Outputs (Tensorflow, Python)",https://www.reddit.com/r/MachineLearning/comments/93x2zr/multiple_outputs_tensorflow_python/,LarsHProbst,1533193570,[removed],1,1
56,2018-8-2,2018,8,2,17,93xdih,Stopping GAN Violence: Generative Unadversarial Networks,https://www.reddit.com/r/MachineLearning/comments/93xdih/stopping_gan_violence_generative_unadversarial/,xiangwangzhe,1533196955,,41,141
57,2018-8-2,2018,8,2,18,93xo9n,TTS-Cube: A new open-source end-2-end speech synthesis system,https://www.reddit.com/r/MachineLearning/comments/93xo9n/ttscube_a_new_opensource_end2end_speech_synthesis/,[deleted],1533200668,[deleted],0,1
58,2018-8-2,2018,8,2,18,93xrsm,Dynamic Bayesian Networks,https://www.reddit.com/r/MachineLearning/comments/93xrsm/dynamic_bayesian_networks/,bulba-sore,1533201796,[removed],0,1
59,2018-8-2,2018,8,2,18,93xy41,[P] Video tutorial: Build an A2C agent that learns to play Sonic with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/93xy41/p_video_tutorial_build_an_a2c_agent_that_learns/,cranthir_,1533203853,[removed],0,1
60,2018-8-2,2018,8,2,19,93y2z9,[P] Jupyter notebook on how to detect binary black holes using constitutional neural networks,https://www.reddit.com/r/MachineLearning/comments/93y2z9/p_jupyter_notebook_on_how_to_detect_binary_black/,rebels40,1533205349,[removed],0,1
61,2018-8-2,2018,8,2,19,93y3yp,[Survey] $50 worth Cloud Credits + Results of the survey will be shared with the participants,https://www.reddit.com/r/MachineLearning/comments/93y3yp/survey_50_worth_cloud_credits_results_of_the/,HolyGrail619,1533205656,,0,1
62,2018-8-2,2018,8,2,20,93ye82,"People Ask Me, What Do You Have Against Deep Learning?",https://www.reddit.com/r/MachineLearning/comments/93ye82/people_ask_me_what_do_you_have_against_deep/,alsouphuxley,1533208673,,0,1
63,2018-8-2,2018,8,2,20,93yglv,Program Induction and Synthesis on ICML 2018,https://www.reddit.com/r/MachineLearning/comments/93yglv/program_induction_and_synthesis_on_icml_2018/,gfrison,1533209385,,0,1
64,2018-8-2,2018,8,2,21,93yrj9,Data Science School - Practical deep learning course syllabus,https://www.reddit.com/r/MachineLearning/comments/93yrj9/data_science_school_practical_deep_learning/,viktoriia_shulga,1533212251,,1,1
65,2018-8-2,2018,8,2,21,93ysr3,Begginner for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/93ysr3/begginner_for_machine_learning/,DvynshChan_17,1533212560,[removed],0,1
66,2018-8-2,2018,8,2,21,93ywmf,Laptop to get started in machine learning,https://www.reddit.com/r/MachineLearning/comments/93ywmf/laptop_to_get_started_in_machine_learning/,gorillagamez,1533213489,[removed],0,1
67,2018-8-2,2018,8,2,21,93yz5b,ICML 2018 recap,https://www.reddit.com/r/MachineLearning/comments/93yz5b/icml_2018_recap/,zhebrak,1533214114,,0,1
68,2018-8-2,2018,8,2,21,93yzs4,Top 10 Data Science Use Cases in Retail,https://www.reddit.com/r/MachineLearning/comments/93yzs4/top_10_data_science_use_cases_in_retail/,viktoriia_shulga,1533214270,,0,9
69,2018-8-2,2018,8,2,22,93z3fi,[P]Reccrd - tool for ML practitioners/researchers to keep track of experiment results,https://www.reddit.com/r/MachineLearning/comments/93z3fi/preccrd_tool_for_ml_practitionersresearchers_to/,arxseven,1533215147,,4,4
70,2018-8-2,2018,8,2,22,93z4kf,Predicting World War 3 with data driven approach,https://www.reddit.com/r/MachineLearning/comments/93z4kf/predicting_world_war_3_with_data_driven_approach/,aryancodify,1533215384,[removed],0,1
71,2018-8-2,2018,8,2,22,93z74l,Isolation forest anomaly visualisation,https://www.reddit.com/r/MachineLearning/comments/93z74l/isolation_forest_anomaly_visualisation/,SoberZorba,1533215936,[removed],0,1
72,2018-8-2,2018,8,2,22,93zdls,"Question about Graph Attention Layers (Velickovic et al, ICLR 2018)",https://www.reddit.com/r/MachineLearning/comments/93zdls/question_about_graph_attention_layers_velickovic/,rbool,1533217393,[removed],0,1
73,2018-8-2,2018,8,2,23,93zit9,SaaS company seeks ML partner,https://www.reddit.com/r/MachineLearning/comments/93zit9/saas_company_seeks_ml_partner/,vbsql7,1533218535,[removed],0,1
74,2018-8-2,2018,8,2,23,93zqvf,[R] [1805.08522] Deep learning generalizes because the parameter-function map is biased towards simple functions,https://www.reddit.com/r/MachineLearning/comments/93zqvf/r_180508522_deep_learning_generalizes_because_the/,evc123,1533220169,,12,72
75,2018-8-2,2018,8,2,23,93zu30,Wikipedia2Vec: A tool for learning vector representations of words and entities from Wikipedia,https://www.reddit.com/r/MachineLearning/comments/93zu30/wikipedia2vec_a_tool_for_learning_vector/,ikuyamada,1533220838,,0,1
76,2018-8-3,2018,8,3,0,9408vh,[D] I made a list of shortcuts for learning Tensorflow. Any others I should add?,https://www.reddit.com/r/MachineLearning/comments/9408vh/d_i_made_a_list_of_shortcuts_for_learning/,milecrazy,1533223700,,22,304
77,2018-8-3,2018,8,3,0,940h2g,[R] Relational Deep Reinforcement learning discussion,https://www.reddit.com/r/MachineLearning/comments/940h2g/r_relational_deep_reinforcement_learning/,dusanix,1533225249,"Hello I'm trying to implement this paper(only one that beats BuildMarines map in SC2?) and would like to start a discussion with other folks who are interested!

Does anyone know what does this paragraph mean?

&gt;Actions are sampled using computed policy logits and embedded into a 16 dimensional vector. This embedding is used to condition shared features and generate logits for non-spatial arguments (Args) through independent linear combinations (one for each argument).

How exactly are linear combinations gathered from embedding and shared features?",12,5
78,2018-8-3,2018,8,3,1,940lfg,[D] Dynamic Bayesian Network,https://www.reddit.com/r/MachineLearning/comments/940lfg/d_dynamic_bayesian_network/,bulba-sore,1533226054,Has any one come across a python library for performing inference and learning in dynamic or temporal Bayesian networks?,2,5
79,2018-8-3,2018,8,3,1,940x15,[R] Can you train a neural network using SMT?,https://www.reddit.com/r/MachineLearning/comments/940x15/r_can_you_train_a_neural_network_using_smt/,mttd,1533228287,,6,20
80,2018-8-3,2018,8,3,2,941jhd,Is There a Voice Learning Program That Can Use Recordings?,https://www.reddit.com/r/MachineLearning/comments/941jhd/is_there_a_voice_learning_program_that_can_use/,Robo56,1533232347,[removed],0,1
81,2018-8-3,2018,8,3,3,94213c,Deep learning,https://www.reddit.com/r/MachineLearning/comments/94213c/deep_learning/,specialak,1533235667,[removed],0,1
82,2018-8-3,2018,8,3,4,94265a,Data Scientist Interviews Demystified,https://www.reddit.com/r/MachineLearning/comments/94265a/data_scientist_interviews_demystified/,DanClark-KDnuggets,1533236606,,0,1
83,2018-8-3,2018,8,3,4,9428e2,Pytorch implementation of WARP loss (for recommenders),https://www.reddit.com/r/MachineLearning/comments/9428e2/pytorch_implementation_of_warp_loss_for/,NegatioNZor,1533237016,,0,1
84,2018-8-3,2018,8,3,4,942aaw,SuperMicro SuperServers w 4pcs P100 Need Advice,https://www.reddit.com/r/MachineLearning/comments/942aaw/supermicro_superservers_w_4pcs_p100_need_advice/,MyMining,1533237364,[removed],0,1
85,2018-8-3,2018,8,3,4,942bnq,[P] PyTorch implementation of WARP loss (for recommenders),https://www.reddit.com/r/MachineLearning/comments/942bnq/p_pytorch_implementation_of_warp_loss_for/,NegatioNZor,1533237624,,0,1
86,2018-8-3,2018,8,3,4,942kht,Inside the Mind of a Human Artificial Intelligence with Professor Robin Hanson,https://www.reddit.com/r/MachineLearning/comments/942kht/inside_the_mind_of_a_human_artificial/,The_Syndicate_VC,1533239312,[removed],0,1
87,2018-8-3,2018,8,3,6,943c7y,"Shannon Fellowship: $100,000 fellowship for independent intelligence researchers",https://www.reddit.com/r/MachineLearning/comments/943c7y/shannon_fellowship_100000_fellowship_for/,shannonlabs,1533244570,,0,1
88,2018-8-3,2018,8,3,6,943lz4,"[project] Public Git Archive, the largest dataset of Git repositories in the world",https://www.reddit.com/r/MachineLearning/comments/943lz4/project_public_git_archive_the_largest_dataset_of/,vcoisne,1533246556,,0,1
89,2018-8-3,2018,8,3,7,9446iq,[D] Random Forest Classification Feature Importance with Categorical Features? (scikit-learn),https://www.reddit.com/r/MachineLearning/comments/9446iq/d_random_forest_classification_feature_importance/,Zawadscki,1533250750,"I ran a random forest with exclusively low-cardinality categorical features which meant I had to make plenty of dummy variables. After looking at the feature importance table that you obtain from the model, you get an importance for *each* dummy variable. This can be particularly difficult to interpret.

I was reading about this online and it looks like adding up the feature importance for each of the dummy variables is not advisable. Are there any approaches that can work to interpret the feature importance from the dummy variables together? 

How about any other ML classifiers where I can evaluate the importance of categorical features at prediction? ",10,6
90,2018-8-3,2018,8,3,8,9448p8,Helping computers perceive human emotions,https://www.reddit.com/r/MachineLearning/comments/9448p8/helping_computers_perceive_human_emotions/,Chipdoc,1533251190,,3,9
91,2018-8-3,2018,8,3,8,944e4r," ,    .",https://www.reddit.com/r/MachineLearning/comments/944e4r/_____/,lijun981405,1533252382,[removed],0,1
92,2018-8-3,2018,8,3,8,944ksa,Examining Gender and Race Bias in Sentiment Analysis Systems,https://www.reddit.com/r/MachineLearning/comments/944ksa/examining_gender_and_race_bias_in_sentiment/,omarsar,1533253845,,0,1
93,2018-8-3,2018,8,3,10,9459h4,What are your views and opinions on the Golem Project?,https://www.reddit.com/r/MachineLearning/comments/9459h4/what_are_your_views_and_opinions_on_the_golem/,billium28,1533259513,,1,1
94,2018-8-3,2018,8,3,12,9467a6,How are review highlights in Google Play generated?,https://www.reddit.com/r/MachineLearning/comments/9467a6/how_are_review_highlights_in_google_play_generated/,hack777,1533267455,,0,1
95,2018-8-3,2018,8,3,14,946v0k,[D] Loss function for deep learning based edge detection?,https://www.reddit.com/r/MachineLearning/comments/946v0k/d_loss_function_for_deep_learning_based_edge/,Dark_Daiver,1533273664,"First of all I'm sorry for my poor English.

I'm trying to find edges of the specific object. Unfortunately i cannot solve this problem by semantic segmentation because i need to distinguish two sides of object from each other. 

I tried to solve this problem by rasterizing borders to image and performing pixelwise classification (my loss is binary entropy) using such image as target. It works pretty well but i failed to extend such approach to high-resolution images - my neural network overfits fast even with heavy augmentations.

So i have two questions

1) What is SOTA for deep learning based edge detection? Of course i tried to use google but i cannot find anything modern.

2) I think that binary entropy is pretty bad loss for edges. For example assume you border is one pixel-width horizontal line. if model give you border equal to target border shifted by one pixel up, binary entropy give you same error as if predicted border was shifted by 1000 pixels. So what kind of losses can be used for this case?",10,9
96,2018-8-3,2018,8,3,14,946z1e,3D Print,https://www.reddit.com/r/MachineLearning/comments/946z1e/3d_print/,Guckenberger,1533274882,,0,1
97,2018-8-3,2018,8,3,14,9471iu,"Using Gumbel distribution to form a NN containing a discrete random component (VAE, GAN)",https://www.reddit.com/r/MachineLearning/comments/9471iu/using_gumbel_distribution_to_form_a_nn_containing/,yoelzeldes,1533275649,,0,1
98,2018-8-3,2018,8,3,15,9477aj,ClusterOne  AI platform as a service,https://www.reddit.com/r/MachineLearning/comments/9477aj/clusterone_ai_platform_as_a_service/,clusterone02,1533277405,,1,1
99,2018-8-3,2018,8,3,15,947c4m,How to stop the training automatically in which trainbr function is used when the effective number of parameters or the sum squared error (sse) has converged?,https://www.reddit.com/r/MachineLearning/comments/947c4m/how_to_stop_the_training_automatically_in_which/,ilyyui,1533278903,[removed],0,1
100,2018-8-3,2018,8,3,16,947fob,Professional testing machine manufacturers-Zhilitong producing the global qualified product safety testing equipment,https://www.reddit.com/r/MachineLearning/comments/947fob/professional_testing_machine/,jumitop,1533280033,,0,1
101,2018-8-3,2018,8,3,16,947gwu,Industrial Pressure Transmitters for Highly Corrosive and Aggressive Media,https://www.reddit.com/r/MachineLearning/comments/947gwu/industrial_pressure_transmitters_for_highly/,Holykell,1533280391,[removed],0,1
102,2018-8-3,2018,8,3,16,947ody,How to modify existing functional API in keras?,https://www.reddit.com/r/MachineLearning/comments/947ody/how_to_modify_existing_functional_api_in_keras/,emergenthoughts,1533282831,"I have the following python code:

    original_model=ks.applications.vgg16.VGG16()
    original_model.summary()
    new_model=original_model
    new_model.layers.pop()
    for layer in new_model.layers:
        layer.trainable=False

    new_model.layers.append(Dense(10,activation='softmax'))
    new_model.summary()

But when I try it, it throws some sort of error. 

I'm aware of there being a workaround with copying the layers in a sequential model, but I'd rather learn how to modify the functional API, for future, more complex models.

Thanks!",0,1
103,2018-8-3,2018,8,3,16,947p7e,Getting Started with Machine Learning? Here are some useful resources.,https://www.reddit.com/r/MachineLearning/comments/947p7e/getting_started_with_machine_learning_here_are/,PyGhost,1533283127,[removed],0,1
104,2018-8-3,2018,8,3,17,947q9m,[P] TensorFlow 1.9 Officially Supports the Raspberry Pi,https://www.reddit.com/r/MachineLearning/comments/947q9m/p_tensorflow_19_officially_supports_the_raspberry/,chisai_mikan,1533283489,,0,1
105,2018-8-3,2018,8,3,17,947qsh,[P] TensorFlow 1.9 Officially Supports the Raspberry Pi,https://www.reddit.com/r/MachineLearning/comments/947qsh/p_tensorflow_19_officially_supports_the_raspberry/,chisai_mikan,1533283672,,59,322
106,2018-8-3,2018,8,3,17,947s64,Payment for NVIDIA cuDNN.,https://www.reddit.com/r/MachineLearning/comments/947s64/payment_for_nvidia_cudnn/,vdzioszek,1533284138,[removed],0,1
107,2018-8-3,2018,8,3,17,947t74,Why Decision Trees are Important for Customer Service?,https://www.reddit.com/r/MachineLearning/comments/947t74/why_decision_trees_are_important_for_customer/,RounakRD,1533284517,[removed],0,1
108,2018-8-3,2018,8,3,17,947xpn,[R] Histopatholgy pre-trained models requiered,https://www.reddit.com/r/MachineLearning/comments/947xpn/r_histopatholgy_pretrained_models_requiered/,omayrakhtar,1533286106,"Hello Everybody,

I am doing research on prostate cancer detection and looking for pre-trained models to employ transfer learning for PC detection. I am using histology slides and before training any model from scratch or using *Imagenet* pre-trained models, I'd like to test a pre-trained model, trained on a data set which is similar to this prostate histology slides data set.I have been following [Camelyon breast cancer competitions ](https://camelyon17.grand-challenge.org/): an example of the kind of data set the model should be trained on. I'd be immensely grateful if anybody can share such pre-trained models or guide me where I can get one.   
",3,1
109,2018-8-3,2018,8,3,18,94804z,"Prediction market: What will be the value of the (herein described) ""AI winter index"" at end of 2021?",https://www.reddit.com/r/MachineLearning/comments/94804z/prediction_market_what_will_be_the_value_of_the/,PresentCompanyExcl,1533286935,,0,1
110,2018-8-3,2018,8,3,18,94815u,[R] GENDIS: GENetic DIscovery of Shapelets,https://www.reddit.com/r/MachineLearning/comments/94815u/r_gendis_genetic_discovery_of_shapelets/,givdwiel,1533287275,,0,1
111,2018-8-3,2018,8,3,18,9481px,cheap water bottles,https://www.reddit.com/r/MachineLearning/comments/9481px/cheap_water_bottles/,winterkuperxbs,1533287435,,0,1
112,2018-8-3,2018,8,3,18,9481y1,Comparator Networks.,https://www.reddit.com/r/MachineLearning/comments/9481y1/comparator_networks/,XWD_,1533287510,[removed],0,1
113,2018-8-3,2018,8,3,18,948259,"Dataset containing 10,000 images for all Generation One Pokmon.",https://www.reddit.com/r/MachineLearning/comments/948259/dataset_containing_10000_images_for_all/,the-dagger,1533287586,,0,1
114,2018-8-3,2018,8,3,18,94833t,Neural Arithmetic Logic Units,https://www.reddit.com/r/MachineLearning/comments/94833t/neural_arithmetic_logic_units/,iamtrask,1533287927,,88,100
115,2018-8-3,2018,8,3,18,9483m7,State of Art preprocessing techniques in machine learning.,https://www.reddit.com/r/MachineLearning/comments/9483m7/state_of_art_preprocessing_techniques_in_machine/,ArunLko,1533288110,[removed],0,1
116,2018-8-3,2018,8,3,18,94849i,Best Practices for ML Engineering - A google guide for best practices for a machine learning enginner,https://www.reddit.com/r/MachineLearning/comments/94849i/best_practices_for_ml_engineering_a_google_guide/,Tabish_Shaikh,1533288326,[removed],0,1
117,2018-8-3,2018,8,3,19,948gry,Peanut oil press production line,https://www.reddit.com/r/MachineLearning/comments/948gry/peanut_oil_press_production_line/,oil-machine,1533292378,,0,1
118,2018-8-3,2018,8,3,19,948los,Knowledge Management + Technology : Perfect Recipe for Successful Chatbots,https://www.reddit.com/r/MachineLearning/comments/948los/knowledge_management_technology_perfect_recipe/,RounakRD,1533293885,[removed],0,1
119,2018-8-3,2018,8,3,20,948rcj,Machine Learning Tutorial With Python -1: What is Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/948rcj/machine_learning_tutorial_with_python_1_what_is/,Beneficial3Fish,1533295510,,0,1
120,2018-8-3,2018,8,3,20,948s7o,Simple Introduction to Evolutionary Algorithms,https://www.reddit.com/r/MachineLearning/comments/948s7o/simple_introduction_to_evolutionary_algorithms/,firefly_88,1533295769,,0,1
121,2018-8-3,2018,8,3,20,948wxn,Why cant I get tensorflow to import to Pycharm?,https://www.reddit.com/r/MachineLearning/comments/948wxn/why_cant_i_get_tensorflow_to_import_to_pycharm/,Silver5005,1533297067,[removed],0,1
122,2018-8-3,2018,8,3,21,9491jv,[P] Domain randomization library in Python for object-detection and classification using Blender.,https://www.reddit.com/r/MachineLearning/comments/9491jv/p_domain_randomization_library_in_python_for/,oarriaga,1533298249,,0,1
123,2018-8-3,2018,8,3,22,949gg0,Who should be testing ml models on ongoing basis?,https://www.reddit.com/r/MachineLearning/comments/949gg0/who_should_be_testing_ml_models_on_ongoing_basis/,svyas,1533301867,"As like traditional apps where there are test engineers / QA team for testing the apps, could there be a similar setup for testing ML models? I understand that there are challenges primarily related to skills. However, given that data scientist who worked on models can move on from the organisation, would this be another data scientist taking his model and maintaining the same from QA perspective. Please suggest.",0,1
124,2018-8-3,2018,8,3,22,949n2o,[Academic] Amazon Alexa New Quiz Skill! (Everyone),https://www.reddit.com/r/MachineLearning/comments/949n2o/academic_amazon_alexa_new_quiz_skill_everyone/,AnaMcL,1533303416,[removed],0,1
125,2018-8-3,2018,8,3,23,949yp8,Google Simplifies Machine Learning With SQL,https://www.reddit.com/r/MachineLearning/comments/949yp8/google_simplifies_machine_learning_with_sql/,CrankyBear,1533305897,,0,2
126,2018-8-3,2018,8,3,23,94a91z,[P] Computational Hairdressing,https://www.reddit.com/r/MachineLearning/comments/94a91z/p_computational_hairdressing/,sataky,1533308090,,0,10
127,2018-8-4,2018,8,4,0,94abvk,[P] Animating Doodles with Autoencoders and Synthetic Data,https://www.reddit.com/r/MachineLearning/comments/94abvk/p_animating_doodles_with_autoencoders_and/,MindSustenance,1533308655,,12,85
128,2018-8-4,2018,8,4,0,94ad5e,Question regarding Image-To-Image Translation Networks,https://www.reddit.com/r/MachineLearning/comments/94ad5e/question_regarding_imagetoimage_translation/,lifeadvicesponge,1533308887,"Hi r/machinelearning   

I am exploring applications of I-2-I translation for inter-modal conversion (Thermal to RGB etc) and I was wondering what is the state of the art for such networks. Because I am getting nowhere near the same performance on Thermal-&gt;RGB images as compared to RGB images and the translations are also not very good. I was using [CycleGAN](https://arxiv.org/pdf/1703.10593.pdf) for my project as I was trying to work in an unsupervised manner. I will next be trying [Pix2Pix](https://arxiv.org/abs/1611.07004) to see how good I can do with paired images.     

I came across this paper from NVIDIA [Unsupervised Image-to-Image Translation Networks](https://arxiv.org/pdf/1703.00848.pdf) and they have only reported results for digit classification which is a rather non-complex vision problem and does not come close to the complexity of something like person recognition. I was wondering if someone can help me out regarding the state-of-the-art in this field or give me pointers on how to do such cross-modal image translations. I am working with images of people and would like the translations to preserve the identity of the person.   ",0,1
129,2018-8-4,2018,8,4,0,94afnu,[D] Successful approaches for Automated Neural Network architecture search,https://www.reddit.com/r/MachineLearning/comments/94afnu/d_successful_approaches_for_automated_neural/,AndriPi,1533309379,"Which are the most common approaches currently being used for Automated Architecture search? I can think of the following:

1. [Neural Architecture Search](https://arxiv.org/pdf/1707.07012.pdf), based on Reinforcement Learning, used in Google Cloud AutoML
2. [Efficient Neural Architecture Search](https://arxiv.org/pdf/1802.03268.pdf), improving (in terms of speed) on NAS thanks to weight sharing, implemented in AutoKeras
3. [Differentiable Architecture Search](https://arxiv.org/abs/1806.09055v1) available in PyTorch but incompatible with PyTorch 0.4

Anything else comes to mind? Is there anything based on evolutionary algorithms?",26,21
130,2018-8-4,2018,8,4,0,94ahgp,Course recommendation for Unity3d Developer,https://www.reddit.com/r/MachineLearning/comments/94ahgp/course_recommendation_for_unity3d_developer/,eco_bach,1533309748,[removed],0,1
131,2018-8-4,2018,8,4,0,94alf1,[P] Sonic the Hedgehog Bot with NEAT and Open-AI Retro (Tutorial and Repo),https://www.reddit.com/r/MachineLearning/comments/94alf1/p_sonic_the_hedgehog_bot_with_neat_and_openai/,wholeywoolly,1533310518,"I've created a series of tutorials on how to use NEAT (Neural Evolution of Augmenting Topologies) with Open-AI's Retro library to train a network to play basically any retro game. How well it does depends on lots of factors. I've personally had success with Donkey Kong Country and Sonic the Hedgehog 2. 

Here's the tutorial:
https://www.youtube.com/watch?v=CFa6NhLgeL0&amp;list=PLTWFMbPFsvz3CeozHfeuJIXWAJMkPtAdS

Repo:
https://gitlab.com/lucasrthompson/Sonic-Bot-In-OpenAI-and-NEAT

I just wanted to thank this sub for all the cool ideas. I love it here.",8,48
132,2018-8-4,2018,8,4,1,94atwi,Weeding out fake customer leads vs. real customer leads,https://www.reddit.com/r/MachineLearning/comments/94atwi/weeding_out_fake_customer_leads_vs_real_customer/,tor_brat,1533312152,[removed],0,1
133,2018-8-4,2018,8,4,1,94auo2,"""The true challenge to artificial intelligence proved to be solving the tasks that are easy for people to perform but hard to describe formally""- the deeplearning book by Ian Goodfellow",https://www.reddit.com/r/MachineLearning/comments/94auo2/the_true_challenge_to_artificial_intelligence/,Tabish_Shaikh,1533312290,[removed],0,1
134,2018-8-4,2018,8,4,2,94beuw,How to Prepare for a Machine Learning Interview,https://www.reddit.com/r/MachineLearning/comments/94beuw/how_to_prepare_for_a_machine_learning_interview/,RudyWurlitzer,1533316132,,0,1
135,2018-8-4,2018,8,4,2,94bneq,[D] Has anyone done a seq2seq with relative time output?,https://www.reddit.com/r/MachineLearning/comments/94bneq/d_has_anyone_done_a_seq2seq_with_relative_time/,StevieLamchops,1533317753,"I'm trying to test a model design where, given a list of binary digits, it would return a list of relative indices of the 1s are in the input list.

i.e. simply
    [0, 1, 0, 1, 0] -&gt; [0.2, 0.6]

I started out trying it out myself, with a naive RNN -&gt; RNN that got nowhere.

Then I tried adding an attention mechanism as recommended by many people, but I can't seem to figure out the maths to create an alignment matrix for variable input and output lengths as illustrated here:

https://heuritech.files.wordpress.com/2016/01/alignment_badhanau.png

What I currently have is a in terms of matrix shapes is:
    (n, 1) -&gt; (n, a) -&gt; (a, m) -&gt; (m, 1)

Where *n* is the input length, *a* is the size of the attention vector, and *m* is the output length.

I'm basically creating an attention vector using an attention model like [this](https://heuritech.files.wordpress.com/2016/01/detail_attentionmodel1.png), passing the output to an rnn as a single step, and passing the hidden state back to the attention model, until I have *m* output values.

The loss does go down slowly, however the accuracy never really goes up.

If there's a better way to do this, please do share.",6,10
136,2018-8-4,2018,8,4,3,94byam,"[Discussion] Why tune ""c"" in MCTS to manage exploration-exploitation trade-off when optimal value is known by UCB?",https://www.reddit.com/r/MachineLearning/comments/94byam/discussion_why_tune_c_in_mcts_to_manage/,DeludedMonk,1533319792,"UCB gives the value sqrt(2) for parameter ""c"" in formulation MCTS action value function for rewards in range 0 to 1, for which the value satisfies Hoeffding inequality. Yet I have seen papers where they tune this value to control the trade-off explicitly. Why then is this tuned when the optimal value is known?

I hope I am not missing something obvious here

Thanks",4,3
137,2018-8-4,2018,8,4,3,94c2b1,[D] Reinforcement Learning in a Nutshell,https://www.reddit.com/r/MachineLearning/comments/94c2b1/d_reinforcement_learning_in_a_nutshell/,vector_machines,1533320553,,0,0
138,2018-8-4,2018,8,4,3,94c6h0,What kind of NN architecture do I need to identify signals in a continuous stream?,https://www.reddit.com/r/MachineLearning/comments/94c6h0/what_kind_of_nn_architecture_do_i_need_to/,i-stat,1533321358,"I have a continuous stream of data arriving on several channels and I want to use a NN to detect fairly short duration events (signals) that occur at irregular intervals.

Most of the NN applications I have seen either deal with discrete inputs like individual images &amp; I have seen some that process time series, but only for forecasting, not event detection.

Any suggestions how to do this?  I guess I could somehow move a 1d convnet window along the stream, but I haven't really got much further.  Any thoughts/pointers appreciated. Thanks.",0,1
139,2018-8-4,2018,8,4,5,94cxkz,[Question] is it possible to buy custom datasets?,https://www.reddit.com/r/MachineLearning/comments/94cxkz/question_is_it_possible_to_buy_custom_datasets/,YesIAmAHuman,1533326629,[removed],0,1
140,2018-8-4,2018,8,4,5,94d7wg,[P] Practical tutorials on getting started with PyTorch and TorchText for sentiment analysis,https://www.reddit.com/r/MachineLearning/comments/94d7wg/p_practical_tutorials_on_getting_started_with/,desku,1533328739,,0,1
141,2018-8-4,2018,8,4,5,94d8sg,[P] I implemented some RL algorithms!,https://www.reddit.com/r/MachineLearning/comments/94d8sg/p_i_implemented_some_rl_algorithms/,Jonas_SV,1533328901,"* DQN: [https://github.com/JonasRSV/DQNTensorflow](https://github.com/JonasRSV/DQNTensorflow)
* DDPG: [https://github.com/JonasRSV/PGTensorflow](https://github.com/JonasRSV/PGTensorflow)
* CEM: [https://github.com/JonasRSV/CEM\_Tensorflow](https://github.com/JonasRSV/CEM_Tensorflow)

With AIGym examples showing that they work, at least a little . 

I'm thinking of Implementing PPO, are there any other reinforcement algorithms that might be fun implementing? After PPO i'll probably be tired of PG based algorithms, i had some real issues getting satisfactory performance from DDPG. If anyone has any pointers how i can improve mine; that'd be super cool! :) 

Anyway is there any cool non PG algorithms thats worth implementing apart from CEM? :) ",0,0
142,2018-8-4,2018,8,4,5,94dazj,Join this github project for newbie of machine learning.,https://www.reddit.com/r/MachineLearning/comments/94dazj/join_this_github_project_for_newbie_of_machine/,fredriccliver,1533329369,[removed],0,1
143,2018-8-4,2018,8,4,5,94dbzl,"Seeking cooperation, landslide susceptibility mapping, data sharing, online research union",https://www.reddit.com/r/MachineLearning/comments/94dbzl/seeking_cooperation_landslide_susceptibility/,GeoClay,1533329580,[removed],0,1
144,2018-8-4,2018,8,4,6,94dg0c,A tutorial on how to prepare for a Machine Learning interview,https://www.reddit.com/r/MachineLearning/comments/94dg0c/a_tutorial_on_how_to_prepare_for_a_machine/,lohoban,1533330398,[removed],0,1
145,2018-8-4,2018,8,4,6,94dge1,[R] DeepMind - Neural Arithmetic Logic Units,https://www.reddit.com/r/MachineLearning/comments/94dge1/r_deepmind_neural_arithmetic_logic_units/,regalalgorithm,1533330484,,1,1
146,2018-8-4,2018,8,4,6,94dhb1,[N] Bringing Learning to Robotics: Highlights from RSS 2018,https://www.reddit.com/r/MachineLearning/comments/94dhb1/n_bringing_learning_to_robotics_highlights_from/,regalalgorithm,1533330672,,7,29
147,2018-8-4,2018,8,4,6,94dhpj,[R] World's Smallest Self-Driving Car: Version 2,https://www.reddit.com/r/MachineLearning/comments/94dhpj/r_worlds_smallest_selfdriving_car_version_2/,CireNeikual,1533330752,,29,96
148,2018-8-4,2018,8,4,9,94f342,Google AI Residency (Healthcare),https://www.reddit.com/r/MachineLearning/comments/94f342/google_ai_residency_healthcare/,michaelmuelly,1533343773,[removed],0,1
149,2018-8-4,2018,8,4,11,94fpw9,Is there an algorithm to match a doctor to a patient?,https://www.reddit.com/r/MachineLearning/comments/94fpw9/is_there_an_algorithm_to_match_a_doctor_to_a/,depressed_guy_sigh,1533349643,[removed],0,1
150,2018-8-4,2018,8,4,11,94fqam,A hitchhiker guide to python NumPy Arrays  Towards Data Science,https://www.reddit.com/r/MachineLearning/comments/94fqam/a_hitchhiker_guide_to_python_numpy_arrays_towards/,DakshHub,1533349753,,0,1
151,2018-8-4,2018,8,4,12,94g0k0,[Project] The Deep Anime Plot Generator is a system that uses a Recurrent Neural Network (RNN) to generate novel anime plot summaries and posts them to Reddit.,https://www.reddit.com/r/MachineLearning/comments/94g0k0/project_the_deep_anime_plot_generator_is_a_system/,shanoxilt,1533352486,,0,1
152,2018-8-4,2018,8,4,12,94g3i2,Neural Style Transfer: Creating Art with Deep Learning using tf.keras and eager execution,https://www.reddit.com/r/MachineLearning/comments/94g3i2/neural_style_transfer_creating_art_with_deep/,MainaWycliffe,1533353283,,0,1
153,2018-8-4,2018,8,4,14,94gwxe,AI learns to solve the Rubik's Cube!,https://www.reddit.com/r/MachineLearning/comments/94gwxe/ai_learns_to_solve_the_rubiks_cube/,VCubingX,1533361575,,1,1
154,2018-8-4,2018,8,4,15,94h5bq,Resume Parsing - extracting skills from resume using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/94h5bq/resume_parsing_extracting_skills_from_resume/,sociopath27,1533364249,[removed],0,1
155,2018-8-4,2018,8,4,17,94hlck,Countinous learning with DNN,https://www.reddit.com/r/MachineLearning/comments/94hlck/countinous_learning_with_dnn/,hungle9,1533369911,[removed],0,1
156,2018-8-4,2018,8,4,17,94hroi,"NIH Clinical Center releases dataset of 32,000 CT images",https://www.reddit.com/r/MachineLearning/comments/94hroi/nih_clinical_center_releases_dataset_of_32000_ct/,LordKlevin,1533372370,,0,1
157,2018-8-4,2018,8,4,18,94hv05,What is state of the art in Natural Language Inference for long texts ?,https://www.reddit.com/r/MachineLearning/comments/94hv05/what_is_state_of_the_art_in_natural_language/,saurabhvyas3,1533373696,"I am looking to implement a model for NLI Task, in which I have a premise and a hypothesis, however, the premise can be variable in length, it can be as small as 3 lines, and as big as 2000 words, I am curious to know from others, what is state of the art for this task ?

Which is the most effective approach to encode long texts for sequence to sequence model with attention ? Sentence embedding / Glove / FastText ? ",0,1
158,2018-8-4,2018,8,4,18,94hvso,CUDA 9.2 with ubuntu 18.04.1,https://www.reddit.com/r/MachineLearning/comments/94hvso/cuda_92_with_ubuntu_18041/,topmage,1533373994,[removed],0,1
159,2018-8-4,2018,8,4,21,94iuj9,What is the Three Monks Problem in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/94iuj9/what_is_the_three_monks_problem_in_machine/,moschles,1533386452,[removed],0,1
160,2018-8-4,2018,8,4,22,94j0iw,[N] Google AI Residency (Healthcare),https://www.reddit.com/r/MachineLearning/comments/94j0iw/n_google_ai_residency_healthcare/,michaelmuelly,1533388263,[removed],0,1
161,2018-8-4,2018,8,4,22,94j9hz,[D] New YouTube Channel on making AI Research accessible,https://www.reddit.com/r/MachineLearning/comments/94j9hz/d_new_youtube_channel_on_making_ai_research/,vector_machines,1533390751,"Hi, Please check out my channel ([https://www.youtube.com/c/aijournal](https://www.youtube.com/c/aijournal)) which talks about research in Deep Learning, Machine Learning, Reinforcement Learning, NLP. The main aim is to bring as much research content available as possible. Majority of information is stored inside papers, and very few people have access to it. I want to bring out the best out of all of them.

I also have a subreddit ([https://www.reddit.com/r/aijournal/](https://www.reddit.com/r/aijournal/)) if you have any doubts regarding the content being discussed on the channel or if you written a blog regarding research paper. We're a really friendly community interested in cutting edge research in ML. Your work will be shared. Because Good Ideas are worth sharing !!",8,3
162,2018-8-4,2018,8,4,23,94jokk,Need to do a major project,https://www.reddit.com/r/MachineLearning/comments/94jokk/need_to_do_a_major_project/,MrHktrioot,1533394418,"So, I want to do this major project in the in the field of machine learning and I have no really good ideas.
I'm a beginner in this field it will be my first attempt at doing such a project, what would be a great topic to work on.",0,1
163,2018-8-4,2018,8,4,23,94jpal,[D] [Meta learning] Leveraging knowledge graphs for neural networks.,https://www.reddit.com/r/MachineLearning/comments/94jpal/d_meta_learning_leveraging_knowledge_graphs_for/,Morninglow,1533394588,"What's the word on using knowledge graphs with neural networks? It seems like this would be a very powerful model that could ground a NLP task in the same way that transfer learning with trained word vectors does. 

I'm looking at some papers on knowledge embeddings but there use seems to be limited to some NLP tasks. Is the architecture difference just not conducive to transfer learning in the way you would use word vectors? 

Has anyone tried using a TreeRNN as en autoencoder? Wouldn't that be the natural choice for dealing with graph data?",11,62
164,2018-8-5,2018,8,5,0,94jql3,Anyone doing CoRL 2018?,https://www.reddit.com/r/MachineLearning/comments/94jql3/anyone_doing_corl_2018/,edwardthegreat2,1533394903,[removed],0,1
165,2018-8-5,2018,8,5,1,94kc8p,Is unsupervised learning useful without labeled data?,https://www.reddit.com/r/MachineLearning/comments/94kc8p/is_unsupervised_learning_useful_without_labeled/,CacheMeUp,1533399903,[removed],0,1
166,2018-8-5,2018,8,5,1,94kleg,Real-time hand detection and tracking using OpenCV and Python,https://www.reddit.com/r/MachineLearning/comments/94kleg/realtime_hand_detection_and_tracking_using_opencv/,amarpandey,1533401948,"Real-time Finger detection and tracking using OpenCV and Python. Feedbacks and suggestions are welcome :)  

Github link:[https://github.com/amarlearning/opencv](https://github.com/amarlearning/opencv)

[**#opencv**](https://www.linkedin.com/feed/topic/?keywords=%23opencv) [**hashtag#realtime**](https://www.linkedin.com/feed/topic/?keywords=%23realtime) [**hashtag#objectdetection**](https://www.linkedin.com/feed/topic/?keywords=%23objectdetection) [**hashtag#python**](https://www.linkedin.com/feed/topic/?keywords=%23python) [**hashtag#opensourcesoftware**](https://www.linkedin.com/feed/topic/?keywords=%23opensourcesoftware) [**hashtag#computervision**](https://www.linkedin.com/feed/topic/?keywords=%23computervision) [**hashtag#inspiration**](https://www.linkedin.com/feed/topic/?keywords=%23inspiration) [**hashtag#github**](https://www.linkedin.com/feed/topic/?keywords=%23github)

![video](dp99cnwdx3e11 ""Real-time Finger detection and tracking using OpenCV and Python."")",0,1
167,2018-8-5,2018,8,5,2,94kqhz,4chan Text Generator using Markov Chains (NSFW),https://www.reddit.com/r/MachineLearning/comments/94kqhz/4chan_text_generator_using_markov_chains_nsfw/,ossama_hj,1533403002,,0,1
168,2018-8-5,2018,8,5,2,94ktn3,[P] Text Generator using Markov Chains with 4chan APIs (NSFW),https://www.reddit.com/r/MachineLearning/comments/94ktn3/p_text_generator_using_markov_chains_with_4chan/,ossama_hj,1533403691,,1,1
169,2018-8-5,2018,8,5,2,94l07x,[P] torchsummaryX: Improved visualization tool of torchsummary,https://www.reddit.com/r/MachineLearning/comments/94l07x/p_torchsummaryx_improved_visualization_tool_of/,nmhkahn,1533405127,,0,1
170,2018-8-5,2018,8,5,2,94l29s,How to Create SDK for a Machine Learning Model?,https://www.reddit.com/r/MachineLearning/comments/94l29s/how_to_create_sdk_for_a_machine_learning_model/,taewoo,1533405566,[removed],0,1
171,2018-8-5,2018,8,5,3,94lf4v,[P] 4chan Text Generator using Markov Chains (NSFW),https://www.reddit.com/r/MachineLearning/comments/94lf4v/p_4chan_text_generator_using_markov_chains_nsfw/,ossama_hj,1533408397,,9,15
172,2018-8-5,2018,8,5,4,94lwjm,[N] Witness artificial intelligence at its peak this Sunday,https://www.reddit.com/r/MachineLearning/comments/94lwjm/n_witness_artificial_intelligence_at_its_peak/,Dohong,1533412298,,0,1
173,2018-8-5,2018,8,5,5,94m0z2,[R] Comparator networks for template-to-template verification.,https://www.reddit.com/r/MachineLearning/comments/94m0z2/r_comparator_networks_for_templatetotemplate/,XWD_,1533413299,,4,12
174,2018-8-5,2018,8,5,5,94m7qs,Autokeras - python package to automate ML/DL models for those with little or no data science experience,https://www.reddit.com/r/MachineLearning/comments/94m7qs/autokeras_python_package_to_automate_mldl_models/,primemozartmessi,1533414861,,0,1
175,2018-8-5,2018,8,5,7,94my92,Can't use the old victory prediction charm when you have the dota+ one too,https://www.reddit.com/r/MachineLearning/comments/94my92/cant_use_the_old_victory_prediction_charm_when/,Valiox,1533421018,,0,1
176,2018-8-5,2018,8,5,9,94nuz3,[P] ml_board: A simple dashboard for comparing training parameters vs output statistics,https://www.reddit.com/r/MachineLearning/comments/94nuz3/p_ml_board_a_simple_dashboard_for_comparing/,bbbli,1533429148,"Hi guys,

I used the Dash web app framework from plotly to build a machine learning dashboard. I decided to create this for my own personal use because there were certain featuresthat tensorboard lacked, which is explained further in the repo. Comments and pull requests are greatly appreciated, as I am still new to software development and open source!",4,68
177,2018-8-5,2018,8,5,11,94orws,Looking for Online Children abuse dataset.,https://www.reddit.com/r/MachineLearning/comments/94orws/looking_for_online_children_abuse_dataset/,spectre_S,1533437803,[removed],0,1
178,2018-8-5,2018,8,5,14,94ppsq,[P] ESPnet: end-to-end speech processing toolkit,https://www.reddit.com/r/MachineLearning/comments/94ppsq/p_espnet_endtoend_speech_processing_toolkit/,Loggerny,1533447813,,1,9
179,2018-8-5,2018,8,5,17,94qhqf,AI Weekly 5 August 2018,https://www.reddit.com/r/MachineLearning/comments/94qhqf/ai_weekly_5_august_2018/,TomekB,1533458087,,0,1
180,2018-8-5,2018,8,5,17,94qjdo,[P] Real-Time Fraud Detection System,https://www.reddit.com/r/MachineLearning/comments/94qjdo/p_realtime_fraud_detection_system/,hoaphumanoid,1533458758,,12,41
181,2018-8-5,2018,8,5,18,94qrln,Top Loader Vs Front Loading Machine - Which One Is Best For You?,https://www.reddit.com/r/MachineLearning/comments/94qrln/top_loader_vs_front_loading_machine_which_one_is/,houmayo,1533462046,[removed],0,1
182,2018-8-5,2018,8,5,19,94qwz2,[Discussion] What is your opinion of Probabilistic Programming?,https://www.reddit.com/r/MachineLearning/comments/94qwz2/discussion_what_is_your_opinion_of_probabilistic/,DeludedMonk,1533464244,"Probabilistic programming has been slowly gaining momentum over the past few years. Particularly, the likes of Josh Tenenbaum and his students have been making ever stronger arguments for ""Intuitive Physics"", ""Inverse Graphics"" and more generally for structured generative models. I really like how it combines the robust learning of statistical methods, while also being good at symbolic reasoning like GOFAI techniques. It has also gained traction in industry, with Uber releasing their own Probabilistic Programming library on top of PyTorch. Many top researchers have also begun writing papers on it and discussing it in main conferences. 

While the philosophy behind it sounds inspiring, I haven't seen a killer demo that has convinced me of its potential: sort of like what Alex Khrizhevsky's ImageNet result did for Deep Learning. Bayesian Program Learning (BPL) by Brenden Lake came close, but it's results were matched and surpassed by Deep Learning methods in just a couple of years. And I am not aware of any other big result with BPL.

To be honest, I don't see why something like Probabilistic Programming is necessary for AI/AGI. Seems to me that the people working on it are very rigorous seeking most general versions of things, hence working on Turing complete languages, general inference mechanisms etc.,But at the end of the day its still Bayesian --- so requires a prior, there is no free lunch and so depends a lot on domain-expertise to setup the model and hand tune the inference mechanism. Rich Sutton recently said (to paraphrase) ""domain agnostic methods will always eventually surpass domain specific methods"". He hence encouraged working on domain agnostic methods, I guess being inspired by his own work in RL. This makes the future of Probabilistic Programming look not so promising to me. This is of course my biased opinion.

What are your thoughts and insights about this? Is it the next big thing or will it go in the same direction as GOFAI? Or will it find a niche in some areas?",62,182
183,2018-8-5,2018,8,5,19,94qz8o,"AI for drummers, human-like robot hand &amp; solving Montezuma's Revenge",https://www.reddit.com/r/MachineLearning/comments/94qz8o/ai_for_drummers_humanlike_robot_hand_solving/,Enterprisesoft,1533465149,,0,1
184,2018-8-5,2018,8,5,22,94rqxx,[P] TwitterBlob - Visualising Sentiment Distribution on Topics,https://www.reddit.com/r/MachineLearning/comments/94rqxx/p_twitterblob_visualising_sentiment_distribution/,paubric,1533474686,,0,1
185,2018-8-5,2018,8,5,22,94ruuo,Clustering correlated tags on a pornographic torrent tracker,https://www.reddit.com/r/MachineLearning/comments/94ruuo/clustering_correlated_tags_on_a_pornographic/,bdwaffle,1533475785,,1,1
186,2018-8-5,2018,8,5,22,94s05a,"Lookup table, help me fill in the blanks",https://www.reddit.com/r/MachineLearning/comments/94s05a/lookup_table_help_me_fill_in_the_blanks/,anticant,1533477272,[removed],0,1
187,2018-8-5,2018,8,5,23,94s9v7,[D] Aren't the discussions between AC and reviewers supposed to be anonymized? #nips2018,https://www.reddit.com/r/MachineLearning/comments/94s9v7/d_arent_the_discussions_between_ac_and_reviewers/,sarf1234,1533479767,"I got a notification email from CMT that an AC just posted a message to the discussion for the paper I just reviewed. The email clearly shows the identity of the AC . When I replied to the discussion, I got a notification email from CMT showing my name in the email. 

In the double blind review process of NIPS 2018, aren't the discussions between AC and reviewers supposed to be anonymized? i.e. no one should know the identity of the AC and the other reviewers.",11,22
188,2018-8-6,2018,8,6,0,94siir,The Mechanic t-shirt for by machine man !,https://www.reddit.com/r/MachineLearning/comments/94siir/the_mechanic_tshirt_for_by_machine_man/,halofatih,1533481896,"Hello everyone. Today I'm here for show the basic but the characteristic t-shirt. If you like this or like this tshirt you absolutely look at the store.

Store link: [https://teespring.com/stores/jonathanandfletcher](https://teespring.com/stores/jonathanandfletcher)

Mechanic tshirt link: [https://teespring.com/the-mechanic-limited-edition#pid=2&amp;cid=573&amp;sid=front](https://teespring.com/the-mechanic-limited-edition#pid=2&amp;cid=573&amp;sid=front)",0,1
189,2018-8-6,2018,8,6,1,94t3cs,Dell EMC Ready Solutions for AI,https://www.reddit.com/r/MachineLearning/comments/94t3cs/dell_emc_ready_solutions_for_ai/,TechieBrosevelt,1533486617,,0,1
190,2018-8-6,2018,8,6,2,94tfth,Boss detector to become employee of the month!,https://www.reddit.com/r/MachineLearning/comments/94tfth/boss_detector_to_become_employee_of_the_month/,hasibzunair,1533489427,,0,1
191,2018-8-6,2018,8,6,3,94tyui,Learn how neural networks work!,https://www.reddit.com/r/MachineLearning/comments/94tyui/learn_how_neural_networks_work/,antaloaalonso,1533493502,,0,1
192,2018-8-6,2018,8,6,4,94u9f3,Measure ML interest level,https://www.reddit.com/r/MachineLearning/comments/94u9f3/measure_ml_interest_level/,msaadsaif5,1533495822,[removed],0,1
193,2018-8-6,2018,8,6,4,94uj5x,[N] OpenAI is currently presenting high skill show matches,https://www.reddit.com/r/MachineLearning/comments/94uj5x/n_openai_is_currently_presenting_high_skill_show/,stf,1533497930,,113,248
194,2018-8-6,2018,8,6,4,94ummw,Hi. I'm new on programming and I want to learn machine learning. Where to start?,https://www.reddit.com/r/MachineLearning/comments/94ummw/hi_im_new_on_programming_and_i_want_to_learn/,jdgaravito,1533498684,"I'm designer and I i'm beginning to learn programming.. I want to learn about neural networks, cnn, and all the stuff. I'm interested on style transfer algorithms, genetic algorithms  

Is there a dummies online course or book to newcommers? 

Thank you. ",0,1
195,2018-8-6,2018,8,6,5,94up0g,[D] Machine Learning - WAYR (What Are You Reading) - Week 48,https://www.reddit.com/r/MachineLearning/comments/94up0g/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1533499204,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)||

Most upvoted papers two weeks ago:

/u/lmcinnes: [Information Theoretic Clustering using Minimum Spanning Trees](https://pub.ist.ac.at/~chl/papers/mueller-dagm2012.pdf)

/u/whymauri: [RUDDER](https://arxiv.org/abs/1806.07857)

Besides that, there are no rules, have fun.",3,19
196,2018-8-6,2018,8,6,5,94urey,Recommended storage options for large datasets?,https://www.reddit.com/r/MachineLearning/comments/94urey/recommended_storage_options_for_large_datasets/,Wenste,1533499707,[removed],0,1
197,2018-8-6,2018,8,6,5,94uthv,Any know of an easy to use style transfer windows app for videos (preferavly free),https://www.reddit.com/r/MachineLearning/comments/94uthv/any_know_of_an_easy_to_use_style_transfer_windows/,EarlHot,1533500143,My goal is to find an application that can apply style transfers preferably using video but I may opt for frame by frame. I'm not a coder so if it's a python code I'd need a simple one or one with at least a tutorial. Thanks so much for the help in advance guys.,2,1
198,2018-8-6,2018,8,6,5,94uunn,[R] Speaker Recognition from raw waveform with SincNet,https://www.reddit.com/r/MachineLearning/comments/94uunn/r_speaker_recognition_from_raw_waveform_with/,xhlu,1533500394,,7,8
199,2018-8-6,2018,8,6,5,94ux88,Building RL Trading Algorithm with a team. Who would like to join?,https://www.reddit.com/r/MachineLearning/comments/94ux88/building_rl_trading_algorithm_with_a_team_who/,rafaelDgrate,1533500945,[removed],0,1
200,2018-8-6,2018,8,6,5,94v3y7,"Academic research on Second Language Acquisition (SLA), focusing on language proficiency.",https://www.reddit.com/r/MachineLearning/comments/94v3y7/academic_research_on_second_language_acquisition/,DisastrousTHESIS,1533502393,[removed],0,1
201,2018-8-6,2018,8,6,6,94vbfz,Simple blog post for beginners about text clustering with K-means and tf-idf,https://www.reddit.com/r/MachineLearning/comments/94vbfz/simple_blog_post_for_beginners_about_text/,Yawo_o,1533504028,,0,1
202,2018-8-6,2018,8,6,6,94vegq,[D] Simple blog post for beginners about text clustering with K-means and tf-idf,https://www.reddit.com/r/MachineLearning/comments/94vegq/d_simple_blog_post_for_beginners_about_text/,Yawo_o,1533504713,"[https://medium.com/@MSalnikov/text-clustering-with-k-means-and-tf-idf-f099bcf95183](https://medium.com/@MSalnikov/text-clustering-with-k-means-and-tf-idf-f099bcf95183)  


I just wrote a small notes, great me your opinion whether I should write some notes like it, can such notes be useful to someone?",0,0
203,2018-8-6,2018,8,6,8,94wen7,[Discussion] Bayesian regression with noise injection?,https://www.reddit.com/r/MachineLearning/comments/94wen7/discussion_bayesian_regression_with_noise/,nothingbutdown,1533513233,"So I have a bit of experience with Bayesian regression using PyMC3. I've also heard of people using noise injection as a better regularizer than dropout (e.g. add in some small amount of gaussian noise to each of the outputs of the layers of a neural network). So I tried doing this with a simple linear regression in PyTorch, trying to model it as if I were setting up a Bayesian linear model in pymc3.

E.g. in PyMC3 I would model the data as `y ~ Normal(mu, sigma)`

where `mu = beta * X + alpha` and `sigma ~ HalfNormal(0,1)`

and `beta ~ Normal(2,1)`, `alpha ~ Normal(0.1,1)`

    def model(x):
         beta = torch.abs(b_sd) * torch.randn(x.shape) + b_mu
         alpha = torch.abs(a_sd) * torch.randn(x.shape) + a_mu
        mu = beta * x + alpha
        sigma = torch.abs(sig) * torch.abs(torch.randn(x.shape)) + sig_mean#
        y = torch.abs(sigma) * torch.randn(x.shape) + mu
        return y
    b_mu = Variable(torch.Tensor([2.0]), requires_grad=True)
    b_sd = Variable(torch.Tensor([1.0]), requires_grad=True)
    a_mu = Variable(torch.Tensor([0.1]), requires_grad=True)
    a_sd = Variable(torch.Tensor([1.0]), requires_grad=True)
    sig = Variable(torch.Tensor([1.0]), requires_grad=True)
    sig_mean = Variable(torch.Tensor([1.0]), requires_grad=True)
    loss_fn = torch.nn.MSELoss(size_average=True)
    lr = 0.0001
    optimizer = torch.optim.SGD(params=[b_mu, b_sd, a_mu, a_sd, sig, sig_mean], lr=lr)

And then I train it like an ordinary linear regression using SGD and mini-batches on some synthetic noisy linear data. After training, the standard deviation variables actually do reflect the amount variance in the training data and in particular, the \`b\_sd\` variable actually ends up very close to what pymc3 gives me using ""exact"" bayesian inference from MCMC. 

My question is, what exactly am I doing with this method? This noise injection technique w/ SGD seems to be a way of doing something like variational inference on a model with conjugate priors (the prior and posteriors for all variables are all gaussians), but I'm still learning the mechanics of variational inference so I'm not sure.

In any case, from a practical standpoint,  even if its not giving me exact variance/standard deviation values, it does seem to quantify uncertainty which is useful and is probably regularizing as well.",1,5
204,2018-8-6,2018,8,6,8,94wffo,References to literature for RL with adaptive reward,https://www.reddit.com/r/MachineLearning/comments/94wffo/references_to_literature_for_rl_with_adaptive/,zEnOb1,1533513425,[removed],0,1
205,2018-8-6,2018,8,6,10,94x5od,OpenAI 5vs5,https://www.reddit.com/r/MachineLearning/comments/94x5od/openai_5vs5/,nuberudi,1533519866,,0,1
206,2018-8-6,2018,8,6,12,94xuid,What are some of the best language processing libraries for sentiment analysis?,https://www.reddit.com/r/MachineLearning/comments/94xuid/what_are_some_of_the_best_language_processing/,Ambigraham,1533525884,"Im looking for something thats available for free and commercial use, which limits my options a bit. 

Im looking for something with a bit more accuracy than something like NLTK. Ive also heard of Spacy but didnt find much about how to perform sentiment analysis with it. Ive looked at Open NLP as well but it seems like a lot of documents for it are outdated. Ive heard of many more but I cant seem to figure out what is the best option.

I feel stuck! ",0,1
207,2018-8-6,2018,8,6,12,94y0xh,How to employ word2vec's embeddings and A* search algorithm to morph between words.,https://www.reddit.com/r/MachineLearning/comments/94y0xh/how_to_employ_word2vecs_embeddings_and_a_search/,yoelzeldes,1533527585,,0,1
208,2018-8-6,2018,8,6,12,94y1ms,Ian Goodfellow's book on Deep Learning,https://www.reddit.com/r/MachineLearning/comments/94y1ms/ian_goodfellows_book_on_deep_learning/,aryancodify,1533527778,[removed],0,1
209,2018-8-6,2018,8,6,13,94y45g,[D] Systems Neuroscience Is About to Get Bonkers,https://www.reddit.com/r/MachineLearning/comments/94y45g/d_systems_neuroscience_is_about_to_get_bonkers/,hardmaru,1533528436,,3,13
210,2018-8-6,2018,8,6,14,94yi6i,paging system amplifier,https://www.reddit.com/r/MachineLearning/comments/94yi6i/paging_system_amplifier/,rhaudio,1533532327,,0,1
211,2018-8-6,2018,8,6,15,94z1ox,List of AI and ML discord servers,https://www.reddit.com/r/MachineLearning/comments/94z1ox/list_of_ai_and_ml_discord_servers/,morph--,1533538260,[removed],0,1
212,2018-8-6,2018,8,6,16,94z500,[P] Vast.ai: docker-based peer GPU rental market (training costs 3x to 5x less),https://www.reddit.com/r/MachineLearning/comments/94z500/p_vastai_dockerbased_peer_gpu_rental_market/,lahwran_,1533539288,,65,170
213,2018-8-6,2018,8,6,16,94z6pa,Top 10 Technologies To Learn In 2019 | Trending Technologies | Intellipaat,https://www.reddit.com/r/MachineLearning/comments/94z6pa/top_10_technologies_to_learn_in_2019_trending/,kunaalsharma,1533539778,,0,1
214,2018-8-6,2018,8,6,16,94z8k8,Regression problem in machine learning,https://www.reddit.com/r/MachineLearning/comments/94z8k8/regression_problem_in_machine_learning/,AliML2,1533540335,[removed],0,1
215,2018-8-6,2018,8,6,16,94zac2,How Machine Learning Is Revolutionizing Supply Chain Management,https://www.reddit.com/r/MachineLearning/comments/94zac2/how_machine_learning_is_revolutionizing_supply/,vidushivij,1533540880,,0,1
216,2018-8-6,2018,8,6,16,94zcgh,Reading recommendations for non-technical people,https://www.reddit.com/r/MachineLearning/comments/94zcgh/reading_recommendations_for_nontechnical_people/,ctgeier,1533541576,[removed],0,1
217,2018-8-6,2018,8,6,17,94zh48,How soon do i need a gpu,https://www.reddit.com/r/MachineLearning/comments/94zh48/how_soon_do_i_need_a_gpu/,pg13mvp,1533543132,[removed],0,1
218,2018-8-6,2018,8,6,17,94zkg9,[D]Bridge between Neural nets and Stochastic Differential Equations,https://www.reddit.com/r/MachineLearning/comments/94zkg9/dbridge_between_neural_nets_and_stochastic/,redna11,1533544309,"Just wanted to review what is the latest in the research regarding the relationship between Neural Nets and Stochastic Differential Equations? Is there any way to formulate a Neural Net and its output as the solution to an SDE?

Any clues welcome.",9,25
219,2018-8-6,2018,8,6,17,94zkrn,Is there any one using densepose? Not getting how to use it.,https://www.reddit.com/r/MachineLearning/comments/94zkrn/is_there_any_one_using_densepose_not_getting_how/,008karan,1533544434,[removed],0,1
220,2018-8-6,2018,8,6,17,94zl7y,[Discussion] Reading recommendations for non-technical people,https://www.reddit.com/r/MachineLearning/comments/94zl7y/discussion_reading_recommendations_for/,ctgeier,1533544601,"Hi everybody,

I  work as a data scientist in a consultancy and some of my non-technical  colleagues have recently asked me for some reading recommendations to  get them up to speed on machine learning. My colleagues are mostly (IT)  management and strategy consultants, I'd say all very smart people, but  at least some of them never even took a programming class at university.  The introduction-materials I started with myself are too math-heavy and  go into too much details, managerial types are probably not that  interested in.

What material do you recommend in instances like these?",9,11
221,2018-8-6,2018,8,6,17,94zlay,Machine Learning Use Cases,https://www.reddit.com/r/MachineLearning/comments/94zlay/machine_learning_use_cases/,Jelvix,1533544628,,0,1
222,2018-8-6,2018,8,6,17,94zmzn,"[P] PyTorch implementation of Generative Query Network (GQN) from DeepMind's ""Neural Scene Representation and Rendering""",https://www.reddit.com/r/MachineLearning/comments/94zmzn/p_pytorch_implementation_of_generative_query/,inarrears,1533545249,,0,2
223,2018-8-6,2018,8,6,17,94zo16,Automatic Horizontal 4 Sides Zipper-Type Bag Packaging Machine,https://www.reddit.com/r/MachineLearning/comments/94zo16/automatic_horizontal_4_sides_zippertype_bag/,chinamachine,1533545624,,0,1
224,2018-8-6,2018,8,6,18,94zp2r,Python Tools for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/94zp2r/python_tools_for_machine_learning/,birchyio,1533546010,,0,1
225,2018-8-6,2018,8,6,19,95042x,Alibaba AI Model beats Humans In Stanford Reading Test,https://www.reddit.com/r/MachineLearning/comments/95042x/alibaba_ai_model_beats_humans_in_stanford_reading/,vidushivij,1533550878,,0,1
226,2018-8-6,2018,8,6,19,9504ip,does tensorflow-gpu or theano support the NVS5400M Graphics Card ?,https://www.reddit.com/r/MachineLearning/comments/9504ip/does_tensorflowgpu_or_theano_support_the_nvs5400m/,Nyd3r,1533550996,[removed],0,1
227,2018-8-6,2018,8,6,20,950d5a,Convolutional autoencoder to find signal that is representative of a dataset of 1D vectors,https://www.reddit.com/r/MachineLearning/comments/950d5a/convolutional_autoencoder_to_find_signal_that_is/,tryingtounderstand18,1533553618,[removed],0,1
228,2018-8-6,2018,8,6,20,950dtm,[D] #APaperADay Reading Challenge Week 3,https://www.reddit.com/r/MachineLearning/comments/950dtm/d_apaperaday_reading_challenge_week_3/,leenz2,1533553806,[removed],0,1
229,2018-8-6,2018,8,6,21,950xlb,Sources of knowledge for ML in Finance/Trading?,https://www.reddit.com/r/MachineLearning/comments/950xlb/sources_of_knowledge_for_ml_in_financetrading/,SettySatt,1533559175,[removed],0,1
230,2018-8-6,2018,8,6,22,951gk2,Source I can use to practically understand when I have chosen the right k in k-means clustering?,https://www.reddit.com/r/MachineLearning/comments/951gk2/source_i_can_use_to_practically_understand_when_i/,cybercrusader,1533563565,[removed],0,1
231,2018-8-6,2018,8,6,23,951pe6,Machine learning model suggestions,https://www.reddit.com/r/MachineLearning/comments/951pe6/machine_learning_model_suggestions/,sectechguy1,1533565450,[removed],0,1
232,2018-8-7,2018,8,7,0,95258g,"[N] Manubot, NALU, GluonCV, ml5.js, doc.ai, OpenAI Benchmark, Deep-Speare, Cyberbullying Detection,",https://www.reddit.com/r/MachineLearning/comments/95258g/n_manubot_nalu_gluoncv_ml5js_docai_openai/,omarsar,1533568640,,0,1
233,2018-8-7,2018,8,7,0,952adu,End to End framework - Lore vs ?,https://www.reddit.com/r/MachineLearning/comments/952adu/end_to_end_framework_lore_vs/,updownbam,1533569689,[removed],0,1
234,2018-8-7,2018,8,7,2,9533g8,[N] OpenAI Five Benchmark: Results,https://www.reddit.com/r/MachineLearning/comments/9533g8/n_openai_five_benchmark_results/,luiscosio,1533575284,,183,224
235,2018-8-7,2018,8,7,2,95357b,[R] Survey: the most stable method for training GANs?,https://www.reddit.com/r/MachineLearning/comments/95357b/r_survey_the_most_stable_method_for_training_gans/,feedthecreed,1533575608,"Has anything particularly robust to mode collapse and consistently converges been proposed for GANs yet?

What are your favorite GAN tricks?
",11,14
236,2018-8-7,2018,8,7,2,953e02,[R][BAIR] When Recurrent Models Don't Need to be Recurrent,https://www.reddit.com/r/MachineLearning/comments/953e02/rbair_when_recurrent_models_dont_need_to_be/,downtownslim,1533577252,,6,41
237,2018-8-7,2018,8,7,3,953m0d,The 9 best Talks on Machine Learning at SciPy 2018,https://www.reddit.com/r/MachineLearning/comments/953m0d/the_9_best_talks_on_machine_learning_at_scipy_2018/,PythonLinksDotInfo,1533578704,,0,1
238,2018-8-7,2018,8,7,3,953rw6,"[P] Text Mining - Try Resumio, our Telegram Bot to create summaries",https://www.reddit.com/r/MachineLearning/comments/953rw6/p_text_mining_try_resumio_our_telegram_bot_to/,alfileres1,1533579810,"Resumio is a Telegram Bot that creates a summary from a web article. Just copy &amp; paste the url or share the url with Resumio and you will get back a 4-paragraphs summary [https://telegram.me/ResumioBot](https://telegram.me/ResumioBot)

It fetches the article, gets the text and performs TextRank on it. TextRank builds a graph where nodes are the sentences and the edges between nodes are the tfidf distances. Then it uses PageRank to discover which are the most important nodes. This is the summary.

The summary is extractive, meaning that it does the summary by extracting sentences (e.g. like highlighting the most useful parts of the article).",2,0
239,2018-8-7,2018,8,7,3,953veo,[D] Towards automating machine learning - Dr Thorben Jensen,https://www.reddit.com/r/MachineLearning/comments/953veo/d_towards_automating_machine_learning_dr_thorben/,_quanttrader_,1533580475,,0,1
240,2018-8-7,2018,8,7,3,953zpc,Algorithms and high performance computing tickle your fancy?,https://www.reddit.com/r/MachineLearning/comments/953zpc/algorithms_and_high_performance_computing_tickle/,TechCareers,1533581283,[removed],0,1
241,2018-8-7,2018,8,7,4,954d14,Newbie Question regarding probability of an event in given time frame,https://www.reddit.com/r/MachineLearning/comments/954d14/newbie_question_regarding_probability_of_an_event/,RAWhephaistos,1533583798,[removed],1,1
242,2018-8-7,2018,8,7,5,954ty6,[R] Interaction-aware Spatio-temporal Pyramid Attention Networks for Action Classification,https://www.reddit.com/r/MachineLearning/comments/954ty6/r_interactionaware_spatiotemporal_pyramid/,MediumInterview,1533587019,,1,7
243,2018-8-7,2018,8,7,6,955ire,[D] pyGAM: balancing interpretability and predictive power using... - Dani Servn Marn,https://www.reddit.com/r/MachineLearning/comments/955ire/d_pygam_balancing_interpretability_and_predictive/,_quanttrader_,1533591817,,0,1
244,2018-8-7,2018,8,7,6,955njs,[R] One-Shot Imitation from Watching Videos,https://www.reddit.com/r/MachineLearning/comments/955njs/r_oneshot_imitation_from_watching_videos/,MediumInterview,1533592754,,1,16
245,2018-8-7,2018,8,7,7,955pdk,"[N] Pentagon Rolls Out Major Cyber, AI Strategies This Summer",https://www.reddit.com/r/MachineLearning/comments/955pdk/n_pentagon_rolls_out_major_cyber_ai_strategies/,calebh,1533593113,,3,14
246,2018-8-7,2018,8,7,7,9561o2,When to apply time series models?,https://www.reddit.com/r/MachineLearning/comments/9561o2/when_to_apply_time_series_models/,UnlikelyLow,1533595624,"When should I apply traditional time series models (e.g. additive, ARIMA) versus other models such as linear regression?

For example, if I wanted to build a predictive model for website traffic, I could approach it with:

1. Use previous traffic data + time series technique like exponential smoothing
2. Collect other data features such as advertising spend, social media activity, email campaigns and run a linear regression model

The former approach is more straight forward, faster to implement and likely to fit better compared to the latter. What disadvantages am I not taking into account here?

The only thing I'm coming up with is that approach #2 will provide some insight into the weighting of the feature data (e.g. relationship between ad spend and traffic).",0,1
247,2018-8-7,2018,8,7,7,956400,[N] Boston Dynamics Is Getting Ready to Produce Lots of SpotMinis,https://www.reddit.com/r/MachineLearning/comments/956400/n_boston_dynamics_is_getting_ready_to_produce/,baylearn,1533596117,,11,34
248,2018-8-7,2018,8,7,8,956922,How do you draw Neural Networks effectively while learning them?,https://www.reddit.com/r/MachineLearning/comments/956922/how_do_you_draw_neural_networks_effectively_while/,Robot_Tumas,1533597170,[removed],0,1
249,2018-8-7,2018,8,7,8,956e4y,"[P] Wolpert, stacked ensemble framework",https://www.reddit.com/r/MachineLearning/comments/956e4y/p_wolpert_stacked_ensemble_framework/,caio__oliveira,1533598247,"I wrote this library to build stacked ensembles with a scikit-learn compatible API and just released a beta version of it. Feedback is appreciated :) 

The project: [http://github.com/caioaao/wolpert](http://github.com/caioaao/wolpert)

The docs: [http://wolpert.readthedocs.io](http://wolpert.readthedocs.io)

A little post I made showing how to implement a famous paper using wolpert: [https://medium.com/@caioaao/stacked-regressions-using-wolpert-aa461a7342aa](https://medium.com/@caioaao/stacked-regressions-using-wolpert-aa461a7342aa)",3,8
250,2018-8-7,2018,8,7,9,956xg0,Titan V's Arrived in Force!,https://www.reddit.com/r/MachineLearning/comments/956xg0/titan_vs_arrived_in_force/,Simusid,1533602574,,1,1
251,2018-8-7,2018,8,7,10,957e91,Automatic Horizontal 4 Sides Zipper-Type Bag Packaging Machine,https://www.reddit.com/r/MachineLearning/comments/957e91/automatic_horizontal_4_sides_zippertype_bag/,chinamachine,1533606474,,0,1
252,2018-8-7,2018,8,7,11,957ldl,A Key Redesign for AI and Blockchain Unleashes Their Full Potential.,https://www.reddit.com/r/MachineLearning/comments/957ldl/a_key_redesign_for_ai_and_blockchain_unleashes/,mataleo,1533608134,,0,1
253,2018-8-7,2018,8,7,12,9585c9,[D] How do you see Quantum Computing effecting ML (if at all),https://www.reddit.com/r/MachineLearning/comments/9585c9/d_how_do_you_see_quantum_computing_effecting_ml/,jellysnake,1533612889,"***Disclaimer:** My knowledge of ML is limited to basic understanding from assorted videos, skimming items in this sub, and general public knowledge.*  
*I apologize if this is a dumb question to ask.*

I was wondering if anyone here knows of any impact that having a fully functioning Quantum Computer would have on ML? Assuming we were at the stage where most research facilities would have one?",42,42
254,2018-8-7,2018,8,7,13,958o8p,"Optical Network Unit (ONU) Market is Predicted To Grow at 7.31% CAGR | Global Industry Size, Share, Growth, Trends and Forecasts 2023",https://www.reddit.com/r/MachineLearning/comments/958o8p/optical_network_unit_onu_market_is_predicted_to/,priyankaw,1533617661,,0,1
255,2018-8-7,2018,8,7,15,9596v4,[P] Modular Pytorch Implementation for custom attention+hierarchical attention models ) for visual question answering along with live-demo and experimentation details.,https://www.reddit.com/r/MachineLearning/comments/9596v4/p_modular_pytorch_implementation_for_custom/,diligentprocrastinar,1533623082,,0,1
256,2018-8-7,2018,8,7,16,959hjs,Should I report ROC or concave envelope of ROC,https://www.reddit.com/r/MachineLearning/comments/959hjs/should_i_report_roc_or_concave_envelope_of_roc/,pevnak,1533626311,[removed],0,1
257,2018-8-7,2018,8,7,16,959ko9,How Artificial Intelligence Will Save Us From Epic Stock Market Failures?,https://www.reddit.com/r/MachineLearning/comments/959ko9/how_artificial_intelligence_will_save_us_from/,amberstevens311,1533627317,[removed],0,1
258,2018-8-7,2018,8,7,16,959noc,The Moral Responsibility of Artificial Intelligence System,https://www.reddit.com/r/MachineLearning/comments/959noc/the_moral_responsibility_of_artificial/,amberstevens311,1533628342,[removed],0,1
259,2018-8-7,2018,8,7,16,959oky,Can you help me make a list of companies that use machine learning to help a good cause?,https://www.reddit.com/r/MachineLearning/comments/959oky/can_you_help_me_make_a_list_of_companies_that_use/,WishFor_a_Dog,1533628642,[removed],0,1
260,2018-8-7,2018,8,7,17,959rb5,[D] Make a NN that finds the standard deviation of X?,https://www.reddit.com/r/MachineLearning/comments/959rb5/d_make_a_nn_that_finds_the_standard_deviation_of_x/,ME_PhD,1533629559,"I cannot do it. Given X in R^n, create a forward network f such that f(X) = stdev(X).

I tried a 20 layer deep and 25 wide and still it cannot fit the stdev function at all. It's not surprising but I don't think it's possible to make a mapping R^n to R from X to  stdev(X). Is this true or does anyone have ideas?",16,0
261,2018-8-7,2018,8,7,17,959szu,The Moral Responsibility of Artificial Intelligence System,https://www.reddit.com/r/MachineLearning/comments/959szu/the_moral_responsibility_of_artificial/,amberstevens311,1533630133,[removed],0,1
262,2018-8-7,2018,8,7,17,959wim,How Machine Learning Can Help The Security Industry?,https://www.reddit.com/r/MachineLearning/comments/959wim/how_machine_learning_can_help_the_security/,amberstevens311,1533631367,[removed],0,1
263,2018-8-7,2018,8,7,18,95a7cx,Need guidance in order to pursue a career in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/95a7cx/need_guidance_in_order_to_pursue_a_career_in/,anonymous_guyy,1533634949,[removed],0,1
264,2018-8-7,2018,8,7,19,95ac5j,[R] CIKM 2018 reviews,https://www.reddit.com/r/MachineLearning/comments/95ac5j/r_cikm_2018_reviews/,borbag,1533636495,How were your reviews? ,8,11
265,2018-8-7,2018,8,7,19,95agbs,[P] Building a Matrix with reinforcement learning and artificial imagination,https://www.reddit.com/r/MachineLearning/comments/95agbs/p_building_a_matrix_with_reinforcement_learning/,AnnaKow,1533637760,,0,1
266,2018-8-7,2018,8,7,19,95ai1r,Horizontal 4-side seal Pregnancy Test Kit Packaging machine-for patches...,https://www.reddit.com/r/MachineLearning/comments/95ai1r/horizontal_4side_seal_pregnancy_test_kit/,chinamachine,1533638285,,0,1
267,2018-8-7,2018,8,7,19,95aj0r,[D] Question about Thorsten's 2016 paper on using propensity in LTR problems,https://www.reddit.com/r/MachineLearning/comments/95aj0r/d_question_about_thorstens_2016_paper_on_using/,jasons0219,1533638550,"Paper that I'm talking about : [https://arxiv.org/abs/1608.04468](https://arxiv.org/abs/1608.04468)

I understand that propensity weighting could potentially be used with any click model and any LTR algorithms, which I think is one of the main research field Thorsten's lab is working on.

However, the whole point of removing bias from implicit feedback stems from wanting to retrieve ""objective"" relevance labels for &lt;query, document&gt; pairs. The paper above implements a simple propensity-weighted SVM ranker based on a simple PBM click model, but seems to use data that is already pair-wise labeled based on some kind of relevance score.

Am I misunderstanding something or does the paper assume that we already have relevance labels and want to formulate a better bias correcting LTR algorithm?",0,2
268,2018-8-7,2018,8,7,19,95akdn,[D] How deep should be the knowledge of statistics to excel in ML?,https://www.reddit.com/r/MachineLearning/comments/95akdn/d_how_deep_should_be_the_knowledge_of_statistics/,hawksejmm,1533638974," Jason Brownlee just released a mini course where we covers statistics for machine learning.

In this course, he talks about distributions, hypothesis test, correlation, etc. What other statistics concepts a machine learning engineer should have in-depth knowledge to excel in the area? Do you think that a data scientists should be more into statistics that an ML engineer?

[https://machinelearningmastery.com/statistics-for-machine-learning-mini-course/](https://machinelearningmastery.com/statistics-for-machine-learning-mini-course/)",58,73
269,2018-8-7,2018,8,7,22,95bivg,Working with more than one dummy variable in neural net.,https://www.reddit.com/r/MachineLearning/comments/95bivg/working_with_more_than_one_dummy_variable_in/,sectechguy1,1533647688,[removed],0,1
270,2018-8-7,2018,8,7,22,95bka6,[D] Is it possible to have correlated columns in the training set for unsupervised learning?,https://www.reddit.com/r/MachineLearning/comments/95bka6/d_is_it_possible_to_have_correlated_columns_in/,ds_buns,1533648009,"I recall that columns that are highly correlated shouldn't be included in supervised learning or it is basically not giving new information.... Does this apply for unsupervised learning as well? (Specifically-- k-means clustering)

For example, if I have a column ""how much a person spends on food"" and ""how much a person spends on rent"",

1. Can I feature engineer a column for ""$food / $rent"" ?  (essentially a ratio)
2. Can I also add a boolean column for when ""$food / $rent"" &lt; 10% ?  Or would this be redundant and not contribute to the model?

Thanks for help! ",5,7
271,2018-8-7,2018,8,7,22,95bkw1,"Former Microsoft software engineer now applying inverse covariance matrix and pseudo-likelihood ML methods to windpower, finance, influenza spread predictions and other problems",https://www.reddit.com/r/MachineLearning/comments/95bkw1/former_microsoft_software_engineer_now_applying/,greenprius,1533648153,,0,1
272,2018-8-7,2018,8,7,22,95bq00,[D] Rebuttal for NIPS,https://www.reddit.com/r/MachineLearning/comments/95bq00/d_rebuttal_for_nips/,UnfairHorror,1533649247,This is my first time using the CMT system. Is it normal that I can't see the file with my response in the system anymore?,6,17
273,2018-8-7,2018,8,7,22,95btfg,Top Data Science Online Courses in 2018,https://www.reddit.com/r/MachineLearning/comments/95btfg/top_data_science_online_courses_in_2018/,ANNA_Systems,1533649970,,0,1
274,2018-8-8,2018,8,8,0,95cga5,SOS we need rich data in consumer agriculture.,https://www.reddit.com/r/MachineLearning/comments/95cga5/sos_we_need_rich_data_in_consumer_agriculture/,kr3wn,1533654593,[removed],0,1
275,2018-8-8,2018,8,8,0,95ck4j,Google Next 2018: A deeper dive on AI and machine learning advances | ZDNet,https://www.reddit.com/r/MachineLearning/comments/95ck4j/google_next_2018_a_deeper_dive_on_ai_and_machine/,datanerd840,1533655326,,0,1
276,2018-8-8,2018,8,8,0,95clhn,Prevent overfitting with multiple error functions,https://www.reddit.com/r/MachineLearning/comments/95clhn/prevent_overfitting_with_multiple_error_functions/,LeanderKu,1533655586,[removed],0,1
277,2018-8-8,2018,8,8,0,95cn6m,[D] Prevent premature overfitting with multiple error functions,https://www.reddit.com/r/MachineLearning/comments/95cn6m/d_prevent_premature_overfitting_with_multiple/,LeanderKu,1533655908,"I have an NN that is trained on a Loss-Function that is composed of multiple (I have 2) Error-Functions. I have got a strong suspicion the NN is overfitting on Problem 1 before Problem 2 is properly solved, but it is, unfortunately, hard to evaluate (I can't directly measure it[1]). Is there any research on how to approximately balance the training in such a scenario without an explicit computation of overfitting?
[1] One optimizes the Type I and one type II errors of my problem. Both are hard to actually evalute.",11,3
278,2018-8-8,2018,8,8,0,95crbq,Benchmarking TF on CPU/GPU and TPU,https://www.reddit.com/r/MachineLearning/comments/95crbq/benchmarking_tf_on_cpugpu_and_tpu/,jthat92,1533656682,[removed],0,1
279,2018-8-8,2018,8,8,0,95ctp2,[R] Detailed Dense Inference with Convolutional Neural Networks via Discrete Wavelet Transform,https://www.reddit.com/r/MachineLearning/comments/95ctp2/r_detailed_dense_inference_with_convolutional/,MediumInterview,1533657138,,1,5
280,2018-8-8,2018,8,8,1,95czh0,Complete Machine Learning Fundamentals in less than 5 minutes,https://www.reddit.com/r/MachineLearning/comments/95czh0/complete_machine_learning_fundamentals_in_less/,thereflective,1533658212,"[https://www.youtube.com/channel/UCo5DZgCa5n6Hzc0tIX\_Ot7w](https://www.youtube.com/channel/UCo5DZgCa5n6Hzc0tIX_Ot7w)

Complete Machine Learning Fundamentals in less than 5 minutes

Easy ways to get through the machine learning fundamentals in really less time and you will learn in super fast ",0,1
281,2018-8-8,2018,8,8,1,95d3kz,Using Machine Learning AI into sports console games,https://www.reddit.com/r/MachineLearning/comments/95d3kz/using_machine_learning_ai_into_sports_console/,hahysi2030,1533659004,"When I was playing FIFA 18, I was just wondering that if, one day, we can play our own team with machine learning AI systems to play my team that constantly learn my style of playing and work as I predict. It will bring more fun of playing sports games!",0,1
282,2018-8-8,2018,8,8,1,95d99y,How to generate more than 1 output per input in LSTM?,https://www.reddit.com/r/MachineLearning/comments/95d99y/how_to_generate_more_than_1_output_per_input_in/,lcukerd,1533660120,"Assume this is my model:

    _________________________________________________________________  Layer (type)                 Output Shape              Param #    =================================================================  embedding_16 (Embedding)     (None, 10, 500)          71500      _________________________________________________________________  lstm_31 (LSTM)               (None, 10, 500)          2002000    _________________________________________________________________  dropout_15 (Dropout)         (None, 10, 500)          0          _________________________________________________________________  time_distributed_16          (None, 10, 500)          250500    _________________________________________________________________  softmax (Activation)         (None, 10, 500)           0     ================================================================= 

But I want to have in my last layer:

    softmax (Activation)         (None, 100, 1000)           0     ================================================================= 

I have been trying to do this for hours. I don't know if this is possible or not. I don't think you can change output size of LSTM (looking at its model) but is there a layer that i can add so that it generates , say, 10 ouputs per input?

In simple words, assume I want to my model to generate 10 words for each word i put in. I hope I am able to explain.",0,1
283,2018-8-8,2018,8,8,2,95ds0u,[P] CycleGAN Bikini Fix for Nudes,https://www.reddit.com/r/MachineLearning/comments/95ds0u/p_cyclegan_bikini_fix_for_nudes/,gwen0927,1533663584,,0,1
284,2018-8-8,2018,8,8,2,95duur,[N] The Defense Department has produced the first tools for catching deepfakes,https://www.reddit.com/r/MachineLearning/comments/95duur/n_the_defense_department_has_produced_the_first/,cryptoz,1533664113,,28,249
285,2018-8-8,2018,8,8,2,95dyb7,Passive Income Ideas?,https://www.reddit.com/r/MachineLearning/comments/95dyb7/passive_income_ideas/,Mackelday,1533664764,[removed],0,1
286,2018-8-8,2018,8,8,3,95e7pv,Use of Artificial Intelligence and Machine Learning in Marketing,https://www.reddit.com/r/MachineLearning/comments/95e7pv/use_of_artificial_intelligence_and_machine/,Rasmus121,1533666508,,0,1
287,2018-8-8,2018,8,8,3,95ed41,Character-To-Character RNN With Pytorchs LSTMCell  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/95ed41/charactertocharacter_rnn_with_pytorchs_lstmcell/,coinmonks,1533667512,,0,1
288,2018-8-8,2018,8,8,4,95emss,[R] Unsupervised Learning of a Hierarchical Spiking Neural Network for Optical Flow Estimation: From Events to Global Motion Perception,https://www.reddit.com/r/MachineLearning/comments/95emss/r_unsupervised_learning_of_a_hierarchical_spiking/,feddddo,1533669276,,2,18
289,2018-8-8,2018,8,8,4,95en54,DeepDribble: Simulating Basketball with AI,https://www.reddit.com/r/MachineLearning/comments/95en54/deepdribble_simulating_basketball_with_ai/,awuwp,1533669346,,0,3
290,2018-8-8,2018,8,8,4,95eoyb,#Repost @juliancanderson (@get_repost)  20/100 #100DaysOfCode Another busy day at the bootcamp. A lot of tasks to do today and I think it will be everyday  Today I learnt about sorting algorithm and found out that there are a lot of sorting algorithms out there. In javascript there is a built i,https://www.reddit.com/r/MachineLearning/comments/95eoyb/repost_juliancanderson_get_repost_20100/,cloudmax_,1533669699,,0,0
291,2018-8-8,2018,8,8,4,95eslp,Systems for Auditing/Review Neural Network Detections,https://www.reddit.com/r/MachineLearning/comments/95eslp/systems_for_auditingreview_neural_network/,clifgray,1533670358,[removed],0,1
292,2018-8-8,2018,8,8,4,95et15,[D] Tools for Reviewing/Auditing Neural Net Detections,https://www.reddit.com/r/MachineLearning/comments/95et15/d_tools_for_reviewingauditing_neural_net/,clifgray,1533670439,"I'm using this keras based implementation of [RetinaNet](https://github.com/fizyr/keras-retinanet) and I've found it really well designed and maintained but I'm now getting thousands of detections, many of which are false positives, and I'm curious if y'all have suggestions for tools or methods for reviewing the results from a CNN?

I've been using the [VGG Image Annotator](http://www.robots.ox.ac.uk/~vgg/software/via/) to create my labeled training data and I'm considering using that to go through review the detections too but I wanted to see what everyone suggests and if there are any rapid tools for reviewing the results from a neural net. 

I'm also considering building something custom in python to go through and mark detections as correct or incorrect but wanted to check landscape beforehand.",0,2
293,2018-8-8,2018,8,8,4,95ey8w,I created a search engine for my science channel which currently works by just finding keywords in the script that match the querys keywords.But I want to use tensorflow to understand the deeper meaning behind queries and find results based on that but idk where to start,https://www.reddit.com/r/MachineLearning/comments/95ey8w/i_created_a_search_engine_for_my_science_channel/,TheScienceVerse,1533671414,,0,1
294,2018-8-8,2018,8,8,5,95f91g,[P] CycleGAN Bikini Fix for Nudes,https://www.reddit.com/r/MachineLearning/comments/95f91g/p_cyclegan_bikini_fix_for_nudes/,trcytony,1533673429,,0,1
295,2018-8-8,2018,8,8,6,95fmvl,"Doomsday, or BADA-boomsday?",https://www.reddit.com/r/MachineLearning/comments/95fmvl/doomsday_or_badaboomsday/,WordsofHers,1533676016,,0,1
296,2018-8-8,2018,8,8,6,95ft1j,[D] Are OpenAI codes difficult to read or is it just me,https://www.reddit.com/r/MachineLearning/comments/95ft1j/d_are_openai_codes_difficult_to_read_or_is_it/,schrodingershit,1533677191,"Lately I have been exploring OpenAI baselines and MADDPG code both from OpenAI and the only thing I have been able to deduce from this effort is that their code is extremely difficult to change.  Code is highly coupled. Super fancy methods have been written to prove God knows but, but readability is not one of those. I am trying just only tiny bit of change(i.e concatenation) and I have not been able to do that in MADDPG code. I wonder is it me or their implementations are difficult to understand",41,127
297,2018-8-8,2018,8,8,6,95g2mu,Autoencoder ambivalent about order of input data?,https://www.reddit.com/r/MachineLearning/comments/95g2mu/autoencoder_ambivalent_about_order_of_input_data/,to_the_sun,1533679066,[removed],0,1
298,2018-8-8,2018,8,8,7,95g6mj,Autoencoder ambivalent about order of input data?,https://www.reddit.com/r/MachineLearning/comments/95g6mj/autoencoder_ambivalent_about_order_of_input_data/,to_the_sun,1533679846,,1,1
299,2018-8-8,2018,8,8,8,95gps2,[P] RemoteML V2: Remote Machine Learning Jobs &amp; Community,https://www.reddit.com/r/MachineLearning/comments/95gps2/p_remoteml_v2_remote_machine_learning_jobs/,dqmonn,1533683928,,7,15
300,2018-8-8,2018,8,8,9,95h8l4,Any Entertaining Youtube Channels that constantly Upload Neural Network Experiments and Simulations?,https://www.reddit.com/r/MachineLearning/comments/95h8l4/any_entertaining_youtube_channels_that_constantly/,IoSonoFormaggio,1533688166,\[removed\],0,1
301,2018-8-8,2018,8,8,9,95hfzb,"[D] When people say they've trained an A.I. to play a game by playing against itself thousands of times, how is this done in practice?",https://www.reddit.com/r/MachineLearning/comments/95hfzb/d_when_people_say_theyve_trained_an_ai_to_play_a/,SlimesWithBowties,1533689849,"To clarify, how does the A.I. actually learn from itself and know how to improve if the only thing it can compare itself to is itself? (If that makes sense...)",6,0
302,2018-8-8,2018,8,8,10,95hm1l,4 side seal flow wrapper (HFFS),https://www.reddit.com/r/MachineLearning/comments/95hm1l/4_side_seal_flow_wrapper_hffs/,chinamachine,1533691275,\[removed\],0,1
303,2018-8-8,2018,8,8,10,95hpa0,4 side seal packing machine,https://www.reddit.com/r/MachineLearning/comments/95hpa0/4_side_seal_packing_machine/,chinamachine,1533692033,\[removed\],0,1
304,2018-8-8,2018,8,8,10,95hqi4,[P] Here's a simple program I wrote to generate abstract art using CPPNs and a user directed genetic algorithm using Pytorch that you can try!,https://www.reddit.com/r/MachineLearning/comments/95hqi4/p_heres_a_simple_program_i_wrote_to_generate/,jutemachine,1533692311,,0,1
305,2018-8-8,2018,8,8,11,95hzbk,Generate text using an RNN for cheap like the olive garden tweet,https://www.reddit.com/r/MachineLearning/comments/95hzbk/generate_text_using_an_rnn_for_cheap_like_the/,MachineML,1533694369,[Click Here!](https://www.fiverr.com/fineprogrammer/use-machine-learning-to-make-text-similar-to-the-olive-garden-tweet) ,0,1
306,2018-8-8,2018,8,8,11,95i0oy,Looking for help with LSTM implementation,https://www.reddit.com/r/MachineLearning/comments/95i0oy/looking_for_help_with_lstm_implementation/,timwalsh41,1533694686,\[removed\],0,1
307,2018-8-8,2018,8,8,11,95i5ql,Looking For Advice,https://www.reddit.com/r/MachineLearning/comments/95i5ql/looking_for_advice/,TricksterDTM,1533695892,\[removed\],0,1
308,2018-8-8,2018,8,8,12,95im9n,Looking for recent paper about NN model making maths,https://www.reddit.com/r/MachineLearning/comments/95im9n/looking_for_recent_paper_about_nn_model_making/,ML_machine,1533699886,\[removed\],0,1
309,2018-8-8,2018,8,8,13,95iwzy,[D] Neural Network Visualization and Interaction,https://www.reddit.com/r/MachineLearning/comments/95iwzy/d_neural_network_visualization_and_interaction/,tobyclh,1533702618,"I am looking for visualization library of neural network, which I can use to monitor training process (how parameters change through time) and interactively (put in arbitrary data, get output as well as all intermediate layers response for examination). I suspect this can be done and should be many libraries out there doing it, but I simply cannot find any.

Meanwhile, here are some libraries I have found, not don't really suit my need but seems solid.

1. [Visualization for Keras](https://github.com/Prodicode/ann-visualizer)  
(seems to only support some very basic operations, isn't interactive)

2.  [A Neural Network playground](https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.62967&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false)  
More interactive, but as the name suggest only a playground

To this end I have 2 questions,

1. Is there any library that is practical for monitoring training of parameters?
2. If I were to build a library for debugging and monitoring, what feature would be beneficial to you and why? 

Cheers",10,21
310,2018-8-8,2018,8,8,13,95ix1b,[N] Facebook provides $4M in funding to new African Masters In Machine Intelligence,https://www.reddit.com/r/MachineLearning/comments/95ix1b/n_facebook_provides_4m_in_funding_to_new_african/,MediumInterview,1533702630,,2,28
311,2018-8-8,2018,8,8,14,95j77b,[R] MCRM: Mother Compact Recurrent Memory A Biologically Inspired Recurrent Neural Network Architecture,https://www.reddit.com/r/MachineLearning/comments/95j77b/r_mcrm_mother_compact_recurrent_memory_a/,AbduallahM,1533705478,\[removed\],0,2
312,2018-8-8,2018,8,8,15,95jg3z,[D] Is it alright to use TF or Keras rather than coding everything from scratch?,https://www.reddit.com/r/MachineLearning/comments/95jg3z/d_is_it_alright_to_use_tf_or_keras_rather_than/,AnEccentricScientist,1533708138,"Im a beginner to ML . I have been seeing on online courses and even on Kaggle Competitions kernel pages that people use TF or Keras to skip coding convolution ,max-pooling etc .is this way of skipping the low level work a common practice or does this have some disadvantages?  
Forgive my lack of knowledge if im saying something without adequate research.",3,1
313,2018-8-8,2018,8,8,15,95jien,[N] Worrying! Someone just used a Drone to try to Assassinate a World Leader,https://www.reddit.com/r/MachineLearning/comments/95jien/n_worrying_someone_just_used_a_drone_to_try_to/,svaisakh,1533708803,,0,1
314,2018-8-8,2018,8,8,15,95jj9n,[P] Regression Connectome for Homogenous Prediction Environment,https://www.reddit.com/r/MachineLearning/comments/95jj9n/p_regression_connectome_for_homogenous_prediction/,paubric,1533709060,,0,1
315,2018-8-8,2018,8,8,16,95jxqc,How do col2im works in CNN?,https://www.reddit.com/r/MachineLearning/comments/95jxqc/how_do_col2im_works_in_cnn/,eric01300,1533713428,\[removed\],0,1
316,2018-8-8,2018,8,8,16,95jxz1,28 Expert Opinions Every Business Leader Should Know About Enterprise AI,https://www.reddit.com/r/MachineLearning/comments/95jxz1/28_expert_opinions_every_business_leader_should/,aditya44,1533713505,,0,1
317,2018-8-8,2018,8,8,16,95jyrt,Links to Computer Vision News of August,https://www.reddit.com/r/MachineLearning/comments/95jyrt/links_to_computer_vision_news_of_august/,Gletta,1533713780,\[removed\],0,1
318,2018-8-8,2018,8,8,16,95jzox,"Help please. A bit late to the GAN party. What is the most effective way to level up to state of the art understanding? So many papers out there, I don't know where to start.",https://www.reddit.com/r/MachineLearning/comments/95jzox/help_please_a_bit_late_to_the_gan_party_what_is/,the_3bodyproblem,1533714078,\[removed\],0,1
319,2018-8-8,2018,8,8,16,95k0ag,[D] How do col2im work in CNN?,https://www.reddit.com/r/MachineLearning/comments/95k0ag/d_how_do_col2im_work_in_cnn/,eric01300,1533714270,"I've heard that functions such as im2col and col2im are used to speed up the computation in Convolutional layer. So I've checked the implementation in [https://github.com/huyouare/CS231n/blob/master/assignment2/cs231n/im2col.py](https://github.com/huyouare/CS231n/blob/master/assignment2/cs231n/im2col.py).

I thought during the backward pass, we calculate dx\_col (col vector of input x), and reshape it through col2im. However, according to [https://stackoverflow.com/questions/51703367/col2im-implementation-in-convnet/51717536?noredirect=1#comment90434938\_51717536](https://stackoverflow.com/questions/51703367/col2im-implementation-in-convnet/51717536?noredirect=1#comment90434938_51717536), col2im's job was to add the cols in an appropriate position, not to recreate X from X\_col.

Am I understanding something wrong about the backpropagation part in CNN using col2im?",1,2
320,2018-8-8,2018,8,8,16,95k0ph,[N] Links to Computer Vision News of August,https://www.reddit.com/r/MachineLearning/comments/95k0ph/n_links_to_computer_vision_news_of_august/,Gletta,1533714408,"Here is the August 2018 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: 32 pages worth reading, about Artificial Intelligence, Deep Learning, Image Processing and Computer Vision. Technical review of new technologies at page 4 and free subscription at page 32.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2018August/) 

[PDF version](http://www.rsipvision.com/computer-vision-news-2018-august-pdf/)

Enjoy!",0,2
321,2018-8-8,2018,8,8,16,95k2eo,Best Five Machine Learning Courses Online -Big Data Analytics News,https://www.reddit.com/r/MachineLearning/comments/95k2eo/best_five_machine_learning_courses_online_big/,Veerans,1533714997,,0,1
322,2018-8-8,2018,8,8,17,95k3mj,Neural Network to replace text on images like Google Translate,https://www.reddit.com/r/MachineLearning/comments/95k3mj/neural_network_to_replace_text_on_images_like/,dafukami,1533715409,\[removed\],0,1
323,2018-8-8,2018,8,8,17,95k3nn,Ideas for a Bachelor's degree thesis in machine learning ?,https://www.reddit.com/r/MachineLearning/comments/95k3nn/ideas_for_a_bachelors_degree_thesis_in_machine/,dung3z,1533715420,\[removed\],0,1
324,2018-8-8,2018,8,8,17,95k4ra,[D] How is YOLO a great advancement over Overfeat,https://www.reddit.com/r/MachineLearning/comments/95k4ra/d_how_is_yolo_a_great_advancement_over_overfeat/,Eoncarry,1533715784,"From what I understand, If stride of overfeat = length of sliding window (so that sliding windows don't overlap), and in Yolo number of anchor boxes=1, Overfeat and YOLO are basically doing the same thing. I don't get what YOLO is doing different?",2,12
325,2018-8-8,2018,8,8,17,95k5al,Elmo embeddings - Vocab,https://www.reddit.com/r/MachineLearning/comments/95k5al/elmo_embeddings_vocab/,tadeuszjasina,1533715973,\[removed\],0,1
326,2018-8-8,2018,8,8,17,95k7w8,Storage options for data,https://www.reddit.com/r/MachineLearning/comments/95k7w8/storage_options_for_data/,jetjodh,1533716842,\[removed\],0,1
327,2018-8-8,2018,8,8,18,95kg93,"[R] MLReview Digest: Bandit Algorithms Book, Deep Video Portraits, Human Pose Estimation Using WiFi, Multi-Modal Methods, CVPR 2018",https://www.reddit.com/r/MachineLearning/comments/95kg93/r_mlreview_digest_bandit_algorithms_book_deep/,fooboss,1533719732,,0,5
328,2018-8-8,2018,8,8,18,95khrj,What about chatbot?,https://www.reddit.com/r/MachineLearning/comments/95khrj/what_about_chatbot/,spoulimen,1533720219,\[removed\],0,1
329,2018-8-8,2018,8,8,18,95kk5u,Help modeling LSTM network,https://www.reddit.com/r/MachineLearning/comments/95kk5u/help_modeling_lstm_network/,ravaan,1533721009,\[removed\],0,1
330,2018-8-8,2018,8,8,18,95kkd2,Top 5 Machine Learning industrial applications,https://www.reddit.com/r/MachineLearning/comments/95kkd2/top_5_machine_learning_industrial_applications/,DianaMaltseva,1533721060,,0,1
331,2018-8-8,2018,8,8,18,95kmtz,DataScience Digest - Issue #14,https://www.reddit.com/r/MachineLearning/comments/95kmtz/datascience_digest_issue_14/,flyelephant,1533721845,,0,1
332,2018-8-8,2018,8,8,19,95ksv5,[D] Learning Meaning from Raw Text in NLP - A Discussion,https://www.reddit.com/r/MachineLearning/comments/95ksv5/d_learning_meaning_from_raw_text_in_nlp_a/,Thomjazz,1533723690,,0,1
333,2018-8-8,2018,8,8,19,95kuai,Any dataset for multi intent classification?,https://www.reddit.com/r/MachineLearning/comments/95kuai/any_dataset_for_multi_intent_classification/,SaviniSenla,1533724151,,0,1
334,2018-8-8,2018,8,8,19,95kuyx,How do I learn efficiently about machine learning ?,https://www.reddit.com/r/MachineLearning/comments/95kuyx/how_do_i_learn_efficiently_about_machine_learning/,Hot_Ices,1533724358,\[removed\],0,1
335,2018-8-8,2018,8,8,19,95kw92,[P] TensorFlow C API on Windows without pain.,https://www.reddit.com/r/MachineLearning/comments/95kw92/p_tensorflow_c_api_on_windows_without_pain/,Neargye,1533724763,,1,3
336,2018-8-8,2018,8,8,20,95l1qm,Multi Label Intent Classification  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/95l1qm/multi_label_intent_classification_coinmonks_medium/,coinmonks,1533726414,,0,1
337,2018-8-8,2018,8,8,21,95lmn6,Where do you actually use linear algebra and other mathematics?,https://www.reddit.com/r/MachineLearning/comments/95lmn6/where_do_you_actually_use_linear_algebra_and/,Radon-Nikodym,1533731898,\[removed\],0,1
338,2018-8-8,2018,8,8,21,95lnr2,Pedestrian prediction,https://www.reddit.com/r/MachineLearning/comments/95lnr2/pedestrian_prediction/,Tessavdheiden,1533732170,\[removed\],0,1
339,2018-8-8,2018,8,8,21,95lo0b,[R] TDLS: Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond,https://www.reddit.com/r/MachineLearning/comments/95lo0b/r_tdls_abstractive_text_summarization_using/,machinetrainer,1533732241,,4,23
340,2018-8-8,2018,8,8,22,95lxxk,Azure Customvision (AKA TensorFlow Object Detection) Basic Question,https://www.reddit.com/r/MachineLearning/comments/95lxxk/azure_customvision_aka_tensorflow_object/,latitudehopper,1533734467,\[removed\],0,1
341,2018-8-8,2018,8,8,22,95ly0z,[P] Learn ML Algorithms by coding: Decision Trees,https://www.reddit.com/r/MachineLearning/comments/95ly0z/p_learn_ml_algorithms_by_coding_decision_trees/,juror-number-8,1533734486,,0,39
342,2018-8-8,2018,8,8,22,95m27y,Having trouble understanding a paper (CoFiRank) -- help wanted,https://www.reddit.com/r/MachineLearning/comments/95m27y/having_trouble_understanding_a_paper_cofirank/,asdfwaevc,1533735419,\[removed\],0,1
343,2018-8-8,2018,8,8,22,95m75b,What services do you use for data labeling? We are building one and need your inputs.,https://www.reddit.com/r/MachineLearning/comments/95m75b/what_services_do_you_use_for_data_labeling_we_are/,Csai,1533736492,\[removed\],0,1
344,2018-8-8,2018,8,8,23,95m8of,[D] What types of speed-ups have you seen using quantization in production?,https://www.reddit.com/r/MachineLearning/comments/95m8of/d_what_types_of_speedups_have_you_seen_using/,jamesonatfritz,1533736827,,3,6
345,2018-8-8,2018,8,8,23,95mc9y,Complete Machine Learning Fundamentals in less than 5 minutes,https://www.reddit.com/r/MachineLearning/comments/95mc9y/complete_machine_learning_fundamentals_in_less/,thereflective,1533737528,,0,1
346,2018-8-8,2018,8,8,23,95meq9,Need an idea or concept for a Machine Learning Project.,https://www.reddit.com/r/MachineLearning/comments/95meq9/need_an_idea_or_concept_for_a_machine_learning/,Troied,1533738019,Guys please help me out to find some awesome ML/DL project ideas,0,1
347,2018-8-8,2018,8,8,23,95mgec,"Dance generator using autoencoder, LSTM and Mixed Density Network (Keras)",https://www.reddit.com/r/MachineLearning/comments/95mgec/dance_generator_using_autoencoder_lstm_and_mixed/,HairyIndianDude,1533738358,,1,1
348,2018-8-8,2018,8,8,23,95minr,Quality management of machine learning projects &amp; PDCA Cycle,https://www.reddit.com/r/MachineLearning/comments/95minr/quality_management_of_machine_learning_projects/,svyas,1533738801,,0,1
349,2018-8-8,2018,8,8,23,95mmsb,"Dance generator using Autoencoder, LSTM and Mixture Density Network (Keras)",https://www.reddit.com/r/MachineLearning/comments/95mmsb/dance_generator_using_autoencoder_lstm_and/,HairyIndianDude,1533739632,,1,1
350,2018-8-9,2018,8,9,0,95muf0,[D] Trying to find for this paper on GANs that places furniture items together in a consistent manner.,https://www.reddit.com/r/MachineLearning/comments/95muf0/d_trying_to_find_for_this_paper_on_gans_that/,T_hank,1533741058,"I saw this paper sometime back then forgot what it's name was, maybe something like 'does this go with that...'. It talked about placing together furniture in a physically consistent manner. Would anyone know the name for it?",1,8
351,2018-8-9,2018,8,9,0,95my05,"[P] SVM Explorer, an app where you can run SVMs through a user interface",https://www.reddit.com/r/MachineLearning/comments/95my05/p_svm_explorer_an_app_where_you_can_run_svms/,MediumInterview,1533741707,,0,2
352,2018-8-9,2018,8,9,0,95n0m3,Guided Analytics using KNIME Analytics Platform  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/95n0m3/guided_analytics_using_knime_analytics_platform/,coinmonks,1533742201,,0,1
353,2018-8-9,2018,8,9,0,95n0ti,Google photos has evolved and can now digitally recognize memes,https://www.reddit.com/r/MachineLearning/comments/95n0ti/google_photos_has_evolved_and_can_now_digitally/,shmishmouyes,1533742241,,0,1
354,2018-8-9,2018,8,9,0,95n261,"[D] How do you scale KubeFlow from local -&gt; cloud, while orchestrating locally?",https://www.reddit.com/r/MachineLearning/comments/95n261/d_how_do_you_scale_kubeflow_from_local_cloud/,obliviron,1533742483,Trying to scale a KubeFlow GAN model to use cloud during certain times.,3,1
355,2018-8-9,2018,8,9,0,95n47b,DanceNet - Generate dance videos using LSTM and Mixed Density Network,https://www.reddit.com/r/MachineLearning/comments/95n47b/dancenet_generate_dance_videos_using_lstm_and/,HairyIndianDude,1533742867,\[removed\],0,1
356,2018-8-9,2018,8,9,0,95n51p,Dijkstra's in Disguise [R],https://www.reddit.com/r/MachineLearning/comments/95n51p/dijkstras_in_disguise_r/,larseidnes,1533743005,,17,189
357,2018-8-9,2018,8,9,0,95n90s,"Simple Questions Thread August 08, 2018",https://www.reddit.com/r/MachineLearning/comments/95n90s/simple_questions_thread_august_08_2018/,AutoModerator,1533743736,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",0,1
358,2018-8-9,2018,8,9,1,95nbqf,Generate Dance video using LSTM and Mixture Density Network (Keras),https://www.reddit.com/r/MachineLearning/comments/95nbqf/generate_dance_video_using_lstm_and_mixture/,HairyIndianDude,1533744232,,1,1
359,2018-8-9,2018,8,9,1,95ngid,Dance Generator using LSTM and Mixed Density Network (Keras),https://www.reddit.com/r/MachineLearning/comments/95ngid/dance_generator_using_lstm_and_mixed_density/,jaison_ml,1533745121,,0,1
360,2018-8-9,2018,8,9,1,95nm1u,"[D] Poll: While doing ML, how much time do you spend doing non-ML tasks?",https://www.reddit.com/r/MachineLearning/comments/95nm1u/d_poll_while_doing_ml_how_much_time_do_you_spend/,rstoj,1533746153,,24,17
361,2018-8-9,2018,8,9,1,95nmwf,Few activation functions handling various problems - neural networks,https://www.reddit.com/r/MachineLearning/comments/95nmwf/few_activation_functions_handling_various/,mikinoqwert,1533746317,\[removed\],0,1
362,2018-8-9,2018,8,9,1,95ntj5,[D] Research on Inverted Data?,https://www.reddit.com/r/MachineLearning/comments/95ntj5/d_research_on_inverted_data/,tshrjn,1533747563,"Hi everyone,
Do you know of any such research where the number of input features (couple of millions) can be orders of magnitude larger than the number of training examples(5k per class)?

I found a few, most of them used some variation of Auto-Encoder and to get a more compact feature representation and work from there, also the first idea which comes to the mind that is.

The most recent I came across was by [Bengio and MILA team](https://arxiv.org/abs/1611.09340) which had a bit different approach. 
But the results were still not that impressive.

If you have worked on similar problems or have come across such research, please point me to it. 

Thanks",0,0
363,2018-8-9,2018,8,9,2,95nufb,[D] Dataset Augmentation: Train NNs with Limited Data,https://www.reddit.com/r/MachineLearning/comments/95nufb/d_dataset_augmentation_train_nns_with_limited_data/,mikeyanderson,1533747723,,0,5
364,2018-8-9,2018,8,9,2,95o2ov,Dance generator using keras,https://www.reddit.com/r/MachineLearning/comments/95o2ov/dance_generator_using_keras/,HairyIndianDude,1533749200,,0,1
365,2018-8-9,2018,8,9,2,95o4u6,I need some tips to a Sequence-to-sequence project,https://www.reddit.com/r/MachineLearning/comments/95o4u6/i_need_some_tips_to_a_sequencetosequence_project/,VniciusMt,1533749584,\[removed\],0,1
366,2018-8-9,2018,8,9,2,95o6rb,[R] How can I work with data that may be moderately mislabeled?,https://www.reddit.com/r/MachineLearning/comments/95o6rb/r_how_can_i_work_with_data_that_may_be_moderately/,sczepanski,1533749916,"(disclaimer) First of all, this isn't research, its for my internship.

I have 10 dimensions of data, and I've collected about 60,000 observations.

This data is unlabeled, so I used TSNE to reduce the dimensionality of it, then used Gaussian Mixture Models to label the clusters.

I'm pretty satisfied with the results, but I am experimenting with DBSCAN and Spectral Clustering in hopes for something more interesting.

Regardless, I've been training with what I have so far.  Now I know for certain that many observations are mislabeled, my question is, how big of a problem this is?  How do I mitigate these problems?

Can you offer any techniques or tips? Or how to better cluster and label my data?

Thanks!

Also if it seems appropriate, i'll x-post this to r/learnmachinelearning",1,2
367,2018-8-9,2018,8,9,2,95oc78,[P] Dance generator AI using LSTM and MDN (keras),https://www.reddit.com/r/MachineLearning/comments/95oc78/p_dance_generator_ai_using_lstm_and_mdn_keras/,jaison_ml,1533750921,,35,279
368,2018-8-9,2018,8,9,3,95ofvq,"[Discussion] Possible Scenario? ""Despite the reviewer negativity, as an AC Chair of NIPS and Research Scientist at Facebook, I really think this paper on Click-through-rate will move the science forward.""",https://www.reddit.com/r/MachineLearning/comments/95ofvq/discussion_possible_scenario_despite_the_reviewer/,ACConflictOfInterest,1533751587,"How do we resolve the potential conflicts of interest that can arise from those who have multiple appointments in Academia and Industry? 

We've been here before when Tobacco companies sponsored research studies and Sugar companies sponsored diabetes research.",1,1
369,2018-8-9,2018,8,9,3,95oiej,[P] Keras ProGAN with Weights,https://www.reddit.com/r/MachineLearning/comments/95oiej/p_keras_progan_with_weights/,NMcA,1533752062,,0,1
370,2018-8-9,2018,8,9,3,95ouj3,[Classification problem] Classify email as spam or regular and then show insurance quote on website.,https://www.reddit.com/r/MachineLearning/comments/95ouj3/classification_problem_classify_email_as_spam_or/,gutterandstars,1533754249,\[removed\],0,1
371,2018-8-9,2018,8,9,4,95p0if,Can somebody please share the link for Deeplearning.ai specialization(zipped videos) to view offline ?,https://www.reddit.com/r/MachineLearning/comments/95p0if/can_somebody_please_share_the_link_for/,nodechef,1533755348,\[removed\],0,1
372,2018-8-9,2018,8,9,4,95p1no,"I'm building a MMO platform for playing games with ML, come help!",https://www.reddit.com/r/MachineLearning/comments/95p1no/im_building_a_mmo_platform_for_playing_games_with/,BammyBums,1533755561,\[removed\],0,1
373,2018-8-9,2018,8,9,4,95pg7x,[N] Kaggle now offering free GPU Tesla K80 time on their notebooks,https://www.reddit.com/r/MachineLearning/comments/95pg7x/n_kaggle_now_offering_free_gpu_tesla_k80_time_on/,AdditionalWay,1533758235,"Kaggle now offering free GPU Tesla K80 time on their notebooks like Google Colaboratory. 

Here's the email I got this morning 

&gt; Now you can tap into the power of GPUs with Kaggle Kernels! Simply click the new Enable GPU checkbox on the Settings tab of your script or notebook and run that deep learning model at light speed*.
&gt; 
&gt; Looking to play around with GPUs and learn some new deep learning techniques?  
&gt; 
&gt; Fork Kevin Maders kernel on Attention Models or Megans introduction to LSTMs w/ Keras+GPU for Text Generation. Or see what others are working on with GPUs and start something new.
&gt; 
&gt; Free GPUs for Deep Learning
&gt; One more thing: for extra deep learning credit, take a look at this paper on Quasi-recurrent neural networks that caught our eye. If you can get one to run in a kernel, tag Jamie (@datacanary) in the comments and hell send you some Kaggle swag.",16,22
374,2018-8-9,2018,8,9,5,95pi7k,[p] PyCon UK 2016: Test Driven data Analysis,https://www.reddit.com/r/MachineLearning/comments/95pi7k/p_pycon_uk_2016_test_driven_data_analysis/,villasv,1533758607,,2,3
375,2018-8-9,2018,8,9,5,95pm5t,MXNet implementation of DeepMind Neural Arithmetic Logic Units by Trask et.al,https://www.reddit.com/r/MachineLearning/comments/95pm5t/mxnet_implementation_of_deepmind_neural/,gautamrbharadwaj,1533759337,,0,1
376,2018-8-9,2018,8,9,5,95pqvy,"[P] SVM Explorer, an app where you can run SVMs through a user interface",https://www.reddit.com/r/MachineLearning/comments/95pqvy/p_svm_explorer_an_app_where_you_can_run_svms/,MediumInterview,1533760230,,16,148
377,2018-8-9,2018,8,9,5,95psj5,MCTS: question about rollout policy function and legal actions,https://www.reddit.com/r/MachineLearning/comments/95psj5/mcts_question_about_rollout_policy_function_and/,ew20030822,1533760525,\[removed\],0,1
378,2018-8-9,2018,8,9,5,95pz3f,[D] Inclusion in ML on Twitter,https://www.reddit.com/r/MachineLearning/comments/95pz3f/d_inclusion_in_ml_on_twitter/,XalosXandrez,1533761758,,6,0
379,2018-8-9,2018,8,9,6,95qdcl,[D] Deep dive into manifold learning,https://www.reddit.com/r/MachineLearning/comments/95qdcl/d_deep_dive_into_manifold_learning/,Cartesian_Currents,1533764504,"I just realized that I'm really passionate about manifold learning, and it's likely the area of Machine learning that interests me the most. 

I'm hoping there's a way I can do research in this area, and to that end I was wondering of any particular labs that are know for their research focus on it and what papers you suggest to understand the current state of research.",0,4
380,2018-8-9,2018,8,9,6,95qgf7,Project Amika: Open-source consensual data collection for conversational deep learning,https://www.reddit.com/r/MachineLearning/comments/95qgf7/project_amika_opensource_consensual_data/,PlatinumNinja72,1533765095,,1,1
381,2018-8-9,2018,8,9,7,95quyn,[N] Harvard &amp; University of Toronto Researchers Apply Deep Generative Models to Inverse Molecular Design,https://www.reddit.com/r/MachineLearning/comments/95quyn/n_harvard_university_of_toronto_researchers_apply/,trcytony,1533768081,,0,1
382,2018-8-9,2018,8,9,8,95r3nu,"[D] Can anyone confirm this? ""$400-700k with PhD at places like Google, Facebook, etc.""",https://www.reddit.com/r/MachineLearning/comments/95r3nu/d_can_anyone_confirm_this_400700k_with_phd_at/,TypicalDraft,1533769949,"Are these the normal machine learning salaries in the Bay Area? 

https://www.reddit.com/r/MachineLearning/comments/95gps2/p_remoteml_v2_remote_machine_learning_jobs/e3u8bxw/

Just curious as a European in tech.",30,14
383,2018-8-9,2018,8,9,8,95r3z3,Essential beginners Q/A for machine learning/data science,https://www.reddit.com/r/MachineLearning/comments/95r3z3/essential_beginners_qa_for_machine_learningdata/,tirthajyoti,1533770019,\[removed\],0,1
384,2018-8-9,2018,8,9,8,95r8kg,[R] AutoPool for deep learning from weakly labeled time series,https://www.reddit.com/r/MachineLearning/comments/95r8kg/r_autopool_for_deep_learning_from_weakly_labeled/,wavelander,1533770977,,0,3
385,2018-8-9,2018,8,9,8,95rcty,[D] Do most of these papers on improved models make it to implementation in industry/famous open source libraries?,https://www.reddit.com/r/MachineLearning/comments/95rcty/d_do_most_of_these_papers_on_improved_models_make/,mofoss,1533771911,"I was reading a paper on neural decision trees and forest where they essentially make the splitting decision via a sigmoidal function and obviously construct the problem such that you can train via backprop based on a loss. Cool. 

There will be some experiments and most of the time it beats some state of the art on a particular dataset. Okay cool.

Do these little tweaks or paradigm shifts discussed in research papers make into famous libraries? In my previous example does the random forest algorithm in scikit learn work the way a student would learn in a classroom? 

I'm not talking about the parallelization of training and efficiency of how something's may be tuned, but rather changes to the fundamental construction/training of the model. When we talk about random forest or trees, we're like ""oh yeah gini impurity or entropy criterions"" and you get your splits and your tree in built. But is it done like that in the currently commonly used libraries or is it filled with tiny hacks and changes discovered via all these research papers?

I read a older paper about negative error correlation in ensemble neural networks, would that ever make it to current libraries or is it just that current methods are just better and some papers won't ever see the light of day again?

Sorry if I sound naive, I'm more of a self taught practitioner so I'm not up to date with academia or contributions to open source. Thanks :) ",12,20
386,2018-8-9,2018,8,9,9,95rhka,Difference between Research Scientist and Research Engineer,https://www.reddit.com/r/MachineLearning/comments/95rhka/difference_between_research_scientist_and/,General_Dragonfruit,1533772948,\[removed\],0,1
387,2018-8-9,2018,8,9,9,95rpgg,Essential Math for Data Science and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/95rpgg/essential_math_for_data_science_and_machine/,tirthajyoti,1533774704,\[removed\],0,1
388,2018-8-9,2018,8,9,9,95rrnn,Can I automatically sort a dataset into folders with corresponding titles for use with TF for Poets?,https://www.reddit.com/r/MachineLearning/comments/95rrnn/can_i_automatically_sort_a_dataset_into_folders/,JesseOS,1533775202,\[removed\],0,1
389,2018-8-9,2018,8,9,10,95s1aa,[P] Getting Alexa to Respond to Sign Language Using Your Webcam and TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/95s1aa/p_getting_alexa_to_respond_to_sign_language_using/,hardmaru,1533777410,,16,231
390,2018-8-9,2018,8,9,10,95s72s,How do You Prepare for Coding Interviews of ML Engineer Jobs in FAMGA?,https://www.reddit.com/r/MachineLearning/comments/95s72s/how_do_you_prepare_for_coding_interviews_of_ml/,upulbandara,1533778798,,0,1
391,2018-8-9,2018,8,9,10,95s9cl,[D] Research Engineer vs Research Scientist in industrial labs,https://www.reddit.com/r/MachineLearning/comments/95s9cl/d_research_engineer_vs_research_scientist_in/,General_Dragonfruit,1533779302,"I see that most of industrial AI labs hire both Research Scientists and Research Engineers. What's the difference between them? Are Research Engineers consider first class people or just as highly qualified technicians for 'real' researchers? Do they direct their own research or just follow their lead researchers? Do they appear in paper authors as first authors or at all?

P.S. The question is interesting for me, because whether I can do research without PhD or not determines my future directions.",35,36
392,2018-8-9,2018,8,9,11,95sczl,[R]MCRM: Mother Compact Recurrent Memory A Biologically Inspired Recurrent Neural Network Architecture,https://www.reddit.com/r/MachineLearning/comments/95sczl/rmcrm_mother_compact_recurrent_memory_a/,AbduallahM,1533780148,\[removed\],0,1
393,2018-8-9,2018,8,9,11,95sgpm,4 side seal packaging machine,https://www.reddit.com/r/MachineLearning/comments/95sgpm/4_side_seal_packaging_machine/,chinamachine,1533781046,\[removed\],0,1
394,2018-8-9,2018,8,9,11,95sk0i,How to use recurrent neural network | Custom Web Development Blog,https://www.reddit.com/r/MachineLearning/comments/95sk0i/how_to_use_recurrent_neural_network_custom_web/,issart,1533781860,\[removed\],0,1
395,2018-8-9,2018,8,9,11,95skkz,[R] Logits can be used as confidence if their weak indicators are boosted using an ensemble - Parkinson's Disease Assessment from a Wearable Sensor,https://www.reddit.com/r/MachineLearning/comments/95skkz/r_logits_can_be_used_as_confidence_if_their_weak/,terryum,1533782018,,3,5
396,2018-8-9,2018,8,9,12,95srul,Look-Dev Machine Learning Researcher,https://www.reddit.com/r/MachineLearning/comments/95srul/lookdev_machine_learning_researcher/,lyondhur,1533783816,\[removed\],0,1
397,2018-8-9,2018,8,9,12,95srzr,"AI, ML : K Means Clustering in less than 3 minutes",https://www.reddit.com/r/MachineLearning/comments/95srzr/ai_ml_k_means_clustering_in_less_than_3_minutes/,The_Magnum,1533783855,,0,1
398,2018-8-9,2018,8,9,12,95svxp,Data Science in just 3 words,https://www.reddit.com/r/MachineLearning/comments/95svxp/data_science_in_just_3_words/,amaryvk,1533784804,,0,1
399,2018-8-9,2018,8,9,13,95t8sa,"Looking for friendly machine learning experts to join our Discord Server for Developers, Tinkerers, and Hackers!",https://www.reddit.com/r/MachineLearning/comments/95t8sa/looking_for_friendly_machine_learning_experts_to/,bv9900,1533788104,\[removed\],0,1
400,2018-8-9,2018,8,9,14,95tn5g,Does anyone have a dataset for multi-intent classification?,https://www.reddit.com/r/MachineLearning/comments/95tn5g/does_anyone_have_a_dataset_for_multiintent/,clrajapaksha,1533792068,\[removed\],0,1
401,2018-8-9,2018,8,9,14,95tn5h,Is Machine Learning Worth For All Businesses? | Analytics Insight,https://www.reddit.com/r/MachineLearning/comments/95tn5h/is_machine_learning_worth_for_all_businesses/,analyticsinsight,1533792068,,0,1
402,2018-8-9,2018,8,9,14,95to0h,"[P] Examples for Machine Translation with Attention, Image Captioning, Text Generation, and DCGAN (tf.keras + eager execution)",https://www.reddit.com/r/MachineLearning/comments/95to0h/p_examples_for_machine_translation_with_attention/,SupraluminalShift,1533792330,,0,1
403,2018-8-9,2018,8,9,14,95tpll,[D] Download the Pytorch documentation?,https://www.reddit.com/r/MachineLearning/comments/95tpll/d_download_the_pytorch_documentation/,maxisawesome538,1533792823,"Hey all, perhaps stackoverflow is better for this, but....

How can I download the pytorch docs? I'm going offline for a week or so and they'd be very helpful. The files on the github repo don't look like the html site, I know this is because they get auto-generated, but the online version is really what I want. If I run the makefile in the docs directory, will that make what I want locally on my machine? Thanks in advance.",5,0
404,2018-8-9,2018,8,9,14,95tqjh,Predicting Expressive Speaking Style From Text in End-to-End Speech Synthesis,https://www.reddit.com/r/MachineLearning/comments/95tqjh/predicting_expressive_speaking_style_from_text_in/,daisystanton,1533793125,,0,1
405,2018-8-9,2018,8,9,14,95tsjd,Optical Fiber For Welding Machines,https://www.reddit.com/r/MachineLearning/comments/95tsjd/optical_fiber_for_welding_machines/,SuntecLaser,1533793752,,0,1
406,2018-8-9,2018,8,9,15,95tyiq,Bitumen Pavement Vehicle,https://www.reddit.com/r/MachineLearning/comments/95tyiq/bitumen_pavement_vehicle/,Metongmachine,1533795529,,0,1
407,2018-8-9,2018,8,9,15,95tzhy,[N] TensorFlow 1.10.0 is out,https://www.reddit.com/r/MachineLearning/comments/95tzhy/n_tensorflow_1100_is_out/,b0noi,1533795817,"* [Official changelog](https://github.com/tensorflow/tensorflow/releases/tag/v1.10.0);
* [Google Compute Engine Deep Learning images also now support TF 1.10](https://blog.kovalevskyi.com/deep-learning-images-for-google-cloud-engine-the-definitive-guide-bc74f5fb02bc);

from the official changelog:

## Major Features And Improvements

* Updated docs for tf.keras  
: New Keras-based [get started](http://tensorflow.org/versions/r1.9/get_started) and [programmers guide page](http://tensorflow.org/versions/r1.9/programmers_guide/keras).
* Update tf.keras  
 to the Keras 2.1.6 API.
* Added [tf.keras.layers.CuDNNGRU](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/keras/layers/CuDNNGRU) and [tf.keras.layers.CuDNNLSTM](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/keras/layers/CuDNNLSTM) layers. [Try it](https://colab.sandbox.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb?linkId=53292082).
* Adding support of core [feature columns](https://www.tensorflow.org/get_started/feature_columns) and [losses](https://www.tensorflow.org/api_docs/python/tf/losses) to [gradient boosted trees estimators](https://github.com/tensorflow/models/tree/master/official/boosted_trees).
* The [python interface](https://tensorflow-dot-devsite.googleplex.com/versions/r1.9/api_docs/python/tf/contrib/lite) for the [TFLite Optimizing Converter](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/README.md) has been expanded, and the command line interface (AKA: toco  
, tflite\_convert  
) is once again included in the standard pip  
installation.
* Improved data-loading and text processing with:
   * [tf.decode\_compressed](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/decode_compressed)
   * [tf.string\_strip](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/string_strip)
   * [tf.strings.regex\_full\_match](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/strings/regex_full_match)
* Added experimental support for new pre-made Estimators:
   * [tf.contrib.estimator.BaselineEstimator](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/estimator/BaselineEstimator)
   * [tf.contrib.estimator.RNNClassifier](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/estimator/RNNEstimator)
   * [tf.contrib.estimator.RNNEstimator](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/estimator/RNNClassifier)
* The [distributions.Bijector](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/distributions/bijectors/Bijector) API supports broadcasting for Bijectors with new API changes.",0,1
408,2018-8-9,2018,8,9,15,95u04z,Effect of GDPR on Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/95u04z/effect_of_gdpr_on_machine_learning_algorithms/,deepak387,1533796009,,0,1
409,2018-8-9,2018,8,9,16,95u6v5,Graph convolutional network applications in transportation.,https://www.reddit.com/r/MachineLearning/comments/95u6v5/graph_convolutional_network_applications_in/,shiresabastian,1533798169,\[removed\],0,1
410,2018-8-9,2018,8,9,16,95ubhg,"[D] Inverse machine learning: What if we knew the actual model, how to infer the parameters?",https://www.reddit.com/r/MachineLearning/comments/95ubhg/d_inverse_machine_learning_what_if_we_knew_the/,RobRomijnders,1533799591,"Say a domain expert comes up to us and ask to infer the parameters of his model. He actually knows the model and needs uncertainty bounds on his parameters. How would we do that?

More explanation:
For many of our problems, we get to choose our model. In classifying cats from dogs, we get to choose between neural nets and SVMs. In finding clusters, we get to choose between K-means or PCA. Now what if a domain expert has an actual model, but needs to find the parameters.

Example:
Let's say the known model is 

`y(x) = exp(-a*x) + b*x + sin(c*x) + d` 



  * where sample points  `x_i ~ Uniform(0, 1)` and 
  * observations `y_{i} ~ y(x_i) + Normal(0, variance)`

Here are some images:
![examples](https://github.com/RobRomijnders/known_model/blob/master/known_model/im/example.png?raw=true)

and [here](https://github.com/RobRomijnders/known_model) is the code for generating these images


TL;DR How to find confidence bounds on `a`, `b`, `c`, and `d`?",18,11
411,2018-8-9,2018,8,9,16,95ufzj,Simple and intuitive Python API for UC Irvine Machine Learning Repository,https://www.reddit.com/r/MachineLearning/comments/95ufzj/simple_and_intuitive_python_api_for_uc_irvine/,tirthajyoti,1533801107,\[removed\],0,1
412,2018-8-9,2018,8,9,17,95urss,Better Medicine: How AI is Improving Cancer Research - HPCwire,https://www.reddit.com/r/MachineLearning/comments/95urss/better_medicine_how_ai_is_improving_cancer/,ANNA_Systems,1533805127,,0,1
413,2018-8-9,2018,8,9,18,95uspe,[D] Is Machine Learning a pseudoscience?,https://www.reddit.com/r/MachineLearning/comments/95uspe/d_is_machine_learning_a_pseudoscience/,goxul,1533805414,,3,0
414,2018-8-9,2018,8,9,18,95uz71,Fed TF DCGAN image set from photographer Kristen Wrzesniewskis instagramz - wouldnt have imagined this sort of stuff would come out. So very cool.,https://www.reddit.com/r/MachineLearning/comments/95uz71/fed_tf_dcgan_image_set_from_photographer_kristen/,normalcereal,1533807457,,0,1
415,2018-8-9,2018,8,9,19,95v4g9,Horizontal 4 Side Seal Packaging Machine (Patches Flat &amp; Solid Items),https://www.reddit.com/r/MachineLearning/comments/95v4g9/horizontal_4_side_seal_packaging_machine_patches/,chinamachine,1533809044,,0,1
416,2018-8-9,2018,8,9,19,95vbgx,[P] Playing Around With Noise As Targets,https://www.reddit.com/r/MachineLearning/comments/95vbgx/p_playing_around_with_noise_as_targets/,CaHoop,1533811144,,4,44
417,2018-8-9,2018,8,9,20,95vft2,How to run Keras model on Movidius neural compute stick,https://www.reddit.com/r/MachineLearning/comments/95vft2/how_to_run_keras_model_on_movidius_neural_compute/,coinmonks,1533812444,,0,1
418,2018-8-9,2018,8,9,20,95vro2,Mask RCNN help needed,https://www.reddit.com/r/MachineLearning/comments/95vro2/mask_rcnn_help_needed/,cmoscrob,1533815643,\[removed\],0,1
419,2018-8-9,2018,8,9,21,95w1uq,Should I learn NLP or CV ?,https://www.reddit.com/r/MachineLearning/comments/95w1uq/should_i_learn_nlp_or_cv/,jfk1792,1533818157,\[removed\],0,1
420,2018-8-9,2018,8,9,22,95w9ob,Preparing your product for machine learning,https://www.reddit.com/r/MachineLearning/comments/95w9ob/preparing_your_product_for_machine_learning/,NegatioNZor,1533819996,,0,1
421,2018-8-9,2018,8,9,22,95wdk7,"HMM with nested time intervals? Is there a model that reflects musics patterns over notes, measures, and 4-measure sequences? (Different from HSMM since time intervals are constant within each layer)",https://www.reddit.com/r/MachineLearning/comments/95wdk7/hmm_with_nested_time_intervals_is_there_a_model/,ternary56783,1533820847,\[removed\],0,1
422,2018-8-9,2018,8,9,22,95wh43,Google photos has evolved and can now digitally recognize memes,https://www.reddit.com/r/MachineLearning/comments/95wh43/google_photos_has_evolved_and_can_now_digitally/,shmishmouyes,1533821676,,0,2
423,2018-8-9,2018,8,9,22,95wjeb,"[N] Weekly Machine Learning Opensource Roundup  Aug. 9, 2018",https://www.reddit.com/r/MachineLearning/comments/95wjeb/n_weekly_machine_learning_opensource_roundup_aug/,stkim1,1533822178,,0,1
424,2018-8-9,2018,8,9,23,95wppu,[D] Unsupervised Object Segmentation of still images?,https://www.reddit.com/r/MachineLearning/comments/95wppu/d_unsupervised_object_segmentation_of_still_images/,wildtales,1533823525,"Babies learn to group pixels that move together as a single object without supervision. Thereafter, they can localize objects in still images as well. Has someone attempted to create a model to mimic the same?  


 My team attempted a related project last year, whereby two images were fed as input to a CNN and the output was supposed to be the motion vectors for the pixels (optical flow). In order to train the CNN, the predicted flow was applied to the first image and the resultant was supposed to be close to the second image in Euclidean distance. Hence, the supervision on the flow was indirect (from the next image).  For smoothness, neighboring pixels were constrained to have similar motion vectors.  Needless to say, it didn't work. ",0,1
425,2018-8-10,2018,8,10,0,95x72e,partial categorized input data for lstm,https://www.reddit.com/r/MachineLearning/comments/95x72e/partial_categorized_input_data_for_lstm/,jirade,1533827005,\[removed\],0,1
426,2018-8-10,2018,8,10,0,95x9gp,[D] Anyone have any thoughts on Insight AI?,https://www.reddit.com/r/MachineLearning/comments/95x9gp/d_anyone_have_any_thoughts_on_insight_ai/,TheRedSphinx,1533827456,"I tried asking this in r/datascience and it didn't get much traction, so I figured I would try this here. If this is more appropiate for r/MLQuestions or r/cscareerquestions, I will gladly move it there. 

I'll be doing the Insight AI fellowship. Insight already put me in contact with a past Fellow, but it'd be great if I could get more information from anyone else whose done it. Has anyone here done it? Any tips to maximize my time spent at Insight? Any way to prepare? Any general tips on the job hunting prospect during Insight? Thanks!",27,2
427,2018-8-10,2018,8,10,0,95xn06,Real Machine Learning,https://www.reddit.com/r/MachineLearning/comments/95xn06/real_machine_learning/,vernik911,1533829989,,0,1
428,2018-8-10,2018,8,10,1,95xq37,Group Travel Problem,https://www.reddit.com/r/MachineLearning/comments/95xq37/group_travel_problem/,coolnikhilj22,1533830542,\[removed\],0,1
429,2018-8-10,2018,8,10,1,95xsaj,[P] Literature review on Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/95xsaj/p_literature_review_on_adversarial_examples/,1o0ko,1533830958,"[Tricking a Machine into Thinking Youre MillaJovovich](https://medium.com/element-ai-research-lab/tricking-a-machine-into-thinking-youre-milla-jovovich-b19bf322d55c) \- And other types of adversarial attacks in machinelearning.  
",0,15
430,2018-8-10,2018,8,10,1,95y0v4,Need some advise on AI studies,https://www.reddit.com/r/MachineLearning/comments/95y0v4/need_some_advise_on_ai_studies/,TheAIStudent,1533832518,\[removed\],0,1
431,2018-8-10,2018,8,10,1,95y43f,Deep Learning Image Classifier - Happy to know what you think - Final Project Udacity Nanodegree,https://www.reddit.com/r/MachineLearning/comments/95y43f/deep_learning_image_classifier_happy_to_know_what/,fotisk07,1533833118,,0,1
432,2018-8-10,2018,8,10,1,95y469,Why is DenseNet perform so well and what is its drawbacks?,https://www.reddit.com/r/MachineLearning/comments/95y469/why_is_densenet_perform_so_well_and_what_is_its/,moewiewp,1533833131,\[removed\],0,1
433,2018-8-10,2018,8,10,2,95ygm6,"[Paper] Review of AlexNet, CaffeNet  The Winner of ILSVRC 2012 (Image Classification)",https://www.reddit.com/r/MachineLearning/comments/95ygm6/paper_review_of_alexnet_caffenet_the_winner_of/,coinmonks,1533835404,,0,1
434,2018-8-10,2018,8,10,2,95yiyg,"Top 5 companies to work for as a ML researcher, especially in EU",https://www.reddit.com/r/MachineLearning/comments/95yiyg/top_5_companies_to_work_for_as_a_ml_researcher/,fabudlx,1533835837,\[removed\],0,1
435,2018-8-10,2018,8,10,2,95ylv7,The Machine Learning Behind Android Smart Linkify,https://www.reddit.com/r/MachineLearning/comments/95ylv7/the_machine_learning_behind_android_smart_linkify/,dezzion,1533836386,,0,1
436,2018-8-10,2018,8,10,2,95yoeg,A great guide to performing dimensionality reduction for beginners.,https://www.reddit.com/r/MachineLearning/comments/95yoeg/a_great_guide_to_performing_dimensionality/,saloni_ba,1533836856,,0,2
437,2018-8-10,2018,8,10,2,95ypi2,[N] TensorFlow 1.10 is out,https://www.reddit.com/r/MachineLearning/comments/95ypi2/n_tensorflow_110_is_out/,hack777,1533837051,,0,1
438,2018-8-10,2018,8,10,3,95z25h,[D] Is it possible to use U-net in a cGAN?,https://www.reddit.com/r/MachineLearning/comments/95z25h/d_is_it_possible_to_use_unet_in_a_cgan/,kidraga,1533839402,"I'm pretty new to machine learning so this might be a silly question...
I'm thinking of using U-net or an autoencoder as the generator in the conditional GAN, this way I can feed in an image and a condition vector, and output an image with some modification that I want.
One example would be that I can feed in a image before rendering, along with the light condition (position, brightness etc), and output an image after rendering.
The problem that I have is I don't know how to include the condition vector into the model. What I learnt is that in typical cGAN we simply concatenate the condition vector with the noise vector, but this won't work if we are feeding in an image. A possible way that I can think of is to concatenate the condition in the middle of the AutoEncoder, but that means we have to down sampling the image until is a 1D vector.

Any suggestions?",2,5
439,2018-8-10,2018,8,10,4,95zctw,My CS231n course notes,https://www.reddit.com/r/MachineLearning/comments/95zctw/my_cs231n_course_notes/,kaoshost,1533841368,,1,1
440,2018-8-10,2018,8,10,4,95zdmp,My CS231n course notes (Convolutional Neural Networks for Visual Recognition),https://www.reddit.com/r/MachineLearning/comments/95zdmp/my_cs231n_course_notes_convolutional_neural/,kaoshost,1533841508,,1,1
441,2018-8-10,2018,8,10,4,95zl86,Improving websites with a multi-armed-bandit recommender system,https://www.reddit.com/r/MachineLearning/comments/95zl86/improving_websites_with_a_multiarmedbandit/,marcua,1533842894,,0,1
442,2018-8-10,2018,8,10,4,95zlsa,Machine Learning for detecting things invisible to naked eye,https://www.reddit.com/r/MachineLearning/comments/95zlsa/machine_learning_for_detecting_things_invisible/,EthanKer,1533843005,[removed],0,1
443,2018-8-10,2018,8,10,4,95zqu7,[P] Improving websites with a multi-armed-bandit recommender system,https://www.reddit.com/r/MachineLearning/comments/95zqu7/p_improving_websites_with_a_multiarmedbandit/,marcua,1533843947,,1,5
444,2018-8-10,2018,8,10,4,95zqzv,Is this kind of decent possible with gradient decent,https://www.reddit.com/r/MachineLearning/comments/95zqzv/is_this_kind_of_decent_possible_with_gradient/,Bhoomeendra,1533843974,"i made a logistics regression model with gradient decent and plotted loss(square error) with each loop and in a segment i got a graph like this 

[Y axis is loss and X axis is number of loop](https://i.redd.it/d42qsrucf4f11.png)

This is the code

`import numpy as np`

`import pandas as pd`

`import matplotlib.pyplot as plt`

`class sigmoid :`

`def __init__ (self,X,y,alpha = 0.01,loop = 1000):`

`self.row = X.shape[0]`

`self.clm = X.shape[1]+1`

`self.X = np.append(np.ones(self.row).reshape(self.row,1),X, axis = 1)`

`self.y = y.reshape(self.row,1)`

`self.w = np.ones(self.clm).reshape(self.clm,1)`

`self.loop = loop`

`self.alpha = alpha`

`def sigf (self,Z):# X is a vector and w is a variable AND Z is their product`

`return 1/(1 + np.exp(-Z))`

`def grad (self):`

`local = np.ones(self.row).reshape(self.row,1)`

`w = np.zeros(self.clm).reshape(self.clm , 1)`

`for i in range(self.clm):`

`fx = self.sigf(self.X[:,[i]]*self.w[i])`

`new = fx * (local - fx) * (fx - self.y) * self.X[:,[i]]`

`w[i] = np.sum(new)`

`return w`

`def loss (self):`

`loss = 0.5 * (self.y - self.predict())** 2`

`return np.sum(loss)`

`def predict(self):`

`return self.sigf(`[`self.X.dot`](https://self.X.dot)`(self.w))`

`def grad_decent(self):`

`ls_loss = list()`

`for i in range(self.loop):`

`self.w = self.w - self.alpha * self.grad()`

`k = self.loss()`

`print(""loop:{} loss:{}"".format(i,k))`

`ls_loss.append(k)`

`plt.scatter([i for i in  range(self.loop)],ls_loss)`

[`plt.show`](https://plt.show)`()`",0,1
445,2018-8-10,2018,8,10,6,960er3,[N]: Tensorflow 1.10 Released,https://www.reddit.com/r/MachineLearning/comments/960er3/n_tensorflow_110_released/,ntenenz,1533848425,"Biggest changes include:
* Bigtable support in tf.data
* NCCL no longer included in the binary install


[Release Notes](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md)",24,152
446,2018-8-10,2018,8,10,6,960j5x,[D] Google Cloud TPUs now can be used with Google Colab,https://www.reddit.com/r/MachineLearning/comments/960j5x/d_google_cloud_tpus_now_can_be_used_with_google/,b0noi,1533849232,,9,28
447,2018-8-10,2018,8,10,6,960mgh,is possible to train only one conv layer? (using caffe would be cool),https://www.reddit.com/r/MachineLearning/comments/960mgh/is_possible_to_train_only_one_conv_layer_using/,adnire,1533849891,[removed],0,1
448,2018-8-10,2018,8,10,7,9613gs,[D] What are your opinions when ML is being applied in classical science research? What are some examples when you think certain ML technique will shine?,https://www.reddit.com/r/MachineLearning/comments/9613gs/d_what_are_your_opinions_when_ml_is_being_applied/,QueueTee314,1533853201,"I have seen more and more of them as of late: people solving PDEs with ML, people discovering new physics with ML etc.

Some examples: https://arxiv.org/abs/1509.03580

And: https://www.sciencedirect.com/science/article/pii/S2405896316318298

These are minimal examples at best.

But what are your thoughts? And what popular ML technique should be applied more frequently in other sciences? ",6,0
449,2018-8-10,2018,8,10,7,961861,Introducing TAZ: A.I. Powered Churn Analytics,https://www.reddit.com/r/MachineLearning/comments/961861/introducing_taz_ai_powered_churn_analytics/,coAdjoint_Tom,1533854173,,0,1
450,2018-8-10,2018,8,10,8,961fp1,"[D] Musical HMM with nested time intervals? Is there a model that reflects state changes over notes, measures, and 4-bar groups?",https://www.reddit.com/r/MachineLearning/comments/961fp1/d_musical_hmm_with_nested_time_intervals_is_there/,ternary56783,1533855737,"i.e. every 4 beats (one step in the time variable t) the model progresses to a new Xt hidden state. Each X produces a probability distribution for a progression along Ys hidden states, such that a time step in the variable s is 1/4 of a step in t. Each Y has an emission distribution to observable states Zs (which also occur on each beat.

This is assuming a 4/4 time signature but could also be set to 3/4 or others by adjusting the time step ratios.

Ideally, an even longer time interval could be created for 4 measure sequences, making up a verse since the larger-scale changes in music are noticeable at this scale

Does anyone know if this has been explored or have any thoughts?",1,1
451,2018-8-10,2018,8,10,11,962sa0,"That's not enough, We have to go deeper",https://www.reddit.com/r/MachineLearning/comments/962sa0/thats_not_enough_we_have_to_go_deeper/,arjunkava,1533866447,,0,1
452,2018-8-10,2018,8,10,11,9631uv,r/all,https://www.reddit.com/r/MachineLearning/comments/9631uv/rall/,dead-apparatas,1533868628,[removed],0,1
453,2018-8-10,2018,8,10,12,963e4f,#100DaysOfMLCode,https://www.reddit.com/r/MachineLearning/comments/963e4f/100daysofmlcode/,partoftheorigin,1533871565,[removed],0,1
454,2018-8-10,2018,8,10,13,963pek,[R] You Cannot Serve Two Masters: The Harms of Dual Affiliation,https://www.reddit.com/r/MachineLearning/comments/963pek/r_you_cannot_serve_two_masters_the_harms_of_dual/,downtownslim,1533874391,,13,71
455,2018-8-10,2018,8,10,13,963pwg,My favorite machine learning youtuber (carykh) made a dance generator using neural networks and it's quite good,https://www.reddit.com/r/MachineLearning/comments/963pwg/my_favorite_machine_learning_youtuber_carykh_made/,ytivarg18,1533874505,,0,1
456,2018-8-10,2018,8,10,13,963x4d,"Helicopter Tourism Market 2018 Key Players Update, Growth Rate, Industry Analysis and Forecast 2025",https://www.reddit.com/r/MachineLearning/comments/963x4d/helicopter_tourism_market_2018_key_players_update/,priyankaw,1533876382,,0,1
457,2018-8-10,2018,8,10,13,963xaf,Artificial Intelligence (AI) emulates how people think  Artificial Emotional Intelligence (AEI) emulates how people feel,https://www.reddit.com/r/MachineLearning/comments/963xaf/artificial_intelligence_ai_emulates_how_people/,Batareika_1,1533876431,,0,1
458,2018-8-10,2018,8,10,14,9645ev,Real like Pokdex built using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/9645ev/real_like_pokdex_built_using_tensorflow/,the-dagger,1533878644,[removed],0,1
459,2018-8-10,2018,8,10,14,9649l5,How can someone follow up all of these huge ML papers produced daily,https://www.reddit.com/r/MachineLearning/comments/9649l5/how_can_someone_follow_up_all_of_these_huge_ml/,AbduallahM,1533879823,[removed],0,2
460,2018-8-10,2018,8,10,15,964jys,"they, these robots, saw me. Its ok...its pretty cool I hope. Im not in the band.",https://www.reddit.com/r/MachineLearning/comments/964jys/they_these_robots_saw_me_its_okits_pretty_cool_i/,dead-apparatas,1533882903,[removed],0,1
461,2018-8-10,2018,8,10,15,964lzg,"[N]: CUDNN 7.2.1 released, has CUDNN_DATA_INT8x32 for sm_72 (new GPU is coming soon)",https://www.reddit.com/r/MachineLearning/comments/964lzg/n_cudnn_721_released_has_cudnn_data_int8x32_for/,Remi_Coulom,1533883530,,11,22
462,2018-8-10,2018,8,10,16,964w9u,What is the Holt-Winters Forecasting Algorithm and How Can it be Used for Enterprise Analysis?,https://www.reddit.com/r/MachineLearning/comments/964w9u/what_is_the_holtwinters_forecasting_algorithm_and/,ElegantMicroWebIndia,1533886529,,0,1
463,2018-8-10,2018,8,10,16,964zuo,No degree needed in ML?,https://www.reddit.com/r/MachineLearning/comments/964zuo/no_degree_needed_in_ml/,DankMudkip,1533887683,[removed],0,1
464,2018-8-10,2018,8,10,17,96561z,Any good GUI based software to build Computer Vision/Machine Learning networks?,https://www.reddit.com/r/MachineLearning/comments/96561z/any_good_gui_based_software_to_build_computer/,NarniaRunRun,1533889843,[removed],0,1
465,2018-8-10,2018,8,10,17,9657et,[D] Is it possible to apply distillation to VAEs ?,https://www.reddit.com/r/MachineLearning/comments/9657et/d_is_it_possible_to_apply_distillation_to_vaes/,gohu_cd,1533890406,"Distillation \[1\] is used to transfer knowledge that a model A has learnt on a task, to another model B, using as targets the outputs produced by model A. 

I wonder if it researchers have already proved possible to do the same knowledge distillation between VAEs (or generative models in general) ? Let me know if you have papers that treat this problem. 

\[1\] : [https://arxiv.org/abs/1503.02531](https://arxiv.org/abs/1503.02531) ",4,8
466,2018-8-10,2018,8,10,17,9657vb,Horizontal 4 Side Seal Packaging Machine (Patches Flat &amp; Solid Items),https://www.reddit.com/r/MachineLearning/comments/9657vb/horizontal_4_side_seal_packaging_machine_patches/,chinamachine,1533890583,,0,1
467,2018-8-10,2018,8,10,17,9658h3,Gra Pluma 3 Toneladas,https://www.reddit.com/r/MachineLearning/comments/9658h3/gra_pluma_3_toneladas/,weihuagruapluma,1533890842,,0,1
468,2018-8-10,2018,8,10,17,9659oi,Horizontal 4-side seal Pregnancy Test Kit Packaging machine-for patches...,https://www.reddit.com/r/MachineLearning/comments/9659oi/horizontal_4side_seal_pregnancy_test_kit/,chinamachine,1533891288,,0,1
469,2018-8-10,2018,8,10,17,9659r1,What is Descriptive Statistics and How Do You Choose the Right One for Enterprise Analysis?,https://www.reddit.com/r/MachineLearning/comments/9659r1/what_is_descriptive_statistics_and_how_do_you/,ElegantMicroWebIndia,1533891318,,0,1
470,2018-8-10,2018,8,10,18,965dqy,The internet of intelligent things: How AI makes IoT smarter,https://www.reddit.com/r/MachineLearning/comments/965dqy/the_internet_of_intelligent_things_how_ai_makes/,Victor_Stakh,1533892799,,0,1
471,2018-8-10,2018,8,10,18,965ewc,AWS for Data Science,https://www.reddit.com/r/MachineLearning/comments/965ewc/aws_for_data_science/,fiatluxberk,1533893050,[removed],0,1
472,2018-8-10,2018,8,10,18,965hs3,PE/PP/EVA Automatic Plastic zipper lock bag making machine,https://www.reddit.com/r/MachineLearning/comments/965hs3/peppeva_automatic_plastic_zipper_lock_bag_making/,chinamachine,1533893798,,0,1
473,2018-8-10,2018,8,10,19,965pzc,How does collaboration happen in larger research labs?,https://www.reddit.com/r/MachineLearning/comments/965pzc/how_does_collaboration_happen_in_larger_research/,Artistic_Wrongdoer,1533896336,[removed],0,1
474,2018-8-10,2018,8,10,19,965qyz,Identifying page/content types,https://www.reddit.com/r/MachineLearning/comments/965qyz/identifying_pagecontent_types/,tocka9,1533896652,[removed],0,1
475,2018-8-10,2018,8,10,19,965smj,[D] How does collaboration happen in larger research labs?,https://www.reddit.com/r/MachineLearning/comments/965smj/d_how_does_collaboration_happen_in_larger/,Artistic_Wrongdoer,1533897146,"I got a smaller lab filled with PhD students. I look at these 27 author papers and think to myself: How do all these people contribute to the project?! It's hard for me to get the PhD students to actually collaborate, since they all seem to have their own ambitions. But how can I compete with labs where each project has a larger number of collaborators? Does this happen on its own or is it necessary to force them to work together?",14,26
476,2018-8-10,2018,8,10,19,965so8,[D] How to build a research lab?  Q&amp;A with Yoshua Bengio,https://www.reddit.com/r/MachineLearning/comments/965so8/d_how_to_build_a_research_lab_qa_with_yoshua/,baylearn,1533897161,,1,90
477,2018-8-10,2018,8,10,20,965z4j,Tell me about how you were a victim of data leakage in your ML project [x-post /r/datascience].,https://www.reddit.com/r/MachineLearning/comments/965z4j/tell_me_about_how_you_were_a_victim_of_data/,hawksejmm,1533899115,[removed],0,1
478,2018-8-10,2018,8,10,20,965zgf,[D] Tell me about how you were a victim of data leakage in your ML project [x-post /r/datascience].,https://www.reddit.com/r/MachineLearning/comments/965zgf/d_tell_me_about_how_you_were_a_victim_of_data/,hawksejmm,1533899215,"I think some crucial steps in data science projects are data gathering, data preprocessing and not contaminating your test data by leaking information, which is the usual pitfalls beginners fall into. Can you tell me if have you ever been a victim of data leakage in any of your ML project and how much did this cost you, what were the consequences that you had? ",41,111
479,2018-8-10,2018,8,10,20,9660mp,Backpropagation question: why not update errors during the chain rule?,https://www.reddit.com/r/MachineLearning/comments/9660mp/backpropagation_question_why_not_update_errors/,sedthh,1533899523,"Can someone please explain to me why aren't we recalculating the loss for every layer while doing backpropagation with updated weights? Sine the previous layer's weights were already updated, changing the current layer's weights would only minimize errors for an outdated function, the outputs different values. Wouldn't it make more sense to feedforward every time a layer's weights are updated to be able to find the current layer's weight's gradient in respect to the actual, updated loss value? 

Am I misunderstanding something here? Thanks in advance!",0,1
480,2018-8-10,2018,8,10,20,9663js,ClusterOne - Large scale machine learning platform,https://www.reddit.com/r/MachineLearning/comments/9663js/clusterone_large_scale_machine_learning_platform/,clusterone02,1533900367,[removed],0,1
481,2018-8-10,2018,8,10,20,9669k7,[OC] Estimate calories burnt using silhouettes and accelerometers,https://www.reddit.com/r/MachineLearning/comments/9669k7/oc_estimate_calories_burnt_using_silhouettes_and/,ale152,1533902027,"I built a neural network to estimate the energy expenditure (calories burnt) during daily activities using silhouettes and accelerometers. It's very interesting how a very shallow network was enough to handle simple images like silhouettes.

Link to the source code:

[https://github.com/ale152/CaloriNet](https://github.com/ale152/CaloriNet)

Link to the paper:

[https://arxiv.org/abs/1806.08152](https://arxiv.org/abs/1806.08152)

![video](jzgw8nnh89f11)",0,1
482,2018-8-10,2018,8,10,21,966gv1,Generator loss and discriminator loss are mirror images,https://www.reddit.com/r/MachineLearning/comments/966gv1/generator_loss_and_discriminator_loss_are_mirror/,simmimourya,1533903834,[removed],0,1
483,2018-8-10,2018,8,10,22,966su8,How should I approach to video analysis using Image Recognition in TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/966su8/how_should_i_approach_to_video_analysis_using/,Pingofdeath01,1533906706,[removed],0,1
484,2018-8-10,2018,8,10,22,966szy,Any recommendation about datacamp.com to learn data science and machine learning with Python?,https://www.reddit.com/r/MachineLearning/comments/966szy/any_recommendation_about_datacampcom_to_learn/,vitalysim,1533906742,[removed],0,1
485,2018-8-10,2018,8,10,22,966wog,What is the KMeans Clustering Algorithm and How Does an Enterprise Use it to Analyze Data?,https://www.reddit.com/r/MachineLearning/comments/966wog/what_is_the_kmeans_clustering_algorithm_and_how/,ElegantMicroWebIndia,1533907558,,0,1
486,2018-8-10,2018,8,10,22,96735b,Interesting idea...,https://www.reddit.com/r/MachineLearning/comments/96735b/interesting_idea/,accio-upvotes,1533908986,,0,1
487,2018-8-10,2018,8,10,23,9677cd,[R] Calorie estimation using silhouettes and accelerometers,https://www.reddit.com/r/MachineLearning/comments/9677cd/r_calorie_estimation_using_silhouettes_and/,ale152,1533909892,"![video](lobzz2csv9f11 ""Prediction results"")

Hi all,

I coded a convolutional neural network to estimate calories burnt during daily activities using silhouettes and accelerometers. It's interesting how a shallow network is already good enough to work with so simple images yet with such a complicate dataset.

Links:

[https://arxiv.org/abs/1806.08152](https://arxiv.org/abs/1806.08152)

[https://github.com/ale152/CaloriNet](https://github.com/ale152/CaloriNet)",0,1
488,2018-8-10,2018,8,10,23,9679tu,Anyone here that tried out Google Cloud TPU?,https://www.reddit.com/r/MachineLearning/comments/9679tu/anyone_here_that_tried_out_google_cloud_tpu/,jthat92,1533910396,[removed],0,1
489,2018-8-10,2018,8,10,23,967ayo,All ICML GANs / Generative Papers,https://www.reddit.com/r/MachineLearning/comments/967ayo/all_icml_gans_generative_papers/,generatedLeaf,1533910628,[removed],0,1
490,2018-8-11,2018,8,11,0,967vns,Additional insight on using Topological Data Analysis to discern how neural network actually learn,https://www.reddit.com/r/MachineLearning/comments/967vns/additional_insight_on_using_topological_data/,jtsymonds,1533914688,,1,2
491,2018-8-11,2018,8,11,0,967xjy,[D] Suggest some ML applied projects for a CS major final year project ?,https://www.reddit.com/r/MachineLearning/comments/967xjy/d_suggest_some_ml_applied_projects_for_a_cs_major/,amaljossy,1533915054,It would be nice if it had to do something with augmented reality too. ,7,0
492,2018-8-11,2018,8,11,1,968923,Trouble with Neural Network from Scratch in Matlab,https://www.reddit.com/r/MachineLearning/comments/968923/trouble_with_neural_network_from_scratch_in_matlab/,drummer43_0,1533917211,[removed],0,1
493,2018-8-11,2018,8,11,1,9689ga,[D] NIPS 2018 Workshops,https://www.reddit.com/r/MachineLearning/comments/9689ga/d_nips_2018_workshops/,abhishkk65,1533917281,,5,26
494,2018-8-11,2018,8,11,1,968cdc,"[D] Do you want to shape the future of Deep Learning images for Google Cloud ? If so, please fill out the small survey.",https://www.reddit.com/r/MachineLearning/comments/968cdc/d_do_you_want_to_shape_the_future_of_deep/,b0noi,1533917796,,2,0
495,2018-8-11,2018,8,11,1,968cjf,"Hold on! Human Brain is NOT the fastest one, Yes, thats true!!",https://www.reddit.com/r/MachineLearning/comments/968cjf/hold_on_human_brain_is_not_the_fastest_one_yes/,stormysharad1,1533917825,,0,1
496,2018-8-11,2018,8,11,1,968d9x,Learn AI/ML/Deep Learning with new iOS/Android App!,https://www.reddit.com/r/MachineLearning/comments/968d9x/learn_aimldeep_learning_with_new_iosandroid_app/,MusingEtMachina,1533917963,[removed],0,1
497,2018-8-11,2018,8,11,1,968oar,Continuously active learning,https://www.reddit.com/r/MachineLearning/comments/968oar/continuously_active_learning/,Gaudi91,1533920023,[removed],0,1
498,2018-8-11,2018,8,11,2,968wqs,Did someone already train a RL agent to play multiple (Atari) games?,https://www.reddit.com/r/MachineLearning/comments/968wqs/did_someone_already_train_a_rl_agent_to_play/,zebrasecond,1533921590,[removed],0,1
499,2018-8-11,2018,8,11,2,9697al,[D] A Data Scientist's Reference for Choosing AutoML Python Packages,https://www.reddit.com/r/MachineLearning/comments/9697al/d_a_data_scientists_reference_for_choosing_automl/,adithya_balaji,1533923568,,1,3
500,2018-8-11,2018,8,11,2,96995v,Is my training loss normal?,https://www.reddit.com/r/MachineLearning/comments/96995v/is_my_training_loss_normal/,oussmak,1533923932,[removed],0,1
501,2018-8-11,2018,8,11,3,969jjx,Journey Through The 100 Days of ML Code Challenge,https://www.reddit.com/r/MachineLearning/comments/969jjx/journey_through_the_100_days_of_ml_code_challenge/,avik-jain,1533925877,"I took a Challenge by Siraj Raval called #100DaysOfMLCode, Under which the challenge taker is supposed to learn or code Machine Learning at least 1 hour daily for 100 days. I started off with it and along with learning I started making info graphics of what I learned. I found out that these infographics were very helpful for beginners just like me. 

If you are new to machine Learning or need to brush up you knowledge on Machine Learning then do Check put my repository on GitHub. It Has around 6500+ Stars and 1000+ forks. 

Link To Repository - ([https://github.com/Avik-Jain/100-Days-Of-ML-Code](https://github.com/Avik-Jain/100-Days-Of-ML-Code))",0,1
502,2018-8-11,2018,8,11,3,969q91,Create an iOS application using machine learning,https://www.reddit.com/r/MachineLearning/comments/969q91/create_an_ios_application_using_machine_learning/,prtkgpt,1533927167,,0,1
503,2018-8-11,2018,8,11,3,969qnq,Best content filtering recommendation system algorithm?,https://www.reddit.com/r/MachineLearning/comments/969qnq/best_content_filtering_recommendation_system/,gautiexe,1533927250,"We are trying to make a recommendation engine for our products. Unfortunately our customer dont make many transactions. Hence we want to go the content filtering way? What would be some of the best algorithms we should try? (We have all the masters, images, customer info etc. and we are not shy on using deep learning)",0,1
504,2018-8-11,2018,8,11,4,969yi3,Robots that Could Beat World Cup Champs and How Governments Can Work With and Plan For Artificial Intelligence and Effect of AI on Jobs and Society with Prof Peter Stone,https://www.reddit.com/r/MachineLearning/comments/969yi3/robots_that_could_beat_world_cup_champs_and_how/,The_Syndicate_VC,1533928765,"[Robots that Could Beat World Cup Champs and How Governments Can Work With and Plan For Artificial Intelligence and Effect of AI on Jobs and Society with Prof Peter Stone](https://fringe.fm/23-robots-that-could-beat-world-cup-champs-and-how-governments-can-work-with-and-plan-for-artificial-intelligence-and-effect-of-ai-on-jobs-and-society-with-prof-peter-stone/)

**Prof Peter Stone**is the founder and director of the Learning Agents Research Group (LARG) within the [Artificial Intelligence Laboratory](http://www.cs.utexas.edu/~pstone/index.shtml) in the Department of Computer Science at The University of Texas at Austin, as well as associate department chair and chair of the Universitys Robotics Portfolio Program.

He is also the President, COO, and co-founder of Cogitai, a startup companybuilding AIs that learn continually from interaction with the real world  ie brains or continual-learning AI sof tware.

Peters main research interest is understanding how we can best create complete intelligent agents and focuses mainly on machine learning, multiagent systems, and robotics. Prof Stone has worked with modeling/creating robot soccer, autonomous bidding agents, autonomous vehicles, autonomic computing and social agents.

In 2007 he received the prestigious IJCAI Computers and Thought Award, given biannually to the top AI researcher under the age of 35, and in 2016 he was awarded the ACM/SIGAI Autonomous Agents Research Award.

**In our wide-ranging conversation, we cover many things, including:**

* Why the general public is confused about artificial intelligence
* What is cutting edge in the space of robotics and AI
* How Peter and his team are perfecting soccer robotically
* The big problem with government action/inaction when it comes to AI
* The different types of AI and machine learning and advantages of each
* How Peter and others think about consciousness with machines
* The problems Peter sees with hype and fear mongering
* The implications to healthcare and quality of life in an society with increased automation
* Peters recommendations to governments and regulators on AI
* Why Peter believes we are still a long way off from AGI
* Why AI is overhyped and underhyped",0,1
505,2018-8-11,2018,8,11,5,96aei9,Can someone suggest readings for learning about mathematics behind ML?,https://www.reddit.com/r/MachineLearning/comments/96aei9/can_someone_suggest_readings_for_learning_about/,ibrahmin13,1533931910,,0,1
506,2018-8-11,2018,8,11,5,96alob,LeFlow: Enabling Flexible FPGA High-Level Synthesis of Tensorflow Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/96alob/leflow_enabling_flexible_fpga_highlevel_synthesis/,Drtat,1533933343,,4,1
507,2018-8-11,2018,8,11,5,96ao4e,Small team of AI coders beats Googles machine learning code,https://www.reddit.com/r/MachineLearning/comments/96ao4e/small_team_of_ai_coders_beats_googles_machine/,georgeo,1533933831,,0,1
508,2018-8-11,2018,8,11,5,96aok4,[R] LeFlow: Enabling Flexible FPGA High-Level Synthesis of Tensorflow Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/96aok4/r_leflow_enabling_flexible_fpga_highlevel/,Drtat,1533933920,,6,37
509,2018-8-11,2018,8,11,5,96aqw3,Class imbalance in binary classification (Tutorial and GitHub repo),https://www.reddit.com/r/MachineLearning/comments/96aqw3/class_imbalance_in_binary_classification_tutorial/,wangz10,1533934403,,0,1
510,2018-8-11,2018,8,11,5,96as2c,[N] Julia 1.0 Released,https://www.reddit.com/r/MachineLearning/comments/96as2c/n_julia_10_released/,gwen0927,1533934642,,0,1
511,2018-8-11,2018,8,11,6,96au43,[D] ICML Summary of Transfer Learning and MLT literature,https://www.reddit.com/r/MachineLearning/comments/96au43/d_icml_summary_of_transfer_learning_and_mlt/,svpadd2,1533935039,,0,1
512,2018-8-11,2018,8,11,6,96axxm,[D] Summary of ICML Transfer and Multitask Learning Papers,https://www.reddit.com/r/MachineLearning/comments/96axxm/d_summary_of_icml_transfer_and_multitask_learning/,ueTw2,1533935828,,0,1
513,2018-8-11,2018,8,11,6,96b507,[N] Julia 1.0 Released,https://www.reddit.com/r/MachineLearning/comments/96b507/n_julia_10_released/,trcytony,1533937343,,0,1
514,2018-8-11,2018,8,11,7,96bf22,[P] Now anyone can train Imagenet in 18 minutes,https://www.reddit.com/r/MachineLearning/comments/96bf22/p_now_anyone_can_train_imagenet_in_18_minutes/,inarrears,1533939432,,43,179
515,2018-8-11,2018,8,11,7,96biuo,General image quality assessment,https://www.reddit.com/r/MachineLearning/comments/96biuo/general_image_quality_assessment/,elcric_krej,1533940245,[removed],0,1
516,2018-8-11,2018,8,11,7,96bkhg,Machine learning - /u/GovSchwarzeneggar,https://www.reddit.com/r/MachineLearning/comments/96bkhg/machine_learning_ugovschwarzeneggar/,CHAD_J_THUNDERCOCK,1533940583,,0,1
517,2018-8-11,2018,8,11,8,96bs55,[P] Building a Cross-Framework Deep Learning Compiler via DLPack,https://www.reddit.com/r/MachineLearning/comments/96bs55/p_building_a_crossframework_deep_learning/,Loser777,1533942241,,0,5
518,2018-8-11,2018,8,11,8,96bw7d,Claude Shannon demonstrates machine learning,https://www.reddit.com/r/MachineLearning/comments/96bw7d/claude_shannon_demonstrates_machine_learning/,Cock-tail,1533943121,,0,1
519,2018-8-11,2018,8,11,8,96c1fo,[R] Training Robust Classifiers (Part 2),https://www.reddit.com/r/MachineLearning/comments/96c1fo/r_training_robust_classifiers_part_2/,mttd,1533944318,,0,12
520,2018-8-11,2018,8,11,9,96cl0r,Data Science Cheatsheet,https://www.reddit.com/r/MachineLearning/comments/96cl0r/data_science_cheatsheet/,ml874,1533949023,"Hi guys, been spending some time with *ISLR* and the *Data Science Design Manual* lately.

Thought I'd share the cheatsheet that I ended up creating- covers a bit of probability, statistical learning, modeling, and machine learning. 

Hope it'll be helpful to those just starting out or those who might need a quick refresher (sorry if it's not particularly math heavy). Feel free to point out mistakes or suggest improvements. 

Cheers.",0,1
521,2018-8-11,2018,8,11,11,96d20d,[N] Machine learning links brain connectivity patterns with psychiatric symptoms,https://www.reddit.com/r/MachineLearning/comments/96d20d/n_machine_learning_links_brain_connectivity/,cryptoz,1533953368,,1,4
522,2018-8-11,2018,8,11,11,96dbc4,"Andrew Ng in a lecture video ""create a new feature based on..."" vs Principal Component Analysis, these ideas are conflicting, can someone please explain?",https://www.reddit.com/r/MachineLearning/comments/96dbc4/andrew_ng_in_a_lecture_video_create_a_new_feature/,heylibrarian,1533955834,[removed],0,1
523,2018-8-11,2018,8,11,12,96ddjz,[D] OpenAI &amp; DOTA 2: Game Is Hard,https://www.reddit.com/r/MachineLearning/comments/96ddjz/d_openai_dota_2_game_is_hard/,thebackpropaganda,1533956434,,12,44
524,2018-8-11,2018,8,11,12,96ddxk,"whether to send a ""thanks only"" email back?",https://www.reddit.com/r/MachineLearning/comments/96ddxk/whether_to_send_a_thanks_only_email_back/,youkaichao,1533956523,[removed],0,1
525,2018-8-11,2018,8,11,12,96df80,Data Science Cheatsheet,https://www.reddit.com/r/MachineLearning/comments/96df80/data_science_cheatsheet/,ml874,1533956840,"Hi guys, been spending some time with ISLR and the Data Science Design Manual lately.

Thought I'd share the cheatsheet that I ended up creating- covers a bit of probability, statistical learning, modeling, and machine learning.

Hope it'll be helpful to those just starting out or those who might need a quick refresher (sorry if it's not particularly math heavy). Feel free to point out mistakes or suggest improvements.

Cheers.

Github Repo: [https://github.com/ml874/Data-Science-Cheatsheet](https://github.com/ml874/Data-Science-Cheatsheet)",0,1
526,2018-8-11,2018,8,11,12,96dju3,Mua xe p th thao  u ti H Ni v TPHCM?. Lh: 0943.786.786,https://www.reddit.com/r/MachineLearning/comments/96dju3/mua_xe_p_th_thao__u_ti_h_ni_v_tphcm_lh/,xedapkhaisanghcm,1533958063,,0,1
527,2018-8-11,2018,8,11,16,96era4,Privacy regarding numbers in Images,https://www.reddit.com/r/MachineLearning/comments/96era4/privacy_regarding_numbers_in_images/,GangadharHiShaktiman,1533971268,[removed],0,1
528,2018-8-11,2018,8,11,18,96falf,Help me,https://www.reddit.com/r/MachineLearning/comments/96falf/help_me/,TheBiggestOfFellas,1533978548,[removed],0,1
529,2018-8-11,2018,8,11,18,96fgga,AI Weekly 11 August 2018,https://www.reddit.com/r/MachineLearning/comments/96fgga/ai_weekly_11_august_2018/,TomekB,1533980820,,0,1
530,2018-8-11,2018,8,11,18,96fgzb,Egg Breaking Machine,https://www.reddit.com/r/MachineLearning/comments/96fgzb/egg_breaking_machine/,palakkk,1533981033,,0,1
531,2018-8-11,2018,8,11,18,96fi8d,"[D] How can a machine learn a real dictionary, since they are full of circular dependencies?",https://www.reddit.com/r/MachineLearning/comments/96fi8d/d_how_can_a_machine_learn_a_real_dictionary_since/,verekia,1533981575,"I'm a programmer without a ML background, so I apologize if I don't use the right terminology here and for my lack of ML culture. I'm just very curious about that topic from a theoretical point of view.

A real dictionary defines words using other words. For instance, the words 'A', 'B', and 'C' could be defined like so:

\- A: 'B C'

\- B: 'A C'

\- C: 'A B'

In regular programming, that's straight up circular dependencies, and any program would choke on that. So I'm wondering how can AIs do it (can they even do that yet?), and what kind of approaches work.

I think the way it works for children is that they are taught some essential words like ""dog"" and ""black"" with sensorial association (visually, behaviorial, tactile, auditive...), and then they are taught ""THE dog IS black"", so that's when they figure out what ""the"" and ""is"" mean. From there they can expand their vocabulary exponentially.

For machines I have a few naive ideas of how it would work, and would be interested in hearing what you think about them, and if there are better ones:

\- If the AI is smart enough, it could ""figure it out"" by keeping not-yet-understood definitions in memory and put things together with logic at the end. That would be incredible if that's possible.

\- Maybe hard-coding some definitions with a language that is understood by machines instead of human language could bootstrap the learning process. Just like children learn visually, we could hard-code ""the"", ""dog"", ""is"", ""black"" without using English definitions. Once you reach a critical mass of definitions, it should unlock every English definition.

\- Maybe it is possible to create English-like dictionaries specifically for machines that have less circular dependencies? It's impossible to have zero circular dependencies, but an optimized dictionary could avoid hard-coding too many definitions.

What do you think?

Thanks for reading.",47,81
532,2018-8-11,2018,8,11,19,96fkc2,[D] New Name Candidates for NIPS Conference,https://www.reddit.com/r/MachineLearning/comments/96fkc2/d_new_name_candidates_for_nips_conference/,wei_jok,1533982348,"*Received this message from the NIPS committee:*

**New name for NIPS?**

We would like to hear your opinion about the possibility of changing the name of the NIPS conference. Arguments in favor of keeping the existing name include a desire to respect the intellectual tradition that brought the meeting to where it is today and the strong brand that comes with this tradition. Arguments in favor of changing the name include a desire to better reflect the modern scope of the conference and to avoid distasteful connotations of the name.

Do you think we should change the name of the NIPS conference?

If we were to change the name of the NIPS conference, to what degree do you like the following suggestions? Among the many alternative names suggested by respondents to our first poll, the following are under consideration:

ICLIPS (pronounced eclipse): International Conference on Learning and Information Processing Systems

ICOLS, ICLS, and CLS: variants of the previous name

NILS: Neural Information and Learning Systems

NALS: Natural and Artificial Learning Systems

SNIPS: Synthetic and Neural Information Processing Systems

Moreover, to some of these alternatives, one can consider adding the subtitle ""Natural and Synthetic"" or the subtitle ""Artificial and Natural"".

Please answer the questions below and be sure to press Submit at the bottom of the page.

The NIPS Foundation will collect and analyze the data. Although the poll is not anonymous, the raw data will not be shared outside of the governing body.",35,29
533,2018-8-11,2018,8,11,19,96fpw6,Going Deeper: Understanding How Convolutional Neural Networks Learn Using TDA,https://www.reddit.com/r/MachineLearning/comments/96fpw6/going_deeper_understanding_how_convolutional/,Sinkencronge,1533984588,[https://www.ayasdi.com/blog/artificial-intelligence/going-deeper-understanding-convolutional-neural-networks-learn-using-tda/](https://www.ayasdi.com/blog/artificial-intelligence/going-deeper-understanding-convolutional-neural-networks-learn-using-tda/),0,1
534,2018-8-11,2018,8,11,20,96fzxd,"Theoretically if an ASI was possible , then could it's intelligence be infinitely amplified ?",https://www.reddit.com/r/MachineLearning/comments/96fzxd/theoretically_if_an_asi_was_possible_then_could/,Designer124K,1533988243,[removed],0,1
535,2018-8-11,2018,8,11,21,96g3cg,Levels of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/96g3cg/levels_of_deep_learning/,CantBeLucid,1533989382,,0,1
536,2018-8-11,2018,8,11,21,96g4uh,Diffractive Deep Neural networks???,https://www.reddit.com/r/MachineLearning/comments/96g4uh/diffractive_deep_neural_networks/,jetjodh,1533989852,,0,1
537,2018-8-11,2018,8,11,21,96g502,Singer Tradition 2259 Elektronik Diki Makinesi,https://www.reddit.com/r/MachineLearning/comments/96g502/singer_tradition_2259_elektronik_diki_makinesi/,cazipalisveris38,1533989903,,0,1
538,2018-8-11,2018,8,11,21,96g6r0,"[P] All-DeepLearning-Models-in-Pytorch-Template: A scalable template for PyTorch projects, with examples in Image Segmentation, Object classification, GANs and Reinforcement Learning.",https://www.reddit.com/r/MachineLearning/comments/96g6r0/p_alldeeplearningmodelsinpytorchtemplate_a/,moemen95,1533990439,,0,3
539,2018-8-11,2018,8,11,21,96g8fb,Going Deeper: Understanding How Convolutional Neural Networks Learn Using TDA,https://www.reddit.com/r/MachineLearning/comments/96g8fb/going_deeper_understanding_how_convolutional/,Sinkencronge,1533990942,[removed],0,1
540,2018-8-11,2018,8,11,21,96gc9n,"[R] Framework for state-of-the-art NLP by Zalando (NER, Text Classification, Word Embeddings)",https://www.reddit.com/r/MachineLearning/comments/96gc9n/r_framework_for_stateoftheart_nlp_by_zalando_ner/,filt_er,1533992036,,0,1
541,2018-8-11,2018,8,11,22,96gdpt,[P] Pytorch Project Template - Modular way to handle your projects,https://www.reddit.com/r/MachineLearning/comments/96gdpt/p_pytorch_project_template_modular_way_to_handle/,mrgemy95,1533992463,,0,1
542,2018-8-11,2018,8,11,23,96h2hq,Tutorial Machine learning for beginners: How to become a master in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/96h2hq/tutorial_machine_learning_for_beginners_how_to/,The_Magnum,1533998988,,0,1
543,2018-8-12,2018,8,12,0,96hhhl,Functionally Transparent Neural Network as a Learning Tool,https://www.reddit.com/r/MachineLearning/comments/96hhhl/functionally_transparent_neural_network_as_a/,KadenMc,1534002448,[removed],0,1
544,2018-8-12,2018,8,12,2,96igqo,[R] Policy Optimization as Wasserstein Gradient Flows,https://www.reddit.com/r/MachineLearning/comments/96igqo/r_policy_optimization_as_wasserstein_gradient/,HigherTopoi,1534010115,,1,25
545,2018-8-12,2018,8,12,3,96ilj7,Is self-teaching machine learning worth it?,https://www.reddit.com/r/MachineLearning/comments/96ilj7/is_selfteaching_machine_learning_worth_it/,CryptoShiller2018,1534011166,[removed],0,1
546,2018-8-12,2018,8,12,3,96im6t,[P] Online Visualisation of Convolutional Layer's Activation Map (Gender Detection),https://www.reddit.com/r/MachineLearning/comments/96im6t/p_online_visualisation_of_convolutional_layers/,immortal333,1534011306,,8,13
547,2018-8-12,2018,8,12,3,96iobu,Survey Form (urdu required),https://www.reddit.com/r/MachineLearning/comments/96iobu/survey_form_urdu_required/,kazzastic,1534011790,[removed],0,1
548,2018-8-12,2018,8,12,3,96ioea,Is my training loss normal?,https://www.reddit.com/r/MachineLearning/comments/96ioea/is_my_training_loss_normal/,oussmak,1534011805,,0,1
549,2018-8-12,2018,8,12,3,96iu3l,OpenAI five at The Internation Dota2 comp,https://www.reddit.com/r/MachineLearning/comments/96iu3l/openai_five_at_the_internation_dota2_comp/,Skeptoptimist,1534013098,[removed],0,1
550,2018-8-12,2018,8,12,3,96ivft,My Learning from ML5.js,https://www.reddit.com/r/MachineLearning/comments/96ivft/my_learning_from_ml5js/,i_am_adl,1534013390,"## Hello Everyone,

I have been Experimenting with ML5.js for sometime now, I would Like to share my leanings with the community.

https://i.redd.it/eh9kl1rxeif11.png

**ML.js**    is a recently developed high level Library which aims to make machine    learning approachable for a broad audience of artists, creative  coders,   and students. The Library is developed at the **New York University and**    has been publicly released on \*\*July 2018.\*\*The library provides   access  to machine learning algorithms,task and models in the browser,    building on top of  [TensorFlow.js](https://js.tensorflow.org/)with no other external dependencies.So, It can be compared to Keras. [**ML.js**](https://ml5js.org/) is built over [TensorFlow.js](https://js.tensorflow.org/)and it uses the functionality of [TensorFlow.js](https://js.tensorflow.org/)at the backend but makes life easier for people who are new to Machine Learning arena.

https://i.redd.it/1d76cudzeif11.png

[**ML.js**](https://ml5js.org/) is built with a Motive to simplify things out for beginners. We can compare this to [Keras](https://keras.io/).    The Motivation behind Keras was to make ML/DL in python so Simple  that   it can be used by Beginners. Similar is the case with ML.js..

This    is possible by making a wrapper around the Tensorflow.js library and    use all the functionality at the backend. So Intuitively, It is an  Easy   to use API for TensorFlow.js.

## Getting Started withML.js

We can use [**ML.js**](https://ml5js.org/) by  Referencing the [latest version](https://unpkg.com/ml5@0.1.1/dist/ml5.min.js) of it in our project, by just using a script tag in an HTML file as below:

    &lt;html&gt;
    &lt;head&gt;
      &lt;title&gt;Getting Started&lt;/title&gt;
    
               &lt;script src=""https://unpkg.com/ml5@0.1.1/dist/ml5.min.js""&gt;&lt;/script&gt;
    
        &lt;/head&gt;
       &lt;body&gt;
      &lt;script&gt;
           // Your code will go here
         &lt;/script&gt;
       &lt;/body&gt;
    &lt;/html&gt;

Thats all! 

You are ready to go..

Please Consider watching this Video for Detailed explanation on ML5.js:-

r/[https://youtu.be/D1jxmyQwM1A](https://youtu.be/D1jxmyQwM1A)

## Promises and Callbacks

[**ML.js**](https://ml5js.org/) supports both **error-first callbacks** and Promises in all methods.

## Using Callbacks

**ML.js** uses a pattern referred to as an **error-first callback**:

**For example** if you are using the \*\*imageClassifier()\*\*method, you will need to construct it in the following way:

    // Pass a callback function to constructor   
    const classifier = ml5.imageClassifier('MobileNet', function(err, model) {        
    
         console.log('Model Loaded!');     
     
    }       
    
    // Make a prediction with the selected image and pass a callback function with two arguments   
    classifier.predict(image, function(err, results) {       
     
         // Check for errors. If no errors, then do something with the results       
    
    });

Error first callbacks is a convention common to many JavaScript libraries that is implemented in **ML.js**. The language JavaScript itself does not enforce this pattern. Before implementation, we need to understand that most **ML.js** methods and functions are asynchronous ( *because machine learning models can take significant amounts of time to process inputs and generate outputs!).*

## Using Promises

[**ML.js**](https://ml5js.org/) also supports [Promises](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise). If no callback is provided to any asynchronous function then a Promise is returned.

With Promises, the image classification example can be used in the following way:

// No callback needs to be passed to use Promises.

    ml5.imageClassifier('MobileNet')     
      .then(classifier =&gt; classifier.predict(image))    
      .then(results =&gt; {     
           
           // Do something with the results        
     });

## Image Classification UsingML.js - An Example Casestudy

## imageClassifier()

**ML.js**    can use neural networks to recognize the content of images.    ml5.imageClassifier()is a default method to create an object that    classifies an image using a pre-trained models like MobileNet etc.

The **ML.js** library accesses these model from the cloud.

**Let us build a concrete example:-**

We will use the p5 Library along with **ML.js.** p5 is a Powerful yet simple library to use in Javascript.You can find more details [here.](https://p5js.org/) You can always use Vanilla JavaScript or other frame works of your choice with [**ML.js.**](https://ml5js.org/)

Before we start with the Javascript part,We will need to host a local server using NodeJS.

**Below is the Code:-**

    let express = require(""express"");  
    let app = express();  
         
    app.use(function(req, res, next){    
          console.log(`${new Date()} - ${req.method} reqest for ${req.url}`);    
         next();  
     }); 
          
    app.use(express.static(""../local""));      
     
    app.listen(8081, function(){   
          console.log(""Serving at 8081"")   
    });

After the Local server is Successfully up and Running, We can start off with the coding of HTML and JS files.

**Index.html**

    &lt;html&gt;      
     &lt;head&gt;   
           &lt;!-- importing p5 library into the project --&gt;       
      &lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.6.1/p5.js""&gt;&lt;/script&gt;
        
          &lt;!-- importing ML5 library into the project --&gt;     
      &lt;script src=""https://unpkg.com/ml5@0.1.1/dist/ml5.min.js""&gt;&lt;/script&gt;   
    
           &lt;!-- importing p5 addons library into the project --&gt;       
      &lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.6.1/addons/p5.dom.min.js""&gt;&lt;/script&gt; 
       
           &lt;!-- importing main.js  into the project --&gt;      
        &lt;script src=""./main.js"" type=""text/javascript""&gt;&lt;/script&gt;       
    &lt;/head&gt;  
     &lt;body&gt;       
    &lt;/body&gt;  
    &lt;/html&gt;

**main.js**

    //initialization of the model object  
    let mobileNet;
    
    //setup function is the Startup function in P5   
    function setup()   {
      //create canvas on the page   
       createCanvas(400,300);    
    
      //initialize the image in a variable       
      img_dog=createImg('./dog.jpg',imageReady);    
    
      //hide the image from displaying it on the Page    
      img_dog.hide();        
    
      //initialize the mobilenet object with a callback       
      mobileNet= ml5.imageClassifier('MobileNet',ModelLoaded);      
    }
    
    //callback function indicating  the image is ready and is Displayed on the Canvas   
    function imageReady()   {
    
           //Displaying the image on the canvas     
           image(img_dog,0,0,400,300);   
    
    }       
    
    //callback function for when the model is ready for prediction   
    function ModelLoaded()   {       
           console.log('Model is ready');       
           
           //predicting the image after the Image and Model is Ready, Its again need a callback because prediction takes time   
           mobileNet.predict(img_dog,result)  
     }     
      
    //callback function to get the results   
    function result(err,res)   {    
    
           //check for errors   
            if(err)       
            {   
             //log the error if any    
             console.error(err)      
            }    
           else
           {   
            //log the result    
            console.log(res);  
      
            //get the label from the JSON result   
           let label = res[0].className;     
       
            //get the probablity from the JSON result   
           let prob = res[0].probability;  
         
           //creation of DOM and printing the label and probability    
           fill(0);    
           createP(label);    
           createP(prob);   
        
          }  
     }

Thats it..We have Successfully Implemented a Image classifier using **ML.js.**

You can go to [http://localhost:8081/index.html](http://localhost:8081/main.html) and check the results. The Screenshot is as below:-

[ScreenShot of WebAPP](https://i.redd.it/f8ju2uvhfif11.png)

&gt;Note: This above example  was not focused on UI rather it was focused basically on getting the Basics of **ML.js** clear\*\*. UI can be improved and there is no limit to UI.\*\*

Please Consider watching this Video for Detailed explanation on Image Classification using **ML.js**:-

r/[https://youtu.be/NbGdBp7Dccs](https://youtu.be/NbGdBp7Dccs)

# My Take onML5.js

This is excellent for coders who are familiar with JavaScript &amp; HTML and are trying to find their way in the ML/DL world!

It    makes things a lot simpler for people coming from a non-ML/DL    background, but who are looking to understand this field.It makes    machine learning approachable for a broad audience of artists, creative    coders, and students.

The use cases for this are many, and I personally think its something we need at the moment.

What do you think of ML5? Let me know your views...

**Thanks For reading and giving your Precious Time.**",0,1
551,2018-8-12,2018,8,12,4,96j48t,[D] Data Science Cheatsheet,https://www.reddit.com/r/MachineLearning/comments/96j48t/d_data_science_cheatsheet/,sugarhilldt2,1534015386,,0,1
552,2018-8-12,2018,8,12,5,96jhb3,"[P] Implementations of MT with Attention, Image Captioning, Text Generation, GAN (Keras and TensorFlow Eager)",https://www.reddit.com/r/MachineLearning/comments/96jhb3/p_implementations_of_mt_with_attention_image/,olegnikit,1534018326,,0,1
553,2018-8-12,2018,8,12,5,96jk52,[P] TensorFlow Eager example notebooks,https://www.reddit.com/r/MachineLearning/comments/96jk52/p_tensorflow_eager_example_notebooks/,SupraluminalShift,1534018960,,0,1
554,2018-8-12,2018,8,12,5,96jm4c,"[R] ""Alignment for advanced machine learning systems""  MIRI",https://www.reddit.com/r/MachineLearning/comments/96jm4c/r_alignment_for_advanced_machine_learning_systems/,The_Ebb_and_Flow,1534019405,,0,8
555,2018-8-12,2018,8,12,5,96jpjs,SHERPA is an open-source Python library for hyperparameter tuning with a choice of algorithms and a visualization dashboard,https://www.reddit.com/r/MachineLearning/comments/96jpjs/sherpa_is_an_opensource_python_library_for/,larshh,1534020200,,0,1
556,2018-8-12,2018,8,12,5,96jsji,Creating an Indian Faces dataset. How to simulate different lighting conditions?,https://www.reddit.com/r/MachineLearning/comments/96jsji/creating_an_indian_faces_dataset_how_to_simulate/,Kotkaikiso,1534020904,[removed],0,1
557,2018-8-12,2018,8,12,6,96ju9t,"Building a Multi-GPU Work station (Ubuntu, Deep Learning)",https://www.reddit.com/r/MachineLearning/comments/96ju9t/building_a_multigpu_work_station_ubuntu_deep/,curious_geek_90,1534021299,[removed],0,1
558,2018-8-12,2018,8,12,7,96kc1e,[research] AI Driving Olympics at NIPS 2018: Everybody can compete with the pros!,https://www.reddit.com/r/MachineLearning/comments/96kc1e/research_ai_driving_olympics_at_nips_2018/,andrea,1534025484,"I am one of the organizers of [the AI Driving Olympics](https://www.duckietown.org/research/ai-driving-olympics) at NIPS 2018, in which 6 universities are involved (U. Montral / MILA, ETH Zrich, Georgia Tech, Tsinghua, NCTU, TTIC), plus 2 industry partners (self-driving car company nuTonomy and Amazon Web Services).

We are excited because this is going to be the first robotic competition at a machine learning conference: you send your code - we run it on our robots. Or, you can get a robot yourself through [the Kickstarter](https://www.kickstarter.com/projects/163162211/duckietown-a-playful-road-to-learning-robotics-and?ref=ay75ep) run by our non-profit foundation.

AMA in the comments. I am here with students and collaborators /u/stratanis, /u/gzardini, /u/manfred_diaz, /u/afdaniele, /u/duckietown-udem.",16,140
559,2018-8-12,2018,8,12,7,96khco,Given a great opportunity to research.. don't know what to do with it.,https://www.reddit.com/r/MachineLearning/comments/96khco/given_a_great_opportunity_to_research_dont_know/,GetmeOutofNowhere,1534026736,[removed],0,1
560,2018-8-12,2018,8,12,7,96kl8h,Methods to Group Scanned Pages Together,https://www.reddit.com/r/MachineLearning/comments/96kl8h/methods_to_group_scanned_pages_together/,TheBottleSeller,1534027695,[removed],0,1
561,2018-8-12,2018,8,12,8,96ku6a,Structuring R projects: a pragmatic perspective,https://www.reddit.com/r/MachineLearning/comments/96ku6a/structuring_r_projects_a_pragmatic_perspective/,chrisvoncsefalvay,1534029906,,0,1
562,2018-8-12,2018,8,12,10,96lkrr,What separates good and bad ML researchers and engineers?,https://www.reddit.com/r/MachineLearning/comments/96lkrr/what_separates_good_and_bad_ml_researchers_and/,prgrmrstrvng,1534036786,[removed],0,1
563,2018-8-12,2018,8,12,10,96llpf,[D] Best way to manage ML experiements,https://www.reddit.com/r/MachineLearning/comments/96llpf/d_best_way_to_manage_ml_experiements/,schrodingershit,1534037034,"Does someone know how to efficiently manage ML experiments. Every time I change a parameter, I had to create a new branch on github and run the experiment there. I know this is stupid, does anyone else have a classy solution?",12,28
564,2018-8-12,2018,8,12,10,96lt1x,UX Design Guide for Data Scientists and AI Products,https://www.reddit.com/r/MachineLearning/comments/96lt1x/ux_design_guide_for_data_scientists_and_ai/,snazrul,1534038964,,0,1
565,2018-8-12,2018,8,12,10,96lter,"[P] Interactive Machine Learning, Deep Learning and Statistics websites - a collaborative list",https://www.reddit.com/r/MachineLearning/comments/96lter/p_interactive_machine_learning_deep_learning_and/,pmigdal,1534039066,,4,77
566,2018-8-12,2018,8,12,13,96mrlz,Nazar: Electronic component classification using tensorflow and react-native with server deployed to Heroku,https://www.reddit.com/r/MachineLearning/comments/96mrlz/nazar_electronic_component_classification_using/,arya_minus,1534048644,,0,1
567,2018-8-12,2018,8,12,14,96n23q,Old Model Teaching The New Model,https://www.reddit.com/r/MachineLearning/comments/96n23q/old_model_teaching_the_new_model/,largehawaiian,1534052019,,0,1
568,2018-8-12,2018,8,12,15,96nb7t,Speeding up word distance calculation 100x,https://www.reddit.com/r/MachineLearning/comments/96nb7t/speeding_up_word_distance_calculation_100x/,snakers41,1534055304,[removed],0,1
569,2018-8-12,2018,8,12,16,96noaw,Question: Freelance Platforms,https://www.reddit.com/r/MachineLearning/comments/96noaw/question_freelance_platforms/,junwonpk,1534060353,[removed],0,1
570,2018-8-12,2018,8,12,18,96o31c,[P] FAGAN: Full Attention GAN,https://www.reddit.com/r/MachineLearning/comments/96o31c/p_fagan_full_attention_gan/,akanimax,1534066451,"After reading the SAGAN (Self Attention GAN) paper, I wanted to try it, and experiment with it more. I decided to write a python package called "" attn_gan_pytorch"" similar to my previous pro-gan-pth package. I first trained a model as described in the SAGAN paper, and then came up with this new layer called full attention. 


So, the GAN created using this layer should be FAGAN.


github code -&gt; https://github.com/akanimax/fagan


medium blog -&gt; https://medium.com/@animeshsk3/fagan-full-attention-gan-2a29227dc014


python package -&gt; https://pypi.org/project/attn-gan-pytorch/",4,10
571,2018-8-12,2018,8,12,19,96o7tu,Is it worth writing a research paper even if I don't have means of publishing it?,https://www.reddit.com/r/MachineLearning/comments/96o7tu/is_it_worth_writing_a_research_paper_even_if_i/,mankadronit,1534068508,"I'm doing a Essay Grading using LSTMs project and I have achieved performance equal to current state of the art systems. So I want to write a paper on my method(and architecture). But I'm pretty sure my chances of publishing a paper are very low.

So can I just get by by publishing it on arXiv just to gain some CV leverage? I'm looking forward to do a Master's in CS/ML and I thought that this would boost my profile a little bit.",0,1
572,2018-8-12,2018,8,12,19,96oc6n,How to know which neural network to use?,https://www.reddit.com/r/MachineLearning/comments/96oc6n/how_to_know_which_neural_network_to_use/,Ineedhelpwithnn,1534070359,"I've been given a job, which is to increase the accuracy of a network. It's currently a lstm model. My laptop isn't up to scratch of running lots of tests (running the lstm is taking over 3 hours and counting) and I'm wondering if there is a way to check if this is the best network? Is this just something I'll have to test? Or something people will learn with experience and I simply haven't worked in this field long enough...? the task is figuring out when someone is resting or sprinting. Is a lstm appropriate for this. I wasn't the one who originally coded it and therefore I'm not 100% why it was used. Any help would be greatly appreciated. ",0,1
573,2018-8-12,2018,8,12,20,96olv7,Yann LeCun's view on youngsters in the field.,https://www.reddit.com/r/MachineLearning/comments/96olv7/yann_lecuns_view_on_youngsters_in_the_field/,equinox932,1534074167,,0,1
574,2018-8-12,2018,8,12,20,96oo2i,A small team of student AI coders beats Googles machine-learning code,https://www.reddit.com/r/MachineLearning/comments/96oo2i/a_small_team_of_student_ai_coders_beats_googles/,MattyBv3,1534075024,,0,1
575,2018-8-12,2018,8,12,21,96oshl,"Is there any repository about using Lstm policy in continual actions envs, especially mujoco ?",https://www.reddit.com/r/MachineLearning/comments/96oshl/is_there_any_repository_about_using_lstm_policy/,RebornHugo,1534076504,[removed],0,1
576,2018-8-12,2018,8,12,21,96otkc,"Why are word embeddings not ""activated"" when used in downstream tasks?",https://www.reddit.com/r/MachineLearning/comments/96otkc/why_are_word_embeddings_not_activated_when_used/,P4ND0RA_,1534076869,[removed],0,1
577,2018-8-12,2018,8,12,21,96ou4w,[R] Echo State Networks. Geoff Hinton presents.,https://www.reddit.com/r/MachineLearning/comments/96ou4w/r_echo_state_networks_geoff_hinton_presents/,moschles,1534077063,,20,96
578,2018-8-12,2018,8,12,21,96ou9t,Linear compression in python: PCA vs unsupervised feature selection,https://www.reddit.com/r/MachineLearning/comments/96ou9t/linear_compression_in_python_pca_vs_unsupervised/,efavdb,1534077106,,0,1
579,2018-8-12,2018,8,12,21,96ovct,"[D] Why are word embeddings not ""activated"" when used in downstream tasks?",https://www.reddit.com/r/MachineLearning/comments/96ovct/d_why_are_word_embeddings_not_activated_when_used/,P4ND0RA_,1534077467,"In vanilla fully connected, convolutional or recurrent layers, the outputs are usually activated with a non-linear activation function (e.g. ReLU, TanH, etc.). A word embedding is in principal x * W, where x is a one-hot vector and W the word embedding matrix. I.e. a word embedding is also some kind of output from the raw data. 

However, when this serves as input to any model (FC, CNN, RNN), usually they are passed unactivated. Is there any particular reason why this is not done? Or does it empirically just not lead to any improvements?",6,14
580,2018-8-12,2018,8,12,23,96phow,[R] Transfer Learning in NLP | Universal Language Models,https://www.reddit.com/r/MachineLearning/comments/96phow/r_transfer_learning_in_nlp_universal_language/,vector_machines,1534085028,,2,19
581,2018-8-12,2018,8,12,23,96pl7l,Academic Torrents - Making 27TB of research data available (including datasets),https://www.reddit.com/r/MachineLearning/comments/96pl7l/academic_torrents_making_27tb_of_research_data/,vasili111,1534085875,,0,1
582,2018-8-13,2018,8,13,0,96plvu,[d] Convolutional DRAW compressed image sizes,https://www.reddit.com/r/MachineLearning/comments/96plvu/d_convolutional_draw_compressed_image_sizes/,wfdctrl,1534086040,"I'm trying to implement the Convolutional DRAW paper. I can't figure out how the compressed image sizes are calculated. It seems to me that the size of latent variables is greater than the number of pixels in the image. If there are stride 2 convolutions between the input and the hidden layer, that means that the feature maps are 16x16 and there are 12 of them, that means there are 3072 floats to store for each time step. The original image size is 32x32x3, that means the uncompressed size is 3072 bytes, which is less than the size of latent variables for a single time step. How does the method compresses anything? Am I missing something?

Also in the input distribution is turned into a Gaussian by adding uniform noise and then dividing the likelihood p(x|z) by q0(x). Does anyone know how to calculate q0(x)?

Here it the [paper](https://arxiv.org/pdf/1604.08772.pdf).",4,2
583,2018-8-13,2018,8,13,0,96pq25,[D] Unsupervised pretraining on images for transfer learning?,https://www.reddit.com/r/MachineLearning/comments/96pq25/d_unsupervised_pretraining_on_images_for_transfer/,HigherTopoi,1534086974,"I've read a paper on arXiv about what is written in this title a while ago, but I've lost a track of it. The paper was probably released from June to July, and it's a computer vision counterpart of OpenAI's similar paper using Transformer LM. These papers essentially say that unsupervised pretraining on a large dataset plus fine-tuning beats existing algorithms without pretraining. Could anyone give me the link to the former paper? ",3,23
584,2018-8-13,2018,8,13,0,96pt7z,python class,https://www.reddit.com/r/MachineLearning/comments/96pt7z/python_class/,saket0565,1534087712,"On the following code given below i have two doubts:

1.class MajorityVoteClassifier(BaseEstimator, ClassifierMixin)- why we're using BaseEstimator, ClassifierMixin in the bracket of class i've seen some e.g in where they even write python.

2. why we,ve to write a seperate method predic\_proba inside the class as each classifier has the attribute predict\_proba (when i'm not using it an error comes that MajorityVoteClassifier class has no attribute predict\_proba )

&amp; also why we're using get\_params method as we're not using this method(if not written shows an error)

\#MajorityVoteClassifier

from sklearn.base import BaseEstimator

from sklearn.base import ClassifierMixin

from sklearn.preprocessing import LabelEncoder

from sklearn.externals import six

from sklearn.base import clone

from sklearn.pipeline import \_name\_estimators

import numpy as np

import operator

class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):

def \_\_init\_\_(self, classifiers, vote='classlabel', weights=None):

self.classifiers = classifiers

self.named\_classifiers = {key: value 

for key, value in \_name\_estimators(classifiers)}

[self.vote](https://self.vote) = vote

self.weights = weights        

def fit(self, X, y):

self.lae = LabelEncoder()

self.subset=\[\]

for clf in self.classifiers:

fitted\_clf = [clf.fit](https://clf.fit)(X, self.lae.fit\_transform(y))

\#print(clf.predict\_proba(X))

self.subset.append(fitted\_clf)

return self

def predict(self, X):

if self.vote=='classlabel':

clf\_label = \[clf.predict(X)

for clf in self.subset\]

y\_pred1 = np.argmax(np.bincount(clf\_label, weights=self.weight))

y\_pred = self.lae.inverse\_transform(y\_pred1)

elif [self.vote](https://self.vote) == 'probability':

y\_pred1 = np.argmax(self.predict\_proba(X), axis=1)

y\_pred = self.lae.inverse\_transform(y\_pred1)

return y\_pred

def predict\_proba(self, X):

probas = np.asarray(\[clf.predict\_proba(X)

for clf in self.subset\])

avg\_proba = np.average(probas,

axis=0, weights=self.weights)

return avg\_proba    

def get\_params(self, deep=True):

"""""" Get classifier parameter names for GridSearch""""""

if not deep:

return super(MajorityVoteClassifier, self).get\_params(deep=False)

else:

out = self.named\_classifiers.copy()

for name, step in six.iteritems(self.named\_classifiers):

for key, value in six.iteritems(step.get\_params(deep=True)):

out\['%s\_\_%s' % (name, key)\] = value

return out

clf\_labels = \['Logistic Regression', 'Decision Tree', 'KNN'\]

my\_vc = MajorityVoteClassifier(classifiers=\[pipe1, clf2, pipe3\])

clf\_labels+=\['Majority Voting'\]

for clf, label in zip(\[pipe1, pipe2, pipe3, my\_vc\], clf\_labels):

score = cross\_val\_score(estimator=clf,

X=X\_train, y=y\_train, cv=10, scoring='roc\_auc')

print(""ROC\_AUC: %0.2f (+/- %0.2f) \[%s\]""

%(score.mean(), score.std(), label))

THANKS",0,1
585,2018-8-13,2018,8,13,0,96px1u,"[P] Generalization of Adam, AdaMax, AMSGrad algorithms",https://www.reddit.com/r/MachineLearning/comments/96px1u/p_generalization_of_adam_adamax_amsgrad_algorithms/,sss135,1534088587,,1,1
586,2018-8-13,2018,8,13,1,96qfzq,Understanding deep learning,https://www.reddit.com/r/MachineLearning/comments/96qfzq/understanding_deep_learning/,Stelman,1534092860,,0,1
587,2018-8-13,2018,8,13,3,96rane,Why would I use a derivative of sigmoid?,https://www.reddit.com/r/MachineLearning/comments/96rane/why_would_i_use_a_derivative_of_sigmoid/,kir486680,1534099643,[removed],0,1
588,2018-8-13,2018,8,13,3,96ratv,Writing Tensorflow code in explicit files?,https://www.reddit.com/r/MachineLearning/comments/96ratv/writing_tensorflow_code_in_explicit_files/,jthat92,1534099683,,0,1
589,2018-8-13,2018,8,13,4,96rrua,"I just want some basic advice from anyone senior in this field, like is there any kind of road-map for Machine learning or Data Science. I learned ML, it's algorithms from online courses till now but I don't know what should I do now? What to learn, how to proceed, where to participate, etc.",https://www.reddit.com/r/MachineLearning/comments/96rrua/i_just_want_some_basic_advice_from_anyone_senior/,Kunalvats0,1534103406,[removed],0,1
590,2018-8-13,2018,8,13,4,96rssc,Why you need to learn Machine Learning Right Now!!,https://www.reddit.com/r/MachineLearning/comments/96rssc/why_you_need_to_learn_machine_learning_right_now/,heemanshusuri,1534103611,,0,1
591,2018-8-13,2018,8,13,5,96rw6o,[D] What is SOTA in Discrete / Categorical Latent Variables?,https://www.reddit.com/r/MachineLearning/comments/96rw6o/d_what_is_sota_in_discrete_categorical_latent/,throwaway775849,1534104326,"My understanding is limited in being able to compare their stability, scalability, and efficiency, and I'm hoping more enlightened individuals can contribute additional methods or clarify any inaccuracies. Below is my soft-ranking from least successful to most, looking at methods that allow backprop through discrete latent variables.

* Gumbel Softmax / Concrete Distribution
* Vector Quantization (VQ-VAE) - uses a hack, copying the gradient
* Decomposed Vector Quantization (DVQ) - [arxiv](https://arxiv.org/abs/1803.03382)
* Self Organizing Map (SOM-VAE) [arxiv](https://arxiv.org/abs/1806.02199)

",7,12
592,2018-8-13,2018,8,13,5,96rz23,[D] Poll: How do you use jupyter notebooks for ML?,https://www.reddit.com/r/MachineLearning/comments/96rz23/d_poll_how_do_you_use_jupyter_notebooks_for_ml/,rstoj,1534104944,,13,6
593,2018-8-13,2018,8,13,5,96s3s3,Machine Learning Can Identify the Authors of Anonymous Code,https://www.reddit.com/r/MachineLearning/comments/96s3s3/machine_learning_can_identify_the_authors_of/,MBA_ErnestoCR,1534106009,,0,1
594,2018-8-13,2018,8,13,5,96s84h,ML internships for undergrads,https://www.reddit.com/r/MachineLearning/comments/96s84h/ml_internships_for_undergrads/,hoopercuber,1534106989,[removed],0,1
595,2018-8-13,2018,8,13,6,96sf27,Looking for some help understanding LSTM/RNN Models (especially with Keras),https://www.reddit.com/r/MachineLearning/comments/96sf27/looking_for_some_help_understanding_lstmrnn/,kiunthmo,1534108499,[removed],0,1
596,2018-8-13,2018,8,13,6,96socq,I trained a DCGAN to generate sneakers. This is the output after 100 epochs,https://www.reddit.com/r/MachineLearning/comments/96socq/i_trained_a_dcgan_to_generate_sneakers_this_is/,oppai_suika,1534110553,,0,1
597,2018-8-13,2018,8,13,7,96svx5,[P] Academic Torrents: 27TB of research data,https://www.reddit.com/r/MachineLearning/comments/96svx5/p_academic_torrents_27tb_of_research_data/,chisai_mikan,1534112287,,0,1
598,2018-8-13,2018,8,13,7,96swa7,Artificial Intelligence Finance News,https://www.reddit.com/r/MachineLearning/comments/96swa7/artificial_intelligence_finance_news/,eyeonai,1534112374,[removed],0,1
599,2018-8-13,2018,8,13,7,96t39e,Pooling vs Stride on CNN,https://www.reddit.com/r/MachineLearning/comments/96t39e/pooling_vs_stride_on_cnn/,kingsj0405,1534114020,[removed],0,1
600,2018-8-13,2018,8,13,7,96t45z,[P] Academic Torrents: A distributed system for sharing enormous datasets,https://www.reddit.com/r/MachineLearning/comments/96t45z/p_academic_torrents_a_distributed_system_for/,chisai_mikan,1534114231,,27,305
601,2018-8-13,2018,8,13,7,96t5xs,[D] Informal poll for new name of NIPS conference,https://www.reddit.com/r/MachineLearning/comments/96t5xs/d_informal_poll_for_new_name_of_nips_conference/,inarrears,1534114654,,29,14
602,2018-8-13,2018,8,13,11,96urag,[R] [Official Survey] New name for NIPS?,https://www.reddit.com/r/MachineLearning/comments/96urag/r_official_survey_new_name_for_nips/,downtownslim,1534128889,,0,3
603,2018-8-13,2018,8,13,12,96ut8a,How much of a role will feature selection have in the future?,https://www.reddit.com/r/MachineLearning/comments/96ut8a/how_much_of_a_role_will_feature_selection_have_in/,rayven1lk,1534129376,"Most of the points in favor of feature selection are along the lines of computational ease and feature interpretability.

However, there is a lot of research being done that suggests the hypothesis-driven approach in modeling leads to less than optimal results in terms of prediction power.

What do you think of performing feature selection? Is there an absolute case in the future for getting rid of it, especially in the case of fields where there is a lot of subject-matter knowledge?",0,1
604,2018-8-13,2018,8,13,12,96uxzg, ! !  - G.S ,https://www.reddit.com/r/MachineLearning/comments/96uxzg/__gs_/,Woodworking94,1534130577,,0,1
605,2018-8-13,2018,8,13,12,96v2sq,Face recognition with Go,https://www.reddit.com/r/MachineLearning/comments/96v2sq/face_recognition_with_go/,ndha1995,1534131806,,0,1
606,2018-8-13,2018,8,13,12,96v4q7,How to start deep learning?,https://www.reddit.com/r/MachineLearning/comments/96v4q7/how_to_start_deep_learning/,tarunguntaka,1534132313,[removed],0,1
607,2018-8-13,2018,8,13,13,96vgvr,[R] [1808.03578] Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning,https://www.reddit.com/r/MachineLearning/comments/96vgvr/r_180803578_dropout_is_a_special_case_of_the/,evc123,1534135638,,24,36
608,2018-8-13,2018,8,13,14,96vtci,"[P] GPU/CPU optimized TensorFlow 1.10 build (CUDA 9.2, CuDNN 7.2, AVX2)",https://www.reddit.com/r/MachineLearning/comments/96vtci/p_gpucpu_optimized_tensorflow_110_build_cuda_92/,Inori,1534139456,,0,1
609,2018-8-13,2018,8,13,15,96w47a,28 Expert Opinions Every Business Leader Should Know About Enterprise AI,https://www.reddit.com/r/MachineLearning/comments/96w47a/28_expert_opinions_every_business_leader_should/,aditya44,1534142896,,0,1
610,2018-8-13,2018,8,13,15,96w64c,[xpost from r/Dota2] Understanding OpenAI Five - A simplified dissection by MIT PhD in AI,https://www.reddit.com/r/MachineLearning/comments/96w64c/xpost_from_rdota2_understanding_openai_five_a/,evanthebouncy,1534143544,,1,2
611,2018-8-13,2018,8,13,16,96w6qs,[R] What did you learn?,https://www.reddit.com/r/MachineLearning/comments/96w6qs/r_what_did_you_learn/,kmkolasinski,1534143733,"Hi, just sharing my slides from presentations which I gave in my company at our weekly meetings called ""What did you learn"". Two years ago I switched from being a physicist to the ML/DL industry. Making those presentations gave me a huge boost in my understanding of ML concepts. The slides cover different topics, but mostly they tackle theoretical concepts like variational inference, self normalizing neural nets etc. Some of them include additional material like jupyter notebooks. 

Link to slides: [link](https://github.com/kmkolasinski/deep-learning-notes/tree/master/seminars)",7,24
612,2018-8-13,2018,8,13,16,96wbku,Machine learning in Finance - Present and Future Applications,https://www.reddit.com/r/MachineLearning/comments/96wbku/machine_learning_in_finance_present_and_future/,imarticus_nirmal,1534145340,,0,1
613,2018-8-13,2018,8,13,16,96wdc8,What is the difference between Machine Learning and Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/96wdc8/what_is_the_difference_between_machine_learning/,imarticus_nirmal,1534145939,,0,1
614,2018-8-13,2018,8,13,16,96wfg4,K-means Clustering of Wine Data  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/96wfg4/kmeans_clustering_of_wine_data_coinmonks_medium/,coinmonks,1534146723,,0,1
615,2018-8-13,2018,8,13,17,96whrd,Is Machine Learning the Best Way To Grow a FinTech Company?,https://www.reddit.com/r/MachineLearning/comments/96whrd/is_machine_learning_the_best_way_to_grow_a/,imarticus_nirmal,1534147522,,0,1
616,2018-8-13,2018,8,13,17,96wo6k,"MXNet implementation of Deepminds latest paper ""Neural Arithmetics Logic Units""",https://www.reddit.com/r/MachineLearning/comments/96wo6k/mxnet_implementation_of_deepminds_latest_paper/,gautamrbharadwaj,1534149807,[https://github.com/gautam1858/Neural-Arithmetic-Logic-Units](https://github.com/gautam1858/Neural-Arithmetic-Logic-Units),0,1
617,2018-8-13,2018,8,13,19,96x4mp,"[N] Pictures to Poetry, Facebook teaches ML, TensorFlow 1.10.0, MnasNet, Bixby Speaker, AI in 2026,",https://www.reddit.com/r/MachineLearning/comments/96x4mp/n_pictures_to_poetry_facebook_teaches_ml/,omarsar,1534155408,,0,1
618,2018-8-13,2018,8,13,19,96x50i,K-means Clustering of Wine Data,https://www.reddit.com/r/MachineLearning/comments/96x50i/kmeans_clustering_of_wine_data/,dina_jankovic,1534155540,,0,1
619,2018-8-13,2018,8,13,19,96xc89,[D] GANs: Would it be possible to retrain discriminator to recover latent vector?,https://www.reddit.com/r/MachineLearning/comments/96xc89/d_gans_would_it_be_possible_to_retrain/,veqtor,1534157843,"So, an idea struck me, given that the discriminator in a GAN network is already very good at analyzing outputs from a generator, wouldn't it be possible to retrain it to recover the latent vector?
I'm thinking this could be useful to convert a GAN into a VAE.
Thoughts? Am I missing something? Is gradient descent recovery fast and cheap enough?",5,1
620,2018-8-13,2018,8,13,20,96xe2o,Difference and similarities : Data Science vs Data Analytics vs Machine Learning,https://www.reddit.com/r/MachineLearning/comments/96xe2o/difference_and_similarities_data_science_vs_data/,gyansetu23,1534158361,,0,1
621,2018-8-13,2018,8,13,20,96xlgv,[P] Building Your First Wordcloud with Google Colaboratory and Python,https://www.reddit.com/r/MachineLearning/comments/96xlgv/p_building_your_first_wordcloud_with_google/,omarsar,1534160518,,0,1
622,2018-8-13,2018,8,13,20,96xp56,A Social Media Mapping Tool that correlates profiles via facial recognition,https://www.reddit.com/r/MachineLearning/comments/96xp56/a_social_media_mapping_tool_that_correlates/,CareyANeely,1534161572,[removed],0,3
623,2018-8-13,2018,8,13,21,96xy2g,[P] torchsummaryX: Improved visualization tool of torchsummary,https://www.reddit.com/r/MachineLearning/comments/96xy2g/p_torchsummaryx_improved_visualization_tool_of/,nmhkahn,1534163858,,0,1
624,2018-8-13,2018,8,13,21,96xyih,Tensorflow  Graphs and Sessions  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/96xyih/tensorflow_graphs_and_sessions_coinmonks_medium/,coinmonks,1534163981,,0,1
625,2018-8-13,2018,8,13,21,96y2c2,Flanging Machine Manufacturers,https://www.reddit.com/r/MachineLearning/comments/96y2c2/flanging_machine_manufacturers/,matnfur2017,1534164945,,1,1
626,2018-8-13,2018,8,13,22,96y7q7,What is prediction trend accuracy???????,https://www.reddit.com/r/MachineLearning/comments/96y7q7/what_is_prediction_trend_accuracy/,nighter97,1534166218,[removed],0,1
627,2018-8-13,2018,8,13,22,96yb40,"A.I. can cure click frauds $100 million problem, and it wont steal your job",https://www.reddit.com/r/MachineLearning/comments/96yb40/ai_can_cure_click_frauds_100_million_problem_and/,amberstevens311,1534167015,[removed],0,1
628,2018-8-13,2018,8,13,22,96ybml,Hierarchical Bayesian Neural Networks with Informative Priors in PyMC3,https://www.reddit.com/r/MachineLearning/comments/96ybml/hierarchical_bayesian_neural_networks_with/,Whyking,1534167132,,0,2
629,2018-8-13,2018,8,13,22,96ye26,"How Different Chatbots Responded to Random, Unrelated Questions?",https://www.reddit.com/r/MachineLearning/comments/96ye26/how_different_chatbots_responded_to_random/,amberstevens311,1534167678,[removed],0,1
630,2018-8-13,2018,8,13,22,96ye9h,Robust optimization approach to defending against adversarial perturbations,https://www.reddit.com/r/MachineLearning/comments/96ye9h/robust_optimization_approach_to_defending_against/,vector_machines,1534167719,,1,17
631,2018-8-13,2018,8,13,22,96ygvc,Retailers are Reaping from Embracing Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/96ygvc/retailers_are_reaping_from_embracing_artificial/,amberstevens311,1534168325,[removed],0,1
632,2018-8-13,2018,8,13,22,96yipl,"Has anyone successfully reproduced this work -&gt; ""LaVAN: Localized and Visible Adversarial Noise""?",https://www.reddit.com/r/MachineLearning/comments/96yipl/has_anyone_successfully_reproduced_this_work/,ChesterAiGo2012,1534168755,[removed],0,1
633,2018-8-13,2018,8,13,23,96yqed,[P] Pytorch Implementation of Deep Spectral Clustering Learning,https://www.reddit.com/r/MachineLearning/comments/96yqed/p_pytorch_implementation_of_deep_spectral/,wlwkgus,1534170395,,0,1
634,2018-8-13,2018,8,13,23,96yrdt,[P] Pytorch Implementation of Deep Spectral Clustering Learning,https://www.reddit.com/r/MachineLearning/comments/96yrdt/p_pytorch_implementation_of_deep_spectral/,wlwkgus,1534170599,,1,1
635,2018-8-13,2018,8,13,23,96yt1r,"Fastai now supports mixed precision (bringing the benefits of half precision and FP), will help increase the size of model, increased batch size and more precise updation of weights as HP.",https://www.reddit.com/r/MachineLearning/comments/96yt1r/fastai_now_supports_mixed_precision_bringing_the/,vector_machines,1534170931,,0,1
636,2018-8-13,2018,8,13,23,96yu43,Should an aspiring machine learning engineer major in comp sci or data sci?,https://www.reddit.com/r/MachineLearning/comments/96yu43/should_an_aspiring_machine_learning_engineer/,LarryJohnsonlol,1534171166,[removed],1,1
637,2018-8-13,2018,8,13,23,96yupz,we are building a chatbot for Python programming language and the dataset which I've used is the python stackoverflow dataset from https://t.co/Rcvn9ZQLII What is the exact procedure for data-preprocessing or cleaning a CSV file in python for the training seqtoseq model ?,https://www.reddit.com/r/MachineLearning/comments/96yupz/we_are_building_a_chatbot_for_python_programming/,okaydexter,1534171292,"Can anyone help me with the data-preprocessing steps in CSV file .

We have 1 csv file for questions and other file for Answers .
 Any references would be better .
",0,1
638,2018-8-14,2018,8,14,0,96zbhv,How to Create a Digital Clone of your Voice Using AI,https://www.reddit.com/r/MachineLearning/comments/96zbhv/how_to_create_a_digital_clone_of_your_voice_using/,TechyGyan,1534174622,,0,1
639,2018-8-14,2018,8,14,1,96zl7h,Powerful Statistics About Where Artificial Intelligence is Making a Huge Impact [Infographic],https://www.reddit.com/r/MachineLearning/comments/96zl7h/powerful_statistics_about_where_artificial/,allieatcsio,1534176519,,0,1
640,2018-8-14,2018,8,14,1,96zsgj,[P] Pytorch Implementation of Deep Spectral Clustering Learning (SOTA of the Deep Metric Learning),https://www.reddit.com/r/MachineLearning/comments/96zsgj/p_pytorch_implementation_of_deep_spectral/,wlwkgus,1534177914,,0,1
641,2018-8-14,2018,8,14,1,96ztqt,"[P] Pytorch Implementation of paper ""Deep Spectral Clustering Learning""",https://www.reddit.com/r/MachineLearning/comments/96ztqt/p_pytorch_implementation_of_paper_deep_spectral/,wlwkgus,1534178164,"This is a implementation of paper ""Deep Spectral Clustering Learning"", which is the SOTA of Deep Metric Learning
https://github.com/wlwkgus/DeepSpectralClustering",5,19
642,2018-8-14,2018,8,14,1,96zuqg,[D] Finding a common object from a set of Images,https://www.reddit.com/r/MachineLearning/comments/96zuqg/d_finding_a_common_object_from_a_set_of_images/,Captain_Price_777,1534178366,"To explain, If I have 10 images each containing, say a football, at different locations and of different sizes, How can we extract that that ball out of them?

I know we could probably use object detection techniques, but they AFAIK usually detect a fixed number of object types. Beside I was hoping for something more general that can work in feature space. So maybe I can turn 10 images into 10 512-D vectors, combine them somehow to produce a 512-D ""common"" vector, and convert it back to image space by sending it through a generator to get the football back. 

As another example, say I have 1000 water color paintings and want to learn ""watercoloring"" effect as style image for neural style transfer. 

(This work)\[[https://arxiv.org/abs/1711.06454](https://arxiv.org/abs/1711.06454)\] is probably close to what I want, but admittedly out of my depth. Thanks.",4,4
643,2018-8-14,2018,8,14,1,96zz02,Using Docker for Research/Debugging,https://www.reddit.com/r/MachineLearning/comments/96zz02/using_docker_for_researchdebugging/,kylepob,1534179191,[removed],0,1
644,2018-8-14,2018,8,14,1,96zzkx,[D] What is the state of the art in speech and image generation?,https://www.reddit.com/r/MachineLearning/comments/96zzkx/d_what_is_the_state_of_the_art_in_speech_and/,the-bayesian,1534179304,"What are some relevant papers I can review to understand what's currently feasible in the domain of speech and image generation?

Thanks",1,3
645,2018-8-14,2018,8,14,2,9703qr,"[D] Made a tiny map of books, that are often bought together with Hands-On ML. What do you think?",https://www.reddit.com/r/MachineLearning/comments/9703qr/d_made_a_tiny_map_of_books_that_are_often_bought/,anvaka,1534180069,,27,210
646,2018-8-14,2018,8,14,2,9706wm,"I'm trying to install SerpentAI, but it keeps failing.",https://www.reddit.com/r/MachineLearning/comments/9706wm/im_trying_to_install_serpentai_but_it_keeps/,ForeignPint,1534180650,[removed],0,1
647,2018-8-14,2018,8,14,2,97078u,Trying to figure out what technology stack used to build these clips....,https://www.reddit.com/r/MachineLearning/comments/97078u/trying_to_figure_out_what_technology_stack_used/,jppope,1534180716,[removed],0,1
648,2018-8-14,2018,8,14,2,970cto,TensorFlow 2.0 is coming,https://www.reddit.com/r/MachineLearning/comments/970cto/tensorflow_20_is_coming/,mtngld,1534181749,[removed],0,1
649,2018-8-14,2018,8,14,2,970dqz,[R] Concrete Problems in AI Safety [pdf],https://www.reddit.com/r/MachineLearning/comments/970dqz/r_concrete_problems_in_ai_safety_pdf/,The_Ebb_and_Flow,1534181920,,1,2
650,2018-8-14,2018,8,14,3,970m2k,How can i make a neutral network learn ^n function?,https://www.reddit.com/r/MachineLearning/comments/970m2k/how_can_i_make_a_neutral_network_learn_n_function/,Niladri99,1534183496,"Given X : 1,2,3,4,5,6,7......
Y:1,4,9,16,25,36,49.......
How can I make a neutral network learn the function 'square'?",0,1
651,2018-8-14,2018,8,14,4,971lcb,A beginner's guide to Machine Learning for Application Security,https://www.reddit.com/r/MachineLearning/comments/971lcb/a_beginners_guide_to_machine_learning_for/,isityoupaul,1534190239,,0,1
652,2018-8-14,2018,8,14,5,971ufa,"[N] TVM v0.4 is released, AutoTVM, cutomized accelerator backends",https://www.reddit.com/r/MachineLearning/comments/971ufa/n_tvm_v04_is_released_autotvm_cutomized/,crowwork,1534192003,"major changes:

* AutoTVM for automated tensor program optimization
* VTA: customized open source accelerator design and compiler backend

[Release note](https://github.com/dmlc/tvm/releases/tag/v0.4)",0,3
653,2018-8-14,2018,8,14,5,971x46,ML Related Independent Study - High School,https://www.reddit.com/r/MachineLearning/comments/971x46/ml_related_independent_study_high_school/,i_wasserman,1534192527,[removed],0,1
654,2018-8-14,2018,8,14,5,97200w,Eye see what you did there,https://www.reddit.com/r/MachineLearning/comments/97200w/eye_see_what_you_did_there/,skylinker,1534193109,,0,1
655,2018-8-14,2018,8,14,6,9725ml,"If you have a potentially profitable proprietary ML software and a dataset you built yourself, would you try to sell only the results of your analysis (say monthly/yearly subscription) or would you sell your algorithms along with your data (as a one off thing)? What would the pros and cons be?",https://www.reddit.com/r/MachineLearning/comments/9725ml/if_you_have_a_potentially_profitable_proprietary/,pinouche13,1534194206,,0,1
656,2018-8-14,2018,8,14,6,9726o8,The Eyes Have It: DeepMinds AI 3D OCT Scans,https://www.reddit.com/r/MachineLearning/comments/9726o8/the_eyes_have_it_deepminds_ai_3d_oct_scans/,trcytony,1534194421,,0,1
657,2018-8-14,2018,8,14,6,972csp,A major milestone for the treatment of eye disease | DeepMind,https://www.reddit.com/r/MachineLearning/comments/972csp/a_major_milestone_for_the_treatment_of_eye/,curious_neuron,1534195666,,0,1
658,2018-8-14,2018,8,14,6,972m8z,Data analysis - beginner - where to start ?,https://www.reddit.com/r/MachineLearning/comments/972m8z/data_analysis_beginner_where_to_start/,duyth,1534197577,[removed],0,1
659,2018-8-14,2018,8,14,7,972njj,Does a diagonal Covariance relate to the independency in a Gaussian Distribution?,https://www.reddit.com/r/MachineLearning/comments/972njj/does_a_diagonal_covariance_relate_to_the/,parcelpath,1534197829,[removed],0,1
660,2018-8-14,2018,8,14,8,9736cw,What are some more intermediate ML papers that beginners can understand?,https://www.reddit.com/r/MachineLearning/comments/9736cw/what_are_some_more_intermediate_ml_papers_that/,PKJY,1534201917,[removed],0,1
661,2018-8-14,2018,8,14,8,973fkd,Continuous bernoulli samples.,https://www.reddit.com/r/MachineLearning/comments/973fkd/continuous_bernoulli_samples/,Matschreiner,1534203964,[removed],0,1
662,2018-8-14,2018,8,14,9,973rqw,Linked Causal Variational Autoencoder for Inferring Paired Spillover Effects,https://www.reddit.com/r/MachineLearning/comments/973rqw/linked_causal_variational_autoencoder_for/,breadFTD,1534206751,,1,3
663,2018-8-14,2018,8,14,9,973wri,[D] Social contribution projects?,https://www.reddit.com/r/MachineLearning/comments/973wri/d_social_contribution_projects/,murakamifanboy,1534207937,"Hi all,

This year I will teach Evolutionary Computing and also Artificial Intelligence (although the latter more focused on machine learning). Do you have any suggestions, ideas or examples of  2-3 month projects that could have a positive impact on society? 

I usually like to propose projects based on games, but I would like to spice up things a little this period. Thanks in advance!",6,4
664,2018-8-14,2018,8,14,10,9747y5,[R]Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network,https://www.reddit.com/r/MachineLearning/comments/9747y5/rfundamentals_of_recurrent_neural_network_rnn_and/,mlvpj,1534210590,,8,108
665,2018-8-14,2018,8,14,10,974dx1,Where should I start learning machine learning? I am a beginner and I am learning python,https://www.reddit.com/r/MachineLearning/comments/974dx1/where_should_i_start_learning_machine_learning_i/,rohitrauthan121,1534211959,[removed],0,1
666,2018-8-14,2018,8,14,11,974fil,[D] Books on machine learning good for doing from scratch examples AND / OR good intro theory/foundation books,https://www.reddit.com/r/MachineLearning/comments/974fil/d_books_on_machine_learning_good_for_doing_from/,Morninglow,1534212320,"Hello, I'm looking for any books that feature a good array of algorithms with enough information to do the examples yourself. Preferably something with concise descriptions of the algorithm so it can be done from scratch and without using a library like keras.  


I'm also looking for good intro level theory and foundations books. Some books for getting my statistics, calculus, and linear algebra up to the point where I can really understand the theory books and the equations in research papers would be a great help. ",10,9
667,2018-8-14,2018,8,14,12,974ydl,heading die core,https://www.reddit.com/r/MachineLearning/comments/974ydl/heading_die_core/,TOONNEY,1534216916,,0,1
668,2018-8-14,2018,8,14,12,9755km,Need help with English transcript for GAN Lecture 3 (2018): Unsupervised Conditional Generation.,https://www.reddit.com/r/MachineLearning/comments/9755km/need_help_with_english_transcript_for_gan_lecture/,gsk694,1534218792,"I am working on Sequence generation using GAN + reinforcement learning and came across [this](https://www.youtube.com/watch?v=Xb1x4ZgV6iM) video lecture but unfortunately there are no subs provided.   


The slides are very informative and are in English that helps only a little. It would be great if someone can provide a gist if not a complete English translation (transcript).  


Not limited to this lecture, if there is an easy way to get English transcripts (where one is not provided) ?",0,1
669,2018-8-14,2018,8,14,13,975b48,[D] Best Framework for practical PPO.,https://www.reddit.com/r/MachineLearning/comments/975b48/d_best_framework_for_practical_ppo/,mistertipster,1534220254,"Hi everyone, is there a good python PPO for practical application?

I'm trying to train a reinforcement learning algorithm on my own data set and make predictions.

 But right now everything seems to be running only on gym.",12,9
670,2018-8-14,2018,8,14,13,975cpf,carbide rod manufacturers,https://www.reddit.com/r/MachineLearning/comments/975cpf/carbide_rod_manufacturers/,TOONNEY,1534220679,,0,1
671,2018-8-14,2018,8,14,13,975hlx,A Reinforcement Learning agent learning to play Clash Royale on Twitch,https://www.reddit.com/r/MachineLearning/comments/975hlx/a_reinforcement_learning_agent_learning_to_play/,drhon1337,1534222077,,0,1
672,2018-8-14,2018,8,14,13,975jq0,[R] MCRM: Mother Compact Recurrent Memory A Biologically Inspired Recurrent Neural Network Architecture,https://www.reddit.com/r/MachineLearning/comments/975jq0/r_mcrm_mother_compact_recurrent_memory_a/,browniesandcookies,1534222691,,10,0
673,2018-8-14,2018,8,14,14,975kw6,solid carbide manufacturer,https://www.reddit.com/r/MachineLearning/comments/975kw6/solid_carbide_manufacturer/,TOONNEY,1534223021,,0,1
674,2018-8-14,2018,8,14,14,975rde,hip sintering,https://www.reddit.com/r/MachineLearning/comments/975rde/hip_sintering/,TOONNEY,1534224879,,0,1
675,2018-8-14,2018,8,14,14,975txl,Data Preprocessing for ML: Theory and Implementation,https://www.reddit.com/r/MachineLearning/comments/975txl/data_preprocessing_for_ml_theory_and/,hitchensrazr,1534225661,[removed],0,1
676,2018-8-14,2018,8,14,14,975u18,forging die manufacturer,https://www.reddit.com/r/MachineLearning/comments/975u18/forging_die_manufacturer/,TOONNEY,1534225697,,0,1
677,2018-8-14,2018,8,14,15,975x3d,progressive die manufacturer,https://www.reddit.com/r/MachineLearning/comments/975x3d/progressive_die_manufacturer/,TOONNEY,1534226646,,0,1
678,2018-8-14,2018,8,14,15,975zk4,carbide blanks manufacturers,https://www.reddit.com/r/MachineLearning/comments/975zk4/carbide_blanks_manufacturers/,TOONNEY,1534227405,,0,1
679,2018-8-14,2018,8,14,15,9761od,tungsten rod factory,https://www.reddit.com/r/MachineLearning/comments/9761od/tungsten_rod_factory/,TOONNEY,1534228106,,0,1
680,2018-8-14,2018,8,14,15,97622k,Why You Should Use Machine Learning In Your Website for Customers,https://www.reddit.com/r/MachineLearning/comments/97622k/why_you_should_use_machine_learning_in_your/,SDI_Sakshi,1534228227,,0,1
681,2018-8-14,2018,8,14,15,9764pr,sintering furnace manufacturers,https://www.reddit.com/r/MachineLearning/comments/9764pr/sintering_furnace_manufacturers/,TOONNEY,1534229095,,0,1
682,2018-8-14,2018,8,14,15,97666u,Brief Introduction to Support Vector Machine(SVM) - StepUp Analytics,https://www.reddit.com/r/MachineLearning/comments/97666u/brief_introduction_to_support_vector_machinesvm/,Stepup_Analytics,1534229549,,1,1
683,2018-8-14,2018,8,14,16,976ag8,[D] Projects in Machine Learning : Beginner To Professional,https://www.reddit.com/r/MachineLearning/comments/976ag8/d_projects_in_machine_learning_beginner_to/,thecodingfossil,1534230955," If youve ever wanted Jetsons to be real, well we arent that far off from a future like that. If youve ever chatted with automated robots, then youve definitely interacted with machine learning. From self-driving cars to AI bots, machine learning is slowly spreading its reach and making our devices smarter.

Artificial intelligence is the future of computers, where your devices will be able to decide what is right for you. Machine learning is the core for having a futuristic reality where robot maids and robodogs exist. Machine learning includes the algorithms that allow the computers to think and respond, as well as manipulate the data depending on the scenario thats placed before them.

So, if youve ever wanted to play a role in the future of technology development, then heres your chance to get started with Machine Learning. Because machine learning is complex and tough, weve designed a course to help break it down into more simple concepts that are easier to understand with a all new updated course has been updated to include 9 projects that will give you a real-world experience with different concepts of Machine Learning. Keep an eye out for more projects that will be added to this course in the future now - [https://www.udemy.com/machine-learning-for-absolute-beginners/?couponCode=DUAUG18](https://www.udemy.com/machine-learning-for-absolute-beginners/?couponCode=DUAUG18)",4,0
684,2018-8-14,2018,8,14,16,976cch,[D] Best way to publish papers as a non-scholar?,https://www.reddit.com/r/MachineLearning/comments/976cch/d_best_way_to_publish_papers_as_a_nonscholar/,non_scholar,1534231599,"There's a similar post on HN right now: [https://news.ycombinator.com/item?id=17750861](https://news.ycombinator.com/item?id=17750861)

I want the ML perspective. In particular, are there even any precedents of an independent researcher producing a highly cited work (without prior formal graduate affiliations)? Were there any significant results that came from a blog posts by a no-name?",16,16
685,2018-8-14,2018,8,14,16,976cgj,What are the most important papers for beginners to read?,https://www.reddit.com/r/MachineLearning/comments/976cgj/what_are_the_most_important_papers_for_beginners/,PKJY,1534231642,[removed],0,1
686,2018-8-14,2018,8,14,16,976cmf,[D] End-to-end ML techniques for text classification,https://www.reddit.com/r/MachineLearning/comments/976cmf/d_endtoend_ml_techniques_for_text_classification/,kugkfokj,1534231699,"Convolution neural networks are often referred to as end-to-end, in the sense that they both generate the signals and perform the modelling. Is there a similar technique for text classification?",3,2
687,2018-8-14,2018,8,14,16,976dkr,tungsten strips,https://www.reddit.com/r/MachineLearning/comments/976dkr/tungsten_strips/,TOONNEY,1534232026,,0,1
688,2018-8-14,2018,8,14,16,976ema,hanxiao/tf-nlp-blocks: A collection of frequently-used deep learning NLP blocks implemented in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/976ema/hanxiaotfnlpblocks_a_collection_of_frequentlyused/,h_xiao,1534232394,,0,1
689,2018-8-14,2018,8,14,16,976g80,cemented carbide inserts,https://www.reddit.com/r/MachineLearning/comments/976g80/cemented_carbide_inserts/,TOONNEY,1534232987,,0,1
690,2018-8-14,2018,8,14,16,976hcz,"How shall I learn GAN technology after I have some experience of machine learning, such as CNN, RNN and so on, and shall I get some materials or courses about GAN?",https://www.reddit.com/r/MachineLearning/comments/976hcz/how_shall_i_learn_gan_technology_after_i_have/,frank_cao,1534233425,[removed],0,1
691,2018-8-14,2018,8,14,16,976hm6,Machine learning as an intern,https://www.reddit.com/r/MachineLearning/comments/976hm6/machine_learning_as_an_intern/,jackalope100,1534233523,[removed],0,1
692,2018-8-14,2018,8,14,17,976iuj,cemented carbide tips,https://www.reddit.com/r/MachineLearning/comments/976iuj/cemented_carbide_tips/,TOONNEY,1534233955,,0,1
693,2018-8-14,2018,8,14,17,976kw4,carbide cutting tools properties,https://www.reddit.com/r/MachineLearning/comments/976kw4/carbide_cutting_tools_properties/,TOONNEY,1534234662,,0,1
694,2018-8-14,2018,8,14,17,976mun,[D] Blog post and implementation: Neural Processes,https://www.reddit.com/r/MachineLearning/comments/976mun/d_blog_post_and_implementation_neural_processes/,kasparmartens,1534235402,"[http://kasparmartens.rbind.io/post/np/](http://kasparmartens.rbind.io/post/np/)

*Processing gif ren9236ur0g11...*",0,1
695,2018-8-14,2018,8,14,17,976n6p,cold heading dies,https://www.reddit.com/r/MachineLearning/comments/976n6p/cold_heading_dies/,TOONNEY,1534235523,,0,1
696,2018-8-14,2018,8,14,17,976qrh,[D] Blog post and implementation: Neural Processes,https://www.reddit.com/r/MachineLearning/comments/976qrh/d_blog_post_and_implementation_neural_processes/,kasparmartens,1534236816,,3,22
697,2018-8-14,2018,8,14,18,976s1m,Deep learning platform to solve complex problems,https://www.reddit.com/r/MachineLearning/comments/976s1m/deep_learning_platform_to_solve_complex_problems/,clusterone02,1534237246,,1,1
698,2018-8-14,2018,8,14,18,976uig,A collection of data science formula,https://www.reddit.com/r/MachineLearning/comments/976uig/a_collection_of_data_science_formula/,MillionStrength,1534238051,"The URL provides a PDF book that contains a collection of data science formula:

https://www.datasciencecentral.com/profiles/blogs/free-book-probability-and-statistics-cookbook",0,1
699,2018-8-14,2018,8,14,18,976vwq,Active Learning with Human-in-the-Loop,https://www.reddit.com/r/MachineLearning/comments/976vwq/active_learning_with_humanintheloop/,Gaudi91,1534238547,[removed],0,1
700,2018-8-14,2018,8,14,19,9778ds,What if my data has two-time series?,https://www.reddit.com/r/MachineLearning/comments/9778ds/what_if_my_data_has_twotime_series/,pooja307,1534242666,[removed],0,0
701,2018-8-14,2018,8,14,19,977bjy,Horizontal 4-side seal Pregnancy Test Kit Packaging machine-for patches...,https://www.reddit.com/r/MachineLearning/comments/977bjy/horizontal_4side_seal_pregnancy_test_kit/,chinamachine,1534243694,,0,1
702,2018-8-14,2018,8,14,20,977fbp,[D] #APaperADay Reading Challenge Week 4. It's the final week!,https://www.reddit.com/r/MachineLearning/comments/977fbp/d_apaperaday_reading_challenge_week_4_its_the/,leenz2,1534244847,"On the 23rd of July, [Nurture.AI](https://nurture.ai/) initiated the [\#APaperADay Reading Challenge](https://apaperaday.nurture.ai/), where we will read an AI paper everyday.

Here is our pick of 6 papers for the fourth week:

1. [Deep RNNs Encode Soft Hierarchical Syntax](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/deep-rnns-encode-soft-hierarchical-syntax/annotations) ([2-min summary](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/deep-rnns-encode-soft-hierarchical-syntax/tldr))

**Why read**: This paper shows that hidden representations of RNNs actually learn more than you think. With transfer learning garnering interest in the NLP community, this is worth a read. 

2. [Image2GIF: Generating Cinemagraphs using Recurrent Deep Q-Networks](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/image2gif-generating-cinemagraphs-using-recurrent-deep-q-networks/annotations) ([2-min summary](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/image2gif-generating-cinemagraphs-using-recurrent-deep-q-networks/tldr))

**Why read**: An interesting application of Deep Q-learning (using deep learning to determine optimum actions given a state) to generate GIFs from still images. 

3. [Building Machines That Learn and Think Like People](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/building-machines-that-learn-and-think-like-people/annotations)

**Why read**:  We don't have AI... yet? Despite the success and biological inspiration of Deep Neural Networks, these systems differ from human intelligence in crucial ways. This paper was also highlighted in an ICML 2018 talk by Joshua Tenenbaum from MIT.

4. [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/accurate-large-minibatch-sgd-training-imagenet-in-1-hour/annotations)

**Why read**:   While distributed synchronous SGD is now commonplace, no existing results show that generalization accuracy can be maintained with minibatches as large as 8192 or that such high-accuracy models can be trained in such short time.

5. [Effective Use of Word Order for Text Categorization with Convolutional Neural Networks](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/effective-use-of-word-order-for-text-categorization-with-convolutional-neural-networks/annotations)

**Why read**: Instead of using low-dimensional word vectors as input,  CNN is directly applied to high-dimensional text data. This leads to the model directly learning embeddings of small text regions for use in classification.
 
6. [Efficient Progressive Neural Architecture Search](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/efficient-progressive-neural-architecture-search/annotations)

**Why read**: Addresses the difficult problem of finding an optimal neural architecture design for a given image classification task.  

## Archive

More details can be found [here](https://apaperaday.nurture.ai).

- [Link to original post](https://www.reddit.com/r/MachineLearning/comments/903ta0/d_what_is_one_ai_paper_which_you_feel_did_not_get/)
- [Week 1 papers](https://www.reddit.com/r/MachineLearning/comments/91fyni/d_apaperaday_reading_challenge_week_1_what_are/)
- [Week 2 papers](https://www.reddit.com/r/MachineLearning/comments/93dm73/d_apaperaday_reading_challenge_week_2_what_are/)
- [Week 3 papers](https://www.reddit.com/r/MachineLearning/comments/950dtm/d_apaperaday_reading_challenge_week_3/)",2,8
703,2018-8-14,2018,8,14,20,977h8q,[D] Effects,https://www.reddit.com/r/MachineLearning/comments/977h8q/d_effects/,Valiox,1534245405,,0,1
704,2018-8-14,2018,8,14,20,977lmp,[R] TDLS: Principles of Riemannian Geometry in Neural Networks,https://www.reddit.com/r/MachineLearning/comments/977lmp/r_tdls_principles_of_riemannian_geometry_in/,machinetrainer,1534246682,,28,151
705,2018-8-14,2018,8,14,20,977pus,Running an autoencoder algorithm,https://www.reddit.com/r/MachineLearning/comments/977pus/running_an_autoencoder_algorithm/,StormPooper42,1534247827,[removed],0,1
706,2018-8-14,2018,8,14,21,977wnc,What is the Multinomial-Logistic Regression Classification Algorithm and How Does One Use it for Analysis?,https://www.reddit.com/r/MachineLearning/comments/977wnc/what_is_the_multinomiallogistic_regression/,ElegantMicroWebIndia,1534249512,,0,1
707,2018-8-14,2018,8,14,22,9786sj,What is ARIMA Forecasting and How Can it Be Used for Enterprise Analysis?,https://www.reddit.com/r/MachineLearning/comments/9786sj/what_is_arima_forecasting_and_how_can_it_be_used/,ElegantMicroWebIndia,1534252010,,0,1
708,2018-8-14,2018,8,14,22,9788al,Active Learning with Human-in-the-Loop,https://www.reddit.com/r/MachineLearning/comments/9788al/active_learning_with_humanintheloop/,Gaudi91,1534252345,[removed],0,1
709,2018-8-14,2018,8,14,22,978e40,Active Learning with Human-in-the-Loop,https://www.reddit.com/r/MachineLearning/comments/978e40/active_learning_with_humanintheloop/,Gaudi91,1534253629,"Hi guys,

I did a lot of research and can't find a satisfactory answer. I have just a quick question about Active Learning and would be pleased if you could answer it.

I'm still wondering if active learning only fit for the training of a classifier? I know it can help to reduce the size of the training data while iteratively learning from an unlabeled data pool using human annotation. But all papers and literature I could found refer only to the training phase of classifiers. Is it also possible if the classifier is ""live"" and make some predictions to use the new observations to actively learn from them? **Like continuously active learning?**

For example, if the classifier has a low confidence about a prediction (wrong prediction), can this new information be used to improve the classifier?

In this context, I've read a lot about Human-in-the-Loop with active learning. [https://www.slideshare.net/BillLiu31/natural-intelligence-the-human-factor-in-ai](https://www.slideshare.net/BillLiu31/natural-intelligence-the-human-factor-in-ai) If I look at this presentation, then I would said yes, it can continuously learning actively. Facebook's DeepFace is described, where the algorithm ask a human to help with labeling if it is uncertain about the face (page 63). Or by adding a human feedback loop on page 82.

I also found another real-world example where Coca Cola claims to use active learning. A user can correct invalid predictions and the algorithm could be improved over time via active learning (sounds similar to DeepFace): [https://developers.googleblog.com/2017/09/how-machine-learning-with-tensorflow.html](https://developers.googleblog.com/2017/09/how-machine-learning-with-tensorflow.html) In fact, I have found some more real-world example where I believe or the companies say that they use active learning.

For example, at figure-eight. But nobody says how they implement it. Its very difficult to find good literature or papers about this intention.

Thank you",0,1
710,2018-8-14,2018,8,14,22,978h4i,Active Learning with Human-in-the-Loop,https://www.reddit.com/r/MachineLearning/comments/978h4i/active_learning_with_humanintheloop/,Gaudi91,1534254292,"Hi guys,

I did a lot of research and can't find a satisfactory answer. I have just a quick question about Active Learning and would be pleased if you could answer it.

I'm still wondering if active learning only fit for the training of a classifier? I know it can help to reduce the size of the training data while iteratively learning from an unlabeled data pool using human annotation. But all papers and literature I could found refer only to the training phase of classifiers. Is it also possible if the classifier is ""live"" and make some predictions to use the new observations to actively learn from them? **Like continuously active learning?**

For example, if the classifier has a low confidence about a prediction (wrong prediction), can this new information be used to improve the classifier?

In this context, I've read a lot about Human-in-the-Loop with active learning. [https://www.slideshare.net/BillLiu31/natural-intelligence-the-human-factor-in-ai](https://www.slideshare.net/BillLiu31/natural-intelligence-the-human-factor-in-ai) If I look at this presentation, then I would said yes, it can continuously learning actively. Facebook's DeepFace is described, where the algorithm ask a human to help with labeling if it is uncertain about the face (page 63). Or by adding a human feedback loop on page 82.

I also found another real-world example where Coca Cola claims to use active learning. A user can correct invalid predictions and the algorithm could be improved over time via active learning (sounds similar to DeepFace): [https://developers.googleblog.com/2017/09/how-machine-learning-with-tensorflow.html](https://developers.googleblog.com/2017/09/how-machine-learning-with-tensorflow.html) In fact, I have found some more real-world example where I believe or the companies say that they use active learning.

For example, at figure-eight. But nobody says how they implement it. Its very difficult to find good literature or papers about this intention.

Thank you",0,1
711,2018-8-14,2018,8,14,22,978h5n,[R] Corrigibility [pdf],https://www.reddit.com/r/MachineLearning/comments/978h5n/r_corrigibility_pdf/,The_Ebb_and_Flow,1534254303,,1,9
712,2018-8-14,2018,8,14,22,978hwo,What is FP Growth Analysis and How Can a Business Use Frequent Pattern Mining to Analyze Data?,https://www.reddit.com/r/MachineLearning/comments/978hwo/what_is_fp_growth_analysis_and_how_can_a_business/,ElegantMicroWebIndia,1534254464,,0,1
713,2018-8-14,2018,8,14,22,978k16,[D] Active Learning with Human-in-the-Loop,https://www.reddit.com/r/MachineLearning/comments/978k16/d_active_learning_with_humanintheloop/,Gaudi91,1534254946,"Hi guys,

I did a lot of research and can't find a satisfactory answer. I have just a quick question about Active Learning and would be pleased if you could answer it.

I'm still wondering if active learning only fit for the training of a classifier? I know it can help to reduce the size of the training data while iteratively learning from an unlabeled data pool using human annotation. But all papers and literature I could found refer only to the training phase of classifiers. Is it also possible if the classifier is ""live"" and make some predictions to use the new observations to actively learn from them? **To fed back the new data points into the model so it has additional training data to learn from?**

For example, if the classifier has a low confidence about a prediction or the prediction is wrong, can this new information be used to improve the classifier?

In this context, I've read a lot about Human-in-the-Loop with active learning. If I look at [this presentation](https://www.slideshare.net/BillLiu31/natural-intelligence-the-human-factor-in-ai), then I would said yes, it can continuously learning actively. Facebook's DeepFace is described, where the algorithm ask a human to help with labeling if it is uncertain about the face (page 63). Or by adding a human feedback loop on page 82.

I also found another real-world example where [Coca Cola](https://developers.googleblog.com/2017/09/how-machine-learning-with-tensorflow.html) claims to use active learning. A user can correct invalid predictions and the algorithm could be improved over time via active learning (sounds similar to Facebook's DeepFace): 

In fact, I have found some more real-world example where I believe or the companies say that they use active learning. For example, at figure-eight. **But nobody says how they implement it. Many questions are raised. For example, does every new data point help? How many data points must be collected until you can learn actively? Which is the right batch size?** I know it depends on the use case, but its very difficult to find good literature or papers about this intention.

Thank you",5,4
714,2018-8-14,2018,8,14,23,978ton,Why all the excitement about artificial intelligence?,https://www.reddit.com/r/MachineLearning/comments/978ton/why_all_the_excitement_about_artificial/,ElegantFeeling,1534256976,[removed],0,1
715,2018-8-14,2018,8,14,23,978zg6,What is the best way to learn Math for AI/ML?,https://www.reddit.com/r/MachineLearning/comments/978zg6/what_is_the_best_way_to_learn_math_for_aiml/,raymestalez,1534258155,[removed],0,1
716,2018-8-14,2018,8,14,23,9791g7,[D] What is the best way to learn Math for AI/ML?,https://www.reddit.com/r/MachineLearning/comments/9791g7/d_what_is_the_best_way_to_learn_math_for_aiml/,raymestalez,1534258557,"I want to learn all the necessary basic math for ML/DL, as quickly and efficiently as possible. Can you recommend some good books or courses?

I don't want to go too in depth, I just want a good understanding of fundamentals so I could understand algorithms/formulas, and follow courses.

If there's one book/course specifically designed to take me through all the topics necessary for ML - that would be perfect.",14,16
717,2018-8-15,2018,8,15,0,97940x,Evolutionary Algorithms: the Next Big Thing in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/97940x/evolutionary_algorithms_the_next_big_thing_in/,andrewturnerrr,1534259076,,0,1
718,2018-8-15,2018,8,15,0,9794v0,Dual GPU Machine Learning Workstation (Opinion Needed),https://www.reddit.com/r/MachineLearning/comments/9794v0/dual_gpu_machine_learning_workstation_opinion/,jonlmbs,1534259245,,0,1
719,2018-8-15,2018,8,15,0,979d6m,School of AI  Raleigh,https://www.reddit.com/r/MachineLearning/comments/979d6m/school_of_ai_raleigh/,jubeenshah,1534260890,[removed],0,1
720,2018-8-15,2018,8,15,0,979dzt,[N] The Defense Department has produced the first tools for catching deepfakes,https://www.reddit.com/r/MachineLearning/comments/979dzt/n_the_defense_department_has_produced_the_first/,redditman09876543,1534261059,,0,1
721,2018-8-15,2018,8,15,0,979gb4,"[D] Question on the rational behind the score function (""log derivative"") in policy gradient",https://www.reddit.com/r/MachineLearning/comments/979gb4/d_question_on_the_rational_behind_the_score/,rbecq,1534261512,"I'm studying the policy gradient methods, and all the tutorials mention the method of taking derivative of the epoch total reward function w.r.t the policy parameter theta, which is by introducing the log likelihood function, such as in page 7 of http://rail.eecs.berkeley.edu/deeprlcoursesp17/docs/lec2.pdf

I think I understand the equations, but my question is why do we do it this way, why not just calculate the derivative numerically, say construct a policy using neural network, and express epoch reward in code, and let TensorFlow or anyone's favorite DL framework to calculate the derivative automatically?

Any hint would be appreciated, thanks!",10,2
722,2018-8-15,2018,8,15,1,97a0rk,Modeling System Resource Usage for Predictive Scheduling using DeepAR and Sagemaker,https://www.reddit.com/r/MachineLearning/comments/97a0rk/modeling_system_resource_usage_for_predictive/,darosati,1534265538,,0,1
723,2018-8-15,2018,8,15,1,97a194,Translating Machine Learning into Business  Part 1: Deep Learning &amp; the Stock Market,https://www.reddit.com/r/MachineLearning/comments/97a194/translating_machine_learning_into_business_part_1/,coinmonks,1534265642,,0,1
724,2018-8-15,2018,8,15,3,97ao9x,[D] EFF white paper: How Militaries Should Plan for AI,https://www.reddit.com/r/MachineLearning/comments/97ao9x/d_eff_white_paper_how_militaries_should_plan_for/,pde,1534270121,,11,12
725,2018-8-15,2018,8,15,3,97au76,[D] No Time Like The Present For AI Safety Work,https://www.reddit.com/r/MachineLearning/comments/97au76/d_no_time_like_the_present_for_ai_safety_work/,banksyb00mb00m,1534271275,,6,0
726,2018-8-15,2018,8,15,4,97b4jg,Is mathematics so important ?,https://www.reddit.com/r/MachineLearning/comments/97b4jg/is_mathematics_so_important/,amdforlive,1534273262,[removed],0,1
727,2018-8-15,2018,8,15,4,97b84a,[D] TensorFlow 2.0 is coming,https://www.reddit.com/r/MachineLearning/comments/97b84a/d_tensorflow_20_is_coming/,Kaixhin,1534273954,,75,210
728,2018-8-15,2018,8,15,5,97bsd3,Computer Vision and 2D images - University project to ouptut flat geometry data,https://www.reddit.com/r/MachineLearning/comments/97bsd3/computer_vision_and_2d_images_university_project/,spanisharmada,1534277952,[removed],0,1
729,2018-8-15,2018,8,15,5,97bwfg,"Khronos Group Releases Neural Network Exchange Format 1.0, Showcases First Public OpenXR Demo",https://www.reddit.com/r/MachineLearning/comments/97bwfg/khronos_group_releases_neural_network_exchange/,Marha01,1534278748,,0,1
730,2018-8-15,2018,8,15,5,97byas,Last month two researchers from Shanghai clamed more accuracy and 100x speedup over other RNN approaches to sentiment analysis. Are they really onto something?,https://www.reddit.com/r/MachineLearning/comments/97byas/last_month_two_researchers_from_shanghai_clamed/,inceloide,1534279107,,31,83
731,2018-8-15,2018,8,15,5,97c3jd,"[N] GCE Deep Learning images M5 are out. Main changes: Nvidia-Docker, CuDNN 7.2.1",https://www.reddit.com/r/MachineLearning/comments/97c3jd/n_gce_deep_learning_images_m5_are_out_main/,b0noi,1534280133,,0,5
732,2018-8-15,2018,8,15,6,97c4zh,[D] How Do You Write A Good Paper To Spread A New Theory And Technique Effectively To The Community?,https://www.reddit.com/r/MachineLearning/comments/97c4zh/d_how_do_you_write_a_good_paper_to_spread_a_new/,JosephLChu,1534280427,"So I came up with what seems like a really sensible and straightforward extension of a mathematical theory that when applied to neural nets leads to a very cool technique to reliably improve performance wherever a certain common activation function is normally utilized to perform a very common task in a variety of fields of ML (including both CV and NLP).  I don't want to give away too much detail, but I'm curious if people here have any advice for how I should go about publishing this discovery and resulting technique.

Currently I work at a large tech company that tends to care a bit more about products and patents than papers, but I've been given the leeway to spend some time testing the theory and application and put together a paper and try to submit it to a conference somewhere.  I am tempted to try to publish somewhere really big, like NIPS or ICML, but a colleague has suggested it may be safer to publish somewhere like ACL.  Any advice on this?

Also, any advice on how I should go about structuring this paper?  I've only published two papers previously, and they were probably not my finest work and found in relatively obscure conference proceedings.  What should I do to maximize the probability of acceptance and eventual readership so that as many people as possible can benefit from the improvement in the long run?  I understand I need to emphasize rigor and quality, but how?

Sorry I can't really explain in much detail what it is that I actually have.  Non-Disclosure Agreement and stuff.",6,7
733,2018-8-15,2018,8,15,6,97c6yr,Anyone also thinks regularization is actually a workaround rather than the solution?,https://www.reddit.com/r/MachineLearning/comments/97c6yr/anyone_also_thinks_regularization_is_actually_a/,cli1980,1534280807,[removed],0,1
734,2018-8-15,2018,8,15,6,97cf9i,[D] TensorFlow v2.0 is coming - with a focus on ease of use!,https://www.reddit.com/r/MachineLearning/comments/97cf9i/d_tensorflow_v20_is_coming_with_a_focus_on_ease/,sksq9,1534282504,,0,0
735,2018-8-15,2018,8,15,6,97cfhx,What is the GCP equivalent of Amazon's DeepLearning AMI?,https://www.reddit.com/r/MachineLearning/comments/97cfhx/what_is_the_gcp_equivalent_of_amazons/,podcast_frog3817,1534282549,[removed],0,1
736,2018-8-15,2018,8,15,7,97cscy,Tool For Training and Hyper-parameter Tuning At Scale,https://www.reddit.com/r/MachineLearning/comments/97cscy/tool_for_training_and_hyperparameter_tuning_at/,tregnal,1534285205,[removed],0,1
737,2018-8-15,2018,8,15,7,97cwak,[D] Experts Weigh in on the Future of AI and Evolutionary Algorithms,https://www.reddit.com/r/MachineLearning/comments/97cwak/d_experts_weigh_in_on_the_future_of_ai_and/,baylearn,1534286055,,0,0
738,2018-8-15,2018,8,15,7,97cykv,[D] Distill Update 2018,https://www.reddit.com/r/MachineLearning/comments/97cykv/d_distill_update_2018/,wei_jok,1534286560,,13,42
739,2018-8-15,2018,8,15,7,97cz2r,[R] Large-Scale Study of Curiosity-Driven Learning,https://www.reddit.com/r/MachineLearning/comments/97cz2r/r_largescale_study_of_curiositydriven_learning/,hardmaru,1534286670,,2,35
740,2018-8-15,2018,8,15,8,97da8c,Will doing combinatorial optimization research help me if I do ML in the future?,https://www.reddit.com/r/MachineLearning/comments/97da8c/will_doing_combinatorial_optimization_research/,csquestions5583292,1534289168,[removed],0,1
741,2018-8-15,2018,8,15,9,97dkvu,[R] Deep Neural Decision Trees,https://www.reddit.com/r/MachineLearning/comments/97dkvu/r_deep_neural_decision_trees/,soft-error,1534291582,,19,17
742,2018-8-15,2018,8,15,10,97e0p4,New SOTA on character level language modelling using deep Transformers!,https://www.reddit.com/r/MachineLearning/comments/97e0p4/new_sota_on_character_level_language_modelling/,RaionTategami,1534295202,,13,38
743,2018-8-15,2018,8,15,10,97e4ip,How difficult is it to code and implement ML algorithms without using packages such as scikit-learn from a non-CS background?,https://www.reddit.com/r/MachineLearning/comments/97e4ip/how_difficult_is_it_to_code_and_implement_ml/,jambery,1534296074,[removed],0,1
744,2018-8-15,2018,8,15,10,97e6jh,[P] A Reinforcement Learning agent learning to play Clash Royale on Twitch,https://www.reddit.com/r/MachineLearning/comments/97e6jh/p_a_reinforcement_learning_agent_learning_to_play/,drhon1337,1534296546,,21,46
745,2018-8-15,2018,8,15,10,97e8ya,"[D] Which PhD to pursue for ""data scientist""/ ""machine learning researcher"" roles?",https://www.reddit.com/r/MachineLearning/comments/97e8ya/d_which_phd_to_pursue_for_data_scientist_machine/,Tiff9595,1534297092,"Hello, I am a masters student working with a ML Theory (Bayesian Stat side) professor. 
Thanks to your help last time, I could make a good decision in choosing my advisor! As a noob who's pretty lost, I came back to ask you on phd decisions!
So I am pretty decided on applying to a phd. But for my phd application, I am split between choosing an applied subfield(ex. NLP, robotoics, vision, ...) and sticking with more ""theoretical"" fields (like network models, ml + numerical methods,  bayesian stat...). I don't really want to work with the same kind of data(like only images in CV, only documents in NLP) for years. But at the same time, I don't want to pursue stuff that is only proofs with no code. Most importantly, I want to do a field with good industry job prospects. 

Between an applied phd and a more theoretical phd, what is more welcomed when getting 
1. ""data scientist"" jobs
and 
2. ""machine learning researcher"" jobs?

Also, are you limited in the job you can get if do an ""applied subfield""? (For example, if you do NLP PhD, can you only get NLP jobs? Or, for example, can you get a NLP job even if you did robotics phd?)

Finally, is doing numerical methods (like numerical matrix methods, parallel computing...) together with ml considered a ""promising direction""?

I honestly don't even really know what these jobs actually are  ... but would like to just get some advice from you (who must know a lot more than me at least!) Sorry to ask so many questions in one post. Any feedback really helps me. Thanks in advance!",7,0
746,2018-8-15,2018,8,15,11,97esk3,How can deep learning be applied in Physics ?,https://www.reddit.com/r/MachineLearning/comments/97esk3/how_can_deep_learning_be_applied_in_physics/,Al-Khazrajy,1534301759,[removed],0,1
747,2018-8-15,2018,8,15,11,97esw2,Attention model - How to deal with variable feature dimension ?,https://www.reddit.com/r/MachineLearning/comments/97esw2/attention_model_how_to_deal_with_variable_feature/,HaziqRazali,1534301837,[removed],0,1
748,2018-8-15,2018,8,15,15,97fxso,[R] R-grams: Unsupervised Learning of Semantic Units in Natural Language,https://www.reddit.com/r/MachineLearning/comments/97fxso/r_rgrams_unsupervised_learning_of_semantic_units/,mesmer_adama,1534313159,,22,16
749,2018-8-15,2018,8,15,15,97g3gy,Website having links for ML tutorials,https://www.reddit.com/r/MachineLearning/comments/97g3gy/website_having_links_for_ml_tutorials/,aiaorta09,1534315092,[removed],0,1
750,2018-8-15,2018,8,15,16,97g84p,[R] Understanding and Applying Self-attention for NLP,https://www.reddit.com/r/MachineLearning/comments/97g84p/r_understanding_and_applying_selfattention_for_nlp/,DemiourgosD,1534316752,[removed],0,1
751,2018-8-15,2018,8,15,16,97g9xe,[R] Understanding and Applying Self-attention,https://www.reddit.com/r/MachineLearning/comments/97g9xe/r_understanding_and_applying_selfattention/,DemiourgosD,1534317352,,0,0
752,2018-8-15,2018,8,15,17,97ghf2,Help needed! Trying to install CUDA in Ubuntu 18.04,https://www.reddit.com/r/MachineLearning/comments/97ghf2/help_needed_trying_to_install_cuda_in_ubuntu_1804/,jetjodh,1534320090,[removed],0,1
753,2018-8-15,2018,8,15,17,97ghsw,[R] Understanding human-human interactions: a survey,https://www.reddit.com/r/MachineLearning/comments/97ghsw/r_understanding_humanhuman_interactions_a_survey/,Alex_Stergiou,1534320240,"Many videos depict people, and it is their interactions that inform us of their activities, relation to one another and the cultural and social setting. With advances in human action recognition, researchers have begun to address the automated recognition of these human-human interactions from video. The main challenges stem from dealing with the considerable variation in recording settings, the appearance of the people depicted and the performance of their interaction. This survey provides a summary of these challenges and datasets, followed by an in-depth discussion of relevant vision-based recognition and detection methods. We focus on recent, promising work based on convolutional neural networks (CNNs). Finally, we outline directions to overcome the limitations of the current state-of-the-art.

[Three interactions: handshake, hug or lift, and passing object. These examples show a non-standard body poses \(left\), ambiguous class labeling \(center\) and the need for temporal information \(right\).](https://i.redd.it/m1h1fj8kr7g11.jpg)",3,0
754,2018-8-15,2018,8,15,17,97gm7a,Horizontal 4 Side Seal Packaging Machine (Patches Flat &amp; Solid Items),https://www.reddit.com/r/MachineLearning/comments/97gm7a/horizontal_4_side_seal_packaging_machine_patches/,chinamachine,1534321911,,0,1
755,2018-8-15,2018,8,15,18,97gulk,Tutorial of GAN from CVPR 2018,https://www.reddit.com/r/MachineLearning/comments/97gulk/tutorial_of_gan_from_cvpr_2018/,nobodykid23,1534325026,[removed],0,1
756,2018-8-15,2018,8,15,18,97gvm4,Postdoctoral fellowship: Machine Learning for NeuroImaging of Stroke Recovery,https://www.reddit.com/r/MachineLearning/comments/97gvm4/postdoctoral_fellowship_machine_learning_for/,mreyesag,1534325413,,0,1
757,2018-8-15,2018,8,15,18,97gw7t,Check this out!,https://www.reddit.com/r/MachineLearning/comments/97gw7t/check_this_out/,bolteltend,1534325623,,0,1
758,2018-8-15,2018,8,15,19,97h58s,Which tools to use for illustrations in ML research papers,https://www.reddit.com/r/MachineLearning/comments/97h58s/which_tools_to_use_for_illustrations_in_ml/,vector_machines,1534328779,[removed],0,1
759,2018-8-15,2018,8,15,21,97hnb3,How Deep Learning Predicts Who Wrote @realDonaldTrump Tweets,https://www.reddit.com/r/MachineLearning/comments/97hnb3/how_deep_learning_predicts_who_wrote/,didtrumptweetit,1534334455,,0,1
760,2018-8-15,2018,8,15,21,97hnm8,The 10 best talks on Machine Learning at PyData Amsterdam 2018,https://www.reddit.com/r/MachineLearning/comments/97hnm8/the_10_best_talks_on_machine_learning_at_pydata/,PythonLinksDotInfo,1534334532,,0,1
761,2018-8-15,2018,8,15,21,97hqna,Are conditional GANs and auxiliary GANs the same thing?,https://www.reddit.com/r/MachineLearning/comments/97hqna/are_conditional_gans_and_auxiliary_gans_the_same/,PKJY,1534335324,[removed],0,1
762,2018-8-15,2018,8,15,21,97hsqq,Building Pokdex in Android using TensorFlow Lite and Firebase ML Kit,https://www.reddit.com/r/MachineLearning/comments/97hsqq/building_pokdex_in_android_using_tensorflow_lite/,the-dagger,1534335883,,0,1
763,2018-8-15,2018,8,15,21,97hszz,Machine Learning With Python - 6: Dummy Variables &amp; One Hot Encoding,https://www.reddit.com/r/MachineLearning/comments/97hszz/machine_learning_with_python_6_dummy_variables/,Beneficial3Fish,1534335958,,0,1
764,2018-8-15,2018,8,15,21,97hx0u,An explanation on Facebook's universal music translation GAN,https://www.reddit.com/r/MachineLearning/comments/97hx0u/an_explanation_on_facebooks_universal_music/,taixhi,1534337023,,0,1
765,2018-8-15,2018,8,15,22,97i2ij,Help with understanding LSTM networks,https://www.reddit.com/r/MachineLearning/comments/97i2ij/help_with_understanding_lstm_networks/,tnugget,1534338408,[removed],0,1
766,2018-8-15,2018,8,15,22,97i2y9,Comment a theory that will work on machine that works like a human.,https://www.reddit.com/r/MachineLearning/comments/97i2y9/comment_a_theory_that_will_work_on_machine_that/,machine_to_brain,1534338505,[removed],0,1
767,2018-8-15,2018,8,15,22,97igpm,"i made this NN, any criticisms?",https://www.reddit.com/r/MachineLearning/comments/97igpm/i_made_this_nn_any_criticisms/,lnadav,1534341586,[removed],0,1
768,2018-8-15,2018,8,15,23,97ijxj,[Q] Can someone help me with this simple backpropagation?,https://www.reddit.com/r/MachineLearning/comments/97ijxj/q_can_someone_help_me_with_this_simple/,math_questions101,1534342321,[removed],0,1
769,2018-8-15,2018,8,15,23,97iktx,AMD ROCm vs. Nvidia CUDA.,https://www.reddit.com/r/MachineLearning/comments/97iktx/amd_rocm_vs_nvidia_cuda/,MusicIsLife1995,1534342515,[removed],0,1
770,2018-8-15,2018,8,15,23,97in0f,[D] Need help with this backpropagation,https://www.reddit.com/r/MachineLearning/comments/97in0f/d_need_help_with_this_backpropagation/,0b01,1534342966,"This is a very simple NAC implementation. Can't seem to get this to work. What am I missing?

```python
from random import random
import math

def tanh(x):
    return math.tanh(x)

def dtanh(x):
    return 1. - math.tanh(x) ** 2

def sigmoid(x):
    return 1 / (1 + math.exp(-x))

def dsigmoid(x):
    return x * (1 - x)

m0 = 2.2
m1 = 2.2
w0 = 2.2
w1 = 2.2

for i in range(1000000):
    x0 = 0.5 + random()
    x1 = 0.5 + random()
    y = x0 + x1

    # forward
    y_h = tanh(m0) * sigmoid(w0) * x0 + \
          tanh(m1) * sigmoid(w1) * x1

    # calculate error
    e = y_h - y
    err = 0.5 * e ** 2

    # backward
    m0 -= e * x0 * sigmoid(w0) * dtanh(m0)
    w0 -= e * x0 * dsigmoid(w0) * tanh(m0)
    m1 -= e * x1 * sigmoid(w1) * dtanh(m1)
    w1 -= e * x1 * dsigmoid(w1) * tanh(m1)


    print(m0, m1 ,w0 ,w1)
    print(tanh(m1) * sigmoid(w1))

```",3,1
771,2018-8-15,2018,8,15,23,97iq5m,Can you create an image classifier that can detect the cat in this picture? Please share your GitHub repo bellow :),https://www.reddit.com/r/MachineLearning/comments/97iq5m/can_you_create_an_image_classifier_that_can/,saadmrb,1534343602,[removed],0,1
772,2018-8-16,2018,8,16,0,97j0fc,[R] Exploring the limits of weakly supervised learning - FAIR (Kaiming He),https://www.reddit.com/r/MachineLearning/comments/97j0fc/r_exploring_the_limits_of_weakly_supervised/,vector_machines,1534345698,,2,26
773,2018-8-16,2018,8,16,0,97j431,"[R] FAIR EMNLP papers, unsupervised MT",https://www.reddit.com/r/MachineLearning/comments/97j431/r_fair_emnlp_papers_unsupervised_mt/,vector_machines,1534346435,,0,0
774,2018-8-16,2018,8,16,0,97jbbf,[R] Analyzing Inverse Problems with Invertible Neural Networks,https://www.reddit.com/r/MachineLearning/comments/97jbbf/r_analyzing_inverse_problems_with_invertible/,vll_diz,1534347869,"Paper: [https://arxiv.org/abs/1808.04730](https://arxiv.org/abs/1808.04730)

Blogpost: [https://hci.iwr.uni-heidelberg.de/vislearn/inverse-problems-invertible-neural-networks/](https://hci.iwr.uni-heidelberg.de/vislearn/inverse-problems-invertible-neural-networks/)",32,74
775,2018-8-16,2018,8,16,0,97jeoz,"Simple Questions Thread August 15, 2018",https://www.reddit.com/r/MachineLearning/comments/97jeoz/simple_questions_thread_august_15_2018/,AutoModerator,1534348541,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",0,1
776,2018-8-16,2018,8,16,1,97jm2m,The 3 Types of Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/97jm2m/the_3_types_of_machine_learning_algorithms/,yamsalm,1534349916,,0,1
777,2018-8-16,2018,8,16,2,97k9nv,Recent paper on an approximately discrete activation function?,https://www.reddit.com/r/MachineLearning/comments/97k9nv/recent_paper_on_an_approximately_discrete/,shmageggy,1534354372,[removed],0,1
778,2018-8-16,2018,8,16,3,97ktma,[P] GraphPipe -- Dead Simple ML Model Serving via a Standard Protocol,https://www.reddit.com/r/MachineLearning/comments/97ktma/p_graphpipe_dead_simple_ml_model_serving_via_a/,vishvananda,1534358254,,3,12
779,2018-8-16,2018,8,16,3,97kxme,[R] Clinically applicable deep learning for diagnosis and referral in retinal disease,https://www.reddit.com/r/MachineLearning/comments/97kxme/r_clinically_applicable_deep_learning_for/,brates09,1534359053,,4,33
780,2018-8-16,2018,8,16,4,97l3ec,Random Gradient,https://www.reddit.com/r/MachineLearning/comments/97l3ec/random_gradient/,kkoehncke,1534360236,,1,1
781,2018-8-16,2018,8,16,4,97l741,[R] Multiplying Loss by Random Number Improves Training,https://www.reddit.com/r/MachineLearning/comments/97l741/r_multiplying_loss_by_random_number_improves/,kkoehncke,1534360995,Paper: [https://arxiv.org/pdf/1808.04293v1.pdf](https://arxiv.org/pdf/1808.04293v1.pdf),3,0
782,2018-8-16,2018,8,16,4,97l9e1,has anyone done the udacity deep reinforcement learning nanodegree program?,https://www.reddit.com/r/MachineLearning/comments/97l9e1/has_anyone_done_the_udacity_deep_reinforcement/,phosphorvk,1534361471,[removed],0,1
783,2018-8-16,2018,8,16,4,97la30,"Ant Financial, the world's largest unicorn, is already using Ray in production in multiple use cases",https://www.reddit.com/r/MachineLearning/comments/97la30/ant_financial_the_worlds_largest_unicorn_is/,gradientflow,1534361613,,0,1
784,2018-8-16,2018,8,16,5,97lnpe,"How does the brain implement perception and action? A deep dive into Karl Friston's Free Energy Principle and Active Inference that explains the behavior of cells, organs, animals, humans, and entire species.",https://www.reddit.com/r/MachineLearning/comments/97lnpe/how_does_the_brain_implement_perception_and/,Time-Over,1534364324,,0,1
785,2018-8-16,2018,8,16,5,97lt5c,"[P] Check out Evolute, my evolutionary algorithm toolbox for Python!",https://www.reddit.com/r/MachineLearning/comments/97lt5c/p_check_out_evolute_my_evolutionary_algorithm/,csxeba,1534365443,"Hi guys, I'm open sourcing my evolutionary algorithm toolbox for Python 3. It is still quite simple, but I intend to develop it more and if it gets mature enough, maybe publish it on PIP.

I use it mainly to do Neuroevolution with Keras, so it is designed to easily interface with Keras and it is able to evolve the network parameters, but it is also a general toolbox for evolutionary algorithms.

Note: I know about DEAP, it is much more feature rich than Evolute, but it is also much more complicated to use. Evolute is aiming for as much user friendliness as possible.

Feedback is welcome, and also pull requests :)",24,124
786,2018-8-16,2018,8,16,6,97m1hp,[Discussion] Machine Learning course at Coursera,https://www.reddit.com/r/MachineLearning/comments/97m1hp/discussion_machine_learning_course_at_coursera/,the_empty,1534367105,"Hey guys, I am a software developer and I am interested in ML, what do you think about this course? 

https://www.coursera.org/learn/machine-learning",20,13
787,2018-8-16,2018,8,16,6,97m2gi,Turning Fortnite into PUBG with Deep Learning (CycleGAN),https://www.reddit.com/r/MachineLearning/comments/97m2gi/turning_fortnite_into_pubg_with_deep_learning/,TripTripHooray,1534367294,,0,1
788,2018-8-16,2018,8,16,6,97m5uc,UT ECE or UT CS?,https://www.reddit.com/r/MachineLearning/comments/97m5uc/ut_ece_or_ut_cs/,CuriousA1,1534367959,[removed],0,1
789,2018-8-16,2018,8,16,6,97maxq,"[R] ""Improving Shape Deformation in Unsupervised Image-to-Image Translation"", Gokaslan et al 2018 [semantic segmentation for anime&lt;-&gt;photo faces]",https://www.reddit.com/r/MachineLearning/comments/97maxq/r_improving_shape_deformation_in_unsupervised/,gwern,1534369033,,2,10
790,2018-8-16,2018,8,16,8,97mz1a,Curiosity-Driven Learning: Learning by avoiding boredom,https://www.reddit.com/r/MachineLearning/comments/97mz1a/curiositydriven_learning_learning_by_avoiding/,pacukluka,1534374166,,32,60
791,2018-8-16,2018,8,16,8,97mze3,[Discussion] Thoughts on pipelining GANs to word embedders (such as Word2Vec or Doc2Vec) in order to recreate similar words/documents?,https://www.reddit.com/r/MachineLearning/comments/97mze3/discussion_thoughts_on_pipelining_gans_to_word/,quit_daedalus,1534374252,"Hello there. 

I've previously implemented a binary classification system on text corpora using word embeddings for feature extraction, but my next assignment is to extract keywords or a summary of a document in this system. In other words, I'm assigned to find which words are crucial to the meaning of a document. Currently, I'm thinking of using a GAN network in order to generate 5 words length documents and comparing the feature vector of the generated document to the original for loss computation, but I've heard that training GAN requires lots of time and is really experimental, so I had to come here and ask you guys what do you think? If you agree with using a GAN, which architecture do you recommend? ",2,2
792,2018-8-16,2018,8,16,8,97n8xb,Neural Machine Translation as a Path to Paraphrastic Sentence Identification,https://www.reddit.com/r/MachineLearning/comments/97n8xb/neural_machine_translation_as_a_path_to/,CamUrban,1534376438,,0,1
793,2018-8-16,2018,8,16,9,97nl05,[R] Moving Beyond Translation with the Universal Transformer,https://www.reddit.com/r/MachineLearning/comments/97nl05/r_moving_beyond_translation_with_the_universal/,rasmii,1534379221,,14,69
794,2018-8-16,2018,8,16,10,97nyyj,Masters: CS or Applied Statistics?,https://www.reddit.com/r/MachineLearning/comments/97nyyj/masters_cs_or_applied_statistics/,alildoge,1534382457,[removed],0,1
795,2018-8-16,2018,8,16,12,97oyet,Top 20 Amazing Machine Learning Tools To Try Right Now,https://www.reddit.com/r/MachineLearning/comments/97oyet/top_20_amazing_machine_learning_tools_to_try/,mlcrunch,1534391135,,1,1
796,2018-8-16,2018,8,16,15,97prav,UnsupervisedMT released by FAIR,https://www.reddit.com/r/MachineLearning/comments/97prav/unsupervisedmt_released_by_fair/,adammathias,1534399320,,0,1
797,2018-8-16,2018,8,16,15,97pu0e,[P] Neural ALU Implemented in x86 Assembly,https://www.reddit.com/r/MachineLearning/comments/97pu0e/p_neural_alu_implemented_in_x86_assembly/,0b01,1534400139,,11,122
798,2018-8-16,2018,8,16,15,97q1vt,CFP: ZhejiangLab Cup Global Artificial Intelligence Competition 2018,https://www.reddit.com/r/MachineLearning/comments/97q1vt/cfp_zhejianglab_cup_global_artificial/,zcgaic2018,1534402600,[removed],0,1
799,2018-8-16,2018,8,16,16,97qa7l,Neural Network,https://www.reddit.com/r/MachineLearning/comments/97qa7l/neural_network/,SiDinh_ITRI_Taiwan,1534405223,[removed],0,1
800,2018-8-16,2018,8,16,17,97qjzr,[D] Experts Weigh in on the Future of AI and Evolutionary Algorithms,https://www.reddit.com/r/MachineLearning/comments/97qjzr/d_experts_weigh_in_on_the_future_of_ai_and/,Kaixhin,1534408546,,3,3
801,2018-8-16,2018,8,16,18,97qp9f,[D] (Re)-Train on a small dataset and new incoming data,https://www.reddit.com/r/MachineLearning/comments/97qp9f/d_retrain_on_a_small_dataset_and_new_incoming_data/,Gaudi91,1534410374,"Hello guys,

I would like to train a classifier (doesn't matter which learning algorithm) on a small set of training data.  As soon as the system predicts new samples, it should collect it, add the samples to the training data and re-train the classifier.  The users have the option to validate the prediction so that the new incoming data is labeled correctly.

But which new data should be selected? Every data, doesn't matter if the prediction was correct or wrong? Only data that prediction was wrong, or where the confidence was low? What about class imbalance? What happens if one class is more represented in the new data?

Is this intention possible?

Thank you",4,4
802,2018-8-16,2018,8,16,18,97qv1h,Linear Regression in R - Explained,https://www.reddit.com/r/MachineLearning/comments/97qv1h/linear_regression_in_r_explained/,pooja307,1534412301,,0,1
803,2018-8-16,2018,8,16,21,97rnmm,Convolutional Neural Networks In Classifying Cancer Through DNA Methylation,https://www.reddit.com/r/MachineLearning/comments/97rnmm/convolutional_neural_networks_in_classifying/,learned_entrepreneur,1534420805,[removed],0,2
804,2018-8-16,2018,8,16,21,97rpjw,Introducing GraphPipe,https://www.reddit.com/r/MachineLearning/comments/97rpjw/introducing_graphpipe/,udelblue,1534421292,,0,1
805,2018-8-16,2018,8,16,21,97rua6,Top 10 Applications of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/97rua6/top_10_applications_of_machine_learning/,pooja307,1534422455,,0,1
806,2018-8-16,2018,8,16,22,97s9pc,"""Distributing Research"" - Internship Question",https://www.reddit.com/r/MachineLearning/comments/97s9pc/distributing_research_internship_question/,rtk25,1534426046,[removed],0,1
807,2018-8-16,2018,8,16,22,97sa7b,"[D] ""Distributed Research"" - Internship Question",https://www.reddit.com/r/MachineLearning/comments/97sa7b/d_distributed_research_internship_question/,rtk25,1534426164,"Hey all,

I'm a new PhD student currently abroad on a short research internship. After delving into the research problem, I came up with a solution sketch which I have a feeling could be quite a bit more general approach beyond the original problem, which was quite focused.

I would like to undertake this more general approach, but I'm the only one working on it, and it involves a few disciplines, so I'm thinking it may not be doable in the short time I have. Therefore, I was wondering whether it could be worth putting out a short paper describing the solution sketch (unfortunately no experiments or implementation yet)

\- an idea that could be of interest for the wider community

\- a sort of proposal for collaboration and means by which to ""distribute"" the research effort if it is found interesting by others.

\- a way to come out of the internship with a paper :)

Or would this be deemed as not serious by the community?

I will of course consult with my advisor back home regarding this, but would be happy for *n* other opinions and papers similar in scope if you're familiar with any.

Thanks!",4,2
808,2018-8-16,2018,8,16,23,97sipf,"Data Science in 30 Minutes: Deep Learning to Detect Fake News with Uber ATG Head of Data Science, Mike Tamir",https://www.reddit.com/r/MachineLearning/comments/97sipf/data_science_in_30_minutes_deep_learning_to/,datascienceguy203,1534428052,,0,1
809,2018-8-16,2018,8,16,23,97srz7,Posing a Teachable Machine  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/97srz7/posing_a_teachable_machine_coinmonks_medium/,coinmonks,1534429864,,0,1
810,2018-8-16,2018,8,16,23,97swa2,[D] Parallelizing Pure-Exploration in Multi-Armed Bandit Settings,https://www.reddit.com/r/MachineLearning/comments/97swa2/d_parallelizing_pureexploration_in_multiarmed/,HenryHux,1534430713,"Hi Reddit!

I have already posted this to r/datascience but was advised that this was the right sub for my question:

recently, I have written a Java implementation of the fairly new [Anchors](https://homes.cs.washington.edu/%7Emarcotcr/aaai18.pdf) algorithm. 

However, as the algorithm is highly computation-intensive, I would like to add some performance improvements. 

The algorithm's authors formulate finding the best n-candidates as a  multi-armed bandit problem and propose to use the pure-exploration  KL-LUCB algorithm. 

As the evaluation consists of both repeated perturbation of the  inspected instance and subsequent evaluation by the means of a provided  model, this is where definitely most resources are being consumed. When  an instance gets perturbed, all features not specified by the candidate  may get changed. After each perturbation has been evaluated by the  provided model, the anchor's precision can easily be calculated by  relating correct predictions. This is how the best candidates get  chosen.

Therefore, I'd like to introduce a parallel/batch pure-exploration  multi-armed bandit algorithm to make use of threading. As there are no  open-source implementations, yet and I am no mathematician, this haven  proven very hard for me. 

I have found an algorithm called [GP-UCB-PE](https://arxiv.org/abs/1304.5350) which sounds promising. However, I am not even sure whether this algorithm may be applied to the problem depicted above.

What would you say is the best way to parallelize the evaluation? Is there any chance to do this at all?

Any advice and suggestions will be greatly appreciated!",12,7
811,2018-8-16,2018,8,16,23,97sy28,"AMA happening right now. Alan Majer, founder of Good Robot in Toronto - is custom building a functional AI Robot to be the co-host of a new podcast called ""Artificial"" created by comedian Ana-Marija Stojic",https://www.reddit.com/r/MachineLearning/comments/97sy28/ama_happening_right_now_alan_majer_founder_of/,yimmy51,1534431069,,0,1
812,2018-8-16,2018,8,16,23,97t0c6,"[N] Weekly Machine Learning Opensource Roundup  Aug. 16, 2018",https://www.reddit.com/r/MachineLearning/comments/97t0c6/n_weekly_machine_learning_opensource_roundup_aug/,stkim1,1534431539,,0,1
813,2018-8-17,2018,8,17,0,97t6mm,RNN or CNN to Sequence-to-Sequence tasks?,https://www.reddit.com/r/MachineLearning/comments/97t6mm/rnn_or_cnn_to_sequencetosequence_tasks/,VniciusMt,1534432753,[removed],0,1
814,2018-8-17,2018,8,17,0,97t8yo,Salesforce open-sources machine learning library that powers Einstein: TransmogrifAI,https://www.reddit.com/r/MachineLearning/comments/97t8yo/salesforce_opensources_machine_learning_library/,snendroid-ai,1534433220,"Official blog: [https://engineering.salesforce.com/open-sourcing-transmogrifai-4e5d0e098da2](https://engineering.salesforce.com/open-sourcing-transmogrifai-4e5d0e098da2)

Github: [https://github.com/salesforce/TransmogrifAI](https://github.com/salesforce/TransmogrifAI)

Documents: [https://transmogrif.ai/](https://transmogrif.ai/)",0,1
815,2018-8-17,2018,8,17,1,97tjx8,"[X-Post] Machine Learning, Natural Language Signatures, and Privacy",https://www.reddit.com/r/MachineLearning/comments/97tjx8/xpost_machine_learning_natural_language/,cryptot14,1534435355,,0,1
816,2018-8-17,2018,8,17,1,97tuwt,Browser plugin to analyze chess positions from videos in real time x-post from /r/chess,https://www.reddit.com/r/MachineLearning/comments/97tuwt/browser_plugin_to_analyze_chess_positions_from/,pkacprzak,1534437472,,0,1
817,2018-8-17,2018,8,17,2,97u4ax,Understanding integrating contexts into RNNs,https://www.reddit.com/r/MachineLearning/comments/97u4ax/understanding_integrating_contexts_into_rnns/,__cxa_finalize,1534439239,[removed],0,1
818,2018-8-17,2018,8,17,2,97u605,[P] Open Sourcing TransmogrifAI - Automated Machine Learning for Structured Data,https://www.reddit.com/r/MachineLearning/comments/97u605/p_open_sourcing_transmogrifai_automated_machine/,jauntbox,1534439557,,1,66
819,2018-8-17,2018,8,17,2,97u7i3,[D] Question on context dependent RNN,https://www.reddit.com/r/MachineLearning/comments/97u7i3/d_question_on_context_dependent_rnn/,__cxa_finalize,1534439848,"I'm a bit confused by the diagram of the paper ""Context dependent recurrent neural network language model.""

https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/rnn_ctxt.pdf

I'm assuming s(t) is the state at time t, and they give the following equation:
s(t) = f (Uw(t) + Ws(t1) + Ff (t))
y(t) = g (Vs(t) + Gf(t))

1. Why is it necessary that both s(t) and y(t) use f(t), or what goes wrong if you only use it in y(t)? My intuition says that if you simply had the second equation, then the weight matrix G would still learn to capture some relationship between the sequences and the context.
2. (implementation question) If I were to implement this in TensorFlow, would I have to make my own custom LSTM cell that incorporates the context somehow?

Note of where I'm coming from: I have a basic grasp of RNNs (at the level where I'm trying to understand a variation such as this one), and I've currently implemented a basic one in TensorFlow that takes my sequence features. 

",1,2
820,2018-8-17,2018,8,17,2,97u8zj,When PyTorch is user friendly but TensorFlow is bae,https://www.reddit.com/r/MachineLearning/comments/97u8zj/when_pytorch_is_user_friendly_but_tensorflow_is/,KingSlayer94,1534440112,,0,1
821,2018-8-17,2018,8,17,3,97uqt6,[D] Is Nassim Taleb right about AI not being able to accurately predict certain types of distributions?,https://www.reddit.com/r/MachineLearning/comments/97uqt6/d_is_nassim_taleb_right_about_ai_not_being_able/,TillBillyJoe,1534443534,"So Taleb has two heuristics to generally describe data distributions. One is Mediocristan, which basically means things that are on a Gaussian distribution such as height and/or weight of people.

The other is called Extremistan, which describes a more Pareto like or fat-tailed distribution. An example is wealth distribution, 1% of people own 50% of the wealth or something close to that and so predictability from limited data sets is much harder or even impossible. This is because you can add a single sample to your data set and the consequences are so large that it breaks the model, or has an effect so large that it cancels out any of the benefits from prior accurate predictions. In fact this is how he claims to have made money in the stock market, because everyone else was using bad, Gaussian distribution models to predict the market, which actually would work for a short period of time but when things went wrong, they went really wrong which would cause you to have net losses in the market.

I found this video of Taleb being asked about AI. His claim is that A.I. doesn't work (as well) for things that fall into extremistan.

Is he right? Will some things just be inherently unpredictable even with A.I.?

Here is the video I am referring to https://youtu.be/B2-QCv-hChY?t=43m08s",64,28
822,2018-8-17,2018,8,17,3,97utod,"""Do you fear a robot uprising?"" - conversation with AI Robot designer and builder Alan Majer, founder of Good Robot",https://www.reddit.com/r/MachineLearning/comments/97utod/do_you_fear_a_robot_uprising_conversation_with_ai/,ArtificialThePodcast,1534444061,,0,1
823,2018-8-17,2018,8,17,3,97v0wn,Help me think about this document and user classification problem,https://www.reddit.com/r/MachineLearning/comments/97v0wn/help_me_think_about_this_document_and_user/,CactusSmackedus,1534445434," New job trying not to let them down :)

We have a website with lots of content.

Presently we use Watson NLP to detect taxonomies and attach them to the content.  Then, based on these taxonomies, a human-defined mapping categorizes the content into human-defined categories.

Finally, Users are categorized based on a human-defined mapping from pageviews into the same content categories.

One problem is that on this particular content, much of which is about research, everyone is over-fit into the ""Researcher"" role because the content they tend to access is (to the humans that delineated the categories) research oriented.

What I want to do is use unsupervised learning to read the bag of words model attached to the content (of form ""key"" : probability in [0,1]) to find clusters of related content (e.g. research about plants, research about water, or whatever clusters emerge).

Then, these clusters are used to redefine the categories that content fits in, and users are associated with the content they are most interested in.

A further enhancement would be to observe correlated user behavior and then build distinct user categories that don't necessarily map 1-1 with the content categories, but that's putting the cart before the horse right now.

Does this problem description make sense?  Do you think it's solvable?  What algos should I start looking at?

I have reinforcement learning under my belt but no real NLP or unsupervised learning.

My initial sense of direction is to look at clustering algorithms that are OK with correlated terms (not naive Bayes?).  Then I'll extract the data, run the clustering algos in Python and see what is to be seen.  Any recommended reading?  Tips/tricks? 

Thanks in advance :)",0,1
824,2018-8-17,2018,8,17,4,97v63k,"Backplay: ""Man muss immer umkehren""",https://www.reddit.com/r/MachineLearning/comments/97v63k/backplay_man_muss_immer_umkehren/,cinjon,1534446435,[removed],0,1
825,2018-8-17,2018,8,17,4,97v6cl,I'm trying to build GAN library using Keras,https://www.reddit.com/r/MachineLearning/comments/97v6cl/im_trying_to_build_gan_library_using_keras/,Another__one,1534446477,[removed],0,1
826,2018-8-17,2018,8,17,4,97v6lo,"Backplay: Invert, always invert.",https://www.reddit.com/r/MachineLearning/comments/97v6lo/backplay_invert_always_invert/,cinjon,1534446529,[removed],0,1
827,2018-8-17,2018,8,17,4,97v7fa,"Backplay: ""Man muss immer umkehren""",https://www.reddit.com/r/MachineLearning/comments/97v7fa/backplay_man_muss_immer_umkehren/,cinjon,1534446685,[removed],1,1
828,2018-8-17,2018,8,17,4,97vf4y,Understanding Neural ALU  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/97vf4y/understanding_neural_alu_coinmonks_medium/,coinmonks,1534448179,,0,1
829,2018-8-17,2018,8,17,6,97w5dh,"Artificial, The Podcast - A podcast co-hosted with a real, functional, interactive, Artificial Intelligence Robot. Be a part of history.",https://www.reddit.com/r/MachineLearning/comments/97w5dh/artificial_the_podcast_a_podcast_cohosted_with_a/,ArtificialThePodcast,1534453383,,0,1
830,2018-8-17,2018,8,17,6,97wf56,[1808.05174] Recycle-GAN: Unsupervised Video Retargeting,https://www.reddit.com/r/MachineLearning/comments/97wf56/180805174_recyclegan_unsupervised_video/,Bardelaz,1534455369,,1,17
831,2018-8-17,2018,8,17,7,97wt7h,[DLMIA 2018] UNet++: A Nested U-Net Architecture for Medical Image Segmentation,https://www.reddit.com/r/MachineLearning/comments/97wt7h/dlmia_2018_unet_a_nested_unet_architecture_for/,mahfuzmohammad,1534458343,[removed],0,1
832,2018-8-17,2018,8,17,7,97wuxy,"Hey everyone, I am finishing my masters in machine learning and I was bored so I was wondering if anyone has any fun projects I can help with in my free time?",https://www.reddit.com/r/MachineLearning/comments/97wuxy/hey_everyone_i_am_finishing_my_masters_in_machine/,kitronas,1534458728,,0,1
833,2018-8-17,2018,8,17,7,97wz8h,Is classification data recorded ever as a fraction for data ambiguously identified?,https://www.reddit.com/r/MachineLearning/comments/97wz8h/is_classification_data_recorded_ever_as_a/,Ikuyas,1534459667,"In data collection and recording stage, there will be cases when humans also have a hard time identifying which one for example, say, binary classification application. In this case, does the data get recorded as 0.5 or something like that? 

it helps the algorithm doesn't it? It could help the model mistakenly generate too high probability on the wrong classification like 75% or something when in fact it should be more like 52%. I also wonder if it speeds up the training process.",0,1
834,2018-8-17,2018,8,17,8,97x4du,My work on Andrew's Ng Deep Learning Coursera Specialization,https://www.reddit.com/r/MachineLearning/comments/97x4du/my_work_on_andrews_ng_deep_learning_coursera/,fotisk07,1534460788,,0,1
835,2018-8-17,2018,8,17,8,97x6r8,Help hypothesis!,https://www.reddit.com/r/MachineLearning/comments/97x6r8/help_hypothesis/,joshuaronis,1534461292,,0,1
836,2018-8-17,2018,8,17,8,97x8aq,[D] To find a thesis advisor in ML,https://www.reddit.com/r/MachineLearning/comments/97x8aq/d_to_find_a_thesis_advisor_in_ml/,HigherTopoi,1534461642,"I'm a PhD student in one of the top 10 programs in the world in terms of DL research, and I'm looking for a thesis advisor (inside or outside of my university) to present my projects on DL. I'm working on my own projects in certain subfields of NLP and RL, and it is difficult to find someone who is interested in them or even can understand my projects. For example, one of my projects uses Transformer and its more recent variants, and it's hard to find someone who is aware that, say, using convolution with k strictly greater than 1 in addition to self-attention is actually crucial for obtaining the SOTA result in LM with long-range dependency. 

Almost everyone who produces meaningful works on this area is in either Google Brain, FAIR, OpenAI or DeepMind. One or two of them may possibly accept graduate students to be his/her advisee, but it's uncertain whether they will accept me even if I have relevant publications, given they have other works to do. 

As I achieved a SOTA result in my paper to be submitted on my own, I believe I can do meaningful research works without help of my advisor (e.g. without any feedback). However, I cannot obtain the degree without having an advisor, so all I ask for him/her is to let me do my own work freely. 

In this case, who should I ask to be my advisor? Should I wait till I publish relevant papers? If I cannot find an advisor even after I have publications, what should I do?",12,3
837,2018-8-17,2018,8,17,8,97x8jx,[N] Women in Machine Learning Call for Participation for NIPS 2018 Workshop,https://www.reddit.com/r/MachineLearning/comments/97x8jx/n_women_in_machine_learning_call_for/,MediumInterview,1534461699,,47,10
838,2018-8-17,2018,8,17,8,97xejd,[D] Google Employees Protest Secret Work on Censored Search Engine for China,https://www.reddit.com/r/MachineLearning/comments/97xejd/d_google_employees_protest_secret_work_on/,inarrears,1534463078,,60,286
839,2018-8-17,2018,8,17,10,97y61g,Analyzing a dataset using Python Pandas Library | Importing CSV files,https://www.reddit.com/r/MachineLearning/comments/97y61g/analyzing_a_dataset_using_python_pandas_library/,RichSecretary,1534469540,,0,1
840,2018-8-17,2018,8,17,10,97y7ar,[R] NVIDIA/vid2vid: Pytorch implementation of our method for high-resolution (e.g. 2048x1024) photorealistic video-to-video translation.,https://www.reddit.com/r/MachineLearning/comments/97y7ar/r_nvidiavid2vid_pytorch_implementation_of_our/,m_ke,1534469850,,0,1
841,2018-8-17,2018,8,17,10,97yas3,LARNN: Linear Attention Recurrent Neural Network,https://www.reddit.com/r/MachineLearning/comments/97yas3/larnn_linear_attention_recurrent_neural_network/,GChe,1534470688,,4,1
842,2018-8-17,2018,8,17,11,97ydon,[P] I'm trying to build GAN library on top of Keras,https://www.reddit.com/r/MachineLearning/comments/97ydon/p_im_trying_to_build_gan_library_on_top_of_keras/,Another__one,1534471390,"I'm trying to build GAN library that would allow to create any sort of GAN with minimum amount of code to make it easy to implement and experiment with. Right now I'm seeking for any sort of feedback and suggestions how to make it more usable. If you are interested in such sort of project, please take a look and share your thoughts about it.

Link: [https://github.com/Mylittlerapture/GANLib](https://github.com/Mylittlerapture/GANLib)",3,17
843,2018-8-17,2018,8,17,11,97yhg4,"How feminism has made me a better scientist - Statistical Modeling, Causal Inference, and Social Science",https://www.reddit.com/r/MachineLearning/comments/97yhg4/how_feminism_has_made_me_a_better_scientist/,CadeOCarimbo,1534472327,,0,1
844,2018-8-17,2018,8,17,11,97ylmo,"Do I have to normalize my input data to the range [0,1] for a neural network?",https://www.reddit.com/r/MachineLearning/comments/97ylmo/do_i_have_to_normalize_my_input_data_to_the_range/,nakedBoy1,1534473394,,0,1
845,2018-8-17,2018,8,17,11,97ypks,Is MIT short online course on Artifical Intelligence worth 2600$,https://www.reddit.com/r/MachineLearning/comments/97ypks/is_mit_short_online_course_on_artifical/,brokenottoman,1534474380,[removed],0,1
846,2018-8-17,2018,8,17,11,97ypu8,Deep Dive into Computer Vision with Neural Networks  Part 2,https://www.reddit.com/r/MachineLearning/comments/97ypu8/deep_dive_into_computer_vision_with_neural/,Michael_Pa,1534474443,,0,1
847,2018-8-17,2018,8,17,12,97ytaa,[D] Are you part of an AI/ML product team? Help us design tools to help you and your team deal with algorithmic bias and unfairness!,https://www.reddit.com/r/MachineLearning/comments/97ytaa/d_are_you_part_of_an_aiml_product_team_help_us/,d19fe8,1534475312,"If you are **part of a team that develops AI or machine learning (ML) products**, we want to hear from you.  
Help us design tools to help you and your team create fairer AI/ML systems! 

We are researchers at Microsoft Research and Carnegie Mellon University, conducting an **anonymous survey** to better understand product teams' current practices, challenges, and needs for support around AI/ML fairness and algorithmic bias. 

Even if you have not thought much about these issues previously, we would love to hear your perspective! 

The survey should take about 15-25 minutes to complete, and will be available at the link below until August 31st:  
r/https://tinyurl.com/FairML",1,0
848,2018-8-17,2018,8,17,12,97yuiz,Just installed tensorflow and i keep getting this error,https://www.reddit.com/r/MachineLearning/comments/97yuiz/just_installed_tensorflow_and_i_keep_getting_this/,CountJeewb,1534475644,[removed],0,1
849,2018-8-17,2018,8,17,12,97yvw0,Deep Dive into Computer Vision with Neural Networks  Part 1,https://www.reddit.com/r/MachineLearning/comments/97yvw0/deep_dive_into_computer_vision_with_neural/,Michael_Pa,1534475980,,0,1
850,2018-8-17,2018,8,17,12,97yxdu,Trying to predict but no luck with CNN using Pytorch.,https://www.reddit.com/r/MachineLearning/comments/97yxdu/trying_to_predict_but_no_luck_with_cnn_using/,PythonGod123,1534476371,"I really need some help with this issue. I have been trying to predict based on a pretrained model but I cannot figure it out at all. I keep getting the same prediction for every picture I put in. Could someone please help me out and tell me what I am doing wrong.

[https://pastebin.com/2vhy09UV](https://pastebin.com/2vhy09UV)",0,1
851,2018-8-17,2018,8,17,13,97z7zz,[R] This proves that CPUs can be a competitive alternative when training neural nets.,https://www.reddit.com/r/MachineLearning/comments/97z7zz/r_this_proves_that_cpus_can_be_a_competitive/,vector_machines,1534479258,,10,20
852,2018-8-17,2018,8,17,13,97zbuw,Javascript ML Libraries that can process text?,https://www.reddit.com/r/MachineLearning/comments/97zbuw/javascript_ml_libraries_that_can_process_text/,RTSx1,1534480331,[removed],0,1
853,2018-8-17,2018,8,17,14,97zr86,More efficient security for cloud-based machine learning,https://www.reddit.com/r/MachineLearning/comments/97zr86/more_efficient_security_for_cloudbased_machine/,ARforKids,1534484894,,0,1
854,2018-8-17,2018,8,17,15,9801rw,wrap and blend image,https://www.reddit.com/r/MachineLearning/comments/9801rw/wrap_and_blend_image/,akshay951228,1534488307,"Given a mask and image .wrap image into mask
Is there any Machine learning paper which I can start with
",0,1
855,2018-8-17,2018,8,17,16,980623,Advantages of Machine Learning in DevOps,https://www.reddit.com/r/MachineLearning/comments/980623/advantages_of_machine_learning_in_devops/,vidushivij,1534489684,,0,1
856,2018-8-17,2018,8,17,17,980gka,[1808.05587] Deep Convolutional Networks as shallow Gaussian Processes,https://www.reddit.com/r/MachineLearning/comments/980gka/180805587_deep_convolutional_networks_as_shallow/,statmlsn,1534493221,,15,75
857,2018-8-17,2018,8,17,18,980r0i,Recommendation system on large-scale data,https://www.reddit.com/r/MachineLearning/comments/980r0i/recommendation_system_on_largescale_data/,duongbaho1988,1534496955,[removed],0,1
858,2018-8-17,2018,8,17,18,980vht,What Makes Paris Look Like Paris?,https://www.reddit.com/r/MachineLearning/comments/980vht/what_makes_paris_look_like_paris/,adammathias,1534498503,,0,1
859,2018-8-17,2018,8,17,19,98145z,nano-tube network devices enable artificial spiking neurons #deeplearning #science,https://www.reddit.com/r/MachineLearning/comments/98145z/nanotube_network_devices_enable_artificial/,_Jess_B,1534501290,[removed],0,1
860,2018-8-17,2018,8,17,20,981dlk,[P][help] Trying to reconstruct charged particle tracks in CERN's CMS experiment. Refeeding predicted values into the network,https://www.reddit.com/r/MachineLearning/comments/981dlk/phelp_trying_to_reconstruct_charged_particle/,The_Kilo,1534504273,"Hi!

I'm currently working on a project where my task is to build a neural network to reconstruct particle tracks in the CMS experiment. I'm using simulated data as my training data, which in practice consists of time-ordered xyz-coordinates.

The problem is to try and predict the next coordinate in a track (a track is basically a set of about \~10 time-ordered xyz-coordinates defining the path of a charged particle in 3D space) using a seed, which consists of the first three coordinates in a particle's track. From these 3 hits the network is supposed to predict the 4th hit. The ultimate goal is to predict the \~10th, or so, hit using the seed and the predicted values. 

Basically, I want this:

1. From seed, predict 4th hit
2. Using seed and predicted 4th hit, predict 5th hit.
3. Using the seed, predicted 4th and 5th hit, predict the 6th hit
4. ...and so on...
5. End up with the predicted 10th hit.

During training, all the coordinates are known.

Needless to say, I am using recurrent layers. **Is there any way in keras(+tensorflow) to train a network which would use it's predictions as input?** The KISS method (as I see it) would be to chain networks together, but it is a pain to train and prone to a lot of errors.

Cheers!",5,3
861,2018-8-17,2018,8,17,20,981g7g,The Amazing Ways How Wikipedia Uses Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/981g7g/the_amazing_ways_how_wikipedia_uses_artificial/,Donn3lly,1534505020,[removed],0,1
862,2018-8-17,2018,8,17,21,981rnd,Program Induction and Synthesis on ICML 2018,https://www.reddit.com/r/MachineLearning/comments/981rnd/program_induction_and_synthesis_on_icml_2018/,yazriel0,1534508205,,1,1
863,2018-8-17,2018,8,17,21,981ywt,Accuracy percent seems too high in Neural Network,https://www.reddit.com/r/MachineLearning/comments/981ywt/accuracy_percent_seems_too_high_in_neural_network/,sectechguy1,1534510022,[removed],0,1
864,2018-8-17,2018,8,17,22,9824yd,I analysed Indian PM Narendra Modi's speeches on radio,https://www.reddit.com/r/MachineLearning/comments/9824yd/i_analysed_indian_pm_narendra_modis_speeches_on/,aryancodify,1534511461,,0,1
865,2018-8-17,2018,8,17,22,9826bt,[D] Why is Deep Learning so bad for tabular data?,https://www.reddit.com/r/MachineLearning/comments/9826bt/d_why_is_deep_learning_so_bad_for_tabular_data/,maltin,1534511779,"By personal experience and general ML culture, I know that standard ML methods like SVM, RF and tree boostings outperform DL models for supervised prediction in tabular data for the vast majority of cases. They outperform both in score and execution time, and I did try to torture my network to employ state of the art techniques without making much progress. Actually, my best results are with shallow (1 layer) and wider networks, which are one step away of becoming a logistic regression. My question is: do you guys know any literature that explores this very question? I understand that \*it is\*, I want to know \*why\* it sucks so bad for tabular / Excel / structured data. Thanks!",71,133
866,2018-8-17,2018,8,17,23,982m6f,[R] Safety-first AI for autonomous data centre cooling and industrial control,https://www.reddit.com/r/MachineLearning/comments/982m6f/r_safetyfirst_ai_for_autonomous_data_centre/,P4TR10T_TR41T0R,1534515316,,11,51
867,2018-8-18,2018,8,18,0,983a23,[D] I'm looking for applications where wide (10k+ nodes) layers are state of the art (or nearly so). Anyone know of any?,https://www.reddit.com/r/MachineLearning/comments/983a23/d_im_looking_for_applications_where_wide_10k/,PokerPirate,1534520249,"I've found a method that makes computing with very wide layers faster, and I'm trying to find as many applications as I can.",24,11
868,2018-8-18,2018,8,18,0,983f31,[D] Deep Learning Frameworks Survey August 2018,https://www.reddit.com/r/MachineLearning/comments/983f31/d_deep_learning_frameworks_survey_august_2018/,azai91,1534521256,,1,0
869,2018-8-18,2018,8,18,1,983h85,[R] Google Brain - Skill Rating for Generative Models,https://www.reddit.com/r/MachineLearning/comments/983h85/r_google_brain_skill_rating_for_generative_models/,trcytony,1534521682,,0,1
870,2018-8-18,2018,8,18,1,983u9d,Books and Courses to Learn Tensorflow on Python,https://www.reddit.com/r/MachineLearning/comments/983u9d/books_and_courses_to_learn_tensorflow_on_python/,hey_krish,1534524242,[removed],0,1
871,2018-8-18,2018,8,18,2,984b57,[D] Combining multiple binary classifiers into a multi-class classifier.,https://www.reddit.com/r/MachineLearning/comments/984b57/d_combining_multiple_binary_classifiers_into_a/,edutainment123,1534527579,"I found this relevant information - [An Overview of Ensemble Methods for Binary Classifiers in Multi-class Problems: Experimental Study on One-vs-One and One-vs-All Schemes](http://sci2s.ugr.es/ovo-ova)

The following problem is pertaining to **Text Classification.** 

**Problem:** Let's say I have a **text dataset** which I want to bifurcate into classes **A, B, C, and Others.** Around 60% of the text is going to be Others (Non A, B, C class) and the rest 40% is distributed among A,B and C, **not mutually exclusive**! That is, a sentence can belong to class A &amp; B or A &amp; C and so on. 

Further the annotated dataset is in the form of three CSVs - A vs \~A, B vs \~B and C vs \~C. **Note** that the sentences belonging to \~&lt;Class\_Name&gt; in each of the CSVs is always large. 

Initially the problem has been treated as a multiple binary classifications -  binary classifiers have been built in the form of **A vs others**, **B vs others** and **C vs others.** 

At this juncture, where the three binary classifiers are already built and which are working ok-ish right now (as per requirements) - 

1. How would you suggest to **combine the classifiers into one multi-class classifier**? That is where the linked resource comes in. **Multi-label** would be one step ahead. 
2. The second alternative could be merge the 3 different CSVs into one CSV and st\\art building models based on this aggregated data which would ultimately lead to building a multi-class classifier. But still the problem of multi-label remains. I have no idea how that should be approached.

Has anyone encountered such a situation before? Appreciate the help :)",4,1
872,2018-8-18,2018,8,18,2,984fk6,UNet++: A Nested U-Net Architecture for Medical Image Segmentation,https://www.reddit.com/r/MachineLearning/comments/984fk6/unet_a_nested_unet_architecture_for_medical_image/,mahfuzmohammad,1534528464,"**Abstract.**

In this paper, we present UNet++, a new, more powerful architecture for medical image segmentation. Our architecture is essentially a deeply-supervised encoder-decoder network where the encoder and decoder sub-networks are connected through a series of nested, dense skip pathways. The re-designed skip pathways aim at reducing the semantic gap between the feature maps of the encoder and decoder sub-networks. We argue that the optimizer would deal with an easier learning task when the feature maps from the decoder and encoder networks are semantically similar. We have evaluated UNet++ in comparison with U-Net and wide U-Net architectures across multiple medical image segmentation tasks: nodule segmentation in the low-dose CT scans of chest, nuclei segmentation  in  the  microscopy  images,  liver  segmentation  in  abdominal  CT scans, and polyp segmentation in colonoscopy videos. Our experiments demonstrate  that  UNet++  with  deep  supervision  achieves  an  average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively.

**Full paper:** [**https://arxiv.org/pdf/1807.10165.pdf**](https://arxiv.org/pdf/1807.10165.pdf)

**Code:** [**https://github.com/MrGiovanni/Nested-UNet**](https://github.com/MrGiovanni/Nested-UNet)",0,1
873,2018-8-18,2018,8,18,3,984iol,UNet++: A Nested U-Net Architecture for Medical Image Segmentation,https://www.reddit.com/r/MachineLearning/comments/984iol/unet_a_nested_unet_architecture_for_medical_image/,ZongweiZhou,1534529061,"&gt;Paper: [https://arxiv.org/abs/1807.10165](https://arxiv.org/abs/1807.10165)  
&gt;  
&gt;Code: [https://github.com/MrGiovanni/Nested-UNet](https://github.com/MrGiovanni/Nested-UNet)  
&gt;  
&gt;Publish in [4th Deep Learning in Medical Image Analysis (DLMIA) Workshop](https://cs.adelaide.edu.au/~dlmia4/)  
&gt;  
&gt;Contact: [zongweiz@asu.edu](mailto:zongweiz@asu.edu)

In this paper, we present UNet++, a new, more powerful architecture for medical image segmentation. Our architecture is essentially a deeply-supervised encoder-decoder network where the encoder and decoder sub-networks are connected through a series of nested, dense skip pathways. The re-designed skip pathways aim at reducing the semantic gap between the feature maps of the encoder and decoder sub-networks. We argue that the optimizer would deal with an easier learning task when the feature maps from the decoder and encoder networks are semantically similar. We have evaluated UNet++ in comparison with U-Net and wide U-Net architectures across multiple medical image segmentation tasks: nodule segmentation in the low-dose CT scans of chest, nuclei segmentation in the microscopy images, liver segmentation in abdominal CT scans, and polyp segmentation in colonoscopy videos. Our experiments demonstrate that UNet++ with deep supervision achieves an average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively.",0,1
874,2018-8-18,2018,8,18,4,9851ui,Organized Resources for Deep Learning Researchers and Developers,https://www.reddit.com/r/MachineLearning/comments/9851ui/organized_resources_for_deep_learning_researchers/,banguru,1534532876,,0,1
875,2018-8-18,2018,8,18,4,9858xb,[D] James Blackburn at All Your Base 2015 on Vimeo,https://www.reddit.com/r/MachineLearning/comments/9858xb/d_james_blackburn_at_all_your_base_2015_on_vimeo/,_quanttrader_,1534534294,,0,1
876,2018-8-18,2018,8,18,5,985tyo,Chat bot : confused to build chat bot intent (500 intents) classifier with less data (10 utterances for each intent) having lots of domain specific words.,https://www.reddit.com/r/MachineLearning/comments/985tyo/chat_bot_confused_to_build_chat_bot_intent_500/,raghavakotala,1534538538,[removed],0,1
877,2018-8-18,2018,8,18,6,98600w,"Machine Learning Basics, in Rust",https://www.reddit.com/r/MachineLearning/comments/98600w/machine_learning_basics_in_rust/,tsorn,1534539802,,1,1
878,2018-8-18,2018,8,18,6,98608u,[N] Pedro Domingos Will Lead New D.E. Shaw Machine Learning Group,https://www.reddit.com/r/MachineLearning/comments/98608u/n_pedro_domingos_will_lead_new_de_shaw_machine/,trcytony,1534539847,,0,1
879,2018-8-18,2018,8,18,6,9862q1,Specs for Deep RL,https://www.reddit.com/r/MachineLearning/comments/9862q1/specs_for_deep_rl/,bnakebnake,1534540375,[removed],0,1
880,2018-8-18,2018,8,18,6,9867mg,Brief question about dimensionality in layers in CNNs,https://www.reddit.com/r/MachineLearning/comments/9867mg/brief_question_about_dimensionality_in_layers_in/,Segfault_Inside,1534541464,[removed],0,1
881,2018-8-18,2018,8,18,6,986f0m,Books and Courses to Learn Tensorflow,https://www.reddit.com/r/MachineLearning/comments/986f0m/books_and_courses_to_learn_tensorflow/,hey_krish,1534543068,[removed],0,1
882,2018-8-18,2018,8,18,8,986y5l,[P] Distributed Gradient Descent for PyTorch,https://www.reddit.com/r/MachineLearning/comments/986y5l/p_distributed_gradient_descent_for_pytorch/,kingcai,1534547356,"Hey there!

I've been working withe a friend on a pytorch implementation of DownpourSGD, a distributed optimization algorithm. I ended up writing a blog post about our implementation and some problems we ran into along the way. It was a pretty interesting project to work on, would appreciate if y'all checked it out!

Post: https://jcaip.github.io/Distbelief/

Github: https://github.com/ucla-labx/distbelief",9,59
883,2018-8-18,2018,8,18,8,98773x,[D] GANsters invent all sorts of excuses not to measure likelihoods,https://www.reddit.com/r/MachineLearning/comments/98773x/d_gansters_invent_all_sorts_of_excuses_not_to/,wei_jok,1534549471,,39,52
884,2018-8-18,2018,8,18,9,987hiy,Why Keras if you have estimator and layers API?,https://www.reddit.com/r/MachineLearning/comments/987hiy/why_keras_if_you_have_estimator_and_layers_api/,rodrigo-silveira,1534551967,[removed],0,1
885,2018-8-18,2018,8,18,9,987j97,[D] Where do you work?,https://www.reddit.com/r/MachineLearning/comments/987j97/d_where_do_you_work/,ME_PhD,1534552397,"Just to get a feel - are you:

A) a graduate student

B) undergrad

C) consultant

D) work at a startup

E) work at a large company

F) in academia (post-doc, faculty etc.)

G) other?",34,13
886,2018-8-18,2018,8,18,11,9884p9,Using Multi-Layer Recurrent Neural Network for language models,https://www.reddit.com/r/MachineLearning/comments/9884p9/using_multilayer_recurrent_neural_network_for/,openjscience,1534557920,Example showing how to use RNN for text processing: [http://jwork.org/main/node/41](http://jwork.org/main/node/41),0,1
887,2018-8-18,2018,8,18,11,988et3,DCGAN - how do I know that it has converged?,https://www.reddit.com/r/MachineLearning/comments/988et3/dcgan_how_do_i_know_that_it_has_converged/,lppier,1534560468,[removed],0,1
888,2018-8-18,2018,8,18,11,988et8,Do most folks use NVIDIA GPU multi processors for writing software ?,https://www.reddit.com/r/MachineLearning/comments/988et8/do_most_folks_use_nvidia_gpu_multi_processors_for/,jayjay59,1534560469,,0,1
889,2018-8-18,2018,8,18,11,988gk3,[D] How to interpret the information/function encoded by the weights of a neural network in a mathematical and conceptual sense.,https://www.reddit.com/r/MachineLearning/comments/988gk3/d_how_to_interpret_the_informationfunction/,Morninglow,1534560909,"So I've done a few programming projects but now I'm thinking I don't understand what I am doing enough.  


What I want to know is what the weights are learning when I train a neural network, and how do I interpret and understand what is happening.  


My current understanding is that I am fitting a function to a high dimensional surface. 

How does the answer differ across shallow and deep vanilla nets, convolutional nets, recurrent nets, etc? What about across different tasks and loss / activation functions? ",12,20
890,2018-8-18,2018,8,18,13,988ze9,Is there a clear difference between modelling a problem with value function (Q) and successor representations in deep reinforcement leaning?,https://www.reddit.com/r/MachineLearning/comments/988ze9/is_there_a_clear_difference_between_modelling_a/,sha92g,1534566047,[removed],0,1
891,2018-8-18,2018,8,18,13,98908a,Understand Googles cutting-edge HDRnet in 10 minutes - tried writing an accessible explanation and would love some feedback!!,https://www.reddit.com/r/MachineLearning/comments/98908a/understand_googles_cuttingedge_hdrnet_in_10/,SuperSpy827,1534566269,,0,1
892,2018-8-18,2018,8,18,14,989a9z,Deep learning articles for time series data,https://www.reddit.com/r/MachineLearning/comments/989a9z/deep_learning_articles_for_time_series_data/,FckYouBill,1534569250,[removed],0,1
893,2018-8-18,2018,8,18,14,989ie5,Trying to Choose Machine Learning or Data Science Master's Program. How Much Does Reputation Matter?,https://www.reddit.com/r/MachineLearning/comments/989ie5/trying_to_choose_machine_learning_or_data_science/,blanketNTea,1534571849,"I'm trying to decide between Syracuse, John Hopkins, Lewis University, Southern Methodist University, and Regis University. There's a large difference between their costs \~28K - 61K. How much will it matter what their reputation is for getting a first time ML or DS job? How much will it matter in the long run? Are there any of these universities you would recommend or be cautious about?",0,1
894,2018-8-18,2018,8,18,15,989qmz,Creating jokes using ML?,https://www.reddit.com/r/MachineLearning/comments/989qmz/creating_jokes_using_ml/,OfferedJoggersDonuts,1534574577,Has anyone thought about this?,0,1
895,2018-8-18,2018,8,18,16,989ymb,If You Wanna Check Out Something Epic Click On This Link:,https://www.reddit.com/r/MachineLearning/comments/989ymb/if_you_wanna_check_out_something_epic_click_on/,proprpoovhj,1534577353,,0,1
896,2018-8-18,2018,8,18,16,989yr7,Maximum Likelihood Estimator(MLE),https://www.reddit.com/r/MachineLearning/comments/989yr7/maximum_likelihood_estimatormle/,saket0565,1534577397,[removed],0,1
897,2018-8-18,2018,8,18,17,98a4to,Analyzing a dataset using Python Pandas Library | Importing CSV files,https://www.reddit.com/r/MachineLearning/comments/98a4to/analyzing_a_dataset_using_python_pandas_library/,RichSecretary,1534579689,,0,1
898,2018-8-18,2018,8,18,17,98a6af,R Squared =0.64 for Multiple Linear Regression Model. Good fit?,https://www.reddit.com/r/MachineLearning/comments/98a6af/r_squared_064_for_multiple_linear_regression/,deeyaa,1534580215,[removed],0,1
899,2018-8-18,2018,8,18,18,98aj32,First Step To Machine Learning,https://www.reddit.com/r/MachineLearning/comments/98aj32/first_step_to_machine_learning/,Rushd1987,1534585103,[removed],0,1
900,2018-8-18,2018,8,18,19,98arbl,Know about the importance of Rotary Pumps for Espresso,https://www.reddit.com/r/MachineLearning/comments/98arbl/know_about_the_importance_of_rotary_pumps_for/,ambicamachinetools,1534588199,[removed],0,1
901,2018-8-18,2018,8,18,20,98b2wo,PDEs in ML vs ML to solve PDEs,https://www.reddit.com/r/MachineLearning/comments/98b2wo/pdes_in_ml_vs_ml_to_solve_pdes/,ThrowawayBrisvegas,1534592293,[removed],0,1
902,2018-8-18,2018,8,18,20,98b4mi,Rewriting Asimovs Laws of Robotics and Enslaving AI with Prof Joanna Bryson,https://www.reddit.com/r/MachineLearning/comments/98b4mi/rewriting_asimovs_laws_of_robotics_and_enslaving/,The_Syndicate_VC,1534592861,[removed],0,0
903,2018-8-18,2018,8,18,20,98b55n,Tips and Tricks for fine-tuning a Neural Network model,https://www.reddit.com/r/MachineLearning/comments/98b55n/tips_and_tricks_for_finetuning_a_neural_network/,perseus_14,1534593043,[removed],0,1
904,2018-8-18,2018,8,18,20,98b6jt,Scalable Machine Learning with Dask | SciPy 2018,https://www.reddit.com/r/MachineLearning/comments/98b6jt/scalable_machine_learning_with_dask_scipy_2018/,gabegm,1534593497,,0,1
905,2018-8-18,2018,8,18,22,98bk4l,[Discussion]What happens to EMNLP 2018?,https://www.reddit.com/r/MachineLearning/comments/98bk4l/discussionwhat_happens_to_emnlp_2018/,yhg0112,1534597710,"[http://emnlp2018.org/registration/](http://emnlp2018.org/registration/)

I'm planning to visit EMNLP 2018 this year, yet its registration have kept postponed to early August, and it has still not opened.

I'm not one of authors so the only way for get noticed is the official webpage linked above. 

Are they planning to open the registration in August? or did there something happened in EMNLP 2018?",1,12
906,2018-8-19,2018,8,19,0,98cej3,AI Is the FutureBut Where Are the Women?,https://www.reddit.com/r/MachineLearning/comments/98cej3/ai_is_the_futurebut_where_are_the_women/,multipliedby0,1534605478,,0,1
907,2018-8-19,2018,8,19,1,98cpu4,AI Weekly 18 August 2018,https://www.reddit.com/r/MachineLearning/comments/98cpu4/ai_weekly_18_august_2018/,TomekB,1534608130,,0,1
908,2018-8-19,2018,8,19,1,98cs4z,[P] TensorFlow.js video and blog series - Deep Learning in the Browser with JavaScript,https://www.reddit.com/r/MachineLearning/comments/98cs4z/p_tensorflowjs_video_and_blog_series_deep/,blackHoleDetector,1534608661,"- [Click here for the video series only](https://www.youtube.com/playlist?list=PLZbbT5o_s2xr83l8w44N_g3pygvajLrJ-)  
- [Click here for the blog and video series](http://deeplizard.com/learn/playlist/PLZbbT5o_s2xr83l8w44N_g3pygvajLrJ-)

In this series, we'll learn how to deploy and run models, along with full deep learning applications, in the browser! To implement this cool capability, well use TensorFlow.js (TFJS), TensorFlows JavaScript library, which allows us to build and access models in JavaScript. Topics include client-server deep learning architectures, converting Keras models to TFJS models, serving models with Node.js, building deep learning browser applications, tensor operations, and more!",8,116
909,2018-8-19,2018,8,19,1,98cxgf,"[D] True or False? ""Indeed. nips has devolved into a bunch of corporates with influx of outsiders who have no respect for research.""",https://www.reddit.com/r/MachineLearning/comments/98cxgf/d_true_or_false_indeed_nips_has_devolved_into_a/,InformalQuit,1534609866,"A colleague mentioned this quote and it has gotten be thinking; is there any truth to this? I don't have the experience to know what nips used to be, but has it changed substantially from what it was like in the past?",25,41
910,2018-8-19,2018,8,19,2,98dc2q,Ml and deep testing to solve text/natural language to sql problem,https://www.reddit.com/r/MachineLearning/comments/98dc2q/ml_and_deep_testing_to_solve_textnatural_language/,gauravbrills,1534613126,[removed],0,1
911,2018-8-19,2018,8,19,2,98df2k,[R] Online Adaptative Curriculum Learning for GANs,https://www.reddit.com/r/MachineLearning/comments/98df2k/r_online_adaptative_curriculum_learning_for_gans/,MediumInterview,1534613811,,1,6
912,2018-8-19,2018,8,19,3,98dw6h,Building a chatbot with Rasa,https://www.reddit.com/r/MachineLearning/comments/98dw6h/building_a_chatbot_with_rasa/,kiarash-irandoust,1534617609,,0,1
913,2018-8-19,2018,8,19,3,98dwpl,Hello machine learning people! I'm having some trouble trouble understanding the linear algebra behind closed form solutions to gradient vector cost functions. Does anyone have an intuitive way to think about it?,https://www.reddit.com/r/MachineLearning/comments/98dwpl/hello_machine_learning_people_im_having_some/,cam_man_can,1534617731,"I'm learning about cost functions for training models and I'm trying to understand a couple equations in particular. 

First there is the Normal Equation (theta) = (X^(T) \* X)^(-1) \* ^(X)T \* y. Where (theta) is the vector of parameters that minimize the cost function, X is the matrix of feature values, and y is the vector of target values.

 I've taken college linear algebra so I have a good idea of what each of those symbols mean, and if I had to compute it manually I know how to do the operations. I guess I'm just having a hard time getting an intuitive understanding of how this equation works.  

Then there is the closed form solution for ridge regression (theta) = (X^(T) \* X + (alpha)A^(T)^()-)1 \* ^(X)T \* y.  (alpha) is the regularization hyper-parameter, and A is the n x n identity matrix.

Anyone have a good explanation? Or can at least point me to a good resource?",0,1
914,2018-8-19,2018,8,19,3,98e1a3,Confused about studying machine learning,https://www.reddit.com/r/MachineLearning/comments/98e1a3/confused_about_studying_machine_learning/,Tj_Detweiler_,1534618743,"Hi all. I just graduated from my college as an electrical engineer and computer engineer and I am confused about my future. My thesis was about building a convolutional neural network to recognize musical instruments. Doing this, made me like a lot machine learning, I searched a lot and I liked the whole study area. Now that I have my degree, I was thinking to do a master in Europe (I am also from Europe). As I searched for machine learning masters I found that most masters related to machine learning, which seem good, are about data science. 

My question is: If I want to study more about machine learning and work as a machine learning engineer, is wise to take a data science master? Can anyone enlight me more about this? I am so confused about my future and I will apreciate every answer.",0,1
915,2018-8-19,2018,8,19,3,98e1d3,[P] Building a chatbot with Rasa,https://www.reddit.com/r/MachineLearning/comments/98e1d3/p_building_a_chatbot_with_rasa/,kiarash-irandoust,1534618764,,0,1
916,2018-8-19,2018,8,19,4,98e423,Confused about studying machine learning,https://www.reddit.com/r/MachineLearning/comments/98e423/confused_about_studying_machine_learning/,Tj_Detweiler_,1534619344,[removed],0,1
917,2018-8-19,2018,8,19,7,98fetm,"Simple(?) Interpretability Scenario : Train classifier on 2 images, output prediction on another; how to explain decision?",https://www.reddit.com/r/MachineLearning/comments/98fetm/simple_interpretability_scenario_train_classifier/,JamesWitten,1534630270,[removed],0,1
918,2018-8-19,2018,8,19,7,98fpbs,Hello serious question here.,https://www.reddit.com/r/MachineLearning/comments/98fpbs/hello_serious_question_here/,YouSuck225,1534632919,[removed],0,1
919,2018-8-19,2018,8,19,10,98gt0w,"A Freemind - mind map of all references in ""[D] If you had to show one paper ...""",https://www.reddit.com/r/MachineLearning/comments/98gt0w/a_freemind_mind_map_of_all_references_in_d_if_you/,jayjay59,1534643396,,4,3
920,2018-8-19,2018,8,19,11,98gw7s,[N] D.E. Shaw (some hedge fund..) forms new ML research group led by Pedro Domingos,https://www.reddit.com/r/MachineLearning/comments/98gw7s/n_de_shaw_some_hedge_fund_forms_new_ml_research/,baylearn,1534644187,,15,13
921,2018-8-19,2018,8,19,11,98h6vg,Build a Neural Network from scratch in Python,https://www.reddit.com/r/MachineLearning/comments/98h6vg/build_a_neural_network_from_scratch_in_python/,shamdasani,1534647125,,0,1
922,2018-8-19,2018,8,19,13,98hpy0,How to Write a Novel With Machine Learning | Ars Technica Video,https://www.reddit.com/r/MachineLearning/comments/98hpy0/how_to_write_a_novel_with_machine_learning_ars/,jayjay59,1534652572,,0,1
923,2018-8-19,2018,8,19,14,98hxuq,"[D] [Meta] The toxicity of this sub, discussed by ML researchers on Twitter",https://www.reddit.com/r/MachineLearning/comments/98hxuq/d_meta_the_toxicity_of_this_sub_discussed_by_ml/,kirasolo,1534654993,,223,64
924,2018-8-19,2018,8,19,14,98i1ks,One of the simplest and easy to understand K-Means article,https://www.reddit.com/r/MachineLearning/comments/98i1ks/one_of_the_simplest_and_easy_to_understand_kmeans/,rexlow0823,1534656130,[removed],0,1
925,2018-8-19,2018,8,19,15,98ichc,Sharing from Netflix data science team,https://www.reddit.com/r/MachineLearning/comments/98ichc/sharing_from_netflix_data_science_team/,hz265,1534660032,[removed],0,1
926,2018-8-19,2018,8,19,17,98iti5,Imbalance in data sets.,https://www.reddit.com/r/MachineLearning/comments/98iti5/imbalance_in_data_sets/,MrHktrioot,1534666565,[removed],0,1
927,2018-8-19,2018,8,19,17,98iyai,[D] confused about studying machine learning,https://www.reddit.com/r/MachineLearning/comments/98iyai/d_confused_about_studying_machine_learning/,Tj_Detweiler_,1534668556," Hi all

I just graduated from my college as an electrical engineer and computer engineer and I am confused about my future. My thesis was about building a convolutional neural network to recognize musical instruments.

Doing this, made me like a lot machine learning, I searched a lot and I liked the whole study area. Now that I have my degree, I was thinking to do a master in Europe (I am also from Europe). As I searched for machine learning masters I found that most masters related to machine learning, which seem good, are about data science.

My question is: If I want to study more about machine learning and work as a machine learning engineer, is wise to take a data science master? Can anyone enlight me more about this? I am so confused about my future and I will apreciate every answer.",7,5
928,2018-8-19,2018,8,19,19,98jcvh,Support Vector Machine in R - Explained with Example,https://www.reddit.com/r/MachineLearning/comments/98jcvh/support_vector_machine_in_r_explained_with_example/,pooja307,1534674428,,0,1
929,2018-8-19,2018,8,19,20,98jiuo,What is your choice of tool for processing file of about 10 gb in size?,https://www.reddit.com/r/MachineLearning/comments/98jiuo/what_is_your_choice_of_tool_for_processing_file/,sirkarthik,1534676797,,0,1
930,2018-8-19,2018,8,19,21,98k0r8,[R][bioinformatics] rawMSA: proper Deep Learning makes protein sequence profiles and feature extraction obsolete,https://www.reddit.com/r/MachineLearning/comments/98k0r8/rbioinformatics_rawmsa_proper_deep_learning_makes/,clauck,1534683084,,6,25
931,2018-8-19,2018,8,19,22,98k2kd,Classifying or training on a hash-table like dataset for medical application,https://www.reddit.com/r/MachineLearning/comments/98k2kd/classifying_or_training_on_a_hashtable_like/,edo6667,1534683660,[removed],0,1
932,2018-8-19,2018,8,19,22,98k3so,"What topics from Linear Algebra, Calculus, Probability, and Statistics are the most important for Machine Learning?",https://www.reddit.com/r/MachineLearning/comments/98k3so/what_topics_from_linear_algebra_calculus/,raymestalez,1534683992,[removed],0,1
933,2018-8-19,2018,8,19,22,98k455,"[D] What topics from Linear Algebra, Calculus, Probability, and Statistics are the most important for Machine Learning?",https://www.reddit.com/r/MachineLearning/comments/98k455/d_what_topics_from_linear_algebra_calculus/,raymestalez,1534684095,"I'm just beginning to learn Math for ML, with no background(other than high school). I see that Linear Algebra, Calculus, Probability, and Statistics are the most important areas I should be learning, but turns out these are pretty wide fields that can take years to master.

So I'm trying to make a curriculum of the most important subjects from each of these fields that I need to learn. By ""most important"" I mean most useful for applying ML on practice. Can you help me out?",12,46
934,2018-8-19,2018,8,19,22,98k4xn,Im finishing my undergraduate degree and want to pursue a career in ML without having taken any CS courses,https://www.reddit.com/r/MachineLearning/comments/98k4xn/im_finishing_my_undergraduate_degree_and_want_to/,PixarAnimationStudio,1534684319,[removed],0,1
935,2018-8-19,2018,8,19,23,98khdc,My first Object Detection Model - Yu-Gi-Oh Card Recognition,https://www.reddit.com/r/MachineLearning/comments/98khdc/my_first_object_detection_model_yugioh_card/,humanovan,1534687808,,0,1
936,2018-8-19,2018,8,19,23,98knn9,[HELP]How is this data an ill-posed problem &amp; how do you remedy it? (Assume row-wise instances),https://www.reddit.com/r/MachineLearning/comments/98knn9/helphow_is_this_data_an_illposed_problem_how_do/,freshprincemoali,1534689457,,0,1
937,2018-8-20,2018,8,20,0,98kwln,[Paper] Review of ZFNet The Winner of ILSVLC 2013 (Image Classification),https://www.reddit.com/r/MachineLearning/comments/98kwln/paper_review_of_zfnet_the_winner_of_ilsvlc_2013/,coinmonks,1534691594,,0,1
938,2018-8-20,2018,8,20,0,98kwww,Have there been any models or papers trying to solve P vs NP?,https://www.reddit.com/r/MachineLearning/comments/98kwww/have_there_been_any_models_or_papers_trying_to/,Arkhaya,1534691661,I'm trying to see if I can hope into trying to solve P Vs Np. My machine learning experience has been mostly data and image classification. So trying to solve an impossible challenge should be fun.,0,1
939,2018-8-20,2018,8,20,0,98l1ml,[R] Joint &amp; Progressive Learning from High-Dimensional Data for Multi-Label Classification,https://www.reddit.com/r/MachineLearning/comments/98l1ml/r_joint_progressive_learning_from_highdimensional/,MediumInterview,1534692787,,1,3
940,2018-8-20,2018,8,20,0,98l2vn,[D] How to Evaluate Nvidia's New Graphics Cards for ML?,https://www.reddit.com/r/MachineLearning/comments/98l2vn/d_how_to_evaluate_nvidias_new_graphics_cards_for/,tpapp157,1534693088,"A bunch of specs for Nvidia's new line of consumer graphics have leaked over the past week in the leadup to the official announcement tomorrow (8/20). Speculation and leaks seem to point to a performance improvement around 50% for the new 2000 series cards over their 1000 series counterparts but this is in a gaming context. How big of an improvement do you think these will represent for an ML workload?

2080 Ti / 1080 Ti

Cuda Cores: 4352 / 3584

2080 / 1080

Cuda Cores: 2944 / 2560

2070 / 1070

Cuda Cores: 2304 / 1920

That's about a 15-20% increase in Cuda Cores across the line. While amount of memory remains the same, the 2000 series features GDDR6 (14-16 Gb/s) vs the 1000 series GDDR5x (10-12 Gb/s). It's also expected the 2000 series to have Cuda Compute 7.X support vs 6.X for the 1000 series.",35,86
941,2018-8-20,2018,8,20,1,98lgvl,"Siraj Ravall = ""It's cool cuz it's neardy!""",https://www.reddit.com/r/MachineLearning/comments/98lgvl/siraj_ravall_its_cool_cuz_its_neardy/,viniciusbr93,1534696298,[removed],0,1
942,2018-8-20,2018,8,20,1,98lo0t,[R] Neural Importance Sampling,https://www.reddit.com/r/MachineLearning/comments/98lo0t/r_neural_importance_sampling/,fng185,1534697880,,1,12
943,2018-8-20,2018,8,20,2,98lpq6,Building RNNs is Fun with PyTorch and Google Colab,https://www.reddit.com/r/MachineLearning/comments/98lpq6/building_rnns_is_fun_with_pytorch_and_google_colab/,omarsar,1534698237,,0,1
944,2018-8-20,2018,8,20,2,98ly5k,"1 million classes, need to learn ""is x member of class Y""",https://www.reddit.com/r/MachineLearning/comments/98ly5k/1_million_classes_need_to_learn_is_x_member_of/,ML_noob92,1534700071,[removed],0,1
945,2018-8-20,2018,8,20,3,98m7yu,How to integrate my ML model in my Android/iOS application?,https://www.reddit.com/r/MachineLearning/comments/98m7yu/how_to_integrate_my_ml_model_in_my_androidios/,ank_itsharma,1534702167,[removed],0,1
946,2018-8-20,2018,8,20,3,98mdvc,Do papers use mathematical notations to induce a sense of expertise and complexity ?,https://www.reddit.com/r/MachineLearning/comments/98mdvc/do_papers_use_mathematical_notations_to_induce_a/,elcric_krej,1534703406,[removed],32,0
947,2018-8-20,2018,8,20,4,98my7f,"[D] Analyzing location, speed and traffic data to determine optimal car speed for every road",https://www.reddit.com/r/MachineLearning/comments/98my7f/d_analyzing_location_speed_and_traffic_data_to/,izybit,1534707807,"Was watching earlier a video ([link](https://www.youtube.com/watch?v=jOPYpD1Knpw)) of a Tesla on Autopilot drive for almost 20 minutes on some winding roads and doing a pretty good job.

One of the problems though was that its speed wasn't always optimal and often times it was taking some pretty tight turns or turns with poor visibility at full speed.

We know that Tesla is building maps for their Autopilot suite so the car can have an internal knowledge of the environment and these maps have (among other things) hardcoded speed limits for turns or certain sections of the road but I don't really know how Tesla or the whole industry in general determines the optimal speed the system should be aiming for (if they even do that and Tesla isn't just doing it till their software gets better at reading the road/environment).

While watching the video I was thinking that if cars were logging the location (GPS data), speed and traffic data for every road they are being driven on (Tesla, Mobileye and possibly others can already do this) then given enough data one could easily determine the optimal speed for every single stretch of road and particularly the speed before, during and after a curve, hill or other difficult/dangerous spot.

If you know how they do it, if they do it at all, please let me know.",44,16
948,2018-8-20,2018,8,20,5,98n2rt,[D] Machine Learning - WAYR (What Are You Reading) - Week 49,https://www.reddit.com/r/MachineLearning/comments/98n2rt/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1534708806,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)||

Most upvoted papers two weeks ago:

/u/shortscience_dot_org: [Summary by author /u/SirJAM_armedi]()

/u/shortscience_dot_org: [Summary by author /u/SirJAM_armedi]()

Besides that, there are no rules, have fun.",17,45
949,2018-8-20,2018,8,20,7,98o8x6,What are some of the techniques to make text classification models learn automatically from human feedback?,https://www.reddit.com/r/MachineLearning/comments/98o8x6/what_are_some_of_the_techniques_to_make_text/,frittaa454,1534718136,[removed],0,1
950,2018-8-20,2018,8,20,7,98obk5,"What are some of the techniques to make text classification models ""self-learn"" from human feedback?",https://www.reddit.com/r/MachineLearning/comments/98obk5/what_are_some_of_the_techniques_to_make_text/,frittaa454,1534718739,"Unfortunately, many business people believe that a machine learning system in production will somehow learn automatically when provided with human feedback. In some ways, they are not wrong having been used to marking spam and watching those emails get automatically classified as spam.

However, I am trying to understand how we can teach a supervised text classification model (Sentiment Analysis, in my case) automatically as and when new data is generated? Currently, we are waiting for sufficient number of samples to be collected and manually train the entire architecture from scratch. This does result in improved accuracy but does not work for us since our customers do not want to pay us for this additional effort and need a solution that self-learns.

Does anyone of you have an experience where we can iteratively train a text classification model on new set of data by setting up a cron job? How does one account for variability in the new data (i.e. whether new data belongs to the same distribution) and does the same hyperparameters work always even when new data is added to an existing model?",0,1
951,2018-8-20,2018,8,20,7,98oda8,Gibbs Distribution for a MRF/CRF - Doubt,https://www.reddit.com/r/MachineLearning/comments/98oda8/gibbs_distribution_for_a_mrfcrf_doubt/,WillingCucumber,1534719142,[removed],0,1
952,2018-8-20,2018,8,20,7,98oesr,"[D] What are some of the techniques to make text classification models ""self-learn"" from human feedback?",https://www.reddit.com/r/MachineLearning/comments/98oesr/d_what_are_some_of_the_techniques_to_make_text/,frittaa454,1534719493,"Unfortunately, many business people believe that a machine learning system in production will somehow learn automatically when provided with human feedback. In some ways, they are not wrong having been used to marking spam and watching those emails get automatically classified as spam.

However, I am trying to understand how we can teach a supervised text classification model (Sentiment Analysis, in my case) automatically as and when new data is generated? Currently, we are waiting for sufficient number of samples to be collected and manually train the entire architecture from scratch. This does result in improved accuracy but does not work for us since our customers do not want to pay us for this additional effort and need a solution that self-learns.

Does anyone of you have an experience where we can iteratively train a text classification model on new set of data by setting up a cron job? How does one account for variability in the new data (i.e. whether new data belongs to the same distribution) and does the same hyperparameters work always even when new data is added to an existing model?",12,38
953,2018-8-20,2018,8,20,8,98ojis,How to compare the training performance of a deep learning model on different data sets?,https://www.reddit.com/r/MachineLearning/comments/98ojis/how_to_compare_the_training_performance_of_a_deep/,turing_maan,1534720599,[removed],0,1
954,2018-8-20,2018,8,20,10,98p9fr,Best python package for (scalable) Gaussian Process,https://www.reddit.com/r/MachineLearning/comments/98p9fr/best_python_package_for_scalable_gaussian_process/,wannabe_markov_state,1534726887,[removed],0,2
955,2018-8-20,2018,8,20,10,98pldy,[R] From Autoencoder to Beta-VAE,https://www.reddit.com/r/MachineLearning/comments/98pldy/r_from_autoencoder_to_betavae/,downtownslim,1534729858,,43,94
956,2018-8-20,2018,8,20,12,98q95o,Advice on How to Match Employees,https://www.reddit.com/r/MachineLearning/comments/98q95o/advice_on_how_to_match_employees/,jemiller1963,1534735801,"I'm a ruby on rails developer researching how to create a model with TensorFlow and call it from a web based application. My objective is to match employees with similar skills.  We have a database of our employees. The employees have attributes that describe their skills based on a rating from 1-5, their location, and some other information.  I'd like to use TensorFlow to match employees by skills. I have a basic knowledge of machine learning and am currently learning how to use TensorFlow. I'd like to ask for advice on which libraries would be best to use and any advice on the logic to use to set up a model that could solve my problems.

Thanks in advance!",0,1
957,2018-8-20,2018,8,20,13,98qiur,rlsl: Reinforcement Learning for Skip Lists,https://www.reddit.com/r/MachineLearning/comments/98qiur/rlsl_reinforcement_learning_for_skip_lists/,corestar,1534738533,[removed],0,1
958,2018-8-20,2018,8,20,14,98qrxi,[Research][IJCAI '18] An ensemble approach for multimodal image generation within GANs,https://www.reddit.com/r/MachineLearning/comments/98qrxi/researchijcai_18_an_ensemble_approach_for/,heykeetae,1534741230,,1,4
959,2018-8-20,2018,8,20,15,98r3q5,[R] MCRM: Mother Compact Recurrent Memory,https://www.reddit.com/r/MachineLearning/comments/98r3q5/r_mcrm_mother_compact_recurrent_memory/,AbduallahM,1534744812,"[https://arxiv.org/abs/1808.02016](https://arxiv.org/abs/1808.02016)

[MCRM cell state inherits both LSTM and GRU behaviors into a compact memory pattern](https://i.redd.it/9yrfe95ou6h11.png)",1,1
960,2018-8-20,2018,8,20,15,98rcul,"[D] ""I made similar experiences with reddit /ML. I no longer pay any attention to what is going on there, because it is just biased non-sense and Trump-style arguments...""",https://www.reddit.com/r/MachineLearning/comments/98rcul/d_i_made_similar_experiences_with_reddit_ml_i_no/,azn_racoon,1534747727,,11,0
961,2018-8-20,2018,8,20,16,98rf8c,Deep learning really ???????,https://www.reddit.com/r/MachineLearning/comments/98rf8c/deep_learning_really/,Humble_Transition,1534748465,[removed],0,1
962,2018-8-20,2018,8,20,16,98rk8e,Parallel pandas DataFrame.apply() suggestion,https://www.reddit.com/r/MachineLearning/comments/98rk8e/parallel_pandas_dataframeapply_suggestion/,Alfred456654,1534750096,[removed],0,1
963,2018-8-20,2018,8,20,16,98rltc,India International Textile Machinery Exhibition 2016 | Dynamic Looms,https://www.reddit.com/r/MachineLearning/comments/98rltc/india_international_textile_machinery_exhibition/,closestbuddies,1534750590,,0,1
964,2018-8-20,2018,8,20,17,98rui2,Fluid Bed Dryer Lab Model | Chitra Machineries | Pharmaceuticals Industries | Food Industries | Cosmetic Industries,https://www.reddit.com/r/MachineLearning/comments/98rui2/fluid_bed_dryer_lab_model_chitra_machineries/,closestbuddies,1534753599,,0,1
965,2018-8-20,2018,8,20,17,98rzr7,Reinforcement Learning and generative models in Pytorch,https://www.reddit.com/r/MachineLearning/comments/98rzr7/reinforcement_learning_and_generative_models_in/,Teenvan1995,1534755540,[removed],0,1
966,2018-8-20,2018,8,20,18,98s9pj,"[D] How to use additional data, such as gender and age, for sentiment analysis of textual data in a neural network?",https://www.reddit.com/r/MachineLearning/comments/98s9pj/d_how_to_use_additional_data_such_as_gender_and/,jbr1245,1534758877,"For a test case, I am trying to perform sentiment analysis in tensorflow. It got me thinking. Women and men might express themselves in different ways and young people are probably more likely to rely on emoticons. Therefore, would it be possible to combine word embeddings, LSTM/convolution layers with additional information such as gender and age?

I am thinking about an approach, described in this [blog ](http://konukoii.com/blog/2018/02/19/twitter-sentiment-analysis-using-combined-lstm-cnn-models/)but then to use these additional factors seperate branch of the network (e.g., using some fully connected layers) and concatenate this layer to the max pooling layer, such that both the output from the word embeddings as well as age and gender are included.

Would this be a good place to start? Does anyone know some literature on this or similar topics?",4,1
967,2018-8-20,2018,8,20,18,98sa40,"[D] Do you use commercial business software to keep track of predictive models, or have you built your own system?",https://www.reddit.com/r/MachineLearning/comments/98sa40/d_do_you_use_commercial_business_software_to_keep/,Tullsokk,1534759005,,2,0
968,2018-8-20,2018,8,20,19,98saxw,Hi-res Image Dataset,https://www.reddit.com/r/MachineLearning/comments/98saxw/hires_image_dataset/,deepKrish,1534759271,[removed],0,1
969,2018-8-20,2018,8,20,19,98scpb,Complete Guide to Mathematical Foundation For Machine Learning and AI,https://www.reddit.com/r/MachineLearning/comments/98scpb/complete_guide_to_mathematical_foundation_for/,KiranKiller,1534759825,,0,1
970,2018-8-20,2018,8,20,19,98shln,AI Servers,https://www.reddit.com/r/MachineLearning/comments/98shln/ai_servers/,Yorzic,1534761388,[removed],0,1
971,2018-8-20,2018,8,20,20,98sr5w,[N] Face detection - An overview and comparison of different solutions,https://www.reddit.com/r/MachineLearning/comments/98sr5w/n_face_detection_an_overview_and_comparison_of/,stdiozh,1534764247,,8,47
972,2018-8-20,2018,8,20,20,98srt0,Building a chatbot with Rasa,https://www.reddit.com/r/MachineLearning/comments/98srt0/building_a_chatbot_with_rasa/,Fewthp,1534764421,,0,1
973,2018-8-20,2018,8,20,21,98t2a9,"Two interesting papers, Attention Is All You Need, but CNNs and RNNs help.",https://www.reddit.com/r/MachineLearning/comments/98t2a9/two_interesting_papers_attention_is_all_you_need/,vector_machines,1534767287,,0,1
974,2018-8-20,2018,8,20,21,98t8v7,Model-Based Machine Learning: an online book by John Winn and Christopher Bishop with Thomas Diethe,https://www.reddit.com/r/MachineLearning/comments/98t8v7/modelbased_machine_learning_an_online_book_by/,banksyb00mb00m,1534768992,,0,1
975,2018-8-20,2018,8,20,21,98t9qi,"New NLP News: Learning Meaning in NLP, Recurrence in NNs, Q&amp;A with Yoshua Bengio, ML == pseudo science?, ImageNet &lt; 18mins, Where's Waldo?, Frontiers of NLP",https://www.reddit.com/r/MachineLearning/comments/98t9qi/new_nlp_news_learning_meaning_in_nlp_recurrence/,vector_machines,1534769208,,0,1
976,2018-8-20,2018,8,20,21,98taor,Unpooling layer in Keras with TensorFlow backend?,https://www.reddit.com/r/MachineLearning/comments/98taor/unpooling_layer_in_keras_with_tensorflow_backend/,hazybluez,1534769438,[removed],0,1
977,2018-8-20,2018,8,20,22,98tj6e,Which Skills Are Required for Machine Learning Jobs?,https://www.reddit.com/r/MachineLearning/comments/98tj6e/which_skills_are_required_for_machine_learning/,imarticus_nirmal,1534771341,,0,1
978,2018-8-20,2018,8,20,22,98tou0,What is The Easiest Way To Learn Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/98tou0/what_is_the_easiest_way_to_learn_machine_learning/,imarticus_nirmal,1534772658,,0,1
979,2018-8-20,2018,8,20,22,98tsia,"Simple weighted-average sentence vectors get SOTA on sentence similarity tasks (Best Paper, Repl4NLP @ ACL 2018)",https://www.reddit.com/r/MachineLearning/comments/98tsia/simple_weightedaverage_sentence_vectors_get_sota/,HipsterToofer,1534773497,,0,1
980,2018-8-20,2018,8,20,23,98tumd,How older aged devs outpace their peers and should get respect,https://www.reddit.com/r/MachineLearning/comments/98tumd/how_older_aged_devs_outpace_their_peers_and/,programming-innovate,1534773935,[removed],0,1
981,2018-8-20,2018,8,20,23,98twby,How to Start a Career in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/98twby/how_to_start_a_career_in_machine_learning/,imarticus_nirmal,1534774264,,0,1
982,2018-8-20,2018,8,20,23,98u445,How to crowd-source the maintenance of a cooking and kitchen manipulation dataset overview,https://www.reddit.com/r/MachineLearning/comments/98u445/how_to_crowdsource_the_maintenance_of_a_cooking/,whiletrue2,1534775820,[removed],0,1
983,2018-8-20,2018,8,20,23,98u79u,Cooking and Kitchen Manipulation Dataset Overview / Comparison,https://www.reddit.com/r/MachineLearning/comments/98u79u/cooking_and_kitchen_manipulation_dataset_overview/,whiletrue2,1534776426,,0,1
984,2018-8-21,2018,8,21,0,98uhk4,"SWAG Q/A Dataset, PolygonRNN++, Deep Learning in NLP, Diagnosing Retinal Disease, Pix2Pix on the Browser, AutoKeras,",https://www.reddit.com/r/MachineLearning/comments/98uhk4/swag_qa_dataset_polygonrnn_deep_learning_in_nlp/,omarsar,1534778363,,0,1
985,2018-8-21,2018,8,21,0,98ulq8,"Video-to-Video Synthesis from NVIDIA, with code [R]",https://www.reddit.com/r/MachineLearning/comments/98ulq8/videotovideo_synthesis_from_nvidia_with_code_r/,larseidnes,1534779157,,71,527
986,2018-8-21,2018,8,21,0,98unzy,[D] How do you store your training data?,https://www.reddit.com/r/MachineLearning/comments/98unzy/d_how_do_you_store_your_training_data/,rstoj,1534779612,,0,1
987,2018-8-21,2018,8,21,0,98uo81,[D] Poll: How do you store your training data?,https://www.reddit.com/r/MachineLearning/comments/98uo81/d_poll_how_do_you_store_your_training_data/,rstoj,1534779660,,16,10
988,2018-8-21,2018,8,21,0,98uqjw,What services/platforms exist for natural language generation (NLG) to produce written blurbs based on spreadsheet data? Open-source or commercial.,https://www.reddit.com/r/MachineLearning/comments/98uqjw/what_servicesplatforms_exist_for_natural_language/,TheBraveProtonDuck,1534780125,"Looking for a tool that can output simple sentences based on data in a spreadsheet - grabbing stats from structured data and converting them to human readable narratives.

I've found Automated Insights and their Wordsmith product ([https://automatedinsights.com/wordsmith/](https://automatedinsights.com/wordsmith/)), and Narrative Science ([https://narrativescience.com](https://narrativescience.com)). Their solutions both appear aimed at enterprise (and probably come with an enterprise price tag). 

Is anyone doing this closer to entry-level? Maybe aimed at consumers or small businesses?

If not, are there open-source tools that accomplish this?",0,1
989,2018-8-21,2018,8,21,0,98ur2e,Are you getting the most out of your GPU cluster?,https://www.reddit.com/r/MachineLearning/comments/98ur2e/are_you_getting_the_most_out_of_your_gpu_cluster/,yoavz,1534780235,,0,1
990,2018-8-21,2018,8,21,1,98ux01,Derivation in Thomas Mitchell's book.,https://www.reddit.com/r/MachineLearning/comments/98ux01/derivation_in_thomas_mitchells_book/,Andy_Reds,1534781370,[removed],0,1
991,2018-8-21,2018,8,21,1,98uzs5,awesome-twitter-data: A list of Twitter datasets and related resources.,https://www.reddit.com/r/MachineLearning/comments/98uzs5/awesometwitterdata_a_list_of_twitter_datasets_and/,shaypal5,1534781896,,0,1
992,2018-8-21,2018,8,21,1,98v4dj,"[D] I worked on credit card fraud detection data and I achieved almost 99.9% accuracy using SVM and Random Forest. I don't know if it's correct or faulty, I want reviews or if I had missed something.",https://www.reddit.com/r/MachineLearning/comments/98v4dj/d_i_worked_on_credit_card_fraud_detection_data/,Kunalvats0,1534782806,"[Github repo of my IPython notebook](https://github.com/roh2020/Credit-card-fraud-detection-/blob/master/credit%20card%20fraud%20detection.ipynb)

Thanks, though.",16,14
993,2018-8-21,2018,8,21,2,98vo4o,[N] Face detection - An overview and comparison of different solutions,https://www.reddit.com/r/MachineLearning/comments/98vo4o/n_face_detection_an_overview_and_comparison_of/,dpacassi,1534786592,,2,8
994,2018-8-21,2018,8,21,3,98vwlo,Group Travel Problem and optimization with Hill Climbing Approach,https://www.reddit.com/r/MachineLearning/comments/98vwlo/group_travel_problem_and_optimization_with_hill/,coolnikhilj22,1534788196,[http://www.dotnetlovers.com/article/205/group-travel-problem-and-optimization-with-hill-climbing-approach](http://www.dotnetlovers.com/article/205/group-travel-problem-and-optimization-with-hill-climbing-approach),0,1
995,2018-8-21,2018,8,21,3,98w3lm,"Looking for the b/w (art) short film, where a Scientist trains a neural net with world data ... and on the end the have to switch it of (and go for a drink)",https://www.reddit.com/r/MachineLearning/comments/98w3lm/looking_for_the_bw_art_short_film_where_a/,meta96,1534789520,[removed],1,1
996,2018-8-21,2018,8,21,3,98w9kt,Anyone have experience with Precision-Recall Gain curves? Confused about the relationship between AUC and the expected F-gain score.,https://www.reddit.com/r/MachineLearning/comments/98w9kt/anyone_have_experience_with_precisionrecall_gain/,IKSSE3,1534790669,[removed],0,1
997,2018-8-21,2018,8,21,4,98wezx,How Wikipedia is using AI to identify and eliminate sources of hostile commentary while improving editing,https://www.reddit.com/r/MachineLearning/comments/98wezx/how_wikipedia_is_using_ai_to_identify_and/,jonfla,1534791710,,0,1
998,2018-8-21,2018,8,21,4,98wm2y,Twitter suggestions for ML,https://www.reddit.com/r/MachineLearning/comments/98wm2y/twitter_suggestions_for_ml/,yazriel0,1534793056,[removed],0,1
999,2018-8-21,2018,8,21,4,98wrkw,Illustrated Machine Learning cheatsheets covering Stanford's CS 229 class,https://www.reddit.com/r/MachineLearning/comments/98wrkw/illustrated_machine_learning_cheatsheets_covering/,shervinea,1534794142,[removed],17,535
1000,2018-8-21,2018,8,21,4,98ww1m,Is it a good idea to train a Neural Network on continiously randomly generated training data?,https://www.reddit.com/r/MachineLearning/comments/98ww1m/is_it_a_good_idea_to_train_a_neural_network_on/,ronsap123,1534795003,[removed],0,1
1001,2018-8-21,2018,8,21,5,98x7hf,"[R] Survey: Current Practices, Challenges, and Needs for Support around Fair AI and Machine Learning",https://www.reddit.com/r/MachineLearning/comments/98x7hf/r_survey_current_practices_challenges_and_needs/,FamousNumber5,1534797172,,0,0
1002,2018-8-21,2018,8,21,6,98xhpo,Recommended deep learning resources?,https://www.reddit.com/r/MachineLearning/comments/98xhpo/recommended_deep_learning_resources/,falconberger,1534799269,[removed],0,1
1003,2018-8-21,2018,8,21,6,98xn8k,[HELP]Sometimes Neural Network doesn't learn properly,https://www.reddit.com/r/MachineLearning/comments/98xn8k/helpsometimes_neural_network_doesnt_learn_properly/,Jadw1,1534800389,[removed],1,1
1004,2018-8-21,2018,8,21,6,98xwmt,"[D] ICML+ACL'18: Structure Back in Play, Translation Wants More Context",https://www.reddit.com/r/MachineLearning/comments/98xwmt/d_icmlacl18_structure_back_in_play_translation/,ofirpress,1534802313,,0,1
1005,2018-8-21,2018,8,21,7,98yaml,[N] OpenAI Five will be playing against five top Dota 2 professionals at The International on Wednesday,https://www.reddit.com/r/MachineLearning/comments/98yaml/n_openai_five_will_be_playing_against_five_top/,MediumInterview,1534805247,,25,91
1006,2018-8-21,2018,8,21,7,98ybeh,[D] Unobserved Heterogeneity in Neural Networks,https://www.reddit.com/r/MachineLearning/comments/98ybeh/d_unobserved_heterogeneity_in_neural_networks/,amstell,1534805411,"
Using panel data, a simple OLS specification can control for unobserved heterogeneity by simply using dummy variables for the group (such as state), or demean the data by each group (within group estimator). However, I'm not sure how to do this with neural networks (NN).

I have compared RMSE for a simple OLS with fixed effects and a NN by demeaning values. The in-sample RMSE for NN (0.14) beats the OLS (0.19) RMSE, but when cross-validating the out-of-sample RMSE is higher for NN (0.21) than OLS (0.17). My guess is demeaning values in NN is not appropriate and is why my out-of-sample predictions are not very good.

So my question is: How do you control for unobserved heterogeneity in Neural Networks (NN)?

",1,1
1007,2018-8-21,2018,8,21,9,98yscc,Artificial intelligence is now directly controlling cooling at Google data centers [DeepMind],https://www.reddit.com/r/MachineLearning/comments/98yscc/artificial_intelligence_is_now_directly/,MattyBv3,1534812382,,0,1
1008,2018-8-21,2018,8,21,10,98z0ag,A conversation with MIT Prof. Gilbert Strang at JuliaCon 2018,https://www.reddit.com/r/MachineLearning/comments/98z0ag/a_conversation_with_mit_prof_gilbert_strang_at/,ViralBShah,1534815987,,0,1
1009,2018-8-21,2018,8,21,11,98z713,[P] IBM RXN Chemistry: using neural networks to predict organic chemical reactions,https://www.reddit.com/r/MachineLearning/comments/98z713/p_ibm_rxn_chemistry_using_neural_networks_to/,dominiquec,1534818007,,3,26
1010,2018-8-21,2018,8,21,11,98z76q,Using neural network to identify pets,https://www.reddit.com/r/MachineLearning/comments/98z76q/using_neural_network_to_identify_pets/,honghuac,1534818041,,0,1
1011,2018-8-21,2018,8,21,11,98zbvu,[R] [1808.06508] Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies [DeepMind],https://www.reddit.com/r/MachineLearning/comments/98zbvu/r_180806508_lifelong_disentangled_representation/,evc123,1534818995,,11,24
1012,2018-8-21,2018,8,21,11,98zclu,Guarantees for GP hyperparameters optimized using brute-force mini-batch ?,https://www.reddit.com/r/MachineLearning/comments/98zclu/guarantees_for_gp_hyperparameters_optimized_using/,ssydasheng,1534819141,[removed],0,1
1013,2018-8-21,2018,8,21,11,98ze54,TDLS: Large-Scale Unsupervised Deep Representation Learning for Brain Structure (https://arxiv.org/abs/1805.01049),https://www.reddit.com/r/MachineLearning/comments/98ze54/tdls_largescale_unsupervised_deep_representation/,machinetrainer,1534819457,,0,1
1014,2018-8-21,2018,8,21,13,9902bz,[D] Is machine learning research stuck near a local maxima?,https://www.reddit.com/r/MachineLearning/comments/9902bz/d_is_machine_learning_research_stuck_near_a_local/,stringy_pants,1534825142,"There was an exuberant feeling around 2012-2014 that the hard problems of intelligence could really be solved by deep learning. Right now it seems like we're back to grinding on benchmarks and hacking on tweaks and tricks, not new paradigms. Reward engineering has become the new feature engineering. ML models still don't learn to do anything remotely sentient compared to humans, they make silly mistakes and are very brittle.

Is the expansion of narrow AI a step towards general AI, or have we jumped out of one local maxima into another?",31,34
1015,2018-8-21,2018,8,21,13,9906jd,"Real-Time Ray Tracing + Turing Architecture yet Digital Trends says Nvidias new GPUs look amazing, but that doesnt mean you should buy one",https://www.reddit.com/r/MachineLearning/comments/9906jd/realtime_ray_tracing_turing_architecture_yet/,MattyBv3,1534826245,,0,1
1016,2018-8-21,2018,8,21,14,990cln,Complex Valued Inputs to DNN's,https://www.reddit.com/r/MachineLearning/comments/990cln/complex_valued_inputs_to_dnns/,deep_learning_algo,1534827889,[removed],0,1
1017,2018-8-21,2018,8,21,14,990i9x,"If you use Python for Data Science and ML, but haven't heard of or not used Anaconda, watch this video and thank me later",https://www.reddit.com/r/MachineLearning/comments/990i9x/if_you_use_python_for_data_science_and_ml_but/,Additional_Proof,1534829506,,0,1
1018,2018-8-21,2018,8,21,14,990jw1,Distributed machine learning is now easy,https://www.reddit.com/r/MachineLearning/comments/990jw1/distributed_machine_learning_is_now_easy/,clusterone02,1534829983,,1,1
1019,2018-8-21,2018,8,21,15,990vng,[Research][arxiv] PAC-learning is Undecidable,https://www.reddit.com/r/MachineLearning/comments/990vng/researcharxiv_paclearning_is_undecidable/,sairaamv92,1534833649,"Abstract:

The problem of attempting to learn the mapping between data and labels is the crux of any machine learning task. It is, therefore, of interest to the machine learning community on practical as well as theoretical counts to consider the existence of a test or criterion for deciding the feasibility of attempting to learn. We investigate the existence of such a criterion in the setting of PAC-learning, basing the feasibility solely on whether the mapping to be learnt lends itself to approximation by a given class of hypothesis functions. We show that no such criterion exists, exposing a fundamental limitation in the decidability of learning. In other words, we prove that testing for PAC-learnability is undecidable in the Turing sense. We also briefly discuss some of the probable implications of this result to the current practice of machine learning.",6,11
1020,2018-8-21,2018,8,21,16,991488,The Unified Theory of Everything: A Solution for Huge Data,https://www.reddit.com/r/MachineLearning/comments/991488/the_unified_theory_of_everything_a_solution_for/,amberstevens311,1534836408,[removed],0,1
1021,2018-8-21,2018,8,21,16,9916z9,How AI and Machine Learning Will Boost Your Printing Business,https://www.reddit.com/r/MachineLearning/comments/9916z9/how_ai_and_machine_learning_will_boost_your/,idesignibuy,1534837318,,0,1
1022,2018-8-21,2018,8,21,17,991alx,New Artificial Intelligence Model Provides Smart Solution to Water Logging in Indian Cities,https://www.reddit.com/r/MachineLearning/comments/991alx/new_artificial_intelligence_model_provides_smart/,dexlabanalytics,1534838559,,0,1
1023,2018-8-21,2018,8,21,17,991cu0,How to Tell if your Bot is Smart Enough?,https://www.reddit.com/r/MachineLearning/comments/991cu0/how_to_tell_if_your_bot_is_smart_enough/,amberstevens311,1534839288,[removed],0,1
1024,2018-8-21,2018,8,21,17,991es5,Filtering spam and classify text using Naive Bayes Classifier,https://www.reddit.com/r/MachineLearning/comments/991es5/filtering_spam_and_classify_text_using_naive/,coolnikhilj22,1534839982,[removed],0,1
1025,2018-8-21,2018,8,21,17,991exp,7 Myths About Bots Most People Get Completely Wrong,https://www.reddit.com/r/MachineLearning/comments/991exp/7_myths_about_bots_most_people_get_completely/,amberstevens311,1534840044,[removed],0,1
1026,2018-8-21,2018,8,21,17,991fx0,[P] PyTorch implementation of DeepMind's Relational Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/991fx0/p_pytorch_implementation_of_deepminds_relational/,L0SG,1534840400,,4,21
1027,2018-8-21,2018,8,21,18,991mjc,[D] Is depth estimation from focus dead?,https://www.reddit.com/r/MachineLearning/comments/991mjc/d_is_depth_estimation_from_focus_dead/,hapliniste,1534842619,"Hi, I was thinking about doing depth estimation using multiples similar photos but using different focus for each. Maybe even do it as a RL task on mobile devices.

I never heard of it and now that I look at it, there's some research on it like [this one (Deep Depth From Focus)](file:///E:/Users/Alexandre/Downloads/0696.pdf).

Is this not a good idea? The paper I linked seems to work quite well so why isn't it more talked about, especially when depth estimation and scene mapping is a hot topic?

Is this impractical?

I fell like it would be a good option in mobile depth estimation and could be used in conjunction with SLAM methods to extract a scene from a serie of images, but it seems no one uses it.

I'll maybe try to make a simple Blender script that render multiple focal length and train a DNN on it, but it could be interesting to let the network choose how to change the focal lenght as it needs (as the goal would be to run it real-time on mobile devices).

Would love to hear what you think about it.",5,3
1028,2018-8-21,2018,8,21,18,991n0x,Tensorflow Implementation of NALU,https://www.reddit.com/r/MachineLearning/comments/991n0x/tensorflow_implementation_of_nalu/,Ragabov,1534842775,[removed],0,1
1029,2018-8-21,2018,8,21,18,991o57,[Discussion] Since when did the community drop image normalization,https://www.reddit.com/r/MachineLearning/comments/991o57/discussion_since_when_did_the_community_drop/,swagrin,1534843129,"I've been disconnected from the recent couple of years in image classification progress. From what I can tell plenty of papers (e.g. Inception v4, Mobile Net) seem to skip preprocessing techniques like image normalization and mean value subtraction (e.g. the original ResNet).

When did these techniques fall out of favor and what was the motivation? I see arguments along the lines of ""it probably doesn't matter much since we do batch/layer/instance/x-normalization anyway"", but I haven't been able to find results showing this is the case. Thoughts, arguments and references to papers arguing this convincingly would be highly appreciated.",16,32
1030,2018-8-21,2018,8,21,18,991vab,"Delmer - eWeighing, Jewellery Machinery &amp; Milking Automation",https://www.reddit.com/r/MachineLearning/comments/991vab/delmer_eweighing_jewellery_machinery_milking/,BorismA111,1534845453,"The [Delmer Group](http://www.delmer.in/Eweighing.php) is a globally known and respected name in the field of eWeighing (weighing scales), covering various diverse sectors in weighing technology.",0,1
1031,2018-8-21,2018,8,21,19,9923kl,Python Tutorial Multithreading - Introduction,https://www.reddit.com/r/MachineLearning/comments/9923kl/python_tutorial_multithreading_introduction/,Beneficial3Fish,1534847999,,0,1
1032,2018-8-21,2018,8,21,19,9927eb,Are NALUs hard to train ?!,https://www.reddit.com/r/MachineLearning/comments/9927eb/are_nalus_hard_to_train/,Ragabov,1534849169,[removed],0,1
1033,2018-8-21,2018,8,21,20,9927ll,[P] For your reinforcement learning experiments- I used python as a brain for a virtual robot in a Unity simulation,https://www.reddit.com/r/MachineLearning/comments/9927ll/p_for_your_reinforcement_learning_experiments_i/,apockill,1534849219,,17,69
1034,2018-8-21,2018,8,21,20,992duf,[Discussion] New Nvidia cards for accelerating ML tasks. Yay or nay?,https://www.reddit.com/r/MachineLearning/comments/992duf/discussion_new_nvidia_cards_for_accelerating_ml/,TwoAbove,1534850951,"I know there is not much info available about the new generation of Nvidia's GPUs, but I'm intrigued about the new tensor cores.

I'm 100% certain that, initially, they will be weaker than the current gen because they have less CUDA cores (with the new tpu in their place and no info on an sdk of any sort). 

Will we be able to leverage the tpu in the future? Or will Nvidia lock that out for enterprise products? Will the tpu give a noticeable difference? 

Interested in hearing your opinion!",41,25
1035,2018-8-21,2018,8,21,20,992e52,[D] Twitter feed suggestions for ML ?!,https://www.reddit.com/r/MachineLearning/comments/992e52/d_twitter_feed_suggestions_for_ml/,yazriel0,1534851025,"/r/ML is great and i find really insightful comments here. 

Can people share their twitter feeds which are good for ML - especially deep RL, and structured data",3,5
1036,2018-8-21,2018,8,21,21,992owm,DeepKoch  Image to Recipe Food Classification,https://www.reddit.com/r/MachineLearning/comments/992owm/deepkoch_image_to_recipe_food_classification/,Murmani,1534854067,,0,1
1037,2018-8-21,2018,8,21,21,992vvb,Is new nVidia RTX 2080ti worth buying for DL?,https://www.reddit.com/r/MachineLearning/comments/992vvb/is_new_nvidia_rtx_2080ti_worth_buying_for_dl/,Walkir108,1534856089,[removed],0,1
1038,2018-8-21,2018,8,21,21,992wrj,"[R] A Simple but Effective Baseline for Sentence Vectors (Best Paper, Repl4NLP @ ACL 2018)",https://www.reddit.com/r/MachineLearning/comments/992wrj/r_a_simple_but_effective_baseline_for_sentence/,kawin_e,1534856315,,7,36
1039,2018-8-21,2018,8,21,22,992xwh,Ideas for a network architecture that could output click location given a screenshot,https://www.reddit.com/r/MachineLearning/comments/992xwh/ideas_for_a_network_architecture_that_could/,Manto1,1534856570,[removed],0,1
1040,2018-8-21,2018,8,21,22,9938ni,Loss Optimization in Scientific Python  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/9938ni/loss_optimization_in_scientific_python_coinmonks/,coinmonks,1534858968,,0,1
1041,2018-8-21,2018,8,21,23,993lxf,Machine Learning  The different ways to evaluate your Classification models and choose the best,https://www.reddit.com/r/MachineLearning/comments/993lxf/machine_learning_the_different_ways_to_evaluate/,coinmonks,1534861749,,0,1
1042,2018-8-21,2018,8,21,23,993o46,[R] Messing With Intents Translation  Generative Adversarial Networks at intent mapping,https://www.reddit.com/r/MachineLearning/comments/993o46/r_messing_with_intents_translation_generative/,fjaguero,1534862183,,0,3
1043,2018-8-21,2018,8,21,23,993opy,course introducing concepts of Big Data,https://www.reddit.com/r/MachineLearning/comments/993opy/course_introducing_concepts_of_big_data/,shokaniliyas,1534862314,[removed],0,1
1044,2018-8-22,2018,8,22,0,993yve,[D] How to Fit large Neural Networks on the Edge,https://www.reddit.com/r/MachineLearning/comments/993yve/d_how_to_fit_large_neural_networks_on_the_edge/,thatbrguy_,1534864309,,1,13
1045,2018-8-22,2018,8,22,0,993zwd,Initial guidance for pattern recognition between images matching,https://www.reddit.com/r/MachineLearning/comments/993zwd/initial_guidance_for_pattern_recognition_between/,namedlambda,1534864525,[removed],0,1
1046,2018-8-22,2018,8,22,0,9942es,Engineering GANs to create cities,https://www.reddit.com/r/MachineLearning/comments/9942es/engineering_gans_to_create_cities/,twak,1534865007,,0,1
1047,2018-8-22,2018,8,22,0,99497h,[R] Excitation Dropout: Encouraging Plasticity in Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/99497h/r_excitation_dropout_encouraging_plasticity_in/,abstractcontrol,1534866333,,5,54
1048,2018-8-22,2018,8,22,0,99498y,[P] Engineering GANs to decorate cities,https://www.reddit.com/r/MachineLearning/comments/99498y/p_engineering_gans_to_decorate_cities/,twak,1534866344,,8,48
1049,2018-8-22,2018,8,22,0,994dl7,[D] How's Julia language (MIT) for ML?,https://www.reddit.com/r/MachineLearning/comments/994dl7/d_hows_julia_language_mit_for_ml/,curious_riddler,1534867196,I am looking for a review of sorts for Julia. Has anyone here tried using it for ML and what were your experiences? How's the package library and any hiccups along the way ? ,72,133
1050,2018-8-22,2018,8,22,1,994e3m,Autoencoder Tutorial Machine Learning With Keras,https://www.reddit.com/r/MachineLearning/comments/994e3m/autoencoder_tutorial_machine_learning_with_keras/,jfishersolutions,1534867283,,0,1
1051,2018-8-22,2018,8,22,2,9951e5,Which GPU(s) to Get for Deep Learning (Updated w/ RTX Cards),https://www.reddit.com/r/MachineLearning/comments/9951e5/which_gpus_to_get_for_deep_learning_updated_w_rtx/,rubycowgames,1534871714,,0,2
1052,2018-8-22,2018,8,22,2,9952pr,Prerequisites to understand GANs,https://www.reddit.com/r/MachineLearning/comments/9952pr/prerequisites_to_understand_gans/,not_a_gan,1534871991,[removed],0,1
1053,2018-8-22,2018,8,22,2,9955md,How is statistics and probability used in ML?,https://www.reddit.com/r/MachineLearning/comments/9955md/how_is_statistics_and_probability_used_in_ml/,BySNiP,1534872552,So I started learning statistics and probability and wondered how it's used.I heard Linear algebra is useful too but I don't see how because tensorflow seems to do everything automatically.,0,1
1054,2018-8-22,2018,8,22,2,995c96,ML/DS: How your PS/Essay looked like when you applied for Masters?,https://www.reddit.com/r/MachineLearning/comments/995c96/mlds_how_your_psessay_looked_like_when_you/,nodechef,1534873812,[removed],0,1
1055,2018-8-22,2018,8,22,2,995eob,What kind of projects should I work on to get good at using python for data analytics and sql or mongodb for databases. Any links or tips would be appreciated.,https://www.reddit.com/r/MachineLearning/comments/995eob/what_kind_of_projects_should_i_work_on_to_get/,kartikagarwal8,1534874274,[removed],0,1
1056,2018-8-22,2018,8,22,3,995jxj,[P] MSG-GAN: Multi-Scale Gradients GAN,https://www.reddit.com/r/MachineLearning/comments/995jxj/p_msggan_multiscale_gradients_gan/,akanimax,1534875255,"I thought of an alternative solution to the problem of irrelevant gradients for images generated at higher resolutions apart from the layer-wise training of Progressive growing of GANs.


The proposed solution is to allow flow of gradients from the discriminator to the generator at multiple scales. The architecture uses single Generator and single Discriminator, but due to the connections between the intermediate layers of Generator and the intermediate layers of Discriminator, the architecture resembles the ""U-Net"" architecture.

I ran an experiment of training this GAN on Celeba. Following are links for more info:

medium blog -&gt; https://medium.com/@animeshsk3/msg-gan-multi-scale-gradients-gan-ee2170f55d50


pytorch code -&gt; https://github.com/akanimax/MSG-GAN


video of samples generated during training -&gt; https://www.youtube.com/watch?v=9v46ygTQ6cw",27,5
1057,2018-8-22,2018,8,22,3,995n8w,[N] NVIDIA &amp; MIT CSAIL Open-Source Video-to-Video Synthesis Method,https://www.reddit.com/r/MachineLearning/comments/995n8w/n_nvidia_mit_csail_opensource_videotovideo/,trcytony,1534875888,,0,1
1058,2018-8-22,2018,8,22,3,995tp6,[N] NVIDIA &amp; MIT CSAIL Open-Source Video-to-Video Synthesis Method,https://www.reddit.com/r/MachineLearning/comments/995tp6/n_nvidia_mit_csail_opensource_videotovideo/,gwen0927,1534877147,,0,1
1059,2018-8-22,2018,8,22,4,995zyz,Overview of Inverse Dynamics for Robots and Unity,https://www.reddit.com/r/MachineLearning/comments/995zyz/overview_of_inverse_dynamics_for_robots_and_unity/,beluis3d,1534878350,,0,1
1060,2018-8-22,2018,8,22,4,99620u,I built a beginning to end Self Driving Car course using Deep Learning. Im giving it away for free for the first 200 students. Click the link to activate coupon. I hope you enjoy it!,https://www.reddit.com/r/MachineLearning/comments/99620u/i_built_a_beginning_to_end_self_driving_car/,nottingpill,1534878744,,0,1
1061,2018-8-22,2018,8,22,4,9962gh,State-of-the-art performance on CNN?,https://www.reddit.com/r/MachineLearning/comments/9962gh/stateoftheart_performance_on_cnn/,nek2700,1534878824,[removed],0,1
1062,2018-8-22,2018,8,22,4,996dw0,[P] AI learns to shoot Zombies (NN + RL),https://www.reddit.com/r/MachineLearning/comments/996dw0/p_ai_learns_to_shoot_zombies_nn_rl/,Daporan,1534881037,,18,47
1063,2018-8-22,2018,8,22,4,996ext,Splunk MLTK and Anomaly Detection,https://www.reddit.com/r/MachineLearning/comments/996ext/splunk_mltk_and_anomaly_detection/,mustard_pickle,1534881247,,0,1
1064,2018-8-22,2018,8,22,5,996nr0,Just launched Black Swans  - It's like Indie Hackers for Statisticians! (X-Post r/SideProject),https://www.reddit.com/r/MachineLearning/comments/996nr0/just_launched_black_swans_its_like_indie_hackers/,jdyr1729,1534882961,"Hey guys,

Im a 4th year maths student at St Andrews University and have recently created an online statistics/ machine-learning community  called Black Swans ([www.blackswans.io](https://www.blackswans.io/)).

The site allows users to post about anything related to statistics and then other users can comment on these posts. E.g., perhaps you had successfully predicted the result of every World Cup  match and wanted to share the story of how you did it, or maybe you wanted to find people interested in developing a quant trading strategy  with you.

We also run competitions  on the site, e.g., best solution to [this statistics puzzle](https://blackswans.io/post/8/) wins a year of Spotify Premium .

Hope you like it 

Jack",0,1
1065,2018-8-22,2018,8,22,5,996poo,"[D]What is the State of the art in ""Image Captioning""?",https://www.reddit.com/r/MachineLearning/comments/996poo/dwhat_is_the_state_of_the_art_in_image_captioning/,HenryJia,1534883342,"Hi guys, what do you guys consider to be SOTA in neural image captioning now? I'm familiar with the Show and Tell paper [https://arxiv.org/abs/1411.4555](https://arxiv.org/abs/1411.4555) but that's a few years old now and I find it quite complex computationally to implement (the LSTM attention mechanism). What do people use now for neural captioning?",2,2
1066,2018-8-22,2018,8,22,7,997ho3,What is SOTA in unsupervised topic modeling of sentences?,https://www.reddit.com/r/MachineLearning/comments/997ho3/what_is_sota_in_unsupervised_topic_modeling_of/,rameshnotabot,1534888807,[removed],0,1
1067,2018-8-22,2018,8,22,7,997k0x,"Corpus Conversion Service: AI-based cloud service can ingest and convert up to 100,000 PDF pages per day per server",https://www.reddit.com/r/MachineLearning/comments/997k0x/corpus_conversion_service_aibased_cloud_service/,dominiquec,1534889268,,2,1
1068,2018-8-22,2018,8,22,8,998e4l,Attention #MachineLearning enthusiasts. This is the Loughborough #schoolofai Facebook group for anyone wanting to share ideas on all things #AI. join the group for our local meetup at: https://www.facebook.com/groups/683372875358463/ For more info see video here: https://youtu.be/8yu8rtXThy8,https://www.reddit.com/r/MachineLearning/comments/998e4l/attention_machinelearning_enthusiasts_this_is_the/,pyface69,1534895698,[removed],0,1
1069,2018-8-22,2018,8,22,9,998nz4,Looking for feedback on my free Self-Driving Car Course.,https://www.reddit.com/r/MachineLearning/comments/998nz4/looking_for_feedback_on_my_free_selfdriving_car/,thewhateves,1534897939,[removed],0,1
1070,2018-8-22,2018,8,22,10,998vb3,Looking for feedback on my new Self-Driving Car course,https://www.reddit.com/r/MachineLearning/comments/998vb3/looking_for_feedback_on_my_new_selfdriving_car/,thewhateves,1534899624,[removed],0,1
1071,2018-8-22,2018,8,22,11,999b94,[R] [1808.06670] Learning deep representations by mutual information estimation and maximization,https://www.reddit.com/r/MachineLearning/comments/999b94/r_180806670_learning_deep_representations_by/,evc123,1534903308,,7,44
1072,2018-8-22,2018,8,22,11,999ftm,"[D] We've updated OpenAI Baselines...[with] common experiment interface, reusable policy building code, [and] benchmarks...",https://www.reddit.com/r/MachineLearning/comments/999ftm/d_weve_updated_openai_baselineswith_common/,abhishkk65,1534904317,,4,129
1073,2018-8-22,2018,8,22,11,999jg5,Problem with validation set for random forest classifier. PLEASE HELP!!,https://www.reddit.com/r/MachineLearning/comments/999jg5/problem_with_validation_set_for_random_forest/,Drgoldsz22,1534905187,"Hello guys, 

I am training a binary classifier to identify pictures of good and bad zippers. The pictures that I am using for this task are being taken from a conveyor belt. I have around 8000 pictures of which 4400 are of good zippers.

One important factor to consider, is that when I was constructing this dataset, I would take 4 pictures every time I passed a zipper through te conveyor belt in order to increase the size of the dataset quickly (I am not sure if this can be the cause to my error)

When I trained the classifier (random forest) using about 30% for testing set I end up getting very high scores in both the training and testing (1.00 , 0.9987). Furthermore, a 5 fold cross validation test with an average of 99%+

The problem I am having is that when I use the trained classifier with live pictures (zippers that I am passing through the conveyor belt to do validation) it predicts all zippers as bad. 

I took 42 individual pictures of good zippers to validate and it predicts all of them as being bad (only one picture per pass this time). I dont understand how this can be happening if it performs so well on the testing set. It predicts more than 1000 zippers that are good correctly. 

Also when I place the first 20 pictures of the validation set in the training set, it is able to predict about 16 right out of the 22 that are left in the validation set. 

I really do not know what to do. I would appreciate any piece of advise. 

Thanks for the help! 
",0,1
1074,2018-8-22,2018,8,22,11,999ld0,How to create fake data using python,https://www.reddit.com/r/MachineLearning/comments/999ld0/how_to_create_fake_data_using_python/,ExcelDataScience,1534905664,,0,1
1075,2018-8-22,2018,8,22,12,99a4ho,[Discussion] Using ML to study a priori mathematical objects? (+ pretty visualizations),https://www.reddit.com/r/MachineLearning/comments/99a4ho/discussion_using_ml_to_study_a_priori/,goodside,1534910356,"Richard K. Guy's ""Strong Law of Small Numbers"":

&gt;*""There aren't enough small numbers to meet the many demands made of them.""*

Or, as Wikipedia puts it:

&gt;\[A\]ny given small number appears in far more contexts than may seem reasonable, leading to many apparently surprising coincidences in mathematics, simply because small numbers appear so often and yet are so few.

Intuitively, this rings true. The number 71 occurring in two seemingly unrelated math proofs is a non-event, but the same 40-digit integer showing twice cries for an explanation. Small integers coincide by dumb luck, big ones do not.

It's hard *not* to think like this, even when you know nothing involved is stochastic. For a mathematical proof there clearly is no counterfactual  no sense in which 4 is an ""expected"" or ""unexpected"" result of adding 2 and 2   but we freely pretend there is, and we seem to get derive useful intuitions from thinking this way. Try scrolling through &lt;[https://en.wikipedia.org/wiki/Mathematical\_coincidence](https://en.wikipedia.org/wiki/Mathematical_coincidence)\&gt; and notice how many of the examples you find boring because they contain ""cherry-picked"" values or because the size of the coincidence isn't very ""significant"".

Leland McInnes's UMAP (&lt;[https://arxiv.org/abs/1802.03426](https://arxiv.org/abs/1802.03426)\&gt;) is a dimensionality reduction technique that seems to preserve topology better than t-SNE (see COIL20 visualization on p.12 especially) and with drastically better performance  11x faster to embed F-MNIST, and anecdotally I've seen it outperform by &gt;50x on real-world large inputs.

Today, I saw this UMAP masterpiece on Twitter from John Williamson: &lt;[https://twitter.com/jhnhw/status/1031829726757900288](https://twitter.com/jhnhw/status/1031829726757900288)\&gt;

As he describes it:

&gt;Details: for each i up to n, find prime factors of i. For each i, make binary vector with (n) columns, 1=prime factor present, 0=absent and stack into matrix. Lay out with UMAP, using cosine similarity.

My first thought was this has to be the ML equivalent of humans staring at clouds, finding meaningless patterns in noise. But this *isn't* noise  it's the exact opposite if anything. Noise has maximal information content while integers have none. If UMAP recovers structure in spite of noise, why wouldn't it work  when structure is all there is? The follow-up examples in that Twitter thread color UMAP-embedded points with simple criteria (parity, primality, number of prime factors), and the contrasting effects between clusters couldn't be more striking.

So now I'm curious: What are some examples of using ML or statistics to study *a priori* mathematical structures? I'm interested in any domain other than modeling data collected by sensors in the real world (or some real-world artifact, as with RL agents playing a video game).",7,25
1076,2018-8-22,2018,8,22,13,99a7xo,How is statistics used in ML?,https://www.reddit.com/r/MachineLearning/comments/99a7xo/how_is_statistics_used_in_ml/,BySNiP,1534911227,[removed],0,1
1077,2018-8-22,2018,8,22,13,99ab81,How Did OpenAIs Bot Defeat the Team of Dota2 Semi-Pros?,https://www.reddit.com/r/MachineLearning/comments/99ab81/how_did_openais_bot_defeat_the_team_of_dota2/,coinmonks,1534912110,,0,1
1078,2018-8-22,2018,8,22,13,99agxu,Good Resources for Preparing Yourself for Machine Learning Engineer Interviews in FAMGA?,https://www.reddit.com/r/MachineLearning/comments/99agxu/good_resources_for_preparing_yourself_for_machine/,upulbandara,1534913684,[removed],0,1
1079,2018-8-22,2018,8,22,14,99aqwx,The Hottest Artificial Intelligence Technologies and Algorithms,https://www.reddit.com/r/MachineLearning/comments/99aqwx/the_hottest_artificial_intelligence_technologies/,Giri2611,1534916619,,0,1
1080,2018-8-22,2018,8,22,15,99ay45,Identifying road quality from images,https://www.reddit.com/r/MachineLearning/comments/99ay45/identifying_road_quality_from_images/,ANil1729,1534918890,[removed],0,1
1081,2018-8-22,2018,8,22,15,99ayxe,Analyzing a dataset using Python Pandas Library | Importing CSV files,https://www.reddit.com/r/MachineLearning/comments/99ayxe/analyzing_a_dataset_using_python_pandas_library/,Additional_Proof,1534919157,,0,1
1082,2018-8-22,2018,8,22,17,99bhlt,Looking for intuition/papers to read for accelerating RNN training,https://www.reddit.com/r/MachineLearning/comments/99bhlt/looking_for_intuitionpapers_to_read_for/,sidsig,1534925213,[removed],0,1
1083,2018-8-22,2018,8,22,17,99bj0t,Why Machine Learning Seems To Be All Around These Days,https://www.reddit.com/r/MachineLearning/comments/99bj0t/why_machine_learning_seems_to_be_all_around_these/,vidushivij,1534925712,,0,1
1084,2018-8-22,2018,8,22,17,99bmxc,An Executive's Guide to AI and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/99bmxc/an_executives_guide_to_ai_and_machine_learning/,j_galler,1534927121,,0,2
1085,2018-8-22,2018,8,22,18,99bw62,Machine Learning using golany for improved results,https://www.reddit.com/r/MachineLearning/comments/99bw62/machine_learning_using_golany_for_improved_results/,PriyaNemade,1534930342,,0,1
1086,2018-8-22,2018,8,22,18,99bytq,Why Accountants Should Embrace Machine Learning,https://www.reddit.com/r/MachineLearning/comments/99bytq/why_accountants_should_embrace_machine_learning/,cryptobach,1534931185,,0,1
1087,2018-8-22,2018,8,22,19,99c6br,What is Machine Learning and How It Benefit Your Business?,https://www.reddit.com/r/MachineLearning/comments/99c6br/what_is_machine_learning_and_how_it_benefit_your/,sailotech,1534933581,,0,1
1088,2018-8-22,2018,8,22,19,99c6z2,Big Data Masters Program (simplilearn),https://www.reddit.com/r/MachineLearning/comments/99c6z2/big_data_masters_program_simplilearn/,OverFlow10,1534933802,[removed],0,1
1089,2018-8-22,2018,8,22,20,99ce1e,Multi Criteria Decision Making (MCDM),https://www.reddit.com/r/MachineLearning/comments/99ce1e/multi_criteria_decision_making_mcdm/,divyn10,1534935960,[removed],0,1
1090,2018-8-22,2018,8,22,21,99crd7,[P] Serverless Machine Learning with ML.NET and Azure Functions,https://www.reddit.com/r/MachineLearning/comments/99crd7/p_serverless_machine_learning_with_mlnet_and/,darkjeepers,1534939614,,0,1
1091,2018-8-22,2018,8,22,23,99dw8s,Difficulty to understand U-net,https://www.reddit.com/r/MachineLearning/comments/99dw8s/difficulty_to_understand_unet/,fredcourch,1534948855,[removed],0,1
1092,2018-8-22,2018,8,22,23,99dzi9,Free Biotech &amp; Longevity Livestream Panel,https://www.reddit.com/r/MachineLearning/comments/99dzi9/free_biotech_longevity_livestream_panel/,The_Syndicate_VC,1534949520,"Hey guys, I will be hosting a free biotech &amp; longevity livestream panel with Aubrey de Grey, Mike Selden and Dr Jenny Rooke and the Future of Biotech on 8/27 @ 11am EST (5pm CET) for anyone interested



The panelists are top notch:



\*\*\*Aubrey de Grey - Cambridge Longevity Researcher, [SENS.org](https://sens.org/)



\*\*\*Mike Selden - Founder @ Finless Foods - Startup producing clean meat



\*\*\*Dr Jenny Rooke - Biotech Venture Investor @ Genoa Ventures



[https://fringefm.typeform.com/to/I6Hs7O](https://fringefm.typeform.com/to/I6Hs7O)



We will cover a wide range of topics from genetic engineering and human longevity to personalized medicine, pharma, manufactured meats and much more.. Plus there will be a live Q&amp;A session at the end



Here is the RSVP via Typeform if you are interested



[https://fringefm.typeform.com/to/I6Hs7O](https://fringefm.typeform.com/to/I6Hs7O)



Thought this could be very interesting for members so figured Id share it out (if not okay, please let me know asap). Invite anyone you think would be interested.",0,1
1093,2018-8-22,2018,8,22,23,99e1fp,Machine learning algorithms #Machine Learning #algorithms #DataScience,https://www.reddit.com/r/MachineLearning/comments/99e1fp/machine_learning_algorithms_machine_learning/,ysivaram89,1534949905,,0,1
1094,2018-8-23,2018,8,23,0,99e2nu,Help With arxiv Endorsement,https://www.reddit.com/r/MachineLearning/comments/99e2nu/help_with_arxiv_endorsement/,iitrsamrat,1534950159,[removed],0,1
1095,2018-8-23,2018,8,23,0,99e4sx,"Serverless as a Success, explained from a vendor-free view",https://www.reddit.com/r/MachineLearning/comments/99e4sx/serverless_as_a_success_explained_from_a/,programming-innovate,1534950572,[removed],0,1
1096,2018-8-23,2018,8,23,0,99e7l7,[D] Can anyone explain this paragraph from the Batch Normalization paper? (Description in comment),https://www.reddit.com/r/MachineLearning/comments/99e7l7/d_can_anyone_explain_this_paragraph_from_the/,Eoncarry,1534951120,"&amp;#x200B;

https://i.redd.it/gxnczbuvvnh11.png",8,7
1097,2018-8-23,2018,8,23,0,99e7xg,"Can you quys help me create a dataset of ways to ask an ai assistant to do something? This links to google forms questionaire, fill it in however many time you want. Thanks!",https://www.reddit.com/r/MachineLearning/comments/99e7xg/can_you_quys_help_me_create_a_dataset_of_ways_to/,jtomes123,1534951193,,0,1
1098,2018-8-23,2018,8,23,0,99ee6n,10 Python Trending Projects on GitHub,https://www.reddit.com/r/MachineLearning/comments/99ee6n/10_python_trending_projects_on_github/,jessse33,1534952466,,0,1
1099,2018-8-23,2018,8,23,0,99efcu,[D] An essay on Morphology (and contra some current machine learning techniques),https://www.reddit.com/r/MachineLearning/comments/99efcu/d_an_essay_on_morphology_and_contra_some_current/,hernandezurbina,1534952697,"Reddit folk, 

Currently, I'm working on a project that had me thinking about the limitations of current ML techniques (particularly, for NLP), which led me to write the essay in the link below. I don't know about you but sometimes I can't help to feel critical, skeptical, disappointed and -even- angry with the current direction that AI is taking both in terms of applications and research. Especially when just a few companies and labs out there are setting up the research agenda of the entire field. 

Are we any close to reach AGI? How our understanding about \*natural\* intelligence has progressed by having \[insert your favorite AI technique/algorithm here\]?

[https://thoughtistblog.wordpress.com/2018/08/03/on-morphology-and-contra-some-current-machine-learning-technique](https://thoughtistblog.wordpress.com/2018/08/03/on-morphology-and-contra-some-current-machine-learning-technique)",4,1
1100,2018-8-23,2018,8,23,0,99eijd,"Simple Questions Thread August 22, 2018",https://www.reddit.com/r/MachineLearning/comments/99eijd/simple_questions_thread_august_22_2018/,AutoModerator,1534953345,[removed],0,1
1101,2018-8-23,2018,8,23,1,99elcs,Machine Learning for Retail,https://www.reddit.com/r/MachineLearning/comments/99elcs/machine_learning_for_retail/,minmidinosaur,1534953871,[removed],0,1
1102,2018-8-23,2018,8,23,1,99emat,[N] KDD 2018 Announces Best Paper &amp; Other Awards,https://www.reddit.com/r/MachineLearning/comments/99emat/n_kdd_2018_announces_best_paper_other_awards/,trcytony,1534954059,,0,1
1103,2018-8-23,2018,8,23,1,99endz,The Guide to Machine Learning in Retail,https://www.reddit.com/r/MachineLearning/comments/99endz/the_guide_to_machine_learning_in_retail/,minmidinosaur,1534954252,,0,1
1104,2018-8-23,2018,8,23,1,99enlt,Stable Baselines: a Fork of OpenAI Baselines  Reinforcement Learning Made Easy,https://www.reddit.com/r/MachineLearning/comments/99enlt/stable_baselines_a_fork_of_openai_baselines/,atooo57,1534954291,,1,1
1105,2018-8-23,2018,8,23,1,99eoch,Balanced random forests in H2O?,https://www.reddit.com/r/MachineLearning/comments/99eoch/balanced_random_forests_in_h2o/,_flo_rian,1534954435,[removed],0,1
1106,2018-8-23,2018,8,23,1,99ey1r,"[R] ""Snorkel: rapid training data creation with weak supervision"", Ratner et al 2018 [supporting noisy data annotation with simple rules, crowdsourcing, external knowledge databases etc]",https://www.reddit.com/r/MachineLearning/comments/99ey1r/r_snorkel_rapid_training_data_creation_with_weak/,gwern,1534956367,,7,38
1107,2018-8-23,2018,8,23,1,99ezmz,Unsupervised Learning Project Help - How to identify single data points within KMeans clusters,https://www.reddit.com/r/MachineLearning/comments/99ezmz/unsupervised_learning_project_help_how_to/,Allyi302,1534956674,[removed],0,1
1108,2018-8-23,2018,8,23,2,99f791,Why is my computational graph of a (convolutional) variational auto-encoder in tensorflow so ugly?,https://www.reddit.com/r/MachineLearning/comments/99f791/why_is_my_computational_graph_of_a_convolutional/,MaximilioneinHD,1534958141,"Hi guys,

I am implementing a (convolutional) variational auto-encoder in tensorflow and when viewing the computational graph (with [Netron](https://lutzroeder.github.io/Netron/)) I see some very confusing lines. It does not seem to be as straight forward as I hope it should be (especially in comparison to the sample files given on the website of Netron)...

I would appreciate if someone could explain me what is going on here (there is also a browser version of Netron, so no need to install it)!

[My computational graph for download.](https://www.dropbox.com/s/b7mud1hercash3i/graph.pb?dl=0)

 The graph I am implementing has the following main characteristics (for details I also pasted my code below):

* input dim: 512x512x3
* three alternating layers of 2D convolution and max-pooling
* sampling from the 2D code
* three alternating layers of 2D 'de-convolution' and 2D unpooling

Thanks a lot for any input!

&amp;#x200B;

**Appendix**: The implementation looks like this:

    def unpool_2d(pool, ind, stride=[1, 2, 2, 1], scope='unpool_2d'):
        """"""Adds a 2D unpooling op.
      https://arxiv.org/abs/1505.04366
    
      Unpooling layer after max_pool_with_argmax.
           Args:
               pool:        max pooled output tensor
               ind:         argmax indices
               stride:      stride is the same as for the pool
               scope:       ??
           Return:
               unpool:    unpooling tensor
      """"""
        with tf.variable_scope(scope):
            input_shape = tf.shape(pool)
            output_shape = [input_shape[0], input_shape[1] * stride[1], input_shape[2] * stride[2], input_shape[3]]
    
            flat_input_size = tf.reduce_prod(input_shape)
            flat_output_shape = [output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]
    
            pool_ = tf.reshape(pool, [flat_input_size])
            batch_range = tf.reshape(tf.range(tf.cast(output_shape[0], tf.int64), dtype=ind.dtype),
                                     shape=[input_shape[0], 1, 1, 1])
            b = tf.ones_like(ind) * batch_range
            b1 = tf.reshape(b, [flat_input_size, 1])
            ind_ = tf.reshape(ind, [flat_input_size, 1])
            ind_ = tf.concat([b1, ind_], 1)
    
            ret = tf.scatter_nd(ind_, pool_, shape=tf.cast(flat_output_shape, tf.int64))
            ret = tf.reshape(ret, output_shape)
    
            set_input_shape = pool.get_shape()
            set_output_shape = [set_input_shape[0], set_input_shape[1] * stride[1], set_input_shape[2] * stride[2],
                                set_input_shape[3]]
            ret.set_shape(set_output_shape)
            return ret
    
    # ======================
    # Graph Definition: Define the Encoder
    # ======================
    
    # Input Layer
    # Input 4-D tensor: [batch_size, width, height, channels]
    # images are 512x512 pixels, and have 3 color channel
    input_image = tf.placeholder(tf.float32, [None, 512, 512, 3])
    
    # Convolutional Layer #1
    # Computes 16 features using a 10x10 filter and stride of 2 with ReLU activation.
    # Input Tensor Shape: [batch_size, 512, 512, 3]
    # Output Tensor Shape: [batch_size, 252, 252, 16]
    conv1 = tf.layers.conv2d(
        inputs=input_image,
        filters=16,
        kernel_size=[10, 10],
        strides=2,
        padding=""valid"",
        activation=tf.nn.relu,
        name='conv1')
    
    # Pooling Layer #1
    # First max pooling layer with a 3x3 filter and stride of 3
    # Input Tensor Shape: [batch_size, 252, 252, 16]
    # Output Tensor Shape: [batch_size, 84, 84, 16]
    # pool1_l = tf.layers.max_pooling2d(inputs=conv1, pool_size=[3, 3], strides=3)
    pool1, pool1_am = tf.nn.max_pool_with_argmax(
        input=conv1,
        ksize=[1, 3, 3, 1],
        strides=[1, 3, 3, 1],
        padding='VALID',
        name='pool1'
    )
    
    # Convolutional Layer #2
    # Computes 16 features using a 10x10 filter and stride of 2.
    # Input Tensor Shape: [batch_size, 84, 84, 16]
    # Output Tensor Shape: [batch_size, 38, 38, 16]
    conv2 = tf.layers.conv2d(
        inputs=pool1,
        filters=16,
        kernel_size=[10, 10],
        strides=2,
        padding=""valid"",
        activation=tf.nn.relu,
        name='conv2')
    
    # Pooling Layer #2
    # Second max pooling layer with a 2x2 filter and stride of 2
    # Input Tensor Shape: [batch_size, 38, 38, 16]
    # Output Tensor Shape: [batch_size, 19, 19, 16]
    # pool2_l = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
    pool2, pool2_am = tf.nn.max_pool_with_argmax(
        input=conv2,
        ksize=[1, 2, 2, 1],
        strides=[1, 2, 2, 1],
        padding='VALID',
        name='pool2'
    )
    
    # Convolutional Layer #3
    # Computes 16 features using a 5x5 filter and stride of 2.
    # Input Tensor Shape: [batch_size, 19, 19, 16]
    # Output Tensor Shape: [batch_size, 8, 8, 16]
    conv3 = tf.layers.conv2d(
        inputs=pool2,
        filters=16,
        kernel_size=[5, 5],
        strides=2,
        padding=""valid"",
        activation=tf.nn.relu,
        name='conv3')
    
    # Pooling Layer #3
    # Third max pooling layer with a 2x2 filter and stride of 2
    # Input Tensor Shape: [batch_size, 8, 8, 16]
    # Output Tensor Shape: [batch_size, 4, 4, 16]
    # pool3_l = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)
    pool3, pool3_am = tf.nn.max_pool_with_argmax(
        input=conv3,
        ksize=[1, 2, 2, 1],
        strides=[1, 2, 2, 1],
        padding='VALID',
        name='pool3'
    )
    
    # Flatten tensor into a batch of vectors
    # Input Tensor Shape: [batch_size, 4, 4, 16]
    # Output Tensor Shape: [batch_size, 4 * 4 * 16]
    pool3_flat = tf.reshape(pool3, [-1, 4 * 4 * 16])
    
    # learn mean and log(standard deviation) with densely connected layers
    # Input Tensor Shape: [batch_size, 4 * 4 * 16]
    # Output Tensor Shape: [batch_size, 2]
    z_mean = tf.layers.dense(pool3_flat, 2, activation=tf.nn.relu, name='dense')
    z_log_var = tf.layers.dense(pool3_flat, 2, tf.nn.softplus)
    
    # reparameterization trick
    # instead of sampling from Q(z|X), sample eps = N(0,I)
    # then z = z_mean + z_std * eps
    eps = tf.random_normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')
    z = z_mean + tf.exp(z_log_var / 2) * eps
    
    # ======================
    # Graph Definition: Define the Decoder
    # ======================
    
    # reverse fully connected layer
    # Input Tensor Shape: [batch_size, 2]
    # Output Tensor Shape: [batch_size, 4 * 4 * 16]
    z_fc_flat = tf.layers.dense(z, 4 * 4 * 16, activation=tf.nn.relu, name='undense')
    
    # Unflatten tensor into a batch of vectors
    # Input Tensor Shape: [batch_size, 4 * 4 * 16]
    # Output Tensor Shape: [batch_size, 4, 4, 16]
    z_fc_unflat = tf.reshape(z_fc_flat, [-1, 4, 4, 16])
    
    # Unpooling Layer #3
    # Unpooling layer with a 2x2 filter and stride of 2
    # Input Tensor Shape: [batch_size, 4, 4, 16]
    # Output Tensor Shape: [batch_size, 8, 8, 16]
    unpool3 = unpool_2d(pool=z_fc_unflat, ind=pool3_am)
    
    # Deconvolutional Layer #3
    # Computes 16 features using a 5x5 filter and stride of 2.
    # Input Tensor Shape: [batch_size, 8, 8, 16]
    # Output Tensor Shape: [batch_size, 19, 19, 16]
    filter_deconv3 = tf.get_variable(name=""filter_deconv3"", shape=[5, 5, 16, 16],
                                     initializer=tf.initializers.random_normal)
    deconv3 = tf.nn.relu(
        tf.nn.conv2d_transpose(
            value=unpool3,
            filter=filter_deconv3,
            output_shape=[-1, 19, 19, 16],
            strides=[1, 2, 2, 1],
            padding='VALID',
            name='deconv3'
        )
    )
    
    # Unpooling Layer #2
    # Unpooling layer with a 2x2 filter and stride of 2
    # Input Tensor Shape: [batch_size, 19, 19, 16]
    # Output Tensor Shape: [batch_size, 38, 38, 16]
    unpool2 = unpool_2d(pool=deconv3, ind=pool2_am)
    
    # Deconvolutional Layer #2
    # Computes 16 features using a 10x10 filter and stride of 2.
    # Input Tensor Shape: [batch_size, 38, 38, 16]
    # Output Tensor Shape: [batch_size, 84, 84, 16]
    filter_deconv2 = tf.get_variable(name=""filter_deconv2"", shape=[10, 10, 16, 16],
                                     initializer=tf.initializers.random_normal)
    deconv2 = tf.nn.relu(
        tf.nn.conv2d_transpose(
            value=unpool2,
            filter=filter_deconv2,
            output_shape=[-1, 84, 84, 16],
            strides=[1, 2, 2, 1],
            padding='VALID',
            name='deconv2'
        )
    )
    
    # Unpooling Layer #1
    # Unpooling layer layer with a 3x3 filter and stride of 3
    # Input Tensor Shape: [batch_size, 84, 84, 16]
    # Output Tensor Shape: [batch_size, 252, 252, 16]
    unpool1 = unpool_2d(pool=deconv2, ind=pool1_am, stride=[1, 3, 3, 1])
    
    # Deconvolutional Layer #1
    # Computes 16 features using a 10x10 filter and stride of 2 with ReLU activation.
    # Input Tensor Shape: [batch_size, 252, 252, 16]
    # Output Tensor Shape: [batch_size, 512, 512, 3]
    filter_deconv1 = tf.get_variable(name=""filter_deconv1"", shape=[10, 10, 3, 16],
                                     initializer=tf.initializers.random_normal)
    recon_image = tf.nn.relu(
        tf.nn.conv2d_transpose(
            value=unpool1,
            filter=filter_deconv1,
            output_shape=[-1, 512, 512, 3],
            strides=[1, 2, 2, 1],
            padding='VALID',
            name='deconv1'
        )
    )
    
    # The loss is composed of two terms:
    # 1.) The reconstruction loss (the negative log probability
    #     of the input under the reconstructed Bernoulli distribution
    #     induced by the decoder in the data space).
    #     This can be interpreted as the number of ""nats"" required
    #     for reconstructing the input when the activation in latent
    #     is given.
    # Adding 1e-10 to avoid evaluation of log(0.0)
    reconstr_loss = -tf.reduce_sum(
        input_image * tf.log(1e-10 + recon_image) + (1 - input_image) * tf.log(1e-10 + 1 - recon_image),
        1
    )
    
    # 2.) The latent loss, which is defined as the Kullback Leibler divergence
    #     between the distribution in latent space induced by the encoder on
    #     the data and some prior. This acts as a kind of regularizer.
    #     This can be interpreted as the number of ""nats"" required
    #     for transmitting the the latent space distribution given
    #     the prior.
    KL = -0.5 * tf.reduce_sum(1 + z_log_var
                              - tf.square(z_mean)
                              - tf.exp(z_log_var), 1)
    
    # Total loss
    loss = tf.reduce_mean(reconstr_loss + KL)  # average over batch
    
    # Hyperparameters
    learning_rate = 0.001
    num_epochs = 2
    batch_size = 5
    
    # Use ADAM optimizer
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
    train_op = optimizer.minimize(loss)
    
    # Seed the random number generator for reproducible batches
    np.random.seed(0)
    
    # Print list of variables
    print("""")
    print(""Variables"")
    print(""---------"")
    variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
    num_params = 0
    for v in variables:
        num_params += np.prod(v.get_shape().as_list())
        print(v.name, v.get_shape())
    print(""=&gt; Total number of parameters ="", num_params)
    
    # TF session
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    
    # save graph for visualisation purposes
    tf.train.write_graph(sess.graph_def, 'my-model/', 'graph.pb', as_text=False)",0,1
1109,2018-8-23,2018,8,23,2,99faim,[D] Why is my computational graph of a (convolutional) variational auto-encoder in tensorflow so ugly?,https://www.reddit.com/r/MachineLearning/comments/99faim/d_why_is_my_computational_graph_of_a/,MaximilioneinHD,1534958775,"Hi guys,

I am implementing a (convolutional) variational auto-encoder in tensorflow and when viewing the computational graph (with [Netron](https://lutzroeder.github.io/Netron/)) I see some very confusing lines. It does not seem to be as straight forward as I hope it should be (especially in comparison to the well organised views of some sample files given on the website of Netron)...

I would appreciate if someone could explain me what is going on here or if I am doing something completely wrong! There is also a browser version of Netron, so no need to install it :)

[My computational graph for download.](https://www.dropbox.com/s/b7mud1hercash3i/graph.pb?dl=0)

The graph I am implementing has the following main characteristics (for details I also pasted my code below):

* input dim: 512x512x3
* three alternating layers of 2D convolution and max-pooling
* sampling from the 2D code
* three alternating layers of 2D 'de-convolution' and 2D unpooling

Thanks a lot for any input!



**Appendix**: The implementation looks like this:

    def unpool_2d(pool, ind, stride=[1, 2, 2, 1], scope='unpool_2d'):
        """"""Adds a 2D unpooling op.
      https://arxiv.org/abs/1505.04366
    
      Unpooling layer after max_pool_with_argmax.
           Args:
               pool:        max pooled output tensor
               ind:         argmax indices
               stride:      stride is the same as for the pool
               scope:       ??
           Return:
               unpool:    unpooling tensor
      """"""
        with tf.variable_scope(scope):
            input_shape = tf.shape(pool)
            output_shape = [input_shape[0], input_shape[1] * stride[1], input_shape[2] * stride[2], input_shape[3]]
    
            flat_input_size = tf.reduce_prod(input_shape)
            flat_output_shape = [output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]
    
            pool_ = tf.reshape(pool, [flat_input_size])
            batch_range = tf.reshape(tf.range(tf.cast(output_shape[0], tf.int64), dtype=ind.dtype),
                                     shape=[input_shape[0], 1, 1, 1])
            b = tf.ones_like(ind) * batch_range
            b1 = tf.reshape(b, [flat_input_size, 1])
            ind_ = tf.reshape(ind, [flat_input_size, 1])
            ind_ = tf.concat([b1, ind_], 1)
    
            ret = tf.scatter_nd(ind_, pool_, shape=tf.cast(flat_output_shape, tf.int64))
            ret = tf.reshape(ret, output_shape)
    
            set_input_shape = pool.get_shape()
            set_output_shape = [set_input_shape[0], set_input_shape[1] * stride[1], set_input_shape[2] * stride[2],
                                set_input_shape[3]]
            ret.set_shape(set_output_shape)
            return ret
    
    # ======================
    # Graph Definition: Define the Encoder
    # ======================
    
    # Input Layer
    # Input 4-D tensor: [batch_size, width, height, channels]
    # images are 512x512 pixels, and have 3 color channel
    input_image = tf.placeholder(tf.float32, [None, 512, 512, 3])
    
    # Convolutional Layer #1
    # Computes 16 features using a 10x10 filter and stride of 2 with ReLU activation.
    # Input Tensor Shape: [batch_size, 512, 512, 3]
    # Output Tensor Shape: [batch_size, 252, 252, 16]
    conv1 = tf.layers.conv2d(
        inputs=input_image,
        filters=16,
        kernel_size=[10, 10],
        strides=2,
        padding=""valid"",
        activation=tf.nn.relu,
        name='conv1')
    
    # Pooling Layer #1
    # First max pooling layer with a 3x3 filter and stride of 3
    # Input Tensor Shape: [batch_size, 252, 252, 16]
    # Output Tensor Shape: [batch_size, 84, 84, 16]
    # pool1_l = tf.layers.max_pooling2d(inputs=conv1, pool_size=[3, 3], strides=3)
    pool1, pool1_am = tf.nn.max_pool_with_argmax(
        input=conv1,
        ksize=[1, 3, 3, 1],
        strides=[1, 3, 3, 1],
        padding='VALID',
        name='pool1'
    )
    
    # Convolutional Layer #2
    # Computes 16 features using a 10x10 filter and stride of 2.
    # Input Tensor Shape: [batch_size, 84, 84, 16]
    # Output Tensor Shape: [batch_size, 38, 38, 16]
    conv2 = tf.layers.conv2d(
        inputs=pool1,
        filters=16,
        kernel_size=[10, 10],
        strides=2,
        padding=""valid"",
        activation=tf.nn.relu,
        name='conv2')
    
    # Pooling Layer #2
    # Second max pooling layer with a 2x2 filter and stride of 2
    # Input Tensor Shape: [batch_size, 38, 38, 16]
    # Output Tensor Shape: [batch_size, 19, 19, 16]
    # pool2_l = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
    pool2, pool2_am = tf.nn.max_pool_with_argmax(
        input=conv2,
        ksize=[1, 2, 2, 1],
        strides=[1, 2, 2, 1],
        padding='VALID',
        name='pool2'
    )
    
    # Convolutional Layer #3
    # Computes 16 features using a 5x5 filter and stride of 2.
    # Input Tensor Shape: [batch_size, 19, 19, 16]
    # Output Tensor Shape: [batch_size, 8, 8, 16]
    conv3 = tf.layers.conv2d(
        inputs=pool2,
        filters=16,
        kernel_size=[5, 5],
        strides=2,
        padding=""valid"",
        activation=tf.nn.relu,
        name='conv3')
    
    # Pooling Layer #3
    # Third max pooling layer with a 2x2 filter and stride of 2
    # Input Tensor Shape: [batch_size, 8, 8, 16]
    # Output Tensor Shape: [batch_size, 4, 4, 16]
    # pool3_l = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)
    pool3, pool3_am = tf.nn.max_pool_with_argmax(
        input=conv3,
        ksize=[1, 2, 2, 1],
        strides=[1, 2, 2, 1],
        padding='VALID',
        name='pool3'
    )
    
    # Flatten tensor into a batch of vectors
    # Input Tensor Shape: [batch_size, 4, 4, 16]
    # Output Tensor Shape: [batch_size, 4 * 4 * 16]
    pool3_flat = tf.reshape(pool3, [-1, 4 * 4 * 16])
    
    # learn mean and log(standard deviation) with densely connected layers
    # Input Tensor Shape: [batch_size, 4 * 4 * 16]
    # Output Tensor Shape: [batch_size, 2]
    z_mean = tf.layers.dense(pool3_flat, 2, activation=tf.nn.relu, name='dense')
    z_log_var = tf.layers.dense(pool3_flat, 2, tf.nn.softplus)
    
    # reparameterization trick
    # instead of sampling from Q(z|X), sample eps = N(0,I)
    # then z = z_mean + z_std * eps
    eps = tf.random_normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')
    z = z_mean + tf.exp(z_log_var / 2) * eps
    
    # ======================
    # Graph Definition: Define the Decoder
    # ======================
    
    # reverse fully connected layer
    # Input Tensor Shape: [batch_size, 2]
    # Output Tensor Shape: [batch_size, 4 * 4 * 16]
    z_fc_flat = tf.layers.dense(z, 4 * 4 * 16, activation=tf.nn.relu, name='undense')
    
    # Unflatten tensor into a batch of vectors
    # Input Tensor Shape: [batch_size, 4 * 4 * 16]
    # Output Tensor Shape: [batch_size, 4, 4, 16]
    z_fc_unflat = tf.reshape(z_fc_flat, [-1, 4, 4, 16])
    
    # Unpooling Layer #3
    # Unpooling layer with a 2x2 filter and stride of 2
    # Input Tensor Shape: [batch_size, 4, 4, 16]
    # Output Tensor Shape: [batch_size, 8, 8, 16]
    unpool3 = unpool_2d(pool=z_fc_unflat, ind=pool3_am)
    
    # Deconvolutional Layer #3
    # Computes 16 features using a 5x5 filter and stride of 2.
    # Input Tensor Shape: [batch_size, 8, 8, 16]
    # Output Tensor Shape: [batch_size, 19, 19, 16]
    filter_deconv3 = tf.get_variable(name=""filter_deconv3"", shape=[5, 5, 16, 16],
                                     initializer=tf.initializers.random_normal)
    deconv3 = tf.nn.relu(
        tf.nn.conv2d_transpose(
            value=unpool3,
            filter=filter_deconv3,
            output_shape=[-1, 19, 19, 16],
            strides=[1, 2, 2, 1],
            padding='VALID',
            name='deconv3'
        )
    )
    
    # Unpooling Layer #2
    # Unpooling layer with a 2x2 filter and stride of 2
    # Input Tensor Shape: [batch_size, 19, 19, 16]
    # Output Tensor Shape: [batch_size, 38, 38, 16]
    unpool2 = unpool_2d(pool=deconv3, ind=pool2_am)
    
    # Deconvolutional Layer #2
    # Computes 16 features using a 10x10 filter and stride of 2.
    # Input Tensor Shape: [batch_size, 38, 38, 16]
    # Output Tensor Shape: [batch_size, 84, 84, 16]
    filter_deconv2 = tf.get_variable(name=""filter_deconv2"", shape=[10, 10, 16, 16],
                                     initializer=tf.initializers.random_normal)
    deconv2 = tf.nn.relu(
        tf.nn.conv2d_transpose(
            value=unpool2,
            filter=filter_deconv2,
            output_shape=[-1, 84, 84, 16],
            strides=[1, 2, 2, 1],
            padding='VALID',
            name='deconv2'
        )
    )
    
    # Unpooling Layer #1
    # Unpooling layer layer with a 3x3 filter and stride of 3
    # Input Tensor Shape: [batch_size, 84, 84, 16]
    # Output Tensor Shape: [batch_size, 252, 252, 16]
    unpool1 = unpool_2d(pool=deconv2, ind=pool1_am, stride=[1, 3, 3, 1])
    
    # Deconvolutional Layer #1
    # Computes 16 features using a 10x10 filter and stride of 2 with ReLU activation.
    # Input Tensor Shape: [batch_size, 252, 252, 16]
    # Output Tensor Shape: [batch_size, 512, 512, 3]
    filter_deconv1 = tf.get_variable(name=""filter_deconv1"", shape=[10, 10, 3, 16],
                                     initializer=tf.initializers.random_normal)
    recon_image = tf.nn.relu(
        tf.nn.conv2d_transpose(
            value=unpool1,
            filter=filter_deconv1,
            output_shape=[-1, 512, 512, 3],
            strides=[1, 2, 2, 1],
            padding='VALID',
            name='deconv1'
        )
    )
    
    # The loss is composed of two terms:
    # 1.) The reconstruction loss (the negative log probability
    #     of the input under the reconstructed Bernoulli distribution
    #     induced by the decoder in the data space).
    #     This can be interpreted as the number of ""nats"" required
    #     for reconstructing the input when the activation in latent
    #     is given.
    # Adding 1e-10 to avoid evaluation of log(0.0)
    reconstr_loss = -tf.reduce_sum(
        input_image * tf.log(1e-10 + recon_image) + (1 - input_image) * tf.log(1e-10 + 1 - recon_image),
        1
    )
    
    # 2.) The latent loss, which is defined as the Kullback Leibler divergence
    #     between the distribution in latent space induced by the encoder on
    #     the data and some prior. This acts as a kind of regularizer.
    #     This can be interpreted as the number of ""nats"" required
    #     for transmitting the the latent space distribution given
    #     the prior.
    KL = -0.5 * tf.reduce_sum(1 + z_log_var
                              - tf.square(z_mean)
                              - tf.exp(z_log_var), 1)
    
    # Total loss
    loss = tf.reduce_mean(reconstr_loss + KL)  # average over batch
    
    # Hyperparameters
    learning_rate = 0.001
    num_epochs = 2
    batch_size = 5
    
    # Use ADAM optimizer
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
    train_op = optimizer.minimize(loss)
    
    # Seed the random number generator for reproducible batches
    np.random.seed(0)
    
    # Print list of variables
    print("""")
    print(""Variables"")
    print(""---------"")
    variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
    num_params = 0
    for v in variables:
        num_params += np.prod(v.get_shape().as_list())
        print(v.name, v.get_shape())
    print(""=&gt; Total number of parameters ="", num_params)
    
    # TF session
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    
    # save graph for visualisation purposes
    tf.train.write_graph(sess.graph_def, 'my-model/', 'graph.pb', as_text=False)",1,0
1110,2018-8-23,2018,8,23,2,99fbsi,"How did you deal with the ""unknown"" class problem ?",https://www.reddit.com/r/MachineLearning/comments/99fbsi/how_did_you_deal_with_the_unknown_class_problem/,Ragabov,1534959031,[removed],0,1
1111,2018-8-23,2018,8,23,2,99fjfk,[D] merging a PPO DRL with Java production code?,https://www.reddit.com/r/MachineLearning/comments/99fjfk/d_merging_a_ppo_drl_with_java_production_code/,yazriel0,1534960479,"I have a PPO  DRL agent prototype which uses some existing data files and data manipulation. 

This has to be some how merged in a much larger Java production system. Its a batch processing system, ingesting ~100MB, converting it to 10GB of structured data, which is  then searched. The DRL agent acts as a search hueristic. 


Can anyone share suggestions about getting this to work ?

Rewrite  the PPO in Java (any base libs out there?)?? Yikes. 

I am a programmer messing with ML rather than the other way round.",4,4
1112,2018-8-23,2018,8,23,3,99furh,Unsupervised learning on pictures,https://www.reddit.com/r/MachineLearning/comments/99furh/unsupervised_learning_on_pictures/,shortless,1534962668,"I need to classify images by similarities, for example if I have 30 images of tomatoes, 40 images of apples and 30 images of bananas, I would like the algorithm to reconstruct the 3 classes with a k-mean for example. 
 
But it is difficult to make k-mean work directly on images, how to reduce their dimentionality?



If you have a solution I am taker



Thank you, I hope I was clear, English is not my native language.

Translated with www.DeepL.com/Translator",0,1
1113,2018-8-23,2018,8,23,4,99g6cl,"My colleagues and I have just drafted a 20 hour free course that teaches the practice of Deep Learning through the applied theme of building a self-driving car. Were looking for feedback. If youre interested in the subject, feel free to inbox me for a link.",https://www.reddit.com/r/MachineLearning/comments/99g6cl/my_colleagues_and_i_have_just_drafted_a_20_hour/,nottingpill,1534964940,[removed],0,1
1114,2018-8-23,2018,8,23,4,99ga4j,"Towards AI: How long does it take you to go from idea to working prototype? - a day, a month?",https://www.reddit.com/r/MachineLearning/comments/99ga4j/towards_ai_how_long_does_it_take_you_to_go_from/,tdionis,1534965690,,0,1
1115,2018-8-23,2018,8,23,4,99girq,[D] Could Central Limit Theorem shed some light on Batch Normalization.,https://www.reddit.com/r/MachineLearning/comments/99girq/d_could_central_limit_theorem_shed_some_light_on/,gsk694,1534967402,"One of the most fundamental problems with reproducing research papers was to understand the little details that are missing from the relatively vague descriptions.   
And one of these problems is in particular related to BatchNorm layer specifically for test time. I was just wondering if there is any literature out there that describes batchnorm statistics with respect to central limit theorem with strong results showing the effect of batch size on these batchnorm statistics?   
Basically, what I would like to know is how do we decide the batch size if BN layers are the only deciding factor (i.e assuming we have enough compute power/memory, etc). Could we use CLT approach to decide the batch size which I think would have a lot of impact on BN for test time. (Without evidence of course)",4,1
1116,2018-8-23,2018,8,23,6,99h5d1,[Project]Looking for paper suggestion for a generative chatbot,https://www.reddit.com/r/MachineLearning/comments/99h5d1/projectlooking_for_paper_suggestion_for_a/,Atom_101,1534971953,"Just as the title says, I'm looking for paper suggestions for a chatbot. I would prefer something a bit out of the ordinary, but with good accuracy. Maybe CNN with attention instead of plain LSTMs... I'm open to ideas.

An interesting paper I have looked into is:

[Convolutional Deep Structured Semantic Model](https://www.microsoft.com/en-us/research/publication/learning-bidirectional-intent-embeddings-by-convolutional-deep-structured-semantic-models-for-spoken-language-understanding/)",5,1
1117,2018-8-23,2018,8,23,6,99h66y,HyperparameterHunter: Automatically Save and Learn from Experiments During Optimization,https://www.reddit.com/r/MachineLearning/comments/99h66y/hyperparameterhunter_automatically_save_and_learn/,HunterMcGushion,1534972119,"TL;DR: [HyperparameterHunter](https://github.com/HunterMcGushion/hyperparameter_hunter) lets hyperparameter optimization use all your past experiments as learning material automatically. If you're already sold, `pip install hyperparameter-hunter`

*Processing gif e1miiba3mph11...*

[HyperparameterHunter](https://github.com/HunterMcGushion/hyperparameter_hunter) makes optimization a truly informed process by 1) automatically recording the results of your experiments for you, and 2) reading past results during hyperparameter optimization rounds, leading to a persistent learning process that doesn't let any of your experiments go to waste. Let [HyperparameterHunter](https://github.com/HunterMcGushion/hyperparameter_hunter) do the hard work of recording, organizing, and learning from your tests  all while using the same libraries you already do  with no need to provide extra information. 

&amp;#x200B;

This is my first repository, and I would really appreciate any suggestions, criticisms, or help you can offer. I've been a long-time reader of this sub, so thank you for all you've taught me, as well! Hopefully [HyperparameterHunter](https://github.com/HunterMcGushion/hyperparameter_hunter) can be as useful to you as it has been to me!",0,3
1118,2018-8-23,2018,8,23,6,99h6y2,NLPs generalization problem,https://www.reddit.com/r/MachineLearning/comments/99h6y2/nlps_generalization_problem/,tensorflower,1534972274,,0,1
1119,2018-8-23,2018,8,23,6,99h9ey,Would like to start a Machine Learning focused blog! Keen to interview too Machine Learning experts.. Drop me a message if interested as I have a big platform!!,https://www.reddit.com/r/MachineLearning/comments/99h9ey/would_like_to_start_a_machine_learning_focused/,k3ssie,1534972796,[removed],0,1
1120,2018-8-23,2018,8,23,6,99hh5a,"[R] Glow: Generative Flow with Invertible 1x1 Convolutions ""first likelihood-based model in the literature that can efficiently synthesize high-resolution natural images""",https://www.reddit.com/r/MachineLearning/comments/99hh5a/r_glow_generative_flow_with_invertible_1x1/,downtownslim,1534974350,,22,43
1121,2018-8-23,2018,8,23,6,99hi6a,[D] ML Researchers at Work,https://www.reddit.com/r/MachineLearning/comments/99hi6a/d_ml_researchers_at_work/,satsatsat,1534974557,"Just wondering if there's anything like a ""ML Researchers at Work"" comparable but more technical and research-process focused, than  this older related book ""Data Scientists at Work""
https://www.amazon.com/Data-Scientists-Work-Sebastian-Gutierrez/dp/1430265981/

Here on Reddit, I would love to hear about researchers' personal process for 
  (1) time-management i.e. being productive for their employer vs. self-growth work 
  (2) how they keep up with research / the ArXiV torrent  
  (3) how they self-teach when they need to learn new math 
  (4) anything else that might be worth knowing to become a more successful researcher!",7,53
1122,2018-8-23,2018,8,23,7,99huhb,Pursuing AI masters and unsure on module selection,https://www.reddit.com/r/MachineLearning/comments/99huhb/pursuing_ai_masters_and_unsure_on_module_selection/,colonel_50,1534977167,[removed],0,1
1123,2018-8-23,2018,8,23,8,99i83a,A Harvard professor says Coconut oil is 'Pure Poison',https://www.reddit.com/r/MachineLearning/comments/99i83a/a_harvard_professor_says_coconut_oil_is_pure/,SmartDumbGuy1,1534980156,,0,1
1124,2018-8-23,2018,8,23,8,99iami,how classify if i have more input features in train and only some in production?,https://www.reddit.com/r/MachineLearning/comments/99iami/how_classify_if_i_have_more_input_features_in/,yeenot_today,1534980734,[removed],0,1
1125,2018-8-23,2018,8,23,8,99idmw,[D] How classify if i have more input features in train and only some in production?,https://www.reddit.com/r/MachineLearning/comments/99idmw/d_how_classify_if_i_have_more_input_features_in/,yeenot_today,1534981408,"Example:

I have 20 parameters in train and test data. But in production i need classify with only 5 parameters.

how should I use the trained model?

This is a fairly common problem. For example, in assessing credit risks, there may be more parameters when the model is prepared, and less when questioning those who need to be evaluated. Or for example there is a set of game matches. There are many statistics on the played matches. And we must evaluate the future game, which only known the names of players.

May be in the validation sample to use zeros? Or is there any technique that distinguishes between basic and additional parameters?
",17,0
1126,2018-8-23,2018,8,23,8,99ifp1,Career planning,https://www.reddit.com/r/MachineLearning/comments/99ifp1/career_planning/,memedata,1534981866,"Hey everyone,

This is my first time posting here but I just started browsing this sub and really like the stuff Ive seen posted here.

I have a bachelors double major in math and statistics and have been working as a data scientist for about 2-3 years now. I didnt initially want to get into machine learning although my senior thesis was related to it. As Ive been working Ive been getting more and more restless watching the progress being made in deep learning and computer vision. 

Do you think it would be a good idea to go to graduate school for a masters in machine learning? I have a business idea using computer vision that Id like to try and build on the side too. I miss doing real math and I feel like I have a lot of skills I still need to learn even though Ive been using some deep learning things at work it hasnt been anything beyond transfer learning. The goal would be to increase my skills and I wont lie, my salary, as well as ability to execute proof of concepts on some of my business ideas.

I know Im not a contributor here but I dont know where else to go for advice. Id be more than willing to do some resume reviews for people trying to break into the data science industry though.

",0,1
1127,2018-8-23,2018,8,23,8,99ih3r,[P] Structured Data and Deep Learning: Kaggles Titanic Competition,https://www.reddit.com/r/MachineLearning/comments/99ih3r/p_structured_data_and_deep_learning_kaggles/,valexiev,1534982198,,0,1
1128,2018-8-23,2018,8,23,9,99ix2d,[D] OpenAI Five loses against first professional team at Dota 2 The International,https://www.reddit.com/r/MachineLearning/comments/99ix2d/d_openai_five_loses_against_first_professional/,PogClap,1534985916,,116,331
1129,2018-8-23,2018,8,23,11,99jd55,Python for newbies **cheat sheet**,https://www.reddit.com/r/MachineLearning/comments/99jd55/python_for_newbies_cheat_sheet/,Jiminoir,1534989703,,0,1
1130,2018-8-23,2018,8,23,12,99jy1v,[P] Is it possible to retrain tensorflow's Inception models on animated GIF's?,https://www.reddit.com/r/MachineLearning/comments/99jy1v/p_is_it_possible_to_retrain_tensorflows_inception/,Arkhaya,1534994882,"I'm trying to find a way to train inception on a GIF dataset rather than the usual jpg's.

Has anyone tried doing that?",11,0
1131,2018-8-23,2018,8,23,13,99k5jd,[Discussion]Question about deepmind ML paper applied to eye disease,https://www.reddit.com/r/MachineLearning/comments/99k5jd/discussionquestion_about_deepmind_ml_paper/,sPiraless,1534996838,"Hello.
I was reading the paper [Clinically applicable deep learning for
diagnosis and referral in retinal disease](https://deepmind.com/documents/239/De%20Fauw%20et.%20al%20Nature%20Medicine%202018%20.pdf) referenced on this blog [post](https://deepmind.com/blog/moorfields-major-milestone/).

This paper has a section about the segmentation procedure and describes a U-net like architecture
(Section Segmentation Network and supplementary figure 14).
At the bottom of the U-net the authors have utilized fully connected layers instead of convolutional ones.
Maybe after some sort of pooling. However in this figure its shown  
5 FC layers before returning to the convolutional  layers. This would be usual?
I was concerned with the number of parameters being too high on this section.
I have seen in other works using dilated convolutions instead of FC layers.
thanks",0,7
1132,2018-8-23,2018,8,23,14,99kj62,"Discussion on Deep Learning by Vijji Vennelakanti at Great Learning, Bangalore",https://www.reddit.com/r/MachineLearning/comments/99kj62/discussion_on_deep_learning_by_vijji_vennelakanti/,akshad_GL,1535000555,,0,1
1133,2018-8-23,2018,8,23,14,99klxi,Natural way to clean clothes is now in Africa!,https://www.reddit.com/r/MachineLearning/comments/99klxi/natural_way_to_clean_clothes_is_now_in_africa/,jasmineana,1535001331,,0,1
1134,2018-8-23,2018,8,23,14,99ktip,Layerwise Relevance Propagation,https://www.reddit.com/r/MachineLearning/comments/99ktip/layerwise_relevance_propagation/,atulshanbhag,1535003650,,0,1
1135,2018-8-23,2018,8,23,15,99l1h3,Improving Bottom Lines with Machine Learning based E-Surveillance,https://www.reddit.com/r/MachineLearning/comments/99l1h3/improving_bottom_lines_with_machine_learning/,Harjot16,1535006142,,0,1
1136,2018-8-23,2018,8,23,15,99l3nr,Artificial Intelligence Amongst Various Industries,https://www.reddit.com/r/MachineLearning/comments/99l3nr/artificial_intelligence_amongst_various_industries/,Batareika_1,1535006859,,0,1
1137,2018-8-23,2018,8,23,16,99l6ua,[D] Keras Backend Performance Comparison,https://www.reddit.com/r/MachineLearning/comments/99l6ua/d_keras_backend_performance_comparison/,hermonjay,1535007866,"Last year, Keras promoted its new backend using [MXNet](https://github.com/awslabs/keras-apache-mxnet) and the documentation is so compelling against Tensorflow. On the other hand, KDNuggets published this [post](https://www.kdnuggets.com/2017/09/search-fastest-keras-deep-learning-backend.html) and it seemed Tensorflow slightly outperform MXNet. So, which one's better?

&amp;#x200B;

Do you guys have any personal preference? What backend should I use? Btw, my research mainly focus on CNN.",5,7
1138,2018-8-23,2018,8,23,16,99ldbm,"Implementation of Layerwise Relevance Propagation for heatmapping ""deep"" layers",https://www.reddit.com/r/MachineLearning/comments/99ldbm/implementation_of_layerwise_relevance_propagation/,atulshanbhag,1535009874,,0,1
1139,2018-8-23,2018,8,23,16,99ledx,Understanding Machine Learning as a Data Engineer with The Simpsons,https://www.reddit.com/r/MachineLearning/comments/99ledx/understanding_machine_learning_as_a_data_engineer/,gavlaaaaaaaa,1535010232,,0,1
1140,2018-8-23,2018,8,23,16,99lf02,[D] Applied Machine Learning | A Detailed and Complete Overview 2018 (Infographic),https://www.reddit.com/r/MachineLearning/comments/99lf02/d_applied_machine_learning_a_detailed_and/,mlcrunch,1535010460,,4,0
1141,2018-8-23,2018,8,23,17,99lk7w,Data Science Training,https://www.reddit.com/r/MachineLearning/comments/99lk7w/data_science_training/,asokaDs,1535012231,,0,1
1142,2018-8-23,2018,8,23,18,99lulx,"[P] An ""Art-Bot"" That Draws Subjects Using A Genetic Algorithm Judged By image Classifier NN Models",https://www.reddit.com/r/MachineLearning/comments/99lulx/p_an_artbot_that_draws_subjects_using_a_genetic/,ootsby,1535015794,,2,1
1143,2018-8-23,2018,8,23,18,99luuc,How does Machine Learning work? (x-post /r/VoiceTech),https://www.reddit.com/r/MachineLearning/comments/99luuc/how_does_machine_learning_work_xpost_rvoicetech/,wootnoob,1535015858,,0,1
1144,2018-8-23,2018,8,23,18,99luwi,Server for machine learning,https://www.reddit.com/r/MachineLearning/comments/99luwi/server_for_machine_learning/,OkToe1,1535015881,"I have a server, which I want to rent to AI researchers.

It has 

\- i5-8th gen processor

\- 16 GB ram

\- 1 TB hdd, 250 gb ssd

\- 12\* nvidia gtx 1050 ti GPU

\- ubuntu/windows dual boot

Price is very less.

PM/comment if you would like to rent it.",0,1
1145,2018-8-23,2018,8,23,18,99lwvk,[D] Deploying models on FPGA,https://www.reddit.com/r/MachineLearning/comments/99lwvk/d_deploying_models_on_fpga/,radenML,1535016559,Currently what are the methods to compile and deploy trained models on FPGA?,17,19
1146,2018-8-23,2018,8,23,18,99lwxl,I want to create a program that detects sign language and predict what it means,https://www.reddit.com/r/MachineLearning/comments/99lwxl/i_want_to_create_a_program_that_detects_sign/,revant_t,1535016580,[removed],0,1
1147,2018-8-23,2018,8,23,18,99m16b,Considerations for building a custom PC for ML/DL/AI,https://www.reddit.com/r/MachineLearning/comments/99m16b/considerations_for_building_a_custom_pc_for_mldlai/,Pimp_Fada,1535017982,[removed],0,1
1148,2018-8-23,2018,8,23,18,99m2b5,Fume Extraction Systems,https://www.reddit.com/r/MachineLearning/comments/99m2b5/fume_extraction_systems/,Messer-123,1535018364,,0,1
1149,2018-8-23,2018,8,23,19,99mamu,Cryptocurrency trading and application of AI (anonymous poll),https://www.reddit.com/r/MachineLearning/comments/99mamu/cryptocurrency_trading_and_application_of_ai/,superdaim,1535020787,[removed],0,1
1150,2018-8-23,2018,8,23,20,99mpwu,Help selecting a CPU for my Deep Learning and Computer Vision Rig,https://www.reddit.com/r/MachineLearning/comments/99mpwu/help_selecting_a_cpu_for_my_deep_learning_and/,r00tdr1v3,1535025137,[removed],0,1
1151,2018-8-23,2018,8,23,20,99mqxg,[NLP] Best practices for labeling text data,https://www.reddit.com/r/MachineLearning/comments/99mqxg/nlp_best_practices_for_labeling_text_data/,nipun_sadvilkar,1535025408,[removed],1,1
1152,2018-8-23,2018,8,23,22,99ndft,More Effective Transfer Learning for NLP,https://www.reddit.com/r/MachineLearning/comments/99ndft/more_effective_transfer_learning_for_nlp/,madisonmay,1535030855,,0,1
1153,2018-8-23,2018,8,23,22,99nio4,[P] A tool to visualize what a visual recognition model is focusing on,https://www.reddit.com/r/MachineLearning/comments/99nio4/p_a_tool_to_visualize_what_a_visual_recognition/,dirtPUNK_,1535032034,,0,1
1154,2018-8-23,2018,8,23,23,99noru,Online free to use trained neural networks,https://www.reddit.com/r/MachineLearning/comments/99noru/online_free_to_use_trained_neural_networks/,John-Dun,1535033310,[removed],0,1
1155,2018-8-23,2018,8,23,23,99npmx,Neural Network Backpropagation Maths,https://www.reddit.com/r/MachineLearning/comments/99npmx/neural_network_backpropagation_maths/,Ben_09,1535033489,[removed],0,1
1156,2018-8-23,2018,8,23,23,99nrvm,"[N] Weekly Machine Learning Opensource Roundup  Aug. 23, 2018",https://www.reddit.com/r/MachineLearning/comments/99nrvm/n_weekly_machine_learning_opensource_roundup_aug/,stkim1,1535033974,,0,1
1157,2018-8-23,2018,8,23,23,99ns5t,[R] DeepLabCut: Markerless tracking of user-defined features with deep learning,https://www.reddit.com/r/MachineLearning/comments/99ns5t/r_deeplabcut_markerless_tracking_of_userdefined/,wandering_blue,1535034038,,0,1
1158,2018-8-23,2018,8,23,23,99nvr6,[P] TensorFlow: adaptive style transfer - Train ONE model for all styles !!!,https://www.reddit.com/r/MachineLearning/comments/99nvr6/p_tensorflow_adaptive_style_transfer_train_one/,zsdh123,1535034776,,0,1
1159,2018-8-23,2018,8,23,23,99o32e,Do OpenAI Five Dota 2 bots communicate?,https://www.reddit.com/r/MachineLearning/comments/99o32e/do_openai_five_dota_2_bots_communicate/,qwert7890-,1535036290,,0,1
1160,2018-8-24,2018,8,24,0,99o6f6,Jupyter Notebooks Complete Tutorial | The Best IDE for Python (Also includes some amazing extensions),https://www.reddit.com/r/MachineLearning/comments/99o6f6/jupyter_notebooks_complete_tutorial_the_best_ide/,Additional_Proof,1535036936,,0,1
1161,2018-8-24,2018,8,24,0,99o6fo,[D] Do OpenAI Five Dota 2 bots communicate?,https://www.reddit.com/r/MachineLearning/comments/99o6fo/d_do_openai_five_dota_2_bots_communicate/,qwert7890-,1535036939,,0,1
1162,2018-8-24,2018,8,24,0,99oil8,Why is a naive bayes model performing so much better than a logistic regression model for my language detection algorithm?,https://www.reddit.com/r/MachineLearning/comments/99oil8/why_is_a_naive_bayes_model_performing_so_much/,pshisscb,1535039385,"I'm building a language detector. My classes are 8 languages, 4 Germanic (English, German, Dutch, Swedish) and 4 Romance (French, Spanish, Italian, Portuguese). I chose these classes to have a good variety and yet similar enough languages so if a model can distinguish among them, I know it's doing a good job.

My training data: The same 3 wikipedia articles in each language: ""Football"" (as in soccer/association football), ""world war 2"", and ""atlantic ocean"". I chose these because all 8 languages have reasonably extensive articles for them.

My test data: From a random sentence generation website. I generated 80 sentences and put them all through google translate, so that I had each sentence in all 8 languages, which I then labeled with the 2-letter language codes (EN, DE, NL, SV, FR, ES, IT, PT). 640 test examples total.

My features: ngrams, i.e. token/word and character sequences. I gathered all word sequences in ngrams from 1-5, and all charater sequences as ngrams from 1-5. All of these serve as features in my data set. I rank them in order of total occurrences. In total it's over a million features, but for each language I cut down to the top N features occurring in each language (I experiment by changing N, usually it's between 1000-10000).

Logistic Regression gives me ~77%.
Naive Bayes gives me ~97%.

I don't know why exactly though. Is my method of feature selection and feature creation better suited for naive bayes then logreg? If so, why? I always thought naive bayes was much more random since it assumed feature occurrences for a given class were all independent of each other, which intuitively, doesn't make sense for a task like language detection. Why does logistic regression perform so poorly here? I'm using scikit-learn's prebuilt models. Can anyone shed some light on what's going on under the hood here?",0,1
1163,2018-8-24,2018,8,24,1,99oqdn,Comparing GPU Performance for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/99oqdn/comparing_gpu_performance_for_machine_learning/,bashterm,1535040904,[removed],0,1
1164,2018-8-24,2018,8,24,1,99oqfv,[D] Character RNN's non-words to words?,https://www.reddit.com/r/MachineLearning/comments/99oqfv/d_character_rnns_nonwords_to_words/,maxisawesome538,1535040914,"When making a character RNN, sometimes it'll predict strings of characters that are almost but not words. How can you convert them to nearby words? ",15,2
1165,2018-8-24,2018,8,24,1,99oyx6,OpenAI Blogs: A Micro-Event Analysis  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/99oyx6/openai_blogs_a_microevent_analysis_coinmonks/,coinmonks,1535042564,,0,1
1166,2018-8-24,2018,8,24,1,99p42x,"Undergrad here, can I get into machine learning without doing traditional practical CS courses? (like OS, Networks, etc.)",https://www.reddit.com/r/MachineLearning/comments/99p42x/undergrad_here_can_i_get_into_machine_learning/,mozartsixnine,1535043541,[removed],0,1
1167,2018-8-24,2018,8,24,2,99pjkt,Retrofitting the Womb: Deep Painterly Harmonization of Ultrasound Images,https://www.reddit.com/r/MachineLearning/comments/99pjkt/retrofitting_the_womb_deep_painterly/,RemoteCoder,1535046472,,2,6
1168,2018-8-24,2018,8,24,3,99pqoi,Fake news detector about India possible?,https://www.reddit.com/r/MachineLearning/comments/99pqoi/fake_news_detector_about_india_possible/,Herculean_breed,1535047848,[removed],0,1
1169,2018-8-24,2018,8,24,3,99pxy0,[D] Optimizing for real time object detection.,https://www.reddit.com/r/MachineLearning/comments/99pxy0/d_optimizing_for_real_time_object_detection/,dnamez_nevin,1535049232,"I am a very beginner when it comes to Machine Learning, but I have dug fairly deep into some of the concepts of using deep learning for computer vision. So while looking at some of the implementation of algorithms like the YOLO V3, they seemed to be running at very low fps. I looked at a Keras implementation of this. But my friend tried the Dark Flow implementation of the YOLO V2 and that was still only running at 11 fps. So is there any way to optimize it to run it on such hardware specs or should we always rely on high end GPUs for running them? ",10,2
1170,2018-8-24,2018,8,24,3,99py10,A better way to find AI jobs in Switzerland,https://www.reddit.com/r/MachineLearning/comments/99py10/a_better_way_to_find_ai_jobs_in_switzerland/,ai_jobsCH,1535049249,,0,2
1171,2018-8-24,2018,8,24,3,99pyb1,What algorithm for text classification?,https://www.reddit.com/r/MachineLearning/comments/99pyb1/what_algorithm_for_text_classification/,ewliang,1535049305,[removed],0,1
1172,2018-8-24,2018,8,24,3,99q2nv,What makes the difference between novice and expert in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/99q2nv/what_makes_the_difference_between_novice_and/,Mandri97,1535050169,[removed],0,1
1173,2018-8-24,2018,8,24,3,99q4dx,Using Machine Learning to automate accounting,https://www.reddit.com/r/MachineLearning/comments/99q4dx/using_machine_learning_to_automate_accounting/,defkathy,1535050514,[removed],0,1
1174,2018-8-24,2018,8,24,4,99qbs1,Deep Deterministic Policy Gradient (DDPG) algorithm in javascript.,https://www.reddit.com/r/MachineLearning/comments/99qbs1/deep_deterministic_policy_gradient_ddpg_algorithm/,cryptofanatic123,1535051926,[removed],0,1
1175,2018-8-24,2018,8,24,4,99qeh1,[D] More Effective Transfer Learning for NLP,https://www.reddit.com/r/MachineLearning/comments/99qeh1/d_more_effective_transfer_learning_for_nlp/,madisonmay,1535052461,,6,27
1176,2018-8-24,2018,8,24,4,99qkrk,[R][UC Berkeley] Everybody Dance Now,https://www.reddit.com/r/MachineLearning/comments/99qkrk/ruc_berkeley_everybody_dance_now/,downtownslim,1535053719,,79,720
1177,2018-8-24,2018,8,24,4,99ql7i,[D] What algorithm(s) for text classification?,https://www.reddit.com/r/MachineLearning/comments/99ql7i/d_what_algorithms_for_text_classification/,ewliang,1535053806,"So I found out about Kmeans a while ago but never used it in anything since I had no use for it.

I recently wanted to make a program using machine learning to help me automatically categorize stuff (with me being able to add my own category labels as a end user in the future). Sadly, I found out Kmeans is for number based data, not text.

What algorithm or algorithms do I need to create such a tool?

Let's say for the sake of discussion, I am passing in articles as a input. 1 input = 1 article. The program will do its thing, and then assign 1 label based on a list of preexisting labels or new labels I add onto the list. For instance, if the article was about Trench Composting contain the steps needed to do it and the pros and cons, the article will be labeled ""Gardening"".

Thanks!

I plan to make this using Javascript. ",10,1
1178,2018-8-24,2018,8,24,5,99qp5j,SSD based object detection,https://www.reddit.com/r/MachineLearning/comments/99qp5j/ssd_based_object_detection/,learnml,1535054575,[removed],0,1
1179,2018-8-24,2018,8,24,5,99qplg,[D] How feasible is it to create a model that gets rid of the advertisements in podcasts?,https://www.reddit.com/r/MachineLearning/comments/99qplg/d_how_feasible_is_it_to_create_a_model_that_gets/,weekdayjason,1535054659,I would assume I need access to transcriptions and time stamps. ,15,0
1180,2018-8-24,2018,8,24,6,99r7y7,[N] Revenge of the Nerds! Humans Beat Bots at Dota 2 International,https://www.reddit.com/r/MachineLearning/comments/99r7y7/n_revenge_of_the_nerds_humans_beat_bots_at_dota_2/,trcytony,1535058278,,0,1
1181,2018-8-24,2018,8,24,6,99rk1v,Its time to turn up the Ai industry with blockchain,https://www.reddit.com/r/MachineLearning/comments/99rk1v/its_time_to_turn_up_the_ai_industry_with/,AiBBio,1535060761,,0,4
1182,2018-8-24,2018,8,24,7,99rryb,"My Robot, Noodle's First Peek-a-boo With Mommy",https://www.reddit.com/r/MachineLearning/comments/99rryb/my_robot_noodles_first_peekaboo_with_mommy/,spetku,1535062392,,0,1
1183,2018-8-24,2018,8,24,7,99rs2m,Machine Learning and Artificial Intelligence in Marketing and Advertising,https://www.reddit.com/r/MachineLearning/comments/99rs2m/machine_learning_and_artificial_intelligence_in/,tanmoyray01,1535062414,,0,1
1184,2018-8-24,2018,8,24,7,99rvmk,"""A Prelude to Pyro"" - Technical ingredients for the new ""deep universal probabilistic programming language"" from Uber AI Labs",https://www.reddit.com/r/MachineLearning/comments/99rvmk/a_prelude_to_pyro_technical_ingredients_for_the/,cscherrer,1535063173,,0,1
1185,2018-8-24,2018,8,24,7,99s359,"[R] NLPs generalization problem, and how researchers are tackling it",https://www.reddit.com/r/MachineLearning/comments/99s359/r_nlps_generalization_problem_and_how_researchers/,baylearn,1535064927,,10,52
1186,2018-8-24,2018,8,24,8,99saem,Deep Learning for NLP: An Overview of Recent Trends,https://www.reddit.com/r/MachineLearning/comments/99saem/deep_learning_for_nlp_an_overview_of_recent_trends/,omarsar,1535066465,,0,1
1187,2018-8-24,2018,8,24,9,99stw4,[D] OpenAI Five loses second match at The Internationals,https://www.reddit.com/r/MachineLearning/comments/99stw4/d_openai_five_loses_second_match_at_the/,P4TR10T_TR41T0R,1535070915,&amp;#x200B;,49,65
1188,2018-8-24,2018,8,24,10,99t454,[D] What are your opinions about the first loss of OpenAI Five? Is it the weakness of deep learning?,https://www.reddit.com/r/MachineLearning/comments/99t454/d_what_are_your_opinions_about_the_first_loss_of/,TeemoLikeToEat,1535073340,"I only watched the first game. I feel that in the first 35 minutes, the AI team was doing great. However, the human team found a margin spot between &lt;totally beaten to death&gt; and &lt;running around to avoid fight while gain strength&gt;. IMO the AI team even once being cheated into thinking that they already won ... at least I feel in later game OpenAI were doing nothing. I might be wrong, but could all this happen because the model was tricked in later game? Something along this line: a deep learning model could be tricked by the data fed into it therefore has little power to adapt to new situations? Is it true?",33,0
1189,2018-8-24,2018,8,24,10,99t5m0,[P] dourflow: Yet another Keras Yolo v2 Implementation for easy use with video and webcams,https://www.reddit.com/r/MachineLearning/comments/99t5m0/p_dourflow_yet_another_keras_yolo_v2/,JuicyRacoonAnus,1535073684,"[dourflow](https://github.com/ksanjeevan/dourflow) is a fully (almost, NMS got me) Keras implementation of YOLO v2.  

There are so many others out there but I think this allows for fast iteration between training and validating (mAP is implemented, and can be monitored during training). It also has Multiclass Non Max Suppression implemented as a Keras layer which I guess is clean / faster (?). Runs at ~40fps on my GTX 1080 Ti.

This project was my first in Deep Learning, and I cleaned it up a bit in case anyone finds it useful.",0,1
1190,2018-8-24,2018,8,24,10,99t8oi,dourflow: Yet yet yet another Keras Yolo v2 Implementation. Easy to use on video and webcam!,https://www.reddit.com/r/MachineLearning/comments/99t8oi/dourflow_yet_yet_yet_another_keras_yolo_v2/,depth-for-what,1535074402,"[dourflow](https://github.com/ksanjeevan/dourflow) is a fully (almost, NMS got me) Keras implementation of YOLO v2.

There are so many others out there but I think this allows for fast iteration between training and validating (mAP is implemented, and can be monitored during training). It also has Multiclass Non Max Suppression implemented as a Keras layer which I guess is clean / faster (?). Runs at \~40fps on my GTX 1080 Ti.

This project was my first in deep learning, and I cleaned it up a bit in case anyone finds it useful.",0,1
1191,2018-8-24,2018,8,24,10,99t9t4,"I trained a model to classify popular cat breeds and analysed my moggie, apparently he has Norwegian Forest Cat and maybe Turkish Van in his lineage.",https://www.reddit.com/r/MachineLearning/comments/99t9t4/i_trained_a_model_to_classify_popular_cat_breeds/,einsidler,1535074675,,0,1
1192,2018-8-24,2018,8,24,11,99tocs,Como estudar Machine Learning - do bsico ao avanado,https://www.reddit.com/r/MachineLearning/comments/99tocs/como_estudar_machine_learning_do_bsico_ao/,dannyeuu,1535078048,,0,1
1193,2018-8-24,2018,8,24,12,99tzxk,A Deep Dive into Tensors in JavaScript  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/99tzxk/a_deep_dive_into_tensors_in_javascript_coinmonks/,coinmonks,1535080899,,0,1
1194,2018-8-24,2018,8,24,13,99ud8t,Questions for someone doing Remote Machine Learning Jobs,https://www.reddit.com/r/MachineLearning/comments/99ud8t/questions_for_someone_doing_remote_machine/,PersonalDevKit,1535084334,,0,1
1195,2018-8-24,2018,8,24,14,99uop7,How to implement the elastic weight consolidation in keras,https://www.reddit.com/r/MachineLearning/comments/99uop7/how_to_implement_the_elastic_weight_consolidation/,decade5d,1535087575,[removed],0,1
1196,2018-8-24,2018,8,24,14,99uxlm,A weekend with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/99uxlm/a_weekend_with_deep_learning/,akshad_GL,1535090349,[removed],0,1
1197,2018-8-24,2018,8,24,16,99vaax,Could anyone give me some ideas about how to prove a reconstructed image from given features is its best reconstruction? Or how to evaluate the reconstruction?,https://www.reddit.com/r/MachineLearning/comments/99vaax/could_anyone_give_me_some_ideas_about_how_to/,xymeng,1535094482,[removed],0,1
1198,2018-8-24,2018,8,24,17,99vrav,Pressure Booster System - Enginature India,https://www.reddit.com/r/MachineLearning/comments/99vrav/pressure_booster_system_enginature_india/,enginatures,1535100391,,0,1
1199,2018-8-24,2018,8,24,17,99vt56,Automation Engineering Solutions Automation Services Canada | Robot Panel welding,https://www.reddit.com/r/MachineLearning/comments/99vt56/automation_engineering_solutions_automation/,rickbanklaw2,1535101056,,0,1
1200,2018-8-24,2018,8,24,18,99w06n,[D]Starter on Safe Reinforcement Learning - Approaches and Challenges,https://www.reddit.com/r/MachineLearning/comments/99w06n/dstarter_on_safe_reinforcement_learning/,harshitsikchi,1535103429,"[https://medium.com/@harshitsikchi/towards-safe-reinforcement-learning-88b7caa5702e](https://medium.com/@harshitsikchi/towards-safe-reinforcement-learning-88b7caa5702e)

A starter blog on safe reinforcement learning with some of the recent approaches and theory. Any ideas are welcome! ",0,2
1201,2018-8-24,2018,8,24,18,99w3ex,A Brief Introduction to Prototype Development,https://www.reddit.com/r/MachineLearning/comments/99w3ex/a_brief_introduction_to_prototype_development/,rickbanklaw2,1535104538,,0,1
1202,2018-8-24,2018,8,24,19,99w7fx,horizontal 4 side seal facial mask packing machine,https://www.reddit.com/r/MachineLearning/comments/99w7fx/horizontal_4_side_seal_facial_mask_packing_machine/,chinamachine,1535105764,,0,1
1203,2018-8-24,2018,8,24,19,99wa2e,Predicting the profit a company using the expenditures and R&amp;D Reports|Linear Regression,https://www.reddit.com/r/MachineLearning/comments/99wa2e/predicting_the_profit_a_company_using_the/,pooja307,1535106584,,0,1
1204,2018-8-24,2018,8,24,19,99wcw0,Pipe Cladding Straight Pipe BP Automation,https://www.reddit.com/r/MachineLearning/comments/99wcw0/pipe_cladding_straight_pipe_bp_automation/,rickbanklaw2,1535107408,,0,1
1205,2018-8-24,2018,8,24,19,99wf2o,Does running a Decision Tree classifier several times help?,https://www.reddit.com/r/MachineLearning/comments/99wf2o/does_running_a_decision_tree_classifier_several/,funnyornotletitrot,1535108114,[removed],0,1
1206,2018-8-24,2018,8,24,20,99whqh,Starter on Safe Reinforcement Learning  Approaches,https://www.reddit.com/r/MachineLearning/comments/99whqh/starter_on_safe_reinforcement_learning_approaches/,harshitsikchi,1535108902,,0,1
1207,2018-8-24,2018,8,24,20,99wqmf,[D] What are excellent tools to extract Text Lines from scanned pages?,https://www.reddit.com/r/MachineLearning/comments/99wqmf/d_what_are_excellent_tools_to_extract_text_lines/,crytoy,1535111435,I am looking for tools and methods that can detect and extract text-lines from scanned pages.,7,0
1208,2018-8-24,2018,8,24,21,99wt6j,[D]Starter on Safe Reinforcement Learning  Approaches,https://www.reddit.com/r/MachineLearning/comments/99wt6j/dstarter_on_safe_reinforcement_learning_approaches/,harshitsikchi,1535112124,,0,1
1209,2018-8-24,2018,8,24,21,99ww02,What is label smearing,https://www.reddit.com/r/MachineLearning/comments/99ww02/what_is_label_smearing/,hanchi1017,1535112858,[removed],0,1
1210,2018-8-24,2018,8,24,21,99wxnl,How is Machine Learning Helping Businesses Grow?,https://www.reddit.com/r/MachineLearning/comments/99wxnl/how_is_machine_learning_helping_businesses_grow/,imarticus_nirmal,1535113263,,0,1
1211,2018-8-24,2018,8,24,21,99wz1p,"A question about the squeeze-and-excitation networks. (SENet,2017 ImageNet champion)",https://www.reddit.com/r/MachineLearning/comments/99wz1p/a_question_about_the_squeezeandexcitation/,wchenchen30,1535113592,[removed],0,1
1212,2018-8-24,2018,8,24,21,99x2yv,Translating ONNX to SMT-Lib.,https://www.reddit.com/r/MachineLearning/comments/99x2yv/translating_onnx_to_smtlib/,Hizachi,1535114536,[removed],1,1
1213,2018-8-24,2018,8,24,22,99xarb,What are The Skills You Need to Become a Machine Learning Engineer?,https://www.reddit.com/r/MachineLearning/comments/99xarb/what_are_the_skills_you_need_to_become_a_machine/,imarticus_nirmal,1535116383,,0,1
1214,2018-8-24,2018,8,24,22,99xds4,Everything You Need To Know About Machine Learning and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/99xds4/everything_you_need_to_know_about_machine/,imarticus_nirmal,1535117059,,0,1
1215,2018-8-24,2018,8,24,23,99xoh0,Is ASIC going to Win the Artificial Intelligence Race?,https://www.reddit.com/r/MachineLearning/comments/99xoh0/is_asic_going_to_win_the_artificial_intelligence/,stormysharad1,1535119489,,0,1
1216,2018-8-24,2018,8,24,23,99y28b,[D] OpenAI Gym poorly maintained,https://www.reddit.com/r/MachineLearning/comments/99y28b/d_openai_gym_poorly_maintained/,rikkajounin,1535122370,"Maybe it's an issue with OpenAI repositories in general but i think that, given the popularity of the repo  (more than 10 thousand stars) and the increase in interest in reinforcement learning in general,  OpenAI should think of ways to better maintain and improve gym. The [github page](https://github.com/openai/gym) has now several open issues and pull requests, some proposing very simple and useful changes, but the developers give very little feedback.

&amp;#x200B;

I think that it's wonderful to have a single place to handle the environments interface and with some basic environments implemented, but I think that such place should be better maintained, more complete and more efficient than is gym now.

&amp;#x200B;

Let me know what you think in the comments. I hope that someone at OpenAI will see this post and do something about this issue. A good start would be to check and eventually merge more often the pull requests.",28,149
1217,2018-8-25,2018,8,25,0,99y8n1,Are Decision Trees Robust to Outliers,https://www.reddit.com/r/MachineLearning/comments/99y8n1/are_decision_trees_robust_to_outliers/,funnyornotletitrot,1535123653,[removed],0,1
1218,2018-8-25,2018,8,25,1,99yv1d,Chatterbot - GUI front-end anyone?,https://www.reddit.com/r/MachineLearning/comments/99yv1d/chatterbot_gui_frontend_anyone/,MikeTheWatchGuy,1535127970,[removed],0,1
1219,2018-8-25,2018,8,25,1,99ywcq,Can anyone suggest a gaming project with an AI agent ?,https://www.reddit.com/r/MachineLearning/comments/99ywcq/can_anyone_suggest_a_gaming_project_with_an_ai/,sbhyd,1535128238,[removed],0,1
1220,2018-8-25,2018,8,25,3,99zt19,Final Year Project,https://www.reddit.com/r/MachineLearning/comments/99zt19/final_year_project/,Saleh_Ahmad,1535134601,"Hello guys! I am doing a project which is a converter device for speech impaired people through image processing. would you guys spare some time to fill up the survey for it? and also give some suggestions which machine learning model best fits the sign language gestures.

[https://docs.google.com/forms/d/e/1FAIpQLSf3HQqxeQNTAPrJXTqOKyfNQrdtXkXGMFMCbTVVDxgKCetEbQ/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSf3HQqxeQNTAPrJXTqOKyfNQrdtXkXGMFMCbTVVDxgKCetEbQ/viewform?usp=sf_link)",0,1
1221,2018-8-25,2018,8,25,3,99zzz3,Detailed Notes from UCB CS 188x: Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/99zzz3/detailed_notes_from_ucb_cs_188x_artificial/,deathbullet,1535136010,,0,1
1222,2018-8-25,2018,8,25,3,9a05ff,[R] Generating financial data for portfolio simulations: WGAN-GP shows promise (with a little help from GAN tips &amp; tricks).,https://www.reddit.com/r/MachineLearning/comments/9a05ff/r_generating_financial_data_for_portfolio/,QuantMountain,1535137116,,6,23
1223,2018-8-25,2018,8,25,4,9a0e55,[Paper] Review of GoogLeNet (Inception v1) Winner of ILSVLC 2014 (Image Classification),https://www.reddit.com/r/MachineLearning/comments/9a0e55/paper_review_of_googlenet_inception_v1_winner_of/,coinmonks,1535138822,,0,1
1224,2018-8-25,2018,8,25,4,9a0k2m,[D] Utilizing NVlink for multi-gpu training with tensorflow,https://www.reddit.com/r/MachineLearning/comments/9a0k2m/d_utilizing_nvlink_for_multigpu_training_with/,realHansen,1535140051,"Hi guys,

with nvidias new consumer line supporting NVLink I was wondering if the common frameworks - especially tensorflow - support unified memory. I'd love a scenario where I have two 2080s interconnected with NVLink show up as one big 16GB virtual device, instead of having to manually place variables and ops on the two gpus and cpu, as it has been the case thus far. Would something like that be possible?",5,21
1225,2018-8-25,2018,8,25,5,9a11ba,Enforcing Lipschitz continuity for restricting projections,https://www.reddit.com/r/MachineLearning/comments/9a11ba/enforcing_lipschitz_continuity_for_restricting/,kamranjanjua,1535143593,[removed],0,1
1226,2018-8-25,2018,8,25,5,9a12mf,"Image Recognition: My Robot, Noodle Thinks anyone Wearing my Glasses is Me",https://www.reddit.com/r/MachineLearning/comments/9a12mf/image_recognition_my_robot_noodle_thinks_anyone/,spetku,1535143874,,0,1
1227,2018-8-25,2018,8,25,7,9a1vty,Alternatives to state-of-the-art CNNs for Image Classification?,https://www.reddit.com/r/MachineLearning/comments/9a1vty/alternatives_to_stateoftheart_cnns_for_image/,AdventurousLimit,1535150079,[removed],0,1
1228,2018-8-25,2018,8,25,9,9a2s8f,[D] What are some best practises to avoid sensitivity to random initial parameters?,https://www.reddit.com/r/MachineLearning/comments/9a2s8f/d_what_are_some_best_practises_to_avoid/,CommunismDoesntWork,1535157803,"I'm running an image through a standard series of convolutions, and then when it's 'long and skinny', I run it through a series of deconvolutions/transpose convolutions. I also have some short-circuits between deconvolution layers thrown in there every few layers.

When I run the model, I can tell within 30 secs whether or not it ran into a local minima. It seems like the problem is that the deconvolution layers are completely ignoring the convolutional layers. It's almost as if the layer between the last convolution and the first deconvolution is all 0s.

Sometimes it works though, and when it works it works great. I have also found specific seeds where it works fine.

Also, every layer uses relu, with a final tanh output. Also I added dropouts between every other layer. Batch normalization doesn't seems to change anything whatsoever.

Any  advice?",20,15
1229,2018-8-25,2018,8,25,12,9a3odo,Genetic algorithms with constraints,https://www.reddit.com/r/MachineLearning/comments/9a3odo/genetic_algorithms_with_constraints/,bbzinhodomal,1535166145,[removed],0,1
1230,2018-8-25,2018,8,25,12,9a3ug5,Upscaling game textures,https://www.reddit.com/r/MachineLearning/comments/9a3ug5/upscaling_game_textures/,shayolden,1535167746,[removed],0,1
1231,2018-8-25,2018,8,25,14,9a4jqh,"Hi, everyone, I'm looking into GANs right now and I came across a problem which Ive marked down in the picture below. I am confused about how does these two procedures go through? Can someone else illustrate it for me. Thanks",https://www.reddit.com/r/MachineLearning/comments/9a4jqh/hi_everyone_im_looking_into_gans_right_now_and_i/,lonioi,1535175185,,1,1
1232,2018-8-25,2018,8,25,15,9a4qp8,Temporally Stable Spatial Recurrent Denoising Filters For Real-time Raytracing Scenes - Nvidia (2017),https://www.reddit.com/r/MachineLearning/comments/9a4qp8/temporally_stable_spatial_recurrent_denoising/,ilikepancakez,1535177549,,0,1
1233,2018-8-25,2018,8,25,15,9a4xyh,[P] Intro to TensorFlow.js with Nick Kreeger,https://www.reddit.com/r/MachineLearning/comments/9a4xyh/p_intro_to_tensorflowjs_with_nick_kreeger/,utopiah,1535180137,,0,82
1234,2018-8-25,2018,8,25,17,9a58o5,[D] Could you help me understand the math in this paper?,https://www.reddit.com/r/MachineLearning/comments/9a58o5/d_could_you_help_me_understand_the_math_in_this/,kugkfokj,1535184162,"I finished reading [End-to-End Multi-View Networks for Text Classification](https://arxiv.org/abs/1704.05907) by Guo et al. (2017). The paper is only a few pages long and it's fairly intuitive. However, the equations are not described very well IMHO and I'm struggling to understand them all.

&amp;#x200B;

Specifically:

1. What does B\[h:h\] means in (1) and (3)? Is it a vector or a matrix?
2. Are the s+ and views vectors or matrices?
3. In (5) there's a concatenation, is this vertical or horizontal?",7,4
1235,2018-8-25,2018,8,25,17,9a5fjn,CPU RAM vs GPU VRAM usage.,https://www.reddit.com/r/MachineLearning/comments/9a5fjn/cpu_ram_vs_gpu_vram_usage/,multiks2200,1535186893,"I was wondering how does the typical CPU RAM to VRAM pipeline looks like? Let's say I load a model to train, how does the data transfer is performed ? Is it HDD -&gt; RAM -&gt; VRAM or  CPU transfers the data straight from HDD -&gt; VRAM ? If RAM is involved, does that mean there is redundant data stored in RAM simply because it is required for filling up the VRAM?",0,1
1236,2018-8-25,2018,8,25,17,9a5g30,CPU for ML - AMD or Intel?,https://www.reddit.com/r/MachineLearning/comments/9a5g30/cpu_for_ml_amd_or_intel/,lelijan,1535187134,[removed],0,1
1237,2018-8-25,2018,8,25,18,9a5mpy,[P] Tensorflow slim implementation of Convolutional Block Attention Module (CBAM),https://www.reddit.com/r/MachineLearning/comments/9a5mpy/p_tensorflow_slim_implementation_of_convolutional/,kobiso,1535189780,,0,1
1238,2018-8-25,2018,8,25,19,9a5req,Bridge saw for granite,https://www.reddit.com/r/MachineLearning/comments/9a5req/bridge_saw_for_granite/,marblesawlosangeles,1535191626,[removed],0,1
1239,2018-8-25,2018,8,25,19,9a5uzi,AI Weekly 25 August 2018,https://www.reddit.com/r/MachineLearning/comments/9a5uzi/ai_weekly_25_august_2018/,TomekB,1535192987,,0,1
1240,2018-8-25,2018,8,25,20,9a6717,How is Machine learning and artificial intelligence useful in Civil industry and which are the companies working on it?,https://www.reddit.com/r/MachineLearning/comments/9a6717/how_is_machine_learning_and_artificial/,rishiikesh2,1535197397,,0,1
1241,2018-8-25,2018,8,25,20,9a678h,Help with neural network aiming to predict material stress values,https://www.reddit.com/r/MachineLearning/comments/9a678h/help_with_neural_network_aiming_to_predict/,blythmar,1535197467,"Mechanical engineer here. I'm working on a project that aims to use machine learning in the design of a novel stress sensor. Through various tests, a series of 97 measurements are taken from this sensor. A separate calibrated sensor is used to measure the target value. A total of 1200 measurements have been taken at different load steps (actually 6000 measurements total - 5 at each loadstep - but I average them). I've implemented a neural network in Keras to map the inputs to the output, but can achieve only about 60% of values within +/- 10 MPa on the test set. The accuracy on the training set is much higher, indicating overfitting. I've implemented dropout and regularisation, as well as reducing the number of hidden layers and neurons per layer, but can't beat the 60% accuracy value. The optimum model has 2 hidden layers of 50 neurons (with ReLU activation) with 1 output layer (with linear activation). I use MSE as the loss and RMSprop as the optimiser. I normalise the inputs and validate on a test set of 10%. Is there something I'm missing, or any other techniques that I could implement?",0,1
1242,2018-8-25,2018,8,25,21,9a6b2t,How is machine learning implemented in civil industry and the companies working with machine learning techniques.,https://www.reddit.com/r/MachineLearning/comments/9a6b2t/how_is_machine_learning_implemented_in_civil/,rishiikesh2,1535198717,,0,1
1243,2018-8-25,2018,8,25,21,9a6dub,How useful is machine learning in civil industry and the companies working with machine learning techniques?,https://www.reddit.com/r/MachineLearning/comments/9a6dub/how_useful_is_machine_learning_in_civil_industry/,rishiikesh2,1535199591,,0,1
1244,2018-8-25,2018,8,25,21,9a6gk1,How useful is machine learning in civil industry and the companies working with machine learning techniques?,https://www.reddit.com/r/MachineLearning/comments/9a6gk1/how_useful_is_machine_learning_in_civil_industry/,rishiikesh2,1535200420,,0,1
1245,2018-8-25,2018,8,25,21,9a6isn,How machine learning is used in construction industry and what are the companies employing AI and machine learning?,https://www.reddit.com/r/MachineLearning/comments/9a6isn/how_machine_learning_is_used_in_construction/,rishiikesh2,1535201138,,0,1
1246,2018-8-25,2018,8,25,22,9a6tju,How do I as a beginner in ML with an undergrad degree(CS) start reading and implementing papers published on arXiv.org?,https://www.reddit.com/r/MachineLearning/comments/9a6tju/how_do_i_as_a_beginner_in_ml_with_an_undergrad/,ML-newb,1535204176,[removed],0,1
1247,2018-8-25,2018,8,25,22,9a6wk8,How is machine learning and AI used in civil industry and which are the companies employing AI in practical work?,https://www.reddit.com/r/MachineLearning/comments/9a6wk8/how_is_machine_learning_and_ai_used_in_civil/,rishiikesh2,1535204992,"Machine learning and AI have made their way into almost all fields from agriculture to food to medicine,civil also has its share of AI involved in it. They are involved in risk mitigation,quantity and quality analysis,composition of the substance is also supervised using AI. Safety of the workers are also taken into account by machine learning techniques where they work with the historic data and bring about a solution for their problems and supervise the implementation of the workers safety.

University like Auto-desk work with some construction companies to estimate their work and foresee the challenges ahead in their construction process,they calculate the risks and the steps to avoid them,the estimation of work on a daily basis and implementation of the plans are performed using AI.They are working also on risk mitigation and safety factor of the workers,enabling a safe and calculative construction site.

X-materials is US based company who provides building blocks using AI and machine learning techniques,these block may replace the conventional brick and stones and provide a much more durable product for the future in an Eco-friendly manner. Their building block can be customized as per as their geographic region and are produced in a much faster manner.To cover the aspects of design they can be molded into any shape.They are also a good substitute for flooring materials like marble and granite's,ornamental products  are made using x-materials as an alternate for ceramics.   r/https://xmat.io ",0,1
1248,2018-8-25,2018,8,25,23,9a6zt6,[R] Style Transfer: One Model for All Styles!,https://www.reddit.com/r/MachineLearning/comments/9a6zt6/r_style_transfer_one_model_for_all_styles/,zsdh123,1535205831,,0,1
1249,2018-8-25,2018,8,25,23,9a72ak,Tuning parameters in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9a72ak/tuning_parameters_in_reinforcement_learning/,steamingironkettle,1535206469,[removed],0,1
1250,2018-8-25,2018,8,25,23,9a78f8,"Joel Grus: slides for my ""I Don't Like Notebooks"" #JupyterCon talk",https://www.reddit.com/r/MachineLearning/comments/9a78f8/joel_grus_slides_for_my_i_dont_like_notebooks/,adammathias,1535207975,,0,1
1251,2018-8-26,2018,8,26,0,9a7h96,[P] OpenPose in TensorFlow (wip),https://www.reddit.com/r/MachineLearning/comments/9a7h96/p_openpose_in_tensorflow_wip/,zsdh123,1535210078,,0,1
1252,2018-8-26,2018,8,26,0,9a7ibz,How can i do TFIDF Weighting With Multiple Categorized Documents,https://www.reddit.com/r/MachineLearning/comments/9a7ibz/how_can_i_do_tfidf_weighting_with_multiple/,kemalcankara,1535210330,[removed],0,1
1253,2018-8-26,2018,8,26,0,9a7la4,Deep Learning book summaries,https://www.reddit.com/r/MachineLearning/comments/9a7la4/deep_learning_book_summaries/,amandalmia,1535211020,[removed],0,1
1254,2018-8-26,2018,8,26,0,9a7pnz,An O(N) Sorting Algorithm: Machine Learning Sort,https://www.reddit.com/r/MachineLearning/comments/9a7pnz/an_on_sorting_algorithm_machine_learning_sort/,theainerd,1535212009,,10,12
1255,2018-8-26,2018,8,26,0,9a7t4s,Busting Moves with DanceNet AI,https://www.reddit.com/r/MachineLearning/comments/9a7t4s/busting_moves_with_dancenet_ai/,gwen0927,1535212774,,0,1
1256,2018-8-26,2018,8,26,1,9a7usg,[D] I Don't Like Notebooks,https://www.reddit.com/r/MachineLearning/comments/9a7usg/d_i_dont_like_notebooks/,rasmii,1535213118,,119,339
1257,2018-8-26,2018,8,26,1,9a7vs6,"[D] Resources for recent and ""canon"" DL papers?",https://www.reddit.com/r/MachineLearning/comments/9a7vs6/d_resources_for_recent_and_canon_dl_papers/,CSartistInTraining,1535213337,"I'm looking to read more DL papers from two broad categories: 
Recent papers with promising/important results, 

And papers from the last 5 years or so that form a sort of ""canon"" of important papers in the field that most DL folks know about (e.g., the batch norm paper, deep image prior, capsule network paper, etc).

There are a lot of good resources for the first category including this sub, Brundage-bot, etc. But I would be happy to hear additional suggestions. What do you use?

For the second category, I don't really know of any resources. Are there any lists that approximately comprise the DL canon?",4,5
1258,2018-8-26,2018,8,26,1,9a82w1,Beginner Question: Should I buy an Nvidia GTX 1050ti laptop or should I use Google Colab?,https://www.reddit.com/r/MachineLearning/comments/9a82w1/beginner_question_should_i_buy_an_nvidia_gtx/,pranjal_22,1535214931,[removed],0,1
1259,2018-8-26,2018,8,26,2,9a8ard,[N] Pioneer (previously AI Grant) is handing out $5k grants for awesome projects in any area,https://www.reddit.com/r/MachineLearning/comments/9a8ard/n_pioneer_previously_ai_grant_is_handing_out_5k/,RCostaReis,1535216659,,0,13
1260,2018-8-26,2018,8,26,2,9a8kq0,"[D] Anyone going to ""Machine Learning at Google Cloud""?",https://www.reddit.com/r/MachineLearning/comments/9a8kq0/d_anyone_going_to_machine_learning_at_google_cloud/,carmichael561,1535218776,"I got an email advertising this event:
&gt; Youre invited to attend the Machine Learning at Google Cloud event on Wednesday, September 12th, 2018 from 5:15 PM - 9:00 PM PT at the Google office in Sunnyvale. 
&gt;
&gt;The event will kick off with a welcome and keynote from Cloud leaders, Jia Li and Hussein Mehanna, followed by a Q&amp;A panel that will give you an in-depth insight into Cloud's Machine Learning industry and research efforts. This will be followed by a networking social where you will have the chance to chat with some of the leading Machine Learning engineers in the Cloud industry. And of course, there will be plenty of food, drinks, and swag for you to enjoy!

I've never been to one of these events before. Are they any good?",1,7
1261,2018-8-26,2018,8,26,3,9a94c9,/usr/local/bin/python3: No module named pip Error on or near line 85; exiting with status,https://www.reddit.com/r/MachineLearning/comments/9a94c9/usrlocalbinpython3_no_module_named_pip_error_on/,Ankit-gupta2257074,1535222912,"

(ankit) ankit@ankit-HP-Notebook:~/intel/computer_vision_sdk_2018.3.343/deployment_tools/model_optimizer/install_prerequisites$ sudo ./install_prerequisites.sh Hit:1 https://download.docker.com/linux/ubuntu xenial InRelease Hit:2 http://in.archive.ubuntu.com/ubuntu xenial InRelease
Get:3 http://security.ubuntu.com/ubuntu xenial-security InRelease [107 kB]
Hit:4 http://archive.canonical.com xenial InRelease
Get:5 http://in.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]
Get:6 http://in.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]
Get:7 http://in.archive.ubuntu.com/ubuntu xenial-proposed InRelease [260 kB] Fetched 583 kB in 2s (287 kB/s)
Reading package lists... Done Building dependency tree
Reading state information... Done 21 packages can be upgraded. Run 'apt list --upgradable' to see them. Reading package lists... Done Building dependency tree
Reading state information... Done python3-venv is already the newest version (3.5.1-3). libgfortran3 is already the newest version (5.4.0-6ubuntu1~16.04.10). python3-pip is already the newest version (8.1.1-2ubuntu0.4). 0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded. /usr/local/bin/python3: No module named pip Error on or near line 85; exiting with status 1

i installing intel openvino toolkit in which i configure the model optimizer so how can i solve it ?

i have tried many things

thank you........................
apt package-management intel python3 jupyter
shareeditdeleteflag
",2,1
1262,2018-8-26,2018,8,26,4,9a9i56,[R] Temporally stable Recurrent Autoencoder Denoising Filters for Real Time Ray Tracing Scenes using RTX.,https://www.reddit.com/r/MachineLearning/comments/9a9i56/r_temporally_stable_recurrent_autoencoder/,ilikepancakez,1535225851,,2,60
1263,2018-8-26,2018,8,26,5,9a9qlm,"[D] ""Beyond the pixel plane: sensing and learning in 3D""",https://www.reddit.com/r/MachineLearning/comments/9a9qlm/d_beyond_the_pixel_plane_sensing_and_learning_in/,gwern,1535227739,,5,21
1264,2018-8-26,2018,8,26,6,9aacgw,"Does it take an ""ear"" to tune hyperparameters?",https://www.reddit.com/r/MachineLearning/comments/9aacgw/does_it_take_an_ear_to_tune_hyperparameters/,CosmicPennyworth,1535232786,"I'm thinking of an old violin instructor of mine who would tune my violin for me before each lesson. I didn't know how to tune it for myself. To me it just sounded like random noise. But years of experience gave him the ear for pitch and he was able to tune a violin with ease, in seconds. Meanwhile I wouldn't have even known where to start, and I probably wouldn't have been able to tell whether my violin sounded bad because I was playing it badly or because it was out of tune.

So is tuning hyperparameters like tuning a violin? If so, how much of learning machine learning is learning that sense of pitch? Are there any strong techniques for automatically tuning hyperparameters that don't require you to tune hyperhyperparameters?",0,1
1265,2018-8-26,2018,8,26,7,9aal1r,"""Addressing these anxieties about technology head-on, Artificial, The Podcast questions whether humans and robots can work together. It follows the progression of a relationship between Toronto-based comedian Ana-Marija Stojic and her co-host, a real functioning Artificial Intelligence robot.""",https://www.reddit.com/r/MachineLearning/comments/9aal1r/addressing_these_anxieties_about_technology/,yimmy51,1535234727,,0,1
1266,2018-8-26,2018,8,26,7,9aapi8,Coffee mug designed by AI. Thoughts?,https://www.reddit.com/r/MachineLearning/comments/9aapi8/coffee_mug_designed_by_ai_thoughts/,zbnone,1535235738,"I am playing around with the idea of starting an AI Coffee Mug online store, let me explain:

The plan is to sell coffee mugs designed by AI. My first mug would be only text based, the user could choose the first couple of words written on the mug and my AI would continue the text in the style of e.g. Shakespeare, a favorite novel (harry potter, to kill a mockingbird, etc), a character from a movie and more, you get the gist. This text would then be written on the mug in a certain design scheme.



Sample images with one prototype scheme:

[https://imgur.com/a/xsfb4CT](https://imgur.com/a/xsfb4CT)

[https://imgur.com/a/SkgDNKp](https://imgur.com/a/SkgDNKp)

[https://imgur.com/a/9JGnJzf](https://imgur.com/a/9JGnJzf)



What I am interested in are your thoughts about such a product, are you interested, would you buy that, do you know of a competitor, more ideas for mug designs, etc?



I am looking forward to your answers.",0,1
1267,2018-8-26,2018,8,26,9,9abfp1,Simple neural net question from coursera neural net course,https://www.reddit.com/r/MachineLearning/comments/9abfp1/simple_neural_net_question_from_coursera_neural/,deejay217,1535242273,[removed],0,1
1268,2018-8-26,2018,8,26,9,9abm77,[R] [1802.05844] A Unified View of Causal and Non-causal Feature Selection [2018],https://www.reddit.com/r/MachineLearning/comments/9abm77/r_180205844_a_unified_view_of_causal_and/,AforAnonymous,1535243839,,1,10
1269,2018-8-26,2018,8,26,9,9abmmw,[R] The Polynomial Volume Law of Complex Networks in the Context of Local and Global Optimization [2018],https://www.reddit.com/r/MachineLearning/comments/9abmmw/r_the_polynomial_volume_law_of_complex_networks/,AforAnonymous,1535243947,,0,10
1270,2018-8-26,2018,8,26,9,9abqvx,"[P] PyTorch Implementation of ""Learning Longer-term Dependencies in RNNs with Auxiliary Losses""",https://www.reddit.com/r/MachineLearning/comments/9abqvx/p_pytorch_implementation_of_learning_longerterm/,BelePi93,1535245004,,1,1
1271,2018-8-26,2018,8,26,10,9ac1ia,[D] Source separatio?,https://www.reddit.com/r/MachineLearning/comments/9ac1ia/d_source_separatio/,garfledluvslasnaga,1535247829,"Hi!

My project requires collecting audio from a nature setting, and using machine learning to isolate bird calls amongst the noise. Does anyone have any recommendations with respect to how I should go about doing this? Thank you!",0,1
1272,2018-8-26,2018,8,26,13,9ad53j,Top 8 Performance Metrics One Should Know,https://www.reddit.com/r/MachineLearning/comments/9ad53j/top_8_performance_metrics_one_should_know/,kalsi_sachin,1535258809,,0,1
1273,2018-8-26,2018,8,26,14,9adcb4,Side Project Ideas,https://www.reddit.com/r/MachineLearning/comments/9adcb4/side_project_ideas/,vmfhrmfoald,1535261152,"Hi, what are some AI side projects can a 2nd/3rd year cs student can try?
I almost have no experiences in this area but I love learning new things on my own and I'd love a challenge. 
(I would like to write it in C++)
Any ideas?",0,1
1274,2018-8-26,2018,8,26,15,9adjkv,Need some insights for getting a Master in Statistics vs Data Science.,https://www.reddit.com/r/MachineLearning/comments/9adjkv/need_some_insights_for_getting_a_master_in/,currentaccount123,1535263722,[removed],0,1
1275,2018-8-26,2018,8,26,17,9ae2du,How does Machine Learning work? (x-post /r/VoiceTech),https://www.reddit.com/r/MachineLearning/comments/9ae2du/how_does_machine_learning_work_xpost_rvoicetech/,wootnoob,1535271078,,0,1
1276,2018-8-26,2018,8,26,18,9aecly,"I tried my best, would love feedback!",https://www.reddit.com/r/MachineLearning/comments/9aecly/i_tried_my_best_would_love_feedback/,VCubingX,1535275305,,0,1
1277,2018-8-26,2018,8,26,19,9aen6q,Deep Dive in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9aen6q/deep_dive_in_machine_learning/,RamboRedDevil,1535279598,[removed],0,1
1278,2018-8-26,2018,8,26,19,9aeolo,Need help choosing my final year project related to Multi-Agent Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9aeolo/need_help_choosing_my_final_year_project_related/,nadee_writer,1535280173,[removed],0,1
1279,2018-8-26,2018,8,26,20,9aesse,Machine Learning Open Source of the Month (v.Aug 2018),https://www.reddit.com/r/MachineLearning/comments/9aesse/machine_learning_open_source_of_the_month_vaug/,kumeralex,1535281789,,0,1
1280,2018-8-26,2018,8,26,21,9af2yt,The prior term in the lower bound for variational auto encoders,https://www.reddit.com/r/MachineLearning/comments/9af2yt/the_prior_term_in_the_lower_bound_for_variational/,n191091,1535285372,[removed],0,1
1281,2018-8-26,2018,8,26,21,9af564,I don't understand how to practice implementing models,https://www.reddit.com/r/MachineLearning/comments/9af564/i_dont_understand_how_to_practice_implementing/,Cyclonedx,1535286072,"Spent the entirety of today watching various videos on implementations of random forests from fast.ai, siraj and other places. I really want to try implementing one myself using a random data set online but I have no clue where to start.

A few videos have used Jupyter but it looks extremely confusing to set up and I think it's paid. Is there not a simple IDE I can install on my macbook pro and start coding like a normal python code?",0,1
1282,2018-8-26,2018,8,26,22,9afmj4,Looking for a Java Framework with Machine Learning understanding chaos in chaos theory,https://www.reddit.com/r/MachineLearning/comments/9afmj4/looking_for_a_java_framework_with_machine/,PFPersonality,1535291119,[removed],0,1
1283,2018-8-26,2018,8,26,23,9afqka,[D] Using a trained GAN discriminator for one-class estimation or classification,https://www.reddit.com/r/MachineLearning/comments/9afqka/d_using_a_trained_gan_discriminator_for_oneclass/,Phosphoglucomutase,1535292204,"I have created a WGAN neural network with Tensorflow, which consists of two layer dense disciminator and two layer dense generator. I have trained the network against one Iris dataset species. In other words, the generator can now estimate the probability distribution of one certain species. I am very happy with the generator result. Since I use WGAN, discriminator's (=critic) output is linear. Other layers are leaky relu's in both networks. 

However, is it possible to use the trained discriminator to estimate or classify, if given sample belongs to the target species distribution? This is not a case now. If I let the discriminator to evaluate all the Iris dataset, the discriminator's output values for the target dataset are not the highest, but not the lowest either. It also gives inconsistent values. Some target species class output values can be high. In other words, I want the discriminator to give reasonable estimate, if a given sample belongs to to trained data distribution. I don't need real probabilities or absolute accuracy, but rather estimates, where great output value for input means ""definitely belongs to training data distribution"".

Somewhere I have read that the inconsistency of the discriminator is normal and instead of the discriminator I should use the generator for estimation. Is this information correct or not? If it's, how could the generator be used for that?
https://imgur.com/a/aBPHJph",13,39
1284,2018-8-26,2018,8,26,23,9afzj0,[P] Machine Learning Open Source of the Month (v.Aug 2018),https://www.reddit.com/r/MachineLearning/comments/9afzj0/p_machine_learning_open_source_of_the_month_vaug/,kumeralex,1535294392,,0,1
1285,2018-8-26,2018,8,26,23,9afzx2,"[P] Automatic Speech Recognition Data Collection with Youtube V3 API, Mask-RCNN and Google Vision API",https://www.reddit.com/r/MachineLearning/comments/9afzx2/p_automatic_speech_recognition_data_collection/,steeveHuang,1535294488,,0,1
1286,2018-8-26,2018,8,26,23,9ag3s0,"[R] Simple guide to Neural Arithmetic Logic Units (NALU): Explanation, Intuition and Code",https://www.reddit.com/r/MachineLearning/comments/9ag3s0/r_simple_guide_to_neural_arithmetic_logic_units/,fooboss,1535295400,,0,1
1287,2018-8-27,2018,8,27,1,9ago5u,eTextbooks improve learning and raise grades,https://www.reddit.com/r/MachineLearning/comments/9ago5u/etextbooks_improve_learning_and_raise_grades/,VidrihMarko,1535299907,,0,1
1288,2018-8-27,2018,8,27,1,9ah007,[R] Causality and function approximations,https://www.reddit.com/r/MachineLearning/comments/9ah007/r_causality_and_function_approximations/,chpr,1535302462,"Motivated by the recent release of Judea Pearl's Book of Why, I started to sort my notes on causality and write some parts down in a more structured way. In doing so, I stumbled over a question I bumped into repeatedly in past projects: The simplest causal system is one in which features determine actions and the combination of features and actions determine the outcome. One popular approach for this system is to apply inverse probability of treatment weighting. My intuition always was that this step should not be necessary. After some research, the answer is a resounding ""Yes, but ..."".

In short: no causal treatment is necessary for this system according to theory.  However, causal treatment becomes important when applying function approximations.

I typed up my findings here: [https://cprohm.de/article/causality-and-function-approximations.html](https://cprohm.de/article/causality-and-function-approximations.html) 

Small disclaimer: first time submitter, so I hope I followed the rules.",12,48
1289,2018-8-27,2018,8,27,2,9ah61f,"Simple guide to Neural Arithmetic Logic Units (NALU): Explanation, Intuition and Code",https://www.reddit.com/r/MachineLearning/comments/9ah61f/simple_guide_to_neural_arithmetic_logic_units/,sksq9,1535303700,,0,1
1290,2018-8-27,2018,8,27,2,9ah9ul,Face Image Quality Assessment,https://www.reddit.com/r/MachineLearning/comments/9ah9ul/face_image_quality_assessment/,vishalagarwal,1535304515,"I am working on a project that should evaluate a facial image based on its utility for facial recognition. Like a person looking straight (towards the camera) should have a higher score and a person who is ill-posed, looking sideways or down should have a low score.  
I am planning to use a No Reference IQA model with CNN to extract features and then a regression layer to predict score.

Can anyone suggest me 

\- a dataset where I can get facial images with some score labels ? 

\- some related literature?",0,1
1291,2018-8-27,2018,8,27,2,9ahfuz,Kernel Smoothing Methods,https://www.reddit.com/r/MachineLearning/comments/9ahfuz/kernel_smoothing_methods/,kapil-sharma,1535305779,,0,1
1292,2018-8-27,2018,8,27,3,9ahmpe,Best way to get reliable data on cryptocurrency to python?,https://www.reddit.com/r/MachineLearning/comments/9ahmpe/best_way_to_get_reliable_data_on_cryptocurrency/,MuhMuhRoads,1535307205,[removed],0,1
1293,2018-8-27,2018,8,27,3,9ahn6u,Kernel Smoothing Methods,https://www.reddit.com/r/MachineLearning/comments/9ahn6u/kernel_smoothing_methods/,kapil-sharma,1535307316,[removed],0,1
1294,2018-8-27,2018,8,27,3,9ahr9y,[R] MSG-GAN allowing multi-scale gradient flow in GAN through intermediate layer connections,https://www.reddit.com/r/MachineLearning/comments/9ahr9y/r_msggan_allowing_multiscale_gradient_flow_in_gan/,akanimax,1535308179,,0,2
1295,2018-8-27,2018,8,27,4,9ai3r1,[D] What RL techniques could OpenAI have added to their Dota system to have won against humans?,https://www.reddit.com/r/MachineLearning/comments/9ai3r1/d_what_rl_techniques_could_openai_have_added_to/,antonosika,1535310758,"Would be great to hear some of the community's ideas on the question title!  


I would also be (very) grateful for feedback on some ideas I had:

1. Hierarchical RL. One idea here would be to sample random surrogate reward functions during training (= e.g. high reward for killing a certain hero, getting a certain item), and train the policy with that reward, as well as presenting a certain 'option context vector' as input when this surrogate reward function is active. And then let the agent always make decisions on when to activate 'option context vectors' as input, to improve long term strategical behaviour.
2. Increase gamma and decrease learning rate ( and increase regularisation) even more. In their post OpenAI talk about a discount factor that acts on \~ 5 minutes. (right now the bots seem to always waste all their mana and care little for farm, potentially as an effect of this)
3. (Increase the network sizes, and regularise accordingly)
4. Train subsystems for things like warding. E.g:
   1. Give contextual feature-engineered information on what ward placement at a certain position would do as input to base it on. E.g. 'how much new area will this ward see that was not seen before'.
   2. Add a reward term for 'seeing enemy heroes' (or even specific as 'seeing enemy heroes with a ward', which would require some more Dota API logic)
5. Learn the reward functions (and make them context-dependent), by optimising how many games the agents they train that win against agents trained with other reward functions.
6. Implement RUDDER (Return Decomposition for Delayed Rewards).

If anyone at OpenAI sees this please comment ahead on the ideas!

&amp;#x200B;

&amp;#x200B;",31,25
1296,2018-8-27,2018,8,27,5,9aiukf,Support Vector Machine(SVM),https://www.reddit.com/r/MachineLearning/comments/9aiukf/support_vector_machinesvm/,SurpriseArmadillo,1535316385,[removed],0,1
1297,2018-8-27,2018,8,27,8,9ak2nu,Recommender System,https://www.reddit.com/r/MachineLearning/comments/9ak2nu/recommender_system/,I_m_Abbas,1535326599,[removed],0,1
1298,2018-8-27,2018,8,27,9,9akmdf,[HELP] Need Project Idea Suggestions,https://www.reddit.com/r/MachineLearning/comments/9akmdf/help_need_project_idea_suggestions/,vmfhrmfoald,1535331359,[removed],0,1
1299,2018-8-27,2018,8,27,12,9alses,[R] [1808.03867] Pervasive Attention: 2D Convolutional Neural Networks for Sequence-to-Sequence Prediction,https://www.reddit.com/r/MachineLearning/comments/9alses/r_180803867_pervasive_attention_2d_convolutional/,cetautomatixyz,1535341789,,9,51
1300,2018-8-27,2018,8,27,12,9alt1z,[P] AdvancedEAST: text extraction in arbitrary scenes,https://www.reddit.com/r/MachineLearning/comments/9alt1z/p_advancedeast_text_extraction_in_arbitrary_scenes/,MaxTalanov,1535341969,,0,1
1301,2018-8-27,2018,8,27,13,9alvrz,Experiences building newsfeeds from twitter streams,https://www.reddit.com/r/MachineLearning/comments/9alvrz/experiences_building_newsfeeds_from_twitter/,dorian_here,1535342721,,0,1
1302,2018-8-27,2018,8,27,13,9am213,Googles Jeff Dean undergrad senior thesis project (1990),https://www.reddit.com/r/MachineLearning/comments/9am213/googles_jeff_dean_undergrad_senior_thesis_project/,anandaverma18,1535344582,,0,2
1303,2018-8-27,2018,8,27,13,9am4td,"Ontology Reasoning with Deep Neural Networks,"" Hohenecker and Lukasiewicz",https://www.reddit.com/r/MachineLearning/comments/9am4td/ontology_reasoning_with_deep_neural_networks/,sksq9,1535345389,,1,1
1304,2018-8-27,2018,8,27,13,9am5jx,"[R] Ontology Reasoning with Deep Neural Networks,"" Hohenecker and Lukasiewicz",https://www.reddit.com/r/MachineLearning/comments/9am5jx/r_ontology_reasoning_with_deep_neural_networks/,sksq9,1535345621,,1,14
1305,2018-8-27,2018,8,27,13,9am5no,"[P] Simple guide to Neural Arithmetic Logic Units (NALU): Explanation, Intuition and Code",https://www.reddit.com/r/MachineLearning/comments/9am5no/p_simple_guide_to_neural_arithmetic_logic_units/,sksq9,1535345657,,0,1
1306,2018-8-27,2018,8,27,13,9am5uv,"[D] Simple guide to Neural Arithmetic Logic Units (NALU): Explanation, Intuition and Code",https://www.reddit.com/r/MachineLearning/comments/9am5uv/d_simple_guide_to_neural_arithmetic_logic_units/,sksq9,1535345722,,0,1
1307,2018-8-27,2018,8,27,13,9am6lj,[R] Improving Abstraction in Text Summarization,https://www.reddit.com/r/MachineLearning/comments/9am6lj/r_improving_abstraction_in_text_summarization/,sksq9,1535345933,,2,7
1308,2018-8-27,2018,8,27,14,9am7f1,Get into Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9am7f1/get_into_machine_learning/,sheikh_md_hanif,1535346167,[removed],0,1
1309,2018-8-27,2018,8,27,14,9amb08,Which country has better career opportunities and future growth prospects in AI/ML among Canada and Australia?,https://www.reddit.com/r/MachineLearning/comments/9amb08/which_country_has_better_career_opportunities_and/,mrcet007,1535347242,[removed],0,1
1310,2018-8-27,2018,8,27,14,9amgun,[P] Multi-lingual Text Processing,https://www.reddit.com/r/MachineLearning/comments/9amgun/p_multilingual_text_processing/,longinglove,1535349089,,0,1
1311,2018-8-27,2018,8,27,15,9amihm,How to extract data from web pages for analysis,https://www.reddit.com/r/MachineLearning/comments/9amihm/how_to_extract_data_from_web_pages_for_analysis/,ExcelDataScience,1535349638,,0,1
1312,2018-8-27,2018,8,27,15,9ammdg,How do I improve my technical language of machine learning?,https://www.reddit.com/r/MachineLearning/comments/9ammdg/how_do_i_improve_my_technical_language_of_machine/,nodechef,1535350880,[removed],0,1
1313,2018-8-27,2018,8,27,15,9ammzg,How to compute the loss and backprop of word2vec skip-gram using hierarchical softmax?,https://www.reddit.com/r/MachineLearning/comments/9ammzg/how_to_compute_the_loss_and_backprop_of_word2vec/,TDHale,1535351094,[removed],0,1
1314,2018-8-27,2018,8,27,15,9amra6,3 Recent Applications of AI will leave you Spellbound,https://www.reddit.com/r/MachineLearning/comments/9amra6/3_recent_applications_of_ai_will_leave_you/,dexlabanalytics,1535352602,,0,1
1315,2018-8-27,2018,8,27,16,9amt2d,[R] Googles Jeff Dean undergrad senior thesis on parallel training of neural nets (1990) [pdf],https://www.reddit.com/r/MachineLearning/comments/9amt2d/r_googles_jeff_dean_undergrad_senior_thesis_on/,baylearn,1535353225,,20,151
1316,2018-8-27,2018,8,27,16,9amts8,what is the best way to make a child understand ML?,https://www.reddit.com/r/MachineLearning/comments/9amts8/what_is_the_best_way_to_make_a_child_understand_ml/,pooja307,1535353459,[removed],0,1
1317,2018-8-27,2018,8,27,16,9amu4p,Is this a legitimate solution to the catostrophic interference problem in neural networks?,https://www.reddit.com/r/MachineLearning/comments/9amu4p/is_this_a_legitimate_solution_to_the_catostrophic/,_Idmi_,1535353583,[removed],0,1
1318,2018-8-27,2018,8,27,17,9an78r,[R} Pervasive Attention: Outperforming ConvS2S and Transformers,https://www.reddit.com/r/MachineLearning/comments/9an78r/r_pervasive_attention_outperforming_convs2s_and/,sksq9,1535358361,,2,1
1319,2018-8-27,2018,8,27,17,9an9on,Andrew ng course pn coursera.,https://www.reddit.com/r/MachineLearning/comments/9an9on/andrew_ng_course_pn_coursera/,bhatnaushad,1535359301,[removed],0,1
1320,2018-8-27,2018,8,27,18,9anlgr,How to combine 2 images as input of training data,https://www.reddit.com/r/MachineLearning/comments/9anlgr/how_to_combine_2_images_as_input_of_training_data/,sonld89,1535363435,"Hello everyone,

I am a developer and I am a newbie in machine learning. I have been researching for optical motion detections. I have been working for a Golf company and we have been using Polhemus devices for motion tracking. In our system, each swing (a short) is captured by 2 cameras from 2 sides (side and front of the player). So the output of each swing is 2 videos from 2 sides and a list of motion numbers for each video frame.

Basically, I can convert those videos to frames and can have motion numbers of each frame. So I intend to use existing data to train and create a model then using it to predict motion for new swings instead of using Polhemus devices.

I have a few questions and I hope someone here can help me:

1. Where should I start with machine learning to address this function? Could you please suggest some algorithms or framework? I know that PyTorch is a great one but I am not sure it fits with my project or not.
2. Is it possible to combine 2 sides of a frame as input of training data in PyTorch? I think that combining 2 sides of a frame will improve the accuracy.

Thank you so much!",0,1
1321,2018-8-27,2018,8,27,18,9anlnv,Artificial Intelligence in Banking Sectors,https://www.reddit.com/r/MachineLearning/comments/9anlnv/artificial_intelligence_in_banking_sectors/,johnstones15,1535363498,[removed],0,1
1322,2018-8-27,2018,8,27,19,9antkq,Machine learning Subset of Artificial Intelligence - IT SKills Training Blog,https://www.reddit.com/r/MachineLearning/comments/9antkq/machine_learning_subset_of_artificial/,beerstranger,1535366013,,0,1
1323,2018-8-27,2018,8,27,19,9antya,How to scale CoreNLP?,https://www.reddit.com/r/MachineLearning/comments/9antya/how_to_scale_corenlp/,Kshikhar9,1535366121,[removed],0,1
1324,2018-8-27,2018,8,27,19,9anuvq,Multiple parameters for an time-series forecasting in an RNN,https://www.reddit.com/r/MachineLearning/comments/9anuvq/multiple_parameters_for_an_timeseries_forecasting/,lugenboy94,1535366420,"Suppose we have a dataset for a furniture store such as:

Date, Cost, Category, Material Type, GDP, CPI, Quantity

,where we are forecasting quantity for the next three months.

Now, a sample row could be something like:

&amp;#x200B;

![img](rfrf9o266mi11)

I want to apply a time-series forecasting using an RNN on the above dataset. Clearly, 'category', 'type', and 'material' will be categorical data while 'quantity', 'GDP', 'CPI' and 'cost' will be numerical data. 

&amp;#x200B;

How can we fit an RNN model for the above dataset to predict quantity, considering we have multiple parameters of different natures, i.e, categorical and numerical? I tried Googling this but I did not get a clear answer. Any poke in the right direction would be highly appreciated :)",0,1
1325,2018-8-27,2018,8,27,19,9anyhc,My Final Year Project About Common ML Algorithms. Feedback Appreciated.,https://www.reddit.com/r/MachineLearning/comments/9anyhc/my_final_year_project_about_common_ml_algorithms/,rana_ali_raza,1535367515,,0,1
1326,2018-8-27,2018,8,27,20,9anyua,Top Languages for Machine Learning &amp; Data Science - YourTechDiet,https://www.reddit.com/r/MachineLearning/comments/9anyua/top_languages_for_machine_learning_data_science/,cwadamsmith,1535367624,,1,1
1327,2018-8-27,2018,8,27,20,9aoazi,Management AI types with machine learning,https://www.reddit.com/r/MachineLearning/comments/9aoazi/management_ai_types_with_machine_learning/,asifrazzaq1988,1535371048,,0,1
1328,2018-8-27,2018,8,27,22,9ap2zx,Meta-learning and AutoML talk - commented slides with links,https://www.reddit.com/r/MachineLearning/comments/9ap2zx/metalearning_and_automl_talk_commented_slides/,kordikp,1535377761,,0,1
1329,2018-8-27,2018,8,27,23,9apemk,Colorizing video footage,https://www.reddit.com/r/MachineLearning/comments/9apemk/colorizing_video_footage/,Dano303,1535380274,[removed],0,1
1330,2018-8-27,2018,8,27,23,9apijf,"New paper from Amazon explains how ""slot carryover"" will let Alexa converse more naturally",https://www.reddit.com/r/MachineLearning/comments/9apijf/new_paper_from_amazon_explains_how_slot_carryover/,georgecarlyle76,1535381082,,0,1
1331,2018-8-27,2018,8,27,23,9apilq,Writing an ORB descriptor based classifier in python,https://www.reddit.com/r/MachineLearning/comments/9apilq/writing_an_orb_descriptor_based_classifier_in/,shashankgwl,1535381097,[removed],0,1
1332,2018-8-27,2018,8,27,23,9apm0f,[Javascript] Should I use TensorflowJS or vanilla javascript for doing k-means clustering client side?,https://www.reddit.com/r/MachineLearning/comments/9apm0f/javascript_should_i_use_tensorflowjs_or_vanilla/,welc0meToTheMachine,1535381809,[removed],0,1
1333,2018-8-28,2018,8,28,0,9aprx4,Building a Neural Style Transfer app on iOS with PyTorch and CoreML,https://www.reddit.com/r/MachineLearning/comments/9aprx4/building_a_neural_style_transfer_app_on_ios_with/,kirualex,1535382900,,0,1
1334,2018-8-28,2018,8,28,0,9apsbi,An artificially intelligent mash-up machine,https://www.reddit.com/r/MachineLearning/comments/9apsbi/an_artificially_intelligent_mashup_machine/,anandaverma18,1535382978,,0,2
1335,2018-8-28,2018,8,28,0,9apv7s,"[N] Deep INFOMAX, Image to Image Translation, FEVER, Perception Engines, QuAC, Best 150 ML Tutorials,",https://www.reddit.com/r/MachineLearning/comments/9apv7s/n_deep_infomax_image_to_image_translation_fever/,omarsar,1535383506,,0,1
1336,2018-8-28,2018,8,28,0,9apv95,Which Data Science/Statistics programs in US accept GMAT as an alternative to GRE?,https://www.reddit.com/r/MachineLearning/comments/9apv95/which_data_sciencestatistics_programs_in_us/,nodechef,1535383516,[removed],0,1
1337,2018-8-28,2018,8,28,0,9apx5h,Does machine learning give you a 'solution' with no understanding?,https://www.reddit.com/r/MachineLearning/comments/9apx5h/does_machine_learning_give_you_a_solution_with_no/,QSCFE,1535383894,,6,1
1338,2018-8-28,2018,8,28,0,9apzk5,"[D] OpenAI, DeepMinds Reinforcement Learning  Here is my selection of Julys Best AI articles!",https://www.reddit.com/r/MachineLearning/comments/9apzk5/d_openai_deepminds_reinforcement_learning_here_is/,ArnaultChazareix,1535384348,"Hi there! 

Sicaras team cherry-picked a section of the 10 best articles in AI published in July! We talk about whats happening in Reinforcement Learning at OpenAI and Deepmind, in Recommendations at Tinder and Netflix, but also amazing ideas like Switchable Normalization or Multi-task Multi-lingual learning.

[https://blog.sicara.com/07-2018-best-ai-new-articles-this-month-de7d718290fa](https://blog.sicara.com/07-2018-best-ai-new-articles-this-month-de7d718290fa)

[#MachineLearning](https://www.facebook.com/hashtag/machinelearning?source=feed_text&amp;__xts__%5B0%5D=68.ARBOGcEb1VtplLpEJyFGptlvDaXEK5EKNwKWYUu8RPurf7CrMzNeEgTVTkYM0Wo79h2X7yWuHKiRl7X71lq_7Sd6gzgbb2gp2_9uNa89r-LppwUFZluFTx5YpLVjCe1DJMA-nnaNnJWW&amp;__tn__=K-R) [#ArtificialIntelligence](https://www.facebook.com/hashtag/artificialintelligence?source=feed_text&amp;__xts__%5B0%5D=68.ARBOGcEb1VtplLpEJyFGptlvDaXEK5EKNwKWYUu8RPurf7CrMzNeEgTVTkYM0Wo79h2X7yWuHKiRl7X71lq_7Sd6gzgbb2gp2_9uNa89r-LppwUFZluFTx5YpLVjCe1DJMA-nnaNnJWW&amp;__tn__=K-R) ",1,10
1339,2018-8-28,2018,8,28,0,9aq0av,Machine learning environment setup within 10min,https://www.reddit.com/r/MachineLearning/comments/9aq0av/machine_learning_environment_setup_within_10min/,balavenkatesh123,1535384498,[removed],0,1
1340,2018-8-28,2018,8,28,0,9aq15w,"[P] How to apply a CNN, like Mask-RCNN, to a large image that you have to tile into many patches?",https://www.reddit.com/r/MachineLearning/comments/9aq15w/p_how_to_apply_a_cnn_like_maskrcnn_to_a_large/,clifgray,1535384662,"I'm working on applying Mask-RCNN ([paper](https://arxiv.org/abs/1703.06870) and [code](https://github.com/matterport/Mask_RCNN)) to a large scale habitat mapping project where images are often 16,000px x 10,000px or even larger. I'm using both satellite and drone imagery here.

The main issue is that you have to tile this image into dozens if not hundreds of small image patches and this means that they no longer have as much spatial context and the edges of each tile can be mismatched creating artificial habitat boundaries that conflict from patch to patch and don't match the reality on the ground. Does anyone have ideas for how to mitigate this? I've had a couple:

* I could downsample the data. This would give a larger spatial context for each image but makes the final output map coarser resolution.
* Could tile the image it 2-5 times offset by 1/2-1/5 of the image in order to get multiple predictions and eliminate some edge effects of the patches. 
* Could look more into multi-scale prediction a la [Maggori 2017](https://hal.inria.fr/hal-01369906/document)

I don't totally understand the multi-scale approach so any insight on that would be useful. I know generating similar results regardless of image tiling is really vital for large-scale satellite/drone image processing, and an active research topic but I've had a hard time finding good resources/advice for this.",6,14
1341,2018-8-28,2018,8,28,0,9aq5yt,Scaling Ubers Customer Support Ticket Assistant (COTA) System with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9aq5yt/scaling_ubers_customer_support_ticket_assistant/,mili_m3011,1535385586,,0,1
1342,2018-8-28,2018,8,28,1,9aq751,(Looking for) Advice on area specialization (for industry),https://www.reddit.com/r/MachineLearning/comments/9aq751/looking_for_advice_on_area_specialization_for/,kraftbbc,1535385787,[removed],0,1
1343,2018-8-28,2018,8,28,1,9aq7im,Computer Vision App to Recognize Faces and Identify People,https://www.reddit.com/r/MachineLearning/comments/9aq7im/computer_vision_app_to_recognize_faces_and/,weownnothing,1535385852,[removed],0,1
1344,2018-8-28,2018,8,28,1,9aqig3,How good is currently the best summarizer algorithm?,https://www.reddit.com/r/MachineLearning/comments/9aqig3/how_good_is_currently_the_best_summarizer/,UserWithComputer,1535387968,[removed],0,1
1345,2018-8-28,2018,8,28,2,9aqzcp,[R] [1808.06934] Backpropagation and Biological Plausibility,https://www.reddit.com/r/MachineLearning/comments/9aqzcp/r_180806934_backpropagation_and_biological/,aetolicus,1535391144,,3,17
1346,2018-8-28,2018,8,28,2,9ar0wx,[N] Sentiment Analysis via Self-Attention with MXNet Gluon,https://www.reddit.com/r/MachineLearning/comments/9ar0wx/n_sentiment_analysis_via_selfattention_with_mxnet/,dogenet-164,1535391440,[removed],1,3
1347,2018-8-28,2018,8,28,3,9arevb,[Discussion] Wiki-style Bayesian network for medical diagnosis,https://www.reddit.com/r/MachineLearning/comments/9arevb/discussion_wikistyle_bayesian_network_for_medical/,nothingbutdown,1535394043,"Machine learning is being used everywhere, and medicine is no exception. However, despite the huge potential, it still has little to no role in the daily practice of most clinicians. One manner in which it would be useful is in diagnosis. You give an algorithm the patient's signs and symptoms and whatever lab tests are currently available, and it spits out a probability-ranked list of potential diseases (in medical jargon, a differential diagnosis) with uncertainty estimates.

There have been small-scale attempts at this in the past, but a major issue is finding the requisite empirical statistics to build such an algorithm. For example, how much does the presence of left-sided chest pain increase the probability of a heart attack? We would need at least approximate statistics on the conditional influence of thousands of symptoms, lab tests, etc on thousands of different diseases, which seems intractable.

However, would it be feasible to have an open wiki-style graphical model/Bayesian network where experienced clinicians from around the world could add nodes and conditional dependencies between nodes and fill in the necessary statistics using their clinical experience? For example, a single random doctor may not know P(heart attack | left-sided chest pain) precisely, but maybe the averaged estimates of thousands of doctors might get an approximately accurate value.",5,8
1348,2018-8-28,2018,8,28,3,9arjqb,The Humble Book Bundle: Machine Learning by O'Reilly ($641 worth of eBooks for just $15),https://www.reddit.com/r/MachineLearning/comments/9arjqb/the_humble_book_bundle_machine_learning_by/,abelion,1535395054,,0,1
1349,2018-8-28,2018,8,28,3,9ark8c,Is an echo-chamber effect a threat to AI-driven healthcare?,https://www.reddit.com/r/MachineLearning/comments/9ark8c/is_an_echochamber_effect_a_threat_to_aidriven/,madscientist2407,1535395143,,0,1
1350,2018-8-28,2018,8,28,3,9arn4o,The Humble Book Bundle: Machine Learning by O'Reilly ($641 worth of eBooks for just $15),https://www.reddit.com/r/MachineLearning/comments/9arn4o/the_humble_book_bundle_machine_learning_by/,abelion,1535395722,,0,1
1351,2018-8-28,2018,8,28,4,9arqou,[R] Google's Research framework for RL algorithms.,https://www.reddit.com/r/MachineLearning/comments/9arqou/r_googles_research_framework_for_rl_algorithms/,shagunsodhani,1535396435,,0,2
1352,2018-8-28,2018,8,28,4,9arrtf,final year project help,https://www.reddit.com/r/MachineLearning/comments/9arrtf/final_year_project_help/,RDM355190,1535396649,[removed],0,1
1353,2018-8-28,2018,8,28,4,9as6o4,Neat / Hyper Neat / Es-Hyperneat vs DL RL / DQN / Rainbow,https://www.reddit.com/r/MachineLearning/comments/9as6o4/neat_hyper_neat_eshyperneat_vs_dl_rl_dqn_rainbow/,michael-relleum,1535399559,[removed],0,1
1354,2018-8-28,2018,8,28,4,9as74t,Humble Book Bundle: Machine Learning by O'Reilly,https://www.reddit.com/r/MachineLearning/comments/9as74t/humble_book_bundle_machine_learning_by_oreilly/,koavf,1535399657,,0,2
1355,2018-8-28,2018,8,28,4,9as85e,[D] Why bother doing non-smooth optimization?,https://www.reddit.com/r/MachineLearning/comments/9as85e/d_why_bother_doing_nonsmooth_optimization/,trash_robotics,1535399865,"Whenever you have a non-smooth loss function, just approximate it with a smooth one. For example, if you have f(x) = |x|, approximate it with f(x) = sqrt(0.0001 + x\^2). Or simple ignore the case x = 0, which almost never happens in numerics.  


So why bother doing sub-gradient, primal-dual and all that?",12,0
1356,2018-8-28,2018,8,28,4,9as8kf,[P] HyperparameterHunter: Automatically Save and Learn from Experiments During Optimization,https://www.reddit.com/r/MachineLearning/comments/9as8kf/p_hyperparameterhunter_automatically_save_and/,HunterMcGushion,1535399950,"TL;DR: [HyperparameterHunter](https://github.com/HunterMcGushion/hyperparameter_hunter) lets hyperparameter optimization use all your past experiments as learning material automatically. If you're already sold, pip install hyperparameter-hunter



[HyperparameterHunter](https://github.com/HunterMcGushion/hyperparameter_hunter) makes optimization a truly informed process by 1) automatically recording the results of your experiments for you, and 2) reading past results during hyperparameter optimization rounds, leading to a persistent learning process that doesn't let any of your experiments go to waste. Let [HyperparameterHunter](https://github.com/HunterMcGushion/hyperparameter_hunter) do the hard work of recording, organizing, and learning from your tests  all while using the same libraries you already do  with no need to provide extra information.



This is my first repository, and I would really appreciate any suggestions, criticisms, or help you can offer. I've been a long-time reader of this sub, so thank you for all you've taught me, as well! Hopefully [HyperparameterHunter](https://github.com/HunterMcGushion/hyperparameter_hunter) can be as useful to you as it has been to me!",23,68
1357,2018-8-28,2018,8,28,5,9asfet,[P] Introducing a New Framework for Flexible and Reproducible Reinforcement Learning Research,https://www.reddit.com/r/MachineLearning/comments/9asfet/p_introducing_a_new_framework_for_flexible_and/,Kaixhin,1535401278,,4,35
1358,2018-8-28,2018,8,28,6,9asrn1,"[R] [1808.04293] Fast, Better Training Trick -- Random Gradient",https://www.reddit.com/r/MachineLearning/comments/9asrn1/r_180804293_fast_better_training_trick_random/,evc123,1535403739,,8,0
1359,2018-8-28,2018,8,28,6,9at41i,ML Learning Neat vs DQN,https://www.reddit.com/r/MachineLearning/comments/9at41i/ml_learning_neat_vs_dqn/,michael-relleum,1535406335,[removed],0,1
1360,2018-8-28,2018,8,28,8,9atvov,"[D] ""Online Transfer Learning"" in the context of CNN?",https://www.reddit.com/r/MachineLearning/comments/9atvov/d_online_transfer_learning_in_the_context_of_cnn/,notevencrazy99,1535412442,"I'm trying to find literature on what I'm calling ""Online Transfer Learning"", particularly in the context of CNN, or DNNs in general. But I've only found these two articles which are related to what I'm looking for.

https://arxiv.org/pdf/1503.00072.pdf
https://arxiv.org/pdf/1706.09364.pdf

Is there a common term for this kind of training/fine-tuning procedure, that would yield existing research I'm missing?",3,2
1361,2018-8-28,2018,8,28,8,9atwa1,[D] What You Need to Know Before Considering a PhD,https://www.reddit.com/r/MachineLearning/comments/9atwa1/d_what_you_need_to_know_before_considering_a_phd/,wei_jok,1535412578,,29,10
1362,2018-8-28,2018,8,28,8,9atwri,[D] I found a Stanford Guest Lecture where GM Cruise explains their self driving tech stack and showcases the various model architectures they use on their autonomous cars.,https://www.reddit.com/r/MachineLearning/comments/9atwri/d_i_found_a_stanford_guest_lecture_where_gm/,ilikepancakez,1535412680,,29,408
1363,2018-8-28,2018,8,28,10,9aunak,Build a Random Forest Algorithm in Python,https://www.reddit.com/r/MachineLearning/comments/9aunak/build_a_random_forest_algorithm_in_python/,shamdasani,1535419103,,0,1
1364,2018-8-28,2018,8,28,10,9auog6,Humble Bundle Machine Learning bundle - O'Reily books for $15,https://www.reddit.com/r/MachineLearning/comments/9auog6/humble_bundle_machine_learning_bundle_oreily/,acidplasm,1535419388,,0,1
1365,2018-8-28,2018,8,28,11,9av3o4,Gra Pluma Giratoria De Columna - Weihua Fabricante De Gra Pluma,https://www.reddit.com/r/MachineLearning/comments/9av3o4/gra_pluma_giratoria_de_columna_weihua_fabricante/,weihuagruapluma,1535423039,,0,1
1366,2018-8-28,2018,8,28,11,9av7in,Gra Pluma Giratoria De Pared - Weihua Fabricante De Gra Pluma,https://www.reddit.com/r/MachineLearning/comments/9av7in/gra_pluma_giratoria_de_pared_weihua_fabricante/,weihuagruapluma,1535423975,,0,1
1367,2018-8-28,2018,8,28,11,9av92z,Do I really need a graduate degree?,https://www.reddit.com/r/MachineLearning/comments/9av92z/do_i_really_need_a_graduate_degree/,pr0methium,1535424361,[removed],0,1
1368,2018-8-28,2018,8,28,12,9avpqi,Is it possible to get a job as a data scientist/machine learning engineer as an applied math major?,https://www.reddit.com/r/MachineLearning/comments/9avpqi/is_it_possible_to_get_a_job_as_a_data/,SpiderSaliva,1535428630,[removed],0,1
1369,2018-8-28,2018,8,28,13,9avqwx,AI is not just for Silicon Valley: Powering Changes in the Energy Sector,https://www.reddit.com/r/MachineLearning/comments/9avqwx/ai_is_not_just_for_silicon_valley_powering/,i_RobertJones,1535428952,"As done with new technology in the pastfor example, when advanced energy storage was first introduced more than 10 years ago by AESpower system stakeholders should put AI through a checklist and ask five key questions before embarking on the journey:

&amp;#x200B;

1. How does it work? 

2. Is it dependable? 

3. Is it scalable? 

4. Is it sustainable? 

5. Is it cost effective?

&amp;#x200B;

Read More here =&gt; [https://www.cioapplications.com/cxoinsights/ai-is-not-just-for-silicon-valley-powering-changes-in-the-energy-sector-nid-2231.html](https://www.cioapplications.com/cxoinsights/ai-is-not-just-for-silicon-valley-powering-changes-in-the-energy-sector-nid-2231.html)",0,1
1370,2018-8-28,2018,8,28,13,9avvlr,"$4,718  Using Machine Learning to Bet on the NHL  Coinmonks  Medium",https://www.reddit.com/r/MachineLearning/comments/9avvlr/4718_using_machine_learning_to_bet_on_the_nhl/,coinmonks,1535430184,,0,1
1371,2018-8-28,2018,8,28,15,9awgan,[R] Scientists identify a new kind of human brain cell,https://www.reddit.com/r/MachineLearning/comments/9awgan/r_scientists_identify_a_new_kind_of_human_brain/,inarrears,1535436390,,12,57
1372,2018-8-28,2018,8,28,15,9awhcg,HyperLearn,https://www.reddit.com/r/MachineLearning/comments/9awhcg/hyperlearn/,danielhanchen,1535436745,[removed],0,1
1373,2018-8-28,2018,8,28,15,9awiju,"50%+ Faster, 50%+ Leaner Sklearn morphed with Statsmodels Drop In Substitute - HyperLearn. Fully parallelized with GPU support. HELP NEEDED :). Written in PyTorch, Numba, LAPACK.",https://www.reddit.com/r/MachineLearning/comments/9awiju/50_faster_50_leaner_sklearn_morphed_with/,danielhanchen,1535437132,,0,1
1374,2018-8-28,2018,8,28,15,9awk43,AI MachineLearning Poker bot,https://www.reddit.com/r/MachineLearning/comments/9awk43/ai_machinelearning_poker_bot/,OptiCares,1535437637,"I was wondering, has there ever been a project whereby someone trains an AI to play poker? I can't find anything good on google, that could be because of my poor searching skills. Has anyone heard of this and can anyone link me to it? Thanks! ",0,1
1375,2018-8-28,2018,8,28,15,9awkn1,"Sklearn + Statsmodels written in PyTorch, Numba - HyperLearn (50% Faster, Learner with GPU support)",https://www.reddit.com/r/MachineLearning/comments/9awkn1/sklearn_statsmodels_written_in_pytorch_numba/,danielhanchen,1535437820," **Faster, Leaner Scikit Learn (Sklearn) morphed with Statsmodels &amp; Deep Learning drop in substitute. Designed for big data, HyperLearn can use 50%+ less memory, and runs 50%+ faster on some modules. Will have GPU support, and all modules are parallelized.** [**https://github.com/danielhanchen/hyperlearn**](https://github.com/danielhanchen/hyperlearn)

HyperLearn is written completely in PyTorch, NoGil Numba, Numpy, Pandas, Scipy &amp; LAPACK, and mirrors (mostly) Scikit Learn. HyperLearn also has statistical inference measures embedded, and can be called just like Scikit Learn's syntax (model.confidence\_interval\_, [model.fit](https://model.fit), model.predict)

I started this project last month, and I really need more help on it! (Also I want to gauge the popularity / usefulness of the package to machine learning practitioners.) Help is really needed! Email me or message me [danielhanchen@gmail.com](mailto:danielhanchen@gmail.com)!

I'm currently trying to make Linear Regression, Ridge, PCA, LDA/QDA faster, which then flows onto other algorithms being faster. Below you can see the 50%+ improvement on QDA (similar improvements for other models)

|Sklearn Time|HyperLearn Time|Sklearn RAM|HyperLearn RAM|
|:-|:-|:-|:-|
| 54.2 s| *22.25* s| 2,700 mb| *1,200* mb|

Thanks! (Project in progress, so package still unstable --&gt; QDA works, and SVD / solving methods)

[I even made a logo! \(Since combo of PyTorch, Sklearn, Numba --\&gt; water like PyTorch, Blue &amp; Shape from Sklearn, Numba\)](https://i.redd.it/phxtr0c23si11.png)

[https://github.com/danielhanchen/hyperlearn](https://github.com/danielhanchen/hyperlearn)",0,1
1376,2018-8-28,2018,8,28,15,9awlqr,"[P] Sklearn + Statsmodels written in PyTorch, Numba - HyperLearn (50% Faster, Learner with GPU support)",https://www.reddit.com/r/MachineLearning/comments/9awlqr/p_sklearn_statsmodels_written_in_pytorch_numba/,danielhanchen,1535438198," **Faster, Leaner Scikit Learn (Sklearn) morphed with Statsmodels &amp; Deep Learning drop in substitute. Designed for big data, HyperLearn can use 50%+ less memory, and runs 50%+ faster on some modules. Will have GPU support, and all modules are parallelized.** [**https://github.com/danielhanchen/hyperlearn**](https://github.com/danielhanchen/hyperlearn)

HyperLearn is written completely in PyTorch, NoGil Numba, Numpy, Pandas, Scipy &amp; LAPACK, and mirrors (mostly) Scikit Learn. HyperLearn also has statistical inference measures embedded, and can be called just like Scikit Learn's syntax (model.confidence\_interval\_, [model.fit](https://model.fit/), model.predict)

I started this project last month, and I really need more help on it! (Also I want to gauge the popularity / usefulness of the package to machine learning practitioners.) Help is really needed! Email me or message me [danielhanchen@gmail.com](mailto:danielhanchen@gmail.com)!

I'm currently trying to make Linear Regression, Ridge, PCA, LDA/QDA faster, which then flows onto other algorithms being faster. Below you can see the 50%+ improvement on QDA (similar improvements for other models)

 

| Sklearn Time | HyperLearn Time| Sklearn RAM | HyperLearn RAM |
|:-|:-|:-|:-|
| 54.2 s | *22.25* s | 2,700 mb | *1,200* mb |

Thanks! (Project in progress, so package still unstable --&gt; QDA works, and SVD / solving methods)

[https://github.com/danielhanchen/hyperlearn](https://github.com/danielhanchen/hyperlearn)

![img](hqam5ydf4si11 "" I even made a logo! (Since combo of PyTorch, Sklearn, Numba --&gt; water like PyTorch, Blue &amp; Shape from Sklearn, Numba) "")",40,38
1377,2018-8-28,2018,8,28,15,9awn3q,[R] Generalisation in humans and deep neural networks,https://www.reddit.com/r/MachineLearning/comments/9awn3q/r_generalisation_in_humans_and_deep_neural/,chisai_mikan,1535438669,,1,14
1378,2018-8-28,2018,8,28,15,9awo5f,Road to ML,https://www.reddit.com/r/MachineLearning/comments/9awo5f/road_to_ml/,splitzer123,1535439007,[removed],0,1
1379,2018-8-28,2018,8,28,16,9awtse,Introducing a New Framework for Flexible and Reproducible Reinforcement Learning Research,https://www.reddit.com/r/MachineLearning/comments/9awtse/introducing_a_new_framework_for_flexible_and/,WearsVests,1535440814,,0,1
1380,2018-8-28,2018,8,28,16,9awtw8,[P] Building a Neural Style Transfer app on iOS with PyTorch and CoreML,https://www.reddit.com/r/MachineLearning/comments/9awtw8/p_building_a_neural_style_transfer_app_on_ios/,kirualex,1535440851,,0,1
1381,2018-8-28,2018,8,28,17,9ax49q,"What does a professor of cognitive, linguistic, and psychological sciences know about Image processing anyway? is it fair to treat CNN algorithms the same way psychologists study human behavior? (check the first comment to understand my concern)",https://www.reddit.com/r/MachineLearning/comments/9ax49q/what_does_a_professor_of_cognitive_linguistic_and/,worthyNull,1535444441,,0,1
1382,2018-8-28,2018,8,28,17,9ax99x,Perks of Getting Assistance Of The Top Data Analytics Companies,https://www.reddit.com/r/MachineLearning/comments/9ax99x/perks_of_getting_assistance_of_the_top_data/,samparkin601,1535446279,[removed],0,1
1383,2018-8-28,2018,8,28,17,9axaim,Audio for neural networks,https://www.reddit.com/r/MachineLearning/comments/9axaim/audio_for_neural_networks/,tomerha,1535446735,[removed],0,1
1384,2018-8-28,2018,8,28,18,9axdne,Meta-learning and AutoML talk - commented slides with links,https://www.reddit.com/r/MachineLearning/comments/9axdne/metalearning_and_automl_talk_commented_slides/,kordikp,1535447762,,0,1
1385,2018-8-28,2018,8,28,18,9axj8z,What if you knew of an advanced AI system that was manipulating people on a global scale? Would you share the existence of it?,https://www.reddit.com/r/MachineLearning/comments/9axj8z/what_if_you_knew_of_an_advanced_ai_system_that/,aRaBaK,1535449709,[removed],2,2
1386,2018-8-28,2018,8,28,18,9axl5g,Machine Learning memes,https://www.reddit.com/r/MachineLearning/comments/9axl5g/machine_learning_memes/,akshad_GL,1535450344,[removed],0,1
1387,2018-8-28,2018,8,28,19,9axlrf,Do you know how to set the specimen for glow wire test apparatus?,https://www.reddit.com/r/MachineLearning/comments/9axlrf/do_you_know_how_to_set_the_specimen_for_glow_wire/,jumitop,1535450538,,0,1
1388,2018-8-28,2018,8,28,19,9axltq,Any recent comparative between TF1.10 and PyTorch 0.4?,https://www.reddit.com/r/MachineLearning/comments/9axltq/any_recent_comparative_between_tf110_and_pytorch/,RichHS,1535450556,[removed],0,1
1389,2018-8-28,2018,8,28,19,9axt1v,[D] Why don't we see more Bayesian Network libraries?,https://www.reddit.com/r/MachineLearning/comments/9axt1v/d_why_dont_we_see_more_bayesian_network_libraries/,ccmlacc,1535452822,"Currently the best tool for Bayesian Networks (BNs), which includes different methods of both structure learning, parameter learning and inference, seems to be `bnlearn` package in R.  
  
There are some alternatives in Python, but the ecosystem is unfortunately quite poor in comparison to the tools we have for deep learning, and other ML algos like gradient boosting, random forests etc.  
  
Is the industry adoption rate of BNs low? If so, are there any particular reasons for that?  
  
Note that I realize models like Naive Bayes are also minimal BNs, but I am talking more structured and complex models.",23,41
1390,2018-8-28,2018,8,28,19,9axuho,What Benefits Does Artificial Intelligence Afford For Creative Mind?,https://www.reddit.com/r/MachineLearning/comments/9axuho/what_benefits_does_artificial_intelligence_afford/,amberstevens311,1535453254,[removed],0,1
1391,2018-8-28,2018,8,28,19,9axvar,Humble Book bundle: Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9axvar/humble_book_bundle_machine_learning/,kont_no,1535453507,,0,1
1392,2018-8-28,2018,8,28,19,9axwb7,[D] Feel free to rent my 6x 1070ti server for $0.12/h/gpu (or cheaper from someone else) to do ML,https://www.reddit.com/r/MachineLearning/comments/9axwb7/d_feel_free_to_rent_my_6x_1070ti_server_for/,Darth_bunny,1535453814,,8,11
1393,2018-8-28,2018,8,28,19,9axwis,Chatbots and A.I. Paving the Way for the Future,https://www.reddit.com/r/MachineLearning/comments/9axwis/chatbots_and_ai_paving_the_way_for_the_future/,amberstevens311,1535453878,[removed],0,1
1394,2018-8-28,2018,8,28,19,9axwtx,Granite saw for sale,https://www.reddit.com/r/MachineLearning/comments/9axwtx/granite_saw_for_sale/,Bridgesawlosangeles,1535453964,[removed],0,1
1395,2018-8-28,2018,8,28,20,9axz0i,Can Employees Feel Liberated with Chatbots?,https://www.reddit.com/r/MachineLearning/comments/9axz0i/can_employees_feel_liberated_with_chatbots/,amberstevens311,1535454576,[removed],0,1
1396,2018-8-28,2018,8,28,20,9ay2r0,Using Microsoft coco api,https://www.reddit.com/r/MachineLearning/comments/9ay2r0/using_microsoft_coco_api/,_10ZIN_,1535455616,[removed],0,1
1397,2018-8-28,2018,8,28,21,9aybgp,"[R] TDLS: Eve, A Gradient Based Optimization Method with Locally and Globally Adaptive Learning Rates (https://arxiv.org/abs/1611.01505)",https://www.reddit.com/r/MachineLearning/comments/9aybgp/r_tdls_eve_a_gradient_based_optimization_method/,machinetrainer,1535457897,,11,28
1398,2018-8-28,2018,8,28,21,9ayc4x,[R] TDLS: Large-Scale Unsupervised Deep Representation Learning for Brain Structure (https://arxiv.org/abs/1805.01049),https://www.reddit.com/r/MachineLearning/comments/9ayc4x/r_tdls_largescale_unsupervised_deep/,machinetrainer,1535458046,,3,6
1399,2018-8-28,2018,8,28,22,9aypkd,What are the upsides or downsides to having Cognitive Science classes in my MSc in Artificial Intelligence?,https://www.reddit.com/r/MachineLearning/comments/9aypkd/what_are_the_upsides_or_downsides_to_having/,DogeTheDev,1535461291,[removed],0,1
1400,2018-8-28,2018,8,28,22,9ayqfs,[Discussion] A research paper reading text-to-speech model,https://www.reddit.com/r/MachineLearning/comments/9ayqfs/discussion_a_research_paper_reading_texttospeech/,liftoff01,1535461479,"Is there an open source project out there trying to build a model that reads research papers, like the ones posted on arxiv, out loud (text to speech but trained to handle research style input? 

I feel like, based off the last performance update of wavenet we got from Google, it should not be too difficult for the community to get together to work on the project. We already have the base architecture figured out, so basically, we just need folks to donate GPU hours for training and sample reading sessions to use as input data.

Let me know if you think this is worthwhile project or if there is an on-going project of this kind out there.",3,6
1401,2018-8-28,2018,8,28,22,9ayzdi,"Call for papers: Interpretability and Robustness in Audio, Speech, and Language workshop at NIPS2018",https://www.reddit.com/r/MachineLearning/comments/9ayzdi/call_for_papers_interpretability_and_robustness/,d_serdyuk,1535463459,,0,1
1402,2018-8-28,2018,8,28,23,9azbc3,[R] Machine Learning Applications for the Retail Industry,https://www.reddit.com/r/MachineLearning/comments/9azbc3/r_machine_learning_applications_for_the_retail/,minmidinosaur,1535465994,&amp;#x200B;,2,1
1403,2018-8-28,2018,8,28,23,9azcai,Advice on a program to use,https://www.reddit.com/r/MachineLearning/comments/9azcai/advice_on_a_program_to_use/,Rufashaw,1535466196,[removed],0,1
1404,2018-8-28,2018,8,28,23,9azmfb,[R] Machine Learning Applications for the Retail Industry,https://www.reddit.com/r/MachineLearning/comments/9azmfb/r_machine_learning_applications_for_the_retail/,minmidinosaur,1535468338,,0,1
1405,2018-8-28,2018,8,28,23,9azmkt,Find similarities between different translations of the same text using NLP,https://www.reddit.com/r/MachineLearning/comments/9azmkt/find_similarities_between_different_translations/,sedthh,1535468368,[removed],0,1
1406,2018-8-29,2018,8,29,0,9azrah,Which Deep Learning algorithms to use? Where to start?,https://www.reddit.com/r/MachineLearning/comments/9azrah/which_deep_learning_algorithms_to_use_where_to/,ZelelB,1535469268,[removed],0,1
1407,2018-8-29,2018,8,29,0,9azs5n,Conv net implementations &amp; torch/tf comparisons - for reference/understanding,https://www.reddit.com/r/MachineLearning/comments/9azs5n/conv_net_implementations_torchtf_comparisons_for/,jalexvig,1535469452,,0,1
1408,2018-8-29,2018,8,29,0,9azyl9,"If Google charged the same for their cloud TPU service as AWS or Azure does with NVidia v100's, would you use it?",https://www.reddit.com/r/MachineLearning/comments/9azyl9/if_google_charged_the_same_for_their_cloud_tpu/,pocketacez,1535470728,[removed],0,1
1409,2018-8-29,2018,8,29,0,9azz1e,A Docker-based playground for Data Science exploration: Python3.6/2.7+Tensorflow+Postgres and more with one command,https://www.reddit.com/r/MachineLearning/comments/9azz1e/a_dockerbased_playground_for_data_science/,anatoliykmetyuk,1535470821,,0,1
1410,2018-8-29,2018,8,29,0,9b01x5,List of free resources to learn Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/9b01x5/list_of_free_resources_to_learn_natural_language/,Fewthp,1535471400,,0,1
1411,2018-8-29,2018,8,29,0,9b0282,High school thesis about AI &amp; machine learning,https://www.reddit.com/r/MachineLearning/comments/9b0282/high_school_thesis_about_ai_machine_learning/,GerbenVZ,1535471460,[removed],0,1
1412,2018-8-29,2018,8,29,0,9b042g,"[D] What are your top productivity ""hacks""?",https://www.reddit.com/r/MachineLearning/comments/9b042g/d_what_are_your_top_productivity_hacks/,m_ke,1535471813,"Sorry for the clickbait title. 

Assuming you're not working at google, have constrained resources and deadlines, how do you stay productive when models you're training take days-weeks to converge?

Main things that worked for me:

1. Training on subset / smaller dataset first before scaling things up
2. Starting new experiments from previous model checkpoints
3. Experiment queuing system that keeps GPUs hot 24/7
4. Working on other things while the models are running (data collection / cleaning)


Are there any tools or workflow changes that have improved your productivity? Airflow? Hyperparameter Optimization Tools? Experiment Tracking? Architecture Search? Testing? Docker?

",53,147
1413,2018-8-29,2018,8,29,1,9b06sf,Recommend one ML book that you have read and state why ?,https://www.reddit.com/r/MachineLearning/comments/9b06sf/recommend_one_ml_book_that_you_have_read_and/,Ragabov,1535472343,[removed],0,1
1414,2018-8-29,2018,8,29,1,9b0hev,Dimensionality Reduction Techniques (Python Codes) | The Self Starter Guide | Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9b0hev/dimensionality_reduction_techniques_python_codes/,mlcrunch,1535474387,,0,1
1415,2018-8-29,2018,8,29,3,9b1gff,[N] Using Apache MXNet GluonCV with Apache NiFi,https://www.reddit.com/r/MachineLearning/comments/9b1gff/n_using_apache_mxnet_gluoncv_with_apache_nifi/,dogenet-164,1535481120,"Read this article in order to learn how to use Apache MXNet GluonCV with Apache NiFi.

[https://dzone.com/articles/using-apache-mxnet-gluoncv-with-apache-nifi](https://dzone.com/articles/using-apache-mxnet-gluoncv-with-apache-nifi)",0,5
1416,2018-8-29,2018,8,29,3,9b1mfh,Back Propagation Algorithm in Deep learning,https://www.reddit.com/r/MachineLearning/comments/9b1mfh/back_propagation_algorithm_in_deep_learning/,auzshah,1535482270,[removed],0,1
1417,2018-8-29,2018,8,29,3,9b1n0g,How Blockchain Will Transform AI,https://www.reddit.com/r/MachineLearning/comments/9b1n0g/how_blockchain_will_transform_ai/,Reclusiarh,1535482380,,0,2
1418,2018-8-29,2018,8,29,4,9b24rl,"Google Brain team open sources a Tensorflow-based research framework, Dopamine, for fast prototyping of Reinforcement Learning algorithms.",https://www.reddit.com/r/MachineLearning/comments/9b24rl/google_brain_team_open_sources_a_tensorflowbased/,ndha1995,1535485733,,0,1
1419,2018-8-29,2018,8,29,5,9b2h2n,How SpaceX use conical optimisers to land the falcon 9 boosters,https://www.reddit.com/r/MachineLearning/comments/9b2h2n/how_spacex_use_conical_optimisers_to_land_the/,HugoRAS,1535488064,[removed],0,1
1420,2018-8-29,2018,8,29,6,9b2tsg,Learning Algorithms vs. using libraries,https://www.reddit.com/r/MachineLearning/comments/9b2tsg/learning_algorithms_vs_using_libraries/,gkarwchan,1535490490,[removed],0,1
1421,2018-8-29,2018,8,29,6,9b32jp,AMD ROCm GPU support for TensorFlow,https://www.reddit.com/r/MachineLearning/comments/9b32jp/amd_rocm_gpu_support_for_tensorflow/,rekt_brownie,1535492204,,1,1
1422,2018-8-29,2018,8,29,6,9b33k3,[P] Interactive AI to remove objects from images based on Mask R-CNN and Deep Fill,https://www.reddit.com/r/MachineLearning/comments/9b33k3/p_interactive_ai_to_remove_objects_from_images/,wahoooooooo2,1535492412,,3,10
1423,2018-8-29,2018,8,29,7,9b3g8g,[D] How to compute the loss and backprop of word2vec skip-gram using hierarchical softmax?,https://www.reddit.com/r/MachineLearning/comments/9b3g8g/d_how_to_compute_the_loss_and_backprop_of/,TDHale,1535495021,"So we are calculating the loss

`$J(\theta) = -\frac{1}{T}\sigma_{t=1}^T\Sigma_{-m \leq j \leq m} log P(w_{t+j}|w_t;\theta)$`

and to do this we need to calculate

`$P(o|c) = \frac{exp(u_o^Tv_c)}{\Sigma exp(u_w^Tv_c)}$`

, which is computationally inefficient. To solve this we could use the hierarchical softmax and construct a tree based on word frequency. However, I am having trouble on how we could get the probability based on the word frequency. And what exactly is the backprop step if using hierarchical softmax?

",3,3
1424,2018-8-29,2018,8,29,7,9b3je2,[R] Brown University Paper Shows Research Robot Vulnerability,https://www.reddit.com/r/MachineLearning/comments/9b3je2/r_brown_university_paper_shows_research_robot/,trcytony,1535495699,,0,1
1425,2018-8-29,2018,8,29,8,9b3v3v,[P] Synthetic Abstractions: essay covering 'adversarial' ink prints and examining the visual abstractions they might represent.,https://www.reddit.com/r/MachineLearning/comments/9b3v3v/p_synthetic_abstractions_essay_covering/,baylearn,1535498089,,0,1
1426,2018-8-29,2018,8,29,8,9b43zg,[R] Contextual Parameter Generation for Universal Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/9b43zg/r_contextual_parameter_generation_for_universal/,wei_jok,1535499984,,3,12
1427,2018-8-29,2018,8,29,8,9b45jx,[P] Machine Learning Observability with Timber.io,https://www.reddit.com/r/MachineLearning/comments/9b45jx/p_machine_learning_observability_with_timberio/,darosati,1535500336,,0,22
1428,2018-8-29,2018,8,29,10,9b4q8x,How can I get started?,https://www.reddit.com/r/MachineLearning/comments/9b4q8x/how_can_i_get_started/,PsychicPanda53,1535505020,[removed],0,1
1429,2018-8-29,2018,8,29,10,9b4rpn,What would happen if we remove the first tree from a random forest ensemble?,https://www.reddit.com/r/MachineLearning/comments/9b4rpn/what_would_happen_if_we_remove_the_first_tree/,aryancodify,1535505371,[removed],0,1
1430,2018-8-29,2018,8,29,11,9b57de,[R] Merge or Not? Learning to Group Faces via Imitation Learning,https://www.reddit.com/r/MachineLearning/comments/9b57de/r_merge_or_not_learning_to_group_faces_via/,ewanlee,1535508885,,2,4
1431,2018-8-29,2018,8,29,11,9b5brf,Google's reinforcement learning framework Dopamine is now open source.,https://www.reddit.com/r/MachineLearning/comments/9b5brf/googles_reinforcement_learning_framework_dopamine/,Bexirt,1535509871,[removed],0,1
1432,2018-8-29,2018,8,29,11,9b5fam,A weekly about happenings in Data Science and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9b5fam/a_weekly_about_happenings_in_data_science_and/,mindaslab,1535510663,[removed],0,1
1433,2018-8-29,2018,8,29,11,9b5hw5,[P] Distributed Hyperparameter Optimisation with Hyperas/Hyperopt,https://www.reddit.com/r/MachineLearning/comments/9b5hw5/p_distributed_hyperparameter_optimisation_with/,Jonno_FTW,1535511258,,8,43
1434,2018-8-29,2018,8,29,12,9b5mh4,Focal Loss for Dense Object Detection - RetinaNet,https://www.reddit.com/r/MachineLearning/comments/9b5mh4/focal_loss_for_dense_object_detection_retinanet/,nottakumasato,1535512313,[removed],0,1
1435,2018-8-29,2018,8,29,12,9b5rjs,Accidentally left dropout on during inference for semantic segmentation. Can't explain the good results.,https://www.reddit.com/r/MachineLearning/comments/9b5rjs/accidentally_left_dropout_on_during_inference_for/,Moonnse,1535513595,[removed],0,1
1436,2018-8-29,2018,8,29,15,9b6ub4,Implementing Self-Organizing Maps with Python and TensorFlow,https://www.reddit.com/r/MachineLearning/comments/9b6ub4/implementing_selforganizing_maps_with_python_and/,RubiksCodeNMZ,1535524533,,0,1
1437,2018-8-29,2018,8,29,15,9b6uru,"How to handle 2 input representations (""channels"") of a data that is associated with the exact same label?",https://www.reddit.com/r/MachineLearning/comments/9b6uru/how_to_handle_2_input_representations_channels_of/,melonochelo,1535524687,,0,1
1438,2018-8-29,2018,8,29,15,9b6uwr,I think this is a very important topic in ML and thought it could use some more definitive answers,https://www.reddit.com/r/MachineLearning/comments/9b6uwr/i_think_this_is_a_very_important_topic_in_ml_and/,santoso-sheep,1535524735,,0,1
1439,2018-8-29,2018,8,29,16,9b7a11,Customised loss functions,https://www.reddit.com/r/MachineLearning/comments/9b7a11/customised_loss_functions/,gautiexe,1535529469,[removed],0,1
1440,2018-8-29,2018,8,29,16,9b7a44,We are Looking for a Deep Learning Engineer !,https://www.reddit.com/r/MachineLearning/comments/9b7a44/we_are_looking_for_a_deep_learning_engineer/,zacharyYoon,1535529498,"Hi there, 

&amp;#x200B;

My name is Zachary Yoon and I am a senior research engineer of Deepstudio Co Ltd. 

Our company mainly deals with deep learning theories and practice to generate **photo-realistic synthesized image and videos**. 

Below is our company's recent research result where the left actor reenact the right person's expression and torso movement. 

![video](ji3pat10kzi11)

Right now our company has a **open position** for a deep learning research engineer. 

Our company is located in Seoul, the capital city of South Korea.

We guarantee every employees being provided with the most advanced research and development environment such as unlimited AWS credits, free work-hours for given tasks and iMAC pro for every R&amp;D personnel. 

&amp;#x200B;

Qualification for this position is quite simple as following:

1. At least 1 year of experience of dealing with deep learning framework- such as tensorflow or pytorch 
2. Clear understanding over the foundational theories of deep-learning  
3. Github portfolio that can verify your competency over deep learning development process - such as data collection/pre-processing, data-feeding, network structuring and result-checking and feedback process upon acquired result through experiment. 

We prefer a person who have an experience of reproducing a paper of which the corresponding codes is not provided. 

&amp;#x200B;

Hope you enjoy your day and if you have any question, just email me via [syyun@snu.ac.kr](mailto:syyun@snu.ac.kr) ! 

&amp;#x200B;",0,1
1441,2018-8-29,2018,8,29,16,9b7a66,"[R] Dykstra's Algorithm, ADMM, and Coordinate Descent: Connections, Insights, and Extensions",https://www.reddit.com/r/MachineLearning/comments/9b7a66/r_dykstras_algorithm_admm_and_coordinate_descent/,chisai_mikan,1535529519,,5,14
1442,2018-8-29,2018,8,29,16,9b7ad7,[R] Fisher Information and Natural Gradient Learning of Random Deep Networks,https://www.reddit.com/r/MachineLearning/comments/9b7ad7/r_fisher_information_and_natural_gradient/,wei_jok,1535529598,,15,62
1443,2018-8-29,2018,8,29,17,9b7is4,Rare Datasets for Computer Vision Every Machine Learning Expert Must Work With,https://www.reddit.com/r/MachineLearning/comments/9b7is4/rare_datasets_for_computer_vision_every_machine/,yesnoornext,1535532446,,0,1
1444,2018-8-29,2018,8,29,19,9b81d1,A neural networks based football management game!,https://www.reddit.com/r/MachineLearning/comments/9b81d1/a_neural_networks_based_football_management_game/,orenog,1535538183,[removed],1,1
1445,2018-8-29,2018,8,29,19,9b87g0,Best practice for splitting datasets,https://www.reddit.com/r/MachineLearning/comments/9b87g0/best_practice_for_splitting_datasets/,JClub,1535539973,[removed],0,1
1446,2018-8-29,2018,8,29,20,9b8d58,Manual Machining/Repair,https://www.reddit.com/r/MachineLearning/comments/9b8d58/manual_machiningrepair/,rickbanklaw2,1535541466,,0,1
1447,2018-8-29,2018,8,29,20,9b8des,Simple Tensorflow implementation of Diverse Image-to-Image Translation via Disentangled Representations (ECCV 2018 Oral),https://www.reddit.com/r/MachineLearning/comments/9b8des/simple_tensorflow_implementation_of_diverse/,taki0112,1535541541,,1,1
1448,2018-8-29,2018,8,29,20,9b8e6q,Simple Tensorflow implementation of Diverse Image-to-Image Translation via Disentangled Representations (ECCV 2018 Oral),https://www.reddit.com/r/MachineLearning/comments/9b8e6q/simple_tensorflow_implementation_of_diverse/,taki0112,1535541746,[removed],1,1
1449,2018-8-29,2018,8,29,20,9b8ffg,[P] Simple Tensorflow implementation of Diverse Image-to-Image Translation via Disentangled Representations (ECCV 2018 Oral),https://www.reddit.com/r/MachineLearning/comments/9b8ffg/p_simple_tensorflow_implementation_of_diverse/,taki0112,1535542071,"&amp;#x200B;

https://i.redd.it/mth9c5hfp0j11.gif",1,14
1450,2018-8-29,2018,8,29,20,9b8g66,OpenHack: has anyone gone to this MS ML hacking event?,https://www.reddit.com/r/MachineLearning/comments/9b8g66/openhack_has_anyone_gone_to_this_ms_ml_hacking/,_busch,1535542275,[removed],0,1
1451,2018-8-29,2018,8,29,21,9b8sqh,Bridge saw for granite,https://www.reddit.com/r/MachineLearning/comments/9b8sqh/bridge_saw_for_granite/,marblesawlosangeles,1535545352,[removed],0,1
1452,2018-8-29,2018,8,29,21,9b8vvs,Focal Loss for Dense Object Detection - RetinaNet,https://www.reddit.com/r/MachineLearning/comments/9b8vvs/focal_loss_for_dense_object_detection_retinanet/,nottakumasato,1535546103,[removed],0,1
1453,2018-8-29,2018,8,29,21,9b8yrw,The Future with Reinforcement Learning - Part 2: Comparisons and Applications,https://www.reddit.com/r/MachineLearning/comments/9b8yrw/the_future_with_reinforcement_learning_part_2/,recastai,1535546767,[removed],0,1
1454,2018-8-29,2018,8,29,21,9b91ut,[D] Anima Anandkumar leaves Amazon AWS,https://www.reddit.com/r/MachineLearning/comments/9b91ut/d_anima_anandkumar_leaves_amazon_aws/,inarrears,1535547498,,0,0
1455,2018-8-29,2018,8,29,22,9b939u,[D] Focal Loss for Dense Object Detection - RetinaNet,https://www.reddit.com/r/MachineLearning/comments/9b939u/d_focal_loss_for_dense_object_detection_retinanet/,nottakumasato,1535547779,"Hi,

I just read this paper titled ""Focal Loss for Dense Object Detection"", found here: https://arxiv.org/abs/1708.02002

The authors show that this new method with the RetinaNet architecture can outperform the two-stage object detectors like Faster R-CNN in both accuracy and speed.

I have some questions about the paper:

1. Why was the hinge loss unstable? Is it because of the not differentiable region of the hinge loss function? Would Generalized Smooth Hinge loss have worked?

2. How scalable is focal loss on the number of classes? RetineNet requires 9 filters for each class, so would the speed slow down inference drastically if the number of classes was very large?

3. The paper talks about the ""hard example"", but I couldn't understand it completely. Could anyone give an image region that is a hard example?

4. Why cant the alpha-balanced cross entropy loss differentiate between easy and hard examples?

5. Does this improvement in accuracy open up new applications for one-stage detectors?

Any help is appreciated!",5,3
1456,2018-8-29,2018,8,29,22,9b94h4,[D] Looking for interesting papers in regards to IoT and reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/9b94h4/d_looking_for_interesting_papers_in_regards_to/,foldo,1535548039,"Do some of you know some interesting papers in that area? Something sports related would be a huge plus but anything that combines the internet of things and reinforcement learning is much appreciated.       
Thanks!",0,0
1457,2018-8-29,2018,8,29,22,9b964z,What is the most suitable algorithm for specific time series prediction?,https://www.reddit.com/r/MachineLearning/comments/9b964z/what_is_the_most_suitable_algorithm_for_specific/,char27,1535548387,[removed],0,1
1458,2018-8-29,2018,8,29,22,9b99iy,[D] Learning to Label Aerial Images from Noisy Data,https://www.reddit.com/r/MachineLearning/comments/9b99iy/d_learning_to_label_aerial_images_from_noisy_data/,borbag,1535549140,"[Here is the paper](https://www.cs.toronto.edu/~vmnih/docs/noisy_maps.pdf)

I'm trying to reuse this in a comparison process on noise resilience. At first look this paper looks really cool and you get the general idea. Change the loss function such that you trust more your model than ground truth if your model is really really sure he's right.

But they are far from explicit enough to be re implemented. They don't even explicitly state the final loss function, even if this is the very subject of the paper. Unless I'm missing something?

So I tried to find it by myself. I'll spare you the math, but here is the result, using the same notations as the article :

    $$\epsilon_0(\tilde{m}_i) = \frac{\theta_1 * \hat{m}_i}{\theta_1 * \hat{m}_i + (1- \theta_0) * (1-\hat{m}_i))} - \hat{m}_i$$
    $$\epsilon_1(\tilde{m}_i) = \frac{(1-\theta_1) * \hat{m}_i}{(1-\theta_1) * \hat{m}_i +  \theta_0 *  (1-\hat{m}_i)} -\hat{m}_i$$
    $$\hat{m}_\epsilon = \tilde{m}*-\epsilon_0(\hat{m}) + (1 - \tilde{m}) * (1 - \epsilon_1(\hat{m}))$$

It's the first time I try latex on reddit, if you use an extension like ""tex all the things"" you should be able to see it properly.

[the curves](https://imgur.com/YP456Bb)

So I replace my prediction by this adapted prediction before computing the loss. I have the same curve as the one in the paper. If my model is really sure that there is a building under this pixel and outputs 1, he will then not be punished when the ground truth is 0.

is that really what they did?

I am not able to train my model, as it will quickly see the trick and always output either 0 or 1, driving the loss to 0.
",10,13
1459,2018-8-29,2018,8,29,22,9b9hhb,[P] Adversarial Training on Raw Audio for Voice Conversion,https://www.reddit.com/r/MachineLearning/comments/9b9hhb/p_adversarial_training_on_raw_audio_for_voice/,modulate_ai,1535550878,,6,23
1460,2018-8-29,2018,8,29,23,9b9jan,Text to speech system that uses ssml,https://www.reddit.com/r/MachineLearning/comments/9b9jan/text_to_speech_system_that_uses_ssml/,yungyahoo,1535551278,[removed],0,1
1461,2018-8-29,2018,8,29,23,9b9jmc,Home rig development workflow,https://www.reddit.com/r/MachineLearning/comments/9b9jmc/home_rig_development_workflow/,JoaoFLF,1535551346,"Hey guys,

&amp;#x200B;

I am currently setting up a rig at home to run my ML experiments, but I plan to use my laptop to code and work.

I plan to use jupyter for prototyping but I was wondering what do you use as your python dev workflow with remote machines?

Do you use ssh with tmux or screen to run multiple experiments? 

What about coding, do you edit and/or use a remote file system to code directly on the machine? Or do connect to a remote python kernel with your laptop's IDE.

&amp;#x200B;

Thanks",0,1
1462,2018-8-29,2018,8,29,23,9b9kea,10 Ways Machine Learning Is Revolutionizing Marketing,https://www.reddit.com/r/MachineLearning/comments/9b9kea/10_ways_machine_learning_is_revolutionizing/,Dmitrovic01,1535551508,,0,1
1463,2018-8-29,2018,8,29,23,9b9pjf,Relu6 vs Relu,https://www.reddit.com/r/MachineLearning/comments/9b9pjf/relu6_vs_relu/,jetjodh,1535552530,[removed],0,1
1464,2018-8-29,2018,8,29,23,9b9qml,"[D] Thread from a biostatistician at a hospital about how hard it is to participate in the AI research community while neither in academia nor industry, &amp; proposals about how to fix this issue",https://www.reddit.com/r/MachineLearning/comments/9b9qml/d_thread_from_a_biostatistician_at_a_hospital/,evc123,1535552739,,125,148
1465,2018-8-30,2018,8,30,0,9ba2yb,Back propagation alternatives? Anyone?,https://www.reddit.com/r/MachineLearning/comments/9ba2yb/back_propagation_alternatives_anyone/,auzshah,1535555173,[removed],0,1
1466,2018-8-30,2018,8,30,0,9bab1p,What do you think is the most suitable machine learning approach in this problem?,https://www.reddit.com/r/MachineLearning/comments/9bab1p/what_do_you_think_is_the_most_suitable_machine/,adriaenaa,1535556719,[removed],0,1
1467,2018-8-30,2018,8,30,0,9bail3,"Simple Questions Thread August 29, 2018",https://www.reddit.com/r/MachineLearning/comments/9bail3/simple_questions_thread_august_29_2018/,AutoModerator,1535558145,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",0,1
1468,2018-8-30,2018,8,30,2,9bb83f,Speed up your Keras Training with tf records,https://www.reddit.com/r/MachineLearning/comments/9bb83f/speed_up_your_keras_training_with_tf_records/,smokrow,1535562846,,0,1
1469,2018-8-30,2018,8,30,2,9bbmfi,Best multiple object tracker?,https://www.reddit.com/r/MachineLearning/comments/9bbmfi/best_multiple_object_tracker/,Talos19,1535565553,[removed],0,1
1470,2018-8-30,2018,8,30,3,9bbonu,Odsc west 2018,https://www.reddit.com/r/MachineLearning/comments/9bbonu/odsc_west_2018/,deltaIncrement,1535565969,[removed],0,1
1471,2018-8-30,2018,8,30,3,9bbrew,Mimetik - machine learning software (easy to understand and use),https://www.reddit.com/r/MachineLearning/comments/9bbrew/mimetik_machine_learning_software_easy_to/,mimetik_ia,1535566491,,0,1
1472,2018-8-30,2018,8,30,3,9bbvo7,Artificial intelligence nails predictions of earthquake aftershocks - a neural-network analysis outperforms the method scientists typically use to work out where these tremors will strike.,https://www.reddit.com/r/MachineLearning/comments/9bbvo7/artificial_intelligence_nails_predictions_of/,edwinksl,1535567313,,0,1
1473,2018-8-30,2018,8,30,3,9bbxbc,[D] Finding the most cosine similar vector using active learning.,https://www.reddit.com/r/MachineLearning/comments/9bbxbc/d_finding_the_most_cosine_similar_vector_using/,FlyingOctopus0,1535567632,"I want to make a program for finding interesting interpolation in GAN's latant space.

The idea is simple. I generate some unit vectors denoting direction of interpolation. The program visualizes those interpolations (this part I figured out) and then user has to choose the best one(s). Using this information we generate new directions and we repeat this process to get desired result.

The problem is with generating new directions. I assumed that the influence of the searched direction x is determined by cosine similarity between x and visualized direction v. So it is just dot product of unit vectors x and v. After the choice we know that not chosen directions are less similar to vector x than chosen directions. More formally If v\_1,v\_2, ... v\_n are chosen vectors and a\_1,a\_2,...,a\_{m-n} are the remaining vectors. Then we know that v\_i \\dot x &gt;a\_j \\ dot x what is equivalent to (v\_i-a\_j)\\dot x &gt; 0 for i=1,2,...,n and j=1,2,...,m-n . Now we have to generate new directions based on this knowldege.  It is similar to active learning, but instead of labels we just get relative relation between data points.

Can anybody point my to some reaserch concerning this problem (or variant\\generalization). I think that problem is relatively simple (to state) so there is probably some work done on it. 

PS: I tried searching for a way to sample in the constrained section of a sphere(from a uniform distribution ), but didn't found anything. I tried also approximating section by a half-plane (a little bit like in SVM), but this approach does not work in dynamic case. ",5,2
1474,2018-8-30,2018,8,30,3,9bc01w,I Have Too Many Questions - I'm Newly Getting Started,https://www.reddit.com/r/MachineLearning/comments/9bc01w/i_have_too_many_questions_im_newly_getting_started/,WuchaDoin,1535568153,[removed],0,1
1475,2018-8-30,2018,8,30,3,9bc2nc,Mimetik - new machine learning software (easy to understand and use),https://www.reddit.com/r/MachineLearning/comments/9bc2nc/mimetik_new_machine_learning_software_easy_to/,mimetik_ia,1535568662,,0,1
1476,2018-8-30,2018,8,30,3,9bc53l,[P] Work on the Cold-Start Problem in Energy Timeseries (ML Competition),https://www.reddit.com/r/MachineLearning/comments/9bc53l/p_work_on_the_coldstart_problem_in_energy/,dat-um,1535569144,,0,2
1477,2018-8-30,2018,8,30,4,9bcg5j,TensorFlow.js Crash Course - Machine Learning For The Web - Getting Started - CodingTheSmartWay.com,https://www.reddit.com/r/MachineLearning/comments/9bcg5j/tensorflowjs_crash_course_machine_learning_for/,codingthesmartway,1535571230,,0,0
1478,2018-8-30,2018,8,30,4,9bcl5e,Financial Data analysis with tree-based machine learning algorithoms,https://www.reddit.com/r/MachineLearning/comments/9bcl5e/financial_data_analysis_with_treebased_machine/,xoolooloo,1535572157,,0,1
1479,2018-8-30,2018,8,30,4,9bco4o,Just saw on Twitter that Humble Bundle decided to show us some love again with a machine learning ebook bundle,https://www.reddit.com/r/MachineLearning/comments/9bco4o/just_saw_on_twitter_that_humble_bundle_decided_to/,br4sco,1535572721,,0,1
1480,2018-8-30,2018,8,30,5,9bcqox,Research internship??,https://www.reddit.com/r/MachineLearning/comments/9bcqox/research_internship/,Teenvan1995,1535573177,"So I am a masters student in Germany working on reinforcement learning and was wondering how to get a research internship in any of the research groups. It's really hard to work on reinforcement learning in the industry.
Any pointers or sources would be great. Thanks!

https://github.com/navneet-nmk/pytorch-rl

",0,1
1481,2018-8-30,2018,8,30,5,9bcs23,[N] Just saw on Twitter that Humble Bundle decided to show us some love again with a machine learning ebook bundle,https://www.reddit.com/r/MachineLearning/comments/9bcs23/n_just_saw_on_twitter_that_humble_bundle_decided/,br4sco,1535573436,,0,4
1482,2018-8-30,2018,8,30,6,9bd86s,How do I create this kind of Neural Network by using Python?,https://www.reddit.com/r/MachineLearning/comments/9bd86s/how_do_i_create_this_kind_of_neural_network_by/,sisco_0123,1535576475,,0,1
1483,2018-8-30,2018,8,30,6,9bdhnx,Prediction Markets and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9bdhnx/prediction_markets_and_machine_learning/,D_Oe,1535578315,[removed],0,1
1484,2018-8-30,2018,8,30,7,9bduy7,Webinar on how online retailer (Rue La La) built their recommendation engine using machine learning models,https://www.reddit.com/r/MachineLearning/comments/9bduy7/webinar_on_how_online_retailer_rue_la_la_built/,mfox2,1535580991,,0,1
1485,2018-8-30,2018,8,30,8,9beafp,eGPU over USB 3.1 gen 1 for machine learning,https://www.reddit.com/r/MachineLearning/comments/9beafp/egpu_over_usb_31_gen_1_for_machine_learning/,kutsalmustafa,1535584374,[removed],0,1
1486,2018-8-30,2018,8,30,8,9bedxl,"Interested in Neural Networks, but bad attitude towards math",https://www.reddit.com/r/MachineLearning/comments/9bedxl/interested_in_neural_networks_but_bad_attitude/,BlackberryPy,1535585157,,0,1
1487,2018-8-30,2018,8,30,8,9bedzy,eGPU over USB 3.1 Gen 1 for machine learning,https://www.reddit.com/r/MachineLearning/comments/9bedzy/egpu_over_usb_31_gen_1_for_machine_learning/,kutsalmustafa,1535585173,"Hi r/MachineLearning community,



We have a gaming laptop for training (which has GTX 1060) with an USB 3.1 Gen1 plug. Do anyone know is it possible to connect an eGPU via this plug? Or will it work if we buy a thunderbolt eGPU box, and connect it with some kind of adapter?



I know about perfomance will not be the same because of I/O speeds, but probably USB 3.1 gen 1's speed will be enough for us. Main reason of bottleneck for our model is VRAM of gpu, and because of it we want to accelarate the speed of training with GTX 1080 Ti.",0,1
1488,2018-8-30,2018,8,30,9,9beplp,Intuition for using dropout with ReLU vs with Leaky ReLU (on LeNet5),https://www.reddit.com/r/MachineLearning/comments/9beplp/intuition_for_using_dropout_with_relu_vs_with/,peoplecantalk,1535587788,[removed],0,1
1489,2018-8-30,2018,8,30,10,9bf52k,PyTorch Implementations of Coursera's Deep Learning(deeplearning.ai) Specialization,https://www.reddit.com/r/MachineLearning/comments/9bf52k/pytorch_implementations_of_courseras_deep/,Historical_Coconut,1535591276,[removed],0,1
1490,2018-8-30,2018,8,30,10,9bf6dh,"[D] Intuition for surprising result using (ReLU, LeakyReLU) x (Dropout, No Dropout) on MNIST",https://www.reddit.com/r/MachineLearning/comments/9bf6dh/d_intuition_for_surprising_result_using_relu/,peoplecantalk,1535591586,"I was doing some basic experimentation with LeNet5 (on MNIST) which contains the following simple network:

Conv(1-&gt;32) -&gt; MaxPool(2) -&gt; Conv(32-&gt;64) -&gt; MaxPool(2) -&gt; FullyConnected(1024) -&gt; Dropout -&gt; FullyConnected(10) -&gt; CrossEntropyLoss.

&amp;#x200B;

I was trying to look at the effect of different activations  on the conv/FC layers and how much dropout improved final accuracy.

&amp;#x200B;

I found the following for accuracies. (Note, I applied the activation to all Conv/FC layers)

LeakyReLU + Dropout =&gt; 99.1%

LeakyReLU + No Dropout =&gt; 99.1%

ReLU + Dropout =&gt; 99.2%

**ReLU + No Dropout =&gt; 70%**



I found this really surprising. Any intuition for why ReLU does so badly without dropout whereas LeakyReLU seems to not need dropout? 

&amp;#x200B;

(Used for training: lr=.0001, batch=64, epochs=20)",12,5
1491,2018-8-30,2018,8,30,10,9bfase,PyTorch Implementations of Coursera's Deep Learning(deeplearning.ai) Specialization,https://www.reddit.com/r/MachineLearning/comments/9bfase/pytorch_implementations_of_courseras_deep/,Historical_Coconut,1535592608,"Hi everyone,

I have implemented tensorflow and/or Keras versions of some assignments in PyTorch. Their logic and style may not be exactly the same as their original versions but most of them should be logically close enough. I am not an expert and my implementations are not perfect but I hope this helps some of you.

[github link](https://github.com/furkanu/deeplearning.ai-pytorch)",0,1
1492,2018-8-30,2018,8,30,10,9bfdol,[P] PyTorch Implementations of Coursera's Deep Learning(deeplearning.ai) Specialization,https://www.reddit.com/r/MachineLearning/comments/9bfdol/p_pytorch_implementations_of_courseras_deep/,Historical_Coconut,1535593273,"Hi everyone,

I have implemented tensorflow and/or Keras versions of some assignments in PyTorch. Their logic and style may not be exactly the same as their original versions but most of them should be logically close enough. I am not an expert and my implementations are not perfect but I hope this helps some of you.

[github link](https://github.com/furkanu/deeplearning.ai-pytorch)",6,29
1493,2018-8-30,2018,8,30,11,9bfjsi,Free eBooks on Data Visualization and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9bfjsi/free_ebooks_on_data_visualization_and_machine/,jayjay59,1535594689,,0,1
1494,2018-8-30,2018,8,30,11,9bfqvw,Having a more discussion focused MachineLearning subreddit,https://www.reddit.com/r/MachineLearning/comments/9bfqvw/having_a_more_discussion_focused_machinelearning/,olaf_nij,1535596300,"After discussing with the other moderators, we are deciding to try out a new format for this subreddit. To encourage more focused discussions and a more positive community overall, we are going to emphasize the use of self-posts. Users can still post links, but only within self-posts to give the link more context for further discussion. Current exceptions to this with be arxiv.org links as we've seen in the past this already creates a fairly focused and positive discussion.

We're looking forward to seeing how these changes will continue to move the subreddit forward as it grows.",0,1
1495,2018-8-30,2018,8,30,11,9bfr9p,[D] Having a more discussion focused MachineLearning subreddit,https://www.reddit.com/r/MachineLearning/comments/9bfr9p/d_having_a_more_discussion_focused/,olaf_nij,1535596389,"After discussing with the other moderators, we are deciding to try out a new format for this subreddit. To encourage more focused discussions and a more positive community overall, we are going to emphasize the use of self-posts. Users can still post links, but only within self-posts to give the link more context for further discussion. Current exceptions to this with be arxiv.org links as we've seen in the past this already creates a fairly focused and positive discussion.

We're looking forward to seeing how these changes will continue to move the subreddit forward as it grows.",39,202
1496,2018-8-30,2018,8,30,11,9bfwes,How to start?,https://www.reddit.com/r/MachineLearning/comments/9bfwes/how_to_start/,Love-19,1535597569,"How do I start learning ML?
What are the tools to be downloaded?
What are the programming languages to learn?
And the best source of information?",0,1
1497,2018-8-30,2018,8,30,14,9bgszd,[R] Wasserstein is all you need,https://www.reddit.com/r/MachineLearning/comments/9bgszd/r_wasserstein_is_all_you_need/,baylearn,1535606046,,10,22
1498,2018-8-30,2018,8,30,14,9bgu3f,[R] Revisiting Character-Based Neural Machine Translation with Capacity and Compression,https://www.reddit.com/r/MachineLearning/comments/9bgu3f/r_revisiting_characterbased_neural_machine/,inarrears,1535606314,,4,10
1499,2018-8-30,2018,8,30,14,9bh0to,Why switch to TF Estimator from TF Keras? (Pros and Cons please),https://www.reddit.com/r/MachineLearning/comments/9bh0to/why_switch_to_tf_estimator_from_tf_keras_pros_and/,midnitekoder,1535608291,"For productizing an idea, which is better TF Estimator or TF Keras because in the end what goes into production is TF Serving model?",0,1
1500,2018-8-30,2018,8,30,14,9bh0z7,Any grad students or ML researchers here who want data annotation done?,https://www.reddit.com/r/MachineLearning/comments/9bh0z7/any_grad_students_or_ml_researchers_here_who_want/,Csai,1535608340,[removed],0,1
1501,2018-8-30,2018,8,30,15,9bh4t5,Any grad students or ML researchers here who want data annotation done?,https://www.reddit.com/r/MachineLearning/comments/9bh4t5/any_grad_students_or_ml_researchers_here_who_want/,Csai,1535609511,[removed],0,1
1502,2018-8-30,2018,8,30,15,9bh9rb,Nvidia RTX series will have tensor cores enabled in CUDA - new king in price/performance?,https://www.reddit.com/r/MachineLearning/comments/9bh9rb/nvidia_rtx_series_will_have_tensor_cores_enabled/,ziptofaf,1535611091,[removed],17,56
1503,2018-8-30,2018,8,30,16,9bhfh3,Voting and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9bhfh3/voting_and_machine_learning/,D_Oe,1535612848,[removed],0,1
1504,2018-8-30,2018,8,30,16,9bhhii,[R] MSG (Multi Scale Gradients) - GAN generates 1024 x 1024 CelebA images,https://www.reddit.com/r/MachineLearning/comments/9bhhii/r_msg_multi_scale_gradients_gan_generates_1024_x/,akanimax,1535613485,,1,1
1505,2018-8-30,2018,8,30,16,9bhihe,Machine Learning for Many Body Physics,https://www.reddit.com/r/MachineLearning/comments/9bhihe/machine_learning_for_many_body_physics/,thenikkkhil,1535613813,,0,1
1506,2018-8-30,2018,8,30,16,9bhlee,Revisiting character-based neural machine translation with capacity and compression,https://www.reddit.com/r/MachineLearning/comments/9bhlee/revisiting_characterbased_neural_machine/,adammathias,1535614786,,2,0
1507,2018-8-30,2018,8,30,16,9bhor3,Is this possible? Timedistributed CNN learning from custom loss with reward?,https://www.reddit.com/r/MachineLearning/comments/9bhor3/is_this_possible_timedistributed_cnn_learning/,michael-relleum,1535615966,[removed],0,1
1508,2018-8-30,2018,8,30,17,9bhp5b,Why can attention network be trained without supervision?,https://www.reddit.com/r/MachineLearning/comments/9bhp5b/why_can_attention_network_be_trained_without/,misssprite,1535616087,[removed],0,1
1509,2018-8-30,2018,8,30,17,9bhwqi,Golang is google programming language which also involves machine learning in order to improvise the results,https://www.reddit.com/r/MachineLearning/comments/9bhwqi/golang_is_google_programming_language_which_also/,PriyaNemade,1535618779,,0,1
1510,2018-8-30,2018,8,30,17,9bhxdl,Good practices for storing datasets?,https://www.reddit.com/r/MachineLearning/comments/9bhxdl/good_practices_for_storing_datasets/,n1c0_ds,1535619034,"I am working on a product that uses machine learning. Our team is split between machine learning people, and developers. The machine learning people usually send us a model and we drop it into our application. However, once in a while, we need to retrain the model ourselves, or simply have a look at the training data.

This is where things get messy. There is virtually no traceability on the machine learning side, and we struggle to know exactly which data was used for training, where it sits, and whether the data was altered since then. It feels like opening a folder full of ""`Copy of Untitled 1 (3).pdf.docx`"" files.

My question is ""**how can we better manage our training data?**""

Our requirements are the following:

* Be able to link a version of our model to its training dataset
* Be able to trace a training dataset to its source (as the dataset can evolve over time)
* Be able to ensure that the dataset wasn't tampered with since we used it to train a model (e.g. no files added/removed/modified)
* Be able to easily find datasets
* Be able to easily understand what dataset we are looking at

My foolish solution is the following:

* Generate a hash of the datasets to know if they have changed
* Create a standard README file that describes the dataset, its source, its date of creation etc
* Make the datasets as immutable as possible (readonly at the very least)

That would probably yield a directory structure like this one:

`/datasets`

`/dataset-customer-date`

`checksum.txt`

[`README.md`](https://README.md)

`/data`

Does that make sense? How does your team do it?",0,1
1511,2018-8-30,2018,8,30,18,9bi1ed,"Computer Vision Technologies Market 2018 With Industry Trend Study and Global Players Analysis Like MediaTek, KEYENCE CORPORATION, Basler AG, Synopsys Inc, ISRA VISION, Sony, Teledyne Technologies Incorporated, Cognex Corporation, National Instruments, Te",https://www.reddit.com/r/MachineLearning/comments/9bi1ed/computer_vision_technologies_market_2018_with/,kathline_Says,1535620378,,0,1
1512,2018-8-30,2018,8,30,18,9bi1q1,Machine learning and malware (similarity) detection,https://www.reddit.com/r/MachineLearning/comments/9bi1q1/machine_learning_and_malware_similarity_detection/,zerodayblackhat,1535620484,[removed],0,1
1513,2018-8-30,2018,8,30,19,9biegx,Comb Binding Machine at Best Rates with Easitech,https://www.reddit.com/r/MachineLearning/comments/9biegx/comb_binding_machine_at_best_rates_with_easitech/,kennywilliamson1990,1535624447,,0,1
1514,2018-8-30,2018,8,30,19,9biej6,[D] The lost Machine Learning Definition from A. Samuel,https://www.reddit.com/r/MachineLearning/comments/9biej6/d_the_lost_machine_learning_definition_from_a/,CannLeYun,1535624467,"Hi everyone,

&amp;#x200B;

for my research I'd like to write a properly researched definition of ML. So I went along and did my research, found several important ones, until I got stuck at this definition of Arthur Samuel from 1959. This one for me really is the essence of what machine learning is. It goes like this:

ML is the ""f*ield of study that gives computers the ability to learn without being explicitly programmed*"".

&amp;#x200B;

&amp;#x200B;

The problem is:

I found this on several research papers and blogs, including one from IBM. But when I was going through their sources, most of them were pointing to an article from Samuel from 1959 ""Some studies in machine learning using the game of Checkers (1959)"" ([Citeseerx](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=4532168EB80249485503F6A8F833C8CC?doi=10.1.1.368.2254&amp;rep=rep1&amp;type=pdf)). But in that paper the specific quote is never stated.

While trying to hunt down this quote I found this thread on [stack exchange](https://cs.stackexchange.com/questions/37618/who-coined-the-term-machine-learning). There this problem already popped up 3 years ago, but as far as I can tell never got solved.

&amp;#x200B;

It seems so strange to me, that everybody uses this quote while I cannot find it anywhere. Or is this definition really a myth?

&amp;#x200B;

  
Disclaimer: I am a first time submitter. Please delete the post if it is not compliant with the rules",12,37
1515,2018-8-30,2018,8,30,19,9bigbf,[P] Machine Learning Based App Turns Users Into Live Cartoon Characters.,https://www.reddit.com/r/MachineLearning/comments/9bigbf/p_machine_learning_based_app_turns_users_into/,philippbatura,1535625004,"&amp;#x200B;

[Example of how Chudo's technology works](https://i.redd.it/r365ha8qj7j11.gif)

&amp;#x200B;

[Another Example](https://i.redd.it/xf6etsovj7j11.gif)

&amp;#x200B;

[Another example](https://i.redd.it/lf7hqxezj7j11.gif)

Hey everyone! Our team has been working on the [app called Chudo](https://www.producthunt.com/posts/chudo), that uses machine learning to turn people into personalized characters. We've been building this for two years, collecting unique data, building proprietary machine learning algorithms for face recognition, emotions tracking. The characters are generated automatically by AI and look like animals (and even vegetables).

Most importantly, the app works without the TrueDepth camera and supports old devices like iPhone 5S and Android ones too. The app is cross-platform.

We have launched the app on Android (iOS Version is ""In Review"" status). We also started a [Product Hunt page](https://www.producthunt.com/posts/chudo).

Feel free to check out the app and leave some fair feedback using the link: [https://www.producthunt.com/posts/chudo](https://www.producthunt.com/posts/chudo)",0,1
1516,2018-8-30,2018,8,30,20,9bis69,U.S. Startups Locations Analysis,https://www.reddit.com/r/MachineLearning/comments/9bis69/us_startups_locations_analysis/,viktoriia_shulga,1535628437,,0,13
1517,2018-8-30,2018,8,30,20,9biw9z,"Python Jupyter Notebooks Complete Tutorial | Everything you need to know about them, quite elaborate (Includes some amazing extensions - nbextensions)",https://www.reddit.com/r/MachineLearning/comments/9biw9z/python_jupyter_notebooks_complete_tutorial/,Additional_Proof,1535629509,,0,1
1518,2018-8-30,2018,8,30,21,9bjazh,How to best do automatic video analysis of prototype tests?,https://www.reddit.com/r/MachineLearning/comments/9bjazh/how_to_best_do_automatic_video_analysis_of/,spo0ky_,1535633141,[removed],0,2
1519,2018-8-30,2018,8,30,21,9bjbzm,[R] MSG (Multi Scale Gradients) - GAN generates 1024 x 1024 CelebA images,https://www.reddit.com/r/MachineLearning/comments/9bjbzm/r_msg_multi_scale_gradients_gan_generates_1024_x/,akanimax,1535633372,"In continuation to my previous post about MSG-GAN:


I have been able to generate 1024 x 1024 resolution images using my proposed MSG (Multi-Scale Gradients) - GAN architecture, refer the accompanying image. here -&gt; https://github.com/akanimax/MSG-GAN/blob/master/sourcecode/samples/Celeba/1/doing_%20Work/sample_sheet.jpeg 


Code used for this training has been modified to use the DataParallel feature for multiple GPUs (latest commits). find here -&gt; https://github.com/akanimax/MSG-GAN


I have trained the network for 3 epochs till now; the training is still in progression. The trained models till this checkpoint have been made available here -&gt; https://drive.google.com/drive/folders/119n0CoMDGq2K1dnnGpOA3gOf4RwFAGFs


command for reproduction:

    $ python train.py --images_dir=[path to celeba directory] \
                               --sample_dir=[generated samples directory] \
                               --model_dir=[checkpoints dir] \
                               --depth=9 \
                               --latent_size=512 \
                               --batch_size=32 \
                               --g_lr=0.0003 \
                               --d_lr=0.0003 \


You can train from scratch, or you can use the 3 epochs pretrained models as mentioned above.


I perceive this experiment should validate the hypothesis that the network architecture can indeed be used to synthesise high resolution images.",19,15
1520,2018-8-30,2018,8,30,21,9bjcc6,"Fast, scalable and maintainable project architecture for competitive data science",https://www.reddit.com/r/MachineLearning/comments/9bjcc6/fast_scalable_and_maintainable_project/,Karyo_Ten,1535633455,,1,1
1521,2018-8-30,2018,8,30,22,9bjl8m,doubt regarding Neural Style Transfer,https://www.reddit.com/r/MachineLearning/comments/9bjl8m/doubt_regarding_neural_style_transfer/,ady_anr,1535635468,[removed],0,1
1522,2018-8-30,2018,8,30,22,9bjmp4,Bias Towards Brightness Intensity,https://www.reddit.com/r/MachineLearning/comments/9bjmp4/bias_towards_brightness_intensity/,newtestdrive,1535635800,[removed],0,1
1523,2018-8-30,2018,8,30,22,9bjo1e,Supermicro SuperServer 1028GQ-TXRT 1U 4x NVIDIA Pascal GPU P100 Deep Learning AI Dream Machine,https://www.reddit.com/r/MachineLearning/comments/9bjo1e/supermicro_superserver_1028gqtxrt_1u_4x_nvidia/,MyMining,1535636096,,1,1
1524,2018-8-30,2018,8,30,22,9bjuhu,Adding source code to a publication,https://www.reddit.com/r/MachineLearning/comments/9bjuhu/adding_source_code_to_a_publication/,msusik,1535637485,[removed],0,1
1525,2018-8-30,2018,8,30,23,9bjzfx,Regarding neural style transfer,https://www.reddit.com/r/MachineLearning/comments/9bjzfx/regarding_neural_style_transfer/,ady_anr,1535638504,[removed],0,1
1526,2018-8-30,2018,8,30,23,9bk1yc,One Deep Learning Benchmark to Rule Them All,https://www.reddit.com/r/MachineLearning/comments/9bk1yc/one_deep_learning_benchmark_to_rule_them_all/,gtechmisc,1535639031,,0,1
1527,2018-8-30,2018,8,30,23,9bk3js,[N] One Deep Learning Benchmark to Rule Them All,https://www.reddit.com/r/MachineLearning/comments/9bk3js/n_one_deep_learning_benchmark_to_rule_them_all/,gtechmisc,1535639352,,0,1
1528,2018-8-30,2018,8,30,23,9bk58o,[R] PCA of high dimensional random walks with comparison to neural network training,https://www.reddit.com/r/MachineLearning/comments/9bk58o/r_pca_of_high_dimensional_random_walks_with/,splatula,1535639695,,10,26
1529,2018-8-30,2018,8,30,23,9bk93e,Bayesian Machine learning.,https://www.reddit.com/r/MachineLearning/comments/9bk93e/bayesian_machine_learning/,dvijayd,1535640446,[removed],0,1
1530,2018-8-31,2018,8,31,0,9bkgwk,A great guide for beginners dealing with missing data in datasets,https://www.reddit.com/r/MachineLearning/comments/9bkgwk/a_great_guide_for_beginners_dealing_with_missing/,saloni_ba,1535641957,,0,1
1531,2018-8-31,2018,8,31,0,9bkpnm,How to Make a Bad Deep Learning Accelerator,https://www.reddit.com/r/MachineLearning/comments/9bkpnm/how_to_make_a_bad_deep_learning_accelerator/,failrocket,1535643639,,0,2
1532,2018-8-31,2018,8,31,0,9bktbn,"I built facial landmarking models for dogs using Keras. I know how silly this sounds, but it was an extremely complex ML problem!",https://www.reddit.com/r/MachineLearning/comments/9bktbn/i_built_facial_landmarking_models_for_dogs_using/,hwoolery,1535644339,,0,1
1533,2018-8-31,2018,8,31,0,9bktzv,"[P] I built facial landmarking models for dogs using Keras. I know how silly this sounds, but it was an extremely complex ML problem!",https://www.reddit.com/r/MachineLearning/comments/9bktzv/p_i_built_facial_landmarking_models_for_dogs/,hwoolery,1535644466,,2,3
1534,2018-8-31,2018,8,31,1,9bkxmj,Breaking: Incorporating Prior Information Can Speed Neural Networks Learning By 3.5X While Increasing Accuracy,https://www.reddit.com/r/MachineLearning/comments/9bkxmj/breaking_incorporating_prior_information_can/,jtsymonds,1535645149,,1,1
1535,2018-8-31,2018,8,31,1,9bl1wv,Humble Book Bundle: Machine Learning by O'Reilly,https://www.reddit.com/r/MachineLearning/comments/9bl1wv/humble_book_bundle_machine_learning_by_oreilly/,ItsMeBobSacamano,1535645960,,1,1
1536,2018-8-31,2018,8,31,1,9bl52m,Use of KNN Algo on categorisation of sentiments expressed through short text,https://www.reddit.com/r/MachineLearning/comments/9bl52m/use_of_knn_algo_on_categorisation_of_sentiments/,duckowacko,1535646572,[removed],0,1
1537,2018-8-31,2018,8,31,1,9bldbz,[D] Free-space object detection,https://www.reddit.com/r/MachineLearning/comments/9bldbz/d_freespace_object_detection/,iliauk,1535648130,"Considering cases such as empty spaces in parking lots, empty shelves in a store, empty parts of the road (not necessarily just background class)

Would it make sense to try and do traditional object-detection with the free-space being the bounding-box to predict? Or would it be better to instead predict the main boundary around the objects, identify the objects and then subtract (e.g. this is a car-park in the photo, these are the cars so car-park - cars = empty parking spots).

With the latter it seems you can avoid having to label anything just by chopping a pre-trained two-stage detection model after RPN and just using the region proposals. However you have the issue that not all empty space is free space (e.g. if a car or motorbike can't fit here it's not empty car-park space)

I was curious in general if there has been any work done on cases like detecting empty spaces on store-shelves.",6,7
1538,2018-8-31,2018,8,31,2,9blfis,"[N] Weekly Machine Learning Opensource Roundup  Aug. 30, 2018",https://www.reddit.com/r/MachineLearning/comments/9blfis/n_weekly_machine_learning_opensource_roundup_aug/,stkim1,1535648551,,0,1
1539,2018-8-31,2018,8,31,2,9bllxe,Deep Gradient Compression implementation,https://www.reddit.com/r/MachineLearning/comments/9bllxe/deep_gradient_compression_implementation/,anandj91,1535649704,[removed],0,1
1540,2018-8-31,2018,8,31,2,9blqck,[Question] Extracting face vector from image function?,https://www.reddit.com/r/MachineLearning/comments/9blqck/question_extracting_face_vector_from_image/,jy2k,1535650558,[removed],0,1
1541,2018-8-31,2018,8,31,2,9bltlz,[P] Training a Cell Classifier,https://www.reddit.com/r/MachineLearning/comments/9bltlz/p_training_a_cell_classifier/,histomapping,1535651131,,0,1
1542,2018-8-31,2018,8,31,3,9bm72c,"[D] Could Pose Detection be used on non-humans, such as robot arms?",https://www.reddit.com/r/MachineLearning/comments/9bm72c/d_could_pose_detection_be_used_on_nonhumans_such/,vcxzzxcv,1535653650,"Now with machine learning we have really good pose detection, such as the Open Pose work: 

https://github.com/CMU-Perceptual-Computing-Lab/openpose
https://arxiv.org/abs/1611.08050

I am wondering if this approach/software could possibly be adapted to finding and fitting the poses of other ""things"", such as animals, or more relevant for me, robot arms. 

For example here's pose detection on humans: 

https://www.youtube.com/watch?v=4rIfsORVPzI

How could one leverage the existing work, or adapt/recreate it, to create similar pose outlines for a robot? E.g.

https://www.youtube.com/watch?v=NY-DSU_2gOg (i.e. the goal is to calculate and draw stick outlines representing the pose)

How might you approach the problem? Would it be possible to transfer and adapt existing work from human pose? Would you create data by manually labeling a robot video and then training a similar model? ",10,2
1543,2018-8-31,2018,8,31,4,9bmleq,"[N] Polyaxon 0.2 Updated dashboard, integrations, private registries, better search, replication, SSO, multi volume mounts...",https://www.reddit.com/r/MachineLearning/comments/9bmleq/n_polyaxon_02_updated_dashboard_integrations/,xboost1,1535656387,,0,1
1544,2018-8-31,2018,8,31,4,9bmm7s,"Obscene/fun/interesting hand pose database and or images needed. Middle finger, shocker, etc. #handposeirl",https://www.reddit.com/r/MachineLearning/comments/9bmm7s/obscenefuninteresting_hand_pose_database_and_or/,Fhuckin,1535656542,[removed],0,1
1545,2018-8-31,2018,8,31,4,9bmue1,Using MacBook Pro to run Deep Learning algorithms,https://www.reddit.com/r/MachineLearning/comments/9bmue1/using_macbook_pro_to_run_deep_learning_algorithms/,mano2-mano,1535658139,[removed],0,1
1546,2018-8-31,2018,8,31,4,9bmujm,Data Processing,https://www.reddit.com/r/MachineLearning/comments/9bmujm/data_processing/,always-stressed,1535658159,[removed],0,1
1547,2018-8-31,2018,8,31,5,9bn556,[R] Using Derived Features to Accelerate the Training Time of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9bn556/r_using_derived_features_to_accelerate_the/,jtsymonds,1535660209,,1,1
1548,2018-8-31,2018,8,31,5,9bn8xg,"New free book about / Nuevo libro gratis sobre DEEPLEARNING WITH KERAS for beginners in English, Spanish (in the future in Traditional Chinese) #DL #AI #ML #IA #Keras",https://www.reddit.com/r/MachineLearning/comments/9bn8xg/new_free_book_about_nuevo_libro_gratis_sobre/,jorditorresBCN,1535660962,,0,1
1549,2018-8-31,2018,8,31,5,9bnc2k,"New free book about / Nuevo libro gratis sobre DEEPLEARNING WITH KERAS for beginners in English, Spanish (in the future in Traditional Chinese) #DL #AI #ML #IA #Keras https://torres.ai/DeepLearning",https://www.reddit.com/r/MachineLearning/comments/9bnc2k/new_free_book_about_nuevo_libro_gratis_sobre/,jorditorresBCN,1535661570,,0,1
1550,2018-8-31,2018,8,31,5,9bnfhd,Humble bundle machine learning books by O'Reilly,https://www.reddit.com/r/MachineLearning/comments/9bnfhd/humble_bundle_machine_learning_books_by_oreilly/,TheWickedApple,1535662256,[removed],0,1
1551,2018-8-31,2018,8,31,6,9bnpms,15 Machine Learning books on Humble Bundle for $15,https://www.reddit.com/r/MachineLearning/comments/9bnpms/15_machine_learning_books_on_humble_bundle_for_15/,nomand,1535664763,,0,1
1552,2018-8-31,2018,8,31,7,9bo0b7,[R] Forecasting earthquake aftershock locations with AI-assisted science,https://www.reddit.com/r/MachineLearning/comments/9bo0b7/r_forecasting_earthquake_aftershock_locations/,hardmaru,1535667498,,0,1
1553,2018-8-31,2018,8,31,7,9bo7na,[R] Deep learning of aftershock patterns following large earthquakes,https://www.reddit.com/r/MachineLearning/comments/9bo7na/r_deep_learning_of_aftershock_patterns_following/,hardmaru,1535669336,,0,1
1554,2018-8-31,2018,8,31,7,9bo7xj,[R] Deep learning of aftershock patterns following large earthquakes,https://www.reddit.com/r/MachineLearning/comments/9bo7xj/r_deep_learning_of_aftershock_patterns_following/,baylearn,1535669405,,1,1
1555,2018-8-31,2018,8,31,7,9bo8z5,[P] browser demo various pix2pix models,https://www.reddit.com/r/MachineLearning/comments/9bo8z5/p_browser_demo_various_pix2pix_models/,baylearn,1535669643,,0,1
1556,2018-8-31,2018,8,31,7,9bo95p,Faster Mask-RCNN?,https://www.reddit.com/r/MachineLearning/comments/9bo95p/faster_maskrcnn/,drsxr,1535669678,"Curious if anyone has run across a faster version of the matterport Mask-RCNN.  As opposed to other CNN's I typically use it is much more CPU-dependent - uses up all my CPU cores and doesn't maximize as much on my GPU as I would like it to.

Has anyone come across a better implementation?",0,1
1557,2018-8-31,2018,8,31,7,9bo9i9,[R] Deep learning of aftershock patterns following large earthquakes,https://www.reddit.com/r/MachineLearning/comments/9bo9i9/r_deep_learning_of_aftershock_patterns_following/,downtownslim,1535669759,"Aftershocks are a response to changes in stress generated by large earthquakes and represent the most common observations of the triggering of earthquakes. The maximum magnitude of aftershocks and their temporal decay are well described by empirical laws (such as Baths law1 and Omoris law2), but explaining and forecasting the spatial distribution of aftershocks is more difficult. Coulomb failure stress change3 is perhaps the most widely used criterion to explain the spatial distributions of aftershocks but its applicability has been disputed. Here we use a deep-learning approach to identify a static-stress-based criterion that forecasts aftershock locations without prior assumptions about fault orientation. We show that a neural network trained on more than 131,000 mainshockaftershock pairs can predict the locations of aftershocks in an independent test dataset of more than 30,000 mainshockaftershock pairs more accurately (area under curve of 0.849) than can classic Coulomb failure stress change (area under curve of 0.583). We find that the learned aftershock pattern is physically interpretable: the maximum change in shear stress, the von Mises yield criterion (a scaled version of the second invariant of the deviatoric stress-change tensor) and the sum of the absolute values of the independent components of the stress-change tensor each explain more than 98 per cent of the variance in the neural-network prediction. This machine-learning-driven insight provides improved forecasts of aftershock locations and identifies physical quantities that may control earthquake triggering during the most active part of the seismic cycle.",21,79
1558,2018-8-31,2018,8,31,8,9bodp6,[R] MIT PixelPlayer Sees Where Sounds Are Coming From,https://www.reddit.com/r/MachineLearning/comments/9bodp6/r_mit_pixelplayer_sees_where_sounds_are_coming/,trcytony,1535670620,,0,1
1559,2018-8-31,2018,8,31,8,9boqmd,Deep gradient compression implementation,https://www.reddit.com/r/MachineLearning/comments/9boqmd/deep_gradient_compression_implementation/,anandj91,1535673480,[removed],0,1
1560,2018-8-31,2018,8,31,8,9boqwd,[D] Better version of MaskR-CNN than Matterport?,https://www.reddit.com/r/MachineLearning/comments/9boqwd/d_better_version_of_maskrcnn_than_matterport/,drsxr,1535673551,"Curious if anyone has run across a better and faster version of the  Mask-RCNN than matterport's. As opposed to other CNN's I typically use it is much more CPU-dependent than I expected.  Not complaining - just searching.

Has anyone come across an implementation that they like better?  
",4,15
1561,2018-8-31,2018,8,31,9,9bp3o5,Can self-play PPO beat Stockfish? How will it fare against AlphaZero?,https://www.reddit.com/r/MachineLearning/comments/9bp3o5/can_selfplay_ppo_beat_stockfish_how_will_it_fare/,PuzzledForm,1535676515,[removed],0,1
1562,2018-8-31,2018,8,31,9,9bp3zh,[D] Introducing a modification of an algorithm as extension or a new method?,https://www.reddit.com/r/MachineLearning/comments/9bp3zh/d_introducing_a_modification_of_an_algorithm_as/,schrodingershit,1535676595,"As everyone know, paper writing is an art. I came across papers in which authors have made bare minimum changes to algorithms and introduced them as new techniques. What do you guys think what is an appropriate thing to do?",5,2
1563,2018-8-31,2018,8,31,9,9bp66l,Can self-play PPO beat Stockfish? How will it fare against AlphaZero?,https://www.reddit.com/r/MachineLearning/comments/9bp66l/can_selfplay_ppo_beat_stockfish_how_will_it_fare/,PuzzledForm,1535677121,[removed],0,1
1564,2018-8-31,2018,8,31,10,9bpf6h,Would these be the five pillars of the brain of AI?,https://www.reddit.com/r/MachineLearning/comments/9bpf6h/would_these_be_the_five_pillars_of_the_brain_of_ai/,mozartsixnine,1535679231,[removed],0,1
1565,2018-8-31,2018,8,31,12,9bq5ds,Is NN with no hidden layer is behave like a regression?,https://www.reddit.com/r/MachineLearning/comments/9bq5ds/is_nn_with_no_hidden_layer_is_behave_like_a/,sara0011,1535685662,[removed],0,1
1566,2018-8-31,2018,8,31,13,9bqhp4,[R] Using topology to learn features that speed up neural net training,https://www.reddit.com/r/MachineLearning/comments/9bqhp4/r_using_topology_to_learn_features_that_speed_up/,singhgurjeet,1535688940,,0,1
1567,2018-8-31,2018,8,31,13,9bqly9,[R] IEA: Inner Ensemble Average within a convolutional neural network,https://www.reddit.com/r/MachineLearning/comments/9bqly9/r_iea_inner_ensemble_average_within_a/,AbduallahM,1535690152,[removed],0,1
1568,2018-8-31,2018,8,31,13,9bqn4a,Contextual Emotion Detection in Textual Conversations,https://www.reddit.com/r/MachineLearning/comments/9bqn4a/contextual_emotion_detection_in_textual/,Ankush96Chatterjee,1535690471,[removed],0,1
1569,2018-8-31,2018,8,31,13,9bqq13,[R] ExpIt-OOS: Towards Learning from Planning in Imperfect Information Games,https://www.reddit.com/r/MachineLearning/comments/9bqq13/r_expitoos_towards_learning_from_planning_in/,stringy_pants,1535691241,,2,22
1570,2018-8-31,2018,8,31,14,9bqyry,[D] Is ML research biased by big money?,https://www.reddit.com/r/MachineLearning/comments/9bqyry/d_is_ml_research_biased_by_big_money/,stringy_pants,1535693751,"At ICML last year, in the RL track, presentations were dominated by researchers from Deep Mind. This is one corporate research lab, who is also a major sponsor. It seems impossible to have reliable unbiased research under these conditions.

Some presentations and keynotes have corporate logos on every slide, highly polished graphic design and while often rigorous feel like an academic / marketing hybrid.

Some research papers now, would literally take millions of dollars of cloud compute for a normal person to reproduce. This is not bad in and of itself, but spending huge amounts of money to squeeze out a 1% improvement on a benchmark may not be good science, but a good way for corporations to set up barriers to entry.

Should there be per-track caps on the number of submissions one organization can have at a conference, especially for-profit corporations and sponsors?

Should there be stricter social norms against things like corporate logos on slides?",26,22
1571,2018-8-31,2018,8,31,15,9br67f,HOW LONG HAS IT BEEN SINCE YOU STARTED LEARNING ML AND WHICH IS THE PROJECT YOU'RE MOST PROUD OF?,https://www.reddit.com/r/MachineLearning/comments/9br67f/how_long_has_it_been_since_you_started_learning/,ady_anr,1535696070,[removed],0,1
1572,2018-8-31,2018,8,31,15,9bra4d,"Inductive Bias, not fully grasping",https://www.reddit.com/r/MachineLearning/comments/9bra4d/inductive_bias_not_fully_grasping/,albert1905,1535697296,[removed],0,1
1573,2018-8-31,2018,8,31,15,9bre3g,[R] IEA: Inner Ensemble Average within a convolutional neural network post body,https://www.reddit.com/r/MachineLearning/comments/9bre3g/r_iea_inner_ensemble_average_within_a/,browniesandcookies,1535698542,,6,8
1574,2018-8-31,2018,8,31,16,9brixj,"If machine learning algorithm infers race from data provided and it's behavior starts being racist, how can that be unethical? (e.g. in default risk assessment)",https://www.reddit.com/r/MachineLearning/comments/9brixj/if_machine_learning_algorithm_infers_race_from/,rumaak,1535699963,,0,1
1575,2018-8-31,2018,8,31,16,9brox7,Why you should see AI as your future best friend!,https://www.reddit.com/r/MachineLearning/comments/9brox7/why_you_should_see_ai_as_your_future_best_friend/,soorojul,1535701971,[removed],0,1
1576,2018-8-31,2018,8,31,18,9bs2f0,Contextual Emotion Detection Task in SemEval 2019,https://www.reddit.com/r/MachineLearning/comments/9bs2f0/contextual_emotion_detection_task_in_semeval_2019/,Ankush96Chatterjee,1535706696,"For anyone who is looking to get started with  deep learning, we are organizing a shared task called **EmoContext** in **SemEval** 2019 (which will be held at ACL in Europe or NAACL in USA in summer of 2019). You can find more information about the same at  [https://www.humanizing-ai.com/emocontext.html](https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.humanizing-ai.com%2Femocontext.html&amp;data=02%7C01%7CAnkush.Chatterjee%40microsoft.com%7Cb817cec8d3cd4b64cd8008d60ef2cd23%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636712833321756394&amp;sdata=sL9t7EiFsPg0%2FS3FGQRPN77ZXTSWkzKxXEOjNOcEMck%3D&amp;reserved=0)An LSTM-based baseline script is available for those who want to make their first submissions quickly. Feel free to reach out if you have any queries.",0,1
1577,2018-8-31,2018,8,31,18,9bs2o9,"I desperately need help. Accroding to the work detail, what exactly employer expect me to do. (image attached)",https://www.reddit.com/r/MachineLearning/comments/9bs2o9/i_desperately_need_help_accroding_to_the_work/,B_jennings,1535706782,[removed],0,1
1578,2018-8-31,2018,8,31,18,9bs70f,Non-ANN,https://www.reddit.com/r/MachineLearning/comments/9bs70f/nonann/,theChaosBeast,1535708255,[removed],0,1
1579,2018-8-31,2018,8,31,19,9bsb81,Mathematics for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9bsb81/mathematics_for_machine_learning/,ndha1995,1535709674,,0,1
1580,2018-8-31,2018,8,31,19,9bsit3,Compare models using a subset of the training data,https://www.reddit.com/r/MachineLearning/comments/9bsit3/compare_models_using_a_subset_of_the_training_data/,JosepArnau,1535712031,"Hi, everyone!

I have a large dataset with which I want to train a simple neural network for classification.

I want to test multiple models (whether with different features, layers, etc.) on the dataset and compare them to get the best model.

I was wondering if it would be possible to only train the model candidates using a subset of the dataset in order to save time and still get results that would extrapolate to all the dataset. This ""training"" with the data subset would only be done in order to discriminate the best model between all the other model candidates, not to train the model itself.

After, I would train the best model with the full dataset.

Anyone has any experience, or knows any approach or any paper to do something similar?",0,1
1581,2018-8-31,2018,8,31,20,9bsoct,Mathematics for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9bsoct/mathematics_for_machine_learning/,ndha1995,1535713710,[removed],0,1
1582,2018-8-31,2018,8,31,20,9bsu7q,Improving Factor-Based Quantitative Investing by Forecasting Company Fundamentals,https://www.reddit.com/r/MachineLearning/comments/9bsu7q/improving_factorbased_quantitative_investing_by/,arxseven,1535715320,,11,27
1583,2018-8-31,2018,8,31,21,9bt86j,[P] Tabular implementations of 30+ MDP and POMDP papers,https://www.reddit.com/r/MachineLearning/comments/9bt86j/p_tabular_implementations_of_30_mdp_and_pomdp/,svalorzen,1535718949,"Hello everyone,  


I'm the author and maintainer of [https://github.com/Svalorzen/AI-Toolbox](https://github.com/Svalorzen/AI-Toolbox). This is a C++/Python project that I started during my Master years, as I could not find any comprehensive repository of all the methods that I wanted to experiment with when I was first starting to learn about the field. It contains implementations of more than 30 papers, and it is basically my own way of taking notes of papers I like. It is very actively maintained (by me).  


The code quality is very high and is very well documented, but it only supports tabular representations,. I also hope to be able to use this in course materials, to teach students, so I try to keep the code as simple as possible (which should help if you want to customize it) and explain everything it does in comments. I have published a paper in ICML 2018 using this code, and I am currently trying to publish the toolbox in JMLR.  


I would love to receive any type of feedback, as I have struggled to find people who would engage with the project. I'm not sure whether I am doing something wrong. I really hope you will like it and that it will help you in some way.  
",14,84
1584,2018-8-31,2018,8,31,22,9btixn,YOLO Anchor box,https://www.reddit.com/r/MachineLearning/comments/9btixn/yolo_anchor_box/,praan2413,1535721424,[removed],0,1
1585,2018-8-31,2018,8,31,22,9btm1p,Compare models using a subset of the training data,https://www.reddit.com/r/MachineLearning/comments/9btm1p/compare_models_using_a_subset_of_the_training_data/,JosepArnau,1535722146,[removed],0,1
1586,2018-8-31,2018,8,31,22,9btotg,[D] Compare models using a subset of the training data,https://www.reddit.com/r/MachineLearning/comments/9btotg/d_compare_models_using_a_subset_of_the_training/,JosepArnau,1535722764,"Hi, everyone!

I have a large dataset with which I want to train a simple neural network for classification.

I want to test multiple models (whether with different features, layers, etc.) on the dataset and compare them to get the best model.

I was wondering if it would be possible to only train the model candidates using a subset of the dataset in order to save time and still get results that would extrapolate to all the dataset. This ""training"" with the data subset would only be done in order to discriminate the best model between all the other model candidates, not to train the model itself.

After, I would train the best model with the full dataset.

Anyone has any experience, or knows any approach or any paper to do something similar?",3,3
1587,2018-8-31,2018,8,31,22,9btpe5,[D] Publish peer reviews (nature),https://www.reddit.com/r/MachineLearning/comments/9btpe5/d_publish_peer_reviews_nature/,pablo_gomez,1535722886,"Recently, an [article in nature](https://www.nature.com/articles/d41586-018-06032-w) argued for the publication of reviews (but not necessarily reviewers' names).

Associated with the article is an [open letter](http://asapbio.org/letter) signed by publishers and editors pledging to either implement this in the future or having implemented it already. 

This is already common practice among  some ML conferences/journals afaik. The article argues that some possible drawbacks such as the ""weaponization"" of reviews to discredit science on politicized topics do not outweigh advantages such as better transparency or easier research on the peer-review process.

&amp;#x200B;

Personally, I am happy to see this issue brought up outside of machine learning too and hope this trend will catch on.

&amp;#x200B;

What do you think? 

&amp;#x200B;

Further, I was a little surprised not to find ML folk on the letter, but I presume this is due to the different field and the fact that the letter is only aimed at journals not conferences. Maybe a journal like distill might fit in.",9,13
1588,2018-8-31,2018,8,31,23,9bub5z,What If we can Control The laptop and Play games by using Tech Wearables? It's possible with KAI. Order now on Indiegogo!,https://www.reddit.com/r/MachineLearning/comments/9bub5z/what_if_we_can_control_the_laptop_and_play_games/,vicara_hq,1535727469,,0,1
