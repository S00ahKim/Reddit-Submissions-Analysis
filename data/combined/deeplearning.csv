Unnamed: 0,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
0,2014-8-25,2014,8,25,0,2eg5yn,"DEEP LEARNING: An MIT Press book in preparation by Yoshua Bengio, Ian Goodfellow and Aaron Courville",https://www.reddit.com/r/deeplearning/comments/2eg5yn/deep_learning_an_mit_press_book_in_preparation_by/,[deleted],1408893786,,0,2
1,2014-8-28,2014,8,28,8,2ers4y,Yoshua Bengio's comments on the current state of Deep Learning,https://www.reddit.com/r/deeplearning/comments/2ers4y/yoshua_bengios_comments_on_the_current_state_of/,vikkamath,1409180864,,0,3
0,2014-10-4,2014,10,4,3,2i7nut,this is a test NWM please,https://www.reddit.com/r/deeplearning/comments/2i7nut/this_is_a_test_nwm_please/,[deleted],1412362534,sorry,0,1
0,2014-10-4,2014,10,4,3,2i7nut,this is a test NWM please,https://www.reddit.com/r/deeplearning/comments/2i7nut/this_is_a_test_nwm_please/,[deleted],1412362534,sorry,0,1
1,2014-10-24,2014,10,24,10,2k5oq8,New Theano Deep Learning Tutorial Book,https://www.reddit.com/r/deeplearning/comments/2k5oq8/new_theano_deep_learning_tutorial_book/,kendrick90,1414115830,,0,3
0,2014-12-12,2014,12,12,9,2p128t,Introduction to Deep Learning for Big Data and talks,https://www.reddit.com/r/deeplearning/comments/2p128t/introduction_to_deep_learning_for_big_data_and/,geppelle,1418344456,,0,1
0,2014-12-12,2014,12,12,9,2p128t,Introduction to Deep Learning for Big Data and talks,https://www.reddit.com/r/deeplearning/comments/2p128t/introduction_to_deep_learning_for_big_data_and/,geppelle,1418344456,,0,1
1,2014-12-17,2014,12,17,23,2pkwid,Jeremy Howard: The wonderful and terrifying implications of computers that can learn,https://www.reddit.com/r/deeplearning/comments/2pkwid/jeremy_howard_the_wonderful_and_terrifying/,CaptainHoek,1418828283,,0,8
0,2015-1-18,2015,1,18,22,2stvgu,Google search wants to be your next brain,https://www.reddit.com/r/deeplearning/comments/2stvgu/google_search_wants_to_be_your_next_brain/,jonfla,1421588824,,0,5
1,2015-2-26,2015,2,26,19,2x802k,"Wouldn't it be clever to feed deep learning algorhythms audio books and their text equivalent to teach them language, or has this been done already?",https://www.reddit.com/r/deeplearning/comments/2x802k/wouldnt_it_be_clever_to_feed_deep_learning/,Morex2000,1424948249,"I was cutting some audio books to find interesting quotes the other day, and wondered if those audio books wouldn't be the perfect datasets to feed deep learning algorhythms. I thought one would just have to feed them the audiobooks and the equivalent text files, to teach the algorhythm how words sound. There is literally 10s of thousands of hours of perfectly intonated and pronounced audio material and each of those is perfectly written down.
Anybody got some intel on that thought?",2,2
0,2015-2-26,2015,2,26,19,2x802k,"Wouldn't it be clever to feed deep learning algorhythms audio books and their text equivalent to teach them language, or has this been done already?",https://www.reddit.com/r/deeplearning/comments/2x802k/wouldnt_it_be_clever_to_feed_deep_learning/,Morex2000,1424948249,"I was cutting some audio books to find interesting quotes the other day, and wondered if those audio books wouldn't be the perfect datasets to feed deep learning algorhythms. I thought one would just have to feed them the audiobooks and the equivalent text files, to teach the algorhythm how words sound. There is literally 10s of thousands of hours of perfectly intonated and pronounced audio material and each of those is perfectly written down.
Anybody got some intel on that thought?",2,2
1,2015-3-10,2015,3,10,3,2ygrg1,A Full Hardware Guide to Deep Learning,https://www.reddit.com/r/deeplearning/comments/2ygrg1/a_full_hardware_guide_to_deep_learning/,RockDiesel,1425924812,,0,9
0,2015-3-10,2015,3,10,3,2ygrg1,A Full Hardware Guide to Deep Learning,https://www.reddit.com/r/deeplearning/comments/2ygrg1/a_full_hardware_guide_to_deep_learning/,RockDiesel,1425924812,,0,9
1,2015-3-14,2015,3,14,1,2yxak9,Edu-Video | Introduction to Deep Learning (Class Videos),https://www.reddit.com/r/deeplearning/comments/2yxak9/eduvideo_introduction_to_deep_learning_class/,Friars1993,1426264440,,0,1
0,2015-5-13,2015,5,13,19,35tevq,What math is needed for doing research on deep learning?,https://www.reddit.com/r/deeplearning/comments/35tevq/what_math_is_needed_for_doing_research_on_deep/,AEEEE3,1431513540,"What particular areas of math are most useful for deep learning research?  Also, explain WHY those areas of math are important.

I don't have a math degree (finance unfortunately) so I want to know what are the minimum classes I am going to need to take to get into a PhD focused on deep learning?

I believe I am mathematically gifted and could get at least in the the top 5 percentile for the quant of GRE.  However my ""gift"" didn't start kicking in until I was like 17.  I started at a community college and did very well up to Calculus II.  I pretty much loved math.  Then a few things happened.  I took 1 absolutely awfully taught class during the summer (this guy was like 4 standard deviations worse than any other teacher I've had) but because it was a prereq, I had to take it.  I didn't think it would affect my love of math but it did.  Around that time I was reading on higher level math on my own, stuff like ""Proofs without words"" and ""Concepts of Modern Mathematics"".  I was also having to transfer from my CC to a state university.  This was during the hedge fund boom, and hearing about the ridiculous salaries that people made in quantitative finance, and after getting rejectd from a great universities math degree, since I was going to a lesser university, I decided to be more practical.  Finance had a lot of math, or so I was told.

If deep learning hadn't come along I probably woudn't have changed my opinion.  I had taken a strong interest in neuroscience for the past 4 years anyways, but reading about deep learning has allowed me to understand higher math, which I have never taken formally, but I know I need to. The idea of an ""algerbra of reasoning"" as posited in ""From Machine Learning to Machine Reasoning"" and the other ideas are amazing.  I understand linear algerbra, but I never took a class.  The way I understand it, is that vectors are like ""higher dimensional analogs"" of regular numbers.  Hence you need a new algebra to do stuff with them.  Matricies are like functions for these higher-dimensional numbers (aka vectors).

I understand how you can map things in an n-dimensional parameter space and like things will end up close together, possibly on some manifold.  The fact that these spatial relations can define an algerbra which can be used for reasoning as proven by https://code.google.com/p/word2vec/ is amazing.

Basically, I want to take classes, and get the math I will need, and get into a PhD program focused on deep learning.

As far as I understand, graduate schools will let you in for a different subject, but usually you have to take certain courses, so I want to take the courses that will be necessary to get into deep learning, and perhaps I can do research with a professor as well (is that likley?)  Because I heard undergrad research is a must for grad school.  I want to do research.

So what math classes should I take?


",3,7
0,2015-5-13,2015,5,13,19,35tevq,What math is needed for doing research on deep learning?,https://www.reddit.com/r/deeplearning/comments/35tevq/what_math_is_needed_for_doing_research_on_deep/,AEEEE3,1431513540,"What particular areas of math are most useful for deep learning research?  Also, explain WHY those areas of math are important.

I don't have a math degree (finance unfortunately) so I want to know what are the minimum classes I am going to need to take to get into a PhD focused on deep learning?

I believe I am mathematically gifted and could get at least in the the top 5 percentile for the quant of GRE.  However my ""gift"" didn't start kicking in until I was like 17.  I started at a community college and did very well up to Calculus II.  I pretty much loved math.  Then a few things happened.  I took 1 absolutely awfully taught class during the summer (this guy was like 4 standard deviations worse than any other teacher I've had) but because it was a prereq, I had to take it.  I didn't think it would affect my love of math but it did.  Around that time I was reading on higher level math on my own, stuff like ""Proofs without words"" and ""Concepts of Modern Mathematics"".  I was also having to transfer from my CC to a state university.  This was during the hedge fund boom, and hearing about the ridiculous salaries that people made in quantitative finance, and after getting rejectd from a great universities math degree, since I was going to a lesser university, I decided to be more practical.  Finance had a lot of math, or so I was told.

If deep learning hadn't come along I probably woudn't have changed my opinion.  I had taken a strong interest in neuroscience for the past 4 years anyways, but reading about deep learning has allowed me to understand higher math, which I have never taken formally, but I know I need to. The idea of an ""algerbra of reasoning"" as posited in ""From Machine Learning to Machine Reasoning"" and the other ideas are amazing.  I understand linear algerbra, but I never took a class.  The way I understand it, is that vectors are like ""higher dimensional analogs"" of regular numbers.  Hence you need a new algebra to do stuff with them.  Matricies are like functions for these higher-dimensional numbers (aka vectors).

I understand how you can map things in an n-dimensional parameter space and like things will end up close together, possibly on some manifold.  The fact that these spatial relations can define an algerbra which can be used for reasoning as proven by https://code.google.com/p/word2vec/ is amazing.

Basically, I want to take classes, and get the math I will need, and get into a PhD program focused on deep learning.

As far as I understand, graduate schools will let you in for a different subject, but usually you have to take certain courses, so I want to take the courses that will be necessary to get into deep learning, and perhaps I can do research with a professor as well (is that likley?)  Because I heard undergrad research is a must for grad school.  I want to do research.

So what math classes should I take?


",3,7
1,2015-7-22,2015,7,22,10,3e5alc,can i do deep learning research? what minimum resources do i need?,https://www.reddit.com/r/deeplearning/comments/3e5alc/can_i_do_deep_learning_research_what_minimum/,poporing88,1437529808,i use windows and have a 24gb PC... can i do deep learning in a virtual box? what framework is most suitable with my setup? theano?,2,2
0,2015-7-22,2015,7,22,10,3e5alc,can i do deep learning research? what minimum resources do i need?,https://www.reddit.com/r/deeplearning/comments/3e5alc/can_i_do_deep_learning_research_what_minimum/,poporing88,1437529808,i use windows and have a 24gb PC... can i do deep learning in a virtual box? what framework is most suitable with my setup? theano?,2,2
0,2015-7-22,2015,7,22,10,3e5alc,can i do deep learning research? what minimum resources do i need?,https://www.reddit.com/r/deeplearning/comments/3e5alc/can_i_do_deep_learning_research_what_minimum/,poporing88,1437529808,i use windows and have a 24gb PC... can i do deep learning in a virtual box? what framework is most suitable with my setup? theano?,2,2
1,2015-7-26,2015,7,26,22,3enmwe,ConvNetJS - Deep Learning in your browser,https://www.reddit.com/r/deeplearning/comments/3enmwe/convnetjs_deep_learning_in_your_browser/,john_philip,1437915789,,0,2
0,2015-8-7,2015,8,7,8,3g2e2x,Deeplearning for Java developers. a simple tutorial site,https://www.reddit.com/r/deeplearning/comments/3g2e2x/deeplearning_for_java_developers_a_simple/,nrshrivatsan,1438903417,,1,1
1,2015-8-11,2015,8,11,2,3ghmt5,Labellio: Scalable Cloud Architecture for Efficient Multi-GPU Deep Learning,https://www.reddit.com/r/deeplearning/comments/3ghmt5/labellio_scalable_cloud_architecture_for/,umitanuki,1439228970,,0,5
2,2015-8-14,2015,8,14,14,3gy1qt,NVIDIA and IBM Cloud Support ImageNet Large Scale Visual Recognition Challenge (Free GPUs for Competitors),https://www.reddit.com/r/deeplearning/comments/3gy1qt/nvidia_and_ibm_cloud_support_imagenet_large_scale/,harrism,1439531873,,0,1
3,2015-8-16,2015,8,16,1,3h3whf,Deep Learning Bitmaps to PCM Audio -- source code and trained brains included!,https://www.reddit.com/r/deeplearning/comments/3h3whf/deep_learning_bitmaps_to_pcm_audio_source_code/,skruntskrunt,1439655948,,0,1
4,2015-8-21,2015,8,21,11,3hssrd,Harnessing the Caffe Framework for Deep Visualization,https://www.reddit.com/r/deeplearning/comments/3hssrd/harnessing_the_caffe_framework_for_deep/,harrism,1440124240,,0,3
5,2015-8-23,2015,8,23,17,3i27kw,"Recursive Deep Learning for Modelling Compositional and Grounded Meaning  Richard Socher, Founder of MetaMind",https://www.reddit.com/r/deeplearning/comments/3i27kw/recursive_deep_learning_for_modelling/,ojaved,1440318021,,0,1
0,2015-9-2,2015,9,2,14,3jbgvi,What can I do with Deep Learning?,https://www.reddit.com/r/deeplearning/comments/3jbgvi/what_can_i_do_with_deep_learning/,john_philip,1441170198,,0,1
1,2015-9-2,2015,9,2,21,3jcitg,Mocha.jl: Deep Learning for Julia,https://www.reddit.com/r/deeplearning/comments/3jcitg/mochajl_deep_learning_for_julia/,harrism,1441195465,,0,1
2,2015-9-3,2015,9,3,2,3jdoiu,Find your Dream Job!,https://www.reddit.com/r/deeplearning/comments/3jdoiu/find_your_dream_job/,[deleted],1441213719,[deleted],0,1
3,2015-9-3,2015,9,3,2,3jdq4o,Find your Dream Job! A Recurrent Neural Network learns Indeed.com Job Postings,https://www.reddit.com/r/deeplearning/comments/3jdq4o/find_your_dream_job_a_recurrent_neural_network/,mwakanosya,1441214329,,1,2
4,2015-9-7,2015,9,7,0,3jv21j,Good tutorials on Youtube from this guy.,https://www.reddit.com/r/deeplearning/comments/3jv21j/good_tutorials_on_youtube_from_this_guy/,DeepDeadMind,1441552016,,1,4
5,2015-9-24,2015,9,24,5,3m41or,Deep Learning Tutorial by Lizhen Qu,https://www.reddit.com/r/deeplearning/comments/3m41or/deep_learning_tutorial_by_lizhen_qu/,ojaved,1443040407,,0,1
6,2015-9-24,2015,9,24,7,3m4m3k,apple's deep learning challenge,https://www.reddit.com/r/deeplearning/comments/3m4m3k/apples_deep_learning_challenge/,toisanji,1443048748,,0,0
0,2015-10-7,2015,10,7,22,3nu7ww,Deep Learning with Torch: blog series,https://www.reddit.com/r/deeplearning/comments/3nu7ww/deep_learning_with_torch_blog_series/,fabiofumarola,1444224871,,0,6
1,2015-10-12,2015,10,12,21,3ofysc,Deep Learning with torch 5: practically training RNNs and LSTMs using Torch,https://www.reddit.com/r/deeplearning/comments/3ofysc/deep_learning_with_torch_5_practically_training/,fabiofumarola,1444652039,,0,4
2,2015-10-13,2015,10,13,21,3oktd5,OpenFace: Face recognition with Google's FaceNet deep neural network.,https://www.reddit.com/r/deeplearning/comments/3oktd5/openface_face_recognition_with_googles_facenet/,bdamos,1444738726,,0,5
3,2015-10-14,2015,10,14,20,3opkhc,"Interview with Matthew Zeiler, founder and CEO of deep-learning startup Clarifai",https://www.reddit.com/r/deeplearning/comments/3opkhc/interview_with_matthew_zeiler_founder_and_ceo_of/,ghazalbig,1444821646,,0,1
4,2015-10-19,2015,10,19,5,3p9obi,"A Tutorial on Deep Learning Part 2: Autoencoders, Convolutional Neural Networks and Recurrent Neural Networks [PDF]",https://www.reddit.com/r/deeplearning/comments/3p9obi/a_tutorial_on_deep_learning_part_2_autoencoders/,RockDiesel,1445200511,,0,6
5,2015-10-25,2015,10,25,1,3q1pt5,Deep learning for detecting images regions,https://www.reddit.com/r/deeplearning/comments/3q1pt5/deep_learning_for_detecting_images_regions/,selat,1445705437,"Are there any articles about using deep learning for separating parts of images into classes? For example, is it possible to detect regions like ""forest"", ""road"", ""building"" on one image?",3,2
6,2015-10-27,2015,10,27,18,3qeflp,Deep Minds: An Interview with Google's Alex Graves &amp; Koray Kavukcuoglu #reworkDL,https://www.reddit.com/r/deeplearning/comments/3qeflp/deep_minds_an_interview_with_googles_alex_graves/,[deleted],1445939983,[deleted],0,1
7,2015-10-27,2015,10,27,19,3qei69,I've Taught Computers How to Paint Portraits  and to Code,https://www.reddit.com/r/deeplearning/comments/3qei69/ive_taught_computers_how_to_paint_portraits_and/,reworksophie,1445941901,,0,1
8,2015-10-27,2015,10,27,19,3qejvc,Deep Learning for Computer Vision with MATLAB and cuDNN,https://www.reddit.com/r/deeplearning/comments/3qejvc/deep_learning_for_computer_vision_with_matlab_and/,harrism,1445943133,,0,2
9,2015-10-27,2015,10,27,23,3qfd74,Blocks and fuel overview,https://www.reddit.com/r/deeplearning/comments/3qfd74/blocks_and_fuel_overview/,deepbeast,1445957976,,0,1
10,2015-10-28,2015,10,28,1,3qfphn,"New Q&amp;A on our blog today with Google DeepMind senior research scientists Alex Graves &amp; Koray Kavukcuoglu discussing neural Turing machines, reinforcement learning, personal thoughts on deep learning &amp; more",https://www.reddit.com/r/deeplearning/comments/3qfphn/new_qa_on_our_blog_today_with_google_deepmind/,reworksophie,1445962783,,0,1
11,2015-10-29,2015,10,29,5,3qluj7,Deep Learning in a Nutshell,https://www.reddit.com/r/deeplearning/comments/3qluj7/deep_learning_in_a_nutshell/,dabshitty,1446062926,,0,0
12,2015-10-29,2015,10,29,10,3qn72l,deep learning is still missing a key ingredient,https://www.reddit.com/r/deeplearning/comments/3qn72l/deep_learning_is_still_missing_a_key_ingredient/,toisanji,1446081832,,0,0
13,2015-10-29,2015,10,29,21,3qoyk0,"Visionary Cars: With Deep Learning, Autonomous Cars Get Smarter as They Drive",https://www.reddit.com/r/deeplearning/comments/3qoyk0/visionary_cars_with_deep_learning_autonomous_cars/,reworksophie,1446120341,,0,1
14,2015-10-31,2015,10,31,1,3quyxe,How Deep Learning APIs Can Solve Real-World Data Issues,https://www.reddit.com/r/deeplearning/comments/3quyxe/how_deep_learning_apis_can_solve_realworld_data/,Nuno_EdgarFernandes,1446224341,,0,2
0,2015-11-3,2015,11,3,7,3r9t95,Deep learning project,https://www.reddit.com/r/deeplearning/comments/3r9t95/deep_learning_project/,szabx,1446503611,"Hello there,

I have a uni project about recognizing something in an image. Samples are given in a huge database. I am very new to this thing, so my question is what would be the easiest to learn  and well documented framework/software that supports CNN?

Thanks",4,2
1,2015-11-5,2015,11,5,1,3riafv,Google is using AI to create automatic email replies,https://www.reddit.com/r/deeplearning/comments/3riafv/google_is_using_ai_to_create_automatic_email/,jonfla,1446653989,,0,2
2,2015-11-5,2015,11,5,9,3rk9gh,Deep Learning in a Nutshell: Core Concepts,https://www.reddit.com/r/deeplearning/comments/3rk9gh/deep_learning_in_a_nutshell_core_concepts/,harrism,1446681826,,0,7
3,2015-11-11,2015,11,11,5,3sbet0,Google Open Sources its Deep Learning framework - TensorFlow,https://www.reddit.com/r/deeplearning/comments/3sbet0/google_open_sources_its_deep_learning_framework/,deeperlearner,1447186634,,0,2
4,2015-11-12,2015,11,12,20,3sitll,Inference: The Next Step in GPU-Accelerated Deep Learning,https://www.reddit.com/r/deeplearning/comments/3sitll/inference_the_next_step_in_gpuaccelerated_deep/,harrism,1447326259,,0,1
5,2015-11-15,2015,11,15,5,3sthz1,Deep Neural Decision Forests,https://www.reddit.com/r/deeplearning/comments/3sthz1/deep_neural_decision_forests/,woadwarrior,1447533429,,0,2
6,2015-11-16,2015,11,16,5,3sxqbt,Interesting listing of opensource deeplearning frameworks,https://www.reddit.com/r/deeplearning/comments/3sxqbt/interesting_listing_of_opensource_deeplearning/,danyblue,1447620678,,0,3
7,2015-11-26,2015,11,26,17,3ubqvz,Any good multi-GPU LSTM implementations?,https://www.reddit.com/r/deeplearning/comments/3ubqvz/any_good_multigpu_lstm_implementations/,anonDogeLover,1448527088,Does anyone know any deep learning frameworks that can train LSTMs using multiple GPUs?,0,3
8,2015-11-28,2015,11,28,2,3uhgwy,Interview with deep learning expert Andrej Karpathy,https://www.reddit.com/r/deeplearning/comments/3uhgwy/interview_with_deep_learning_expert_andrej/,reworksophie,1448644982,,0,1
9,2015-11-30,2015,11,30,13,3ut4hr,CAFFE INSTALLATION ON UBUNTU 14.04,https://www.reddit.com/r/deeplearning/comments/3ut4hr/caffe_installation_on_ubuntu_1404/,mwakanosya,1448857259,,0,3
0,2015-12-2,2015,12,2,2,3v0qv0,Deep Neural Networks' models already trained for object classification,https://www.reddit.com/r/deeplearning/comments/3v0qv0/deep_neural_networks_models_already_trained_for/,sungiv,1448990378,"Hi. I've been recently introduced to deep learning and I would like to try it in object classification. I read some papers and saw some object categories datasets, but initially I'm looking for some models already trained, which I could use to observe how deep models visualize objects in practice.

I found this github which I'm going to try: https://github.com/uoguelph-mlrg/theano_alexnet

However, I'm looking for more different models to perform a comparison. Do you know where can I find those models?

Thank you in advance. ",1,1
1,2015-12-2,2015,12,2,21,3v4wiv,Deep Learning and Robots,https://www.reddit.com/r/deeplearning/comments/3v4wiv/deep_learning_and_robots/,PrestonBerg,1449060058,,0,2
2,2015-12-3,2015,12,3,20,3v9php,Chemical structure extraction from images with deep learning,https://www.reddit.com/r/deeplearning/comments/3v9php/chemical_structure_extraction_from_images_with/,eleitl,1449142070,"I'm trying to figure out the hardware requirements for extraction of chemical structures from a very large (millions) number of images like https://commons.wikimedia.org/wiki/File:Solanine_chemical_structure.png by way of deep learning. The images vary in quality and way a given chemical structure (think of it as a graph, or connectivity table) is drawn.

Q1: How many machines (do they need to have GPU?) do you think one would need for such a project?

Q2: How long would one need to extract the graph information from such an image, in terms of machine time? Seconds, minutes?

Q3: What kind of error rates are we likely looking at? Current solutions like e.g. OSRA take forever (minutes) and produce a high error rate.",8,3
3,2015-12-7,2015,12,7,8,3vpw2x,Medicine Related Deep Learning in the Bay Area? : MachineLearning,https://www.reddit.com/r/deeplearning/comments/3vpw2x/medicine_related_deep_learning_in_the_bay_area/,freelyread,1449443813,,0,2
4,2015-12-7,2015,12,7,23,3vskde,"The present, future and challenges of deep learning.",https://www.reddit.com/r/deeplearning/comments/3vskde/the_present_future_and_challenges_of_deep_learning/,YRAL_TV,1449498469,,0,3
5,2015-12-9,2015,12,9,2,3vy7ix,"Check out the Deep Learning playlist: 79 presentations available for free - includes speakers from Baidu, Stanford University, Google, DeepMind, Twitter, Flickr, MIT, U of Toronto &amp; more",https://www.reddit.com/r/deeplearning/comments/3vy7ix/check_out_the_deep_learning_playlist_79/,reworksophie,1449594131,,0,1
6,2015-12-10,2015,12,10,22,3w808k,Deep Reinforcement Learning for Robotics,https://www.reddit.com/r/deeplearning/comments/3w808k/deep_reinforcement_learning_for_robotics/,reworksophie,1449754762,,0,1
7,2015-12-11,2015,12,11,1,3w8pzl,Image recognition of several instances of the same object in a given image,https://www.reddit.com/r/deeplearning/comments/3w8pzl/image_recognition_of_several_instances_of_the/,tunguz,1449765249,[removed],0,1
8,2015-12-17,2015,12,17,12,3x62pz,Deep Learning in a Nutshell part 2: History and Training,https://www.reddit.com/r/deeplearning/comments/3x62pz/deep_learning_in_a_nutshell_part_2_history_and/,harrism,1450323136,,0,1
9,2015-12-18,2015,12,18,3,3x8rbf,"A Q&amp;A with Ilya Sutskever, Research Director at OpenAI",https://www.reddit.com/r/deeplearning/comments/3x8rbf/a_qa_with_ilya_sutskever_research_director_at/,reworksophie,1450376221,,0,1
10,2015-12-19,2015,12,19,5,3xdysr,Story of a decent amen break generated by LSTM! [own blog post],https://www.reddit.com/r/deeplearning/comments/3xdysr/story_of_a_decent_amen_break_generated_by_lstm/,fiala__,1450471108,,0,5
11,2015-12-30,2015,12,30,4,3you2w,Here's What We Can Expect from Deep Learning in 2016 and Beyond (Roundtable Q&amp;A with 14 Experts),https://www.reddit.com/r/deeplearning/comments/3you2w/heres_what_we_can_expect_from_deep_learning_in/,reworksophie,1451417955,,0,1
0,2016-1-1,2016,1,1,22,3z0kmu,How I Learned To Code Neural Networks In 2015,https://www.reddit.com/r/deeplearning/comments/3z0kmu/how_i_learned_to_code_neural_networks_in_2015/,mrborgen86,1451653914,,0,4
1,2016-1-4,2016,1,4,19,3zebek,"20% off tickets to upcoming Deep Learning Summits in San Francisco, Boston, London &amp; Singapore (includes Startup/Student passes)",https://www.reddit.com/r/deeplearning/comments/3zebek/20_off_tickets_to_upcoming_deep_learning_summits/,reworksophie,1451904258,,0,1
2,2016-1-4,2016,1,4,20,3zed6d,5 deep learning startups to follow in 2016,https://www.reddit.com/r/deeplearning/comments/3zed6d/5_deep_learning_startups_to_follow_in_2016/,reworksophie,1451905442,,0,1
3,2016-1-8,2016,1,8,14,3zznyz,LSTM Benchmarks,https://www.reddit.com/r/deeplearning/comments/3zznyz/lstm_benchmarks/,anonDogeLover,1452230257,I'm looking for comparisons of deep learning frameworks that include LSTMs. I need to run an LSTM on a massive dataset and need to know which will offer the absolute fastest implementation. Any advice or recommended reading/resources?,2,2
4,2016-1-8,2016,1,8,17,400beh,[deeplearning] Base profiles unmarried age 21+ online. The base is available only 2 hours.,https://www.reddit.com/r/deeplearning/comments/400beh/deeplearning_base_profiles_unmarried_age_21/,kranri771531,1452243122,,0,0
5,2016-1-12,2016,1,12,15,40ld68,Is 2016 the Year of AI?,https://www.reddit.com/r/deeplearning/comments/40ld68/is_2016_the_year_of_ai/,vincentg64,1452581046,,0,1
6,2016-1-15,2016,1,15,3,40ytk3,Baidu Releases New Deep Learning Open Source Code 'Warp-CTC',https://www.reddit.com/r/deeplearning/comments/40ytk3/baidu_releases_new_deep_learning_open_source_code/,reworksophie,1452795524,,0,1
7,2016-1-15,2016,1,15,5,40zjir,"Interview with Adam Coates, Director of Baidu's Silicon Valley AI Lab - talking Warp-CTC, Deep Speech 2 &amp; more",https://www.reddit.com/r/deeplearning/comments/40zjir/interview_with_adam_coates_director_of_baidus/,reworksophie,1452804536,,0,1
8,2016-1-19,2016,1,19,1,41jmql,Striving testing binary Deep Learning classifier with caffe and OpenCV Contrib,https://www.reddit.com/r/deeplearning/comments/41jmql/striving_testing_binary_deep_learning_classifier/,[deleted],1453134258,[deleted],0,1
9,2016-1-19,2016,1,19,18,41ntxe,8th layer in Caffe's AlexNet clone?,https://www.reddit.com/r/deeplearning/comments/41ntxe/8th_layer_in_caffes_alexnet_clone/,anonDogeLover,1453195279,Does anyone know what the fc8 layer does in Caffe's AlexNet clone (CaffeNet)? This layer is not in the original paper.,3,3
10,2016-1-19,2016,1,19,20,41o9fn,OpenFace 0.2.0: Higher accuracy and halved execution time.,https://www.reddit.com/r/deeplearning/comments/41o9fn/openface_020_higher_accuracy_and_halved_execution/,bdamos,1453203959,,0,3
11,2016-1-22,2016,1,22,2,420wce,breaking deep learning captioning systems,https://www.reddit.com/r/deeplearning/comments/420wce/breaking_deep_learning_captioning_systems/,toisanji,1453395869,,1,1
12,2016-1-22,2016,1,22,4,421gpv,What Deep Learning book does Reddit recommend?,https://www.reddit.com/r/deeplearning/comments/421gpv/what_deep_learning_book_does_reddit_recommend/,QuestionProgram,1453403076,"...title says all

*or does it?*",3,2
13,2016-1-23,2016,1,23,5,427dow,What will be the next big thing in machine learning after deep learning?,https://www.reddit.com/r/deeplearning/comments/427dow/what_will_be_the_next_big_thing_in_machine/,b1gde4l,1453494241,Any broad predictions? Or will the post-deep learning future of ML be based on manipulations of deep neural nets?,5,2
14,2016-1-23,2016,1,23,23,42b1in,Study Group for Tenzor Flow,https://www.reddit.com/r/deeplearning/comments/42b1in/study_group_for_tenzor_flow/,StarAvenger,1453559752,"Hi,

I am starting a course on TF using Google free deep learning course on Udacity. While the course is great, I find myself sometimes unsure why I am doing what I am doing. 

Is there a community / studygroup where you can ask questions about this course?

",4,5
15,2016-1-26,2016,1,26,9,42oq19,Scalable Data Science and Deep Learning with H2O.ai,https://www.reddit.com/r/deeplearning/comments/42oq19/scalable_data_science_and_deep_learning_with_h2oai/,reworksophie,1453767613,,0,1
16,2016-1-28,2016,1,28,2,42ykd7,A Deep Net that Predicts Emojis for Images: Emojini by Curalate,https://www.reddit.com/r/deeplearning/comments/42ykd7/a_deep_net_that_predicts_emojis_for_images/,louk83,1453915977,,0,6
17,2016-1-28,2016,1,28,9,430ryk,Google Deepminds 'AlphaGo' just beat the European Go Champion,https://www.reddit.com/r/deeplearning/comments/430ryk/google_deepminds_alphago_just_beat_the_european/,ScruffySteez,1453942449,,0,0
18,2016-1-31,2016,1,31,22,43j1jw,"""There is not much low-hanging fruit left for deep learning""",https://www.reddit.com/r/deeplearning/comments/43j1jw/there_is_not_much_lowhanging_fruit_left_for_deep/,dispcm,1454246851,,0,7
0,2016-2-4,2016,2,4,1,440fpf,DeepArt is selling first painting generated by a computer,https://www.reddit.com/r/deeplearning/comments/440fpf/deepart_is_selling_first_painting_generated_by_a/,[deleted],1454515429,[deleted],0,1
1,2016-2-4,2016,2,4,1,440k95,DeepArt is selling the first painting generated by artificial intelligence,https://www.reddit.com/r/deeplearning/comments/440k95/deepart_is_selling_the_first_painting_generated/,[deleted],1454516994,[deleted],1,2
2,2016-2-9,2016,2,9,3,44s7mu,Join the celebration of women working in Machine Intelligence at this dinner in London! Speakers include Google DeepMind. The dinner is open to anyone keen to support advancing women in the industry,https://www.reddit.com/r/deeplearning/comments/44s7mu/join_the_celebration_of_women_working_in_machine/,reworksophie,1454955791,,0,1
3,2016-2-10,2016,2,10,11,450ci3,Deep Learning Introduction with ConvNetJS,https://www.reddit.com/r/deeplearning/comments/450ci3/deep_learning_introduction_with_convnetjs/,julien42,1455070081,,0,1
4,2016-2-11,2016,2,11,2,453xqq,Install NVIDIA DIGITS 3 on EC2,https://www.reddit.com/r/deeplearning/comments/453xqq/install_nvidia_digits_3_on_ec2/,spmallick,1455126412,,0,1
5,2016-2-17,2016,2,17,22,468d41,"Videos from the REWORK Deep Learning Summit, San Francisco, January 2016 - feat Andrej Karpathy, OpenAI; Hassan Sawag, eBay; Clement Farabet, Twitter; Andrew Ng, Baidu &amp; more",https://www.reddit.com/r/deeplearning/comments/468d41/videos_from_the_rework_deep_learning_summit_san/,reworksophie,1455714115,,0,1
6,2016-2-24,2016,2,24,1,477aak,the cost of deep learning must dramatically come down,https://www.reddit.com/r/deeplearning/comments/477aak/the_cost_of_deep_learning_must_dramatically_come/,toisanji,1456244030,,4,0
7,2016-2-24,2016,2,24,2,477oj8,Video tutorial for training a Convolutional Neural Network for flower classification using DIGITS 3 on Amazon EC2,https://www.reddit.com/r/deeplearning/comments/477oj8/video_tutorial_for_training_a_convolutional/,spmallick,1456248579,,0,1
8,2016-2-25,2016,2,25,3,47dxmn,NTM-Lasagne: A Library for Neural Turing Machines in Lasagne  Snips Blog,https://www.reddit.com/r/deeplearning/comments/47dxmn/ntmlasagne_a_library_for_neural_turing_machines/,oulipo,1456337324,,0,5
9,2016-2-27,2016,2,27,3,47qivl,What is the best resource for learning deep learning applied to computer vision problems?,https://www.reddit.com/r/deeplearning/comments/47qivl/what_is_the_best_resource_for_learning_deep/,Dragonfliesfoos222,1456512239,"I know Rob Fergus has these lectures from NIPS 2013:
https://www.youtube.com/watch?v=qgx57X0fBdA

What other resources are available? ",2,2
0,2016-3-2,2016,3,2,5,48ihfh,Understanding Aesthetics with Deep Learning,https://www.reddit.com/r/deeplearning/comments/48ihfh/understanding_aesthetics_with_deep_learning/,harrism,1456864747,,0,5
1,2016-3-4,2016,3,4,5,48ts6d,Deep Learning: an Interview with Yoshua Bengio,https://www.reddit.com/r/deeplearning/comments/48ts6d/deep_learning_an_interview_with_yoshua_bengio/,reworksophie,1457036115,,0,1
2,2016-3-7,2016,3,7,3,498i7w,How fast should these processes run?,https://www.reddit.com/r/deeplearning/comments/498i7w/how_fast_should_these_processes_run/,MacroMeez,1457289143,"I am playing with the image analogies codebase (https://github.com/awentzonline/image-analogies) right now, and my desktop has a GTX770 4gig graphics card.  Currently the first passes take about a minute or two each, the second layer takes a few minutes but the 3rd layer of passes takes about 5 hours each.  Do i have something set up incorrectly or is that just the current state of things?  How much faster could I get if i upgraded to a 980ti or something?",1,0
3,2016-3-8,2016,3,8,16,49hfxm,"Can you recommend me a book based on my knowledge, before diving deep into deep learning?",https://www.reddit.com/r/deeplearning/comments/49hfxm/can_you_recommend_me_a_book_based_on_my_knowledge/,Mr__Christian_Grey,1457422548,"I have questions regarding this Normalized weights and Initial inputs video on Udacity course Deep Learning.(https://www.udacity.com/course/viewer#!/c-ud730/l-6370362152/m-7119160655)

In this video it talks about variables that go into Big-loss function should have zero mean and equal variances. I cant figure about which variables it is talking about? Are they weights and biases or are they soft-max function and labels in the Big-loss function? And how zero mean and equal variance would help in optimization?

The other question I have is, in the video it talks about weight initialization randomly using Gaussian distribution, I cannot understand how can we initialize weights using gaussian distribution with zero mean and standard deviation sigma? And where optimizer will move the point (initialized weight), up or down to find the local minima?

So can you recommend me a book that I should study before taking this course, so that problems like these don't occur ?",0,3
4,2016-3-8,2016,3,8,17,49hmpy,Deep Learning in a Nutshell: Sequence Learning,https://www.reddit.com/r/deeplearning/comments/49hmpy/deep_learning_in_a_nutshell_sequence_learning/,harrism,1457426583,,0,4
5,2016-3-11,2016,3,11,0,49tybk,"With AlphaGo in the news this week, we looked back at our interview with scientists from Google DeepMind - talking advancements in deep learning, DeepMind algorithms, and using games to teach machines.",https://www.reddit.com/r/deeplearning/comments/49tybk/with_alphago_in_the_news_this_week_we_looked_back/,reworksophie,1457624730,,0,1
6,2016-3-14,2016,3,14,21,4acvo3,Deep Reinforcement Learning for Robotics - Pieter Abbeel presentation #reworkDL,https://www.reddit.com/r/deeplearning/comments/4acvo3/deep_reinforcement_learning_for_robotics_pieter/,reworksophie,1457958395,,0,1
7,2016-3-17,2016,3,17,23,4atbj2,How to make image classification go real-time in Deep Learning ?,https://www.reddit.com/r/deeplearning/comments/4atbj2/how_to_make_image_classification_go_realtime_in/,nex_jeb,1458225320,"Training with well-known frameworks like caffe or torch isn't the hardest thing in deep learning. However, once the neural network trained, it's not that easy to make things go real-time. A lot of people seem to face this unfortunate constraint that limits the scope of R-T applications for Deep Learning with existing tools. 

So, before giving up the deep learning approach, I would like to ask you guys if there are any heuristics that could boost the things up.

Cheers,",1,4
8,2016-3-18,2016,3,18,0,4athq7,Validation and training set. How to choose the ratio ?,https://www.reddit.com/r/deeplearning/comments/4athq7/validation_and_training_set_how_to_choose_the/,nex_jeb,1458227392,"I am a bit confused about the chosen ratio between the size of the validation &amp; training sets. 

Some guys build a validation set taking about 20 to 25% of the training set, some choose a total independent data for it, etc ...

Finally, is it better to choose a validation set from a part of the training set than to build a new one ?

Thanks, ",0,3
9,2016-3-18,2016,3,18,23,4aylix,Some insights from this training graph ?,https://www.reddit.com/r/deeplearning/comments/4aylix/some_insights_from_this_training_graph/,nex_jeb,1458312391,,0,3
10,2016-3-23,2016,3,23,3,4binjf,Some Starting Points for Deep Learning and RNNs,https://www.reddit.com/r/deeplearning/comments/4binjf/some_starting_points_for_deep_learning_and_rnns/,60secs,1458670838,,0,0
11,2016-3-25,2016,3,25,2,4bsi9n,"Experts from Deep Genomics, AiCure Stratified Medical, Cambridge University &amp; Twitter talk Deep Learning in Healthcare",https://www.reddit.com/r/deeplearning/comments/4bsi9n/experts_from_deep_genomics_aicure_stratified/,reworksophie,1458839599,,0,1
12,2016-3-30,2016,3,30,0,4cg1m8,How is deep learning impacting radiological imaging &amp; anomaly detection?,https://www.reddit.com/r/deeplearning/comments/4cg1m8/how_is_deep_learning_impacting_radiological/,reworksophie,1459266859,,0,1
13,2016-3-31,2016,3,31,21,4cpqtn,Experts discuss the opportunities and risks of integrating AI &amp; Deep Learning in healthcare,https://www.reddit.com/r/deeplearning/comments/4cpqtn/experts_discuss_the_opportunities_and_risks_of/,reworksophie,1459426572,,0,1
0,2016-4-1,2016,4,1,21,4cve05,"We asked deep learning and healthcare experts for their predictions for the next 5 years, the risks involved with AI integration &amp; areas for disruption",https://www.reddit.com/r/deeplearning/comments/4cve05/we_asked_deep_learning_and_healthcare_experts_for/,reworksophie,1459514013,,0,1
1,2016-4-5,2016,4,5,6,4dd91f,How to add new layers to deep neural networks,https://www.reddit.com/r/deeplearning/comments/4dd91f/how_to_add_new_layers_to_deep_neural_networks/,cycle_cologne,1459805446,,0,0
2,2016-4-5,2016,4,5,13,4dez3t,TensorFlow Simplified Interface,https://www.reddit.com/r/deeplearning/comments/4dez3t/tensorflow_simplified_interface/,mela1029,1459831822,,1,3
3,2016-4-5,2016,4,5,23,4dgr8r,Packt Explains: Deep Learning in 90 seconds,https://www.reddit.com/r/deeplearning/comments/4dgr8r/packt_explains_deep_learning_in_90_seconds/,PacktStaff,1459868015,,0,1
4,2016-4-6,2016,4,6,2,4dhju7,Inside Pascal: NVIDIA's Newest Computing Platform,https://www.reddit.com/r/deeplearning/comments/4dhju7/inside_pascal_nvidias_newest_computing_platform/,harrism,1459878141,,0,2
5,2016-4-7,2016,4,7,6,4dnvkz,Optimizing Recurrent Neural Networks In CuDNN 5,https://www.reddit.com/r/deeplearning/comments/4dnvkz/optimizing_recurrent_neural_networks_in_cudnn_5/,harrism,1459977798,,0,1
6,2016-4-7,2016,4,7,16,4dq0wd,Create Your Own Neural Paintings using Deep Learning,https://www.reddit.com/r/deeplearning/comments/4dq0wd/create_your_own_neural_paintings_using_deep/,bilalbarki,1460014102,,0,1
7,2016-4-7,2016,4,7,22,4dr1yc,"Deep Learning: Modular in Theory, Inflexible in Practice - Q&amp;A with Enlitic's Senior Data Scientist #reworkDL #WHD2016",https://www.reddit.com/r/deeplearning/comments/4dr1yc/deep_learning_modular_in_theory_inflexible_in/,reworksophie,1460036145,,0,1
8,2016-4-9,2016,4,9,12,4dzw3a,Top performing caffe models for a Mixture of Deep Convolutional Neural Networks (MixDCNN) is now available,https://www.reddit.com/r/deeplearning/comments/4dzw3a/top_performing_caffe_models_for_a_mixture_of_deep/,dyndet,1460173671,,0,2
9,2016-4-13,2016,4,13,3,4ehgox,Deep learning &amp; XgBoost : Winning it hands down !,https://www.reddit.com/r/deeplearning/comments/4ehgox/deep_learning_xgboost_winning_it_hands_down/,vincentg64,1460485935,,0,1
10,2016-4-13,2016,4,13,20,4el63q,Docker and Deep Learning are a bad match,https://www.reddit.com/r/deeplearning/comments/4el63q/docker_and_deep_learning_are_a_bad_match/,toisanji,1460547945,,1,3
11,2016-4-13,2016,4,13,23,4eltsd,"Deep Learning at Scale: Q&amp;A with Naveen Rao, Nervana Systems",https://www.reddit.com/r/deeplearning/comments/4eltsd/deep_learning_at_scale_qa_with_naveen_rao_nervana/,reworksophie,1460557942,,0,1
12,2016-4-15,2016,4,15,5,4et915,How to do something equivalent to ImageNet when we are a company?,https://www.reddit.com/r/deeplearning/comments/4et915/how_to_do_something_equivalent_to_imagenet_when/,mphuget,1460667133,"Hello everyone, 

I hope my question is not misplaced. 
ImageNet is a useful resource for (academic) research and not for commercial purpose, as a consequence how to do something equivalent when we are a company: for each category in WordNet, search for images on Google, label them and feed our CNN with these images? Or does there exist another solution? 

Thanks in advance for your answer

",0,2
13,2016-4-15,2016,4,15,23,4ewywr,Tensorflow VS Theano performance,https://www.reddit.com/r/deeplearning/comments/4ewywr/tensorflow_vs_theano_performance/,yield22,1460730687,I cannot find a updated benchmark comparing these two on RNN/LSTM and/or other algorithms. Anyone has experiences on that?,1,8
14,2016-4-16,2016,4,16,0,4exakz,"The intersection of machine learning &amp; IoT for a healthier, smarter home",https://www.reddit.com/r/deeplearning/comments/4exakz/the_intersection_of_machine_learning_iot_for_a/,reworksophie,1460734998,,0,1
15,2016-4-17,2016,4,17,17,4f5vaj,How should I proceed ?,https://www.reddit.com/r/deeplearning/comments/4f5vaj/how_should_i_proceed/,huad,1460882527,I have comments at website that needs to be approved. Currently all approving process done by humans. I want to automatize this process. I used word2vec to vectorize this comments.For each word I generated 200 element vector. Then I take average of vectors that constructs each sentence. Approval status is used as label. I tried deeplearning4j and used layer configuration from [here](https://github.com/deeplearning4j/dl4j-0.4-examples/blob/master/src/main/java/org/deeplearning4j/examples/misc/csv/CSVExample.java). F1 score is around %60-%65. My native language doesn't have any nlp library. Is there anything I can do to improve this score ?,1,1
16,2016-4-21,2016,4,21,20,4fsizc,Stanford CoreNLP sentiment analysis different results,https://www.reddit.com/r/deeplearning/comments/4fsizc/stanford_corenlp_sentiment_analysis_different/,Faceman1208,1461238114,"Is there anybody who was able to archive the same results like in the Socher paper (http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf). I used the pretrained model from the website http://nlp.stanford.edu/sentiment/code.html and got the following results:

Paper results

* Fine-grained 80.7 (All)  45.7 (Root) 
* Positive/Negative 87.6 (All) 85.4 (Root)

The results which I got

* Fine-grained 0.802155 (All)  0.441629 (Root) 
* Positive/Negative 0.695110 (All) 0.785832 (Root) 

The whole results:

		EVALUATION SUMMARY
	Tested 82600 labels
	  66258 correct
	  16342 incorrect
	  0.802155 accuracy
	Tested 2210 roots
	  976 correct
	  1234 incorrect
	  0.441629 accuracy
	Label confusion matrix
		  Guess/Gold       0       1       2       3       4    Marg. (Guess)
				   0     323     161      27       3       3     517
				   1    1294    5498    2245     652     148    9837
				   2     292    2993   51972    2868     282   58407
				   3      99     602    2283    7247    2140   12371
				   4       0       1      21     228    1218    1468
		Marg. (Gold)    2008    9255   56548   10998    3791

				   0        prec=0.62476, recall=0.16086, spec=0.99759, f1=0.25584
				   1        prec=0.55891, recall=0.59406, spec=0.94084, f1=0.57595
				   2        prec=0.88982, recall=0.91908, spec=0.75299, f1=0.90421
				   3        prec=0.58581, recall=0.65894, spec=0.92844, f1=0.62022
				   4        prec=0.8297, recall=0.32129, spec=0.99683, f1=0.46321
	Root label confusion matrix
		  Guess/Gold       0       1       2       3       4    Marg. (Guess)
				   0      44      39       9       0       0      92
				   1     193     451     190     131      36    1001
				   2      23      62      82      30       8     205
				   3      19      81     101     299     255     755
				   4       0       0       7      50     100     157
		Marg. (Gold)     279     633     389     510     399

				   0        prec=0.47826, recall=0.15771, spec=0.97514, f1=0.2372
				   1        prec=0.45055, recall=0.71248, spec=0.65124, f1=0.55202
				   2        prec=0.4, recall=0.2108, spec=0.93245, f1=0.27609
				   3        prec=0.39603, recall=0.58627, spec=0.73176, f1=0.47273
				   4        prec=0.63694, recall=0.25063, spec=0.96853, f1=0.35971

	Approximate Negative label accuracy: 0.646009
	Approximate Positive label accuracy: 0.732504
	Combined approximate label accuracy: 0.695110
	Approximate Negative root label accuracy: 0.797149
	Approximate Positive root label accuracy: 0.774477
	Combined approximate root label accuracy: 0.785832 

But I was not able to get the same results like in the paper.",4,2
17,2016-4-21,2016,4,21,21,4fsnxt,2-class pre-trained sentiment model,https://www.reddit.com/r/deeplearning/comments/4fsnxt/2class_pretrained_sentiment_model/,Faceman1208,1461240739,"I already trained and evaluated successfully a 5 class model with the Stanford CoreNLP sentiment parser and the data which is available on the website. Now, I recognized that there is in the Models.jar also a **2-class pre-trained sentiment model** available. The model is named **sentiment.binary.ser.gz**. Now I want to evaluate the model. 

    java -cp ""*"" -mx24g edu.stanford.nlp.sentiment.Evaluate -model models/sentiment.binary.ser.gz -treebank corpora/test.txt
",0,1
18,2016-4-24,2016,4,24,1,4g455v,"Minecraft, ENHANCE! Neural Networks to Upscale &amp; Stylize Pixel Art",https://www.reddit.com/r/deeplearning/comments/4g455v/minecraft_enhance_neural_networks_to_upscale/,linuxjava,1461428870,,0,4
19,2016-4-25,2016,4,25,17,4gcgy9,"Collection of books, courses and papers on Deep Learning",https://www.reddit.com/r/deeplearning/comments/4gcgy9/collection_of_books_courses_and_papers_on_deep/,udayj,1461574543,,0,3
20,2016-4-26,2016,4,26,12,4ggye0,"I'm going to run this deep learning python script, should I use TensorFlow or Theano?",https://www.reddit.com/r/deeplearning/comments/4ggye0/im_going_to_run_this_deep_learning_python_script/,thecheesehouse,1461639994,,3,1
21,2016-4-28,2016,4,28,1,4gpdju,"Deep Learning: Now &amp; Beyond - Q&amp;A with Hugo Larochelle, Research Scientist at Twitter Cortex",https://www.reddit.com/r/deeplearning/comments/4gpdju/deep_learning_now_beyond_qa_with_hugo_larochelle/,reworksophie,1461775719,,0,1
22,2016-4-28,2016,4,28,8,4graaq,Train Your Reinforcement Learning Agents At The OpenAI Gym,https://www.reddit.com/r/deeplearning/comments/4graaq/train_your_reinforcement_learning_agents_at_the/,harrism,1461800310,,0,5
23,2016-4-29,2016,4,29,7,4gwkvn,"Andrew Ng: Deep Learning, Self-Taught Learning and Unsupervised Feature ...",https://www.reddit.com/r/deeplearning/comments/4gwkvn/andrew_ng_deep_learning_selftaught_learning_and/,pummit,1461883791,,0,1
24,2016-4-29,2016,4,29,16,4gyd9d,LSTM: Presetting the internal state?,https://www.reddit.com/r/deeplearning/comments/4gyd9d/lstm_presetting_the_internal_state/,flaschenpost-de,1461915134,"Following problem: I want to learn a prediction for a big set of different persons. Let's say it would be text prediction. Each person has it's own style, but of course there are similarities between many of them.
LSTMs keep their internal state. So what I understand it would be reasonable to initialize that hidden state with the personal parameters of the single person that is speaking.
Does anybody know an example or a teaching article about problems like that?
When a new person enters, I do not know much about her, but some kind of group she belongs to. So she should inherit the default settings of her group but that parameter set should be adopted fast to her own style.

I hope my limited english doesn't confuse the already confusing problem.

(Cross-Posted at /r/machinelearning)",0,0
25,2016-4-29,2016,4,29,18,4gykjo,Stanford sentiment treebank and recursive neural tensor network parameters,https://www.reddit.com/r/deeplearning/comments/4gykjo/stanford_sentiment_treebank_and_recursive_neural/,Faceman1208,1461920432,"Hi,

I try to retrain the recursive neural tensor networks with the stanford treebank **(http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)**, to achieve the same results like with the models **(sentiment.ser.gz and sentiment.binary.ser.gz)** they provide on the homepage **(http://stanfordnlp.github.io/CoreNLP/index.html#download)** in the english language jar. Is there anyboy, who was able to reproduce the same results and can send me the parameters?

Greetings and thanks in advance",0,1
26,2016-4-30,2016,4,30,1,4h0ahl,Deep Learning Generative Models for Handwriting Analysis,https://www.reddit.com/r/deeplearning/comments/4h0ahl/deep_learning_generative_models_for_handwriting/,amplifier_khan,1461948476,,0,2
27,2016-4-30,2016,4,30,21,4h49ir,Hype on Deep Learning That No One Knows,https://www.reddit.com/r/deeplearning/comments/4h49ir/hype_on_deep_learning_that_no_one_knows/,JoeyRob,1462019201,,0,0
0,2016-5-3,2016,5,3,5,4hjpe1,GTX 750ti for deep learning,https://www.reddit.com/r/deeplearning/comments/4hjpe1/gtx_750ti_for_deep_learning/,John_Saxon,1462222024,"I'm tired of training tying up my gaming box for days. Is a small, cheap server with a 750ti good for small models (LSTM?)",2,3
1,2016-5-4,2016,5,4,9,4hs25y,State of the art for depth of LSTM networks?,https://www.reddit.com/r/deeplearning/comments/4hs25y/state_of_the_art_for_depth_of_lstm_networks/,bradneuberg,1462323414,What's the state of the art in terms of depth when unrolling LSTM networks? 150 layers (about the same as ResNet) or more? Are any techniques used for gradient stability across so many unrolled LSTM layers (akin to batch normalization)? If anyone has links to relevant papers that would be very useful.,2,3
2,2016-5-5,2016,5,5,2,4hvpv4,Can Deep Learning Change the Way We Interact With Our Environment?,https://www.reddit.com/r/deeplearning/comments/4hvpv4/can_deep_learning_change_the_way_we_interact_with/,reworksophie,1462384457,,0,1
3,2016-5-5,2016,5,5,3,4hvu6y,How to detect and record only when I speak?,https://www.reddit.com/r/deeplearning/comments/4hvu6y/how_to_detect_and_record_only_when_i_speak/,pummit,1462385907,"Hi, I'd like to make a mobile app, that detects when I speak and record my audio, (then uploads my audio to cloud every night when the phone is charged and on wifi, the cloud then does speech-&gt;text using deep learning).
My question is regarding the 1st step: detects when I speak and record only my audio. Note 2 goals here: (1) super low battery drain, won't record when I'm not speaking. (2) detects only when I speak, so training using my voice is allowed.

How do I do this? Anyone could give a roadmap and pointers to libraries/ tools? Thanks for any suggestion!",1,2
4,2016-5-9,2016,5,9,18,4iivkb,DeepOSM - train a deep learning neural network with Openstreetmap features &amp; orbital imagery,https://www.reddit.com/r/deeplearning/comments/4iivkb/deeposm_train_a_deep_learning_neural_network_with/,liotier,1462787253,,0,2
5,2016-5-9,2016,5,9,21,4ij9b6,How to export a trained neural net a smartphone/tablet?,https://www.reddit.com/r/deeplearning/comments/4ij9b6/how_to_export_a_trained_neural_net_a/,guyov,1462795696,"Hey guys,
I have a deep neural network I trained using Caffe or Theano frameworks.
I want to use that net on my iPad for another application.

Does anyone know how to do it?

Thanks a bunch,
Guy",1,1
6,2016-5-10,2016,5,10,7,4im74q,How Our Deep Learning Tech Taught a Car to Drive | NVIDIA Blog,https://www.reddit.com/r/deeplearning/comments/4im74q/how_our_deep_learning_tech_taught_a_car_to_drive/,josephd,1462833906,,0,3
7,2016-5-11,2016,5,11,0,4ipmh6,Machine Learning Experts Gather in Boston #reworkDL,https://www.reddit.com/r/deeplearning/comments/4ipmh6/machine_learning_experts_gather_in_boston_reworkdl/,reworksophie,1462892644,,0,1
8,2016-5-11,2016,5,11,0,4ipouc,How is deep learning being used in the financial sector?,https://www.reddit.com/r/deeplearning/comments/4ipouc/how_is_deep_learning_being_used_in_the_financial/,reworksophie,1462893434,,0,1
9,2016-5-11,2016,5,11,6,4irjkw,"via MIT Technology Review: ""AI Intolerance"" - How do we feel about Artificial Intelligence?",https://www.reddit.com/r/deeplearning/comments/4irjkw/via_mit_technology_review_ai_intolerance_how_do/,ky1e,1462915676,,1,2
10,2016-5-11,2016,5,11,8,4is428,"Amazon Open sources its Deep learning Framework ""Destiny"". Claims 2.1 Speed up over TesnsorFlow",https://www.reddit.com/r/deeplearning/comments/4is428/amazon_open_sources_its_deep_learning_framework/,gobimanchurian,1462923225,,0,13
11,2016-5-12,2016,5,12,6,4ixdhn,what is the minimum vocabulary size when it is necessary using sampling based training?,https://www.reddit.com/r/deeplearning/comments/4ixdhn/what_is_the_minimum_vocabulary_size_when_it_is/,yield22,1463003644,"such as ""sampled_softmax_loss"" in tensorflow.",0,1
12,2016-5-16,2016,5,16,6,4ji78w,"For fun, I trained a RNN model to answer questions using the most poorly rated responses from /r/askreddit. Now it's a twitterbot! @auto_stoopidity",https://www.reddit.com/r/deeplearning/comments/4ji78w/for_fun_i_trained_a_rnn_model_to_answer_questions/,lildeam0n,1463349473,https://twitter.com/auto_stoopidity,3,5
13,2016-5-19,2016,5,19,9,4jztfb,Book: Deep Learning With Python,https://www.reddit.com/r/deeplearning/comments/4jztfb/book_deep_learning_with_python/,abdsc,1463617024,,0,5
14,2016-5-20,2016,5,20,12,4k6elt,Introducing CV2Vec: A Neural Model For Candidate Similarity,https://www.reddit.com/r/deeplearning/comments/4k6elt/introducing_cv2vec_a_neural_model_for_candidate/,vitaminq,1463715571,,0,5
15,2016-5-24,2016,5,24,23,4kty5d,The future of mobility is starting now. Do you know where we are heading?,https://www.reddit.com/r/deeplearning/comments/4kty5d/the_future_of_mobility_is_starting_now_do_you/,sciencefictionfan05,1464099014,,0,0
16,2016-5-26,2016,5,26,9,4l2q24,Statistics degree or CS/EE degree for Deep learning?,https://www.reddit.com/r/deeplearning/comments/4l2q24/statistics_degree_or_csee_degree_for_deep_learning/,whoisthriller,1464222394,which one is a better fit for deep learning?,11,2
17,2016-5-27,2016,5,27,19,4la3sp,"Deep Learning with Tony Jebara, Director of ML Research at Netflix",https://www.reddit.com/r/deeplearning/comments/4la3sp/deep_learning_with_tony_jebara_director_of_ml/,reworksophie,1464344014,,0,1
18,2016-5-28,2016,5,28,3,4lc2lb,Good for beginners but thorough history of deep learning?,https://www.reddit.com/r/deeplearning/comments/4lc2lb/good_for_beginners_but_thorough_history_of_deep/,snylekkie,1464373151,Hi there. Can anyone paste a link to a publication dedicated to explaining all the crucial concepts as they were developed across the years?,9,4
19,2016-5-31,2016,5,31,12,4lt626,Build an AI Artist - ML for Hackers #5,https://www.reddit.com/r/deeplearning/comments/4lt626/build_an_ai_artist_ml_for_hackers_5/,llSourcell,1464664331,,1,3
0,2016-6-1,2016,6,1,20,4m0vkn,"Deep Listening: the Neural Network Learning to Hear in a Crowd - A Q&amp;A with John Hershey, Principal Scientist of Mitsubishi Electric Research Lab",https://www.reddit.com/r/deeplearning/comments/4m0vkn/deep_listening_the_neural_network_learning_to/,reworksophie,1464782231,,0,1
1,2016-6-5,2016,6,5,16,4mmgdh,CS algorithms VS DeepLearning algorithms,https://www.reddit.com/r/deeplearning/comments/4mmgdh/cs_algorithms_vs_deeplearning_algorithms/,whoisthriller,1465112779,"From my understanding, Machine Learning's algorithms such as SVM, k-means,Random forest are more mathematical and statistical algorithms, while CS's algorithms such as Binary Search Trees, Red-Black trees, Hash table are traditional CS algorithms which is a total different thing to ML's algorithms. Also, CS programming is object orientied programming using java, c++, while ML uses script languages such as R, SAS, Python. So why many people say it is better to get a CS degree rather than a math.stat degree to get into DL/ML field?",5,5
2,2016-6-7,2016,6,7,2,4mu33n,Ending busy days with more AI/Deep learning news options,https://www.reddit.com/r/deeplearning/comments/4mu33n/ending_busy_days_with_more_aideep_learning_news/,MachineLearner85,1465233564,,0,1
3,2016-6-7,2016,6,7,15,4mxnm6,"Wrote my first NN, some questions",https://www.reddit.com/r/deeplearning/comments/4mxnm6/wrote_my_first_nn_some_questions/,what_a_n00b,1465279869,"Hi there, please excuse me for being dumb:

I wrote my first neural network and it is doing well after 1000 iterations of say....  XOR or another logical binary function.  So after showing it XOR 1000 times (either 1 ^ 1 = 0, 1 ^ 0 = 1, 0 ^ 1 = 1 and 0 ^ 0 = 0).  It has 2 inputs, 1 hidden layer with 4 nodes, and 1 output.

I tried to teach it modulo.  Like a%b=c where a=1-&gt;100 and b=1-&gt;15.  I taught it 10000 iterations of this, random inputs, back propagating the expected result - it doesn't work at all.  I thought, OK, maybe it needs more example - tried 100000 iterations.  Still crap.

Then I thought...  Maybe I need more layers?  More nodes?  I tried 2 inputs, 3 layers of 10 hidden, and 1 output - still shit.  

So a couple questions...

1. How do I find out what NN topography will work best for a given problem?

2. How many examples do you need to give (a rule of thumb?) in relation to the input/output combination size?

3. If you teach the neural net to do modulo between 1-100, but you never teach it to do higher numbers, will it be inaccurate in that higher range?  Do you need to teach a NN the LIMITS of the problem space in order to interpolate results inside of this range?


Thanks,
and sorry for being such a n00b
-what_a_n00b",10,3
4,2016-6-7,2016,6,7,20,4myknt,Applying Deep Learning to Biomarker Development &amp; Drug Discovery,https://www.reddit.com/r/deeplearning/comments/4myknt/applying_deep_learning_to_biomarker_development/,reworksophie,1465298904,,0,1
5,2016-6-9,2016,6,9,9,4n87m2,GTX 1080 vs Titan X for deep learning,https://www.reddit.com/r/deeplearning/comments/4n87m2/gtx_1080_vs_titan_x_for_deep_learning/,DiegoAlonsoCortez,1465430787,"The 1080 has ~1.4x the base clock speed of the Titan (1600 vs 1000), ~1.3x the TFLOPS (9 vs 7  nevermind that writing a kernel that performs within 10% of the limit is a software-engineering feat), ~0.8x the CUDA cores (2560 vs 3072), ~1x the memory bandwith (320 vs 336), and ~0.7x the memory (8GB vs 12GB).

I wonder two things. 1) Should one consider upgrading if one already has a Titan X? 2) What if one doesn't own either, and is considering choosing one?

Side note. Currently there's some really cool [SGEMM](https://github.com/NervanaSystems/maxas) and [convolution kernels](https://github.com/eBay/maxDNN) that perform within 4% of the theoretical peak FLOPS, hand-coded for Maxwell. I also wonder how easy it'll be to adapt them for Pascal.",6,1
6,2016-6-9,2016,6,9,16,4n9tg8,Dealing with varying amounts of inputs?,https://www.reddit.com/r/deeplearning/comments/4n9tg8/dealing_with_varying_amounts_of_inputs/,[deleted],1465458676,[deleted],0,1
7,2016-6-10,2016,6,10,4,4ncdxn,MLDB: the open-source Machine Learning Database with TensorFlow support,https://www.reddit.com/r/deeplearning/comments/4ncdxn/mldb_the_opensource_machine_learning_database/,ddcarnage,1465499487,,0,3
8,2016-6-11,2016,6,11,7,4niume,NVIDIA Jetson TX1 for Deep learning users,https://www.reddit.com/r/deeplearning/comments/4niume/nvidia_jetson_tx1_for_deep_learning_users/,[deleted],1465598306,[deleted],0,0
9,2016-6-12,2016,6,12,22,4nqamx,Deeplearnig subreddit,https://www.reddit.com/r/deeplearning/comments/4nqamx/deeplearnig_subreddit/,[deleted],1465739285,[deleted],0,1
10,2016-6-13,2016,6,13,11,4ntnmr,Essential software/programming skills for effective Deep Learning with TensorFlow/etc?,https://www.reddit.com/r/deeplearning/comments/4ntnmr/essential_softwareprogramming_skills_for/,dclaz,1465785791,"Hi guys, I've seen lots of talks/slides/videos about all the wondrous things Deep Learning can do, and I'd like to equip myself with the skills required to build networks to perform various tasks.

I've recently graduated with a PhD in Applied Statistics and am familiar with most modern statistical and machine learning concepts, including very basic neural networks. 

Unfortunately, the only programming language I am adept in is R, and operating system, Windows. My main questions are:

* Do I go ahead and install and become familiar with Linux ASAP?
* Do I start learning Python? What other languages are essential or useful?
* Besides the maths, what other hurdles are there to being able build, train and operationalise deep learning models from scratch for someone in my position?

Many thanks.
",3,5
11,2016-6-13,2016,6,13,23,4nvxo3,INPUTTING IMAGE DATA INTO TENSORFLOW FOR UNSUPERVISED DEEP LEARNING,https://www.reddit.com/r/deeplearning/comments/4nvxo3/inputting_image_data_into_tensorflow_for/,[deleted],1465829052,[deleted],0,1
12,2016-6-14,2016,6,14,0,4nw04w,Inputting Image Data into TensorFlow for Unsupervised Deep Learning,https://www.reddit.com/r/deeplearning/comments/4nw04w/inputting_image_data_into_tensorflow_for/,mwakanosya,1465830003,,0,1
13,2016-6-14,2016,6,14,1,4nwdqz,Sentiment classification on node level for RNTN and SVN,https://www.reddit.com/r/deeplearning/comments/4nwdqz/sentiment_classification_on_node_level_for_rntn/,Faceman1208,1465834793,"Hi,

I have question regarding this paper (http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf). In the paper there are some results on page 7 in Table 1. There are results for **All** and **Root**. For the results **All** they use the results of all nodes of the tree. For **Root** they use the results on sentence level. I'm aware of how they calculate the results for the RNTN. But how do they calculate the All results for SVN?

Greetings and thanks in advance",0,1
14,2016-6-14,2016,6,14,1,4nwfl4,Build an AI Reader w/ Parsey Mcparseface,https://www.reddit.com/r/deeplearning/comments/4nwfl4/build_an_ai_reader_w_parsey_mcparseface/,llSourcell,1465835387,,0,5
15,2016-6-14,2016,6,14,21,4o17lq,One more time please: what exactly was the breakthrough that led to sudden success with neural networks?,https://www.reddit.com/r/deeplearning/comments/4o17lq/one_more_time_please_what_exactly_was_the/,knnjns,1465908241,"The idea of neural networks has been around for decades.  What accounts for their sudden success in the last few years?

---

I've come across three general answers to this question.  The somewhat banal first one boils down to the availability of much larger collections of the kinds of data that neural networks are most effective for.

The second slightly less banal answer: we now have the processing power to train much deeper neural networks.

So the first two answers boil down to sheer scale, in one way or another.

The third, and to me most interesting, answer is not about scale; rather, it claims that the recent success is due to fundamentally better algorithms for training neural networks.  (To be more precise: here I'm referring to algorithms that, had they been known, say, 30 years ago, and applied to the datasets available then, running on the available hardware, they would have shown the same superior performance that they show today.)

Which is it?  It should be possible to the new ""fundamentally better algorithms"" on the old datasets.  Conversely, for the earlier algorithms, if their performance is up to the task, one could run them on the new large datasets.  (If their performance is such that they could not be applied to datasets of the size we have today, then this would argue in favor of ""better algorithms"".)

Has anyone tried to sort this one out?

Also, regarding the ""better algorithms"" answer: what exactly are the breakthrough algorithms?

---

I apologize for this question.  I'm sure something like it has been, and answered, before, but I have not yet found a satisfying answer.
",5,5
16,2016-6-14,2016,6,14,22,4o1fee,unsupervised clustering of points in R^13,https://www.reddit.com/r/deeplearning/comments/4o1fee/unsupervised_clustering_of_points_in_r13/,knnjns,1465911566,"I have a dataset consisting, basically, of ~10^8 points in R^13 (more precisely, each ""point"", aka ""event"", is a vector of 13 floating point numbers).  I'm looking for ways to cluster the 10^8 points in an unsupervised way.


Are deep learning methods suitable for this clustering problem?  If so, what keywords should I search for to learn more?

---

The 10^8 points are measurements performed on individual cells from tissue samples.  The 13 measurements per cell correlate positively with the presence of cell-surface markers that identify the cell as belonging to one of a handful of morphologically distinguishable ""families"" (macrophages, T-cells, B-cells, etc.).  My hope is that the ""signatures"" of the clusters we obtain (or at least most of them) will correspond to the expected signatures for the various families of cells.  (By a cluster's ""signature"" I mean, roughly, the 13-vector for a ""representative point"" of the cluster.)

---

In case it matters, the computational capacity I can count on is a ~2K-node 8-core/node (non-GPU) computer cluster.  I can apply for more computational resources through various channels, but I can't count on it.
",1,1
17,2016-6-15,2016,6,15,0,4o217c,Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks,https://www.reddit.com/r/deeplearning/comments/4o217c/machine_learning_is_fun_part_3_deep_learning_and/,alpyhp,1465919326,,0,7
18,2016-6-17,2016,6,17,1,4oe37j,LSTM vs. Language Theory Automaton,https://www.reddit.com/r/deeplearning/comments/4oe37j/lstm_vs_language_theory_automaton/,mphuget,1466093183,"Hello everyone, 

Question from a noob: if I understand well, training a LSTM for text generation corresponds to digesting text so as to have a neural network that could predict what could be the next character based on the weights

Now, my immediate thinking about such text generation would be to use an automaton where each node is a letter and there are at most 26 edges corresponding to the letters

Then, I could generate text.

So my question is: why is it preferable to use LSTM?

Thanks for your opinion

mph",1,2
19,2016-6-17,2016,6,17,12,4ohbtq,"A topic wise list of Deep Learning tutorials, articles and other resources",https://www.reddit.com/r/deeplearning/comments/4ohbtq/a_topic_wise_list_of_deep_learning_tutorials/,hX3S,1466134148,,0,4
20,2016-6-17,2016,6,17,12,4ohdge,"Computers to execute neural nets, therefore neural nets are restricted to only solving the types of problems outlined by the curch-turing thesis. Are humans more?",https://www.reddit.com/r/deeplearning/comments/4ohdge/computers_to_execute_neural_nets_therefore_neural/,lildeam0n,1466134847,"Human brains are not Artificial Neural Nets for two reasons:
1) They are not executed on a computer (I.E, a turing machine)
2) They are not artificial

Therefore, humans may be able to solve problems outside of the scope of ""pseudocode"", as in, the set of computations outlined in the church turing thesis. 

What if ""intelligence"" and ""sentience"" are things which can't be computed by a turing machine. Maybe we need a different model of computing to make a truly intelligent artificial system.",1,0
21,2016-6-18,2016,6,18,0,4ojtd6,Image recognition tutorial with a deep convnet using Tensorflow on MLDB,https://www.reddit.com/r/deeplearning/comments/4ojtd6/image_recognition_tutorial_with_a_deep_convnet/,ddcarnage,1466178106,,0,0
22,2016-6-18,2016,6,18,7,4olpns,"Noob question, Q/A and Neural Net",https://www.reddit.com/r/deeplearning/comments/4olpns/noob_question_qa_and_neural_net/,afripress,1466201723,"Hey,
Is it possible to train a neural net to ask questions based on certain inputs and in context? Are the open source tools which could help do this. i.e i send the text ""What is computer science"", provides me with information on computer science but follow up with a question such as Do you know when the first computer was built? Is deep learning the approach to solve this kind of problem?",1,2
23,2016-6-20,2016,6,20,19,4oy1ef,Production Deep Learning with NVIDIA GPU Inference Engine,https://www.reddit.com/r/deeplearning/comments/4oy1ef/production_deep_learning_with_nvidia_gpu/,harrism,1466417533,,1,3
24,2016-6-22,2016,6,22,14,4p929u,Video: Quadcopter Navigation in the Forest using Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/4p929u/video_quadcopter_navigation_in_the_forest_using/,abdsc,1466572851,,0,1
25,2016-6-23,2016,6,23,14,4pf4kx,Can Deep Q-Learning really scale to problems with continuous action spaces?,https://www.reddit.com/r/deeplearning/comments/4pf4kx/can_deep_qlearning_really_scale_to_problems_with/,juniorrojas,1466659325,"I'm getting familiar with various reinforcement learning algorithms and, having implemented the standard version of Q-learning in a grid world, it seems to me that even if I approximate the Q-function with a deep net, I'm still going to be very limited in that it's only going to work well for problems with simple discrete actions, like in classic Atari games.

I'm interested in problems with continuous action spaces like robotics and character animation, in which the possible actions are not just ""go up"" or ""go down"", but more like ""rotate joint A 3 degrees + rotate joint B 10 degrees + rotate joint C 5 degrees, simultaneously"". I guess there are some tricks one can use to make Deep Q-learning work better for continuous action spaces, but is it really worth taking the time to learn them considering I'm not interested at all in problems with discrete actions? Am I better off going straight into other methods like policy gradient?",2,6
26,2016-6-23,2016,6,23,19,4pfzdp,Deep Image Homography Estimation,https://www.reddit.com/r/deeplearning/comments/4pfzdp/deep_image_homography_estimation/,jai-chaudhary,1466676159,,0,3
27,2016-6-24,2016,6,24,4,4pinly,Nvidia's new Pascal GPU to supercharge deep learning. This is some serious processing power!,https://www.reddit.com/r/deeplearning/comments/4pinly/nvidias_new_pascal_gpu_to_supercharge_deep/,[deleted],1466711098,[deleted],0,1
28,2016-6-24,2016,6,24,7,4pjdww,Auto-enhanced city-scape,https://www.reddit.com/r/deeplearning/comments/4pjdww/autoenhanced_cityscape/,DemBones85,1466720076,,0,2
29,2016-6-25,2016,6,25,2,4po1l3,ImageNet: The Original Machine Learning Database - somatic blog,https://www.reddit.com/r/deeplearning/comments/4po1l3/imagenet_the_original_machine_learning_database/,[deleted],1466788757,[deleted],0,2
30,2016-6-27,2016,6,27,22,4q38gv,Neat visualization tool for recurrent neural networks by the Harvard NLP group,https://www.reddit.com/r/deeplearning/comments/4q38gv/neat_visualization_tool_for_recurrent_neural/,[deleted],1467032941,[deleted],0,1
31,2016-6-28,2016,6,28,1,4q47g0,LSTMVis: A tool to visualize recurrent neural network by Harvard NLP,https://www.reddit.com/r/deeplearning/comments/4q47g0/lstmvis_a_tool_to_visualize_recurrent_neural/,Valedra,1467044753,,0,7
32,2016-6-29,2016,6,29,10,4qd06k,NVIDIA Docker: Deep Learning Framework Deployment Made Easy,https://www.reddit.com/r/deeplearning/comments/4qd06k/nvidia_docker_deep_learning_framework_deployment/,harrism,1467163768,,0,6
33,2016-6-30,2016,6,30,12,4qjjhv,"10 Great Data Science, Machine / Deep Learning, IoT, AI, Stats, Python and R Resources",https://www.reddit.com/r/deeplearning/comments/4qjjhv/10_great_data_science_machine_deep_learning_iot/,abdsc,1467255883,,0,1
34,2016-6-30,2016,6,30,13,4qjtkk,List of pre-trained networks?,https://www.reddit.com/r/deeplearning/comments/4qjtkk/list_of_pretrained_networks/,gregw134,1467260156,"Hi,

Has anybody compiled a list of pre-trained neural networks? 

Thanks!",2,6
35,2016-6-30,2016,6,30,18,4qkt5o,Http://somatic.io/models/list,https://www.reddit.com/r/deeplearning/comments/4qkt5o/httpsomaticiomodelslist/,[deleted],1467278963,[deleted],1,1
0,2016-7-1,2016,7,1,14,4qq1gi,TFLearn: A Simplified Interface for TensorFlow,https://www.reddit.com/r/deeplearning/comments/4qq1gi/tflearn_a_simplified_interface_for_tensorflow/,malleus17,1467349423,,0,11
1,2016-7-4,2016,7,4,17,4r6bmv,Any insights on how to remove heat haze from an image using deep learning ?,https://www.reddit.com/r/deeplearning/comments/4r6bmv/any_insights_on_how_to_remove_heat_haze_from_an/,nex_jeb,1467621592,,3,3
2,2016-7-6,2016,7,6,19,4rhv9u,Machine Intelligence Allows Robots to Work in Unfamiliar Environments,https://www.reddit.com/r/deeplearning/comments/4rhv9u/machine_intelligence_allows_robots_to_work_in/,reworksophie,1467800952,,0,1
3,2016-7-6,2016,7,6,20,4ri1y3,Word Embeddings and Their Challenges,https://www.reddit.com/r/deeplearning/comments/4ri1y3/word_embeddings_and_their_challenges/,[deleted],1467804828,[deleted],0,1
4,2016-7-6,2016,7,6,20,4ri3oi,Word Embeddings and their challenges,https://www.reddit.com/r/deeplearning/comments/4ri3oi/word_embeddings_and_their_challenges/,MikeWally,1467805748,,0,2
5,2016-7-8,2016,7,8,11,4rseb1,How the hell do you measure accuracy in the TensorFlow Playground?,https://www.reddit.com/r/deeplearning/comments/4rseb1/how_the_hell_do_you_measure_accuracy_in_the/,zbplot,1467944866,"I'm using the playground to experiment with hyperparameters and am about to pull my hair out. 

Is there a way to observe the accuracy of your network in the TensorFlow Playground? I've noted how little the test loss and training loss have to do with accuracy....there must be an acccuracy metric somewhere though, right? 

Surely the best way isn't to count the dots? Please don't make me count the dots.",1,4
6,2016-7-9,2016,7,9,6,4rwytt,Humans are not random,https://www.reddit.com/r/deeplearning/comments/4rwytt/humans_are_not_random/,iliar87,1468012207,"I wanted to share a program that guesses the next digit you're about to enter (0 or 1).

https://github.com/iliar1987/RealTimeRecurrentLearning2

Works on theano on python 2.7.

First time running it, it will hang for a minute or two as the theano graph is being compiled so be patient.

Please tell me if you like it.
",6,10
7,2016-7-9,2016,7,9,16,4rzayc,Best Data science articals on june2016,https://www.reddit.com/r/deeplearning/comments/4rzayc/best_data_science_articals_on_june2016/,dataaspirant,1468048360,,0,1
8,2016-7-11,2016,7,11,6,4s7kxb,Generative Adversarial Networks - Fresh ML #2,https://www.reddit.com/r/deeplearning/comments/4s7kxb/generative_adversarial_networks_fresh_ml_2/,llSourcell,1468187493,,0,7
9,2016-7-12,2016,7,12,8,4se210,Keras: pixel-wise softmax from output of a convolutional autoencoder?,https://www.reddit.com/r/deeplearning/comments/4se210/keras_pixelwise_softmax_from_output_of_a/,planaria123,1468281173,"
I'm working on a segmentation problem.  There are 4 classes for the pixels in the masks for the ground truth data.

I would like to use softmax + categorical_cross_entropy as the last layer to classify each pixel in the output.

The general network structure is a pretty standard convolutional autoencoder: Conv2D/MaxPool2D layers followed by ""deconvolution layers"" (UpSampling2D/Conv2D).

Currently, the penultimate layer is this: 

Convolution2D(num_classes, 1, 1, activation='sigmoid',  border_mode='same')

My problem is understanding how can I put a softmax layer as the last layer.  Also, I believe what I want is to recod the training masks as one-hot encoded of the 4 pixel classes.

Any suggestions would be most welcome; thanks in advance!

Cheers,
Mark
",2,2
10,2016-7-18,2016,7,18,1,4taexg,How to evaluate the process of the training and test loss,https://www.reddit.com/r/deeplearning/comments/4taexg/how_to_evaluate_the_process_of_the_training_and/,miguka,1468774137,"When I am training a deep network, I usually plot the training and validation loss for each epoch. I would like to know what kind of hints can I get from the curve progressions to optimize my parameters to get a better result. 

For example [here](https://s32.postimg.org/9yytm932d/curve_progression.png) is an image of a training process for 200 Epochs. The blue curve is the training process and the red one is the loss from the test set.
As you can see, the the network works fairly well on the training data set but not on the test set.
What I would like to know is how do I have to read the curve progressions to know which parameters I should change in which direction.  

My initial guess is that due to the progression of the blue curve the learning rate and its scheduling plan is quite fine.
But the network has a heavy problem with overfitting (dropout was used in this example with a probability of 0.5).  
Does that indicate that the network is too small? Or am I wrong with my guess about the learning rate? 

Are there tricks and tips that are generally applicable for specific loss progressions, that reveal how to optimize parameters?",0,1
11,2016-7-18,2016,7,18,19,4tem3g,Should We Be Rethinking Unsupervised Learning?,https://www.reddit.com/r/deeplearning/comments/4tem3g/should_we_be_rethinking_unsupervised_learning/,reworksophie,1468839265,,0,1
12,2016-7-19,2016,7,19,20,4tkmw3,Exploring the Artificially Intelligent Future of Finance,https://www.reddit.com/r/deeplearning/comments/4tkmw3/exploring_the_artificially_intelligent_future_of/,reworksophie,1468927358,,0,1
13,2016-7-20,2016,7,20,0,4tlsmt,Torch-rnn breaking down for large token counts,https://www.reddit.com/r/deeplearning/comments/4tlsmt/torchrnn_breaking_down_for_large_token_counts/,[deleted],1468943213,[deleted],0,1
14,2016-7-20,2016,7,20,10,4tomxx,[1607.04793] Learning to Decode Linear Codes Using Deep Learning,https://www.reddit.com/r/deeplearning/comments/4tomxx/160704793_learning_to_decode_linear_codes_using/,vikarpa,1468977431,,0,2
15,2016-7-20,2016,7,20,11,4tow69,Why are my LSTMs performing worse on the training set with higher cell size?,https://www.reddit.com/r/deeplearning/comments/4tow69/why_are_my_lstms_performing_worse_on_the_training/,[deleted],1468980980,[deleted],0,1
16,2016-7-21,2016,7,21,10,4tuhfv,Standalone Free Chapter from Tensorflow for Machine Intelligence,https://www.reddit.com/r/deeplearning/comments/4tuhfv/standalone_free_chapter_from_tensorflow_for/,gbin,1469063677,,2,7
17,2016-7-25,2016,7,25,5,4uer73,dracula.js: an LSTM-based sentiment analyser running in your browser,https://www.reddit.com/r/deeplearning/comments/4uer73/draculajs_an_lstmbased_sentiment_analyser_running/,acornalert,1469390509,,0,3
18,2016-7-25,2016,7,25,21,4uicxd,"do you guys know of a good place(groups,forums...) to ask experts for technical advises in neural computation?",https://www.reddit.com/r/deeplearning/comments/4uicxd/do_you_guys_know_of_a_good_placegroupsforums_to/,asafamr,1469450018,"my final goal is to create a network that auto encode MNIST images as a series of pen strokes and train it with unsupervised learning. I also have several ideas i would like to throw in that i'm pretty sure somebody has already tried.
I'm looking for a place to ask experts familiar with latest approaches to this. any help could be great. Thanks!",1,3
19,2016-7-26,2016,7,26,3,4uk97q,Tensorflow 3 Ways,https://www.reddit.com/r/deeplearning/comments/4uk97q/tensorflow_3_ways/,amplifier_khan,1469472797,,0,2
20,2016-7-26,2016,7,26,5,4ukohs,Ask Reddit: What GPUs should I purchase?,https://www.reddit.com/r/deeplearning/comments/4ukohs/ask_reddit_what_gpus_should_i_purchase/,jtwarren,1469477777,"For context: I've been experimenting with training deep NNs on my MBP with a GTX 750M for some time now (mostly ML class homework and TF tutorials).  I'm starting to see a bottle neck and looking for a better option -- more performance, longer training, etc.  Since it might be relevant I'm doing mostly text but I don't want to preclude myself from working with larger image data sets.

My server has 3-way SLI so I'm trying to determine if multi-GPU is the way to go over a single (more robust) GPU.  I'm looking to spend in the ballpark of a couple hundred ($300?), but really mostly interested in getting the most bang for my buck.  

I'm aware AWS offers GPU instances but I'd like to use my server for ""development"" purposes and go with AWS when I have everything more fleshed out.",5,5
21,2016-7-27,2016,7,27,0,4upbak,how creative types are driving the deep learning revolution,https://www.reddit.com/r/deeplearning/comments/4upbak/how_creative_types_are_driving_the_deep_learning/,toisanji,1469548336,,0,2
22,2016-7-27,2016,7,27,13,4usy4p,20+ Use cases of deep learning in various fields,https://www.reddit.com/r/deeplearning/comments/4usy4p/20_use_cases_of_deep_learning_in_various_fields/,datameer,1469595216,,0,5
23,2016-7-28,2016,7,28,23,4v0xad,deep learning for text analysis,https://www.reddit.com/r/deeplearning/comments/4v0xad/deep_learning_for_text_analysis/,[deleted],1469715505,[deleted],0,1
24,2016-7-28,2016,7,28,23,4v10ps,deep learning for video analysis,https://www.reddit.com/r/deeplearning/comments/4v10ps/deep_learning_for_video_analysis/,riyijiye,1469716664,Can anyone suggest some existing good work of deep learning for video analysis? thanks!,2,2
25,2016-7-29,2016,7,29,3,4v22nb,eBooks/Papers for beginners in Deep Learning,https://www.reddit.com/r/deeplearning/comments/4v22nb/ebookspapers_for_beginners_in_deep_learning/,redrum88_,1469728929,"What ebook, scientific paper, or tutorial do you suggest for a beginner in deep learning?",1,5
26,2016-7-29,2016,7,29,19,4v6090,Meet the Woman Creating AI Assistant Cortana's Personality,https://www.reddit.com/r/deeplearning/comments/4v6090/meet_the_woman_creating_ai_assistant_cortanas/,reworksophie,1469789203,,0,1
27,2016-7-31,2016,7,31,5,4vdqxe,Learn to code with tensorflow from raw equations,https://www.reddit.com/r/deeplearning/comments/4vdqxe/learn_to_code_with_tensorflow_from_raw_equations/,kazi_shezan,1469909376,,0,2
0,2016-8-2,2016,8,2,20,4vrwrd,Build an AI Cat Chaser with Jetson TX1 and Caffe,https://www.reddit.com/r/deeplearning/comments/4vrwrd/build_an_ai_cat_chaser_with_jetson_tx1_and_caffe/,harrism,1470136468,,0,2
1,2016-8-4,2016,8,4,16,4w3g0b,Harry Potter: Written by Artificial Intelligence  Deep Writing,https://www.reddit.com/r/deeplearning/comments/4w3g0b/harry_potter_written_by_artificial_intelligence/,nex_jeb,1470297106,,1,3
2,2016-8-7,2016,8,7,20,4wkiss,Master Thesis Project,https://www.reddit.com/r/deeplearning/comments/4wkiss/master_thesis_project/,kaplansinan,1470569693,"Hi All, I am a MSc. student from Finland and I'm looking for some master thesis ideas related to deep learning and machine learning. I didn't come through anything interesting and I thought I could ask for some help here. Any guidance or advice would be appreciated. 

Thanks a lot in advance for any help.",10,2
3,2016-8-7,2016,8,7,21,4wko1o,Computer Vision News - August 2016,https://www.reddit.com/r/deeplearning/comments/4wko1o/computer_vision_news_august_2016/,Gletta,1470572996,"Online magazine for the algorithm community, including deep learning content. Free subscription at page 23.
http://www.rsipvision.com/ComputerVisionNews-2016August/",0,2
4,2016-8-9,2016,8,9,1,4wqxbi,Perception,https://www.reddit.com/r/deeplearning/comments/4wqxbi/perception/,DarthRhaego,1470672896,"Are you waiting for the world to be taken over by robots ? 
NiTeFiSe's can hold their breath.  ",0,1
5,2016-8-9,2016,8,9,5,4wsa8e,"DL: areas of application? Most obvious and most potential. Your thoughts, please.",https://www.reddit.com/r/deeplearning/comments/4wsa8e/dl_areas_of_application_most_obvious_and_most/,deeteegee,1470687883,"I've been researching (in a lay way) deep learning and its areas of focus. Is there an application, sector, or area that you think has interesting potential? I'm curious about what /deeplearning folks think.",6,5
6,2016-8-10,2016,8,10,2,4wxdi1,3 Ways to Compress a Neural Network,https://www.reddit.com/r/deeplearning/comments/4wxdi1/3_ways_to_compress_a_neural_network/,amplifier_khan,1470763698,,0,5
7,2016-8-10,2016,8,10,22,4x21dn,"How Can Computers Learn, See &amp; Simulate Our World?",https://www.reddit.com/r/deeplearning/comments/4x21dn/how_can_computers_learn_see_simulate_our_world/,reworksophie,1470834659,,0,1
8,2016-8-11,2016,8,11,0,4x2lpt,"Visualizing &amp; Understanding Recurrent Neural Networks with Andrej Karpathy, OpenAI",https://www.reddit.com/r/deeplearning/comments/4x2lpt/visualizing_understanding_recurrent_neural/,reworksophie,1470842058,,0,1
9,2016-8-11,2016,8,11,1,4x2vc4,Democratising Deep Learning: Q&amp;A With Prof. Neil Lawrence,https://www.reddit.com/r/deeplearning/comments/4x2vc4/democratising_deep_learning_qa_with_prof_neil/,reworksophie,1470845203,,0,1
10,2016-8-11,2016,8,11,1,4x32nq,A.I. Acquisitions: The Evolving Deep Learning Landscape,https://www.reddit.com/r/deeplearning/comments/4x32nq/ai_acquisitions_the_evolving_deep_learning/,reworksophie,1470847582,,0,1
11,2016-8-11,2016,8,11,2,4x3agm,An Intuitive Explanation of Convolutional Neural Networks,https://www.reddit.com/r/deeplearning/comments/4x3agm/an_intuitive_explanation_of_convolutional_neural/,hX3S,1470850183,,0,6
12,2016-8-11,2016,8,11,20,4x7jtk,Text regression for Outbrain click-throug-rate prediction using convnets,https://www.reddit.com/r/deeplearning/comments/4x7jtk/text_regression_for_outbrain_clickthrougrate/,orgaron,1470915390,,0,3
13,2016-8-11,2016,8,11,20,4x7kvy,"Video interview with deep learning expert Yoshua Bengio, at the REWORK Deep Learning Summit, Boston 2016",https://www.reddit.com/r/deeplearning/comments/4x7kvy/video_interview_with_deep_learning_expert_yoshua/,reworksophie,1470915976,,0,1
14,2016-8-11,2016,8,11,22,4x81nq,Deep Learning Newsletter,https://www.reddit.com/r/deeplearning/comments/4x81nq/deep_learning_newsletter/,jantanplan,1470923064,,2,2
15,2016-8-12,2016,8,12,2,4x9csi,Deep Learning Sentiment One Character at a T-i-m-e,https://www.reddit.com/r/deeplearning/comments/4x9csi/deep_learning_sentiment_one_character_at_a_time/,amplifier_khan,1470938391,,0,3
16,2016-8-15,2016,8,15,4,4xpm53,Playing with convolutions in TensorFlow,https://www.reddit.com/r/deeplearning/comments/4xpm53/playing_with_convolutions_in_tensorflow/,pipado,1471202619,,0,2
17,2016-8-15,2016,8,15,21,4xtc9d,Quora Session with Franois Chollet (author of Keras),https://www.reddit.com/r/deeplearning/comments/4xtc9d/quora_session_with_franois_chollet_author_of/,mphuget,1471264617,,0,2
18,2016-8-15,2016,8,15,21,4xtdhx,An implementation of word2vec applied to stanford philosophy encyclopedia,https://www.reddit.com/r/deeplearning/comments/4xtdhx/an_implementation_of_word2vec_applied_to_stanford/,pipado,1471265195,,0,6
19,2016-8-18,2016,8,18,5,4y7xmk,Backpropagation Equations in Matrix Form - Easy to derive and remember,https://www.reddit.com/r/deeplearning/comments/4y7xmk/backpropagation_equations_in_matrix_form_easy_to/,sudeepraja,1471465610,,0,7
20,2016-8-19,2016,8,19,2,4ydg4g,Teach a Neural Network to Taste Wine,https://www.reddit.com/r/deeplearning/comments/4ydg4g/teach_a_neural_network_to_taste_wine/,amplifier_khan,1471540175,,0,1
21,2016-8-19,2016,8,19,19,4yi863,Talking Chatbots With IBM Watson's Ashley Hathaway,https://www.reddit.com/r/deeplearning/comments/4yi863/talking_chatbots_with_ibm_watsons_ashley_hathaway/,reworksophie,1471603586,,0,1
22,2016-8-20,2016,8,20,12,4yn1n7,Awesome Deep Learning,https://www.reddit.com/r/deeplearning/comments/4yn1n7/awesome_deep_learning/,[deleted],1471663970,[deleted],0,1
23,2016-8-21,2016,8,21,3,4yqamq,[1608.02164] Adapting Deep Network Features to Capture Psychological Representations,https://www.reddit.com/r/deeplearning/comments/4yqamq/160802164_adapting_deep_network_features_to/,anonDogeLover,1471716339,,0,2
24,2016-8-22,2016,8,22,14,4yyzqy,"An absolute beginners guide to machine learning, deep learning, and AI",https://www.reddit.com/r/deeplearning/comments/4yyzqy/an_absolute_beginners_guide_to_machine_learning/,abdsc,1471842152,,0,1
25,2016-8-22,2016,8,22,20,4z00s7,"Facebook opensources fastText - boasts faster, better text classification",https://www.reddit.com/r/deeplearning/comments/4z00s7/facebook_opensources_fasttext_boasts_faster/,reworksophie,1471864129,,0,1
26,2016-8-22,2016,8,22,21,4z0d8o,"20% off all tickets to REWORK events inc. Machine Intelligence, Deep Learning, Autonomous Vehicles, locations inc NY, SF, London, Amsterdam, Singapore &amp; more!",https://www.reddit.com/r/deeplearning/comments/4z0d8o/20_off_all_tickets_to_rework_events_inc_machine/,reworksophie,1471870159,,0,1
27,2016-8-23,2016,8,23,3,4z1z5h,Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning,https://www.reddit.com/r/deeplearning/comments/4z1z5h/deep_predictive_coding_networks_for_video/,JonathanHoleton,1471890417,,0,1
28,2016-8-23,2016,8,23,20,4z6167,NeuralStyler AI-Turn Your Videos into Art,https://www.reddit.com/r/deeplearning/comments/4z6167/neuralstyler_aiturn_your_videos_into_art/,simpleuserhere,1471952455,,0,0
29,2016-8-24,2016,8,24,0,4z6z97,A community challenge to automate and improve the radiology of mammograms using machine learning,https://www.reddit.com/r/deeplearning/comments/4z6z97/a_community_challenge_to_automate_and_improve_the/,dreamchallenges,1471965554,"I'm writing to invite you to participate an effort I have been helping to launch and that the White House highlighted at Vice President Biden's June 29 Cancer Moonshot Summit. 

The Digital Mammography DREAM Challenge is a crowdsourced computational Challenge focused on improving the predictive accuracy of digital mammography for the early detection of breast cancer. The primary benefit of this Challenge will be to establish new quantitative tools based in deep learning that can help decrease the recall rate of screening mammography, with a potential impact on shifting the balance of routine breast cancer screening towards more benefit and less harm.

The challenge has been donated approximately 640,000 mammogram images along with clinical metadata, a fleet of high powered GPU-based servers, and over a million dollars in prize money.

Our public Challenge website where people can register and read all of our details and timing is here:  https://www.synapse.org/Digital_Mammography_DREAM_Challenge

I hope you find this interesting.  We feel the challenge will only be successful with the engagement of people, such as yourselves, with strong machine learning expertise.",0,1
30,2016-8-24,2016,8,24,5,4z8ois,Using Deep Learning To Make Hamburgers,https://www.reddit.com/r/deeplearning/comments/4z8ois/using_deep_learning_to_make_hamburgers/,baronofbitcoin,1471985238,"I have recently been trying to educate myself about deep learning and have been experimenting with scikit-learn and entering Kaggle competitions.  I've dabbled in XGBoost using Python.  I've also bought a GPU, installed Cuda, and have been using Keras to understand more about deep learning.  It is really an exciting field and I'm learning as much as I can.

What I want to do is to buy some robotic arms and to try to teach them how to make a hamburger.  I imagine there would be some mirroring function where I could stick a camera in front of a kitchen/stove and I could manipulate the arms to so the neural net could learn how to pick up and grill patties, add lettuce, tomatoes, condiments, and finally wrap it in paper.

I was just wondering what the general approach would be in terms of hardware, software, and implementation. 

For hardware, I am thinking having 4 arms working in unison.  Humans have hand and fingers which are very dexterous.  Right now you can buy a robot arms with 2 fingers to grapple, so having an additional 4 arms would mean 8 fingers total. 

For a computer would four Nvidia Teslas work?  What about hard disk space?  How much would I need?

For software what kind of neural net would work best?  Is it possible to use an existing API or library to teach the robot?  How many hamburgers would I have to teach it to make before it can actually make it on its own?

Thanks in advanced for your input.  I would love to start on this project if it were indeed technically and financially possible for a enthusiast like myself. ",5,10
31,2016-8-25,2016,8,25,0,4zd35r,How can we combine fuzzy logic and neural nets?,https://www.reddit.com/r/deeplearning/comments/4zd35r/how_can_we_combine_fuzzy_logic_and_neural_nets/,satwik_,1472051904,,1,0
32,2016-8-25,2016,8,25,12,4zghwk,Tips for getting linux/nvidia-gpu/drivers working for deep learning?,https://www.reddit.com/r/deeplearning/comments/4zghwk/tips_for_getting_linuxnvidiagpudrivers_working/,socratesKisses,1472095041,"I have a background in machine learning, but my computations have always been cpu or cloud-based. I recently built a machine with an nvidia gtx 1070 so that I could dive in to deep learning and image processing with cuda, tensorflow, torch, etc..

Given my familiarity with mac OS and my orientation towards python, I figured my best bet would be to develop on linux. I've tried a variety of distros, include Mint 17.0-3 (Ubuntu 14.04) and Ubuntu 16. The main problem I'm having is getting the right drivers set up. I've read through a lot of materials online and come pretty close to getting things set up properly, but each time with the different distros I've ultimately run into a problem, which appear to be compatibility issues with different drivers and different versions of libraries I'm trying to install.

So, any tips for the most stable OS for running cuda and other deep learning libraries with modern nvidia drivers?",6,2
33,2016-8-26,2016,8,26,1,4zjbsy,"Check out this video spotlight we made of Nervana at the Deep Learning Summit, shortly before they were acquired by Intel",https://www.reddit.com/r/deeplearning/comments/4zjbsy/check_out_this_video_spotlight_we_made_of_nervana/,reworksophie,1472141889,,0,1
34,2016-8-26,2016,8,26,18,4znomk,Study shows speech recognition is 3x faster than typing,https://www.reddit.com/r/deeplearning/comments/4znomk/study_shows_speech_recognition_is_3x_faster_than/,reworksophie,1472202201,,0,1
35,2016-8-27,2016,8,27,6,4zquyd,"SpaceNet satellite imagery repository launched by DigitalGlobe, CosmiQ Works and NVIDIA on AWS",https://www.reddit.com/r/deeplearning/comments/4zquyd/spacenet_satellite_imagery_repository_launched_by/,g2p2u,1472245220,,0,2
36,2016-8-27,2016,8,27,12,4zsdl4,"r/DeepLearning, Fun Scenario!",https://www.reddit.com/r/deeplearning/comments/4zsdl4/rdeeplearning_fun_scenario/,redditpostreddit,1472266871,"If you were apart of a machine learning startup with $40,000 to spend on equipment/ engineering, how would you best put it to use? What tough decisions would have to be made and how would you schedule your time with the machine after completing the buying process?",1,3
37,2016-8-30,2016,8,30,0,505j1s,"The Silent Revolution #2: AI and ML Futures By Neil Lawrence, Professor of Machine Learning - University of Sheffield",https://www.reddit.com/r/deeplearning/comments/505j1s/the_silent_revolution_2_ai_and_ml_futures_by_neil/,OpenDataSciCon,1472484169,,0,2
38,2016-8-30,2016,8,30,5,5079qc,CNN feature visualization with deconvnet,https://www.reddit.com/r/deeplearning/comments/5079qc/cnn_feature_visualization_with_deconvnet/,riyijiye,1472504050,"There is the well-known paper about deconvnet for cnn feature visualization

""Visualizing and Understanding Convolutional Networks""
http://arxiv.org/pdf/1311.2901v3.pdf

Can anyone please explain a little bit how the visualizations in Figure 2 are generated (left and right for each layer). which (left or right hand side) visualization are generated by the deconvolution of max activated features, and how the others are generated then?
 
thanks,",0,2
39,2016-8-31,2016,8,31,6,50djtp,Achlinux or macos os for dl laptop?,https://www.reddit.com/r/deeplearning/comments/50djtp/achlinux_or_macos_os_for_dl_laptop/,scitator,1472592531,"Which laptop is better for deep learning (tensorflow) experiments and everyday use?
Archlinux laptop (Thinkpad, Asus ROG, Dell) or Apple Macbook pro?
What really matter are: good keyboard and some kind of gpu to debug locally.
And why dl experts are so fond of MacBook?",4,1
40,2016-8-31,2016,8,31,18,50g95s,Learning Path for Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/50g95s/learning_path_for_deep_learning_in_python/,jalFaizy,1472634090,,0,4
41,2016-8-31,2016,8,31,20,50grbo,Social Eyes - Creating an Ophthalmologist In-A-Box with Deep Learning,https://www.reddit.com/r/deeplearning/comments/50grbo/social_eyes_creating_an_ophthalmologist_inabox/,d4v1dv00,1472643921,,0,1
0,2016-9-1,2016,9,1,9,50kfey,"anybody know how much this would actually cost to implement? (for the sake of analysis just consider cloud compute costs to google and the raspberry pi, not the servos and robotic hardware, thanks!)",https://www.reddit.com/r/deeplearning/comments/50kfey/anybody_know_how_much_this_would_actually_cost_to/,jbark55,1472689223,,1,3
1,2016-9-1,2016,9,1,22,50n3sq,Tricks in DNN design for better generalization ?,https://www.reddit.com/r/deeplearning/comments/50n3sq/tricks_in_dnn_design_for_better_generalization/,nex_jeb,1472735712,What are the tricks in DNN architecture design that promote better generalization with small data ? ,5,2
2,2016-9-1,2016,9,1,23,50neyk,"Introduction: Deep Learning for Chatbots, Part 2 By Denny Britz, Deep Learning Specialist - Google Brain",https://www.reddit.com/r/deeplearning/comments/50neyk/introduction_deep_learning_for_chatbots_part_2_by/,OpenDataSciCon,1472739831,,0,6
3,2016-9-2,2016,9,2,10,50quhh,Land use classification / building detection in the SpaceNet dataset,https://www.reddit.com/r/deeplearning/comments/50quhh/land_use_classification_building_detection_in_the/,harrism,1472780935,,0,1
4,2016-9-2,2016,9,2,10,50qupj,The App Using Artificial Intelligence To Improve English Speaking Skills,https://www.reddit.com/r/deeplearning/comments/50qupj/the_app_using_artificial_intelligence_to_improve/,harrism,1472781030,,0,1
5,2016-9-2,2016,9,2,17,50sarj,PaddlePaddle ---- PArallel Distributed Deep LEarning,https://www.reddit.com/r/deeplearning/comments/50sarj/paddlepaddle_parallel_distributed_deep_learning/,nex_jeb,1472806126,,0,1
6,2016-9-2,2016,9,2,23,50tj4i,NeuralPainter,https://www.reddit.com/r/deeplearning/comments/50tj4i/neuralpainter/,anjali0309,1472827061,,0,0
7,2016-9-4,2016,9,4,0,50zc6k,Online Action Detection,https://www.reddit.com/r/deeplearning/comments/50zc6k/online_action_detection/,wandering007,1472917285,,1,1
8,2016-9-5,2016,9,5,14,517x0v,Computer Vision News of September,https://www.reddit.com/r/deeplearning/comments/517x0v/computer_vision_news_of_september/,Gletta,1473052170,"You will find here the magazine of September:
http://www.rsipvision.com/ComputerVisionNews-2016September/
News, reviews, interviews, tools, tricks, research, events and much more (really!)
Free subscription to Computer Vision News at page 39.
Enjoy!",0,2
9,2016-9-5,2016,9,5,20,518zs3,The Evolution of NLP: Natural Language Understanding,https://www.reddit.com/r/deeplearning/comments/518zs3/the_evolution_of_nlp_natural_language/,reworksophie,1473074979,,0,1
10,2016-9-6,2016,9,6,14,51dqcp,14 Most popular August 2016 data science articles to read,https://www.reddit.com/r/deeplearning/comments/51dqcp/14_most_popular_august_2016_data_science_articles/,dataaspirant,1473139965,,0,1
11,2016-9-6,2016,9,6,19,51eiuc,How two CNN trained model with different data can be mixed together to build a unified CNN Model?,https://www.reddit.com/r/deeplearning/comments/51eiuc/how_two_cnn_trained_model_with_different_data_can/,rnnandi,1473156920,A CNN which is trained to recognized Chinese handwritten characters and another CNN is trained is to recognized Japanese handwritten Characters . How two CNN can be merged to make a new CNN model that can detect both Chinese and Japanese Characters without training.,7,3
12,2016-9-7,2016,9,7,19,51kjfb,Visual Question Answering Problems: Reasoning With Deep Learning,https://www.reddit.com/r/deeplearning/comments/51kjfb/visual_question_answering_problems_reasoning_with/,reworksophie,1473242858,,0,1
13,2016-9-8,2016,9,8,5,51njbb,Notes on recent neural network architectures,https://www.reddit.com/r/deeplearning/comments/51njbb/notes_on_recent_neural_network_architectures/,kshitid20,1473281920,,0,4
14,2016-9-8,2016,9,8,6,51nrcj,[Question] Deep learning applied to video data for outlier detection?,https://www.reddit.com/r/deeplearning/comments/51nrcj/question_deep_learning_applied_to_video_data_for/,Zeekawla99ii,1473284495,"I learned of a company that works primarily with security camera footage. Theyre using deep learning algorithms find in real time guy with a skimask on, and other outliers from hours of CCTV footage.

Question: what algorithms could they be applying for ""outlier detection""? It appears as if they are applying convolutional neural networks to hours of imaging data...somehow.

Any papers, etc. appreciated. Thanks!",0,2
15,2016-9-8,2016,9,8,20,51qqqj,[Question] Creating a Deep Neural Network for image prediction,https://www.reddit.com/r/deeplearning/comments/51qqqj/question_creating_a_deep_neural_network_for_image/,rumirama,1473332583,"I tried to get some help [here](https://www.reddit.com/r/tensorflow/comments/51aerv/creating_a_deep_neural_network_for_image/) but haven't been very lucky.

I'm trying to implement a DNN for image prediction. The inputs are an image and a motion vector (e.g.: up:-1, right:3, down:4, left:-5) and the output would be the next image. For the training we would have the image, the motion vector and the correct next image (imagine like sequencial frames of a video, for instance).
I'm having troubles implementing this net and the vast majority of the things I find online are mostly for classification in specific labels. In this case there aren't any specific labels as the pixels in the output can be in different ranges of gray (if we consider a gray scale to simplify). Is this a correct approach? Should I try to implement a unsupervised learning approach or should I try to do a one-hot for each pixel (being the labels the different shades of gray)?

BTW, I'm using TensorFlow.

Does anyone have any suggestions or know any tutorial? Any idea/suggestion/help would be great.

Thank you.",3,3
16,2016-9-9,2016,9,9,8,51u9fk,WaveNet: A Generative Model for Raw Audio | DeepMind,https://www.reddit.com/r/deeplearning/comments/51u9fk/wavenet_a_generative_model_for_raw_audio_deepmind/,harrism,1473376586,,0,11
17,2016-9-9,2016,9,9,8,51u9i4,Deep Learning in a Nutshell: Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/51u9i4/deep_learning_in_a_nutshell_reinforcement_learning/,harrism,1473376610,,0,1
18,2016-9-9,2016,9,9,18,51wlyg,Using Deep Learning to turn an iPhone into a 3D camera,https://www.reddit.com/r/deeplearning/comments/51wlyg/using_deep_learning_to_turn_an_iphone_into_a_3d/,aralekk,1473414730,,1,6
19,2016-9-10,2016,9,10,10,520ud5,Why does deep and cheap learning work so well?,https://www.reddit.com/r/deeplearning/comments/520ud5/why_does_deep_and_cheap_learning_work_so_well/,[deleted],1473470575,[deleted],0,1
20,2016-9-10,2016,9,10,17,522b2l,Physicists have discovered what makes neural networks so extraordinarily powerful,https://www.reddit.com/r/deeplearning/comments/522b2l/physicists_have_discovered_what_makes_neural/,DarthRhaego,1473497605,,2,6
21,2016-9-11,2016,9,11,12,526sq6,Speed Up Reports Of Cancer Data With Deep Learning | NVIDIA Blog,https://www.reddit.com/r/deeplearning/comments/526sq6/speed_up_reports_of_cancer_data_with_deep/,shiv4nsh,1473565120,,0,1
22,2016-9-11,2016,9,11,21,528dr2,How to train a deep learning net on this data?,https://www.reddit.com/r/deeplearning/comments/528dr2/how_to_train_a_deep_learning_net_on_this_data/,kneelb4darth,1473598546,"There is a product for which the consumers are sent some promotion material. I have the date of promotion recieved by the consumer and the date when they bought something. I need a deep net that can tell me if the promotion affected the purchase or not. Also I need to predict that if I have sent the promotion to a particular date, for each consumer according to their history of purchase, when approx will they buy the product. I am having difficulty creating a model that gives me acceptable accuracy. Please give me some ideas on how I should work on the problem and suggestions on increasing the accuracy of any model you propose. ",1,0
23,2016-9-12,2016,9,12,19,52dr7j,What HR can expect from Deep Learning in 2016 and Beyond,https://www.reddit.com/r/deeplearning/comments/52dr7j/what_hr_can_expect_from_deep_learning_in_2016_and/,prajakta27,1473677747,,0,1
24,2016-9-12,2016,9,12,21,52e69t,New deep learning startup seeking new co-founders and collaborators.,https://www.reddit.com/r/deeplearning/comments/52e69t/new_deep_learning_startup_seeking_new_cofounders/,BenjaminBoyle,1473684755,"I am trying to get a startup going and am looking for co-founders. The premise of the startup is to use deep learning like AlphaGo to play the financial markets. I believe it can be trained initially on one instrument like OIL and once it has ""cracked the game"" it can then be trained on other instruments.

Someone eventually is going to crack the financial markets using AI and we might as well work together and start now!

The landing page is http://TickAI.com
",17,0
25,2016-9-12,2016,9,12,22,52eano,"Bayesian Deep Learning By Thomas Wiecki PhD, Data Science Lead - Quantopian",https://www.reddit.com/r/deeplearning/comments/52eano/bayesian_deep_learning_by_thomas_wiecki_phd_data/,OpenDataSciCon,1473686563,,0,3
26,2016-9-13,2016,9,13,17,52jfek,"Custom Computer Vision Technology, TechCrunch Disrupt 2016 in San Francisco.",https://www.reddit.com/r/deeplearning/comments/52jfek/custom_computer_vision_technology_techcrunch/,restb,1473755410,,0,2
27,2016-9-14,2016,9,14,19,52pria,Deep learning Education: Training The Trainers,https://www.reddit.com/r/deeplearning/comments/52pria/deep_learning_education_training_the_trainers/,freelyread,1473847584,"**Where can we learn how to teach DL (Deep Learning)?**  
  
It is not unlikely that progress in DL will take off like home computers did when they were first introduced, or like the early days of the internet.  
  
What happened back in those days was a crisis: there was nobody to teach computer programming, for example. If somebody *was* good enough to teach programming at college, they were soon offered a salary so high outside of Education that they left.  
  
What is available today to help people reach a position where they become able to help others understand Deep learning?  
",0,3
28,2016-9-14,2016,9,14,23,52qsbr,Image prediction and generation based on dataset,https://www.reddit.com/r/deeplearning/comments/52qsbr/image_prediction_and_generation_based_on_dataset/,matlo,1473863935,"I'm looking for a way to implement a program that we can feed images and it would output a similar image, based on the samples provided. Image prediction based on a dataset basically.
Conceptually something like https://www.nextrembrandt.com/
Are there some libraries or other code that we can use already or how would you approach this problem? Thanks :)",2,6
29,2016-9-16,2016,9,16,1,52x448,Glove Word Embedding's implementation in Theano,https://www.reddit.com/r/deeplearning/comments/52x448/glove_word_embeddings_implementation_in_theano/,shash27,1473958258,,0,3
30,2016-9-16,2016,9,16,2,52xaj0,"Weather forecasting, pre-natal care ultrasound, energy, space missions - these are just some of the ways deep learning is now being applied",https://www.reddit.com/r/deeplearning/comments/52xaj0/weather_forecasting_prenatal_care_ultrasound/,reworksophie,1473960404,,0,1
31,2016-9-16,2016,9,16,17,530ydt,Nvidia Expands Deep Learning Institute,https://www.reddit.com/r/deeplearning/comments/530ydt/nvidia_expands_deep_learning_institute/,reworksophie,1474014647,,0,1
32,2016-9-16,2016,9,16,18,5311ks,Predicting Future Human Behavior With Deep Learning,https://www.reddit.com/r/deeplearning/comments/5311ks/predicting_future_human_behavior_with_deep/,reworksophie,1474016892,,0,1
33,2016-9-17,2016,9,17,3,533f2c,Can anyone help me in reading the data files from cifar-10 database?,https://www.reddit.com/r/deeplearning/comments/533f2c/can_anyone_help_me_in_reading_the_data_files_from/,Talos19,1474051355,,1,1
34,2016-9-19,2016,9,19,21,53h9nz,Building Bots: How to Start a Successful Chatbot Business,https://www.reddit.com/r/deeplearning/comments/53h9nz/building_bots_how_to_start_a_successful_chatbot/,reworksophie,1474287645,,0,1
35,2016-9-20,2016,9,20,2,53iv02,Image-to-Markup Generation,https://www.reddit.com/r/deeplearning/comments/53iv02/imagetomarkup_generation/,harvardnlp,1474307954,,1,1
36,2016-9-20,2016,9,20,3,53iwsd,Is a larger batch size always better?,https://www.reddit.com/r/deeplearning/comments/53iwsd/is_a_larger_batch_size_always_better/,Jemnian,1474308523,"Hey guys, I am looking into ways to speed up training a neural network. Is it always better to increase the batch size to as large as your GPUs can handle? And how do I appropriately scale the other hyper-parameters if the neural-net that I have already converges? ",1,3
37,2016-9-20,2016,9,20,9,53kn5n,[X-post from r/machinelearning] Call for deep learning research problems,https://www.reddit.com/r/deeplearning/comments/53kn5n/xpost_from_rmachinelearning_call_for_deep/,355_over_113,1474329807,,2,5
38,2016-9-21,2016,9,21,6,53pw3a,"Help with recreating blog post example with TensorFlow, transfer learning, Inception v3 and CIFAR10",https://www.reddit.com/r/deeplearning/comments/53pw3a/help_with_recreating_blog_post_example_with/,thumperj,1474408719,"I've been trying to recreate what the author has demonstrated in this very interesting [post](https://medium.com/@st553/using-transfer-learning-to-classify-images-with-tensorflow-b0f3142b9366#.ihhc9rfky) ([Github](https://github.com/sthomp/tensorflow_transfer_cifar10) for the author's code.)

However, I'm stuck with an error I'm unable to resolve and am unsure how to poke at it to make progress.  I've clearly got some mental wires crossed or missing and could use some assistance.

I've successfully serialized the training data from CIFAR10, the 1st step.  However, when I run do_train in transfer_cifar10_softmax.py, I hit the following error:

    Traceback (most recent call last):
      File ""transfer_cifar10_softmax.py"", line 286, in &lt;module&gt;
        do_train(sess,X_train,Y_train,X_validation,y_validation)
      File ""transfer_cifar10_softmax.py"", line 227, in do_train
        ground_truth_tensor: Yi})
      File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 382, in run
        run_metadata_ptr)
      File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 640, in _run
        % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
    ValueError: Cannot feed value of shape (10, 2048) for Tensor u'pool_3/_reshape:0', which has shape '(1, 2048)'    

Here's the [top part of the graph](http://imgur.com/a/MsOu9) with the transfer learning node expanded (pool).

This is the shape of the passed-in feed_dict data for sess.run in the do_train:
Xi shape:  (10, 2048)
Yi shape:  (10, 10)

Obviously, CIFAR10 has 10 classes which is what is driving the 10-dim.  

*  How do I convert the 10x2048 Xi data into the 1x2048 that the pool_3/reshape is expecting?  
*  WHY is the pool_3/_reshape expecting a 1x2048 from pool_3?
*  (Possibly a related question) What is the role of the encode_one_hot (line 200-ish) in the process?  I understand what the function is doing but what's the role of the result of the function?

Any hints or keen observations would be much appreciated....
",0,2
39,2016-9-22,2016,9,22,4,53uz7f,Exploring computer vision pioneer: ImageNet,https://www.reddit.com/r/deeplearning/comments/53uz7f/exploring_computer_vision_pioneer_imagenet/,WikiBrain8,1474486557,,0,1
40,2016-9-22,2016,9,22,6,53vkb5,AI at Airbnb: Extracting Customer Insights,https://www.reddit.com/r/deeplearning/comments/53vkb5/ai_at_airbnb_extracting_customer_insights/,reworksophie,1474493567,,0,1
41,2016-9-23,2016,9,23,0,53zdvh,Using deep learning to automate sales,https://www.reddit.com/r/deeplearning/comments/53zdvh/using_deep_learning_to_automate_sales/,c0cky_,1474556755,,1,0
42,2016-9-23,2016,9,23,2,5404xx,"Listening to Nervana, Google DeepMind, SwiftKey, NVIDIA at the Deep Learning Summit London today - continues tomorrow you can follow with hashtag #reworkDL",https://www.reddit.com/r/deeplearning/comments/5404xx/listening_to_nervana_google_deepmind_swiftkey/,reworksophie,1474565646,,0,1
43,2016-9-23,2016,9,23,4,540nxn,How to Get a Job In Deep Learning,https://www.reddit.com/r/deeplearning/comments/540nxn/how_to_get_a_job_in_deep_learning/,pain_perdu,1474571691,,0,6
44,2016-9-25,2016,9,25,4,54brfl,Prof. Yann LeCun - Deep Learning and the Future of AI [x-post from /r/machinelearning],https://www.reddit.com/r/deeplearning/comments/54brfl/prof_yann_lecun_deep_learning_and_the_future_of/,CopyofacOpyofacoPyof,1474746973,,1,7
45,2016-9-26,2016,9,26,4,54gmf1,faster-rcnn help,https://www.reddit.com/r/deeplearning/comments/54gmf1/fasterrcnn_help/,RetardedChimpanzee,1474831072,"Good afternoon, 

I am attempting to use faster R-CNN on a original dataset and have been running into issues. I have taken my data, about 700 images and segmented it into 6 classes. I changed the num_classes, cls_score, and bbox_pred parameters to 6 and 24 as instructed by a tutorial. However. When ran every input image has the same boxes in the same location, and the same cls_score. 

Does this issue sound familiar to anyone, and if so what. 

",2,1
46,2016-9-26,2016,9,26,23,54kqc0,Intel Acquisition Nervana Uses Brains to Make Better A.I.,https://www.reddit.com/r/deeplearning/comments/54kqc0/intel_acquisition_nervana_uses_brains_to_make/,reworksophie,1474898761,,0,1
47,2016-9-27,2016,9,27,4,54m9w3,Inferring exposure in photographs,https://www.reddit.com/r/deeplearning/comments/54m9w3/inferring_exposure_in_photographs/,ganesha1024,1474916649,"I've had a request to build a system that can estimate the level of exposure a photograph was taken with. I think it should be fairly straightforward with a CNN, but I couldn't find any examples of someone doing this. Is there something obvious I'm missing that makes this difficult?",7,1
48,2016-9-28,2016,9,28,0,54r7e5,Neural Attention: Machine Learning Meets Neuroscience,https://www.reddit.com/r/deeplearning/comments/54r7e5/neural_attention_machine_learning_meets/,reworksophie,1474991403,,0,1
49,2016-9-28,2016,9,28,9,54ttxr,Usefulness of Deep Learning to Drug Discovery and Eliminating Diseases,https://www.reddit.com/r/deeplearning/comments/54ttxr/usefulness_of_deep_learning_to_drug_discovery_and/,JoeyRob,1475023632,,0,1
50,2016-9-29,2016,9,29,0,54wu78,What Did You Miss at the Deep Learning Summit Last Week?,https://www.reddit.com/r/deeplearning/comments/54wu78/what_did_you_miss_at_the_deep_learning_summit/,reworkdiane,1475075994,,0,0
51,2016-9-29,2016,9,29,4,54y1af,Announcing YouTube-8M: A Large and Diverse Labeled Video Dataset for Video Understanding Research,https://www.reddit.com/r/deeplearning/comments/54y1af/announcing_youtube8m_a_large_and_diverse_labeled/,nex_jeb,1475089772,,0,6
52,2016-9-29,2016,9,29,17,551a2n,CUDA 8.0 Official Release,https://www.reddit.com/r/deeplearning/comments/551a2n/cuda_80_official_release/,nex_jeb,1475139328,,0,10
53,2016-9-30,2016,9,30,20,557dk1,Video Interview With Deep Learning Expert Honglak Lee,https://www.reddit.com/r/deeplearning/comments/557dk1/video_interview_with_deep_learning_expert_honglak/,reworkdiane,1475233464,,0,2
0,2016-10-3,2016,10,3,10,55lapo,"[Noob] Installed new Geforce 970 video card, how do I take advantage of it?",https://www.reddit.com/r/deeplearning/comments/55lapo/noob_installed_new_geforce_970_video_card_how_do/,[deleted],1475456680,[deleted],2,1
1,2016-10-3,2016,10,3,22,55nl6o,Visual Question Answering (VQA) in Keras with demo,https://www.reddit.com/r/deeplearning/comments/55nl6o/visual_question_answering_vqa_in_keras_with_demo/,anantzoid,1475500570,,2,1
2,2016-10-4,2016,10,4,2,55orrs,Binary Stochastic Neurons in Tensorflow,https://www.reddit.com/r/deeplearning/comments/55orrs/binary_stochastic_neurons_in_tensorflow/,[deleted],1475515416,[deleted],0,1
3,2016-10-4,2016,10,4,11,55rajt,TensorFlow in a Nutshell  Part Three: All the Models,https://www.reddit.com/r/deeplearning/comments/55rajt/tensorflow_in_a_nutshell_part_three_all_the_models/,c0cky_,1475546768,,0,11
4,2016-10-4,2016,10,4,13,55rt71,Yahoo Open Sources a Deep Learning Solution for Detecting Not Safe For Work (NSFW) Images,https://www.reddit.com/r/deeplearning/comments/55rt71/yahoo_open_sources_a_deep_learning_solution_for/,skurilyak,1475554623,,0,2
5,2016-10-4,2016,10,4,13,55rukk,Deep Learning Startup Skymind (YC W16) Raises $3M,https://www.reddit.com/r/deeplearning/comments/55rukk/deep_learning_startup_skymind_yc_w16_raises_3m/,skurilyak,1475555257,,0,1
6,2016-10-4,2016,10,4,19,55stqw,How Keras.io is building everyones go-to interface for deep learning,https://www.reddit.com/r/deeplearning/comments/55stqw/how_kerasio_is_building_everyones_goto_interface/,kohola71,1475576364,,0,1
7,2016-10-5,2016,10,5,18,55ylvy,Stat212b: Topics Course on Deep Learning by joanbruna,https://www.reddit.com/r/deeplearning/comments/55ylvy/stat212b_topics_course_on_deep_learning_by/,[deleted],1475658535,[deleted],0,1
8,2016-10-5,2016,10,5,18,55ynip,"Topics Course on Deep Learning by Joan Bruna, UC Berkeley, Stats Department. Spring 2016",https://www.reddit.com/r/deeplearning/comments/55ynip/topics_course_on_deep_learning_by_joan_bruna_uc/,terrorlucid,1475659596,,2,5
9,2016-10-5,2016,10,5,21,55z3iz,Tensorflow Sentiment Analysis and Data Reading tutorial made by me (cross post from r/MachineLearning),https://www.reddit.com/r/deeplearning/comments/55z3iz/tensorflow_sentiment_analysis_and_data_reading/,[deleted],1475668835,[deleted],0,1
10,2016-10-6,2016,10,6,0,5604sy,Computer Vision News of October,https://www.reddit.com/r/deeplearning/comments/5604sy/computer_vision_news_of_october/,Gletta,1475682578,Hello. Computer Vision News of October is here: http://www.rsipvision.com/ComputerVisionNews-2016October/ with an exclusive interview of Professor Jrgen Schmidhuber and great deeplearning / machinelearning stories. At page 3 a surprise for those who next week will attend ECCV in Amsterdam. Free subscription at page 33. Enjoy!,0,3
11,2016-10-6,2016,10,6,2,560ne2,Insight Artificial Intelligence Fellow Program launches in Silicon Valley and New York,https://www.reddit.com/r/deeplearning/comments/560ne2/insight_artificial_intelligence_fellow_program/,mwakanosya,1475688421,,0,6
12,2016-10-7,2016,10,7,21,56b56q,Top 10 Topics Not To Be Missed at the Machine Intelligence Summit,https://www.reddit.com/r/deeplearning/comments/56b56q/top_10_topics_not_to_be_missed_at_the_machine/,reworksophie,1475844012,,0,1
13,2016-10-12,2016,10,12,1,56yu7s,Learning and Computing Paradigm Shifts,https://www.reddit.com/r/deeplearning/comments/56yu7s/learning_and_computing_paradigm_shifts/,vikashkodati,1476202862,,0,0
14,2016-10-12,2016,10,12,2,56z6jg,"Hugo Larochelle's neural network &amp; deep learning tutorial videos, subtitled &amp; screengrabbed",https://www.reddit.com/r/deeplearning/comments/56z6jg/hugo_larochelles_neural_network_deep_learning/,Prooffread3r,1476206655,,2,2
15,2016-10-12,2016,10,12,3,56zp75,The 7 Myths of AI,https://www.reddit.com/r/deeplearning/comments/56zp75/the_7_myths_of_ai/,abdsc,1476212348,,0,1
16,2016-10-12,2016,10,12,17,5734zq,When is deep learning a bad idea? [X-post /r/machinelearning],https://www.reddit.com/r/deeplearning/comments/5734zq/when_is_deep_learning_a_bad_idea_xpost/,linuxjava,1476261943,https://www.reddit.com/r/MachineLearning/comments/56st2s/discussion_when_is_deep_learning_a_bad_idea/,1,1
17,2016-10-14,2016,10,14,20,57fx99,NYU Using NVIDIA DGX-1 Supercomputer to Push Boundaries of AI,https://www.reddit.com/r/deeplearning/comments/57fx99/nyu_using_nvidia_dgx1_supercomputer_to_push/,Nuno_EdgarFernandes,1476445578,,1,1
18,2016-10-17,2016,10,17,16,57w4ru,Video Interview With SwiftKey Founder &amp; CTO Ben Medlock,https://www.reddit.com/r/deeplearning/comments/57w4ru/video_interview_with_swiftkey_founder_cto_ben/,reworksophie,1476688950,,0,1
19,2016-10-18,2016,10,18,15,582gjf,Four Google data sets to kickstart machine learning!,https://www.reddit.com/r/deeplearning/comments/582gjf/four_google_data_sets_to_kickstart_machine/,ale_tuz,1476773400,,0,1
20,2016-10-19,2016,10,19,21,589z45,Video Interview With Deep Learning Expert Yoshua Bengio,https://www.reddit.com/r/deeplearning/comments/589z45/video_interview_with_deep_learning_expert_yoshua/,reworksophie,1476879871,,0,1
21,2016-10-20,2016,10,20,1,58b6a9,Multi-GPU Multi-Server training using CNTK,https://www.reddit.com/r/deeplearning/comments/58b6a9/multigpu_multiserver_training_using_cntk/,rrbilgi,1476894244,"I am training an acoustic model for speech recognition using CNTK. I am using Kaldi reader and can train the model (DNN model, 429:4*1024*4021) using 20 hours of data. However, when I increase the data to 1000 hours, it consumes all the system RAM (not GPU RAM) and gets killed by the system. It is getting killed while reading the features and alignment (first step). What is the best way to train DNN model for larger data set. 

Following is the system configuration:

2 GTX GPU with 4 GB RAM each, 64 GB RAM, 30 CPU cores. I am running two parallel process with mpiexec (mpiexec -np cntk config=CNTK.cntk with parallelTrain set to true with dataParallelSGD). Also I tried with just one process and even it fails to start the model training. I am using minibatch of 4096 (tried also with smaller minibatch size).

What is the best way to train the model with huge amount of data ?.

PS: I can use Kaldi tool to train AM using all the 1000 hours data on same system.",5,3
22,2016-10-20,2016,10,20,11,58ectk,Question about Input Layer in Neural Network,https://www.reddit.com/r/deeplearning/comments/58ectk/question_about_input_layer_in_neural_network/,[deleted],1476929271,[deleted],2,2
23,2016-10-21,2016,10,21,17,58m5fn,"Overview of Day 1: The Deep Learning Summit in Singapore, 20 Oct 2016 #reworkDL",https://www.reddit.com/r/deeplearning/comments/58m5fn/overview_of_day_1_the_deep_learning_summit_in/,reworkdiane,1477037627,,0,0
24,2016-10-22,2016,10,22,3,58otdi,LIFT: Learned Invariant Feature Points,https://www.reddit.com/r/deeplearning/comments/58otdi/lift_learned_invariant_feature_points/,afeder_,1477074848,,1,3
25,2016-10-22,2016,10,22,9,58qqp8,Just Started This Today - Write Letters to the Artificial Intelligence Singularity that it can read when it is eventually created and conscious!,https://www.reddit.com/r/deeplearning/comments/58qqp8/just_started_this_today_write_letters_to_the/,BenjaminBoyle,1477097806,,1,0
26,2016-10-23,2016,10,23,14,58x6v0,Data Compression + Denoising,https://www.reddit.com/r/deeplearning/comments/58x6v0/data_compression_denoising/,hiteshv09,1477199450,"what wud be the best way 2 implement noise reduction + data compression? Autoencoder or something else? For example, consider a satellite capturing data. This Data is compressed and sent over network bottleneck to space station. At receiving station this data is decompressed and denoised. This can work for online video streaming,drive storage etc. The aim is that like Deep Mind, this system should work for all kind of data. But let's say we start with images. Also how will the system know for a new data that what is a noise in it? Humans can easily distinguish noise.
The problem is, autoencoder is good for denoising but not good for data compression. So can we design a hybrod system. And most importantly, how to implement this?",1,1
27,2016-10-23,2016,10,23,14,58x79d,Thermset : A thermal video dataset of elders at their bedrooms,https://www.reddit.com/r/deeplearning/comments/58x79d/thermset_a_thermal_video_dataset_of_elders_at/,[deleted],1477199643,[deleted],1,1
28,2016-10-23,2016,10,23,15,58xhwq,Does my GPU work for deeplearning ?,https://www.reddit.com/r/deeplearning/comments/58xhwq/does_my_gpu_work_for_deeplearning/,shravankumar147,1477205470,"I have Asus k55VJ notebook, which have i5 3rd generation processor, with 8GB RAM. It has both Intel and Nvidia Graphics cards. My Nvidia graphic card is Geforce GT635M and I'm using ubuntu os. So my question is whether my GPU works for deep learning or not, whether it can be used to speedup the computation or not?

Thanks in advance",7,4
29,2016-10-25,2016,10,25,18,59a26j,The Potential for Deep Learning to Change Your Business,https://www.reddit.com/r/deeplearning/comments/59a26j/the_potential_for_deep_learning_to_change_your/,JoeyRob,1477386078,,0,1
30,2016-10-25,2016,10,25,22,59b12v,O que  Machine Learning? E Deep Learning?,https://www.reddit.com/r/deeplearning/comments/59b12v/o_que__machine_learning_e_deep_learning/,brunolaredo,1477402426,,0,1
31,2016-10-25,2016,10,25,22,59b3tc,gym - Reinforcement Learning in R,https://www.reddit.com/r/deeplearning/comments/59b3tc/gym_reinforcement_learning_in_r/,paulhendricks,1477403383,,0,1
32,2016-10-26,2016,10,26,1,59btz5,Feature reduction using deep learning,https://www.reddit.com/r/deeplearning/comments/59btz5/feature_reduction_using_deep_learning/,gntc,1477411426,"I'm working on a project for which I have a very high dimensional feature space and a limited number of samples.  It was recommended to me to try using RNNs to reduce the feature space prior to training a model for classification.  Does anyone know of any literature regarding how to do this with RNNs?

Thanks",2,1
33,2016-10-26,2016,10,26,3,59clzx,Neural net video analysis of webcam/live,https://www.reddit.com/r/deeplearning/comments/59clzx/neural_net_video_analysis_of_webcamlive/,dirtyharry2,1477419440,"I'm looking into automating a very specific video analysis, for a sport called ""flyball"" a dogsport.  https://www.youtube.com/watch?v=zHniPoweqCc&amp;feature=youtu.be is a link of an overhead (via drone) view of what we're doing - around the 1:20 mark you see a full run with ""passes"" (basically, there's an infrared beambreak, and dog A has to finish before dog B is allowed to break the beam with his running start, then same for dogs C and D).  Those passes are important (you see the distance marks on the grass; a few 4 foot passes is often the difference between winning and losing).  Assume for this purpose (a) I'll have a fixed camera, always directly above the start-line at the same height, shooting 720/120fps; and (b) I have no trouble ""training"" a system by manually telling it ""this was a X foot pass"" for a couple thousand examples.   The crunch is that I want this information displayed to the contestants LIVE via a 7-segment.  I've looked into Clarifai, Watson, Tensorflow, etc, and can't get my head around if this is possible, if it needs to be cloud-connected and I'm paying to analyze a million frames if even possible, etc.  Ideally the end goal would be to make this an APP that goes on any modern phone with a good camera, but one step at a time.",1,1
34,2016-10-28,2016,10,28,18,59tlb0,"Democratising Deep Learning: The Data Delusion - Slides &amp; Presentation by Neil Lawrence, Senior Principal Scientist at Amazon",https://www.reddit.com/r/deeplearning/comments/59tlb0/democratising_deep_learning_the_data_delusion/,reworksophie,1477647986,,0,1
35,2016-10-28,2016,10,28,19,59tstv,Is there good paper on investigation of loss functions?,https://www.reddit.com/r/deeplearning/comments/59tstv/is_there_good_paper_on_investigation_of_loss/,InfiniteLife2,1477652215,"I want to understand what is motivation for creating particular cost function, how does it affects slope for same data and mapping function switching loss function, when to use one and when other. Can you advise materials to read on this subject?",0,2
36,2016-10-28,2016,10,28,21,59u1qw,47 New External Data Science / Machine Learning Resources and Articles,https://www.reddit.com/r/deeplearning/comments/59u1qw/47_new_external_data_science_machine_learning/,Ushaia,1477656551,,0,1
37,2016-10-29,2016,10,29,18,59zsfh,"Deep Learning, Alchemy or Science?",https://www.reddit.com/r/deeplearning/comments/59zsfh/deep_learning_alchemy_or_science/,codeaudit,1477734534,,2,7
38,2016-10-29,2016,10,29,19,59ztuy,Design Patterns for Deep Learning (Composable Differentiable) Architectures,https://www.reddit.com/r/deeplearning/comments/59ztuy/design_patterns_for_deep_learning_composable/,codeaudit,1477735477,,0,2
0,2016-11-3,2016,11,3,8,5ataio,Introducing The Nexar Challenge: Deep-Driving into the Future,https://www.reddit.com/r/deeplearning/comments/5ataio/introducing_the_nexar_challenge_deepdriving_into/,ilankadar,1478128500,"Nexar is prepared to make the world's roads safer, and you can help. Introducing our first open challenge. Your participation could be vital to creating a collision-free world, and the chance to win great prizes never hurts. For details, click here:https://blog.getnexar.com/introducing-the-nexar-challenge-deep-driving-into-the-future-31e0ed9db4b7#.9j40j9w9o",1,2
1,2016-11-3,2016,11,3,23,5awusb,Online learning in Tensorflow?,https://www.reddit.com/r/deeplearning/comments/5awusb/online_learning_in_tensorflow/,yahyaheee,1478181635,"Hey, I was wondering if anyone had come across any online learning examples in Tensorflow? Thanks",0,5
2,2016-11-3,2016,11,3,23,5awz59,Deep Learning in Aerial Systems Using Jetson,https://www.reddit.com/r/deeplearning/comments/5awz59/deep_learning_in_aerial_systems_using_jetson/,harrism,1478182956,,0,2
3,2016-11-4,2016,11,4,4,5ayzv6,Is it possible to jump into DL with little ML knowledge or do I need to study ML algorithms first?,https://www.reddit.com/r/deeplearning/comments/5ayzv6/is_it_possible_to_jump_into_dl_with_little_ml/,[deleted],1478202975,[deleted],2,0
4,2016-11-4,2016,11,4,7,5azrvk,My New Blog About Deep Learning With Torch and My Thoughts About It,https://www.reddit.com/r/deeplearning/comments/5azrvk/my_new_blog_about_deep_learning_with_torch_and_my/,TenseTV,1478210731,,0,1
5,2016-11-6,2016,11,6,17,5bewns,NeuralStyler 2.0 released,https://www.reddit.com/r/deeplearning/comments/5bewns/neuralstyler_20_released/,simpleuserhere,1478421580,,2,6
6,2016-11-7,2016,11,7,9,5bj7ex,Deep Learning can Now Design Itself!,https://www.reddit.com/r/deeplearning/comments/5bj7ex/deep_learning_can_now_design_itself/,codeaudit,1478479399,,0,1
7,2016-11-7,2016,11,7,22,5bm7a0,Computer Vision News (November) + Best of ECCV,https://www.reddit.com/r/deeplearning/comments/5bm7a0/computer_vision_news_november_best_of_eccv/,Gletta,1478526280,"Computer Vision News of November (72 pages):
http://www.rsipvision.com/ComputerVisionNews-2016November/
It includes the regular sections, as well as special Best of ECCV and Best of MICCAI, with interviews with Jitendra Malik, Michael Black, Polina Golland and others. Most research papers reviewed build on deep learning.",0,2
8,2016-11-8,2016,11,8,5,5bogwj,Prisma-like NeuralStyler brings more creative control,https://www.reddit.com/r/deeplearning/comments/5bogwj/prismalike_neuralstyler_brings_more_creative/,simpleuserhere,1478549240,,0,0
9,2016-11-8,2016,11,8,7,5bpgnl,PCIe Bandwidth for Workstation,https://www.reddit.com/r/deeplearning/comments/5bpgnl/pcie_bandwidth_for_workstation/,Gio_Gats,1478558840,"Working on a build that's part workstation, part gaming rig, and part deep-learning research platform.  I'm trying to eliminate bottlenecks wherever possible to get the most out of my hardware.
I'm planning to put two GTX 1070s, a 10Gb/s networking card, and a NVMe SSD into the PCIe slots on a MSI X99A Gaming Pro Carbon with an Intel i7-6850K (40 PCIe lanes).  
The manual tells me I can get x8/x16/x8/x8 bandwidth out of those slots.  With those limitations, am I better off sticking with 1Gb/s networking and a SATAIII?  
I know I probably won't see much bottleneck while gaming, but what about running optimized deep learning libraries like TensorFlow?  ",2,0
10,2016-11-9,2016,11,9,20,5c0j9r,Neural Networks Overview CheatSheet,https://www.reddit.com/r/deeplearning/comments/5c0j9r/neural_networks_overview_cheatsheet/,devnull90,1478690536,,1,12
11,2016-11-10,2016,11,10,17,5c6uz1,Architecture of RoI Pooling Layer,https://www.reddit.com/r/deeplearning/comments/5c6uz1/architecture_of_roi_pooling_layer/,mishastik,1478767132,Could somebody please point to an explicit description of the architecture of the Region of Interest (RoI) Pooling Layer in the Region-based CNNs ?,3,1
12,2016-11-11,2016,11,11,10,5cbvmu,Using AI for encouraging the elderly to live independently,https://www.reddit.com/r/deeplearning/comments/5cbvmu/using_ai_for_encouraging_the_elderly_to_live/,fpolacov,1478829077,,1,1
13,2016-11-11,2016,11,11,18,5cdn1o,Deep Learning - Eine bersicht,https://www.reddit.com/r/deeplearning/comments/5cdn1o/deep_learning_eine_bersicht/,flezzfx,1478856148,,0,1
14,2016-11-11,2016,11,11,18,5cdpdu,Nervana's VP of Algorithms: Catalyzing Deep Learnings Impact in the Enterprise,https://www.reddit.com/r/deeplearning/comments/5cdpdu/nervanas_vp_of_algorithms_catalyzing_deep/,reworksophie,1478857485,,0,1
15,2016-11-12,2016,11,12,0,5cf24z,"Where would you place ""deep learning"" on the Gartner Hype Cycle?",https://www.reddit.com/r/deeplearning/comments/5cf24z/where_would_you_place_deep_learning_on_the/,[deleted],1478878483,[deleted],2,4
16,2016-11-12,2016,11,12,3,5cfzrg,Image Segmentation Using DIGITS 5,https://www.reddit.com/r/deeplearning/comments/5cfzrg/image_segmentation_using_digits_5/,harrism,1478888520,,0,3
17,2016-11-12,2016,11,12,13,5cixc8,How AI Careers Fit into the Data Landscape,https://www.reddit.com/r/deeplearning/comments/5cixc8/how_ai_careers_fit_into_the_data_landscape/,mwakanosya,1478925893,,0,4
18,2016-11-13,2016,11,13,1,5cl0h1,Using deep learning to remove glasses from faces,https://www.reddit.com/r/deeplearning/comments/5cl0h1/using_deep_learning_to_remove_glasses_from_faces/,mwakanosya,1478966781,,1,7
19,2016-11-13,2016,11,13,3,5clkh4,Deep Learning for Natural Language Processing  ICLR 2017 Discoveries,https://www.reddit.com/r/deeplearning/comments/5clkh4/deep_learning_for_natural_language_processing/,atveit,1478973888,,0,2
20,2016-11-13,2016,11,13,11,5cnt6a,Let's build a Discord community for AI research,https://www.reddit.com/r/deeplearning/comments/5cnt6a/lets_build_a_discord_community_for_ai_research/,SyntaxExpert,1479002670,,0,6
21,2016-11-14,2016,11,14,23,5cw3y5,Deep Learning cheat sheet?,https://www.reddit.com/r/deeplearning/comments/5cw3y5/deep_learning_cheat_sheet/,[deleted],1479132601,[deleted],1,7
22,2016-11-15,2016,11,15,1,5cwspu,"Video Interview with Oriol Vinyals, Research Scientist at Google DeepMind",https://www.reddit.com/r/deeplearning/comments/5cwspu/video_interview_with_oriol_vinyals_research/,reworksophie,1479140850,,0,1
23,2016-11-17,2016,11,17,0,5d9osd,Heuristics for neural network hyperparameter selection,https://www.reddit.com/r/deeplearning/comments/5d9osd/heuristics_for_neural_network_hyperparameter/,Lopelh,1479309331,,0,2
24,2016-11-17,2016,11,17,7,5dc22v,Paid Research Opportunity: Deep Learning or Machine Learning,https://www.reddit.com/r/deeplearning/comments/5dc22v/paid_research_opportunity_deep_learning_or/,[deleted],1479333931,[deleted],0,1
25,2016-11-17,2016,11,17,9,5dcoae,Can't get MNIST tensor flow tutorial working,https://www.reddit.com/r/deeplearning/comments/5dcoae/cant_get_mnist_tensor_flow_tutorial_working/,[deleted],1479340800,[deleted],0,1
26,2016-11-17,2016,11,17,16,5demrq,text classification and prediction of relatedness,https://www.reddit.com/r/deeplearning/comments/5demrq/text_classification_and_prediction_of_relatedness/,Catslinger,1479368542,"Hello, I have a hypothetical project in mind:

I'd like a personal fulltext &amp; metadata search engine that can compare the content of text files (pdf, txt, doc) and arrange them visually according to their similarity and relatedness. This arrangement would look at the semantic surface of texts without being able to draw conclusions on the nature of their correlation (e.g. causal, hierarchical).

Now for the machine learning part:

Users should be able to rank and specify these relationships between texts whether or not they are, in fact, related argumentationally, and content-wise.

And the software would draw conclusions from these user-generated rankings / specifications and would make its own future predictions.

Example: ""Text A and Text B do not only use similar terms and structure, but Text B is also younger than Text A and - although not referencing Text A - uses ideas that were introduced in Text A."" or ""Text C references Text A, but from the argument it develops, it looks like it is targeting Text B rather than Text A.""

How would one start setting something like this up? Are there any projects doing something similar?
",1,2
27,2016-11-19,2016,11,19,7,5dp8r3,Lessons Learned from Deploying Deep Learning at Scale,https://www.reddit.com/r/deeplearning/comments/5dp8r3/lessons_learned_from_deploying_deep_learning_at/,[deleted],1479507532,[deleted],0,0
28,2016-11-19,2016,11,19,14,5dr4lm,Deep Learning for layman,https://www.reddit.com/r/deeplearning/comments/5dr4lm/deep_learning_for_layman/,shakthydoss,1479534295,,0,1
29,2016-11-19,2016,11,19,20,5ds3u5,Julia for Deep Learning Presented by IBM and Julia Computing at SC16,https://www.reddit.com/r/deeplearning/comments/5ds3u5/julia_for_deep_learning_presented_by_ibm_and/,Nuno_EdgarFernandes,1479555716,,0,4
30,2016-11-20,2016,11,20,3,5dto09,Wow! A photonic neural network.,https://www.reddit.com/r/deeplearning/comments/5dto09/wow_a_photonic_neural_network/,DarthRhaego,1479578828,And thus Alexander Tait and co embark on yet another promising pavement to faster and intelligent computing.   ,0,0
31,2016-11-20,2016,11,20,7,5duvu5,Deep Reinforcement Learning with Averaged Target DQN (a variance reduction method for DRL),https://www.reddit.com/r/deeplearning/comments/5duvu5/deep_reinforcement_learning_with_averaged_target/,MisterO123,1479593816,,0,2
32,2016-11-21,2016,11,21,8,5e0stm,Top 5 most important things that happened in deep learning in 2016?,https://www.reddit.com/r/deeplearning/comments/5e0stm/top_5_most_important_things_that_happened_in_deep/,[deleted],1479683708,[deleted],2,6
33,2016-11-22,2016,11,22,8,5e789d,Why did Bengio not sell out like Hinton and LeCun?,https://www.reddit.com/r/deeplearning/comments/5e789d/why_did_bengio_not_sell_out_like_hinton_and_lecun/,[deleted],1479769609,[deleted],1,3
34,2016-11-22,2016,11,22,12,5e8kxg,Top 5 developments that happened in deep learning in 2016 or 2015?,https://www.reddit.com/r/deeplearning/comments/5e8kxg/top_5_developments_that_happened_in_deep_learning/,[deleted],1479785853,[deleted],1,0
35,2016-11-22,2016,11,22,14,5e94ic,[D] A question about GANs,https://www.reddit.com/r/deeplearning/comments/5e94ic/d_a_question_about_gans/,yield22,1479793488,Will there be any differences by swapping min_G max_D in the objective of GANs? Training wise and optimality wise.,3,1
36,2016-11-23,2016,11,23,20,5egu5x,"Limited time special offer on REWORK Deep Learning, Machine Intelligence &amp; AI events! Super savings on Early Bird/Startup/Student passes",https://www.reddit.com/r/deeplearning/comments/5egu5x/limited_time_special_offer_on_rework_deep/,reworksophie,1479900662,,0,1
37,2016-11-23,2016,11,23,22,5ehb1k,Deep Learning Demo with eSOMTK1 in Retail Outlet | nVIDIA Tegra K1 SOM,https://www.reddit.com/r/deeplearning/comments/5ehb1k/deep_learning_demo_with_esomtk1_in_retail_outlet/,econsystems,1479908161,,0,2
38,2016-11-25,2016,11,25,20,5et3xs,"My LSTM is predicting white noise, something is wrong.",https://www.reddit.com/r/deeplearning/comments/5et3xs/my_lstm_is_predicting_white_noise_something_is/,PhantomFav,1480072425,"I'm playing with this tutorial:

http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/#comment-372293

And it's working correctly, but if i use the fitted model on the flight data, i can use the same hyper parameters to predict white noise using this code:

#Data Generation:

dataset = numpy.random.randint(500, size=(200,1))
dataset = dataset.astype(float32)

#Data Prediction:

scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)
plt.plot(dataset,b,model.predict(dataset[:,:,numpy.newaxis]),r)

final result:
https://s17.postimg.org/oavua7uq7/download.png

what am i doing wrong?",1,2
39,2016-11-25,2016,11,25,23,5etq7d,[D] What can deep learning actually achieve in medicine?,https://www.reddit.com/r/deeplearning/comments/5etq7d/d_what_can_deep_learning_actually_achieve_in/,[deleted],1480083008,[deleted],2,4
40,2016-11-27,2016,11,27,1,5f0448,[D] Is Deep Learning Growing at an Exponential Rate?,https://www.reddit.com/r/deeplearning/comments/5f0448/d_is_deep_learning_growing_at_an_exponential_rate/,[deleted],1480176746,[deleted],3,0
41,2016-11-28,2016,11,28,9,5f8m4b,[D] Why don't more teams use deep learning in Kaggle?,https://www.reddit.com/r/deeplearning/comments/5f8m4b/d_why_dont_more_teams_use_deep_learning_in_kaggle/,[deleted],1480293250,[deleted],2,2
42,2016-11-29,2016,11,29,1,5fclsi,"[D] Have 10K AWS Promotional Credit, how much DL work can I do on the cloud?",https://www.reddit.com/r/deeplearning/comments/5fclsi/d_have_10k_aws_promotional_credit_how_much_dl/,[deleted],1480350979,[deleted],0,1
43,2016-11-29,2016,11,29,1,5fcnmf,"[D] Won $5000 AWS Promotional Credit from a hackathon, how much DL work can I do on the cloud?",https://www.reddit.com/r/deeplearning/comments/5fcnmf/d_won_5000_aws_promotional_credit_from_a/,[deleted],1480351487,[deleted],0,1
44,2016-11-29,2016,11,29,5,5fe2rb,How does sparse autoencoder apply to variable time-sequence data for feature extraction?,https://www.reddit.com/r/deeplearning/comments/5fe2rb/how_does_sparse_autoencoder_apply_to_variable/,starsmiling,1480365451,"I have a variable length of time-sequence data, say 6 dimensions. I would like to use sparse autoencoder for feature extraction. Specifically, I want to get high dimensional features. From the references it seems that people always use same-length data to feed into autoencoder. What if the data has variable length? Is it a must to convert/pad/cut variable length into the same-length in order to train autoencoder?

Any information is appreciated!",0,2
45,2016-11-29,2016,11,29,9,5ffdzi,Image Processing using Deep Neural Networks Virtual Conference,https://www.reddit.com/r/deeplearning/comments/5ffdzi/image_processing_using_deep_neural_networks/,kevin_img_processing,1480378858,"Hello!

Just wanted to pass along a free Deep Learning for Image Processing Virtual Conference being put on by Wolfram Research Wednesday 11/30/16 and Wednesday 12/7/16. It's in Mathematica, which has recently released a deep learning library. 

You can find more information here:
https://www.wolfram.com/training/special-event/wolfram-virtual-conference-series/

I'm x-posting this on /r/deeplearning /r/Mathematica and /r/machinelearning as those seem to be the pertinent subs, but as it's an open invitation virtual conference, feel free to pass it on to anyone who might be interested.

Feel free to post any questions you might have here and I'll do my best to answer them.",0,2
46,2016-11-29,2016,11,29,17,5fhl1z,Picking a DL framework,https://www.reddit.com/r/deeplearning/comments/5fhl1z/picking_a_dl_framework/,[deleted],1480408265,[deleted],0,2
47,2016-11-29,2016,11,29,21,5fiboq,Deep-Learning Algorithm That Can Peer Into The Future,https://www.reddit.com/r/deeplearning/comments/5fiboq/deeplearning_algorithm_that_can_peer_into_the/,massiveattack778,1480421872,,0,0
48,2016-11-30,2016,11,30,11,5fmxh8,Deep networks performance on classifying convex regular polygons.,https://www.reddit.com/r/deeplearning/comments/5fmxh8/deep_networks_performance_on_classifying_convex/,puplan,1480471731,"I'm trying to find papers or just performance data on classifying simple geometric shapes, e.g. the first six convex regular polygons. The input data is computer graphics generated, producing high contrast, clean images of convex regular polygons in various scales and orientations (rotation only). There is no limit, other than reasonable CPU time, on number of training images provided. Testing is also done on randomly generated CG images.

Regular polygons are just an example. You can add circles, ellipses, non-regular polygons, etc. Basically any simple geometric shape, which competent elementary school students easily classify with 100% accuracy.",0,1
49,2016-11-30,2016,11,30,17,5fohlp,Hardware choices: VRAM and PCIe bandwidth,https://www.reddit.com/r/deeplearning/comments/5fohlp/hardware_choices_vram_and_pcie_bandwidth/,newtonian_mechanics,1480493198,"I want to build a system for deep learning. Since I'm new to this area and a lot of this is empirical science, I do not have a good idea of the tradeoffs involved.

I'm on a budget of about $2k.

I have read Tim Dettmers' [blog posts](http://timdettmers.com/) to get a general idea of what I should be looking for, but I still have the following questions:

Amount of VRAM: How much will it limit me if I go for GTX 1080 (8GB) instead of Pascal Titan (12GB)? I can buy 2 1080s for the price of a Titan. If it doesn't limit me much in terms of what models I can run, I think 2 1080s might be a better choice because I'd be able to test hyperparameters in parallel.

PCIe bandwidth: Tim Dettmers says I should go for CPUs with 40 PCIe lanes. That would mean Intel LGA2011 socket. How much of a performance difference can I expect between running a GPU on 8x vs 16x PCIe 3.0? If there isn't much difference, I could go for LGA1151 CPUs (16 lanes) as I probably won't be running more than 2 GPUs.

Thank you!",4,2
0,2016-12-1,2016,12,1,14,5fusfy,MIT's Deep-learning system generates Videos that predict what will happen next in a scene.,https://www.reddit.com/r/deeplearning/comments/5fusfy/mits_deeplearning_system_generates_videos_that/,chrisqpt,1480568967,,0,1
1,2016-12-2,2016,12,2,13,5g1g81,What does it mean when hidden layers are increasingly sparse?,https://www.reddit.com/r/deeplearning/comments/5g1g81/what_does_it_mean_when_hidden_layers_are/,nwpositronics,1480654349,,2,6
2,2016-12-3,2016,12,3,22,5g9jiy,DNN architecture with variable-length output ?,https://www.reddit.com/r/deeplearning/comments/5g9jiy/dnn_architecture_with_variablelength_output/,asfarley,1480771548,"Anyone know about DNN architectures with variable-length outputs? A quick Google search doesn't turn up much. I'm not really interested in ideas like padding a maximum-length output with ""null"" - I'm looking for an architecture with a more natural representation of a variable length output.

Specifically, I would like to represent image scenes as a partially-ordered graph/lattice where the ordering is equivalent to depth/Z-order in the image. ",1,1
3,2016-12-4,2016,12,4,2,5gaiho,"Deep, Machine Learning, AI Developer jobs and salary.",https://www.reddit.com/r/deeplearning/comments/5gaiho/deep_machine_learning_ai_developer_jobs_and_salary/,petroDollaWarMachine,1480785155,"I've been researching jobs and salaries for deep learning, machine learning, AI developer and data scientists.  All of the job salary sites seem to report very average salaries for this new industry.  The salaries are on par with typical senior level Microsoft / LAMP / fullstack / web / java / ios developer positions.

I don't get it?  For a field that requires such high level math, why isn't this level of difficulty reflected in the compensation?

Could it be another case of this?

http://www.zdnet.com/article/court-settlement-hides-how-silicon-valley-companies-saved-billions-in-secret-conspiracy-against-own-workers/

http://www.nytimes.com/2014/03/01/technology/engineers-allege-hiring-collusion-in-silicon-valley.html?_r=0",2,7
4,2016-12-4,2016,12,4,13,5gdndv,A summary of Udacity's lessons on DL pooling,https://www.reddit.com/r/deeplearning/comments/5gdndv/a_summary_of_udacitys_lessons_on_dl_pooling/,pkpp1234,1480824009,,0,1
5,2016-12-6,2016,12,6,15,5grfsr,Computer Vision News of December (magazine format - click on Download icon if you prefer to read a PDF),https://www.reddit.com/r/deeplearning/comments/5grfsr/computer_vision_news_of_december_magazine_format/,Gletta,1481006463,,0,1
6,2016-12-6,2016,12,6,22,5gssx9,How much of a difference does 16x vs 8x pci-e lanes make for multi-GPU training?,https://www.reddit.com/r/deeplearning/comments/5gssx9/how_much_of_a_difference_does_16x_vs_8x_pcie/,gr_eabe,1481030564,"My understanding is that with a 40 lane motherboard, you can have 4 GPUs running at 8x (~8GB/s) or 2 GPUs running at 16x (~16GB/s).  When you run the same model on multiple GPUs, you need to sync the parameters after every mini-batch (at least ideally).  It seems like you could potentially be bottlenecked by these transfer speeds, so there might be a big advantage to the 2 GPU setup.  On the other hand, things would seem to be even worse with distributed training.  Can anyone speak from experience about how big a deal 8x vs. 16x is and whether it could ever be good to use two machines with two GPUs each rather than one machine with four GPUs?  (Also, what do dual socket motherboards add to the mix?)",0,7
7,2016-12-7,2016,12,7,3,5guoam,The major advancements in Deep Learning in 2016,https://www.reddit.com/r/deeplearning/comments/5guoam/the_major_advancements_in_deep_learning_in_2016/,[deleted],1481050539,[deleted],0,1
8,2016-12-8,2016,12,8,2,5h16m9,"'A Deep Hierarchical Approach to Lifelong Learning in Minecraft' (AAAI-17), Tessler et al 2016",https://www.reddit.com/r/deeplearning/comments/5h16m9/a_deep_hierarchical_approach_to_lifelong_learning/,chentessler,1481131615,"Hi everyone, 

We would like to share with you our recent work entitled 'A Deep Hierarchical Approach to Lifelong Learning in Minecraft' (AAAI-17) ([paper](https://arxiv.org/abs/1604.07255), [website](http://chentessler.wixsite.com/hdrlnminecraft)). This work presents a lifelong deep reinforcement learning system that is able to efficiently retain as well as transfer knowledge (via reusable skills) to solve new, unseen tasks; two of the key building blocks to lifelong learning.
It is an exciting time for Deep Reinforcement Learning (DRL) research as new, complex gaming environments are being open sourced ([Minecraft - Malmo](https://www.microsoft.com/en-us/research/project/project-malmo/), [OpenAI - Universe](https://universe.openai.com/), [StarCraft - TorchCraft](https://arxiv.org/abs/1611.00625), [StarCraft 2](https://deepmind.com/blog/deepmind-and-blizzard-release-starcraft-ii-ai-research-environment/), [DeepMind Lab](https://deepmind.com/blog/open-sourcing-deepmind-lab/)
) and shared with the AI community. We strongly believe that taking advantage of hierarchy as well as efficient mechanisms to transfer and retain knowledge are soon to play significant roles in the ability of DRL agents to scale in these new exciting environments. 

Cheers",2,6
9,2016-12-8,2016,12,8,2,5h16oh,Processing images of multiple sizes,https://www.reddit.com/r/deeplearning/comments/5h16oh/processing_images_of_multiple_sizes/,fusionlove,1481131631,"Hey :)

We now have the ability to run CNNs on different sized images - thanks to convolutional layers (which don't care about the size) and spatial pooling layers (which convert multiple sized inputs to a fixed size representation).

My question is about how to do this efficiently. Most implementations (I've tried Keras and Lasagne) batch images together for efficiency - but they do this by placing them into a big Numpy matrix, which constrains them all to be the same size!

I've approached this by training on one image at a time - but sadly this slows down training time by a factor of 50 (in Lasagne).

Any tips? :)",1,2
10,2016-12-9,2016,12,9,5,5h9al9,DBN: generatively modeling the labels and data - Hinton's paper,https://www.reddit.com/r/deeplearning/comments/5h9al9/dbn_generatively_modeling_the_labels_and_data/,hassanzadeh,1481228816,"Hi everyone,
In Hinton's paper (http://www.cs.toronto.edu/~hinton/absps/montrealTR.pdf) the MNIST data as well as the LABELS are generatively incorporated into the model, however, in the code provided for that paper (http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html) labels are left out. I'm having a hard time understanding how the labels can be effectively incorporated there. Any thoughts?",0,0
11,2016-12-10,2016,12,10,2,5hf7q5,making a Deep Learning Dataset in 24 hours,https://www.reddit.com/r/deeplearning/comments/5hf7q5/making_a_deep_learning_dataset_in_24_hours/,datasutra,1481306232,,1,1
12,2016-12-10,2016,12,10,11,5hhsw8,How to add a new category to a deep learning model?,https://www.reddit.com/r/deeplearning/comments/5hhsw8/how_to_add_a_new_category_to_a_deep_learning_model/,robot_t0,1481335319,"Say I have done transfer learning on a pre-trained network to recognize 10 objects. How do add a 11th item that the network can classify without losing all the 10 categories that I already trained nor the information from the original pre-trained model ? A friend told me that active research is going on in this field, but I can't find any relevant papers or a name by which to search for ?
Thank you.",6,2
13,2016-12-10,2016,12,10,18,5hjf2p,Anyone trying to implement their own deep learning library ?,https://www.reddit.com/r/deeplearning/comments/5hjf2p/anyone_trying_to_implement_their_own_deep/,robot_t0,1481362412,"Ofcourse, it won't be as cool as Google's etc, but I think it is a awesome project. So much to learn ! ",8,3
14,2016-12-10,2016,12,10,22,5hk876,Slides from Tutorials in NIPS 2016,https://www.reddit.com/r/deeplearning/comments/5hk876/slides_from_tutorials_in_nips_2016/,shubhamjain0594,1481378349,,0,9
15,2016-12-11,2016,12,11,1,5hkygk,[Course] Accelerated Deep Learning with TensorFlow - London 24-25th January 17 [x-post from [r/learnmachinelearning](www.reddit.com/r/learnmachinelearning)],https://www.reddit.com/r/deeplearning/comments/5hkygk/course_accelerated_deep_learning_with_tensorflow/,Geilminister,1481388179,,0,1
16,2016-12-11,2016,12,11,14,5hok9b,How is deep learning implemented in Amazon Go?,https://www.reddit.com/r/deeplearning/comments/5hok9b/how_is_deep_learning_implemented_in_amazon_go/,janeboo,1481433244,,2,3
17,2016-12-13,2016,12,13,4,5hyr0m,CNN correctly detected 95% of diabetic retinopathy cases - leads in public dataset classification results  /r/computervision,https://www.reddit.com/r/deeplearning/comments/5hyr0m/cnn_correctly_detected_95_of_diabetic_retinopathy/,CyndaquilTurd,1481571993,,0,1
18,2016-12-13,2016,12,13,5,5hz6am,Is it correct that we don't understand how neural nets actually arrive at their conclusions?,https://www.reddit.com/r/deeplearning/comments/5hz6am/is_it_correct_that_we_dont_understand_how_neural/,RefurbishedMac,1481576108,"To clarify, we understand how the NN architecture works, but we cannot define a neural net into a set of rules or laws that explain WHY it arrived at it's prediction?

But we can do this with decision trees?",9,7
19,2016-12-14,2016,12,14,2,5i4ybn,"NIPS 2016 Review, Day 2",https://www.reddit.com/r/deeplearning/comments/5i4ybn/nips_2016_review_day_2/,amplifier_khan,1481651033,,1,5
20,2016-12-15,2016,12,15,20,5igxg2,A Deep Learning Study Group,https://www.reddit.com/r/deeplearning/comments/5igxg2/a_deep_learning_study_group/,jantanplan,1481799604,"Hi,
I recently put together an open-source deep learning curriculum and after receiving feedback that it would be nice to have a central place to discuss the materials I created a Slack group to do just that. We just kicked off and are around 43 people. 
If you are interested you can join here:
http://www.deeplearningweekly.com/slack_invitations/new
You can find the curriculum here:
http://www.deeplearningweekly.com/pages/open_source_deep_learning_curriculum

Cheers :)",1,4
21,2016-12-16,2016,12,16,5,5ijsq2,A ConvLSTM cell for TensorFlow's RNN API.,https://www.reddit.com/r/deeplearning/comments/5ijsq2/a_convlstm_cell_for_tensorflows_rnn_api/,carlthome,1481832922,,0,3
22,2016-12-16,2016,12,16,19,5injep,Multi label time series classification with LSTM,https://www.reddit.com/r/deeplearning/comments/5injep/multi_label_time_series_classification_with_lstm/,a_endurance,1481883260,,0,0
23,2016-12-17,2016,12,17,20,5iu4un,Song style transfer AI test,https://www.reddit.com/r/deeplearning/comments/5iu4un/song_style_transfer_ai_test/,simpleuserhere,1481974986,,0,5
24,2016-12-18,2016,12,18,10,5ixweo,[Hardware configuration] How to setup 4 GTX 1080 GPUs machine,https://www.reddit.com/r/deeplearning/comments/5ixweo/hardware_configuration_how_to_setup_4_gtx_1080/,zagwin,1482025162,"Hello, I am working on Deep Learning projects with single GPU system. I want to build a more powerful machine. However, I don't have experience to build a deep learning machine (hardware parts). After online research, I am confused.

1. Is it possible to build system with 4 Nvidia GTX 1080 GPUs?

EDIT: from answers, I know that it is ok with 4 GTX 1080.

2. I found that the ""GTX 1080 GPUs won't support 4-way SLI"", does this mean I can only setup 2 GTX 1080 GPUs system? Or this is only for gaming/display not for deep learning computation?

Edit: from answers and I understand, I think the 2-way SLI or 4-way SLI is mainly for display or gaming. For Deep learning compuatation, it should be ok.

3. I found that GTX 1080 GPU's width is 2 slots. I think this means the motherboard should have 8 slots to support 4 GPUs. However, All (to my best knowledge) Asus workstation motherboards have 7 slots at max. Can they hold 4 gpus? Does the 4th GPU blocks pins on the mohterboard (at the bottom part along side the PCIE_7)?

Edit: from answers, Asus x99-e WS works well alghough the 4rd GPUs will block some connectors. and cheaper one GIGABYTE GA-X99P-SLI also work if update BIOS. Also, for speedup, it will be better to buy motherboard supports m2 ssd.

Thanks very much!
Weldon",14,2
25,2016-12-18,2016,12,18,11,5iy35s,neural song style,https://www.reddit.com/r/deeplearning/comments/5iy35s/neural_song_style/,simpleuserhere,1482027888,,0,3
26,2016-12-19,2016,12,19,7,5j2xip,Blind spot in PixelCNN?,https://www.reddit.com/r/deeplearning/comments/5j2xip/blind_spot_in_pixelcnn/,jsuit38,1482101829,"The paper ""Conditional Image Generation with PixelCNN Decoders"" says PixelCNN have a blind spot. But I don't see why this is true. 

For background: see https://arxiv.org/pdf/1606.05328v2.pdf section 2.2. ",2,2
27,2016-12-19,2016,12,19,11,5j3tvy,Is there any implementation of a neural model that extracts semantic label maps from portrait photos?,https://www.reddit.com/r/deeplearning/comments/5j3tvy/is_there_any_implementation_of_a_neural_model/,afg500,1482113061,I want to integrate it with a neural style transfer calibrated on portraits,0,1
28,2016-12-19,2016,12,19,15,5j50oh,Amazon Go : The Just Walk out Technology,https://www.reddit.com/r/deeplearning/comments/5j50oh/amazon_go_the_just_walk_out_technology/,dataaspirant,1482130134,,0,1
29,2016-12-20,2016,12,20,0,5j6vop,question about document embedding,https://www.reddit.com/r/deeplearning/comments/5j6vop/question_about_document_embedding/,davido1221,1482160594,"Is there any approach today to embed documents in a vector form ,via sentiment  analysis ? (for example DocumentA speaks positively about Apple &amp; DocumentB also speaks positively about apple ,so the cosine distance between the 2 documents will be high).",3,0
30,2016-12-20,2016,12,20,7,5j9f66,Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,https://www.reddit.com/r/deeplearning/comments/5j9f66/learning_a_probabilistic_latent_space_of_object/,rozgo,1482186295,,0,1
31,2016-12-23,2016,12,23,11,5jujto,Understanding Locally Connected Layers In Convolutional Neural Networks,https://www.reddit.com/r/deeplearning/comments/5jujto/understanding_locally_connected_layers_in/,AlexanderYau,1482458519,,0,3
32,2016-12-26,2016,12,26,0,5k8quh,need a companion to finish this,https://www.reddit.com/r/deeplearning/comments/5k8quh/need_a_companion_to_finish_this/,PhpDev2k14,1482679807,"anybody with me to complete this : http://neuralnetworksanddeeplearning.com/ 

we could connect over teamviewer. I am good at math, but need motivation to go faster with this resource. It is always better when you have a group.",2,3
33,2016-12-26,2016,12,26,4,5k9t6y,2016: The Year That Deep Learning Took Over the Internet,https://www.reddit.com/r/deeplearning/comments/5k9t6y/2016_the_year_that_deep_learning_took_over_the/,MavraSay,1482695364,,0,5
34,2016-12-28,2016,12,28,9,5kn54b,TensorFlow on Azure GPU,https://www.reddit.com/r/deeplearning/comments/5kn54b/tensorflow_on_azure_gpu/,lutzr,1482884652,,0,4
35,2016-12-29,2016,12,29,1,5kqyea,RGB-D image segmentation using deep learning,https://www.reddit.com/r/deeplearning/comments/5kqyea/rgbd_image_segmentation_using_deep_learning/,NailIbrahimli,1482941379,Is there any new paper about  segmentation of RGB-D images using deep learning approach? ,2,2
36,2016-12-30,2016,12,30,7,5kzr5u,Deep Learning Gallery - a curated list of awesome deep learning projects. Any feedback?,https://www.reddit.com/r/deeplearning/comments/5kzr5u/deep_learning_gallery_a_curated_list_of_awesome/,alecmgo,1483050977,,3,18
37,2016-12-30,2016,12,30,13,5l1iw9,"AutoDiff Graph that supports BatchNorm, Conv2d, LSTM built from scratch on numpy, with a Tensorflow-like interface and highly readable code.",https://www.reddit.com/r/deeplearning/comments/5l1iw9/autodiff_graph_that_supports_batchnorm_conv2d/,[deleted],1483072537,[deleted],0,1
38,2016-12-31,2016,12,31,3,5l4s5g,Collection of Deep Learning Cyber Security Research Papers,https://www.reddit.com/r/deeplearning/comments/5l4s5g/collection_of_deep_learning_cyber_security/,jt6211,1483120851,,0,10
0,2017-1-2,2017,1,2,16,5ljz7n,Deep Learning Market,https://www.reddit.com/r/deeplearning/comments/5ljz7n/deep_learning_market/,marketsandmarkets,1483340567,,0,1
1,2017-1-3,2017,1,3,5,5ln9c9,"What is the best Deep Learning library for learning ML, with a focus on neural networks?",https://www.reddit.com/r/deeplearning/comments/5ln9c9/what_is_the_best_deep_learning_library_for/,OnunOatiel,1483387486,"Can you kind people suggest a few libraries/frameworks which are suitable for learning ML and deep learning? Preferably python based, but other languages as well.",2,0
2,2017-1-3,2017,1,3,6,5lnm3f,Three part tutorial for getting started with gpu-driven deep learning,https://www.reddit.com/r/deeplearning/comments/5lnm3f/three_part_tutorial_for_getting_started_with/,socratesKisses,1483391256,"* [Building a &lt;$2000 machine](https://medium.com/@SocraticDatum/getting-started-with-gpu-driven-deep-learning-part-1-building-a-machine-d24a3ed1ab1e#.ilyzd2by7)
* [Setting up Ubuntu 16 and Docker](https://medium.com/@SocraticDatum/getting-started-with-gpu-driven-deep-learning-part-2-environment-setup-fd1947aab29#.exjt7p8a1)
* [Implementing style transfer with Docker](https://medium.com/@SocraticDatum/getting-started-with-gpu-driven-deep-learning-part-3-style-transfer-dec5f387d9ed#.tx6m6r259)",0,11
3,2017-1-3,2017,1,3,12,5lpoa9,Deep learning techniques for detecting extremely small blobs in grayscale images?,https://www.reddit.com/r/deeplearning/comments/5lpoa9/deep_learning_techniques_for_detecting_extremely/,HV250,1483414693,"Hello all,  

I am currently working on a dataset of images from an X ray imager that contain very faint blobs that need detection. Initially I tried using computer vision techniques but realized that there is way too much parameter tuning required for it to work reliably, and I have gotten some suggestions that deep learning techniques such as convolutional neural networks would have better luck with images like this. I was wondering if someone here could comment on that and possibly suggest some good software packages/algorithms to start off with.   

Here is a link to some of my images: in every image, there are four faint but dark blobs approximately around the center of the image. Any thoughts on the effectiveness of CNNs/other learning techniques for images like this are welcome.

http://imgur.com/a/OLEzE

Thank you!",2,3
4,2017-1-3,2017,1,3,14,5lq3lk,Pass through gpu on windows to Linux,https://www.reddit.com/r/deeplearning/comments/5lq3lk/pass_through_gpu_on_windows_to_linux/,SillyLilBear,1483420188,Is there a way to pass through nvidia gpu to Linux vm with windows as host for tensorflow and theano?,4,2
5,2017-1-4,2017,1,4,5,5lugdc,Anybody interested in an online reading group?,https://www.reddit.com/r/deeplearning/comments/5lugdc/anybody_interested_in_an_online_reading_group/,jalFaizy,1483477089,"I have just started the book by Goodfellow et al. Its a bit math heavy so it would be great to collaborate and discuss on it. I found this local meetup (https://www.meetup.com/Deep-Learning-Textbook-Study-Group/), but it has ended. Anybody interested?


EDIT 1: 

Since many of the people seem interested, we could start as early as possible. Could the people interested comment on 

* Where should we conduct our meetings?
* What time would be suitable for all?
* What would be the format of the reading group?

My personal suggestions, we could do a weekly meet on hangouts, preferably Sunday, but I'm up for everyday if it suits every1. Also for the format, as I suggested [below](https://www.reddit.com/r/deeplearning/comments/5lugdc/anybody_interested_in_an_online_reading_group/dbyrcgt/), it would be great if I could teach the book as an MOOC if everyone agrees. Eagerly waiting for your reply!


EDIT 2:
I've made a [google group](https://groups.google.com/forum/#!forum/deepreading), and we should start from next Sunday (15th of Jan). Till then we can decide on the above points",79,45
6,2017-1-4,2017,1,4,13,5lx588,NPainter AI-Artistic patterns using recurrent neural network,https://www.reddit.com/r/deeplearning/comments/5lx588/npainter_aiartistic_patterns_using_recurrent/,simpleuserhere,1483505798,,2,2
7,2017-1-4,2017,1,4,22,5lz3j1,Review: Caffe deep learning conquers image classification,https://www.reddit.com/r/deeplearning/comments/5lz3j1/review_caffe_deep_learning_conquers_image/,dannyeuu,1483536425,,1,1
8,2017-1-5,2017,1,5,2,5m0gbf,Quick Rundown: Generative Adversarial Nets,https://www.reddit.com/r/deeplearning/comments/5m0gbf/quick_rundown_generative_adversarial_nets/,amplifier_khan,1483551112,,0,2
9,2017-1-5,2017,1,5,11,5m3nxp,NPainter- AI powered Wallpaper generator,https://www.reddit.com/r/deeplearning/comments/5m3nxp/npainter_ai_powered_wallpaper_generator/,simpleuserhere,1483583381,,0,3
10,2017-1-5,2017,1,5,13,5m4ebc,A neural turing machine built from scratch on numpy,https://www.reddit.com/r/deeplearning/comments/5m4ebc/a_neural_turing_machine_built_from_scratch_on/,thtrieu,1483591965,,2,4
11,2017-1-5,2017,1,5,23,5m6r2g,Can Deep Learning be used for discovering new classes from the training data ?,https://www.reddit.com/r/deeplearning/comments/5m6r2g/can_deep_learning_be_used_for_discovering_new/,thak123,1483627583,More likely to prevent semantic drift in a supervised corpus where number of classes decided initially may not be the only classes the data actually takes,1,1
12,2017-1-6,2017,1,6,1,5m7hfk,TFLearn beginner question,https://www.reddit.com/r/deeplearning/comments/5m7hfk/tflearn_beginner_question/,[deleted],1483635189,[deleted],0,1
13,2017-1-6,2017,1,6,16,5mc7s6,Performance Difference between NVIDIA K80 and GTX 1080,https://www.reddit.com/r/deeplearning/comments/5mc7s6/performance_difference_between_nvidia_k80_and_gtx/,nyxynyx,1483686294,"For training deep learning models in general, what is the difference in performance (Speed) between NVIDIA K80 and NVIDIA GTX 1080? How much faster is the 1080?

Looking at the specs, K80 has

* CUDA Cores: 2880
* Core clock: 562MHz (875 MHz boost)
* Mem clock: 5 GHz GDDR5
* Mem bus: 2 x 384 bit
* Mem bandwidth: 240.6 GB/s x2
* VRAM: 2 x 12GB
* Single Precision: 8.74 TFLOPS
* TDP: 300W
* Process: TSMC 28nm

GTX 1080 has

* CUDA Cores: 2560
* Core Clock: 1607MHz (1733 MHz boost)
* Mem clock: 10 GHz
* Mem bus: 256 bit
* Mem bandwidth: 320 GB/sec
* VRAM: 8GB GDDR5X
* TDP: 180W
* Process: TSMC 16nm

",4,3
14,2017-1-7,2017,1,7,10,5mhpid,Deep Learning in Action,https://www.reddit.com/r/deeplearning/comments/5mhpid/deep_learning_in_action/,psangrene,1483753148,,0,4
15,2017-1-8,2017,1,8,1,5mle9x,Max Image Resolution of CNN using GTX 1080,https://www.reddit.com/r/deeplearning/comments/5mle9x/max_image_resolution_of_cnn_using_gtx_1080/,nyxynyx,1483808211,"When using a GTX 1080, is there a limit to the resolution of the images that we can use to train the neural network?",3,1
16,2017-1-8,2017,1,8,9,5mnsj9,Deep learning in virtual reality?,https://www.reddit.com/r/deeplearning/comments/5mnsj9/deep_learning_in_virtual_reality/,Tumml3r,1483834023,"Anyone interested in chatting about deep learning applications related to VR? Are there any good resources on this?

I'm trying to determine the feasibility of using deep learning in a VR app I'm building.",5,2
17,2017-1-8,2017,1,8,15,5mpi17,[Personal Study Journal] A Theory Explains Deep Learning - Deduction Theory blog,https://www.reddit.com/r/deeplearning/comments/5mpi17/personal_study_journal_a_theory_explains_deep/,kifhan,1483856124,,0,0
18,2017-1-8,2017,1,8,19,5mq924,Top Machine learning Books,https://www.reddit.com/r/deeplearning/comments/5mq924/top_machine_learning_books/,WTSxDev,1483870859,,0,13
19,2017-1-9,2017,1,9,20,5mx77g,"AI, Machine Learning, Deep Learning  Getting Started",https://www.reddit.com/r/deeplearning/comments/5mx77g/ai_machine_learning_deep_learning_getting_started/,tatvamasi1,1483961848,,0,4
20,2017-1-9,2017,1,9,21,5mxdkv,"AI, deep-learning company specialised in image recognition - looking for a Lead DevOps to join the team.",https://www.reddit.com/r/deeplearning/comments/5mxdkv/ai_deeplearning_company_specialised_in_image/,42math,1483964785,The job is based in Paris. 6 months minimum. Message us here.,0,1
21,2017-1-9,2017,1,9,21,5mxfmr,Computer Vision News of January 2017 - both formats (magazine and PDF),https://www.reddit.com/r/deeplearning/comments/5mxfmr/computer_vision_news_of_january_2017_both_formats/,Gletta,1483965644,"Hi.
New issue of Computer Vision News - 40 pages, great content. Free subscription at page 38.
This is the magazine version (recommended): http://www.rsipvision.com/ComputerVisionNews-2017January/
This is the PDF version: http://www.rsipvision.com/ComputerVisionNews-2017January/files/assets/common/downloads/publication.pdf
Enjoy!",0,1
22,2017-1-10,2017,1,10,4,5mzwez,What exactly is truncated backpropagation through time algorithm?,https://www.reddit.com/r/deeplearning/comments/5mzwez/what_exactly_is_truncated_backpropagation_through/,pikachuchameleon,1483991679,I am following this blog  https://medium.com/@jianqiangma/all-about-recurrent-neural-networks-9e5ae2936f6e#.ahr6o2n43 to understand the backpropagation through time algorithm in recurrent neural networks and now I am confident that what exactly it is. But I do not understand this truncated BPTT algorithm that I keep seeing in a lot of blogs. Can anyone explain in simple terms keeping the above frame work in mind (in some mathematical terms like the gradients explained in the blog I mean) what exactly it is?,2,1
23,2017-1-10,2017,1,10,6,5n0ew0,Keep up with the 2017 data trends,https://www.reddit.com/r/deeplearning/comments/5n0ew0/keep_up_with_the_2017_data_trends/,asenaatilla,1483996478,,1,0
24,2017-1-10,2017,1,10,21,5n4nsv,Deep Learning (book) is on sale at the moment for $72.00 (-10%),https://www.reddit.com/r/deeplearning/comments/5n4nsv/deep_learning_book_is_on_sale_at_the_moment_for/,nosucejs,1484049873,,0,0
25,2017-1-10,2017,1,10,23,5n566h,Indice link between Pooling layer and Upsampling layer with Keras,https://www.reddit.com/r/deeplearning/comments/5n566h/indice_link_between_pooling_layer_and_upsampling/,borbag,1484056810,"Hello DeepLearning folks!
I'm using the segnet implementation found in [this blog post](http://pradyu1993.github.io/2016/03/08/segnet-post.html) and I have the following questions:

Can you please explain how the indices based unpooling layer work. Does it take the indicies from the maxpool layer of the corresponding encoder and then unpool with indicies of the corresponding decode layer? It is stated multiple times in the segnet paper that they stored the index of the max during the pooling phase to use it during the umpsamplig phase. I see none of it here, is it done automatically by keras / tensorflow / theano?

Or is the implementation not reproducing the paper description?

Also, I've seen in the keras documentation that the class weights must be a dictionary and here it's a list. Is it an undocumented use that will works or will it be ignored by keras?",3,1
26,2017-1-12,2017,1,12,3,5ndv0f,Convolutional Neural Network based regression approach for estimation of machinery's remaining useful life,https://www.reddit.com/r/deeplearning/comments/5ndv0f/convolutional_neural_network_based_regression/,a_endurance,1484159455,,0,1
27,2017-1-12,2017,1,12,6,5nf1sr,Pretrained self-driving car models that run in GTAV / Universe [Tensorflow][Caffe],https://www.reddit.com/r/deeplearning/comments/5nf1sr/pretrained_selfdriving_car_models_that_run_in/,AmineHorseman,1484170937,,2,9
28,2017-1-12,2017,1,12,13,5nh7kx,15 Deep Learning Libraries,https://www.reddit.com/r/deeplearning/comments/5nh7kx/15_deep_learning_libraries/,psangrene,1484194309,,1,0
29,2017-1-13,2017,1,13,6,5nm7ec,"Training a neural network to map from x,y of an images pixels to r,g,b.",https://www.reddit.com/r/deeplearning/comments/5nm7ec/training_a_neural_network_to_map_from_xy_of_an/,green349,1484256977,,0,3
30,2017-1-13,2017,1,13,11,5nnwry,Yet another neural network toolbox. - A personal CNN toolbox project.,https://www.reddit.com/r/deeplearning/comments/5nnwry/yet_another_neural_network_toolbox_a_personal_cnn/,procarastinizer,1484274960,,2,1
31,2017-1-13,2017,1,13,23,5nqtxp,Computer Chips Evolve to Keep Up With Deep Learning,https://www.reddit.com/r/deeplearning/comments/5nqtxp/computer_chips_evolve_to_keep_up_with_deep/,nikitaljohnson,1484317039,,0,0
32,2017-1-14,2017,1,14,0,5nr635,Why go long on artificial intelligence?,https://www.reddit.com/r/deeplearning/comments/5nr635/why_go_long_on_artificial_intelligence/,nikitaljohnson,1484320874,,0,2
33,2017-1-15,2017,1,15,6,5nzter,Question about normalization in a simple autoencoder,https://www.reddit.com/r/deeplearning/comments/5nzter/question_about_normalization_in_a_simple/,jiminiminimini,1484428313,"I have a dataset with mean=0, std=1.3, range = [-74, 74]. My activation function is tanh for all layers, linear for output layer. Cost function is mean squared difference. 


The thing is, if I normalize my data, either by dividing it by std or simply scaling it to [-1, 1], or to [0, 1] - (in which case I change the activation function to sigmoid) cost gets very small right at the beginning (~= 0.005) but the network is unable to learn anything meaningful. If I don't normalize the data costs starts at around 3.0, quickly gets down to 1.15 and the network actually learns some useful features.


What am I doing wrong? Is it my cost function, normalization method or is it just that this dataset shouldn't be normalized for some reason?",7,1
34,2017-1-15,2017,1,15,9,5o0zxz,[Hardware] A Workstation for deep learning,https://www.reddit.com/r/deeplearning/comments/5o0zxz/hardware_a_workstation_for_deep_learning/,dd_2_dd,1484441332,"We are going to build our workstation, and we would like to know what do you think about the configuration we thought.
The workstation is mainly for deep learning and optimisation problems. The idea is to start with just one *Titan x Pascal*
but we want to have a machine ready to scale to up to four *Titan X* cards (even though we will probably arrive up to 3).

| desc | model |
|--------------|----------------------------------------------|
| motherboard | Asus Z10PE-D8 WS |
| gpu | Titan X pascal |
| ram | 4 x 32 GB RDIMM DDR4 (PC4-19200) |
| HD | Samsung 850 EVO SSD da 1 TB |
| HD | SATA 6T |
| cooler | 2x Noctua NH-U12DX i4 |
| case | Corsair Obsidian Series 750D Airflow Edition |
| cpu | 2 x Xeon E5 2630 v4 |
| power supply | EVGA SuperNOVA 1600 P2 |

We want a configuration with two CPUs for scientific calculations; the CPU is chosen because it seems to have the best (cores*frequency)/price ratio.

What bothers us the most is the **motherboard**: `Asus Z10PE-D8 WS` seems [to have had troubles](http://news.softpedia.com/news/The-Problems-With-ASUS-Z10PE-D8-WS-Dual-Socket-Motherboard-459168.shtml), or `Asus Z10PE-D16 W`. 
Another issue mentioned in http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/
is about the importance of the CACHE size for CPU and GPU clock speed. 
Is 2.2 GHz enough, given the plots in the article?

So, what do you think? Is it a good configuration? 
**Does it make the most of our `Titan X Pascal` cards?** 
Or can it be improved? (the current configuration should cost around 5000$, in principle, we can spend also a bit more, but this was the best power/price conf we managed to do) 

**EDIT:**
So, thank to your comments and other info gathered here and there, we changed some components, the machine is now  more expensive: 

| desc | model |
|-----------------|----------------------------------------------|
| motherboard | Asus Z10PE-D8 WS |
| gpu         |**2x Titan X pascal** |
| ram | **8 x 32 GB RDIMM DDR4 (PC4-19200) * *|
| HD | **Samsung 960 pro M.2 SSD 512 GB** |
| HD | **Samsung 850 pro 1TB** |
| HD | SATA 6T |
| cooler | 2x Noctua NH-U12DX i4 |
| case | Corsair Obsidian Series 750D Airflow Edition |
| cpu | 2 x **Xeon E5 2687W v4** |
| power supply | EVGA SuperNOVA 1600 P2 |

We decided to go as soon as possible for 2x titan X. Following a suggestion, we choose to occupy all the channels  available for the ram for each CPU, so we occupied all the 8 slots. We moved to 960PRO SSD, but only one for slot space reasons. We also decided to pump the CPUs.
We are still wondering if a liquid cooling system is too dangerous for this machine.",11,2
35,2017-1-15,2017,1,15,19,5o3bfy,"Recognizing Traffic Lights With Deep Learning (and winning $5,000)",https://www.reddit.com/r/deeplearning/comments/5o3bfy/recognizing_traffic_lights_with_deep_learning_and/,davidbrai,1484476158,,5,15
36,2017-1-16,2017,1,16,5,5o69h8,List of tools and resources related to the use of machine learning for cyber security,https://www.reddit.com/r/deeplearning/comments/5o69h8/list_of_tools_and_resources_related_to_the_use_of/,WTSxDev,1484512976,,0,5
37,2017-1-16,2017,1,16,7,5o6zl8,NVIDIA DIGITS Assists Alzheimers Disease Prediction,https://www.reddit.com/r/deeplearning/comments/5o6zl8/nvidia_digits_assists_alzheimers_disease/,harrism,1484520419,,0,6
38,2017-1-16,2017,1,16,9,5o7jlc,What Do you all think about the content in this new Deep Learning Foundations Program from Udacity? Is it worth $400?,https://www.reddit.com/r/deeplearning/comments/5o7jlc/what_do_you_all_think_about_the_content_in_this/,DIYjackass,1484526382,,15,10
39,2017-1-16,2017,1,16,14,5o9277,Building a Deep Learning Model for Process Optimisation,https://www.reddit.com/r/deeplearning/comments/5o9277/building_a_deep_learning_model_for_process/,psangrene,1484544842,,0,4
40,2017-1-17,2017,1,17,20,5ohhrv,Why is Address Verification Important to your Business?,https://www.reddit.com/r/deeplearning/comments/5ohhrv/why_is_address_verification_important_to_your/,asenaatilla,1484651317,,0,0
41,2017-1-17,2017,1,17,21,5ohscp,A complete and easy to follow course for understanding ANNs,https://www.reddit.com/r/deeplearning/comments/5ohscp/a_complete_and_easy_to_follow_course_for/,jiminiminimini,1484656148,,0,3
42,2017-1-18,2017,1,18,19,5oonse,Hey reddit. I need help my assignment about neural networks.,https://www.reddit.com/r/deeplearning/comments/5oonse/hey_reddit_i_need_help_my_assignment_about_neural/,E1mst3d,1484735820,"My friends and I are working on a school project about artificial intelligence. We are kinda stuck on ""how to describe"" neural networks for other people. So can you guys please help us with how the different parts work in a neural network. We are most curious about the nodes. We can't find much information about it. So it would be really nice if you would take a minute or two to explain it for us.

Sorry if my grammar is a bit rusty.

Thanks a lot!",1,0
43,2017-1-18,2017,1,18,20,5ootrc,"[Q] Playing around with parameters improves error on test set, but difference between train- and test-set errors increases. Is this bad?",https://www.reddit.com/r/deeplearning/comments/5ootrc/q_playing_around_with_parameters_improves_error/,Awesome_Incarnate,1484738599,"Hi,

I am using a fully connected feed forward classification network in CNTK with 39 inputs, 3 hidden layers with dimensions 1000,750,500 and 7 outputs.

My training set has 180k samples and testing has 60k samples.

Playing around with epochs and minibatch sizes I am able to reduce  my overall test error rate, but the difference between training error rate and testing error rate increases.

For example:

Configuration 1: Train-error = 47%  ;  Test-Error 48%

Configuration 2: Train-error = 44%  ;  Test-Error 46%

Configuration 3: Train-error = 40%  ;  Test-Error 44%

Configuration 4: Train-error = 35%  ;  Test-Error 42%



etc. (Note: this is excellent results for what I am trying to accomplish, post processing results in almost 90% success rate in application)

As you can see, the 2 errors diverge while the error on the test set gets better.

Is this the result of overfitting? Is this something I have to worry about? Any recommendations? 



EDIT: Seems a simple [Wikipedia Graph](https://en.wikipedia.org/wiki/File:Overfitting_svg.svg) gave me an answer. Doh. As long as the validation error doesn't start going up again, it seems ok that the training error decreases faster than the testing error.",2,1
44,2017-1-19,2017,1,19,14,5ouvsu,multiple gpu performance w/ Keras and/or Tensorflow,https://www.reddit.com/r/deeplearning/comments/5ouvsu/multiple_gpu_performance_w_keras_andor_tensorflow/,Saxi,1484804753,"Anyone using multiple GPU with Keras &amp; Tensorflow?

Does performance scale 100% per GPU or is there a loss? (As far as I understand it, you have to assign each GPU to each piece, so I assume there is some loss if you don't split it perfectly, but also wondering if it will use them both 100% for what they are assigned.  I suspect a single GPU will always be preferred if it is big enough).

How much more work do you have to do to code a model to utilize multiple GPUs?

Do they need to be the same GPU?  

How parallel can you do it, like can you have one epoch on one and other on another, and have it combine the results?  I suspect not as probably have to happen one after another.  What can be done in parallel?",2,7
45,2017-1-19,2017,1,19,22,5owiuc,Help on neural tensor network with relation embedding,https://www.reddit.com/r/deeplearning/comments/5owiuc/help_on_neural_tensor_network_with_relation/,davido1221,1484832160,"Hello I have  A question , I have read the paper on neural tensor network (Reasoning With Neural Tensor Networks
for Knowledge Base Completion) ,but it describes how to classify them , is there an approach on embedding them similar to word2vec?",0,1
46,2017-1-21,2017,1,21,5,5p6ahs,NVidia released a deep reinforcement learning library,https://www.reddit.com/r/deeplearning/comments/5p6ahs/nvidia_released_a_deep_reinforcement_learning/,sangihi,1484943104,,3,11
47,2017-1-22,2017,1,22,7,5pd7hq,I want to code a policy gradients algorithm from scratch. Am I crazy?,https://www.reddit.com/r/deeplearning/comments/5pd7hq/i_want_to_code_a_policy_gradients_algorithm_from/,charl3sworth,1485036116,"Hello all,

I am a final year undergrad student. For my final project (worth 50% of the year) I am doing some sort of deep learning. I want to use it for playing 2 player turn based games and ideally want to code it from scratch. 

However, in doing some reading on the subject I am finding it hard to clearly understand how it works which is is part because often they seem to be applied to single player games such as Pong.

As a dry run for my actual project code (which is in c#) I was going to code an algorithm to learn Tic Tac Toe in Python (because it is easy to read). However, I am having a hard understanding exactly what the steps of the algorithm are.

Does anyone have any links to pseudo-code or worked examples for simple adversarial games such as Tic Tak Toe?

Thanks :)",1,1
48,2017-1-22,2017,1,22,19,5pgatc,Should I reimplement existing projects?,https://www.reddit.com/r/deeplearning/comments/5pgatc/should_i_reimplement_existing_projects/,__The_Coder__,1485080300,"Andrej Karpathy had mentioned that he reimplemented a lot of projects to learn about concepts. 

So, recently, I was watching videos about object recognition using deep learning and want to implement it on my own. But whenever I think of doing something like this, I feel that all I'll be doing is reading 2-3 codes and combine them. 

Can I be proud of such a project? Can I mention it on resumes, given that tons of other people have done the same thing. Because even this will take me 2-3 months and I need to be doing something at least. And I'm not that intelligent to do it on my own without reading existing codes. 

I need your advise regarding this.

",4,5
49,2017-1-23,2017,1,23,11,5plrdx,Classifying e-commerce products based on images and text,https://www.reddit.com/r/deeplearning/comments/5plrdx/classifying_ecommerce_products_based_on_images/,mwakanosya,1485140025,,0,2
50,2017-1-24,2017,1,24,3,5pqkkc,Deep learning with video data?,https://www.reddit.com/r/deeplearning/comments/5pqkkc/deep_learning_with_video_data/,cctap,1485195751,Does anyone know of any papers or resources that use video data as input data to a convolutional neural network?,4,6
51,2017-1-25,2017,1,25,4,5py529,Train a net...But where?,https://www.reddit.com/r/deeplearning/comments/5py529/train_a_netbut_where/,gabegabe6,1485285913,"Hi!

I would like to train my models created with Keras, Tensorflow, etc... but I can not do it on my Laptop because I have Windows and I do not have a strong GPU.

I know there is AWS but unfortunately I do not have an accepted credit card (I own a card called *Maestro*) so I can not register to AWS.

Where can I find other sites which provides (for a ""cheap"" price) GPU where I can train my models and I can pay with paypal?",6,2
52,2017-1-25,2017,1,25,14,5q1iv5,Inception and OCR,https://www.reddit.com/r/deeplearning/comments/5q1iv5/inception_and_ocr/,vrbala,1485322919,"Hello all, I am trying my hands on an OCR project. I have this idea of casting OCR as caption generation problem and wanted to use inception v3 as feature extractor with RNN head (similar to show and tell architecture). Currently, from SVHN dataset, I have extracted bottleneck tensors of inception and fed them to RNN after embedding to suitable size. The result is I get overfitting on training data i.e. training sequences are generated perfectly but the test results are bad indicating the network failing to generalise.

I am wondering if it is bad to cast OCR as caption generation problem, and if the results I see in training is just the network memorizing stuff during training. I would like to have your opinion on this. Thanks a lot in advance.",3,3
53,2017-1-27,2017,1,27,5,5qcpkf,Use your eyes and Deep Learning to command your computer,https://www.reddit.com/r/deeplearning/comments/5qcpkf/use_your_eyes_and_deep_learning_to_command_your/,Totoketchup,1485463557,,0,5
54,2017-1-27,2017,1,27,11,5qeih3,Ethics and Artificial Intelligence: The Moral Compass of a Machine,https://www.reddit.com/r/deeplearning/comments/5qeih3/ethics_and_artificial_intelligence_the_moral/,chipbag01,1485482773,,0,0
55,2017-1-28,2017,1,28,13,5qltxj,[Project] Clickbait detection using Deep Learning (Github); X-post from /r/MachineLearning,https://www.reddit.com/r/deeplearning/comments/5qltxj/project_clickbait_detection_using_deep_learning/,saurabhmathur96,1485577173,,1,6
56,2017-1-29,2017,1,29,2,5qot1p,Rust binding for OpenAI Gym,https://www.reddit.com/r/deeplearning/comments/5qot1p/rust_binding_for_openai_gym/,andrew-lucker,1485625805,,0,2
57,2017-1-29,2017,1,29,5,5qpkkl,Interesting introduction to deep learning for coders,https://www.reddit.com/r/deeplearning/comments/5qpkkl/interesting_introduction_to_deep_learning_for/,danyblue,1485633962,,1,3
58,2017-1-29,2017,1,29,17,5qsxuk,Data augmentation in the correct way,https://www.reddit.com/r/deeplearning/comments/5qsxuk/data_augmentation_in_the_correct_way/,gabegabe6,1485679556,"Let's expect that I have a dataset which contains 30.000 images about logos. 80% (24.000) for training and 20% (6.000) for testing.

I would like to enrich the data.

Which is the correct way?

1. Augment all the images when we preprocess them and save to a numpy array.

2. Augment the images when we fit the data to the network with a generator.

Or what do you think which is the most efficient?",6,3
59,2017-1-30,2017,1,30,10,5qxr2g,ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation,https://www.reddit.com/r/deeplearning/comments/5qxr2g/enet_a_deep_neural_network_architecture_for/,PullThisFinger,1485740245,,1,2
60,2017-1-31,2017,1,31,11,5r5fhh,Can I use CNNs for blob detection in noisy images?,https://www.reddit.com/r/deeplearning/comments/5r5fhh/can_i_use_cnns_for_blob_detection_in_noisy_images/,HV250,1485829730,"Hello all,  

I am currently working on a dataset of images from an X ray imager that contain very faint blobs that need detection. Initially I tried using computer vision techniques but realized that there is way too much parameter tuning required for it to work reliably, and I have gotten some suggestions that deep learning techniques such as convolutional neural networks would have better luck with images like this. I was wondering if someone here could comment on that and possibly suggest some good software packages/algorithms to start off with. I've looked at some implementations in Nvidia DIGITS and in MATLAB, but it looks like most of those use pretrained models and extensive datasets that focus on real world objects, so I don't know if those would be applicable for my data.   

Here is a link to some of my images: in every image, there are four faint but dark blobs approximately around the center of the image. Any thoughts on the effectiveness of CNNs/other learning techniques for images like this are welcome. The way I was thinking it would work was to train a network by providing a 'label' set of the blobs with bounding boxes for instance: but I suspect this approach would need training with a LOT of images?  

http://imgur.com/a/OLEzE  
http://i.imgur.com/QeVyPiE.png  

Thank you!  
",2,2
61,2017-1-31,2017,1,31,23,5r8c89,Behaviour: from intervention to diagnosis,https://www.reddit.com/r/deeplearning/comments/5r8c89/behaviour_from_intervention_to_diagnosis/,ReworkCharlotte,1485871232,,0,0
0,2017-2-1,2017,2,1,13,5rddha,Noob questions - DL recommendations,https://www.reddit.com/r/deeplearning/comments/5rddha/noob_questions_dl_recommendations/,noisyfart,1485922238,"Hey guys,

I'm new to Reddit and relatively new to the whole ML/DL field (although I've played with some genetic algorithms in the past), and I was wondering if you could guide me through the tons of info available in the net.

I want to learn about DL and whatnot and I thought of giving you some background. Long term, I'd like to implement an NN that's pretty visual: maybe it can detect the predominant colour(s) of an image, whether you see animals or objects (and which ones ideally), detect text, etc. Probably a long shot, but I want to write an app that is continuously using the camera and giving you some extra metadata (and maybe feeding stuff to your HoloLens or something like that).

I was browsing and there's so many options. Do you recommend offline or cloud-based solutions? If offline, which one? Keras on top of TensorFlow/Theano? Any other alternative? If it's only, do you recommend Google, CNTK, etc?

Thanks!",6,4
1,2017-2-1,2017,2,1,20,5rf1a6,NeuroEvolution on Autonomous Car Pathing,https://www.reddit.com/r/deeplearning/comments/5rf1a6/neuroevolution_on_autonomous_car_pathing/,Digital10,1485949872,,0,3
2,2017-2-3,2017,2,3,2,5roaw1,Increasing Performance using Multi-Layer LSTM,https://www.reddit.com/r/deeplearning/comments/5roaw1/increasing_performance_using_multilayer_lstm/,mjfnd,1486058219,,0,1
3,2017-2-4,2017,2,4,0,5rughp,"Learn TensorFlow and deep learning, without a Ph.D. by Google Cloud Team",https://www.reddit.com/r/deeplearning/comments/5rughp/learn_tensorflow_and_deep_learning_without_a_phd/,[deleted],1486135060,[deleted],0,1
4,2017-2-4,2017,2,4,14,5rz3px,"Deep Learning community with articles on intuition for concepts, research paper summaries and study groups",https://www.reddit.com/r/deeplearning/comments/5rz3px/deep_learning_community_with_articles_on/,keshav57,1486187775,,1,6
5,2017-2-5,2017,2,5,2,5s1yjk,Training a chatbot on non-conversational text?,https://www.reddit.com/r/deeplearning/comments/5s1yjk/training_a_chatbot_on_nonconversational_text/,USAFairyPrincess,1486230957,"Hey all, this is something I've been thinking a lot of lately but I haven't really been able to find anything on the web about it, and my understanding of ML is still too limited for me to really produce anything original at the moment. That being said, I've had this idea.

I've seen videos of people creating chatbots with TensorFlow and other ML libraries, but they always need a training dataset that is conversational dialogue, a back and forth between two people. What I'm wondering, is if it is currently possible for us to create a chatbot that was trained off non-conversational text, such as a monologue, and then emulate the speech patterns of the author. This has come to my mind because I am 18 years old and started keeping a journal on May 5, 2008, and have 9 years of my detailed thoughts and experiences written down, with almost all of it now typed into a digital document. I want to train a chatbot off my journal to create, essentially, a little virtual me.

Thoughts?",12,4
6,2017-2-6,2017,2,6,15,5scrzz,15 Deep Learning Tutorials,https://www.reddit.com/r/deeplearning/comments/5scrzz/15_deep_learning_tutorials/,psangrene,1486363756,,0,8
7,2017-2-6,2017,2,6,23,5sefnl,Singular-Vision blog by BJ Dooley-- Deep Learning in Finance: The Video,https://www.reddit.com/r/deeplearning/comments/5sefnl/singularvision_blog_by_bj_dooley_deep_learning_in/,bjdooley,1486390304,,0,1
8,2017-2-7,2017,2,7,0,5seyfn,Deep Q Learning with Keras and Gym,https://www.reddit.com/r/deeplearning/comments/5seyfn/deep_q_learning_with_keras_and_gym/,kwk236,1486396248,,0,3
9,2017-2-7,2017,2,7,2,5sfjh9,"SimGANs - A Game Changer in Unsupervised Learning, Self Driving Cars, and More  Intuition Machine",https://www.reddit.com/r/deeplearning/comments/5sfjh9/simgans_a_game_changer_in_unsupervised_learning/,wayaai,1486401989,,0,5
10,2017-2-7,2017,2,7,12,5sj5y8,On the intuition behind deep learning and GANs  towards a fundamental understanding,https://www.reddit.com/r/deeplearning/comments/5sj5y8/on_the_intuition_behind_deep_learning_and_gans/,wayaai,1486439517,,0,5
11,2017-2-7,2017,2,7,18,5sken8,Oxford Deep NLP 2017 course with videos and Practicals,https://www.reddit.com/r/deeplearning/comments/5sken8/oxford_deep_nlp_2017_course_with_videos_and/,Digital10,1486458774,,1,11
12,2017-2-7,2017,2,7,21,5sl2e0,"Deep Learning &amp; Parameter Tuning with MXnet, H2o Package in R",https://www.reddit.com/r/deeplearning/comments/5sl2e0/deep_learning_parameter_tuning_with_mxnet_h2o/,NarendhiranS,1486469767,,0,2
13,2017-2-8,2017,2,8,0,5sm3zp,"Announcing AI With The Best online conference with Yoshua, Geoffrey and Ian Goodfellow in April",https://www.reddit.com/r/deeplearning/comments/5sm3zp/announcing_ai_with_the_best_online_conference/,MariaWTB,1486482548,,4,1
14,2017-2-8,2017,2,8,3,5sn49q,Anonymizing documents with Word Vectors and O(n) models,https://www.reddit.com/r/deeplearning/comments/5sn49q/anonymizing_documents_with_word_vectors_and_on/,mwakanosya,1486492133,,0,2
15,2017-2-8,2017,2,8,14,5squ9d,10 Deep Learning Terms Explained in Simple English,https://www.reddit.com/r/deeplearning/comments/5squ9d/10_deep_learning_terms_explained_in_simple_english/,psangrene,1486531222,,0,16
16,2017-2-8,2017,2,8,20,5ss7i4,What is the Relation Between Internet of Things and Data Visualization?,https://www.reddit.com/r/deeplearning/comments/5ss7i4/what_is_the_relation_between_internet_of_things/,cagataydemir,1486553656,,0,0
17,2017-2-9,2017,2,9,11,5sxe6m,A Comprehensive Introduction to Word Vector Representations,https://www.reddit.com/r/deeplearning/comments/5sxe6m/a_comprehensive_introduction_to_word_vector/,baristaGeek,1486607966,,0,1
18,2017-2-9,2017,2,9,21,5szqgz,Understanding Agent Cooperation | DeepMind,https://www.reddit.com/r/deeplearning/comments/5szqgz/understanding_agent_cooperation_deepmind/,[deleted],1486643652,[deleted],0,2
19,2017-2-10,2017,2,10,2,5t1kty,Build a fast deep learning machine for under $1K (hackernews discussion),https://www.reddit.com/r/deeplearning/comments/5t1kty/build_a_fast_deep_learning_machine_for_under_1k/,eleitl,1486662829,,0,6
20,2017-2-10,2017,2,10,16,5t5zdp,"13 Free Self-Study Books on Mathematics, Machine Learning &amp; Deep Learning",https://www.reddit.com/r/deeplearning/comments/5t5zdp/13_free_selfstudy_books_on_mathematics_machine/,NarendhiranS,1486712064,,1,8
21,2017-2-10,2017,2,10,21,5t6wqx,Evolution of Location Intelligence Tools,https://www.reddit.com/r/deeplearning/comments/5t6wqx/evolution_of_location_intelligence_tools/,cagataydemir,1486728306,,0,1
22,2017-2-10,2017,2,10,22,5t7bqz,"Which kind of network parameters do I need for document (black/white, high contrast, sparse) classification?",https://www.reddit.com/r/deeplearning/comments/5t7bqz/which_kind_of_network_parameters_do_i_need_for/,eleitl,1486734263,"I'm thinking about using deep learning to be able to relatively rapidly classify pages of documents -- all black/white or greyscale but with rather hard contrasts -- on presence or absence of certain graphs (molecular structures). I have a nice data set to train for that.

Question: are e.g. deep convoluted networks at all suitable for such input? There are no nice smooth gradients, only black/white or otherwise solid color angular lines. Example: https://upload.wikimedia.org/wikipedia/commons/9/90/Mitragynine2DACS.svg

The structures like above are *typically* not filling the full page. There might be several of such present on a single page. They are typically much larger than text characters but reasonably stereotypical. They have recurring subfeatures. They are typically not hand-drawn, so have little variance in terms of jitter, though of course bad scans can add artifacts.

So how large should I make my input tile? 

Should I reduce the resolution of the input image, or will I be able to handle e.g. 300 ppi images as is?

How do I know how many intermediate layers are enough? 

By trial and error?

Thanks.




",0,3
23,2017-2-11,2017,2,11,0,5t7slh,How to use Webhose.io rated reviews for sentiment classification,https://www.reddit.com/r/deeplearning/comments/5t7slh/how_to_use_webhoseio_rated_reviews_for_sentiment/,rangeva,1486739630,,0,1
24,2017-2-11,2017,2,11,0,5t7um0,Deep Learning for NLP at Oxford with Deep Mind 2017,https://www.reddit.com/r/deeplearning/comments/5t7um0/deep_learning_for_nlp_at_oxford_with_deep_mind/,zafmahmood,1486740219,,0,4
25,2017-2-11,2017,2,11,5,5t9or5,Ubuntu Deep Learning AWS AMI,https://www.reddit.com/r/deeplearning/comments/5t9or5/ubuntu_deep_learning_aws_ami/,Data-Daddy,1486758295,,3,3
26,2017-2-11,2017,2,11,11,5tbljb,[X-post from /r/machinelearning] An Idea on Machine Ethics,https://www.reddit.com/r/deeplearning/comments/5tbljb/xpost_from_rmachinelearning_an_idea_on_machine/,chipbag01,1486779387,"Disclaimer: Im not an AI researcher, just someone interested in the field.

Ive had an idea about how to align intelligent AI programs goals with our human goals:

The problem is simple: Say you have some sort of software AI agent. The agent has a goal (or goals) mandated by its creator(s), and makes decisions on actions to take that would further the goal(s). Whether or not it can carry out those actions *immediately* or *directly* is irrelevant; for now, were focusing on the agents decisions, since its actions result from them. How do the creators capture the nuance and conditions of their goals, and communicate it to the agent effectively?

My idea: dont give the agent discrete goals at all, at least initially. Instead, give it a network of weighted values to *guide* its decisions.

An example implementation could be created as follows:
1. Download a copy of [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download#Where_do_I_get_it.3F), in its entirety.
2. Find an article on something you like, or value highly (in my case, [fun](https://en.wikipedia.org/wiki/Fun)).
3. Apply a numerical value to the article. The value should correspond, as best as you can make it, to the ethical value you actually apply to what is described in the article. For example, I could value fun at 9.5/10. This tells the agent that, when it makes decisions, it should try to promote/encourage/further/increase the thing with a high value. This works in reverse, too: a low value (e.g., 2/10) would tell the agent to prevent/discourage/stop/decrease/eliminate the thing at hand.

NOTE: The scale doesnt really matter here; it could go from -10 to 10, -1 to 1, 0 to 10, 0 to 1, whatever works best for your particular setup. Im using 0 
to 10 in my example because its familiar (e.g., movie ratings).

4. Repeat steps 2-3 for multiple articles about things you find important to rate for the AI. All of these values are your specified values, and they cannot/should not be changed by the agent, at ***least*** not without user permission.
5. Specify to the agent that you are, in fact, done inputting specified values.
6. The AI agent analyzes the language used in all the articles in the database, paying special attention to links to other articles and the context of those links. It then uses these to calculate generated values, which have the same function as specified values ***except that*** the agent can change them whenever the user changes one or more specified values. This is similar to how Googles [PageRank](https://en.wikipedia.org/wiki/PageRank#Description) system works, at the base level.

Is this a thing out there? I found [this on MIRIs website](https://intelligence.org/research-guide/#eight), and [this article has the same idea](http://www.recode.net/2016/4/13/11644890/ethics-and-artificial-intelligence-the-moral-compass-of-a-machine), but I dont know of any implementations of it. Other than that, Ive found nothing quite like it.

Thoughts?",3,2
27,2017-2-12,2017,2,12,2,5tgac6,Multiple Different Natural Language Processing Tasks in a Single Deep Model,https://www.reddit.com/r/deeplearning/comments/5tgac6/multiple_different_natural_language_processing/,rajarsheem,1486834987,,0,4
28,2017-2-12,2017,2,12,22,5tlhcq,"Autoencoders  Deep Learning bits #1 data compression, image reconstruction and segmentation (with examples!)",https://www.reddit.com/r/deeplearning/comments/5tlhcq/autoencoders_deep_learning_bits_1_data/,pmz,1486907142,,0,7
29,2017-2-13,2017,2,13,0,5tlypv,"Is a GTX 295 useful for deep learning, and not just a space heater?",https://www.reddit.com/r/deeplearning/comments/5tlypv/is_a_gtx_295_useful_for_deep_learning_and_not/,eleitl,1486913808,"Is a dual-GPU with below specs of any use for deep learning? Thanks.

GPU-Prozessor:        GeForce GTX 295 (GPU 1 von 2)  
Treiberversion:        342.01  
Direct3D-API-Version:    10  
CUDA-Kerne:        240  
Kerntakt:        576 MHz  
Shadertakt:        1242 MHz  
Speicher-Datenrate:    1998 MHz  
Speicherschnittstelle:    448-Bit  
Gesamter verfgbarer Grafikspeicher:    2682 MB  
Dedizierter Videospeicher:    896 MB GDDR3  
System-Videospeicher:    0 MB  
Freigegebener Systemspeicher:    1786 MB  
Video-BIOS-Version:    62.00.45.00.02  
IRQ:            18  
Bus:            PCI Express x16  
 
GPU-Prozessor:        GeForce GTX 295 (GPU 2 von 2)  
Treiberversion:        342.01  
Direct3D-API-Version:    10  
CUDA-Kerne:        240  
Kerntakt:        576 MHz  
Shadertakt:        1242 MHz  
Speicher-Datenrate:    1998 MHz  
Speicherschnittstelle:    448-Bit  
Gesamter verfgbarer Grafikspeicher:    2682 MB  
Dedizierter Videospeicher:    896 MB GDDR3  
System-Videospeicher:    0 MB  
Freigegebener Systemspeicher:    1786 MB  
Video-BIOS-Version:    62.00.45.00.01  
IRQ:            16  
Bus:            PCI Express x16  ",2,1
30,2017-2-13,2017,2,13,6,5togrm,How to extract cnn features from small patches?,https://www.reddit.com/r/deeplearning/comments/5togrm/how_to_extract_cnn_features_from_small_patches/,mojovski,1486935630,"Can anyone advice me about feasible methods on cnn feature extraction from small patches? I would like to use something pre trained such as VGG models, which however are optimized for 256x256 only. (python or c++). Thanks in advance to everyone!",1,2
31,2017-2-13,2017,2,13,14,5tr5z0,Deep Learning for NLP at Oxford 2017 - Lecture 2a - Word Level Semantics...,https://www.reddit.com/r/deeplearning/comments/5tr5z0/deep_learning_for_nlp_at_oxford_2017_lecture_2a/,zafmahmood,1486963456,,0,1
32,2017-2-13,2017,2,13,19,5ts4tg,The risks and dangers of deep-learned biomarkers,https://www.reddit.com/r/deeplearning/comments/5ts4tg/the_risks_and_dangers_of_deeplearned_biomarkers/,nikitaljohnson,1486980787,,0,0
33,2017-2-13,2017,2,13,19,5ts8rx,Computer Vision News of February 2017 (both magazine and PDF formats),https://www.reddit.com/r/deeplearning/comments/5ts8rx/computer_vision_news_of_february_2017_both/,Gletta,1486982916,"Dear all,
here is the new issue of Computer Vision News - 36 pages with great content (and with codes). Free subscription at page 36.
This is the magazine version (recommended): http://www.rsipvision.com/ComputerVisionNews-2017February/
This is the PDF version: http://www.rsipvision.com/computervisionnews-2017february-pdf/
Enjoy!",0,2
34,2017-2-14,2017,2,14,4,5tusek,Turn your laptop into a Deep Learning BEAST,https://www.reddit.com/r/deeplearning/comments/5tusek/turn_your_laptop_into_a_deep_learning_beast/,danimex,1487012730,,10,0
35,2017-2-14,2017,2,14,6,5tvki5,Neural net with set (unordered) output instead of array,https://www.reddit.com/r/deeplearning/comments/5tvki5/neural_net_with_set_unordered_output_instead_of/,asfarley,1487020237,"I'd like to create a neural network where the output is a variable-sized, discrete set. Each element of the set is an (x,y) coordinate. 

I don't want to treat this output as an array/list because an array implies that the ordering of elements within the set is signifiant. Instead, I want to train a network where the output is considered to be correct when it contains the right elements, regardless of ordering. 

Has anyone seen something like this before? 
",8,7
36,2017-2-15,2017,2,15,0,5u0vbn,Distributed Tensorflow + Inifiband + Spark all in one System by Yahoo,https://www.reddit.com/r/deeplearning/comments/5u0vbn/distributed_tensorflow_inifiband_spark_all_in_one/,jpdowlin,1487086767,,3,5
37,2017-2-15,2017,2,15,1,5u147d,Interview With Google's Conversation Design Lead Nandini Stocker for International Women in Science Day 2017!,https://www.reddit.com/r/deeplearning/comments/5u147d/interview_with_googles_conversation_design_lead/,reworksophie,1487089211,,0,1
38,2017-2-15,2017,2,15,9,5u4adn,"I am quite proficient in R Language. In order to get the full potential of deep learning, should I learn Phython ?",https://www.reddit.com/r/deeplearning/comments/5u4adn/i_am_quite_proficient_in_r_language_in_order_to/,josenilocm,1487119575,,3,1
39,2017-2-15,2017,2,15,16,5u60bv,"[Data] Spanner, the Google Database That Mastered Time, Is Now Open to Everyone",https://www.reddit.com/r/deeplearning/comments/5u60bv/data_spanner_the_google_database_that_mastered/,NarendhiranS,1487142471,,3,7
40,2017-2-15,2017,2,15,20,5u6wlq,"Interview with the director of the new General AI Challenge, launching today, $50k prize",https://www.reddit.com/r/deeplearning/comments/5u6wlq/interview_with_the_director_of_the_new_general_ai/,reworksophie,1487159270,,0,1
41,2017-2-16,2017,2,16,16,5udeh4,FPGAs Focal Point for Efficient Neural Network Inference,https://www.reddit.com/r/deeplearning/comments/5udeh4/fpgas_focal_point_for_efficient_neural_network/,pete0273,1487229533,,0,2
42,2017-2-17,2017,2,17,16,5ukxqa,Innovation with Real-Time Data and Insights,https://www.reddit.com/r/deeplearning/comments/5ukxqa/innovation_with_realtime_data_and_insights/,cagataydemir,1487317285,,0,1
43,2017-2-17,2017,2,17,19,5ulfia,The Importance of Predictive Analytics for Your Business,https://www.reddit.com/r/deeplearning/comments/5ulfia/the_importance_of_predictive_analytics_for_your/,cagataydemir,1487326855,,0,1
44,2017-2-17,2017,2,17,20,5ulnvq,Deep Learning: A Practitioner's Approach (book) for is on sale at the moment $28.56 (-43%),https://www.reddit.com/r/deeplearning/comments/5ulnvq/deep_learning_a_practitioners_approach_book_for/,vecmilgravis,1487331381,,1,3
45,2017-2-17,2017,2,17,21,5ultep,"[Question] Is there an Atlas of deep learning models, learning algorithms, initializations, etc.",https://www.reddit.com/r/deeplearning/comments/5ultep/question_is_there_an_atlas_of_deep_learning/,jiminiminimini,1487333866,"I mean a guide that explains the relationships between current state of the art DNN models, initialization functions for different layers, training methods, data preprocessing, different normalization approaches etc. organized by properties of your dataset, the kind of task you are trying to do (such as classification, generation, prediction, sequence to sequence conversion, etc.).

I feel like I should be able to navigate the existing state of the art before trying to reinvent the wheel and fail.",4,3
46,2017-2-17,2017,2,17,22,5um4mg,Deep Learning; What are the current research issues?,https://www.reddit.com/r/deeplearning/comments/5um4mg/deep_learning_what_are_the_current_research_issues/,ebaldac,1487338494,"I would like to start researching on deep learning (I am particularly interested on designing algorithms). I am know about linear algebra, optimization, and machine learning basics, but I don't know where to look for ideas (among the huge amount of papers on deep learning). So, what are the current problems in the deep learning community?",7,3
47,2017-2-18,2017,2,18,23,5usjzy,Ground-up &amp; hands-on deep learning tutorial  diagnosing skin cancer w/ dermatologist-level,https://www.reddit.com/r/deeplearning/comments/5usjzy/groundup_handson_deep_learning_tutorial/,wayaai,1487426706,,0,3
48,2017-2-19,2017,2,19,17,5uxfsd,Deep Learning for Self-Driving Cars : Lecture 5,https://www.reddit.com/r/deeplearning/comments/5uxfsd/deep_learning_for_selfdriving_cars_lecture_5/,Mussem17,1487493992,,2,2
49,2017-2-20,2017,2,20,8,5v1a8a,Can anyone please list labs working on robotic grasp problem in vision apart from Prof. Ashutosh Saxena's lab?,https://www.reddit.com/r/deeplearning/comments/5v1a8a/can_anyone_please_list_labs_working_on_robotic/,Talos19,1487548331,"Also, if you know any latest paper on grasp problem, please mention that as well. Thank you! ",4,1
50,2017-2-21,2017,2,21,19,5vash9,Using Machine Learning for Anomaly Detection,https://www.reddit.com/r/deeplearning/comments/5vash9/using_machine_learning_for_anomaly_detection/,cagataydemir,1487672428,,0,1
51,2017-2-22,2017,2,22,0,5vc0yp,How is Deep Learning Changing Data Science Paradigms?,https://www.reddit.com/r/deeplearning/comments/5vc0yp/how_is_deep_learning_changing_data_science/,__me_again__,1487690436,,0,1
52,2017-2-22,2017,2,22,3,5vd05e,tensorflow 1.0.0 with rstudio docker images up.,https://www.reddit.com/r/deeplearning/comments/5vd05e/tensorflow_100_with_rstudio_docker_images_up/,mrchypark,1487700167,,0,1
53,2017-2-22,2017,2,22,4,5vdhs8,GPUs Are Now Available for Google Compute Engine and Cloud Machine Learning,https://www.reddit.com/r/deeplearning/comments/5vdhs8/gpus_are_now_available_for_google_compute_engine/,eleitl,1487704753,,0,2
54,2017-2-22,2017,2,22,4,5vdr0h,Wide &amp; Deep Learning: Memorization + Generalization,https://www.reddit.com/r/deeplearning/comments/5vdr0h/wide_deep_learning_memorization_generalization/,Mussem17,1487707155,,0,0
55,2017-2-22,2017,2,22,14,5vgxks,"Can anyone enlist the list of essential properties of an object to understand complete structure of the object? E.g. - geometric aspects, depth, what else? It's better they are quantifiable.",https://www.reddit.com/r/deeplearning/comments/5vgxks/can_anyone_enlist_the_list_of_essential/,Talos19,1487741736,,2,0
56,2017-2-23,2017,2,23,1,5vjsb7,Opening the Black Box: Interpretable Deep Learning for Genomics,https://www.reddit.com/r/deeplearning/comments/5vjsb7/opening_the_black_box_interpretable_deep_learning/,reworksophie,1487782368,,0,1
57,2017-2-23,2017,2,23,5,5vl702,Why Medicine Needs Deep Learning,https://www.reddit.com/r/deeplearning/comments/5vl702/why_medicine_needs_deep_learning/,Mussem17,1487795555,,1,0
58,2017-2-23,2017,2,23,12,5vnw5c,Any suggestions on a 1U/2U chassis that would support 4 GPUs?,https://www.reddit.com/r/deeplearning/comments/5vnw5c/any_suggestions_on_a_1u2u_chassis_that_would/,Saxi,1487821053,"I was looking at super micro's stuff, but they are only complete systems with P100 and I'm not looking to spend $35K, I want to drop in 1060's or 1070's.

Most servers don't have the PSU cables for GPUs nor the space.",3,2
59,2017-2-23,2017,2,23,16,5vp4m9,Faster R-CNN,https://www.reddit.com/r/deeplearning/comments/5vp4m9/faster_rcnn/,gungorbasa,1487835149,"Hey guys, I was trying to understand Faster RCNN paper but I am stuck on Region Proposing Networks part? Can someone help me on that?",2,2
60,2017-2-24,2017,2,24,0,5vr1u0,Choose subject for Thesis project between Deep Fool algorithm and Data Stream Anomaly Detection.,https://www.reddit.com/r/deeplearning/comments/5vr1u0/choose_subject_for_thesis_project_between_deep/,billythekid-,1487864320,I am about choosing one of two these subject.My main purpose is to parallize the algorithm via cuda . Which one of the two topics is according to your opinion and your experience more in demand these days? Thanks in advance,1,1
61,2017-2-24,2017,2,24,6,5vt8tx,Any examples of 3D/time-distributed cnn/r-cnn in Tensorflow/Keras?,https://www.reddit.com/r/deeplearning/comments/5vt8tx/any_examples_of_3dtimedistributed_cnnrcnn_in/,cctap,1487885346,Does anyone know of any 3D cnn or time-distributed cnn examples in Keras for video data? I have not been able to find any. ,0,3
62,2017-2-24,2017,2,24,6,5vt9xc,DeepCoder: Learning to Write Programs,https://www.reddit.com/r/deeplearning/comments/5vt9xc/deepcoder_learning_to_write_programs/,DataScienceInc,1487885627,,0,1
63,2017-2-24,2017,2,24,11,5vutts,"Talk + Q&amp;A on Deep Q-learning, based on the project ""Deep Reinforcement Learning: Playing a Racing Game""",https://www.reddit.com/r/deeplearning/comments/5vutts/talk_qa_on_deep_qlearning_based_on_the_project/,lopespm,1487902291,,0,1
64,2017-2-24,2017,2,24,17,5vwgow,Face Recognition with Deep Learning - Do I look like Brad Pitt?,https://www.reddit.com/r/deeplearning/comments/5vwgow/face_recognition_with_deep_learning_do_i_look/,gavlaaaaaaaa,1487925910,,1,1
65,2017-2-24,2017,2,24,18,5vwjq4,Online Workshop - Deep Dream and neural style transfer - matching deep learning with art,https://www.reddit.com/r/deeplearning/comments/5vwjq4/online_workshop_deep_dream_and_neural_style/,annkov,1487927612,,0,5
66,2017-2-24,2017,2,24,20,5vwx2e,Exploring Machine Learning at OpenAI &amp;amp; Google With the Experts,https://www.reddit.com/r/deeplearning/comments/5vwx2e/exploring_machine_learning_at_openai_amp_google/,teamrework,1487934543,,0,2
67,2017-2-26,2017,2,26,4,5w5tho,Convolutional Neural Networks for Underwater Color Classification,https://www.reddit.com/r/deeplearning/comments/5w5tho/convolutional_neural_networks_for_underwater/,Arzela-Ascoli,1488051120,"I have a set of underwater scenes consisting of known objects. I'm trying to segment these objects, and have pixel-level segmentation labels, but it seems that convolutional neural networks seem to be designed for image-level classification. When at a distance, the objects become sufficiently close in color to the background water that they can be difficult to recognize to the human eye (but by looking at other color space planes, you can usually figure it out). Any advice as to how to proceed?

I've also considered just a regular neural net or some other classifier trained on the individual pixel values (possibly preprocessed to stretch the color planes), and passing in a few patch statistics (ie, maximum, min value in patch, range)",1,1
68,2017-2-26,2017,2,26,9,5w7hed,Batch normalization and weight/activity regularization pathology?,https://www.reddit.com/r/deeplearning/comments/5w7hed/batch_normalization_and_weightactivity/,kappago,1488070167,"Using an example:

FC1-&gt;ReLu-&gt;X
or 
X-&gt;ReLu-&gt;FC1
where FC1 has some sort of regularization on it, and X is some sort of layer that can scale by a constant, for example another FC layer, or simply a scaling layer. Also, X is not regularized.
It seems that FC1 can ""cheat"" by just scaling all of its weights down by a constant, and having X scale up proportionally, causing the effective regularization to become gradually less powerful over time. So the idea is that X should be regularized as well.

Batch norm consists of scaling to 1 std dev, then scaling up or down as desired using the gamma parameter. But the first step doesn't have regularization applied to it, only gamma does (at least in the implementations I've seen). 
So the BN-&gt;ReLu-&gt;FC1 case should be okay, but not FC1-&gt;ReLu-&gt;BN.

Is my reasoning correct? How big of a problem is this?
",0,3
69,2017-2-27,2017,2,27,1,5warcx,The State Of AI: A list of the human tasks artificial intelligence has mastered,https://www.reddit.com/r/deeplearning/comments/5warcx/the_state_of_ai_a_list_of_the_human_tasks/,nikitaljohnson,1488125314,,2,2
70,2017-2-27,2017,2,27,13,5wes2f,How to implement Long-term Recurrent Convolutional Networks in Keras??,https://www.reddit.com/r/deeplearning/comments/5wes2f/how_to_implement_longterm_recurrent_convolutional/,GengisDroundStone,1488170668,"I want to implement the Long-term Recurrent Convolutional Networks, with keras and theano backend according to this [paper](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper.pdf) . How do I feed the output of the CNN into the LSTM? I'm very new to this, so any kind of help will be appreciated. ",3,1
71,2017-2-27,2017,2,27,19,5wg1sk,"Interpretability: the Next Deep Learning Challenge (Interview with Charlie Tang, Research Scientist at Apple)",https://www.reddit.com/r/deeplearning/comments/5wg1sk/interpretability_the_next_deep_learning_challenge/,reworksophie,1488191526,,0,1
72,2017-2-27,2017,2,27,21,5wghrp,Can Mobile Apps Benefit from Deep Learning AI?,https://www.reddit.com/r/deeplearning/comments/5wghrp/can_mobile_apps_benefit_from_deep_learning_ai/,julianrobert,1488199161,,0,1
73,2017-2-28,2017,2,28,5,5wj2p0,Deep Learning Lectures at the University of Oxford by Nando de Freitas,https://www.reddit.com/r/deeplearning/comments/5wj2p0/deep_learning_lectures_at_the_university_of/,Mussem17,1488226435,,1,11
0,2017-3-2,2017,3,2,7,5wzbw9,Pro Tip: cuBLAS Strided Batched Matrix Multiply | Parallel Forall,https://www.reddit.com/r/deeplearning/comments/5wzbw9/pro_tip_cublas_strided_batched_matrix_multiply/,harrism,1488408218,,0,1
1,2017-3-2,2017,3,2,10,5x08xk,H2O.ai experts needed--the hourly rate is $150 per hour. Work virtually. Experfy is a Harvard-incubated marketplace.,https://www.reddit.com/r/deeplearning/comments/5x08xk/h2oai_experts_neededthe_hourly_rate_is_150_per/,zafarnamah,1488417902,,0,0
2,2017-3-3,2017,3,3,6,5x666f,[q] Torch Backpropagation Question,https://www.reddit.com/r/deeplearning/comments/5x666f/q_torch_backpropagation_question/,bjuncek,1488490758,"Hello all,

I had the following problem - namely, I am trying to get a complete backwards computation from a vector of values in torch (guided back-propagation).

The module in question is: 
    `cudnn.SpatialConvolution(3 -&gt; 64, 7x7, 2,2, 3,3) without bias`

I'm trying to perform the following computation:
   ` currentModule:backwards(batch:cuda(), previousGradInput)`

where `batch` is a input image, converted to batch input, and `currentGradOutput` is a vector of previously computed gradients such that 

     th&gt; currentGradOutput:size()
           1
          64
          112
          112
    [torch.LongStorage of size 4]


According to my calculations, gradient w.r.t weights should be of the size of the input image, however, it returns NULL. 

Any ideas where my thinking is wrong? I'm using torch7, and Facebook's resnet model. ",0,1
3,2017-3-3,2017,3,3,19,5x9odd,Deep Learning Platforms &amp; GPUs: an Interview With Bryan Catanzaro,https://www.reddit.com/r/deeplearning/comments/5x9odd/deep_learning_platforms_gpus_an_interview_with/,reworksophie,1488537452,,0,1
4,2017-3-5,2017,3,5,4,5ximlh,Convolutional Neural Networks for Image Classification,https://www.reddit.com/r/deeplearning/comments/5ximlh/convolutional_neural_networks_for_image/,vikramasia,1488655643,,0,1
5,2017-3-5,2017,3,5,4,5xis8m,Deep Learning and Self-Driving Cars from MIT: Lectures 01-05,https://www.reddit.com/r/deeplearning/comments/5xis8m/deep_learning_and_selfdriving_cars_from_mit/,Mussem17,1488657300,,0,7
6,2017-3-6,2017,3,6,3,5xo4yu,deep learning setup,https://www.reddit.com/r/deeplearning/comments/5xo4yu/deep_learning_setup/,prakashyadav008,1488737684,"I am new to deep learning .Can anyone suggest me any good references to start with deep learning for practical applications using tensor flow or other libraries? and  how to  setup amazon instance for deep learning ? with tensor flow , theano and keras ? ",1,3
7,2017-3-6,2017,3,6,21,5xt1v8,Texas Hold'em AI Bot Taps Deep Learning to Demolish Humans,https://www.reddit.com/r/deeplearning/comments/5xt1v8/texas_holdem_ai_bot_taps_deep_learning_to/,vegax87,1488804898,,2,1
8,2017-3-6,2017,3,6,22,5xtakz,Getting started with deep learning,https://www.reddit.com/r/deeplearning/comments/5xtakz/getting_started_with_deep_learning/,thealsomepanda,1488808178,"I would like to get started with learning how work with deep learning programs (such as caffe or tensor flow). I do not really have any kind of programming experience, and I know Python is a good place to start when learning to program so I would like to start with a deep learning program that I can use Python with. If there is a better way to go about this please let me know. My end goal is to get it to a point where I can have it write an essay for me. Keep in mind I have no idea what I am doing so any advice helps, where to start, where to learn, what to use, stuff like that.",2,1
9,2017-3-7,2017,3,7,5,5xvuhr,Most cited deep learning papers,https://www.reddit.com/r/deeplearning/comments/5xvuhr/most_cited_deep_learning_papers/,psangrene,1488833749,,1,5
10,2017-3-7,2017,3,7,14,5xylg9,Deep Learning Resource Matrix,https://www.reddit.com/r/deeplearning/comments/5xylg9/deep_learning_resource_matrix/,psangrene,1488863988,,0,0
11,2017-3-7,2017,3,7,19,5xzph7,Training via evolution,https://www.reddit.com/r/deeplearning/comments/5xzph7/training_via_evolution/,tqhabib,1488883725,,1,0
12,2017-3-8,2017,3,8,10,5y51va,New kind of recurrent neural network using attention,https://www.reddit.com/r/deeplearning/comments/5y51va/new_kind_of_recurrent_neural_network_using/,jostmey,1488937495,,0,4
13,2017-3-8,2017,3,8,16,5y6nn8,Doom Bots in TensorFlow,https://www.reddit.com/r/deeplearning/comments/5y6nn8/doom_bots_in_tensorflow/,marklit,1488958817,,0,3
14,2017-3-8,2017,3,8,18,5y6ym2,NVIDIA Jetson TX2 Delivers Twice the Intelligence to the Edge,https://www.reddit.com/r/deeplearning/comments/5y6ym2/nvidia_jetson_tx2_delivers_twice_the_intelligence/,dusty_nv,1488964536,,1,1
15,2017-3-8,2017,3,8,19,5y76fm,"TensorFlow &amp; Deep Learning, without a PhD by Martin Grner",https://www.reddit.com/r/deeplearning/comments/5y76fm/tensorflow_deep_learning_without_a_phd_by_martin/,rick-rebel,1488968624,,0,1
16,2017-3-8,2017,3,8,19,5y7afd,IWD 2017: Interview with Accenture's Manager of AI,https://www.reddit.com/r/deeplearning/comments/5y7afd/iwd_2017_interview_with_accentures_manager_of_ai/,teamrework,1488970675,,0,2
17,2017-3-9,2017,3,9,10,5yc05h,Can you guys please help me recommend deep learning rig build guides?,https://www.reddit.com/r/deeplearning/comments/5yc05h/can_you_guys_please_help_me_recommend_deep/,arkar_aung,1489021321,I am willing to spend up to 10K USD. Please also let me know the computing power I get out of this build as well.,15,6
18,2017-3-9,2017,3,9,14,5yd6pw,Adding noise to Mnist data,https://www.reddit.com/r/deeplearning/comments/5yd6pw/adding_noise_to_mnist_data/,muneeb2405,1489035785,"Hi, I just want to add noise in Mnist data, Does anyone know how to do that.
These(http://csc.lsu.edu/~saikat/n-mnist/) guys provide the data but its compatible for matlab. Does anyone know how to add noise in the whole dataset?",1,1
19,2017-3-10,2017,3,10,11,5yjet8,Need advice for implementing a sound classifier using a convolutional neural network.,https://www.reddit.com/r/deeplearning/comments/5yjet8/need_advice_for_implementing_a_sound_classifier/,foomly,1489111461,"I've been working on a sound classifier using deeplearning4j (java), but recently realised that it wasn't a viable option since the tool doesn't permit pooling over time yet. 

Basically, I have a .csv file with the time as one column and other columns are frequencies of a sound from different sensors.

I have little time left before I need to be done with this project and now I will be using python. I was wondering if there are any good examples of time pooling on a .csv file out there because I couldn't find any, the ones I found were done on a waveform which I don't have. Thank you!",6,2
20,2017-3-11,2017,3,11,6,5yp09e,If you had unlimited resources to build any model...,https://www.reddit.com/r/deeplearning/comments/5yp09e/if_you_had_unlimited_resources_to_build_any_model/,nlp_question,1489182700,"If you had unlimited resources to download/crawl/scrape any dataset and unlimited resources to train a model, what would you do? I'm not completely in this situation, but I do have considerable resources right now and I'm looking for good ideas. I'm open to collaborate if we agree on research areas. 

My work is mostly in building neural networks for text/NLP tasks. I have two ideas for tasks that I'm kinda interested in. 

1. I'd like to create an algorithm that crawls every newspaper and looks for references to a person being killed. Kinda like this but on a global scale: http://homicide.latimes.com/ the output would be a spatio-temporal map with instances of homicide. 

2. Create an instant fact checker. Basically, when someone speaks, e.g. Trump, the algorithm would take the text and try to search for evidence that supports or discredits the claim. 

 ",4,1
21,2017-3-11,2017,3,11,18,5yrxe7,Can we all look back and appreciate how advanced the AI that ran Inspector Gadget's car was?,https://www.reddit.com/r/deeplearning/comments/5yrxe7/can_we_all_look_back_and_appreciate_how_advanced/,AlexanderLuthorJr,1489224559,,0,2
22,2017-3-13,2017,3,13,17,5z3vre,What's the difference between a single output RNN and a MLP whose input data contains all the features of all given time steps?,https://www.reddit.com/r/deeplearning/comments/5z3vre/whats_the_difference_between_a_single_output_rnn/,ispinfx,1489392968,,0,1
23,2017-3-13,2017,3,13,21,5z4r2h,Improving Reinforcement Learning With Minecraft,https://www.reddit.com/r/deeplearning/comments/5z4r2h/improving_reinforcement_learning_with_minecraft/,nikitaljohnson,1489408887,,0,0
24,2017-3-14,2017,3,14,0,5z5hu5,"New feature by BJ Dooley for TDWI: AI, Deep Learning, and Financial Services, by Brian J. Dooley",https://www.reddit.com/r/deeplearning/comments/5z5hu5/new_feature_by_bj_dooley_for_tdwi_ai_deep/,bjdooley,1489417765,,0,0
25,2017-3-14,2017,3,14,0,5z5j00,Computer Vision News of March,https://www.reddit.com/r/deeplearning/comments/5z5j00/computer_vision_news_of_march/,Gletta,1489418081,"Dear all, 
here is the March issue of Computer Vision News - 38 pages, great content (with codes).
Free subscription at page 38.
This is the magazine version (recommended): http://www.rsipvision.com/ComputerVisionNews-2017March/
This is the PDF version: http://www.rsipvision.com/computer-vision-news-2017-march-pdf/
Enjoy!",0,9
26,2017-3-14,2017,3,14,0,5z5nv9,Can you explain the difference between Machine Learning and Deep Learning in a sentence?,https://www.reddit.com/r/deeplearning/comments/5z5nv9/can_you_explain_the_difference_between_machine/,reworkmagnall,1489419503,"The difference doesn't tend to be well known and its extremely complicated to explain. If you were to simplify it to one sentence, how would you describe it?",9,3
27,2017-3-14,2017,3,14,7,5z89rz,Methods to forecast unbiased probability distribution of target value.,https://www.reddit.com/r/deeplearning/comments/5z89rz/methods_to_forecast_unbiased_probability/,sashkello,1489444318,"Hi, guys!
I'm interested in (deep learning) algorithms which are able to generate not a point forecast, but a probability distribution of the target value in a time series. So, say we have a real-valued time series (not necessarily evenly-spaced in time, but that doesn't matter for now) and we'd like to learn to predict its value at a certain point in the future. How do I generate not just a number, but a whole distribution (through MC, I assume), and which model will be best fit to make it unbiased yet precise?

Edit: 
To add a bit more details. The time series is stationary, but undergoes regime switching. That is, there are points when it exhibits new kind of behaviour and we'd expect to have a wide (very uncertain) forecast. I thought something derived from LSTM might work here, as it is well suited for detecting the context, but I'm not sure what is the most efficient way of adapting it to this particular situation...

Thank you!",4,2
28,2017-3-14,2017,3,14,22,5zc3r9,How to apply dropout for getting prediction from the last layer of a trained model?,https://www.reddit.com/r/deeplearning/comments/5zc3r9/how_to_apply_dropout_for_getting_prediction_from/,umairalipathan,1489498158,"I have used transfer learning to retrain/fine-tune Inception-V3 model for image classification on my own data in Tensorflow. However, when I test the image classification after training, I get the following error:

""Invalid argument: You must feed a value for placeholder tensor 'final_layer/dropout/Placeholder' with dtype float""

I am using the following code for getting the predictions from the final layer:

softmax_tensor = sess.graph.get_tensor_by_name('final_layer/final_result/Softmax:0')
predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})

I guess the error is caused by not applying the dropout placeholder in the second statement, as the training was performed with dropout layer. How do I add a dropout placeholder here?",2,0
29,2017-3-15,2017,3,15,9,5zg5jc,Check this for find out is it really super easy to understand deep learning!,https://www.reddit.com/r/deeplearning/comments/5zg5jc/check_this_for_find_out_is_it_really_super_easy/,kifhan,1489538040,,0,2
30,2017-3-15,2017,3,15,21,5zixf3,Applying Autoencoding in the Financial Sector,https://www.reddit.com/r/deeplearning/comments/5zixf3/applying_autoencoding_in_the_financial_sector/,teamrework,1489579230,,0,1
31,2017-3-16,2017,3,16,20,5zpxlv,Hyperparameter optimization using Hyperopt/hyperas in Deep Learning,https://www.reddit.com/r/deeplearning/comments/5zpxlv/hyperparameter_optimization_using_hyperopthyperas/,kailashahirwar12,1489662333,"Is anyone working on Hyperparameter optimization using Hyperopt or hyperas? Is there any other library for Hyperparameter optimization?
Bayesian opmitization or any other optimization methods?",0,4
32,2017-3-17,2017,3,17,1,5zroii,Crowd-sourcing a dataset of English and Cyrillic alphabet images,https://www.reddit.com/r/deeplearning/comments/5zroii/crowdsourcing_a_dataset_of_english_and_cyrillic/,gregvial,1489682544,"Hello
I am working on a few non-commercial applications for language learning, based on hand-writing recognition with convolutional neural network. 

For English, rather than using existing dataset (NIST) that is copyrighted to the US secretary of commerce, I would like to build my own dataset. For Cyrillic there is not much choice as as far as I know, there is no such public dataset.

The idea is to crowd-source the dataset and make it a creative common, free of right for anybody to use.

If you would like to support the machine learning community, please go on http://comnist.gregvi.al (English) or http://comnist.gregvi.al/?ru (Cyrillic) and draw some letters on your touch screen. No matter whether you speak Russian or not, you can draw letters of both alphabets. Kids can play too if they know how to write already. Data will be fully curated to remove mistakes/vandalism.

More details on http://github.com/GregVial/comnist

Cheers
Greg",0,0
33,2017-3-17,2017,3,17,6,5zti6x,How to use batch_sequences_with_states in tensorflow?,https://www.reddit.com/r/deeplearning/comments/5zti6x/how_to_use_batch_sequences_with_states_in/,jiminiminimini,1489700316,"[This example](https://www.tensorflow.org/versions/master/api_docs/python/contrib.training/splitting_sequence_inputs_into_minibatches_with_state_saving) in the documentation does not work and all the other bits and pieces required to use this method are scattered around tests, examples, comments inside the repository. I have preprocessed data of different lengths. They are currently stored as a list of numpy arrays of shape `(time, features)`. How should I format this list in order to be able to use `batch_sequences_with_states` method?",0,1
34,2017-3-17,2017,3,17,16,5zw80x,Neural network with a varying input size,https://www.reddit.com/r/deeplearning/comments/5zw80x/neural_network_with_a_varying_input_size/,davido1221,1489734921,"Is there an approach to have a standard neural network that can have a varying size of inputs? (Not using RNN or padding), 
My input data is M vectors for a specific label for example  and the vectors are word vectors (w2v)",7,1
35,2017-3-17,2017,3,17,23,5zxzs2,Get started with Deep Learning using Keras.,https://www.reddit.com/r/deeplearning/comments/5zxzs2/get_started_with_deep_learning_using_keras/,thesemicoloncode,1489762161,,0,10
36,2017-3-18,2017,3,18,2,5zyu9l,Swapout: Learning an Ensemble of Deep Architectures,https://www.reddit.com/r/deeplearning/comments/5zyu9l/swapout_learning_an_ensemble_of_deep_architectures/,amplifier_khan,1489770541,,0,4
37,2017-3-18,2017,3,18,2,5zyzi2,Squeezing Deep Learning into Mobile Phones - A Practitioner's guide,https://www.reddit.com/r/deeplearning/comments/5zyzi2/squeezing_deep_learning_into_mobile_phones_a/,psangrene,1489771922,,0,3
38,2017-3-18,2017,3,18,3,5zz7xu,Deep Learning From A to Z,https://www.reddit.com/r/deeplearning/comments/5zz7xu/deep_learning_from_a_to_z/,Mussem17,1489774150,,0,2
39,2017-3-18,2017,3,18,4,5zzp94,LSTM Encoder,https://www.reddit.com/r/deeplearning/comments/5zzp94/lstm_encoder/,Gio_Gats,1489778693,"I'm working on a project in TF Learn where I'm comparing variable length sequences.  Essentially, I'd like to use an LSTM to encode a sequence as a fixed-length vector, which I can then compare with kmeans/gmm/etc.

Does anyone know of existing implementations/pre-trained models that might be able to do this?  I've thought about modifying a [tensorflow tutorial](https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/) and trying to train it myself, but someone out there has a model already, right? ",3,2
40,2017-3-18,2017,3,18,21,603s9a,Titan X Pascal or 1080 ti for DL?,https://www.reddit.com/r/deeplearning/comments/603s9a/titan_x_pascal_or_1080_ti_for_dl/,entelechii,1489838766,"For deep learning which GPU is better and why?  Titan X has 12GB vs 11GB 1080 ti, and 1080 ti is $699 vs $1200, but is there anything else which significantly separates these two for use in ML/DL?",3,8
41,2017-3-20,2017,3,20,0,60ahxl,Where does double precision matter in deep learning?,https://www.reddit.com/r/deeplearning/comments/60ahxl/where_does_double_precision_matter_in_deep/,arkar_aung,1489936436,"Since GTX1080Ti is good with single/half precision, I am considering whether I should invest in more expensive cards which perform better in double-precision. Which use cases require double precision? ",8,2
42,2017-3-20,2017,3,20,6,60chsa,OC - texture net film,https://www.reddit.com/r/deeplearning/comments/60chsa/oc_texture_net_film/,kur_einu,1489958684,,0,1
43,2017-3-20,2017,3,20,16,60f75d,Sequence learning with pytorch,https://www.reddit.com/r/deeplearning/comments/60f75d/sequence_learning_with_pytorch/,rajarsheem,1489995332,,0,2
44,2017-3-20,2017,3,20,20,60fv3n,"What are the best free, interactive resources to learn Deep Learning with Python/Tensorflow?",https://www.reddit.com/r/deeplearning/comments/60fv3n/what_are_the_best_free_interactive_resources_to/,Estiui,1490008164,"So I have a background in Computer Vision with some Machine Learning from the University, but I'm not currently using it on my job, so I'd like to update myself a bit with Deep Learning to be able to apply for related jobs.

That being said, which is the best online resource, in your opinion, to learn from scratch? Is Tensorflow the go-to option to be up to date?",7,4
45,2017-3-20,2017,3,20,20,60fy88,Beating The Perils of Non-Convexity in Neural Nets,https://www.reddit.com/r/deeplearning/comments/60fy88/beating_the_perils_of_nonconvexity_in_neural_nets/,nikitaljohnson,1490009564,,0,1
46,2017-3-21,2017,3,21,0,60h2i4,Learn TensorFlow and Deep Learning Together and Now!,https://www.reddit.com/r/deeplearning/comments/60h2i4/learn_tensorflow_and_deep_learning_together_and/,SaeedAgha,1490022910,,0,3
47,2017-3-21,2017,3,21,9,60kk2v,"Deep learning ""keywords""",https://www.reddit.com/r/deeplearning/comments/60kk2v/deep_learning_keywords/,[deleted],1490057542,[deleted],0,3
48,2017-3-21,2017,3,21,15,60m0vb,Good source of open medicine/health data for training a network?,https://www.reddit.com/r/deeplearning/comments/60m0vb/good_source_of_open_medicinehealth_data_for/,avjr,1490077245,"Where could one get images or text data for training a deep learning network, similar to http://news.stanford.edu/2017/01/25/artificial-intelligence-used-identify-skin-cancer/?",2,1
49,2017-3-22,2017,3,22,0,60o4is,Choosing a conference to visit? Pick the best ones in 2017 and engage with others on Medium.,https://www.reddit.com/r/deeplearning/comments/60o4is/choosing_a_conference_to_visit_pick_the_best_ones/,tds1,1490109041,,0,3
50,2017-3-22,2017,3,22,19,60tu8t,Deep Learning methods forecasts of stocks prices,https://www.reddit.com/r/deeplearning/comments/60tu8t/deep_learning_methods_forecasts_of_stocks_prices/,editorsocial,1490179169,,2,3
51,2017-3-23,2017,3,23,3,60wi1o,VocalToneToVector,https://www.reddit.com/r/deeplearning/comments/60wi1o/vocaltonetovector/,barnyardman,1490207942,"I've been looking into animation completion via key frames (for cartoons) in order to speed up development between sources like manga and comics to anime/full feature movies.

One of the biggest issues in the community is quality of ""dubs"", or audio translations.  It seems like this could be solved by capturing a vectorization of the ""tone"" of the source and applying it to a generated translation.

Is anyone working on or heard of something similar?",2,2
52,2017-3-23,2017,3,23,4,60wy0h,Deep Learning in Finance: Learning to Trade with Q-RL and DQNs,https://www.reddit.com/r/deeplearning/comments/60wy0h/deep_learning_in_finance_learning_to_trade_with/,teamrework,1490212120,,0,7
53,2017-3-24,2017,3,24,17,617qnz,What does using more that one gpu increase?,https://www.reddit.com/r/deeplearning/comments/617qnz/what_does_using_more_that_one_gpu_increase/,entelechii,1490343714,"If I have one titan x pascal (for example) I have 12gb, and about 3500 cuda cores.. How does using 2 titans compared to using just 1?  Ie is there total of 24gb (I'm guessing this is not the case).. Is the benefit that each gpu can work on half of a process each, so splitting the time in half.  Essentially why is 2 better than 1 or 6 better than 2 etc etc?",3,1
54,2017-3-25,2017,3,25,4,61b46u,Addressing the Critical Issues of Deep Learning in Medical Imaging,https://www.reddit.com/r/deeplearning/comments/61b46u/addressing_the_critical_issues_of_deep_learning/,teamrework,1490384168,,0,3
55,2017-3-25,2017,3,25,10,61d1cs,Where to start in Deep Learning as a non-Mathematician,https://www.reddit.com/r/deeplearning/comments/61d1cs/where_to_start_in_deep_learning_as_a/,jsnab,1490404753,"I'm a software engineer and I'm very interested in Deep Learning. However, all of the texts I have read so far are totally impenetrable and seem to assume I have a PHD in AI already or at least a Math masters. Any advice on where to start reading for a mere mortal?
",10,6
56,2017-3-25,2017,3,25,11,61d8cs,Goodbye Age of Hadoop  Hello Cambrian Explosion of Deep Learning,https://www.reddit.com/r/deeplearning/comments/61d8cs/goodbye_age_of_hadoop_hello_cambrian_explosion_of/,psangrene,1490407239,,2,6
57,2017-3-26,2017,3,26,6,61hyk8,Deep learning for cluster analysis,https://www.reddit.com/r/deeplearning/comments/61hyk8/deep_learning_for_cluster_analysis/,_tinygiant_,1490477153,"Does a DNN make sense in extracting clusters of a particular shape? Whilst DBSCAN are very good at clustering data points, I would like to cluster based on the shape of the cluster (e.g. circular blobs vs, linear blobs). 

Does it make sense to tackle this with a DNN?",1,2
58,2017-3-27,2017,3,27,0,61m7ag,A complete feed on deep learning.. please check it out and thanks for feedback.,https://www.reddit.com/r/deeplearning/comments/61m7ag/a_complete_feed_on_deep_learning_please_check_it/,gobeno,1490543411,,2,2
59,2017-3-27,2017,3,27,9,61oze3,What are the newest deep learning networks?,https://www.reddit.com/r/deeplearning/comments/61oze3/what_are_the_newest_deep_learning_networks/,Alirezag,1490574090,"I know there are different networks for image recognition, such as Alexnet, VGG, ResNet, etc. is  there any website or source that keep the track of these networks and tell us what is coming out recently? and tell us the their ranking on different image dataset?",6,2
60,2017-3-27,2017,3,27,14,61qekw,Getting Started with Deep Learning,https://www.reddit.com/r/deeplearning/comments/61qekw/getting_started_with_deep_learning/,psangrene,1490593015,,1,3
61,2017-3-27,2017,3,27,18,61r3f2,New Approaches to Unsupervised Domain Adaptation,https://www.reddit.com/r/deeplearning/comments/61r3f2/new_approaches_to_unsupervised_domain_adaptation/,reworksophie,1490605757,,0,1
62,2017-3-27,2017,3,27,22,61s24y,Deep Learning: A Practitioner's Approach (book) is on sale for $28.56 (-43%),https://www.reddit.com/r/deeplearning/comments/61s24y/deep_learning_a_practitioners_approach_book_is_on/,arvaldim,1490620479,,1,3
63,2017-3-28,2017,3,28,2,61tfmn,Get started with deep learning by using Anaconda as a first step,https://www.reddit.com/r/deeplearning/comments/61tfmn/get_started_with_deep_learning_by_using_anaconda/,MieRobot,1490634338,,0,0
64,2017-3-28,2017,3,28,2,61ti43,Install Google's Tensorflow with easy steps in a laptop the Anaconda way,https://www.reddit.com/r/deeplearning/comments/61ti43/install_googles_tensorflow_with_easy_steps_in_a/,MieRobot,1490634940,,0,0
65,2017-3-28,2017,3,28,12,61x37q,include_top in Keras,https://www.reddit.com/r/deeplearning/comments/61x37q/include_top_in_keras/,mrkebi,1490672797,Can anyone help me understand the meaning of 'include_top = False' in Keras? Does it just mean it will not include fully connected layer(s)?,1,0
66,2017-3-28,2017,3,28,22,61zeha,So What is Deep Learning?,https://www.reddit.com/r/deeplearning/comments/61zeha/so_what_is_deep_learning/,BigCloudTeam,1490708505,,1,0
67,2017-3-29,2017,3,29,7,622ri6,Free Deep Learning Textbook,https://www.reddit.com/r/deeplearning/comments/622ri6/free_deep_learning_textbook/,psangrene,1490740633,,0,0
68,2017-3-29,2017,3,29,9,623bfl,classification vs detection vs localization?,https://www.reddit.com/r/deeplearning/comments/623bfl/classification_vs_detection_vs_localization/,pepitolander,1490746752,"I'm a bit confused here. In papers the discussion is always in terms of how well CNNs classify/detect/localize objects in images.

I understand what is to **classify** an image in terms of it's content. There is a true classification vector with 0s and a 1 indicating the true class of the object present in the image. The net is trained to minimize the difference between the output vector and the true vector. ok.

but, **detection** and **localization**? what's the difference between them? what is minimised in each case? how is this achieved?",4,1
69,2017-3-29,2017,3,29,9,623dgx,[Part 1] How to setup your own environment for deep learning  Locally,https://www.reddit.com/r/deeplearning/comments/623dgx/part_1_how_to_setup_your_own_environment_for_deep/,Ekami66,1490747414,,0,2
70,2017-3-29,2017,3,29,9,623gzx,https://www.highly.co/hl/J9fP54w1JFfDgX [Part 2] How to setup your own environment for deep learning  For remote access [Part 2] How to setup your own environment for deep learning  For remote access,https://www.reddit.com/r/deeplearning/comments/623gzx/httpswwwhighlycohlj9fp54w1jffdgx_part_2_how_to/,Ekami66,1490748523,,0,5
71,2017-3-29,2017,3,29,17,625ful,"Miniconda3, TensorFlow, Keras on Google Compute Engine GPU instance: The step-by-step guide.",https://www.reddit.com/r/deeplearning/comments/625ful/miniconda3_tensorflow_keras_on_google_compute/,cpbotha,1490776614,,0,8
72,2017-3-29,2017,3,29,18,625k7a,5 coole Anwendungen fr Deep Learning,https://www.reddit.com/r/deeplearning/comments/625k7a/5_coole_anwendungen_fr_deep_learning/,flezzfx,1490778876,,0,1
73,2017-3-29,2017,3,29,19,625s7m,The Great Conundrum of Hyperparameter Optimization,https://www.reddit.com/r/deeplearning/comments/625s7m/the_great_conundrum_of_hyperparameter_optimization/,teamrework,1490782789,,0,1
74,2017-3-30,2017,3,30,2,6280a3,Philips and PathAI to improve breast cancer diagnosis with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/6280a3/philips_and_pathai_to_improve_breast_cancer/,Mussem17,1490807828,,1,6
75,2017-3-30,2017,3,30,5,629d6j,Can you have two different gpus in the same workstation?,https://www.reddit.com/r/deeplearning/comments/629d6j/can_you_have_two_different_gpus_in_the_same/,entelechii,1490820504,Can you have a Titan x and a 1080 ti in the same workstation being used for deep learning?  Do you need to install both nvidia drivers to allow them both to work?  Anything else?,4,2
76,2017-3-30,2017,3,30,19,62d56f,Deep Learning Transforming the Future,https://www.reddit.com/r/deeplearning/comments/62d56f/deep_learning_transforming_the_future/,yagmurnur,1490869814,,0,1
77,2017-3-30,2017,3,30,19,62d6k6,op Five Use Cases of Tensorflow,https://www.reddit.com/r/deeplearning/comments/62d6k6/op_five_use_cases_of_tensorflow/,[deleted],1490870469,[deleted],0,1
78,2017-3-30,2017,3,30,20,62d99f,Top Five Use Cases of Tensorflow,https://www.reddit.com/r/deeplearning/comments/62d99f/top_five_use_cases_of_tensorflow/,yagmurnur,1490871718,,0,3
79,2017-3-31,2017,3,31,10,62iakc,Plug and play generative network experiment,https://www.reddit.com/r/deeplearning/comments/62iakc/plug_and_play_generative_network_experiment/,Hidden_dreamz,1490923764,,0,2
80,2017-3-31,2017,3,31,11,62igh9,Personalized Aesthetics: Recording the Visual Mind using Machine Learning,https://www.reddit.com/r/deeplearning/comments/62igh9/personalized_aesthetics_recording_the_visual_mind/,harrism,1490925716,,0,3
81,2017-3-31,2017,3,31,17,62k290,Using AI to Estimate Customer Life Time Value in E-Commerce,https://www.reddit.com/r/deeplearning/comments/62k290/using_ai_to_estimate_customer_life_time_value_in/,reworksophie,1490949870,,0,1
0,2017-4-1,2017,4,1,13,62qlkb,Rethinking Recurrent Neural Networks,https://www.reddit.com/r/deeplearning/comments/62qlkb/rethinking_recurrent_neural_networks/,jostmey,1491020844,,2,6
1,2017-4-1,2017,4,1,22,62sr64,Microsoft patent could be the ultimate disrupt to the content search market,https://www.reddit.com/r/deeplearning/comments/62sr64/microsoft_patent_could_be_the_ultimate_disrupt_to/,heydude_675,1491053949,,0,0
2,2017-4-3,2017,4,3,9,633goy,NLP Pre-Trained Embeddings Best Practices Question,https://www.reddit.com/r/deeplearning/comments/633goy/nlp_pretrained_embeddings_best_practices_question/,clamman,1491180210,"When performing a NLP task using pre-trained embeddings (such as sentiment analysis), what is the best practice when encountering a word that is in your training word corpus but is not in the pre-trained embeddings corpus? 

Two options off of the top of my head are we could initialize the missing words to just the zero vector or we could initialize them to a random unit vector. Are there others? What are the possible advantages/disadvantages of each? What if I treat my embeddings as constant rather than a trainable variable?

Thanks in advance for any insight/help.",7,2
3,2017-4-3,2017,4,3,18,635rbo,Online Banking is Evolving With NLP &amp;amp; Deep Learning,https://www.reddit.com/r/deeplearning/comments/635rbo/online_banking_is_evolving_with_nlp_amp_deep/,teamrework,1491212946,,0,3
4,2017-4-3,2017,4,3,19,635t1i,How Will Deep Learning Revolutionize Online Banking?,https://www.reddit.com/r/deeplearning/comments/635t1i/how_will_deep_learning_revolutionize_online/,reworksophie,1491213759,,0,1
5,2017-4-4,2017,4,4,18,63d4u0,Computer Vision News - April 2017 (in both HTML5 and PDF),https://www.reddit.com/r/deeplearning/comments/63d4u0/computer_vision_news_april_2017_in_both_html5_and/,Gletta,1491299077,"Here are two links to the April issue of Computer Vision News, published by RSIP Vision: 44 pages with exclusive articles and free subscription at page 44. Following general request, Flash version has been discontinued.

Read it in HTML5: http://www.rsipvision.com/ComputerVisionNews-2017April/ 
Read it in PDF: 
http://www.rsipvision.com/computer-vision-news-2017-april-pdf/ 
Enjoy!",0,2
6,2017-4-5,2017,4,5,7,63hjgt,Semantic Segmentation Domain Adaptation,https://www.reddit.com/r/deeplearning/comments/63hjgt/semantic_segmentation_domain_adaptation/,miat123,1491344940,"I am trying to train a conv net for semantic image segmentation. The problem is that I have a synthetic dataset and a real one and there is an obvious domain shift. What would be a way to do a domain adaptation? I have successfully done the simplest approach where I use 4 mini-batches from the real and 4 mini-batches from the synthetic domain in the SGD optimization.
I believe a more complicated approach would be better.",0,1
7,2017-4-5,2017,4,5,18,63kf44,SECURITY &amp; PRIVACY IS VITAL FOR MACHINE LEARNING TO SUCCEED,https://www.reddit.com/r/deeplearning/comments/63kf44/security_privacy_is_vital_for_machine_learning_to/,nikitaljohnson,1491383230,,1,0
8,2017-4-6,2017,4,6,2,63mu8w,First In-Depth Look at Googles TPU Architecture,https://www.reddit.com/r/deeplearning/comments/63mu8w/first_indepth_look_at_googles_tpu_architecture/,eleitl,1491411756,,0,10
9,2017-4-6,2017,4,6,11,63q4fj,In-depth NVIDIA DGX-1 Architecture White Paper,https://www.reddit.com/r/deeplearning/comments/63q4fj/indepth_nvidia_dgx1_architecture_white_paper/,harrism,1491444415,,0,3
10,2017-4-6,2017,4,6,13,63qpjt,Deep Learning and Quantum Physics : A Fundamental Bridge,https://www.reddit.com/r/deeplearning/comments/63qpjt/deep_learning_and_quantum_physics_a_fundamental/,hammy_bob,1491451540,,4,9
11,2017-4-6,2017,4,6,14,63r1op,What topic or idea in Deep Learning that requires not too much computational power but is still fertile for new development?,https://www.reddit.com/r/deeplearning/comments/63r1op/what_topic_or_idea_in_deep_learning_that_requires/,[deleted],1491456357,[deleted],1,1
12,2017-4-6,2017,4,6,19,63s4gp,Keras example of Pixel Wise classification,https://www.reddit.com/r/deeplearning/comments/63s4gp/keras_example_of_pixel_wise_classification/,S2ica,1491475049,"Hi, I'm new to deep learning (machine learning in general).

Currently I'm trying to implement a residual ConvNet for pixel wise classification, but am not sure how in general to do it. Currently all examples of neural networks in keras just performs image classification. 

Any information or hints towards doing this would help alot.
The implementation of residual CovNet I'm currently looking at is [this here](https://github.com/raghakot/kerasresnet/blob/master/resnet.py). ",1,3
13,2017-4-7,2017,4,7,3,63urt3,Specifying incorrect input dimensions for image classification,https://www.reddit.com/r/deeplearning/comments/63urt3/specifying_incorrect_input_dimensions_for_image/,BoltzmannMachine,1491502858,"What is the behaviour of Keras if an input dimension of (x, y) is specified but an image with dimensions (x', y') are introduced to the first layer of a sequential model? ",1,0
14,2017-4-7,2017,4,7,7,63whnw,AI Painting - Generative Neural Style,https://www.reddit.com/r/deeplearning/comments/63whnw/ai_painting_generative_neural_style/,Hidden_dreamz,1491519159,,0,5
15,2017-4-7,2017,4,7,12,63xz5e,How many images (data) do I need to start training a Deep Neural network from scratch?,https://www.reddit.com/r/deeplearning/comments/63xz5e/how_many_images_data_do_i_need_to_start_training/,Alirezag,1491535462,"I have a naive question.

How can I know the amount of the images (data) that I have is enough to start training a network from scratch?
I guess the amount of data for each DNN architecture would be different, for example, the amount of data that AlexNet requires would be less than the amount of data that ResNet Needs (at least that is what I think).

But How I can figure out that I have the minimum sufficient amount of images to start training a network from scratch?

Is there any paper/explanation/method/logical/non-logical way to compute the minimum required number/amount of images(data)?

Thanks :)",1,7
16,2017-4-8,2017,4,8,16,645wjn,PDF version of MIT DeepLearningBook,https://www.reddit.com/r/deeplearning/comments/645wjn/pdf_version_of_mit_deeplearningbook/,janishar,1491637089,,1,22
17,2017-4-9,2017,4,9,2,64895e,Top 9 Deep Learning and Neural Networks Books,https://www.reddit.com/r/deeplearning/comments/64895e/top_9_deep_learning_and_neural_networks_books/,kjahan,1491672800,,1,1
18,2017-4-9,2017,4,9,14,64bmne,What would be the benefits of image data sets with contour annotations?,https://www.reddit.com/r/deeplearning/comments/64bmne/what_would_be_the_benefits_of_image_data_sets/,dyanson,1491715967,"We have a technology can automatically generate training image data sets for deep learning with true contour annotations, i.e. objects labeled without background. Instead of conventional bounding boxes around annotated objects that contain irrelevant background in the corners / edges, we can provide training images that are cropped to the contour of an object of interest with &gt;90% relevant fill factor (either non-rectangular ROI or rectangular ROI with zero background outside the object contour).

What are the use cases for such data? What benefits can it offer?
",3,3
19,2017-4-9,2017,4,9,17,64c6o4,Question Answering using Deep Learning,https://www.reddit.com/r/deeplearning/comments/64c6o4/question_answering_using_deep_learning/,rajarsheem,1491727423,,4,1
20,2017-4-10,2017,4,10,16,64i5nx,"Books on everything you need to know on Deep Learning and Machine Learning. This list contains books recommended by Nando De Freitas, Michael I Jordan, Juergen Schmidhuber, Alex Lamb and Geoffrey Hinton.",https://www.reddit.com/r/deeplearning/comments/64i5nx/books_on_everything_you_need_to_know_on_deep/,kawaii_potatosan,1491808388,,0,17
21,2017-4-12,2017,4,12,3,64slke,Cognitive Robotics: Learning Semantic Environment Perception,https://www.reddit.com/r/deeplearning/comments/64slke/cognitive_robotics_learning_semantic_environment/,reworksophie,1491934432,,0,1
22,2017-4-12,2017,4,12,3,64stkm,Security &amp; Privacy is Vital For Machine Learning to Succeed,https://www.reddit.com/r/deeplearning/comments/64stkm/security_privacy_is_vital_for_machine_learning_to/,reworksophie,1491936431,,0,1
23,2017-4-12,2017,4,12,6,64tyqj,Quantomic's Tagspire Drives Social Commerce with Innovative Artificial Intelligence (AI),https://www.reddit.com/r/deeplearning/comments/64tyqj/quantomics_tagspire_drives_social_commerce_with/,mediawoman,1491947133,,0,1
24,2017-4-12,2017,4,12,7,64u8xt,Recursive Neural Networks with PyTorch | Parallel Forall,https://www.reddit.com/r/deeplearning/comments/64u8xt/recursive_neural_networks_with_pytorch_parallel/,harrism,1491950034,,0,5
25,2017-4-12,2017,4,12,18,64x0kr,Security &amp; Privacy is Vital For Machine Learning to Succeed,https://www.reddit.com/r/deeplearning/comments/64x0kr/security_privacy_is_vital_for_machine_learning_to/,reworksophie,1491987670,,0,1
26,2017-4-13,2017,4,13,21,65574z,DCGAN for Image Completion in Torch,https://www.reddit.com/r/deeplearning/comments/65574z/dcgan_for_image_completion_in_torch/,fonfonx,1492087150,,0,2
27,2017-4-15,2017,4,15,0,65d79h,"DeepMind CEO, ""Artificial Intelligence (AI) invents new knowledge and teaches human new theories""",https://www.reddit.com/r/deeplearning/comments/65d79h/deepmind_ceo_artificial_intelligence_ai_invents/,scidem,1492184050,,0,1
28,2017-4-15,2017,4,15,2,65e1rn,Measuring Performance for Object Detectors - Part 1,https://www.reddit.com/r/deeplearning/comments/65e1rn/measuring_performance_for_object_detectors_part_1/,geodawg,1492192305,,0,3
29,2017-4-15,2017,4,15,18,65icnm,What Is Deep Learning?,https://www.reddit.com/r/deeplearning/comments/65icnm/what_is_deep_learning/,Mussem17,1492249960,,0,0
30,2017-4-16,2017,4,16,18,65obzd,Visualizing convolutional layers,https://www.reddit.com/r/deeplearning/comments/65obzd/visualizing_convolutional_layers/,svjan5,1492334765,"Please try to answer this question on stackoverflow site:
http://stackoverflow.com/questions/43433734/deconvolution-conv2d-transpose-in-tensor-flow",1,1
31,2017-4-17,2017,4,17,13,65thuf,Deep learning internship: should I take it?,https://www.reddit.com/r/deeplearning/comments/65thuf/deep_learning_internship_should_i_take_it/,chris_munley,1492402664,"I am being offered the choice between deep learning and parallel programming at a university near where I live as a summer internship. I am in high school, I have looked into both topics, and I found parallel programming to be more up my alley and easier to learn, however deep learning is very interesting to me although somewhat hard to understand. Should I challenge myself and try to work on deep learning with the help of a professor and some phd students, or go into parallel programming. Suggestions greatly appreciated. ",14,4
32,2017-4-18,2017,4,18,17,661kam,Cloud-based Deep Learning: Reducing Tedium in Radiology,https://www.reddit.com/r/deeplearning/comments/661kam/cloudbased_deep_learning_reducing_tedium_in/,teamrework,1492503509,,0,0
33,2017-4-18,2017,4,18,18,661rnt,Creating the Open-Source Autonomous Vehicle,https://www.reddit.com/r/deeplearning/comments/661rnt/creating_the_opensource_autonomous_vehicle/,teamrework,1492507358,,0,1
34,2017-4-19,2017,4,19,0,663nil,Question: Autoencoder vs Pre-trained DNN,https://www.reddit.com/r/deeplearning/comments/663nil/question_autoencoder_vs_pretrained_dnn/,[deleted],1492530545,[deleted],1,0
35,2017-4-19,2017,4,19,1,66423a,[Question][Discussion] Where to go from here?,https://www.reddit.com/r/deeplearning/comments/66423a/questiondiscussion_where_to_go_from_here/,[deleted],1492534295,[deleted],0,0
36,2017-4-19,2017,4,19,3,664lfp,How do you create a self-contained deep-learning executable?,https://www.reddit.com/r/deeplearning/comments/664lfp/how_do_you_create_a_selfcontained_deeplearning/,etrnloptimist,1492539176,"I'm on Windows, and I'm looking to create a simple, portable, self-contained executable that does image classification. 

The libraries I work with (Keras, Theano, Anaconda Python, etc.) require a ton of environment stuff to run properly. Compilers, environment variables, etc. This is fine for test and development, but when it comes to production, I would like it to behave like a traditional program, with a traditional installer.

Ideally it would be run like this:

c:\\MyExecutable.exe MyModel.cnn MyTestImage.jpg

Is there a way to do this?",8,2
37,2017-4-19,2017,4,19,6,665rlj,Last Words: Computational Linguistics and Deep Learning - MITP on Nautilus,https://www.reddit.com/r/deeplearning/comments/665rlj/last_words_computational_linguistics_and_deep/,pmz,1492550162,,0,2
38,2017-4-19,2017,4,19,8,666hql,IBM Boosts Deep Learning Offerings with Anaconda Data Science Platform,https://www.reddit.com/r/deeplearning/comments/666hql/ibm_boosts_deep_learning_offerings_with_anaconda/,dataengconf,1492557629,,0,6
39,2017-4-19,2017,4,19,8,666ou0,Sentiment analysis of social media posts using deep learning,https://www.reddit.com/r/deeplearning/comments/666ou0/sentiment_analysis_of_social_media_posts_using/,wnbhckr,1492559848,"I wanted to do something interesting as my master's thesis so I chose sentiment analysis with deep learning, but now I'm a bit stuck and have motivation problems due to (in my opinion) high entry barrier of the field. My supervisor wanted me to dig in academic journals, but I have a feeling it's very hard to teach yourself from academic papers, since authors don't share (one exception I found is OpenAI) all of their work, but only some vague description, comparison tables and charts, conclusions/summary.

I think I get the gist of what sentiment analysis is, but don't exactly know what could I aim for with my research as a newbie. For now I don't even have a clue how to glue sentiment analysis with deep learning. I guess extraction of opinions about specific aspects of subjects mentioned in post would be too much.

It's worth mentioning I'm also new to deep learning, however I know the basics of neural nets and had to do with reinforcement learning a little.

Fortunately, programming skills aren't a problem.

I'm looking for advice how to get started, get hyped, so I'd want to explore and experiment more on my own. All resources which you think are valuable are welcome. Thank you for your time.",1,1
40,2017-4-19,2017,4,19,11,667k7l,"What does ""run it 5 times"" mean in ResNet paper?",https://www.reddit.com/r/deeplearning/comments/667k7l/what_does_run_it_5_times_mean_in_resnet_paper/,cuekoo,1492569798,"In the caption of Table 6 of ResNet paper (https://arxiv.org/abs/1512.03385), the authors run the model 5 times to report some results. How is it done? Is it to train the model 5 times, or to test 5 times with the same set of learned parameters?",2,1
41,2017-4-20,2017,4,20,1,66bgqs,"Harvard Professor, ""We are Building Artificial Brains and Uploading Mind in to Cloud.""",https://www.reddit.com/r/deeplearning/comments/66bgqs/harvard_professor_we_are_building_artificial/,scidem,1492620845,,0,1
42,2017-4-20,2017,4,20,7,66dixd,Caffe2: Portable High-Performance Deep Learning Framework from Facebook | Parallel Forall,https://www.reddit.com/r/deeplearning/comments/66dixd/caffe2_portable_highperformance_deep_learning/,harrism,1492639976,,0,4
43,2017-4-20,2017,4,20,7,66dsoo,[CNN] Lower batch size leads to overfitting,https://www.reddit.com/r/deeplearning/comments/66dsoo/cnn_lower_batch_size_leads_to_overfitting/,RauanArgyn,1492642710,"Hello everyone. I am trying to train a CNN to recognize facial expressions. I use FER 2013 dataset by Kaggle.


I use SGD with mini-batch. I have been playing with different values and observed that lower batch size values lead to overfitting. 

Please check these two graphs:

**1. Batch-size = 128** http://imgur.com/5iJp0zg

&gt; You can see the validation loss starts to increase after 10 epochs indicating the model starts to overfit. At the same time, the validation accuracy does not increase, so the model does output correct predictions but does so less confidently.

**2. Batch-size = 256** http://imgur.com/YGwRKHy

&gt; Exactly the same hyper-parameters, apart from the batch-size. In this case there is no overfitting, the validation loss just plateaus.

The following are my hyper-parameters:

Hyper-parameter| Value|
--------- | --------- |
Number of epochs| 30
L2 regularization term| 0.0001
Momentum| 0.9

I have tried increasing the regularization strength, it does not help. 

I should mention I use Caffe with Nvidia Digits. FC layers also contain dropout, with ratio=0.5 to prevent the network from overfitting. 

Can anyone suggest a reason why lower batch size leads to overfitting? I do realise large batch sizes allowsmore precise estimates of the gradients, but in this case I would expect the loss to oscillate around some value and not just increase monotonically. 

The following is my network arch:  
&gt;&gt;INPUT(48x48)  
CONV1(3x3, 64 filters, zero-pad=1, stride=1)  
ReLU  
CONV2(3x3, 64 filters, zero-pad=1, stride=1)  
ReLU  
POOL1(stochastic, 3x3, stride=2)  
CONV3(3x3, 128 filters, zero-pad=1, stride=1)  
ReLU  
CONV4(3x3, 128 filters, zero-pad=1, stride=1)  
ReLU  
POOL2(stochastic, 3x3, stride=2)  
CONV5(3x3, 256 filters, zero-pad=1, stride=1)  
ReLU  
CONV6(3x3, 256 filters, zero-pad=1, stride=1)  
ReLU  
POOL3(stochastic, 3x3, stride=2)  
FC1(1024 neurons)  
Dropout(ratio=0.5)  
FC2(1024 neurons)  
Dropout(ratio=0.5)  
FC7(7 neurons)  
Softmax(7 scores)  ",4,3
44,2017-4-20,2017,4,20,8,66e024,Facebook builds brain-computer interface for typing-from-thoughts and skin-hearing. Crazy!!,https://www.reddit.com/r/deeplearning/comments/66e024/facebook_builds_braincomputer_interface_for/,scidem,1492644891,,0,1
45,2017-4-20,2017,4,20,10,66ei76,Building Artificial Intelligence Together,https://www.reddit.com/r/deeplearning/comments/66ei76/building_artificial_intelligence_together/,datmo_io,1492650476,,0,1
46,2017-4-20,2017,4,20,16,66g8x0,[P]Collection of Minimal Reinforcement Learning Implementations,https://www.reddit.com/r/deeplearning/comments/66g8x0/pcollection_of_minimal_reinforcement_learning/,hr_yang,1492673783,,0,7
47,2017-4-20,2017,4,20,23,66i7hd,A guide to receptive field arithmetic for CNNs,https://www.reddit.com/r/deeplearning/comments/66i7hd/a_guide_to_receptive_field_arithmetic_for_cnns/,Nikasa1889,1492700175,,0,1
48,2017-4-21,2017,4,21,1,66iypf,What artificial intelligence can and can't do now? Does AI have moral?,https://www.reddit.com/r/deeplearning/comments/66iypf/what_artificial_intelligence_can_and_cant_do_now/,scidem,1492706986,,0,1
49,2017-4-21,2017,4,21,9,66lt4l,Photo Editing with Generative Adversarial Networks (Part 1),https://www.reddit.com/r/deeplearning/comments/66lt4l/photo_editing_with_generative_adversarial/,harrism,1492734004,,0,2
50,2017-4-21,2017,4,21,16,66nsdw,Analyzing Patents for Prior Art,https://www.reddit.com/r/deeplearning/comments/66nsdw/analyzing_patents_for_prior_art/,barnyardman,1492760437,Is there anything promising in this idea?  I don't know if this would be too complex of a concept as I haven't done much NLP.,3,0
51,2017-4-21,2017,4,21,19,66oago,How to set up Tensorflow with CUDA and cuDNN on a free Google Cloud Instance (and perform style transfer),https://www.reddit.com/r/deeplearning/comments/66oago/how_to_set_up_tensorflow_with_cuda_and_cudnn_on_a/,tftutorial,1492769472,,0,6
52,2017-4-21,2017,4,21,19,66odzb,Confusion about the transposed convolution implementation in caffe,https://www.reddit.com/r/deeplearning/comments/66odzb/confusion_about_the_transposed_convolution/,aragakiyuigaki,1492771046,"Q1: Deconv 

Hi there, I recently read the doc about the deconvolution (also be deemed as transposed convolution) implementation in the caffe framework. In the doc, it is mentioned that :


""
ConvolutionLayer computes each output value by dotting an input window with a filter; DeconvolutionLayer multiplies each input value by a filter elementwise, and sums over the resulting output windows. In other words, DeconvolutionLayer is ConvolutionLayer with the forward and backward passes reversed. DeconvolutionLayer reuses ConvolutionParameter for its parameters, but they take the opposite sense as in ConvolutionLayer (so padding is removed from the output rather than added to the input, and stride results in upsampling rather than downsampling).
""


It says that the deconvolution layer reuses convolutionParameter for its parameters. So, my question is that why not learn the parameters instead of just taking the learnt parameters of the convolution layer?

Q2: GAN

In adversarial networks, we can add a N-by-N noise to the original N-by-N image so as to fool the CNN model. The sign of the element in the N-by-N noise matrix should be the same as that in the gradient matrix. So, if we add a regularizer to constrain the gradient to satisfy that for each real image, the gradient to each pixel should be as close as possible to zero, will that help to solve this problem?",0,1
53,2017-4-22,2017,4,22,0,66psa2,Earth Day 2017: Tackling Climate Science With Deep Learning,https://www.reddit.com/r/deeplearning/comments/66psa2/earth_day_2017_tackling_climate_science_with_deep/,teamrework,1492787456,,0,1
54,2017-4-22,2017,4,22,0,66pt7x,"Facebook Open Sources Caffe2; Nvidia, Intel Rush to Optimize",https://www.reddit.com/r/deeplearning/comments/66pt7x/facebook_open_sources_caffe2_nvidia_intel_rush_to/,Kindlychung,1492787694,,1,6
55,2017-4-24,2017,4,24,18,67819k,compile pytorch with ICC (intel c++ compiler),https://www.reddit.com/r/deeplearning/comments/67819k/compile_pytorch_with_icc_intel_c_compiler/,niraj_vara,1493026518,"Hi

    I have the GPU server and I have install the nvidia drivers, cuda cudnn and intel python and other related packages in docker images.

I have installed the pytorch and running pytorch test scripts alos.  But  to measure the performance I have install intel parallel studio (ICC) so  I want to check  with ICC any performance difference or not.

Please guide how to use ICC(intel c++ compiler) with pytorch to check performance improve or not ?",0,2
56,2017-4-25,2017,4,25,2,67apg4,Open Source Deep Learning Frameworks and Visual Analytics,https://www.reddit.com/r/deeplearning/comments/67apg4/open_source_deep_learning_frameworks_and_visual/,psangrene,1493056412,,0,2
57,2017-4-25,2017,4,25,16,67f61o,question and problem about LSTM Keras implantation,https://www.reddit.com/r/deeplearning/comments/67f61o/question_and_problem_about_lstm_keras_implantation/,davido1221,1493106825,"can a lstm in keras process a sequence of tensors ? 
for example an lstm layer will have an input of (None,100,200,20)?
the problem is I have a matrix of words (a matrix that each row is a sentence ) that goes  through an embedding layers that adds a dim and the lstm expects a 3 dim input shape but gets 4 is there a way to go around it?",1,2
58,2017-4-25,2017,4,25,22,67goc9,Discovering Extrasolar Planets with Deep Learning,https://www.reddit.com/r/deeplearning/comments/67goc9/discovering_extrasolar_planets_with_deep_learning/,teamrework,1493128439,,0,1
59,2017-4-25,2017,4,25,23,67gqmc,Implementation of Wasserstein GAN in Torch,https://www.reddit.com/r/deeplearning/comments/67gqmc/implementation_of_wasserstein_gan_in_torch/,fonfonx,1493129084,,0,5
60,2017-4-26,2017,4,26,0,67h48p,Automatically Detect Objects in Satellite Imagery using Deep Learning,https://www.reddit.com/r/deeplearning/comments/67h48p/automatically_detect_objects_in_satellite_imagery/,DGKevin,1493132788,,0,1
61,2017-4-26,2017,4,26,4,67iuo1,Build with AI - Use deep learning in your applications,https://www.reddit.com/r/deeplearning/comments/67iuo1/build_with_ai_use_deep_learning_in_your/,deepaihost,1493148351,,0,0
62,2017-4-26,2017,4,26,11,67l8nk,Photo Editing with Generative Adversarial Networks (Part 2),https://www.reddit.com/r/deeplearning/comments/67l8nk/photo_editing_with_generative_adversarial/,harrism,1493172830,,0,4
63,2017-4-26,2017,4,26,21,67ntsu,Creating Synthetic Clouds in Python,https://www.reddit.com/r/deeplearning/comments/67ntsu/creating_synthetic_clouds_in_python/,geodawg,1493210135,,0,2
64,2017-4-27,2017,4,27,1,67p8pl,VAE_DCGAN implemented in pytorch,https://www.reddit.com/r/deeplearning/comments/67p8pl/vae_dcgan_implemented_in_pytorch/,seangal2,1493223979,,0,2
65,2017-4-27,2017,4,27,2,67phv8,Writing Travel Blog Posts with Deep Learning,https://www.reddit.com/r/deeplearning/comments/67phv8/writing_travel_blog_posts_with_deep_learning/,goncalogordo,1493226274,,0,1
66,2017-4-27,2017,4,27,5,67r0xw,Deep learning for time series made easy: Dafne van Kuppevelt,https://www.reddit.com/r/deeplearning/comments/67r0xw/deep_learning_for_time_series_made_easy_dafne_van/,Mussem17,1493240393,,0,3
67,2017-4-27,2017,4,27,6,67r14x,"Deep Learning at Booking.com: Emrah Tasli, Stas Girkin",https://www.reddit.com/r/deeplearning/comments/67r14x/deep_learning_at_bookingcom_emrah_tasli_stas/,Mussem17,1493240440,,0,3
68,2017-4-27,2017,4,27,20,67v3ph,Read to know why do we need the Democratization of Machine Learning?,https://www.reddit.com/r/deeplearning/comments/67v3ph/read_to_know_why_do_we_need_the_democratization/,kailashahirwar12,1493294099,,1,1
69,2017-4-27,2017,4,27,21,67vbnn,Scripts to install and setup Tensorflow and it's dependencies on Ubuntu.,https://www.reddit.com/r/deeplearning/comments/67vbnn/scripts_to_install_and_setup_tensorflow_and_its/,kailashahirwar12,1493296767,,0,1
70,2017-4-28,2017,4,28,3,67xmry,Data Science - Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/67xmry/data_science_deep_learning_in_python/,vasira,1493318450,,0,0
71,2017-4-28,2017,4,28,6,67yt4g,Is anyone making money by using deep learning in trading?,https://www.reddit.com/r/deeplearning/comments/67yt4g/is_anyone_making_money_by_using_deep_learning_in/,MaverickSoulprorer,1493329367,,1,5
72,2017-4-28,2017,4,28,13,680xwp,"Eldritch by Omni Dragon Development, Inc.",https://www.reddit.com/r/deeplearning/comments/680xwp/eldritch_by_omni_dragon_development_inc/,OmniDragonDevelopmen,1493353685,,0,1
73,2017-4-28,2017,4,28,17,681cku,Best hardware for Deep Learning with 2000$ USD as budget,https://www.reddit.com/r/deeplearning/comments/681cku/best_hardware_for_deep_learning_with_2000_usd_as/,Driiper,1493367456,"As the title says, anyone have tweaks on my current setup for Deep Learning?
There might also be some CPU intensive calculations like tree-search but GPU is main focus
#------------------------------------------------------------------------
Mainboard: ZOTAC GeForce GTX 1080 Ti AMP Extreme

Memory: Crucial Ballistix Sport DDR4 32GB RED

HDD: Samsung 960 EVO 250GB M.2 PCIe SSD

PSU: EVGA GQ 1000W Hybrid Modular 80+ PSU

CPU: Intel Core i7-7700K Kaby Lake Prosessor

MOBO: MSI X99A RAIDER, Socket-2011-3
#------------------------------------------------------------------------


This hardware is primarily for development so it is fine that its consumer hardware.
Is there any considerations which can improve this setup?",7,3
74,2017-4-28,2017,4,28,22,682rs6,Run Object Detection using Deep Learning on Raspberry Pi 3 - II,https://www.reddit.com/r/deeplearning/comments/682rs6/run_object_detection_using_deep_learning_on/,kailashahirwar12,1493387746,,2,6
75,2017-4-29,2017,4,29,2,6840wp,Deep Learning Cheat Sheet (using Python Libraries),https://www.reddit.com/r/deeplearning/comments/6840wp/deep_learning_cheat_sheet_using_python_libraries/,psangrene,1493399900,,1,5
76,2017-4-29,2017,4,29,21,6891xf,Using Deep Learning and Machine Learning in emotion detection technology,https://www.reddit.com/r/deeplearning/comments/6891xf/using_deep_learning_and_machine_learning_in/,parth10,1493468160,,0,1
77,2017-4-29,2017,4,29,22,689fqh,The Modern History of Object Recognition  Infographic,https://www.reddit.com/r/deeplearning/comments/689fqh/the_modern_history_of_object_recognition/,Nikasa1889,1493474022,,0,3
78,2017-4-30,2017,4,30,7,68c3dp,Separating Overlapping Chromosomes with Deep Learning,https://www.reddit.com/r/deeplearning/comments/68c3dp/separating_overlapping_chromosomes_with_deep/,mwakanosya,1493504583,,1,1
79,2017-4-30,2017,4,30,8,68ch80,How to use Magenta and Tensorflow to generate music in a free Google Cloud instance,https://www.reddit.com/r/deeplearning/comments/68ch80/how_to_use_magenta_and_tensorflow_to_generate/,tftutorial,1493509307,,1,2
80,2017-4-30,2017,4,30,9,68cu2s,Top 9 Deep Learning and Neural Networks Books,https://www.reddit.com/r/deeplearning/comments/68cu2s/top_9_deep_learning_and_neural_networks_books/,kjahan,1493513817,,0,1
0,2017-5-2,2017,5,2,1,68n3e8,Generative Adversarial Networks,https://www.reddit.com/r/deeplearning/comments/68n3e8/generative_adversarial_networks/,[deleted],1493657128,[deleted],2,0
1,2017-5-2,2017,5,2,19,68sa3t,"Resolution of pairs of overlapping chromosomes by semantic segmentation, results from the cooperation.",https://www.reddit.com/r/deeplearning/comments/68sa3t/resolution_of_pairs_of_overlapping_chromosomes_by/,jean-pat,1493720023,,0,0
2,2017-5-2,2017,5,2,21,68syeb,Top 5 Key Areas: Deep Learning in Retail &amp; Advertising,https://www.reddit.com/r/deeplearning/comments/68syeb/top_5_key_areas_deep_learning_in_retail/,teamrework,1493729900,,0,0
3,2017-5-3,2017,5,3,0,68tz0l,"Understand deep residual networks - a simple, modular learning framework that has redefined state-of-the-art",https://www.reddit.com/r/deeplearning/comments/68tz0l/understand_deep_residual_networks_a_simple/,wayaai,1493740607,,0,2
4,2017-5-3,2017,5,3,3,68uun3,Movie recommendations in terms of Deep Learning,https://www.reddit.com/r/deeplearning/comments/68uun3/movie_recommendations_in_terms_of_deep_learning/,tdionis,1493748876,,1,6
5,2017-5-3,2017,5,3,13,68y902,XOR problem with eras,https://www.reddit.com/r/deeplearning/comments/68y902/xor_problem_with_eras/,215_215,1493786055,"I have for some time gotten pretty bad results using the tool keras, and haven't been suspisous about the tool that much.. But I am beginning to be a bit concerned now.

I tried to see whether it could handle a simple XOR problem, and after 30000 epochs it still haven't solved it...

code:
https://pastebin.com/h5U67Bgh

results:
https://pastebin.com/KSWXk7KL

Is there something wrong with the tool - or am I doing something wrong??

",9,1
6,2017-5-4,2017,5,4,19,696m5s,Computer Vision News for the Algorithm Community - Magazine of May (with codes!),https://www.reddit.com/r/deeplearning/comments/696m5s/computer_vision_news_for_the_algorithm_community/,Gletta,1493892385,"Here is Computer Vision News of May, published by RSIP Vision, with 38 pages of exclusive content about computer vision, artificial intelligence, deep learning and image processing - with codes! It's free for everyone to read and subscribe. You can choose between HTML5 (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2017May/      and PDF ==&gt; http://www.rsipvision.com/computer-vision-news-2017-may-pdf/ 
Enjoy!",0,3
7,2017-5-4,2017,5,4,20,696v4l,Looking for the Appendix for 'Deterministic Policy Gradient Algorithms',https://www.reddit.com/r/deeplearning/comments/696v4l/looking_for_the_appendix_for_deterministic_policy/,Geilminister,1493896357,"I am reading the DeepMind paper: [Deterministic Policy Gradient Algorithms](http://proceedings.mlr.press/v32/silver14.pdf), where they reference an appendix. It isn't included in the PDF, and I can't find it online.

Does anybody have it, or know where to find it?",4,1
8,2017-5-5,2017,5,5,0,6988am,Finding corners of an image in another,https://www.reddit.com/r/deeplearning/comments/6988am/finding_corners_of_an_image_in_another/,passingtime23,1493912101,Does anyone have resources or studies regarding finding an image into another? I'd be interested into finding the 4 points of a 'bounding box' that encompasses an image (pattern) into a bigger one (search space).,2,1
9,2017-5-5,2017,5,5,4,699mpz,The VisDA challenge aims to test domain adaptation methods ability to transfer source knowledge and adapt it to novel target domains. The goal is to develop a method of unsupervised syntetic-to-real domain adaptation.,https://www.reddit.com/r/deeplearning/comments/699mpz/the_visda_challenge_aims_to_test_domain/,bbminner,1493925119,,0,2
10,2017-5-5,2017,5,5,15,69d3sk,Detect whether or not a video is dashcam footage (or footage of the road),https://www.reddit.com/r/deeplearning/comments/69d3sk/detect_whether_or_not_a_video_is_dashcam_footage/,DivergenceOfThought,1493966244,Any suggestions? I am using cv2 but can use a different library if needed.,7,2
11,2017-5-6,2017,5,6,7,69huo8,Interesting tool for keeping track of your models. Video at the bottom.,https://www.reddit.com/r/deeplearning/comments/69huo8/interesting_tool_for_keeping_track_of_your_models/,pennyfx,1494023906,,0,2
12,2017-5-6,2017,5,6,14,69jlt0,Overview of deep learning?,https://www.reddit.com/r/deeplearning/comments/69jlt0/overview_of_deep_learning/,dbsopinion,1494047907,I'm trying to find a guide that will overview deep learning. What have you found to be helpful when getting started?,5,0
13,2017-5-8,2017,5,8,0,69rr8f,"Deep Learnings Impact on Image Processing, Mathematics, and Humanity",https://www.reddit.com/r/deeplearning/comments/69rr8f/deep_learnings_impact_on_image_processing/,Mymelodii,1494170047,,1,1
14,2017-5-8,2017,5,8,12,69vsue,Automatic Speech Recognition system in Tensorflow v0.10.0 release,https://www.reddit.com/r/deeplearning/comments/69vsue/automatic_speech_recognition_system_in_tensorflow/,zzw922cn,1494215143,,0,2
15,2017-5-8,2017,5,8,15,69wdfg,Does tensor in deep learning mean the same thing as in mathematics?,https://www.reddit.com/r/deeplearning/comments/69wdfg/does_tensor_in_deep_learning_mean_the_same_thing/,pkuwjf,1494223748,,2,1
16,2017-5-8,2017,5,8,22,69xzex,Artifician Neural Networks and Neuroscience,https://www.reddit.com/r/deeplearning/comments/69xzex/artifician_neural_networks_and_neuroscience/,NicolaBernini,1494249021,,2,0
17,2017-5-8,2017,5,8,23,69yirs,Agile Deep Learning For Modern Software Development (Interview with ML lead at Spotify),https://www.reddit.com/r/deeplearning/comments/69yirs/agile_deep_learning_for_modern_software/,reworksophie,1494254857,,0,1
18,2017-5-9,2017,5,9,4,6a0h6b,What are the biggest challenges of applying deep learning to the financial markets?,https://www.reddit.com/r/deeplearning/comments/6a0h6b/what_are_the_biggest_challenges_of_applying_deep/,Targaryen1947,1494273135,,4,10
19,2017-5-9,2017,5,9,23,6a5qcn,Automated text classification using deep learning algorithms,https://www.reddit.com/r/deeplearning/comments/6a5qcn/automated_text_classification_using_deep_learning/,parth10,1494340093,,0,1
20,2017-5-10,2017,5,10,6,6a8ddn,Deep learning for Sequence Tasks,https://www.reddit.com/r/deeplearning/comments/6a8ddn/deep_learning_for_sequence_tasks/,rahul_singh1288,1494364845,"I want to use deep learning techniques to perform better inference tasks than Hidden Markov Models (which is a shallow model)? I was wondering what is the state-of-the art deep learning model to replace Hidden Markov Models (HMM)? The set-up is semi-supervised. The training data X(t),Y(t) is a time series, with significant temporal correlations. Also, there is a huge amount of unlabelled data, i.e., simply X(t) and no Y(t). After reading many papers, I narrowed down on the following model -&gt; Conditionally Restricted Boltzmann Machines (Ilya Sustkever MS thesis) and use Deep Belief Networks for unsupervised pretraining (or use variational autoencoders for pretraining). I am very new to the field, and was wondering if these techniques are outdated. 
",9,1
21,2017-5-10,2017,5,10,17,6abhsn,What's Next For Virtual Assistants &amp; Deep Learning?,https://www.reddit.com/r/deeplearning/comments/6abhsn/whats_next_for_virtual_assistants_deep_learning/,reworksophie,1494404149,,0,1
22,2017-5-11,2017,5,11,2,6aebcv,"Resnet overfitting on Imagenet pretrained model, but not from scratch",https://www.reddit.com/r/deeplearning/comments/6aebcv/resnet_overfitting_on_imagenet_pretrained_model/,princedhiman,1494437936,"Hi Redditers, 
Please help me resolve a problem.
I have a data-set of 20K multi-label images for three classes. I am using Resnet-50 to train a classifier for this data-set (loss function: binary entropy with sigmoid in the end).
If trained using ImageNet pre-trained model, training accuracy reaches 100%, and validation accuracy 93%.
But If trained from scratch, then it reaches only 90% training accuracy.",9,1
23,2017-5-11,2017,5,11,15,6aii40,How can one get accepted into Google Brain Residency Program?,https://www.reddit.com/r/deeplearning/comments/6aii40/how_can_one_get_accepted_into_google_brain/,[deleted],1494485077,[deleted],0,0
24,2017-5-11,2017,5,11,20,6ajk4f,A good article for those getting started with Deep Learning,https://www.reddit.com/r/deeplearning/comments/6ajk4f/a_good_article_for_those_getting_started_with/,saloni_ba,1494502819,,0,2
25,2017-5-12,2017,5,12,2,6aljth,"Maybe useful slides for an overview of Deep Learning techniques (Neural networks, CNNs, RNNs, and toolboxes)",https://www.reddit.com/r/deeplearning/comments/6aljth/maybe_useful_slides_for_an_overview_of_deep/,[deleted],1494523137,[deleted],0,0
26,2017-5-12,2017,5,12,5,6ampgw,Learning to Estimate 3D Hand Pose from Single RGB Images,https://www.reddit.com/r/deeplearning/comments/6ampgw/learning_to_estimate_3d_hand_pose_from_single_rgb/,hellomichibye,1494533848,,1,2
27,2017-5-12,2017,5,12,7,6anect,Deep Learning Chatbot Assistant?,https://www.reddit.com/r/deeplearning/comments/6anect/deep_learning_chatbot_assistant/,[deleted],1494540803,[deleted],0,3
28,2017-5-12,2017,5,12,20,6aqspo,Fundamentals of Deep Learning (book) is now 34% off,https://www.reddit.com/r/deeplearning/comments/6aqspo/fundamentals_of_deep_learning_book_is_now_34_off/,krenksn,1494589525,,0,1
29,2017-5-12,2017,5,12,22,6ar8ez,Deep Learning as music teachers?,https://www.reddit.com/r/deeplearning/comments/6ar8ez/deep_learning_as_music_teachers/,ahorsefish,1494595069,"First post on this sub.
I am a professional classical musician and teacher, I am also an amateur Go player.  I have been intrigued by machine learning since Alphago...

Lately I have been wondering the possiblity of using machine learning technique to teach basic level of musicianship training...
There are many attempts to use A.I. and machine learning in music but the focus always seem to be on the quantifiable physical quality of sound and music,  like the frequency,  speed,  or harmonic structure etc... in essence,  things that machines are good at identifying.

I wonder if there is any possibility to train a computer to hear music like human.
Like, for entry level music classes.  The ""material"" (simple melodies,  or ryhthms) are relatively straight forward and the ""results"" are usually rather objective,  in comparison with sth like a Beethoven symphony.
I am sure many of us have this experience in music class:  we sing something,  and the teacher would say, ""this note is wrong. "" ""don't slow down here. "" ""be careful in the end"" etc...
I am thinking,  can't we teach a machine to do that?

Rather than finding ""solutions"" we can teach a machine to be a guide on these simple things,  let's say first year or music class of a school children.  I understand it is a rather vague comparison but these things don't seem to be more complicated than the game of Go.

If we keep things simple,  like 100 simple melodies,  the rules can be quite objective and leaves very little room for personal interpretation.  In that case,  is it feasible to teach a machine to become a proficient ""teacher"" in this 100 melodies?

Thx for reading and pls excuse me for my complete lack of knowledge in programming &amp; computer.  Just want to share this idea with someone. ",2,0
30,2017-5-13,2017,5,13,6,6au7ch,Microsoft launches a new service for training deep neural networks on Azure,https://www.reddit.com/r/deeplearning/comments/6au7ch/microsoft_launches_a_new_service_for_training/,dannyeuu,1494625274,,0,3
31,2017-5-13,2017,5,13,22,6axrkf,Will using deep learning in trading work?,https://www.reddit.com/r/deeplearning/comments/6axrkf/will_using_deep_learning_in_trading_work/,malobika,1494681346,[removed],0,1
32,2017-5-14,2017,5,14,10,6b1kfu,Google DeepMind Wavenet text-to-speech algorithm,https://www.reddit.com/r/deeplearning/comments/6b1kfu/google_deepmind_wavenet_texttospeech_algorithm/,dylxnxil,1494727119,"Here is the YouTube link: https://www.youtube.com/watch?v=zg3Ouup_09o&amp;t=37s. I was wondering if it would be possible to recreate this or something similar, and how to do that. I did some google searches and I can't seem to find this anywhere. Is there anywhere I'm not looking? How would I be able to implement something like this? Sorry if this was confusing and I would greatly appreciate any advice. Thanks!",4,2
33,2017-5-14,2017,5,14,15,6b2jv4,"Is MicrosoftComputerVision API better than Google, Amazon?",https://www.reddit.com/r/deeplearning/comments/6b2jv4/is_microsoftcomputervision_api_better_than_google/,aprl_la,1494742600,I was looking at the https://rapidapi.com/package/MicrosoftComputerVision this api and it has most number of installs. (Way higher than Amazon and Google's equivalent). ,2,2
34,2017-5-14,2017,5,14,20,6b3crm,Deep Learning and Kernels,https://www.reddit.com/r/deeplearning/comments/6b3crm/deep_learning_and_kernels/,NicolaBernini,1494759636,"It seems to me that Deep Learning is mostly about performing an effective Representation Learning. One of the main idea (which justifies the deep nature of this learning strategy) here is to develop a Hierarchical Multi-Layer representation, moving from a High Dimensional Input Space (e.g. the Image Space) to more Abstract and Lower Dimensional Spaces. 
In Supervised Learning, the Representation(s) Learned is (are) biased to allow for a (easy, to some extent) solution of a certain task and indeed final layers are typically classical ones (e.g. Logistic Regression on top of a CNN Stack for Object Classification) 

So basically this idea looks similar to the Kernel based Strategies one: instead of solving a problem in the Input Space looking for a very complex function (i.e. searching over a huge hypothesis space) its better to investigate the possibility of developing a projection into a space where the solution can be easier (i.e. reducing the hypothesis space): so instead of learning a complex nonlinear classification function in the input space its better to develop a mapping into an intermediate abstract space where the solution can be a linear classifier. 

The different I see is that in Kernel based Strategies, like SVM, the Kernel is a prior typically defined as a result of some domain expertise, while in DL based Strategies, like CNN, the Convolutional Kernels are learned from Data. 
However it does not mean CNNs do not need any prior: they actually do but they are at the level of Learning Machine, like Architecture related Priors (e.g. number of layers, connections, ...) and Convolutional Kernel related Priors (e.g. size, stride, ...) 

What do you think ? 

Thanks 
",5,10
35,2017-5-15,2017,5,15,22,6bacns,Deep Learning Explained From Scratch,https://www.reddit.com/r/deeplearning/comments/6bacns/deep_learning_explained_from_scratch/,pooja_edureka,1494854578,,0,3
36,2017-5-16,2017,5,16,23,6bhxdg,Adversarial learning  w/ Wasserstein GAN,https://www.reddit.com/r/deeplearning/comments/6bhxdg/adversarial_learning_w_wasserstein_gan/,wayaai,1494946360,,1,3
37,2017-5-17,2017,5,17,4,6bjonc,Visual Domain Adaptation Challenge 2017,https://www.reddit.com/r/deeplearning/comments/6bjonc/visual_domain_adaptation_challenge_2017/,nkaushik1,1494963158,,0,2
38,2017-5-17,2017,5,17,5,6bk2n5,PhD chance with 2.33 masters GPA?,https://www.reddit.com/r/deeplearning/comments/6bk2n5/phd_chance_with_233_masters_gpa/,pete0273,1494967001,Published two papers in undergrad and presented at a national conference and two regional conferences but in grad school I interned a bunch (deep learning for prescription reccomendation) and let my GPA tank. How screwed am I?,9,1
39,2017-5-17,2017,5,17,23,6bp0q6,Radeon Vega Frontier Edition,https://www.reddit.com/r/deeplearning/comments/6bp0q6/radeon_vega_frontier_edition/,RadeonVegaFrontier,1495031220,"Hi r/deeplearning,

This is the AMD Radeon team here to say hi to the community. We have recently launched our Radeon Vega Frontier Edition graphics card, designed for machine + deep learning and advanced visualization.

We would like to invite you to an AMA this Thursday at 2PM PST on r/AMD with AMDs Raja Koduri to discuss what the Radeon Vega Frontier Edition means for the future of scientists, data analysts and professionals.

http://pro.radeon.com/en-us/vega-frontier-edition/

Hope to see you there!",0,6
40,2017-5-18,2017,5,18,6,6brwir,Pre-Trained model for faster-RCNN,https://www.reddit.com/r/deeplearning/comments/6brwir/pretrained_model_for_fasterrcnn/,forthoseaboutcaca,1495058140,"I'm looking for a pre-trained model for rcnn, fast-rcnn or faster-rcnn, trained with 1000 clases, preferably with imagenet dataset.

The faster-rcnn repository using caffe: https://github.com/KuoHaoZeng/py-faster-rcnn-ImageNet-Det has a pretrained model on imagenet but only has 20 clases.

Someone knows about a pretrained model with 1000 clases? training myself is not an option because i dont have the space for the dataset. I already look and found nothing, maybe it doesn't exist, but if someone know about a model it will be very helpful.

I'm currently working on a research in my university and need this to move forward. Not finding this will require to change entirely the approach we been taking.

Thank you very much.",2,1
41,2017-5-18,2017,5,18,18,6bv1l3,How AI Startups Must Compete with Google: Reply to Fei-Fei Li,https://www.reddit.com/r/deeplearning/comments/6bv1l3/how_ai_startups_must_compete_with_google_reply_to/,mostafabenh,1495098474,,8,0
42,2017-5-19,2017,5,19,4,6bynxn,"Deep Learning in Trading. Presentation slides of Gaurav Chakravorty at The Trading Show, Chicago.",https://www.reddit.com/r/deeplearning/comments/6bynxn/deep_learning_in_trading_presentation_slides_of/,qplum,1495137231,,4,7
43,2017-5-19,2017,5,19,5,6bys4d,Chosen books For Data Science,https://www.reddit.com/r/deeplearning/comments/6bys4d/chosen_books_for_data_science/,WTSxDev,1495138295,,1,2
44,2017-5-20,2017,5,20,18,6c9gwp,Installing NVidia GeForce 1070TX Graphics Card in HP OMEN-17-w250tx (Linux) without login loop issue,https://www.reddit.com/r/deeplearning/comments/6c9gwp/installing_nvidia_geforce_1070tx_graphics_card_in/,advig,1495271213," I am looking to procure a new laptop for my deep learning application. I am considering HP OMEN - 17-w250tx with 8GB NVidia GeForce 1070TX Graphics Card.
I will be installing Ubuntu 14.04 in this machine. I am not sure about the support for this graphic card on Ubuntu 14.04.
1.     Has anyone tried out installing NVidia GeForce 1070TX on Ubuntu 14.04 on the same or similar laptops?
2.     Have anyone faced login loop issues due to the installation?
3.     How to solve the login loop issue for this particular issue?
4.     Request for a step by step procedure to install NVidia GeForce 1070TX on HP OMEN - 17-w250tx with Ubuntu 14.04",5,1
45,2017-5-20,2017,5,20,18,6c9hyh,Deep Learning library for TensorFlow for building end to end models and experiments.,https://www.reddit.com/r/deeplearning/comments/6c9hyh/deep_learning_library_for_tensorflow_for_building/,pipado,1495271876,,0,3
46,2017-5-22,2017,5,22,17,6clz2f,Can someone explain this binary classification accuracy calculation?,https://www.reddit.com/r/deeplearning/comments/6clz2f/can_someone_explain_this_binary_classification/,burn_in_flames,1495440729,"I have began to play around with Keras, and have noticed that many of the examples do not use the built in Keras accuracy metrics but rather their own accuracy function which they run the y_pred values through in relation to y_true.

The function is used for computing the accuracy of binary classification [0,1] but I do not understand why it works, as even on a small example I can see it is incorrect.

The function in the Keras example code is:

def compute_accuracy(predictions, labels): 
return labels[predictions.ravel()&lt;0.5].mean() 

However, if we use the example of

labels = [0,1,1,1] 
predictions = [0.2, 0.6, 0.7, 0.3] 

we can see that the classifier only got one of the predictions incorrect (0.3 was labelled as 1 instead of 0). However in this case the above accuracy function says that the accuracy is 0.5 and not 0.75. Furthermore, if using the binary accuracy metric within Keras, I get completely different accuracy results.",3,1
47,2017-5-22,2017,5,22,18,6cmb71,"First speakers announced for REWORK Deep Learning Summit in Canada include Yoshua Bengio, Yann LeCun, Geoff Hinton, Aaron Courville, Roland Memisevic",https://www.reddit.com/r/deeplearning/comments/6cmb71/first_speakers_announced_for_rework_deep_learning/,reworksophie,1495446695,,0,1
48,2017-5-22,2017,5,22,18,6cmc56,Deep learning for best fitting shape,https://www.reddit.com/r/deeplearning/comments/6cmc56/deep_learning_for_best_fitting_shape/,arijitiit,1495447137,"How do you use deep learning (say networks like Alexnet or VGG16) to find the best fitting square for a given figure.
Let me put it in other way, given a circle or a square, how will you use the network to predict the Centre and radius for the circle and Length, breadth and 2 points of the square.

Edit:-
INPUT :- http://imgur.com/doSVKqU  OUTPUT :- Centre - 120,160 RADIUS 35 

INPUT :- http://imgur.com/bDti98c      OUTPUT :- LENGTH 35 BREADTH 20 ROTATION ANGLE : 45 degrees POINT 30,40 

Something like this",7,2
49,2017-5-22,2017,5,22,20,6cmsgg,"Advances in AI &amp; Deep Learning: DeepMind, Facebook &amp; OpenAI",https://www.reddit.com/r/deeplearning/comments/6cmsgg/advances_in_ai_deep_learning_deepmind_facebook/,reworksophie,1495454160,,0,1
50,2017-5-24,2017,5,24,0,6cv9s4,Spotify Has Acquired Machine-Learning Startup Niland,https://www.reddit.com/r/deeplearning/comments/6cv9s4/spotify_has_acquired_machinelearning_startup/,dannyeuu,1495552489,,0,10
51,2017-5-24,2017,5,24,1,6cvlsv,18 online courses on Deep Learning,https://www.reddit.com/r/deeplearning/comments/6cvlsv/18_online_courses_on_deep_learning/,smartsg,1495555624,,0,1
52,2017-5-24,2017,5,24,1,6cvnm2,Need help with my first NN /w backpropagation in Theano,https://www.reddit.com/r/deeplearning/comments/6cvnm2/need_help_with_my_first_nn_w_backpropagation_in/,[deleted],1495556084,[deleted],0,1
53,2017-5-24,2017,5,24,1,6cvswo,A curated list of resources about bayesian deep learning,https://www.reddit.com/r/deeplearning/comments/6cvswo/a_curated_list_of_resources_about_bayesian_deep/,psangrene,1495557418,,0,3
54,2017-5-24,2017,5,24,10,6cz0qd,Explaining How End-to-End Deep Learning Steers a Self-Driving Car,https://www.reddit.com/r/deeplearning/comments/6cz0qd/explaining_how_endtoend_deep_learning_steers_a/,harrism,1495589039,,0,4
55,2017-5-25,2017,5,25,1,6d32iv,Meet The World's Leading AI Pioneers in The 'Silicon Valley of Deep Learning',https://www.reddit.com/r/deeplearning/comments/6d32iv/meet_the_worlds_leading_ai_pioneers_in_the/,teamrework,1495641812,,0,4
56,2017-5-25,2017,5,25,15,6d7uwm,"Deep CorrNet for multi-view data: combining text, images, audio, etc.",https://www.reddit.com/r/deeplearning/comments/6d7uwm/deep_corrnet_for_multiview_data_combining_text/,bhatt_gaurav,1495692730,,0,6
57,2017-5-26,2017,5,26,22,6dh0mj,Computer build for deep learning,https://www.reddit.com/r/deeplearning/comments/6dh0mj/computer_build_for_deep_learning/,entirix,1495806119,"Hello!!

I'm a 3rd year Computer Science student at a decent university in Canada and I am interested to learn about deep learning and neural networks. I know it requires lot of computing power which is why I am thinking of building a powerful linux workstation. As of right now, I am thinking AMD Ryzen 1700, GTX 1060 should suffice. What do you all think?",11,7
58,2017-5-27,2017,5,27,0,6dhtbl,Applying CNN to *kind of* cross sectional data,https://www.reddit.com/r/deeplearning/comments/6dhtbl/applying_cnn_to_kind_of_cross_sectional_data/,amplexian,1495814307,"Hi everyone! I'm dealing with a dataset consisting in some anagraphic data about the users and a target dummy variable that I want to predict (which is subscribed or not). Besides the numerical fixed variables like age etc. I also have a time serie variable, which makes the things quite complex for me. I know how to adapt a CNN for binary classification with panel data, but what should I do when dealing with also (and not only) a time serie? Thanks in advance and keep up the amazing work!",3,2
59,2017-5-27,2017,5,27,15,6dm908,[Help] Noob here. I want a sample Python code for a project idea I have.,https://www.reddit.com/r/deeplearning/comments/6dm908/help_noob_here_i_want_a_sample_python_code_for_a/,notyourdaddy,1495866157,"Hello everyone,

Really sorry if this is a stupid question or a bad place to ask it. Let me know where to go and I will! 

My understanding of NNs is extremely limited and there's no way I will be able to learn and implement this on my own before next year. Therefore, I am hoping someone can redirect me to something similar which will allow me to customize the code to my needs and just make it work by next week hopefully. 

THE PROJECT:

So I want the program to take a picture of a person wearing glasses (from my HDD) and generate an image without the glasses. I believe I'll need to make use of a convolutional NN. I have 3000 images of 1500 people with and without glasses for training dataset already. Also, I have at my disposal a desktop PC with a GTX 1060.

Thank you for reading and any help will be appreciated! Thank you.",11,1
60,2017-5-27,2017,5,27,18,6dmtj1,Bring Magic To Your Mobile App With Deep Learning   Medium,https://www.reddit.com/r/deeplearning/comments/6dmtj1/bring_magic_to_your_mobile_app_with_deep_learning/,avihaya,1495877157,,0,3
61,2017-5-28,2017,5,28,5,6dptbe,"""Make your own neural network"" for 3.75 Kindle Edition in Germany (at least)",https://www.reddit.com/r/deeplearning/comments/6dptbe/make_your_own_neural_network_for_375_kindle/,HarryDell,1495916752,,0,0
62,2017-5-28,2017,5,28,5,6dpxc0,Open sourcing Sonnet - a new library for constructing neural networks | DeepMind,https://www.reddit.com/r/deeplearning/comments/6dpxc0/open_sourcing_sonnet_a_new_library_for/,vegax87,1495918042,,0,7
63,2017-5-30,2017,5,30,5,6e2pqw,Understanding Deep Learning - in 4 minutes,https://www.reddit.com/r/deeplearning/comments/6e2pqw/understanding_deep_learning_in_4_minutes/,CorsairsIn,1496090203,,1,0
64,2017-5-30,2017,5,30,15,6e5jyi,Essential Cheat Sheets for Machine Learning and Deep Learning Engineers,https://www.reddit.com/r/deeplearning/comments/6e5jyi/essential_cheat_sheets_for_machine_learning_and/,kailashahirwar12,1496124062,,2,31
65,2017-5-30,2017,5,30,18,6e6cws,Deep learning to code for you?,https://www.reddit.com/r/deeplearning/comments/6e6cws/deep_learning_to_code_for_you/,whitevo,1496137598,"On my free time I'm learning deep learning and searching for projects what could benefit my work.


I haven't found any projects which goal is to increase coding in general, doesn't matter what coding language.
There are projects what take text in and then make and or suggest improvements based on context, but haven't found anything which train or simply generate code from ideas.


Since I'm pretty new to this I don't even know where to start when giving idea and then machines generates the code files.


So I though of simpler approach:
Make a desktop software where you talk in small code concepts and in real time it displays a result or multiple results.
And then with shortcut keys you pretty much copy paste the code snippets from the software.


Example how would it work.
You choose tab ""train"" from software.
Then you create a category (for example Lua)
then you record a message, like ""loop ipairs""
Then you type into text field what this message should represent
     
     for key, value in ipairs(table) do
     
    end

You can listen your recording or make several solutions for same outcome, but the software is trained to get the closest result anyway.
so you press train/ok
and now you choose tab code.
you can make the microphone be open all the time or make it while holding a certain key.
so whenever you say similar text speech you get this code line into software.
and with another shortcut key you can paste it on your code.


This would just be start of code helper software, could implement some macro keys by speech recognition, which open files or move your cursor to spesific point, etc.


What you think about this? does it already exists?
Does anyone want to make such software with me?

I'm going to make discord channel because I rarely check reddit:

My discord: whitevo#9715

Deep learning channel: https://discord.gg/bSmGddw",0,1
66,2017-5-31,2017,5,31,0,6e84dt,"Love this! Deep learning, apprendimento profondo, tiefes lernen, pembelajaran dalam... How do you say it?",https://www.reddit.com/r/deeplearning/comments/6e84dt/love_this_deep_learning_apprendimento_profondo/,reworksophie,1496159024,,0,1
67,2017-5-31,2017,5,31,2,6e8nl4,BOSTON DEEP LEARNING IN HEALTHCARE SUMMIT - DAY 2 HIGHLIGHTS,https://www.reddit.com/r/deeplearning/comments/6e8nl4/boston_deep_learning_in_healthcare_summit_day_2/,reworksophie,1496164017,,0,1
68,2017-5-31,2017,5,31,2,6e8qta,BOSTON DEEP LEARNING SUMMIT - DAY 1 HIGHLIGHTS,https://www.reddit.com/r/deeplearning/comments/6e8qta/boston_deep_learning_summit_day_1_highlights/,reworksophie,1496164812,,0,1
0,2017-6-1,2017,6,1,16,6el6nf,"A DL box for $1700. Assembly, setup and benchmarks",https://www.reddit.com/r/deeplearning/comments/6el6nf/a_dl_box_for_1700_assembly_setup_and_benchmarks/,slavivanov,1496301686,,0,11
1,2017-6-2,2017,6,2,5,6epfir,Artificial Intelligence in Perspective,https://www.reddit.com/r/deeplearning/comments/6epfir/artificial_intelligence_in_perspective/,towk22,1496347960,,0,0
2,2017-6-2,2017,6,2,13,6escir,[N] Chainer version 2.0 released!,https://www.reddit.com/r/deeplearning/comments/6escir/n_chainer_version_20_released/,[deleted],1496379515,[deleted],0,1
3,2017-6-2,2017,6,2,20,6etvae,Can transfer learning be applied to detecting faults like cracks?,https://www.reddit.com/r/deeplearning/comments/6etvae/can_transfer_learning_be_applied_to_detecting/,__The_Coder__,1496403938,"Can modes like VGG/ inception be used to detect if there is a crack in a pipe and similar  other defects, if I have the data for each class. What other methods can be used for this purpose? Thank you.",4,1
4,2017-6-3,2017,6,3,1,6evabl,Noob here... can you help me get started with this project?,https://www.reddit.com/r/deeplearning/comments/6evabl/noob_here_can_you_help_me_get_started_with_this/,ap711,1496419411,"I want to start by saying I am very new to neural networks and coding. I have been thinking about a project, but I am unsure of how to start. I am working with MATLAB. I want to train a network to detect whether an audio file contains a male voice or a female voice in a noisy environment. I have been looking at the neural networking toolbox, but it looks like the sample data provided is not necessarily dependent on each other. The frequency value in my data is strictly dependent on its position in time. I have no idea how to show this relationship in code. Any help is appreciated. ",1,2
5,2017-6-4,2017,6,4,23,6f7h6z,Deep Learning Architecture Question,https://www.reddit.com/r/deeplearning/comments/6f7h6z/deep_learning_architecture_question/,Jsarseno,1496584986,"Hey, I'm pretty new to deep learning and have been wondering what architecture is best for using if you have multiple scalars as your input (e.g. temperature, humidity, etc.) and want to train your neural network to output another scalar (e.g. % chance of rainfall). I would assume you would have to use different learning algorithms if time is independent so you can input any weather conditions and it will tell estimate the amount of rainfall, or if it is time dependent and the output also depends on the the previous data points?

I guess my question is which deep learning architecture (e.g. CNN, RNN, etc.) would be most useful in each of these time dependent and independent situations? What NNs work best for regression fitting data points and is polynomial regression usually the best way of creating a 'best fit model?'",5,2
6,2017-6-6,2017,6,6,1,6ff61r,Does understanding deep learning require rethinking generalisation?,https://www.reddit.com/r/deeplearning/comments/6ff61r/does_understanding_deep_learning_require/,[deleted],1496679235,[deleted],0,0
7,2017-6-7,2017,6,7,21,6ft0qx,Computer Vision News for the Algorithm Community - June (with codes!),https://www.reddit.com/r/deeplearning/comments/6ft0qx/computer_vision_news_for_the_algorithm_community/,Gletta,1496837550,"This is Computer Vision News of June, published by RSIP Vision, with 38 pages of exclusive content about computer vision, artificial intelligence, deep learning and image processing - with codes! It's free for everyone to read and subscribe.        
This month, don't miss a great review of the Mask R-CNN research by the Facebook Artificial Intelligence group (FAIR).       
As one of our engineers said: ""It's one of those works that people will talk about for years!""       
Judge by yourself at page 4...        
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2017June/         
and PDF version ==&gt; http://www.rsipvision.com/computer-vision-news-2017-june-pdf/             
Enjoy!",0,6
8,2017-6-7,2017,6,7,23,6ftxg4,What's the coolest term in deep learning that you know?,https://www.reddit.com/r/deeplearning/comments/6ftxg4/whats_the_coolest_term_in_deep_learning_that_you/,[deleted],1496847325,[deleted],4,4
9,2017-6-8,2017,6,8,17,6fzn16,Newbie qns on training images for deep learning,https://www.reddit.com/r/deeplearning/comments/6fzn16/newbie_qns_on_training_images_for_deep_learning/,thealchemist89,1496909598,"Hi everyone,

I'm a hobbyist and am fascinated with the coolness of deep learning. I have observed across numerous youtube videos and several publications where the training image resolution is generally more than 100 pixels x 100 pixels.

I like to ask, if I am interested to train and therefore detect objects other than handwritten digits with a resolution of say approximately 30 pixels x 30 pixels:

1) How does Deep Learning technique perform for training samples with small image resolutions?

2) What architecture/technique can I look into to explore further?

Thanks mates for your time in reading and sharing!

Cheers!",4,1
10,2017-6-8,2017,6,8,20,6g0a0j,Reasons to Switch from TensorFlow to CNTK,https://www.reddit.com/r/deeplearning/comments/6g0a0j/reasons_to_switch_from_tensorflow_to_cntk/,izmty,1496920107,,0,0
11,2017-6-9,2017,6,9,13,6g6com,Is a Geforce 1080 Ti worth it for ConvNets?,https://www.reddit.com/r/deeplearning/comments/6g6com/is_a_geforce_1080_ti_worth_it_for_convnets/,[deleted],1496984391,[deleted],13,3
12,2017-6-9,2017,6,9,16,6g6wkf,"Hi, I need some help.",https://www.reddit.com/r/deeplearning/comments/6g6wkf/hi_i_need_some_help/,Gauravvik,1496992609,"I am interested in deep learning. I am in college and do not have the money needed to build a full-on system, I have an average laptop: AMD A10 7310, 2GB AMD R265, 8GB RAM.

Is buying and configuring an external GPU an option?
Also, how do the cloud services go about?",5,0
13,2017-6-9,2017,6,9,23,6g8uv0,What OS is best for deep learning?,https://www.reddit.com/r/deeplearning/comments/6g8uv0/what_os_is_best_for_deep_learning/,[deleted],1497019667,[deleted],0,1
14,2017-6-9,2017,6,9,23,6g8v09,What OS is best for deep learning and why?,https://www.reddit.com/r/deeplearning/comments/6g8v09/what_os_is_best_for_deep_learning_and_why/,[deleted],1497019711,[deleted],0,1
15,2017-6-10,2017,6,10,2,6g9r1e,Natural Language Processing with Deep Learning,https://www.reddit.com/r/deeplearning/comments/6g9r1e/natural_language_processing_with_deep_learning/,artificialbrainxyz,1497028071,,0,1
16,2017-6-10,2017,6,10,12,6gd5ek,Unpaired Style Transfer,https://www.reddit.com/r/deeplearning/comments/6gd5ek/unpaired_style_transfer/,lucidrage,1497064659,"From what I understand in [this paper](https://junyanz.github.io/CycleGAN/), X and Y are the 2 styles and they used generator G to create Y-styled images and F to create X-styled images. The paper didn't really explain how they are trained though. Can anyone give me some plain English explanation on how they were trained?",2,2
17,2017-6-10,2017,6,10,15,6gdyam,"Super resolution - best implementation , anyone?",https://www.reddit.com/r/deeplearning/comments/6gdyam/super_resolution_best_implementation_anyone/,smahajan07,1497077591,"Hi. I am working on a project to **super resolve** images of faces from ID's like driver's license and match in real time with a user's image (like a selfie or clicked by someone). **The issue is that the image on the ID is generally distorted or low res, hence the super resolution.** 

Mostly research papers downsize all input images and then super resolve them, means we already lose info from pixels and then add info to it and the results are not up to the mark. 

Can anyone tell which state of the art method can be used to super resolve or enhance facial images so that they can be matched with another picture of the user?

Tried the following papers and their implementations from the following Github.
Paper 1 and implementation

* [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802)
* [Github](https://github.com/leehomyc/Photo-Realistic-Super-Resoluton)

Paper 2 and implementation (**Result is much better than paper 1**)

* [Pixel Recursive Super Resolution](https://arxiv.org/abs/1702.00783)
* [Github](https://github.com/nilboy/pixel-recursive-super-resolution)

Two reference links where this is being/could be used:
[Link 1](https://arstechnica.com/information-technology/2013/05/hallucinating-a-face-new-software-could-have-idd-boston-bomber/)
[Link 2](https://www.theguardian.com/australia-news/2017/jan/22/facial-recognition-to-replace-passports-in-security-overhaul-at-australian-airports)",0,1
18,2017-6-11,2017,6,11,4,6gh037,Is Ryzen 1800X or i7 7700K better for deep learning?,https://www.reddit.com/r/deeplearning/comments/6gh037/is_ryzen_1800x_or_i7_7700k_better_for_deep/,[deleted],1497122025,[deleted],2,5
19,2017-6-11,2017,6,11,19,6gkp56,Japan is offering solutions to various challenges through Deep Learning,https://www.reddit.com/r/deeplearning/comments/6gkp56/japan_is_offering_solutions_to_various_challenges/,artificialbrainxyz,1497176252,,1,2
20,2017-6-11,2017,6,11,23,6gljex,Multiclass classification,https://www.reddit.com/r/deeplearning/comments/6gljex/multiclass_classification/,Amrekameinbaitadesi,1497190008,"Hi a newbie here,

I was reading across object recognition papers and did some reading on how the architectures have evolved over time from Alexnet to Residualnet for object recognition. Then I even read up on a few papers that combine object detection + recognition such as faster-rcnn, Yolo.
Here are my generic doubts related to these topics
How many classes can you train at max with the classification algorithms? 
Is there an online learning algorithm which can keep on learning new classes but not forget the old ones? 
Can this online learning algorithm be combined with YOLO or faster-rcnn 

Appreciate any guidance!",0,0
21,2017-6-11,2017,6,11,23,6glp20,CFP: Workshop on Deep Learning for Autonomous Driving (DLAD 2017),https://www.reddit.com/r/deeplearning/comments/6glp20/cfp_workshop_on_deep_learning_for_autonomous/,[deleted],1497192015,[deleted],0,1
22,2017-6-11,2017,6,11,23,6glqwg,CFP: Workshop on Deep Learning for Autonomous Driving (DLAD 2017),https://www.reddit.com/r/deeplearning/comments/6glqwg/cfp_workshop_on_deep_learning_for_autonomous/,ysenthilece,1497192638,,1,3
23,2017-6-12,2017,6,12,1,6gmcx7,Setting up your GPU TensorFlow Docker platform,https://www.reddit.com/r/deeplearning/comments/6gmcx7/setting_up_your_gpu_tensorflow_docker_platform/,__me_again__,1497199505,,1,10
24,2017-6-12,2017,6,12,16,6gqrgq,Generating HTML from GUI Screenshot,https://www.reddit.com/r/deeplearning/comments/6gqrgq/generating_html_from_gui_screenshot/,harvey_slash,1497252503,,0,8
25,2017-6-13,2017,6,13,12,6gx94x,Zero to One  A Ton of Awe-Inspiring Deep Learning Demos with Code for Beginners,https://www.reddit.com/r/deeplearning/comments/6gx94x/zero_to_one_a_ton_of_aweinspiring_deep_learning/,tfzb,1497323766,,0,25
26,2017-6-15,2017,6,15,0,6h8do6,Program that learns how to read: Where do I even start?,https://www.reddit.com/r/deeplearning/comments/6h8do6/program_that_learns_how_to_read_where_do_i_even/,MCSenss,1497455614,"Hello Guys,

I'm afraid to sound lazy but I am absolutely overwhelmed by the amount of information out there.

What I would like to do is create a program that learns how to read the letter ""A"", preferably completely from scratch! You give him a training set of 100 pictures with an ""A"" on it. Then you give him a set of pictures and it has to decide whether it sees an ""A"" or not. Simple enough (in theory).

But where do I have to start? What do I even need in order to do that? Is it deep learning or machine learning or AI or.......?

I would be happy with a few tags that are more specific than ""object detection"" or ""deep learning"".

Thanks a lot in advance.

 ",3,1
27,2017-6-15,2017,6,15,4,6h9z3c,"Valeo launches Valeo.ai, the first global research center in artificial intelligence and deep learning for automotive applications based in Paris | Valeo",https://www.reddit.com/r/deeplearning/comments/6h9z3c/valeo_launches_valeoai_the_first_global_research/,dannyeuu,1497469915,,0,3
28,2017-6-15,2017,6,15,22,6hf5ei,Make Pharma Great Again with Artificial Intelligence: some Challenges,https://www.reddit.com/r/deeplearning/comments/6hf5ei/make_pharma_great_again_with_artificial/,mostafabenh,1497534986,,0,0
29,2017-6-16,2017,6,16,1,6hg9ry,A new easy-to-use open source project which contains tutorials on how to implement different models using TensorFLow,https://www.reddit.com/r/deeplearning/comments/6hg9ry/a_new_easytouse_open_source_project_which/,irsina,1497545589,,0,9
30,2017-6-16,2017,6,16,4,6hhg8d,Data Science - Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/6hhg8d/data_science_deep_learning_in_python/,rvarinder,1497556094,,0,3
31,2017-6-16,2017,6,16,6,6hi12l,Nuts and Bolts of Applying Deep Learning (Andrew Ng),https://www.reddit.com/r/deeplearning/comments/6hi12l/nuts_and_bolts_of_applying_deep_learning_andrew_ng/,neopunisher,1497561435,,2,11
32,2017-6-16,2017,6,16,15,6hkxmz,Ahem detector with deep learning,https://www.reddit.com/r/deeplearning/comments/6hkxmz/ahem_detector_with_deep_learning/,fgadaleta,1497596200,,2,3
33,2017-6-16,2017,6,16,18,6hldpa,Facebook Has increased Its Training For Visual Recognition Models.,https://www.reddit.com/r/deeplearning/comments/6hldpa/facebook_has_increased_its_training_for_visual/,digitalmarketingrobi,1497603699,,0,1
34,2017-6-16,2017,6,16,23,6hmuqv,Need some direction on neural networks.,https://www.reddit.com/r/deeplearning/comments/6hmuqv/need_some_direction_on_neural_networks/,PASTAREADERBRO,1497623273,"Hey,

Just started to learn about NN, and got a little overwhelmed. 
Their are just so many types, from RNN's to LTSM's, i'm just a bit confused and don't really know where to start.

Was wondering if someone could provided me with an ordered reading list (or websites). I would also like to learn some of the math involved (and whatever prerequisite maths).

I'm especially interested in ConvNet's and NLP.

Also I apologize if this is a stupid / redundant post. 

Thanks.",5,2
35,2017-6-17,2017,6,17,8,6hq4g9,Tensorflow transfer learning tutorial,https://www.reddit.com/r/deeplearning/comments/6hq4g9/tensorflow_transfer_learning_tutorial/,__The_Coder__,1497655266,,1,5
36,2017-6-17,2017,6,17,21,6ht9b4,What are some techniques to use deep learning models for inferences on devices like Raspberry Pi or Odroid?,https://www.reddit.com/r/deeplearning/comments/6ht9b4/what_are_some_techniques_to_use_deep_learning/,mehuljain1902,1497704303,[removed],0,1
37,2017-6-18,2017,6,18,7,6hwcau,Help with Keras and LSTMs,https://www.reddit.com/r/deeplearning/comments/6hwcau/help_with_keras_and_lstms/,[deleted],1497739515,[deleted],0,1
38,2017-6-19,2017,6,19,12,6i42wc,Using 3D Convolutional Neural Networks for Speaker Verification,https://www.reddit.com/r/deeplearning/comments/6i42wc/using_3d_convolutional_neural_networks_for/,irsina,1497844577,,0,4
39,2017-6-19,2017,6,19,14,6i4fqu,Martin Arjovsky (Wasserstein GAN) Interview,https://www.reddit.com/r/deeplearning/comments/6i4fqu/martin_arjovsky_wasserstein_gan_interview/,alexmlamb,1497849597,,0,2
40,2017-6-19,2017,6,19,17,6i514v,"Suggest idea for a research paper, please?",https://www.reddit.com/r/deeplearning/comments/6i514v/suggest_idea_for_a_research_paper_please/,mananpal1997,1497859227,"I've worked with nlp and vision a bit. I want to write a research paper and have problem figuring out what to begin with. Can you suggest something? (I've interest in audio dsp as well, so if anything on that is also welcome) :)",6,1
41,2017-6-20,2017,6,20,16,6iclya,please suggest some applications for an app,https://www.reddit.com/r/deeplearning/comments/6iclya/please_suggest_some_applications_for_an_app/,harvey_slash,1497945162,"I have been studying deep learning for a few months. I am familiar with beginner to intermediate architectures like cnn,lstms, GANS. I have done some implementation of fairly recent papers like style transfer , WGAN etc. 
I am looking for some ideas for an app (can be mobile app, or a web based app) that uses deep learning. It does not need to be a 'useful' app, but should be fairly fun atleast. I am looking for ideas or even somebody to work and collaborate. 
Thanks ",5,1
42,2017-6-21,2017,6,21,0,6iewn8,How qplum utilizes Deep Learning in quantitative trading.,https://www.reddit.com/r/deeplearning/comments/6iewn8/how_qplum_utilizes_deep_learning_in_quantitative/,FintechNerd,1497974017,,1,4
43,2017-6-21,2017,6,21,17,6ikjc3,[video] Composing Bach Chorales Using Deep Learning by Feynman Liang,https://www.reddit.com/r/deeplearning/comments/6ikjc3/video_composing_bach_chorales_using_deep_learning/,rick-rebel,1498034044,,0,1
44,2017-6-21,2017,6,21,19,6il303,Face detection was never this simple!,https://www.reddit.com/r/deeplearning/comments/6il303/face_detection_was_never_this_simple/,knolspeak,1498042759,,0,1
45,2017-6-21,2017,6,21,22,6ilyao,use output of aNN for input (kind of bidirectional aNN),https://www.reddit.com/r/deeplearning/comments/6ilyao/use_output_of_ann_for_input_kind_of_bidirectional/,vadim878,1498053218,"Dear all, 

I was wondering, is it possible to use an output for an ANN as an input for the next task. I mean, I have a model with multiple layers, and I decided to ""reverse"" it, so using the initial output value for input, got input values from the normal mode. 

Hope it's clear. 

Kind regards,
Vadim",2,1
46,2017-6-22,2017,6,22,2,6incq2,What the hell is going on in NLP?,https://www.reddit.com/r/deeplearning/comments/6incq2/what_the_hell_is_going_on_in_nlp/,wzup_w_nlp,1498066226,"I'm new to NLP research. In my short-time, I've seen RNN's surpass older techniques. ConvNets have then beaten RNN's on certain NLP tasks. And now attention models with only feed forward networks are beating both of those techniques for machine translation. (See the paper, ""Attention is All You Need"") I expect this attention model to outperform RNNs and CNNs on other NLP tasks soon. 

Anyway, can a more seasoned NLP researcher tell me what the hell is going on? Why is there so little stability in NLP? Is it just that we have very little understanding of how language works? Are we just building big models and learning millions of parameters w/o having a deeper understanding? Sorry for the rant...",5,11
47,2017-6-23,2017,6,23,5,6iw62m,Demo App For Skin Cancer Diagnosis in Real Time Using Tensorflow Deep Learning,https://www.reddit.com/r/deeplearning/comments/6iw62m/demo_app_for_skin_cancer_diagnosis_in_real_time/,[deleted],1498162606,[deleted],0,1
48,2017-6-23,2017,6,23,14,6iz91c,Advice on building an object recognion training set,https://www.reddit.com/r/deeplearning/comments/6iz91c/advice_on_building_an_object_recognion_training/,[deleted],1498195842,[deleted],0,1
49,2017-6-23,2017,6,23,14,6izcaj,Advice on building object recognition training set,https://www.reddit.com/r/deeplearning/comments/6izcaj/advice_on_building_object_recognition_training_set/,Data-Daddy,1498197154,"I'm looking to collect and annotate data for a project. How many data points for each class do I need to collect to be able to realistically expect a faster rcnn model to do well? I know there is no straight answer to this but I would like to know some heuristics of how many to start with at least.

I'm also interested in any other tips you girls/guys may have with where to start with model params and also how to stratify the training set(split by class, bounding boc location/size, pixel distribution of image,  etc.)",3,1
50,2017-6-24,2017,6,24,3,6j30ca,Using Deep Learning to Reconstruct High-Resolution Audio,https://www.reddit.com/r/deeplearning/comments/6j30ca/using_deep_learning_to_reconstruct_highresolution/,mwakanosya,1498241819,,2,7
51,2017-6-26,2017,6,26,2,6jfidr,"Creative Adversarial networks , Simplified",https://www.reddit.com/r/deeplearning/comments/6jfidr/creative_adversarial_networks_simplified/,harvey_slash,1498411407,,15,5
52,2017-6-26,2017,6,26,3,6jft4t,Deep Learning with TensorFlow in Python,https://www.reddit.com/r/deeplearning/comments/6jft4t/deep_learning_with_tensorflow_in_python/,psangrene,1498414574,,0,3
53,2017-6-26,2017,6,26,7,6jh9oq,"TensorFlow/TensorLayer implementation ""SRGAN: Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network""",https://www.reddit.com/r/deeplearning/comments/6jh9oq/tensorflowtensorlayer_implementation_srgan/,zsdh123,1498430545,,0,1
54,2017-6-26,2017,6,26,16,6jjkrc, Unsupervised learning with CNN's,https://www.reddit.com/r/deeplearning/comments/6jjkrc/unsupervised_learning_with_cnns/,tajhrun,1498460661,"The research problem I was working on requires using CNN's. I wish to use standard CNN architectures like VGG-Net, LeNet at start. But the dataset I work upon doesn't have the kind of labels these CNN's are pre-trained for. Hence I need to do an unsupervised finetuning of the CNN models over my dataset. Literature review suggests using convolutional versions of autoencoders, boltzmann machines. Is it practical to build an autoencoder from a LeNet architecture and how would it perform? Do the standard deep learning libraries like Keras, Lasagne have modules for convolutional autoencoder models? ",2,3
55,2017-6-27,2017,6,27,0,6jlmb4,Learning / optimizing strategies?,https://www.reddit.com/r/deeplearning/comments/6jlmb4/learning_optimizing_strategies/,kwhali,1498489381,"**TL;DR:** Bold text below is mainly what I want to know. FlappyBird game with one action and a goal to survive sounds like a good example.

---

I'm new to machine/deep learning, it seems a rather broad field! I have experience programming but not quite sure where to look to get started here. I see alot of pattern/feature matching/manipulation going on, usually with images or audio.

**What are the terms to look into if you have some actions/events that can occur and you have a rough goal/outcome desired and would like the AI to learn what is effective/ineffective based on datasets it's given?** I saw a video on MarI/O which was an AI with genetic algorithm to learn how to play a level(I think it had learned mostly how to play that single level really well, overfitting?) and I found that quite interesting.

Another example could be guessing passwords, a large dataset of known passwords could be fed in, and it could guess what letters are most likely to follow after a previous one or common word combinations/patterns. I've read of this being done with markov chains(or hidden markov models, not sure). This sounds more in line with what deep learning is good at.

I think I am more interested in the ones like MarI/O where the AI has actions it can perform with a measurable goal to achieve while learning from it's actions/decisions that fail. The issue with that propped up was the likely overfitting to that specific level, how would you avoid that, would more levels help or would it need to be combined with other methods so it actually learnt how to play well to procedurally generated levels?

Could I take a more basic game like FlappyBird(one button to move the player up while they otherwise fall to gravity trying to dodge obstacles) and teach it how to survive the procedural generated level by using that one action?",0,1
56,2017-6-27,2017,6,27,0,6jlou4,Deep Atrous CNN Network for Sentiment Analysis,https://www.reddit.com/r/deeplearning/comments/6jlou4/deep_atrous_cnn_network_for_sentiment_analysis/,gvssvg,1498490035,,0,1
57,2017-6-27,2017,6,27,5,6jnnrl,Deep Learning - Hands-On Artificial Neural Networks,https://www.reddit.com/r/deeplearning/comments/6jnnrl/deep_learning_handson_artificial_neural_networks/,vasira,1498508115,,0,2
58,2017-6-27,2017,6,27,21,6js6pl,Microsoft Releases Second Update of Its Deep Learning Toolkit,https://www.reddit.com/r/deeplearning/comments/6js6pl/microsoft_releases_second_update_of_its_deep/,digitalmarketingrobi,1498564858,,0,1
59,2017-6-28,2017,6,28,3,6jurji,Learned/random weights per neuron or per weights with PReLU / RReLU?,https://www.reddit.com/r/deeplearning/comments/6jurji/learnedrandom_weights_per_neuron_or_per_weights/,[deleted],1498588829,[deleted],0,1
60,2017-6-28,2017,6,28,3,6jusbn,Free Webinar on How AI/Deep Learning is disrupting trading? And why now?,https://www.reddit.com/r/deeplearning/comments/6jusbn/free_webinar_on_how_aideep_learning_is_disrupting/,qplum,1498589026,,0,0
61,2017-6-28,2017,6,28,4,6jv6wb,How Deep Learning Can Transform Investing from a Daunting Art into a Simple Utility.,https://www.reddit.com/r/deeplearning/comments/6jv6wb/how_deep_learning_can_transform_investing_from_a/,PotterBear,1498592500,,0,1
62,2017-6-28,2017,6,28,5,6jvm5t,Philosophy of Deep Learning,https://www.reddit.com/r/deeplearning/comments/6jvm5t/philosophy_of_deep_learning/,artificialbrainxyz,1498596167,,0,1
63,2017-6-28,2017,6,28,5,6jvonr,"How to handle ""variable length input"" in neural networks?",https://www.reddit.com/r/deeplearning/comments/6jvonr/how_to_handle_variable_length_input_in_neural/,mehrankh,1498596760,"I am training a classifier that gets as input the probability distribution of an instance and outputs a binary value. For example let's say each instance in my dataset can have 10 different labels (For example MNIST), I have the probability distributions of all the instances. Let's say I want to classify these instances as Good/Bad.
Let's say I have trained a model on one dataset (MNIST) and now I want to expand it to another dataset like cifar-100, in which every instance could have 100 different labels.
I want to design a model (Neural Network) that could be trained on one dataset and trained on another dataset.

For example, people trained AlexNet on ImageNet and finetune it on another dataset by removing the last layer, and adding another layer with different size.

How could I do similar thing when the constraint is on the input not the output of the network?
Is it possible to design a network that could have a variable length input? Or is it possible to change maybe 1,2 layers and finetune the network on another dataset?

[Is the problem clear? :)]",2,5
64,2017-6-28,2017,6,28,20,6jzxn7,"Youtube Live Session Recording on ""Deep Learning - A Step Closer To Artificial Intelligence""",https://www.reddit.com/r/deeplearning/comments/6jzxn7/youtube_live_session_recording_on_deep_learning_a/,pooja_edureka,1498649065,,0,2
65,2017-6-29,2017,6,29,0,6k17go,Two ways to improve accuracy and reduce training time - Explained,https://www.reddit.com/r/deeplearning/comments/6k17go/two_ways_to_improve_accuracy_and_reduce_training/,harvey_slash,1498663081,,2,7
66,2017-6-29,2017,6,29,16,6k6tdb,Learning to Reason with Neural Module Networks,https://www.reddit.com/r/deeplearning/comments/6k6tdb/learning_to_reason_with_neural_module_networks/,pandashitman,1498721430,,1,12
67,2017-6-29,2017,6,29,18,6k76p4,A full pytorch implementation of DrQA on SQuAD dataset,https://www.reddit.com/r/deeplearning/comments/6k76p4/a_full_pytorch_implementation_of_drqa_on_squad/,rqyang,1498727647,,0,1
68,2017-6-29,2017,6,29,19,6k7kvn,Designing custom loss functions for Deep Conv Networks for Regression,https://www.reddit.com/r/deeplearning/comments/6k7kvn/designing_custom_loss_functions_for_deep_conv/,Nox_90,1498733886,"I am trying to predict a vector of values from a large set of images. These are future values of a certain quantity (1 to 10 minutes ahead). However, the network seems to predict the correct trend but not when there is a drastic change some minutes ahead. The set is biased towards non-drastic-change (80%) of samples. For reasons, it is hard to balance the dataset (unless you know of a good way to do online resampling of batches with tensorflow). Therefore I thought I might force the network to predict such changes using a weighted loss (depending on whether a sample contains drastic changes). I tried both L1/L2 loss and a simple weighting scheme but it does not really help (about the same performance).  I also tried different architectures (simple one with 3 conv laxers and 2 fully connected) and a 18 Layer Resnet. The Resnet improves the performance a fair bit. But it is still not satisfactory. So I thought it might be worthwhile to build a more intricate loss function to reflect drastic changes better. Are there any best practices for doing so? ",1,5
69,2017-6-29,2017,6,29,23,6k8p6r,Who is the #1 Deep Learning Expert in Israel?,https://www.reddit.com/r/deeplearning/comments/6k8p6r/who_is_the_1_deep_learning_expert_in_israel/,JacobSmith1980,1498746605,,0,0
70,2017-6-30,2017,6,30,5,6kazce,"Unfolding of RNN, popular Deep Learning Model",https://www.reddit.com/r/deeplearning/comments/6kazce/unfolding_of_rnn_popular_deep_learning_model/,hskang9,1498766900,,0,1
71,2017-6-30,2017,6,30,12,6kdkeg,Are there any image training apps with a GUI?,https://www.reddit.com/r/deeplearning/comments/6kdkeg/are_there_any_image_training_apps_with_a_gui/,jonwheat,1498794806,"I desperately want to get into creating models but all this command line stuff is daunting.

I saw there is NVIDIA Numbers available, is that worth looking into / any other apps worth mentioning?",6,2
72,2017-6-30,2017,6,30,20,6kfa1p,Is it possible to teach a computer how to teach something a computer?,https://www.reddit.com/r/deeplearning/comments/6kfa1p/is_it_possible_to_teach_a_computer_how_to_teach/,albinoameise,1498821331,"I didn't really dig into this topic yet, but thought popped up last night and i think it could be an interesting concept.
So could this work, or are there technical or logical issues?",3,0
0,2017-7-2,2017,7,2,13,6krl3p,Practical Deep Learning with PyTorch,https://www.reddit.com/r/deeplearning/comments/6krl3p/practical_deep_learning_with_pytorch/,deeplearningwizard,1498971103,,0,1
1,2017-7-2,2017,7,2,15,6krxry,Deep Learning Audio files,https://www.reddit.com/r/deeplearning/comments/6krxry/deep_learning_audio_files/,choseausernamereddit,1498977270,"I want to find out what can DL do with audio files. Like, what kind of algorithms are there (other than cocktail party problem) that can help analyse an audio (maybe an mp3 song).",3,3
2,2017-7-2,2017,7,2,23,6ktkpq,Looking for machine learning investment strategies,https://www.reddit.com/r/deeplearning/comments/6ktkpq/looking_for_machine_learning_investment_strategies/,MachineLearnInvest,1499006732,"Hi Reddit!

I and a group of partners with significant investment management industry experience in Canada are looking at the machine learning space to potentially build a new ai focused investment products in the Canadian marketplace.  If you are working on machine learning equity investment strategies and have a meaningful track record or back test we would love to hear from you, especially if you are in the Toronto-Waterloo region corridor.  Send me a DM! Cheers!",0,0
3,2017-7-3,2017,7,3,2,6kugkz,A backpropagation example you can actually understand,https://www.reddit.com/r/deeplearning/comments/6kugkz/a_backpropagation_example_you_can_actually/,sohel888,1499016782,,0,3
4,2017-7-3,2017,7,3,5,6kvc7l,Distribution of Deep Learning Supertalent in Industry - Any feedback?,https://www.reddit.com/r/deeplearning/comments/6kvc7l/distribution_of_deep_learning_supertalent_in/,alecmgo,1499026324,,3,1
5,2017-7-3,2017,7,3,23,6l023q,DeepMinds Relational Networks  Demystified,https://www.reddit.com/r/deeplearning/comments/6l023q/deepminds_relational_networks_demystified/,harvey_slash,1499090532,,0,10
6,2017-7-4,2017,7,4,10,6l46jg,"KDD 2017 | Halifax, Nova Scotia - Canada",https://www.reddit.com/r/deeplearning/comments/6l46jg/kdd_2017_halifax_nova_scotia_canada/,hylihitic,1499133314,,0,3
7,2017-7-4,2017,7,4,23,6l7egc,A fresh start to understanding Neural Nets using Tensorflow,https://www.reddit.com/r/deeplearning/comments/6l7egc/a_fresh_start_to_understanding_neural_nets_using/,raksham97,1499178861,,0,7
8,2017-7-5,2017,7,5,2,6l8j5b,Train your Deep Learning models on the Cloud,https://www.reddit.com/r/deeplearning/comments/6l8j5b/train_your_deep_learning_models_on_the_cloud/,goddamnsteve,1499190248,,0,0
9,2017-7-7,2017,7,7,2,6ln6dv,Build an AI Programmer using Recurrent Neural Network,https://www.reddit.com/r/deeplearning/comments/6ln6dv/build_an_ai_programmer_using_recurrent_neural/,ryanlr,1499360938,,0,1
10,2017-7-7,2017,7,7,13,6lrd8w,Backpropagation Through Time: recurrent neural network training technique,https://www.reddit.com/r/deeplearning/comments/6lrd8w/backpropagation_through_time_recurrent_neural/,sudheeran,1499401963,,0,1
11,2017-7-7,2017,7,7,17,6lse9h,Features and capabilities of Deep Learning,https://www.reddit.com/r/deeplearning/comments/6lse9h/features_and_capabilities_of_deep_learning/,zinerminer,1499417011,"I have here analyzed the concept of deep learning in detail. Any other points/opinions?

teks.co.in/site/blog/artificial-intelligence-3-0-13-things-to-know-about-deep-learning/

",0,0
12,2017-7-9,2017,7,9,1,6m1upj,Introduction to Apache MXNet on AWS (AWS podcast),https://www.reddit.com/r/deeplearning/comments/6m1upj/introduction_to_apache_mxnet_on_aws_aws_podcast/,julsimon,1499530937,,4,2
13,2017-7-9,2017,7,9,13,6m5jzu,A Neural Network in 10 lines of C++ Code,https://www.reddit.com/r/deeplearning/comments/6m5jzu/a_neural_network_in_10_lines_of_c_code/,[deleted],1499573846,[deleted],2,0
14,2017-7-9,2017,7,9,17,6m6elp,I made a parody song about deep learning,https://www.reddit.com/r/deeplearning/comments/6m6elp/i_made_a_parody_song_about_deep_learning/,zephiem,1499588394,,5,6
15,2017-7-10,2017,7,10,9,6mb762,When not to use deep learning,https://www.reddit.com/r/deeplearning/comments/6mb762/when_not_to_use_deep_learning/,_alphamaximus_,1499647978,,2,1
16,2017-7-10,2017,7,10,12,6mbzyb,A comprehensive and organized collection of resources for TensorFlow,https://www.reddit.com/r/deeplearning/comments/6mbzyb/a_comprehensive_and_organized_collection_of/,irsina,1499657774,,0,4
17,2017-7-10,2017,7,10,19,6mdpql,Adding attention mechanism to IMDB dataset using keras,https://www.reddit.com/r/deeplearning/comments/6mdpql/adding_attention_mechanism_to_imdb_dataset_using/,dude_perf3ct,1499684137,"I am trying to add attention mechanism to IMDB dataset which is basically sentiment analysis. The attention mechanism will contain the information as to which word contributed more or less to the sentiment. All the model code and problem are posted on stack overflow and github. Any suggestions?

Github Issue:
https://github.com/fchollet/keras/issues/4962#issuecomment-313859541

Stack Overflow question:
https://stackoverflow.com/questions/44966840/training-loss-and-accuracy-remain-constant-after-adding-attention-mechanism",0,2
18,2017-7-10,2017,7,10,22,6mefhq,MatchNet,https://www.reddit.com/r/deeplearning/comments/6mefhq/matchnet/,burn_in_flames,1499693240,"I wanted to find out what models have replaced/improved on MatchNet for matching two images and getting a classification of matched/not match?

Currently, MatchNet is 2 years old, but I haven't come across many papers of networks which are solving the same task as MatchNet did originally.",1,1
19,2017-7-11,2017,7,11,0,6mf03i,Is there a deep learning program or similar system that can help me do analyses based on knowledge/data it is fed?,https://www.reddit.com/r/deeplearning/comments/6mf03i/is_there_a_deep_learning_program_or_similar/,[deleted],1499699052,[deleted],2,1
20,2017-7-11,2017,7,11,7,6mi4rg,Deep Learning powered Facial Recognition APIs - Have a play around with it :),https://www.reddit.com/r/deeplearning/comments/6mi4rg/deep_learning_powered_facial_recognition_apis/,truefaceAI,1499727303,"https://trueface.ai/
Face Detect
Fact Matching
Identification
Raw Landmark Detection
Picture Attack Detection
We welcome developer involvement and feedback",0,2
21,2017-7-11,2017,7,11,15,6mkcob,New CS224n: Natural Language Processing with Deep Learning,https://www.reddit.com/r/deeplearning/comments/6mkcob/new_cs224n_natural_language_processing_with_deep/,cognitivedemons,1499752903,Stanford has started a new version of [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/) with both Chris Manning and Richard Socher. Are you looking forward to watching it?,1,11
22,2017-7-11,2017,7,11,17,6mkxbs,I'm a newbie and need a bit of help in deciding whether to install the CPU or the GPU version of tensorflow,https://www.reddit.com/r/deeplearning/comments/6mkxbs/im_a_newbie_and_need_a_bit_of_help_in_deciding/,vallsin,1499761911,So i'm very new to the machine learning and deep learning field and i only recently have been thinking of using tensorflow. Now i have a i7 6700hq processor @2.60hz and a 960m Nvidia graphic card with 4GB Memory. I'm confused whether i should install the Gpu version or the cpu version and which one would ensure faster training times in my case?,16,4
23,2017-7-12,2017,7,12,4,6mogb3,[Question] Feeding raw signal data into a Deep Belief Network in Python?,https://www.reddit.com/r/deeplearning/comments/6mogb3/question_feeding_raw_signal_data_into_a_deep/,eragonngo,1499800303,"I have a question regarding inputting raw signal data into a Deep Belief Network. The nature of input data includes 1,000 signal data of 3 classifications. Each signal data has 6 features and contain 10,000 samples in it. Instead of using statistical feature extraction (which will extract the RMS, mean, max, kurtosis, etc of those signal data) and feed it into a standard Neural Network to do the classification task, I wonder can I feed the Deep Belief Network with 3 hidden layers with X = [1,000 x 10,000; 6] and y = [1,000 ; 1] matrix to do the classification task ?

If it's possible, how can I map X correspond to y?

Thank you all for reading my questions",0,3
24,2017-7-12,2017,7,12,6,6mpab9,Deep Learning with Python and Keras,https://www.reddit.com/r/deeplearning/comments/6mpab9/deep_learning_with_python_and_keras/,vasira,1499807722,,0,2
25,2017-7-12,2017,7,12,9,6mqc24,www.marwane.cf,https://www.reddit.com/r/deeplearning/comments/6mqc24/wwwmarwanecf/,youmarwane,1499818264,,0,1
26,2017-7-12,2017,7,12,10,6mqwrt,Deep learning projects are coming!,https://www.reddit.com/r/deeplearning/comments/6mqwrt/deep_learning_projects_are_coming/,[deleted],1499824697,[deleted],4,3
27,2017-7-12,2017,7,12,14,6mrwan,GPU temperature reads 88 C when training a LSTM on tensorflow. Is it normal (and safe)?,https://www.reddit.com/r/deeplearning/comments/6mrwan/gpu_temperature_reads_88_c_when_training_a_lstm/,dmdmello,1499836795,"I've got a 1 layer LSTM model in tensorflow and the temperature reading of my GPU gets rather high during the training phase. Always varying between 80 C and 90 C. My GPU is a water cooled gtx 1080 ""Super-clocked"" edition in a 24/7 refrigerated room. The model works, but this temperature worries me. I'd like to know if this is normal and safe.

I'm training the LSTM for a next-word-prediction problem with tokenized reddit comments. I got the idea from different tutorials in wildml.com. Here are some details about it:

    Tensorflow 1.2.1, Cuda tk 8.0, Cudnn 6.0, Nvidia Driver 375.66
    My training data consists of 200 K reddit comments.
    My word dictionary consists of 8000 words, which means 8000 classes of classification for each prediction
    I use GLOVE pre-trained 100 Dimensions embeddings of Wikipedia words
    I'm not using placeholders to feed my input. It's all done with TFRecordfiles readers, which input the examples to a 100k capacity random shuffle queue
    From the random shuffle queue, it goes to a padding FIFO queue, where I generated zero-paddaded mini-batches of 20
    The 20 size mini batches go to a tf.dynamic_rnn() with LSTM cell with Hidden dimension of 150
    I mask the losses using tf.sign() and minimize the result with Adam optimizer

I've noticed that the temperature rises a lot when I raise the mini-batch size. 1 size mini-batches (single examples), it reads between 72-75 C. With 10 size mini-batches, it immediately goes to 78 C and stays in the range of 78-84 C. With 20 size mini-batches, 84-88 C. With 30 size mini-batches, 87-92 C.

If I raise the hidden dimension to 200, 250, 300, etc, while maintaining the minibatch size fixed, I also get similar temperature raises.

I've also trained the same model, but feeding the data with placeholders only, i.e, not using TFRecord, Queues and mini-batches. It stays around 65 C, but it's obviously far from optimized and ideal to use placeholders for feeding the net.

I really appreciate your help, I'm kinda desperate, to be honest.
",11,1
28,2017-7-12,2017,7,12,17,6msk8m,"Tensorflow: RNN model works with LSTM cell, but returns NaN with GRU cell",https://www.reddit.com/r/deeplearning/comments/6msk8m/tensorflow_rnn_model_works_with_lstm_cell_but/,dmdmello,1499846904,"Hi.
I've created a simple LSTM model for the problem of prediction of the next word in a phrase and I'm getting a rather strange result when I try the same thing with GRU cell instead. I use dynamic RNN to implement the internal ops of the neural net, and use a LSTM cell with ""State_is_tuple"" set to ""True"" as input. After 50 epochs, with each epoch iterating over the entire dataset, it gets 72 % accuracy. I'm still working on getting a better result, but that's not the point. I'm running the model on a GTX 1080.

However, when I substitute the LSTM cell for a GRU cell, during aprox. 20 epochs of training, something goes wrong and one of the parameters is calculated as NaN, which subsequently makes all other parameters be calculated as NaN too, which ruins the training.

So, what could it be? Could it be a memory issue? I'm almost sure it doesn't have nothing to do with cross entropy, since I use the highlevel function sparse_softmax_cross_entropy_with_logits(), which handles log(0) cases. I really have no idea why it's happening. 

Another important detail is that I'm not using tf.placeholder to feed the input, but a TFRecord reader that inputs data to a 100k capacity Random Shuffle Queue, which in turn inputs examples to a Padding FIFO Queue, which dequeues zero-padded batches of 20 elements to the model. I also use a pre-trained embedding layer. For optimization I use Adam.  ",2,2
29,2017-7-12,2017,7,12,22,6mtrol,A deep learning and reinforcement learning experimentation library on top of tensorflow.,https://www.reddit.com/r/deeplearning/comments/6mtrol/a_deep_learning_and_reinforcement_learning/,pipado,1499864466,,0,11
30,2017-7-13,2017,7,13,1,6mv8qy,[1707.03300] New paper explores how agents can learn from unintentional accomplishments.,https://www.reddit.com/r/deeplearning/comments/6mv8qy/170703300_new_paper_explores_how_agents_can_learn/,cognitivedemons,1499878447,,0,2
31,2017-7-13,2017,7,13,2,6mvaxo,[1707.03141] 1-shot classification: 56.48% accuracy on 5-Way Mini-ImageNet!,https://www.reddit.com/r/deeplearning/comments/6mvaxo/170703141_1shot_classification_5648_accuracy_on/,cognitivedemons,1499878984,,2,4
32,2017-7-13,2017,7,13,12,6mz6cj,"Audio + Video Manipulation Detection: Combatting CycleGAN, Face2Face, etc.",https://www.reddit.com/r/deeplearning/comments/6mz6cj/audio_video_manipulation_detection_combatting/,mhdempsey,1499917778,,1,2
33,2017-7-13,2017,7,13,14,6mzp7v,Mate Labs mixes machine learning with IFTTT,https://www.reddit.com/r/deeplearning/comments/6mzp7v/mate_labs_mixes_machine_learning_with_ifttt/,kailashahirwar12,1499924589,,0,2
34,2017-7-13,2017,7,13,19,6n0qka,Computer Vision News for the Algorithm Community - July,https://www.reddit.com/r/deeplearning/comments/6n0qka/computer_vision_news_for_the_algorithm_community/,Gletta,1499941192,"This is Computer Vision News of July, published by RSIP Vision, with 50 pages of exclusive content about computer vision, artificial intelligence, deep learning and image processing! It's free for everyone to read and subscribe.
This month, don't miss our exclusive review about ""Understanding Googles Transformer"", the new attention unit by Google.
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2017July/
and PDF version ==&gt; http://www.rsipvision.com/computer-vision-news-2017-july-pdf/
Enjoy!",0,2
35,2017-7-14,2017,7,14,4,6n42mj,Google's DeepMind AI just taught itself to walk,https://www.reddit.com/r/deeplearning/comments/6n42mj/googles_deepmind_ai_just_taught_itself_to_walk/,[deleted],1499975579,[deleted],1,1
36,2017-7-15,2017,7,15,4,6nb4v1,Data Science-Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/6nb4v1/data_sciencedeep_learning_in_python/,LocalStar,1500058997,,1,1
37,2017-7-15,2017,7,15,8,6nclz2,Doubt in YOLO implementation,https://www.reddit.com/r/deeplearning/comments/6nclz2/doubt_in_yolo_implementation/,[deleted],1500074046,[deleted],0,1
38,2017-7-15,2017,7,15,13,6ne5p0,Lip Reading  Who Said What? Answered by Deep Learning,https://www.reddit.com/r/deeplearning/comments/6ne5p0/lip_reading_who_said_what_answered_by_deep/,irsina,1500094296,,0,2
39,2017-7-16,2017,7,16,13,6nkj3w,Siamese Networks for One Shot Learning in PyTorch - part 1,https://www.reddit.com/r/deeplearning/comments/6nkj3w/siamese_networks_for_one_shot_learning_in_pytorch/,harvey_slash,1500181081,,0,4
40,2017-7-17,2017,7,17,8,6npfyb,Useful Data Science Resources &amp; Recommended Study Routes,https://www.reddit.com/r/deeplearning/comments/6npfyb/useful_data_science_resources_recommended_study/,datasciencelover,1500247740,,0,6
41,2017-7-17,2017,7,17,14,6nr5h5,Practical Deep Learning on Images and Text.,https://www.reddit.com/r/deeplearning/comments/6nr5h5/practical_deep_learning_on_images_and_text/,snlpatel001213,1500269450,,0,4
42,2017-7-17,2017,7,17,17,6nrs93,Debugging &amp; Visualising training of Neural Network with TensorBoard,https://www.reddit.com/r/deeplearning/comments/6nrs93/debugging_visualising_training_of_neural_network/,jalFaizy,1500279816,,0,4
43,2017-7-18,2017,7,18,4,6nvdzr,Choice of Biometric Identification/Authentification,https://www.reddit.com/r/deeplearning/comments/6nvdzr/choice_of_biometric_identificationauthentification/,truefaceAI,1500319575,"If you are required to give your biometric information, are you more comfortable with iris, finger print, or facial recognition?",5,1
44,2017-7-18,2017,7,18,15,6nyxam,Logical and Lucid way to learn Machine Learning.,https://www.reddit.com/r/deeplearning/comments/6nyxam/logical_and_lucid_way_to_learn_machine_learning/,snlpatel001213,1500357792,,2,5
45,2017-7-19,2017,7,19,0,6o1hiv,AI Co-Pilot: RNNs for Dynamic Facial Analysis,https://www.reddit.com/r/deeplearning/comments/6o1hiv/ai_copilot_rnns_for_dynamic_facial_analysis/,harrism,1500391818,,1,5
46,2017-7-19,2017,7,19,3,6o2ps4,SSD Object detection,https://www.reddit.com/r/deeplearning/comments/6o2ps4/ssd_object_detection/,sirLuckyLuke,1500402641,"Hey folks,

I am currently trying to build a door detector with the singleshot multibox detector. I have roundabout 3k images with labeled doors from imagenet. Training is fine and I get up to 75 percent mAP on my test set.       But if I put ""real world"" images through my model I get many wrong detections. Especially Square shaped objects like computer monitors are labeled as doors with a confidence near 100 percent. Further  the detector run in trouble with Windows and so on...

Have someone an idea how to get rid of these miss detection without labeling a bunch of ""anti classes"" or fine tune my model with domain specific images?
",1,1
47,2017-7-19,2017,7,19,17,6o73a2,The future of deep learning,https://www.reddit.com/r/deeplearning/comments/6o73a2/the_future_of_deep_learning/,cloudgentleman,1500451803,,0,10
48,2017-7-20,2017,7,20,22,6og6l3,Facial Similarity with Siamese Networks in PyTorch  Hacker Noon,https://www.reddit.com/r/deeplearning/comments/6og6l3/facial_similarity_with_siamese_networks_in/,harvey_slash,1500556837,,0,2
49,2017-7-20,2017,7,20,23,6ogfrm,How the Leading Stationery Company Optimized Their Sales Strategies,https://www.reddit.com/r/deeplearning/comments/6ogfrm/how_the_leading_stationery_company_optimized/,cevizligizem,1500559566,https://www.exastax.com/case-studies/how-the-leading-stationery-company-optimized-their-sales-strategies/,1,0
50,2017-7-21,2017,7,21,0,6ogzuh,"I started a new sub dedicated to the intersection between connected device, time-series data and machine learning. Your thoughts?",https://www.reddit.com/r/deeplearning/comments/6ogzuh/i_started_a_new_sub_dedicated_to_the_intersection/,onegazillion,1500564847,,2,6
51,2017-7-21,2017,7,21,15,6om5q8,"When training a Deep Learning model, does it matter if I input examples of my dataset randomly or in a order?",https://www.reddit.com/r/deeplearning/comments/6om5q8/when_training_a_deep_learning_model_does_it/,dmdmello,1500618097,"To be more specific, Im training a LSTM to word prediction given a initial sequence of words, and my dataset is 200k reddit comments. Does it matter if I randomly feed the examples one at a time (allowing repeated inputs) or if I feed them in a sequence (not allowing repetitions)?",2,0
52,2017-7-21,2017,7,21,22,6onvaq,Very hard to work around continuous latent code in InfoGAN,https://www.reddit.com/r/deeplearning/comments/6onvaq/very_hard_to_work_around_continuous_latent_code/,kudo1026,1500643372,"It is always a pleasure to work with InfoGAN as it can unsupervisedly decode the structure of the data. The discrete latent worked very well for me to categorize different trajectories. However, I've been a little frustrated recently as I'm trying to implement the continuous latent code.

I first tried the mnist example given by the original InfoGAN paper, and it worked fine as the first continuous latent code represents the leaning angle and the second continuous latent represents the width. However, when I tried it on my own toy data sets,(something like
[first][1], [second][2]) nothing really works out. I expect to see continuous variation on my output, but they are instead completely random, like the latent code doesn't work at all.

I use convolutional and deconvolutional networks to discriminate and generate samples and follow the same manner for the discrete latent code as in the original openAI implementation. My treatment towards the continuous latent code is a little different, I have my discriminating network output continuous output with the same dimension as the input continuous latent code, and then try to minimize the MSE of the two. On the contrary, openaAI was modelling the code as a Gaussian distribution, and calculate its distance based on the distribution property.


    loss_c_cont = tf.reduce_mean(tf.reduce_sum(tf.square(c_cont_fake - c_cont), 1))


I think about it for a while, but don't think it could cause a huge difference as the gaussian distribution distance also mainly takes into account the square of epsilon = (x_var - mean).

    return tf.reduce_sum(
            - 0.5 * np.log(2 * np.pi) - tf.log(stddev + TINY) - 0.5 * tf.square(epsilon),
            reduction_indices=1,
        )

So my question would be: is this really the problem that caused all the problems? Or is there anything I need to pay more attention to but I did not notice?

Or in a more general sense, is there anything special about what kind of characteristics of the data can be represented by the continuous latent code? Is there any limitations to the representation capability of the continuous latent code(translation or rotation)? Can anyone share their experience about what kind of features they represented using the continuous latent code except for the examples given by the openAI paper?

I'd really welcome all your thoughts! Thanks!

P.S. Another thing I noticed was when I try to use a 5-category discrete code(in one-hot encoding) and 1-dim continuous code, it will take 5 digit for the discrete code and only 1 digit for the continuous code in the feeding input noise to the generator. Is it somehow unbalanced? Each of these code actually just represents one characteristic of the dataset. In mnist dataset, it could either number, width or rotation angle. Can this be a problem?


  [1]: https://i.stack.imgur.com/YXAMm.jpg
  [2]: https://i.stack.imgur.com/WNRTM.jpg
",4,2
53,2017-7-22,2017,7,22,0,6oopcu,Deep Learning for Automated Driving with MATLAB,https://www.reddit.com/r/deeplearning/comments/6oopcu/deep_learning_for_automated_driving_with_matlab/,harrism,1500651682,,0,9
54,2017-7-22,2017,7,22,4,6oq68u,"Fujitsu Enters Deep Learning, AI Markets With Custom Architecture",https://www.reddit.com/r/deeplearning/comments/6oq68u/fujitsu_enters_deep_learning_ai_markets_with/,chlordane2501,1500664833,,0,1
55,2017-7-22,2017,7,22,12,6osuot,How do you version control your neural net? [x-post from /r/MachineLearning],https://www.reddit.com/r/deeplearning/comments/6osuot/how_do_you_version_control_your_neural_net_xpost/,thumbsdrivesmecrazy,1500693985,,0,4
56,2017-7-23,2017,7,23,4,6owu77,Why would a pre trained word embedding like 'Glove' don't work with a GRU model for word prediction?,https://www.reddit.com/r/deeplearning/comments/6owu77/why_would_a_pre_trained_word_embedding_like_glove/,dmdmello,1500751146,"Its a GRU for predicting the next word given an initial sequence of words. Dataset is 200k reddit comments. Each comment is an example. Ive used glove 50 dim word embeddings pretrained on 6 billion wikipedia occurrences. I have not created it. Ive downloaded it from Gloves web site. The net trains and minimizes the loss, but strangely performs better with a random matrix instead of the embedding.

My model is supposed to receive a reddit comment, input it to a GRU and learn sequential patterns of words from it. It tries to predict the next word given the first word of the comment, and then the 3rd word given the first two, then the 4th given the first three and so on. Each example = one comment. This model is well explained on Wildml.com, from where I got it

The length of my dictionary of words is 8000. So each word is an index, and I use it to index a column of the embedding matrix, which has dims of  8000 x 50 (50 being the dim of the Glove embedding) .

Hidden dims of my GRU is 350. Ive tried 120, 150, 200, 250, results are almost the same. I'm minimizing the results for the sparse cross entropy with softmax of logits. I use Adam as optimizer, clipping the gradients between -1e16 and 1e16, and I have tried learning rates of 0.001 (default) 0.0001 and 0.00001.

Its all being done with tensorflow and Im sure everything is being done right. But the result on the training set is not doing well. With embedding the best accuracy of prediction when the lowest loss is achieved is always something like 25%. With random matrix instead of Glove's embedding,  I get 30 %.

IMPORTANT: All is being done considering the embedding matrix is not trainable (i.e, I set the flags trainable=FALSE) so tensorflow wont change it during BP. Ive done that both for Glove embedding and for the Random embedding.

I really appreciate your help.





",4,5
57,2017-7-23,2017,7,23,17,6p08t7,The most popular deep learning libraries - code(love),https://www.reddit.com/r/deeplearning/comments/6p08t7/the_most_popular_deep_learning_libraries_codelove/,pmz,1500797206,,2,1
58,2017-7-23,2017,7,23,20,6p0qxu,2 Deep Learning for Enterprise Workshops in New York This Week,https://www.reddit.com/r/deeplearning/comments/6p0qxu/2_deep_learning_for_enterprise_workshops_in_new/,tfzb,1500807651,,1,2
59,2017-7-24,2017,7,24,1,6p2dac,Install Keras + tensorflow-gpu with a NVidia Card,https://www.reddit.com/r/deeplearning/comments/6p2dac/install_keras_tensorflowgpu_with_a_nvidia_card/,nostub,1500828941,,2,0
60,2017-7-24,2017,7,24,4,6p36u0,http://www.thegeeklegacy.com/t/install-keras-tensorflow-gpu-with-a-nvidia-card/101/new/,https://www.reddit.com/r/deeplearning/comments/6p36u0/httpwwwthegeeklegacycomtinstallkerastensorflowgpuw/,nostub,1500837107,,0,0
61,2017-7-24,2017,7,24,5,6p3saz,"[NSFW] 50,000 tasteful nudes with neural network search",https://www.reddit.com/r/deeplearning/comments/6p3saz/nsfw_50000_tasteful_nudes_with_neural_network/,driftwheeler,1500843082,"http://driftwheeler.com

Citation: Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks (https://arxiv.org/abs/1406.6909)

50,000 MetArt-style nudes. No banners, no ads, no hassles, no distractions. Smart image zoom to fit the woman to the screen.

See random pics (WANDER). When you like one, see the photoshoot on repeat (TRANCE).

To search for something-- e.g., grass, beach, face, pussy-- long press the image (DREAM). This finds nearest neighbors in deep feature space, but only works reliably for simple concepts because it's fully unsupervised. The features you selected by long pressing (inside the box that appears) are more likely, but only very simple searches are ""pure"".

For example, long press a close-up pussy to see more pussies... find one you like, then press TRANCE to see the rest of her. Long press sand and water to see more girls on the beach. Long press forest greenery to see more girls in the forest. Long press a close-up face to see similar faces... And so on.

If this is not familiar to you, take a look at: http://cs.stanford.edu/people/karpathy/cnnembed/ Consider one of the big ""maps"" on that webpage. Notice how the tiny image patches clustered together in a map tend to be similar to each other. When you long press the image in Melondream, a box appears. That box is like one of the tiny image patches. Melondream's DREAM shows you images having patches near the patch you selected, in Melondream's map. Also notice how impure even a supervised dream would be.

This is an Android app. You may ask whether it's safe. Our reply:

1. We wrote it and we're telling you it's clean. And awesome.

2. Two independent security teams, one at The Register and and one at Wired, vetted the APK before publishing. In their opinion, it's clean and safe.

3. It requires no Android system permissions. It runs in the Android sandbox, with Android's maximum security. If you don't understand what this means, please see: https://developer.android.com/training/permissions/index.html

4. Melondream has thousands of regular users, and has been installed on tens of thousands of Android devices. No one complains and no one has problems.

Enjoy!",1,1
62,2017-7-24,2017,7,24,10,6p5f3a,cosine similarity can be object function for deep learning?,https://www.reddit.com/r/deeplearning/comments/6p5f3a/cosine_similarity_can_be_object_function_for_deep/,[deleted],1500861149,[deleted],1,2
63,2017-7-24,2017,7,24,23,6p8wfv,5 Free Resources for Getting Started with Deep Learning for Natural Language Processing,https://www.reddit.com/r/deeplearning/comments/6p8wfv/5_free_resources_for_getting_started_with_deep/,lalypopa123,1500908302,,0,1
64,2017-7-25,2017,7,25,0,6p98hb,Why deep learning isnt always the best AI solution,https://www.reddit.com/r/deeplearning/comments/6p98hb/why_deep_learning_isnt_always_the_best_ai_solution/,jonfla,1500911379,,2,1
65,2017-7-25,2017,7,25,2,6p9sfj,JetPack 3.1 Doubles Jetsons Low-Latency Inference Performance,https://www.reddit.com/r/deeplearning/comments/6p9sfj/jetpack_31_doubles_jetsons_lowlatency_inference/,harrism,1500916294,,0,4
66,2017-7-25,2017,7,25,5,6pb3ko,Intel Movidius Neural Compute Stick - On Mouser  r/iotml,https://www.reddit.com/r/deeplearning/comments/6pb3ko/intel_movidius_neural_compute_stick_on_mouser/,onegazillion,1500927702,,0,2
67,2017-7-25,2017,7,25,17,6peuym,37 ways to debug a DL model,https://www.reddit.com/r/deeplearning/comments/6peuym/37_ways_to_debug_a_dl_model/,[deleted],1500971666,[deleted],0,0
68,2017-7-25,2017,7,25,21,6pfth0,5 Reasons to Consider AI Automation for Banking,https://www.reddit.com/r/deeplearning/comments/6pfth0/5_reasons_to_consider_ai_automation_for_banking/,cevizligizem,1500985940,,0,0
69,2017-7-26,2017,7,26,2,6phpg3,Dimensionality reduction,https://www.reddit.com/r/deeplearning/comments/6phpg3/dimensionality_reduction/,dgl85,1501003729,"Hello, does anybody have experience in using CNN's or Autoencoders for dimensionality reduction? I need to reduce the dimension of my features and I thought of stacking a CNN or an autoencoder over a MLP or LSTM in order to do so. Any thoughts on which would be more appropriate?",2,3
70,2017-7-26,2017,7,26,3,6pi176,Squeeze Net Download,https://www.reddit.com/r/deeplearning/comments/6pi176/squeeze_net_download/,DecentMakeover,1501006499,"Has anyone tried downloading SqueezeNet-
they have mentioned that they have provided us a pretrained network,but im wondering do i need to have the ImageNet data downloaded for me to use the model or two train or install it??",0,0
71,2017-7-26,2017,7,26,13,6plr2e,"Are the Videos of Deep Learning Summer School, Montreal 2017 avaiable either in youtube or videolectures.net or facebook live?",https://www.reddit.com/r/deeplearning/comments/6plr2e/are_the_videos_of_deep_learning_summer_school/,rnnandi,1501043611,"Deep Learning Summer School, Montreal 2017 took place recently .
But I don't find the recorded videos in Internet. Is it available?",2,25
72,2017-7-26,2017,7,26,22,6pnwrq,CAN (Creative Adversarial Network),https://www.reddit.com/r/deeplearning/comments/6pnwrq/can_creative_adversarial_network/,lalypopa123,1501074575,,0,1
73,2017-7-26,2017,7,26,22,6po7ry,"Medical Image Analysis with Deep Learning , Part 4",https://www.reddit.com/r/deeplearning/comments/6po7ry/medical_image_analysis_with_deep_learning_part_4/,digitalson,1501077592,,0,6
74,2017-7-26,2017,7,26,23,6po8tg,Occupancy detection in the office by analyzing surveillance videos and its application to building energy conservation  r/iotml,https://www.reddit.com/r/deeplearning/comments/6po8tg/occupancy_detection_in_the_office_by_analyzing/,onegazillion,1501077860,,0,1
75,2017-7-27,2017,7,27,0,6poxrr,"Deep Learning Zero to One: 5 Awe-Inspiring Demos with Code for Beginners, part 2",https://www.reddit.com/r/deeplearning/comments/6poxrr/deep_learning_zero_to_one_5_aweinspiring_demos/,jackblun,1501084212,,0,0
76,2017-7-27,2017,7,27,1,6pp82q,Any good project ideas in Keras easy to implement?,https://www.reddit.com/r/deeplearning/comments/6pp82q/any_good_project_ideas_in_keras_easy_to_implement/,waverick,1501086702,"I want to practice in Keras/Tensorflow, do you have some project ideas for training?
",5,3
77,2017-7-27,2017,7,27,9,6psbir,A collection of best practices for using neural networks in Natural Language Processing,https://www.reddit.com/r/deeplearning/comments/6psbir/a_collection_of_best_practices_for_using_neural/,cognitivedemons,1501114762,,0,11
78,2017-7-27,2017,7,27,16,6pudtu,training - no. images vs no. objects in images,https://www.reddit.com/r/deeplearning/comments/6pudtu/training_no_images_vs_no_objects_in_images/,c94jk,1501140540,"I'm training an object detection network on a currently small dataset of 1000 images. In each image however there are on average 10-15 objects, sometimes more, sometimes less. Is the number of individual images an isolated factor, or does having relatively densely distributed objects help?

For reference I am getting an mAP or 80-90% using SSD on my dataset.",0,1
79,2017-7-27,2017,7,27,18,6pur7m,Using Deep Learning to find genetic causes of conditions such as Autism,https://www.reddit.com/r/deeplearning/comments/6pur7m/using_deep_learning_to_find_genetic_causes_of/,artificialbrainxyz,1501146624,,0,5
80,2017-7-27,2017,7,27,22,6pvvmh,How to train the RPN in Faster R CNN?,https://www.reddit.com/r/deeplearning/comments/6pvvmh/how_to_train_the_rpn_in_faster_r_cnn/,mimi_the_kid,1501161781,"[Link to paper](https://arxiv.org/abs/1506.01497)


I'm trying to understand the region proposal network in faster rcnn. I understand what it's doing, but I still don't understand how training exactly works, especially the details.

Let's assume we're using VGG16's last layer with shape 14x14x512 (before maxpool and with 228x228 images) and k=9 different anchors. At inference time I want to predict 9*2 class labels and 9*4 bounding box coordinates. My intermediate layer is a 512 dimensional vector.
(image shows 256 from ZF network)
[![from the paper][1]][1]


  [1]: https://i.stack.imgur.com/sK37S.png

In the paper they write 

&gt; ""we randomly sample 256 anchors in an image to compute the loss
&gt; function of a mini-batch, where the sampled positive and negative
&gt; anchors have a ratio of up to 1:1""

That's the part I'm not sure about. __Does this mean that for each one of the 9(k) anchor types the particular classifier and regressor are trained with minibatches that only contain positive and negative anchors of that type?__

Such that I basically train k different networks with shared weights in the intermediate layer? Therefore each minibatch would consist of the training data x=the 3x3x512 sliding window of the conv feature map and y=the ground truth for that specific anchor type.
And at inference time I put them all together.

I appreciate your help.",0,3
81,2017-7-27,2017,7,27,23,6pw8k3,Applying Deep Learning to Real-world Problems,https://www.reddit.com/r/deeplearning/comments/6pw8k3/applying_deep_learning_to_realworld_problems/,friscotime,1501165271,,0,12
82,2017-7-27,2017,7,27,23,6pw90h,Question: Can a mining rig be used for deep learning?,https://www.reddit.com/r/deeplearning/comments/6pw90h/question_can_a_mining_rig_be_used_for_deep/,snapo84,1501165389,"I found a kinda cheap mining rig with 6xGTX1070, but they are all connected with something like pcie 1x ... is this feasible to use it with for example tensorflow or not? can cudnn run with pcie 1x? or does it requrie 8x like in the specifications?",3,3
83,2017-7-27,2017,7,27,23,6pwez7,Using the TensorFlow API: An Introductory Tutorial Series,https://www.reddit.com/r/deeplearning/comments/6pwez7/using_the_tensorflow_api_an_introductory_tutorial/,lalypopa123,1501166971,,0,1
84,2017-7-28,2017,7,28,3,6pxqsf,Identifying Traffic Signs with Deep Learning,https://www.reddit.com/r/deeplearning/comments/6pxqsf/identifying_traffic_signs_with_deep_learning/,psangrene,1501178491,,0,5
85,2017-7-28,2017,7,28,8,6pzzki,"GANs, more than pretty pictures?",https://www.reddit.com/r/deeplearning/comments/6pzzki/gans_more_than_pretty_pictures/,pderuxx,1501198791,"Goodfellow done changed the game with GANs, or course. Generative modeling is intellectually more interesting that discriminative modeling, IMHO, as these issues relate to fundamental questions in AI and ultimately Philosophy of Mind. BUT, do GAN-based models have a place in *business* contexts?

A simple example is that of **semi-supervised GANs**, which can perform state-of-the-art classification on eg SVHN while a mere 1% of training data has a class label (the rest are only labeled ""real"" v ""fake"").

Any more?",4,1
86,2017-7-28,2017,7,28,16,6q2e98,Prediction pixels using RNN,https://www.reddit.com/r/deeplearning/comments/6q2e98/prediction_pixels_using_rnn/,pjavia,1501228661,"How to predict pixel values from previous pixels? Besides Pixel RNN is there any causal system that can achieve the same. Also, Is there a simpler way to do that? I tried using RNN but it heavily overfits. The loss does not decrease it oscillates even after decreasing learning rate. Any idea why that is happening?
Thank you",0,3
87,2017-7-28,2017,7,28,20,6q3877,Deep Learning with R + Keras,https://www.reddit.com/r/deeplearning/comments/6q3877/deep_learning_with_r_keras/,lalypopa123,1501241842,,0,1
88,2017-7-28,2017,7,28,20,6q3av8,Deep Learning Zero to One: 5 Awe-Inspiring Demos with Code for Beginners,https://www.reddit.com/r/deeplearning/comments/6q3av8/deep_learning_zero_to_one_5_aweinspiring_demos/,jackblun,1501242889,,0,7
89,2017-7-28,2017,7,28,21,6q3c1y,Taxonomy of Methods for Deep Meta Learning,https://www.reddit.com/r/deeplearning/comments/6q3c1y/taxonomy_of_methods_for_deep_meta_learning/,digitalson,1501243344,,0,9
90,2017-7-29,2017,7,29,12,6q8n8y,Traning GAN from scratch by using pytorch?,https://www.reddit.com/r/deeplearning/comments/6q8n8y/traning_gan_from_scratch_by_using_pytorch/,Alirezag,1501297366,"Can you anyone suggest any good tutorial for training GAN from scratch by using pytorch, please?
Thanks",0,3
91,2017-7-29,2017,7,29,18,6qa1x3,Pixel RNN - Row LSTM explanation in simplest manner possible? https://arxiv.org/abs/1601.06759,https://www.reddit.com/r/deeplearning/comments/6qa1x3/pixel_rnn_row_lstm_explanation_in_simplest_manner/,pjavia,1501319659,"Q-1 Row LSTM?
--&gt; Is this correct  sigmoid(Kss*h_i-1 + Kis*xi) --- (1)
or you meant to say sigmoid(Wh . Kss*h_i-1 + Wx . Ksi*x_i + b_x + b_h) ___ (2)

If authors meant (1) then how do they explain the hidden units = 512 in 4 layers for input size 64. If the authors meant (2) and are increasing hidden units what is the kernel size for the next layer?
Also, is Row LSTM described in the paper is same as ConvLSTM?

Q-2 Triangular context in ROW LSTM?

If padding is used during convolution and k=3, the output feature size is same as input, then how context is lost? 

Is training possible on single GPU or it requires multi GPU environment?

I would be more than grateful to receive any advice on this.",1,5
92,2017-7-30,2017,7,30,17,6qgeay,Breaking down the process of deep learning into components,https://www.reddit.com/r/deeplearning/comments/6qgeay/breaking_down_the_process_of_deep_learning_into/,maxtheman45,1501403950,"Hi everyone, new to this sub. Doing some research around the complexity of deep learning and was hoping to get some feedback on the process I've created. As I am not technical, I'm sure I'm missing some aspects and I would love to get as granular as possible. Thanks in advance for your help. 

1.	Determine how much training data is required
2.	Decide how to acquire the training data
3.	Decide to labeling the data post-training vs. pre-training &amp; post-training
4.	Deciding which framework to use
5.	Which CNN to run the data through 
6.	Defining the desired parameters of the CNN
7.	Configuring the parameters of the CNN
8.	Which computational environment to use to train the model
a.	Which type of server (IBM, Intel, Nvidia, etc)  either cloud or on-prem
9.	How to build an application that leverages one or more trained models
",0,4
93,2017-7-30,2017,7,30,19,6qgos9,How to get a free environment to run my deep code?,https://www.reddit.com/r/deeplearning/comments/6qgos9/how_to_get_a_free_environment_to_run_my_deep_code/,daicoolb,1501410031,"I want to run the code in GPU. But our laboratory does not have any support to achieve it. Can anyone give me some advice how to solve it? I have applied in google cloud and amazon service, but they only support for CPU.",11,6
94,2017-7-31,2017,7,31,10,6qlel8,How do people gather training images for Deep Learning?,https://www.reddit.com/r/deeplearning/comments/6qlel8/how_do_people_gather_training_images_for_deep/,Facial_Tissue,1501465758,"I hope you guys are having a good weekend.

I am currently working on a image classification part of deep learning and I am writing this to ask you guys about the gathering process of images for training.

I know that to train my network, I need to gather a lot of images for certain object. Usually, I did this with google image search and such, but I realized that when it comes to a certain object that doesn't have many useful images, then I had to roll up my sleeves to take photos of that object... which was darn tedious and time consuming to gather every possible angle, tilt, brightness and such for perfect image classification result.

Long story short, I haven't heard or found any specific image tool yet... but deep within the corners of my mind I just know that such tool exist for deep learning training process and I want to find it so badly.",1,1
95,2017-7-31,2017,7,31,11,6qlhdq,Robust Physical-World Attacks on Machine Learning Models - paper,https://www.reddit.com/r/deeplearning/comments/6qlhdq/robust_physicalworld_attacks_on_machine_learning/,dattgoswami,1501466756,,0,4
96,2017-7-31,2017,7,31,13,6qm7oq,Are ImageNet pre-trained models good for logo recognition?,https://www.reddit.com/r/deeplearning/comments/6qm7oq/are_imagenet_pretrained_models_good_for_logo/,brakaza,1501476008,"Hi there. I'm new to deep learning. I'm starting a project, where I have a dataset of logos and I want to find most similar logos to the one being uploaded by user.  
Is it a good idea to use ImageNet pre-trained models for this task? Or are there any better options?",2,1
97,2017-7-31,2017,7,31,18,6qnfsd,Artificial Neural Networks Tutorial - A Complete Guide,https://www.reddit.com/r/deeplearning/comments/6qnfsd/artificial_neural_networks_tutorial_a_complete/,pooja_edureka,1501495147,,0,3
98,2017-7-31,2017,7,31,23,6qoxs6,Time difference dual core cpu vs gtx 10 series,https://www.reddit.com/r/deeplearning/comments/6qoxs6/time_difference_dual_core_cpu_vs_gtx_10_series/,angularion,1501513080,"Im planning to get a new laptop for computer science.
I have just started learning tensorflow and found that it has gpu support.
So would Dell XPS 15 with GTX 1050 be a better fit than the XPS 13 as a laptop for a beginner?
Note that whatever I get will be the only computer I have and I prefer something portable hence considering the XPS line",5,3
0,2017-8-1,2017,8,1,21,6qvrvc,Understanding Deep Learning Requires Re-thinking Generalization,https://www.reddit.com/r/deeplearning/comments/6qvrvc/understanding_deep_learning_requires_rethinking/,digitalson,1501589242,,0,1
1,2017-8-1,2017,8,1,21,6qvsxy,"Medical Image Analysis with Deep Learning , Part 3",https://www.reddit.com/r/deeplearning/comments/6qvsxy/medical_image_analysis_with_deep_learning_part_3/,friscotime,1501589596,,0,1
2,2017-8-2,2017,8,2,20,6r3lit,The Difference Between AI and Machine Learning,https://www.reddit.com/r/deeplearning/comments/6r3lit/the_difference_between_ai_and_machine_learning/,cevizligizem,1501674235,,0,0
3,2017-8-3,2017,8,3,0,6r4u6p,Deep Learning: TensorFlow Programming via XML and PMML,https://www.reddit.com/r/deeplearning/comments/6r4u6p/deep_learning_tensorflow_programming_via_xml_and/,magneticono,1501686891,,0,1
4,2017-8-3,2017,8,3,2,6r5ws5,Convolutional Networks for High Resolution Images,https://www.reddit.com/r/deeplearning/comments/6r5ws5/convolutional_networks_for_high_resolution_images/,waxymcrivers,1501695928,"Can anyone recommend a technique for predicting/classifying on high resolution (2000x2000 pixel) images?

I'm aware of the aggressive down-sampling technique that allows normal conv networks to handle these images by reducing computational complexity, but the images I'm working with are unlike medical images with high detail and many features. My images are high frequency with subtle features; every bit of detail counts.

I had a thought of possibly breaking the image into sub patches and feeding each patch into an LSTM, so that the patches are fed in as if they were frames of a video and each prediction feeds into the next. Not sure if it would work as I imagine it might.",9,3
5,2017-8-3,2017,8,3,6,6r7hgg,"I have a working LSTM that learns to predict the next character in a text, now struggling to make it produce its own text",https://www.reddit.com/r/deeplearning/comments/6r7hgg/i_have_a_working_lstm_that_learns_to_predict_the/,JustinQueeber,1501709265,"I have just recently begun studying Deep Learning and also have no previous experience with TensorFlow. I am very confident in my understanding of the theoretical side of Neural Networks and have written a couple of very simple RNNs from scratch. I have now started to become familiar with using TensorFlow and have been trying to implement slightly more advanced NNs using it.

Currently, I am writing an LSTM that reads sequences of characters from a text, character-by-character, and then (hopefully) learns to accurately predict the next character. I encoded each character in the vocab as a one-hot vector of length equal to the size of the vocab, and the 1 represents the key to that character in my `int : char` map. The model takes as input `n` batches (100 in the example) of `m` character input and label sequences (25 in the example). These input sequences are just any random sequence of `m` characters from the first 80% of the text, the labels are the same sequences, but shifted one character forward. The last 20% is then used for validating the model's accuracy after it has been trained.

It can train itself to over 90% accuracy over 10,000 iterations of 100 batches of 25 character sequences, and and slightly lower level of accuracy on the unseen 20%  of the text (unless there are errors in my model somewhere).

I am now attempting to allow my model to generate its own text after it has been trained. You will see my attempt at the bottom of my code. This is completely wrong as it is still takes in sequences of length 25, predicts the next 25 characters, and then uses this sequence of 25 predicted characters as the next input. Therefore, each time it is still only shifting along by one character and so each sequence it produces is nearly identical.

In order to correct this, I need my model to still train itself with the `m` length sequences, but then in the generating stage it must just take one character as input, predict the next character, and then use this predicted character as the next input. To do this, I will need to adjust my TensorFlow graph so that the `sequenceLength` variable used throughout is implemented using a `placeholder` instead of a fixed integer. That way, I will be able to set `sequenceLength` to 25 when training, and 1 when generating.

I did something similar with the `batchSz` placeholder, but I cannot seem to reproduce something similar for `sequenceLength`.

    from __future__ import print_function
    import tensorflow as tf
    from tensorflow.contrib import rnn
    import numpy as np
    import random

    text = open(""/home/kev/Documents/NeuralNetworks/CharacterPredicter/input.txt"", 'r').read()
    #text = ""abcdefghi""
    vocab = list(set(text))
    textSize = len(text)
    vocabSize = len(vocab)
    testingStartChar = int(textSize * 0.8)

    charToInt = {char : i for i, char in enumerate(vocab)}
    intToChar = {i : char for i, char in enumerate(vocab)}

    sequenceLength = 25  # Must be strictly < (textSize / 5)
    trainingIterations = 10000
    batchSize = 100
    numTestingSequences = int((textSize - testingStartChar - 1) / sequenceLength)

    hiddenDimension = 100
    learningRate = 0.01
    forgetRate = 1.0
    printStep = 1000

    # Returns two 3D arrays of shape (batchSize x seqLength x vocabSize)
    def generateData(batchSize, seqLength, isTraining):
        inputs = []                                                 # e.g.  a, b = generateData(2, 3, True)
        labels = []
        charPointer = testingStartChar                              #       a -> [[[0, 1, ..., 0], [1, 0, ..., 0], [0, 0, ..., 1]]
        for _ in range(batchSize):                                  #             [[1, 0, ..., 0], [0, 0, ..., 1], [0, 1, ..., 0]]]
            inputSequence = []
            labelSequence = []
            if isTraining:
                charPointer = random.randint(0, testingStartChar - seqLength)
            for _ in range(seqLength):
                oneHotInput = charToOneHot(text[charPointer])
                oneHotLabel = charToOneHot(text[charPointer + 1])
                inputSequence.append(oneHotInput)
                labelSequence.append(oneHotLabel)
                charPointer += 1
            inputs.append(inputSequence)
            labels.append(labelSequence)
        return inputs, labels

    # Takes in a single character and returns its corresponding
    # one-hot vector of length vocabSize
    def charToOneHot(char):
        oneHot = [0] * vocabSize
        oneHot[charToInt[char]] = 1
        return oneHot

    # Takes in a one-hot vector and returns its corresponding char
    def oneHotToChar(oneHot):
        charIndex = np.argmax(oneHot)
        return intToChar[charIndex]

    # Takes in a 3D array (last axis is one-hot vectors) and returns
    # an array of the corresponding strings per row (batchSize)
    # (Used for printing outputs)
    def oneHotsToChars(array):                                          # e.g. [[[0, 1, ..., 0], [1, 0, ..., 0], [0, 0, ..., 1]],
        chars = []                                                      #       [[1, 0, ..., 0], [0, 0, ..., 1], [0, 1, ..., 0]]]
        for batchIndex in range(len(array)):
            batchChars = """"                                             # ->   ['hpb',
            for oneHotIndex in range(len(array[batchIndex])):           #      'pbh']
                batchChars += oneHotToChar(array[batchIndex][oneHotIndex])
            chars.append(batchChars)
        return chars

    # Takes a 3D array of real numbers (batchSize x sequenceLength x vocabSize)
    # and returns a 3D array with the last axis being one-hot vectors
    # corresponding to the real number of the highest value
    def predictionToOneHots(prediction):
        oneHots = []
        for batchIndex in range(len(prediction)):
            batchOneHots = []
            for charArrayIndex in range(len(prediction[batchIndex])):
                charArray = prediction[batchIndex][charArrayIndex]
                charOneHot = [0] * len(charArray)
                charIndex = np.argmax(charArray)
                charOneHot[charIndex] = 1
                batchOneHots.append(charOneHot)
            oneHots.append(batchOneHots)
        return oneHots

    batchSz = tf.placeholder(tf.int32, shape=())
    x = tf.placeholder(tf.float32, [None, sequenceLength, vocabSize])
    y = tf.placeholder(tf.float32, [None, sequenceLength, vocabSize])
    xFlat = tf.contrib.layers.flatten(x)                                                # [batchSize, sequenceLength*vocabSize]

    W = tf.Variable(tf.random_normal([hiddenDimension, sequenceLength, vocabSize]))
    b = tf.Variable(tf.random_normal([1, sequenceLength, vocabSize]))
    WFlat = tf.contrib.layers.flatten(W)                                                # [hiddenDimension, sequenceLength*vocabSize]
    bFlat = tf.contrib.layers.flatten(b)                                                # [1, sequenceLength*vocabSize]

    cell = rnn.BasicLSTMCell(hiddenDimension, forget_bias=forgetRate)
    outputs, states = tf.nn.static_rnn(cell, [xFlat], dtype=tf.float32)                 # outputs    = [[batchSize, hiddenDimension]]
    predictionFlat = tf.add(tf.matmul(outputs[0], WFlat), bFlat)                        # outputs[0] = [batchSize, hiddenDimension]
    prediction = tf.reshape(predictionFlat, [batchSz, sequenceLength, vocabSize])

    # 2D array corresponding to whether character per sequence per batch was predicted correctly
    # A correct prediction is when the highest predicted value is the same index as the 1 of the one-hot label
    correctPrediction = tf.equal(tf.argmax(prediction, axis=2), tf.argmax(y, axis=2))   # [batchSize, sequenceLength]
    accuracy = tf.reduce_mean(tf.cast(correctPrediction, tf.float32))

    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction, labels=y))
    optimiser = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss)

    with tf.Session() as session:
        session.run(tf.global_variables_initializer())

        ############################################################################
        #   TRAINING
        ############################################################################
        for iteration in range(trainingIterations):
            batchX, batchY = generateData(batchSize, sequenceLength, isTraining=True)
            dict = {batchSz: batchSize, x: batchX, y: batchY}
            session.run(optimiser, dict)
            if (iteration + 1) % printStep == 0 or iteration in (0, trainingIterations - 1):
                batchAccuracy = session.run(accuracy, dict)
                batchLoss  = session.run(loss, dict)
                # inputOneHots = session.run(x, dict)
                # labelOneHots = session.run(y, dict)
                # predictions = session.run(prediction, dict)
                # correctPredictions = session.run(correctPrediction, dict)
                print(""Iteration:\t"" + str(iteration + 1))
                print(""Accuracy:\t"" + str(""%.2f"" % (batchAccuracy * 100) + ""%""))
                print(""Loss:\t\t"" + str(batchLoss) + ""\n"")
                # print(""Inputs:\n"" + str(oneHotsToChars(inputOneHots)) + ""\n"")
                # print(""Labels:\n"" + str(oneHotsToChars(labelOneHots)) + ""\n"")
                # print(""Prediction:\n"" + str(oneHotsToChars(predictionToOneHots(predictions))) + ""\n"")
                # print(""Correct:\n"" + str(correctPredictions) + ""\n"")

        ############################################################################
        #   TESTING
        ############################################################################
        testX, testY = generateData(numTestingSequences, sequenceLength, isTraining=False)
        testAccuracy = session.run(accuracy, feed_dict={batchSz: numTestingSequences, x: testX, y: testY})
        print(""Testing Accuracy: "" + str(""%.2f"" % (testAccuracy * 100) + ""%""))

        ############################################################################
        #   GENERATING
        ############################################################################
        def stringToOneHots(string):
            oneHots = []
            for char in string:
                oneHots.append(charToOneHot(char))
            return oneHots

        randIndex = random.randint(0, textSize - sequenceLength)
        seedSequence = text[randIndex: randIndex + sequenceLength]
        inputOneHots = stringToOneHots(seedSequence)

        generatedText = """"
        for _ in range(100):
            dict = {x: [inputOneHots], batchSz: 1}
            pred = session.run(prediction, dict)
            predString = oneHotsToChars(predictionToOneHots(pred))[0]
            inputOneHots = stringToOneHots(predString)
            generatedText += predString

        print(generatedText)



*Side Notes:*

1. If you uncomment all the `print` lines in the training loop, and reduce `sequenceLength` and `batchSize` to lower values, like 3, it is easier to follow exactly how the model works and what  outputs it produces at each stage.

2. Is my method of initially keeping things in 3D arrays (batchSize x sequenceLength x vocabSize), and then flattening it all to be processed with TensorFlow ok? I find it easier to visualise all of the data in these dimensions, rather than having huge arrays of all the one-hot vectors concatenated into one. However, the code does get a bit messy by flattening everything, and then reshaping it all back into its original format. ",0,2
6,2017-8-3,2017,8,3,23,6rcjum,Train your Deep Learning model faster and sharper: Snapshot Ensembling,https://www.reddit.com/r/deeplearning/comments/6rcjum/train_your_deep_learning_model_faster_and_sharper/,digitalson,1501769604,,1,1
7,2017-8-3,2017,8,3,23,6rckbz,DeepSense: A unified deep learning framework for time-series mobile sensing data processing,https://www.reddit.com/r/deeplearning/comments/6rckbz/deepsense_a_unified_deep_learning_framework_for/,magneticono,1501769738,,0,12
8,2017-8-4,2017,8,4,0,6rd2l2,Deep Learning Hyperparameter Optimization with Competing Objectives,https://www.reddit.com/r/deeplearning/comments/6rd2l2/deep_learning_hyperparameter_optimization_with/,harrism,1501774367,,1,4
9,2017-8-4,2017,8,4,7,6rfyn7,Encode not resolved embeddings,https://www.reddit.com/r/deeplearning/comments/6rfyn7/encode_not_resolved_embeddings/,riku_iki,1501798270,"I am building TensorFlow model for NLP task, and I am using pretrained Glove 300d word-vector/embedding dataset.

Obviously some tokens can't be resolved as embeddings, because were not included into training dataset for word vector embedding model, e.g. rare names.

I can replace those tokens with vectors of 0s, but rather than dropping this information on the floor, I prefer to encode it somehow and include to my training data.

Say, I have 'raijin' word, which can't be resolved as embedding vector, what would be the best way to encode it consistently with Glove embedding dataset? What is the best approach to convert it to 300d vector?

Thank you.",1,1
10,2017-8-4,2017,8,4,9,6rgphj,Building Tensorflow from Scratch,https://www.reddit.com/r/deeplearning/comments/6rgphj/building_tensorflow_from_scratch/,czhu12,1501805276,,0,12
11,2017-8-4,2017,8,4,14,6riheo,Image Labelling Tools,https://www.reddit.com/r/deeplearning/comments/6riheo/image_labelling_tools/,uridah,1501825121,I am looking for a tool that can help me in labelling image data. I have satellite images of roofs and I am trying to label roof sections and trees. Somebody suggested http://labelme.csail.mit.edu/Release3.0/browserTools/php/mechanical_turk.php but this looks too complicated. Are there any other tools available for this?,8,1
12,2017-8-4,2017,8,4,19,6rjmcl,Data Science Digest - Issue #9,https://www.reddit.com/r/deeplearning/comments/6rjmcl/data_science_digest_issue_9/,flyelephant,1501842924,,0,1
13,2017-8-4,2017,8,4,23,6rku6z,Train your Deep Learning Faster: FreezeOut,https://www.reddit.com/r/deeplearning/comments/6rku6z/train_your_deep_learning_faster_freezeout/,molode,1501857138,,0,11
14,2017-8-5,2017,8,5,2,6rlxes,Deep Learning 101: Demystifying Tensors,https://www.reddit.com/r/deeplearning/comments/6rlxes/deep_learning_101_demystifying_tensors/,magneticono,1501866758,,0,3
15,2017-8-5,2017,8,5,4,6rmoet,Data preprocessing for deep learning with nuts-ml,https://www.reddit.com/r/deeplearning/comments/6rmoet/data_preprocessing_for_deep_learning_with_nutsml/,jackblun,1501873298,,0,2
16,2017-8-5,2017,8,5,6,6rnobe,DeepRL bootcamp-Berkeley,https://www.reddit.com/r/deeplearning/comments/6rnobe/deeprl_bootcampberkeley/,hull11,1501882470,"Anybody here attending the bootcamp from Aug 26-Aug 27,2017?",4,2
17,2017-8-6,2017,8,6,20,6rxw2k,Is there any deep learning software where I can specify the number of CPU cores to work on ?,https://www.reddit.com/r/deeplearning/comments/6rxw2k/is_there_any_deep_learning_software_where_i_can/,dexterdev30,1502019092,"Hi I am from a University in India where we have CPU cluster facility for doing MD (molecular dynamics) simulations etc. Unfortunately there are no GPUs. *I want to know if there exists any ML/DL software existing, where I can train models by specifying the number of cores?* I use a MD software called NAMD where we run it using *mpirun* by specifying the number of cores. So I was thinking if I can get something similar for ML/DL.",4,1
18,2017-8-7,2017,8,7,3,6rzyqx,When Not to Use Deep Learning,https://www.reddit.com/r/deeplearning/comments/6rzyqx/when_not_to_use_deep_learning/,psangrene,1502043681,,0,7
19,2017-8-7,2017,8,7,5,6s0njr,Deep Learning with Python and Keras,https://www.reddit.com/r/deeplearning/comments/6s0njr/deep_learning_with_python_and_keras/,alphatym,1502050563,,0,1
20,2017-8-7,2017,8,7,15,6s3vvv,DeepLearning for text analysis and NLP,https://www.reddit.com/r/deeplearning/comments/6s3vvv/deeplearning_for_text_analysis_and_nlp/,rajnp,1502088291,"Hi,

I am new to ML/DL and thinking about whether DL would help me to solve the below use case,

Users will raise a support request thru our existing ticketing system. Now my ML should read the description and understand the below key points,

  1. Severity
  2. Sentiment (+ve or -ve)
  3. If any key information like user id,  email, etc (already configured) are missing

If it is possible, what type of model I have to choose and what would be the high level NN architecture required for this?

Thanks.",3,1
21,2017-8-7,2017,8,7,22,6s5i8x,Deep Learning in Medical Imaging Diagnosis,https://www.reddit.com/r/deeplearning/comments/6s5i8x/deep_learning_in_medical_imaging_diagnosis/,artificialbrainxyz,1502112485,,0,0
22,2017-8-7,2017,8,7,23,6s5v1w,Recent Breakthroughs in Deep Learning and Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/6s5v1w/recent_breakthroughs_in_deep_learning_and/,artificialbrainxyz,1502116166,,0,0
23,2017-8-8,2017,8,8,3,6s7ho9,Step by Step Example to Version Control Machine Learning and Deep Learning Tasks - Numerai Model Prediction,https://www.reddit.com/r/deeplearning/comments/6s7ho9/step_by_step_example_to_version_control_machine/,thumbsdrivesmecrazy,1502130254,,0,4
24,2017-8-8,2017,8,8,18,6schsj,Inside Google: in this way we use the Deep Learning,https://www.reddit.com/r/deeplearning/comments/6schsj/inside_google_in_this_way_we_use_the_deep_learning/,chvleo,1502186306,,0,1
25,2017-8-8,2017,8,8,21,6sd9m6,An Introduction to the MXNet Python API,https://www.reddit.com/r/deeplearning/comments/6sd9m6/an_introduction_to_the_mxnet_python_api/,janemoz,1502196705,,0,1
26,2017-8-8,2017,8,8,23,6sdtgf,IBM claims big Deep Learning breakthrough,https://www.reddit.com/r/deeplearning/comments/6sdtgf/ibm_claims_big_deep_learning_breakthrough/,chlordane2501,1502202386,,1,0
27,2017-8-9,2017,8,9,0,6seepb,Using AI to Super Compress Images  Hacker Noon,https://www.reddit.com/r/deeplearning/comments/6seepb/using_ai_to_super_compress_images_hacker_noon/,harvey_slash,1502207797,,0,1
28,2017-8-9,2017,8,9,1,6selby,Andrew Ng launches new deep learning course on Coursera,https://www.reddit.com/r/deeplearning/comments/6selby/andrew_ng_launches_new_deep_learning_course_on/,pfrcks,1502209385,,2,16
29,2017-8-9,2017,8,9,6,6sgllc,Top Deep Learning Books,https://www.reddit.com/r/deeplearning/comments/6sgllc/top_deep_learning_books/,kjahan,1502226569,,0,1
30,2017-8-9,2017,8,9,10,6si56e,TensorFlow Serving 1.0,https://www.reddit.com/r/deeplearning/comments/6si56e/tensorflow_serving_10/,_rusht,1502241696,,0,2
31,2017-8-9,2017,8,9,18,6sk9kv,Computer Vision News and BEST OF CVPR2017,https://www.reddit.com/r/deeplearning/comments/6sk9kv/computer_vision_news_and_best_of_cvpr2017/,Gletta,1502269511,"This is Computer Vision News of August, published by RSIP Vision, with 56 pages of exclusive content about computer vision, artificial intelligence, deep learning and image processing. Most of it is a BEST OF CVPR section, including many reviews of work presented 2 weeks ago at CVPR2017 in Honolulu, Hawaii.
HTML5 version (recommended) ==> http://www.rsipvision.com/ComputerVisionNews-2017August/
and
PDF version ==> http://www.rsipvision.com/computer-vision-news-2017-august-pdf/
Enjoy!",1,3
32,2017-8-9,2017,8,9,22,6slklz,Autonomio | Unlike Human Intelligence,https://www.reddit.com/r/deeplearning/comments/6slklz/autonomio_unlike_human_intelligence/,mikkokotila,1502286432,,0,4
33,2017-8-10,2017,8,10,3,6snmp7,UK based company was looking to hire a few hundred people in AI domain,https://www.reddit.com/r/deeplearning/comments/6snmp7/uk_based_company_was_looking_to_hire_a_few/,chvleo,1502304770,,0,1
34,2017-8-10,2017,8,10,16,6srr5w,Autonomous Selfie Drone by Crazyflie using Deep Learning Models,https://www.reddit.com/r/deeplearning/comments/6srr5w/autonomous_selfie_drone_by_crazyflie_using_deep/,ildoonet,1502349967,,0,1
35,2017-8-10,2017,8,10,23,6stimm,"Who is the child of the artificial intelligence for which Google has paid a transfer price of nearly 600 million dollars PHOTO, VIDEO",https://www.reddit.com/r/deeplearning/comments/6stimm/who_is_the_child_of_the_artificial_intelligence/,chvleo,1502373930,,0,1
36,2017-8-10,2017,8,10,23,6stoac,Deep Learning Framework- TensorFLow and PyTorch,https://www.reddit.com/r/deeplearning/comments/6stoac/deep_learning_framework_tensorflow_and_pytorch/,sudheeran,1502375470,,0,1
37,2017-8-11,2017,8,11,0,6su5nf,Preparing for the Transition to Applied AI - A Guide for Software Engineers,https://www.reddit.com/r/deeplearning/comments/6su5nf/preparing_for_the_transition_to_applied_ai_a/,e_ameisen,1502379935,,0,7
38,2017-8-11,2017,8,11,14,6sz25o,Anyone interested in Kaggle competition,https://www.reddit.com/r/deeplearning/comments/6sz25o/anyone_interested_in_kaggle_competition/,chitrang6,1502428296,"Hello folks, I am planning to work on some image based kaggle datasets or competition. Kindly let me know if anyone is interested. My Gmail - chitrang6@gmail.com. LinkedIn- www.linkedin.com/in/chitrangtalaviya",0,1
39,2017-8-11,2017,8,11,20,6t0fis,Trailblazing Tech in Facial Recognition,https://www.reddit.com/r/deeplearning/comments/6t0fis/trailblazing_tech_in_facial_recognition/,truefaceAI,1502449683,,0,1
40,2017-8-11,2017,8,11,21,6t0xuv,The Future of Artificial Intelligence: Predictions for 2018,https://www.reddit.com/r/deeplearning/comments/6t0xuv/the_future_of_artificial_intelligence_predictions/,cevizligizem,1502455982,,0,0
41,2017-8-12,2017,8,12,2,6t2sva,Number plate detection with Supervisely and Tensorflow,https://www.reddit.com/r/deeplearning/comments/6t2sva/number_plate_detection_with_supervisely_and/,tdionis,1502473469,,0,2
42,2017-8-13,2017,8,13,6,6tb93a,Tensorflow from Scratch pt 2,https://www.reddit.com/r/deeplearning/comments/6tb93a/tensorflow_from_scratch_pt_2/,czhu12,1502574977,,0,8
43,2017-8-14,2017,8,14,5,6thltr,Mind Reading: Using Artificial Neural Nets to Predict Viewed Image Categories From EEG Readings,https://www.reddit.com/r/deeplearning/comments/6thltr/mind_reading_using_artificial_neural_nets_to/,trumtra,1502656796,,0,1
44,2017-8-14,2017,8,14,5,6thms7,Going deeper with recurrent networks: Sequence to Bag of Words Model,https://www.reddit.com/r/deeplearning/comments/6thms7/going_deeper_with_recurrent_networks_sequence_to/,lalypopa123,1502657095,,0,1
45,2017-8-14,2017,8,14,14,6tkg62,Is Spark useful in deep learning?,https://www.reddit.com/r/deeplearning/comments/6tkg62/is_spark_useful_in_deep_learning/,jobsforlifkla,1502688805,I'm getting started with deep learning starting with Tensor Flow. Do you recommend learning Spark as well?,4,4
46,2017-8-14,2017,8,14,17,6tl34w,I open source a Deep Learning toolkit base on iOS Metal on github:https://github.com/amazingyyc/Brouhaha Someone who is interested in Mobile-Deep Learning could use it,https://www.reddit.com/r/deeplearning/comments/6tl34w/i_open_source_a_deep_learning_toolkit_base_on_ios/,amazingyyc,1502698809,,0,2
47,2017-8-14,2017,8,14,19,6tljm0,Must read breakthrough research papers about Image Classification using Deep Learning,https://www.reddit.com/r/deeplearning/comments/6tljm0/must_read_breakthrough_research_papers_about/,parth10,1502706449,,0,1
48,2017-8-14,2017,8,14,23,6tmmjy,The largest AI event in Germany,https://www.reddit.com/r/deeplearning/comments/6tmmjy/the_largest_ai_event_in_germany/,DeeJayDeepLearning,1502719651,"https://www.gputechconf.eu/Register.aspx

Use code DanielSaaristoGTCEU17 for a 25% discount on any ticket",0,0
49,2017-8-15,2017,8,15,6,6tpl10,"Learning, Deep Learning. Where to start?",https://www.reddit.com/r/deeplearning/comments/6tpl10/learning_deep_learning_where_to_start/,eardil,1502745943,"Hi! First time redditing (is that a word here?). Anyway, I'm trying to learn to implement deep learning, specifically RNNs. And I'm struggling to decide where to start.

My problem is not with the theory, I'm an applied mathematician, I have implemented other models (including NN) in the past and work doing ML and NLP. I've been reading and getting familiar with the theory of DL for a while now. Nor is it configuration, since I've installed and tested TF for GPU.

The thing is the technology seems to be moving really fast and I don't know which tool to learn (TF, Keras, TF+Keras) and every tutorial I've started seems to be outdated by some new language or interface so I keep getting paranoid of learning syntax that I'll have to forget soon (I'm working in Python BTW). Does anyone have some insight/advice on where to start if I'm doing it at this instant?

tl;dr Fairly familiar with theory of DL but don't know what language/API to start learning.",3,1
50,2017-8-15,2017,8,15,21,6ttuad,Gpu selection for server grid,https://www.reddit.com/r/deeplearning/comments/6ttuad/gpu_selection_for_server_grid/,abhi_annamraju,1502800868,"Which gpu architecture should be used to create a server grid? - Nvidia Tesla series (P40, p100, M40, etc) or Nvidia GeForce (Titan XP, 1080 TI, 980 TI etc)
As pointed out over the comments, adding here more specs:
1. Need to accommodate convnet, semantic segmentation, and GAN based networks requiring GPU RAM specification of more than 20 GB.
2. Data is satellite imagery ranging upto 1-1.5 TB.
3. Softwares/Tools: Keras/TF.
4. OS: Linux.
5. CPUs: Yet to decide. Will select a one compatible with GPU architecture.

Consider the case associated: If I have 2 P40s, each having 24Gigs of RAM. Now suppose I am running a CycleGAN module training (on Keras/TF) which requires 30 GB RAM with the batch size I selected. Will these P40s communicate to assign the required GPU. {Read this from a blog: Tesla/Quadro Pascal Unified Memory allows GPUs to share each others memory to load even larger datasets]. I haven't got the chance to test it out, so asking it here. 


 ",4,1
51,2017-8-16,2017,8,16,2,6tvnts,Free Deep Learning Book (MIT Press),https://www.reddit.com/r/deeplearning/comments/6tvnts/free_deep_learning_book_mit_press/,psangrene,1502818036,,4,11
52,2017-8-16,2017,8,16,2,6tvqq6,Two Great Courses on Deep Learning and AI,https://www.reddit.com/r/deeplearning/comments/6tvqq6/two_great_courses_on_deep_learning_and_ai/,psangrene,1502818726,,0,5
53,2017-8-16,2017,8,16,3,6tw3h3,Are there any papers comparing the ImageNet problem vs. binary ImageNet (hot_dog/not_hot_dog) problem?,https://www.reddit.com/r/deeplearning/comments/6tw3h3/are_there_any_papers_comparing_the_imagenet/,gukjoon,1502821708,Are there any studies on whether we get much higher performance when building a NN to detect a particular ImageNet class vs. building a general NN to detect all the ImageNet classes. Is the precision of the former >> precision of the latter? What about recall?,0,0
54,2017-8-16,2017,8,16,4,6twqf8,Tutorial on deep learning in Python,https://www.reddit.com/r/deeplearning/comments/6twqf8/tutorial_on_deep_learning_in_python/,pvigier,1502827191,"Hello everyone!

I've written two blog posts:

* [Part 1 is about computational graphs and how to code a little framework for doing deep learning](https://pvigier.github.io/2017/07/21/pychain-part1-computational-graphs.html)
* [Part 2 is about using this framework on MNIST dataset](https://pvigier.github.io/2017/08/13/pychain-part2-mnist.html)

And I want to share them with you so please, feel free to give me your thoughts on them!

I am planning on writing about RNNs and LSTM next and also reproducing the results of Karparthy on text generation.",2,5
55,2017-8-16,2017,8,16,17,6u0sdp,Data Science Digest - Issue #10,https://www.reddit.com/r/deeplearning/comments/6u0sdp/data_science_digest_issue_10/,flyelephant,1502873803,,0,0
56,2017-8-16,2017,8,16,22,6u1xlv,Top 5 Benefits of Containerization,https://www.reddit.com/r/deeplearning/comments/6u1xlv/top_5_benefits_of_containerization/,cevizligizem,1502889148,,0,0
57,2017-8-16,2017,8,16,22,6u2649,"The Difference between Artificial Intelligence, Machine Learning and Deep Learning?",https://www.reddit.com/r/deeplearning/comments/6u2649/the_difference_between_artificial_intelligence/,truefaceAI,1502891621,,0,0
58,2017-8-16,2017,8,16,23,6u2c31,DataScan Digest: Issue #43,https://www.reddit.com/r/deeplearning/comments/6u2c31/datascan_digest_issue_43/,[deleted],1502893177,[deleted],0,0
59,2017-8-16,2017,8,16,23,6u2d1v,Is the movidius stick suitable for training a semantic segmentation network ?,https://www.reddit.com/r/deeplearning/comments/6u2d1v/is_the_movidius_stick_suitable_for_training_a/,jean-pat,1502893451,,1,0
60,2017-8-17,2017,8,17,1,6u32ml,Andrew Ng is raising a $150M AI Fund,https://www.reddit.com/r/deeplearning/comments/6u32ml/andrew_ng_is_raising_a_150m_ai_fund/,milly1993,1502899809,,1,4
61,2017-8-17,2017,8,17,3,6u47i6,Scaling Keras Model Training to Multiple GPUs,https://www.reddit.com/r/deeplearning/comments/6u47i6/scaling_keras_model_training_to_multiple_gpus/,harrism,1502909571,,0,6
62,2017-8-17,2017,8,17,16,6u8b57,Tutorial: quick guide on how to train keras UNet implementation on Cityscapes dataset,https://www.reddit.com/r/deeplearning/comments/6u8b57/tutorial_quick_guide_on_how_to_train_keras_unet/,tdionis,1502953353,,0,0
63,2017-8-17,2017,8,17,22,6ua2hk,First Steps of Learning Deep Learning: Image Classification in Keras,https://www.reddit.com/r/deeplearning/comments/6ua2hk/first_steps_of_learning_deep_learning_image/,dearpetra,1502977713,,0,3
64,2017-8-17,2017,8,17,22,6ua2p9,A Guide to Understanding AI Toolkits,https://www.reddit.com/r/deeplearning/comments/6ua2p9/a_guide_to_understanding_ai_toolkits/,molode,1502977775,,0,1
65,2017-8-17,2017,8,17,23,6ua71q,The Two Phases of Gradient Descent in Deep Learning,https://www.reddit.com/r/deeplearning/comments/6ua71q/the_two_phases_of_gradient_descent_in_deep/,digitalson,1502978961,,0,0
66,2017-8-17,2017,8,17,23,6uabsq,Using Deep Learning To Extract Knowledge From Job Descriptions,https://www.reddit.com/r/deeplearning/comments/6uabsq/using_deep_learning_to_extract_knowledge_from_job/,dearpetra,1502980228,,0,0
67,2017-8-18,2017,8,18,18,6ugri2,Deep Learning In Retail,https://www.reddit.com/r/deeplearning/comments/6ugri2/deep_learning_in_retail/,avilash100,1503048982,"How do you detect individual instances of retail boxes and classify them on supermarket shelves.
The number of classes may range from 10000 - 100000.",3,2
68,2017-8-19,2017,8,19,2,6uje5g,Dogs vs. Cats: Image Classification with Deep Learning using TensorFlow in Python,https://www.reddit.com/r/deeplearning/comments/6uje5g/dogs_vs_cats_image_classification_with_deep/,psangrene,1503077583,,0,1
69,2017-8-19,2017,8,19,7,6ulb1r,Assembling a team of Deep Learning enthusiasts for a chatroom for General AI research.,https://www.reddit.com/r/deeplearning/comments/6ulb1r/assembling_a_team_of_deep_learning_enthusiasts/,nkoutrou,1503095342,"The basic idea behind this project is the creation of a *chat-room* of highly qualified individuals interested in the development of novel applications of AI towards product development as well as academic research. 

Our team wants to focus on the Deep Learning approach to general AI so we are specifically looking for people with experience and ambition to succeed in this particular field. Your position in such a group aids both the quality of it as a whole as much as it aids you to better yourself since youll have access to many other deep learners with whom you can discuss area-specific concerns. Of course, to create such a community we need to implement a safeguard in the form of an interview/ exam to ensure that we are both headed in the same direction. Bear in mind that down the line this chat-room is also a prospect for professional employment so your temporal investment will most likely also pay out in the literal sense, should you choose to engage in the commercial side of things.

This project will be a **paid** venture for anyone who chooses to assist in the development of any product that comes from it. 

If being a part of such a team interests you can find a full description of what our idea is and of the way we plan to implement it, go ahead and read this document:  https://docs.google.com/document/d/1I4LiAJB-mxcXrQmfUJfSUj_V8_5XwNz_8CKxEZC1dfI/edit

**TL;DR:** Does a chatroom for General AI through Deep Learning sound like your kind of thing? *Check out our google doc!*
",2,3
70,2017-8-19,2017,8,19,9,6um1ev,SimpleDNN is a machine learning library written in Kotlin whose purpose is to support the development of feed-forward and recurrent Neural Networks,https://www.reddit.com/r/deeplearning/comments/6um1ev/simplednn_is_a_machine_learning_library_written/,matteo_reddit,1503103445,,0,3
71,2017-8-19,2017,8,19,16,6unqwx,What can be the best ways to fit on failed test cases?,https://www.reddit.com/r/deeplearning/comments/6unqwx/what_can_be_the_best_ways_to_fit_on_failed_test/,raghuemani,1503127033,"I have been trying to solve a recognition problem on real world handwriting dataset using EMNIST data by various forms of augmentation on EMNIST which looks like real.

So after testing, I found out there are some close cases where it is very much evident that for example it is a '8' but predicted as '3' due to bad image quality.

Since, I don't have much real data which I can use for training and testing so basically dependent on EMNIST data. 
Now, what I would like to know are the best practices Deep learning community adopts while fitting model on failed cases, how would you use failed cases to your advantage? 
Can we augment the failed cases and try to fit a model on it from pre-trained weights, but I feel that would somehow overfit on test data since augmentation doesn't create independent samples.
Thanks   ",0,1
72,2017-8-19,2017,8,19,17,6unzv3,New Gitter chat channel about Artificial General Intelligence / Strong AI,https://www.reddit.com/r/deeplearning/comments/6unzv3/new_gitter_chat_channel_about_artificial_general/,razvanpanda,1503131606,,1,1
73,2017-8-19,2017,8,19,19,6uoa1p,Facebook's controversial patent grants extend to caffe as well,https://www.reddit.com/r/deeplearning/comments/6uoa1p/facebooks_controversial_patent_grants_extend_to/,sandys1,1503137006,"What is the opinion of the community on the patent grants that facebook has in place for caffe ?
Basically, the issue came up from facebook's [refusal to change](https://github.com/facebook/react/issues/10191#issuecomment-323486580) reactjs license to apache2. This is because, Facebook has license terms that allows them to *revoke* patent grants and countersue... if you sue them first.
Even if your lawsuit is justified (for example Facebook wilfully infringed on something that you invented). Caffe/Caffe2 is covered by this license as well.
FWIW, Tensorflow is under an irrevocable Apache2 license.

For people who are using caffe/caffe2 in production, what does your legal team have to say about this ?",2,11
74,2017-8-20,2017,8,20,3,6uqudo,Teaching Machines How To Spot Diseases,https://www.reddit.com/r/deeplearning/comments/6uqudo/teaching_machines_how_to_spot_diseases/,artificialbrainxyz,1503168864,,0,1
75,2017-8-20,2017,8,20,20,6uvbho,Towards Artificial General Intelligence: Oriol Vinyals,https://www.reddit.com/r/deeplearning/comments/6uvbho/towards_artificial_general_intelligence_oriol/,artificialbrainxyz,1503229936,,0,1
76,2017-8-20,2017,8,20,22,6uvpxk,A compiled list of resources for machine learning and deep learning engineers working with neural style transfer or deep photo style transfer.,https://www.reddit.com/r/deeplearning/comments/6uvpxk/a_compiled_list_of_resources_for_machine_learning/,kailashahirwar12,1503235805,,0,8
77,2017-8-21,2017,8,21,2,6ux5z8,Deep Learning and Neural Networks Primer: Basic Concepts for Beginners,https://www.reddit.com/r/deeplearning/comments/6ux5z8/deep_learning_and_neural_networks_primer_basic/,molode,1503251801,,0,1
78,2017-8-21,2017,8,21,4,6uxjv0,Interesting examples of transfer learning? (xpost /r/machinelearning),https://www.reddit.com/r/deeplearning/comments/6uxjv0/interesting_examples_of_transfer_learning_xpost/,ProfThrowaway17,1503255601,,0,3
79,2017-8-21,2017,8,21,5,6uy7se,Deep Learning in Minutes with this Pre-configured Python VM Image,https://www.reddit.com/r/deeplearning/comments/6uy7se/deep_learning_in_minutes_with_this_preconfigured/,friscotime,1503262228,,1,3
80,2017-8-21,2017,8,21,18,6v1tl2,Data protection and AI: How can we control our creations?,https://www.reddit.com/r/deeplearning/comments/6v1tl2/data_protection_and_ai_how_can_we_control_our/,[deleted],1503307719,[deleted],1,1
81,2017-8-21,2017,8,21,20,6v2d4y,I've Got a Lot of Questions,https://www.reddit.com/r/deeplearning/comments/6v2d4y/ive_got_a_lot_of_questions/,TheNASAguy,1503315877,"	Are there any Weights Libraries, I mean Neural Nets Are Trained on Huge Datasets and then Implemented into Products, Services and Research so, are there any libraries of Pre-Trained Neural Nets that we could use 

	How can we tackle an ML Problem if the Data is Heterogeneous or Complex or Recursive? Like can you use a Neural Net to Solve Definite Integrals?

	What are the ways we can prepare and feed data sets into TensorFlow?

	Projects that involve Generating Insights or Further building on Trained Data? What are the ways we can acquire outputs?

	Can we combine multiple Neural Nets into a Modular Pipeline to Process data? ",2,0
82,2017-8-21,2017,8,21,22,6v31bg,DataScan: Issue #44,https://www.reddit.com/r/deeplearning/comments/6v31bg/datascan_issue_44/,[deleted],1503323529,[deleted],0,1
83,2017-8-22,2017,8,22,0,6v3jrs,"Top 10 Machine Learning Videos on YouTube, updated",https://www.reddit.com/r/deeplearning/comments/6v3jrs/top_10_machine_learning_videos_on_youtube_updated/,lalypopa123,1503328353,,0,1
84,2017-8-22,2017,8,22,1,6v3xfe,Learning to write Hindi Fonts in style (x-post r/machinelearning),https://www.reddit.com/r/deeplearning/comments/6v3xfe/learning_to_write_hindi_fonts_in_style_xpost/,slartibartfst,1503331705,,1,1
85,2017-8-22,2017,8,22,1,6v4498,open source: channel pruning for accelerating very deep CNN,https://www.reddit.com/r/deeplearning/comments/6v4498/open_source_channel_pruning_for_accelerating_very/,ikkiho,1503333371,"We are glad that we have released source code of [channel pruning for accelerating very deep CNN](https://arxiv.org/abs/1707.06168), *ICCV 2017*. It's an elegant algorithm that effectively prune channels each layer.

* accelerate VGG-16 4x without losing accuracy
* accelerate ResNet-50 2x with 1.4% increase of Top-5 error
* accelerate Xception-50 2x with 1.0% increase of Top-5 error

The address is: [github.com/yihui-he/channel-pruning](https://github.com/yihui-he/channel-pruning). Please feel free to test and leave your comments.",1,3
86,2017-8-22,2017,8,22,2,6v4dbl,Lecture on How to build a recognition system (Part 1): best practices,https://www.reddit.com/r/deeplearning/comments/6v4dbl/lecture_on_how_to_build_a_recognition_system_part/,tdionis,1503335570,,0,1
87,2017-8-22,2017,8,22,3,6v4um6,Lecture. Evolution: from vanilla RNN to GRU &amp; LSTMs,https://www.reddit.com/r/deeplearning/comments/6v4um6/lecture_evolution_from_vanilla_rnn_to_gru_lstms/,tdionis,1503339570,,0,3
88,2017-8-22,2017,8,22,4,6v56au,Deep Learning with Python and Keras,https://www.reddit.com/r/deeplearning/comments/6v56au/deep_learning_with_python_and_keras/,dnonsense,1503342197,,0,4
89,2017-8-23,2017,8,23,0,6vbrnr,How Not To Program the TensorFlow Graph,https://www.reddit.com/r/deeplearning/comments/6vbrnr/how_not_to_program_the_tensorflow_graph/,friscotime,1503415769,,0,0
90,2017-8-23,2017,8,23,2,6vchtt,Using deep learning to colorise black &amp; white images,https://www.reddit.com/r/deeplearning/comments/6vchtt/using_deep_learning_to_colorise_black_white_images/,harvey_slash,1503422106,,0,8
91,2017-8-23,2017,8,23,15,6vh39c,Existence of Shallow networks which perform nearly good?,https://www.reddit.com/r/deeplearning/comments/6vh39c/existence_of_shallow_networks_which_perform/,dexterdev30,1503468604,"Is there any shallow network implementation of a ""tough"" classification problem or so? To make it specific let me give an example: Think CAT vs DOG images classification problem. Which is the most light weight network ever designed to solve this problem? Can someone give me resources (like papers or articles etc) related to this kind of stuff?",1,2
92,2017-8-23,2017,8,23,19,6vi5dv,THIS IS HOW SCALING LOOKS LIKE | The Hidden Cost of Deep Learning,https://www.reddit.com/r/deeplearning/comments/6vi5dv/this_is_how_scaling_looks_like_the_hidden_cost_of/,mikkokotila,1503485175,,14,3
93,2017-8-23,2017,8,23,22,6vj00b,The Guerrilla Guide to Machine Learning with Python,https://www.reddit.com/r/deeplearning/comments/6vj00b/the_guerrilla_guide_to_machine_learning_with/,jackblun,1503495409,,0,4
94,2017-8-23,2017,8,23,23,6vj6zm,One Deep Learning Virtual Machine to Rule Them All,https://www.reddit.com/r/deeplearning/comments/6vj6zm/one_deep_learning_virtual_machine_to_rule_them_all/,friscotime,1503497309,,0,1
95,2017-8-24,2017,8,24,2,6vkplo,Secret Sauce behind the beauty of Deep Learning: Beginners guide to Activation Functions,https://www.reddit.com/r/deeplearning/comments/6vkplo/secret_sauce_behind_the_beauty_of_deep_learning/,kailashahirwar12,1503510809,,1,4
96,2017-8-25,2017,8,25,4,6vtbaj,Deep Learning with MXNet livecoding on twitch,https://www.reddit.com/r/deeplearning/comments/6vtbaj/deep_learning_with_mxnet_livecoding_on_twitch/,ranman96734,1503603838,,0,3
97,2017-8-25,2017,8,25,6,6vtx7j,"Deep Learning, Where are we going?",https://www.reddit.com/r/deeplearning/comments/6vtx7j/deep_learning_where_are_we_going/,artificialbrainxyz,1503609185,,0,1
98,2017-8-25,2017,8,25,21,6vy65d,Deep Learning From Scratch: Theory and Implementation,https://www.reddit.com/r/deeplearning/comments/6vy65d/deep_learning_from_scratch_theory_and/,deepideas,1503664941,,2,1
99,2017-8-26,2017,8,26,1,6vzii0,Conv net combined with recurrent net for video analysis? (xpost /r/MachineLearning),https://www.reddit.com/r/deeplearning/comments/6vzii0/conv_net_combined_with_recurrent_net_for_video/,[deleted],1503677907,[deleted],0,1
100,2017-8-26,2017,8,26,2,6vztr5,Training a unet to resolve pairs of overlapping chromosomes,https://www.reddit.com/r/deeplearning/comments/6vztr5/training_a_unet_to_resolve_pairs_of_overlapping/,jean-pat,1503680889,,0,1
101,2017-8-26,2017,8,26,3,6w0au5,"Approaches for analyzing the shape of 2D or 3D objects from segmented (i.e., binarized) images",https://www.reddit.com/r/deeplearning/comments/6w0au5/approaches_for_analyzing_the_shape_of_2d_or_3d/,ProfThrowaway17,1503685181,"Medical images that have already been segmented are basically representations of just the *shape* of 2D or 3D objects, without any notion of color, shading or other scalar features.  I imagine this type of ""shape"" data occurs in other applications too. 

A raw representation in 2D would be an image where pixels take binary values (i.e., a binary matrix). In 3D, you'd have a stack of such images or, equivalently, a 3D array of binary voxels. For most data sets, the ""ON"" or ""white"" pixels or voxels would be grouped into 1-3 contiguous blobs. 

Would convolutional layers make sense for these types of data?  A conv layer would reduce the number of pixels/voxels and perform operations like edge detection with a relatively small number of parameters, but it would also change the binary values into floating point values, partly destroying the simplicity of the raw data. Would this be a good approach if we want to learn about the shape of the represented object?

What about using fewer conv layers than normal? Or skipping the convolution altogether and jumping to max-pool? The idea is that we don't really need the powerful feature detection provided by convolution since the features of contiguous binary pixels are so simple.

Another approach would be to convert the input to a set of points, i.e. a list of the voxels that are ""white.""  This is certainly a more compact representation, especially if the image is sparse, but would it be any easier for a deep net to analyze?  What architecture would work well for this data format?  Just a bunch of fully connected ReLu layers?  

Are there other representations and architectures that make sense for this type of data?",1,1
102,2017-8-26,2017,8,26,4,6w0ows,Data Science - Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/6w0ows/data_science_deep_learning_in_python/,dnonsense,1503688741,,0,4
103,2017-8-26,2017,8,26,21,6w5c0e,Is there any free trained networks available to create art paintings like in deepart.io?,https://www.reddit.com/r/deeplearning/comments/6w5c0e/is_there_any_free_trained_networks_available_to/,dexterdev30,1503751219,"So if I have an input image and a style images, I can give the inputs to [deepart](https://deepart.io) to get artisitc output images. I assume that there exists an underlying trained network for these purposes. If my understanding is wrong, I am very sorry. Is there is any such free trained deep networks available to download and play with?",2,2
104,2017-8-27,2017,8,27,2,6w6wx1,Network architecture for large number of classes,https://www.reddit.com/r/deeplearning/comments/6w6wx1/network_architecture_for_large_number_of_classes/,riku_iki,1503769370,"Hi,

I am trying to design NN, which suppose to recognize large number of classes (500k). Obviously it produces very large number of connections between output and last hidden layers. Say last hidden layer has 10k neurons, then number of connections will be 10k * 500k.

Something I have in my mind is to use class label as encoded combination from output layer. For example in primitive binary encoding, class 1 would correspond to firing output #1, class 6 (110 in binary) would correspond to firing output #2 and #3 (represented as ones in binary encoding).

Another idea is to use convolution for output layer.

What kind of NN architecture you would chose to solve this problem?
",6,1
105,2017-8-27,2017,8,27,5,6w7slh,Signal Prediction with seq2seq RNNs [TensorFlow exercises],https://www.reddit.com/r/deeplearning/comments/6w7slh/signal_prediction_with_seq2seq_rnns_tensorflow/,GChe,1503778059,,0,7
106,2017-8-28,2017,8,28,1,6wcz1c,Learning Hierarchical Features from Generative Models: A Critical Paper Review,https://www.reddit.com/r/deeplearning/comments/6wcz1c/learning_hierarchical_features_from_generative/,alexmlamb,1503850039,,0,2
107,2017-8-28,2017,8,28,1,6wd69a,A small Interspeech 2017 recap,https://www.reddit.com/r/deeplearning/comments/6wd69a/a_small_interspeech_2017_recap/,troltilla,1503852093,,0,2
108,2017-8-28,2017,8,28,2,6wde1n,The math of logistic regression,https://www.reddit.com/r/deeplearning/comments/6wde1n/the_math_of_logistic_regression/,marshalization,1503854221,,0,6
109,2017-8-28,2017,8,28,3,6wdx4u,End to End Deep Learning,https://www.reddit.com/r/deeplearning/comments/6wdx4u/end_to_end_deep_learning/,psangrene,1503859432,,0,0
110,2017-8-28,2017,8,28,22,6wji3h,Any docker-image for deep learning?,https://www.reddit.com/r/deeplearning/comments/6wji3h/any_dockerimage_for_deep_learning/,Siddas27,1503928246,"Is there any docker image that consists of all deep learning and computer vision tools such as opencv, keras, tensorflow, theano, etc??",5,3
111,2017-8-29,2017,8,29,2,6wl2ul,Good project? Trumpet coach,https://www.reddit.com/r/deeplearning/comments/6wl2ul/good_project_trumpet_coach/,LeScanMars,1503942692,"I thought I'd learn about deep-learning by working on a project that would be useful to me. 


I'm intrigued to develop a trumpet practice coach.

Trumpet is a pretty difficult musical instrument. Lots of different challenges. I've been at it for four years now, can finally see a bit of the light.

In terms of learning any musical instrument, one likes to be able to set up goals and then measure progress. Then work on improving.

Unfortunately there is no formula for measurement as such. Human teachers adapt their knowledge to their students, there's lots that goes into that. Diagnose problems, recommend what to change. Send away, repeat next lesson.

So I'm thinking to build a computer systems to measure progress.

In terms of what kinds of progress there is, number one with trumpet is always ""nice tone."" And that would be a universe in itself. Next comes intonation. And then you might look at alternating notes, phrases, scales. Is the rhythm even, is the volume balanced. Also, of course, expanding the range is going to take effort.

(BTW intonation is ok to practice with a simple tuner. Doesn't pick out problems in different aspects of a note (attack, overtones, but still helps a lot)

So I'm posting to ask if anyone has a recommendation how to start on something like this. Is there anything related in machine learning? What's a good entry point to get started?",2,2
112,2017-8-29,2017,8,29,8,6wnb62,Hi.,https://www.reddit.com/r/deeplearning/comments/6wnb62/hi/,[deleted],1503962937,[deleted],0,1
113,2017-8-29,2017,8,29,14,6wp64b,Attention Mechanisms in Recurrent Neural Networks (RNNs) - IGGG,https://www.reddit.com/r/deeplearning/comments/6wp64b/attention_mechanisms_in_recurrent_neural_networks/,GChe,1503983984,,1,5
114,2017-8-29,2017,8,29,23,6wrqjh,Deep Learning for Video Game Playing,https://www.reddit.com/r/deeplearning/comments/6wrqjh/deep_learning_for_video_game_playing/,dezzion,1504018551,,0,4
115,2017-8-30,2017,8,30,3,6wt1l6,Leverage Big Data to Deliver Better Business Outcomes,https://www.reddit.com/r/deeplearning/comments/6wt1l6/leverage_big_data_to_deliver_better_business/,cevizligizem,1504030071,,0,0
116,2017-8-30,2017,8,30,6,6wuava,"training for two things, where the second is only trained on successful actions",https://www.reddit.com/r/deeplearning/comments/6wuava/training_for_two_things_where_the_second_is_only/,fuckme,1504041071,"Im a bit of a newbie here, but Im trying to build a model that does multiple things. 
First its trying to see if a action will be successful, and secondly its trying to see when the optimal time would be for a successful transaction. 

My approach is to first train the net on success/non-success. (Sigmoid single node)

I was then planning on adding a set of softmax nodes to get day of week (and another set for hour of day) and doing another round of backprop with only the successful actions. 

Im concerned that it will screw up the initial success/fail node if I do backprop again. 

Is this the correct approach?

Is there a better way than going through the data twice in two large batches like that?

Ideally Id like a single pass where the softmaxs only get activated on a successful action (I think)

Btw Im using tensorflow. 
",0,1
117,2017-8-30,2017,8,30,10,6wvx2n,What is the best approach to learn Deep Learning using Python starting from syntax?,https://www.reddit.com/r/deeplearning/comments/6wvx2n/what_is_the_best_approach_to_learn_deep_learning/,TheSexyDuckling,1504056974,"Hello world! To give you some background, I am a beginner in programming. I always found programming courses/tasks that I was  forced to do in university easy (I have a degree in Mechanical Engineering, so didn't program much), but I never ventured into actually learning it in depth besides some basic problem solving.

I have some ideas to use computer vision with deep learning in the real-life. As my first step to achieve this, I went through the basic Python syntax by completing the Codecademy course, which was easy. However, now I am completely lost as to what my next step should be. I want the most efficient, but sensible approach to go from learning Python syntax to becoming good at Deep Learning and computer vision. I would appreciate your input on a methodical approach I should take to reach my goal.

I am not interesting in developing a game or website. I want to learn Deep Learning and computer vision. Thank you! And sorry for the lengthy post!",14,1
118,2017-8-30,2017,8,30,23,6wzgjp,The brain most likely does backpropagation,https://www.reddit.com/r/deeplearning/comments/6wzgjp/the_brain_most_likely_does_backpropagation/,Roboserg,1504102972,,9,15
119,2017-8-31,2017,8,31,0,6wzzuo,What to do after Andrew Ng's deep learning courses?,https://www.reddit.com/r/deeplearning/comments/6wzzuo/what_to_do_after_andrew_ngs_deep_learning_courses/,Northstat,1504107899,"I've covered deep learning in school so I mostly took the courses as a refresher and to gain additional insight 
 from Andrew.  I've completed the first 3 courses and while I wait for the other sessions to start I'd like to continue working with deep learning. What should the next steps be? Additional courses, books, kaggle, research papers? I'm sure all of these are good, just curious what others are doing and what they find helpful.",4,2
120,2017-8-31,2017,8,31,4,6x1mp6,Generate image dataset for shape classification,https://www.reddit.com/r/deeplearning/comments/6x1mp6/generate_image_dataset_for_shape_classification/,uridah,1504121845,"I want to create a dataset for some particular shapes that I have.
So given a binary image of a perfect shape, I need to create many different variations of that shape in many different rotations. This will serve as a dataset for training a classifier which should be able to classify a binary shape image. 
I am working with 12 different shapes here (Right-angled triangle, triangle, rectangle, parallelogram, trapezoid, right-angled trapezoid, concave pentagon, equilateral pentagon etc.) 

I came up with an approach where a given number of sides, I randomly generate points and make a polygon out of that and see which shape it fits but I don't think that'll give me a good number of samples for all the shapes. Any ideas on how I should go about it (using Python preferably)? ",0,1
121,2017-8-31,2017,8,31,5,6x1su2,Practical techniques for getting style transfer to work,https://www.reddit.com/r/deeplearning/comments/6x1su2/practical_techniques_for_getting_style_transfer/,singlasahil14,1504123331,,1,2
122,2017-8-31,2017,8,31,9,6x3nci,The future of neural networks depend on neuroscience,https://www.reddit.com/r/deeplearning/comments/6x3nci/the_future_of_neural_networks_depend_on/,droidarmy95,1504141077,,0,2
123,2017-8-31,2017,8,31,19,6x65au,"A Mathematical Framework for the Analysis of Neural Networks [Anthony 2017, pdf]",https://www.reddit.com/r/deeplearning/comments/6x65au/a_mathematical_framework_for_the_analysis_of/,cbeak,1504177097,,0,9
124,2017-8-31,2017,8,31,20,6x67om,What is Intelligence?,https://www.reddit.com/r/deeplearning/comments/6x67om/what_is_intelligence/,mikkokotila,1504178077,,0,0
0,2017-9-1,2017,9,1,12,6xbv7q,The code of logistic regression,https://www.reddit.com/r/deeplearning/comments/6xbv7q/the_code_of_logistic_regression/,marshalization,1504234993,,3,4
1,2017-9-3,2017,9,3,0,6xmtt4,Opinion on PyTorch.,https://www.reddit.com/r/deeplearning/comments/6xmtt4/opinion_on_pytorch/,SmokinAce88,1504367866,I am getting started with deep learning and I have heard that PyTourch is now faster than Tensorflow and it might be a better choice. What is your opinion based in experience ?,10,5
2,2017-9-3,2017,9,3,15,6xrnop,Object and distance detection using a CNN?,https://www.reddit.com/r/deeplearning/comments/6xrnop/object_and_distance_detection_using_a_cnn/,emmanuel-p,1504419434,"I have a dataset with 1000s of labeled images, only one class (cars) and also their respective distances from the camera at the moment the pictures were taken.

Id like to train a TensorFlow (Keras or Caffe examples would also be okay) model to detect other cars (this I already know how to), but also to try and predict their distances from the camera as accurately as possible given what was learned from the dataset.

Any thoughts?

Thanks!",1,1
3,2017-9-3,2017,9,3,18,6xs9ic,Learning PyTorch,https://www.reddit.com/r/deeplearning/comments/6xs9ic/learning_pytorch/,sdhnshu,1504431092,"Hey everyone. I have recently started working on a **model zoo** in **PyTorch** as a way to learn about deep learning models and PyTorch along the way. I've already made a couple of them and am constantly working on it. Be sure to check it out if you are on the same path.

[https://github.com/sdhnshu/pytorch-model-zoo](https://github.com/sdhnshu/pytorch-model-zoo)",4,5
4,2017-9-3,2017,9,3,19,6xsgzi,Quick favor from anyone running a GTX 1080ti + TF/Keras,https://www.reddit.com/r/deeplearning/comments/6xsgzi/quick_favor_from_anyone_running_a_gtx_1080ti/,bmxer8330,1504434895,"Can anyone running a GTX 1080ti (11GB) with TF or Keras (using Tensorflow backend) tell me how much GPU memory it allocates?

I've have a strange issue where the GPU shows 11264mb of memory but Tensorflow only grabs a 8192mb chunk.  If I allow memory expansion for the current TF session I get an ""out of memory"" error if it tries to use any more than 8192mb.  I believe it is supposed to allocate all available GPU memory.  

Would greatly appreciate if anyone running an identical setup could confirm this behavior.",5,0
5,2017-9-4,2017,9,4,3,6xuuyw,Conditioned GANs,https://www.reddit.com/r/deeplearning/comments/6xuuyw/conditioned_gans/,minnuu,1504463353,"Wanted to do something like this - http://scribbler.eye.gatech.edu/paper.pdf. could someone point me to working model for this? They have mentioned building on (https://github.com/TengdaHan/Convolutional_Sketch_Inversion). However, I do not have much experience with GANs and do not know how to adapt a normal CNN to a GAN. Any help with this would be greatly appreciated too.",0,1
6,2017-9-4,2017,9,4,7,6xwftl,How hard is it to parallelize a Titan X Pascal (2016) and a Titan XP (2017) for deep learning?,https://www.reddit.com/r/deeplearning/comments/6xwftl/how_hard_is_it_to_parallelize_a_titan_x_pascal/,drrobobot,1504479463,"My home deep learning box build currently has a 2016 Titan X Pascal. I'm debating buying a Titan XP (2017 release) which has the same onboard memory specs but with a few feature improvements. However, since they're not exactly the same model - just very similar - I'm not sure how easy they are parallelize vs. if I just bought another 2016 Titan X Pascal model.

Any advice on this?

Related question: same as above, but re: parallelizing a Titan X Pascal (2016) and a 1080 TI

You can see spec comparisons here: 
https://www.vrfocus.com/2017/04/titan-x-vs-titan-xp-comparison-guide",5,3
7,2017-9-4,2017,9,4,19,6xzi7q,My Neural Network isn't working! What should I do?,https://www.reddit.com/r/deeplearning/comments/6xzi7q/my_neural_network_isnt_working_what_should_i_do/,moh1371,1504520014,,0,11
8,2017-9-4,2017,9,4,21,6y03ri,point-and-click dataset creator; should I bother to work further on this?,https://www.reddit.com/r/deeplearning/comments/6y03ri/pointandclick_dataset_creator_should_i_bother_to/,futilon,1504529118,,2,3
9,2017-9-5,2017,9,5,22,6y7szu,https://buzzrobot.com/5-ways-to-get-started-with-reinforcement-learning-b96d1989c575,https://www.reddit.com/r/deeplearning/comments/6y7szu/httpsbuzzrobotcom5waystogetstartedwithreinforcemen/,[deleted],1504616407,[deleted],0,1
10,2017-9-5,2017,9,5,22,6y7u8l,5 Ways to Get Started with Reinforcement Learning  buZZrobot,https://www.reddit.com/r/deeplearning/comments/6y7u8l/5_ways_to_get_started_with_reinforcement_learning/,harvey_slash,1504616768,,0,1
11,2017-9-5,2017,9,5,23,6y8adj,PyTorch or TensorFlow?,https://www.reddit.com/r/deeplearning/comments/6y8adj/pytorch_or_tensorflow/,dearpetra,1504621378,,5,7
12,2017-9-5,2017,9,5,23,6y8c99,42 Steps to Mastering Data Science,https://www.reddit.com/r/deeplearning/comments/6y8c99/42_steps_to_mastering_data_science/,friscotime,1504621893,,0,2
13,2017-9-6,2017,9,6,2,6y9i0q,Building perceptrons from scratch in Python,https://www.reddit.com/r/deeplearning/comments/6y9i0q/building_perceptrons_from_scratch_in_python/,deepideas,1504632239,,0,2
14,2017-9-6,2017,9,6,6,6yb4e2,Getting a computer to see moss is a lot harder than you might think,https://www.reddit.com/r/deeplearning/comments/6yb4e2/getting_a_computer_to_see_moss_is_a_lot_harder/,pmz,1504646838,,1,2
15,2017-9-6,2017,9,6,17,6yea5h,Meet Michelangelo: Ubers Machine Learning Platform,https://www.reddit.com/r/deeplearning/comments/6yea5h/meet_michelangelo_ubers_machine_learning_platform/,steccami,1504684905,,0,4
16,2017-9-6,2017,9,6,18,6yeotb,Call out for expressions of interest.,https://www.reddit.com/r/deeplearning/comments/6yeotb/call_out_for_expressions_of_interest/,misteralanyo,1504691961,"Im an artist currently researching a few forthcoming projects which will involve AI and deep learning. I am hoping to hire a programmer(s) to help develop a number of deep learning tools over the next year. The projects will primarily involve linguistic learning and output generative texts, and also image generation based on custom datasets.

Right now I just want to get an idea for whos out there and what you can offer. So, DM me your details and links to any examples of your work if think you might be interested. 

If there are other websites/subreddits that you think I should be asking, do let me know below also.

Thanks!",1,0
17,2017-9-7,2017,9,7,0,6yg7xe,Computer Vision News of September,https://www.reddit.com/r/deeplearning/comments/6yg7xe/computer_vision_news_of_september/,Gletta,1504710835,"Here is Computer Vision News of September 2017, published by RSIP Vision as a gift to the algorithm community.
38 pages of computer vision, artificial intelligence, image processing and deep learning exclusive stories (with codes!). Free subscription at page 38.
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2017September/
and
PDF version ==&gt; http://www.rsipvision.com/computer-vision-news-2017-september-pdf/
Enjoy!",0,4
18,2017-9-7,2017,9,7,0,6yggus,Detecting Facial Features Using Deep Learning,https://www.reddit.com/r/deeplearning/comments/6yggus/detecting_facial_features_using_deep_learning/,friscotime,1504713216,,0,1
19,2017-9-7,2017,9,7,11,6ykh53,The math of neural networks,https://www.reddit.com/r/deeplearning/comments/6ykh53/the_math_of_neural_networks/,marshalization,1504752276,,0,4
20,2017-9-7,2017,9,7,15,6ylljn,Deep Learning Techniques for Music Generation - A Survey,https://www.reddit.com/r/deeplearning/comments/6ylljn/deep_learning_techniques_for_music_generation_a/,dezzion,1504767261,,0,2
21,2017-9-7,2017,9,7,17,6ym03o,An implement of Google deep dream,https://www.reddit.com/r/deeplearning/comments/6ym03o/an_implement_of_google_deep_dream/,hjptriplebee,1504774237,,0,3
22,2017-9-8,2017,9,8,2,6you1v,Weaponized deep learning.,https://www.reddit.com/r/deeplearning/comments/6you1v/weaponized_deep_learning/,te_trac_tys,1504806455,"Would deep learning be useful to train an ""AI"" on how to react to targets, say, by training it using footage of combat shot from a first person view?  For example, sending troops into combat with gopros, recording that footage and then using that footage to train machine learning/deep learning algorithims that then instruct the AI?

I may be using the wrong terms but hopefully someone understands what I'm getting at here. I'm trying to identify the right technology that could be used to do what I'm suggesting.",8,0
23,2017-9-8,2017,9,8,4,6ypg33,Maximum Likelihood for Neural Network Training: Theory and Implementation,https://www.reddit.com/r/deeplearning/comments/6ypg33/maximum_likelihood_for_neural_network_training/,deepideas,1504812056,,0,3
24,2017-9-8,2017,9,8,9,6yr8xr,Classification NN's with a 'None' option?,https://www.reddit.com/r/deeplearning/comments/6yr8xr/classification_nns_with_a_none_option/,Nightsd01,1504829670,"Hi everyone,

I am just getting my toes wet with deep learning. How do you typically solve this problem:

I recently trained a NN to do object classification using the CIFAR-100 image dataset. I built an iOS app which uses the camera as input to this NN. However, when the camera is aimed at nothing in particular (none of the 100 categories the NN was trained on), I am not sure how to handle this situation. Is it possible to add 'None' as one of the categories to train the NN on, so that if none of the categories are seen in an example it just outputs 'None'?

How do the experts in the field typically handle cases like this? Forgive me, I am self-taught so I may be misusing terminology.",10,2
25,2017-9-8,2017,9,8,23,6yv8mt,The Future and Benefits of Cloud Computing,https://www.reddit.com/r/deeplearning/comments/6yv8mt/the_future_and_benefits_of_cloud_computing/,cevizligizem,1504882301,,0,1
26,2017-9-9,2017,9,9,1,6yvo86,Classification of text files,https://www.reddit.com/r/deeplearning/comments/6yvo86/classification_of_text_files/,largeeddy,1504886431,I have data files containing text.  Each data file gets classified by humans based on what is in the text - basically a collection of key words supports the classification.  There are multiple classifications and some data files are assigned multiple classifications.  I want to explore training a neural network using the text data and corresponding classifications to predict what new text data should be classified as.  Most of my work prior to this has been in the sciences and while I have some ideas I do not want to reinvent the wheel here.  I would greatly appreciate a suggestion of what to start looking at.  Thanks!,4,2
27,2017-9-9,2017,9,9,2,6yw6p5,Siamese Network papers,https://www.reddit.com/r/deeplearning/comments/6yw6p5/siamese_network_papers/,DecentMakeover,1504891254,Anyone know papers relating to Siamese network?,2,0
28,2017-9-10,2017,9,10,3,6z372e,"Online demo of ""Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression""",https://www.reddit.com/r/deeplearning/comments/6z372e/online_demo_of_large_pose_3d_face_reconstruction/,uint64,1504980384,,8,13
29,2017-9-10,2017,9,10,10,6z5ioq,Building Convolutional Neural Networks with Tensorflow,https://www.reddit.com/r/deeplearning/comments/6z5ioq/building_convolutional_neural_networks_with/,psangrene,1505006076,,0,2
30,2017-9-11,2017,9,11,5,6zaok4,A Neural Network in 11 lines of Python (Part 1),https://www.reddit.com/r/deeplearning/comments/6zaok4/a_neural_network_in_11_lines_of_python_part_1/,mikkokotila,1505075488,,1,2
31,2017-9-11,2017,9,11,5,6zartl,Thoughts on using deep learning to predict stock prices?,https://www.reddit.com/r/deeplearning/comments/6zartl/thoughts_on_using_deep_learning_to_predict_stock/,disruptor_2016,1505076394,"I just started learning deep learning a few weeks ago. Currently I am working on a deep learning project that uses tensorflow to predict stock prices. I think I currently lack a bigger picture of how DP can be applied to this type of problem due to the insufficent data set and features. I will post my thoughts and what I've done and would like to hear people's opionions on this.

Here is what I've done so far.

Let's say I pick one stock and its history prices of past 30 years, and price is given in a montly basis. And I use that as my Y.

For X, I use features like company revenues, profits, growth rate, etc for that company as well as interest rate, inflation rate. Also that data is spread in a monthly basis.

So the total sample size is about ~550 (80% used as training set and 20% as testing set) and currently I am just using various shallow layers (1-3) and with various hidden units in each layer (2-30) along with combinations of different learning rate, optimizers, batch sizes etc. So far I couldn't get any good results.

Am I doing something completely off the chart here? I would like to make sure I am at least on the right track.
",6,0
32,2017-9-11,2017,9,11,15,6zdsay,"Question : Does it makes sense to train deep learning models on a subset of an original dataset due to computational constraints, and choose the best model from this approach, but later, train the best model on full dataset?",https://www.reddit.com/r/deeplearning/comments/6zdsay/question_does_it_makes_sense_to_train_deep/,infinitylogesh,1505112797,Considering that all variance of the dataset is covered in the subset. ,7,3
33,2017-9-11,2017,9,11,18,6zedeu,"One - Shot - Learning , Object Detection",https://www.reddit.com/r/deeplearning/comments/6zedeu/one_shot_learning_object_detection/,avilash100,1505123005,Any papers/code available concerning object detection based on one shot learning,0,2
34,2017-9-11,2017,9,11,19,6zejuv,Google Launches Free Course on Deep Learning: The Science of Teaching Computers How to Teach Themselves,https://www.reddit.com/r/deeplearning/comments/6zejuv/google_launches_free_course_on_deep_learning_the/,firmsecure,1505125900,,5,25
35,2017-9-12,2017,9,12,2,6zgpyb,limitations of deep q-networks?,https://www.reddit.com/r/deeplearning/comments/6zgpyb/limitations_of_deep_qnetworks/,randomWalk112358,1505149425,"Many extol the virtues of Deep Mind's deep q-networks, but what are their limitations? Why are they capable of solving complex tasks but not simple ones? The cons have been surprisingly difficult to find. If anyone can point me to a few references on their limitations, I'd be appreciative!
",1,2
36,2017-9-12,2017,9,12,15,6zl7y6,Gradient Descent and Backpropagation: Theory and Implementation,https://www.reddit.com/r/deeplearning/comments/6zl7y6/gradient_descent_and_backpropagation_theory_and/,deepideas,1505197150,,0,5
37,2017-9-12,2017,9,12,18,6zlwan,Question : How to integrate domain specific embeddings which are trained on glove/word2vec/fasttext with the original pretrained embeddings? Any suggestions?,https://www.reddit.com/r/deeplearning/comments/6zlwan/question_how_to_integrate_domain_specific/,infinitylogesh,1505208547,"We trained our own domain specific embeddings, and we are looking for ways to integrate / use it along with the original pretrained embeddings which are publicly available. How to go about it? my understanding is that just adding the embeddings to the original pretrained embeddings wouldn't be that helpful ( I could be wrong) . Suggestions are appreciated. Thanks",4,2
38,2017-9-12,2017,9,12,20,6zmgc4,Training a classifier with negative cases,https://www.reddit.com/r/deeplearning/comments/6zmgc4/training_a_classifier_with_negative_cases/,fuckme,1505217144,"Hi.
I am trying to build a model which predicts what is the best time to do something. (for example submit something to a processor)

In my training set, I have examples of when something successfully works, but I also have examples of when it doesn't work. It is sourced from a skewed source (where batch jobs run early in the morning with a large amount of submissions)

At the moment I'm filtering out all the non-successful attempts when I build the time-of-day predictor, but I'd like to do some kind of negative reward for the ones which don't work.

I'm concerned that what I am actually doing is just teaching the time the most frequent submissions come in, instead of the most positive.

Is there any papers, tutorials, or suggestions? (ideally with TF examples ;-) )

My immediate thought is to build a negative softmax response so that each other hour has 1/23 weight in it for when I do backprop for the negative responses? 

are there better ways?

",0,1
39,2017-9-12,2017,9,12,23,6zna1b,First neural network (mnist) looking for feedback,https://www.reddit.com/r/deeplearning/comments/6zna1b/first_neural_network_mnist_looking_for_feedback/,ThinkOfFutureSelf,1505226357,"I've created my first neural network following various tutorials and applying various techniques. I'm wondering if there are best practices I'm not adhering to or things I've missed that I'd be grateful if you guys could point out?

link : https://github.com/DaneHague/mnist-neural-network/blob/master/vanilla_nn.py

Thank you",8,2
40,2017-9-13,2017,9,13,0,6znjip,OpenAI's Dota bot learns through self-play. Can anyone explain and/or provide specifics?,https://www.reddit.com/r/deeplearning/comments/6znjip/openais_dota_bot_learns_through_selfplay_can/,KloppOnThruTheRain,1505228867,,3,2
41,2017-9-13,2017,9,13,1,6znvzi,Heart Disease Diagnosis with Deep Learning,https://www.reddit.com/r/deeplearning/comments/6znvzi/heart_disease_diagnosis_with_deep_learning/,e_ameisen,1505232030,,1,8
42,2017-9-13,2017,9,13,2,6zokza,Can This Man Make AI More Human? - MIT Technology Review,https://www.reddit.com/r/deeplearning/comments/6zokza/can_this_man_make_ai_more_human_mit_technology/,smorrel1,1505238348,,1,0
43,2017-9-13,2017,9,13,3,6zowdl,"Implementation of Gaussian Processes Classifier, MLP, k-NN, PCA, RBM, LogReg from scratch in python and examples on MNIST",https://www.reddit.com/r/deeplearning/comments/6zowdl/implementation_of_gaussian_processes_classifier/,monsta-hd,1505241255,,0,1
44,2017-9-13,2017,9,13,5,6zpi4i,Photo organizer app using CNNs,https://www.reddit.com/r/deeplearning/comments/6zpi4i/photo_organizer_app_using_cnns/,monsta-hd,1505246664,,0,3
45,2017-9-13,2017,9,13,10,6zrjpy,what is the best robust model in image segmentation with deep learning ?,https://www.reddit.com/r/deeplearning/comments/6zrjpy/what_is_the_best_robust_model_in_image/,daicoolb,1505267030,"Our group want have a good image segmentation with deep learning, which means that the processing time with each picture is below 80ms, and the performance is better than FCN or other old models. Can anybody give me some advice ? I have read the papers in CVPR 2017 and tried some experiments , but the performance is not good enough.",8,1
46,2017-9-13,2017,9,13,20,6ztwba,Bank Operation Optimization,https://www.reddit.com/r/deeplearning/comments/6ztwba/bank_operation_optimization/,cevizligizem,1505301673,,1,0
47,2017-9-13,2017,9,13,22,6zue3i,"The Evolution of Named Entity Recognition: Milestone Papers, Models and Technologies",https://www.reddit.com/r/deeplearning/comments/6zue3i/the_evolution_of_named_entity_recognition/,parth10,1505307898,,0,1
48,2017-9-13,2017,9,13,23,6zupfu,A Meta-analysis of DAVIS-2017 Video Object Segmentation Challenge,https://www.reddit.com/r/deeplearning/comments/6zupfu/a_metaanalysis_of_davis2017_video_object/,Discordy,1505311235,,0,2
49,2017-9-14,2017,9,14,0,6zvcj5,The director of Baidus Silicon Valley AI Lab has departed,https://www.reddit.com/r/deeplearning/comments/6zvcj5/the_director_of_baidus_silicon_valley_ai_lab_has/,vonnik,1505317173,,1,1
50,2017-9-14,2017,9,14,7,6zy738,Using machine learning to pull important info from science journals,https://www.reddit.com/r/deeplearning/comments/6zy738/using_machine_learning_to_pull_important_info/,ml_i,1505342743,,0,8
51,2017-9-14,2017,9,14,22,70236q,Ryzen Build for Machine/Deep Learning,https://www.reddit.com/r/deeplearning/comments/70236q/ryzen_build_for_machinedeep_learning/,sanemate,1505394379,"Hi, I am planning an AMD 1700x + 1080ti build for machine/deep learning. Would be dual booting into Linux. Have heard AMD Ryzen had some SegFault issues with earlier chips (which it is now replacing). Anyone with a Ryzen build here, may you share your experience? Thanks!",9,3
52,2017-9-15,2017,9,15,4,704lsg,AI Tries to Predict Next Chapter in Game of Thrones Saga - with Comical Results,https://www.reddit.com/r/deeplearning/comments/704lsg/ai_tries_to_predict_next_chapter_in_game_of/,bcaulfield,1505417885,,0,1
53,2017-9-15,2017,9,15,4,704nne,2500$ prize for a better Visual Domain Adaptation method [ICCV2017 Workshop Challenge],https://www.reddit.com/r/deeplearning/comments/704nne/2500_prize_for_a_better_visual_domain_adaptation/,bbminner,1505418338,,1,0
54,2017-9-15,2017,9,15,12,707f68,PyTorch Implementation of Deep Semantic Similarity Model(Microsoft Research),https://www.reddit.com/r/deeplearning/comments/707f68/pytorch_implementation_of_deep_semantic/,nishnik,1505447071,,0,5
55,2017-9-15,2017,9,15,14,707snl,Eugene Charniak-Introduction to Deep Learning Book [pdf],https://www.reddit.com/r/deeplearning/comments/707snl/eugene_charniakintroduction_to_deep_learning_book/,scvalencia,1505451991,,0,8
56,2017-9-15,2017,9,15,14,707xyw,"We collected 10 CVPR 2017 posters which have MIT authors, and made this web-app to view them effortlessly on a phone! (Privacy Disclaimer : The app tracks user's interactions with poster)",https://www.reddit.com/r/deeplearning/comments/707xyw/we_collected_10_cvpr_2017_posters_which_have_mit/,spandanmadan,1505454139,,0,2
57,2017-9-15,2017,9,15,18,708rns,Webtunix is a company of Artificial Intelligence in India who build algorithms based on subjective fuzzy modeling to develop necessary input for prediction system.,https://www.reddit.com/r/deeplearning/comments/708rns/webtunix_is_a_company_of_artificial_intelligence/,webtunixml,1505467919,,0,0
58,2017-9-16,2017,9,16,19,70g3xf,Nanocheeze MEQUAVIS using Dragon Ball as a roadmap to AI for an Emergent Reality based system (Exploiting Retrocausality),https://www.reddit.com/r/deeplearning/comments/70g3xf/nanocheeze_mequavis_using_dragon_ball_as_a/,cybershrapnel,1505556234,,0,1
59,2017-9-16,2017,9,16,23,70h72e,Throw back-propagation to garbage and start again.,https://www.reddit.com/r/deeplearning/comments/70h72e/throw_backpropagation_to_garbage_and_start_again/,[deleted],1505572617,[deleted],0,1
60,2017-9-16,2017,9,16,23,70h7bz,"Hinton says back-propagation needs to die, and we start over +1",https://www.reddit.com/r/deeplearning/comments/70h7bz/hinton_says_backpropagation_needs_to_die_and_we/,mikkokotila,1505572704,,4,0
61,2017-9-17,2017,9,17,0,70hik7,Deep Learning Drone Project,https://www.reddit.com/r/deeplearning/comments/70hik7/deep_learning_drone_project/,TissaFissa,1505576239,"Hi!
I'm a 17 year old student from the Netherlands. This year I get the chance to research a subject of my choice, which in my case is Deep Learning, as I am deeply fascinated by it. I want to ""teach"" a quadcopter to fly itself, by using Deep Learning and Deep Neural Nets, the quadcopter would then learn to hover by itself after many flight attempts. Would this project be doable for someone my age and my skill level? I am willing to pour as much time as needed into this project! Thanks in advanced!!!",8,2
62,2017-9-18,2017,9,18,21,70unry,The robot Pepper learns to navigate thanks to deep learning,https://www.reddit.com/r/deeplearning/comments/70unry/the_robot_pepper_learns_to_navigate_thanks_to/,ano85,1505737645,,0,6
63,2017-9-18,2017,9,18,21,70upbl,How we Hacked GTA V for Carvana Kaggle Challenge,https://www.reddit.com/r/deeplearning/comments/70upbl/how_we_hacked_gta_v_for_carvana_kaggle_challenge/,tdionis,1505738148,,1,7
64,2017-9-18,2017,9,18,23,70vi0k,Does anyone have any experience with npdl deep learning module in python,https://www.reddit.com/r/deeplearning/comments/70vi0k/does_anyone_have_any_experience_with_npdl_deep/,kushagra2569,1505746377,Hello guys i am learning deep learning and so i was hoping If anyone has any experience with npdl module can help me with it . Thanks in advance,0,0
65,2017-9-19,2017,9,19,3,70wxtd,Is a GeForce GT 730 suitable for a beginner?,https://www.reddit.com/r/deeplearning/comments/70wxtd/is_a_geforce_gt_730_suitable_for_a_beginner/,dustin_jsa,1505759405,"Hi,

I'm currently going through Udacity's course on parallel programming using CUDA. I'm also planning to do the assignments of Stanford's CS231n.

The PC I have is an HTPC and clearly not suited for deep learning (Pentium G3240, $4gb RAM, intel HD Graphics). However, I was thinking a low end CUDA enabled GPU may come in handy in my learning process.

As I said, I would use it to learn CUDA, do CS231n assignments (except the final project) and also give a try to Caffe or TensorFlow. I'm aware any serious project would require AWS or a decent GPU.

Would a GT 730 2gb DDR 5 be ok? Would it be better choose the 4gb DDR3 version instead? (I know there's a 4gb DDR5 version, but I want the card to be passive cooled).

Regards",5,5
66,2017-9-19,2017,9,19,14,710zmi,Forums to Ask Questions About Deep Learning Side Projects,https://www.reddit.com/r/deeplearning/comments/710zmi/forums_to_ask_questions_about_deep_learning_side/,life2pointO,1505800093,"Dear all, 

I'm wondering if anyone knows where I can post questions about my side project involve deep learning. I need help on how to start because I know the idea for my twitter bot but I don't know how to implement different aspects of the idea (algorithm, connecting my application to the internet, etc.)

Any leads would be much appreciated! Thank you very much for reading this! 

",0,0
67,2017-9-19,2017,9,19,15,7111vr,"Which is has the potential to produce a more accurate time series model prediction: Vowpal Wabbit Learning Algorithms, LSTM , RNN?",https://www.reddit.com/r/deeplearning/comments/7111vr/which_is_has_the_potential_to_produce_a_more/,noob_dev01,1505801024,"Which has the potential to produce a more accurate time series model prediction. Vowpal Wabbit Learning Algorithms, LSTM , RNN?",3,8
68,2017-9-19,2017,9,19,20,712br9,A 101 to get started with deep learning,https://www.reddit.com/r/deeplearning/comments/712br9/a_101_to_get_started_with_deep_learning/,emilwallner,1505820586,,0,2
69,2017-9-20,2017,9,20,1,713z85,Introducing: Unity Machine Learning Agents,https://www.reddit.com/r/deeplearning/comments/713z85/introducing_unity_machine_learning_agents/,leonchenzhy,1505837090,,1,8
70,2017-9-20,2017,9,20,3,7153xe,Expandable Neural networks for life long learning  Simplified,https://www.reddit.com/r/deeplearning/comments/7153xe/expandable_neural_networks_for_life_long_learning/,harvey_slash,1505846526,,2,6
71,2017-9-20,2017,9,20,23,71bmhf,New-Age Machine Learning Algorithms in Retail Lending,https://www.reddit.com/r/deeplearning/comments/71bmhf/newage_machine_learning_algorithms_in_retail/,dearpetra,1505919559,,0,1
72,2017-9-21,2017,9,21,0,71boef,My pre-configured Deep Learning + Python Amazon AWS AMI is publicly available for your use.,https://www.reddit.com/r/deeplearning/comments/71boef/my_preconfigured_deep_learning_python_amazon_aws/,zionsrogue,1505920014,,4,15
73,2017-9-21,2017,9,21,0,71bq11,Object Detection: An Overview in the Age of Deep Learning,https://www.reddit.com/r/deeplearning/comments/71bq11/object_detection_an_overview_in_the_age_of_deep/,jackblun,1505920409,,0,5
74,2017-9-21,2017,9,21,20,71ig2r,Coding the History of Deep Learning,https://www.reddit.com/r/deeplearning/comments/71ig2r/coding_the_history_of_deep_learning/,[deleted],1505992846,[deleted],0,1
75,2017-9-21,2017,9,21,21,71ixbb,New Breakthroughs from DeepMind  Relational Networks and Visual Interaction Networks,https://www.reddit.com/r/deeplearning/comments/71ixbb/new_breakthroughs_from_deepmind_relational/,dearpetra,1505998585,,1,0
76,2017-9-22,2017,9,22,0,71k2hm,Siamese with Places Dataset,https://www.reddit.com/r/deeplearning/comments/71k2hm/siamese_with_places_dataset/,pnambiar,1506009351,"

I am trying to initialize Siamese with ' Places' dataset and then finetune with my own dataset. The example give in caffe is for MNIST dataset that is being trained end to end. Any leads will be highly appreciated.

Thanks, -P
",0,1
77,2017-9-22,2017,9,22,4,71lhfh,Learn how to build and train a machine learning model from scratch! - Vivint's Game of Codes,https://www.reddit.com/r/deeplearning/comments/71lhfh/learn_how_to_build_and_train_a_machine_learning/,jtolds,1506021329,,0,2
78,2017-9-22,2017,9,22,19,71q35h,The History of Chatbots,https://www.reddit.com/r/deeplearning/comments/71q35h/the_history_of_chatbots/,cevizligizem,1506075672,,0,0
79,2017-9-22,2017,9,22,22,71qtmo,data augmentation error with keras - need help please,https://www.reddit.com/r/deeplearning/comments/71qtmo/data_augmentation_error_with_keras_need_help/,v4mvp,1506085251,"hi! 
I have very few image data and I would like to perform data augmentation to increase the number of training data. 

I am trying to implement the code in the keras blog : 

https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html 

but , when I try to rum the fit_generator function I get the error 

""Error when checking target: expected activation_5 to have shape (None, 1) but got array with shape (8, 2)""

can you take a look at my simple code and please help me figure out what's the problem ? 

from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
K.clear_session()
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(1,256,256)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)
X_train = X_train.reshape(X_train.shape[0] ,1, 256, 256)
X_test = X_test.reshape(X_test.shape[0] ,1, 256, 256)

train_datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rescale = 1./255,
    rotation_range=20,
    zoom_range = 0.2,
    height_shift_range=0.2,
    horizontal_flip=True)

test_datagen = ImageDataGenerator(featurewise_center=True,
                                 featurewise_std_normalization = True,
                                 rescale = 1./255)


train_datagen.fit(X_train)
test_datagen.fit(X_test)
train_generator = train_datagen.flow(X_train,y_train,batch_size = 8 , save_to_dir='train',save_prefix='aug')
validation_generator = test_datagen.flow(X_test,y_test,batch_size =8 , save_to_dir='test' , save_prefix = 'aug')

batch_size = 8
model.fit_generator(
        train_generator,
        steps_per_epoch=2000 // batch_size,
        epochs=50,
        validation_data=validation_generator,
        validation_steps=800 // batch_size)
model.save_weights('first_try.h5')  # always save your weights after training or during training




and now I get the error..",2,1
80,2017-9-22,2017,9,22,23,71rcce,Coding the History of Deep Learning,https://www.reddit.com/r/deeplearning/comments/71rcce/coding_the_history_of_deep_learning/,NeverUsesCondoms,1506090612,,1,3
81,2017-9-23,2017,9,23,4,71tak8,Deep Learning on AWS Batch | AWS Compute Blog,https://www.reddit.com/r/deeplearning/comments/71tak8/deep_learning_on_aws_batch_aws_compute_blog/,dannyeuu,1506107926,,0,3
82,2017-9-23,2017,9,23,6,71uaza,Using ML to explore insights on sepsis from medical literature,https://www.reddit.com/r/deeplearning/comments/71uaza/using_ml_to_explore_insights_on_sepsis_from/,alexa_y,1506117490,,0,2
83,2017-9-23,2017,9,23,8,71utk2,Audio Style transfer using CylceGAN,https://www.reddit.com/r/deeplearning/comments/71utk2/audio_style_transfer_using_cylcegan/,gauthamz,1506122899,,2,10
84,2017-9-24,2017,9,24,1,71z7m4,Failures of Deep Learning,https://www.reddit.com/r/deeplearning/comments/71z7m4/failures_of_deep_learning/,adrianb82,1506183671,A very short talk and a paper about the failures of Deep Learning (Gradient-based DL). Video: https://www.youtube.com/watch?v=jWVZnkTfB3c and Paper: https://arxiv.org/abs/1703.07950,3,11
85,2017-9-24,2017,9,24,2,71zhl8,Deep Learning Mindmap,https://www.reddit.com/r/deeplearning/comments/71zhl8/deep_learning_mindmap/,adrianb82,1506186418,A good Deep Learning Mindmap in 3 graphs: https://github.com/dformoso/deeplearning-mindmap,0,2
86,2017-9-24,2017,9,24,10,722bsl,Deep Learning Research Review: Natural Language Processing,https://www.reddit.com/r/deeplearning/comments/722bsl/deep_learning_research_review_natural_language/,psangrene,1506216769,,0,2
87,2017-9-24,2017,9,24,18,72452d,A doubt in object location using keras,https://www.reddit.com/r/deeplearning/comments/72452d/a_doubt_in_object_location_using_keras/,MachineLearner97,1506245055,"I asked this question on /r/learnmachinelearning, but there was no answer so I'm reposting it here.

I was reading this article on detecting rectangles in an image, [here](https://medium.com/towards-data-science/object-detection-with-neural-networks-a4e2c46b4491). My doubt is in the part where the model works fine with detecting a single object, but struggles with two rectangles detection.

The author reasons this as follows:

    We train our network on the leftmost image in the plot above. Lets say 
    that the expected bounding box of the left rectangle is at position 1 in the 
    target vector (x1, y1, w1, h1), and the expected bounding box of the 
    right rectangle is at position 2 in the vector (x2, y2, w2, h2). Apparently, 
    our optimizer will change the parameters of the network so that the first 
    predictor moves to the left, and the second predictor moves to the right. 
    Imagine now that a bit later we come across a similar image, but this 
    time the positions in the target vector are swapped (i.e. left rectangle at 
    position 2, right rectangle at position 1). Now, our optimizer will pull 
    predictor 1 to the right and predictor 2 to the left  exactly the opposite 
    of the previous update step! In effect, the predicted bounding boxes stay 
    in the center.

I don't understand how this reasoning is correct, apart from the fact that when they try to flip the rectangles to mitigate this error, accuracy actually improves (so there's experimental observation, but not much theoretical reasoning).

The reason I think so is because in case of single rectangle also the network has to learn for all differently placed objects just as in the two-rectangle-case, so there too, it should predict boxes in the somewhat the center only. I have to concede I am only a noob in this, so I would love to find out where I am wrong in my reasoning, because experimentally I am wrong (i.e. accuracy does improve when rectangles are flipped).

Thoughts? Also if this is not the correct sub/forum for these type of questions, please feel free to guide me towards those that better suit the content.
And finally thank you for reading :)
",0,2
88,2017-9-25,2017,9,25,22,72ccki,open source camera adds machine vision to projects for under $50,https://www.reddit.com/r/deeplearning/comments/72ccki/open_source_camera_adds_machine_vision_to/,ezeeetm,1506345392,,3,10
89,2017-9-25,2017,9,25,23,72cs5i,Baidu's Mobile Deep Learning project for iOS and Android,https://www.reddit.com/r/deeplearning/comments/72cs5i/baidus_mobile_deep_learning_project_for_ios_and/,vegax87,1506349876,,0,1
90,2017-9-26,2017,9,26,4,72eocf,Learn how hackers down website using DoS attack,https://www.reddit.com/r/deeplearning/comments/72eocf/learn_how_hackers_down_website_using_dos_attack/,hamza245,1506366393,,0,1
91,2017-9-26,2017,9,26,19,72jjvi,[R] Guiding InfoGAN with Semi-Supervision,https://www.reddit.com/r/deeplearning/comments/72jjvi/r_guiding_infogan_with_semisupervision/,spurra,1506423168,,2,3
92,2017-9-26,2017,9,26,23,72kr2u,Thoughts on ML Interpretabi,https://www.reddit.com/r/deeplearning/comments/72kr2u/thoughts_on_ml_interpretabi/,atlvet,1506436585,"https://www.h2o.ai/wp-content/uploads/2017/09/MLI.pdf

I have an intro level understanding of ML, took the Udacity Nanodegree program and have a few Masters courses in CS completed. I know enough to understand this article and the problem of interpretability. I don't know much about H20.ai though and I'm curious what the implications of this research are and what other methods are being explored to solve this problem. I would appreciate any insights!",0,1
93,2017-9-27,2017,9,27,3,72maun,Deep Learning From Scratch: Multi-Layer Perceptrons,https://www.reddit.com/r/deeplearning/comments/72maun/deep_learning_from_scratch_multilayer_perceptrons/,deepideas,1506450015,,0,2
94,2017-9-27,2017,9,27,9,72ojjm,Bayesian Deep Learning: NIPS 2017 Workshop,https://www.reddit.com/r/deeplearning/comments/72ojjm/bayesian_deep_learning_nips_2017_workshop/,cognitivedemons,1506470490,,0,6
95,2017-9-27,2017,9,27,14,72q537,Neural Network Hyper Parameter Optimization Using Distributed TensorFlow,https://www.reddit.com/r/deeplearning/comments/72q537/neural_network_hyper_parameter_optimization_using/,srianant,1506488620,,1,3
96,2017-9-27,2017,9,27,14,72q68v,"Fabrik  Collaboratively build, visualize, and design neural nets in the browser",https://www.reddit.com/r/deeplearning/comments/72q68v/fabrik_collaboratively_build_visualize_and_design/,vardhan,1506489043,,0,7
97,2017-9-27,2017,9,27,19,72rcno,Machine learning and Cognitive API's,https://www.reddit.com/r/deeplearning/comments/72rcno/machine_learning_and_cognitive_apis/,siadroid,1506507756,,0,5
98,2017-9-28,2017,9,28,0,72t2ug,RNNoise: Learning Noise Suppression,https://www.reddit.com/r/deeplearning/comments/72t2ug/rnnoise_learning_noise_suppression/,jvalin,1506526749,,0,7
99,2017-9-28,2017,9,28,8,72wc6o,Deep Learning versus Machine Learning in One Picture,https://www.reddit.com/r/deeplearning/comments/72wc6o/deep_learning_versus_machine_learning_in_one/,psangrene,1506556343,,2,0
100,2017-9-29,2017,9,29,0,730vil,Keras Cheat Sheet: Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/730vil/keras_cheat_sheet_deep_learning_in_python/,jackblun,1506612983,,0,15
101,2017-9-29,2017,9,29,0,730zdl,The Search for the Fastest Keras Deep Learning Backend,https://www.reddit.com/r/deeplearning/comments/730zdl/the_search_for_the_fastest_keras_deep_learning/,dearpetra,1506613935,,0,1
102,2017-9-29,2017,9,29,2,731l1h,Potential impact of ML on media and entertainment,https://www.reddit.com/r/deeplearning/comments/731l1h/potential_impact_of_ml_on_media_and_entertainment/,alexa_y,1506619221,,0,2
103,2017-9-29,2017,9,29,10,734rbv,"One network for Pose estimation, detection and localisation",https://www.reddit.com/r/deeplearning/comments/734rbv/one_network_for_pose_estimation_detection_and/,Kylar_Reed,1506649697,"Hey,

I'm working on a project at the moment that involves estimating the pose and position of a small object. The dataset contains images of the object along with its pose in rads and its position in x/y coords. 

Would I be able to train a network with this data to predict pose and localise in keras? How would I go about inputting so many labels for one image?

Any help would be appreciated 
",1,1
104,2017-9-29,2017,9,29,20,7379kc,Top 7 Benefits of Chatbots for Your Business,https://www.reddit.com/r/deeplearning/comments/7379kc/top_7_benefits_of_chatbots_for_your_business/,cevizligizem,1506685409,,0,6
105,2017-9-29,2017,9,29,23,738861,GAN Training Tips,https://www.reddit.com/r/deeplearning/comments/738861/gan_training_tips/,snapitreditt,1506696130,"I am trying to train a GAN by training on a sample of ""Aerial Maps"". I have some 1000 images of aerial view of landscapes. After several epochs, I get different distributed non-linear oval shapes in the generated image - which is quite encouraging. But training is not proceeding further. The generator is not learning anything more from that point of time. Even after several hundred epochs, it still generates similar kind of pictures. How do I figure out what is wrong?
I disabled Batch Normalization in Discriminator as it distorts the view of the discriminator and generator network. (What discriminator considers as well classified will appear as mis-classified to the Generator and both of them will be happy)
I read about Feature matching (openAI paper and McGAN) where the Generator cost function is changed to match statistical properties of some intermediate layer. Say, If I develop a cost function based on ""mean"", Is that really going to help? It looks so simple to be effective. Any thoughts or comments?",2,0
106,2017-9-30,2017,9,30,10,73c2pd,Best forum to ask about convolutional neural network design?,https://www.reddit.com/r/deeplearning/comments/73c2pd/best_forum_to_ask_about_convolutional_neural/,Ethcad,1506733389,"Hey everyone,

I've got some fairly specific questions about CNN design (specifically replacing a sliding window system with a single network that outputs the position of an object). I don't _think_ this is the right place to ask about that, and I can't find one that is. Cross Validated (Stack Exchange) would shoot me down for some reason about the question not being adequate, and I don't think any of the NVIDIA forums are exactly the right place. Does anyone know if, for instance, the Keras forums will accept questions about network design? I am using Keras, but my questions are not about Keras per se.

Does Google have a forum like this or something?",3,2
107,2017-9-30,2017,9,30,21,73eiw3,A super mini but powerful deep learning framework,https://www.reddit.com/r/deeplearning/comments/73eiw3/a_super_mini_but_powerful_deep_learning_framework/,microic,1506772846,,9,1
108,2017-9-30,2017,9,30,22,73ewa9,DeepSchool.io a free open source deep learning tutorial framework,https://www.reddit.com/r/deeplearning/comments/73ewa9/deepschoolio_a_free_open_source_deep_learning/,themathstudent,1506778158,,0,11
0,2017-10-2,2017,10,2,8,73p09a,"Gesture, Emotions, Posture and Face Recognition using OpenPose/DLIB",https://www.reddit.com/r/deeplearning/comments/73p09a/gesture_emotions_posture_and_face_recognition/,srianant,1506898975,,0,2
1,2017-10-2,2017,10,2,13,73qma1,Deep Learning: Theano Obituary,https://www.reddit.com/r/deeplearning/comments/73qma1/deep_learning_theano_obituary/,psangrene,1506917607,,0,2
2,2017-10-2,2017,10,2,19,73rv5r,Wraping your Repo with Anaconda Project  Simple How To,https://www.reddit.com/r/deeplearning/comments/73rv5r/wraping_your_repo_with_anaconda_project_simple/,ta_katarzyna,1506938445,,0,3
3,2017-10-2,2017,10,2,22,73sv3b,"Tensorflow Tutorial, Part 2",https://www.reddit.com/r/deeplearning/comments/73sv3b/tensorflow_tutorial_part_2/,digitalson,1506952131,,0,5
4,2017-10-3,2017,10,3,2,73u68w,Artificial creativity - AI that writes songs and paints,https://www.reddit.com/r/deeplearning/comments/73u68w/artificial_creativity_ai_that_writes_songs_and/,[deleted],1506964569,[deleted],0,0
5,2017-10-3,2017,10,3,14,73ygc8,Using NLP to parse anticipation,https://www.reddit.com/r/deeplearning/comments/73ygc8/using_nlp_to_parse_anticipation/,qhead,1507008514,"Few weeks ago in a discussion somebody mentioned that it would be awesome if event organizers could use NLP to detect anticipation for the event. A bit like are people excited about this or not?. We can already do sentiment analysis easily but I havent seen anything about parsing anticipation in general or towards something.

This got me curious and I have researched NLP papers for the past week, but I havent found anything.

Does anybody here know if theres been research on this area?",2,1
6,2017-10-3,2017,10,3,22,740gcv,Exclusive interview with Professor Yoshua Bengio in Computer Vision News of October - link,https://www.reddit.com/r/deeplearning/comments/740gcv/exclusive_interview_with_professor_yoshua_bengio/,Gletta,1507038104,"Find take-home thoughts by Yoshua Bengio in the October issue of Computer Vision News, published by RSIP Vision.
Read this fascinating interview at page 4! Free subscription at page 56.
HTML5 version (recommended) ==&gt;
http://www.rsipvision.com/ComputerVisionNews-2017October/
and
PDF version ==&gt;
http://www.rsipvision.com/computer-vision-news-2017-october-pdf/

Enjoy!",1,2
7,2017-10-4,2017,10,4,7,7442nb,I just started taking Andrew Ng's deep learning courses! Here are my top 4 takeaways (and a graph) from week 1.,https://www.reddit.com/r/deeplearning/comments/7442nb/i_just_started_taking_andrew_ngs_deep_learning/,latetodata,1507071019,,4,8
8,2017-10-4,2017,10,4,13,745s1j,Deep Learning From Scratch I: Computational Graphs - deep ideas,https://www.reddit.com/r/deeplearning/comments/745s1j/deep_learning_from_scratch_i_computational_graphs/,pmz,1507089894,,0,2
9,2017-10-4,2017,10,4,14,7468sn,Jose Portilla recently released a new Deep Learning class on Udemy.,https://www.reddit.com/r/deeplearning/comments/7468sn/jose_portilla_recently_released_a_new_deep/,latetodata,1507096240,,1,1
10,2017-10-4,2017,10,4,20,747eks,Move Your Cursor with Webcam Using Tensorflow Object Detection API,https://www.reddit.com/r/deeplearning/comments/747eks/move_your_cursor_with_webcam_using_tensorflow/,thelole,1507114874,,0,2
11,2017-10-5,2017,10,5,0,748znh,Skymind contributes Deeplearning4j suite to Eclipse Foundation,https://www.reddit.com/r/deeplearning/comments/748znh/skymind_contributes_deeplearning4j_suite_to/,vonnik,1507131916,,0,3
12,2017-10-5,2017,10,5,6,74bg6o,Visual Discovery at Pinterest,https://www.reddit.com/r/deeplearning/comments/74bg6o/visual_discovery_at_pinterest/,linekin,1507153379,,0,3
13,2017-10-5,2017,10,5,11,74d1yq,Cheapest 1080ti?,https://www.reddit.com/r/deeplearning/comments/74d1yq/cheapest_1080ti/,vynlwombat,1507169962,"Just got my AWS bill for the month and have decided that I would rather invest in a graphics card to train models instead of sticking with AWS or GCP. I also play PC games so it's a 50/50 justification for the money. Anyway, I've done the cursory googling, but thought I would ask if anyone had any leads on the cheapest 1080ti? Employee discounts? Special favors? Any competition teams need some extra compute power?

Anyone want to start a deep learning company with military applications? 




",0,0
14,2017-10-5,2017,10,5,11,74d6qt,Deep Learning vs Bayesian Learning,https://www.reddit.com/r/deeplearning/comments/74d6qt/deep_learning_vs_bayesian_learning/,themathstudent,1507171446,,0,4
15,2017-10-5,2017,10,5,23,74g98b,"30 Essential Data Science, Machine Learning &amp;amp; Deep Learning Cheat Sheets",https://www.reddit.com/r/deeplearning/comments/74g98b/30_essential_data_science_machine_learning_amp/,dearpetra,1507213232,,0,10
16,2017-10-6,2017,10,6,1,74h4xf,Catching up: The Near-future of Commercial AI,https://www.reddit.com/r/deeplearning/comments/74h4xf/catching_up_the_nearfuture_of_commercial_ai/,e_ameisen,1507221264,,0,2
17,2017-10-6,2017,10,6,3,74hrgx,My new favorite site - Tensorflow Playground,https://www.reddit.com/r/deeplearning/comments/74hrgx/my_new_favorite_site_tensorflow_playground/,latetodata,1507226744,,0,21
18,2017-10-6,2017,10,6,17,74mfhb,Big Data Overview,https://www.reddit.com/r/deeplearning/comments/74mfhb/big_data_overview/,cevizligizem,1507280337,,0,1
19,2017-10-7,2017,10,7,0,74o6ha,Deep Learning for Object Detection: A Comprehensive Review,https://www.reddit.com/r/deeplearning/comments/74o6ha/deep_learning_for_object_detection_a/,digitalson,1507302239,,0,6
20,2017-10-7,2017,10,7,7,74r3by,Extracting features from images: CNN or autoencoders?,https://www.reddit.com/r/deeplearning/comments/74r3by/extracting_features_from_images_cnn_or/,Zeekawla99ii,1507328974,"I'm exploring a project to extract features from imaging data. 

I'm familiar with CNNs, but it appears many people are choosing autoencoders. What are the differences of these two approaches? Why would I choose one over the other? ",4,1
21,2017-10-7,2017,10,7,18,74u11f,Big Data company in India | Data Mining Services | Webtunix,https://www.reddit.com/r/deeplearning/comments/74u11f/big_data_company_in_india_data_mining_services/,webtunixml,1507370177,,0,0
22,2017-10-7,2017,10,7,22,74uzek,A visual essay on image similarity in Wes Anderson films via deep learning. (Best on desktop),https://www.reddit.com/r/deeplearning/comments/74uzek/a_visual_essay_on_image_similarity_in_wes/,singham,1507384569,,0,1
23,2017-10-8,2017,10,8,5,74xbk2,Deep Learning Cheat Sheet for Beginners,https://www.reddit.com/r/deeplearning/comments/74xbk2/deep_learning_cheat_sheet_for_beginners/,psangrene,1507408643,,0,8
24,2017-10-8,2017,10,8,11,74zb0p,Recursive (not recurrent!) Neural Nets in TensorFlow,https://www.reddit.com/r/deeplearning/comments/74zb0p/recursive_not_recurrent_neural_nets_in_tensorflow/,psangrene,1507430829,,0,1
25,2017-10-9,2017,10,9,18,757xvc,How do one imply creativity in a currently rule based neural network?,https://www.reddit.com/r/deeplearning/comments/757xvc/how_do_one_imply_creativity_in_a_currently_rule/,215_215,1507540919,"I recently became interested in how creativity is generated in NN, what I know of in NN is that the output is always known, given it is trained with a target value, but how does one train a network to be creative, I mean in such case would the task be to create something creative, but the actual target would not be known, and how does the creativity express itself in a rule based system, such as NN?
",1,2
26,2017-10-9,2017,10,9,20,758idt,AI Journal,https://www.reddit.com/r/deeplearning/comments/758idt/ai_journal/,larry_physics,1507549436,"Please subscribe to 
https://www.youtube.com/channel/UClYa0mbW-2TgBc_Xnu4HdYg
It covers machine learning, deep learning, NLP, Computer vision.
",0,0
27,2017-10-10,2017,10,10,10,75du7j,Abs max pooling is better than max pooling or ave pooling?,https://www.reddit.com/r/deeplearning/comments/75du7j/abs_max_pooling_is_better_than_max_pooling_or_ave/,microic,1507599614,"I did a research on abs max pooling and found that abs max pooling is a liitle better than max pooling or ave pooling.
For max pooling, array_out = max(array_in)
For abs max pooling, array_out = max(abs(array_in)) 

And I write a mini deep learning framework that support abs max pooling, https://github.com/microic/niy",1,1
28,2017-10-10,2017,10,10,14,75f4jm,Multi Task Learning in CNTK 1.7.1,https://www.reddit.com/r/deeplearning/comments/75f4jm/multi_task_learning_in_cntk_171/,provoke_universe,1507615152,"I want my LSTM network to have multiple outputs sharing same previous layers, it's like splitting in the final layer. Then backpropagate using gradient from both these outputs having different objective functions. Specifically I wanted to know if it is possible to have multiple LabelNodes, OutputNodes etc in this version (1.7.1+) of CNTK.",0,2
29,2017-10-10,2017,10,10,21,75gr24,Awesome Deep Learning: Most Cited Deep Learning Papers,https://www.reddit.com/r/deeplearning/comments/75gr24/awesome_deep_learning_most_cited_deep_learning/,trumtra,1507638960,,0,7
30,2017-10-10,2017,10,10,21,75gtag,Negative Results on Negative Images: Major Flaw in Deep Learning?,https://www.reddit.com/r/deeplearning/comments/75gtag/negative_results_on_negative_images_major_flaw_in/,digitalson,1507639701,,1,6
31,2017-10-10,2017,10,10,22,75h62o,PyTorch vs. TensorFlow: 1 month summary,https://www.reddit.com/r/deeplearning/comments/75h62o/pytorch_vs_tensorflow_1_month_summary/,Sig_Luna,1507643490,,0,5
32,2017-10-11,2017,10,11,7,75kvmz,How to prevent Neural Network from minimizing cost by outputting average of target dataset?,https://www.reddit.com/r/deeplearning/comments/75kvmz/how_to_prevent_neural_network_from_minimizing/,ronsap123,1507676303,"Hello, I have a Dataset of about 1.5 million examples, all of which contain about 40 parameters about a person and the target output should be either 0 or 1, trying to predict a certain attribute about a person. 

So I built a 4 layered network in Tensorflow, and I tried everything, and I mean everything. I built so many weird cost functions with reversed datasets and weird ideas but I just can't get it to output ones or zeroes. The target of the dataset I train it with is mostly 0s with about 0.36% being 1s. So the network just outputs really really small outputs from 0 - 0.0001 and calls it a day because the cost becomes around 0.036.

I tried feeding in the inputs reverses comparing it to the regular target and maximize this cost, I tried comparing the outputs of random inputs with the inputs from the dataset and maximizing the difference between them, all kinds of stuff and I was never able to really get it to work.

I tried using Relu, up to 8 layers with up to 100 hidden units per layer.
I tried training with a MomentumOptimizer and an AdamOptimizer with a variety of decaying or stable learning rates and momentums.

Any advice will be greatly appreciated, I'm here to learn.

P.S: I also tried seperating only the positive examples and pairing it with the same amount of negative examples but it just started outputting 0.5

Also the output layer has sigmoid activation",14,3
33,2017-10-11,2017,10,11,11,75lypf,"How to open source a program, and get some basic earning?",https://www.reddit.com/r/deeplearning/comments/75lypf/how_to_open_source_a_program_and_get_some_basic/,microic,1507687266,"Hi, everyone, I write a mini deep learning framework https://github.com/microic/niy
It is now better than most other deep learning frameworks over a variety of tasks. But I need some more money to develop the software further. 

Right now I can not afford a GPU, or even rent a house.
How can I get money to develop the framework further?
Open source? Or find a company for sponsorship",10,1
34,2017-10-11,2017,10,11,17,75nqom,Nows the time to do deep learning in the cloud,https://www.reddit.com/r/deeplearning/comments/75nqom/nows_the_time_to_do_deep_learning_in_the_cloud/,ZamSpeedyCloud,1507710684,,0,1
35,2017-10-11,2017,10,11,23,75pbgj,Speed breaker Detection using Deep Learning with Matlab 2016,https://www.reddit.com/r/deeplearning/comments/75pbgj/speed_breaker_detection_using_deep_learning_with/,manirags,1507731220,"My Aim of the project is to detect speed break from the given image dataset consists images of speed breaks. How Can I achieve  this using Deep Learning with Matlab Tool.
Should I do this with Matlab tool by creating ROI, training the model  or should I proceed with any of the Python Framework ?
Please Mentor me..
Thanks in Advance.",1,0
36,2017-10-12,2017,10,12,3,75r6au,Interesting Deep Learning Platform Through Keras Integration,https://www.reddit.com/r/deeplearning/comments/75r6au/interesting_deep_learning_platform_through_keras/,datascienceguru,1507747599,,1,1
37,2017-10-12,2017,10,12,8,75t2v6,"Cool new Kickstarter project: Deep Learning, No Coding (DLNC)",https://www.reddit.com/r/deeplearning/comments/75t2v6/cool_new_kickstarter_project_deep_learning_no/,simplifyai,1507764921,,0,0
38,2017-10-12,2017,10,12,9,75tc8t,Mixed-Precision Training of Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/75tc8t/mixedprecision_training_of_deep_neural_networks/,harrism,1507767554,,0,1
39,2017-10-12,2017,10,12,18,75vxzd,Speech Emotion Recognition using Deep Learing,https://www.reddit.com/r/deeplearning/comments/75vxzd/speech_emotion_recognition_using_deep_learing/,lttesp,1507801588,"I am planning to do a project using **Deep Learning**.               
My Aim of the project is to recognise the **Emotion** using from Speech in real time.   
I am planning to use **Convolutional Neural Networks**.      
Should I proceed with Neural net. or Is there any better way to do this? 
Is there any Datasets available for this project?             
Please mentor me.   
Thanks in Advance.
",0,0
40,2017-10-12,2017,10,12,22,75x28y,Searching All 1800+ Of Munchs Paintings With Machine Learning,https://www.reddit.com/r/deeplearning/comments/75x28y/searching_all_1800_of_munchs_paintings_with/,Artnome,1507815777,,0,4
41,2017-10-13,2017,10,13,1,75y1i9,Humanizing Artificial Intelligence (AI) with Deep Learning,https://www.reddit.com/r/deeplearning/comments/75y1i9/humanizing_artificial_intelligence_ai_with_deep/,magneticono,1507824909,,0,3
42,2017-10-13,2017,10,13,1,75y2mq,Deep Thinking- Where Machine Intelligence Ends And Human Creativity Begins,https://www.reddit.com/r/deeplearning/comments/75y2mq/deep_thinking_where_machine_intelligence_ends_and/,sudheeran,1507825174,,0,1
43,2017-10-13,2017,10,13,4,75z88q,Semantic segmentation of overlapping chromosomes with OverlapSegmentationNet,https://www.reddit.com/r/deeplearning/comments/75z88q/semantic_segmentation_of_overlapping_chromosomes/,jean-pat,1507835367,,0,1
44,2017-10-13,2017,10,13,21,764d7k,New Machine Learning Blog Aggregator: Hillclimber.ai,https://www.reddit.com/r/deeplearning/comments/764d7k/new_machine_learning_blog_aggregator_hillclimberai/,Jackal008,1507896766,,0,3
45,2017-10-13,2017,10,13,21,764d7z,Easily log and tune Deep Learning experiments,https://www.reddit.com/r/deeplearning/comments/764d7z/easily_log_and_tune_deep_learning_experiments/,waf04,1507896772,,1,6
46,2017-10-14,2017,10,14,7,7685pa,I'm trying to understand deep learning so I plotted 4 activation functions I learned about from Andrew Ng's DL Course.,https://www.reddit.com/r/deeplearning/comments/7685pa/im_trying_to_understand_deep_learning_so_i/,latetodata,1507932655,,9,1
47,2017-10-14,2017,10,14,12,769sd4,A simple neural network with Python and Keras,https://www.reddit.com/r/deeplearning/comments/769sd4/a_simple_neural_network_with_python_and_keras/,psangrene,1507951374,,0,2
48,2017-10-14,2017,10,14,21,76bq3p,Training a Deep Learning Neural Network to be The Universal Beauty Standard,https://www.reddit.com/r/deeplearning/comments/76bq3p/training_a_deep_learning_neural_network_to_be_the/,[deleted],1507982529,[deleted],1,0
49,2017-10-15,2017,10,15,2,76dazs,Help with Celebrity Voice Changer,https://www.reddit.com/r/deeplearning/comments/76dazs/help_with_celebrity_voice_changer/,jsther,1508000498,,1,3
50,2017-10-15,2017,10,15,13,76gzpx,"Summary: Control of Memory, Active Perception, and Action in Minecraft",https://www.reddit.com/r/deeplearning/comments/76gzpx/summary_control_of_memory_active_perception_and/,Data-Daddy,1508041665,,0,1
51,2017-10-15,2017,10,15,16,76hpes,Help with strange NN,https://www.reddit.com/r/deeplearning/comments/76hpes/help_with_strange_nn/,BeastjungleNA,1508053082,,4,0
52,2017-10-15,2017,10,15,21,76ione,Check This Out: This Deep Learning demo video will blow your mind,https://www.reddit.com/r/deeplearning/comments/76ione/check_this_out_this_deep_learning_demo_video_will/,Classicdude1,1508070494,,0,1
53,2017-10-15,2017,10,15,23,76jdf6,Deep learning for brain control interfaces,https://www.reddit.com/r/deeplearning/comments/76jdf6/deep_learning_for_brain_control_interfaces/,yobenm,1508079330,"I'm wondering if there are projects using deep learning to simplify brain control interfaces and other means to interpret brain waves. I have no specific knowledge in deep learning, just a crude understanding of the principle, but it seems to me that it could be useful to recognize brainwaves patterns that would beforehand be learned during the training phase. 
Does anyone know if such approach already exists and if it could be relevant to speed up brain control technologies development ?",1,1
54,2017-10-16,2017,10,16,4,76l6zu,Microsoft Releases Open Source Library for Distributed Deep Learning on Spark,https://www.reddit.com/r/deeplearning/comments/76l6zu/microsoft_releases_open_source_library_for/,mhamilton723,1508096766,,0,10
55,2017-10-16,2017,10,16,5,76lekq,too many iterations produces worse results? (overfitting),https://www.reddit.com/r/deeplearning/comments/76lekq/too_many_iterations_produces_worse_results/,fuckme,1508098689,"hi.
I have built a basic model, which seems to perform much better after 10-20 epochs. (based on accuracy &amp; F1 scores) but if i keep on running it, it seems to get much worse. 

I'm experimenting with more regularization/drop-outs and adding another layer.

any other hints ?",12,1
56,2017-10-16,2017,10,16,5,76lli3,Is deep learning powerful enough to approximate the determinate of a matrix?,https://www.reddit.com/r/deeplearning/comments/76lli3/is_deep_learning_powerful_enough_to_approximate/,wigmaestro,1508100485,"As a fun experiment, I tried to build a deep learning model to approximate the determinant of a matrix. To make it slightly easier, the matrices are chosen as random submatrices of a fixed larger one and all the entries are binary. However, I have had no luck at all and am wondering if it is in fact possible. Here is some example python3 code.

    import numpy as np
    import sys
    from scipy.linalg import det
    from sklearn.model_selection import train_test_split
    from tqdm import tqdm
    from sklearn.preprocessing import StandardScaler
    from sklearn.pipeline import Pipeline
    import math
    import tensorflow as tf
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.wrappers.scikit_learn import KerasRegressor
    from keras import backend as K
    from keras import regularizers

    def baseline_model():
    # create model
            model = Sequential()
            model.add(Dense(n**2, input_dim=n**2, kernel_initializer='glorot_normal', activation='relu'))
            model.add(Dense(int((n**2)/2.0), kernel_initializer='glorot_normal', activation='relu', kernel_regularizer=regularizers.l2(0.01)))
            model.add(Dense(int((n**2)/2.0), kernel_initializer='glorot_normal', activation='relu', kernel_regularizer=regularizers.l2(0.01)))
            model.add(Dense(int((n**2)/2.0), kernel_initializer='glorot_normal', activation='relu', kernel_regularizer=regularizers.l2(0.01)))
            model.add(Dense(1, kernel_initializer='glorot_normal'))
            # Compile model
            model.compile(loss='mean_squared_error', optimizer='adam')
            return model
    

    n = 15

    print(""Making the input data using seed 7"", file=sys.stderr)
    np.random.seed(7)
    U = np.random.choice([0, 1], size=(n**2,n))
    #U is a random n**2 by n binary matrix
    X =[]
    Y =[]

    for i in tqdm(range(100000)):
            I = np.random.choice(n**2, size = n)
            # Pick out n random rows and sort the rows lexicographically.
            A = U[I][np.lexsort(np.rot90(U[I]))]
            X.append(A.ravel())
            Y.append(det(A))

 
    X = np.array(X)
    Y = np.array(Y)

    print(""Data created"")

    estimators = []
    estimators.append(('standardize', StandardScaler()))
    estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, verbose=2)))
    pipeline = Pipeline(estimators)
    X_train, X_test, y_train, y_test = train_test_split(X, Y,
                                                    train_size=0.75, test_size=0.25)
    pipeline.fit(X_train, y_train, mlp__validation_split=0.3)


If you run this, the loss decreases and validation_loss just goes up and up.

Is it in fact possible to approximate the determinant using keras? That is, is deep learning powerful enough to do this?",5,2
57,2017-10-17,2017,10,17,0,76rbds,GTX 1050 Ti 4GB vs GTX 1060 3GB ?,https://www.reddit.com/r/deeplearning/comments/76rbds/gtx_1050_ti_4gb_vs_gtx_1060_3gb/,nguyenleccss361,1508168537,"GTX 1050 Ti 4GB vs GTX 1060 3GB, which one is better for DL. I just want to compare, so please don't recommend me which card I should buy. Thanks :D",4,1
58,2017-10-17,2017,10,17,5,76tk2i,Keras Pipelines - Rapid Experimentation and Easy Usage,https://www.reddit.com/r/deeplearning/comments/76tk2i/keras_pipelines_rapid_experimentation_and_easy/,Wrosinski,1508187335,,0,3
59,2017-10-17,2017,10,17,17,76x72z,Clean Data for seq2seq Translation,https://www.reddit.com/r/deeplearning/comments/76x72z/clean_data_for_seq2seq_translation/,polaroid_kidd,1508228732,"Hi

A colleague of mine and myself are attempting to set up seq2seq translation char based(EN-&gt;DE) but are having trouble finding clean data. Innitially we used the data from the [wmt conference](http://www.statmt.org/wmt17/) but quickly noticed that they were not sanatised (ie. line 10 in the german file corresponds to line 12 on the english file).  The [stanford data](https://nlp.stanford.edu/projects/nmt/) is sanatised to tokenize word-based (added a space infront of every '.')


My question, does anyone have any idea where to get cleaned data?",0,2
60,2017-10-17,2017,10,17,23,76yxfc,Deep Learning in Finance,https://www.reddit.com/r/deeplearning/comments/76yxfc/deep_learning_in_finance/,sonaam1234,1508250874,,0,7
61,2017-10-18,2017,10,18,0,76zbyi,Deep Learning for Object Detection: A Comprehensive Review,https://www.reddit.com/r/deeplearning/comments/76zbyi/deep_learning_for_object_detection_a/,digitalson,1508254593,,0,5
62,2017-10-18,2017,10,18,7,772coe,Brain MRI image segmentation using Stacked Denoising Autoencoders,https://www.reddit.com/r/deeplearning/comments/772coe/brain_mri_image_segmentation_using_stacked/,mwakanosya,1508280795,,1,7
63,2017-10-18,2017,10,18,13,77491h,Help slicing outputs of a ConvNet on Theano/Keras,https://www.reddit.com/r/deeplearning/comments/77491h/help_slicing_outputs_of_a_convnet_on_theanokeras/,Meloku171,1508300306,"I'm training a ConvNet for handwritten digits recognition using the MNIST dataset. My code is written in Keras using Theano as backend, and it's based on [the examples from the Machine Learning Mastery website](https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/).

Using a ConvNet as a starting point I want to build several smaller ConvNets, each one capable of classifying a subset of classes (for example, five ConvNets capable of classifying a pair of digits each). I have a trained model and tensors array, but I can't find a way to easily build the smaller ones.

I initially thought about keeping just a subset of outputs from the tensors array on the original network (see [this](https://stackoverflow.com/questions/44899850/changing-a-trained-network-to-keep-only-a-subset-of-its-output) entry on Stackoverflow) but Keras keeps throwing errors when I try to do it.

My plan B is to try again with Lambda layers as discussed [here](https://github.com/fchollet/keras/issues/890). I need to read a lot about this method, but AFAIK I should need one Lambda layer per output, and then merge them in pairs...

This is the code I use for training and saving my model:

    import numpy
    from keras.datasets import mnist
    from keras.models import Sequential
    from keras.models import load_model
    from keras.layers import Dense
    from keras.layers import Dropout
    from keras.layers import Flatten
    from keras.layers.convolutional import Conv2D
    from keras.layers.convolutional import MaxPooling2D
    from keras.utils import np_utils
    from keras import backend as K
    K.set_image_dim_ordering('th')
    
    seed = 7
    numpy.random.seed(seed)
    
    # Data load
    (X_train, y_train), (X_test, y_test) = mnist.load_data()

    # Image format
    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')
    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')
    
    # normalize inputs
    X_train = X_train / 255
    X_test = X_test / 255
    y_train = np_utils.to_categorical(y_train)
    y_test = np_utils.to_categorical(y_test)
    num_classes = y_test.shape[1]
    
    def baseline_model():
    	# Model design
        model = Sequential()

        # Convolutional Layer
        model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))
    
        # Pooling Layer
        model.add(MaxPooling2D(pool_size=(2, 2)))
    
        # Dropout Layer
        model.add(Dropout(0.2))
    
        # Flatten Layer
        model.add(Flatten())
    
        # Fully Connected Layer
        model.add(Dense(128, activation='relu'))
    
        # Output Layer
    	model.add(Dense(num_classes, activation='softmax'))
    
    	# Model Compilation
    	model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    	return model
    
    # Model Construction
    model = baseline_model()

    # Model Training
    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)

    # Model Testing
    scores = model.evaluate(X_test, y_test, verbose=0)
    print(""Baseline Error: %.2f%%"" % (100-scores[1]*100))
    
    # Model Saving
    model.save(""convnet_simple_model.h5"")

    # Tensors Saving
    model.save_weights(""convnet_simple_tensors.h5"")
    print(""Model saved."")

    # Model Clearing
    del model 

And this is the code I'm trying to use for slicing the outputs of the pretrained model above:
    
    import numpy
    from keras.datasets import mnist
    from keras.models import Sequential
    from keras.models import load_model
    from keras.layers import Dense
    from keras.layers import Dropout
    from keras.layers import Flatten
    from keras.layers.convolutional import Conv2D
    from keras.layers.convolutional import MaxPooling2D
    from keras.utils import np_utils
    from keras import backend as K
    K.set_image_dim_ordering('th')
    
    # Loading saved model
    model = load_model('convnet_simple_model.h5')

    # Loading saved tensors
    model.load_weights(""convnet_simple_tensors.h5"")
    
    # Selecting outputs to be sliced
    outputs = [0, 1, 2]

    # Slicing outputs
    # [NOT WORKING!]   
    weights = model.layers[5].get_weights()
    
    # This is the line that throws the error    
    transpose = K.transpose(weights)

    gather = K.gather(transpose, outputs)
    new_W = K.transpose(gather)
    print(new_W)
    
    ### TODO: Save Tensors Array as file.

On this final piece of code, I get the following error when compiling:

    Traceback (most recent call last):
       File ""convnet_load_trained.py"", line 25, in &lt;module&gt;
          transpose = K.transpose(weights)
       File ""C:\Users\shado\Miniconda3\envs\ann\lib\site-packages\keras\backend\theano_backend.py"", line 405, in transpose
          y = T.transpose(x)
       File ""C:\Users\shado\Miniconda3\envs\ann\lib\site-packages\theano\tensor\basic.py"", line 3566, in transpose
          axes = list(range((x.ndim - 1), -1, -1))
    AttributeError: 'list' object has no attribute 'ndim'

I hope someone can help me with this.",1,2
64,2017-10-18,2017,10,18,15,774u3c,How do I focus on a subregion within an image for classification in deep learning?,https://www.reddit.com/r/deeplearning/comments/774u3c/how_do_i_focus_on_a_subregion_within_an_image_for/,theoneandonlypatriot,1508308399,"I have a dataset consisting of images, where the images have a lot of noise in it except for a recognizable region within which the classification must take place.

For instance,

/--------$$&amp;:&amp;/
//&amp;:@;&amp;@:@!/
/:&amp;(1111111:&amp;/
/$/1122111$/
/&amp;/1111111$/
/---------////

In that example, the region I need to focus on is the area of 1's, and I need to classify whether it contains any 2s or not. Can I train a network to first identify the region of 1s, then pass that output region to a classifier to detect whether it contains any 2s? 

Hopefully this is making sense. I don't want to have to manually crop my images down to the 1 regions. ",3,1
65,2017-10-19,2017,10,19,0,777g6w,What is the major difference between using Theano and Tensorflow?,https://www.reddit.com/r/deeplearning/comments/777g6w/what_is_the_major_difference_between_using_theano/,zigbo23,1508341846,,1,1
66,2017-10-19,2017,10,19,4,7792sy,Mastering the game of Go without human knowledge,https://www.reddit.com/r/deeplearning/comments/7792sy/mastering_the_game_of_go_without_human_knowledge/,cognitivedemons,1508355727,,0,4
67,2017-10-19,2017,10,19,9,77au6j,Don't miss the upcoming High-Performance Computing (HPC) Developer Conference hosted by Intel! Register here.,https://www.reddit.com/r/deeplearning/comments/77au6j/dont_miss_the_upcoming_highperformance_computing/,helpercaffelli,1508371887,,0,0
68,2017-10-19,2017,10,19,9,77b3oa,Hey Siri: An On-device DNN-powered Voice Trigger for Apples Personal Assistant,https://www.reddit.com/r/deeplearning/comments/77b3oa/hey_siri_an_ondevice_dnnpowered_voice_trigger_for/,cognitivedemons,1508374621,,1,2
69,2017-10-19,2017,10,19,13,77cane,Meet Horovod: Uber's Open Source Distributed Deep Learning Framework for TensorFlow,https://www.reddit.com/r/deeplearning/comments/77cane/meet_horovod_ubers_open_source_distributed_deep/,sudheeran,1508388378,,0,1
70,2017-10-19,2017,10,19,18,77db05,Deep Learning for Object Detection: A Comprehensive Review,https://www.reddit.com/r/deeplearning/comments/77db05/deep_learning_for_object_detection_a/,tzuchinc,1508404795,,2,4
71,2017-10-20,2017,10,20,17,77kvgj,Looking for a good dataset with handwritten english characters.,https://www.reddit.com/r/deeplearning/comments/77kvgj/looking_for_a_good_dataset_with_handwritten/,TissaFissa,1508489278,"Hey!
Does anyone know of a good dataset with handwritten english characters?",2,1
72,2017-10-20,2017,10,20,21,77lvqf,Keras gets stuck on last image of training set...,https://www.reddit.com/r/deeplearning/comments/77lvqf/keras_gets_stuck_on_last_image_of_training_set/,TissaFissa,1508504125,"Hi everyone, I am currently training a keras CNN model on the MNIST dataset, my computer is kind of slow so I let it do 1 epoch (I know I should do more but i'm just trying some things out), and every time keras stops at image 59999/60000 images, and just stops doing anything, the test set is not run and I have no idea what is causing this problem.",2,2
73,2017-10-21,2017,10,21,8,77q0ys,Distributed DL Reading List,https://www.reddit.com/r/deeplearning/comments/77q0ys/distributed_dl_reading_list/,chiraqe,1508543028,,2,10
74,2017-10-21,2017,10,21,18,77sjaf,Horovod: An Open Source Distributed Deep Learning Framework for TensorFlow by Uber,https://www.reddit.com/r/deeplearning/comments/77sjaf/horovod_an_open_source_distributed_deep_learning/,sudheeran,1508579635,,0,1
75,2017-10-22,2017,10,22,20,77zmto,Choosing which framework start with,https://www.reddit.com/r/deeplearning/comments/77zmto/choosing_which_framework_start_with/,Envenger,1508670550,"Hello everyone..
I have been working as a freelance game programmer for last 4 years with most of my work done in c++(Unreal engine 4).

I have been trying to get into AI programming for last 1 year now. 
I have a decent idea on how neural networks function and I have written some very simple neural networks from scratch.

I want to get into something bit more complicated and have been looking at tensorflow.
My goal for learning is, I want to do some research projects using neural nets and try to add it to game AI to do some interesting things and add it to my existing skills so i can get more freelance work related to AI.

I don't know Python very well but I can learn it.",9,4
76,2017-10-22,2017,10,22,21,77zy79,Why does proximal policy optimization(PPO) not need a replay buffer?,https://www.reddit.com/r/deeplearning/comments/77zy79/why_does_proximal_policy_optimizationppo_not_need/,Data-Daddy,1508675668,"How come PPO does not use a replay buffer? I never saw them explicitly address this in the paper, but the openai blogpost does(https://blog.openai.com/openai-baselines-ppo/)",1,3
77,2017-10-23,2017,10,23,0,780r9x,Is it possible to encode labels to hot-one encoding on batch level on the fly with Keras?,https://www.reddit.com/r/deeplearning/comments/780r9x/is_it_possible_to_encode_labels_to_hotone/,This_Is_The_End,1508685404,"The background for my question is simply, I have a dataset that is large and it would be interesting to avoid preprocessing.",1,2
78,2017-10-23,2017,10,23,3,7824t5,Deep learning engineers wanted for creative projects / future collaboration,https://www.reddit.com/r/deeplearning/comments/7824t5/deep_learning_engineers_wanted_for_creative/,spagoop,1508698470,"Hi there,

Artist with a background in programming looking for more technical programmer to help me deploy a few deep learning libraries for a creative project. Happy to pay if it's a hassle.

The libraries are:

- https://github.com/manuelruder/artistic-videos

- https://github.com/ryankiros/neural-storyteller

I need help selecting a server to run this on (or the pros and cons of running on a non-GPU machine), and general set up as I've hit some frustrating road blocks.

If you're interested (or know someone who would be) and want to collaborate on some fun creative projects with this technology, get in touch and I'll tell you more about me and my work!",4,3
79,2017-10-23,2017,10,23,18,786jx1,Labeling objects in photo,https://www.reddit.com/r/deeplearning/comments/786jx1/labeling_objects_in_photo/,bo17age,1508750276,"Hi there,
I'm new to deep learning.
is there any example of Labeling objects in a photo.

Thank you!",5,0
80,2017-10-24,2017,10,24,1,788tii,10 Free New Resources for Enhancing Your Understanding of Deep Learning,https://www.reddit.com/r/deeplearning/comments/788tii/10_free_new_resources_for_enhancing_your/,favouriteblog,1508775458,,1,1
81,2017-10-24,2017,10,24,2,789bpz,Deep learning application in image recognition,https://www.reddit.com/r/deeplearning/comments/789bpz/deep_learning_application_in_image_recognition/,Chartsharing,1508779753,"I would be interested to know if you think that we could train a model enough to recognize type of food in a plate and the approx quantity of this food ? 

",6,2
82,2017-10-24,2017,10,24,4,78a3ud,"Hi, I created this group about 4 months ago to read papers with other people to help each other learn and be artificially intelligent. You are welcome to our events (events tab on our site). If you are remote, you are welcome to participate in our online activities through slack.",https://www.reddit.com/r/deeplearning/comments/78a3ud/hi_i_created_this_group_about_4_months_ago_to/,sashasheng,1508786251,,0,9
83,2017-10-24,2017,10,24,5,78an7p,I built a Chatbot in 2 hours and this is what I learned,https://www.reddit.com/r/deeplearning/comments/78an7p/i_built_a_chatbot_in_2_hours_and_this_is_what_i/,psangrene,1508790845,,3,2
84,2017-10-24,2017,10,24,14,78dtek,How to Improve my Business Through AI and Machine Learning,https://www.reddit.com/r/deeplearning/comments/78dtek/how_to_improve_my_business_through_ai_and_machine/,hector356,1508824189,,0,0
85,2017-10-24,2017,10,24,15,78dwmm,Facebook and Intel Are Joining Forces for Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/78dwmm/facebook_and_intel_are_joining_forces_for/,eugenekristiansen7,1508825499,,0,1
86,2017-10-25,2017,10,25,0,78gb11,Deploying trained SSD to fully serverless workflow in AWS Lambda;Moving off OpenCV/HaaR to Deep Learning for object detection,https://www.reddit.com/r/deeplearning/comments/78gb11/deploying_trained_ssd_to_fully_serverless/,miro_team,1508857393,,0,7
87,2017-10-25,2017,10,25,1,78h30l,Realtime pose estimation on Macbook,https://www.reddit.com/r/deeplearning/comments/78h30l/realtime_pose_estimation_on_macbook/,[deleted],1508864188,[deleted],0,1
88,2017-10-25,2017,10,25,2,78h5tv,Realtime human pose estimation on Macbook using Deep Learning,https://www.reddit.com/r/deeplearning/comments/78h5tv/realtime_human_pose_estimation_on_macbook_using/,ildoonet,1508864853,,0,3
89,2017-10-25,2017,10,25,2,78hd41,Prototype a reverse image search engine,https://www.reddit.com/r/deeplearning/comments/78hd41/prototype_a_reverse_image_search_engine/,psnr,1508866591,,0,2
90,2017-10-25,2017,10,25,5,78ieud,I'm working on my first deep learning project and was looking for help.,https://www.reddit.com/r/deeplearning/comments/78ieud/im_working_on_my_first_deep_learning_project_and/,Jmac3213,1508875496,"So I am working on a project that involves audio and we were wondering if anyone knew something that can convert wav files to a spectrogram, and back. That would allow us to do convolution over more data. Thanks for any help!",1,1
91,2017-10-25,2017,10,25,6,78j52c,DeepStream: Next-Generation Video Analytics for Smart Cities,https://www.reddit.com/r/deeplearning/comments/78j52c/deepstream_nextgeneration_video_analytics_for/,harrism,1508881911,,0,6
92,2017-10-25,2017,10,25,20,78mzek,"How do you find the optimal neural network meta parameters? Tweaking, grid search, genetic programming ...?",https://www.reddit.com/r/deeplearning/comments/78mzek/how_do_you_find_the_optimal_neural_network_meta/,eobermuhlner,1508929907,"Do you just tweak (guided by experience and intuition) or do you run an algorithmic solution 
(for example grid search over the meta parameter space or genetic programming)?",11,5
93,2017-10-25,2017,10,25,23,78o0gb,CNN for several images derived from microtomography. How to apply it?,https://www.reddit.com/r/deeplearning/comments/78o0gb/cnn_for_several_images_derived_from/,ArgNio,1508941638,"I've started working on a project to classify the shape of an object by the various horizontal sections of it, acquired using microtomography. 

So, for each object I have a folder with hundreds of images that look something like this: https://imgur.com/a/q9pfV

I have no clue on how to use all those images to classify just one instance. I've played a bit with tensorflow to classify things with only one image, but I am completely lost with an array of them. 
I've been thinking about using video classifier, but not sure how that would workout or what algorithim to use.

Do any of you know how to tackle this problem? Any kind of reference would help me tons.

Thank you very very much in advance! (sorry for the poor english, not my first language)",14,4
94,2017-10-26,2017,10,26,9,78s41y,,https://www.reddit.com/r/deeplearning/comments/78s41y//,520sunshine,1508978858,,1,0
95,2017-10-26,2017,10,26,15,78tung,Top 10 Deep Learning &amp; Neural-Net Books,https://www.reddit.com/r/deeplearning/comments/78tung/top_10_deep_learning_neuralnet_books/,kjahan,1509000403,,0,1
96,2017-10-26,2017,10,26,22,78voaz,can we use auto encoder and rbm for analysing the text and summarizing it.,https://www.reddit.com/r/deeplearning/comments/78voaz/can_we_use_auto_encoder_and_rbm_for_analysing_the/,prasanthpichu,1509025865,,0,1
97,2017-10-27,2017,10,27,0,78wevl,Distributed TensorFlow Guide,https://www.reddit.com/r/deeplearning/comments/78wevl/distributed_tensorflow_guide/,chiraqe,1509032739,,0,3
98,2017-10-27,2017,10,27,1,78wvg5,StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks,https://www.reddit.com/r/deeplearning/comments/78wvg5/stackgan_text_to_photorealistic_image_synthesis/,jskdr,1509036707,,2,4
99,2017-10-27,2017,10,27,3,78xqbu,Speech Recognition Is Not Solved,https://www.reddit.com/r/deeplearning/comments/78xqbu/speech_recognition_is_not_solved/,dpgowan,1509044222,,1,1
100,2017-10-27,2017,10,27,3,78xqw0,Tired of AWS. External GPU for MacBook?,https://www.reddit.com/r/deeplearning/comments/78xqw0/tired_of_aws_external_gpu_for_macbook/,Kehv1n,1509044364,"Hello!

I'm just wondering if anyone has ever tried to train their models via external GPU on their MacBook before? I've done some research and looked at few external GPU's (BISON) and they've peaked my interest.

My issue is that my AWS server costs are becoming somewhat high (I'm probably doing something silly while running my epochs) and I would much rather invest into something that I can have for the long run and use for other things (gaming, maybe even mining? Correct me if I'm over my head here).

Just wondering if anyone has ever tried to use an external GPU from BISON or other companies? And if something like this is even possible in the mac world. 

If all else fails, I'll invest some money into a more intricate computer, but I really just need a GPU with CUDDA 

Thanks again

- K",12,3
101,2017-10-27,2017,10,27,5,78yd22,What is the best encoding for the output of a binary classifier,https://www.reddit.com/r/deeplearning/comments/78yd22/what_is_the_best_encoding_for_the_output_of_a/,mlnairdon,1509049891,"I am new to the ML world, and my question is quite simple, but I was not able to find a clear response by googling.

Imagine I have a binary classification task for which I want to use some DNN. It could be recognizing if a picture is a cat or a dog, or if a MNIST digit is even or odd.

What are the best practices when it comes to encoding the output:

- should I use a one hot vector (e.g. cat=[0,1] and dog=[1,0])
- should I just use a single value (e.g. cat=0 and dog=1)

Is one approach better than the other, or is it totally irrelevant.

Tx in advance

Neil",2,1
102,2017-10-27,2017,10,27,8,78zk44,Introducing Gluon: a new library for machine learning from AWS and Microsoft | AWS Blog,https://www.reddit.com/r/deeplearning/comments/78zk44/introducing_gluon_a_new_library_for_machine/,dannyeuu,1509061354,,1,1
103,2017-10-27,2017,10,27,22,793962,7 Types of Artificial Neural Networks for Natural Language Processing,https://www.reddit.com/r/deeplearning/comments/793962/7_types_of_artificial_neural_networks_for_natural/,dearpetra,1509111208,,0,4
104,2017-10-29,2017,10,29,16,79f8iw,What is wrong with the batch_size of the following tensorflow code?,https://www.reddit.com/r/deeplearning/comments/79f8iw/what_is_wrong_with_the_batch_size_of_the/,[deleted],1509261279,[deleted],0,1
105,2017-10-29,2017,10,29,16,79f9pv,This Tensorflow code does not train when batch_size is more than 1.....,https://www.reddit.com/r/deeplearning/comments/79f9pv/this_tensorflow_code_does_not_train_when_batch/,[deleted],1509261964,[deleted],0,1
106,2017-10-30,2017,10,30,1,79h9nj,"Progressive Growing of GANs for Improved Quality, Stability, and Variation",https://www.reddit.com/r/deeplearning/comments/79h9nj/progressive_growing_of_gans_for_improved_quality/,pmz,1509292924,,0,9
107,2017-10-30,2017,10,30,7,79jhw5,How good is LSTM for time series forecasting?,https://www.reddit.com/r/deeplearning/comments/79jhw5/how_good_is_lstm_for_time_series_forecasting/,gaeioran,1509314611,"I am writing my master's project proposal and really want to work on deep learning. The dataset I will be working with is the sales data of products on an E-commerce shop. The goal is to perform sales forecast. 

LSTM is the most mentioned model when it comes to deep learning time series forecast. However, I haven't found any paper suggesting that it performs well on other data sets rather than image recognition and translation. Instead, I found many people complaining about its performance and difficult tuning process. I am now worried that LSTM may never work for sales forecast.

So, my question is, according to your experience do you think LSTM performs well on real-life time series forecast in comparison with tranditional models like ARIMA and Holt-winters? ",4,9
108,2017-10-30,2017,10,30,20,79n2tv,How to Learn Deep Learning in 90 days?,https://www.reddit.com/r/deeplearning/comments/79n2tv/how_to_learn_deep_learning_in_90_days/,favouriteblog,1509362749,,2,1
109,2017-10-30,2017,10,30,21,79ndkn,Deep learning noob needs guidance,https://www.reddit.com/r/deeplearning/comments/79ndkn/deep_learning_noob_needs_guidance/,nenad96,1509366534,"Hi all,
I've recently began to take interest in neural networks (month or two). I've watched a couple of tutorials, and the udacity free deep learning course. I am completely confused about this field. 
There was some introductory class in machine learning on my college , but they didn't teach introductory stuff like training, testing, fitting and those concepts, they began with some linear algebra math that involved some four dimensional spaces and reducing them to two dimensions. It left me completely confused. I was always good at math but not that abstract area. 
Watching online videos I made MNIST classifier and notMNIST (udacity thing), I have good (or I think so) understanding of math involved there: matrices multiplying, softmax probabilities, one hot encoding, cross entropy error, taking derivatives with respect to the weights and subtracting them. I also understood convolutions with strides, padding, filters etc. I really enjoyed getting from 0 understanding on this field, to being able to classify handwritten digits.
I need your opinions whether should I continue to spend time in deep learning if I posses math skills to understand derivatives and matrices multiplying and not abstract spaces. Would you recommend some materials that I should look through?

I am really grateful for your advice :)

",4,2
110,2017-10-31,2017,10,31,1,79ov65,https://www.favouriteblog.com/how-to-learn-deep-learning-in-90-days/,https://www.reddit.com/r/deeplearning/comments/79ov65/httpswwwfavouriteblogcomhowtolearndeeplearningin90/,favouriteblog,1509381161,,1,1
111,2017-10-31,2017,10,31,13,79thxg,Neural network game AI,https://www.reddit.com/r/deeplearning/comments/79thxg/neural_network_game_ai/,reidjako,1509424321,"https://i.gyazo.com/ac1da943c555670f52fa3935e95ad902.mp4
So I have a pretty basic game I have here. I created a very simple neural network with 20 hidden layers 9 input layers and 1 out put. Which in the end allowed me to aim the ""cannon"" the green line which shoots. I had another network which would shoot if it was visible etc. etc. 

What do you guys think best way to have one network to make the blue thing move on its own. I am using dlib with cuda, the bit I am becoming stuck with is that how do I effectively teach it movement for example, I could say if you move closer it is good, however, it could just easily get stuck in a corner. So any advice would be appreciated. 
+ What sized network do you think would be best suited. ",1,3
112,2017-10-31,2017,10,31,21,79vdv2,"Hello, World: Building an AI that understands the world through video",https://www.reddit.com/r/deeplearning/comments/79vdv2/hello_world_building_an_ai_that_understands_the/,digitalson,1509452877,,1,10
0,2017-11-1,2017,11,1,19,7a2prk,MonkeyLearn integration with Scrapinghub!,https://www.reddit.com/r/deeplearning/comments/7a2prk/monkeylearn_integration_with_scrapinghub/,janemoz,1509532077,,0,7
1,2017-11-1,2017,11,1,22,7a3mv2,A Non-Experts Guide to Image Segmentation Using Deep Neural Nets,https://www.reddit.com/r/deeplearning/comments/7a3mv2/a_nonexperts_guide_to_image_segmentation_using/,trumtra,1509543784,,0,1
2,2017-11-2,2017,11,2,1,7a4o7p,Top 15 Courses to Break into Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/7a4o7p/top_15_courses_to_break_into_artificial/,byAllaAI,1509553510,,0,1
3,2017-11-2,2017,11,2,3,7a5hy4,Why Deep Learning Surprises me,https://www.reddit.com/r/deeplearning/comments/7a5hy4/why_deep_learning_surprises_me/,disty1a,1509560658,,0,1
4,2017-11-2,2017,11,2,6,7a6r77,What do you expect will happen in ResNet if dropout is used?,https://www.reddit.com/r/deeplearning/comments/7a6r77/what_do_you_expect_will_happen_in_resnet_if/,Talos19,1509571904,,0,0
5,2017-11-2,2017,11,2,10,7a8d5x,Tenure Track Position in Deep Learning,https://www.reddit.com/r/deeplearning/comments/7a8d5x/tenure_track_position_in_deep_learning/,ml_account,1509587142,,0,0
6,2017-11-2,2017,11,2,13,7a9b0i,"Thoughts on ""Deep learning with segregated dendrites""?",https://www.reddit.com/r/deeplearning/comments/7a9b0i/thoughts_on_deep_learning_with_segregated/,rsChron,1509597503,"Paper: https://arxiv.org/abs/1610.00161
video at conference: https://www.youtube.com/watch?v=AfrU2wHQnrs

What are your thoughts on this work? I find his approach interesting.",3,4
7,2017-11-3,2017,11,3,3,7adpm8,Skymind Intelligence Layer CE (Bundles open-source deep learning tools for one-click deployment),https://www.reddit.com/r/deeplearning/comments/7adpm8/skymind_intelligence_layer_ce_bundles_opensource/,vonnik,1509649137,,1,1
8,2017-11-3,2017,11,3,6,7aekkk,Building Deep Learning system ($20K),https://www.reddit.com/r/deeplearning/comments/7aekkk/building_deep_learning_system_20k/,jfrmqOX,1509656572,"Hi,
I got a budget of $15K - $20K for building a Deep Learning setup. I would say I know how to design a good $5K-$7K system (fast i7/i9, pcieSSD, x2 TitanXp, 64Gb RAM ) and there are a few guidelines out there. However, how should I scale this up to a system 2x-3x the price? Does it make sense having a muli-soket 12/16 threads Xeon system? x8 1080 or x4 TitanXp? Should I go for the later since the bandwidth is way higher 550Gb/s vs 320Gb/s on the 1080?
Thanks!
",13,2
9,2017-11-3,2017,11,3,7,7af3k2,Generative Adversarial networks overlooks the sampled noise in conditional setting.,https://www.reddit.com/r/deeplearning/comments/7af3k2/generative_adversarial_networks_overlooks_the/,saharudra,1509661385,"Hi all, I am looking for the paper that mentions that during training a conditional gan, the generator stops looking at the noise. Also, if that is not the case (ie no such paper exists and my memory has fooled me) please state a counter otherwise.",1,2
10,2017-11-3,2017,11,3,9,7afsif, Latest Deep Learning OCR with Keras and Supervisely in 15 minutes,https://www.reddit.com/r/deeplearning/comments/7afsif/latest_deep_learning_ocr_with_keras_and/,tdionis,1509668033,,1,4
11,2017-11-3,2017,11,3,14,7ahheu,Deep Learning - Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/7ahheu/deep_learning_learn_recurrent_neural_networks_in/,dnonsense,1509687732,,0,2
12,2017-11-3,2017,11,3,18,7aicpj,Christoph Krner - Run Deep Learning models in the browser with JavaScript and ConvNetJS,https://www.reddit.com/r/deeplearning/comments/7aicpj/christoph_krner_run_deep_learning_models_in_the/,pmz,1509702252,,1,10
13,2017-11-3,2017,11,3,21,7aj314,New Theory Cracks Open the Black Box of Deep Learning,https://www.reddit.com/r/deeplearning/comments/7aj314/new_theory_cracks_open_the_black_box_of_deep/,molode,1509712622,,2,2
14,2017-11-3,2017,11,3,22,7ajj2r,Geoffrey Hinton proposes a 'twist' on Neural Networks,https://www.reddit.com/r/deeplearning/comments/7ajj2r/geoffrey_hinton_proposes_a_twist_on_neural/,teamrework,1509717462,,0,1
15,2017-11-4,2017,11,4,13,7aopof,What are the advantages of using deep learning methods to classify fingerprints (compared to decision trees)?,https://www.reddit.com/r/deeplearning/comments/7aopof/what_are_the_advantages_of_using_deep_learning/,Szyve,1509769862,"I'm trying to understand why deep learning might be more suitable for the task of classifying fingerprints. I know that deep learning is extremely accurate at solving similar complex pattern matching problems such as object recognition but I'm struggling to find a good explanation (that I can translate to fingerprints) as to why this is the case.


Some articles seem to suggest that deep learning could be less affected when the input is flawed, such as if the finger was placed at an odd angle, compared to other methods. If this is true, why is this the case?


It's worth mentioning that this is not for any assessed work that I'm doing so my motive is purely curiosity. Also, the purpose of classifying fingerprints would be to reduce the search space for identification in databases.
",3,6
16,2017-11-5,2017,11,5,5,7asyky,Venturing into Deep Learning : Dilemma about training approaches,https://www.reddit.com/r/deeplearning/comments/7asyky/venturing_into_deep_learning_dilemma_about/,I_M_VA,1509826084,"Hello everyone! This is my first question on Reddit and it's a dilemma I'm having about the approach to follow.

So I'm working on projects involving application of deep learning into the computer vision problem, primarily object detection and segmentation. Till now, I was designing models using Keras on my Ubuntu laptop. It's an old HP laptop, the 2014 version of the 15 inch pavilion series, P007tx. It has 8gb ram and the Nvidia GeForce GT 840m card. It has a lot of hardware issues so I'm looking to purchase a new laptop. I'll be utilizing the new laptop for running softwares like Matlab, reading research papers, making presentations and designing the deep learning models.

My dilemma is, should I use the laptop for training the models as well, in which case I'll have to buy a decent gaming laptop with a GTX 1080 card or should I buy a normal laptop, like the latest 15 inch MacBook pro, use it for model design and then use AWS instances or Google cloud computing services to train the models?

I am looking for a long term investment, I.e looking to use the laptop for next 4-5 years atleast. I read on an online forum that using gaming laptops for graphic intensive purposes like training Deep neural nets for long time may result in damage of the hardware inside them, hence I'm inclined to follow the second approach which I have suggested.

The budget is not an issue. But it has to be a laptop as I'm a university student and have to carry the laptop around for classes and all. Can't be a desktop. 

Please give suggestions as soon as possible. ",7,2
17,2017-11-5,2017,11,5,8,7au75e,Q{&amp;A} Deep Learning Comprehensive Book,https://www.reddit.com/r/deeplearning/comments/7au75e/qa_deep_learning_comprehensive_book/,CygnusOB2,1509839176,"I've read Deep Learning by Ian Goodfellow and Yoshi's Bengio and Aaron Courville, except for the last Section (Mainly introduced researching sub-domains).

I also tried searching thoroughly Amazon's stand for some technical/theoretical up to date alternatives that cover CV (more detailed and wider than Standford cs231n) along with further DL subareas like deep reinforcement learning, not being a code by example guide, wherein no theoretical foundations/proofs/illustration is provided. 

Thought this question answered to benefit me tremendously because I have no access to most Google Scholar articles, or Proceedings in any DL conference, or journals. In the same manner, I know there's Arxiv, though an extensive up to date book would have a context in place and then allow me to digress through relevant advancements without much trouble.  

Note: the Deep Learning book is great, nonetheless while reading I got the gist it covered material til 2016 tops. And I know I can buy subscriptions to academia material. It's just I want to get artillery to work in DL, because right now I am not with any solution in hands needed to be solved. ",9,7
18,2017-11-5,2017,11,5,22,7axku8,"IDea, Self learning Car, Vs Self learning Track.",https://www.reddit.com/r/deeplearning/comments/7axku8/idea_self_learning_car_vs_self_learning_track/,somerandomperson412,1509889077,"So i had a silly idea, -Car Vs terrain.

The car tries to learn how to drive, while the Track learns how to best be a bad track for the car.

there should be a few rules for the track though, like no to sharp turns or crazy loopty loops, 



",3,4
19,2017-11-6,2017,11,6,7,7b0r1v,Image Classification using Feedforward Neural Network in Keras,https://www.reddit.com/r/deeplearning/comments/7b0r1v/image_classification_using_feedforward_neural/,keghn,1509919967,,0,5
20,2017-11-6,2017,11,6,9,7b1p8w,Hetelek  Jupyter Notebooks in the cloud (on powerful GPUs)!,https://www.reddit.com/r/deeplearning/comments/7b1p8w/hetelek_jupyter_notebooks_in_the_cloud_on/,hetelek_,1509929547,,2,8
21,2017-11-6,2017,11,6,12,7b2owe,Why do we use sampled points instead of mean to reconstruct outputs in variational autoencoder?,https://www.reddit.com/r/deeplearning/comments/7b2owe/why_do_we_use_sampled_points_instead_of_mean_to/,adsada1231,1509940359,"I read information about variational autoencoder from this post: https://blog.keras.io/building-autoencoders-in-keras.html. To get reconstructed output, a value is sampled from Gaussian distribution in latent space, does anyone know why we need to use sampled data instead of the mean value itself to reconstruct the output? Would that be less accurate (since it introduces noise by sampling)?

Thanks!",1,3
22,2017-11-7,2017,11,7,1,7b6c2u,This Startup's Artificial Voice Sounds Almost Indistinguishable From A Human's,https://www.reddit.com/r/deeplearning/comments/7b6c2u/this_startups_artificial_voice_sounds_almost/,macinnis23,1509986702,,1,3
23,2017-11-7,2017,11,7,4,7b7bx5,Creating a Question Model from Text (nlp),https://www.reddit.com/r/deeplearning/comments/7b7bx5/creating_a_question_model_from_text_nlp/,resoredo,1509995227,"Hi!
I dont remember wehre it was, maybe can someone lead me to the right direction ro something similiar:

There was a website (and github) which demonstrated the Creation of a Question Model based on some input text. Basically, I could jsut enter the first two paragraphs of the Wikipedia article from Coco Chanel, and then ask questions and get answers, based on the aforementioned paragraphs.

",1,2
24,2017-11-7,2017,11,7,5,7b7t8f,Video Game Graphics To Reality And Back | Two Minute Papers #203,https://www.reddit.com/r/deeplearning/comments/7b7t8f/video_game_graphics_to_reality_and_back_two/,keghn,1509999364,,0,9
25,2017-11-7,2017,11,7,7,7b8mon,Fooling DNN descriptive statistics? Better be relevant.,https://www.reddit.com/r/deeplearning/comments/7b8mon/fooling_dnn_descriptive_statistics_better_be/,CygnusOB2,1510006423,,0,7
26,2017-11-8,2017,11,8,3,7bf11t,There are many ways to do deep learning. This might be the geekiest.,https://www.reddit.com/r/deeplearning/comments/7bf11t/there_are_many_ways_to_do_deep_learning_this/,bcaulfield,1510078461,,0,1
27,2017-11-8,2017,11,8,3,7bfbm0,How to train a simple linear regression model with SGD in pytorch successfully?,https://www.reddit.com/r/deeplearning/comments/7bfbm0/how_to_train_a_simple_linear_regression_model/,real_charlie_parker,1510080928,,0,4
28,2017-11-8,2017,11,8,7,7bgqq2,Deep learning in a third world country,https://www.reddit.com/r/deeplearning/comments/7bgqq2/deep_learning_in_a_third_world_country/,ChmHsm,1510093009,"Hello deep learners,
I won't be long. 
I'm a 24 year old software engineer, and I'm hugely excited and passionate about deep learning but I'm from Morocco (north Africa). What is, according to you, the best way to get professional experience in deep learning in order to make a career out of it. 
Ps: I've been following DL advances for 2 years now, practiced it a bit, and I'm currently enrolled in the deep learning specialization on coursera (taught by Andrew Ng). Thoughts pleeeaaase!! ",4,8
29,2017-11-8,2017,11,8,8,7bh2dr,"If deep learning eliminates the ability for poor human decision making, what will happen to all speculative markets in the future? For example, the stock market wouldnt need to exist and the person with the best machine wins. ??",https://www.reddit.com/r/deeplearning/comments/7bh2dr/if_deep_learning_eliminates_the_ability_for_poor/,weisguymcfly,1510096031,,3,3
30,2017-11-8,2017,11,8,21,7bl0r3,Should I deploy deeplearning in production using Tensorflow or Keras?,https://www.reddit.com/r/deeplearning/comments/7bl0r3/should_i_deploy_deeplearning_in_production_using/,mrcet007,1510144383,"Currently I am working on deep learning project which I am going to deploy in production.

Should I write my code in pure low level tensorflow or should I implement everything using tf.keras (keras is fully intergrated in core tensorflow as of version 1.4)?

My project can be implemented in using Keras functionality, I dont see any requirement like custom loss function etc. which is easier with tensorflow.

What do experts usually do in top companies which uses deeplearning models in production? I feel that using low level tensorflow will need lot more effort and time. But is there any advantages in using tensorflow over keras, if my project only requires functionality in keras?",4,7
31,2017-11-9,2017,11,9,4,7bnrfk,Pre Trained QA Model,https://www.reddit.com/r/deeplearning/comments/7bnrfk/pre_trained_qa_model/,artificial_intel423,1510169644,Anyone know of a pretrained model for question answering that was built using Stanfords SQUAD data set?,0,2
32,2017-11-9,2017,11,9,4,7bnu9g,Set of operators that allow an easy visual configuration of Deep Learning network,https://www.reddit.com/r/deeplearning/comments/7bnu9g/set_of_operators_that_allow_an_easy_visual/,datascienceguru,1510170317,,0,2
33,2017-11-9,2017,11,9,4,7bnw4k,How can I train the joint layer of a multimodal deep belief net?,https://www.reddit.com/r/deeplearning/comments/7bnw4k/how_can_i_train_the_joint_layer_of_a_multimodal/,Alex5316,1510170764,"I tried to implement a multimodal deep belief net, which was proposed by Nitish Srivastava et al. in their paper.
I know how to train an RBM and DBN. But for multimodal deep belief net, Nitish said the joint layer can also be trained using the greedily layer-wise strategy. My understanding about the joint layer is an RBM whose visible layer is the concatenation of the top hidden layer of the two separate DBN. Am I right? Could someone help me with this problem? Thanks!",1,2
34,2017-11-9,2017,11,9,7,7bp32p,What IBM is doing different w machine learning,https://www.reddit.com/r/deeplearning/comments/7bp32p/what_ibm_is_doing_different_w_machine_learning/,alexa_y,1510181334,,0,1
35,2017-11-9,2017,11,9,19,7bsi4x,BEST OF ICCV in Computer Vision News of November [link],https://www.reddit.com/r/deeplearning/comments/7bsi4x/best_of_iccv_in_computer_vision_news_of_november/,Gletta,1510223235,"Find out great take-home lessons from ICCV2017 in the BEST OF ICCV section of Computer Vision News, published by RSIP Vision: 33 pages from one of the main Computer Vision conferences, held only a few days ago. Many articles about deep learning!
Free subscription at page 60. 
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2017November/  
and PDF version ==&gt; 
http://www.rsipvision.com/computer-vision-news-2017-november-pdf/ 
Enjoy!",2,3
36,2017-11-9,2017,11,9,23,7btgmm,Nvidia Deep Learning Institute Workshops to be held in 6 cities in India,https://www.reddit.com/r/deeplearning/comments/7btgmm/nvidia_deep_learning_institute_workshops_to_be/,cloudirec,1510236117,,0,1
37,2017-11-10,2017,11,10,1,7bu8ml,frugally-deep - A header-only library for using Keras models in C++,https://www.reddit.com/r/deeplearning/comments/7bu8ml/frugallydeep_a_headeronly_library_for_using_keras/,Dobias,1510243562,,5,14
38,2017-11-10,2017,11,10,1,7bue71,"VNCoreMLTransform request failed, ""The size of the output layer 'output1' in the neural network does not match the number of classes in the classifier.""",https://www.reddit.com/r/deeplearning/comments/7bue71/vncoremltransform_request_failed_the_size_of_the/,TissaFissa,1510244929,"Hello everyone! I have gotten terribly stuck on this one problem in my Deep Learning project. I developed a CNN which has 26 classes, one for every letter in the alphabet, the classifier therefore has 26 outputs and 26 classes I would say? However I keep getting this error in Xcode. I have no idea why this is occuring...

The code for my Xcode file can be found here: https://github.com/thijsheijden/Visionary
The code for my Keras CNN can be found here: https://github.com/thijsheijden/chars74kCNN
",0,3
39,2017-11-10,2017,11,10,1,7bueak,MariFlow - Self-Driving Mario Kart w/Recurrent Neural Network,https://www.reddit.com/r/deeplearning/comments/7bueak/mariflow_selfdriving_mario_kart_wrecurrent_neural/,keghn,1510244953,,0,11
40,2017-11-10,2017,11,10,2,7butmn,I would appreciate if you could answer a few questions on machine learning,https://www.reddit.com/r/deeplearning/comments/7butmn/i_would_appreciate_if_you_could_answer_a_few/,MLGJuan,1510248642,,0,2
41,2017-11-10,2017,11,10,5,7bvygu,Need a zombie army in a hurry? Deep learning can help.,https://www.reddit.com/r/deeplearning/comments/7bvygu/need_a_zombie_army_in_a_hurry_deep_learning_can/,bcaulfield,1510258260,,0,1
42,2017-11-12,2017,11,12,2,7c9k9y,Setting mean and std of REWARDS in reinforcement learning - a question,https://www.reddit.com/r/deeplearning/comments/7c9k9y/setting_mean_and_std_of_rewards_in_reinforcement/,closedloopy,1510420136,"In the great post [pong to pixels](http://karpathy.github.io/2016/05/31/rl/) by Karpathy, and more explicitly in his code [here](https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5#file-pg-pong-py-L108) we see that he sets the mean of the rewards to 0 and the standard deviation to 1. This confuses me because that means that half of the rewards will be greater than zero, and the other less than zero. Now, lets assume this array of rewards came from an episode that we liked (good performance) then we'd want to reinforce the behavior. But as far as I can tell half of the actions will be associated with positive reward (and thus encouraged) and the other half with negative reward (and thus discourage). 


*Can anyone help me get a better intuition about why he does this? An example by Pytorch follows:*


PyTorch has in [their demo](https://github.com/pytorch/examples/blob/master/reinforcement_learning/reinforce.py) a solution of solving the [cart pole](https://gym.openai.com/envs/CartPole-v0/) from open ai gym, and the solution does the same thing in terms of modifying the rewards:

First we have the raw rewards (all ones. The longer the pole stays balanced, the more reward we get):

    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,
      1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,
      1.,  1.,  1.,  1.,  1.]

Then we [discount](https://github.com/pytorch/examples/blob/master/reinforcement_learning/reinforce.py#L62) them:

    [26.76966303456023, 26.02996266117195, 25.282790566840355, 24.528071279636723, 23.76572856528962, 
    22.995685419484467, 22.21786406008532, 21.4321859192781, 20.638571635634445, 19.8369410460954, 
    19.027213177874142, 18.209306240276913, 17.383137616441328, 16.54862385499124, 
    15.705680661607312, 14.854222890512437, 13.994164535871148, 13.12541872310217, 
    12.247897700103202, 11.361512828387072, 10.466174574128356, 9.561792499119552, 8.64827525163591, 
    7.72553055720799, 6.793465209301, 5.8519850599, 4.90099501, 3.9403989999999998, 2.9701, 1.99, 1.0]

Then finally we apply the [mean of 0 and std of 1](https://github.com/pytorch/examples/blob/master/reinforcement_learning/reinforce.py#L65):

     [1.6023, 1.5001, 1.3965, 1.2929, 1.1897,
     1.0875, 0.9859, 0.8842, 0.7819, 0.6796,
     0.5768, 0.4728, 0.3672, 0.2595, 0.1500,
     0.0383, -0.0761, -0.1939, -0.3137, -0.4315,
    -0.5477, -0.6630, -0.7778, -0.8916, -1.0049
    -1.1172, -1.2289, -1.3396, -1.4498, -1.5600, -1.6695]

To be clear, I've seen [this post](http://cs231n.github.io/neural-networks-2/) where we learn about data pre-processing and the value of updating mean and std of INPUT, but that is on the INPUT DATA, not the REWARDS. My question is why we would apply this transformation to the REWARDS.

Thank you!",10,3
43,2017-11-12,2017,11,12,20,7cf0pf,Inference of sequential events: what methods exist to do something like this?,https://www.reddit.com/r/deeplearning/comments/7cf0pf/inference_of_sequential_events_what_methods_exist/,Zeekawla99ii,1510487672,"This is a rather clumsy question, but I'm trying to work something out. This post is motivated by I conversation I had with an ecologist trying to working with events in systems which occur in a sequence, i.e. the events are related by time. 

Let me give two abstract examples, ""thought experiments"":

(1) Let's say you didn't know how to play chess. However, I am able to give you thousands of images of chess boards in mid-play; that is, for several years, I've been politely interrupting thousands of games of chess and taking pictures of a chess board from time start to time finish. I give them to you, but they are not labeled as to when during the game I took the picture. 

Question: could you infer (or statistically characterize) the rules of chess? That is, how could you characterize with confidence how the pieces move, the sequence of how the pieces are played, etc.?

What methods could one use to at least describe the rules of the game?

(2) Let's say there's a 1000 by 1000 matrix of pixel values, all black. Based on a color order rule that I know but you don't know, I switch a small subset of the pixels to either blue, red, green, yellow or purple. Once a pixel is switched from black to a non-black color, it cannot be switched again. (As an example, the rule is turn a few black pixels to red, then a few black pixels to green, then blue, then purple, then yellow. The rule is red-green-blue-purple-yellow.) I do this hundreds of thousands of times, each time starting with a new set of all black pixels, and saving the matrix at some point before I'm done. I send you each of these matrices.

From these thousands of matrices, how could you possibly infer the sequence of colors? Could you also infer something about where I've decided to place the colored pixels (i.e. is it entirely random or could there be a logic to where I'm placing these pixels)?",6,1
44,2017-11-13,2017,11,13,5,7chuib,"1x1 convolutions with stride (2,2)",https://www.reddit.com/r/deeplearning/comments/7chuib/1x1_convolutions_with_stride_22/,aendrs,1510518245,"I was looking at the Xception implementation in keras and in some blocks Chollet uses residual connections with 1x1 convolutions with stride (2,2) and 'same' padding:
(Conv2D(128, (1, 1), strides=(2, 2),padding='same',use_bias=False)(x)) 

I wonder, how is the output calculated in that case for the 'skipped' spatial elements? (since the stride is larger than the kernel) ",4,6
45,2017-11-13,2017,11,13,6,7cicwn,Traceback issue in CNN,https://www.reddit.com/r/deeplearning/comments/7cicwn/traceback_issue_in_cnn/,[deleted],1510522964,[deleted],0,1
46,2017-11-13,2017,11,13,21,7cmu1t,What did you practice to improve yourself as a beginner?,https://www.reddit.com/r/deeplearning/comments/7cmu1t/what_did_you_practice_to_improve_yourself_as_a/,Amacei,1510577018,"


",12,2
47,2017-11-13,2017,11,13,21,7cmuc1,How to Master Function Optimization in Deep Learning,https://www.reddit.com/r/deeplearning/comments/7cmuc1/how_to_master_function_optimization_in_deep/,dearpetra,1510577127,,0,2
48,2017-11-14,2017,11,14,0,7cnusr,what kind of hardware (gpu) do I need to train a large neural net like this?,https://www.reddit.com/r/deeplearning/comments/7cnusr/what_kind_of_hardware_gpu_do_i_need_to_train_a/,geekfolk,1510587461,"I have been playing with higher order resnets recently, I mean ""higher order"" similar to ""higher order derivatives"", anyways, I got myself a neural net that has approximately 42 million parameters, and I got a training set of approximately 480 thousands of small image blocks (augmented), I'm doing it on Keras and it's killing my titan x, what kind of gpu would you recommend for this kind of large neural net? I'm thinking about some hardware upgrading here",12,1
49,2017-11-14,2017,11,14,3,7cp104,CNN translation invariance,https://www.reddit.com/r/deeplearning/comments/7cp104/cnn_translation_invariance/,[deleted],1510597112,[deleted],1,3
50,2017-11-14,2017,11,14,7,7cqx0n,A practical tutorial to understand Convolutional Neural Networks and apply them to a concrete image classification problem using Keras and Tensorflow,https://www.reddit.com/r/deeplearning/comments/7cqx0n/a_practical_tutorial_to_understand_convolutional/,ahmedbesbes,1510612369,,0,8
51,2017-11-14,2017,11,14,8,7cr7mp,Deep Learning Fundamentals - YouTube Playlist,https://www.reddit.com/r/deeplearning/comments/7cr7mp/deep_learning_fundamentals_youtube_playlist/,blackHoleDetector,1510614909,"This [Deep Learning Fundamentals YouTube playlist](https://www.youtube.com/playlist?list=PL_SSujepRkqy0QhD4RK_3VCd2O5valQit) covers essential topics in deep learning for beginners. The videos give short, general explanations of deep learning concepts and also show the technical implementation of some of these topics in code using the neural network API, Keras (written in Python). The playlist is still being developed, with new videos being added regularly. 

Some topics so far include:

- Machine learning overview
- Deep learning overview
- Artificial Neural Networks (ANN)
- Layers in an ANN
- Activation functions
- Training a model
- How a model learns
- Loss functions
- Data sets: train, validation, and test
- Under/overfitting
- Predicting with an ANN
- Regularization
- Fine-tuning
- Data augmentation
- More...
",3,9
52,2017-11-14,2017,11,14,12,7csnvj,What are some currently popular techniques for 'fast' object detection and tracking?,https://www.reddit.com/r/deeplearning/comments/7csnvj/what_are_some_currently_popular_techniques_for/,interstellarhighway,1510628521,"Over the last few months, I have been trying to familiarize myself with deep learning for an upcoming research project I want to try my hand at: which essentially involves object detection and tracking from a drone where the objects usually are people, cars etc. The algorithm would have to find out what object it is, and then track it reliably through the drone's own motion as well as that of the target itself.

By the end of the project, we plan to perform the inference on something like the Nvidia Jetson onboard the drone: where the challenge would be something like, say, landing the drone on a moving vehicle etc: which implies the tracking needs to be fairly accurate and also fast enough such that it runs at ~30fps on an embedded platform like the Jetson. The ones I have come across so far are algorithms like Faster RCNN, SSD, YOLO etc. As part of my research about existing techniques, I was hoping to get some feedback from the community here about some popular algorithms right now that focus on fast object detection and tracking. Thanks!",2,7
53,2017-11-14,2017,11,14,17,7cubwx,TensorFlow based android app which does image-captioning in real-time,https://www.reddit.com/r/deeplearning/comments/7cubwx/tensorflow_based_android_app_which_does/,Xe0n360,1510648823,"Check out our deep-learning based android app which captions live camera frames in real-time. https://github.com/neural-nuts/Cam2Caption

This app uses pre-trained model generated using
https://github.com/neural-nuts/image-caption-generator

Preview: http://gph.is/2iFzN9h",0,4
54,2017-11-14,2017,11,14,23,7cvw63,Hetelek  Jupyter Notebooks in the cloud on powerful GPUs starting at $0.35/hour!,https://www.reddit.com/r/deeplearning/comments/7cvw63/hetelek_jupyter_notebooks_in_the_cloud_on/,hetelek_,1510669371,,2,17
55,2017-11-15,2017,11,15,11,7d0zik,Are AMD RX series of graphics card good for Deep learning setup.,https://www.reddit.com/r/deeplearning/comments/7d0zik/are_amd_rx_series_of_graphics_card_good_for_deep/,theExactlyGuy,1510713441,RX graphics card are in Heavy demand for Miners. How is its Performance in regards to Deep learning platform?,5,3
56,2017-11-15,2017,11,15,21,7d3pr3,Google launches TensorFlow Lite developer preview for mobile machine learning,https://www.reddit.com/r/deeplearning/comments/7d3pr3/google_launches_tensorflow_lite_developer_preview/,molode,1510748240,,0,19
57,2017-11-16,2017,11,16,5,7d6w1u,Is it possible to do unsupervised image classification?,https://www.reddit.com/r/deeplearning/comments/7d6w1u/is_it_possible_to_do_unsupervised_image/,TheSexyDuckling,1510777170,"I recently finished the Machine Learning course by Andrew Ng on Coursera. However, I am still unsure how to go forward with the initial problem that I had in mind when I started the course.

Basically, what I am trying to do is implement an algorithm that will classify objects based on similarities of objects given multiple images without a supervised training set (i.e. an unsupervised training). For example, let's say I give the algorithm a bunch of images of cars on road (e.g. https://img3.stockfresh.com/files/p/paha_l/m/88/647080_stock-photo-many-cars-on-road.jpg), it should come up with a few classes such as Class 1 (cars), Class 2 (road), Class 3 (road marking), Class 4 (road sign), Class 5 (street light), Class 6 (Other). Obviously, it wouldn't know Class 1 is called a car because we never trained the object ""car"" explicitly. But the user can infer Class 1 is for cars based on what is highlighted after the algorithm has been completed.

I am not sure if what I'm asking for is impossible or if I should learn more such as Deep Learning in order to get this to work. Or is my only option to basically train each object (car, road, marking, etc.) separately based on images off Google?

I appreciate your inputs!

Cheers,
TSD",6,5
58,2017-11-16,2017,11,16,16,7dat1g,Top 50 Awesome Deep Learning Projects on Github,https://www.reddit.com/r/deeplearning/comments/7dat1g/top_50_awesome_deep_learning_projects_on_github/,favouriteblog,1510816657,,1,1
59,2017-11-16,2017,11,16,21,7dbzeb,TensorFlow text classification GPU on cloud,https://www.reddit.com/r/deeplearning/comments/7dbzeb/tensorflow_text_classification_gpu_on_cloud/,niujin,1510834305,"I'm looking at cloud based GPU solutions for running TensorFlow. Ideally I would use a 1080 GPU.

For example I found this one:

https://aws.amazon.com/marketplace/pp/B01M0AXXQB?qid=1510834051291&amp;sr=0-3&amp;ref_=srh_res_product_title Deep Learning AMI with Source Code (CUDA 8, Amazon Linux)

However some of the reviews are complaining that only CPU TF is installed, NVIDIA drivers are missing, etc. Is this true? Does anyone recommend a cloud based product on Amazon or similar that doesn't have these problems? Thanks!",8,5
60,2017-11-16,2017,11,16,21,7dc4v9,Deep Learning on Steroids with Keras and Horovod,https://www.reddit.com/r/deeplearning/comments/7dc4v9/deep_learning_on_steroids_with_keras_and_horovod/,nischalhp,1510836212,,5,9
61,2017-11-17,2017,11,17,1,7ddd08,How Deep Learning Will Alter the Retail Space,https://www.reddit.com/r/deeplearning/comments/7ddd08/how_deep_learning_will_alter_the_retail_space/,nicknikolaev,1510848486,,2,26
62,2017-11-17,2017,11,17,4,7dep7j,Logistic Regression Made Easy,https://www.reddit.com/r/deeplearning/comments/7dep7j/logistic_regression_made_easy/,mgr2786,1510859701,"Hey Everyone, 
I'm new to reddit and I thought I'd start out here on Machine learning with an Inaugural post about Logistic Regression. I hope you enjoy!
https://3dbabove.com/2017/11/14/logistic-regression/",5,1
63,2017-11-17,2017,11,17,5,7dfgub,What got you into studying A.I?,https://www.reddit.com/r/deeplearning/comments/7dfgub/what_got_you_into_studying_ai/,Amacei,1510865922,"All throughout childhood I've always found robots amazing. Transformers prime, code Yoko and mega man where my main favourite cartoons they somewhat built the inspiration for me which is why I focus on figuring out speech and personality 

Additional questions: do you have any preferred personalities or appearance for your program?",1,1
64,2017-11-17,2017,11,17,6,7dfmsm,Deep Learning for Time Series?,https://www.reddit.com/r/deeplearning/comments/7dfmsm/deep_learning_for_time_series/,deep_learning_minion,1510867240,"Hello all!

I am quite new to deep learning, and I am very interested in the idea of applying deep learning to time series data. I've worked through a few of the CNN and RNN Tensorflow tutorials and am feeling good enough to start playing with some real data. However, I am unsure of the correct approach to take.

I have time series data in which a scalar value of light intensity occupies each timestep. After x timesteps, the environment conditions change. After y timesteps, the environment conditions change again. The profile of the light intensity is quite distinct for each of the windows of time.

Is there a way I can build a network that will learn that a change occurs in the profile, and learn at what timestep this change has occurred?

Thanks!",1,3
65,2017-11-17,2017,11,17,15,7diujz,What are the good gpu clouds to use?,https://www.reddit.com/r/deeplearning/comments/7diujz/what_are_the_good_gpu_clouds_to_use/,Alirezag,1510899071,"I need to use gpu to run some deeplearning python code.
Was wondering if someone can give me a suggestion on which one of AWS, google cloud, etc is the best to go?
what are the options, is there any other company that provides good service and good price? just for the sake of asking, is there any free gpu cloud?

If that matters, Im a student and my code is written using pytorch.

Thanks",6,5
66,2017-11-17,2017,11,17,19,7dk4d7,Data Tagging in Medical Imaging  Diving Deep into the Processes,https://www.reddit.com/r/deeplearning/comments/7dk4d7/data_tagging_in_medical_imaging_diving_deep_into/,shashankg22,1510916037,,0,1
67,2017-11-17,2017,11,17,22,7dkrg6,Any advice for a data analyst looking to cross over to deep learning/AI?,https://www.reddit.com/r/deeplearning/comments/7dkrg6/any_advice_for_a_data_analyst_looking_to_cross/,bandalorian,1510923822,"I did my bachelors in mathematical statistics. I've been working in analytcs/data analysis for a number of years so am comfortable with relevant programming (SQL, python, R). I've also taken a number of classes and certifications in data science/big data/ML/AI - though in terms of ML I've had limited experience using this in practice (just done a bunch of random projects for different courses). I have familiarity with fundamental ML concepts but that's about it. 

I'm currently doing the [coursera deep learning specialization](https://www.coursera.org/specializations/deep-learning), and I'm now starting to think about how I can build a path to actually getting working with it at some point. Udacity offers a [9 month self driving car engineer program](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd013) which seems timely with everything that's going on, and also a direct practical application of everything. I also find computer vision extremely interesting, so autonomous driving seems like a good setting for me. 

What other things could I be doing? I have time, and I find it interesting so I'm just going to chip away until either I qualify for something or the field has grown enough that they'll take me out of desparation :)  Trying to methodically add to my educational background with the goal of being able to go to an interview and have a shot at getting hired. I've been looking at doing master programs, but very difficult to find the time for an on-campus degree, and I don't know that an online degree is all that much better/applicable than the very specialized courses that are popping up in this field, but all options are currently on the table. Any advice is appreciated! thanks",7,1
68,2017-11-17,2017,11,17,23,7dl3uu,How to feed activations vector as an input to the pooling layer,https://www.reddit.com/r/deeplearning/comments/7dl3uu/how_to_feed_activations_vector_as_an_input_to_the/,portlion,1510927242,"I am using activations function in matlab to get the output feature of conv5 layer in alexnet. I have got 43264 feature vector saved in a mat file. 

I need to feed this output of conv5 layer to the next layer which is pooling layer.

BUT, there is an error say unexpected input. The thing is I did not change the output size of conv5, it is just be as a feature vector.

Any help, Thanks in advance",4,3
69,2017-11-17,2017,11,17,23,7dl7gq,The Popular Deep Learning Libraries for Data Science,https://www.reddit.com/r/deeplearning/comments/7dl7gq/the_popular_deep_learning_libraries_for_data/,jackblun,1510928210,,0,1
70,2017-11-18,2017,11,18,1,7dmbs1,Prediction varies too much from one training to another,https://www.reddit.com/r/deeplearning/comments/7dmbs1/prediction_varies_too_much_from_one_training_to/,lazyleaaaf,1510937979,"I'm using keras to implement a CNN for a image classification task (5 classes). The loss I'm using is categorical cross entropy. The training seems to work fine, for now I reach around 70% of accuracy. The problem comes when I compute class scores on my test set: the performance is very different from one training to another, even though I use exact same parameters and trainset for each training. 

See the attached image: https://drive.google.com/open?id=1KXNxmn92B58Pb25JkXgmHBpL7he3cYLz
when looking at overall loss and accuracy during training, performances seem similar. But when checking for each class on my test set, performance is very different. Does anyone has an idea of what could have gone wrong?",9,3
71,2017-11-18,2017,11,18,4,7dngwb,A growing personality for an A.I,https://www.reddit.com/r/deeplearning/comments/7dngwb/a_growing_personality_for_an_ai/,[deleted],1510948040,[deleted],0,1
72,2017-11-18,2017,11,18,16,7drcw5,Using Deep Learning to draw caricatures. Best style transfer technique,https://www.reddit.com/r/deeplearning/comments/7drcw5/using_deep_learning_to_draw_caricatures_best/,harvey_slash,1510988703,,3,4
73,2017-11-18,2017,11,18,23,7dt6ns,Is there a way to do text summarization using autoencoders,https://www.reddit.com/r/deeplearning/comments/7dt6ns/is_there_a_way_to_do_text_summarization_using/,happy_pirate,1511014994,I need to know if there is a way to build a text summarizer which uses rbm and auto encoders,4,6
74,2017-11-19,2017,11,19,6,7dw1j9,     ,https://www.reddit.com/r/deeplearning/comments/7dw1j9/_____/,AhmedGadFCIT,1511041904,,0,1
75,2017-11-19,2017,11,19,20,7e04on,"Hi guys! I'm Subhash, and I've just released a new open source tool for instantly creating a REST API for any ML model. For now, it's a work in progress and so far supports all Keras models. What do you guys think? Would love your feedback!",https://www.reddit.com/r/deeplearning/comments/7e04on/hi_guys_im_subhash_and_ive_just_released_a_new/,[deleted],1511092007,[deleted],0,1
76,2017-11-19,2017,11,19,20,7e06a2,Introducing Olympus - A tool that instantly creates a REST API for any AI model.,https://www.reddit.com/r/deeplearning/comments/7e06a2/introducing_olympus_a_tool_that_instantly_creates/,subbytech,1511092730,,1,12
77,2017-11-20,2017,11,20,3,7e296a,Power &amp; Limits of Deep Learning  Yann LeCun,https://www.reddit.com/r/deeplearning/comments/7e296a/power_limits_of_deep_learning_yann_lecun/,yildiz17,1511114939,[removed],0,1
78,2017-11-20,2017,11,20,7,7e44en,Boltzmann Machines in TensorFlow with examples,https://www.reddit.com/r/deeplearning/comments/7e44en/boltzmann_machines_in_tensorflow_with_examples/,monsta-hd,1511131002,,0,8
79,2017-11-20,2017,11,20,8,7e4fop,Optimization Algorithms for Deep Learning: Math and Code,https://www.reddit.com/r/deeplearning/comments/7e4fop/optimization_algorithms_for_deep_learning_math/,mgr2786,1511133788,A colleague of mine had mentioned that they were getting asked quite a few questions about optimization algorithms in their interviews for deep learning positions. I decided to make a quick post about the important ones over at 3dbabove: https://3dbabove.com/2017/11/14/optimizationalgorithms/,2,20
80,2017-11-20,2017,11,20,19,7e7v07,Artificial Intelligence in India,https://www.reddit.com/r/deeplearning/comments/7e7v07/artificial_intelligence_in_india/,webtunixml,1511172159,,1,0
81,2017-11-20,2017,11,20,19,7e7ymw,Announcing Excel Add-in for ParallelDots AI APIs,https://www.reddit.com/r/deeplearning/comments/7e7ymw/announcing_excel_addin_for_paralleldots_ai_apis/,shashankg22,1511173523,,0,1
82,2017-11-20,2017,11,20,20,7e8co4,Error with unexpected input to MAX POOLING 3,https://www.reddit.com/r/deeplearning/comments/7e8co4/error_with_unexpected_input_to_max_pooling_3/,portlion,1511178809,"I used the activations function in Matlab to get the features of my data from the output of conv5 layer. The output is a feature vector with a dimension 43264 for each single image (I have 14000 Images).

I did some processing on this output with no change in the dimension so it still 43264.

As you can notice in the structure of alexnet, the input of the pooling3 should 13x13x256. So I changed the feature vector 43264 to 13x13x256 matrix, to be a cell array 14000x1 each cell has 13x13x256.

I used the following code to train the network:

net = trainNetwork (Data, Datalabels, Layers, trainingOptions)

I still has an error saying unexpected input to Pooling layer!

Any I idea please?

Thanks in advance",0,0
83,2017-11-20,2017,11,20,21,7e8hn2,"How Deep Learning, Quantum Rank Among 2017s Top Emerging Tech - CIO Journal.",https://www.reddit.com/r/deeplearning/comments/7e8hn2/how_deep_learning_quantum_rank_among_2017s_top/,dearpetra,1511180410,,0,0
84,2017-11-21,2017,11,21,4,7eb902,Is it possible to use Feature vector with Input Layer,https://www.reddit.com/r/deeplearning/comments/7eb902/is_it_possible_to_use_feature_vector_with_input/,portlion,1511204828,"I have 18000 images and each has 24000 feature vector, so the training data will be 18000x24000. My question is it possible to use a feature vector as an input to the networks? if yes, should it be like following:

InputLayer = imageinputlayer [1 24000]

And also, what should I write in number of channel is it 1 or 3 I mean [1 24000 3] or [1 24000 1]?

Many Thanks",0,3
85,2017-11-21,2017,11,21,13,7efae2,"Top 10 Best Deep Learning Videos, Tutorials &amp; Courses on Youtube from 2017",https://www.reddit.com/r/deeplearning/comments/7efae2/top_10_best_deep_learning_videos_tutorials/,favouriteblog,1511239753,,1,1
86,2017-11-21,2017,11,21,14,7efm2r,Hi. I have posted a video explaining how a Neural Network works using a simple real life example. Do check it out.,https://www.reddit.com/r/deeplearning/comments/7efm2r/hi_i_have_posted_a_video_explaining_how_a_neural/,harshMachineLearning,1511243214,,0,5
87,2017-11-21,2017,11,21,19,7egtjq,AANN: Absolute Artificial Neural Network,https://www.reddit.com/r/deeplearning/comments/7egtjq/aann_absolute_artificial_neural_network/,akanimax,1511258881,,2,4
88,2017-11-21,2017,11,21,21,7ehdt3,AI Can Help Hunt Down Missile Sites in China,https://www.reddit.com/r/deeplearning/comments/7ehdt3/ai_can_help_hunt_down_missile_sites_in_china/,polllyyy,1511266066,,0,0
89,2017-11-22,2017,11,22,1,7ej57b,Backpropagation in a RNN (BPTT): an easy to understand tutorial?,https://www.reddit.com/r/deeplearning/comments/7ej57b/backpropagation_in_a_rnn_bptt_an_easy_to/,Magus66,1511282500,"Hi!
I am working through the DeepLearning course of Prof. Hinton at Coursera. Unluckily - or luckily? (depends) - he isn't that easy to follow. Fortunately for me I did the DeepLearning Coursera course with Prof. Ng. And he is very easy to follow and explains everything in great detail.

Now I have to get an understanding of how the backprop in a RNN works if you want to implement it from scratch (I know there are libraries). But I want to understand it so I have to at least implement it on a small scale.

I worked myself through a simple two step RNN using Prof Ng graph method and working backwards. 

I searched my way through Google and Youtube, found some interesting stuff. But nothing that good. 

Which tutorials on BPTT - video or text - can you recommend?

Thanks. ",2,4
90,2017-11-22,2017,11,22,1,7ej7rs,Deploying WaveNet on Android Using TensorFlow,https://www.reddit.com/r/deeplearning/comments/7ej7rs/deploying_wavenet_on_android_using_tensorflow/,mwakanosya,1511283072,,0,7
91,2017-11-22,2017,11,22,2,7ejb5x, Big challenge in Deep Learning: training data  Hacker Noon,https://www.reddit.com/r/deeplearning/comments/7ejb5x/big_challenge_in_deep_learning_training_data/,tdionis,1511283811,,1,2
92,2017-11-22,2017,11,22,9,7emhw8,A Primer on Deep Learning,https://www.reddit.com/r/deeplearning/comments/7emhw8/a_primer_on_deep_learning/,psangrene,1511309207,,0,8
93,2017-11-22,2017,11,22,15,7eos0i,Implementation of Neural Tensor Network for Knowledge-base completion in Python using Keras.,https://www.reddit.com/r/deeplearning/comments/7eos0i/implementation_of_neural_tensor_network_for/,bhatt_gaurav,1511331239,,0,4
94,2017-11-22,2017,11,22,19,7epygv,GPUs for Deep Learning: Buyer's Guide,https://www.reddit.com/r/deeplearning/comments/7epygv/gpus_for_deep_learning_buyers_guide/,slavivanov,1511345959,,9,12
95,2017-11-23,2017,11,23,0,7ero5p,CardIO framework for deep research of electrocardiograms,https://www.reddit.com/r/deeplearning/comments/7ero5p/cardio_framework_for_deep_research_of/,Dearkafka,1511364134,,0,1
96,2017-11-23,2017,11,23,1,7es4y9,Reinforcement Learning: The quirks  Towards Data Science,https://www.reddit.com/r/deeplearning/comments/7es4y9/reinforcement_learning_the_quirks_towards_data/,Sig_Luna,1511367868,,0,5
97,2017-11-23,2017,11,23,12,7ewviu,"First blog in a series. -- ""Human Pose Estimation is a wonderful example of Deep Learning""",https://www.reddit.com/r/deeplearning/comments/7ewviu/first_blog_in_a_series_human_pose_estimation_is_a/,gilbeckers,1511409456,,0,4
98,2017-11-24,2017,11,24,21,7f78uw,Top 10 deep learning Framesworks everyone should know,https://www.reddit.com/r/deeplearning/comments/7f78uw/top_10_deep_learning_framesworks_everyone_should/,dearpetra,1511527338,,0,1
99,2017-11-24,2017,11,24,22,7f7mg1,Embedded deep learning: out of the cloud and onto devices,https://www.reddit.com/r/deeplearning/comments/7f7mg1/embedded_deep_learning_out_of_the_cloud_and_onto/,jackblun,1511531898,,0,7
100,2017-11-24,2017,11,24,23,7f7qrv,Understanding Objective Functions in Neural Networks,https://www.reddit.com/r/deeplearning/comments/7f7qrv/understanding_objective_functions_in_neural/,friscotime,1511533221,,0,6
101,2017-11-25,2017,11,25,7,7faxty,CNN for Short-Term Stocks Prediction using Tensorflow,https://www.reddit.com/r/deeplearning/comments/7faxty/cnn_for_shortterm_stocks_prediction_using/,psangrene,1511562971,,0,5
102,2017-11-25,2017,11,25,17,7fdwuk,Visual Analytics of Instagrams #gopro hashtag with AI,https://www.reddit.com/r/deeplearning/comments/7fdwuk/visual_analytics_of_instagrams_gopro_hashtag_with/,shashankg22,1511596958,,0,1
103,2017-11-25,2017,11,25,21,7fez6h,Which is better for deep learning: 4x1070 vs 2x1080ti vs 1x1080ti,https://www.reddit.com/r/deeplearning/comments/7fez6h/which_is_better_for_deep_learning_4x1070_vs/,aciurana,1511613730,"I'm trying to set up a good computer for deep learning. And I had one of these combinations in mind:

- 4x1070 4x450euros

- 2x1080ti 2x800euros

- 2x1070 or 2x1070ti

- 1x1080ti 800euros

From what I've seen in a tensorflow benchmark, you get very good results with 2x1080ti, but can you get better even using 4x1070?
Is it worth using 2x1080ti instead of one?
https://github.com/tobigithub/tensorflow-deep-learning/wiki/tf-benchmarks

Basically I want it to train different types of networks. I do not care which deep learning framework to use, I would use the one that worked best for me with that configuration.",6,6
104,2017-11-26,2017,11,26,1,7fg75e,Multivariate Time-Series Prediction using RNN,https://www.reddit.com/r/deeplearning/comments/7fg75e/multivariate_timeseries_prediction_using_rnn/,ragas_,1511627270,"Hi,
I'm trying to do multivariate time-series RNN using Tensorflow. Can someone guide me some resources on this. I don't want to use Keras. 

Thanks!",6,6
105,2017-11-26,2017,11,26,7,7fifbw,"Some Deep Learning with Python, TensorFlow and Keras",https://www.reddit.com/r/deeplearning/comments/7fifbw/some_deep_learning_with_python_tensorflow_and/,SandipanDeyUMBC,1511648096,,0,8
106,2017-11-26,2017,11,26,7,7fim01,Dogs vs. Cats: Image Classification with Deep Learning using TensorFlow in Python,https://www.reddit.com/r/deeplearning/comments/7fim01/dogs_vs_cats_image_classification_with_deep/,SandipanDeyUMBC,1511649928,,1,5
107,2017-11-26,2017,11,26,7,7fio8p,Deep Learning with TensorFlow in Python,https://www.reddit.com/r/deeplearning/comments/7fio8p/deep_learning_with_tensorflow_in_python/,SandipanDeyUMBC,1511650532,,2,11
108,2017-11-26,2017,11,26,8,7fira3,Deep Learning with TensorFlow in Python: Convolution Neural Nets,https://www.reddit.com/r/deeplearning/comments/7fira3/deep_learning_with_tensorflow_in_python/,SandipanDeyUMBC,1511651277,,0,2
109,2017-11-27,2017,11,27,0,7fnd5g,"If you would like to learn more about how Machine Learning and Deep Learning can be applied to daily processes, please check out my youtube video! I hope it helps, and if you found it interesting, please feel free to leave a comment and subscribe",https://www.reddit.com/r/deeplearning/comments/7fnd5g/if_you_would_like_to_learn_more_about_how_machine/,DiscoverAI,1511708530,,0,0
110,2017-11-27,2017,11,27,3,7foiqo,IoT interfaced Chatbot?,https://www.reddit.com/r/deeplearning/comments/7foiqo/iot_interfaced_chatbot/,dylxnxil,1511719368,"Hi, I was wondering how it would be possible to interface a learning tensorflow chatbot with an Internet of Things network in a home, with appliances such as outlets, lights, and temperature controllers. Thanks so much for any input!",4,2
111,2017-11-27,2017,11,27,5,7fpn7m,Deep Learning And The Information Bottleneck,https://www.reddit.com/r/deeplearning/comments/7fpn7m/deep_learning_and_the_information_bottleneck/,psangrene,1511729125,,0,6
112,2017-11-27,2017,11,27,7,7fq5y9,Implementing a Neural Network from Scratch in Python  An Introduction,https://www.reddit.com/r/deeplearning/comments/7fq5y9/implementing_a_neural_network_from_scratch_in/,psangrene,1511733631,,0,7
113,2017-11-27,2017,11,27,8,7fqla3,Deep Learning with Keras - YouTube Playlist,https://www.reddit.com/r/deeplearning/comments/7fqla3/deep_learning_with_keras_youtube_playlist/,blackHoleDetector,1511737496,"[Deep Learning with Keras - YouTube Playlist](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL)  

This playlist gives step-by-step tutorials for getting started with deep learning using Python and Keras. 

Some topics include:

- What prerequisites need to be met to start working with Keras
- Keras configurations
- Preprocessing data 
- Creating a neural net
- Training a neural net
- Using a neural net to predict on data
- Creating a convolutional neural net
- Using pre-trained models
- Fine-tuning/transfer learning
- Saving and loading model weights
- Data augmentation
- More...",0,2
114,2017-11-27,2017,11,27,10,7frieu,Tutorials To Learn Deep Learning With Python For Beginners,https://www.reddit.com/r/deeplearning/comments/7frieu/tutorials_to_learn_deep_learning_with_python_for/,dev2049,1511746177,,0,13
115,2017-11-27,2017,11,27,20,7fuime,Deep Learning Specialization by Andrew Ng,https://www.reddit.com/r/deeplearning/comments/7fuime/deep_learning_specialization_by_andrew_ng/,magneticono,1511781627,,0,1
116,2017-11-28,2017,11,28,8,7fzh9h,Methods for classifying sounds?,https://www.reddit.com/r/deeplearning/comments/7fzh9h/methods_for_classifying_sounds/,AspiringGuru,1511824987,"Have a local challenge to detect and classify noises in urban setting. Obviously not low hanging fruit, and possibly out of my skill level - will be hitting this hard over the weekend due to a local hackathon with a non trivial prize (startup deal from local council).

Some strategic steering on this topic would be really appreciated. 

I'll admit the links below are result of googling (light reading and discarding non useful results) rather than deep research on this topic. My previous work has been classifying images and building models on numerical input data. Sound analysis is a new area for me. So um.. yeah, hoping for pointers on fundamental methods for proof of concept and pathway to best practice.

https://aqibsaeed.github.io/2016-09-03-urban-sound-classification-part-1/
https://aqibsaeed.github.io/2016-09-24-urban-sound-classification-part-2/

https://github.com/bapalto/birdsong-keras

http://ceur-ws.org/Vol-1609/16090547.pdf

sound datasets.
https://serv.cusp.nyu.edu/projects/urbansounddataset/
https://research.google.com/audioset/",1,5
117,2017-11-28,2017,11,28,15,7g26bz,What good geospatial based RNN research can I look into doing for a PhD?,https://www.reddit.com/r/deeplearning/comments/7g26bz/what_good_geospatial_based_rnn_research_can_i/,GeoResearchRedditor,1511850566,I'm stuck trying to think how I can combine geospatial data and use RNNs for research that will still be relevant and useful 4 years from now.,3,1
118,2017-11-28,2017,11,28,17,7g2n3a,How Deep Learning trains AI using supervised data method,https://www.reddit.com/r/deeplearning/comments/7g2n3a/how_deep_learning_trains_ai_using_supervised_data/,alzador123,1511856398,,0,1
119,2017-11-28,2017,11,28,18,7g2zem,Deep Writing Novels,https://www.reddit.com/r/deeplearning/comments/7g2zem/deep_writing_novels/,DrFolAmour007,1511861146,"Hi everyone!

Does any of you know a good AI to help write novels? I want to play around with it...
I have Python and I know how to code!

thanks for your suggestions!

cheers",1,0
120,2017-11-28,2017,11,28,22,7g483b,Exclusive: Google Poaching Deep Learning Talent From NVIDIA,https://www.reddit.com/r/deeplearning/comments/7g483b/exclusive_google_poaching_deep_learning_talent/,friscotime,1511876721,,0,6
121,2017-11-29,2017,11,29,2,7g5tkl,Transform anything into a vector,https://www.reddit.com/r/deeplearning/comments/7g5tkl/transform_anything_into_a_vector/,mwakanosya,1511890479,,0,6
122,2017-11-29,2017,11,29,19,7gc99i,http://blog.paralleldots.com/product/use-cases-excel-add-text-analysis/?utm_source=Reddit&amp;utm_medium=group_post&amp;utm_campaign=r/deeplearning,https://www.reddit.com/r/deeplearning/comments/7gc99i/httpblogparalleldotscomproductusecasesexceladdtext/,shashankg22,1511950773,,0,1
123,2017-11-29,2017,11,29,22,7gd7xw,Set up TensorFlow with Docker + GPU in Minutes,https://www.reddit.com/r/deeplearning/comments/7gd7xw/set_up_tensorflow_with_docker_gpu_in_minutes/,redaBoumahdi,1511961903,,0,5
124,2017-11-30,2017,11,30,3,7gfh7r,How to Organize YOLO Training Data?,https://www.reddit.com/r/deeplearning/comments/7gfh7r/how_to_organize_yolo_training_data/,Nightsd01,1511980408,"Hi everyone,

YOLO allows you to detect multiple bounding boxes per image segment using anchor boxes.

My question is: the YOLO config contains an array of anchor values, specifically:

```anchors = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]```

How do I make use of these anchor values? How can I organize custom training data into a format where each image segment has, for example, 5 anchor boxes? How do I know which specific anchor box to put a label into?

PS: I've tried researching this topic for a few days now and I've come up blank.",4,0
125,2017-11-30,2017,11,30,4,7gftcr,Understanding deep Convolutional Neural Networks with a practical use-case in Tensorflow and Keras,https://www.reddit.com/r/deeplearning/comments/7gftcr/understanding_deep_convolutional_neural_networks/,ahmedbesbes,1511982986,,0,1
126,2017-11-30,2017,11,30,5,7gg8ll,Building a feedforward neural network,https://www.reddit.com/r/deeplearning/comments/7gg8ll/building_a_feedforward_neural_network/,[deleted],1511986101,[deleted],0,1
127,2017-11-30,2017,11,30,7,7ghew3,Want to try out some DL training and testing. Which gives me least time and effort for a quick test: Keras or Caffe?,https://www.reddit.com/r/deeplearning/comments/7ghew3/want_to_try_out_some_dl_training_and_testing/,bladeofglass,1511995365,"So, with some background in machine learning and neural network, I am looking to just play around with DL using one of the popular frameworks.

The data I have is not natural images. Mine are very special images taken in a lab using some fancy optical instruments. My understanding is that various pre-trained models in Model Zoo of Caffe won't be of help to me. Correct me if I am wrong here.

Which is the easiest and the quickest DL framework I should try out to determine whether it will be useful for classification given my dataset? Caffe? Tensorflow? Keras? 

I only want to do a proof of concept exercise to show whether DL is feasible for my tasks. Don't need to create novel DL architectures at this point in time. If this works out, I am ready to  invest more time and effort either in Caffe or Tensorflow and start messing with custom networks and layers.",3,2
128,2017-11-30,2017,11,30,9,7gi2y0,Amazon launches DeepLens to facilitate developers looking to tinker with AI and enhance deeplearning and computervision skills,https://www.reddit.com/r/deeplearning/comments/7gi2y0/amazon_launches_deeplens_to_facilitate_developers/,thingsthathink,1512000989,,0,4
129,2017-11-30,2017,11,30,14,7gk1g3,Class 24 - Deep Learning Theory: Generalization,https://www.reddit.com/r/deeplearning/comments/7gk1g3/class_24_deep_learning_theory_generalization/,real_charlie_parker,1512019738,,0,2
130,2017-11-30,2017,11,30,22,7gm83f,"A glasses virtual try-on web application where a client-side webgl deep-learning network detects the face, displacement, rotation, lighting then sunglasses are rendered above 8-)",https://www.reddit.com/r/deeplearning/comments/7gm83f/a_glasses_virtual_tryon_web_application_where_a/,__xavier__,1512047494,,0,1
0,2017-12-2,2017,12,2,1,7gw36m,5 Best Deep Learning in Python videos for a Beginner,https://www.reddit.com/r/deeplearning/comments/7gw36m/5_best_deep_learning_in_python_videos_for_a/,sudheeran,1512145700,,0,1
1,2017-12-2,2017,12,2,8,7gz4do,"SF Bay Area devs - Join us on 12/7 for the Unity Evangelists 2017 Blow Out, where recent updates to ML-Agents will be shared and the first ever machine learning community challenge will be announced!",https://www.reddit.com/r/deeplearning/comments/7gz4do/sf_bay_area_devs_join_us_on_127_for_the_unity/,leonchenzhy,1512171959,,0,3
2,2017-12-2,2017,12,2,22,7h2mib,How to use Conv1D and Bidirectional LSTM in keras to do multiclass classification of each timestep?,https://www.reddit.com/r/deeplearning/comments/7h2mib/how_to_use_conv1d_and_bidirectional_lstm_in_keras/,happy_pirate,1512221386,"I am trying to use a Conv1D and Bidirectional LSTM in keras for signal processing, but doing a multiclass classification of each time step.The problem is that even though the shapes used by Conv1D and LSTM are somewhat equivalent:

Conv1D: (batch, length, channels)
LSTM: (batch, timeSteps, features)

The output of the Conv1D is = (length - (kernel_size - 1)/strides), and therefore doesn't match the LSTM shape anymore, even without using MaxPooling1D and Dropout.

To be more specific, my training set X has n samples with 1000 time steps and one channel (n_samples, 1000, 1), and I used LabelEncoder and OneHotEncoder so y has n samples, 1000 time steps and 5 one hot encoded classes (n_samples, 1000, 5).Since one class is much more prevalent than the others (is actually the absence of signal), I am using loss='sparse_categorical_crossentropy', sample_weight_mode=""temporal"" and sample_weight to give a higher weight to time steps containing meaningful classes.
    model = Sequential()
    model.add(Conv1D(128, 3, strides=1, input_shape = (1000, 1), activation = 'relu'))
    model.add(Bidirectional(LSTM(128, return_sequences=True)))
    model.add(TimeDistributed(Dense(5, activation='softmax')))
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'], sample_weight_mode=""temporal"")
    print(model.summary())
When I try to fit the model I get this error message: 
**Error when checking target: expected time_distributed_1 to have shape (None, 998, 1) but got array with shape (100, 1000, 5).**

 Is there ant way to make such neural net work?",2,1
3,2017-12-3,2017,12,3,2,7h3qob,Artificial Intelligence vs Machine Learning vs Deep Learning,https://www.reddit.com/r/deeplearning/comments/7h3qob/artificial_intelligence_vs_machine_learning_vs/,anuj633,1512234048,,0,1
4,2017-12-3,2017,12,3,4,7h4jzn,How can I do voice emulation or voice cloning with deep learning?,https://www.reddit.com/r/deeplearning/comments/7h4jzn/how_can_i_do_voice_emulation_or_voice_cloning/,Oso_de_Oro,1512241732,"Hi all. I recently had an idea to make a text to speech web app using a particular individual's voice just to learn and have fun. Can anyone point me in the right direction on how to learn to clone his voice? I also recently heard about Lyrebird.ai, which is exactly like what I'm trying to do but I can't really find any documentation on how they do voice cloning.",1,2
5,2017-12-3,2017,12,3,8,7h68zg,RNNoise: Learning Noise Suppression with Deep Learning,https://www.reddit.com/r/deeplearning/comments/7h68zg/rnnoise_learning_noise_suppression_with_deep/,psangrene,1512258752,,0,3
6,2017-12-3,2017,12,3,9,7h6k7u,Do the hidden layers represent meaningful classes/groups (e.g. image recognition of sceneries)?,https://www.reddit.com/r/deeplearning/comments/7h6k7u/do_the_hidden_layers_represent_meaningful/,TheSexyDuckling,1512261980,"I have a question about the hidden units in a NN. To start off, Andrew Ng talks about the hidden units in this video (from 3:07 to 5:00) -- https://youtu.be/yV3e8LwWs3U?list=PLBAGcD3siRDguyYYzhVwZ3tLvOyyG5k6K&amp;t=187

&amp;nbsp;

His example is a linear regression problem but let's say I have a classification problem and I give a NN algorithm images of some sceneries. Will the hidden layers represent the types of objects in that image (e.g. tree, rock, sky) or is it just something visually meaningless?

&amp;nbsp;

Cheers!",11,6
7,2017-12-4,2017,12,4,10,7he4c2,[P] Using T-SNE to Visualise how your Deep Model thinks,https://www.reddit.com/r/deeplearning/comments/7he4c2/p_using_tsne_to_visualise_how_your_deep_model/,harvey_slash,1512352149,,0,1
8,2017-12-4,2017,12,4,12,7heqcy,How does one use Hermite polynomials with Stochastic Gradient Descent (SGD)?,https://www.reddit.com/r/deeplearning/comments/7heqcy/how_does_one_use_hermite_polynomials_with/,real_charlie_parker,1512358683,,0,1
9,2017-12-4,2017,12,4,19,7hgkhs,Help with Automatic Speech Recognition for medical audio files.,https://www.reddit.com/r/deeplearning/comments/7hgkhs/help_with_automatic_speech_recognition_for/,Metamyrddin,1512384255,"Hi, I am very new to all this. i have some audio files that I would like to transcribe.  I want to do it from scratch (instead of using API's like Google cloud or Dragon, etc..). Anyone have any suggestions on where and how to begin? From the basics. I looked and a lot of the information I found is rather advanced. Is there a tutorial for beginners that anyone knows about?",5,1
10,2017-12-4,2017,12,4,22,7hh8fb,Automated Caries Detection on Bitewing Radiographs Using Deep CNNs,https://www.reddit.com/r/deeplearning/comments/7hh8fb/automated_caries_detection_on_bitewing/,shashankg22,1512393325,,0,1
11,2017-12-4,2017,12,4,23,7hhjfw,How to train CNN with multiple-labels data ?,https://www.reddit.com/r/deeplearning/comments/7hhjfw/how_to_train_cnn_with_multiplelabels_data/,cestlefeu,1512396690,"Hi everyone, I am trying to train a network on images that contain multiple classes on it (the image can contains a cat and a dog for example). I want my network to output all the classes that it can detect in the image. How can I do that as simple as possible ? I have already watch the YOLO net but I don't think that I can used it for that.

Thanks in advance   ",6,4
12,2017-12-5,2017,12,5,0,7hi6e5,Is GTX1050 4gb sufficient for fast.ai deep learning course?,https://www.reddit.com/r/deeplearning/comments/7hi6e5/is_gtx1050_4gb_sufficient_for_fastai_deep/,stn994,1512402950,,3,0
13,2017-12-5,2017,12,5,1,7hidyr,Tensorflow vs PyTorch for Research,https://www.reddit.com/r/deeplearning/comments/7hidyr/tensorflow_vs_pytorch_for_research/,dsengupta16,1512404793,"I am a fresher in PhD curriculum currently completed my first semester. I want to focus my area of research on computer vision and deep learning. 

There is so much hue and cry as to which framework is the winner. I want to ask a simple question. 

Which should I go with? PyTorch or Tensorflow? 

PyTorch seems more python like. But tensorflow has huge community and lota and lots of tutorials. Mkrwover whenever any new paper comes out, the tensorflow community is fast enough to produce multiple implementations of the paper. Whereas in PyTorch a handful of them comes out that too a bit later. 

I am confused which to invest my time on. 

P.S. I am not so much in love with ""it has to be Pythonic omg"" trend. ",6,8
14,2017-12-5,2017,12,5,21,7hpam6,A Gentle Introduction to Deep Learning Caption Generation Models - Machine Learning Mastery,https://www.reddit.com/r/deeplearning/comments/7hpam6/a_gentle_introduction_to_deep_learning_caption/,dearpetra,1512476147,,0,7
15,2017-12-5,2017,12,5,21,7hpduc,Estimating an Optimal Learning Rate For a Deep Neural Network,https://www.reddit.com/r/deeplearning/comments/7hpduc/estimating_an_optimal_learning_rate_for_a_deep/,polllyyy,1512477325,,0,3
16,2017-12-6,2017,12,6,8,7htmjf,What do you think of my self driving car project? Still working on it!! Will improve/add a lot more features,https://www.reddit.com/r/deeplearning/comments/7htmjf/what_do_you_think_of_my_self_driving_car_project/,smahajan07,1512514985,,4,1
17,2017-12-6,2017,12,6,10,7huepu,Three reasons machine learning models go out of sync,https://www.reddit.com/r/deeplearning/comments/7huepu/three_reasons_machine_learning_models_go_out_of/,ml_i,1512522042,,0,1
18,2017-12-6,2017,12,6,17,7hwue2,PyTorch vs Tensorflow,https://www.reddit.com/r/deeplearning/comments/7hwue2/pytorch_vs_tensorflow/,cloudirec,1512550553,,0,2
19,2017-12-7,2017,12,7,1,7hz5tv,What is Regularization in Machine Learning?,https://www.reddit.com/r/deeplearning/comments/7hz5tv/what_is_regularization_in_machine_learning/,kailashahirwar12,1512577984,,0,4
20,2017-12-7,2017,12,7,3,7i0825,NIPS 2017  Day 2 Highlights,https://www.reddit.com/r/deeplearning/comments/7i0825/nips_2017_day_2_highlights/,e_ameisen,1512586418,,0,2
21,2017-12-7,2017,12,7,7,7i1m7g,What were the biggest obstacles to start deep learning?,https://www.reddit.com/r/deeplearning/comments/7i1m7g/what_were_the_biggest_obstacles_to_start_deep/,o-rka,1512598282,I'm new to deep learning but very interested.  I've been implementing everything in Keras with Tensorflow backend.  My biggest obstacle so far is knowing how many layers to add and how many neurons per layer.  I'm curious to see what other people's opinions are on that and what was the most confusing part about starting to implement neural networks from their academic background.,1,2
22,2017-12-7,2017,12,7,8,7i2992,CUTLASS: Fast Linear Algebra in CUDA C++,https://www.reddit.com/r/deeplearning/comments/7i2992/cutlass_fast_linear_algebra_in_cuda_c/,kerrmudgeon,1512603805,,1,7
23,2017-12-7,2017,12,7,19,7i5kze,How to Prepare a Photo Caption Dataset for Training a Deep Learning Model,https://www.reddit.com/r/deeplearning/comments/7i5kze/how_to_prepare_a_photo_caption_dataset_for/,magneticono,1512643227,,0,1
24,2017-12-7,2017,12,7,23,7i6usq,"On-Demand Webinar  AI Development Using Data Science VMs (DSVM), Deep Learning VMs (DLVM) &amp;amp; Azure Batch AI",https://www.reddit.com/r/deeplearning/comments/7i6usq/ondemand_webinar_ai_development_using_data/,chris_shpak,1512657547,,0,3
25,2017-12-8,2017,12,8,3,7i8di8,NIPS 2017  Day 3 Highlights,https://www.reddit.com/r/deeplearning/comments/7i8di8/nips_2017_day_3_highlights/,e_ameisen,1512670390,,0,3
26,2017-12-8,2017,12,8,3,7i8oat,Deep Learning Fundamentals YouTube playlist,https://www.reddit.com/r/deeplearning/comments/7i8oat/deep_learning_fundamentals_youtube_playlist/,blackHoleDetector,1512672545,"This [Deep Learning Fundamentals YouTube playlist](https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU) covers essential topics in deep learning for beginners. The videos give short, general explanations of deep learning concepts and also show the technical implementation of some of these topics in code using the neural network API, Keras, written in Python. (More Keras-specific video tutorials [here](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL).) 

The playlist is still being developed, with new videos being added regularly. 
Some topics so far include:

- Machine learning overview
- Deep learning overview
- Artificial Neural Networks (ANN)
- Layers in an ANN
- Activation functions
- Training a model
- How a model learns
- Loss functions
- Data sets: train, validation, and test
- Under/overfitting
- Predicting with an ANN
- Regularization
- Fine-tuning/transfer learning
- Data augmentation
- Supervised, unsupervised, &amp; semi-supervised learning
- More...
",2,1
27,2017-12-8,2017,12,8,8,7iade8,Building my own deep learning machine,https://www.reddit.com/r/deeplearning/comments/7iade8/building_my_own_deep_learning_machine/,LolouX,1512687728,"Hi, As it is the first time i am building my own computer, i would need advise and / or confirmation regards the build i want to do (budget is max 2000 euros) :

CPU : Inter Core i7-7700K 

Motherboard : MSI Z270 SLI PLUS

GPU : Gigabyte Nvidia GTX 1080 Ti

Cooling : be quiet ! Dark Rock 3

RAM : Corsaire Vengeance LPX 16 GB (2 x 8GB)

SSD : Samsung - 960 EVO 250GB M.2-2280

HDD : Seagate - FireCuda 2TB 3.5"" 7200RPM 

Case : Deepcool - DUKASE WHV2 ATX Mid Tower Case

Supply : Corsair RM650x 80PLUS Gold
 
So, what do you think about this configuration ? Will the cooling and the supply be enough (those are the main parts i am not confortable with) ?

https://pcpartpicker.com/list/97...

Thanks",6,1
28,2017-12-8,2017,12,8,11,7ibtjw,mini pc for deep learning,https://www.reddit.com/r/deeplearning/comments/7ibtjw/mini_pc_for_deep_learning/,lbcommer,1512701652,"I am looking for a silent and small pc with at least a nvidia 1070 gpu to practice deep learning. I have discovered Zotac mini pcs which are oriented to gaming:

https://www.zotac.com/product/mini_pcs/zbox-e-series/all

Although officially only windows is supported it looks like it is possible to install ubuntu. 

Anyone has used these mini-pc's for deep learning? Do you know other mini-pc alternatives for that use case? ",3,2
29,2017-12-8,2017,12,8,13,7iccid,I7 8650k Or 8700k for two 1080 tis,https://www.reddit.com/r/deeplearning/comments/7iccid/i7_8650k_or_8700k_for_two_1080_tis/,Aklenar,1512706476,I am building a computer mostly for training neural nets. Should I get a i7 8650k (40 lanes) or 8700k (16 lanes) for two 1080 tis. With the latter my 1080 tis will get x16 lanes while the former will allow x8 lanes. Any recommendations? (Different in cost is negligible for me),6,1
30,2017-12-8,2017,12,8,19,7ie365,Crowd-Acting: How to Grow Large-Scale Video Datasets for Deep Learning,https://www.reddit.com/r/deeplearning/comments/7ie365/crowdacting_how_to_grow_largescale_video_datasets/,nahuak,1512727760,,0,2
31,2017-12-9,2017,12,9,5,7ihm59,How OpenMined uses your idle consoles to train the next generation of AI,https://www.reddit.com/r/deeplearning/comments/7ihm59/how_openmined_uses_your_idle_consoles_to_train/,Sig_Luna,1512763888,,0,3
32,2017-12-10,2017,12,10,2,7io7zi,Machine Learning for Art Valuation,https://www.reddit.com/r/deeplearning/comments/7io7zi/machine_learning_for_art_valuation/,Artnome,1512842143,,0,1
33,2017-12-10,2017,12,10,16,7isqa4,RANIK optimizer: Mathematical Optimization for Machine Learning using insights from Physics,https://www.reddit.com/r/deeplearning/comments/7isqa4/ranik_optimizer_mathematical_optimization_for/,akanimax,1512892588,,4,5
34,2017-12-11,2017,12,11,2,7iv3f8,What Deep learning framework would you recommend me to get good at?,https://www.reddit.com/r/deeplearning/comments/7iv3f8/what_deep_learning_framework_would_you_recommend/,GTHell,1512925634,"I've going on and off with Machine Learning and Deep learning for quiet awhile but can't get any grip with it. I know I need to get good at exactly one thing before I need to be a jack of all trade. Just like when I get started with programming, I pick one specific language and try to get good at it and it work. And Now I would like to know which is the most prefer framework for deep learning so I can get a book and start with it.

I really like Andrew Ng's course and other courses but I still prefer book that why I need to know which framework should I get good at. 

Thank for sharing!",12,0
35,2017-12-11,2017,12,11,4,7iwbdy,Need opinion on my first deep learning cum gaming budget build,https://www.reddit.com/r/deeplearning/comments/7iwbdy/need_opinion_on_my_first_deep_learning_cum_gaming/,narudarurarasya,1512935944,"Hello, I am putting up my first DL cum gaming build and not aiming for perfection. It's already a bit over my budget now and I don't want to spend more. 

https://de.pcpartpicker.com/list/PMZ67h

Do I lose anything significant, if I wish to stay with AMD? Please let me know your thoughts.

Thanks &amp; Cheers :)",5,2
36,2017-12-11,2017,12,11,8,7ixqmb,One-shot Learning with Memory-Augmented Neural Networks,https://www.reddit.com/r/deeplearning/comments/7ixqmb/oneshot_learning_with_memoryaugmented_neural/,psangrene,1512948163,,0,2
37,2017-12-11,2017,12,11,20,7j1mo6,Detecting Diseases in Chest X-ray Using Deep Learning,https://www.reddit.com/r/deeplearning/comments/7j1mo6/detecting_diseases_in_chest_xray_using_deep/,shashankg22,1512991684,,0,1
38,2017-12-12,2017,12,12,0,7j2p8p,Quantum Neuron: an elementary building block for machine learning on quantum computers,https://www.reddit.com/r/deeplearning/comments/7j2p8p/quantum_neuron_an_elementary_building_block_for/,pcastonguay,1513004510,,1,6
39,2017-12-12,2017,12,12,0,7j2w2c,I used transfer learning to recreate a scene from the matrix (song overlay should be self-explanatory),https://www.reddit.com/r/deeplearning/comments/7j2w2c/i_used_transfer_learning_to_recreate_a_scene_from/,Diddlydinkbong,1513006318,,12,14
40,2017-12-12,2017,12,12,0,7j327c,December issue of COMPUTER VISION NEWS [links],https://www.reddit.com/r/deeplearning/comments/7j327c/december_issue_of_computer_vision_news_links/,Gletta,1513007921,"Here is the December issue of Computer Vision News, published by RSIP Vision: a 32 pages magazine about Computer Vision, Image Processing, Deep Learning and Artificial Intelligence.
Free subscription at page 32.
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2017December/
and
PDF version ==&gt; http://www.rsipvision.com/computer-vision-news-2017-december-pdf/
Enjoy!
",2,3
41,2017-12-12,2017,12,12,2,7j3ion,"The first episode of our podcast, ""Machine Learning made Known."" Here, Ola, Andrew and Megan have a short interview with our Swiss machine learning engineer, Timo Rohner. He talks about Hilbert, Gdel, and Deep Learning.",https://www.reddit.com/r/deeplearning/comments/7j3ion/the_first_episode_of_our_podcast_machine_learning/,Craftinity,1513011946,,0,5
42,2017-12-12,2017,12,12,8,7j6grn,t-SNE visualization of instagram posts  The Bit Theories,https://www.reddit.com/r/deeplearning/comments/7j6grn/tsne_visualization_of_instagram_posts_the_bit/,farr3l,1513036016,,0,1
43,2017-12-12,2017,12,12,13,7j8eg3,Teaching computers how to draw new and original manga and anime faces with MangaGAN,https://www.reddit.com/r/deeplearning/comments/7j8eg3/teaching_computers_how_to_draw_new_and_original/,unmatchedsock31,1513054615,,0,7
44,2017-12-12,2017,12,12,15,7j8z5f,Generative Adversarial Networks  A Deep Learning Architecture,https://www.reddit.com/r/deeplearning/comments/7j8z5f/generative_adversarial_networks_a_deep_learning/,gautamrbharadwaj,1513061705,,0,4
45,2017-12-12,2017,12,12,19,7j9uje,Capsule Network implementation (with dynamic tensorflow routing loop and tensorboard visualizations),https://www.reddit.com/r/deeplearning/comments/7j9uje/capsule_network_implementation_with_dynamic/,akanimax,1513073556,,0,2
46,2017-12-12,2017,12,12,20,7ja1hc,Detecting Diseases in Chest X-ray Using Deep Learning,https://www.reddit.com/r/deeplearning/comments/7ja1hc/detecting_diseases_in_chest_xray_using_deep/,grey_shirts,1513076565,,0,1
47,2017-12-12,2017,12,12,22,7jannm,How to Find Wally With a Neural Network,https://www.reddit.com/r/deeplearning/comments/7jannm/how_to_find_wally_with_a_neural_network/,thelole,1513084686,,8,8
48,2017-12-13,2017,12,13,4,7jd56r,"A nice, easy to follow tutorial on Capsule Networks based on Sabour, Frosst and Hinton's Paper.",https://www.reddit.com/r/deeplearning/comments/7jd56r/a_nice_easy_to_follow_tutorial_on_capsule/,F4il3d,1513106104,,0,22
49,2017-12-13,2017,12,13,4,7jde5j,"Deep Learning for NLP, advancements and trends in 2017",https://www.reddit.com/r/deeplearning/comments/7jde5j/deep_learning_for_nlp_advancements_and_trends_in/,thesameoldstories,1513108186,,0,3
50,2017-12-13,2017,12,13,6,7jeay3,Fast INT8 Inference for Autonomous Vehicles with TensorRT 3,https://www.reddit.com/r/deeplearning/comments/7jeay3/fast_int8_inference_for_autonomous_vehicles_with/,harrism,1513115683,,0,2
51,2017-12-13,2017,12,13,15,7jhghp,"Christmas Gift: BerryNet 2.0 Available now :) now support movidius, Nest camera... and more for users to build AI applications their way with RPi3",https://www.reddit.com/r/deeplearning/comments/7jhghp/christmas_gift_berrynet_20_available_now_now/,eurekamfc,1513147145,,0,4
52,2017-12-13,2017,12,13,18,7ji16b,"The second episode of our podcast, ""Machine Learning made Known. Michael Jamroz - machine learning engineer talks about image generation with Deep Learning, particularly Generative Adversarial Networks",https://www.reddit.com/r/deeplearning/comments/7ji16b/the_second_episode_of_our_podcast_machine/,Craftinity,1513155647,,0,4
53,2017-12-13,2017,12,13,19,7jifo6,How to Visualize a Deep Learning Neural Network Model in Keras,https://www.reddit.com/r/deeplearning/comments/7jifo6/how_to_visualize_a_deep_learning_neural_network/,jackblun,1513161951,,0,1
54,2017-12-14,2017,12,14,0,7jk009,A Tensor Flow implementation of Capsule Networks Explained by Aurelien Geron,https://www.reddit.com/r/deeplearning/comments/7jk009/a_tensor_flow_implementation_of_capsule_networks/,F4il3d,1513179274,,0,18
55,2017-12-15,2017,12,15,7,7jv3q7,Where to post images to be used for training neural networks?,https://www.reddit.com/r/deeplearning/comments/7jv3q7/where_to_post_images_to_be_used_for_training/,Shumatsu,1513288943,"I have mundane objects surrounding me, working camera in a phone, and some free time. Where should I upload photos to be used for training neural networks?",2,3
56,2017-12-15,2017,12,15,15,7jxxso,Hyperparameter Tuning with Keras Functional API,https://www.reddit.com/r/deeplearning/comments/7jxxso/hyperparameter_tuning_with_keras_functional_api/,wrathofthekoalas,1513318623,"Hi, 

I am working on a problem where in currently I have managed to define the architecture of my neural network which consumes multiple inputs using the Keras functional API. However I haven't been able to tune the hyperparameters like dropout rate, number of neurons in hidden layers etc using either GridSearchCV by scikit-learn or hyperas as both of them don't support the functional model. Any leads on how to go about this ? TIA.",8,2
57,2017-12-16,2017,12,16,0,7k0iy5,AI Weekly 15 Dec 2017,https://www.reddit.com/r/deeplearning/comments/7k0iy5/ai_weekly_15_dec_2017/,TomekB,1513353217,,0,3
58,2017-12-16,2017,12,16,2,7k1624,Deep Learning for Disaster Recovery,https://www.reddit.com/r/deeplearning/comments/7k1624/deep_learning_for_disaster_recovery/,e_ameisen,1513358916,,0,6
59,2017-12-16,2017,12,16,4,7k1tpj,Twitter Sentiment Analysis,https://www.reddit.com/r/deeplearning/comments/7k1tpj/twitter_sentiment_analysis/,kamranjanjua,1513364682,,0,1
60,2017-12-16,2017,12,16,5,7k2kni,A cheat sheet of top online courses for beginners on up,https://www.reddit.com/r/deeplearning/comments/7k2kni/a_cheat_sheet_of_top_online_courses_for_beginners/,bcaulfield,1513371526,,0,1
61,2017-12-16,2017,12,16,6,7k2ti8,"Repository for setting-up cuda-8.0, nvidia-384/387 driver, OpenCV-3.3, ROS Kinetic, Tensorflow1.2.1 maintained for setting-up the step-zero Deep Learning framework (Tensorflow), especially for Robotics application.",https://www.reddit.com/r/deeplearning/comments/7k2ti8/repository_for_settingup_cuda80_nvidia384387/,chahatdeep,1513373798,,0,6
62,2017-12-16,2017,12,16,13,7k4zjc,Bestseller [Udemy 100% Off] 23+ Hours Deep Learning A-Z: Hands-On Artificial Neural Networks Now On SmartyBro For Free,https://www.reddit.com/r/deeplearning/comments/7k4zjc/bestseller_udemy_100_off_23_hours_deep_learning/,DeveloperChoice,1513397638,,0,1
63,2017-12-16,2017,12,16,14,7k5f1z,"TensorFlow implementation of the ""Order-Planning Neural Text Generation From Structured Data"".",https://www.reddit.com/r/deeplearning/comments/7k5f1z/tensorflow_implementation_of_the_orderplanning/,akanimax,1513403436,,0,3
64,2017-12-16,2017,12,16,17,7k61y6,Suggestions on Deep learning based projects,https://www.reddit.com/r/deeplearning/comments/7k61y6/suggestions_on_deep_learning_based_projects/,babycorn24,1513414123,"Hey guys, I need some help in deciding upon taking up a project related to deep learning as a part of my final year of engineering. It needs to be something innovative and not too tough to implement. I'd be highly grateful if anyone could recommend a paper or thesis from the SCOPUS journals.",4,1
65,2017-12-17,2017,12,17,7,7k9vy2,Generating dataset using street view images for commercial use,https://www.reddit.com/r/deeplearning/comments/7k9vy2/generating_dataset_using_street_view_images_for/,ssivri,1513461907,I have a project idea but I'm wondering how can I acquire  street view panoramas without violating terms of use. Anyone came across similar situation ?,1,1
66,2017-12-17,2017,12,17,19,7kd484,Cross-entropy cost function when expected output y is 0.5,https://www.reddit.com/r/deeplearning/comments/7kd484/crossentropy_cost_function_when_expected_output_y/,vincentcent1,1513505777,,3,1
67,2017-12-17,2017,12,17,21,7kdlv5,New YouTube channel on Deep Learning,https://www.reddit.com/r/deeplearning/comments/7kdlv5/new_youtube_channel_on_deep_learning/,tr1pzz,1513514826,Check out my new YouTube channel on Deep Learning (inspired by Siraj &amp; Two Min Papers): https://youtu.be/McgxRxi2Jqo,7,24
68,2017-12-17,2017,12,17,22,7kds9t,Deep Learning for Robotics  Prof. Pieter Abbeel,https://www.reddit.com/r/deeplearning/comments/7kds9t/deep_learning_for_robotics_prof_pieter_abbeel/,[deleted],1513517546,[deleted],0,1
69,2017-12-17,2017,12,17,23,7ke1o6,Difference between noisy ReLUs and Dual Rectified Linear Units.,https://www.reddit.com/r/deeplearning/comments/7ke1o6/difference_between_noisy_relus_and_dual_rectified/,happy_pirate,1513521086,,1,3
70,2017-12-18,2017,12,18,5,7kgco9,"Question about terminology: what are ""activations""?",https://www.reddit.com/r/deeplearning/comments/7kgco9/question_about_terminology_what_are_activations/,puremath369,1513544388,"Just started reading [this](http://www.deeplearningbook.org/contents/intro.html) deep learning book and they used a term which they have not yet defined. Here is the context, they are trying to explain two ways of viewing deep learning, here is the second view (bottom of page 5 on the link I provided):

""Another perspective on deep learning is that depthenables the computer to learn a multistep computer program. Each layer of the representation can be thought of as the state of the computers memory after executing another set of instructions in parallel. Networks with greater depth can execute more instructions in sequence. Sequential instructions oer great power because later instructions can refer back to the results of earlier instructions. According to this view of deep learning, **not all the information in a layers activations** necessarily encodes factors of variation that explain the input.""

I've heard this term a lot, a ""layer's ACTIVATIONS"". What exactly IS a ""layer's activation?
",10,2
71,2017-12-19,2017,12,19,4,7kne5s,Tensorflow and AEM,https://www.reddit.com/r/deeplearning/comments/7kne5s/tensorflow_and_aem/,alseambusher,1513624304,,0,2
72,2017-12-19,2017,12,19,18,7ks9k3,Deep learning,https://www.reddit.com/r/deeplearning/comments/7ks9k3/deep_learning/,HHG123456,1513676388,"I am new to deep learning.I have background in computer networks, electronics programming several languages and have done many projects .where can I start to learn deep learning... I tired the tensorflow series by Sentdex youtube,but i m finding difficulty in following that",15,0
73,2017-12-19,2017,12,19,22,7kt6w2,Recent Discussions on Neuroevolution,https://www.reddit.com/r/deeplearning/comments/7kt6w2/recent_discussions_on_neuroevolution/,gokulbalex,1513689518,,0,5
74,2017-12-19,2017,12,19,23,7ktivv,CapsNet - connection between convolutional and primary capsules layers,https://www.reddit.com/r/deeplearning/comments/7ktivv/capsnet_connection_between_convolutional_and/,z3lazny,1513693240,"Hinton's recent paper (https://arxiv.org/abs/1710.09829) introduces CapsNets. It is unclear to me how the link between the first convolutional layer (ReLU Conv1) and the primary capsules layer (PrimaryCaps) is designed. In implementations I have come across on the web, it seems that we apply convolution again to ReLU Conv1, get 256 feature maps and then resize them to 32 vector maps. So, we would employ convolution to get PrimaryCaps. This seems to contradict information given in the paper [Section 4]:

""Each primary capsule output sees the outputs of all 256  81 Conv1 units whose receptive fields overlap with the location of the center of the capsule.""

The paper suggests that either 1) each element of each local capsule vector is fully-connected to each local unit in ReLU Conv1 or 2) the first element of a capsule vector is connected to units 1:32 of ReLU Conv1, the second element of the capsule is connected to untis 33:64 and so on. It is unclear to me which is the case. In particular, option 1) looks very much like a fully-connected layer.

So which one is it? 1)? 2)? Or am I missing something and the implementation I described earlier is correct? I would appreciate any comments.",2,1
75,2017-12-19,2017,12,19,23,7ktm4d,"Dear DL Researchers, what are your best practices for designing and training GANs.",https://www.reddit.com/r/deeplearning/comments/7ktm4d/dear_dl_researchers_what_are_your_best_practices/,MandirWahiBanaienge,1513694156,It's really difficult to design and train GANs. If you could share some practices you follow when you design and then train GANs.,2,5
76,2017-12-20,2017,12,20,4,7kvrxl,TensorFlow implementation of The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation,https://www.reddit.com/r/deeplearning/comments/7kvrxl/tensorflow_implementation_of_the_one_hundred/,gseif94,1513713344,,0,3
77,2017-12-20,2017,12,20,11,7kyiem,How should one approach getting the Pytorch DCGAN example to work with different sized images? (e.g. 224x224 sized images),https://www.reddit.com/r/deeplearning/comments/7kyiem/how_should_one_approach_getting_the_pytorch_dcgan/,unmatchedsock31,1513738635,,0,1
78,2017-12-20,2017,12,20,20,7l0y2b,A Quick Guide to Identify Twitterbots Using AI,https://www.reddit.com/r/deeplearning/comments/7l0y2b/a_quick_guide_to_identify_twitterbots_using_ai/,shashankg22,1513770986,,0,1
79,2017-12-20,2017,12,20,22,7l1i8p,KL divergence more numerically stable than Cross-entropy?,https://www.reddit.com/r/deeplearning/comments/7l1i8p/kl_divergence_more_numerically_stable_than/,car202,1513778006,"I have a strong feeling that it is for two reasons:

1. In my keras learning, when I used cross-entropy loss function, loss became negative (I suspect it is due to overflow since it cannot be negative mathematically, although I did not check thoroughly). But when I changed loss function to KL divergence, this no longer happened.

2. Intuitively, it divides and subtracts, so less likely to overflow.

Is there any paper on this? I could not find any.

If I am right, why and when do we use cross-entropy loss function over KL divergence?
If I am wrong, why wrong?",4,3
80,2017-12-21,2017,12,21,1,7l2fvp,Examples of Multi_GPU_Model implementation in Keras?,https://www.reddit.com/r/deeplearning/comments/7l2fvp/examples_of_multi_gpu_model_implementation_in/,onmywaytostealyagirl,1513787124,"Hi all, thought I would reach out to the community and see if anyone could point me in the right direction in terms of finding examples of using multi_gpu_model implementation in Keras? Set-up of hardware is 4 TITAN X gpu",1,3
81,2017-12-21,2017,12,21,3,7l3fq0,"NVIDIA DGX STATION - On Sale - $49,900",https://www.reddit.com/r/deeplearning/comments/7l3fq0/nvidia_dgx_station_on_sale_49900/,RetardedChimpanzee,1513795683,,4,10
82,2017-12-21,2017,12,21,6,7l4i9m,"If you need help with computer science, please check out my video I made on Machine Learning! Please Subscribe, it would help me a lot",https://www.reddit.com/r/deeplearning/comments/7l4i9m/if_you_need_help_with_computer_science_please/,DiscoverAI,1513804756,,0,0
83,2017-12-21,2017,12,21,18,7l8fta,Evolving Government: An artificial intelligence just for English,https://www.reddit.com/r/deeplearning/comments/7l8fta/evolving_government_an_artificial_intelligence/,mr_j_b,1513848970,,0,1
84,2017-12-21,2017,12,21,18,7l8h8n,Deep Learning news feed powered by CityFALCON,https://www.reddit.com/r/deeplearning/comments/7l8h8n/deep_learning_news_feed_powered_by_cityfalcon/,mr_j_b,1513849618,,0,1
85,2017-12-21,2017,12,21,23,7l9qcp,Face Recognition : Deep Learning.,https://www.reddit.com/r/deeplearning/comments/7l9qcp/face_recognition_deep_learning/,tiger287,1513866055,"So I have been trying to create a face recognition model that can work on frames from a live Camera. I explored : 

1.Facenet which is based on Open face implementation and research paper Facenet : A Unified Embedding for Face Recognition and Clustering.

2. Face Recognition using Dlib library.

3.Using Resnet152 to train on the custom dataset of faces.

Using all the 3 approaches I am not able to get a good working model for our use-case of a live Camera. Can anyone share any thoughts on what they might have used or any modifications to the above libraries that they have implemented which I can use ? ",8,1
86,2017-12-22,2017,12,22,0,7la27j,Great Deep Learning Achievements Over the Past Year,https://www.reddit.com/r/deeplearning/comments/7la27j/great_deep_learning_achievements_over_the_past/,digitalson,1513869434,,0,7
87,2017-12-22,2017,12,22,12,7lew7d,Deep learning is inspired by the brain...but does brain computation actually run on similar algorithms?,https://www.reddit.com/r/deeplearning/comments/7lew7d/deep_learning_is_inspired_by_the_brainbut_does/,SkaiFox,1513914752,,0,4
88,2017-12-22,2017,12,22,18,7lgina,Deep Learning for the Enterprise,https://www.reddit.com/r/deeplearning/comments/7lgina/deep_learning_for_the_enterprise/,mr_j_b,1513936504,,0,0
89,2017-12-22,2017,12,22,21,7lha62,Deep Learning Made Easy with Deep Cognition,https://www.reddit.com/r/deeplearning/comments/7lha62/deep_learning_made_easy_with_deep_cognition/,jackblun,1513947551,,0,3
90,2017-12-22,2017,12,22,23,7lhlgq,4U GPU server,https://www.reddit.com/r/deeplearning/comments/7lhlgq/4u_gpu_server/,tice_tequila,1513951318,"Good morning, I work for company, which provides cloud services. We plan on building GPU server(s), which will be doing GPU heavy tasks - mostly AI and hopefully mining in spare time.

I know there are many comercial pre-build machines, but to be honest, they are way overpriced. I want to build it myself. Want to fit 4-8 gpus, probably GTX 1080 Ti's reference designs - cooling reasons. The most challenging thing will be finding right MOBO and case. For tasks like this we want to use pci-e x16. So I will probably have to use risers, which are x16 to x16. There are not many mobos, which provide that many x16 slots. :( Do you have any tips, where to start? Any tips for cpu? Thanks

For chassis id like to use something like this: https://www.newegg.com/Product/Product.aspx?item=N82E16811147154

but they are pretty hard to get in Europe, will have to find different one probably.
",3,1
91,2017-12-23,2017,12,23,5,7lk0bd,AI Weekly 22 Dec 2017,https://www.reddit.com/r/deeplearning/comments/7lk0bd/ai_weekly_22_dec_2017/,TomekB,1513974234,,0,4
92,2017-12-23,2017,12,23,19,7lo1ps,"Arraymancer, teaching Nim language digit recognition from scratch [x-post /r/programming/]",https://www.reddit.com/r/deeplearning/comments/7lo1ps/arraymancer_teaching_nim_language_digit/,Karyo_Ten,1514025845,,3,7
93,2017-12-24,2017,12,24,20,7luqm2,feeding variable length words to neural network,https://www.reddit.com/r/deeplearning/comments/7luqm2/feeding_variable_length_words_to_neural_network/,i_bm88,1514115123,How can you feed varying length words to a neural network? There is no structure or context behind the words and they have different lengths.,3,1
94,2017-12-24,2017,12,24,22,7lv3wm,Nvidia changed EULA - no deep learning on geforce gpus in datacenters,https://www.reddit.com/r/deeplearning/comments/7lv3wm/nvidia_changed_eula_no_deep_learning_on_geforce/,l3fth4nd3r,1514121719,,21,25
95,2017-12-25,2017,12,25,22,7m1946,Computer Vision by Andrew Ng,https://www.reddit.com/r/deeplearning/comments/7m1946/computer_vision_by_andrew_ng/,trumtra,1514206859,,0,1
96,2017-12-26,2017,12,26,3,7m2rr2,Deep Learning Surprises and My Implicit Beliefs,https://www.reddit.com/r/deeplearning/comments/7m2rr2/deep_learning_surprises_and_my_implicit_beliefs/,whence1a,1514226537,,0,1
97,2017-12-26,2017,12,26,18,7m6ybt,NASA Deep Learning Program Aims to Ward Off Asteroid Attack,https://www.reddit.com/r/deeplearning/comments/7m6ybt/nasa_deep_learning_program_aims_to_ward_off/,mr_j_b,1514281630,,1,7
98,2017-12-26,2017,12,26,23,7m860l,Properly uninstall CUDA 9.1,https://www.reddit.com/r/deeplearning/comments/7m860l/properly_uninstall_cuda_91/,EnderFuckingWiggin,1514300335,"I installed the newest version of CUDA by accident, not knowing I needed 8.0. I now want to fully uninstall it so I can install the 8.0 version, but can't seem to find a good way to do this (Windows 10). Have any of you dealt with this?",1,2
99,2017-12-27,2017,12,27,5,7ma2f9,Keras Tutorial : Using pre-trained Imagenet models,https://www.reddit.com/r/deeplearning/comments/7ma2f9/keras_tutorial_using_pretrained_imagenet_models/,keghn,1514319738,,0,4
100,2017-12-27,2017,12,27,11,7mc7xq,Pytorch Implementation of Rainbow DQN for RL,https://www.reddit.com/r/deeplearning/comments/7mc7xq/pytorch_implementation_of_rainbow_dqn_for_rl/,hengyuan,1514342117,,0,7
101,2017-12-27,2017,12,27,12,7mchkw,Numericcal - Making Deep Learning Usable on Mobile with ReactiveX &amp; Late Artifact Binding (x-post from r/SideProject),https://www.reddit.com/r/deeplearning/comments/7mchkw/numericcal_making_deep_learning_usable_on_mobile/,radoye,1514345174,,0,1
102,2017-12-27,2017,12,27,14,7md47x,Could you please explain what are hand-crafted feature and deep feature?,https://www.reddit.com/r/deeplearning/comments/7md47x/could_you_please_explain_what_are_handcrafted/,Zulqarnayn_26,1514352759,got it from here http://ieeexplore.ieee.org/document/8051277/,2,1
103,2017-12-27,2017,12,27,17,7mdryp,Visual Analytics: Exploring #KendrickLamar on Instagram,https://www.reddit.com/r/deeplearning/comments/7mdryp/visual_analytics_exploring_kendricklamar_on/,shashankg22,1514362154,,0,1
104,2017-12-27,2017,12,27,17,7mdx4q,Adam - momentum + y (aka. cost) terms.,https://www.reddit.com/r/deeplearning/comments/7mdx4q/adam_momentum_y_aka_cost_terms/,akanimax,1514364552,"I had earlier posted this -&gt; https://www.reddit.com/r/MachineLearning/comments/7isnft/ranik_optimizer_mathematical_optimization_for/

as an update equation for mathematical optimization. It was the Newton-Raphson method for finding roots of an equation. I thought this method mostly applies for minimization in machine learning as cost is always defined as a positive real valued function. But it was pointed out to me that the update equation of newton-raphson method, which is x = x - y / dy_dx, is unstable at local minimas (where dy_dx = 0) since it makes the update burst to infinity.

I kept playing with this equation more since it gave me the smoothest curve for what I had been trying to do -&gt; https://github.com/akanimax/my-deity/blob/master/Scripts/IDEA_2/RANIK%20optimizer.ipynb and, I was firm on the idea that the update equation must include the cost term (the Einstein's space-time analogy: The dimension of cost is connected with all the parameter dimensions).

Eventually, I landed on this update equation, x = x - ((y * dy_dx) / (y + dy_dx2)); dy_dx = derivative of y wrt. x link to code -&gt; https://github.com/akanimax/my-deity/blob/master/Scripts/IDEA_2/RANIK%20optimizer%202.0.ipynb found in last section: ""Equation 2: modified from newton-raphson method"".

To relate this update equation with the title: if we consider the update portion of the equation -&gt; g(x, y) = (y * x) / (y + x2) ; y &gt;= 0 It is quite similar to adam since there is a square gradient term in the denominator and the gradient term in the numerator. This equation doesn't use momentum (running averages) and, the learning_rate is replaced by cost (y).

Now, in Adam, the alpha is initially manually set and is utilised as per the decay equation -&gt; lr_t &lt;- learning_rate * sqrt(1 - beta2t) / (1 - beta1t). WIth the equation that I have mentioned, the hypothesis is that this decay is kind of estimating the cost term itself.

Link to the 3d curve of the g(x, y) function -&gt; https://academo.org/demos/3d-surface-plotter/?expression=(x*y)%2F(x%2B(y*y))&amp;xRange=0%2C+200&amp;yRange=-100%2C+100&amp;resolution=25

Please let me know what you think about this hypothesis and what it's implications are. I would be thankful and highly grateful if you could point me to some more relevant research so that I can move forward with this. Thank you!",0,1
105,2017-12-27,2017,12,27,19,7medl5,Find the difference between human and AI speech,https://www.reddit.com/r/deeplearning/comments/7medl5/find_the_difference_between_human_and_ai_speech/,un_known_name,1514371972,,0,2
106,2017-12-27,2017,12,27,23,7mffml,The promise of AI in audio processing,https://www.reddit.com/r/deeplearning/comments/7mffml/the_promise_of_ai_in_audio_processing/,keghn,1514386372,,1,12
107,2017-12-28,2017,12,28,0,7mfjzc,Essentials of Deep Learning : Introduction to Long Short Term Memory,https://www.reddit.com/r/deeplearning/comments/7mfjzc/essentials_of_deep_learning_introduction_to_long/,[deleted],1514387670,[deleted],0,1
108,2017-12-28,2017,12,28,3,7mgq0y,Why Mention Training Data Size for Transfer Learning?,https://www.reddit.com/r/deeplearning/comments/7mgq0y/why_mention_training_data_size_for_transfer/,schedutron,1514398779,"When performing transfer learning from task A to task B, it's usually said that A should have more data than B, because each example from A is less valuable for B than each example of B itself.

However, isn't transfer learning performed only when we have a pre-trained network for A so that B has ease of learning, since then it already has knowledge of low-level features from A? Because the network is pre-trained, there should be no question for the size of data required to train it. Still, data size is mentioned whenever transfer learning comes up.

Please resolve this confusion and sorry if it's trivial; I'm new to the concept.",3,1
109,2017-12-28,2017,12,28,12,7mjx7y,Visualizing Convolutional Filters from a CNN,https://www.reddit.com/r/deeplearning/comments/7mjx7y/visualizing_convolutional_filters_from_a_cnn/,blackHoleDetector,1514430409,,0,8
110,2017-12-28,2017,12,28,16,7ml9xs,"Why does Faster-RCNN and the like regress x-center, y-center, w, and h instead of ymin, xmin, ymax, and xmax?",https://www.reddit.com/r/deeplearning/comments/7ml9xs/why_does_fasterrcnn_and_the_like_regress_xcenter/,ceekaychng,1514447207,"To be exact, I'm referring to this work[1]. I've read the paper but they don't seems to have explained why it was encoded in this way.

[1]https://arxiv.org/pdf/1506.01497.pdf",2,2
111,2017-12-28,2017,12,28,20,7mlztw,"Our third episode featuring Craftinity's CTO, Mattew Opala. Mattew explains what object detection is, its types and how it might be applied as a solution for different fields.",https://www.reddit.com/r/deeplearning/comments/7mlztw/our_third_episode_featuring_craftinitys_cto/,Craftinity,1514459111,,0,1
112,2017-12-29,2017,12,29,2,7mnw7k,Xavier Initialization Intuition,https://www.reddit.com/r/deeplearning/comments/7mnw7k/xavier_initialization_intuition/,whoisburbansky,1514481385,,2,1
113,2017-12-29,2017,12,29,3,7mohl7,Question: deep learning weather data,https://www.reddit.com/r/deeplearning/comments/7mohl7/question_deep_learning_weather_data/,range_et,1514486741,"I was wondering over the last few days , what would happen if I created a simple rnn and fed it weather data from the past , trained it to the present and then asked it to predict the next day, feeding back the changes (if correct none , if wrong the cost) back in.
Weather systems are chaotic an are not deterministic so would a neural net work with any success?
What if I gave it a range of temperature and humidity to predict to , instead of a single absolute value would the success rate be higher in making feasible weather predictions?",11,1
114,2017-12-29,2017,12,29,6,7mppdg,How a Swedish hacker is using deep learning to find dates on Tinder,https://www.reddit.com/r/deeplearning/comments/7mppdg/how_a_swedish_hacker_is_using_deep_learning_to/,bcaulfield,1514497731,,0,1
115,2017-12-29,2017,12,29,9,7mqjh0,help needed for deep learning computer,https://www.reddit.com/r/deeplearning/comments/7mqjh0/help_needed_for_deep_learning_computer/,wutongsu,1514505691,"Hi, I am trying to build a desktop for research purposes. Nvidia donated two Titan XP. Therefore, I am trying to get everything to assemble the computer. Our budget is a bit flexible, ~3K. This computer is going to be used mainly for process 3D medical image analysis (CT, MRI), we prefer it to be stable. We will use windows for this computer. For deep learning, we are going to use either tenserflow or Matlab. 

After reading many posts, I have generated a list: https://pcpartpicker.com/list/jBBqYr

We do have several must have preferences:
1. since we already have two Titan XP, we need to house both of them
2. This is mainly for research, we will not overclock. Also we prefer Intel core
3. Currently, we will use 2-way SLI, and prefer to have potentials to extend to 4-way SLI

We will need your advice on
1. since we have two titan xp, do we need to build other cooling system other than the CPU cooling?
2. is there anything we need to tweak to avoid any bottleneck in the computer
3. if we purchase everything online, how hard will it be to build from scratch by ourselves? I knew the local Fry's store can do it for us, but not quite sure if they will have every hardware we want. Since we are not expert, we hate to bring the final list to store and then switch things here and there.

Thank you in advance for any helpful comments.
",4,1
116,2017-12-30,2017,12,30,4,7mwcys,What is median of X runs?,https://www.reddit.com/r/deeplearning/comments/7mwcys/what_is_median_of_x_runs/,ericalcaide1,1514575032,"Sorry if the question sounds stupid, but what does it mean: results were computed on a median of 5 runs?

As far as I've seen, it can mean 2 things:

- 5 models were trained, then predicted the probabilities for each example in the test set and they were summed together. Accuracy was calculated for this final sum.

- 5 models were trained. Accuracy was calculated for each one. The median of that results was calculated after that.

If the first one is the correct, then how is the standard deviation calculated?

Which of this option is the correct?",1,1
117,2017-12-30,2017,12,30,5,7mwn16,AI Weekly 29 Dec 2017,https://www.reddit.com/r/deeplearning/comments/7mwn16/ai_weekly_29_dec_2017/,TomekB,1514577669,,0,0
118,2017-12-30,2017,12,30,8,7mxv3r,How are vector sum/subtraction done with word2vec?,https://www.reddit.com/r/deeplearning/comments/7mxv3r/how_are_vector_sumsubtraction_done_with_word2vec/,kookaburro,1514589607,"In the oft quoted example of king-male + female = queen example what is the actual math?

Say king = [k1...kn]
Male = [m1..mn]
Female = [f1..fn]

Is it as simple as k1-m1+f1....?


",1,2
119,2017-12-30,2017,12,30,16,7n0b21,How does one design regularizers such that they match the parameters that generated the data when one has strong priors about the parameters?,https://www.reddit.com/r/deeplearning/comments/7n0b21/how_does_one_design_regularizers_such_that_they/,real_pinocchio,1514618625,,0,2
120,2017-12-30,2017,12,30,18,7n0tgw,Serverless deeplearnning using tensorflow and lambda,https://www.reddit.com/r/deeplearning/comments/7n0tgw/serverless_deeplearnning_using_tensorflow_and/,un_known_name,1514627684,"Serverless is pay per request service. Run predictions or analysis on lambda. 

Full details here :
https://aws.amazon.com/blogs/ai/how-to-deploy-deep-learning-models-with-aws-lambda-and-tensorflow/",0,3
121,2017-12-30,2017,12,30,23,7n1seq,34C3:TUWAT: Deep Learning Blindspots,https://www.reddit.com/r/deeplearning/comments/7n1seq/34c3tuwat_deep_learning_blindspots/,Bhima,1514644042,,0,2
122,2017-12-31,2017,12,31,10,7n5ilk,Help: What do the file contents mean?,https://www.reddit.com/r/deeplearning/comments/7n5ilk/help_what_do_the_file_contents_mean/,templeoftiger,1514682873,"So I am trying to tackle my first project when it comes to computer vision. I read this paper -

http://hi.cs.waseda.ac.jp/~esimo/publications/SimoSerraCVPR2015.pdf

I understood most of it and am trying to replicate what the author did with his dataset:

http://hi.cs.waseda.ac.jp/~esimo/en/data/fashion144k_stylenet/.

When I open the dataset, I see the pictures, a read me, and mat files. In the read me, the author explains the .mat file contents. But when I open the files, the files essentially contain matrices. What I don't understand is how do these files translate to words? Like there is a file with different garment styles, but all it has is numbers (I presume category).

Single File Link where author explains that there are 1352 ""Bags of Words"": https://expirebox.com/download/f4c3089390dc2cef53e08b8ee36a12d8.html

Read Me: https://expirebox.com/download/5d7ff66765e46b5c9c4b7cb50cb2abde.html

I apologize in advance if this question sounds stupid. But any help here would do wonder to my confidence.",1,0
0,2018-1-2,2018,1,2,4,7ngyn0,A Primer On Generative Adversarial Networks,https://www.reddit.com/r/deeplearning/comments/7ngyn0/a_primer_on_generative_adversarial_networks/,psangrene,1514834434,,0,7
1,2018-1-2,2018,1,2,4,7nh1i8,Best online course for python for deep learning?,https://www.reddit.com/r/deeplearning/comments/7nh1i8/best_online_course_for_python_for_deep_learning/,m2bop,1514835222,"Hi.
I'm a psychologist with no significant expertise in mathematics and 
I tried doing the online course on python for deep learning from datacamp.com, however, I felt like I needed some more basic knowledge about Python before I could complete the tasks at that course. Therefore, I jumped into their intro course, which has a focus on data science. Is this the right way to go if I want to be able to code deep learning in python or is there better ways?

Thanks in advance",7,2
2,2018-1-2,2018,1,2,11,7njo04,QA Systems and Deep Learning Technologies  Part 2,https://www.reddit.com/r/deeplearning/comments/7njo04/qa_systems_and_deep_learning_technologies_part_2/,Andrea_01,1514861967,,0,1
3,2018-1-2,2018,1,2,12,7njr0l,QA Systems and Deep Learning Technologies  Part 1,https://www.reddit.com/r/deeplearning/comments/7njr0l/qa_systems_and_deep_learning_technologies_part_1/,Andrea_01,1514862926,,0,1
4,2018-1-3,2018,1,3,0,7nn1kr,What is the computer vision technique used here in DeepGlint CVPR16?,https://www.reddit.com/r/deeplearning/comments/7nn1kr/what_is_the_computer_vision_technique_used_here/,stevofolife,1514906724,"Starting at 0:02 from their video https://www.youtube.com/watch?v=xhp47v5OBXQ - what is the technique used for the bottom left corner ""God's View""? Can anyone link or refer papers relating to the methods they are using here for estimating 3D spatial orientations? I'm having trouble finding relevant papers or using the right keywords to conduct my search.",0,1
5,2018-1-3,2018,1,3,1,7nn9wv,CIFAR: the shape of deep learning,https://www.reddit.com/r/deeplearning/comments/7nn9wv/cifar_the_shape_of_deep_learning/,mwscidata,1514908952,,0,1
6,2018-1-3,2018,1,3,4,7noict,Ontology Building using NLP,https://www.reddit.com/r/deeplearning/comments/7noict/ontology_building_using_nlp/,artificial_intel423,1514919802,Anyone have any recommendations on papers or books that go over ontology extraction from scratch using natural language processing / deep learning? I am trying to learn from the very basics to the more recent and advanced methods. Thanks,2,3
7,2018-1-3,2018,1,3,6,7nps4d,Deep Learning &amp; Art: Neural Style Transfer  An Implementation with Tensorflow in Python,https://www.reddit.com/r/deeplearning/comments/7nps4d/deep_learning_art_neural_style_transfer_an/,SandipanDeyUMBC,1514930385,,0,3
8,2018-1-3,2018,1,3,21,7nu7l5,Mathematical Optimization: simplicity is all you need,https://www.reddit.com/r/deeplearning/comments/7nu7l5/mathematical_optimization_simplicity_is_all_you/,akanimax,1514980869,,0,1
9,2018-1-3,2018,1,3,21,7nubh1,"AI in drug discovery is overhyped: examples from AstraZeneca, Harvard, Stanford and Insilico",https://www.reddit.com/r/deeplearning/comments/7nubh1/ai_in_drug_discovery_is_overhyped_examples_from/,mostafabenh,1514982313,,2,6
10,2018-1-4,2018,1,4,0,7nv8te,Best end-to-end ML/DL pipeline/platform?,https://www.reddit.com/r/deeplearning/comments/7nv8te/best_endtoend_mldl_pipelineplatform/,vladimir_b,1514992542,"What are you guys currently using or planning to use for your end-to-end DL/ML pipelines, especially if you are a startup with minimal resources? The goal of such a platform is to provide scalable, reliable, reproducible, easy-to-use, and automated tools to address the following six-step workflow:

* Manage and explore data
* Train models
* Evaluate models
* Deploy models
* Make predictions
* Monitor predictions

Ideally, a platform would be relatively easy to setup, allow practical data exploration and management, distributed/parallel model training (e.g. hyperparameter tuning), model deployment into docker containers etc.

So far, I've found efforts from https://github.com/databricks/spark-deep-learning, http://pipeline.ai, https://cloud.google.com/ml-engine/, https://eng.uber.com/michelangelo/ and most recently https://aws.amazon.com/sagemaker/
&amp;nbsp;
Anything else I missed? What are your experiences if you are using one of these platforms/architectures? Which one would you recommend and why?",0,1
11,2018-1-4,2018,1,4,2,7nw0v2,Build PC for Deep Learning,https://www.reddit.com/r/deeplearning/comments/7nw0v2/build_pc_for_deep_learning/,papatya2,1514999568,"Trying to prepare PC with ""1080 ti"" for Deep Learning&amp;Python :
""1080 ti""
Intel 8700 K
SSD (240 GB 220s)
1 TB Hard Disc

Windows 10 and Linux Ubuntu 16.04 will be set up together.
Half of hard disc will be for Windows 10.
SSD will have Linux Ubuntu, it will use half of hard disc also. Because half of hard disc will be empty and linux can be use it.
Is this configuration enough or is there any better solution ?
",6,5
12,2018-1-4,2018,1,4,3,7nwpi3,Reverse Image search using CNN features,https://www.reddit.com/r/deeplearning/comments/7nwpi3/reverse_image_search_using_cnn_features/,immortal333,1515005324,,0,3
13,2018-1-4,2018,1,4,8,7nyokl,Deep Learning Approaches Advice for Algorithm Testing.,https://www.reddit.com/r/deeplearning/comments/7nyokl/deep_learning_approaches_advice_for_algorithm/,pixie_laluna,1515021914,"I'm a student, and currently into image processing project and coding using OpenCV. Recently, I watched Sebastian Thrun from Udacity in TedTalks talked about AlphaGo. I was wondering if same approaches can be used in my project.  
  

I'm going to perform color enhancement method for any natural images. And of course, color sampling is a huge task now, I have to prepare condition for each key-color sampling given then also prepare &amp; pick the best enhancement function for it. I was thinking if I could load tons of sample pictures instead, have my system test them against each other, and figure out its own enhancement rules from all testing.  I'm able to do it using OpenCV already.
  
I'm not that familiar with Deep Learning, we don't even have deep learning course at my university, but I'm interested in the idea and ready to learn. I'm not even sure if this can be done or not, but I wonder what kind of approaches should I learn to achieve my goal ? Is Deep Learning --&gt; Neural Network a good start ? In my case, to which method in DeepLearning should I go with ? Any reference / advice will be highly appreciated.
",2,1
14,2018-1-4,2018,1,4,12,7o09f3,[StudySharing] SSD_Keras_ObjectDetection,https://www.reddit.com/r/deeplearning/comments/7o09f3/studysharing_ssd_keras_objectdetection/,jedichien,1515037075,,0,1
15,2018-1-4,2018,1,4,14,7o103i,Keras - Contrib,https://www.reddit.com/r/deeplearning/comments/7o103i/keras_contrib/,tiger287,1515045347,"In the keras contrib repository , for resnet in it's application module there is an extra parameter called as repetitions . Does anyone know what does that mean? 

Here is the GitHub link : 

https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/applications/resnet.py",0,1
16,2018-1-4,2018,1,4,17,7o1nvr,Training An Artificial Neural Network To Sketch From Nature,https://www.reddit.com/r/deeplearning/comments/7o1nvr/training_an_artificial_neural_network_to_sketch/,microic,1515054244,,0,0
17,2018-1-4,2018,1,4,21,7o2rb8,"Deep Learning from basic principles in Python, R and Octave - Part 1",https://www.reddit.com/r/deeplearning/comments/7o2rb8/deep_learning_from_basic_principles_in_python_r/,tvganesh,1515070164,,0,1
18,2018-1-5,2018,1,5,1,7o44xv,Keras Tutorial : Transfer Learning using pre-trained models,https://www.reddit.com/r/deeplearning/comments/7o44xv/keras_tutorial_transfer_learning_using_pretrained/,keghn,1515083736,,0,1
19,2018-1-5,2018,1,5,1,7o49oh,[D] Unsupervised Machine Translation using Deep Learning,https://www.reddit.com/r/deeplearning/comments/7o49oh/d_unsupervised_machine_translation_using_deep/,harvey_slash,1515084823,,0,5
20,2018-1-5,2018,1,5,14,7o93g6,Top 11 Deep Learning and Neural Networks Books,https://www.reddit.com/r/deeplearning/comments/7o93g6/top_11_deep_learning_and_neural_networks_books/,kjahan,1515130090,,0,1
21,2018-1-5,2018,1,5,16,7o9mjs,The New Version Of Tensorflow 1.5.0 Released!,https://www.reddit.com/r/deeplearning/comments/7o9mjs/the_new_version_of_tensorflow_150_released/,sudheeran,1515136829,,0,1
22,2018-1-5,2018,1,5,19,7oaafi,Deep Learning Sharpens Views of Cells and Genes,https://www.reddit.com/r/deeplearning/comments/7oaafi/deep_learning_sharpens_views_of_cells_and_genes/,mr_j_b,1515146536,,0,1
23,2018-1-5,2018,1,5,21,7oavj6,Visual Aesthetics: Judging a photo's quality using AI techniques,https://www.reddit.com/r/deeplearning/comments/7oavj6/visual_aesthetics_judging_a_photos_quality_using/,shashankg22,1515154865,,0,1
24,2018-1-5,2018,1,5,23,7obd8j,How To Utilize Big Data in Logistics,https://www.reddit.com/r/deeplearning/comments/7obd8j/how_to_utilize_big_data_in_logistics/,iremalmila,1515160856,,0,1
25,2018-1-5,2018,1,5,23,7obi13,Best seven books to check out in 2018 for Machine/Deep Learning and Medical Image Computing,https://www.reddit.com/r/deeplearning/comments/7obi13/best_seven_books_to_check_out_in_2018_for/,mreyesag,1515162372,,0,8
26,2018-1-6,2018,1,6,1,7ocbew,"Fake images, deep learning and medical image segmentation - new lit review 17Q4",https://www.reddit.com/r/deeplearning/comments/7ocbew/fake_images_deep_learning_and_medical_image/,JScheinpheld,1515169911,,0,1
27,2018-1-6,2018,1,6,4,7odmzy,AI Weekly 5 Jan 2018,https://www.reddit.com/r/deeplearning/comments/7odmzy/ai_weekly_5_jan_2018/,TomekB,1515180866,,0,5
28,2018-1-7,2018,1,7,2,7okk6s,[D][Help] Need help about a CNN Architecture,https://www.reddit.com/r/deeplearning/comments/7okk6s/dhelp_need_help_about_a_cnn_architecture/,tomuz,1515259964,"Hi guys! Im currently working on making an image ""domain"" recognition CNN.

The CNN have to recognize different domains of products based on the picture of the product.

I've 20 main ""categories"" like clothes, electronics, etc and inside each one have like 15-20 different domains.

My question here is what kind of architecture would you recommend for that task
 - Should I train a big CNN with all domains (arround 350 domains) 
or 
 - Should I train 20 smalls CNN (each one corresponding to each category) and another one to decide in which CNN should look (like if it should look into the ""Clothes"" CNN or ""Cellphones"" CNN).

What do you consideer the best practice in that kind of scenarios?
",5,2
29,2018-1-7,2018,1,7,6,7olwt0,"Want to learn how to make your own CNN/DeepLearning TENSORFLOW model to detect images in just 5 MINUTES? Check this video out, and make sure to SUBSCRIBE for more content. :)",https://www.reddit.com/r/deeplearning/comments/7olwt0/want_to_learn_how_to_make_your_own/,DiscoverAI,1515272419,,0,0
30,2018-1-7,2018,1,7,9,7on6jq,Classifying a Face as Happy/Unhappy and Face Recognition using Deep Convolution Net with Keras in Python,https://www.reddit.com/r/deeplearning/comments/7on6jq/classifying_a_face_as_happyunhappy_and_face/,SandipanDeyUMBC,1515284587,,0,12
31,2018-1-8,2018,1,8,21,7oy79q,Udemy Course: Deep Learning A-Z: Hands-On Artificial Neural Networks is 94% off,https://www.reddit.com/r/deeplearning/comments/7oy79q/udemy_course_deep_learning_az_handson_artificial/,plukucisf,1515414496,,1,8
32,2018-1-9,2018,1,9,9,7p33m4,[P] Deep learning project idea for anyone who likes settlers of catan,https://www.reddit.com/r/deeplearning/comments/7p33m4/p_deep_learning_project_idea_for_anyone_who_likes/,arikr,1515457110,"This is aimed at anyone interested in catan who may be looking for a project idea

1. Use machine learning to discover new optimal catan play strategies. Create alphago zero for catan, and watch what the pro versions do, and turn that into a human readable strategy guide. 

2. Create a catan board setup generator that creates boards with no first/last placement (dis)advantage. The software could generate many possible board/port setup combinations, and then play the (equal strength) bots against each other 100x on each map, and then select all of the maps that result in roughly 25%/25%/25%/25% win ratios for the players in 1st/2nd/3rd/4th position, or 33%/33%/33% for 3 players. Then you could publish a list of board setups that are completely neutral for 3 players, and a separate list that are completely neutral for 4 players.

This may be impossible, but writing this in case it's useful to someone!",0,0
33,2018-1-9,2018,1,9,9,7p3a4b,A simple ConvNet to classify toxic comments with Keras,https://www.reddit.com/r/deeplearning/comments/7p3a4b/a_simple_convnet_to_classify_toxic_comments_with/,sachinrjoglekar,1515458753,,0,3
34,2018-1-9,2018,1,9,14,7p4w6c,What is the input noise variable pz(z) in a GAN?,https://www.reddit.com/r/deeplearning/comments/7p4w6c/what_is_the_input_noise_variable_pzz_in_a_gan/,minnuu,1515474860,I was looking at the task of image translation https://phillipi.github.io/pix2pix/ however I am not able to understand what is the gaussian noise that is fed into the network and why do we require it?,0,1
35,2018-1-9,2018,1,9,14,7p51w0,"The ""Hello World"" Example Of Audio Recognition Using Raw Wav Data As Input",https://www.reddit.com/r/deeplearning/comments/7p51w0/the_hello_world_example_of_audio_recognition/,microic,1515476652,,0,2
36,2018-1-9,2018,1,9,19,7p68im,[P] Deep Learning Book from MIT,https://www.reddit.com/r/deeplearning/comments/7p68im/p_deep_learning_book_from_mit/,liranbh,1515493185,,2,14
37,2018-1-9,2018,1,9,23,7p7fac,Viewing and Creating a .h5 file,https://www.reddit.com/r/deeplearning/comments/7p7fac/viewing_and_creating_a_h5_file/,arjundupa,1515508187,"I recently completed Andrew Ng's online course on Deep Learning and Neural Networks. In it, we used supervised data stored in h5 files to train and test our data. The dataset consisted of just 200 labelled images, and this inspired me to create my own dataset to train a neural network with.

How do I go about creating a .h5 file? How can I view the .h5 files used in the course (I have the files, how can I view how the data in them is stored) so that I can use the same format when creating my own file so that I don't have to change the algorithm?

Any help will be greatly appreciated, thanks in advance. ",1,1
38,2018-1-10,2018,1,10,4,7p9g3l,"To become truly intelligent, machines need a sense of the unknown",https://www.reddit.com/r/deeplearning/comments/7p9g3l/to_become_truly_intelligent_machines_need_a_sense/,rexlow0823,1515525372,,0,2
39,2018-1-10,2018,1,10,4,7p9g73,Colorize black and white pictures - working examples needed,https://www.reddit.com/r/deeplearning/comments/7p9g73/colorize_black_and_white_pictures_working/,bar_n,1515525392,"Hey guys,

I am pretty new at this world so be easy with me :)

I need CNN that know to colorize black and white pictures - so I can ""work"" with the hyper parameters and get some understanding (my final goal is to colorize pictures of flowers so if you know any good dataset its also will be great) 

I searched in the net but got really confused by all the options, I really appreciate if someone could give me some working example of python code (keras\tensorflow) that I can run into the jupyter notebook.

* If there is instruction to prepare I will appreciate that will be detail so I can manage to make it work (as I said I am not such an expert in that world so be easy with me)

Thank you very much ",2,1
40,2018-1-10,2018,1,10,9,7pbq9r,Building Machines that Learn and Think Like People,https://www.reddit.com/r/deeplearning/comments/7pbq9r/building_machines_that_learn_and_think_like_people/,wcarvalho,1515544442,,0,1
41,2018-1-10,2018,1,10,17,7pe64n,Created a simple app to manage deep learning papers on the phone,https://www.reddit.com/r/deeplearning/comments/7pe64n/created_a_simple_app_to_manage_deep_learning/,Benjamin_DL,1515571285,"Hi everyone, I've created a simple app, [PaperShelf](https://play.google.com/store/apps/details?id=com.papers.batyr.papers), that allows you to manage the deep learning papers on the phone (Android). Just thought it might be useful to share.",3,6
42,2018-1-10,2018,1,10,19,7peov1,Anybody looking for a Deep Learning Fundamentals course?,https://www.reddit.com/r/deeplearning/comments/7peov1/anybody_looking_for_a_deep_learning_fundamentals/,bostonrb,1515579195,,0,0
43,2018-1-10,2018,1,10,21,7pfeh6,10 high-quality libraries that are used for artificial intelligence,https://www.reddit.com/r/deeplearning/comments/7pfeh6/10_highquality_libraries_that_are_used_for/,antonshaleynikov,1515589044,,4,0
44,2018-1-11,2018,1,11,0,7pggq1,What is Location Intelligence?,https://www.reddit.com/r/deeplearning/comments/7pggq1/what_is_location_intelligence/,y-emre,1515599815,,0,1
45,2018-1-11,2018,1,11,3,7phegp,"New episode of ""Machine Learning Made Known"" by Radio Craftinity is out! Machine Learning has gone mobile!",https://www.reddit.com/r/deeplearning/comments/7phegp/new_episode_of_machine_learning_made_known_by/,[deleted],1515607632,,0,1
46,2018-1-11,2018,1,11,3,7phikg,"New episode of ""Machine Learning Made Known"" podcast is out! This time, our special guest talks on deploying machine learning on mobile devices!",https://www.reddit.com/r/deeplearning/comments/7phikg/new_episode_of_machine_learning_made_known/,Craftinity,1515608575,,0,8
47,2018-1-11,2018,1,11,8,7pjy7s,Types of CNNs,https://www.reddit.com/r/deeplearning/comments/7pjy7s/types_of_cnns/,artificial_intel423,1515628691,"Are there different ""types"" of CNNs, or is it just based on the combination of layers that make them different?",2,0
48,2018-1-11,2018,1,11,9,7pk2n3,Pre trained image classification models,https://www.reddit.com/r/deeplearning/comments/7pk2n3/pre_trained_image_classification_models/,artificial_intel423,1515629709,Are there any links out there that break down all the existing pre trained image CNNs and highlight how they differ? Ie. Whats the difference between all the 'VGG' pre trained models? What does VGG even mean?,4,0
49,2018-1-11,2018,1,11,9,7pkckc,How transferable are features in deep neural networks?,https://www.reddit.com/r/deeplearning/comments/7pkckc/how_transferable_are_features_in_deep_neural/,lokeshsonii,1515632231,,0,2
50,2018-1-11,2018,1,11,11,7pkqtz,"Is deep learning good for ""creating""?",https://www.reddit.com/r/deeplearning/comments/7pkqtz/is_deep_learning_good_for_creating/,FateRiddle,1515636082,"Hi, I've just watched a tutorial, and all is focusing on recognizing/classification. So it feels like we only use it to ""judge"" things. I'm just curious is deep learning/machine learing good for ""creating""? By creating I mean creating something that meets certain criteria given. ",3,1
51,2018-1-11,2018,1,11,13,7plh67,Anyone interested in Auto-generation of WTO panel report?,https://www.reddit.com/r/deeplearning/comments/7plh67/anyone_interested_in_autogeneration_of_wto_panel/,complectere,1515643455,"Hi there, I am a graduate school student. 

Recently I had known about the RNN which holds its speciality generating sequential data, including writings.

I had learnd WTO rulings so far, and this rule and its jurisdiction is quite predictable.

I'd like to launch a project-group which shares the common interest to learn and develop the model for learning WTO rulings - like train the model with factual relation each WTO dispute case with the Panel report as labelled data(since it includes the jurisdiction whether a party's claim is right and wrong)

As far as I know each region globally has the Moot WTO ruling competition, so we can later on hand in our auto-generated panel report for the competition as a turing test-like trial.

Anyone interested in this task please contact me ro the following please.

syyun@snu.ac.kr

Thx!
",1,3
52,2018-1-11,2018,1,11,21,7pnq05,Custom Optimizer in TensorFlow,https://www.reddit.com/r/deeplearning/comments/7pnq05/custom_optimizer_in_tensorflow/,friscotime,1515673233,,1,4
53,2018-1-11,2018,1,11,23,7pols7,"Deep Learning from first principles in Python, R and Octave - Part 2",https://www.reddit.com/r/deeplearning/comments/7pols7/deep_learning_from_first_principles_in_python_r/,tvganesh,1515682561,,0,1
54,2018-1-12,2018,1,12,2,7ppqa7,Linear Algebra for DL,https://www.reddit.com/r/deeplearning/comments/7ppqa7/linear_algebra_for_dl/,AkashSarda,1515691992,Can you guys tell me how much of Linear Algebra should I revise for Deep Learning and share your useful I insights too?,8,1
55,2018-1-12,2018,1,12,4,7pqg1a,Image storage for classification in Keras,https://www.reddit.com/r/deeplearning/comments/7pqg1a/image_storage_for_classification_in_keras/,artificial_intel423,1515697849,"Is there a preferred / efficient way for storing raw images to be imported for a Keras CNN? I am download around 10k images from websites to a disk and saving as .jpg, but didn't know if there is a different format or what to do this.",3,2
56,2018-1-12,2018,1,12,20,7pvxyj,"Jargon Help, I'm looking for an image classification example, which shows where things are in an image too.",https://www.reddit.com/r/deeplearning/comments/7pvxyj/jargon_help_im_looking_for_an_image/,TopcatTomki,1515755702,"I am searching for some example code in something like keras, that would help me with the following tasks, but I'm not sure exactly what the established jargon for the problem is, any help pointing me where to look would be great.

The problem:

Take a picture of a house, and identify what you see and where. Ie:
Window at x1,y1
Window at x2,y2
Door at x3, y3 roof at... etc.

Its not imge classification, as I want to know several things within the image and its position. Something like a maars facial cascade, but for other features would seemingly do the same idea too.

Thanks for any help.

",5,1
57,2018-1-12,2018,1,12,21,7pwcl5,Deep Dive Into Deep Learning,https://www.reddit.com/r/deeplearning/comments/7pwcl5/deep_dive_into_deep_learning/,dearpetra,1515761161,,0,3
58,2018-1-12,2018,1,12,22,7pwnwa,Deep Learning 101,https://www.reddit.com/r/deeplearning/comments/7pwnwa/deep_learning_101/,jackblun,1515764887,,0,2
59,2018-1-12,2018,1,12,23,7pwy4a,What industries do you think are being the most impacted by AI and deep learning?,https://www.reddit.com/r/deeplearning/comments/7pwy4a/what_industries_do_you_think_are_being_the_most/,teamrework,1515767783,"When we think of AI, initially you think about tech giants like Google, Twitter, Microsoft and so on, but what about other industries? I'm pretty sure most sectors are being impacted through chatbots, AI Assistants, automation and so many other aspects. Here are the areas I can think of, but let me know if you think of more:

Healthcare, Retail, Finance, Advertising, Customer Service, Education, Agriculture &amp; Food, Transport &amp; Travel",3,5
60,2018-1-13,2018,1,13,2,7pyanl,What should I focus on understanding the most to make forming my own algorithms easier?,https://www.reddit.com/r/deeplearning/comments/7pyanl/what_should_i_focus_on_understanding_the_most_to/,Amacei,1515779488,"Im on my last year of high school so I havent gotten any experience in programming which is why the subject seems pretty intimidating to me but Im planning to take lessons which are suitable for people with my experience level
But before that I want to take some advices ",2,1
61,2018-1-13,2018,1,13,3,7pyeu8,Adversarial auto-encoders and text,https://www.reddit.com/r/deeplearning/comments/7pyeu8/adversarial_autoencoders_and_text/,[deleted],1515780447,[deleted],0,1
62,2018-1-13,2018,1,13,4,7pz5jt,AI Weekly 12 Jan 2018,https://www.reddit.com/r/deeplearning/comments/7pz5jt/ai_weekly_12_jan_2018/,TomekB,1515786549,,0,2
63,2018-1-13,2018,1,13,5,7pzb3n,How do I properly use sampled softmax in Tensorflow?,https://www.reddit.com/r/deeplearning/comments/7pzb3n/how_do_i_properly_use_sampled_softmax_in/,the_bored_potato,1515787788,"I'm very new at deep learning, so apology in advance, if this is a stupid question.

I have a dataset of about 250k examples. The examples consist of 130 columns and there are about 1200 classes that need to be classified. I tried training this using a regular softmax, with three hidden layers. It is taking really long, even with a GPU (close to 24 hours). Increasing the minibatch size helped, but not too much (it is currently set to 400). The learning rate is 0.0001, should I increase it a bit, as the training set is very large?

I read that sampled softmax(tf.nn.sampled_softmax_loss) can potentially speed up the training. But I don't understand the signature. So far, I was computing the cost by using the logits from the last hidden layer and labels from my training set. But this method requires me to put in weights and biases. Do I initialize new weights? Why is this needed? Is there a sample source code that implements this?

I would really appreciate any help with this. 
Thanks!",4,1
64,2018-1-13,2018,1,13,5,7pzcj8,Deep learning sharpens views of cells and genes,https://www.reddit.com/r/deeplearning/comments/7pzcj8/deep_learning_sharpens_views_of_cells_and_genes/,allthingsvr,1515788115,,0,6
65,2018-1-13,2018,1,13,15,7q2xfj,3D MNIST Image Classification.,https://www.reddit.com/r/deeplearning/comments/7q2xfj/3d_mnist_image_classification/,shashwataggarwal,1515824903,,0,3
66,2018-1-14,2018,1,14,22,7qbw09,CNN hyperparameter tuning in Keras,https://www.reddit.com/r/deeplearning/comments/7qbw09/cnn_hyperparameter_tuning_in_keras/,artificial_intel423,1515937290,Is there any source code out there or tutorials that specifically talk about how to tune hypers for a CNN used in image classification? How many layers should I do. How wide should I make it. How do I select the filter sizes. Im pretty much just guessing at this point ,2,1
67,2018-1-15,2018,1,15,3,7qdi6d,Design Patterns for Deep Learning Architectures - with Free eBook,https://www.reddit.com/r/deeplearning/comments/7qdi6d/design_patterns_for_deep_learning_architectures/,psangrene,1515953873,,0,10
68,2018-1-15,2018,1,15,9,7qfvzf,"A 'Brief' History of Neural Nets and Deep Learning, Parts 1-4",https://www.reddit.com/r/deeplearning/comments/7qfvzf/a_brief_history_of_neural_nets_and_deep_learning/,dimber-damber,1515975695,"A 'Brief' History of Neural Nets and Deep Learning by Andrey Kurenkov

- [Part 1](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/)
In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets return to popularity with backpropagation in 1986.
 - Prologue: The Deep Learning Tsunami
 - The Centuries Old Machine Learning Algorithm
 - The Folly of False Promises
 - The Thaw of the AI Winter
- [Part 2](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-2/) we will look into several strains of research that made rapid progress following the development of backpropagation and until the late 90s, which we shall see later are the essential foundations of Deep Learning.
 - Neural Nets Gain Vision
 - Neural Nets Go Unsupervised
 - Neural Nets Gain Beliefs
- [Part 3](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-3/)  we will continue to see the swift pace of research in the 90s, and see why neural nets ultimately lost favor much as they did in the late 60s.
 - Neural Nets Make Decisions
 - Neural Nets Get Loopy
 - A New Winter Dawns
- [Part 4](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4/)  we will get to the end of our story and see how deep learning emerged from the slump neural nets found themselves in by the late 90s, and the amazing state of the art results it has achieved since.  
 - The Deep Learning Conspiracy
 - The Importance of Brute Force
 - The Ascendance of Deep Learning
 - Epilogue: state of the art",2,1
69,2018-1-16,2018,1,16,3,7qlqsk,I am trying to understand how to train the Mask R-CNN with my dataset. Can an expert help me out?,https://www.reddit.com/r/deeplearning/comments/7qlqsk/i_am_trying_to_understand_how_to_train_the_mask/,templeoftiger,1516041677,"Looking to train my dataset with the Mask R-CNN Keras implementation proposed here: https://github.com/matterport/Mask_RCNN . I am unsure how to use my dataset to do so. Can someone help me understand:

1. How to load the data?
2. Where to specify the bounding box information. 
3. How to train the complete network with initial weights coming in from COCO. 

Thanks!",2,5
70,2018-1-16,2018,1,16,22,7qsbff,January 2018 issue of COMPUTER VISION NEWS [LINKS],https://www.reddit.com/r/deeplearning/comments/7qsbff/january_2018_issue_of_computer_vision_news_links/,Gletta,1516109556,"Here is the January 2018 issue of Computer Vision News, published by RSIP Vision: a 44 pages magazine about Computer Vision, Image Processing, Deep Learning and Artificial Intelligence. Don't miss the fascinating interview with UBER ATG's head Raquel Urtasun about future cities, transportation and more...
Free subscription at page 43.
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2018January/
and PDF version ==&gt; http://www.rsipvision.com/computer-vision-news-2018-january-pdf/
Enjoy!",0,3
71,2018-1-16,2018,1,16,23,7qsmjv,"Generative Adversarial Networks, an overview",https://www.reddit.com/r/deeplearning/comments/7qsmjv/generative_adversarial_networks_an_overview/,trumtra,1516112778,,0,1
72,2018-1-18,2018,1,18,0,7r1n91,Anybody looking for a course on the fundamentals of deep learning?,https://www.reddit.com/r/deeplearning/comments/7r1n91/anybody_looking_for_a_course_on_the_fundamentals/,bostonrb,1516202407,"My company is an NVIDIA Elite Partner and we're hosting a Deep Learning Fundamentals course on February 13th in Daresbury, Cheshire.

Details of the course content can be found at the link below.

Additionally, if you feel the course would benefit a number of people within your organisation/university, inbox me and we can arrange to deliver the course directly to yourselves.

https://www.eventbrite.co.uk/e/nvidia-deep-learning-fundamentals-with-computer-vision-tickets-41306651306

I'll answer questions in the comments :)",2,0
73,2018-1-18,2018,1,18,12,7r6wyn,"Where can I find the marked voice training data? Urgent, thank you.",https://www.reddit.com/r/deeplearning/comments/7r6wyn/where_can_i_find_the_marked_voice_training_data/,eddi2838,1516246636,"Where can I find the marked voice training data? Urgent, thank you.",3,1
74,2018-1-18,2018,1,18,13,7r73xf,Hacking FaceNet using Adversarial examples,https://www.reddit.com/r/deeplearning/comments/7r73xf/hacking_facenet_using_adversarial_examples/,alseambusher,1516248672,,0,3
75,2018-1-18,2018,1,18,13,7r75m2,The value of Event Sourcing,https://www.reddit.com/r/deeplearning/comments/7r75m2/the_value_of_event_sourcing/,keithmifsud,1516249188,,0,3
76,2018-1-18,2018,1,18,18,7r8p86,[D] Synthetic Data for Video Understanding in Deep Learning,https://www.reddit.com/r/deeplearning/comments/7r8p86/d_synthetic_data_for_video_understanding_in_deep/,nahuak,1516269490,,0,2
77,2018-1-19,2018,1,19,0,7rak9o,"[ASK]Traffic sign recognition with tensorflow, data set and architecture",https://www.reddit.com/r/deeplearning/comments/7rak9o/asktraffic_sign_recognition_with_tensorflow_data/,Minhcht,1516290492,"Recently im working on a sign detection project. With my algorithm, can i locate where the sign is in frame by extracting from the raw image, and even crop it out into single image of that sign, but i cant recognize which sign it is, so i was thinking about using deep learning to solve the problem. This is an example of my data set, which was croped out from the video:

https://imgur.com/GxCnijt

I have about 4000-5000 image like that.

My question is, for this type of problem, what architecture should i use and any advices?",8,2
78,2018-1-19,2018,1,19,4,7rc27q,Deep Learning for Self-Driving Cars (2018 version) - Lecture 1,https://www.reddit.com/r/deeplearning/comments/7rc27q/deep_learning_for_selfdriving_cars_2018_version/,yildiz17,1516302445,,0,1
79,2018-1-19,2018,1,19,7,7rdjt0,Deep Learning and INMARSAT Data [x-post from r/MH370],https://www.reddit.com/r/deeplearning/comments/7rdjt0/deep_learning_and_inmarsat_data_xpost_from_rmh370/,XenonOfArcticus,1516314399,,0,1
80,2018-1-19,2018,1,19,11,7rezzw,"In-depth learning activation function, cost function, depth learning algorithm for solving various cost function?",https://www.reddit.com/r/deeplearning/comments/7rezzw/indepth_learning_activation_function_cost/,eddi2838,1516327459,"how many cost functions in Deep learning ?

Depth learning algorithm for solving various cost function?

There are different activation functions, the cost function have any effect? Then the solution algorithm has any effect?",6,0
81,2018-1-19,2018,1,19,23,7rigzs,Audio Recognition Using Spectrogram As Input,https://www.reddit.com/r/deeplearning/comments/7rigzs/audio_recognition_using_spectrogram_as_input/,microic,1516370404,,0,3
82,2018-1-20,2018,1,20,0,7rj7k6,Deep learning on climate,https://www.reddit.com/r/deeplearning/comments/7rj7k6/deep_learning_on_climate/,angelinux74,1516377153,Has anybody found a paper that is focused on using deep learning for climate forecast? Thanks,1,1
83,2018-1-20,2018,1,20,4,7rkxsn,AI Weekly 19 Jan 2018,https://www.reddit.com/r/deeplearning/comments/7rkxsn/ai_weekly_19_jan_2018/,TomekB,1516391091,,0,1
84,2018-1-20,2018,1,20,5,7rl1sj,Wikipedize text using deep learning,https://www.reddit.com/r/deeplearning/comments/7rl1sj/wikipedize_text_using_deep_learning/,CaptainSlow42,1516392002,"I need to use deep learning to ""Wikipedize"" text. E.g. to provide an article and get tags containing articles's topic. Then I have to select some keywords and assign Wiki links to them. I would be grateful for any reasonable advice regarding available frameworks or approaches. I have about 80 Intel Xeons capacity to train my models, so power is not a barrier.",3,2
85,2018-1-20,2018,1,20,10,7rn7kd,Hand-Gesture Classification using Deep Convolution and Residual Neural Network with Tensorflow / Keras in Python,https://www.reddit.com/r/deeplearning/comments/7rn7kd/handgesture_classification_using_deep_convolution/,SandipanDeyUMBC,1516411531,,2,3
86,2018-1-20,2018,1,20,11,7rnoi5,"Announcing conx, software for Deep Learning",https://www.reddit.com/r/deeplearning/comments/7rnoi5/announcing_conx_software_for_deep_learning/,whimsical_monkey,1516416506,,0,4
87,2018-1-21,2018,1,21,2,7rrmjr,Train an Image Classifier in 3 Minutes Using Tensor Flow and Docker,https://www.reddit.com/r/deeplearning/comments/7rrmjr/train_an_image_classifier_in_3_minutes_using/,tim_macgyver,1516468464,,0,11
88,2018-1-21,2018,1,21,21,7rxe2h,I have two doubts in this: 1) How GANs minimize Jensen Shanon Divergence? 2) Was this paper published as it shows that it was under review?,https://www.reddit.com/r/deeplearning/comments/7rxe2h/i_have_two_doubts_in_this_1_how_gans_minimize/,Ashutosh311297,1516536988,,0,2
89,2018-1-22,2018,1,22,1,7ryobu,Text summarizer,https://www.reddit.com/r/deeplearning/comments/7ryobu/text_summarizer/,happy_pirate,1516552531,"Can anyone help me find working code to this paper.
It is about [Text summarization using unsupervised deep learning](https://www.researchgate.net/publication/309184127_Text_Summarization_Using_Unsupervised_Deep_Learning).

Any help is much appreciated.",1,3
90,2018-1-22,2018,1,22,1,7ryokr,5 tips for Multi-GPU training with Keras,https://www.reddit.com/r/deeplearning/comments/7ryokr/5_tips_for_multigpu_training_with_keras/,datumbox,1516552600,,0,12
91,2018-1-22,2018,1,22,10,7s2a8a,"Semantic Segmentation Suite in TensorFlow. Implement, train, and test new Semantic Segmentation models easily!",https://www.reddit.com/r/deeplearning/comments/7s2a8a/semantic_segmentation_suite_in_tensorflow/,gseif94,1516584910,,0,5
92,2018-1-22,2018,1,22,19,7s4xrr,How to Run Deep Learning Experiments on a Linux Server,https://www.reddit.com/r/deeplearning/comments/7s4xrr/how_to_run_deep_learning_experiments_on_a_linux/,jackblun,1516617374,,0,1
93,2018-1-22,2018,1,22,20,7s54ik,"Scaling Kubernetes to 2,500 Nodes",https://www.reddit.com/r/deeplearning/comments/7s54ik/scaling_kubernetes_to_2500_nodes/,friscotime,1516620064,,0,5
94,2018-1-23,2018,1,23,2,7s78sf,Using high definition satellital images on a CNN,https://www.reddit.com/r/deeplearning/comments/7s78sf/using_high_definition_satellital_images_on_a_cnn/,ivanzez,1516641371,"I'm using a CNN in Keras to classify satellital images of resolution 2000x1500 pixels.

Is there a recommended way of introducing the images to the network? At this moment i'm introducing the images with an input_shape of (300, 300) with 3 channels.

The code i'm using is the following: 


ratio = 0.2
n = 5458
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1/255.,
                                    shear_range=0.2,
                                    zoom_range=0.2,
                                    horizontal_flip=True
                                    )

val_datagen = ImageDataGenerator(rescale=1/255.)

train_generator = train_datagen.flow_from_directory(
        './data/train/',
        target_size=(300, 300),
        batch_size=batch_size,
        class_mode='categorical')

validation_generator = val_datagen.flow_from_directory(
        './data/validation/',
        target_size=(300, 300),
        batch_size=batch_size,
        class_mode='categorical')

model = Sequential()

model.add(Conv2D(32, (3, 3), input_shape=(300, 300, 3), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

epochs = 100
lrate = 0.01
decay = lrate/epochs

sgd = SGD(lr=lrate, momentum=0.95, decay=decay, nesterov=False)
model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])

Is there a better way to introduce the images in the network?",6,5
95,2018-1-23,2018,1,23,5,7s8r3o,Faster R-CNN: Down the rabbit hole of modern object detection,https://www.reddit.com/r/deeplearning/comments/7s8r3o/faster_rcnn_down_the_rabbit_hole_of_modern_object/,minmidinosaur,1516653250,,0,2
96,2018-1-23,2018,1,23,6,7s98zi,Where can I find the new syllabus of the Deep Learning Nanodegree?,https://www.reddit.com/r/deeplearning/comments/7s98zi/where_can_i_find_the_new_syllabus_of_the_deep/,ASamir,1516657194,,2,4
97,2018-1-23,2018,1,23,22,7seicd,Deep Learning and the Artificial Intelligence Revolution: Part 1,https://www.reddit.com/r/deeplearning/comments/7seicd/deep_learning_and_the_artificial_intelligence/,trumtra,1516715598,,0,1
98,2018-1-24,2018,1,24,3,7sgbmj,any better object detection methods that outperforms yolov2?,https://www.reddit.com/r/deeplearning/comments/7sgbmj/any_better_object_detection_methods_that/,chadrick-kwag,1516730823,"I've been searching around for object detection methods for a while.
Noticed that yolov2(or yolo9000) seems to be the best one that I came across so far. By the paper, it says it has outperformed SSD.

Are there any better methods that have outperformed yolov2?
I'm also concerned about speed, so any suggestions related to this would be even better.",1,7
99,2018-1-24,2018,1,24,5,7shbju,[D] Techniques to Generate adversarial data for Deep Learning,https://www.reddit.com/r/deeplearning/comments/7shbju/d_techniques_to_generate_adversarial_data_for/,harvey_slash,1516738424,,0,1
100,2018-1-24,2018,1,24,9,7sjbz4,Could a multi camera input learn how to ref a sport?,https://www.reddit.com/r/deeplearning/comments/7sjbz4/could_a_multi_camera_input_learn_how_to_ref_a/,Wanderson90,1516755138,If we fed it a ton of game footage could it learn how to ref a sport like hockey/soccer/basketball ect? ,3,6
101,2018-1-24,2018,1,24,13,7sktay,How can I improve my image classification model? Any suggestions would be greatly appreciated!,https://www.reddit.com/r/deeplearning/comments/7sktay/how_can_i_improve_my_image_classification_model/,junkwhinger,1516769671,"Hi! I'm currently working on a binary image classification task at work using Keras. I've read some basic CNN references like VGGNet, Inception, Xception, ResNet, and visualization including CAM, Grad-CAM, Guided backpropagation.

The problem I'm working on is to find images that contain anomalous features in an image and mark them with bounding boxes. ResNet50 among other architectures so far shows the best test error so far (not tried any newer models like ResNext or DenseNet). Grad-CAM is used to annotate problematic features.

Could you give me any useful references I can apply to my problem? Thank you very much!

",8,3
102,2018-1-24,2018,1,24,14,7sl3xb,[Visit to the Hinton Lab] The Latest Research After CapsuleUse DNR to Better Understand DNN Classification,https://www.reddit.com/r/deeplearning/comments/7sl3xb/visit_to_the_hinton_lab_the_latest_research_after/,Andrea_01,1516773028,,0,1
103,2018-1-24,2018,1,24,17,7slte8,Can I convert my regular PC into a deep learning one?,https://www.reddit.com/r/deeplearning/comments/7slte8/can_i_convert_my_regular_pc_into_a_deep_learning/,ryanmccauley211,1516784007,"I have a regular PC with linux installed:

Zoostorm Desktop PC AMD A10-7850K 3.7Ghz Quad Core APU 8GB RAM 1TB HDD DVDRW Radeon R7 Graphics mATX Case.

Is it possible and advisable to upgrade this to a deep learning PC? I keep reading that gtx 1080 ti is a good GPU to go for but know little about hardware so I am not sure if I can simply buy one for this PC and what else I would need to do?",7,0
104,2018-1-24,2018,1,24,19,7sm73e,I want to begin phd study in deep learning within 2 years. Any advice will be appreciated.,https://www.reddit.com/r/deeplearning/comments/7sm73e/i_want_to_begin_phd_study_in_deep_learning_within/,newbornlife,1516789598,"My background:
Currently, I am finishing up my master's degree in applied statistics. I did my undergraduate study in biology and economics.

I first heard about deep learning when alphago was on the news. Since then, I was interested in the topic but only got to consume some surface information about it (watching video lectures about it, videos of concepts or following through really simple tutorials on website). But never thought I would dive deeply into it. because, first I am not from any computer science background so my knowledge of computation is very basic.
Second, I am not good at programming. I can code in R,SAS or Python but haven't touched any low level language such as C, C++ etc.

But recently, I am thinking I want to do something truly interests me. Currently, I am finishing up my master thesis on modelling with medical data (oncology) and was planning on applying to the jobs in pharmaceutical industry.

So, this plan has changed, I want to start phd in deep learning within 2 years from now (if this is in any way possible). I am dedicating all my off work hours (for my thesis) reading textbooks about it, watching through all the high quality lecture series available and coding in python.

First, after my master, I want to get a job that I can have some experiences in deep learning (again, I wonder if this is in any way possible) for about 2 years,  studying &amp; strengthening my knowledge on the topic.

I am here if anyone can give just any advice, 

Is this feasible plan?

What kind of programming language should I learn other than 
R and Python?

What kind of low level jobs in deep learning do I have a chance to get after my master?

Just any advice will be appreciated, Thanks 

",2,7
105,2018-1-24,2018,1,24,22,7smyhv,Deep Learning in H2O using R,https://www.reddit.com/r/deeplearning/comments/7smyhv/deep_learning_in_h2o_using_r/,trumtra,1516799374,,0,1
106,2018-1-25,2018,1,25,1,7soci6,[Keras] A thing you should know about Keras if you plan to train a deep learning model on a large datasets,https://www.reddit.com/r/deeplearning/comments/7soci6/keras_a_thing_you_should_know_about_keras_if_you/,databiryani,1516812098,,2,8
107,2018-1-25,2018,1,25,3,7sozuy,It's a very basic CNN. I'm getting accuracy of 67%. Can anyone tell me what modification should be done to the layers or options for better accuracy?,https://www.reddit.com/r/deeplearning/comments/7sozuy/its_a_very_basic_cnn_im_getting_accuracy_of_67/,ItIsOkSuraj,1516817123,,10,0
108,2018-1-25,2018,1,25,4,7spjge,How to solve 90% of NLP problems: a step-by-step guide,https://www.reddit.com/r/deeplearning/comments/7spjge/how_to_solve_90_of_nlp_problems_a_stepbystep_guide/,e_ameisen,1516821316,,0,10
109,2018-1-25,2018,1,25,4,7spoig,Saliency Mapping using Black Box Classifiers - Pytorch,https://www.reddit.com/r/deeplearning/comments/7spoig/saliency_mapping_using_black_box_classifiers/,karanchahal1996,1516822408,,0,1
110,2018-1-25,2018,1,25,23,7swasr,How Deep Learning is Transforming the Future of Technology?,https://www.reddit.com/r/deeplearning/comments/7swasr/how_deep_learning_is_transforming_the_future_of/,y-emre,1516889497,,0,1
111,2018-1-25,2018,1,25,23,7sweq7,15 Deep Learning Open Courses and Tutorials,https://www.reddit.com/r/deeplearning/comments/7sweq7/15_deep_learning_open_courses_and_tutorials/,seanDL_,1516890598,,1,14
112,2018-1-25,2018,1,25,23,7swevc,An open source Deep Learning stack on Kubernetes,https://www.reddit.com/r/deeplearning/comments/7swevc/an_open_source_deep_learning_stack_on_kubernetes/,[deleted],1516890639,,0,1
113,2018-1-26,2018,1,26,1,7sx4qc,[question] Cooperative networks?,https://www.reddit.com/r/deeplearning/comments/7sx4qc/question_cooperative_networks/,davidc9320,1516896856,"Hello deeplearning redditors! 
I was wondering if any of you knew anything about sets of supervised NNs working together cooperatively, thus exchanging information on their task. I you did, it would be really helpful if you could link the articles or webpages on the subject. 
I think GANs could be a starting point, however as far as I know, they work in a competitive way and are used for unsupervised learning.
Thank you in advance :)",2,1
114,2018-1-26,2018,1,26,18,7t3kog,*Job Opportunities* Deep Learning Research Scientist &amp; Research Engineer Positions  Cutting-edge Biometrics Security Firm - London,https://www.reddit.com/r/deeplearning/comments/7t3kog/job_opportunities_deep_learning_research/,WestbournePartnersAI,1516960483,"I am currently working in partnership with a well-funded, cutting-edge Deep Learning and Computer Vision Biometrics firm, who require Deep Learning experts to join their London based R&amp;D team, to work on revolutionizing security, internationally across multiple channels in the Fintech and Financial industries.

Through the use of computer vision and deep learning technology, my client has developed the most powerful and effective biometrics authentication system in the world. The successful hires for these positions will be afforded the opportunity to develop and enhance cutting-edge biometric authentication algorithms, which will contribute towards revolutionizing security as we know it. My client is an alumnus from one of the most prestigious start-up accelerators, and has attracted multi mn investments from previous investors in some of the most successful tech start-ups.

You will have an MSc or PhD from a world-leading university, in a field such as, but not limited to, Deep Learning, Machine Learning or Computer Vision. You will have a broad knowledge of Deep Learning frameworks, techniques and have experience with developing and applying novel Deep Learning algorithms. Experience across CNNs, RNNs and LSTMs is seen to be highly desirable. You will ideally count Python as your expert language, where you have extensive experience developing code using associated Deep Learning frameworks, such as Tensorflow and Keras. However, experts in both C++ and Java will also be considered. A stellar publication record, with acceptance at conferences including NIPS, ICML, ECCV and CVPR etc. would be very highly regarded.

Research Scientist

This position is very research heavy, incorporating lots of innovation, novel side projects (akin to a research lab) and the chance to publish and showcase work. The hire for this role will be an autonomous and innovative individual, who continuously strives to find ground breaking new methods of developing technology. Research has been a key part to my clients success in building the most powerful and effective biometrics authentication system in the world and you will be working to continually improve their flagship product.

Research Engineer

This position heavily revolves around optimisation, improving the accuracy of algorithms and overall efficiency of my clients models. Examples of tasks include decreasing the amount of data required to train their neural nets and fine-tuning hyperparameters. You will be working closely with the research scientists, but the work you will undertake is more applied and closer to the products.

This firm offers competitive salaries and the position represents a remarkable opportunity to join an established yet relatively early stage company, with plans to grow significantly in 2018.

If you would like any further information about this outstanding company, please apply with a CV to my email  D.Bennie@westbourne-partners.com.",2,0
115,2018-1-26,2018,1,26,20,7t41j7,Using Deep Learning to Solve Real World Problems,https://www.reddit.com/r/deeplearning/comments/7t41j7/using_deep_learning_to_solve_real_world_problems/,digitalson,1516967719,,0,4
116,2018-1-27,2018,1,27,0,7t57ab,Dimension Miss-Match in RNN LSTM,https://www.reddit.com/r/deeplearning/comments/7t57ab/dimension_missmatch_in_rnn_lstm/,ragas_,1516980367,"Hi,

I'm trying to run multivariate `lstm`. The code is the following:

`from math import sqrt`
`import numpy as np`
`from matplotlib import pyplot`
`from pandas import read_csv`
`from pandas import DataFrame`
`from pandas import concat`
`import pandas as pd`
`from sklearn.preprocessing import MinMaxScaler`
`from sklearn.preprocessing import LabelEncoder`
`from sklearn.metrics import mean_squared_error`

`import tensorflow as tf`
`import sets`
`from datetime import datetime`
`import random`


`def parse(x):
 return datetime.strptime(x, '%Y %m %d %H')`
`pol_data = pd.read_csv('pollution.csv', sep="";"", parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse) `
`pol_data.fillna(0, inplace=True)`
`pol_data.index.name = 'date'`

`pol_data = pol_data[24:]`

`pol_data.head(5)`
`def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
    n_vars = 1 if type(data) is list else data.shape[1]
    print(n_vars)
    df = DataFrame(data)
    
    cols, names = list(), list()
    print(cols)
    print(names)
    
    
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
   
    
    for i in range(0, n_out):
        cols.append(df.shift(-i))
        if i == 0:
            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
        else:
            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
    
   
    agg = concat(cols, axis=1)
    agg.columns = names
   
    if dropnan:
        agg.dropna(inplace=True)
    return agg`
`values = pol_data.values`

`n_train_hours = 365 * 24`
`train = values[:n_train_hours, :]`
`test = values[n_train_hours:, :]`

`train_X, train_y = train[:, :-1], train[:, -1]`
`test_X, test_y = test[:, :-1], test[:, -1]`

`train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))`
`test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))`
`print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)`

`def generate_one_epoch(batch_size):

    num_batches = int(len(train_X))//batch_size
    
    if batch_size * num_batches &lt; len(train_X):
        num_batches += 1
        
    batch_indices = list(range(num_batches))
    random.shuffle(batch_indices)
    for j in batch_indices:
        
        batch_X = train_X[j * batch_size: (j + 1) * batch_size]
        batch_Y = train_y[j * batch_size: (j + 1) * batch_size]
        yield batch_X, batch_Y`


`lstm_size = 128`
`num_layers = 1`
`num_steps = 1`
`input_size = 8`
`keep_prob = 0.8`
`batch_size = 30`


`learning_rate = tf.placeholder(tf.float32, None, name = 'learning_rate')
inputs = tf.placeholder(tf.float32, [None, num_steps, input_size], name=""inputs"")
targets = tf.placeholder(tf.float32, [None, num_steps], name=""targets"")`


`cells = []
for _ in range(num_layers):
    cell = tf.contrib.rnn.LSTMCell(lstm_size)  # Or LSTMCell(num_units)
    cell = tf.contrib.rnn.DropoutWrapper(
        cell, output_keep_prob=keep_prob)
    cells.append(cell)
cell = tf.contrib.rnn.MultiRNNCell(cells)`


`val, _ = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)
val = tf.transpose(val, [1, 0, 2])
last = tf.gather(val, int(val.get_shape()[0]) - 1, name=""last_lstm_output"")
weight = tf.Variable(tf.truncated_normal([lstm_size, input_size]))
bias = tf.Variable(tf.constant(0.1, shape=[input_size]))
prediction = tf.matmul(last, weight) + bias
loss = tf.reduce_mean(tf.square(prediction - targets))
optimizer = tf.train.RMSPropOptimizer(learning_rate)
minimize = optimizer.minimize(loss)`

`max_epoch = 2
learning_rate = 0.001
with tf.Session() as sess:
    tf.global_variables_initializer().run()
    
    for epoch_step in range(max_epoch):
        for batch_X, batch_y in generate_one_epoch(batch_size):
            train_data_feed = {
                inputs: batch_X, 
                targets: batch_y, 
                learning_rate: learning_rate
            }
            print(batch_X.shape)
            print(batch_y.shape)
            train_loss, _ = sess.run([loss, minimize], train_data_feed)
    saver = tf.train.Saver()
    saver.save(sess, ""your_awesome_model_path_and_name"", global_step=max_epoch_step)`

I'm using this [pollution][1] data.

But I'm getting the following error:

&gt; ValueError: Cannot feed value of shape (30,) for Tensor 'targets:0', which has shape '(?, 1)' 

Can someone please guide me where I'm making the mistake?

Thanks!

https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data
",0,0
117,2018-1-27,2018,1,27,1,7t5son,Speedy Neural Networks for Smart Auto-Cropping of Images,https://www.reddit.com/r/deeplearning/comments/7t5son/speedy_neural_networks_for_smart_autocropping_of/,TommyMundial,1516985352,,0,1
118,2018-1-27,2018,1,27,4,7t727d,GTX 1060 VS GTX 1070,https://www.reddit.com/r/deeplearning/comments/7t727d/gtx_1060_vs_gtx_1070/,WulveriNn,1516995714,"So I am planning to buy a laptop for a computer vision Project and for my subsequent use for kaggle competitions so I am actually kind of confused whether to buy a GTX 1060 laptop  or a 1070 one, so can someone please explain me the difference between the performance concerning the two and is it worth spending 600 dollars extra for a GTX 1070 which might be useful for the long run. Thanks in advance.",13,2
119,2018-1-27,2018,1,27,4,7t72c6,Self-Normalizing Neural Networks Interview with Gunter Klambauer,https://www.reddit.com/r/deeplearning/comments/7t72c6/selfnormalizing_neural_networks_interview_with/,alexmlamb,1516995740,,0,3
120,2018-1-27,2018,1,27,7,7t81xl,AI Weekly 26 Jan 2018,https://www.reddit.com/r/deeplearning/comments/7t81xl/ai_weekly_26_jan_2018/,TomekB,1517004041,,0,2
121,2018-1-27,2018,1,27,9,7t8vdn,Platform for creating neural network in real time. Anyone interested?,https://www.reddit.com/r/deeplearning/comments/7t8vdn/platform_for_creating_neural_network_in_real_time/,kifhan,1517011581,,0,0
122,2018-1-27,2018,1,27,19,7tby6j,How to write some Walt Whitman style poetry using Deep Learning,https://www.reddit.com/r/deeplearning/comments/7tby6j/how_to_write_some_walt_whitman_style_poetry_using/,hackofalltrades89,1517048209,,0,7
123,2018-1-28,2018,1,28,9,7tgscn,Explainable Artificial Intelligence - feature or product,https://www.reddit.com/r/deeplearning/comments/7tgscn/explainable_artificial_intelligence_feature_or/,rondr,1517098770,"There has been a bunch of press and activity around XAI - explainable artificial intelligence- for example, this DARPA grant: https://www.darpa.mil/program/explainable-artificial-intelligence

However, I don't see any companies offering any product to help explain results.
Is that because just no one has XAI working yet?
Or because its a feature not a product?  Would it be conceivable to have an API that called an XAI to layer on top of other results?  ",3,4
124,2018-1-28,2018,1,28,13,7ti89q,Join us on a conversation with Paige Fox about creating DL technologies for discovery and learning. (Bay Area) Her projects include: Dupelganger.com and Francka.org. She also works at Google on integrating machine intelligence technologies into video data infrastructure. Refreshments will be served.,https://www.reddit.com/r/deeplearning/comments/7ti89q/join_us_on_a_conversation_with_paige_fox_about/,sashasheng,1517114900,,0,3
125,2018-1-28,2018,1,28,15,7tirl8,Best way to create your own Dataset,https://www.reddit.com/r/deeplearning/comments/7tirl8/best_way_to_create_your_own_dataset/,Js_bagel,1517121944,"Hello, so I am trying to create a dataset to predict Weather phenomena, I'm using Pandas to read the file, and Sklearn to program a result. However I feel that my dataset is terrible. I am using Excel to turn my file into a CSV, any tips on how I can format my data? I'm new to creating datasets so any tips are appreciated. ",4,0
126,2018-1-28,2018,1,28,18,7tj9vu,Approach for transferlearning with small image input size,https://www.reddit.com/r/deeplearning/comments/7tj9vu/approach_for_transferlearning_with_small_image/,aenbacka,1517130221,"Hello,

I am working with the Inception V3 model in Keras, and trying to use transfer learning on my own custom dataset. The images in my dataset are significantly smaller than the size originally used for training Inception (64x64 versus 224x244). I have considered to pad the images, i.e., create a solid color border around the 64x64 area in order to make all input images 224x224. Is this practise correct, or will it introduce bias issues when predicting on images without such border? Any information would be greatly appreciated.",0,1
127,2018-1-29,2018,1,29,1,7tl0y9,Dynamic action recognition,https://www.reddit.com/r/deeplearning/comments/7tl0y9/dynamic_action_recognition/,ItIsOkSuraj,1517155310,"I've developed a CNN which provides me a decent accuracy of 80%, which basically classifies Humans and vehicles, now I need to classify if it's a human, if it's walking, sitting, talking (Normal behaviour) or hitting another one, Falling down (Abnormal behaviour).
Can anyone tell me where to start?
(I have no idea how to train a system using video data)",3,1
128,2018-1-29,2018,1,29,11,7tp7ms,How to Implement Neural Networks with TensorFlow,https://www.reddit.com/r/deeplearning/comments/7tp7ms/how_to_implement_neural_networks_with_tensorflow/,Andrea_01,1517193520,,0,1
129,2018-1-29,2018,1,29,18,7tr7nr,Can anyone suggest me a good tutorial/video to learn Convolutional neural networks from scratch?. I want to code Convolutional neural networks in python without using any framework. Suggestions are welcome.,https://www.reddit.com/r/deeplearning/comments/7tr7nr/can_anyone_suggest_me_a_good_tutorialvideo_to/,kailashahirwar12,1517218491,Can anyone suggest me a good tutorial/video to learn Convolutional neural networks from scratch?. I want to code Convolutional neural networks in python without using any framework. Suggestions are welcome.,5,3
130,2018-1-29,2018,1,29,19,7treli,Powering Artificial Intelligence with the Worlds Best Ethernet Solutions,https://www.reddit.com/r/deeplearning/comments/7treli/powering_artificial_intelligence_with_the_worlds/,-SPOF,1517221297,,0,0
131,2018-1-29,2018,1,29,21,7trzf7,Google Colab Free GPU Tutorial,https://www.reddit.com/r/deeplearning/comments/7trzf7/google_colab_free_gpu_tutorial/,deeplearningturkey,1517229129,,7,17
132,2018-1-29,2018,1,29,23,7tsgtv,An open source Deep Learning / Machine Learning stack on Kubernetes,https://www.reddit.com/r/deeplearning/comments/7tsgtv/an_open_source_deep_learning_machine_learning/,mmourafiq,1517234431,,0,3
133,2018-1-29,2018,1,29,23,7tsqck,"The next episode of ""Machine Learning Made Known"" has been released. Machine Learning engineer Michael Bigaj speaks about using visualization in ML.",https://www.reddit.com/r/deeplearning/comments/7tsqck/the_next_episode_of_machine_learning_made_known/,Craftinity,1517237068,,0,2
134,2018-1-30,2018,1,30,2,7ttp28,Dictionary Learning,https://www.reddit.com/r/deeplearning/comments/7ttp28/dictionary_learning/,Mondestrasz,1517245290,Was there any decent paper recently concerning learning of dictionaries? (sparse coding),0,1
135,2018-1-30,2018,1,30,5,7tv5t0,How we made music using Neural Networks,https://www.reddit.com/r/deeplearning/comments/7tv5t0/how_we_made_music_using_neural_networks/,AleksandrTavgen,1517256790,"My name is Aleksandr Tavgen and I work as a Software Architect in Playtech. I have always loved playing. When I was younger, I mostly played with LEGOs, but these days, my toys are slightly more complex. 

Here is our journey working with Magenta and TensorFlow

https://medium.com/@ATavgen/how-we-made-music-using-neural-networks-449a62b8a332",0,3
136,2018-1-30,2018,1,30,13,7tyiqm,Neural Network Algorithms - Learn How To Train ANN,https://www.reddit.com/r/deeplearning/comments/7tyiqm/neural_network_algorithms_learn_how_to_train_ann/,psangrene,1517286975,,0,1
137,2018-1-30,2018,1,30,17,7tzq9n,Why we need a better learning algorithm than Backpropagation in Deep Learning,https://www.reddit.com/r/deeplearning/comments/7tzq9n/why_we_need_a_better_learning_algorithm_than/,kailashahirwar12,1517302324,,2,1
138,2018-1-30,2018,1,30,19,7u013u,Deep Learning &amp;amp; Computer Vision in the Microsoft Azure Cloud,https://www.reddit.com/r/deeplearning/comments/7u013u/deep_learning_amp_computer_vision_in_the/,chris_shpak,1517306772,,0,3
139,2018-1-30,2018,1,30,20,7u0dsm,Why is Address Verification Important for Your Business?,https://www.reddit.com/r/deeplearning/comments/7u0dsm/why_is_address_verification_important_for_your/,y-emre,1517311698,,0,0
140,2018-1-31,2018,1,31,1,7u25r6,"Deep Learning from first principles in Python, R and Octave  Part 3",https://www.reddit.com/r/deeplearning/comments/7u25r6/deep_learning_from_first_principles_in_python_r/,tvganesh,1517329409,,0,1
141,2018-1-31,2018,1,31,6,7u4feq,Deep Learning for Self-Driving Cars (2018 version) - Lecture 1 and 5,https://www.reddit.com/r/deeplearning/comments/7u4feq/deep_learning_for_selfdriving_cars_2018_version/,artificialbrainxyz,1517347298,,0,1
142,2018-1-31,2018,1,31,14,7u7qhv,"In the next 100 days, EU GDPR regulations can make AI illegal in Europe",https://www.reddit.com/r/deeplearning/comments/7u7qhv/in_the_next_100_days_eu_gdpr_regulations_can_make/,analyticsindiamag,1517377349,,4,0
143,2018-1-31,2018,1,31,22,7u9zsq,Pre-built PC for deep learning (X-Post from r/suggestapc),https://www.reddit.com/r/deeplearning/comments/7u9zsq/prebuilt_pc_for_deep_learning_xpost_from/,not_so_tufte,1517406546,"I was looking to build a box for doing deep learning, but with GPU prices so high right now, I've read that getting a pre-built will probably be the cheaper option. I have a $2000 budget and was looking at these two options on  NewEgg:

* [iBUYPOWER Desktop Computer NE730KACi, Intel Core i7 7th Gen 7700K (4.20 GHz), 32 GB DDR4, 1 TB HDD, 480 GB SSD, NVIDIA GeForce GTX 1080 ](https://www.newegg.com/Product/Product.aspx?Item=N82E16883227767)
* [iBUYPOWER Battlebox Ultimate Desktop Computer NE8410Ki, Intel Core i7 8th Gen 8700K (3.70 GHz), 16 GB DDR4, 2 TB HDD, 240 GB SSD, NVIDIA GeForce GTX 1080 Ti ](https://www.newegg.com/Product/Product.aspx?Item=N82E16883227780)

Curious to know whether people would suggest one over the other -- particularly, whether the higher RAM in the first model would be advantageous? Seems like it would, but it might be offset by the GTX 1080 Ti (vs. 1080) in the second. 

Totally open to building, as well -- just don't know if I can do it with this budget.",1,7
144,2018-1-31,2018,1,31,23,7ua44m,"I created a new subreddit to watch and discuss the development of content-generation and media synthesizing AI, especially for the areas of GANs and style transfer",https://www.reddit.com/r/deeplearning/comments/7ua44m/i_created_a_new_subreddit_to_watch_and_discuss/,Yuli-Ban,1517407689,,0,7
145,2018-1-31,2018,1,31,23,7ua9rf,Sparse Classification,https://www.reddit.com/r/deeplearning/comments/7ua9rf/sparse_classification/,artificial_intel423,1517409161,"Im working on a toy problem where Im trying to build a DL classifier to predict whether or not a user query is a product search or a general question.

I have a dataset with a bunch of example searches [ie. dog toys, Apple TV]
And I also have another source with a bunch of general questions [how to hook up hdmi cord]

Unfortunately I DO NOT have an entity recognition system to tag products. 

I built an LSTM and got 98% accuracy with a loss of 0.04 on the validation but when I predict a couple examples it always is wrong. 

The dataset is 70k searches and 30k questions. I used weight priors in the Keras model but it doesnt help. 

Any suggestions?",1,7
0,2018-2-1,2018,2,1,10,7ufaf2,Intuitive and practical guide for building neural networks from scratch: Using perceptrons to solve university acceptance problem,https://www.reddit.com/r/deeplearning/comments/7ufaf2/intuitive_and_practical_guide_for_building_neural/,hackintoshrao,1517450321,,0,4
1,2018-2-1,2018,2,1,19,7uhvb5,Detecting cancer with neural networks fast and easy,https://www.reddit.com/r/deeplearning/comments/7uhvb5/detecting_cancer_with_neural_networks_fast_and/,roman-kh,1517481034,,0,9
2,2018-2-1,2018,2,1,23,7uj9na,Hearing AI: Getting Started with Deep Learning for Audio on Azure,https://www.reddit.com/r/deeplearning/comments/7uj9na/hearing_ai_getting_started_with_deep_learning_for/,friscotime,1517497120,,0,2
3,2018-2-2,2018,2,2,8,7umxno,Anyone knows a open-source deep / machine learning for sentiment analysis.,https://www.reddit.com/r/deeplearning/comments/7umxno/anyone_knows_a_opensource_deep_machine_learning/,YahooGuys,1517526751,[removed],0,1
4,2018-2-2,2018,2,2,11,7uo5yg,A Case Study of Deep Metric Embedding,https://www.reddit.com/r/deeplearning/comments/7uo5yg/a_case_study_of_deep_metric_embedding/,databas,1517538568,,0,8
5,2018-2-2,2018,2,2,17,7uq2wp,LSTM for time series forecasting with H20.ai,https://www.reddit.com/r/deeplearning/comments/7uq2wp/lstm_for_time_series_forecasting_with_h20ai/,padfootedHighlander,1517561837,"I want to implement a time-series prediction model using LSTMs like the one mentioned here: https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/

The model works pretty well using a similar Keras code above, though I want to implement the same using H20.ai

This [documentation here on H2O Deep Water](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/deep-learning.html) says ""The H2O Deep Water project supports CNNs and **RNNs** though third-party integrations of other deep learning libraries such as TensorFlow, Caffe and MXNet."". Though there are no demos for the same. 

In this conversation here in Jan '16 on ['Recurrent Neural Networks in H2O for time series prediction?'](https://groups.google.com/forum/#!topic/h2ostream/qU2FezMCyW8), they say it hasn't been implemented yet.

Any advice or links to similar implementations on H2O would be deeply appreciated  
Thank You",2,1
6,2018-2-2,2018,2,2,22,7ur9pb,Understanding Learning Rates and How It Improves Performance in Deep Learning,https://www.reddit.com/r/deeplearning/comments/7ur9pb/understanding_learning_rates_and_how_it_improves/,chris_shpak,1517577985,,2,8
7,2018-2-3,2018,2,3,4,7utrgb,AI Weekly 2 Feb 2018,https://www.reddit.com/r/deeplearning/comments/7utrgb/ai_weekly_2_feb_2018/,TomekB,1517599309,,0,3
8,2018-2-3,2018,2,3,8,7uvivb,Is it a good idea to switch from Pytorch to TensorFlow Eager?,https://www.reddit.com/r/deeplearning/comments/7uvivb/is_it_a_good_idea_to_switch_from_pytorch_to/,real_charlie_parker,1517613995,,8,7
9,2018-2-4,2018,2,4,6,7v22l8,Opening TensorFlow .pb model,https://www.reddit.com/r/deeplearning/comments/7v22l8/opening_tensorflow_pb_model/,[deleted],1517691754,[deleted],0,1
10,2018-2-4,2018,2,4,22,7v6nir,"A DL version of HSTracker (i.e. ""watching"" a video card game)",https://www.reddit.com/r/deeplearning/comments/7v6nir/a_dl_version_of_hstracker_ie_watching_a_video/,giantgrothe,1517750057,"NOTE: I have only minimal experience with DL but have been writing code for 20+ years - I am *very* interested in learning more about DL and thought the following might be a fun pet project for me.

I have video recordings of hundreds of games of [Hearthstone](https://playhearthstone.com/en-us/). [typical gameplay](https://www.youtube.com/watch?v=4W_LdRIWN_g).

I thought it would fun to see if, using only the video as input, I could build a DNN that would automatically tell me which player played which card, in order, throughout the game.

I realize that in many ways this is a straightforward object detection problem which doesn't require DL. The cards played by both players are clearly displayed (upper-left for the opponent, lower-right for the current player). But it *could* though... right? Also, there is a lot of other information embedded in the video: which creatures attacked other creatures, the specific damage done, which spells were played and their targets, etc.

[HSTracker](https://hsdecktracker.net) already does some of the above by injecting into the Hearthstone process and monitoring it from within. But again, I think it would be a fun way for me way to jump into DL.

Input: video file

Output: detailed gameplay information

I can easily obtain graphics of each card. Also, it would be fine to start with only a limited set of cards (e.g. the same deck played against each other).

So... where would you suggest I start? A CNN that takes in each frame of the video and predicts which card(s) are visible, etc.?

TIA
",4,2
11,2018-2-5,2018,2,5,6,7v9kfg,"Pre Crime Comes 2 ""Life"" ?!",https://www.reddit.com/r/deeplearning/comments/7v9kfg/pre_crime_comes_2_life/,HouseOfOZz,1517778117,https://twitter.com/Wicked_Mercy/status/960241763444289538?ref_src=twcamp%5Eshare%7Ctwsrc%5Em5%7Ctwgr%5Eemail%7Ctwcon%5E7046%7Ctwterm%5E1 ,0,0
12,2018-2-5,2018,2,5,8,7valxe,Installation of CUDA Toolkit on Linux A short guideline for installation of CUDA Toolkit 9.1 on Ubuntu 17.10,https://www.reddit.com/r/deeplearning/comments/7valxe/installation_of_cuda_toolkit_on_linux_a_short/,Y4Rv1K,1517787521,,0,3
13,2018-2-5,2018,2,5,17,7vdevg,Logo detection using Apache MXNet,https://www.reddit.com/r/deeplearning/comments/7vdevg/logo_detection_using_apache_mxnet/,digitalson,1517818768,,0,2
14,2018-2-5,2018,2,5,17,7vdju4,Has anyone worked with 512x512 images for classification?,https://www.reddit.com/r/deeplearning/comments/7vdju4/has_anyone_worked_with_512x512_images_for/,bhargava27,1517820875,"I was successful in training 224x224 images using densenets. My images are mostly chest X Rays (approx 100k images). I was able to get an AUC of 0.9 but when I train with 512X512 images using the same densenets the network is over fitting and wasn't able to learn as good as 224 images. My AUC dropped to 0.85.
Any suggestions on how I can improve the training on bigger images or is it still a big challenge in AI/ML?",5,6
15,2018-2-6,2018,2,6,0,7vfnq3,February issue of COMPUTER VISION NEWS [LINKS],https://www.reddit.com/r/deeplearning/comments/7vfnq3/february_issue_of_computer_vision_news_links/,Gletta,1517846198,"Here is the February 2018 issue of Computer Vision News, published by RSIP Vision: a 36-pages magazine about Computer Vision, Image Processing, Deep Learning and Artificial Intelligence. Don't miss the fascinating interview with Professor Roy Davies, one of the pioneers of our field. Free subscription at page 36.
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2018February/
and
PDF version ==&gt; http://www.rsipvision.com/computer-vision-news-2018-february-pdf/
Enjoy!",0,4
16,2018-2-6,2018,2,6,6,7vibzv,Finding a deep learning job after completing the Udacity Deep Learning nanodegree,https://www.reddit.com/r/deeplearning/comments/7vibzv/finding_a_deep_learning_job_after_completing_the/,itsmeomarj,1517867536,Hello. My name is Omar. I very recently completed the Udacity Deep Learning Nanodegree that they recently added to their list of Nanodegrees. I want to go out and start looking for a Junior Deep Learning Scientist position. Do anyone have any advice they can give me on how to go about looking for a deep learning job or things to look out for. I would really appreciate it.,7,6
17,2018-2-6,2018,2,6,8,7vj2or, From Artificial Intelligence to Machine Learning &amp; Deep Learning,https://www.reddit.com/r/deeplearning/comments/7vj2or/_from_artificial_intelligence_to_machine/,AhmedGadFCIT,1517873750,,0,1
18,2018-2-6,2018,2,6,15,7vlg3k,Convolutional Neural Networks For All | Part I  Towards Data Science,https://www.reddit.com/r/deeplearning/comments/7vlg3k/convolutional_neural_networks_for_all_part_i/,pmz,1517898020,,0,6
19,2018-2-6,2018,2,6,16,7vls3v,Deep Learning summary for 2017: Machine Perception Developments,https://www.reddit.com/r/deeplearning/comments/7vls3v/deep_learning_summary_for_2017_machine_perception/,pmz,1517902540,,0,1
20,2018-2-6,2018,2,6,20,7vmt24,"This technology, called RadIO, is freely available for anyone (https://github.com/analysiscenter/radio). And while it doesnt represent a magical cancer detection button, it will almost certainly save lives.",https://www.reddit.com/r/deeplearning/comments/7vmt24/this_technology_called_radio_is_freely_available/,roman-kh,1517917642,,0,1
21,2018-2-6,2018,2,6,21,7vmwmu,"Understanding AI, Machine Learning, and Deep Learning",https://www.reddit.com/r/deeplearning/comments/7vmwmu/understanding_ai_machine_learning_and_deep/,chris_shpak,1517918935,,0,1
22,2018-2-6,2018,2,6,21,7vn1fx,Face recognition.,https://www.reddit.com/r/deeplearning/comments/7vn1fx/face_recognition/,parthiv9,1517920639,"Hey I know the basic understanding of neural networks.
I want to prepare face detection by my own.
So where should I start and which data set should I use ?",4,1
23,2018-2-7,2018,2,7,3,7vpiu7,"The human brain has roughly 100bn neurones, with each connecting to up to roughly 1000 neighbours - how do current neural networks compare to this?",https://www.reddit.com/r/deeplearning/comments/7vpiu7/the_human_brain_has_roughly_100bn_neurones_with/,FIREATWlLL,1517942689,Title.,7,2
24,2018-2-7,2018,2,7,12,7vt7y6,Is regularisation needed If I have more than 10B samples?,https://www.reddit.com/r/deeplearning/comments/7vt7y6/is_regularisation_needed_if_i_have_more_than_10b/,[deleted],1517974052,[deleted],0,1
25,2018-2-7,2018,2,7,12,7vtaet,Is regularization needed if I have a lot of data (&gt;10B samples),https://www.reddit.com/r/deeplearning/comments/7vtaet/is_regularization_needed_if_i_have_a_lot_of_data/,pythomad,1517974709,"Hello, I am working on a computer vision problem and I have a metric ton of data so I was thinking not to apply regularization (l2, dropout,etc..) as the model would never see the same sample twice, Should I do that or not, If so why?
,thank you",3,5
26,2018-2-7,2018,2,7,17,7vumri,Visual Feature Attribution Using Wasserstein GANs (with Python and Pytorch),https://www.reddit.com/r/deeplearning/comments/7vumri/visual_feature_attribution_using_wasserstein_gans/,[deleted],1517990912,[deleted],0,1
27,2018-2-7,2018,2,7,19,7vva0m,Neural Spelling Corrections and the Importance of Accuracy,https://www.reddit.com/r/deeplearning/comments/7vva0m/neural_spelling_corrections_and_the_importance_of/,chris_shpak,1518000352,,0,5
28,2018-2-7,2018,2,7,19,7vvasb,Video recognition,https://www.reddit.com/r/deeplearning/comments/7vvasb/video_recognition/,ItIsOkSuraj,1518000632,"Can anybody give some ideas to dig for video recognition? Let's say we've to classify a human walking or jumping. Training a model using static images won't work. 

P.s. Please tell me about the layers of CNN which I should use and why.",6,2
29,2018-2-7,2018,2,7,21,7vvt19,5 Fantastic Practical Machine Learning Resources,https://www.reddit.com/r/deeplearning/comments/7vvt19/5_fantastic_practical_machine_learning_resources/,trumtra,1518007166,,0,1
30,2018-2-7,2018,2,7,21,7vvwki,Internet of Things and Data Visualization,https://www.reddit.com/r/deeplearning/comments/7vvwki/internet_of_things_and_data_visualization/,y-emre,1518008296,,0,1
31,2018-2-8,2018,2,8,8,7w0909,Broken screen detection help!,https://www.reddit.com/r/deeplearning/comments/7w0909/broken_screen_detection_help/,lokeshsonii,1518044420,"I wassolving a problem recently for an insurance company inwhich I have to build a model to classify a Phone screen into broken or non brokenfollowed bytempered vs screen glass classification. I have triedlot of fine tuning with different architectures but it seems that the models are Biased towards one class I spite of the training data containing equal no of classes. As both the classes are very identical.

Can you please help me out?
Im attaching training data link
https://www.dropbox.com/sh/7vt0fdpawzj3znm/AABQPT7BDGyjC105HBj0aJZqa?dl=0

Thankyou so very much",12,1
32,2018-2-8,2018,2,8,11,7w1hvr,"Noob ?: Difference between &gt;= ""level"", and deep learning",https://www.reddit.com/r/deeplearning/comments/7w1hvr/noob_difference_between_level_and_deep_learning/,DelosBoard2052,1518055866,"Apologies, complete noob, not even sure what to search to get this answer, but - I want to understand the following:

In the example where I want to have a chatbot, for example, understand what a ""cold"" temperature is, vs a ""hot"" temperature, standard programming is easy.  After I use NLTK (for example) and REs to determine that the respondent is stating a temperature value, it is very easy to simply use a comparison, if t &lt; 60, for example (F obviously), then it is ""cold"".  If t &gt; 80 then it is ""hot"", else it's ""comfortable"".  But how can I NOT do this with deep learning.  How do I train a neural net (say I'm using TensorFlow or SciKit Learn?) to know this distinction without setting a simple if/then/else comparison?

Thanks for your help and patience.
",3,0
33,2018-2-8,2018,2,8,14,7w2njt,Can DL write an efficient sorting algorithm?,https://www.reddit.com/r/deeplearning/comments/7w2njt/can_dl_write_an_efficient_sorting_algorithm/,xiaodai,1518068001,"I have a stat background but no DL experience. I  have been thinking about whether DL can be applied to write a sorting algorithm for integers. 

I think I can supply alot of arrays and define all the atomic operations you can apply to an array e.g. swaps, and atomic operations you can apply to the elements e.g. &lt;&lt; &gt;&gt; etc. Then I ""guide"" the DL machine towards sorted array i.e. reward it if it makes the array more sorted; I also reward if it does it faster than quicksort or for getting close to quicksort for performance.  Over time it should have developed an algorithms that can sort arrays fast.

Do you think it will work? ",6,0
34,2018-2-8,2018,2,8,16,7w3abc,Suggestions for a neural network that contains groupings?,https://www.reddit.com/r/deeplearning/comments/7w3abc/suggestions_for_a_neural_network_that_contains/,NeuralNetHelp,1518076345,"Ive been working on a fairly complex problem, but may have reached the lowest MSE possible for the data, but need it lower. I thought I would ask the community for any ideas as some additional experience could help.

The inputs:

Y = A (relatively small) continuous variable.  EX: -15.000 to 15.000 but some outliers going much higher (~50).

X= *multiple properties referring to an object
*multiple properties referring to a replacement for that object
*multiple properties referring to nearby objects as well as their distance to the initial object/replacement.

There are ~65-70 features, no categoricals for the groups (but could be), properties can be the same if the objects are the same, and over 10k rows. 

With Keras (sequential/dense), the data is input all together. The 3 layers start large ( ~250 and fan down to ~100. Relu function, Adam or Nadam optimizer, uniform kernel initiation, 50 batch size and the lowest MSE (0.5-7) at 250-350 epochs. Only ~50% of the predicted Y are near the actual Y. 

It could potentially be getting caught in a minima, which I am not sure just yet how to fix exactly as I havent had a problem like this previously.  Would definitely be glad to hear any suggestions the community has. 

Edit: Should also mention that different parameters don't affect the MSE or custom accuracy much. ",6,1
35,2018-2-8,2018,2,8,20,7w48ne,How to learn Deep Learning in 6 months,https://www.reddit.com/r/deeplearning/comments/7w48ne/how_to_learn_deep_learning_in_6_months/,petrwilson,1518090372,,7,12
36,2018-2-8,2018,2,8,21,7w4g29,Deep Learning for Sentiment Classification,https://www.reddit.com/r/deeplearning/comments/7w4g29/deep_learning_for_sentiment_classification/,janemoz,1518092993,,0,1
37,2018-2-9,2018,2,9,15,7wbqri,NOOB: What should my loss graph look like if I have a low number layers?,https://www.reddit.com/r/deeplearning/comments/7wbqri/noob_what_should_my_loss_graph_look_like_if_i/,pythomad,1518159445,"I know If I have too many layers the graph should display the loss decreasing then bouncing back up, but my loss graph looks like [this](https://imgur.com/a/DcWXK) 
what does that mean?
,thank you",5,3
38,2018-2-9,2018,2,9,20,7wcwqs,Predicting Cancer Type With KNIME Deep Learning and Keras,https://www.reddit.com/r/deeplearning/comments/7wcwqs/predicting_cancer_type_with_knime_deep_learning/,chris_shpak,1518176843,,0,1
39,2018-2-9,2018,2,9,21,7wd3x5,Fast.ai Lesson 1 on Google Colab (Free GPU),https://www.reddit.com/r/deeplearning/comments/7wd3x5/fastai_lesson_1_on_google_colab_free_gpu/,polllyyy,1518179343,,1,12
40,2018-2-9,2018,2,9,21,7wd7e5,My Journey into Deep Learning,https://www.reddit.com/r/deeplearning/comments/7wd7e5/my_journey_into_deep_learning/,chris_shpak,1518180476,,0,1
41,2018-2-9,2018,2,9,23,7wduxy,Where to start for Text Summarizer,https://www.reddit.com/r/deeplearning/comments/7wduxy/where_to_start_for_text_summarizer/,atulsingh0,1518187410,I have to design a text Summarizer tool in Python/NLP/DL but need some guidance there. I have started with Standford course CS224d. Please add what else I have to study or look into for being able to develop this tool. ,3,1
42,2018-2-10,2018,2,10,2,7weugz,Deep learning technology is now being used to put Nic Cage in every movie,https://www.reddit.com/r/deeplearning/comments/7weugz/deep_learning_technology_is_now_being_used_to_put/,zemcunha,1518195853,,0,1
43,2018-2-10,2018,2,10,2,7wf26g,AI Weekly 9 Feb 2018,https://www.reddit.com/r/deeplearning/comments/7wf26g/ai_weekly_9_feb_2018/,TomekB,1518197583,,0,1
44,2018-2-10,2018,2,10,9,7whwd9,"Loss hovers around 0.7, then jumps to 500,000+ once every epoch. Not on the same training sample either.",https://www.reddit.com/r/deeplearning/comments/7whwd9/loss_hovers_around_07_then_jumps_to_500000_once/,bonbonbaron,1518221975,"I'm implementing the YOLO network in Tensorflow (not the same network as Darkflow). The input data all makes sense, so... any idea what could be causing this???",1,2
45,2018-2-10,2018,2,10,18,7wkj4o,Testing the correctiveness of my ML Engine,https://www.reddit.com/r/deeplearning/comments/7wkj4o/testing_the_correctiveness_of_my_ml_engine/,el_drone,1518255048,"
Im learning about ML engines and testing them. I had a few questions on how to go about doing that. I have an ML engine which recommend what movies based on my list of recently watched movies.

My Questions, does anyone know any resources that would help me learn how to:

1. Test the correctiveness of my engine
2. How to train the model

Im more interested in #1

Essentially the workflow is:
[List of recently watched videos] &gt; [ML Engine] &gt; [Recommended Videos]

Resources or examples in python would be very helpful ",0,0
46,2018-2-10,2018,2,10,23,7wlsl4,f1score values goes to nan for few classes,https://www.reddit.com/r/deeplearning/comments/7wlsl4/f1score_values_goes_to_nan_for_few_classes/,harshadeepg27,1518273895,"input samples = (1044552, 17, 100)
output samples = (1044552,17, 10) 

using tensorflow - dynamic rnn - LSTM cell - with the below parameters:

word_dim= 100
sentence_length = 17
class_size = 10
rnn_size = 80
num_layers = 2
batch_size = 16
epoch = 500
lr = 0.0000001
decay = lr/epoch

the f1score it return is : 
[c1, c2, c3, c4, c5, c6, c7 , c8, c9 , c10] = 
[1, 0.99, 0.89, 0.98, 0.97,nan,nan,nan,nan,nan] .

AS you can see, the last four classes accuracy as in f1score is returning nan. 

could somebody tell me why this is happening. 

I have tried with different batch size, learning rate, rnn size but it still recurs and I dont why.
",2,1
47,2018-2-11,2018,2,11,0,7wlzzl,New course Practical Deep Learning with Keras and Python (x-post r/learnmachinelearning),https://www.reddit.com/r/deeplearning/comments/7wlzzl/new_course_practical_deep_learning_with_keras_and/,recluzestudy,1518276112,"Hi all,

I have just created a new course on Udemy called, ""Practical Deep Learning with Keras and Python"". This course tries to cover the gap left by many deep learning courses -- applying the models on non-toy examples. In my time as a university teacher teaching Machine Learning, I have repeatedly seen students come up to me and ask me why they are getting ""shape mismatch"" issues and how to prepare their data to feed to deep models. I have tried to cover the ""why"" of the concepts that starters struggle with (and not cover the whole deep learning curriculum for which there are already quite a few great courses.)

If you are new to deep learning and need a soft introduction, this might be a good place to start. If you have already taken a theory course and want to know how to use this amazing tool Keras, you only have to spend about 3 hours on this course. I sincerely believe this will be worth your time.

This is for complete newbies (either to ML/DL or to Keras). If you have had experience before (and are not struggling), it would not be worth your time.

Use this coupon for a discounted price of $12.99: https://www.udemy.com/practical-deep-learning-with-keras/?couponCode=REDDIT-QU-OFF

Hope you like it.",2,9
48,2018-2-13,2018,2,13,0,7x1bc5,Best Website/Online Resource for beginning to program in deep learning?,https://www.reddit.com/r/deeplearning/comments/7x1bc5/best_websiteonline_resource_for_beginning_to/,rjolayolay,1518448002,"I am incredibly interested in AI and Deep Learning, but have no programming experience, besides about an hour of python courses through codeacademy. I want to eventually be able to program machines for deep learning, but I dont know where to start. What is the best roadmap for me to end up coding deep learning programs? Best free online courses? Best paid? Is there a single resource or website that I could go to to find all of the cutting edge work being done in the field?

Thanks.",12,5
49,2018-2-13,2018,2,13,1,7x1srs,Microsoft Releases MMLSpark v0.11 for Multi-GPU Distributed Training of Deep Networks,https://www.reddit.com/r/deeplearning/comments/7x1srs/microsoft_releases_mmlspark_v011_for_multigpu/,mhamilton723,1518452112,,0,5
50,2018-2-13,2018,2,13,1,7x1wpr,New Course - Deep Learning: The Big Picture,https://www.reddit.com/r/deeplearning/comments/7x1wpr/new_course_deep_learning_the_big_picture/,hoekrb,1518452996,,0,1
51,2018-2-13,2018,2,13,1,7x1za1,Deep Learning: Going Deeper toward Meaningful Patterns in Complex Data,https://www.reddit.com/r/deeplearning/comments/7x1za1/deep_learning_going_deeper_toward_meaningful/,ritwik_g,1518453572,,1,7
52,2018-2-13,2018,2,13,2,7x2a7x,Extraction of unique faces in a video,https://www.reddit.com/r/deeplearning/comments/7x2a7x/extraction_of_unique_faces_in_a_video/,WulveriNn,1518455919,"Hey there everyone, I am working on a project that needs to identify the number of unique people in a video. Is there any other approach that you people have used to identify these unique people In a video? Please let me know and thanks in advance.",1,1
53,2018-2-13,2018,2,13,2,7x2j86,GPUs in Google Kubernetes Engine now available in beta,https://www.reddit.com/r/deeplearning/comments/7x2j86/gpus_in_google_kubernetes_engine_now_available_in/,mindprince,1518457854,,0,3
54,2018-2-13,2018,2,13,2,7x2lqk,Pytorch implementation of [A simple neural network module for relational reasoning](https://arxiv.org/pdf/1706.01427.pdf) for the CLEVR dataset probably suffering with overfitting.,https://www.reddit.com/r/deeplearning/comments/7x2lqk/pytorch_implementation_of_a_simple_neural_network/,[deleted],1518458374,[deleted],0,1
55,2018-2-13,2018,2,13,3,7x2pbx,PyTorch implementation of (A simple neural network module for relational reasoning)[https://arxiv.org/abs/1706.01427],https://www.reddit.com/r/deeplearning/comments/7x2pbx/pytorch_implementation_of_a_simple_neural_network/,[deleted],1518459162,[deleted],0,1
56,2018-2-13,2018,2,13,3,7x2sf0,Pytorch implementation of A simple neural network for relational reasoning suffering from probable over-fitting. Need Help.,https://www.reddit.com/r/deeplearning/comments/7x2sf0/pytorch_implementation_of_a_simple_neural_network/,rrud,1518459812,"I have implemented the above paper for both SOC (able to achieve stated results, not a publicly available dataset) and CLEVR. But I am facing the following issue with CLEVR, my training accuracy keeps on increasing but my validation stops improving after reaching ~50% under first 10 epochs. My implementation can be found [here](https://github.com/saharudra/relational_network). The paper can be found [here](https://arxiv.org/abs/1706.01427)

Any help in resolving this will be appreciated.
",2,3
57,2018-2-13,2018,2,13,4,7x3c5z,Bounding box,https://www.reddit.com/r/deeplearning/comments/7x3c5z/bounding_box/,gmaggess,1518464158,"Gurus,

I'm looking for a way to automate my image annotation. I have recorded a video of the same object with a black background. I've split the video into separate frames / images and now I want to create a bounding box around this object and annotate it with a label that I have provided. Using RectLabel is not an option since it's quite labor intensive.

Does anyone know a simple way to do it? Any help is appreciated.",4,1
58,2018-2-13,2018,2,13,12,7x6hdl,Interspeech 2017 Series | Acoustic Model for Speech Recognition Technology,https://www.reddit.com/r/deeplearning/comments/7x6hdl/interspeech_2017_series_acoustic_model_for_speech/,Andrea_01,1518491783,,0,1
59,2018-2-13,2018,2,13,21,7x93si,"How I Shipped a Neural Network on iOS with CoreML, PyTorch, and React Native",https://www.reddit.com/r/deeplearning/comments/7x93si/how_i_shipped_a_neural_network_on_ios_with_coreml/,semi23,1518525663,,2,5
60,2018-2-13,2018,2,13,23,7x9nlv,Evolution of Location Intelligence Tools,https://www.reddit.com/r/deeplearning/comments/7x9nlv/evolution_of_location_intelligence_tools/,y-emre,1518531382,,0,2
61,2018-2-14,2018,2,14,9,7xe5qo,Deep Learning Meets DSP: OFDM Signal Detection,https://www.reddit.com/r/deeplearning/comments/7xe5qo/deep_learning_meets_dsp_ofdm_signal_detection/,k3blu3,1518568957,,0,6
62,2018-2-14,2018,2,14,19,7xh56q,Learn Data Science  Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/7xh56q/learn_data_science_deep_learning_in_python/,loneisthere,1518604551,,2,6
63,2018-2-14,2018,2,14,20,7xhghr,"ICYMI: Recent Microsoft AI Updates, Including in Custom Speech Recognition, Voice Output, and Video Indexing",https://www.reddit.com/r/deeplearning/comments/7xhghr/icymi_recent_microsoft_ai_updates_including_in/,chris_shpak,1518608917,,0,2
64,2018-2-14,2018,2,14,21,7xhk8x,A Basic Recipe for Machine Learning,https://www.reddit.com/r/deeplearning/comments/7xhk8x/a_basic_recipe_for_machine_learning/,jackblun,1518610257,,0,2
65,2018-2-14,2018,2,14,22,7xi015,Building a Toy Detector with Tensorflow Object Detection API,https://www.reddit.com/r/deeplearning/comments/7xi015/building_a_toy_detector_with_tensorflow_object/,magneticono,1518615154,,0,1
66,2018-2-15,2018,2,15,5,7xkv6y,Online mooc for a beginner,https://www.reddit.com/r/deeplearning/comments/7xkv6y/online_mooc_for_a_beginner/,vipul115,1518638728,"I recently was introduced to machine learning. After 1-2 months of its study, I have decided to get into deep learning. As you can tell, I have inchoate understanding of it. I've tensorflow is the biggest library but also quite complex. On the other hand keras and pytorch are simpler but have limited functionalities. Can you suggest any good online course to DL from? Also, which library should i go for? I am an undergraduate in my 3rd year and I plan to enter the field of artificial intelligence.  
Thank you",5,5
67,2018-2-15,2018,2,15,11,7xn98d,VAE question,https://www.reddit.com/r/deeplearning/comments/7xn98d/vae_question/,Hungryham,1518660306,Can Variational Autoencoders (VAE) take as input continuous variables?,3,2
68,2018-2-15,2018,2,15,18,7xpb2w,Combining CNN and LSTMs to achieve Spatial and Temporal Learning,https://www.reddit.com/r/deeplearning/comments/7xpb2w/combining_cnn_and_lstms_to_achieve_spatial_and/,foreigner90,1518687295,"CNNs, by principle, are translation invariant. To learn emerging patterns where the relative positions of the items in a 2D space are important, CNN would perform poorly.

Problem: A 2D grid of sensors triggered by some series of events X (like human movement), over time t. Nearby sensors have similar patterns.
Objective: To predict an event happening in time t+1, for each sensor, while retaining position information of each sensor in the grid. So basically sensors in one part of the grid learn different patterns compared to sensors in another part of the grid.

Possible Solution: Use CNN to extract grid features and feed it to LSTM + fully connected output layer to predict value for each sensor, at time t+1.

Any intuitions on how to make this work? Max pooling is one of the reasons why CNNs achieve translation invariance, and this would also result in loss of localisation information for each sensor. ",4,9
69,2018-2-15,2018,2,15,20,7xpsey,How Chatbots Are Learning Emotions Using Deep Learning,https://www.reddit.com/r/deeplearning/comments/7xpsey/how_chatbots_are_learning_emotions_using_deep/,digitalson,1518694480,,0,2
70,2018-2-15,2018,2,15,20,7xpv16,Any good tutorial on this?,https://www.reddit.com/r/deeplearning/comments/7xpv16/any_good_tutorial_on_this/,pinkman61,1518695505,,0,3
71,2018-2-16,2018,2,16,0,7xr53j,Is there any reason to weight features that have a higher correlation to the label in a neural net?,https://www.reddit.com/r/deeplearning/comments/7xr53j/is_there_any_reason_to_weight_features_that_have/,[deleted],1518709156,[deleted],0,1
72,2018-2-16,2018,2,16,0,7xr7j5,Is there any reason to weight features that have a higher correlation to the label in a neural net?,https://www.reddit.com/r/deeplearning/comments/7xr7j5/is_there_any_reason_to_weight_features_that_have/,JustinQueeber,1518709754,"I am using a dataset I have collected of many temporal indicators that have been studied to correlate with the direction and trend of stock prices and am feeding them into an LSTM.

Some of these features correlate far more closely than others to the stock price trends, and some also take high values when they are indicating a very important and rare large change in the stock price.

Would it be any benefit to compute the correlation between each individual feature and the output labels, and then somehow have these features weighted accordingly to give more/less of an influence in the NN? I have come across [this study](https://www.google.ie/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://arxiv.org/pdf/1101.4918&amp;ved=2ahUKEwjhs5qf6KfZAhUhI8AKHalAAsYQFjAAegQIDxAB&amp;usg=AOvVaw0kfyhXZTrvIiyJD_losqJj) of using their proposed Correlation Aided Neural Network to do so, but I have also seen conflicting opinions with the usual ""neural networks are magic boxes and this weighting of the features would eventually be embedded through backprop"".

I do somewhat agree to this, as backpropagation is ultimately computing the weights at each feature input wrt the loss.

What are your opinions? Is there any need to weight features according to how well they correlate to the labels, prior to feeding them into the network?",1,1
73,2018-2-16,2018,2,16,2,7xrzwd,ARM Launches Project Trillium To Boost AI Machine Learning On Smartphones,https://www.reddit.com/r/deeplearning/comments/7xrzwd/arm_launches_project_trillium_to_boost_ai_machine/,keghn,1518716189,,0,6
74,2018-2-16,2018,2,16,2,7xs60f,Is it possible to use pix2pix for converting hand drawn shapes (with wavy edges) to straight-edge shapes?,https://www.reddit.com/r/deeplearning/comments/7xs60f/is_it_possible_to_use_pix2pix_for_converting_hand/,utkarshmttl,1518717581,"If I gather a dataset of rough hand-drawn pencil sketches of shapes such as rectangles circle triangle etc and have corresponding geometric shapes, would it work?",0,1
75,2018-2-16,2018,2,16,3,7xsizc,Lossless Triplet loss - A more efficient loss function for Siamese,https://www.reddit.com/r/deeplearning/comments/7xsizc/lossless_triplet_loss_a_more_efficient_loss/,[deleted],1518720428,[deleted],0,1
76,2018-2-16,2018,2,16,4,7xsu71,Lossless Triplet Loss - A more efficient loss function for Siamese,https://www.reddit.com/r/deeplearning/comments/7xsu71/lossless_triplet_loss_a_more_efficient_loss/,marcolivierarsenault,1518722948,,0,3
77,2018-2-16,2018,2,16,6,7xtnht,Shape classification using deep learning,https://www.reddit.com/r/deeplearning/comments/7xtnht/shape_classification_using_deep_learning/,uridah,1518729574,"
I have a shape classification problem: I have a large dataset containing polygon points of some shapes and their labels. (11 classes)
Some people in my team trained rnn with lstms in Tensorflow but that hasn't worked out very well. What do you suggest  we can do with this dataset? What kind of network will work better? And is there a pre-existing similar example (of a trained neural network) already implemented that I can follow?",3,5
78,2018-2-16,2018,2,16,8,7xue5w,Convolutional autoencoder for text reconstruction,https://www.reddit.com/r/deeplearning/comments/7xue5w/convolutional_autoencoder_for_text_reconstruction/,deepneuralnetwork,1518735899,"Hi all - for fun, I've been exploring training convolutional autoencoders for text reconstruction using GloVe word embeddings. I've found it to be significantly more difficult than I expected, particularly given the success of convolutional networks for various text classification tasks (e.g. [Understanding how Convolutional Neural Network (CNN) perform text classification with word embeddings](https://towardsdatascience.com/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-d2ee64b9dd0b)).

I thought I'd reach out to this group for some thoughts - would love any feedback on how I'm approaching the problem (huge apologies if this isn't really the right place to ask this).

Basically, what I'm trying to do is:

* Train a 3-layer convolutional autoencoder that takes as input a sequence of N tokens (I've been working with between 10-20 length sequences)
* 300d GloVe embeddings for N tokens are retrieved and assembled into a N x 300 'image'
* That 'image' is the input for my autoencoder, which is trained to reconstruct the original 'image' via mean squared error loss

The reconstructions are pretty poor, even after significant training (100k iterations). The loss usually startsaround 0.85 or so and always converges to around 0.13-0.14 a few thousand iterations in, and just hangs there indefinitely.

* Have tried with/without batch normalization, with no real improvement
* Have tried various optimizers (standard SGD, Adam, RMSProp, momentum) with no real improvement
* Tried including max pooling layers, but output was extremely blocky / much worse than without
* Haven't yet tried much in the way of regularization (outside of dropout)

This is just a quick snippet of what the model looks like for reference. Highlights basically are - I've been trying a bunch of different kernel sizes (and #s of filters per convolutional layer), ranging from extending the entire width of the GloVe vector to more standard [5,5], [4,4], [3,3] sizes. The [h,300] kernels are doing the best job of reconstructing the image as far as I can tell (though it's still a pretty poor reconstruction).

Really, I'm mostly just curious to see if there's anything really obviously, blindingly stupid in how I'm conceptually approaching the problem. I've been playing a lot with widely varying hyperparameters to see if that improves the reconstructions, but ultimately my gut feeling is there is something more conceptually wrong with my model than not.

    conv1 = tf.layers.conv2d(inputs=data, filters=64, kernel_size=[1, 300], strides=[1,1], padding=""same"", activation=None)
    conv1_bn = tf.layers.batch_normalization(inputs=conv1, axis=-1, momentum=0.9, epsilon=0.001, center=True, scale=True, training = is_training)
    conv1_bn_relu = tf.nn.relu(conv1_bn)
    
    conv2 = tf.layers.conv2d(inputs=conv1_bn_relu, filters=32, kernel_size=[2, 300], strides=[1,1], padding=""same"", activation=None)
    conv2_bn = tf.layers.batch_normalization(inputs=conv2, axis=-1, momentum=0.9, epsilon=0.001, center=True, scale=True, training = is_training)
    conv2_bn_relu = tf.nn.relu(conv2_bn)
    
    conv3 = tf.layers.conv2d(inputs=conv2_bn_relu, filters=16, kernel_size=[3, 300], strides=[1,1], padding=""same"", activation=tf.nn.relu)
    conv3_bn = tf.layers.batch_normalization(inputs=conv3, axis=-1, momentum=0.9, epsilon=0.001, center=True, scale=True, training = is_training)
    conv3_bn_relu = tf.nn.relu(conv3_bn)
    
    conv3_shape = conv3_bn_relu.get_shape().as_list()
    conv3_units = conv3_shape[1] * conv3_shape[2] * conv3_shape[3]
    conv3_flat = tf.reshape(conv3_bn_relu, [-1, conv3_units])
    middle_layer = tf.layers.dense(conv3_flat, 1024, tf.nn.relu)
    
    rev_middle_layer  = tf.layers.dense(middle_layer, conv3_units, tf.nn.relu)
    rev_middle_layer   = tf.reshape(rev_middle_layer, [-1, conv3_shape[1], conv3_shape[2], conv3_shape[3]])
    
    conv4 = tf.layers.conv2d(inputs=rev_semantic_vector, filters=16, kernel_size=[3, 300], strides=[1,1], padding=""same"", activation=tf.nn.relu)
    conv4_bn = tf.layers.batch_normalization(inputs=conv4, axis=-1, momentum=0.9, epsilon=0.001, center=True, scale=True, training = is_training)
    conv4_bn_relu = tf.nn.relu(conv4_bn) 
                                                    
    conv5 = tf.layers.conv2d(inputs=conv4_bn_relu, filters=32, kernel_size=[2, 300], strides=[1,1], padding=""same"", activation=tf.nn.relu)
    conv5_bn = tf.layers.batch_normalization(inputs=conv5, axis=-1, momentum=0.9, epsilon=0.001, center=True, scale=True, training = is_training)
    conv5_bn_relu = tf.nn.relu(conv5_bn)
                            
    conv6 = tf.layers.conv2d(inputs=conv5_bn_relu, filters=1, kernel_size=[1, 300], strides=[1,1], padding=""same"", activation=tf.nn.relu)
    conv6_bn = tf.layers.batch_normalization(inputs=conv6, axis=-1, momentum=0.9, epsilon=0.001, center=True, scale=True, training = is_training)
    conv6_bn_relu = tf.nn.relu(conv6_bn)
    conv6_shape = conv6_bn_relu.get_shape().as_list()
    conv6_units = conv6_shape[1] * conv6_shape[2] * conv6_shape[3]
    output = tf.reshape(conv6_bn_relu, [-1, conv6_units])

    self.cost = tf.sqrt(tf.reduce_mean(tf.square(y - output)))

Any thoughts? :)",3,1
79,2018-2-16,2018,2,16,12,7xvuph,Prediction using Tensorflow Estimators (Quick draw: RNNs with LSTMs),https://www.reddit.com/r/deeplearning/comments/7xvuph/prediction_using_tensorflow_estimators_quick_draw/,uridah,1518750030,"I am following this tutorial:
https://www.tensorflow.org/versions/master/tutorials/recurrent_quickdraw#training_and_evaluating_the_model
This contains a step by step description on how to convert your dataset to tfrecord format and then use training and evaluation to train a recurrent neural network.
What I am trying to figure out is that, is there a way we can test i.e. predict given a single example. For instance, a drawing of a cat. Would we need to convert our prediction sample to tfrecord before feeding it to the network?

It makes use of Estimator for training and evaluation. How can we use an Estimator to predict. Where do we need to make the changes to the model_fn.",0,5
80,2018-2-16,2018,2,16,20,7xy5q7,Accelerating I/O bound deep learning on shared storage,https://www.reddit.com/r/deeplearning/comments/7xy5q7/accelerating_io_bound_deep_learning_on_shared/,chris_shpak,1518780877,,0,5
81,2018-2-16,2018,2,16,22,7xyuey,Need help estimating GPU specs I need,https://www.reddit.com/r/deeplearning/comments/7xyuey/need_help_estimating_gpu_specs_i_need/,barrelrider12,1518789197,"So I need a GPU in order to complete a project I'm working on, but I'm not sure how to estimate the specs I need. Planning to go to a local GPU renting store, and I need to specify the GPU and system specs of what I need in order for them to arrange it. Could anyone help me?

Training involves:- Running around 80k (~10gb) of images through the VGG16 classifier (probably the bottleneck); Running around 450k lines of text through a basic 3 layered LSTM (~500 units/layer); Training these predictions (in the form of ~4608-sized 1D vectors) on a basic feed forward neural net classifier (3-4 layers)",1,2
82,2018-2-17,2018,2,17,2,7y08va,"This Tangled Web  Intelligence, Technology and Fiction",https://www.reddit.com/r/deeplearning/comments/7y08va/this_tangled_web_intelligence_technology_and/,nilicie,1518801478,,0,1
83,2018-2-17,2018,2,17,3,7y0ywy,AI Weekly 16 Feb 2018,https://www.reddit.com/r/deeplearning/comments/7y0ywy/ai_weekly_16_feb_2018/,TomekB,1518807181,,0,5
84,2018-2-17,2018,2,17,12,7y4a8a,Densenet applied on multi-class unbalanced datasets,https://www.reddit.com/r/deeplearning/comments/7y4a8a/densenet_applied_on_multiclass_unbalanced_datasets/,wujy128,1518838507,"I have 30000 image data with 5 class grading label (0,1,2,3,4). I use dynamic resampling technique. At beginning I resample each class to equal amount. Then I decrease the minor class(1,2,3,4). In the end, the ratio approach to 1:2:2:2:2 at 200 epoch.

I applied densenet169 with cross entropy loss on raw image:
https://i.stack.imgur.com/ccdy4.png

I found most prediction value is 0. Then I applied a color strengthen technique to preprocess the image. Then send to Densenet169: 

https://i.stack.imgur.com/GZnOW.png

I found class 3 got activated at some epoch in the end. Then I merged these two datasets and another preprocessed datasets on channel. I got 512*512*9 input size. Here is the result from Densenet:

https://i.stack.imgur.com/LDW0X.png

The results seem really unstable. Any suggestions on how to future improve the results?

",0,7
85,2018-2-18,2018,2,18,23,7yehmi,Persecution classification,https://www.reddit.com/r/deeplearning/comments/7yehmi/persecution_classification/,depredador93,1518963607,So I made a simple Java program where I set a trajectory of two people to move in a 2D canvas. What I want is to use some kind neural network that could be able to classify whether one of the persons is following the other. However I am completely clueless as to what kind of algorithm I could use since there are a lot of them. Can someone point out to me in the right direction? I only worked with Adaboost in the past to classify whether an image has a person's face in it.,0,1
86,2018-2-19,2018,2,19,6,7yheru,Machine Learning Society - February Evolution,https://www.reddit.com/r/deeplearning/comments/7yheru/machine_learning_society_february_evolution/,Mathriddle,1518988481,,0,1
87,2018-2-19,2018,2,19,7,7yhvfg,no more sleepless n_ights,https://www.reddit.com/r/deeplearning/comments/7yhvfg/no_more_sleepless_n_ights/,notetofutureself,1518992445,,2,0
88,2018-2-19,2018,2,19,8,7yidei,Keras TensorFlow Model in 7 Minutes,https://www.reddit.com/r/deeplearning/comments/7yidei/keras_tensorflow_model_in_7_minutes/,tim_macgyver,1518997149,,0,2
89,2018-2-19,2018,2,19,14,7ykki8,DAgger Explanation,https://www.reddit.com/r/deeplearning/comments/7ykki8/dagger_explanation/,sauhaarda,1519019649,"Anyone willing to break down/explain the DAgger algorithm in simpler terms? I'm not quite sure what it's doing from the paper:
https://www.cs.cmu.edu/~sross1/publications/Ross-AIStats11-NoRegret.pdf

Is it attempting to train a network based on a combination of perfect imitation behavior and the networks bad behavior? Or is it something different?",2,3
90,2018-2-19,2018,2,19,15,7ykm7o,Sampling,https://www.reddit.com/r/deeplearning/comments/7ykm7o/sampling/,niteshsekhar,1519020227,"Is there a way to get an informative sampling of 3d point clouds? while farthest point sampling does give a decent sample, is there any neural network implementation which can give a more informative sampling?",1,4
91,2018-2-19,2018,2,19,17,7ylb6l,Assemble and Configure Your Ubuntu 16.04 Server for Deep Learning,https://www.reddit.com/r/deeplearning/comments/7ylb6l/assemble_and_configure_your_ubuntu_1604_server/,chris_shpak,1519029455,,0,1
92,2018-2-19,2018,2,19,19,7ylnma,7 Steps to Mastering Deep Learning with Keras,https://www.reddit.com/r/deeplearning/comments/7ylnma/7_steps_to_mastering_deep_learning_with_keras/,molode,1519034497,,2,11
93,2018-2-20,2018,2,20,1,7yntdp,Deep Learning for DNA Synthesis,https://www.reddit.com/r/deeplearning/comments/7yntdp/deep_learning_for_dna_synthesis/,alexmlamb,1519057552,,0,5
94,2018-2-20,2018,2,20,4,7yp9lt,CORe50: a new Dataset and Benchmark for Continuous/Lifelong Object RecognitionNews (self.MachineLearning),https://www.reddit.com/r/deeplearning/comments/7yp9lt/core50_a_new_dataset_and_benchmark_for/,[deleted],1519068169,[deleted],0,1
95,2018-2-20,2018,2,20,9,7yrnmc,Knowledge Graph Inference with Neural Embeddings,https://www.reddit.com/r/deeplearning/comments/7yrnmc/knowledge_graph_inference_with_neural_embeddings/,bsubs,1519086403,,0,6
96,2018-2-20,2018,2,20,21,7yvmed,Which Continent Does Pyeongchang Belong To? LSTM models in PyTorch,https://www.reddit.com/r/deeplearning/comments/7yvmed/which_continent_does_pyeongchang_belong_to_lstm/,junkwhinger,1519130875,,1,3
97,2018-2-20,2018,2,20,23,7yw6x9,The Importance of Predictive Analytics for Your Business,https://www.reddit.com/r/deeplearning/comments/7yw6x9/the_importance_of_predictive_analytics_for_your/,y-emre,1519136350,,0,6
98,2018-2-21,2018,2,21,1,7yx14v,Off the Beaten path  Using Deep Forests to Outperform CNNs and RNNs,https://www.reddit.com/r/deeplearning/comments/7yx14v/off_the_beaten_path_using_deep_forests_to/,psangrene,1519143006,,1,7
99,2018-2-21,2018,2,21,1,7yx5t8,Introducing Capsule Networks by @aureliengeron via @OReillyMedia https://t.co/WEBdq2a5n5 #DeepLearning #NeuralNetworks,https://www.reddit.com/r/deeplearning/comments/7yx5t8/introducing_capsule_networks_by_aureliengeron_via/,iraquitan,1519143972,[removed],0,1
100,2018-2-21,2018,2,21,1,7yxcfy,CORe50: a new Dataset and Benchmark for Continuous/Lifelong Object Recognition,https://www.reddit.com/r/deeplearning/comments/7yxcfy/core50_a_new_dataset_and_benchmark_for/,Gengiolo,1519145287,"Dear all,

We are happy to announce that the CORe50 dataset from the paper CORe50: a new Dataset and Benchmark for Continuous Object Recognition (CoRL, 2017) is now publicly available at the link: https://vlomonaco.github.io/core50/

CORe50, specifically designed for Continuous/Lifelong Learning and Object Recognition, is a collection of more than 500 videos (30fps) of 50 domestic objects belonging to 10 different categories. Instance level granularity, temporal coherence, first-person point-of-view and very different environmental conditions and backgrounds (outdoor sessions included) is what makes CORe50 particularly useful for assessing Continuous Learning techniques.

On top of the CORe50 dataset we are also happy to release a 3-way benchmark with multiple baselines and a living leaderboard to keep track of the progresses made in this new exciting area! For downloading the code, the dataset, the benchmark and more, check out the official website https://vlomonaco.github.io/core50/

Vincenzo Lomonaco, PhD student @ University of Bologna",0,1
101,2018-2-21,2018,2,21,3,7yybc1,Navigation with End-to-End deep learning for Self driving cars,https://www.reddit.com/r/deeplearning/comments/7yybc1/navigation_with_endtoend_deep_learning_for_self/,scmmishra,1519152289,I am following this tutorial by Microsoft for AirSim: https://github.com/Microsoft/AutonomousDrivingCookbook/tree/master/AirSimE2EDeepLearning so far I have used Udacity simulator for a similar project. However this tutorial works for a scenario with just a single lane road without turns. How do I extend end to end learning where the car takes turns when required based on the destination it needs to go like in a city scenario (Assuming GPS singals can be emulated for the purpose).  Thanks in advance.,0,2
102,2018-2-21,2018,2,21,7,7z07e1,[project] Dynamic Neural Networks in Tensorflow,https://www.reddit.com/r/deeplearning/comments/7z07e1/project_dynamic_neural_networks_in_tensorflow/,Miejuib,1519165656,,1,5
103,2018-2-21,2018,2,21,10,7z1fwd,CMU Deep Learning Course,https://www.reddit.com/r/deeplearning/comments/7z1fwd/cmu_deep_learning_course/,taurish,1519175532,"Carnegie Mellon's Deep Learning Course is being broadcasted for the first time this semester. So far we have had 9-10 lectures.
The class covers some topics that I haven't really seen in any other online course yet.

Lecturer: Bhiksha Raj

Channel link :https://www.youtube.com/channel/UC8hYZGEkI2dDO8scT8C5UQA/videos

Syllabus and Slides: http://deeplearning.cs.cmu.edu/",2,37
104,2018-2-21,2018,2,21,11,7z23xs,Votes needed for competition please!!,https://www.reddit.com/r/deeplearning/comments/7z23xs/votes_needed_for_competition_please/,py-guy,1519181172,"Hey Guys, my friend and I have been working on an autonomous drone project for a competition, if you can please take a look at our submission video an if you liked it please vote!! Heres the link https://challengerocket.com/as2399/TITUS-f18f33.html",0,0
105,2018-2-21,2018,2,21,17,7z450f,Porting Lua code with Torch7 and Loadcaffe to Python Jupyter Notebook?,https://www.reddit.com/r/deeplearning/comments/7z450f/porting_lua_code_with_torch7_and_loadcaffe_to/,rraallvv,1519202457,"I'd like to try some implementations of neural style transfer in Jupyter Notebook, the problem is that they are written in Lua and use Torch7 and Loadcaffe. So, I wonder what could I use to port the code to Python running on a Jupyter Notebook?",1,1
106,2018-2-21,2018,2,21,20,7z4zx7,"Deep Learning Development with Google Colab, TensorFlow, Keras &amp; PyTorch",https://www.reddit.com/r/deeplearning/comments/7z4zx7/deep_learning_development_with_google_colab/,dearpetra,1519214025,,0,9
107,2018-2-21,2018,2,21,21,7z58vh,"Neural Networks, Step 1: Where to Begin with Neural Nets &amp; Deep Learning",https://www.reddit.com/r/deeplearning/comments/7z58vh/neural_networks_step_1_where_to_begin_with_neural/,jackblun,1519216862,,0,12
108,2018-2-22,2018,2,22,1,7z6pzb,Voice Cloning with only a few samples - Baidu,https://www.reddit.com/r/deeplearning/comments/7z6pzb/voice_cloning_with_only_a_few_samples_baidu/,fuckme,1519229904,,2,2
109,2018-2-22,2018,2,22,5,7z8rft,Deep learning with microphone and speaker,https://www.reddit.com/r/deeplearning/comments/7z8rft/deep_learning_with_microphone_and_speaker/,Tobaganner,1519244834,"So I have recently discovered deep learning, and was wondering if you could get a computer to learn language through you speaking into a microphone, maybe the reward for a proper word could be a response or something, just an idea",5,3
110,2018-2-22,2018,2,22,8,7za8oi,Order agnostic search,https://www.reddit.com/r/deeplearning/comments/7za8oi/order_agnostic_search/,the_bored_potato,1519256447,"I wish to implement a sampled softmax classification algorithm that classifies the given input to an item number. For example: 
ABCLS10PJ40 -&gt; Item 3

The user often makes a mistake in entering the input. Like they might confuse l with 1, or i with 1 or O with 0 or S with 5. Also, they might mess up the order in which the input is arranged, for example:
ABC3000P20 can sometimes be put in like 3000ABC20P or 3000ABCP20.

I thought about training the model by emulating these mistakes, but I thought it would be worth asking if there's an efficient way to handle problems like this. Any suggestions would be great. Thanks!
",0,1
111,2018-2-22,2018,2,22,18,7zdrx6,Face recognition systems (CNNs),https://www.reddit.com/r/deeplearning/comments/7zdrx6/face_recognition_systems_cnns/,maildivert,1519292910,"Consider a CNN trained on dataset of faces of 10 different people.
It can predict new images of the people from the dataset.

Is there any Face Rec CNN/software/system that can identify new faces other than the ones from the data set and automatically create a new node for the face to predict for it in the future?

Thanks.",1,3
112,2018-2-22,2018,2,22,21,7zel5f,Deep Neural Networks for YouTube Recommendations paper implementation,https://www.reddit.com/r/deeplearning/comments/7zel5f/deep_neural_networks_for_youtube_recommendations/,dpoulopoulos,1519303133,"Is there anyone who has implemented the techniques described in the paper ""Deep Neural Networks for YouTube Recommendations"", so I could ask some relevant questions?",1,3
113,2018-2-23,2018,2,23,1,7zg4y0,Deep Learning and Smart Curation with HUE,https://www.reddit.com/r/deeplearning/comments/7zg4y0/deep_learning_and_smart_curation_with_hue/,abigagildunncmsn,1519316916,,0,1
114,2018-2-23,2018,2,23,2,7zgjpv,How to apply constraint to 2D-Conv weights to make it symmetric?,https://www.reddit.com/r/deeplearning/comments/7zgjpv/how_to_apply_constraint_to_2dconv_weights_to_make/,[deleted],1519320011,[deleted],6,2
115,2018-2-23,2018,2,23,3,7zh7u4,Deep learning technique to find answers in a text,https://www.reddit.com/r/deeplearning/comments/7zh7u4/deep_learning_technique_to_find_answers_in_a_text/,WerewolfBar-Mitzvah,1519325007,,0,9
116,2018-2-23,2018,2,23,4,7zhgac,TensorFlow on AWS (EC2?) for Dummies?,https://www.reddit.com/r/deeplearning/comments/7zhgac/tensorflow_on_aws_ec2_for_dummies/,PullThisFinger,1519326743,"I want to upload an existing Git repo from my laptop (Ubuntu 14.04 LTS) to an AWS instance. The repo is a TensorFlow-based deep learning example (https://github.com/LouieYang/deep-photo-styletransfer-tf) and can be launched from my command line with $python &lt;opts&gt;.

This is my first time using AWS for anything other than S3 services, and there's nobody around to provide hints. Does anybody know of a step-by-step tutorial?",3,0
117,2018-2-23,2018,2,23,4,7zhoyc,Testing Nvidia GTX 1050 on Generative Adversarial Network (GAN) | stdlog.net,https://www.reddit.com/r/deeplearning/comments/7zhoyc/testing_nvidia_gtx_1050_on_generative_adversarial/,pvsukale1,1519328543,,0,4
118,2018-2-23,2018,2,23,8,7zjmn2,"if I have tensors, `v`, `w`, I know you can multiply them together with a = Multiply()([v, w]) But what if I want to multiply `v` or `w` by a scalar?",https://www.reddit.com/r/deeplearning/comments/7zjmn2/if_i_have_tensors_v_w_i_know_you_can_multiply/,[deleted],1519343794,[deleted],0,1
119,2018-2-23,2018,2,23,9,7zjsum,How to multiply Keras tensor by scalar?,https://www.reddit.com/r/deeplearning/comments/7zjsum/how_to_multiply_keras_tensor_by_scalar/,74throwaway,1519345306,"if I have tensors, `v`, `w`, I know you can multiply them together with

    a = Multiply()([v, w])

But what if I want to multiply `v` or `w` by a scalar?",0,0
120,2018-2-23,2018,2,23,10,7zk6a6,How big are the largest datasets for Deep Learning ?,https://www.reddit.com/r/deeplearning/comments/7zk6a6/how_big_are_the_largest_datasets_for_deep_learning/,GrandGuitar,1519348600,Just curious what are the largest training sets for Deep Learning. Do people train a model with petabytes of data for example ? use cases ?,2,3
121,2018-2-23,2018,2,23,10,7zkbho,Relation between weight matrix and filter in CNN,https://www.reddit.com/r/deeplearning/comments/7zkbho/relation_between_weight_matrix_and_filter_in_cnn/,74throwaway,1519349935,"Let's say I have an original image and use just 1 filter to blur that image for the first part of the CNN. Suppose the original image is 100x100, the filter is 20x20 and the resulting blurred image is 100x100. In that case, wouldn't the weight matrix be 10000x10000? Shouldn't the output of the weight matrix with `imshow` resemble the 20x20 filter used to blur the image?

How do the values in the 20x20 filter correspond to the 10000x10000 weight matrix? Would it be something like rows/columns 49990 to 50010 contain the 20x20 filter values, and the remaining 99980x99980 values of the weight matrix are all 0?",62,2
122,2018-2-24,2018,2,24,4,7zqjxb,AI Weekly 23 Feb 2018,https://www.reddit.com/r/deeplearning/comments/7zqjxb/ai_weekly_23_feb_2018/,TomekB,1519412903,,0,5
123,2018-2-24,2018,2,24,11,7zth1s,Codementor worth it to get individual help?,https://www.reddit.com/r/deeplearning/comments/7zth1s/codementor_worth_it_to_get_individual_help/,74throwaway,1519437734,"I'm really stuck on a current deep learning problem using Tensorflow, Keras, and PyTorch. I've asked for help here, other subreddits, StackOveflow, etc, but I need help quickly and with more individual focus on my problem. I'm willing to pay to get expert advice on my problem where we can talk about it over the phone or skype

The only site I've found which offers instant help with individual attention is codementor. Has anyone tried this? Is it worth it?",0,3
124,2018-2-24,2018,2,24,11,7ztikn,Keras TensorFlow Model in 7 Minutes,https://www.reddit.com/r/deeplearning/comments/7ztikn/keras_tensorflow_model_in_7_minutes/,keghn,1519438158,,0,11
125,2018-2-24,2018,2,24,12,7ztyz1,Image Segmentation Does Not Improve Results,https://www.reddit.com/r/deeplearning/comments/7ztyz1/image_segmentation_does_not_improve_results/,bikermicefrmars,1519442918,"Hey every one, I am working on a binary image classification problem. I have ~300 images each for the class ""Yes"" and ""No"". I have written the code in Keras using VGG-16.

Now, I was getting an accuracy of 85 percent. To improve the results, I segmented (through masking) the area of interest from the image in hopes of increasing the accuracy. To my dismay, the accuracy dropped to 50%.

One reason that came to my mind was that the neural net might be learning the edges of the segmented image for classification rather than the area of interest itself. So I smoothed the edges, but still no improvement in results.

Can anyone please help?",1,1
126,2018-2-25,2018,2,25,0,7zxdot,"Any complex-valued, labelled dataset out there?",https://www.reddit.com/r/deeplearning/comments/7zxdot/any_complexvalued_labelled_dataset_out_there/,OK92,1519487493,"I am trying to work on my thesis related to Complex Valued Convolutional Neural networks for the classification task, for which I also require complex-valued data. Is there such a dataset available? Thank you.",4,2
127,2018-2-25,2018,2,25,11,801oa0,We are getting closer to our 5000 signature goal every day! Support our DeepBIO Conference (maybe Hackathon) by signing our Scientific Petition,https://www.reddit.com/r/deeplearning/comments/801oa0/we_are_getting_closer_to_our_5000_signature_goal/,Mathriddle,1519526895,,0,6
128,2018-2-26,2018,2,26,0,8052ab,What DeepLearning Technique for this kind of problem?,https://www.reddit.com/r/deeplearning/comments/8052ab/what_deeplearning_technique_for_this_kind_of/,juice_456,1519572290,"I just started last week with reading on deeplearning.
I am interested in solving this Problem with deeplearning but i dont know which technique should i consider?

Example:
Columns: Before  --&gt;    After       

- a      --&gt;       ab
- c       --&gt;    null
- null    --&gt;      a
- b=1.1  --&gt;    b=1.3


I want to classify/cluster the transistion types of {BEFORE} --&gt; {After} with an unsupervised manner

Really appreciate if you could help me",3,1
129,2018-2-26,2018,2,26,14,80apjl,How to make feature-wise heatmap images,https://www.reddit.com/r/deeplearning/comments/80apjl/how_to_make_featurewise_heatmap_images/,plznw4me,1519623849,"I'm new in tensorflow.
I've been implementing Paper 'Learning of subtle features in retinal images'


But I really don't know how to implement feature-wise heatmap like below(link)

https://imgur.com/BM8Crdr

more precisely , i understand about using neural network to make prediction each slide , but i don't know how to make heatmap

 did research on this issue, making heatmap

Class Activation Map
http://cnnlocalization.csail.mit.edu/

Regression Activation Map
https://arxiv.org/pdf/1703.10757.pdf

Grad-CAM Activation Map
https://arxiv.org/pdf/1610.02391.pdf


so, Could you give me some information about how to make feature-wise heatmap? web page, github, code, anything is ok thank you :)",2,5
130,2018-2-26,2018,2,26,20,80cc6y,Cryptoassets and Investments: Deep Learning Approach,https://www.reddit.com/r/deeplearning/comments/80cc6y/cryptoassets_and_investments_deep_learning/,AleksandrTavgen,1519644061,"We are currently developing portfolio optimization program for trading with crypto assets. Here is the second article about our research based on latest academic publications which involves Reinforcement Learning Agent's performance at the cryptomarket. All questions and suggestions are welcome!
https://medium.com/@ATavgen/cryptoassets-and-investments-deep-learning-approach-97f3d649afc1",0,2
131,2018-2-26,2018,2,26,22,80d04x,Multi-view Mask-R-CNN: Combining multiple images of the same object to generate a super accurate segmentation. Ideas how to get started?,https://www.reddit.com/r/deeplearning/comments/80d04x/multiview_maskrcnn_combining_multiple_images_of/,[deleted],1519651770,[deleted],0,1
132,2018-2-26,2018,2,26,23,80d8fb,Can I use Relu-&gt;SoftMax activation for this case?,https://www.reddit.com/r/deeplearning/comments/80d8fb/can_i_use_relusoftmax_activation_for_this_case/,marcelo_brazil,1519653991,"Hello everyone.
In Coursera Hyperparameter Tuning Course, I learned about using SoftMax for multi class problems.

I am trying to apply it to different problems to check if I really got it. Just for fun, I chose a problem that I know the deep net won't learn, but I would like to see it trying to learn.

The problem is: try to predict the number of a lottery here in Brazil called ""megasena"". The result of each game is a set of 6 numbers between 1 and 60. The training set is the last 2.000 games and each training example has 4 features: 

	1. the number of the game (eg. the 1st... until the 2000th)
	2. day of the game
	3. month of the game
	4. year of the game

For each Y of the example, I have a column with 60 rows, and in each row where the number was chosen in a particular game, I assigned ""1"". Eg. If the game 11th the result was (1, 2, 3, 5, 59 60), Y (column vector) will be = [1, 1, 1, 0, 1, 0, 0...., 0, 1, 1]. If the 12th game the result was (2, 4, 7, 57, 58, 60), Y will be = [0, 1, 0, 1, 0, 0, 1, 0..., 0, 1, 1, 0, 1].

It is a little bit different of the example in the course. In the class, the professor used an example where he has only one row where ""1"" was assigned for each example (when one row is ""1"", other rows are ""0""). In my experiment, I have 6 rows in the same column with ""1"" assigned and the other 54 rows with ""0"".

Do you guys know if I can use the same configuration for my example? (relu -&gt; relu -&gt; ... -&gt; relu -&gt; softmax?

Or as I have more than one row with ""1"", I should use another configuration or activation function?

Thank you! :)
",2,3
133,2018-2-27,2018,2,27,2,80ejw9,Machine Learning vs Deep Learning vs Artificial Intelligence - Are they really all that different - The best video explanation I came across,https://www.reddit.com/r/deeplearning/comments/80ejw9/machine_learning_vs_deep_learning_vs_artificial/,pooja307,1519664787,,0,12
134,2018-2-27,2018,2,27,2,80epnk,"Deep Learning from first principles in Python, R and Octave  Part 4",https://www.reddit.com/r/deeplearning/comments/80epnk/deep_learning_from_first_principles_in_python_r/,tvganesh,1519665910,,0,1
135,2018-2-27,2018,2,27,3,80f19q,Please solve and join the conversation:,https://www.reddit.com/r/deeplearning/comments/80f19q/please_solve_and_join_the_conversation/,levelship,1519668225,,0,0
136,2018-2-27,2018,2,27,6,80gu6h,Benevolent AI drug discovery paper at ICLR 2018: review,https://www.reddit.com/r/deeplearning/comments/80gu6h/benevolent_ai_drug_discovery_paper_at_iclr_2018/,mostafabenh,1519681627,,0,2
137,2018-2-27,2018,2,27,9,80i2ns,Transfer Learning - Use Inception V3 to Solve Any ML Problem (Tempo Detection),https://www.reddit.com/r/deeplearning/comments/80i2ns/transfer_learning_use_inception_v3_to_solve_any/,tim_macgyver,1519691652,,1,7
138,2018-2-27,2018,2,27,10,80iicp,Total memory is sum up to 15.1 M instead of 24. Am i incorrect??,https://www.reddit.com/r/deeplearning/comments/80iicp/total_memory_is_sum_up_to_151_m_instead_of_24_am/,ram_dl,1519695525,,0,0
139,2018-2-27,2018,2,27,13,80jpsn,Can anyone with tensorflow experience please help me with this??,https://www.reddit.com/r/deeplearning/comments/80jpsn/can_anyone_with_tensorflow_experience_please_help/,alluriharikishan,1519706818,,0,0
140,2018-2-27,2018,2,27,16,80kkm5,"22 Minutes to 2nd Place in a Kaggle Competition, with Deep Learning &amp; Azure",https://www.reddit.com/r/deeplearning/comments/80kkm5/22_minutes_to_2nd_place_in_a_kaggle_competition/,dearpetra,1519716314,,0,6
141,2018-2-27,2018,2,27,19,80lkca,5 Fantastic Practical Natural Language Processing Resources,https://www.reddit.com/r/deeplearning/comments/80lkca/5_fantastic_practical_natural_language_processing/,magneticono,1519728607,,0,6
142,2018-2-27,2018,2,27,23,80mon6,A Comparison of Deep Learning Frameworks,https://www.reddit.com/r/deeplearning/comments/80mon6/a_comparison_of_deep_learning_frameworks/,y-emre,1519740569,,0,0
143,2018-2-28,2018,2,28,4,80p8tx,Scientists Pioneer Use of Deep Learning for Real-Time Gravitational Wave Discovery,https://www.reddit.com/r/deeplearning/comments/80p8tx/scientists_pioneer_use_of_deep_learning_for/,WerewolfBar-Mitzvah,1519759397,,0,1
144,2018-2-28,2018,2,28,5,80pp1y,Can't implement Sampled Softmax,https://www.reddit.com/r/deeplearning/comments/80pp1y/cant_implement_sampled_softmax/,the_bored_potato,1519762662,"I have been trying for a while to implement sampled softmax because I have half a million output classes.

I have tried to follow the official documentation exactly, but I always get an error. This is my code:

def forward_propagation_sampled(X, parameters):

    W1 = parameters['W1']
    b1 = parameters['b1']
    W2 = parameters['W2']
    b2 = parameters['b2']
    W3 = parameters['W3']
    b3 = parameters['b3']

    
    Z1 = tf.add(tf.matmul(W1, X), b1)
    A1 = tf.nn.relu(Z1)
    Z2 = tf.add(tf.matmul(W2,A1), b2)
    A2 = tf.nn.relu(Z2)
    Z3 = tf.add(tf.matmul(W3,A2), b3)
    
    
    return Z3, W3, b3

This is the cost computation function:

def compute_cost(Z3, W3, b3, Y, mode):

    Z3.set_shape([1144,1])

    if mode == ""train"":

        loss = tf.nn.sampled_softmax_loss(

        weights=tf.transpose(W3),

        biases=tf.Variable(b3),

        labels = tf.reshape(tf.argmax(Y, 1), [-1,1]), #Since Y is one hot encoded

        inputs=tf.Variable(initial_value=Z3,dtype=tf.float32, expected_shape=[1144,1]),

        num_sampled = 2000,

        num_classes = 1144, 

        partition_strategy=""div""

        )

    elif mode == ""eval"":

        logits = tf.matmul(inputs, tf.transpose(weights))

        logits = tf.nn.bias_add(logits, biases)

        labels_one_hot = tf.one_hot(labels, n_classes)

        loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels_one_hot,logits=logits)

    cost = tf.reduce_mean(loss)

    return cost

For the purpose of just testing this out, I am using 1144 output classes, which would otherwise scale to 500,000. There are 3144 training examples.

I get this error: 

Shape must be rank 1 but is rank 2 for 'sampled_softmax_loss/Slice_1' (op: 'Slice') with input shapes: [3144,1], [1], [1].

I am unable to debug this or make any sense out of it. Any help would be really appreciated.



",0,1
145,2018-2-28,2018,2,28,5,80prn0,Dual NN's for Comparison Task,https://www.reddit.com/r/deeplearning/comments/80prn0/dual_nns_for_comparison_task/,Nightsd01,1519763172,"I am working on a facial recognition system that accepts two images as input and outputs a single yes/no probability indicating if they are the same person.

My question is, I would like to train a facial extraction system to extract features from face pictures. I would run the two images through this NN (separately) and then feed the results into the facial recognition NN. 

Is there a way to implement this in Keras so that I can effectively run forward and backprop with an input NN that is essentially duplicated? How would back propagation even work, would it simply average the gradients for both iterations/images before updating weights?",2,4
146,2018-2-28,2018,2,28,5,80q10k,A reflection on deep learning: 2013 and now,https://www.reddit.com/r/deeplearning/comments/80q10k/a_reflection_on_deep_learning_2013_and_now/,_data_scientist_,1519765001,"Rachel Thomas of fast.ai recounts her experience (https://vimeo.com/214233053#t=81s) of attending a meetup on deep learning in the Bay Area back in 2013. The speaker was Ilya Sutskever, who (along with Geoffrey Hinton and Alex Krizhevsky) started the revolution in deep learning by winning the 2012 ImageNet challenge with a convolutional neural network architecture.

The talk by Sutskever was mostly theoretical, and at the end of the talk, someone in the audience asked how Sutskever initialized his weights. His reply was the following:

""That's part of a dirty bag of tricks that nobody publishes.""

Deep learning has certainly come a long way since then. In only a matter of five years, deep learning has now reached the masses. A whole dozen deep learning frameworks (https://en.wikipedia.org//Comparison_of_deep_learning_soft) have been set up. Online courses on deep learning now include those by influential academics, such as Geoffrey Hinton (https://www.coursera.org/learn/neural-networks), Andrew Ng (https://www.coursera.org/specializations/deep-learning) and Andrej Karpathy (http://cs231n.stanford.edu). Top researchers such as Ian Goodfellow, Yoshua Bengio and Aaron Courville have even published a book (http://www.deeplearningbook.org) on deep learning. Hell, we can now even train a state-of-the-art cats-and-dogs model in just 10 lines of code (see the first lecture of fast.ai).

Finally, let me recall a story from my own learning experience. In my machine learning class, we are still being taught how to train our model with good-old ""step-wise learning rate annealing"". Jeremy Howard, on the other hand, teaches you (in the very first lecture of the 2017 fast.ai course) how to create a state-of-the-art model using ""stochastic gradient descent with restarts"" (see under the heading 'Improving our model': https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb). You cannot simply underestimate the impact this can have on learning your deep learning model.

Jeremy Howard and Rachel Thomas have done an awesome work in bringing CUTTING-EDGE deep learning to the masses.",2,8
147,2018-2-28,2018,2,28,8,80r6un,Seeking anyone with Machine/Deep Learning experience in Financial trading,https://www.reddit.com/r/deeplearning/comments/80r6un/seeking_anyone_with_machinedeep_learning/,JustinQueeber,1519773699,I am currently completing an academic research project in a Deep Learning application to the financial markets. I'd love to connect with someone with relevant real-world experience to discuss the subject and gain their expert guidance.,5,2
148,2018-2-28,2018,2,28,18,80up3d,Finding the genre of a song with Deep Learning  AI Odyssey Part 1,https://www.reddit.com/r/deeplearning/comments/80up3d/finding_the_genre_of_a_song_with_deep_learning_ai/,akaleeroy,1519809173,,2,1
149,2018-2-28,2018,2,28,20,80v9md,Deep learning India,https://www.reddit.com/r/deeplearning/comments/80v9md/deep_learning_india/,luci_dity,1519816517,Looking to get connected to top teams/individuals in India involved in deep learning. Would love to connect here or find out where I could go to collaborate. ,8,10
0,2018-3-1,2018,3,1,19,8149bv,Running your Coursera (and all other) Jupyter Notebooks locally,https://www.reddit.com/r/deeplearning/comments/8149bv/running_your_coursera_and_all_other_jupyter/,janvandepoel,1519899221,,0,1
1,2018-3-2,2018,3,2,0,8164am,Project: image recognition,https://www.reddit.com/r/deeplearning/comments/8164am/project_image_recognition/,Moni93,1519918735,"Hello everyone,
This is my first non academic project in deep learning and i feel that i need some advice to know in which direction i can go.
Let's start: I want to use deep learning to build a model that recognizes many characteristic in an image. To be precise, i want to create a model that allows me to recognize in a photo:
.if the person is a MALE/Female.
.what type of clothing is he/she wearing( i will create a list of labels corresponding to some possible type of clothing.)
.what are the colors of the clothes he/she is wearing.
I really need some guidance in order to start thinking of the possible techniques that could help me go deeper in this project.
Do you advise me to start thinking first of a model that can  distinguish male/femal?Or do i need to think of the subject from another perespective?
What are the topics that i need to look for?
All responses are welcome. I do really want to know what do you think of this guys.
",12,3
2,2018-3-2,2018,3,2,3,817ny4,"Guide to Visual Question Answering: Datasets, Approaches and Evaluation",https://www.reddit.com/r/deeplearning/comments/817ny4/guide_to_visual_question_answering_datasets/,minmidinosaur,1519930323,,0,6
3,2018-3-2,2018,3,2,15,81cfp5,Machine Learning Crash Course | Google Developers,https://www.reddit.com/r/deeplearning/comments/81cfp5/machine_learning_crash_course_google_developers/,semi23,1519973577,,1,29
4,2018-3-2,2018,3,2,16,81cn52,Would AMD GPU ever catch up in popularly compared to Nvidia GPU?,https://www.reddit.com/r/deeplearning/comments/81cn52/would_amd_gpu_ever_catch_up_in_popularly_compared/,smallbee2,1519976679,"Would AMD GPU ever catch up in popularly compared to Nvidia GPU  in the field of deep learning?  
If yes, how long does it take?",1,2
5,2018-3-2,2018,3,2,21,81dubg,"Can We Classify ""Cooked"" Instant Noodle?",https://www.reddit.com/r/deeplearning/comments/81dubg/can_we_classify_cooked_instant_noodle/,complectere,1519993498,"https://imgur.com/a/7XAWR

Today my company got some request to develop/train a network that can classify ""cooked"" instant noodles from two different company.

This company is a major instant noodle manufacturer in my region and they want to crawl the blog posts about small-sized restaurants who serves cooked instant noodles and hope to check whether they are using their product or not just by the blog posted pics of Instant Noodles. 

The attached two pictures are the example of them, one is from the company that requested this weird but interesting task and the other one is from their major competitor.

I had checked which network the famous ""Not Hot Dog App"" had used, but still however, remains two main questions.

1) Would it be possible? (This question is minor, because anyway I will try)

2) How many qualitative training pics would be required to get fancy and accurate learned network? 

We can gather as many pics as we want using the company's whole employees :D Anyway that's a good news.

Imagine that all employees in the company just got text message from the CEO saying, ""Go home and take a picture of noodles and upload it. That's your job today"" 

LOL (still, my question is serious and valid)
",4,3
6,2018-3-3,2018,3,3,3,81gd7x,Predicting e-sports winners with Machine Learning,https://www.reddit.com/r/deeplearning/comments/81gd7x/predicting_esports_winners_with_machine_learning/,e_ameisen,1520015010,,0,8
7,2018-3-3,2018,3,3,5,81hkes,AI Weekly 2 Mar 2018,https://www.reddit.com/r/deeplearning/comments/81hkes/ai_weekly_2_mar_2018/,TomekB,1520021309,,0,2
8,2018-3-3,2018,3,3,13,81msu7,Stephen Wolfram's talk at MIT on how artificial general intelligence will be achieved.,https://www.reddit.com/r/deeplearning/comments/81msu7/stephen_wolframs_talk_at_mit_on_how_artificial/,CuttingWithScissors,1520052088,,10,16
9,2018-3-3,2018,3,3,15,81nw5o,KihwanNet: A Collaborative Neural Network Creating Platform. We are looking for beta testers.,https://www.reddit.com/r/deeplearning/comments/81nw5o/kihwannet_a_collaborative_neural_network_creating/,kifhan,1520059846,,0,2
10,2018-3-3,2018,3,3,17,81olem,Better CNNs than ENet? Or 'next' version of ENet?,https://www.reddit.com/r/deeplearning/comments/81olem/better_cnns_than_enet_or_next_version_of_enet/,mr_mulay,1520065430,ENet gives highest accuracy per parameter. It is really efficient. I was wondering if there has been any further development based-off ENet-like architectures? Can anyone point me to some papers after ENet (2016)? Thanks!,1,4
11,2018-3-4,2018,3,4,0,81qrxo,TensorFlow Object Detection in Action,https://www.reddit.com/r/deeplearning/comments/81qrxo/tensorflow_object_detection_in_action/,keghn,1520090977,,0,1
12,2018-3-4,2018,3,4,1,81r7rv,Tony Starks Jarvis,https://www.reddit.com/r/deeplearning/comments/81r7rv/tony_starks_jarvis/,itsdevkay,1520095228,"Would this be the subreddit I need to find the resources to build a Jarvis ? Machine learning and neural networks? I would love to build a chatbot that could have conversations and give resources for things that I ask, news and searches like Siri and amazon echo, recommendations and so forth but I dont really know where or how to starts",2,5
13,2018-3-4,2018,3,4,2,81rf7d,Black-Box Attacks on Perceptual Image Hashes with GANs,https://www.reddit.com/r/deeplearning/comments/81rf7d/blackbox_attacks_on_perceptual_image_hashes_with/,tanked1,1520097078,,2,15
14,2018-3-4,2018,3,4,17,81wl8k,Edison - Self Driving Car | Test Drive #1,https://www.reddit.com/r/deeplearning/comments/81wl8k/edison_self_driving_car_test_drive_1/,aniruddh1998,1520152647,,3,7
15,2018-3-4,2018,3,4,21,81xes8,Video GAN in Tensorflow,https://www.reddit.com/r/deeplearning/comments/81xes8/video_gan_in_tensorflow/,Vignesh_Gokul,1520166644,"Hey guys, do check out my implementation of ""Generating Videos with Scene Dynamics"" in Tensorflow here : https://github.com/GV1028/videogan",2,11
16,2018-3-5,2018,3,5,1,81ynyu,Totally Noob Here -&gt; Need Some Help With Where to Start,https://www.reddit.com/r/deeplearning/comments/81ynyu/totally_noob_here_need_some_help_with_where_to/,mmertTR,1520181004,"Hi there!

After hearing lots about Deep Learning, i searched for it and it got my interest. Then i decided that i should start it! 
Everything was going good until the starting part comes in. I have no idea which framework to use or which tutorial to follow. I have 2 years of C# experience and some C++. Especially i want to be into Image Recognation. 
Anyways, i'm open to all tips and help. Thanks!",1,1
17,2018-3-5,2018,3,5,3,81zi2q,Thesis on Cryptocurrency price prediction using Deep Learning.,https://www.reddit.com/r/deeplearning/comments/81zi2q/thesis_on_cryptocurrency_price_prediction_using/,brellio24,1520188379,"Hello Everybody,
I am an engineering student who is planning to write my final year thesis on using machine learning/deep learning to predict cryptocurrency price movements. The idea is to use some conventional methods of stock prediction and compare the mean standard error of those results to that of the deep learning model. If anybody has any advice or tips/links that they think would be helpful i would really appreciate it. Any suggestions or input would be great!
PS: I plan to use python with Tensorflow to build the deep learning model and have found some useful posts on Medium already.",11,4
18,2018-3-5,2018,3,5,3,81zobo,"Backpropagation is a commonly used technique for training neural network. There are many resources explaining the technique, but this post will explain backpropagation with concrete example in a very detailed colorful steps.",https://www.reddit.com/r/deeplearning/comments/81zobo/backpropagation_is_a_commonly_used_technique_for/,[deleted],1520189877,[deleted],0,1
19,2018-3-5,2018,3,5,4,81zr1w,Backpropagation Step by Step,https://www.reddit.com/r/deeplearning/comments/81zr1w/backpropagation_step_by_step/,hmkcode,1520190517,,0,1
20,2018-3-5,2018,3,5,4,81zsjg,Deep Learning/Neural Network Video Tutorials- Subscribe here!,https://www.reddit.com/r/deeplearning/comments/81zsjg/deep_learningneural_network_video_tutorials/,DiscoverAI,1520190889,,0,2
21,2018-3-5,2018,3,5,9,821r58,Tensorflow import,https://www.reddit.com/r/deeplearning/comments/821r58/tensorflow_import/,itsdevkay,1520208044,"Im having trouble importing tensorflow with python, it ends up crashing python, any reason why ?

System info:
Late 2008 MacBook
Upgraded to 8GB of ram 

I know I cant run tensorflow gpu but do my specs affect the normal tensorflow ?",7,1
22,2018-3-5,2018,3,5,13,823ctj,Using Neural Networks for sales prospecting,https://www.reddit.com/r/deeplearning/comments/823ctj/using_neural_networks_for_sales_prospecting/,psangrene,1520223948,,0,3
23,2018-3-5,2018,3,5,14,823q0k,"MXNet implementation of SEC, a weakly supervised segmentation method",https://www.reddit.com/r/deeplearning/comments/823q0k/mxnet_implementation_of_sec_a_weakly_supervised/,ascust,1520228132,"The MXNet implementation of the paper ""Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation"", a weakly supervised method for semantic segmentation. 

https://github.com/ascust/SEC-MXNet",2,8
24,2018-3-5,2018,3,5,20,825ayl,Where to get DNA data,https://www.reddit.com/r/deeplearning/comments/825ayl/where_to_get_dna_data/,niujin,1520249435,"I've been using TensorFlow seq2seq and CNNs on natural language data and got some really good results.

I'm now wondering if there's any kind of simple classifier I can build that would work on DNA data? I'd like to make a model that takes a sequence in human readable form 
 such as ACGAGT and can output some useful characteristics:

* gender

* race

* susceptibility to diseases

Does anyone know of a dataset that can be freely downloaded to build such a model? Also what would be the best kind of data to start with? 

I am thinking about Mitochondrial DNA because it is short: 16,569 tokens. If there's somewhere where I can download a few tens of thousands Mitochondrial DNA files together with other metadata that would be great. 

I found this DB: http://www.mtdb.igp.uu.se/ however it is not that huge. Is there any other genome DB with &gt;10,000 files?

It's not a commercial thing, just a project I'm interested in trying for my own education. I'm not affiliated with any university so there isn't an obvious place for me to ask about this stuff and I won't have access to things behind paywalls.

Thanks!
",9,4
25,2018-3-5,2018,3,5,21,825pk0,Deep Learning  Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/825pk0/deep_learning_learn_recurrent_neural_networks_in/,loneisthere,1520254300,,0,0
26,2018-3-6,2018,3,6,13,82cgvp,Questions about automated router hacking based on DeepLearning,https://www.reddit.com/r/deeplearning/comments/82cgvp/questions_about_automated_router_hacking_based_on/,Import-Sys,1520311661,"Hi everyone,I am new here.I am currently involved in a project and that project is about automated hacking router based on deeplearning .Cause I am new to this field ,and I wonder which approach should i take to solve this problem. 
I am thinking about using LSTM to build a fuzzing module ,but I dont know if this is a right path.",0,0
27,2018-3-6,2018,3,6,21,82esfv,Apache Deep Learning 101: Using Apache MXNet on an HDF Node,https://www.reddit.com/r/deeplearning/comments/82esfv/apache_deep_learning_101_using_apache_mxnet_on_an/,molode,1520340308,,0,2
28,2018-3-6,2018,3,6,22,82ey7d,Innovation with Real-Time Data and Insights,https://www.reddit.com/r/deeplearning/comments/82ey7d/innovation_with_realtime_data_and_insights/,y-emre,1520341842,,1,0
29,2018-3-7,2018,3,7,1,82gk0a,Computed filter from Conv2D not making sense,https://www.reddit.com/r/deeplearning/comments/82gk0a/computed_filter_from_conv2d_not_making_sense/,74throwaway,1520355283,"I have an original image and a blurred image that was obtained by doing a convolution of the original image and the known PSF. I followed the code in this link to generate the blurred image and known PSF: http://matlabgeeks.com/tips-tutorials/how-to-blur-an-image-with-a-fourier-transform-in-matlab-part-i/

Here is the exact Matlab code I used to generate the blurred image and known PSF:

https://pastebin.com/YExKkS5C 
https://pastebin.com/bqxS28q4 
https://pastebin.com/dj18nm5P

Now that I know the original image and the blurred image, I want to use Conv2D to compute the filter and compare it with the known PSF. Basically deconvolution using NN. This is just an exercise. This is *not* a classification problem. I'm not trying to classify images, for example as dogs or cats

I have Keras code here: https://pastebin.com/r0pqBjZ6

The images I have are here: https://imgur.com/a/3H7V2

In the 2x2 grid of images, here are what the images are:

-Top-left: original blurred image

-Top-right: computed blurred image

-Bottom-left: Computed kernel

-Bottom-right: kernel scaled to grayscale

As seen in the link, I've tried various different losses and optimizers, but none of them are giving the kernel that really looks like the actual kernel. I've also tried various epochs such as 10-5000, and learning rates such as .5, .05, .005, but none of them give good results

Can anyone help?",0,2
30,2018-3-7,2018,3,7,3,82hcv6,"Always start with a stupid model, no exceptions",https://www.reddit.com/r/deeplearning/comments/82hcv6/always_start_with_a_stupid_model_no_exceptions/,e_ameisen,1520361185,,1,13
31,2018-3-7,2018,3,7,6,82itsw,Several technical questions about training on custom dataset,https://www.reddit.com/r/deeplearning/comments/82itsw/several_technical_questions_about_training_on/,aviadm,1520372315,"I want to perform image detection (objects recognition in image along with bounding boxes) on a custom dataset of images I own.

The framework which I know the best is PyTorch, therefore I was looking for an implementation of some detection neural network (i.e. SSD, Faster-RCNN...) implemented in this framework.
I've found a nice open source implementation of Faster-RCNN (https://github.com/jwyang/faster-rcnn.pytorch) which I picked for now (however I'm open to hear if there are other recommended implementations which might be better / easier, etc).

I've succeeded on training the network on a dataset it supports (coco/pascal voc).
In order to train on my dataset, which is annotated in a custom csv file, I have to convert the annotations to coco or pascal voc.

First problem: My dataset has coarse-grained labels (large car, small car, etc) and then fine-grained labels (features of the cars), where the fine-grained labels are only presented for some of the coarse-grained labels (only for cars), and are different for each coarse grained label.
How can I deal with that? The COCO / Pascal Voc formats does not support fine-grained labels.

Second problem: My dataset is annotated with oriented bounding boxes (4 points which are not rectangular), and the other datasets have rectangular / horizontal bounding boxes. I thought about wrapping each oriented bounding box in a horizontal one so it would fit the coco / pascal voc formats, but... I'm losing the flexibility of the oriented boxes.

Third problem: Some of the images are too large to run on my Tesla K40 GPU (they are ~4000x2000), considering the benchmarks posted in the git repo.

Many thanks for any ideas",0,2
32,2018-3-7,2018,3,7,6,82iypu,Data augmentation : boost your image dataset with few lines of Python,https://www.reddit.com/r/deeplearning/comments/82iypu/data_augmentation_boost_your_image_dataset_with/,tomahim,1520373315,,0,2
33,2018-3-7,2018,3,7,7,82j87s,Style Transfer using Google Colab - Colaboratory,https://www.reddit.com/r/deeplearning/comments/82j87s/style_transfer_using_google_colab_colaboratory/,Roots91,1520375313,,0,13
34,2018-3-7,2018,3,7,18,82mxwt,how to classify data sampling from sources with temporal distribution?,https://www.reddit.com/r/deeplearning/comments/82mxwt/how_to_classify_data_sampling_from_sources_with/,dlnewer,1520413402,"Hi, I have temporal data sampled from sources with temporal distributions, for example, 
source1  y1 = 1|t=5,10,15,20,..; source2 y2 = 1|t=3,6,9,12,15..., then we get the temporal sequence : [0,0,1,0,1,1,0,0,0,1,0,1,0,0,1,0,0,0,0,1....], how can I classify the 1s into class y1 and y2, especially when y1 and y2 are gaussian-hood distributions on time? any suggestions?",0,2
35,2018-3-8,2018,3,8,0,82ozub,Backpropagation of LSTM,https://www.reddit.com/r/deeplearning/comments/82ozub/backpropagation_of_lstm/,wllnyubupt,1520435878,"Hi,guys,

Recently, I am reading this tutorial (https://arxiv.org/pdf/1610.02583.pdf) about RNN and LSTM. However, when I read about the backpropagation part of LSTM, I cannot understand how he got equations(21)~(23).

Specifically, 
1. for equation(21), I think dz should be (z-y), instead of (y-z).
2. for equation(22) and (23), it seems that he didn't consider the derivative of the softmax function.

Thanks in advance for any help!",4,11
36,2018-3-8,2018,3,8,1,82plz1,How to prepare these models to Serving,https://www.reddit.com/r/deeplearning/comments/82plz1/how_to_prepare_these_models_to_serving/,steveastevea,1520440629,"I've just trained these models https://github.com/Maluuba/qgen-workshop/blob/master/qgen/model.py

Got 5 models

model-1.data-00000-of-00001
model-1.index
model-1.meta
(from model-1 to model-5)

and those files:

checkpoint
embeddings.ckpt.data-00000-of-00001
embeddings.ckpt.index
embeddings.ckpt.meta
projector_config.pbtxt
vocab.tsv
tensorflow dashboard works perfectly

So, now I want to deploy this model to production with TensorFlow Serving which is really confused to me.

I've read few manuals, and the main question is how should I convert all this model to use it in TensorFlow Serving and should I convert all of them?",1,2
37,2018-3-9,2018,3,9,10,832z2t,Emulating Neural Synapses through AI,https://www.reddit.com/r/deeplearning/comments/832z2t/emulating_neural_synapses_through_ai/,Michael_Pa,1520559406,,0,1
38,2018-3-9,2018,3,9,12,833m6k,Capsule Networks for Food Classification,https://www.reddit.com/r/deeplearning/comments/833m6k/capsule_networks_for_food_classification/,k9thedog,1520565596,,1,7
39,2018-3-9,2018,3,9,14,834bnb,"CNN : Fine tuning small,simple network vs feature extracting from a big,complex one",https://www.reddit.com/r/deeplearning/comments/834bnb/cnn_fine_tuning_smallsimple_network_vs_feature/,Captain_Price_777,1520573130,"To elaborate : Under what circumstances would fine tuning all layers of a small network (say SqueezeNet) perform better than feature extracting or fine tuning only last 1 or 2 Convolution layer of a big network (e.g inceptionV4)?

My understanding is computing resource required for both is somewhat comparable. And I remember reading in a paper that extreme options i.e fine tuning 90% or 10% of network is far better compared to more moderate like 50%. So, what should be the default choice when experimenting extensively is not an option?

Any past experiments and intuitive description of their result, research paper or blog would be specially helpful. Thanks.

This question was [asked in stackoverflow] (https://stackoverflow.com/questions/49178991/cnn-fine-tuning-small-network-vs-feature-extracting-from-a-big-network) but didn't generate any response. Thanks again.",1,7
40,2018-3-10,2018,3,10,4,839aah,"There are way too many 'getting started with data science' things. I have an idea to make it better, but I need some help.",https://www.reddit.com/r/deeplearning/comments/839aah/there_are_way_too_many_getting_started_with_data/,ezeeetm,1520622913,,1,10
41,2018-3-10,2018,3,10,5,839ni1,AI Weekly 9 Mar 2018,https://www.reddit.com/r/deeplearning/comments/839ni1/ai_weekly_9_mar_2018/,TomekB,1520625763,,0,6
42,2018-3-10,2018,3,10,11,83cfyh,Tensorflow -- Printing Accuracy of Training,https://www.reddit.com/r/deeplearning/comments/83cfyh/tensorflow_printing_accuracy_of_training/,arjundupa,1520650466,"This is code from the MNIST tutorial:

    correct_prediction = tf.equal(tf.argmax(y, 1), y_)
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(sess.run(
      accuracy, feed_dict={
          x: mnist.test.images,
          y_: mnist.test.labels
      }))

I modelled this for my own neural network:

    print(batch_ys.shape)  
    correct_prediction = tf.equal(y, float_y_)
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(sess.run(
      accuracy, feed_dict={
          x: batch_test_x,
          y_: batch_ys
      }))

I get an error on the ""y_: batch_ys"" line saying ""TypeError: Cannot interpret feed_dict key as Tensor: Can not convert a int into a Tensor.""

The first print statement in my code was to debug this, which successfully prints out (2, 11, 1), which is clearly a tensor. Any ideas?

Any help will be greatly appreciated, thanks in advance. ",2,1
43,2018-3-11,2018,3,11,9,83jbtm,Autonomous Driving  Car detection with YOLO Model with Keras in Python,https://www.reddit.com/r/deeplearning/comments/83jbtm/autonomous_driving_car_detection_with_yolo_model/,SandipanDeyUMBC,1520728593,,0,4
44,2018-3-11,2018,3,11,11,83juk1,Questions about matconvnet + gpu clouds,https://www.reddit.com/r/deeplearning/comments/83juk1/questions_about_matconvnet_gpu_clouds/,quackledinkle,1520734018,"Hi there...Im running this on my windows 7 computer:  
https://github.com/dixinhan/DCor  
But its obviously having one hell of a hard time, as im not using any GPU.  
Im wondering, I've heard of these cloud-based gpu things...is there one I can run this particular code with to help speed it up?  
It uses matconvnet.  
Reason for not buying a GPU is that im curious what the alternatives are before I even dive into that, im no expert on this whole bizness.  
Thanks!  

",0,3
45,2018-3-12,2018,3,12,2,83o27k,is the Visualization result of Attentions proved enough?,https://www.reddit.com/r/deeplearning/comments/83o27k/is_the_visualization_result_of_attentions_proved/,dongyi_kim,1520788785,"(Sorry for my pool english, plz understand XD )

I have a question about the relationship between the visualization result of the Attention Map and the actual meaning.

In case of applying Attention to video information, it is applied to Response Map that passes through neural network instead of applying it to original input image in general.

If so, can you be sure that the Patch with high output in the Attention Map actually emphasizes the same position in the original image? (Of course, the Attention Map is smaller than the original image, so resizing is necessary.)

In the case of feature maps after passing enough neural networks, the Receptive Field of each output value will be large enough to occupy most of the original image.
In my opinion, the fact that the Attention Value corresponding to one Resonse Value is large can not confirm that the position is emphasized in the original input image.

If the Attention Map is directly applied to the original input image, it can be said that the output of each Attention Patch represents the importance of the corresponding position in the input image. However, most papers apply attention to feature maps in the middle of the neural network rather than the original image.

Is there a paper describing that the output of each patch in the Attention Map is an Attention at the corresponding position in the actual input image?

In extreme cases, I think the pattern at the top of the actual input image may emphasize the patch at the bottom of the Attention Map.",0,2
46,2018-3-12,2018,3,12,11,83rtzf,Deciding the architecture of a CNN,https://www.reddit.com/r/deeplearning/comments/83rtzf/deciding_the_architecture_of_a_cnn/,gunnvant,1520823108,"How does one decide the architecture of a CNN? In essence how to decide how many conv layers, how many pooling layers etc.

Also do people in general build CNNs from scratch or do they use  transfer learning + fine tuning with pre-trained models?",4,6
47,2018-3-12,2018,3,12,18,83troe,Ratings of Labs in Artificial Intelligence for Drug Discovery,https://www.reddit.com/r/deeplearning/comments/83troe/ratings_of_labs_in_artificial_intelligence_for/,mostafabenh,1520847899,,0,6
48,2018-3-12,2018,3,12,20,83u7yh,Time Series for Dummies,https://www.reddit.com/r/deeplearning/comments/83u7yh/time_series_for_dummies/,chris_shpak,1520853591,,0,7
49,2018-3-12,2018,3,12,21,83un0o,Using Microsoft AI to Build a Lung-Disease Prediction Model Using Chest X-Ray Images,https://www.reddit.com/r/deeplearning/comments/83un0o/using_microsoft_ai_to_build_a_lungdisease/,chris_shpak,1520858305,,1,18
50,2018-3-13,2018,3,13,1,83wgdb,LSTM Spam Detection,https://www.reddit.com/r/deeplearning/comments/83wgdb/lstm_spam_detection/,simpleuserhere,1520873588,,0,1
51,2018-3-13,2018,3,13,3,83x1d1,Dealing with large number of output classes,https://www.reddit.com/r/deeplearning/comments/83x1d1/dealing_with_large_number_of_output_classes/,the_bored_potato,1520877848,"How can I implement a deep neural network classifier, when the number of output classes is very large (in millions)? Normally I would use tf.nn.softmax_cross_entropy_with_logits and minimize it. But with millions of output classes, I am looking at equal number of neurons in the final layer. Is there a better way of doing this?

Thanks!",1,5
52,2018-3-13,2018,3,13,3,83x7og,Humble Book Bundle: A.I. by Packt includes several books about Deep Learning (partner),https://www.reddit.com/r/deeplearning/comments/83x7og/humble_book_bundle_ai_by_packt_includes_several/,sipolsa,1520879100,,3,19
53,2018-3-13,2018,3,13,17,842h3y,Deeplearning in R + RStudio.. would you recommend it ?,https://www.reddit.com/r/deeplearning/comments/842h3y/deeplearning_in_r_rstudio_would_you_recommend_it/,thegymnosophist,1520928341,"Google and Rstudio seem to have gone to some lengths to make deep learning with keras and tensorflow fairly painless in R

A talk outlining tensorflow in R : https://www.youtube.com/watch?v=atiYXm7JZv0
Code snippets : https://github.com/jjallaire/deep-learning-with-r-notebooks

My question is, is it worth investing some time in getting comfortable with this setup ? 

I personally prefer doing data science in R over Python, but I don't want to invest time in something that might be gone in 10 months. ",2,5
54,2018-3-13,2018,3,13,17,842jak,"How to Detect if Recognized Face (via Deep Learning) is actual face, not a picture of a face?",https://www.reddit.com/r/deeplearning/comments/842jak/how_to_detect_if_recognized_face_via_deep/,taewoo,1520929125,"How would you go about verifying that the face recognized is actually that of a person, instead of a photo on paper (or ipad or some other device)? I guess you can do some behavioral stuff like ask the person to do sequence of stuff like close eyes, open mouth, etc... but are there any ""DL""-ish way of solving this problem?

",6,3
55,2018-3-13,2018,3,13,17,842n07,"A docker container to make it easy to use your NVIDIA GPU with Tensorflow, Keras in R.",https://www.reddit.com/r/deeplearning/comments/842n07/a_docker_container_to_make_it_easy_to_use_your/,thegymnosophist,1520930538,,0,3
56,2018-3-13,2018,3,13,22,8445s1,Big Data Use Cases in the Fin-Tech Industry,https://www.reddit.com/r/deeplearning/comments/8445s1/big_data_use_cases_in_the_fintech_industry/,y-emre,1520947959,,0,2
57,2018-3-13,2018,3,13,23,844pyw,Deep Neural Network implemented in pure SQL over BigQuery,https://www.reddit.com/r/deeplearning/comments/844pyw/deep_neural_network_implemented_in_pure_sql_over/,chris_shpak,1520952661,,1,2
58,2018-3-14,2018,3,14,2,845u34,Real-time Distance Measurement Using Single Image,https://www.reddit.com/r/deeplearning/comments/845u34/realtime_distance_measurement_using_single_image/,[deleted],1520961032,[deleted],0,1
59,2018-3-14,2018,3,14,2,845x2z,Handwritten Multi-digit String Segmentation and Recognition using Deep Learning,https://www.reddit.com/r/deeplearning/comments/845x2z/handwritten_multidigit_string_segmentation_and/,tahaemara,1520961629,"Handwritten Multi-digit String Segmentation and Recognition using Deep Learning

Source code: https://github.com/emara-geek/multi-digit-segmentation-and-recognition

More Info: http://www.emaraic.com/blog/multi-digit-segmentation-and-recognition",0,1
60,2018-3-14,2018,3,14,4,846wb6,"The paper that introduces the Edward PPL by /u/dustintran et al, also an excellent intro to Deep PPLs in general.",https://www.reddit.com/r/deeplearning/comments/846wb6/the_paper_that_introduces_the_edward_ppl_by/,thegymnosophist,1520968786,,0,2
61,2018-3-14,2018,3,14,6,847pw4,Looking for someone with extensive deep learning (specifically LSTMs) experience for some guidance,https://www.reddit.com/r/deeplearning/comments/847pw4/looking_for_someone_with_extensive_deep_learning/,JustinQueeber,1520975392,"I am completing an academic research project in a deep learning application to the financial markets. So far, all I have been able to achieve is extreme overfitting with no improvement on my test set when compared with making random predictions.

I have tried many, many ways to avoid overfitting hoping to make some sort of meaningful predicitions - all with no luck. I am beginning to think that possibly there is an error in the way I have implemented my model, or it is doing something differently somewhere to what I think it is doing.

I have implemented everything using TensorFlow. I would be incredibly greatful if someone more experienced than myself would be able to take a look at my work and see if they can spot any issues.",4,1
62,2018-3-14,2018,3,14,7,8487wj,Simple Q: Can AI surpass it's training set?,https://www.reddit.com/r/deeplearning/comments/8487wj/simple_q_can_ai_surpass_its_training_set/,BallScratches,1520979316,"Hi, newb here. I'm just a few days in, so a lot is still unknown to me, but one basic question sticks out: can AI surpass it's training data?  
If my trainingdata is 90% accurate; will I always see results with an accuracy below 90%, not counting any flukes?  
If it is possible to go higher, how does that happen?  
Edit: I guess this question also depends on what the AI does, but take for this instance an example of detecting cats in images.",4,1
63,2018-3-14,2018,3,14,7,8487xg,"Very good introduction to Hamiltonian Monte Carlo, the engine that powers a lot of deep probabilistic programming languages",https://www.reddit.com/r/deeplearning/comments/8487xg/very_good_introduction_to_hamiltonian_monte_carlo/,thegymnosophist,1520979323,,0,11
64,2018-3-14,2018,3,14,8,848mam,Best CapsNet implementations in TensorFlow,https://www.reddit.com/r/deeplearning/comments/848mam/best_capsnet_implementations_in_tensorflow/,r2m2,1520982424,"Hi /r/deeplearning - I was looking for what is generally regarded as the best/reference implementation of Capsule Networks and the corresponding MNIST model that was given in Dynamic Routing Between Capsules (https://arxiv.org/abs/1710.09829). Preferably the implementation is relatively simple (i.e. biases more towards readability than optimizing the training time) and ideally in TensorFlow, though other frameworks are fine as well. ",0,3
65,2018-3-14,2018,3,14,8,848wu5,Beginner DL Computer,https://www.reddit.com/r/deeplearning/comments/848wu5/beginner_dl_computer/,bayesian_thought,1520985003,"I'm tempted to purchase this desktop as a intro rig while I get up to speed on deep learning with a GPU. I'd like to keep the beginner setup under $900 and don't won't to use cloud resources. Is this a good deal for the money? They have an open box one for $765 which seams like a solid price .

http://www.microcenter.com/product/484657/G11DF-DBR5-GTX1060_Desktop_Computer;_AMD_Ryzen_5_1400_Processor_32GHz;_NVIDIA_GeForce_GTX_1060_6GB;_8GB_DDR4_RAM;_1TB_HDD256GB_SSD;_Microsoft_Windows_",1,1
66,2018-3-14,2018,3,14,12,84a9y0,"Why VAE(variational auto encoder) encode an input image into mean and variance, rather than a point in a distribution(which is to be learned)?",https://www.reddit.com/r/deeplearning/comments/84a9y0/why_vaevariational_auto_encoder_encode_an_input/,boostsch,1520997825,"VAE encodes an input image to mean and variance to represent a statistical distribution, and resample a point in that distribution and decode that point to the original image. Finally, what is learned is the distribution for all input images, in which a point is a distribution of the corresponding input image. The problem is just here. Since the final purpose is to learn a statistical distribution of all input images, why not encode a single image to a point (x, y coordinates) in that distribution? Anyone can help? Thanks so much!",0,2
67,2018-3-14,2018,3,14,15,84b7nh,How I implemented iPhone Xs FaceID using Deep Learning in Python.,https://www.reddit.com/r/deeplearning/comments/84b7nh/how_i_implemented_iphone_xs_faceid_using_deep/,semi23,1521008067,,1,8
68,2018-3-14,2018,3,14,19,84cas0,Bitcoin price forecasting with deep learning algorithms,https://www.reddit.com/r/deeplearning/comments/84cas0/bitcoin_price_forecasting_with_deep_learning/,magneticono,1521022782,,6,7
69,2018-3-14,2018,3,14,21,84d2f7,"How to create snapchat-like filters in webapps with deep-learning based APIs...Here ""Luffy's hat"" in AR",https://www.reddit.com/r/deeplearning/comments/84d2f7/how_to_create_snapchatlike_filters_in_webapps/,StartupJeeliz,1521031296,,5,13
70,2018-3-15,2018,3,15,0,84e5si,What's the best way to pass in input from an image?,https://www.reddit.com/r/deeplearning/comments/84e5si/whats_the_best_way_to_pass_in_input_from_an_image/,swegmesterflex,1521040676,"I'm still trying to figure this out and I seem to have to do it on a case by case basis. What I mean by the question is how should I convert an image into data and then what should I do with that data before passing it to my network's input layer? I've tried various things that have resulted in convergence: making anything with a grayscale value above 150 1 and below 150 0, applying a modified sigmoid to the input data that pushes values below the median grayscale value of the image to 0 and values above the median to 1. Both of these worked but I could not achieve the same results by simply passing in the RGB values whether they be represented by a number in [0,1] or by a number in [0,255].",2,4
71,2018-3-15,2018,3,15,2,84fca9,Is Keras fit_generator method supposed to be slow ??,https://www.reddit.com/r/deeplearning/comments/84fca9/is_keras_fit_generator_method_supposed_to_be_slow/,atulsingh0,1521049495,"Hi Gurus, Working with Keras fit_generator method to fit the model but it is taking too much time to get trained, when researched I have found this ---

steps_per_epoch: Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch

I have trained the 2 models with same data with different no of steps_per_epochs (500 and 1) but in both training each epoch is taking same time (~570sec) where batch size is 128.  

Please correct me if my understanding wrong...
In first model, it ran for 570 secs to process 500 * 128 samples
but in second model, it ran for 570 secs to process 1 * 128 samples

any specific reasons why ? or I am messing with some bad config ?
",2,1
72,2018-3-15,2018,3,15,3,84fks8,Deep Learning for Gravitational Wave Detection,https://www.reddit.com/r/deeplearning/comments/84fks8/deep_learning_for_gravitational_wave_detection/,CuttingWithScissors,1521051240,,0,5
73,2018-3-15,2018,3,15,8,84i371,5-part video series explaining the intuition AND the math underlying backpropagation,https://www.reddit.com/r/deeplearning/comments/84i371/5part_video_series_explaining_the_intuition_and/,blackHoleDetector,1521070850,"- [Backpropagation explained | Part 1 - The intuition](https://youtu.be/XE3krf3CQls)
- [Backpropagation explained | Part 2 - The mathematical notation](https://youtu.be/2mSysRx-1c0)
- [Backpropagation explained | Part 3 - Mathematical observations](https://youtu.be/G5b4jRBKNxw)
- [Backpropagation explained | Part 4 - Calculating the gradient](https://youtu.be/Zr5viAZGndE)
- [Backpropagation explained | Part 5 - What puts the back in backprop?](https://youtu.be/xClK__CqZnQ)

This series is part of this [larger deep learning playlist](https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU).
",0,15
74,2018-3-15,2018,3,15,9,84i8gx,Deep Learning in medicine: how to segment vessels when you only have 6 images in training set,https://www.reddit.com/r/deeplearning/comments/84i8gx/deep_learning_in_medicine_how_to_segment_vessels/,tdionis,1521072204,,1,7
75,2018-3-15,2018,3,15,9,84i930,Probabilistic programming for n00bs.. a super simple introduction.,https://www.reddit.com/r/deeplearning/comments/84i930/probabilistic_programming_for_n00bs_a_super/,thegymnosophist,1521072379,,3,7
76,2018-3-15,2018,3,15,15,84kf0y,Introduction to Recurrent Neural Networks in Pytorch,https://www.reddit.com/r/deeplearning/comments/84kf0y/introduction_to_recurrent_neural_networks_in/,semi23,1521095374,,0,8
77,2018-3-15,2018,3,15,19,84letb,Deep Learning Summer schools 2018,https://www.reddit.com/r/deeplearning/comments/84letb/deep_learning_summer_schools_2018/,shidilrzf,1521109278,Does anyone know any good deep learning summer schools this year? Preferably in Europe...,2,7
78,2018-3-15,2018,3,15,19,84lfmg,TensorFlow: Building Feed-Forward Neural Networks Step-by-Step,https://www.reddit.com/r/deeplearning/comments/84lfmg/tensorflow_building_feedforward_neural_networks/,digitalson,1521109569,,0,6
79,2018-3-15,2018,3,15,22,84mb0i,Underwater Sonar Image dataset for deep learning,https://www.reddit.com/r/deeplearning/comments/84mb0i/underwater_sonar_image_dataset_for_deep_learning/,swagh1611,1521119196,"Hi!
I would really appreciate if someone can share underwater sonar image dataset or any links for downloading it.

Thanks!",0,2
80,2018-3-15,2018,3,15,22,84mgja,1 PDL (alpha): download and discover datasets with one line of code.,https://www.reddit.com/r/deeplearning/comments/84mgja/1_pdl_alpha_download_and_discover_datasets_with/,janvandepoel,1521120685,,0,5
81,2018-3-15,2018,3,15,22,84mkxe,Where to start ?,https://www.reddit.com/r/deeplearning/comments/84mkxe/where_to_start/,Ayerys,1521121832,"Im a student and one of our project is to build an OCR using a neural network in C. 

But the thing is that we just started to learn C (actually discovering pointers) and while I understand the general idea of a neural network I have no idea of how to implement it. I already looked online for ressources but either it was written 10 years ago (and maybe outdated ?) or either an OCR already written and I dont want to copy someone else code. 

So where to start ?",7,3
82,2018-3-16,2018,3,16,1,84nt2d,Demo using our computer vision (deep-learning based) in the browser. Github: https://github.com/jeeliz/jeelizFaceFilter Webapp: https://jeeliz.com/demos/faceFilter/demos/cesium/headControls/,https://www.reddit.com/r/deeplearning/comments/84nt2d/demo_using_our_computer_vision_deeplearning_based/,[deleted],1521131500,[deleted],1,1
83,2018-3-16,2018,3,16,2,84o48u,Ask for a Snapchap-like filter! Will make it available for the web.,https://www.reddit.com/r/deeplearning/comments/84o48u/ask_for_a_snapchaplike_filter_will_make_it/,StartupJeeliz,1521133810,,1,9
84,2018-3-16,2018,3,16,2,84o5jk,Unity ML-Agents v0.3 is now available!,https://www.reddit.com/r/deeplearning/comments/84o5jk/unity_mlagents_v03_is_now_available/,leonchenzhy,1521134077,,0,6
85,2018-3-16,2018,3,16,5,84phia, Supervisely v2.0: supercharge your training data pipeline with Deep Learning,https://www.reddit.com/r/deeplearning/comments/84phia/supervisely_v20_supercharge_your_training_data/,tdionis,1521144137,,0,7
86,2018-3-16,2018,3,16,11,84s0jd,Pattern of life activity using Deep Learning,https://www.reddit.com/r/deeplearning/comments/84s0jd/pattern_of_life_activity_using_deep_learning/,geodawg,1521165616,,0,4
87,2018-3-16,2018,3,16,15,84tiuz,Deep Learning to detect scene cuts,https://www.reddit.com/r/deeplearning/comments/84tiuz/deep_learning_to_detect_scene_cuts/,tiger287,1521182979,"I am trying a new use case currently, in the same grounds of audio speaker segmentation where we can train a deep neural network to understand when there is a change in the person currently speaking, I wish to create a model which can understand in a video if there is a scene cut. A scene cut can be defined as change in the context of what the people are talking about or change in the location. For eg : Take a popular TV show like game of thrones where many multiple stories go hand in hand. Given an episode I would like to cut it when a new scene comes. I know it's a very different use case but I am open to all the possible ideas . Let's ideate ! ",9,2
88,2018-3-16,2018,3,16,18,84u39x,Using Neural network for Simple Linear Regression problem,https://www.reddit.com/r/deeplearning/comments/84u39x/using_neural_network_for_simple_linear_regression/,joey_php,1521191293,"Hi
I have some experience with machine learning but new to NN. Is there any reason to use NN for simple linear regression problem? 

For example i have a dataset with pupils average grade as a target variable and age, height, weight as features  
can i build a NN to train my data and then predict new values?
is there any simple example for that ?
thanks",6,1
89,2018-3-16,2018,3,16,18,84u9zn,NIPS 2017  Day 1 Highlights,https://www.reddit.com/r/deeplearning/comments/84u9zn/nips_2017_day_1_highlights/,dearpetra,1521194155,,0,4
90,2018-3-16,2018,3,16,19,84uewq,Deep Learning 101: Using Apache MXNet on the Edge With Sensors and Intel Movidius,https://www.reddit.com/r/deeplearning/comments/84uewq/deep_learning_101_using_apache_mxnet_on_the_edge/,chris_shpak,1521195878,,0,3
91,2018-3-16,2018,3,16,19,84uj95,A history of machine translation from the Cold War to deep learning,https://www.reddit.com/r/deeplearning/comments/84uj95/a_history_of_machine_translation_from_the_cold/,janemoz,1521197426,,0,9
92,2018-3-16,2018,3,16,22,84vg9s,"Bus Lane Blocked, He Trained His Computer to Catch Scofflaws",https://www.reddit.com/r/deeplearning/comments/84vg9s/bus_lane_blocked_he_trained_his_computer_to_catch/,keghn,1521207340,,0,1
93,2018-3-16,2018,3,16,22,84vims,PCI-e lanes for deep learning rig,https://www.reddit.com/r/deeplearning/comments/84vims/pcie_lanes_for_deep_learning_rig/,arc144,1521207953,"Hi, I'm buying a deep learning PC and have some doubts about the PCI-e lanes required. I intend to buy a PC with following specs:
GPU: Geforce 1080ti
Memory: 16RAM
CPU: Intel i7 6800k
Motherboard: Gigabyte GA-X99-UD3P DDR4 LGA 2011-V3, Chipset Intel X99
PSU: 600W

Right now I intend to use only one GPU card, however I want a rig that can support a second GPU card later on. 

From what I've seen, the motherboard supplies the 2 PCI-e with x16 lanes each that would be required for the 2 GPUs. However, the I7-6800k only have 28 PCI-e lanes. How this affect general performance? Should I change the processor?

Thanks
",4,1
94,2018-3-17,2018,3,17,3,84xhk7,AI Weekly 16 Mar 2018,https://www.reddit.com/r/deeplearning/comments/84xhk7/ai_weekly_16_mar_2018/,TomekB,1521223736,,0,7
95,2018-3-17,2018,3,17,3,84xkuj,"what is your personal list of the 10 most important _fundamental_ , canonical data science problems that a beginner should address?",https://www.reddit.com/r/deeplearning/comments/84xkuj/what_is_your_personal_list_of_the_10_most/,ezeeetm,1521224447,,0,0
96,2018-3-17,2018,3,17,16,852aac,A good place to discuss the inside &amp; maths of deep learning?,https://www.reddit.com/r/deeplearning/comments/852aac/a_good_place_to_discuss_the_inside_maths_of_deep/,anderl1980,1521271472,What is a good place to place some questions that refer to mathematics or particular coding issues?,3,4
97,2018-3-17,2018,3,17,16,852cze,Derivate of sigmoid function,https://www.reddit.com/r/deeplearning/comments/852cze/derivate_of_sigmoid_function/,anderl1980,1521272721,"I've stumbled across this a few times:
The derivative of the sigmoid function s(x) is ds(x)/dx = s(x) * (1 - s(x)) and not x * (1 - x), as shown in many blogs / code snippets.
What's wrong here? What am I not seeing?
See the code here: https://iamtrask.github.io/2015/07/12/basic-python-network/",4,1
98,2018-3-18,2018,3,18,0,854cb2,How do I combine features like word embeddings and sentiment polarity for text classification using LSTM neural networks?,https://www.reddit.com/r/deeplearning/comments/854cb2/how_do_i_combine_features_like_word_embeddings/,rafiya1908,1521299780,"Embeddings layer of LSTM is fed with the weights=embedding_matrix from the vocab, and model.fit has X_train which is the tokenized text data. My X_train has shape (12,000 , 100) and embeddings_matrix has shape (34613, 300) where 34613 are the number of tokens(vocab from complete data ~15000 sentences).

I created a sentiment_matrix associating a polarity -1/0/1 with every word of shape (34613, 1).

Given the sentiment polarity is a per word information(just like embeddings are), how do I prepare the sentiment feature, and how to give this as input to the neural network?

I looked up the keras functional API https://keras.io/getting-started/functional-api-guide/ But I couldn't get it to work, so please help.",0,6
99,2018-3-18,2018,3,18,3,855if0,Autonomous Driving  Car detection with YOLO Model with Keras in Python,https://www.reddit.com/r/deeplearning/comments/855if0/autonomous_driving_car_detection_with_yolo_model/,psangrene,1521310267,,1,9
100,2018-3-18,2018,3,18,3,855t1e,Multiple digits MNIST and transfer learning,https://www.reddit.com/r/deeplearning/comments/855t1e/multiple_digits_mnist_and_transfer_learning/,_data_scientist_,1521312755,"I have a sample of 50,000 images, some of which are shown below:

[[Picture 1][1]][1] 
 [[Picture 2][2]][2] [[Picture 3][3]][3] [[Picture 4][4]][4] [[Picture 5][5]][5]

Associated to these images are labels for the digit with the largest pixel size. My goal is to build a machine learning model to predict the largest digit in an image by pixel size.

To that end, I used transfer learning on the resnext model, but only found an accuracy of 60%.

Given that [this](https://github.com/kkweon/mnist-competition) implementation uses transfer learning to train a model to predict MNIST digits, I would now like to crop each training image to retain only the largest digit and then train the model using the [linked](https://github.com/kkweon/mnist-competition) implementation.

So, my question is, how I do crop the training images to retain only the digit in each image with the largest size.


  [1]: https://i.stack.imgur.com/Vy4Is.png
  [2]: https://i.stack.imgur.com/zZiuY.png
  [3]: https://i.stack.imgur.com/Ar8QI.png
  [4]: https://i.stack.imgur.com/X0kkG.png
  [5]: https://i.stack.imgur.com/f4UbB.png",2,1
101,2018-3-18,2018,3,18,5,856fpx,LSTM2.py - Automated Forex Trading Script,https://www.reddit.com/r/deeplearning/comments/856fpx/lstm2py_automated_forex_trading_script/,TheGuru12,1521318373,,6,1
102,2018-3-18,2018,3,18,8,857ogb,"Baidu releases Apollo Scape, possibly the world's largest dataset for autonomous driving",https://www.reddit.com/r/deeplearning/comments/857ogb/baidu_releases_apollo_scape_possibly_the_worlds/,italo3d,1521330428,,3,24
103,2018-3-18,2018,3,18,18,85a8vz,Learning Distributed Word Representations with Neural Network: an implementation from scratch in Octave,https://www.reddit.com/r/deeplearning/comments/85a8vz/learning_distributed_word_representations_with/,[deleted],1521364521,[deleted],0,0
104,2018-3-19,2018,3,19,3,85d0gw,[Porcupine] On-device wake word detection engine powered by deep learning.,https://www.reddit.com/r/deeplearning/comments/85d0gw/porcupine_ondevice_wake_word_detection_engine/,aanhari,1521397153,,0,3
105,2018-3-19,2018,3,19,7,85exg1,Facial Keypoints Model (2016) Questions,https://www.reddit.com/r/deeplearning/comments/85exg1/facial_keypoints_model_2016_questions/,rambossa1,1521413774,"Hey all, 

&amp;nbsp;

I have a few questions related to this model from 2016: (you'll need to translate if you don't read Japanese)

https://elix-tech.github.io/ja/2016/06/02/kaggle-facial-keypoints-ja.html

(it is based off of a 2014 model here: http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/)

&amp;nbsp;

1) This is from 2016, &amp; subsequently 2014, models that use CNN &amp; methods like Dropout... are there better-known, but still simple, ways to implement this model now in 2018?

&amp;nbsp;

2) Is a larger training set better for overfitting here? One method used in the model is to randomly horizontally flip the images and keypoints--but keeping the same data size. What if I have a training set that already includes the flipped images &amp; keypoints... would it be better for those to be randomly generated in training vs including them in the larger dataset?

&amp;nbsp;

3) Suppose I want to apply facial keypoints model to video, is there a more efficient way to do this vs running the model on individual frames?",1,3
106,2018-3-19,2018,3,19,15,85hi7y,Time to train a VGG model,https://www.reddit.com/r/deeplearning/comments/85hi7y/time_to_train_a_vgg_model/,_data_scientist_,1521441774,How long does it take to train a VGG16 model on MNIST data using a single GPU?,6,2
107,2018-3-20,2018,3,20,4,85m9f2,Is it possible to using deep learning on a Mac?,https://www.reddit.com/r/deeplearning/comments/85m9f2/is_it_possible_to_using_deep_learning_on_a_mac/,Noahwar97,1521487751,I love my Mac very much but I use it for personal things (Im a college student studying electrical and computer engineering). Ive found some programs online like tensorflow and theano but they dont seem to work with any Mac. Is there any way to make it work?,7,0
108,2018-3-20,2018,3,20,8,85o0b3,Anyone know of a pre-trained model on car classification in Tensorflow?,https://www.reddit.com/r/deeplearning/comments/85o0b3/anyone_know_of_a_pretrained_model_on_car/,Talos19,1521501053, I am looking for a model which is pre-trained on car classification dataset (preferably CompCar dataset) in Tensorflow. I couldn't find it by google search or on Tensorflow models. Please let me know. Thank you.  ,3,5
109,2018-3-20,2018,3,20,9,85oq8x,Trouble Running RNN LSTM tutorial on Adventuresmachinelearning,https://www.reddit.com/r/deeplearning/comments/85oq8x/trouble_running_rnn_lstm_tutorial_on/,Delengowski,1521507214,"Hi, ML student, trying to run this tutorial 

http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/

I am getting the error 

usage: lstm.py [-h] [--data_path DATA_PATH] run_opt
lstm.py: error: the following arguments are required: run_opt

I'm new to python, I have anaconda3 installed with python 3.6, CUDA, cuDNN, and tensorflow installed. Whether I run this through sublime text or pycharm I am getting this error. I copied his code directly from the git. 

I've also charged the file path as per the instructions. I can only find two instances of run_opt in the entire .py file. 

https://github.com/adventuresinML/adventures-in-ml-code/blob/master/lstm_tutorial.py",0,3
110,2018-3-20,2018,3,20,10,85owce,"Intel AI: nGraph, A New Open Source Compiler for Deep Learning Systems",https://www.reddit.com/r/deeplearning/comments/85owce/intel_ai_ngraph_a_new_open_source_compiler_for/,dayman56,1521508712,,0,27
111,2018-3-20,2018,3,20,16,85qxbf,IBM launches deep learning as a service inside its Watson Studio - Scribble &amp; Scroll,https://www.reddit.com/r/deeplearning/comments/85qxbf/ibm_launches_deep_learning_as_a_service_inside/,Scribble_Scroll,1521531622,,0,1
112,2018-3-20,2018,3,20,19,85rpx8,How to efficiently load input images,https://www.reddit.com/r/deeplearning/comments/85rpx8/how_to_efficiently_load_input_images/,stargrazie,1521542407,"Hello everyone, 
I am working on diabetic retinopathy detection , which use to be a competition on kaggle.
Currently I am simply running a loop, reading  all 35 thousand images from csv file and then finding them in the train folder, converting it into a numpy array and storing it. 

Is there a fast and efficient way to load data ?
I tried flow from directory(keras) but since my father is not divided into folders by class it didn't work out. 

Any help would be appreciated, thank you !
",5,3
113,2018-3-20,2018,3,20,22,85sjsw,How to Build a Great Data Product?,https://www.reddit.com/r/deeplearning/comments/85sjsw/how_to_build_a_great_data_product/,y-emre,1521551164,,0,0
114,2018-3-20,2018,3,20,22,85st0s,Any legacy deep learning environment for a Windows computer with a NVS 300 GPU and CUDA 6.5?,https://www.reddit.com/r/deeplearning/comments/85st0s/any_legacy_deep_learning_environment_for_a/,ragnarkar,1521553494,"This is my main workstation at work. I found out that the NVS 300 cards aren't supported by CUDA beyond 6.5.

The lowest version of Tensorflow on Pip is 1.0 but even that requires CUDA 8 for the GPU version.  I also tried compiling Tensorflow (current and older versions) to no avail plus tried versions 0.8 - 1.0 of Theano. Not sure about MS CNTK.

Does there exist any deep learning environments for Windows that can use this GPU even though it's outdated?  Its not a big deal but it's more for convenience.",4,3
115,2018-3-20,2018,3,20,22,85su23,Image normalization for training an object detector...?,https://www.reddit.com/r/deeplearning/comments/85su23/image_normalization_for_training_an_object/,Boxsc2,1521553753,"I'm using the Tensorflow object detection API to train an object detector. I am getting good results. However, I have noticed the object detector (SSD) can often have a ""flickering"" effect when I process a video. Even though visually the object is not moving and there is very little difference I see the detections per frame are somewhat variable. 

From my understanding, this can be due to noise in the image which is not visible to the human eye but is present in the input image tensor to the object detector. Are there any techniques for minimizing this effect? 

I found [this](https://github.com/aleju/imgaug) library for image preprocessing, but I'm uncertain about to what to actually do to each image before I train or predict...",0,1
116,2018-3-20,2018,3,20,23,85syyj,MALE/FEMALE database images,https://www.reddit.com/r/deeplearning/comments/85syyj/malefemale_database_images/,Moni93,1521554876,"Hello!
I have been wondering if it is possible to find a database with male and female images.
I did a quick research online, but i didn't find anything..Do you think it is something available online (for free) ?",2,1
117,2018-3-21,2018,3,21,1,85u0vj,AI2 - An Efficient System for Verifying Safety Critical Neural Networks,https://www.reddit.com/r/deeplearning/comments/85u0vj/ai2_an_efficient_system_for_verifying_safety/,mmirman,1521563024,,0,10
118,2018-3-21,2018,3,21,1,85u224,Automated front-end development using deep learning,https://www.reddit.com/r/deeplearning/comments/85u224/automated_frontend_development_using_deep_learning/,e_ameisen,1521563251,,1,13
119,2018-3-21,2018,3,21,15,8604yf,Using doc2vec to cluster news headlines,https://www.reddit.com/r/deeplearning/comments/8604yf/using_doc2vec_to_cluster_news_headlines/,gunnvant,1521615570,"I read about doc2vec and to further my understanding I used a kaggle data set of news headlines to train doc vectors. Now this dataset is already tagged, categorizing each news item to 4 categories. With my document vectors, I am getting good results when I check them using cosine similarity. For example if I use cosine similarity to find headlines similar to a given headline and if the headline I am checking for is sports related, I get other similar headlines that are sports related

This got me thinking and I experimented further by creating a kmeans cluster model on these document vectors. I was expecting to see   all headlines of one category being assigned a unique cluster. But that is not happening, in each cluster created by kmeans I am getting articles of all categories, though there is one category that is always dominant (60 to 70%) in each of the clusters. 

Why would clustering algorithm fail to place documents of each category in separate clusters in this document vector space?

Is it possible to use clustering in the manner I described above to group documents by theme, in the document vector space?

I have used sklearn's and nltk implementations of kmeans. Tried to use dbscan but my corpus is large and I am getting memory errors.",4,8
120,2018-3-21,2018,3,21,18,860ne7,Issue: Model Classification cats and dogs (keras): Constant result for training and test.,https://www.reddit.com/r/deeplearning/comments/860ne7/issue_model_classification_cats_and_dogs_keras/,Moni93,1521622855,"I am trying to build a model that classifies cats and dogs, something that should not be a real problem. So, here what I am doing:
I created a folder with two labeled subfolders: cats and dogs. In each folder I have 1000 image of cats/dogs.
I built iteratively an numpy array in which I put my images after converting them to arrays ( I have chosen (200,200,3) size for each image) and I have up-scaled the array by dividing it by 255. So I got a (2000,200,200,3) up-scaled array.
Then, I create an array for the labels. Since I have two categories, I will have 2 biniary digits for each row of the array: (1,0) if cat and (0,1) if a dog. So I found myself with a (2000,2) array of labels.
Next, I create X_train,Y_train and X_valid,Y_valid ( 70% for train and 30% for valid).
Then I create a neural network with this architecture:
Dense(200x200x3,1000,relu)&gt;&gt;&gt; Dense(1000,500,sigmoid)&gt;&gt;&gt;Dense(500,100,sigmoid)&gt;&gt;&gt;Dense(100,2,softmax) : BACKPROP:loss=categorical_crossentropy,optimizer=adam.

Till now, everything looks fine, the model is trained. But then, when I try to predict values: the model always gives back the same value whatever is the input ( even if i try to predict elements with the training set , i always get the same constant output= array([[0.5188029 , 0.48119715]] )

I do really need help, i don't know why this is happening.. So in order to guide you guys I'll write down all the code corresponding to what I did:
I explained everything in stackoverflow: i will give you the link to the page because I can't add code in reddit (it will not be readable)

https://stackoverflow.com/questions/49395327/issue-model-classification-cats-and-dogs-keras",10,1
121,2018-3-22,2018,3,22,3,864noj, Releasing Supervisely Person dataset for teaching machines to segment humans,https://www.reddit.com/r/deeplearning/comments/864noj/releasing_supervisely_person_dataset_for_teaching/,tdionis,1521658065,,1,8
122,2018-3-22,2018,3,22,6,86678s,Is dropout better than dithering?,https://www.reddit.com/r/deeplearning/comments/86678s/is_dropout_better_than_dithering/,BallScratches,1521669039,"At the moment I'm using dithering on my images and it works great. Lot of underfitting before, not anymore.  
I figure dropout and dithering lead to the same result, but my guess would be that dropout is more efficient.. Is that correct?  
Dropout also takes a lot less time to prepare (dithering the images), and you wouldn't need additional memory.  
So is dithering still relevant then?",4,5
123,2018-3-22,2018,3,22,7,866qq6,Line-by-line annotation of fchollet's text generation code,https://www.reddit.com/r/deeplearning/comments/866qq6/linebyline_annotation_of_fchollets_text/,vitrifyher,1521673136,,4,6
124,2018-3-22,2018,3,22,20,86ao1g,Demystifying Docker for Data Scientists  A Docker Tutorial for Your Deep Learning Projects,https://www.reddit.com/r/deeplearning/comments/86ao1g/demystifying_docker_for_data_scientists_a_docker/,dearpetra,1521716769,,4,15
125,2018-3-22,2018,3,22,20,86arni,Data Speaker Series: Kevin Ferguson on AlphaGo Zero,https://www.reddit.com/r/deeplearning/comments/86arni/data_speaker_series_kevin_ferguson_on_alphago_zero/,janemoz,1521718031,,0,3
126,2018-3-23,2018,3,23,7,86flx8,"Deep learning, a field in machine learning is experiencing a great and fairly sudden storm of enthusiasm and excitement after over twenty years of relative quietness. The AI industry has spurred countless investments and acquisitions over the past years.",https://www.reddit.com/r/deeplearning/comments/86flx8/deep_learning_a_field_in_machine_learning_is/,NinaMJ,1521756981,,0,2
127,2018-3-23,2018,3,23,10,86h3c7,using Bayesian optimization in practice?,https://www.reddit.com/r/deeplearning/comments/86h3c7/using_bayesian_optimization_in_practice/,adsada1231,1521769865,"I recently read some papers about automatic tuning of hyperparameters using Bayesian optimization.  I know traditionally people typically using grid search or random search since they are easier to parallelize.  Just wondering is Bayesian optimization a popular method currently for tuning hyperparameters in practice or people still use grid/random search?

Thank you!",2,8
128,2018-3-23,2018,3,23,17,86j0nw,Speed up labeling by detecting similar objects in a neural network?,https://www.reddit.com/r/deeplearning/comments/86j0nw/speed_up_labeling_by_detecting_similar_objects_in/,josealb,1521792580,"I am trying to train CNNs to find objects which are not found in the typical computer vision datasets.

I think this is time consuming because I will have to label all objects by hand (at most using video tracking)

I thought maybe it is possible to train a neural net to detect similar objects? Then it shows the user all the kinds of objects it found in the data, and then the user selects the one he is interested in, maybe uses the data to train a more conventional object detector.

I don't know if this is possible though, I wouldn't know how to train it, especially because most objects of the same class will be found in different pictures. Is there some work in this direction?",1,1
129,2018-3-23,2018,3,23,17,86j4k1,Coding Wont Cut It: How to increase your deep learning skills,https://www.reddit.com/r/deeplearning/comments/86j4k1/coding_wont_cut_it_how_to_increase_your_deep/,Batareika_1,1521794162,,0,1
130,2018-3-23,2018,3,23,20,86k01g,"Deep Learning from first principles in Python, R and Octave  Part 5",https://www.reddit.com/r/deeplearning/comments/86k01g/deep_learning_from_first_principles_in_python_r/,tvganesh,1521805716,,0,1
131,2018-3-23,2018,3,23,21,86kcby,Automating Breast Cancer Detection with Deep Learning,https://www.reddit.com/r/deeplearning/comments/86kcby/automating_breast_cancer_detection_with_deep/,molode,1521809163,,0,4
132,2018-3-23,2018,3,23,23,86l1o7,Running Tensorflow on AMD Radeon Frontier Edition  r/Amd,https://www.reddit.com/r/deeplearning/comments/86l1o7/running_tensorflow_on_amd_radeon_frontier_edition/,[deleted],1521815367,[deleted],0,1
133,2018-3-23,2018,3,23,23,86l62h,What Comes After Deep Learning,https://www.reddit.com/r/deeplearning/comments/86l62h/what_comes_after_deep_learning/,psangrene,1521816325,,5,26
134,2018-3-24,2018,3,24,0,86liw9,Running Tensorflow on AMD Radeon Frontier Edition  r/Amd,https://www.reddit.com/r/deeplearning/comments/86liw9/running_tensorflow_on_amd_radeon_frontier_edition/,lonesail,1521819119,,0,5
135,2018-3-24,2018,3,24,2,86mbkw,One-shot object detection with Deep Learning,https://www.reddit.com/r/deeplearning/comments/86mbkw/oneshot_object_detection_with_deep_learning/,Lopelh,1521825117,,0,2
136,2018-3-24,2018,3,24,4,86nad2,AI Weekly 23 Mar 2018,https://www.reddit.com/r/deeplearning/comments/86nad2/ai_weekly_23_mar_2018/,TomekB,1521832438,,4,5
137,2018-3-24,2018,3,24,17,86rvst,Pretrained VGG16 for grayscale documents?,https://www.reddit.com/r/deeplearning/comments/86rvst/pretrained_vgg16_for_grayscale_documents/,FlatNut,1521881175,"Multiclass-Classifier of ~10k scanned documents, into ~10 classes:

Using VGG-16 pretrained on ImageNet and fine tune it after reading in papers it outperformed others (around 90% accuracy on tobacco scanned documents). My approach is similar to the one starting in the middle of this page (Using the bottleneck features of a pre-trained network): https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html

I'd much appreciate your help with two issues:

1. Pretrained VGG-16 architecture and weights are initialized for 3 channels, and running my model on (mostly) grayscale documents loaded as RGB images achieved around 45% accuracy (with 10 classes). What is the optimal way to spread the 1-channel vectors across RGB to maintain important features? Is there a suitable way to apply this while using Keras's ImageDataGenerator for augmentation? 

2. What other techniques would you recommend trying for scanned documents? Such as splitting the document to parts and creating an ensemble of networks for each part? (Please note that OCR performed weakly here)",3,7
138,2018-3-25,2018,3,25,3,86v376,Derivative and Double Derivative to check the minima of a function?,https://www.reddit.com/r/deeplearning/comments/86v376/derivative_and_double_derivative_to_check_the/,aaditkapoor1201,1521917486,I want to ask why cant we just differentiate the function and perform the double derivative test to repeatedly check for minimum values in a simple neural network?,4,1
139,2018-3-25,2018,3,25,21,870hfg,Anyone interested in a reading group for PRML?,https://www.reddit.com/r/deeplearning/comments/870hfg/anyone_interested_in_a_reading_group_for_prml/,adsada1231,1521982255,"I am currently reading PRML and just roughly finished first two chapters. Just wondering if anyone is interested in an online reading group that we could possibly share some notes and discuss questions?

My current plan is to spend about 1-3 weeks on each chapter, depending on the difficulty. For each chapter, one of the group member would need to post a bullet-point notes to cover the key points of the chapter, and discuss questions you have when reading the text, or exercise problems if you wish.

Let me know if you are interested, any suggestions/comments will be welcomed!  

UPDATE: I just created a subreddit for the reading group: https://www.reddit.com/r/PRML_reading/.   Go ahead to vote and discuss how to make it happen there!  Thanks!",23,7
140,2018-3-25,2018,3,25,22,870mgr,"Deep learning, a field in machine learning is experiencing a great and fairly sudden storm of enthusiasm and excitement after over twenty years of relative quietness. The AI industry has spurred countless investments and acquisitions over the past years.",https://www.reddit.com/r/deeplearning/comments/870mgr/deep_learning_a_field_in_machine_learning_is/,NinaMJ,1521983978,,0,1
141,2018-3-26,2018,3,26,0,871g0o,"Can a neural network do supervised, unsupervised , reinforcement learning simultaneously?",https://www.reddit.com/r/deeplearning/comments/871g0o/can_a_neural_network_do_supervised_unsupervised/,aaditkapoor1201,1521992421,,2,0
142,2018-3-26,2018,3,26,2,8725xb,Can we use Linear Programming to minimise a given cost function?,https://www.reddit.com/r/deeplearning/comments/8725xb/can_we_use_linear_programming_to_minimise_a_given/,aaditkapoor1201,1521998654,,2,1
143,2018-3-26,2018,3,26,2,872bs0,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/deeplearning/comments/872bs0/are_you_interested_in_ai_and_want_to_start/,DiscoverAI,1522000042,,1,1
144,2018-3-26,2018,3,26,18,877syz,Facebook using GANs?,https://www.reddit.com/r/deeplearning/comments/877syz/facebook_using_gans/,MetabolismZeitgeist,1522056475,I read somewhere that facebook is extensively using GANs. Does anyone know where and how it is using them?,6,6
145,2018-3-26,2018,3,26,19,877yct,A list of papers and other resources on Generative Adversarial (Neural) Networks,https://www.reddit.com/r/deeplearning/comments/877yct/a_list_of_papers_and_other_resources_on/,joey_php,1522058568,,0,4
146,2018-3-27,2018,3,27,3,87b8nv,11 Javascript Machine Learning Libraries To Use In Your App,https://www.reddit.com/r/deeplearning/comments/87b8nv/11_javascript_machine_learning_libraries_to_use/,JSislife,1522087550,,0,9
147,2018-3-27,2018,3,27,7,87dj6t,PacGAN Interview with Sewoong Oh (UIUC) and Zinan Lin (CMU),https://www.reddit.com/r/deeplearning/comments/87dj6t/pacgan_interview_with_sewoong_oh_uiuc_and_zinan/,alexmlamb,1522105032,,0,3
148,2018-3-27,2018,3,27,17,87gx0g,Using deep learning to model the hierarchical structure and function of a cell,https://www.reddit.com/r/deeplearning/comments/87gx0g/using_deep_learning_to_model_the_hierarchical/,eleitl,1522141151,,3,15
149,2018-3-27,2018,3,27,20,87hld4,"Best of arXiv.org for AI, Machine Learning, and Deep Learning  February 2018",https://www.reddit.com/r/deeplearning/comments/87hld4/best_of_arxivorg_for_ai_machine_learning_and_deep/,chris_shpak,1522149531,,0,24
150,2018-3-27,2018,3,27,20,87hmo5,The History of Data Mining,https://www.reddit.com/r/deeplearning/comments/87hmo5/the_history_of_data_mining/,y-emre,1522149930,,0,3
151,2018-3-27,2018,3,27,23,87iqcn,"Can't exactly hear what Christopher says right before PCA, what factor is he talking about? Thanks",https://www.reddit.com/r/deeplearning/comments/87iqcn/cant_exactly_hear_what_christopher_says_right/,fuck_your_diploma,1522160112,,4,7
152,2018-3-27,2018,3,27,23,87iwh6,Choicie of normalzation (upscaling) method of data,https://www.reddit.com/r/deeplearning/comments/87iwh6/choicie_of_normalzation_upscaling_method_of_data/,Moni93,1522161386,"I have a set of RGB images ( 200x200x200). I need to upscale them before feeding them to the neuran netowrk. The big question is: 
Does the method of upscaling influence something?If so, is there an 'absolute' best upscaling methode to be used ? 
PS:I am already familiar with upscaling methods , so what i want to know here is if the choice has an impact, and if so, it does have an impact on what?

Thanks in advance.
",2,1
153,2018-3-28,2018,3,28,5,87m304,How do residual connections affect the convolutional filters learned?,https://www.reddit.com/r/deeplearning/comments/87m304/how_do_residual_connections_affect_the/,slala2121,1522184085,"According to the cs231 tutorial (http://cs231n.github.io/understanding-cnn/), the 1st layer filters should be interpretable. 

Does this hold true when residual connections are used?",1,4
154,2018-3-28,2018,3,28,20,87r5xl,Exploring DeepFakes,https://www.reddit.com/r/deeplearning/comments/87r5xl/exploring_deepfakes/,dearpetra,1522236834,,0,16
155,2018-3-29,2018,3,29,11,87xshv,Libratus  The AI that Defeated Humans in the Game of Poker,https://www.reddit.com/r/deeplearning/comments/87xshv/libratus_the_ai_that_defeated_humans_in_the_game/,Michael_Pa,1522290620,,0,1
156,2018-3-29,2018,3,29,21,880qwf,Planning chemical syntheses with deep neural networks and symbolic AI  r/chemistry,https://www.reddit.com/r/deeplearning/comments/880qwf/planning_chemical_syntheses_with_deep_neural/,eleitl,1522325483,,0,3
157,2018-3-29,2018,3,29,21,880z4d,Messed up validation accuracy &amp; loss - overfitting or something else?,https://www.reddit.com/r/deeplearning/comments/880z4d/messed_up_validation_accuracy_loss_overfitting_or/,crowoy,1522327666,,11,1
158,2018-3-29,2018,3,29,22,88176w,Catch me if you can: A simple english explanation of GANs or Dueling neural-nets,https://www.reddit.com/r/deeplearning/comments/88176w/catch_me_if_you_can_a_simple_english_explanation/,dearpetra,1522329641,,0,2
159,2018-3-29,2018,3,29,22,8819yq,"Demystifying Neural Networks, Deep Learning, Machine Learning, and Artificial Intelligence",https://www.reddit.com/r/deeplearning/comments/8819yq/demystifying_neural_networks_deep_learning/,tanmoyray01,1522330317,,0,1
160,2018-3-29,2018,3,29,22,881ene,"Hi guys, did anyone complete this book http://neuralnetworksanddeeplearning.com/? If so, how much time did it take to complete along with working the problems?",https://www.reddit.com/r/deeplearning/comments/881ene/hi_guys_did_anyone_complete_this_book/,mutobikumail,1522331438,,0,0
161,2018-3-29,2018,3,29,23,881jqk,"In this article, I explain about Deep Learning in extreme Laymans terms. No mathematical equations to scare you away. This will serve as a starting point for anyone venturing into their Deep Learning journey.",https://www.reddit.com/r/deeplearning/comments/881jqk/in_this_article_i_explain_about_deep_learning_in/,GlazingFlakes,1522332575,,0,4
162,2018-3-30,2018,3,30,0,881ywa,YOLO v3 Release!,https://www.reddit.com/r/deeplearning/comments/881ywa/yolo_v3_release/,onmywaytostealyagirl,1522335759,,4,37
163,2018-3-30,2018,3,30,1,882sn1,"For most of us, when we hear the word AI, the first picture that comes to our mind is that of a human-like Robot from one of those sci-fi movies which talks to humans and takes orders. But have you ever imagined how those robots understand what we say?",https://www.reddit.com/r/deeplearning/comments/882sn1/for_most_of_us_when_we_hear_the_word_ai_the_first/,[deleted],1522341788,[deleted],0,2
164,2018-3-30,2018,3,30,7,885hl8,"Can I combine machine learning frameworks like scikit learn, tensorflow and keras to solve a particular problem.",https://www.reddit.com/r/deeplearning/comments/885hl8/can_i_combine_machine_learning_frameworks_like/,aaditkapoor1201,1522362056,,5,0
165,2018-3-30,2018,3,30,18,88964p,Looking for classification architectures that focus on getting high precision/How would I go about designing a Loss Function that focus on Precision [Question],https://www.reddit.com/r/deeplearning/comments/88964p/looking_for_classification_architectures_that/,algo_rithm,1522402813,"I'm working with some time series data with high (binary) class imbalance where the accuracy isn't particularly important. However, precision is very important. 

IE I want the True Positive/(True Positive + False Positive Rate) to be as high as possible. 

Are there any architectures like this that exist? If not, how would I go about modifying existing architectures to focus on precision?

Literally the only important factor I'm looking for is high precision. Even if it only detects 10% of True Positive Events, those True Positive events must be as correct as possible.",6,0
166,2018-3-30,2018,3,30,22,88agnq,Bilinear sampler at loss calculation pytorch,https://www.reddit.com/r/deeplearning/comments/88agnq/bilinear_sampler_at_loss_calculation_pytorch/,alwynmathew,1522417751,"I used [differentiable bilinear sampler](https://github.com/alwynmathew/bilinear-sampler-pytorch) from [STN](https://arxiv.org/pdf/1506.02025.pdf) during loss calculation in my model as below:

`mask = model(input)`   
`output = bilinear_sampler(input, mask)`  
`loss = loss_cal(input, output)`

Will the gradient flow automatically when `loss.backward()` is called?

`model.optimizer.zerograd()`    
`loss.backward()`  
`model.optimizer.steps()`

Should I write `backward()` function separately for this model? Thank you.",0,2
167,2018-3-31,2018,3,31,3,88cksa,AI Weekly 30 Mar 2018,https://www.reddit.com/r/deeplearning/comments/88cksa/ai_weekly_30_mar_2018/,TomekB,1522434602,,0,6
168,2018-3-31,2018,3,31,13,88gbrk,Multi object tracking for autonomous driving using 3D lidar data.,https://www.reddit.com/r/deeplearning/comments/88gbrk/multi_object_tracking_for_autonomous_driving/,gudhe01,1522469909,"Hello everyone, i'm working on multi target tracking using lidar sensor data. My question is can we use Capsule nets for this task. Any suggestions or idea's highly appreciated.  My idea is to implement capsule nets for object detection and RNN for tracking. Any pointers to help me.",2,3
169,2018-3-31,2018,3,31,14,88gn9k,Looking for a facial description dataset,https://www.reddit.com/r/deeplearning/comments/88gn9k/looking_for_a_facial_description_dataset/,akanimax,1522473944,"Hello all! I am looking for a dataset that has images of faces as the X for the training and for the Y (labels), what I need is a simple natural language description of the facial features, viz. the nose type, lips, eyes, eyebrows, complexion, jaw size, etc.

I have been looking for such a dataset, but couldn't find an exact one. There are many face datasets classified on gender, there are datasets containing the keypoints of the face, but not like the one that I am looking for. Could you please point me to such a dataset if you guys are aware?",3,7
0,2018-4-1,2018,4,1,21,88qbyi,Pre-trained sparse weights for YOLOV2 and Baidu Deep speech 2,https://www.reddit.com/r/deeplearning/comments/88qbyi/pretrained_sparse_weights_for_yolov2_and_baidu/,mosheshahar,1522584160,"Hi,

I am looking to download pre-trained weight sets for networks trained for weight sparsity. Does anyone have a link or a source?

Thanks",0,5
1,2018-4-2,2018,4,2,2,88sd0t,Stabilizing Training of GANs Intuitive Introduction with Kevin Roth (ETH Zurich),https://www.reddit.com/r/deeplearning/comments/88sd0t/stabilizing_training_of_gans_intuitive/,alexmlamb,1522602985,,0,5
2,2018-4-2,2018,4,2,5,88tujz,Implementation of a CNN application on FPGA (HELP),https://www.reddit.com/r/deeplearning/comments/88tujz/implementation_of_a_cnn_application_on_fpga_help/,spookyboogy22,1522615331,"Hello guys, I am actually working on a project of image recognition by a deep convolutional neural network using FPGA, reading all those research papers made me lost and I really don't know from where should I begin and of course I do know how a neural network and its training work but the difficult part for me is the implementation, could you guys give me some suggestions, link of a helpful paper, steps to follow ...etc ? thank you",1,2
3,2018-4-2,2018,4,2,10,88vwd3,Entity extraction using deep learning,https://www.reddit.com/r/deeplearning/comments/88vwd3/entity_extraction_using_deep_learning/,dkarunakaran,1522633957,,0,8
4,2018-4-2,2018,4,2,17,88xvhg,A course-by-course review of Andrew Ng's Deep Learning specialization,https://www.reddit.com/r/deeplearning/comments/88xvhg/a_coursebycourse_review_of_andrew_ngs_deep/,wasabihater,1522658342,,0,10
5,2018-4-2,2018,4,2,19,88yc85,AI and digital forgery,https://www.reddit.com/r/deeplearning/comments/88yc85/ai_and_digital_forgery/,dayikkk,1522665149,,0,8
6,2018-4-2,2018,4,2,20,88yijz,A Weird Introduction to Deep Learning,https://www.reddit.com/r/deeplearning/comments/88yijz/a_weird_introduction_to_deep_learning/,digitalson,1522667499,,0,3
7,2018-4-3,2018,4,3,4,893ryg,Document classification strategy,https://www.reddit.com/r/deeplearning/comments/893ryg/document_classification_strategy/,chepetronix,1522696794,"Hi all! I have to design a model that classifies and performs OCR over a large collection of scanned documents in image format. There are around 10 different types of documents and depending on each type of document, a different set of information needs to be extracted. 
So, my question is, what would be your approach? Should I try to classify them as images and then perform OCR? Or OCR first and then classify depending on the text? A sequential model for this maybe?

Any insight would be appreciated!
",1,2
8,2018-4-3,2018,4,3,8,8967fu,"Do I still need to learn Caffe, or can I get by with Tensorflow and Keras?",https://www.reddit.com/r/deeplearning/comments/8967fu/do_i_still_need_to_learn_caffe_or_can_i_get_by/,krishnab75,1522710675,"Hey Folks, I am new to the deep learning world, but my background is in statistics. I had a question about libraries. So I love DIGITS and have been able to get the demos working, etc. So that is good. But I am having any amount of frustration with getting Caffe models to run in DIGITs because of some protobuf errors, etc. (Yes, I have consulted lots of stackexchange, nvidia forum, and github posts on issue).

Note, the only reason I did any work with Caffe was because many of the demos for Nvidia DIGITS are done in Caffe. 

Anyhow, this effort got me thinking about whether I really needed to learn all of the environments? I think DIGITS supports Caffe, Torch, and Tensorflow now, but even without DIGITS there is no reason to learn every library out there. A lot of my applications focus on CNNs for Object Detection in images, as well as some applications on textual analysis, etc. 

So I was not sure if I really needed to go through all of the trouble of getting every library installed and working, if I really was not going to use them all. Perhaps this is a good application of Zipf's law :). Of course, the folks on the forums have more experience with these libraries than I do, so I would defer to their judgement. Are there any big problems or limitations that I will run into if I focus on just TF and Keras? If I had to pick an additional library beyond this, which one should I choose?",0,1
9,2018-4-3,2018,4,3,12,898pag,Diabetic Retinopathy Detection,https://www.reddit.com/r/deeplearning/comments/898pag/diabetic_retinopathy_detection/,stargrazie,1522725426,"Hi guys, I have been working on this project for a while now. 
I have performed minimal image pre-processing, just data augmentation using Image Datagenerator from keras. 
Augmented the data to roughly extra 15k images per class. Thus making my data set to be 90k.
I have a CV of 5k images evenly split amount all 5 classes. 
I am using xavier initialization for weights, L2 regularization for class weights. Adam optimizer with a learning rate of 0.05. 
My architecture is similar to vgg 16. It has roughly 16 million parameters.

Unfortunately my model only predicts one class i.e 0. 
What should I do ? 
Any advice would be appreciated.",0,1
10,2018-4-3,2018,4,3,12,898tux,Diabetic retinopathy detection project,https://www.reddit.com/r/deeplearning/comments/898tux/diabetic_retinopathy_detection_project/,stargrazie,1522726035,"I have been working on this project for a while now. Would appreciate some help. 
My model isn't learning anything and only predicts one single class. 
The architecture is similar to vgg 16. 
I have used data augmentation to balance classes and also used class weights to give extra weightage to class 4/5 images. 
I am using relu activation function. 
i am initializing my weights using Xavier initialization and regularizing them using L2 regularization. 

There's minimal image processing only data augmentation using Image Datagenerator. 

What else can I do ? 
",3,0
11,2018-4-3,2018,4,3,14,89a5z4,How does the keras TimeDistributed Wrapper work internally?,https://www.reddit.com/r/deeplearning/comments/89a5z4/how_does_the_keras_timedistributed_wrapper_work/,akanimax,1522733231,"I have read the documentation of the TimeDistributed wrapper of keras. The shape information associated with the operation is clear. What I would like to know is if the wrapper applies the same set of weights to all the timesteps, or spawns different weights for different timesteps. 
If, the former is true, how does backpropagation take place through these ops?
Thank you!",2,3
12,2018-4-3,2018,4,3,20,89cyok,How Big Data Analytics is Transforming the Travel Industry,https://www.reddit.com/r/deeplearning/comments/89cyok/how_big_data_analytics_is_transforming_the_travel/,y-emre,1522756749,,0,1
13,2018-4-3,2018,4,3,21,89ddn2,Paper repro: Deep Metalearning using MAML and Reptile,https://www.reddit.com/r/deeplearning/comments/89ddn2/paper_repro_deep_metalearning_using_maml_and/,digitalson,1522759711,,0,3
14,2018-4-3,2018,4,3,23,89e8a2,How I train my models,https://www.reddit.com/r/deeplearning/comments/89e8a2/how_i_train_my_models/,csyrup,1522765159,,7,67
15,2018-4-3,2018,4,3,23,89efss,How to build a Neural Network with Keras,https://www.reddit.com/r/deeplearning/comments/89efss/how_to_build_a_neural_network_with_keras/,jackblun,1522766365,,0,3
16,2018-4-4,2018,4,4,6,89il7b,LSTM - loss goes down and then back up,https://www.reddit.com/r/deeplearning/comments/89il7b/lstm_loss_goes_down_and_then_back_up/,crowoy,1522789404,"Attempting to train an LSTM - the loss seems to decrease sharply over the first ~50 epochs and the gradually increases continuously for the next ~1000 epochs.

I've been informed regularisation is a possible solutions. I've tried 20% dropout, 20% recurrent dropout, and then 20% of both. All of these options increase the values seen for loss, and the same shape of the graph is seen as well.

I've also been told to try L1 and L2 regularisation. But the LSTM section on Keras (https://keras.io/layers/recurrent/) seems to have 4 different types of regularisers:

- recurrent regulariser
- kernel regulariser
- activity regulariser
-bias regulariser

I'm really unsure on which ones to go about starting with, and with what values. As my network takes a long time to train in each case, an exhaustive search method is not feasible.",1,1
17,2018-4-4,2018,4,4,16,89nbx4,"Hey, guys, I created ML Jobs List, what do you think?",https://www.reddit.com/r/deeplearning/comments/89nbx4/hey_guys_i_created_ml_jobs_list_what_do_you_think/,gauthamz,1522826227,,6,3
18,2018-4-4,2018,4,4,17,89nn8p,Could this be a viable career for me?,https://www.reddit.com/r/deeplearning/comments/89nn8p/could_this_be_a_viable_career_for_me/,LikeMike81,1522830047,"Hi there,
Right now I am a journalist in my mid 30s thinking about switching careers at some point. In university I got a minor degree in ""information processing"" which is basically computer science with programming as well as linguistics. I was also doing some pretty beginner so stuff. The only programming language I ever worked with is c++.

So I got basic understanding of programming and ai but would have to learn a lot of stuff by myself. My question: would that even be viable or would I be way too far behind people that actually got a full time and more specific education? Would companies even bother with my resume?

And where would I start? Which programming language to learn, which books to read - what to ""build"" to show people that I know what I am doing?",8,4
19,2018-4-4,2018,4,4,22,89pa3e,Deep Learning vs Classical Machine Learning,https://www.reddit.com/r/deeplearning/comments/89pa3e/deep_learning_vs_classical_machine_learning/,magneticono,1522847210,,1,2
20,2018-4-4,2018,4,4,23,89prc6,A Robust Real-Time Automatic License Plate Recognition based on the YOLO Detector (comprehensible paper with public dataset),https://www.reddit.com/r/deeplearning/comments/89prc6/a_robust_realtime_automatic_license_plate/,ghostzin,1522850864,,0,10
21,2018-4-5,2018,4,5,0,89qcxo,"Some questions about ""Deep Learning: An Introduction for Applied Mathematicians"" paper",https://www.reddit.com/r/deeplearning/comments/89qcxo/some_questions_about_deep_learning_an/,[deleted],1522855035,[deleted],1,1
22,2018-4-5,2018,4,5,0,89qfyg,"Some questions about ""Deep Learning: An Introduction for Applied Mathematicians"" paper",https://www.reddit.com/r/deeplearning/comments/89qfyg/some_questions_about_deep_learning_an/,maybenexttime82,1522855675,"I've came across an interesting paper about Deep Learning (""Deep Learning: An Introduction for Applied Mathematicians""), which could be found on arXiv, but I've stuck at interpreting this part marked in yellow:

https://imgur.com/a/dm9R0

If F(x) is 2D vector then in what sense it is ""close to some vector [1,0]^T""? 

My thought: Maybe in context ""angle between two vectors aka dot product"". If [1,0]^T and [0,1]^T could be interpreted as unit vectors of x and y axis, respectively then we could give some ""rules"" which determine if vector F(x) should be in category A (""close to [1,0]^T""). For example we could say: ""If angle between F(x) vector and [1,0]^T is less than equal to zero or less than 45 degrees then F(x) is in category A."" (I presume we need more constraints other than ""angle between vectors"" but let it be for this case it only depends on angle). 

How to interpret F1(x)&gt;F2(x) if those are vectors? How do you ""compare vectors"" anyway?
",8,6
23,2018-4-5,2018,4,5,5,89sws9,Fast-RCNN,https://www.reddit.com/r/deeplearning/comments/89sws9/fastrcnn/,asranand7,1522872003,"
""A Fast R-CNN network takes as input an entire image and a set of object proposals. The networks first processes the whole image with several convolutions(conv) and max pooling layer to produce a conv feature map.Then for each object proposal region of interest pooling layer extracts a fixed length feature vector from the feature map."" (paragraph from Fast R-CNN paper)

How do we find the object proposal region in the final conv feature map given the object proposal on the real image ???
",7,6
24,2018-4-5,2018,4,5,10,89vnux,LSTM classification in time series data,https://www.reddit.com/r/deeplearning/comments/89vnux/lstm_classification_in_time_series_data/,xpbit1024,1522892420,"So I was wondering howd one go about classifying every point of a time series data. Like the data points themselves are time dependent, but I want to predict the class of every single data point using this time dependency. ",10,1
25,2018-4-5,2018,4,5,11,89w5mz,Anyone take the deeplearning.ai course?,https://www.reddit.com/r/deeplearning/comments/89w5mz/anyone_take_the_deeplearningai_course/,MLJungle,1522896539,"Hi,

I'm currently auditing the deeplearning.ai course and was wondering if anyone   enrolled in the course could share the programming assignments (they're locked for me) in the form of the jupyternotebooks. I would be highly grateful.

",2,1
26,2018-4-5,2018,4,5,12,89wd77,Looking for any documentation on creating my own dataset to feed into a TensorFlow model.,https://www.reddit.com/r/deeplearning/comments/89wd77/looking_for_any_documentation_on_creating_my_own/,avtges,1522898418,Im stuck. How do I create a dataset using images? I do not want to pull pixel values and generate a flat file from the images like MNIST. ,0,1
27,2018-4-5,2018,4,5,12,89wguq,Looking for a Deep Learning course that's tailored towards Java users?,https://www.reddit.com/r/deeplearning/comments/89wguq/looking_for_a_deep_learning_course_thats_tailored/,drea2,1522899386,Any help? All I can find are courses tailored for python. ,5,0
28,2018-4-5,2018,4,5,20,89ys4u,Top 8 Deep Learning Frameworks,https://www.reddit.com/r/deeplearning/comments/89ys4u/top_8_deep_learning_frameworks/,chris_shpak,1522926629,,2,1
29,2018-4-5,2018,4,5,20,89yvic,"Top 20 Deep Learning Papers, 2018 Edition",https://www.reddit.com/r/deeplearning/comments/89yvic/top_20_deep_learning_papers_2018_edition/,magneticono,1522927565,,2,17
30,2018-4-5,2018,4,5,21,89z72q,Computer for deep learning,https://www.reddit.com/r/deeplearning/comments/89z72q/computer_for_deep_learning/,Stygian2a,1522930680,"Hi everybody!

I need to buy a computer for research in deep learningm and I have a budget of 3000/4000
Do you have any suggestions?

Thank you!",1,3
31,2018-4-5,2018,4,5,21,89z7d4,Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW),https://www.reddit.com/r/deeplearning/comments/89z7d4/implementing_deep_learning_methods_and_feature/,dearpetra,1522930752,,0,2
32,2018-4-5,2018,4,5,22,89zslp,How AI Can Create Conflict within Businesses  and What to Do About It,https://www.reddit.com/r/deeplearning/comments/89zslp/how_ai_can_create_conflict_within_businesses_and/,trumtra,1522935836,,0,1
33,2018-4-5,2018,4,5,23,89zy0c,Is this config good for deep learning?,https://www.reddit.com/r/deeplearning/comments/89zy0c/is_this_config_good_for_deep_learning/,Stygian2a,1522936973,"Hi everyone!

I want to build a computer for research in deep learning, and I thought I might go with this config : https://pcpartpicker.com/list/8VcXP3

Do you have any opinions on this build? I think everything is compatible. Any ideas on how I might upgrade it? I have maybe 1000 pounds to spend (in addition to the current build)

Thank you!",2,2
34,2018-4-6,2018,4,6,1,8a19n1,"DeepLearn - Implementation and reproducible code for deep learning papers on NLP(QA, sentence matching, attention, knowledge base completion), CV(transfer learning, multi-modal learning), Audio(scene recognition, tagging).",https://www.reddit.com/r/deeplearning/comments/8a19n1/deeplearn_implementation_and_reproducible_code/,bhatt_gaurav,1522946451,,0,6
35,2018-4-6,2018,4,6,4,8a2kfk,Extension of Deep Photo Style Transfer to Videos,https://www.reddit.com/r/deeplearning/comments/8a2kfk/extension_of_deep_photo_style_transfer_to_videos/,randomchickibum,1522955404,,6,19
36,2018-4-6,2018,4,6,20,8a8krd,Prof Andrew Ng is writing a book about managing a ML project - sign up for free updates,https://www.reddit.com/r/deeplearning/comments/8a8krd/prof_andrew_ng_is_writing_a_book_about_managing_a/,ScotchMonk,1523012401,,11,31
37,2018-4-6,2018,4,6,21,8a97io,How to predict labels from sequences?,https://www.reddit.com/r/deeplearning/comments/8a97io/how_to_predict_labels_from_sequences/,M0shka,1523018851,"Hi! I'm new to Deep Learning. I don't know if I'm allowed to ask this here, so I'm sorry if I'm breaking any rule. 

I have a dataset with 3 columns. 
Column 1 - ID number (0 to 2000)
Column 2 - sequence number (14 alphabets long) 
Column 3 - label (either 1 or 0) 

I'd like to predict the label given only the ID number. 

I was hoping someone would guide me on what method I could use. Or if you could link some existing projects or papers on something like this, I would really appreciate it! 

Thanks ",2,9
38,2018-4-6,2018,4,6,23,8a9v4h,Generating glove vectors with lstm (seq2seq)?,https://www.reddit.com/r/deeplearning/comments/8a9v4h/generating_glove_vectors_with_lstm_seq2seq/,myfirstproject,1523024312,"Hello!

I am currently involved in a project that aims to generate new word sequences from an word input sequence. Ideally I would like my model to output 50 dimensional vectors which we then assign the closest known 50D Glove vector. However, I haven't encountered anyone trying this approach (instead, most generative text models seem to use one hot encodings or word indices as targets)? Is there something I am missing that makes it difficult to use gloVe vectors as targets? Do you know of any paper that attempts to do this?

Thank you!


",2,3
39,2018-4-7,2018,4,7,0,8aanf4,Hiring NLP Deep Learning Position at Wells Fargo,https://www.reddit.com/r/deeplearning/comments/8aanf4/hiring_nlp_deep_learning_position_at_wells_fargo/,nsu0000,1523030111,"Hi,

I'm hiring two data scientists at Wells Fargo (jobs just posted) and I think a lot of people that follow this subreddit would make good candidates, particularly for the senior of the two positions.

I'm in a specialized NLP / Machine Learning group at Wells Fargo where we are looking to build out our capabilities with deep learning methods for text classification and other use cases. We work in Python (Tensorflow/Keras) and PySpark primarily, and tend to make heavy use of word embeddings. Past projects have included things like automatic complaint detection in customer communications using word embeddings and an ensemble of machine learning models, as well as a deep autoencoder to identify anomalous complaints.

If you are interested, you can look at the job descriptions at [WellsFargo.com/careers](https://www.wellsfargo.com/about/careers/) and search for job opening IDs 5398649 (for the senior position) or 5398760 (for a mid-level data scientist position). Both jobs are open for any U.S. location (including remote / work from home).

Ideal candidates would be strong Python/PySpark coders who have an NLP / ML background and big data experience. The best thing to do if you're interested is just to apply. But, if anyone wants to reach out to me directly with questions, LinkedIn is probably the best way. Thanks! [https://www.linkedin.com/in/nathan-susanj-35856824/](https://www.linkedin.com/in/nathan-susanj-35856824/)",0,7
40,2018-4-7,2018,4,7,3,8abtf0,AI Weekly 6 April 2018,https://www.reddit.com/r/deeplearning/comments/8abtf0/ai_weekly_6_april_2018/,TomekB,1523038690,,0,2
41,2018-4-8,2018,4,8,5,8akozs,Convolutional neural network for colorizing and up-scaling B&amp;W flowers images,https://www.reddit.com/r/deeplearning/comments/8akozs/convolutional_neural_network_for_colorizing_and/,Henshmi,1523131769,,0,4
42,2018-4-8,2018,4,8,7,8alj2a,LSTM inference shoot-out: Intel Skylake vs NVIDIA V100,https://www.reddit.com/r/deeplearning/comments/8alj2a/lstm_inference_shootout_intel_skylake_vs_nvidia/,dayman56,1523138979,,1,3
43,2018-4-8,2018,4,8,7,8alnso,Intels Naveen Rao Confirms on twitter that Intel will show Nervana NNP benchmarks at AI event in May,https://www.reddit.com/r/deeplearning/comments/8alnso/intels_naveen_rao_confirms_on_twitter_that_intel/,dayman56,1523140190,,1,6
44,2018-4-8,2018,4,8,16,8aohl1,The Evolution of Convolution Neural Networks,https://www.reddit.com/r/deeplearning/comments/8aohl1/the_evolution_of_convolution_neural_networks/,ajhalthor,1523171939,,0,18
45,2018-4-9,2018,4,9,12,8avf8p,Rapid Prototyping NLP Deep Learning Systems,https://www.reddit.com/r/deeplearning/comments/8avf8p/rapid_prototyping_nlp_deep_learning_systems/,Deepblue129,1523243895,,0,4
46,2018-4-9,2018,4,9,13,8avx5n,Alibaba Cloud Announces Cooperation with NVIDIA GPU Cloud (NGC) at The Computing Conference  Shenzhen Summit,https://www.reddit.com/r/deeplearning/comments/8avx5n/alibaba_cloud_announces_cooperation_with_nvidia/,Michael_Pa,1523249212,,0,1
47,2018-4-9,2018,4,9,21,8axyy9,How would one go about amplifying features of an image,https://www.reddit.com/r/deeplearning/comments/8axyy9/how_would_one_go_about_amplifying_features_of_an/,pythomad,1523276275,"Hello,I am trying to make a model that is like an auto encoder but instead of a bottleneck it is simply bigger than the sample size so it learns to make the sample bigger in size without padding it so far I have tried Dense layers with mnist but so far I have had no luck does anyone know a paper about this subject ,thanks",1,2
48,2018-4-9,2018,4,9,23,8ayoyg,"Supporting rapid prototyping for research, I am LAUNCHING PyTorch-NLP, a deep learning NLP toolkit!",https://www.reddit.com/r/deeplearning/comments/8ayoyg/supporting_rapid_prototyping_for_research_i_am/,Deepblue129,1523283014,,4,9
49,2018-4-10,2018,4,10,9,8b3kj7,Simple and Clean Keras Project Template Architecture,https://www.reddit.com/r/deeplearning/comments/8b3kj7/simple_and_clean_keras_project_template/,Ahmed_El_Hinidy,1523321329,,0,12
50,2018-4-10,2018,4,10,15,8b5hli,Need help with training a GAN on CIFAR-10,https://www.reddit.com/r/deeplearning/comments/8b5hli/need_help_with_training_a_gan_on_cifar10/,akanimax,1523340723,"I have been trying to train a simple dc-gan for the cifar-10 dataset first before learning and experimenting with other gan architectures. But, I have had no luck yet. 
the code is here -&gt; https://github.com/ARANIKC/adversarial-learning

The problem that I am facing is that the discriminator gives up very soon due to which even though the generator outputs noise, the model converges. I have refered to the Radford et. al. paper of dc-gans and incorporated all the suggestions given in it. 

Still, the problem persists.

To all the GAN experts out there, and also those who have sucessfully trained a dc-gan on cifar-10 before, I call out to please help me. 

Thank you!",0,3
51,2018-4-10,2018,4,10,19,8b6oqb,Why do a lot of people try to explain some DL concepts on activation functions like tanh() or sigmoid() but not Relu?,https://www.reddit.com/r/deeplearning/comments/8b6oqb/why_do_a_lot_of_people_try_to_explain_some_dl/,flyed1,1523357395,"I read before that the Relu function (or its variants, ex: leaky Relu...etc) became the default activation function for training DL models. And no one is still using sigmoid or tanh.

In one of the deep learning courses of Andrew Ng. He explained the effect of frobenius norm (L2 regularization) on the tanh function, why not Relu although things is different in the Relu function (the shape of the function).

I'm not just talking about the L2 norm but a few other concepts too that i read or learn about. i know maybe it's easier but it is different, the shape of the function and its properties are different. And it's the most used activation function too so it'll be useful to explain the concepts on it.",1,2
52,2018-4-10,2018,4,10,20,8b6rq3,Google colab - OOM error,https://www.reddit.com/r/deeplearning/comments/8b6rq3/google_colab_oom_error/,maildivert,1523358426,"Has anyone got their model running on Colab's GPU ?

I know its free but I always get OOM error.",1,2
53,2018-4-10,2018,4,10,23,8b7wra,Lessons Learned Reproducing a Deep Reinforcement Learning Paper,https://www.reddit.com/r/deeplearning/comments/8b7wra/lessons_learned_reproducing_a_deep_reinforcement/,dearpetra,1523370053,,0,11
54,2018-4-11,2018,4,11,2,8b9hlq,[P] NuDream - Some changes were made in the original Deep Dream's code to get more control or change the outcome.,https://www.reddit.com/r/deeplearning/comments/8b9hlq/p_nudream_some_changes_were_made_in_the_original/,[deleted],1523381251,[deleted],0,1
55,2018-4-11,2018,4,11,4,8bae74,Backpropagation - Neural Networks with Java,https://www.reddit.com/r/deeplearning/comments/8bae74/backpropagation_neural_networks_with_java/,joey_php,1523387392,,0,0
56,2018-4-11,2018,4,11,15,8bf1d2,AV1 beats x264 and libvpx-vp9 in practical use case,https://www.reddit.com/r/deeplearning/comments/8bf1d2/av1_beats_x264_and_libvpxvp9_in_practical_use_case/,semi23,1523428673,,1,1
57,2018-4-11,2018,4,11,18,8bfv13,"Classify images using keras, This is my first trial of blogging about machine learning. Please if you have any feedback, it is highly appreciated.",https://www.reddit.com/r/deeplearning/comments/8bfv13/classify_images_using_keras_this_is_my_first/,AbdallahNasir,1523440429,,0,1
58,2018-4-11,2018,4,11,19,8bg2dh,How Airlines are Using Big Data,https://www.reddit.com/r/deeplearning/comments/8bg2dh/how_airlines_are_using_big_data/,y-emre,1523443036,,2,1
59,2018-4-11,2018,4,11,20,8bgcmt,Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model,https://www.reddit.com/r/deeplearning/comments/8bgcmt/implementing_deep_learning_methods_and_feature/,magneticono,1523446397,,0,4
60,2018-4-11,2018,4,11,20,8bgdo5,My Journey to Reinforcement Learning  Part 1.5: Simple Binary Image Transformation with Q-Learning,https://www.reddit.com/r/deeplearning/comments/8bgdo5/my_journey_to_reinforcement_learning_part_15/,polllyyy,1523446745,,0,11
61,2018-4-11,2018,4,11,22,8bgx4a,What can we explain about the following Convolutional neural network layers in the link below?,https://www.reddit.com/r/deeplearning/comments/8bgx4a/what_can_we_explain_about_the_following/,amnon123,1523452113,"Here is the link for the image of relevant Convolutional neural network:
https://ibb.co/b0Ddbc",1,0
62,2018-4-11,2018,4,11,23,8bh9q1,What can we explain about the following Convolutional neural network layers in the link below?,https://www.reddit.com/r/deeplearning/comments/8bh9q1/what_can_we_explain_about_the_following/,amnon123,1523455224,How and what can be learned from the Convolutional neural network in the attached image?,0,0
63,2018-4-11,2018,4,11,23,8bhp08,Fast Blind Guidance System using Deep Learning,https://www.reddit.com/r/deeplearning/comments/8bhp08/fast_blind_guidance_system_using_deep_learning/,Mrshadow143,1523458615,,2,4
64,2018-4-12,2018,4,12,0,8bhudg,AI &amp; Deep Learning Bundle - Explore the Future's Most Exciting New Technologies in 7 e-Books &amp; 10 Hours of Course Content,https://www.reddit.com/r/deeplearning/comments/8bhudg/ai_deep_learning_bundle_explore_the_futures_most/,NVIDIA_CEO,1523459764,,0,0
65,2018-4-12,2018,4,12,0,8bi0ot,Is this a toxic comment? - a set of experiments using sequence models and CNNs for a Kaggle competition,https://www.reddit.com/r/deeplearning/comments/8bi0ot/is_this_a_toxic_comment_a_set_of_experiments/,laknath,1523461107,,0,2
66,2018-4-12,2018,4,12,2,8bir9z,What can we explain about the following Convolutional neural network layers in the link below?,https://www.reddit.com/r/deeplearning/comments/8bir9z/what_can_we_explain_about_the_following/,amnon123,1523466710,"Here is the link for the image of relevant Convolutional neural network:
https://ibb.co/b0Ddbc
What can we say and deduce about this neural network?  ",1,1
67,2018-4-12,2018,4,12,6,8bkp9d,From Industrial Revolution to AI Revolution,https://www.reddit.com/r/deeplearning/comments/8bkp9d/from_industrial_revolution_to_ai_revolution/,aqavi,1523481471,"From Industrial Revolution to AI Revolution #AI #ArtificialIntelligence #DeepLearning #MachineLearning #Industry40  
https://blog.wecognize.com/blog/2018/04/11/industrial-ai-revolution/",0,0
68,2018-4-12,2018,4,12,11,8bmqan,Image to Text converter OCR,https://www.reddit.com/r/deeplearning/comments/8bmqan/image_to_text_converter_ocr/,Mrshadow143,1523499168,,4,1
69,2018-4-12,2018,4,12,11,8bmvfv,Computer Vision or NLP project ideas,https://www.reddit.com/r/deeplearning/comments/8bmvfv/computer_vision_or_nlp_project_ideas/,errminator,1523500535,"Hi everyone,

I'm looking for a project that could realistically be completed in 1 month (full time). Ideally I'd like to work on something with medical imaging or with NLP.

I'm relatively new to the field but will receive supervision and funding during this project if I can make it exciting/attractive to a potential supervisor, hence why I'm appealing to the community for ideas.

My ideas so far would be cancer detection (but maybe data isn't public and also it's been done before?) or some sort of educational chatbot that can teach and answer calculus questions and is capable of producing LaTeX output. What do you think of these?

As I said I'm really open to any computer vision or NLP suggestions (generative/classification etc). The key point is it should be realistic for someone who's only been learning the field for 6 months or so and should be possible to complete in 1 month full time.

Thanks. I really appreciate your thoughts and input :)",3,3
70,2018-4-12,2018,4,12,19,8bp8ja,CFP: CHASE DL-EDGE-IOT Workshop,https://www.reddit.com/r/deeplearning/comments/8bp8ja/cfp_chase_dledgeiot_workshop/,kunalbme,1523530343,"CHASE Workshop 2018
https://sites.google.com/view/chase-dl-edge-iot/home

DL-EDGE-IOT

Deep Learning and Edge Computing in IOT-centered Health Applications

Sep 26-Sep 28, 2018 - Washington, D.C., USA

In conjunction with IEEE/ACM CHASE 2018

Important Dates:
- Workshop Paper Submission: June 8, 2018
- Workshop Paper Acceptance: July 13, 2018
- Workshop Camera-Ready Paper: July 23, 2018
- Submission link:  https://edas.info/newPaper.php?c=24762

Interdisciplinary landscape of connected health research demands researchers from different areas such as deep learning, machine learning, internet of things (IoT), wearable sensing, distributed computing, embedded systems, big data, and medical devices to collaborate for accurate, efficient and reliable systems for a wide array of health applications. Recent advancements in deep learning and model compression of deep models on wearables have created unique opportunities for connected health. The new opportunities also have associated challenges that need to be addressed to achieve the goal of accuracy, efficiency, privacy, reliability and security. 

This workshop aims to bring together the collaboration between research groups in academia and industry. It compasses a wide array of techniques, methods, architectures and solutions in low-resource machine learning, model-compressed deep learning, secure, private and efficient fog computing for practical IoT use cases. The DL-EDGE-IOT workshop invite authors from both academia and industry to submit high quality papers containing original work.

DL-EDGE-IOT workshop includes (but not limited to) the following topics:

- Deep learning and low-resource machine learning for wearable IoT
- Machine learning for IoT signal processing on edge device
- Neural network model compression for wearables
- Information-theoretic signal learning on IoT devices
- Fog, edge and mist computing for DL in connected health
- Edge-based DL for wearable health solutions
- Novel emerging applications of IoT in biomedical signal processing on edge devices
- Fog computing for mobile-based location search; context-aware, information processing
- Scalability, privacy and usability aspects of DL-focused IoT
- Design, development and evaluation of fog architectures for data analysis, visualization and interoperability for connected health
- Big data storage in IoT and Edge Computing for healthcare applications
- Nano-CMOS and Post-CMOS based sensors, circuits, and controller
- Accelerators for IoT Health (e.g., neuromorphic and cognitive computing)
- End-to-End ML-driven privacy preserving and security approaches for IoT Health 
- Braininspired and neuromorphic components, circuits, and systems for Connected Health 
- Case studies of IoT Health (e.g., Predictive analytics and population health management, risk prediction and patient subtyping, behavioral coaching, social network analysis for IoT Health)

KEYNOTE: ""Intelligent ear-level devices for hearing enhancement and health monitoring leveraging edge and cloud computing""

Tao Zhang, PhD, Director of the Signal Processing Research, Starkey Hearing Technologies


",0,1
71,2018-4-12,2018,4,12,21,8bpn8t,Getting Started with PyTorch Part 1: Understanding How Automatic Differentiation Works,https://www.reddit.com/r/deeplearning/comments/8bpn8t/getting_started_with_pytorch_part_1_understanding/,magneticono,1523534965,,1,17
72,2018-4-12,2018,4,12,21,8bpq6d,Building an image caption generator with Deep Learning in Tensorflow,https://www.reddit.com/r/deeplearning/comments/8bpq6d/building_an_image_caption_generator_with_deep/,trumtra,1523535831,,0,1
73,2018-4-13,2018,4,13,16,8bxgcb,Facebook AI Director Yann LeCun on His Quest to Unleash Deep Learning and Make Machines Smarter,https://www.reddit.com/r/deeplearning/comments/8bxgcb/facebook_ai_director_yann_lecun_on_his_quest_to/,tahaemara,1523605621,,0,10
74,2018-4-13,2018,4,13,21,8byns2,How Attractive Are You in the Eyes of Deep Neural Network?,https://www.reddit.com/r/deeplearning/comments/8byns2/how_attractive_are_you_in_the_eyes_of_deep_neural/,polllyyy,1523621453,,4,7
75,2018-4-13,2018,4,13,23,8bzjne,What We Learned Deploying Deep Learning at Scale for Radiology Images,https://www.reddit.com/r/deeplearning/comments/8bzjne/what_we_learned_deploying_deep_learning_at_scale/,rahulBatmanDravid,1523629502,,4,31
76,2018-4-13,2018,4,13,23,8bzsse,How do I assemble a training dataset of images?,https://www.reddit.com/r/deeplearning/comments/8bzsse/how_do_i_assemble_a_training_dataset_of_images/,avtges,1523631561,"I want to build my own dataset with images I download from the internet, to train my ML project in TensorFlow I have searched google, searched stack overflow, looked at other datasets on Kaggle and all over. 

I am just not able (smart enough) to put the pieces together. Does anyone have any experience doing this?

The app compares images to guess whether, for example, it's looking at a dog or a cat. ",0,2
77,2018-4-14,2018,4,14,3,8c1dg9,AI Weekly 13 April 2018,https://www.reddit.com/r/deeplearning/comments/8c1dg9/ai_weekly_13_april_2018/,TomekB,1523643665,,0,2
78,2018-4-14,2018,4,14,12,8c552d,Good techniques for forecasting revenue over various timeframes,https://www.reddit.com/r/deeplearning/comments/8c552d/good_techniques_for_forecasting_revenue_over/,interstellarhighway,1523678065,"I am working on a problem where the goal is to develop a predictive model for predicting taxi revenue. My data is a subset from a publicly available dataset of taxi details from the city of Chicago. Basically the dataset contains details such as cab ID, start and destination locations, total price of the ride and such. I am looking to write a predictive model that can train on this data, and be able to predict how taxi revenue for a 'typical' taxi (median) would be like in the future: hourly, daily, weekly, etc. (which I will be testing against the data from 2017, training on the data before that). Because the data also contains Taxi ID, my idea is to concatenate the details for each taxi together based on hour/day/week etc., and then use those medians as training data.

I was hoping to get some suggestions as to what would some good techniques to look into for a problem like this. From my research there seem to be a lot of techniques (ARIMA, decision trees, LSTM etc.) aimed at this kind of problems but I am not completely sure if I should consider it as a time series forecasting or a classical regression problem. Would LSTMs be a good choice? And if I want to predict for different timeframes (hour/day/week), do I have to train separately for each?",6,5
79,2018-4-14,2018,4,14,17,8c6d52,Get to know what makes it Deep Learning,https://www.reddit.com/r/deeplearning/comments/8c6d52/get_to_know_what_makes_it_deep_learning/,anuj1207,1523695366,,0,0
80,2018-4-15,2018,4,15,14,8cd9g4,Hot Deep Learning Applications to Watch,https://www.reddit.com/r/deeplearning/comments/8cd9g4/hot_deep_learning_applications_to_watch/,analyticsinsight,1523770255,,0,4
81,2018-4-15,2018,4,15,16,8cdr77,Using pretrained network,https://www.reddit.com/r/deeplearning/comments/8cdr77/using_pretrained_network/,errminator,1523777858,"What does it mean to do this? For example, I have read about people taking VGG16 or AlexNet and applying them to other CNN image classification problems. My question is how does this work as presumably VGG16 and AlexNet were trained on some particular dataset so how can we suddenly expect them to classify totally new images?

Thank you ",5,1
82,2018-4-15,2018,4,15,23,8cff96,Deep learning project template using PyTorch,https://www.reddit.com/r/deeplearning/comments/8cff96/deep_learning_project_template_using_pytorch/,vic964404,1523802214,,0,10
83,2018-4-16,2018,4,16,1,8cgb8v,Gaussian Material Synthesis  ACM Transactions on Graphics (SIGGRAPH 2018),https://www.reddit.com/r/deeplearning/comments/8cgb8v/gaussian_material_synthesis_acm_transactions_on/,keghn,1523810358,,1,7
84,2018-4-16,2018,4,16,1,8cgce6,Why use convolution on character embeddings before using RNN/CNN?,https://www.reddit.com/r/deeplearning/comments/8cgce6/why_use_convolution_on_character_embeddings/,rinkujadhav2014,1523810632,"Why does everyone use convolution operations on character embeddings before passing them to RNNs (or CNNs if it's Facebook)?
Actually, I'm trying to build a character level model for sentiment analysis and using character embeddings doesn't seem to work at all. Gradients are all 0 except for the output layer and I've verified that it's neither a coding error nor a vanishing gradient problem. I tried to google a character level model for sentiment analysis but all of them seem to use CNN over embeddings before using an RNN",2,4
85,2018-4-16,2018,4,16,17,8cm2bx,{CNN}Multi labels classification: Sparse labels,https://www.reddit.com/r/deeplearning/comments/8cm2bx/cnnmulti_labels_classification_sparse_labels/,Moni93,1523867727,"I am working on a model where i need to predict multiple attributes from an image: So, I am in a multi label classification situation. For each image, there are 36 possible labels: still in average, every image has a maximum of 3 labels : which means in my label vector there are three 1 and thirty three 0 in average.   
My question is as follows: does the label being sparse affect badly the CNN ??  I know that the answer is a Yes if the data ( X ) is sparse, but what about Y ( labels) ???",7,5
86,2018-4-16,2018,4,16,20,8cmx0q,Deep learning methodologies to extend image based application to videos,https://www.reddit.com/r/deeplearning/comments/8cmx0q/deep_learning_methodologies_to_extend_image_based/,chris_shpak,1523879293,,0,1
87,2018-4-16,2018,4,16,20,8cmxau,Recurrent Neural Network Tutorial for Artists,https://www.reddit.com/r/deeplearning/comments/8cmxau/recurrent_neural_network_tutorial_for_artists/,joey_php,1523879365,,0,13
88,2018-4-16,2018,4,16,20,8cmyus,3D generated annotated data,https://www.reddit.com/r/deeplearning/comments/8cmyus/3d_generated_annotated_data/,Bulbali,1523879877,,0,2
89,2018-4-16,2018,4,16,23,8cny46,"Deep Learning from first principles in Python, R and Octave  Part 6",https://www.reddit.com/r/deeplearning/comments/8cny46/deep_learning_from_first_principles_in_python_r/,tvganesh,1523889238,,0,1
90,2018-4-17,2018,4,17,5,8cqsss,What is the difference between conditional NNs and multiple independent NNs?,https://www.reddit.com/r/deeplearning/comments/8cqsss/what_is_the_difference_between_conditional_nns/,jackcmlg,1523910904,"Assuming there are two different types of data but in the same format: {X_1, Y_1} and {X_2, Y_2}, with a binary variable t indicating the type, we want to build a model to do some regression/classification tasks: when t=0(or 1), Y_1(or Y_2) can be estimated given X_1(or X_2). In general, there are two choices:

1) We train two separate NNs: Y_1=NN_1(X_1) for t=0 and Y_2=NN_2(X_2) for t=1

2) We train a conditional NNs: Y = NN(X, t) where X=X_1(or X_2), Y=Y_1(or Y_2) when t=0(or 1)

In theory, what is the difference between them?",1,1
91,2018-4-17,2018,4,17,10,8cswoj,AI with minimum data,https://www.reddit.com/r/deeplearning/comments/8cswoj/ai_with_minimum_data/,parthiv9,1523929151,,0,2
92,2018-4-17,2018,4,17,21,8cw9t5,How to implement general machine learning algorithms?,https://www.reddit.com/r/deeplearning/comments/8cw9t5/how_to_implement_general_machine_learning/,k920049,1523969498," So I'm in the middle of implementing an algorithm based on probabilistic graphical model and the thing is that I have no idea how to implement it with Tensorflow. 

 Tensorflow is one of the most popular framework in deep learning society and many people use it to implement lots of deep learning algorithm. However, when it comes to implementing many algorithms other than deep learning algorithms, I think choosing Tensorflow to do such jobs is a bad idea. 

 The reason why people use Tensorflow is probably because it has many good features, let alone with autograd. But Tensorflow narrows so many options like subscription(indexing), debugger and so on just to provide operator tree for tractable gradient computation. 
 
 Anyway, is there any other options for implementing general m/l algorithms? It seems like a good idea to use cuBLAS for doing it. Matlab is another solution for this problem but I heard that it is almost impossible to write a Matlab code and deploy it online.

",3,2
93,2018-4-17,2018,4,17,22,8cwdf9,Top 7 Big Data Use Cases in Insurance Industry,https://www.reddit.com/r/deeplearning/comments/8cwdf9/top_7_big_data_use_cases_in_insurance_industry/,y-emre,1523970437,,0,0
94,2018-4-17,2018,4,17,22,8cwdjy,iMIMIC - Interpretability of Machine Intelligence in Medical Image Computing Workshop,https://www.reddit.com/r/deeplearning/comments/8cwdjy/imimic_interpretability_of_machine_intelligence/,pereirasrm,1523970473,,0,6
95,2018-4-18,2018,4,18,8,8d11en,How do Neural Networks learn?,https://www.reddit.com/r/deeplearning/comments/8d11en/how_do_neural_networks_learn/,ajhalthor,1524007347,,0,0
96,2018-4-18,2018,4,18,9,8d1o9c,The Batch Normalization layer of Keras is broken,https://www.reddit.com/r/deeplearning/comments/8d1o9c/the_batch_normalization_layer_of_keras_is_broken/,datumbox,1524012906,,1,10
97,2018-4-18,2018,4,18,15,8d3owb,Links to the April issue of COMPUTER VISION NEWS,https://www.reddit.com/r/deeplearning/comments/8d3owb/links_to_the_april_issue_of_computer_vision_news/,Gletta,1524034677,"Here is the April 2018 issue of Computer Vision News, published by RSIP Vision: a 34-pages magazine about Computer Vision, Image Processing, Deep Learning and Artificial Intelligence.
Great articles about advanced technologies and their applications.
Free subscription at page 34.
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2018April/ and
PDF version ==&gt; http://www.rsipvision.com/computer-vision-news-2018-april-pdf/
Enjoy!",0,0
98,2018-4-18,2018,4,18,19,8d4pnq,Training ImageNet on a TPU in 12.5 hours with GKE and RiseML,https://www.reddit.com/r/deeplearning/comments/8d4pnq/training_imagenet_on_a_tpu_in_125_hours_with_gke/,dearpetra,1524048739,,0,4
99,2018-4-18,2018,4,18,20,8d4t3e,5 Free Resources for Furthering Your Understanding of Deep Learning,https://www.reddit.com/r/deeplearning/comments/8d4t3e/5_free_resources_for_furthering_your/,magneticono,1524049922,,0,15
100,2018-4-18,2018,4,18,22,8d5m0y,multi-label classfication project: how to improve bad performance,https://www.reddit.com/r/deeplearning/comments/8d5m0y/multilabel_classfication_project_how_to_improve/,Moni93,1524058144,"Contextualization:   
I am building a model that identifes three categories in a given image.
There are three categories:

Gender: male/female

Type clotes: Blazers,Blazers&amp;Jacket,Blouses,Cardigan,Coats,Coats&amp;Jackets,Culottes,Dresses,Jeans,Jumper,Jumpsuits&amp;Dungarees,Knitwear&amp;Sweatshirts,Leggings&amp;CigaretteTrousers,Maternity,Polo,Pololong,Shirts,Shorts,Skirts,Suits,Swimwear,Swimwear &amp; Beachwear,T-shirts,T-shirts &amp; Tops,Trousers,Tunics.

Color clothes: beige,black,blue,brown,green,grey,orange,pink,red,white,yellow.
In other words every image should have these 3 categories ( one value per category).

Data
My database for training my model is composed of 1812 images and an excel file containing the values of the three categories for each image ( and its url).
Here are some information about my database:

number of males: 759
number of females: 1055
I also have the number of times each attribute ( from each category) is appearing in my database ( I can't list all of them, but if it's something usefull for interpretation I can send you that information)
most appearing triplet is (Male,Jeans,blue): 66 times
What I have done
It seemed pretty clear that I am in a multi-label classification context.
1. Clean &amp; preprocess my data
I created (X,Y) data where X is is of shape (1814,204,204,3) and Y is of shape (1814,39) '' 39 corresponds to the dummy variable : category 1 has 2 attributes, category 2 has 26 attribute , category 3 has 11 attributes: so total makes 39 ''.
2. Building my neural neural network
the different parameters of my model are :

epochs = 100
lrate = 0.001
decay = lrate/epochs
sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)
loss=binary_crossentropy
optimizer=sgd
metrics=accuracy
The structure of my trained network is as follows:

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 204, 204, 32)      896       
_________________________________________________________________
dropout_3 (Dropout)          (None, 204, 204, 32)      0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 204, 204, 32)      9248      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 102, 102, 32)      0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 332928)            0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               170459648 
_________________________________________________________________
dropout_4 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 39)                20007     
_________________________________________________________________
activation_1 (Activation)    (None, 39)                0         

=================================================================
Total params: 170,489,799
Trainable params: 170,489,799
Non-trainable params: 0
Questions

I don't think my metric ='accuracy' is a good choice: it doesn't reflect the reality of what happens. For example, I executed an evaluation test on my training data and got 0.95 ( 95% of all bins are well classified), but that doesn't mean the model is doing well because in every output: there should be 3 ones out of the 39 components and all the remaining are zeros.. so there is a high probability to have a lot of zeros and thus even in the worse case the 39 values are predicted to be 0 ( nothing is detected) than we have 36/39 accuracy: which doesn't reflect the real issue? ( That's what I got as a result, for a given X, i got many Values near to zeros , so when I use a threshold (0.5) it makes everything equal to zero: I tried to implement a threshold based on statistical approach using mathiew correlation coefficient: but still doesn't add anything usefull) .. So , what do you think is a good metric for a multi-label classification problem with many (39) labels output?
Do you think that the bad performance of my model comes from the fact that I don't have many images? ( images per label ) ?
Do you think my model has bad performance because the structure of Neural network is not good? I tried to used a pretrained model where I fix first layers since state of the art says that these layers are responsible for detecting edges, and I trained only next layers: In that case I have also bad results (calcaluated through the 'accuracy' metric?
To sum up , i Know that maybe there is not a universal solution to my issues, but at least I want to know what may cause these kind of issues and how to remedy them? So any help especially from people who worked on multi-label classifications with many labels at the output, is welcome",5,2
101,2018-4-18,2018,4,18,23,8d63pz,Microsoft Releases Deep Learning Web Service Deployment on Spark,https://www.reddit.com/r/deeplearning/comments/8d63pz/microsoft_releases_deep_learning_web_service/,mhamilton723,1524062331,,2,13
102,2018-4-19,2018,4,19,1,8d6sh0,"Announcing Luminoth 0.1: new object detection models, checkpoints and more!",https://www.reddit.com/r/deeplearning/comments/8d6sh0/announcing_luminoth_01_new_object_detection/,minmidinosaur,1524067560,,0,1
103,2018-4-19,2018,4,19,12,8dbtot,Question: Why don't we use 2*2 kernel (or other even 4*4) in CNN?,https://www.reddit.com/r/deeplearning/comments/8dbtot/question_why_dont_we_use_22_kernel_or_other_even/,zbwby,1524109703,,4,3
104,2018-4-19,2018,4,19,13,8dc1hs,Problems installing CUDA on Ubuntu 16?,https://www.reddit.com/r/deeplearning/comments/8dc1hs/problems_installing_cuda_on_ubuntu_16/,74throwaway,1524112038,"I downloaded the deb version of CUDA from here: https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1604&amp;target_type=deblocal

I then followed steps 3.6 and 7.1 from here: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html

I also noticed that in `additional drivers`, it was at Nvidia 387 by default, and I also saw Nvidia 384. I clicked on Nvidia 384, clicked apply changes, and then clicked back on Nvidia 387 and hit apply changes. I remember when I typed `nvidia-smi`, I got an error message or nothing showed up

After doing all of the above and rebooting, this is what my screen looks like now:

https://imgur.com/a/6pTYN

After I enter my password, it accepts my password and appears to log me in, then the log in page just shows back up again. I see the system menu on the top right, but I cannot launch any programs or see any files/icons on the desktop. This keeps happening even though I've rebooted and tried to re-login over 10 times now

In the GUI environment (Ctrl+Alt+F7), I'm unable to launch a shell session window from the GUI environment

I then accessed the text-based login screen after typing Ctrl+Alt+F1, and typed:

    lspci -v
    apt search nvidia | grep -P ""nvidia-\d+""
    sudo apt install --reinstall nvidia-384

The results I got are here: https://imgur.com/a/5hjCGlb

The top image for when I type `lspci -v`. I saw a ton of stuff being displayed fast, but I couldn't see alot of what was displayed

`apt search nvidia | grep -P ""nvidia-\d+""`

I saw the most recent Nvidia was 387 and 384. I reinstalled 387, rebooted, and I still get the abnormal login screen

I then tried removing CUDA with `sudo apt-get remove cuda` and `sudo apt autoremove`, rebooted, and the screen *still* looks like the ones in the imgur link

What else can I do about this?

**EDIT**: After I just typed Ctrl-Alt-F1, in the terminal there, I just saw some nvidia-graphics file. I changed it so it ends in `.no` instead of `.conf`

I rebooted and now I get the normal desktop!! I can see the files on my desktop and the program icons on the left toolbar

what do I do now to confirm CUDA works?",7,1
105,2018-4-19,2018,4,19,18,8ddha6,Architecture to match between documents and search terms,https://www.reddit.com/r/deeplearning/comments/8ddha6/architecture_to_match_between_documents_and/,niujin,1524131469,"I have a lot of search logs like this:

* user searches for term A
* user searches for term B
* user clicks on document C THEREFORE document C is a better match for term B than term A

I have already repurposed TensorFlow NMT (a seq2seq model) to recommend search terms for documents when they are uploaded to the database. So it ""translates"" from a 1000-word long document, to a 10-word long search term. This works very well.

However I would now like to make a model that will map from term + document combinations to a probability or score:

* input: term B + doc C, output 79%
* input: term A + doc C, output 43%

What architecture should I use for this? 

I am thinking of taking TensorFlow CNN for text classification (https://github.com/dennybritz/cnn-text-classification-tf), and modifying it to have 2 inputs.",0,1
106,2018-4-19,2018,4,19,19,8ddlzo,Leela Chess Zero - The public collaborative project chess AI - Better then Alpha Zero,https://www.reddit.com/r/deeplearning/comments/8ddlzo/leela_chess_zero_the_public_collaborative_project/,DrWhatNoName,1524133247,,3,1
107,2018-4-19,2018,4,19,20,8ddy2e,Sizing the potential value of AI and advanced analytics,https://www.reddit.com/r/deeplearning/comments/8ddy2e/sizing_the_potential_value_of_ai_and_advanced/,molode,1524137470,,0,4
108,2018-4-19,2018,4,19,20,8de0nf,AI based movies recommendations,https://www.reddit.com/r/deeplearning/comments/8de0nf/ai_based_movies_recommendations/,alta1r,1524138302,,2,0
109,2018-4-19,2018,4,19,20,8de2cq,Lets build an Open-Source Image Database,https://www.reddit.com/r/deeplearning/comments/8de2cq/lets_build_an_opensource_image_database/,dewayneroyj,1524138844,"What if we could just take a photograph ourselves, of anything, and label it based on the object. Then, upload it to a server. I adamantly believe that the only way for us to build an extensive dataset to train our models on is for us to collectively come together. ",10,18
110,2018-4-19,2018,4,19,23,8df2sh,Derivation of Convolutional Neural Network from Fully Connected Network Step-By-Step,https://www.reddit.com/r/deeplearning/comments/8df2sh/derivation_of_convolutional_neural_network_from/,AhmedGadFCIT,1524148388,,0,1
111,2018-4-20,2018,4,20,5,8dhv83,Which parts of the deep learning stack will end up automated and which will matter?,https://www.reddit.com/r/deeplearning/comments/8dhv83/which_parts_of_the_deep_learning_stack_will_end/,gagejustins,1524169734,"In any situation where infrastructure is complicated, there's a chance that something open source (e.g. Docker) or otherwise obviates the need for deep underlying technical knowledge about the systems being used (to an extent). What parts of deep learning are going to get automated?",1,13
112,2018-4-20,2018,4,20,5,8di0xd,GPU version of Tensorflow not working in Ubuntu 16,https://www.reddit.com/r/deeplearning/comments/8di0xd/gpu_version_of_tensorflow_not_working_in_ubuntu_16/,74throwaway,1524170955,"    from tensorflow.python.client import device_lib
    print(device_lib.list_local_devices())

returns
 
    The TensorFlow library wasn't compiled to use FMA instructions, but these    are available on your machine and could speed up CPU computations.
    [name: ""/cpu:0""
    device_type: ""CPU""

even though the GPU version seemed to successfully install with `sudo pip3 install tensorflow-gpu` and under `pip3 list`, I see `tensorflow-gpu     1.7.0`
 
I also noticed that under `pip list`, there was `tensorflow`. So I removed it with `pip uninstall tensorflow`

When I try the python commands above, I now get `ModuleNotFoundError: No module named 'tensorflow'`

I even uninstalled the gpu version and re-installed it:

    sudo pip3 uninstall tensorflow-gpu
    sudo pip3 install tensorflow-gpu

but I still get the `No module named 'tensorflow'` error

why is this?

",14,3
113,2018-4-20,2018,4,20,12,8dkm6i,Neural network Learning - Step by Step,https://www.reddit.com/r/deeplearning/comments/8dkm6i/neural_network_learning_step_by_step/,ajhalthor,1524195266,,0,1
114,2018-4-20,2018,4,20,13,8dl363,New Mathematical Optimization Method That Could Revolutionize Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/8dl363/new_mathematical_optimization_method_that_could/,deapest1989,1524200310,,2,0
115,2018-4-20,2018,4,20,19,8dmmbk,Deep Learning With Apache Spark: Part 1,https://www.reddit.com/r/deeplearning/comments/8dmmbk/deep_learning_with_apache_spark_part_1/,jackblun,1524220882,,0,6
116,2018-4-20,2018,4,20,19,8dmp3m,The Circular Relationship Between Mind and Matter,https://www.reddit.com/r/deeplearning/comments/8dmp3m/the_circular_relationship_between_mind_and_matter/,magneticono,1524221896,,0,0
117,2018-4-20,2018,4,20,20,8dmv10,Solving internal co-variate shift in deep learning with linked Neurons with Interactive Code,https://www.reddit.com/r/deeplearning/comments/8dmv10/solving_internal_covariate_shift_in_deep_learning/,polllyyy,1524223829,,0,2
118,2018-4-21,2018,4,21,0,8dok2o,Suggested Paper to work with RNN Models,https://www.reddit.com/r/deeplearning/comments/8dok2o/suggested_paper_to_work_with_rnn_models/,ragas_,1524238925,"Hi,
I've basic understanding of RNN structure. To practice further I want to implement RNN from research papers. If someone can suggest me research papers to implement RNN architecture from there, it will be of great help. I'm looking for vanilla RNN, Seq2Seq model &amp; Attention model papers. 
Thanks!",0,0
119,2018-4-21,2018,4,21,3,8dpwng,Adaptive Meta-heuristically Intelligent Particle - Newly Discovered Optimization Method,https://www.reddit.com/r/deeplearning/comments/8dpwng/adaptive_metaheuristically_intelligent_particle/,deapest1989,1524249363,,2,10
120,2018-4-21,2018,4,21,7,8drs0j,"I want to make some project related to vehicle detection and tracking. I may be using Vehicle Image Dataset, or Kitti vehicle dataset. Please suggest some worthy idea/ project. I have looked at implementation of track to detect and detect to track paper also.",https://www.reddit.com/r/deeplearning/comments/8drs0j/i_want_to_make_some_project_related_to_vehicle/,Darshb34,1524265152,"
https://arxiv.org/abs/1710.03958",0,2
121,2018-4-21,2018,4,21,8,8dryby,Training an unsupervised network with a supervised network,https://www.reddit.com/r/deeplearning/comments/8dryby/training_an_unsupervised_network_with_a/,mount_sumInt,1524266821,"Let's say that you would like to train a neural network to be as nice as possible in textual interactions. What would be the ideal way to train it? To sit there for a few years and reward it based on how nice it's being. Failing that, if you had another neural network that could do that for you, except for a lot less time and a lot quicker, that would also be nice.

You could train a GAN to score a regression network on how nice it's being, then train a regression network to get the best score possible from the GAN.

If you train a GAN to train an unsupervised neural network to do an abstract goal, you can now give unsupervised neural networks abstract goals. Why would you want to do that? Because an unsupervised network can sometimes perform a task better than a human can.

This technique might one day be involved in creating machines that behave more ethically than humans can.

Has this technique ever been employed before? What is it called and what do you think of it?

Thank you for reading and thank you for responding. :)",0,1
122,2018-4-21,2018,4,21,17,8dujfl,Improving Naive Bates Sentiment Analysis,https://www.reddit.com/r/deeplearning/comments/8dujfl/improving_naive_bates_sentiment_analysis/,errminator,1524299440,"I have implemented a Naive Bayes classifier trained on wordnet movie reviews to do live sentiment analysis from Twitter. I'm curious how I could improve this further?

Finding a bigger dataset to train on top positive and negative words would probably help - any recommendations for such datasets with labels?

What about the Naive Bayes classifier itself. I read that it's simplicity allows it to scale easily but perhaps at a cost of accuracy. I'm tempted to try using a neural network to get higher accuracy but I guess it might not scale well or there may be a significant lag in my algorithm? Any advice on what I could do here?

Thanks.",1,1
123,2018-4-21,2018,4,21,23,8dw1re,Asking for feedback - I'm building a web app to convert models between frameworks,https://www.reddit.com/r/deeplearning/comments/8dw1re/asking_for_feedback_im_building_a_web_app_to/,dar_1978,1524320696,"Hi! Im currently building a web app to convert models between frameworks, especially for mobile applications. I ran into lots of problems when converting from PyTorch to Caffe or to Keras.

Made a prototype and posted it here: https://convertmodel-ai.carrd.co Currently collecting feedback on the most annoying problems, so that I can prioritize accordingly. Would love to hear of any problems you had plus if and how you solved them. Thanks! :)",0,3
124,2018-4-22,2018,4,22,0,8dw9uz,"The first article in a series exploring Deep Learning in Computer Vision using PyTorch. In this, we set the goal of getting into the top 1% in a Kaggle Competition (you need to be in top 10% to be an expert).",https://www.reddit.com/r/deeplearning/comments/8dw9uz/the_first_article_in_a_series_exploring_deep/,databiryani,1524322992,,9,38
125,2018-4-22,2018,4,22,3,8dxsb5,AI Weekly 21 April 2018,https://www.reddit.com/r/deeplearning/comments/8dxsb5/ai_weekly_21_april_2018/,TomekB,1524337041,,0,1
126,2018-4-22,2018,4,22,15,8e1krs,Has anyone tried implementing STARGAN here?,https://www.reddit.com/r/deeplearning/comments/8e1krs/has_anyone_tried_implementing_stargan_here/,sksiitb,1524378117,,3,7
127,2018-4-23,2018,4,23,10,8e7y7d,Automated Grading Possibility?,https://www.reddit.com/r/deeplearning/comments/8e7y7d/automated_grading_possibility/,errminator,1524448149,"Automated graded has been applied to essays (see Kaggle competition) using LSTMs amongst other things. I was wondering if anybody has tried applying similar techniques to grading mathematical calculations - even simple ones such as 3 figure addition.

If so, is there any datasets out there on this?",2,3
128,2018-4-23,2018,4,23,22,8ebagp,Areas That Enterprises Should Consider When Developing Deep Learning Platforms,https://www.reddit.com/r/deeplearning/comments/8ebagp/areas_that_enterprises_should_consider_when/,fullstackanalytics1,1524488723,,0,2
129,2018-4-23,2018,4,23,22,8ebevt,Deploying Deep Learning Models on Kubernetes with GPUs,https://www.reddit.com/r/deeplearning/comments/8ebevt/deploying_deep_learning_models_on_kubernetes_with/,digitalson,1524489854,,0,6
130,2018-4-24,2018,4,24,4,8ee29d,https://stackoverflow.com/questions/49987614/how-does-one-create-a-data-set-in-pytorch-and-save-it-into-a-file-to-later-be-us,https://www.reddit.com/r/deeplearning/comments/8ee29d/httpsstackoverflowcomquestions49987614howdoesonecr/,real_charlie_parker,1524510662,"I want to extract data from cifar10 in a specific order according to some criterion f\(Image,label\) \(for the sake of an example lets say f\(Image,label\) simply computes the sum of all the pixels in Image\). Then it I want to generate 1 file for the train set and 1 file for the test set that I can later load in a dataloader to use for training a neural net.

How do I do this? My current idea was simply to loop through the data with data loader with shuffle off and remember the indices of the images and the score and then sort the indices according to the score and then loop through everything again and create some giant numpy array and save it. After I save it Id use torch.utils.data.TensorDataset\(X\_train, X\_test\) to wrap with TensorDataset and feed to DataLoader.

I think it might work for a small data set like cifar10 at the very least, right?

Another very important thing for me is that I also want to only train on the first K images \(especially since I already sorted them the first K have a special meaning which I want to keep\) so respecting but training only with a fraction will be important.

[https://stackoverflow.com/questions/49987614/how\-does\-one\-create\-a\-data\-set\-in\-pytorch\-and\-save\-it\-into\-a\-file\-to\-later\-be\-us](https://stackoverflow.com/questions/49987614/how-does-one-create-a-data-set-in-pytorch-and-save-it-into-a-file-to-later-be-us)",0,0
131,2018-4-24,2018,4,24,12,8ehbcg,How Deep The Deep Learning Is? - Measuring The Depth of Deep Learning,https://www.reddit.com/r/deeplearning/comments/8ehbcg/how_deep_the_deep_learning_is_measuring_the_depth/,LearningFromData,1524538987,,0,0
132,2018-4-24,2018,4,24,16,8eiqz4,When #DeepLearning learns #basketball ,https://www.reddit.com/r/deeplearning/comments/8eiqz4/when_deeplearning_learns_basketball/,odingah,1524556505,,8,109
133,2018-4-24,2018,4,24,17,8eiwqy,Multi-label classifciation: keras custom metrics,https://www.reddit.com/r/deeplearning/comments/8eiwqy/multilabel_classifciation_keras_custom_metrics/,Moni93,1524558893,"**Contextualization**   
I am working on a multi_label classification problem with images. I am trying to predict 39 labels. In other words, I am trying to identifying which one of the 39 characteristics is present in a given image( many characteristics can be found in one image that's why I am on a multi label classification situation.   

**Data**    

My input data are (X,Y): X is of shape (1814,204,204,3) and Y is of shape (1814,39). So basically X are the set of images and Y are the labels associated to each images which will be used for the supervised learning process.

**Model**  

I am building a Convolutional neural network in order to make predictions. For this task, I am using Keras in order to create my model.

**What I have done**  

In order to validate my model, I need to choose a metric. However, metrics available in Keras are irreverent in my case and won't help me validate my model since I am in multi-label classification situation. That's why I decided to create my custom metric. I created recall and precision metrics applied to columns of Y and Y_predict . In other words, I will calculate recall and precision for each class of the 39 classes. So here is the code of my metrics:

    def recall(y_true, y_pred):
    #Recall metric.

    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)),axis=0)
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)),axis=0)
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

    def precision(y_true, y_pred):
    #Precision metric.

    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)),axis=0)
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)),axis=1)
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

My vector Y is of shape (n,39) that's why I am doing operations over axis=0. In other words, for each label, I am caluclating precision and recall.

Next step, I called these two metrics by precising it to keras fit function. In other words I used this line of code:

model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[precision,recall])
Code for building, compiling and fitting model:
Here is the code that I use for building the model an training it + its result . ( I am not putting the part of code where I split data into train and validation: Train on 1269 samples, validate on 545 samples)


    def recall(y_true, y_pred):
    # Model: CNN
     model = Sequential()
     model.add(Conv2D(32, (3, 3), input_shape=(204, 204, 3), padding='same', activation='relu', 
     kernel_constraint=maxnorm(3)))
     model.add(Dropout(0.2))
     model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))
     model.add(MaxPooling2D(pool_size=(2, 2)))
     model.add(Flatten())
     model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))
     model.add(Dropout(0.5))
     model.add(Dense(39))
     model.add(Activation('sigmoid'))
     # Compile model
     epochs = 5
     lrate = 0.001
     decay = lrate/epochs
     sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)
     model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[precision,recall])

    # fitting the model 
     model.fit(X_train, Y_train, epochs=epochs, batch_size=32,validation_data=(X_valid,Y_valid))


**Results**

     Train on 1269 samples, validate on 545 samples
     Epoch 1/5
     96/1269 [=&gt;............................] - ETA: 6:40 - loss: 0.6668 - precision: 0.1031 - recall: 0.2493   

**Issues/Questions**   

**Question 1:** In the log of the results section , there are precision and recall values. I don't know why I got real values instead of vector of values. The way I constructed my two metrics should give me an array of shape (1,39) for precision and (1,39) for recall, which should contain precision and recall for each class, still The output is only a number?  

**Question 2:** these values of precision and recall given by the log, they represent metric calculation for a data of size= batch? How can I calculate the metric over an epoch ( which is more useful as an information than just a calculation over a batch? Some may say, just calculate the average over all batches? Sure , that's what I am thinking of but I don't know how to do it since KERAS is kinda of a black box to me and I don't exactly what is happening ''behind the scenes'' in order to follow/modify the adequate part of code?",0,3
134,2018-4-24,2018,4,24,18,8ej9cx,Nvidia's AI Realistically Reconstructs Photos,https://www.reddit.com/r/deeplearning/comments/8ej9cx/nvidias_ai_realistically_reconstructs_photos/,BlackHoleTec,1524563911,,0,2
135,2018-4-24,2018,4,24,19,8ejean,What Is Deep Learning?,https://www.reddit.com/r/deeplearning/comments/8ejean/what_is_deep_learning/,molode,1524565808,,0,1
136,2018-4-24,2018,4,24,19,8ejia0,Why Deep Learning is perfect for NLP (Natural Language Processing),https://www.reddit.com/r/deeplearning/comments/8ejia0/why_deep_learning_is_perfect_for_nlp_natural/,molode,1524567279,,0,1
137,2018-4-24,2018,4,24,21,8ejzka,How to Win with Predictive Analytics in Retail?,https://www.reddit.com/r/deeplearning/comments/8ejzka/how_to_win_with_predictive_analytics_in_retail/,y-emre,1524572701,,0,1
138,2018-4-24,2018,4,24,23,8ekxrp,"Train and Integrate Tensorflow models, utilizing PySpark ML Pipelines",https://www.reddit.com/r/deeplearning/comments/8ekxrp/train_and_integrate_tensorflow_models_utilizing/,lodev12,1524581119,,0,2
139,2018-4-25,2018,4,25,0,8el8bm,"We made a platform to get your palm read accurately by trained artificial intelligence! Give it a go, reviews and feedback are welcome :)",https://www.reddit.com/r/deeplearning/comments/8el8bm/we_made_a_platform_to_get_your_palm_read/,readmypalm,1524583403,,2,0
140,2018-4-25,2018,4,25,0,8elaon,Visual Domain Adaptation Challenge 2018,https://www.reddit.com/r/deeplearning/comments/8elaon/visual_domain_adaptation_challenge_2018/,nkaushik1,1524583914,"Announcing the 2018 Visual Domain Adaptation (VisDA) Challenge!

The VisDA challenge aims to test domain adaptation methods ability to transfer source knowledge and adapt it to novel target domains. The goal is to develop a method of unsupervised adaptation for synthetic-to-real visual domain shifts.
The competition will take place during the months of May - August 2018, and the top performing teams will be invited to present their results at the TASK-CV workshop at ECCV 2018 in Munich, Germany. This years challenge includes two tracks:

1) open-set image classification
2) object detection

We invite participants to enter in one or both tracks. Registration open now.

http://ai.bu.edu/visda-2018/",0,2
141,2018-4-25,2018,4,25,0,8elegv,Visual Domain Adaptation Challenge 2018,https://www.reddit.com/r/deeplearning/comments/8elegv/visual_domain_adaptation_challenge_2018/,nkaushik1,1524584709,,0,3
142,2018-4-25,2018,4,25,13,8eqrf5,How do i create simple neural network in tensorflow?,https://www.reddit.com/r/deeplearning/comments/8eqrf5/how_do_i_create_simple_neural_network_in/,SusmithHCK,1524629221,"i have this dataset:

|A|B|label|
|:-|:-|:-|
|1|6|1|
|10|11|0|
|20|54|0|
|32|33|0|
|44|49|1|
|10|5|1|

as you can see there is a pattern, If the difference between A and B is 5 it should return 1. Actually there is no need of NN here but i just want to learn the basics and working of tensorflow.

can someone help me write code for this nn ?

Every other tutorials seems to be advanced. Even though i have worked with other tensorflow project i couldn't understand it completely.",6,0
143,2018-4-25,2018,4,25,15,8erfb4,What Is Deep Learning - Very Well Explained Video,https://www.reddit.com/r/deeplearning/comments/8erfb4/what_is_deep_learning_very_well_explained_video/,pooja307,1524637046,,1,4
144,2018-4-25,2018,4,25,16,8ers3t,What Makes Naive Bayes Classification So Naive? | How Does Naive Bayes Classifier Work,https://www.reddit.com/r/deeplearning/comments/8ers3t/what_makes_naive_bayes_classification_so_naive/,LearningFromData,1524641747,,0,2
145,2018-4-25,2018,4,25,19,8esksa,Top 16 Open Source Deep Learning Libraries and Platforms,https://www.reddit.com/r/deeplearning/comments/8esksa/top_16_open_source_deep_learning_libraries_and/,polllyyy,1524652984,,0,3
146,2018-4-25,2018,4,25,19,8esmrs,Deep Learning for Emojis with VS Code Tools for AI,https://www.reddit.com/r/deeplearning/comments/8esmrs/deep_learning_for_emojis_with_vs_code_tools_for_ai/,molode,1524653697,,0,8
147,2018-4-25,2018,4,25,23,8eu5n0,Looking for a good tutorial explaining coding aspect of lstm in detail with example.,https://www.reddit.com/r/deeplearning/comments/8eu5n0/looking_for_a_good_tutorial_explaining_coding/,sachinky20,1524667998,,1,3
148,2018-4-26,2018,4,26,1,8euyf8,n-grams in deep learning,https://www.reddit.com/r/deeplearning/comments/8euyf8/ngrams_in_deep_learning/,rotronic,1524674056,"I am trying to use n-grams in deep learning but unable to figure out how to give an input to the network. I have checked out the sklearn count vectorizer which outputs n-grams but then how can I use these n-grams as input to a MLP in keras?
The output of count vectorizer is a sparse vector which when converted to dense does not make sense to me.

I have also tried nltk which gives the output as a list of tuples of n-grams but how do I convert this into an input that the MLP will understand?

More information if it helps: I am doing sentiment analysis on the imdb dataset using keras.",4,1
149,2018-4-26,2018,4,26,2,8evh5g,I have a dream,https://www.reddit.com/r/deeplearning/comments/8evh5g/i_have_a_dream/,[deleted],1524677988,[deleted],0,1
150,2018-4-26,2018,4,26,2,8evm52,Newbie needs some advice,https://www.reddit.com/r/deeplearning/comments/8evm52/newbie_needs_some_advice/,professorhojoz,1524679031,"Hey guys!

I'm an entrepreneur with a dream of using Deep Learning to automatically create better websites for businesses. We have a traditional website builder platform right now, and I want to make it more useful by incorporating DL into it, but at this stage, I'm not sure even the right questions to ask to get me started.

I guess I'm looking for a legit way to incorporate Deep Learning in a way that'll actually handle much of the work for the customer and come up with something that's as good or better than what they'd do on their own if they put in the time or if they hired someone.

What do you recommend I read/study/learn right away for the problem I'm trying to solve?

Long term - I'm looking for someone with a knowledge of all this stuff who's interested in this challenge that I can partner with.",0,0
151,2018-4-26,2018,4,26,4,8ewgt6,Deep Learning Tutorial Video With TensorFlow - Loved the part especially from 21 mins when he explains how neural network works with animation!,https://www.reddit.com/r/deeplearning/comments/8ewgt6/deep_learning_tutorial_video_with_tensorflow/,pooja307,1524685484,,0,8
152,2018-4-26,2018,4,26,7,8exk2j,Using RNN (LSTM) for Gesture Recognition System,https://www.reddit.com/r/deeplearning/comments/8exk2j/using_rnn_lstm_for_gesture_recognition_system/,Anasovich,1524693968,"https://datascience.stackexchange.com/q/30829/51143

any help would be appreciated.",2,5
153,2018-4-26,2018,4,26,11,8ezeq7,What would be a good curriculum to learn optimization for Deep Learning?,https://www.reddit.com/r/deeplearning/comments/8ezeq7/what_would_be_a_good_curriculum_to_learn/,QinLu,1524710810,"I have started to learn more about optimization for Deep Learning. The obvious starting point is http://www.deeplearningbook.org/contents/optimization.html.  Yet, It would be great to have learning material that expands the content introduced in the book,  or introduces more recent development.",0,5
154,2018-4-26,2018,4,26,12,8ezjvl,[R] Teach Machine to Comprehend Text and Answer Question with Tensorflow - Part I,https://www.reddit.com/r/deeplearning/comments/8ezjvl/r_teach_machine_to_comprehend_text_and_answer/,h_xiao,1524712216,,1,13
155,2018-4-26,2018,4,26,20,8f1sm9,Detecting small features in large images. Is cutting the original image into small tiles and running CNN on each tile a good solution?,https://www.reddit.com/r/deeplearning/comments/8f1sm9/detecting_small_features_in_large_images_is/,eobermuhlner,1524740865,"I want to detect small features \(50 \- 200 pixels\) in pretty large images \(6720x4480 pixels\).

I am afraid that I lose the feature when I downscale too much.

Currently I am considering of cutting the original image into many small tiles \(for example 128x128 or 256x256\) and use a CNN on each of the smaller tiles to categorize into \[background, feature1, fature2, ...\]. Downscaling by a small factor \(for example 2\-4\) is still an option.

Is this a feasible approach or is there some different approach?",4,3
156,2018-4-26,2018,4,26,21,8f29ab,"Deep Learning for Head CT scans: 9 Emergency Findings, Validation on ~22k scans, &gt;0.9 AUCs, Publicly Available Dataset",https://www.reddit.com/r/deeplearning/comments/8f29ab/deep_learning_for_head_ct_scans_9_emergency/,saucysassy,1524745832,,1,8
157,2018-4-27,2018,4,27,1,8f47j3,What's the best DL framework for text?,https://www.reddit.com/r/deeplearning/comments/8f47j3/whats_the_best_dl_framework_for_text/,professorhojoz,1524761742,"Hey DL!

We are starting a test project and want to train a Deep Learning framework with a couple thousand high-quality pieces of text (advertising headlines) to examine patterns and eventually write its own high-quality headlines.

I'm not sure which framework to use -- I see SageMaker works with a bunch of them, including TensorFlow, Pytorch, etc..  

In your experience what's the best DL framework for analyzing and producing text?

thank you!",0,0
158,2018-4-27,2018,4,27,4,8f5gcg,Possible to expect net loss of &lt;$300 for building deep learning machine?,https://www.reddit.com/r/deeplearning/comments/8f5gcg/possible_to_expect_net_loss_of_300_for_building/,74throwaway,1524771162,"I am considering building my own machine for deep learning. I am interested in using this to work on hobby and personal projects \(I already have a full\-time job\) related to computer vision and deep learning. I am about to receive a Raspberry Pi, so I was thinking of using them together

I saw some webpages showing how to build a Deep Learning machine for around $800:

[https://www.oreilly.com/learning/build\-a\-super\-fast\-deep\-learning\-machine\-for\-under\-1000](https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000)

[https://towardsdatascience.com/build\-a\-deep\-learning\-rig\-for\-800\-4434e21a424f](https://towardsdatascience.com/build-a-deep-learning-rig-for-800-4434e21a424f)

These were both written last year. For the latter one, I checked the prices of the parts that sold on Ebay, and found that the used working ones were able to sell for as low as:

|Component|Price paid by guy in towardsdatascience link|Lowest prices for used component on eBay|
|:-|:-|:-|
|[GeForce GTX 1060](https://www.amazon.com/gp/product/B01LW14DG7/ref=oh_aui_detailpage_o00_s00?ie=UTF8&amp;th=1) 6GB|218|$150\-158|
|240 GB Sandisk SSD|70, 50| $45\-60, $20\-30|
|CPU Intel Core i3\-6100|110|$70\-80|
|Case|40|Didn't check|
|Power Supply EVGA 750W 80\+|89|$50\-70|
|RAM 2x [8GB of Corsair Vengeanc](https://www.amazon.com/gp/product/B01HKF450S/ref=oh_aui_search_detailpage?ie=UTF8&amp;psc=1)e|100|$74\-110|
|Motherboard MSI Z170A Krait Gaming 3x|\~$108?|$56\-76|
|Total|785|\~$470\-586 \(excluding Case\)|

Now because I'm on a rather low budget, I would be hesitant to pay around $500\-600 for this, considering that I would probably only get to use this as a hobby for at most 30 hours/week, since I have a full\-time job and other things to worry about. Moreover, it is possible I could only use this for at most 6\-12 months because I could quit the job and travel, or other unforseen possibilities. However, I would be much more willing to spend this money if I knew I could eventually re\-sell them and get half the money back. 

Would it be reasonable to expect to use these for around 6\-12 months, and then re\-sell them on ebay/Craigslist/whatever and get around $250\-300 back? Or could I get away with being newer, more expensive components than in the table above, and still expect to have a net loss of at most $300?",3,2
159,2018-4-27,2018,4,27,6,8f6f5u,Data consisting of variable number of 2 dimensional points?,https://www.reddit.com/r/deeplearning/comments/8f6f5u/data_consisting_of_variable_number_of_2/,aulisaulisaulis,1524778844,"I'm sort of a beginner to DL, but I'm working on a small project in keras where each sample has a variable amount of dimensions \(think bar graph data, or experimental spectra\). Each of my samples basically consists of a set of \(x,y\) pairs. However, I'm not really sure how to convert my raw data into data that I could use in a neural net.

One naive idea I had was just to pad the data for every single point that shows up \(and have their y values at 0\), but that seems like it wouldn't work very well, since the data would become extremely high dimensional \(and sparse\). 

Does anybody have any ideas of how I could best represent the data?",0,1
160,2018-4-27,2018,4,27,12,8f8n2r,Why Do Neural Networks Need An Activation Function? (by Computer Vision Specialist),https://www.reddit.com/r/deeplearning/comments/8f8n2r/why_do_neural_networks_need_an_activation/,Batareika_1,1524799716,,2,7
161,2018-4-27,2018,4,27,14,8f9df3,Why cnn are much deeper than fully connected ?,https://www.reddit.com/r/deeplearning/comments/8f9df3/why_cnn_are_much_deeper_than_fully_connected/,bushaev,1524808037,"Practice shows that convolutions neural networks work better as they get deeper, the same cant be said about fully connected networks, where 3-layer network can be as good as 7-layer network, why is that ?",4,4
162,2018-4-27,2018,4,27,17,8fa0is,Comparing Googles TPUv2 against Nvidias V100 on ResNet-50,https://www.reddit.com/r/deeplearning/comments/8fa0is/comparing_googles_tpuv2_against_nvidias_v100_on/,digitalson,1524816590,,1,19
163,2018-4-27,2018,4,27,17,8fa1gx,Hyperparameters tuning with Polyaxon  Polyaxon,https://www.reddit.com/r/deeplearning/comments/8fa1gx/hyperparameters_tuning_with_polyaxon_polyaxon/,trumtra,1524816971,,0,1
164,2018-4-27,2018,4,27,17,8fa672,Implementing Deep Learning Methods and Feature Engineering for Text Data: The GloVe Model,https://www.reddit.com/r/deeplearning/comments/8fa672/implementing_deep_learning_methods_and_feature/,jackblun,1524818995,,0,4
165,2018-4-28,2018,4,28,2,8fdhqt,iMac with eGPU ???,https://www.reddit.com/r/deeplearning/comments/8fdhqt/imac_with_egpu/,2141rika,1524850471,Is it possible to connect iMac desktop with eGPU (Titan or GTX 1080 Ti) for deep learning research??,3,3
166,2018-4-28,2018,4,28,4,8fe9z4,AI Weekly 27 April 2018,https://www.reddit.com/r/deeplearning/comments/8fe9z4/ai_weekly_27_april_2018/,TomekB,1524856722,,0,2
167,2018-4-28,2018,4,28,15,8fi5du,mozilla/DeepSpeech - A TensorFlow implementation of Baidu's DeepSpeech architecture.,https://www.reddit.com/r/deeplearning/comments/8fi5du/mozilladeepspeech_a_tensorflow_implementation_of/,stephentt-me,1524896437,,0,14
168,2018-4-28,2018,4,28,18,8fiy9j,A step by-step guide for tensorflow gpu installation on ubuntu 18.04,https://www.reddit.com/r/deeplearning/comments/8fiy9j/a_step_bystep_guide_for_tensorflow_gpu/,kekayan,1524909210,,2,15
169,2018-4-28,2018,4,28,22,8fjwny,"Do you think RNN (including LSTM, attention model) can really do time-series prediction?",https://www.reddit.com/r/deeplearning/comments/8fjwny/do_you_think_rnn_including_lstm_attention_model/,helmetti,1524922431,"I'm disappointed a bit about RNN. I've never seen ""real"" time-series prediction. Even in Kaggle, I only can see boring ""one step aheaded"" Bitcoin price prediction. Especially it seems miserable on multi valiate prediction. How do you think?",5,5
170,2018-4-29,2018,4,29,0,8fkkfz,"[Question] If the training data is licensed one (e.g. images), the trained model's licence belong to whom? Me? Who has the licence of training data? Or Machine?",https://www.reddit.com/r/deeplearning/comments/8fkkfz/question_if_the_training_data_is_licensed_one_eg/,helmetti,1524929167,Many people scraping training data from websites which has copyright. Is it legal?,5,6
171,2018-4-29,2018,4,29,1,8fkywy,Ohad Shamir (Weizman Institute) -- Is depth needed for Deep Learning?,https://www.reddit.com/r/deeplearning/comments/8fkywy/ohad_shamir_weizman_institute_is_depth_needed_for/,DrJohanson,1524932977,,0,8
172,2018-4-29,2018,4,29,14,8fpfzs,Can a recurrent neural network perform the same functions as a Kalman filter?,https://www.reddit.com/r/deeplearning/comments/8fpfzs/can_a_recurrent_neural_network_perform_the_same/,interstellarhighway,1524979543,"I've read that RNNs are particularly well suited for time series predictions, especially equipped with LSTM units that can learn from past data and estimate dependence between instants. 

This makes me wonder: can RNNs perform estimation like conventional Kalman filters do? For example, in the case of an IMU, typically Kalman filters predict the orientations given raw data from the individual sensors. Would the RNN be able to learn the mapping between raw IMU data and filtered orientations, and predict for future timesteps? If so, it brings me to my second question: would they also be able to 'learn' the parameters that model the IMU: such as bias, noise etc.?",2,14
173,2018-4-29,2018,4,29,17,8fq47g,Factor Analysis And Its Applications | Understanding Factor Analysis,https://www.reddit.com/r/deeplearning/comments/8fq47g/factor_analysis_and_its_applications/,LearningFromData,1524989979,,0,1
174,2018-4-29,2018,4,29,19,8fqmjk,"Using deep learning to detect relationships between patterns (number of occurrences, order, etc)",https://www.reddit.com/r/deeplearning/comments/8fqmjk/using_deep_learning_to_detect_relationships/,wa3dbk,1524998688,"Deep learning models such as CNNs try to find a number a simple patterns (edges,lines, etc) from which it can infer more complex shapes like a car or a face and each layer represents a higher level of abstraction leading to the final prediction.

My problem is being able to find relationships between patters like repetition and order without paying much attention to the patterns presented to the network. I've been reading Hinton's paper on capsule networks I don't think that's the right way of going about this. Any suggestions about the kind of system/architecture to be used for this kind of problems is welcome.",1,1
175,2018-4-29,2018,4,29,22,8fr7ed,"Deep Learning from first principles in Python, R and Octave  Part 7",https://www.reddit.com/r/deeplearning/comments/8fr7ed/deep_learning_from_first_principles_in_python_r/,tvganesh,1525006950,,0,1
176,2018-4-29,2018,4,29,23,8frjn6,Terraform + AWS: Fully Automated Provisioning of AWS Spot Instances for GPU-based Deep Learning Workloads,https://www.reddit.com/r/deeplearning/comments/8frjn6/terraform_aws_fully_automated_provisioning_of_aws/,brownmamba94,1525011000,,3,12
177,2018-4-30,2018,4,30,9,8fvo1z,Looking for books and white papers on deep learning and CNNs (pdf),https://www.reddit.com/r/deeplearning/comments/8fvo1z/looking_for_books_and_white_papers_on_deep/,RikiMaro18,1525048765,"Hello, I'm new to deep learning and I'm trying to learn deep learning and CNNs but I have trouble finding good free books/whitepapers with detailed explanations on google. ",7,7
178,2018-4-30,2018,4,30,15,8fxefh,Is there any AI chat app based on deep learning?,https://www.reddit.com/r/deeplearning/comments/8fxefh/is_there_any_ai_chat_app_based_on_deep_learning/,everytalker,1525068482,"I want to talk to AI machine.
But I hope the machine have AI based on deep learning.
Do you know it?",2,0
179,2018-4-30,2018,4,30,18,8fyamg,Feedback on a neural net API for my written-from-scratch tensor library (x-post /r/neuralnetworks),https://www.reddit.com/r/deeplearning/comments/8fyamg/feedback_on_a_neural_net_api_for_my/,Karyo_Ten,1525081749,"Hey, I've been working for a bit more than a year on my own tensor library from scratch (first commit on April 13, 2017).

What started as a hobby and curiosity project to learn more about linear algebra, machine learning, deep learning and a young programming language called Nim became a huge evening time sink.

After implementing Numpy-like ndarrays, Torch/Tensorflow like primitives, I just finalised the first part of my high-level API which hopefully takes the best from Keras and PyTorch.

Id like your feedback on that. Quick note on Nim, it is a strongly typed language, hence why you see f32/float32 from time to time.

For example, declaring a two-layers NN currently is like this:

    # ##################################################################
    # Environment variables
    
    # N is batch size; D_in is input dimension;
    # H is hidden dimension; D_out is output dimension.
    let (N, D_in, H, D_out) = (64, 1000, 100, 10)
    
    # Create the autograd context that will hold the computational graph
    let ctx = newContext Tensor[float32]
    
    # Create random Tensors to hold inputs and outputs, and wrap them in Variables.
    let
      x = ctx.variable(randomTensor[float32](N, D_in, 1'f32))
      y = randomTensor[float32](N, D_out, 1'f32)
    
    # ##################################################################
    # Define the model.
    
    network ctx, TwoLayersNet:
      layers:
        fc1: Linear(D_in, H)
        fc2: Linear(H, D_out)
      forward x:
        x.fc1.relu.fc2
    
    let
      model = ctx.init(TwoLayersNet)
      optim = model.optimizerSGD(learning_rate = 1e-4'f32)
    
    # ##################################################################
    # Training
    
    for t in 0 ..&lt; 500:
      let
        y_pred = model.forward(x)
        loss = mse_loss(y_pred, y)
    
      echo &amp;""Epoch {t}: loss {loss.value[0]}""
    
      loss.backprop()
      optim.update()
This is a port of Jcjohnson PyTorch example: https://github.com/jcjohnson/pytorch-examples#pytorch-autograd.

3 examples are available directly in my repo: https://github.com/mratsim/Arraymancer/tree/master/examples.

A MNIST simple convnet with 2 conv layers, 1 hidden layer and automatic shape inference would be like this:

    randomize(42) # Random seed for reproducibility
    
    let
      ctx = newContext Tensor[float32] # Autograd/neural network graph
      n = 32                           # Batch size
    
    let
      x_train = read_mnist_images(""build/train-images.idx3-ubyte"").astype(float32) / 255'f32
      X_train = ctx.variable x_train.unsqueeze(1) # Change shape from [N, H, W] to [N, C, H, W], with C = 1
    
      y_train = read_mnist_labels(""build/train-labels.idx1-ubyte"").astype(int)
    
      x_test = read_mnist_images(""build/t10k-images.idx3-ubyte"").astype(float32) / 255'f32
      X_test = ctx.variable x_test.unsqueeze(1) Change shape from [N, H, W] to [N, C, H, W], with C = 1
      y_test = read_mnist_labels(""build/t10k-labels.idx1-ubyte"").astype(int)
    
    network ctx, DemoNet:
      layers:
        x:          Input([1, 28, 28])
        cv1:        Conv2D(x.out_shape, 20, 5, 5)
        mp1:        MaxPool2D(cv1.out_shape, (2,2), (0,0), (2,2))
        cv2:        Conv2D(mp1.out_shape, 50, 5, 5)
        mp2:        MaxPool2D(cv2.out_shape, (2,2), (0,0), (2,2))
        hidden:     Linear(mp2.out_shape.flatten, 500)
        classifier: Linear(500, 10)
      forward x:
        x.cv1.relu.mp1.cv2.relu.mp2.flatten.hidden.relu.classifier
    
    let model = ctx.init(DemoNet)
    let optim = model.optimizerSGD(learning_rate = 0.01'f32)
    
    . &lt; Training loop &gt; 
    
So what I would like to know is:

   - What are your main grips with the current neural networks library?
   - If you could do it yourself what syntax would you prefer to use for which use cases?
   - What do you think of my network declaration section?
",0,11
180,2018-4-30,2018,4,30,18,8fyax1,How do I tackle problems where the size of the input and output layer can change?,https://www.reddit.com/r/deeplearning/comments/8fyax1/how_do_i_tackle_problems_where_the_size_of_the/,jtfidje,1525081861,"Hi all. I'm trying to do some research related to a project I'm current working on, but I'm struggling to find any related research.

&amp;nbsp;

In my problem the mapping from input to output can be either of the following:

- One-to-one
- One-to-many
- Many-to-one
- Many-to-many

&amp;nbsp;

In practice it means my input is a matrix which can have an arbitrary number of rows, and the same goes for the output - the model should be able to produce a matrix with the correct number of rows where the columns can be both classes or continuous  numbers.

&amp;nbsp;

I hope I've managed to phrase the problem well enough for you all to understand what I'm looking for. Thank you all in advance for any help or guidance :-)",3,1
181,2018-4-30,2018,4,30,20,8fymfs,The Fin-ternet of Things: The Impact of IoT on Financial Services,https://www.reddit.com/r/deeplearning/comments/8fymfs/the_finternet_of_things_the_impact_of_iot_on/,y-emre,1525086178,,0,3
182,2018-4-30,2018,4,30,20,8fyu9r,"Hi, guys. Do you know how to aggregate the result of sentiment analysis for further Machine Learning?",https://www.reddit.com/r/deeplearning/comments/8fyu9r/hi_guys_do_you_know_how_to_aggregate_the_result/,InterestingPea,1525088813,"My final paper is about a prediction model for Bitcoin Price based on comments which I've extracted from Reddit and Twitter, I collected over 1000 short text per day, and used VADER to analyze them. My question is how can I calculate a specific kind of vector to represent a whole day's sentiment, I really stuck in here since I have 1000 results for a single day and it is definitely not the input of LSTM model, how should I do? do you guys have any suggestion? or should I use Doc2Vec to transfer them into word vectors which seems reasonable inputs for a Deep Learning model?",1,1
183,2018-4-30,2018,4,30,20,8fyvkm,Python GTA5,https://www.reddit.com/r/deeplearning/comments/8fyvkm/python_gta5/,errminator,1525089233,"Hello, a very basic question here: in the Sentdex YouTube tutorials of GTA5 self driving cars, is he using a purchased version of the game or is there now some version u can download online  (don't really play games so not sure whether I need buy it or not to follow along). 

Thanks",1,1
184,2018-4-30,2018,4,30,21,8fyyea,What's New in Deep Learning Research: Parameter Noise &amp; The Sentiment Neuron,https://www.reddit.com/r/deeplearning/comments/8fyyea/whats_new_in_deep_learning_research_parameter/,EdmundWorks,1525090129,,0,1
0,2018-5-1,2018,5,1,19,8g7gdz,Links to the May issue of COMPUTER VISION NEWS,https://www.reddit.com/r/deeplearning/comments/8g7gdz/links_to_the_may_issue_of_computer_vision_news/,Gletta,1525170792,"Here is the May 2018 issue of **Computer Vision News**, published by RSIP Vision: **52 pages** about Computer Vision, Biomedical Imaging, **Deep Learning** and Artificial Intelligence. Technical reviews of new papers and technologies \(with codes!\), including YOLO version 3! **Free subscription** at page 52.

HTML5 version \(recommended\) ==\&gt; [http://www.rsipvision.com/ComputerVisionNews\-2018May/](http://www.rsipvision.com/ComputerVisionNews-2018May/)

and PDF version ==\&gt; [http://www.rsipvision.com/computer\-vision\-news\-2018\-may\-pdf/](http://www.rsipvision.com/computer-vision-news-2018-may-pdf/)

**Enjoy!**",0,6
1,2018-5-2,2018,5,2,6,8gbv9j,Feature-matching Generative Adversarial Networks,https://www.reddit.com/r/deeplearning/comments/8gbv9j/featurematching_generative_adversarial_networks/,not_untrue,1525208404,,0,10
2,2018-5-2,2018,5,2,7,8gck4k,road sign recognition ?,https://www.reddit.com/r/deeplearning/comments/8gck4k/road_sign_recognition/,1CSX,1525214193,"Hello everyone, I was wondering if any of you have any paper that deals with the recognition of road signs \(using deep learning\). Thanks very much. ",2,5
3,2018-5-2,2018,5,2,13,8getdl,Network with Binary weights?,https://www.reddit.com/r/deeplearning/comments/8getdl/network_with_binary_weights/,atenaNg,1525236386,"I would like to restrict particular Convolution layers in a network to have binary weights. Any suggestion for paper or reference code?

Thank you",5,2
4,2018-5-3,2018,5,3,1,8girh0,Getting started with deep learning and NLP?,https://www.reddit.com/r/deeplearning/comments/8girh0/getting_started_with_deep_learning_and_nlp/,Param-eter,1525278719,"So I've been doing the Fast AI deep learning course, and while it's got some really good content, the code isn't the greatest and I'm getting errors when running some of the lessons and sometimes doing a git pull just breaks parts of my script.

I'm getting into deep learning to improve my NLP skills to incorporate embeddings.

What's the best way to get into deep learning, particularly with a focus on NLP?

",5,9
5,2018-5-3,2018,5,3,7,8glf5a,PyTorch 1.0 is going to be awesome - an engineering perspective,https://www.reddit.com/r/deeplearning/comments/8glf5a/pytorch_10_is_going_to_be_awesome_an_engineering/,not_untrue,1525299503,,1,18
6,2018-5-3,2018,5,3,15,8goapy,Creating Music by Beatboxing using Deep Learning.,https://www.reddit.com/r/deeplearning/comments/8goapy/creating_music_by_beatboxing_using_deep_learning/,sksiitb,1525328509,"Do you guys think its possible?  

If it is, is anyone already doing it?

If not, can we create an opensource project and crowdsource the data?",5,4
7,2018-5-3,2018,5,3,15,8goept,"Browse all deep learning projects, papers and pre trained models in a detailed list sorted by categories. Moreover it gives links to numerous tutorials on each project, paper and model. And the list is daily updated, so subscribe to the newsletter to get notified of latest content.",https://www.reddit.com/r/deeplearning/comments/8goept/browse_all_deep_learning_projects_papers_and_pre/,kotkaramit,1525329987,,0,1
8,2018-5-3,2018,5,3,16,8gojf0,Hello World  Raven Protocol  RavenProtocol  Medium,https://www.reddit.com/r/deeplearning/comments/8gojf0/hello_world_raven_protocol_ravenprotocol_medium/,kailashahirwar12,1525331673,,0,2
9,2018-5-3,2018,5,3,16,8gop18,ConvNet on satellite imagery time series and missing data,https://www.reddit.com/r/deeplearning/comments/8gop18/convnet_on_satellite_imagery_time_series_and/,perilo,1525333933,"
Let's suppose I want to use convnets for a segmentation task on satellite imagery. Using the information of the evolution of a given area over time would be great, let's say the last 4 months. The problem is that clouds are a big issue and a lot of images are simply unusable. For example, in the period of one month, of the 6 images captured (one every 5 days), only one is not completely covered by clouds.

What are some common practices for cases like this?",1,1
10,2018-5-3,2018,5,3,17,8goyt2,Disentanglement in NLP - toy dataset equivalent to dSprites dataset,https://www.reddit.com/r/deeplearning/comments/8goyt2/disentanglement_in_nlp_toy_dataset_equivalent_to/,solingermuc,1525337977,"Hello Deep Learning Reddit community,

I am working on disentanglement in the area of natural language processing and I am wondering if anyone has an idea, if there is a similar dataset to the one used for disentanglement of images published by Deepmind. Their dataset is called ""dSprites - Disentanglement testing Sprites dataset"". 

Link:
https://github.com/deepmind/dsprites-dataset


I am looking for a similar dataset for text learning, where one can generate/got simple sentences with different subjects (I,you,he,she,...), different verbs and also different objects and therefore get a dataset with all grammatical correct variations of combinations.

Thank you!",0,1
11,2018-5-3,2018,5,3,21,8gpw2g,OCR model,https://www.reddit.com/r/deeplearning/comments/8gpw2g/ocr_model/,hristo_rv,1525349542,"Hello, i am looking for an OCR model that can recognize images with text like the Quotes/Memes found on the internet. That means different colors,positions and angles of the text. With that said i cant use Tessaract and i need a better solution.

Is there any trained model for OCR capable of doing this? I cant train it myself since i dont have the hardware or the money to use the cloud solutions.",1,4
12,2018-5-3,2018,5,3,22,8gqax9,[Blog] Managing Deep Learning Workloads on Japans RAIDEN Supercomputer with Univa Grid Engine http://bit.ly/2HP22O2,https://www.reddit.com/r/deeplearning/comments/8gqax9/blog_managing_deep_learning_workloads_on_japans/,alejandralopzs,1525353561,,0,6
13,2018-5-4,2018,5,4,2,8gs1nl,"[PyTorch for Computer Vision 2]: GPU in Deep Learning, do you need one? - The AI Journal",https://www.reddit.com/r/deeplearning/comments/8gs1nl/pytorch_for_computer_vision_2_gpu_in_deep/,databiryani,1525367871,,0,3
14,2018-5-4,2018,5,4,4,8gt25o,Disentanglement in NLP - toy dataset equivalent to dSprites dataset,https://www.reddit.com/r/deeplearning/comments/8gt25o/disentanglement_in_nlp_toy_dataset_equivalent_to/,solingermuc,1525375806,,0,7
15,2018-5-4,2018,5,4,9,8gvd8j,Can you provide tutorials and guides for totally new students?,https://www.reddit.com/r/deeplearning/comments/8gvd8j/can_you_provide_tutorials_and_guides_for_totally/,KevinNintyNine,1525395429,,7,1
16,2018-5-4,2018,5,4,14,8gx0kp,Convolutional Neural Networks: The Biologically-Inspired Model,https://www.reddit.com/r/deeplearning/comments/8gx0kp/convolutional_neural_networks_the/,janemoz,1525413124,,0,1
17,2018-5-4,2018,5,4,18,8gxzlw,Export images from Tensorboard / read tensorboard raw data?,https://www.reddit.com/r/deeplearning/comments/8gxzlw/export_images_from_tensorboard_read_tensorboard/,Jadeyard,1525426550,"How can I extract the data from the tensorboard visualization/files in order to plot it with a different program or include it as .png somewhere else? Googled for a while, but didn't find a clear answer yet. I saw some comments about csv export but didnt find a tutorial for it.

Thanks!",0,1
18,2018-5-5,2018,5,5,11,8h4lej,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/deeplearning/comments/8h4lej/are_you_interested_in_ai_and_want_to_start/,DiscoverAI,1525487310,,1,13
19,2018-5-5,2018,5,5,14,8h5i7r,Average salary in data/AI-related professions,https://www.reddit.com/r/deeplearning/comments/8h5i7r/average_salary_in_dataairelated_professions/,_data_scientist_,1525498112,"In today's job market in the States and Canada, which group of people make the most on average?

\- Data Scientists?

\- Applied \(Deep Learning\) Research Scientists who put recent research results into production?

\- Pure \(Deep Learning\) Research Scientists who come up with novel algorithms and architectures?",0,2
20,2018-5-6,2018,5,6,0,8h8bck,AI Weekly 5 May 2018,https://www.reddit.com/r/deeplearning/comments/8h8bck/ai_weekly_5_may_2018/,TomekB,1525535102,,0,1
21,2018-5-6,2018,5,6,2,8h8uy9,[YouTube] Neural Voice Cloning,https://www.reddit.com/r/deeplearning/comments/8h8uy9/youtube_neural_voice_cloning/,ajhalthor,1525540115,,5,20
22,2018-5-6,2018,5,6,4,8h9y9y,Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/8h9y9y/deep_learning_in_python/,whimsical_monkey,1525550022,"A new version of [Conx](http://conx.readthedocs.io/en/latest/), a Deep Learning library in Python, allows easy exploration of sophisticated models. Start here: [http://conx.readthedocs.io/en/latest/](http://conx.readthedocs.io/en/latest/) but check out AlphaZero: [http://nbviewer.jupyter.org/github/Calysto/conx\-notebooks/blob/master/work\-in\-progress/AlphaZero.ipynb](http://nbviewer.jupyter.org/github/Calysto/conx-notebooks/blob/master/work-in-progress/AlphaZero.ipynb) and VGG16: [http://nbviewer.jupyter.org/github/Calysto/conx\-notebooks/blob/master/VGG16&amp;#37;20and&amp;#37;20ImageNet.ipynb](http://nbviewer.jupyter.org/github/Calysto/conx-notebooks/blob/master/VGG16%20and%20ImageNet.ipynb) Demonstrations at PyCon 2018.",0,1
23,2018-5-6,2018,5,6,7,8hayux,Concepts heavily involved or related with text/natural language processing,https://www.reddit.com/r/deeplearning/comments/8hayux/concepts_heavily_involved_or_related_with/,seands,1525559767,As a programmer and marketer I notice most of my projects on the drawing board require heavy use of text / natural language processing. Being a motivated self learner I'd like to put together a list of concepts to make sure I'm checking all the right boxes; what are the important concepts I should put on my list for this subset of deep learning?,0,1
24,2018-5-6,2018,5,6,12,8hcnqv,"Deep Learning from first principles in Python, R and Octave  Part 8",https://www.reddit.com/r/deeplearning/comments/8hcnqv/deep_learning_from_first_principles_in_python_r/,tvganesh,1525577860,,0,1
25,2018-5-6,2018,5,6,17,8hducp,LSTM Networks (RNN/GRUs) Explained,https://www.reddit.com/r/deeplearning/comments/8hducp/lstm_networks_rnngrus_explained/,vector_machines,1525593865,,1,15
26,2018-5-6,2018,5,6,17,8he0ep,Rephrase Neural Network : Find the Fittest Word for Given Meaning,https://www.reddit.com/r/deeplearning/comments/8he0ep/rephrase_neural_network_find_the_fittest_word_for/,complectere,1525596510,"Hi, I am a sophomore student who's interested in deep learning and its method layering up some linear/non-linear operations and makes up the complex function through the network.

I'd like to comprise a network that finds the word for the given explanation ; 

e.g. input: a spherically shaped fruit which tastes sour and sweet and gets red when matured well output: apple 

e.g., input: to make up the boundary between multiple options for the base of one's behavior or decision output: determine.


So basically it's a classification problem but the class might be more than 20,000.

I'd like to name this task ""rephrase neural network"". 

Any good reference or starting point, or, any network recommendation for comprising this neural network?

",1,2
27,2018-5-6,2018,5,6,22,8hf6od,"What is some software that takes my favourites, files, and/or email and categorizes them into different area of interests?",https://www.reddit.com/r/deeplearning/comments/8hf6od/what_is_some_software_that_takes_my_favourites/,Italian_Nerd,1525613358,"It would use a hierarchical and/or tag categorization. Ideally it would also suggest new content based on my interests.

Do you know of any such thing?",2,1
28,2018-5-7,2018,5,7,10,8hjtt0,How could i import U-Net using caffe in matlab (windows 8),https://www.reddit.com/r/deeplearning/comments/8hjtt0/how_could_i_import_unet_using_caffe_in_matlab/,ahmedsharf11,1525655735,Iam trying to import U-net a pre trained  network to matlab using caffe but every time i try to it get an error while i import .prototxt and .caffemodel files,1,1
29,2018-5-7,2018,5,7,16,8hlr6y,"Deep Conversations: Lisha Li, Principal at Amplify Partners",https://www.reddit.com/r/deeplearning/comments/8hlr6y/deep_conversations_lisha_li_principal_at_amplify/,molode,1525678553,,0,6
30,2018-5-7,2018,5,7,16,8hlrsn,How to do Semantic Segmentation using Deep learning,https://www.reddit.com/r/deeplearning/comments/8hlrsn/how_to_do_semantic_segmentation_using_deep/,magneticono,1525678791,,2,21
31,2018-5-7,2018,5,7,21,8hmy2l,What is the best (Tesorflow) Optimizer for multi label classification ?,https://www.reddit.com/r/deeplearning/comments/8hmy2l/what_is_the_best_tesorflow_optimizer_for_multi/,Naughty_Nagaland,1525694450,,7,4
32,2018-5-7,2018,5,7,22,8hnesl,Validation loss never decreases,https://www.reddit.com/r/deeplearning/comments/8hnesl/validation_loss_never_decreases/,rotronic,1525699044,"I am training a sentiment analysis model using different methods on IMDB dataset. I have tried out BoW model till now and used a MLP and a CNN for classification. But in all the models the validation loss always increases. even if i change the learning rate. What am i doing wrong?
I have plotted the train and val loss.
link to project: https://github.com/rgujju/sentiment-analysis

",1,1
33,2018-5-8,2018,5,8,0,8ho85z,Any experience with graying out background in training images for CNN?,https://www.reddit.com/r/deeplearning/comments/8ho85z/any_experience_with_graying_out_background_in/,eobermuhlner,1525705961,"I currently have the \(not unusual\) problem of having not many samples for some categories in a classification project using CNN. Besides the usual augmentation tricks \(crop, rotation, scale, illumination, ...\) I wonder whether I could improve the training set be graying out the non\-relevant part \(background\) of some images.

My reasoning is that the CNN would then be less confused by the background and only learn the relevant features.

A possible enhancement would be to make this an additional augmentation step that adds random noise to the background \(thereby creating even more samples out of every original image\).

I am a bit afraid that the CNN might learn the editing artifacts instead.

Has anybody done this already or knows any relevant papers about this?",3,8
34,2018-5-8,2018,5,8,3,8hpu9c,Case study: How Google Is Using Deep Learning AI,https://www.reddit.com/r/deeplearning/comments/8hpu9c/case_study_how_google_is_using_deep_learning_ai/,jonfla,1525718486,,0,1
35,2018-5-8,2018,5,8,9,8hsi26,Deep Learning A-Z: Hands-On Artificial Neural Networks,https://www.reddit.com/r/deeplearning/comments/8hsi26/deep_learning_az_handson_artificial_neural/,SmartUdemy,1525739800,"Appreciate your review. Thanks in advance. Smile Android Game Development for Beginners - Promotion For limited time! Limited coupons.
+23 hours Learn to create Deep Learning Algorithms in Python from two Machine Learning &amp; Data Science experts. Templates included.

This course is simply awesome. Anyone get an understanding about deep learning within such a short time. This could be a starting point for deep learning enthusiastic persons.It gives perfect overview about deep learning, though some in-depth explanations needed.
https://deal5star.com/deep-learning-a-z-hands-on-artificial-neural-networks-2/",4,0
36,2018-5-8,2018,5,8,10,8hstu5,"If we combine one trainable parameters with a non-trainable parameter, is the original trainable param trainable?",https://www.reddit.com/r/deeplearning/comments/8hstu5/if_we_combine_one_trainable_parameters_with_a/,real_charlie_parker,1525742604,[https://stackoverflow.com/questions/50144597/if\-we\-combine\-one\-trainable\-parameters\-with\-a\-non\-trainable\-parameter\-is\-the\-or/50215456#50215456](https://stackoverflow.com/questions/50144597/if-we-combine-one-trainable-parameters-with-a-non-trainable-parameter-is-the-or/50215456#50215456),0,1
37,2018-5-8,2018,5,8,20,8hw0p2,Video Object Detection: Detecting object in the video frames (sequentially),https://www.reddit.com/r/deeplearning/comments/8hw0p2/video_object_detection_detecting_object_in_the/,uridah,1525779789,"My goal is to detect an object that is being flashed in front of a camera. Therefore, the input is a video (converted into images (frames)) and the sequence matters.
I am trying to figure out how to go about training it. Usually video object detection algorithms detect objects in each frame. My problem is that the objects I am trying to classify are similar and the object is not fully visible in any single frame (because of a hand holding it). In order to correctly tell what the object is you have to look at multiple frames.
I found https://www.tensorflow.org/versions/master/tutorials/recurrent_quickdraw which looks at the data sequentially but I am not sure how to map it to my situation. Anyone else knows about any implementations of a similar problem or potential ways of solving it.",3,6
38,2018-5-8,2018,5,8,21,8hw6ub,Keras random_rotation introducing noise. Have used code arguments direct from API. Not sure what the problem is?,https://www.reddit.com/r/deeplearning/comments/8hw6ub/keras_random_rotation_introducing_noise_have_used/,errminator,1525781556,,1,0
39,2018-5-8,2018,5,8,21,8hwakm,Instance Segmentation using Deep Learning,https://www.reddit.com/r/deeplearning/comments/8hwakm/instance_segmentation_using_deep_learning/,Zeolearn,1525782579," As we all know, object detection is the task of detecting objects in an image in the form of a bounding box. What if we wanted to get a more accurate information about the object? Youd go for more than a rectangle \(bounding box\), maybe a polygon which represents the object more tightly. But thats still not the best way. The best way would be to assign each pixel inside the bounding box which actually has the object. This task is called as Instance segmentation, where you segment the object instances. ",2,2
40,2018-5-9,2018,5,9,0,8hxj6c,Detecting Uncertainty from Facial Images,https://www.reddit.com/r/deeplearning/comments/8hxj6c/detecting_uncertainty_from_facial_images/,Goron97,1525793018,,0,10
41,2018-5-9,2018,5,9,1,8hy07q,"AI at massive scale, and Reinforcement Learning in industry",https://www.reddit.com/r/deeplearning/comments/8hy07q/ai_at_massive_scale_and_reinforcement_learning_in/,e_ameisen,1525796550,,0,12
42,2018-5-9,2018,5,9,5,8i00c5,"Getting an error ""ValueError: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.""",https://www.reddit.com/r/deeplearning/comments/8i00c5/getting_an_error_valueerror_the_first_layer_in_a/,haidershahzeb,1525811262,"I am trying to combine CNN with LSTM but getting the error in when executes the 2nd line in the following code:
model=Sequential()
model.add(TimeDistributed(Convolution2D(64, (2,2), border_mode= 'valid' , input_shape=( 2, 2), dim_ordering='th' activation= 'relu')))
model.add(TimeDistributed(Convolution2D(64, (1,1), border_mode= 'valid', activation= 'relu')))
model.add(TimeDistributed(MaxPooling2D(pool_size=(1,1))))
model.add(TimeDistributed(Convolution2D(64, (1,1), activation= 'relu' )))
model.add(TimeDistributed(MaxPooling2D(pool_size=(1,1))))
model.add(TimeDistributed(Dropout(0.0)))
model.add(TimeDistributed(Flatten()))
model.add(TimeDistributed(Dense(16, activation= 'relu' )))
model.add(TimeDistributed(Dense(16, activation= 'relu' )))
#lstm
m=Sequential()
m.add(LSTM(units = 1, activation='sigmoid'))",0,1
43,2018-5-9,2018,5,9,14,8i3idq,Regression model never converge,https://www.reddit.com/r/deeplearning/comments/8i3idq/regression_model_never_converge/,L_E_I,1525843405,"Hi all, I am a new to deep learning, now I implemented a Fully-connected neural network and CNN based model to do prediction task, and the loss is defined by RMSE. 
1. However, I found that the training loss will keep getting lower, no matter how many epochs I use. Is this normal or I do something wrong?
2. Besides, for prediction task, is there any good regularization norms?",4,1
44,2018-5-9,2018,5,9,15,8i3tg5,[P] Seg-mentor - A TF based sanbox for exploring semantic segmentation,https://www.reddit.com/r/deeplearning/comments/8i3tg5/p_segmentor_a_tf_based_sanbox_for_exploring/,falex-ml,1525847236,,0,1
45,2018-5-9,2018,5,9,20,8i5bhh,The Difference Between AI and Machine Learning,https://www.reddit.com/r/deeplearning/comments/8i5bhh/the_difference_between_ai_and_machine_learning/,y-emre,1525866442,,0,0
46,2018-5-9,2018,5,9,22,8i5vt3,Building a simple Generative Adversarial Network (GAN) using TensorFlow,https://www.reddit.com/r/deeplearning/comments/8i5vt3/building_a_simple_generative_adversarial_network/,keghn,1525871734,,1,24
47,2018-5-9,2018,5,9,22,8i65ez,Five Important Techniques That You Should Know About Deep Learning,https://www.reddit.com/r/deeplearning/comments/8i65ez/five_important_techniques_that_you_should_know/,Zeolearn,1525874092,,0,0
48,2018-5-10,2018,5,10,14,8icmze,RMDL: Random Multimodel Deep Learning for Classification,https://www.reddit.com/r/deeplearning/comments/8icmze/rmdl_random_multimodel_deep_learning_for/,kk7nc,1525931400,,0,2
49,2018-5-10,2018,5,10,21,8iekkl,Q learning help,https://www.reddit.com/r/deeplearning/comments/8iekkl/q_learning_help/,Jandevries101,1525956142,"Hey,

 i am new to the Q learning coding. And i am wondering how it is done. I watched alot of tutorials and i know the state and trail and error terms, but when it gets to the code i don't really get what to do.... if somebody could help/explain to me some more information, would be appreciated!

so what i want to create with this code = Input is numbers or visual, doesn't matter for the outcome really... by the way is only numbers even possible with qlearning? the AI will make a decision when he feels like its the right moment, between action1 or action2. When action1 or action2 is performed the game will return a number above 0 or higher, or 0 or lower. when he gets 0 or higher that will mean a trail, i heard with qlearning they give alot of examples with +1 and -1, but i think higher numbers can do the same? objective is of course get the highest number possible and if its a high number and the AI thinks it won't go ""Higher"" he will perform another command that will restart the game.

the code sample i think i will ""need"" (got from a youtuber, not touched), if you could maybe let me know if this is indeed enough for my plan, let me know. I don't need you to tell exactly how to code the whole plan, but some help would be appreciated :), cause i am stuck at this. 

N_STATES = 6				#Lenght of the 1 dimensional world
ACTIONS = ['LEFT', 'RIGHT']	#Available action
EPSILON = 0.9				#Greedy police
ALPHA = 0.1					#Dearning rate
GAMMA = 0.9					#Discount factor
MAX_EPISODES = 13			#Maximum episodes
FRESH_TIME = 0.3			#Fresh time for one move


def build_q_table(n_states, actions):					#Enviroment
	table = pd.DataFrame(
		np.zeros((n_states, len(actions))),				#Q_table initial values	
		columns=actions, 								#Action name
		
	)
	print(table)										#Show Table
	return table
#build_q_table(4, ['a', 'b'])
#exit()
		
		
		
		
def choose_action(state, g table):						#Actie plek
	state_actions = q_table.iloc[state, :]
	if (np.random.uniform() &gt; EPSILON or (state_actions.all() == 0): #act non greedy or state-iets
		action_name = np.random.choice(ACTIONS)
	else: #act greedy
		action_name = state_actions.argmax()
	return action_name
	
	
	
	
def get_env_feedback(S, A):
    # This is how agent will interact with the environment
    if A == 'right':    # move right
        if S == N_STATES - 2:   # terminate
            S_ = 'terminal'
            R = 1
        else:
            S_ = S + 1
            R = 0
    else:   # move left
        R = 0
        if S == 0:
            S_ = S  # reach the wall
        else:
            S_ = S - 1
    return S_, R


	
	
def update_env(S, episode, step_counter):
    # This is how environment be updated
    env_list = ['-']*(N_STATES-1) + ['T']   # '---------T' our environment
    if S == 'terminal':
        interaction = 'Episode %s: total_steps = %s' % (episode+1, step_counter)
        print('\r{}'.format(interaction), end='')
        time.sleep(2)
        print('\r                                ', end='')
    else:
        env_list[S] = 'o'
        interaction = ''.join(env_list)
        print('\r{}'.format(interaction), end='')
        time.sleep(FRESH_TIME)


		
		
def rl():
    # main part of RL loop
    q_table = build_q_table(N_STATES, ACTIONS)
    for episode in range(MAX_EPISODES):
        step_counter = 0
        S = 0
        is_terminated = False
        update_env(S, episode, step_counter)
        while not is_terminated:

            A = choose_action(S, q_table)
            S_, R = get_env_feedback(S, A)  # take action &amp; get next state and reward
            q_predict = q_table.loc[S, A]
            if S_ != 'terminal':
                q_target = R + GAMMA * q_table.iloc[S_, :].max()   # next state is not terminal
            else:
                q_target = R     # next state is terminal
                is_terminated = True    # terminate this episode

            q_table.loc[S, A] += ALPHA * (q_target - q_predict)  # update
            S = S_  # move to next state

            update_env(S, episode, step_counter+1)
            step_counter += 1
    return q_table

	
	

if __name__ == ""__main__"":
    q_table = rl()
    print('\r\nQ-table:\n')
    print(q_table)



Already thanks for replying on this post!

~Jan",0,1
50,2018-5-10,2018,5,10,22,8iewxr,fast.ai course part 2 (2018 New!),https://www.reddit.com/r/deeplearning/comments/8iewxr/fastai_course_part_2_2018_new/,ScotchMonk,1525959292,,1,21
51,2018-5-10,2018,5,10,22,8ieywp,Introduction to Recommender Systems in 2018,https://www.reddit.com/r/deeplearning/comments/8ieywp/introduction_to_recommender_systems_in_2018/,minmidinosaur,1525959804,,2,5
52,2018-5-10,2018,5,10,23,8ifdsh,How to implement a YOLO (v3) object detector from scratch in PyTorch: Part 1,https://www.reddit.com/r/deeplearning/comments/8ifdsh/how_to_implement_a_yolo_v3_object_detector_from/,bzindovic,1525963246,,0,34
53,2018-5-10,2018,5,10,23,8iffta,Deep Learning in Scala Part 1: Basics and Libraries by Soren Brunk,https://www.reddit.com/r/deeplearning/comments/8iffta/deep_learning_in_scala_part_1_basics_and/,EdmundWorks,1525963692,,1,4
54,2018-5-11,2018,5,11,0,8ifl1m,What are some original graduation projects ideas that uses deep learning?,https://www.reddit.com/r/deeplearning/comments/8ifl1m/what_are_some_original_graduation_projects_ideas/,ASamir,1525964802,"We're interested in building a product whether a website or an app that includes deep learning in areas like CV, NLP or etc. ",1,3
55,2018-5-11,2018,5,11,10,8ik4ic,"How to calculate/compare the quality of text generated by two RNNs, w.r.t to data which is used to train it?",https://www.reddit.com/r/deeplearning/comments/8ik4ic/how_to_calculatecompare_the_quality_of_text/,ghost-research,1526002926,"Consider two RNN based on LSTMs, which are trained on same text data. Is there any way to measure the quality of text generated by them? [ NOT talking about translation]. Can we use BLEU score for the same? BLEU score can be used to evaluate translations, but not sure about if can use it in this case also... In this case, we have RNN based on LSTM, which is first trained on a text dataset, and then at inference, it outputs some textual data.",9,5
56,2018-5-12,2018,5,12,4,8iqisb,AI Weekly 11 May 2018,https://www.reddit.com/r/deeplearning/comments/8iqisb/ai_weekly_11_may_2018/,TomekB,1526067332,,0,3
57,2018-5-12,2018,5,12,9,8isnt4,What's wrong with my variational autoencoder?,https://www.reddit.com/r/deeplearning/comments/8isnt4/whats_wrong_with_my_variational_autoencoder/,domokato,1526086462,"Hi guys, new here, and somewhat new to deep learning. I've been stuck on this thing for a couple days and could use some help. [Here's my VAE](https://render.githubusercontent.com/view/ipynb?commit=4cc9fcaee4f6b9798e4344a3d88e6e9557ebfdfa&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f646f6d6f6b61746f2f6d6e697374636e6e2f346363396663616565346636623937393865343334346133643838653665393535376562666466612f6d6e6973746175746f656e636f6465722e6970796e62&amp;nwo=domokato%2Fmnistcnn&amp;path=mnistautoencoder.ipynb&amp;repository_id=131773529&amp;repository_type=Repository#2.-Variational-Autoencoder-(VAE)---(WIP)). Please scroll down to section 2. I used these [two](https://blog.keras.io/building-autoencoders-in-keras.html) [webpages](https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/) as a rough guide. You can see at the bottom of my jupyter notebook that my generated digits look nothing like the digits at the bottom of the first page I mentioned. I tried using the simple two\-layer Dense network architecture that they used just to check if my architecture was the problem, but it ended up looking even worse. I'm not sure what I'm doing wrong? Thanks",5,3
58,2018-5-13,2018,5,13,23,8j3zkl,Help with multi-label classification,https://www.reddit.com/r/deeplearning/comments/8j3zkl/help_with_multilabel_classification/,mkinkela,1526220338,"Hi, I'm new to deep learning. I got huge amount of movie posters and I have to classify them to 11 movie genres. One movie can have multiple genres. I split images into train and test subsets. Then I made 2 directories (train and test) and inside them I made one directory for each of the genres. 

So, my question is. Why is my trained model giving me strange results? For instance, if learning rate is below 1e-4 then both accuracies are stuck at 0.9091 and if i set learning rate to something close to 1e-6 then in 30 epochs I get from 50% to 60% train accuracy and 70-80% validation accuracy. When I make a graph, those 2 lines don't ever intersect (the same is with loss lines). When I try to make bar graph it shows me that 1 or 2 classes are inferior to others and predicted arrays arent event close to given test outputs.

Since my problem explaining capabilities aren't very good, I think that the best way to show you my problem is by pasting part of my code:

MODEL
model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, channels)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(3, 3)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(3, 3)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(11,activation='sigmoid'))

opt=SGD(lr=1e-3, decay=0.1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=1e-5)
model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])

train_datagen = ImageDataGenerator(rescale=1./255,)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        'train',  
        target_size=(256, 256), 
        batch_size=batch_size)

test_generator = test_datagen.flow_from_directory(
        'test',
        target_size=(256, 256),
        batch_size=batch_size)

history = model.fit_generator(
        train_generator,
        steps_per_epoch=n_train // batch_size,
        epochs=10,
        validation_data=test_generator,
        validation_steps=n_test // batch_size,
        callbacks=[reduce_lr],
        shuffle=True
)

model.save_weights('model_wieghts.h5')
model.save('model_keras.h5')

",15,5
59,2018-5-14,2018,5,14,5,8j6sos,ELI5 Deep Learning starting with Zero Abstractions. [Long Post],https://www.reddit.com/r/deeplearning/comments/8j6sos/eli5_deep_learning_starting_with_zero/,sksiitb,1526244079,"I wanted to make the perfect tea. I couldnt take the taste of the ginger tea I recently had in Bangalore. That ginger, the perfect amount of milk! Neither too much, nor too less. The satisfaction of the hot sip of tea making its way through my throat in that chilly winter morning was something that I was craving for a very long time. I needed this. I indeed did.

I looked up recipes for making ginger tea, but if you are anything like me, You know that we almost always screw up any dish. So I decided to do it myself. No recipe. No formula. But my goal was to feel that satisfaction again. 

Note that I did know where to begin, I knew the ingredients were tea leaves, water, milk, sugar &amp; ginger. I knew I had to experiment with these items, these inputs to my recipe. I had to create a drink out of so many individual ingredients, so many inputs, there was some secret unknown proportion of these very ingredients, these inputs that made the tea perfect or ruined it. This proportion was the key. The amount of each ingredient, How many cups of water, how many cups of milk, how many grams of ginger, how many grams of sugar do I need to add? What the right weights of each ingredients?

And in that moment a thought crossed my head, Tea doesnt actually exist. Tea is just a name we have given to the mixture of all these individual ingredients, these individual items, inputs. Its still all these inputs, but at the same time neither one of them. Its something more. Had I chucked milk, It would have black tea. Again, common base ingredients but something new. Oh and if I had kept it in a freezer, it would be an ice\-tea? Isnt it still the same common base ingredients? The same inputs? But now its something new. Oh and add lemon to it, its a lemon\-ice\-tea now isnt it? Tea doesnt actually exist! Its just the ingredients mixed in a certain proportion. Lemon\-ice\-tea doesnt actually exist, the ingredients do. Its just a name weve given to the mixture of inputs. At the core of it, its still about the ingredients and the proportions. Its still about the inputs and the weights. And there was something that we did to those ingredients which turned them into tea. We transformed those ingredients to something special. We transformed those inputs. So it wasnt just about the right proportions i.e. the right weights but also about the transformation.

Anyhow, lets come back to the main story. The satisfaction of ginger tea!

So I started. I put half a cup of water. Note two things here. Water \(My ingredient / My input\). Half a cup \(The proportion / The weights\). Then I added a cup of milk to it. Note again, Milk = Ingredient / Input. A cup = Proportion / Weight. A tea spoon of Tea Leaves. As you must have already noticed by now, Tea Leaves = Inputs, A tea Spoon = weight. Two tea spoons of sugar \(Sugar = input, A spoon = weight\) and of course, my favourite, a ginger slice approximately half the size of your thumb \(Ginger = input, half a thumb = weight\) 

And then came the important step! Boiling. The transformation. Transformation of our ingredients into something new \(Tea\). Transformation of our inputs.

When it was done, it was time to taste the tea, the output. What was I looking for? The satisfaction. I closed my eyes, finally took the first sip and although fine, it was no where near what I really wanted. To put it in numbers, I was perhaps just 60&amp;#37; satisfied. Well If I really want to have success at making this work, maybe I shouldnt be satisfied, I should be dissatisfied. Dissatisfied until there is no more dissatisfaction. I should measure my dissatisfaction instead. I was 60&amp;#37; satisfied so that makes 100&amp;#37;\-60&amp;#37;=40&amp;#37; Dissatisfied. I knew it was very watery. Water was a major contributor to this disaster. The Ginger was about fine, but a little more would be better. But very sweet. Yes Sugar was a major contributor to the disaster too

The next day I began again. But this time, I had insight. I had to reduce water, reduce sugar, add ginger. But note one thing here! I had to reduce sugar a LOT. I had to reduce water SOMEWHAT. I had to add ginger a LITTLE more. 

I repeated the process again. Added the ingredients\(inputs\) in the new proportion\(weights\). Boiled them\(transformed\).

Now it was the testing time again. I tasted it. Well, not bad. But not the best either. 80&amp;#37; satisfied. Oops, I mean 20&amp;#37; dissatisfied. Ginger was a little more and Sugar less. I had to correct my recipe. I had to Optimise it. I had to reduce the ginger now, by a very little value. So I made my changes and followed the process again. 

The next few days went on like this. 

Added the ingredients\(inputs\) in the new proportion\(weights\). Boiled them\(transformed\).Tasted\(tested\). Corrected\(Optimised\). Repeat. The dissatisfaction kept reducing.

And then one fine day, I took the hot sip of tea making its way through my throat and there it was. 0&amp;#37; dissatisfaction, or let me call it 100&amp;#37; satisfaction now.

And in this moment another profound thought came to my mind. Isnt this how the world works? Few people are dissatisfied. Be it a teacher in the school, who wants his students to achieve an A\+? He starts with teaching the syllabus \(Inputs\), few topics more important than others \(the weights\), gives them assignments to make them understand the knowledge better \(transform\) Give them exams \(Tests\) take feedback and improve knowledge of students \(Optimise\) and repeat until it all works out?

Isnt that how a cricket team wins the World Cup? They start by sending out certain players \(inputs\) with a certain proportion of bowlers / batsmen / allrounders. They play the match \(transformation\). See the result of a match\(Test\). Make changes to team based on performance \(optimising\) and repeat until you have the perfect team?

This process of achieving solutions to problems which dont have a formula is somewhat interesting. 

Few days back, when I was reading about deep learning, I couldnt help but notice how the Deep Neural Networks work. They have a certain inputs like numbers / images / etc \(ingredients in our case\),with certain weights, which are transformed into newer numbers and then tested based on a criteria called loss function\(like satisfaction&amp;#37; in our case\) and then optimised using an optimiser function\(changing quantities\) and repeating the process several times until the loss function gives a reduced value \(reducing the dissatisfaction in our case\) and achieving the goal.",3,0
60,2018-5-14,2018,5,14,18,8jatzx,Loss going to infinity on siamese network with contrastive loss,https://www.reddit.com/r/deeplearning/comments/8jatzx/loss_going_to_infinity_on_siamese_network_with/,FrStealer,1526288642,"Hello, 
I want to train a siamese network on my own dataset. I've got 10 classes and my goal is to finetune AlexNet in order to compare the class with each other.
I am struggling on the contrastive loss minimisation, it goes to NaN  even when i change the learning_rate, the batch_size or the dropout_rate = 0.2.

A little sample of my code, i will show more if you need more:

left = model1.fc8 #Model1 is a simple AlexNet
right= model2.fc8 #Model2 is Model1 with shared weigths

#### contrastive loss ####
d = tf.reduce_sum(tf.square(left - right), 1)
d_sqrt = tf.sqrt(d)
loss = y * tf.square(tf.maximum(0., margin - d_sqrt)) + (1 - y) * d
loss = 0.5 * tf.reduce_mean(loss)
 
### Optimization ### 
train_op=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)

I also tried:
gradients = tf.gradients(loss, var_list)
gradients = list(zip(gradients, var_list))
optimizer = tf.train.GradientDescentOptimizer(learning_rate)
train_op = optimizer.apply_gradients(grads_and_vars=gradients)  

#train_op=optimizer.minimize(loss=loss,global_step=tf.train.get_global_step))

The rest of the code is  actually classic (batch, sess.run).

I just do not understand why the loss is going to Nan after a few iteration, even when i lower the learning rate to 10^-20.

Sorry for my english, it is not my first language, thank you in advance.
        ",0,2
61,2018-5-14,2018,5,14,20,8jbgho,"Text summarize with Google, Amazon or Azure?",https://www.reddit.com/r/deeplearning/comments/8jbgho/text_summarize_with_google_amazon_or_azure/,duyth,1526296838,"hi guys,
I'm evaluating Amazon, Google and Azure for a small project that involves text summarization. Has anyone had experience with one of these 3 platforms and can recommend one?  Or is there a better solution that I should know of?
Thanks",0,1
62,2018-5-14,2018,5,14,22,8jcbou,Currently experimenting with two-layer LSTMs. Should I continue training?,https://www.reddit.com/r/deeplearning/comments/8jcbou/currently_experimenting_with_twolayer_lstms/,E-3_A-0H2_D-0_D-2,1526305315,"I'm currently playing around with LSTMs in Keras. For starters, I decided to go for character generation. I'm using Pink Floyd's lyrics as a corpus. Here are the details:

Number of unique characters in the corpus:  **48**

Sequence length: **50**

Number of sequences generated:  **113627** 

Input shape:  **\(113627, 50, 1\)** 

Output shape:  **\(113627, 48\)** 

Word Embedding used: **No**

A small code snippet of the architecture:

    def build_model(in_shape, out_shape):
      # Keras imports.
      from keras.layers import LSTM
      from keras.layers import Activation
      from keras.models import Sequential
      from keras.layers import Dropout
      from keras.layers import Dense
      
      # Start building the model.
      model = Sequential()
      
      # Add the first LSTM layer. Remember to set the return_sequences argument to
      # True, and specify the input shape.
      model.add(LSTM(64, input_shape=(in_shape[1], in_shape[2]),
                     return_sequences=True))
      
      # Add Dropout.
      model.add(Dropout(0.6))
      
      # Add the second LSTM layer. Do not set return_sequences=True here.
      model.add(LSTM(64))
      
      # Add Dropout.
      model.add(Dropout(0.55))
      
      # Add the final softmax layer.
      model.add(Dense(out_shape[1], activation='softmax'))
      
      print(""Model built!"")
      return model

**Side Note:** I've also used the `LearningRateScheduler` to decay the Learning Rate \(1e\-3\) by 10&amp;#37; every 25 epochs.

A small snippet of the setup:

    def schedule(epoch, lr):
      # Reduce learning rate every e epochs.
      if epoch % LR_DECAY_INTERVAL == 0 and epoch != 0:
        
        old_lr = lr
        
        # decay the lr by x% of it's original value.
        lr = lr - (LR_DECAY_INTENSITY * lr)
        
        print(""Epoch number %d: Reduced lr by %f percent. Old lr = %s, new lr = %s"" 
              % (epoch, LR_DECAY_INTENSITY*100, str(old_lr)[:6], str(lr)[:6]))
        
      return lr
    
    
    # Start the model training.
    def train_model(model, X, y, num_epochs, b_size):
      from keras.callbacks import EarlyStopping
      from keras.callbacks import LearningRateScheduler
      
      # Set up the scheduler.
      lr_scheduler = LearningRateScheduler(schedule, verbose=0)
      
      print(""Fitting data to model..."")
      
      stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, 
                              verbose=0, mode='min')
      
      # Save all the epoch data in the history object.
      history = model.fit(X, y, batch_size=b_size, epochs=num_epochs, 
                          validation_split=0.2
                          ,callbacks=[lr_scheduler]
                         )

After \~50 epochs, here's how the loss graph looks:

[Loss after 50 epochs](https://i.redd.it/hv24s6maptx01.png)

After \~80 epochs:

[Loss after 80 epochs](https://i.redd.it/im7h2eo1rtx01.png)

My question is this \- Should I train the network for a longer time? You all might be noticing the drift between the validation and training loss at around 45^(th) epoch, denoting the onset of a variance problem. Some more additional follow\-up questions:

* Should I increase the regularization strength?
* Reducing the sequence length seems like a viable option to me. Should I try that out?

Any tips would be appreciated. Please let me know if any additional code is required. 

Thanks!",5,4
63,2018-5-15,2018,5,15,4,8jfaih,RMDL: Random Multimodel Deep Learning for Classification,https://www.reddit.com/r/deeplearning/comments/8jfaih/rmdl_random_multimodel_deep_learning_for/,kk7nc,1526327563,,0,4
64,2018-5-15,2018,5,15,7,8jgmeh,unsupervised clustering of short text based on similarity - which model do you recommend me?,https://www.reddit.com/r/deeplearning/comments/8jgmeh/unsupervised_clustering_of_short_text_based_on/,juice_456,1526338012,"Hi guys

Im very new in deeplearning and have a problem..

i have a dataset of one milion rows with short text and i want to cluster them based on their similarity

my question is now which model do you recommend me to do that or a better question is if it is even possible to do that?

would really appreciate if you could give me some advise/personal experience...
",1,2
65,2018-5-15,2018,5,15,12,8jim5z,Visualizing the activations within an RNN?,https://www.reddit.com/r/deeplearning/comments/8jim5z/visualizing_the_activations_within_an_rnn/,quackzilla2,1526356252,"I would like to see the values of each activation inside of an RNN after making a prediction. I would like to find which neurons get excited when predicting text. 

I want to write a program that makes a prediction, and then grabs random activations and overlays them on a graph with the string printed and show a heatmap of what kind of text gets that neuron excited. I hope to find out and visualize some of the rules that it learns. 

But I've spent a while trying to figure out how to extract this information from a Tensorflow model at the prediction step and have gotten nowhere. 

I'm open to using any framework. Tensorflow, PyTorch, Keras, etc. 

Thanks in advance! ",1,2
66,2018-5-15,2018,5,15,15,8jjdtc,"CNN training, oversampled a minority class for the training set, should I also do the same for validation set?",https://www.reddit.com/r/deeplearning/comments/8jjdtc/cnn_training_oversampled_a_minority_class_for_the/,CaliforniaCoder,1526364759,"I have oversampled a minority class in my training set, should I also oversample that same class for my validation set? I know not to do that for my test case.
I have not oversampled that class in my validation set because I thought it would be more representative of what the test case would ultimately look like.

Just wanted to see what your thoughts were.",1,1
67,2018-5-15,2018,5,15,17,8jk2m3,Deep Learning Applications - Live Session with Mike Tamir (Head of Data Science UBER ATG)- May 16 - 3.30 PM(GMT),https://www.reddit.com/r/deeplearning/comments/8jk2m3/deep_learning_applications_live_session_with_mike/,pooja307,1526374177,,0,6
68,2018-5-15,2018,5,15,23,8jm40l,Interesting TechCrunch article on how deep learning with synthetic data will democratize the tech industry!,https://www.reddit.com/r/deeplearning/comments/8jm40l/interesting_techcrunch_article_on_how_deep/,happymod,1526395450,,4,8
69,2018-5-16,2018,5,16,2,8jnaxo,"Where do I find medical imaging datasets for deep-learning, apart from kaggle?",https://www.reddit.com/r/deeplearning/comments/8jnaxo/where_do_i_find_medical_imaging_datasets_for/,ritabratamaiti,1526404446,,2,4
70,2018-5-16,2018,5,16,4,8joc0m,What if AI makes play too predictable?,https://www.reddit.com/r/deeplearning/comments/8joc0m/what_if_ai_makes_play_too_predictable/,stinkytofu415,1526412029,,0,0
71,2018-5-16,2018,5,16,5,8jos5p,Deep learning real time analytics,https://www.reddit.com/r/deeplearning/comments/8jos5p/deep_learning_real_time_analytics/,catchergg,1526415373,"Hi,

I'm responsible for Outliers detection at my job. We currently do a hourly batch statistical model analysis of our data. So that once every hour we aggregate our data and then run analysis process which updates our statistical models and if something is abnormal it set up an alert.

This approach was fine for a while, but now we are trying to push towards two things (possibly combined):
1. Real time analytics.
2. Deep learning.

We've started going towards streams. 

Our data is mainly textual (Username, IP, Session start / End and so on) , but we also have a 'free text' (represent user query with the system) - We have a predefined language so users could interact with the system. Similar to any command line interface. Users can create objects and interact with them using the language. The data is ordered by time and is quite repetitive (Users tend to do roughly same queries with different values) 

I thought about using LSTMs, since from what I understand it works with sequenced data. The thing is - can it work with streams? Can it learn from the stream? Are there any references for this kind of thing?

Am I even going to the right direction?  What do you think? Got any suggestions or other references? ",8,6
72,2018-5-16,2018,5,16,7,8jpt7g,"from tensorflow to fpga , is it possible ?",https://www.reddit.com/r/deeplearning/comments/8jpt7g/from_tensorflow_to_fpga_is_it_possible/,batbouyassou,1526423422,"hello guys,

I've compiled a python program using tensorflow functions, now that i have the ready trained model can i transfer it to an fpga ? maybe extract registers and then convert them to describe the neural net hardwarely ?

thank you !
",4,3
73,2018-5-16,2018,5,16,22,8juuhw,Using parallel capsules with Keras in Python.,https://www.reddit.com/r/deeplearning/comments/8juuhw/using_parallel_capsules_with_keras_in_python/,mount_sumInt,1526476814,I need to make the most of my GPU. How can I compute thousands of capsules in parallel? Thank you for the help. :),2,6
74,2018-5-17,2018,5,17,4,8jxjdq,Comparison of DL frameworks,https://www.reddit.com/r/deeplearning/comments/8jxjdq/comparison_of_dl_frameworks/,ejpak,1526497296,"Hey guys,

I'm new to deep learning and was wondering if there is an updated version of this link \(which describes the best frameworks for different uses\), OR if an expert could update on this. \[Something along the lines of the attached pic\]

Thank you very much. ",5,3
75,2018-5-17,2018,5,17,4,8jxkfd,Get dzdx of of a any NN layer in python,https://www.reddit.com/r/deeplearning/comments/8jxkfd/get_dzdx_of_of_a_any_nn_layer_in_python/,imransalam,1526497515,"In matlab we use matconvnet's vl_nnconv with x, F, B, Y. This is how it looks in matlab. 

Example 1
l = net.layers{i}
[res(i).dzdx, dzdw{1}, dzdw{2}] = vl_nnconv(res(i).x, l.weights{1}, l.weights{2}, res(i+1).dzdx)

Example 2
l = net.layers{i}
[res(i).dzdx] = vl_nnpool(res(i).x, res(i+1).dzdx)


Assume that in Example 2 res(i).x is a matrix of size (29, 29, 512) and res(i+1).dzdx is a matrix of size (15, 15, 512). The result is res(i).dzdx, of shape (29, 29, 512) respectively.

I am interested in exactly the same thing but in python, pytorch or keras precisely. I am trying to use just a simple numpy array (or a pytorch tensor/variable) for my equivalent of res(i).x and res(i+1).dzdx (and weights). Is there anyway that can be achieved? Thanks.",0,1
76,2018-5-17,2018,5,17,4,8jxo6l,An Introduction to Deep Learning for Tabular Data,https://www.reddit.com/r/deeplearning/comments/8jxo6l/an_introduction_to_deep_learning_for_tabular_data/,gagejustins,1526498285,,0,9
77,2018-5-17,2018,5,17,4,8jxoip,2D to 3D image representation - Deep Learning (Caffe help),https://www.reddit.com/r/deeplearning/comments/8jxoip/2d_to_3d_image_representation_deep_learning_caffe/,ejpak,1526498363,"Hi guys, 

I'm trying to implement this algorithm to represent a 2D image with a dense 64D feature. Paper: [https://arxiv.org/abs/1603.08637](https://arxiv.org/abs/1603.08637) Code: [https://github.com/rohitgirdhar/GenerativePredictableVoxels](https://github.com/rohitgirdhar/GenerativePredictableVoxels) 

This algorithm in built on Caffe, and I'm having a hard time setting it up. Not much help online. I would have preferred to use PyTorch/ Tensorflow, since they have a lot of support. Do you guys know of any similar implementation/codes? 

Thanks for your help! ",0,4
78,2018-5-17,2018,5,17,6,8jyhmh,Auto-Deep Learning for Video &amp; Images,https://www.reddit.com/r/deeplearning/comments/8jyhmh/autodeep_learning_for_video_images/,sumitg,1526504519,"Please check out this new software that we built that automatically picks a model and trains it using deep learning for videos &amp; images.   This software called PowerAI Vision, also enables semi-automatic labeling, because you can label a small set of images or video frames, train a model, and then used the trained model for labeling the rest of the data.  Then correct some labels, retrain, relabel, and repeat.   This makes it much easier to label image / video data
[Blog on PowerAI Vision](https://medium.com/@sumitg_16893/deep-insights-with-ai-for-video-analytics-5464fd30ebe1)

Sumit",0,1
79,2018-5-17,2018,5,17,10,8k0efz,CNN,https://www.reddit.com/r/deeplearning/comments/8k0efz/cnn/,1CSX,1526521371,"I know that convolutional neural networks regularly are supervised learning, but ... do they use backpropagation? or do they use another algorithm? Thank you.",4,1
80,2018-5-17,2018,5,17,14,8k1w0k,[R] Arbitrary Facial Attribute Editing: Only Change What You Want,https://www.reddit.com/r/deeplearning/comments/8k1w0k/r_arbitrary_facial_attribute_editing_only_change/,LynnHoHZL,1526536224,,1,2
81,2018-5-17,2018,5,17,15,8k20l6,[P] AttGAN-Tensorflow,https://www.reddit.com/r/deeplearning/comments/8k20l6/p_attgantensorflow/,LynnHoHZL,1526537620,,0,1
82,2018-5-17,2018,5,17,15,8k26t6,Deep Learning with Ensembles of Neocortical Microcircuits - Dr. Blake Richards,https://www.reddit.com/r/deeplearning/comments/8k26t6/deep_learning_with_ensembles_of_neocortical/,otakuman,1526539618,,1,24
83,2018-5-17,2018,5,17,16,8k2fyg,"Deep text summarization: of amazon reviews, github issues and news articles",https://www.reddit.com/r/deeplearning/comments/8k2fyg/deep_text_summarization_of_amazon_reviews_github/,tttttm,1526542613,,1,7
84,2018-5-17,2018,5,17,17,8k2rff,Deep Learning top relevant and latest news feed,https://www.reddit.com/r/deeplearning/comments/8k2rff/deep_learning_top_relevant_and_latest_news_feed/,mr_j_b,1526547195,,0,1
85,2018-5-17,2018,5,17,20,8k3o75,Q-Learning,https://www.reddit.com/r/deeplearning/comments/8k3o75/qlearning/,Jandevries101,1526558234," Hey Reader

 &amp;nbsp; 

I am pretty new to the Q\-Learning area, but i really want to learn it! I watched some tutorials already, but i don't really understand how to code it, for example if i see some example code for Q\-Learning i don't really understand what it going on. I know the terms for the most part, but not were to implement them in the code.

 &amp;nbsp; 

**Main Question** 

* Explanation of Q\-Learning code \(Also Where Parameters should be placed\) 
* What exactly is ""Gamma""? I can't really find a clear answer on the internet for that. 
* How much space does a ""big"" Q\-Learning dataset take? do i need like TBs or are we talking about somewhere between 100Gb for a pretty learned Dataset? 
* Is there a point where the Q\-Learning AI doesn't need much more Data anymore? I mean that it saves on a certain point ony useful data? 
* Does the Q\-Learning has to do constantly actions or can you make it that it waits with his next action when he needs to \(if not maybe create action ""do nothing""?\)

 &amp;nbsp; 

Already thank you for your response!

 &amp;nbsp; 

Greetings, 

 &amp;nbsp; 

Jan",1,5
86,2018-5-17,2018,5,17,21,8k40a9,Re-train model with new classes,https://www.reddit.com/r/deeplearning/comments/8k40a9/retrain_model_with_new_classes/,dilipajm,1526561525,"I have built an image classifier with 2 classes, say 'A' and 'B'. I have also saved this model, using model.save().

Now, after a certain time, the requirement arose to add one more class 'C'. Is it possible to load_model() and then add only one class to the previously saved model so that we have the final model with 3 classes ('A','B' and 'C'), without having to retrain the whole model, for classes 'A and 'B' again?

Can anyone help?

I have tried this:

I used vgg16 as a base model and pop out its last layer, freeze weights and added one dense layer (DL2), trained it for predicting 2 classes.

Then I added one more dense layer on top of DL2 say DL3, freeze weights and train with class C only but now its always predicting class C.

https://stackoverflow.com/questions/50366160/re-train-model-with-new-classes
",0,1
87,2018-5-18,2018,5,18,2,8k5xs6,"Diffrence between model.compile(), model.fit(), model.evaluate(), model.predict() ?",https://www.reddit.com/r/deeplearning/comments/8k5xs6/diffrence_between_modelcompile_modelfit/,Dump7,1526577211,"I am new to ML and trying to build a basic NN using Keras.
I am not able to understand the difference help me out will you? ",2,0
88,2018-5-18,2018,5,18,5,8k7i3f,3D Coordinates to Voxel to 3DCNN,https://www.reddit.com/r/deeplearning/comments/8k7i3f/3d_coordinates_to_voxel_to_3dcnn/,VoxelHelp,1526589177,"I have a list of 3D coordinates and am trying to take it to a voxel for a 3DCNN in Python.

1. I re\-orgin the coordinates around a point.
2. Convert/round raw coordinates so that 1 voxel equal 1 original X,Y, Z coordinate.
3. Trim down to \+/\- a certain dimension value in X Y and Z direction. I.E. only a certain distance away from the origin is used, going from 500x500x500 to 30x30x30.
4. Go from the new coordinates to 0s and 1s in an 3d array.

I am having trouble with 3 things.

1. Rotating the voxel/array so that each one will have the same rotation according to a point\(s\) near the origin.
2. There will need to be multiple channels, probably 4, of multiple voxels that feed into the network.
3. Gaussian or Interpolation to make the voxels spherical.

I've looked for info on the last 3 parts and can't seem to find any sort of information on how to accomplish it. Any help would be appreciated.",0,1
89,2018-5-18,2018,5,18,8,8k8ud9,What are some simple and easy neural network modules in Python?,https://www.reddit.com/r/deeplearning/comments/8k8ud9/what_are_some_simple_and_easy_neural_network/,Dragonnova5091,1526600687,Me and my friend are new to the game of deep learning and are having trouble finding modules that have good documentation for us to use. I have made only one small network and we are looking to make a decent sized project that requires a NN. What are some simple modules for us to use?,2,2
90,2018-5-18,2018,5,18,8,8k8v3e,Discriminative Separable Networks (DSN),https://www.reddit.com/r/deeplearning/comments/8k8v3e/discriminative_separable_networks_dsn/,kamranjanjua,1526600880,"Do you guys think there could exist a network that would be extact replica of GAN i.e. instead of generating samples from same distribution, it would distinguish between samples in a sense to check for pirated content. Much like hashing images to detect pirated images/copied images. Maybe a hidden watermark which will not be exactly visible but will exist in the image so that when features are extracted, there is an added feature(s) of that hidden mark as well. 
So, do you think DSN could exist? If so, how?? ",1,6
91,2018-5-18,2018,5,18,20,8kcjzx,My book Deep Learning from first principles now on Amazon,https://www.reddit.com/r/deeplearning/comments/8kcjzx/my_book_deep_learning_from_first_principles_now/,tvganesh,1526644231,,0,1
92,2018-5-18,2018,5,18,21,8kcupa,TensorFlow Tutorial- Explained For Beginners,https://www.reddit.com/r/deeplearning/comments/8kcupa/tensorflow_tutorial_explained_for_beginners/,pooja307,1526647267,,0,12
93,2018-5-19,2018,5,19,1,8keiqb,[N] Call for papers: iMIMIC - Workshop on Interpretability of Machine Intelligence in Medical Image Computing @ MICCAI,https://www.reddit.com/r/deeplearning/comments/8keiqb/n_call_for_papers_imimic_workshop_on/,pereirasrm,1526661213,"We would like to invite you to submit your contributions to the Workshop on Interpretability of Machine Intelligence in Medical Image  Computing ([iMIMIC](https://imimic.bitbucket.io/)) at the 2018 [MICCAI](https://www.miccai2018.org) conference in Granada.

iMIMIC is a half-day workshop to be held on September 16th, 2018. The program features two excellent keynote speakers as well as oral presentations from selected paper contributions.

This workshop aims at introducing the challenges and opportunities related to the topic of interpretability of ML systems in the context of Medical Image Computing and Computer Assisted Intervention.

Call for papers
----------------------
There will be a regular paper track (8 pages LNCS format). We intend to join the MICCAI Satellite Events joint proceedings published in LNCS. We encourage participants to submit their exploratory research work. Covered topics include but are not limited to:

- Definition of interpretability in context of medical image analysis.
- Visualization techniques useful for model interpretation in medical image analysis.
- Local explanations for model interpretability in medical image analysis.
- Methods to improve transparency of machine learning models commonly used in medical image analysis
- Textual explanations of model decisions in medical image analysis.
- Uncertainty quantification in context of model interpretability.
- Quantification and measurement of interpretability.
- Legal and regulatory aspects of model interpretability in medicine.

Please, submit your paper [here](https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FIMIMIC2018).

Important dates
----------------------
- **Submission deadline (11th June)**
- Reviews due (9th July)
- Notification of acceptance (13th July)
- Camera-ready papers (20th July)
- Half- day workshop (16th September, afternoon)

Invited speakers
----------------------
- Been Kim (Google Brain)
- Scott Lundberg (University of Washington)

More information
----------------------
For more information, please, visit the workshop's website, or, feel free to contact the organization.

Website: https://imimic.bitbucket.io/",0,9
94,2018-5-19,2018,5,19,6,8kgry0,New AI tool controls people in videos!,https://www.reddit.com/r/deeplearning/comments/8kgry0/new_ai_tool_controls_people_in_videos/,NicoleK1993,1526679951,[https://www.youtube.com/watch?v=qc5P2bvfl44&amp;feature=youtu.be&amp;t=59s](https://www.youtube.com/watch?v=qc5P2bvfl44&amp;feature=youtu.be&amp;t=7s),0,1
95,2018-5-19,2018,5,19,7,8kgxg3,New AI tool controls people in videos!,https://www.reddit.com/r/deeplearning/comments/8kgxg3/new_ai_tool_controls_people_in_videos/,NicoleK1993,1526681396,,1,72
96,2018-5-19,2018,5,19,14,8kj9a2,"Google TPU * 1  vs NVIDIA V100 *4, does it worth for rewrite my TensorFlow codes?",https://www.reddit.com/r/deeplearning/comments/8kj9a2/google_tpu_1_vs_nvidia_v100_4_does_it_worth_for/,helmetti,1526707254,"Currently I'm coding on CPU Jupyter Notebook and train by GPU.

TensorFlow works both on CPU or GPU, but when I want to use TPUs, I need to rewrite code for TPU

\(such as tf.contrib.tpu.TPUEstimator\) 1TPU and 4V100s are almost same performance and cost for now.

I wonder how you guys do debugging on TPU?",1,3
97,2018-5-20,2018,5,20,3,8kmx3p,AI Weekly 19 May 2018,https://www.reddit.com/r/deeplearning/comments/8kmx3p/ai_weekly_19_may_2018/,TomekB,1526752894,,0,1
98,2018-5-20,2018,5,20,6,8ko7gh,How to CNN count the dogs in an image with detection or without detection?,https://www.reddit.com/r/deeplearning/comments/8ko7gh/how_to_cnn_count_the_dogs_in_an_image_with/,piskil,1526764962,I want to count the dogs in a given image by employing CNNs. First alternative is to train the CNN such that it detects dog objects then count them seperately. Second one is that CNN is trained such that it directly regress to the number of dogs without explicitly detecting dogs.  Can anybody compare the alternatives?,2,3
99,2018-5-20,2018,5,20,16,8kr8d0,"[P] ""I Pity the fool"", Deep Learning style",https://www.reddit.com/r/deeplearning/comments/8kr8d0/p_i_pity_the_fool_deep_learning_style/,rragundez,1526801450,,0,11
100,2018-5-21,2018,5,21,4,8kv2r5,Real-time Sudoku Solver,https://www.reddit.com/r/deeplearning/comments/8kv2r5/realtime_sudoku_solver/,tahaemara,1526846169,,9,19
101,2018-5-21,2018,5,21,9,8kwwom,Really nice summary of AI history,https://www.reddit.com/r/deeplearning/comments/8kwwom/really_nice_summary_of_ai_history/,ScotchMonk,1526863265,,2,11
102,2018-5-21,2018,5,21,10,8kx3ty,Collaboration,https://www.reddit.com/r/deeplearning/comments/8kx3ty/collaboration/,kamranjanjua,1526865311,"Anybody up for collaborating on a DL based network and then publishing in a decent conference? 
I have an idea regarding a network but I don't have enough time to pull it off alone. I am looking for collaboration. If you are up for it, do reach out at kamranejaz98@gmail.com. 

Thanks. ",0,2
103,2018-5-21,2018,5,21,12,8kxtng,Image clustering,https://www.reddit.com/r/deeplearning/comments/8kxtng/image_clustering/,guruji93,1526872630,"Can you suggest a good unsupervised clustering algorithm for images, preferably with open source implementation?",7,7
104,2018-5-21,2018,5,21,19,8kzsqr,What Is Deep Learning and How Does It Work,https://www.reddit.com/r/deeplearning/comments/8kzsqr/what_is_deep_learning_and_how_does_it_work/,imarticus_nirmal,1526898523,,0,1
105,2018-5-21,2018,5,21,20,8l03mf,Fizzbuzz zero,https://www.reddit.com/r/deeplearning/comments/8l03mf/fizzbuzz_zero/,chocolechat,1526902203,,0,2
106,2018-5-21,2018,5,21,21,8l0kwy,What's the best deep learning machine I can build on a $500 budget?,https://www.reddit.com/r/deeplearning/comments/8l0kwy/whats_the_best_deep_learning_machine_i_can_build/,bonbonbaron,1526907176,,7,6
107,2018-5-22,2018,5,22,3,8l2vqr,Deep Q-Learning,https://www.reddit.com/r/deeplearning/comments/8l2vqr/deep_qlearning/,Jandevries101,1526925708,"Hey Reader

I am pretty new to the Q\-Learning area, but i really want to learn it! I watched some tutorials already, but i don't really understand how to code it, for example if i see some example code for Q\-Learning i don't really understand what it going on. I know the terms for the most part, but not were to implement them in the code.

**Main Question**

* Explanation of Q\-Learning code \(Also Where Parameters should be placed\)
* How much space does a ""big"" Q\-Learning dataset take? do i need like TBs or are we talking about somewhere between 100Gb for a pretty learned Dataset?
* Is there a point where the Q\-Learning AI doesn't need much more Data anymore? I mean that it saves on a certain point ony useful data?
* Does the Q\-Learning has to do constantly actions or can you make it that it waits with his next action when he needs to \(if not maybe create action ""do nothing""?\)

Please do respond or contact me if you have any ideas, also leave your own thoughts.

Already thank you for your response!

Greetings,

Jan",4,11
108,2018-5-22,2018,5,22,13,8l7682,Deploy Keras neural network to Flask web service - Video Series,https://www.reddit.com/r/deeplearning/comments/8l7682/deploy_keras_neural_network_to_flask_web_service/,blackHoleDetector,1526962438,"Learn how to deploy and host your machine learning model as a Flask web service, build a front end web application to access your model, and interact with your model in the browser with this video series.

- [Part 1 - Overview](https://youtu.be/SI1hVGvbbZ4)
- [Part 2 - Build your first Flask app](https://youtu.be/_yoxrAIf5u4)
- [Part 3 - Send and Receive Data with Flask](https://youtu.be/RkmfXz304ck)
- [Part 4 - Build a front end web application](https://youtu.be/TW_ck9NDMGI)
- [Part 5 - Host VGG16 image classification model with Flask](https://youtu.be/XgzxH6G-ufA)
- [Part 6 - Build web app to send images to VGG16](https://youtu.be/eCz_DTtUBfo)",0,12
109,2018-5-22,2018,5,22,18,8l8roa,Searching for a good text/article/book on what is deep learning and what are the differences to machine learning,https://www.reddit.com/r/deeplearning/comments/8l8roa/searching_for_a_good_textarticlebook_on_what_is/,jakjfkea,1526982443,"im studying computer science and starting just now with deep learning.
any help or pointers in the right direction are welcome :)",5,1
110,2018-5-22,2018,5,22,21,8l9rlw,"Date Extended June 05, 2018: 10th International Conference on Intelligent Human Computer Interaction (IHCI 2018)",https://www.reddit.com/r/deeplearning/comments/8l9rlw/date_extended_june_05_2018_10th_international/,ihciconf,1526993787,[removed],0,1
111,2018-5-23,2018,5,23,7,8lea19,YOLOv2 Output Tensor,https://www.reddit.com/r/deeplearning/comments/8lea19/yolov2_output_tensor/,Esc99,1527028421,Hi! I was playing around with the Darkflow version of Yolov2  \([https://github.com/thtrieu/darkflow](https://github.com/thtrieu/darkflow)\) and I was wondering how the hell is built the predictions dictionary from the output tensor of the network. This is pretty important because if you want to use the network outside the darkflow package \(for example using a generated .pb file\) you need that interpretation. Without it you have a only a 1D tensor! Is there someone that knows how to do it? ,4,4
112,2018-5-23,2018,5,23,15,8lh2di,Input to a neural network.,https://www.reddit.com/r/deeplearning/comments/8lh2di/input_to_a_neural_network/,Dump7,1527055304,"How does the NN take input? For example, I have an 8 input variables and 1 output variable dataset, then will I give single input variable to a single neuron which will result in 8 neurons in the input layer? If that's the case what if we have 100 input parameters will we have 100 neurons in the input layer?",15,0
113,2018-5-23,2018,5,23,19,8li6hu,Getting into it or first steps,https://www.reddit.com/r/deeplearning/comments/8li6hu/getting_into_it_or_first_steps/,Asrijaal,1527069978,"I'm trying to get a deeper understanding on the whole machine learning/deeplearning subject (it got my attention by the Tensorflow Google I/O 18 talks). Where - tbh - I don't understand everything totally, I'm willing to pay in time to get it. So most examples out there use preformatted datasets which is kinda nice for get something running on your machine but I struggle to ""produce"" something out of my own, in case of missing knowledge to preformat my data.

First idea/experiment:

I've got folders of source code in different programming languages and now I want a model which will predicate programming language on given text/sourceode. How are big chunks of raw data preprocessed? Keras as example operates on Numpy arrays, converting a huge list of textfiles into Numpy arrays results in Out of Memory exceptions on my machine. 
I can't really imagine that this is something out standing what I'm trying to do. 

So for my conclusion: I'm just missing theory and overview of technology. Are there resources/books/examples (beyond them with preformatted datasets) which could help me on getting into this?



",3,3
114,2018-5-23,2018,5,23,23,8ljxz0,"Searching for a 3D Dataset, segmented by 2 or more Experts",https://www.reddit.com/r/deeplearning/comments/8ljxz0/searching_for_a_3d_dataset_segmented_by_2_or_more/,ThrawNeX,1527086914,"We are looking for data sets with 3D images, preferably from the medical field. It is important that they have been segmented by more than one person/expert. An example of this is the BraTS Challenge dataset \([https://www.med.upenn.edu/sbia/brats2018/data.html](https://www.med.upenn.edu/sbia/brats2018/data.html)\) or the LIDC IDRI Dataset \([https://wiki.cancerimagingarchive.net/display/Public/LIDC\-IDRI](https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI)\), but we need more datasets for our research.

Many thanks in advance!",0,5
115,2018-5-23,2018,5,23,23,8ljy9m,Where to go with algorithmic breakthrough?,https://www.reddit.com/r/deeplearning/comments/8ljy9m/where_to_go_with_algorithmic_breakthrough/,4rtemi5,1527086978,Partly by chance and partly by very hard work I stumbled upon an algorithm to speed up training of most deep neural networks by \&gt;10x. I am fully aware of the absurdity of the situation since I am by no means an established researcher in the field so just in case you dont believe me \(which i fully understand\) I pose this as a hypothetical question: what would you do in my situation? Who would you approach with your discovery? How would you try to prove your claim? Or should I just write a paper and throw it out there? Really happy for any thoughts and suggestions!,14,0
116,2018-5-24,2018,5,24,1,8lkow8,A simple webapp using face detection directly in the browser (webGL &amp; deep-learning),https://www.reddit.com/r/deeplearning/comments/8lkow8/a_simple_webapp_using_face_detection_directly_in/,StartupJeeliz,1527092630,"[On the occasion of the soccer world cup 2018, we have released a webapp featuring makeup for fans...](https://jeeliz.com/demos/faceFilter/demos/threejs/football_fan_app/)

https://i.redd.it/plvzdtttsmz01.gif",0,5
117,2018-5-24,2018,5,24,3,8llv0q,How to build Amazon like text recognition system in python?,https://www.reddit.com/r/deeplearning/comments/8llv0q/how_to_build_amazon_like_text_recognition_system/,xpbit1024,1527101336,"I was just playing around with Amazons rekognition API and it works amazingly well with detecting text from images, how would one go about building something like that?",2,3
118,2018-5-24,2018,5,24,17,8lr3ou,Perceptual Super-Resolution Challenge @ ECCV 2018 Workshop,https://www.reddit.com/r/deeplearning/comments/8lr3ou/perceptual_superresolution_challenge_eccv_2018/,YocB,1527151135,,1,3
119,2018-5-24,2018,5,24,21,8lsczo,Deep Learning With Apache Spark: Part 2,https://www.reddit.com/r/deeplearning/comments/8lsczo/deep_learning_with_apache_spark_part_2/,polllyyy,1527166002,,0,12
120,2018-5-25,2018,5,25,2,8lumdz,ResNet Question,https://www.reddit.com/r/deeplearning/comments/8lumdz/resnet_question/,deepmariaaa,1527184058,"Hi guys!

In ResNet-50: 

http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006

What is suppossed to be doing the first pooling layer right at the begging (""pool1""). I mean, the input size is 224x224 and after the first convolution and pooling the size goes to 56x56. At that point the net starts becoming dense and doing the residual branches stuff. But why that preprocessing. Is that computionally better? Could you get better results if you dont reduce the size like that so early? 

Regards
",1,5
121,2018-5-25,2018,5,25,6,8lweof,How much of a person's face is required to ID that person?,https://www.reddit.com/r/deeplearning/comments/8lweof/how_much_of_a_persons_face_is_required_to_id_that/,PullThisFinger,1527197835,"A colleague has pretty deep roots at a Tier\-1 e\-commerce retailer. He's been told that well under 7&amp;#37; of a person's face is required to ID that person with \(TBD&amp;#37;\) confidence.

Before I dive into ArXiV \- has anybody seen a metric or paper on this?",5,3
122,2018-5-25,2018,5,25,14,8lzdgb,Setup guide for TensorFlow GPU latest release 1.8,https://www.reddit.com/r/deeplearning/comments/8lzdgb/setup_guide_for_tensorflow_gpu_latest_release_18/,DecipherTechnic,1527226482,,0,18
123,2018-5-25,2018,5,25,14,8lzgut,How do I apply deep learning model over the following dataset?https://github.com/urwithajit9/ClaMP/blob/master/dataset/ClaMP_Raw-5184.csv,https://www.reddit.com/r/deeplearning/comments/8lzgut/how_do_i_apply_deep_learning_model_over_the/,Abhijeet2410,1527227624,"How do I apply deep learning to malware dataset? Below I mentioned link malware dataset? How do I apply lstm, lstm+1D convolution, convolution+fully connected model over below given malware dataset?",0,1
124,2018-5-25,2018,5,25,15,8lzimj,How do I apply deep learning model over below mentioned malware dataset?,https://www.reddit.com/r/deeplearning/comments/8lzimj/how_do_i_apply_deep_learning_model_over_below/,Abhijeet2410,1527228246,"How do I apply LSTM, LSTM+1D convolution model, 1D convolution+fully connected model to following malware dataset  https://github.com/urwithajit9/C... by using the below-mentioned code in colab? https://colab.research.google.com/drive/1-S0c1e52mTvsqDEcdSpBJ6ZysJI9oi3T",0,1
125,2018-5-25,2018,5,25,16,8lztvg,Builders Clean London,https://www.reddit.com/r/deeplearning/comments/8lztvg/builders_clean_london/,Bfacleaning,1527232212,,0,1
126,2018-5-25,2018,5,25,19,8m0net,Deep Learning - From the Scratch for Beginners - PART 1,https://www.reddit.com/r/deeplearning/comments/8m0net/deep_learning_from_the_scratch_for_beginners_part/,pooja307,1527243408,,0,1
127,2018-5-25,2018,5,25,19,8m0nty,Deep Learning - Explained from Scratch(Tensorflow Object Detection) - Part 2,https://www.reddit.com/r/deeplearning/comments/8m0nty/deep_learning_explained_from_scratchtensorflow/,pooja307,1527243566,,0,1
128,2018-5-25,2018,5,25,19,8m0pcb,Deep Learning - Explained from Scratch(Tensorflow) - Part 1,https://www.reddit.com/r/deeplearning/comments/8m0pcb/deep_learning_explained_from_scratchtensorflow/,pooja307,1527244082,,0,13
129,2018-5-25,2018,5,25,19,8m0psk,Deep Learning - Explained from Scratch(TensorFlow Object Detection) - Part 2,https://www.reddit.com/r/deeplearning/comments/8m0psk/deep_learning_explained_from_scratchtensorflow/,pooja307,1527244234,,0,7
130,2018-5-25,2018,5,25,19,8m0tq6,Understanding Convolutional Neural Networks  Adel Nehme,https://www.reddit.com/r/deeplearning/comments/8m0tq6/understanding_convolutional_neural_networks_adel/,jackblun,1527245627,,0,3
131,2018-5-25,2018,5,25,20,8m147s,Computer Vision System Design Deep Learning and 3D Vision,https://www.reddit.com/r/deeplearning/comments/8m147s/computer_vision_system_design_deep_learning_and/,tiagomoraismorgado88,1527248867,,0,4
132,2018-5-25,2018,5,25,22,8m1or6,"Been There, Done That: Meta-Learning with Episodic Recall",https://www.reddit.com/r/deeplearning/comments/8m1or6/been_there_done_that_metalearning_with_episodic/,PullThisFinger,1527254392,,1,5
133,2018-5-25,2018,5,25,22,8m1vbu,"Loss getting close to zero, no overfit, bad result.",https://www.reddit.com/r/deeplearning/comments/8m1vbu/loss_getting_close_to_zero_no_overfit_bad_result/,FrStealer,1527256022,"Hello,

I was theoretically wondering why doesn't my data overfit.

It is in a classification problem, the loss is getting close to zero but when i test the same image \(the one i just fed the network with\), i got bad accuracy.

My question is theoretical, if you need to know more about my work in order to answer, i will be more precise.

Sorry for my English, it is my second language.

Thank you in advance.",7,2
134,2018-5-26,2018,5,26,22,8ma5nf,Q-Learning Python,https://www.reddit.com/r/deeplearning/comments/8ma5nf/qlearning_python/,Jandevries101,1527341439," Hey Reader

&amp;nbsp;

I am pretty new to the Q\-Learning area, but i really want to learn it! I watched some tutorials already, but i don't really understand how to code it, for example if i see some example code for Q\-Learning i don't really understand what it going on. I know the terms for the most part, but not were to implement them in the code. 

**Main Question**

&amp;nbsp;

* How to input the values S, A , Env in code?
* I want to predict, i should MDP for that correct?
* How much Gb space will a Q\-Learning AI take?
* Can somebody post some very easy python code about Q\-Learning and explain where every value should be placed?
* PM me to get my Discord/Telegram if you want to really help me out further.

&amp;nbsp;

Please do respond or contact me if you have any ideas, also leave your own thoughts. if you don't know the answer too, don't forget to upvote this post, so more people will see it!

&amp;nbsp;

Already thank you for your response!

&amp;nbsp;

 Greetings, 

&amp;nbsp;

Jan ",5,1
135,2018-5-27,2018,5,27,1,8mbehs,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/deeplearning/comments/8mbehs/are_you_interested_in_ai_and_want_to_start/,DiscoverAI,1527353517,,1,1
136,2018-5-27,2018,5,27,3,8mbx57,https://arxiv.org/pdf/1704.04760.pdf,https://www.reddit.com/r/deeplearning/comments/8mbx57/httpsarxivorgpdf170404760pdf/,PullThisFinger,1527358110,How Google's TPU does its magic.,2,8
137,2018-5-27,2018,5,27,3,8mbzsq,AI Weekly 26 May 2018,https://www.reddit.com/r/deeplearning/comments/8mbzsq/ai_weekly_26_may_2018/,TomekB,1527358767,,0,1
138,2018-5-27,2018,5,27,4,8mck2p,How to build an Artificial Neural Network in Java,https://www.reddit.com/r/deeplearning/comments/8mck2p/how_to_build_an_artificial_neural_network_in_java/,EndyJBC,1527363894,,0,1
139,2018-5-27,2018,5,27,9,8me9t6,Online discussion group for deeplearningbook by Ian Goodfellow,https://www.reddit.com/r/deeplearning/comments/8me9t6/online_discussion_group_for_deeplearningbook_by/,ashunigion,1527380329,"Hello everyone,

 i have started reading the deep learning  book by Ian Goodfellow, anyone out there who have already read it or is reading it and is willing to form an online discussion group?",3,11
140,2018-5-27,2018,5,27,11,8meyml,Deep Learning vs Classical Machine Learning for Healthcare,https://www.reddit.com/r/deeplearning/comments/8meyml/deep_learning_vs_classical_machine_learning_for/,kbnewreddit,1527387948,"In general, which is more preferable in the Healthcare industry? DL or Classical ML? I would love some insights from every scenario .i.e. ease of development of the product to launching it into the market.",3,2
141,2018-5-27,2018,5,27,11,8mezch,Tensor Transport Protocol v1.0.0-alpha!,https://www.reddit.com/r/deeplearning/comments/8mezch/tensor_transport_protocol_v100alpha/,sbsends,1527388192,,0,1
142,2018-5-27,2018,5,27,14,8mfwdo,Deep Reinforcement Learning For Sequence to Sequence Models (Source Code),https://www.reddit.com/r/deeplearning/comments/8mfwdo/deep_reinforcement_learning_for_sequence_to/,yaserkl,1527399553,,0,8
143,2018-5-27,2018,5,27,17,8mgmom,Tensorflow Debugging,https://www.reddit.com/r/deeplearning/comments/8mgmom/tensorflow_debugging/,ragas_,1527411420,"Hi,

I'm looking for how to debug tensorflow codes. Can someone please guide me to resources regarding this?

Thanks!",6,5
144,2018-5-27,2018,5,27,21,8mhib7,The Significance of Poisson Distribution in Statistics | Hashtag Statistics,https://www.reddit.com/r/deeplearning/comments/8mhib7/the_significance_of_poisson_distribution_in/,LearningFromData,1527424978,,1,3
145,2018-5-28,2018,5,28,15,8mo1f8,Whats the different between causal convolution and the regular one and what makes it special?,https://www.reddit.com/r/deeplearning/comments/8mo1f8/whats_the_different_between_causal_convolution/,chengchingwen,1527489141,"  Im study on using convolution for sequence and structured data and I find that they often use a causal convolution like the one in TCN(Temporal convolution network). But in my understanding, it just a convolution with padding at the beginning of the input sequence or cropping the output that involve the end padding. It doesnt seem to have any super power or stronger than the regular one.",14,7
146,2018-5-28,2018,5,28,18,8movgq,Object Detection for Similar objects,https://www.reddit.com/r/deeplearning/comments/8movgq/object_detection_for_similar_objects/,uridah,1527500409,What algorithms/networks are good for detecting similar looking objects?,1,2
147,2018-5-28,2018,5,28,23,8mq9e2,"How to easily do Topic Modeling with LSA, PSLA, LDA &amp; lda2Vec",https://www.reddit.com/r/deeplearning/comments/8mq9e2/how_to_easily_do_topic_modeling_with_lsa_psla_lda/,digitalson,1527516148,,4,11
148,2018-5-28,2018,5,28,23,8mqc2b,Graph in TensorBoard or Model Problem.,https://www.reddit.com/r/deeplearning/comments/8mqc2b/graph_in_tensorboard_or_model_problem/,FrStealer,1527516757,"Hello,

I want to use the same variable in two ""different"" network \(I want to use a Siamese Network\). To do so i used Reuse=True/False in the scope i wanted and then get the variable i wanted, the variable of the first model in the second one. However, when i check the model in tensorboard, the convolution layers are not linked and i am wondering why.   


Below a small portion of my code, where i am struggling. 

    def create(self, reuse=False):
            """"""Create the network graph.""""""
            # 1st Layer: Conv (w ReLu) -&gt; Lrn -&gt; Pool
    
            conv1 = conv(self.X, 11, 11, 96, 4, 4, padding='VALID', name='conv1',reuse=reuse)
            
            
            print(""conv1:"",conv1.name)
            norm1 = lrn(conv1, 2, 1e-05, 0.75, name='norm1')
            
            pool1 = max_pool(norm1, 3, 3, 2, 2, padding='VALID', name='pool1')
            conv2 = conv(pool1, 5, 5, 256, 1, 1, groups=1, name='conv2',reuse=reuse)
            pool2 = max_pool(conv2, 3, 3, 2, 2, padding='VALID', name='pool2')
            norm2 = lrn(pool2, 2, 2e-05, 0.75, name='norm2')
    
    def conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,
             padding='SAME', groups=1, reuse=False):
        
        convolve = lambda i, k: tf.nn.conv2d(i, k,
                                               strides=[1, stride_y, stride_x, 1],
                                                padding=padding)
        with tf.variable_scope(name,reuse=reuse) as scope:
            weights = tf.get_variable('weights', shape=[filter_height,
                                                        filter_width,
                                                        input_channels/groups,
                                                        num_filters])
            biases = tf.get_variable('biases', shape=[num_filters])
                
        conv = convolve(x, weights)
     
        # Add biases
        bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))
        # Apply relu function
        relu = tf.nn.relu(bias, name=scope.name)
    
       return relu
    
    
    
    To see the graph of the session in tensorboard: 
        writer = tf.summary.FileWriter(path, sess.graph)
    ",0,1
149,2018-5-29,2018,5,29,0,8mqy1j,MTailor Deep Learning,https://www.reddit.com/r/deeplearning/comments/8mqy1j/mtailor_deep_learning/,harrybhines,1527521843,"Does anybody know how MTailor works to measure body parts accurately? I assume they use some type of deep learning. When using their app, they require you to place your phone on the ground up against a wall at a certain angle. I assume they use this angle to undistort the perspective of the photo. Does anyone know of the math required to go about doing this?",1,6
150,2018-5-29,2018,5,29,8,8muazb,Unsure what input data structure to use,https://www.reddit.com/r/deeplearning/comments/8muazb/unsure_what_input_data_structure_to_use/,Hexillium,1527549519,"If I have data on two teams competing, and say a pool of exactly 20 people that can play at any given time on either of the teams and get a strict team 1 won or team 2 won result, what's the best input layer structure to have?

I tried having 40 input nodes (the first 20 for each of the players being on team 1 [each node being 1 or 0 for the player being there or not] second 20 for the other team), but this didn't work well and effectively creates two players per player.

What is the best structure for trying to analyse which team will win? ",2,4
151,2018-5-29,2018,5,29,10,8mv794,is it possible to build an ASR specific to a business domain ?,https://www.reddit.com/r/deeplearning/comments/8mv794/is_it_possible_to_build_an_asr_specific_to_a/,Abhijeet3922,1527557912,I am about to start exploring KALDI toolkit to build a production level ASR system for a specific business domain (for example say banking or insurance domain) . I wanted to know how realistic it is to build such a product. Has anyone here had developed such systems with KALDI ?,2,5
152,2018-5-29,2018,5,29,11,8mvj74,Identical object - Image Classification,https://www.reddit.com/r/deeplearning/comments/8mvj74/identical_object_image_classification/,tilakd,1527560898,[removed],0,1
153,2018-5-29,2018,5,29,17,8mxgv2,Deep learning: Memory error with arrays and lists in python,https://www.reddit.com/r/deeplearning/comments/8mxgv2/deep_learning_memory_error_with_arrays_and_lists/,Moni93,1527582247,"Before reading

I couldn't fit the text to the adequate format: so here is the original thread I posted on stack and i t is more readible than this one : https://stackoverflow.com/questions/50570305/deep-learning-memory-error-with-arrays-and-lists-in-python  


Goal

I am trying to build a neural network that recognizes multiple label within a given image. I started with a database composed of 1800 images (each image is an array of shape (204,204,3). I trained my model and concluded that data used wasn't enough in order to build a good model ( with respect to chosen metric). So i decided to apply data augmentation technique in order to get more images. I managed to get 25396 images ( all of them are of shape (204,204,3)). I stored all of them in arrays . I obtained (X,Y) where X are the training examples (is an array of shape (25396,204,204,3)) and Y are the labels ( an array of shape (25396,39) : the number 39 refers to the possible labels in a given image).
Issues
My data (X,Y) weights approximately arround 26 giga bytes. I successfully managed to use them . However, when i try to do manipulation (like permutations) I encounter memory Error in python. Exemple
1. I started jupyter and successfully imported my data (X,Y)  

```
x=np.load('x.npy')
y=np.load('y.npy')
```

```
output: x is an np.array of shape (25396,204,204,3) and y is an np.array of shape (25396,39).
```
2. I divide my dataSet in train and test by using sklearn built in function train_test_split

```
X_train, X_valid, Y_train, Y_valid= `train_test_split(x_train,y_train_augmented,test_size=0.3, random_state=42)`
```
```
output
```
-------------testing size of different elements et toplogie: 
```
```
-------------x size:  (25396, 204, 204, 3)
```
```
-------------y size:  (25396, 39)
```
```
-------------X_train size:  (17777, 204, 204, 3)
```
```
-------------X_valid size:  (7619, 204, 204, 3)
```
```
-------------Y_train size:  (17777, 39)
```
```
-------------Y_valid size:  (7619, 39)
```
3. I am creating a list composed of random batches extracted from (X,Y) and then iterate over the batches in order to complete the learning process for a given epoch :'this opperation is done in each epoch of the training part. Here is the function used in order to create the list of random batches:

def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):
    """"""
    Creates a list of random minibatches from (X, Y)

    Arguments:
    X -- input data, of shape (input size, number of examples)
    Y -- true ""label"" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)
    mini_batch_size -- size of the mini-batches, integer

    Returns:
    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)
    """"""


    np.random.seed(seed)            
    m = X.shape[0]                  
    mini_batches = []
    # Step 1: Shuffle (X, Y)
    permutation = list(np.random.permutation(m))



    shuffled_X = X[permutation,:]
    shuffled_Y = Y[permutation,:]


    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.
    num_complete_minibatches = floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning
    for k in range(0, num_complete_minibatches):


        mini_batch_X = shuffled_X[k * mini_batch_size : (k + 1) * mini_batch_size, :]
        mini_batch_Y = shuffled_Y[k * mini_batch_size : (k + 1) * mini_batch_size, :]
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)
        '''
        mini_batches.append((X[permutation,:][k * mini_batch_size : (k + 1) * mini_batch_size, :], Y[permutation,:][k * mini_batch_size : (k + 1) * mini_batch_size, :]))
        '''
    # Handling the end case (last mini-batch &lt; mini_batch_size)
    if m % mini_batch_size != 0:
        ### START CODE HERE ### (approx. 2 lines)
        mini_batch_X = shuffled_X[ num_complete_minibatches * mini_batch_size:, :]
        mini_batch_Y = shuffled_Y[ num_complete_minibatches * mini_batch_size:, :]
        ### END CODE HERE ###
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)
        '''
        mini_batches.append((X[permutation,:][ num_complete_minibatches * mini_batch_size:, :], Y[permutation,:][ num_complete_minibatches * mini_batch_size:, :]))
        '''
    shuffled_X=None
    shuffled_Y=None
    return mini_batches
4. I am creating a loop (of 4 iterations) and i am testing the random_mini_batch function in each iteration. At the end of each iteration I am assigning None values to the list of mini_batches in order to liberate memory and redo the random_mini_batch_function in the next iteration .So these line of codes works fine and I ve got no memory issues:
minibatch_size=32
seed=2
for i in range(4):
    seed=seed+1
    minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)

    minibatches=None 
    minibatches_valid=create_mini_batches(X_valid, Y_valid, minibatch_size)
    print(i)
minibatches_valid=None
5. If I add iteration over the different batches! then I am getting a memory issue. In other words, if a run this code i get an error:
minibatch_size=32
seed=2
for i in range(4):
    seed=seed+1
    minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)
    #added code: iteration over mini_batches
    for minibatch in minibatches:
                print('batch training number ')
    #end of added code        
    minibatches=None 
    minibatches_valid=create_mini_batches(X_valid, Y_valid, minibatch_size)
    print(i)
    minibatches_valid=None
MemoryError                               Traceback (most recent call last)
&lt;ipython-input-13-9c1942cdf0bc&gt; in &lt;module&gt;()
      3 for i in range(4):
      4     seed=seed+1
----&gt; 5     minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)
      6     
      7     for minibatch in minibatches:

&lt;ipython-input-3-2056fee14def&gt; in random_mini_batches(X, Y, mini_batch_size, seed)

     23 
---&gt; 24     shuffled_X = X[permutation,:]
     25     shuffled_Y = Y[permutation,:]
     26 

MemoryError: 
Does any one knows what's the issue with np.arrays ? And why does the simple fact of adding an loop (iterating over the list of batches) result in a memory error.",4,5
154,2018-5-29,2018,5,29,18,8mxuz3,Suggestions on the relevant tutorial in pytorch,https://www.reddit.com/r/deeplearning/comments/8mxuz3/suggestions_on_the_relevant_tutorial_in_pytorch/,[deleted],1527587512,[deleted],0,1
155,2018-5-29,2018,5,29,18,8mxvnv,Advanced scheduling of experiments and jobs on Polyaxon,https://www.reddit.com/r/deeplearning/comments/8mxvnv/advanced_scheduling_of_experiments_and_jobs_on/,molode,1527587763,,0,3
156,2018-5-29,2018,5,29,19,8mxysa,Suggestions for good implementation oriented tutorials of seq2seq models pytorch,https://www.reddit.com/r/deeplearning/comments/8mxysa/suggestions_for_good_implementation_oriented/,[deleted],1527588785,[deleted],0,1
157,2018-5-29,2018,5,29,19,8my1d4,Suggestions for implementation oriented tutorials of seq2seq models preferably in pytorch,https://www.reddit.com/r/deeplearning/comments/8my1d4/suggestions_for_implementation_oriented_tutorials/,TrustAnonymity,1527589636,Any suggestions would be helpful. Thanks. ,0,2
158,2018-5-29,2018,5,29,19,8my5my,Does memory frequency matter in computation?,https://www.reddit.com/r/deeplearning/comments/8my5my/does_memory_frequency_matter_in_computation/,OhmSnail,1527591057,"I would like to start with 2x8 GB RAM, and there are two plans, **2400MHz DDR4 for about 155 USD**, and **3600MHz DDR4 for about 200 USD\(with Samsung B die\)**. Is the additional 50 buck worth it?

My CPU is 7820x, so with a **x299** motherboard, I guess I could **OC the ram to 4000MHz**?

And I am doing **reinforcement learning**. Using methods like MCTS\(Monte Carlo Tree Search, It doesn't matter\). So I think there would be a lot of work to do for CPU, so the RAM frequency should play a role?",0,5
159,2018-5-29,2018,5,29,23,8mzf9h,Jeeliz FaceFilter API: the javaScript library detects and tracks the face from the videofeed (available on gitHub)...,https://www.reddit.com/r/deeplearning/comments/8mzf9h/jeeliz_facefilter_api_the_javascript_library/,StartupJeeliz,1527603355,,0,1
160,2018-5-29,2018,5,29,23,8mzfih,Jeeliz FaceFilter API: the javaScript library detects and tracks the face from the videofeed (available on gitHub)...,https://www.reddit.com/r/deeplearning/comments/8mzfih/jeeliz_facefilter_api_the_javascript_library/,StartupJeeliz,1527603409,,1,17
161,2018-5-29,2018,5,29,23,8mzj2t,Best way to learn model sequence models ?,https://www.reddit.com/r/deeplearning/comments/8mzj2t/best_way_to_learn_model_sequence_models/,TrustAnonymity,1527604231,,0,1
162,2018-5-30,2018,5,30,14,8n5x7c,Batch Normalization smooths parameter landscape,https://www.reddit.com/r/deeplearning/comments/8n5x7c/batch_normalization_smooths_parameter_landscape/,pete0273,1527656497,,0,7
163,2018-5-30,2018,5,30,16,8n6l3a,What are the good courses on Natural Language Understanding?,https://www.reddit.com/r/deeplearning/comments/8n6l3a/what_are_the_good_courses_on_natural_language/,kpshah,1527664363,Are there any courses available online for learning Natural Language Understanding(NLU)? I found a good course from Stanford but could not find lecture videos.(http://web.stanford.edu/class/cs224u/index.html) ,0,7
164,2018-5-30,2018,5,30,18,8n79as,classification network predicts same class for the entire batch,https://www.reddit.com/r/deeplearning/comments/8n79as/classification_network_predicts_same_class_for/,lazygoldenpanda,1527673313,"Hi.

I have a simple classification network \(9 conv layers with relu activation, followed by 3 fully connected\). If I use batch norm after each conv layer everything is great, the classification accuracy is 93&amp;#37; after a few epochs.  
If I don't use batch norm the classification accuracy is 0&amp;#37; even after many epochs, and the prediction for each element batch element is constant. For example, in the first iteration it predicts class 6 for all the inputs and after several iterations it predicts class 20 for all the inputs. I've normalized and scaled my data, tried to use a different weight initialization, nothing works. The problem gets solved when I use batch norm but I'm afraid there's some code bug that I'm not aware of. 

This is my network:

    class myClasifier_1_6(nn.Module):
    
        def __init__(self, nClasses):
            super(myClasifier_1_6, self).__init__()
            # conv2d(in_channels, outChannels, kernel_size
            self.conv1 = nn.Conv2d(1, 32, 2)
            self.conv2 = nn.Conv2d(32, 32, (2, 1))
            self.conv3 = nn.Conv2d(32, 32, (1, 2))
            self.pool = nn.MaxPool2d(2, 2)
    
            self.conv4 = nn.Conv2d(32, 48, 2)
            self.conv5 = nn.Conv2d(48, 48, 2)
            self.conv6 = nn.Conv2d(48, 48, 2)
    
            self.conv7 = nn.Conv2d(48, 80, 2)
            self.conv8 = nn.Conv2d(80, 80, 2)
            self.conv9 = nn.Conv2d(80, 80, 2)
    
            self.fc1 = nn.Linear(80 * 5 * 5, 800)
            self.fc2 = nn.Linear(800, 500)
            self.fc3 = nn.Linear(500, nClasses)
    
            for m in self.modules():
                if isinstance(m, nn.Conv2d):
                    m.weight.data.normal_(0.0, 0.02)
                elif isinstance(m, nn.BatchNorm2d):
                    nn.init.constant_(m.weight, 1)
                    nn.init.constant_(m.bias, 0)
    
        def forward(self, x):
            x = F.relu(self.conv1(x))
            x = F.relu(self.conv2(x))
            x = self.pool(F.relu(self.conv3(x)))
    
            x = F.relu(self.conv4(x))
            x = F.relu(self.conv5(x))
            x = self.pool(F.relu(self.conv6(x)))
    
            x = F.relu(self.conv7(x))
            x = F.relu(self.conv8(x))
            x = self.pool(F.relu(self.conv9(x)))
    
            x = x.view(-1, 80 * 5 * 5)
    
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
    
            return x

and here is my training code:

    train_ds = dataLoaderLetters.LettersDataset(csvFilePathTrain, rootDirTrain, classesDir, True)
    
    trainLoader = torch.utils.data.DataLoader(train_ds, batch_size=opt.batchSize,
                                               num_workers=int(opt.workers), 
                                               drop_last = True, shuffle=True)
    
    
    myClassifier = myClasifier_1_6(opt.nClasses)
    if opt.cuda:
         myClassifier.cuda()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(myClassifier.parameters(), lr=opt.lr, momentum=0.9)
    
    for epoch in range(opt.nEpochs):  # loop over the dataset multiple times
        myClassifier.train()
    
        running_loss = 0.0
        correctTrain = 0
        totalTrain = 0
        for i, data in enumerate(trainLoader, 0):
            # get the inputs
            inputs, labels = data
    
            # wrap them in Variable
            if opt.cuda:
                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())
            else:
                inputs, labels = Variable(inputs), Variable(labels)
    
            # zero the parameter gradients
            optimizer.zero_grad()
            outputs = myClassifier(inputs)
    
            _, predictedTrain = torch.max(outputs.data, 1)
            totalTrain += labels.size(0)
            correctTrain += (predictedTrain == labels.data).cpu().sum()
    
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
    ",0,1
165,2018-5-30,2018,5,30,20,8n7tpc,Top 10 Datasets for Deep Learning,https://www.reddit.com/r/deeplearning/comments/8n7tpc/top_10_datasets_for_deep_learning/,rennytech,1527679910,,5,24
166,2018-5-31,2018,5,31,3,8nb30f,"Aspiring Deep Learning Researcher/Engineer Here, Grad School Advice?",https://www.reddit.com/r/deeplearning/comments/8nb30f/aspiring_deep_learning_researcherengineer_here/,jonboighini,1527705811,"Im in my junior year of my undergrad in mathematical science. I recently took numerical linear algebra. We talked a lot about machine learning/deep learning and it has sparked my interest.

Ive been looking at graduate schools for machine learning. A lot of them are far away from where I currently reside. There is a few schools around me (Georgia tech, UNC) that have caught my attention, but I'm just exploring my options.

So in order to become a DL researcher/engineer, would I have to attend one of these colleges that offer ML as a graduate program? Or if I got my masters or phD in computer science would that be sufficient? Any guidance would be greatly appreciated! ",3,1
167,2018-5-31,2018,5,31,5,8nbqqf,Is it possible to explain Stochastic gradient descent in layman's term?,https://www.reddit.com/r/deeplearning/comments/8nbqqf/is_it_possible_to_explain_stochastic_gradient/,bharadwajp,1527710634,Is it possible to explain Stochastic gradient descent in layman's term?,7,1
168,2018-5-31,2018,5,31,5,8nc0hr,Heat Map of Crowd,https://www.reddit.com/r/deeplearning/comments/8nc0hr/heat_map_of_crowd/,ragas_,1527712628,"Hi,

I want to generate heat map based on number of individuals in a space.

Can anyone please suggest how to do it?

Thanks! ",5,2
169,2018-5-31,2018,5,31,14,8nfvxs,Will GTX1080 and GTX1070TI make a huge difference while training?,https://www.reddit.com/r/deeplearning/comments/8nfvxs/will_gtx1080_and_gtx1070ti_make_a_huge_difference/,OhmSnail,1527745172,"1080 will cost **additional 100 bucks** over 1070TI, it seems like their performance is very close, but what **the real difference in practice** they could make?

Is the 100 bucks worth the improvement?",14,6
170,2018-5-31,2018,5,31,17,8ngra1,DepthWise Weparable Convolutions,https://www.reddit.com/r/deeplearning/comments/8ngra1/depthwise_weparable_convolutions/,bluesky314,1527755244,How come we dont loose much accuracy in case of Depth wise separable convolution even when the number of learnable parameters reduces significantly? Im specifically talking about the MobileNet paper where there is a drastic reduction in parameter numbers. What is the intuition behind dept wise separation capturing important patters from the image?,0,1
171,2018-5-31,2018,5,31,17,8ngudl,Alexnet Finetune,https://www.reddit.com/r/deeplearning/comments/8ngudl/alexnet_finetune/,FrStealer,1527756428,"Hello,

I want to finetune AlexNet model using tf.layers. I have created the model \(below first layer\): 

    with tf.variable_scope(""conv1"",reuse=reuse) as scope:
                conv1 = tf.layers.conv2d(inputs=self.X, filters=96, kernel_size=[11, 11], strides=4, padding=""valid"", activation=tf.nn.relu)
                lrn1 = tf.nn.lrn(input=conv1, depth_radius=5, bias=1.0, alpha=0.0001/5.0, beta=0.75); 
                pool1_conv1 = tf.layers.max_pooling2d(inputs=lrn1, pool_size=[3, 3], strides=2)
                
     

However, when i try to load the finetuned weigth, the name of the weigth and the bias doesn't match. ""ValueError: Variable conv1/weights does not exist, or was not created with tf.get\_variable\(\). Did you mean to set reuse=tf.AUTO\_REUSE in VarScope?""

Is it possible to name the weight and the bias in tf.layers.conv2d ?

Thank you in advance",0,1
172,2018-5-31,2018,5,31,20,8nhmki,3 ways how Deep Learning is personalizing the Internet and inducing better engagement,https://www.reddit.com/r/deeplearning/comments/8nhmki/3_ways_how_deep_learning_is_personalizing_the/,alzador123,1527765859,,0,0
173,2018-5-31,2018,5,31,21,8nhwea,An Introduction to Deep Learning for Tabular Data,https://www.reddit.com/r/deeplearning/comments/8nhwea/an_introduction_to_deep_learning_for_tabular_data/,dearpetra,1527768630,,3,11
0,2018-6-1,2018,6,1,19,8nqq8v,Using ML to detect digits in American Sign Language: Featured Dataset + Live Webcam Detection + Documentation + Argparse functionality,https://www.reddit.com/r/deeplearning/comments/8nqq8v/using_ml_to_detect_digits_in_american_sign/,callMeSpacetime,1527847425,,1,5
1,2018-6-2,2018,6,2,14,8nyic5,Convolutional Neural Networks from scratch using tensorflow to classify Images.,https://www.reddit.com/r/deeplearning/comments/8nyic5/convolutional_neural_networks_from_scratch_using/,Perseus784,1527917189,,9,18
2,2018-6-2,2018,6,2,18,8nzdtm,"Neuromation, A Platform For Deep Learning Applications",https://www.reddit.com/r/deeplearning/comments/8nzdtm/neuromation_a_platform_for_deep_learning/,jessicafclancy,1527930224,"[**Neuromation platform**](https://neuromation.io/en/)  is used in different transaction\-related and distributed computing  tasks. The system also delivers rewards for all kinds of miners which  helps in providing the capacity of the computing. In recent studies, it  has been noted that the neurotoken platform has seen a considerable hike  in the system and in the coming time there is a great future of it.",0,0
3,2018-6-2,2018,6,2,19,8nzm2n,Deep learning hyperparameter search Project.,https://www.reddit.com/r/deeplearning/comments/8nzm2n/deep_learning_hyperparameter_search_project/,liftoff01,1527933791,"I was wondering if anyone knows of a project like Dawn Bench [https://dawn.cs.stanford.edu/benchmark/] but aimed at hyper-parameter optimisation of deep learning models?

I have been reviewing a bunch of papers on the topic and it seems a lot of their proposals could be built into a single pipeline that will speed up hyperparameter search. New papers only compare their proposal to a handful of techniques. And having all these results in one place will benefit the community a lot.

Please let me know if you know of a project or github page currently doing this.",6,7
4,2018-6-3,2018,6,3,2,8o23x9,AI Weekly 2 June 2018,https://www.reddit.com/r/deeplearning/comments/8o23x9/ai_weekly_2_june_2018/,TomekB,1527960436,,0,1
5,2018-6-3,2018,6,3,12,8o5rac,Recommend papers for image captioning.,https://www.reddit.com/r/deeplearning/comments/8o5rac/recommend_papers_for_image_captioning/,amit2rockon,1527994902,"Dear fellows, I need some research papers on Image captioning , would you recommend any?",2,3
6,2018-6-3,2018,6,3,16,8o6y39,Deep learning/machine learning applications to climate risk,https://www.reddit.com/r/deeplearning/comments/8o6y39/deep_learningmachine_learning_applications_to/,IcyCelebration,1528009447,"Hi all!

I am a graduate student in atmospheric and oceanic sciences researching climate variability and change. Due to personal reasons, I am planning to transition into the industry. I am specifically looking for deep learning/machine learning roles with applications to climate change/climate risk/renewable energy. Is anyone familiar with companies that offer such roles? [other than climate corporation] I have been searching online and networking offline for the last couple of weeks with no luck. Any help is greatly appreciated!",1,6
7,2018-6-3,2018,6,3,19,8o7mzl,Hyper Parameter Optimization Using Deeplearning4j,https://www.reddit.com/r/deeplearning/comments/8o7mzl/hyper_parameter_optimization_using_deeplearning4j/,EndyJBC,1528020479,,1,1
8,2018-6-4,2018,6,4,0,8o9ajx,Implementing YOLO v3 in Tensorflow (TF-Slim),https://www.reddit.com/r/deeplearning/comments/8o9ajx/implementing_yolo_v3_in_tensorflow_tfslim/,mystic12321,1528040321,,2,22
9,2018-6-4,2018,6,4,1,8o9hs1,Anyone using vectordash for cheap GPU?,https://www.reddit.com/r/deeplearning/comments/8o9hs1/anyone_using_vectordash_for_cheap_gpu/,potatomind,1528041904,"A couple of weeks ago I found a new service for GPU rent with 0.5$/hr for 1080 ti - vectordash.com . They made it by allowing bitcoin etc miners lend theirs GPU servers to deep learning researchers. For almost a week I can't rent a GPU instance - my dashboard always shows the message that there are no GPU available. Does anyone use the service for computations? Are they even alive, or is it just a grand scam scheme to lure miners' addresses, configurations and AI researchers' emails? I wasn't able to rent GPU at all. ",11,4
10,2018-6-4,2018,6,4,2,8oa04k,What should the shapes from the generator and discriminator be like for a GAN ?,https://www.reddit.com/r/deeplearning/comments/8oa04k/what_should_the_shapes_from_the_generator_and/,mohanradhakrishnan,1528045923,"I have been training a GAN for some time now. Initially I started with a printed document with sentences and I was told that that distribution is too hard for a GAN. Now I use a flower dataset. Have 700 images.

After burning a few dollars on a AWS machine I started using my Google compute credit. 

The code is here [https://github.com/mohanr/Machine\-Learning/blob/master/Generative&amp;#37;20Adversarial&amp;#37;20Networks/gan.py](https://github.com/mohanr/Machine-Learning/blob/master/Generative%20Adversarial%20Networks/gan.py)

I runs but seems to take about 10\-15 minutes for one iteration with one GPU. I am unsure about a few things. Tensorboard shows the next image roughly after 10 minutes. So this may take several hours. Right ?

1. The shape coming out of the generator and discriminator are arbitrary in my code. Should it be the same size as my original images which is \[256,256,3\]
2. How many images or iterations do I need ?

After about 100 iterations doesn't seem to be doing anything. Obviously there is something wrong. I think.",1,2
11,2018-6-4,2018,6,4,2,8oa4at,Stop button problem and cheat provention.,https://www.reddit.com/r/deeplearning/comments/8oa4at/stop_button_problem_and_cheat_provention/,mount_sumInt,1528046874,"**WARNING: The following is simply my opinion, obviously. It might not be right or I might have fluffed up the explanation or left something important out. Please don't assume I believe my opinions are gospel because I don't. Thank you. :\)**

I was watching [this video](https://www.youtube.com/watch?v=3TYT1QfdfsM) about a stop button for AI. The approaches mentioned seem to be going about the problem the long way. If you don't want an AI to avoid being stopped or getting itself stopped, you could just create a classifier that learns to recognise when the AI is cheating at its job of allowing the button to be pressed and not getting it pressed on purpose and gives the AI the worst cost it can get if the classifier suspects it is cheating. Instead of going for indifference whether the button is pressed, you could simply go for trapping the network into being unable to cheat without being caught, meaning that the network won't cheat. As long as the classifier that you trained to classify how certain it is that the network is cheating is better at classifying when it is cheating than the AI is at getting away with cheating, then the AI will be too ""afraid"" to cheat in case it gets caught. Cheating includes glitching and hacking, meaning that the AI won't glitch or hack its own system or the classifier.

Cheat prevention, of course, is not limited to the stop button problem. It can also be used to make sure that an AI doesn't cheat at anything else by trying to fool the classifier. Thank you for reading. :\)",0,1
12,2018-6-4,2018,6,4,3,8oaf3x,What is the name for this concept?,https://www.reddit.com/r/deeplearning/comments/8oaf3x/what_is_the_name_for_this_concept/,mount_sumInt,1528049362,"Humans can test how well someone does something. A novice chess player, for example, can tell that a grandmaster is better at chess than they are because the grand master has already taken their queen, rook and bishop in 12 moves while retaining all of their pieces. No one needed to program that kind of test into them; the novice learned it from experience. If you created a classifier, for example, that learns from examples and says how obedient a neural network is and that neural network tries to get the best possible score from the classifier, the neural network might learn to be more obedient than any human could, even though obedience is an abstract concept that no one can program as a utility function. What do you call this hybrid of neural networks where a classifier network incentivises a reinforment network? \(It might have something to do with q learning\) Thank you. :\)",0,1
13,2018-6-4,2018,6,4,7,8occpi,[Youtube] AI creates Image Classifiersby DRAWING!,https://www.reddit.com/r/deeplearning/comments/8occpi/youtube_ai_creates_image_classifiersby_drawing/,ajhalthor,1528065671,,1,9
14,2018-6-4,2018,6,4,12,8oe8ho,convnets for handwritten math,https://www.reddit.com/r/deeplearning/comments/8oe8ho/convnets_for_handwritten_math/,phosphorvk,1528083156,"With all the advances in convnets, I'd assume it's possible to create a system where you can write math by hand and convert it into some computational form, like a Mathematica, Matlab or LaTeX expression. This is something I'm interested in as a user. Is anybody aware of any software or research projects working on handwritten math recognition?",2,8
15,2018-6-4,2018,6,4,16,8ofgzf,Rubbish Amazon web services!,https://www.reddit.com/r/deeplearning/comments/8ofgzf/rubbish_amazon_web_services/,hainingbaby,1528097709,"I just registed an Amazon web services account. update my credit card information three times , then AWS deducted me three dollars for certificationAnd i still can't use my card!",0,0
16,2018-6-4,2018,6,4,20,8ogjob,is Stochastic gradient descent same as cyclic learning rate?,https://www.reddit.com/r/deeplearning/comments/8ogjob/is_stochastic_gradient_descent_same_as_cyclic/,vamos47,1528111996,"I am going through Stochastic gradient descent with restarts &lt;p&gt;&lt;a href=""https://arxiv.org/pdf/1608.03983.pdf""&gt;This Paper&lt;/a&gt;&lt;/p&gt; and cyclical Learning rate &lt;p&gt;&lt;a href=""https://arxiv.org/pdf/1506.01186.pdf""&gt;This Paper&lt;/a&gt;&lt;/p&gt;. And I feel cyclical learning rate is essentially restarting at the end of each cycle, hence both are experimenting on same thing. But I feel I am missing some subtle difference between these two as both papers seem to be very popular (especially after fast.ai v2). Anyone can explain the difference",0,2
17,2018-6-4,2018,6,4,21,8ogqge,Improving the Performance of a Neural Network,https://www.reddit.com/r/deeplearning/comments/8ogqge/improving_the_performance_of_a_neural_network/,friscotime,1528113986,,0,2
18,2018-6-4,2018,6,4,21,8ogqud,"Deep Learning Market, by Manufacturers, Regions, Type and Application, Forecast to 2025",https://www.reddit.com/r/deeplearning/comments/8ogqud/deep_learning_market_by_manufacturers_regions/,alanmarsh1307,1528114097,,0,1
19,2018-6-4,2018,6,4,21,8oguvl,Using Deep Q-Learning in FIFA 18 to perfect the art of free-kicks,https://www.reddit.com/r/deeplearning/comments/8oguvl/using_deep_qlearning_in_fifa_18_to_perfect_the/,chris_shpak,1528115189,,0,2
20,2018-6-4,2018,6,4,23,8ohj02,How to Use FPGAs for Deep Learning Inference to Perform Land Cover Mapping on Terabytes of Aerial Images,https://www.reddit.com/r/deeplearning/comments/8ohj02/how_to_use_fpgas_for_deep_learning_inference_to/,magneticono,1528121256,,0,5
21,2018-6-4,2018,6,4,23,8ohkzj,How to solve 90% of NLP problems: a step-by-step guide,https://www.reddit.com/r/deeplearning/comments/8ohkzj/how_to_solve_90_of_nlp_problems_a_stepbystep_guide/,polllyyy,1528121687,,1,27
22,2018-6-4,2018,6,4,23,8ohneg,Which method should I use to classify 3 classes in DeepFashion dataset?,https://www.reddit.com/r/deeplearning/comments/8ohneg/which_method_should_i_use_to_classify_3_classes/,iwannahug,1528122240,"I need to train a deep neural net using [this dataset](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/AttributePrediction.html) but I don't know where to start. Should I train a neural network from scratch or should I retrain a neural network using transfer learning? And if you have any article or tutorial related to this can you share them in the comments.

Thanks in advance!",3,1
23,2018-6-5,2018,6,5,8,8om5za,Apple dropping support for OpenCL,https://www.reddit.com/r/deeplearning/comments/8om5za/apple_dropping_support_for_opencl/,Karyo_Ten,1528156217,,0,3
24,2018-6-5,2018,6,5,10,8omwzl,Help out a high school student,https://www.reddit.com/r/deeplearning/comments/8omwzl/help_out_a_high_school_student/,UglyMasterpiece,1528162816,"Hi!

Im a current sophomore enrolled into a scientific research course for school. It basically gives high school students a way to pursue something they are interested in and conduct a project on it.

Ive decided to look into deep learning because it genuinely interested me. However, Ive hit a roadblock. I simply dont know where to start. Ive looked into deep learning and disease diagnosis/detection but thats really about it. 

The thing is we are required to have a unique research idea. I cant figure one out because I just dont know what aspect of deep learning that I could research that could make me unique.

The main point here is Im having trouble finding something in deep learning to REALLY look into, preferably in the medical field. Im really just asking if anybody has any insight on this. 

I remember reading something about how methods cant explain how they got to a certain answer/output. I was thinking about pursuing this but if a bunch of professionals cant manage to explain it, I assume I wont be able to either. I should also probably mention that I wont be doing this entire thing by myself since students are also required to have a mentor. ",2,1
25,2018-6-5,2018,6,5,17,8op5no,The dataset for facial expression,https://www.reddit.com/r/deeplearning/comments/8op5no/the_dataset_for_facial_expression/,amit2rockon,1528187205,"I need facial expression dataset. I have fer2013 but it has low quantity and even unevenly distributed data are present. 
",2,2
26,2018-6-5,2018,6,5,19,8opovv,Deep learning with TENSORFLOW: Issues with saving and loading models,https://www.reddit.com/r/deeplearning/comments/8opovv/deep_learning_with_tensorflow_issues_with_saving/,Moni93,1528194183,"I tried to post my issue in adequate format here in reddit. But I couldn't find how to do it, so i posted the link for my issue in stackoverflow. Here is the link :  
https://stackoverflow.com/questions/50697550/deep-learning-with-tensorflow-issues-with-saving-and-loading-models",1,3
27,2018-6-5,2018,6,5,19,8opq61,Neural Network Tutorial - Simplified for you,https://www.reddit.com/r/deeplearning/comments/8opq61/neural_network_tutorial_simplified_for_you/,pooja307,1528194614,,0,1
28,2018-6-5,2018,6,5,21,8oqddo,Link to Computer Vision News of June,https://www.reddit.com/r/deeplearning/comments/8oqddo/link_to_computer_vision_news_of_june/,Gletta,1528201481,"Here is the June 2018 issue of **Computer Vision News**, the magazine of the algorithm community published by RSIP Vision: 46 pages worth reading about Computer Vision, Image Processing, **Deep Learning** and Artificial Intelligence. Technical reviews of new papers and technologies \(with codes!\), including a **new project** with Tufts Medical Center**! Free subscripti**on at page 46.

[HTML5 version](https://www.rsipvision.com/ComputerVisionNews-2018June/) \(recommended\)   

[PDF version](http://www.rsipvision.com/computer-vision-news-2018-june-pdf/)

Enjoy!",0,9
29,2018-6-6,2018,6,6,4,8otxyc,Usage of element_size in RNN,https://www.reddit.com/r/deeplearning/comments/8otxyc/usage_of_element_size_in_rnn/,ragas_,1528228389,,0,1
30,2018-6-6,2018,6,6,10,8owmqz,Installing Keras on a GPU,https://www.reddit.com/r/deeplearning/comments/8owmqz/installing_keras_on_a_gpu/,arjundupa,1528249259,"I have access to a GPU from my university, however I do understand how exactly it works.

I have a list of commands I use to ssh into it, and in the process, terminal launches a server(?) on my browser (with localhost, if that helps), and I get a list of the jupyter notebooks I've been working on. I can click on anyone of them or create a new one and go from there.

The admin has installed Tensorflow, but not Keras. I'd like to work with Keras. I emailed him and he asked me to try installing it in my ""user space."" I told him that I had Keras installed locally on my laptop, and he responded with ""try installing Keras on the server in your home directory."" 

I have no idea what this means or how to do this. Any help will be greatly appreciated, thanks in advance.",1,1
31,2018-6-6,2018,6,6,13,8oxqmz,Fast.ai: Up to speed with the best of Deep Learning,https://www.reddit.com/r/deeplearning/comments/8oxqmz/fastai_up_to_speed_with_the_best_of_deep_learning/,janvandepoel,1528259436,,8,16
32,2018-6-6,2018,6,6,16,8oyncq,What to do after completing Deep Learning Specialisation?,https://www.reddit.com/r/deeplearning/comments/8oyncq/what_to_do_after_completing_deep_learning/,atulsachdeva,1528269564,"I have completed Prof Andrew Ng's course and I feel like the course does not implement Deep Learning in Unsupervised problems. Also, there is always more knowledge to be gained(GANs, etc). So, what should be my next step? Thanks in advance",1,7
33,2018-6-7,2018,6,7,8,8p5j7a,Keras LSTM Layer Dimensions,https://www.reddit.com/r/deeplearning/comments/8p5j7a/keras_lstm_layer_dimensions/,arjundupa,1528328467,"I've been going through a tutorial on LSTMs with Keras (http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction), and I do not get how the input_dim and output_dim parameters of the LSTM layers are all integers. 

You have,

    def build_model(layers):
        model = Sequential()

        model.add(LSTM(
            input_dim=layers[0],
            output_dim=layers[1],
            return_sequences=True))
        model.add(Dropout(0.2))

        model.add(LSTM(
            layers[2],
            return_sequences=False))
        model.add(Dropout(0.2))

        model.add(Dense(
            output_dim=layers[3]))
        model.add(Activation(""linear""))

        model.compile(loss=""mse"", optimizer=""rmsprop"")

        return model

And then:

        model = build_model([1, 50, 100, 1])

Why are the dimensions integers? How did they come up with [1, 50, 100, 1]?

Any help will be greatly appreciated!",10,1
34,2018-6-7,2018,6,7,9,8p5ral,Multimodel Deep Learning,https://www.reddit.com/r/deeplearning/comments/8p5ral/multimodel_deep_learning/,kk7nc,1528330425,,0,9
35,2018-6-7,2018,6,7,13,8p79au,Jordan Peterson react to war of idea's,https://www.reddit.com/r/deeplearning/comments/8p79au/jordan_peterson_react_to_war_of_ideas/,New7Era,1528344226,,1,0
36,2018-6-7,2018,6,7,18,8p8vl9,How to do reinforcement learning on a trained pytorch model?,https://www.reddit.com/r/deeplearning/comments/8p8vl9/how_to_do_reinforcement_learning_on_a_trained/,NotSoGreatLeader,1528363158,"Hi,

I have a seq2seq model saved in a .pt file and would like to continue the training but with reinforcement learning.

Any idea how I could do so? 

Thanks in advance",0,3
37,2018-6-7,2018,6,7,22,8pab1c,Jordan Peterson on proper role of a father,https://www.reddit.com/r/deeplearning/comments/8pab1c/jordan_peterson_on_proper_role_of_a_father/,New7Era,1528378165,,3,0
38,2018-6-7,2018,6,7,22,8pab60,What type of loss function for multiple softmax output (in setup of Variational Autoencoder architectures),https://www.reddit.com/r/deeplearning/comments/8pab60/what_type_of_loss_function_for_multiple_softmax/,solingermuc,1528378193,,8,5
39,2018-6-8,2018,6,8,1,8pbjo4,Reinforcement Learning from scratch,https://www.reddit.com/r/deeplearning/comments/8pbjo4/reinforcement_learning_from_scratch/,e_ameisen,1528387732,,0,8
40,2018-6-8,2018,6,8,4,8pdaif,CNN for auto-tagging of audio clips on MagnaTagATune dataset,https://www.reddit.com/r/deeplearning/comments/8pdaif/cnn_for_autotagging_of_audio_clips_on/,elemark,1528400226,,0,4
41,2018-6-8,2018,6,8,16,8pi05g,How to easily automate Drone-based monitoring using Deep Learning,https://www.reddit.com/r/deeplearning/comments/8pi05g/how_to_easily_automate_dronebased_monitoring/,dearpetra,1528443190,,0,3
42,2018-6-8,2018,6,8,21,8pjljq,Best (and Free!!) Resources to understand Nuts and Bolts of Deep learning,https://www.reddit.com/r/deeplearning/comments/8pjljq/best_and_free_resources_to_understand_nuts_and/,Fewthp,1528462024,,0,16
43,2018-6-8,2018,6,8,23,8pke7w,Jordan Peterson on character development,https://www.reddit.com/r/deeplearning/comments/8pke7w/jordan_peterson_on_character_development/,New7Era,1528468729,,0,1
44,2018-6-8,2018,6,8,23,8pkgld,How to end a presentation.,https://www.reddit.com/r/deeplearning/comments/8pkgld/how_to_end_a_presentation/,DeepInEvil,1528469208,,0,1
45,2018-6-8,2018,6,8,23,8pkjma,How to end a presentation,https://www.reddit.com/r/deeplearning/comments/8pkjma/how_to_end_a_presentation/,DeepInEvil,1528469825,"I had to present a paper today called ""KATE: K\-Competitive Autoencoder for Text"", ended the presentation slides with a meme.",0,1
46,2018-6-9,2018,6,9,0,8pkmuo,Ended a paper presentation with a meme,https://www.reddit.com/r/deeplearning/comments/8pkmuo/ended_a_paper_presentation_with_a_meme/,DeepInEvil,1528470439,,2,0
47,2018-6-9,2018,6,9,1,8plhj5,Has anyone implemented this paper ?,https://www.reddit.com/r/deeplearning/comments/8plhj5/has_anyone_implemented_this_paper/,amit2rockon,1528476532,"[https://arxiv.org/abs/1804.03619](https://arxiv.org/abs/1804.03619) 

Though Dataset is not publicly available but if anyone have tried it .",0,1
48,2018-6-9,2018,6,9,5,8pn9r8,Input Dimension in RNN,https://www.reddit.com/r/deeplearning/comments/8pn9r8/input_dimension_in_rnn/,ragas_,1528489589,"Hi,

I'm hard time finding the reason, why input structure in RNN for character and time\-series analysis is different. E.g.

for character analysis, we use input structure the following:

\`input = tf.placeholder(tf.int32, \[batch\_size, num\_steps\], name = ""input""\]\`

But for time\-series analysis, it's the following:

\`input = tf.placeholder(tf.int32, \[batch\_size,time\_steps, inputs\], name = ""input""\]\`

Assuming, \`num\_step\` and \`time\_steps\` are the same (number of period the RNN is looking back into past), why additional \`inputs\` is used in time\-series analysis of RNN?

If someone please help me answer this question, I'll be extremely grateful! I'm having extremely hard time grasping this issue.

Thanks!",2,1
49,2018-6-9,2018,6,9,9,8pp1el,"Starting with deeplearning, with AMD?",https://www.reddit.com/r/deeplearning/comments/8pp1el/starting_with_deeplearning_with_amd/,shinobicl,1528504271,"Hi

I want to start playing with deeplearning, hopefully using modern libraries frameworks, but i only have a 4GB r9 290 (watercooled) without any chance to buy a new card for the next months.

What are my options?",7,6
50,2018-6-9,2018,6,9,11,8ppp97,Any suggestions of loss functions for hierarchical data?,https://www.reddit.com/r/deeplearning/comments/8ppp97/any_suggestions_of_loss_functions_for/,zhwu,1528510881,"Currently, I am working on a image classification task with dozens of labels. However, those labels have strong hierarchical relationships, for example, Atopic dermatitis and Diaper dermatitis both belong to dermatitis. Dermatitis is also one of labels. If model sees a dermatitis but is uncertain what type of dermatitis it is, it will predict dermatitis with high confidence but have lower confidence spread out other specific dermatitis. 
I have read several papers discussing hierarchical loss, one of paper, https://arxiv.org/pdf/1709.01062.pdf, presents 'ultrametric tree' to calculate the loss. After implementing the loss function and integrating into the current classifier, the performance is down. In another paper, YOLO9000, https://arxiv.org/pdf/1612.08242.pdf, which also mentions hierarchical classification based on WordTree. Essentially it's using hierarchical softmax. Now I am trying to implement it. 
Here is my question: is there any other loss functions that is designed for hierarchical data, or any other solution to classify hierarchical data? Any suggestions or comments are welcome!
",0,3
51,2018-6-9,2018,6,9,19,8prykb,Deep Learning for Emojis with VS Code Tools for AI  Part 2,https://www.reddit.com/r/deeplearning/comments/8prykb/deep_learning_for_emojis_with_vs_code_tools_for/,digitalson,1528540375,,0,1
52,2018-6-9,2018,6,9,19,8przq6,DIY Deep Learning Projects,https://www.reddit.com/r/deeplearning/comments/8przq6/diy_deep_learning_projects/,friscotime,1528540858,,0,19
53,2018-6-9,2018,6,9,23,8pt2md,How to decide the result of deep learning,https://www.reddit.com/r/deeplearning/comments/8pt2md/how_to_decide_the_result_of_deep_learning/,jindongwang,1528553913,"Let's say there is a network, which we train on the training data. and valid on the validation set. How do I know in which epoch, the model is steady to be saved? More general, for all the accuracies in each epoch, how to decide which step is the ideal state of the model?",2,1
54,2018-6-9,2018,6,9,23,8pt9e9,Best (and Free!!) Resources to understand Nuts and Bolts of Deep learning,https://www.reddit.com/r/deeplearning/comments/8pt9e9/best_and_free_resources_to_understand_nuts_and/,yourbasicgeek,1528555747,,0,1
55,2018-6-10,2018,6,10,0,8ptd20,Product attributes from description,https://www.reddit.com/r/deeplearning/comments/8ptd20/product_attributes_from_description/,hega72,1528556687,"Hi Guys 
I have the task to extract product attributes from the products description as well as categorise the products. 
I have only been working with deep learning and image data so far - so maybe someone can point me in the right direction here.?
Or maybe something like this is already there ? Seems like a common problem
To me ?
Tia",3,3
56,2018-6-10,2018,6,10,1,8pu1dj,Jordan Peterson react on how political correctness corrupt our university,https://www.reddit.com/r/deeplearning/comments/8pu1dj/jordan_peterson_react_on_how_political/,New7Era,1528562634,,0,1
57,2018-6-10,2018,6,10,2,8pujsl,AI Weekly 9 June 2018,https://www.reddit.com/r/deeplearning/comments/8pujsl/ai_weekly_9_june_2018/,TomekB,1528566926,,0,1
58,2018-6-10,2018,6,10,14,8pyqet,Deep Learning + IPFS + Ethereum Blockchain in practice,https://www.reddit.com/r/deeplearning/comments/8pyqet/deep_learning_ipfs_ethereum_blockchain_in_practice/,coinmonks,1528607310,,3,13
59,2018-6-11,2018,6,11,15,8q7ckp,Keras Dimensions of Final Layer,https://www.reddit.com/r/deeplearning/comments/8q7ckp/keras_dimensions_of_final_layer/,arjundupa,1528698513,"As a dummy project, I tried to see if I could get an RNN to learn the sine wave. data is an array with 5000 data points from a sine wave:

    seq_len = 50
    result = []
    for index in range(len(data) - seq_len - 1):
        result.append(data[index: index + seq_len + 1])

    result = np.array(result)
    # result is a list of 4950 lists where each sublist is a list of the datapoints in that particular 51 datapoint window
    # this shape is 4950 x 51

    row = round(0.9 * result.shape[0])
    # to split the data set into train and test

    x_train = result[:int(row), :-1]
    y_train = result[:int(row), -1]
    x_test = result[int(row):, :-1]
    y_test = result[int(row):, -1]

    # x_train.shape = (4455, 50), and x_test.shape = (495, 50)
    # Adding an extra dimension as Keras LSTM layers take in a NumPy array of 3 dimensions: (4455, 50) --&gt; (4455, 50, 1)
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

    def build_model(layers):
    
        model = Sequential()
    
        model.add(LSTM(
            input_dim = layers[0],
            output_dim = layers[1],
            return_sequences = True))
        model.add(Dropout(0.2))
    
        model.add(LSTM(
            layers[2],
            return_sequences = False))
        model.add(Dropout(0.2))
    
        model.add(Dense(
            output_dim = layers[3]))
        model.add(Activation(""tanh""))
    
        model.compile(loss=""mse"", optimizer=""rmsprop"")
        
        return model

    epochs = 10
    global_start_time = time.time()

    model = build_model([1, 50, 100, 1])

    model.fit(x_train,
              y_train,
              batch_size=512,
              nb_epoch=epochs,
              validation_split=0.1)

    predicted = model.predict(x_test)

This works perfectly.

I then wanted to see if I could predict 2 data points instead of 1 per 50 datapoint input.

I changed:

    x_train = result[:int(row), :-1]
    y_train = result[:int(row), -1]
    x_test = result[int(row):, :-1]
    y_test = result[int(row):, -1]

to:

    x_train = result[:int(row), :-2]
    y_train = result[:int(row), -2]
    x_test = result[int(row):, :-2]
    y_test = result[int(row):, -2]

and:

    model = build_model([1, 50, 100, 1])

to:

    model = build_model([1, 50, 100, 2])

However, this resulted in an error saying ""Error when checking target: expected activation_7 to have shape (2,) but got array with shape (1,)"" where I say ""validation_split=0.1""

For some reason, the number in ""activation_7"" in the error message is incremented by 1 each time I enter the final snippet of code in my Jupyter notebook. I am completely stumped as to what I am doing wrong as it seems to me that I made every change necessary to predict 2 data points instead of 1. 

Any help will be greatly appreciated!


",5,1
60,2018-6-11,2018,6,11,21,8q922t,Deep Learning for Videos: A 2018 Guide to Action Recognition,https://www.reddit.com/r/deeplearning/comments/8q922t/deep_learning_for_videos_a_2018_guide_to_action/,saucysassy,1528719303,,0,17
61,2018-6-11,2018,6,11,22,8q9cwb,Is the Braess Paradox related to Dropout in Neural Nets ?,https://www.reddit.com/r/deeplearning/comments/8q9cwb/is_the_braess_paradox_related_to_dropout_in/,themoderndayhercules,1528722180,,0,4
62,2018-6-11,2018,6,11,23,8q9xfo,"Implement my own residual network using pytorch doesn't work, need help.",https://www.reddit.com/r/deeplearning/comments/8q9xfo/implement_my_own_residual_network_using_pytorch/,372995411,1528727157,"Hi, everyone, I recently implemented my own resnet using pytorch, trained on cifar100 dataset, I dont know why my resnet only have an accuracy around 1&amp;#37;.

here is my github repo,

[https://github.com/weiaicunzai/pytorch\-cifar\-100](https://github.com/weiaicunzai/pytorch-cifar-100)

my [resnet.py](https://resnet.py) file:

[https://github.com/weiaicunzai/pytorch\-cifar\-100/blob/master/models/resnet.py](https://github.com/weiaicunzai/pytorch-cifar-100/blob/master/models/resnet.py)

my [train.py](https://train.py) file:

[https://github.com/weiaicunzai/pytorch\-cifar\-100/blob/master/train.py](https://github.com/weiaicunzai/pytorch-cifar-100/blob/master/train.py)

could you please tell me where I did wrong, or how can I find the bug(some hints), that would be great, this is the second neuron network I've  implemented, the first is VGG, so Im kind newbie here. 

Thanks in advance, have a nice day.",1,2
63,2018-6-12,2018,6,12,0,8qaa7k,[Research] Participate in research survey. Chance to win $50 gift card.,https://www.reddit.com/r/deeplearning/comments/8qaa7k/research_participate_in_research_survey_chance_to/,IBM_dpiorkowski,1528729908,"Our team at IBM Research is running a research study to understand the barriers that practitioners face when using machine learning, deep learning, and AI in the context of building models and/or software. We are looking for participants willing to take a 15\-30 minute survey to better understand these barriers. One lucky participant will win a **$50 gift card** at the end of the survey period. (See full terms and conditions [here](http://ai-survey.mybluemix.net/terms.html)).

This survey is anonymous. We know your privacy is important to you, and we are committed to protecting it. Your responses to this survey will be kept private and used only for the purposes of this study, research publications, and future IBM Research AI projects. All results are anonymized and confidential and reported results will be anonymized and in aggregate.

**To participate, click** [here](http://ai-survey.mybluemix.net/index.php/673946?lang=en)**.**

Thank you for your help. We very much appreciate your time and your input.",0,0
64,2018-6-12,2018,6,12,0,8qagyh,Speech Recognition with TensorFlow,https://www.reddit.com/r/deeplearning/comments/8qagyh/speech_recognition_with_tensorflow/,tttttm,1528731326,,0,9
65,2018-6-12,2018,6,12,1,8qasvs,"Animojis in the browser, without iPhone X",https://www.reddit.com/r/deeplearning/comments/8qasvs/animojis_in_the_browser_without_iphone_x/,StartupJeeliz,1528733782,,0,1
66,2018-6-12,2018,6,12,2,8qb7nd,Can neural network be modelled to all kinds of natural images?,https://www.reddit.com/r/deeplearning/comments/8qb7nd/can_neural_network_be_modelled_to_all_kinds_of/,deepak3011,1528737907,Can neural network be modelled to all kinds of natural images such that if any image containing any sort of artifact can be classified as corrupted?,4,1
67,2018-6-12,2018,6,12,3,8qbnu5,Apple CreateML vs Kaggle Competitions,https://www.reddit.com/r/deeplearning/comments/8qbnu5/apple_createml_vs_kaggle_competitions/,TomekB,1528741260,,0,1
68,2018-6-12,2018,6,12,5,8qcjhg,Where is the __call__() in tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py,https://www.reddit.com/r/deeplearning/comments/8qcjhg/where_is_the_call_in_tensorflowcontribcudnn/,tingkai_zhang,1528747470,,0,1
69,2018-6-12,2018,6,12,8,8qdxfa,Where is the __call__() in tensorflow cudnn_rnn.py,https://www.reddit.com/r/deeplearning/comments/8qdxfa/where_is_the_call_in_tensorflow_cudnn_rnnpy/,tingkai_zhang,1528758070,"Hi, folks! I have a question when I am using tf.contrib.cudnn\_rnn.CudnnLSTM. 

In short, the question is in the given example, it creates a CudnnLSTM object, then call this object. But there is no definition of \_\_call\_\_() in  [tensorflow](https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow)/[contrib](https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib)/[cudnn\_rnn](https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/cudnn_rnn)/[python](https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/cudnn_rnn/python)/[layers](https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/cudnn_rnn/python/layers)/**cudnn\_rnn.py** 

How can it call the object and pass parameters without defining the \_\_call\_\_()?

Question description: 

[https://stackoverflow.com/questions/50805147/where\-is\-the\-call\-in\-tensorflow\-contrib\-cudnn\-rnn\-python\-layers\-cudnn\-rnn\-py](https://stackoverflow.com/questions/50805147/where-is-the-call-in-tensorflow-contrib-cudnn-rnn-python-layers-cudnn-rnn-py)

Though in  tensorflow.python.layers.base.Layer  it defines the \_\_call\_\_() but it doesn't implement the \_\_call\_\_  as  the function with corresponding signatures in that example.

Appreciate your help!",5,3
70,2018-6-12,2018,6,12,9,8qej0g,Nvdia GRID server question,https://www.reddit.com/r/deeplearning/comments/8qej0g/nvdia_grid_server_question/,Throwaway_geology,1528763361,"Hello,

I am interested in learning more about AI and I have some money to throw around to purchase a high end computer / server to train models. I do not have to time to build my own nor do I want to waste my money on AWS or Google, so I am looking into servers with Tesla GPUs. While rummaging around some sub, I stumbled across this link to nvidia grid servers: http://www.nvidia.com/object/grid-certified-servers.html

My question is: are these virtual GPU servers practical / useful for training models? Is there any particular reason / advantage why these might be better than a non virtual or why one might prefer this kind? Do you think the AI industry is moving more into this direction? I do not really understand this technology yet, and I am not sure if a non virtual server would better suit my hobbies. Please convince me why! 

Basically, I would like to purchase a server, plug it in, run code, train, test, and have it produce. That's it. 

Any extra comments or suggestions would be greatly appreciated! ",1,1
71,2018-6-12,2018,6,12,16,8qgymb,Text summarization with Tensorlflow.,https://www.reddit.com/r/deeplearning/comments/8qgymb/text_summarization_with_tensorlflow/,ganji1055,1528787465,,0,1
72,2018-6-12,2018,6,12,16,8qh1fn,Text summarization with Tensorflow.,https://www.reddit.com/r/deeplearning/comments/8qh1fn/text_summarization_with_tensorflow/,ganji1055,1528788409,,0,12
73,2018-6-12,2018,6,12,23,8qjcgf,Text Normalization using Memory Augmented Neural Networks,https://www.reddit.com/r/deeplearning/comments/8qjcgf/text_normalization_using_memory_augmented_neural/,turing_1997,1528813585,,0,6
74,2018-6-13,2018,6,13,5,8qmd56,Github Report based on types of RNN,https://www.reddit.com/r/deeplearning/comments/8qmd56/github_report_based_on_types_of_rnn/,ragas_,1528835492,"Hi,

I'm looking for references based on RNN architecture. For, articles or github repo organized by RNN architecture like many\-to\-one, many\-to\-many, one\-to\-many, etc. 

If someone can guide me to something like this it will be great!

Thanks!",9,5
75,2018-6-13,2018,6,13,22,8qslyv,"Interview: Dr. Roger Brooks, Chief Scientist at Guavus",https://www.reddit.com/r/deeplearning/comments/8qslyv/interview_dr_roger_brooks_chief_scientist_at/,molode,1528898188,,0,2
76,2018-6-13,2018,6,13,23,8qsrkp,Overview and benchmark of traditional and deep learning models in text classification,https://www.reddit.com/r/deeplearning/comments/8qsrkp/overview_and_benchmark_of_traditional_and_deep/,ahmedbesbes,1528899421,,0,9
77,2018-6-14,2018,6,14,2,8quhcs,Anybody working on or wants to work on Incremental Learning for Object Detectors?,https://www.reddit.com/r/deeplearning/comments/8quhcs/anybody_working_on_or_wants_to_work_on/,Geeks_sid,1528912400,I am planning to create an incremental learning for object detectors without catastrophic forgetting and would like to do it with someone who has worked in it.,3,4
78,2018-6-14,2018,6,14,8,8qwyi6,Fast Manual Image Classifier,https://www.reddit.com/r/deeplearning/comments/8qwyi6/fast_manual_image_classifier/,data_bandit,1528931239,"Hey all,   


I created a tool to help manually generate training data for image classification models. It basically provides a quick way to label training set images using RShiny. It's not as easy to use as I'd like yet, but I'm pretty happy with the initial version!

Github repo:

[https://github.com/jai\-bansal/fast\-manual\-image\-classifier](https://github.com/jai-bansal/fast-manual-image-classifier)",0,6
79,2018-6-14,2018,6,14,17,8r04j5,How to get h from this?,https://www.reddit.com/r/deeplearning/comments/8r04j5/how_to_get_h_from_this/,KevinNintyNine,1528963779,"*Processing img o57ngiq8cx311...*

Hi,I'm new to both machine learning &amp;&amp; linear algebra,can anyone tell me how get h from this ?",9,0
80,2018-6-14,2018,6,14,19,8r0wnk,Time Series split as input - how to evaluate model?,https://www.reddit.com/r/deeplearning/comments/8r0wnk/time_series_split_as_input_how_to_evaluate_model/,u743346,1528973714,"Hi,

I am training a LSTM model with time series data. I performed a sklearn time series split trying to improve the standard split. 
However, right now I have 3 splits but it is not clear to me how to evaluate the model since I have 3 models each with a different score.

Can someone explain to me how I can choose the best parameters based on these splits?

Thanks!",0,1
81,2018-6-14,2018,6,14,21,8r1e3r,Training a CNN with Keras(Python) and predicting with Tensorflow Go(Golang),https://www.reddit.com/r/deeplearning/comments/8r1e3r/training_a_cnn_with_keraspython_and_predicting/,sudproquo,1528978782,,0,4
82,2018-6-15,2018,6,15,0,8r2w3o,Respect my authoritaaaa!! Our talking avatars API ('webojis') is now available on gitHub. :),https://www.reddit.com/r/deeplearning/comments/8r2w3o/respect_my_authoritaaaa_our_talking_avatars_api/,StartupJeeliz,1528991275,,6,26
83,2018-6-15,2018,6,15,2,8r3hbz,(resnet) Why identity mapping is hard to train directly?,https://www.reddit.com/r/deeplearning/comments/8r3hbz/resnet_why_identity_mapping_is_hard_to_train/,372995411,1528995612,"Hi,  everyone,  in  resnet's  paper,  the  author  said identity  mapping  is  hard  to  train  directly, thats  why  it  causes the  degradation problem.  But  the  author  doesn't  explain  why.  Can  some  one please  tell  me  why  identity mapping  is  hard  to  train? Thanks.",6,1
84,2018-6-15,2018,6,15,2,8r3r3u,"17 Best Online Courses on Machine Learning, Deep Learning, AI and Big Data Analytics",https://www.reddit.com/r/deeplearning/comments/8r3r3u/17_best_online_courses_on_machine_learning_deep/,tanmoyray01,1528997525,,0,1
85,2018-6-15,2018,6,15,9,8r6sq8,Deep learning bootcamp,https://www.reddit.com/r/deeplearning/comments/8r6sq8/deep_learning_bootcamp/,johnlavolpe,1529022371,,3,1
86,2018-6-15,2018,6,15,10,8r7cs3,Hungry For Data,https://www.reddit.com/r/deeplearning/comments/8r7cs3/hungry_for_data/,pointyears00,1529027864,,2,23
87,2018-6-15,2018,6,15,16,8r9105,AI-powered drones are now being used to monitor construction in Africa,https://www.reddit.com/r/deeplearning/comments/8r9105/aipowered_drones_are_now_being_used_to_monitor/,nanonets,1529046502,,0,7
88,2018-6-15,2018,6,15,19,8ra1mr,Large data manipulation with HDF5,https://www.reddit.com/r/deeplearning/comments/8ra1mr/large_data_manipulation_with_hdf5/,nekize,1529060194,"So i have created dataset from a video where i have 6 persons doing some actions. Since the data for really big i started using hdf5 file format for storing, so during training i can read the data from disk. What my problem now is, is that the way i train my model is that i take 1 person for validation and other 5 for training, and i was preping my data in a way, that i crated a new hdf5 file for each combination (like persons 1-5, 2-6, 3-1, ...) and what i for was a lot of doubled/tripled/... data in files that are around 12gb each. 

So my question now is, if there is a way for me to save all 6 persons into hdf5 file and than call for combinations to load as 1 dataset. What i was thinking is something like I store each person as its own dataset in hdf5 and then somehow call for which persons to load (example: train data= h5File\['person1', 'person3', ...\]. This is made up and doesn t work.). Or if you got any alternatives to hdf5, that could make my life easier. 

All of my arrays for each person are the same size of (39900, 256, 256, 1). ",0,3
89,2018-6-15,2018,6,15,19,8ra23t,Googles AutoML will change how businesses use Machine Learning,https://www.reddit.com/r/deeplearning/comments/8ra23t/googles_automl_will_change_how_businesses_use/,VanillaMonster,1529060358,,0,5
90,2018-6-15,2018,6,15,23,8rbbwv,"IntuitiveAI-An Interactive Platform To Effortlessly Train Artificial Intelligence With Images, Text, Audio and Videos",https://www.reddit.com/r/deeplearning/comments/8rbbwv/intuitiveaian_interactive_platform_to/,kailashahirwar12,1529072683,,0,7
91,2018-6-15,2018,6,15,23,8rbjlz,what does fine layer and coarse layer mean in FCN?,https://www.reddit.com/r/deeplearning/comments/8rbjlz/what_does_fine_layer_and_coarse_layer_mean_in_fcn/,372995411,1529074404,"In paper &lt;Fully Convolutional Networks for Semantic Segmentation&gt;, Section 4.2:

&gt; Combining fine layers and coarse layers lets the  
&gt;  
&gt;model make local predictions that respect global structure.

what does fine layers and coarse layers mean here?? fine layers means shadow layers, and coarse layers means deep layers??",0,3
92,2018-6-16,2018,6,16,0,8rbu9z,Finding Where's Waldo using Mask R-CNN,https://www.reddit.com/r/deeplearning/comments/8rbu9z/finding_wheres_waldo_using_mask_rcnn/,alseambusher,1529076713,,3,9
93,2018-6-16,2018,6,16,1,8rc7e3,"Wolfram Research goes for Software 2.0, releases neural net repository",https://www.reddit.com/r/deeplearning/comments/8rc7e3/wolfram_research_goes_for_software_20_releases/,MountainHawk81,1529079503,,0,6
94,2018-6-16,2018,6,16,2,8rcupz,AI Weekly 15 June 2018,https://www.reddit.com/r/deeplearning/comments/8rcupz/ai_weekly_15_june_2018/,TomekB,1529084556,,0,1
95,2018-6-16,2018,6,16,4,8rdu85,AI and data science trends to watch out for at DataWorks Summit,https://www.reddit.com/r/deeplearning/comments/8rdu85/ai_and_data_science_trends_to_watch_out_for_at/,alexa_y,1529092413,,1,3
96,2018-6-16,2018,6,16,12,8rgpi1,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/deeplearning/comments/8rgpi1/are_you_interested_in_ai_and_want_to_start/,DiscoverAI,1529119332,,2,7
97,2018-6-16,2018,6,16,14,8rhajn,"Is one deep learning library more consistent across versions? TensorFlow, PyTorch, Caffe2, CNTK, others?",https://www.reddit.com/r/deeplearning/comments/8rhajn/is_one_deep_learning_library_more_consistent/,bathmlaster,1529126015,"Hi all,
I've started learning PyTorch recently and I have tried TensorFlow in the past. In both instances I've hit some cases where install instructions or code examples would only function on specific versions of the code, and this leads to many roadblocks in the learning journey. In fact I just went 10 minutes into a Microsoft CNTK demo in their online Azure Notebooks and I found code in their [getting started page](https://www.cntk.ai/pythondocs/gettingstarted.html) that doesn't run because a method seems to have been updated.

Are there specific deep learning libraries for Python that are considered more stable from version to version? Does using something like Keras help to manage this? 

Or this simply a byproduct of new code bases, since TF is 2 years old and PyTorch is 1 year old?

Thanks!",1,4
98,2018-6-16,2018,6,16,16,8rhszb,Multivariate Time Series Forecasting,https://www.reddit.com/r/deeplearning/comments/8rhszb/multivariate_time_series_forecasting/,arjundupa,1529133095," I've been trying to learn multivariate time series forecasting. As a dummy example, I decided to try to train a recurrent neural network to determine the average of the two time series' (in my case, sin(t) and cos(t) ) given to it. Here's my code:

[https://github.com/arjung128/deep-learning-experiments/blob/master/Multivariate.ipynb](https://github.com/arjung128/deep-learning-experiments/blob/master/Multivariate.ipynb)

I don't understand why the input to my first LSTM layer has to be 2D and not 3D...any ideas?

Any help will be appreciated. Thanks! ",1,3
99,2018-6-17,2018,6,17,22,8rqzrq,AI powered fashion stylist,https://www.reddit.com/r/deeplearning/comments/8rqzrq/ai_powered_fashion_stylist/,ashish_kr23,1529241844,"I worked on this project during the last year.It is an ensemble recommendation engine that suggest what clothes go well together.I trained it on 5 million fashion ensembles.
https://medium.com/@ashishkumar_96311/does-this-blazer-go-with-this-shirt-ai-stylist-54ec79a47215
Would love to hear your thoughts.",6,16
100,2018-6-18,2018,6,18,0,8rrxoc,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/8rrxoc/are_you_interested_in_ai_and_want_to_start/,DiscoverAI,1529251073,,0,2
101,2018-6-18,2018,6,18,11,8rvxfk,An easy to use program needs to be made so everyone can do this!!!,https://www.reddit.com/r/deeplearning/comments/8rvxfk/an_easy_to_use_program_needs_to_be_made_so/,TransferTrip,1529287647,,2,0
102,2018-6-18,2018,6,18,16,8rxro0,How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning,https://www.reddit.com/r/deeplearning/comments/8rxro0/how_to_create_natural_language_semantic_search/,polllyyy,1529308559,,0,2
103,2018-6-18,2018,6,18,17,8rxtvr,"Maintaining deep learning projects on Java (DL4J) here. Feel free to add your feedback, contributions or any suggestions.",https://www.reddit.com/r/deeplearning/comments/8rxtvr/maintaining_deep_learning_projects_on_java_dl4j/,EndyJBC,1529309391,,0,26
104,2018-6-18,2018,6,18,18,8ry3ak,Company Name Detection with Neural Networks,https://www.reddit.com/r/deeplearning/comments/8ry3ak/company_name_detection_with_neural_networks/,arjundupa,1529313041,"I am working on a company name detector (binary classification  given an input, determine if the input is a company name or not) for Japanese companies in specific. 

I used a Wikipedia article titled List of Companies in Japan ([https://en.wikipedia.org/wiki/List\_of\_companies\_of\_Japan](https://en.wikipedia.org/wiki/List_of_companies_of_Japan)) to create one half of my training data (the English names column)  this is currently a NumPy array of about 650 strings. I also used a random gibberish generator ([http://www.weirdhat.com/gibberish.php](http://www.weirdhat.com/gibberish.php)) to generate the second half of my training data  this is also a NumPy array of roughly 650 strings, where each string is a pair of two consecutive words from the paragraphs on the webpage. 

To be able to feed this data into a neural network, I need to:

1. convert the strings into numbers, and

2. Make all inputs of the same length

however, I do not know how to do this. 

I have looked into word2vec  I dont think I can use this as the database wont have vectors corresponding to non-dictionary terms, like names nor gibberish, right? Could I simply convert each letter to its binary/hex ASCII value and use a padding of 0s at the end to resolve both problems listed above? Would this even work?

Any help will be greatly appreciated!",2,2
105,2018-6-18,2018,6,18,19,8ryc6b,Paper discussion Deformable Convolutional Networks,https://www.reddit.com/r/deeplearning/comments/8ryc6b/paper_discussion_deformable_convolutional_networks/,bvienna12,1529316223,"The paper proposes deformable convolutions in neural networks however many questions remain:

For an input feature map of say 50x50x20 with h x w x nbr features, is the offset calculated for each feature map say for a 3 x 3 kernel, I have a kernel of size 3 x 3 x 20 with the same offset and a summed output or do I have 3 x 3 x 1 times 20 with different offset and summed output. 

Further more during inference: the offset map would cause the kernels to shift as well, meaning deformable kernels during inference too? ",0,0
106,2018-6-18,2018,6,18,21,8rz3qf,Which are the best video tutorials to understand the basics and methodologies for deep learning?,https://www.reddit.com/r/deeplearning/comments/8rz3qf/which_are_the_best_video_tutorials_to_understand/,abdush,1529324807,,4,2
107,2018-6-19,2018,6,19,1,8s12z8,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/8s12z8/are_you_interested_in_ai_and_want_to_start/,ailearn12,1529341019,,0,0
108,2018-6-19,2018,6,19,3,8s1mfm,"Implemented a FC-DenseNet (Tiramisu), would love some feedback!",https://www.reddit.com/r/deeplearning/comments/8s1mfm/implemented_a_fcdensenet_tiramisu_would_love_some/,breaking_ciphers,1529344988,"Hey Reddit,

I have been working on structuring my models and code nicely, along with working on the README for my repos because I'm a lazy bum with that stuff most of the time. I would appreciate some feedback if you guys could give me some on this Fully Convolutional DenseNet model, I'm trying to evolve how I work compared to some of my other repos:

\[Tiramisu\]([https://github.com/HasnainRaz/FC-DenseNet-TensorFlow](https://github.com/HasnainRaz/FC-DenseNet-TensorFlow))

\[The original paper\]([https://arxiv.org/abs/1611.09326](https://arxiv.org/abs/1611.09326))

I have also been wondering, is ML/DL code tested (unit tests) commonly? if so, what is the best way to go about it?  


Thanks for the feedback!",0,4
109,2018-6-19,2018,6,19,8,8s46se,RNN training performance GPU and CPU,https://www.reddit.com/r/deeplearning/comments/8s46se/rnn_training_performance_gpu_and_cpu/,TrustAnonymity,1529364986,"Training RNN on GPU slower than that on CPU. Infact, even on CPU, with increase in training epochs also the training speed is getting slower. 

Please help if any particular reasons are there that I need to look at. Thanks.",7,4
110,2018-6-19,2018,6,19,13,8s5xa9,How do we calculate the performance for each layer in object detection,https://www.reddit.com/r/deeplearning/comments/8s5xa9/how_do_we_calculate_the_performance_for_each/,ashwinraju101,1529381261,I was reading faster rcnn  tech report and they have mentioned they calculated performance layer by layer but I was not able to fully understand how they did.. Any explanation would be highly appreciated. ,0,4
111,2018-6-19,2018,6,19,14,8s6d7u,Best CPU for Deep Learning.,https://www.reddit.com/r/deeplearning/comments/8s6d7u/best_cpu_for_deep_learning/,RohitDulam,1529386136,"I want to know which is the best CPU for Deep Learning, right now I'm thinking about buying an i5-8600k, but many of the builds have AMD CPUs, so now I'm in a dilemma. I'm on a tight budget of around $1100-$1200, where almost half of that is going to the GPU, preferably a gtx 1070.",11,1
112,2018-6-19,2018,6,19,17,8s77ii,[N] Spark Summit + AI 2018 from a Data Scientist perspective,https://www.reddit.com/r/deeplearning/comments/8s77ii/n_spark_summit_ai_2018_from_a_data_scientist/,rragundez,1529396396,,0,1
113,2018-6-19,2018,6,19,20,8s86gb,Turning Fortnite into PUBG with Deep Learning (CycleGAN),https://www.reddit.com/r/deeplearning/comments/8s86gb/turning_fortnite_into_pubg_with_deep_learning/,rennytech,1529408500,,2,47
114,2018-6-20,2018,6,20,3,8sbd2i,"Deep Learning: The Good, The Bad, and the Future",https://www.reddit.com/r/deeplearning/comments/8sbd2i/deep_learning_the_good_the_bad_and_the_future/,lynchr,1529434013,,0,1
115,2018-6-20,2018,6,20,8,8sdeho,Annotation tool for image classification,https://www.reddit.com/r/deeplearning/comments/8sdeho/annotation_tool_for_image_classification/,smahajan07,1529449649,"I'm working on a custom data set and want to annotate a batch of images with 6-10 classes, so that I can crop/extract them and train my network to classify such images. I am trying to look for a tool which can save the output in csv format. Anyone has used or can suggest a tool which is easy to use.    ",1,2
116,2018-6-20,2018,6,20,16,8sgfv5,Generative Adversarial Networks (GANs),https://www.reddit.com/r/deeplearning/comments/8sgfv5/generative_adversarial_networks_gans/,arjundupa,1529480320,"I just began learning about GANs. I find the idea of two neural networks (the generator and the discriminator) training simultaneously to improve each other very intriguing, but I was wondering if training the discriminator first as much as possible before using this trained discriminator in the (loss function of the) training of the generator would work equally well. I don't see how the simultaneous training aspect is particularly important -- the only benefit of simultaneous training seems to be that training simultaneously may achieve better results more quickly (and this too I'm not too sure of since you're splitting your computational power on two networks...). I don't see how simultaneous training may lead to a more optimal solution when compared to sequential training (training one neural network before the other).

Any ideas?",2,3
117,2018-6-20,2018,6,20,17,8sgnls,Why sigmoid kills gradient?,https://www.reddit.com/r/deeplearning/comments/8sgnls/why_sigmoid_kills_gradient/,prithvi45,1529483031,Why sigmoid kills gradient during learning stage explained here,0,4
118,2018-6-20,2018,6,20,20,8shfau,AI Lab: Learn to Code with the Cutting-Edge Microsoft AI Platform,https://www.reddit.com/r/deeplearning/comments/8shfau/ai_lab_learn_to_code_with_the_cuttingedge/,magneticono,1529492802,,1,13
119,2018-6-20,2018,6,20,21,8shwqj,Deploying deep learning models: Part 1 an overview,https://www.reddit.com/r/deeplearning/comments/8shwqj/deploying_deep_learning_models_part_1_an_overview/,molode,1529497743,,0,3
120,2018-6-20,2018,6,20,23,8sijxf,The Conversational Intelligence Challenge,https://www.reddit.com/r/deeplearning/comments/8sijxf/the_conversational_intelligence_challenge/,Moscow_Phystech,1529503419,"We invite you to take part in the Convai competition, organized by Facebook AI research the Neural Networks and Deep Learning laboratory at MIPT. Even if youve never made chatbots, you can participate: Using open-source baselines is allowed, so you dont have to develop a chatbot from scratch. The only requirements are curiosity and enthusiasm.

The lab will announce the results of the competition at the NIPS-2018 conference in December. To encourage further data collection for dialogue research, the winner will receive $20,000 on Amazon Mechanical Turk, a service that brings together assessors and people offering data markup tasks.

Hurry up and register for the Convai competition: [http://convai.io/](http://convai.io/)",0,1
121,2018-6-20,2018,6,20,23,8sikhq,Facebook Open Sources DensePose!,https://www.reddit.com/r/deeplearning/comments/8sikhq/facebook_open_sources_densepose/,onmywaytostealyagirl,1529503549,"[https://research.fb.com/facebook-open-sources-densepose/](https://research.fb.com/facebook-open-sources-densepose/)

Looking forward to working with this myself for things like medical applications in joint movement. Hope it's interesting to some people!",1,1
122,2018-6-21,2018,6,21,0,8sizwu,Buying computing power on a spot market to reduce deep learning training costs,https://www.reddit.com/r/deeplearning/comments/8sizwu/buying_computing_power_on_a_spot_market_to_reduce/,sply,1529506917,,10,4
123,2018-6-21,2018,6,21,0,8sj4sw,Leaky ReLU on Tensorflow 1.1.0,https://www.reddit.com/r/deeplearning/comments/8sj4sw/leaky_relu_on_tensorflow_110/,arjundupa,1529507928,"I understand that a Leaky ReLU function has been implemented in the latest Tensorflow version, but my university's GPU has Tensorflow 1.1.0 installed and it cannot be updated in the near future. 

I have tried using Keras' Leaky ReLU function, but that happens to use Tensorflow's Leaky ReLU function and therefore I get an error.

Is there any way I could use the Leaky ReLU function? If I implement it myself, how would I use it in the following syntax for Keras:

model.add(LeakyReLU(0.2))

Any input will be appreciated, thanks!",5,0
124,2018-6-21,2018,6,21,1,8sjwjk,Program crashes at first epoch??,https://www.reddit.com/r/deeplearning/comments/8sjwjk/program_crashes_at_first_epoch/,ian_ben,1529513564,"So I'm fairly new to deep learning but I am at early stages of my project and am testing my first model with my dataset. For test I was going to feed it 200 images (512x512) with a contour mask and see the results but it seems to crash at the first epoch. Like the progress bar stays at 0% and my jupyter notebook's kernel crashes. I thought it was the notebook so I ran it as a script in a my python console but the same thing happened.
Has this ever happened to anyone and does anyone have any tips? 

My network is simply two convolution/activation and max pooling layers, followed by a dense layer.
I have tried playing with batch sizes and number of epochs but nothing seems to work; it just keeps crashing.

this is what i have: 
Layer, Input Size, Output Size
('Conv2D_2', (None, 512, 512, 1), (None, 512, 512, 64))
('Max_Pooling2D_2', (None, 512, 512, 64), (None, 256, 256, 64))
('Conv2D_3', (None, 256, 256, 64), (None, 256, 256, 128))
('Max_Pooling2D_3', (None, 256, 256, 128), (None, 128, 128, 128))
('Reshape_1', (None, 128, 128, 128), (None, 1, 2097152))
('Dense_1', (None, 1, 2097152), (None, 1, 262144))
('Reshape_2', (None, 1, 262144), (None, 512, 512, 1))

when i call model.fit i am feeding it two (200,512,512,1)  arrays (one for the images and one for the binary mask) 

Any help would be great!!! 
Thanks in advance.",2,1
125,2018-6-21,2018,6,21,6,8sm4gj,Medical Image segmentation,https://www.reddit.com/r/deeplearning/comments/8sm4gj/medical_image_segmentation/,ian_ben,1529529787,"Hi,

I am working with medical images, and I would like to build a CNN to learn contour certain parts of them (which I have contoured). My images are 512x512 and I have the contours as binary masks also of 512x512. I built a neural net with two blocks, a block consisting of a convolution/relu  and a max pooling layer. 
The thing that confuses me is that after these two blocks, I have a dense layer but I don't understand how many units this should have. I want this network to learn to get the whole binary mask which is 512x512, and i tried making the dense layer have (512x512 = )262,144 units so that i can simply reshape its outputs but that is obviously much too large computation wise. 

How should i be going about this? Any guidance would help! 
Thanks in advance",2,4
126,2018-6-21,2018,6,21,7,8smpkq,Is going down the Deep Learning path a good idea?,https://www.reddit.com/r/deeplearning/comments/8smpkq/is_going_down_the_deep_learning_path_a_good_idea/,Freebalanced,1529534438,"I've always been really fascinated by DL and the promise it has for solving real world problems.

I recently listed to a Tim Ferriss podcast where he was interviewing Steve Jurvetson.  Deep Learning came up in their talk and Steve was mentioned that the market is pretty short of DL experts and there is a fairly large arbitrage opportunity for this skill compared to other areas. Steve said that someone could become fairly knowledgeable in the field within 6-8 months and command a very healthy salary, topping that of developers and even finance grads. Is this true?

Do you think it would be possible for me (and others) to make the switch in a relatively short period of time, similar to people who learn development via online courses + bootcamps?

My background: I have a college degree in Computer Programming from the early 2000's which I never quite used, as well as an Arts degree and Project Management certifications. I wound up going into IT Project Management, and various other business related fields.

Reading the posts in here about others wanting to make the switch, I would be looking at starting off with something like this to brush up on CS and programming in general:

[https://courses.edx.org/courses/course-v1:MITx+6.00.1x+2T2017\_2/course/](https://courses.edx.org/courses/course-v1:MITx+6.00.1x+2T2017_2/course/)

then:  
[https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)

followed by:  
[https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning)

Is making the switch to Deep Learning feasible for someone like me?

Is the course path I've outlined seem possible? Am I missing anything?",11,8
127,2018-6-21,2018,6,21,12,8somor,Doubt about the SqueezeNet architecture.,https://www.reddit.com/r/deeplearning/comments/8somor/doubt_about_the_squeezenet_architecture/,r5sb,1529551856,"I was reading through the SqueezeNet paper (https://arxiv.org/abs/1602.07360) and had a doubt regarding the way the architecture is represented here https://imgur.com/a/L2tbTax

From my understanding, the Squeeze Layer seems to be a single 1X1X3 convolution stage and the output of this is given parallel to a 1X1X4 convolution and 3X3X4 convolution (expand stage). Is this inference correct? That is what I understood looking at the model code.

Alternatively, could it be that the squeeze layer is 3 sequential 1X1XN filters the output of which is given a expand step with sequential 1X1XN convolutions and then 3X3xN convolutions? 

I'm confused by the explanation of the Fire module architecture and its illustration in the paper.",2,3
128,2018-6-21,2018,6,21,16,8sptex,Why Leaky ReLu is better than ReLu ?,https://www.reddit.com/r/deeplearning/comments/8sptex/why_leaky_relu_is_better_than_relu/,prithvi45,1529564869,[removed],0,1
129,2018-6-21,2018,6,21,16,8spvac,Why Leaky ReLu is better than ReLu?,https://www.reddit.com/r/deeplearning/comments/8spvac/why_leaky_relu_is_better_than_relu/,prithvi45,1529565491,[removed],0,1
130,2018-6-21,2018,6,21,16,8spygw,Why Leaky ReLu is better tha ReLu?,https://www.reddit.com/r/deeplearning/comments/8spygw/why_leaky_relu_is_better_tha_relu/,prithvi45,1529566604," ReLu won't converge at Negative value and it will not give output in zero centric , these are the shortcoming of ReLu and Leaky ReLu overcomes, lets understand the details by watching this video [why leaky ReLu is better than ReLu?](https://www.edyoda.com/resources/watch/54AEACDD9BC024F07FEFC156235E1229D7A999C/)",2,4
131,2018-6-21,2018,6,21,17,8sq6kn,Questions about resnet's layer response,https://www.reddit.com/r/deeplearning/comments/8sq6kn/questions_about_resnets_layer_response/,372995411,1529569474,"I've been reading resnet paper&lt;[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385v1)\&gt;, the layer response part is quit confusing to me.

at page 8 of  the original paper, figure 7:

*Processing img 5nbhi0yybb511...*

and the ""Analysis of Layer Responses."" paragraph:

&gt;These results support our basic motivation (Sec.3.1) that the residual functions   
&gt;  
&gt;might be generally closer to zero than the non-residual functions.

My question is : why the author proved residual layers tend to have smaller layer response close to zero by providing a figure which contains the STD information of the layer response instead of the layer response mean???

residual layer responses have a smaller  STD dont necessarily mean that they are smaller than plain network layer responses, only means they are close to the mean of layer responses, right??? Why they didnt provide the mean information as well?

Thanks  in advance",0,2
132,2018-6-21,2018,6,21,18,8sqh6z,Choosing a build for Deep Learning.,https://www.reddit.com/r/deeplearning/comments/8sqh6z/choosing_a_build_for_deep_learning/,RohitDulam,1529573325,"This is my Ryzen build(Ryzen 5 2600x)
https://pcpartpicker.com/list/CdkjGG

And 

This is my Intel build(i5-8400)
https://pcpartpicker.com/list/MmtQyX

Which one's better for Deep Learning?",4,2
133,2018-6-21,2018,6,21,22,8ss1s7,Deep learning career?,https://www.reddit.com/r/deeplearning/comments/8ss1s7/deep_learning_career/,innerpanda,1529589322,"I am a physics student and this semester I had a course on ""neural networks"". I am going to graduate soon and I'd love to follow a path about deep learning and neural networks both from a theorical and practical approach.
I have two opportunities and I cant figure out which would fit this career most .

It would be better to get into a theoretical physics master and then search for a Phd about this topics or to attend a master mainly about data and scientific computing (which has only one or two courses about deep learning?)

I was fascinated by the ideas of kohonen networks and non supervisionised learning, but I cant quite understand which path to follow since the paths I see are only marginally related to this kind of topics.

In the end, where can a student interested in these topics get a preparation?

Sorry for the length of the post and for any grammar mistakes: english is not my first language.",7,8
134,2018-6-22,2018,6,22,10,8sxinz,Choosing an appropriate method,https://www.reddit.com/r/deeplearning/comments/8sxinz/choosing_an_appropriate_method/,happy_pirate,1529632082,"I recently got an assignment to rank colleges based on thier acdamecic result,products developed from that college,no.of people applied and extra curricular activities.What ml and dl learning approach should i take.


If anyone have any similar code or links. pls share",7,2
135,2018-6-22,2018,6,22,14,8syuug,Regularization means we want small weight values. Does it contribute to vanishing gradient as well because smaller weights cause vanishing gradient?,https://www.reddit.com/r/deeplearning/comments/8syuug/regularization_means_we_want_small_weight_values/,LongjumpingGift,1529645456,,2,3
136,2018-6-22,2018,6,22,15,8sz59k,Why Linear Regression is impacted by Outliers ?,https://www.reddit.com/r/deeplearning/comments/8sz59k/why_linear_regression_is_impacted_by_outliers/,prithvi45,1529648861,"In simple words, **regression line moves away from ideal fit line due to outliers**

Lets understand with an example by watching this video [Why Liner Regression is impacted by Outliers ?](https://www.edyoda.com/resources/watch/54AEA770EE7FB10083C97A3E24729692A/) ",2,0
137,2018-6-22,2018,6,22,17,8szpuh,Deep Learning and Neural networks,https://www.reddit.com/r/deeplearning/comments/8szpuh/deep_learning_and_neural_networks/,ATGhoul1212,1529656062,"Im a newbie in deep learning and just started with gradient descent , i have a small doubt like why do we always look for local minima?",4,1
138,2018-6-22,2018,6,22,18,8t00kz,Why should I trust you? Interpreting deep learning models,https://www.reddit.com/r/deeplearning/comments/8t00kz/why_should_i_trust_you_interpreting_deep_learning/,antiquemule,1529660030,"When created, deep learning models are black boxes. That's a problem because it's easy to make stupid mistakes when you don't understand why your model is making some decision or other. The linked paper describes a general method for interpreting deep learning models. The ideas are incorporated into a Python package: LIME, that is also available in R. Cool stuff!",2,19
139,2018-6-22,2018,6,22,23,8t1mei,Deep Cars,https://www.reddit.com/r/deeplearning/comments/8t1mei/deep_cars/,marceloboeira,1529676671,,0,3
140,2018-6-23,2018,6,23,3,8t3mv6,Live text detection,https://www.reddit.com/r/deeplearning/comments/8t3mv6/live_text_detection/,dark_head0,1529692149,"I'm new in deep learning world, I want to develop a project regarding live text detection on mobile camera (without taking an image by the camera), can I do it by the tesorflow object detection api ? or with anyother tensorflow api or with opencv, which way is best? other suggestions are also welcome.",2,6
141,2018-6-23,2018,6,23,16,8t8erm,Convolutional Neural Network Layer Dimensions,https://www.reddit.com/r/deeplearning/comments/8t8erm/convolutional_neural_network_layer_dimensions/,arjundupa,1529739377,"I've been trying to train a CNN where x\_train has dimensions (1, 4500, 8192, 3) and y\_train has dimensions (4500, 8192). My model is:

`model = Sequential()`

`model.add(Conv2D(32, (3, 3), input_shape=(None, 8192, 3)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling2D(pool_size=(2, 2)))`

`model.add(Dense(output_dim = 8192))`

`model.add(Activation(""linear""))`

`model.compile(loss=""mse"", optimizer=""rmsprop"")`

I get the following error:

Error when checking target: expected activation\_14 to have 4 dimensions, but got array with shape (4500, 8192)

The shape is the same shape as my y\_train...I still do not understand why I get this error. Any ideas?

If you would like to look at the entire file, here it is: [https://github.com/arjung128/denoising-gravitational-waves/blob/master/Convolutional\_Neural\_Network.ipynb](https://github.com/arjung128/denoising-gravitational-waves/blob/master/Convolutional_Neural_Network.ipynb)

Any help will be appreciated. Thanks!",7,1
142,2018-6-23,2018,6,23,17,8t8od7,What is the best approach to replicate the google entity based sentiment analysis api.,https://www.reddit.com/r/deeplearning/comments/8t8od7/what_is_the_best_approach_to_replicate_the_google/,ashish_kr23,1529743453,"I am working on a project that requires such a service in languages that Google doesn't provide. Because of yhe scale/usecase i cannot afford to use the google api. Would be great if some can point out research papers/projects in this domain.Deep learning methods preferred.
I have researching since a few days, haven't been able to come up with something concrete.
Thanks.",3,3
143,2018-6-23,2018,6,23,19,8t94ug,Deep learning and neural networks,https://www.reddit.com/r/deeplearning/comments/8t94ug/deep_learning_and_neural_networks/,ATGhoul1212,1529750405,"Im a rookie in deep learning and have this one question  

How do we calculate weight and biases for the second time when my n has been defined  , Let us Suppose I have a target of 4 and suppose that the function is parabola , we take first step as negative slope. So as per the convention in order to find local minima , we would increase the value and finally adjust x to the point where we find the local minima , but my question is how do we decide the next weights then?  


1 =  ( x - a ))\^2

error is let suppose 0.8 and therefore again the descent is calculated and step is moved but im unable to understand the weights and biases calculation on basis of the step. I would appreciate if anyone could walk me through with this

Thanks in adv",1,2
144,2018-6-23,2018,6,23,23,8taeam,Kaggle Debut with Java - DL4J Learning Curve,https://www.reddit.com/r/deeplearning/comments/8taeam/kaggle_debut_with_java_dl4j_learning_curve/,EndyJBC,1529765241,"Just joined this [kaggle competition](https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-santander-value/) so as to learn and work with a real world puzzle. Unlike fast prototyping using Python, I'm using Java here and worked on bit and pieces of data pre-processing so far. My purpose here is to learn and make it good shape using Java rather than winning. Going through kernels posted by developers &amp; here is my DL4J code if anyone interested to see:   
[https://github.com/rahul-raj/Deeplearning4J/blob/master/src/main/java/SantanderValuePrediction.java](https://github.com/rahul-raj/Deeplearning4J/blob/master/src/main/java/SantanderValuePrediction.java)   
Appreciate if anyone could share their insights on the problem statement or if you have DL4J knowledgebase. ",0,1
145,2018-6-24,2018,6,24,1,8tawd7,What Makes Naive Bayes Classification So Naive? | How Does Naive Bayes Classifier Work,https://www.reddit.com/r/deeplearning/comments/8tawd7/what_makes_naive_bayes_classification_so_naive/,LearningFromData,1529769806,,0,0
146,2018-6-24,2018,6,24,5,8tcjyx,I recently built (from scratch) my first successful Neural Network! It can successfully classify MNIST with ~96% accuracy.,https://www.reddit.com/r/deeplearning/comments/8tcjyx/i_recently_built_from_scratch_my_first_successful/,award28,1529784380,,10,22
147,2018-6-24,2018,6,24,6,8td327,Tensorflow estimator API Tutorial,https://www.reddit.com/r/deeplearning/comments/8td327/tensorflow_estimator_api_tutorial/,tensor_assassin,1529789238,,0,1
148,2018-6-24,2018,6,24,7,8tdihl,Trying to understand the meaning of model.train() and model.eval(),https://www.reddit.com/r/deeplearning/comments/8tdihl/trying_to_understand_the_meaning_of_modeltrain/,Alirezag,1529793377,"Hi

So i see in the main.py ([Link](https://github.com/pytorch/examples/blob/master/imagenet/main.py)) we have model.train() and model.val(), i dont understand how to use them. can someone explain it to me please.For example in here:python main.py -a resnet18 \[imagenet-folder with train and val folders\]we did not specify train or eval, so how do we know which one to use.I know my question is stupid, please let me know if there is any good tutorial to read and understand it.

Thanks",1,0
149,2018-6-24,2018,6,24,20,8th3gj,MobileNet Image Classification with Keras - Video series,https://www.reddit.com/r/deeplearning/comments/8th3gj/mobilenet_image_classification_with_keras_video/,blackHoleDetector,1529838030,"In this series, we learn about MobileNets, a class of light weight deep convolutional neural networks that are vastly smaller in size and faster in performance than many other widely known models, like VGG16 and GoogleNet. Well also learn how to work with MobileNets in code using Keras. Because of their small size, MobileNets are considered great deep learning models to be used on mobile devices or to run in browser applications.

- [Part 1 - Intro to MobileNet Image Classification with Keras](https://youtu.be/OO4HD-1wRN8)
- [Part 2 - Build a fine-tuned MobileNet model with Keras](https://youtu.be/4Tcqw5oIfIg)
- [Part 3 - Train a fine-tuned MobileNet model with Keras](https://youtu.be/-0Blng0Ww8c)
- [Part 4 - Build a sign language image classifier using MobileNets](https://youtu.be/FNqp4ZY0wDY)",0,1
150,2018-6-24,2018,6,24,20,8th8d3,Laptop for DL,https://www.reddit.com/r/deeplearning/comments/8th8d3/laptop_for_dl/,PascP,1529839983,"Hello guys, 
I would like your opinion on buying [this](https://www.amazon.com/MSI-GE63-Raider-RGB-010-Performance/dp/B07BBCMKLW) laptop for DL training.
I know a lot of you might say that a laptop is not the right tool for this kind of activity but since I cannot have a desktop due to portability reasons, what do you think. I've also heard guys suggesting getting a cheap laptop and a desktop but this still involves a desktop. 
Lastly, I think that cloud services are quite expensive when u need to use a GPU and you end up spending money without owning the hardware in the long term. I might be wrong but I think that I month o continues usage of GPU in cloud services costs about 1000$. Is that correct?

",8,1
151,2018-6-25,2018,6,25,4,8tkdn3,One Cycle Policy,https://www.reddit.com/r/deeplearning/comments/8tkdn3/one_cycle_policy/,nachiket273,1529870025,Finding Good Learning Rate and The One Cycle Policy. https://medium.com/@nachiket.tanksale/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6,1,4
152,2018-6-25,2018,6,25,5,8tkflu,Downloaded 20 classes from ImageNet (~24000 pictures total). Is there any point in training a convnet from scratch with that amount of data?,https://www.reddit.com/r/deeplearning/comments/8tkflu/downloaded_20_classes_from_imagenet_24000/,gerphys,1529870477,"I am currently working through 'Deep Learning with Python' from Francois Chollet. I'd like to do something like the 'Dogs versus Cats' example. I downloaded pictures of 20 classes from the ImageNet collection, typical office objects (laptops, coffee mugs, mice, office plants etc.)

Doing feature extraction with one of the pre-trained convnets provided by Keras works quite fine. (for example I reach \~89&amp;#37; test accuracy for a DenseNet121). 

But I didn't manage so far to reach satisfactory accuracy on any attempt at a custom convnet from scratch. Training one of Keras' networks (I mostly experimented with MobileNet and DenseNet) from scratch usually gives me only 40-50&amp;#37; test accuracy on those 20 classes. Sure, this does beat the expected baseline of 5&amp;#37; by far, but I wonder why I cannot reach better accuracy..

I am employing data augmentation as described in the DLWP book; experimented with SGD, RMSprop, Adam with various parameters. Smaller custom convnets show similiar training behaviour; the most best I ever got was 56&amp;#37; test accuracy on a down-sized version of Xception ('Small Xception' by Francois Chollet, [https://gist.github.com/fchollet/0f8eaa08f09e33e547431023d5955709](https://gist.github.com/fchollet/0f8eaa08f09e33e547431023d5955709) ). Validation loss always stalls at 50-150 epochs, then usually starts to degrade into overfitting.

Question: Is this amount of data (I split the data into \~22000 training images, \~2000 test images) even sufficient for training any kind of convnet from scratch, or is the attempt simply hopeless, even with employing the full DL arsenal like data augmentation, perfectly tuned network size, dropout layers, etc? Have people successfully trained a MobileNet or another one of Keras' provided networks from scratch with custom data?",7,6
153,2018-6-25,2018,6,25,7,8tle5c,Registering a transcript and its summary,https://www.reddit.com/r/deeplearning/comments/8tle5c/registering_a_transcript_and_its_summary/,sairegrefree,1529878510,"I have a bullet point summary and the transcript of a conversation between two person. Any idea on how find out which set of lines in the transcript that corresponds to a point in the summary?

Idea 1: Convert the point in the summary to a 'question' and use comprehension models. 

Idea 2: Find matching key words in the transcript and use co-reference resolution and word matching to find other lines in the transcript to find all the relevant conversations.

Cons: Both comprehension and co-reference models/data sets do not work well in dialog transcripts.

Any new ideas or comments on my approaches? 

\[post from r/LanguageTechnology\]",0,2
154,2018-6-25,2018,6,25,11,8tn2o8,Finding the correct NN model for the task,https://www.reddit.com/r/deeplearning/comments/8tn2o8/finding_the_correct_nn_model_for_the_task/,Envenger,1529894448,"Hello,

I started with python and tensorflow recently and as my first training project, I have been looking to make something like this.  


A. I want to move a group of objects each having a 2 position and a facing direction to another 2 position and a facing direction. Each object should have a maximum speed it can move in and how fast in can accelerate or brake.  
I don't want them to break the formation as they are moving.  


*Processing img 4ggubk6872611...*

B. The number of objects are dynamic so the neural network should be able to take inputs for 5 objects to 30 objects.  


C. Apart from moving in formation, I want them to change their formation as they move.  


*Processing img 3b21ih2972611...*

  
As for training, I plan on generating starting positions and ending positions and run the neural network on it per frame with input as the objects locations at he initial and desired positions.  


And would write a function to check the initial and final output of the neural network and test based on it.  


I want to know which kind of model should I used and where exactly to stat this.  


For now, I have written a class in python for the unit which it has a location and a facing direction and can move in a XY plane. I wrote a visual representation using tkinter class so at time, i can check how the training of the model is going.",5,10
155,2018-6-25,2018,6,25,14,8to0x2,Neural Nets in High Frequency Trading,https://www.reddit.com/r/deeplearning/comments/8to0x2/neural_nets_in_high_frequency_trading/,robresno,1529904537,[removed],0,1
156,2018-6-25,2018,6,25,19,8tpejd,"Learn Data Science, Machine and Deep Learning with Python",https://www.reddit.com/r/deeplearning/comments/8tpejd/learn_data_science_machine_and_deep_learning_with/,atkarti,1529922193,,0,0
157,2018-6-25,2018,6,25,21,8tpxx9,Help on transfer learning,https://www.reddit.com/r/deeplearning/comments/8tpxx9/help_on_transfer_learning/,captainskrra,1529928128,"Can anyone post links to implementations of transfer learning in tensorflow?  
The steps where we cache the values of the second-last layer for the training examples, organising them and then extracting them to retrain on newer classes,",1,2
158,2018-6-26,2018,6,26,0,8tr9ij,Cars detection from satellite imagery using RetinaNet,https://www.reddit.com/r/deeplearning/comments/8tr9ij/cars_detection_from_satellite_imagery_using/,Bo_Bibelo,1529939407,,3,24
159,2018-6-26,2018,6,26,1,8ts20h,Help with how to progress with Convolutional Neural Networks,https://www.reddit.com/r/deeplearning/comments/8ts20h/help_with_how_to_progress_with_convolutional/,hardhat528491,1529945284,"I have understood the theory behind Convolutional Neural Networks and would like to practice implementing them in PyTorch. 

I have implemented a CNN for the MNIST dataset. How should I proceed?

My approach was to search github for implementations for MNIST CNN, understand the code using the PyTorch documentation and then implement it myself.

What should be my next move? 

I was thinking of implementing some of the popular network architectures(ResNet, Inception etc) myself on datasets like CIFAR-10 to deepen my understanding of CNNs

Would this be a good strategy? If yes, what should be my next move when I'm done with these? If not, what should I rather be doing? ",3,2
160,2018-6-26,2018,6,26,10,8tw022,Resource Exhausted Error,https://www.reddit.com/r/deeplearning/comments/8tw022/resource_exhausted_error/,arjundupa,1529976746,"I'm training a CNN ([https://github.com/clarle/denoising-gravitational-waves/blob/master/Convolutional\_Neural\_Network.ipynb](https://github.com/clarle/denoising-gravitational-waves/blob/master/Convolutional_Neural_Network.ipynb)), and I get the following error:

`OOM when allocating tensor with shape[8192]`

\*Please ignore the error at the end of the Jupyter notebook in the link -- I tried to train the exact same CNN on a GPU and got the above error.

I do not understand why I get this error since the same GPU is able to comfortably evaluate the RNN here ([https://github.com/arjung128/denoising-gravitational-waves/blob/master/Recurrent\_Neural\_Network\_Multivariate\_Gaussian.ipynb](https://github.com/arjung128/denoising-gravitational-waves/blob/master/Recurrent_Neural_Network_Multivariate_Gaussian.ipynb)) which uses tensors of shape \[8192, 3\] at the minimum...

Any ideas?

Any help will be appreciated, thanks in advance.",5,1
161,2018-6-26,2018,6,26,16,8ty2ul,Deep learning and neural networks,https://www.reddit.com/r/deeplearning/comments/8ty2ul/deep_learning_and_neural_networks/,ATGhoul1212,1529997932,I just have one simple doubt like what is the reason for z to be -z in sigmoid function?,0,0
162,2018-6-26,2018,6,26,16,8ty2w1,A simple deep learning approach i wrote to read 100k vernacular newspapers in india for issue detection and combating fake news.,https://www.reddit.com/r/deeplearning/comments/8ty2w1/a_simple_deep_learning_approach_i_wrote_to_read/,ashish_kr23,1529997945,Reading 100K newspapers in 20 vernacular languages in India https://medium.com/@ashishkumar_96311/reading-100k-newspapers-in-20-vernacular-languages-in-india-4e859c468a57,4,18
163,2018-6-26,2018,6,26,18,8tyoc0,Deep Learning for Time Series Forecasting: Predicting Sunspot Frequency with Keras,https://www.reddit.com/r/deeplearning/comments/8tyoc0/deep_learning_for_time_series_forecasting/,antiquemule,1530005720,"A very complete tutorial on fitting a times series. In R, but hey, you pythonistas are all bilingual, right?

[https://tensorflow.rstudio.com/blog/sunspots-lstm.html](https://tensorflow.rstudio.com/blog/sunspots-lstm.html)",0,13
164,2018-6-26,2018,6,26,19,8tyv5b,Does anyone have Diabetic Retinopathy data other than Kaggle data?,https://www.reddit.com/r/deeplearning/comments/8tyv5b/does_anyone_have_diabetic_retinopathy_data_other/,vikaskookna,1530008077,,0,2
165,2018-6-26,2018,6,26,19,8tz2mp,Deep Learning on the Edge  Towards Data Science,https://www.reddit.com/r/deeplearning/comments/8tz2mp/deep_learning_on_the_edge_towards_data_science/,friscotime,1530010568,,0,2
166,2018-6-26,2018,6,26,21,8tzh5j,Independent multiple Human keypoint detector,https://www.reddit.com/r/deeplearning/comments/8tzh5j/independent_multiple_human_keypoint_detector/,yuyangaichifan,1530014897,"I want a human keypoint detector which can detect human joints on the whole image, as the way in Openpose, however, Openpose fails on small targets in an image. Other methods, e.g. Mask RCNN and RMPE, requires human detection bounding box and apply keypoint detection within the bounding box region which is different with my problem setting.

Is there any existing work on this topic??

Or is there any way to improve openpose performance on small targets?",2,6
167,2018-6-27,2018,6,27,21,8u9blp,What is the best way to host a DL pipeline where image input passes and transforms at multiple steps and multiple models?,https://www.reddit.com/r/deeplearning/comments/8u9blp/what_is_the_best_way_to_host_a_dl_pipeline_where/,xpbit1024,1530103651,,2,3
168,2018-6-28,2018,6,28,1,8ub9aj,Range of values of system prediction and test array don't match,https://www.reddit.com/r/deeplearning/comments/8ub9aj/range_of_values_of_system_prediction_and_test/,Lorderbs,1530118502,"So I'm running a deep learning network with Keras in python and basically the ""expected"" output values are between -1 and 1, which the test and training array both are uniform distributed between. But after I run my network and let the model predict on test data, it predicts values outside of this range, while the results ""in general"" make sense. Is this something I need to worry about/am I doing something wrong (pretty new to deep learning)?
(Will add pictures to make the situation clearer later)",5,1
169,2018-6-28,2018,6,28,5,8ucxzm,"Keras Layers cheat sheet, written for the Metis curriculum",https://www.reddit.com/r/deeplearning/comments/8ucxzm/keras_layers_cheat_sheet_written_for_the_metis/,hergertarian,1530130412,"https://www.hergertarian.com/keras-layers-intro

What would you guys add?",0,18
170,2018-6-28,2018,6,28,12,8ug5bi,This is a pretty dope shirt,https://www.reddit.com/r/deeplearning/comments/8ug5bi/this_is_a_pretty_dope_shirt/,Weekly_Positive_Tips,1530157953,,1,0
171,2018-6-28,2018,6,28,23,8ujxtn,[AR &amp; DeepLearning] Spider 'faceFilter' available on github: https://github.com/jeeliz/jeelizFaceFilter,https://www.reddit.com/r/deeplearning/comments/8ujxtn/ar_deeplearning_spider_facefilter_available_on/,StartupJeeliz,1530196260,,3,18
172,2018-6-29,2018,6,29,3,8ulwck,Using mini-batch SGD (confusion),https://www.reddit.com/r/deeplearning/comments/8ulwck/using_minibatch_sgd_confusion/,maybenexttime82,1530208988,"Let's imagine I want to solve some image classification problem (MNIST example) and let's say that I'm using Mini Batch SGD algorithm. What I'm confused with is this: For every random batch of samples we feed into network do we generate new loss function relative to those batch of samples or we generate one loss function relative to all samples we have before we even start training network and then we just run the network on batches of samples in order to calculate gradient and then minimize that one function. Don't know why but I'm confused because in regression problems we first define MSE loss function relative to all samples and then we use gradient descent to come back to (possibly) global minima. Somehow I don't see this step of how n-dimensional loss surface is, so to say, ""initialized"" (and based on what?) in MNIST example?",7,1
173,2018-6-29,2018,6,29,11,8uprzn,GAN Results Discrepancy,https://www.reddit.com/r/deeplearning/comments/8uprzn/gan_results_discrepancy/,arjundupa,1530241144,"I was going through DataCamp's tutorial on GANs ([https://www.datacamp.com/community/tutorials/generative-adversarial-networks](https://www.datacamp.com/community/tutorials/generative-adversarial-networks)) -- As you can see, the results are pretty impressive just after 40 epochs.

I implemented this myself with minor code modifications (mostly structural) and got the same results yesterday. My code and results from yesterday are here: [https://github.com/arjung128/deep-learning-experiments/blob/master/MNIST\_GAN\_V1.ipynb](https://github.com/arjung128/deep-learning-experiments/blob/master/MNIST_GAN_V1.ipynb)

I ran the same notebook today, and, to my surprise, the results were horrendous. Nothing like the results in the tutorial or the results I had gotten yesterday. I copied and pasted my code from yesterday into a new Jupyter notebook and the results were still terrible. You can view the code and the results here: [https://github.com/arjung128/deep-learning-experiments/blob/master/MNIST\_GAN\_V2.ipynb](https://github.com/arjung128/deep-learning-experiments/blob/master/MNIST_GAN_V2.ipynb)

Any ideas? Any input will be appreciated! ",2,3
174,2018-6-29,2018,6,29,17,8urhhe,Profiling Tensorflow Code,https://www.reddit.com/r/deeplearning/comments/8urhhe/profiling_tensorflow_code/,liftoff01,1530260146,"From what I gather, the profiling framework shown in the last tensorflow summit, [https://www.youtube.com/watch?v=SxOsJPaxHME] works only on the Google TPUs. 

Does anyone know a similar facility available for GPUs or if I can tweak the framework above to work with a GPU?",2,4
175,2018-6-29,2018,6,29,18,8urp8o,"Keras - CNN, workers, queue",https://www.reddit.com/r/deeplearning/comments/8urp8o/keras_cnn_workers_queue/,TheKocka8,1530263136,"Hello,

Can someone please explain to me, what do these parameters in fit\_generator actually do and mean?(**Workers**, ** max\_queue\_siz**e)   I was not able to find any satisfying answer so far. That is the reason I am turning to this community.

Thanks in advance for your answers",3,5
176,2018-6-29,2018,6,29,19,8us1il,How to Do Distributed Deep Learning for Object Detection Using Horovod on Azure,https://www.reddit.com/r/deeplearning/comments/8us1il/how_to_do_distributed_deep_learning_for_object/,rennytech,1530267525,,0,1
177,2018-6-29,2018,6,29,19,8us20k,Personalized deep learning equips robots for autism therapy,https://www.reddit.com/r/deeplearning/comments/8us20k/personalized_deep_learning_equips_robots_for/,jackblun,1530267714,,0,1
178,2018-6-30,2018,6,30,3,8uvgll,how is the result of deeplearning if our data is small,https://www.reddit.com/r/deeplearning/comments/8uvgll/how_is_the_result_of_deeplearning_if_our_data_is/,iceporter,1530296961,"hello all I want to reproduce tony beltramelli study ([pix2code](https://github.com/tonybeltramelli/pix2code))  


but instead html it produce js code like vue/react/angular   


  
but the problem is I have no team just a single man who want to have fun with deep learning  


so the dataset that I have will be small, I see from tony github his data for training and validating is around 3500   


thanks for your attention have a good day/",6,3
179,2018-6-30,2018,6,30,18,8v0qc7,T2F: Text to Face generation using Deep Learning,https://www.reddit.com/r/deeplearning/comments/8v0qc7/t2f_text_to_face_generation_using_deep_learning/,akanimax,1530350662,,0,30
180,2018-6-30,2018,6,30,21,8v1j7s,AI Weekly 29 June 2018,https://www.reddit.com/r/deeplearning/comments/8v1j7s/ai_weekly_29_june_2018/,TomekB,1530361828,,0,1
181,2018-6-30,2018,6,30,21,8v1ldu,Fully Connected Networks and Generative Neural Networks Applied to Sclera Segmentation,https://www.reddit.com/r/deeplearning/comments/8v1ldu/fully_connected_networks_and_generative_neural/,ghostzin,1530362557,,0,2
0,2018-7-1,2018,7,1,17,8v8o03,Multi class prediction in higher dimensional outputs,https://www.reddit.com/r/deeplearning/comments/8v8o03/multi_class_prediction_in_higher_dimensional/,captainskrra,1530434556,"I have an image of animals - cats, dogs, horses.. (10 animals).

Let's say they are of different colours - black, white, blue.. (10 colors).

I want to build a CNN that tells me which animal is it, and also what is the colour of the animal.

1. Should the output layer have 100 features, or 20 are enough - first 10 for the animal and second for colour? 
2. Should we do one-hot encoding if we want to predict multiple classes in an image?
3. If we use 20 layers, what loss function is desired to be used?
4. What if there are more number of classes (100 animals and 100 colors) ?

P.S. I know we can use two CNNs for this task, but I wish to do this by using only one.",1,8
1,2018-7-1,2018,7,1,23,8va4yd,Learn Data Science - Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/8va4yd/learn_data_science_deep_learning_in_python/,algbra,1530454247,,0,2
2,2018-7-2,2018,7,2,7,8vdgx5,"I made a labelling tool to annotate very long and repetitive videos. It shows several clips on screen simultaneously in loop, it's called MuViLab. What do you think?",https://www.reddit.com/r/deeplearning/comments/8vdgx5/i_made_a_labelling_tool_to_annotate_very_long_and/,ale152,1530482559,,19,51
3,2018-7-2,2018,7,2,13,8vfpz4,Self-Help Books Are Changing My Life,https://www.reddit.com/r/deeplearning/comments/8vfpz4/selfhelp_books_are_changing_my_life/,MindfullMaster,1530504303,,0,0
4,2018-7-2,2018,7,2,16,8vgnel,Instant WillPower BOOST (animation),https://www.reddit.com/r/deeplearning/comments/8vgnel/instant_willpower_boost_animation/,MindfullMaster,1530514993,,0,0
5,2018-7-2,2018,7,2,19,8vhm5m,Why are printed documents difficult for GAN's to reproduce ?,https://www.reddit.com/r/deeplearning/comments/8vhm5m/why_are_printed_documents_difficult_for_gans_to/,mohanradhakrishnan,1530527511,"I am looking for some simple papers to read and understand why this is a hard problem to solve.  Can't GAN's just reproduce words and create meaningless printed text images ? Is that hard too ? 

I tried to train a GAN on multiple clouds without realizing this problem is not solved.

Is this a statistical distribution issue ?",1,1
6,2018-7-3,2018,7,3,0,8vjc0e,Microsoft Releases v0.13 of its distributed deep learning framework,https://www.reddit.com/r/deeplearning/comments/8vjc0e/microsoft_releases_v013_of_its_distributed_deep/,mhamilton723,1530543954,,0,4
7,2018-7-3,2018,7,3,3,8vky4d,Neural Net Classifier with sparse output,https://www.reddit.com/r/deeplearning/comments/8vky4d/neural_net_classifier_with_sparse_output/,robresno,1530555721,"I have a data-set where the output is a class:

0 - don't do anything

1 - long trade signal

2 - short trade signal

The problem is that 75&amp;#37; of training data has 0 as output. Signal 1 or 2 are present less frequently about 25&amp;#37;.

The neural net learned that it needs to produce zero output in most cases while don't really care about the signal 1 or 2.

How do I tell that model that when signal is predicted correctly it's much more valuable then predicting zero?

I'm sure this must be a common case. I'm new to NN.",1,2
8,2018-7-3,2018,7,3,11,8vonm3,Just an idea...,https://www.reddit.com/r/deeplearning/comments/8vonm3/just_an_idea/,TransferTrip,1530585515,"Wouldnt it be amazing to use deep learning algorithms in a program that allows you to put yourself in movies.  We already have that technology as displayed with deepfaking, but could you imagine the application of free form movies where you describe what you look like, and it analyzes your voice so your character sounds like you.  That kind of entertainment in VR would be a game changer.  Video games would take a whole different direction, with storylines that change as your character develops. I dont know what that would take, but hopefully one day somebody has this same idea.",1,12
9,2018-7-3,2018,7,3,12,8votg8,[Question] DNN type and structure for waveform generation?,https://www.reddit.com/r/deeplearning/comments/8votg8/question_dnn_type_and_structure_for_waveform/,ThatsALovelyShirt,1530587045,"So I would like to train a generative network to create waveforms/audio samples (either as waveforms outright or something I can convert to one, e.g., via fft) based on the audio sample's potential  association to keywords or images. That is, I would first train a network to classify audio samples to either a set of keywords or an image. Then, perhaps using that trained network to train another generative network, I would like to be able to supply a set of keywords (or an image) to the second generative network and get a waveform back out.

Obviously there is a lot at play here. I would like a very rich classification set with many possibilities, so obviously accuracy will be low on the first classification network. Which is fine, I don't need a lot of accuracy. But what sort of DNN structure would best for this? Also, how might I want to represent the input waveform to be classified? Should I convert it into a 2D representation and pair that with a convolutional network? Or perhaps keep it as a linear stream of data and use an RNN?

And on the generative end, reverse convolutional networks are still a bit of a mystery to me. Is it really as simple as training a CNN structured in reverse using an adversarial type of training regimen (I.e., using the first classification network to judge/classify the generated results of the generative network, and thus iteratively train it)?

Any insights would be greatly appreciated. Thanks!",5,2
10,2018-7-3,2018,7,3,13,8vpelb,[P] Python package for ProGAN using PyTorch,https://www.reddit.com/r/deeplearning/comments/8vpelb/p_python_package_for_progan_using_pytorch/,akanimax,1530592928,,2,2
11,2018-7-3,2018,7,3,20,8vrk0z,"If You Find Drawing Difficult, Learn This To Impress Your Friends",https://www.reddit.com/r/deeplearning/comments/8vrk0z/if_you_find_drawing_difficult_learn_this_to/,Razinon,1530618541,,2,0
12,2018-7-3,2018,7,3,23,8vsjvn,How I built a Self Flying Drone to track People in under 50 lines of code,https://www.reddit.com/r/deeplearning/comments/8vsjvn/how_i_built_a_self_flying_drone_to_track_people/,digitalson,1530627495,,0,1
13,2018-7-3,2018,7,3,23,8vsknk,Supercharging Classification - The Value of Multi-task Learning,https://www.reddit.com/r/deeplearning/comments/8vsknk/supercharging_classification_the_value_of/,magneticono,1530627678,,0,1
14,2018-7-3,2018,7,3,23,8vsoz2,"The Good, Bad and Ugly: Apache Spark for Data Science Work",https://www.reddit.com/r/deeplearning/comments/8vsoz2/the_good_bad_and_ugly_apache_spark_for_data/,chris_shpak,1530628636,,0,1
15,2018-7-4,2018,7,4,2,8vtw1y,Deploy State-of-the-Art Deep Learning on Edge Devices in Minutes,https://www.reddit.com/r/deeplearning/comments/8vtw1y/deploy_stateoftheart_deep_learning_on_edge/,DrDetection,1530637491,,1,1
16,2018-7-4,2018,7,4,2,8vubkg,DCGAN Producing same image as input,https://www.reddit.com/r/deeplearning/comments/8vubkg/dcgan_producing_same_image_as_input/,og_kratos,1530640587,"Hi, I am trying to recreate a paper that uses a deep learning model to recreate under-sampled MRI images.

I am using a DCGAN with an encoder and decoder structure and perform 5 convolutions in each encoder block and 3 convolutions (residual structure) in each decoder block followed by a nearest neighbor interpolations. (I am using 4 encoder and 4 decoder blocks for my structure) 

The problem I am running into is that my output images are the same as my input images (undersampled images). I tried searching online but the only issue addressed that I could find was that all the output images produced were the same. In my case the output images are not similar to one another but are exactly the same as their corresponding input images. 

The loss function for the discriminator is defined as follows

Dreal = Discriminator(input\_D) where input\_D are the original images without any undersampling.

Dfake = Discriminator(Gout)

D\_loss = -tf.reduce\_mean(tf.log(Dreal) + tf.log(1. - Dfake))

Both Discriminator and Generator loss are decreasing and around 100 epochs the discriminator loss is around 1 and the generator loss around 18. However, no matter the epoch i get the same output as my input, whether I have trained it for 25 epochs or for 250 epochs. 

This does not make any sense to me as the loss is clearly decreasing which means that both the generator and discriminator are learning so the output image should not be the same as the undersampled input image.

I am using tensorflow and the optimizer being used is AdamOptimizer. 

Any hep would be appreciated and thanks in advance.",5,1
17,2018-7-4,2018,7,4,7,8vwnjt,Top 22 Deep Learning Papers,https://www.reddit.com/r/deeplearning/comments/8vwnjt/top_22_deep_learning_papers/,asifrazzaq1988,1530658527,,6,11
18,2018-7-4,2018,7,4,17,8vzykf,Overview and benchmark of traditional and deep learning models in text classification,https://www.reddit.com/r/deeplearning/comments/8vzykf/overview_and_benchmark_of_traditional_and_deep/,dearpetra,1530691495,,0,1
19,2018-7-4,2018,7,4,17,8w006z,anyone know an implementation of densecrf(fully connected crf) in any major deep learning framework?,https://www.reddit.com/r/deeplearning/comments/8w006z/anyone_know_an_implementation_of_densecrffully/,chadrick-kwag,1530692026,"While looking into image segmentation, I've encountered a few papers that used dense CRF (fully connected CRF) .

However I cannot seem to find any major deep learning frameworks that support this.

Has anyone seen this implementation?",1,3
20,2018-7-4,2018,7,4,17,8w05cg,Learn Convolutional Neural Networks / Residual Connections / Inception Module,https://www.reddit.com/r/deeplearning/comments/8w05cg/learn_convolutional_neural_networks_residual/,John1807,1530693911,,2,1
21,2018-7-5,2018,7,5,5,8w4jx8,GANs: Should the learning rate of Generator and Discriminator be same? Why or why not?,https://www.reddit.com/r/deeplearning/comments/8w4jx8/gans_should_the_learning_rate_of_generator_and/,Naughty_Nagaland,1530734611,,3,5
22,2018-7-5,2018,7,5,12,8w7ewl,Can object location by deep learning adapt to different scene?,https://www.reddit.com/r/deeplearning/comments/8w7ewl/can_object_location_by_deep_learning_adapt_to/,mhaoyanghb,1530761952,"As we know, deep learning can locate object and classify objects. it depends on training samples(data).

now I want to discuss object location problem in different scene, if I had trained a system that can locate cat, dog.

is the training sample include background ? what is the training set compose of?

because I have a question, if the system is deployed into a new environment, will the system locate the objects correctly?

my point is will the new environment (background ) affect the system's location performance ?

we know that deep learning system depend on samples, while in object location problem, background samples are also needed in training.

so if changed to a different scene , background changed to a new one ,which not included in training samples, will the system still work properly?

if so ,why ? if not, why ?

and how to improve it , because we can't collect all scenes into training samples, then , how can the system deploy into any scenes ?

Let's talk about the recognition ability of CNN while samples is limited",8,5
23,2018-7-5,2018,7,5,15,8w8auh,Deep Learning,https://www.reddit.com/r/deeplearning/comments/8w8auh/deep_learning/,ATGhoul1212,1530772339,Can we make a system which understands and notify user for someone else's vicious intentions ?,3,2
24,2018-7-5,2018,7,5,15,8w8efa,Links to Computer Vision News of July and BEST OF CVPR,https://www.reddit.com/r/deeplearning/comments/8w8efa/links_to_computer_vision_news_of_july_and_best_of/,Gletta,1530773554,"Here is the July 2018 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: 52 pages worth reading, most of them about BEST OF CVPR2018 presentations, interviews and highlights. Technical review of new technologies (with codes!) at page 4 and free subscription at page 52.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2018July/)

[PDF version](http://www.rsipvision.com/computer-vision-news-2018-june-pdf/)

Enjoy!",0,8
25,2018-7-5,2018,7,5,17,8w8sbf,All the latest @ AI Expo Europe,https://www.reddit.com/r/deeplearning/comments/8w8sbf/all_the_latest_ai_expo_europe/,Batareika_1,1530778408,,0,1
26,2018-7-5,2018,7,5,18,8w93ht,Request for recommendation,https://www.reddit.com/r/deeplearning/comments/8w93ht/request_for_recommendation/,altunhasanli,1530782649,"Hi everyone, Ive worked on a few small projects in deep learning. I want to get my hands on something big and something that will end up being a relatively large learning curve.

What do you advise me to do? Which specific area should I better work on (nlp, computer vision etc.)? Whats trending right now?

Im open to any kind of recommendation &amp; advice as Im only learning.",2,8
27,2018-7-5,2018,7,5,20,8w9oda,Deep Learning Tips and Tricks,https://www.reddit.com/r/deeplearning/comments/8w9oda/deep_learning_tips_and_tricks/,digitalson,1530789842,,0,1
28,2018-7-6,2018,7,6,0,8wb3xs,WILL ARTIFICIAL INTELLIGENCE MAKE CITIZEN SCIENTISTS OBSOLETE?,https://www.reddit.com/r/deeplearning/comments/8wb3xs/will_artificial_intelligence_make_citizen/,asifrazzaq1988,1530802828,,1,0
29,2018-7-6,2018,7,6,0,8wb66h,Neural Networks on iOS App,https://www.reddit.com/r/deeplearning/comments/8wb66h/neural_networks_on_ios_app/,arjundupa,1530803291,"So I can capture images on this demo iOS app I made, and on my laptop, I've got this python file with a neural network I need to run the captured image through before sending some results (image / string) back to the iOS app.

How can I go about doing this? I don't think I'll be able to use the Swift neural network libraries out there since I'm currently using the dlib library locally, but if I must I will look into those.

Any help will be appreciated. Thanks!",2,1
30,2018-7-6,2018,7,6,0,8wban2,The unreasonable effectiveness of Deep Learning Representations,https://www.reddit.com/r/deeplearning/comments/8wban2/the_unreasonable_effectiveness_of_deep_learning/,e_ameisen,1530804234,,1,15
31,2018-7-6,2018,7,6,14,8whlpp,yummmy,https://www.reddit.com/r/deeplearning/comments/8whlpp/yummmy/,karrysong,1530855881,,1,0
32,2018-7-6,2018,7,6,17,8wido7,Autonomous UAV (drone) for technical inspections,https://www.reddit.com/r/deeplearning/comments/8wido7/autonomous_uav_drone_for_technical_inspections/,Batareika_1,1530865029,,1,7
33,2018-7-6,2018,7,6,22,8wk8zw,Bag of datasets,https://www.reddit.com/r/deeplearning/comments/8wk8zw/bag_of_datasets/,mihir_parulekar,1530885253,Is there any platform where we can keep our datasets so that others can use that ?,5,7
34,2018-7-7,2018,7,7,4,8wmqsa,Need Image dataset,https://www.reddit.com/r/deeplearning/comments/8wmqsa/need_image_dataset/,NetworkForce,1530903792,"hi i am Searching eye disease TRACHOMA and cataract image dataset. Can anyone send me the image dataset of these diseases

",0,1
35,2018-7-7,2018,7,7,4,8wmujx,RCNN,https://www.reddit.com/r/deeplearning/comments/8wmujx/rcnn/,ATGhoul1212,1530904560,"Hello all, Im getting this error No module named 'keras\_retinanet.utils.compute\_overlap' 

Here is the code snippet:

model\_path = os.path.join('..', 'snapshots', 'resnet50\_coco\_best\_v2.1.0.h5')

\# load retinanet model

model = models.load\_model(model\_path, backbone\_name='resnet50')

\# if the model is not converted to an inference model, use the line below

\# see: [https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model](https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model)

model = models.load\_model(model\_path, backbone\_name='resnet50', convert\_model=True)

\#print(model.summary())

\# load label to names mapping for visualization purposes

labels\_to\_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}  
Can anyone help ?",0,3
36,2018-7-7,2018,7,7,6,8wnv8d,Loading GloVe pre-trained embeddings as a TensorFlow embedding layer IN THE GPU,https://www.reddit.com/r/deeplearning/comments/8wnv8d/loading_glove_pretrained_embeddings_as_a/,GChe,1530912351,,0,5
37,2018-7-7,2018,7,7,12,8wqbi0,[Question] Network structure/type best geared towards classifying non-language sounds?,https://www.reddit.com/r/deeplearning/comments/8wqbi0/question_network_structuretype_best_geared/,ThatsALovelyShirt,1530934746,"So I'm trying to design a deep neural network takes with classifying or characterizing sounds (16 bit signed wav files @ 44100 KHz sampling rate). The audio clips will be between 0.2 and 20 seconds in length. 

I initially thought about converting the sounds into spectrograms and then feed those into a standard CNN, but I would instead like to be able to recover the sound data back from whatever form it takes as its fed into the network. Unfortunately spectrograms are often subsampled and merely carry absolute amplitude, thus lack any phase information.

To get around this, I'm going to convert the wav files into something more akin to what an actual brain deals with. Using a fast Fourier transform, I will construct a 150 x 150 pixel single channel ""image"" of floating point data for each sample of the wav file, with the data normalized to the maximum signed potential value of the 16 bit samples. This will provide me a 22.5 KHz frequency range (150^2). At a 44.1 KHz (Nyquist freq. for human hearing) sampling rate, that's 44100 images per second of audio, and thus a lot of data. But it's similar to how a cochlea converts sound into something useful.

The trouble is finding a network structure that is able to deal with this much data in a temporally cohesive way. A traditional CNN will fail, as will most RNNs. But does anyone have any ideas about how to go about this?

The hope here is to be able to take the trained latent space and reverse the process, whereby I can have the network *generate* a sequence of images representative of an input classification or characterization, and then convert that sequence of ""images"" back into it's wav file representation. 

I've looked into Wavenet, but it doesn't perform exactly what I'm after.

Any insights would be welcome! Thanks!

",6,3
38,2018-7-8,2018,7,8,1,8wufyg,Agent Based Model using Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/8wufyg/agent_based_model_using_reinforcement_learning/,ragas_,1530981660,"Hi,

I'm looking for reference or examle code for agent based model simulation using reinforcement learning. Can anyone please guide me?

Thanks!",5,8
39,2018-7-8,2018,7,8,19,8x0j1f,AI Weekly 8 July 2018,https://www.reddit.com/r/deeplearning/comments/8x0j1f/ai_weekly_8_july_2018/,TomekB,1531044616,,0,1
40,2018-7-9,2018,7,9,5,8x4g9q,Is it worth to invest myself in deep learning while being self taught?,https://www.reddit.com/r/deeplearning/comments/8x4g9q/is_it_worth_to_invest_myself_in_deep_learning/,AccidentalKing,1531081597, I'd like to know if I'd be able to do interesting stuff by myself ,6,3
41,2018-7-9,2018,7,9,6,8x4z59,[R] Few Shot Learning Using Human Robot Interaction,https://www.reddit.com/r/deeplearning/comments/8x4z59/r_few_shot_learning_using_human_robot_interaction/,mennasiam,1531085689,,0,6
42,2018-7-9,2018,7,9,7,8x5b1a,[P]Tell Me Where To Look ( Guided Attention Inference Network ),https://www.reddit.com/r/deeplearning/comments/8x5b1a/ptell_me_where_to_look_guided_attention_inference/,iamlordkurdleak,1531088351,,0,1
43,2018-7-9,2018,7,9,19,8xai4o,How I built a Self Flying Drone to track People in under 50 lines of code,https://www.reddit.com/r/deeplearning/comments/8xai4o/how_i_built_a_self_flying_drone_to_track_people/,nanonets,1531133799,,7,4
44,2018-7-9,2018,7,9,22,8xblxs,NN Model to classify straight vs bent objects,https://www.reddit.com/r/deeplearning/comments/8xblxs/nn_model_to_classify_straight_vs_bent_objects/,PontifexVorticis,1531143082,"Hi,
I'm new to NN modelling and try to build a simple model (using tensorflow) to classify images of objects into the two categories ""straight"" and ""bent"". All image pre-processing is done and I feed tensorflow with square greyscale images of a single centered object. They are either straight or bent, that is, have some deviation from being straight.
Please help me to build a simple model to learn this classification. Thanks :)",8,3
45,2018-7-10,2018,7,10,0,8xcnba,Deep Learning,https://www.reddit.com/r/deeplearning/comments/8xcnba/deep_learning/,var97,1531149838,"Hi Bloggers,

This post is fully dedicated to the concept of Deep Learning. It contains various topics like What is Deep Learning? How it is useful? How it all started? Etc.

If you know about this topic then you know How excited it is? and If you are new then I am sure that you will be excited till the end of this blog post.So Lets Get Started

It all begins around the 1960s, Many Researchers were working on Deep Learning models which later on brought the exceptional change in the field of AI &amp; Machine Learning, but what was the reason that it was not popular then and Currently, It is a most trending topic in the Industry.

**What is Deep Learning?** **Deep Learning can be defined as a subset of Machine Learning that contains various supervised and unsupervised models.** **These models basically try to mimic the nature of human brain and its capability to learn and understand complex things.**

While back then in the 1960s when the research was going on various Deep Learning models, the theories surrounding these models were theoretically fine but the processing power and data storage capacity which was required to train &amp; test those theories were seemed to be very costly &amp; unaffordable.

**In 1960s, 5 MB data storage device costs around 2500$ and requires an airplane to transport it from one place to another. **

And thats why the researches at that time were mostly on papers and didnt get that much popularity.

But as technological improvement takes place in the field of data storage and processing power, the more popularity were gain by these Deep Learning models because now we have sufficient storage &amp; processing power at affordable costs to train &amp; test these models and make further improvement in them.

Now we can train these Deep Learning models on cloud storage since various cloud storage service providers like Amazon Web Services(AWS), Crestle, Paperspace etc. are providing sufficient cloud storage &amp; processing power at affordable costs.

Nowadays Researchers are working on DNA storage which will help us to store data in our DNA. It currently costs around 7000$ to synthesize 2MB of data and another 2000$ to read it from DNA. Since it is quite costly to store data on DNA we can hope that as technological advancements are taking place it might be affordable &amp; efficient to use DNA Storage in coming years.

**The Basic requirement of any Deep Learning model is Good Processing Power.**

**More the processing power of the system, the better the Deep Learning model performs.**

* Currently, any 1000$ computer system can process at a speed of Rat Brain.
* It is estimated that around 2023-25 we will have systems that can process at the speed of a human brain.
* And around 2045-50 we might be able to surpass the human brain capabilities.

As technology is increasing day by day it is easier to train and test these Deep Learning models and apply them to real-world problems.

Many cutting-edge technologies are based on these deep learning models like Image Recognition, Speech Recognitions, Chabot, Recommendation Systems and many more.

I have done various projects in the field of Deep Learning and currently, I am working on Self Organizing Maps(Unsupervised Deep Learning Model) for Fraud Detection.

So stay tuned, In my next blog post, I will provide you with a detailed explanation on Deep Learning Models.

Your comments and feedbacks are valuable to us, so provide us with your thoughts on this topic??",0,0
46,2018-7-10,2018,7,10,0,8xct8x,Using Topological Data Analysis to Understand the Behavior and Learning Patterns of Neural Networks,https://www.reddit.com/r/deeplearning/comments/8xct8x/using_topological_data_analysis_to_understand_the/,jtsymonds,1531150831,,6,11
47,2018-7-10,2018,7,10,2,8xdxus,I need to discuss the implementation of ACGAN!,https://www.reddit.com/r/deeplearning/comments/8xdxus/i_need_to_discuss_the_implementation_of_acgan/,nile6499,1531157403,"If anyone has implemented ACGAN in any framework could comment? So I could ask a certain question.

Thanks",0,3
48,2018-7-10,2018,7,10,3,8xed3s,Deep Learning and Neural Networks,https://www.reddit.com/r/deeplearning/comments/8xed3s/deep_learning_and_neural_networks/,ATGhoul1212,1531159822,"Hi All, I have started with deep learning , i was not sure how to start so i just took one project of images and tried to run that , it worked fine after alterations but i do not have much idea about the code i copied from some link just to see how that works,How should i start further my journey with deep learning?",2,1
49,2018-7-10,2018,7,10,4,8xez0k,A dive into the deep end of deep neural networks for recommender engines.,https://www.reddit.com/r/deeplearning/comments/8xez0k/a_dive_into_the_deep_end_of_deep_neural_networks/,cptAwesome_070,1531163231,,0,1
50,2018-7-10,2018,7,10,4,8xf9p6,Why isn't relative error used in the cost function of linear regression instead of squared error?,https://www.reddit.com/r/deeplearning/comments/8xf9p6/why_isnt_relative_error_used_in_the_cost_function/,TheSexyDuckling,1531164920,"Say we have a housing prediction problem. Does it not make sense to penalize the algorithm based on how far the prediction is relative to the actual output?

For example,

House 1 actual = $200

House 2 actual = $1000

&amp;nbsp;

House 1 Predicted = $400

House 2 Predicted = $1200

&amp;nbsp;

In both cases, the predictions are off by $200 and hence the squared error would be the same. However, the relative percentages would be different. House 1 prediction will be off by 100% and House 2 by only 20%.

Is the cost function not better suited with a relative error?",10,8
51,2018-7-10,2018,7,10,9,8xidoz,How should I create a LSTM layer as library in C++?,https://www.reddit.com/r/deeplearning/comments/8xidoz/how_should_i_create_a_lstm_layer_as_library_in_c/,harshitprasad,1531182175,"Hi. I'm actually, working on a project in which I've to create a deep-learning library. Currently, I'm working on LSTM part. Now, it's a bit difficult to further proceed with layer design in C++. According to this paper: [https://arxiv.org/pdf/1503.04069.pdf](https://arxiv.org/pdf/1503.04069.pdf) I'm working on backpropagation feature. In my header file, I've to keep these two functions as it is:  


    /*! Back-propagates the error. Must only be called directly at the corresponding
     *  call to Forward(...). */ */
    Backward(Tensor_t &amp;gradients_backward, // B x T x D 
             const Tensor_t &amp;activations_backward, // B x T x D          
             std::vector&lt;Matrix_t&gt; &amp; /*inp1*/,          
             std::vector&lt;Matrix_t&gt; &amp; /*inp2*/) 
    
    /*! Backward for a single time unit
     *  a the corresponding call to Forward(...). */
    CellBackward(Matrix_t &amp; state_gradients_backward, 
                 const Matrix_t &amp; precStateActivations, 
                 const Matrix_t &amp; input, 
                 Matrix_t &amp; input_gradient)

How should I implement the feature keeping both the functions same? Note: In LSTM, we've to deal with 4 gates which implies - 8 different weight matrices, 4 bias vectors and gradient flow from each gate. (according to paper)  


It would be great if anyone can help me out. Thanks! :)",0,2
52,2018-7-10,2018,7,10,9,8xitk0,There is any paper about Universal Approximation Theorem?,https://www.reddit.com/r/deeplearning/comments/8xitk0/there_is_any_paper_about_universal_approximation/,curaai00,1531184393,I want to read it if there is.,1,3
53,2018-7-10,2018,7,10,10,8xiwtg,Machine for deep learning,https://www.reddit.com/r/deeplearning/comments/8xiwtg/machine_for_deep_learning/,jotalbs,1531184811,"Hey guys!   
I received a request to build a machine for deep learning to my lab and I cannot find the good parts for that, and I want to request a good setup out there to build this machine. 

I was thinking in something like 4x 1080TIs. Because we are going to order 2x now and 2x next 6 months (we don't have budget to order 4 now). 

Hope you guys can help me!

Thank you.",21,6
54,2018-7-10,2018,7,10,11,8xjv23,Definitely check this out.. Glow your skin by DL..,https://www.reddit.com/r/deeplearning/comments/8xjv23/definitely_check_this_out_glow_your_skin_by_dl/,prashant-kikani,1531189599,,0,9
55,2018-7-10,2018,7,10,12,8xkmdy,"Are you interested in Deep Learning and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/8xkmdy/are_you_interested_in_deep_learning_and_want_to/,DiscoverAI,1531193459,,0,1
56,2018-7-10,2018,7,10,19,8xnoi7,GAN  Ways to improve GAN performance,https://www.reddit.com/r/deeplearning/comments/8xnoi7/gan_ways_to_improve_gan_performance/,polllyyy,1531217826,,0,1
57,2018-7-10,2018,7,10,22,8xpb14,Converting Fortnite to PUBG using Cycle GANs,https://www.reddit.com/r/deeplearning/comments/8xpb14/converting_fortnite_to_pubg_using_cycle_gans/,Naughty_Nagaland,1531230741,https://github.com/bendangnuksung/fortnite-pubg,0,1
58,2018-7-10,2018,7,10,23,8xpegk,Converting Fortnite to PUBG using GANs,https://www.reddit.com/r/deeplearning/comments/8xpegk/converting_fortnite_to_pubg_using_gans/,Naughty_Nagaland,1531231369,,1,6
59,2018-7-11,2018,7,11,0,8xq44x,Is there any paper on using siamese network in unsupervised setting?,https://www.reddit.com/r/deeplearning/comments/8xq44x/is_there_any_paper_on_using_siamese_network_in/,Talos19,1531235910,,2,5
60,2018-7-11,2018,7,11,3,8xrvob,Ryzen Build for Machine/Deep Learning Experimentation,https://www.reddit.com/r/deeplearning/comments/8xrvob/ryzen_build_for_machinedeep_learning/,rubycowgames,1531246828,"I'm planning a Ryzen 7 2700X + 1080ti build for machine / deep learning.

Been spending time with machine learning for work and as a hobby, primarily burning through Paperspace credits/cash and now at a point where it makes sense to build my own workstation.

[PCPartPicker part list](https://pcpartpicker.com/list/BJNmxG) / [Price breakdown by merchant](https://pcpartpicker.com/list/BJNmxG/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [AMD - Ryzen 7 2700X 3.7GHz 8-Core Processor](https://pcpartpicker.com/product/bddxFT/amd-ryzen-7-2700x-37ghz-8-core-processor-yd270xbgafbox) | $309.90 @ SuperBiiz 
**CPU Cooler** | [Scythe - Mugen 5 Rev. B 51.2 CFM CPU Cooler](https://pcpartpicker.com/product/8GBrxr/scythe-mugen-5-rev-b-512-cfm-cpu-cooler-scmg-5100) | $47.99 @ Newegg Marketplace 
**Motherboard** | [Asus - Prime X470-Pro ATX AM4 Motherboard](https://pcpartpicker.com/product/6hF48d/asus-prime-x470-pro-atx-am4-motherboard-prime-x470-pro) | $164.89 @ OutletPC 
**Memory** | [G.Skill - Trident Z 16GB (2 x 8GB) DDR4-3200 Memory](https://pcpartpicker.com/product/4n648d/gskill-tridentz-series-16gb-2-x-8gb-ddr4-3200-memory-f4-3200c16d-16gtzkw) | $164.99 @ Newegg 
**Memory** | [G.Skill - Trident Z 16GB (2 x 8GB) DDR4-3200 Memory](https://pcpartpicker.com/product/4n648d/gskill-tridentz-series-16gb-2-x-8gb-ddr4-3200-memory-f4-3200c16d-16gtzkw) | $164.99 @ Newegg 
**Storage** | [Samsung - 970 Evo 500GB M.2-2280 Solid State Drive](https://pcpartpicker.com/product/P4ZFf7/samsung-970-evo-500gb-m2-2280-solid-state-drive-mz-v7e500bw) | $196.99 @ Amazon 
**Storage** | [Seagate - Barracuda 3TB 3.5"" 7200RPM Internal Hard Drive](https://pcpartpicker.com/product/gwBv6h/seagate-internal-hard-drive-st3000dm001) | $72.09 @ Newegg Marketplace 
**Video Card** | [EVGA - GeForce GTX 1080 Ti 11GB FTW3 GAMING iCX Video Card](https://pcpartpicker.com/product/KBtWGX/evga-geforce-gtx-1080-ti-11gb-ftw-gaming-icx-video-card-11g-p4-6696-kr) | $799.99 @ Amazon 
**Case** | [Fractal Design - Define R6 Black TG ATX Mid Tower Case](https://pcpartpicker.com/product/n297YJ/fractal-design-define-r6-black-tg-atx-mid-tower-case-fd-ca-def-r6-bk-tg) | $109.99 @ Newegg 
**Power Supply** | [EVGA - SuperNOVA G3 750W 80+ Gold Certified Fully-Modular ATX Power Supply](https://pcpartpicker.com/product/dMM323/evga-supernova-g3-750w-80-gold-certified-fully-modular-atx-power-supply-220-g3-0750) | $69.88 @ OutletPC 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | Total (before mail-in rebates) | $2121.70
 | Mail-in rebates | -$20.00
 | **Total** | **$2101.70**
 | Generated by [PCPartPicker](https://pcpartpicker.com) 2018-07-10 14:19 EDT-0400 |

Anyone have experience with a Ryzen 7 build? Anything I should be looking out for or modifying build wise?",12,9
61,2018-7-11,2018,7,11,8,8xunaw,Neural Networks and Deep Learning the online book,https://www.reddit.com/r/deeplearning/comments/8xunaw/neural_networks_and_deep_learning_the_online_book/,mori226,1531267046,"I'm a complete newb...that is fascinated by computer science and deep learning. I've been reading the above online book by Michael Nielsen. Can someone please explain what exactly Michael is referring to in the first chapter when he says:

""The design of the input and output layers in a network is often straightforward. For example, suppose we're trying to determine whether a handwritten image depicts a ""9"" or not.   A natural way to design the network is to **encode the intensities of the image pixels into the input neurons**.  If the image is a 64 by 64 greyscale image, then we'd have 4,096=6464 input neurons, **with the intensities scaled appropriately between 0 and 1**.""

I'm confused with the highlighted parts. What does ""encode the intensities of the image pixels into the input neurons"" mean? How do you accomplish this? Also, how does the intensity of the greyscale get set? 

Any clarification would be greatly appreciated. This is fascinating to read and learn!",7,7
62,2018-7-11,2018,7,11,11,8xvwod,"Are you interested in Computer Science and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/8xvwod/are_you_interested_in_computer_science_and_want/,DiscoverAI,1531277596,,1,0
63,2018-7-11,2018,7,11,17,8xxxbo,Churn prediction with variational auto-encoder,https://www.reddit.com/r/deeplearning/comments/8xxxbo/churn_prediction_with_variational_autoencoder/,naomi_fridman,1531298934,,1,8
64,2018-7-11,2018,7,11,18,8xy1uc,Practical Deep Learning with Keras and Python,https://www.reddit.com/r/deeplearning/comments/8xy1uc/practical_deep_learning_with_keras_and_python/,_john_alex,1531300483,[removed],0,1
65,2018-7-11,2018,7,11,18,8xy5xz,Practical Deep Learning with Keras and Python,https://www.reddit.com/r/deeplearning/comments/8xy5xz/practical_deep_learning_with_keras_and_python/,Sampada_cutiee,1531301846,,0,1
66,2018-7-12,2018,7,12,0,8y0hsx,Instructions for using GPU Cluster,https://www.reddit.com/r/deeplearning/comments/8y0hsx/instructions_for_using_gpu_cluster/,arjundupa,1531322585,"I've been trying to use my university's GPU cluster.

I log in using ssh in Terminal, and then type ""qsub -I -l nodes=nano7:ppn=1:gpus=1,walltime=3600"" 

I get the following as the output:

`qsub: waiting for job 14540.nano to start`

`qsub: job 14540.nano ready`

`Prologue Args:`

`Job ID: 14540.nano`

`User ID: arjung2`

`Group ID: grp_202`

`---------------------------`

`Copyright (C) 2009-2016 Intel Corporation. All rights reserved.`

`Intel(R) Inspector XE 2016 (build 450824)`

`Copyright (C) 2009-2015 Intel Corporation. All rights reserved.`

`Intel(R) VTune(TM) Amplifier XE 2016 (build 444464)`

`Copyright (C) 2009-2016 Intel Corporation. All rights reserved.`

`Intel(R) Advisor XE 2016 (build 450722)`

I get stuck at this point. How can I proceed from here?

Where should I store the files I want to run on the GPU and what is the command for running them? Is there a way I can run a Jupyter (iPython) notebook on it?

If it helps, here's the very brief bit of documentation they've provided: [https://wiki.ncsa.illinois.edu/display/ISL20/Nano+cluster](https://wiki.ncsa.illinois.edu/display/ISL20/Nano+cluster)

Any help will be much appreciated. Thanks!",0,0
67,2018-7-12,2018,7,12,12,8y6bz6,ResourceExhaustedError on GPU,https://www.reddit.com/r/deeplearning/comments/8y6bz6/resourceexhaustederror_on_gpu/,arjundupa,1531366764,"I've been trying to train a Siamese Network on a V100 with 15.36 GB of RAM. My model doesn't seem to be one that would be extremely computationally expensive:

`# create model`

`input_shape = (250, 250, 3)`

`left_input = Input(input_shape)`

`right_input = Input(input_shape)`

`# convnet for each siamese leg`

`convnet = Sequential()`

`convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape))`

`convnet.add(MaxPooling2D())`

`convnet.add(Conv2D(128,(7,7),activation='relu', kernel_regularizer=l2(2e-4)))`

`convnet.add(MaxPooling2D())`

`convnet.add(Conv2D(128,(4,4),activation='relu',kernel_regularizer=l2(2e-4)))`

`convnet.add(MaxPooling2D())`

`convnet.add(Conv2D(256,(4,4),activation='relu',kernel_regularizer=l2(2e-4)))`

`convnet.add(Flatten())`

`convnet.add(Dense(4096,activation=""sigmoid"",kernel_regularizer=l2(1e-3)))`

`# call the convnet Sequential model on each of the input tensors so params will be shared`

`encoded_l = convnet(left_input)`

`encoded_r = convnet(right_input)`

`# layer to merge two encoded inputs with the l1 distance between them`

`L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))`

`L1_distance = L1_layer([encoded_l, encoded_r])`

`prediction = Dense(1,activation='sigmoid')(L1_distance)`

`siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)`

`siamese_net.compile(loss=""binary_crossentropy"", optimizer=Adam(0.00006)`

The weird thing is that when I run it with a batch size of 1, I get a ResourceExhaustedError with a tensor of shape\[147456,4096\] -- 147456 = (384)\^2, and 384 = 128 + 256 where 128 and 256 are the number of filters in the last two layers of my convnet. I am using the LFW faces dataset where each image is 250 x 250 in dimension.

Also, I trained this on my CPU, with a batch size of 16, and though it took an hour for one epoch, trained perfectly fine (with the loss decreasing when I trained on multiple epochs).

Any help will be much appreciated. Thanks!",7,5
68,2018-7-12,2018,7,12,18,8y88g8,Seemingly simple task for RNNs,https://www.reddit.com/r/deeplearning/comments/8y88g8/seemingly_simple_task_for_rnns/,captain_foo,1531387968,"I was experimenting with memorization capabilities of LSTMs and tried to train a model to do a simple task. Let's say we have a sequence of two numbers. The first number can only take values of 0 and 1. Depending on the value of the first number the model has to either remember the second number or check if the number has already been remembered. In case it was not, the predicted value should be 1, in all other cases the model should predict 0. For example:

|First Number|Second Number|Prediction|
|:-|:-|:-|
|0|393|0|
|0|728|0|
|0|281|0|
|0|136|0|
|0|254|0|
|1|224|1|
|1|947|1|
|0|323|0|
|1|323|0|
|0|133|0|

I could not get the LSTMs to work for this task, I tried Differentiable Neural Computer architecture, but it also doesn't seem to work. Am I doing something wrong? Any suggestions are appreciated.",7,2
69,2018-7-12,2018,7,12,22,8ya05g,Fast.ai - Part 1 - Lesson 1 - Annotated notes,https://www.reddit.com/r/deeplearning/comments/8ya05g/fastai_part_1_lesson_1_annotated_notes/,janvandepoel,1531403969,,0,9
70,2018-7-13,2018,7,13,5,8ydb38,"Building a strategy of creating Artificial Consciousness, from the a Please Help :)",https://www.reddit.com/r/deeplearning/comments/8ydb38/building_a_strategy_of_creating_artificial/,Polycapn,1531426646,"This post is meant for an objective discussion on providing useful suggestions on building a strategy of realizing the vision I set forth. We can table the discussion of the feasibility of such an approach for a later time:) 

I have been working on a algorithm that in theory would give rise to the much sort after missing like to building true Artificial Intelligence. I believe Consciousness preceded Intelligence. And so I set forth to create the algorithm below. 

[186 Algorithm](https://i.redd.it/zg96lvsgek911.jpg)

It's modeled on the human body and the repeating hierarchical structures found within it. You can see and read my evolving thought process on the subject on my [medium](https://medium.com/@polycapn/polyocracys-architecture-v-001-69a2854c6368) and [youtube channel.](https://www.youtube.com/channel/UCtWHlqEPs7nE3daPuKhpGsw) But we aren't here for that. 

What I'm here for is to translate what the above algorithm means to you so you can help me figure out a strategy of building it. Let's get started. 

*Processing img bp82kxsrhk911...*

Levels 1 - 6 are supposed to represent the six hierarchies of complex systems. Below is the the way these hierarchies correspond to known regions of the human brain.   
*Level I* \- **Neuron** 

*Level II* \- **Neural Tissue** 

*Level III* \- **Specialized Lobes** 

**(frontal lobe (***TBD***), parietal lobe (***TBD***), occipital lobe (**image processing**), and temporal lobe (***Natural language processing etc.***))**

*Level IV* \- **Hemispheres (Unified Brain)**

*Level V* \-  **User**

*Level VI* \- **Environment**

(*NOTE: The sixth level represents the environment, but we aren't concerned with that just yet)* 

[six hierarchies of complex systems](https://i.redd.it/ivw5s9bvdk911.png)

The neural network below is a simplified example of neural net. This represents the first two Level 1 &amp; 2 (Neuron &amp; Neuron Tissues *respectively*). Much more complicated neural nets create image processors and natural language processors (*Level 3)* 

(*NOTE: Neurons also have the same repeating hierarchical structure.*)

*Processing img wuhhcaisdk911...*

**The Ask**

Hopefully I didn't lose you in my attempt to communicate a much much much simplified version of what I have been working on. Nonetheless, I need help with three simple things :) (*might not be so simple lol*): 

1. **A strategy to turn this algorithm into python code (*****or any other suitable language for building neural nets*****)**

***Level I*** 

1. `To create first circle`
   1. `Go to the center` 
   2. `If first circle then`

* `Use standard radius of 1`

1. `Else` 

* `Use radius of new circle = Diameter of smaller circle`

1. `To create consequent circles`
   1. `Start center at the point of tangent of the initial circle`
   2. `Connect point of tangent for new circle with the center of initial circle`

The above algorithm creates the chain of circles on Level I, reference image below

[Reference 2 ](https://i.redd.it/vf4ho44nok911.png)

***Level II***

1. `To create first circle`
   1. `Go to the center` 
   2. `Radius of new circle = Diameter of Level I circle`
2. `To create consequent circles`
   1. `Start center at the point of tangent of the initial circle`
   2. `Connect point of tangent for new circle with the center of initial circle`

***Level III***

1. `To create first circle`
   1. `Go to the center` 
   2. `Radius of new circle = Diameter of Level II circle`
2. `To create consequent circles`
   1. `Start center at the point of tangent of the initial circle`
   2. `Connect point of tangent for new circle with the center of initial circle`

***Level IV***

1. `To Create first  Circle`
   1. `Go to the middle point of the vesica piscis (mandorla) between 2 Level II circles`
   2. `Connect the point of tangent for new circle with point of tangent at the end of chain`
2. `To create consequent circles`
   1. `Go to the middle point of the other vesica piscis (mandorla) between 2 Level II circles`
   2. `Connect the point of tangent for new circle with point of tangent at the opposite end of chain`

***Level V***

1. `Create last Circle`
   1. `Go to center`
   2. `Connect point of tangent for new circle with the end of whole chain`
      1. `The diameter should encompass whole chain` 

***Level VI***

1. `Everything outside Circle is the environment`
2. `Can link more Level V circles together`

2. **How can I combine above algorithm with the activation function of a neuron ?**  
(*reference image below*)

[Neuron Activation Function](https://i.redd.it/s3tl6gvqpk911.jpg)

  
3.  ***Last but not least: How can I combine all these into a neural network that can do something simple as classified an image ?***

***In conclusion***

I know what I'm asking for sounds impossible, but I'd love you to help out a fellow human who's bored and has alot of time on his hands :) After all, *if* *there's even a one* percent *chance* that I'm on the right path, I'm taking it as an absolute, and rolling with it for the upsides are too great to simply ignore such an insight.   


I'm available for questions, clarifications and even collaborations. Let me know what you think, any objective suggestion will help. I'll always give credit where it's due   


In the meantime, Have a fantastic day, stay woke and awesome, looking forward towards making the world a better place :)",13,4
71,2018-7-13,2018,7,13,10,8yfnav,Trained models able to recreate data,https://www.reddit.com/r/deeplearning/comments/8yfnav/trained_models_able_to_recreate_data/,BrosephBSJ2LC,1531444819,"Hello

I was wondering if there has been any research, papers, or other materials on the notion of a trained deep learning model's ability to recreate the training data? This was brought up to me a while ago, but have not had any luck finding any material to substantiate it.

Thanks in advance",5,6
72,2018-7-13,2018,7,13,15,8yhr7q,OCR of Handwritten text using deep learning,https://www.reddit.com/r/deeplearning/comments/8yhr7q/ocr_of_handwritten_text_using_deep_learning/,taniya63,1531464780,Extracting handwritten text from the invoices pdf and getting the important information. How can i solve this?,5,7
73,2018-7-13,2018,7,13,18,8yigdh,Neural Networks in MySQL,https://www.reddit.com/r/deeplearning/comments/8yigdh/neural_networks_in_mysql/,itdxer,1531473200,,0,6
74,2018-7-13,2018,7,13,18,8yin4r,Using Deep Learning to Estimate Coffee Harvest Yields,https://www.reddit.com/r/deeplearning/comments/8yin4r/using_deep_learning_to_estimate_coffee_harvest/,magneticono,1531475437,,0,1
75,2018-7-13,2018,7,13,18,8yinkf,fast.ai Deep Learning Part 1 Complete Course Notes,https://www.reddit.com/r/deeplearning/comments/8yinkf/fastai_deep_learning_part_1_complete_course_notes/,friscotime,1531475570,,0,1
76,2018-7-13,2018,7,13,19,8yiwni,Deep Learning: Predicting hard disks failures using recurrent LSTM network,https://www.reddit.com/r/deeplearning/comments/8yiwni/deep_learning_predicting_hard_disks_failures/,magneticono,1531478456,,0,1
77,2018-7-13,2018,7,13,20,8yj2ub,Output of Conv2dTranspose Layer,https://www.reddit.com/r/deeplearning/comments/8yj2ub/output_of_conv2dtranspose_layer/,arjundupa,1531480376,"I've been trying to implement a GAN, and need to know how to calculate the output dimensions for each Conv2DTranspose layer to make sure that the output of my generator has the dimensions of my image dataset. Here's my generator:

`input_shape = (100, 1, 1)`

`generator = Sequential()`

`generator.add(Conv2DTranspose(64,(5,5),strides=(2,2),activation='relu',input_shape=input_shape))` 

`generator.add(BatchNormalization())`

`generator.add(Conv2DTranspose(128,(5,5),strides=(2,2),activation='relu',input_shape=input_shape))` 

`generator.add(BatchNormalization())`

`generator.add(Conv2DTranspose(256,(5,5),strides=(2,2),activation='relu',input_shape=input_shape))` 

`generator.add(BatchNormalization())`

`generator.add(Conv2DTranspose(512,(5,5),strides=(2,2),activation='relu',input_shape=input_shape))`

`generator.add(BatchNormalization())`

If what I'm asking is unclear, here's my discriminator with the output layer dimensions:

`img_shape = (250, 250, 3)`

`discriminator = Sequential()`

`discriminator.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape)) # 64x241x241 --&gt; 64x120x120`

`discriminator.add(MaxPooling2D())`

`discriminator.add(Conv2D(128,(7,7),activation='relu', kernel_regularizer=l2(2e-4))) # 128x114x114 --&gt; 128x57x57`

`discriminator.add(MaxPooling2D())`

`discriminator.add(Conv2D(256,(4,4),activation='relu',kernel_regularizer=l2(2e-4))) # 256x54x54 --&gt; 256x27x27` 

`discriminator.add(MaxPooling2D())`

`discriminator.add(Conv2D(512,(7,7),activation='relu',kernel_regularizer=l2(2e-4))) # 512x21x21 --&gt; 512x10x10`

`discriminator.add(MaxPooling2D())`

`discriminator.add(Conv2D(1024,(10,10),activation='relu')) # 1024x1x1`

`discriminator.add(Flatten()) # (None, 1024)`

`discriminator.add(Dense(1,activation=""sigmoid"",kernel_regularizer=l2(1e-3))) # (None, 1)`

Any help will be much appreciated. Thanks!",0,1
78,2018-7-14,2018,7,14,2,8ym1ps,"Do you have to know CNNs, RNNs and GANs before you read about reinforcement learning?",https://www.reddit.com/r/deeplearning/comments/8ym1ps/do_you_have_to_know_cnns_rnns_and_gans_before_you/,ASamir,1531503595,Just asking if I could skip those 3 modules in the deep learning nanodegree for now and hop on the Deep RL.. ,11,9
79,2018-7-14,2018,7,14,3,8ymbj9,How to scale the machine learning community to 1 Million researchers,https://www.reddit.com/r/deeplearning/comments/8ymbj9/how_to_scale_the_machine_learning_community_to_1/,mostafabenh,1531505509,,0,0
80,2018-7-14,2018,7,14,5,8ynke1,MS-SSIM loss function implementation in Tensorflow.,https://www.reddit.com/r/deeplearning/comments/8ynke1/msssim_loss_function_implementation_in_tensorflow/,utkarshverma,1531514311,"I'm working on a deep learning problem where I want to increase the perceptual quality of images. I'm thinking of taking MS-SSIM as the loss function. I'm writing the code in Tensorflow. Athough they have an inbuilt function for it called `tf.nn.ssim_multiscale( )`, I'm getting some error. If anyone has used this loss function, please guide me through it. Thanks!",1,2
81,2018-7-14,2018,7,14,14,8yqvy8,Dataset creation with an indian data,https://www.reddit.com/r/deeplearning/comments/8yqvy8/dataset_creation_with_an_indian_data/,sujitrrai,1531544471,I would like to create a dataset which contains images and text related to some indian context. Please provide some suggestions.,3,1
82,2018-7-14,2018,7,14,14,8yqzl8,What Artificial Intelligence Has Taught Us,https://www.reddit.com/r/deeplearning/comments/8yqzl8/what_artificial_intelligence_has_taught_us/,harshMachineLearning,1531545586,"Hi. I have uploaded a video about ""What Artificial Intelligence Has Taught Us"". It is about the message that the search for AI is giving is and what we can learn about ourselves from it. 

Do check it out!

[https://www.youtube.com/watch?v=oTxbbLI4Yho&amp;t=52s](https://www.youtube.com/watch?v=oTxbbLI4Yho&amp;t=52s)",0,0
83,2018-7-14,2018,7,14,17,8yrz9l,Why processed data take more training time?,https://www.reddit.com/r/deeplearning/comments/8yrz9l/why_processed_data_take_more_training_time/,emissary_of_death,1531558575,"I have been working on a image classifier. So I tried to see the difference between unprocessed vs processed image and saw unprocessed images take lesser time to train. Can anyone explain to me why is that?

P.S- By processed image, I mean cropping, threshold, Gaussian blurring etc.",2,0
84,2018-7-14,2018,7,14,18,8ys24t,Deep Learning Is a Blessing to Police for Crime Investigations | Analytics Insight,https://www.reddit.com/r/deeplearning/comments/8ys24t/deep_learning_is_a_blessing_to_police_for_crime/,analyticsinsight,1531559692,,2,0
85,2018-7-14,2018,7,14,20,8yso1q,Deep Learning - Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/8yso1q/deep_learning_learn_recurrent_neural_networks_in/,algbra,1531568126,,0,5
86,2018-7-15,2018,7,15,8,8yxc1t,Training on random labels,https://www.reddit.com/r/deeplearning/comments/8yxc1t/training_on_random_labels/,gntc,1531610154,A friend of mine mentioned to me that training a CNN on ImageNet images with randomized labels has yielded filters that resemble the Gabor filters.  I'm having trouble finding any literature that supports this.  Does anyone know of anything?,1,4
87,2018-7-15,2018,7,15,19,8z0pm8,Resources to make Hand Gesture recognition using Deep learning and Arduino.,https://www.reddit.com/r/deeplearning/comments/8z0pm8/resources_to_make_hand_gesture_recognition_using/,amit2rockon,1531648938,"Please provide relevant link to the give topic .

You may also put  your own views here.",3,5
88,2018-7-16,2018,7,16,11,8z7dud,"Are you interested in Computer Science and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/8z7dud/are_you_interested_in_computer_science_and_want/,DiscoverAI,1531709659,,0,2
89,2018-7-16,2018,7,16,13,8z7wca,Keras Custom Loss Function,https://www.reddit.com/r/deeplearning/comments/8z7wca/keras_custom_loss_function/,arjundupa,1531714564,"I used the contrastive\_loss function implementation at [https://github.com/keras-team/keras/blob/master/examples/mnist\_siamese.py](https://github.com/keras-team/keras/blob/master/examples/mnist_siamese.py) in my own Siamese network -- oddly, while the loss displayed by Keras after each epoch decreased significantly, the results of the trained network on both the training set and the testing set showed that the neural network neither learned nor overfitted. 

I changed my loss function to binary\_crossentropy -- just as before, the loss displayed by Keras after each epoch decreased significantly, but this time, the results of the trained network on both the training set and the testing set showed that the neural network clearly learned and did not overfit. 

Any ideas for what I may be doing wrongly?

Any help will be much appreciated. Thanks!",2,3
90,2018-7-16,2018,7,16,17,8z99bv,AI Weekly 16 July 2018,https://www.reddit.com/r/deeplearning/comments/8z99bv/ai_weekly_16_july_2018/,TomekB,1531730416,,0,1
91,2018-7-17,2018,7,17,1,8zc9jg,Sequencing the DNA of Real Estate: An AI-Driven Approach for Comparing Assets,https://www.reddit.com/r/deeplearning/comments/8zc9jg/sequencing_the_dna_of_real_estate_an_aidriven/,_orcaman_,1531758039,,0,1
92,2018-7-17,2018,7,17,2,8zd0th,A beginner's guide to deriving and implementing backpropagation,https://www.reddit.com/r/deeplearning/comments/8zd0th/a_beginners_guide_to_deriving_and_implementing/,prnvb,1531763100,,0,9
93,2018-7-17,2018,7,17,14,8zieay,Virtual Reality / Augmented Reality Ecosystem,https://www.reddit.com/r/deeplearning/comments/8zieay/virtual_reality_augmented_reality_ecosystem/,seoaleait,1531804668,,2,3
94,2018-7-17,2018,7,17,20,8zk6vt,Need Help: How to train the neural network to replicate the Set data structure?,https://www.reddit.com/r/deeplearning/comments/8zk6vt/need_help_how_to_train_the_neural_network_to/,captain_foo,1531825520,"I want to train a recurrent neural network to replicate the functionality of a Set data structure. Specifically two methods: add(value) and contains(value). I thought the best architecture for this task to be the differentiable neural computer by Deepmind. I have tried to encode the training data in many different ways, but none of them has worked so far. Essentially my training data is a sequence of commands (add or contains) along with the value to be added or checked for existense. If the command is contains() and the value has appeared before in the sequence as a part of a save command, then the RNN should predict 1, in all other cases 0. I have tried one-hot encoding both the command and the value. Also I have tried to put the value in a time-step next to the command. I cannot get the loss to be near-zero, at some point the network starts to overfit the training data and the dev-set error goes up. Which means it hasn't really learned to behave like a set. I make sure to have a big enough memory allocated for the DNC.

Training / Dev data sizes are 10K / 1K respectively, but can be any arbitrary value.

An example of the training data is below:

    # the data is a sequence of command blocks of the format:
    # [[&lt;command&gt; 0      ]
    #  [0         &lt;value&gt;]]
    # 
    # command
    #  0 == save() 
    #  1 == contains()
    
    Input: 
    tensor([[ 0.,  0.], # save          output: 0
            [ 0.,  2.], # value of 2    output: 0
            [ 1.,  0.], # contains      output: 0
            [ 0.,  2.], # value of 2    output: 1
            [ 0.,  0.], # save          output: 0
            [ 0., 13.], # value of 13   output: 0
            [ 1.,  0.], # contains      output: 0
            [ 0.,  1.], # value of 1    output: 0
            [ 1.,  0.], # contains      output: 0
            [ 0.,  2.], # value of 2    output: 1
            [ 1.,  0.], # contains      output: 0
            [ 0.,  2.]],# value of 2    output: 1
    device='cuda:0')

Any suggestions on why the DNC cannot learn this task / what could be the problem?",2,3
95,2018-7-17,2018,7,17,20,8zk7l8,Beginners Ask How Many Hidden Layers/Neurons to Use in Artificial Neural Networks?,https://www.reddit.com/r/deeplearning/comments/8zk7l8/beginners_ask_how_many_hidden_layersneurons_to/,molode,1531825718,,0,1
96,2018-7-17,2018,7,17,21,8zkvzv,Simple neural network on iris data (from Andrew Ng's course),https://www.reddit.com/r/deeplearning/comments/8zkvzv/simple_neural_network_on_iris_data_from_andrew/,rohan_joseph93,1531832195,,0,2
97,2018-7-17,2018,7,17,22,8zlabv,Quick guide to understand the hype around deep learning,https://www.reddit.com/r/deeplearning/comments/8zlabv/quick_guide_to_understand_the_hype_around_deep/,ANNA_Systems,1531835448,,0,3
98,2018-7-17,2018,7,17,23,8zlkhs,Text Classification Models in TensorFlow,https://www.reddit.com/r/deeplearning/comments/8zlkhs/text_classification_models_in_tensorflow/,ganji1055,1531837565,"Implemented famous text classification models in TensorFlow: [https://github.com/dongjun-Lee/text-classification-models-tf](https://github.com/dongjun-Lee/text-classification-models-tf)

Implemented models are 1) Word-level CNN, 2) Character-level CNN 3) VDCNN(Very Deep CNN) 4) Word-level Bidirectional RNN 5) Attention-based Bidirectional RNN, 6) RCNN  


Semi-supervised Learning for Text Classification(Transfer Learning) is implemented at: [https://github.com/dongjun-Lee/transfer-learning-text-tf](https://github.com/dongjun-Lee/transfer-learning-text-tf)

Here, auto-encoder or language model is used as a pre-trained model to initialize LSTM text classification model. 

I hope it helps! Thanks!",0,18
99,2018-7-18,2018,7,18,13,8zseag,"For any Data scientists / machine engineers on here, IBM is looking to pay $100 for a short interview with you if you are able to describe the Deep Learing workflow w/ the tools involved",https://www.reddit.com/r/deeplearning/comments/8zseag/for_any_data_scientists_machine_engineers_on_here/,Momordicas,1531888755,"Description from Respondent's website (the company they are using to source people for these interviews):

"" We at IBM would like to better understand the different stages of work involved with Deep Learning and what tools are used throughout the entire process. We welcome Data Scientists / Machine Learning Engineers that are savvy with the end to end process of deep learning. ""

I've used Respondent before, and its all pretty straight forward. They pay through paypal after the interview. Let me know if you have any questions!

Link to interview: [https://app.respondent.io/projects/view/5b4eb886c00db10023e78964/seeking-data-scientists-who-can-describe-the-deep-learing-workflow-w-the-tools-involved/brianroy-4abcac313e7a](https://app.respondent.io/projects/view/5b4eb886c00db10023e78964/seeking-data-scientists-who-can-describe-the-deep-learing-workflow-w-the-tools-involved/brianroy-4abcac313e7a)

(Referral link btw, in case that matters to anybody)",0,11
100,2018-7-19,2018,7,19,1,8zx4ca,Build TensorFlow from source on Docker,https://www.reddit.com/r/deeplearning/comments/8zx4ca/build_tensorflow_from_source_on_docker/,nkalavak,1531932211,"I am looking to build TensorFlow 1.8 from source for Ubuntu 16.04 and CUDA 9.0 to run [PoseCNN](https://github.com/yuxng/PoseCNN).  I am however unable to find a good way to do it. I have built a docker  image with Ubuntu 16.04, CUDA 9.0 and cuDNN 7.0.5. Any suggestions on  how to get started on building TF from source or available resources  will be very helpful.

Also posted on r/Dockerfiles",0,2
101,2018-7-19,2018,7,19,4,8zyqtb,Hyperparameter optimization for Neural Networks,https://www.reddit.com/r/deeplearning/comments/8zyqtb/hyperparameter_optimization_for_neural_networks/,itdxer,1531943121,,1,8
102,2018-7-19,2018,7,19,9,900ura,"Are you interested in Deep Learning and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/900ura/are_you_interested_in_deep_learning_and_want_to/,DiscoverAI,1531958971,,1,4
103,2018-7-19,2018,7,19,9,9015cl,GAN for Faces,https://www.reddit.com/r/deeplearning/comments/9015cl/gan_for_faces/,arjundupa,1531961350,"I've been working on a GAN for Faces using the LFW dataset, but can't seem to get any results -- all of my outputs are images of one color (black, purple, or green so far) and the discriminator's prediction for all these outputs is 0.5. Clearly, I'm doing something wrong, but I can't figure it out. 

Here's my code: 

[https://github.com/arjung128/deep-learning-experiments/blob/master/FaceGAN.ipynb](https://github.com/arjung128/deep-learning-experiments/blob/master/FaceGAN.ipynb)

Any ideas?

Any help will be much appreciated. Thanks!",1,2
104,2018-7-19,2018,7,19,16,903tan,Masters' thesis research topic in NLP QA system,https://www.reddit.com/r/deeplearning/comments/903tan/masters_thesis_research_topic_in_nlp_qa_system/,anis016,1531986224,"Hello

I have started my Masters' thesis and I am searching for research topics in the area of Deep Learning for NLP. I am interested in exploring the Question and Answering system or other topics which have the available datasets. I would like to work on Attention mechanisms. Can someone please suggest good research topics in this?

Thank you",2,3
105,2018-7-19,2018,7,19,20,9055j1,Embedded Hardware for Deep Learning,https://www.reddit.com/r/deeplearning/comments/9055j1/embedded_hardware_for_deep_learning/,whiletrue2,1532001012,"Hi,

I am currently looking into embedded hardware that allows to run DNNs on them, preferably with support of state-of-the-art frameworks such as TensorFlow, Caffe2 etc..

In particular, I am interested in alternatives to NVIDIA's embedded platforms (e.g. Jetson modules). So far, I have found the following suppliers:

[1] Xlinix, https://www.xilinx.com/applications/megatrends/machine-learning.html

[2] Renesas, http://renesasatces.com/renesas-r-car-v3m-starter-kit/

Do you know of any other suppliers?",4,2
106,2018-7-19,2018,7,19,21,905856,convert video data (eg. .avi) to TensorFlow's tfrecords file format,https://www.reddit.com/r/deeplearning/comments/905856/convert_video_data_eg_avi_to_tensorflows/,whiletrue2,1532001708,,0,6
107,2018-7-19,2018,7,19,21,905aou,Generalization and unwanted Generalization in Deep Neural Network,https://www.reddit.com/r/deeplearning/comments/905aou/generalization_and_unwanted_generalization_in/,dataCamper,1532002336,"Recently, when working with LSTMs for sequence classification, I came across a query from a professor, he said How will you ensure that your model is actually learning and not just brute force memorizing and also how will you know if it has unwanted Generalization?. Now I was able to answer the first one with empirical results but I found it hard to answer the second one as I dont understand what unwanted Generalization is ? Or what it even means.",4,7
108,2018-7-19,2018,7,19,21,905bb7,"Toy dataset for deep learning (planar manipulation task, available as .avi and .tfrecord)",https://www.reddit.com/r/deeplearning/comments/905bb7/toy_dataset_for_deep_learning_planar_manipulation/,whiletrue2,1532002495,,0,2
109,2018-7-20,2018,7,20,1,907go6,"If you want to go from zero to Deep Learning in 5 days, check out this bootcamp that just launched! 5 star yelp reviews, great value. 17-21 Sept in SF!",https://www.reddit.com/r/deeplearning/comments/907go6/if_you_want_to_go_from_zero_to_deep_learning_in_5/,cbbell,1532018441,,1,0
110,2018-7-20,2018,7,20,4,908qre,CERN: Finding Elusive Particles With Deep Learning,https://www.reddit.com/r/deeplearning/comments/908qre/cern_finding_elusive_particles_with_deep_learning/,corlinp,1532027062,,2,5
111,2018-7-20,2018,7,20,5,9099hg,"Question to everyone, how do you approach a paper whose implementation code is not made public, and you need to implement the paper from scratch.",https://www.reddit.com/r/deeplearning/comments/9099hg/question_to_everyone_how_do_you_approach_a_paper/,nile6499,1532030751,"I have implemented only 2-3 papers but they were new loss function or technique, but never did any thing from 0.

***One-shot learning with Augmented memory*** is the paper I need to implement, [https://arxiv.org/pdf/1605.06065.pdf](https://arxiv.org/pdf/1605.06065.pdf) 

How should one approach when implementing papers with unreleased code? Kindly share experience (Please no bullshiting, be precise as much as possible)",6,10
112,2018-7-20,2018,7,20,18,90egg2,Best (and Free!!) Resources to Understand Nuts and Bolts of Deep Learning,https://www.reddit.com/r/deeplearning/comments/90egg2/best_and_free_resources_to_understand_nuts_and/,dearpetra,1532077853,,0,1
113,2018-7-20,2018,7,20,19,90evim,Autopsy of a deep learning paper,https://www.reddit.com/r/deeplearning/comments/90evim/autopsy_of_a_deep_learning_paper/,moravak,1532082833,,3,9
114,2018-7-20,2018,7,20,19,90exhv,First Steps in Machine Learning with Microsoft Azure. Part 1 | Redwerk,https://www.reddit.com/r/deeplearning/comments/90exhv/first_steps_in_machine_learning_with_microsoft/,mariafilina,1532083434,,0,1
115,2018-7-20,2018,7,20,20,90f2ua,[Discussion] What are some limitations on using Deep Learning compared to Machine Learning.,https://www.reddit.com/r/deeplearning/comments/90f2ua/discussion_what_are_some_limitations_on_using/,dataCamper,1532084944,"I have came to know the skepticism of Academic people regarding deep learning and I was surprised to see a lot of points they were making to be true and that I have never thought about them. One point they made which was specially surprising to me was ""Training a neural network right"". Now to some extent this is true that we have to take care of a lot of things while training such as 1) Don't let model overfit or underfit 2) Keep in mind the generalization error 3) Data Imbalances 4) Points on pre-processing. But apart from these I don't know what are the other things we need to keep in mind. I would be grateful if people from this community can point out some other points that may help alleviate the skepticism and restore the confidence in Deep Learning because of the ""black box"" nature of it.",8,0
116,2018-7-20,2018,7,20,21,90fmh6,Ratio Analysis with and without a chatbot,https://www.reddit.com/r/deeplearning/comments/90fmh6/ratio_analysis_with_and_without_a_chatbot/,seoaleait,1532090289,,1,0
117,2018-7-20,2018,7,20,21,90fqzr,"Question about Mnih &amp; Hinton paper : ""learning to label aerial images from noisy data""",https://www.reddit.com/r/deeplearning/comments/90fqzr/question_about_mnih_hinton_paper_learning_to/,borbag,1532091404,"Link to the paper : https://www.cs.toronto.edu/~vmnih/docs/noisy_maps.pdf 

What is the loss function introduced in section 4? I was looking for a function f_theta(m_i, m_i), close to the cross entropy, figuring theta_0 and theta_1. But it is never written.",0,8
118,2018-7-21,2018,7,21,16,90nij0,Tensorflow : How do i perform pairwise minimum operation on a minibatch.,https://www.reddit.com/r/deeplearning/comments/90nij0/tensorflow_how_do_i_perform_pairwise_minimum/,sujitrrai,1532156440,Like for performing pairwise dot product i would perform matrix multiplication with the minibatch and its transpose similarly how can i replace the row column multiplication with the minimum operation?,0,1
119,2018-7-21,2018,7,21,17,90nz0g,What could be a baseline model in traditional approach (not deep learning) for a Question and Answering System for comparative research?,https://www.reddit.com/r/deeplearning/comments/90nz0g/what_could_be_a_baseline_model_in_traditional/,anis016,1532162742,,0,4
120,2018-7-21,2018,7,21,21,90ot39,A computer build for deep learning?,https://www.reddit.com/r/deeplearning/comments/90ot39/a_computer_build_for_deep_learning/,winger_syndrome,1532174521,"Hello! Sorry to bother everyone, and I'm not sure if this a question that's fit for here, but I'm really stuck. I tried to train a CNN for cat and dog classifier for a course I'm taking, and that ended on my laptop seriously overheating and shutting down (I know, a very naive mistake, but I didn't imagine that this would happen as it's my first CNN), so I can't go on with the course to train my model.

I tried some cloud solutions, but they're really inconvenient for me and if I'm going to pay for the cloud instances, then it's cheaper on the long run to get a computer fit for deep learning.

So, my question is, what is the bare minimum GPU that I can go with that would fit a beginner's need in deep learning? I have seen most computer builds go for $1000, but that's steep for me. So, is there any way I can get a build for half that or something, or is that not possible?

Thanks in advance and I'm really sorry for such a question here, but I'm really stuck and I can't find anyone saying anything on Google that recommends a GPU suited for beginners.",1,0
121,2018-7-21,2018,7,21,23,90pomy,Here is a list of Machine Learning Data Resources,https://www.reddit.com/r/deeplearning/comments/90pomy/here_is_a_list_of_machine_learning_data_resources/,asifrazzaq1988,1532183572,,0,18
122,2018-7-22,2018,7,22,0,90q2gq,[P] Examples trained using the python pytorch package pro-gan-pth,https://www.reddit.com/r/deeplearning/comments/90q2gq/p_examples_trained_using_the_python_pytorch/,akanimax,1532186875,,0,0
123,2018-7-22,2018,7,22,3,90r706,AI Weekly 21 July 2018,https://www.reddit.com/r/deeplearning/comments/90r706/ai_weekly_21_july_2018/,TomekB,1532196139,,0,1
124,2018-7-22,2018,7,22,14,90vq0j,Latest TensorFlow Release 1.9 is Out! Let us upgrade,https://www.reddit.com/r/deeplearning/comments/90vq0j/latest_tensorflow_release_19_is_out_let_us_upgrade/,DecipherTechnic,1532238458,,4,2
125,2018-7-23,2018,7,23,0,90yg0m,Delete Diagonal elements from a tensor in Tensorflow ?,https://www.reddit.com/r/deeplearning/comments/90yg0m/delete_diagonal_elements_from_a_tensor_in/,sujitrrai,1532272830,"Can you please let me know how to delete the diagonal elements from a (N,N) tensor in tensorflow.",13,1
126,2018-7-23,2018,7,23,16,914zlm,Implementation of Deep CORAL: Correlation Alignment for Deep Domain Adaptation in Tensorflow,https://www.reddit.com/r/deeplearning/comments/914zlm/implementation_of_deep_coral_correlation/,iamharsshit,1532330410,[https://github.com/harshitbansal05/Deep-Coral-Tf](https://github.com/harshitbansal05/Deep-Coral-Tf),0,2
127,2018-7-23,2018,7,23,17,915g9a,"""Towards Automated Deep Learning: Efficient Joint Neural Architecture and Hyperparameter Search"", Zela et al 2018",https://www.reddit.com/r/deeplearning/comments/915g9a/towards_automated_deep_learning_efficient_joint/,arberzela,1532336205,,3,5
128,2018-7-23,2018,7,23,19,915wlt,How to suppress the activation of the samples from outside the known classes of the classifier,https://www.reddit.com/r/deeplearning/comments/915wlt/how_to_suppress_the_activation_of_the_samples/,HoiM_1994,1532341648,"Hello, everyone. I encounter a problem that may need your ideas. 

Usually we train a classification CNN network, we have limited classes. For example, we can train a model classifying cats and dogs, then we use a dataset called 'cat and dogs' that only has cat images and dogs images (along with the labels--cat, dog). After the training, it should only be able to classify cat images and dog images. When an image containing a car gets in, it should predict neither cat or dog.

We trained a large-scale convolutional neural network classifier for classifying the faces of celebrities. Since it is applied to a face recognition system, it is unavoidable that some faces that are outside the known classes may get in. Usually we use a threshold to avoid wrong prediction. When the maximum activation of the last FC layer is under 0.7, we make decision that this face is outside the known classes. But the problem is that, sometimes these faces may get a very high maximum activation, such that the threshold cannot filter this out. 

So do any of you have good ideas or have similar experience for the problem? (Except training with more data, our data set is already large enough) I'd really appreciate it if you could help me. ",0,1
129,2018-7-23,2018,7,23,21,916ivr,Deep Learning Basics: The Score Function &amp; Cross Entropy,https://www.reddit.com/r/deeplearning/comments/916ivr/deep_learning_basics_the_score_function_cross/,magneticono,1532347965,,0,1
130,2018-7-24,2018,7,24,2,91928l,Air pollution forecast,https://www.reddit.com/r/deeplearning/comments/91928l/air_pollution_forecast/,angelinux74,1532366905,"Which are the best deep learning architectures to explore air pollution forecast? Is there a 2D model to represent earth surface with randomly distributed sensors, capable of predicting pollutant concentration? Could you please let me know some relevant research paper?",0,1
131,2018-7-24,2018,7,24,2,9197pg,Does anyone use MATLAB ?,https://www.reddit.com/r/deeplearning/comments/9197pg/does_anyone_use_matlab/,whatarelightquanta,1532367977,"I take a glance at neural network toolbox and it seems pretty high level and useful, i wonder if anyone in the field is using it ? ",13,1
132,2018-7-24,2018,7,24,3,919he1,Evolutionary algorithm outperforms deep-learning machines at video games,https://www.reddit.com/r/deeplearning/comments/919he1/evolutionary_algorithm_outperforms_deeplearning/,_b0t,1532369735,,3,32
133,2018-7-24,2018,7,24,7,91bgfr,Local Receptive Field - how does it work?,https://www.reddit.com/r/deeplearning/comments/91bgfr/local_receptive_field_how_does_it_work/,shuklaswag,1532383323,"So if two 3x3 convolution layers are stacked on top of each other, their aggregate Local Receptive Field is 5x5. Does this imply that two stacked 3x3 convolution layers are equivalent in power/utility to a single 5x5 layer?

Also, what is the end-goal of the local receptive field? Are we trying to get our convolutional neural net's final local receptive field to equal the size of the input image? So larger, more high-resolution images would require deeper networks and/or larger kernels?",0,1
134,2018-7-24,2018,7,24,20,91gdpj,Anybody interested in an online brain training for speed reading?,https://www.reddit.com/r/deeplearning/comments/91gdpj/anybody_interested_in_an_online_brain_training/,golovatuy,1532430011,"There are some brain fitness apps to train speed reading skill, and it's interesting how many people are interested in this training and skill",3,0
135,2018-7-25,2018,7,25,1,91isi0,Is there a market potential for autonomous outdoor rovers?,https://www.reddit.com/r/deeplearning/comments/91isi0/is_there_a_market_potential_for_autonomous/,nathgilson,1532448924,"We are a Swiss team developing an autonomous navigation system as a service: we afford an API that takes an image and GPS coordinates in inpout and outputs the navigation commands in &gt;250 ms. That enables a rover to be autonomous in outdoor environments like streets, campus, etc.
Our problem is: we have difficulties to find clients since there are a very few applications for outdoor rovers at the moment. 

Does anyone know a market field our NSaaS could interest?

Thanks for your help,

Nathan from rb2.io
 ",3,4
136,2018-7-25,2018,7,25,7,91m8ps,Would data augmentation with audio data work for training a voice synthesizer?,https://www.reddit.com/r/deeplearning/comments/91m8ps/would_data_augmentation_with_audio_data_work_for/,floridianfisher,1532472563,I'm wondering if I can take a small voice dataset (2-3 hours) and do data augmentation on it to train a voice synthesizer. Anyone know if it is a good or bad idea? One the one hand more training data is good. But this is supposed to sound like a particular voice and augmenting the files would mess that voice up.,1,2
137,2018-7-25,2018,7,25,11,91nwjx,Artificial Neural Networks explained,https://www.reddit.com/r/deeplearning/comments/91nwjx/artificial_neural_networks_explained/,Al-Khazrajy,1532485957,,0,0
138,2018-7-25,2018,7,25,13,91oqcd,"Are you interested in Deep Learning and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/91oqcd/are_you_interested_in_deep_learning_and_want_to/,DiscoverAI,1532493438,,0,4
139,2018-7-25,2018,7,25,18,91q94r,GAN with Labelled Faces in the Wild,https://www.reddit.com/r/deeplearning/comments/91q94r/gan_with_labelled_faces_in_the_wild/,arjundupa,1532509930,"I've been trying to train a GAN which is able to generate faces using the Labelled Faces in the Wild dataset -- while both my discriminator and generator losses decrease, the outputs of the generator are still just noise. 

My code and results are here: [https://github.com/arjung128/deep-learning-experiments/blob/master/FaceGAN\_LFW.ipynb](https://github.com/arjung128/deep-learning-experiments/blob/master/FaceGAN_LFW.ipynb)

I've tried tweaking the learning rate, the models, etc. and I've got it this far but can't seem to do better than these results (these are terrible but I started with black images being outputted).

Any ideas?

Any help will be much appreciated, thanks!",0,2
140,2018-7-26,2018,7,26,3,91up6m, Supervisely goes beyond annotation - latest Deep Learning models out of the box,https://www.reddit.com/r/deeplearning/comments/91up6m/supervisely_goes_beyond_annotation_latest_deep/,tdionis,1532545007,,0,3
141,2018-7-26,2018,7,26,5,91vh47,"Looking for an annotated database/large set of pictures of used Magic: The Gathering cards, with their qualities (like mint, heavily played, etc) for a neural network.",https://www.reddit.com/r/deeplearning/comments/91vh47/looking_for_an_annotated_databaselarge_set_of/,GollyGeeGolly,1532550168,"If someone could tell me where to look, that would be great. Thanks!",0,1
142,2018-7-26,2018,7,26,10,91y0w6,Prove Simplification of Neural Network,https://www.reddit.com/r/deeplearning/comments/91y0w6/prove_simplification_of_neural_network/,arjunkava,1532569328,,0,1
143,2018-7-26,2018,7,26,10,91y257,"ROCm-1.8.2(AMD GPU Driver for ML/DL) is out , and here comes Tensorflow-1.8",https://www.reddit.com/r/deeplearning/comments/91y257/rocm182amd_gpu_driver_for_mldl_is_out_and_here/,grandoldmikaduki,1532569625,,0,13
144,2018-7-26,2018,7,26,14,91zgu4,Best tool to annotate a video file?,https://www.reddit.com/r/deeplearning/comments/91zgu4/best_tool_to_annotate_a_video_file/,amit2rockon,1532582603,I need a software to annotate a video file having multiple objects.,7,2
145,2018-7-26,2018,7,26,15,91zqec,All You Need to Know About Neural Networks  Part 2,https://www.reddit.com/r/deeplearning/comments/91zqec/all_you_need_to_know_about_neural_networks_part_2/,Michael_Pa,1532585420,,0,1
146,2018-7-26,2018,7,26,15,91zr9o,Help with implementing RES30 Network (Noise2Noise reimplementation),https://www.reddit.com/r/deeplearning/comments/91zr9o/help_with_implementing_res30_network_noise2noise/,Geralt_of_Rivia96,1532585682,"Hello,

I am not sure if this is the right thread to post this on, but:

I am a relative novice in machine learning. I want to reimplement the RES30 network for image denoising as described in the recent paper Noise2Noise ([https://arxiv.org/pdf/1803.04189.pdf](https://arxiv.org/pdf/1803.04189.pdf)). What I am having trouble is even understanding how to begin, or finding source code from which to build off of. Any direction or help, or someone who could mentor me through the process would be greatly appreciated. I tried doing some research into available code and models to use, but couldn't find something that provided code for training (found a repository from the referenced RES30 net paper that has the trained weights and RES30 model for image denoising), but nothing to help me with training (in regards to implementing the noise2noise methods). Thank you",0,1
147,2018-7-26,2018,7,26,15,91zuzx,"My computer hangs (freezes), when training a convolutional network",https://www.reddit.com/r/deeplearning/comments/91zuzx/my_computer_hangs_freezes_when_training_a/,suraty,1532586793,"Hello,
My computer hangs (freezes), when training a convolutional network with below architecture:
(Codes in Keras-CPU)


    model = models.Sequential()
    model.add(layers.Conv2D(64,(3, 3), activation='relu', input_shape=(320,20,1), padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Flatten())
    model.add(layers.Dense(5*320))

Train on 15048 samples, validation on 1368 samples.
batch_size=16

   model.fit(train_x, train_y, batch_size=batch_size,
                    epochs=epochs, verbose=2,
                    callbacks=early_stopping,
                    validation_data=(val_x, val_y))

   model.evaluate(test_x, test_y)

And model summary:

Layer (type)                  output Shape             Param #
------------------------------------------------------------------
conv2d                     (None, 320, 20,64)            640
___________________________________________________
max_pooling2d         (None, 160,10,64)               0
___________________________________________________
flatten                          (None, 102400)               0
___________________________________________________
dense                           (None, 1600)            163841600
-------------------------------------------------------------------


What operation does make the computer to freeze? (What operation is hard to doing?)
How can I prevent my computer from hanging?
Thank you",6,3
148,2018-7-26,2018,7,26,20,921jvd,About understanding theoretical GAN papers.,https://www.reddit.com/r/deeplearning/comments/921jvd/about_understanding_theoretical_gan_papers/,porygon93,1532605649,"I am having hard time understanding the underlying theory and notation of the papers such as Wasserstein GAN, Towards Principled Methods for Training GANs as well as other theoretical papers such as f-gan; due to my insufficient Maths background.

My question is, which topics do I need to study to understand(and do research on) the theory and analysis on your work? I have an engineering background so I know about multivariable calculus, probability, linear algebra which allows me to follow most machine learning, deep learning related papers. However, I cant understand the notation or terms used these papers such as ""support, manifold, sup, inf, induced topology, Borel subset, K-Lipschitz, Lebesgue measure, metric set, hilbert space, Fenchel conjugate, etc."".

Of course, I could google these to learn what they mean but I think I need a systematic treatment about the whatever topic which includes these terms to have a solid understanding about your work, and do research on it. So, which topics would you recommend me to study?


Greetings.

",2,10
149,2018-7-26,2018,7,26,21,921ypo,Looking for the deep learning experts,https://www.reddit.com/r/deeplearning/comments/921ypo/looking_for_the_deep_learning_experts/,viktoriia_shulga,1532609338,,1,0
150,2018-7-27,2018,7,27,0,923d5h,When would you not use Batch Norm?,https://www.reddit.com/r/deeplearning/comments/923d5h/when_would_you_not_use_batch_norm/,ASBrainBeast,1532619834,"I mean, it sounds pretty generally fantastic. If normalizing and standardizing your data is common practice and always helpful, why wouldn't normalizing and standardizing your layer outputs be?",0,10
151,2018-7-27,2018,7,27,1,923l7f,New Deep Learning Algorithm Solves Rubiks Cube,https://www.reddit.com/r/deeplearning/comments/923l7f/new_deep_learning_algorithm_solves_rubiks_cube/,ANNA_Systems,1532621349,,1,15
152,2018-7-27,2018,7,27,4,925lqq,Longivity of ML vs Dl,https://www.reddit.com/r/deeplearning/comments/925lqq/longivity_of_ml_vs_dl/,ragas_,1532635046,"ML and DL mainly solve same types of problem, i.e regression and classification . (When I'm saying ML means linear regression, Random Forest, SVM, etc.). The advantage of ML is it can work on small dataset with great accuracy and have good mathematical foundation. But DL  has far better accuracy then ML when have good computation power and enough data. Over the period, say 5 years, later, computation power will be fat better than now and with the advancement of DL methodologies data requirement will also comes down (one-shot learning an example). In that case how much ML method will becrelevant then?
Just curious to know. ",10,0
153,2018-7-27,2018,7,27,20,92btmg,Introduction to Deep learning mathematics,https://www.reddit.com/r/deeplearning/comments/92btmg/introduction_to_deep_learning_mathematics/,Zeolearn,1532692104,,0,1
154,2018-7-27,2018,7,27,20,92burc,Age Detection of Indian Actors with Deep Learning Studio,https://www.reddit.com/r/deeplearning/comments/92burc/age_detection_of_indian_actors_with_deep_learning/,digitalson,1532692438,,0,1
155,2018-7-27,2018,7,27,23,92cszo,Doubt regarding the slide on differentiable programming for Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/92cszo/doubt_regarding_the_slide_on_differentiable/,sriharsha_0806,1532700382,Can anyone explain me regarding this slide? I thought DNN is always fixed and is not based on data.,2,1
156,2018-7-28,2018,7,28,0,92df5f,AI in Agriculture,https://www.reddit.com/r/deeplearning/comments/92df5f/ai_in_agriculture/,_first_of_his_name_,1532704841,I am searching for a good problem definition in agriculture domain requiring computer vision and AI. Can anyone suggest a few?,20,2
157,2018-7-28,2018,7,28,2,92ego5,Why don't we want Autoencoders to perfectly represent their training data?,https://www.reddit.com/r/deeplearning/comments/92ego5/why_dont_we_want_autoencoders_to_perfectly/,shuklaswag,1532712129,"From Ian Goodfellow's Deep Learning Book:

&gt; If an autoencoder succeeds in simply learning to set `g(f(x)) = x` everywhere, then it is not especially useful. Instead, autoencoders are designed to be unable to learn to copy perfectly

I don't understand this part. `g` is the decoder, and `f` is the encoder. Why is it undesirable for the encoder and decoder to perfectly represent the input data `x`?

Another way to frame this question is - why do autoencoders require regularization? I understand in predictive machine learning, we regularize the model so that it can generalize beyond the training data. 

However, with a sufficiently massive training set (as is common in Deep Learning), there should not be a need for regularization. To me, it seems desirable to learn `g(f(x)) = x` everywhere, and I don't understand why the author says otherwise.",5,12
158,2018-7-28,2018,7,28,13,92jhbb,Stacked LSTM with in between dropouts...,https://www.reddit.com/r/deeplearning/comments/92jhbb/stacked_lstm_with_in_between_dropouts/,172knot,1532752537,"I have tried to implement a stacked LSTM with dropout in between.

     inp_ = tf.unstack(inp_ ,n_input, 1)
     lstm_cell1 = tf.contrib.rnn.BasicLSTMCell(200)
     lstm_cell2 = tf.contrib.rnn.BasicLSTMCell(100)
     lstm_dropout1 = tf.contrib.rnn.DropoutWrapper(lstm_cell1, input_keep_prob = 1.0, output_keep_prob=0.8)
     lstm_dropout2 = tf.contrib.rnn.DropoutWrapper(lstm_cell2, input_keep_prob = 1.0, output_keep_prob=0.8)
     lstm_layers = tf.contrib.rnn.MultiRNNCell([lstm_dropout1, lstm_dropout2])
     outputs1, states1 = tf.contrib.rnn.static_rnn(lstm_layers, inp_, dtype=tf.float32)

Is this the right method to implement dropout in between LSTM cells?

If anyone of you have previously implemented such model, can you please help me?",0,4
159,2018-7-28,2018,7,28,13,92jjyz,Windows 10 vs. Linux for Deep Learning,https://www.reddit.com/r/deeplearning/comments/92jjyz/windows_10_vs_linux_for_deep_learning/,stefecon,1532753308,"Hello everyone. I am currently a data analyst/economist and learning about Deep Learning. In my line of work, I mostly use Windows 10 for SAS, R, and some Python. I am wondering if it's worth it to switch from Windows to Linux for Deep Learning for my home desktop. Could you enlighten me with pros and cons of these 2 OS's? Much thanks. ",13,1
160,2018-7-28,2018,7,28,22,92m2vl,Understanding Tensorflow's tensors shape: static and dynamic,https://www.reddit.com/r/deeplearning/comments/92m2vl/understanding_tensorflows_tensors_shape_static/,pgaleone,1532784149,,0,5
161,2018-7-28,2018,7,28,22,92m3s8,Google colab gives me only 11MB of GPU memory,https://www.reddit.com/r/deeplearning/comments/92m3s8/google_colab_gives_me_only_11mb_of_gpu_memory/,l0ve_y0u_t00,1532784399,"I've been using Google colab for past 4 days. First 2 days, I was alloted approx 9GB. But for the last 2 days, I'm getting only 11MB and the program can't even import data from my Google drive. I changed my account, cleared the browser data &amp; system cache, restarted my computer and the problem still persists.

Is anyone else facing the same problem? What can I do to get more GPU quota?",8,3
162,2018-7-29,2018,7,29,2,92nudm,what is a good resource in learning the real-life training of LSTM network,https://www.reddit.com/r/deeplearning/comments/92nudm/what_is_a_good_resource_in_learning_the_reallife/,ramana2887,1532799074,"I'm trying to train and LSTM network for two applications-speech recognition as well as stock prediction. This is done in Python using Keras.

As I have learnt, the programming for this is now pretty simple and programs to do this are available at various websites.

What is difficult perhaps is figuring out how to present the data and how to tweak the parameters for making the LSTM neural network get trained faster with more accuracy.

Are there any resources where one can learn how to do this? The kind of tutorials I have seen either give a theoretical understanding of neural networks/LSTM neural network or give the program and understanding of how to use keras / tensorflow.

I am hoping that perhaps there would be some place where I get some tips or an account of how someone trained and LSTM network how much time it took, and what was done in order to make it converge.

Thank you for any inputs

",1,2
163,2018-7-29,2018,7,29,12,92rwwe,My Learnings With Tensorflow.js,https://www.reddit.com/r/deeplearning/comments/92rwwe/my_learnings_with_tensorflowjs/,i_am_adl,1532834661,"Hello Everyone,

I have been experimenting on Tensorflow.js for sometime , I would like to Share my Learning with the Community.

We know that An increasing number of developers are using TensorFlow in their machine learning projects. In March this year, the TensorFlow team at Google announced the arrival of the much-awaited JavaScript framework, TensorFlow.js (which was previously called DeepLearn.js).

Now developers can build lightweight models and run them in the browser using JavaScript. Lets understand what the need was for the development of this framework.

## History

Before going to TensorFlow.js, I would like to start off with TensorFlow.

TensorFlow was developed in 2011 at Google as their propitiatory library for Machine learning/Deep learning applications at Google. This library was open sourced in 2015 under the Apache License.

TensorFlow is built in C++, which enables the code to execute at a very low level. TensorFlow has bindings to different language like Python, R, &amp; Java. This enables TensorFlow to be used in these languages.

So, the obvious question is: what about JavaScript?

Conventionally, in JavaScript, ML/DL was performed by using an API. An API was made using some framework, and the model was deployed at the server. The client sent a request using JavaScript to get results from the server.

[Client Server Architecture](https://i.redd.it/fk51671p2tc11.png)

In 2017, a project called Deeplearn.js appeared, which aimed to enable ML/DL in JavaScript, without the API hassle.

But there were questions about speed. It was very well known that JavaScript code could not run on GPU. To solve this problem, WebGL was introduced. This is a browser interface to OpenGL. WebGL enabled the execution of JavaScript code on GPU.

In March 2018, the DeepLearn.js team got merged into the TensorFlow Team at Google and was renamed TensorFlow.js.

Watch the below video for further details:

[https://youtu.be/qa1OXssGBHw](https://youtu.be/qa1OXssGBHw)

## TensorFlow.js

Tensorflow.js provides two things:

* The CoreAPI, which deals with the low level code
* LayerAPI is built over the CoreAPI, and makes our lives easier by increasing the level of abstraction.

## Getting Started

There are two main ways to get TensorFlow.js in your project:

## 1. via &lt;script&gt;Tag

Add the following code to an HTML file:

    &lt;html&gt;
    &lt;head&gt;
      &lt;!-- Load TensorFlow.js --&gt;
        &lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.0""&gt; &lt;/script&gt;
      &lt;/head&gt;
        &lt;body&gt;
          Hello
      &lt;/body&gt;
    &lt;/html&gt;

## 2. viaNPM

Add TensorFlow.js to your project using yarn or npm.

    yarn add @tensorflow/tfjs  npm install @tensorflow/tfjs  

In your main js file:

    import * as tf from '@tensorflow/tfjs';  

## CoreAPI

## 1. Tensors

So, what is a Tensor?

[Visual Representation of Scalar,Vector,Matrix and Tensor](https://i.redd.it/ppbngayi2tc11.jpg)

* A scalar is a single number. For example, x = 1
* A vector is an array of numbers. For example, *x*=\[1,2\]
* A matrix is a 2-D array =&gt; (\[\[1, 2\],\[3, 4\],\[5, 6\]\])
* A tensor is a \*n-\*dimensional array with *n*\&gt;2

TensorFlow.js has utility functions for common cases like Scalar, 1D, 2D, 3D and 4D tensors, as well a number of functions to initialize tensors in ways useful for machine learning.

## Code Examples

**tf.tensor():**

    // Pass an array of values to create a vector.  
    tf.tensor([1, 2, 3, 4]).print(); 

**tf.scalar():**

    tf.scalar(3.14).print();  

And so on

Watch the Below Video to get a deep insight into Tensors in TensorFlow.js:

[https://youtu.be/sZrwxnIfHCo](https://youtu.be/sZrwxnIfHCo)

## 2. Variables &amp; Operations

Tensors are immutable data structures. That means their values cant be changed once they are set.

However, tf.variable()is introduced in TensorFlow.js. The real use case for tf.variable()is when we need to change the data frequently, such as when adjusting model weights in Machine Learning.

Code sample:

    const x = tf.variable(tf.tensor([1, 2, 3]));  
    x.assign(tf.tensor([4, 5, 6])); 
     x.print();  

## Operations

There are various operations in TensorFlow.js. In order to perform mathematical computation on Tensors, we use operations. Tensors are immutable, so all operations always return new Tensors and never modify input Tensors. So tf.variable()can be used in order to save memory.

Lets look into some operations:

**tf.add()Adds two** [**tf.Tensor**](https://js.tensorflow.org/api/0.12.0/#class:Tensor)**s element-wise**

    const a = tf.tensor1d([1, 2, 3, 4]);  
    const b = tf.tensor1d([10, 20, 30, 40]); 
     a.add(b).print();  // or tf.add(a, b)  

There are many operations in TensorFlow.js. You can check the [documentation](https://js.tensorflow.org/api/0.12.0/#Operations)for other operations. I will demonstrate one more operation here: **tf.matmul()**

**tf.matmul()Computes the dot product of two matrices, A \* B.**

    const a = tf.tensor2d([1, 2], [1, 2]);  
    const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);
     a.matMul(b).print();  // or tf.matMul(a, b)  

Watch the below video for deep insight into Variable and Operations:

[https://youtu.be/AP1BmP0BZmQ](https://youtu.be/AP1BmP0BZmQ)

## 3. Memory Management

Memory management is the key in Machine Learning/Deep Learning tasks, because they are generally computationally expensive.

TensorFlow.js provides two major ways to manage memory:

1. tf.dispose()
2. tf.tidy()

They both typically do the same thing, but they do it in different ways.

## tf.tidy()

This executes the provided function function and after it is executed, cleans up all intermediate tensors allocated by function except those returned by function.

tf.tidy() helps avoid memory leaks. In general, it wraps calls to operations in [tf.tidy()](https://js.tensorflow.org/api/0.12.0/#tidy) for automatic memory cleanup.

Code example:

    const y = tf.tidy(() =&gt; {
        // aa, b, and two will be cleaned up when the tidy ends.
    
        const two= tf.scalar(2); 
        const aa = tf.scalar(2); 
        const b = aa.square();
    
        console.log('numTensors (in tidy): ' + tf.memory().numTensors);
    
        // The value returned inside the tidy function will return // through the tidy,     in this case to the variable y. 
    
        return b.add(two); 
    });
    
    console.log('numTensors (outside tidy): ' + tf.memory().numTensors); y.print();
    tf.dispose()

Disposes any [tf.Tensor](https://js.tensorflow.org/api/0.12.0/#class:Tensor)s found within the mentioned object.

Code example:

    const two= tf.scalar(2); 
     two.dispose()  

## LayersAPI

Layers are the primary building block for constructing a ML/DL Model. Each layer will typically perform some computation to transform its input to its output. Under the hood, every layer uses the CoreAPI of Tensorflow.js.

Layers will automatically take care of creating and initializing the various internal variables/weights they need to function. So, basically it makes life easier by increasing the level of abstraction.

We will make a simple example feed forward network using the LayerAPI. The Feed Forward network we will build is as below:

## Code:

**Index.html**

    &lt;html&gt;
    &lt;head&gt;
    &lt;title&gt;
    &lt;/title&gt;    
       &lt;script src=https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.0""&gt; &lt;/script&gt;
    &lt;script src=main.js type=text/javascript&gt;&lt;/script&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Tensorflow JS Demo
    &lt;/body&gt;
    &lt;/html&gt;

**main.js**

    const model = tf.sequential();
    
    //config for layer
    const config_hidden = {
      inputShape:[3],
      activation:'sigmoid',
      units:4
    }
    const config_output={
      units:2,
      activation:'sigmoid'
    }
    
    //defining the hidden and output layer
    const hidden = tf.layers.dense(config_hidden);
    const output = tf.layers.dense(config_output);
    
    //adding layers to model
    model.add(hidden);
    model.add(output);
    
    //define an optimizer
    const optimize=tf.train.sgd(0.1);
    
    //config for model
    const config={
    optimizer:optimize,
    loss:'meanSquaredError'
    }
    
    //compiling the model
    model.compile(config);
    
    console.log('Model Successfully Compiled');
    
    //Dummy training data
    const x_train = tf.tensor([
      [0.1,0.5,0.1],
      [0.9,0.3,0.4],
      [0.4,0.5,0.5],
      [0.7,0.1,0.9]
    ])
    
    //Dummy training labels
    const y_train = tf.tensor([
      [0.2,0.8],
      [0.9,0.10],
      [0.4,0.6],
      [0.5,0.5]
    ])
    
    //Dummy testing data
    const x_test = tf.tensor([
      [0.9,0.1,0.5]
    ])
    
    train_data().then(function(){
      console.log('Training is Complete');
      console.log('Predictions :');
      model.predict(x_test).print();
    })
    
    async function train_data(){
      for(let i=0;i&lt;10;i++){
      const res = await model.fit(x_train,y_train,epoch=1000,batch_size=10);
       console.log(res.history.loss[0]);
      }
    }

Output:

[Output of the code](https://i.redd.it/u75d2bt72tc11.png)

Pls watch the below videos for deep insight and code explanation:

[https://youtu.be/z2u-s3NzHhY](https://youtu.be/z2u-s3NzHhY)

[https://youtu.be/lKWUSkwOR5s](https://youtu.be/lKWUSkwOR5s)

## My take onthis

This is excellent for coders who are familiar with JavaScript and are trying to find their way in the ML/DL world!

It makes things a lot simpler for people coming from a non-ML/DL background, but who are looking to understand this field. The use cases for this are many, and I personally think its something we need at the moment.

What do you think about TensorFlow.js? Let me know in the comments section below.

**Thanks For Reading and Giving your Precious Time**",2,15
164,2018-7-29,2018,7,29,21,92ukqg,RNN on Bag of Words,https://www.reddit.com/r/deeplearning/comments/92ukqg/rnn_on_bag_of_words/,rotronic,1532868993,Does it make sense to have a RNN or LSTM on a bag of words model. I tried this in keras and go an accuracy of 0. Any idea why?,8,3
165,2018-7-29,2018,7,29,22,92up0u,Implementation of Image Outpainting,https://www.reddit.com/r/deeplearning/comments/92up0u/implementation_of_image_outpainting/,Naughty_Nagaland,1532870244,,0,1
166,2018-7-29,2018,7,29,22,92upjy,Image Outpainting,https://www.reddit.com/r/deeplearning/comments/92upjy/image_outpainting/,Naughty_Nagaland,1532870399,,1,4
167,2018-7-30,2018,7,30,6,92y5ly,Resource for training sets?,https://www.reddit.com/r/deeplearning/comments/92y5ly/resource_for_training_sets/,NickJaGr01,1532899290,Is there a comvenient resource or website where one can find substantial training sets for pretty much any problem?,3,1
168,2018-7-30,2018,7,30,19,932xfo,Any startup or big firm taking deep learning interns in Canada? I am MMath student in Uwaterloo looking for 8 month co ops.,https://www.reddit.com/r/deeplearning/comments/932xfo/any_startup_or_big_firm_taking_deep_learning/,randomchickibum,1532946418,,2,7
169,2018-7-30,2018,7,30,21,933lv8,AI vs. Humans: Upending the Division of Labor,https://www.reddit.com/r/deeplearning/comments/933lv8/ai_vs_humans_upending_the_division_of_labor/,ANNA_Systems,1532953397,,0,2
170,2018-7-31,2018,7,31,2,936bgr,Learn Data Science - Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/936bgr/learn_data_science_deep_learning_in_python/,algbra,1532973287,,0,0
171,2018-7-31,2018,7,31,3,936j5r,detecting paper sheet with deep learning,https://www.reddit.com/r/deeplearning/comments/936j5r/detecting_paper_sheet_with_deep_learning/,Vankir,1532974693,"Hi All,

I need to detect sheet of paper or driver license or book, in other words rectangle with any document. What is the best way to do that? Should I try some object detection and then apply classic contour detection, for example, from OpenCV to find out contour of paper? Is there better way? 

Thanks you!",8,4
172,2018-7-31,2018,7,31,4,9370gg,Faster RCNN,https://www.reddit.com/r/deeplearning/comments/9370gg/faster_rcnn/,amaljossy,1532977915,"Can someone point me to some learning materials/ video explanations on Faster RCNN, Fast RCNN and RCNN. Other than the original papers ofcourse. It's for a paper review sort of thing",4,5
173,2018-7-31,2018,7,31,4,9376bh,Convolutional Neural Network based Image Colorization using OpenCV,https://www.reddit.com/r/deeplearning/comments/9376bh/convolutional_neural_network_based_image/,spmallick,1532978986,,0,11
174,2018-7-31,2018,7,31,7,938lc8,How to detect language of handwritten text in an image,https://www.reddit.com/r/deeplearning/comments/938lc8/how_to_detect_language_of_handwritten_text_in_an/,arush1836,1532988671,Suppose we have an image with a mix of printed and handwritten text. How can we detect the language of handwritten text. Any advice will be helpful.,1,2
175,2018-7-31,2018,7,31,10,93aa5y,Deep Learning and Neural Networks,https://www.reddit.com/r/deeplearning/comments/93aa5y/deep_learning_and_neural_networks/,ATGhoul1212,1533001968,"According to Andrew Ng's suggestion , he mentioned that stack up the inputs in different columns as in row vector and stack the weights as a column vector , but why is that ?.Can anyone get me the intuition.",0,0
176,2018-7-31,2018,7,31,19,93dg56,(VIDEO) NTR LAB Rocks IT In Siberia,https://www.reddit.com/r/deeplearning/comments/93dg56/video_ntr_lab_rocks_it_in_siberia/,Batareika_1,1533034410,,0,0
177,2018-7-31,2018,7,31,22,93enmo,"Incentivised Multi-Target, Multi-Camera Tracking with Untrusted Cameras",https://www.reddit.com/r/deeplearning/comments/93enmo/incentivised_multitarget_multicamera_tracking/,david_at,1533045162,,2,4
0,2018-8-1,2018,8,1,10,93kd8z,Do You Know The Mathematics For Machine Learning ?,https://www.reddit.com/r/deeplearning/comments/93kd8z/do_you_know_the_mathematics_for_machine_learning/,asifrazzaq1988,1533085696,,4,10
1,2018-8-1,2018,8,1,10,93kdhc,Ideas for Improving Training of GAN,https://www.reddit.com/r/deeplearning/comments/93kdhc/ideas_for_improving_training_of_gan/,arjundupa,1533085747,"I've been trying to train a GAN which is able to generate faces using the Labelled Faces in the Wild dataset -- while both my discriminator and generator losses decrease, and while the outputs of the generator begin to resemble faces, they never get to the point where they're really good because at some point the generator always seems to beat the discriminator.

My code and results are here: 

[https://www.dropbox.com/s/optjdi5u0o6ybml/FaceGAN-2.pdf?dl=0](https://www.dropbox.com/s/optjdi5u0o6ybml/FaceGAN-2.pdf?dl=0)

I've tried tweaking the learning rate, the models, etc. and I've got it this far but can't seem to do better than these results.

Any ideas?

Any help will be much appreciated, thanks!",1,1
2,2018-8-1,2018,8,1,12,93lfs0,A Data-Driven Approach to Resisting Adversarial Attacks by Inducing Confusion,https://www.reddit.com/r/deeplearning/comments/93lfs0/a_datadriven_approach_to_resisting_adversarial/,srianant,1533094574,,0,6
3,2018-8-1,2018,8,1,21,93oq79,Benefits and Risks of Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/93oq79/benefits_and_risks_of_artificial_intelligence/,seoaleait,1533128305,,1,0
4,2018-8-2,2018,8,2,2,93r1fv,resources (papers/useful links/etc) for generating music with deep learning,https://www.reddit.com/r/deeplearning/comments/93r1fv/resources_papersuseful_linksetc_for_generating/,amit2rockon,1533144447,,1,10
5,2018-8-2,2018,8,2,3,93ro69,Here is the list of some of the deep learning books for reading:,https://www.reddit.com/r/deeplearning/comments/93ro69/here_is_the_list_of_some_of_the_deep_learning/,asifrazzaq1988,1533148579,"# Here is the list of some of the recommended deep learning books for reading:

#### 1. [Deep Learning](https://www.amazon.com/gp/product/0262035618/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0262035618&amp;linkId=160f03fc387166681f28ecb014effa2c) by Goodfellow, Bengio, and Courville

The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and video games. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. *(Content from Amazon)*

#### 2. [Deep Learning](https://www.amazon.com/gp/product/1617294438/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1617294438&amp;linkId=e617ae088aa586b65cc2e9cf81f892df) with Python byFrancois Chollet

*Deep Learning with Python* introduces the field of deep learning using the Python language and the powerful Keras library. Written by Keras creator and Google AI researcher Franois Chollet, this book builds your understanding through intuitive explanations and practical examples. Youll explore challenging concepts and practice with applications in computer vision, natural-language processing, and generative models. By the time you finish, youll have the knowledge and hands-on skills to apply deep learning in your own projects.*(Content from Amazon)*

#### 3.[Hands-On Machine Learning with Scikit-Learn and TensorFlow](https://www.amazon.com/gp/product/1492032646/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1492032646&amp;linkId=afb3b56e446fb6d25712434a379e2dc7) byAurlien Gron

By using concrete examples, minimal theory, and two production-ready Python frameworksscikit-learn and TensorFlowauthor Aurlien Gron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. Youll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what youve learned, all you need is programming experience to get started.*(Content from Amazon)*

#### 4.[TensorFlow Deep Learning Cookbook](https://www.amazon.com/gp/product/1788293592/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1788293592&amp;linkId=c3cf2b95878c5feed6ac6ad68981fa61) byAntonio Gulli

Deep neural networks (DNNs) have achieved a lot of success in the field of computer vision, speech recognition, and natural language processing. The entire world is filled with excitement about how deep networks are revolutionizing artificial intelligence. This exciting recipe-based guide will take you from the realm of DNN theory to implementing them practically to solve the real-life problems in artificial intelligence domain.

In this book, you will learn how to efficiently use TensorFlow, Googles open source framework for deep learning. You will implement different deep learning networks such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Deep Q-learning Networks (DQNs), and Generative Adversarial Networks (GANs) with easy to follow independent recipes. You will learn how to make Keras as backend with TensorFlow.*(Content from Amazon)*

#### 5.[Deep Learning: A Practitioners Approach](https://www.amazon.com/gp/product/1491914254/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1491914254&amp;linkId=a4d9fc2a0e6eca62ed9bea7fa25cdb74) byJosh Patterson andAdam Gibson

Authors Adam Gibson and Josh Patterson provide theory on deep learning before introducing their open-source Deeplearning4j (DL4J) library for developing production-class workflows. Through real-world examples, youll learn methods and strategies for training deep network architectures and running deep learning workflows on Spark and Hadoop with DL4J.*(Content from Amazon)*

#### 6.[Make Your Own Neural Network](https://www.amazon.com/gp/product/1530826608/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1530826608&amp;linkId=4d62a3d5b0f35b9b031db70f725d67d3) byTariq Rashid

A step-by-step gentle journey through the mathematics of neural networks, and making your own using the Python computer language. Neural networks are a key element of deep learning and artificial intelligence, which today is capable of some truly impressive feats. Yet too few really understand how neural networks actually work. This guide will take you on a fun and unhurried journey, starting from very simple ideas, and gradually building up an understanding of how neural networks work.*(Content from Amazon)*

#### 7.[Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithms](https://www.amazon.com/gp/product/1491925612/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1491925612&amp;linkId=9f5efc212ffa47a21a7479fbff22f000) by[Nikhil Buduma](https://www.linkedin.com/in/nikhilbuduma)

With the reinvigoration of neural networks in the 2000s, deep learning has become an extremely active area of research, one thats paving the way for modern machine learning. In this practical book, author Nikhil Buduma provides examples and clear explanations to guide you through major concepts of this complicated field.

Companies such as Google, Microsoft, and Facebook are actively growing in-house deep-learning teams. For the rest of us, however, deep learning is still a pretty complex and difficult subject to grasp. If youre familiar with Python, and have a background in calculus, along with a basic understanding of machine learning, this book will get you started.*(Content from Amazon)*

#### 8.[Neural Network Design (2nd Edition)](https://www.amazon.com/gp/product/0971732116/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0971732116&amp;linkId=6f4ff3438aea81bac6c957cbfd639fd1) byMartin T Hagan, Mark H Beale, andOrlando De Jess

This book, by the authors of the Neural Network Toolbox for MATLAB, provides a clear and detailed coverage of fundamental neural network architectures and learning rules. In it, the authors emphasize a coherent presentation of the principal neural networks, methods for training them and their applications to practical problems. Features Extensive coverage of training methods for both feedforward networks (including multilayer and radial basis networks) and recurrent networks. In addition to conjugate gradient and Levenberg-Marquardt variations of the backpropagation algorithm, the text also covers Bayesian regularization and early stopping, which ensure the generalization ability of trained networks. Associative and competitive networks, including feature maps and learning vector quantization, are explained with simple building blocks. A chapter of practical training tips for function approximation, pattern recognition, clustering, and prediction, along with five chapters presenting detailed real-world case studies.*(Content from Amazon)*

#### 9.[Neural Networks for Pattern Recognition](https://www.amazon.com/gp/product/0198538642/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0198538642&amp;linkId=44360a03df2efa82d5d4bbbed3b66dbc) byChristopher M. Bishop

This is the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts, the book examines techniques for modeling probability density functions and the properties and merits of the multi-layer perceptron and radial basis function network models. Also covered are various forms of error functions, principal algorithms for error function minimalization, learning and generalization in neural networks, and Bayesian techniques and their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved in the fields of neural computation and pattern recognition.*(Content from Amazon)*

#### 10.[Python Machine Learning: Machine Learning and Deep Learning](https://www.amazon.com/gp/product/B0742K7HYF/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=marktechpost-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B0742K7HYF&amp;linkId=e994afd3bc05299d5b36fe173e79a875) bySebastian Raschka andVahid Mirjalili

Machine learning is eating the software world, and now deep learning is extending machine learning. Understand and work at the cutting edge of machine learning, neural networks, and deep learning with this second edition of Sebastian Raschkas bestselling book, Python Machine Learning. Thoroughly updated using the latest Python open source libraries, this book offers the practical knowledge and techniques you need to create and contribute to machine learning, deep learning, and modern data analysis.*(Content from Amazon)*

 Note: This list consists of some of the deep learning books which we found useful for you. If you think we missed any book then please comment.

Article Source: [https://www.marktechpost.com/2018/07/31/list-of-deep-learning-books-to-read/](https://www.marktechpost.com/2018/07/31/list-of-deep-learning-books-to-read/)",0,1
6,2018-8-2,2018,8,2,16,93xa4j,[Paper] Hypergradient,https://www.reddit.com/r/deeplearning/comments/93xa4j/paper_hypergradient/,string111,1533195781,"Hey guys, I found a really cool paper [https://arxiv.org/pdf/1703.04782.pdf](https://arxiv.org/pdf/1703.04782.pdf) which discusses/rediscovers a Method  proposed by Almeida et al. (1998), which neglects fine tuning of the learning rate. I find this to be really awesome.

Has anybody implemented this or used this kind of optimizers? Opening discussion",0,11
7,2018-8-2,2018,8,2,17,93xmw5,Model interpretation to explain what factors helped Titanic survivors,https://www.reddit.com/r/deeplearning/comments/93xmw5/model_interpretation_to_explain_what_factors/,antiquemule,1533200227,"A nice blog post that shows the different plots to get clear explanation of ""black box"" models. 

This kind of model interpretation seems to be getting better and easier by the day.",0,0
8,2018-8-2,2018,8,2,18,93xr4j,LEVERAGING AR FOR INDUSTRY 4.0,https://www.reddit.com/r/deeplearning/comments/93xr4j/leveraging_ar_for_industry_40/,sam-Ideas2IT,1533201571,,0,0
9,2018-8-3,2018,8,3,3,941s7i,"Snark AI Update: Jupyter, Docker and Fast.AI",https://www.reddit.com/r/deeplearning/comments/941s7i/snark_ai_update_jupyter_docker_and_fastai/,snarkai,1533233981,"Since our previous blogpost about [Unchaining GPUs for Deep Learning](https://blog.usejournal.com/blockchain-gpus-unchained-running-neural-networks-without-hurting-mining-hash-rate-38a88728a1c9), [Hacker News Launch](https://news.ycombinator.com/item?id=17491604) and [TechCrunch](https://techcrunch.com/2018/07/25/snark-ai-looks-to-help-companies-get-on-demand-access-to-idle-gpus/) article, we have worked hard with our early users to provide **low-cost GPUs for Deep Learning** through a very simple interface.

    $pip3 install snark

![video](p1zxe3680qd11)

Throughout working with them, we learnt so much about their workflow and came up with some important feature updates. We are ready to share them today.

    $snark start

**Persistent Storage**

Files in your home folder are stored persistently across all running pods. No need to attach volumes. Everything is just there when you login to your pod. We found this very convenient on two aspects:

1. Reconfigure hardware specs at ease. Want to scale up training with more GPUs? Simply stop the old pod and start a new pod with more GPUs. Your old files and installed packages will still be there with the new hardware spec!

&amp;#8203;

    $snark stop pod_13432
    $snark start -g 5

2.  Easier instance management. Now you can easily stop at any point, take a break and then start the instance again. This feature is still in development mode, if you need more storage or need to move your data across gpu types, please email us.  


**Jupyter Support**

We are releasing simple Jupyter access.

    $snark start --jupyter

Just open your local browser with [http://localhost:8888](http://localhost:8888). You will need to copy the token from the CLI for security reasons. Start experimenting on a remote GPU quickly. You can also open a manual port as you would do in SSH in case you want to run e.g. Tensorboard

    $snark start -L 6006:localhost:6006

Jupyter lab next to come.

  
**Docker (beta)**

If you need to run your custom container with your prebuilt environment, here you go. One requirement would be to make sure that the base of the docker is Ubuntu such that we can easily wrap connection to the container.

    $start -t custom --docker_image username/image:tag

If you need other images please reach us and we will support it. This feature is still in beta and your feedback would really help us to improve.

[**Fast.ai**](https://Fast.ai)**Ready**

Once you have persistent storage, Jupyter access and customized dockers, what else you might need to hack Deep Learning? We also provide ready [Fast.ai](https://Fast.ai) courses for your ease to start learning Deep Learning.

    $snark start --pod_type fast.ai --jupyter

If you have more feature requests or feedback happy to chat with you on our website.",0,17
10,2018-8-3,2018,8,3,16,947hxk,"28-part Deep Learning Course / Book (with PyTorch): 19 Free Tutorials. Paid Quizzes, Assignments, Projects and Certificate.",https://www.reddit.com/r/deeplearning/comments/947hxk/28part_deep_learning_course_book_with_pytorch_19/,keshav57,1533280682,"The course / book was created by myself (MIT alum) and 3 other experts. We've been working on this course for more than a year, and it is constantly improving.

The course covers machine learning and deep learning concepts, including the important deep learning architectures like convolutional neural networks (CNN) and long short-term memory (LSTM) networks applied to computer vision and natural language processing.

All the tutorials are available for free. Hands-on projects require Pro version (ranges from $5-$9/month) which gives unrestricted access to ALL courses. Almost all the user reviews say that this is a ""real steal"" / ""no brainer"".

Links

* [Deep Learning Course](https://www.commonlounge.com/discussion/eacc875c797744739a1770ba0f605739)
* [Machine Learning Course](https://www.commonlounge.com/discussion/33a9cce246d343dd85acce5c3c505009)
* [Deep Learning for NLP Course](https://www.commonlounge.com/discussion/27984d9c014e49b1b5c7f7fab08de256)
* [Natural Language Processing Course](https://www.commonlounge.com/discussion/9e98fc12d49e4cd59e248fc5fb72a8e9)
* [Data Science with Python Course](https://www.commonlounge.com/discussion/367fb21455e04c7c896e9cac25b11b47)

Hope you all like it. Do let me know if you have any questions. P.S.: We collect ratings and reviews from students. The course has an average rating of 4.9/5.0",0,17
11,2018-8-3,2018,8,3,16,947ld4,SOTA object Detection,https://www.reddit.com/r/deeplearning/comments/947ld4/sota_object_detection/,bikashg,1533281800,,2,42
12,2018-8-3,2018,8,3,18,94888w,Seven spectrum of Outcomes of AI,https://www.reddit.com/r/deeplearning/comments/94888w/seven_spectrum_of_outcomes_of_ai/,seoaleait,1533289652,,0,5
13,2018-8-3,2018,8,3,18,9489q8,Deep Learning Interview Questions And Answers - Great Info,https://www.reddit.com/r/deeplearning/comments/9489q8/deep_learning_interview_questions_and_answers/,pooja307,1533290149,,1,2
14,2018-8-3,2018,8,3,22,949emg,Predicting customer churn in banking using ANN,https://www.reddit.com/r/deeplearning/comments/949emg/predicting_customer_churn_in_banking_using_ann/,blackbird9820,1533301451,,0,0
15,2018-8-4,2018,8,4,1,94b66x,"Should I gloss over the linear algebra chapter in the book ""Deep Learning"" by Ian Goodfellow?",https://www.reddit.com/r/deeplearning/comments/94b66x/should_i_gloss_over_the_linear_algebra_chapter_in/,Crenox,1533314515,"Hi everyone!

Currently I am reading ""Deep Learning"" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville. I'm on Chapter 2 which is the Linear Algebra section where they go over the linear algebra that pertains to the book. I understand most of what is being taught but not at a deep level. And when I get to some of the latter parts of the chapter like ""2.9 The Moore-Penrose Pseudoinverse"" and specifically ""2.12 Example: Principal Components Analysis"", I don't really understand them that well at all.

Would it be okay if I go onto Chapter 3 and beyond before I understand these concepts comfortably, or will I be fine with having basic knowledge of them and the symbols they use?",6,4
16,2018-8-4,2018,8,4,2,94bcfa,Why do we flip the kernel in convolutional neural network?,https://www.reddit.com/r/deeplearning/comments/94bcfa/why_do_we_flip_the_kernel_in_convolutional_neural/,darylflx,1533315725,I have read the answer from https://stackoverflow.com/questions/45152473/why-is-the-convolutional-filter-flipped-in-convolutional-neural-networks but I still do not get why we should flip the kernel. ,7,3
17,2018-8-4,2018,8,4,7,94e3zn,Neural net case study for sports image classification.,https://www.reddit.com/r/deeplearning/comments/94e3zn/neural_net_case_study_for_sports_image/,wai_land,1533335494,,0,1
18,2018-8-4,2018,8,4,13,94gixw,New Youtube Channel on making cutting edge AI Research accessible,https://www.reddit.com/r/deeplearning/comments/94gixw/new_youtube_channel_on_making_cutting_edge_ai/,vector_machines,1533357538,"Hi, Please check out my channel ([https://www.youtube.com/c/aijournal](https://www.youtube.com/c/aijournal)) which talks about research in Deep Learning, Machine Learning, Reinforcement Learning, NLP. The main aim is to bring as much research content available as possible. Majority of information is stored inside papers, and very few people have access to it. I want to bring out the best out of all of them. 

I also have a subreddit  ([https://www.reddit.com/r/aijournal/](https://www.reddit.com/r/aijournal/)) if you have any doubts regarding the content being discussed on the channel. We're a really friendly community interested in cutting edge research in ML.",7,46
19,2018-8-5,2018,8,5,0,94k4n8,GIF classification,https://www.reddit.com/r/deeplearning/comments/94k4n8/gif_classification/,Arkhaya,1533398211,Are there any papers or methods that can help in learning if the GIF format can be added to an image classifier or have a model specifically for it?,3,1
20,2018-8-5,2018,8,5,17,94qhpu,AI Weekly 5 August 2018,https://www.reddit.com/r/deeplearning/comments/94qhpu/ai_weekly_5_august_2018/,TomekB,1533458080,,0,1
21,2018-8-5,2018,8,5,20,94r67g,Some questions about Text-to-Image Synthesis,https://www.reddit.com/r/deeplearning/comments/94r67g/some_questions_about_texttoimage_synthesis/,EricDZhang,1533467862,"I start to focus on Text-to-Image Synthesis on complex Dataset (like MSCOCO) Using GAN these days.

After searching, some relevant works are StackGAN, [Hong](https://arxiv.org/abs/1801.05091) et.al. and AttnGAN

It seems there are mainly two methods for synthesis: either generating from scratch (low resolution) to reality (high resolution) or generating from bbox to shape(Mask) and finally to image.

Here are some of my questions about current situation of Text-to-Image Synthesis research:

1. Is there any other method to deal with this kind of task?
2. What are the pros and shortcuts of these two methods?
3. In a view of such a high Inception Score AttnGAN has achieved (nearly 170% improved), it seems rather difficult to get improvement. Is it possible to get my paper accepted if I don't exceed AttnGAN?",0,5
22,2018-8-6,2018,8,6,1,94t38s,Some questions about ConvLSTMs,https://www.reddit.com/r/deeplearning/comments/94t38s/some_questions_about_convlstms/,adi1709,1533486596,"Has anyone tried batch normalisation on ConvLSTMs (Tensorflow) ? My network is descending into a local minima in my opinion and I'm finding it hard to fix it. Are there any tips / tricks I should be looking at to avoid this? 
Also if there are any specific procedure I can use to debug it would be very helpful. Thank you. ",5,1
23,2018-8-6,2018,8,6,1,94t5id,Mode collapse vaegan in atari frames.,https://www.reddit.com/r/deeplearning/comments/94t5id/mode_collapse_vaegan_in_atari_frames/,Teenvan1995,1533487107,"I am was trying develop a generative model for the frames of the atari game Montezuma revenge. 
Initially, I tried a simple car but the model only predicted the background and not the agent and the skull (the pixels that are moving basically)
To solve this, I thought probably an adversarial loss may help because of the averaging nature of the reconstruction loss that fails the standard  vae.
But I still get a single image with no variations.
And the image is an average of all the environments the network sees.
Is there any solution to this problem. Thanks!",0,1
24,2018-8-6,2018,8,6,2,94tqbo,Learn how a neural network works!,https://www.reddit.com/r/deeplearning/comments/94tqbo/learn_how_a_neural_network_works/,antaloaalonso,1533491690,"If you want to learn how exactly a neural network works, check out this video!

[https://www.youtube.com/watch?v=EF7LBSCfW7c&amp;t=1s](https://www.youtube.com/watch?v=EF7LBSCfW7c&amp;t=1s)",0,1
25,2018-8-6,2018,8,6,3,94u6tr,Suggestions for papers,https://www.reddit.com/r/deeplearning/comments/94u6tr/suggestions_for_papers/,pranjal_22,1533495258,"Hi everyone, I am trying to build a model to detect and grade Diabetic Retinopathy using deep learning. I am looking for a few good research papers regarding that. Any help would be really appreciated!
Thanks ",5,1
26,2018-8-6,2018,8,6,19,950bgg,How to setup the environment for deep learning?,https://www.reddit.com/r/deeplearning/comments/950bgg/how_to_setup_the_environment_for_deep_learning/,83krkf,1533553125,"I'm getting started with deep learning([fast.ai](https://fast.ai)). At the moment I can't afford cloud nor a new rig. I would like to setup my workstation on my laptop. Someone suggested me NVIDIA + docker, any guides or suggestions regarding this?",5,3
27,2018-8-6,2018,8,6,22,95177s,Image Recognition on an iOS/Android app,https://www.reddit.com/r/deeplearning/comments/95177s/image_recognition_on_an_iosandroid_app/,FrenchDizzie,1533561433,"Hi all,

I'd like to develop an iOS app where you can take a picture of a tree or a flower (or any plant basically) and it tells you what that plant is, and some useful tips to take care of it. I'd like to be able to also diagnose plant diseases (fungi, parasites, ...).

Would it be possible to design and train a deep neural network, and then implement it and use it in an iOS or Android application ?",2,3
28,2018-8-6,2018,8,6,23,951neq,project ideal for the final year engineering,https://www.reddit.com/r/deeplearning/comments/951neq/project_ideal_for_the_final_year_engineering/,random_forest97,1533565019,"I am currently in the 7th sem of engineering and I am really interested in doing a project in the domain of deeplearning . 
I have some project ideas like  a sentiment analysis for social media using rrn , but I don't know how to convert it into a project, as most of things I have to borrow it from others work, including dataset.",1,2
29,2018-8-6,2018,8,6,23,951wvd,Similar Study for Lewd Analysis,https://www.reddit.com/r/deeplearning/comments/951wvd/similar_study_for_lewd_analysis/,TagChild,1533566992," Hi everyone, I am trying to build a model for lewd analysis for chatting application using deep learning. I am looking for a few good research papers regarding that. Any help would be really appreciated! Thanks ",0,3
30,2018-8-7,2018,8,7,0,9524oi,"Hi, Please have a look at the equations below, I do need a proper reasoning for understanding. Thank you. (ACGAN)",https://www.reddit.com/r/deeplearning/comments/9524oi/hi_please_have_a_look_at_the_equations_below_i_do/,nile6499,1533568532,"The Generator equation  are **maximizing(Lc -Ls)**, where Lc is the loss of how similar Labels from Fake Image is close to real Image, Ls is the loss to find whether the image is fake or real.

**In implementation of the above equation is written has min(Lc + Ls), I am very confused on this.**",4,2
31,2018-8-7,2018,8,7,1,952p4e,"Given data, how to determine if deep learning needs to be used?",https://www.reddit.com/r/deeplearning/comments/952p4e/given_data_how_to_determine_if_deep_learning/,eemamedo,1533572517,"If I am given data, what techniques/algorithms can I use/run to determine if deep learning algorithms will need to be applied?

I understand that one of hints is to check if function is non-linear in some neighborhood (machine learning algorithms tend to assume that function is linear). Are there any other tests I can run on data that will help me to determine that deep learning is needed?
",6,4
32,2018-8-7,2018,8,7,3,953ma4,"Free webinar 8/21 - Deep Learning to Detect Fake News with Uber ATG Head of Data Science, Mike Tamir",https://www.reddit.com/r/deeplearning/comments/953ma4/free_webinar_821_deep_learning_to_detect_fake/,redditman09876543,1533578762,,0,1
33,2018-8-7,2018,8,7,9,956rjv,Question regarding equation in Glow: Generative Flow (a reversible model),https://www.reddit.com/r/deeplearning/comments/956rjv/question_regarding_equation_in_glow_generative/,darylflx,1533601251,"Hi everyone, I am having trouble understanding how this equation in this paper, https://arxiv.org/pdf/1807.03039.pdf , at equation(6). I will be very much appreciated if any assistance can be provided. ",2,2
34,2018-8-7,2018,8,7,11,957t8l,Question about merging feature maps,https://www.reddit.com/r/deeplearning/comments/957t8l/question_about_merging_feature_maps/,OpenStorm5,1533610023,"Hi all:

I have some questions about merging two feature maps.

1. what is the difference between concating them and summing them up? (FCN uses sum operation, while UNET is concating the two features)
2. is it necessary to apply 1x1 conv to feature maps before merging?

Thank you!",1,2
35,2018-8-7,2018,8,7,13,958nf4,has anyone used Nvidia V100? How fast is this card?,https://www.reddit.com/r/deeplearning/comments/958nf4/has_anyone_used_nvidia_v100_how_fast_is_this_card/,MasterSama,1533617435,"Hi everyone,

I'm trying to assess how much time I would need to rent a V100. I am using a GTX1080 and training a simple VGGNet like architecture (Simplenet). for 30 epochs it takes about 24 hours, and roughly it needs at least 100\~120 epochs to call the training completed. Now I need to know how much faster the V100 is compared to my GTX1080. Couldn't find any benchmarks that would help me in this regard. so any help is greatly appreciated ",13,3
36,2018-8-8,2018,8,8,0,95cv0b,Deep learning in NLP research paper Reading Group,https://www.reddit.com/r/deeplearning/comments/95cv0b/deep_learning_in_nlp_research_paper_reading_group/,pcidev,1533657394,"I was trying to start a research paper reading group, where we will aim to read a paper and implement it in a week and then discuss. I am excited about it. If anyone interested please comment. 
TOPIC - Recent research in NLP.",31,26
37,2018-8-8,2018,8,8,1,95cyew,"When we back propagate the gradients, are the gradients added or subtracted to the original values?",https://www.reddit.com/r/deeplearning/comments/95cyew/when_we_back_propagate_the_gradients_are_the/,nile6499,1533658030,,1,2
38,2018-8-8,2018,8,8,4,95ekxu,Has anyone implemented StackGAN in Keras?,https://www.reddit.com/r/deeplearning/comments/95ekxu/has_anyone_implemented_stackgan_in_keras/,kailashahirwar12,1533668914,"I am trying to implement StackGAN in Keras. Tensorflow and Pytorch implementation of StackGAN is already out there on Github, but no one has implemented StackGAN in Keras. If yes, any links to repos would be appreciated.",0,1
39,2018-8-8,2018,8,8,5,95fb4y,Beginner's Deep Learning video course (50% off with code 'vlcarnes2'),https://www.reddit.com/r/deeplearning/comments/95fb4y/beginners_deep_learning_video_course_50_off_with/,beaucarnes,1533673835,,0,0
40,2018-8-8,2018,8,8,16,95k222,Links to Computer Vision News of August,https://www.reddit.com/r/deeplearning/comments/95k222/links_to_computer_vision_news_of_august/,Gletta,1533714886,"Here is the August 2018 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: 32 pages worth reading, about Artificial Intelligence, Deep Learning, Image Processing and Computer Vision. Technical review of new technologies at page 4 and free subscription at page 32.

[HTML5 version (recommended) ](https://www.rsipvision.com/ComputerVisionNews-2018August/)

[PDF version](http://www.rsipvision.com/computer-vision-news-2018-august-pdf/)

Enjoy!",0,2
41,2018-8-8,2018,8,8,18,95ke8v,Help regarding model of LSTM Network,https://www.reddit.com/r/deeplearning/comments/95ke8v/help_regarding_model_of_lstm_network/,ravaan,1533719068,"I am new to this sub and also new to deep learning so apologies if I am saying anything wrong/not allowed.

I want to model a deep learning network for a service based chat bot which has limited functionality, take an example of a customer interacting with the chat bot of a bank. 

I have, say, 100 functionalities ( as sentences and their variations). I also have a dictionary of all the important vectors, I have vectorized the the 100 functionalities and their variations and this will be the input data for the neural network. (i.e. -  these vectors correspond to these sentences (commands)).

Now for the result expected - Suppose, The customer enters  - ""My bank account balance"", the neural network should break the sentence into important vectors - {&lt;my account&gt;, &lt;balance&gt;} and then return this to me, matching it to the most probable functionality. 

As far as I have read till now an LSTM network would be the best network for this kind of problem, what I am not able to figure out is how to decide the structure of the network. 

Any help in terms of how to model the network, resources to read, similar code et cetra is highly appreciated. ",6,2
42,2018-8-8,2018,8,8,18,95kh6f,"How to Setup Ubuntu 16.04 with CUDA, GPU, and other requirements for Deep Learning",https://www.reddit.com/r/deeplearning/comments/95kh6f/how_to_setup_ubuntu_1604_with_cuda_gpu_and_other/,coinmonks,1533720035,,7,8
43,2018-8-8,2018,8,8,18,95ko32,Complete Guide to TensorFlow for Deep Learning with Python,https://www.reddit.com/r/deeplearning/comments/95ko32/complete_guide_to_tensorflow_for_deep_learning/,plpface,1533722254,,0,1
44,2018-8-8,2018,8,8,19,95kwjz,DataScience Digest - Issue #14,https://www.reddit.com/r/deeplearning/comments/95kwjz/datascience_digest_issue_14/,flyelephant,1533724861,,0,1
45,2018-8-8,2018,8,8,23,95mqky,Suggestion for ML and DL projects.,https://www.reddit.com/r/deeplearning/comments/95mqky/suggestion_for_ml_and_dl_projects/,Troied,1533740369,Please help me out.,10,0
46,2018-8-9,2018,8,9,0,95ms53,"Dance generator using Autoencoder, LSTM and Mixture Density Network (Keras)",https://www.reddit.com/r/deeplearning/comments/95ms53/dance_generator_using_autoencoder_lstm_and/,HairyIndianDude,1533740660,,1,5
47,2018-8-9,2018,8,9,0,95n7u3,"Dance generator using LSTM, Autoencoder and Mixture Density Network",https://www.reddit.com/r/deeplearning/comments/95n7u3/dance_generator_using_lstm_autoencoder_and/,HairyIndianDude,1533743528,"https://i.redd.it/19p2uiz15we11.gif

github link: r/https://github.com/jsn5/dancenet",5,13
48,2018-8-9,2018,8,9,1,95nco8,Best tools to use for real time detection of classes.,https://www.reddit.com/r/deeplearning/comments/95nco8/best_tools_to_use_for_real_time_detection_of/,amit2rockon,1533744407,I have polygonal  labelled dataset having multi classes. I want to detect those classes in real time. What  tools do you prefer to use and it's approach ?,0,1
49,2018-8-9,2018,8,9,1,95ntem,Few activation functions handling various problems - neural networks,https://www.reddit.com/r/deeplearning/comments/95ntem/few_activation_functions_handling_various/,mikinoqwert2,1533747537,"Please, explain me, how a few activation functions in neural networks can handle so many problems? I know some basics theory behind ANN, but I can't get what in common have sigmoid function etc. with for example picture classification?",1,1
50,2018-8-9,2018,8,9,4,95pgl0,Are view() in torch and reshape() in Numpy similar?,https://www.reddit.com/r/deeplearning/comments/95pgl0/are_view_in_torch_and_reshape_in_numpy_similar/,kailashahirwar12,1533758304,"Are view() in torch and reshape in Numpy similar?

view() is applied on torch tensors to change it's shape and reshape is a numpy function to change shapes of ndarrays.",2,2
51,2018-8-9,2018,8,9,8,95rera,What kind of model to use?,https://www.reddit.com/r/deeplearning/comments/95rera/what_kind_of_model_to_use/,champulal,1533772320,"Hi all, I am  using a thermal sesor that returns  (1,64) 2d array.the array contains numerical value. Now I want to use deep learning to detect from the sensor values is there's a person or not. Can you help me decide which kind of model to use and any other information.",2,1
52,2018-8-9,2018,8,9,15,95txe2,Is it possible to create a recurrent neural network that learns to loop a variable number of times based on the input?,https://www.reddit.com/r/deeplearning/comments/95txe2/is_it_possible_to_create_a_recurrent_neural/,hapa93,1533795200,"I.e, the number of times to feed the output to itself is learned. 

This seems impossible because the number of times to loop can only be integers which is not differentiable.",2,4
53,2018-8-9,2018,8,9,22,95wlll,Human presence detection.,https://www.reddit.com/r/deeplearning/comments/95wlll/human_presence_detection/,HumbBest,1533822640,"Hello, thanks for your guidance. 
I'm quite new to deep learning, I've been following the Deep Learning A-Z course on udemy.
I am looking towards detecting human presence in a video stream from a cam and maybe sound an alarm or take other actions.
From what I've been able to collect, my problem then becomes an object detection problem but with a single class (person).
However, using an object detector seems a bit overkill, especially when I don't really need the bounding boxes from object detectors, I just want to know whether there is one person or more in my image. So I'm left wondering:
How should I approach my problem?",5,2
54,2018-8-9,2018,8,9,23,95wsjd,Postdoctoral fellowship: Machine Learning for NeuroImaging of Stroke Recovery,https://www.reddit.com/r/deeplearning/comments/95wsjd/postdoctoral_fellowship_machine_learning_for/,mreyesag,1533824121,"Applicants are invited for a Postdoctoral fellowship at the Medical Image Analysis group of the University of Bern as part of a multidisciplinary project between the Support Center for Advanced NeuroImaging, at Inselspital, Bern and Intento AG, an award-winning company developing innovative technologies to improve recovery of severely paralyzed stroke patients.

More info: https://www.linkedin.com/pulse/postdoctoral-fellowship-machine-learning-neuroimaging-mauricio-reyes/

Thank for upvoting to help spread the word!
",0,4
55,2018-8-9,2018,8,9,23,95wv3p,Why we reverse the words in source sentence improve the efficiency of LSTM ?,https://www.reddit.com/r/deeplearning/comments/95wv3p/why_we_reverse_the_words_in_source_sentence/,pcidev,1533824688,"I was reading the paper -  *Sequence to Sequence learning using Neural Nets* . In that paper the author has reversed the order of the source sentence but not the target sentence and claim that it improves their performance. 

Could someone explain how reversing help and can we used that trick in other task on NLP ?  


PS: in paper the reason was not clear. ",9,8
56,2018-8-10,2018,8,10,1,95y363,"That's not enough, We have to go deeper",https://www.reddit.com/r/deeplearning/comments/95y363/thats_not_enough_we_have_to_go_deeper/,arjunkava,1533832960,,0,1
57,2018-8-10,2018,8,10,1,95y6fq,"That's not enough, We have to go deeperThat&amp;#x27;s not enough, We have to go deeper",https://www.reddit.com/r/deeplearning/comments/95y6fq/thats_not_enough_we_have_to_go_deeperthatx27s_not/,arjunkava,1533833558,,0,1
58,2018-8-10,2018,8,10,2,95ydvt,What Artificial Intelligence Taught Us,https://www.reddit.com/r/deeplearning/comments/95ydvt/what_artificial_intelligence_taught_us/,harshMachineLearning,1533834901,,0,2
59,2018-8-10,2018,8,10,7,960y1e,Introducing TAZ: A.I. Powered Churn Analytics,https://www.reddit.com/r/deeplearning/comments/960y1e/introducing_taz_ai_powered_churn_analytics/,coAdjoint_Tom,1533852127,,0,0
60,2018-8-10,2018,8,10,13,963y6v,Artificial Intelligence (AI) emulates how people think  Artificial Emotional Intelligence (AEI) emulates how people feel,https://www.reddit.com/r/deeplearning/comments/963y6v/artificial_intelligence_ai_emulates_how_people/,Batareika_1,1533876670,,2,0
61,2018-8-10,2018,8,10,18,965jsw,"Sometimes, I get tired of pretending I actually know statistics.",https://www.reddit.com/r/deeplearning/comments/965jsw/sometimes_i_get_tired_of_pretending_i_actually/,ASBrainBeast,1533894446,"And I don't just want to gloss over something I don't understand :) The paragraph below is from this blogpost: [https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning/](https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning/)

&gt;Several techniques are required for a DQN to work effectively. As the agent interacts with the environment, &lt;st,at,rt,st+1&gt;&lt;st,at,rt,st+1&gt;tuples it experiences are stored in an *experience buffer*. Training the *Q-network* is accomplished by randomly sampling batches from the *experience buffer* to compute the loss. The *experience buffer* is essential for learning; if the agent was trained using consecutive samples of experience, the samples would be highly correlated, updates would have high variance, and the network parameters could become stuck in a local minimum or diverge.

It's from the background section on RL; I don't really understand the latter part, about the consequences of not randomly sampling from the experience buffer. Would anyone be able to clarify? Thanks!!",11,19
62,2018-8-11,2018,8,11,0,967ra4,Literature on extracting additional features from a dataset using other neural networks?,https://www.reddit.com/r/deeplearning/comments/967ra4/literature_on_extracting_additional_features_from/,clarle,1533913823,"I've seen this come up in a few Kaggle competition solutions around computer vision, but I can't seem to find good literature or journal articles on this.

People will take another neural network separate from the one they're using, and use different layers as additional inputs into their own custom architecture.  It seems to be similar to transfer learning, but not exactly the same, as they use multiple resolution layers from the same other network as inputs.

It makes sense to me in theory, but I was just curious what sort of papers were out there discussing this.  ",0,1
63,2018-8-11,2018,8,11,0,967spb,Learn AI/ML/Deep Learning with new iOS/Android App!,https://www.reddit.com/r/deeplearning/comments/967spb/learn_aimldeep_learning_with_new_iosandroid_app/,MusingEtMachina,1533914111,"Hey everyone! First a bit about me: I did my undergrad and master's in Stanford's AI program.

I know firsthand that learning AI is challenging, but it doesn't have to be! I've released an iOS/Android app that is a full-fledged curriculum for learning the basics of AI/ML/Deep Learning in a \*\*no-experience necessary, accessible\*\* way.

For a limited time, the app is available with a \*\*special 66% off discount\*\*! Check it out on \[iOS\]([https://itunes.apple.com/us/app/artificial-intelligence-school/id1369987569?mt=8](https://itunes.apple.com/us/app/artificial-intelligence-school/id1369987569?mt=8)) and \[Android\]([https://play.google.com/store/apps/details?id=com.theaischool](https://play.google.com/store/apps/details?id=com.theaischool)).",2,0
64,2018-8-11,2018,8,11,2,96935p,New to deep learning!,https://www.reddit.com/r/deeplearning/comments/96935p/new_to_deep_learning/,datavoyager92,1533922780,"In neural networks, we talk a lot about weights. How are these weights assigned?

Are they random? Where does the system get those numbers?",15,2
65,2018-8-11,2018,8,11,6,96b9f4,"I have a cos function in interval of [0,pie/n], I need to remove the restriction, how can I? --&gt; Thanks",https://www.reddit.com/r/deeplearning/comments/96b9f4/i_have_a_cos_function_in_interval_of_0pien_i_need/,nile6499,1533938278,,2,0
66,2018-8-11,2018,8,11,16,96eqpt,What does linearly seperable mean?,https://www.reddit.com/r/deeplearning/comments/96eqpt/what_does_linearly_seperable_mean/,nshmadhani,1533971058,"I am new to Neural Networks and could not get my head wrapped around what is linearly separable and what is not , please help me .",6,0
67,2018-8-11,2018,8,11,18,96f9j4,Deep Supervised Learning: Loss-Accuracy Function Conundrum,https://www.reddit.com/r/deeplearning/comments/96f9j4/deep_supervised_learning_lossaccuracy_function/,Diaa07,1533978116,"So we all know that loss functions devised for deep learning, in particular softmax cross entropy, are not equivalent to the ideal 1-0 accuracy loss in classification tasks. Nonetheless, they work out together so well that it seems that practitioners ignore the aforementioned fact and end up happy with standard loss functions.  
 Has anybody encountered total contradiction between  loss and accuracy function with standard back-propagation, where your deep model ends up in a trivial minimum solution where the accuracy is 1/#Classes (totally random guessing)?  
Any suggestions or insightful comments as to how to tackle this issue?",2,3
68,2018-8-11,2018,8,11,18,96fgft,AI Weekly 11 August 2018,https://www.reddit.com/r/deeplearning/comments/96fgft/ai_weekly_11_august_2018/,TomekB,1533980813,,0,1
69,2018-8-11,2018,8,11,23,96h49j,Not able to train a feature fusion network.,https://www.reddit.com/r/deeplearning/comments/96h49j/not_able_to_train_a_feature_fusion_network/,adi1709,1533999441,"I have an RGB image and another modality (which also has 3 channels and is an image). This is an object detection network (SqueezeDet). Each modality has a seperate branch until I fuse the feature maps with each other and then few other layers after the fusion of the feature maps. (there are no fully connected layers, the output is obtained directly by conv layers). The individual networks converge ie when the one branch is not present. But when I train them together it is not converging. I am using a simple tf.concat to fuse the feature maps. I'm sorry, but any help is appreciated. It's sort of an emergency. Thank you. ",0,2
70,2018-8-12,2018,8,12,7,96kbg3,A small team of student AI coders beats Googles machine-learning code,https://www.reddit.com/r/deeplearning/comments/96kbg3/a_small_team_of_student_ai_coders_beats_googles/,MattyBv3,1534025350,,0,14
71,2018-8-12,2018,8,12,7,96khlf,AI Driving Olympics at NIPS 2018: deep learning vs traditional approaches,https://www.reddit.com/r/deeplearning/comments/96khlf/ai_driving_olympics_at_nips_2018_deep_learning_vs/,andrea,1534026793,"I am one of the organizers of [the AI Driving Olympics](https://www.duckietown.org/research/ai-driving-olympics) at NIPS 2018, in which 6 universities are involved (U. Montral / MILA, ETH Zrich, Georgia Tech, Tsinghua, NCTU, TTIC), plus 2 industry partners (self-driving car company nuTonomy and Amazon Web Services).

We are excited because this is going to be the first robotic competition at a machine learning conference: you send your code - we run it on our robots. Or, you can get a robot yourself through [the Kickstarter](https://www.kickstarter.com/projects/163162211/duckietown-a-playful-road-to-learning-robotics-and?ref=ay75ep) run by our non-profit foundation.

We are also very curious about what approach will be the winner...

AMA in the comments. I am here with students and collaborators /u/stratanis, /u/gzardini,  /u/manfred_diaz, /u/afdaniele, /u/duckietown-udem.
",2,18
72,2018-8-12,2018,8,12,15,96neuf,DeepLearning.ai Coursera study group,https://www.reddit.com/r/deeplearning/comments/96neuf/deeplearningai_coursera_study_group/,bo123x,1534056646,"Hi guys,

I am looking for a buddy or set up a study group to go help complete [DeepLearning.ai](https://DeepLearning.ai) specialisation. 

I would be keen to collaborate via slack and set up pair programming sessions do discuss and hack python code together

Are there volunteers?

Cheers",21,23
73,2018-8-12,2018,8,12,18,96nzq2,"Deep Learning - Mandate for Humans, Not Just Machines",https://www.reddit.com/r/deeplearning/comments/96nzq2/deep_learning_mandate_for_humans_not_just_machines/,vinods1975,1534065051,,0,5
74,2018-8-12,2018,8,12,18,96o5hj,Is it worth writing a research paper even if I have no means/ or chances of publishing it?,https://www.reddit.com/r/deeplearning/comments/96o5hj/is_it_worth_writing_a_research_paper_even_if_i/,mankadronit,1534067545,"I'm doing a Essay Grading using LSTMs project and I have achieved performance equal to current state of the art systems. So I want to write a paper on my method(and architecture). But I'm pretty sure my chances of publishing a paper are very low.

So can I just get by by publishing it on arXiv just to gain some CV leverage? I'm looking forward to do a Master's in CS/ML and I thought that this would boost my profile a little bit.",8,15
75,2018-8-12,2018,8,12,19,96ocrq,Introduction to Artificial Intelligence ( AI ) for Beginners,https://www.reddit.com/r/deeplearning/comments/96ocrq/introduction_to_artificial_intelligence_ai_for/,HannahHumphreys,1534070588,,0,1
76,2018-8-12,2018,8,12,23,96pftg,Is NVIDIA GTX 1050 good enough for deep learning? (Beginners),https://www.reddit.com/r/deeplearning/comments/96pftg/is_nvidia_gtx_1050_good_enough_for_deep_learning/,shyam_sundar19,1534084565,"I am about to purchase the Lenovo Y520 gaming laptop which rocks an NVIDIA GTX 1050 GPU. I am just starting out on Neural Nets especially for computer vision. Is this good enough to train reasonably sized models?
Your thoughts?",20,2
77,2018-8-12,2018,8,12,23,96phy3,https://www.youtube.com/watch?v=zxJJ0T54HX8,https://www.reddit.com/r/deeplearning/comments/96phy3/httpswwwyoutubecomwatchvzxjj0t54hx8/,vector_machines,1534085089,[https://www.youtube.com/watch?v=zxJJ0T54HX8](https://www.youtube.com/watch?v=zxJJ0T54HX8),0,1
78,2018-8-12,2018,8,12,23,96pjr1,Transfer Learning in NLP | Universal Language Models,https://www.reddit.com/r/deeplearning/comments/96pjr1/transfer_learning_in_nlp_universal_language_models/,vector_machines,1534085520,[https://www.youtube.com/watch?v=zxJJ0T54HX8](https://www.youtube.com/watch?v=zxJJ0T54HX8),0,1
79,2018-8-13,2018,8,13,2,96qs16,Understanding deep learning - a novice's perspective,https://www.reddit.com/r/deeplearning/comments/96qs16/understanding_deep_learning_a_novices_perspective/,Stelman,1534095524,,0,1
80,2018-8-13,2018,8,13,5,96s7uf,How to deal with missing values for a Simple Deep Neural Network ?,https://www.reddit.com/r/deeplearning/comments/96s7uf/how_to_deal_with_missing_values_for_a_simple_deep/,mihirbhatia999,1534106920,"I'm looking for a way to deal with missing values in my dataset. The dataset consists of 40 columns of structured data (NOT time-series). Most problems that I had dealt with earlier, I could just get rid of  where missing data was present and I was good to go since there were such few NaN values. But in this dataset, I would end up eliminating almost 40% of my data if I did the same thing.

I tried referring to [this paper](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=3E447DA9F99A2EFB3A762A94447DB5EC?doi=10.1.1.23.6971&amp;rep=rep1&amp;type=pdf) but I found it hard to grasp.  I have the following questions :

1.  I read on some forums that averaging or using other algorithms to fill the NaN values in some columns isn't the best route to go by. Is this true ? 
2. What are other alternatives of training my NN with the data that I have without having to get rid of all the data essential to train it ? 
3. Once trained and checked on the Dev set, how to deal with the test set values ? ",7,9
81,2018-8-13,2018,8,13,14,96vqy5,RNN model with 3 hidden layers,https://www.reddit.com/r/deeplearning/comments/96vqy5/rnn_model_with_3_hidden_layers/,suraty,1534138677,"Hello,
In a paper, it mentioned: ANN, RNN, and LSTM NN are optimized to contain three hidden layers with 1000 hidden units in each layer.
I would like to model the RNN model in Keras. But my code fails in an error!
My code:
     model=Sequential()
     model.add(SimpleRNN(1000,input_shape=(320,15),activation='relu'))
     model.add(SimpleRNN(1000))
     model.add(SimpleRNN(1000))
     model.add(Dense(1600))
Error:
     ValueError                                Traceback (most recent call last)
     &lt;ipython-input-49-ff01ce62eb30&gt; in &lt;module&gt;()
      1 model=Sequential()
      2 model.add(SimpleRNN(1000,input_shape=(320,15),activation='relu'))
     ----&gt; 3 model.add(SimpleRNN(1000))
      4 model.add(SimpleRNN(1000))
      5 model.add(Dense(1600))
     .....
     ....
     ...
     ..
     .
     
   
    ValueError: Input 0 is incompatible with layer simple_rnn_2: expected ndim=3, found ndim=2


How can I code for the RNN model which is optimized to contain three hidden layers with 1000 hidden units in each layer?
Thank you so much",4,1
82,2018-8-13,2018,8,13,19,96x85u,Transfer Learning in NLP | Universal language models,https://www.reddit.com/r/deeplearning/comments/96x85u/transfer_learning_in_nlp_universal_language_models/,vector_machines,1534156524,,0,21
83,2018-8-14,2018,8,14,5,971vl0,Webinar: Using Hypothetical Data in Machine Learning Trading Strategies,https://www.reddit.com/r/deeplearning/comments/971vl0/webinar_using_hypothetical_data_in_machine/,qplum,1534192232,[removed],0,1
84,2018-8-14,2018,8,14,8,973bzm,Need help with identifying the proper operations for 2 sequential tensor,https://www.reddit.com/r/deeplearning/comments/973bzm/need_help_with_identifying_the_proper_operations/,anis016,1534203159,"Hi,

I have a tensor X , which is of shape:

batch_size X number_of_sequence X hidden_size
ex: 10 X 253 X 768  This tensor X is from the output of an LSTM.

There is another tensor Y, of shape:

batch_size X number_of_sequence X embedding_size
ex: 10 X 253 X 300  This tensor Y is the output from an Embedding.

I need to work with these 2 tensors X and Y and feed this to an Attention network to match the sequence Y to each element in X. I need bit help as to which operations would be better to pack X and Y  Since I am coding in pytorch, if I do torch.cat((X, Y), dim=2) will this be a good idea?",4,5
85,2018-8-14,2018,8,14,23,978qd9,Why all the excitement about artificial intelligence?,https://www.reddit.com/r/deeplearning/comments/978qd9/why_all_the_excitement_about_artificial/,ElegantFeeling,1534256275,"https://medium.com/@mihail_eric/why-all-the-excitement-about-artificial-intelligence-435957ba9ed3
",4,0
86,2018-8-15,2018,8,15,1,979m78,"Deep Learning; Personal Notes Part 1 Lesson 2, Learning rate, Data Augmentation, Annealing, Test",https://www.reddit.com/r/deeplearning/comments/979m78/deep_learning_personal_notes_part_1_lesson_2/,keghn,1534262685,,0,16
87,2018-8-15,2018,8,15,2,97agre,attn_gan_pytorch: python package for building attention based GANs,https://www.reddit.com/r/deeplearning/comments/97agre/attn_gan_pytorch_python_package_for_building/,akanimax,1534268659,,0,2
88,2018-8-15,2018,8,15,10,97e3re,Starting Deep Learning (not from scratch),https://www.reddit.com/r/deeplearning/comments/97e3re/starting_deep_learning_not_from_scratch/,notepad---,1534295913,"Hello everyone,

I am a student actively interested in deep learning and computer science. I have completed the 5 course specialization on Coursera from [Deeplearning.AI](https://Deeplearning.AI), and I understand the concepts and linear algebra behind this very well. I was thinking about doing [fast.AI](https://fast.AI) next, since I have heard that it provides a lot of documentation and tutorials on how to increase deep learning skills. 

I was wondering if you all had any suggestions regarding some other things I can do to practice and enhance my deep learning skills? Right now, I have experience with ANNs and CNNS, and am mildly familiar with RNNs. However, I also want to learn more about GANs since they are growing in popularity.

Thanks,

notepad---",2,15
89,2018-8-15,2018,8,15,13,97fk7z,how to log (evetything) and handle correctly the multiple hyperparameters,https://www.reddit.com/r/deeplearning/comments/97fk7z/how_to_log_evetything_and_handle_correctly_the/,finallyifoundvalidUN,1534309092,"It's how I log (everything) and handle correctly the multiple hyperparameters that arise in my deep learning projects:

https://cs230-stanford.github.io/logging-hyperparams.html#logging

I have a file that I log every command that I use, so it's a terrible kind of logging of hyper-parameters, but honestly I don't know how to effectively do these stuff. I know of sacred and fglab, but I haven't had the time to start using them in my project.
What do you do?",0,1
90,2018-8-15,2018,8,15,15,97fyoa,Making a CNN model according to a presented architecture,https://www.reddit.com/r/deeplearning/comments/97fyoa/making_a_cnn_model_according_to_a_presented/,suraty,1534313460,"Hello,
I would like to make a model in Keras whose architecture should be as below and the *relu* function is applied to it.
I just have this information:
Layer 		Name 		Parameters 		Dimensions 	Parameter Scale
Input	 	 		 			(1, 236, 20) 		
Layer 1 		Convolution 	Filter (256, 3, 3) 	(256, 236, 20) 		2304
Layer 1 		Pooling 		Pooling (2, 2) 		(256, 118, 10) 		0
Layer 2 		Convolution 	Filter (128, 3, 3) 	(128, 118, 10) 		1152
Layer 2 		Pooling 		Pooling (2, 2) 		(128, 59, 5) 		0
Layer 3 		Convolution 	Filter (64, 3, 3) 		(64, 59, 5) 		576
Layer 3 		Pooling 		Pooling (2, 2) 		(64, 30, 3) 		0
Layer 4 		Data flatten 		 		(5760, ) 		0
Layer 4 		Fully-connected 	 		(1180, ) 		6,796,800
Output		  			 		(1180, ) 		

My codes:
      model = models.Sequential()
    model.add(Conv2D(256,(3, 3),
                     activation='relu',
                     input_shape=(236,20,1), padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))

    model.add(Flatten())
    model.add(Dense(1180))

    model.summary()


Is my code true for that architecture? Isn't there a nonlinear activation on the layers?

And any other opinions.

Thank you",2,5
91,2018-8-15,2018,8,15,17,97glat,Can learning image transformations improve prediction accuracy?,https://www.reddit.com/r/deeplearning/comments/97glat/can_learning_image_transformations_improve/,LiorZim,1534321560,"Hi Everyone,

I have created a network for the classification of cell cultures into wildtype and mutants.

Since I'm pretty new to this - I'm wondering - is there any value to creating layers that are meant to apply image transformations?

For example: applying a gamma transformation where gamma is a learned parameter. 

In my case. when certain transformations are applied to the images (adjusting contrast, brightness selectively)  the distinction is made much more easily (at least by my inferior human visual cortex...)

Thanks!",4,2
92,2018-8-16,2018,8,16,4,97lagz,Don't use dropout in convolutional networks.,https://www.reddit.com/r/deeplearning/comments/97lagz/dont_use_dropout_in_convolutional_networks/,Harrisonjansma,1534361698,[https://towardsdatascience.com/dont-use-dropout-in-convolutional-networks-81486c823c16](https://towardsdatascience.com/dont-use-dropout-in-convolutional-networks-81486c823c16),3,16
93,2018-8-16,2018,8,16,12,97oyih,Top 11 Deep Learning and Neural Networks Books,https://www.reddit.com/r/deeplearning/comments/97oyih/top_11_deep_learning_and_neural_networks_books/,kjahan,1534391168,,0,1
94,2018-8-16,2018,8,16,13,97pcuc,"MXNet implementation of the paper ""Neural Arithmetic Logic Units"" by DeepMind",https://www.reddit.com/r/deeplearning/comments/97pcuc/mxnet_implementation_of_the_paper_neural/,gautamrbharadwaj,1534395026,,0,1
95,2018-8-16,2018,8,16,16,97q49r,CFP: ZhejiangLab Cup Global Artificial Intelligence Competition 2018,https://www.reddit.com/r/deeplearning/comments/97q49r/cfp_zhejianglab_cup_global_artificial/,zcgaic2018,1534403322,"ZhejiangLab Global Artificial Intelligence Competition is held by Zhejiang Lab, Zhejiang Expert Committee on Artificial Intelligence Development (AI top 30), China Artificial Intelligence Industry Development Alliance (AIIA). As the sole competition platform, Zhejiang Lab-Tianchi Alibaba Cloud Platform invites participants to train their models on known classified samples to develop models to recognize unclassified samples.     

This competition consists of two separate contests: Video Recognition and Q&amp;A contest, and Zero-Shot Learning Picture Recognition contest. For **Video Recognition and Q&amp;A** contest, participants need to recognize, analyze specific videos and answer corresponding questions; for **Zero-shot Learning Picture Recognition** contest, participants need to train their models on known classified samples to develop models to recognize unclassified samples.

There is also an **Entrepreneurial Competition** about applying artificial intelligence to improve and solve technical matters in professional fields. The professional fields below are recommended but not required: medical Application (utilizing Artificial Intelligence to diagnose patients graphical); petty Commodities (applying Artificial Intelligence to analyze the costs of petty commodities); intelligent Manufacturing (applying Artificial Intelligence to manage the production of manufactures); education Application (utilizing Artificial Intelligence to evaluate education based on AI technology) and business Application (applying Artificial Intelligence to manage businesses etc.) For more details, please refer to [http://aicup2018.zhejianglab.com/](http://aicup2018.zhejianglab.com/) 

**1. Competition Schedule**

a. Preliminary contest: Aug. 1st  Sept. 25th, 2018

b. Semifinal contest: Sept. 28th  Oct. 30th, 2018

c. Final contest: Late November, 2018

**2.  Competition Participants**

The competition is available to the whole society. The upper limit of team size is five members, and there is no lower limit. Individuals related to the competition committee are not allowed to participate in any contest in this competition.

**3.  Registration**

Registration is now open until Sept. 25th, 2018. Click the link below to sign up.

**The official website of this competition:**

[http://aicup2018.zhejianglab.com/](http://aicup2018.zhejianglab.com/)

**Zero-shot Learning Picture Recognition:** [https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.11409391.333.2.3b1f49feMjToDE&amp;raceId=231677](https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.11409391.333.2.3b1f49feMjToDE&amp;raceId=231677) 

**Video Recognition and Q&amp;A:** [https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.11409391.333.4.3b1f49feMjToDE&amp;raceId=231676](https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.11409391.333.4.3b1f49feMjToDE&amp;raceId=231676) 

**Entrepreneurial Competition**

[http://zhejianglab.mikecrm.com/OBBxe7a](http://zhejianglab.mikecrm.com/OBBxe7a) 

**4.  Competition Awards**

**a. Financial Awards** 

\- First place:1 team, **500,000 CNY** with award diploma

\- Second place:2 teams, **250,000 CNY** with award diplomas

\- Third place:3 teams, **100,000 CNY** with award diplomas

\- Honorable mention:4 teams, **10,000 CNY** with award diplomas

**b. Other Awards**

**Internship offers**Top 3 teams in the final contest will receive internship offers from Zhejiang Lab. Only one member in each team has the opportunity of receiving internship offer;

**Final round interview offers**: Top 10 teams from semifinal contest will receive final round interview offers from Zhejiang lab. Only two members in each team have the opportunities of receiving final round interview offers;

**Writing examination exemption**: Every team and individual who participates in semifinal contest are exempt from writing examination when applying to the Zhejiang Lab. The mentioned participants have the privilege to participate in Zhejiang Labs first round interview directly.

**5.  Competition Organization**

\- Guidance Organization: Office of the Central Cyberspace Affairs Commission, The Peoples government of Zhejiang Province

\- Host: Zhejiang Lab, Zhejiang Expert Committee on Artificial Intelligence Development (AI top 30), China Artificial Intelligence Industry Development Alliance (AIIA)

\- Co-organizer: Administrative Committee of Zhejiang Hangzhou Future Sci-Tech City, Bank of Nanjing

\- Competition Platform: Zhejiang Lab-Tianchi Alibaba Cloud Platform ([aicup2018.zhejianglab.com](https://www.reddit.com/r/deeplearning/aicup2018.zhejianglab.com))

\- Organized by: Zhejiang Labs Center of Competition

\- Supported by: Zhejiang University, Hangzhou Dianzi University, Alibaba Cloud etc.

Announcement: The competition is a nonprofit, non-commercial competition, aiming to promote the development of artificial intelligence, and to provide a platform for individuals to research and study. Utilizing this competition or competition data for any commercial activities is prohibited.

**6. Contact us**

If you have any question, please contact us at [AICup2018@zhejianglab.com](mailto:AICup2018@zhejianglab.com). 

https://i.redd.it/z83v4socleg11.png",0,5
96,2018-8-16,2018,8,16,20,97rcwh,Does anyone know Tesseract 4 OCR model architecture?,https://www.reddit.com/r/deeplearning/comments/97rcwh/does_anyone_know_tesseract_4_ocr_model/,steamaacount,1534417823,,2,3
97,2018-8-16,2018,8,16,21,97rr61,A Quick Easy Guide to Deep Learning with Java  Deeplearaning4j / DL4J,https://www.reddit.com/r/deeplearning/comments/97rr61/a_quick_easy_guide_to_deep_learning_with_java/,Shilpa_Opencodez,1534421682,,0,17
98,2018-8-17,2018,8,17,1,97tj8z,Deep Learning to Detect Fake News with Uber ATG Head of Data Science - free webinar 8/21,https://www.reddit.com/r/deeplearning/comments/97tj8z/deep_learning_to_detect_fake_news_with_uber_atg/,TheDataIncubator,1534435229,,0,0
99,2018-8-17,2018,8,17,6,97wbr7,"From here to AI - ep. 003 with Jack Wells, Director of Science - Oak Ridge National Lab",https://www.reddit.com/r/deeplearning/comments/97wbr7/from_here_to_ai_ep_003_with_jack_wells_director/,keghn,1534454666,,0,2
100,2018-8-17,2018,8,17,7,97wtbc,How to derive P(h|v) for a spike-and-slab RBM?,https://www.reddit.com/r/deeplearning/comments/97wtbc/how_to_derive_phv_for_a_spikeandslab_rbm/,parcelpath,1534458366,"In paper *""Unsupervised Models of Images by Spike-and-Slab RBM""* (Courville, Bergstra, Bengio) it says:

But I don't know how to derive this equation.",0,1
101,2018-8-17,2018,8,17,7,97ww8i,How to derive P(h|v) of a spike-and-slab RBM (ssRBM)?,https://www.reddit.com/r/deeplearning/comments/97ww8i/how_to_derive_phv_of_a_spikeandslab_rbm_ssrbm/,parcelpath,1534459011,"In paper *""Unsupervised Models of Images by Spike-and-Slab RBM""* (Courville, Bergstra, Bengio) it says:

[ ](https://i.redd.it/znx4tfjj7jg11.png)

But I don't know how to derive this equation.",0,3
102,2018-8-18,2018,8,18,2,98480p,5 Deep Learning Breakthroughs You Should Know,https://www.reddit.com/r/deeplearning/comments/98480p/5_deep_learning_breakthroughs_you_should_know/,asifrazzaq1988,1534526904,,3,1
103,2018-8-18,2018,8,18,4,9856l3,Sign Language and Static-Gesture Recognition using CNN,https://www.reddit.com/r/deeplearning/comments/9856l3/sign_language_and_staticgesture_recognition_using/,blackbird9820,1534533825,,4,6
104,2018-8-18,2018,8,18,9,987jyw,Building complex deep learning systems,https://www.reddit.com/r/deeplearning/comments/987jyw/building_complex_deep_learning_systems/,adi1709,1534552582,"What is the general method of building large complex deep learning systems from scratch? 
Take for example YOLO - writing the code for this in one shot is not easy. How does one approach writing this from scratch? Specifically, debugging the inputs, then the loss function how does one go about putting each of these pieces together and making sure they work? ",4,5
105,2018-8-18,2018,8,18,14,9899g5,fpga options?,https://www.reddit.com/r/deeplearning/comments/9899g5/fpga_options/,ekmungi,1534569019,"Hey all,

I have a project which requires making choice of implementing a simple 5 layer CNN model on an fpga or not!

I have never programmed an fpga, but from what I read there are compilers for c++ to translate it with expensive translators.

I am working with a company on this and I am sure they have such translators. But the question is how translatable is a deep net?

Would implementing it using Caffe or Caffe2 be a viable solution in let's say 6 months? 

Thanks for your views.

Anant.",11,1
106,2018-8-19,2018,8,19,1,98cps5,AI Weekly 18 August 2018,https://www.reddit.com/r/deeplearning/comments/98cps5/ai_weekly_18_august_2018/,TomekB,1534608120,,0,1
107,2018-8-19,2018,8,19,11,98gziu,Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis,https://www.reddit.com/r/deeplearning/comments/98gziu/demystifying_parallel_and_distributed_deep/,dt_magic,1534645073,"Deep Neural Networks (DNNs) are becoming an important tool in modern computing applications. Accelerating their training is a major challenge and techniques range from distributed algorithms to low-level circuit design. In this survey, we describe the problem from a theoretical perspective, followed by approaches for its parallelization. Specifically, we present trends in DNN architectures and the resulting implications on parallelization strategies. We discuss the different types of concurrency in DNNs; synchronous and asynchronous stochastic gradient descent; distributed system architectures; communication schemes; and performance modeling. Based on these approaches, we extrapolate potential directions for parallelism in deep learning.",1,8
108,2018-8-19,2018,8,19,16,98ilcx,Hot Trend in Artificial Intelligence  Deep Learning | Analytics Insight,https://www.reddit.com/r/deeplearning/comments/98ilcx/hot_trend_in_artificial_intelligence_deep/,analyticsinsight,1534663341,,0,4
109,2018-8-20,2018,8,20,5,98n4h5,Switching to DeepLearning based career,https://www.reddit.com/r/deeplearning/comments/98n4h5/switching_to_deeplearning_based_career/,anilmaddala,1534709183,"I am a software enginner with good understanding on the deeplearning concepts. I completed courses from Andrew Ng and fastai.

However, I am not sure how to take my experience in developing Android apps to a deeplearning career. Any help or guidelines? I am in the process of going through papers from [https://www.reddit.com/r/MachineLearning/comments/8vmuet/d\_what\_deep\_learning\_papers\_should\_i\_implement\_to/](https://www.reddit.com/r/MachineLearning/comments/8vmuet/d_what_deep_learning_papers_should_i_implement_to/) and implementing them.",3,3
110,2018-8-20,2018,8,20,14,98qy5s,Full time ML carrer drom Javascript or web development background,https://www.reddit.com/r/deeplearning/comments/98qy5s/full_time_ml_carrer_drom_javascript_or_web/,benstark982,1534743064,"I am a javascript developer from India ,I have a few programming language during my high school and college days like c++ python matlab . So ML programming part was not difficult,i hade difficulty (Still struggling) with maths of it and getting a hang of ML ,i consider myself somewhere bw beginner to intermediate but i am not sure how i can switch my carrer to ML .please suggest. Moreover i would like to work in EU or canada how can work there on ML/AI. What should be the path.",1,0
111,2018-8-20,2018,8,20,15,98r3pt,PaperSpace Promo code August 2018 $15 Credit,https://www.reddit.com/r/deeplearning/comments/98r3pt/paperspace_promo_code_august_2018_15_credit/,niraj_ag,1534744809,"[https://www.paperspace.com/&amp;R=691Z1O4](https://www.paperspace.com/&amp;R=691Z1O4)

Promo code: 691Z1O4 

Click Above Link or go to billing page in Paperspace: [https://www.paperspace.com/console/account/billing](https://www.paperspace.com/console/account/billing)

Copy &amp; Paste Promo code --&gt; Click Apply 

You have your credit.  ",9,2
112,2018-8-20,2018,8,20,15,98r79b,Resources to practice deep learning?,https://www.reddit.com/r/deeplearning/comments/98r79b/resources_to_practice_deep_learning/,hardhat528491,1534745909,"I have sound knowledge of CNNs and have implemented popular datasets like MNIST, CIFAR-10 etc in PyTorch for image classification. I want to practice deep learning for computer vision to get better at it. Where should I start? Or what should I do next?",3,1
113,2018-8-20,2018,8,20,17,98rx6m,Free eBook: Python Deep Learning [PDF],https://www.reddit.com/r/deeplearning/comments/98rx6m/free_ebook_python_deep_learning_pdf/,PacktStaff,1534754570,,3,3
114,2018-8-20,2018,8,20,22,98tsk7,"Speech recognition model, Vocabulary",https://www.reddit.com/r/deeplearning/comments/98tsk7/speech_recognition_model_vocabulary/,albert1905,1534773510,"Hi guys, I'm working on Speech recognition model, and I have a difficult time to think about the vocabulary concept.
When I Worked on a language model, I had 2 Vocabularies, one for each language (I saw some with 1 vocabulary for both languages).
So now I have only 1 vocabulary? or I'm missing something ?!

Thanks!",0,4
115,2018-8-21,2018,8,21,0,98ulj1,Are tensorflow pre made models or pytorch models better?,https://www.reddit.com/r/deeplearning/comments/98ulj1/are_tensorflow_pre_made_models_or_pytorch_models/,Arkhaya,1534779115,"I've been using tensorflow for a few months and am quite well versed in it and I've also seen things about pytorch.

And I'm trying to make a prototype with pre-trained model.

I have no idea about pytorch and how retraining works.

Should I just continue on tensorflow or change over to pytorch? I am pretty deep into my prototype but I do have a complete dataset to train off of.",1,2
116,2018-8-21,2018,8,21,2,98vkgu,How older aged devs outpace their peers and should get respect,https://www.reddit.com/r/deeplearning/comments/98vkgu/how_older_aged_devs_outpace_their_peers_and/,programming-innovate,1534785911,"How older aged devs outpace their peers and should get respect - https://ift.tt/2nQ6Me7, recommended on August 20, 2018 at 03:52PM
   
   
",0,1
117,2018-8-21,2018,8,21,2,98vtik,[P] TensorFlow.js video and blog series - Deep Learning in the Browser with JavaScript,https://www.reddit.com/r/deeplearning/comments/98vtik/p_tensorflowjs_video_and_blog_series_deep/,blackHoleDetector,1534787618,"- [Click here for the video series only](https://www.youtube.com/playlist?list=PLZbbT5o_s2xr83l8w44N_g3pygvajLrJ-)  
- [Click here for the blog and video series](http://deeplizard.com/learn/playlist/PLZbbT5o_s2xr83l8w44N_g3pygvajLrJ-)

In this series, we'll learn how to deploy and run models, along with full deep learning applications, in the browser! To implement this cool capability, well use TensorFlow.js (TFJS), TensorFlows JavaScript library, which allows us to build and access models in JavaScript. Topics include client-server deep learning architectures, converting Keras models to TFJS models, serving models with Node.js, building deep learning browser applications, tensor operations, and more!",0,1
118,2018-8-21,2018,8,21,9,98yqcy,Tensorflow Implementation of NALU,https://www.reddit.com/r/deeplearning/comments/98yqcy/tensorflow_implementation_of_nalu/,Ragabov,1534811398,"Here is my implementation of the NALU, I have managed to replicate the results for the first part of the experiments, but contributions are more than welcome.

NOTE : the repo is a work in progress.  


[https://github.com/Ragabov/tensorflow-nalu](https://github.com/Ragabov/tensorflow-nalu)",0,7
119,2018-8-21,2018,8,21,20,9929mw,Are NALUs hard to train?,https://www.reddit.com/r/deeplearning/comments/9929mw/are_nalus_hard_to_train/,Ragabov,1534849769,"I have tried to replicate the results provided in the Neural Arithmetic Logical Unit paper proposed here r/https://arxiv.org/abs/1808.00508, but seems like i usually get stuck in a local optima. I have tried to use multiple initialization functions, although some are better than others, most of them would eventually get optimized towards a local optimum.

The NALU for those who don't know tries to get the model to actually learn a set of arithmetic operations (+, -, \*, /) between the inputs to generate the expected output. This is basically attempted by learning weight matrices that would indicate an addition or subtraction operation each represented by (1 or -1) while 0 would mean that the input is irrelevant, and to indicate multiplication/division, similar weights are applied on the log of the inputs.

Why i do think this would lead the model to optimize towards a local minima, let's take the \`Arithmetic Synthetic Task\` for example, in this task the inputs are a set of vectors of real numbers, and the output is basically the sum over the numbers of two random but consistent subsections of the vector, say \`a\` and \`b\`, and then applying one of the arithmetic ops to the two sums, (a + b, a - b, a \* b, a / b). So let's take this concrete example where the arithmetic op is addition :

V = \[600, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100\]

s1 = \[10,20,30,40\], s2 = \[50,60,70,80,90,100\]

then a = 100 and b = 450

output = 550

So the model will see the vector \`V\` as the input and 550 as the output, the shortest way to optimize for this output is to add the 1st element of the vector and neglect all others as the gradients would most probably be boosted toward the largest elements of the vector, this would cause the greatest straightforward decrease in the loss (MSE) and the model would most probably keep optimizing towards it, until it get over the expected output, then it might learn to subtract some of the other elements in the vector.

What i am trying to say is, that this specific task is quite tricky to learn as there are multiple ways to generate that specific output using this approach, i do also know that usually the inputs are provided in large batches so that the pattern is quite obvious, but i do think that this depends heavily on the distribution of the inputs and the input size, if V was a vector of 10000 elements all in range of -5 to 5, this would result in an enormous amount of combinations possible to generate the true output which would cause the model to optimize towards one of those many local minimum and it might be too deep to escape.

So what do you guys think ?, is there any possible ways to tweak the model towards the global minimum !?

Below is my implementation of the NALU, you can check the experiments directory to tweak and re-run the experiment, any contributions are more than welcome.

r/https://github.com/Ragabov/tensorflow-nalu

Note that the repo is a work in progress.",1,3
120,2018-8-22,2018,8,22,0,9945hh,GPUBay.com - Computer Bay Adapters for Graphics Cards,https://www.reddit.com/r/deeplearning/comments/9945hh/gpubaycom_computer_bay_adapters_for_graphics_cards/,techtot,1534865601,"Hi Guys,

We have developed a bracket which allows your unused computer bays, usually reserved for DVD ROM drives, to be utilized by graphics cards.  We have just started selling these brackets after a year of development and testing.  We have built a few systems for researchers/developers using the adapter, saving them space and making for a better looking machine.  

https://gpubay.com/

",0,0
121,2018-8-22,2018,8,22,1,994izv,Collection of online resources for Audio-Visual Speech Recognition (AVSR) using Deep Learning,https://www.reddit.com/r/deeplearning/comments/994izv/collection_of_online_resources_for_audiovisual/,invincible_guy,1534868195,,0,13
122,2018-8-22,2018,8,22,4,995ywb,"I built a beginning to end Self Driving Car course using Deep Learning. Im giving it away for free for the first 200 students. Click the link to activate coupon, I hope you enjoy it!",https://www.reddit.com/r/deeplearning/comments/995ywb/i_built_a_beginning_to_end_self_driving_car/,nottingpill,1534878147,,0,1
123,2018-8-22,2018,8,22,5,996yqb,Deep learning,https://www.reddit.com/r/deeplearning/comments/996yqb/deep_learning/,sanchit2843,1534885080,"sanchit tanwar:
Hello guys, i am studying deep learning for 6 months now and dont know what to do next. Every project is either too small or very big. What should be my next step in deep learning?",3,1
124,2018-8-22,2018,8,22,9,998iev,"I built a beginning to end Self Driving Car course using Deep Learning. Im giving it away for free for the first 200 students. Click the link to activate coupon, I hope you enjoy it!",https://www.reddit.com/r/deeplearning/comments/998iev/i_built_a_beginning_to_end_self_driving_car/,ameero1234,1534896674,,0,1
125,2018-8-22,2018,8,22,10,9990ug,Font Recognizer Java using Self Organizing Map,https://www.reddit.com/r/deeplearning/comments/9990ug/font_recognizer_java_using_self_organizing_map/,farhantariq560,1534900904,I have my project to develop a font recognizer . Not familiar with the java D4LG library and Artificial neural networks in general . Please guide me with best approach to learn about ANN and SOM and then do the D4LG library will be useful to implement the solution . Thanks in advance,0,2
126,2018-8-22,2018,8,22,14,99ali1,Looking to retrain tensorflow inception resnet v3 on animated GIFs.,https://www.reddit.com/r/deeplearning/comments/99ali1/looking_to_retrain_tensorflow_inception_resnet_v3/,Arkhaya,1534914974,,0,4
127,2018-8-23,2018,8,23,0,99eio2,"Serverless as a Success, explained from a vendor-free view",https://www.reddit.com/r/deeplearning/comments/99eio2/serverless_as_a_success_explained_from_a/,programming-innovate,1534953368,[removed],0,1
128,2018-8-23,2018,8,23,2,99fei9,[D] Why is my computational graph of a (convolutional) variational auto-encoder in tensorflow so ugly? [x-post r/MachineLearning],https://www.reddit.com/r/deeplearning/comments/99fei9/d_why_is_my_computational_graph_of_a/,MaximilioneinHD,1534959552,,5,1
129,2018-8-23,2018,8,23,3,99fpz2,[P] MSG-GAN: Multi-Scale Gradients GAN,https://www.reddit.com/r/deeplearning/comments/99fpz2/p_msggan_multiscale_gradients_gan/,akanimax,1534961728,"I thought of an alternative solution to the problem of irrelevant gradients for images generated at higher resolutions apart from the layer-wise training of Progressive growing of GANs.

The proposed solution is to allow flow of gradients from the discriminator to the generator at multiple scales. The architecture uses single Generator and single Discriminator, but due to the connections between the intermediate layers of Generator and the intermediate layers of Discriminator, the architecture resembles the ""U-Net"" architecture.

I ran an experiment of training this GAN on Celeba. Following are links for more info:

medium blog -&gt; https://medium.com/@animeshsk3/msg-gan-multi-scale-gradients-gan-ee2170f55d50

pytorch code -&gt; https://github.com/akanimax/MSG-GAN

video of samples generated during training -&gt; https://www.youtube.com/watch?v=9v46ygTQ6cw",0,5
130,2018-8-23,2018,8,23,4,99g9yf,"Towards AI: How long does it take you to go from idea to working prototype? - a day, a month?",https://www.reddit.com/r/deeplearning/comments/99g9yf/towards_ai_how_long_does_it_take_you_to_go_from/,tdionis,1534965656,,0,1
131,2018-8-23,2018,8,23,6,99h5ol,1x 2080Ti vs 2x 1080Ti for Deep Learning,https://www.reddit.com/r/deeplearning/comments/99h5ol/1x_2080ti_vs_2x_1080ti_for_deep_learning/,TacticalFloridaMan,1534972018,"I've been wanting to build a beefy system (for both DL, ML, and Gaming) and now that the 1080Ti's are discounted, I was wondering what everyone thought.

Would 1x 2080Ti be better than 2x 1080Ti's? The former is supposedly faster, but the latter has double the memory so you can increase the batch sizes.

cost of 1x 2080Ti  cost of 2x 1080Ti (with the new discounts)",21,29
132,2018-8-23,2018,8,23,15,99l2b7,Is my dataset any good for pix2pix?,https://www.reddit.com/r/deeplearning/comments/99l2b7/is_my_dataset_any_good_for_pix2pix/,audovoice,1535006431,"[https://imgur.com/gallery/uuAZ4D6](https://imgur.com/gallery/uuAZ4D6)

This is a portion of a data set I made using sliced up  Impressionists paintings. 

This is the first time I am using pix2pix for something like this. 

Does anyone know just by looking at a few images, if it looks like it will work or not? 

I am 11 epochs in. ",1,1
133,2018-8-23,2018,8,23,20,99mri3,Any tutorials/links to build a closed domain Chatbot?,https://www.reddit.com/r/deeplearning/comments/99mri3/any_tutorialslinks_to_build_a_closed_domain/,mankadronit,1535025549,I want to build a closed domain Chatbot (for example: a Chatbot to order pizza). Can anyone give me some important tutorials/links so I can get started. I have seen quite a few tutorials on Seq2Seq General Chatbots but they are all open domain.,3,8
134,2018-8-23,2018,8,23,21,99mzrr,GOTO 2018  Deep Learning for Developers  Julien Simon,https://www.reddit.com/r/deeplearning/comments/99mzrr/goto_2018_deep_learning_for_developers_julien/,rick-rebel,1535027614,,0,1
135,2018-8-24,2018,8,24,0,99o4ea,Free 1080Ti GPUs for AI startups,https://www.reddit.com/r/deeplearning/comments/99o4ea/free_1080ti_gpus_for_ai_startups/,whitezl0,1535036547,"Hi there,

I am developing a cloud platform and offering free 1080Ti cloud instance(s) for data scientists and deep learning startups to use. I believe that there are many companies in this thread that are experienced and have valuable insights regarding the industry. I would like to learn more about your product, achievements, and challenges in the field of artificial intelligence.

Is there anyone who would like to chat more?
Please, fill out the 1-question form and let's chat. https://goo.gl/forms/dYWnw3CUSY4kjuTo1
After a quick chat, I will set you up with the free access to GPU instances.",1,0
136,2018-8-24,2018,8,24,0,99ogny,AMD CPU + Nvidia GPUs for deep learning,https://www.reddit.com/r/deeplearning/comments/99ogny/amd_cpu_nvidia_gpus_for_deep_learning/,multiks2200,1535038948,"Hi,  


I'm trying to build a deep learning system. I'm thinking of which CPU to get. The main bottleneck currently seems to be the support for the # of PCIe lanes, for hooking up multiple GPUs. Ideally, I would like to have at least two, that is 2x16 PCIe 3.0 GPUs working. Many modern Intel processors support up to 28 of PCIe lanes (and that's only top end i7s). If one needs more, only the expensive i9s offer that (or some older, discontinued i7s)   


At the same time, AMD offers even up to 64 PCIe Lanes with Ryzen Threadripper, or even the older FX9590, which I believe offers 40 PCIe lanes (for some reason AMD makes is really hard to find the # of PCIe lanes information)  


Therefore I was wondering if anyone has got any experience of hooking up together an AMD CPU with Nvidia GPUs for running deep learning simulations with Tensorflow, Pytorch etc?  


Does that work fine, is it inferior in any way to an Intel Setup?  


Thanks in advance.",9,3
137,2018-8-24,2018,8,24,4,99qgel,"Computer upgrade planning questions, factoring in ML/DL",https://www.reddit.com/r/deeplearning/comments/99qgel/computer_upgrade_planning_questions_factoring_in/,S54Holden,1535052843,"Hi all,

Forgive me if this is the wrong subreddit for this sort of question, I am new to this.

I'm currently taking classes on deep learning (via Coursera and Udacity), and am starting to tinker with things. I've got a few projects I'm working on and, on the whole, am really getting into this. It's also time to upgrade my computer. That said, I'm at a hobbyist level with this, not a researcher or professional (yet?).

I'm currently running an Intel X58 platform Xeon, OC'd heftily, and have 2x R9 290 GPUs. It's a trusty computer but it's definitely an aged platform. I used it primarily for gaming and matlab/CAD work in school, and now am using it for ML/DL and occasional gaming use. Gaming definitely isn't a focus anymore, maybe once every couple weeks I'll be bored enough to play something.

As I'm considering what to upgrade, I have some questions that are more ML/DL oriented than generic PC building questions. I'd really appreciate any insight you all have! I've been googling and researching these questions but haven't found much that's helpful.

I'm considering two upgrade paths: 1) Upgrade GPU only (1080ti or 2080ti are the contenders for CUDA core count and tensor core counts, respectively) 2) upgrade full platform (CPU/Ram/GPU, likely Threadripper platform).

**bold**CPU Questions:
*Is the AVX instruction set critically important for numpy/tensorflow stuff? Image processing?
*Am I losing out on anything by continuing to limp along my trusty non-AVX Xeon until the 7/10nm chips come out next year?

**bold**GPU Questions: 
*My current motherboard is PCIe-2.0. A GPU running in 16x 2.0 is getting roughly the same bandwidth as 8x 3.0. 
*Has anyone experienced this being an issue? I know it'll theoretically bottleneck, but is it going to drastically affect training/processing times?
*Is OpenCL compelling enough to consider a AMD GPU upgrade? Or is CUDA pretty much the only game in town?

Thanks!
",11,6
138,2018-8-24,2018,8,24,19,99wcpx,Benefits of Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/99wcpx/benefits_of_artificial_intelligence/,seoaleait,1535107357,,0,0
139,2018-8-25,2018,8,25,15,9a4th8,Why running the same code on the same data gives a different result every time?,https://www.reddit.com/r/deeplearning/comments/9a4th8/why_running_the_same_code_on_the_same_data_gives/,suraty,1535178528,"Hello,

I am using Keras in Jupyter Notebook.

I understood that for the same results, the random numbers should be produced from the same seed each time.

So, in the first of all my codes, I set random.seed as 1234 in a cell.

    np.random.seed(1234)

Then Other cells are the codes of my model and the fit and evaluate codes. But each time that I run the model cells, the Loss values are different! 

Why does it happen? How can I solve it?

Thank you very much
",3,3
140,2018-8-25,2018,8,25,19,9a5uyu,AI Weekly 25 August 2018,https://www.reddit.com/r/deeplearning/comments/9a5uyu/ai_weekly_25_august_2018/,TomekB,1535192980,,0,1
141,2018-8-25,2018,8,25,21,9a6e8c,CPU RAM vs GPU VRAM usage when training models.,https://www.reddit.com/r/deeplearning/comments/9a6e8c/cpu_ram_vs_gpu_vram_usage_when_training_models/,multiks2200,1535199718,"I was wondering how does the typical CPU RAM to VRAM pipeline looks like? Let's say I load a model to train, how does the data transfer is performed ? Is it HDD -&gt; RAM -&gt; VRAM or CPU transfers the data straight from HDD -&gt; VRAM ? If RAM is involved, does that mean there is redundant data stored in RAM simply because it is required for filling up the VRAM? ",1,8
142,2018-8-26,2018,8,26,1,9a82ht,Free servers with 1080Ti for deep learning,https://www.reddit.com/r/deeplearning/comments/9a82ht/free_servers_with_1080ti_for_deep_learning/,whitezl0,1535214843,"I am offering free 1080Ti GPU instances for deep learning.

Sign up at https://dashboard.tensorpad.com/signup

- The instances have 16GB RAM, 4 CPUs cores, and one 1080Ti GPU and you can run multiple instances in parallel.

- Instances run on customized JupyterLab images (Fast.ai, PyTorch 0.4, TensorFlow+Keras 1.10, 1.9, 1.8, 1.7 and 1.5 on CuDNN 9.0)

- You can access the command line and use it as a dedicated server for training

Our goal is to lower the entry barrier for deep learning so we will work hard to make sure we support the community. We are inviting you to help us learn how we can better support researchers in the field of AI. We want to improve the product, and so we are exploring the community feedback.

We will be providing free GPU time, reaching out to the registered users and asking for feedback. If this sounds like something that would fit you, sign up at https://dashboard.tensorpad.com/signup

Contact for support@tensorpad.com",13,36
143,2018-8-26,2018,8,26,22,9afddt,How the initial (default) binary-values of the neurons in the ANN gets determined when we training them?,https://www.reddit.com/r/deeplearning/comments/9afddt/how_the_initial_default_binaryvalues_of_the/,Anyone_Someone2018,1535288629,"I am currently reading a paper on the mathematics lying behind of the ANN, how they inspired from biological neurons, how they work etc. 

&amp;#x200B;

The paper says that when the synapses (the input weight from a neuron to the another neuron) and thresholds (the minimum required input value which is necessary for the neuron to fire) is getting determined (namely, ANN gets trained), also the initial binary values (firing or not firing, true or false) of these neurons gets determined. So that when the weighted input not exceeds the threshold of the neuron, but exceptionally equal to it, we can use this initial value as our most optimal output. 

&amp;#x200B;

But then, how is it getting calculated? Understanding the calculation of the synapses and threshold is very intuitive, but this make me confused.

&amp;#x200B;

[The article i am reading: A Begginers Guide to Mathematics of Neural Networks](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.3556&amp;rep=rep1&amp;type=pdf)[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.3556&amp;rep=rep1&amp;type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.3556&amp;rep=rep1&amp;type=pdf)

&amp;#x200B;",2,1
144,2018-8-27,2018,8,27,7,9ajhno,Busting Moves with DanceNet AI,https://www.reddit.com/r/deeplearning/comments/9ajhno/busting_moves_with_dancenet_ai/,trcytony,1535321561,,0,13
145,2018-8-27,2018,8,27,19,9anw6t,5 things to know about Deep Learning | machine learning | Yourtechdiet,https://www.reddit.com/r/deeplearning/comments/9anw6t/5_things_to_know_about_deep_learning_machine/,cwadamsmith,1535366796,,1,0
146,2018-8-28,2018,8,28,2,9ar4wk,Can unsupervised learning be powered by neural deep nets?,https://www.reddit.com/r/deeplearning/comments/9ar4wk/can_unsupervised_learning_be_powered_by_neural/,kruelc,1535392178,"Newbie question: can I have deep neural networks applied to unsupervised learning? Seems to me that deep learning relates to reinforcement and supervised learning only.

",7,0
147,2018-8-28,2018,8,28,7,9atcdg,Como la inteligencia artificial est cambiando a los retailers.,https://www.reddit.com/r/deeplearning/comments/9atcdg/como_la_inteligencia_artificial_est_cambiando_a/,chevelle102,1535408155,,0,1
148,2018-8-28,2018,8,28,7,9athpn,Detectar el idioma de un texto con redes neuronales LSTM,https://www.reddit.com/r/deeplearning/comments/9athpn/detectar_el_idioma_de_un_texto_con_redes/,chevelle102,1535409339,,0,2
149,2018-8-28,2018,8,28,13,9avzn6,How to handle 2 input representations of a data with the same label?,https://www.reddit.com/r/deeplearning/comments/9avzn6/how_to_handle_2_input_representations_of_a_data/,melonochelo,1535431284,,0,2
150,2018-8-28,2018,8,28,16,9awu2g,Learn Data Science  Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/9awu2g/learn_data_science_deep_learning_in_python/,plpface,1535440914,,0,2
151,2018-8-28,2018,8,28,16,9awuro,Early stopping and final Loss or weights of models,https://www.reddit.com/r/deeplearning/comments/9awuro/early_stopping_and_final_loss_or_weights_of_models/,suraty,1535441154,"Hello,
In a deep model, I used the Early stopping technique as below in Keras:

    from keras.callbacks import EarlyStopping
    
    early_stopping = [EarlyStopping(monitor='val_loss',
                              min_delta=0,
                              patience=2,
                              verbose=2, mode='auto')]

    model.fit(train_x, train_y, batch_size=batch_size,
                    epochs=epochs, verbose=1,
                    callbacks=early_stopping,
                    validation_data=(val_x, val_y))

    model.fit(train_x, train_y, batch_size=batch_size, 
                    epochs=epochs, verbose=2, 
                    callbacks=early_stopping,
                    validation_data=(val_x, val_y))

Now, when I run these codes, In the output, It prints the loss value for training and validation of each epoch.

I set the patience=2 in the early stopping. So, it continues the training process two times after when the validation loss increased instead of decreased. 

Some things like this:

    Epoch 1/10
    - 198s - loss: 99.7160 - val_loss: 123.0397 
    Epoch 2/10
    - 204s - loss: 78.7000 - val_loss: 109.0344 
    Epoch 3/10
    - 208s - loss: 65.4412 - val_loss: 78.0097 
    Epoch 4/10
    - 268s - loss: 61.9812 - val_loss: 79.0312
    Epoch 5/10
    - 298s - loss: 59.1124 - val_loss: 79.3397 
    Epoch 6/10
    - 308s - loss: 57.2200 - val_loss: 218.0397 
    Epoch 00007: early stopping

In the end, what will be the final weights of the model and the Loss values? The final epoch of training or two times before it?

If it considers the final epoch, so should it be better if I set the patience as little as possible to overcome the overfitting?

Thank you",1,3
152,2018-8-28,2018,8,28,20,9ay5jb,Humble Bundle: Machine Learning by O'Reilly,https://www.reddit.com/r/deeplearning/comments/9ay5jb/humble_bundle_machine_learning_by_oreilly/,MrZantag,1535456379,,2,18
153,2018-8-28,2018,8,28,21,9ayewl,"I am trying to practice gradient descent learning with a simple Python script i wrote, but the algorithm not works as required. What is the problem?",https://www.reddit.com/r/deeplearning/comments/9ayewl/i_am_trying_to_practice_gradient_descent_learning/,Anyone_Someone2018,1535458706,"I am reading the following [tutorial](http://neuralnetworksanddeeplearning.com/chap1.html), and in exercises i see that: 

&amp;#x200B;

&gt;I explained gradient descent when *C* is a function of two variables, and when it's a function of more than two variables.  What happens when *C* is a function of just one variable? Can you provide a geometric interpretation of what gradient descent is doing in the one-dimensional case?

&amp;#x200B;

After that i think it would be a good exercise to implement such a system for comprehending the topic better, and i wrote Python script. But the algorithm not works as it is required.

&amp;#x200B;

[Here](https://github.com/CprogrammerIbrahim/deeplearningtrials/blob/master/ANN.py) is the source code. The results are written at the bottom of the code.

&amp;#x200B;",0,1
154,2018-8-28,2018,8,28,23,9azfku,Level Up Your ML Code from Notebook to Production,https://www.reddit.com/r/deeplearning/comments/9azfku/level_up_your_ml_code_from_notebook_to_production/,freducom,1535466897,,2,3
155,2018-8-29,2018,8,29,5,9b2fp7,Xeon v. i7 for DL rig,https://www.reddit.com/r/deeplearning/comments/9b2fp7/xeon_v_i7_for_dl_rig/,minutestomidnight,1535487800,"I work at a lab where we are budgeted \~$2000 to make a DL rig for research purposes. This is one iteration of the type of rig that we will build, however, I am torn between choosing a Xeon processor or some variant of an i7. 

Thoughts? Suggestions? Recommendations for the motherboard and CPU? - as these are my sticking points. 

&amp;#x200B;

\[PCPartPicker part list\]([https://pcpartpicker.com/list/d3PWzY](https://pcpartpicker.com/list/d3PWzY)) / \[Price breakdown by merchant\]([https://pcpartpicker.com/list/d3PWzY/by\_merchant/](https://pcpartpicker.com/list/d3PWzY/by_merchant/))

&amp;#x200B;

Type|Item|Price

:----|:----|:----

\*\*CPU\*\* | \[Intel - Xeon E5-2670 2.6GHz 8-Core Processor\]([https://pcpartpicker.com/product/rBkD4D/intel-cpu-bx80621e52670](https://pcpartpicker.com/product/rBkD4D/intel-cpu-bx80621e52670)) | $137.09 @ Newegg Marketplace 

\*\*CPU Cooler\*\* | \[Corsair - H60 54.0 CFM Liquid CPU Cooler\]([https://pcpartpicker.com/product/Vwdqqs/corsair-cpu-cooler-h60cw9060007ww](https://pcpartpicker.com/product/Vwdqqs/corsair-cpu-cooler-h60cw9060007ww)) | $89.89 @ OutletPC 

\*\*Motherboard\*\* | \[MSI - X99A GAMING 7 ATX LGA2011-3 Motherboard\]([https://pcpartpicker.com/product/8KZ2FT/msi-motherboard-x99agaming7](https://pcpartpicker.com/product/8KZ2FT/msi-motherboard-x99agaming7)) |-

\*\*Memory\*\* | \[Corsair - Vengeance LPX 32GB (2 x 16GB) DDR4-2133 Memory\]([https://pcpartpicker.com/product/wMvZxr/corsair-memory-cmk32gx4m2a2133c13](https://pcpartpicker.com/product/wMvZxr/corsair-memory-cmk32gx4m2a2133c13)) | $279.74 @ Newegg 

\*\*Storage\*\* | \[PNY - CS1311 240GB 2.5"" Solid State Drive\]([https://pcpartpicker.com/product/7v38TW/pny-internal-hard-drive-ssd7cs1311240rb](https://pcpartpicker.com/product/7v38TW/pny-internal-hard-drive-ssd7cs1311240rb)) | $59.99 @ Amazon 

\*\*Storage\*\* | \[Seagate - Barracuda 2TB 3.5"" 7200RPM Internal Hard Drive\]([https://pcpartpicker.com/product/CbL7YJ/seagate-barracuda-2tb-35-7200rpm-internal-hard-drive-st2000dm006](https://pcpartpicker.com/product/CbL7YJ/seagate-barracuda-2tb-35-7200rpm-internal-hard-drive-st2000dm006)) | $59.59 @ OutletPC 

\*\*Video Card\*\* | \[EVGA - GeForce GTX 1080 Ti 11GB iCX GAMING Video Card\]([https://pcpartpicker.com/product/KxPKHx/evga-geforce-gtx-1080-ti-11gb-icx-gaming-video-card-11g-p4-6591-kr](https://pcpartpicker.com/product/KxPKHx/evga-geforce-gtx-1080-ti-11gb-icx-gaming-video-card-11g-p4-6591-kr)) | $664.98 @ Newegg Business 

\*\*Case\*\* | \[Fractal Design - Define XL R2 (Titanium Grey) ATX Full Tower Case\]([https://pcpartpicker.com/product/GTGkcf/fractal-design-case-fdcadefxlr2ti](https://pcpartpicker.com/product/GTGkcf/fractal-design-case-fdcadefxlr2ti)) | $119.99 @ SuperBiiz 

\*\*Power Supply\*\* | \[EVGA - SuperNOVA 1000 P2 1000W 80+ Platinum Certified Fully-Modular ATX Power Supply\]([https://pcpartpicker.com/product/dJ6BD3/evga-power-supply-220p21000xr](https://pcpartpicker.com/product/dJ6BD3/evga-power-supply-220p21000xr)) | $149.99 @ B&amp;H 

 | \*Prices include shipping, taxes, rebates, and discounts\* |

 | Total (before mail-in rebates) | $1581.26

 | Mail-in rebates | -$20.00

 | \*\*Total\*\* | \*\*$1561.26\*\*

 | Generated by \[PCPartPicker\]([https://pcpartpicker.com](https://pcpartpicker.com)) 2018-08-28 16:21 EDT-0400 |",15,3
156,2018-8-29,2018,8,29,8,9b3r5b,Do I need to use identical GPU's if I am not using (SLI) Parallelism?,https://www.reddit.com/r/deeplearning/comments/9b3r5b/do_i_need_to_use_identical_gpus_if_i_am_not_using/,minutestomidnight,1535497277,"I have proposed setups in this [thread](https://www.reddit.com/r/deeplearning/comments/9b2fp7/xeon_v_i7_for_dl_rig/).

I work for a research lab and my superiors want us to build this deep learning rig ASAP and do not want to wait for the RTX 2080 which comes out in a month. 

However, I think we can buy them when they come out and add them as additional GPU's to the 1080 Ti that we already will have. 

According to this [post](http://timdettmers.com/2018/08/21/which-gpu-for-deep-learning/), there isn't much of a pronounced benefit in parallelism, so we can run multiple experiments on each GPU. 

My question is two-fold:

* will I be able to have potentially 1 GTX 1080 Ti, and 3 RTX 2080's on a motherboard with 4 slots - and run them all separately?
* will I be able to run the 3 RTX 2080's in parallel (SLI), with the 1 GTX 1080 Ti separately?

Thank you. ",2,3
157,2018-8-29,2018,8,29,12,9b5vj8,Representation learning,https://www.reddit.com/r/deeplearning/comments/9b5vj8/representation_learning/,late_to_ml,1535514646,"Iam watching the 2012 summer school lectures by Yoshua Bengio 

   [http://www.iro.umontreal.ca/\~bengioy/talks/deep-learning-gss2012.html](http://www.iro.umontreal.ca/~bengioy/talks/deep-learning-gss2012.html)

4-part videos starting with 

   [https://www.youtube.com/watch?v=O6itYc2nnnM](https://www.youtube.com/watch?v=O6itYc2nnnM)

&amp;#x200B;

The material covers unsupervised pre-training, RBMs etc. Is this material still relevant ? Do you have any other suggestions for Feature learning/Representation learning/Transfer learning that is more recent and relevant ?",6,5
158,2018-8-29,2018,8,29,15,9b6ut4,Are you a researcher doing deep learning? Get free computing power for your model training!,https://www.reddit.com/r/deeplearning/comments/9b6ut4/are_you_a_researcher_doing_deep_learning_get_free/,freducom,1535524701,,4,0
159,2018-8-29,2018,8,29,18,9b7n6u,"Anyone, who has trained TextureGAN for deep image synthesis in Keras?",https://www.reddit.com/r/deeplearning/comments/9b7n6u/anyone_who_has_trained_texturegan_for_deep_image/,kailashahirwar12,1535533900,I am working on TextureGAN and trying to implement TextureGAN in keras. Pytorch implementation of TextureGAN is already there. Paper - [https://arxiv.org/pdf/1706.02823.pdf](https://arxiv.org/pdf/1706.02823.pdf) and [https://github.com/Cuiyirui/TextureGAN](https://github.com/Cuiyirui/TextureGAN) \- Pytorch implementation of TextureGAN. ,6,5
160,2018-8-30,2018,8,30,8,9bek56,Build concept images from a set of images?,https://www.reddit.com/r/deeplearning/comments/9bek56/build_concept_images_from_a_set_of_images/,duythvn,1535586531,"Hi guys  
I'm learning ML &amp; DL  and I'm wondering if there is a solution to this : let's say if we have a small set of images (say 100+?)   is there something I should look into to say generate a concept image from that data set  (in other words,  I have  a set of product images that I like, I 'd like to see DL to recommend a product mockup/ concept )

&amp;#x200B;

thank you",2,3
161,2018-8-30,2018,8,30,9,9bepu0,Request for Generative Adversarial Network Guidance,https://www.reddit.com/r/deeplearning/comments/9bepu0/request_for_generative_adversarial_network/,JamesGeoffreyHill,1535587830,"Hello.

I've been creating a conditional GANs.  It is a conditional version of a model known as WaveGAN.  WaveGAN generates samples of audio after having been trained on one second samples of spoken words.  My model is a similar model, although smaller in depth and number of different modes of data being trained with / generated.

I have been able to replicate the WaveGAN model and produce a non-conditional GANs that generates samples.  However, although I have made only the absolute minimum changes to the model to produce a conditioned version, it is far more difficult to train.

With both models I found that most training runs would quickly result in the Generator and Discriminator losses both heading towards infinity and never stopping; with the result being noise.  The non-conditioned model occassionally (1 in 5 times) would train in a way that would produce samples that make some sense.

To improve the conditional GAN I've run a large number of tests on different measures of the learning rate (for Adam optimizer), the alpha (or epsilon) used in the wasserstein-gp loss, the number of discriminator updates relative to generator updates, and the size of the batches.

The tests have shown that I can increase the average time that the conditional generator trains dramatically: from less than 5000 batches to upwards of 30,000 batches before the loss starts heading to infinity.

So I just wanted to ask advice from anyone who has worked with conditional GANs before.  I'm relatively new to generative adversarial networks (and neural networks in general) and this is the first major project I've worked on.  I'm also working under some time pressure as this is for a course, so I don't have the leisure of being able to take my time and learn everything possible very thoroughly.

So if anyone has any tips or advice that would be great.  I don't even know what this problem is called actually.  I would be happy to show some of the code if anyone wanted to see it but I don't expect that much help; just some guidance.

Thanks for any help in advance.",1,5
162,2018-8-30,2018,8,30,14,9bguw3,Char level seq2seq model details,https://www.reddit.com/r/deeplearning/comments/9bguw3/char_level_seq2seq_model_details/,Indypop,1535606532,"I have a chat-bot seq2seq model (char-level). Almost the same as in this tutorial https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html, so very basic, but with bidirectional encoder.

On my training set i have a pairs of input texts and answers. There are situations when one input text causes several difference answers, e.g.:

input    output
Hello    Hey there!
Hello    Whatsup!
Hello    Hi, nice to see you!

And so on. So anybody has an experience with training such a models? My main questions are:
1) How representative is the CE loss with such situations, and what metrics to look on training?
2) On inference i also dont want to see one answer per same question, so there have to be some sampling techniques maybe?

Thanks.
",2,8
163,2018-8-30,2018,8,30,22,9bjf6g,Stages of Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/9bjf6g/stages_of_artificial_intelligence/,seoaleait,1535634108,,4,0
164,2018-8-31,2018,8,31,1,9bkyc0,Pytorch Cycle GAN collapses after around 210 iterations,https://www.reddit.com/r/deeplearning/comments/9bkyc0/pytorch_cycle_gan_collapses_after_around_210/,Cracin,1535645290,"I'm trying to implement a CycleGAN in pytorch but it keeps collapsing. I tried adding gaussian noise, tweaked the optimizer parameters, but every time after around 210-220 iterations(epoch 0), the models collapse and generate a colourful string of images which in no way resemble the training data. Why is this happening? Thank you for your help.

Link to the code: [https://github.com/HelioStrike/Pytorch-CycleGAN](https://github.com/HelioStrike/Pytorch-CycleGAN)",0,10
165,2018-8-31,2018,8,31,4,9bmqjg,Loss function going up,https://www.reddit.com/r/deeplearning/comments/9bmqjg/loss_function_going_up/,Giuan0,1535657415,"`epoch: 15300, loss: 1.5845516543322447e-07` 

`epoch: 15400, loss: 1.5136505737700645e-07` 

`epoch: 15500, loss: 1.5444538803421892e-07`

`epoch: 15600, loss: 1.628581998147638e-07` 

`epoch: 15700, loss: 2.270505632395725e-07` 

`epoch: 15800, loss: 1.6242563724517822` 

`epoch: 15900, loss: 0.9675204157829285` 

`epoch: 16000, loss: 0.9559752345085144` 

`epoch: 16100, loss: 0.9482427835464478`

&amp;#x200B;

After many epochs, this is happening on my neural network. Is it a normal problem that happens when you train too much? Can it be avoided?  ",3,2
166,2018-8-31,2018,8,31,14,9bqumv,Keras discussion group on fb,https://www.reddit.com/r/deeplearning/comments/9bqumv/keras_discussion_group_on_fb/,amit2rockon,1535692539,"[https://www.facebook.com/groups/2111902102393596/](https://www.facebook.com/groups/2111902102393596/)

&amp;#x200B;

join it to get help and also help others.",3,0
167,2018-8-31,2018,8,31,23,9bub7g,Need help with DL Object Identification,https://www.reddit.com/r/deeplearning/comments/9bub7g/need_help_with_dl_object_identification/,Megasim1113,1535727481,Please send me a message if you've worked with Amazon and Google's Deep Learning object identification programs. I am having trouble in setting these up and running some tests for a paper that I need to complete and would love some help. Shoot me a message and I would be more than happy to explain further in detail. Thanks! ,2,1
0,2018-9-1,2018,9,1,15,9c0xpa,Demo: Accelerate Deep Learning Inference on Raspberry Pi (2018 ver.),https://www.reddit.com/r/deeplearning/comments/9c0xpa/demo_accelerate_deep_learning_inference_on/,9_ties,1535782646,,5,52
1,2018-9-1,2018,9,1,18,9c1sqs,US News top Computer Science Artificial Intelligence schools,https://www.reddit.com/r/deeplearning/comments/9c1sqs/us_news_top_computer_science_artificial/,dt_magic,1535793946,,0,1
2,2018-9-1,2018,9,1,18,9c1uu3,AI Weekly 1 September 2018,https://www.reddit.com/r/deeplearning/comments/9c1uu3/ai_weekly_1_september_2018/,TomekB,1535794652,,0,1
3,2018-9-2,2018,9,2,2,9c4wez,,https://www.reddit.com/r/deeplearning/comments/9c4wez/_/,c00l_boi,1535823123,,0,0
4,2018-9-2,2018,9,2,16,9caikq,Someone knows a good course on video analysis using deep learning?,https://www.reddit.com/r/deeplearning/comments/9caikq/someone_knows_a_good_course_on_video_analysis/,milions90,1535875014,,3,0
5,2018-9-2,2018,9,2,18,9cayyl,I have an interview tomorrow,https://www.reddit.com/r/deeplearning/comments/9cayyl/i_have_an_interview_tomorrow/,ninenerd,1535881625,"I need to know the use of C++ in ML/DL.  
I have not used C++ for ML, HR asked me if I know C++ and I know.  
So which concepts from C++ can come handy for interview ?  
ANd why we prefer it over java/python ?  
Thanks",6,0
6,2018-9-2,2018,9,2,20,9cbdet,Polyaxon v0.2 (DL/ML on Kuberentes),https://www.reddit.com/r/deeplearning/comments/9cbdet/polyaxon_v02_dlml_on_kuberentes/,mmourafiq,1535887316,,0,1
7,2018-9-3,2018,9,3,2,9cdok9,"Any recommended cloud for training NN? (preferably free of cost, just for hobby)",https://www.reddit.com/r/deeplearning/comments/9cdok9/any_recommended_cloud_for_training_nn_preferably/,Cannikin18,1535908206,I started to learn about deep learning(online course) and found out that my laptop can't handle the NN training. I have look through some website but not sure if it is what I'm looking for.,4,0
8,2018-9-3,2018,9,3,2,9cdpib,Deep learning retreat scholarships,https://www.reddit.com/r/deeplearning/comments/9cdpib/deep_learning_retreat_scholarships/,urlwolf,1535908382,"Hi guys,

&amp;#x200B;

I run Deep learning retreat, a 3-month school that takes pretty advanced machine learners and gets them to work together with mentors to produce a killer deep learning portfolio project. We want these projects to have social impact (example: a malaria microscope). 

&amp;#x200B;

We are launching our first batch in SF. We are going to live together (participants and mentors) at walking distance from the office. It's going to be great. 

&amp;#x200B;

It costs 12k. And this is clearly a problem for many, many people. So I'm happy to announce that a benefactor that wishes to remain anonymous contributed money to start up a scholarship program. This is really amazing because we while we didnt know each other before we were still united by our mental model of how deep learning can change the world.

&amp;#x200B;

The scholarships will work as a pay it forward model. That is, if you got one, whenever you are well-to-do in your life, give one to someone who needs it. Be anonymous.

&amp;#x200B;

Since a lot of influential people hang out here, I want to ask you. Can you recommend someone for the scholarship? It's merit first, then need. We want to get the best people possible, and have the maximum amount of impact.

&amp;#x200B;

If you want to apply yourself, head to  [https://deeplearningretreat.com/deep-learning-retreat-scholarships/](https://deeplearningretreat.com/deep-learning-retreat-scholarships/)

&amp;#x200B;",5,14
9,2018-9-3,2018,9,3,14,9ciytu,Anyone familiar with platforms that I can rent out my GPUs power for deep learning besides Vectordash?,https://www.reddit.com/r/deeplearning/comments/9ciytu/anyone_familiar_with_platforms_that_i_can_rent/,AnonymousGOAT08,1535954357,"I built a rig awhile back and seen the whole Vectordash movement and long story short, seems like the founders are heavily dragging their feet. Extremely frustrating.. Via Reddit and my own experiences I got a message back inquiring about my hosting application and responded myself but havent seen anything since. Wondering if there are any other places that I can use my GPU power to rent out for deep learning such as what Vectordash was trying to provide?",4,6
10,2018-9-3,2018,9,3,17,9cjtna,[P] MagNet: High-Level PyTorch API for Quick Experimentation,https://www.reddit.com/r/deeplearning/comments/9cjtna/p_magnet_highlevel_pytorch_api_for_quick/,svaisakh,1535963878,,5,19
11,2018-9-3,2018,9,3,21,9cl902,Scientists Have Trained an AI to Spot Obesity From Space,https://www.reddit.com/r/deeplearning/comments/9cl902/scientists_have_trained_an_ai_to_spot_obesity/,asifrazzaq1988,1535979313,,4,13
12,2018-9-3,2018,9,3,23,9clsan,Can you solve a person detection task in 10 minutes?,https://www.reddit.com/r/deeplearning/comments/9clsan/can_you_solve_a_person_detection_task_in_10/,tdionis,1535984010,,0,0
13,2018-9-4,2018,9,4,17,9ctssi,Real World Example of Deep Learning: Sexual Abuse Material Detection,https://www.reddit.com/r/deeplearning/comments/9ctssi/real_world_example_of_deep_learning_sexual_abuse/,freducom,1536050408,,1,4
14,2018-9-4,2018,9,4,17,9cttvo,Machine Learning India,https://www.reddit.com/r/deeplearning/comments/9cttvo/machine_learning_india/,hamir_s,1536050750,"Hi all,

This is an invite to all Indians on this community to /r/MLIndia. This community is focused on particular problems unique to Indians in the journey to learn ML/DL in India.

Thanks! ",2,1
15,2018-9-5,2018,9,5,0,9cwqhk,Deep-learning algorithms are being used to detect lithium-ion batteries in airport luggage,https://www.reddit.com/r/deeplearning/comments/9cwqhk/deeplearning_algorithms_are_being_used_to_detect/,asifrazzaq1988,1536075476,,0,12
16,2018-9-5,2018,9,5,8,9d0r62,"too many AI model, such as: lstm,reinforcement learning, qlearning, dqn,ddqn, rainbow........ any good idea help people to easy understand and remember ?",https://www.reddit.com/r/deeplearning/comments/9d0r62/too_many_ai_model_such_as_lstmreinforcement/,asda43asdf23423,1536102906,"too many AI model,  such as:  lstm,reinforcement learning, qlearning, dqn,ddqn, rainbow........

any  good idea help people to easy understand and remember ?",3,1
17,2018-9-5,2018,9,5,11,9d2abk,Can someone explain the OneHotEncoder and train_test_split?,https://www.reddit.com/r/deeplearning/comments/9d2abk/can_someone_explain_the_onehotencoder_and_train/,Pawin3210,1536115381,I am learning Deep Learning through books and Udemy courses ( I'm very very new ) and I find the documents quite hard to understand.,7,3
18,2018-9-5,2018,9,5,12,9d2irc,What is the best options to use an remote GPU on the cloud while I only have a notebook with CPU ?,https://www.reddit.com/r/deeplearning/comments/9d2irc/what_is_the_best_options_to_use_an_remote_gpu_on/,Laurence-Lin,1536117166,"I want to get start on deep learning practice, but due to the hardware restrict, I need to get access of the cloud GPU server in order to run the program successfully. Some website have suggest the Jupyter can enables the access to GPU server, I would like to ask if anyone recommend it? Or is there any other better choice to get access ?  
Thanks for helping.  
",20,3
19,2018-9-5,2018,9,5,15,9d3tlk,How to explain why some weights are bigger in MLP,https://www.reddit.com/r/deeplearning/comments/9d3tlk/how_to_explain_why_some_weights_are_bigger_in_mlp/,cyph_r,1536129514,"I noticed that after a deep learning training using MLP, if I look to the first layer weights, then some weights are much bigger than others, and usually the biggest weights corresponds to the weights which are connected to the inputs nodes where the information is.

&amp;#x200B;

For example using some data like MNIST, let say that the relevant pixels are usually in the center of the image, then the weights connected to the central pixels will be bigger than the weights on the edges.

&amp;#x200B;

It seems obvious, but how can we explain this mathematically. Why the weights connected to the relevant inputs are higher than the weights connected to the non-relevant inputs nodes?

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",2,1
20,2018-9-5,2018,9,5,22,9d6dwc,Generative Adversial Networks,https://www.reddit.com/r/deeplearning/comments/9d6dwc/generative_adversial_networks/,shaswat98,1536152971,,0,0
21,2018-9-6,2018,9,6,1,9d8e0f,Should I learn concepts from blogs or books?,https://www.reddit.com/r/deeplearning/comments/9d8e0f/should_i_learn_concepts_from_blogs_or_books/,Pawin3210,1536166005,,0,1
22,2018-9-6,2018,9,6,7,9dbn65,Yolov2 for object detection task (Pytorch implementation),https://www.reddit.com/r/deeplearning/comments/9dbn65/yolov2_for_object_detection_task_pytorch/,1991viet,1536185745,,3,55
23,2018-9-6,2018,9,6,8,9dcbls,Should I go to college for AI / data science?,https://www.reddit.com/r/deeplearning/comments/9dcbls/should_i_go_to_college_for_ai_data_science/,Ducknado1337,1536190291,"Not sure if this is the right place to ask, but I was wondering what you guys think. Should I go to college for AI or something similar, or just keep learning on my own? I'm currently in highschool and have a year or two, but I know I want to go into this field. I've seen mixed feelings on the topic, what do you guys think? Thanks ahead of time.",2,1
24,2018-9-6,2018,9,6,12,9de9ev,Everybody Dance now explained! Latest research from Berkeley AI Research,https://www.reddit.com/r/deeplearning/comments/9de9ev/everybody_dance_now_explained_latest_research/,vector_machines,1536204046,,0,7
25,2018-9-6,2018,9,6,16,9dg4kk,Alternatives to NIPS,https://www.reddit.com/r/deeplearning/comments/9dg4kk/alternatives_to_nips/,dmilushev,1536220101,"Now for the ones who were not able to get into NIPS, are there any reasonable alternatives/similar venues to NIPS between now and the end of February 2019. I know about about ICML and ICLR, but they are outside of the mentioned time-window. Is there something else worth attending, even it is more on the technical/development side than the above -mentioned?
",0,1
26,2018-9-6,2018,9,6,17,9dgibz,Company events in Russian software development company,https://www.reddit.com/r/deeplearning/comments/9dgibz/company_events_in_russian_software_development/,Batareika_1,1536223798,,0,2
27,2018-9-6,2018,9,6,18,9dgp2q,Reinforcement learning for NLP,https://www.reddit.com/r/deeplearning/comments/9dgp2q/reinforcement_learning_for_nlp/,pcidev,1536225656,"What do you think of RL use in NLP.? 
Could someone suggest me some interesting tutorials to read  about this topic. ",4,5
28,2018-9-6,2018,9,6,18,9dgq4n,Vast.ai -&gt; Insanely cheap GPU instances while in beta,https://www.reddit.com/r/deeplearning/comments/9dgq4n/vastai_insanely_cheap_gpu_instances_while_in_beta/,sparky_the_unicorn,1536225922,,10,9
29,2018-9-6,2018,9,6,19,9dh1r2,How can I use stacked autoencoder to initialize weight for my neural network in Pytorch?,https://www.reddit.com/r/deeplearning/comments/9dh1r2/how_can_i_use_stacked_autoencoder_to_initialize/,namnguyen_hust,1536228886,"Dear experienced ones,  


Any suggestions for my question?

&amp;#x200B;

Thanks in advance.",0,1
30,2018-9-6,2018,9,6,22,9dik6t,September 2018 issue of Computer Vision News,https://www.reddit.com/r/deeplearning/comments/9dik6t/september_2018_issue_of_computer_vision_news/,Gletta,1536240423,"Hot off the Press! Links to Computer Vision News of September

Here is the September 2018 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: 30 pages worth reading about Artificial Intelligence, Deep Learning, Image Processing and Computer Vision. Technical review of a new paper at page 4 and free subscription at page 30.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2018September/)

[PDF version](http://www.rsipvision.com/computer-vision-news-2018-september-pdf/)

Enjoy!

&amp;#x200B;

&amp;#x200B;",0,5
31,2018-9-6,2018,9,6,22,9distp,PyCM: Multiclass confusion matrix library in Python,https://www.reddit.com/r/deeplearning/comments/9distp/pycm_multiclass_confusion_matrix_library_in_python/,sepandhaghighi,1536242040," PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters. PyCM is the swiss-army knife of confusion matrices, targeted mainly at data scientists that need a broad array of metrics for predictive models and an accurate evaluation of large variety of classifiers. 

&amp;#x200B;

[Github Repo](https://github.com/sepandhaghighi/pycm)

[Webpage](http://pycm.shaghighi.ir/)

[JOSS Paper](http://joss.theoj.org/papers/10.21105/joss.00729)",0,6
32,2018-9-7,2018,9,7,1,9dkcrf,Deep Learning  Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/9dkcrf/deep_learning_learn_recurrent_neural_networks_in/,atkarti,1536251745,,0,2
33,2018-9-7,2018,9,7,2,9dl63a,Multi input transfer learning - Check it out,https://www.reddit.com/r/deeplearning/comments/9dl63a/multi_input_transfer_learning_check_it_out/,mlwhiz,1536256527,,2,3
34,2018-9-7,2018,9,7,3,9dln0t,What was the path that lead you to your Deep Learning job?,https://www.reddit.com/r/deeplearning/comments/9dln0t/what_was_the_path_that_lead_you_to_your_deep/,DerSteppenWulf,1536259238,What someone should do after completing something like a degree in CS or nanodegree programs or any other course that could give you a potential job in a CS field? You started to make your own personal projects or just went straight looking for jobs and you gained experience in the field there without knowing much? ,1,0
35,2018-9-7,2018,9,7,4,9dm2u0,Deep learning cluster setup suggestions,https://www.reddit.com/r/deeplearning/comments/9dm2u0/deep_learning_cluster_setup_suggestions/,adi1709,1536261928,"We are planning to setup a deep learning cluster for about 8-10 people. I was looking for suggestions for the GPUs, criteria to keep in mind while setting one up. What is the latest offering from NVIDIA in terms of architecture if we are not looking at a high end one?",1,0
36,2018-9-7,2018,9,7,4,9dm7uh,Introduction to Reinforcement Learning using MXNet   r/MachineLearning,https://www.reddit.com/r/deeplearning/comments/9dm7uh/introduction_to_reinforcement_learning_using/,tomtx0,1536262756,,0,16
37,2018-9-7,2018,9,7,6,9dn8lb,Megvii UPerNet Performs Multi-Level Visual Scene Interpretation at a Glance,https://www.reddit.com/r/deeplearning/comments/9dn8lb/megvii_upernet_performs_multilevel_visual_scene/,trcytony,1536268854,,0,1
38,2018-9-7,2018,9,7,10,9dpest,Is there any python code for neural network for pattern recognition?,https://www.reddit.com/r/deeplearning/comments/9dpest/is_there_any_python_code_for_neural_network_for/,VenyWun1729,1536283481,,2,0
39,2018-9-7,2018,9,7,17,9ds6wz,AI can now program in HTML,https://www.reddit.com/r/deeplearning/comments/9ds6wz/ai_can_now_program_in_html/,as_ninja6,1536307966,"Web developers need to run fast, AI is catching up... Microsoft's sketch2code provides html code from hand sketch 

*Processing img z927ztuayrk11...*",11,12
40,2018-9-7,2018,9,7,17,9ds85y,Interesting Podcast where Raia Hadsell from DeepMind discusses 'Deep Reinforcement Learning in Complex Environments',https://www.reddit.com/r/deeplearning/comments/9ds85y/interesting_podcast_where_raia_hadsell_from/,teamrework,1536308361,"Where am I, and where am I going, and where have I been before? Answering these questions requires cognitive navigation skills--fundamental skills which are employed by every intelligent biological species to find food, evade predators, and return home. On this week's episode of the Podcast, Raia discusses her work on Deep Reinforcement Learning in Complex Environments. [http://videos.re-work.co/podcast](http://videos.re-work.co/podcast) ",0,1
41,2018-9-7,2018,9,7,22,9dubts,Can WiFi frequencies reflect off objects ?,https://www.reddit.com/r/deeplearning/comments/9dubts/can_wifi_frequencies_reflect_off_objects/,saadmrb,1536326822,"Can we see through-wall(Clothes/Objects etc..) Estimation for an object(i.e keys/t-shirt) using Radio Signals ?  
 ",6,0
42,2018-9-8,2018,9,8,0,9dve9f,Using Video synthesis to generate semantic segmentation,https://www.reddit.com/r/deeplearning/comments/9dve9f/using_video_synthesis_to_generate_semantic/,zurister,1536333897,"I was wondering**can video segmentation be viewed as a video synthesis problem**? All we need to do is to generate a video with label colors given the original video. Video synthesis networks try to learn the detailed intricacies of the video and doing segmentation for them wont be too hard. Even a slightly less performing model on cityscapes can perform good in semantic segmentation domain. Models like Vid2Vid should perform very good on such task.

Does this make sense? Any insights on this?",0,5
43,2018-9-8,2018,9,8,5,9dyabn,"Q&amp;A: Spirit &amp; Glitch, A Fashion Brand Designed with Neural Networks",https://www.reddit.com/r/deeplearning/comments/9dyabn/qa_spirit_glitch_a_fashion_brand_designed_with/,continuaco,1536352599,,0,1
44,2018-9-8,2018,9,8,5,9dyho2,How does dilated convolution (a.k.a atrous convolution) help?,https://www.reddit.com/r/deeplearning/comments/9dyho2/how_does_dilated_convolution_aka_atrous/,zurister,1536353879,I am not able to understand - how does atrous convolution help in dense feature prediction?,11,8
45,2018-9-8,2018,9,8,7,9dz0t4,[x-post] Cheat sheet: Deep learning losses &amp; optimizers,https://www.reddit.com/r/deeplearning/comments/9dz0t4/xpost_cheat_sheet_deep_learning_losses_optimizers/,hergertarian,1536357834,"**tl;dr:** Sane defaults for deep learning loss functions and optimizers, followed by in-depth descriptions.

https://www.hergertarian.com/cheat-sheet-deep-learning-losses-optimizers",0,3
46,2018-9-8,2018,9,8,15,9e27tv,Making Music: When Simple Probabilities Outperform Deep Learning,https://www.reddit.com/r/deeplearning/comments/9e27tv/making_music_when_simple_probabilities_outperform/,FollowSteph,1536388134,,1,15
47,2018-9-8,2018,9,8,22,9e49ai,AI Weekly 8 September 2018,https://www.reddit.com/r/deeplearning/comments/9e49ai/ai_weekly_8_september_2018/,TomekB,1536412498,,0,1
48,2018-9-9,2018,9,9,13,9eaj9q,"Humble Book Bundle: Machine Learning by O'Reilly. $641 worth of Machine Learning Books like Introduction to Machine Learning with Python, Learning TensorFlow, 1Ed, and Thoughtful Machine Learning with Python, 1Ed is 97% OFF !",https://www.reddit.com/r/deeplearning/comments/9eaj9q/humble_book_bundle_machine_learning_by_oreilly/,Ariana675,1536468539,,0,1
49,2018-9-9,2018,9,9,15,9eb5f7,Stanford's Deep Learning cheatsheet  r/MachinesLearn,https://www.reddit.com/r/deeplearning/comments/9eb5f7/stanfords_deep_learning_cheatsheet_rmachineslearn/,lohoban,1536476253,,0,36
50,2018-9-9,2018,9,9,20,9ec7ou,Using K-fold cross-validation in Keras,https://www.reddit.com/r/deeplearning/comments/9ec7ou/using_kfold_crossvalidation_in_keras/,suraty,1536491323,"Hello,
I would like to use K-fold cross-validation on my data of my model.

My codes in Keras is :

    a = np.array(  
    [[283, 95, 72, 65],
    [290, 100, 80, 72],
    [120,170,130,122],
    [100,230,110,200],
    [300,100,200,500]]
        )
    X = a[:,0:2]
    Y = a[:,3]

    from sklearn.model_selection import KFold, cross_val_score
    k_fold = KFold(n_splits=3)    
    model = models.Sequential()
    model.add(Dense(12, input_shape=(3,)))
    model.add(LeakyReLU())
    model.summary()
    
    cross_val_score(model,X,Y)

But, It makes this error:

&gt;If no scoring is specified, the estimator passed should have a 'score' method. The estimator &lt;keras.engine.sequential.Sequential object at 0x00000138D28D2E10&gt; does not.

And when I select a scoring parameter as:

    cross_val_score(model,X,Y, scoring= 'accuracy')

It makes another error:
&gt;TypeError: Cannot clone object '&lt;keras.engine.sequential.Sequential object at 0x00000138D28D2E10&gt;' (type &lt;class 'keras.engine.sequential.Sequential'&gt;): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.

How can I use K-fold cross-validation correctly?
Thank you",1,2
51,2018-9-9,2018,9,9,23,9ed7t1,Generative Adversarial Networks  An Entertaining Introduction,https://www.reddit.com/r/deeplearning/comments/9ed7t1/generative_adversarial_networks_an_entertaining/,codingwoman_,1536502251,,0,4
52,2018-9-10,2018,9,10,1,9eegj2,Practical Advice for Building Deep Neural Networks  r/MachinesLearn,https://www.reddit.com/r/deeplearning/comments/9eegj2/practical_advice_for_building_deep_neural/,lohoban,1536511918,,0,1
53,2018-9-10,2018,9,10,13,9ejpgs,Papers with Code,https://www.reddit.com/r/deeplearning/comments/9ejpgs/papers_with_code/,fvzaur,1536554273,I'm working on making a list of Machine Learning papers that has open source code on GitHub. My initial version can be reached at the link included below. I think it will be helpful to this community to select their next paper to read. Please also include your comments and suggestions for improvement. https://github.com/zziz/pwc,5,38
54,2018-9-11,2018,9,11,12,9etzo6,Sensitivity analysis,https://www.reddit.com/r/deeplearning/comments/9etzo6/sensitivity_analysis/,cyph_r,1536636852,"I want to know which input pixels contribute the most to the classification.

&amp;#x200B;

I heard about sensitivity analysis which is based on computing derivative with regards to the input directly.

&amp;#x200B;

However, should I compute the derivative of the loss or of the network output? (with regards to the input)

&amp;#x200B;

Thanks",5,6
55,2018-9-11,2018,9,11,17,9evo36,Deep Learning Market Worth 18.16 Billion USD by 2023,https://www.reddit.com/r/deeplearning/comments/9evo36/deep_learning_market_worth_1816_billion_usd_by/,marketsandmarkets,1536654007,[removed],0,1
56,2018-9-11,2018,9,11,21,9ex5v7,Multivariate Time Series Deep Learning Models,https://www.reddit.com/r/deeplearning/comments/9ex5v7/multivariate_time_series_deep_learning_models/,liftoff01,1536669429,"I was wondering if there are any specific deep learning models designed to handle multivariate time series data.

Classical multivariate models will be vector autoregressive models (VAR) and univariate models includes the arima class. 

I maybe wrong but RNNs are more akin to arima models than VAR models, no? ",13,10
57,2018-9-11,2018,9,11,23,9ey0i4,Practical guide to hyperparameters search for deep learning models,https://www.reddit.com/r/deeplearning/comments/9ey0i4/practical_guide_to_hyperparameters_search_for/,pirate7777777,1536675977,,0,1
58,2018-9-12,2018,9,12,3,9f02or,"ML-Agents reference paper, Gym interface support, and Marathon Environments",https://www.reddit.com/r/deeplearning/comments/9f02or/mlagents_reference_paper_gym_interface_support/,leonchenzhy,1536690390,,0,7
59,2018-9-12,2018,9,12,8,9f2dib,Preserve colour in autoencoder,https://www.reddit.com/r/deeplearning/comments/9f2dib/preserve_colour_in_autoencoder/,__Lau__,1536707600,,0,1
60,2018-9-12,2018,9,12,13,9f4phr,Implementation of Batch normalization and instance normalization from scratch in Python?,https://www.reddit.com/r/deeplearning/comments/9f4phr/implementation_of_batch_normalization_and/,kailashahirwar12,1536727232,Batch normalization is a very important method to speedup training of neural networks. Instance normalization is relatively new and promises more. I am looking for a very good explanation of batch normalization and instance normalization in Python.,1,2
61,2018-9-12,2018,9,12,13,9f4pwh,Multi-Person Pose Estimation (Python / C++),https://www.reddit.com/r/deeplearning/comments/9f4pwh/multiperson_pose_estimation_python_c/,spmallick,1536727351,,3,49
62,2018-9-12,2018,9,12,23,9f82fq,Training seq2seq on smaller datasets,https://www.reddit.com/r/deeplearning/comments/9f82fq/training_seq2seq_on_smaller_datasets/,pchelina,1536761231,"I wonder if anybody had experience with pretraining a seq2seq model when you don't have millions of message-response pairs. I want to train a chatbot and i have good dialogue data but it makes just a few thousands pairs. The dataset is in a fairly restricted domain (therapy sessions), but it is still much smaller than datasets i see conmonly used to train a chatbot. I hear some people pre-train their models on larger 'garbage' datasets like twitter, but i fail to see how it would work exactly. Does it mean the weights pretrained on this large dataset capture some low-level features like common ngram patterns, and then when you retrain it on the clean data it just learns to mimic the style? Or does it mean you are still likely to generate twitter-like comments? ",6,2
63,2018-9-12,2018,9,12,23,9f82pg,I'm finding a Image Captioning paper,https://www.reddit.com/r/deeplearning/comments/9f82pg/im_finding_a_image_captioning_paper/,curaai00,1536761278,Is there CRNN applied image captioning paper??,1,2
64,2018-9-13,2018,9,13,5,9fbf2d,Mixing text and numeric features for text classification using deep learning,https://www.reddit.com/r/deeplearning/comments/9fbf2d/mixing_text_and_numeric_features_for_text/,mathcircler,1536784256,"I have a problem about classification of text into several categories (topics). Apart from text, I have some numeric features that I believe may be useful (there are also missing values among those features). But the most important information is, of course, presented in the text. Therefore, I think deep learning  approach (with common pipeline: embedding layer + CNN or RNN with dropout + Dense layer) would be the best choice. What is the best practice to mix the current model that works only on text input with numeric features? Are there any tricks, best practices? Are there any papers/experiments (on GitHub maybe) on this topic?",3,7
65,2018-9-13,2018,9,13,5,9fbk3x,Best deep learning practices in NLP for text classification,https://www.reddit.com/r/deeplearning/comments/9fbk3x/best_deep_learning_practices_in_nlp_for_text/,mathcircler,1536785212,"Are there any list of best practices on text classification (not only in English language, but in general)? In particular, I'm interested:

\- what kind of text preprocessing techniques are usually useful? Can you share some good open-source text preprocessors?

\- what kind of neural networks architectures one should try first on a new text classification problem? What kind of architectures should be solid baselines?

\- what are the ""rules of thumb"" for choosing the size of the dictionary? maximum number of words to be left (in sequence padding)? word embeddings dimension?  


Would be great if you could share articles or (even better!) the must-read research papers or anything else you find useful about this topic.",2,19
66,2018-9-13,2018,9,13,13,9ff17o,foobar.edu deep foobar dataset http server is very slow!!,https://www.reddit.com/r/deeplearning/comments/9ff17o/foobaredu_deep_foobar_dataset_http_server_is_very/,Yusuke_Suzuki,1536813583,"Many labs of many universities provides very useful dataset for deeplearning.

Bat their http servers are very very poor.

Why don't they use cloud server?

I spent a day to download a dataset.

Other day, I can't download dataset for connection timeout, response timeout, disconnection ...",0,1
67,2018-9-13,2018,9,13,18,9fgl2m, Traveling the ML. Next hop: step by step guide to recognize drivable area,https://www.reddit.com/r/deeplearning/comments/9fgl2m/traveling_the_ml_next_hop_step_by_step_guide_to/,tdionis,1536831743,,0,8
68,2018-9-13,2018,9,13,21,9fhqxb,Adam Optimizer with large learning rate doesn't converge,https://www.reddit.com/r/deeplearning/comments/9fhqxb/adam_optimizer_with_large_learning_rate_doesnt/,varian97,1536843501,I try to implement a Deep Neural Network by myself and I use adam as the optimizer. Then I try different value of learning rate to it. When the learning rate = 0.0007 the algorithm produces low error ( approx. 0.76 ) but for larger learning rate (ex. 0.1) it produces higher error ( &gt; 3 ). Does adam optimizer behave like that? or is it my implementation that buggy? ( same thing happen to the RMSProp ),5,2
69,2018-9-14,2018,9,14,0,9fj7v0,Deep Learning  Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/9fj7v0/deep_learning_learn_recurrent_neural_networks_in/,plpface,1536854306,,0,7
70,2018-9-14,2018,9,14,2,9fk7er,[P] New series on data augmentation for object detection - Code + open source augmentation library included,https://www.reddit.com/r/deeplearning/comments/9fk7er/p_new_series_on_data_augmentation_for_object/,taltal13,1536861106,,0,1
71,2018-9-14,2018,9,14,10,9fnvdd,"Machine Reading Comprehension Part II: Learning to Ask &amp; Answer  Han Xiao Tech Blog - Deep Learning, Tensorflow, Machine Learning and more!",https://www.reddit.com/r/deeplearning/comments/9fnvdd/machine_reading_comprehension_part_ii_learning_to/,h_xiao,1536888726,,1,6
72,2018-9-14,2018,9,14,13,9fp5pk,"Understanding Neural Networks. From neuron to RNN, CNN, and Deep Learning",https://www.reddit.com/r/deeplearning/comments/9fp5pk/understanding_neural_networks_from_neuron_to_rnn/,nigamv01,1536900382,,0,1
73,2018-9-14,2018,9,14,23,9fsk2h,GitHub - lezwon/DeepGamingAI_FIFARL: Using Reinforcement Learning to play FIFA,https://www.reddit.com/r/deeplearning/comments/9fsk2h/github_lezwondeepgamingai_fifarl_using/,lezwon,1536936046,,0,2
74,2018-9-15,2018,9,15,0,9fswk2,Generative Adversarial Networks  Paper Reading Road Map,https://www.reddit.com/r/deeplearning/comments/9fswk2/generative_adversarial_networks_paper_reading/,codingwoman_,1536938546,,3,20
75,2018-9-15,2018,9,15,2,9fu635,What are the advantages of cupy library over Eigen library?,https://www.reddit.com/r/deeplearning/comments/9fu635/what_are_the_advantages_of_cupy_library_over/,sriharsha_0806,1536947404,"Currently cupy library is used by chainer. Eigen library is used by Pytorch, Tensorflow.",4,6
76,2018-9-15,2018,9,15,7,9fwhw2,MIT &amp; Google Propose AutoML for Model Compression,https://www.reddit.com/r/deeplearning/comments/9fwhw2/mit_google_propose_automl_for_model_compression/,trcytony,1536964384,,1,2
77,2018-9-15,2018,9,15,15,9fzahi,HIP Vs CUDA,https://www.reddit.com/r/deeplearning/comments/9fzahi/hip_vs_cuda/,Keysmart_Andy,1536991552,"Hey, Im relatively new to the machine learning/deep learning space.  
I have been using SPSS and then Statistica since I was in college.  
(Pretty lame I know) :(  
Anyways... I love econ and am going through [https://quantecon.org/](https://quantecon.org/).  
(I love Macro)  
Anyways... I have an RX Vega 64...   
I know the AMD card won't work with CUDA.  
But does anyone here have experience with HIP? [https://github.com/ROCm-Developer-Tools/HIP](https://github.com/ROCm-Developer-Tools/HIP)  
Is working with HIP on par with working directly on CUDA?  
Would you guys recommend I get a Nvidia card just so I could use CUDA?  
Also, do you guys think its worth investing in one of these new nVidia cards to speed up my training?  ",2,2
78,2018-9-15,2018,9,15,17,9fzwbj,"[Question] RNN-LSTM ,Make it to learn anomalies.",https://www.reddit.com/r/deeplearning/comments/9fzwbj/question_rnnlstm_make_it_to_learn_anomalies/,Abhishek_Advance,1536999265," (Some depth in understanding of LSTM required): 

I'm trying to make LSTM learn multivariate time series ,I have been successful to an extent. Now I want to make the LSTM learn anomalies in time series(eg. an unusual drop in values ,when rendering a sine wave in a cyclic manner ). I tried introducing such anomalies in training data,LSTM did not learn.

&gt;**I****s there a way to increase the weightage on parts of time series that has anomalies or some other ways to make LSTM learn that pattern and produce it later.** 

&amp;#x200B;",2,4
79,2018-9-15,2018,9,15,19,9g0iql,How to become deep learning researcher?,https://www.reddit.com/r/deeplearning/comments/9g0iql/how_to_become_deep_learning_researcher/,sanchit2843,1537007526,"I am an undergrad student in india and want to be researcher in field of robotics. For the same I started with machine learning and deep learning. I will start studying reinforcement learning and robotics techniques like slam,pid etc next year. But I was thinking of how to study machine learning(more concentration on deep learning) of ms/phd level in my under graduation. Reply will be grateful

Peace",9,10
80,2018-9-15,2018,9,15,21,9g16qo,Attention based models for machine comprehension,https://www.reddit.com/r/deeplearning/comments/9g16qo/attention_based_models_for_machine_comprehension/,ImaginaryAnon,1537015479,"Currently, I am understanding Attention models. I specifically need it to build a machine comprehension model (a model which can find answer to a question from a given comprehension). But I want to understand the model generally and not specifically to this topic. I have a question about attention layer but before that I would like to share what I understood.

&amp;#x200B;

\## The things I understood so that you can correct me if I made some mistakes

For this, I have referred an article online which I am sharing here - [http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)

It gave basic intuition of what the attention layer does - It asks the model the model to focus on a specific part of the input in order to generate the output. Here's an image of it - [http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.51.19-PM.png](http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.51.19-PM.png)

The pink shades are defined by attention variables 'a(i)'. These variables are actually probability distribution that shows 'the probability that the model should focus on the area represented by that variable'. So, a general figure on any attention based model is as - [http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.16.08-PM.png](http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.16.08-PM.png) \- where 'a's are the attention variables (weights). These variables are trained by the model.

&amp;#x200B;

\## The question

I have a question in mind. Are the attention weights same for every inputs (in machine comprehension, input = 'comprehension'). If so, then independent of the comprehension, the model will focus on a very small part of every comprehension to find an answer. And it isn't necessary that the answer lies in same part of all comprehensions.

If the weights are different for different inputs, then how will we train them. Because, as per my knowledge, in every neural network, the weights are trained for all the input data irrelevant of the input identifier i.e the final weight values at the end of training is same for all the inputs. And after training, these weights are the final values which are used in real-time application.",0,2
81,2018-9-15,2018,9,15,21,9g1909,New exciting Deep learning Project !!!,https://www.reddit.com/r/deeplearning/comments/9g1909/new_exciting_deep_learning_project/,pcidev,1537016166,"I was looking for some cool deep leaning project. Could any one suggest me list of new deep learning project, that I can work on from scratch. 

May be more related to the language, but every suggestion is welcomed. :)

Also would any one interested in working on some group project. I was thinking of work  on some research on Machine Translation Using Monolingual Corpora. If interested ping me, personally we could discuss.  ",0,0
82,2018-9-16,2018,9,16,12,9g7f1i,CVPR 2018 | Paper Review: LayoutNet,https://www.reddit.com/r/deeplearning/comments/9g7f1i/cvpr_2018_paper_review_layoutnet/,steeveHuang,1537067005,"This week, I would like to share with you another CVPR paper, ""LayoutNet"", regarding 3D layout reconstruction from 2D images. In this video, I will explain the detail of the Network structure and how it optimizes the parameters. Hope you like it. :)

r/https://www.youtube.com/watch?v=NBxsfyDaPuk&amp;t=71s",0,11
83,2018-9-16,2018,9,16,17,9g97ab,"How can I understand the maths of back propagation of neural network, CNN and RNN?",https://www.reddit.com/r/deeplearning/comments/9g97ab/how_can_i_understand_the_maths_of_back/,kitgary,1537088019,"I have been struggling for over 3 months to understand the maths (especially multivariable calculus part) of back propagation algorithm, I have read many resources, taking online courses such as taking Andrew Ng's Deep Learning Specialization, reading books and blog articles but none of them help to teach me back propagation step by step, I am totally lost and really want to give me. Can anyone help?",6,6
84,2018-9-17,2018,9,17,2,9gci26,Could you use reinforcement learning to generate a model,https://www.reddit.com/r/deeplearning/comments/9gci26/could_you_use_reinforcement_learning_to_generate/,CzoKc,1537119888,Could you use reinforcement learning to generate different models for e.g. for object detection. So in a way you will be using machine learning to generate machine learning ,4,13
85,2018-9-17,2018,9,17,4,9gdbjw,Capsule networks vs one pixel attack,https://www.reddit.com/r/deeplearning/comments/9gdbjw/capsule_networks_vs_one_pixel_attack/,Numanrsheidat,1537125751,Are capsnets resistant to one pixel attacks or are they just better than cnn?,1,6
86,2018-9-17,2018,9,17,6,9ge9b0,"Semantic Segmentation Suite in TensorFlow. Implement, train, and test new Semantic Segmentation models easily!",https://www.reddit.com/r/deeplearning/comments/9ge9b0/semantic_segmentation_suite_in_tensorflow/,gseif94,1537132551,,0,7
87,2018-9-17,2018,9,17,7,9gf177,"Google's tpu have a lot of performance far exceeds gpu, will TPU completely replace gpu in artificial intelligence ?",https://www.reddit.com/r/deeplearning/comments/9gf177/googles_tpu_have_a_lot_of_performance_far_exceeds/,asda43asdf23423,1537138707,the  gpu  will not be necessary in artificial intelligence  ?,3,1
88,2018-9-17,2018,9,17,23,9gkr1q,CPU power for deep learning model processing,https://www.reddit.com/r/deeplearning/comments/9gkr1q/cpu_power_for_deep_learning_model_processing/,suraty,1537194260,"Hello,
In a system
CPU = Intel(R) Xeon(R) CPU E5-2699 v4 @ 2.20GHz 2.20 GHz (2 processor)
Ram = 64.0 GB
Windows10

I installed Keras on it to deep learning programming.
My models often contain about 20 million parameters. 
Is it a suitable system to run the deep learning models?
Thank you",3,2
89,2018-9-18,2018,9,18,1,9glk4o,How does a deconvolution layer work?,https://www.reddit.com/r/deeplearning/comments/9glk4o/how_does_a_deconvolution_layer_work/,thepixelatedguy,1537200053,"I have read some literature of deconvolutional layers of transpose convolutions but i am still confused about the complete architecture of these networks,why do we substract bias from the input before multiplying with filters and is the a non-linear activation used after a transpose convolution?",0,2
90,2018-9-18,2018,9,18,1,9glyhr,Does horizontally flipping a face during data augmentation helps in face recognition?,https://www.reddit.com/r/deeplearning/comments/9glyhr/does_horizontally_flipping_a_face_during_data/,rexlow0823,1537202576,"Had a weird thought this whole day and decided to get it out. As per title, so when doing face recognition we generally want to acquire as many samples of faces of a person as possible. So one of the ways I came up is to horizontally flip the face of an image sample, as what we would usually do in object recognition. 

If anyone has done it before, how does it affect the Embeddings, lets take FaceNet for example. 

Thanks. ",0,0
91,2018-9-18,2018,9,18,3,9gmx3z,AI FINDS MORE SPACE CHATTER,https://www.reddit.com/r/deeplearning/comments/9gmx3z/ai_finds_more_space_chatter/,keghn,1537208943,,0,5
92,2018-9-18,2018,9,18,15,9gscwp,A dataset contained spatial and temporal features and CNN model,https://www.reddit.com/r/deeplearning/comments/9gscwp/a_dataset_contained_spatial_and_temporal_features/,suraty,1537251830,"Hello, 

A dataset is contained of spatial and temporal features.

It contains the time series data (2 min intervals) of the sections of a map.

It is 320*480 (320 map sections and 480-time intervals). Each row belongs to a section and each column is a time interval. So each cell in the dataset is a value of data in a map section in a time interval.

I would like to make a model to import all map sections in 40 min and predict the following 10 next min of all map sections.

So the input shape equals 320*20 and the output shape will be 320*5.

I split data to 320*20 as X and 320*5 as Y samples.

The input and the output of the model are 2-dimensional matrixes.

I can consider the input as a one channel image (320*20*1) and it is possible to use a CNN model.

The codes of the final architecture of my model:

    model = models.Sequential()
    model.add(Conv2D(256,(3, 3),
                 activation='relu',
                 input_shape=(320,20,1), padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))

    model.add(Flatten())
    model.add(Dense(1600))

    model.summary()

The Loss value (MSE) is about 70. Is it lower than the random prediction?

I reshaped the output to 1600 (320*5) which the final Dense layer expects.

While the output is 2d. Does it make the model erroneous?

Thank you",0,6
93,2018-9-18,2018,9,18,18,9gtc9s,Trainable vs Non Trainable Parameters,https://www.reddit.com/r/deeplearning/comments/9gtc9s/trainable_vs_non_trainable_parameters/,PiAreSqured,1537263355,"I am using LSTM's for a project, I am using keras for prototyping. This is what the summary looks like

    Layer (type)                 Output Shape              Param #   
    =================================================================
    embedding_12 (Embedding)     (None, 30, 300)           29372700  
    _________________________________________________________________
    bidirectional_21 (Bidirectio (None, 30, 64)            85248     
    _________________________________________________________________
    dropout_11 (Dropout)         (None, 30, 64)            0         
    _________________________________________________________________
    bidirectional_22 (Bidirectio (None, 40)                13600     
    _________________________________________________________________
    dense_11 (Dense)             (None, 2)                 82        
    =================================================================
    Total params: 29,471,630
    Trainable params: 29,471,630
    Non-trainable params: 0

I have 661119 training samples, and from what I have read online and from discussions is that ideally one should have less trainable parameters then the training examples. I am using pre-trained word embedding. 

So the questions are:

1. As I know a little bit about using pre-trained weights, one has to train it for few iterations and then freeze them, but if it train them then the trainable parameters exceeds the number of samples and I can not justify if my model is not just memorizing instead of learning something. 
2. If I freeze the embedding layer, the performance of the model decrease by 10% (when I do not freeze the embedding layer, I am using early stopping to make sure that my model do not overfit, training pre-trained models generally overfits, but I am making sure mine doesn't).  So the question is should I take 10% dip and ensure that my trainable parameters are less than my training samples or not?
3. How to interpret these trainable parameters?

It would be really helpful if some one could point me out in this direction, some resources or papers explaining this. 

Thank You!

&amp;#x200B;

&amp;#x200B;",6,3
94,2018-9-19,2018,9,19,0,9gw0xi,How to calculate memory usage of NNs,https://www.reddit.com/r/deeplearning/comments/9gw0xi/how_to_calculate_memory_usage_of_nns/,DuckDuckFooGoo,1537285943,What are the steps to theoretically calculate the needed CPU or GPU RAM per processor,4,2
95,2018-9-19,2018,9,19,1,9gwkjq,convert videos (eg. .avi) to TensorFlow's tfrecords file format,https://www.reddit.com/r/deeplearning/comments/9gwkjq/convert_videos_eg_avi_to_tensorflows_tfrecords/,whiletrue2,1537289598,,0,2
96,2018-9-19,2018,9,19,5,9gykjc,Backpropagation for any Network,https://www.reddit.com/r/deeplearning/comments/9gykjc/backpropagation_for_any_network/,mrathi12,1537303286,,2,7
97,2018-9-19,2018,9,19,16,9h30fx,[D] Anyone having trouble reading a particular paper ? Post it here and we'll help figure out any parts you are stuck on | Anyone having trouble finding papers on a particular concept ? Post it here and we'll help you find papers on that topic [ROUND 3],https://www.reddit.com/r/deeplearning/comments/9h30fx/d_anyone_having_trouble_reading_a_particular/,harshalmittal4,1537341255,,2,1
98,2018-9-19,2018,9,19,16,9h34p7,Attention mechanism,https://www.reddit.com/r/deeplearning/comments/9h34p7/attention_mechanism/,suraty,1537342678,"Hello,
I am a beginner in deep learning.
What is the attention mechanism in CNN and LSTM networks in simple words?
IS there any simple and short code for example?

Thank you",3,11
99,2018-9-20,2018,9,20,0,9h605w,Profiling user's preferences based on tagged pictures,https://www.reddit.com/r/deeplearning/comments/9h605w/profiling_users_preferences_based_on_tagged/,Iddogal,1537369993,"Hello, I would like to create a DL model using a dataset with pictures tagged from 1 to 5 by a specific user.
I was hoping it will learn his specific preferences on those pictures, understand and predict his specific preferences on pictures of the same kind. 
I have read about surrogate modeling and wondered if there are algorithms of that kind that models a person point of view, and if not then any other kind of profiling models. Specific on pictures of faces would really help and models with academic research are even better. Thanks in advance.",0,1
100,2018-9-20,2018,9,20,2,9h73vn,Semantic Segmentation with Deep Learning: A guide and code,https://www.reddit.com/r/deeplearning/comments/9h73vn/semantic_segmentation_with_deep_learning_a_guide/,lohoban,1537377582,,0,2
101,2018-9-20,2018,9,20,3,9h7uq4,use-cases of variational autoencoders,https://www.reddit.com/r/deeplearning/comments/9h7uq4/usecases_of_variational_autoencoders/,kei_kuro,1537382757,"I've been reading about VAE's, and I'm really excited about different ways to apply them. Does this idea make sense in theory?

Let's say that we have a bunch of people and their messages (just an example), and we want to learn the distribution of people based on the words they use. For example, male &amp; female / young &amp; old people would speak differently. For simplicity, let's represent a person as an MxD matrix of their top M most used D-dimensional word embeddings.

Could we expect a variational autoencoder to be able to learn concept vectors like male vs female and young vs old from data like this? To be more explicit, we would train a variational autoencoder to reconstruct this matrix, and use the decoder as a way to vectorize users.",0,2
102,2018-9-20,2018,9,20,3,9h7xo4,Fast object detection in videos using region-of-interest packing,https://www.reddit.com/r/deeplearning/comments/9h7xo4/fast_object_detection_in_videos_using/,keghn,1537383322,,0,16
103,2018-9-20,2018,9,20,4,9h881n,"Attractor Networks, (A bit of) Computational Neuroscience Part III",https://www.reddit.com/r/deeplearning/comments/9h881n/attractor_networks_a_bit_of_computational/,dergthemeek,1537385324,,0,5
104,2018-9-20,2018,9,20,5,9h8vti,A learned feature descriptor for 3D LiDAR Scans (IROS-2018),https://www.reddit.com/r/deeplearning/comments/9h8vti/a_learned_feature_descriptor_for_3d_lidar_scans/,deep_descriptor,1537389826,,2,3
105,2018-9-20,2018,9,20,7,9h9pnw,Introduction to Deep Learning,https://www.reddit.com/r/deeplearning/comments/9h9pnw/introduction_to_deep_learning/,psangrene,1537395931,,0,1
106,2018-9-20,2018,9,20,17,9hdnte,Usecases of estimating object's velocity from vibrations and audio,https://www.reddit.com/r/deeplearning/comments/9hdnte/usecases_of_estimating_objects_velocity_from/,Northpaw42,1537433712,"Hey everyone, I have a following setup: microphone and a sensor capable of capturing vibrations attached to an object (position of the sensors is not yet strictly defined). As the object moves over a surface it creates vibrations and some audio signal. I want to use deep learning to estimate speed of the object from those information. I'm now in a early phase where I'm trying to figure out what this could be used for. I have come up with few ideas (such as improving precision of gaming mice on surfaces where optical flow sensor isn't optimal) but I'm looking for more. Any suggestions? ",4,5
107,2018-9-20,2018,9,20,22,9hfd2c,How to train Deep Learning models on AWS Spot Instances using Spotty (with an example for Tacotron 2 speech synthesis model),https://www.reddit.com/r/deeplearning/comments/9hfd2c/how_to_train_deep_learning_models_on_aws_spot/,apls777,1537450580,,0,1
108,2018-9-21,2018,9,21,2,9hhdo7,Illustrated Guide to Recurrent Neural Networks,https://www.reddit.com/r/deeplearning/comments/9hhdo7/illustrated_guide_to_recurrent_neural_networks/,lohoban,1537465905,,0,19
109,2018-9-21,2018,9,21,2,9hhfr8,Luminoth: Deep Learning toolkit for Computer Vision,https://www.reddit.com/r/deeplearning/comments/9hhfr8/luminoth_deep_learning_toolkit_for_computer_vision/,lohoban,1537466339,,0,0
110,2018-9-21,2018,9,21,3,9hhwum,"Can curriculum learning, GANs and others be considered as ""metaheuristics""?",https://www.reddit.com/r/deeplearning/comments/9hhwum/can_curriculum_learning_gans_and_others_be/,perilo,1537469794,Thanks.,1,1
111,2018-9-21,2018,9,21,4,9hie61,Overview of the TOP 10 Machine Learning Frameworks,https://www.reddit.com/r/deeplearning/comments/9hie61/overview_of_the_top_10_machine_learning_frameworks/,flyelephant,1537473187,,0,0
112,2018-9-21,2018,9,21,19,9hocki,Already trained model data for FakeApp,https://www.reddit.com/r/deeplearning/comments/9hocki/already_trained_model_data_for_fakeapp/,mltraningmodels,1537526004,"Hi iam looking for already trained data file of a face for Fakeapp,i don't have much GPU resources that is why.

P.s: This is just for my own curiosity and learning,and would'nt be used for any adult purposes,the modelled data can be either be of male or female face.

Thanks",1,1
113,2018-9-21,2018,9,21,21,9hpiwj,Deep Learning : Write your own Bible ( An Application of Generative Adversarial Networks (GAN)),https://www.reddit.com/r/deeplearning/comments/9hpiwj/deep_learning_write_your_own_bible_an_application/,asifrazzaq1988,1537534336,,6,14
114,2018-9-22,2018,9,22,0,9hr5vf,Attention Layer of BiDAF Model - Intuition,https://www.reddit.com/r/deeplearning/comments/9hr5vf/attention_layer_of_bidaf_model_intuition/,ImaginaryAnon,1537544580,"I am currently studying the BiDAF model for using it in Machine Comprehension task. I looked at the mathematics they implemented in the model. And I kind of understood the mathematics. But I didn't get the intuition of it. I still have a question like ""Why they did this? What's the outcome of implementing such complex functionality?"" Someone in here said that ""There is nothing like magic in any model, there's always a reason behind it's implementation"".

## Here's what I know so that you can correct me if I made any mistake
The main idea in BiDAF model is that attention should flow both waysfrom the context to the question and from the question to the context. I will be using notations ci for ith word in the comprehension/context and qi for ith word in question.

We first compute the similarity matrix S  RNM, which contains a similarity score Sij for each pair (ci , qj ) of context and question hidden states. Sij = wT sim[ci ; qj ; ci  qj ]  R Here, ci  qj is an elementwise product and wT is a weight vector. Described in equation below:

Next, we perform Context-to-Question (C2Q) Attention. (This is similar to the dot product attention). We take the row-wise softmax of S to obtain attention distributions i , which we use to take weighted sums of the question hidden states qj , yielding C2Q attention outputs ai.
https://cdn-images-1.medium.com/max/1000/1*kcckGB2g7rHT_lbKV85wUg.png

Next, we perform Question-to-Context(Q2C) Attention. For each context location i  {1, . . . , N}, we take the max of the corresponding row of the similarity matrix, mi = max_over_j(Sij)  R. Then we take the softmax over the resulting vector m  RNthis gives us an attention distribution   RN over context locations. We then use  to take a weighted sum of the context hidden states cithis is the Q2C attention output c prime.
https://cdn-images-1.medium.com/max/1000/1*VVOiMKLn1MLav3blYyPrYw.png

Finally we combine both the outputs of C2Q and Q2C as below:
https://cdn-images-1.medium.com/max/1000/1*PXdIGEJrrn3VuTlQRodAaQ.png

## My question
I got the mathematics implemented by I don't know what each step in here does intuitively. Can someone explain this please.. Thank you.",0,1
115,2018-9-22,2018,9,22,1,9hrtyg,Pose detection accurate enough to detect finger movement.,https://www.reddit.com/r/deeplearning/comments/9hrtyg/pose_detection_accurate_enough_to_detect_finger/,GingerBoredMan,1537548771,"I've been working on a robotic arm that shadows a human arm via camera as a pet project. While i can get it to move along the larger joints using PoseNet, I'm having a tough time doing the same with fingers. Anyone have any ideas to overcome this?",2,5
116,2018-9-22,2018,9,22,2,9hs98t,Learn Data Science - Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/9hs98t/learn_data_science_deep_learning_in_python/,cntcee,1537551442,,0,0
117,2018-9-22,2018,9,22,10,9hvr44,"Machine-learning system tackles speech and object recognition, all at once",https://www.reddit.com/r/deeplearning/comments/9hvr44/machinelearning_system_tackles_speech_and_object/,asifrazzaq1988,1537578107,,0,1
118,2018-9-22,2018,9,22,16,9hxydd,Computing MSE loss in a model,https://www.reddit.com/r/deeplearning/comments/9hxydd/computing_mse_loss_in_a_model/,suraty,1537601789,"Hello,
I know that the MSE value is the average squared difference between the estimated values and what is estimated. 

In a model, there are several inputs and outputs (15000 samples), while each output is a tuple of numbers (1000 cells). 

How will the MSE calculate for all of the inputs? Is it the average of MSEs of each output?

Each input is a number between 0 and 80, what will be the maximum value of the MSE?

Thank you

",1,2
119,2018-9-23,2018,9,23,2,9i1915,ACL 2018 | Paper Review: Hierarchical Neural Story Generation,https://www.reddit.com/r/deeplearning/comments/9i1915/acl_2018_paper_review_hierarchical_neural_story/,steeveHuang,1537635947,"This week, I am going to talk about an ACL'18 paper with title ""Hierarchical Neural Story Generation"", published by FAIR.

The majority of this video is about the algorithm and the Neural Net structure. It also explain concepts such as Gated Linear Units, Multi-head Attention, and Convolutional Seq2Seq. 

I hope you enjoy it :)

[https://youtu.be/U4TQoRZsj7M](https://youtu.be/U4TQoRZsj7M)",0,12
120,2018-9-23,2018,9,23,6,9i318e,How Deep The Deep Learning Is? - Measuring The Depth of Deep Learning,https://www.reddit.com/r/deeplearning/comments/9i318e/how_deep_the_deep_learning_is_measuring_the_depth/,LearningFromData,1537650035,,0,1
121,2018-9-23,2018,9,23,14,9i69mx,Instaling Tensorflow on GPU,https://www.reddit.com/r/deeplearning/comments/9i69mx/instaling_tensorflow_on_gpu/,suraty,1537681844,"Hello,
I would like to install Tensorflow on GPU. 

I searched and I found out the Nvidia graphics cards needed. Then I looked at the Device manager window for Display adapters. 

There are two items in it:

* Intel(R) HD Graphics 4600
* NVIDIA GeForce GTX 950M

How can I use the NVIDIA card for installation?

Thank you",3,1
122,2018-9-23,2018,9,23,18,9i77et,Is there any other free gpu service like google colab.,https://www.reddit.com/r/deeplearning/comments/9i77et/is_there_any_other_free_gpu_service_like_google/,sanchit2843,1537694869,,12,4
123,2018-9-23,2018,9,23,18,9i78aw,Text/Speech classification (natural language -&gt; commands to a machine) using bidirectional LSTM.,https://www.reddit.com/r/deeplearning/comments/9i78aw/textspeech_classification_natural_language/,MountainDrool,1537695229,"Hi, I'd like your honest opinion about my idea and if it's feasible as a school project/masters thesis. 

I've been delving into LSTM neural networks using TensorFlow lately and would like to use them in an automation/control application, which is mainly what my classes specialize on (sensors, controllers, PLCs etc.). During the summer break, due to an arm injury, I've gotten fascinated by speech recognition using deep neural networks, especially recurrent ones (RNNs), but I feel like all the applications are not really applicable in the field of automation. When I went to my project supervisor with this, he came up with using an RNN to classify textual inputs (ideally in my native language ... Czech) to a set of commands (left, right, up, down, lift, ...) which could then be used to control a simple machine (that I would build/simulate) like a crane or something  similar. The main problem I have with this is that i feel like it would be difficult to gather enough data that can be used for training the network for this specific application. The way I see it, I would have to manually come up with enough diverse sentences and then label them with the correct commands to be executed, which seems pretty  time consuming for just one person. Alternatively I could use unsupervised learning, but I've no experience with that and don't know if it would be applicable to something like this.

&amp;#x200B;

I'd be glad for any suggestions for improvement/alteartion of this topic. Also, if you have a suggestion about another aplication that would be better fit for automation using LSTMs, I'd really appreciate it.

&amp;#x200B;

Thank you and have a nice day.",5,7
124,2018-9-23,2018,9,23,20,9i7lmz,Graph Convolution Network,https://www.reddit.com/r/deeplearning/comments/9i7lmz/graph_convolution_network/,pcidev,1537700579,Could some one suggest some good reading sources for the graphical convolution network. Any implementation would be nice. ,1,2
125,2018-9-23,2018,9,23,20,9i7usw,Object detection easy explanation,https://www.reddit.com/r/deeplearning/comments/9i7usw/object_detection_easy_explanation/,mlwhiz,1537703860,Object Detection using Deep Learning Approaches: An End to End Theoretical Perspective @MLWhiz https://medium.com/@rahulagarwal_20850/object-detection-using-deep-learning-approaches-an-end-to-end-theoretical-perspective-4ca27eee8a9a,1,17
126,2018-9-23,2018,9,23,22,9i8cpl,Print the predicted values by a model,https://www.reddit.com/r/deeplearning/comments/9i8cpl/print_the_predicted_values_by_a_model/,suraty,1537709262,"Hello,
I use the Keras (Tensorflow backend).

After building a model, it should train and test the model by data.

My codes:

    model.compile(optimizer='adamax', loss='mse', metrics=['mae'])

    model.fit(train_x, train_y, batch_size=batch_size,
                    epochs=epochs, verbose=2,
                    callbacks=early_stopping,
                    validation_data=(val_x, val_y))


    model.evaluate(test_x, test_y)

The output of the evaluation of the model on the test data shows the loss and the metrics values and the predicted time.
I would like to print the predicted values. In other words, the numbers or values whom the model produces in the evaluation.
I like to look at the predicted numbers and compare them with expected numbers.
How can I print the output?
Thank you",1,1
127,2018-9-24,2018,9,24,2,9i9ycv,Combining improvements in deep reinforcement learning,https://www.reddit.com/r/deeplearning/comments/9i9ycv/combining_improvements_in_deep_reinforcement/,user180921,1537722338,,0,1
128,2018-9-24,2018,9,24,2,9ia3t6,Review (YouTube): Combining Improvements in Deep Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/9ia3t6/review_youtube_combining_improvements_in_deep/,user180921,1537723446,,0,1
129,2018-9-24,2018,9,24,3,9iae90,Methods for speeding up inference performance?,https://www.reddit.com/r/deeplearning/comments/9iae90/methods_for_speeding_up_inference_performance/,eovf,1537725619,"Does anyone know of a good recent review article that covers different methods for speeding up inference? Methods that work for the typical CNN that I know of are e.g.

1. Quantization
2. Pruning
3. Architectural tricks (e.g. separable convolutions)

I would especially be interested in what general tools currently exist in category (3) as well as a good intro to (1).",0,2
130,2018-9-24,2018,9,24,4,9iazlu,How is the best approach to execute a multilabel classification problem when you have a lots of zeroes?,https://www.reddit.com/r/deeplearning/comments/9iazlu/how_is_the_best_approach_to_execute_a_multilabel/,Khiel_Arclight,1537729848,"Hello!

&amp;#x200B;

I'm trying to run a multilabel classification where I use title and description of a video. However, My dataset has over 2 million videos and more than 400 classes. The main issue I'm facing is that the classes have a lot of zeroes (the most frequent class represents about 19% of the whole dataset). Is there a more comfortable way to approach this problem?",0,1
131,2018-9-24,2018,9,24,6,9ic9lo,Depthwise Separable Convolution - A FASTER CONVOLUTION!,https://www.reddit.com/r/deeplearning/comments/9ic9lo/depthwise_separable_convolution_a_faster/,italo3d,1537739265,,2,11
132,2018-9-24,2018,9,24,7,9ickdn,Multivariate DA-RNN multi-step forecasting PyTorch,https://www.reddit.com/r/deeplearning/comments/9ickdn/multivariate_darnn_multistep_forecasting_pytorch/,ThrwKps,1537741620,"I've implemented a DA-RNN model mostly [following this example in PyTorch](http://chandlerzuo.github.io/blog/2017/11/darnn) which works well for 1-step predictions for my problem. 

Now I wanted to test multi-step predictions, but I can't seem to understand how to do it without inadvertently using 'future' data from my test sample. The trivial approach would be to append the prediction at each step and use the appended input to get the next prediction and repeat for however many steps I want. However, I also need to input all exogenous factors for each time step which, unless I'm missing something obvious, I don't have unless I use future data. 

Another approach would've been training the model over a lagged time series by however many steps I want to forecast, but because previous values of the target series are used as an input for the decoder I also cannot do that, since the lagged series technically wouldn't exist ""today"" for me to forecast ""tomorrow"".

In the end, the solution I could come up with would be to also predict the exogenous factors with other models in parallel to predicting my target series so I'd have the full input for each time step without looking ahead in my test data, but this doesn't feel like a good approach. 

Is there any other way of doing a multi-step forecast that I'm missing or is this model just not suited for it?

Thanks in advance.",3,2
133,2018-9-24,2018,9,24,10,9idx3e,"Batch size greater than data length, what happens?",https://www.reddit.com/r/deeplearning/comments/9idx3e/batch_size_greater_than_data_length_what_happens/,Monster-Zero,1537753073,"I'm experimenting with batch size versus data size, but am unclear on what happens when batch size is significantly larger than the amount of rows in my data. 


Let's say the data is 800 rows long, but my batch size is 1000. What happens with the extra 200 allocated batches? Is the data just repeating to fill the extra size? Is it filled with null entries?


I seem to get better models when I increase the batch size to like 2000 (the data is approx 800 rows long) but I'm wondering why the numbers returned are better...?",1,1
134,2018-9-24,2018,9,24,14,9if965,#DeepStories,https://www.reddit.com/r/deeplearning/comments/9if965/deepstories/,1adamj,1537765788,"[\#Moment](https://www.facebook.com/hashtag/moment?source=feed_text&amp;__xts__%5B0%5D=68.ARAuQOPSehHI-xh6rjRPuFIirek3nJQ28NtJbQF3i5rlvJUySmLcu5j_93Rsw2jH1oFGGotZ4fPCp7WloYn3OlkvvnfuW8pAuNRMa3dVCUqpyGVTLXH6MYADCT2mc6_IG8Sq5GfRlDum52CVKx3MMA8LYsErYEOmDSQf6sRbP6SqIsgXGDYijvg&amp;__tn__=%2ANK-R)

Imagine belief succeeding grief.  
Shouldn't this soul already know?   
Trust not and find again, within.   
Do you believe?

Eternal adjournment, we may never, cease to find.  
Yet, we seek such in others in hopes to survive.   
Drain and drought for days, we seek. And seep. [\#Deep](https://www.facebook.com/hashtag/deep?source=feed_text&amp;__xts__%5B0%5D=68.ARAuQOPSehHI-xh6rjRPuFIirek3nJQ28NtJbQF3i5rlvJUySmLcu5j_93Rsw2jH1oFGGotZ4fPCp7WloYn3OlkvvnfuW8pAuNRMa3dVCUqpyGVTLXH6MYADCT2mc6_IG8Sq5GfRlDum52CVKx3MMA8LYsErYEOmDSQf6sRbP6SqIsgXGDYijvg&amp;__tn__=%2ANK-R)  
Let this sink..

For no one is right and two sensing, is still less than five.   
Thrive. And Survive.   
For I to exist, we must exhaust ourselves.  
Delve into you. Dive with me.

From the depths, I yearn to reach an understanding of what my life purpose may be. In a deep thinking mind-set, I spin and continue not to win. I spin &amp; sin..  
Yet, here I am, again.

Think attention seeking, speak for your self. Now let that sink.. I attack posed threats head on and forgive the stubborn. For I am..  
And in this I say,   
I forgive the author. [\#Lessthan10](https://www.facebook.com/hashtag/lessthan10?source=feed_text&amp;__xts__%5B0%5D=68.ARAuQOPSehHI-xh6rjRPuFIirek3nJQ28NtJbQF3i5rlvJUySmLcu5j_93Rsw2jH1oFGGotZ4fPCp7WloYn3OlkvvnfuW8pAuNRMa3dVCUqpyGVTLXH6MYADCT2mc6_IG8Sq5GfRlDum52CVKx3MMA8LYsErYEOmDSQf6sRbP6SqIsgXGDYijvg&amp;__tn__=%2ANK-R)",1,2
135,2018-9-24,2018,9,24,17,9ig7ib,Personal profiling algorithm,https://www.reddit.com/r/deeplearning/comments/9ig7ib/personal_profiling_algorithm/,Iddogal,1537777468,"Hello, I am trying to build a photo based tinder like application, that tries to profile a person's preferences, in order to predict future choices. 

Is there any known algorithm for deep learning picture based profiling? (Looking for academic researched algorithm)",2,3
136,2018-9-24,2018,9,24,17,9ig7o7,Need help for active learning,https://www.reddit.com/r/deeplearning/comments/9ig7o7/need_help_for_active_learning/,rmfajri,1537777543,"Hi guys, I need help converting my raw text data to work in active learning. I found one library that seem promising [https://github.com/cosmic-cortex/modAL](https://github.com/cosmic-cortex/modAL). Since I am not familiar with deep learning. How do I convert my raw text data to work in this library. Thank you for your help guys. ",0,1
137,2018-9-24,2018,9,24,21,9ihgcs,"Is this multi-class, multi-label, or something else?",https://www.reddit.com/r/deeplearning/comments/9ihgcs/is_this_multiclass_multilabel_or_something_else/,lillojohn,1537791773,"
0
down vote
favorite
I want to create a simple deep learning model in keras. I have the data of a webshop. For my model I want to use the order data. Each order has different products, those products have a category.

My goal is to know which category match with each other. Example: Computer -&gt; Keyboard , Screen -&gt; HDMI cable.

I want to do this by matching categories with each other in Keras.

The data looks like this:

[""Computer""] -&gt; [""Keyboard"", ""Mouse"", ""Monitor""]

[""Monitor""] -&gt; [""HDMI cable""]

[""Printer""] -&gt; [""Paper"", ""Cartridge""]
So, I thought to use the MultiLabelBinarizer for the y_train. There are 205 different categories. And for the X_train, I gave all the answers a unique integer.

X_train[0]:

[0]
y_train[0]:

[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]
I tried a lot of different things.

model = Sequential()
model.add(Dense(len(lb.classes_),input_shape=(1,),
kernel_initializer='he_normal', activation='softmax'))
model.compile(loss='categorical_crossentropy',
  optimizer=eval('Adam(lr=0.1)'),
  metrics=['accuracy'])
model.fit(X_train, y_train, epochs=5, verbose=1)
I tried using different kind of batch sizes, optimizers, activations, learning rates, losses. But the model seems no to be learning. It only gives a max of 3 different categories, to 205 categories.

I want to know if the MultiLabelBinarizer, is the right thing to use. X can be one of the answers, But X can not be multiple answers.

Example:

Input | Prediction | Answer | Result

Computer -&gt; Printer -&gt; Monitor, Keyboard, Mouse -&gt; False

Computer -&gt; Monitor -&gt; Monitor, Keyboard, Mouse -&gt; True

Computer -&gt; Keyboard -&gt; Monitor, Keyboard, Mouse -&gt; True

The deep learning model should only predict one category, and check if one of the Answers is true.",4,0
138,2018-9-24,2018,9,24,23,9iicf2,reinforcement learning for spam classification?,https://www.reddit.com/r/deeplearning/comments/9iicf2/reinforcement_learning_for_spam_classification/,s1korrrr,1537799067,"Hello all, I was wondering about that.

I have model prepared with MLP Classifier. I have 41 features and trying to predict is it/or will be spam or not.

Everything is real-time read and written in the MySQL DB. So I have constant updates. It has around 95% average precision/recall/accuracy. I want to achieve better recall to lower false-negatives.

I was thinking about implementing some reinforcement learning algorithms. What do you think? Does it make sense at all?",3,3
139,2018-9-24,2018,9,24,23,9iicq7,Request for Quotation of a Use Case from the DL Community; Parse Chinese Character Subtitles Physically Embedded from Videos,https://www.reddit.com/r/deeplearning/comments/9iicq7/request_for_quotation_of_a_use_case_from_the_dl/,WholesaleDreamBoy,1537799134,"I'm interested in creating a tool that can parse Chinese Character subtitles that are physically embedded in videos and output them to text with timestamps.

&amp;#x200B;

There can sometimes be additional character overlays present, static/dynamic:

*Processing img aixn3vrz17o11...*

Subtitles appear to be:

1. static
2. refresh periodically
3. pop up in the same general area
4. a solid color
5. generally standardized size

This is intended to be a SaaS product where customers would provide videos as input which I imagine should be used to further train the network; I have general development experience but no DL.  


How much resources would you estimate would be required to develop this application? Hours to code, length/size of dataset to train application, monetary costs including hiring an engineer, maintenance and other potential considerations? Thank you.",4,3
140,2018-9-25,2018,9,25,1,9ijany,Can I deploy pytorch model on web?,https://www.reddit.com/r/deeplearning/comments/9ijany/can_i_deploy_pytorch_model_on_web/,sanchit2843,1537805755,,4,4
141,2018-9-26,2018,9,26,5,9ivkht,My First Deep Learning Workshop,https://www.reddit.com/r/deeplearning/comments/9ivkht/my_first_deep_learning_workshop/,codingwoman_,1537905845,,0,9
142,2018-9-26,2018,9,26,10,9ixy6q,Sequence Modeling with Neural Networks - Part I,https://www.reddit.com/r/deeplearning/comments/9ixy6q/sequence_modeling_with_neural_networks_part_i/,psangrene,1537924071,,0,2
143,2018-9-26,2018,9,26,12,9iysrq,Deep Learning Framework Power Scores 2018,https://www.reddit.com/r/deeplearning/comments/9iysrq/deep_learning_framework_power_scores_2018/,lohoban,1537931127,,2,5
144,2018-9-26,2018,9,26,19,9j1fbi,Image Classification on the Real-World,https://www.reddit.com/r/deeplearning/comments/9j1fbi/image_classification_on_the_realworld/,marceloboeira,1537959219,,1,2
145,2018-9-26,2018,9,26,20,9j1k51,What is difference between blackbox and whitebox attack in adversarial attack domain,https://www.reddit.com/r/deeplearning/comments/9j1k51/what_is_difference_between_blackbox_and_whitebox/,postero20,1537960490," Nowadays I really interested in adversarial attack and defense against to adversarial attack. In almost paper, they said about blackbox attack and whitebox attack. Of course, there is an explanation about those things such as blackblox can not know about the model's parameters, while whitebox know about the ones. However, I can't intuitively understand this concept. Someone who knows the concept PLEASE help me! ",0,0
146,2018-9-27,2018,9,27,0,9j3lax,SUGGESTION !!!,https://www.reddit.com/r/deeplearning/comments/9j3lax/suggestion/,pcidev,1537976213,,1,0
147,2018-9-27,2018,9,27,1,9j3tf1,Segmentation using UNET,https://www.reddit.com/r/deeplearning/comments/9j3tf1/segmentation_using_unet/,ganLover,1537977674,"I am performing Segmentation using UNET

&amp;#x200B;

The input images are GREYSCALE and goundtruth images are Binary (Black/ White)

My network outputs GREYSCALE Images

I am using scikit learn- Precision and Recall for measuring the accuracy.

For that I need to have the output images in Binary, so that TP and FP can be calculated.

I can convert the  GREYSCALE Images to Binary, but I do not know how to choose the Threshold value???

Any Threshold value can change the accuracy severly.

&amp;#x200B;",4,4
148,2018-9-27,2018,9,27,1,9j3zu5,What is the future of Deep Learning?,https://www.reddit.com/r/deeplearning/comments/9j3zu5/what_is_the_future_of_deep_learning/,codingwoman_,1537978828,Where are we going with the new Deep Learning architectures? What do you think that can be or can not be improved? Will we get stuck at some point?,3,3
149,2018-9-27,2018,9,27,2,9j4lth,How does face unlocking on modern phones work?,https://www.reddit.com/r/deeplearning/comments/9j4lth/how_does_face_unlocking_on_modern_phones_work/,ILikeCheapWater,1537982886,"Particularly, I'm interested in how the Samsung Galaxy S9's face unlocking feature works. I guess it uses some form of face recognition and spoof detection (to help against images, videos, masks). Do you guys know of any resource that describes how face unlocking on modern phones work? (the more detailed the better)

I'm asking here because problems such as face recognition seem to have public state of the art solutions. I guess that a lot of companies adopt such public solutions when implementing a feature such as face unlock. I'm interested to learn more about how exactly these face unlocking features work, I mean on phones such as the Galaxy S9, the Galaxy Note 8, the OnePlus 6, the Asus ZenFone 5Z, and [other modern phones](http://blog.awok.com/10-best-face-recognition-phones-2018-face-unlock/) that use only the front camera for the face unlocking feature (everything except the iPhone X).

Main reason why I'm posting this here is that on their [website](https://news.samsung.com/global/in-depth-look-3-how-samsung-streamlined-the-galaxy-s9s-security-features) they call their combination of face recognition and iris scanning a ""deep learning-based verification solution"". Specifically for the face recognition they say ""The Galaxy S9s advanced facial-recognition technology utilizes an immense amount of data to recognize your faces distinct features from a wide range of angles"". What [approach](https://arxiv.org/abs/1804.06655) do they use? Do you guys have any resource/intuition about what exactly they are using? ",9,11
150,2018-9-27,2018,9,27,2,9j4viz,Google Brain &amp; Georgia Techs GAN Lab Visualizes Model Training in Browsers,https://www.reddit.com/r/deeplearning/comments/9j4viz/google_brain_georgia_techs_gan_lab_visualizes/,gwen0927,1537984714,,0,3
151,2018-9-27,2018,9,27,16,9jawgi,[D] Detecting region of interest in documents using deep learning?.,https://www.reddit.com/r/deeplearning/comments/9jawgi/d_detecting_region_of_interest_in_documents_using/,soulrapier,1538034840,"I have scanned documents in which the regions of interest are either  circled, or ticked and there\`s a lot of variation. I was wondering if I could segment this circled text using YOLO or any other method?. I have many such images, and thus training data is not an issue.",1,1
152,2018-9-27,2018,9,27,17,9jb4o9,"Should I get RTX 2080TI, Titan Xp, or GTX 108TI?",https://www.reddit.com/r/deeplearning/comments/9jb4o9/should_i_get_rtx_2080ti_titan_xp_or_gtx_108ti/,iamalotaibi,1538037772,"TL;TR:
As the title suggests, should I get RTX 2080TI, Titan Xp, or GTX 108TI?

Why I need a newer GPU:
I have GTX 670 and I have noticed a huge amount wasted in training, like 3-4 days on average, on my PC. In the other hand, have used K80 x4 for my school's ML/AI club when doing final model by training a larger set of data, but it requires queuing tasks, which might take a longer time than  In both cases, I am annoyed on the waiting time although I have seen my friends who has 1080TI to train the same model that took me 3 days to fully train in my machine, and it took them 7-8 hours of training, which is way better than waiting days to train my models.

Comparing GPUs:
I have saved some money for RTX 2080TI, but I have researched online and they stated that RTX 2080TI performance in training isn't that much good compared to GTX 1080TI performance and the price of RTX 2080TI. In addition, I have noticed that Titan Xp has better benchmarks than GTX 1080TI that's why I am also considering Titan Xp.

Question:
However, I have read an article saying that CUDA 10 will use RTX 2080TI's architecture fully to make the training process x10 faster than GTX 1080TI. Is that true?",6,5
153,2018-9-27,2018,9,27,18,9jb7p1,Do i still nedd to go deep into machine learning or should i study only deep learning deeply to become deep learning researcher?,https://www.reddit.com/r/deeplearning/comments/9jb7p1/do_i_still_nedd_to_go_deep_into_machine_learning/,sanchit2843,1538038837,I know basics of machine learning and few algorithms of classification and regression like decision tree svm etc. ,5,7
154,2018-9-27,2018,9,27,19,9jbp17,Attention Models: Amplifying Machine Learning Benefits for Enterprise,https://www.reddit.com/r/deeplearning/comments/9jbp17/attention_models_amplifying_machine_learning/,Victor_Stakh,1538044276,,0,1
155,2018-9-27,2018,9,27,22,9jcyln,"[Hardware] NVLink on GeForce RTX, does it pool memory?",https://www.reddit.com/r/deeplearning/comments/9jcyln/hardware_nvlink_on_geforce_rtx_does_it_pool_memory/,Karyo_Ten,1538055610,"I'm on the market for a fresh new workstation dedicated to deep learning. With the 2080ti being released today and 2080 released last week I'm very curious about the consumer NVLink.

Quadro/Tesla NVLink allows GPU to pool their memory together which enables training bigger models or using bigger batch sizes.

Can someone confirm that on consumer RTX 2080 (16GB pooled) or RTX 2080ti (22GB pooled) NVlinked?",12,3
156,2018-9-28,2018,9,28,0,9jdvww,What is a neural net exactly?  Medium,https://www.reddit.com/r/deeplearning/comments/9jdvww/what_is_a_neural_net_exactly_medium/,CuttingWithScissors,1538062468,,0,0
157,2018-9-28,2018,9,28,1,9jeimh,Learning how to learn deep learninga personal view,https://www.reddit.com/r/deeplearning/comments/9jeimh/learning_how_to_learn_deep_learninga_personal_view/,progapandist,1538066904,,0,25
158,2018-9-28,2018,9,28,3,9jfczx,AC-GAN Training,https://www.reddit.com/r/deeplearning/comments/9jfczx/acgan_training/,ganLover,1538072723,"While training the Discriminator for FAKE images from Generator-&gt;

I defined the loss function as-&gt;

True/Fake = criterionTF(discriminator\_output, discriminator\_groundTruth)

Where-&gt; discriminator\_groundTruth=0

&amp;#x200B;

Aux\_Classifier = aux\_criterion(aux\_output, aux\_label) 

&amp;#x200B;

My question is should-&gt; ""aux\_label""  have Ground Truth labels OR any random value because the inputs to Discriminator are fake, so classification does not matter.

&amp;#x200B;

Same goes for Training the Generator from Discriminator's loss

Here discriminator\_groundTruth=1

But what should be the value for-&gt; aux\_label

&amp;#x200B;

PLS HELP!!!!

&amp;#x200B;",0,1
159,2018-9-28,2018,9,28,6,9jgute,Project ideas,https://www.reddit.com/r/deeplearning/comments/9jgute/project_ideas/,Shubham3694,1538083342,"\[Suggestions\]

Hello, I'm planning on doing a project (research paper implementation, competition etc) which will have applications in Autonomous (Self-driving) cars. Can you guys me state-of-the-art papers from top conferences(CVPR, NIPS, ICCV, ECCV, ICML etc) published in 2018 or 2017?

Thanks in advance.

 ",0,0
160,2018-9-28,2018,9,28,6,9jh1kw,"Papers on Deep Learning approaches for Search Engine problems such as Ranking, Query Processing",https://www.reddit.com/r/deeplearning/comments/9jh1kw/papers_on_deep_learning_approaches_for_search/,satyapk_y12uc231,1538084679,"Hi, 

&amp;#x200B;

Are there any good papers on deep learning for query understanding/ Ranking/ relevance function?

&amp;#x200B;

I know that ad hoc relevance has few models such as DRMM, etc. Have not been able to find many deep learning papers for search engine.

&amp;#x200B;

&amp;#x200B;",0,3
161,2018-9-28,2018,9,28,8,9jhv4d,Insect brain inspired AI better than deep learning models?: No honey bee has ever gone Skynet and decided they would kill all humans,https://www.reddit.com/r/deeplearning/comments/9jhv4d/insect_brain_inspired_ai_better_than_deep/,GtothePtotheN,1538091003,,1,3
162,2018-9-28,2018,9,28,10,9jitbx,"Still curious about ""What is reinforcement learning?""",https://www.reddit.com/r/deeplearning/comments/9jitbx/still_curious_about_what_is_reinforcement_learning/,onclick360,1538098982,,3,0
163,2018-9-28,2018,9,28,17,9jl392,"Updated for Sep 2018 post ""Hardware for Deep Learning. Part 3: GPU"". Added Turing cards",https://www.reddit.com/r/deeplearning/comments/9jl392/updated_for_sep_2018_post_hardware_for_deep/,aleph_two,1538121887,[https://blog.inten.to/hardware-for-deep-learning-part-3-gpu-8906c1644664](https://blog.inten.to/hardware-for-deep-learning-part-3-gpu-8906c1644664),4,4
164,2018-9-28,2018,9,28,23,9jnczi,Limiting the model prediction values,https://www.reddit.com/r/deeplearning/comments/9jnczi/limiting_the_model_prediction_values/,suraty,1538144405,"Hello,

There is a deep model for prediction.

The outputs are some numbers between 0 and 80. (In the dataset the outputs are the mean of vehicles speed and they are 0-80)

The model:

    model = models.Sequential()
    model.add(Conv2D(256,(3, 3),
                 activation='relu',
                 input_shape=(236,20,1), padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))

    model.add(Flatten())
    model.add(Dense(1180))

    model.summary()


The model Loss value equals to 70 and I would like to reduce it.

I printed the outputs after evaluating the model by test values and some of the predicted values are more than 80 or less than 0.

How can I limit the model prediction values?

Is it a standard work?

Thank you

",1,1
165,2018-9-29,2018,9,29,0,9jnv1x,Facebook Open-Sources SKIP Programming Language,https://www.reddit.com/r/deeplearning/comments/9jnv1x/facebook_opensources_skip_programming_language/,gwen0927,1538148015,,1,2
166,2018-9-29,2018,9,29,2,9joxj4,First public 2080 Ti Deep Learning Benchmarks,https://www.reddit.com/r/deeplearning/comments/9joxj4/first_public_2080_ti_deep_learning_benchmarks/,sabalaba,1538155404,[https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks/](https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks/),11,19
167,2018-9-29,2018,9,29,3,9jpcmq,Calculating the uncertainty in deep learning,https://www.reddit.com/r/deeplearning/comments/9jpcmq/calculating_the_uncertainty_in_deep_learning/,deeplearner4,1538158326,"Hi,  
In the field of deep learning, I'm interested in calculating the uncertainty directly, for example without optimization, but with a function to do so.

I've been googling it, but couldn't find much about it, so I'd appreciate if you could direct me or share your thoughts about that.

Thanks!  
",1,1
168,2018-9-29,2018,9,29,5,9jqg33,Deep Learning setup,https://www.reddit.com/r/deeplearning/comments/9jqg33/deep_learning_setup/,Flajt,1538165928,"Hey guys, my question is about my Deep Learning setup:[https://de.pcpartpicker.com/list/Mzkv29](https://de.pcpartpicker.com/list/Mzkv29) . I want to know if it's a good setup and if I can save some money, because currently it's to much. So I would appreciate some feedback and some tips. The server should be for Deep Learning, project hosting/development and NAS (That are the reason behind the big HDD). Maybe it's useful to build two machines (But this might become very expensive)?",8,4
169,2018-9-29,2018,9,29,7,9jreeh,Deep Exploration via Bootstrapped DQN Implementation,https://www.reddit.com/r/deeplearning/comments/9jreeh/deep_exploration_via_bootstrapped_dqn/,platinumbjj,1538173121,"So I'm a Master's student taking a deep learning course this semester. As part of our course, I've been asked to do a project by the end of the semester where I have to work on Ian Osband's paper of Deep Exploration via Bootstrapped DQN. 

Unfortunately, however, we won't be covering any reinforcement learning in the course. So I have to teach myself the material. I am allowed to look at any code or resources online to complete the project. Does anyone have an idea on how I should get started? I do have a background in probability models and stochastic processes so I understand the theory of Markov decision processes and Q learning. However, I am not sure about how to get started with the code and implementing the research paper. Would appreciate your input!

Heres' the paper for reference (https://papers.nips.cc/paper/6501-deep-exploration-via-bootstrapped-dqn.pdf)",0,1
170,2018-9-29,2018,9,29,15,9jugry,Udacity AI in trading course-free,https://www.reddit.com/r/deeplearning/comments/9jugry/udacity_ai_in_trading_coursefree/,create_urself,1538202991," Hi! I found this course on udacity:[https://in.udacity.com/course/ai-for-trading--nd880](https://in.udacity.com/course/ai-for-trading--nd880),  but I don't have the money to buy this course. Is there any way I can  get the course material for free? If not, can you please suggest some  similar resources? Thanks in advance! ",4,1
171,2018-9-29,2018,9,29,16,9jus70,Ian Goodfellow: Input/Parameter linearity in DNNs,https://www.reddit.com/r/deeplearning/comments/9jus70/ian_goodfellow_inputparameter_linearity_in_dnns/,bluesky314,1538207022,"&amp;#x200B;

Ian Goodfellow says at 18:20 in [https://www.youtube.com/watch?v=CIfsB\_EYsVI](https://www.youtube.com/watch?v=CIfsB_EYsVI) : The input of the model to the output of the model is close to being linear or piecewise linear with relatively few pieces. The mapping of the parameters of the model to the output is highly non linear. So the parameters have highly non linear interactions and thats what makes training much harder. Thats why optimising parameters is much harder than optimising inputs.

I don't understand how the inputs are linear and parameters non linear. Can someone pls explain this. He goes on to show an image to illustrate this as well.",0,3
172,2018-9-29,2018,9,29,17,9jv3q3,"Learn Data Science, Machine and Deep Learning with Python",https://www.reddit.com/r/deeplearning/comments/9jv3q3/learn_data_science_machine_and_deep_learning_with/,atkarti,1538211528,,0,1
173,2018-9-29,2018,9,29,19,9jve1q,Hierarchical Attention Networks for Document Classification with web demo (Pytorch implementation),https://www.reddit.com/r/deeplearning/comments/9jve1q/hierarchical_attention_networks_for_document/,1991viet,1538215476,,2,1
174,2018-9-29,2018,9,29,19,9jvecz,Hierarchical Attention Networks for Document Classification with web demo (Pytorch implementation),https://www.reddit.com/r/deeplearning/comments/9jvecz/hierarchical_attention_networks_for_document/,1991viet,1538215595,,7,46
175,2018-9-29,2018,9,29,21,9jwdmx,"Learn Data Science, Machine and Deep Learning with Python",https://www.reddit.com/r/deeplearning/comments/9jwdmx/learn_data_science_machine_and_deep_learning_with/,frstnm,1538225436,,0,1
176,2018-9-29,2018,9,29,22,9jwqmc,Convolutional Sequence to Sequence Learning Detailed Explanation,https://www.reddit.com/r/deeplearning/comments/9jwqmc/convolutional_sequence_to_sequence_learning/,steeveHuang,1538228088,"This video is about Convolutional Sequence to Sequence. It explains the model structure in tail, how it is trained, and how it generates sequences. 

I made this video because some of you PM me about the detail of Conv Seq2Seq, and I was struggling understanding this paper while preparing for the last video, ""ACL 2018 | Paper Review: Hierarchical Neural Story Generation"".

Hope you enjoy it.:)

[https://www.youtube.com/watch?v=iXGFm7oC9TE&amp;t=7s&amp;ab\_channel=SteeveHuang](https://www.youtube.com/watch?v=iXGFm7oC9TE&amp;t=7s&amp;ab_channel=SteeveHuang)",0,3
177,2018-9-30,2018,9,30,3,9jzaan,How to finetune a network with batch normalization?,https://www.reddit.com/r/deeplearning/comments/9jzaan/how_to_finetune_a_network_with_batch_normalization/,Arsenal591,1538245386,"Let's say there is a pre-trained network, containing multiple batch-normalization stages, is used for finetuning on another  dataset. 

However, the moving means/variances are usually highly different between different datasets(while weights are usually similar). So how do I fix this problem? Do I need to first compute statistics on the new dataset?",1,2
178,2018-9-30,2018,9,30,13,9k3j9v,"Regarding the meaning of ""Eq"",",https://www.reddit.com/r/deeplearning/comments/9k3j9v/regarding_the_meaning_of_eq/,nodejsprogrammer,1538282396,"I'm not sure about the meaning of Eq in following sentence:  

Fully-Connected (FC) layers refer to the standard neural network layers from Eq .

convolution layers use Eq.

&amp;#x200B;

This Eq means equation? ",1,1
179,2018-9-30,2018,9,30,14,9k3ork,"Fairly new to deep learning, need some direction.",https://www.reddit.com/r/deeplearning/comments/9k3ork/fairly_new_to_deep_learning_need_some_direction/,thealsomepanda,1538283719,"Hey everyone!

So I am fairly new to deep learning. I know my way pretty well around Python but I still have quite a way to go. But I wanted to take on a project with a friend who creates art for an apparel company. We want to be able to have the program look at designs that are currently on shirts and with those designs create a few designs of its own. 

I've looked around for something like this but I'm having a hard time finding a place to start with this project. Can anybody help point me in the right direction?

Any help is much appreciated!",6,6
180,2018-9-30,2018,9,30,15,9k44n5,What is Unsupervised Machine learning ??,https://www.reddit.com/r/deeplearning/comments/9k44n5/what_is_unsupervised_machine_learning/,onclick360,1538287915,,3,0
181,2018-9-30,2018,9,30,18,9k4ww2,How to use jupter notebook with google cloud ubuntu vm,https://www.reddit.com/r/deeplearning/comments/9k4ww2/how_to_use_jupter_notebook_with_google_cloud/,sanchit2843,1538298626,,3,1
0,2018-10-1,2018,10,1,12,9kcpfk,Building a detector using pretrained models,https://www.reddit.com/r/deeplearning/comments/9kcpfk/building_a_detector_using_pretrained_models/,ykim104,1538363053,"Hi all! 

I have been studying ML/DL for some time and am now working on a project to learn. 

I am trying to detect boxes in the images. I first tested with a pre-trained model from Tensorflow Model API. 

I noticed that it does poorly on detecting colorful boxes. It also detects them in groups if it ever do.

I want to build a detector that can detect and locate individual boxes, and also all kind of boxes not just brown packaging boxes. What do you suggest I do? 

&amp;#x200B;

I wonder if I need to get more data. I don't think it's feasible to get hundreds of training images for each type of boxes to be able to detect them all. I also don't need it to recognize what kind of box it is, although maybe it will be helpful.  

Should I re-annotate the images with new sets of labels and bounding boxes? Maybe many of the training images had grouped the boxes.

&amp;#x200B;

For starter, I do have a set of dozen type/brand boxes I'll like to detect. Should I create a database just for these boxes to start, and treat each brand logo box as a new class? But then, I would need to add training images and retrain with a new class every time i'll like to detect different item, right? How many images per class do I need to build a robust detector?

Please advise. Thank you in advance! 

https://i.redd.it/woo0ujzqmhp11.png

*Processing img ga0k6dsomhp11...*",2,1
1,2018-10-1,2018,10,1,17,9keoac,Fashion-MNIST: Year In Review,https://www.reddit.com/r/deeplearning/comments/9keoac/fashionmnist_year_in_review/,h_xiao,1538384102,,0,1
2,2018-10-1,2018,10,1,21,9kg341,Restricting the output didn't improve the loss value of the model evaluation,https://www.reddit.com/r/deeplearning/comments/9kg341/restricting_the_output_didnt_improve_the_loss/,suraty,1538398712,"Hello,

There is a deep model for prediction.

The outputs are some numbers between 0 and 80. (In the dataset the outputs are 0-80)

I built a model and its Loss value equals to 70 and I would like to reduce it.

I printed the outputs after evaluating the model by test values and some of the predicted values are more than 80 or less than 0.

I decided to set up the final layer to predict just in 0-80 in training step, therefore I set a lambda layer after final Dense layer to clip output values.

The codes:

    def relu_advanced(x):
    return K.relu(x, max_value=80)

    def createModel4():
    model = models.Sequential()
    model.add(Conv2D(256,(3, 3),
                     activation='relu',
                     input_shape=(320,20,1), padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))

    model.add(Flatten())
    #model.add(Dense(5*320, activation= 'relu'))
    model.add(Dense(5*320))
    model.add(Lambda(relu_advanced))
    
    
    
    model.summary()
    return model

I tested the model with and without the relu_advanced and unfortunately the Loss value is increased!

I don't know what may happend that the Loss is increased while there is no value much than 80 or less than zero?

Thank you",0,1
3,2018-10-1,2018,10,1,23,9kgq9h,Object Detection with R-CNN,https://www.reddit.com/r/deeplearning/comments/9kgq9h/object_detection_with_rcnn/,ElegantFeeling,1538403574,Cool post describing main ideas of R-CNN: [https://www.mihaileric.com/posts/object-detection-with-rcnn/](https://www.mihaileric.com/posts/object-detection-with-rcnn/),0,1
4,2018-10-2,2018,10,2,2,9kihrp,Mask R-CNN using OpenCV (C++/Python),https://www.reddit.com/r/deeplearning/comments/9kihrp/mask_rcnn_using_opencv_cpython/,spmallick,1538415516,,3,1
5,2018-10-2,2018,10,2,4,9kjggu,"Is there any open source implementation of the paper - ""FACE AGING WITH CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS"" https://arxiv.org/pdf/1702.01983.pdf ?",https://www.reddit.com/r/deeplearning/comments/9kjggu/is_there_any_open_source_implementation_of_the/,kailashahirwar12,1538421914,"""FACE AGING WITH CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS"" got published in May 2017 on arxiv. It is an interesting application of Aage-cGAN or ACGAN. If you know any open source implementation of the paper or suggest me a similar github implementation, let me know.",1,1
6,2018-10-2,2018,10,2,9,9kluw3,Turning digital images to analog images,https://www.reddit.com/r/deeplearning/comments/9kluw3/turning_digital_images_to_analog_images/,microic,1538439220,"&amp;#x200B;

*Processing img r2772gkrznp11...*",0,1
7,2018-10-2,2018,10,2,10,9kmac8,"What do you mean by ""..where memory cells/recurrent components are employed.""?",https://www.reddit.com/r/deeplearning/comments/9kmac8/what_do_you_mean_by_where_memory_cellsrecurrent/,satyapk_y12uc231,1538442614,"I was a reading paper [https://arxiv.org/abs/1508.01991](https://arxiv.org/abs/1508.01991) , and if you see the last line of the first paragraph of section 2.3, it says ""Note that the inputs and outputs are directly connected, as opposed to LSTM and bidirectional LSTM networks where memory cells/recurrent components are **employed**."" Not sure what is meant by employed here.

&amp;#x200B;

&amp;#x200B;",2,1
8,2018-10-2,2018,10,2,11,9kmo3w,What papers are you reading at the moment?,https://www.reddit.com/r/deeplearning/comments/9kmo3w/what_papers_are_you_reading_at_the_moment/,easylifeforme,1538445690,"I was asked for a class to find an interesting paper that has been published in the last 1-2 years. So I want to see if anyone is reading something they find interesting/ worth sharing. If so let me know below, if you only have the title I'll take what I can get and try to find it.

Thanks ",2,1
9,2018-10-2,2018,10,2,15,9kocwf,Deep Learning to Analyse Human Activities Recorded on Videos | Analytics Insight,https://www.reddit.com/r/deeplearning/comments/9kocwf/deep_learning_to_analyse_human_activities/,analyticsinsight,1538462137,,0,1
10,2018-10-2,2018,10,2,17,9koutc,Pre-trained networks,https://www.reddit.com/r/deeplearning/comments/9koutc/pretrained_networks/,suraty,1538468562,"Hello,
I know there are some pre-trained models like VGGNet, ResNet, AlexNet, LeNet, ...

I would like to use a pre-trained network for transfer learning. I like to find a proper network which is more like to my project and use it.

Now, I need a small abstract to review the summary of all pre-trained networks in a chart or other which shows the number of layers, accuracy and other to compare them.

My project doesn't contain high level features and I need a pre-trained model with fewer layers.

My work is not a classification and the input and the output of the network are matrixes, I will change the final dense layer. My model inputs are one-channel images.

Thank you to any help",0,1
11,2018-10-3,2018,10,3,3,9kt7vf,BigGAN: A New State of the Art in Image Synthesis,https://www.reddit.com/r/deeplearning/comments/9kt7vf/biggan_a_new_state_of_the_art_in_image_synthesis/,gwen0927,1538504885,,2,1
12,2018-10-3,2018,10,3,6,9kuwd2,Free GPUs for academic purposes,https://www.reddit.com/r/deeplearning/comments/9kuwd2/free_gpus_for_academic_purposes/,sherlock31,1538516165,"Hello everyone, I am not sure whether this post violates any rule of this subreddit or not so please bear with me.  
Can anyone please suggest a method to access free GPUs where I can run my code without may limits?  
I have tried using Google Colab but I quicly reach the memory limit after some time. Any help at all will be very appreciated!!  


  
",10,1
13,2018-10-3,2018,10,3,12,9kxr2l,[GITHUB] Lightning speed web scraper for Shutterstock and GettyImages training images,https://www.reddit.com/r/deeplearning/comments/9kxr2l/github_lightning_speed_web_scraper_for/,affinitive2,1538538848,"I've spend some time to code this Python-based web scraper which can bulk download training images and videos from Shutterstock and Getty Images with blinding speed. Feel free to check it out and use it with no restrictions at all! If you like it, please remember to ""star"" the repo! :)  
[https://github.com/chuanenlin/shutterscrape](https://github.com/chuanenlin/shutterscrape) ",1,1
14,2018-10-3,2018,10,3,13,9ky4on,Interpreting Neural Networks for Classification,https://www.reddit.com/r/deeplearning/comments/9ky4on/interpreting_neural_networks_for_classification/,bluesky314,1538542382,"Hey, I just wrote a blog on Interpreting Neural Networks for Classification where I discuss HOW a neural network internally achieves its objective of classification : [**https://medium.com/@rahuld3eora/interpretable-neural-networks-classification-45cffb37725f**](https://medium.com/@rahuld3eora/interpretable-neural-networks-classification-45cffb37725f)

&amp;#x200B;

Comments and feedback appreciated",0,1
15,2018-10-3,2018,10,3,15,9kyufn,Top Interesting Facts Related to Deep Learning,https://www.reddit.com/r/deeplearning/comments/9kyufn/top_interesting_facts_related_to_deep_learning/,Technographx,1538549898,[removed],0,1
16,2018-10-3,2018,10,3,20,9l0aqc,Is there any group to have a discussion on Generative Adversarial Networks and advancements in GANS?,https://www.reddit.com/r/deeplearning/comments/9l0aqc/is_there_any_group_to_have_a_discussion_on/,kailashahirwar12,1538566247,"Is there any group, page or community to discuss Generative Adversarial Networks and it's advancements with fellow Deep Learning researchers. I tried to find a subreddit, group, but didn't find any. If anyone interested in creating a subreddit for GAN discussions, let me know. I would love to collaborate and put my views on different subtopics in GANs. ",2,1
17,2018-10-3,2018,10,3,21,9l0qko,Ocr,https://www.reddit.com/r/deeplearning/comments/9l0qko/ocr/,nithin1357,1538570039,"What is the best available ocr , that can work with both normal text and handwritten text? I know about tesseract but it is not giving good accuracy. ",10,1
18,2018-10-3,2018,10,3,21,9l0sdm,GANsResearch: To have discussions on the progress and advancements in gans.  r/GANsResearch,https://www.reddit.com/r/deeplearning/comments/9l0sdm/gansresearch_to_have_discussions_on_the_progress/,kailashahirwar12,1538570443,,0,1
19,2018-10-3,2018,10,3,22,9l0xmj,Generalized mean Pooling in CNN,https://www.reddit.com/r/deeplearning/comments/9l0xmj/generalized_mean_pooling_in_cnn/,mebpin,1538571645,Is generalized mean pooling is better than average / max pooling in CNN for extracting features from image? ,0,1
20,2018-10-3,2018,10,3,23,9l1fbf,Free webinar: Keras vs. PyTorch - Alien vs. Predator recognition with transfer learning,https://www.reddit.com/r/deeplearning/comments/9l1fbf/free_webinar_keras_vs_pytorch_alien_vs_predator/,AnnaKow,1538575315,,0,1
21,2018-10-3,2018,10,3,23,9l1qy2,What is L2 in the given equation? FR here is a Face Recognition Network(FR).,https://www.reddit.com/r/deeplearning/comments/9l1qy2/what_is_l2_in_the_given_equation_fr_here_is_a/,kailashahirwar12,1538577547,,6,1
22,2018-10-4,2018,10,4,4,9l4gbe,New sharing economy cloud GPU platform promises cheaper AI computing,https://www.reddit.com/r/deeplearning/comments/9l4gbe/new_sharing_economy_cloud_gpu_platform_promises/,RandonWriter,1538594858,,2,1
23,2018-10-4,2018,10,4,5,9l4zkd,Suggestions for the pc build to a deeplearning enthusiast?,https://www.reddit.com/r/deeplearning/comments/9l4zkd/suggestions_for_the_pc_build_to_a_deeplearning/,k_4_karan,1538598267,"Hello DeepLearners, 

I am a web-developer moving to AI field, currently pursuing deeplearning specialization course from Coursera | [deeplearning.ai](https://deeplearning.ai). As I will soon complete the course and want to explore more at home and for Kaggle competitions I decided to build a pc. **I would like to get any suggestions regarding the** [**PCPartPicker part list**](https://pcpartpicker.com/list/sgRCgw) **I plan to build.** 

I selected 1080 Ti because 2080 has nothing to compete for and 2080 Ti is out of budget. Also I wanted to know whether I should change i7 8700k with Ryzen 2700x and save some money or it will not be worth it in the long run.

 I am planning to purchase everything from local stores except GPU and SSD, which I will get from US \[online\] stores through a friend because they are &gt;20-30% costlier in India.",3,1
24,2018-10-4,2018,10,4,16,9l9uc5,The input shape in using of pre-trained models,https://www.reddit.com/r/deeplearning/comments/9l9uc5/the_input_shape_in_using_of_pretrained_models/,suraty,1538639309,"Hello, 

I am a beginner at Keras.

I would like to use the transfer learning on my data.

The shape of my inputs is (320,20,1).

But when a pre-trained model, there are some errors on my input shape.


    VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(320, 20, 1))

Error:

    The input must have 3 channels; got `input_shape=(320, 20, 1)`

If I repeat the last channel value 3 times, It makes 3 channel image. 

But, In this case, the code makes other error!

    VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(320, 20, 3))

Error:

    Input size must be at least 48x48; got `input_shape=(320, 20, 3)`

Same error for other nets like InceptionV3, ResNet50, Xception, DenseNet169, MobileNet, InceptionResNetV2

How can I set the input shape correctly?

Thank you",6,1
25,2018-10-4,2018,10,4,19,9lalpv,Using pretrained deep neural networks for commercial purposes,https://www.reddit.com/r/deeplearning/comments/9lalpv/using_pretrained_deep_neural_networks_for/,leoguti85,1538648345,"Do you guys know whether is possible (in legal plane) or not to use pretrained neural networks to build commercial products? 

Example, what if use a nnet trained on Imagenet or whatever dataset and I fine tune the network on another dataset for build a commercial products. 

Thanks.",2,1
26,2018-10-4,2018,10,4,19,9lapis,AI companies in India,https://www.reddit.com/r/deeplearning/comments/9lapis/ai_companies_in_india/,Latha202092,1538649435,"Colan Infotech is the best [artificial intelligence companies](https://colaninfotech.com/artificial-intelligence-services/) in India.We offer high quality and  intellectual [artificial intelligence services](https://colaninfotech.com/artificial-intelligence-services/) to our clients worldwide. Our [artificial intelligence providers](https://colaninfotech.com/artificial-intelligence-services/) are talented to handle all types of challenging services. We provide [ai software development](https://colaninfotech.com/artificial-intelligence-services/)solution for predictive and analytic model construction. Hire Colan Infotech developers, the [top ai companies](https://colaninfotech.com/artificial-intelligence-services/).",1,1
27,2018-10-5,2018,10,5,4,9lf9e2,[questionnaire] Age estimation from audio,https://www.reddit.com/r/deeplearning/comments/9lf9e2/questionnaire_age_estimation_from_audio/,Goron97,1538682669,[removed],0,1
28,2018-10-5,2018,10,5,5,9lfi0g,[questionnaire] Age detection from audio,https://www.reddit.com/r/deeplearning/comments/9lfi0g/questionnaire_age_detection_from_audio/,Goron97,1538684279,,7,1
29,2018-10-5,2018,10,5,9,9lhnuh,Questions about LSTM and PyTorch,https://www.reddit.com/r/deeplearning/comments/9lhnuh/questions_about_lstm_and_pytorch/,luckypanda95,1538700437,"Hi there, I'm starting to learn about LSTM recently and read some blogs (one of them is [colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)) related to it. I tried to used PyTorch for implementing the LSTM for speech tagging and I don't quite understand some of the arguments for torch.nn.LSTM.

For input\_size, is it the length of the RNN? What is hidden\_size? Is hidden\_state the same as the output? ",11,1
30,2018-10-5,2018,10,5,15,9ljq5n,Deep Learning,https://www.reddit.com/r/deeplearning/comments/9ljq5n/deep_learning/,BEPEC_Solutions,1538719376,[removed],0,1
31,2018-10-5,2018,10,5,15,9ljs5m,How can I use my own images instead of a dataset like MNIST?,https://www.reddit.com/r/deeplearning/comments/9ljs5m/how_can_i_use_my_own_images_instead_of_a_dataset/,minutestomidnight,1538719974,"I'm using information from colormaps, like these. Long story, but it's for neuro research. Also, do I absolutely need to resize it to 28x28? 

https://i.redd.it/cbfs9vxs6bq11.png",4,1
32,2018-10-5,2018,10,5,20,9lldr4,Dynamic Convolutional Neural Network,https://www.reddit.com/r/deeplearning/comments/9lldr4/dynamic_convolutional_neural_network/,gregdhill,1538738355,"CryptoKnight is a tool I developed over a year ago whilst finishing my undergraduate degree. As described in my [recent publication](https://www.mdpi.com/2078-2489/9/9/231), I have introduced a unique variant of [DCNN](https://arxiv.org/abs/1404.2188) to model variable length feature matrices from the output of a dynamic binary trace to map the symbolic execution of cryptographic code. The reasoning behind this was to build noisy 'images' that describe the relevant features and simplify malware analysis, but I do think that recurrent neural networks could offer further benefits. This is my first official research contribution and as the tool is still in its infancy, I would appreciate any comments or [collaborations](https://github.com/AbertayMachineLearningGroup/CryptoKnight)!",0,1
33,2018-10-5,2018,10,5,22,9lm6pf,"Neuton: A new, disruptive neural network framework for AI applications",https://www.reddit.com/r/deeplearning/comments/9lm6pf/neuton_a_new_disruptive_neural_network_framework/,hangel,1538745373,"**Deep learning neural networks** are behind much of the progress in **#AI** these days. [https://neuton.ai/](https://neuton.ai/) (from r/http://bellintegrators.com) is a new framework that claims to be much **#faster** and **#compac**t, and it requires less skills and training than anything the **AWS**s, **Google**s, and **Facebook**s of the world have.

By [George Anadiotis](https://www.zdnet.com/meet-the-team/us/george-anadiotis/)   
[https://www.zdnet.com/article/neuton-a-new-disruptive-neural-network-framework-for-ai-applications/](https://www.zdnet.com/article/neuton-a-new-disruptive-neural-network-framework-for-ai-applications/)",0,1
34,2018-10-6,2018,10,6,1,9lnzmw,Creating Partially Connected NNs with specified connections using Tensorflow (or something else)? (X-post from /r/MachineLearning),https://www.reddit.com/r/deeplearning/comments/9lnzmw/creating_partially_connected_nns_with_specified/,pinard9,1538758144,"Hi!

I'd  like to implement a partially connected neural network with  \~3-4  hidden layers (a sparse deep neural network?) where I can specify which  node connects to which node from the previous/next layer. So I want the  architecture to be

highly  specified/customized from the get go and I want the neural network to  optimize the weights of the specified connections, while keeping  everything else 0 during the forward pass and the back-propagation  (connection does not exist). I am a complete beginner in neural  networks. I have been recently working with tensorflow &amp;  tensorflow-keras to construct fully connected deep networks. Is there  anything in tensorflow that I should look into that might allow me to do  this? I think I should be able to specify the computational graph such  that only certain connections exist but I really have no idea yet where  to start from to do this...

While  doing some online research, I came across papers/posts on network  pruning, but it doesn't seem really relevant to me. I don't want to go  back and prune my network to make it less over-parameterized or  eliminate insignificant connections. I want the connections to be  specified and the network to be relatively sparse from the  initialization and stay that way during the back-propagation.

Thanks!

&amp;#x200B;

X-post from /r/MachineLearning: [https://www.reddit.com/r/MachineLearning/comments/9lntwy/creating\_partially\_connected\_nns\_with\_specified/](https://www.reddit.com/r/MachineLearning/comments/9lntwy/creating_partially_connected_nns_with_specified/) 

Hope posting here afterwards wasn't inappropriate.",0,1
35,2018-10-6,2018,10,6,3,9lorkh,YOLO v3 (Yolo9000 ) load and latency profiling,https://www.reddit.com/r/deeplearning/comments/9lorkh/yolo_v3_yolo9000_load_and_latency_profiling/,rafeey,1538763270,"  

I need a load profile of YOLO v3 for research purpose. Which is how  much time does each layer takes to compute the output for the next layer   and how many compute resources every layers takes. Has anyone done  this analysis? Or is there a place where I can get this analysis?

Best.",6,1
36,2018-10-6,2018,10,6,4,9lpg2x,Fastai 1.0 for PyTorch: Theres Nothing Better Out There,https://www.reddit.com/r/deeplearning/comments/9lpg2x/fastai_10_for_pytorch_theres_nothing_better_out/,trcytony,1538767963,,1,1
37,2018-10-6,2018,10,6,4,9lpk4u,Prettytensor is compatible with which version of Tensorflow?,https://www.reddit.com/r/deeplearning/comments/9lpk4u/prettytensor_is_compatible_with_which_version_of/,kailashahirwar12,1538768787,"I am using Prettytensor for a project and getting bugs related to version issues. Version of tensorflow for prettytensor is not mentioned anywhere. 

I am using Tensorflow 0.12 and prettytensor 0.7.4

If anyone working with prettytensor, help me to solve this problem.",0,1
38,2018-10-6,2018,10,6,5,9lpv3i,Hyperparameter Optimization for Keras Models,https://www.reddit.com/r/deeplearning/comments/9lpv3i/hyperparameter_optimization_for_keras_models/,mikkokotila,1538770972,,2,1
39,2018-10-6,2018,10,6,7,9lqtiu,Ultimate List of Youtube Channels for Deep Learning and Computer Vision,https://www.reddit.com/r/deeplearning/comments/9lqtiu/ultimate_list_of_youtube_channels_for_deep/,codingwoman_,1538777445,,6,1
40,2018-10-6,2018,10,6,9,9lryzf,What pre-built GPU Workstations do you recommend?,https://www.reddit.com/r/deeplearning/comments/9lryzf/what_prebuilt_gpu_workstations_do_you_recommend/,FrimannKjerulf,1538787235,"I'm looking for a good prebuilt, ready out-of-the box, GPU workstation, preferably with about 2 x 2048 Ti GPU cards. Got about $8,000 to spare. At the end of this post I've listed the options that I've found so far. What would you recommend?

&amp;#x200B;

My thought is that buying a pre-built workstation / server, will be way more expensive than building one myself, but the benefits of having a setup that is tried and tested, not having to spend weeks getting it up and running, and the possibility of having access to good support, highly out-weights the cost-difference. Allowing me to focus on my resource in stead. I'm wondering though if I'm being to pessimistic here.  Any thoughts on this? 

&amp;#x200B;

So far I've found these prebuilt options:

* Exxact [https://www.exxactcorp.com/Deep-Learning-NVIDIA-GPU-Solutions](https://www.exxactcorp.com/Deep-Learning-NVIDIA-GPU-Solutions)
* Velocity [https://www.velocitymicro.com/deep-learning-pc.php](https://www.velocitymicro.com/deep-learning-pc.php)
* Puget Systems [https://www.pugetsystems.com/recommended/Recommended-Systems-for-Machine-Learning-AI-TensorFlow-etc-174](https://www.pugetsystems.com/recommended/Recommended-Systems-for-Machine-Learning-AI-TensorFlow-etc-174)
* Boxx [https://www.boxx.com/solutions/deep-learning](https://www.boxx.com/solutions/deep-learning)
* Amax [https://www.amax.com/solutions/deep-learning-solutions/deep-learning-platforms/](https://www.amax.com/solutions/deep-learning-solutions/deep-learning-platforms/)
* Lambdalabs [https://lambdalabs.com/](https://lambdalabs.com/)",10,1
41,2018-10-6,2018,10,6,10,9ls7rt,Age detection using faces is classification problem or regression?,https://www.reddit.com/r/deeplearning/comments/9ls7rt/age_detection_using_faces_is_classification/,sanchit2843,1538789555,,4,1
42,2018-10-7,2018,10,7,1,9lx7xv,Deep Learning in educationand teaching,https://www.reddit.com/r/deeplearning/comments/9lx7xv/deep_learning_in_educationand_teaching/,anilmaddala,1538843162,"How can AI and deeplearning impact education and teaching?

I specifically am looking for any research/resources which point to how AI can make learning easy for students.

Any other possible applications/use cases in terms of education and teaching?",1,1
43,2018-10-7,2018,10,7,8,9m0ixp,Simple Introduction to Computer Vision in Under 1 Hour(Tensorflow + Keras),https://www.reddit.com/r/deeplearning/comments/9m0ixp/simple_introduction_to_computer_vision_in_under_1/,hisairnessag3,1538867694,,0,1
44,2018-10-7,2018,10,7,22,9m4x4t,"Master Deep Learning, and Break into Artificial Intelligence",https://www.reddit.com/r/deeplearning/comments/9m4x4t/master_deep_learning_and_break_into_artificial/,dthgs,1538917813,,0,1
45,2018-10-8,2018,10,8,4,9m84c8,Which UK universities offer the best AI undergraduate programs?,https://www.reddit.com/r/deeplearning/comments/9m84c8/which_uk_universities_offer_the_best_ai/,cosmoserdean,1538941750,I'm looking to study Computer Science in the UK with a focus on machine learning. What universities would you recommend?,1,1
46,2018-10-8,2018,10,8,10,9malro,Fine tuning resnet50 through keras for single channel,https://www.reddit.com/r/deeplearning/comments/9malro/fine_tuning_resnet50_through_keras_for_single/,anubhav445,1538962024,"I am a beginner at deep learning. I wanted to find an easy way to fine tune resnet50(with imagenet weights) for grayscale images i.e. number of channels is 1 instead of 3(default) for my medical image dataset. 
I came across keras applications which let's me initialize resnet50 with imagenet weights. However, I am not able to tweak the number of channels. How can I do so?
Thanks for the help",0,1
47,2018-10-8,2018,10,8,14,9mc816,"Learn how Kaggle, a popular Deep Learning Practice Platform, can help YOU boost your career in 8 Minutes! Simply Explained :)",https://www.reddit.com/r/deeplearning/comments/9mc816/learn_how_kaggle_a_popular_deep_learning_practice/,DiscoverAI,1538977260,,0,1
48,2018-10-8,2018,10,8,16,9mco11,Introduction to Deep Learning with Keras and Tensorflow,https://www.reddit.com/r/deeplearning/comments/9mco11/introduction_to_deep_learning_with_keras_and/,KateParryz,1538982159,"**Deep Learning has already conquered areas such as image  recognition, NLP, voice recognition, and is a must-know tool for every  Data Practitioner. This tutorial for aspiring Deep Learners will consist  of a quick blunt Deep Learning overview followed by a hands-on tutorial  that will teach you how to get started using Keras and Tesorflow.** 

https://i.redd.it/l6ddzy8kuwq11.png

 [https://codequs.com/p/ByYw\_KTVm/](https://codequs.com/p/ByYw_KTVm/)",1,1
49,2018-10-8,2018,10,8,16,9mcrsa,Is paperspace the cheapest way to experiment with deep learning,https://www.reddit.com/r/deeplearning/comments/9mcrsa/is_paperspace_the_cheapest_way_to_experiment_with/,manjush3v,1538983347,"I have been checking options to get a gpu machine to train deep learning models. I tried my laptop and it takes few days. I can't use google's free gpu, because it is my company's private data. I checked Amazon gpus and cheaper options. One of them is paperspace.com . I am just wondering if this is the best way to get your hands on gpu or there are better options ",5,1
50,2018-10-8,2018,10,8,19,9mdv2q,BEST OF ECCV2018 and BEST OF MICCAI2018 in the same online magazine!,https://www.reddit.com/r/deeplearning/comments/9mdv2q/best_of_eccv2018_and_best_of_miccai2018_in_the/,Gletta,1538996330,"Hot off the Press! Here are the links to the October 2018 issue of **Computer Vision News,** the magazine of the algorithm community published by RSIP Vision: **60 pages worth reading** about Artificial Intelligence, Deep Learning, Image Processing and Computer Vision, with the **highlights of the major conferences** held in September: **ECCV** and **MICCAI**. Technical review of a new paper at page 4 and free subscription at page 60.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2018October/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2018-october-pdf/)

Enjoy!

https://i.redd.it/3ihe5g8c0yq11.jpg",0,1
51,2018-10-8,2018,10,8,20,9mdz24,Why is ReLU the most common activation function used in neural networks?,https://www.reddit.com/r/deeplearning/comments/9mdz24/why_is_relu_the_most_common_activation_function/,ariyanhasan,1538997452,,5,1
52,2018-10-8,2018,10,8,23,9mf4s0,Deep Contextualized Word Representations With ELMo from AI2,https://www.reddit.com/r/deeplearning/comments/9mf4s0/deep_contextualized_word_representations_with/,ElegantFeeling,1539007517,"Nice blog post describing the impressive recent work by the Allen Institute for AI: https://www.mihaileric.com/posts/deep-contextualized-word-representations-elmo/
",1,1
53,2018-10-9,2018,10,9,1,9mgatx,"Which model cost the most to produce? I other words, what model probably took the most computing ""energy"" to train? (As in Gigaflop hours for example) Open source or private, if known.",https://www.reddit.com/r/deeplearning/comments/9mgatx/which_model_cost_the_most_to_produce_i_other/,wakka54,1539015540,,1,1
54,2018-10-9,2018,10,9,3,9mhopo,Deep Learning based Hand Pose Estimation (C++/Python),https://www.reddit.com/r/deeplearning/comments/9mhopo/deep_learning_based_hand_pose_estimation_cpython/,spmallick,1539024452,,1,1
55,2018-10-9,2018,10,9,4,9mi34h,STATS385: Theories of Deep Learning (Stanford),https://www.reddit.com/r/deeplearning/comments/9mi34h/stats385_theories_of_deep_learning_stanford/,ndha1995,1539027146,,0,1
56,2018-10-9,2018,10,9,11,9mldj1,Some clarification on using dual GPU build - details below.,https://www.reddit.com/r/deeplearning/comments/9mldj1/some_clarification_on_using_dual_gpu_build/,hshshsbbssbbs,1539052591,"If I have 2 1080s in SLI mode what does that mean for  deep learning ? Does the SLI make it possible to run the GPUs in parallel or could they run in parallel without the SLI ? 

If I have SLI can I still use each GPU independent so to run 2 separate training sets on each GPU ?

Thank you !",4,1
57,2018-10-9,2018,10,9,12,9mluow,How to calculate API usage cost for a Computer vision product?,https://www.reddit.com/r/deeplearning/comments/9mluow/how_to_calculate_api_usage_cost_for_a_computer/,deeplearning2018,1539056688,"We are in the process of building a computer vision product for a client but we need to be very careful with our pricing because we are already aware of what our competition has quoted this client and that's too much

A client will take a picture, send it to our servers for processing and get a Json response back

In order to arrive at a reasonable price I need to know how to effectively calculate our costs first, a rudimentary approach is to include the following costs

GPU server cost

Database server cost

Electricity cost

Warehouse cost

Backup power cost

Hardware Maintenance cost

Operational Monitoring cost per person

Internet bandwidth cost

My questions are the following

how should I calculate the CPU cycles burnt for each individual scan, what tools can help with it? 

Is that even the right approach? 

Should we charge them a fixed monthly cost instead of a per scan?

At this point I am open to any suggestions from experienced professionals

Thanks in advance",7,1
58,2018-10-9,2018,10,9,18,9mnknb,GOTO 2018  Deep Learning in Medicine  Allen Day,https://www.reddit.com/r/deeplearning/comments/9mnknb/goto_2018_deep_learning_in_medicine_allen_day/,rick-rebel,1539076024,,0,1
59,2018-10-9,2018,10,9,19,9mo4pn,[Blog post] Keras vs. PyTorch: Alien vs. Predator recognition with transfer learning,https://www.reddit.com/r/deeplearning/comments/9mo4pn/blog_post_keras_vs_pytorch_alien_vs_predator/,AnnaKow,1539082469,,0,1
60,2018-10-9,2018,10,9,23,9mpk2b,Pre-trained networks for grayscale images,https://www.reddit.com/r/deeplearning/comments/9mpk2b/pretrained_networks_for_grayscale_images/,suraty,1539094908,"Hello,
Is there any pre-trained network proper to grayscale images?
(Networks with 1 channel instead of 3)

Some models are introduced in Keras documentation,
https://keras.io/applications/#documentation-for-individual-models

Which one of them suitable?

Thank you
",0,1
61,2018-10-9,2018,10,9,23,9mpuah,Get a Grip! Berkeley Targets Dexterous Manipulation Using Deep RL,https://www.reddit.com/r/deeplearning/comments/9mpuah/get_a_grip_berkeley_targets_dexterous/,gwen0927,1539096941,,0,1
62,2018-10-10,2018,10,10,1,9mqrtl,Text intent generation and request handling doubt,https://www.reddit.com/r/deeplearning/comments/9mqrtl/text_intent_generation_and_request_handling_doubt/,Kadersk,1539103306,"  

I am developing a chatbot for assistance in career related problems for high school students as a project for our Grad course

For this purpose, i'll be going to make use of Deep Learning. The  chatbot will comprise of the following four components: Natural Language  Processing (NLP) module, decision module, Natural Language Generation  (NLG), and a database which will be connected to the decision module.  Use of NLG is done to identify human text/speech, in their natural form  (as spoken between two or more humans); this will in-turn also  facilitate achieving the purpose of establishing simulation of actual  human conversation. The decision module will be responsible for making  decisions.

But for achieving this, the chatbot needs to recognize the intent of  the user. We are planning to use the Word2Vec model , but we arent  clear on how it will actually facilitate the working? We went through  research papers but we got confused after that. Hence, we would  appreciate assistance regarding the same.",0,1
63,2018-10-10,2018,10,10,2,9mrdsw,"I am Kate Saenko, Artificial Intelligence researcher and professor at Boston University Department of Computer Science. Ask me anything!",https://www.reddit.com/r/deeplearning/comments/9mrdsw/i_am_kate_saenko_artificial_intelligence/,mgluck_23,1539107470,,1,1
64,2018-10-10,2018,10,10,3,9mrryz,Learning Acrobatics by Watching YouTube,https://www.reddit.com/r/deeplearning/comments/9mrryz/learning_acrobatics_by_watching_youtube/,xbpeng,1539110200,,0,1
65,2018-10-10,2018,10,10,3,9mrwpm,Logistic Regression in NumPy vs Keras,https://www.reddit.com/r/deeplearning/comments/9mrwpm/logistic_regression_in_numpy_vs_keras/,arjundupa,1539111135,"I implemented logistic regression for binary classification in just NumPy (on a dummy data set for a very simple problem), and now I've been wanting to the same thing with Keras.

Here's my NumPy implementation:

[https://github.com/arjung128/sigai\_tutorials/blob/master/single-layer-nn.ipynb](https://github.com/arjung128/sigai_tutorials/blob/master/single-layer-nn.ipynb)

Here's my Keras implementation:

[https://github.com/arjung128/sigai\_tutorials/blob/master/logistic\_regression\_keras.ipynb](https://github.com/arjung128/sigai_tutorials/blob/master/logistic_regression_keras.ipynb)

I've been trying real hard to get the same results, just so I know that what I'm doing in NumPy is EXACTLY what Keras does. So far, both the learned weights and the values for the loss function during training are not similar at all.

I've made sure the learning rate is the same, and I've initialized the weights in my NumPy implementation to be the same as the random initializations in Keras, but still no luck.

Any ideas?

Any help will be much appreciated, thanks in advance!",0,1
66,2018-10-10,2018,10,10,4,9ms9r4,Demystifying GAN...,https://www.reddit.com/r/deeplearning/comments/9ms9r4/demystifying_gan/,Karthik9999,1539113666,Demystifying Generative Adversarial Networks https://towardsdatascience.com/demystifying-generative-adversarial-networks-c076d8db8f44,0,1
67,2018-10-10,2018,10,10,6,9mtibw,An examination of the current state of deep learning on Android platforms,https://www.reddit.com/r/deeplearning/comments/9mtibw/an_examination_of_the_current_state_of_deep/,gwen0927,1539122341,,0,1
68,2018-10-10,2018,10,10,9,9muuy3,"Announcing the Big Data Summit + Deep Learning Lounge - Nov 6th, San Diego",https://www.reddit.com/r/deeplearning/comments/9muuy3/announcing_the_big_data_summit_deep_learning/,Mathriddle,1539132764,,0,1
69,2018-10-11,2018,10,11,7,9n445a,"Study Group for Goodfellow's Book ""Deep Learning""",https://www.reddit.com/r/deeplearning/comments/9n445a/study_group_for_goodfellows_book_deep_learning/,kal138,1539209738,"Hi,

Ive just started working through Goodfellows brilliant book [Deep Learning](https://www.deeplearningbook.org/) and thought it would be very useful to start a study group to discuss bits which are difficult to understand and also to keep us motivated!

Heres what I have in mind:

* Each week we work through a small section of the book and post questions we have on the relevant thread on blackswans.io for the rest of the group to answer.
* Each fortnight we set an optional programming challenge, e.g., create an RNN for stock price prediction using TensorFlow, and compare our code.

Id like to finish the first section *Applied Math and Machine Learning Basics* by Christmas, which translates to about 15 pages per week.

If youd like to join, please comment on [blackswans.io/post/44/](https://blackswans.io/post/44/).

Thanks!",1,1
70,2018-10-11,2018,10,11,7,9n48ex,Building a language translator from scratch with deep learning,https://www.reddit.com/r/deeplearning/comments/9n48ex/building_a_language_translator_from_scratch_with/,sammy_samster,1539210635,"Hey all,

&amp;#x200B;

First post on this thread (and reddit even). Just started studying ML and DL at the beginning of this summer in France, and couldn't help but decide an English-French language translator would be a good first project. 

I found a dataset of 2m sentences and tried using RNNs but they turned out to be really slow, and have since been surprised that so much of the literature for seq2seq concerns them. Reading further into the issue it seems there are better and faster models available such as using CNNs or just using attention mechanisms.

The Transformer is the model I found and implemented, and it reduced training time from a month to about three/four days. I thought this was phenomenal, to have gained such understanding of two languages and their relationship with each other in such a short time.

I've written up the results and my learning experience during my first project and wanted to share it. Hope it's of interest to any of you out there! Would love to hear too if anyone has suggestions for how to improve or thoughts on RNNs vs other current models in seq2seq.

[https://blog.floydhub.com/language-translator/](https://blog.floydhub.com/language-translator/)",0,1
71,2018-10-11,2018,10,11,9,9n51ys,New deep learning setup for a research lab,https://www.reddit.com/r/deeplearning/comments/9n51ys/new_deep_learning_setup_for_a_research_lab/,MyNetworkIsDeeper,1539217195,,0,1
72,2018-10-11,2018,10,11,12,9n6hh9,Choosing the right hardware for ML/DL applications,https://www.reddit.com/r/deeplearning/comments/9n6hh9/choosing_the_right_hardware_for_mldl_applications/,Nubby109,1539229219,"Hey, guys I need some help in choosing the right hardware for my laptop for ML/DL application

1. Would 8GB RAM be sufficient with a 128 GB SSD(which can be used as swap)? How much RAM should I go for?
2. Would i5 8th gen work with Nvidia GTX 1060 graphics, or should I necessarily go with i7 8th Gen with GTX 1060.

Also, if you have any suggestions, please let me know.

Thanks",4,1
73,2018-10-11,2018,10,11,16,9n7nm0,Should I learn machine learning before looking into deep learning?,https://www.reddit.com/r/deeplearning/comments/9n7nm0/should_i_learn_machine_learning_before_looking/,ahmedshaikh626,1539241346,"I enrolled in Andrew Ng's ML course, but after the first week I've chosen to un-enroll, not because it's bad but I am familiar with python but not at all with Octave and Matlab.

I am looking at [deeplearning.ai](https://deeplearning.ai) course on coursera for deep learning. Should I first learn [Sentdex's ML with python](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v) or go directly to DLearning?",21,1
74,2018-10-12,2018,10,12,0,9nawnu,Deep Learning for Advanced Additive Manufacturing,https://www.reddit.com/r/deeplearning/comments/9nawnu/deep_learning_for_advanced_additive_manufacturing/,amyne02,1539271354,,0,1
75,2018-10-12,2018,10,12,0,9nazul,Deep Learning for Advanced Additive Manufacturing,https://www.reddit.com/r/deeplearning/comments/9nazul/deep_learning_for_advanced_additive_manufacturing/,amyne02,1539271958,[https://medium.com/@amynebenali/deep-learning-for-advanced-additive-manufacturing-65157e7a1b06](https://medium.com/@amynebenali/deep-learning-for-advanced-additive-manufacturing-65157e7a1b06),0,1
76,2018-10-12,2018,10,12,1,9nbc5n,PC build for Deep Learning and Computer Vision.,https://www.reddit.com/r/deeplearning/comments/9nbc5n/pc_build_for_deep_learning_and_computer_vision/,RohitDulam,1539274333,"[https://pcpartpicker.com/list/2g9qWD](https://pcpartpicker.com/list/2g9qWD)

Above is the link to my proposed build. I'll mainly use the build for running Computer Vision and Deep Learning models, more centered around Convolutional Neural Networks. Will the RTX 2080 have better performance than gtx 1080ti in my case? Also any other suggestions to my build are also welcome. ",10,1
77,2018-10-12,2018,10,12,5,9ndlpv,2080 Ti TensorFlow GPU benchmark roundup: 2080 Ti vs 2080 vs V100 vs 1080 Ti vs Titan V,https://www.reddit.com/r/deeplearning/comments/9ndlpv/2080_ti_tensorflow_gpu_benchmark_roundup_2080_ti/,sabalaba,1539289643,,7,1
78,2018-10-12,2018,10,12,7,9nes8t,Introduction to using recurrent neural networks for the prediction of stock prices.,https://www.reddit.com/r/deeplearning/comments/9nes8t/introduction_to_using_recurrent_neural_networks/,vivekpa,1539298165,,0,1
79,2018-10-12,2018,10,12,9,9nfd4t,How effective is PCIe switching for sharing PCIe lanes? When does it be come  bottle neck?,https://www.reddit.com/r/deeplearning/comments/9nfd4t/how_effective_is_pcie_switching_for_sharing_pcie/,FrimannKjerulf,1539302718,"Would be great to be able to answer questions like: ""For a 4x 2080 Ti  server, what is the lowest amount of CPU PCIE lanes that I can use without having a big impact on performance? 

Without switching then I would probably need minimum 8 lanes per gpu, so in total 32 lanes for the gpus, and then  few extra for my M.2 and other possible periperials. So something around 40 lanes. 

BUT when using PCIe switching, how much lower can the CPU lane count be without affecting performance to much? Would 28 lanes on the CPU be ok on a motherboard that has switching?
",2,1
80,2018-10-12,2018,10,12,15,9nhrz0,Speech to Text for Non-English language,https://www.reddit.com/r/deeplearning/comments/9nhrz0/speech_to_text_for_nonenglish_language/,anilmaddala,1539324391,"I am interested in doing a speech to text and NLP model for Non-English language.

How do I go about it? Where do I start?",5,1
81,2018-10-12,2018,10,12,15,9nhtj9,Is it possible to drape/cloth a human mesh in realtime?,https://www.reddit.com/r/deeplearning/comments/9nhtj9/is_it_possible_to_drapecloth_a_human_mesh_in/,tejan1501,1539324868,I am trying to cloth a human mesh in realtime. Is there any predefined model or architecture anywhere which can be used?,2,1
82,2018-10-12,2018,10,12,18,9nitvs,Support Vector Machines VS LSTMs: How well it is justifiable to use LSTM for its Generalization properties?,https://www.reddit.com/r/deeplearning/comments/9nitvs/support_vector_machines_vs_lstms_how_well_it_is/,PiAreSqured,1539337066,"Hello all, 

The question is pretty straightforward, How well one can justify using LSTMs(Neural Networks) for text classification task in terms of ***""******Generalization""*** compared to classic support vector machines(SVM) given that for text classification SVM works better most of the time in terms of evaluation metrics.

There are numerous advantages of using LSTMs when compared to using SVMs such as scalability, parameter sensitivity, etc which are well described everywhere but when it comes to generalization, there is not much to read. Hence the question remains ""*How can one justify using LSTMs for text classification in terms of generalization when compared to SVM*""",1,1
83,2018-10-12,2018,10,12,19,9niz4g,Good tutorial or explanation about Deep Reinforcement Learning?,https://www.reddit.com/r/deeplearning/comments/9niz4g/good_tutorial_or_explanation_about_deep/,luckypanda95,1539338791,"Hi guys, I want to learn about Deep Reinforcement Learning. is there any recommended video or website out there?",1,1
84,2018-10-12,2018,10,12,19,9nj9zl,Neural Network Editor - Machine Learning - Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/9nj9zl/neural_network_editor_machine_learning_artificial/,DevTechRetopall,1539341971,,20,1
85,2018-10-12,2018,10,12,20,9njfdm,Deep learning for adult content,https://www.reddit.com/r/deeplearning/comments/9njfdm/deep_learning_for_adult_content/,danielfranca,1539343419,"Hi guys,  
The company I work is adult-content related, and we are working on some machine learning techniques to identify scenes and actions in adult movies.  
I'm totally noob in machine learning, so I was just playing with some classifiers that can successful recognize a lot of things in the scene... except the action that we want, because, you know, it's NSFW.  


So I was doing some research and found this [https://github.com/ryanjay0/miles-deep](https://github.com/ryanjay0/miles-deep)  
Which seems pretty cool and is very close to what I need to do, however, it's not maintained for a while and I couldn't compile it against more recent versions of OpenCV, and it seems that no one is looking at it (there are some unanswered issues opened about those problems already).  


Other libraries I found can only identify whether it is SFW or not, couldn't find much material specific for adult content.  


Does anyone has any tip about this? Where can I start looking, suggestions? Or maybe someone already worked with something similar.",5,1
86,2018-10-12,2018,10,12,23,9nkops,Best language to write a Multilayer Perceptron??,https://www.reddit.com/r/deeplearning/comments/9nkops/best_language_to_write_a_multilayer_perceptron/,ippasodimetaponto,1539354136,"Hi everyone! I'm a math student and in my master thesis i'm focusing on deep neural network with ReLu activation function. I wanna just create my own first MLP to make some experiment. 

What is  the best programming language? Which one do you use in your codes?",6,1
87,2018-10-13,2018,10,13,3,9nmwes,What is deep learning limitations?,https://www.reddit.com/r/deeplearning/comments/9nmwes/what_is_deep_learning_limitations/,nagdawi,1539369708,"I see deep learning can do human task very well. Image recognition, segmentation, etc. 

I am not sure about the ability of deep learning to detect the fake news. Even human can't do so. 

Are there any applications deep learning can do human can't?

Do you know any great project about detect fake news (preferably open source) is must be known?

What is the best paper you read try to solve fake news detection issue using any technique?
",8,1
88,2018-10-13,2018,10,13,4,9nnk00,REWORK London Deep Learning Summit,https://www.reddit.com/r/deeplearning/comments/9nnk00/rework_london_deep_learning_summit/,trcytony,1539374359,,0,1
89,2018-10-13,2018,10,13,6,9no4h4,GPU Technology Conference (Largest AI developer conference in DC),https://www.reddit.com/r/deeplearning/comments/9no4h4/gpu_technology_conference_largest_ai_developer/,GPUHarrison,1539378437,"The largest GPU developer conference is coming to DC in a couple of weeks. Register for free with a govt email address, use code NVCHHARRISON for 25% off registration. Lots of awesome talks, labs, etc:

&amp;#x200B;

[https://www.nvidia.com/en-us/gtc-dc/](https://www.nvidia.com/en-us/gtc-dc/)",0,1
90,2018-10-13,2018,10,13,13,9nqydq,Cat hipsterizer,https://www.reddit.com/r/deeplearning/comments/9nqydq/cat_hipsterizer/,kairess,1539403288,,3,1
91,2018-10-13,2018,10,13,14,9nrdyl,What deeplearning resource are available for mid level python developer with no math background.,https://www.reddit.com/r/deeplearning/comments/9nrdyl/what_deeplearning_resource_are_available_for_mid/,Tranceash,1539408003,,2,1
92,2018-10-13,2018,10,13,16,9nrzi4,Keras RGB image to Grayscale,https://www.reddit.com/r/deeplearning/comments/9nrzi4/keras_rgb_image_to_grayscale/,arjundupa,1539415146,"So I've been wanting to take the Labelled Faces in the Wild dataset and turn the RGB images into grayscale. Here's the function I created:

    def to_gray(arr):
        output = []
        for img in arr:
            output_img = tf.image.rgb_to_grayscale(img)
            sess = tf.Session()
            with sess.as_default():
                output_img = output_img.eval()
            output.append(output_img)
                
        return output

This works -- only problem is, it takes 0.008 min per conversion which adds up to just over 100 minutes for the entire LFW dataset -- any ideas on how I can do this more quickly and get the same output (array)?

Any ideas will be greatly appreciated, thanks!",3,1
93,2018-10-13,2018,10,13,20,9nt04u,Machine Learning: Sentiment analysis of movie reviews using LogisticRegression,https://www.reddit.com/r/deeplearning/comments/9nt04u/machine_learning_sentiment_analysis_of_movie/,Fewthp,1539429008,,0,1
94,2018-10-13,2018,10,13,21,9nta2q,DeepCon 18  Artificial Intelligence Conference,https://www.reddit.com/r/deeplearning/comments/9nta2q/deepcon_18_artificial_intelligence_conference/,codingwoman_,1539432388,,0,1
95,2018-10-13,2018,10,13,22,9nto3t,Looking for teammates to write a research paper in deeplearning/computer vision,https://www.reddit.com/r/deeplearning/comments/9nto3t/looking_for_teammates_to_write_a_research_paper/,Mrshadow143,1539436535,"hi, If you are interested to do some research in DL/CV plz ping me.

About me: I am a bachelors degree student in India who is interested in DL/CV, msg me to

 know more 

&amp;#x200B;

if this post annoyed someone I'm sorry ",5,1
96,2018-10-13,2018,10,13,22,9ntwo4,Edit the pre-trained models,https://www.reddit.com/r/deeplearning/comments/9ntwo4/edit_the_pretrained_models/,suraty,1539438859,"Hello,

I would like to use a pre-trained model on my data.

The input shape of my data is 300*20*3 and my code:

    input_tensor = Input(shape=(320, 20, 3))
    model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=True)

But it caused this error:
    Negative dimension size caused by subtracting 2 from 1 for 'block5_pool_1/MaxPool' (op: 'MaxPool') with input shapes: [?,20,1,512].

I would like to reduce the number of pretrained model layers. How can I do it?

Thank you",0,1
97,2018-10-13,2018,10,13,22,9ntxmo,DeNAs PSGAN Dresses Anime Characters at 1024x1024 Pixels,https://www.reddit.com/r/deeplearning/comments/9ntxmo/denas_psgan_dresses_anime_characters_at_1024x1024/,gwen0927,1539439094,,0,1
98,2018-10-13,2018,10,13,23,9nuc91,"CS Sophomore, interested in deep learning",https://www.reddit.com/r/deeplearning/comments/9nuc91/cs_sophomore_interested_in_deep_learning/,DillonNotDylanPlease,1539442652,"Like the title says, I'm a CS major with mid-level experience in C and basic knowledge of Java. I am also interested in Python but have just begun to start learning it. The thing is I only started coding when I first got to college so I'm kind of a newbie.

I read a LOT of A.I., M.L, and deep learning theory and I am very interested in the topic. I'm decent on my math also so that's not too much of a problem either. My question is what kind of resources are out there to teach a beginner how to start coding something like let's say a neural network for example?",2,1
99,2018-10-14,2018,10,14,6,9nx8im,"Study Group for Bishop's Book ""Pattern Recognition and Machine Learning""",https://www.reddit.com/r/deeplearning/comments/9nx8im/study_group_for_bishops_book_pattern_recognition/,kal138,1539464605,"Hi,

Since launching our [study group](https://blackswans.io/post/44/) for Goodfellow's book ""Deep Learning"", lots of people have asked us to run one for Bishop's book ""Pattern Recognition and Machine Learning"" as well. So we decided to set one up. Here's what we have in mind:

* Read roughly 20 pages each week and post questions we have on the relevant thread on blackswans.io for the rest of the group to answer.
* Each fortnight, we'll set a handful of problems to solve from the end of a chapter to bolster our understanding, and we'll compare answers.

If youd like to join, please comment on [blackswans.io/post/46/](https://blackswans.io/post/44/).

Thanks!",2,1
100,2018-10-14,2018,10,14,9,9nyo19,Kaggle Machine Learning Tutorial,https://www.reddit.com/r/deeplearning/comments/9nyo19/kaggle_machine_learning_tutorial/,DiscoverAI,1539476602,,1,1
101,2018-10-14,2018,10,14,22,9o2m8z,PROGRESSIVE GROWING OF GANS,https://www.reddit.com/r/deeplearning/comments/9o2m8z/progressive_growing_of_gans/,Karthik9999,1539522853,,0,1
102,2018-10-15,2018,10,15,0,9o3rr6,Vision4j - computer vision integrations for the JVM,https://www.reddit.com/r/deeplearning/comments/9o3rr6/vision4j_computer_vision_integrations_for_the_jvm/,dev-ai,1539532515,"Very often we need to integrate the final computer vision model with the JVM (due to business constraints) and for a given model, we want to experiment with different models. My goal with the Vision4j project is for each problem to provide:

* Java interface class
* Provide explanations for the metrics used to evaluate models
* Links to leaderboards
* List of possible implementations, e.g DeepLearning4J model or client classes for external models (Python, Lua), etc.

For every implementation, I provide:

* A docker image for CPU and GPU using nvidia-docker.
* Benchmarking image - quickly get an idea of how well the model is going to perform
* Java client

The idea is to provide quick iterations for computer vision related problems. Let me know what you guys think. :)

[Link](https://github.com/vision4j/vision4j-collection)",0,1
103,2018-10-15,2018,10,15,2,9o4k00,Neural Network in Never,https://www.reddit.com/r/deeplearning/comments/9o4k00/neural_network_in_never/,smaludzi,1539538015,,5,1
104,2018-10-15,2018,10,15,5,9o69hx,Deep Learning Via Desktop Computers,https://www.reddit.com/r/deeplearning/comments/9o69hx/deep_learning_via_desktop_computers/,Puppys_cryin,1539550379,"For the people in this sub that do deep learning on their desktop computers via a GPU, while the GPU is in use does it mean that the GPU is unavailable to power the desktop monitors?  What have you done as a work around?  ",4,1
105,2018-10-15,2018,10,15,11,9o8s1e,Fully convolutional networks for classification,https://www.reddit.com/r/deeplearning/comments/9o8s1e/fully_convolutional_networks_for_classification/,thesurfingslug,1539570920,"I'm looking for resources on classification networks that are fully convolutional.  What fully convolutional architectures are out there for classification applications?  What papers should I be reading, and what open source projects should I look at?",3,1
106,2018-10-15,2018,10,15,14,9oa0ea,Understanding CycleGAN code,https://www.reddit.com/r/deeplearning/comments/9oa0ea/understanding_cyclegan_code/,HDidwania,1539582355,"[https://github.com/eriklindernoren/Keras-GAN/blob/master/cyclegan/cyclegan.py](https://github.com/eriklindernoren/Keras-GAN/blob/master/cyclegan/cyclegan.py)  


I am referring to the above code to understand the implementation of CycleGANs. I am facing an issue understanding about the losses in code. As far as I understand the paper, there should be 4 loss terms, each corresponding to- validity of x translated to y, validity of y translated to x, forward cyclic loss, backward cyclic loss. But this code adds 2 identity losses too, making a total of 6 losses which I do not understand. ",4,1
107,2018-10-15,2018,10,15,16,9oall4,Deep Learning Market,https://www.reddit.com/r/deeplearning/comments/9oall4/deep_learning_market/,marketsandmarkets,1539589038,[removed],0,1
108,2018-10-15,2018,10,15,17,9oaq66,Face recognizer application using a deep learning model (Python and Keras),https://www.reddit.com/r/deeplearning/comments/9oaq66/face_recognizer_application_using_a_deep_learning/,sumantrajoshi,1539590623,,0,1
109,2018-10-15,2018,10,15,19,9obfpi,"Easy to understand PyTorch Implementation of PyTorch implementation of the paper Progressive Growing Of GANS For Improved Quality, Stability, And Variation. Decent Generated samples.",https://www.reddit.com/r/deeplearning/comments/9obfpi/easy_to_understand_pytorch_implementation_of/,nvnbny,1539598905,"[https://github.com/nvnbny/progressive\_growing\_of\_gans](https://github.com/nvnbny/progressive_growing_of_gans)

&amp;#x200B;

https://i.redd.it/n7pu4v2asbs11.png",0,1
110,2018-10-15,2018,10,15,19,9obi8o,Easy to understand PyTorch implementation of the paper Progressive Growing Of GANS with decent generated samples-https://github.com/nvnbny/progressive_growing_of_gans,https://www.reddit.com/r/deeplearning/comments/9obi8o/easy_to_understand_pytorch_implementation_of_the/,nvnbny,1539599648,,1,1
111,2018-10-15,2018,10,15,22,9oco8t,Run Keras-Yolo on AWS Lambda.,https://www.reddit.com/r/deeplearning/comments/9oco8t/run_kerasyolo_on_aws_lambda/,akashsoftvan,1539610123," Can we install the all library dependency in lambda function?, I have found the lambda default deployment package size 250-MB.

Library Need to Install

Tensorflow  
Keras  
Opencv

I have tired to install all library but total size is near about 300-MB.  
Is there any chance to run yolo on lambda?  
Any answer is appreciated.",2,1
112,2018-10-15,2018,10,15,22,9ocul1,Fast Object Detection with Fast R-CNN,https://www.reddit.com/r/deeplearning/comments/9ocul1/fast_object_detection_with_fast_rcnn/,ElegantFeeling,1539611480,"Blog post describing the Fast R-CNN object detection algorithm, a follow-up to the original R-CNN paper: https://www.mihaileric.com/posts/fast-object-detection-with-fast-rcnn/
",0,1
113,2018-10-16,2018,10,16,0,9odojf,GPU choosing: 1x RTX 2080 or 2x GTX 1080 (as multi gpu) is better for deep learning?,https://www.reddit.com/r/deeplearning/comments/9odojf/gpu_choosing_1x_rtx_2080_or_2x_gtx_1080_as_multi/,naszabi,1539617354,"Hi.  


In my country one RTX 2080 has the same price like two GTX 1080 (used cards). I do not know which combination I should buy.   
With two GPU I can train my models parallel with different parameters (Or one model with two gpu) [as wrote here](http://timdettmers.com/2018/08/21/which-gpu-for-deep-learning/), or using only an RTX 2080 for tensorflow models. I do not know which config is more powerful.  


I have read brenchmarks with 2080 Ti and 2x1080 Ti. (But first I want GPU cards without Ti verson - because of limit of money and watts of power supply).  
",4,1
114,2018-10-16,2018,10,16,3,9ofhei,to lazy to write school project myself need a neural network program to write it for me,https://www.reddit.com/r/deeplearning/comments/9ofhei/to_lazy_to_write_school_project_myself_need_a/,MyNameFinn,1539629049,"so in English class i have to come up with a short story but im way to lazy to come up with one myself, but theres lots of short story's on the internet so i came up with the genius idea of getting a neural network to do it for me

&amp;#x200B;

ps: i only have a basic understanding of code.",12,1
115,2018-10-16,2018,10,16,5,9ogf86,Origin of Siamese Neural Architecture?,https://www.reddit.com/r/deeplearning/comments/9ogf86/origin_of_siamese_neural_architecture/,sethcoast,1539634956,"Does anyone know when the concept of Siamese Neural Architecture was first proposed and by whom? There are papers from the early 90's that reference it by name, but none that I have read seem to have proposed the idea as a novel architecture themselves. They sometimes reference other earlier papers, which do not mention ""Siamese Architecture"" by name, but do implement a similar architecture in their experiments. That's kinda where the trail goes cold. Any help would be greatly appreciated! 

For instance, this paper  
[https://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf](https://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf)

uses a siamese neural architecture, and cites this one  
[https://www.researchgate.net/publication/30770288\_Neural\_Networks\_for\_Fingerprint\_Recognition](https://www.researchgate.net/publication/30770288_Neural_Networks_for_Fingerprint_Recognition)

 as having used one, but the latter doesn't seem to propose the siamese architecture as novel (nor does it mention it by name).",0,1
116,2018-10-16,2018,10,16,6,9ogzoi,not able to find facerec.hpp file.,https://www.reddit.com/r/deeplearning/comments/9ogzoi/not_able_to_find_facerechpp_file/,ransan123,1539638605,"Not able to find opencv2/face/facerec.hpp while building opencv with Hunter?

&amp;#x200B;

Any help will be appreciated.",1,1
117,2018-10-16,2018,10,16,11,9ojiym,How far deep learning can go?,https://www.reddit.com/r/deeplearning/comments/9ojiym/how_far_deep_learning_can_go/,as_ninja6,1539657461,"It has been an successful run for the Neural Networks and it's ever increasing. NN is used almost every problems where near human intelligence or processing is needed. 

What's next???

what do you think are some of the common problems that NNs can't produce a significant result? Is this the time to think of some different approach rather than adding conv layers for everything? Will we ever achieve AGI with deep learning approach? 

Thanks...",1,1
118,2018-10-16,2018,10,16,14,9okpfn,"Everyone is very interested to move into Data Science job roles, but they do various mistakes in their data science resume projects",https://www.reddit.com/r/deeplearning/comments/9okpfn/everyone_is_very_interested_to_move_into_data/,BEPEC_Solutions,1539668087,,0,1
119,2018-10-16,2018,10,16,15,9ol43x,Image Recognition AI Survey Questions,https://www.reddit.com/r/deeplearning/comments/9ol43x/image_recognition_ai_survey_questions/,LivyMcKaine,1539672331,"Hey everyone,

Were conducting a short (2 min) survey about image recognition based AI. Our target audience involves everyone who is currently working on or is researching AI driven image recognition solutions. The results will be completely anonymous and well share them here after the survey is complete. If you could help us out that would be great, thanks.

[https://docs.google.com/forms/d/e/1FAIpQLSfN7ZM8eGJeAXu3NZ5OaxNag1o\_HC\_v1kcoGY18FSXQ5qaGSA/viewform](https://docs.google.com/forms/d/e/1FAIpQLSfN7ZM8eGJeAXu3NZ5OaxNag1o_HC_v1kcoGY18FSXQ5qaGSA/viewform)",1,1
120,2018-10-16,2018,10,16,21,9on4ue,CNN histogram visualization with Tensorboard : does my model learn something ?,https://www.reddit.com/r/deeplearning/comments/9on4ue/cnn_histogram_visualization_with_tensorboard_does/,gandroz,1539692770,"Hi

I designed a CNN model and trained it on a given task of own. As the performances stucked, I wanted to look at the layers weights with tensorboard to see how they evolve, if I need more regularization etc. However the model seems to effectively learn something, the layer weights have always the same distribution over the training. My first idea was that those layers could be flushed, but the model performances decreased.

Here is how it looks like for the second layer

&amp;#x200B;

[second layer weights \(bias and kernel\) evolution during learning](https://i.redd.it/jpvhoidmijs11.png)

It is even worst (to my mind) for the last layer where all weight seem to converge to 0

&amp;#x200B;

[last layer weights \(bias and kernel\) evolution during learning](https://i.redd.it/va4w3s7tijs11.png)

As you can see, the bias distributions evolves during learning, but not the weights one, so I am afraid that the model only learns the bias. 

How is that possible ? What can I do to solve it ? Am I misunderstanding the plots ?",7,1
121,2018-10-16,2018,10,16,21,9onbci,Distribuated inference on low power hardware,https://www.reddit.com/r/deeplearning/comments/9onbci/distribuated_inference_on_low_power_hardware/,anilmaddala,1539694240,"Realtime inference on low power CPU is key to my project. I am running inference for object detection on a low end CPU like Raspberry Pi and I have a cluster of raspberry pis.

To ensure real time inference is it possible to split the image of one 300x300 into four 150x150 images and run each of the four through one raspberry pi? (I have access to 4 raspberry pi in cluster) I want detection to happen over the entire 300x300 image not the individual 150x150 image.

Could you please point to any documentation or prior work in this regard. Thanks.",1,1
122,2018-10-17,2018,10,17,0,9ooni8,My first article,https://www.reddit.com/r/deeplearning/comments/9ooni8/my_first_article/,sbhyd,1539703656,"I recently started working in deep learning and while developing my first project I had to go through some papers . I decided write an article related to that . I will love to receive reviews and advices from you guys .

https://medium.com/@saurabh.yadav919/brief-intro-of-medical-image-analysis-and-deep-learning-810df940d2f7",4,1
123,2018-10-17,2018,10,17,2,9opnpd,Best NLP Model Ever? Google BERT Sets New Standards in 11 Language Tasks,https://www.reddit.com/r/deeplearning/comments/9opnpd/best_nlp_model_ever_google_bert_sets_new/,trcytony,1539710058,,1,1
124,2018-10-17,2018,10,17,4,9oqvbd,"If you're looking for the best labeling/annotation tool for semantic segmentation, object detection, etc, look no further than Labelbox",https://www.reddit.com/r/deeplearning/comments/9oqvbd/if_youre_looking_for_the_best_labelingannotation/,cyrusj89,1539717771," 

You should definitely check out [Labelbox](http://labelbox.com/). They are based out of San Francisco and are funded by Google, Kleiner Perkins, and First Round. They have set out to build the most advanced data labeling tool in the world. Here are some key features:

**Customizable Labeling Interfaces**

Quickly setup segmentation (vector or pixel-wise) and classification labeling tasks using the GUI builder.

https://i.redd.it/2gaedsa8lls11.gif

**Tiled Imagery Support (Maps)**

Imagery from drones and satellites are often processed to form a mosaic of an area using techniques like photogrammetry. Use Labelbox to create bounding boxes and polygons directly on the tiled imagery (zoomable maps). Ideal for drone maps, satellite imagery and even medical data.

**Advanced Labeling Tools**

Labelbox supports Polygon, Rectangle, Line, and Point segmentation. Theres also support for pixel-wise annotation with the Superpixel and Brush tools. This allows you to have super precision and speed when annotating complicates shapes like clouds and trees for instance.

&amp;#x200B;

https://i.redd.it/ztjd0yeclls11.gif

**Concurrent Labeling Queue**

Instantly scale your labeling team to any size and Labelbox will serve up images to be labeled asynchronously. No two labelers will label the same data.

**Private and Secure Data**

Labelbox works with source data hosted on-premise or on a private cloud. The source data is accessed directly from the client computer and never shared (or accessible) by Labelbox. Check out the guide [here](https://support.labelbox.com/docs/private-on-premise).

**Collaboration**

Whether you have an in-house team of experts or are using a managed workforce to label data, you can bring all of this in one place with flexible collaboration and management tools.

The collaborators feature allows you to invite Individuals or Teams to help with a labeling project. If multiple users are collaborating on a labeling project, Labelbox distributes all of the data attached to a project to the collaborators with access. Labelbox also gives you the option to automatically measure the *consensus/agreement* on labels.

&amp;#x200B;

https://i.redd.it/o49919bglls11.gif

**Quality Assurance**

You can configure Labelbox to have more than one labeler label the same image in order to compare the quality of work and identify hard to label images or a labeler thats not following directions. This tool is called Consensus and it works by having more than one labeler (human or machine) label the same asset (image, text string, video, etc...). Once an asset has been labeled more than once, the results can be compared quantitatively (by using an equation) and a *consensus* score is calculated automatically. Auto Consensus works in real time so you can take immediate and corrective actions towards improving your training data and model performance.

Alternatively, Labelbox has a review tool so that you or your team can review every label and score them, or even put them back in the queue to be re-labeled.

**Fully Featured API**

Labelbox is an API first product. You can build and operate fully automated human in the loop machine learning pipelines. Click [here](https://support.labelbox.com/docs/labeling-api-js-reference) to read through the API docs.

**Measure Performance**

Maintain the highest quality standards for your data by keeping track of labeling task performance of individuals and teams.

&amp;#x200B;

https://i.redd.it/7zob7xrjlls11.png

**Export Your Labels**

You can export in popular formats such as JSON, CSV, Pascal VOC, COCO, and TFRecord format. You can also use the API to automatically pipe your labeled data into your ML training environment.",0,1
125,2018-10-17,2018,10,17,8,9ot1pg,[1810.04793] Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record,https://www.reddit.com/r/deeplearning/comments/9ot1pg/181004793_patient2vec_a_personalized/,kk7nc,1539733015,,0,1
126,2018-10-17,2018,10,17,8,9ot22b,Random Multimodel Deep Learning (RMDL),https://www.reddit.com/r/deeplearning/comments/9ot22b/random_multimodel_deep_learning_rmdl/,kk7nc,1539733092,,0,1
127,2018-10-17,2018,10,17,9,9otcgi,"AlphaAI is a stacked machine learning models that denoise data, automate feature extraction and train LSTM models to predict stock prices with 98% accuracy. Check it out on GitHub! Leave a star!!",https://www.reddit.com/r/deeplearning/comments/9otcgi/alphaai_is_a_stacked_machine_learning_models_that/,vivekpa,1539735337,,15,1
128,2018-10-17,2018,10,17,14,9ovsjm,Introduction to fast.ai,https://www.reddit.com/r/deeplearning/comments/9ovsjm/introduction_to_fastai/,arunoda,1539754493,,0,1
129,2018-10-17,2018,10,17,18,9ox4hm,How to Create and Deploy a Pre-Trained Word2Vec Deep Learning REST API,https://www.reddit.com/r/deeplearning/comments/9ox4hm/how_to_create_and_deploy_a_pretrained_word2vec/,Jen_Cl,1539768958,,0,1
130,2018-10-17,2018,10,17,20,9oxs08,Survey for a ML Project,https://www.reddit.com/r/deeplearning/comments/9oxs08/survey_for_a_ml_project/,Dev_Ahmed_Radwan,1539775666,"i am at collage and i am working on a project. i need you to kindly answer these two question if you can. it will take less than 30 sec (this is an early survey for the main survey) thanks in advance for your contribution

this is the google form link for the survey

[https://docs.google.com/forms/d/e/1FAIpQLSdWb9Pn9fHbbl763tnXyHW11QZ7X9DVZwz\_5pNd26aDSycdNQ/viewform](https://docs.google.com/forms/d/e/1FAIpQLSdWb9Pn9fHbbl763tnXyHW11QZ7X9DVZwz_5pNd26aDSycdNQ/viewform)",5,1
131,2018-10-18,2018,10,18,14,9p67v2,Deep-learning for spotting differences in images,https://www.reddit.com/r/deeplearning/comments/9p67v2/deeplearning_for_spotting_differences_in_images/,duythvn,1539839318,"hello guys

firstly, please let me know if there is another appropriate sub for this   
I normally have to deal with checking &amp; comparing  webpages and their original ""approved designs""  - the process is simple but tedious (for example, sometimes the header in the product is missing, or the tag line is bigger than originally approved)   
I'm wondering if there is anything that we can base on to expand into something that can be used  to at least compare screenshots (taken from those web pages) with the original designs and spot the differences 

&amp;#x200B;

Thank you",8,1
132,2018-10-18,2018,10,18,19,9p7v1b,Computer Vision with Deep Learning,https://www.reddit.com/r/deeplearning/comments/9p7v1b/computer_vision_with_deep_learning/,arunkumar_bvr,1539856884,Can anybody list out the projects and research papers for computer vision with deep learning?,4,1
133,2018-10-18,2018,10,18,19,9p83fd,Natural Language Processing with Deep Learning,https://www.reddit.com/r/deeplearning/comments/9p83fd/natural_language_processing_with_deep_learning/,arunkumar_bvr,1539859295,Can anybody list out the projects and research papers for Natural Language Processing with Deep Learning?,6,1
134,2018-10-18,2018,10,18,20,9p88gz,Large Scale Distributed Machine Learning (Deep Learning) Systems,https://www.reddit.com/r/deeplearning/comments/9p88gz/large_scale_distributed_machine_learning_deep/,arunkumar_bvr,1539860688,Can anybody list out the popular/great projects and research papers for Large Scale Distributed Machine Learning (Deep Learning) Systems?,2,1
135,2018-10-18,2018,10,18,21,9p8n9e,Computational Advertising with Recommender Systems for Targeting and Ranking Ads through Machine Learning,https://www.reddit.com/r/deeplearning/comments/9p8n9e/computational_advertising_with_recommender/,arunkumar_bvr,1539864394,Can anybody list out the popular/great projects and research papers for Computational Advertising with Recommender Systems for Targeting and Ranking Ads through Machine Learning?,3,1
136,2018-10-18,2018,10,18,23,9p9nwl,Manifold learning: what it is and how it works. Interesting article that gives clarity about manifold regularisation and dimensionality reduction.,https://www.reddit.com/r/deeplearning/comments/9p9nwl/manifold_learning_what_it_is_and_how_it_works/,vivekpa,1539872167,,0,1
137,2018-10-19,2018,10,19,5,9pcpyr,DeepMind Open-Sources RL Library TRFL,https://www.reddit.com/r/deeplearning/comments/9pcpyr/deepmind_opensources_rl_library_trfl/,gwen0927,1539892949,,0,1
138,2018-10-19,2018,10,19,5,9pd7na,Berkeley AI Research Open-Sources DeepMimic,https://www.reddit.com/r/deeplearning/comments/9pd7na/berkeley_ai_research_opensources_deepmimic/,gwen0927,1539896345,,0,1
139,2018-10-19,2018,10,19,10,9pfgbm,Tensorpad  1080ti cloud GPU for 0.49$ per hour,https://www.reddit.com/r/deeplearning/comments/9pfgbm/tensorpad_1080ti_cloud_gpu_for_049_per_hour/,whitezl0,1539913926,"We have released features that will make working with Deep Learning models much more convenient and faster.

1. Persistent storage. All instances have persistent storage now. You can upload datasets, pause and start your environment, and immediately continue training.
2. We have improved network speed. It makes your training environment reliable and responsive. Upload and download speeds are adjusted to fit you better.
3. Referral program. Recommend us to your friends, and earn 10 GPU hours from their first purchase.

Sincerely, Tensorpad team https://tensorpad.com

Follow us on twitter for updates and upcoming tutorials: https://twitter.com/tensorpad_com",3,1
140,2018-10-19,2018,10,19,15,9ph6xp,Looking for a deep learning laptop,https://www.reddit.com/r/deeplearning/comments/9ph6xp/looking_for_a_deep_learning_laptop/,clanceZ,1539930121,"I know, i know laptops are not generally the go to for deep learning. But i am a student and will be on exchange in China for a year. I dont expect to be able to reliably access any cloud resources or any servers i set up here. So the question: any advice for someone looking for laptops with decent specs at a decent price specifically for deep learning?",10,1
141,2018-10-19,2018,10,19,17,9phu2b,"R&amp;D Work for Artificial Intelligence, Machine Learning, and Deep Learning Areas",https://www.reddit.com/r/deeplearning/comments/9phu2b/rd_work_for_artificial_intelligence_machine/,arunkumar_bvr,1539937084,,2,1
142,2018-10-19,2018,10,19,19,9pigvz,Good Survey Papers on Adversarial Deep Learning,https://www.reddit.com/r/deeplearning/comments/9pigvz/good_survey_papers_on_adversarial_deep_learning/,legendkiller_007,1539943974,Can anybody suggest me links to good survey papers or sources for Adversarial Deep Learning?,1,1
143,2018-10-19,2018,10,19,21,9pj5fk,"Hi, Im new to DL and this may seem like a weird question, but I wanted to ask how does one develop the intuition/knowledge for developing new architectures in deep learning?",https://www.reddit.com/r/deeplearning/comments/9pj5fk/hi_im_new_to_dl_and_this_may_seem_like_a_weird/,S_T47,1539950474,"Like for example; developing the inception network or the resent architecture, even certain types of VAE. These dont involve simple stacking one layer after another (although that is one component of it)
So how can one learn to develops awesome architectures like these? and how can one know that a particular architecture would be great for a particular task (is it literally just testing ?)",11,1
144,2018-10-19,2018,10,19,23,9pkl1g,"Productionizing a machine learning model with an API, and iOS and Watch applications",https://www.reddit.com/r/deeplearning/comments/9pkl1g/productionizing_a_machine_learning_model_with_an/,Laboratory_one,1539961066,,2,1
145,2018-10-20,2018,10,20,2,9plv1r,"Artificial Intelligence, Machine Learning, and Deep Learning",https://www.reddit.com/r/deeplearning/comments/9plv1r/artificial_intelligence_machine_learning_and_deep/,arunkumar_bvr,1539969341,,2,1
146,2018-10-20,2018,10,20,5,9pnlok,DeepMind Releases Graph Nets Library,https://www.reddit.com/r/deeplearning/comments/9pnlok/deepmind_releases_graph_nets_library/,gwen0927,1539980726,,0,1
147,2018-10-20,2018,10,20,12,9pqpc4,Keras error : setting an array element with sequence.(in model.predict()),https://www.reddit.com/r/deeplearning/comments/9pqpc4/keras_error_setting_an_array_element_with/,keerthi_reddit,1540005187,"I'm trying to implement a classifier in deep learning . I am facing no issues while training the model and fitting the values in model but model.predict() is throwing this error even when I convert the input to bumpy array.
Can someone help me",1,1
148,2018-10-21,2018,10,21,0,9puwlq,"Hey, I just wanted to know, for time series prediction, other than normalising the data what other preprocessing should one do to attain a good prediction from a DL model?",https://www.reddit.com/r/deeplearning/comments/9puwlq/hey_i_just_wanted_to_know_for_time_series/,S_T47,1540048477,"I know its seem silly, but when I try running some of my models on time series data from Kaggle I usually get poor results! And am unsure of what kind of steps I should follow other than letting the model train.",9,1
149,2018-10-21,2018,10,21,2,9pvsnx,The Complete Guide to Master Deep Learning,https://www.reddit.com/r/deeplearning/comments/9pvsnx/the_complete_guide_to_master_deep_learning/,dnalist,1540055222,,1,1
150,2018-10-21,2018,10,21,7,9pylbt,Good mobo for 10+ card rig?,https://www.reddit.com/r/deeplearning/comments/9pylbt/good_mobo_for_10_card_rig/,oDaftDank,1540075872,"Hey everyone, I am trying to put together possibly a 12 card 1070ti rig and also possibly another 1080ti rig. I have all the components except for a proper motherboard. I'm looking for a motherboard that will support 128gb or more of RAM and enough PCI-e slots for 12 cards. Any suggestions would be much appreciated :)",18,1
151,2018-10-21,2018,10,21,11,9q05kv,Can someone take a look at code and tell if I am allowed to do this or not? { Image augmentation concept's doubt },https://www.reddit.com/r/deeplearning/comments/9q05kv/can_someone_take_a_look_at_code_and_tell_if_i_am/,bladorunnero,1540089651,"&amp;#x200B;

https://i.redd.it/00dmt5fdbgt11.png

&amp;#x200B;

Does this count as image augmentation?

Like passing augmented data for some epochs and non augmented data for some epochs. I have this for an assignment. Would it be considered cheating in any way?",5,1
152,2018-10-21,2018,10,21,13,9q0ui1,Why are autodifferentiation librarires/deep learning libraries always implemented with a computational graph?,https://www.reddit.com/r/deeplearning/comments/9q0ui1/why_are_autodifferentiation_librariresdeep/,adamits,1540096166,"Instead of, e.g., keeping a stack of closures? I feel like a functional approach to this is more intuitive and true to the specification of backpropogation.

Is using a computational graph more optimal for parallelizing computations, or better for putting work on a gpu?",6,1
153,2018-10-22,2018,10,22,6,9q7hh1,What next after finishing deep learning course by ng andrew?,https://www.reddit.com/r/deeplearning/comments/9q7hh1/what_next_after_finishing_deep_learning_course_by/,ImranAl5,1540158305,"As deep learning is a vast field, which areas have not been covered by this course? Can you share some material from where I could learn them?",4,1
154,2018-10-22,2018,10,22,8,9q8cmk,[MNIST Dataset] Missing classes with Keras???,https://www.reddit.com/r/deeplearning/comments/9q8cmk/mnist_dataset_missing_classes_with_keras/,Meloku171,1540165148," 

I'm training a ConvNet using Keras and Theano, but before doing that I decided to take a peek into the dataset, its data samples and classes... And I don't like what I'm seeing.

I'm using the following code to load both training and test datasets and count how many data samples are labeled for each one:

    import numpy as np 
    from keras.datasets import mnist  
    
    (X_train, y_train), (X_test, y_test) = mnist.load_data()  
    
    train_classes = [0,0,0,0,0,0,0,0,0,0] 
    test_classes = [0,0,0,0,0,0,0,0,0,0] 
    
    for i in y_train:
         train_classes[y_train[i]] = train_classes[y_train[i]] + 1
    for i in y_test:
         test_classes[y_test[i]] = test_classes[y_test[i]] + 1 
    
    print('Training classes: ', train_classes) 
    print('\nTesting classes: ', test_classes)

... And the results are worrying:

    (ann) C:\Users\shado\mnist&gt;python statistics.py 
    Using Theano backend. 
    Training classes: [6742, 17900, 5421, 6265, 11907, 5923, 0, 0, 0, 5842] 
    Testing classes: [1010, 1924, 1135, 0, 1940, 974, 0, 980, 0, 2037]

So as you can see from the label counts, the training dataset is missing the '6', '7' and '8' classes, while the testing dataset is missing the '3', '6' and '8' classes. And of course, the class distribution is all over the place, specially on the training dataset.

Am I downloading the wrong dataset? Am I missing something here?",2,1
155,2018-10-22,2018,10,22,14,9qasea,Recurrent Autoencoders for text similarity,https://www.reddit.com/r/deeplearning/comments/9qasea/recurrent_autoencoders_for_text_similarity/,pchelina,1540185964,"Hi,

I have a dataset of short texts in Korean close to personal writings in style and I'm looking to find a good way of representing them to measure similarity.  I am considering experimenting with a few different methods, starting from TF-IDF, LSA, LDA, through word vector-based ones, like doc2vec and some ways to compose word vectors (p-mean, WMD, weighted average).  

I wonder if using subword-level RNN's hidden states as text representations would have an advantage over these methods in capturing semantic similarity, since they seem to perform well on classification tasks. 

I'm willing to experiment with this anyway, but can't quite estimate how big of a dataset I'd need to train it in an unsupervised way like an autoencoder to get reasonable results and if it is worth the effort at all. Since the data is in Korean, I can't just use state-of-the-art models like BERT or ELMo.

I would greatly appreciate if someone shared experience dealing with a similar problem or links to papers or blogs I might have missed.

Thanks!",2,1
156,2018-10-22,2018,10,22,17,9qbrea,The Era of Computer Vision is Here | Analytics Insight,https://www.reddit.com/r/deeplearning/comments/9qbrea/the_era_of_computer_vision_is_here_analytics/,analyticsinsight,1540195897,,0,1
157,2018-10-22,2018,10,22,21,9qddws,"Implementation of NIPS 2017 paper ""Pose Guided Person Image Generation"" in PyTorch. https://arxiv.org/abs/1705.09368",https://www.reddit.com/r/deeplearning/comments/9qddws/implementation_of_nips_2017_paper_pose_guided/,iamharsshit,1540211488,,0,1
158,2018-10-22,2018,10,22,21,9qde0r,Tips before starting Fast.ai Part 1 MOOC.,https://www.reddit.com/r/deeplearning/comments/9qde0r/tips_before_starting_fastai_part_1_mooc/,captain_c0ld,1540211515,"I'm soon going to start [Fast.ai](https://Fast.ai) Practical Deep Learning for Coders MOOC. I know this course follows Top-Down approach and I have heard that each week's video is about 2 hours long and I'm going to be watching it live. So I would like to know if you have any tips for me for getting the most out of it.

&amp;#x200B;

Thanks. ",4,1
159,2018-10-22,2018,10,22,21,9qdh0p,"""Yann LeCun @EPFL - ""Self-supervised learning: could machines learn like humans?""""",https://www.reddit.com/r/deeplearning/comments/9qdh0p/yann_lecun_epfl_selfsupervised_learning_could/,dt_magic,1540212210,,1,1
160,2018-10-22,2018,10,22,22,9qdor1,Possible using 3rd Generation CPU with top graphic cards for local machine learning?,https://www.reddit.com/r/deeplearning/comments/9qdor1/possible_using_3rd_generation_cpu_with_top/,Brlala,1540213890,"Hi, I've looked around the internet if the CPU will affect the time taken to train a model but there's quite a lot of mix results. I'm planning to learn [fast.ai](https://fast.ai) course but considering the fact that renting instances may cost as much as building my own desktop in the long run, I'd like to invest in a local machine. 

Current PC Specs

* i5-3470@3.20GHz
* 1x8GBRAM
* Radeon R9 390X (Upgrading it to RTX2080Ti)
* 128GBSSD+2TBHHD

Is it possible to continue using my current desktop+upgrading the Graphic card? Will the CPU cause a bottleneck? thank you",8,1
161,2018-10-22,2018,10,22,23,9qecjl,"The Neural Aesthetic @ ITP-NYU :: 05 Visualization, deepdream, style &amp; texture synthesis",https://www.reddit.com/r/deeplearning/comments/9qecjl/the_neural_aesthetic_itpnyu_05_visualization/,keghn,1540218714,,1,1
162,2018-10-23,2018,10,23,0,9qevvr,Inception Score: A metrics to evaluate the performance of Generative Adversarial Networks.,https://www.reddit.com/r/deeplearning/comments/9qevvr/inception_score_a_metrics_to_evaluate_the/,kailashahirwar12,1540222299,"Has anyone worked with Inception score to evaluate the performance of GANs? 

Pros and cons of Inception score. 

Metrics better than Inception score.

&amp;#x200B;",0,1
163,2018-10-23,2018,10,23,7,9qimdt,Live Webinar: Manage and Version Huge Data to Accelerate Your Deep Learning Training,https://www.reddit.com/r/deeplearning/comments/9qimdt/live_webinar_manage_and_version_huge_data_to/,treguess,1540246469,"**In this webinar, you will learn how to:**   


Handle terabytes of data at scale.  
 Prepare and stream your data for deep learning training.  
 View and explore data with MissingLink query tool.  
Train deep-learning models from your own data and only share the key parameters to maintain data privacy.

&amp;#x200B;

Register now to save your spot! 

[https://learn.missinglink.ai/webinar-manage-data-like-a-pro/](https://learn.missinglink.ai/webinar-manage-data-like-a-pro/)",0,1
164,2018-10-23,2018,10,23,9,9qjmla,List of Deep Learning Cloud Service Providers - places you can rent a GPU,https://www.reddit.com/r/deeplearning/comments/9qjmla/list_of_deep_learning_cloud_service_providers/,discdiver,1540253539,"I made a list of deep learning cloud providers because I couldn't find a comprehensive one. I found 29 places where you can rent a GPU (or use one for free). Who am I missing?

&amp;#x200B;

    Alibaba
    AWS EC2
    AWS Sagemaker
    Cirrascale
    Cogeco Peer 1
    Crestle
    Deep Cognition 
    Exoscale
    FloydHub
    Google Cloud
    Google Colab
    GPUEater
    Hetzner 
    IBM Watson
    Kaggle
    Lambda
    LeaderGPU
    Microsoft Azure
    Nimbix
    Oracle
    Outscale
    Paperspace
    Penguin Computing
    Rapid Switch
    Rescale
    Salamander
    Snark.ai
    Vast.ai
    Vectordash

&amp;#x200B;

Keeping list updated at [https://github.com/discdiver/deep-learning-cloud-providers/blob/master/list.md](https://github.com/discdiver/deep-learning-cloud-providers/blob/master/list.md) and briefly discussed at [https://towardsdatascience.com/list-of-deep-learning-cloud-service-providers-579f2c769ed6](https://towardsdatascience.com/list-of-deep-learning-cloud-service-providers-579f2c769ed6)",4,1
165,2018-10-23,2018,10,23,9,9qjzz8,Free Promocode for Paperspace,https://www.reddit.com/r/deeplearning/comments/9qjzz8/free_promocode_for_paperspace/,Astafy,1540256357,"I just signed up for paperspace through [fast.ai](https://fast.ai) and got $10 to share. If anyone is interested in cloud-computing for deep learning, here's my promo code: **XCKV2UD**",2,1
166,2018-10-23,2018,10,23,11,9qkw9y,Cost function cannot converge,https://www.reddit.com/r/deeplearning/comments/9qkw9y/cost_function_cannot_converge/,warlord85,1540263383,"Hi guys, noobs question here, my cost keeps getting more and more fluctuating at the end of the training: blue chart is the actual cost, yellow is 50 point moving average. Is this normal? If not, what could possibly the cause of this? I am using a very low learning rate (10\^-6). Thank you.

[Cost function get fluctuate more and more during training](https://i.redd.it/zx3kbbqrnut11.jpg)",4,1
167,2018-10-23,2018,10,23,18,9qnb74,Top 5 Deep Learning Trends That Will Dominate 2019,https://www.reddit.com/r/deeplearning/comments/9qnb74/top_5_deep_learning_trends_that_will_dominate_2019/,fullstackanalytics1,1540286995,,1,1
168,2018-10-23,2018,10,23,20,9qo34a,Fluid Annotation.,https://www.reddit.com/r/deeplearning/comments/9qo34a/fluid_annotation/,Karthik9999,1540294370,,0,1
169,2018-10-23,2018,10,23,22,9qp1lr,Transformers: Attention is All You Need,https://www.reddit.com/r/deeplearning/comments/9qp1lr/transformers_attention_is_all_you_need/,ElegantFeeling,1540301928,"Blog post describing Google's state-of-the-art Transformer architecture: https://www.mihaileric.com/posts/transformers-attention-in-disguise/
",0,1
170,2018-10-24,2018,10,24,1,9qqlxt,Global Deep Learning In Machine Vision Market is Growing at a Significant Rate in the Forecast Period 2018-2025,https://www.reddit.com/r/deeplearning/comments/9qqlxt/global_deep_learning_in_machine_vision_market_is/,Rubin_McCarter,1540312152,,1,1
171,2018-10-24,2018,10,24,2,9qqzuw,Baidu Announces Breakthrough in Simultaneous Translation,https://www.reddit.com/r/deeplearning/comments/9qqzuw/baidu_announces_breakthrough_in_simultaneous/,gwen0927,1540314581,,0,1
172,2018-10-24,2018,10,24,2,9qremu,About future of deep learning (Question),https://www.reddit.com/r/deeplearning/comments/9qremu/about_future_of_deep_learning_question/,dorukugur,1540317292,"Hello guys, what do you think about future of deep learning? Which libraries are favorite for the future?",3,1
173,2018-10-24,2018,10,24,12,9qvzia,kernels learned by CNN,https://www.reddit.com/r/deeplearning/comments/9qvzia/kernels_learned_by_cnn/,1CSX,1540350201,"Hi, I would like to know how I can get the filters learned by my CNN (like the uploaded image). I work in Python / Tensorflow / Keras. Thank you.",7,1
174,2018-10-24,2018,10,24,21,9qzcbh,Approximating Gaussian Processes with deep neural networks?,https://www.reddit.com/r/deeplearning/comments/9qzcbh/approximating_gaussian_processes_with_deep_neural/,tsuberim,1540385348,"I've been messing with Bayesian optimization and Gaussian Processes. Seems like the Baysian approach is more ""correct"" and than DNNs because it takes to account uncertainties and is non-parametric. Though the main point of pain with it is the poor efficiency in inverting a covariance matrix (O(n^3)).
I've seen some applications of DNNs used to obtain an efficient approximation to an inefficient algorithm (E.g. Ray tracing in computer graphics), Can the same be done on Gaussian Processes? ",0,1
175,2018-10-24,2018,10,24,23,9r02gl,"Microsoft Releases Integration between Cognitive Services, Deep Learning, and Distributed Computing",https://www.reddit.com/r/deeplearning/comments/9r02gl/microsoft_releases_integration_between_cognitive/,mhamilton723,1540390658,,6,1
176,2018-10-25,2018,10,25,15,9r7q8b,[P] Machine learning research papers,https://www.reddit.com/r/deeplearning/comments/9r7q8b/p_machine_learning_research_papers/,donutloop,1540448330,,6,1
177,2018-10-25,2018,10,25,18,9r8ov5,Keras implementation of Attention mechanism in ConvNets? (question),https://www.reddit.com/r/deeplearning/comments/9r8ov5/keras_implementation_of_attention_mechanism_in/,aendrs,1540459535,"Do anyone of you know of any Keras implementation of an attention mechanism in ConvNets?

So far I have only found this one

https://github.com/dvatterott/BMM_attentional_CNN

thanks",1,1
178,2018-10-25,2018,10,25,19,9r96z4,Neural language model performing worse as training corpus grows,https://www.reddit.com/r/deeplearning/comments/9r96z4/neural_language_model_performing_worse_as/,mtanti,1540464868,Does any one know if this is something that can happen? I'm training an RNN+softmax language model on the google news corpus (LM1B) on different numbers of sentences between 3k and 300k and the perplexity on the same validation set becomes bigger the more sentences I train on. Could it be that the vocabulary is too sparse to be learned with 300k sentences?,3,1
179,2018-10-25,2018,10,25,20,9r9a49,Mode Normalization for Keras,https://www.reddit.com/r/deeplearning/comments/9r9a49/mode_normalization_for_keras/,philipperemy,1540465693,[https://github.com/philipperemy/mode-normalization](https://github.com/philipperemy/mode-normalization),0,1
180,2018-10-25,2018,10,25,23,9ranq9,The Neural Aesthetic @ ITP-NYU :: 06 Generative models,https://www.reddit.com/r/deeplearning/comments/9ranq9/the_neural_aesthetic_itpnyu_06_generative_models/,keghn,1540476729,,0,1
181,2018-10-26,2018,10,26,0,9rbajt,Machine Learning and Deep Learning with fast.ai,https://www.reddit.com/r/deeplearning/comments/9rbajt/machine_learning_and_deep_learning_with_fastai/,harrshjain,1540481146,"Hey guys,

I just heard about [fast.ai](https://fast.ai/) Machine learning and Deep learning courses and they have great reviews.

I want to enrol in this course, but I am confused about which one should I start first with?

* Machine Learning

[http://course.fast.ai/ml](http://course.fast.ai/ml)

* Deep Learning

**Part 1 --** [http://course.fast.ai/](http://course.fast.ai/)

**Part 2 --** [http://course.fast.ai/part2.html](http://course.fast.ai/part2.html)

.

Now help me here, should I go with ML first or DL first?

(P.S: I'm a beginner, and I have almost no knowledge of both of them)",5,1
182,2018-10-26,2018,10,26,1,9rbu5w,Anyone here built a chatbot? Would you mind taking a survey?,https://www.reddit.com/r/deeplearning/comments/9rbu5w/anyone_here_built_a_chatbot_would_you_mind_taking/,Living_Hovercraft,1540484829,,0,1
183,2018-10-26,2018,10,26,2,9rco14,Generating custom photo-realistic faces using AI,https://www.reddit.com/r/deeplearning/comments/9rco14/generating_custom_photorealistic_faces_using_ai/,e_ameisen,1540490378,,1,1
184,2018-10-26,2018,10,26,6,9rejn5,"""Learned optimizers that outperform SGD on wall-clock and validation loss"", Metz et al 2018 {GB}",https://www.reddit.com/r/deeplearning/comments/9rejn5/learned_optimizers_that_outperform_sgd_on/,theslt,1540503124,,0,1
185,2018-10-26,2018,10,26,13,9rhp0a,Problem with MLP producing same outputs? possibly due to bias term?,https://www.reddit.com/r/deeplearning/comments/9rhp0a/problem_with_mlp_producing_same_outputs_possibly/,qudcjf7928,1540528959,"So I've implemented a ""simple"", fully connected, feed forward neural network, using sigmoid functions, for regression.

Initially, no matter what the hyperparameters were, the outputs that were getting produced were all 0.5, thus indicating vanishing gradient problem (1/(1+exp(0))) = 0.5 

So, I standardized all the data inputs, changed it to tanh functions, applied batch normalization for all the hidden layers, including the output layer, and it does seem to produce some sensible outputs, 

But then now, it's giving the same outputs regardless of the inputs I feed in. I've implemented batch normalization such that given the next layer's neurons' values, you would standardize them, then multiply each with its own trainable constant (scaling parameter), and then shift it by another its own trainable constant (shifting parameter)

&amp;#x200B;

I think the problem comes from the shifting parameter ""taking over"" and the network just updating those shifting parameters, thereby decreasing the error overall, but not changing the network's weights, thus even when given different inputs, still produces the same outputs. 

&amp;#x200B;

Could that be the reason? What would be the work around that? I tried just standardizing the batch's neurons without applying scaling and shifting parameters, but it still causes vanishing gradient problem, that is, the outputs given are always 0.5 for sigmoid functions

&amp;#x200B;",5,1
186,2018-10-26,2018,10,26,18,9rj47l,Machine learning latest trends,https://www.reddit.com/r/deeplearning/comments/9rj47l/machine_learning_latest_trends/,FitRemove,1540544918,"I have here jotted down some interesting trends to look forward to in Machine Learning and Deep Learning. Thoughts?

&amp;#x200B;

teks.co.in/site/blog/machine-learning-in-2019-tracing-the-artificial-intelligence-growth-path/",1,1
187,2018-10-27,2018,10,27,7,9rp3gc,"Deep Learning Lounge - San Diego, Nov 6th",https://www.reddit.com/r/deeplearning/comments/9rp3gc/deep_learning_lounge_san_diego_nov_6th/,Mathriddle,1540591447,,3,1
188,2018-10-27,2018,10,27,7,9rp66t,DeepMind Paper Challenges Generative Models Judgement,https://www.reddit.com/r/deeplearning/comments/9rp66t/deepmind_paper_challenges_generative_models/,Yuqing7,1540592027,,0,1
189,2018-10-27,2018,10,27,12,9rr7gq,Where do I start ???,https://www.reddit.com/r/deeplearning/comments/9rr7gq/where_do_i_start/,mohamedahmed95,1540610346,"Hello everyone, i am a fresh graduate from computer engineering. I am interested in the ML and DL, where should I start ??",3,1
190,2018-10-28,2018,10,28,0,9rv0eq,GANs for future scene/frame prediction?,https://www.reddit.com/r/deeplearning/comments/9rv0eq/gans_for_future_sceneframe_prediction/,daniel451,1540653493,"Hey hey,

I am searching for GANs that solve predictive tasks like future scene/frame prediction in videos, for example.

Any suggestions for interesting papers, blog posts or implementations?

To give an example: *Deep multi-scale video prediction beyond mean square error* by Mathieu, Couprie &amp; LeCun (paper: [https://arxiv.org/abs/1511.05440](https://arxiv.org/abs/1511.05440); implementation: [https://github.com/dyelax/Adversarial\_Video\_Generation](https://github.com/dyelax/Adversarial_Video_Generation))

&amp;#x200B;",1,1
191,2018-10-28,2018,10,28,1,9rvldq,Recurrent Binary Embedding for GPU-Enabled Exhaustive Retrieval from Billion-Scale Semantic Vectors,https://www.reddit.com/r/deeplearning/comments/9rvldq/recurrent_binary_embedding_for_gpuenabled/,gwen0927,1540657992,,0,1
192,2018-10-28,2018,10,28,3,9rwmhd,Help in making a model to detect cannabis flowers,https://www.reddit.com/r/deeplearning/comments/9rwmhd/help_in_making_a_model_to_detect_cannabis_flowers/,you_fuck_er,1540665613,"Hey there, Im pretty new in this field, I have a bit of theoretical and practical knowledge and now I want to get to more advanced stuff. 

What is the best way to detect cannabis picture ?

please give me material to read about to help me achieve this.",4,1
193,2018-10-28,2018,10,28,3,9rwnl8,Dynamic Programming in Reinforcement Learning (RL in a nutshell),https://www.reddit.com/r/deeplearning/comments/9rwnl8/dynamic_programming_in_reinforcement_learning_rl/,vector_machines,1540665854,,0,1
194,2018-10-28,2018,10,28,13,9s0kc4,Free servers with 1080Ti for deep learning,https://www.reddit.com/r/deeplearning/comments/9s0kc4/free_servers_with_1080ti_for_deep_learning/,whitezl0,1540699869,"I am offering free 1080Ti GPU instances for deep learning. I am a co-founder of Tensorpad; we are creating a service for AI startups to train neural networks. We have paid traffic, but some servers are idle. Hence, we are offering some credits for free, so that students, startups, and others can benefit from ML technologies and help us by using our product and providing honest feedback for us to improve services.

Sign up at https://dashboard.tensorpad.com/signup and apply the following referral code: trial5. You can apply the referral code in the ""Billing"" tab.

Hope this explains our story and motivation. Here is more info: * The instances have 16GB RAM, 4 CPUs cores and one 1080Ti GPU. You can run multiple instances in parallel * You get access to the JupyterLab environment * We have pre-installed Tensorflow, Keras, and other ML frameworks * You can access the command line and use it as a dedicated server for training * By default, persistent storage is enabled

For extra free trial hours, use promo code trial5

And for questions, please contact me at ilie@tensorpad.com

Sincerely, Ilie Diacov
",20,1
195,2018-10-28,2018,10,28,19,9s28ot,I made a codeless web GUI (Django) to build Images Classifiers (CNN) with Keras,https://www.reddit.com/r/deeplearning/comments/9s28ot/i_made_a_codeless_web_gui_django_to_build_images/,Klhnikov,1540722510,,2,1
196,2018-10-28,2018,10,28,23,9s3l73,How did you scrap this data?  Arjun Kava  Medium,https://www.reddit.com/r/deeplearning/comments/9s3l73/how_did_you_scrap_this_data_arjun_kava_medium/,arjunkava,1540737422,,0,1
197,2018-10-29,2018,10,29,0,9s45el,What are the best resources/tutorials for deep reinforcement learning?,https://www.reddit.com/r/deeplearning/comments/9s45el/what_are_the_best_resourcestutorials_for_deep/,sainimohit23,1540741948,I know deep learning and now I want to learn deep reinforcement learning. I find it's applications quite exciting.,5,1
198,2018-10-29,2018,10,29,3,9s5gvh,Machine Learning Algorithms (Concept + Implementation),https://www.reddit.com/r/deeplearning/comments/9s5gvh/machine_learning_algorithms_concept_implementation/,adarsh_adg,1540751559," 

Guys I am happy to share that i started creating Machine Learning Algorithms videos, in which i will explain each and every algorithm have a look and give your valuable feedback to it please

[https://youtu.be/Zt83JnjD8zg](https://youtu.be/Zt83JnjD8zg)",0,1
199,2018-10-29,2018,10,29,4,9s63ug,Practical course in reinforcement learning?,https://www.reddit.com/r/deeplearning/comments/9s63ug/practical_course_in_reinforcement_learning/,MoonAmunet,1540756121,"I'm looking for a practical course in reinforcement learning. Course that will include coding assignments (I prefer Python) but also covers the theoretical and mathematical parts. 

Any recommendations?",3,1
200,2018-10-29,2018,10,29,5,9s6lgs,Fixed set label generator from feature vector?,https://www.reddit.com/r/deeplearning/comments/9s6lgs/fixed_set_label_generator_from_feature_vector/,anilmaddala,1540759660,"I have an image passed through a feature extractor resulting in feature vector of size 1280. 

The problem is I want to generate a label of size 6 characters and each character in the label can be picked from  a character set of 6 characters. 

For example some valid labels are ABCDEF, CBBAAA, FFFFFF, BABDAC.

I am not sure how to approach this problem. Is there a name for such problems? Any help is appreciated. Thank you.",0,1
201,2018-10-29,2018,10,29,15,9sap2n,CNN-LSTM models,https://www.reddit.com/r/deeplearning/comments/9sap2n/cnnlstm_models/,suraty,1540794476,"Hello,

In some papers, whose data are time series, a model which combined the CNN and LSTM is used. Somewhere it is named as CNN-Lstm network.

The first question is that how such combined model will improve the final predictions of the model? what are the functions of CNN and the followed LSTM in these models? How is it working?

I would like to use such a model for my time series data. My input is 320*20*1 matrix and the output is 1600 matrix. 

At first, I used the CNN model for predicting and the loss value is approximately high. I decided to improve it by using CNN-LSTM model. 

I tried to build a CNN-LSTM model for my data. In the LSTM models, the input shape is (number of examples, TimeSteps, FeaturesPerStep). 

When I use the LSTM layers after the CNN layers, it needs to a reshape layer for preparing to import to LSTM layers.

While the input and output contain one time_step data, So I reshaped to (1,1600) which 1600 is as size as the output! 

Is it correct? Can I increase the timestep value?

My Loss didn't decrease in CNN-LSTM model, is the mistake in my model?

I append the LSTM at the end of CNN, as below:

    model = models.Sequential()
    model.add(Conv2D(256,(3, 3),
                     input_shape=(320,20,1), padding='same'))
    model.add(MaxPooling2D((2, 2)))
    model.add(LeakyReLU())

    model.add(Conv2D(128, (3, 3), padding='same'))
    model.add(MaxPooling2D((2, 2)))
    model.add(LeakyReLU())

    model.add(Conv2D(64, (3, 3), padding='same'))
    model.add(MaxPooling2D((2,2)))
    model.add(LeakyReLU())

    model.add(Flatten())
    model.add(Dense(1600))
    
    model.add(Reshape((1,1600)))
    
    model.add(LSTM(400, return_sequences=True))
    model.add(LSTM(400))
    
    model.add(Activation(activation='tanh'))
    
    model.add(Dense(1600))
    

    model.summary()",5,1
202,2018-10-29,2018,10,29,17,9sbd6s,Recommendations for deep learning and medical image analysis and diagnostics,https://www.reddit.com/r/deeplearning/comments/9sbd6s/recommendations_for_deep_learning_and_medical/,melvinkoopmans,1540802897,"I'm currently studying deep learning at Udacity and pursue a career in Deep Learning for Medical image analysis and medical diagnostics. I wonder if anyone here has experience in this field and has some recommendations to move into that direction (books, courses, papers etc.) Also, if you have anything else that is important to know when pursuing such a career, please do share :)  


Thanks!",3,1
203,2018-10-30,2018,10,30,1,9seebd,Machine Learning Algorithms for beginners,https://www.reddit.com/r/deeplearning/comments/9seebd/machine_learning_algorithms_for_beginners/,adarsh_adg,1540829111," 

Guys we are happy to share that we started creating Machine Learning Algorithms videos, in which we will explain each and every algorithm have a look and give your valuable feedback to us please.

[https://youtu.be/Zt83JnjD8zg](https://youtu.be/Zt83JnjD8zg)",0,1
204,2018-10-30,2018,10,30,1,9seix6,"Neuroengineering Article, Some Neural Nets",https://www.reddit.com/r/deeplearning/comments/9seix6/neuroengineering_article_some_neural_nets/,ScienTecht,1540829959,"Cool article about Neuroengineering that touches on some
neural networks. 

https://saberatalukder.com/what_is_neuroengineering.html
",0,1
205,2018-10-30,2018,10,30,1,9sesuk,Scam call manipulation with deep learning.,https://www.reddit.com/r/deeplearning/comments/9sesuk/scam_call_manipulation_with_deep_learning/,pelcgbtencul,1540831632,"This is just a concept - feel free to point out flaws in my idea, I'm here to learn.


If you haven't seen, Google has successfully made an AI that uses deep learning, and can call people for you and schedule appointments for you, and it appears strikingly similar to a human.


If you used this technology to automate scam calling, and used deep learning to study, psychological vulnerabilities, and then to evaluate and integrate it's data to which vulnerabilities &amp; methodw are most effective, wouldn't this be certainly catastrophic?


If this was successfully developed I speculate that the number of victims could be in the millions within the first 6 months. The AI would calculate what it could say that would have mathematically the highest probablility of success, and even calculate the humans most likely responses... ",9,1
206,2018-10-30,2018,10,30,2,9sf8lm,Deep learning Paper Summary,https://www.reddit.com/r/deeplearning/comments/9sf8lm/deep_learning_paper_summary/,Karthik9999,1540834347,,0,1
207,2018-10-30,2018,10,30,4,9sgho5,What are the best and most popular research papers on sentiment analysis?,https://www.reddit.com/r/deeplearning/comments/9sgho5/what_are_the_best_and_most_popular_research/,vipul115,1540842154,Title,2,1
208,2018-10-30,2018,10,30,4,9sglwt,Decensoring Hentai with Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/9sglwt/decensoring_hentai_with_deep_neural_networks/,allthingsvr,1540842911,,16,1
209,2018-10-30,2018,10,30,5,9sgygb,"For anyone looking to get into machine learning, I would advise that you don't learn the behemoth libraries like Tensorflow or Theano, but instead learn how to use a high-level API like Keras. Here's a quick video to explain what it is. Hope I was helpful!",https://www.reddit.com/r/deeplearning/comments/9sgygb/for_anyone_looking_to_get_into_machine_learning_i/,antaloaalonso,1540845134,,2,1
210,2018-10-30,2018,10,30,5,9sh3ec,Dataset database and search,https://www.reddit.com/r/deeplearning/comments/9sh3ec/dataset_database_and_search/,alex_titanovo,1540846025,"Hey guys,
I need your advice/feedback. As a ML/AL engineer I quite often struggle to find new and relevant datasets for my tasks. One of the key problems - some great datasets are buried into articles with no real SEO visibilty, some are just usually on-demand for academics only and it's hard to track articles where specific dataset was used.
I am thinking of creating a simple website + storage to help solve those problems with the power of crowdsourcing. It should be non-profit I think.
So, I created a simple website with limited capabilities just to show off the idea. What you think of this? I know that there's a Google Dataset Search, but it's not really what I need. Would you like to participate I this kind of project on a github/contibute? Or maybe you think idea is useless?
Feedback is welcomed here. Website - [mlbase](https://mlbase.io]",0,1
211,2018-10-30,2018,10,30,8,9simih,How to perform incremental learning/training in convolutional neural networks,https://www.reddit.com/r/deeplearning/comments/9simih/how_to_perform_incremental_learningtraining_in/,adi1709,1540856830,"If you have an object detector trained for 20 classes and you collect more data for 5 more classes, what is the best way to include the new classes? What are some of the state of the art approaches to deal with the same? Specifically - 
1. Should the model be retrained on the entire initial dataset by appending the new data to it?
2. Should we include a small chunk of the original data with the new data and fine tune the network with the output now including 25 classes? 
3. Is catastrophic forgetting a concern in this case? ",3,1
212,2018-10-30,2018,10,30,13,9skp91,A machine learning game I've been working on...,https://www.reddit.com/r/deeplearning/comments/9skp91/a_machine_learning_game_ive_been_working_on/,twm7,1540873555,"I posted this in the [/r/learnmachinelearning](https://www.reddit.com/r/learnmachinelearning) sub and got a load of responses and I've had a chance to change it a bit. I'm still working on it but wanted to put it out there to get any useful feedback or thoughts from the experts. It's basically a game similar to 20 Questions (or Animal, Vegetable, Mineral) that attempts to ask you questions to work out an object you are thinking about. You can think of everyday items (animals, household objects, food, quite a bit of other stuff etc) and it has 30 questions to try and guess the item. I've been working on it for a while but not sure what to do next so interested to hear anyone's thoughts...

The link for anyone that wants to try it out is [incredicat.com](http://www.incredicat.com/)

Thanks in advance!",3,1
213,2018-10-30,2018,10,30,14,9sl0ti,China releases Deep Learning Engineer Certification Standards Released.,https://www.reddit.com/r/deeplearning/comments/9sl0ti/china_releases_deep_learning_engineer/,_spicyramen,1540876770,"""The company's employees and social developers, mainly for the artificial intelligence industry, are divided into three levels: primary, intermediate and advanced. The deep learning engineer's ability assessment elements mainly include professional knowledge, engineering ability, business understanding and practice. There are 3 categories and 9 categories.""

[http://www.xinhuanet.com/tech/2018-10/11/c\_1123543498.htm](http://www.xinhuanet.com/tech/2018-10/11/c_1123543498.htm)

&amp;#x200B;

Is there a similar certification in the US ? 

With the popularity of AI and universities updating their syllabus to be relevant in Industry, is no surprise that China is taking the lead in this area. I believe it makes sense to evaluate the professional in the area according to their abilities. (As long as a Certifications doesn't become a business like it was for Cisco/MS/etc.) 

Opinions?",2,1
214,2018-10-30,2018,10,30,15,9slgpb,A Complete Guide to Master Deep Learning,https://www.reddit.com/r/deeplearning/comments/9slgpb/a_complete_guide_to_master_deep_learning/,dthgs,1540881797,,2,1
215,2018-10-30,2018,10,30,17,9sm1l9,Fedora is enough good for Deep Learning?,https://www.reddit.com/r/deeplearning/comments/9sm1l9/fedora_is_enough_good_for_deep_learning/,naszabi,1540889122,"Hi.

I used to use Fedora for backend development, when I started to learn deep learning I saw that everybody uses Ubuntu. 

But Fedora is enough good for DL too? I am not sure about that if I install the Nvidia Cuda tools, those will be fully compatible with Fedora or Ubuntu better?  


Because Fedora always changes the Linux Kernel and if I am right the NV Cuda tools build for a specific linux kernel.

Here what I see: [https://developer.nvidia.com/cuda-downloads?target\_os=Linux&amp;target\_arch=x86\_64&amp;target\_distro=Fedora&amp;target\_version=27](https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Fedora&amp;target_version=27) \- Cuda tools support only Fedora 27.  


What do you think?",7,1
216,2018-10-30,2018,10,30,23,9soe0w,How I built a car model classifier with 98% accuracy using fastai,https://www.reddit.com/r/deeplearning/comments/9soe0w/how_i_built_a_car_model_classifier_with_98/,arunoda,1540909689,,0,1
217,2018-10-31,2018,10,31,2,9spu3w,Anywhere i can find datasets of pens and pencils ?,https://www.reddit.com/r/deeplearning/comments/9spu3w/anywhere_i_can_find_datasets_of_pens_and_pencils/,SerMabrouk,1540918978,,1,1
218,2018-10-31,2018,10,31,6,9ss7yg,Facebook Open-Sources QNNPACK Kernel Library,https://www.reddit.com/r/deeplearning/comments/9ss7yg/facebook_opensources_qnnpack_kernel_library/,gwen0927,1540934548,,1,1
219,2018-10-31,2018,10,31,15,9sw5xt,"The History, Evolution and Growth of Deep Learning | Analytics Insight",https://www.reddit.com/r/deeplearning/comments/9sw5xt/the_history_evolution_and_growth_of_deep_learning/,analyticsinsight,1540966144,,0,1
220,2018-10-31,2018,10,31,15,9sw7v0,Deep learning technology expected to grow at the highest growth of Artificial Intelligence in Healthcare Market,https://www.reddit.com/r/deeplearning/comments/9sw7v0/deep_learning_technology_expected_to_grow_at_the/,JackWallner2,1540966752,[removed],0,1
0,2018-11-1,2018,11,1,17,9t7qpb,Reinforcement learning noob here for help...,https://www.reddit.com/r/deeplearning/comments/9t7qpb/reinforcement_learning_noob_here_for_help/,kvmgamer1,1541062174,"Recently I ve  searching about Reinforcement deeplearning ,and I discoverd microsoft malmo project

malmo project provides some interface to control the actor in minecraft and get some feedback

tensorforce project provides Reinforcement learning api based on tensorflow

so my goal is to use tensorforce to play minecraft via malmo

------
In my opinion:
in tensorforce,I need to pass state to the agent ,and get the action from agent

        action = agent.act(state)
        state, terminal, reward = environment.execute(action)

then pass action to malmo (parse to `command`) and get the state (maybe `world_state.observations`)

        agent_host.sendCommand(command)
        world_state = agent_host.getWorldState()
        obvsText = world_state.observations[-1].text

but how ? I dont know .and doing research now.

I really need some advice",5,1
1,2018-11-1,2018,11,1,22,9t99jx,SoundTrack - Colorful Darkness,https://www.reddit.com/r/deeplearning/comments/9t99jx/soundtrack_colorful_darkness/,AiZt3,1541077791,,0,1
2,2018-11-2,2018,11,2,0,9ta8xc,A Conversation With Quoc Le: The AI Expert Behind Google AutoML,https://www.reddit.com/r/deeplearning/comments/9ta8xc/a_conversation_with_quoc_le_the_ai_expert_behind/,gwen0927,1541084936,,0,1
3,2018-11-2,2018,11,2,0,9tabv9,Pre-built GPU Deep Learning Workstations vs DIY,https://www.reddit.com/r/deeplearning/comments/9tabv9/prebuilt_gpu_deep_learning_workstations_vs_diy/,nvidiaturing,1541085480,"Hey, guys I need some help in choosing the right hardware for deep learning workstation or recommendation for a good prebuilt workstation.

&amp;#x200B;

$5,000 budget

2 GPUs minimum (1080 Ti or RTX 2080 Ti)

64GB RAM, PCIe SSD

&amp;#x200B;

I shortlisted few reputable companies focused on deep learning PCs below:

[https://www.exxactcorp.com/Deep-Learning-NVIDIA-GPU-Solutions](https://www.exxactcorp.com/Deep-Learning-NVIDIA-GPU-Solutions)

[https://www.pugetsystems.com/recommended/Recommended-Systems-for-Machine-Learning-AI-TensorFlow-etc-174](https://www.pugetsystems.com/recommended/Recommended-Systems-for-Machine-Learning-AI-TensorFlow-etc-174)

[https://www.boxx.com/solutions/deep-learning](https://www.boxx.com/solutions/deep-learning)

[https://bizon-tech.com/us/workstations/deeplearning/](https://bizon-tech.com/us/workstations/deeplearning/)

&amp;#x200B;

I understand that buying a prebuilt will be a bit more expensive than building one myself, but the benefits of having a tested product with support and saving my time is really important. I have some basic experience building PCs, but I am not sure it will be enough here.

Any thoughts on this?",7,1
4,2018-11-2,2018,11,2,0,9taelf,Awesome! Relation Extraction!,https://www.reddit.com/r/deeplearning/comments/9taelf/awesome_relation_extraction/,roomylee,1541085975,,0,1
5,2018-11-2,2018,11,2,1,9tay2v,Awesome! Relation Extraction!,https://www.reddit.com/r/deeplearning/comments/9tay2v/awesome_relation_extraction/,roomylee,1541089520,"# 

https://i.redd.it/7vua9kaswqv11.jpg

# [Awesome Relation Extraction](https://github.com/roomylee/awesome-relation-extraction)

There is a brand new curated list of awesome resources dedicated to Relation Extraction!

This awesome list contains papers, datasets, videos and lectures related to Relation Extraction. A relation extraction, one of the most important Natural Language Processing (NLP) tasks, requires the detection and classification of semantic relationship mentions within a set of artifacts, typically from text or XML documents.

Have anything in mind that you think is awesome and would fit in this list? Please feel free to make [*pull requests*](https://github.com/roomylee/awesome-relation-extraction/pulls).",1,1
6,2018-11-2,2018,11,2,1,9tb3lk,LSTM Recurrent Neural Network (RNN) without Date column,https://www.reddit.com/r/deeplearning/comments/9tb3lk/lstm_recurrent_neural_network_rnn_without_date/,fullarray,1541090574,"Is it possible to conduct LSTM Deep Learning prediction analysis without the date column in the dataset?

If so, are there any tutorial or resources I can look. 

***Please don't post some thing just to post if it's not related to the question. I did some research already and I found nothing yet.

Thanks",5,1
7,2018-11-2,2018,11,2,4,9tcln4,[P] Awesome! Relation Extraction!,https://www.reddit.com/r/deeplearning/comments/9tcln4/p_awesome_relation_extraction/,roomylee,1541100424,,0,1
8,2018-11-2,2018,11,2,4,9tcvng,Is there any available database of trained CNNs?,https://www.reddit.com/r/deeplearning/comments/9tcvng/is_there_any_available_database_of_trained_cnns/,venkuJeZima,1541102252,"I know there is [onnx](https://github.com/onnx/models).  Also something similar for keras models, etc?  ",3,1
9,2018-11-2,2018,11,2,8,9tey9h,How do you all get your datasets?,https://www.reddit.com/r/deeplearning/comments/9tey9h/how_do_you_all_get_your_datasets/,hmmhhhmhhmhmhmhh,1541116662,"Hey all,

I'm cooking up an idea and wanted some input from potential users. So I know for ML you need good sample data (like tagged pictures). Where do you usually get this data? Is there a specific type of data that's hard to come by (ie: what else other than image recognition stuff)? What types of sets would it be most beneficial to have a human go through and tag (Pictures of dogs? Spatulas? etc)? Vent to me!",4,1
10,2018-11-2,2018,11,2,11,9tg420,Beginner using Literai but loss stays too high,https://www.reddit.com/r/deeplearning/comments/9tg420/beginner_using_literai_but_loss_stays_too_high/,BwillWall,1541125490,"I'm trying to use the tools I found on [Literai.com](https://Literai.com) to train a bot that can write scripts based on certain TV shows and such. The results are a bit disappointing because it seems to just be saying a lot of random words that don't consecutively make sense. The loss seems to remain 1.1 to 1.6 with the things I've tried (it complete entirely with that).

I guess my questions are...

Is there a better tool I can be using as a beginner?

Are there any specific settings I should be changing to get better results?

Are my expectations just too high with the current capabilities of machine learning creating its own content?",0,1
11,2018-11-2,2018,11,2,13,9th02r,Problem while using multi-gpu on pytorch,https://www.reddit.com/r/deeplearning/comments/9th02r/problem_while_using_multigpu_on_pytorch/,sangrockEG,1541133238,"Hello.

I'm trying to run cycleGAN on pytorch with 2 GPUs. (both are GTX 1080 ti)

([https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix))

When I run it, after few minutes, my screen freezes.

I cannot find why this freezing happens.

What can I do for it?",3,1
12,2018-11-2,2018,11,2,14,9thbut,Universal approximation theorem vs Fourier series,https://www.reddit.com/r/deeplearning/comments/9thbut/universal_approximation_theorem_vs_fourier_series/,machine_monkey_62,1541136588,Why not use Fourier series instead of neural networks for regression? I have a feeling it has to do with the difficulty of finding appropriate coefficients for the Fourier series.,16,1
13,2018-11-2,2018,11,2,17,9ti6o9,Story about one Russian software development company's offices,https://www.reddit.com/r/deeplearning/comments/9ti6o9/story_about_one_russian_software_development/,Batareika_1,1541147097,,0,1
14,2018-11-3,2018,11,3,6,9to3mg,Is recurrent neural network good for time series with mean reverting properties?,https://www.reddit.com/r/deeplearning/comments/9to3mg/is_recurrent_neural_network_good_for_time_series/,qudcjf7928,1541192662,"I haven't got into RNNs yet, but it's near impossible to use a simple fully connected feed forward neural network for extrapolating or predicting a time series with mean reverting properties or periodicity (I mean, ANNs aren't great for extrapolating at all, let alone try to predict a time series with mean reverting property) 

&amp;#x200B;

But then if the whole point of RNNs or LSTMs are to capture the temporal dependencies, then is it the right choice to use? 

&amp;#x200B;",6,1
15,2018-11-3,2018,11,3,6,9to8jq,What alogithm/paper/software is Jordan Pele using here to generate fake videos ?,https://www.reddit.com/r/deeplearning/comments/9to8jq/what_alogithmpapersoftware_is_jordan_pele_using/,ishandutta2007,1541193623,"[https://youtu.be/bE1KWpoX9Hk](https://youtu.be/bE1KWpoX9Hk)

There are efforts by google's tacotron2 and expressive version of that like [https://ai.googleblog.com/2018/03/expressive-speech-synthesis-with.html](https://ai.googleblog.com/2018/03/expressive-speech-synthesis-with.html). for expressive voice which may or may not be needed.

And also replicating facial expression to a new video might be via something like this [https://arxiv.org/pdf/1804.08348.pdf](https://arxiv.org/pdf/1804.08348.pdf)  .

These might not be enough as we also need to clone Obma's voice with something like adobe voco or lyrebird (I am still searching for what they use).

&amp;#x200B;",0,1
16,2018-11-3,2018,11,3,11,9tqqds,Neural Network Part 1 - Machine Learning Tutorial,https://www.reddit.com/r/deeplearning/comments/9tqqds/neural_network_part_1_machine_learning_tutorial/,jeffxu999,1541213311,,1,1
17,2018-11-3,2018,11,3,16,9ts5qm,Where can I download all the tutorials of InterSpeech of ICASSP?,https://www.reddit.com/r/deeplearning/comments/9ts5qm/where_can_i_download_all_the_tutorials_of/,Max_Jiayi,1541228508,"I tried to find the tutorials of InterSpeech 2018 and ICASSP 2018 and I just found only one tutorial about GAN.

Can anybody tell me where can I find these slides? They seem like can't be download from the official website and google scholar...

Thanks !",0,1
18,2018-11-3,2018,11,3,16,9tsedp,MULTI STEP LSTM,https://www.reddit.com/r/deeplearning/comments/9tsedp/multi_step_lstm/,saravanakumar17,1541231818,"Hi, I've been learning Deep Learning for a while now I got struck with this concept called as MULTI STEP TIME SERIES FORECASTING. I can predict the next day values with this method, but how do I predict the prices after a month or an year
(note: I've tried machine learning mastery and it didn't work as expected). Can someone link the relevant code or blog associated with and any kind of help will make my day.

Thanks in advance.",4,1
19,2018-11-3,2018,11,3,21,9ttq2p,Convolutional autoencoder notebook for MNIST dimensional reduction on keras,https://www.reddit.com/r/deeplearning/comments/9ttq2p/convolutional_autoencoder_notebook_for_mnist/,MungoSoft,1541248415,"Autoencoder are a unsupervised learning method. One application of those networks are dimensional reduction. There is two main step:

1) Reduce the dimensionality of a given input with various layers
2) Repeat the same layers as step 1 (but inverted) 

So in fact to train your network you try to retreive the given input as the output. At the end of step one you have your encoder and at the end of step two you have your autoencoder.

[https://github.com/gringet/ipynb_dl/blob/master/cae.ipynb](https://github.com/gringet/ipynb_dl/blob/master/cae.ipynb)

I tried to reduce the MNIST dataset to a two dimensional space. Some results are shown in the notebook.

From this we could try a clustering of the data in this low dimensional space. Of course if you put the data in a higher dimension at the end of the encoder you will have better results, but I try to have a good visual representation on this 2D space.",0,1
20,2018-11-3,2018,11,3,22,9ttynz,Supervised learning a digest function data,https://www.reddit.com/r/deeplearning/comments/9ttynz/supervised_learning_a_digest_function_data/,bytedonor,1541250714,"Hi there!

In basic examples of supervised learning NN is trained to map a finite input (e.g. pixels of a 25x25 image) to an output (e.g. vector of probabilities).

I'm wondering how would this work if a learned function maps (practically) infinite input to a vector of 256 outputs (like SHA-256)? How would the input layer look?

&amp;#x200B;",0,1
21,2018-11-3,2018,11,3,22,9tu0x1,Approximate a digest function with supervised learning,https://www.reddit.com/r/deeplearning/comments/9tu0x1/approximate_a_digest_function_with_supervised/,bytedonor,1541251316,"Hi there!

In basic examples of supervised learning NN is trained to map a finite input (e.g. pixels of a 25x25 image) to an output (e.g. vector of probabilities).

I'm wondering how would this work if a learned function maps (practically) infinite input to a vector of 256 values (like SHA-256)? How would the input layer look?",4,1
22,2018-11-3,2018,11,3,23,9tula2,How Deep The Deep Learning Is? - Measuring The Depth of Deep Learning,https://www.reddit.com/r/deeplearning/comments/9tula2/how_deep_the_deep_learning_is_measuring_the_depth/,LearningFromData,1541255967,,0,1
23,2018-11-4,2018,11,4,4,9tx1hu,Artificial Intelligence and Deep Learning Are Changing How We Live Our Lives,https://www.reddit.com/r/deeplearning/comments/9tx1hu/artificial_intelligence_and_deep_learning_are/,BlockDelta,1541274178,,0,1
24,2018-11-4,2018,11,4,7,9ty5ow,Learning to count in visual question answering.,https://www.reddit.com/r/deeplearning/comments/9ty5ow/learning_to_count_in_visual_question_answering/,manoja328,1541282719,"This paper introduces new dataset and method to help deep learning models particularly VQA models to learn to count. [https://arxiv.org/abs/1810.12440](https://arxiv.org/abs/1810.12440)

&amp;#x200B;

&amp;#x200B;",0,1
25,2018-11-4,2018,11,4,7,9ty8l8,Logistic Regression Part 1 - Machine Learning Tutorial,https://www.reddit.com/r/deeplearning/comments/9ty8l8/logistic_regression_part_1_machine_learning/,jeffxu999,1541283339,,1,1
26,2018-11-4,2018,11,4,10,9tzrac,Best route for Deep Learning on Terabytes of data?,https://www.reddit.com/r/deeplearning/comments/9tzrac/best_route_for_deep_learning_on_terabytes_of_data/,normalism,1541295726,"I am trying to figure out the best route to go in terms of hardware/environment for performing deep learning on terabytes of data. Data resides in SQL server. 

On prem multiple machine setup (distributed workload) ?
On prem single machine multiple Gpu setup?
Cloud based (distributed?)

Thanks in advance for opinions. ",0,1
27,2018-11-4,2018,11,4,12,9u0hte,Anyone tried hacking ps4 to use its gpu for training deep learning model ?,https://www.reddit.com/r/deeplearning/comments/9u0hte/anyone_tried_hacking_ps4_to_use_its_gpu_for/,manjush3v,1541302216,,1,1
28,2018-11-4,2018,11,4,14,9u12di,Deep Learning could help us produce a faster Cardiac MRIs Report,https://www.reddit.com/r/deeplearning/comments/9u12di/deep_learning_could_help_us_produce_a_faster/,asifrazzaq1988,1541308127,,0,1
29,2018-11-4,2018,11,4,18,9u23wk,Converting legacy DGAN torch-lua model to pytorch throws an error,https://www.reddit.com/r/deeplearning/comments/9u23wk/converting_legacy_dgan_torchlua_model_to_pytorch/,aszenx,1541322878,"So I wanted to port (this)[https://github.com/robbiebarrat/art-DCGAN] repositories DGAN code written in torch-lua to pytorch but for that I have to convert the model weights too since I don't have the computing power to train the model. I tried using the `load_lua` function in pytorch but it doesn't work. 
Exact error on pytorch's Github (issue)[https://github.com/pytorch/pytorch/issues/13302#event-1935083694]

I also tried using several model converters from GitHub but they too throw the same error. 

Can anyone suggest a way for me to convert these pretrained models so that I can load them in pytorch?",0,1
30,2018-11-4,2018,11,4,18,9u26s3,Labels,https://www.reddit.com/r/deeplearning/comments/9u26s3/labels/,thefucunknown123456,1541324081,What are true labels and random labels? .need intuitive answer . Thanks,2,1
31,2018-11-4,2018,11,4,20,9u2sxq,Privacy-preserving ML: Crafting building blocks for secure AI,https://www.reddit.com/r/deeplearning/comments/9u2sxq/privacypreserving_ml_crafting_building_blocks_for/,morgangiraud,1541332752,,0,1
32,2018-11-4,2018,11,4,22,9u3cx4,"This Researcher Created DeepCreamPy, a Machine Learning Algorithm That Uncensors Hentai",https://www.reddit.com/r/deeplearning/comments/9u3cx4/this_researcher_created_deepcreampy_a_machine/,MuzzleO,1541338492,,1,1
33,2018-11-5,2018,11,5,0,9u40q1,"Help !! Need advice regarding research topic ""Robot Learning""",https://www.reddit.com/r/deeplearning/comments/9u40q1/help_need_advice_regarding_research_topic_robot/,big_man123,1541344166,"I am currently a Masters student in Robotics . For a class I need to collect few literature articles/papers/journals on the broad topic of ""Robot Learning"".  


My current interest lies in :-

1. Deep Learning
2. Reinforcement learning
3. Imitation Learning
4. Robot perception

Can someone give me advice on any of the following :-

* How to start collecting the papers? I am overwhelmed by the amount of papers that are in the above field and I am not able to understand most of it. 
* Suggest other sub topics that comes under Robot Learning.
* How to go about doing research about a new topic ? Dive in head first or ?
* Suggestion on good papers on the above topics with its application in Robotics.
* Good sources to find such papers.

Thanks a lot for your Help!  
",1,1
34,2018-11-5,2018,11,5,1,9u4vut,HELP : How to classify e-commerce products with only product images and descriptions but no labels ?,https://www.reddit.com/r/deeplearning/comments/9u4vut/help_how_to_classify_ecommerce_products_with_only/,Nike_Zoldyck,1541350533,I have a bunch of data samples and a list of categories it can fall into but no sample wise label. Is this a tagging problem? Is there any deep learning code on github or an example/video tutorial somewhere that you can point me to? That would help me a lot at my current work. Thank you !,6,1
35,2018-11-5,2018,11,5,5,9u6t3k,Tensorflow 2.0: models migration and new design,https://www.reddit.com/r/deeplearning/comments/9u6t3k/tensorflow_20_models_migration_and_new_design/,pgaleone,1541363454,,0,1
36,2018-11-5,2018,11,5,8,9u83yw,How does alphago receive its input data?,https://www.reddit.com/r/deeplearning/comments/9u83yw/how_does_alphago_receive_its_input_data/,gil_ho,1541372684,"Is there literally a camera that sits and watches a game played on TV where the (1) camera captures the moves, (2) feeds it into alphago, (3) alphago converts that into some sort of data capable of being analysed (eg each row represents a move)

I havent been able to find an article that talks about this. Most talk about the algorithms",2,1
37,2018-11-5,2018,11,5,8,9u8b39,Vision based Human detection,https://www.reddit.com/r/deeplearning/comments/9u8b39/vision_based_human_detection/,alexchauncy,1541374187,,0,1
38,2018-11-5,2018,11,5,12,9ua6fk,Tensorflow implementation of the paper: StarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks.,https://www.reddit.com/r/deeplearning/comments/9ua6fk/tensorflow_implementation_of_the_paper_starganvc/,hujinsen,1541389103,"I implementation the paper StarGAN-VC Voice Conversion using tensorflow. Hope you feel it is interest. Any advice is welcome!

[Github](https://github.com/hujinsen/StarGAN-Voice-Conversion)",0,1
39,2018-11-5,2018,11,5,14,9uarvv,Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study,https://www.reddit.com/r/deeplearning/comments/9uarvv/deep_learning_algorithms_for_detection_of/,asifrazzaq1988,1541394496,,0,1
40,2018-11-5,2018,11,5,16,9ubofb,Learning deep learning,https://www.reddit.com/r/deeplearning/comments/9ubofb/learning_deep_learning/,mcurasya,1541404262,"Hey guys!

I am a student and want to begin learning deep learning. I already have knowledge of python. I also know matplotlib and pandas a little.

What can you suggest to read/watch/listen?",3,1
41,2018-11-5,2018,11,5,17,9ubxrd,how filters (kernels) are trained in CNN,https://www.reddit.com/r/deeplearning/comments/9ubxrd/how_filters_kernels_are_trained_in_cnn/,Vankir,1541407607,"Hi All,

I've watched several different courses regarding CNN but still don't understand clearly how kernel filters are trained. Do I understand correctly that values in kernel are set during backward propagation and nobody try to set particular kernels like sobel manually and when kernels are visualized and you can see lines or color spots for different kernels it is not a result of model creator's design but it is result of automatically tunning of kernel values during backward propagation. Could somebody advise good article regarding backward propagation for CNN?",4,1
42,2018-11-6,2018,11,6,6,9uhlod,Fidelity of saliency map for LSTM,https://www.reddit.com/r/deeplearning/comments/9uhlod/fidelity_of_saliency_map_for_lstm/,bonggu,1541451861,"I've obtained instance-specific saliency map (Simonyan et al. 2013, https://arxiv.org/abs/1312.6034) for a simple LSTM and CNN on the same dataset as below:

&lt;a href=""https://www.codecogs.com/eqnedit.php?latex=w_c&amp;space;=&amp;space;\left&amp;space;.&amp;space;\frac{\partial&amp;space;S_c}{\partial&amp;space;X}&amp;space;\right&amp;space;|_{X_0}"" target=""_blank""&gt;&lt;img src=""https://latex.codecogs.com/gif.latex?w_c&amp;space;=&amp;space;\left&amp;space;.&amp;space;\frac{\partial&amp;space;S_c}{\partial&amp;space;X}&amp;space;\right&amp;space;|_{X_0}"" title=""w_c = \left . \frac{\partial S_c}{\partial X} \right |_{X_0}"" /&gt;&lt;/a&gt;

where &lt;a href=""https://www.codecogs.com/eqnedit.php?latex=X_0"" target=""_blank""&gt;&lt;img src=""https://latex.codecogs.com/gif.latex?X_0"" title=""X_0"" /&gt;&lt;/a&gt; is an input and &lt;a href=""https://www.codecogs.com/eqnedit.php?latex=S_c(X)"" target=""_blank""&gt;&lt;img src=""https://latex.codecogs.com/gif.latex?S_c(X)"" title=""S_c(X)"" /&gt;&lt;/a&gt; is the class score function. 

Note that given an input &lt;a href=""https://www.codecogs.com/eqnedit.php?latex=X_0"" target=""_blank""&gt;&lt;img src=""https://latex.codecogs.com/gif.latex?X_0"" title=""X_0"" /&gt;&lt;/a&gt;, we can linearly approximate &lt;a href=""https://www.codecogs.com/eqnedit.php?latex=S_c(X)"" target=""_blank""&gt;&lt;img src=""https://latex.codecogs.com/gif.latex?S_c(X)"" title=""S_c(X)"" /&gt;&lt;/a&gt; around &lt;a href=""https://www.codecogs.com/eqnedit.php?latex=X_0"" target=""_blank""&gt;&lt;img src=""https://latex.codecogs.com/gif.latex?X_0"" title=""X_0"" /&gt;&lt;/a&gt; by computing the first-order Taylor expansion.

&lt;a href=""https://www.codecogs.com/eqnedit.php?latex=S_c(X)&amp;space;\approx&amp;space;w_c^TX&amp;space;&amp;plus;&amp;space;b_c"" target=""_blank""&gt;&lt;img src=""https://latex.codecogs.com/gif.latex?S_c(X)&amp;space;\approx&amp;space;w_c^TX&amp;space;&amp;plus;&amp;space;b_c"" title=""S_c(X) \approx w_c^TX + b_c"" /&gt;&lt;/a&gt;


&lt;!-- begin snippet: js hide: false console: true babel: false --&gt;

&lt;!-- language: lang-html --&gt;

output = model(input)

for c_idx in range(c_num+1):
w, = torch.autograd.grad(output[c_idx], input, retain_graph = True)
_, index = torch.abs(w).topk(k, dim = -1)

approx = w * input

&lt;!-- end snippet --&gt;",1,1
43,2018-11-6,2018,11,6,8,9uio22,Decision Tree Classifier Part 1 - Machine Learning Tutorial,https://www.reddit.com/r/deeplearning/comments/9uio22/decision_tree_classifier_part_1_machine_learning/,jeffxu999,1541459106,,0,1
44,2018-11-6,2018,11,6,9,9ujawm,Text to image matching,https://www.reddit.com/r/deeplearning/comments/9ujawm/text_to_image_matching/,ishandutta2007,1541463706,I have m paragraphs of text(about 50-70 words each) and n images (m&lt;n).  I want to find a matching image from those n images for each of these m paragraphs. Please suggest of any paper or open source implementation that you can think of.,3,1
45,2018-11-6,2018,11,6,12,9uklw7,"I need a walkthrough NLP. I work extensively in computer vision and deep learning, but I have no experience or whatsoever in NLP so any walk through is good for me. I need infor about embedding, glove, what are the preprocess for text, and how text differs from image when passed through NN. Thank",https://www.reddit.com/r/deeplearning/comments/9uklw7/i_need_a_walkthrough_nlp_i_work_extensively_in/,nile6499,1541473529,,2,1
46,2018-11-6,2018,11,6,17,9uml1b,What are the best introductory it neuroscience books that a deep learning engineer should read?,https://www.reddit.com/r/deeplearning/comments/9uml1b/what_are_the_best_introductory_it_neuroscience/,ariyanhasan,1541492047,,8,1
47,2018-11-6,2018,11,6,17,9ump4m,Summary of Google BERT Paper,https://www.reddit.com/r/deeplearning/comments/9ump4m/summary_of_google_bert_paper/,Karthik9999,1541493479,,0,1
48,2018-11-6,2018,11,6,19,9un9gq,Data Science Webinar: Recommender Systems - From Simple to Complex - November 15,https://www.reddit.com/r/deeplearning/comments/9un9gq/data_science_webinar_recommender_systems_from/,supercake53,1541500466,"Recommender Systems are a collection of algorithms that can be used to personalize content and offers for customers. Often considered one of the most successful and widespread application of machine learning technologies in business, they have been employed by major companies like Netflix, Amazon or Google to create new revenue streams and provide tailored experiences. Fortunately, their benefits are not limited to major tech companies with deep pockets. With a minimal technical background, almost anyone can implement a simple recommender system.

The objective of this webinar, hosted by Bigstep's Data Scientist, Andras Palfi, is to demystify the algorithms and methods used by recommender systems and provide a few practical use cases. No previous technical background is necessary, but familiarity with high-school level programming and mathematics will be helpful.

For more details, you can check out [this article](https://bigstep.com/blog/data-science-webinar-recommender-systems-from-simple-to-complex), for fast registering, see [here](https://zoom.us/webinar/register/5115397636034/WN_-Ch4K0gLTYeTEv5l2L8Ojw).",0,1
49,2018-11-6,2018,11,6,22,9uodev,One hot encoding with float as input / Keras,https://www.reddit.com/r/deeplearning/comments/9uodev/one_hot_encoding_with_float_as_input_keras/,lillojohn,1541511590,"Hi reddit,

I was working on a schoolproject. My data is like this

['reviewPoints (float)', 'price (float)', 'country (string)']

ex: [68, 10.12, 'Belgium'], [70, 20.50, 'UK']

So for the country column, I used on hot encoding.
Through a LabelBinarizer, I made the countries in labels.
So now the data looks like this:

ex: [68, 10.12, [1,0,0,0,0,0]], [70, 20.50, [0,0,1,0,0,0]]

X = ['reviewPoints', 'country']
y = ['price']

Now I want to do the fitting, but I get an error. Because I do not know what kind of input shape is.

model.add(Dense(1, input_shape=(1,0), kernel_initializer='he_normal', activation='sigmoid'))

Anyone has an idea?",8,1
50,2018-11-6,2018,11,6,22,9uoi6d,PyTorch Scholarship Challenge from Facebook: Im in!,https://www.reddit.com/r/deeplearning/comments/9uoi6d/pytorch_scholarship_challenge_from_facebook_im_in/,RegularJudge,1541512662,,12,1
51,2018-11-6,2018,11,6,22,9uoiar,"""That's my goal for the next few years!"" says Yann LeCun, the charismatic leader of Facebook AI. Follow the link to read the full interview on Computer Vision News",https://www.reddit.com/r/deeplearning/comments/9uoiar/thats_my_goal_for_the_next_few_years_says_yann/,Gletta,1541512692," 

Hot off the Press! Here are the links to the November 2018 issue of **Computer Vision News**, the magazine of the algorithm community published by **RSIP Vision**: interview with **Yann LeCun**, many more articles about computer vision and **free subscription at page 32**.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2018November/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2018-november-pdf/)

Enjoy!",1,1
52,2018-11-7,2018,11,7,3,9uqv7q,DeepMind Announces Pre-Symptom Eye Disease Prediction at Moorfields,https://www.reddit.com/r/deeplearning/comments/9uqv7q/deepmind_announces_presymptom_eye_disease/,trcytony,1541528516,,0,1
53,2018-11-7,2018,11,7,15,9ux3ed,Deep Learning for Network Biology,https://www.reddit.com/r/deeplearning/comments/9ux3ed/deep_learning_for_network_biology/,TsukiZombina,1541572960,,0,1
54,2018-11-8,2018,11,8,1,9v0xwl,How do you use Deep Learning in production?,https://www.reddit.com/r/deeplearning/comments/9v0xwl/how_do_you_use_deep_learning_in_production/,_spicyramen,1541608560,"I subscribe to a News Feed where I received tens of tutorials and articles about Tensorflow, Pytorch, Keras but I'm interested in knowing how do you use Neural Networks in your company, I have seen conflicting articles that mention traditional algorithms still prevail and wondering what are the use cases outside the Big N",6,1
55,2018-11-8,2018,11,8,4,9v2hme,Tool for Scene annotation,https://www.reddit.com/r/deeplearning/comments/9v2hme/tool_for_scene_annotation/,bluesky314,1541618918,"I am looking to run my convolutional net on a tennis video and see if it can recognise the type of shot played( straight, volley or cross court). What tool can I use to annote the scenes in my video?",2,1
56,2018-11-8,2018,11,8,12,9v6ma6,PCA,https://www.reddit.com/r/deeplearning/comments/9v6ma6/pca/,acvictor,1541648605,"I have a dataset of 1,800,000 with 40 dimensions (both test and train). I want to use PCA to reduce dimension to maybe 10. Do I need to run PCA on all the datapoints? Or run only on the train set and then use the same matrices on the test set? Or should I run on a 'large enough' subset of the train set? ",4,1
57,2018-11-8,2018,11,8,16,9v8039,Educational implementation of CNN in pure C++ with documentation,https://www.reddit.com/r/deeplearning/comments/9v8039/educational_implementation_of_cnn_in_pure_c_with/,ribtoks,1541661986,,0,1
58,2018-11-8,2018,11,8,22,9va6mf,How to generate a fitting album cover given a song when training on a large data set of songs and corresponding album covers?,https://www.reddit.com/r/deeplearning/comments/9va6mf/how_to_generate_a_fitting_album_cover_given_a/,deeplearningall,1541685431,"Hello!

I am interested in deep neural networks and have some experience with CNNs and RNNs. I want to generate a fitting album cover given a song, by training on a large data set of songs and their corresponding album covers. However I can't figure out how it could be done. 

I have looked into GANs and supervised learning, but I find it difficult to adapt these algorithms to my use case. There is some literature on the subject here that is similar to my goal:

[http://openaccess.thecvf.com/content\_cvpr\_2018\_workshops/papers/w49/Qiu\_Image\_Generation\_Associated\_CVPR\_2018\_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w49/Qiu_Image_Generation_Associated_CVPR_2018_paper.pdf)

&amp;#x200B;

I currently have a large data set of 30 second songs and album covers. I decided to convert the songs into stft chromagrams thinking that it will be easier to train using image representations of the songs. but I don't know where to go from here. Is there anyone who knows some method of doing this? ",6,1
59,2018-11-9,2018,11,9,6,9ve4ef,Data Labeling Impact,https://www.reddit.com/r/deeplearning/comments/9ve4ef/data_labeling_impact/,Cejan781,1541712361,"\*Noob here,  I hope i'm asking this question correctly\*

&amp;#x200B;

If you trained two CNNs on the same data, in the same order, with the same step size, same batch size, same initial weights and biases, same everything would the models perform uniformly on the same test data?  Are there any papers around this topic?

&amp;#x200B;

Maybe I'll just to jump to real question...

For images, I'm wondering how much better\*\* does a CNN perform with object image classification vs. object classification with localization (bounding box) vs. object classification with instance segmentation?  Are there any papers around this topic?",3,1
60,2018-11-9,2018,11,9,9,9vfk7j,"Things MUST know about fat, Obesity &amp; how to LOSE WEIGHT! (Evidence-Based)",https://www.reddit.com/r/deeplearning/comments/9vfk7j/things_must_know_about_fat_obesity_how_to_lose/,dr_barakat,1541722715,"Hey everyone, I am Dr Barakat, Medical doctor, researcher &amp; instructor as well

You must always believe that your capable of doing anything you want in your life, it's just all about taking a decision, having a willpower, and taking the right steps and guidance

Becoming overweight or obese is a cumulative result of having positive energy balance for a certain peroid of time, to reverse your condition and get a healthy weight, you should get a certain negative energy balance scheduled over a certain peroid...

To accomplish such thing, you should always start with changing your lifestyle; like:

\- Diet (eating low energy density food, drinking more water, using certain meal replacementsetc.)

\- Physical Activity (doing more housework or even engaging in some sports in a certain schedule...etc.)

\- Change your behaviors

Later on, in certain situations, you could use some medications which are very effective combined with lifestyle changes (some are even found as Over The Counter medications), and lastly surgeries can be done...

You should always know that being in good general condition doesn't, in anyhow, being safe from more than 195 complication of obesity!! So you must lose that excess fat!

Moreover, studies shows that being overweight is carrying some serious medical consequences...

This was a brief nutshell, for the sake of increasing your awareness of how important to lose your excess fat, and how some tips are used to do so...

I've already made few lectures available for preview, you can also take a more detailed idea about some facts &amp; myths about obesity, which way to start losing weight, what food to eat, how much to exercise &amp; much other in the provided course...

[https://dailylife.teachable.com/p/secrets-of-obesity-a-new-hope](https://dailylife.teachable.com/p/secrets-of-obesity-a-new-hope)

I hope it can help you out to become supremely healthy \^\_\^

Feel free to ask, and I will try to afford help as much as I can...

Good luck",1,1
61,2018-11-9,2018,11,9,19,9vjckm,What is the best way to initialize LSTM weights,https://www.reddit.com/r/deeplearning/comments/9vjckm/what_is_the_best_way_to_initialize_lstm_weights/,aziz_22,1541759107,"I came across different methods of initializing LSTM weights.

Currently, the tensorflow framework are using the Xavier\_initializer for their LSTM cells.

In the other hand, I have found other developers using the Orthogonal\_initializer in their implementations.

I didn't find any benchmarking concerning the effect of the weight initialization in LSTM.

But my current experiments showed me that the orthogonal\_initialization is working way better than the xavier\_init

Does anybody have a clear POC? or hint me with a paper that discussed this problem?",1,1
62,2018-11-9,2018,11,9,22,9vkg9l,Is the early stopping criteria during training considered as a hyperparameter of the model?,https://www.reddit.com/r/deeplearning/comments/9vkg9l/is_the_early_stopping_criteria_during_training/,aziz_22,1541770435,,2,1
63,2018-11-10,2018,11,10,0,9vllhg,ConvNet Parameters explanation???,https://www.reddit.com/r/deeplearning/comments/9vllhg/convnet_parameters_explanation/,KarthikMgk,1541779083,[removed],0,1
64,2018-11-10,2018,11,10,2,9vmav9,Seeing Through Walls with Adversarial WiFi Sensing: Attack and Defence Strategies,https://www.reddit.com/r/deeplearning/comments/9vmav9/seeing_through_walls_with_adversarial_wifi/,gwen0927,1541783849,,3,1
65,2018-11-10,2018,11,10,3,9vmvs4,Best way to create a training set for image text extraction?,https://www.reddit.com/r/deeplearning/comments/9vmvs4/best_way_to_create_a_training_set_for_image_text/,77sps,1541787745,"Hey, sort of new to computer vision and deep learning. Does anyone have advice about what the best way to create a training set for a deep learning model that will extract text from images? The text is words and numbers on peoples shoes in photos. 

Is there an easy tool that lets you upload your photos and tag them (a database that doesnt require lines of code just to actually label the different images). 

Thanks!",0,1
66,2018-11-10,2018,11,10,4,9vnjmc,Where to continue learning?,https://www.reddit.com/r/deeplearning/comments/9vnjmc/where_to_continue_learning/,PDihax,1541792294,"I've just finished the book ''Make your own neural network'' by Tariq Rashid. I had already known the math, but the book works perfectly as a gentle introduction to deep learning. My question is, where to continue? I really want to learn how to make a multi-hidden layered network, and also learn more about different architectures.
Where do you recommend me to continue this journey?",2,1
67,2018-11-10,2018,11,10,6,9vohtk,Classification within Images,https://www.reddit.com/r/deeplearning/comments/9vohtk/classification_within_images/,martian_rover,1541799075,"Hey guys,

I am working on a project to classify within an image as to classify what are the phases present in the microstructure image.

I learned deep learning algorithms are great in classifying images based on different classes but I am a bit confused on where to go and how to go for an algorithm to classify something within images.

I am attaching an image to make it more clear.

Hope to get some help and it will be appreciated.

[Al-Cu alloy microstructure](https://i.redd.it/mdhpi701hdx11.jpg)",13,1
68,2018-11-10,2018,11,10,7,9vos04,Deep learning for image generation under occlusions,https://www.reddit.com/r/deeplearning/comments/9vos04/deep_learning_for_image_generation_under/,S_T47,1541801070,"Hey I am starting a personal project to strengthen my experience in computer vision. And I wanted to know where can I start with trying to generate the underlying image which is occluded by some object so for example, if a person is occluded by some objects, how can a model generate the image of that person with the occluded object removed?
Any suggestions of reports? Code links? To get started with",2,1
69,2018-11-10,2018,11,10,8,9vpcmy,Intro to Deep Learning with PyTorch [Udacity Course],https://www.reddit.com/r/deeplearning/comments/9vpcmy/intro_to_deep_learning_with_pytorch_udacity_course/,dayanruben,1541805339,,0,1
70,2018-11-10,2018,11,10,12,9vr66b,I gave a non-technical intro to deep learning at SDC,https://www.reddit.com/r/deeplearning/comments/9vr66b/i_gave_a_nontechnical_intro_to_deep_learning_at/,ubershmekel,1541820838,,4,1
71,2018-11-10,2018,11,10,14,9vrxqs,Weird percentages,https://www.reddit.com/r/deeplearning/comments/9vrxqs/weird_percentages/,KarthikMgk,1541828286,[removed],0,1
72,2018-11-10,2018,11,10,23,9vuvaj,Self Driving 3D Simulation Neural Networks Genetic Algorithm Deep Learning,https://www.reddit.com/r/deeplearning/comments/9vuvaj/self_driving_3d_simulation_neural_networks/,DevTechRetopall,1541861635,,3,1
73,2018-11-11,2018,11,11,5,9vxibt,Neural Network Part 1 - Tensorflow Tutorial,https://www.reddit.com/r/deeplearning/comments/9vxibt/neural_network_part_1_tensorflow_tutorial/,jeffxu999,1541881207,,1,1
74,2018-11-11,2018,11,11,12,9w0txq,Highlight important word from text,https://www.reddit.com/r/deeplearning/comments/9w0txq/highlight_important_word_from_text/,ishandutta2007,1541908653,"Let me know if you can think of any AI code/model/paper to underline(ie select) important names, places, dates, numbers from a paragraph of text. ",1,1
75,2018-11-11,2018,11,11,17,9w28qy,Website for trending deep learning research papers.,https://www.reddit.com/r/deeplearning/comments/9w28qy/website_for_trending_deep_learning_research_papers/,Karthik9999,1541924560,,3,1
76,2018-11-11,2018,11,11,17,9w2egr,Beginner question: RNN Predicting Sine Wave,https://www.reddit.com/r/deeplearning/comments/9w2egr/beginner_question_rnn_predicting_sine_wave/,BttrThanU,1541926637,"I self-coded an LSTM (not using TensorFlow and the like). Using `0.2*sin(x)+0.5` as an exercise, I can't seem to get the validation error down: the predicted curve is always slightly shifted.

[Validation curve](https://i.redd.it/qynnysug0ox11.png)

&amp;#x200B;

*Processing img f8qsrdew0ox11...*

Do you guys have any suggestions as to why might this be the case?",7,1
77,2018-11-11,2018,11,11,18,9w2exe,"As a new Deep Learning practitioner, what would be some good papers to implement?",https://www.reddit.com/r/deeplearning/comments/9w2exe/as_a_new_deep_learning_practitioner_what_would_be/,justachetan,1541926807,"Hi! 

I have just completed an Undergrad level course in Deep Learning and wanted to get into the practical side of it by implementing some papers. What would be some good papers to start with?",9,1
78,2018-11-12,2018,11,12,3,9w5znb,Kaggle first notebook,https://www.reddit.com/r/deeplearning/comments/9w5znb/kaggle_first_notebook/,dvegliante,1541959883,"Hi, 

in the last year I'm studying some Machine Learning and Deep Learning algorithms from Coursera and other sources. I've published my first notebook on Kaggle using the Credit Card Fraud Detection dataset and I would to share here with you my work and maybe obtain some useful comment and advice. 

&amp;#x200B;

Since the data is highly imbalanced I decided to make two notebooks where I use two technique for avoid the problem. I leave here the link, and I thank to everyone that decide to take a look. :-)

&amp;#x200B;

Undersampling ([https://www.kaggle.com/davidevegliante/nn-for-fraud-detection](https://www.kaggle.com/davidevegliante/nn-for-fraud-detection))

Using SMOTE (oversampling) ([https://www.kaggle.com/davidevegliante/nn-for-fraud-detection](https://www.kaggle.com/davidevegliante/nn-for-fraud-detection))

&amp;#x200B;

Davide",0,1
79,2018-11-12,2018,11,12,3,9w63q3,Looking for Implementation of Probabilistic Binary Neural Networks,https://www.reddit.com/r/deeplearning/comments/9w63q3/looking_for_implementation_of_probabilistic/,nelsonlinsanity,1541960699,"I'm currently looking to find implementations of two papers. One of them is Probabilistic Binary Neural Networks. Does anyone know where I can find them besides Github, which I've already looked through?
",0,1
80,2018-11-12,2018,11,12,3,9w67rs,Fast R-CNN assumes that there is at most one bounding box for each category?,https://www.reddit.com/r/deeplearning/comments/9w67rs/fast_rcnn_assumes_that_there_is_at_most_one/,Kindlychung,1541961510,"From the Fast R-CNN paper:

https://i.redd.it/zpm2v2v6xqx11.png

Since there is a fully connected layer for ""category-specific bounding box regressors"", does this imply that it assumes that there is at most one bounding box for each category?",3,1
81,2018-11-12,2018,11,12,4,9w6p17,Implementation of AlphaGo Zero in tensorflow,https://www.reddit.com/r/deeplearning/comments/9w6p17/implementation_of_alphago_zero_in_tensorflow/,cody2007_2,1541964942,[removed],0,1
82,2018-11-12,2018,11,12,14,9wb6n6,[BEGINNER TUTORIAL] Build your own custom real-time object classifier,https://www.reddit.com/r/deeplearning/comments/9wb6n6/beginner_tutorial_build_your_own_custom_realtime/,affinitive2,1542000243,"Step-by-step beginners tutorial on building a real-time object classifier for any custom object of your choice.

[https://medium.com/@chuanenlin/tutorial-build-an-object-detection-system-using-yolo-9a930513643a](https://medium.com/@chuanenlin/tutorial-build-an-object-detection-system-using-yolo-9a930513643a)

Feel free to check it out!",1,1
83,2018-11-12,2018,11,12,20,9wd7l8,GitHub - hanxiao/bert-as-service: Mapping a variable-length sentence to a fixed-length vector using pretrained BERT model,https://www.reddit.com/r/deeplearning/comments/9wd7l8/github_hanxiaobertasservice_mapping_a/,h_xiao,1542021487,,1,1
84,2018-11-13,2018,11,13,4,9whfew,How to make a custom object detector using YOLOv3 in python,https://www.reddit.com/r/deeplearning/comments/9whfew/how_to_make_a_custom_object_detector_using_yolov3/,tahaemara,1542052296,"I published a new post about making a custom object detector using YOLOv3 in python. For those who prefer using docker, I wrote a dockerfile to create a docker image contains darknet, opencv 3, and Cuda.

Post: [http://emaraic.com/blog/yolov3-custom-object-detector](http://emaraic.com/blog/yolov3-custom-object-detector)

 Source code: [https://github.com/tahaemara/yolo-custom-object-detector/tree/master/python](https://github.com/tahaemara/yolo-custom-object-detector/tree/master/python) 

Docker file: [https://github.com/tahaemara/yolo-custom-object-detector/tree/master/docker](https://github.com/tahaemara/yolo-custom-object-detector/tree/master/docker)",6,1
85,2018-11-13,2018,11,13,12,9wlhh0,3D visualization of network and it's working with tensorflow .js,https://www.reddit.com/r/deeplearning/comments/9wlhh0/3d_visualization_of_network_and_its_working_with/,amit2rockon,1542080607,[https://github.com/tensorspace-team/tensorspace](https://github.com/tensorspace-team/tensorspace),0,1
86,2018-11-13,2018,11,13,13,9wlqgp,Deep Learning Newbie -Nvidia CUDA Version 10.0 install Question,https://www.reddit.com/r/deeplearning/comments/9wlqgp/deep_learning_newbie_nvidia_cuda_version_100/,polandtown,1542082667,,3,1
87,2018-11-13,2018,11,13,20,9wocz9,An Awesome Playlist to start Learning Neural Networks,https://www.reddit.com/r/deeplearning/comments/9wocz9/an_awesome_playlist_to_start_learning_neural/,_bnjmn,1542109394,,0,1
88,2018-11-13,2018,11,13,20,9wof85,An Awesome Playlist to get you started with Neural Networks,https://www.reddit.com/r/deeplearning/comments/9wof85/an_awesome_playlist_to_get_you_started_with/,_bnjmn,1542110036,"I am currently an engineering undergrad that got interested in Machine Learning and Neural Networks.

At first it was frustrating because I don't where to start learning and I'm having a hard time understanding the technicalities of 
implementing neural networks (though, I can understand the concept).

But gladly I found this awesome playlist. I only have about a month of Python experience (I have a Java background), and I was able to follow along with these videos and I am proud to say that I have implemented my own neural network trained with my own pre-processed data and incorporated the model in my own project.

So, I'm sharing this amazing find with my fellow deeplearning enthusiasts. Enjoy!

Thanks deeplizard for this playlist.",0,1
89,2018-11-13,2018,11,13,21,9wohhh,Sharing this awesome playlist to get you started with Neural Networks,https://www.reddit.com/r/deeplearning/comments/9wohhh/sharing_this_awesome_playlist_to_get_you_started/,_bnjmn,1542110650,,2,1
90,2018-11-13,2018,11,13,22,9wozrf,Data Science in Esports,https://www.reddit.com/r/deeplearning/comments/9wozrf/data_science_in_esports/,divya2018,1542115264,,0,1
91,2018-11-14,2018,11,14,4,9ws04t,Neural Network Embeddings: from inception to simple,https://www.reddit.com/r/deeplearning/comments/9ws04t/neural_network_embeddings_from_inception_to_simple/,cptAwesome_070,1542135973,,2,1
92,2018-11-14,2018,11,14,6,9wt8kj,How do you find the neurons excited by an object in an image?,https://www.reddit.com/r/deeplearning/comments/9wt8kj/how_do_you_find_the_neurons_excited_by_an_object/,thelethargicdreamer,1542143895,"Hi all,

I'm currently working on object detection using pre-trained classifiers. Was looking for some advice on how to 
1. visualize features from the convolutional layers for an image that would form a new object class, and 
2. find the neurons that already react positively to that image. 

Would I need to train the last layer to identify the new class in order to answer my second question?

Thanks in advance!",3,1
93,2018-11-14,2018,11,14,6,9wthv0,MFCC Data augmentation,https://www.reddit.com/r/deeplearning/comments/9wthv0/mfcc_data_augmentation/,qeVut7tguCpxKqqMPtWU,1542145588,"Hi, Im training a network with MFCC as part of the input. I was wondering if anyone has some ideas how to make the training speaker independent. I have a lot of data for a very small number of people and I was wondering whats the best way to extract most information from the dataset, thanks! ",2,1
94,2018-11-14,2018,11,14,8,9wuhqf,AdaBoost Part 1- Machine Learning Tutorial,https://www.reddit.com/r/deeplearning/comments/9wuhqf/adaboost_part_1_machine_learning_tutorial/,jeffxu999,1542152450,,3,1
95,2018-11-14,2018,11,14,14,9wx3bn,Building a mid-range deep learning PC,https://www.reddit.com/r/deeplearning/comments/9wx3bn/building_a_midrange_deep_learning_pc/,atinesh229,1542172702,"Hello guys, I'm building a mid-range budget PC for Deep Learning research before I finalize I thought I should get some comments from you guys. Here is the list of parts that I have chosen that fits in my budget.

&amp;#x200B;

\[PCPartPicker part list\]([https://pcpartpicker.com/list/HLtZHh](https://pcpartpicker.com/list/HLtZHh)) / \[Price breakdown by merchant\]([https://pcpartpicker.com/list/HLtZHh/by\_merchant/](https://pcpartpicker.com/list/HLtZHh/by_merchant/))

&amp;#x200B;

Type|Item|Price

:----|:----|:----

\*\*CPU\*\* | \[Intel - Core i3-8100 3.6 GHz Quad-Core Processor\]([https://pcpartpicker.com/product/YqKhP6/intel-core-i3-8100-36ghz-4-core-processor-bx80684i38100](https://pcpartpicker.com/product/YqKhP6/intel-core-i3-8100-36ghz-4-core-processor-bx80684i38100)) | $129.79 @ Amazon

\*\*Motherboard\*\* | \[ASRock - B360M Pro4 Micro ATX LGA1151 Motherboard\]([https://pcpartpicker.com/product/vZzkcf/asrock-b360m-pro4-micro-atx-lga1151-motherboard-b360m-pro4](https://pcpartpicker.com/product/vZzkcf/asrock-b360m-pro4-micro-atx-lga1151-motherboard-b360m-pro4)) | $78.99 @ Amazon

\*\*Memory\*\* | \[Corsair - Vengeance LPX 8 GB (1 x 8 GB) DDR4-2400 Memory\]([https://pcpartpicker.com/product/y8rcCJ/corsair-memory-cmk8gx4m1a2400c16r](https://pcpartpicker.com/product/y8rcCJ/corsair-memory-cmk8gx4m1a2400c16r)) | $59.99 @ Amazon

\*\*Storage\*\* | \[Seagate - Barracuda 2 TB 3.5"" 7200RPM Internal Hard Drive\]([https://pcpartpicker.com/product/CbL7YJ/seagate-barracuda-2tb-35-7200rpm-internal-hard-drive-st2000dm006](https://pcpartpicker.com/product/CbL7YJ/seagate-barracuda-2tb-35-7200rpm-internal-hard-drive-st2000dm006)) | $54.99 @ Amazon

\*\*Video Card\*\* | \[Zotac - GeForce GTX 1050 Ti 4 GB OC Edition Video Card\]([https://pcpartpicker.com/product/LrmxFT/zotac-geforce-gtx-1050-ti-4gb-oc-edition-video-card-zt-p10510b-10l](https://pcpartpicker.com/product/LrmxFT/zotac-geforce-gtx-1050-ti-4gb-oc-edition-video-card-zt-p10510b-10l)) | $179.99 @ Amazon

\*\*Power Supply\*\* | \[Corsair - VS 450 W 80+ Certified ATX Power Supply\]([https://pcpartpicker.com/product/6rc48d/corsair-vs-450w-80-certified-atx-power-supply-cp-9020170-na](https://pcpartpicker.com/product/6rc48d/corsair-vs-450w-80-certified-atx-power-supply-cp-9020170-na)) | $34.99 @ Amazon

\*\*Optical Drive\*\* | \[Asus - DRW-24D5MT DVD/CD Writer\]([https://pcpartpicker.com/product/wh38TW/asus-drw-24d5mt-dvdcd-writer-drw-24d5mt](https://pcpartpicker.com/product/wh38TW/asus-drw-24d5mt-dvdcd-writer-drw-24d5mt)) |-

| \*Prices include shipping, taxes, rebates, and discounts\* |

| \*\*Total\*\* | \*\*$538.74\*\*

| Generated by \[PCPartPicker\]([https://pcpartpicker.com](https://pcpartpicker.com)) 2018-11-14 00:16 EST-0500 |",17,1
96,2018-11-14,2018,11,14,17,9wycag,Deep Learning Market,https://www.reddit.com/r/deeplearning/comments/9wycag/deep_learning_market/,marketsandmarkets,1542184872,[removed],0,1
97,2018-11-14,2018,11,14,21,9wzsv2,Interpretation of Results,https://www.reddit.com/r/deeplearning/comments/9wzsv2/interpretation_of_results/,PiAreSqured,1542199706,"I have been working on text classification on a multilingual legal corpus. As an initial test, I preprocessed a single language corpus and fed it into a *bidirectional LSTM*. There are around 5000 documents divided into 32 categories and around 2 Million sentences(examples). Now the average precision, recall, and f-score values were around 0.54,0.56,0.55. As the classes were imbalanced I decided to apply class weights and there was a 0.03 difference. However when I clustered the data into 2 clusters (I did find out the number of clusters through Shilloute score) using agglomerative clustering, one cluster of 14 classes and one cluster of 18 classes and performed classification on both of these clusters and I received 0.79, 0.79, 0.79 precision, recall, and f-score values for both cluster. I could not understand the sudden increase in the performance?

&amp;#x200B;

Note: I check if my model overfits, but they don't. ",0,1
98,2018-11-15,2018,11,15,0,9x1aqi,OpenAI Founder: Short-Term AGI Is a Serious Possibility,https://www.reddit.com/r/deeplearning/comments/9x1aqi/openai_founder_shortterm_agi_is_a_serious/,gwen0927,1542210976,,5,1
99,2018-11-15,2018,11,15,2,9x25e2,Just Dance Fortnite edition game hack with OpenPose DNN,https://www.reddit.com/r/deeplearning/comments/9x25e2/just_dance_fortnite_edition_game_hack_with/,rafaelmizrahi,1542216532,"We've hacked a Just Dance Fortniteedition game at Geekcon.org 2018 makers weekend.

[https://www.youtube.com/watch?v=mKVvQLzAXaM](https://www.youtube.com/watch?v=mKVvQLzAXaM)

[https://www.youtube.com/watch?v=yvjxjdjyEw4](https://www.youtube.com/watch?v=yvjxjdjyEw4)

The project core is using Open Broadcaster Software (OBS).  
OBS filter pose detection and matching implemented using **OpenCV** and **OpenPose** MobileNet deep neural network.

Project members: Rafael Mizrahi, Mickey Martin, Myriam Schmidt

**project page**

[https://rafaelmizrahi.blogspot.com/2018/09/just-dance-fortnite-edition.html](https://rafaelmizrahi.blogspot.com/2018/09/just-dance-fortnite-edition.html)

**source code**

[https://github.com/Feng-GUI/experience/tree/master/JustDanceFortnite](https://github.com/Feng-GUI/experience/tree/master/JustDanceFortnite)

&amp;#x200B;

*Processing img jrvfun2wsby11...*",2,1
100,2018-11-15,2018,11,15,2,9x266a,Performance profiling of Neural Networks,https://www.reddit.com/r/deeplearning/comments/9x266a/performance_profiling_of_neural_networks/,rafeey,1542216671,"&amp;#x200B;

https://i.redd.it/txekmv1f0cy11.png",0,1
101,2018-11-15,2018,11,15,2,9x27u6,I need data!,https://www.reddit.com/r/deeplearning/comments/9x27u6/i_need_data/,ljferguson94,1542216981,"Hey all, it took me ages but I successfully installed Tensorflow &amp; Keras on my PC, and I've confirmed it's routing deep neural network goodness to my Nvidia GE940MX (348 nodes, I think, 2 gb of GPU RAM) using other people's code/datasets. (also, is this enough GPU for decent computation??)

I'm asking if any of you have a good online resource of pre-curated data I can play around with? Text data, image data, genomic data, anything, news articles/titles, advert content, anything? 

Thanks!",8,1
102,2018-11-15,2018,11,15,2,9x2aiu,Performance profiling of Neural Networks,https://www.reddit.com/r/deeplearning/comments/9x2aiu/performance_profiling_of_neural_networks/,rafeey,1542217472,"  

I am looking to perform performance profiling (per layer latency,  execution times, number of operation etc) of neural networks during  inference phase i.e. mymodel.predict() phase. I am using keras to build  my neural networks. Does anyone know of any usefull libraries in this  domain? 

Also, I researched about Tensorboard's Runtime statistics, Can it be  used with keras?  does it profile forward passes, like if  I just want to calculate per  layer execution time during a forward pass of pre trained net from the  input. Can tensorboard do that?

My main goal is the performance profiling of famous deep learning models like  resnet, googlenet etc. Which framework has better tools to do that, TF or Keras?",2,1
103,2018-11-15,2018,11,15,3,9x2rbx,Colorizing and Restoring Old Images with Deep Learning,https://www.reddit.com/r/deeplearning/comments/9x2rbx/colorizing_and_restoring_old_images_with_deep/,MyMomSaysImHot,1542220533,,0,1
104,2018-11-15,2018,11,15,4,9x3840,Is it worth learning TensorFlow with TensorFlow 2.0 coming out so soon?,https://www.reddit.com/r/deeplearning/comments/9x3840/is_it_worth_learning_tensorflow_with_tensorflow/,hunchojackson,1542223610,I have been programming for a few years and I am looking to get into using ML python libraries. I have familiarity with a few but I am looking to take a deeper dive. So is it even worth learning TF right now with 2.0 around the corner? If not is there something that would be more practical to learn from a professional perspective in the mean time?,4,1
105,2018-11-15,2018,11,15,6,9x4k4r,Where should apply a stride of 2 on bottleneck of resnet?,https://www.reddit.com/r/deeplearning/comments/9x4k4r/where_should_apply_a_stride_of_2_on_bottleneck_of/,zhwu,1542232129,"The first of block of every stage of resnet, it will perform downsample on the input. [Tensornets](https://github.com/taehoonlee/tensornets/blob/90967d49dab55dc8adab37a3b016c07dae47eea9/tensornets/resnets.py#L270) implement this via applying stride of 2 on 1x1 conv, but it says many other implementation apply stride of 2 on 3x3 conv. I wonder if there is any reason to choose different conv layer to apply stride of 2, or it doesn't matter where we apply a stride of 2 on bottleneck. ",0,1
106,2018-11-15,2018,11,15,7,9x50lw,Andrew Ng Offers AI For Everyone,https://www.reddit.com/r/deeplearning/comments/9x50lw/andrew_ng_offers_ai_for_everyone/,gwen0927,1542235173,,1,1
107,2018-11-15,2018,11,15,7,9x55n6,Intillegent Bot with database,https://www.reddit.com/r/deeplearning/comments/9x55n6/intillegent_bot_with_database/,e_heaven,1542236130,"Guys hello there!

My aim is to create support bot for, uh, Iphone retailer, for example. The main thing is, that bot must be connected with database, which has tables with information about Iphones (like model, price, amount avavailible, color etc).

For example, user asks bot if they have Iphone 7 plus 'Space grey' or smth like that, and bot has to understand the message and take the information from DB and answer user.

I've looked for MS Azure opportunities, but I'm not sure if it provies DL chat bot (I've found only Q&amp;A chatbot, it means I have to predict all question and prepare answers to them. Btw there are C# and node.js options, no python availible).

Can u guys give me any advises how to perform this, or maybe some links which could help me? (I use Python)

Thank you!",0,1
108,2018-11-15,2018,11,15,8,9x5p0v,Deep Learning Without Frameworks [75 min video],https://www.reddit.com/r/deeplearning/comments/9x5p0v/deep_learning_without_frameworks_75_min_video/,beaucarnes,1542239881,,0,1
109,2018-11-15,2018,11,15,12,9x76t6,"For anyone looking to get into machine learning, I would advise that you don't learn the behemoth libraries like Tensorflow or Theano, but instead learn how to use a high-level API like Keras. Here's a quick video to explain what it is. Hope I was helpful!",https://www.reddit.com/r/deeplearning/comments/9x76t6/for_anyone_looking_to_get_into_machine_learning_i/,antaloaalonso,1542251104,,4,1
110,2018-11-15,2018,11,15,18,9x9kxm,Volunteers needed to test the AI chatbot,https://www.reddit.com/r/deeplearning/comments/9x9kxm/volunteers_needed_to_test_the_ai_chatbot/,Moscow_Phystech,1542272653,"Would you like to talk to an Artificial Intelligence?  
We invite volunteers to help researchers improve their chatbot. You will be asked to have a small conversation with either AI bot or another human. Please join our effort to create an open dataset for the development of the next generation of conversational AI solutions. Your donated dialogues will help establish a concrete scenario for chatbots testing.

The evaluation system is available at FB Messenger via link [https://m.me/convai.io](https://m.me/convai.io?fbclid=IwAR1A5Xn6IGpZLlxLsy0yYgH2QBOlDaGoRQIRV0Z6I97hFCGhSL_j3-rQUL8)",0,1
111,2018-11-15,2018,11,15,22,9xbbt6,"In deep learning, what's the best train-validation-test split? Is it different for transfer learning?",https://www.reddit.com/r/deeplearning/comments/9xbbt6/in_deep_learning_whats_the_best/,musafirsafwan,1542289830,I know there is no definite answer for this question. I just want to get the popular opinion so that I can use it as a rule of thumb.,2,1
112,2018-11-16,2018,11,16,0,9xcbtr,Global Minima Solution for Neural Networks?,https://www.reddit.com/r/deeplearning/comments/9xcbtr/global_minima_solution_for_neural_networks/,gwen0927,1542296972,,0,1
113,2018-11-16,2018,11,16,1,9xcjgk,Best resource for tracking/reading important ArXiV papers?,https://www.reddit.com/r/deeplearning/comments/9xcjgk/best_resource_for_trackingreading_important_arxiv/,PullThisFinger,1542298351,"I've been reading ArXiV papers from the following sources:

[www.arxiv-sanity.com](https://www.arxiv-sanity.com)

DL Reading Roadmap (Github): [https://github.com/bjpcjp/Deep-Learning-Papers-Reading-Roadmap](https://github.com/bjpcjp/Deep-Learning-Papers-Reading-Roadmap)

Awesome Deep Learning (Github): [https://github.com/terryum/awesome-deep-learning-papers](https://github.com/terryum/awesome-deep-learning-papers)

&amp;#x200B;

I also subscribe, via Feedly, to ArXiV's RSS feed. Thing is, I'm not embedded in the DL community. It's difficult for this amateur to know which papers are worth my time. Suggestions? ",8,1
114,2018-11-16,2018,11,16,1,9xcu7d,Laptop GTX 1060 vs Google Colab for deep learning,https://www.reddit.com/r/deeplearning/comments/9xcu7d/laptop_gtx_1060_vs_google_colab_for_deep_learning/,tejasa97,1542300348,"Hi I've been using Colab for a while now, but I hear that even the laptop variant of GTX1060 outperforms it. Hence I was planning on buying it this during this Black Friday sale. One with i7 8th gen, 16GB ram, 256 Pcie SSD. Will it be better than Colab?",7,1
115,2018-11-16,2018,11,16,6,9xfcat,Building a computer for deeplearning at work. Whats your take on the best build for my budget?,https://www.reddit.com/r/deeplearning/comments/9xfcat/building_a_computer_for_deeplearning_at_work/,that_marty_guy,1542316332,"Hi all,

Work is giving me a $5000 budget for a DL station. They dont want to use the cloud for now. I have some thoughts about what I would want, but I am curious what sort of builds you would get on PC part picker.

Note: I am located in Canada.",1,1
116,2018-11-16,2018,11,16,6,9xfqlz,"If you aren't in a hurry to start implementing deep learning, then you may want to consider that before you jump into an API like Keras, you learn exactly how Neural Networks do what they do. Here's a helpful video series that talks about just this.",https://www.reddit.com/r/deeplearning/comments/9xfqlz/if_you_arent_in_a_hurry_to_start_implementing/,JohnJohnant,1542318992,,0,1
117,2018-11-16,2018,11,16,8,9xgiip,How to get started with deep reinforcement learning applied to finance (price prediction)?,https://www.reddit.com/r/deeplearning/comments/9xgiip/how_to_get_started_with_deep_reinforcement/,S_T47,1542324422,"Just curious to see how DRL applies outside of open ai gym based environments and want to learn how to apply it to a real world kind of problem. Finance data/ price prediction is just for fun.... however Im struggling to understand how to get started with this (plenty resources available for supervised learning on price prediction but very little on DRL for price prediction)

",5,1
118,2018-11-16,2018,11,16,9,9xgvvs,Array - Numpy Python Tutorial,https://www.reddit.com/r/deeplearning/comments/9xgvvs/array_numpy_python_tutorial/,jeffxu999,1542327118,,0,1
119,2018-11-16,2018,11,16,15,9xjj6z,Noob Trying to Get Started,https://www.reddit.com/r/deeplearning/comments/9xjj6z/noob_trying_to_get_started/,FlamingKoala6,1542348415,"So I've been real interested in deep learning for a while, but never had the inspiration to get started, especially after hearing about the Legendary Elon Dota Machine. I'd kinda forgot about the whole deep learning scene until I saw a video talking about an ai challenge (https://youtu.be/qIW7C9JelCw) and began to wonder how difficult it would be to do something like the Dota bot for this. As far as I can tell, the ""Rapid"" API used in that bot isn't out yet? I haven't done anything with neural networks but am interested in trying to see if I can get something passable working. Any help or tutorials you can shoot my way would be especially appreciated. Also if you haven't heard of that project you might want to look into it bc there looks to be some good prizes.",4,1
120,2018-11-16,2018,11,16,15,9xjpfr,Deep Learning going to change,https://www.reddit.com/r/deeplearning/comments/9xjpfr/deep_learning_going_to_change/,BEPEC_Solutions,1542350045,,0,1
121,2018-11-16,2018,11,16,18,9xkn5v,convert videos (eg. .avi) to TensorFlow's tfrecords file format,https://www.reddit.com/r/deeplearning/comments/9xkn5v/convert_videos_eg_avi_to_tensorflows_tfrecords/,whiletrue2,1542359869,,0,1
122,2018-11-16,2018,11,16,18,9xksg7,Understanding the scaling of L regularization in the context of neural networks,https://www.reddit.com/r/deeplearning/comments/9xksg7/understanding_the_scaling_of_l_regularization_in/,shaypal5,1542361465,,10,1
123,2018-11-16,2018,11,16,21,9xllpf,3 Reasons for Using Artificial Intelligence in Cyber Security,https://www.reddit.com/r/deeplearning/comments/9xllpf/3_reasons_for_using_artificial_intelligence_in/,Victor_Stakh,1542370022,,0,1
124,2018-11-16,2018,11,16,22,9xlywg,Any good mathmatical exercises to train typical deep learning formulas?,https://www.reddit.com/r/deeplearning/comments/9xlywg/any_good_mathmatical_exercises_to_train_typical/,labonabo,1542373383,"I am having trouble remembering and understanding what exactly which formula does, so math is usually a good way to train it, at least for me... but I can't find any exercises online, maybe you know one?

(for example calculating sigmoid and relu functions)",3,2
125,2018-11-16,2018,11,16,23,9xmidm,Building a deep learning station for work. Anything I should change?,https://www.reddit.com/r/deeplearning/comments/9xmidm/building_a_deep_learning_station_for_work/,that_marty_guy,1542377668,,6,2
126,2018-11-17,2018,11,17,2,9xnyjl,"List of AI research project at Stanford , MIT , CMU",https://www.reddit.com/r/deeplearning/comments/9xnyjl/list_of_ai_research_project_at_stanford_mit_cmu/,Karthik9999,1542387635,,3,1
127,2018-11-17,2018,11,17,4,9xplhr,AMD vs Intel CPU for DL Machine,https://www.reddit.com/r/deeplearning/comments/9xplhr/amd_vs_intel_cpu_for_dl_machine/,brsystem,1542398393,"Hey guys, I'm building a machine for deep learning and was a bit lost on what CPU I should choose. I have chosen a Nvidia 2070 XC Gaming for my GPU, but I'm a bit lost on how important the CPU is and whether there is a downside to either AMD or Intel. I read some past posts which mentioned that AMD incompatbilibty with Intel's MKL might be an issue for some pieces of software. What do you guys think? Would that only affect some preprocessing? The AMD chips are significantly cheaper with higher core counts, but I think avoiding software compatibility issues is more important. Any thoughts would be appreciated.",8,1
128,2018-11-17,2018,11,17,6,9xqo12,Random website I made using deep learning to predict how attractive you are,https://www.reddit.com/r/deeplearning/comments/9xqo12/random_website_i_made_using_deep_learning_to/,genixpro,1542405475,,3,1
129,2018-11-17,2018,11,17,12,9xt3m1,Catboost: the new generation of gradient boosting,https://www.reddit.com/r/deeplearning/comments/9xt3m1/catboost_the_new_generation_of_gradient_boosting/,PullThisFinger,1542425024,,3,1
130,2018-11-17,2018,11,17,12,9xt8cd,Install Package - Google Colab Tutorial,https://www.reddit.com/r/deeplearning/comments/9xt8cd/install_package_google_colab_tutorial/,jeffxu999,1542426203,,1,1
131,2018-11-17,2018,11,17,16,9xufee,Building footprint extraction.,https://www.reddit.com/r/deeplearning/comments/9xufee/building_footprint_extraction/,girishpillai17,1542438198,"How can you extract the footprints of the building rooftops from an satellite image using computer vision, machine learning and deep learning. My aim is to just extract the buildings rooftops from the image. What should be the approach for this and what all technologies should be used to achieve the output as shown in the image? ",0,1
132,2018-11-17,2018,11,17,16,9xuk8c,Sentiment analysis using Arabic data,https://www.reddit.com/r/deeplearning/comments/9xuk8c/sentiment_analysis_using_arabic_data/,mgalalen,1542439726,"My attempt to compare machine learning approach vs deep learning in sentiment analysis using Arabic data

[Github repo](https://github.com/galalen/arabic-sentiment-analysis)",1,1
133,2018-11-17,2018,11,17,17,9xuqhg,cvpr 2019 has 7000+ submissions!,https://www.reddit.com/r/deeplearning/comments/9xuqhg/cvpr_2019_has_7000_submissions/,hankaixyz,1542441806,"wowwwww
",2,1
134,2018-11-18,2018,11,18,2,9xy5m4,How does one select a GPU for setting up a Deep Learning machine?,https://www.reddit.com/r/deeplearning/comments/9xy5m4/how_does_one_select_a_gpu_for_setting_up_a_deep/,S_T47,1542475552,"I'm finding it difficult to understand based on what parameters does one select the right GPU? The ones I'm considering at the moment are: Cuda cores and the GPU Memory. So far (based on my budget of 690, approx $ 885 for a GPU) I think gtx 1080ti  is the best. However a cheaper alternative RTX 2070 is also recommended by some people, so how do you choose? ",25,1
135,2018-11-18,2018,11,18,4,9xz1ht,Creating a self-driving car simulator 2019 Neural Networks and Genetic Algorithm Tutorial 1,https://www.reddit.com/r/deeplearning/comments/9xz1ht/creating_a_selfdriving_car_simulator_2019_neural/,DevTechRetopall,1542481734,,0,1
136,2018-11-18,2018,11,18,6,9y08es,Amazing performance laptop for deep learning using tensorflow and keras! Super fast in running DL models for image classification and predictions,https://www.reddit.com/r/deeplearning/comments/9y08es/amazing_performance_laptop_for_deep_learning/,nietzstark33,1542490522,,2,1
137,2018-11-18,2018,11,18,7,9y0p1e,[video] The Evolution of ConvNets [x-post learnmachinelearning],https://www.reddit.com/r/deeplearning/comments/9y0p1e/video_the_evolution_of_convnets_xpost/,ajhalthor,1542494055,,0,1
138,2018-11-18,2018,11,18,11,9y2ima,The Significance of Poisson Distribution in Statistics | Hashtag Statistics,https://www.reddit.com/r/deeplearning/comments/9y2ima/the_significance_of_poisson_distribution_in/,LearningFromData,1542509101,,1,1
139,2018-11-18,2018,11,18,14,9y3g7i,"Where, how to set a random state on Caffe for CNN",https://www.reddit.com/r/deeplearning/comments/9y3g7i/where_how_to_set_a_random_state_on_caffe_for_cnn/,giggitygigg14,1542518015,"I'm new to Caffe and I am working on the MNIST dataset. 

 The weights are being randomly initialized using the Xavier algorithm and I'm not able to reproduce the exact results.

Any leads on how and where to set up the random state?",0,1
140,2018-11-18,2018,11,18,14,9y3lf8,"[Discussion] Where, how to set up the random state in Caffe for CNN.",https://www.reddit.com/r/deeplearning/comments/9y3lf8/discussion_where_how_to_set_up_the_random_state/,giggitygigg14,1542519437,"I'm new to Caffe and I am working on the MNIST dataset. 

The weights are being randomly initialized using the Xavier algorithm and I'm not able to reproduce the exact results.

Any leads on how and where to set up the random state?",1,1
141,2018-11-18,2018,11,18,17,9y4hw8,How do you (unit) test your code?,https://www.reddit.com/r/deeplearning/comments/9y4hw8/how_do_you_unit_test_your_code/,TheCriticalSkeptic,1542530107,"I was building a model recently in Tensorflow. The model took days of GPU training.

When it was done I wanted to do some visualisations on the embeddings. When I started going through it I noticed some unusual results. It turns out that some of my embeddings were not being trained. I had to change my code and re-run the training.

It got me thinking about how I might have avoided this bug in the first place. 

How do you test your code? Do you test your models differently to your batch loafers? What about in RL, how do you test your environments?",2,1
142,2018-11-18,2018,11,18,19,9y55cp,Survey about self-driving cars for a Master's thesis,https://www.reddit.com/r/deeplearning/comments/9y55cp/survey_about_selfdriving_cars_for_a_masters_thesis/,wtf_rainbows,1542538653,"Hi all

I apologize if this type of post is against the rules. Please remove it if it is.

I  am a CS student at NTNU in Norway, currently working on my Master's  thesis. My partner and I are exploring a new way of gathering and  assembling data for the training of self-driving cars, and have  developed a short survey to confirm some of our hypotheses. We would  greatly appreciate it if some of you spent 5 minutes to complete the  survey!

The survey is intentionally pretty high-level, as it is being shared with people from all backgrounds.

Here is the link: [https://goo.gl/forms/tgS86cGB9pCtFBLg2](https://goo.gl/forms/tgS86cGB9pCtFBLg2)

Thanks!",2,1
143,2018-11-19,2018,11,19,1,9y737l,"For me, one of the main barriers to the world of deep learning was setting up all the tools. Here's a video that I hope will eliminate this barrier. Hope you guys found it helpful!",https://www.reddit.com/r/deeplearning/comments/9y737l/for_me_one_of_the_main_barriers_to_the_world_of/,antaloaalonso,1542557080,,0,2
144,2018-11-19,2018,11,19,5,9y9fiu,Fingerspelling with AI,https://www.reddit.com/r/deeplearning/comments/9y9fiu/fingerspelling_with_ai/,weeklyWebWisdom,1542572747,,0,1
145,2018-11-19,2018,11,19,6,9ya4p8,"Don't code your UI, draw it !",https://www.reddit.com/r/deeplearning/comments/9ya4p8/dont_code_your_ui_draw_it/,karanchahal1996,1542577416,,5,1
146,2018-11-19,2018,11,19,7,9yaam0,IWTL Language Identification Of Audio On The Fly (Sequence Models),https://www.reddit.com/r/deeplearning/comments/9yaam0/iwtl_language_identification_of_audio_on_the_fly/,41br05,1542578561,"I would like to create a LID system that predicts a language on the fly, unlike CNNs that take spectograms of a predefined number of seconds.

Basically, I'd like to create a model that predicts the language of an audio file of any length. Ultimately, my goal is to have an app that I can talk to which would output the language in (more or less) real time

I have read about sequence models such as RNNs, but the materials often talk about their application in textual NLP, so I can't say that I have really grasped them. 

I have already acquired the data, it's a dataset of four languages that contains .wav files of different lengths ranging from a minute to about an hour. 

I'd appreciate any help, be it useful resources, your own explanations, discussions or advice. Thanks!",0,1
147,2018-11-19,2018,11,19,9,9ybccf,"The ""Strange Loop"" in Deep Learning",https://www.reddit.com/r/deeplearning/comments/9ybccf/the_strange_loop_in_deep_learning/,Tivra,1542586057,,0,1
148,2018-11-19,2018,11,19,12,9yd19q,Im looking for the implementation of Professor Forcing by Pytorch,https://www.reddit.com/r/deeplearning/comments/9yd19q/im_looking_for_the_implementation_of_professor/,KorChris,1542598867,"Hi reddit! 

Im looking for the implementation of professor forcing by pytorch to do some experiments with pytorch on PTB and wiki data. 

I tried to find this but still cant find it.

If you have one, or know where it is, could you give me a hand to deal with it?

Thank you

",1,1
149,2018-11-19,2018,11,19,15,9yectm,4 FAQs on Deep Learning,https://www.reddit.com/r/deeplearning/comments/9yectm/4_faqs_on_deep_learning/,dexlabanalytics,1542610092,,0,1
150,2018-11-19,2018,11,19,16,9yemjm,Image segementation using Encoder-Decoder technique,https://www.reddit.com/r/deeplearning/comments/9yemjm/image_segementation_using_encoderdecoder_technique/,martian_rover,1542612709," Hey guys,

I am working on a project for classification which requires 'image segmentation' using an 'encoder-decoder' technique (at least I found this best).

I am a beginner with this technique and it would be great if someone could share any tutorial or guide for building my model. I thinking of building this with Keras or Pytorch ( pls exclude Tensorflow).

Will I need to label my image dataset for this?

My image contains different phases of Metal alloys (Image for reference)

Any type of tutorial will be helpful.

&amp;#x200B;

[Metal-alloy microstructure image](https://i.redd.it/0o1ec8l0o8z11.jpg)",3,1
151,2018-11-19,2018,11,19,21,9ygg0y,Building a prediction model,https://www.reddit.com/r/deeplearning/comments/9ygg0y/building_a_prediction_model/,suraty,1542631553,"Hello,

In a dataset, the data are the average of vehicles speed in the points (cells) of a map. I am trying to build a prediction model. 

While the inputs are the average of vehicles speed of all points in recent 40 min and the outputs are the next 10 min of all points.

If there were 320 points on the map, the input shape = (320,20) and the output shape =(320,5). The averages of vehicles speed are collected each 2 min in all points.

There are several such samples (n samples, x=(n,320,20), y=(n,320,5)).

I thought that it is a time series problem. So, after the transposing the input and output, I used the LSTM network.

    model = Sequential()
    model.add(LSTM(400, input_shape=(20,320),activation='relu', return_sequences=True))
    model.add(LSTM(400, return_sequences=True))
    model.add(LSTM(400, return_sequences=True))
    model.add(MaxPooling1D((2)))
    model.add(MaxPooling1D((2)))
    model.add(Dense(320))
    model.summary()


    _________________________________________________________________
     Layer (type)                 Output Shape              Param #   
    =================================================================
    lstm_19 (LSTM)               (None, 20, 400)           1153600   
    _________________________________________________________________
    lstm_20 (LSTM)               (None, 20, 400)           1281600   
    _________________________________________________________________
    lstm_21 (LSTM)               (None, 20, 400)           1281600   
    _________________________________________________________________
    max_pooling1d_6 (MaxPooling1 (None, 10, 400)           0         
    _________________________________________________________________
    max_pooling1d_7 (MaxPooling1 (None, 5, 400)            0         
    _________________________________________________________________
    dense_4 (Dense)              (None, 5, 320)            128320    
    =================================================================


Is it a correct solution? Is there any offer to improve it?

Thank you",0,1
152,2018-11-19,2018,11,19,22,9ygyri,Why dont people tend to use 16 bit floating points over 32 bits for DL?,https://www.reddit.com/r/deeplearning/comments/9ygyri/why_dont_people_tend_to_use_16_bit_floating/,S_T47,1542635861,"I was just reading an Nvidia article that explains why 16 bit floating point numbers are actually enough to represent the weights. Hence providing a significant speed up in training (less strain on memory) 
So why arent developers utilising this more? Or am I missing something
",6,1
153,2018-11-19,2018,11,19,23,9yh13m,Where should i start for learning artificial intelligence?,https://www.reddit.com/r/deeplearning/comments/9yh13m/where_should_i_start_for_learning_artificial/,Hardik-shah,1542636315,,1,1
154,2018-11-20,2018,11,20,0,9yhvu0,Sudoku Solver: Image Processing and Deep Learning,https://www.reddit.com/r/deeplearning/comments/9yhvu0/sudoku_solver_image_processing_and_deep_learning/,Buntworthy,1542642375,,0,1
155,2018-11-20,2018,11,20,1,9yi8e4,Free servers with 1080Ti for deep learning,https://www.reddit.com/r/deeplearning/comments/9yi8e4/free_servers_with_1080ti_for_deep_learning/,whitezl0,1542644650,"Hi, I am offering free credits for you to access 1080Ti GPU instances for deep learning purposes.

I am a co-founder of Tensorpad; where we are creating a service for AI startups to train neural networks. We have paid traffic, but some servers are idle. Hence, we are offering some credits for free, so that students, startups, and others can benefit from ML technologies and help us by using our product and providing honest feedback for us to improve.

You can Sign Up at https://dashboard.tensorpad.com/signup and redeem the code ""REDDIT650"" in the Billing tab.

Hope this explains our story and motivation for providing free credits.

Here is additional information: 
* The instances have 16GB RAM, 4 CPUs cores and one 1080Ti GPU. You can run multiple instances in parallel 
* You get access to the JupyterLab environment 
* We have pre-installed Tensorflow, Keras, and other ML frameworks 
* You can access the terminal through the JupyterLab 
* By default, persistent storage is enabled 
* Here are the available software versions https://docs.tensorpad.com/jobs_env/ For extra free trial hours, use promo code: REDDIT650

And for questions, please contact me at ilie@tensorpad.com. I am looking forward to seeing you on our platform! 

Sincerely, 
Ilie Diacov",0,1
156,2018-11-20,2018,11,20,2,9yis98,Sony Breaks ResNet-50 Training Record on ImageNet,https://www.reddit.com/r/deeplearning/comments/9yis98/sony_breaks_resnet50_training_record_on_imagenet/,gwen0927,1542648122,,1,1
157,2018-11-20,2018,11,20,6,9yl9gr,Deep learning project in neurology fields? (beginner),https://www.reddit.com/r/deeplearning/comments/9yl9gr/deep_learning_project_in_neurology_fields_beginner/,OverLordGoldDragon,1542663448,"I seek to work on a deep learning AI project in the field of neurology, with required knowledge not notably greater than that offered in [Andrew Ng's courses](https://www.coursera.org/instructor/andrewng). An [existing project](https://www.sciencedirect.com/science/article/pii/S0149763416305176?via%3Dihub) applies deep learning (DL) to investigate disorder neurological correlates, and is appealing to pursue - but requires DL expertise.

What are some of the subfields in neurology - problems to be solved, methods to be improved, etc. - about which a DL project can be based without requiring DL expertise? Ongoing or completed projects, or ideas for new projects, are all of interest.",0,1
158,2018-11-20,2018,11,20,14,9yp9yt,looking for a study partner,https://www.reddit.com/r/deeplearning/comments/9yp9yt/looking_for_a_study_partner/,niki_niki123,1542692975," Is there anybody who is interested in implementing yolov3? I want to make a study group.  All skill levels are welcome. I  want to start this group to meet other deep learning enthusiasts. Looking forward to exploring the YOLOV3 with everybody.

 ",53,1
159,2018-11-21,2018,11,21,2,9yuenb,Name Flip-Flop: NIPS Is Now NeurIPS,https://www.reddit.com/r/deeplearning/comments/9yuenb/name_flipflop_nips_is_now_neurips/,trcytony,1542735911,,8,1
160,2018-11-21,2018,11,21,3,9yulp2,"If you want to break into AI, these Deep Learning Courses will help you do so",https://www.reddit.com/r/deeplearning/comments/9yulp2/if_you_want_to_break_into_ai_these_deep_learning/,skj8,1542737113,,5,1
161,2018-11-21,2018,11,21,5,9yvwrz,Shanghai Tests Graph Recurrent Neural Networks for Traffic Prediction,https://www.reddit.com/r/deeplearning/comments/9yvwrz/shanghai_tests_graph_recurrent_neural_networks/,gwen0927,1542745223,,1,1
162,2018-11-21,2018,11,21,14,9z0340,An Analysis of Google's Patent Policies on Open Source AI Software (1),https://www.reddit.com/r/deeplearning/comments/9z0340/an_analysis_of_googles_patent_policies_on_open/,PIIP_LAW,1542776411,,1,1
163,2018-11-21,2018,11,21,21,9z2xyz,Pytorch implementation of StNet: Local and Global Spatial-Temporal Modeling for Action Recognition,https://www.reddit.com/r/deeplearning/comments/9z2xyz/pytorch_implementation_of_stnet_local_and_global/,Damien_Menigaux,1542804645,"Hi. I loved the StNet paper that was recently released and I went ahead and designed the exposed architecture. Please tell me about any thing I might have overlooked.

&amp;#x200B;

&amp;#x200B;

[https://arxiv.org/pdf/1811.01549.pdf](https://arxiv.org/pdf/1811.01549.pdf)

&amp;#x200B;

[https://github.com/hyperfraise/StNet](https://github.com/hyperfraise/StNet)",0,1
164,2018-11-21,2018,11,21,23,9z3gl3,Finding it difficult to understand what dilated convolutions are useful for?,https://www.reddit.com/r/deeplearning/comments/9z3gl3/finding_it_difficult_to_understand_what_dilated/,S_T47,1542808961,"I understand what dilated convolutions are, and have seen examples of them being used for semantic segmentation, however I'm finding it difficult to understand why it's any better then regular convolutions (which also achieve good segmentation results). Additionally, what are the possible use cases other than segmentation?

&amp;#x200B;",5,1
165,2018-11-22,2018,11,22,0,9z4clz,Google Brain &amp; Geoffrey Hinton Technique Thwarts Adversarial Attacks,https://www.reddit.com/r/deeplearning/comments/9z4clz/google_brain_geoffrey_hinton_technique_thwarts/,gwen0927,1542815422,,11,1
166,2018-11-22,2018,11,22,2,9z50qi,Confused about YOLO loss function,https://www.reddit.com/r/deeplearning/comments/9z50qi/confused_about_yolo_loss_function/,OtherSideOfTheDark,1542819761,"I am trying to implement YOLO with keras. In their paper, they say they are using linear activation for the last layer. In the loss function some of the predictions(width-height) are in square-root. Isn't linear activation gives negative values too? I think it will make loss function to go lower, right?

&amp;#x200B;

You can see loss function here: [https://medium.com/adventures-with-deep-learning/yolo-v1-part3-78f22bd97de4](https://medium.com/adventures-with-deep-learning/yolo-v1-part3-78f22bd97de4)",6,1
167,2018-11-22,2018,11,22,4,9z6njp,How to implement Faster RCNN in tensorflow or any other platform? (not with the help of tf object detection API),https://www.reddit.com/r/deeplearning/comments/9z6njp/how_to_implement_faster_rcnn_in_tensorflow_or_any/,will_xdxd,1542829955,"Hi, recently wanna try to implement Faster RCNN, I mean finish coding of RPN, ROI these parts and training by myself. 

Checked the original paper and some blogs online but still confused about where to start. 

Is checking official code and try to write some the only way to do it? ",0,1
168,2018-11-22,2018,11,22,6,9z7rfv,UNet segments everything as the same region,https://www.reddit.com/r/deeplearning/comments/9z7rfv/unet_segments_everything_as_the_same_region/,isthisathrowawaay,1542837152,"In the end, I get a solid black image. I've got a comparable sample size as the one used in the original paper (40 to their 30).  The only real difference I see is that I use elu vs relu.

I'm going to increase number of epochs and try again, but I doubt this would change anything.

Any advice on how to fix this problem?",1,1
169,2018-11-22,2018,11,22,8,9z8m0b,Deep learning for transactional data,https://www.reddit.com/r/deeplearning/comments/9z8m0b/deep_learning_for_transactional_data/,ProjectPsygma,1542843229,"Hi r/MachineLearning,

I recently started a new project to investigate the business use cases and commercial viability of neural networks on structured and semi-structured data. The scope is exploring how deep learning can be applied to raw bank transactions.

The two hypothesis which I would like to validate are based around automating feature engineering:

* Unsupervised learning algorithms like word2vec and autoencoding can be used to generate embedding vectors representing customer attributes/features. These vectors capture latent information in a lower dimensional space which can then be used for modelling

* RNNs/LSTMs can be used on raw transactions (sequential data) to train predictive models that are as good as GBMs, but significantly faster to build because features don't need to be handcrafted and no domain specific knowledge is needed

Are there any other areas that you would recommend for me to look into for my investigation into how neural networks can be applied to raw bank transaction data?

Cheers,

PS",0,1
170,2018-11-22,2018,11,22,11,9z9pt2,"Are you interested in Deep Learning and want to start learning more with Free Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/9z9pt2/are_you_interested_in_deep_learning_and_want_to/,DiscoverAI,1542852133,,0,1
171,2018-11-22,2018,11,22,12,9zahsl,Introduction of Deep Learning.,https://www.reddit.com/r/deeplearning/comments/9zahsl/introduction_of_deep_learning/,BlockDelta,1542858523,,0,1
172,2018-11-22,2018,11,22,20,9zdf15,3D Morphable Models as Spatial Transformer Networks #weeklypaper42,https://www.reddit.com/r/deeplearning/comments/9zdf15/3d_morphable_models_as_spatial_transformer/,BrighterAI,1542886843,"Hi all, we are a bunch of Deep Learning and Machine Learning scientists working together in a startup using AI. We share and discuss papers every week and we thought to share it with the world.

&amp;#x200B;

The authors of our weekly paper propose a method to produce texture maps for 3D morphable models of the face from images of faces in the wild. They introduce an extension of the spatial transformer network block. The new block interprets and normalizes 3D poses and self-occlusion. The rotation, translation, face model parameters in this block are learned unsupervised while training for simple geometric objectives.  
As an example, we show the texture maps produced by the network when images of Elon Musk are fed into it.

[https://medium.com/generate-vision/the-paperoftheweek-42-was-3d-morphable-models-as-spatial-transformer-networks-dbbf3c670289](https://medium.com/generate-vision/the-paperoftheweek-42-was-3d-morphable-models-as-spatial-transformer-networks-dbbf3c670289) 

&amp;#x200B;",1,1
173,2018-11-22,2018,11,22,22,9ze4cy,Tensorflow CNN + Mapbox 3D == Real Life SimCity,https://www.reddit.com/r/deeplearning/comments/9ze4cy/tensorflow_cnn_mapbox_3d_real_life_simcity/,00hello,1542893510,"[https://www.grassland.network/](https://www.grassland.network/)  I've been building some P2P software to provide a (politically) stateless and indelible public record of human activities in live, 3D simulated cities. I made a proof-of-work that cryptographically hashes certain hidden activations of feed-forward neural networks to prove whether computational resources were expended on the model to process camera frames correctly (see diagram). The last inference output from every node is hashed into a [Merkle Tree](https://brilliant.org/wiki/merkle-tree/) at certain intervals by the network for data ""compression"", indelibility and consistency across the network. Current computational requirements are low as the network's model only detects and ""tracks"" people and cars now but that will increase over time. 

The network's designed to be a form of [inverse surveillance or undersight](https://en.wikipedia.org/wiki/Sousveillance).

It's version 0.1 so there is ""Some Assembly Required"", but I'm constantly updating it. It's open source, so feel free to provide fixes or updates if you want.",14,1
174,2018-11-23,2018,11,23,0,9zev7w,"AiFiddle | Web GUI to Design, Train &amp; Share deep neural networks",https://www.reddit.com/r/deeplearning/comments/9zev7w/aifiddle_web_gui_to_design_train_share_deep/,0mbre,1542899517,"Hi guys,

Last month, I've released a quick preview of [Aifiddle.io](https://Aifiddle.io) a tool that I had been working on to enable easy prototyping and sharing of deep neural network in the browser. Since then I have added some polish and quite a few feature (Save to cloud, layer edit, sharing by URL and more)

I would love to hear what you guys think about this.   


I've set up a Trello board for feedback there: [https://trello.com/b/vEF1GDyR/aifiddlei](https://trello.com/b/vEF1GDyR/aifiddlei)

Video Into here: [https://www.youtube.com/watch?v=PzBHemMOIZY](https://www.youtube.com/watch?v=PzBHemMOIZY&amp;feature=youtu.be)

&amp;#x200B;

Thanks a lot for checking this out.

Emmanuel

&amp;#x200B;",1,1
175,2018-11-23,2018,11,23,0,9zexhi,DeepMind Revolution - Part I.,https://www.reddit.com/r/deeplearning/comments/9zexhi/deepmind_revolution_part_i/,BlockDelta,1542899975,,0,1
176,2018-11-23,2018,11,23,0,9zeynh,Forecasting conference,https://www.reddit.com/r/deeplearning/comments/9zeynh/forecasting_conference/,AnastasiaSka,1542900213," 

Hello!

I would like to invite you to *M4 Conference: Advances in Forecasting - Machine Learning and Statistical Methods*

*and a Novel Hybrid Approach*. Website: [http://www.mcompetitions.unic.ac.cy/](http://www.mcompetitions.unic.ac.cy/)

 This will be an amazing 2-day mini-conference, co-hosted by UNIC (University of Nicosia) and NYU, on Dec 10th and Dec 11th at the Tribeca Rooftop.

The conference is headlined by NassimNicholas Taleb, who needs no introduction, and Spyros Makridakis, a  distinguished University of Nicosia faculty member, one of the top  statisticians in the world, who invented data forecasting competitions  and a lot of other speakers from Google, Uber, SAS, etc.

At this conference, we will be presenting the  results of M4 (the largest Makridakis forecasting competition by far) as  well as covering related topics.

We would love to see you there and also any suggestions about participants and sponsors/media partners.",2,1
177,2018-11-23,2018,11,23,4,9zh2xn,"Are you interested in Deep Learning and want to start learning more with Free Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/9zh2xn/are_you_interested_in_deep_learning_and_want_to/,DiscoverAI,1542914780,,0,1
178,2018-11-23,2018,11,23,5,9zheod,anyone would like to discuss or explain ICaRl 2016 paper! https://arxiv.org/abs/1611.07725,https://www.reddit.com/r/deeplearning/comments/9zheod/anyone_would_like_to_discuss_or_explain_icarl/,nile6499,1542917074,"Hi, I urgently need to understand ICaRl paper for my thesis work, so anyone of you could help.. Thanks",0,1
179,2018-11-23,2018,11,23,21,9znwve,"AlexNet Matlab beginner, need help^^",https://www.reddit.com/r/deeplearning/comments/9znwve/alexnet_matlab_beginner_need_help/,tdbeaar,1542976420,"So i'm new to all this, and i'm trying to train a AlexNet using some given image set. I want to utilize these images to their fullest as I'm not allowed to use other images for this training.   


So what i was thinking initially is to transform the images in the code where I also resize the images to fit the input for AlexNet.

&amp;#x200B;

This is what i have so far:

function I = readFunctionTrain(filename)

% Resize the input image named ""filename"" such that the output

% image (I) has a dimension of 227x227x3

&amp;#x200B;

I = imread(filename);

&amp;#x200B;

I = imresize(I, \[227 227\]); %Simple resize function for resizing to 277x277

&amp;#x200B;

If = flipdim(I,2); %flips image to the right

Ik = imrotate(I,35,'bilinear','crop'); %rotates image 35 degree

It = imtranslate(I,\[15, 25\]); %translates image by 15 and 25 pixels in X and Y direction

Ih = histeq(I); %normalizez histogram

&amp;#x200B;

end

&amp;#x200B;

And i was wondering if anyone knew how i could make it so that in addition to the original images, i could add flipping, histogram normalization, tilting and so on, so that the training would benefit more from each image.

&amp;#x200B;

Thank you in advance.

&amp;#x200B;

&amp;#x200B;",2,1
180,2018-11-24,2018,11,24,1,9zpgf8,DeepBrain Chain opens up free trials for AI cloud computing network.,https://www.reddit.com/r/deeplearning/comments/9zpgf8/deepbrain_chain_opens_up_free_trials_for_ai_cloud/,DeepBrainChain,1542989104,[removed],0,1
181,2018-11-24,2018,11,24,1,9zptn5,DeepBrain Chain opens up trial for AI cloud computing network.,https://www.reddit.com/r/deeplearning/comments/9zptn5/deepbrain_chain_opens_up_trial_for_ai_cloud/,DeepBrainChain,1542991703,"DeepBrain Chain has opened up our distributed AI Cloud training net to trial users for free over the next month.

We have 1, 2, 4 and 8GPU servers available for use.

You need to follow these steps to get free access:

1. Register on our website
2. Head to the AI training net portal on your personal account page
3. Click  AI training net from the side tab and install the DBC client -  set  your machine ID (click the little blue ? to find your machine ID)
4. You automatically receive 500 DBC (around 10 training hours on our 2GPU servers)

Github  guides/user manuals and resources are available through the  training  net/github portal from the training net page on DBC website.",3,1
182,2018-11-24,2018,11,24,4,9zrews,Scalable DL Interview Question,https://www.reddit.com/r/deeplearning/comments/9zrews/scalable_dl_interview_question/,DuckDuckFooGoo,1543002540,"Just got a interview question that involves scalable DL models, but I only know of scalable use of GPUs/CPUs, is there such a thing as scalable DL models?",2,1
183,2018-11-24,2018,11,24,5,9zrnxa,Display output of vgg19 layer as image,https://www.reddit.com/r/deeplearning/comments/9zrnxa/display_output_of_vgg19_layer_as_image/,noobmaster007,1543004273,"I was reading this paper: [Neural Style Transfer](https://arxiv.org/pdf/1508.06576.pdf). In this paper author reconstructs image from output of layers of vgg19. I am using Keras. The size of output of block1_conv1 layer is (1, 400, 533, 64). Here 1 is number of images as input, 400 is number of rows, 533 number of columns and 64 number of channels. When I try to reconstruct it as an image, I get an error as size of image is 13644800 which is not a multiple of 3, so I can't display the image in three channels. How can I reconstruct this image?

I want to reconstruct images from layers as shown: [Image reconstruction from cnn layer output](https://imgur.com/a/yPzVZIR) 

Here is my code: [Code](https://pastebin.com/rYwXF7za)

I am trying following error on trying to reshape the array: 
    ValueError: cannot reshape array of size 13644800 into shape (400,newaxis,3)",0,1
184,2018-11-24,2018,11,24,6,9zsfrs,Advanced Deep Learning &amp; Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/9zsfrs/advanced_deep_learning_reinforcement_learning/,keghn,1543009708,,0,1
185,2018-11-24,2018,11,24,7,9zsn7y,Specific semi-supervised task,https://www.reddit.com/r/deeplearning/comments/9zsn7y/specific_semisupervised_task/,Oktai15,1543011178,"We have D = {(x\_i, y\_i)}  labeled dataset, y\_i from  where C is set of considered classes. For example, dataset of images exotic fishes. Suppose we collected small amount of these fishes. However, we also have extra\_D = {(x\_i)} representing a huge dataset unmarked fishes that don't belong to , because it's dataset of usual fishes, not exotic.

Question: how can we get benefit of extra\_D? If it is possible, please, send me a concrete papers or describe ideas :)",0,1
186,2018-11-24,2018,11,24,8,9ztdbi,"Are you interested in Deep Learning and want to start learning more with Free Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/deeplearning/comments/9ztdbi/are_you_interested_in_deep_learning_and_want_to/,DiscoverAI,1543016560,,0,1
187,2018-11-24,2018,11,24,21,9zy7e2,Pacman Deep Q learning,https://www.reddit.com/r/deeplearning/comments/9zy7e2/pacman_deep_q_learning/,FenryrMKIII,1543063625,"Hello,

I am starting (few months) studying about AI and now I am at the point where I am studying about reinforcement learning.

I am using Berkeley pacman framework to do that. At this point, I achieved coding an approximate Q learning agent using homemade features.

Now, I would like to continue my work toward ultimately coding a deep Q learning with CNN and so on. But it seems the gap is still huge between where I am now and a full DQN.

I would have liked to take baby steps and see for myself what the problems are step by step (e.g. Divergence,...) before jumping right into a complete solution that works but where I would not have understood the steps to get there.

So now, given that I have an approximate Q learning agent with home made features that works, I would have thought the next step would be coding an approximate agent that approximates the Q values with a fully connected network (no CNN) where the features (the inputs) are the pixels (so in Berkeley implementation, the information given by the state variable) and the outputs are the Q values for each action.

Do you think my way of seeing things is correct? Because I searched through the internet and I never saw a tutorial about that. I only find tutos about complete DQN with CNN, experience replay,...

Thanks for your time and support ",5,1
188,2018-11-24,2018,11,24,22,9zycrm,Is my pytorch cnn implementation for mnist correct or not?,https://www.reddit.com/r/deeplearning/comments/9zycrm/is_my_pytorch_cnn_implementation_for_mnist/,begooboi,1543065142,"I wrote a cnn model to classify mnist data  in pytorch for learning purpose. Can anyone  tell me whether my implementation of code is correct or not?

    import numpy as np
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.autograd import Variable
    from sklearn.datasets import load_iris
    from keras.datasets import mnist
    from keras.utils import to_categorical

    batch_size=10


    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    
    x_data=np.float32(x_train)
    x_data=x_data.reshape(x_data.shape[0],1,x_data.shape[1],x_data.shape[2])
    y_data=np.int64(y_train)
    #y_data = to_categorical(y_data)
    x_data = Variable(torch.from_numpy(x_data))
    y_data = Variable(torch.from_numpy(y_data))

    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
            self.mp = nn.MaxPool2d(2)
            self.fc = nn.Linear(320, 10)
        def forward(self, x):
            in_size = x.size(0)
            x = F.relu(self.mp(self.conv1(x)))
            x = F.relu(self.mp(self.conv2(x)))
            x = x.view(in_size, -1)  # flatten the tensor
            x = self.fc(x)
            return F.log_softmax(x)

    model =Model()
    print(model)
    loss_fun=nn.CrossEntropyLoss()
    opt= torch.optim.SGD(model.parameters(),lr=0.01)

    permutation = torch.randperm(x_data.size()[0])

    for epoch in range(100):
        print ""Epoch: ""+str(epoch)
        for i in range(0,x_data.size()[0],batch_size):
            print ""batch: ""+str(i)
            indices = permutation[i:i+batch_size]
            batch_x, batch_y = x_data[indices], y_data[indices]
            y_pred_val=model(batch_x)
            loss=loss_fun(y_pred_val,batch_y)
            print(epoch, loss.data[0])
            
            opt.zero_grad()
            loss.backward()
            opt.step()
        break
",5,1
189,2018-11-25,2018,11,25,8,a03k6c,https://medium.com/@merajulislam/804777073e43,https://www.reddit.com/r/deeplearning/comments/a03k6c/httpsmediumcommerajulislam804777073e43/,kiarash-irandoust,1543103216,,1,1
190,2018-11-25,2018,11,25,9,a03o1w,Up and running with Keras: Deep Learning Digit Classification using CNN,https://www.reddit.com/r/deeplearning/comments/a03o1w/up_and_running_with_keras_deep_learning_digit/,kiarash-irandoust,1543104029,,0,1
191,2018-11-25,2018,11,25,18,a078iu,Progressive growing / Interpolation with own images?,https://www.reddit.com/r/deeplearning/comments/a078iu/progressive_growing_interpolation_with_own_images/,vinnivinnivinni,1543137991,"Hi, I saw this image interpolation https://twitter.com/aphextwin/status/1065621470099984385 and would like to play around with it by using own images. 

I just couldnt find out how it is done. I looked at nvidias progressive growing of gans, but if I understand that correctly you cant interpolate between two images, it rather generates all. 

(I have a 1070)

Thanks!",0,1
192,2018-11-25,2018,11,25,19,a07lwv,My implementation of QuickDraw - an online gamed developed by Google,https://www.reddit.com/r/deeplearning/comments/a07lwv/my_implementation_of_quickdraw_an_online_gamed/,1991viet,1543142620,,4,1
193,2018-11-25,2018,11,25,23,a08yfo,"For me, one of the main barriers to the world of deep learning was setting up all the tools. Here's a video that I hope will eliminate this barrier. Hope you guys found it helpful!",https://www.reddit.com/r/deeplearning/comments/a08yfo/for_me_one_of_the_main_barriers_to_the_world_of/,antaloaalonso,1543156785,,0,1
194,2018-11-26,2018,11,26,3,a0b10a,"For anyone looking to get into deep learning, I would advise that you consider not learning the behemoth libraries like Tensorflow or Theano, but instead learn how to use a high-level API like Keras. Here's a quick video to explain what it is. Hope I was helpful!",https://www.reddit.com/r/deeplearning/comments/a0b10a/for_anyone_looking_to_get_into_deep_learning_i/,antaloaalonso,1543171283,,0,1
195,2018-11-26,2018,11,26,7,a0cy47,"Autonomous driving ""IronCar"" championship winner !!",https://www.reddit.com/r/deeplearning/comments/a0cy47/autonomous_driving_ironcar_championship_winner/,Klhnikov,1543183632,,3,1
196,2018-11-26,2018,11,26,10,a0eg77,"When will a ""vanilla"" CNN suffice? (r/computervision x-post)",https://www.reddit.com/r/deeplearning/comments/a0eg77/when_will_a_vanilla_cnn_suffice_rcomputervision/,EighteenthVariable,1543194246,"With all these new and interesting architectures coming out (seemingly) every other day like RCNN and YOLO Vx, I was wondering, when will a regular, relatively shallow cnn suffice to get the job done (supposing that extremely high accuracy isn't required)? 

Sorry for the extremely broad question.",1,1
197,2018-11-26,2018,11,26,14,a0gi4a,AWS instance selection for Fully Convolutional Neural Network,https://www.reddit.com/r/deeplearning/comments/a0gi4a/aws_instance_selection_for_fully_convolutional/,naga_di,1543210353,"I am working on a semantic segmentation project.

&amp;#x200B;

Input images are in GeoTiff format. 

Input dimension: 20000 by 20000 pixels, each image size is \~ 1 GB, with mean resolution of 1cm/pixel

each pixel is 5 dimensional (x, y, r, g, b)

&amp;#x200B;

Total number of images: 10

&amp;#x200B;

I would like to know:

 \- which GPU instance should I choose?

 \- how long will it take to train this huge data?

 \- Do you have any network recommendations for me? (if you have used FCN, 8-bit -32-bit?)",8,1
198,2018-11-26,2018,11,26,14,a0gj2o,Is there a noticeable performance improvement using brand name overclocked gpus ?,https://www.reddit.com/r/deeplearning/comments/a0gj2o/is_there_a_noticeable_performance_improvement/,gagnwoooooo,1543210570,For example Im looking at a asus rog strix ,0,1
199,2018-11-26,2018,11,26,19,a0iclk,Why is my loss coming down very slowly?,https://www.reddit.com/r/deeplearning/comments/a0iclk/why_is_my_loss_coming_down_very_slowly/,snapitreditt,1543229783," 

Hi,

I am training a Siamese network using a variant of AlexNet (I added some inception like features like Depth concatenation instead of having a plain coarse 11x11 conv layer to boot)

Hardware: K80 GPU on Amazon AWS

Agenda is to do face identification.

Dataset: Facescrub dataset duly requested and collected from the original Authors. Using only 1/2 of the dataset due to space constraint.

Augmentation: Eye detection and Face alignment, Zoom in, Zoom out, Gaussian Noise, Rotation clock and anti-clock and random combination of these

Training always starts with 50% of the samples coming from aug set(at least one of the images of the siamese triplet was from aug set)

L2 Loss is also added (L2 Loss starts with 15% of the total loss at start of training)

My layer arch looks like this:  
*NOTE: (conv layer ==&gt; relu, maxpool 3x3 and strided by 2x2 )*  
c1a - (3x3) conv layer on grayscale input  
LRN - (Local response normalization)  
c1b - (5x5) conv layer on grayscale input  
LRN - (Local response normalization)  
c1 - Depth concat of c1a and c1b  
c2 - 5x5 conv layer on c1  
c3 - 3x3 conv on c2 but no maxpool  
c4 - 3x3 conv on c3 but no maxpool  
c5 - 3x3 conv layer on c4  
Flatten C5  
Dropout at 50%  
Dense Layer with Sigmoid  
Drop out at 50%  
Dense Layer with Sigmoid to produce Facial Embedding

My problem is that even after 16,000 batches, the loss has come down only from 3.5 to 1.3. It has been running for more than 24 hours now.

**Should I continue this training or abort it?**

If you look at the Gradients below, the layers C1A, C1B and the likes have the best gradients (max of all gradients in the layer as well as mean values)  
And the layers closer to the output have lesser gradients  
It sounds counter-intuitive to me.

I thought the ones closer to the output will have the best gradients and the ones further down will worsen But what I observe is counter-intuitive. What do you guys think?

I use Adam Optimizer. The gradients below are calculated using the computeGradients API call.

&gt;GRADIENTLOSS at iteration 16000  
GRADIENTs for VECTOR/c1aFilter:0  
Mean: 0.010530296,Std: 0.08831231,Median: 0.0037496341,Max: 0.34390756,Min: -0.20923898  
GRADIENTs for VECTOR/b1a:0  
Mean: 0.014000396,Std: 0.1359879,Median: 0.023553304,Max: 0.36028913,Min: -0.29602805  
GRADIENTs for VECTOR/c1bFilter:0  
Mean: 0.003996292,Std: 0.060440883,Median: -0.0041986424,Max: 0.22272776,Min: -0.14110538  
GRADIENTs for VECTOR/b1b:0  
Mean: 0.017228054,Std: 0.1255607,Median: 0.0052211885,Max: 0.3601057,Min: -0.23093922  
GRADIENTs for VECTOR/c1cFilter:0  
Mean: -0.030846026,Std: 0.13179947,Median: -0.0036058915,Max: 0.9246183,Min: -1.4013114  
GRADIENTs for VECTOR/b1c:0  
Mean: -0.19204378,Std: 0.4582537,Median: -0.20062844,Max: 1.1991782,Min: -1.1817778  
GRADIENTs for VECTOR/c2Filter:0  
Mean: 0.00085157086,Std: 0.015450722,Median: 1.1536713e-34,Max: 0.17678176,Min: -0.107637085  
GRADIENTs for VECTOR/b2:0  
Mean: -0.00999434,Std: 0.17034349,Median: 0.01284295,Max: 0.5719912,Min: -0.5927037  
GRADIENTs for VECTOR/c3Filter:0  
Mean: -6.849167e-05,Std: 0.004842096,Median: -1.1726105e-34,Max: 0.07113129,Min: -0.09903844  
GRADIENTs for VECTOR/b3:0  
Mean: 0.00089150603,Std: 0.04053916,Median: 0.0,Max: 0.15465239,Min: -0.12784223  
GRADIENTs for VECTOR/c4Filter:0  
Mean: 3.3387943e-05,Std: 0.0011260371,Median: 5.408392e-35,Max: 0.008018609,Min: -0.0108721405  
GRADIENTs for VECTOR/b4:0  
Mean: 2.0310885e-05,Std: 0.008101722,Median: 0.0,Max: 0.0338539,Min: -0.024426486  
GRADIENTs for VECTOR/c5Filter:0  
Mean: -0.00012642296,Std: 0.0016604387,Median: -1.2935101e-34,Max: 0.012831819,Min: -0.016537711  
GRADIENTs for VECTOR/b5:0  
Mean: -0.0005427574,Std: 0.0049887337,Median: -0.00052600756,Max: 0.011803339,Min: -0.013275687  
GRADIENTs for VECTOR/dense/kernel:0  
Mean: 2.623862e-06,Std: 0.00025185716,Median: 3.61513e-35,Max: 0.0032541258,Min: -0.0039389245  
GRADIENTs for VECTOR/dense/bias:0  
Mean: 5.296417e-06,Std: 0.0002104719,Median: 6.043442e-06,Max: 0.0006891279,Min: -0.0009231151  
GRADIENTs for VECTOR/dense2/kernel:0  
Mean: -1.4274097e-05,Std: 0.0006795507,Median: -7.807914e-06,Max: 0.004824273,Min: -0.0046136547  
GRADIENTs for VECTOR/dense2/bias:0  
Mean: -4.609408e-05,Std: 0.00067597226,Median: -0.00010044244,Max: 0.0018383545,Min: -0.0024985338  
Testing Loss = 1.3011401

Best,  
MagmaMan",7,1
200,2018-11-26,2018,11,26,22,a0jk26,"DIfference between Keras dot layer, K.dot and K.batch_dot AND the use of axes parameter",https://www.reddit.com/r/deeplearning/comments/a0jk26/difference_between_keras_dot_layer_kdot_and/,ImaginaryAnon,1543240789,"I have read official documentation of all these three methods. But still I can understand what's actually different in all these.

Like we know that, batch_dot can handle tensors with batch sizes but dot layer does the same. Also, I can easily understand what happens if both the tensors are 2-D. But I can't understand what if the tensors are &gt;2-D (for ex: 3-D).

We also use axes argument, but I don't know how it affects the dot product. The documentation simply states that it takes dot product over that axes but how? I can't understand it without examples. I am trying to implement all these with random tensors for understanding but still confused.

I am still a beginner in Keras. Can anyone please help? Understanding with live examples would be simple but I don't find examples online with such understanding.
",0,1
201,2018-11-26,2018,11,26,23,a0jz2r,U-net model for semantic segmentation,https://www.reddit.com/r/deeplearning/comments/a0jz2r/unet_model_for_semantic_segmentation/,martian_rover,1543243991,"Hey guys,

I have image data as .jpg files and have label image data as .json file(different image has different .json file). Will this be enough to load this in U-net model and classify the labels in test image data? 

And how to load images with labels in another folder in U-net model? ""**Trying to do this in Keras**""

If not what should be the proper format of files?

Moreover, I am just starting to build a classification model for images on a pixel level where I need to ***classify certain shapes in images***. 

Can someone help me with that?",0,1
202,2018-11-27,2018,11,27,0,a0k6h6,Any open source models for detecting lying through speech or vision?,https://www.reddit.com/r/deeplearning/comments/a0k6h6/any_open_source_models_for_detecting_lying/,0_o---,1543245475,looking for models that can use speech or facial expressions to detect if an individual is telling the truth or lying. ,12,1
203,2018-11-27,2018,11,27,0,a0kf0w, Supervisely November release: reimagine image annotation and data science workflows.,https://www.reddit.com/r/deeplearning/comments/a0kf0w/supervisely_november_release_reimagine_image/,tdionis,1543247105,,0,1
204,2018-11-27,2018,11,27,8,a0ovu4,An Analysis of Google's Patent Policies on Open Source AI Software (2),https://www.reddit.com/r/deeplearning/comments/a0ovu4/an_analysis_of_googles_patent_policies_on_open/,PIIP_LAW,1543274952,,1,1
205,2018-11-27,2018,11,27,11,a0qia4,What is the best CPU for a deep learning and gaming build?,https://www.reddit.com/r/deeplearning/comments/a0qia4/what_is_the_best_cpu_for_a_deep_learning_and/,kitgary,1543286530,"I want to build a PC for deep learning and intensive gaming (mostly FPS). For the GPU, its an easy pick, I would choose the RTX 2080 Ti, but I dont know which CPU I should use. 

I want to get a 9900k initially but I just noticed that it has only 16 PCIE lanes, which means if I want to add additional GPU later, I can only run x8/x8 instead of x16/x16. Is it really a big performance loss to run at x8/x8?

As I want to get a new CPU, I found that the best option I have is AMD Threaddripper 2950x, Intel Core i9-7900x/7920x or wait for the new Core i9-9900x/9920x. I would prefer Intel over AMD as I heard that some frameworks are optimised forwards intel CPU.

Can anyone suggest the best CPU for both deep learning and gaming?

Thanks",2,1
206,2018-11-27,2018,11,27,12,a0r2tf,A BitTorrent inspired training framework,https://www.reddit.com/r/deeplearning/comments/a0r2tf/a_bittorrent_inspired_training_framework/,karanchahal1996,1543290677,,1,1
207,2018-11-27,2018,11,27,16,a0sku0,How can I use a human operator to correct my deep learning model predictions and help model re-train?,https://www.reddit.com/r/deeplearning/comments/a0sku0/how_can_i_use_a_human_operator_to_correct_my_deep/,bathmlaster,1543303189,"Hi there,

I'm looking to use a deep learning model like Faster CNN to classify small objects in images. I understand Faster CNN should be better for small, closely spaced objects than SSD and YOLO.

Regardless of model choice I'm trying to understand if I can use a human operator to inspect my model's validation and test results and correct my model or relabel my train/test images. 

The reason I want to do this is that I have a large series of images that I have been able to annotate with some simple computer vision algorithms. I am trying to explore feasibility of applying deep learning to this data set instead, and would ideally like to train my CNN with this image data that was already annotated by OpenCV algorithms. The algorithm has decent performance of detecting my objects but is not particularly strong in sensitivity or precision. I'm interested to see if a CNN can improve performance and extend to future cases better (different resolution, lighting, cameras, etc).

My questions  
Are there any guides for training a CNN, inspecting and correcting some results, and then retraining the model? 

Is this a worthwhile endeavor? 

I feel like this has the possibility to save a lot of hours of work, but I'm wondering whether this is a sensible approach or not.

I'm wondering if any tutorials for this exist. I imagine that I'm looking for a GUI in Python to present predictions on some images, and some ability for the human operator to give inputs about whether model was right, or whether model missed some detections.

&amp;#x200B;

Thanks in advance!",1,1
208,2018-11-27,2018,11,27,17,a0szd9,10 Amazing Examples Of How Deep Learning AI Is Used In Practice,https://www.reddit.com/r/deeplearning/comments/a0szd9/10_amazing_examples_of_how_deep_learning_ai_is/,BravelyGentle,1543307268,"Here are 10 examples of how deep learning AI is used in practice. Let me know which one do you use in which practice. 

1. Customer Experience
2. Translations
3. Adding color to black-and-white images and videos 
4.  Language recognition 
5.  Autonomous vehicles 
6.  Computer vision 
7.  Text generation 
8.  Image caption generation 
9.  News aggregator based on sentiment 
10.  Deep-learning robots 

[https://www.forbes.com/sites/bernardmarr/2018/08/20/10-amazing-examples-of-how-deep-learning-ai-is-used-in-practice/#2bccac36f98a](https://www.forbes.com/sites/bernardmarr/2018/08/20/10-amazing-examples-of-how-deep-learning-ai-is-used-in-practice/#2bccac36f98a)

&amp;#x200B;

https://i.redd.it/746wky183u021.gif",0,1
209,2018-11-27,2018,11,27,19,a0tqlv,Expanding Horizons with Deep learning,https://www.reddit.com/r/deeplearning/comments/a0tqlv/expanding_horizons_with_deep_learning/,SunilAhujaa,1543315216,"If you possess a keen interest in learning new skills, then you can choose to train yourself in Deep learning. Dont worry deep learning training in India is not a challenge anymore. With a deep learning training in India you can be part of Indias tomorrow. Read more at [https://www.contentcafe.org/expanding-horizons-with-deep-learning/](https://www.contentcafe.org/expanding-horizons-with-deep-learning/)

&amp;#x200B;",0,1
210,2018-11-27,2018,11,27,19,a0trii,License plate recognition,https://www.reddit.com/r/deeplearning/comments/a0trii/license_plate_recognition/,sohaib_01,1543315489,,0,1
211,2018-11-27,2018,11,27,20,a0u0ok,"A Facebook group meant to provide a place for people leading data science teams and groups, from anywhere in the world, to discuss common challenges together.",https://www.reddit.com/r/deeplearning/comments/a0u0ok/a_facebook_group_meant_to_provide_a_place_for/,shaypal5,1543318142,,0,1
212,2018-11-27,2018,11,27,22,a0uv65,Presenting Project Ergo: How to Build an Airplane Detector for Satellite Imagery With Deep Learning,https://www.reddit.com/r/deeplearning/comments/a0uv65/presenting_project_ergo_how_to_build_an_airplane/,evilsocket,1543325509,,0,1
213,2018-11-27,2018,11,27,22,a0v26m,Top 3 Myths About Deep Learning,https://www.reddit.com/r/deeplearning/comments/a0v26m/top_3_myths_about_deep_learning/,arunoda,1543327027,,0,1
214,2018-11-27,2018,11,27,23,a0vd96,Any one doing a PhD in deep learning?,https://www.reddit.com/r/deeplearning/comments/a0vd96/any_one_doing_a_phd_in_deep_learning/,sohaib_01,1543329238,,21,1
215,2018-11-28,2018,11,28,0,a0vmfj,[Question] Using AI for instant song mixing,https://www.reddit.com/r/deeplearning/comments/a0vmfj/question_using_ai_for_instant_song_mixing/,hogen04,1543331020,"In music, the individual tracks (guitars, drums, vocals etc.) have to be 'mixed' into a cohesive and balanced stereo track (2 channels = left and right speaker). 

Let's say you want your newly recorded song to sound like your favorite band or artist that is of a similar genre. Normally the mixing engineer (the one who does the mixing work) listens to this reference track and tries to make it sound similar to the reference track. 

**My question is:**

Do you think it would be possible to do this (almost) instantly with the use of AI? 

So, a neural network listens to the song of choice and uses that information to shape the newly recorded song in a similar way. Basically what a mixing engineer would normally do. 

I am almost sure that complete replacement of the mixing engineer is not possible, since there is a lot of nuance going on in each mixing process due to the wide variety of elements that go into a mix (types of instruments, musician skill, instrument tones, instrument qualities, recording equipment and methods, mixing equipment and methods etc.).

But how far can we go?",4,1
216,2018-11-28,2018,11,28,2,a0wrtq,FAIR &amp; NYU School of Medicine Share fastMRI Tools; Release Largest-Ever MRI Dataset,https://www.reddit.com/r/deeplearning/comments/a0wrtq/fair_nyu_school_of_medicine_share_fastmri_tools/,trcytony,1543338473,,0,1
217,2018-11-28,2018,11,28,2,a0wtsh,Did anyone try topic modelling with neural nets?,https://www.reddit.com/r/deeplearning/comments/a0wtsh/did_anyone_try_topic_modelling_with_neural_nets/,LorentzianManifold,1543338798,"Constantly seeing Latent Dirichlet Allocation (LDA) as a go to technique for topic modelling. It performs okay-ish, but ignores word context and (subjectively) seems outdated. Has anyone implemented something like an LSTM with LDA to retain sentence information? What other approaches with neural nets could be a good fit for topic modelling?",4,1
218,2018-11-28,2018,11,28,3,a0xal3,How to Build Artificial General Intelligence AGI (Late 2018) | XUCHAT,https://www.reddit.com/r/deeplearning/comments/a0xal3/how_to_build_artificial_general_intelligence_agi/,jeffxu999,1543341725,,2,1
219,2018-11-28,2018,11,28,5,a0yghn,From Biology to AI: The Perceptron,https://www.reddit.com/r/deeplearning/comments/a0yghn/from_biology_to_ai_the_perceptron/,tangoslurp,1543349135,,0,1
220,2018-11-28,2018,11,28,13,a12m9r,Questions about Backpropagation Through Time for Gated Recurrent Unit?,https://www.reddit.com/r/deeplearning/comments/a12m9r/questions_about_backpropagation_through_time_for/,qudcjf7928,1543377891,"&amp;#x200B;

https://i.redd.it/sa76hmxbxz021.png

&amp;#x200B;

 

I'm trying to implement it myself so I can understand it more. I ended up deriving the gradients myself.

So my understanding is that if t = T is the terminal time index, and suppose you have forward passed GRU,

and   using the equations and notations above, you would find the gradient  of  error wrt h\_(T), then via chain rule, you can find dL/d(z\_(T)) and   dL/d(r\_(T)) .....etc and update the weights matrices and biases.

And   if it's a multi-layered GRU, then I would also find dL/d(x\_(T)) and   that would be the ""gradient of error wrt h\_(T)"" for the previous layer's   GRU unit.

My  question is that after  you update those matrices for t = T, then you  move on to t = T-1 and do  the same thing until t = 0 right? What about  h\_(T-1) ? when I'm  calculating the gradients for the GRU unit for t = T,  do I also have to  calculate the gradient wrt h\_(T-1) ? What do I do  with them then?

Also,   for given t, and given GRU unit, and given the gradients for the   weights, how many times am I supposed to update the weights matrix? only   once and then move on to T-1? if so, wouldn't that make it impossible   to use stuff like adaptive learning rate method? which requires   information about the previous gradient?",11,1
221,2018-11-28,2018,11,28,16,a13zdd,What is your he best thing you love about deep learning community.,https://www.reddit.com/r/deeplearning/comments/a13zdd/what_is_your_he_best_thing_you_love_about_deep/,sanchit2843,1543389638,,2,1
222,2018-11-28,2018,11,28,18,a14p17,Alexa Technology: The Secrets of Amazon Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/a14p17/alexa_technology_the_secrets_of_amazon_artificial/,BlockDelta,1543397283,,0,1
223,2018-11-29,2018,11,29,9,a1c8u6,[N] Lambda is giving away three NeurIPS 2018 Tickets,https://www.reddit.com/r/deeplearning/comments/a1c8u6/n_lambda_is_giving_away_three_neurips_2018_tickets/,sabalaba,1543451805,"Hey everybody, Lambda is a Diamond sponsor this year at NeurIPS 2018 and we have three extra tickets. Knowing that NeurIPS sold out in less than 12 minutes this year, we've decided to give away three of the tickets that we've been given as a sponsor. Here's the direct link to the official blog post and the ticket application form:

[https://lambdalabs.com/blog/neurips-ticket-contest/](https://lambdalabs.com/blog/neurips-ticket-contest/)

[https://docs.google.com/forms/d/e/1FAIpQLSe50HnHeieJ0Huw71qa...](https://docs.google.com/forms/d/e/1FAIpQLSe50HnHeieJ0Huw71qago2wr86cRE5l0wvxOWnTDcoofZ_vkQ/viewform)

If you have any questions, I'm happy to answer them here.

This is the list of NeurIPS 2018 sponsor page to verify our status as a Diamond sponsor and confirm our possession of the tickets:

[https://nips.cc/Conferences/2018/Sponsors](https://nips.cc/Conferences/2018/Sponsors)",1,1
224,2018-11-29,2018,11,29,11,a1d0zs,"Help with Bias, Weights and Pooling Layer in DCNN",https://www.reddit.com/r/deeplearning/comments/a1d0zs/help_with_bias_weights_and_pooling_layer_in_dcnn/,Eganx,1543457715,"[Posted this in r/machinelearning already, but maybe its more fitting here]

Hey Guys 

I am doing a little project for university about deep learning, this includes a theoretical part. 

I am sitting here for a couple of hours (and days to be honest) trying to understand what weights, biases and the pooling layer in a DCNN are. 

So this is what I understood so far:

Weights and Bias

Weights are a binary number that are determined by a neuronal network and basically says how important the output of a neuron is for the calculation of the next neuron. So the importance of a output. 

The Bias is also a number determined by the NN and is basically a threshold that determines if the incoming output of the previous neuron is ""important/high"" enough to activate the neuron. 

The actual output of the activation function of a neuron, the weight and bias are processed by the sigmoid function and gives a value that is given to the next neuron.

The determination of weights and biases in a NN is optimized through gradient descent (or was it back propagation?). 


Pooling and Kernels 


The Kernels in a DCNN ""scan"" the whole picture small area by small area and then gives it to the Pooling Neurons. The pooling Neurons then proceed to check the scanned small areas for features that determine what kind of picture was fed to the DCNN. What I dont understand is why there are multiple pooling layers and what the pooling layers send to the Neurons in the hidden layers. 

Sorry if my understanding is laughable and my questions are dumb, but I just cant wrap my head around this. 

Every help is appreciated!

Thanks!",6,1
225,2018-11-29,2018,11,29,11,a1dadl,"Implementing paper: ""Grouped Recurrent Convolutional Layers for Multivariate Time Series""",https://www.reddit.com/r/deeplearning/comments/a1dadl/implementing_paper_grouped_recurrent/,amarczew,1543459709,"Hi everyone,

&amp;#x200B;

I'm thinking to implement [this paper](https://arxiv.org/abs/1703.09938v4) (Grouped Recurrent Convolutional Layers for Multivariate Time Series) to try some new ideas based on it. To get time, did anyone already do? or some scratch to start from something? I haven't found on web anything about its implementation.

&amp;#x200B;

thanks in advance",0,1
226,2018-11-29,2018,11,29,15,a1ew7r,Does it compute gradient twice and backpropagation once in this implementation of GAN?,https://www.reddit.com/r/deeplearning/comments/a1ew7r/does_it_compute_gradient_twice_and/,Catherine_Fang,1543473082,"Hi, I am a bit confused by 
_, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],
                                feed_dict=feed_dict) 

Does it compute gradient twice and backpropagation once?
https://github.com/aymericdamien/TensorFlow-Examples/blob/9e1bb504f5d0f209d000997ce2ad95bb891798ab/examples/3_NeuralNetworks/dcgan.py#L148 ",1,1
227,2018-11-29,2018,11,29,17,a1fjac,Experience Replay for Continual Learning [PDF] : A DeepMind Publication,https://www.reddit.com/r/deeplearning/comments/a1fjac/experience_replay_for_continual_learning_pdf_a/,suj1th,1543479738,,0,1
228,2018-11-30,2018,11,30,0,a1i5kz,How to determine the number of layers of CNN in image classification?,https://www.reddit.com/r/deeplearning/comments/a1i5kz/how_to_determine_the_number_of_layers_of_cnn_in/,Useless_Daydreamer,1543504402,"I am currently learning deeplearning and working on a project aiming to classify dogs according to there breeds . I am currently using 3 CNN having 96, 64 and 64 filters stacked above each other with MaxPooling layer in between. However, the prediction results are unsatisfactory. Can anyone give me any pointers on how to fine tune?
Are there any steps that I can follow , except for trial and error , which would hasten the process of tuning?",11,1
229,2018-11-30,2018,11,30,1,a1ivbs,DAVIS dataset for Video Object Segmentation.,https://www.reddit.com/r/deeplearning/comments/a1ivbs/davis_dataset_for_video_object_segmentation/,RohitDulam,1543509168,[removed],0,1
230,2018-11-30,2018,11,30,4,a1kc8c,Why is my neural network not working properly?,https://www.reddit.com/r/deeplearning/comments/a1kc8c/why_is_my_neural_network_not_working_properly/,ditox123,1543518710,,6,1
231,2018-11-30,2018,11,30,4,a1klg7,Michael I. Jordan Interview: Clarity of Thought on AI,https://www.reddit.com/r/deeplearning/comments/a1klg7/michael_i_jordan_interview_clarity_of_thought_on/,gwen0927,1543520382,,8,1
232,2018-11-30,2018,11,30,7,a1mfm9,These people never existed!,https://www.reddit.com/r/deeplearning/comments/a1mfm9/these_people_never_existed/,cmillionaire9,1543532187,,12,1
233,2018-11-30,2018,11,30,18,a1qtzz,Reading Minds with Deep Learning,https://www.reddit.com/r/deeplearning/comments/a1qtzz/reading_minds_with_deep_learning/,pirate7777777,1543568513,,0,1
234,2018-11-30,2018,11,30,19,a1raxq,Tensorflow deployment in AWS,https://www.reddit.com/r/deeplearning/comments/a1raxq/tensorflow_deployment_in_aws/,guzguzit,1543573725,"What are the recommend ways to deploy a tensorflow model for production in AWS? 
Links to good tutorials are welcome ",0,1
0,2018-12-1,2018,12,1,9,a1xxzg,Probabilistic Graphical Models : What is the formal definition of consistent directed PGM estimation? I am trying to find a useful link and paper where I get this ? Anyone have any idea,https://www.reddit.com/r/deeplearning/comments/a1xxzg/probabilistic_graphical_models_what_is_the_formal/,muneeb2405,1543622515,,0,1
1,2018-12-1,2018,12,1,18,a21ny5,Big Bezos is Watching You!,https://www.reddit.com/r/deeplearning/comments/a21ny5/big_bezos_is_watching_you/,BlockDelta,1543655955,,1,1
2,2018-12-2,2018,12,2,1,a24jvx,"The deepest problem with deep learning (Some reflections on an accidental Twitterstorm, the future of AI and deep learning, and what happens when you confuse a schoolbus with a snow plow) Gary Marcus  Medium",https://www.reddit.com/r/deeplearning/comments/a24jvx/the_deepest_problem_with_deep_learning_some/,chaoticflipflops,1543682940,,4,1
3,2018-12-2,2018,12,2,3,a25if2,Training a Goal-Oriented Chatbot with Deep Reinforcement Learning in Python,https://www.reddit.com/r/deeplearning/comments/a25if2/training_a_goaloriented_chatbot_with_deep/,DL_IRL,1543689409,[https://medium.com/@maxbrenner110/training-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-i-introduction-and-dce3af21d383](https://medium.com/@maxbrenner110/training-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-i-introduction-and-dce3af21d383),0,1
4,2018-12-2,2018,12,2,17,a2bm98,The difference of LSTM and LSTM RNN,https://www.reddit.com/r/deeplearning/comments/a2bm98/the_difference_of_lstm_and_lstm_rnn/,suraty,1543738613,"Hello, 
What are the differences between the long short-term memory-recurrent neural network (LSTM-RNN) and long short-term memory neural network (LSTM-NN)?
Are they same?

Thank you",3,1
5,2018-12-2,2018,12,2,20,a2cfz8,OpenPose with Google colab ?,https://www.reddit.com/r/deeplearning/comments/a2cfz8/openpose_with_google_colab/,pk12_,1543749019,,0,1
6,2018-12-2,2018,12,2,21,a2covu,Any algorithm for this ?,https://www.reddit.com/r/deeplearning/comments/a2covu/any_algorithm_for_this/,nomoonday,1543752054,"
Say, if I had an essay about an elephant, and 3 classes,

1.Animal,
2.Friendly,
3.Bird.

My output should be  (on a scale of 10)
1. Animal - 10
2. Friendly - 6
3. Bird - 0 
( I have enough labelled essays for three classes, in case I have to train a model )
I thought of multiclass classification but then I found this is not classification. This is something that should give how much similarity or association the test data has with all the classes. 

",1,1
7,2018-12-2,2018,12,2,22,a2d713,Can I predict stock splits using deep learning?,https://www.reddit.com/r/deeplearning/comments/a2d713/can_i_predict_stock_splits_using_deep_learning/,dwlsalmeida,1543757367,"That's based on the assumption that companies tend to have stock splits when their share price is too high or trade too little   


Although there's plenty of research about an 'optimum price', no one really knows what it is for a given company.  


My approach is the following: Given a normalized stock price, amount of trade, and bid-ask spread, can deep learning predict in theory how likely a company is to vote for a stock split in an ordinary shareholders meeting?

  
I have over 20 years of data from my bachelor's thesis, however I only have \~500 splits in it, so the labels are very unbalanced. Is this a problem?  


I plan on using the window slicing method for data augmentation based on this work [https://aaltd16.irisa.fr/files/2016/08/AALTD16\_paper\_9.pdf](https://aaltd16.irisa.fr/files/2016/08/AALTD16_paper_9.pdf)

&amp;#x200B;

Does this sound feasible? What kind of network architecture should I aim for? Can I use transfer learning?   


&amp;#x200B;",6,1
8,2018-12-3,2018,12,3,1,a2esnf,Need Tips and Suggestions for writing deep learning paper summary,https://www.reddit.com/r/deeplearning/comments/a2esnf/need_tips_and_suggestions_for_writing_deep/,enjay93,1543769531,"I am trying to write summaries for the papers that I like in the fields of Computer Vision , Deep Learning and Reinforcement Learning . I needed some suggestion on how to write better summaries .   
Can someone read  few of my summaries and give me some pointers ?  
[http://www.shortscience.org/user?name=anirudhnj](http://www.shortscience.org/user?name=anirudhnj)",0,1
9,2018-12-3,2018,12,3,4,a2giei,Alternatives to converting data into numbers (beginner questions),https://www.reddit.com/r/deeplearning/comments/a2giei/alternatives_to_converting_data_into_numbers/,SuperMedicalLearner,1543780073,"Hello, I want to categorize a sequences of amino acids into ""good"" and ""bad"" proteins. In my dataset, each character represents a spezific amino acid (e.g. c = glutamine , d =  leucine), so the data looks like this:

Good proteins: shjkad, daslkjlk, dasdlkjk, daskljk

Bad proteins: sdakljk, fjaskllk, sadlkkk, dasjlksa

Since no amino acid is valued more than the others (and every amino acid has unique properties) , I think it's not a good idea to convert them into numbers. Am I completely wrong or do you know any alternatives?

&amp;#x200B;

Thanks in advance",2,1
10,2018-12-3,2018,12,3,6,a2hkaw,Text to Speech + Style Transfer Pretrained Models,https://www.reddit.com/r/deeplearning/comments/a2hkaw/text_to_speech_style_transfer_pretrained_models/,ishandutta2007,1543786414,"Well I have been searching for pretrained models or API for TTS with Style transfer ever since google demonstrated duplex at i/o 2017. 

Here is the best repo I found,
https://github.com/syang1993/gst-tacotron
With 200k iterations it has resonably good results compared to other repos(mentioned in links below), hopefully if someone can train it 800k-1000k we will ba able to match google's results.

It's been a year ever since but still no trained model or API publicly available.

Related Old Posts:
https://www.reddit.com/r/MachineLearning/comments/7zb2jm/n_baidu_ai_can_clone_your_voice_in_seconds/
https://www.reddit.com/r/MachineLearning/comments/845uji/d_are_the_hyperrealistic_results_of_tacotron2_and/",0,1
11,2018-12-3,2018,12,3,9,a2ix9b,An Analysis of Google's Patent Policies on Open Source AI Software (3),https://www.reddit.com/r/deeplearning/comments/a2ix9b/an_analysis_of_googles_patent_policies_on_open/,PIIP_LAW,1543795361,,2,1
12,2018-12-3,2018,12,3,10,a2jthq,Text classification issue,https://www.reddit.com/r/deeplearning/comments/a2jthq/text_classification_issue/,ordron,1543801636,"Hey guys, I'm currently working on a text classification issue where I want to get an accurate result between 2 categories,

I've tried multiple NNs like shallow nets, rcnns etc but they all under perform to xgb boost, logistic regression is this normal in some circumstances? ",2,1
13,2018-12-3,2018,12,3,17,a2mp4t,import the same interval of previous week into the model,https://www.reddit.com/r/deeplearning/comments/a2mp4t/import_the_same_interval_of_previous_week_into/,suraty,1543824814,"Hello,

In a dataset, the data are the average of vehicles speed in the points (cells) of a map. I am trying to build a prediction model.

While the inputs are the average of vehicles speed of all points in recent 40 min and the outputs are the next 10 min of all points.

If there were 320 points on the map, the input shape = (320,20) and the output shape =(320,5). The averages of vehicles speed are collected each 2 min in all points.

There are several such samples (n samples, x=(n,320,20), y=(n,320,5)).

The codes of the final architecture of my model:

    model = models.Sequential()
    model.add(Conv2D(256,(3, 3),
             activation='relu',
             input_shape=(320,20,1), padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))

    model.add(Flatten())
    model.add(Dense(1600))

    model.summary()

There is a significant weekly cycle and I would like to import the same interval of the previous week together with the current input to the model. 

How should I change the model?

Should I change the input shape as (n, 2 * 320, 2 * 20)? 

Thank you ",0,1
14,2018-12-3,2018,12,3,17,a2mrmj,Dilated Convolution for Structrure Preserving,https://www.reddit.com/r/deeplearning/comments/a2mrmj/dilated_convolution_for_structrure_preserving/,kamranjanjua,1543825553,"I read the dilated conv paper from 2016 where the authors proposed dilated kernels for dense prediction. Since almost every scene understand work involves some kind of dense prediction, has someone tried to use dilated CNNs for scene understanding? Does it preserve the structure better as compared to vanilla CNNs? ",0,1
15,2018-12-3,2018,12,3,17,a2muyb,"Looking for Suggestions and Tips for Tree/Plant growing ""algorithm"" using Deep Networks",https://www.reddit.com/r/deeplearning/comments/a2muyb/looking_for_suggestions_and_tips_for_treeplant/,capocchione,1543826527,"I am looking for any suggestion or tip to start creating a deep network capable of growing trees/plants according to biological and environmental rules (such as concentration of nitrogen, exposure to light and so on).

Right now, I am dealing with ""classical"" model such as ODE (Ordinary Differential Equations), PDE (Partial Differential Equations), IBM (Individual-Based Hybrid Model), FSPM (Functional-Structural Plant Growth Modeling), etc...  
I want to try something different, maybe linking the deep network growth model to a 3d render of growing process.",11,1
16,2018-12-3,2018,12,3,22,a2ojvy,Do you think training your models on the cloud is a bit expensive? How often do you use it?,https://www.reddit.com/r/deeplearning/comments/a2ojvy/do_you_think_training_your_models_on_the_cloud_is/,ajayrao80,1543843045,I recently started training my models on the cloud. I checked different services. They all had similar prices. I felt it was a bit expensive. Do you think its expensive and how often do you actually go for a cloud computing service to train you models?,10,1
17,2018-12-4,2018,12,4,1,a2q7bt,Recording and Jupyter Notebook for the Data Science Webinar on Recommender Systems - From Simple to Complex,https://www.reddit.com/r/deeplearning/comments/a2q7bt/recording_and_jupyter_notebook_for_the_data/,supercake53,1543854458,,0,1
18,2018-12-4,2018,12,4,1,a2q8wk,Should you overclock GPU for Deep Learning?,https://www.reddit.com/r/deeplearning/comments/a2q8wk/should_you_overclock_gpu_for_deep_learning/,thegreatskywalker,1543854722,Is it safe to overclock 2080ti (or any other GPU) for long Deep Learning sessions (3 days to 1 week)? I am considering getting a water block for a 2080ti but not sure if its possible to overclock on Linux. I've read some posts about setting cool bits but it's not clear if anyone succeeded in overclocking 2080ti on Linux. Any help would be greatly appreciated :),4,1
19,2018-12-4,2018,12,4,2,a2qui4,Which deep learning method (DNN or any) is required to get walls from the 2d floor maps? [important],https://www.reddit.com/r/deeplearning/comments/a2qui4/which_deep_learning_method_dnn_or_any_is_required/,amit2rockon,1543858483,Please put relevant links here and if possible then some links to dataset.,8,1
20,2018-12-4,2018,12,4,4,a2s87s,A short tutorial on how to build efficient Tensorflow dataset pipeline with some non-trivial logic [I'm the author],https://www.reddit.com/r/deeplearning/comments/a2s87s/a_short_tutorial_on_how_to_build_efficient/,urimerhav,1543866571,,0,1
21,2018-12-4,2018,12,4,6,a2t77b,DeepMind AlphaFold Delivers Unprecedented Progress on Protein Folding,https://www.reddit.com/r/deeplearning/comments/a2t77b/deepmind_alphafold_delivers_unprecedented/,gwen0927,1543872255,,0,1
22,2018-12-4,2018,12,4,9,a2uuen,Is it a bad idea to use dropout into a CNN network?,https://www.reddit.com/r/deeplearning/comments/a2uuen/is_it_a_bad_idea_to_use_dropout_into_a_cnn_network/,melonochelo,1543881683,"I saw the paper by Alex from AlexNet that suggests to add a dropout layer, but there is a lot of posts out there from 2017, 2018 that says stuff like: NEVER use dropout layer... 

Is it no more the way to prevent over fitting?",4,1
23,2018-12-4,2018,12,4,9,a2vc98,NeurIPS 2018 Opens; Best Papers Announced,https://www.reddit.com/r/deeplearning/comments/a2vc98/neurips_2018_opens_best_papers_announced/,trcytony,1543885106,,0,1
24,2018-12-4,2018,12,4,11,a2wd2z,"NVIDIA Extends PhysX for High-Fidelity Simulations, Goes Open Source",https://www.reddit.com/r/deeplearning/comments/a2wd2z/nvidia_extends_physx_for_highfidelity_simulations/,Nater5000,1543892133,"https://blogs.nvidia.com/blog/2018/12/03/physx-high-fidelity-open-source/

Has anybody seen this? If so, how do you feel about the RL capabilities of such software? I'm not familiar enough with physics engines to know, but I've used Mujoco in RL projects, and I hate having to used closed source software for something so experiment driven. Could this offer an alternative? Or is this not suitable for such simulations?

I'm also curious about the GPU acceleration. Many RL algorithms, such as PPO, can be bottle necked at the environment simulation. Does this do something that libraries such as Mujoco doesn't? Or are we not going to see any actual increase in efficiency of simulating?",0,1
25,2018-12-4,2018,12,4,12,a2whjt,Announcing Clusterone SaaS,https://www.reddit.com/r/deeplearning/comments/a2whjt/announcing_clusterone_saas/,mhejrati,1543892967,"Hi everyone,

I'm Mohsen, co-founder at Clusterone. We just launched our public SaaS which allows you to train ML models using a wide range of libraries and on GPU and CPUs. We offer best cloud GPU prices in addition to optimized environments, project and job tracking, etc.

You can sign up for free and get $25 free credit, our V100 is $1.9/hour which is half of AWS or GCP and we also have 1080Tis. See `clusterone.com/pricing`

Looking forward to your feedback.

&amp;#x200B;",6,1
26,2018-12-4,2018,12,4,19,a2zfk7,The First Interactive AI Rendered Virtual World,https://www.reddit.com/r/deeplearning/comments/a2zfk7/the_first_interactive_ai_rendered_virtual_world/,cmillionaire9,1543918450,,6,1
27,2018-12-4,2018,12,4,23,a31bbi,[D] NeurIPS (prev. NIPS) papers selection?,https://www.reddit.com/r/deeplearning/comments/a31bbi/d_neurips_prev_nips_papers_selection/,sizaka,1543935015,"NeurIPS (prev. NIPS) has just started and it is not possible for everybody to attend it. That is why I have written this papers selection:  
[https://blog.sicara.com/nips-neurips-papers-selection-28efd4d73189](https://blog.sicara.com/nips-neurips-papers-selection-28efd4d73189)  
Do you like the format? Is it useful? I would really like some feedback on this.

By the way, what are the biggest breakthroughs for you this year?",0,1
28,2018-12-5,2018,12,5,0,a31sas,How can I train an AI to insert fillers and interjections in texts.,https://www.reddit.com/r/deeplearning/comments/a31sas/how_can_i_train_an_ai_to_insert_fillers_and/,ishandutta2007,1543938251,"Given a paragraph of formal text, I need to convert it to a paraghaph with realistic fillers and interjections that people would normally use while speaking it.

&amp;#x200B;

PS:

In case you want to know what fillers and interjections are.

fillers are basically pauses in sentenses without intention of conveing meaning wheras interjections can be more intentional and may express a feeling. examples of filler words would be umm, ahh, er; examples of interjections would be well, ok, i mean, wao, oh, oh dear, Oh, Wow, Hurrah, Alas, Ouch, Oops, Aha, Yahoo, Eww. [https://blog.babbel.com/fillers-interjections-stepping-stones-fluency/](https://blog.babbel.com/fillers-interjections-stepping-stones-fluency/)

&amp;#x200B;",7,1
29,2018-12-5,2018,12,5,1,a323mv,Free instances with 1080Ti for deep learning  trial credits,https://www.reddit.com/r/deeplearning/comments/a323mv/free_instances_with_1080ti_for_deep_learning/,whitezl0,1543940293,"Hi, I am offering free credits for you to access 1080Ti GPU instances for deep learning purposes.

I am a co-founder of Tensorpad; where we are creating a service for  AI startups to train neural networks. We have paid traffic, but some  servers are idle. Hence, we are offering some credits for free, so that  students, startups, and others can benefit from ML technologies and help  us by using our product and providing honest feedback for us to  improve.

You can Sign Up at [https://dashboard.tensorpad.com/signup](https://dashboard.tensorpad.com/signup) and redeem the code ""REDDIT650"" in the Billing tab.

Hope this explains our story and motivation for providing free credits.

Here is additional information:  

\* The instances have 16GB RAM, 4 CPUs cores and one 1080Ti GPU. You can run multiple instances in parallel  

\* You get access to the JupyterLab environment  

\* We have pre-installed Tensorflow, Keras, and other ML frameworks  

\* You can access the terminal through the JupyterLab  

\* By default, persistent storage is enabled  

\* Here are the available software versions [https://docs.tensorpad.com/jobs\_env/](https://docs.tensorpad.com/jobs_env/) For extra free trial hours, use promo code: REDDIT650

And for questions, please contact me at [ilie@tensorpad.com](mailto:ilie@tensorpad.com). I am looking forward to seeing you on our platform! Sincerely, Ilie Diacov Co-founder and UX researcher at Tensorpad",6,1
30,2018-12-5,2018,12,5,4,a33ryp,Is possible to classify pictures with a fully connected deep forward network?,https://www.reddit.com/r/deeplearning/comments/a33ryp/is_possible_to_classify_pictures_with_a_fully/,xNetzwerkchief,1543950761,"And if not, what are typical use cases for deep feed forward networks where every unit is connected? 
Thank you.",3,1
31,2018-12-5,2018,12,5,7,a35n6h,GPU makes a different sound depending on the problem being solved,https://www.reddit.com/r/deeplearning/comments/a35n6h/gpu_makes_a_different_sound_depending_on_the/,m3hh0w,1543962254,"This is probably a very weird question but how is it possible that a GPU makes a weird, flowing-water-like noise only when I run a cudnn version of an LSTM in tensorflow and doesn't make that noise with a regular LSTM implementation or CNNs? 

I don't know nearly enough about hardware to formalize this question further but is it somehow possible that different computation types force the same load (around 70-90%) on the GPU but are somehow different to produce a physical effect like this only in one case but not the others?

The GPU is Zotac 1070Ti if that might matter.",0,1
32,2018-12-5,2018,12,5,10,a372iy,Deep Learning for Image comparision,https://www.reddit.com/r/deeplearning/comments/a372iy/deep_learning_for_image_comparision/,duyth,1543971705,"hi everyone,

I''ve been researching for a solution do do image comparison and I'm hoping and I can some suggestions from the community re the approach  


I have a friend who runs an online store. Normally, he runs into competitors who use a similar /exact product name to out-price him so we want to monitor/price beat the competitors if possible

I'm trying to see if we can automate this and we do not want to rely entirely on the product name / but instead, the images are what we want to use to ensure the competitors are selling our exact products  
The challenge is, take a white iphone for example,  our images could be taken from a different angle or it could be smaller/bigger that the  images from the other sellers (etc.. you got the idea)  
I'm not sure if this is a problem that deep learning can solve / or at least, give us an indicator of % match etc..?

Appreciate if you can point us to the right direction

thank you",3,1
33,2018-12-5,2018,12,5,12,a38a9y,"Notable DL research papers, 2018",https://www.reddit.com/r/deeplearning/comments/a38a9y/notable_dl_research_papers_2018/,PullThisFinger,1543980314,"Several are listed as ""Best Paper"" at the big conferences. Good list? Other candidates?

[https://www.topbots.com/most-important-ai-research-papers-2018/](https://www.topbots.com/most-important-ai-research-papers-2018/)",0,1
34,2018-12-5,2018,12,5,12,a38ded,Averaging the predictions of different Object detection models in an ensemble,https://www.reddit.com/r/deeplearning/comments/a38ded/averaging_the_predictions_of_different_object/,deeplearning2018,1543980950,"In this paper (https://arxiv.org/abs/1809.03193?fbclid=IwAR1p0MHK_GIbdYCJJ05oKcxGWTkRAVM47VLCIfcWMsH2tOKigdWoKDQfa20) the authors propose a technique to get better inference results by using ensembles, I know examples of ensembles in the classification task but has anyone seen and preferably point to a code example of doing inference of object detection using ensemble voting? ",0,1
35,2018-12-5,2018,12,5,21,a3br3x,I need some ideas on Neural Style Transfer,https://www.reddit.com/r/deeplearning/comments/a3br3x/i_need_some_ideas_on_neural_style_transfer/,nolimitex,1544012075,"Hey, could anyone name me the main issues that they *personally* think the Neural Style Transfer has and what could be possibly done to solve them (what could be improved)? Basically, I have some free time now and I need a good NST challenge to work on. Thank you:)",2,1
36,2018-12-5,2018,12,5,23,a3ctdp,Hot off the Press! Links to Computer Vision News of December - with codes!,https://www.reddit.com/r/deeplearning/comments/a3ctdp/hot_off_the_press_links_to_computer_vision_news/,Gletta,1544020542,"Here is the December 2018 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: 38 pages full of articles on computer science, computer scientists and their work.

Enjoy new Deep Learning and Artificial Intelligence researches and reviews. Free subscription at page 38.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2018December/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2018-december-pdf/)

Enjoy!

&amp;#x200B;

*Processing img s59qoba70h221...*",0,1
37,2018-12-6,2018,12,6,0,a3devk,Insilico Medicine Announces MOSES Benchmark Platform for Molecular Generation,https://www.reddit.com/r/deeplearning/comments/a3devk/insilico_medicine_announces_moses_benchmark/,Yuqing7,1544024590,,0,1
38,2018-12-6,2018,12,6,2,a3e6iw,Filtr.pub: Finding signals in noisy AI Research,https://www.reddit.com/r/deeplearning/comments/a3e6iw/filtrpub_finding_signals_in_noisy_ai_research/,jeetmehta,1544029342,"AI research is moving at breakneck pace. State-of-the-art methods seem to become obsolete almost as quickly as they are found - as practitioners, its important to stay on top of the field. 

  
Meanwhile, the quantity of papers uploaded on arXiv is outpacing Moores Law. With the sheer quantity of research published on a daily basis, and the lack of peer review for uploading - its becoming increasingly difficult to know whats important and what isnt. 

  
How do you separate signal from noise?

  
Enter [filtr.pub](https://filtr.pub)

  
A unique platform designed to prioritize quality over quantity. Upvoting. Email subscriptions. Intelligent filters. Everything you wished arXiv had but doesnt - its all here. Brought to you by fellow practitioners - Data Scientists and Machine Learning Engineers equally frustrated with this problem. After a lot of looking, we were unable to find a viable solution. So we decided to build one.

  
Check us out! Were working hard on the platform - and well invite a select group of practitioners for a closed-beta, so we can iterate on feedback and get the product ready for the wider community! Sign up for news + updates + the opportunity to be a part of the beta program.",10,1
39,2018-12-6,2018,12,6,3,a3es6v,Vancouver Named NeurIPS 2019 &amp; 2020 Host,https://www.reddit.com/r/deeplearning/comments/a3es6v/vancouver_named_neurips_2019_2020_host/,gwen0927,1544032923,,0,1
40,2018-12-6,2018,12,6,4,a3foui,Should I be saving for TITAN RTX?,https://www.reddit.com/r/deeplearning/comments/a3foui/should_i_be_saving_for_titan_rtx/,dewise,1544038485,"I'm doing research in a related field and have a access to massive of V100 at work, but at home I'm trying to play with NN for side projects with clear commercial gain in mind. 

I've beet thinking to buy may be a 1-2 more 1080ti (the work station at home has 1080ti and is used by several of my helpers), but since I've seen TITAN RTX I started to think about new possibilities of 24GB ram. ",0,1
41,2018-12-6,2018,12,6,12,a3jxsn,Can't figure out how the output matrix is calculated in this CNN,https://www.reddit.com/r/deeplearning/comments/a3jxsn/cant_figure_out_how_the_output_matrix_is/,Cyclonedx,1544066148,"http://cs231n.github.io/convolutional-networks/

If you scroll down a bit you'll see a gif of matrix multiplication for an example CNN. I've spent over an hour but still cannot figure out how values are calculated for the output (in green). It isn't mentioned anywhere on the page.",2,1
42,2018-12-6,2018,12,6,12,a3jz3i,Hobbyist build for ML fun,https://www.reddit.com/r/deeplearning/comments/a3jz3i/hobbyist_build_for_ml_fun/,moar_qwibqwib,1544066411," Hello /r/deeplearning,

&amp;#x200B;

I'm an ex-machine learner trying to get back into it. In Grad school I focused mostly on smaller NNs and self-organizing networks. Being limited by my build, I couldn't do much more. Now that I have a steady income, I want to do some hobby work. My goal is to get into kaggling and a few side projects. No plans to do big image sets. This is my first build, and I'm worried I'm over thinking and over building.  Am I?

&amp;#x200B;

 [PCPartPicker part list](https://pcpartpicker.com/list/wZdxjy) / [Price breakdown by merchant](https://pcpartpicker.com/list/wZdxjy/by_merchant/)

|Type|Item|Price|
|:-|:-|:-|
|**CPU**|[Intel - Core i7-8700K 3.7 GHz 6-Core Processor](https://pcpartpicker.com/product/sxDzK8/intel-core-i7-8700k-37ghz-6-core-processor-bx80684i78700k)|$369.99 @ Amazon|
|**CPU Cooler**|[be quiet! - Dark Rock Pro 4 50.5 CFM CPU Cooler](https://pcpartpicker.com/product/F3gzK8/be-quiet-dark-rock-pro-4-505-cfm-cpu-cooler-bk022)|$84.89 @ OutletPC|
|**Motherboard**|[Asus - PRIME Z370-A II ATX LGA1151 Motherboard](https://pcpartpicker.com/product/H43H99/asus-prime-z370-a-ii-atx-lga1151-motherboard-prime-z370-a-ii)|$170.98 @ SuperBiiz|
|**Memory**|[G.Skill - Ripjaws V Series 32 GB (2 x 16 GB) DDR4-3200 Memory](https://pcpartpicker.com/product/kXbkcf/gskill-memory-f43200c16d32gvk)|$254.89 @ OutletPC|
|**Storage**|[Samsung - 860 Evo 1 TB M.2-2280 Solid State Drive](https://pcpartpicker.com/product/wd97YJ/samsung-860-evo-1tb-m2-2280-solid-state-drive-mz-n6e1t0bw)|$147.99 @ Amazon|
|**Video Card**|[EVGA - GeForce GTX 1080 Ti 11 GB FTW3 GAMING iCX Video Card](https://pcpartpicker.com/product/KBtWGX/evga-geforce-gtx-1080-ti-11gb-ftw-gaming-icx-video-card-11g-p4-6696-kr)|$804.98 @ Newegg Business|
|**Case**|[Cooler Master - MasterCase MC500M ATX Mid Tower Case](https://pcpartpicker.com/product/tnGxFT/cooler-master-mastercase-mc500m-atx-mid-tower-case-mcm-m500m-kg5n-s00)|$158.98 @ Newegg|
|**Power Supply**|[Corsair - 750 W 80+ Platinum Certified Fully-Modular ATX Power Supply](https://pcpartpicker.com/product/BJFPxr/corsair-power-supply-cp9020072)|$109.89 @ OutletPC|
|**Optical Drive**|[LG - WH14NS40 Blu-Ray/DVD/CD Writer](https://pcpartpicker.com/product/z2dqqs/lg-optical-drive-wh14ns40)|$59.89 @ OutletPC|
|*Prices include shipping, taxes, rebates, and discounts*|||
|Total (before mail-in rebates)|$2202.48||
|Mail-in rebates|\-$40.00||
|**Total**|**$2162.48**||
|Generated by [PCPartPicker](https://pcpartpicker.com) 2018-12-05 22:13 EST-0500|||

&amp;#x200B;",3,1
43,2018-12-6,2018,12,6,14,a3krq6,Can you train a deep recurrent neural network layer by layer?,https://www.reddit.com/r/deeplearning/comments/a3krq6/can_you_train_a_deep_recurrent_neural_network/,qudcjf7928,1544072532,"&amp;#x200B;

https://i.redd.it/hzxn0lcsal221.png

 Specifically for Gated Recurrent Unit, and say GRU is ""layered"" via 

&amp;#x200B;

https://i.redd.it/nakpifgtal221.png

 

but suppose it's only 2 layers deep for simplicity,

and suppose the ""total loss"" = *L*

= *lt*=*error*(*y*2*t*) for all *t*

Then I know how to train the weights for a single layer, so is it possible to train the GRU layer by layer?

In a sense that, find the derivatives wrt the 2nd layer's inputs, thus find *L**X*2*t*,for all *t*, which is identical to *L**h*1*t*,  (thus, the derivatives wrt the 2nd layer's GRU inputs are to be used as  the derivatives wrt to the 1st layer's GRU's output) then train the 2nd  layer's GRU, then using the derivatives wrt to the 2nd layer's inputs,  use the same method that I used to train the 2nd layer, into training  the 1st layer's GRU? ",3,1
44,2018-12-7,2018,12,7,3,a3qtux,User query Dataset,https://www.reddit.com/r/deeplearning/comments/a3qtux/user_query_dataset/,fernix96,1544121710,"Hi everyone, simple question: do you know if there is a dataset with user's queries for playing music? Queries like: ""Play \[song\_name\] by \[artist\]"", ""Play some blues"", or ""Play my favourite playlist"" ecc... 

Thanks a lot.",0,1
45,2018-12-7,2018,12,7,8,a3tyig,"New patent for ""training action selection neural networks using look-ahead"". Should we be worried?",https://www.reddit.com/r/deeplearning/comments/a3tyig/new_patent_for_training_action_selection_neural/,abcd_z,1544140265,,5,1
46,2018-12-7,2018,12,7,13,a3wh1z,Struggling with how to format data before feeding it into a CNN (keras),https://www.reddit.com/r/deeplearning/comments/a3wh1z/struggling_with_how_to_format_data_before_feeding/,Cyclonedx,1544157670,"I've been watching lots of tutorials online and I'm now comfortable with coding a simple CNN in Keras. The problem is no one explains what format data needs to be in before I feed it to the model.

I keep getting input dimensions errors such as ""Error when checking input: expected conv2d_9_input to have 4 dimensions, but got array with shape (27455, 785)"". I have no idea how to fix this and I can't find any documentation/guides on how to preprocess data so it works with a model.

I'm working with MNIST data sets that are 28x28 greyscale images. The CSV file contains training data of shape (27455, 785). This is because the first column is the label (integer between 0 and 25 denoting what the image is out of 26 possibilities) and the remaining 784 rows are pixel data for a 28x28 image.

And this is where I'm stuck. What do I do next? Remove the label column? Why can't I directly feed this into the model?",2,1
47,2018-12-7,2018,12,7,18,a3y8e3,Amazon Web Services re:Invent 2018 - A Game Changer.,https://www.reddit.com/r/deeplearning/comments/a3y8e3/amazon_web_services_reinvent_2018_a_game_changer/,BlockDelta,1544173594,,0,1
48,2018-12-7,2018,12,7,19,a3ylkd,How Augmented Analytics can automate resource-intensive data analysis tasks.,https://www.reddit.com/r/deeplearning/comments/a3ylkd/how_augmented_analytics_can_automate/,Victor_Stakh,1544177449,,0,1
49,2018-12-7,2018,12,7,23,a40lvj,10 Gradient Descent Optimisation Algorithms in a Cheat Sheet,https://www.reddit.com/r/deeplearning/comments/a40lvj/10_gradient_descent_optimisation_algorithms_in_a/,raibosome,1544194579,,0,1
50,2018-12-8,2018,12,8,0,a40oqr,"Hinton explains the differences between the Symbolic and connectionists approach to the AI. He encourages Europe to stop funding ""old-fashioned AI people"" and instead focusing on the connectionists approach a.k.a deep learning",https://www.reddit.com/r/deeplearning/comments/a40oqr/hinton_explains_the_differences_between_the/,dt_magic,1544195131,,3,1
51,2018-12-8,2018,12,8,0,a40p66,10 Gradient Descent Optimisation Algorithms + Cheat Sheet,https://www.reddit.com/r/deeplearning/comments/a40p66/10_gradient_descent_optimisation_algorithms_cheat/,raibosome,1544195218,"Compiled a list of common stochastic gradient descent optimisation algorithms in this post, together with a cheat sheet at the end of it.

[https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9](https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9)

Do let me know if you have any feedback or comments!

https://i.redd.it/93428uk1ev221.png",0,1
52,2018-12-8,2018,12,8,0,a40xx0,Spinning Up a Pong AI With Deep Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/a40xx0/spinning_up_a_pong_ai_with_deep_reinforcement/,pirate7777777,1544196878,,0,1
53,2018-12-8,2018,12,8,1,a41hke,Deep Learning and Computer Vision: Converting Models for the Wolfram Neural Net Repository,https://www.reddit.com/r/deeplearning/comments/a41hke/deep_learning_and_computer_vision_converting/,CuttingWithScissors,1544200342,,0,1
54,2018-12-8,2018,12,8,4,a42yy2,Will AI Devices Become our Benevolent Overlords?,https://www.reddit.com/r/deeplearning/comments/a42yy2/will_ai_devices_become_our_benevolent_overlords/,BlockDelta,1544209597,,1,1
55,2018-12-8,2018,12,8,5,a43jas,Do We Still Need Traditional Pattern Recognition and Signal Processing in the Age of Deep Learning? (Read from: Prof. Dr.-Ing. habil. Andreas Maier Head of the Pattern Recognition Lab of the Friedrich-Alexander-Universitt Erlangen-Nrnberg ),https://www.reddit.com/r/deeplearning/comments/a43jas/do_we_still_need_traditional_pattern_recognition/,asifrazzaq1988,1544213166,[removed],0,1
56,2018-12-8,2018,12,8,6,a446gx,"Meet Deep Graph Library, a Python Package For Graph Neural Networks",https://www.reddit.com/r/deeplearning/comments/a446gx/meet_deep_graph_library_a_python_package_for/,Yuqing7,1544217291,,0,1
57,2018-12-8,2018,12,8,8,a45ats,How to handle good theory that doesn't seem to work?,https://www.reddit.com/r/deeplearning/comments/a45ats/how_to_handle_good_theory_that_doesnt_seem_to_work/,Spenhouet,1544224608,"I thought about something novel that in theory sounds very promising and also low risk. I implemented everything but it just underperforms my expectations. Why trying different settings and parameter combinations I feel like ""I don't know what I'm doing"" and lost the systematic way. It could have many complex reasons why it doesn't perform as my expectations.I feel like it should work, I just didn't discover the right combination or missed a problem but I'm not yet tolerant to such situations and start to get frustrated.I feel like this is a common thing in research. How do you handle such a situation? Go back to the drawing board? Make the problem smaller and more capable? ...?",2,1
58,2018-12-8,2018,12,8,9,a45ri4,"Question regarding the ""Deep Learning with Python"" book",https://www.reddit.com/r/deeplearning/comments/a45ri4/question_regarding_the_deep_learning_with_python/,R_y_n_o,1544227989,"I wanted to ask something to anyone that has read and implemented the examples in this book.

I read the introduction, and the author suggests to either set up a cloud workstation or to set up everything on a local machine with a top notch gpu.

I have a laptop with an average GPU (GTX 960M) which is definitely not enough to do some serious deep learning, but I was wondering if it is enough to follow the examples showcased in the book. I would like to do everything on my machine because I want to learn how to setup the environment myself, instead of relying on a web service. ",2,1
59,2018-12-8,2018,12,8,15,a48hfq,"Is ""Hands on machine learning with scikit-learn &amp; tensorflow"" still relevant?",https://www.reddit.com/r/deeplearning/comments/a48hfq/is_hands_on_machine_learning_with_scikitlearn/,daredevildas,1544251316,"I managed to get my hands on the book ""Hands-On Machine Learning with Scikit-Learn &amp; Tensorflow first edition"" but it was released in March 2017 and the scikit-learn and tensorflow APIs might have changed since then. A new version is coming out next year but to get it shipped to where I stay is going to be expensive. 

My background - I just have an overview of what machine learning is - what supervised and unsupervised learning is, what RNN, LSTM, etc are but no practical experience. I have the relevant mathematical background in probability and linear algebra. 

Is it worth reading this book now as an introductory text? (Getting the second edition is not very viable)

Should I even read this book? (considering my background)

&amp;#x200B;",11,3
60,2018-12-8,2018,12,8,16,a48smm,A bit of confusion regarding data distribution,https://www.reddit.com/r/deeplearning/comments/a48smm/a_bit_of_confusion_regarding_data_distribution/,rahulkulhalli,1544254531,"Hey everyone, 

I'm working on a personal project where I need to classify an image as belonging to one of two categories - for the sake of privacy, let's consider them to be problematic and non-problematic.

The data I have is in the longitudinal form, i.e., each entity has multiple images associated with it. The distribution for this mapping is highly skewed. For e.g., one entity has only ~30 images associated with itself, while another has ~800.

Since considering these images as IID made no sense to me, I decided to split the images into the regular train-val-test folds by ensuring that ALL images associated an entity should be in the same fold. I am also ensuring that the class distribution remain same while splitting the data.

The result is very weird - in about 15 epochs, my model overfits the data pretty easily (The train loss decreases almost linearly per epoch, but the validation loss keeps fluctuating around the same value, sometimes even increasing.)

However, the model gives an amazing prediction on the test set.

This is, in my opinion, some sort of sampling bias. The model seems to have found features that generalize well for the train and test set, but not on the validation set.

Any recommendations on how I could avoid this (possible) sampling bias? I've tried building a ""mixture-of-experts"" model (Hinton's course) with the appropriate loss, but even that doesn't seem to be working out well for me.

If I split the data of EACH entity equally (3 parts) and place each slice in each fold, that would be a very bad idea, right? I would essentially be bleeding information.

Any help would be greatly appreciated.

Thanks!",5,1
61,2018-12-8,2018,12,8,18,a49c3e,Next steps in deep learning,https://www.reddit.com/r/deeplearning/comments/a49c3e/next_steps_in_deep_learning/,solitary_sandman,1544260802,"Hi everyone. I recently finished all of the 5 courses by deeplearning.ai. I will soon join a firm which does image processing using various architectures. A lot of my work will involve reading research papers and try to implement them for a specific use case.

What should be my next steps into deep learning?
Learning tensorflow? If so, what's the best way to about that?

Thanks in advance. ",14,1
62,2018-12-8,2018,12,8,22,a4alc8,"Is my understanding of the terms ""bias"" and ""variance"" correct? [Andrew Ng, Deep Learning, Video#1]",https://www.reddit.com/r/deeplearning/comments/a4alc8/is_my_understanding_of_the_terms_bias_and/,Akainu18448,1544274651,"Taken from the course:  Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization 

https://i.redd.it/ym72no2vy1321.png

Okay, so what I understand here is - you have a training set and a development set. If the machine wrongly classifies an object as a cat, it has a bias error in it. Because this is something that repeated examples of supervised learning won't solve - it's inherent in the machine.

Variance depends on how different the examples are. Suppose you give it 10 different pictures of cats in various resolutions, angles and stuff like that. If it doesn't perform well in that but performs well in the supervised learning examples, it is not something inherent in the machine (since it does well in supervised learning cases). So if you give it time and more examples, it will eventually get it correct. This is the variance error, not the bias error.",2,1
63,2018-12-9,2018,12,9,2,a4cm5v,90s Pop Lyrics Generator using LSTMs,https://www.reddit.com/r/deeplearning/comments/a4cm5v/90s_pop_lyrics_generator_using_lstms/,Laboratory_one,1544290214,,2,1
64,2018-12-9,2018,12,9,22,a4kz96,Newest and most successful methods for image processing in deep learning,https://www.reddit.com/r/deeplearning/comments/a4kz96/newest_and_most_successful_methods_for_image/,suraty,1544362285,"Hello,

In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. 

Is there any other new methodology or technique which is overtaken or overcome on CNN, todays?

What are the newest and most successful methods for image processing in deep learning?

Thank you ",8,1
65,2018-12-9,2018,12,9,23,a4leyk,GPU enabled comparisons in images,https://www.reddit.com/r/deeplearning/comments/a4leyk/gpu_enabled_comparisons_in_images/,Geeks_sid,1544366632,"Hello Everyone,

&amp;#x200B;

I want to do the following task

[The image does not contain any information](https://i.redd.it/nev3athck9321.png)

[The image contains some information](https://i.redd.it/0n6ecthck9321.png)

I want to check whether the image contains information or not, but I want to speed it up with a GPU since I have a million images and the comparisons could be faster. 

So what framework should I use? any particular site where I can learn this from?

&amp;#x200B;",9,1
66,2018-12-10,2018,12,10,12,a4s352,"Building Simple, Portable, Scalable and Cost effective Deep learning pipeline using Kubeflow and Minio",https://www.reddit.com/r/deeplearning/comments/a4s352/building_simple_portable_scalable_and_cost/,hackintoshrao,1544414037,,0,1
67,2018-12-10,2018,12,10,14,a4stz4,Building an Image classification Deep Learning Model using Pytorch,https://www.reddit.com/r/deeplearning/comments/a4stz4/building_an_image_classification_deep_learning/,uncoolai,1544420188,,0,1
68,2018-12-10,2018,12,10,18,a4u2do,What is PAML in PAML+BERT and DA in AoA+DA+BERT?,https://www.reddit.com/r/deeplearning/comments/a4u2do/what_is_paml_in_pamlbert_and_da_in_aoadabert/,ashwinids,1544432429,I'm reading about deep learning applications in Question Answering. The PAML+BERT and AoA+DA+BERT are the best models on the [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) leaderboard. I've read both BERT and AoA papers. What is the meaning PAML and DA( dynamic attention?)?,2,1
69,2018-12-11,2018,12,11,1,a4wxpx,[D] Best AI news in November?,https://www.reddit.com/r/deeplearning/comments/a4wxpx/d_best_ai_news_in_november/,sizaka,1544458038,"I recently wrote an article to help anyone catch up with the latest news from the AI world.

[https://blog.sicara.com/11-2018-best-ai-new-articles-this-month-a219efa105ba-8cf1a554e161](https://blog.sicara.com/11-2018-best-ai-new-articles-this-month-a219efa105ba-8cf1a554e161)

Anything I missed? I would really like some feedback on this as it is quite hard to keep up with the field even when you're actively monitoring it.",2,1
70,2018-12-11,2018,12,11,2,a4xjo3,The experience of improving the Performance of Mask R-CNN Using TensorRT (from six to ten times),https://www.reddit.com/r/deeplearning/comments/a4xjo3/the_experience_of_improving_the_performance_of/,RyanTmthn,1544461958,,2,1
71,2018-12-11,2018,12,11,3,a4y077,Deep Learning Revolution Part II.,https://www.reddit.com/r/deeplearning/comments/a4y077/deep_learning_revolution_part_ii/,BlockDelta,1544464861,,0,1
72,2018-12-11,2018,12,11,5,a4z5mo,Design Pattern for the Fully Connected Layer,https://www.reddit.com/r/deeplearning/comments/a4z5mo/design_pattern_for_the_fully_connected_layer/,xXhachimanXx,1544472010,"Hello fellows Reddit Friends!
I have a question about the Fully-Connected Layer at Top of the CNNs.

How to design them?
There are patterns or they are build in whatever way?
How many dense layers are need? 1, 2, 3? And wich size? 2048, 1024..?
In summary, where are the Design Patterns.

If any of you have any bibliographical references would be perfect and very helpfull.",13,1
73,2018-12-11,2018,12,11,6,a500pc,Neural Abstractive Text Summarization with Sequence-to-Sequence Models,https://www.reddit.com/r/deeplearning/comments/a500pc/neural_abstractive_text_summarization_with/,tianshi2018,1544477391,,0,1
74,2018-12-11,2018,12,11,19,a55jlo,Need help to understand what deep learning is about as a whole !,https://www.reddit.com/r/deeplearning/comments/a55jlo/need_help_to_understand_what_deep_learning_is/,GabyNoTenshi,1544522645,"Hello everyone, I am preparing a thesis on artificial intelligence, and more specifically on Deep Learning. I've just started thinking about it, and I'm missing a lot of keys to be able to make a first version of a plan. I don't know much about it to be honest. I understood the principle of back-propagation and neural network, but that's all. 

What I would like to ask you is what major principles do you think I lack and that I need to look for ? What are the risks, the limits that exist in the field of deep learning. What are the issues at stake? Is it to create a real intelligence? Is there an even more advanced method than DL that will supplant it ?   
Thanks !   
",8,1
75,2018-12-11,2018,12,11,20,a5638y,"Measure, Manifold, Learning, and Optimization: A Theory Of Neural Networks",https://www.reddit.com/r/deeplearning/comments/a5638y/measure_manifold_learning_and_optimization_a/,shawnLeeZX,1544528570,"[https://arxiv.org/abs/1811.12783](https://arxiv.org/abs/1811.12783)

&amp;#x200B;

The theory gives S-System, \***a measure-theoretical definition of NNs**\*; endows a stochastic manifold structure on the intermediate feature space of NNs through information geometry; proposes a learning framework that unifies both supervised learning and unsupervised learning in the same objective function; and proves \***under practical conditions**\*, for \***large size nonlinear deep NNs**\* with a class of losses, including the hinge loss, \***all local minima are global minima**\* with zero loss errors. It also completes the analogy between NNs and Renormalization Group.",0,1
76,2018-12-11,2018,12,11,22,a56p57,Suggestions for research on open problems in 3D pointcloud data with deep learning,https://www.reddit.com/r/deeplearning/comments/a56p57/suggestions_for_research_on_open_problems_in_3d/,big_man123,1544534115,Like the text above can someone suggest some topics for specifically 3D point cloud data that i can work on. I have a little experience in traditional computer vision and deeplearning ,2,1
77,2018-12-11,2018,12,11,23,a57bs2,Introducing the Interactive Deep Learning Landscape - LF Deep Learning,https://www.reddit.com/r/deeplearning/comments/a57bs2/introducing_the_interactive_deep_learning/,chlordane_zero,1544539111,,0,1
78,2018-12-12,2018,12,12,7,a5blqq,for YOLO V3 which frame work gives faster result?,https://www.reddit.com/r/deeplearning/comments/a5blqq/for_yolo_v3_which_frame_work_gives_faster_result/,niki_niki123,1544566133,"I want to implement YOLO V3. I want to know which framework will give me a faster result. 

what are the advantages of implementing on darknet framework vs Keras?
",3,1
79,2018-12-12,2018,12,12,8,a5cb2x,Digging Deeper into Tensorflow: An Analysis of Google's Patent Policies on Open Source AI Software (4),https://www.reddit.com/r/deeplearning/comments/a5cb2x/digging_deeper_into_tensorflow_an_analysis_of/,PIIP_LAW,1544570722,,1,1
80,2018-12-12,2018,12,12,18,a5gkv2,Real-time Object Detection &amp; Classification with Deep Learning on Raspberry Pi,https://www.reddit.com/r/deeplearning/comments/a5gkv2/realtime_object_detection_classification_with/,seemingly_omniscient,1544606084,"Case Study:

&amp;#x200B;

Real-time object detection and classification with DeepLearning on the Raspberry Pi 3 B+

without connecting to any external web/cloud services

Our approach:

&amp;#x200B;

1. Object detection

HoughCircle Detection (OpenCV)

&amp;#x200B;

2. Object classification

A specially optimized deep learning network is used, which is also performant on computers with limited resources without GPU and can nevertheless achieve relatively high accuracies. Only a small training and test data set are available for the eight different euro coins: 1281 photos for training, 707 for testing. Since the training data set is minimal, so-called transfer learning is used. A pre-trained deep learning network is used, which was trained on the ImageNet training dataset (approx. 1.2 million images from 1000 categories). To make the classification more robust against rotations, brightness, contrast etc., the training images were additionally rotated randomly, and brightness and contrast were changed (data augmentation).

&amp;#x200B;

Achieved validation accuracy: 93.3%\*

&amp;#x200B;

Test accuracy achieved: 93.4%\*

&amp;#x200B;

Runtime for classification: 50ms

&amp;#x200B;

\*strongly dependent on lighting conditions and camera settings

&amp;#x200B;

[https://youtu.be/XVvfcj\_F\_uc](https://youtu.be/XVvfcj_F_uc)",1,1
81,2018-12-13,2018,12,13,1,a5jrf4, TensorFlow Object Detection API Project: Wheat Grains Detector (for Celiac Disease sufferers),https://www.reddit.com/r/deeplearning/comments/a5jrf4/tensorflow_object_detection_api_project_wheat/,dynamicwebpaige,1544632672,"&amp;#x200B;

[Detection of wheat grains in Kasha](https://i.redd.it/drs03hpuiv321.gif)

This project was submitted to the TensorFlow Lite mailing list yesterday:  


**Inspiration:** *Having been diagnosed with Celiac Disease, I have to adhere to a strict gluten-free diet. Long story short: buckwheat (also know as ""kasha"" in the U.S.) is gluten-free. The problem is that sometimes buckwheat groats are contaminated with wheat grains (which contain gluten) due to transportation and packagecircumstances. So I have to sort out such grains before cooking. That is how the idea of this project was born.*  
The project might just be object detection - but I really like the practical use case! Especially as someone who has a family member with Celiac. 

&amp;#x200B;

*Link to the GitHub repo:*   
[https://github.com/failure-to-thrive/wheat-grains-detector](https://github.com/failure-to-thrive/wheat-grains-detector)

&amp;#x200B;

**Other references:**

* TensorFlow Object Detection API: [https://github.com/tensorflow/models/tree/master/research/object\_detection](https://github.com/tensorflow/models/tree/master/research/object_detection)
* Google Colaboratory: [http://colab.research.google.com](http://colab.research.google.com) 
* TensorFlow Lite (for mobile devices): [https://www.tensorflow.org/lite/](https://www.tensorflow.org/lite/)
* OpenCV: [https://opencv.org/](https://opencv.org/)",0,1
82,2018-12-13,2018,12,13,1,a5jtuo,How we built a stand-in robot for remote workers using IoT and computer vision,https://www.reddit.com/r/deeplearning/comments/a5jtuo/how_we_built_a_standin_robot_for_remote_workers/,minmidinosaur,1544633102,"[How we built a stand-in robot for remote workers using IoT and computer vision](https://tryolabs.com/blog/hackathon-robot-remote-work-iot-computer-vision/)

https://i.redd.it/4zhfcgmplv321.jpg",0,1
83,2018-12-13,2018,12,13,5,a5m0n2,A Comprehensive Study of Deep Learning for Image Captioning,https://www.reddit.com/r/deeplearning/comments/a5m0n2/a_comprehensive_study_of_deep_learning_for_image/,Surf4kyle,1544646768,,0,1
84,2018-12-13,2018,12,13,6,a5md0d,2018 in Review: 10 AI Failures,https://www.reddit.com/r/deeplearning/comments/a5md0d/2018_in_review_10_ai_failures/,trcytony,1544648927,,2,1
85,2018-12-13,2018,12,13,14,a5qiji,Can an AI Learn To Draw a Caricature?,https://www.reddit.com/r/deeplearning/comments/a5qiji/can_an_ai_learn_to_draw_a_caricature/,AssCalloway,1544678398,,0,1
86,2018-12-13,2018,12,13,18,a5s1fh,What is Deep Learning and How it Helps to Healthcare Sector?,https://www.reddit.com/r/deeplearning/comments/a5s1fh/what_is_deep_learning_and_how_it_helps_to/,trainingdata,1544693514,,0,1
87,2018-12-13,2018,12,13,20,a5sqmh,How to create dataset for YOLO algorithm?,https://www.reddit.com/r/deeplearning/comments/a5sqmh/how_to_create_dataset_for_yolo_algorithm/,MathKlim,1544700971,"I want to create a YOLO model to detect a specific object. I have been reading some papers and articles about how this algorithm works, but the thing is that I don't know how to create my own dataset. I tried to look for some information, but everything is about preparation of the data, not about creation of it.

&amp;#x200B;

Do you know where can I found some information about this part?",10,1
88,2018-12-13,2018,12,13,22,a5thdm,Try run super-fast deep learning inference on Raspberry Pi in your hand!,https://www.reddit.com/r/deeplearning/comments/a5thdm/try_run_superfast_deep_learning_inference_on/,9_ties,1544707619,,5,1
89,2018-12-14,2018,12,14,2,a5vquz,[NEED HELP/ADVICE] on Auto-clustering,https://www.reddit.com/r/deeplearning/comments/a5vquz/need_helpadvice_on_autoclustering/,Nike_Zoldyck,1544723149,"Is there any algorithm/code/tutorial that lets your neural network figure out what the optimal number of clusters should be , without explicitly having to mention it before running. Perhaps some form of modification to an objective function as penalty? Can someone point me to a good resource or code that does this? ",1,1
90,2018-12-14,2018,12,14,3,a5w61p,Technological Challenges of Deep Learning.,https://www.reddit.com/r/deeplearning/comments/a5w61p/technological_challenges_of_deep_learning/,BlockDelta,1544725795,,0,1
91,2018-12-14,2018,12,14,10,a5zuis,My book 'Deep Learning from first principles:Second Edition' now on Amazon,https://www.reddit.com/r/deeplearning/comments/a5zuis/my_book_deep_learning_from_first_principlessecond/,tvganesh,1544749540,,0,1
92,2018-12-14,2018,12,14,10,a609xn,Low shot learning for image recognition,https://www.reddit.com/r/deeplearning/comments/a609xn/low_shot_learning_for_image_recognition/,ashutosj,1544752726,"I'm working on a project - image recognition with very few images. 
Can anyone suggest good papers for low shot learning.",1,1
93,2018-12-14,2018,12,14,16,a62j3o,Deep Learning Questions Answers For Interview Practice Download PDF:- https://drive.google.com/open?id=1cLyQxkQ3P1ufp9sXsjeBfx20T6TgZ_yH,https://www.reddit.com/r/deeplearning/comments/a62j3o/deep_learning_questions_answers_for_interview/,AtivittiAi,1544771078,,3,1
94,2018-12-14,2018,12,14,20,a63zf4,Wider Channel Attention Network for Remote Sensing Image Super-resolution,https://www.reddit.com/r/deeplearning/comments/a63zf4/wider_channel_attention_network_for_remote/,tennant19,1544786479,,0,1
95,2018-12-14,2018,12,14,20,a642to,How to detect logos in scanned documents,https://www.reddit.com/r/deeplearning/comments/a642to/how_to_detect_logos_in_scanned_documents/,arush1836,1544787454,"We have bunch of scanned documents and we want to detect logos of the company (present at the top of the document). We tried image processing techniques using opencv but not getting satisfactory results. There around 400 different classes of logos, Should we try deep learning based approaches.",2,1
96,2018-12-15,2018,12,15,0,a65yf2,"Animated RNN, LSTM and GRU",https://www.reddit.com/r/deeplearning/comments/a65yf2/animated_rnn_lstm_and_gru/,raibosome,1544802601,,3,1
97,2018-12-15,2018,12,15,3,a67k9x,PyText: A natural language modeling framework based on PyTorch,https://www.reddit.com/r/deeplearning/comments/a67k9x/pytext_a_natural_language_modeling_framework/,QuirkySpiceBush,1544812927,,0,1
98,2018-12-15,2018,12,15,5,a68n2d,Here's a question.,https://www.reddit.com/r/deeplearning/comments/a68n2d/heres_a_question/,Hypersapien,1544820006,"Has anyone ever turned neural networks on themselves? Gotten them to analyze other neural networks, or even maps of their own network, to understand better how they work?",0,1
99,2018-12-15,2018,12,15,8,a69ys1,GAN 2.0: NVIDIAs Hyperrealistic Face Generator,https://www.reddit.com/r/deeplearning/comments/a69ys1/gan_20_nvidias_hyperrealistic_face_generator/,gwen0927,1544829146,,1,1
100,2018-12-15,2018,12,15,15,a6d8af,Deep Learning and Neural Network,https://www.reddit.com/r/deeplearning/comments/a6d8af/deep_learning_and_neural_network/,Nishujanu1209,1544857143,,0,1
101,2018-12-15,2018,12,15,17,a6dmwa,Internet of Shopping (IoS) - Is this the future?,https://www.reddit.com/r/deeplearning/comments/a6dmwa/internet_of_shopping_ios_is_this_the_future/,BlockDelta,1544861725,,0,1
102,2018-12-15,2018,12,15,17,a6ds5h,How can I use a pre-trained CNN model to get the features of images?,https://www.reddit.com/r/deeplearning/comments/a6ds5h/how_can_i_use_a_pretrained_cnn_model_to_get_the/,DrifterFun,1544863532,"Dear community:

I noticed that many CNN model require to fix image size as input. However, I want to get CNN-based features from high-resolution images(1920 \* 1080) with a  pre-trained CNN model (such as RESNET). Could you please share me with some idea to use a pre-trained CNN model to get the features of images. ",1,1
103,2018-12-15,2018,12,15,20,a6em2p,Deploy keras app,https://www.reddit.com/r/deeplearning/comments/a6em2p/deploy_keras_app/,ashutosj,1544873985,"I made a model in keras that classifies flowers from image.
Now I've to make an ios app that will take photo and call server, which will process image and return flower class.
Has anyone any idea how to do it and where to deploy the server for free.",0,1
104,2018-12-15,2018,12,15,21,a6eu9i,GitXiv: Collaborative Open Computer Science,https://www.reddit.com/r/deeplearning/comments/a6eu9i/gitxiv_collaborative_open_computer_science/,donutloop,1544876804,,4,1
105,2018-12-15,2018,12,15,23,a6ffxz,[Project] The TL;DR Challenge,https://www.reddit.com/r/deeplearning/comments/a6ffxz/project_the_tldr_challenge/,codemetro,1544882905,,0,1
106,2018-12-16,2018,12,16,3,a6hbwo,How to blurr or remove background in the following image. I just want the side view of the book.,https://www.reddit.com/r/deeplearning/comments/a6hbwo/how_to_blurr_or_remove_background_in_the/,ashutosj,1544897295,,4,1
107,2018-12-16,2018,12,16,3,a6hlu3,Can Capsule Network be applied to graph Convolutional Network,https://www.reddit.com/r/deeplearning/comments/a6hlu3/can_capsule_network_be_applied_to_graph/,pcidev,1544899240,"I am thinking that as Capsule network overcome the problem  of pooling function ( information loss and other). Can anyone explain how can we extend the idea of Capsule network to graph convolutional network ?  
",0,1
108,2018-12-16,2018,12,16,5,a6io0n,Tensorflow or Pytorch? What do you prefer?,https://www.reddit.com/r/deeplearning/comments/a6io0n/tensorflow_or_pytorch_what_do_you_prefer/,dchasani,1544906638,"So, I've got a project, (my final dissertation) and I have a multilabel classification task. What framework do you guys prefer to develop in? Why is that? I started with tensorflow and keras, then switched to pytorch just to have a taste of both but now that I really have to decide I'm torn. 

Any suggestions? ",14,1
109,2018-12-16,2018,12,16,6,a6jb1k,Nerd help with vocabulary,https://www.reddit.com/r/deeplearning/comments/a6jb1k/nerd_help_with_vocabulary/,seb59,1544911092,"I come from the control engineering community and I'm new to Deep learning.
I struggle with some concepts such as 'prior' and 'latent'.
Could you provide me some link to some explanations for newbie, please? 

Thanks for your help. ",4,1
110,2018-12-16,2018,12,16,12,a6ls1u,Using Text to speech models for creating online Tutorial,https://www.reddit.com/r/deeplearning/comments/a6ls1u/using_text_to_speech_models_for_creating_online/,Vurtne94,1544930581,,5,1
111,2018-12-16,2018,12,16,14,a6mh44,Tensor Transport Protocol (TTP) - Inspired From Distributed TensorFlow / TF Serving!,https://www.reddit.com/r/deeplearning/comments/a6mh44/tensor_transport_protocol_ttp_inspired_from/,TensorTask,1544936928,,1,1
112,2018-12-16,2018,12,16,17,a6nmb2,What are some of the areas in deeplearning which are recently in demand these days?,https://www.reddit.com/r/deeplearning/comments/a6nmb2/what_are_some_of_the_areas_in_deeplearning_which/,proread7,1544949852,,1,1
113,2018-12-16,2018,12,16,20,a6ohy1,Whats the best resource for learning Reinforcement Learning?,https://www.reddit.com/r/deeplearning/comments/a6ohy1/whats_the_best_resource_for_learning/,BrunoMelicio,1544961309,"I am an undergraduate computer science student and Im currently studying deep learning. So far, I have only worked with supervised and unsupervised learning.
Now I want to learn Reinforcement Learning, where can I start? ",10,1
114,2018-12-16,2018,12,16,21,a6or4l,Qualify words by how good they sound,https://www.reddit.com/r/deeplearning/comments/a6or4l/qualify_words_by_how_good_they_sound/,hega72,1544964362,"Is there anything available on this topic ?
Basically I want to train a net with a given collection of words that are sounding good
And then I would like to get back a scoring for each new word I present to the network. 
Any help appreciated ",2,1
115,2018-12-17,2018,12,17,1,a6qb8i,Robots were allowed to kill people. Machine learning,https://www.reddit.com/r/deeplearning/comments/a6qb8i/robots_were_allowed_to_kill_people_machine/,cmillionaire9,1544977510,,0,1
116,2018-12-17,2018,12,17,5,a6set5,Input normalization time-series in an feedforward NN.,https://www.reddit.com/r/deeplearning/comments/a6set5/input_normalization_timeseries_in_an_feedforward/,ranirlol,1544991254,"  

I want to use a feed forward NN where the input is a vector of different types of time series. Here are the three types of time series I'm using:

1) I know the actual distribution of this input and it has a known trend overtime. This means that I can use a Z-normalization or a min-max normalization to be between \[0,1\]. 

2) The distribution is unknown and unbounded. I tried to use a running-average Z-normalization (compute the mean and std of that variable up until that time). 

3) A discrete set of values {h,2h,...,Nh} where h and N are known. Their values are much smaller than the other categories (h = 1/252 and N is a small known positive integer). For example: {1/252,2/252,...,15/252} and they are equally possible to be observed.

My questions are:

A) Should I try to use the same normalization for each input or should I try different normalization for each of the input categories?

B) Following on question A), is the goal of normalizing the features is to have similar domains for each feature? For example, a Z-normalization would be possible for the categories 1-2. Should I also use a Z-normalization for the third category? The third category is not at not Gaussian at all, it's a discrete uniform. 

My overall comprehension of normalizing the features is that they should be in the same domain since when you take a gradient step, you use a common learning rate for each feature. Having the same domain for each feature should help the learning overtime. Is this correct?

  
Thanks a lot!  
",0,1
117,2018-12-17,2018,12,17,7,a6tvfu,Eye dataset,https://www.reddit.com/r/deeplearning/comments/a6tvfu/eye_dataset/,BrunoMelicio,1545001106,"Im an undergraduate computer science student and Im currently working on my final year project. Im making an application that lets a user control his/her wheelchair with his/her eyes.
Im using supervised learning for the recognition of the eye movement.
For example: if the user is looking right, then the wheelchair turns right.

Unfortunately my model has a low accuracy on test set. So I need help in finding eye datasets. If possible datasets of people looking right, left, up or down.

Thank you",3,1
118,2018-12-17,2018,12,17,12,a6w6zx,Deep Learning Learning Path,https://www.reddit.com/r/deeplearning/comments/a6w6zx/deep_learning_learning_path/,souvikb07,1545018472,"Hey Everyone,

I am thinking of doing the Deep Learning Nanodegree by Udacity. Is Deep Learning Nanodegree have good material to learn or are there any better resources to learn Deep Learning?
Please help me out.",8,1
119,2018-12-17,2018,12,17,14,a6wqkt,XNOR and XOR functions using neural net. [Hindi],https://www.reddit.com/r/deeplearning/comments/a6wqkt/xnor_and_xor_functions_using_neural_net_hindi/,Neel_kamal_sahu,1545022984,,0,1
120,2018-12-17,2018,12,17,17,a6xvne,Current feel a few months into my research,https://www.reddit.com/r/deeplearning/comments/a6xvne/current_feel_a_few_months_into_my_research/,bossk91,1545033773,,3,1
121,2018-12-17,2018,12,17,22,a6zujo,PyTorch Deep RL Implementations code review,https://www.reddit.com/r/deeplearning/comments/a6zujo/pytorch_deep_rl_implementations_code_review/,1243141deep_rl_14141,1545053661,"I have written some PyTorch implementations of RL algorithms here: [https://github.com/p-christ/Deep\_RL\_Implementations](https://github.com/p-christ/Deep_RL_Implementations)

&amp;#x200B;

Please let me know what you think of this and if you have any ideas on how i could improve the repository?",1,1
122,2018-12-18,2018,12,18,1,a71dey,Transfer Learning - SpongeBob SquarePants Character Recogniser,https://www.reddit.com/r/deeplearning/comments/a71dey/transfer_learning_spongebob_squarepants_character/,Laboratory_one,1545064714,,2,1
123,2018-12-18,2018,12,18,1,a71f3j,Anyone interested in deploying keras/tensorflow model on Heroku,https://www.reddit.com/r/deeplearning/comments/a71f3j/anyone_interested_in_deploying_kerastensorflow/,ashutosj,1545065013,,0,1
124,2018-12-18,2018,12,18,4,a731l4,[BEGINNER TUTORIAL] Build a lane detector,https://www.reddit.com/r/deeplearning/comments/a731l4/beginner_tutorial_build_a_lane_detector/,affinitive2,1545075206,"Step-by-step beginners tutorial on building a lane detector.

[https://medium.com/@chuanenlin/tutorial-build-a-lane-detector-679fd8953132](https://medium.com/@chuanenlin/tutorial-build-a-lane-detector-679fd8953132)

Feel free to check it out and kindly smash the clap button if you found it useful!",1,1
125,2018-12-18,2018,12,18,15,a78oab,"ML-Agents v0.6, Scriptable Object Brains, Demonstration Recorder",https://www.reddit.com/r/deeplearning/comments/a78oab/mlagents_v06_scriptable_object_brains/,leonchenzhy,1545115703,,0,1
126,2018-12-18,2018,12,18,17,a794z5,Implementing ssd from scratch.,https://www.reddit.com/r/deeplearning/comments/a794z5/implementing_ssd_from_scratch/,sanchit2843,1545120410,Can anyone help me or sahre a resource to implement single shot multibox detector(ssd) from scratch in keras tensorflow or pytorch. ,2,1
127,2018-12-18,2018,12,18,21,a7aka2,3 ways how deep learning can solve global warming &amp; climate change,https://www.reddit.com/r/deeplearning/comments/a7aka2/3_ways_how_deep_learning_can_solve_global_warming/,alzador123,1545135460,,0,1
128,2018-12-19,2018,12,19,0,a7bx88,Nvidia learned to make realistic faces,https://www.reddit.com/r/deeplearning/comments/a7bx88/nvidia_learned_to_make_realistic_faces/,cmillionaire9,1545146245,,3,1
129,2018-12-19,2018,12,19,0,a7bz7h,Free credits for cloud GPU instances for deep learning,https://www.reddit.com/r/deeplearning/comments/a7bz7h/free_credits_for_cloud_gpu_instances_for_deep/,whitezl0,1545146631,"Hi, I am offering free credits for you to access 1080Ti GPU instances for deep learning purposes.

I am a co-founder of Tensorpad; where we are creating a service for   AI startups to train neural networks. We have paid traffic, but some   servers are idle. Hence, we are offering some credits for free, so that   students, startups, and others can benefit from ML technologies and  help  us by using our product and providing honest feedback for us to   improve.

You can Sign Up at [https://dashboard.tensorpad.com/signup](https://dashboard.tensorpad.com/signup) and redeem the code ""REDDIT200"" in the Billing tab.

Hope this explains our story and motivation for providing free credits.

Here is additional information:  

\* The instances have 16GB RAM, 4 CPUs cores and one 1080Ti GPU. You can run multiple instances in parallel  

\* You get access to the JupyterLab environment  

\* We have pre-installed Tensorflow, Keras, and other ML frameworks  

\* You can access the terminal through the JupyterLab  

\* By default, persistent storage is enabled  

\* Here are the available software versions [https://docs.tensorpad.com/jobs\_env/](https://docs.tensorpad.com/jobs_env/) For extra free trial hours, use promo code: reddit200

And for questions, please contact me at [ilie@tensorpad.com](mailto:ilie@tensorpad.com). I am looking forward to seeing you on our platform! Sincerely, Ilie Diacov Co-founder and UX researcher at Tensorpad",2,1
130,2018-12-19,2018,12,19,0,a7c4a1,2018 in Review: 10 AI Quotes,https://www.reddit.com/r/deeplearning/comments/a7c4a1/2018_in_review_10_ai_quotes/,gwen0927,1545147577,,0,1
131,2018-12-19,2018,12,19,4,a7e5tb,"I want to make comparison between different NN, how do I make fair comparisons?",https://www.reddit.com/r/deeplearning/comments/a7e5tb/i_want_to_make_comparison_between_different_nn/,LargeKernels,1545160422,"Say that I have a classification task, and I use different architectures / algorithms in my program. And I want to analyze the computational cost / efficiency, by reserving a certain amount of processing power in CPU or GPU such that the if I run these two different programs for a set amount of time, the computer have still consumed the same amount of FLOPS, and then compare results.   


Last time, I fucked up severly by training a NN, and then trying compare it with another NN, but the other time I had some movie rendering in the background. I would like to avoid this situation, but still like to do rendering at the same time lol.",0,1
132,2018-12-19,2018,12,19,4,a7edlv,I'm finding papers about theoretical explanation of adversarial examples,https://www.reddit.com/r/deeplearning/comments/a7edlv/im_finding_papers_about_theoretical_explanation/,yiwan99,1545161754,"I'm beginner for adversarial examples(AEs), and studying about principle and basic fooling methods.

As far as i know, neural network can be easily fooled by AEs, since most of data points have highly steep gradient(dL/dx).

There are so many fooling methods and papers... but what I want to know is, 'why does AE exists?'

Is there any connection between optimization(e.g. crossentropy and ML..) and AEs?",2,1
133,2018-12-19,2018,12,19,6,a7fr3z,Modify Facial Features.,https://www.reddit.com/r/deeplearning/comments/a7fr3z/modify_facial_features/,throwaway201084,1545170343,"I have a large amount of before-after plastic surgery pictures. What algorithms can I use to modify the facial features of a person based on that training data?

I've looked into CycleGAN but it's a different problem because it only considers two sets of images (source and destination) and not paired images such as before-after pictures.

Can you recommend any Neural Net in the literature to solve this problem?",1,1
134,2018-12-19,2018,12,19,7,a7fv9p,What's the start point of studying reinforcement learning?,https://www.reddit.com/r/deeplearning/comments/a7fv9p/whats_the_start_point_of_studying_reinforcement/,Anton1287,1545171071,"Hello guys! I want to know more about reinforcement learning. Currently I have experience in other field of neural networks, that's why I want some seriouse courses or maybe lectures, books etc  
Thanks)",2,1
135,2018-12-19,2018,12,19,13,a7j8x7,Confused with how to plot a 3D surface graph,https://www.reddit.com/r/deeplearning/comments/a7j8x7/confused_with_how_to_plot_a_3d_surface_graph/,Cyclonedx,1545195356,"Hey everyone, been super confused with something Ive been asked to do. I basically have a model that predicts a value based off 3 variables. Ive been asked to plot a 3D graph of this data with a surface connecting the points. I need to plot 2 surfaces on the same graph, one showing predictions from training data and the other showing predictions from test data.

I dont really understand this though. How can I plot a 4th variable (predicted value) on a graph which only has 3?",1,1
136,2018-12-19,2018,12,19,14,a7jcli,Which framework do you use to load and predict pre-trained tensorflow models in Java?,https://www.reddit.com/r/deeplearning/comments/a7jcli/which_framework_do_you_use_to_load_and_predict/,melonochelo,1545196182,"I found deeplearning4j, TensorFlow Lite, TensorFlow for Java.

https://deeplearning4j.org/docs/latest/keras-import-model-import
https://www.tensorflow.org/lite/
https://www.tensorflow.org/install/lang_java

My application runs mostly on PC and uses the latest and greatest NVIDIA GPUs. 

Which library do you use/trust the most?",1,1
137,2018-12-19,2018,12,19,16,a7k59a,Should we look into this?,https://www.reddit.com/r/deeplearning/comments/a7k59a/should_we_look_into_this/,martian_rover,1545203489,,0,1
138,2018-12-19,2018,12,19,16,a7k5pc,ground-truth model of the environment is usually not available to the agent,https://www.reddit.com/r/deeplearning/comments/a7k5pc/groundtruth_model_of_the_environment_is_usually/,sriharsha_0806,1545203608,"Hi, I am reading Reinforcement Learning spiningup of OpenAI. I came across this sentence which is a con for Model-Based RL ""ground-truth model of the environment is usually not available to the agent. If an agent wants to use a model in this case, it has to learn the model purely from experience, which creates several challenges"". Can anyone help me understand this concept? 

Ref: [https://spinningup.openai.com/en/latest/spinningup/rl\_intro2.html](https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html)

&amp;#x200B;",2,1
139,2018-12-19,2018,12,19,16,a7k629,Anyone tried to use Google Colab with local runtime support?,https://www.reddit.com/r/deeplearning/comments/a7k629/anyone_tried_to_use_google_colab_with_local/,aashwin93,1545203709,"If anyone here would be kind enough to help me with the following two queries, I would really appreciate it :-

1)Does running a local instance mean that I won't have access to the K80? I mean, it but what exactly is the purpose behind this option being there if everything is done at my end?

2)When running locally, why is the colab environment not recognizing locally installed drivers and packages?",13,1
140,2018-12-19,2018,12,19,17,a7kfp7,How transition from image processing job to DL?,https://www.reddit.com/r/deeplearning/comments/a7kfp7/how_transition_from_image_processing_job_to_dl/,thraway14,1545206464,"I currently work on image processing code in Matlab and make around 100k/yr as a contractor. My supervisor lets me work remotely the whole time. I've worked in this role for a year, but I did spend about a couple months working on deconvolution projects using deep learning

The image processing projects have been less interesting than the deconvolution/deep learning. My guess is that for this upcoming year I will again spend most of the time working on image processing instead of deep learning

I like my supervisor and that I get to work remotely the whole time, so I prefer not leaving this job unless the new job also lets me work remotely, I'm sure I can get along with the new team, and they offer me a higher salary and they let me work on more deep learning. 

Am I better off just sticking with my current job and asking if I can work on more deep learning? Or should I seek deep learning roles elsewhere? Would I likely get a much higher salary in deep learning? How should I spend my free time so I can be more attractive for deep learning jobs?",1,1
141,2018-12-19,2018,12,19,17,a7knc9,What is deep learning? What are its benefits?,https://www.reddit.com/r/deeplearning/comments/a7knc9/what_is_deep_learning_what_are_its_benefits/,greatlearning1,1545208749,,0,1
142,2018-12-19,2018,12,19,17,a7kppq,Top 10 Applications of Deep Learning,https://www.reddit.com/r/deeplearning/comments/a7kppq/top_10_applications_of_deep_learning/,greatlearning1,1545209501,,0,1
143,2018-12-19,2018,12,19,18,a7krcb,How would you criticize deep learning?,https://www.reddit.com/r/deeplearning/comments/a7krcb/how_would_you_criticize_deep_learning/,xxANONYMxx,1545210015,"I have to do a presentaion about deep learning and the critic of my topic is very important... but I am not able to come up with disadvantages of deep learning.

My solution:  
Ask the subreddit dedicatet to deep learning!",5,1
144,2018-12-19,2018,12,19,21,a7m0vc,"Text generation from structured data, METHOD?",https://www.reddit.com/r/deeplearning/comments/a7m0vc/text_generation_from_structured_data_method/,nreininho,1545222930,"Hi, 
I'm currently doing my thesis about chatbots and my goal is to make a functional chatbot for credit solutions.
Right now, I using a framework that can understand what the user wants and passed it to a JSON file. 
My question is: is there any method in deep learning to generate text that makes sense from a structured data, like Json or something, to implement in the chatbot?",0,1
145,2018-12-19,2018,12,19,22,a7m8um,Need help in implementing custom attention models in keras,https://www.reddit.com/r/deeplearning/comments/a7m8um/need_help_in_implementing_custom_attention_models/,learner_version0,1545224797,"Hi everyone,

I am working on a problem where there are pairs of question and answer, and a label(0,1) denoting whether the answer is relevant to the question. For each question I have 9 answers with label 0 and only 1 answer with label 1.

I am trying to implement a custom attention-based recurrent network in Keras to incorporate question information into answer representation. The implementation is based on this paper ""R-NET: MACHINE READING COMPREHENSION WITH SELF-MATCHING NETWORKS"".Link: [https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf) Section 3.2 contains the details of the attention model.

I am new to keras and have been struggling with this code.The code may contain other errors too. Your help will be much appreciated.

Link to the code: [https://stackoverflow.com/questions/53851836/custom-attention-layer-in-keras](https://stackoverflow.com/questions/53851836/custom-attention-layer-in-keras)

Thanks a lot!",0,1
146,2018-12-19,2018,12,19,23,a7mra0,"Image, Ground Truth and an extra parameter",https://www.reddit.com/r/deeplearning/comments/a7mra0/image_ground_truth_and_an_extra_parameter/,phoenixlads,1545228859,"So, I have to train a network where I have an image, ground-truth, and an extra parameter related to an image (current image state). 

There's a camera which captures images at different zoom level. For a particular surrounding, I have four images with different zoom levels (0,25,50,75). I need to train the network such that given a test image, I can classify if I want to zoom in or zoom out. 

So, the dataset I have is the image, ground-truth (zoom in or zoom out or no zoom), and the current zoom level. 

How can I add this current zoom level in my network so that the network trains properly?",7,1
147,2018-12-20,2018,12,20,0,a7n6ch,GOTO 2018  (Deep) Learning to Fly  Krzysztof Kudrynski &amp; Blazej Kubiak,https://www.reddit.com/r/deeplearning/comments/a7n6ch/goto_2018_deep_learning_to_fly_krzysztof/,rick-rebel,1545231896,,0,1
148,2018-12-20,2018,12,20,0,a7na68,What various types of inputs are used in deep learning?,https://www.reddit.com/r/deeplearning/comments/a7na68/what_various_types_of_inputs_are_used_in_deep/,mr_meeesix,1545232603,"I've worked with CNN's and majority of the places where I've seen deep learning being used are with Images. What kind of other inputs are used to train? Audio signals, lidar, corpus are sources which are used but don't exactly know how",0,1
149,2018-12-20,2018,12,20,0,a7ncbn,How to run the tensorflow shell on Cluster server,https://www.reddit.com/r/deeplearning/comments/a7ncbn/how_to_run_the_tensorflow_shell_on_cluster_server/,Wsnow99,1545233010,"There is a Cluster server in my college,and I want to run my tensorflow shell(made by python) on it,but it should be submitted by PBS shell,but I don't know how to write it.",1,1
150,2018-12-20,2018,12,20,1,a7nq57,NeurIPS 2018 Through the Eyes of First-Timers,https://www.reddit.com/r/deeplearning/comments/a7nq57/neurips_2018_through_the_eyes_of_firsttimers/,gwen0927,1545235566,,0,1
151,2018-12-20,2018,12,20,2,a7opln,The major advancements in Deep Learning in 2018,https://www.reddit.com/r/deeplearning/comments/a7opln/the_major_advancements_in_deep_learning_in_2018/,minmidinosaur,1545241845,"[The major advancements in Deep Learning in 2018](https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/)

https://i.redd.it/cy4bhrqov9521.png",0,1
152,2018-12-20,2018,12,20,4,a7px6r,Does anyone know a good book on RNNs?,https://www.reddit.com/r/deeplearning/comments/a7px6r/does_anyone_know_a_good_book_on_rnns/,TheHawkGriffith,1545249460,"I have a decent grasp of MLPs and CNNs, have made many fairly-working models myself. 
Although I always struggle when it comes to RNNs, the sequential output and modelling seems difficult for me to wrap my head around. 

Any suggestions on any good books or articles that can help me and dont try to sound too smart and abstract? ",7,1
153,2018-12-20,2018,12,20,5,a7q5tm,Is anyone working with aws deeplearning ami for gpus in deep learning??,https://www.reddit.com/r/deeplearning/comments/a7q5tm/is_anyone_working_with_aws_deeplearning_ami_for/,karanbangia14,1545250937,i am having doubt and difficulties using some of the functionality any help is appreciated.,13,1
154,2018-12-20,2018,12,20,6,a7qk0o,Does anyone know which Atari game environments are the least complex?,https://www.reddit.com/r/deeplearning/comments/a7qk0o/does_anyone_know_which_atari_game_environments/,platinumbjj,1545253415,I am trying to train my DQN on atari gym environments but some environments are taking too long. I have tried it on Cartpole and verified my code works but its taking too long to train on environments like MsPacman. Could you guys suggest some environments that will be less complex and will train faster? Thanks!,1,1
155,2018-12-20,2018,12,20,11,a7tcdw,How is udemy's the self driving car complete course is ? is it in any comparison with udacity's one?,https://www.reddit.com/r/deeplearning/comments/a7tcdw/how_is_udemys_the_self_driving_car_complete/,karanbangia14,1545272444,,5,1
156,2018-12-20,2018,12,20,21,a7xedd,First complete online course on Generative Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/a7xedd/first_complete_online_course_on_generative/,martinmusiol14,1545308587,"There is an online course on Generative AI coming up. --&gt; [https://generativeai.net/](https://generativeai.net/)

As I believe Generative AI will affect the way we create content and develop products, this course is really valuable .

Perhaps interesting to you?",11,1
157,2018-12-21,2018,12,21,3,a80qp4,Botty Media - How Can We Eradicate Fake News?!,https://www.reddit.com/r/deeplearning/comments/a80qp4/botty_media_how_can_we_eradicate_fake_news/,BlockDelta,1545329889,,1,1
158,2018-12-21,2018,12,21,3,a80v1i,To anyone who is a professional ML/DL Engineer or works in an equivalent field. I have a question!,https://www.reddit.com/r/deeplearning/comments/a80v1i/to_anyone_who_is_a_professional_mldl_engineer_or/,TheHawkGriffith,1545330588,"Professionally, take it job descriptions or practically, do you NEED to know and be able to apply every Deep Learning model/technique to get hired? 
Cause every subfield seems quite vast and requires mastery in and of itself, should I dive deep into the mechanisms of every popular architecture there is, including Supervised, Unsupervised (AutoEncoders, GANs, HMMs) that sorta thing? 
Or just know how these work and have an intuitive understanding of them but continue to thoroughly know what my interests deem best? 
For me thats personally Deep Reinforcement Learning. 
:3 
Sorry if the question feels opinionated, but thats what I want from you people. 
I have no friends or family that bear knowledge of this field that can guide me through so, here I am. 
Thank you in advanced. ",7,1
159,2018-12-21,2018,12,21,4,a81qkn,Word embedding as a channel in a convolutional network,https://www.reddit.com/r/deeplearning/comments/a81qkn/word_embedding_as_a_channel_in_a_convolutional/,hswerdfe,1545335671,"I had a thought and I just assume somebody else has already done it, so I was hoping somebody could point me to resources on this either code or papers.

Problem: train classifier on scans of documents

Idea:

 1. Train a very small vector for word embedding via the skip gram model

 2.  Use an existing pipeline to OCR the scanned documents (tesseract)

 3.  down sample the scanned document Image

 4. Append The word vector as a series of channels to the scanned document image

5. train the classifier

So if anybody knows what this is called or papers that have attempted this (successfully or not) I would appreciate links

Thanks",3,1
160,2018-12-21,2018,12,21,4,a81qug,What is machine intelligence &amp; how can we measure it?,https://www.reddit.com/r/deeplearning/comments/a81qug/what_is_machine_intelligence_how_can_we_measure_it/,prnvb,1545335715,,1,1
161,2018-12-21,2018,12,21,12,a861kd,Backpropagation equation confusion.,https://www.reddit.com/r/deeplearning/comments/a861kd/backpropagation_equation_confusion/,TheHawkGriffith,1545364219,"So I know how backpropagation works, we need the gradient of the cost function wrt every weight there is, and we keep using the chainrule till we find the equation that is {del J/del wij}. 
But whenever I see some literature use a weights matrix itself, and then compute the gradient of the loss function to it. 
Theres some fancy Harmard Products and matrix transposes going on. 
Can someone explain or reference me to a clear article or paper that explains this? ",8,1
162,2018-12-21,2018,12,21,17,a882t4,Suggestions for architecture to be used in ASL recognition,https://www.reddit.com/r/deeplearning/comments/a882t4/suggestions_for_architecture_to_be_used_in_asl/,Withered_Shadow,1545381847,"Hey,
I'm currently working on a project to detect and recognise American Sign Language from real time video capture. I take each frame, process it and remove only the region having the hand. Now I would like to know any architecture or tips about implementation of the machine learning part. I have already tried GoogLenet and Inception architectures. They don't provide sufficient accuracy. I also tried a combination of the two. I'm currently trying Yolo, but it takes very long to train. I want to know if there are any better architecture suited for the task

Thanks",13,1
163,2018-12-21,2018,12,21,18,a886qj,Hands-on Deep Learning Course,https://www.reddit.com/r/deeplearning/comments/a886qj/handson_deep_learning_course/,DowntownDark,1545382989,[removed],0,1
164,2018-12-21,2018,12,21,19,a88nx7,Deep Learning concepts in a simple way.,https://www.reddit.com/r/deeplearning/comments/a88nx7/deep_learning_concepts_in_a_simple_way/,BrunoMelicio,1545387560,"Hello, Im an undergraduate computer science student and Im going to talk on a workshop about Deep Learning! How can I explain Deep Learning in a simple way to someone that doesnt know/understand anything about it? 
",2,1
165,2018-12-21,2018,12,21,22,a89yvh,Laptop for Deep Learning/Machine Learning,https://www.reddit.com/r/deeplearning/comments/a89yvh/laptop_for_deep_learningmachine_learning/,MashkurAhmed,1545398814,"Hi,

I am a beginner in Machine Learning. I found out that gaming laptops are better suited for it. Is gtx 1060 Maxq laptop considerbly better compared to gtx 1060 in performance for deep learning? What I understand from reviews that as far gaming is concerned it makes less difference. But will it have considerable performance when it comes to deep learning?",33,1
166,2018-12-21,2018,12,21,23,a8ajrx,"Using Sentence Embeddings to Automate Customer Support, Part One",https://www.reddit.com/r/deeplearning/comments/a8ajrx/using_sentence_embeddings_to_automate_customer/,pirate7777777,1545402889,,0,1
167,2018-12-22,2018,12,22,4,a8dkm9,How deep learning helped to map every solar panel in the US,https://www.reddit.com/r/deeplearning/comments/a8dkm9/how_deep_learning_helped_to_map_every_solar_panel/,CodingAdan,1545421122,,0,1
168,2018-12-22,2018,12,22,5,a8e4vf,"""Math is forever."" - Interview with NeurIPS 2018 Best Paper team",https://www.reddit.com/r/deeplearning/comments/a8e4vf/math_is_forever_interview_with_neurips_2018_best/,gwen0927,1545424642,,0,1
169,2018-12-22,2018,12,22,16,a8iwdi,tf.map_fn() doesn't work as expected,https://www.reddit.com/r/deeplearning/comments/a8iwdi/tfmap_fn_doesnt_work_as_expected/,ImaginaryAnon,1545463350,[removed],0,1
170,2018-12-22,2018,12,22,18,a8jnt6,CPU vs. Colab GPU,https://www.reddit.com/r/deeplearning/comments/a8jnt6/cpu_vs_colab_gpu/,nagellette,1545472355,"Hi,

&amp;#x200B;

I'm running same model on my laptop (with no NVidia GPU) and on Colab (with GPU support). I observe that it's running faster on my labtop vs. Colab. Running code is using Tensorflow and the model is an RNN.

&amp;#x200B;

Anyone observerrd the same?",15,1
171,2018-12-23,2018,12,23,1,a8m0z2,Learn Data Science  Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/a8m0z2/learn_data_science_deep_learning_in_python/,jhncna,1545495430,,0,1
172,2018-12-23,2018,12,23,3,a8nc2w,Looking for an open-source implementation of a DC-GAN or similar for producing faces and portraits using wiki-art,https://www.reddit.com/r/deeplearning/comments/a8nc2w/looking_for_an_opensource_implementation_of_a/,CLugis,1545504725,"I am looking for recommendations of an open source GAN implementation I can use to make some 256x256 images based on wikiart and similar datasets, using AWS. Implementations with pre-trained networks (for making new images or for transfer learning) would be even better.

I am definitely interested in all the gory details of coding GANs from scratch, but I'm even more interested in getting results to incorporate in my art practice. 

I have had some success making low res (64x64 pix) images using a DC GAN pytorch implementation [https://github.com/pytorch/examples/tree/master/dcgan](https://github.com/pytorch/examples/tree/master/dcgan)

Most of the other repos I've tried to run are no longer maintained (e.g. [https://github.com/robbiebarrat/art-DCGAN](https://github.com/robbiebarrat/art-DCGAN) and  [https://github.com/rkjones4/GANGogh](https://github.com/rkjones4/GANGogh) ) and I can't get them to run. 

I am not a comp sci whiz, but as far as I can tell the various libraries have moved on and the code is no longer compatible with the up to date AMI I am installing with AWS. I have spent countless hours trying to install old versions of stuff, with no success. In other cases, the code is set up to run on standard datasets, but I struggle (and fail) to get it to work with images I select or any resolution other than the default. 

Any help you can offer a beginner would be greatly appreciated!",2,1
173,2018-12-23,2018,12,23,4,a8ngj9,Do i need to download datasets locally then upload to aws s3 bucket or there is an efficient way??,https://www.reddit.com/r/deeplearning/comments/a8ngj9/do_i_need_to_download_datasets_locally_then/,karanbangia14,1545505596,,2,1
174,2018-12-23,2018,12,23,7,a8p87g,Information Theory of Deep Learning - Explained,https://www.reddit.com/r/deeplearning/comments/a8p87g/information_theory_of_deep_learning_explained/,adityashrm21,1545518109,"I wrote a blog post on the research done by Prof. Naftaly Tishby on Information Theory of Deep Learning ([https://adityashrm21.github.io/Information-Theory-In-Deep-Learning/](https://adityashrm21.github.io/Information-Theory-In-Deep-Learning/)).

He recently gave a talk on the topic at Stanford University. It gave me a new perspective to look at DNNs. Tishby's claims were disregarded for DNNs with ReLUs but a recent paper supports his research with using Mutual Information in NNs with ReLUs. [https://arxiv.org/abs/1801.09125](https://arxiv.org/abs/1801.09125)

Hope this helps someone else too and will give you an overview of the research in a lesser amount of time.

PS: I am new to information theory.",6,1
175,2018-12-23,2018,12,23,9,a8qb1c,Wanted: a trained model that can distinguish between speech and other sounds),https://www.reddit.com/r/deeplearning/comments/a8qb1c/wanted_a_trained_model_that_can_distinguish/,41br05,1545526222,"Hi everyone,  
I'm looking for a trained model that can classify an audio file as speech or other sounds (music, noise, ambient etc.)  
I'd be very grateful if someone could at least point me to the right direction. Thanks!",1,1
176,2018-12-23,2018,12,23,14,a8scr4,How does GAN work in text to image conversion ?,https://www.reddit.com/r/deeplearning/comments/a8scr4/how_does_gan_work_in_text_to_image_conversion/,Bishwa12,1545544421,"In testing dataset suppose we have a text and image of it. Now generator generates the text and compares with the image. But in live how the image produced by the generator is checked whether it is accurate or not since we don't have data related to it now, just we have is text description ?  
For example, initially I have flowers and birds data for testing now if I say I want a red apple. What's the logic now ?

And how does it knows that apple has this kind of image from the text only ? Does it uses NLP ? ",1,1
177,2018-12-24,2018,12,24,12,a91a38,How Neural Networks Work- Simply Explained!,https://www.reddit.com/r/deeplearning/comments/a91a38/how_neural_networks_work_simply_explained/,DiscoverAI,1545621829,,0,1
178,2018-12-24,2018,12,24,12,a91enm,11x1070 Deep learning build questions,https://www.reddit.com/r/deeplearning/comments/a91enm/11x1070_deep_learning_build_questions/,catcoin_miner,1545622873,I have 11 1070s left connected to an asus b250 mining expert motherboard.  Can I create a decent deep learning rig with this as a start?,20,1
179,2018-12-24,2018,12,24,13,a91oxj,What is the best new CPU for deep learning?,https://www.reddit.com/r/deeplearning/comments/a91oxj/what_is_the_best_new_cpu_for_deep_learning/,kitgary,1545625264,"I am building a new rig for deep learning, I have bought a RTX 2080 Ti and I plan to add more GPUs later. I still can't decide which CPU to get. I initially want to get a 9900k because I want to use the PC for gaming too, but 9900k has only 16 PCIe lanes, so it may not suitable. I want to buy only recent CPU, which CPU would you suggest if I want to go for 2 or more GPUs?",7,1
180,2018-12-24,2018,12,24,19,a942ym,Ergonomic ndarrays and deep learning in a compiled language with char-rnn example,https://www.reddit.com/r/deeplearning/comments/a942ym/ergonomic_ndarrays_and_deep_learning_in_a/,Karyo_Ten,1545649085,,1,1
181,2018-12-24,2018,12,24,20,a946a7,Evolution of Drones - BlockDelta,https://www.reddit.com/r/deeplearning/comments/a946a7/evolution_of_drones_blockdelta/,BlockDelta,1545650082,,1,1
182,2018-12-24,2018,12,24,23,a957c1,open cv import error on deep learning ami ubuntu using p3.2x instance any solution?,https://www.reddit.com/r/deeplearning/comments/a957c1/open_cv_import_error_on_deep_learning_ami_ubuntu/,karanbangia14,1545660149,,5,1
183,2018-12-25,2018,12,25,2,a96s9f,"Anyone interested in hosting deep learning model locally, have a look at my recent post",https://www.reddit.com/r/deeplearning/comments/a96s9f/anyone_interested_in_hosting_deep_learning_model/,ashutosj,1545671919,,2,1
184,2018-12-25,2018,12,25,2,a96yg9,Intro To Keras U-NET - Nuclei In Divergent Images,https://www.reddit.com/r/deeplearning/comments/a96yg9/intro_to_keras_unet_nuclei_in_divergent_images/,AshishKhuraishy,1545673088,,0,1
185,2018-12-25,2018,12,25,12,a9bh2v,How Deep Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/a9bh2v/how_deep_neural_networks_work_simply_explained/,DiscoverAI,1545707672,,3,1
186,2018-12-25,2018,12,25,18,a9dkh0,A Guide for Building Convolutional Neural Networks,https://www.reddit.com/r/deeplearning/comments/a9dkh0/a_guide_for_building_convolutional_neural_networks/,christiano,1545728997,[https://towardsdatascience.com/a-guide-for-building-convolutional-neural-networks-e4eefd17f4fd](https://towardsdatascience.com/a-guide-for-building-convolutional-neural-networks-e4eefd17f4fd),5,1
187,2018-12-25,2018,12,25,19,a9dxrg,Learn backprop the hard way: build your neural network from scratch using Numpy only,https://www.reddit.com/r/deeplearning/comments/a9dxrg/learn_backprop_the_hard_way_build_your_neural/,ahmedbesbes,1545733515,,8,1
188,2018-12-25,2018,12,25,20,a9e67c,AlphaGo Documentary,https://www.reddit.com/r/deeplearning/comments/a9e67c/alphago_documentary/,rajarsheem,1545736344,,0,1
189,2018-12-26,2018,12,26,7,a9j1dv,CSDN account,https://www.reddit.com/r/deeplearning/comments/a9j1dv/csdn_account/,bishoyabd,1545777743,"Anyone from china here. I need some help to download a book
here is the link
https://download.csdn.net/download/xingstar1011/10453014",3,1
190,2018-12-26,2018,12,26,13,a9lcd6,WaveNet Output Dimensions,https://www.reddit.com/r/deeplearning/comments/a9lcd6/wavenet_output_dimensions/,arjundupa,1545797554,"I am using the following Keras implementation of the WaveNet architecture: [https://github.com/basveeling/wavenet/blob/master/wavenet.py](https://github.com/basveeling/wavenet/blob/master/wavenet.py)

&amp;#x200B;

When my input shape is (x, y) with z number of filters in all types of convolutional layers (1D, casual), the output is of shape (x, z). I'd like my output to be of shape (x, 1), and so I changed the number of filters for the very last Conv1D layer to be 1 and got my desired output shape.

&amp;#x200B;

If numbers help more than variables:

Input: (8192, 4), Number of Filters: 256

Output: (8192, 256)

Desired Output: (8192, 1)

&amp;#x200B;

My fear is that in doing so (in changing the number of filters for the very last Conv1D layer to be 1), I am losing ""learned"" information -- is this true? Is there another way to get the desired output?

&amp;#x200B;

Any ideas will be much appreciated, thanks in advance!",0,1
191,2018-12-26,2018,12,26,14,a9lzxa,To anyone who has used google colab.,https://www.reddit.com/r/deeplearning/comments/a9lzxa/to_anyone_who_has_used_google_colab/,TheHawkGriffith,1545803228,Do you know how to save a tf.train.Saver() checkpoint and then later download those files from google drive. I do save the model but I dont see any files being saved to my drive. How does it work? ,4,1
192,2018-12-26,2018,12,26,16,a9mrpx,What if the input size of image is 128*128*3 and pass to convolution layer? What will be the output size?,https://www.reddit.com/r/deeplearning/comments/a9mrpx/what_if_the_input_size_of_image_is_1281283_and/,ShwetaGoyal,1545811042,I have often heard the size of input image is 32*32 and that of filter size is 5*5. What if we increase the size of input image to 128*128*3 and use 40 filters of size 5*5. What will be the output size?,8,1
193,2018-12-26,2018,12,26,19,a9njmf,Hexagon Shape Dataset,https://www.reddit.com/r/deeplearning/comments/a9njmf/hexagon_shape_dataset/,akifakkaya,1545820167,Hi everybody. I am searching hexagonal shape data set but i cant find any result. I need minimum 200 hexagonal shape.,0,1
194,2018-12-26,2018,12,26,19,a9noxp,Will Julia Replace Python for Data Science?,https://www.reddit.com/r/deeplearning/comments/a9noxp/will_julia_replace_python_for_data_science/,divya2018,1545821908,,0,1
195,2018-12-26,2018,12,26,22,a9oii5,Prerequisites for Wasserstein GAN/Autoencoder,https://www.reddit.com/r/deeplearning/comments/a9oii5/prerequisites_for_wasserstein_ganautoencoder/,lambdaofgod,1545830466,"To all of you who actually read WGAN/WAE papers, did you prepare by reading on Wasserstein distance?  


The mentioned papers seem little tough if you don't have an intuition on Wasserstein metric/optimal transport theory. The papers mostly cite some books on optimal transport - I don't think I'd be able to go through a whole book, but I wasn't able to find accessible tutorials on the topic.

&amp;#x200B;

Alternatively, could anyone narrow the specific topics that are needed to understand these papers? I've seen that they use Kantorovich duality - can one read Villani's book mostly concentrating on that? Would it be sufficient to understand the papers?",0,1
196,2018-12-26,2018,12,26,22,a9olc2,Drones Changing the Face of Industry,https://www.reddit.com/r/deeplearning/comments/a9olc2/drones_changing_the_face_of_industry/,BlockDelta,1545831239,,0,1
197,2018-12-26,2018,12,26,22,a9onvp,A simple way to understand dimension reduction,https://www.reddit.com/r/deeplearning/comments/a9onvp/a_simple_way_to_understand_dimension_reduction/,Peter0324,1545831873,"As we know, MNIST is a dataset containing handwritten numbers from 0 to 9.

Recently, I designed a simple but exciting experiment using MNIST.

I separated the dataset to 2 part, with one containing 0-4 and another containing 5-9. I used the former dataset to train a CNN, which is consisted of  a dimension reduction net (from 28\*28-d to 3-d) and a classifier (from 3-d to 5 classes). After training, the CNN can reach 99% accuracy.

Then, I discarded the classifier in the CNN and only kept the dimension reduction net. I tested the dimension reduction net with the latter dataset, which contains 5-9, and found it really cool, as you can see in the 3-d scatter plot with each color representing a number from 5 to 9.

PS: I'm a college student, interested in deep learning and computer vision.

I'm new here and i want to find some friends who share the same interest with me.",10,1
198,2018-12-27,2018,12,27,3,a9r7ae,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting",https://www.reddit.com/r/deeplearning/comments/a9r7ae/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1545850454,,1,1
199,2018-12-27,2018,12,27,6,a9str9,Get the contour coordinates in a final predicted mask,https://www.reddit.com/r/deeplearning/comments/a9str9/get_the_contour_coordinates_in_a_final_predicted/,veranceftw,1545861560,"I'm implementing a Unet model for nuclei segmentation. The model is working fine and the segmentation was successfully done. However, I want to save the contours on a json file to properly load it in a web app. 

&amp;#x200B;

Here's my original image: 

\[!\[enter image description here\]\[1\]\]\[1\]

&amp;#x200B;

And here's the corresponding predicted mask.

\[!\[enter image description here\]\[2\]\]\[2\]

&amp;#x200B;

I tried to use \`findContours\` on the mask but overlapped cells would be recognized as one. Note that overlapped cells got that green boundary to differentiate nucleis. 

&amp;#x200B;

What I want is to get the coordinates of the single nuclei contours and save it as a json, like this:

&amp;#x200B;

{""1\_0.jpeg-1"":{""filename"":""1\_0.jpeg"",""size"":-1,""regions"":\[{""shape\_attributes"":{""name"":""polyline"",""all\_points\_x"":\[

216.0,

510.5,

215.5,

510.0,

216.0,

509.5,

216.5,

510.0,

216.0,

510.5

\],""all\_points\_y"":\[\]},""region\_attributes"":{}}\],""file\_attributes"":{}}}

&amp;#x200B;

This is my predict function where I save the mask of each image-to-predict

&amp;#x200B;

if \_\_name\_\_ == '\_\_main\_\_':

t0 = timeit.default\_timer()

args\_models = \['best\_resnet101\_2\_fold0.h5'\]

weights = \[os.path.join(args.models\_dir, m) for m in args\_models\]

models = \[\]

for w in weights:

model = make\_model([args.network](https://args.network), (None, None, 3))

print(""Building model {} from weights {} "".format([args.network](https://args.network), w))

model.load\_weights(w)

models.append(model)

os.makedirs(test\_pred, exist\_ok=True)

print('Predicting test')

for d in tqdm(listdir(test\_folder)):

final\_mask = None

for scale in range(1):

fid = d

print(path.join(test\_folder, '{0}'.format(fid)))

img = cv2.imread(path.join(test\_folder, '{0}'.format(fid)), cv2.IMREAD\_COLOR)\[...,::-1\]



if final\_mask is None:

final\_mask = np.zeros((img.shape\[0\], img.shape\[1\], OUT\_CHANNELS))

if scale == 1:

img = cv2.resize(img, None, fx=0.75, fy=0.75, interpolation=cv2.INTER\_AREA)

elif scale == 2:

img = cv2.resize(img, None, fx=1.25, fy=1.25, interpolation=cv2.INTER\_CUBIC)



x0 = 16

y0 = 16

x1 = 16

y1 = 16

if (img.shape\[1\] % 32) != 0:

x0 = int((32 - img.shape\[1\] % 32) / 2)

x1 = (32 - img.shape\[1\] % 32) - x0

x0 += 16

x1 += 16

if (img.shape\[0\] % 32) != 0:

y0 = int((32 - img.shape\[0\] % 32) / 2)

y1 = (32 - img.shape\[0\] % 32) - y0

y0 += 16

y1 += 16

img0 = np.pad(img, ((y0, y1), (x0, x1), (0, 0)), 'symmetric')



inp0 = \[\]

inp1 = \[\]

for flip in range(2):

for rot in range(4):

if flip &gt; 0:

img = img0\[::-1, ...\]

else:

img = img0

if rot % 2 == 0:

inp0.append(np.rot90(img, k=rot))

else:

inp1.append(np.rot90(img, k=rot))



inp0 = np.asarray(inp0)

inp0 = preprocess\_inputs(np.array(inp0, ""float32""))

inp1 = np.asarray(inp1)

inp1 = preprocess\_inputs(np.array(inp1, ""float32""))



mask = np.zeros((img0.shape\[0\], img0.shape\[1\], OUT\_CHANNELS))



for model in models:

pred0 = model.predict(inp0, batch\_size=1)

pred1 = model.predict(inp1, batch\_size=1)

j = -1

for flip in range(2):

for rot in range(4):

j += 1

if rot % 2 == 0:

pr = np.rot90(pred0\[int(j / 2)\], k=(4 - rot))

else:

pr = np.rot90(pred1\[int(j / 2)\], k=(4 - rot))

if flip &gt; 0:

pr = pr\[::-1, ...\]

mask += pr  # \[..., :2\]



mask /= (8 \* len(models))

mask = mask\[y0:mask.shape\[0\] - y1, x0:mask.shape\[1\] - x1, ...\]

if scale &gt; 0:

mask = cv2.resize(mask, (final\_mask.shape\[1\], final\_mask.shape\[0\]))

final\_mask += mask

final\_mask /= 1

if OUT\_CHANNELS == 2:

final\_mask = np.concatenate(\[final\_mask, np.zeros\_like(final\_mask)\[..., 0:1\]\], axis=-1)

final\_mask = final\_mask \* 255

final\_mask = final\_mask.astype('uint8')

cv2.imwrite(path.join(test\_pred, '{0}'.format(fid)), final\_mask, \[cv2.IMWRITE\_PNG\_COMPRESSION, 9\])



elapsed = timeit.default\_timer() - t0

print('Time: {:.3f} min'.format(elapsed / 60))

&amp;#x200B;

&amp;#x200B;

Do you have any idea how to get the coordinates of each classified nuclei? The json part should be easy but I don't get how can I get the countours' coordinates. Should I do it after the predicted mask is written? Or should I do it on my predict process?

&amp;#x200B;

Kind Regards

&amp;#x200B;

  \[1\]: [https://i.stack.imgur.com/foJOK.jpg](https://i.stack.imgur.com/foJOK.jpg)

  \[2\]: [https://i.stack.imgur.com/rLldU.jpg](https://i.stack.imgur.com/rLldU.jpg)",0,1
200,2018-12-27,2018,12,27,7,a9szjn,A knowledge extractor from text,https://www.reddit.com/r/deeplearning/comments/a9szjn/a_knowledge_extractor_from_text/,ak96,1545862747,"I am trying to build a model which can extract information from a pdf/html file and use it for answering questions which are asked later. So, for example, I have a page on a football club which has information about its captain, manager, owner etc. and I want to extract it and store it for later retrieval upon request. You guys have any suggestions on how to do it? Or any papers that you can point me to? 

(Similar to Question Answering model using RNNs with bi-directional LSTMs/GRUs)",1,1
201,2018-12-27,2018,12,27,13,a9vxey,Data Sets / Notebooks that are good for demo's,https://www.reddit.com/r/deeplearning/comments/a9vxey/data_sets_notebooks_that_are_good_for_demos/,bfeeny,1545885179,"Does anyone have any good notebooks and data sets that are good demos. For example I can load them on our DGX-1 and just show people some of the interesting things you can do with GPU's for example.  I'm trying to find some of the better examples.
",2,1
202,2018-12-27,2018,12,27,16,a9wzot,Reinforcement Learning (RL) &amp; Deep RL Tutorial With Sample Codes/Demo,https://www.reddit.com/r/deeplearning/comments/a9wzot/reinforcement_learning_rl_deep_rl_tutorial_with/,obsezer,1545894447," There   are many RL tutorials, courses, papers in the internet. This one   summarizes all of the RL tutorials, RL courses, and some of the   important RL papers including sample code of RL algorithms. It will   continue to be updated over time.

[https://github.com/omerbsezer/Reinforcement\_learning\_tutorial\_with\_demo](https://github.com/omerbsezer/Reinforcement_learning_tutorial_with_demo)

Extra:   LSTM and RNN Tutorial with Stock/Bitcoin Time Series Prediction Code Example

[https://github.com/omerbsezer/LSTM\_RNN\_Tutorials\_with\_Stock\_Prices\_Prediction](https://github.com/omerbsezer/LSTM_RNN_Tutorials_with_Stock_Prices_Prediction)",1,1
203,2018-12-27,2018,12,27,16,a9x9e2,Andrew's deep learning old course @ coursera,https://www.reddit.com/r/deeplearning/comments/a9x9e2/andrews_deep_learning_old_course_coursera/,snip3r77,1545897062,"I just passed the forward and backprop ( with regularization ) assignment and the coding is pretty tedious.

If I were to code the same thing with PyTorch or Keras, how difficult/easy can it be ? 

Thanks
",4,1
204,2018-12-27,2018,12,27,21,a9yqp3,Lstm help required,https://www.reddit.com/r/deeplearning/comments/a9yqp3/lstm_help_required/,utsavll0,1545912699,I want to use LSTM(LRCN) for video classification but i am not able to find examples or good papers regarding the same. Can you guys help me in doing the same. I just need some examples or a direction to look at where i can study more about lstms and video classification,1,1
205,2018-12-27,2018,12,27,21,a9yx2i,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educative",https://www.reddit.com/r/deeplearning/comments/a9yx2i/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1545914466,,0,1
206,2018-12-27,2018,12,27,21,a9yzwl,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educative",https://www.reddit.com/r/deeplearning/comments/a9yzwl/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1545915226,,0,1
207,2018-12-27,2018,12,27,23,a9zvex,Variable not found when using a Tensorflow session in another function.,https://www.reddit.com/r/deeplearning/comments/a9zvex/variable_not_found_when_using_a_tensorflow/,thepixelatedguy,1545922776,"I am creating a Flask app and I want to restore a tensorflow session with it's variables only once and use it on various routes to make predictions but it doesn't seem to work.I created a class whose constructor restores the interactive session and it's variables,the class also contains a function named predict which tries to predict the outcome using the interactive session described in the constructor.But it throws the following error

ValueError: Variable Net\_WT/block1/bn does not exist, or was not created with tf.get\_variable(). Did you mean to set reuse=tf.AUTO\_REUSE in VarScope?",3,1
208,2018-12-28,2018,12,28,1,aa0dq3,White Hats Vs CAPTCHAs,https://www.reddit.com/r/deeplearning/comments/aa0dq3/white_hats_vs_captchas/,gwen0927,1545926529,,0,1
209,2018-12-28,2018,12,28,1,aa0mfm,"In StarGAN-type autoencoders, the latent space is of higher dimensionality compared to the input space. Shouldn't it be the opposite?",https://www.reddit.com/r/deeplearning/comments/aa0mfm/in_stargantype_autoencoders_the_latent_space_is/,ElBalistico,1545928175,"Hi everyone!

In the official StarGAN implementation, the latent space of the encoder is of higher dimensionality, compared to the image space. Usually, autoencoders are used to extract information from data (images) by forcing the network to learn a more compact and less redundant representation of the input. Here it would seem that the network (fully convolutional encoder) doen't have to trow away any information. 

&amp;#x200B;

I need your help, for this is somewhat confusing.

*Note: with default-ish parameters, the input is 128x128x3 while the latent space is 32x32x256*

&amp;#x200B;

Thanks in advance!",1,1
210,2018-12-28,2018,12,28,6,aa37he,Can AI Judge a Paper on Appearance Alone?,https://www.reddit.com/r/deeplearning/comments/aa37he/can_ai_judge_a_paper_on_appearance_alone/,gwen0927,1545944685,,2,1
211,2018-12-28,2018,12,28,14,aa793y,I am writing blogs on reinforcement learning give it a look.,https://www.reddit.com/r/deeplearning/comments/aa793y/i_am_writing_blogs_on_reinforcement_learning_give/,sanchit2843,1545973945,,3,1
212,2018-12-28,2018,12,28,15,aa7xsj,"LSTM and RNN Tutorial with Demo (with Stock/Bitcoin Time Series Prediction, Sentiment Analysis, Music Generation)",https://www.reddit.com/r/deeplearning/comments/aa7xsj/lstm_and_rnn_tutorial_with_demo_with_stockbitcoin/,obsezer,1545979843,"There are many LSTM tutorials, courses, papers in the internet. This one  summarizes all of them. In this tutorial, RNN Cell, RNN Forward and  Backward Pass, LSTM Cell, LSTM Forward Pass, Sample LSTM Project:  Prediction of Stock Prices Using LSTM network, Sample LSTM Project:  Sentiment Analysis, Sample LSTM Project: Music Generation. It will  continue to be updated over time. 

[https://github.com/omerbsezer/LSTM\_RNN\_Tutorials\_with\_Demo](https://github.com/omerbsezer/LSTM_RNN_Tutorials_with_Demo)",0,1
213,2018-12-28,2018,12,28,20,aa9j7y,Is paperspace only available for US citizens?,https://www.reddit.com/r/deeplearning/comments/aa9j7y/is_paperspace_only_available_for_us_citizens/,ShwetaGoyal,1545996374,,5,1
214,2018-12-28,2018,12,28,21,aa9ucl,Deep Learning library when working professionally.,https://www.reddit.com/r/deeplearning/comments/aa9ucl/deep_learning_library_when_working_professionally/,TheHawkGriffith,1545999419,"Im still a 2nd year undergrad. 
What I want to know from any of you people who are working ML/DL practitioners is that, is there a requirement of knowing a specific library to get a job, in general sense. 
Or you can use what youre comfortable with so long as you know the ins and outs of it?
Cause I find myself much more comfortable with Tensorflow than PyTorch. 
Any suggestions? Or insights into the professional domain will be a great help too. 
Thank you! :)",13,1
215,2018-12-28,2018,12,28,22,aaaivz,"GitHub - hujinsen/awesome-pytorch-StarGAN-VC: An implementation that fully follows the original paper of StarGAN-VC , stable training &amp; better results.",https://www.reddit.com/r/deeplearning/comments/aaaivz/github_hujinsenawesomepytorchstarganvc_an/,hujinsen,1546005554,,3,1
216,2018-12-28,2018,12,28,23,aaap5n,Udacuty deep learning nanodegree,https://www.reddit.com/r/deeplearning/comments/aaap5n/udacuty_deep_learning_nanodegree/,KidDora7,1546006945,If anyone has done deep learning nanodegree from udacity . I am on predicting bike share price project but i am struggling with understanding the code. Is it fine as i am new to deep learning,5,1
217,2018-12-28,2018,12,28,23,aaaqci,5 Best Open-source Frameworks for Creating Machine Learning Models,https://www.reddit.com/r/deeplearning/comments/aaaqci/5_best_opensource_frameworks_for_creating_machine/,BlockDelta,1546007218,,1,1
218,2018-12-28,2018,12,28,23,aaassz,Computer Vision: Object Detection and Segmentation with Mask R-CNN,https://www.reddit.com/r/deeplearning/comments/aaassz/computer_vision_object_detection_and_segmentation/,seemingly_omniscient,1546007758," 

Object Detection and image segmentation with Mask R-CNN and COCO dataset. Source video clips are shot in Frankfurt am Main, Germany. Hope you like it.

[Demo Video](https://youtu.be/akK5ui-vel0)",0,1
219,2018-12-28,2018,12,28,23,aaaxas,Deep Recurrent Neural Networks for ECG Signal Denoising,https://www.reddit.com/r/deeplearning/comments/aaaxas/deep_recurrent_neural_networks_for_ecg_signal/,arjundupa,1546008703,"[https://arxiv.org/pdf/1807.11551.pdf](https://arxiv.org/pdf/1807.11551.pdf) \-- Reading through this paper titled Deep Recurrent Neural Networks for ECG Signal Denoising.

Their architecture is briefly described on the bottom right of page 3 -- I understand the Deep RNN part of it, but I don't understand where / why the denoising autoencoder comes in.

Any ideas?

Any input will be much appreciated, thanks!",10,1
220,2018-12-29,2018,12,29,3,aacoq9,Is this a valid certificate?,https://www.reddit.com/r/deeplearning/comments/aacoq9/is_this_a_valid_certificate/,crazy_lazy_life,1546020613,,12,1
221,2018-12-29,2018,12,29,10,aaghfi,First Titan RTX Benchmarks for Deep Learning  Titan RTX vs. V100 vs. 2080 Ti vs. 1080 Ti vs. Titan V vs. Titan Xp TensorFlow Performance,https://www.reddit.com/r/deeplearning/comments/aaghfi/first_titan_rtx_benchmarks_for_deep_learning/,mippie_moe,1546045922,,1,1
222,2018-12-29,2018,12,29,12,aaheol,GitHub - hujinsen/pytorch-StarGAN-VC: Fully reproduce the paper of StarGAN-VC. Stable training and Better audio quality .,https://www.reddit.com/r/deeplearning/comments/aaheol/github_hujinsenpytorchstarganvc_fully_reproduce/,hujinsen,1546053080,,0,1
223,2018-12-29,2018,12,29,14,aaigzp,Activation Functions for Bidirectional LSTM Model,https://www.reddit.com/r/deeplearning/comments/aaigzp/activation_functions_for_bidirectional_lstm_model/,arjundupa,1546061569,"I've been using the following architecture for de-noising signals (time-series data):

[https://imgur.com/a/NVR5t5v](https://imgur.com/a/NVR5t5v)

[https://imgur.com/a/XixYj58](https://imgur.com/a/XixYj58)

It's been learning moderately well. It just hit me that because there seem to be no activation functions, my supposedly 3-layer deep model is really just 1-layer deep -- is that right?

If so, any suggestions for what activation functions might work well?",3,1
224,2018-12-29,2018,12,29,23,aalgnq,"What's the best way to get into ML? Well, if you're looking to get your feet wet ASAP, you should consider learning APIs like Keras as opposed to backends like Tensorflow and Theano. Here's a good video that explains exactly what Keras is",https://www.reddit.com/r/deeplearning/comments/aalgnq/whats_the_best_way_to_get_into_ml_well_if_youre/,antaloaalonso,1546092454,,1,1
225,2018-12-30,2018,12,30,1,aamlk1,Need deep learning support for my app,https://www.reddit.com/r/deeplearning/comments/aamlk1/need_deep_learning_support_for_my_app/,Skillbill0r,1546101520,"Hi there,

I have an app, where users anonymously upload images.

To ensure the quality of these images, i want to implement an automatic layer which checks these images when uploaded and reject them, when they dont fit a certain ""quality standard"".

I want to solve this requirement with a deep learning algorithm. Is that somehow possible?

At the moment, i have about 1000 images (continuously growing every day) which i could provide to train for images which i dont want to have in the app (blury images, images of white walls or the floor, black images, etc).

So, i dont have any experience with deep/machine learning and i would be very grateful, if some could point me in the right direction, to find a good and/or simple framework, which can support me here.

&amp;#x200B;

Thanks",6,1
226,2018-12-30,2018,12,30,6,aap7f6,LSTM with combined features,https://www.reddit.com/r/deeplearning/comments/aap7f6/lstm_with_combined_features/,nlpredditproject,1546118833," Hi ,

I wanna do the following thing and I'm not sure where to begin:

\- I have a data set that is a log of keystrokes (categorical) and a value (numerical) . I want to predict the next keystroke given a sequence of Z previous keystrokes .

\- I know that I need some architecture that will be very similar to a language model ; at time t , give the previous **real**keystroke **and** the value (and a\_t-1) I want to get y\_hat (which will be the predicted keystroke, after a sofmax I guess)

\- I guess I need to then sum the y\_hats to a loss function and update accordingly

I want to do it in keras at the moment . If anyone knows a tutorial with example similar to my case that would be great too

Thanks",4,1
227,2018-12-30,2018,12,30,6,aapedi,how to visualize datasets,https://www.reddit.com/r/deeplearning/comments/aapedi/how_to_visualize_datasets/,kkbrennm,1546120120,"Hello everyone,

I have been reading deep learning with python by  Fracois Chollet and am having a hard time understanding the examples since i can't visualize the datasets. Whenever I open the python scripts for the given dataset that i am working with, all I see is a link to where the dataset is being downloaded from. How do I open these datasets to visualize the raw data? The datasets from all of these examples are the ones included by default in the [keras.io](https://keras.io) library, 

&amp;#x200B;

Thanks for all the help!",1,1
228,2018-12-30,2018,12,30,8,aaq2wb,Would having a mathematically described function that approximates the function encoded in a neural network help researchers understand how a neural network gets its output?,https://www.reddit.com/r/deeplearning/comments/aaq2wb/would_having_a_mathematically_described_function/,FIREATWlLL,1546124719,"(1st year comp sci undergrad, and self teaching ML basics, so will be prone to misinterpreting things)

&amp;#x200B;

I understand that a big problem with neural networks are that they are ""black box"" models - it is difficult to understand how they achieve outcomes given certain input data. This is an issue when NN models could effect the health and safety of individuals.

&amp;#x200B;

What I am wondering is that if we could describe a mathematical form of the function  encoded by neural network models, would it help researchers gain insight into how they work?

&amp;#x200B;

I guess that the mathematical form of the function would be just as cryptic, as (especially for deep learning models) there are a lot of inputs, but I have no idea, which is why I am asking...",6,1
229,2018-12-30,2018,12,30,9,aar2ww,"[CNN] Difference between a single convolutional step with 128 output feature maps, versus two convolutional steps with 64 output feature maps each?",https://www.reddit.com/r/deeplearning/comments/aar2ww/cnn_difference_between_a_single_convolutional/,Morocco_Bama,1546131521," 

image\_in --&gt; \[Conv\] --&gt; 128 feature maps --&gt; \[Conv\] --&gt; output

image\_in --&gt; \[Conv\] --&gt; 64 feature maps --&gt; \[Conv\] --&gt; 64 feature maps --&gt; \[Conv\] --&gt; output

In both examples, there are 128 feature maps total, so I'm unclear if there is a structural/functional difference in the two cases? Is it just that the second example the model is more flexible for training?

(Apologies if the distinction is obvious)

EDIT: Padding @ each conv step",9,1
230,2018-12-30,2018,12,30,12,aas2no,Bidirectional LSTM Auto-encoder in Keras,https://www.reddit.com/r/deeplearning/comments/aas2no/bidirectional_lstm_autoencoder_in_keras/,arjundupa,1546139044,"I am working on denoising signals.

I have implemented a Bidirectional LSTM-based neural network:

    # layer 1
    input_layer = keras.engine.input_layer.Input(shape=(8192, 4))
    lstm1 = LSTM(return_sequences=True, input_shape=(8192, 4), units=32)(input_layer)
    lstm2 = LSTM(return_sequences=True, input_shape=(8192, 4), units=32, go_backwards=True)(input_layer)
    merge1 = concatenate([lstm1, lstm2])
    
    output_layer = LSTM(return_sequences=True, input_shape=(8192, 32), units=1)(merge1)

I have also implemented an LSTM-based (denoising) auto-encoder:

    input_layer = keras.engine.input_layer.Input(shape=(8192, 4))
    
    # encoder
    encoder = LSTM(input_shape=(8192, 4), units=32, go_backwards=True)(input_layer)
    
    rep_vec = RepeatVector(8192)(encoder)
    
    # decoder
    decoder = LSTM(return_sequences=True, input_shape=(8192, 32), units=1, go_backwards=True)(rep_vec)

Turns out, the Bidirectional LSTM-based neural network learns pretty well on my dataset, while the LSTM-based (denoising) auto-encoder does not. 

I subsequently tried to make my denoising auto-encoder's encoder and decoder out of Bidirectional LSTM-based layers:

    input_layer = keras.engine.input_layer.Input(shape=(8192, 4))
    
    # encoder
    lstm1 = LSTM(return_sequences=True, input_shape=(8192, 4), units=num_units)(input_layer)
    lstm2 = LSTM(return_sequences=True, input_shape=(8192, 4), units=num_units, go_backwards=True)(input_layer)
    merge1 = concatenate([lstm1, lstm2])
    
    rep_vec = RepeatVector(8192)(merge1)
    
    # layer 2
    lstm3 = LSTM(return_sequences=True, input_shape=(8192, num_units), units=num_units)(rep_vec)
    lstm4 = LSTM(return_sequences=True, input_shape=(8192, num_units), units=1, go_backwards=True)(rep_vec)
    merge2 = concatenate([lstm3, lstm4])

However, I get the following error which I haven't been able to resolve:

    Input 0 is incompatible with layer repeat_vector_1: expected ndim=2, found ndim=3

Any ideas?

Any suggestions will be much appreciated, thanks!",0,1
231,2018-12-30,2018,12,30,13,aaslz7,Tensorflow IndRNN,https://www.reddit.com/r/deeplearning/comments/aaslz7/tensorflow_indrnn/,arjundupa,1546143309,"I am trying to use one of Tensorflow's IndRNN implementation: [https://www.tensorflow.org/api\_docs/python/tf/contrib/rnn/IndyLSTMCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/IndyLSTMCell)

However, the following line of code:

    cell = tf.contrib.rnn.IndyLSTMCell(128)

gives me the following error:

    AttributeError: module 'tensorflow.contrib.rnn' has no attribute 'IndyLSTMCell'

I'm not sure why I'm getting this error, since the first line of the Tensorflow documentation referenced above is ""tf.contrib.rnn.IndyLSTMCell""

Any ideas?

Any suggestions will be much appreciated, thanks!",0,1
232,2018-12-30,2018,12,30,13,aasqat,Free Access to HPC GPU Compute for Anyone Interested,https://www.reddit.com/r/deeplearning/comments/aasqat/free_access_to_hpc_gpu_compute_for_anyone/,johanseom,1546144275,"Hi All. Looking for some help in developing a machine/deep learning cloud platform like Paperspace, Floydhub, VectorDash, Vast, TensorPad, etc. I've done a bit of research so far and kind of distilled the information I've learned into a survey about hardware and software used for deep learning model training. I would love to for you guys to take the survey and help me out.

In exchange for your time and insight, I'm able to offer free access to all the high-power gpu computing you need to train your models. The offer is open to anyone who takes the survey, but am willing to work with you directly if you like. My company has deep pockets to setup any kind of workstation hardware for your personal use if you are willing to help us. We are located in Vancouver, Canada, and if any of you are from there, we are willing to buy you a machine to use in exchange for your help.

Thanks!

[https://www.surveymonkey.com/r/T32MPWD](https://www.surveymonkey.com/r/T32MPWD)",6,1
233,2018-12-30,2018,12,30,16,aatvyc,Sudden drop in loss while training a model and stuck at the same loss and accuracy for the last 5 epochs.,https://www.reddit.com/r/deeplearning/comments/aatvyc/sudden_drop_in_loss_while_training_a_model_and/,thepixelatedguy,1546154464,,8,1
234,2018-12-30,2018,12,30,20,aav42x,Best Introductory Course for NLP,https://www.reddit.com/r/deeplearning/comments/aav42x/best_introductory_course_for_nlp/,Shrey_Dixit,1546168424,"I have three courses in mind

[Stanford CS 224n](http://web.stanford.edu/class/cs224n/)

[CMU CS 11-747](http://www.phontron.com/class/nn4nlp2018/schedule.html)

[Oxford Deep NLP 2017](https://github.com/oxford-cs-deepnlp-2017/lectures)

Which one is the best according to you? Any suggestions will be appreciated",3,1
235,2018-12-31,2018,12,31,4,aaz2fa,Understanding SSD MultiBox  Real-Time Object Detection In Deep Learning,https://www.reddit.com/r/deeplearning/comments/aaz2fa/understanding_ssd_multibox_realtime_object/,ConfidentMushroom,1546199261,,0,1
236,2018-12-31,2018,12,31,8,ab1ayc,Img2Img Translation Methods,https://www.reddit.com/r/deeplearning/comments/ab1ayc/img2img_translation_methods/,mennasiam,1546213651,,0,1
237,2018-12-31,2018,12,31,12,ab347j,GANs are being weaponized against women,https://www.reddit.com/r/deeplearning/comments/ab347j/gans_are_being_weaponized_against_women/,sherif_truepic,1546226301,,3,1
238,2018-12-31,2018,12,31,12,ab35dp,How Machine Learning Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/ab35dp/how_machine_learning_neural_networks_work_simply/,DiscoverAI,1546226536,,1,1
239,2018-12-31,2018,12,31,12,ab3bpz,Never understood how Bias actually shifts the curve in neural nets.,https://www.reddit.com/r/deeplearning/comments/ab3bpz/never_understood_how_bias_actually_shifts_the/,katiex7,1546227860,"In the case that Bias stays constant, and has a constant weight associated with it, yes it will shift the curve. For example checkout this great stackoverflow answer. [https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks](https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks)

&amp;#x200B;

However, I usually update the theta associated with the bias and sometimes those theta's change in such a way while doing gradient descent, that it's as if it's just another x(input unit) that has a theta associated with it, with the only difference being that the bias unit never changes.  


In that case, is it really shifting the curve? I don't think so. Perhaps, if the curve needed to be shifted for the ideal model, and because I remembered to include the bias unit, the Neural net found the correct weights(thetas), then yes I'd say the bias did shift it, but aren't those cases really rare? I mean, if we are doing gradient descent with some small learning rate alpha, I still believe that the bias's weights will change to just play a part in finding the right curve, and not really the placement of the curve, and thereby just acting as another input unit like the rest.  


Any insight on this?",9,1
240,2018-12-31,2018,12,31,15,ab4ilf,How to implement ML model into an android app?,https://www.reddit.com/r/deeplearning/comments/ab4ilf/how_to_implement_ml_model_into_an_android_app/,harsh52,1546237157,"Hello everyone,

I have seen an article on internet to ""how to make a snake game using Deep learning"".
And I want to implement this model into an Android app.
I have read some articles to implement this.
But not getting satisfactory result.
It would be very helpful if you guys provide me some information related to this.

Thank you.",2,1
241,2018-12-31,2018,12,31,20,ab6eev,"[crosspost r/ML] As a practitioner, do you read papers? If so, how many per month?",https://www.reddit.com/r/deeplearning/comments/ab6eev/crosspost_rml_as_a_practitioner_do_you_read/,urlwolf,1546256301,I'm really curious about stats here. ,2,1
0,2019-1-1,2019,1,1,12,abekxa,Can someone explain this part in Johnson et al's Perceptual Losses for Real-Time Style Transfer Paper?,https://www.reddit.com/r/deeplearning/comments/abekxa/can_someone_explain_this_part_in_johnson_et_als/,RedditAcy,1546313954,"I was reading on some Johnson et al after getting interested in Neural Style Transfer. Johnson got the image outputs three times faster than Gatys. So of course the paper said the group used a residual network (versus Gatys who used a VGG?), stochastic gradient descent, and it appears like Johnson et al also back-prop after the forward pass, unlike Gatys. But there is one part of the paper that I didn't understand: 

&gt;   The key insight of these methods is that convolutional neural networks pretrained for image classification have already learned to encode the perceptual and semantic information we would like to measure in our loss functions. We therefore make use of a network  pretrained for image classification as a fixed loss network in order to define our loss functions. Our deep convolutional transformation network is thus trained using loss functions that are also deep convolutional networks. 

Does the CNN that is pre-trained trained on the style picture provided? What does fixed mean, like loss that is cached somewhere that will always be the same for all pictures?

&amp;#x200B;

Anyways, happy new years! 1 hour and 20 minutes left for me here on the east coast!",0,1
1,2019-1-1,2019,1,1,17,abgq3r,Having a hard time creating two datasets...,https://www.reddit.com/r/deeplearning/comments/abgq3r/having_a_hard_time_creating_two_datasets/,Phischstaebchen,1546332838,"Hi,

I'm tinkering on a project to measure the speed of either fishes or insects filmed from above. Perhaps I'm just a noob, but how do I create my training-data automatically and efficient? The camera delivers a h.264 stream, I dumped it with youtub-dl and used ffmpeg to convert it to single JPEG-frames at 1280x720 pixels. 

&amp;#x200B;

In all the tutorials for object detection and NeuralNetworking I read about small (like 10x10 pixel?) images as datasets. But eg. the fishes are barely 10x10pixel in size one those frames. Best I can do is like 50x50 without scaling.

And of course, I need to train with a dataset of images showing fishes, and a dataset of the same size showing empty water... right? I wonder if there is a way to do this faster than just cropping images by hand? I already feel exhausted after like 50 frames...! XD",3,1
2,2019-1-1,2019,1,1,18,abgvca,How to import our own module to google colab notebook?,https://www.reddit.com/r/deeplearning/comments/abgvca/how_to_import_our_own_module_to_google_colab/,mebpin,1546334481," 

How can we import our own module (stored in google drive) to google colab notebook? Normal import is not working (mymodule.py and myNotebook.ipynb are in same folder in google drive).

drive.mount(/content/gdrive)#drive is mounted here

 files are stored in gdrive/My Drive/MyFiles/

Please help!",8,1
3,2019-1-1,2019,1,1,22,abi4pp,How to add more emphasis on end columns in CNN?,https://www.reddit.com/r/deeplearning/comments/abi4pp/how_to_add_more_emphasis_on_end_columns_in_cnn/,jsther,1546348717," 

I am using CNN for multivariate time series analysis. The input size  is (30, 500) i.e 30 variables and 500 time steps. I want to put more  emphasis on recent data and less on past data. 

What is the best way to achieve that?",10,1
4,2019-1-1,2019,1,1,22,abi8yg,How to get good at deep learning when your hardware sucks?,https://www.reddit.com/r/deeplearning/comments/abi8yg/how_to_get_good_at_deep_learning_when_your/,TheHawkGriffith,1546349962,"I have a laptop that is powered by an i5 4th gen and a low 4 GB ram. I have an nvidia 820m with a compute compatibility of 2.1 hence I cant use CUDA in PyTorch or Tensorflow. 
And I cant afford a new PC or laptop or any web instance. 
My father is an asshole. 
Do you guys know any workaround for my problem? I know there isnt any way, but Im only hoping! 
So far Ive not stopped at anything, may it seem hard or easy, but this is a bottleneck for me I cant work around. 
Any advice or help is appreciated. ",16,1
5,2019-1-2,2019,1,2,1,abjjrc,Weight Updates,https://www.reddit.com/r/deeplearning/comments/abjjrc/weight_updates/,cuberduderasmit,1546361009,"I started DL 8 months ago, and I've created many AI along the way. However, something I've never found out how to do is keep progress, integrate into a game or website, and running it. Let me explain in short and long.

TL;DR:  
How do I save progress after training?  
How do I integrate into a UE4 game or a website?  
How do I prepare the code for testing, when there's training code in there?

Longer version:  
After making a new network, I run it with the training data. Great! So now, the weights have updated permanently, right? WRONG! If I run it again, I get pretty much the exact same results, 0 improvement. So here's the first problem: how do I keep my progress after training? So, let's say I've saved progress, my network has improved! Now, let's deploy it to one of my games. But... how? How do I put Python code into, say, C++ code for a UE4 game, and how do I integrate it into say a bot. My CNN/Q-Learning hybrid trains on visuals from other games to predict the best next move. But if I were to somehow insert it into my code and run it, it still has the training code with the training datasets. Do I have to redo the code for testing? Wouldn't that again lose all my progress? My current QLCNN is made for a person to monitor it, since it outputs loss and charts and other sorts of data. Is the main code similar to a header file in C++ or Java where I have to make another file that actually runs it? 

Thanks a lot! Sorry these questions, especially the first, seem stupid, but I've watched billions of videos and lectures and never have had someone explain DL after training.",2,1
6,2019-1-2,2019,1,2,2,abk3le,Gated Graph Sequence Neural Networks,https://www.reddit.com/r/deeplearning/comments/abk3le/gated_graph_sequence_neural_networks/,Karthik9999,1546364734,,0,1
7,2019-1-2,2019,1,2,4,abl1la,Open Source website with Music Video tagging system,https://www.reddit.com/r/deeplearning/comments/abl1la/open_source_website_with_music_video_tagging/,slk_g500,1546370841,"I'm making a free open source website where you can tag music videos from YT and search through their content. [Video Demo](https://www.youtube.com/watch?v=lRDzS7lxyDk&amp;t=6s)  
But all tags/lables was added by users. I would like to add some video recognition system. I tried with Google... but is there any libraries to do this kind of work?   
Maybe you would like to join the project, and play around, it's very interesting &amp; fun project. 

[http://culturevein.com/](http://culturevein.com/)   
codebase [https://github.com/slk500/culturevein.com](https://github.com/slk500/culturevein.com) 

&amp;#x200B;",0,1
8,2019-1-2,2019,1,2,5,ablgni,Ubuntu on SSD or HDD?,https://www.reddit.com/r/deeplearning/comments/ablgni/ubuntu_on_ssd_or_hdd/,yoyoyoCake,1546373426,"Hello everybody, I got Windows 10 running on a 128gb SSD with a 1 tb hard drive.  

I'd like to install ubuntu, but i don't think i can fit the 25gb ubuntu on the 128gb SSD without using NTFS compression on the SSD, which might impact system performance.  (there is 5gb minimal ubuntu installation, but i don't think that would be optimal for deep learning, right? Don't know) I don't have quite enough space on the SSD to install ubuntu.  

Would it be fine running ubuntu with machine learning applications on the mechanical hard drive? Would it be fast enough? Not quite sure what to do here. Thanks!",5,1
9,2019-1-2,2019,1,2,6,abm5f5,DCGAN for MNIST,https://www.reddit.com/r/deeplearning/comments/abm5f5/dcgan_for_mnist/,CreativeElephant,1546377759,"I might be totally dumb for asking this but has anyone made DCGAN work with MNIST images (28x28 images)? Most of implementation scale images to 64x64 and use the architecture used by DCGAN paper. I tried to implement a DCGAN with pytorch using networks as below and get very poor results even after 50 iterations. 

I pass MNIST images as is (unnormalized)

&amp;#x200B;

    class Reshape(nn.Module):
        def __init__(self, tup):
            super().__init__()
            self.reshape_tuple = tup
        def forward(self, x):
            return x.view(self.reshape_tuple)
    
    Generator = torch.nn.Sequential(
        nn.ConvTranspose2d(2, 256, (3,3), stride=1, padding=1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.ConvTranspose2d(256, 128, (4,4), stride=1, padding=1),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.ConvTranspose2d(128, 64, (4,4), stride=2, padding=0),
        nn.BatchNorm2d(64),
        nn.ReLU(),
        nn.ConvTranspose2d(64,1, (4,4), stride=2, padding=1),
        nn.Sigmoid()
    ).to(device)
    
    Discriminator = torch.nn.Sequential(
        nn.Conv2d(1, 32, (3, 3), stride=2, padding=1),
        nn.ReLU(),
        nn.Conv2d(32, 64, (3,3), stride=2, padding=1),
        nn.BatchNorm2d(64),
        nn.ReLU(),
        nn.Conv2d(64, 128, (3,3), stride=2, padding=0),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.Conv2d(128,1, (3,3), stride=1, padding=0),
        Reshape((-1,1))
    ).to(device)

Any suggestion, links to working code etc would be really helpful",6,1
10,2019-1-2,2019,1,2,12,abp6j5,Grokking deep learning book by Andrew trask,https://www.reddit.com/r/deeplearning/comments/abp6j5/grokking_deep_learning_book_by_andrew_trask/,KidDora7,1546398314,"I am willing to buy the grokking deep learning book by Andrew trask manning publication.
Will paypal directly.
",8,1
11,2019-1-2,2019,1,2,17,abrleu,Deep Learning vs Machine Learning - and its advantage,https://www.reddit.com/r/deeplearning/comments/abrleu/deep_learning_vs_machine_learning_and_its/,greatlearning1,1546418433,,2,1
12,2019-1-2,2019,1,2,18,abrqew,Extracting frames with bounding boxes in YOLO,https://www.reddit.com/r/deeplearning/comments/abrqew/extracting_frames_with_bounding_boxes_in_yolo/,MathKlim,1546419903,"I have been working on a model that can detect persons using YOLO. Now I have the question if it's possible to extract certain frames (let's say each 5 seconds) from a video, to get the objects detected in that frame from their boxes. Is there any way to perform this operation?",4,1
13,2019-1-2,2019,1,2,22,abtmb7,HC30-S6-T2: Analog Computation in Flash Memory for Datacenter-scale AI,https://www.reddit.com/r/deeplearning/comments/abtmb7/hc30s6t2_analog_computation_in_flash_memory_for/,axeonthra,1546437482,,0,1
14,2019-1-3,2019,1,3,0,abu6mg,Neural Networks and Deep Learning MNIST Code,https://www.reddit.com/r/deeplearning/comments/abu6mg/neural_networks_and_deep_learning_mnist_code/,arjundupa,1546441737,"I copy and pasted much of the code on [http://neuralnetworksanddeeplearning.com/chap3.html#handwriting\_recognition\_revisited\_the\_code](http://neuralnetworksanddeeplearning.com/chap3.html#handwriting_recognition_revisited_the_code) as well as the code from [https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist\_loader.py](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_loader.py) in an attempt to replicate the results before diving in to understanding the code, but encountered an error which has left me scratching my head:

    &lt;ipython-input-8-a6ce41c7644b&gt; in SGD(self, training_data, epochs, mini_batch_size, eta, lmbda, evaluation_data, monitor_evaluation_cost, monitor_evaluation_accuracy, monitor_training_cost, monitor_training_accuracy)
        153 
        154         """"""
    --&gt; 155         if evaluation_data: n_data = len(evaluation_data)
        156         n = len(training_data)
        157         evaluation_cost, evaluation_accuracy = [], []
    
    TypeError: object of type 'zip' has no len()

The notebook I was using and the error message can be found here: [https://github.com/arjung128/MNIST/blob/master/NumPyMNIST.ipynb](https://github.com/arjung128/MNIST/blob/master/NumPyMNIST.ipynb)

Any ideas on what's going wrong and what can be done to fix it?

Any suggestions will be much appreciated, thanks!! ",2,1
15,2019-1-3,2019,1,3,1,abv17m,What are the important things I should take into consideration when choosing a graduation project where I must use deep learning if I do not want to pick a very hard project as an undergraduate student?,https://www.reddit.com/r/deeplearning/comments/abv17m/what_are_the_important_things_i_should_take_into/,superibr,1546447403,I neither do not want to be stuck in a difficult situation nor end up with a very easy project,3,1
16,2019-1-3,2019,1,3,2,abvdpe,The process of training pytorch model got stuck in tmux.,https://www.reddit.com/r/deeplearning/comments/abvdpe/the_process_of_training_pytorch_model_got_stuck/,Catherine_Fang,1546449539,"The process of training pytorch model got stuck in tmux.
Has anyone encountered the same problem?",3,1
17,2019-1-3,2019,1,3,2,abvkfv,[Question]Book Recommendations for Beginners.,https://www.reddit.com/r/deeplearning/comments/abvkfv/questionbook_recommendations_for_beginners/,emperor9876,1546450676,"I'm currently doing the Andrew Ng Deep Learning Specialization from Coursera. I'm a Undergrad student with decent Python experience and am looking for a book that covers not only the deep learning part but also my mathematics behind it. 

Possibly something that could go hand in hand with the specialization or something application focused or anything that helped you the most when starting out. 

 ",1,1
18,2019-1-3,2019,1,3,3,abw542,Seeking cofounder,https://www.reddit.com/r/deeplearning/comments/abw542/seeking_cofounder/,tarantillo,1546454102,"Hello everybody!

I apologize if this post is inappropriate but I'm hoping it's within sub rules.

We are starting a tech company in the Northern California region and are searching for a possible CTO/cofounder.

What we are trying to do is to bring a smart management system for retail businesses. Our system will ""replace"" (or augment) owners/managers by creating smart and dynamic task lists for employees. The task lists are generated using ML vision processing algorithm (i.e. that detects there's a spill or a misplaced item) and IOT sensors that are linked up to provide data such as when an item goes out of stock. When retail businesses are run efficiently and effectively by owners/managers  through clear and concse direction for hourly front end employees on what to do on an ongoing basis the businesses are much more profitable. And we are simply trying to duplicate this increase to their bottom line using our software.

If what I wrote above sounds intimidating then don't be alarmed. What we are trying to do doesn't require that deep of a DL/ML knowledge. In fact someone who has done the Coursera ML class from Stanford and who can code very likely is qualified enough. 

If you have some decent knowledge of DL/ML, can code, and is interested in becoming a founding partner of a tech company in the heart of the tech industry near Silicon Valley then please send me a pm and let's chat further.",0,1
19,2019-1-3,2019,1,3,6,abxwj0,Need advice for PC build,https://www.reddit.com/r/deeplearning/comments/abxwj0/need_advice_for_pc_build/,Irivaka,1546464194,"So since Im starting my bachelors degree in AI and Machine Learning, I need a pc for just that.
 I've read that I need at least as much RAM as VRAM, fast single core speed and I've chosen an RTX 2080ti as GPU of choice. I'm torn between 9600K and 6700K and the RAM to pair it with. 
PCIe lanes are very important but I'm only getting a single card for the coming years, I would like to get an NVMe SSD but I'm afraid I wont have 16 lanes left for my GPU if I go for an Intel CPU. 
Could someone give me any tips? Would appreciate it a lot!",3,1
20,2019-1-3,2019,1,3,11,ac0tb3,Trying out Tensorflow JS,https://www.reddit.com/r/deeplearning/comments/ac0tb3/trying_out_tensorflow_js/,immortaljoe,1546482292,,0,1
21,2019-1-3,2019,1,3,11,ac0tgg,Apache Zeppelin: stairway to notes* haven!,https://www.reddit.com/r/deeplearning/comments/ac0tgg/apache_zeppelin_stairway_to_notes_haven/,neomatrix369,1546482319,,1,1
22,2019-1-3,2019,1,3,11,ac0tu6,Very nice introduction to deep neural network without too much math,https://www.reddit.com/r/deeplearning/comments/ac0tu6/very_nice_introduction_to_deep_neural_network/,qikpal,1546482389,,1,1
23,2019-1-3,2019,1,3,12,ac177v,Kubeflow in 2018: A year in perspective  kubeflow  Medium,https://www.reddit.com/r/deeplearning/comments/ac177v/kubeflow_in_2018_a_year_in_perspective_kubeflow/,codekee,1546484805,,0,1
24,2019-1-3,2019,1,3,14,ac2n6q,The Future of Cloud Computing,https://www.reddit.com/r/deeplearning/comments/ac2n6q/the_future_of_cloud_computing/,BlockDelta,1546494875,,0,1
25,2019-1-3,2019,1,3,15,ac345g,Many of the best probabilistic models represent probability distributions implicitly,https://www.reddit.com/r/deeplearning/comments/ac345g/many_of_the_best_probabilistic_models_represent/,sriharsha_0806,1546498554,"Hi, I'm reading the 5th chapter of Deep Learning book. I came across the following sentence ""Many of the best probabilistic models represent probability distributions implicitly"". What is the meaning of the sentence and can you provide program example explaining this if possible? ",4,1
26,2019-1-3,2019,1,3,20,ac4q30,I am trying to build a PC for my deep learning needs. I am still learning. If I am on a budget here. Need advice.,https://www.reddit.com/r/deeplearning/comments/ac4q30/i_am_trying_to_build_a_pc_for_my_deep_learning/,TheHawkGriffith,1546513611,"I am still learning. My laptop is too sucky for training complex models or longer iteration times. 
I am on a budget. Thus I have so far decided a Gigabyte motherboard, 2x8 GBs of Corsair RAM, an Nvidia 1060, and an i5 8th gen!
Is this a good build? 
Any advice is welcome.  ",12,1
27,2019-1-3,2019,1,3,20,ac52ej,Data Science Project Flow for Startups,https://www.reddit.com/r/deeplearning/comments/ac52ej/data_science_project_flow_for_startups/,shaypal5,1546516761,,0,1
28,2019-1-4,2019,1,4,0,ac6j8h,"Machine Learning, Deep Learning, Neural Networks textbooks",https://www.reddit.com/r/deeplearning/comments/ac6j8h/machine_learning_deep_learning_neural_networks/,PM_ME_UR_TECHNO_GRRL,1546528174,"Any recommendations on textbooks dealing with these topics?

This book on simulation

https://www.amazon.com/Simulation-Mcgraw-hill-Industrial-Engineering-Management-ebook/dp/B00HZ3B2TS/ref=sr_1_2?s=digital-text&amp;ie=UTF8&amp;qid=1546528101&amp;sr=1-2&amp;keywords=simulation+modeling

Handles the topic very well, but makes it accessible to anyone with a rudimentary knowledge of statistics. I am hoping to get something of that sort, dealing with neural networks.

Thank you in advance.",1,1
29,2019-1-4,2019,1,4,3,ac8bzb,SSD Bounding box fitting question,https://www.reddit.com/r/deeplearning/comments/ac8bzb/ssd_bounding_box_fitting_question/,moghaak,1546538983,"So I am trying to implement SSD and have various anchor sizes as defined below.

`SSD_ANCHOR_SIZE = [[0.03, 0.1], [0.04, 0.1], [0.05, 0.1], [0.06, 0.1], [0.07, 0.1], [0.08, 0.1], [0.085, 0.1], [0.09, 0.1],`  
 `[0.095, 0.1], [0.1, 0.1], [0.11, 0.1], [0.12, 0.1], [0.13, 0.1], [0.14, 0.1], [0.15, 0.1]]`  
 `SSD_ANCHOR_RATIO = [[1, 1.1, 1.2], [1, 1.5, 1.75, 2], [1, 2.5, 3],[1, 3.5, 4, 4.5], [1, 4.5, 5, 5.5, 6], [1, 6.5, 7, 8],`  
 `[1, 7, 7.5, 8], [1, 8, 9], [1, 8, 8.5, 9], [1, 9, 9.5, 10], [1, 10, 10.5, 11, 12],`  
 `[1, 10, 11, 12, 13, 14], [1, 12 ,13, 14, 15, 16, 17], [1, 16, 17, 18, 19], [1, 17, 17.5, 18, 19]]`

Specification of boxes generated by these anchor size and ratio is  that either proposed boxes are square or proposed boxes should have  height ranging from 45 px to 55px and width ranging from 50px to 1000px  ranged at about 20px each on image size of 1650x1650px.

So in summary, bounding boxes proposed my MultiboxPrior function of  Gloun would generate bounding boxes that mimics a line (horizontal  rectangle). This rectangle would have size as described above.

But when I train the network and use MultiboxTarget function and  visualize the bounding boxes, I do not get any bounding boxes that are  or horizontal orientation or square. I get all bounding boxes that are  of vertical orientation.

So the question is how is this possible. Because my anchor size and  ratio allows for bounding box to be either horizontal rectangle or a  perfect square. Am I missing something? Does SSD work differently?",0,1
30,2019-1-4,2019,1,4,4,ac9hkc,InstaGAN Excels in Instance-Aware Image-To-Image Translation,https://www.reddit.com/r/deeplearning/comments/ac9hkc/instagan_excels_in_instanceaware_imagetoimage/,gwen0927,1546545484,,0,1
31,2019-1-4,2019,1,4,17,acg27l,Fast Neural Style Transfer demo. Turn your pictures into artwork!,https://www.reddit.com/r/deeplearning/comments/acg27l/fast_neural_style_transfer_demo_turn_your/,ahmedbesbes,1546589026,,1,1
32,2019-1-4,2019,1,4,18,acgpf9,AI that can output computer program when given a natural language query,https://www.reddit.com/r/deeplearning/comments/acgpf9/ai_that_can_output_computer_program_when_given_a/,omkarjc,1546595515,"want an AI architecture which can output Python code snippets or functions or whole classes when given a natural language input

Eg When given input

""Write a program to concatenate two strings"" 

It should output Python code as follows

""str = stra + strb ""

This is just a small example it would be great if it could do complex problems

",7,1
33,2019-1-4,2019,1,4,22,aci8i1,Asynchronous deep learning: training a neural net with Akka,https://www.reddit.com/r/deeplearning/comments/aci8i1/asynchronous_deep_learning_training_a_neural_net/,botkop,1546609134,,0,1
34,2019-1-4,2019,1,4,22,aciaht,[Doubt] Augmentation the training set - oversample a single class or equally scale all the images?,https://www.reddit.com/r/deeplearning/comments/aciaht/doubt_augmentation_the_training_set_oversample_a/,rahulkulhalli,1546609529,"Very naive question, but when we perform augmentations on the training set, do we scale ALL the classes constantly or just the minority class?

Won't oversampling the minority class disrup8t the training data class distribution?",0,1
35,2019-1-5,2019,1,5,0,acjd02,"Another question from the professional standpoint! Any practitioners or interviewers, please answer.",https://www.reddit.com/r/deeplearning/comments/acjd02/another_question_from_the_professional_standpoint/,TheHawkGriffith,1546616832,"I wanted to know if an in depth understanding of traditional CS algorithms and their time and space complexities is required for an ML/DL Engineer who basically specialises in say, NLP or Computer Vision and is hot on modern libraries and frameworks? 
Do you preferably only hire people who can both create the model pipeline and also make it deployable and efficient using algorithms design and analysis? ",3,1
36,2019-1-5,2019,1,5,8,aco0hu,Does deep learning always have to reinvent the wheel?,https://www.reddit.com/r/deeplearning/comments/aco0hu/does_deep_learning_always_have_to_reinvent_the/,ai-lover,1546643991,,0,1
37,2019-1-5,2019,1,5,13,acqnww,Feature data for LSTM - Can we use past labels as well as past features as inputs?,https://www.reddit.com/r/deeplearning/comments/acqnww/feature_data_for_lstm_can_we_use_past_labels_as/,throwaway_6545,1546662213,"Hi All,

I've been playing around with LSTM to understand how they work. I've a basic question regarding the inputs. So, can we use the features as well as ALL labels from the past to predict the label today?

For example -- Suppose I have the daily Open, High, Low, Close for an oil company and the oil Price. I collect the data for first 7 days. Now standing at the 7th day, there are two possibilities for the features -- 

1) I can either use the Open, High, Low, Close data for all 7 days to predict the oil price on day 7

2) Shift all the oil prices down (shift all the labels down -- oil price for day 1 goes to day 2). So, for day 7, use day2-day7 O,H,L,C and all the lagged oil prices (day2 - day7).

Which one seems correct? I'm really sorry if this is a stupid question. This is my first experience with LSTM. Really appreciate any help.",3,1
38,2019-1-5,2019,1,5,18,acsp6b,TCNs as an alternative for LSTMs?,https://www.reddit.com/r/deeplearning/comments/acsp6b/tcns_as_an_alternative_for_lstms/,bayeslaw,1546680278,"Ever since I read this
 https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0

And subsequently checked out (implemented and trained) TCNs

https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://arxiv.org/pdf/1803.01271&amp;ved=2ahUKEwiL09uuqNbfAhXBrHEKHYW4Cw0QFjAAegQIBRAB&amp;usg=AOvVaw28NjGIew4Pxe2jDm95oQDZ&amp;cshid=1546680125146

I've been wondering why aren't people talking more about this.. We got equal or better performance on our data in a fraction of training time.. Any love here for TCNs? ",5,1
39,2019-1-5,2019,1,5,23,acun7x,Deep Learning Training In India,https://www.reddit.com/r/deeplearning/comments/acun7x/deep_learning_training_in_india/,SunilAhujaa,1546699160,"Join Analytixlabs for AI and machine learning online course. This AI and Deep learning course offers practical and task-oriented training using TensorFlow and Keras on Python platform. This is a specialization course which will help you to get a break into AI and Deep Learning domain. To Know more click here [https://www.analytixlabs.co.in/ai-deep-learning-training-with-python](https://www.analytixlabs.co.in/ai-deep-learning-training-with-python)

&amp;#x200B;",2,1
40,2019-1-5,2019,1,5,23,acusa8,Slightly changed keras LSTM architecture for train and test,https://www.reddit.com/r/deeplearning/comments/acusa8/slightly_changed_keras_lstm_architecture_for/,nlpredditproject,1546700297," I'm trying to build a keras LSTM model that is similar to a language model (something like predicting next word , after seeing a few previous words).

My data has 2 features - a previous score and a previous choice. At training ,each cell should get the Xt (which , as said - has 2 features) and predict y\_hat and at the end of the sequence I expect the loss to be the categorical loss between the y\_hats and y\_truths .

Thing is , I want the test to be as follows : option 1: the t th cell should get the previous score (Xt's first feature) and the previous choice(Xt's second feature) - and this t cell should produce y\_hat that will be given to t+1 cell , along with Xt+1 first feature (meaning that the previous choice is now yt\_hat).

option 2: same as 1, only with outputting prediction only at the end of the sequence.

Can it even be done in keras , or should I go to a more low-level approach such as tensorflow ?",0,1
41,2019-1-6,2019,1,6,0,acutdu,Machine Learning Institute In Delhi,https://www.reddit.com/r/deeplearning/comments/acutdu/machine_learning_institute_in_delhi/,SunilAhujaa,1546700523,,0,1
42,2019-1-6,2019,1,6,1,acvtw5,AI Assistance With PyText,https://www.reddit.com/r/deeplearning/comments/acvtw5/ai_assistance_with_pytext/,AshishKhuraishy,1546707542,,0,1
43,2019-1-6,2019,1,6,14,ad2okh,Using both a Amd and Nvidia gpu.,https://www.reddit.com/r/deeplearning/comments/ad2okh/using_both_a_amd_and_nvidia_gpu/,therealatliss,1546751954,"Just wondering about this. If i wanted to use a AMD gpu for general day to day stuff and a Nvidia card for just processing power, would that be possible?

Specs:
Amd Ryzen 1600
Xfx rx 580
Gigabyte Gtx 1050ti

Im new to this stuff btw.",5,1
44,2019-1-6,2019,1,6,18,ad4cbf,Why does RELU activation function work?,https://www.reddit.com/r/deeplearning/comments/ad4cbf/why_does_relu_activation_function_work/,katiex7,1546768434,"Something I never understood is why including RELU Activation functions in the hidden layers improved the model on both my training and test sets for the pet projects I've worked on. I just took it as, it'll magically help accuracy and find correlations, but I never quite understood how.  


I mean the whole concept is so random and would like some intuition as to why RELU helps models.",13,1
45,2019-1-6,2019,1,6,22,ad5q9b,A Layman guide to moving from Keras to Pytorch,https://www.reddit.com/r/deeplearning/comments/ad5q9b/a_layman_guide_to_moving_from_keras_to_pytorch/,mlwhiz,1546782739,,4,1
46,2019-1-6,2019,1,6,22,ad5qxs,[Project] Open Source Feature Store: the missing data layer in ML pipelines?,https://www.reddit.com/r/deeplearning/comments/ad5qxs/project_open_source_feature_store_the_missing/,jpdowlin,1546782901,,0,1
47,2019-1-7,2019,1,7,16,adf722,Whats next after ML and Deep Learning specialization courses at Coursera?,https://www.reddit.com/r/deeplearning/comments/adf722/whats_next_after_ml_and_deep_learning/,gautam5669,1546844620,"I've finished and obtained certificates for ML and Deep Learning specialization courses at Coursera. I am currently working as software engineer. My day to day to work involves mostly building infrastructure for data scientist, researcher and data engineer. I still feel I need more exposure to deep learning in terms of building application by writing code. Any suggestion how to move forward ? I am also looking for some suggestion on application in vision or NLP  etc where deep learning would be applicable. ",9,1
48,2019-1-7,2019,1,7,20,adgtsv,Multilingual Word Embeddings,https://www.reddit.com/r/deeplearning/comments/adgtsv/multilingual_word_embeddings/,PiAreSqured,1546860468,"In order to classify sentences in multiple languages, we need multilingual word embeddings (All languages in single vector space). Now the question is why do you want to do it? why not separate models for separate language? The answer to that is if I have less data for a single language, it would be beneficial to include data from other languages in order to make the model more effective.

I am finding it hard to get any tool that would help me do it. Yes, I know that we can create word embedding on the go while training a network but there comes another fine theory. If I don't have enough data for one language who well the vectors are? Hence what I decided was to use something similar to the original data but which has huge data points.

There are tools like facebooks [MUSE](https://github.com/facebookresearch/MUSE) but they don't align multiple languages into a single vector space.

It would be helpful if the community can help me here. Any further questions or suggestions are welcome here

Have already looked into fastText vector alignment. They allow 2 languages.",1,1
49,2019-1-7,2019,1,7,21,adh11l,Human-in-the-loop for object detection with Supervisely and YOLO v3,https://www.reddit.com/r/deeplearning/comments/adh11l/humanintheloop_for_object_detection_with/,tdionis,1546862409,,0,1
50,2019-1-7,2019,1,7,21,adh2et,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educative",https://www.reddit.com/r/deeplearning/comments/adh2et/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1546862735,,0,1
51,2019-1-7,2019,1,7,22,adhsbi,"Keras merge([layer1, layer2], mode='mul')",https://www.reddit.com/r/deeplearning/comments/adhsbi/keras_mergelayer1_layer2_modemul/,arjundupa,1546868644,"I am trying to use this Keras WaveNet implementation: [https://github.com/usernaamee/keras-wavenet/blob/master/simple-generative-model.py](https://github.com/usernaamee/keras-wavenet/blob/master/simple-generative-model.py)

I get an error on line 23 -- the following is line 23:

    merged = merge([tanh_out, sigmoid_out], mode='mul')

The following is the error:

    TypeError: 'module' object is not callable

I understand what the error is saying; that merge is not a function that can be used like merge(parameter). Right? But I'm not sure how to resolve this error -- since the mode is 'mul', would using Keras' multiply layer (found under [https://keras.io/layers/merge/](https://keras.io/layers/merge/)) be equivalent?

Any ideas will be much appreciated, thanks!",4,1
52,2019-1-8,2019,1,8,0,adij6i,Cool app for learning deep learning concepts,https://www.reddit.com/r/deeplearning/comments/adij6i/cool_app_for_learning_deep_learning_concepts/,ScienTecht,1546873787,Check out this app I've been using to learn deep learning concepts. Very well-explained for newcomers to the field! [Artificial Intelligence School](https://itunes.apple.com/us/app/artificial-intelligence-school/id1369987569?mt=8),0,1
53,2019-1-8,2019,1,8,2,adjn8t,MIT Deep Learning with a tutorial on driving scene segmentation with TensorFlow,https://www.reddit.com/r/deeplearning/comments/adjn8t/mit_deep_learning_with_a_tutorial_on_driving/,ConfidentMushroom,1546880519,,0,1
54,2019-1-8,2019,1,8,3,adkqvt,A Layman guide to moving from Keras to Pytorch,https://www.reddit.com/r/deeplearning/comments/adkqvt/a_layman_guide_to_moving_from_keras_to_pytorch/,mlwhiz,1546886792,,1,1
55,2019-1-8,2019,1,8,4,adkygo,Which label masks do I need for object segmentation?,https://www.reddit.com/r/deeplearning/comments/adkygo/which_label_masks_do_i_need_for_object/,veranceftw,1546887969,"Hello, I'm developing an annotation app for oncocytic cells. However, I'm not sure if I should create different labels for those cells. Cells can be oncocytes or normal and I want an expert to annotate each cell accordingly.  With that annotation I want to implement a model that identifies the cells that are an Oncocyte. Do I need to  ask the pathologist to annotate both the oncocytes (swollen cells) and  non-oncocytes (regular cells)? I read some papers and some foundations of Unet/Mask R-CNN architectures. For  what I could understand for instance-segmentation, the only masks I need  are from the objects I actually want to identify. Could you tell me if  I'm wrong, please?  
 ",0,1
56,2019-1-8,2019,1,8,4,adl2lq,Top Ten Technological Disruptions of 2018 Contd - Part II -,https://www.reddit.com/r/deeplearning/comments/adl2lq/top_ten_technological_disruptions_of_2018_contd/,BlockDelta,1546888624,,0,1
57,2019-1-8,2019,1,8,7,adncld,Why does neural network work?,https://www.reddit.com/r/deeplearning/comments/adncld/why_does_neural_network_work/,Leaves_orz,1546901455,"I am a Computer Science student, and I am learning deep learning recently. I have some confusions on how neural network works. For example, if we have a layer with 4 hidden neurons and we randomize them at the beginning. What factors will  make one neuron different from other 3 neurons? They have the same input and the same process of backpropagation. Why shouldn't these neurons converge to the same value.",6,1
58,2019-1-8,2019,1,8,9,adokiq,"Do conv layers (conv2D) use separable convolutions? If so, why not?",https://www.reddit.com/r/deeplearning/comments/adokiq/do_conv_layers_conv2d_use_separable_convolutions/,TheTierney,1546908830,"Hey!

I'm kind of new to deep learning. Been working on some models and playing around with keras and tensorboard.

Recently, computerphile posted a video on separable convolutions and its applications mostly for gaussian blur and other types of blur [link to the video](https://www.youtube.com/watch?v=SiJpkucGa1o)

&amp;#x200B;

That made me wonder if the conv layers on NN's also used separable convolutions. I didn't find as much info as I was thinking I'd get, but it seemed there's a different type of layer (SeparableConv2D) that does use separable convolutions, whilst the Conv2D doesn't. I also heard it's not ideal to use SeparableConv2D early in the models.

&amp;#x200B;

If both product of matrices produce the same result and separable is so much faster than a normal convolution window, why does conv2D not use this technique? Why is it dangerous?

&amp;#x200B;

Apologies in advance if the question doesn't make much sense or is kind of dumb.

Thank you for your help!

Nuno",1,1
59,2019-1-8,2019,1,8,11,adpbl2,Kaggle: How to Place in the Top 10% (part 1),https://www.reddit.com/r/deeplearning/comments/adpbl2/kaggle_how_to_place_in_the_top_10_part_1/,keghn,1546913551,,2,1
60,2019-1-8,2019,1,8,14,adquyf,"How to create an IMDB rating generator if i have the movie,genre,actor,director associated with film using neural networks?",https://www.reddit.com/r/deeplearning/comments/adquyf/how_to_create_an_imdb_rating_generator_if_i_have/,karanbangia14,1546923932,,1,1
61,2019-1-8,2019,1,8,18,adsqui,MSc project idea,https://www.reddit.com/r/deeplearning/comments/adsqui/msc_project_idea/,nttuan8,1546941024," Dear all, 

I am thinking about the idea for the MSc project. I want to follow deep learning + computer vision. Can you suggest me some interesting ideas? 

Many thanks. ",2,1
62,2019-1-8,2019,1,8,20,adtebm,[Marketing] Pattern Research Survey (All Welcome),https://www.reddit.com/r/deeplearning/comments/adtebm/marketing_pattern_research_survey_all_welcome/,var97,1546947454,,0,1
63,2019-1-8,2019,1,8,21,adtjt9,Learn Data Science  Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/adtjt9/learn_data_science_deep_learning_in_python/,nwyr19,1546948887,,0,1
64,2019-1-9,2019,1,9,0,adv71l,Survey : Understanding the relocation preferences and challenges faced by AI talents,https://www.reddit.com/r/deeplearning/comments/adv71l/survey_understanding_the_relocation_preferences/,Consilience_OY,1546960890,"Do you currently work in or are you a student in data science, machine learning, AI or a closely related field?

If yes, were trying to understand the reasons behind AI talents choice of work, (re)location and the challenges they face. If you feel that companies or cities do not seem to understand what attracts you to (or drives you away from) a job/location, this is your chance to offer some solid statistics on your preferences.

We would really appreciate it if you filled out our survey (\~10-15 minutes):

[https://docs.google.com/forms/d/1qsl0Y0z\_tO4PSuoIJr7NXwAoEAvP\_kluEhcxFzhzZP0/viewform?edit\_requested=true](https://docs.google.com/forms/d/1qsl0Y0z_tO4PSuoIJr7NXwAoEAvP_kluEhcxFzhzZP0/viewform?edit_requested=true)

Thanks a lot!",0,1
65,2019-1-9,2019,1,9,0,advi4k,Dealing with outliers,https://www.reddit.com/r/deeplearning/comments/advi4k/dealing_with_outliers/,Redhatchamp00,1546962637,"(Beginner here)
I recently learnt about how outliers can drastically reduce accuracy and how to find them.
To test my knowledge, I tried applying it on a dataset for predicting house prices. I used scatterplot to find out the outliers for a particular feature. It turned out that the values beyond '3000' were outliers. 

In python, the usual code is:
dataset = dataset [dataset[feature] &lt; 3000]

However, I found that this deletes complete rows, leading to, I think, unaffordable loss of data. The original shape of dataframe was (1460, 80), but after executing the code above it reduced the shape to (1374, 80).

Is there a possible way to get rid of outliers but at the same time not delete every other feature in the particular row? ",5,1
66,2019-1-9,2019,1,9,0,advjfz,Best AI articles in December?,https://www.reddit.com/r/deeplearning/comments/advjfz/best_ai_articles_in_december/,florian_c,1546962850,"The technological watch is so important in Deep Learning. I just published an article that tries to sum up what happened in Artificial Intelligence / Data Science in December:

 [https://blog.sicara.com/12-2018-best-ai-new-articles-this-month-79aa681b4a27](https://blog.sicara.com/12-2018-best-ai-new-articles-this-month-79aa681b4a27) 

&amp;#x200B;

If you could take a look and give your opinion about it (did I miss something? anything approximate?), I'd be grateful!",0,1
67,2019-1-9,2019,1,9,1,adw4l4,The Neural Search Frontier : Doug Turnbull &amp; Tommaso Teofili (Berlin Buzzwords 2018),https://www.reddit.com/r/deeplearning/comments/adw4l4/the_neural_search_frontier_doug_turnbull_tommaso/,newthinkingevents,1546966022,,0,1
68,2019-1-9,2019,1,9,3,adx3j4,Tips for implementing SSD Object Detection (with TensorFlow code),https://www.reddit.com/r/deeplearning/comments/adx3j4/tips_for_implementing_ssd_object_detection_with/,sabalaba,1546971121,,0,1
69,2019-1-9,2019,1,9,14,ae3j8h,Hi. Is there a free cuda cloud server where I can practice PyTorch?,https://www.reddit.com/r/deeplearning/comments/ae3j8h/hi_is_there_a_free_cuda_cloud_server_where_i_can/,Ubrrmensch,1547010663,"My laptop does not have GPU 

",6,1
70,2019-1-9,2019,1,9,18,ae55jt,Deep Learning Applications &amp; Algorithms with Neural Networks - Happiest Minds,https://www.reddit.com/r/deeplearning/comments/ae55jt/deep_learning_applications_algorithms_with_neural/,aksri198,1547025437,,0,1
71,2019-1-9,2019,1,9,18,ae5ckd,DEMO: Automatic image captioning with visual attention using PyTorch,https://www.reddit.com/r/deeplearning/comments/ae5ckd/demo_automatic_image_captioning_with_visual/,ahmedbesbes,1547027428,,3,1
72,2019-1-9,2019,1,9,20,ae5w5m,Scaling machine learning in the cloud with Kubernetes and Kubeflow,https://www.reddit.com/r/deeplearning/comments/ae5w5m/scaling_machine_learning_in_the_cloud_with/,SoulmanIqbal,1547032597,,0,1
73,2019-1-9,2019,1,9,20,ae63ev,How Deep Learning Can Help Predict Human Behavior,https://www.reddit.com/r/deeplearning/comments/ae63ev/how_deep_learning_can_help_predict_human_behavior/,oodlestechnologies,1547034504,"&amp;#x200B;

[Deep Learning is Helping Industries By Forecasting Human Behavior](https://i.redd.it/3gejhqv6yd921.jpg)

With the advent of Deep Learning technology, we can forecast human behavior. Today we have advanced computers, an immense amount of behavioral data, and Deep Learning technology. Let's figure out how deep learning technology is helping in forecasting human behavior!

Read more info at - [**https://www.oodlestechnologies.com/blogs/Deep-Learning-is-Helping-Industries-By-Forecasting-Human-Behavior**](https://www.oodlestechnologies.com/blogs/Deep-Learning-is-Helping-Industries-By-Forecasting-Human-Behavior)",0,1
74,2019-1-10,2019,1,10,1,ae8g83,Tips on how to get started with image manipulation (e.g. making a face smile),https://www.reddit.com/r/deeplearning/comments/ae8g83/tips_on_how_to_get_started_with_image/,bandalorian,1547051243,"I was initially planning on building some kind of binary face classifier (such as a smile detector) as part of a project. However, since there are several available it got me thinking if I could instead build something on top of a smile detector, that manipulates images to make a smiling image (like [this](https://l.faceapp.com/img/asset/Preview_Image_smile-210f88ce8e.png)). 

* What is the proper name for this type of technique? It's not quite the same as neural style transfer so maybe it's called something specific?
* If anyone could recommend any reading material/tutorials etc that would be great
* Compared to building a smile detector from scratch (assuming I'm using an existing face detector), how much harder is this? I.e is taking an existing smile classifier as a base for image manipulation significantly more complex than just taking a face detector and building a smile classifier from scratch? Or maybe it's easier?

Any advice is much appreciated",1,1
75,2019-1-10,2019,1,10,10,aedykk,"My presentations on 'Elements of Neural Networks &amp; Deep Learning' -Part1,2,3",https://www.reddit.com/r/deeplearning/comments/aedykk/my_presentations_on_elements_of_neural_networks/,tvganesh,1547083989,,0,1
76,2019-1-10,2019,1,10,11,aeei4f,B250 mining Mother bored for FPGA based deep learning? (With alternative angle.),https://www.reddit.com/r/deeplearning/comments/aeei4f/b250_mining_mother_bored_for_fpga_based_deep/,Kainkelly2887,1547087685,"Has anyone used a B250 miner like this for deep learning with FPGA's?

[https://www.asus.com/us/Motherboards/B250-MINING-EXPERT/](https://www.asus.com/us/Motherboards/B250-MINING-EXPERT/)

I assume that the bios one that does not automatically load a mining program. This will be used for FPGA based AI training and acceleration. (I may for the sake of it not sitting there between projects, do some mining/coin trading on the side.) Would there still be band width issues due to bottle necking from the lack of band width? Also what about that memory for data sets this big will 32 gb be enough, plus everything on the cards. 

&amp;#x200B;

My alternative would be two of these.

 [https://www.newegg.com/Product/Product.aspx?Item=N82E16813145125](https://www.newegg.com/Product/Product.aspx?Item=N82E16813145125)

I would just rather avoid having two cpus for power draw reasons. Granted the flip side of that being I can do two separate things at once has its own appeal.

&amp;#x200B;

Just in case it holds any relevance, this will be used for AI based code fuzzing and cryptography. Plus what ever else I feel like doing AI related.... Then when I get to busy/stuck, mining/trading.",8,1
77,2019-1-10,2019,1,10,13,aefdfx,Error while running MNLI task using BERT tensorflow.,https://www.reddit.com/r/deeplearning/comments/aefdfx/error_while_running_mnli_task_using_bert/,mundada,1547093839,"I was able to run MRPC task but with MNLI task I getting error. 

The error basically states that there is mismatch of size for labels. MNLI has 3 classes and the graph saved is for 2 classes.

I guess, I am missing some more code changes required to run MNLI.

Any help would be much appreciated.

Thanks for reading.",0,1
78,2019-1-10,2019,1,10,20,aei6tg,How much of statistical theory should I know to be able to come up with better models?,https://www.reddit.com/r/deeplearning/comments/aei6tg/how_much_of_statistical_theory_should_i_know_to/,TheHawkGriffith,1547119565,"I read somewhere that unapplicable knowledge is utter trash. 
So since I dont have a lot of time wandering about reading books. How much of statistics and probability do I need to know what affects what and how to generate better model for different tasks?
Surely its got to be less than what someone who is a researcher in the field of deep learning should know compared to a practitioner/engineer. Any thoughts?  ",7,1
79,2019-1-10,2019,1,10,21,aeitq4,Using VAE for Feature Extraction Question,https://www.reddit.com/r/deeplearning/comments/aeitq4/using_vae_for_feature_extraction_question/,eigenvergle42,1547124468,"Hey guys,

&amp;#x200B;

I heard these are good for feature extraction and I'm drafting one up, but they are a bit more opaque than some other autoencoders it seems. My question is, what exactly is used as the features themselves? 

&amp;#x200B;

Most of the flavors create a latent mean &amp; deviation, then sample from that distribution using noise to build the final latent representation. So, my guess is that you use the latent parametrization instead of the final representation, unless you deliberately want noisy features.

&amp;#x200B;

Can anyone with expertise comment or point me towards any good paper discussing this?",2,1
80,2019-1-11,2019,1,11,1,aekg6b,Stanford Open-Sources Neural Network Verification Project,https://www.reddit.com/r/deeplearning/comments/aekg6b/stanford_opensources_neural_network_verification/,gwen0927,1547136778,,0,1
81,2019-1-11,2019,1,11,1,aekxeh,A deep learning approach to predict the impact of non-coding sequence variants on 3D chromatin structure [Research P],https://www.reddit.com/r/deeplearning/comments/aekxeh/a_deep_learning_approach_to_predict_the_impact_of/,ai-lover,1547139576,,0,1
82,2019-1-11,2019,1,11,4,aemd1b,Exploring DNA with Deep Learning,https://www.reddit.com/r/deeplearning/comments/aemd1b/exploring_dna_with_deep_learning/,pirate7777777,1547147859,,2,1
83,2019-1-11,2019,1,11,5,aemyvx,what are retrieval based methods in deep learning?,https://www.reddit.com/r/deeplearning/comments/aemyvx/what_are_retrieval_based_methods_in_deep_learning/,nisucuk,1547151383,"can anyone tell me about retrieval based methods, what they are, types, examples and applications",0,1
84,2019-1-11,2019,1,11,5,aen9mb,Deep Learning in Python (Free Course Offered),https://www.reddit.com/r/deeplearning/comments/aen9mb/deep_learning_in_python_free_course_offered/,skj8,1547153103,,0,1
85,2019-1-11,2019,1,11,6,aenfvq,AI Uses Face Scans to Diagnose Rare Genetic Disorders,https://www.reddit.com/r/deeplearning/comments/aenfvq/ai_uses_face_scans_to_diagnose_rare_genetic/,gwen0927,1547154104,,0,1
86,2019-1-11,2019,1,11,10,aeq4fs,Google Cloud Question,https://www.reddit.com/r/deeplearning/comments/aeq4fs/google_cloud_question/,VectorACR,1547170288,I've configured a machine program ready to train on my local computer. I don't know how exactly I can implement this on google cloud though. I've made a project on the cloud but I don't know how to train on there. Can somebody help me?,0,1
87,2019-1-11,2019,1,11,14,aes8s7,"[P] All-in-one development container: ""AI Lab""",https://www.reddit.com/r/deeplearning/comments/aes8s7/p_allinone_development_container_ai_lab/,tlkh,1547185266,,3,1
88,2019-1-11,2019,1,11,16,aet50i,"[Advice] Roughly how long should I expect me to take to complete the DL (MIT Press) book if I have an average undergraduate level of understanding of Probability, Statistics and Linear Algebra?",https://www.reddit.com/r/deeplearning/comments/aet50i/advice_roughly_how_long_should_i_expect_me_to/,Akainu18448,1547193003,"I know this isn't the right way to think about it. I'm just making a rough time table for myself to finish a decent sized chunk of the field as a newcomer, by this May.

If anyone here has completed reading the book, please let me know how long it took you to go through it. Thank you!",3,1
89,2019-1-11,2019,1,11,17,aetiul,Tracking Our Children's Future via Smart Uniforms,https://www.reddit.com/r/deeplearning/comments/aetiul/tracking_our_childrens_future_via_smart_uniforms/,BlockDelta,1547196804,,0,1
90,2019-1-11,2019,1,11,18,aetruw,Content Moderation in 2019 : Human vs AI,https://www.reddit.com/r/deeplearning/comments/aetruw/content_moderation_in_2019_human_vs_ai/,nanonets,1547199329,,1,1
91,2019-1-11,2019,1,11,19,aeu65o,Viewing Restricted Access Publications,https://www.reddit.com/r/deeplearning/comments/aeu65o/viewing_restricted_access_publications/,arjundupa,1547203068,"I'm trying to view these two publications:

    https://www.ncbi.nlm.nih.gov/pubmed/30191539
    https://ieeexplore.ieee.org/document/8300189

But both are restricted. If I remember correctly, I saw a link which allows you to see a bunch of restricted access publications -- anyone have that link? Or any other way I could view these publications? Thanks!",1,1
92,2019-1-11,2019,1,11,21,aev0ri,3+ Best Deep Learning Courses [Dev Community],https://www.reddit.com/r/deeplearning/comments/aev0ri/3_best_deep_learning_courses_dev_community/,skj8,1547210672,,2,1
93,2019-1-11,2019,1,11,21,aev233,High loss despite high accuracy?,https://www.reddit.com/r/deeplearning/comments/aev233/high_loss_despite_high_accuracy/,kellyoceallaigh,1547210967,"I'm running Keras on a binary classification problem using binary cross entropy as my loss function. I can get my accuracy on my train data up to 100% but it still reports a very high loss (22). How can this be the case? Is the loss somewhat arbitrary and it should be decreasing only relative to itself i.e. starting at 22.6 and ending at 20.9; or should loss always be aiming to be close to zero? 

If my model is 100% accurate on the train data (probably overfitting) how can there be any loss at all, the error should be zero, no? Thanks if anyone has more intuition on this than I do!",3,1
94,2019-1-11,2019,1,11,21,aev3xn,How to moderate content in 2019 : Human vs AI,https://www.reddit.com/r/deeplearning/comments/aev3xn/how_to_moderate_content_in_2019_human_vs_ai/,nanonets,1547211396,,1,1
95,2019-1-12,2019,1,12,2,aextp7,Most ubiquitously used company or product for turnkey deep learning desktop solutions?,https://www.reddit.com/r/deeplearning/comments/aextp7/most_ubiquitously_used_company_or_product_for/,hatandspecs,1547228641,"Hi,

I'm a academic data analyst/researcher at the level of sophistication where I can stick a Titan X into a tower install drivers, packages, and dependencies and do my experiments.  Pytorch, tensorflow, caffe, no issues.  Hardware is not my area.  A lot of folks on this sub far surpass my level of sophistication and experience!

I just need to get this hardware on more desks to run more simultaneous experiments and I don't have the tech support to do it for me or the time to completely muddle through it myself.

Questions 

1. Am I even thinking about this the right way?  Is there some relatively turnkey system or combination of products that would allow me to easily give 5 or 6 researchers a VM with GPU resources they could use simultaneously?

2. If the way I'm thinking about this isn't wrong, what company or products are most popular among academic researchers without much tech support available?",5,1
96,2019-1-12,2019,1,12,3,aeyavd,"Learn Data Science, Machine and Deep Learning with Python",https://www.reddit.com/r/deeplearning/comments/aeyavd/learn_data_science_machine_and_deep_learning_with/,jhncna,1547231393,,0,1
97,2019-1-12,2019,1,12,8,af1a1s,Deep Learning Basics: Introduction and Overview - MIT (Lex Fridman ),https://www.reddit.com/r/deeplearning/comments/af1a1s/deep_learning_basics_introduction_and_overview/,ai-lover,1547248359,,1,1
98,2019-1-12,2019,1,12,14,af4laz,Google colab for deep learning?,https://www.reddit.com/r/deeplearning/comments/af4laz/google_colab_for_deep_learning/,thor_and_dr_jones,1547272693,"Google colab seems like a great free environment to train DL models. I'm just a beginner, so was curious what the community normally uses for their GPU requirements. 

Is there any better cloud based GPU provider out there for fast, free and easy computation? ",5,1
99,2019-1-12,2019,1,12,15,af4s5i,Resnet 50 Frozen graph,https://www.reddit.com/r/deeplearning/comments/af4s5i/resnet_50_frozen_graph/,_spicyramen,1547274323,"I'm trying to download ResNet 50 FP32 .pb model (Protobuf frozen graph), but can't find it, only option I found is saved models:

[https://github.com/tensorflow/models/tree/master/official/resnet](https://github.com/tensorflow/models/tree/master/official/resnet)

I need to run: python tensorrt.py --frozen\_graph option

[https://github.com/tensorflow/models/blob/master/research/tensorrt/README.md](https://github.com/tensorflow/models/blob/master/research/tensorrt/README.md)

&amp;#x200B;

&amp;#x200B;",0,1
100,2019-1-12,2019,1,12,23,af7lzm,"[P] Implementing P-adam, a novel optimization algorithm for Deep Neural Networks",https://www.reddit.com/r/deeplearning/comments/af7lzm/p_implementing_padam_a_novel_optimization/,pandeykartikey,1547301603,,0,1
101,2019-1-12,2019,1,12,23,af7rjk,"[P] Implementing P-adam, novel optimization algorithm for Neural Networks",https://www.reddit.com/r/deeplearning/comments/af7rjk/p_implementing_padam_novel_optimization_algorithm/,pandeykartikey,1547302777,"This work is a part of ICLR Reproducibility Challenge 2019, we try to reproduce the results in the conference submission PADAM: Closing The Generalization Gap of Adaptive Gradient Methods In Training Deep Neural Networks. Adaptive gradient methods proposed in past demonstrate a degraded generalization performance than the stochastic gradient descent (SGD) with momentum. The authors try to address this problem by designing a new optimization algorithm that bridges the gap between the space of Adaptive Gradient algorithms and SGD with momentum. With this method a new tunable hyperparameter called partially adaptive parameter p is introduced that varies between \[0, 0.5\]. We build the proposed optimizer and use it to mirror the experiments performed by the authors. We review and comment on the empirical analysis performed by the authors. Finally, we also propose a future direction for further study of Padam. Our code is available at: [https://github.com/yashkant/Padam-Tensorflow](https://github.com/yashkant/Padam-Tensorflow)",0,1
102,2019-1-12,2019,1,12,23,af7rn6,"[P] Implementing P-adam, novel optimization algorithm for Neural Networks",https://www.reddit.com/r/deeplearning/comments/af7rn6/p_implementing_padam_novel_optimization_algorithm/,harshalmittal4,1547302802,,0,1
103,2019-1-12,2019,1,12,23,af7ygd,Understanding Keras Dense Layer,https://www.reddit.com/r/deeplearning/comments/af7ygd/understanding_keras_dense_layer/,arjundupa,1547304195,"I am attempting to understand how Keras' dense layer actually works.

I implemented a very basic example of logistic regression using just NumPy, and am trying to obtain the exact same results using Keras. My code and results can be found here: [https://github.com/arjung128/neural-networks-from-scratch/blob/master/LogisticRegression.ipynb](https://github.com/arjung128/neural-networks-from-scratch/blob/master/LogisticRegression.ipynb)

I made sure that the following in the two (NumPy and Keras) implementations were the same: Data, weight initializations, model (number of parameters + activation function), learning rate, number of epochs, . I am pretty sure my loss function and optimizers are also the same, but not certain.

My NumPy implementation is 100% deterministic in that I get the EXACT same output every time I run my code -- nothing is random.

My Keras implementation is also deterministic. I'd like to get the EXACT same output as my NumPy implementation using my Keras implementation -- I am mainly trying to get the learned weights to be the same, but also the loss during training. Currently, my Keras implementation's loss starts out lower and ends up lower than my NumPy implementations.

Any ideas about what I could change to get the exact same results? Thanks!",3,1
104,2019-1-13,2019,1,13,0,af83s1,Deep learning generating Basketball plays survery,https://www.reddit.com/r/deeplearning/comments/af83s1/deep_learning_generating_basketball_plays_survery/,MooMooM1lk,1547305273," 

Hi guys, I created a GAN (Deep-learning) model using STATS NBA player data that learns to simulate basketball plays, both offensively and    defensively for my thesis. I need people to help me do a user survey in determining if the movements generated are realistic or not. If you have  the time please help me out :)

[https://docs.google.com/forms/d/e/1FAIpQLSdQiCIH\_jOywTX7SQxNhvv\_2tjrSYf6ogpKj5JevhHHJihmTw/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSdQiCIH_jOywTX7SQxNhvv_2tjrSYf6ogpKj5JevhHHJihmTw/viewform?usp=sf_link)

Thanks guys!",0,1
105,2019-1-13,2019,1,13,0,af83t0,Best book for deep learning for beginner,https://www.reddit.com/r/deeplearning/comments/af83t0/best_book_for_deep_learning_for_beginner/,durgesh2018,1547305279,"Hello everyone!
I am a new researcher who has zero knowledge of deep learning. What are the best books for a beginner like me to start with the deep learning.

Link to the resources will be appreciated.

Thank you! ",22,1
106,2019-1-13,2019,1,13,7,afclhz,Best Architecture for LSTM Network for Stock Prediction,https://www.reddit.com/r/deeplearning/comments/afclhz/best_architecture_for_lstm_network_for_stock/,jdyr1729,1547332546,"Hi,

I am building an LSTM model to predict stock prices using TensorFlow. Is it best to structure the model so that it accepts X=\[x\_0, x\_1, ... x\_{n-1}\] and predicts y=x\_n, or accepts X=\[x\_0, x\_1, ... x\_{n-1}\] and predicts y=\[x\_1, x\_2, ... x\_n\]?

Thanks!",1,1
107,2019-1-13,2019,1,13,17,afhjyu,Are we at the peak of the AI hype cycle?,https://www.reddit.com/r/deeplearning/comments/afhjyu/are_we_at_the_peak_of_the_ai_hype_cycle/,aquickquestionplzthx,1547369004,"Why is everything ""AI"" of a sudden?

&amp;#x200B;

So netflix wants to crack down on account sharing.... cool but why is this something about the power of ""AI""?

&amp;#x200B;

See article:

&amp;#x200B;

[https://sputniknews.com/science/201901101071364716-netflix-password-ai-accounts/](https://sputniknews.com/science/201901101071364716-netflix-password-ai-accounts/)

&amp;#x200B;

"" which inturn uses AI, behavioural analytics and machine learning  tomonitor and analyse password sharing activity acrossuser accounts.  The AI would then identify rule breakers, aswell asdetect the fine  line betweenfinding account sharers and harassing a customer. ""

&amp;#x200B;

The word AI is misused here... AI, behavioural analytics and machine learning... for reals?

&amp;#x200B;

all three are talking about the same thing...

&amp;#x200B;

Its like saying I went to buy a automobile, car and vehicle....

&amp;#x200B;

Why is everything all of a sudden ""AI""?

&amp;#x200B;

I buy a 4k tv and its touted as ""AI"" this and ""AI"" that...

&amp;#x200B;

Its getting ridiculous folks",4,1
108,2019-1-13,2019,1,13,17,afhmpu,Change hair color in real time. Artificial intelligence can do anything!,https://www.reddit.com/r/deeplearning/comments/afhmpu/change_hair_color_in_real_time_artificial/,cmillionaire9,1547369823,,9,1
109,2019-1-13,2019,1,13,22,afjcr3,Can someone explain what a 'sparse model' is?,https://www.reddit.com/r/deeplearning/comments/afjcr3/can_someone_explain_what_a_sparse_model_is/,Akainu18448,1547386348,"I was looking for the difference between L1 and L2 norms, and I cam across [this](https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models).

&amp;#x200B;",8,1
110,2019-1-14,2019,1,14,0,afka6v,"Has anyone any project idea on ""Smart Campus"" with the use of Deep Learning and/or Fuzzy Logic in mind?",https://www.reddit.com/r/deeplearning/comments/afka6v/has_anyone_any_project_idea_on_smart_campus_with/,Ranajoy_23,1547393213,,2,1
111,2019-1-14,2019,1,14,2,aflj45,Any idea for my University capstone project ..just ..anything ..i just want some ideas to just start thinking and to kickstart..by the way i am 3rd year undergrad and a beginner in deeplearning,https://www.reddit.com/r/deeplearning/comments/aflj45/any_idea_for_my_university_capstone_project_just/,karanbangia14,1547400729,,7,1
112,2019-1-14,2019,1,14,5,afnb4l,PyTorch implementations of RL Algorithms,https://www.reddit.com/r/deeplearning/comments/afnb4l/pytorch_implementations_of_rl_algorithms/,__data_science__,1547410543,"For anyone trying to learn or practice RL, here's a repo with lots of working implementations of RL algorithms like DQN, DQN-HER, Double DQN, Genetic algorithm, REINFORCE, DDPG, DDPG-HER, PPO etc.. that solve lots of different games

Let me know what you think and if you want to contribute!

[https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch)",2,1
113,2019-1-14,2019,1,14,7,afol64,Career advice in applied computer vision /deep learning research with a Master's degree,https://www.reddit.com/r/deeplearning/comments/afol64/career_advice_in_applied_computer_vision_deep/,notThrowawayDL,1547417429,"\[Crossposted in r/cscareerquestions ([link](https://www.reddit.com/r/cscareerquestions/comments/afocbw/career_advice_in_applied_computer_vision_with_a/)) and r/computervision ([link](https://www.reddit.com/r/computervision/comments/afogcu/career_advice_in_applied_computer_vision_deep/))\]

Hi,

&amp;#x200B;

I recently got an Applied Scientist offer in computer vision from a FAANG company. Currently I've been working as a software development engineer (mostly infrastructure, can get boring) in the same company for around 6 months. I have a master's degree in CS (no publications) and am interested in the applied science work but have a few concerns regarding future growth. Since the field is mostly populated by PhDs, would my career growth be impacted as I'll be competing with other PhDs. Also, will it be hard to find jobs in other companies later? I've been looking at the job postings and most companies require a PhD or top tier conference papers and I have none of these. In terms of long term vision, I am interested in going towards the management track(Planning to move in 6-7 years). Would the lack of a PhD/papers be a hindrance in this? My interests lie in computer vision and deep learning probably because of their heavy linear algebra dependence but not in the traditional ML side of things which depend heavily on statistics and probability.  I have to spend a lot of time understanding them. I have concerns because computer vision is a very niche field and I do not want to be in a position where I have to take a step back in the later stages of my career. I would really appreciate any advice on this. Also, it'd be great if anyone can shed light on  how much you have to study in your personal time to keep yourself updated with the ongoing research. Thanks in Advance!",3,1
114,2019-1-14,2019,1,14,12,afrj9m,"How AI, Deep Learning, Predictive Analytics and Digital Twins will Bring an Era of Personalized Care | Analytics Insight",https://www.reddit.com/r/deeplearning/comments/afrj9m/how_ai_deep_learning_predictive_analytics_and/,analyticsinsight,1547436257,,1,1
115,2019-1-14,2019,1,14,15,afsvnp,Confused about time series data and sequences,https://www.reddit.com/r/deeplearning/comments/afsvnp/confused_about_time_series_data_and_sequences/,Cyclonedx,1547446208,"Im working on a project with time series data where we need to predict a value 2 seconds into the future. The data is essentially a bunch of periodic samples that contain data from 10 sensors. The data has been formatted from a 2D shape into a shape of (x,20,y) where x is number or samples, 20 is the sequence length and y is the number of features. Im quite confused by this approach.

1) Why do we need to use a sequence of 20 per sample? Why cant it just be kept as data from 10 sensors at each time stamp (2D format)? This 3 dimensional format makes it much harder to work with the data.

2) I was told that to predict x seconds in the future you need to be able to see x seconds into the past and thats why the data is formatted into sequences of 20 (they correspond to 2 seconds of data). Why is this rule true? And why cant we just use normal 2D data without any sequences and then have the network learn patterns so it can predict 2 seconds into the future?",5,1
116,2019-1-14,2019,1,14,18,afu3fu,Deep Learning Market,https://www.reddit.com/r/deeplearning/comments/afu3fu/deep_learning_market/,nareshkumar02,1547457376,[removed],0,1
117,2019-1-14,2019,1,14,20,afv0cu,"No P2P on RTX 2080ti over PCIE, i.e. bad Multi GPU scaling on these cards",https://www.reddit.com/r/deeplearning/comments/afv0cu/no_p2p_on_rtx_2080ti_over_pcie_ie_bad_multi_gpu/,timrodel,1547465967,,0,1
118,2019-1-15,2019,1,15,13,ag4r12,"My presentations on Elements of Neural Networks &amp; Deep Learning -Parts 4,5",https://www.reddit.com/r/deeplearning/comments/ag4r12/my_presentations_on_elements_of_neural_networks/,tvganesh,1547526964,,0,1
119,2019-1-15,2019,1,15,15,ag5knm,Pinsta Cloud- GPU Instance starting at $0.16/hr,https://www.reddit.com/r/deeplearning/comments/ag5knm/pinsta_cloud_gpu_instance_starting_at_016hr/,sarakomia,1547533221," Hi all!

Sara from Pinsta cloud team .We are excited to offer you **GPU instance** starting at **$0.16/hr**.

Get Jupyter Notebooks supported by powerfull GPUs.

For more info. visit out website [Pinstacloud](https://pinstacloud.com/)

We are in beta,so limited instance are created, New user will get **3 hours extra** to instance.

Questions/feedback are welcome.",10,1
120,2019-1-15,2019,1,15,16,ag621l,New sub: AI_Music,https://www.reddit.com/r/deeplearning/comments/ag621l/new_sub_ai_music/,Stabenfeldt,1547537445,"Fellow humans,

I've created a sub where I'm gathering content I find interesting about **AI / ML** \+ **music** and audio.

[**/r/ai\_music**](https://www.reddit.com/r/ai_music)

I find this topic extremely exciting and would love to hear your thoughts about the potential of **AI / ML** in music and the soundscapes of the future.

If you happen to stumble upon interesting articles, research papers, videos, artists exploring ML technology etc, feel free to share them with the AI\_Music group!

Much love",1,1
121,2019-1-15,2019,1,15,18,ag6qbe,Masters in Deep Learning,https://www.reddit.com/r/deeplearning/comments/ag6qbe/masters_in_deep_learning/,DowntownDark,1547544234,"I am a pre-final year undergraduate student with interests in Deep Learning. I want to do my Masters in Deep Learning, but I've found that very few Universities have this option. What would you suggest as an alternative? Or are you aware of Deep Learning (or relevant) graduate programs in good Universities? 

PS: Appreciate your help :)",10,1
122,2019-1-15,2019,1,15,20,ag7j0v,Software recommendations for labelling images with ground truth,https://www.reddit.com/r/deeplearning/comments/ag7j0v/software_recommendations_for_labelling_images/,raggityrag,1547551535,I'm looking for some nice productive software to draw bounding boxes with accompanying class labels on a whole bunch of unlabelled images. The plan is to run a high accuracy OD algorithm over the images first and then use some software to manually review and if necessary modify or add to the detections. Does such software exist already? Hoping to not have to write it myself.,2,1
123,2019-1-15,2019,1,15,22,ag8a0t,"Could you guys help me to find papers on data generation, or generative model?",https://www.reddit.com/r/deeplearning/comments/ag8a0t/could_you_guys_help_me_to_find_papers_on_data/,vaseline555,1547557409,"Hello, I am very interested in machine learning and deep learning.

Recently, I want to find out how to solve the problem related to data generation (data synthesis).

i.e. generating similar, fake data based on given data. (may be possible by estimating p(x, params), etc.)

Yes, there already are good generative models (including autoregressive model like pixelRNN, WaveNet, ...), GAN, and VAE kind of things, which have gained great performance and lead the way in image and voice data generation.

&lt;Question&gt;

1. Can these models be used in generating generic data of tabular datasets?

For example, if there are 50 Blood Pressure data (continuous value) from three people,  
are there any papers of making 1000 more fake but plausible data using GAN or VAE or other models?

2. Could you recommend some of the papers that should be checked in context of data generation, or strongly related to the data generation or generative models?

I want to understand the flow by reading several papers in order from the old articles of the 20th centuries  
to the recent articles of \~2019s.

Thank you in advance!",0,1
124,2019-1-15,2019,1,15,22,ag8bd7,"Class: Applications of Deep Neural Networks - all videos online, Washington University/St. Louis",https://www.reddit.com/r/deeplearning/comments/ag8bd7/class_applications_of_deep_neural_networks_all/,jeffheaton,1547557659,,1,1
125,2019-1-16,2019,1,16,4,agbzgf,Regularization When Dataset is (for all intents and purposes) Infinitely Large,https://www.reddit.com/r/deeplearning/comments/agbzgf/regularization_when_dataset_is_for_all_intents/,ughfart,1547579297,"Hi Everyone,

I'm training on a dataset that allows me to generate new data every iteration. I take advantage of this; therefore, I don't have to worry about overfitting to the dataset. In this case, should I still add regularization to my model? The space of the data is very large, so I cannot just memorize every possible example.

Thank you!",4,1
126,2019-1-16,2019,1,16,7,agee1q,"Google's Latent Cross, How does it work?",https://www.reddit.com/r/deeplearning/comments/agee1q/googles_latent_cross_how_does_it_work/,InfiniteJets,1547592530,"I am an intermediate here and am having some trouble parsing the paper [Latent Cross: Making Use of Context in Recurrent Recommender Systems](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46488.pdf) from the YouTube recommendations team.  The paper at one point seems to describe context embeddings as vectors, and then as individual scalar weights.  

If they are vectors of a different length than the watch-features, then you cannot do simple element-wise multiplication.  If they are scalars that are simply summed together then how does the network learn anything about the relationships between the context features?

I assume I am missing something big and obvious here but I don't see what it is!  Does anyone else grok this?",0,1
127,2019-1-16,2019,1,16,15,agigi5,Reinventing hearing aids with deep learning,https://www.reddit.com/r/deeplearning/comments/agigi5/reinventing_hearing_aids_with_deep_learning/,ai-lover,1547620811,,1,1
128,2019-1-16,2019,1,16,16,agisd9,AI patent report: Batch Normalization Layers (Google),https://www.reddit.com/r/deeplearning/comments/agisd9/ai_patent_report_batch_normalization_layers_google/,PIIP_LAW,1547623800,,1,1
129,2019-1-16,2019,1,16,16,agisk7,AI patent report - 1st rejection of Google batch normalization layers patent by USPTO,https://www.reddit.com/r/deeplearning/comments/agisk7/ai_patent_report_1st_rejection_of_google_batch/,PIIP_LAW,1547623845,[removed],0,1
130,2019-1-16,2019,1,16,17,agj56d,Complete a Skype/Hangouts Interview on AI &amp; Data Science,https://www.reddit.com/r/deeplearning/comments/agj56d/complete_a_skypehangouts_interview_on_ai_data/,SimonaPop,1547627387,"Are you a data scientist? Are you part of an AI/technology startup? Do you eat data for breakfast? If so, we want to hear from you!   


Here are the details of the project:  


Each interview will last 30 to 45 minutes. To better facilitate discussion during the interview, it will be useful to check out our whitepaper and website prior to the interview.

* Ocean Website: [https://oceanprotocol.com/](https://oceanprotocol.com/)
* Business Whitepaper: [https://oceanprotocol.com/business-whitepaper.pdf](https://oceanprotocol.com/business-whitepaper.pdf)
* Marketplace Framework: [https://oceanprotocol.com/marketplace-framework.pdf](https://oceanprotocol.com/marketplace-framework.pdf)",2,1
131,2019-1-16,2019,1,16,17,agjabj,Improving Access to Sexual Health Information with AI Chatbots,https://www.reddit.com/r/deeplearning/comments/agjabj/improving_access_to_sexual_health_information/,pirate7777777,1547628913,,0,1
132,2019-1-16,2019,1,16,20,agkbb1,Writing tweets like Donald Trump,https://www.reddit.com/r/deeplearning/comments/agkbb1/writing_tweets_like_donald_trump/,yet_another_seeker,1547638752,"I've trained RNN model to write tweets like @realDonaldTrump

I use pre-trained 3-layer LSTM and by [transfer learning](https://nips2018creativity.github.io/doc/Transfer%20Learning%20for%20Style-Specific%20Text%20Generation.pdf) fine-tune this on 2k Trump's tweets.

Here are some examples of generated tweets:

* Working hard for America!
* These are the years of the most Angry and dangerous immigration reform.
* The Senate in November is a total mess . They are weak on crime and border security.
* Great to be there to watch for the great American people!
* There is no reason to spend a year without a wall. I want to protect the border and trade, as many as possible. Fix it!

You can get more examples on [https://twitter.com/realTrumpIdeas](https://twitter.com/realTrumpIdeas)

If anyone is interested I can share the source code after some cleaning/refactoring",30,1
133,2019-1-16,2019,1,16,22,agkyvz,Information extraction using deep learning,https://www.reddit.com/r/deeplearning/comments/agkyvz/information_extraction_using_deep_learning/,rushikeshmeharwade,1547644113,"Hi ,

Can someone suggest good papers or links to look for information extraction from text documents using deep learning method.?",1,1
134,2019-1-16,2019,1,16,22,agl1o1,Estimating Sigmoid Neuron Output,https://www.reddit.com/r/deeplearning/comments/agl1o1/estimating_sigmoid_neuron_output/,koenigscode,1547644692,"Hey!
I'm currently getting into DL and looking into some online resources.
However I can't figure this formula out.

Here's a screenshot of it: https://imgur.com/a/Y1MAyJY

You can find the fitting description as well as the formula here: http://neuralnetworksanddeeplearning.com/chap1.html#sigmoid_neurons 

So here are some questions I've got about it:

1) What's the resulting delta ""output""? It's the change of the output from only one neuron, not from the whole network, right?
2) What is being done is general? Why is the output getting derived?
3) What's the scope of the sigma (sum)? Does it cover only the part with the weights or the one with the bias, too?

Thanks in advance :)",1,1
135,2019-1-16,2019,1,16,23,aglnd7,Neural Learning on the Edge,https://www.reddit.com/r/deeplearning/comments/aglnd7/neural_learning_on_the_edge/,bluesorg,1547648931,,1,1
136,2019-1-17,2019,1,17,1,agn3k4,Auto-DeepLab: Fei-Fei Li &amp; Alan Yuille on Semantic Image Segmentation,https://www.reddit.com/r/deeplearning/comments/agn3k4/autodeeplab_feifei_li_alan_yuille_on_semantic/,gwen0927,1547657669,,0,1
137,2019-1-17,2019,1,17,5,agpoe3,Now AI will shoot your vlog,https://www.reddit.com/r/deeplearning/comments/agpoe3/now_ai_will_shoot_your_vlog/,cmillionaire9,1547672044,,0,1
138,2019-1-17,2019,1,17,7,agqr39,Advanced Guide to Deep Learning and Artificial Intelligence Bundle - High-Intensity 14.5 Hour Bundle Will Help You Help Computers Address Some of Humanity's Biggest Problems,https://www.reddit.com/r/deeplearning/comments/agqr39/advanced_guide_to_deep_learning_and_artificial/,NVIDIA_CEO,1547677924,,2,1
139,2019-1-17,2019,1,17,13,agu33r,[HELP Wanted] Doing multi-label learning in Keras,https://www.reddit.com/r/deeplearning/comments/agu33r/help_wanted_doing_multilabel_learning_in_keras/,immortaljoe,1547699460,"I'm working on training MIDI data to produce and generate more MIDI data. So the data consists of three different parameters:

1. Note Type (On/Off) Boolean
2. Note (Int 1-127)
3. Time (Int 0-480) 

I tried only training the LSTM on notes (Num 2), by doing a one-hot encoding and training. This was done using a softmax activation and getting the value using np.argmax(). This seems to work (work in the sense that the model was able to reduce loss on training and generate some notes), but without time and note type is not so useful by itself. But now how do I incorporate note type and time? 

I was thinking of two different ideas here:

1. Use sigmoid activation and one-hot encode each of the three and make a combined list for predictions.
2. Keep them as integers and train perhaps using a linear activaiton.

What do you guys think? ",0,1
140,2019-1-17,2019,1,17,14,agulev,Generating Data For Deep Learning Project,https://www.reddit.com/r/deeplearning/comments/agulev/generating_data_for_deep_learning_project/,joaoperfig,1547703486,"Hello there,

I was just wondering if anyone would be interested in helping me with a project.

I am a computer science student am am working on a machine learning for a class.

We are training a neural network to play snake from user-generated data.

I wanted to ask if anyone would be interested in playing a few rounds of snake and sending me the data.

We are having a hard time generating enough data to do something useful.

The project is here: [https://github.com/joaoperfig/SnakeML](https://github.com/joaoperfig/SnakeML)

Just clone, cd to source, run snake\_game.py and play!  
Afterwards just send me the recent log files on the resources folder.

(If you dont have tensorflow you can just comment out the line where it is imported)

Thank you!",1,1
141,2019-1-17,2019,1,17,18,agvx7c,The Use of Computer Vision Applications in Different Industries,https://www.reddit.com/r/deeplearning/comments/agvx7c/the_use_of_computer_vision_applications_in/,BlockDelta,1547715794,,1,1
142,2019-1-17,2019,1,17,18,agw5hj,Machine learning Projects for mobile Applications,https://www.reddit.com/r/deeplearning/comments/agw5hj/machine_learning_projects_for_mobile_applications/,mritraloi6789,1547718101,,0,1
143,2019-1-17,2019,1,17,21,agx5tp,Data Science Tools Survey 2019. Please take a part in the survey and share your experience ;),https://www.reddit.com/r/deeplearning/comments/agx5tp/data_science_tools_survey_2019_please_take_a_part/,flyelephant,1547727126,,0,1
144,2019-1-17,2019,1,17,21,agx7qr,My Python Toolkit that I Used for Two Kaggle Top 10% Leaderboard Finishes,https://www.reddit.com/r/deeplearning/comments/agx7qr/my_python_toolkit_that_i_used_for_two_kaggle_top/,jeffheaton,1547727548,,7,1
145,2019-1-17,2019,1,17,22,agxld2,DataScience Digest - Issue #16,https://www.reddit.com/r/deeplearning/comments/agxld2/datascience_digest_issue_16/,flyelephant,1547730454,,0,1
146,2019-1-18,2019,1,18,3,ah0s6d,"Using NLP to Automate Customer Support, Part Two",https://www.reddit.com/r/deeplearning/comments/ah0s6d/using_nlp_to_automate_customer_support_part_two/,pirate7777777,1547749646,,0,1
147,2019-1-18,2019,1,18,3,ah0ust,"Democratizing Deep Learning, with keras-pandas",https://www.reddit.com/r/deeplearning/comments/ah0ust/democratizing_deep_learning_with_keraspandas/,hergertarian,1547750063,"I wrote a package to make it easier to get into Deep Learning, and for pros to build deep learning models more quickly. Check it out!

[https://www.hergertarian.com/democratizing-deep-learning-with-keras-pandas](https://www.hergertarian.com/democratizing-deep-learning-with-keras-pandas)",3,1
148,2019-1-18,2019,1,18,4,ah18re,CES-ar salad 2019 - Consumer Electronic Show,https://www.reddit.com/r/deeplearning/comments/ah18re/cesar_salad_2019_consumer_electronic_show/,BlockDelta,1547752236,,0,1
149,2019-1-18,2019,1,18,4,ah1f12,Clone voice from sample,https://www.reddit.com/r/deeplearning/comments/ah1f12/clone_voice_from_sample/,Lutherush,1547753219,"Hi there. 

I am working on an project that is going well for now but i want to make it talk. For specific reasons i dont want it to use any voice but the voice of my dead wife. 
Sorry please dont judge. Can someone point me on article or tutorial how to clone voice from audio sample?",1,1
150,2019-1-18,2019,1,18,4,ah1hp7,"Amazon Object2Vec: Deep Representation Learning for general-purpose objects such as sentences, customers, products and sequences",https://www.reddit.com/r/deeplearning/comments/ah1hp7/amazon_object2vec_deep_representation_learning/,fairworldcup,1547753620,,1,1
151,2019-1-18,2019,1,18,13,ah6l93,GamePlaying.ai: The Place for Mastering Deep Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/ah6l93/gameplayingai_the_place_for_mastering_deep/,josephd,1547784639,,0,1
152,2019-1-18,2019,1,18,14,ah70mt,How padding works in convnets ?,https://www.reddit.com/r/deeplearning/comments/ah70mt/how_padding_works_in_convnets/,ashutosj,1547787814,"Let's say :
Input = 44
Kernel = 22
Stride = 1

If i calculate padding using formula I'll get 1. 
If I change the kernel to 33 then also I'll get padding as 1.

I'm just wondering then how this value is used.
If i take 1 and append zeros on both up and down then will get wrong answer in first case and right in second.

If i do padding only on top or bottom then I'll get right answer in first case but wrong in second.

Can anyone explain this ?",2,1
153,2019-1-18,2019,1,18,20,ah9ks7,Deep Learning Top News | CityFALCON,https://www.reddit.com/r/deeplearning/comments/ah9ks7/deep_learning_top_news_cityfalcon/,mr_j_b,1547811271,,0,1
154,2019-1-19,2019,1,19,0,ahbid2,Deep Learning State of the Art (2019) - MIT,https://www.reddit.com/r/deeplearning/comments/ahbid2/deep_learning_state_of_the_art_2019_mit/,keghn,1547825055,,2,1
155,2019-1-19,2019,1,19,9,ahgsdd,Fostering AI Research: Meet Unity at AAAI-19,https://www.reddit.com/r/deeplearning/comments/ahgsdd/fostering_ai_research_meet_unity_at_aaai19/,leonchenzhy,1547856895,,0,1
156,2019-1-19,2019,1,19,14,ahjd6e,Sequence Labelling in CNN?,https://www.reddit.com/r/deeplearning/comments/ahjd6e/sequence_labelling_in_cnn/,honeybooboo1989,1547876785,"Hello everyone,

This is more like asking for your opinion because my knowledge about NLP is pretty limited and I believe my problem might be related to it.

I work on a marketing project. I have three years of data. Each customer has 12 months and 36 features. I was planning to treat it as sequence labelling but would like to solve to problem with an algorithm using Convolutional Neural Network (I completed the part using LSTM, pretty straightforward). I have millions of customers each year and I plan to treat `years` as channels (say, of image). Rows are months and columns are feature and depth is 3 years (basically, we can say input is 3d array). However, the problem is that each row is a sequence and it has a corresponding response variable. For sure, using pure CNN seems out of options. Is there any other methods that I can apply on such datasets? I also really would like to hear other alternatives that you can work on? ",0,1
157,2019-1-19,2019,1,19,21,ahlv83,Training word2vec from a lexical dictionary,https://www.reddit.com/r/deeplearning/comments/ahlv83/training_word2vec_from_a_lexical_dictionary/,ThreeForElvenKings,1547902702,"Is it possible to train a word2vec model from a dictionary with words and it's meanings given?
I know word2vec does not do this, but it aims to group similar words together in the vector space. If not for word2vec is there a way to train words from dictionary ? 
Thanks ",1,1
158,2019-1-19,2019,1,19,23,ahmdfu,why do all graph convolutional networks libraries/projects treat the input as 1-dimensional?,https://www.reddit.com/r/deeplearning/comments/ahmdfu/why_do_all_graph_convolutional_networks/,dinitheo,1547907057,"so i've been reading a few papers regarding GCNs, a notable one for example: [https://arxiv.org/pdf/1609.02907.pdf](https://arxiv.org/pdf/1609.02907.pdf).

they base their architecture one the following formula 

https://i.redd.it/d1sbbfhwydb21.png

where H are the layers, thetas are the parameters to optimize, A is the adjacency matrix of the input graph, and D is the normalized degree matrix of the input graph.

&amp;#x200B;

hence, to my understanding (and it is also stated clearly in the papers), a single datapoint for those kind of problems is a single graph (represented by its corresponding A and D matrices). so it may seem like this kind of arch is good for, say, learning if a graph has a certain property or not.

However, every project/library (including those of the original papers) that i found implement a network where the \*whole\* dataset is a single matrix (CORA/KARATE for example).

[https://tkipf.github.io/graph-convolutional-networks/](https://tkipf.github.io/graph-convolutional-networks/)

[https://docs.dgl.ai/tutorials/models/1\_gnn/1\_gcn.html](https://docs.dgl.ai/tutorials/models/1_gnn/1_gcn.html)

is there a library/code to aid me in creating a network for the kind of problem that i (and the papers) stated?

or am i missing something?

&amp;#x200B;",6,1
159,2019-1-20,2019,1,20,1,ahnarn,Does specs really matter to implement DL algorithms?,https://www.reddit.com/r/deeplearning/comments/ahnarn/does_specs_really_matter_to_implement_dl/,code_crawler,1547913954,"!!-- Don't laugh at my Laptop's configuration--!!
I was fascinated by Deep Learning.
I Took on a Deep learning course recently.
My laptop got a processor of 5200U i5 , 4gb Ram ,64 bit, 2 Gb graphic card
But when I'm implementing the Basic neural network which  has 10,000 training examples, I feel like my laptop was heating a lot..!!
Is it normal?
Can I still continue doing Deep Learning..? Or should I stop it :(
If I can continue , what kind of neural networks should I be going with?
I appreciate Any kind of advice..!!",3,1
160,2019-1-20,2019,1,20,2,aho5up,Tensorflow 2.0: Keras is not (yet) a simplified interface to Tensorflow,https://www.reddit.com/r/deeplearning/comments/aho5up/tensorflow_20_keras_is_not_yet_a_simplified/,pgaleone,1547919407,,0,1
161,2019-1-20,2019,1,20,6,ahqink,What Kagglers are using for Text Classification,https://www.reddit.com/r/deeplearning/comments/ahqink/what_kagglers_are_using_for_text_classification/,mlwhiz,1547933521,,3,1
162,2019-1-20,2019,1,20,8,ahrvbo,Questions I leave for myself when drunk.,https://www.reddit.com/r/deeplearning/comments/ahrvbo/questions_i_leave_for_myself_when_drunk/,heytheremiller,1547941697,,2,1
163,2019-1-20,2019,1,20,13,ahue85,Help a student out with a machine learning project!,https://www.reddit.com/r/deeplearning/comments/ahue85/help_a_student_out_with_a_machine_learning_project/,pavanagrawal123,1547960024,"Hi r/deeplearning,

My name is Pavan and I'm a student. I'm currently working on a machine learning/deep learning project, and I would love your help in my research. If you could take 3-4 minutes of your time today to fill out my survey, I would highly appreciate it. If you have any trouble filling it in, please let me know, I will be happy to help you out.

[https://goo.gl/forms/B2jZGq1mYYSggVx72](https://goo.gl/forms/B2jZGq1mYYSggVx72)

The survey covers which tools you are using to write/productionize machine learning algos. If this is not allowed on this sub, please feel free to remove this post! 

Thanks!",1,1
164,2019-1-20,2019,1,20,18,ahw0c1,"[YOLO algo, Object Detection] Why not use the anchor boxes for the grid based search to detect objects directly?",https://www.reddit.com/r/deeplearning/comments/ahw0c1/yolo_algo_object_detection_why_not_use_the_anchor/,Akainu18448,1547976199,"The YOLO algorithm does a grid search based on the grid squares (I'm not sure if they ALWAYS are squares) and when an object is detected in one of the squares, check for the maximum 'Intersection over Union' with one of the anchor boxes and then draw the boundary around the object.

My question is, is computational inefficiency the sole reason why we don't simply run these anchor boxes instead of first running the squares around and then checking with the anchor boxes? I am just starting out with this, so I haven't implemented anything of yet. I don't know how costly that inefficiency will be.

Thanks!",9,1
165,2019-1-20,2019,1,20,20,ahwqda,"My presentations on Elements of Neural Networks &amp; Deep Learning -Parts 6,7,8",https://www.reddit.com/r/deeplearning/comments/ahwqda/my_presentations_on_elements_of_neural_networks/,tvganesh,1547984132,,0,1
166,2019-1-20,2019,1,20,23,ahy8k8,The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology,https://www.reddit.com/r/deeplearning/comments/ahy8k8/the_cornucopia_of_meaningful_leads_applying_deep/,evanatyourservice,1547995826,,2,1
167,2019-1-21,2019,1,21,2,ahztik,Pattern Recognition - what do syntactically and semantically labelled classes mean?,https://www.reddit.com/r/deeplearning/comments/ahztik/pattern_recognition_what_do_syntactically_and/,Akainu18448,1548004156,,7,1
168,2019-1-21,2019,1,21,3,ai0uwh,Training YOLOv3 : Deep Learning based Custom Object Detector,https://www.reddit.com/r/deeplearning/comments/ai0uwh/training_yolov3_deep_learning_based_custom_object/,sunitanyk,1548010030,,6,1
169,2019-1-21,2019,1,21,3,ai0vjj,Computer Vision - Improving images,https://www.reddit.com/r/deeplearning/comments/ai0vjj/computer_vision_improving_images/,ImaginaryAnon,1548010105,[removed],0,1
170,2019-1-21,2019,1,21,6,ai2eux,Deep Learning State of the Art (2019) - MIT,https://www.reddit.com/r/deeplearning/comments/ai2eux/deep_learning_state_of_the_art_2019_mit/,Whenimhere,1548018851,,0,1
171,2019-1-21,2019,1,21,15,ai7ant,Project Advice:CV x NLP,https://www.reddit.com/r/deeplearning/comments/ai7ant/project_advicecv_x_nlp/,Vaiku2718,1548051604,"I am a 3rd year student doing my graduation in computer science. I had to take up a research project at my University which I have to complete before my graduation. I have significant experience in deep learning  for computer vision and now I wish to take up a project which is NLP involved computer vision.I need your advice   and ideas for such a project


Thank you",3,1
172,2019-1-21,2019,1,21,18,ai8dwj,(x-post r/machinelearning) Deep Learning 1 Week Personal Hackathon,https://www.reddit.com/r/deeplearning/comments/ai8dwj/xpost_rmachinelearning_deep_learning_1_week/,eat_those_lemons,1548061521,,0,1
173,2019-1-21,2019,1,21,20,ai9d4i,Pest Control Services in Gurugram - Goodwill Clean Homes,https://www.reddit.com/r/deeplearning/comments/ai9d4i/pest_control_services_in_gurugram_goodwill_clean/,Goodwillcleanhome,1548071015,,0,1
174,2019-1-21,2019,1,21,21,ai9npq,Deep Cleaning Service in Gurgaon - Goodwill Clean Homes,https://www.reddit.com/r/deeplearning/comments/ai9npq/deep_cleaning_service_in_gurgaon_goodwill_clean/,Goodwillcleanhome,1548073723,,1,1
175,2019-1-22,2019,1,22,0,aib3ix,Covariates in Neural Networks,https://www.reddit.com/r/deeplearning/comments/aib3ix/covariates_in_neural_networks/,kellyoceallaigh,1548084401,"Is there any technqiue to add in a covariate(s) to a neural network to control for something? I.e. there's known information/patterns in the data that you want the network to ignore when its classifying. I hope that makes sense, thank you. ",5,1
176,2019-1-22,2019,1,22,2,aicast,Unmasking the Mystery at the Heart of AI - BlockDelta,https://www.reddit.com/r/deeplearning/comments/aicast/unmasking_the_mystery_at_the_heart_of_ai/,BlockDelta,1548091375,,0,1
177,2019-1-22,2019,1,22,2,aicce3,How Machine Learning Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/aicce3/how_machine_learning_neural_networks_work_simply/,DiscoverAI,1548091631,,1,1
178,2019-1-22,2019,1,22,3,aid4nu,Neural Network 2019 Calculations and behavior Artificial Intelligence Tu...,https://www.reddit.com/r/deeplearning/comments/aid4nu/neural_network_2019_calculations_and_behavior/,DevTechRetopall,1548095865,,0,1
179,2019-1-22,2019,1,22,14,aijpy6,Eco-Friendly Pest Control in Gurugram - Goodwill Clean Homes,https://www.reddit.com/r/deeplearning/comments/aijpy6/ecofriendly_pest_control_in_gurugram_goodwill/,Goodwillcleanhome,1548135710,,0,1
180,2019-1-22,2019,1,22,15,aijxho,Project ideas on Neural nets and Fuzzy logic,https://www.reddit.com/r/deeplearning/comments/aijxho/project_ideas_on_neural_nets_and_fuzzy_logic/,Ranajoy_23,1548137378,Can anyone please suggest project ideas in which Neural networks and Fuzzy logic can be used effectively?,1,1
181,2019-1-22,2019,1,22,15,aik5zr,Commercial Office Cleaning Services in Gurgaon,https://www.reddit.com/r/deeplearning/comments/aik5zr/commercial_office_cleaning_services_in_gurgaon/,Goodwillcleanhome,1548139347,,1,1
182,2019-1-22,2019,1,22,16,aikfhr,Best Home Cleaning Services in Gurugram | Book Online,https://www.reddit.com/r/deeplearning/comments/aikfhr/best_home_cleaning_services_in_gurugram_book/,Goodwillcleanhome,1548141684,,0,1
183,2019-1-22,2019,1,22,19,ailr8b,Best Carpet Cleaning Services in Gurgaon | Best Service Guarantee,https://www.reddit.com/r/deeplearning/comments/ailr8b/best_carpet_cleaning_services_in_gurgaon_best/,Goodwillcleanhome,1548154716,,2,1
184,2019-1-22,2019,1,22,20,ailwjb,Building a production ready sentiment analysis pipeline?,https://www.reddit.com/r/deeplearning/comments/ailwjb/building_a_production_ready_sentiment_analysis/,InfamousKratos,1548156038,"I'm trying to build a sentiment analysis pipeline for production, what should I use and What approach should I take?

Should I use CoreNLP with annotators?

Should I use gluon and use a LSTM Model with it?

Please suggest a production grade approach for this problem!",0,1
185,2019-1-22,2019,1,22,20,ailzq2,"Generative Models Tutorial with Demo/Code (GANs, VAE, Bayesian Classifier Sampling, Auto-Regressive Models )",https://www.reddit.com/r/deeplearning/comments/ailzq2/generative_models_tutorial_with_democode_gans_vae/,obsezer,1548156882,"Generative  models are interesting topic in ML. Generative models are a subset of  unsupervised learning that generate new sample/data by using given some  training data. There are different types of ways of modelling same  distribution of training data: Auto-Regressive models, Auto-Encoders and  GANs. In this tutorial, we are focusing theory of generative models,  demonstration of generative models, important papers, courses related  generative models. It will continue to be updated over time.

Generative  Models Tutorial with Demo: Bayesian Classifier Sampling, Variational  Auto Encoder (VAE), Generative Adversial Networks (GANs), Popular GANs  Architectures (DCGAN, CycleGAN, Pix2Pix, PixelDTGAN, SRGAN, StackGAN,  TPGAN, 3DGAN, Age-cGAN, DiscoGAN, AnoGAN, IcGAN, MidiNet, etc. ),  Auto-Regressive Models (PixelRNN, PixelCNN), Important Generative Model  Papers, Courses, etc.

**Tutorial Link**: [**https://github.com/omerbsezer/Generative\_Models\_Tutorial\_with\_Demo**](https://github.com/omerbsezer/Generative_Models_Tutorial_with_Demo)

There are lots of applications for generative models:

* Image Denoising,
* Image Enhancement,
* Image Inpainting,
* Super-resolution (upsampling): SRGAN,
* Generate 3D objects: 3DGAN, [Video](https://youtu.be/HO1LYJb818Q)
* Creating Art:  

   * Create Anime Characters
   * Transform images from one domain (say real scenery) to another domain (Monet paintings or Van Gogh):CycleGAN
   * Creating Emoji: DTN
* Pose Guided Person Image Generation
* Creating clothing images and styles from an image: PixelDTGAN
* Face Synthesis: TP-GAN
* Image-to-Image Translation: Pix2Pix  

   * Labels to Street Scene
   * Aerial to Map
   * Sketch to Realistic Image
* High-resolution Image Synthesis
* Text to image: StackGAN
* Text to Image Synthesis
* Learn Joint Distribution: CoGAN
* Transfering style (or patterns) from one domain (handbag) to another (shoe): DiscoGAN
* Texture Synthesis: MGAN
* Image Editing: IcGAN
* Face Aging: Age-cGAN
* Neural Photo Editor
* Medical (Anomaly Detection): AnoGAN
* Music Generation: MidiNet
* Video Generation

Extra: Reinforcement Learning Tutorial:

[**https://github.com/omerbsezer/Reinforcement\_learning\_tutorial\_with\_demo**](https://github.com/omerbsezer/Reinforcement_learning_tutorial_with_demo)",1,1
186,2019-1-22,2019,1,22,20,aim097,Spider Glass Cleaning Services in Gurugram - Goodwill Clean Homes,https://www.reddit.com/r/deeplearning/comments/aim097/spider_glass_cleaning_services_in_gurugram/,Goodwillcleanhome,1548157018,,0,1
187,2019-1-22,2019,1,22,21,aimbf4,Wooden Floor Installation Services Gurgaon - Best Service Guarantee,https://www.reddit.com/r/deeplearning/comments/aimbf4/wooden_floor_installation_services_gurgaon_best/,Goodwillcleanhome,1548159680,,0,1
188,2019-1-22,2019,1,22,21,aime9e,A Quick &amp; Easy Way Of Knowing Deep Learning In Python Especially For Beginners,https://www.reddit.com/r/deeplearning/comments/aime9e/a_quick_easy_way_of_knowing_deep_learning_in/,Kosha_Shah,1548160346,,0,1
189,2019-1-22,2019,1,22,21,aimf25,Datasets for a beginner GAN project (can not use MNIST or SVHN),https://www.reddit.com/r/deeplearning/comments/aimf25/datasets_for_a_beginner_gan_project_can_not_use/,bandalorian,1548160525,"I am doing a project and was hoping to do something related to generative adversarial networks. I have found several tutorials using the MNIST dataset ([ex1](https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f)[ex2](https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0)), but a requirement for the project is that we can't use MNIST or SVHN. So I am looking for a good alternative dataset to use for this purpose, and don't want to screw myself over by picking something that will be too hard to get decent results on, seeing how this would be my first attempt. Can anyone recommend a dataset, or a type of dataset, that would be suitable for a beginner GAN project? Thanks!",2,1
190,2019-1-22,2019,1,22,21,aiminc,GIF2Video Gives GIFs Realism,https://www.reddit.com/r/deeplearning/comments/aiminc/gif2video_gives_gifs_realism/,gwen0927,1548161350,,0,1
191,2019-1-22,2019,1,22,22,aimzmq,"Question: if embeddings transform words into vectors, how you can input those in a NN considering a text is a group of words. Do you simply put all vectors in the same text-vector a treat it as a single vector?",https://www.reddit.com/r/deeplearning/comments/aimzmq/question_if_embeddings_transform_words_into/,Smaug4,1548164907,Help much appreciated,2,1
192,2019-1-23,2019,1,23,0,ainrok,How can I estimate GPU paramter requirements for my deep learning projects?,https://www.reddit.com/r/deeplearning/comments/ainrok/how_can_i_estimate_gpu_paramter_requirements_for/,nisucuk,1548170070," 

# How can I estimate GPU paramter requirements for my deep learning projects?

&amp;#x200B;

I have to estimate  

CPU-time  
(hours) GPU-time  
(hours) CPU-count  
per job Memory  
per core  
(GByte) Scratch-temporary  
(GByte) . Can you please help",1,1
193,2019-1-23,2019,1,23,1,aiog47,Yelp: A Neural Net Killed Our App /jk,https://www.reddit.com/r/deeplearning/comments/aiog47/yelp_a_neural_net_killed_our_app_jk/,gwen0927,1548174170,,0,1
194,2019-1-23,2019,1,23,3,aiphbk,Making cool diagrams using phonetics and Tensorflow,https://www.reddit.com/r/deeplearning/comments/aiphbk/making_cool_diagrams_using_phonetics_and/,Thr3adnaught,1548180016,,0,1
195,2019-1-23,2019,1,23,5,aiqxat,Prediction Explanation in Deep Learning,https://www.reddit.com/r/deeplearning/comments/aiqxat/prediction_explanation_in_deep_learning/,RegularCombination,1548188092,I am wondering if anyone has come across any prediction explanation examples for deep learning? I am aware of [LIME](https://github.com/marcotcr/lime) and [SHAP](https://github.com/slundberg/shap) but are there any examples of using part of the DL architecture to provide an explanation along with the prediction?,1,1
196,2019-1-23,2019,1,23,5,airdwn,Home &amp;ndash; AI Job Board,https://www.reddit.com/r/deeplearning/comments/airdwn/home_ndash_ai_job_board/,TonyaIrvined85,1548190645,,0,1
197,2019-1-23,2019,1,23,7,aiscld,"Geoffrey Hinton I eventually got a Ph.D. in AI, and then I couldn't get a job in Britain.",https://www.reddit.com/r/deeplearning/comments/aiscld/geoffrey_hinton_i_eventually_got_a_phd_in_ai_and/,alexchauncy,1548195534,"&amp;#x200B;

[ ](https://i.redd.it/kfx6krfdu1c21.png)

#### Geoffrey Hinton interview by NG

[ ](https://www.coursera.org/learn/neural-networks-deep-learning/discussions/weeks/1)",21,1
198,2019-1-23,2019,1,23,8,aisuew,Artifical Intelligence Mimics How Humans Visualize Objects | Deep Learning IO,https://www.reddit.com/r/deeplearning/comments/aisuew/artifical_intelligence_mimics_how_humans/,mrcgllr,1548198327,,1,1
199,2019-1-23,2019,1,23,13,aiw5p9,Multimodal Learning in neural networks.,https://www.reddit.com/r/deeplearning/comments/aiw5p9/multimodal_learning_in_neural_networks/,lomiag,1548219569,"      Hello fellow learners. I came up with a deep learning project idea. It involves images as well as regular attributes and classifies (height, weight, name). The problem I came across is how do I combine this two different universes together in a meaningful way. I did some research and I found this idea of multimodal learning. Modalities refer to the different dimensions of perception. For humans it would be smell vision and so on. In all the research done so far the best approach I could find was building 2 NN's to do separate tasks and then combine them with another smaller NN that would adjust its weighted contribution. There are problems in this approach. 
     It fails to account for nuance between modalities and only looks at the bigger picture instead of going into detail. What I mean by that is that my non image data could work in different combinations with different aspects of the image. For example if the weight is this then the face shape does this and so on. In other words the approach above does not synthesize the different modalities but instead comes up with two conclusions and then kinda decides what to do. 
     Do you know any resources or ideas on this problem. 

Thank you.",1,1
200,2019-1-23,2019,1,23,14,aiwbfx,Wooden Floor Polishing Services in Gurugram - 100% Sparkling floors,https://www.reddit.com/r/deeplearning/comments/aiwbfx/wooden_floor_polishing_services_in_gurugram_100/,Goodwillcleanhome,1548220697,,0,1
201,2019-1-23,2019,1,23,15,aiwxd1,U-Net Introducing Symmetry in Segmentation,https://www.reddit.com/r/deeplearning/comments/aiwxd1/unet_introducing_symmetry_in_segmentation/,Hsankesara,1548225477,,0,1
202,2019-1-23,2019,1,23,19,aiyagu,Deep Learning Software Setup: CUDA 10 + Ubuntu 18.04,https://www.reddit.com/r/deeplearning/comments/aiyagu/deep_learning_software_setup_cuda_10_ubuntu_1804/,joshymeyer,1548238320,[https://hackernoon.com/deep-learning-software-setup-cuda-10-ubuntu-18-04-15548cefa30](https://hackernoon.com/deep-learning-software-setup-cuda-10-ubuntu-18-04-15548cefa30),1,1
203,2019-1-23,2019,1,23,22,aizy2x,Deep learning vs Black Man (using CelebA dataset) - How do we change the bias in ML?,https://www.reddit.com/r/deeplearning/comments/aizy2x/deep_learning_vs_black_man_using_celeba_dataset/,qu42blue,1548251896,,2,1
204,2019-1-24,2019,1,24,0,aj0xs7,Generating Cars with Generative Adversarial Nets,https://www.reddit.com/r/deeplearning/comments/aj0xs7/generating_cars_with_generative_adversarial_nets/,porygon93,1548258157,,0,1
205,2019-1-24,2019,1,24,4,aj36et,Inverting Facial Recognition Models,https://www.reddit.com/r/deeplearning/comments/aj36et/inverting_facial_recognition_models/,pirate7777777,1548270380,,0,1
206,2019-1-24,2019,1,24,4,aj3r13,DeepMind Vs StarCraft II,https://www.reddit.com/r/deeplearning/comments/aj3r13/deepmind_vs_starcraft_ii/,gwen0927,1548273460,,5,1
207,2019-1-24,2019,1,24,5,aj44g3,Rock Guitar Music Generation using LSTMs,https://www.reddit.com/r/deeplearning/comments/aj44g3/rock_guitar_music_generation_using_lstms/,immortaljoe,1548275491,"Blog: [https://nayak.io/posts/deeprock-rock-music-generation-using-lstm/](https://nayak.io/posts/deeprock-rock-music-generation-using-lstm/)

Github: [https://github.com/KarthikNayak/DeepRock](https://github.com/KarthikNayak/DeepRock)",0,1
208,2019-1-24,2019,1,24,6,aj4l71,Can I contribute to research projects part time?,https://www.reddit.com/r/deeplearning/comments/aj4l71/can_i_contribute_to_research_projects_part_time/,haywire12,1548278018,,1,1
209,2019-1-24,2019,1,24,14,aj94jl,bbox - Python library for bounding boxes,https://www.reddit.com/r/deeplearning/comments/aj94jl/bbox_python_library_for_bounding_boxes/,varunagrawal,1548307021,"https://pypi.org/project/bbox/

`bbox` is a pure python library for working with 2D/3D bounding boxes. It provides convenient abstractions for different bounding box representations (single box, multiple boxes, (xyxy) and (xywh) representations) as well as utilities such as efficient Jaccard Index (IoU), non-maximum suppression and custom aspect ratio reshaping.

Looking for feedback from the community!",1,1
210,2019-1-24,2019,1,24,18,ajarpi,Building an Animal Classifier with Tensorflow  Tensorpad  Medium,https://www.reddit.com/r/deeplearning/comments/ajarpi/building_an_animal_classifier_with_tensorflow/,whitezl0,1548322096,,0,1
211,2019-1-25,2019,1,25,1,ajdw3y,How to beat Googles AutoML - Hyperparameter Optimisation with Flair,https://www.reddit.com/r/deeplearning/comments/ajdw3y/how_to_beat_googles_automl_hyperparameter/,vitalitylife,1548346030,,2,1
212,2019-1-25,2019,1,25,2,ajekcp,Breaking Captcha: Validation Accuracy vs Test Accuracy,https://www.reddit.com/r/deeplearning/comments/ajekcp/breaking_captcha_validation_accuracy_vs_test/,duskybomb,1548349841,,0,1
213,2019-1-25,2019,1,25,4,ajfrbt,Looking for Deep Learning Freelancers for Harvard-incubated Experfy $100-$250/hr,https://www.reddit.com/r/deeplearning/comments/ajfrbt/looking_for_deep_learning_freelancers_for/,JyoC,1548356545,,0,1
214,2019-1-25,2019,1,25,4,ajfxs1,School closing/delay predictor... Possible?,https://www.reddit.com/r/deeplearning/comments/ajfxs1/school_closingdelay_predictor_possible/,pelcgbtencul,1548357539,"If I fed a deep learning module weather data from the days in the past when schools around my state closed, would the results be accurate or are there too many variables? ",6,1
215,2019-1-25,2019,1,25,4,ajg8ft,Artificial intelligence in the dining room,https://www.reddit.com/r/deeplearning/comments/ajg8ft/artificial_intelligence_in_the_dining_room/,cmillionaire9,1548359235,,4,1
216,2019-1-25,2019,1,25,5,ajgi1x,"Deep Learning: The Confluence of Big Data, Big Models, Big Compute | Deep Learning IO",https://www.reddit.com/r/deeplearning/comments/ajgi1x/deep_learning_the_confluence_of_big_data_big/,mrcgllr,1548360745,,0,1
217,2019-1-25,2019,1,25,5,ajguth,Computer Vision: An Intuitive Explanation,https://www.reddit.com/r/deeplearning/comments/ajguth/computer_vision_an_intuitive_explanation/,danimex,1548362733,,0,1
218,2019-1-25,2019,1,25,6,ajheoc,Filling Holes: Adobe Proposes Foreground-Aware Image Inpainting,https://www.reddit.com/r/deeplearning/comments/ajheoc/filling_holes_adobe_proposes_foregroundaware/,gwen0927,1548364908,,0,1
219,2019-1-25,2019,1,25,6,ajho6y,Knowledge or skill for deep learning,https://www.reddit.com/r/deeplearning/comments/ajho6y/knowledge_or_skill_for_deep_learning/,foretix,1548366396,What fundamental knowledge or skill I need to have/should have in order to develop software with deep learning feature?,1,1
220,2019-1-25,2019,1,25,14,ajlu1z,Best Window Film Glass Services in Gurgaon - Goodwill Clean Homes,https://www.reddit.com/r/deeplearning/comments/ajlu1z/best_window_film_glass_services_in_gurgaon/,Goodwillcleanhome,1548393871,,0,1
221,2019-1-25,2019,1,25,15,ajmdk3,Move In &amp; Move Out cleaning services in Gurugram,https://www.reddit.com/r/deeplearning/comments/ajmdk3/move_in_move_out_cleaning_services_in_gurugram/,Goodwillcleanhome,1548398323,,0,1
222,2019-1-25,2019,1,25,16,ajmqfz,After Party Cleaning in Gurgaon - Goodwill Clean Homes,https://www.reddit.com/r/deeplearning/comments/ajmqfz/after_party_cleaning_in_gurgaon_goodwill_clean/,Goodwillcleanhome,1548401660,,0,1
223,2019-1-25,2019,1,25,22,ajot40,Bird Box and adversarial examples,https://www.reddit.com/r/deeplearning/comments/ajot40/bird_box_and_adversarial_examples/,ssegvic,1548421376,Were the authors of the Bird Box movie acquainted with the existence of adversarial examples in machine learning?,5,1
224,2019-1-25,2019,1,25,23,ajph88,Why is Business Intelligence Important? | Deep Learning IO,https://www.reddit.com/r/deeplearning/comments/ajph88/why_is_business_intelligence_important_deep/,mrcgllr,1548426132,,0,1
225,2019-1-26,2019,1,26,0,ajpuxr,[D] The best of GAN papers in the year 2018 (part 2),https://www.reddit.com/r/deeplearning/comments/ajpuxr/d_the_best_of_gan_papers_in_the_year_2018_part_2/,dtransposed,1548428606," 

Hi! As a follow-up to my [older post](https://dtransposed.github.io/blog/Best-of-GANs-2018-(Part-1-out-of-2).html) I would like to share a second part of the summary concerning my favourite research papers in 2018 with the focus on the deep learning models - Generative Adversarial Networks.

I am certain there is a substantial number of passionates who would enjoy this short read.

Have fun!

[https://dtransposed.github.io/blog/Best-of-GANs-2018-(Part-2-out-of-2).html](https://dtransposed.github.io/blog/Best-of-GANs-2018-(Part-2-out-of-2).html)",9,1
226,2019-1-26,2019,1,26,1,ajqwso,Classify people on r/amitheasshole using deep learning,https://www.reddit.com/r/deeplearning/comments/ajqwso/classify_people_on_ramitheasshole_using_deep/,NotSoGreatLeader,1548434874,,4,1
227,2019-1-26,2019,1,26,3,ajrxat,"Difference between Data Science, Data Analytics and Machine Learning",https://www.reddit.com/r/deeplearning/comments/ajrxat/difference_between_data_science_data_analytics/,mrcgllr,1548440552,,1,1
228,2019-1-26,2019,1,26,4,ajssaa,"interested in doing some DL collaborative projects to boost my coding skills + GitHub/open-source game, anyone interested?",https://www.reddit.com/r/deeplearning/comments/ajssaa/interested_in_doing_some_dl_collaborative/,S_T47,1548445486,"Hi,

I recently learnt PyTorch and did some personal projects on it, however, I haven't been involved in any collaborative coding projects and thus wanted to get involved in one. I do not have any friends who code/ are interested in DL so I was wondering anyone out there who may want to join up to do something together? I hope to improve my coding by working with someone hence, why the reach out!

what ever the project, just think of it as doing it for fun +  to improve our skills.",30,1
229,2019-1-26,2019,1,26,5,ajt3ou,"[LECTURES] Awesome list of Deep Learning, Machine Learning, and Reinforcement Learning lectures !!!",https://www.reddit.com/r/deeplearning/comments/ajt3ou/lectures_awesome_list_of_deep_learning_machine/,kmario23,1548447295,"Hello everyone,

   In an attempt to put together a list of *good* machine learning, deep learning, and RL lectures that are freely available online, I have created a repo [deep-learning-drizzle](https://github.com/kmario23/deep-learning-drizzle), which I plan to keep it as fresh as possible. So, I'd like to present this list to anyone who might be interested in learning from these great researchers &amp; lecturers. At the same time, I'd also kindly request you to send a PR if you find a course that is missing in this repo but could be added to this list. The only pre-requisite is that it *should* have lectures freely available online (e.g. in YouTube) and optionally a course webpage would definitely be nice as well.

Finally, I request you to share it with anyone and everyone who might be interested in this. Feel free to star, fork, and send a PR! Happy learning and have a nice weekend :)",0,1
230,2019-1-26,2019,1,26,22,ak0q3g,[Discussion] Forming an online study group for AI applications and ideas,https://www.reddit.com/r/deeplearning/comments/ak0q3g/discussion_forming_an_online_study_group_for_ai/,rexlow0823,1548508339,"Hi Redditors, I am thinking of forming an online study group where we will be discussing aspiring AI applications and ideas. 

&amp;#x200B;

The idea is to gather like-minded developers and whoever interested in building AI-related applications in one place so that it would be easier for all of us to discuss ideas and share possible solutions to accelerate our tasks, which I currently have a problem finding such community.

&amp;#x200B;

The group will most likely be on Slack as different channels can be created for specific topics. However, suggestions are welcome :)

&amp;#x200B;

Let me know what you guys think ;)",14,1
231,2019-1-26,2019,1,26,22,ak0zgw,Python or R: What Should You Use For Your Machine Learning Project?,https://www.reddit.com/r/deeplearning/comments/ak0zgw/python_or_r_what_should_you_use_for_your_machine/,mrcgllr,1548510619,,0,1
232,2019-1-27,2019,1,27,2,ak32mo,Free credits for cloud GPU instances for deep learning,https://www.reddit.com/r/deeplearning/comments/ak32mo/free_credits_for_cloud_gpu_instances_for_deep/,whitezl0,1548524780,"Hi, I am offering free credits for you to access 1080Ti GPU instances for deep learning purposes.

I am a co-founder of Tensorpad; where we are creating a service for AI startups to train neural networks. We have paid traffic, but some servers are idle. Hence, we are offering some credits for free, so that students, startups, and others can benefit from ML technologies and help us by using our product and providing honest feedback for us to improve.

You can Sign Up at https://dashboard.tensorpad.com/signup and redeem the code ""REDDIT200"" in the Billing tab.

Hope this explains our story and motivation for providing free credits.

Here is additional information:

* The instances have 16GB RAM, 4 CPUs cores and one 1080Ti GPU. You can run multiple instances in parallel

* You get access to the JupyterLab environment

* We have pre-installed Tensorflow, Keras, and other ML frameworks

* You can access the terminal through the JupyterLab

* By default, persistent storage is enabled

* Here are the available software versions https://docs.tensorpad.com/jobs_env/ For extra free trial hours, use promo code: reddit200

And for questions, please contact me at [ilie@tensorpad.com](mailto:ilie@tensorpad.com). I am looking forward to seeing you on our platform! Sincerely, Ilie Diacov Co-founder and UX researcher at Tensorpad
",2,1
233,2019-1-27,2019,1,27,2,ak34aw,MIT 6.S091: Introduction to Deep Reinforcement Learning (Deep RL),https://www.reddit.com/r/deeplearning/comments/ak34aw/mit_6s091_introduction_to_deep_reinforcement/,keghn,1548525065,,0,1
234,2019-1-27,2019,1,27,11,ak83vt,"fast.ai's 2019 ""Pratical Deep Learning Tutorial"" is out!",https://www.reddit.com/r/deeplearning/comments/ak83vt/fastais_2019_pratical_deep_learning_tutorial_is/,dwlsalmeida,1548557398,,20,1
235,2019-1-27,2019,1,27,18,akal00,Convert HTML Table into JSON data,https://www.reddit.com/r/deeplearning/comments/akal00/convert_html_table_into_json_data/,avejack,1548580374,,0,1
236,2019-1-27,2019,1,27,20,akb9ib,A radical new neural network design could overcome big challenges in AI,https://www.reddit.com/r/deeplearning/comments/akb9ib/a_radical_new_neural_network_design_could/,iamstark07,1548588218,,4,1
237,2019-1-27,2019,1,27,21,akbl1s,Forbes Crypto Billionaire calls Bill Gates a Liar and a Crappy Person,https://www.reddit.com/r/deeplearning/comments/akbl1s/forbes_crypto_billionaire_calls_bill_gates_a_liar/,Immulate,1548591748,,0,1
238,2019-1-27,2019,1,27,22,akc42p,Dense layer as,https://www.reddit.com/r/deeplearning/comments/akc42p/dense_layer_as/,suraty,1548596635," 

Hello,

In a  dataset, the data are the average of vehicles speed in the points  (cells) of a map. I am trying to build a prediction model.

While  the inputs are the average of vehicles speed of all points in recent 40  min and the outputs are the next 10 min of all points.

If  there were 320 points on the map, the input shape = (320,20) and the  output shape =(320,5). The averages of vehicles speed are collected each  2 min in all points.

There are several such samples (n samples, x=(n,320,20), y=(n,320,5)).

If we visualize the average of the vehicles of a day in a plot, then a .gif file as below indicates the input and the output as *x* and *y*.

https://i.redd.it/2upenjlfwyc21.gif

Then we build a CNN model with 1 channel to considering the spatial-temporal features.

The codes of the final architecture of my model:

    model = models.Sequential() 
    model.add(Conv2D(256,(3, 3),
              activation='relu',
              input_shape=(320,20,1), 
              padding='same')) 
    model.add(MaxPooling2D((2, 2)))  
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) 
    model.add(MaxPooling2D((2, 2)))  
    model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) 
    model.add(MaxPooling2D((2,2)))  
    model.add(Flatten()) 
    model.add(Dense(1600))  
    model.summary()

The input\_shape=(320,20,1). I reshaped the output to 1600 (320\*5) which the final Dense layer expects.

While the output is 2d (320 cells and 5 times). Does it make the model bad learning?

Thank you

&amp;#x200B;

&amp;#x200B;",3,1
239,2019-1-28,2019,1,28,14,akk769,RTX 2080Ti Vs GTX 1080Ti: Mixed Precision training comparisions,https://www.reddit.com/r/deeplearning/comments/akk769/rtx_2080ti_vs_gtx_1080ti_mixed_precision_training/,init__27,1548652371,[https://hackernoon.com/rtx-2080ti-vs-gtx-1080ti-fastai-mixed-precision-training-comparisons-on-cifar-100-761d8f615d7f](https://hackernoon.com/rtx-2080ti-vs-gtx-1080ti-fastai-mixed-precision-training-comparisons-on-cifar-100-761d8f615d7f),2,1
240,2019-1-28,2019,1,28,18,aklqpc,Training neural word embeddings,https://www.reddit.com/r/deeplearning/comments/aklqpc/training_neural_word_embeddings/,boredhumen101,1548666386,"So I am new to Deep Learning and NLP. I have read several blog posts on medium, towardsdatascience and papers where they talk about pre-training the word embeddings in an unsupervised fashion and then use them in supervised DNN. But recently I read a blog post
(Link 1) which suggested that training the word embeddings while training the neural network gives better results. 

So my question is which one should I follow?

Links that I referred to:

1. https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment

2. https://towardsdatascience.com/deep-learning-for-specific-information-extraction-from-unstructured-texts-12c5b9dceada

Some YouTube videos:

1. Deep Learning for NLP without Magic Part 1, 2 and 3",2,1
241,2019-1-29,2019,1,29,5,akroo8,Doubts in deep learning based image colorization.,https://www.reddit.com/r/deeplearning/comments/akroo8/doubts_in_deep_learning_based_image_colorization/,sanchit2843,1548707548,"I have been trying to make image colorization project(grayscale to color) using deep learning. I have tried it using cgan, cycle gan and simple regression loss but nothing is working for me. Can anyone help me out for the same, I will share further details and code if required. I am using pytorch. Thanks in advance. ",9,1
242,2019-1-29,2019,1,29,6,aksaik,Approach to take when building a model for small images?,https://www.reddit.com/r/deeplearning/comments/aksaik/approach_to_take_when_building_a_model_for_small/,halfzinc,1548710795,"I have a dataset of small 32x32 images and have been trying to build a network to do binary classification on them. But I am new to neural networks and dont know how to approach this problem.

Some people suggested to just build the popular models like resNet and vgg and see which ones work the best.

So far all i did was increase the network depth but the accuracy of the model has not improved.

How do people approach problems like this? Do they start out by optimizing the hyperparameters? Or do they try out all kinds of popular models?

Any help would be appreciated.",0,1
243,2019-1-29,2019,1,29,7,aksor8,Implementing tensor-based library in C++,https://www.reddit.com/r/deeplearning/comments/aksor8/implementing_tensorbased_library_in_c/,sad-coder,1548712898,"Today I had a pretty bad interview for a DL position where I was asked to code up a C++ class to make an n-dimensional tensor and perform some basic operations.

My recent inexperience with C++ didn't help at all and I was wondering if there are some guides/tutorials that would guide me through making a basic tensor library in C++ myself.",0,1
244,2019-1-29,2019,1,29,7,aksvte,DeepControl.ai: Front Page of Deep Reinforcement Learning and AGI,https://www.reddit.com/r/deeplearning/comments/aksvte/deepcontrolai_front_page_of_deep_reinforcement/,deepcontrolai,1548713973,,1,1
245,2019-1-29,2019,1,29,10,akuqhh,Unity announced the upcoming launch of the Obstacle Tower Challenge to test the limits of intelligence systems.,https://www.reddit.com/r/deeplearning/comments/akuqhh/unity_announced_the_upcoming_launch_of_the/,leonchenzhy,1548725231,,0,1
246,2019-1-29,2019,1,29,11,akvebw,CVPR 2019 reviews are out folks!,https://www.reddit.com/r/deeplearning/comments/akvebw/cvpr_2019_reviews_are_out_folks/,cdrfrk,1548729532,,5,1
247,2019-1-29,2019,1,29,17,aky0oc,Practical Deep Learning for Coders 2019,https://www.reddit.com/r/deeplearning/comments/aky0oc/practical_deep_learning_for_coders_2019/,worldwide__master,1548750264," 

Fast.ai  just launched their 2019 edition of Practical Deep Learning for Coders.  With 100% new materials, new design and applications that have never  been covered by an introductory deep learning course before. Key  applications covered are: Computer vision, NLP, Tabular data (e.g. sales  prediction) and collaborative filtering. There are seven lessons in  total (2hrs long) with assignments. So if you want to get started with  deep learning today then here's your big chance and definitely check  this course out!

Article: [https://www.fast.ai/2019/01/24/course-v3/](https://www.fast.ai/2019/01/24/course-v3/)

Course: [https://course.fast.ai/](https://course.fast.ai/)",20,1
248,2019-1-29,2019,1,29,18,akya64,Introduction to character level CNN in text classification with PyTorch Implementation,https://www.reddit.com/r/deeplearning/comments/akya64/introduction_to_character_level_cnn_in_text/,ahmedbesbes,1548753066,,0,1
249,2019-1-29,2019,1,29,18,akyagy,Introduction to character level CNN in text classification with PyTorch Implementation + Code + models,https://www.reddit.com/r/deeplearning/comments/akyagy/introduction_to_character_level_cnn_in_text/,ahmedbesbes,1548753141,,0,1
250,2019-1-29,2019,1,29,18,akydbl,Character Based CNN for text classification in PyTorch // Detailed code + Visualization + Video Demo,https://www.reddit.com/r/deeplearning/comments/akydbl/character_based_cnn_for_text_classification_in/,ahmedbesbes,1548753949,,0,1
251,2019-1-29,2019,1,29,18,akydfy,Character Based CNN for text classification in PyTorch // Detailed code + Visualization + Video Demo,https://www.reddit.com/r/deeplearning/comments/akydfy/character_based_cnn_for_text_classification_in/,ahmedbesbes,1548753983,,0,1
252,2019-1-29,2019,1,29,18,akyeoq,Car Washing Cleaning Services in Gurgaon - Goodwill Clean Homes,https://www.reddit.com/r/deeplearning/comments/akyeoq/car_washing_cleaning_services_in_gurgaon_goodwill/,Goodwillcleanhome,1548754332,,0,1
253,2019-1-29,2019,1,29,20,akz11w,Any game engine that makes it easy to export data to machine learning models and gives option to import the model into it ?,https://www.reddit.com/r/deeplearning/comments/akz11w/any_game_engine_that_makes_it_easy_to_export_data/,manjush3v,1548760428,"I have 3 years experience in machine learning and recently I came across games which were improved using AI, especially making computer more challenging towards user. I did build very basic games, but game engines make it easy to build good graphic games in less time. Game developers who have experience in machine learning - what is your path to build huge games with awesome graphics along with intelligent surrounding characters ? ",1,1
254,2019-1-29,2019,1,29,22,al08y3,Deep Learning based Text Recognition (OCR) using Tesseract and OpenCV,https://www.reddit.com/r/deeplearning/comments/al08y3/deep_learning_based_text_recognition_ocr_using/,keghn,1548770383,,0,1
255,2019-1-29,2019,1,29,23,al0hf2,Deep Learning  Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/al0hf2/deep_learning_learn_recurrent_neural_networks_in/,jhncna,1548771935,,0,1
256,2019-1-30,2019,1,30,1,al1mci,Github Tutorial Link,https://www.reddit.com/r/deeplearning/comments/al1mci/github_tutorial_link/,param87,1548778836,,0,1
257,2019-1-30,2019,1,30,1,al1q1g,PyTorch tutorial on google colaboratory,https://www.reddit.com/r/deeplearning/comments/al1q1g/pytorch_tutorial_on_google_colaboratory/,param87,1548779437,"Hello, I have created the hands-on PyTorch tutorial on google colaboratory without any local setup requirement. Anyone want to learn PyTorch framework can hop on the following link. Requirements to run the tutorials are just Google Chrome and Google Drive. [Github tutorial link](https://github.com/param087/Pytorch-tutorial-on-Google-colab)",3,1
258,2019-1-30,2019,1,30,2,al21bt,where can i use domain adaptation?,https://www.reddit.com/r/deeplearning/comments/al21bt/where_can_i_use_domain_adaptation/,mohammadkh766,1548781229,I want to choose my topic for my master degree. I like text mining I want to ask you do you know what's trending in domain adaptation and transfer learning for text mining?,0,1
259,2019-1-30,2019,1,30,2,al2cpu,AAAI-19 Announces Best Papers  SyncedReview  Medium,https://www.reddit.com/r/deeplearning/comments/al2cpu/aaai19_announces_best_papers_syncedreview_medium/,gwen0927,1548783026,,0,1
260,2019-1-30,2019,1,30,2,al2lx6,Is there any keras implementation of copynet paper,https://www.reddit.com/r/deeplearning/comments/al2lx6/is_there_any_keras_implementation_of_copynet_paper/,kaustubhdevkar,1548784458,[CopyNet Paper](https://arxiv.org/abs/1603.06393),0,1
261,2019-1-30,2019,1,30,3,al2uew,Deep learning project structure,https://www.reddit.com/r/deeplearning/comments/al2uew/deep_learning_project_structure/,simetin,1548785712,"Hi !

I'm a beginner in the world of ML / DL and I was wondering how people structure their projects. I want to train multiple models in parallel on multiple GPUs in Keras. Do you run every training in the same file or one file per model ? Do you keep a config file of the model to keep track of old models ?

Any tips on structuring a DL project are welcome !",0,1
262,2019-1-30,2019,1,30,4,al3g5h,Black Swans Journal Club,https://www.reddit.com/r/deeplearning/comments/al3g5h/black_swans_journal_club/,jdyr1729,1548788950,"Hey

We're launching a journal club!

Each week we'll discuss a recent deep learning paper. People can ask questions about bits they find difficult, criticize methods, share insights, further resources, etc.

If you'd like to join, head to: [https://blackswans.io/post/138/](https://blackswans.io/post/138/).

Thanks!",0,1
263,2019-1-30,2019,1,30,4,al3ixp,Research Ideas for CNN,https://www.reddit.com/r/deeplearning/comments/al3ixp/research_ideas_for_cnn/,deep_into_ml,1548789382," 

Looking  for ideas to work in CNN: Training/New architectural modifications in  CNN.  Also into Gradient Optimization algorithms. Suggestions, anything,   Something that someone wanted to try?

NEED IDEAS :(",0,1
264,2019-1-30,2019,1,30,5,al4hs9,Image scraping service,https://www.reddit.com/r/deeplearning/comments/al4hs9/image_scraping_service/,gtruck,1548794665,"Hello, I wanted to dive into deep learning but I've stumbled across stumbling block of not being able to get images for training sets so I wrote this service https://www.imgslurp.com/ where you provide keywords and it grabs all images from google image search and then downloads images with labels into user's computer.

Feel free to check it out and leave feedback, users with unique emails and ip's every 24h can claim free scrape credits with which you can download roughly \~10k images or so.

&amp;#x200B;

Feedback is welcome.",4,1
265,2019-1-30,2019,1,30,6,al4sfx,On Building an Instagram Street Art Dataset and Detection Model,https://www.reddit.com/r/deeplearning/comments/al4sfx/on_building_an_instagram_street_art_dataset_and/,pirate7777777,1548796251,,0,1
266,2019-1-30,2019,1,30,7,al5jik,Looking For Senior Design Project Ideas,https://www.reddit.com/r/deeplearning/comments/al5jik/looking_for_senior_design_project_ideas/,djman90,1548800414,"I am a current senior and have been assigned a project using computer vision and deep learning techniques. We are looking for a 'proof of concept' type project that won't be too difficult to finish within the next two semester.   


Our advisor is fairly versed with using deep learning methods on image classification, segmentation, and localization problems so we would like to stay in that subfield. Ideally, our project would be able to have a commercial application or solve some problem.",0,1
267,2019-1-30,2019,1,30,11,al7rhq,Where Are all the Tensorflow tutorials.,https://www.reddit.com/r/deeplearning/comments/al7rhq/where_are_all_the_tensorflow_tutorials/,lomiag,1548814192,Exactly! There are so many Keras tutorials on deep learning. But I can't find adequate Tensorflow tutorial.,3,1
268,2019-1-30,2019,1,30,19,alb8nt,Jennifer Lawrence with Steve Buscemi face,https://www.reddit.com/r/deeplearning/comments/alb8nt/jennifer_lawrence_with_steve_buscemi_face/,cmillionaire9,1548842402,,8,1
269,2019-1-30,2019,1,30,19,albbo6,Understanding and Applying Self-Attention for NLP,https://www.reddit.com/r/deeplearning/comments/albbo6/understanding_and_applying_selfattention_for_nlp/,DemiourgosD,1548843185,,1,1
270,2019-1-30,2019,1,30,19,albfp8,Video recognition,https://www.reddit.com/r/deeplearning/comments/albfp8/video_recognition/,damjanv1,1548844319,Hi community. Im just getting Started in Deep Learning. I want to pursue a DL project in parallel to doing the fast.ai coursework (my MOOC of choice). My goal is to train a model to recognise things within  video and then annotate or edit that video. Ie look for action scenes in a film for example . ,1,1
271,2019-1-30,2019,1,30,21,alc98q,Deep Learning Training In India,https://www.reddit.com/r/deeplearning/comments/alc98q/deep_learning_training_in_india/,SunilAhujaa,1548851715,Learn deep learning using python online at Analytixlabs.,0,1
272,2019-1-31,2019,1,31,1,aledr8,Tsinghua University Proves Quantum Supremacy on GANs,https://www.reddit.com/r/deeplearning/comments/aledr8/tsinghua_university_proves_quantum_supremacy_on/,gwen0927,1548865717,,0,1
273,2019-1-31,2019,1,31,3,alfqit,FastAI: All lesson notebooks now available to use with free GPU(s) as Kaggle kernels,https://www.reddit.com/r/deeplearning/comments/alfqit/fastai_all_lesson_notebooks_now_available_to_use/,init__27,1548872995,[removed],0,1
274,2019-1-31,2019,1,31,6,alhzxt,Papers on working with small datasets,https://www.reddit.com/r/deeplearning/comments/alhzxt/papers_on_working_with_small_datasets/,nkalavak,1548885222,What are some of the interesting papers/resources that talk about working with small datasets? The more prevalent transfer learning and data augmentation methods are ideas we are familiar with now. But are there other interesting techniques for working with smaller datasets? ,8,1
275,2019-1-31,2019,1,31,7,ali96d,"new podcast specializing in Artificial Intelligence , machine learning ,deep learning , computer vision",https://www.reddit.com/r/deeplearning/comments/ali96d/new_podcast_specializing_in_artificial/,Doctor_who1,1548886641,"Hi, I am making a new podcast specializing in Artificial Intelligence , machine learning ,deep learning , computer vision ,....., but unfortunately I have no idea what name to choose for the podcast. Please let me know your proposed names.",8,1
276,2019-1-31,2019,1,31,9,aljmnr,How Deep Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/aljmnr/how_deep_neural_networks_work_simply_explained/,DiscoverAI,1548894532,,0,1
277,2019-1-31,2019,1,31,11,alkqaz,Stegnalysis using CNNs [need help],https://www.reddit.com/r/deeplearning/comments/alkqaz/stegnalysis_using_cnns_need_help/,rajiv7,1548901787,"Hi

I had a floating thought in head. I'm not from deep learning or steganography domain so please feel free to correct my flying ideas.

Stegnalysis using deep learning :
Use a CNN to determine whether given random image is carrying any hidden information or not. To achieve this, train a CNN using datasets of different steganography methods. We currently want to accommodate 2-3 algorithms only. So we wish to train CNN first
 using a primitive steganography method like LSB(using a dataset created using LSB algorithm only). Then we train it using some different algorithm like Hugo (2nd dataset purely using algorithm Hugo). Then another different algorithm like s or j uniward.

At the end of this hardship, what we wish to achieve is : suppose we give a random image that may have been steganographed using the 3 algorithms we trainied(exclusively). Then the CNN should be able to tell if image is stego or not. And if stego, should try &amp; extract the hidden payload.

I explicitly state that I am a noob in both domains. And would work in the direction of suggestions provided as answers to this question. 

Notes : 
Only images are hidden in cover images.
(Purely image dataset)

",0,1
278,2019-1-31,2019,1,31,15,almv28,Washroom Deep Cleaning Services | Litmaid,https://www.reddit.com/r/deeplearning/comments/almv28/washroom_deep_cleaning_services_litmaid/,PreetiShah1122,1548917634,"Hygiene your washroom , lift away dirt and kill off bacteria . Litmaid provide [washroom deep cleaning services](https://www.litmaid.com/services/pune/cleaning-services-in-pune/bathroom-cleaning-services-pune/) in affordable cost. ",4,1
279,2019-1-31,2019,1,31,18,alnpc6,PyTorch or Keras/TensorFlow for tool in Jupyter lab,https://www.reddit.com/r/deeplearning/comments/alnpc6/pytorch_or_kerastensorflow_for_tool_in_jupyter_lab/,baidodo,1548925715,"Hi all

I am about to develop a Deep Learning tool/framework in Python that ultimately will be run inside Jupyter lab. I need to choose a DL framework to be the backend of this tool.

&amp;#x200B;

I am familiar with both PyTorch and Keras/TensorFlow but I am still not sure which one should I use for this project.

&amp;#x200B;

My first idea is to use PyTorch as it works well with Python and it seems it would make a perfect combination with Jupyter environment. I also think it will be easier for me to develop some features with PyTorch.

&amp;#x200B;

It seems the way PyTorch is executed makes it a better choice for Jupyter? However soon TF 2.0 will brings more eager execution, so I am also not sure about this.

&amp;#x200B;

One thing that makes me doubt is that it is very easy to design/save/load networks with Keras API while with PyTorch it is sometimes not straightforward. For instance for CNNs you always need to manage the input size manually (or with extra functions) while with Keras you don't have to bother. Same for loading/saving models, it seems a bit easier with Keras.

&amp;#x200B;

That is why I still think that Keras API might be easier for users to design their own networks.

With so many frameworks out there, and fast changes in these frameworks, it is not easy to choose.

What would be your advice?

Thanks.",7,1
280,2019-1-31,2019,1,31,19,alo56p,US Roadshow: NTR @ the 2019 API Inspection and Mechanical Integrity Summit,https://www.reddit.com/r/deeplearning/comments/alo56p/us_roadshow_ntr_the_2019_api_inspection_and/,Batareika_1,1548930172,,0,1
281,2019-1-31,2019,1,31,19,aloaj9,[P] Keras: multi-label classification with ImageDataGenerator,https://www.reddit.com/r/deeplearning/comments/aloaj9/p_keras_multilabel_classification_with/,rragundez,1548931594,,0,1
282,2019-1-31,2019,1,31,23,alpw8e,So I created my first DL model and I have questions.,https://www.reddit.com/r/deeplearning/comments/alpw8e/so_i_created_my_first_dl_model_and_i_have/,Akainu18448,1548944463,"**1) How do you decide based on a data set what layers and hyperparameters to use?** 

The model that I created, I followed the steps that another guy was doing just so I could get my hands dirty and see something myself. He had a huge data set, but just by looking at the data set, I have no idea how to select the hyperparameters! Moreover, since the guy made a batch gradient descent model, it took a lot of time to train (I have a CPU sadly), which means I can't play around with all permutations of Conv2D, MaxPooling2D and other functions. Is there a clear cut way to at least have an idea just from the data set?

&amp;#x200B;

**2) How are competitions (say, on Kaggle) worth anything if everyone is basically just importing everything from DL libraries?**

Whether one guy wins or the other guy does seems to be only a matter of what functions he used. Conv2D + MaxPool + MaxPool + Conv2D could be the runner up while Conv2D+MaxPool+Conv2D+maxPool could be the winner. I'm not talking competition with the retards who'd use very low level functions here, but at the top, I can't see how the winner will have to rely solely on his knowledge to be more accurate - it's more of a chance, unlike programming.

&amp;#x200B;

**3) I'm still a beginner, but if all the work has already been done for me in the DL Libraries, what makes this difficult?** 

Seems like all that a company needs to be good at AI, is to get someone who can devote his time playing around with permutations of one-liner codes to finally score good on the metric and voila! What skills do I need to possess here that would give me an edge when sitting for the hiring process?

&amp;#x200B;

*----------------Note, I'm still a beginner here. My views are primarily based on the assignments I have done on Coursera, followed by this one model I made using the libraries. I suddenly seem to be losing that excitement, but I'm sure I'm missing something big here. Please go easy on me.----------------*",4,1
0,2019-2-1,2019,2,1,10,alwxms,Recommendations,https://www.reddit.com/r/deeplearning/comments/alwxms/recommendations/,dee_pandas,1548986149,"Hey guys! 
I've been planning to formulate a project on a Siamese network to model image text joint embeddings. I have looked up a few papers that do so using bi directional losses and deep CCA. I was wondering whether there could be something new that could be done in this line of work. ",1,1
1,2019-2-1,2019,2,1,15,alz69d,[Pytorch+OpenCV] My implementation of QuickDraw - an online game developed by Google (Source code: https://github.com/vietnguyen91/QuickDraw),https://www.reddit.com/r/deeplearning/comments/alz69d/pytorchopencv_my_implementation_of_quickdraw_an/,1991viet,1549002067,,5,1
2,2019-2-1,2019,2,1,18,am07rl,Sequence generation.help.,https://www.reddit.com/r/deeplearning/comments/am07rl/sequence_generationhelp/,naskamag,1549011870,Guys can you suggest me some of the papers other than seq2seq for sequence generation?  Thank you,0,1
3,2019-2-1,2019,2,1,18,am0akt,Robotics Revolution: Man vs Machine - Case Study on Japan,https://www.reddit.com/r/deeplearning/comments/am0akt/robotics_revolution_man_vs_machine_case_study_on/,BlockDelta,1549012653,,0,1
4,2019-2-1,2019,2,1,22,am274e,Object Localisation using Simple CNN?,https://www.reddit.com/r/deeplearning/comments/am274e/object_localisation_using_simple_cnn/,hardhat528491,1549029155,"Hi. I am new to deep learning and I had a question. Suppose I have a task to predict only bounding boxes for an object in an image(no classification required) and each image has only one object. 

I am thinking of using a simple CNN with the image as input and the predicted bounding box as the output. The error will be a L2 distance between the ground truth bounding box and predicted bounding box. 

Any idea if this method will work? Or will I need more sophisticated algorithms like YOLO etc?",0,1
5,2019-2-1,2019,2,1,23,am2cn4,Help with single object localization,https://www.reddit.com/r/deeplearning/comments/am2cn4/help_with_single_object_localization/,dhanno65,1549030155,I have to train a model which can give me a bounding box around the object in the image. The image always contains only one object. What architecture do you suggest. I have a dataset of 30k 640480 images. And also is it bad idea to rescale the images to square as to required by typical pretrained model? ,0,1
6,2019-2-2,2019,2,2,0,am2un5,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/am2un5/how_neural_networks_work_simply_explained/,DiscoverAI,1549033297,,0,1
7,2019-2-2,2019,2,2,2,am4b3w,Well-explained Tensorflow Boilerplate using Estimator API,https://www.reddit.com/r/deeplearning/comments/am4b3w/wellexplained_tensorflow_boilerplate_using/,strender,1549041367,,0,1
8,2019-2-2,2019,2,2,6,am6vjj,Deep Learning Journal Club,https://www.reddit.com/r/deeplearning/comments/am6vjj/deep_learning_journal_club/,jdyr1729,1549055622,"I am looking for people who would be interested in reading and discussing recent deep learning papers, one a week.

Being part of a journal club is a fast, efficient, way to stay up to date with current research, learn about exciting new applications, and have your technical questions answered.

Meeting new data-scientists is also a great way to learn different approaches to problems and get new ideas for projects!

I'd like to host the club on my site, [blackswans.io](https://blackswans.io), so we can easily write in LaTeX, share images and videos, etc. I'd also like to have Skype calls (with a few members of the club) every so often, to get to know each other better.

Feel free to make other suggestions!

Jack",16,1
9,2019-2-2,2019,2,2,9,am8hp9,Using AI to Find Where Clowns End and Juggalos Begin,https://www.reddit.com/r/deeplearning/comments/am8hp9/using_ai_to_find_where_clowns_end_and_juggalos/,InspectahM,1549065648,,0,1
10,2019-2-2,2019,2,2,21,amdlsu,Basics of the Transformer Model (Google) explained with examples,https://www.reddit.com/r/deeplearning/comments/amdlsu/basics_of_the_transformer_model_google_explained/,DemiourgosD,1549110068,,0,1
11,2019-2-3,2019,2,3,3,amgv4m,"A journey through neural networks - Self Driving, simulations and education",https://www.reddit.com/r/deeplearning/comments/amgv4m/a_journey_through_neural_networks_self_driving/,DevTechRetopall,1549132396,,1,1
12,2019-2-3,2019,2,3,10,amkt3o,I need help for creating my first DL model,https://www.reddit.com/r/deeplearning/comments/amkt3o/i_need_help_for_creating_my_first_dl_model/,HeiWiper,1549157070,"I'm working on my Software engineering License project and the topic that I applied for consists of making an android application powered by AI, my promoter asked me to search for deep learning and forged deep learning ( by forged she means concrete algorithms ) I started reading a book of Ian Goodfellow which goes through fendamentals then machine learning then deep learning, as of now I am in the machine learning part and things are getting complicated...
What I really need it to create my deep learning model for my application without going through everything that concerns deep learning, I will have to understand the method that my project will include because that's what I am going to be asked about when presenting my application, and next year I am planning to apply for AI master degree so I will be going through more details but as of now the goal is to make use of it while understanding how it works.
Is there a way I can create my DL model without going through everything ?",9,1
13,2019-2-3,2019,2,3,12,amly7j,Time Series Prediction,https://www.reddit.com/r/deeplearning/comments/amly7j/time_series_prediction/,saravanakumar17,1549165529,"Hi, I've been tweaking around time series prediction using LSTM, almost all the algorithms which i saw only predicted the prices up to the last date given in the dataset, if anyone can explain how to predict the future stock prices with code it will make my day. Thanks in advance.",0,1
14,2019-2-3,2019,2,3,12,amm168,Creating a Neural Network from Scratch,https://www.reddit.com/r/deeplearning/comments/amm168/creating_a_neural_network_from_scratch/,AIlearner678,1549166134,,0,1
15,2019-2-3,2019,2,3,15,amn1uz,Feeding data to the Capsule Network.,https://www.reddit.com/r/deeplearning/comments/amn1uz/feeding_data_to_the_capsule_network/,Raman070,1549174410,"I am trying to feed a dataset other than MNIST to the **Capsule network**. I am taking reference from [here](https://www.kaggle.com/kmader/capsulenet-on-mnist).

My data is present in a CSV file. The data contains **247 feature descriptors and 1 label.** I have not been able to feed it to the network. 

This is very important to me. Any sort of help would be highly appreciated. 

*Processing img 5ysphjy2lae21...*

&amp;#x200B;",0,1
16,2019-2-3,2019,2,3,16,amngr0,Help regarding bounding box prediction,https://www.reddit.com/r/deeplearning/comments/amngr0/help_regarding_bounding_box_prediction/,messy_saurabh,1549178436,"I have a dataset that contains the bounding box coordinates for a given image. Each image has only one bounding box. I need to predict the bounding box coordinates for test images. I have tried opencv but I am not able to predict it correctly. It contains some classes which are not found in some standard weights dataset like MS COCO. The training set does not contains classes, but only coordinates of bounding boxes. What should be my approach towards this problem, as I am not getting the intuition as to where to start?",5,1
17,2019-2-4,2019,2,4,0,amqetq,"Confused About Matrix Shaping - ValueError: shapes (2,1,8) and (1,8) not aligned: 8 (dim 2) != 1 (dim 0)",https://www.reddit.com/r/deeplearning/comments/amqetq/confused_about_matrix_shaping_valueerror_shapes/,Upup_naway,1549207131,"I don't understand where my matrices fail to align and how to correct for this problem.

I know it's related to the shape of my data being feed into the system, not the neural network itself.

I keep getting the following errors:

Traceback (most recent call last): File ""NN.py"", line 51, in &lt;module&gt; nn.feedforward()

File ""NN.py"", line 26, in feedforward self.layer1 = sigmoid(np.dot(self.input, self.weights1)) ValueError: shapes (2,1,8) and (1,8) not aligned: 8 (dim 2) != 1 (dim 0)

I have tried reshaping he weights to conform to the dimensions of the data inputs (firstdata, seconddata, and thirddata) but it appears that I'm confused about something.

import numpy as np
import numpy as np
csv = np.genfromtxt ('NNTestSmall.csv', delimiter="","")
first = csv[:,0]
second = csv[:,1]
third = csv[:,2]

firstdata = ([3,4,3,3,3,3,4,4])
seconddata = ([1,3,3,3,3,2,2,3])
thirddata = ([4,2,3,3,2,4,1,3])
def sigmoid(x):
    return 1.0/(1+ np.exp(-x))

def sigmoid_derivative(x):
    return x * (1.0 - x)

class NeuralNetwork:
    def __init__(self, x, y):
        self.input = x
        self.weights1 = np.random.rand(self.input.shape[1],8) 
        self.weights2 = np.random.rand(8,1)                 
        self.y = y
        self.output = np.zeros(self.y.shape)

    def feedforward(self):
        self.layer1 = sigmoid(np.dot(self.input, self.weights1))
        self.output = sigmoid(np.dot(self.layer1, self.weights2))

    def backprop(self):
        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1
        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))
        d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))

        # update the weights with the derivative (slope) of the loss function
        self.weights1 += d_weights1
        self.weights2 += d_weights2


if __name__ == ""__main__"":
    X = np.array([[firstdata],[seconddata]])
    print (X.shape)
    print (X)
    y = np.array([[thirddata]])
    print (y.shape)
    print (y)


    nn = NeuralNetwork(X,y)

    for i in range(15000):
        nn.feedforward()
        nn.backprop()

    print(nn.output)",1,1
18,2019-2-4,2019,2,4,0,amqlhg,Unsupervised Deep Embedding for Clustering Analysis,https://www.reddit.com/r/deeplearning/comments/amqlhg/unsupervised_deep_embedding_for_clustering/,hoda_fakharzade,1549208378,"I was reading [this](https://arxiv.org/pdf/1511.06335) paper (DEC) and in the paper uses stacked denoising autoencoder in the initialization stage, now my question is can we use VAE instead? bcz they also provide us with Representation ??? do you think it will improve the clustering procedure?",1,1
19,2019-2-4,2019,2,4,4,amt2so,Some good deep learning research labs across the globe,https://www.reddit.com/r/deeplearning/comments/amt2so/some_good_deep_learning_research_labs_across_the/,aniket_agarwal,1549222704,"Hi, just wanted to know some of the good deep learning research labs(with special focus on Computer Vision) across the globe, who also do accept Undergrads as summer research interns.

Thanks in advance :)",6,1
20,2019-2-4,2019,2,4,4,amtavr,Source/author of an image,https://www.reddit.com/r/deeplearning/comments/amtavr/sourceauthor_of_an_image/,JulienDLearn,1549223951,"Hi,

&amp;#x200B;

Just wondering if someone could help me find the source/author of this image? 

&amp;#x200B;

Thanks!

&amp;#x200B;

[Evolution of image segmentation \(2013-2018\)](https://i.redd.it/2gf79pnmsee21.png)

&amp;#x200B;",2,1
21,2019-2-4,2019,2,4,15,amz54d,[Q] Data augmentation,https://www.reddit.com/r/deeplearning/comments/amz54d/q_data_augmentation/,pk12_,1549263402,"I want to use data augmentation to alleviate the lack of data for my hobby project

But I am confused, does it make sense to randomly add augmented (say rotation, translation, and scaling) and non-augmented images within the same batch? So mix both types of images.

I am using 2D CNNs and have the input size is fixed, so eventually all augmented images are reshaped into same size as the non-augmented images. ",4,1
22,2019-2-4,2019,2,4,17,amzqsb,"TensorFlow and deep learning, without a PhD",https://www.reddit.com/r/deeplearning/comments/amzqsb/tensorflow_and_deep_learning_without_a_phd/,worldwide__master,1549269080,,6,1
23,2019-2-4,2019,2,4,20,an0plr,Interview with Twice kaggle GrandMaster and Data Scientist at h2oai : (SRK) Sudalai Rajkumar,https://www.reddit.com/r/deeplearning/comments/an0plr/interview_with_twice_kaggle_grandmaster_and_data/,init__27,1549278944,[https://hackernoon.com/interview-with-twice-kaggle-grandmaster-and-data-scientist-at-h20-ai-sudalai-rajkumar-cd952ef0c522](https://hackernoon.com/interview-with-twice-kaggle-grandmaster-and-data-scientist-at-h20-ai-sudalai-rajkumar-cd952ef0c522),2,1
24,2019-2-4,2019,2,4,21,an19yb,Free Webinar on the Next Generation Data Lake designed for exploratory Data Science,https://www.reddit.com/r/deeplearning/comments/an19yb/free_webinar_on_the_next_generation_data_lake/,supercake53,1549283883,"On March 5th, Lentiq will host a free webinar on how to build the next generation data lake, and how data science, analytics, and data analysis projects can easily be implemented in a multi-cloud environment

[https://zoom.us/webinar/register/5315482367983/WN\_Mn6aiN06SQypP7DmT\_fz7g](https://zoom.us/webinar/register/5315482367983/WN_Mn6aiN06SQypP7DmT_fz7g)",0,1
25,2019-2-4,2019,2,4,22,an1gvn,Real Time Object Detection in Android,https://www.reddit.com/r/deeplearning/comments/an1gvn/real_time_object_detection_in_android/,introverted--weirdo,1549285439,"I am supposed to complete a project due Feb 11 on Real Time Object detection in Android. I am a beginner and I don't know how to start it. I chose this topic cause it sounded like fun. It already got approved , so, there's no way i can change it. 

I could use Tensor Flow  but i have to learn it from Scratch. So is there anyone who can help me with the steps?

Any help would be really appreciated.

&amp;#x200B;",1,1
26,2019-2-5,2019,2,5,0,an2ivv,Dealing with Error in NN input,https://www.reddit.com/r/deeplearning/comments/an2ivv/dealing_with_error_in_nn_input/,kellyoceallaigh,1549292935,"When you are building a neural network in which the input values are known to have error is there a way to incorporate this into the network? I.e one value of the input may have a known small error and so it's value is a good estimate; but another may have a larger standard error and so you are less confident in its true value. 

Googling around this question is not easy because it's mostly Error Messages or error in the output that pops up so if someone here knows offhand that would be great thanks!",0,1
27,2019-2-5,2019,2,5,0,an2t54,Learn how Neural Networks Work - implement them from Scratch.,https://www.reddit.com/r/deeplearning/comments/an2t54/learn_how_neural_networks_work_implement_them/,ktessera,1549294733,,0,1
28,2019-2-5,2019,2,5,1,an3eay,Job Offers,https://www.reddit.com/r/deeplearning/comments/an3eay/job_offers/,enes497,1549298171,"How to get a job offer for deep learning?
What do you recommend?",9,1
29,2019-2-5,2019,2,5,1,an3m0k,MIT Self-Driving Cars: State of the Art (2019),https://www.reddit.com/r/deeplearning/comments/an3m0k/mit_selfdriving_cars_state_of_the_art_2019/,keghn,1549299400,,0,1
30,2019-2-5,2019,2,5,2,an3wxs,Can I splitup a model's basic maths tasks and perform it parallely on various machines in a network using a common cloud,https://www.reddit.com/r/deeplearning/comments/an3wxs/can_i_splitup_a_models_basic_maths_tasks_and/,omkarjc,1549301105,,0,1
31,2019-2-5,2019,2,5,2,an494j,MIT Deep Learning Basics: Introduction and Overview with TensorFlow,https://www.reddit.com/r/deeplearning/comments/an494j/mit_deep_learning_basics_introduction_and/,dayanruben,1549302958,,0,1
32,2019-2-5,2019,2,5,5,an5oej,[suggestions] Is it a good idea to make an image localization model from scratch or to use a model like YOLOv3?,https://www.reddit.com/r/deeplearning/comments/an5oej/suggestions_is_it_a_good_idea_to_make_an_image/,Akainu18448,1549310824,"I have a competition coming up and I have to perform an image localization task on the given test and training set. I have studies the YOLO models but I haven't actually been able to implement anything yet - not saying it's not doable.

I just want a general suggestion from the folks out here more experienced than I am, what would your strategy be? Would you implement a model yourself? Is there a good library you can suggest I use? 

Anything that can guide me along the right direction here will be appreciated way more than I can express in words, I really want to do good especially as the noob I'm the underdog here.",1,1
33,2019-2-5,2019,2,5,13,ananjc,Want to skip the intro features in WebSeries,https://www.reddit.com/r/deeplearning/comments/ananjc/want_to_skip_the_intro_features_in_webseries/,8222Tamil,1549342006,"Hey guys, i want to skip the introduction and post credit scenes in a web series using deep [learning.is](https://learning.is) it possible to do that  using tensorflow..if it., need to know the workflow or need know how  to do it.",16,1
34,2019-2-5,2019,2,5,16,anbvp8,"convert video data (.avi, .mp4 etc.) to TensorFlow tfrecords",https://www.reddit.com/r/deeplearning/comments/anbvp8/convert_video_data_avi_mp4_etc_to_tensorflow/,whiletrue2,1549352284,,2,1
35,2019-2-5,2019,2,5,20,and2am,Finding out the detection time of a object from video,https://www.reddit.com/r/deeplearning/comments/and2am/finding_out_the_detection_time_of_a_object_from/,8222Tamil,1549364706,I'm working with tensorflow object detection in videos .Now i want to find the exact time where detection starts and where it ends in the full  video.what i have to do?,0,1
36,2019-2-5,2019,2,5,20,andbgf,[D] What Deep Learning papers do you think are very important to the field but also very hard to understand?,https://www.reddit.com/r/deeplearning/comments/andbgf/d_what_deep_learning_papers_do_you_think_are_very/,freechoice,1549367155,,7,1
37,2019-2-5,2019,2,5,21,andoxy,Screen capture pixel,https://www.reddit.com/r/deeplearning/comments/andoxy/screen_capture_pixel/,utrmliha,1549370298,"Hello guys.
Please, help us, help our community of deep learning in Brazil.
I researched recently anything of how to capture screen in real-time for identify bars(Candles stick) for an database, I need a type of method of capture screen utilizing pixels color to detect this candles. Is there something similar?",2,1
38,2019-2-5,2019,2,5,23,aneefp,Deep Learning: Advanced NLP and RNNs 95% off,https://www.reddit.com/r/deeplearning/comments/aneefp/deep_learning_advanced_nlp_and_rnns_95_off/,IsserlinaImma,1549375543,,1,1
39,2019-2-6,2019,2,6,0,anf7pq,Building a Toy Self-Driving Car: Part One,https://www.reddit.com/r/deeplearning/comments/anf7pq/building_a_toy_selfdriving_car_part_one/,pirate7777777,1549380824,,1,1
40,2019-2-6,2019,2,6,6,aniyww,"I understand your pain, but this is indeed Deep Learning xD",https://www.reddit.com/r/deeplearning/comments/aniyww/i_understand_your_pain_but_this_is_indeed_deep/,Akainu18448,1549402241,[https://imgur.com/gallery/qqGE2sX](https://imgur.com/gallery/qqGE2sX),0,1
41,2019-2-6,2019,2,6,13,anmvg1,Beowulf cluster deep learning.,https://www.reddit.com/r/deeplearning/comments/anmvg1/beowulf_cluster_deep_learning/,Kainkelly2887,1549426518,"Has anyone here looked into building a cheap embedded CPU/Motherboard combo Beowulf cluster? Not Pi's I was thinking along the lines of something like this.
https://m.newegg.com/products/N82E16813157729

Note I am not looking to beat out a top of the line graphics card, just wanted to run a few AI's for datasecurity I am working on. None of them in theory should be that intensive....
",20,1
42,2019-2-6,2019,2,6,15,annwop,"Interview with Kaggle (RSNA Pneumonia Detection Challenge winner) Expert, Radiologist: Dr. Alexandre Cadrin-Chenevert",https://www.reddit.com/r/deeplearning/comments/annwop/interview_with_kaggle_rsna_pneumonia_detection/,init__27,1549433993,[https://hackernoon.com/interview-with-radiologist-fast-ai-fellow-and-kaggle-expert-dr-alexandre-cadrin-chenevert-94145d446da8](https://hackernoon.com/interview-with-radiologist-fast-ai-fellow-and-kaggle-expert-dr-alexandre-cadrin-chenevert-94145d446da8),0,1
43,2019-2-6,2019,2,6,16,ano7mj,AI Daily Podcasts : Episode 1 - Math Blues in Machine Learning,https://www.reddit.com/r/deeplearning/comments/ano7mj/ai_daily_podcasts_episode_1_math_blues_in_machine/,prithvi45,1549436725,,0,1
44,2019-2-6,2019,2,6,16,anoce2,AI Daily Podcasts : Episode 1 - Math Blues in Machine Learning,https://www.reddit.com/r/deeplearning/comments/anoce2/ai_daily_podcasts_episode_1_math_blues_in_machine/,prithvi45,1549437938,,0,1
45,2019-2-6,2019,2,6,17,anoqoh,Deep Learning  Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/anoqoh/deep_learning_learn_recurrent_neural_networks_in/,nwyr19,1549441804,,0,1
46,2019-2-6,2019,2,6,17,anorgo,Deep500: new Deep Learning Benchmark for HPC,https://www.reddit.com/r/deeplearning/comments/anorgo/deep500_new_deep_learning_benchmark_for_hpc/,mllosab,1549442020,"Link to the [HPCWire article](https://www.hpcwire.com/2019/02/05/deep500-eth-researchers-introduce-new-deep-learning-benchmark-for-hpc). It's just a shame that it does not mention already existing modular, customizable and reproducible benchmarking infrastructures and initiatives such as [MLModelScope](https://mlmodelscope.org/) and [ACM REQUEST](https://portalparts.acm.org/3230000/3229762/fm/frontmatter.pdf) which seem to have very similar long-term goals. It would be interesting to compare all these frameworks.

&amp;#x200B;",0,1
47,2019-2-6,2019,2,6,18,anp14f,Is the Deep Learning Era Coming to an End? MIT Argues. Read to Believe,https://www.reddit.com/r/deeplearning/comments/anp14f/is_the_deep_learning_era_coming_to_an_end_mit/,analyticsinsight,1549444894,,4,1
48,2019-2-6,2019,2,6,21,anqciv,"Awesome papers, new tools, AI news and research reviews [with codes!] on Computer Vision News. Links for free reading!",https://www.reddit.com/r/deeplearning/comments/anqciv/awesome_papers_new_tools_ai_news_and_research/,Gletta,1549457094,"Hot off the Press! Here are the links to the February 2019 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: many articles about Artificial Intelligence and Autonomous Driving. Free subscription on page 40.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019February/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-february-pdf/)

Enjoy!

https://i.redd.it/8agvmvyw1ye21.jpg",0,1
49,2019-2-7,2019,2,7,0,anrsgb,Please help me understand deep learning,https://www.reddit.com/r/deeplearning/comments/anrsgb/please_help_me_understand_deep_learning/,knownsuq,1549466913,"Let's assume we want to predict house prices, we have 4 inputs, area, bedrooms, distance to city and age.

In the first hidden layer with 6 neurons and the rectifier function, each of these inputs get ""weighted"" and ""summed"" so some neurons pick up let's say just area &amp; bedrooms (weight to zero the other 2), etc. Now we get 6 prices, as each neuron ""weights"" the inputs via back propagation as close as possible to the actual price right?

&amp;#x200B;

In a third hidden layer, now we ""weight"" these 6 prices? like0.8\*price1 + 0.2\*price2 + 0\*price3...and that's how we get to the closest price? Just by taking percents of several possible prices and sum them? I understand that we try all kind of percents, ""weights"" but it doesn't sounds like it should work to predict the actual price.

&amp;#x200B;

Also I don't really understand how some neurons pick just let's say distance to city and age, how does it ""decides"" which ones to ""weight"" to zero, why dont all neurons pick the same 2 inputs and weight down to zero the other. 

&amp;#x200B;

Thanks",7,1
50,2019-2-7,2019,2,7,2,ant6yn,Has DL been used to enhance the ability to model analog music equipment?,https://www.reddit.com/r/deeplearning/comments/ant6yn/has_dl_been_used_to_enhance_the_ability_to_model/,jsj2008,1549474597,"I remember looking into modeling amplifiers when I bought my tube amp 10 years ago. They were really good, but definitely quite noticeably different sounding.  


Was wondering if anyone has released a product (or even a program) that has used DL to get very close to modeling say, a classic marshall or fender tube amplifier, in a convincing way? I imagine protools has already begun thinking about this, if they haven't already done it.  


Would be really cool to see, but musicians can also be a little hard to convince I imagine. There would be a very strong placebo effect...but I bet double blind trials could rule much of this out. Curious what your guys thoughts are, just randomly thought about this and thought I'd post!",0,1
51,2019-2-7,2019,2,7,4,anuo59,The first TVM and Deep Learning Compiler Conference kicked off in Seattle,https://www.reddit.com/r/deeplearning/comments/anuo59/the_first_tvm_and_deep_learning_compiler/,Yuqing7,1549482501,,0,1
52,2019-2-7,2019,2,7,14,ao093c,"Latest Report on GPU for Deep Learning Market 2019: Innovation, Growth Predictions, Tech Developments, Share, Application and 2025 Forecast | Top Companies are Nvidia, AMD, Intel",https://www.reddit.com/r/deeplearning/comments/ao093c/latest_report_on_gpu_for_deep_learning_market/,research_wire,1549516070,,0,1
53,2019-2-7,2019,2,7,16,ao14my,What sort of projects in computer vision would be good for a university senior design project?,https://www.reddit.com/r/deeplearning/comments/ao14my/what_sort_of_projects_in_computer_vision_would_be/,fjalskdf,1549522935,"At my university we have a year long school $ponsored senior design project for the computer science and engineering students in teams of 4-5. We are able to propose our own ideas and have a lot of creative freedom (upon project approval by the department chair).

Recently, computer vision has really piqued my interest and I've been thinking about potential senior design projects in this area. I don't know if my current ideas are at all doable for someone whose ML knowledge ends at Andrew Ng's coursera.

My first idea was a scantron-like grading application, but for handwritten answers. So given a handwritten key, grade student exams/quizzes against said key using CNN and RNN neural nets.

My second idea came from a recent trip I took through Guatemala. In some places, there was littered trash everywhere along the sides of the roads and I thought, ""Hmm this would be a good thing to map out the density of."" From this I thought of doing a SLAM application that detects trash and maps out the said density of the trash in affected areas.

My most recent idea was to build on top of comma ai's openpilot. I was thinking it would be really cool to work on a self parking functionality on top of comma's level 2 self driving system.

These ideas sound ambitious (to me at least), but I have a full year, and a clever team of 4-5 people. What do you guys think? Should I keep pursuing these ideas? Any thoughts/feedback would be greatly appreciated! :)
",5,1
54,2019-2-7,2019,2,7,22,ao3ibo,Do you know the music like this about car learning and deep learning and artificial intelligence?,https://www.reddit.com/r/deeplearning/comments/ao3ibo/do_you_know_the_music_like_this_about_car/,Doctor_who1,1549544604,"Do you know the music like this about car learning and deep learning and artificial intelligence?

 [https://www.youtube.com/watch?v=XTNl5WxklgE](https://www.youtube.com/watch?v=XTNl5WxklgE) ",0,1
55,2019-2-7,2019,2,7,22,ao3l05,Best AI news in January?,https://www.reddit.com/r/deeplearning/comments/ao3l05/best_ai_news_in_january/,antmoreau,1549545124,"I wrote an article to help anyone catch up with the latest Artificial Intelligence news.

[https://blog.sicara.com/01-2019-best-ai-new-articles-this-month-8e2113fbd17b](https://blog.sicara.com/01-2019-best-ai-new-articles-this-month-8e2113fbd17b)

Anything I missed? I would really like some feedback on this as it is quite hard to keep up with the field even when you're actively monitoring it.",2,1
56,2019-2-7,2019,2,7,23,ao4hr6,Recommending Similar Fashion Images with Deep Learning,https://www.reddit.com/r/deeplearning/comments/ao4hr6/recommending_similar_fashion_images_with_deep/,pirate7777777,1549551148,,0,1
57,2019-2-8,2019,2,8,1,ao5awh,Help understanding this dice loss function,https://www.reddit.com/r/deeplearning/comments/ao5awh/help_understanding_this_dice_loss_function/,alexwasnotfree,1549555899,"Im doing image segmentation, and have  achieved good results using dice as metric and 1-dice as a loss  function. Recently I found this loss function that extracts the original  border and then uses that to compare with the prediction.

    def dice_coef_border(y_true, y_pred):     
        border = get_border_mask((21, 21), y_true)      
        border = K.flatten(border)     
        y_true_f = K.flatten(y_true)     
        y_pred_f = K.flatten(y_pred)     
        y_true_f = K.tf.gather(y_true_f, K.tf.where(border &gt; 0.5))     
        y_pred_f = K.tf.gather(y_pred_f, K.tf.where(border &gt; 0.5))      
        return dice_coef(y_true_f, y_pred_f)  
    
    def get_border_mask(pool_size, y_true):     
        negative = 1 - y_true     
        positive = y_true     
        positive = K.pool2d(positive, pool_size=pool_size, padding=""same"")     
        negative = K.pool2d(negative, pool_size=pool_size, padding=""same"")     
        border = positive * negative     
        return border 

I don't quite understand how  it uses max pooling to get the border, and why it uses such a big  stride. As I understand it this would give some results close to the  border incorrectly labeled as border, and this border it returns would  have a reduced dimentionality.

&amp;#x200B;

Shouldn't it be imposible to compare the result of the pooling with the predicted mask as the pooling will reduce the original dimensions.

&amp;#x200B;

Also  on the dice\_coef\_border I don't understand why it only targets elements  with over 0.5 value? is this just a random threshold.

the complete file can be found at [https://github.com/killthekitten/kaggle-carvana-2017/blob/master/losses.py](https://github.com/killthekitten/kaggle-carvana-2017/blob/master/losses.py)",0,1
58,2019-2-8,2019,2,8,5,ao8352,[help] What should I fabricate the last layer of a CNN for object localization?,https://www.reddit.com/r/deeplearning/comments/ao8352/help_what_should_i_fabricate_the_last_layer_of_a/,Akainu18448,1549570862,"I have a CNN where I'll be feeding it an input image, a CSV file containing the coordinates for the bounding box in each image in the hopes that over the course of training the model, it will finally be able to detect objects in a test set of images that I feed it later.  
I have run into an issue, though. I can't figure out what should be the structure of the last dense layer for this problem. I get that the dense layer should give me 4 outputs, one each for the 4 bounding box coordinates, but: 

* What activation to use? 
* Which loss function to use? 
* Is my procedure to just feed my model the input image and the 4 coordinate values the correct way to be proceeding?",0,1
59,2019-2-8,2019,2,8,5,ao8441,[Help] How should I go about fabricating a model for object localization?,https://www.reddit.com/r/deeplearning/comments/ao8441/help_how_should_i_go_about_fabricating_a_model/,Akainu18448,1549571007," I have a CNN where I'll be feeding it an input image, a CSV file containing the coordinates for the bounding box in each image in the hopes that over the course of training the model, it will finally be able to detect objects in a test set of images that I feed it later.I have run into an issue, though. I can't figure out what should be the structure of the last dense layer for this problem. I get that the dense layer should give me 4 outputs, one each for the 4 bounding box coordinates, but:

* What activation to use?
* Which loss function to use?
* Is my procedure to just feed my model the input image and the 4 coordinate values the correct way to be proceeding?",3,1
60,2019-2-8,2019,2,8,5,ao8hqm,Physics control tasks with Deep Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/ao8hqm/physics_control_tasks_with_deep_reinforcement/,dkobran,1549572980,,0,1
61,2019-2-8,2019,2,8,10,aoba7r,Generative Adversarial Network producing same numbers for training set,https://www.reddit.com/r/deeplearning/comments/aoba7r/generative_adversarial_network_producing_same/,jmarsha5,1549589460,Hey ya'll when a GAN is generating the exact same fake samples what could be the issue?  We have tried changing the learning rate but we get the same results.  We also tried different layers. Any ideas on how to go about figuring out what needs to be changed?,2,1
62,2019-2-8,2019,2,8,11,aobvvi,"i add 2 layers in model , but it is err, why ?",https://www.reddit.com/r/deeplearning/comments/aobvvi/i_add_2_layers_in_model_but_it_is_err_why/,asda43asdf23423,1549593492,"`filters_4 = 32`

`filters_5 = 32`

`model.add(Conv2D(filters4, kernelsize, usebias=False)) model.add(BatchNormalization()) model.add(Activation(""relu"")) model.add(Conv2D(filters4, kernelsize, usebias=False))`  
`model.add(BatchNormalization())`  
`model.add(Activation(""relu""))`  
`model.add(MaxPool2D(poolsize = poolsize))`  
`model.add(Dropout(dropout_conv))`

`model.add(Conv2D(filters5, kernelsize, usebias=False)) model.add(BatchNormalization()) model.add(Activation(""relu"")) model.add(Conv2D(filters5, kernelsize, usebias=False))`  
`model.add(BatchNormalization())`  
`model.add(Activation(""relu""))`  
`model.add(MaxPool2D(poolsize = poolsize))`  
`model.add(Dropout(dropout_conv))`

ValueError: Negative dimension size caused by subtracting 3 from 2 for 'conv2d\_9/convolution' (op: 'Conv2D') with input shapes: \[?,2,2,2\], \[3,3,2,2\].

&amp;#x200B;

this is kaggle kernels: 

[https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-10min-0-925-lb/notebook](https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-10min-0-925-lb/notebook)

&amp;#x200B;

&amp;#x200B;",3,1
63,2019-2-8,2019,2,8,15,aodp8p,[Project] tsalib: a library for tensor shape annotation and transformations (no more shape woes!),https://www.reddit.com/r/deeplearning/comments/aodp8p/project_tsalib_a_library_for_tensor_shape/,ekshaks,1549606716,,1,1
64,2019-2-8,2019,2,8,17,aoegi9,Whenever i try to launch jupyter notebook using deeplearning VM on Google cloud platform ...i keep getting this error,https://www.reddit.com/r/deeplearning/comments/aoegi9/whenever_i_try_to_launch_jupyter_notebook_using/,karanbangia14,1549613601,"I changed the firewall setting on google cloud platform but did not have any effect

![img](b102rsg7zaf21)",2,1
65,2019-2-8,2019,2,8,20,aofr6w,Exciting opportunities to join True AI,https://www.reddit.com/r/deeplearning/comments/aofr6w/exciting_opportunities_to_join_true_ai/,Juliadoncheva,1549626475,"Hello everyone,

Excited about working in a rapidly growing tech startup? Want to be part of the next wave of AI-driven innovation in conversational interfaces?

If you answered yes to the above, you could be just what were looking for.

We currently have 2 exciting opportunities to join us:

Full stack software engineer:  
[https://trueai.workable.com/j/3A4D8FAC29](https://trueai.workable.com/j/3A4D8FAC29?fbclid=IwAR3mLsPQg-OgQ7P3wBhNykwC-XcGaQw0fpCXSoIEix23zRsqmK4weZJqvAQ)

Backend software engineer:  
[https://trueai.workable.com/j/0513556D41](https://trueai.workable.com/j/0513556D41?fbclid=IwAR1WTPa440xLrMKcdxoQanS9lG3ysBRm-jm4hXFB19N6VMLBfHSBzllo3BM)

To apply, please email apply@trueai.io. In your email:

Include your CV / link to your professional profile  
Let us know your ideal start date  
Confirm that you would not require us to arrange a visa and on what grounds (i.e. EU citizenship, student visa)  
Include a link to your portfolio / relevant examples of past work  
Let us know why you are interested in the job

Looking forward to hearing from you! :)

Best regards,  
Julia",4,1
66,2019-2-8,2019,2,8,23,aoh2z1,Journals to publish Research Papers,https://www.reddit.com/r/deeplearning/comments/aoh2z1/journals_to_publish_research_papers/,ThreeForElvenKings,1549636536,"Hey guys, can you suggest a few Scopus Indexed Computer Vision Journals. I have written a research paper in the field of CV and want to publish it. Please suggest a good Scopus indexed journal.",2,1
67,2019-2-9,2019,2,9,5,aokrks,Google Brain Research Scientist Quoc Le on AutoML and More,https://www.reddit.com/r/deeplearning/comments/aokrks/google_brain_research_scientist_quoc_le_on_automl/,Yuqing7,1549658010,,4,1
68,2019-2-9,2019,2,9,20,aorfmo,Do I have to learn deep learning or machine learning before working on an ESN-related project?,https://www.reddit.com/r/deeplearning/comments/aorfmo/do_i_have_to_learn_deep_learning_or_machine/,vardemy,1549710421,"Thanks in advance.

I have a project about ESN for this semester and I am absolutely a novice.  I do know about basic algorithms and coding though. 

So do I have to learn deep learning or machine learning first??",6,1
69,2019-2-9,2019,2,9,20,aornz2,Black Swans Meetups: Get to Know Other Data-Scientists!,https://www.reddit.com/r/deeplearning/comments/aornz2/black_swans_meetups_get_to_know_other/,jdyr1729,1549712762,"  Hi,

The idea behind *Black Swans Meetups* is that: if data-scientists meet with new data-scientists, they will discover wildly different (often better) approaches, models, etc., which can be applied to whatever they are working on.

Paul Erds, the most prolific mathematician ever to have lived, recognised this. He was always travelling around, staying with different mathematicians who gave him new ideas to prove new theorems. His motto was another roof, another proof.

I imagine each meetup would be held in some capital city, and data-scientists could go to share ideas, give cool presentations about what theyre working on, etc. 

Please comment below your thoughts. To learn more, go to: www.blackswans.io/post/143.

Jack",0,1
70,2019-2-10,2019,2,10,0,aot1cm,"as a deep learning beginner learner , do i have to also learn some CAD ?",https://www.reddit.com/r/deeplearning/comments/aot1cm/as_a_deep_learning_beginner_learner_do_i_have_to/,greenkernel,1549724533,"I know two of them are very different thing. I dug about CATIA and Nx. Found CATIA more user friendly than NX. May be because of I am not mechanical engineer.

My main objective is to be a exptert in deep learning. I was also thinking if this will be helpful in the industry if I also know a little bit of CAD like NX or CATIA.

&amp;#x200B;

any input will be very much appreciated.

&amp;#x200B;",4,1
71,2019-2-10,2019,2,10,1,aotkvv,How to make more concrete prediction based on a sequence of past predictions?,https://www.reddit.com/r/deeplearning/comments/aotkvv/how_to_make_more_concrete_prediction_based_on_a/,rexlow0823,1549728301,"Consider this toy example below:

A real-time license plate recognition program is constantly getting prediction result, frame by frame. 

So ideally each second would returns ~10 results, considering the source camera is capable of 60FPS and OCR would introduce some latency. 

Heres the tricky part, each frame is associated with some noise that directly affects the OCR result. For instance, frame 1 predicts the plate number to be ABC 12, frame 2 predicts ABD 12, frame 3 predicts SBD 72, and so on. 

So, is there a method to make more concrete prediction of a single object considering the past predictions? Like after 30 predictions we can almost sure that the license plate is really ABC 123. ",2,1
72,2019-2-10,2019,2,10,2,aoudqe,Can a learning rate graph look unusual and weird?,https://www.reddit.com/r/deeplearning/comments/aoudqe/can_a_learning_rate_graph_look_unusual_and_weird/,joyjit1996,1549733258,"I am trying to model a simple Neural Net to classify data amongst 14 classes. The data is quite high dimensional, with 21392 rows and 1970 columns, with the last column being the labels (which have encoded into integral values for classification purposes). I am referring to the proposed architecture in [https://www.kaggle.com/azzion/iris-data-set-classification-using-neural-network](https://www.kaggle.com/azzion/iris-data-set-classification-using-neural-network), where it is used on Iris data to get a conventional learning curve. But, my learning curve is coming to be something unusual, which I haven't seen before.

&amp;#x200B;

https://i.redd.it/toty9p34vkf21.png

Does my learning curve graph signify that the model performs poorly (as it doesn't go down like a conventional one using the Gradient Descent Optimizer), or is it just some point I am missing? Any comments in this regard would be appreciated. P.S. The accuracy I am getting based on the above model is close to 79%. Thanks!",2,1
73,2019-2-10,2019,2,10,3,aov0yy,No Bullshit guide to install Tensorflow GPU,https://www.reddit.com/r/deeplearning/comments/aov0yy/no_bullshit_guide_to_install_tensorflow_gpu/,rednafi,1549737007,"Despite having a dedicated GPU, installing tensorflow on that is one of those painful things that deterred me multiple times from running gpu accelerated scipts. After rummaging through piles of garbages on the internet, I managed to configure CUDA, CuDNN and tensorflow 1.12 on my new machine. 

Here is a no bullshit guide to configure tf-gpu on ubuntu 18.04.

No Bullshit Guide on Installing Tensorflow GPU (Ubuntu 18.04/18.10) by Redowan Nafi https://link.medium.com/K9QlufuNaU",5,1
74,2019-2-10,2019,2,10,11,aozotj,Advice on what deeplearning app could i make to flex on non data science people.,https://www.reddit.com/r/deeplearning/comments/aozotj/advice_on_what_deeplearning_app_could_i_make_to/,babalinobaba,1549765488,"I need to make some apps to show deeplearning Techniques to a potential client. What can I do to maximize the surprise factor?
I have experience with img recognition and text modeling and classification.
I use pyqt5 and outside for gui.",2,1
75,2019-2-10,2019,2,10,12,ap088n,Lambda Deep Learning Discord Server &amp; Deep Learning Forum,https://www.reddit.com/r/deeplearning/comments/ap088n/lambda_deep_learning_discord_server_deep_learning/,sabalaba,1549769451,"I've posted a few of the benchmarks that we've done here and thought I would also share Lambda's new Deep Learning Discord Server and Deep Learning forum:

Discord Server:
https://discordapp.com/invite/2wDzdD6

Deep Learning Forum:
https://deeptalk.lambdalabs.com

We're always lurking there and are happy to answer any questions you might have.",0,1
76,2019-2-10,2019,2,10,15,ap1gdc,Ddos detection using deep learning/ML,https://www.reddit.com/r/deeplearning/comments/ap1gdc/ddos_detection_using_deep_learningml/,harsh52,1549779608,"Hello everyone,

I need your guidance to work on a project, I am very much interested in machine learning and cyber security stuff. And I am willing to make a system which can prevent/detect ""ddos"" attack using ML, I had already search on Google regarding this but got only research paper and some article, I need some guidance to start this project(like some real code.) it would be very helpful if you guide me.
Thank you.",4,1
77,2019-2-10,2019,2,10,16,ap1qe8,Neural Networks Formalization,https://www.reddit.com/r/deeplearning/comments/ap1qe8/neural_networks_formalization/,freechoice,1549782357,"I am looking for a mathematical formalization of a neural networks. Could you please recommend any papers/books that deals with this problem? Ideally if they deal also with definitions of RNNs, CNNs, etc.",0,1
78,2019-2-10,2019,2,10,18,ap2dm6,NVIDIA Open-Sources Hyper-Realistic Face Generator StyleGAN,https://www.reddit.com/r/deeplearning/comments/ap2dm6/nvidia_opensources_hyperrealistic_face_generator/,gwen0927,1549789568,,7,1
79,2019-2-10,2019,2,10,22,ap40qj,"What is the best choice for laptop in terms of performance and speed? (My work is mainly to develop models, process data and getting insight into it).",https://www.reddit.com/r/deeplearning/comments/ap40qj/what_is_the_best_choice_for_laptop_in_terms_of/,TrustAnonymity,1549806474,,3,1
80,2019-2-10,2019,2,10,23,ap4gwx,Deploying python code,https://www.reddit.com/r/deeplearning/comments/ap4gwx/deploying_python_code/,drax-tic,1549809896,Is it easier/better to deploy my code that uses GMMs and deep neural networks as a desktop app or as a web app? Can you suggest which tool I should use?,0,1
81,2019-2-11,2019,2,11,0,ap51w9,My implementation of 3 NLP models for text classification in Pytorch and Tensorflow,https://www.reddit.com/r/deeplearning/comments/ap51w9/my_implementation_of_3_nlp_models_for_text/,1991viet,1549813739,,2,1
82,2019-2-11,2019,2,11,2,ap677w,A question about RNN's : How to use an RNN in tensorflow to predict the next 19000 timesteps.,https://www.reddit.com/r/deeplearning/comments/ap677w/a_question_about_rnns_how_to_use_an_rnn_in/,Kevin13271327,1549820467,"I want my rnn to take in an input of random noise with length(in timesteps) of 100, and output a sequence with 19000 timestpes. Is there anyway to do this? I'm unfamiliar with RNN's, and it seems that every example I've come across(which is not that many) all return a sequence with the same amount of timesteps as the input. I'm trying to create a GAN, and so I need the generator to produce the full 19,000 timesteps to send to the discriminator. Is there a way to do this?",4,1
83,2019-2-11,2019,2,11,8,ap9n1u,"A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage)",https://www.reddit.com/r/deeplearning/comments/ap9n1u/a_gentle_introduction_to_graph_neural_networks/,steeveHuang,1549839805,"Graph Neural Networks is a special type of NN that directly operates on a graph structure. In a number of recent studies, it has achieved SOTA results on various domains, including Knowledge Graph, Social Network, Life Science, and Recommender System.

&amp;#x200B;

This article will brief you the basics of Graph Neural Networks and introduce you two more advanced algorithms, DeepWalk and GraphSage. Check it out :)

[https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3](https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3)",0,1
84,2019-2-11,2019,2,11,18,apehpl,"Newbie, need advice",https://www.reddit.com/r/deeplearning/comments/apehpl/newbie_need_advice/,moe87b,1549876610,"I'm verry interested in artificial intelligence, especially deep learning,  where do I start, what programming languages are the most adapted? I'm already good in java programming",1,1
85,2019-2-11,2019,2,11,19,apev2k,I have started a complete Reinforcement learning video course series. You might like it if you are new to this exciting field of research,https://www.reddit.com/r/deeplearning/comments/apev2k/i_have_started_a_complete_reinforcement_learning/,Riturajkaushik,1549880182,,0,1
86,2019-2-11,2019,2,11,22,apg5r2,V100 server on-prem vs p3 instance total cost of ownership comparison,https://www.reddit.com/r/deeplearning/comments/apg5r2/v100_server_onprem_vs_p3_instance_total_cost_of/,sabalaba,1549891009,"Lambda just finished up our Total Cost of Ownership (TCO) analysis of an 8 x V100 Server with NVLink and an AWS p3dn.24xlarge instance.

TL;DR

The V100 Server:

- Outperforms p3dn.24xlarge on all tested deep learning tasks.
- Is 2.6% faster than AWS for FP32 training with TensorFlow.
- Is 3.2% faster than AWS for FP16 training with TensorFlow.
- Has a Total Cost of Ownership (TCO) that's $69,441 less than a p3dn.24xlarge 3-year contract with partial upfront payment. Our TCO includes energy, hiring a part-time system administrator, and co-location costs. In addition, you still get value from the system after three years, the AWS instance.

Full results here:
https://lambdalabs.com/blog/8-v100-server-on-prem-vs-p3-instance-tco-analysis-cost-comparison/

Hope you find this useful, we're very happy to be able to share these results with the community.",3,1
87,2019-2-12,2019,2,12,2,apievf,"Deep Learning in Clojure from Scratch to GPU, Part 0 - Why Bother?",https://www.reddit.com/r/deeplearning/comments/apievf/deep_learning_in_clojure_from_scratch_to_gpu_part/,dragandj,1549905153,,0,1
88,2019-2-12,2019,2,12,5,apkd21,The Obstacle Tower Challenge is live!,https://www.reddit.com/r/deeplearning/comments/apkd21/the_obstacle_tower_challenge_is_live/,leonchenzhy,1549915661,,0,1
89,2019-2-12,2019,2,12,6,apl8du,Grid Search and Keras' flow_from_directory Trouble,https://www.reddit.com/r/deeplearning/comments/apl8du/grid_search_and_keras_flow_from_directory_trouble/,thetechkid,1549920311,"Hello there, I recently ran across Grid Searches and finding optimal hyper parameters, but in my models I'm using  flow\_from\_directory for my data instead of a dataset so I was trying to find a way(or if one exists) to implement a Grid Search this way. ",0,1
90,2019-2-12,2019,2,12,6,apljk2,I am enough. #iosapp #deepfakes #realtime #AI #artificialintelligence #faceoff #faceff #faceswap #neuralnetwork #newmedia #avantgarde #newmediaart #deepart #digitalart #experimentalart #comingsoon #trump,https://www.reddit.com/r/deeplearning/comments/apljk2/i_am_enough_iosapp_deepfakes_realtime_ai/,[deleted],1549922006,[deleted],0,1
91,2019-2-12,2019,2,12,8,apmsun,How to do food menu classification,https://www.reddit.com/r/deeplearning/comments/apmsun/how_to_do_food_menu_classification/,HouseLTN,1549929264,"Im new in NLP and I have an idea where I like to classify the texts on a food menu. For example, when it detects Blend Mocha, the probability score for [coffee, beverage] will be highest. Whereas when it gets drumstick then the score for [fast food] should be highest. 

I learned that we might achieve this with FastText but I would like to learn the proper technique for doing this. ",8,1
92,2019-2-12,2019,2,12,11,apodar,One comes with tutorial while the other comes with heartbreake,https://www.reddit.com/r/deeplearning/comments/apodar/one_comes_with_tutorial_while_the_other_comes/,ai_badger,1549939201,,0,1
93,2019-2-12,2019,2,12,15,apq6x5,How to save and load a neural network in TensorFlow (deep learning tips) - Lazy Programmer,https://www.reddit.com/r/deeplearning/comments/apq6x5/how_to_save_and_load_a_neural_network_in/,8222Tamil,1549951620,,0,1
94,2019-2-12,2019,2,12,17,apr5k3,How to win on slot machines in casino with Thompsons Sampling...check this out,https://www.reddit.com/r/deeplearning/comments/apr5k3/how_to_win_on_slot_machines_in_casino_with/,Riturajkaushik,1549959478,,0,1
95,2019-2-12,2019,2,12,17,apra6z,"[P] for beginners, simple PyTorch implementaion of Neural Machine Translation(NMT)",https://www.reddit.com/r/deeplearning/comments/apra6z/p_for_beginners_simple_pytorch_implementaion_of/,lyeoni,1549960679,,0,1
96,2019-2-12,2019,2,12,22,apt6ns,Interviews with Machine Learning Heroes (Kaggle GM(s) + AI Researchers + Practitioners),https://www.reddit.com/r/deeplearning/comments/apt6ns/interviews_with_machine_learning_heroes_kaggle/,init__27,1549977129,"Hi, 

During the past few weeks, I have tried to interview various ""Machine Learning Heroes"". Here is the index to all of the interviews:

[https://www.kaggle.com/general/76241#post448008](https://www.kaggle.com/general/76241#post448008)",0,1
97,2019-2-12,2019,2,12,22,apta7x,"Interview with the Creator of DeOldify: A project that uses DL to ""colorise"" B&amp;W Images",https://www.reddit.com/r/deeplearning/comments/apta7x/interview_with_the_creator_of_deoldify_a_project/,init__27,1549977833,"Interview with Jason Antic (reddit: u/MyMomSaysImHot)

[https://hackernoon.com/interview-with-the-creator-of-deoldify-fast-ai-fellow-jason-antic-c0437670059b](https://hackernoon.com/interview-with-the-creator-of-deoldify-fast-ai-fellow-jason-antic-c0437670059b)",0,1
98,2019-2-13,2019,2,13,1,apv1km,"Intel's practical deep learning MOOC, is it any good?",https://www.reddit.com/r/deeplearning/comments/apv1km/intels_practical_deep_learning_mooc_is_it_any_good/,FewLifetimes_ago_21,1549988658,"How tough is the course for somebody who completed Andrew Ng's Machine Learning course? And how good is the course compared to other MOOCs? I plan to take the course to do deep learning projects.

[https://www.coursera.org/learn/intro-practical-deep-learning](https://www.coursera.org/learn/intro-practical-deep-learning)",1,1
99,2019-2-13,2019,2,13,3,apw6lh,Deep Learning to create music,https://www.reddit.com/r/deeplearning/comments/apw6lh/deep_learning_to_create_music/,Dynamyght,1549994564,"I'm into music and programming, and I've seen a lot of videos recently about people using deep learning to create midi files.

This works, but I've think I was wondering if it would be possible to just feed the algorithm .wav files instead of midi to teach it how to ""make music."" 

As someone who knows next to nothing about deep learning, would this be possible? I feel as if this would be very interesting, as the algorithm would literally be trying to mimic the unique sounds of a combination of instruments and the interesting harmonics that arise from harmony between instruments.",15,1
100,2019-2-13,2019,2,13,3,apwl10,Invisibility Cloak using OpenCV,https://www.reddit.com/r/deeplearning/comments/apwl10/invisibility_cloak_using_opencv/,spmallick,1549996686,"Remember the good old days of Harry Potter?   
Well at LearnOpenCV, we can't provide you with a Philosopher's stone (at least not in the near future) but we can definitely teach you how to make your own invisibility cloak!  
[https://www.learnopencv.com/invisibility-cloak-using-color-detection-and-segmentation-with-opencv/](https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.learnopencv.com%2Finvisibility-cloak-using-color-detection-and-segmentation-with-opencv%2F%3Ffbclid%3DIwAR1WwI-K20Qi5fh8G3FUULkQqEMi4GVik97dD0IPHk_iznKh0mjRnwiJTyc&amp;h=AT1JzfTBH6t9tF_wrDhERMiWkkPU1opRcXSYkFZ4yRnEzAG4MkP9gDuwlfPokYO9kIslcugOL-FcZzMdZKyPrWtXTj_o9WdPxhzI1HkUMZjefGxNfltHw-EJMbzi6KERN0MipQ)  
All you need is a basic idea of colour detection and segmentation. That, and a red cloth and you are all set! We have shared the code in Python and C++.   
[https://github.com/spmallick/learnopencv/tree/master/InvisibilityCloak](https://l.facebook.com/l.php?u=https%3A%2F%2Fgithub.com%2Fspmallick%2Flearnopencv%2Ftree%2Fmaster%2FInvisibilityCloak%3Ffbclid%3DIwAR1WwI-K20Qi5fh8G3FUULkQqEMi4GVik97dD0IPHk_iznKh0mjRnwiJTyc&amp;h=AT1JzfTBH6t9tF_wrDhERMiWkkPU1opRcXSYkFZ4yRnEzAG4MkP9gDuwlfPokYO9kIslcugOL-FcZzMdZKyPrWtXTj_o9WdPxhzI1HkUMZjefGxNfltHw-EJMbzi6KERN0MipQ)  
Please mention reviews and what you want us to work on next, in the comments!  
Invisibility Cloak using OpenCV 

![video](oj3k7nqbm6g21)",0,1
101,2019-2-13,2019,2,13,3,apwo3l,"[DISCUSSION] Trumps' AI, Other countries should also do something ??",https://www.reddit.com/r/deeplearning/comments/apwo3l/discussion_trumps_ai_other_countries_should_also/,pcidev,1549997137,"[Executive Order on Maintaining American Leadership in Artificial Intelligence](https://www.whitehouse.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/?utm_campaign=the_algorithm.unpaid.engagement&amp;utm_source=hs_email&amp;utm_medium=email&amp;utm_content=69829624&amp;_hsenc=p2ANqtz-97-P9eVWonrFphANB4LK9Iv8gZ6xEOjTrWfDsksKS-WHie6gd2MkdpoSNhoRJsrT1Ntiou-sbEdNv_PxRU7r4kH61MdkVevDuIol6UEKZRO9WKy0k&amp;_hsmi=69829624) 

&amp;#x200B;

Comment what do you think about other countries' investment in AI. Also, if some country is not investing, why ??",1,1
102,2019-2-13,2019,2,13,5,apxz72,NEW SUBREDDIT FOR GOOGLE COLABORATORY,https://www.reddit.com/r/deeplearning/comments/apxz72/new_subreddit_for_google_colaboratory/,Atralb,1550004114,"Hi guys,

&amp;#x200B;

Like many of you (if I'm not mistaken), I've been using Google's Colaboratory platform quite excessively these last month. And with usage inevitably comes issues, which are generally talked about in r/deeplearning and r/MachineLearning in Reddit. 

This is good but these threads are generally about Colab itself and not machine learning directly, which kind of is polluting those subreddits. Another big thing to take into account is that we are here working on a remote environment which brings a lot of difference in practice, and again a lot of unanswered questions. 

This is in a nutshell why I felt that creating a new Subreddit focused on the platform would be a good thing,  and well here it is : r/GoogleColab if you feel like joining :)

I've already made several threads with topics which I deemed of interest, take a look !",0,1
103,2019-2-13,2019,2,13,5,apy2rd,Neural Network 2019 Digit Recognition Use Artificial Intelligence Tutori...,https://www.reddit.com/r/deeplearning/comments/apy2rd/neural_network_2019_digit_recognition_use/,DevTechRetopall,1550004619,,0,1
104,2019-2-13,2019,2,13,5,apy5il,Tensorflow Fully Connected Layer,https://www.reddit.com/r/deeplearning/comments/apy5il/tensorflow_fully_connected_layer/,arjundupa,1550005017,"I am trying to use tf.contrib.layers.fully\_connected(inputs, num\_outputs) to convert an input with dimensions (7, 7, 512) into a vector with dimensions (512, ). the inputs would just be my input variable, but would num\_outputs be ""(512, )""?

This seems like a dumb question I should be able to test, but I'm not sure how I would. I'm used to Keras and its model.summary() function -- any parallel to that in tf? Or a simple way to test dimensions like this out? Thanks!",4,1
105,2019-2-13,2019,2,13,6,apypvp,Multilabel classification. 1 model with N outputs or N models with 1 output?,https://www.reddit.com/r/deeplearning/comments/apypvp/multilabel_classification_1_model_with_n_outputs/,dchasani,1550007944,"So I've got a multilabel classification problem. Is there a ""better"" choice between a multilabel model vs N binary models (where N=number of classes). 

So for example say I have images that could contain 4 different thing/classes. People, cars, bikes, boats. 

Is it better to have a model with 4 outputs or 4 models with 1 output each (one for each class)? How do you explain your choice? ",1,1
106,2019-2-13,2019,2,13,10,aq0t49,"I am working on Tumor classification based on Deep Learning using Gene Expression Data, I tried CNN, and accuracy was below 50%, what should I use?",https://www.reddit.com/r/deeplearning/comments/aq0t49/i_am_working_on_tumor_classification_based_on/,kulshrestha97,1550020156,,12,1
107,2019-2-13,2019,2,13,16,aq3xp4,Why a random Rademacher vector is needed to plot the graph of loss surface?,https://www.reddit.com/r/deeplearning/comments/aq3xp4/why_a_random_rademacher_vector_is_needed_to_plot/,Catherine_Fang,1550041858,"In paper *Evaluating and Understanding the Robustness of Adversarial Logit Pairing(*[*http://arxiv.org/pdf/1807.10272.pdf*](http://cn.arxiv.org/pdf/1807.10272.pdf)*)****,***  the author uses a random Rademacher vector when plotting the loss surface. Why use this vector?

&amp;#x200B;

https://i.redd.it/zqbtp30qcag21.png",0,1
108,2019-2-13,2019,2,13,18,aq4xc9,"Introducing Ludwig, a Code-Free Deep Learning Toolbox: Physics Legend Meets AI",https://www.reddit.com/r/deeplearning/comments/aq4xc9/introducing_ludwig_a_codefree_deep_learning/,aiforworld2,1550051009,"This new deep learning toolbox LUDWIG from Uber is out and is named after great physicist Ludwig Boltzmann who was greatly admired by Sir Albert Einstein.

In his book 'RelativityThe Special and General Theory' in 1916, Einstein wrote: ""I adhered scrupulously to the precept of that brilliant theoretical physicist Ludwig Boltzmann, according to whom matters of elegance ought to be left to the tailor and to the cobbler.""

https://eng.uber.com/introducing-ludwig/",4,1
109,2019-2-13,2019,2,13,19,aq5dlp,Computing number of batches in one epoch.,https://www.reddit.com/r/deeplearning/comments/aq5dlp/computing_number_of_batches_in_one_epoch/,jdyr1729,1550055151,"I have been reading through Stanford's code examples for their Deep Learning course, and I see that they have computed `num_steps = (params.train_size + params.batch_size - 1) // params.batch_size`[ \[github link\]](https://github.com/cs230-stanford/cs230-code-examples/blob/159df10a6187c7e1d6ec949c8e06d7f67f8f1cd2/tensorflow/nlp/model/training.py#L94).

Why isn't it `num_steps = params.train_size // params.batch_size` instead?

Thanks!",4,1
110,2019-2-13,2019,2,13,22,aq6l4b,[P] NSFW images URLs collection for scrapping,https://www.reddit.com/r/deeplearning/comments/aq6l4b/p_nsfw_images_urls_collection_for_scrapping/,ebazarov,1550064525,"**Project that provide lists of URLs that will help you download NSFW images**, this set can be used in building big enough dataset to train robust NSFM classification model.

https://github.com/EBazarov/nsfw_data_source_urls

This work was inspired by [nsfw_data_scrapper](https://github.com/alexkimxyz/nsfw_data_scrapper) and for downloading images suggested to use scripts from the scrapper.

**Some stats**

You will find different txt files each of them contains list of URLs, here some stats for this set:

* **159** different categories
* in total **1 589 331** URLs
* after downloading and cleaning it's possible to have ~ **500GB** or in other words ~ **1 300 000** of NSFW images",1,1
111,2019-2-13,2019,2,13,23,aq7aug,Text generation,https://www.reddit.com/r/deeplearning/comments/aq7aug/text_generation/,naskamag,1550069266,"Guys the problem is this. I have a dataset which I can train on and I have a test dataset . I should fill some places in the test dataset, not generating the whole new dataset. Is there any method that I can follow . Btw train set has 140k sentences and test has 30k.
Thanks .",0,1
112,2019-2-14,2019,2,14,0,aq7ffq,Using Gan to generate location,https://www.reddit.com/r/deeplearning/comments/aq7ffq/using_gan_to_generate_location/,NayarTenshi,1550070077,"Hi everybody, I'm having troubles to start a gan project. I have a set of location (latitude, longitude, time), i would like to feed it to a gan, so it would be able to generate new location (and so new itinerary (collection of locations)) that would kind of look like the one that i used for training. The problem is that everything i read related to gan is about generatig pictures instead of just number. Can someone help me not to lose hope in this project haha, thank you !",2,1
113,2019-2-14,2019,2,14,1,aq83q1,Ubers Code-Free Ludwig: Deep Learning for Dummies?,https://www.reddit.com/r/deeplearning/comments/aq83q1/ubers_codefree_ludwig_deep_learning_for_dummies/,Yuqing7,1550074017,,3,1
114,2019-2-14,2019,2,14,4,aqalyd,Easy-to-read summaries of top deep reinforcement learning research papers,https://www.reddit.com/r/deeplearning/comments/aqalyd/easytoread_summaries_of_top_deep_reinforcement/,drrobobot,1550087213,,1,1
115,2019-2-14,2019,2,14,14,aqga5d,Senior Design Project Roulette,https://www.reddit.com/r/deeplearning/comments/aqga5d/senior_design_project_roulette/,aRandomGuy40,1550121440,"My senior design team has decided to use deep learning to beat roulette. I want to make this network efficient and possibly useable. We plan on using a high speed camera, but are open to using other methods as well to train our model. Does anyone have any particular ideas on how to approach this problem?",2,1
116,2019-2-14,2019,2,14,14,aqgjqu,SeqGANs Output numbers,https://www.reddit.com/r/deeplearning/comments/aqgjqu/seqgans_output_numbers/,jmarsha5,1550123447,Hey guys have a quick question about SeqGANs for language generation. I pass in text to the SeqGAN but get varying numbers instead of words. I'm guessing these numbers map to the words but how do I access that mapping. It wasn't made to clear in this github repo here --&gt;[https://github.com/bhushan23/Transformer-SeqGAN-PyTorch](https://github.com/bhushan23/Transformer-SeqGAN-PyTorch),0,1
117,2019-2-14,2019,2,14,17,aqhmop,"Cool Fashion + AI Papers and Resources (datasets, companies, events, ...)",https://www.reddit.com/r/deeplearning/comments/aqhmop/cool_fashion_ai_papers_and_resources_datasets/,lzhbrian,1550132701,"[https://github.com/lzhbrian/Cool-Fashion-Papers](https://github.com/lzhbrian/Cool-Fashion-Papers)

Hi all, I am organizing a curated list of Fashion + AI papers and resources (datasets, companies, events, ...) to track the progress of technologies. Any advice or suggestions would be very much appreciated.

I really look forward to some killer apps of AI in Fashion Design in the near future!

thanks",0,1
118,2019-2-14,2019,2,14,19,aqigpr,Bag-of-Words MLP activation function,https://www.reddit.com/r/deeplearning/comments/aqigpr/bagofwords_mlp_activation_function/,glowycosmos,1550140759,"Hi all,

I trained a MLP, with as input the bag-of-words model for a binary classification task. For the hidden layer I use a relu and for the output layer a sigmoid. The accuracy score is around 0.27 (I don't have that much input data). However, when I use softmax as activation function for the outer layer, I get an accuracy score of around 0.8. In this case, the loss and accuracy do not change over time while training. That combined with the fact that it's a very high score compared to some other activation functions I've tried make me believe that something is going wrong.

I looked it up and it says online that although softmax is more often used for classification with more than two classes, it can be used for a binary classification task as well.

Do you know if this would be the case for me, and do you have a recommendation of hidden/outer layer activation functions for this task. My input data is a two sets of small texts and I followed this tutorial: [https://machinelearningmastery.com/deep-learning-bag-of-words-model-sentiment-analysis/](https://machinelearningmastery.com/deep-learning-bag-of-words-model-sentiment-analysis/).

&amp;#x200B;

Thanks!",2,1
119,2019-2-14,2019,2,14,21,aqjcix,"""Deep Learning in Medicine"" with Allen Day (53min talk from GOTO Amsterdam 2018)",https://www.reddit.com/r/deeplearning/comments/aqjcix/deep_learning_in_medicine_with_allen_day_53min/,goto-con,1550148135,,0,1
120,2019-2-15,2019,2,15,2,aqm35j,OpenAI Guards Its ML Model Code &amp; Data to Thwart Malicious Usage,https://www.reddit.com/r/deeplearning/comments/aqm35j/openai_guards_its_ml_model_code_data_to_thwart/,gwen0927,1550164755,,4,1
121,2019-2-15,2019,2,15,3,aqmxpq,Natural language processing in Healthcare Domain,https://www.reddit.com/r/deeplearning/comments/aqmxpq/natural_language_processing_in_healthcare_domain/,ghothic,1550169295,"Hi People 

I am working on NLP project where I need to extract relevant information through unstructured text at user level data. I have scrapped around 20000 posts from online forums. I need to make a model where I need to define some entities and extract relevant information from the posts of users.
For example-- Let say I have scraped the data for hotel reviews. And I need to define entities by going through the posts. Entities could be like Name of the person, location, unmet needs( What kind of things a user is expecting from the hotel). Let say if I am able to see the pattern in the posts -- For example 1000 out of 20000 users are writing about the size of the bed in the hotel. So I'll define the entity related to size of the bed.  

I am new to this field. And I am struggling like anything. Does anyone have similar experience. Has anyone worked on similar kind of project?? ",2,1
122,2019-2-15,2019,2,15,14,aqt3u8,Just Launched Irvine Algotrading Meetup Group,https://www.reddit.com/r/deeplearning/comments/aqt3u8/just_launched_irvine_algotrading_meetup_group/,imactually,1550207036,,3,1
123,2019-2-15,2019,2,15,19,aqv7j5,Controlling robotic arm with deep reinforcement learning,https://www.reddit.com/r/deeplearning/comments/aqv7j5/controlling_robotic_arm_with_deep_reinforcement/,pirate7777777,1550225784,,1,1
124,2019-2-15,2019,2,15,19,aqvewm,"""Composing Bach Chorales Using Deep Learning"" with Feynman Liang (43min talk from GOTO Amsterdam)",https://www.reddit.com/r/deeplearning/comments/aqvewm/composing_bach_chorales_using_deep_learning_with/,goto-con,1550227768,,0,1
125,2019-2-16,2019,2,16,1,aqy3x3,AI Hasn't Found Its Isaac Newton: Gary Marcus on Deep Learning Defects &amp; 'Frenemy' Yann LeCun,https://www.reddit.com/r/deeplearning/comments/aqy3x3/ai_hasnt_found_its_isaac_newton_gary_marcus_on/,Yuqing7,1550247081,,3,1
126,2019-2-16,2019,2,16,5,ar1754,Get started with Google Colaboratory (Coding TensorFlow),https://www.reddit.com/r/deeplearning/comments/ar1754/get_started_with_google_colaboratory_coding/,asuagar,1550264375,,2,1
127,2019-2-16,2019,2,16,6,ar1tty,Using AI to Turn Your Face Into A Continuum Of Nightmares,https://www.reddit.com/r/deeplearning/comments/ar1tty/using_ai_to_turn_your_face_into_a_continuum_of/,InspectahM,1550267994,,0,1
128,2019-2-16,2019,2,16,9,ar38qp,"Here is my pytorch implementation of the model described in the paper DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs (https://arxiv.org/pdf/1606.00915.pdf) Source code: https://github.com/vietnguyen91/Deeplab-pytorch",https://www.reddit.com/r/deeplearning/comments/ar38qp/here_is_my_pytorch_implementation_of_the_model/,1991viet,1550276808,,1,4
129,2019-2-16,2019,2,16,19,ar7p3x,Mxnet Vs rest of the planet :\,https://www.reddit.com/r/deeplearning/comments/ar7p3x/mxnet_vs_rest_of_the_planet/,mouryarishik,1550313548,"I have started using mxnet and it's been a month, and I love it. I used to be a dead tensorflow fan but since using it changed my mind. It's imperative nature is best for research and prototyping, and it's declarative nature(hybridising) makes it more faster than tensorflow and other frameworks. 

Still a bit curious to know some of thoughta from you guys, what would be the best deep learning framework for research, prototype, debugging and production?

Let's commence the fight.",16,8
130,2019-2-16,2019,2,16,23,ar98dg,Custom WebGL Operation in TensorFlow.js,https://www.reddit.com/r/deeplearning/comments/ar98dg/custom_webgl_operation_in_tensorflowjs/,lewuathe,1550327307,,0,1
131,2019-2-17,2019,2,17,14,arhj0e,Marathon Bib Identification and Recognition,https://www.reddit.com/r/deeplearning/comments/arhj0e/marathon_bib_identification_and_recognition/,kapilvarshney,1550381057,,0,3
132,2019-2-17,2019,2,17,15,ari34p,Take 4 : Presentations on 'Elements of Neural Networks and Deep Learning' - Parts 1-8,https://www.reddit.com/r/deeplearning/comments/ari34p/take_4_presentations_on_elements_of_neural/,tvganesh,1550385688,,0,1
133,2019-2-17,2019,2,17,16,aribgu,Keras Custom Loss Function,https://www.reddit.com/r/deeplearning/comments/aribgu/keras_custom_loss_function/,arjundupa,1550387908,"I've been trying to implement the following loss function in Keras:

&amp;#x200B;

*Processing img griv9ldmx2h21...*

According to [https://stackoverflow.com/questions/43818584/custom-loss-function-in-keras/43821374](https://stackoverflow.com/questions/43818584/custom-loss-function-in-keras/43821374), I must use ""keras backend functions for calculations."" I wanted to implement this and test it out with some values to make sure I was getting the right outputs -- this is the code I wrote, but it doesn't like NumPy inputs and I'm not sure how to feed my 1D NumPy arrays into the Keras placeholders:

    x = K.placeholder(shape=(5, 1))
    y = K.placeholder(shape=(5, 1))
    K.set_value(x,np.ones(shape=(5, 1)))
    K.set_value(y,np.ones(shape=(5, 1)))
    print(K.dot(K.transpose(x), y))

I get an error on the third line saying 'Tensor' object has no attribute 'assign.' Any ideas how to feed my 1D NumPy arrays into the Keras placeholders?

\*I know keras.ones exists in place of np.ones, but I would like to be able to feed my 1D NumPy arrays into the Keras placeholders...

Any ideas will be much appreciated, thanks!

&amp;#x200B;",2,5
134,2019-2-17,2019,2,17,19,arjknc,Deep Learning Song,https://www.reddit.com/r/deeplearning/comments/arjknc/deep_learning_song/,prithvi45,1550400983,,0,1
135,2019-2-17,2019,2,17,20,arjnnj,[D] A Quick Start for Matrix Calculus,https://www.reddit.com/r/deeplearning/comments/arjnnj/d_a_quick_start_for_matrix_calculus/,LynnHoHZL,1550401843,,0,13
136,2019-2-17,2019,2,17,20,arjq87,Predict segmentation mask in another domain,https://www.reddit.com/r/deeplearning/comments/arjq87/predict_segmentation_mask_in_another_domain/,nyquist_karma,1550402556,"I was wondering if it is possible to train a network with images from domain A and masks from domain B, and then input an image from domain A to predict a mask in domain B. For instance, train with CT images and corresponding binary masks from MRI image pairs, then input CT image and predict the binary mask for the 'supposedly' corresponding MRI image. Do you have any ideas?",1,2
137,2019-2-17,2019,2,17,21,ark36i,One-class YOLO vs 2-class YOLO object detection.,https://www.reddit.com/r/deeplearning/comments/ark36i/oneclass_yolo_vs_2class_yolo_object_detection/,srbh66,1550406031,"I am working on a problem where we are interested in only 1-class at the end. Simple example detecting only person. I have an annotated data for only person.
Now I need to decide whether to train a 1-class YOLO or put more annotation in background and mark as ""other"" class then train a 2-class YOLO.? Which one would give better accuracy or recall?

Additional query is:
a) How the YOLO will behave when there is only 1-class. I mean does the network internally learns person vs non-person? How ot will do a contrast when there only 1-class.
b) If a) does not work well, I feel creating a separate class should actually help. BUT here ""other""  class could contain wide variety of objects fitted under 1 annotation. Is network will get even more confused? Will it affect ""person"" class as well?

",11,8
138,2019-2-17,2019,2,17,23,arkwbw,YOLO training with missing annotations,https://www.reddit.com/r/deeplearning/comments/arkwbw/yolo_training_with_missing_annotations/,srbh66,1550412930,"I have a weekly annotated dataset with only 1-class ""human"" annotated. Somehow out of all humans humans, 70% of them are annotated but 30% are still not annotated. For e.g. if there are 5 people in the image only 3or 4 would be annotated.

Now I want to train a YOLO using this dataset, what would you recommend:
a) Train YOLO with existing dataset. 
b) Annotate all the humans( which is time consuming &amp; difficult to do) then train YOLO.

Option b) obviously should work better.

Fundamental question is: how YOLO would perform if I choose option a)? Kindly share your experiences and insight of YOLO understanding.",7,3
139,2019-2-17,2019,2,17,23,arl8js,Help with understanding the deepfakes - faceswap code,https://www.reddit.com/r/deeplearning/comments/arl8js/help_with_understanding_the_deepfakes_faceswap/,xxcaymxx,1550415478,I'm working on the deepfakes - faceswap code on github and I've already trained a model. Now I wish to apply that on a video but I don't understand all the arguments that are involved in the convert part of the code and how they'll affect the resulting video. If someone can explain those or point me to the proper resources that'll be great.,0,0
140,2019-2-18,2019,2,18,2,armv10,Tips to implement huge complicated networks,https://www.reddit.com/r/deeplearning/comments/armv10/tips_to_implement_huge_complicated_networks/,perceptron333,1550425419,"Hey all, 

I would like to implement object detection, segmentation algorithms like Yolo, FRCNN, DeepLab, U-net etc. But these arent just straight-forward neural networks that can be coded up in a few hours, because a lot goes into just implementing the network-architecture itself. So, I was wondering how to go about getting started with these complicated networks in general which are currently the state of the art / widely used in the industry? I also have to point out that my programming knowledge is not phenomenal and I dont come from a computer science background. Any tips or suggestions will be greatly appreciated. ",6,8
141,2019-2-18,2019,2,18,3,arnbe5,RNN using Tabular Data with Categorical Variables,https://www.reddit.com/r/deeplearning/comments/arnbe5/rnn_using_tabular_data_with_categorical_variables/,ragas_,1550427889,"Hi,

Currently I'm working on a project to use tabular data that has categorical variables. I want to use RNN architecture. Can anyone please refer me some example code for this? I prefer to work with tensorflow. So, it will be great if someone share some tensorflow example code.

Thanks!",3,10
142,2019-2-18,2019,2,18,13,arteg1,Has anyone seen this yet?,https://www.reddit.com/r/deeplearning/comments/arteg1/has_anyone_seen_this_yet/,Autogazer,1550465344,,5,13
143,2019-2-18,2019,2,18,15,arugh2,PyTorch or Tensorflow?,https://www.reddit.com/r/deeplearning/comments/arugh2/pytorch_or_tensorflow/,bananakiu,1550473048,Which is better for you and why?,8,2
144,2019-2-18,2019,2,18,19,arvzz7,Google Launches Reinforcement Learning Frameworks to Train AI Models,https://www.reddit.com/r/deeplearning/comments/arvzz7/google_launches_reinforcement_learning_frameworks/,georgedatascience,1550486498,,0,1
145,2019-2-18,2019,2,18,20,arwf1b,learnml.online - GPU-accelerated computing Beta testing.,https://www.reddit.com/r/deeplearning/comments/arwf1b/learnmlonline_gpuaccelerated_computing_beta/,learnml-online,1550490117,"We have an exciting announcement to make. 

We are starting out Beta testing for www.learnml.online, an accessible  GPU cloud computing platform

&amp;#x200B;

During Beta testing you can get free access to our service for for 1 week, in return we would like to hear your feedback.

We have available slots for testers of all categories - including beginners, students and developers. 

To join please complete our 1 minute survey [Here](https://goo.gl/forms/t4XpA3XI6Bts4q5O2)  \&gt; [https://goo.gl/forms/t4XpA3XI6Bts4q5O2](https://goo.gl/forms/t4XpA3XI6Bts4q5O2) 

&amp;#x200B;

The survey data will be public so If you are not interested in testing our platform, you can still help by completing the survey anonymously. This will help us to portray the usage of todays machine learning. 

Were looking forward to getting your feedback!",2,19
146,2019-2-18,2019,2,18,22,arx0ur,Is there is a strong laptop for AI and support linux out of box,https://www.reddit.com/r/deeplearning/comments/arx0ur/is_there_is_a_strong_laptop_for_ai_and_support/,hesham_khalil,1550494999,"Hi , is there is a laptop strong for AI research and at the same support Linux out of the box .   
And doesn't have thermal throttling issue ",7,1
147,2019-2-18,2019,2,18,23,arxukj,North African Summer School in ML with focus on DeepLearning,https://www.reddit.com/r/deeplearning/comments/arxukj/north_african_summer_school_in_ml_with_focus_on/,saadoune2018,1550500788,"A first edition of the North African Summer School in ML (NASSMA) is intended for academics, PhD students, engineers, with the possibility to present a poster. There are also (limited) possibilities for scholarships.
Applications are open on www.nassma-ml.org .
It is an opportunity for networking, engaging collaborations and of course learning about ML from very interesting lecturers.",1,4
148,2019-2-18,2019,2,18,23,arxw7k,How to debug a deep learning model?,https://www.reddit.com/r/deeplearning/comments/arxw7k/how_to_debug_a_deep_learning_model/,No1lived4ever,1550501098,"I was working out an LSTM model. Somehow it is not converging .  Business case is to analyse click sequences on web pages and try to learn them..

I am not showing yet my Keras code. Nonetheless I wanted to discuss on how can we learn effectively debug such a network. In summary my model has one LSTM with 200 units followed by another LSTM with 100 and then finally a Softmax dense output. 
Model summary shows about 2 million parameters.

My data is not flawed , so we can rule out this possibility. What can then go wrong with Gradient Descent ? And I can not Analyze gradients after each batch update as there are 2 M parameters.


I also dont want to just try out different constellations of hyperparameters or the network itself. All I am interested in is to find out why this model doesnt converge.


How would you approach this problem? 
Thanks 

",5,5
149,2019-2-19,2019,2,19,6,as29at,I just posted my 6th video on Reinforcement Learning tutorial series...we are quickly moving towards modern RL approaches such as DQN etc. So check this out and if you feel it's useful then please follow the series. Give your advices and suggestions...,https://www.reddit.com/r/deeplearning/comments/as29at/i_just_posted_my_6th_video_on_reinforcement/,Riturajkaushik,1550524989,,0,0
150,2019-2-19,2019,2,19,7,as2pxc,"what context"" bigger on the inside "" means in artificial intelligence deep learning , machine learning?",https://www.reddit.com/r/deeplearning/comments/as2pxc/what_context_bigger_on_the_inside_means_in/,Doctor_who1,1550527537,"what context"" bigger on the inside "" means in artificial intelligence deep learning , machine learning?",0,0
151,2019-2-19,2019,2,19,8,as3f4f,The Power of AI Generated Stories,https://www.reddit.com/r/deeplearning/comments/as3f4f/the_power_of_ai_generated_stories/,00hello,1550531582,"The past 3 years, I've made a modest income generating genre fiction novels using deep learning and publishing them. By A/B testing under many different pen-names I've been able to discover and serve tiny niches a human author would have trouble even finding. Most of the credit goes to a large and painstakingly annotated data set (which oddly enough, occurred to me just a few hours after my father died).  I'm continuously in awe of how powerful the ability to tell people a fictional story about the world is but more alarmingly, that often times the only difference between my books and many books I see under ""non-fiction"" is the category we each selected in the drop down menu.

&amp;#x200B;

No matter what your opinion is on Open AI's decision to restrict their model,  this technology has much more profound and dangerous implications than most people realize. Whether you want people to build a pyramid, believe in Jesus or buy a stock, stories are how you program people and cultures. Yuval Noah Harari makes a good case in his books that our ability to share and collectively believe in fictional stories is what made us the dominant species on the planet. 

&amp;#x200B;

That being said, I now have a 240 GB training set of over 2.7 million narratives from fiction and non-fiction, about 85-90% English, each with very structuralized meta data, including the names of the central people in the narrative, directional graphs about their relationships, tags of their behavioural traits, tags of narrative themes, outcomes, points of view etc. etc. I have more data than my AI skills or my computational resources can effectively utilize. If there's anyone here with a very strong DL and NLP background who I can partner with to get access to the resources needed to train on my entire data set, please let me know. ",25,42
152,2019-2-19,2019,2,19,8,as3s5f,"Minimal Tensorflow Deep neural network classifier working example, with training, checkpoints and API with Flask.",https://www.reddit.com/r/deeplearning/comments/as3s5f/minimal_tensorflow_deep_neural_network_classifier/,SEND_ME_RARE_PEPES,1550533721,,0,15
153,2019-2-19,2019,2,19,9,as4gaa,Model to predict depression symptoms using twitter data,https://www.reddit.com/r/deeplearning/comments/as4gaa/model_to_predict_depression_symptoms_using/,vinicius978,1550537905," 

* I'm willing to use this dataset ([https://www.kaggle.com/kazanova/sentiment140](https://www.kaggle.com/kazanova/sentiment140)) to train a model to predict if a person has depression symptoms.
* If I classify manually let's say 5000 of the 1kk+ tweets as having depressive symptoms, can I create a reliable model?
* I've been studying and implementing a neural network with 2 input layers, 2 hidden and 1 output. But my question is: can I use NN to train this model or do I have to apply some techniques like the Bag of Words, Bigrams, N-grams?

p.s.: I'm a beginner in ML world, correct me if I'm wrong, please.

&amp;#x200B;

Is there another way to find some insights using natural language processing techniques? I don't have too much knowledge in this area yet. 

This is the final work of my undergraduate course, so I don't need like a perfect Thesis for that, just a work that has meaning and results. I don't have a plan B right now and you're absolutely right, I indeed don't know the truth and my biased opinion will be reflected in a good or bad manner on the final model.

I've been through depression and anxiety crisis in the last 6 months, so my idea at the beginning was to create something to help others. I don't mind changing the subject again. My first idea was to create an app with a Chatbot  feature (and train it with dialogflow) where people could have a conversation and talk about its feelings and perhaps  we could monitor the user's messages in order to find some dark/obscure patterns using a dictionary with words labeled as negative, positive and neutral. But at some point, I thought that nobody was going to use it and changed my mind.

So I appreciate every support that someone would give me about the work's theme. Any kind of help will be welcome! Thanks.",3,7
154,2019-2-19,2019,2,19,13,as66lz,Best Research Groups in Deep Learning today?,https://www.reddit.com/r/deeplearning/comments/as66lz/best_research_groups_in_deep_learning_today/,lazereleven,1550549045,"I apologize if this has already been covered in recent times, but I was just wondering what you guys are the best research groups/schools for Machine Learning, and specifically Deep Learning research right now? Of course we have the usual suspects like CMU, Toronto, etc. Im hoping for some groups and schools that might not be super popular, but anything goes. 

Thank you so much in advance. ",5,6
155,2019-2-19,2019,2,19,14,as6snk,Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/as6snk/deep_learning_in_python/,skj8,1550553413,"If you want to learn Deep Learning in Python, this course will introduce you to the fundamental concepts and terminologies used in deep learning, and understand why deep learning techniques are powerful these days.

[Go To Course](https://sinxloud.com/best-ai-deep-learning-courses/#1-deep-learning-in-python)",1,9
156,2019-2-19,2019,2,19,19,as91h7,"How is the state/memory variable's length (h,a or s) in a RNN specified?",https://www.reddit.com/r/deeplearning/comments/as91h7/how_is_the_statememory_variables_length_ha_or_s/,MasterSama,1550572613,"Hello everyone, 

We know that in RNN there is a state that is responsible for keeping track of the information concerning the fed sequence.

In notations, some write them as *a*, some write them as *s*, and some others write them as *h* .

How do we specify their length ? 

Are they bound to be 1 dimensional ? or can they have any arbitrary dimensions ? 

for example for text processing where the input sequnce is a sentence, I have seen they specify the a, as 100 for example and define it like this : 

`a = np.zeros(shape = (batch, length, number_of_time_steps)`

&amp;#x200B;

is it corroloated with the number of time steps? or any value can be used? 

in case we have images as input, or any image like input at every time step, Do we use a 2D *a* ? 

Is it any difference in GRU/LSTM or are they all the same in this regard ( by that I mean, GRU has this variable, but also it has another one usually called *c*  and LSTM also has similar situation) 

&amp;#x200B;

I would be grateful if anyone could explain this for me. 

Thanks in advance ",7,3
157,2019-2-20,2019,2,20,1,asc2uv,How large of training set required for good results with GANs?,https://www.reddit.com/r/deeplearning/comments/asc2uv/how_large_of_training_set_required_for_good/,thraway14,1550592986,"To use GANs, what is a range of the minimum training size needed to get at least reasonable results? Like 10,000+ rows?",0,1
158,2019-2-20,2019,2,20,1,asccmr,Open Source Beginner,https://www.reddit.com/r/deeplearning/comments/asccmr/open_source_beginner/,Vaiku2718,1550594490,"Hey,I have descent understanding of deep learning and computer vision and I have worked on a few projects on them. I was thinking on getting started with open source. I want to make contributions to some nice communities. I have worked a lot on pytorch but relatively little on tensorflow. So if anyone could suggest some good projects to get started with it would be nice.

Thanks",0,1
159,2019-2-20,2019,2,20,1,ascd60,How large of training set required for good results with GANs?,https://www.reddit.com/r/deeplearning/comments/ascd60/how_large_of_training_set_required_for_good/,rodmunch1,1550594566,"To use GANs, what is a range of the minimum training size needed to get at least reasonable results? If you're generating images, would you need something like 10,000+ images for the training set?",4,13
160,2019-2-20,2019,2,20,5,asf2et,Classification of different footwear types along with other relevant footwear attributes,https://www.reddit.com/r/deeplearning/comments/asf2et/classification_of_different_footwear_types_along/,ramya07,1550608566,"I have a labelled dataset of around 15K footwear images - different orientations and views. I want to train a network for footwear type classification and also other attributes like heel height, boot height, toe type etc. The problem is there are multiple orientations and views of footwear in the dataset. I've tried training a Resnet for each of these attributes but the accuracies are not high.  When I test using different orientations of the same footwear the network fails to give me the correct output.

I would like some assistance on the following points.

1. Are there other computer vision oriented preprocessing techniques that can help me - Like SIFT?
2. What other DL techniques can be used - like visual attention models?",0,2
161,2019-2-20,2019,2,20,8,ash0cn,"I'm learning about convolutional neural networks and would like to implement one by scratch in python using numpy, what are some good resources to learn CNNs intuitively for someone with a non math/cs background?",https://www.reddit.com/r/deeplearning/comments/ash0cn/im_learning_about_convolutional_neural_networks/,ilikerum2,1550619236,,16,19
162,2019-2-20,2019,2,20,19,asmm3l,"Hi all, I'm a research student, researching self-trained algorithms. I would appreciate if you filled in a short 2-minute survey.",https://www.reddit.com/r/deeplearning/comments/asmm3l/hi_all_im_a_research_student_researching/,potatoborn,1550656963,,0,0
163,2019-2-20,2019,2,20,20,asn9p8,What's trend in sentiment analysis on twitter and using transfer learning,https://www.reddit.com/r/deeplearning/comments/asn9p8/whats_trend_in_sentiment_analysis_on_twitter_and/,mohammadkh766,1550662189,I want to working on using  transfer learning in twitter tweets. I want to know what section can i work for my proposal and where can i srart??,4,4
164,2019-2-20,2019,2,20,20,asndkl,Margin loss capsule network,https://www.reddit.com/r/deeplearning/comments/asndkl/margin_loss_capsule_network/,PyWarrior,1550662956,What is the intuition behind margin loss in capsule networks? What is it's intuition in classification?,0,1
165,2019-2-21,2019,2,21,1,asq8yz,FCN re-implementation with TensorFlow - 68.5 mIoU,https://www.reddit.com/r/deeplearning/comments/asq8yz/fcn_reimplementation_with_tensorflow_685_miou/,Fanos6,1550679785,"GitHub is full of implementations of FCN models (arXiv 1605.06211) for pixel-level object class labeling. Yet, finding a comprehensive TensorFlow re-implementation yielding similar results to the ones reported by the authors of the paper can be a challenge. This week I published such a re-implementation, delivering even slightly better results. For more information please check [github.com/fmahoudeau/fcn](https://github.com/fmahoudeau/fcn) ",0,17
166,2019-2-21,2019,2,21,1,asqbs9,Classification for just one type of data,https://www.reddit.com/r/deeplearning/comments/asqbs9/classification_for_just_one_type_of_data/,tanghan,1550680179,"I am trying to get a network to recognize one particular pattern out of various different patterns.

&amp;#x200B;

Kind of like the basic classification example, just that I only intend to train on pictures of shoes. Is there a specific approach to this kind of problem? a term I might not be aware of? or do i have to provide a set of random other pictures and divide the labels as ""shoe"" and ""not a shoe""?

&amp;#x200B;

thanks for your help",5,2
167,2019-2-21,2019,2,21,3,ass5p7,"Cheap GPU Servers | GTX 1080 for $0,185/h",https://www.reddit.com/r/deeplearning/comments/ass5p7/cheap_gpu_servers_gtx_1080_for_0185h/,render_rapidly,1550689136,"As [renderrapidly.com](http://renderrapidly.com) we currently offer special prices for monthly rentals:

* **GTX 1080** (i7, 64GB RAM, 1000GB SSD) server is **$0,197** \*
* **5 x GTX 1080** (i7, 32GB RAM, 600GB SSD + HDD) server is **$0,185** \*

If you need a different configuration, please let us know. For weekly prices and more, please visit [renderrapidly.com](http://renderrapidly.com)

\* *when booked monthly &amp; paid by crypto*   


&amp;#x200B;",5,2
168,2019-2-21,2019,2,21,7,asv2vd,Can some kind soul help me understand this detail about the MXnet fine tuning example in their documentation?,https://www.reddit.com/r/deeplearning/comments/asv2vd/can_some_kind_soul_help_me_understand_this_detail/,bandalorian,1550703250,"Looking at the mxnet documentation here: [https://gluon.mxnet.io/chapter08\_computer-vision/fine-tuning.html](https://gluon.mxnet.io/chapter08_computer-vision/fine-tuning.html)

It takes the pretrained squeenext1\_1 weights, and sets imagenet\_hotdog\_index variable to 713.

    net = models.squeezenet1_1(pretrained=True, prefix='deep_dog_', ctx=contexts) # hot dog happens to be a class in imagenet. # we can reuse the weight for that class for better performance # here's the index for that class for later use 
    imagenet_hotdog_index = 713 

Then they set a 2 class output layer on top of it

    deep_dog_net = models.squeezenet1_1(prefix='deep_dog_', classes=2) deep_dog_net.collect_params().initialize(ctx=contexts) 
    deep_dog_net.features = net.features 
    print(deep_dog_net) 

Where I get confused is in the classify\_hot dog function - it is applying softmax to the output layer, and then returning the highest result index. This would make perfect sense if we had somehow told the network to compare against index 713. But it is called for prediction before the index variable is being reused? How does the network know the class to compare against is index 713/hot dog? We've basically taken squeezenet and reduced it down to 2 class output. But how does the network know what class to compare it to? Why would it give a high probability to the second argument/class when showing a hotdog - seems to me it shouldn't know what class it is comparing it to?

    out = mx.nd.SoftmaxActivation(net(image.as_in_context(contexts[0]))) 
    print('Probabilities are: '+str(out[0].asnumpy())) 
    result = np.argmax(out.asnumpy()) 

I would have expected it to maybe use the full squeezenet output layer, and set something like

    if np.argmax(out.asnumpy()) == 713:      
        ""Hot Dog!' 
    Else:      
        ""Not hot dog!"" 

Never understood this and would appreciate if anyone could help me get this detail.",0,2
169,2019-2-21,2019,2,21,13,asyp9m,Objective evaluation metric of GAN performance?,https://www.reddit.com/r/deeplearning/comments/asyp9m/objective_evaluation_metric_of_gan_performance/,bandalorian,1550723164,"How do you measure incremental improvements of GAN models from hyperparameter tuning? Loss is relative to adversary so can't be used, and smaller improvements in images are hard to tell/subjective. I've heard of [inception score](https://github.com/nnUyi/Inception-Score), and found a few other ideas in papers/articles etc. But is there anything in tensorflow/keras that can be used directly? Are there any standard performance metrics or plots you use to check if changes are showing promise?",0,5
170,2019-2-21,2019,2,21,13,asyuff,NEAT noise-screen representation,https://www.reddit.com/r/deeplearning/comments/asyuff/neat_noisescreen_representation/,nrmxndal,1550724053,"I was reading this paper
https://www.cs.utexas.edu/~mhauskn/papers/atari.pdf
Its about NEAT on atari games. I was wondering what exactly noise screen representation is and how you could implement it possibly in python. any insight?",0,2
171,2019-2-21,2019,2,21,14,aszd70,Gender &amp; Age Classification using OpenCV Deep Learning,https://www.reddit.com/r/deeplearning/comments/aszd70/gender_age_classification_using_opencv_deep/,spmallick,1550727332,"Ever wondered what a person's real age was? Or have you seen a baby and been really confused if it is a boy or a girl? Well, guess what! LearnOpenCV has a new blog post and it reveals how you can easily guess age and gender using OpenCV Deep Learning

![video](fhe21zxwyuh21)

[https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/](https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/)

We'll be using Convolutional Neural Network (CNN) architecture, and focus on honing the Age Prediction Model.   
Like, tag your friends and follow us for more of such exciting stuff! Mention reviews and what you want us to work on next, in the comments!",4,29
172,2019-2-21,2019,2,21,14,aszgra,Deployment of voice assistant trained in keras,https://www.reddit.com/r/deeplearning/comments/aszgra/deployment_of_voice_assistant_trained_in_keras/,analystanand,1550727961,"#voiceassistant 
#keras 
#tensorflow 
Anyone worked on deployment of voice assistant model trained in keras.

Which stack have you utilised and how did you predicted on stream line data ?

Please link the source if you have something regarding it.",0,1
173,2019-2-21,2019,2,21,15,at03h6,How to prepare for Deep Learning technical interview?,https://www.reddit.com/r/deeplearning/comments/at03h6/how_to_prepare_for_deep_learning_technical/,o13086843,1550732340,"I have minimal experience with Deep Learning. My only experience with it was spending a few months in my job developing some basic CNNs. Despite this limited experience, I just added a bullet point on my resume for using CNNs

I've had a few interviews recently in which I was asked some questions about my experience with DL/CNNs and I was honest in that I only have a little experience with it. But those roles seem to have DL as just one component of the job

I have an upcoming interview in which it seems that DL will be the primary component of the job. Although it sounds very interesting, I'm concerned I won't be qualified as I have minimal experience with DL

What are some interview questions I should expect to know about DL?",3,3
174,2019-2-21,2019,2,21,18,at15oe,My implementation of YOLO - You only look once (ver 2) for object detection tasks. Source code: https://github.com/vietnguyen91/Yolo-v2-pytorch,https://www.reddit.com/r/deeplearning/comments/at15oe/my_implementation_of_yolo_you_only_look_once_ver/,1991viet,1550740929,,3,17
175,2019-2-21,2019,2,21,18,at1d3d,Localizing handwritten text in scanned documents,https://www.reddit.com/r/deeplearning/comments/at1d3d/localizing_handwritten_text_in_scanned_documents/,atinesh229,1550742595,"I need to localize handwritten text and signature (not recognize) in scanned documents. I have searched and came across 2 methods

&amp;#x200B;

**Method #1**: Faster R-CNN

Use pre-trained model trained on COCO dataset(large) then apply transfer learning on labeled scanned documents dataset (small).

[Link 1](https://github.com/CatalystCode/Handwriting)   [Link 2](https://www.microsoft.com/developerblog/2018/05/07/handwriting-detection-and-recognition-in-scanned-documents-using-azure-ml-package-computer-vision-azure-cognitive-services-ocr/)   [Link 3](https://github.com/jugg1024/Text-Detection-with-FRCN)

&amp;#x200B;

[Sample](https://i.redd.it/moalitka8wh21.png)

**Method #2**: Maximally Stable Extremal Regions (MSER)

&amp;#x200B;

Which method will be helpful. Has anybody worked in this sort of problem, any advice will be of great help.",0,1
176,2019-2-21,2019,2,21,23,at3vvn,"The Difference Between Artificial Intelligence, Machine Learning, and Deep Learning",https://www.reddit.com/r/deeplearning/comments/at3vvn/the_difference_between_artificial_intelligence/,KendyJa,1550760100,,3,11
177,2019-2-22,2019,2,22,1,at545r,NAS-Generated Model Achieves SOTA In Super-Resolution,https://www.reddit.com/r/deeplearning/comments/at545r/nasgenerated_model_achieves_sota_in/,gwen0927,1550766651,,0,1
178,2019-2-22,2019,2,22,3,at6gcl,Single object localisation problem,https://www.reddit.com/r/deeplearning/comments/at6gcl/single_object_localisation_problem/,edidamanish,1550773164,"Given a dataset containing only the coordinates of the bounding boxes, I have to make a model to predict the bounding boxes on test images. I already tried a resnet model in which I just added a layer of Dense which gave me regressed values of the 4 corrdinates of the bounding boxes pretty accurately. I wanted to know if there are any other approaches which can help me increase the accuracy. ",2,1
179,2019-2-22,2019,2,22,4,at7d3z,Forgery detection,https://www.reddit.com/r/deeplearning/comments/at7d3z/forgery_detection/,roset_ta,1550777703,"
Anyone know if there is any good/big enough video (or image) dataset for copy - move detection?",0,1
180,2019-2-22,2019,2,22,5,at862q,Math behind the Partial Convolution based Padding,https://www.reddit.com/r/deeplearning/comments/at862q/math_behind_the_partial_convolution_based_padding/,Handsome-Beaver,1550781746,"Hello, I was reading through this paper [https://arxiv.org/abs/1811.11718](https://arxiv.org/abs/1811.11718) where it describes a technique for convolutional edges that are not zero padded but instead treated as gaps or edges.

 

I'm a programmer by profession so some of the mathematical notation escapes me. Particularly on page three, there are two equations which describe x\`(i,j)

  


I'm a little lost on the notation. What is the hollow circle with a dot mean? What does the  ||M(i,j) ||1   mean?",1,2
181,2019-2-22,2019,2,22,7,at9mp9,Standard benchmarks for transfer learning,https://www.reddit.com/r/deeplearning/comments/at9mp9/standard_benchmarks_for_transfer_learning/,r2m2,1550789275,"I'm working on generalizing the results of [this paper](https://arxiv.org/abs/1803.03635), and specifically am investigating the efficacy of ""winning tickets"" (i.e. sparse sub-networks with the same validation accuracy) in transfer learning problems. However, unlike other problems such as object detection where there are standard benchmark datasets (i.e. ImageNet, CIFAR-10), I've been unable to find any canonical ones for transfer learning tasks. [This paper](https://arxiv.org/pdf/1802.01483.pdf) (in section 4.1) says that:

&gt;For comparing the effect of similarity between the source problem and the target problem on transfer learning, we chose two source databases: ImageNet (Deng et al. 2009) ... and Places 365 (Zhou et al. 2017) ... Likewise, we have three different databases related to three target problems: Caltech 256 (Griffin et al. 2007) ...MIT Indoors (Quattoni &amp; Torralba 2009)...Stanford Dogs 120 (Khosla et al. 2011) contains images of 120 breeds of dogs

It seems like the standard way of going about this is first training a model on a large, very general dataset and then refining it to a more specific dataset (i.e. SmallNORB/Stanford Dogs, etc.). Are there any canonical datasets that are used to compare benchmarks around papers, or is selecting a set of datasets like the ones mentioned above appropriate?

&amp;#x200B;",0,10
182,2019-2-22,2019,2,22,12,atcbr3,k-fold cross validation: Value of k,https://www.reddit.com/r/deeplearning/comments/atcbr3/kfold_cross_validation_value_of_k/,sud8233,1550805118,"During the training using k-fold cross validation is preferable over residual based training. With the computational point of view, disadvantage is k-times training starts from scratch. If a CNN network is being trained, does this scratch means the weights from previous iteration during cross validation has to be reset? If it is not being reset, for higher value of k the model will get over-trained. Is there any standard with respect to the number of samples in the data for considering the value of k during cross validation based training?",1,5
183,2019-2-22,2019,2,22,14,atdiy8,[Q] Ever tried to optimise Pearson correlation using DL?,https://www.reddit.com/r/deeplearning/comments/atdiy8/q_ever_tried_to_optimise_pearson_correlation/,pk12_,1550812803,"I know we can optimise our network to maximise classification accuracy or reduce MAE for regression.

But does anyone have experience of maximising Pearson correlation? If so, do you have any tips?",10,1
184,2019-2-22,2019,2,22,17,atf1ke,Deploying a Keras Deep Learning Model as a Web Application in Python,https://www.reddit.com/r/deeplearning/comments/atf1ke/deploying_a_keras_deep_learning_model_as_a_web/,AbbeyEg,1550823842,,0,24
185,2019-2-23,2019,2,23,1,atjddr,Find patterns combining images and bios data,https://www.reddit.com/r/deeplearning/comments/atjddr/find_patterns_combining_images_and_bios_data/,Aceconhielo,1550851909,"Hello everyone,

&amp;#x200B;

I was wondering if is it possible combining images and some ""bios"" data for findding patterns. For example, if I want to know if a image is a cat or dog and I have:

1. Enough image data for train my model
2. Enough ""bios"" data like:
   1. *size of the animal*
   2. *size of the tail*
   3. *weight*
   4. height

&amp;#x200B;

Thanks!",0,1
186,2019-2-23,2019,2,23,1,atjmuw,Deep Learning: Alchemy or Science? Livestream @ IAS,https://www.reddit.com/r/deeplearning/comments/atjmuw/deep_learning_alchemy_or_science_livestream_ias/,throwaway__xj9,1550853252,,0,3
187,2019-2-23,2019,2,23,4,atlu03,[Q] What tensorflow version to install?,https://www.reddit.com/r/deeplearning/comments/atlu03/q_what_tensorflow_version_to_install/,kkbrennm,1550864330,"Hello everyone, 

&amp;#x200B;

I am implementing MASK\_R-CNN architecture on Python and I am about to start downloading all of the packages and libraries. I don't have a GPU unit to perfom all of the computations so I am planning on using Amazon Webservices to train my images. Should I install tensorflow on my computer GPU version? Or tensorflow CPU. 

&amp;#x200B;

Many thanks for the help!",2,0
188,2019-2-23,2019,2,23,4,atlzcx,Yann LeCun Cake Analogy 2.0,https://www.reddit.com/r/deeplearning/comments/atlzcx/yann_lecun_cake_analogy_20/,Yuqing7,1550865135,,0,20
189,2019-2-23,2019,2,23,16,att20k,Train the model after each item evaluation,https://www.reddit.com/r/deeplearning/comments/att20k/train_the_model_after_each_item_evaluation/,suraty,1550908643,"Hello,

My dataset is collected along minutes of days. I used 3 layers convolutional network to train the model for predicting the next 5 minutes data when it takes 10 minutes previous steps.

 The model building in Keras:

    model = models.Sequential() 
    model.add(Conv2D(256,(3, 3),
                      activation='relu',
                      input_shape=(236,20,1), padding='same')) 
    model.add(MaxPooling2D((2, 2)))  
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) 
    model.add(MaxPooling2D((2, 2)))  
    model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) 
    model.add(MaxPooling2D((2,2)))  
    model.add(Flatten()) 
    model.add(Dense(1180))  
    model.summary()

The data is split and first 70% of data is used as the train set and the next 30% for the test set. It fits on the first 70% and evaluates on the next 30%.  

X is 10 minutes data and Y is its 5 minutes later, respectively.

    model.fit(train_x, train_y, batch_size=batch_size,
                      epochs=epochs, verbose=2,
                      callbacks=early_stopping,
                     validation_data=(val_x, val_y))
    model.evaluate(testx, testy)

To the reason of strong relation to the recent data steps, Is it possible to train the model after each item evaluation?

I mean this iteration :  test one item ---&gt; train it and update weights ---&gt; test one another item ---&gt; train and update weights ----&gt; ...

How can I do it while test items evaluate altogether?

&amp;#x200B;

Thank you very much",6,6
190,2019-2-23,2019,2,23,17,attgv5,Handwritten text recognition,https://www.reddit.com/r/deeplearning/comments/attgv5/handwritten_text_recognition/,ImranAl5,1550912166,,1,0
191,2019-2-23,2019,2,23,18,atttep,my capstone project,https://www.reddit.com/r/deeplearning/comments/atttep/my_capstone_project/,karanbangia14,1550915151,"Hey  i am working on a project where in i want to create a prototype on a microcontroller that will be attached on a buggy robot with a camera to detect road traffic signs and alert the driver on the upcoming signs i trained my model on GTSRB (german road sign dataset) and got pretty hogh accuracy with 42 different signsnow i want to do object detection on road signthats my first doubtthen can rasberry pi do the image processing,detection,classification  
?? and lastly how to proceed form herei used pretrained resnet architecture and now how to deploy it on rasberry or any other microcontroller???  
thank you",0,2
192,2019-2-23,2019,2,23,20,atun0q,Convolutional Neural Network Tutorial Explanation 1,https://www.reddit.com/r/deeplearning/comments/atun0q/convolutional_neural_network_tutorial_explanation/,DevTechRetopall,1550921954,,0,4
193,2019-2-23,2019,2,23,22,atvnei,What is the meaning of latent space?,https://www.reddit.com/r/deeplearning/comments/atvnei/what_is_the_meaning_of_latent_space/,ariyanhasan,1550929534,,7,14
194,2019-2-23,2019,2,23,23,atvt3f,"In a ConvNet, what does the whole(conv layer, filters, pooling etc.)thing is trying to achieve? My only intuition is the whole setup is trying to lower the input's complexity to make the whole input trainable. Is that correct? I didn't find sources that explains this.",https://www.reddit.com/r/deeplearning/comments/atvt3f/in_a_convnet_what_does_the_wholeconv_layer/,worthyNull,1550930639,"My intuition is the following:

An input instance (i.e. a car image) has a lot of excessive information(pixels) that we actually don't care about, and the more pixels we have the more parameters we get which makes it cumbersome to deal with and train upon. So we try to reduce the complexity of the image and make it less in size (pooling), we might as well amplify certain set of pixels that in unison create a pattern (Filters' job: edges, corners etc..) and make them more noticeable. 

Did I get it right? There is a ton of information about how to use this library or that library or that just merely scratch the surface and doesn't explain the intuition behind it. I'm confused and I don't trust my intuition in this topic yet.",5,1
195,2019-2-23,2019,2,23,23,atvyyv,Scene Preservation for Image Caption Retrieval,https://www.reddit.com/r/deeplearning/comments/atvyyv/scene_preservation_for_image_caption_retrieval/,kamranjanjua,1550931827,"I have been working on scene understanding for some time now. The major goal is to be able to learn that an image is semantically related to text descriptions. However, when in the wild semantics are explored, the results suffer due to severe restrictions by evaluation metric used at the inference stage. I have been thinking if along with learning semantics between images and sentences, one can learn to preserve scene structure in general and the leverage that to further learn specific scenes accordingly. For example performing coarse scene understanding at stage 1 and then moving towards fine grained semantic mapping in accordance to the sentences explaining that scene. However, the issue is that this would require two networks one which has learned all generic scenes as a scene classification i.e. multi class classification network and then once the mapping has been learned, the knowledge of first network is distilled/passed onto the student network before making a decision if the image and sentence match semantically. What do you guys think of the problem? 
I have solved the issue of avoiding separate networks for each modality by mapping the sentences to images [1,2] and then just use class level supervision to push and pull similar classes nearer to each other and divergent ones apart. [3]

[1] https://www.researchgate.net/profile/Shah_Nawaz14/publication/327306576_Semantic_Text_Encoding_for_Text_Classification_using_Convolutional_Neural_Networks/links/5b87ab8f92851c1e123b3fd7/Semantic-Text-Encoding-for-Text-Classification-using-Convolutional-Neural-Networks.pdf
[2] https://arxiv.org/pdf/1810.02001
[3] https://arxiv.org/pdf/1807.08512",0,1
196,2019-2-24,2019,2,24,0,atwg88,Applied Deep Learning with PyTorch - Full Course,https://www.reddit.com/r/deeplearning/comments/atwg88/applied_deep_learning_with_pytorch_full_course/,DavisTL,1550935058,[removed],0,1
197,2019-2-24,2019,2,24,0,atwj1j,RTX 2070 deep learning rig,https://www.reddit.com/r/deeplearning/comments/atwj1j/rtx_2070_deep_learning_rig/,shahrukhx01,1550935575,"I'm trying to build a RTX 2070 based desktop with 32 GB ram, all parts info is in the link.
https://pcpartpicker.com/list/RF6mcY


Would appreciate a feedback since its my first build. I don't know much about the intricacies of custom builds. ",5,7
198,2019-2-24,2019,2,24,4,atyvi5,What my first Silver Medal taught me about Text Classification and Kaggle in general?,https://www.reddit.com/r/deeplearning/comments/atyvi5/what_my_first_silver_medal_taught_me_about_text/,kiser_soze,1550949080,,3,8
199,2019-2-24,2019,2,24,14,au4vsp,Is there a dataset for Captioning of Faces?,https://www.reddit.com/r/deeplearning/comments/au4vsp/is_there_a_dataset_for_captioning_of_faces/,ThreeForElvenKings,1550986595,"I need a dataset that describes facial features. For example: 'Male, thick moustache, broad face, ...' etc",4,6
200,2019-2-24,2019,2,24,22,au8455,Masters in CS Saarland,https://www.reddit.com/r/deeplearning/comments/au8455/masters_in_cs_saarland/,sohaib_01,1551016285,"Is anyone doing a Masters degree in Computer Science from Saarland University, Germany? ",1,1
201,2019-2-24,2019,2,24,23,au88ei,New Perspectives on Statistical Distributions and Deep Learning,https://www.reddit.com/r/deeplearning/comments/au88ei/new_perspectives_on_statistical_distributions_and/,psangrene,1551017147,,0,18
202,2019-2-25,2019,2,25,0,au95yk,How to Become a Data Scientist | Mark Gacoka,https://www.reddit.com/r/deeplearning/comments/au95yk/how_to_become_a_data_scientist_mark_gacoka/,SilentDifficulty,1551023498,,3,1
203,2019-2-25,2019,2,25,1,au9i1h,After Reading Goodfellow's book.,https://www.reddit.com/r/deeplearning/comments/au9i1h/after_reading_goodfellows_book/,turtle_13,1551025571,Are there any math intensive books on deep learning that I should refer?,7,5
204,2019-2-25,2019,2,25,3,aub0eu,BodyPix Google,https://www.reddit.com/r/deeplearning/comments/aub0eu/bodypix_google/,cmillionaire9,1551033911,,0,0
205,2019-2-25,2019,2,25,3,aub1dx,This algorithm decodes rat squeaks and could revolutionize animal research | Verge Science,https://www.reddit.com/r/deeplearning/comments/aub1dx/this_algorithm_decodes_rat_squeaks_and_could/,abhishekchakraborty,1551034055,,3,43
206,2019-2-25,2019,2,25,7,audkux,"Call for Workshop Papers &amp; Prize Challenge Participation ($60, 000 cash prize)",https://www.reddit.com/r/deeplearning/comments/audkux/call_for_workshop_papers_prize_challenge/,yyvettey,1551047986,"**UG2+: Bridging the Gap between Computational Photography and Visual Recognition**  
The 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2019)  
Long Beach, CA, USA, June 16th-21th, 2019  
**Website**:[http://www.ug2challenge.org](http://www.ug2challenge.org/)   


=================  


**Topic Description:**

What is the current state-of-the-art for image restoration and enhancement applied to degraded images acquired under less than ideal circumstances? Can the application of such algorithms as a pre-processing stepimprove image interpretability for automatic visual recognition? Continuing the success of the1st UG2 Prize Challenge workshopheld at CVPR 2018, we significantly expand our workshop scope for thisyear, to provide an integrated forumfor researchers to review the recent progress of handling various adverse visual conditions in real-world scenes, in robust, effective and task-oriented ways. Beyond the human vision-driven restorations, we also extend particular attentionto the degradation models and the related inverse recovery processes that may benefit successive machine vision tasks. We embrace the most advanced deeplearning systems, but are still open to classical physically grounded models,as well as any well-motivated combination of the two streams. The workshop will consist of four invited talks, together with peer-reviewedregular papers (oral and poster), and talks associated with winning prize challenge contributions.Original high-quality contributions are solicited on the following topics:  
 Novel algorithms for robust object detection, segmentation or recognition on outdoor mobility platforms, such as UAVs, gliders, autonomous cars, outdoor robots, etc.  
 Novel algorithms for robust visual understanding in the presence of one or more real-world adverse conditions, such as haze, rain, snow, hail, dust, underwater, low-illumination, low resolution, etc.  
 Novel algorithms for dehazing, deraining, light enhancement, or enhancing other real-world adverse conditions  
 The potential models and theories for explaining, quantifying, and optimizing the mutual influence between the low-level computational photography (image reconstruction, restoration, or enhancement) tasks andvarious high-levelcomputer vision tasks.  
 Novel physically grounded and/or explanatory models, for the underlying degradation and recovery processes, of real-world images going through complicated adverse visual conditions.  
 Novel evaluation methods and metrics for image restoration and enhancement algorithms, with a particular emphasis on no-reference metrics, since for most real outdoor images with adverse visual conditions it ishard to obtain anyclean ground truth to compare with.  


**Submission Instructions:**All submitted work will be assessed based on their relevance to workshop theme, novelty, technical quality, clarity, and reproducibility. For each accepted submission, at least one author mustattend theworkshopand present the paper. All submissions will follow standard CVPR format requirements, and will be double-blind peer-reviewed. Accepted papers will be presented at the poster session, with selectedpapers also being presentedin an oralsession. All accepted papers will be published by the CVPR in the workshop proceedings.  


**Best paper awards (a total of $1,000)**will be given to the highest-quality original submission(s).  
 

=================  


**Challenge Description:**  
We will announce two challenges built on our collected large-scale benchmarks. The teams will be ranked in terms of testing set accuracy. All final winners will be required to**open-source their code**. Winning teams willalso be invited tosubmit papers to the workshop to describe their methods.  
The organizers acknowledge the generous sponsorship from**IARPA, NEC Labs, Walmart, Kuaishou,Meitu, andBrain-Inspired Technology**, leading to a total of**$60, 000 cash prize**for challenge winners. It isstructured as two challenges,divided further into five sub-challenge tracks.  


**Challenge 1: Video Object Classification and Detection from Unconstrained Mobility Platforms**  
It consists of two sub-challenges: (1.1) restoration and enhancement to improve UAV-based object detection; and (1.2) restoration and enhancement to improve UAV-based classification of objects in videos.  


**Challenge 2: Object Detection in Poor Visibility Environments**  
It consists of three sub-challenges: (2.1) (Semi-)supervised object detection in the haze; (2.2) (Semi-)supervised face detection in the low light condition; and (2.3) Zero-shot object detection with raindrop occlusions  
More challenge and dataset details could be found at the website.  


=================  


**Important Dates:**1. Paper Submission  
May 1, 2019: Paper submission deadline  
May 10, 2019: Paper decision notification  
May 17, 2019: Paper camera ready  


2. Challenge Participation:  
January 31, 2019: Development kit and registration made available  
March 15 - April 15, 2019: Dry run period  
April 1, 2019: Registration deadline  
May 1, 2019: Challenge submission deadline  
May 20, 2019: Challenge results will be released  
June 18, 2019: Most successful and innovative teams present at CVPR 2019 workshop  


=================  


**Organization Committee:**  
\-   **Walter** **Scheirer**,Assistant Professor, Notre Dame University, USA  
\-   **Zhangyang** **(Atlas)** **Wang**, Assistant Professor, Texas A&amp;M University, USA  
\-   **Jiaying** **Liu**, Associate Professor, Peking University, China  
\-   **Wenqi** **Ren**,Assistant Professor,Chinese Academy of Sciences, China  
\-   **Wenhan** **Yang**, Postdoc Researcher, City University of Hong Kong, Hong Kong, China  
\-   **Kevin** **Bowyer**, Schubmehl-Prein Family Professor, Notre Dame University, USA  
\-   **Thomas** **S.** **Huang**, Maybelle Leland Swanlund Endowed Chair Emeritus, University of Illinois at Urbana-Champaign, USA  
\-   **Sreya** **Banerjee**,Graduate Student,Notre Dame University, USA  
\-   **Rosaura** **Vidal-Mata**,Graduate Student, Notre Dame University, USA  
\-   **Ye Yuan**,Graduate Student,Texas A&amp;M University, USA  


=================  
For further questions please contact: Walter Scheirer[walter.scheirer@nd.edu](mailto:walter.scheirer@nd.edu), Zhangyang (Atlas) Wang[atlaswang@tamu.edu](mailto:atlaswang@tamu.edu)",0,5
207,2019-2-25,2019,2,25,16,auins2,How to make Obama? A walkthrough,https://www.reddit.com/r/deeplearning/comments/auins2/how_to_make_obama_a_walkthrough/,jackso2000,1551080991,,1,0
208,2019-2-26,2019,2,26,1,aun20n,SenseTime Trains ImageNet/AlexNet In Record 1.5 minutes,https://www.reddit.com/r/deeplearning/comments/aun20n/sensetime_trains_imagenetalexnet_in_record_15/,Yuqing7,1551111991,,1,12
209,2019-2-26,2019,2,26,11,autskz,Deep Learning Prerequisites: The Numpy Stack in Python,https://www.reddit.com/r/deeplearning/comments/autskz/deep_learning_prerequisites_the_numpy_stack_in/,KendyJa,1551147982,,0,1
210,2019-2-26,2019,2,26,11,autv42,Deep Learning Prerequisites: The Numpy Stack in Python,https://www.reddit.com/r/deeplearning/comments/autv42/deep_learning_prerequisites_the_numpy_stack_in/,MarkOliver908,1551148381,,3,19
211,2019-2-26,2019,2,26,13,auv2eq,[Book] Generative Adversarial Networks Projects using Keras and Tensorflow,https://www.reddit.com/r/deeplearning/comments/auv2eq/book_generative_adversarial_networks_projects/,kailashahirwar12,1551155670,,5,14
212,2019-2-26,2019,2,26,14,auvlgy,Is wavenet architecture unsuitable for multivariate input data?,https://www.reddit.com/r/deeplearning/comments/auvlgy/is_wavenet_architecture_unsuitable_for/,Cyclonedx,1551158944,"I tried to implement regression and classification using Wavenet architecture on some 30 input signals.

The results were quite poor. Around 70% classification accuracy and regression didnt fit very well.

The architecture used 7 dilation layers to reference 256 time steps in the past to predict output at 200 time steps in the future. I also added some skip connections via residual blocks but the results didnt improve.

I cant find many implementations of this kind of architecture online which makes me believe its not very good for multivariate data. Any of you have any experiences you can share?
",0,1
213,2019-2-26,2019,2,26,16,auwq8r,Great explanation on what Machine Learning really is!,https://www.reddit.com/r/deeplearning/comments/auwq8r/great_explanation_on_what_machine_learning_really/,SilentDifficulty,1551166786,,0,1
214,2019-2-26,2019,2,26,16,auwqtq,Kickstarter - Artificial Intelligence and Machine Learning E-Degree,https://www.reddit.com/r/deeplearning/comments/auwqtq/kickstarter_artificial_intelligence_and_machine/,KiranKiller,1551166906,,2,0
215,2019-2-26,2019,2,26,17,auxb0q,One shot learning,https://www.reddit.com/r/deeplearning/comments/auxb0q/one_shot_learning/,tetuaa,1551171393,I wanna learn single shot pearning for image classification.I have implemented CNN using keras.and i am familiar with the theory.Help me with the prerequisites for one shot learning i.e. is there any mathematical theory i ned to know before starting one shot learning. I am a sophomore in mechanical engineering so this might help u understand my mathematical knowledge. Also suggest me some good sources to learn these things,2,1
216,2019-2-27,2019,2,27,0,av0ynn,3 reasons to add deep learning to your time series toolkit,https://www.reddit.com/r/deeplearning/comments/av0ynn/3_reasons_to_add_deep_learning_to_your_time/,frlazzeri,1551196640,"The ability to accurately forecast a sequence into the future is critical in many industries: finance, supply chain, and manufacturing are just a few examples. Classical time series techniques have served this task for decades, but now deep learning methodssimilar to those used in computer vision and automatic translationhave the potential to revolutionize time series forecasting as well.

Due to their applicability to many real-life problemssuch as fraud detection, spam email filtering, finance, and medical diagnosisand their ability to produce actionable results, deep learning neural networks have gained a lot of attention in recent years. Generally, deep learning methods have been developed and applied to univariate time series forecasting scenarios, where the time series consists of single observations recorded sequentially over equal time increments. For this reason, they have often performed worse than nave and classical forecasting methods, such as exponential smoothing (ETS) and autoregressive integrated moving average (ARIMA). This has led to a general misconception that deep learning models are inefficient in time series forecasting scenarios, and many data scientists wonder whether its really necessary to add another class of methodssuch as convolutional neural networks or recurrent neural networksto their time series toolkit.

In this post, I'll discuss some of the practical reasons why data scientists may still want to think about deep learning when they build time series forecasting solutions: 

[https://www.oreilly.com/ideas/3-reasons-to-add-deep-learning-to-your-time-series-toolkit](https://www.oreilly.com/ideas/3-reasons-to-add-deep-learning-to-your-time-series-toolkit) ",2,15
217,2019-2-27,2019,2,27,2,av24nx,On Lesson 1 - Image Recognition from fast.ai and need help to make an Emotion Detector.,https://www.reddit.com/r/deeplearning/comments/av24nx/on_lesson_1_image_recognition_from_fastai_and/,bidyutchanda108,1551202595,"First time here. Just started this course yesterday and had a question.

I have seen many a times on Reddit and other websites that people make use of CNNs and make emotion detectors which take live photos via the webcam and predict the emotions?

&amp;#x200B;

Sorry for being naive as this is my first DL course. But my vague idea of doing this is same like I had done some ML problems before.

1. Download a face emotion dataset from Google.
2. Train a CNN like this lesson made me learn.
3. \*\*Pass the webcame images into this and predict results out.\*\*

&amp;#x200B;

This is just an idea. Currently I am stuck at the third step. There was a thing called \*\*validation set\*\* which, as was mentioned, \_\*\*the algorithm does not see\*\*\_. Is that the set where I pass these webcam images to be predicited results upon?

&amp;#x200B;

I really want to work upon this. If anyone can help, please reply to this. Heard great things about this subreddit. :D",1,0
218,2019-2-27,2019,2,27,3,av2vmt,"After Mastering Go and StarCraft, DeepMind Takes on Soccer",https://www.reddit.com/r/deeplearning/comments/av2vmt/after_mastering_go_and_starcraft_deepmind_takes/,gwen0927,1551206474,,5,5
219,2019-2-27,2019,2,27,6,av4kgc,PhD program in Machine/ Deep Learning,https://www.reddit.com/r/deeplearning/comments/av4kgc/phd_program_in_machine_deep_learning/,eracro,1551215146,"Hi everyone, 

&amp;#x200B;

I just finished my master degree in engineering in France and I am now doing a double degree in data analytics at Boston University. I will be graduated in September and after that I would really like to do a PhD program in Machine Learning / Deep Learning but since my school in France and college in Boston are not really implicated in Deep Learning research I am struggling a bit to find information. 

&amp;#x200B;

For 2 years now I have been passionated for Machine Learning, I have done some research for organizations using Deep Learning for Computer Vision and different Machine Learning for forecasting on numeric datas, a few Kaggle challenges and some MOOCS ( FastAI, Machine learning and Deep Learning Specialization from Andrew Ng and Computer Vision from Aaron Bobick ). However, I want to learn more, and I think doing a PhD in deep learning could really help me gain some knowledge. I am not afraid to do something new and I could even take a MOOC along with classes before starting the program. 

&amp;#x200B;

\- Do you agree with my vision of the PhD or am I missing something ? 

&amp;#x200B;

\- What are for you the most promising/ interesting PhD subjects in Deep Learning now ? 

&amp;#x200B;

\- What advice would you give me to find a PhD program ? ( I could do it in USA but also in other countries like France or Canada ) 

&amp;#x200B;

Thank you so much !

&amp;#x200B;

Btw : If you have a machine learning or computer vision project that you want to share send me a message, I love to talk about that kind of stuff and we could maybe do a working group",8,8
220,2019-2-27,2019,2,27,10,av7o4g,Black and white image colorization with OpenCV and Deep Learning Demo,https://www.reddit.com/r/deeplearning/comments/av7o4g/black_and_white_image_colorization_with_opencv/,codemaker1,1551232703,,2,18
221,2019-2-27,2019,2,27,14,av9jog,Can someone suggest any existing deep learning model that can classifies gore and violent content in images or a dataset of such content for training my own model?,https://www.reddit.com/r/deeplearning/comments/av9jog/can_someone_suggest_any_existing_deep_learning/,shobhit18,1551244268,,0,2
222,2019-2-27,2019,2,27,20,avcjo4,My Thoughts on OpenAI Not Releasing Weights,https://www.reddit.com/r/deeplearning/comments/avcjo4/my_thoughts_on_openai_not_releasing_weights/,ericnyamu,1551267465,,1,7
223,2019-2-27,2019,2,27,23,avds4b,Looking For An Enterprise Ready Xeon+RTX PreBuilt,https://www.reddit.com/r/deeplearning/comments/avds4b/looking_for_an_enterprise_ready_xeonrtx_prebuilt/,zachstechturf,1551276037,"Hello all,

I'm a sysadmin for my company and our developers are starting to explore some areas of deep learning. Right now we are currently building ""cookie cutter"" HP workstations with a few upgrades and a budget Quadro, but I want a better system for my deep learning users.

Is there a common prebuilt that other people in my situation are buying right now that include both a Xeon processor and an RTX graphics card, preferably a 2080 or 2080Ti? I don't want Threadripper as we've experimented with that and I still just don't think it's enterprise ready yet.

Also, yes, we are perfectly capable of building our own systems. But at our temp the time taken to pick out individual parts, assemble, test, etc just isn't worth it. I'd certainly be OK with buying a workstation that's ready to go for an RTX card and install that myself, but I'm just trying to avoid spending too much time on the build.

Any help would be great, thanks!",1,1
224,2019-2-28,2019,2,28,1,avfatr,Looking to dip my toes into ML and parallel programming. Could use recommendation on GPU purchase.,https://www.reddit.com/r/deeplearning/comments/avfatr/looking_to_dip_my_toes_into_ml_and_parallel/,Gorthok_EU,1551284850,"As the title states, I would like to get into both parallel programming and machine learning. I have a few years experience with programming, mainly in game development.

I am about to perform a long overdue upgrade on my desktop (i5 2400 / Radeon HD 7790), and was hoping to find some advice here.

Does the 2060 justify the higher price than 1660ti when it comes to ML? In my country the price is $360 for 1660ti and $445 for the 2060. 

Is RX580 completely out of the question? It costs about $295 here. Being able to use both CUDA and OpenCL on an Nvidia card sounds nice.

As mentioned, my goal is for this system to allow me to learn the ropes of parallel programming and ML.",11,8
225,2019-2-28,2019,2,28,2,avg4et,Self Driving Car Simulation Unity 3D using Genetic Algorithms and Neural...,https://www.reddit.com/r/deeplearning/comments/avg4et/self_driving_car_simulation_unity_3d_using/,DevTechRetopall,1551289342,,2,2
226,2019-2-28,2019,2,28,5,avi2rl,From Faces to Kitties to Apartments: GAN Fakes the World,https://www.reddit.com/r/deeplearning/comments/avi2rl/from_faces_to_kitties_to_apartments_gan_fakes_the/,Yuqing7,1551299693,,2,16
227,2019-2-28,2019,2,28,6,avipto,Breast cancer classification with Keras and Deep Learning,https://www.reddit.com/r/deeplearning/comments/avipto/breast_cancer_classification_with_keras_and_deep/,codemaker1,1551303097,,0,0
228,2019-2-28,2019,2,28,15,avnyi7,Looking for Edge device with camera,https://www.reddit.com/r/deeplearning/comments/avnyi7/looking_for_edge_device_with_camera/,sumitg,1551336156,"I am looking for an edge / inference board like a Raspberry Pi with a small FPGA or small GPU, and a low res camera.   Something inexpensive (\~$200-300).   

anyone got any suggestions?

&amp;#x200B;",8,1
229,2019-2-28,2019,2,28,17,avoqsb,Read how the recent advancements in AI can solve the world's problems,https://www.reddit.com/r/deeplearning/comments/avoqsb/read_how_the_recent_advancements_in_ai_can_solve/,georgedatascience,1551342338,,0,2
230,2019-2-28,2019,2,28,19,avpngi,"Conditional Density Estimation for Python with Mixture Density Network, Kernel Mixture Network, various parametric/semi-parametric estimators, data simulators and evaluation functions",https://www.reddit.com/r/deeplearning/comments/avpngi/conditional_density_estimation_for_python_with/,whiletrue2,1551349900,,0,6
231,2019-2-28,2019,2,28,20,avpwb7,Configuring a server for AI application based on tensorflow,https://www.reddit.com/r/deeplearning/comments/avpwb7/configuring_a_server_for_ai_application_based_on/,fralbalbero,1551351912,"I want to deploy a Tensorflow model on the web. What is the best configuration both in terms of software/frameworks (Flask, Cherrypy/Apache/Nodejs+Tensorflowjs etc) and hardware, in relations to the number of requests per second?",1,3
232,2019-2-28,2019,2,28,20,avq1gc,"Implementations of 7 research papers on Seq2Seq learning using Pytorch (Sketch generation, handwriting synthesis, variational autoencoders, machine translation, etc.)",https://www.reddit.com/r/deeplearning/comments/avq1gc/implementations_of_7_research_papers_on_seq2seq/,bhatt_gaurav,1551353080,,0,25
233,2019-2-28,2019,2,28,22,avqv7u,How to setup Docker and Nvidia-Docker 2.0 on Ubuntu 18.04,https://www.reddit.com/r/deeplearning/comments/avqv7u/how_to_setup_docker_and_nvidiadocker_20_on_ubuntu/,Mayalittlepony,1551358846,"Working on Deep Learning applications or computation that benefits from GPUs? There's no doubt you'll need Docker for that.   


Here's a helpful step-by-step guide to install Docker and Nvidia-docker: [https://cnvrg.io/how-to-setup-docker-and-nvidia-docker-2-0-on-ubuntu-18-04/](https://cnvrg.io/how-to-setup-docker-and-nvidia-docker-2-0-on-ubuntu-18-04/) ",2,3
234,2019-2-28,2019,2,28,22,avr34m,Pose Detection comparison : wrnchAI vs OpenPose,https://www.reddit.com/r/deeplearning/comments/avr34m/pose_detection_comparison_wrnchai_vs_openpose/,spmallick,1551360229,"Today's post is for all the geeks who are interested in Human Pose Estimation!

LearnOpenCV compares two really good Human Pose Estimation models -- OpenPose vs wrnchAI.

[https://www.learnopencv.com/pose-detection-comparison-wrnchai-vs-openpose/](https://www.learnopencv.com/pose-detection-comparison-wrnchai-vs-openpose/)

wrnch is backed by Mark Cuban and has been featured in keynote addresses by NVIDIA and Intel.

Three important differences  
1. wrnchAI and OpenPose are similar in accuracy, but wrnchAI is blazingly fast.  
2. OpenPose license prevents use in sports applications, but wrnchAI has no such restrictions.  
3. OpenPose is opensource ( even though you have to pay a licensing fee for commercial use ).

Disclosure: We received a fee from wrnch for producing a report that compared wrnchAI to OpenPose. The report was independently produced without interference or oversight by wrnch.

Do like, comment your opinions and tag your friends to get a debate going!

[\#AI](https://www.facebook.com/hashtag/ai?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARDINtjDPtDC8vghK2vHU0TBxjF2-jXv2tM5VZjWGE6Z3BthiSA6c8-PjMCSrsdxMwz7zyDMIvcDX_YdPkGAKfNcFyiLM6Wlky0sH0oZZ9vRrZjWV5FkR_uGn8e9_Ew2WO1EtKC8rlye81aQVRqaMHK4w-85UGm60uK9XrsnLAZzFA8_X-MdgZvbK-cx4OlKoZRgTTwjlB0flwxh1Z0McNSgYQilj9mYPkkcF42Jo8kemGzPaSAYcubhQ4oXjxy9L-3aMWvzN4mdHVaVh2IgL3IpM2w8c-4QnItsVd6Tz1TALwsT0a34sAqLxPYQRG7cVtDLTc6N5_S3Z_IjFFJxjKKaPm7rmg7IyFrP&amp;__tn__=%2ANK-R) [\#MachineLearning](https://www.facebook.com/hashtag/machinelearning?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARDINtjDPtDC8vghK2vHU0TBxjF2-jXv2tM5VZjWGE6Z3BthiSA6c8-PjMCSrsdxMwz7zyDMIvcDX_YdPkGAKfNcFyiLM6Wlky0sH0oZZ9vRrZjWV5FkR_uGn8e9_Ew2WO1EtKC8rlye81aQVRqaMHK4w-85UGm60uK9XrsnLAZzFA8_X-MdgZvbK-cx4OlKoZRgTTwjlB0flwxh1Z0McNSgYQilj9mYPkkcF42Jo8kemGzPaSAYcubhQ4oXjxy9L-3aMWvzN4mdHVaVh2IgL3IpM2w8c-4QnItsVd6Tz1TALwsT0a34sAqLxPYQRG7cVtDLTc6N5_S3Z_IjFFJxjKKaPm7rmg7IyFrP&amp;__tn__=%2ANK-R) [\#DeepLearning](https://www.facebook.com/hashtag/deeplearning?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARDINtjDPtDC8vghK2vHU0TBxjF2-jXv2tM5VZjWGE6Z3BthiSA6c8-PjMCSrsdxMwz7zyDMIvcDX_YdPkGAKfNcFyiLM6Wlky0sH0oZZ9vRrZjWV5FkR_uGn8e9_Ew2WO1EtKC8rlye81aQVRqaMHK4w-85UGm60uK9XrsnLAZzFA8_X-MdgZvbK-cx4OlKoZRgTTwjlB0flwxh1Z0McNSgYQilj9mYPkkcF42Jo8kemGzPaSAYcubhQ4oXjxy9L-3aMWvzN4mdHVaVh2IgL3IpM2w8c-4QnItsVd6Tz1TALwsT0a34sAqLxPYQRG7cVtDLTc6N5_S3Z_IjFFJxjKKaPm7rmg7IyFrP&amp;__tn__=%2ANK-R) [\#ComputerVision](https://www.facebook.com/hashtag/computervision?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARDINtjDPtDC8vghK2vHU0TBxjF2-jXv2tM5VZjWGE6Z3BthiSA6c8-PjMCSrsdxMwz7zyDMIvcDX_YdPkGAKfNcFyiLM6Wlky0sH0oZZ9vRrZjWV5FkR_uGn8e9_Ew2WO1EtKC8rlye81aQVRqaMHK4w-85UGm60uK9XrsnLAZzFA8_X-MdgZvbK-cx4OlKoZRgTTwjlB0flwxh1Z0McNSgYQilj9mYPkkcF42Jo8kemGzPaSAYcubhQ4oXjxy9L-3aMWvzN4mdHVaVh2IgL3IpM2w8c-4QnItsVd6Tz1TALwsT0a34sAqLxPYQRG7cVtDLTc6N5_S3Z_IjFFJxjKKaPm7rmg7IyFrP&amp;__tn__=%2ANK-R) [\#wrnchAI](https://www.facebook.com/hashtag/wrnchai?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARDINtjDPtDC8vghK2vHU0TBxjF2-jXv2tM5VZjWGE6Z3BthiSA6c8-PjMCSrsdxMwz7zyDMIvcDX_YdPkGAKfNcFyiLM6Wlky0sH0oZZ9vRrZjWV5FkR_uGn8e9_Ew2WO1EtKC8rlye81aQVRqaMHK4w-85UGm60uK9XrsnLAZzFA8_X-MdgZvbK-cx4OlKoZRgTTwjlB0flwxh1Z0McNSgYQilj9mYPkkcF42Jo8kemGzPaSAYcubhQ4oXjxy9L-3aMWvzN4mdHVaVh2IgL3IpM2w8c-4QnItsVd6Tz1TALwsT0a34sAqLxPYQRG7cVtDLTc6N5_S3Z_IjFFJxjKKaPm7rmg7IyFrP&amp;__tn__=%2ANK-R)[\#OpenPose](https://www.facebook.com/hashtag/openpose?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARDINtjDPtDC8vghK2vHU0TBxjF2-jXv2tM5VZjWGE6Z3BthiSA6c8-PjMCSrsdxMwz7zyDMIvcDX_YdPkGAKfNcFyiLM6Wlky0sH0oZZ9vRrZjWV5FkR_uGn8e9_Ew2WO1EtKC8rlye81aQVRqaMHK4w-85UGm60uK9XrsnLAZzFA8_X-MdgZvbK-cx4OlKoZRgTTwjlB0flwxh1Z0McNSgYQilj9mYPkkcF42Jo8kemGzPaSAYcubhQ4oXjxy9L-3aMWvzN4mdHVaVh2IgL3IpM2w8c-4QnItsVd6Tz1TALwsT0a34sAqLxPYQRG7cVtDLTc6N5_S3Z_IjFFJxjKKaPm7rmg7IyFrP&amp;__tn__=%2ANK-R) [\#PoseEstimation](https://www.facebook.com/hashtag/poseestimation?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARDINtjDPtDC8vghK2vHU0TBxjF2-jXv2tM5VZjWGE6Z3BthiSA6c8-PjMCSrsdxMwz7zyDMIvcDX_YdPkGAKfNcFyiLM6Wlky0sH0oZZ9vRrZjWV5FkR_uGn8e9_Ew2WO1EtKC8rlye81aQVRqaMHK4w-85UGm60uK9XrsnLAZzFA8_X-MdgZvbK-cx4OlKoZRgTTwjlB0flwxh1Z0McNSgYQilj9mYPkkcF42Jo8kemGzPaSAYcubhQ4oXjxy9L-3aMWvzN4mdHVaVh2IgL3IpM2w8c-4QnItsVd6Tz1TALwsT0a34sAqLxPYQRG7cVtDLTc6N5_S3Z_IjFFJxjKKaPm7rmg7IyFrP&amp;__tn__=%2ANK-R) [\#PoseDetection](https://www.facebook.com/hashtag/posedetection?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARDINtjDPtDC8vghK2vHU0TBxjF2-jXv2tM5VZjWGE6Z3BthiSA6c8-PjMCSrsdxMwz7zyDMIvcDX_YdPkGAKfNcFyiLM6Wlky0sH0oZZ9vRrZjWV5FkR_uGn8e9_Ew2WO1EtKC8rlye81aQVRqaMHK4w-85UGm60uK9XrsnLAZzFA8_X-MdgZvbK-cx4OlKoZRgTTwjlB0flwxh1Z0McNSgYQilj9mYPkkcF42Jo8kemGzPaSAYcubhQ4oXjxy9L-3aMWvzN4mdHVaVh2IgL3IpM2w8c-4QnItsVd6Tz1TALwsT0a34sAqLxPYQRG7cVtDLTc6N5_S3Z_IjFFJxjKKaPm7rmg7IyFrP&amp;__tn__=%2ANK-R)

![video](eeg17dyn8bj21)",1,3
0,2019-3-1,2019,3,1,17,aw2h19,AI Project - Web application for Object Identification,https://www.reddit.com/r/deeplearning/comments/aw2h19/ai_project_web_application_for_object/,nalinee_choudhary,1551428644,"Using Django &amp; Keras we can develop an web application where user can upload any image &amp; website tells what it is. We can use pretrained Keras model in the backend for the same. 

[AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185/) \- this is the link to the project. ",2,4
1,2019-3-1,2019,3,1,18,aw2yyl,Sentiment Analysis with Deep Learning of Netflix Reviews,https://www.reddit.com/r/deeplearning/comments/aw2yyl/sentiment_analysis_with_deep_learning_of_netflix/,ObsidianAge,1551432925,,0,2
2,2019-3-1,2019,3,1,20,aw3ojx,Great Course on Deep Learning,https://www.reddit.com/r/deeplearning/comments/aw3ojx/great_course_on_deep_learning/,Ta-7,1551438662,"[https://skillsmatter.com/courses/652-deep-learning-fundamentals](https://skillsmatter.com/courses/652-deep-learning-fundamentals)

Skills Matter are also sponsoring a free ticket to infiniteconf 2019 [https://skillsmatter.com/conferences/11187-infiniteconf-2019-the-conference-on-big-data-and-ai](https://skillsmatter.com/conferences/11187-infiniteconf-2019-the-conference-on-big-data-and-ai)

their biggest Data Ai conference, if you sign-up to the course. 

&amp;#x200B;

If you are interested let me know as I can get you a employee discount. ",0,0
3,2019-3-1,2019,3,1,20,aw41v8,Deep Neural Networks &amp; Image Captioning  badoo_tech,https://www.reddit.com/r/deeplearning/comments/aw41v8/deep_neural_networks_image_captioning_badoo_tech/,lauram16_hello,1551441428,,0,1
4,2019-3-1,2019,3,1,22,aw4m90,"""Topology of Learning in Artificial Neural Networks"" 21 Feb 2019 article",https://www.reddit.com/r/deeplearning/comments/aw4m90/topology_of_learning_in_artificial_neural/,BrighterAI,1551445220,,4,38
5,2019-3-1,2019,3,1,23,aw5guh,How early is it ok to conclude that your model is overfitting?,https://www.reddit.com/r/deeplearning/comments/aw5guh/how_early_is_it_ok_to_conclude_that_your_model_is/,dchasani,1551450258,"Say you're training a model (transfer learning) which was originally trained on the imagenet dataset (this may be irrelevant).
After how many epochs can you be sure that your model is overfitting and so you should early stop the training so it's not a huge waste of time?

",1,1
6,2019-3-1,2019,3,1,23,aw5o3j,"""Deep Learning for Developers"" with Julien Simon (55min talk from GOTO Amsterdam 2018)",https://www.reddit.com/r/deeplearning/comments/aw5o3j/deep_learning_for_developers_with_julien_simon/,goto-con,1551451407,,1,1
7,2019-3-2,2019,3,2,0,aw6d6v,CNN training in bfloat16,https://www.reddit.com/r/deeplearning/comments/aw6d6v/cnn_training_in_bfloat16/,CArchGuy,1551455322,"Are there any efforts so far for training CNNs end-to-end with bfloat16 format? especially the convolution part, i.e. both multiplication and addition is done in bfloat16. Can this scale to large datasets such ImageNet? Intel has a published white paper about supporting bfloat16 in their next-generation FPGAs, where they claim that accumulating in FP32 format is essential to avoid losing accuracy on an application level. Would people building custom hardware for training have to stick with the FP32 accumulation?",0,1
8,2019-3-2,2019,3,2,0,aw6hid,"Genetic Algorithm Tutorial Full Explanation, Calculations and uses 2019",https://www.reddit.com/r/deeplearning/comments/aw6hid/genetic_algorithm_tutorial_full_explanation/,DevTechRetopall,1551455993,,0,5
9,2019-3-2,2019,3,2,1,aw7228,How can I deploy my image caption model to flask?,https://www.reddit.com/r/deeplearning/comments/aw7228/how_can_i_deploy_my_image_caption_model_to_flask/,Vinceeeent,1551459105,"Hi guys, I have this image-caption model and I want it to deploy in a flask app. All I can see in google is a image classifier but there are no tutorials on image-captioning.

Any ideas/tips would be appreciated. Thanks!",0,1
10,2019-3-2,2019,3,2,4,aw8t1u,Training Object Recognition Model,https://www.reddit.com/r/deeplearning/comments/aw8t1u/training_object_recognition_model/,ashotarzumanyan,1551469180,,0,3
11,2019-3-2,2019,3,2,5,aw90uc,Autonomous Driving Simulation,https://www.reddit.com/r/deeplearning/comments/aw90uc/autonomous_driving_simulation/,DevTechRetopall,1551470408,,3,3
12,2019-3-2,2019,3,2,16,awfcxd,Why do I get different results for a single forward pass when I only change one dimension?,https://www.reddit.com/r/deeplearning/comments/awfcxd/why_do_i_get_different_results_for_a_single/,MasterSama,1551512416,"I tried to implement a very simple RNN step and compare it with Andrew Ng's function to see if I understood everything correcly.  

however, my results differ from his, but all I did was to place batch size in the first dimension rather than in the second! everything else is the same (except the fact that, I had to change the order of multiplication so the right dimensions sit next to eachother.)  

Here is his my function implementation : 

    import numpy as np
    
    def softmax(x): 
            e_x = np.exp(x - np.max(x))
            return e_x / e_x.sum(axis=0)
        
    class RNNClass(object):
        def __init__(self, vocab_size, outputsize, hidden_state_size=100):
            
            np.random.seed(1)
            #our weight size, is determined by hidden_state_size and vocab_size because
            # they are multiplied by input and also hidden_state, which ultimately should 
            # result in the hidden_size 
            # W1 is multiplied by xt which has the shape (batch, vocabsize)
            self.W1 = np.random.randn(vocab_size, hidden_state_size)
            # W2 is multiplied by hidden_state, which has the shape h=(batchsize, hiddensize) 
            # since w1 and w2 are added together, therefore, the dimension of h0.w2 
            # must have the same shape of the result of xt.w1. 
            self.W2 = np.random.randn(hidden_state_size, hidden_state_size)
            # W3 is multiplied by hidden_state, and it should ultimately have the shape of vocabsize
            # h1.w3
            self.W3 = np.random.randn(outputsize, hidden_state_size)
            # should have size of 1
            self.bh = np.random.randn(hidden_state_size)
            # should have size of 1
            self.bo = np.random.randn(outputsize)
            
            self.outputsize = outputsize
            self.hidden_state_size = hidden_state_size
            print(self.W1.shape)
            print(self.W2.shape)
            print(self.W3.shape)
            print(self.bh.shape)
            print(self.bo.shape)
            
        def rnn_cell_foward(self, xt, h0):
            """"""
                Run the forward pass for a single timestep of a vanilla RNN that uses a tanh
                activation function.
                The input data has dimension D(vocabsize), the hidden state has dimension H(HiddenSize), and we use
                a minibatch size of N(Batch_size).
                Inputs:
                - x: Input data for this timestep, of shape (Batch_size, vocabsize_or_basically_input_dim_size).
                - h0: Hidden state from previous timestep, of shape (Batch_size, HiddenSize)
                - W1: Weight matrix for input-to-hidden connections, of shape (vocabsize, HiddenSize)
                - W2: Weight matrix for hidden-to-hidden connections, of shape (HiddenSize, HiddenSize)
                - W3: Weight matrix for hiddent-to-output connections, of shape(vocabsize_or_output_dim_size, hidden_state_size)
                - bh: Biases of shape (HiddenSize,)
                - bo: Biases of shape (vocabsize_or_output_dim_size,)
                
           """"""
            
            h_t = np.tanh(np.dot(xt, self.W1) + np.dot(h0, self.W2) + self.bh)
            o_t = softmax(np.dot( h_t, self.W3.T) + self.bo)
            print('o_t.shape in cell forward: ', o_t.shape)
            print('h_t.shape in cell forward: ', h_t.shape)
            return o_t, h_t
    

and the output is :

    vocabsize=3
    hidden_state_size=5
    outputsize=2
    batch=10
    Xt = np.random.rand(batch, vocabsize)
    h0 = np.zeros(shape=(batch, hidden_state_size))
    
    rnn = RNNClass(vocab_size=vocabsize, outputsize=outputsize, hidden_state_size=hidden_state_size)
    yt_pred,a_next = rnn.rnn_cell_foward(Xt, h0)
    # so the output looks like andrew's result.
    a_next = a_next.transpose(1,0)
    yt_pred = yt_pred.transpose(1,0)
    
    print(""a_next.shape = "", a_next.shape)
    print(""yt_pred.shape = "", yt_pred.shape)
    print(""a_next[4] = "", a_next[4])
    print(""yt_pred[1] ="", yt_pred[1])
    
    

output : 

  

|**a\_next\[4\]** =| \[0.84867458     0.77846452     0.58705883    0.88028079   0.46130119       0.39808808     0.01003178    0.406457   0.41351936       0.9144255 \]|
|:-|:-|
|**a\_next.shape** = | (5, 10) |
|**yt\_pred\[1\]** = |\[0.06592572      0.06621226      0.13315296   0.06556298 0.08856467       0.14952982      0.13894541   0.13843746 0.08882247       0.06484625\] |
|**yt\_pred.shape=**| (2, 10) |

and this is his implementation : 

    def rnn_cell_forward(xt, a_prev, parameters):
        """"""
        Implements a single forward step of the RNN-cell as described in Figure (2)
    
        Arguments:
        xt -- your input data at timestep ""t"", numpy array of shape (n_x, m).
        a_prev -- Hidden state at timestep ""t-1"", numpy array of shape (n_a, m)
        parameters -- python dictionary containing:
                            Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)
                            Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)
                            Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)
                            ba --  Bias, numpy array of shape (n_a, 1)
                            by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)
        Returns:
        a_next -- next hidden state, of shape (n_a, m)
        yt_pred -- prediction at timestep ""t"", numpy array of shape (n_y, m)
        cache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)
        """"""
        
        # Retrieve parameters from ""parameters""
        Wax = parameters[""Wax""]
        Waa = parameters[""Waa""]
        Wya = parameters[""Wya""]
        ba = parameters[""ba""]
        by = parameters[""by""]
        
        ### START CODE HERE ### (2 lines)
        a_next = np.tanh(np.dot(Wax,xt) + np.dot(Waa,a_prev) + ba)
        # compute output of the current cell using the formula given above
        yt_pred = softmax(np.dot(Wya,a_next)+by)   
        ### END CODE HERE ###
        
        # store values you need for backward propagation in cache
        cache = (a_next, a_prev, xt, parameters)
        
        return a_next, yt_pred, cache
    
    np.random.seed(1)
    xt = np.random.randn(3,10)
    a_prev = np.random.randn(5,10)
    Waa = np.random.randn(5,5)
    Wax = np.random.randn(5,3)
    Wya = np.random.randn(2,5)
    ba = np.random.randn(5,1)
    by = np.random.randn(2,1)
    parameters = {""Waa"": Waa, ""Wax"": Wax, ""Wya"": Wya, ""ba"": ba, ""by"": by}
    
    a_next, yt_pred, cache = rnn_cell_forward(xt, a_prev, parameters)

and the output it generates is : 

&amp;#x200B;

|**a\_next\[4\]** =| \[ 0.59584544      0.18141802      0.61311866   0.99808218  0.85016201         0.99980978     -0.18887155   0.99815551  0.6531151          0.82872037\]  |
|:-|:-|
|**a\_next.shape** = | (5, 10) |
|**yt\_pred\[1\]** = | \[ 0.9888161      0.01682021        0.21140899    0.36817467  0.98988387       0.88945212        0.36920224    0.9966312   0.9982559         0.17746526\]|
|**yt\_pred.shape=**| (2, 10) |

As you can see, I also used `np.random.seed(1)` 

but the results are different. I'm puzzled , is  this expected or not? 

Your help is greatly appreciated . 

&amp;#x200B;",0,2
13,2019-3-3,2019,3,3,2,awk6dn,Training I3D model.,https://www.reddit.com/r/deeplearning/comments/awk6dn/training_i3d_model/,crazy_lazy_life,1551548610,"I have a video dataset of ~230 videos, each divided into two classes. All the information with the video title and the corresponding class's is stored in a csv file and the videos are together in the same folder. 
I am having problem with training an I3D network on this video dataset. I tried to do all that was said in the github repo, but their format for the dataset is different. 
Any help or article suggestion is highly appreciated.
Thanks in advance. ",0,6
14,2019-3-3,2019,3,3,6,awms0j,Evaluation Metrics RMSE and MAPE,https://www.reddit.com/r/deeplearning/comments/awms0j/evaluation_metrics_rmse_and_mape/,armod_reddit,1551563083,I wanted to use the metrics RMSE and MAPE to measure prediction using deep learning techniques like LSTM but I couldn't understand how the values of these metrics change for different numbers of samples in the output of the neural network. Do their value change different samples of the output or not?,0,1
15,2019-3-3,2019,3,3,12,awq60t,deeplearning.ai Specialization Progress | Shaik Asad,https://www.reddit.com/r/deeplearning/comments/awq60t/deeplearningai_specialization_progress_shaik_asad/,theshaikasad,1551584924,"Hey, to anyone interested in the [deeplearning.ai](https://deeplearning.ai/) Specialization, I've made a vlog documenting my progress and I've built an AI to classify numbers in the form of hand-signs. At the end the model didn't do well on my image because examples from the test and train set were hand signs in vertical () and not horizontal ()

Check it out 

[https://youtu.be/yCNpQYbw7vM](https://youtu.be/yCNpQYbw7vM) ",0,0
16,2019-3-3,2019,3,3,19,awt0at,Unsupervised learning using TensorForce and RL-techniques to control mouse movements.,https://www.reddit.com/r/deeplearning/comments/awt0at/unsupervised_learning_using_tensorforce_and/,ZeroMaxinumXZ,1551610575,,5,15
17,2019-3-4,2019,3,4,10,ax0ytl,Is the GTX 1050 good enough to learn the basics of deep learning?,https://www.reddit.com/r/deeplearning/comments/ax0ytl/is_the_gtx_1050_good_enough_to_learn_the_basics/,drummerboxer,1551661259,"I am a manager and want to learn the basics of deep learning -- the tools,  training process, and structure of the main types of deep learning architectures, etc. I  don't think I will be designing very large networks with large data sets, but at the same time I am not sure. I would rather do this on my laptop than on the cloud initially. I can get access to a server in the future to train large models once I get a good grasp of the tools on my laptop. 

I can buy one of two laptops from work: a nice corporate laptop with a 1050 gpu or a new razer blade 15 with a 2070 gpu. Both cost about the same. I have tried the razer at best buy and didn't like the ergonomics much, and hence am considering the corporate laptop. 

Would the 1050 gpu be good enough to properly learn deep learning? I will most likely be running tensor flow under windows, or can dual boot if needed. Also, I usually split my time between a couple of campuses and also spend about 30-50% of my time in meetings. Thus I will probably be doing this work in the evenings at home.",16,7
18,2019-3-4,2019,3,4,20,ax6889,3D Advanced Neural Network Simulation - Computer vision - Digit Recognition,https://www.reddit.com/r/deeplearning/comments/ax6889/3d_advanced_neural_network_simulation_computer/,DevTechRetopall,1551699933,,7,26
19,2019-3-4,2019,3,4,22,ax6zzm,What is the difference between a custom cnn and lets say googlenet or alexnet?,https://www.reddit.com/r/deeplearning/comments/ax6zzm/what_is_the_difference_between_a_custom_cnn_and/,superibr,1551705259,"Can someone please explain me this question?For example if i use a model like below. 

&amp;#x200B;

 model = tf.keras.models.Sequential() #model.add(tf.keras.layers.Flatten())  

&amp;#x200B;

model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input\_shape= x\_train.shape\[1:\])) 

&amp;#x200B;

model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) 

&amp;#x200B;

model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax)) 

&amp;#x200B;

&amp;#x200B;

are googlenet and alexnet the way to make this model? like more layers less dence, different convolution matrix size etc?",1,1
20,2019-3-4,2019,3,4,22,ax7akt,Is MSI GeForce GTX 1080 TI ARMOR 11G OC Graphics Card suitable for Deeplearning?,https://www.reddit.com/r/deeplearning/comments/ax7akt/is_msi_geforce_gtx_1080_ti_armor_11g_oc_graphics/,MasterSama,1551707162,"Hello everyone. 

I have a Gigabyte G1 Gaming GTX1080 and it has worked for me just fine. today I found a second hand MSI GeForce GTX 1080 TI ARMOR 11G OC Graphics Card, that might be a good deal. it was used for mining , but the guy says the temp were around 60 degree Celsius (he had the room cooled with an air conditioner!) 

I have searched the internet and noticed, there are many people complaining about its cooling capability and that this card easily thermal throttles. now this has me worried so I'm asking about those of you who have experience working with such card. 

Do you think its worth it or not? (The card is being sold as 43% less than the actual card and it has warrantee for the next 2 years)   

(I'll be most likely training on ImageNet like datasets for weeks. )",8,2
21,2019-3-4,2019,3,4,23,ax7qeu,Can Transformer networks be applied in audio classification tasks?,https://www.reddit.com/r/deeplearning/comments/ax7qeu/can_transformer_networks_be_applied_in_audio/,Rytis_kap,1551709854,"I was working on audio classification with CNNs (music genre classification in particular) . And now I'm generating ideas for my next project in this field. I was thinking of using CRNN, but I came across Transformer networks ([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)) and found out that it is performing well in machine translation tasks. But I couldn't find anything about using it in audio-related problems. I was wondering, maybe someone has tried applying Transformer networks in audio domain and could share their experience? Or could nod in the right direction? ",0,1
22,2019-3-5,2019,3,5,15,axhs4t,Using instance segmentation for data cleaning. Need help! xpost /r/computervision,https://www.reddit.com/r/deeplearning/comments/axhs4t/using_instance_segmentation_for_data_cleaning/,kimbler69,1551766083,[removed],0,1
23,2019-3-5,2019,3,5,16,axik2t,Using deep learning to read your thoughts  with Keras and an EEG sensor,https://www.reddit.com/r/deeplearning/comments/axik2t/using_deep_learning_to_read_your_thoughts_with/,quasci,1551771893,,0,45
24,2019-3-5,2019,3,5,21,axkw0t,"A PyTorch implementation of ""A Higher-Order Graph Convolutional Layer"" (NeurIPS 2018).",https://www.reddit.com/r/deeplearning/comments/axkw0t/a_pytorch_implementation_of_a_higherorder_graph/,benitorosenberg,1551790789,"&amp;#x200B;

*Processing img qd1n78i2tak21...*

&amp;#x200B;

**PyTorch:** [https://github.com/benedekrozemberczki/NGCN](https://github.com/benedekrozemberczki/NGCN)

**Paper:** [http://sami.haija.org/papers/high-order-gc-layer.pdf](http://sami.haija.org/papers/high-order-gc-layer.pdf)

**Abstract:**

Recent  methods generalize convolutional layers from Euclidean domains to   graph-structured data by approximating the eigenbasis of the graph   Laplacian. The computationally-efficient and broadly-used Graph ConvNet   of Kipf &amp; Welling, over-simplifies the approximation, effectively   rendering graph convolution as a neighborhood-averaging operator. This   simplification restricts the model from learning delta operators, the   very premise of the graph Laplacian.  In this work, we propose a new   Graph Convolutional layer which mixes multiple powers of the adjacency   matrix, allowing it to learn delta operators. Our layer exhibits the   same memory footprint and computational complexity as a GCN. We   illustrate the strength of our proposed layer on both synthetic graph   datasets, and on several real-world citation graphs, setting the record   state-of-the-art on Pubmed.",0,6
25,2019-3-5,2019,3,5,22,axlbv7,Using instance segmentation for data cleaning. Need help! xpost /r/computervision,https://www.reddit.com/r/deeplearning/comments/axlbv7/using_instance_segmentation_for_data_cleaning/,kimbler69,1551793653,[removed],0,1
26,2019-3-5,2019,3,5,23,axlvcp,Learning Deep Learning - A Curriculum,https://www.reddit.com/r/deeplearning/comments/axlvcp/learning_deep_learning_a_curriculum/,pmuens,1551796980,,2,6
27,2019-3-5,2019,3,5,23,axlyof,papers on learning by Exploration,https://www.reddit.com/r/deeplearning/comments/axlyof/papers_on_learning_by_exploration/,sriharsha_0806,1551797524,"Hi, I want to get started on learning by Exploration for computer vision.  What are the papers I should read to get started with the topic?",0,1
28,2019-3-5,2019,3,5,23,axlyxb,Overfitting in pointer generator network,https://www.reddit.com/r/deeplearning/comments/axlyxb/overfitting_in_pointer_generator_network/,fridayc13,1551797557,,0,0
29,2019-3-6,2019,3,6,0,axm7b4,Microsoft Unveils Website to Create Art with GANs,https://www.reddit.com/r/deeplearning/comments/axm7b4/microsoft_unveils_website_to_create_art_with_gans/,mhamilton723,1551798884,,0,32
30,2019-3-6,2019,3,6,1,axmsi8,Deep learning for recommendations systems,https://www.reddit.com/r/deeplearning/comments/axmsi8/deep_learning_for_recommendations_systems/,robotics89,1551802073,,0,1
31,2019-3-6,2019,3,6,3,axo85c,Human Pose Estimation Model HRNet Breaks Three COCO Records; CVPR Accepts Paper,https://www.reddit.com/r/deeplearning/comments/axo85c/human_pose_estimation_model_hrnet_breaks_three/,gwen0927,1551809533,,0,11
32,2019-3-6,2019,3,6,3,axo8ii,Is BERT model suitable for NMT?,https://www.reddit.com/r/deeplearning/comments/axo8ii/is_bert_model_suitable_for_nmt/,KorChris,1551809586,"As I know, BERT puts the input contains the source and the target with \[SEP\]

&amp;#x200B;

Now I'm trying to BERT and attention RNN code(which has the source input and the target output) for NMT.

&amp;#x200B;

But as the BERT encoder puts the input has the source and the target, I have no idea how it can fit.

&amp;#x200B;

Is it possible to adapt BERT model to NMT attention RNN model?",0,4
33,2019-3-6,2019,3,6,3,axoil0,GPU Box Build Advice,https://www.reddit.com/r/deeplearning/comments/axoil0/gpu_box_build_advice/,doyer,1551811014,"Hey all, I'm trying to build a gpu box with a budget of 3-4k (obviously less would be better :P). Don't know too much about this side of the house. 

&amp;#x200B;

Goals: Decent GPU box for now which can be upgraded to \~6-8 gpus and hundreds of gigs of ram in the future

&amp;#x200B;

Use Case: At first I will primarily be using this for training models. Switching between one model/gpu and a few gpus for the same model depending on the situation. Within 6 months, a couple other people will be using this system at the same time as me for training models. May also use it for algo trading so up-time, rapid ingestion of data from sockets, etc is also important but if that is not feasible I am not opposed to building another system for that in a couple months. 

&amp;#x200B;

Thoughts so far:

(1) AMD EPYC 7281@ amazon $680

(1) Kingston 64GB (16 x 4) 2666mgz @amazon $480

(1) Asus KNPA-U16 Motherboard @ amazon $380

(2) Zotac GeForce RTX 2070 Blower 8gb @ amazon $500/each

(1) Samsung 860 evo 500gb ssd @ amazon $80

OS: probably Ubuntu Server

&amp;#x200B;

I still need an hdd, case, cooling system (?) , and ..not really sure what else. Definitely have no idea how to pick a case but I'm presuming I can just buy some sort of server case and that'll work itself out. 

&amp;#x200B;

I have been googling a bunch and I've read something about NUMA architectures but I'm not really sure how that impacts my usecase. 

&amp;#x200B;

I would love any suggestions or ideas if you all have any!",4,2
34,2019-3-6,2019,3,6,6,axqkvy,Want to model a conditional probability p(y|x) with NN? We report best practices for cond density estimation and compare against baseline density estimators typically used in finance.,https://www.reddit.com/r/deeplearning/comments/axqkvy/want_to_model_a_conditional_probability_pyx_with/,whiletrue2,1551821862,"Want to model a conditional probability p(y|x) with NN? We report best practices for cond density estimation and compare against baseline density estimators for a finance application. 

We open-sourced code here with various estimators, data normalization and regularization, data generating processes, statistical divergences for evaluation (KL-divergence, Hellinger, Jensen-Shannon) and other (quantiles, expected shortfalls, likelihood etc.), see here: https://github.com/freelunchtheorem/Conditional_Density_Estimation

Our report can be found here: https://arxiv.org/abs/1903.00954

Take away message: Normalization &amp; regularization helps, Kernel Mixture Models and Mixture Density Models perform better than semi- and non-parametric methods.",0,2
35,2019-3-6,2019,3,6,8,axs0lb,Hyperbolic N-Space encodings for TensorFlow,https://www.reddit.com/r/deeplearning/comments/axs0lb/hyperbolic_nspace_encodings_for_tensorflow/,kousun12,1551829771,"I still think hyperbolic geometry hasn't been appreciated enough in the ML world, following the first few papers by [facebook research](https://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations). Here's an implementation of some basic functions to support the Poincare model for word embeddings in TF. Lorentz model coming eventually...

[https://github.com/kousun12/tf\_hyperbolic](https://github.com/kousun12/tf_hyperbolic)",2,4
36,2019-3-6,2019,3,6,13,axuomg,Xeus-Cling: Run C++ code in Jupyter Notebook,https://www.reddit.com/r/deeplearning/comments/axuomg/xeuscling_run_c_code_in_jupyter_notebook/,spmallick,1551846390,"Have you ever used a Jupyter notebook? If yes, you know it is a pleasure to use it for interactive programming. If no, you should try it! Or you may be a C++ programmer and thinking Jupyter notebooks are not for you, but wait, imagine our joy when we came across the Xeus-Cling kernel! But what does it do?  
[https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/](https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/?fbclid=IwAR3El5cgG2FojF_Hn8f40EVe1JXvu7pkvsrWQuVg9Y5r9wALJouu4ypRJtQ)  
Read this blog post wherein we show how you can use OpenCV and Dlib C++ code in a Jupyter notebook using the Xeus-Cling kernel. Mention reviews and what you want us to work on next, in the comments!

![video](euaaocsiefk21)",1,21
37,2019-3-6,2019,3,6,19,axxa4q,DataScience Digest - Issue #17,https://www.reddit.com/r/deeplearning/comments/axxa4q/datascience_digest_issue_17/,flyelephant,1551867301,,0,3
38,2019-3-6,2019,3,6,21,axy3j6,Is deep reinforcement learning a promising career?,https://www.reddit.com/r/deeplearning/comments/axy3j6/is_deep_reinforcement_learning_a_promising_career/,TheHawkGriffith,1551873915,[removed],0,1
39,2019-3-6,2019,3,6,22,axz399,A collection of graph embedding research papers with implementations.,https://www.reddit.com/r/deeplearning/comments/axz399/a_collection_of_graph_embedding_research_papers/,benitorosenberg,1551880599,"An exhaustive collection of important graph embedding, classification and representation learning papers with implementations.

&amp;#x200B;

[https://github.com/benedekrozemberczki/awesome-graph-embedding](https://github.com/benedekrozemberczki/awesome-graph-embedding)

https://i.redd.it/efplfi268ik21.png

&amp;#x200B;",0,4
40,2019-3-6,2019,3,6,23,axzivj,"Microsoft Releases New Version of Open Source Distributed ML Library, MMLSpark",https://www.reddit.com/r/deeplearning/comments/axzivj/microsoft_releases_new_version_of_open_source/,mhamilton723,1551883217,,0,21
41,2019-3-6,2019,3,6,23,axzptk,Reproducing experimental results from SysML'19 papers (the Conference on Systems and Machine Learning),https://www.reddit.com/r/deeplearning/comments/axzptk/reproducing_experimental_results_from_sysml19/,gfursin,1551884361,"We had a very interesting experience when evaluating artifacts and reproducing experimental results from several accepted [SysML'19](http://cTuning.org/ae/sysml2019.html) papers on deep learning. You can now find the results [online](http://reuseresearch.com/index.php?a=papers-sysml-2019). We plan to discuss the [SysML reproducibility initiative](http://cTuning.org/ae/sysml2019.html) and brainstorm how to improve, simplify and automate validation of experimental results at ML, AI and systems conferences at [SysML'19](http://sysml.cc) on April 2 (1:30-2pm, Fisher Conference Center, Stanford University). Looking forward to further discussions!",0,2
42,2019-3-7,2019,3,7,1,ay0iev,Reinforced Cross-Modal Matching &amp; Self-Supervised Imitation Learning for Vision-Language Navigation,https://www.reddit.com/r/deeplearning/comments/ay0iev/reinforced_crossmodal_matching_selfsupervised/,gwen0927,1551888687,,0,2
43,2019-3-7,2019,3,7,1,ay0p59,Triple Strong Accept for CVPR 2019: Reinforced Cross-Modal Matching &amp; Self-Supervised Imitation,https://www.reddit.com/r/deeplearning/comments/ay0p59/triple_strong_accept_for_cvpr_2019_reinforced/,Yuqing7,1551889661,,0,1
44,2019-3-7,2019,3,7,1,ay0xoz,AMD Vega VII same performance as 2080Ti for Resnet50,https://www.reddit.com/r/deeplearning/comments/ay0xoz/amd_vega_vii_same_performance_as_2080ti_for/,jpdowlin,1551890927,"Some people are trying out ROCm - TensorFlow and there are some benchmarks here:  
[https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/issues/173](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/issues/173)

&amp;#x200B;

The Vega 7 costs about 800 dollars and has 16GB ram and fp64 and fp16 have not been gimped. It has potential to be a mass market GPU for deep learning. ROCm may not have been upstreamed to tensorflow yet, but it's basically ""pip install tensorflow-rocm"" to get it working. Some will say ROCm is flakey, untested - which may be true, but they will get there this year with stability, IMO.

Opinions?",4,3
45,2019-3-7,2019,3,7,2,ay19hg,"Wow, this is insane!",https://www.reddit.com/r/deeplearning/comments/ay19hg/wow_this_is_insane/,CocoFormerChild,1551892627,"I just realized that all adults are just former children, how is this not something everyone realizes?",6,0
46,2019-3-7,2019,3,7,3,ay1zn9,CNN for RNNs  A gentle approach to use CNNs for NLP,https://www.reddit.com/r/deeplearning/comments/ay1zn9/cnn_for_rnns_a_gentle_approach_to_use_cnns_for_nlp/,DataScienceReporter,1551896353,,0,1
47,2019-3-7,2019,3,7,3,ay20ct,Deep Learning in Finance Summit - London,https://www.reddit.com/r/deeplearning/comments/ay20ct/deep_learning_in_finance_summit_london/,BlockDelta,1551896453,,0,4
48,2019-3-7,2019,3,7,6,ay3yta,GIPHY open-sources their celebrity detection deep learning model and code,https://www.reddit.com/r/deeplearning/comments/ay3yta/giphy_opensources_their_celebrity_detection_deep/,giphy,1551906467,,2,39
49,2019-3-7,2019,3,7,6,ay48a9,NeurIPS 2019 Dates and Details Announced,https://www.reddit.com/r/deeplearning/comments/ay48a9/neurips_2019_dates_and_details_announced/,Yuqing7,1551907768,,0,3
50,2019-3-7,2019,3,7,6,ay4j4v,NeurIPS 2019 Dates and Details Announced,https://www.reddit.com/r/deeplearning/comments/ay4j4v/neurips_2019_dates_and_details_announced/,Yuqing7,1551909310,,0,1
51,2019-3-7,2019,3,7,10,ay6t22,Need advise on deep learning,https://www.reddit.com/r/deeplearning/comments/ay6t22/need_advise_on_deep_learning/,happywildrose,1551922046,"Hello all,

&amp;#x200B;

I hope you will give me some constructive opinion and feedback. First all of I would tell little bit about myself.

I have degree in Chemical Engineering (graduated about 13 years ago). Unfortunately, due to different reasons I don't have a stable career. Currently, I am employed but job is not permanent and it's more clerical. I am hoping company will not lay me off. That means I have some time at home every evening which I can invest to some positive activity. My weekends are free too.  I am thinking to start self-taught learning in Computer Science specifically in Deep Learning. I have zero programming knowledge. I am married, 35 years old. 

&amp;#x200B;

My question is for person like myself who has no knowledge of programming how practical it is to switch career if I learn 20 to 25 hours every week. Would I be able to have a decent level knowledge to present myself in an interview after 2-3 years. 

&amp;#x200B;

From where should I start. I have done little bit of browsing which reveals along with some programming languages I also need to get command on statistics (linear regression etc.)

&amp;#x200B;

Please guide me what should be VERY FIRST STEP. I happy and ready to take baby steps :)

&amp;#x200B;

Thank you in advance!

&amp;#x200B;

&amp;#x200B;",10,4
52,2019-3-7,2019,3,7,11,ay79wn,Deep Learning GPU Benchmarks -- RTX 2080 Ti vs Tesla V100 vs RTX 2080 vs Titan RTX vs Titan V vs GTX 1080 Ti vs Titan Xp,https://www.reddit.com/r/deeplearning/comments/ay79wn/deep_learning_gpu_benchmarks_rtx_2080_ti_vs_tesla/,mippie_moe,1551924890,,3,12
53,2019-3-7,2019,3,7,16,ay9x1a,How to get started with Python for Deep Learning and Data Science,https://www.reddit.com/r/deeplearning/comments/ay9x1a/how_to_get_started_with_python_for_deep_learning/,MaryDBlackwell,1551943166,[http://on.geeklearn.net/64d9d6db70](http://on.geeklearn.net/64d9d6db70),0,1
54,2019-3-7,2019,3,7,18,ayax84,"Comprehensive Deep Learning Git Codebook, Video Tutorials and Projects",https://www.reddit.com/r/deeplearning/comments/ayax84/comprehensive_deep_learning_git_codebook_video/,nalinee_choudhary,1551952274,"&amp;#x200B;

https://i.redd.it/4y6inwe65ok21.jpg

&amp;#x200B;

**Comprehensive** **Deep Learning tutorials** [(Free Video Tutorials)](https://www.edyoda.com/course/1429) [(Github codebook)](https://github.com/zekelabs/AI101-DeepLearning)  


**Build Deep Learning Projects (Complete Video Series for FREE )**  


**1.** [Making your RL Projects in 20 Minutes](https://www.edyoda.com/course/1421)  


**2.** [Style Transfer, Face Generation using GANs in 20 minutes](https://www.edyoda.com/course/1418)  


**3.** [Language and Machine Learning in 20 minutes](https://www.edyoda.com/course/1419)  


**4.** [AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185)  


**5.** [Dog Breed Prediction](https://www.edyoda.com/course/1336)  


**Free** **Video Series for Beginners to advanced users**  


**1.** [Machine Learning - Mastering NumPy](https://www.edyoda.com/course/1263)  


**2.** [Machine Learning using Tensorflow](https://www.edyoda.com/course/99)  


**3.** [Step by step guide to Tensorflow](https://www.edyoda.com/course/1429)  


**4.** [Introduction to Neural Networks](https://www.edyoda.com/course/1417)  


**5.** [Knowledge Graphs, Deep Learning and Reasoning](https://www.edyoda.com/course/1420)",0,1
55,2019-3-7,2019,3,7,23,ayd147,"Comprehensive Deep Learning Git Codebook, Video Tutorials and Projects",https://www.reddit.com/r/deeplearning/comments/ayd147/comprehensive_deep_learning_git_codebook_video/,nalinee_choudhary,1551968029,"**Comprehensive** **Deep Learning tutorials** [(Free Video Tutorials)](https://www.edyoda.com/course/1429) [(Github codebook)](https://github.com/zekelabs/AI101-DeepLearning)  


**Build Deep Learning Projects (Complete Video Series for FREE )**  


**1.** [Making your RL Projects in 20 Minutes](https://www.edyoda.com/course/1421)  


**2.** [Style Transfer, Face Generation using GANs in 20 minutes](https://www.edyoda.com/course/1418)  


**3.** [Language and Machine Learning in 20 minutes](https://www.edyoda.com/course/1419)  


**4.** [AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185)  


**5.** [Dog Breed Prediction](https://www.edyoda.com/course/1336)  


**Free** **Video Series for Beginners to advanced users**  


**1.** [Machine Learning - Mastering NumPy](https://www.edyoda.com/course/1263)  


**2.** [Machine Learning using Tensorflow](https://www.edyoda.com/course/99)  


**3.** [Step by step guide to Tensorflow](https://www.edyoda.com/course/1429)  


**4.** [Introduction to Neural Networks](https://www.edyoda.com/course/1417)  


**5.** [Knowledge Graphs, Deep Learning and Reasoning](https://www.edyoda.com/course/1420)",0,31
56,2019-3-8,2019,3,8,1,aye70b,Google Open-Sources GPipe Library for Training Large-Scale Neural Network Models,https://www.reddit.com/r/deeplearning/comments/aye70b/google_opensources_gpipe_library_for_training/,gwen0927,1551974704,,0,13
57,2019-3-8,2019,3,8,1,ayebb3,"A PyTorch Implementation of ""Predict then Propagate: Graph Neural Networks meet Personalized PageRank"" (ICLR 2019)",https://www.reddit.com/r/deeplearning/comments/ayebb3/a_pytorch_implementation_of_predict_then/,benitorosenberg,1551975327,"&amp;#x200B;

&amp;#x200B;

https://i.redd.it/2acxf6ox1qk21.jpg

**Paper:** [https://arxiv.org/abs/1810.05997](https://arxiv.org/abs/1810.05997)

**PyTorch implementation:** [https://github.com/benedekrozemberczki/APPNP/](https://github.com/benedekrozemberczki/APPNP/)

**Abstract:**

Neural  message passing algorithms for semi-supervised classification on graphs  have recently achieved great success. However, these methods only  consider nodes that are a few propagation steps away and the size of  this utilized neighborhood cannot be easily extended. In this paper, we  use the relationship between graph convolutional networks (GCN) and  PageRank to derive an improved propagation scheme based on personalized  PageRank. We utilize this propagation procedure to construct  personalized propagation of neural predictions (PPNP) and its  approximation, APPNP. Our model's training time is on par or faster and  its number of parameters on par or lower than previous models. It  leverages a large, adjustable neighborhood for classification and can be  combined with any neural network. We show that this model outperforms  several recently proposed methods for semi-supervised classification on  multiple graphs in the most thorough study done so far for GCN-like  models.",0,2
58,2019-3-8,2019,3,8,3,ayfl9j,ICLR 2019 | Fast as Adam &amp; Good as SGD  New Optimizer Has Both,https://www.reddit.com/r/deeplearning/comments/ayfl9j/iclr_2019_fast_as_adam_good_as_sgd_new_optimizer/,gwen0927,1551981787,,8,18
59,2019-3-8,2019,3,8,5,ayhejk,TensorFlow Privacy: Learning with Differential Privacy for Training Data,https://www.reddit.com/r/deeplearning/comments/ayhejk/tensorflow_privacy_learning_with_differential/,ConfidentMushroom,1551991172,,0,2
60,2019-3-8,2019,3,8,7,ayid2t,3-D Imaging with deep learning brings together holography and microscopy,https://www.reddit.com/r/deeplearning/comments/ayid2t/3d_imaging_with_deep_learning_brings_together/,FindLight2017,1551996296,"What impacts could this have on medical imaging? Could this be a better way for neural networks to predict outcomes through collecting diagnostic data?

[https://phys.org/news/2019-03-deep-merges-advantages-holography-bright-field.html](https://phys.org/news/2019-03-deep-merges-advantages-holography-bright-field.html)",0,1
61,2019-3-8,2019,3,8,11,aykte5,Assessing quality of downsampled point cloud,https://www.reddit.com/r/deeplearning/comments/aykte5/assessing_quality_of_downsampled_point_cloud/,gwynbleidd2099,1552010739,"How does one measure quality of downsampled point clouds which are being fed to classification network? For example, Pointnet can use ModelNet40 as test and train data, with point clouds consisting of eg. 1024 points. If I were to reduce this number to 128, with some algorithm, how do I know if the new point cloud is actually decent? Feed it to another network and compare accuracy to not-resampled datasets, resampled with another algorithm or is there another way?",0,1
62,2019-3-8,2019,3,8,11,ayl7lo,Why Doesn't Meta-Learning Overfit the Meta-Training Set?,https://www.reddit.com/r/deeplearning/comments/ayl7lo/why_doesnt_metalearning_overfit_the_metatraining/,purboo,1552013286,"I am always wondering why meta-learning works. The meta-learner is trained on tasks that are built from a meta-training set, and it can perform generally well on totally unseen tasks from a meta-testing set. Why doesn't the meta-learner overfit the meta-training tasks?  What if the meta-testing set differs greatly from the meta-training set? What is the deep, essential magic that contributes to the high generalizability of the meta-learner? ",3,1
63,2019-3-8,2019,3,8,15,aymy9o,Udacity's updated tutorial course for Tensorflow2.0!,https://www.reddit.com/r/deeplearning/comments/aymy9o/udacitys_updated_tutorial_course_for_tensorflow20/,shawnmanuel000,1552025459,"Hey guys, some of you might have seen the release of Tensorflow2.0 alpha that came out a few days ago. Just wanted to share the updated [Udacity tutorial](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187) for getting started with it. 

However I did find that it doesn't cover how to actually create your own custom loss function optimizer operations for applying the new 2.0 API for more complex reinforcement learning applications so I'm going to try and make a YouTube coding tutorial for that soon.",6,40
64,2019-3-8,2019,3,8,17,ayo1i9,Deploying a Keras Deep Learning Model as a Web Application in Python,https://www.reddit.com/r/deeplearning/comments/ayo1i9/deploying_a_keras_deep_learning_model_as_a_web/,MarkOliver908,1552034552,,0,1
65,2019-3-8,2019,3,8,18,ayoc67,SimGNN: A Neural Network Approach to Fast Graph Similarity Computation (WSDM 2019),https://www.reddit.com/r/deeplearning/comments/ayoc67/simgnn_a_neural_network_approach_to_fast_graph/,benitorosenberg,1552037188,"&amp;#x200B;

https://i.redd.it/a1uid1av5vk21.jpg

&amp;#x200B;

Paper: [http://web.cs.ucla.edu/\~yzsun/papers/2019\_WSDM\_SimGNN.pdf](http://web.cs.ucla.edu/~yzsun/papers/2019_WSDM_SimGNN.pdf)

PyTorch implementation: [https://github.com/benedekrozemberczki/SimGNN](https://github.com/benedekrozemberczki/SimGNN)

Abstract:

Graph similarity search is among the most important graph-based applications, e.g. finding the chemical compounds that are most similar to a query compound. Graph similarity/distance computation, such as Graph Edit Distance (GED) and Maximum Common Subgraph (MCS), is the core operation of graph similarity search and many other applications, but very costly to compute in practice. Inspired by the recent success of neural network approaches to several graph applications, such as node or graph classification, we propose a novel neural network based approach to address this classic yet challenging graph problem, aiming to alleviate the computational burden while preserving a good performance. The proposed approach, called SimGNN, combines two strategies. First, we design a learnable embedding function that maps every graph into an embedding vector, which provides a global summary of a graph. A novel attention mechanism is proposed to emphasize the important nodes with respect to a specific similarity metric. Second, we design a pairwise node comparison method to sup plement the graph-level embeddings with fine-grained node-level information. Our model achieves better generalization on unseen graphs, and in the worst case runs in quadratic time with respect to the number of nodes in two graphs. Taking GED computation as an example, experimental results on three real graph datasets demonstrate the effectiveness and efficiency of our approach. Specifically, our model achieves smaller error rate and great time reduction compared against a series of baselines, including several approximation algorithms on GED computation, and many existing graph neural network based models. Our study suggests SimGNN provides a new direction for future research on graph similarity computation and graph similarity search.",0,3
66,2019-3-8,2019,3,8,21,aypt5k,"Is there an ELI5 for Python? I'm no CS, and I've never been good at reading/coding... Yet, I work with deep learning on a daily basis.",https://www.reddit.com/r/deeplearning/comments/aypt5k/is_there_an_eli5_for_python_im_no_cs_and_ive/,MightBeKatie,1552048671,"I watched a few ""Basic Python in an hour"" on YouTube but was overwhelmed about 3 minutes in when the prof/speaker started talking about and utilizing a variable he hadn't explained. CS profs seem to talk like football coaches: there's substance there but no connection. ",4,1
67,2019-3-8,2019,3,8,23,ayqxd5,Machine learning on google cloud platform,https://www.reddit.com/r/deeplearning/comments/ayqxd5/machine_learning_on_google_cloud_platform/,frenchdic,1552055627,,0,1
68,2019-3-9,2019,3,9,0,ayrhml,I want to be a researcher in deep learning but I don't know what to do ....code/ learn research papers,https://www.reddit.com/r/deeplearning/comments/ayrhml/i_want_to_be_a_researcher_in_deep_learning_but_i/,arshad_221b,1552058867,"I'm currently a undergraduate student in India and I want to do research in deep learning. I'm more interested in finding new techniques than using existing techniques on certain data sets. 
So what should I do? Focus more on coding or finding more algorithms theoretically? (_  )",2,0
69,2019-3-9,2019,3,9,1,aysat9,Large Dataset for Speech Recognition,https://www.reddit.com/r/deeplearning/comments/aysat9/large_dataset_for_speech_recognition/,limapedro,1552063205,"Hi guys! The new Common Voice datasets were released a few days ago and I created a torrent with all the datasets, so you can usually train your models with different languages.

&amp;#x200B;

Link:  magnet:?xt=urn:btih:6318a9e4735b4cdc6c88ccbd9f16e9c1c016ed88&amp;dn=Common+Voice+V2+March+2019.rar ",1,1
70,2019-3-9,2019,3,9,2,ayt1sh,Algernon -- the curious mouse pointer.,https://www.reddit.com/r/deeplearning/comments/ayt1sh/algernon_the_curious_mouse_pointer/,ZeroMaxinumXZ,1552067135,,9,1
71,2019-3-9,2019,3,9,2,ayt4mp,Google Debuts TensorFlow 2.0 Alpha,https://www.reddit.com/r/deeplearning/comments/ayt4mp/google_debuts_tensorflow_20_alpha/,Yuqing7,1552067566,,1,29
72,2019-3-9,2019,3,9,3,ayt828,Help please,https://www.reddit.com/r/deeplearning/comments/ayt828/help_please/,DustyCakeRendy,1552068065,,0,2
73,2019-3-9,2019,3,9,6,ayvu09,How to deal with image data captured from different camera sources,https://www.reddit.com/r/deeplearning/comments/ayvu09/how_to_deal_with_image_data_captured_from/,naboo_random,1552081915,"Hi, 

I am trying to object classification of a kind, where the image data that I have has been captured via different sources. Can someone suggest ways or models that are unaffected by the source of the data, but can still perform well to identify the object?

The train images are captured using a microscope, dslr and phone camera. Where as the test images are captured using a phone. 

&amp;#x200B;

Again, there are differences in each of their backgrounds, and lightning conditions as well. I know there are image preprocessing techniques that I can use to equalize images on the lightning part, but there is a lot of difference in their resolutions as well. 

&amp;#x200B;

Any help will be appreciated! 

Thanks!",2,1
74,2019-3-9,2019,3,9,9,ayxppn,Weird losses with resnet,https://www.reddit.com/r/deeplearning/comments/ayxppn/weird_losses_with_resnet/,CreativeElephant,1552092586,"I have been trying resnet-18 on CIFAR-10, I did not normalize the data and feed cifar-10 images (0-1 range) as it is to train the model. I see some weird loss behaviour, is it normal? I see that loss goes down initially and accuracy improves but as training progresses loss increases a lot but accuracy plateaus. What confounds me is test loss and test accuracy are not at all correlated!! Optimizer is SGD/ADAM with initial lr=0.1 and varies as initial\_lr\*10\^{-epoch/100}. I train for 300 epochs  

[Accuracy and Loss curves](https://i.redd.it/09hzwa9g9zk21.png)",8,1
75,2019-3-9,2019,3,9,13,ayzntz,Good papers on curiosity in reinforcement-learning.,https://www.reddit.com/r/deeplearning/comments/ayzntz/good_papers_on_curiosity_in_reinforcementlearning/,ZeroMaxinumXZ,1552105981,"I'm looking for some good academic papers on curiosity in reinforcement learning, I've created a curious agent using Tensorforce and Keras as shown here: [https://github.com/ZeroMaxinumXZ/algernon](https://github.com/ZeroMaxinumXZ/algernon), but would like to improve the agent further...  if possible. Any suggestions/recommendations?",1,5
76,2019-3-9,2019,3,9,16,az0v8m,Resources on implementing YOLO.,https://www.reddit.com/r/deeplearning/comments/az0v8m/resources_on_implementing_yolo/,ragingpot,1552115384,I'm looking to implement YOLO from scratch (minus the pretrained model and weights). Any resources which could help me understand the model as I'm a relative beginner in deep learning. Thank you!,4,2
77,2019-3-9,2019,3,9,17,az1cfc,TensorFlow nan Loss,https://www.reddit.com/r/deeplearning/comments/az1cfc/tensorflow_nan_loss/,arjundupa,1552119775,"I am trying to de-noise a signal by training a model based on the IndRNN architecture ([https://arxiv.org/abs/1803.04831](https://arxiv.org/abs/1803.04831)) using TensorFlow. I am using curriculum learning, which in the context of my problem simply means that I started off training the model with data with high signal-to-noise ratio (SNR), and gradually decreased it.

Training was going extremely well until SNR = 1.5 (I originally started at SNR = 4.0 and worked my way down), which is when I began getting this nan loss. I have tried reducing the learning rate (by a factor of 10 of the original), but this hasn't helped either.

Any ideas about the cause of this issue and what I can try to resolve it?

Any ideas will be much appreciated, thanks in advance.",6,4
78,2019-3-9,2019,3,9,19,az2cd4,"Suggestions for multi-input pipeline with ""convolution"" over one of the inputs in keras/tensorflow?",https://www.reddit.com/r/deeplearning/comments/az2cd4/suggestions_for_multiinput_pipeline_with/,nobodywillobserve,1552128835,"Am trying to get a pipeline working in Keras and am hitting up against a lot of issues, wondering if I need to drop to vanilla tf or if there is something wrong with my approach. 

&amp;#x200B;

I have two inputs X, Z. In a naive implementation I can simply repeat X and use the inputs \[\[X, Z0\], \[X, Z1\], ... \[X, Zn\]\] into a regular single input pipeline. This works but involves potentially wasting a lot of memory replicating X across the values of Z.

&amp;#x200B;

I was trying to write this as a a two input pipeline where there is a Conv1D over Z which is then combined with a VectorRepeater or a K.repeat\_elements of X. Ideally, the input Z is of dynamic shape (plus the batch size of X is dynamic). 

&amp;#x200B;

The biggest issue seems to come with trying to get the repeat dimension for X from the Z (which is dynamic and not known until call time). I could potentially have Z dimension be more hard-coded.

&amp;#x200B;

I am reading things that basically when you break the notion of batch size and have \*other\* dynamic dimension, Keras becomes tricky and it is best to descend to pure tensorflow. But am not clear if I can still use some of the layer constructors from Keras and simply some other components from tf.  


&amp;#x200B;

&amp;#x200B;",8,4
79,2019-3-9,2019,3,9,20,az2ic8,Neural ODEs.,https://www.reddit.com/r/deeplearning/comments/az2ic8/neural_odes/,ragingpot,1552130235,Has anyone understood and implemented https://arxiv.org/abs/1806.07366 Neural Differential Equations paper? Any help would be appreciated. Thank you!,2,6
80,2019-3-10,2019,3,10,3,az6r1j,Audio Embeddings,https://www.reddit.com/r/deeplearning/comments/az6r1j/audio_embeddings/,pk12_,1552157827,"I'm looking to investigate audio embeddings for voice recognition. 

Do you guys know of a resource which provides pre trained models",0,2
81,2019-3-10,2019,3,10,4,az71dg,"NLP Learning Series: Part 3 - Attention, CNN and what not for Text Classification",https://www.reddit.com/r/deeplearning/comments/az71dg/nlp_learning_series_part_3_attention_cnn_and_what/,kiser_soze,1552159481,,0,18
82,2019-3-10,2019,3,10,5,az7pka,GAN Human Facial Expression Style Transfer - But Small Dataset?,https://www.reddit.com/r/deeplearning/comments/az7pka/gan_human_facial_expression_style_transfer_but/,wypbusy,1552163300,"Hello guys,

&amp;#x200B;

I am working on a course project and find this [paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Azadi_Multi-Content_GAN_for_CVPR_2018_paper.pdf) fairly interesting and want to apply and modify the idea to modify human face according to different expression (such as happy, angry, surprise, etc). 

&amp;#x200B;

However, it seems the dataset for different human expressions are pretty limited (the original paper used 10K dataset), for example, I found [this dataset](https://mug.ee.auth.gr/fed/) that provides only 86 subjects with 6 different expressions. 

&amp;#x200B;

Is it possible to use such a limited dataset for my project? Any ideas or suggestions are appreciated!. ",0,3
83,2019-3-10,2019,3,10,12,azbkkq,Bengio at Tsinghua University on Maturing Deep Learning and BabyAI,https://www.reddit.com/r/deeplearning/comments/azbkkq/bengio_at_tsinghua_university_on_maturing_deep/,Yuqing7,1552188010,,0,12
84,2019-3-10,2019,3,10,18,aze0e9,A deep learning approach for end-to-end visual odometry,https://www.reddit.com/r/deeplearning/comments/aze0e9/a_deep_learning_approach_for_endtoend_visual/,redditball000,1552209186,,1,7
85,2019-3-10,2019,3,10,20,azen4u,"A PyTorch implementation of ""Graph Wavelet Neural Network"" (ICLR 2019)",https://www.reddit.com/r/deeplearning/comments/azen4u/a_pytorch_implementation_of_graph_wavelet_neural/,benitorosenberg,1552215702,"&amp;#x200B;

&amp;#x200B;

https://i.redd.it/8e3pwq7nw9l21.jpg

Paper: [https://openreview.net/forum?id=H1ewdiR5tQ](https://openreview.net/forum?id=H1ewdiR5tQ)

PyTorch: [https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork](https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork)

Abstract:

We  present graph wavelet neural network (GWNN), a novel graph   convolutional neural network (CNN), leveraging graph wavelet transform   to address the shortcomings of previous spectral graph CNN methods that   depend on graph Fourier transform. Different from graph Fourier   transform, graph wavelet transform can be obtained via a fast algorithm   without requiring matrix eigendecomposition with high computational   cost. Moreover, graph wavelets are sparse and localized in vertex   domain, offering high efficiency and good interpretability for graph   convolution. The proposed GWNN significantly outperforms previous   spectral graph CNNs in the task of graph-based semi-supervised   classification on three benchmark datasets: Cora, Citeseer and Pubmed.",0,24
86,2019-3-11,2019,3,11,0,azgw5r,IBM new Floating Point (FP8) DNN training format in NeurIPS2018,https://www.reddit.com/r/deeplearning/comments/azgw5r/ibm_new_floating_point_fp8_dnn_training_format_in/,CArchGuy,1552232750,"IBM uses FP8 in the forward pass and FP16 in the backprop. with stochastic rounding scheme. What do you think of this paper? Will it scale to train networks larger than ResNet50 (what they report in their paper), and will it be the training standard for the next few years ? 

What about bfloat16 which Intel and Google went to support in their HW ?

For people building custom hardware, which format should they select?",1,1
87,2019-3-11,2019,3,11,5,azk7ms,"""(Deep) Learning to Fly"" with Krzysztof Kudrynski &amp; Blazej Kubiak (45min talk from GOTO Berlin 2018)",https://www.reddit.com/r/deeplearning/comments/azk7ms/deep_learning_to_fly_with_krzysztof_kudrynski/,goto-con,1552250770,,1,8
88,2019-3-11,2019,3,11,8,azlqmi,Implementing Neural Networks from Scratch,https://www.reddit.com/r/deeplearning/comments/azlqmi/implementing_neural_networks_from_scratch/,DiscoverAI,1552259023,,0,0
89,2019-3-11,2019,3,11,11,aznkxh,Will tickets for ICML2019 be sold out in 10-20 min.? (Just like NIPS),https://www.reddit.com/r/deeplearning/comments/aznkxh/will_tickets_for_icml2019_be_sold_out_in_1020_min/,dhjjjj,1552270081,"Registration for ICML starts on March 12th.  
What do you guys think?

On the other hand, it is still possible to register for CVPR2019 which starts right after ICML in Long Beach.   
Will it be sold-out in 20 mins as NIPS was?",0,8
90,2019-3-11,2019,3,11,11,aznusj,What is happening in this basic rnn?,https://www.reddit.com/r/deeplearning/comments/aznusj/what_is_happening_in_this_basic_rnn/,begooboi,1552271753,"I have a lot of confusion in rnn so I am re-learning it. Found this basic implementation in tensorflow https://github.com/StephenOman/TensorFlowExamples/blob/master/Basic%20RNN.ipynb
What is X0 and X1 means here?
      Y0 = tf.tanh(tf.matmul(X0, Wx) + b)
      Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)

I believe rnn follows this struture
      (input+prev_hidden) -&gt; hidden -&gt; output

where Y0 can be taken as hidden value and Y1's input should be current input plus previous hidden value `tf.matmul(Y0, Wy) + tf.matmul(X0, Wx) + b` but here its given as `tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b` (look at X0 and X1). What is happening here?",6,1
91,2019-3-11,2019,3,11,12,azoeq1,Google Colab,https://www.reddit.com/r/deeplearning/comments/azoeq1/google_colab/,pk12_,1552275134,"I read that we need to keep Google colab browser window open in order to keep it running for 12 hours

Does keeping it open in the second monitor count?",1,0
92,2019-3-11,2019,3,11,12,azojgn,NYUv2 Dataset Download Available?,https://www.reddit.com/r/deeplearning/comments/azojgn/nyuv2_dataset_download_available/,kairos9603,1552275960,The NYUv2 download link is not working... Any one can do this?,0,1
93,2019-3-11,2019,3,11,15,azpuwe,How to visualize the accuracy of a neural network in Pytorch?,https://www.reddit.com/r/deeplearning/comments/azpuwe/how_to_visualize_the_accuracy_of_a_neural_network/,Vinceeeent,1552284574,"I want to visualize the accuracy of a neural network I got from github [here](https://github.com/paraschopra/one-network-many-uses/blob/master/four-in-one-network.ipynb). The code was written in Pytorch, is there a way to find the accuracy of this network? I know in keras can visualize the training but in pytorch I can't find any. Hope someone can help me :)",12,5
94,2019-3-11,2019,3,11,18,azr7r3,Any ideas or suggestions for my reinforcement learning AI ...,https://www.reddit.com/r/deeplearning/comments/azr7r3/any_ideas_or_suggestions_for_my_reinforcement/,ZeroMaxinumXZ,1552295280,"So basically I built a reinforcement learning AI that can curiously explore it's environment using aKeras dense neural network's loss (input is the environment, and output is the action) as a reward... The mouse pointer moves based on the actions of the reinforcement learning AI, and the keys are pressable by this agent... I'm using the PPOAgent provided by Tensorforce and the model is a whole bunch of convolutional layers coupled with the swish activation function... So, what should I do next to improve my reinforcement learning agent? It feels like I've done quite a bit, but agent will barely move if at all...",12,1
95,2019-3-11,2019,3,11,18,azrjah,AI JavaScript Rocks,https://www.reddit.com/r/deeplearning/comments/azrjah/ai_javascript_rocks/,DmitriyGenzel,1552297869,,0,0
96,2019-3-11,2019,3,11,20,azs2t7,"A PyTorch Implementation of ""Watch Your Step: Learning Node Embeddings via Graph Attention"" (NeurIPS 2018).",https://www.reddit.com/r/deeplearning/comments/azs2t7/a_pytorch_implementation_of_watch_your_step/,benitorosenberg,1552302003,"&amp;#x200B;

https://i.redd.it/17g6nrfa1hl21.jpg

Paper: [https://github.com/benedekrozemberczki/AttentionWalk/blob/master/paper.pdf](https://github.com/benedekrozemberczki/AttentionWalk/blob/master/paper.pdf)

Python: [https://github.com/benedekrozemberczki/AttentionWalk](https://github.com/benedekrozemberczki/AttentionWalk)

Abstract:

Graph  embedding methods represent nodes in a continuous vector space,   preserving different types of relational information from the graph.   There are many hyper-parameters to these methods (e.g. the length of a   random walk) which have to be manually tuned for every graph. In this   paper, we replace previously fixed hyper-parameters with trainable ones   that we automatically learn via backpropagation. In particular, we   propose a novel attention model on the power series of the transition   matrix, which guides the random walk to optimize an upstream objective.   Unlike previous approaches to attention models, the method that we   propose utilizes attention parameters exclusively on the data itself   (e.g. on the random walk), and are not used by the model for inference.   We experiment on link prediction tasks, as we aim to produce embeddings   that best-preserve the graph structure, generalizing to unseen   information. We improve state-of-the-art results on a comprehensive   suite of real-world graph datasets including social, collaboration, and   biological networks, where we observe that our graph attention model  can  reduce the error by up to 20%-40%. We show that our   automatically-learned attention parameters can vary significantly per   graph, and correspond to the optimal choice of hyper-parameter if we   manually tune existing methods.",0,21
97,2019-3-11,2019,3,11,22,aztle3,Deep Neural Networks &amp; Image Captioning,https://www.reddit.com/r/deeplearning/comments/aztle3/deep_neural_networks_image_captioning/,lauram16_hello,1552311757,,0,2
98,2019-3-11,2019,3,11,23,aztxg7,Find AI and deep learning jobs,https://www.reddit.com/r/deeplearning/comments/aztxg7/find_ai_and_deep_learning_jobs/,ai_jobs,1552313682,,3,8
99,2019-3-12,2019,3,12,2,azw0bj,Introducing TensorFlow Federated,https://www.reddit.com/r/deeplearning/comments/azw0bj/introducing_tensorflow_federated/,Karthik9999,1552324672,,0,20
100,2019-3-12,2019,3,12,3,azx5iv,What is the time complexity of object localization?,https://www.reddit.com/r/deeplearning/comments/azx5iv/what_is_the_time_complexity_of_object_localization/,skyline678,1552330356,"## Given an image of size O(N) pixels, or some features of size O(N), how fast is modern-day object localization, in big-O notation?

## For example, I'd like my model to localize cars. I use some SVM to obtain features, then pass those to a localizer. Based on the O(N) features, it's possible to find the maximum within them in O(N^1.5) time.",4,1
101,2019-3-12,2019,3,12,8,b008vj,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/b008vj/how_neural_networks_work_simply_explained/,DiscoverAI,1552345651,,1,6
102,2019-3-12,2019,3,12,10,b021c6,What are good DL topics for research in 2019?,https://www.reddit.com/r/deeplearning/comments/b021c6/what_are_good_dl_topics_for_research_in_2019/,GabiruAttack,1552355840,I'm looking for a topic for my master degree but I can't decide. Is NLP or reinforcement learning still hot this year? Thanks.,12,15
103,2019-3-12,2019,3,12,11,b02fu6,[Help] Variable length CNN in Keras,https://www.reddit.com/r/deeplearning/comments/b02fu6/help_variable_length_cnn_in_keras/,pk12_,1552358309,How to make CNNs work when I have variable length signals?,0,1
104,2019-3-12,2019,3,12,17,b05a06,Year-Long AI Fellowships,https://www.reddit.com/r/deeplearning/comments/b05a06/yearlong_ai_fellowships/,the_new_scientist,1552378795,"Other than Google, Facebook, and OpenAI, what other companies offer 1 year research fellowships for post masters students?",3,14
105,2019-3-12,2019,3,12,17,b05heu,Needing a cloud desktop with a GPU... Any good services out there?,https://www.reddit.com/r/deeplearning/comments/b05heu/needing_a_cloud_desktop_with_a_gpu_any_good/,ZeroMaxinumXZ,1552380647,"Hello.  I'm a self-proclaimed ""AI researcher"" (double quotes to not insult the real AI researchers here). I'd like a GPU-enabled cloud desktop to continue my research, as I'm running Tensorflow on a pretty ok but definitely not a GPU, CPU.. I'm wondering if anyone has any good recommendations. I know about Colab but I need a desktop preferably running Ubuntu...",9,3
106,2019-3-12,2019,3,12,18,b05l0f,[  ] /,https://www.reddit.com/r/deeplearning/comments/b05l0f/__/,Afault,1552381462,"Location: Shenzhen, Beijing

&amp;#x200B;

Jobs provided : Software Engineer (C/C++/Java/Python/Golang/PHP), Big Data Engineer, Algorithm Engineer , Data Mining Engineer and Front-end Engineer. (internship/ full time)

&amp;#x200B;

Who we are We are ByteDance risk-control department. We have offices in Shenzhen, Beijing and you are free to choose where you work.

&amp;#x200B;

We are looking for several different  kind of engineers, and we have work like big data processing, build system, data mining, machine learning and NLP algorithms. We welcome different technical backgrounds engineer and we value problem solving skills more than specific language or framework. 

&amp;#x200B;

Requirements:

&amp;#x200B;

B.S. or M.S. (preferred) degree in Computer Science or related technical field. We also welcome self-taught programmers but you need to show equivalent knowledge or experience, especially basic data structures and algorithm.

&amp;#x200B;

Specific jobs and requirements see this link:

[https://mp.weixin.qq.com/s?\_\_biz=Mzg2NTA2MTI3OQ==&amp;mid=100000022&amp;idx=1&amp;sn=76461bcf2fc66624f5f6beffa79d2123&amp;chksm=4e5e91e6792918f0b46ab0abba76b663e332116a3d2dc4b200642f133fb4a127affa64e10f30&amp;mpshare=1&amp;scene=1&amp;srcid=0309M1ykbvLYpqrRHvkxSmyv#rd](https://mp.weixin.qq.com/s?__biz=Mzg2NTA2MTI3OQ==&amp;mid=100000022&amp;idx=1&amp;sn=76461bcf2fc66624f5f6beffa79d2123&amp;chksm=4e5e91e6792918f0b46ab0abba76b663e332116a3d2dc4b200642f133fb4a127affa64e10f30&amp;mpshare=1&amp;scene=1&amp;srcid=0309M1ykbvLYpqrRHvkxSmyv#rd)

&amp;#x200B;

Contact:

&amp;#x200B;

PM  (I will refer you if you are qualified) or send your resume to guanjianchun@bytedance.com",0,1
107,2019-3-12,2019,3,12,19,b06ejy,"""Build a Q&amp;A bot with DeepLearning4J"" with Willem Meints (45min from GOTO Berlin 2018)",https://www.reddit.com/r/deeplearning/comments/b06ejy/build_a_qa_bot_with_deeplearning4j_with_willem/,goto-con,1552388140,,1,0
108,2019-3-12,2019,3,12,21,b06zsn,"A PyTorch implementation of ""Signed Graph Convolutional Network"" (ICDM 2018).",https://www.reddit.com/r/deeplearning/comments/b06zsn/a_pytorch_implementation_of_signed_graph/,benitorosenberg,1552392262,"&amp;#x200B;

https://i.redd.it/uvbm9d7phol21.jpg

&amp;#x200B;

Paper: [https://github.com/benedekrozemberczki/SGCN/blob/master/sgcn.pdf](https://github.com/benedekrozemberczki/SGCN/blob/master/sgcn.pdf)

Python: [https://github.com/benedekrozemberczki/SGCN/](https://github.com/benedekrozemberczki/SGCN/)

ABSTRACT:

Due  to the fact much of today's data can be represented as graphs, there   has been a demand for generalizing neural network models for graph   data. One recent direction that has shown fruitful results, and   therefore growing interest, is the usage of graph convolutional neural   networks (GCNs). They have been shown to provide a significant   improvement on a wide range of tasks in network analysis, one of which   being node representation learning. The task of learning low-dimensional   node representations has shown to increase performance on a plethora  of  other tasks from link prediction and node classification, to  community  detection and visualization. Simultaneously, signed networks  (or graphs  having both positive and negative links) have become  ubiquitous with the  growing popularity of social media. However, since  previous GCN models  have primarily focused on unsigned networks (or  graphs consisting of  only positive links), it is unclear how they could  be applied to signed  networks due to the challenges presented by  negative links. The primary  challenges are based on negative links  having not only a different  semantic meaning as compared to positive  links, but their principles are  inherently different and they form  complex relations with positive  links. Therefore we propose a dedicated  and principled effort that  utilizes balance theory to correctly  aggregate and propagate the  information across layers of a signed GCN  model. We perform empirical  experiments comparing our proposed signed  GCN against state-of-the-art  baselines for learning node  representations in signed networks. More  specifically, our experiments  are performed on four real-world datasets  for the classical link sign  prediction problem that is commonly used as  the benchmark for signed  network embeddings algorithms.",0,2
109,2019-3-13,2019,3,13,0,b0973h,"DeepCamera: Turn digital camera into AI-powered video surveillance on embedded Linux/Android. ArcFace, MTCNN, Object Detection and REiD for production",https://www.reddit.com/r/deeplearning/comments/b0973h/deepcamera_turn_digital_camera_into_aipowered/,solderzzc,1552405223,,1,25
110,2019-3-13,2019,3,13,1,b09tgg,[Q] is there a percentage of actual to augmented data?,https://www.reddit.com/r/deeplearning/comments/b09tgg/q_is_there_a_percentage_of_actual_to_augmented/,pk12_,1552408343,"Should I have 20% augmented data in training with 80% actual data?

Are there any such guidelines?",1,0
111,2019-3-13,2019,3,13,2,b0a8gm,"Indian student, no interest in education system and want to do research in deep learning",https://www.reddit.com/r/deeplearning/comments/b0a8gm/indian_student_no_interest_in_education_system/,arshad_221b,1552410404,"I'm an Indian **engineering** student. I want to do my career in deep learning. I'm in 3rd year now. I've been studying machine learning from last 6 months now. I've done some courses online and done some basic projects. Thing is, I don't have any interest in education system. This University syllabus feels like I'm learning what they want to teach me, not what I want to learn. 
I'm confused and somewhat scared. I don't want job in TCS like mass recruiters(I'm will end up there if I don't do anything,low pointer guy). I want to do research in deep learning. Right now I don't have any exposure for that. 
I don't want to go abroad and do PhD. (most researchers say we don't need a PhD to do research in ML(just a fact)) 
What should I do? Where to find a job like that? (_  ) ",4,0
112,2019-3-13,2019,3,13,6,b0d6wp,Dataset recommendation,https://www.reddit.com/r/deeplearning/comments/b0d6wp/dataset_recommendation/,khronoskaiross,1552425263,"Hey guys,
So I've been working on a computer vision problem. And would like a dataset with 3D models and their corresponding 2D images. I read about ObjectNet3D, does anybody have any experience on that? And also would it be better to use a set like ShapeNet and then calculate viewpoints and maybe use ray tracing to extract 2d shape? ",1,5
113,2019-3-13,2019,3,13,12,b0h8h1,Tensorflow2.0 YouTube Tutorial!!,https://www.reddit.com/r/deeplearning/comments/b0h8h1/tensorflow20_youtube_tutorial/,shawnmanuel000,1552447936,"Hey guys, I made a YouTube tutorial to help beginners learn to code their own neural networks with the high level API of Tensorflow2.0 as well as from the low level building blocks for custom models. Hope it helps with adapting to the new version of tf which is much easier to use than the first version!

Link: [https://www.youtube.com/watch?v=fQCKxzHvYnw](https://www.youtube.com/watch?v=fQCKxzHvYnw)

PS: My next tutorial would probably be something similar for tensorflow.js which I can also post here if people are interested.",3,39
114,2019-3-13,2019,3,13,14,b0i2zx,"Dive into Deep Learning (2019) Book By: Aston Zhang, Zachary C. Lipton, Mu Li, Alexander J. Smola Reference: Introduction to Deep Learning STAT 157, University of California, Berkeley, Spring, 2019 UC Berkeley #DeepLearning #machinelearning #artificialintelligence",https://www.reddit.com/r/deeplearning/comments/b0i2zx/dive_into_deep_learning_2019_book_by_aston_zhang/,aiforworld2,1552453705,,0,12
115,2019-3-13,2019,3,13,18,b0jswp,Trouble building caffe from source,https://www.reddit.com/r/deeplearning/comments/b0jswp/trouble_building_caffe_from_source/,atinesh229,1552467863,"I am trying to install caffe by building it from [source](https://github.com/BVLC/caffe)

After issuing the following command from the caffe root directory

    $ make all -j4

I am getting an error

    ...
    CXX src/caffe/layer_factory.cpp
    CXX src/caffe/blob.cpp
    AR -o .build_release/lib/libcaffe.a
    LD -o .build_release/lib/libcaffe.so.1.0.0 
    /usr/bin/x86_64-linux-gnu-ld: cannot find -lpython3.6
    collect2: error: ld returned 1 exit status
    Makefile:582: recipe for target '.build_release/lib/libcaffe.so.1.0.0' failed
    make: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1

**Dependencies installed**

    $ sudo apt install python3-opencv
    $ sudo apt-get install libatlas-base-dev
    $ sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler
    $ sudo apt-get install --no-install-recommends libboost-all-dev
    $ sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev
    $ sudo apt-get install the python3-dev

**CUDA**: CUDA 9, CuDnn 7.4

**Ubuntu**: Ubuntu 18.04

[Makefile.config](https://www.dropbox.com/s/yib5afza5zyytfx/Makefile.config?dl=0)

&amp;#x200B;

I have looked at all the [issues](https://github.com/BVLC/caffe/issues) in the source Github repository but couldn't find anything useful.",0,1
116,2019-3-13,2019,3,13,23,b0mfjp,Latest research papers on deep reinforcement learning?,https://www.reddit.com/r/deeplearning/comments/b0mfjp/latest_research_papers_on_deep_reinforcement/,ZeroMaxinumXZ,1552486156,"I want some of the latest research papers on deep reinforcement learning,  Any recommendations?",0,2
117,2019-3-14,2019,3,14,2,b0optk,ChatBot With WhatsApp Conversation.,https://www.reddit.com/r/deeplearning/comments/b0optk/chatbot_with_whatsapp_conversation/,code_crawler,1552498249,"Anyone here created or tried to create a chatBot with WhatsApp Conversation as a the Train Data?
I wonder how sarcastic the Bot's gonna be....!!",0,1
118,2019-3-14,2019,3,14,2,b0otgs,[P] Reinforcement Learning With Unity 3D: Cleaning up at the Oktoberfest!,https://www.reddit.com/r/deeplearning/comments/b0otgs/p_reinforcement_learning_with_unity_3d_cleaning/,dtransposed,1552498729,"&amp;#x200B;

https://i.redd.it/al7p0eq8axl21.png

Hello! Me and my team have recently created a prototype of an intelligent agent for garbage collection.  

The goal of the agent is collect relevant pieces of garbage, while avoiding collisions with static objects (such as chairs or tables). The  agent navigates in the environment (a mock-up of German Oktoberfest  tent) using camera RBG-D input. 

&amp;#x200B;

The blog post also contains a link to GitHub Repo:

[https://dtransposed.github.io/blog/GEAR.html](https://dtransposed.github.io/blog/GEAR.html)",2,18
119,2019-3-14,2019,3,14,11,b0v2dh,PyTorch 1.0 Now and In the Future || Adam Paszke,https://www.reddit.com/r/deeplearning/comments/b0v2dh/pytorch_10_now_and_in_the_future_adam_paszke/,MarkOliver908,1552531740,,0,4
120,2019-3-14,2019,3,14,15,b0ws77,What deep learning applications do you find to be too slow?,https://www.reddit.com/r/deeplearning/comments/b0ws77/what_deep_learning_applications_do_you_find_to_be/,thevillaincassiopeia,1552543690,I am interested in working on parallel computing and deep learning. I know that training time is the most obvious problem in deep learning. But I am wondering if there are any applications that you find to be very slow. I could maybe work on accelerating that for my next project. ,2,1
121,2019-3-14,2019,3,14,16,b0xldh,How would I create a spiking neural network in tensorflow?,https://www.reddit.com/r/deeplearning/comments/b0xldh/how_would_i_create_a_spiking_neural_network_in/,ZeroMaxinumXZ,1552550170,"I know very little about SNNs, so... From what I can infer, a spiking neural network consists of spikes of energy using a biological model of neurons... I don't really know much about them. So, where can I go to learn about these, and more importantly how would I create one in tensorflow?",9,12
122,2019-3-14,2019,3,14,17,b0xvc6,Best tutorial to get started with TensorFlow,https://www.reddit.com/r/deeplearning/comments/b0xvc6/best_tutorial_to_get_started_with_tensorflow/,AdventurousMine8,1552552551,"So I have been reading Goodfellow's and now I want to get my hands dirty and implement some things in TensorFlow. What tutorial do you guys suggest?

&amp;#x200B;

I already have experience in programming in Python.",2,7
123,2019-3-14,2019,3,14,18,b0y57i,"A PyTorch implementation of ""Graph Classification Using Structural Attention"" (KDD 2018).",https://www.reddit.com/r/deeplearning/comments/b0y57i/a_pytorch_implementation_of_graph_classification/,benitorosenberg,1552554967,"&amp;#x200B;

https://i.redd.it/4zl5d7agx1m21.jpg

&amp;#x200B;

Python: [https://github.com/benedekrozemberczki/GAM](https://github.com/benedekrozemberczki/GAM)

Paper: [https://github.com/benedekrozemberczki/GAM/blob/master/paper.pdf](https://github.com/benedekrozemberczki/GAM/blob/master/paper.pdf)

Abstract:

Graph  classification is a problem with practical applications in many   different domains. To solve this problem, one usually calculates certain   graph statistics (i.e., graph features) that help discriminate between   graphs of different classes. When calculating such features, most   existing approaches process the entire graph. In a graphlet-based   approach, for instance, the entire graph is processed to get the total   count of different graphlets or subgraphs. In many real-world   applications, however, graphs can be noisy with discriminative patterns   confined to certain regions in the graph only. In this work, we study   the problem of attention-based graph classification . The use of   attention allows us to focus on small but informative parts of the   graph, avoiding noise in the rest of the graph. We present a novel RNN   model, called the Graph Attention Model (GAM), that processes only a   portion of the graph by adaptively selecting a sequence of informative   nodes. Experimental results on multiple real-world datasets show that   the proposed method is competitive against various well-known methods  in  graph classification even though our method is limited to only a  portion of the graph.",0,4
124,2019-3-14,2019,3,14,18,b0y8tm,Awesome papers and reviews [with codes!] on Computer Vision News of March. Links for free reading!,https://www.reddit.com/r/deeplearning/comments/b0y8tm/awesome_papers_and_reviews_with_codes_on_computer/,Gletta,1552555829,"Here are the links to the March 2019 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: many articles about Artificial Intelligence, Deep Learning, Computer Vision and more. Free subscription on page 34.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019March/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-march-pdf/)

Enjoy!",0,43
125,2019-3-14,2019,3,14,21,b0zx7y,Just wrote a Medium post on how to serve TensorFlow models with Docker via REST API. It's an end-to-end minimum example with documented Notebook. Hope it helps.,https://www.reddit.com/r/deeplearning/comments/b0zx7y/just_wrote_a_medium_post_on_how_to_serve/,jingw222,1552567635,,0,13
126,2019-3-15,2019,3,15,0,b11tew,Intro To Deep Learning: Taught by a 14-Year-Old,https://www.reddit.com/r/deeplearning/comments/b11tew/intro_to_deep_learning_taught_by_a_14yearold/,jakemalis,1552578088,"Hello everyone! I just wrote an article for a website, Medium, where I talk about how AI and Deep Learning will impact our future, how it works, and why it may be dangerous. Feel free to check it out and give it a clap @ [https://medium.com/@jakemalis/intro-to-deep-learning-taught-by-a-14-year-old-6c49fc94d66](https://medium.com/@jakemalis/intro-to-deep-learning-taught-by-a-14-year-old-6c49fc94d66).",0,0
127,2019-3-15,2019,3,15,3,b13ymp,What skills to gain if I want to become deep learning engineer?,https://www.reddit.com/r/deeplearning/comments/b13ymp/what_skills_to_gain_if_i_want_to_become_deep/,sanchit2843,1552588557,"Hello,

I am an undergraduate and studying deep learning for last two years. Can anyone suggest some skills such as sql that companies expect from deep learning engineer. Also, what should I study now so that I can become better in the field. Please suggest. 

Thanks in advance. ",1,1
128,2019-3-15,2019,3,15,4,b14vg8,Deep Learning: When Should You Use It?,https://www.reddit.com/r/deeplearning/comments/b14vg8/deep_learning_when_should_you_use_it/,edxsocial,1552593039,"The author writes: there are alternatives that may not be as complex, such as traditional machine learning. In cases with smaller datasets and simpler correlations, techniques like KNN or random forest may be more appropriate and effective said Sheldon Fernandez, who is the CEO of [DarwinAI](https://darwinai.ca/). A deep learning model might easily get a problematic or nonsensical correlation, said Sheldon,. That is, the network might draw conclusions based on quirks in the dataset that are catastrophic from a practical point of view.

[https://www.forbes.com/sites/tomtaulli/2019/03/09/deep-learning-when-should-you-use-it/](https://www.forbes.com/sites/tomtaulli/2019/03/09/deep-learning-when-should-you-use-it/#6bfc01e94e36)",2,1
129,2019-3-15,2019,3,15,7,b16z1n,3D UNet in TensorFlow,https://www.reddit.com/r/deeplearning/comments/b16z1n/3d_unet_in_tensorflow/,bayeslaw,1552603387,"If anyone interested

[repo](https://github.com/danielhomola/3D_UNet)",0,7
130,2019-3-15,2019,3,15,11,b196lr,How to modify Adaline Stochastic gradient descent,https://www.reddit.com/r/deeplearning/comments/b196lr/how_to_modify_adaline_stochastic_gradient_descent/,vokoyo,1552616132,"&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

**Dear**

&amp;#x200B;

May I know how to modify my own Python programming so that I will get the

**same picture** as refer to the attached file - Adaline Stochastic gradient descent

(I am using the Anaconda Python 3.7)

&amp;#x200B;

**Prayerfully**

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

Tron Orino Yeong

[tcynotebook@yahoo.com](mailto:tcynotebook@yahoo.com)

0916643858

  


&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

    from matplotlib.colors import ListedColormap
    import matplotlib.pyplot as plt
    import numpy as np
    from numpy.random import seed
    import pandas as pd
    
    # Stochastic Gradient Descent
    class SGD(object):
       def __init__(self, rate = 0.01, niter = 10,
                    shuffle=True, random_state=None):
          self.rate = rate
          self.niter = niter
          self.weight_initialized = False
    
          # If True, Shuffles training data every epoch
          self.shuffle = shuffle
    
          # Set random state for shuffling and initializing the weights.
          if random_state:
             seed(random_state)
    
       def fit(self, X, y):
          """"""Fit training data
          X : Training vectors, X.shape : [#samples, #features]
          y : Target values, y.shape : [#samples]
          """"""
    
          # weights
          self.initialize_weights(X.shape[1])
    
          # Cost function
          self.cost = []
    
          for i in range(self.niter):
             if self.shuffle:
                X, y = self.shuffle_set(X, y)
             cost = []
             for xi, target in zip(X, y):
                cost.append(self.update_weights(xi, target))
             avg_cost = sum(cost)/len(y)
             self.cost.append(avg_cost)
          return self
    
       def partial_fit(self, X, y):
          """"""Fit training data without reinitializing the weights""""""
          if not self.weight_initialized:
             self.initialize_weights(X.shape[1])
          if y.ravel().shape[0] &gt; 1:
             for xi, target in zip(X, y):
                self.update_weights(xi, target)
          else:
             self.up
          return self
    
       def shuffle_set(self, X, y):
          """"""Shuffle training data""""""
          r = np.random.permutation(len(y))
          return X[r], y[r]
    
       def initialize_weights(self, m):
          """"""Initialize weights to zeros""""""
          self.weight = np.zeros(1 + m)
          self.weight_initialized = True
    
       def update_weights(self, xi, target):
          """"""Apply SGD learning rule to update the weights""""""
          output = self.net_input(xi)
          error = (target - output)
          self.weight[1:] += self.rate * xi.dot(error)
          self.weight[0] += self.rate * error
          cost = 0.5 * error**2
          return cost
    
       def net_input(self, X):
          """"""Calculate net input""""""
          return np.dot(X, self.weight[1:]) + self.weight[0]
    
       def activation(self, X):
          """"""Compute linear activation""""""
          return self.net_input(X)
    
       def predict(self, X):
          """"""Return class label after unit step""""""
          return np.where(self.activation(X) &gt;= 0.0, 1, -1)
    
    def plot_decision_regions(X, y, classifier, resolution=0.02):
       # setup marker generator and color map
       markers = ('s', 'x', 'o', '^', 'v')
       colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
       cmap = ListedColormap(colors[:len(np.unique(y))])
    
       # plot the decision surface
       x1_min, x1_max = X[:,  0].min() - 1, X[:, 0].max() + 1
       x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
       xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
       np.arange(x2_min, x2_max, resolution))
       Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
       Z = Z.reshape(xx1.shape)
       plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)
       plt.xlim(xx1.min(), xx1.max())
       plt.ylim(xx2.min(), xx2.max())
    
       # plot class samples
       for idx, cl in enumerate(np.unique(y)):
          plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],
          alpha=0.8, c=cmap(idx),
          marker=markers[idx], label=cl)
    
    df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)
    
    y = df.iloc[0:100, 4].values
    y = np.where(y == 'Iris-setosa', -1, 1)
    X = df.iloc[0:100, [0, 2]].values
    
    # standardize
    X_std = np.copy(X)
    X_std[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
    X_std[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()
    
    sgd1 = SGD(niter=100, rate=0.01, random_state=1)
    sgd2 = SGD(niter=50, rate=0.01, random_state=1)
    sgd3 = SGD(niter=10, rate=0.01, random_state=1)
    
    sgd1.fit(X_std, y)
    sgd2.fit(X_std, y)
    sgd3.fit(X_std, y)
    
    plt.plot(range(1, len(sgd1.cost) + 1), sgd1.cost, 
             marker='o', linestyle='oo', label='batch=1')
    plt.plot(range(1, len(sgd2.cost_) + 1), np.array(sgd2.cost_) / len(y_train), 
             marker='o', linestyle='--', label='batch=2')
    plt.plot(range(1, len(sgd3.cost_) + 1), np.array(sgd3.cost_) / len(y_train), 
             marker='o', linestyle='xx', label='batch=3')
    
    plt.xlabel('Epochs')
    plt.ylabel('Average Cost')
    plt.show()
    
    

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/9aw6sjf7z6m21.jpg

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/7c59caj8z6m21.jpg

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",0,0
131,2019-3-15,2019,3,15,21,b1e8y6,Is there going to be a part 2 of the machine learning course by fastai?,https://www.reddit.com/r/deeplearning/comments/b1e8y6/is_there_going_to_be_a_part_2_of_the_machine/,sanjaynath,1552652388,In the first part part Jeremy mentions that he will go into Gradient Boosting etc. in part 2. Is part 2 out already? If not any idea when is it going to be out? ,5,4
132,2019-3-15,2019,3,15,21,b1ekkr,How to do parameters estimation and choice of machine?,https://www.reddit.com/r/deeplearning/comments/b1ekkr/how_to_do_parameters_estimation_and_choice_of/,nisucuk,1552654297," 

Dear Friends, I have to work on concept detection(treated as a multi-label classification) problem.

I have to choose between 

1) SGI UV 2000 (venus) ,

For highly parallel and data intensive HPC applications

\- ca. 6400 Cores Intel Sandy Bridge and Westmere, 34000 Cores Intel Haswell and ca. 900 Intel Broadwell Cores with various memory configurations,\- 344 GPUs (K80, K20Xm),\- Bullx Linux, Batch system Slurm 

And 
2) Bull Cluster (Taurus)

for memory intensive calculations

\- 512 Cores Intel Sandy Bridge, 2,6 GHz, \- 8 TB shared memory,\- SuSE Linux Enterprise Server

\- Batch system SLURM, \- 10,6 TFlop/s Peak PerformancE 

I have to estimate  several parameters such as CPU time, GPU-count(hrs), CPU-count per unit job, memory per core(Gbyte), Scratch -temporary(G-Byte)

i have a training set of 56,630 Images(max. size=220kb), validation set of 14,120 images .

can anybody kindly guide me on how to estimate it, and on what factors does it depend?",0,1
133,2019-3-15,2019,3,15,22,b1f5dr,Deep Autoencoder-like Nonnegative Matrix Factorization for Community Detection (CIKM 2018).,https://www.reddit.com/r/deeplearning/comments/b1f5dr/deep_autoencoderlike_nonnegative_matrix/,benitorosenberg,1552657574,"&amp;#x200B;

https://i.redd.it/zmzh8g9leam21.jpg

&amp;#x200B;

Paper: [https://github.com/benedekrozemberczki/DANMF/blob/master/18DANMF.pdf](https://github.com/benedekrozemberczki/DANMF/blob/master/18DANMF.pdf)

Python: [https://github.com/benedekrozemberczki/DANMF](https://github.com/benedekrozemberczki/DANMF)

ABSTRACT:

Community  structure is ubiquitous in real-world complex networks. The  task of  community detection over these networks is of paramount  importance in a  variety of applications. Recently, nonnegative matrix  factorization  (NMF) has been widely adopted for community detection due  to its great  interpretability and its natural fitness for capturing the  community  membership of nodes. However, the existing NMF-based community   detection approaches are shallow methods. They learn the community   assignment by mapping the original network to the community membership   space directly. Considering the complicated and diversified topology   structures of real-world networks, it is highly possible that the   mapping between the original network and the community membership space   contains rather complex hierarchical information, which cannot be   interpreted by classic shallow NMF-based approaches. Inspired by the   unique feature representation learning capability of deep autoencoder,   we propose a novel model, named Deep Autoencoder-like NMF (DANMF), for   community detection. Similar to deep autoencoder, DANMF consists of an   encoder component and a decoder component. This architecture empowers   DANMF to learn the hierarchical mappings between the original network   and the final community  assignment  with  implicit  low-to-high  level    hidden attributes of the original network learnt in the intermediate   layers. Thus, DANMF should be better suited to the community detection   task. Extensive experiments on benchmark datasets demonstrate that DANMF   can achieve better performance than the state-of-the-art NMF-based   community detection approaches.",0,13
134,2019-3-15,2019,3,15,23,b1fqd1,Questions regarding chapter 19 of Deep Learning textbook,https://www.reddit.com/r/deeplearning/comments/b1fqd1/questions_regarding_chapter_19_of_deep_learning/,sriharsha_0806,1552660770,"Are there any coding repositories with toy datasets which explains EM and MAP Inference algorithms of chapter 19 of deep learning textbook? At the end of fourth paragraph of Expectation Maximization, The book mentions ""The E-step reduces the gap to zero again as we enter the loop for the next time"". How does E-step reduces the gap?",2,1
135,2019-3-16,2019,3,16,0,b1ggpu,Stanford University Launches Human-Centered AI Institute Led by John Etchemendy &amp; Fei-Fei Li,https://www.reddit.com/r/deeplearning/comments/b1ggpu/stanford_university_launches_humancentered_ai/,Yuqing7,1552664713,,0,5
136,2019-3-16,2019,3,16,2,b1htwf,Keras for Beginners,https://www.reddit.com/r/deeplearning/comments/b1htwf/keras_for_beginners/,limapedro,1552671694,"I made a 15 videos series on Keras for beginners, when I was starting learning I thought that was a lack on how to start using keras, so I did this series help this can be useful for you too. [https://www.youtube.com/playlist?list=PLJ1jRXwHYGNpSKcSVm117e5hy\_xTwsNrS](https://www.youtube.com/playlist?list=PLJ1jRXwHYGNpSKcSVm117e5hy_xTwsNrS)",4,60
137,2019-3-16,2019,3,16,2,b1hu73,AI For Good Idea Challenge - Microsoft AI Lab,https://www.reddit.com/r/deeplearning/comments/b1hu73/ai_for_good_idea_challenge_microsoft_ai_lab/,ConfidentMushroom,1552671737,,0,8
138,2019-3-16,2019,3,16,7,b1l304,Deep learning for molecular generation and optimization - a review of the state of the art,https://www.reddit.com/r/deeplearning/comments/b1l304/deep_learning_for_molecular_generation_and/,delton,1552688681,,0,1
139,2019-3-16,2019,3,16,10,b1n6wc,Are there any resources for engineering practices in deep learning?,https://www.reddit.com/r/deeplearning/comments/b1n6wc/are_there_any_resources_for_engineering_practices/,alias_is,1552701410,Currently I am able to implement few convolutional architecture as well as recurrent networks. But the way I do is very messy and doesn't seem like engineering solution. I come from computer engineering background and would like to learn some good techniques as well as procedures for creating deep learning based solutions and architectures. ,2,4
140,2019-3-16,2019,3,16,13,b1omhy,Deep Learning For Developers,https://www.reddit.com/r/deeplearning/comments/b1omhy/deep_learning_for_developers/,AndyMerskinon,1552711110,[http://on.geeklearn.net/c2110fccf8](http://on.geeklearn.net/c2110fccf8),0,3
141,2019-3-16,2019,3,16,14,b1p518,Converting dataset into a HDF5 file,https://www.reddit.com/r/deeplearning/comments/b1p518/converting_dataset_into_a_hdf5_file/,root__007,1552715122,,0,1
142,2019-3-16,2019,3,16,14,b1p8bw,"hello . I've decided to creat a podcast about deep learning  machine learning  artifical inteligence , neuroscience ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ?",https://www.reddit.com/r/deeplearning/comments/b1p8bw/hello_ive_decided_to_creat_a_podcast_about_deep/,Doctor_who1,1552715876," hello . I've decided to creat a podcast about deep learning  machine learning  artifical inteligence  , neuroscience  ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ? ",6,0
143,2019-3-16,2019,3,16,15,b1pbm4,Converting dataset into a HDF5 file,https://www.reddit.com/r/deeplearning/comments/b1pbm4/converting_dataset_into_a_hdf5_file/,root__007,1552716623,"Hi guys

I wanna convert a facial expressions dataset into a HDF5 file and I don't know how exactly to do it.

from [here](http://www.machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html) I know how to do it with a cat-vs-dog dataset but I wanna know how it's done in general.

(My purpose of all these is to speed up my CNN model training process in google colaboratory and I tried this by mounting google drive and consequently reading my dataset from google drive but it was too slow to train my model (even slower than my pc !) ).",11,1
144,2019-3-17,2019,3,17,2,b1uljc,Autonomous Driving Back Propagation and Genetic Algorithm,https://www.reddit.com/r/deeplearning/comments/b1uljc/autonomous_driving_back_propagation_and_genetic/,DevTechRetopall,1552755604,,0,8
145,2019-3-17,2019,3,17,3,b1vhg3,Conv nets vs nlp,https://www.reddit.com/r/deeplearning/comments/b1vhg3/conv_nets_vs_nlp/,endeavour23,1552760557,"I'm a software consultant on middleware technologies, and from the past year, i've been learning ML, deep learning &amp; CNN's. Deep learning blew my mind, and with great passion, I did some certifications on deep learning, and completed lectures like cs231n being in a job that demands atleast 10 hrs of work. I really want to shift my career into AI . 

This qn is to the experts in DL - should I explore more of CNN's and take that route, or explore the field of DL in other fields like recurrent nets, NLP or reinforcement learning. If I wanna plan my future 10 years, should I be learning the full stack? I'm talking in terms of job opportunities and career growth.

&amp;#x200B;

Also, CNN vs NLP - jobs wise - which is better?",4,7
146,2019-3-17,2019,3,17,7,b1y32y,"I ranked the Best TensorFlow Courses on the internet, based on your reviews",https://www.reddit.com/r/deeplearning/comments/b1y32y/i_ranked_the_best_tensorflow_courses_on_the/,skj8,1552774656,,8,22
147,2019-3-17,2019,3,17,14,b21t3o,How do make a Pytorch dataloader for a pandas dataframe? why do we need a seperate batch everytime we loop the model?,https://www.reddit.com/r/deeplearning/comments/b21t3o/how_do_make_a_pytorch_dataloader_for_a_pandas/,n_unjum,1552799393,"   

I am having a very difficult time making a data loader for pytorch. I have columnar data in train  
 and test  
 set. How do I make a dataloader and how do i implement it on my GPU? Also why do we need seperate batches everytime we loop?",8,7
148,2019-3-17,2019,3,17,16,b22zab,Stateless vs Stateful LSTM in practice?,https://www.reddit.com/r/deeplearning/comments/b22zab/stateless_vs_stateful_lstm_in_practice/,jeril_rebooted_2k17,1552809596,"I've read a lot of sources on stateless vs stateful LSTMs, but I couldn't understand the practical difference between the 2, as in what the practical outcome would be, if I apply it in a Keras-powered Python code. And also, where should each type be applied or avoided? Kindly help me understand this better. Thank you.

&amp;#x200B;

P.S.: For stock market price prediction, which type of LSTM is best suited?",0,6
149,2019-3-17,2019,3,17,18,b23btr,"A PyTorch Implementation of ""SINE: Scalable Incomplete Network Embedding"" (ICDM 2018).",https://www.reddit.com/r/deeplearning/comments/b23btr/a_pytorch_implementation_of_sine_scalable/,benitorosenberg,1552813250,"&amp;#x200B;

https://i.redd.it/of4p09mg9nm21.jpg

Paper: [https://github.com/benedekrozemberczki/SINE/blob/master/paper.pdf](https://github.com/benedekrozemberczki/SINE/blob/master/paper.pdf)

PyTorch: [https://github.com/benedekrozemberczki/SINE](https://github.com/benedekrozemberczki/SINE)

Abstract:

Attributed  network embedding aims to learn low-dimensional vector  representations  for nodes in a network, where each node contains rich   attributes/features describing node content. Because network topology   structure and node attributes often exhibit high correlation,  incorporating node attribute proximity into network embedding is   beneficial for learning good vector representations. In reality,   large-scale networks often have incomplete/missing node content or   linkages, yet existing attributed network embedding algorithms all   operate under the assumption that networks are complete. Thus, their   performance is vulnerable to missing data and suffers from poor  scalability. In this paper, we propose a Scalable Incomplete Network   Embedding (SINE) algorithm for learning node representations from   incomplete graphs. SINE formulates a probabilistic learning framework   that separately models pairs of node-context and node-attribute   relationships. Different from existing attributed network embedding   algorithms, SINE provides greater flexibility to make the best of useful   information and mitigate negative effects of missing information on   representation learning. A stochastic gradient descent based online   algorithm is derived to learn node representations, allowing SINE to   scale up to large-scale networks with high learning efficiency. We   evaluate the effectiveness and efficiency of SINE through extensive   experiments on real-world networks. Experimental results confirm that   SINE outperforms state-of-the-art baselines in various tasks, including   node classification, node clustering, and link prediction, under   settings with missing links and node attributes. SINE is also shown to  be scalable and efficient on large-scale networks with millions of   nodes/edges and high-dimensional node features.",0,17
150,2019-3-18,2019,3,18,4,b28nb5,Object Detection Deep Learning Image Analysis for Classification,https://www.reddit.com/r/deeplearning/comments/b28nb5/object_detection_deep_learning_image_analysis_for/,cderekw4224,1552849459,,0,5
151,2019-3-18,2019,3,18,4,b29578,"Deep learning + Music, Music Generation using GAN , How to play songs from the midi images",https://www.reddit.com/r/deeplearning/comments/b29578/deep_learning_music_music_generation_using_gan/,prashantkr314,1552852063,"I am exploring to this repository : [musegan](https://github.com/salu133445/musegan) and tried to exectue it.

My shared [Google Colab Link](https://colab.research.google.com/drive/12Vw3-94YXbOKmNhuBh0TrKrgfZeOVmlQ)

&amp;#x200B;

It executes but i have no idea where do i get the generated music samples or how do i run the music.It produces bunch of `.png` images in the `./exp/`  folder but i don't know how is that helpful for generating music

&amp;#x200B;

even in the ReadMe file of this project the [Results](https://github.com/salu133445/musegan#sample-results) if you download it , it give bunch of images. I have no idea how can i use these images.

&amp;#x200B;

I am new to ML and Deep Learning, I picked this project because i have interest in music and i wanted to get inspired how deep learning will solve this problem.

&amp;#x200B;

i have read about ANN, RNN &amp; CNN  and GAN but i am at a very noob level. But i want to learn this.

I did watch this video of project owner, [Video](https://www.youtube.com/watch?v=SHPjZwSbRhs) But it's in Chinese , i did used [Google Translate (Chinese to English)](https://translate.google.com/?rlz=1C5CHFA_enIN831IN831&amp;um=1&amp;ie=UTF-8&amp;hl=en&amp;client=tw-ob#zh-TW/en/) to convert the audio into english text but it wasn't that great experience.

&amp;#x200B;

These are the slides :      [Slide 1](https://salu133445.github.io/bmusegan/pdf/bmusegan-ismir2018-slides.pdf)[Slide 2](https://salu133445.github.io/musegan/pdf/musegan-aaai2018-slides.pdf)

&amp;#x200B;

&amp;#x200B;

I know this is not the best first project to choose, but this is what interests me so i'll be more happy to invest my time to know about this project.

&amp;#x200B;

My background is in web-development both front-end &amp; back-end.

&amp;#x200B;",9,30
152,2019-3-18,2019,3,18,6,b29y88,Training a CNN on generated Images,https://www.reddit.com/r/deeplearning/comments/b29y88/training_a_cnn_on_generated_images/,zero_as_a_number,1552856436,"hello r/deeplearning

&amp;#x200B;

i am a first time poster and new to the field. i'm a java developer on and off the job 

hence my tool of choice currently is deeplearning4j. after abstracting away some boilerplate i was able to successfully run a network (like can be found in the dl4j [model zoo](https://deeplearning4j.org/docs/latest/deeplearning4j-zoo-overview) because why re-invent the wheel .. ) . i'm looking into doing image classification using convolutional nets 

&amp;#x200B;

i am trying to solve the following problem: given an image of a target, get me the score based upon the position of the projectile point of impact. for my case we would see an arrow sticking in the target (one of them round things..). score is depending on the position of the arrow. 

&amp;#x200B;

to alleviate the need for data scraping i took an available image of a target board and wrote a little tool which renders an arrow on it in lots of different positions (depending on the image size i got around 150k images out of this). this also takes care of labeling the data correctly. but the data is fairly .. static, as in the only thing that changes is the position of the arrow. i also started randomly transforming the images to hopefully help the network generalize a bit better (color inversion, grayscale, cropping, rotation, .. ) What I'm hoping the network would learn is to associate the \_position\_ of the arrow with a certain label (e.g. score of the shot). this gives me 20 labels since my max score currently is 20. 

&amp;#x200B;

Existing models either converged but did not learn the right features or wouldn't converge at all, 

although i did not yet look into transfer learning. 

  

So I'm kind of stuck and wondering .. 

\- is a conv net the right tool for the job? i feel like what i'm trying to do is understanding a scene, rather than 

\- i think my training data may be problematic. a) the largest portion of the images is the target itself, the arrow is rather small in comparison (when considering amount of pixels .. ) b)  there is very little variance between different images (e.g. the arrow is only moved one pixel over, perspective is always the same).. besides some basic image transformations, is there something else i should do?

\- are there specialized architectures for such scenarios - working with small features?

&amp;#x200B;

hope i'm in the right place for those questions :) 

&amp;#x200B;",2,1
153,2019-3-18,2019,3,18,11,b2d2ql,ML in the browser,https://www.reddit.com/r/deeplearning/comments/b2d2ql/ml_in_the_browser/,parmarsuraj,1552874874,"Machine Learning in the Browser using TensorFlow.js

https://link.medium.com/82cl8YX58U",0,1
154,2019-3-18,2019,3,18,11,b2d9z2,Stopping training early when accuracy does not change across epochs,https://www.reddit.com/r/deeplearning/comments/b2d9z2/stopping_training_early_when_accuracy_does_not/,randomicly,1552876179,"I have implemented a NN (in keras) which runs for a large number of epochs. Now when I train the model, I see that the accuracy does not seem to change after a set of epochs.

&amp;#x200B;

Is there any issue with stopping training when accuracy does not change for let's say 5 epochs? What is the common practice implemented in such cases?",15,2
155,2019-3-18,2019,3,18,14,b2eulz,Paper Review:Automatic Liver Segmentation using Unets with Wasserstein GANs,https://www.reddit.com/r/deeplearning/comments/b2eulz/paper_reviewautomatic_liver_segmentation_using/,sayantandas30011998,1552887283,"\~By Sayantan Das ([https://www.linkedin.com/in/sayantan-das-95b50a125/](https://www.linkedin.com/in/sayantan-das-95b50a125/))

&amp;#x200B;",0,11
156,2019-3-18,2019,3,18,18,b2gscs,Intelligent Video Analytics with e-CAM130_CUXVR &amp; DeepStream SDK 3.0,https://www.reddit.com/r/deeplearning/comments/b2gscs/intelligent_video_analytics_with_ecam130_cuxvr/,shaun272,1552903119,,0,3
157,2019-3-18,2019,3,18,20,b2hj29,"A PyTorch implementation of ""Splitter: Learning Node Representations that Capture Multiple Social Contexts"" (WWW 2019).",https://www.reddit.com/r/deeplearning/comments/b2hj29/a_pytorch_implementation_of_splitter_learning/,benitorosenberg,1552908279,"&amp;#x200B;

https://i.redd.it/il9y7hf24vm21.jpg

Github: [https://github.com/benedekrozemberczki/Splitter](https://github.com/benedekrozemberczki/Splitter)

Paper: [http://epasto.org/papers/www2019splitter.pdf](http://epasto.org/papers/www2019splitter.pdf)

ABSTRACT:

Recent  interest in graph embedding methods has focused on learning a  single  representation for each node in the graph. But can nodes really  be best  described by a single vector representation? In this work, we  propose a  method for learning multiple representations of the nodes in a  graph  (e.g., the users of a social network). Based on a principled   decomposition of the ego-network, each representation encodes the role   of the node in a different local community in which the nodes   participate. These representations allow for improved reconstruction of   the nuanced relationships that occur in the graph a phenomenon that we   illustrate through state-of-the-art results on link prediction tasks on  a  variety of graphs, reducing the error by up to 90%. In addition, we   show that these embeddings allow for effective visual analysis of the   learned community structure.",0,2
158,2019-3-18,2019,3,18,23,b2j5tb,SC-FEGAN: Face Editing Generative Adversarial Network with Users Sketch and Color,https://www.reddit.com/r/deeplearning/comments/b2j5tb/scfegan_face_editing_generative_adversarial/,BrighterAI,1552918150," \[I**n** this paper, South Korean researchers achieved high quality (512512) completion of face images guided by a user-provided edge sketch and colors for a cut-out part of the original image...\] ",0,1
159,2019-3-19,2019,3,19,3,b2lxe9,An introduction to Intel's BigDL and Analytics Zoo,https://www.reddit.com/r/deeplearning/comments/b2lxe9/an_introduction_to_intels_bigdl_and_analytics_zoo/,iamspoilt,1552932272,,0,8
160,2019-3-19,2019,3,19,5,b2ntek,Where do you go when you simply need more compute?,https://www.reddit.com/r/deeplearning/comments/b2ntek/where_do_you_go_when_you_simply_need_more_compute/,johnrudolphdrexler,1552941820,"Hey all -- curious to hear what solutions you turn to when you need more compute power to run your models, to do more robust parameter sweeps, or have a computationally expensive job to run. When you have a job that exceeds the resources on your local machine, where do you go first to get more power? Do you guys depend on cloud? Wait in line for a HPC resource in your lab?  All help appreciated! ",1,1
161,2019-3-19,2019,3,19,7,b2p8ol,A New Super Accurate Indoor Navigation System using Deep Learning,https://www.reddit.com/r/deeplearning/comments/b2p8ol/a_new_super_accurate_indoor_navigation_system/,MESAI0,1552949044,,0,3
162,2019-3-19,2019,3,19,7,b2p8wm,Titan V Machine Learning Training Performance,https://www.reddit.com/r/deeplearning/comments/b2p8wm/titan_v_machine_learning_training_performance/,mippie_moe,1552949076,"[Titan V Machine Learning Training Performance](https://lambdalabs.com/blog/titan-v-deep-learning-benchmarks/)

In general, I don't recommend the Titan V for Machine Learning. At the Titan V price point ($2,999), the Titan RTX ($2,499) is a superior GPU.

**For FP32 training of neural networks, the NVIDIA Titan V is...**

* 42% faster than RTX 2080
* 41% faster than GTX 1080 Ti
* 26% faster than Titan XP
* 4% faster than RTX 2080 Ti
* 90% as fast as Titan RTX
* 75% as fast as Tesla V100 (32 GB)

**For FP16 training of neural networks, the NVIDIA Titan V is..**

* 111% faster than GTX 1080 Ti
* 94% faster than Titan XP
* 70% faster than RTX 2080
* 23% faster than RTX 2080 Ti
* 87% as fast as Titan RTX
* 68% as fast as Tesla V100 (32 GB)

**Multi-GPU training scaling of the Titan V from 1 to 2 to 4 to 8 GPUs:**

* 1 GPU = 1.0x faster than single Titan V
* 2 GPU = 1.62x faster than single Titan V
* 4 GPU = 3.22x faster than single Titan V
* 8 GPU = 5.18x faster than single Titan V",5,27
163,2019-3-19,2019,3,19,10,b2qzag,How to validate whether a task has been done or not?,https://www.reddit.com/r/deeplearning/comments/b2qzag/how_to_validate_whether_a_task_has_been_done_or/,EricDZhang,1552958366,"Recently I have found a interesting Computer Vision task when reading conference papers but I don't know whether it has been done or not.

I have searched on Google Scholar with many keywords but found nothing exactly the same.

When is it safe to say ""To the best of our knowledge, we are the first to propose ..."" while writing papers?",0,2
164,2019-3-19,2019,3,19,15,b2u0mc,1-D CNN vs MLP performance,https://www.reddit.com/r/deeplearning/comments/b2u0mc/1d_cnn_vs_mlp_performance/,aabidhasan,1552977760,"I have three datasets of sizes 706589, 1436489, and 2143289.

I have built a neural network that contains one 1-D convolution layer and 1 fully connected layer that goes through softmax for classification.

Since I know the features do not have any kind of local patterns in them, so a CNN based neural network isn't the appropriate choice. So I build a neural network with just multiple layers. My DNN contains 4 layers (128, 512, 1024, 1024) which goes through softmax for classification. Activation function relu, optimizer adam, Dropout 0.2, Batch size 32. I have changed the hyper-parameters and the performance are pretty similar.

Now after running experiments on both of the architectures with these datasets, CNN model consistently gives better results than DNN model. I even tried randomly shuffling features and then run CNN, and still its better than DNN. The AUC is better at around 2% to 5% in 10-fold cross-validation for CNN model.

Is there any reason why CNN based model is performing better than DNN even though there isn't a local pattern in the feature set? Is it possible to justify the use of CNN based model over DNN in this case?",1,1
165,2019-3-19,2019,3,19,15,b2u1y9,Deploying a Keras Deep Learning Model as a Web Application in Python,https://www.reddit.com/r/deeplearning/comments/b2u1y9/deploying_a_keras_deep_learning_model_as_a_web/,BercoviciAdrian,1552978035,,0,26
166,2019-3-19,2019,3,19,18,b2veyw,Variable length data for LSTM in Keras,https://www.reddit.com/r/deeplearning/comments/b2veyw/variable_length_data_for_lstm_in_keras/,pk12_,1552988854,"I have variable length sequences of 3D data for which I want to build a combination of CNN-LSTM model

The issue here is the variable length. One solution is to pad zeros to make them equal size, but I'm just wondering if there are better solutions. 

Does anyone have experience in dealing with variable length sequences?",6,5
167,2019-3-19,2019,3,19,19,b2vpd2,Major Benefits of Deep Learning for Businesses,https://www.reddit.com/r/deeplearning/comments/b2vpd2/major_benefits_of_deep_learning_for_businesses/,greatlearning1,1552991027,,0,1
168,2019-3-19,2019,3,19,23,b2xz6d,Semantic Question Classification,https://www.reddit.com/r/deeplearning/comments/b2xz6d/semantic_question_classification/,dpz97,1553005151,"Hey folks.
As part of a college project, me and my partner are trying to build a question classification system. 
The idea is simple - we train the model on a dataset which consists of questions and associated tags. We provide an interface where the user can enter a question of his own choice. The system then tags the question with all possibly appropriate labels, and also retrieves questions that are similar.
We've decided that we'll use neural models for our project.
The first issue is the dataset. We've only managed to find one dataset, TREC-6 for question tagging at [http://cogcomp.org/Data/QA/QC/]() and it doesn't really suit our requirements since we want realistic labels like the ones they have at stack exchange or Quora. We plan to scrape questions from these websites, but for now the TREC-6 is a good starting point.
For question tagging, we're trying to follow Yoon Kim's paper at [https://arxiv.org/abs/1408.5882](). Basically, the guy uses convolutional neural networks and word embeddings on the TREC-6 set. We follow his approach and get good results on the test set.
But when we train the model on the combined train set and test set and use it to classify our own questions, it sometimes fails.
Granted, the dataset is small and scraping questions might be our first solution. But I'd like to know if we're on the right track. Is Cnns the way to go or are there better approaches. I tried C-Lstms but they take too long to train and I didn't notice a huge leap in performance.
Reaosn I'm asking is one of our teachers said our approach was a bad one during a recent presentation.
Also, for our similar question retrieval task, we've identified BERT as a solution. Is there any other better approach.
Suggestions would be appreciated. ",4,5
169,2019-3-19,2019,3,19,23,b2yakh,CUB dataset Attribute detection,https://www.reddit.com/r/deeplearning/comments/b2yakh/cub_dataset_attribute_detection/,muneeb2405,1553006821,"Hi, There is a cub dataset [http://www.vision.caltech.edu/visipedia/CUB-200-2011.html](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html) which contain parts and attributes of birds, I want to classify the birds using the attributes and image data. Then detect attributes using some deep learning models. Is there anyone know, how can i prepare the data for classifier&gt;? Can someone point me to example with the similar task. ",0,2
170,2019-3-20,2019,3,20,0,b2ytq9,How to log basic (python) scalars to tensorboard in manner consistent with keras callbacks?,https://www.reddit.com/r/deeplearning/comments/b2ytq9/how_to_log_basic_python_scalars_to_tensorboard_in/,nobodywillobserve,1553009541,"If you use keras callbacks you get scalars in tensorboard (val, val\_loss).

&amp;#x200B;

Adding other scalars is very tricky as I think you need to create tensorflow objects and your own tensorflow summary writer and then hope to use the same step and timestamps as keras. So far nothing is working and the custom scalars are not on the same time/step scales as the keras callbacks.

&amp;#x200B;

Is there a standard way to do this? ",2,4
171,2019-3-20,2019,3,20,1,b2zpmm,Google Brain SimPLe: Complete Model-Based Reinforcement Learning for Atari,https://www.reddit.com/r/deeplearning/comments/b2zpmm/google_brain_simple_complete_modelbased/,gwen0927,1553013933,,0,3
172,2019-3-20,2019,3,20,1,b2zt7y,Help with hardware,https://www.reddit.com/r/deeplearning/comments/b2zt7y/help_with_hardware/,seb59,1553014429,"At my university, I've got a budget to buy several machines for one of our project. We are ""newbies"" in deep learning. We will use the card for image segmentation for autonomous vehicle applications, traffic sign detection, pedestrian recognitions, etc. Basically, we ""only"" want to apply existing network structure to our datasets. Nevertheless, I know that training is be quite demanding in term of computer power.  

Being new to this, I know that we will have to tune the learning algorithm, the network parameters, and being human, I do not like to wait for one week just to find that something is wrong. I believe that we need to have efficient hardware to get a good learning curve.

For once, budget is not an issue (yes, sometimes it can happen !). 

Our hardware provider suggest to buy these expensive QUADRO RTX 6000. I was initially looking for RTX2080Ti, eventually I could use 2 of them. 

Nb : For the computer, I will have the  i9-9900K or KF processor with 64Go RAM + 1To SSD

&amp;#x200B;

So I read the blogs at lambdalabs but there is not Quadro RTX6000 in their chart... Is that a clear indicator that the card is not that well suited?

&amp;#x200B;

1) What are the benefits of the quadro RTX6000 vs RTX 2080 TI with respect to deep learning application (i.e. no graphics, no ray tracing). 

=&gt; For the price of the quadro I can have another computer. Does this card worth its price for deep learning application (I'm not discussing its intrinsic capabilities, but only the deep learning usage). 

2) According to your experience, what's the best value for price.

&amp;#x200B;

&amp;#x200B;

Thanks for your help

&amp;#x200B;",16,3
173,2019-3-20,2019,3,20,3,b318qy,[D] Getting skeletons from the silhouettes,https://www.reddit.com/r/deeplearning/comments/b318qy/d_getting_skeletons_from_the_silhouettes/,akaberto,1553021504,,0,2
174,2019-3-20,2019,3,20,10,b35vo5,How do you guys measure the quality of a generated sentences using ROUGE?,https://www.reddit.com/r/deeplearning/comments/b35vo5/how_do_you_guys_measure_the_quality_of_a/,phereVus,1553045481,"As the title says, how do you guys measure the generated sentences of your model using ROUGE? I  used a [library](https://github.com/pcyin/PyRouge) from GitHub to use rouge but I really don't know what it does. ",0,2
175,2019-3-20,2019,3,20,11,b36r0t,Keras Autoencoder Issues,https://www.reddit.com/r/deeplearning/comments/b36r0t/keras_autoencoder_issues/,ZeroMaxinumXZ,1553050685,"I'm having trouble with this deep convolutional autoencoder I'm building using Keras.  The input's shape is dependent on the screen size, and the output is  going to be a prediction of the next screen size...  However there seems  to be an error that I cannot figure out...  The input is the screen reduced 400%, and the output is the next screen also reduced 400%...

&amp;#x200B;

Here's the code:

    def model_build():
        input_img = InputLayer(shape=(1, env_size()[1], env_size()[0]))
        x = Conv2D(32, (2, 2), activation='relu', padding='same')(input_img)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(16, (2, 2), activation='relu', padding='same')(x)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(8, (2, 2), activation='relu', padding='same')(x)
        encoded = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(8, (2, 2), activation='relu', padding='same')(encoded)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(16, (2, 2), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (2, 2), activation='relu')(x)
        x = UpSampling2D((2, 2))(x)
        decoded = Conv2D(2, (2, 2), activation='sigmoid', padding='same')(x)
        model = Model(input_img, decoded)
        return model

And here's my test code:

     aif __name__ == '__main__':
        model = model_build()
        model.compile('adam', 'mean_squared_error')
        y = np.array([env()])
        print(y.shape)
        print(y.ndim)
        debug = model.fit(np.array([[env()]]), np.array([[env()]]))

Error:

    Traceback (most recent call last):
      File ""/home/ai/Desktop/algernon-test/rewarders.py"", line 46, in &lt;module&gt;
        debug = model.fit(np.array([[env()]]), np.array([[env()]]))
      File ""/home/ai/.local/lib/python3.6/site-packages/keras/engine/training.py"", line 952, in fit
        batch_size=batch_size)
      File ""/home/ai/.local/lib/python3.6/site-packages/keras/engine/training.py"", line 789, in _standardize_user_data
        exception_prefix='target')
      File ""/home/ai/.local/lib/python3.6/site-packages/keras/engine/training_utils.py"", line 138, in standardize_input_data
        str(data_shape))
    ValueError: Error when checking target: expected conv2d_7 to have shape (6, 270, 2) but got array with shape (1, 270, 480)

&amp;#x200B;

&amp;#x200B;

The env() function returns a screenshot, again this screenshot is reduced to 4 times the size and is then converted to greyscale...

&amp;#x200B;",6,3
176,2019-3-20,2019,3,20,18,b39qo9,"A scalable Gensim implementation of ""Learning Role-based Graph Embeddings"" (IJCAI 2018).",https://www.reddit.com/r/deeplearning/comments/b39qo9/a_scalable_gensim_implementation_of_learning/,benitorosenberg,1553072785,"&amp;#x200B;

https://i.redd.it/lwyi9z95p8n21.png

GitHub: [https://github.com/benedekrozemberczki/role2vec](https://github.com/benedekrozemberczki/role2vec)

Paper: [https://arxiv.org/abs/1802.02896](https://arxiv.org/abs/1802.02896)

ABSTRACT:

Random walks are at the heart of many existing network embedding  methods. However, such algorithms have many limitations that arise from  the use of random walks, e.g., the features resulting from these methods  are unable to transfer to new nodes and graphs as they are tied to  vertex identity. In this work, we introduce the Role2Vec framework which  uses the flexible notion of attributed random walks, and serves as a  basis for generalizing existing methods such as DeepWalk, node2vec, and  many others that leverage random walks. Our proposed framework enables  these methods to be more widely applicable for both transductive and  inductive learning as well as for use on graphs with attributes (if  available). This is achieved by learning functions that generalize to  new nodes and graphs. We show that our proposed framework is effective  with an average AUC improvement of 16.55% while requiring on average  853x less space than existing methods on a variety of graphs.",0,13
177,2019-3-20,2019,3,20,19,b3acup,How does RTX 2070 max q compare to non max q versions for deep learning. Is there any comparison for that? I couldn't find any online.,https://www.reddit.com/r/deeplearning/comments/b3acup/how_does_rtx_2070_max_q_compare_to_non_max_q/,ashish421,1553077683,,6,2
178,2019-3-20,2019,3,20,19,b3akey,Outlier Detection in Images,https://www.reddit.com/r/deeplearning/comments/b3akey/outlier_detection_in_images/,abhiksark,1553079281,"Is there any way to do outlier detection in images.
Like Blurry or Falsely Labelled images?
Currently I am Using Variance of Laplacian. It's working fine. But I was looking for better alternatives? ",2,1
179,2019-3-20,2019,3,20,22,b3by0i,masked language model in BERT,https://www.reddit.com/r/deeplearning/comments/b3by0i/masked_language_model_in_bert/,Hua_Keru,1553088118,Why and how masked LMs give us deep bidirectionality in Google's BERT Model? Any explain on that?,1,2
180,2019-3-21,2019,3,21,0,b3d9rv,Is the Deep Learning and AI Bubble Bursting?,https://www.reddit.com/r/deeplearning/comments/b3d9rv/is_the_deep_learning_and_ai_bubble_bursting/,Gabyleon2019,1553095197,What do you think?,22,0
181,2019-3-21,2019,3,21,2,b3esbv,"Keras: BATCH_SIZE, STEPS_PER_EPOCH, and fit_generator",https://www.reddit.com/r/deeplearning/comments/b3esbv/keras_batch_size_steps_per_epoch_and_fit_generator/,_sleepyotter,1553102795,"Hi all deep learning newbie here, I have a question regarding the setting of `BATCH_SIZE` and `STEPS_PER_EPOCH` when using `fit_generator` in keras. 

If I have the following:

* 100 images 
* `BATCH_SIZE` = 1 
* `STEPS_PER_EPOCH` = 20

Will `fit_generator` automagically know that my desired `BATCH_SIZE` is 5 and pull 5 images from my data generator? Or is it pulling 20 batches where each batch size is 1, so my model is actually only seeing 20/100 images? ",7,10
182,2019-3-21,2019,3,21,5,b3h9dr,Can anyone suggest any evaluation libraries in python?,https://www.reddit.com/r/deeplearning/comments/b3h9dr/can_anyone_suggest_any_evaluation_libraries_in/,RaymondKirk,1553115027,"I dont know if this is the right reddit but if so, Im currently using coco eval, (I want to avoid implementing them myself to ensure I put the right metrics in my papers). However Im finding it difficult to extract a confusion matrix or F1 from it. Any suggestions are welcome!",0,1
183,2019-3-21,2019,3,21,8,b3izrw,"Kaggle and Colab free GPU comparison - how to find specs, UX, and deep learning experiments with fastai and mixed precision training",https://www.reddit.com/r/deeplearning/comments/b3izrw/kaggle_and_colab_free_gpu_comparison_how_to_find/,discdiver,1553123752,"I wrote a post comparing Kaggle and Colab for GPUS: Specs, UX, and deep learning experiments with fastai and mixed precision training. Feedback welcome!

[https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029?source=friends\_link&amp;sk=7eb54f51566742d937b8d41adaee1bb9](https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029?source=friends_link&amp;sk=7eb54f51566742d937b8d41adaee1bb9)",4,18
184,2019-3-21,2019,3,21,9,b3jy0f,Is it advisable to learn deeplearning before learning other types of ML?,https://www.reddit.com/r/deeplearning/comments/b3jy0f/is_it_advisable_to_learn_deeplearning_before/,Dave24x7,1553128912,"I know this question might have been asked plenty of times, but please give me some suggestions. Im a complete beginner to the Artificial Intelligence field. Recently I started to look into it as it was interesting. I've read a few books and have a bare minimum knowledge, atleast I cud recognise the terms. 

Being an electrical engineer, I have a solid base in maths and a basic knowledge of python. Im currently reading DL with python by Franois chollet and I cud understand it without much difficulty. I wish to eventually do a course on self driving cars and robotics and move into that field.

Please tell me, is it possible/advisable to learn deep learning before trying out other types of ml. Im worried that if I learned deep learning without learning other aspects of ml, I would be one trick dog and be at a severe disadvantage. Also I hear about Deeplearning requiring tons of data and expensive GPUs. Are any deeplearning projects possible without these, that beginners can try out?

Should I just go ahead with deeplearning with tensorflow on coursera or udacity? And maybe learn other ml types at a later stage.",2,1
185,2019-3-21,2019,3,21,12,b3leyp,Deep Learning Model Speaks Like Trump (v2),https://www.reddit.com/r/deeplearning/comments/b3leyp/deep_learning_model_speaks_like_trump_v2/,hanyuqn,1553137422,,14,24
186,2019-3-21,2019,3,21,13,b3mfr4,Sentiment Analysis with Deep Learning of Netflix Reviews,https://www.reddit.com/r/deeplearning/comments/b3mfr4/sentiment_analysis_with_deep_learning_of_netflix/,NicholasTower,1553143905,,0,2
187,2019-3-21,2019,3,21,18,b3oadu,What are some techniques/areas concerned with a network or algos ability to learn *the absence of relationships* between subsets of inputs and outputs?,https://www.reddit.com/r/deeplearning/comments/b3oadu/what_are_some_techniquesareas_concerned_with_a/,nobodywillobserve,1553159056,"This probably delves into sparse methods but am trying to find if someone has really studied this extensively. 

&amp;#x200B;

For example, if you have some segmentation/separability in your feature and output space that you could represent as a simple (small) causal graph with complexity in the clusters.

&amp;#x200B;

So reality could be

&amp;#x200B;

X = (Astuff, BStuff)

Y = F(Astuff), phi(Astuff) \* psi(Bstuff)

&amp;#x200B;

I'm sure this has been studied in different contexts but trying to find some paper starting points to see the communities of work.

&amp;#x200B;

My feeling is that if you attack that problem in a structureless way it is very challenging (especially in high dimensions) unless you bias your models to discovering sparse structures or input the known causal structure in the network design itself.",0,1
188,2019-3-21,2019,3,21,19,b3ozbm,NVIDIA Jetson Nano is a $99 Computer Built for AI,https://www.reddit.com/r/deeplearning/comments/b3ozbm/nvidia_jetson_nano_is_a_99_computer_built_for_ai/,jaja123789,1553164741,,12,55
189,2019-3-21,2019,3,21,21,b3q57s,Out-domain adversarial inputs for GAN generators,https://www.reddit.com/r/deeplearning/comments/b3q57s/outdomain_adversarial_inputs_for_gan_generators/,NoiseKnows,1553172618,What do you think?  [https://github.com/pasquini-dario/OutDomainExamples](https://github.com/pasquini-dario/OutDomainExamples),0,1
190,2019-3-21,2019,3,21,22,b3qf6w,Prerequisites for understanding and implementing GANs for various tasks,https://www.reddit.com/r/deeplearning/comments/b3qf6w/prerequisites_for_understanding_and_implementing/,UserPobro,1553174279,"Hello, my task for Master Thesis is Image Generation using Deep Learning. I was thinking about GANs for such task. My questions is: are there anything I should learn before tackling image generation. Previously I have completed Coursera Deep Learning specialization and I am wondering is it enough? Any advice would be greatly appreciated.",1,4
191,2019-3-21,2019,3,21,23,b3rhn5,Google Deep Learning Course Online,https://www.reddit.com/r/deeplearning/comments/b3rhn5/google_deep_learning_course_online/,SunilAhujaa,1553180187,If you are looking for Google deep learning course in India then Analytixlabs help you to upgrade yourself and kick-start a career in Deep Learning Course. This is a specialization course which will help you to get a break into AI and Deep Learning domain.,0,0
192,2019-3-22,2019,3,22,0,b3rvhv,AttoNets: Compact and Efficient DNNs Realized via Human-Machine Collaborative,https://www.reddit.com/r/deeplearning/comments/b3rvhv/attonets_compact_and_efficient_dnns_realized_via/,gwen0927,1553182145,,1,1
193,2019-3-22,2019,3,22,0,b3rviv,Could I get a little guidance on a small project?,https://www.reddit.com/r/deeplearning/comments/b3rviv/could_i_get_a_little_guidance_on_a_small_project/,samblack11,1553182148,"Hi All!

I'm a newb at AI trying to get my bearings. I'm trying to use deep q learning to teach an AI a simple game and it's not going well. I'm sort of lost where to even look and could really use some help/guidance.

The project is here: https://github.com/IWasZeroCool/blocksAI
There is a robust README that explains pretty much everything.

Any help would be greatly appreciated!",2,1
194,2019-3-22,2019,3,22,0,b3s4rm,Artificial Intelligence : Open AI - Flow-based Deep Generative Models,https://www.reddit.com/r/deeplearning/comments/b3s4rm/artificial_intelligence_open_ai_flowbased_deep/,gokulbalex,1553183403,,0,13
195,2019-3-22,2019,3,22,2,b3t6vb,recommendations for balancing data - 'dontcare' categories,https://www.reddit.com/r/deeplearning/comments/b3t6vb/recommendations_for_balancing_data_dontcare/,raggityrag,1553188576,"I'm training a visual Object Detector algorithm (YOLO-spp) on a subset of openimages. There are only a few classes that I actually care about detecting (7) so I have selected all images containing those classes and also, to prevent overfitting, some images that contain negative examples ie. depictions of objects that are \*not\* objects of interest but do have some level of resmeblance to my objects of interest. I have then balanced the data on a per-class basis using upsampling until there are the same number of instances of each class of interest. I have changed the labels of all of the instances of objects that are not of interest to 'dontcare'. I now have many more 'dontcare' instances than objects of interest instances. I'm worried about the model just predicting everything as 'dontcare' so I want to undersample (drop images that have many 'dontcare' examples). My question is: What level should I take 'dontcare' down to? Should it be the same number of instances as the classes of interest? Or, given that it is quite a diverse group of objects, would it make more sense to have more dontcares than other classes?",0,1
196,2019-3-22,2019,3,22,3,b3u86o,"A sparsity aware and memory efficient TesnorFlow implementation of ""Attributed Social Network Embedding"" (TKDE 2018).",https://www.reddit.com/r/deeplearning/comments/b3u86o/a_sparsity_aware_and_memory_efficient_tesnorflow/,benitorosenberg,1553193522,"&amp;#x200B;

https://i.redd.it/f341ds77oin21.jpg

Paper: [https://arxiv.org/abs/1705.04969](https://arxiv.org/abs/1705.04969)

GitHub: [https://github.com/benedekrozemberczki/ASNE](https://github.com/benedekrozemberczki/ASNE)

Abstract: 

&gt;Embedding network data into a low-dimensional vector space has shown promising performance for many real-world applications, such as node classification and entity retrieval. However, most existing methods focused only on leveraging network structure. For social networks, besides the network structure, there also exists rich information about social actors, such as user profiles of friendship networks and textual content of citation networks. These rich attribute information of social actors reveal the homophily effect, exerting huge impacts on the formation of social networks. In this paper, we explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Social Network Embedding framework (SNE), which learns representations for social actors (i.e., nodes) by preserving both the structural proximity and attribute proximity. While the structural proximity captures the global network structure, the attribute proximity accounts for the homophily effect. To justify our proposal, we conduct extensive experiments on four real-world social networks. Compared to the state-of-the-art network embedding approaches, SNE can learn more informative representations, achieving substantial gains on the tasks of link prediction and node classification. Specifically, SNE significantly outperforms node2vec with an 8.2% relative improvement on the link prediction task, and a 12.7% gain on the node classification task. 

  ",0,1
197,2019-3-22,2019,3,22,3,b3ugm1,Self Driving Cars 3D Simulation,https://www.reddit.com/r/deeplearning/comments/b3ugm1/self_driving_cars_3d_simulation/,DevTechRetopall,1553194654,,0,1
198,2019-3-22,2019,3,22,4,b3uibr,Analyzing tf.function to discover AutoGraph strengths and subtleties - part 1,https://www.reddit.com/r/deeplearning/comments/b3uibr/analyzing_tffunction_to_discover_autograph/,pgaleone,1553194890,,0,1
199,2019-3-22,2019,3,22,5,b3vdl4,New Study Uses Machine Learning to Predict Sexual Orientation,https://www.reddit.com/r/deeplearning/comments/b3vdl4/new_study_uses_machine_learning_to_predict_sexual/,gwen0927,1553199149,,8,0
200,2019-3-22,2019,3,22,5,b3viw3,Convolutional Kernel Size Formula Issue,https://www.reddit.com/r/deeplearning/comments/b3viw3/convolutional_kernel_size_formula_issue/,ZeroMaxinumXZ,1553199898,"So I know about the formula, o = (w-f+2p)/s+1... But I just don't know how to apply it... I'm wanting my output to be the same as my input, which varies based on the screen resolution.. 

So do I have to put each number of the input shape into the formula or something in order to calculate the output shape .. I'm trying to get f from the output and input. I know how to reverse functions so that f comes first... But I don't understand how I'm supposed to get w and o in the function.

I'm new to ML so please forgive me and my stupid questions...",2,2
201,2019-3-22,2019,3,22,11,b3znz2,Rtx 2080 vs rtx 2080ti ?,https://www.reddit.com/r/deeplearning/comments/b3znz2/rtx_2080_vs_rtx_2080ti/,zosogreen,1553222638,"I'm building a PC for deep learning side projects. Would you recommend spending extra $400 on rtx 2080ti as compared to 2080? I saw the benchmarks recently and 2080 performs roughly at 73% of ti.

Also any preferences for CPU? I'm thinking if saving some money and getting ryzen 2700x instead of Intel i7-87xx/9xxx.",7,3
202,2019-3-22,2019,3,22,13,b40u56,Deep Learning on Mobile Devices,https://www.reddit.com/r/deeplearning/comments/b40u56/deep_learning_on_mobile_devices/,Usama9012,1553230285,[http://tech.learn4startup.com/70c7dfbb63](http://tech.learn4startup.com/70c7dfbb63),0,3
203,2019-3-22,2019,3,22,15,b41mzb,denoising image,https://www.reddit.com/r/deeplearning/comments/b41mzb/denoising_image/,johnthron,1553236388,can anyone suggest me how can i denoise images for give that denoise image to neural network?,4,0
204,2019-3-22,2019,3,22,19,b43fhg,PSU Upgrade Advice for 2nd GPU?,https://www.reddit.com/r/deeplearning/comments/b43fhg/psu_upgrade_advice_for_2nd_gpu/,eigenvergle42,1553250377,"Hi, not sure if this is the right place to go but thank you for anyone that can advise. My current setup is a GTX 1080 TI with a 850 watt PSU. I really need a 2nd GPU, so I'm going ahead with buying a GTX 2080 TI to supplement. I'll likely be running separate models on these on a near constant daily basis. I'm not a hardware expert and wondering if anyone could help me out in determining whether I need to be upgrading the PSU as well to accommodate.",6,2
205,2019-3-22,2019,3,22,23,b45tyi,Hinton's reading list from the removed Coursera MOOC,https://www.reddit.com/r/deeplearning/comments/b45tyi/hintons_reading_list_from_the_removed_coursera/,durmusau,1553265530,"Hi all,

&amp;#x200B;

Geoffrey Hinton's Coursera MOOC was recently discontinued:

[https://twitter.com/geoffreyhinton/status/1085325734044991489?lang=en](https://twitter.com/geoffreyhinton/status/1085325734044991489?lang=en)

&amp;#x200B;

The videos however are still available at both on Youtube and on Hinton's webpage:

[https://www.cs.toronto.edu/\~hinton/coursera\_lectures.html](https://www.cs.toronto.edu/~hinton/coursera_lectures.html)

&amp;#x200B;

However in his MOOC Hinton also had some papers as required (or recommended, I can't really remember) readings after each lecture. They were generally old, seminal papers which provided some good insights and intuitions and were worth reading IMHO for learning purposes. I couldn't find these papers as a reading list online. Does anyone have this list?",3,40
206,2019-3-23,2019,3,23,0,b46m9f,Curated List of Arbitrary Text to Image Papers,https://www.reddit.com/r/deeplearning/comments/b46m9f/curated_list_of_arbitrary_text_to_image_papers/,lzhbrian,1553269538,"[lzhbrian/arbitrary-text-to-image-papers](https://github.com/lzhbrian/arbitrary-text-to-image-papers)

Still preliminary. PR, issues, discussions are welcomed!",0,1
207,2019-3-23,2019,3,23,2,b47icv,Tableau Training &amp; Certification,https://www.reddit.com/r/deeplearning/comments/b47icv/tableau_training_certification/,HannahHumphreys,1553274044,[removed],0,1
208,2019-3-23,2019,3,23,6,b4aevn,[Q] repetition encoder for integer labels?,https://www.reddit.com/r/deeplearning/comments/b4aevn/q_repetition_encoder_for_integer_labels/,pk12_,1553288541,"Is there is an optimised python function to encode integer labels as repetition on binary 1s

For example 

1 =001
2 = 011
3 = 111

Thanks",0,1
209,2019-3-23,2019,3,23,12,b4eluv,Sign language recognition using OpenCV,https://www.reddit.com/r/deeplearning/comments/b4eluv/sign_language_recognition_using_opencv/,arshad_221b,1553313229,Sign Language Recognition Using CNN and OpenCV (Beginner Level) by Arshad Kazi https://link.medium.com/VwhBjBLPgV,0,2
210,2019-3-23,2019,3,23,13,b4f4mw,V100 or t4? How do i know if my problem is scale up or out?,https://www.reddit.com/r/deeplearning/comments/b4f4mw/v100_or_t4_how_do_i_know_if_my_problem_is_scale/,Jpc204,1553316684,"New to dl/ai/ml. Saw the announcement about Nvidia working with oems to deliver boxes with t4s and v100 architectures - all in their ngc ready program.

How will I know if I need t4s or v100s?

Can I just go with t4 boxes to lower barrier to entry? When will adding t4 boxes not work for me anymore?

Note, I know I could start with titan or similar but I'd like to start with a solution that can be shared and scaled. (And we won't be ready for cloud)

(Warning in advance that I'm not actually ready to buy hardware, still working on path to product....probably getting ahead of myself but this is the biggest knowledge gap)

Thx in advance ",8,3
211,2019-3-23,2019,3,23,14,b4ff3k,Good project to get experience with C++ for computer vision/deep learning?,https://www.reddit.com/r/deeplearning/comments/b4ff3k/good_project_to_get_experience_with_c_for/,74throwaway,1553318677,"I have some experience with image processing but I'm interested in transitioning to a job that involves more deep learning and/or computer vision. I had a couple interviews for these roles recently and they mentioned the job duties would be roughly 50% python and 50% C++. I haven't used C++ in awhile so I want to get better at C++ to prepare for these kinds of jobs

Problem is I don't really know where to start in terms of using C++ for a DL/CV project. I've only used Matlab, Python, and Keras for image processing/DL. 

Are there any good projects like Kaggle where I can get practice using C++ for DL/CV? Is having access to a GPU necessary if using C++? What DL framework is easiest to learn for C++?",7,16
212,2019-3-23,2019,3,23,17,b4gpzw,Call for AI writers at FloydHub,https://www.reddit.com/r/deeplearning/comments/b4gpzw/call_for_ai_writers_at_floydhub/,pirate7777777,1553328809,[We are hiring AI Writers for the FloydHub blog](https://blog.floydhub.com/write-for-floydhub/). This is a great gig for anyone passionate about the DeepLearning or MachineLearning community. Join the crew.,0,16
213,2019-3-23,2019,3,23,23,b4jj5n,Learning resources deep learning,https://www.reddit.com/r/deeplearning/comments/b4jj5n/learning_resources_deep_learning/,durgesh2018,1553350017,"Hello everyone!
I am a new researcher in deep learning. Please suggest few resources to learn deep learning from scratch.
Thank you! ",8,5
214,2019-3-24,2019,3,24,1,b4l70u,Fake news detection implementation ?,https://www.reddit.com/r/deeplearning/comments/b4l70u/fake_news_detection_implementation/,yautslil,1553359172,"Hi everyone, I am working on Fake News detection, One implementation I came to know about is using stance detection, But this involves comparison of the article with another true article and then see if both agree.  I want to know if there is some another implementation which doesn't require to compare an article against another. 

P.S. yeah I know about Binary classification but I guess this approach won't be fine for fake news detection as new fake news can be generated without using any of the word combinations that is present on training dataset.",17,8
215,2019-3-24,2019,3,24,2,b4m2wg,TPU Supporting Frameworks?,https://www.reddit.com/r/deeplearning/comments/b4m2wg/tpu_supporting_frameworks/,apoorvagni,1553363787,"Hi, I wanted to know which of the frameworks are currently supporting computations on Google's TPUs and upto what extent. I heard that Pytorch supports it somewhat but it doesn't support RNN Networks. 

&amp;#x200B;

Hope to get some ideas about which technologies to focus learning that would save more bucks down the line (by using cheaper TPUs instead of GPUs).

&amp;#x200B;

Thanks

\-aa",3,3
216,2019-3-24,2019,3,24,7,b4oyuk,How can I improve a curiosity-driven reinforcement learning AI...?,https://www.reddit.com/r/deeplearning/comments/b4oyuk/how_can_i_improve_a_curiositydriven_reinforcement/,ZeroMaxinumXZ,1553379443,"Besides, you know, RND... 

&amp;#x200B;

My reincforcement-learning AI isn't really improving much, and I'm afraid it's barely learning... So any suggestions...?",0,3
217,2019-3-24,2019,3,24,7,b4pdj9,LSTM for text generation?,https://www.reddit.com/r/deeplearning/comments/b4pdj9/lstm_for_text_generation/,RemoteReindeer,1553381924,"Hi, I was following a notebook for text generation with just one LSTM cell.

&amp;#x200B;

The input (about 40 char) predict the next character (only one).

&amp;#x200B;

I was wondering if mapping a series a char to only one char at the output (and not a word or anything else) is the usual way to do it (text generation) ?

&amp;#x200B;

On a side note, if you know some great networks for text generation, give me a link please.

&amp;#x200B;

cheers.",8,9
218,2019-3-24,2019,3,24,8,b4pkzb,How Neural Networks Work- Simply Explained by a Machine Learning Engineer,https://www.reddit.com/r/deeplearning/comments/b4pkzb/how_neural_networks_work_simply_explained_by_a/,DiscoverAI,1553383193,,0,0
219,2019-3-24,2019,3,24,8,b4pqt6,"Trying to implement multi-head attention layer, from Transformer",https://www.reddit.com/r/deeplearning/comments/b4pqt6/trying_to_implement_multihead_attention_layer/,anirbankar21,1553384195,"Trying to implement multi-head attention layer, which was published in [""Attention is all you need""](https://arxiv.org/pdf/1706.03762.pdf)

&amp;#x200B;

here is my try using tensorflow  2.0 keras api

&amp;#x200B;

&amp;#x200B;

![img](bfpqvaoxeyn21)

&amp;#x200B;

any thoughts? is it looking good or i am missing something",0,2
220,2019-3-24,2019,3,24,9,b4qdp5,What happend to google duplex ai,https://www.reddit.com/r/deeplearning/comments/b4qdp5/what_happend_to_google_duplex_ai/,sometimesguru,1553388188,"I mean common. That cant be real. It was announced like 10month ago and it seemed like google duplex could understand every single word in the phone call and not only that it sounded all natural. My question is : why the hell is there no evidence or a single video out there which shows the ai in a real life scenario? We only have this (probably) faked presentation 10month ago and a video on youtube from the youtuber venturebeat 4 months ago but she/he wrote in the description that google has a 'manual line' and a ai line. The ai line is for calls which are made with the ai (google says its the majority of incoming calls) and the manual line is actually a real human speaking and NOT an ai. So we basically have no real proof and on the other hand we still have the google assistant which understands only half of what you say and you have to speak slowly and clearly... Sorry but i think that this is fake

What do you guys think?",5,6
221,2019-3-24,2019,3,24,18,b4ugd6,Predicting type of art using CNNs and FastAI,https://www.reddit.com/r/deeplearning/comments/b4ugd6/predicting_type_of_art_using_cnns_and_fastai/,bidyutchanda108,1553419247,,0,3
222,2019-3-24,2019,3,24,20,b4vj7w,Help on how to start with Machine learning and AI?,https://www.reddit.com/r/deeplearning/comments/b4vj7w/help_on_how_to_start_with_machine_learning_and_ai/,shad282,1553428257,"Hi all, I would like your help since i m planning to get into Machine learning and AI.

I m a graduate in finance, Bachelor and Masters and I m currently working in data analysis, visualization and stuff related. I m amateur in raspberry pi and home automation and a bit of coding.

Recently I m learning more python and i would like to involved python with my data analysis (collection up to prediction) and also in my home automation. I decided that I need also to be up to date with the latest tech and I m becoming really interested in getting involved in AI and Machine learning, that would boost my data analysis skills and my own home automation project and other projects using my pi.

My question is: what should i do next after learning python should I learn more google approach which links to tensorflow, or get myself involved in AWS ML. Also, to fit what is demanded career wise.

Thank you!",14,4
223,2019-3-25,2019,3,25,3,b4zp5m,GPT-2 and Philip K. Dick,https://www.reddit.com/r/deeplearning/comments/b4zp5m/gpt2_and_philip_k_dick/,flancian,1553452418,,1,7
224,2019-3-25,2019,3,25,9,b53m2k,Can I run ..m type of files in google colab?,https://www.reddit.com/r/deeplearning/comments/b53m2k/can_i_run_m_type_of_files_in_google_colab/,nisucuk,1553472814,,6,0
225,2019-3-25,2019,3,25,10,b54l1x,Curiosity Rewarder Optimizer and Loss Function Suggestions?,https://www.reddit.com/r/deeplearning/comments/b54l1x/curiosity_rewarder_optimizer_and_loss_function/,ZeroMaxinumXZ,1553478413,"So, basically I have a curiosity rewarder and an acting agent. The curiosity rewarder is a 5-layer convnet built using Keras, and it takes in the previous state as input, and the current action as it's expected output. The loss function is mean_squared_error and the optimizer is Adam (set to default Keras values) but I'm wondering if there's something better I can use considering my use case... Thanks.",4,3
226,2019-3-25,2019,3,25,13,b561tt,Learn how to make a program that can paint photographs !,https://www.reddit.com/r/deeplearning/comments/b561tt/learn_how_to_make_a_program_that_can_paint/,signal_v_noise,1553487445,"An implementation of ""A Neural Algorithm of Artistic Style"" in Keras

1. Learn how to setup an environment for deep learning.
2. Write a program that is smart enough to paint your photos in the style of whatever painting you like

Code Repository: [https://github.com/devAmoghS/Keras-Style-Transfer](https://github.com/devAmoghS/Keras-Style-Transfer)

Tutorial Blog: [https://medium.com/@singhal.amogh1995/utilising-cnns-to-transform-your-model-into-a-budding-artist-1330dc392e25](https://medium.com/@singhal.amogh1995/utilising-cnns-to-transform-your-model-into-a-budding-artist-1330dc392e25)

[Chicago city as painted with the style of Rain Princess](https://i.redd.it/aq7hfih5y6o21.png)",0,21
227,2019-3-25,2019,3,25,20,b59a2a,Highly imbalanced negative class and noise class in scene segmentation,https://www.reddit.com/r/deeplearning/comments/b59a2a/highly_imbalanced_negative_class_and_noise_class/,_userjv,1553511975,"I'm trying to do a semantic segmentation on point data scene. There are 2 classes of interest- class 0 and class 1. Class 1 overwhelms class 0 by a ratio of 100:1. Also, the scene-wise number of points can vary sample to sample. To solve this, I take a constant input size of 1000. This number is kept because that is the maximum possible number of points I can get from a scene. In order to reach this fixed size, I fill all the features with 0 values.

Any suggestions on training, where I can neglect the dummy class i.e. the one filled with 0 values to meet the input size and also have a decent score for the actual points which are already imbalanced 100:1 ?",0,1
228,2019-3-25,2019,3,25,20,b59c9y,Visual Agnosia: A Neural Network Analogy,https://www.reddit.com/r/deeplearning/comments/b59c9y/visual_agnosia_a_neural_network_analogy/,aryancodify,1553512375," Recently I read the story The man who mistook his wife for a hat by Dr. Oliver Sacks. I could not help but draw strong parallels between neural network deficit and brain dysfunction. In the following medium story I try to capture this intriguing similarity: 

[https://medium.com/@aryancodify/visual-agnosia-a-neural-network-analogy-8e208438b1ec](https://medium.com/@aryancodify/visual-agnosia-a-neural-network-analogy-8e208438b1ec)  
",0,1
229,2019-3-25,2019,3,25,20,b59omy,"A PyTorch implementation of ""Capsule Graph Neural Network"" (ICLR 2019).",https://www.reddit.com/r/deeplearning/comments/b59omy/a_pytorch_implementation_of_capsule_graph_neural/,benitorosenberg,1553514528,"&amp;#x200B;

https://i.redd.it/vff6x48l69o21.jpg

PyTorch: [https://github.com/benedekrozemberczki/CapsGNN](https://github.com/benedekrozemberczki/CapsGNN)

Paper: [https://openreview.net/forum?id=Byl8BnRcYm](https://openreview.net/forum?id=Byl8BnRcYm)

Abstract:

The high-quality node embeddings learned from the Graph Neural Networks (GNNs) have been applied to a wide range of node-based applications and some of them have achieved state-of-the-art (SOTA) performance. However, when applying node embeddings learned from GNNs to generate graph embeddings, the scalar node representation may not suffice to preserve the node/graph properties efficiently, resulting in sub-optimal graph embeddings.  Inspired by the Capsule Neural Network (CapsNet), we propose the Capsule Graph Neural Network (CapsGNN), which adopts the concept of capsules to address the weakness in existing GNN-based graph embeddings algorithms. By extracting node features in the form of capsules, routing mechanism can be utilized to capture important information at the graph level. As a result, our model generates multiple embeddings for each graph to capture graph properties from different aspects. The attention module incorporated in CapsGNN is used to tackle graphs with various sizes which also enables the model to focus on critical parts of the graphs.  Our extensive evaluations with 10 graph-structured datasets demonstrate that CapsGNN has a powerful mechanism that operates to capture macroscopic properties of the whole graph by data-driven. It outperforms other SOTA techniques on several graph classification tasks, by virtue of the new instrument.

&amp;#x200B;

&amp;#x200B;",0,30
230,2019-3-25,2019,3,25,21,b5a6cg,OpenCV basics,https://www.reddit.com/r/deeplearning/comments/b5a6cg/opencv_basics/,arshad_221b,1553517519,,0,1
231,2019-3-25,2019,3,25,23,b5bh5l,Quickly Train and Deploy a Computer Vision App with fastai and Render,https://www.reddit.com/r/deeplearning/comments/b5bh5l/quickly_train_and_deploy_a_computer_vision_app/,discdiver,1553524746,[removed],0,1
232,2019-3-26,2019,3,26,1,b5cnzj,Deploying Deep Learning models using Kubeflow on Azure,https://www.reddit.com/r/deeplearning/comments/b5cnzj/deploying_deep_learning_models_using_kubeflow_on/,brunocborges,1553530615,,0,3
233,2019-3-26,2019,3,26,2,b5date,I dont actually know much,https://www.reddit.com/r/deeplearning/comments/b5date/i_dont_actually_know_much/,tymp-anistam,1553533504,"I know that deep learning can be used in countless applications so I just had a thought, could you record a %100 playthrough of a video game and teach a bot to speed run the game? Or something possibly more simple, create a walkthrough book of the game itself? Any thoughts? Does this already exist?",5,0
234,2019-3-26,2019,3,26,3,b5ednh,Courses Like CS231n and CS224n,https://www.reddit.com/r/deeplearning/comments/b5ednh/courses_like_cs231n_and_cs224n/,abhiksark,1553538394,"What are some best university courses in Deep Learning.

I am aware of Cs231n and Cs224n.

Any more courses like these? ",7,11
235,2019-3-26,2019,3,26,4,b5f58j,Video analytics plausibility question for a basketball app,https://www.reddit.com/r/deeplearning/comments/b5f58j/video_analytics_plausibility_question_for_a/,maholeycow,1553542052,"Hey everyone! So I am a total newb when it comes to AI/ML/DL... and I was hoping to get your insight. Would it be possible to use computer vision to train data sets with videos of professional basketball players shooting a basketball from a few angles and capturing things like the angle of their knee bend, angle of the back, angle of their shooting pocket, jump height, release point at certain jump height, velocity, etc.. and turn that into structured data so that users of say a mobile app can upload videos of themselves shooting and try to mimick the form of their favorite player with feedback from the application?

&amp;#x200B;

If so, what frameworks are out there that I could look into? It'd be cool to get an MVP out there in the next year or two as a side project. I am a software engineer at a pretty great company but I have had this idea in my head for while and wanted to make it as a side project if possible. ",3,1
236,2019-3-26,2019,3,26,6,b5gfka,Deep Learning PC Spec... Is it any good.,https://www.reddit.com/r/deeplearning/comments/b5gfka/deep_learning_pc_spec_is_it_any_good/,CoderYo,1553548081,"Hey 

&amp;#x200B;

Just wondering if this is a good setup for deeplearning use only... I have read up on specs for deep learning (wide range of topics I want to be able to do with this system), wondering if I have this right for what I have listed. Any feedback welcome.. Cheers

&amp;#x200B;

DEEP LEARNING

\*Intel Core i9 9900X

\*Gigabyte X299 UD4 Pro Motherboard

\*Corsair CMT64GX4M4C3000C15 Dominator Platinum RGB 64GB 3000MHz DDR4

\*NZXT Kraken X62 Liquid CPU Cooler (With AM4 Bracket)

\*Samsung 860 EVO 2TB M.2 (SATA) SSD

\*2 x Seagate BarraCuda SSD 500GB, 2.5in SATA III

\*Seagate BarraCuda 8TB, ST8000DM004 (Used for previous training data/backup)

\*2 x Gigabyte GeForce RTX 2080 Ti Windforce, 11GB

\*ZOTAC GAMING GeForce RTX NVLink Bridge - 3 Slot

\*Seasonic Prime 1300W Power Supply

\*Fractal Design Meshify S2 Blackout E-ATX Case, T/G Window, No PSU

\*2 x AOC Q27P1 27inch IPS QHD Monitor

\*Logitech Brio Webcam",1,1
237,2019-3-26,2019,3,26,6,b5gw79,Quantizing a neutral net to custom data types,https://www.reddit.com/r/deeplearning/comments/b5gw79/quantizing_a_neutral_net_to_custom_data_types/,rafeey,1553550249,"I want to quantize yolo and SSD to custom fixed point data types to study the effect on accuracy. Can anyone who've done that please guide me how to do that?  
I've tried tflite converter but it gives error on custom nets like yolo. Plus it only supports int8 conversion. Is there any other way to do it?",1,2
238,2019-3-26,2019,3,26,8,b5i5sv,"Deep Learning from Scratch to GPU: The Backward Pass (CUDA, OpenCL, Nvidia, AMD, Intel)",https://www.reddit.com/r/deeplearning/comments/b5i5sv/deep_learning_from_scratch_to_gpu_the_backward/,dragandj,1553556552,,0,10
239,2019-3-26,2019,3,26,13,b5lbhv,"How does mxnet work with the latest RTX GPUs (2070, 2080, etc)",https://www.reddit.com/r/deeplearning/comments/b5lbhv/how_does_mxnet_work_with_the_latest_rtx_gpus_2070/,heroesneverdie,1553574861,"Cannot find much info on their official website. Many public benchmarks use tensorflow. Curious to know if people have experience in this. Thanks. 

&amp;#x200B;",0,1
240,2019-3-26,2019,3,26,14,b5ln56,"Error 'Failed to get convolution algorithm' shows up, even though cudNN seems to be installed.",https://www.reddit.com/r/deeplearning/comments/b5ln56/error_failed_to_get_convolution_algorithm_shows/,ZeroMaxinumXZ,1553577079,"So, I have a machine with a RTX 2060, and I want to run tensorflow on it. However, the error, Failed to get convolution algorithm, is showing up despite me installing cudNN on it.

&amp;#x200B;

I have Tensorflow-GPU 1.13.1 running on my Linux (Xubuntu 18.04) machine. I have followed the instructions on the site (which are below), and have installed via pip tensorflow-gpu.

&amp;#x200B;

Instructions I've followed:

    
    
    # Add NVIDIA package repositories
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
    sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
    sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
    sudo apt-get update
    wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
    sudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
    sudo apt-get update
    
    # Install NVIDIA driver
    sudo apt-get install --no-install-recommends nvidia-driver-410
    # Reboot. Check that GPUs are visible using the command: nvidia-smi
    
    # Install development and runtime libraries (~4GB)
    sudo apt-get install --no-install-recommends \
        cuda-10-0 \
        libcudnn7=7.4.1.5-1+cuda10.0  \
        libcudnn7-dev=7.4.1.5-1+cuda10.0
     https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb sudo dpkg -i cuda-repo-ubunt
    
    # Install TensorRT. Requires that libcudnn7 is installed above.
    sudo apt-get update &amp;&amp; \
            sudo apt-get install nvinfer-runtime-trt-repo-ubuntu1804-5.0.2-ga-cuda10.0 \
            &amp;&amp; sudo apt-get update \
            &amp;&amp; sudo apt-get install -y --no-install-recommends libnvinfer-dev=5.0.2-1+cuda10.0
    

&amp;#x200B;

Error I get:

    2019-03-25 23:16:50.938950: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
    2019-03-25 23:16:52.732720: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
    2019-03-25 23:16:52.736377: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
    Traceback (most recent call last):
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
        return fn(*args)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
        options, feed_dict, fetch_list, target_list, run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
        run_metadata)
    tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node ppo/actions-and-internals/layered-network/apply/conv2d0/apply/Conv2D}}]]
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""start.py"", line 54, in &lt;module&gt;
        main()
      File ""start.py"", line 51, in main
        main_loop(agent, curiousity_engine)
      File ""start.py"", line 23, in main_loop
        action1 = agent.act(states=get_screen())
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/agent.py"", line 148, in act
        independent=independent
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 1393, in act
        fetch_list = self.monitored_session.run(fetches=fetches, feed_dict=feed_dict)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 676, in run
        run_metadata=run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1270, in run
        raise six.reraise(*original_exc_info)
      File ""/home/user/.local/lib/python3.6/site-packages/six.py"", line 693, in reraise
        raise value
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1255, in run
        return self._sess.run(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1327, in run
        run_metadata=run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1091, in run
        return self._sess.run(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
        run_metadata_ptr)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
        feed_dict_tensor, options, run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
        run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
        raise type(e)(node_def, op, message)
    tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node ppo/actions-and-internals/layered-network/apply/conv2d0/apply/Conv2D (defined at /home/user/.local/lib/python3.6/site-packages/tensorforce/core/networks/layer.py:1079) ]]
    
    Caused by op 'ppo/actions-and-internals/layered-network/apply/conv2d0/apply/Conv2D', defined at:
      File ""start.py"", line 54, in &lt;module&gt;
        main()
      File ""start.py"", line 41, in main
        agent, user_input = agent_build()
      File ""/home/user/Downloads/v2 (2)/agent.py"", line 37, in agent_build
        actions_exploration = 'epsilon_decay'
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/ppo_agent.py"", line 155, in __init__
        entropy_regularization=entropy_regularization
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/learning_agent.py"", line 141, in __init__
        batching_capacity=batching_capacity
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/agent.py"", line 80, in __init__
        self.model = self.initialize_model()
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/ppo_agent.py"", line 183, in initialize_model
        likelihood_ratio_clipping=self.likelihood_ratio_clipping
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/pg_prob_ratio_model.py"", line 88, in __init__
        gae_lambda=gae_lambda
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/pg_model.py"", line 98, in __init__
        requires_deterministic=False
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/distribution_model.py"", line 90, in __init__
        discount=discount
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/memory_model.py"", line 114, in __init__
        reward_preprocessing=reward_preprocessing
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 217, in __init__
        self.setup()
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 290, in setup
        independent=independent
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/memory_model.py"", line 605, in create_operations
        independent=independent
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 1193, in create_operations
        independent=independent
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 1019, in create_act_operations
        deterministic=deterministic
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 368, in __call__
        return self._call_func(args, kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 311, in _call_func
        result = self._func(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/distribution_model.py"", line 187, in tf_actions_and_internals
        return_internals=True
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 368, in __call__
        return self._call_func(args, kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 311, in _call_func
        result = self._func(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/core/networks/network.py"", line 253, in tf_apply
        x = layer.apply(x=x, update=update)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 368, in __call__
        return self._call_func(args, kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 311, in _call_func
        result = self._func(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/core/networks/layer.py"", line 1079, in tf_apply
        x = tf.nn.conv2d(input=x, filter=self.filters, strides=(1, stride_h, stride_w, 1), padding=self.padding)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1026, in conv2d
        data_format=data_format, dilations=dilations, name=name)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
        op_def=op_def)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
        return func(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
        op_def=op_def)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
        self._traceback = tf_stack.extract_stack()
    
    UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node ppo/actions-and-internals/layered-network/apply/conv2d0/apply/Conv2D (defined at /home/user/.local/lib/python3.6/site-packages/tensorforce/core/networks/layer.py:1079) ]]
    

&amp;#x200B;",4,3
241,2019-3-26,2019,3,26,16,b5mnup,All AI News in one Place,https://www.reddit.com/r/deeplearning/comments/b5mnup/all_ai_news_in_one_place/,ai_jobs,1553584659,,2,4
242,2019-3-26,2019,3,26,17,b5n5y5,Advanced TensorFlow For Advance Deep Learning and Cognotive Computing,https://www.reddit.com/r/deeplearning/comments/b5n5y5/advanced_tensorflow_for_advance_deep_learning_and/,AIhacker99,1553589048,"Watch the latest DL concepts of TensorFlow for developers. I have included my deep-voice-conversion algorithms to convert my voice in this video. Hope you all like it. I practice what I preach it. Please share my latest videos on Deep Learning to all you friends and Data Engineers. Have a good time watching this video

&amp;#x200B;

[https://youtu.be/qh9xhFGEIWo](https://youtu.be/qh9xhFGEIWo)",0,8
243,2019-3-26,2019,3,26,19,b5nwkm,What is Machine Learning? Machine Learning Tutorial With Python,https://www.reddit.com/r/deeplearning/comments/b5nwkm/what_is_machine_learning_machine_learning/,surbhipatel432,1553595300,,1,3
244,2019-3-26,2019,3,26,19,b5nxwf,Tensorflow/Pytorch?,https://www.reddit.com/r/deeplearning/comments/b5nxwf/tensorflowpytorch/,arshad_221b,1553595596,What should I learn? I'm a beginner in Deep learning...,4,0
245,2019-3-26,2019,3,26,21,b5p3b0,Deploying Pre-trained Pytorch Model,https://www.reddit.com/r/deeplearning/comments/b5p3b0/deploying_pretrained_pytorch_model/,priya90r,1553603333,"I am trying to understand how to deploy Pytorch models to Google Cloud. I was using the pre-trained Pytorch German-to-English translation model. How do I go about making a Flask API for the same and deploying it in Google Cloud?

&amp;#x200B;

Thanks",3,1
246,2019-3-26,2019,3,26,23,b5q6vo,Solution approaches and ideas for the development and optimization of a computerized procedure for the recognition of LEGO bricks,https://www.reddit.com/r/deeplearning/comments/b5q6vo/solution_approaches_and_ideas_for_the_development/,melbrssl,1553609524,"In my bachelor thesis I dealt with the question how a computer can recognize LEGO bricks. With multiple object detection, I chose a deep learning approach. I also looked at the existing training set of LEGO brick images and tried to optimize it.

&amp;#x200B;

**Task**

A photo of several LEGO bricks is sent to a program and the program detects the LEGO bricks in the photo.

&amp;#x200B;

**Approach 1: Muliple Object Detection**

In a first approach I used [Tensorflow's Object Detection API](https://github.com/tensorflow/models/tree/a8bb5926525763c1e6a023780573cf3e0e29b916/research/object_detection) to detect several bricks in an image. I trained the network with photos of one LEGO brick at a time, taken with the help of a turntable and a stepper motor. The photos show the LEGO brick from different directions, but always on the same background and from the same angle. The pictures were labelled manually.

The Neural Network could not detect all the LEGO bricks in the test photos. The main reason I suspected was the choice of the training data set.

&amp;#x200B;

**Approach 2: Synthetically generated training set**

To optimize the multiple object detection approach, I looked at the data set. It showed no variation of the lighting conditions or the viewing angle. So I decided to model a LEGO brick in Blender and program a camera to capture the brick from different angles, on different surfaces and under different lighting conditions. The LEGO bricks were automatically labelled by Blender as they were taken.

The training of a new Neural Network with the synthetically generated data set lead to significantly better results. However, the recognition of several LEGO bricks in one photo still has to be improved further.

&amp;#x200B;

**My result**

Through both approaches, the multiple object detection and the generation of a synthetic data set to optimize the training data, I was able to achieve a detection rate of 95.2% for one LEGO brick to be detected. For images with several LEGO bricks, the recognition rate was 73.3%. 

One of the main problems I noticed was, that I tried to distinguish three different 2x4 bricks. However, colors are difficult to distinguish, especially in different lighting conditions. A better approach would have been to distinguish a 2x4 from a 2x2 and a 2x6 LEGO brick.

Furthermore, I have noticed that the training set should best consist of ""normal"" and synthetically generated images. The synthetic images give variations in the lighting conditions, the backgrounds, etc., which the photographed images do not give. However, when using the trained Neural Network, photos and not synthetic images are examined. Therefore, photos should also be included in the training data set.

One last point that would probably lead to even better results is that you train the Neural Network with pictures that show more than one LEGO brick. Because this is exactly what is required by the Neural Network when it is in use.

&amp;#x200B;

**More ideas and solutions**

Can you see any further potential for improvement for the Neural Network?

How would you approach the issue?

Which of my approaches don't seem well chosen?

How do you solve the question?",1,2
247,2019-3-26,2019,3,26,23,b5qh6g,I'm trying to train a CNN to classify sound data. How should I preprocess sound files of different lengths?,https://www.reddit.com/r/deeplearning/comments/b5qh6g/im_trying_to_train_a_cnn_to_classify_sound_data/,RnabSanyal,1553611068,"The sound files are of different lengths. This is my first time working with sound data. Based on one of the approaches I read about, I'm gonna try to use a window to get cuts of the sound files to get instances of equal length. Is there a better approach than this? Any help is appreciated!",10,15
248,2019-3-27,2019,3,27,1,b5rsys,Stochastic Gradient Descent,https://www.reddit.com/r/deeplearning/comments/b5rsys/stochastic_gradient_descent/,sriharsha_0806,1553617576,"In chapter 5 of Machine learning  Basics of Deep learning textbook of Ian Goodfellow, (5.9 stochastic gradient descent paragraph after equation 5.99). It is mentioned ""The optimization algorithm may not be guaranteed to arrive at even a local minimum in a reasonable amount of time, but it often finds a very low value of the cost function quickly enough to be useful"". 

what is the meaning behind this sentence? If I am not wrong isn't very low value of cost function is itself a local minimum.",1,1
249,2019-3-27,2019,3,27,3,b5t5ra,How can i know if i can implement a particular model on my dataset?,https://www.reddit.com/r/deeplearning/comments/b5t5ra/how_can_i_know_if_i_can_implement_a_particular/,nisucuk,1553624174,"I found a paper named "" CNN-RNN: A Unified Framework for Multi-Label Image Classification.""

It had worked on MScoco dataset, NUs-wide, Pascal VOC 2007. I have a datset which is a part of ROCO dataset.

How can i know if i can use the model described in this paper, for my dataset???

&amp;#x200B;",0,1
250,2019-3-27,2019,3,27,6,b5vdy7,New to ML,https://www.reddit.com/r/deeplearning/comments/b5vdy7/new_to_ml/,slaptastico,1553634859,"Hello

So i just started learning machine learning and i wanted to attempt to create a model where it colorizes grayscale images.

I am doing this as a final year project that is due in 3 months. Is this enough to write, train and test?

Also in your opinions, is this a good project for university?

And are there any good resources you might suggest i read?

Thank you! ",4,0
251,2019-3-27,2019,3,27,12,b5zgdv,Number of bounding boxes in Tensorflow Object detection module,https://www.reddit.com/r/deeplearning/comments/b5zgdv/number_of_bounding_boxes_in_tensorflow_object/,naboo_random,1553657352,"I'm doing inference using one of the pre-trained models, tensorflow object detection. However, the train config of the model limits the number of detections to just 5 boxes. Any idea on how to change this parameter during inference?

The model i'm using is the one trained on [link](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#inaturalist-species-trained-models). It's config is [here](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config), and [here](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config). The max\_total\_detection is set to 5 here. I'm not sure how to update this to get more number of updates.

Any help will be highly appreciated!

I have tried loading the graph and seeing the variables in the pretrained model. I found a variable that says ""num\_detections"", but I'm not sure how to re-assign it with any of the codes that helps in inference.

During inference, I use the code [here](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb)

I add the following line:

    num_detections = tf.get_default_graph().get_tensor_by_name('num_detections:0') sess.run(tf.assign(num_detections, num_detections+10),feed_dict={image_tensor: np.expand_dims(image,0)}) 

But it gives me an error saying the variable doesn't have any assign attribute. I'm assuming it's because I can't change it.

Is there any other way I can update it? Or would I need to re-train it?",2,8
252,2019-3-27,2019,3,27,13,b5zz9o,Suggestions for model type,https://www.reddit.com/r/deeplearning/comments/b5zz9o/suggestions_for_model_type/,justanator101,1553660818,"Im fairly new to deep learning outside the realm of cnns and lstms. Im doing a course project comparing ML algorithms to a deep learning one. My data is based on gene expressions and each sample has a list of values for each gene. My set is 900 genes so an input is (1,900). I have a custom feature selection algorithm used for the ml stuff and get good results but Im not sure what I should do for the deep learning. 

Ive been thinking of stacked autoencoders fed into a feed forward network? This way itll learn features without the feature selection algorithm and be a deep net. Any other suggestions or comments are appreciated! ",0,1
253,2019-3-27,2019,3,27,13,b608qr,problems when we use Machine Learning to make credit prediction,https://www.reddit.com/r/deeplearning/comments/b608qr/problems_when_we_use_machine_learning_to_make/,GW_KIM,1553662662,"Hi there, is there anyone well knows about make credit prediction using ML/DL ?  
I'm doing a survey about it, but i'm super newbie for financial domain. So it is hard to make some direction of research.

help :)",5,4
254,2019-3-27,2019,3,27,20,b634zp,Creating systems that significantly augment human capabilities with #MachineLearning &amp; #ArtificialInteligence with Wendy Mackay (talk from GOTO Copenhagen 2018),https://www.reddit.com/r/deeplearning/comments/b634zp/creating_systems_that_significantly_augment_human/,mto96,1553684932,,1,1
255,2019-3-27,2019,3,27,20,b635qs,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educational. Do check it out",https://www.reddit.com/r/deeplearning/comments/b635qs/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1553685080,,2,4
256,2019-3-27,2019,3,27,21,b63yom,Question about expanding dataset for YOLO v3,https://www.reddit.com/r/deeplearning/comments/b63yom/question_about_expanding_dataset_for_yolo_v3/,MathKlim,1553690241,"Actually I'm making my own dataset of images. After a while I came to the question if it's possible to double this dataset by just inverting the images. By invertion I mean that you just take an image and the result would be as if you look from the other side. If you got an image of a face looking to the right, you invert it and it would look to the left. 

As a result of this invention, all the bounding boxes would be moved in consequence. Is this operation to double the dataset a good idea, or this counts as repeated data?",1,0
257,2019-3-28,2019,3,28,1,b65zdo,How To Make Deep Learning Models That Dont Suck,https://www.reddit.com/r/deeplearning/comments/b65zdo/how_to_make_deep_learning_models_that_dont_suck/,manneshiva,1553702621,,10,30
258,2019-3-28,2019,3,28,1,b66iv7,Kaggle Kernel on Hyper Opt + Keras,https://www.reddit.com/r/deeplearning/comments/b66iv7/kaggle_kernel_on_hyper_opt_keras/,polyglotdev,1553705194,,0,1
259,2019-3-28,2019,3,28,3,b67qtv,Meta-Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/b67qtv/metareinforcement_learning/,pirate7777777,1553711025,,0,6
260,2019-3-28,2019,3,28,3,b681zd,How to put scalars in tensorboard from Keras outside of the callbacks?,https://www.reddit.com/r/deeplearning/comments/b681zd/how_to_put_scalars_in_tensorboard_from_keras/,nobodywillobserve,1553712514,"I am trying to use

&amp;#x200B;

`with K.get_backend() as sess:`

`with tf.name_scope('custom_scalars'):`

`for k, v in tolog.items():`

`if v is not None:`

`v = tf.Variable(v)`

`tf.summary.scalar(k, v)`

`else:`

`print(f'SKIPPING {k}')`

`merged = tf.summary.merge_all()`

`train_writer = tf.summary.FileWriter(os.path.join(tb_output_dir), sess.graph)`

[`sess.run`](https://sess.run)`(merged)`

&amp;#x200B;

&amp;#x200B;

But am not seeing anything appear in tensorboard except for the loss and val\_loss that the callback puts there. 

&amp;#x200B;

How to get a hold of sess and use it. I think files are landing in the output dir due to that writer.",0,1
261,2019-3-28,2019,3,28,8,b6bm5b,2D to 3D reconstruction,https://www.reddit.com/r/deeplearning/comments/b6bm5b/2d_to_3d_reconstruction/,kavinash366,1553730152,"What are some good 2D to 3D reconstruction papers?

Most of them I've seen construct the shape from the 2d images given the silhouette or the image itself. But I couldn't find any paper that focuses on actual details in the given image. Are there any papers that explored this?

Context: I'm working on reconstructing an MRI (3D) from a single slice. I need to have as much details as possible. I also can't give silhouettes as inputs because there won't be any detail left. ",1,1
262,2019-3-28,2019,3,28,11,b6d5t7,Deep Learning Model for Gait Pattern Recognition,https://www.reddit.com/r/deeplearning/comments/b6d5t7/deep_learning_model_for_gait_pattern_recognition/,supp0rtlife,1553739217,"I am relatively new to deep learning but essentially I am looking for a deep learning courses that will help me in my research which is to recognize Gait Patterns from raw acceleration data, but I am not sure which area of deep learning this concerns, I did work on an LSTM model so would it be RNN? Can someone suggests some university level courses that would help me out in this area. I did check out CS231N but that's more Computer Vision, however I would really appreciate it someone could suggest some university level courses like that. Thanks in advance",13,9
263,2019-3-28,2019,3,28,13,b6eaxr,GIS segmentation model's input data format,https://www.reddit.com/r/deeplearning/comments/b6eaxr/gis_segmentation_models_input_data_format/,karthikziffer,1553746639,I have GIS data in Tiff format. How to convert into training data format ?   Relevant weblinks will be helpful. ,0,3
264,2019-3-28,2019,3,28,13,b6efgr,Question on output_dim of the Embedding layer in keras,https://www.reddit.com/r/deeplearning/comments/b6efgr/question_on_output_dim_of_the_embedding_layer_in/,randomicly,1553747535,"(This is a toy program and I want to understand common techniques of handling large OHE vectors.)

I am experimenting with a toy LSTM network where I want to pass a bag of words OHE representation rather then the commonly used word-vector.

Now the bag of words is large (about 20k) and the OHE representation is a sparse vector of size 20k for each word, so I am running out of memory as expected.

Im trying to use the Embedding layer of keras here with the input_dim being the size of the vocabulary + 1.

I am unable to understand the output_dim variable there. The documentation states:
&gt; output_dim: int &gt;= 0. Dimension of the dense embedding.
I dont know what and how this is chosen. Can someone tell me how to choose this, and also please comment if I am on the right track.


",6,2
265,2019-3-28,2019,3,28,14,b6eop0,Best C++ OpenCL deep learning framework?,https://www.reddit.com/r/deeplearning/comments/b6eop0/best_c_opencl_deep_learning_framework/,iamalex_,1553749387,"I currently use PyTorch for a cross-platform desktop program by converting it to C++ and it can run in production through: [https://pytorch.org/tutorials/advanced/cpp\_export.html](https://pytorch.org/tutorials/advanced/cpp_export.html)

Thing is I would want support Macbooks and AMD's GPU's so I'd like to add OpenCL inference.

&amp;#x200B;

But it either seems like for AMD support everything is heading to RocM, but I don't want that cause I still want to support older and Intel iGPU's.

&amp;#x200B;

Is there any framework that can run in production with C++ and OpenCL that has a good amount of documentation?

The documentation about running PyTorch in a C++ production is really great but sadly it only supports CUDA...

&amp;#x200B;",4,2
266,2019-3-28,2019,3,28,14,b6ey2g,Mandarin Speech-to-Text Models,https://www.reddit.com/r/deeplearning/comments/b6ey2g/mandarin_speechtotext_models/,priya90r,1553751272,"Are there any good models that create transcripts of Chinese audios or some articles on how to train one of the existing models for the same?

&amp;#x200B;

Also how do I get Chinese alphabet list for training a model?

Thanks",0,2
267,2019-3-28,2019,3,28,19,b6h4pf,Built an open source experiment tracker called ModelChimp over past year. Would love to hear your thoughts on the product!,https://www.reddit.com/r/deeplearning/comments/b6h4pf/built_an_open_source_experiment_tracker_called/,kamanjun,1553769058,,3,27
268,2019-3-28,2019,3,28,22,b6ikh3,"Artificial Intelligence is The New Electricity, Are you Kidding Me!",https://www.reddit.com/r/deeplearning/comments/b6ikh3/artificial_intelligence_is_the_new_electricity/,Gabyleon2019,1553778440,"Claiming that Deep Learnings impact on humanity will be as monumental as the discovery of electricity, is not only wrong, but also dangerous!!

What do you guys think?

&amp;#x200B;

 [https://www.linkedin.com/pulse/artificial-intelligence-new-electricity-you-kidding-me-l-hijazi/](https://www.linkedin.com/pulse/artificial-intelligence-new-electricity-you-kidding-me-l-hijazi/) ",10,4
269,2019-3-29,2019,3,29,0,b6jyur,The Rise of Generative Adversarial Networks,https://www.reddit.com/r/deeplearning/comments/b6jyur/the_rise_of_generative_adversarial_networks/,kailashahirwar12,1553785884,,0,3
270,2019-3-29,2019,3,29,0,b6k2dc,Grassland v0.2: Tensorflow CNN + Mapbox 3D == Worldwide SimCity,https://www.reddit.com/r/deeplearning/comments/b6k2dc/grassland_v02_tensorflow_cnn_mapbox_3d_worldwide/,00hello,1553786347,,1,15
271,2019-3-29,2019,3,29,1,b6kl9k,Deep Learning from Scratch to GPU: A Simple Neural Network Inference API,https://www.reddit.com/r/deeplearning/comments/b6kl9k/deep_learning_from_scratch_to_gpu_a_simple_neural/,dragandj,1553788892,,0,3
272,2019-3-29,2019,3,29,7,b6ozsq,Need help understanding backpropogation,https://www.reddit.com/r/deeplearning/comments/b6ozsq/need_help_understanding_backpropogation/,dukes_haven,1553810520,"Am trying to implement a shallow neural network, can somebody explain to me how he coded dZ1?",0,0
273,2019-3-29,2019,3,29,11,b6rpiv,Gradient descent,https://www.reddit.com/r/deeplearning/comments/b6rpiv/gradient_descent/,durgesh2018,1553825610,"Hello everyone!
While calculating gradient descent, why can't we linearly increase or decrease the weight? ",11,6
274,2019-3-29,2019,3,29,11,b6s02x,CNN and GNN together ?,https://www.reddit.com/r/deeplearning/comments/b6s02x/cnn_and_gnn_together/,StupendousEnzio,1553827430,"Can CNN and GNN be implemented together to increase accuracy without the issue of overfitting ? I am a postgrad student pursuing Deep learning and convolutional neural network. I am thinking of doing something in this area, just wanted to get some experienced advice of how feasible it will be. Shoot me questions if you think I am a bit vague in framing the questions. Cheers!",3,2
275,2019-3-29,2019,3,29,13,b6t3r1,Exploring Career Avenues with Deep Learning Certification in 2019,https://www.reddit.com/r/deeplearning/comments/b6t3r1/exploring_career_avenues_with_deep_learning/,SunilAhujaa,1553834990,There are a number of ways you can prepare for future. One surest way to do it is by upgrading your skills and doing Deep Learning Certification. Data literacy and storytelling are the most sought-after skills that the industry is looking it.,0,0
276,2019-3-29,2019,3,29,15,b6txam,Random or Unsupervised features(chapter 9.9 of Deep learning textbook of Ian Good Fellow),https://www.reddit.com/r/deeplearning/comments/b6txam/random_or_unsupervised_featureschapter_99_of_deep/,sriharsha_0806,1553841519,"""Learning the features with an unsupervised criterion allows them(convolutional layers) to be determined separately from the classification layer at the top of the architecture. One can then extract the features for the entire training set just once, essentially constructing a new training set for the last layer. Learning the last layer is then typically a convex optimization problem, assuming the last layer is something like logistic regression or SVM.""  I did not understand this paragraph. 

&amp;#x200B;

How does learning features with an unsupervised criterion make the CNN architectures into two disjoint convolutional layers and classification layer(one is not affecting the other)?",8,5
277,2019-3-29,2019,3,29,20,b6vw1r,Labeling Audio Data,https://www.reddit.com/r/deeplearning/comments/b6vw1r/labeling_audio_data/,yrajsm,1553857499,I am preparing custom audio dataset for classification project. Are there open source labeling tools for audio dataset?,3,3
278,2019-3-29,2019,3,29,21,b6wlpf,DeepSpeech for Mandarin,https://www.reddit.com/r/deeplearning/comments/b6wlpf/deepspeech_for_mandarin/,priya90r,1553862201,"I am trying to train a DeepSpeech model for Mandarin using this [tutorial](https://blog.yuwu.me/?p=3989). I am stuck at finding a generatecsv file that generates a csv file for creating a data for training the model. How do I create/find one?

Thanks",0,4
279,2019-3-30,2019,3,30,0,b6ypkz,Issue with keras and cudNN,https://www.reddit.com/r/deeplearning/comments/b6ypkz/issue_with_keras_and_cudnn/,ZeroMaxinumXZ,1553873501,"I'm having issues with Keras and  tensorflow. Basically, it gives me  the following error ""Segmentation  fault (core dumped)"" anytime I try to fit  a model with a conv2d layer.

My  code works on the CPU. It also works without any conv2d layers  (even  though it's ineffective for my use case). I've got cuda, cudnn,  and  tensorflow installed. I've tried reinstalling keras and tensorflow.   I've tried reinstalling the graphics drivers, CUDA, and all the other   packages. I'm on Ubuntu 16.04 (Mint v18, external USB SSD drive) with   CUDA V9.0, and I simply followed the instructions on Tensorflow (under   GPU support. for 1.12 and under.) to install CUDA. Tensorflow version is   1.12. A theory I have is that cuDNN is somehow broken and needs to be   reinstalled... (Even though I've reinstalled it multiple times so...)

&amp;#x200B;

Code Sample:  


    import numpy as np
    import keras
    
    model = keras.models.Sequential() #Sequential model type.
    model.add(keras.layers.Conv2D(filters=1, kernel_size=(3,3), strides = 1, activation=""sigmoid"")) #Convolutional layer.
    model.add(keras.layers.Flatten()) #Flatten layer.
    model.add(keras.layers.Dense(4)) #Dense layer of 4 units.
    model.compile(loss='mean_squared_error', optimizer='adam') #compile model.
    y = np.random.rand(1,4) #Random expected output
    x = np.random.rand(1, 38, 21, 1) # Random input.
    model.fit(x, y) #And fit... Error occurs here.
    

&amp;#x200B;

Error:  


    Using TensorFlow backend. Epoch 1/1 2019-03-29 03:14:25.259882: I tensorflow/core/platform/cpu_feature_guard.cc:141] 
    Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-03-29 03:14:25.573157: 
    I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] 
    successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-03-29 03:14:25.574989: 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432]
    Found device 0 with properties: name: GeForce RTX 2060 major: 7 minor: 5 memoryClockRate(GHz): 1.83 pciBusID: 0000:01:00.0 
    totalMemory: 5.73GiB
     freeMemory: 5.49GiB 2019-03-29 03:14:25.575033: 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-03-29 03:14:31.770903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 
    Device interconnect StreamExecutor with strength 1 edge matrix: 2019-03-29 03:14:31.770974: 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-03-29 03:14:31.770992: 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-03-29 03:14:31.772113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 
    Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5235 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5) 
    Segmentation fault (core dumped) 
    

&amp;#x200B;",10,1
280,2019-3-30,2019,3,30,2,b701i0,Creating a Neural Network with item embeddings,https://www.reddit.com/r/deeplearning/comments/b701i0/creating_a_neural_network_with_item_embeddings/,Usually_Awkward_32,1553880166,"Hey guys! 

&amp;#x200B;

I hope it is okay to ask something about a project I'm working on. I want to use the instacart database ([https://www.kaggle.com/c/instacart-market-basket-analysis](https://www.kaggle.com/c/instacart-market-basket-analysis)) to create a deep learning recommender system. I made a traditional recommender system before this (based on collaborative filtering), but the sparsity is too high so the results are not that great. At first, I made an item embedding, by doing a word2vec on the add-to-card order for each user (based on the idea that users will browse a category, select similar items, and then continue to another category). The item embeddings work really well, when I look for a similar item to 'soda' I get lemonade and stuff. So, that's great to start with :)

&amp;#x200B;

However, I'm quite the beginner at deep learning (and not that advanced in python). I now want to create a neural network, to forecast what each user will buy next (and thus, make recommendations based on thus). I have made a dataframe where I have the user ID, the product ID and the quantity they purchased. I also have those item embeddings. Now, I'm quite at a loss where to start combining these two. Does anyone maybe have some tips for me? That would be great :) Thank you very much in advance. ",1,9
281,2019-3-30,2019,3,30,4,b71oxv,Training CNN and RNN separately in CRNN,https://www.reddit.com/r/deeplearning/comments/b71oxv/training_cnn_and_rnn_separately_in_crnn/,pk12_,1553888375,"Is it possible to train a CNN first and then add RNN say LSTM to the output of CNN.

Basically, is it possible to load initial layers of the CRNN with weights from the CNN and let the RNN part be trained?

I use keras and wonder if someone has implemented this ",4,5
282,2019-3-30,2019,3,30,7,b73l0o,DeepCamera: Turn your android device into deep learning surveillance monitor which knows person,https://www.reddit.com/r/deeplearning/comments/b73l0o/deepcamera_turn_your_android_device_into_deep/,solderzzc,1553898240,,0,5
283,2019-3-30,2019,3,30,9,b754lf,How essential is it to know C++ well for deep learning jobs?,https://www.reddit.com/r/deeplearning/comments/b754lf/how_essential_is_it_to_know_c_well_for_deep/,74throwaway,1553907136,"I have some experience with image processing but I'm interested in transitioning to a job that involves more deep learning and/or computer vision. I had a couple interviews for these roles recently and a couple of them mentioned C++ would be a major part of the job. They mentioned if I passed the initial phone screen, then they would've test me on my C++ coding. One company worked with autonomous vehicles and the other worked on something else but mentioned they were using C++ to develop their own DL framework similar to Tensorflow

If I want to get a job in DL, am I better off improving my C++? Or just working on any personal project, even if it uses Python and Keras/Pytorch?",19,12
284,2019-3-30,2019,3,30,11,b75tkj,How do I calculate regret in a reinforcement learning algorithm?,https://www.reddit.com/r/deeplearning/comments/b75tkj/how_do_i_calculate_regret_in_a_reinforcement/,ZeroMaxinumXZ,1553911510,"How should I calculate regret in a reinforcement learning algorithm to feed as a negative reward? Any (not just super-mathematical, I'm new to ML and RL) explanations or papers  would be helpful.  Thanks.",6,1
285,2019-3-30,2019,3,30,15,b77zap,permutation invariant,https://www.reddit.com/r/deeplearning/comments/b77zap/permutation_invariant/,sriharsha_0806,1553926660,"Chapter 9.4 last paragraph of Ian Goodfellow Deeplearning textbook.  

""Models that do not use convolution would be able to learn even if we permuted all the pixels in the images.  For many images datasets there are separate benchmarks for models that are permutation invariant and mist discover the concept of topology via learning ""

&amp;#x200B;

I did not understand first sentence and what is concept of topology and what are the models that are permutation invariant?",5,8
286,2019-3-31,2019,3,31,3,b7ensr,Implementing text localization on Natural Image Scenes using tensorflow,https://www.reddit.com/r/deeplearning/comments/b7ensr/implementing_text_localization_on_natural_image/,mutyalu_amballa,1553972324,"I started working on a project in which I want to localize the text in the natural scenery images. For example consider an image that contains text in different parts of the image, with different sizes for each word. So how can I find the locations of all the words in the image.

Previous research:
I found some information in some papers, 
1) which explains that they are using a localization network(CNN + RNN). which produces 'n'(n is total words in the image) affine matrices for each word in the image. 
2) And also other variations which uses the sliding window of different sizes, sliding across the image and trying to find the presence of text. 

I am not able to find any resources that helps me with the implementation in python, tensorflow 

This is a reference link I came across:

https://medium.com/syncedreview/stn-ocr-a-single-neural-network-for-text-detection-and-text-recognition-220debe6ded4

Can anyone suggest me the resources required to achieve this task..!

- Thanks",0,1
287,2019-3-31,2019,3,31,4,b7eukc,Implementing text localization on Natural Scene images using tensorflow,https://www.reddit.com/r/deeplearning/comments/b7eukc/implementing_text_localization_on_natural_scene/,mutyalu_amballa,1553973312,"I started working on a project in which I want to localize the text in the natural scenery images. For example consider an image that contains text in different parts of the image, with different sizes for each word. So how can I find the locations of all the words in the image.

Previous research:
I found some information in some papers, 
1) which explains that they are using a localization network(CNN + RNN). which produces 'n'(n is total words in the image) affine matrices for each word in the image. 
2) And also other variations which uses the sliding window of different sizes, sliding across the image and trying to find the presence of text. 

I am not able to find any resources that helps me with the implementation in python, tensorflow 

This is a reference link I came across:

https://medium.com/syncedreview/stn-ocr-a-single-neural-network-for-text-detection-and-text-recognition-220debe6ded4

Can anyone suggest me the resources required to achieve this task..!

- Thanks",9,4
288,2019-3-31,2019,3,31,4,b7f7fq,"A parallel implementation of Walklets from ""Don't Walk Skip! Online Learning of Multi-scale Network Embeddings"" (ASONAM 2017).",https://www.reddit.com/r/deeplearning/comments/b7f7fq/a_parallel_implementation_of_walklets_from_dont/,benitorosenberg,1553975309,"&amp;#x200B;

&amp;#x200B;

https://i.redd.it/ck05xupo8bp21.jpg

Github: [https://github.com/benedekrozemberczki/walklets](https://github.com/benedekrozemberczki/walklets)

Paper: [https://arxiv.org/abs/1605.02115](https://arxiv.org/abs/1605.02115)

Abstract:

We present Walklets, a novel approach for learning multiscale representations of vertices in a network. In contrast to previous works, these representations explicitly encode multiscale vertex relationships in a way that is analytically derivable.  Walklets generates these multiscale relationships by subsampling short random walks on the vertices of a graph. By \`skipping' over steps in each random walk, our method generates a corpus of vertex pairs which are reachable via paths of a fixed length. This corpus can then be used to learn a series of latent representations, each of which captures successively higher order relationships from the adjacency matrix. We demonstrate the efficacy of Walklets's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, DBLP, Flickr, and YouTube. Our results show that Walklets outperforms new methods based on neural matrix factorization. Specifically, we outperform DeepWalk by up to 10% and LINE by 58% Micro-F1 on challenging multi-label classification tasks. Finally, Walklets is an online algorithm, and can easily scale to graphs with millions of vertices and edges.",0,2
289,2019-3-31,2019,3,31,4,b7f96h,"DL in production: what tools are in your ""full"" software stack?",https://www.reddit.com/r/deeplearning/comments/b7f96h/dl_in_production_what_tools_are_in_your_full/,PullThisFinger,1553975589,,2,23
290,2019-3-31,2019,3,31,15,b7kusi,What will future generations think about us?,https://www.reddit.com/r/deeplearning/comments/b7kusi/what_will_future_generations_think_about_us/,arshad_221b,1554014564,"We are building these neural networks to make our lives better. We are improving each and every field with power of AI. 
But on the other side, AI is stealing the jobs. Robots are becoming stronger and smarter. So what our future generations will think about us? What they will say? We made the world better or stole their jobs? ",8,1
291,2019-3-31,2019,3,31,17,b7lmq5,Is it worth to buy 2 EVO 970 plus 1 TB in Raid 0 for my deep learning build?,https://www.reddit.com/r/deeplearning/comments/b7lmq5/is_it_worth_to_buy_2_evo_970_plus_1_tb_in_raid_0/,kitgary,1554021747,"I am building a PC for deep learning, I have already picked up all other parts but just cant decide if I should have a NVME SSD raid 0 setup, I want to build the fastest PC for deep learning. Btw, I am now using 9980xe, 3x2080Ti, 128GB DDR4 Ram.",4,6
292,2019-3-31,2019,3,31,18,b7m0oi,Deep Learning PC Spec... Is it any good,https://www.reddit.com/r/deeplearning/comments/b7m0oi/deep_learning_pc_spec_is_it_any_good/,whoisweaknow,1554025294,"Hey

Just wondering if this is a good setup for deeplearning and other AI stuff use only... I have read up on specs for deep learning (wide range of topics I want to be able to do with this system), wondering if I have this right for what I have listed. Any feedback welcome.. Cheers

&amp;#x200B;

* Nvidia Titan RTX
* AMD Ryzen Threadripper 1920X  (12 Core)
* MSI  X399 Gaming Pro Carbon AC
* Thermaltake toughpower 80 plus gold
* Cooler Master Masterliquid ML360 AMD TR4
* Samsung 250 GB 970 Evo Plus NVMe M.2 SSD --------------------------- (x2)
* Thermalleke View 37 Rgb Riing Edition MidT E-ATX Case (With Fans)
* GSKILL 32GB (16x2) SniperX DDR 4 3000Mhz  ---------------------------(x2)",9,1
293,2019-3-31,2019,3,31,19,b7m700,Final Wars,https://www.reddit.com/r/deeplearning/comments/b7m700/final_wars/,warlord_64,1554026821,,1,0
0,2019-4-1,2019,4,1,13,b7xkjb,Does anyone know what this in Google Colab ?,https://www.reddit.com/r/deeplearning/comments/b7xkjb/does_anyone_know_what_this_in_google_colab/,dev853,1554094542,,10,5
1,2019-4-1,2019,4,1,14,b7xn31,Deep learning benchmark tool | Benchmark GPU's to know which one is the best for your deep learning workflow,https://www.reddit.com/r/deeplearning/comments/b7xn31/deep_learning_benchmark_tool_benchmark_gpus_to/,gimel1213,1554094977,"**So you are building your new Deep Learning workstation to perform some state-of-the-art computations and run really deep and sophisticated models, but you are indecisive as to which GPU to go for, or you already have a set of GPUs that you are planning to use, but need to know just how efficient are these when compared to whats out there. In this blog post, I plan to present to you an app that will solve both of these problems to you, with no cost associated.**

**Deep Learning is a field that requires some serious computational power, and by using a CPU, you might spend weeks training your model, while a strong GPU would finish the job during the day. This is mainly because of the difference between these two pieces of hardware regarding the design, as we shall see in a minute when we discuss the different types of HW used for Deep Learning, but for now its just good to bear in mind that more efficient hardware will mean not only faster training experiences, but also more room for model tuning and algorithms testing, that will make your life as a Deep Learning developer a lot easier.**

&amp;#x200B;

&amp;#x200B;

[DLBT app | Deep learning Benchmark tool ](https://i.redd.it/ltnpfpqi3lp21.png)

&amp;#x200B;

## Types of Hardware

**If we are going to discuss what are the best pieces of hardware to perform deep learning tasks, we should first take a look at the different types, the following diagram shows the classification breaking it down to four classes.**

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/blcdc78z3lp21.png

**As we can see in the previous diagram, general purpose hardware category splits into Central Processing Units (CPU) and Graphic Processing Units (GPU). The former is specifically designed to be latency oriented, this means it should be able to do complicated big tasks, one after the other, just like a big elephant. As for the GPU, this one is throughput oriented, which implies it specializes in performing many many small dumb tasks simultaneously, resembling a group of small ants.**

**Field Programmable Gate Arrays (FPGA) is a special piece of hardware that allows for programmable logic, this means that the developer can design the hardware structure of the device several times to implement a particular application. This might really come in handy if you want to try out new ideas and prototypes, and its performance increases relative to the general purpose hardware as long as the design is efficient enough.**

**Application Specific Integrated Circuits (ASIC) are much rarer to come by, it implies someone took the job of carefully designing the hardware that solves the problem at hand, and printed the circuit, so this hardware would only make sense when used for that application. Googles Tensor Processing Units (TPU) are a state of the art ASIC circuit. Although ASICs turn out to be faster than FPGAs, they are harder to obtain and assemble into our deep learning workstations.**

**The Deep Learning Bench Tools Application focuses on the General Purpose hardware, as it is by far the most repeatedly used.**

&amp;#x200B;

## DLBT Application

**Suppose you just bought your Graphics Card(s) and plugged it into your motherboard, expecting to run some next level algorithms very fast. It would be very useful if you had a tool that told you how fast is the combination of your CPU with the Graphic Processing Units at your disposal, and that on top of it let you compare the results to other deep learning workstations around the globe to see if youre happy where you stand. Well, look no more, DLBT is the answer.**

**This hardware bench tool automatically recognizes the Machine Learning capable hardware in your computer, this might be just the CPU, in case you have no GPU, or you havent installed the required drivers (if this is the case, we walk you through how to do this, line by line), or it may be multiple GPUs, in which case you have the choice of where to run the benchmark models.**

### Model Used

**In its current version the DLBT app is running a Convolutional Neural Net, with a standard structure in the background, while taking note of how long an episode lasts, as well as splitting this time into the prediction time and the back-propagation time for more advanced users.**

**The structure of the model used, might be seen in the following image.**

&amp;#x200B;

&amp;#x200B;

[Convolutional Neural Net used in the Test Bench](https://i.redd.it/6bxfc4e64lp21.png)

&amp;#x200B;

**As a future update we are currently working on extending this feature into multiple known benchmarks having to do with Recurrent Neural Networks, Natural Language Processing, etc.**

### Obtaining the rating

**How to measure exactly how efficient is the device running? We use the formula displayed below. Intuitively, it would be better for the ratings to increase as the hardware efficiency rises. The K scaling factor serves the purpose of spreading the results more to allow for better comparison.**

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/kzmk3wsd4lp21.png

### Results

**This application has been run on many GPUs to measure their performance running the model explained previously, the following table depicts some of the results thrown by the app. In** [**here**](https://www.technopremium.com/results) **you will find many more results of other pieces of hardware.**

&amp;#x200B;

## Conclusions

**There you have it, you just discovered an easy way to measure your hardware performance, without writing a single line of code.** [**DLBT**](https://drive.google.com/file/d/1gDMs3pLG-UzcEZ0AunnWzWHMwGdfqKxm/view?usp=sharing) **is a GUI application that automatically detects your GPUs, lets you monitor them and run deep learning benchmarks to compare their performance to the standards.** ",3,0
2,2019-4-1,2019,4,1,14,b7y14c,How to prepare your Ubuntu 18.04 ready for deep learning | Full stack installation,https://www.reddit.com/r/deeplearning/comments/b7y14c/how_to_prepare_your_ubuntu_1804_ready_for_deep/,gimel1213,1554097383,"    I remember the first time I was setting the computer to start developing for deep learning, it was a hassle because at that time the information online was not enough and there was a lot of problems when installing the frameworks and drivers to make the GPU's ( Nvidia ) work properly with the stack. 

&amp;#x200B;

That's why I decided to create a guide so everyone can do the full stack installation and get their machine ready for development, this part will install Nvidia driver 415.27, CUDA 10 for the full stack check our blog [here](https://technopremium.com/blog/) the process is pretty straight forward, just copy and paste the commands from here to your terminal and you should be ready to go. 

&amp;#x200B;

&gt;!This install can be used by anyone using Ubuntu 18.04, gamers can benefits from it too, so you are WELCOME :))))!&lt;

&amp;#x200B;

What we are going to install: 

&amp;#x200B;

Drivers: 

1- Nvidia drivers 

2- CUDA 10 

3- Cuddn 7.4 

4- Nccl - For multi GPU's training 

&amp;#x200B;

Frameworks: 

1- Pytorch 

2- Tensorflow 

3- Theano 

4- Caffe2 

5- Julia 

&amp;#x200B;

&gt;!Ok let's get started!&lt; 

&amp;#x200B;

**EACH LINE MUST BE ""COPIED AND PASTED"" ONE LINE AT A TIME**

    sudo apt-get update
    sudo apt-get upgrade

&amp;#x200B;

    lspci | grep -i nvidia
    uname -m &amp;&amp; cat /etc/*release
    sudo apt-get install linux-headers-$(uname -r)
    sudo apt autoremove

&amp;#x200B;

    sudo apt-get install build-essential -y
    sudo apt-get install cmake git unzip zip -y

&amp;#x200B;

    sudo add-apt-repository ppa:graphics-drivers/ppa -y
    sudo apt install nvidia-driver-415 -y

&amp;#x200B;

    sudo wget
    https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda-repo-ubuntu1
    804-10-0-local-10.0.130-410.48_1.0-1_amd64
    sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64
    sudo apt-key add /var/cuda-repo-10-0-local-10.0.130-410.48/7fa2af80.pub
    sudo apt-get update
    sudo apt-get install cuda-toolkit-10-0

&amp;#x200B;

    sudo reboot
    nvidia-smi

&amp;#x200B;

&gt;At this point Nvidia drivers and Cuda should be installed 

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",13,17
3,2019-4-1,2019,4,1,15,b7y9bd,RTX 2060 and 2070 Deep learning benchmarks 2019 | Tensorflow Pytorch,https://www.reddit.com/r/deeplearning/comments/b7y9bd/rtx_2060_and_2070_deep_learning_benchmarks_2019/,gimel1213,1554098861,"&amp;#x200B;

With the release of the RTX 2060 and 2070, it came the idea to measure this cards in order to see the difference between them for deep learning, since the RTX 2060 is $349 it makes sense to see the performance on Tensorflow and Pytorch

&amp;#x200B;

 We use the Yasuko benchmark that can be found here: [https://github.com/u39kun/deep-learni](https://github.com/u39kun/deep-learni)...  The results are based on running the models with images of size 224 x 224 x 3 with a batch size of 16. ""Eval"" shows the duration for a single forward pass averaged over 20 passes. ""Train"" shows the duration for a pair of forwarding and backward passes averaged over 20 runs. In both scenarios, 20 runs of warm-up are performed and those are not counted towards the measured numbers.

&amp;#x200B;

&amp;#x200B;

![video](sypfbv8oflp21 ""DL Benchmark test | RTX 2060 VS 2070"")

&amp;#x200B;

Let me know in the comments what do you think about it, I think the problem with the RTX 2060 is the amount of ram which is 6 GB, but since it has tensor cores inside, it should give it a boost using the new CUDA X and Tensorflow 2.0, hence I have not tested yet. ",3,1
4,2019-4-1,2019,4,1,16,b7z3sz,8x RTX TITAN workstation | I cannot wait to run some models on this beast !!!!,https://www.reddit.com/r/deeplearning/comments/b7z3sz/8x_rtx_titan_workstation_i_cannot_wait_to_run/,gimel1213,1554104673,,37,117
5,2019-4-1,2019,4,1,17,b7zahd,Problem when Loading data in Pytorch using Spyder,https://www.reddit.com/r/deeplearning/comments/b7zahd/problem_when_loading_data_in_pytorch_using_spyder/,smukh98,1554106002,"Hey all,
I was working with a dataset of images (3*150*150)  in Pytorch in Spyder ide .wrote a simple classifier.Tge problem I am facing is that when I am loading the data using Dataset class ,the Spyder ide hogs all the ram and memory usage goes upto 99% ,and then it just hangs .I waited for half an hour to let it load and still nothing happens. The dataset size is about 25000. Can anyone help me with this problem?
",4,1
6,2019-4-1,2019,4,1,17,b7zmgx,Deep Learning on Mobile Devices,https://www.reddit.com/r/deeplearning/comments/b7zmgx/deep_learning_on_mobile_devices/,RobertCotterman,1554108540,,0,1
7,2019-4-1,2019,4,1,18,b800lb,Does anyone have links to a tutorial that uses pytorch for classification/regression on a tabular dataset? Many thanks! :),https://www.reddit.com/r/deeplearning/comments/b800lb/does_anyone_have_links_to_a_tutorial_that_uses/,ai_badger,1554111392,"
",0,1
8,2019-4-1,2019,4,1,22,b82932,Uses of Artificial Intelligence in Health Care and How It Helps in Diagnosing Rare Genetic Disorders,https://www.reddit.com/r/deeplearning/comments/b82932/uses_of_artificial_intelligence_in_health_care/,BlockDelta,1554124598,,0,1
9,2019-4-1,2019,4,1,23,b833bh,NLP Learning Series: Part 4 - Transfer Learning Intuition for Text Classification,https://www.reddit.com/r/deeplearning/comments/b833bh/nlp_learning_series_part_4_transfer_learning/,kiser_soze,1554128903,,0,1
10,2019-4-2,2019,4,2,0,b83qe6,How to share weights inside an tf.estimator.Estimator model_fn?,https://www.reddit.com/r/deeplearning/comments/b83qe6/how_to_share_weights_inside_an/,nobodywillobserve,1554131948,"I was trying to do something with the following pattern:

&amp;#x200B;

`def model_fn(features, labels):`

   `x_input = tf.placeholder(...)`

`def inner_thing(x):`

`with tf.variable_scope('asdf', reuse=tf.AUTO_REUSE):`

`return tf.layers.dense(x, 10, name='thing')`

`a = inner_thing(features['a'])`

`b = inner_thing(features['b'])`

`... combine etc deal with ModeKeys etc`

&amp;#x200B;

&amp;#x200B;

But I don't think that works as you need some sort of [sess.run](https://sess.run) and a feed\_dict to make the placeholders eat some data and estimator is supposed to do all that for you.

&amp;#x200B;

Any suggestions on how to restructure? 

&amp;#x200B;

&amp;#x200B;



",2,1
11,2019-4-2,2019,4,2,1,b84zod,SysML '19 Livestream,https://www.reddit.com/r/deeplearning/comments/b84zod/sysml_19_livestream/,xldrx,1554137752,,1,1
12,2019-4-2,2019,4,2,10,b8cp7o,RTX TITAN Benchmark results 2019 | VGG16 - FP 16 &amp; FP32 | Tensorflow 1.4.0,https://www.reddit.com/r/deeplearning/comments/b8cp7o/rtx_titan_benchmark_results_2019_vgg16_fp_16_fp32/,gimel1213,1554169144,"**VGG16 - FP 16 Combine Chart - Training values** 

**FP 16 - Using the new tensor cores on the Graphic cards.** 

&amp;#x200B;

**Card used:** 

**GTX 1080 TI, RTX 2070, 2080, 2080 TI, TITAN RTX, TITAN V** 

&amp;#x200B;

After a long day testing, here are the results I got from the Benchmarks: 

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/j63buij98rp21.png

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/anu6o9ob8rp21.png

&amp;#x200B;

The performance Benchmark show us that using FP16 the time for training is much better, this is because FP16 use the tensor cores on the new RTX cards and the Titan V, I think the reason why the Titan V is the best is because of the HBM2 memory, looking at the TITAN RTX should be the most powerful since it has 24 GB of Ram but actually is not. 

&amp;#x200B;

In terms of price I would say that the RTX 2080 Ti has the best value here, if you want to check and test your hardware you can use our app [DLBT ( Deep learning benchmark tool )](https://technopremium.com/) and upload your results to our community site so you can be one of the top 10. 

&amp;#x200B;

I am planning to build a deep learning workstation under $3000 using 4x GTX 1080 TI and a Threadripper 1900 , since this CPU has 64 PCI lanes should perform even better than the intel CPU X series that has 44 PCI lanes. 

&amp;#x200B;

&amp;#x200B;",10,2
13,2019-4-2,2019,4,2,15,b8fjdw,"4x RTX 2080 Ti | Deep learning workstation, overheating issue fixed !!!!",https://www.reddit.com/r/deeplearning/comments/b8fjdw/4x_rtx_2080_ti_deep_learning_workstation/,gimel1213,1554186999,,24,91
14,2019-4-2,2019,4,2,16,b8fzsb,Face Liveness Detection,https://www.reddit.com/r/deeplearning/comments/b8fzsb/face_liveness_detection/,Ck_LeGrande,1554190160,"I'm a beginner in DL and I just trained my first CNN on the NUAA dataset [http://parnec.nuaa.edu.cn/xtan/data/NuaaImposterdb.html](http://parnec.nuaa.edu.cn/xtan/data/NuaaImposterdb.html) (only worked on 1000 random images) and got a test accuracy of 97.5%. However as this dataset is composed of low resolution images of fake faces, in real life testing, it was fooled by high resolution face images. 

I wanted to know what architecture of a neural network would suit this dataset (or similar datasets ) the best and what measures I must take to make a highly accurate face liveness detection model. ( I know improving my data would be the best in this situation and that is in progress )",1,3
15,2019-4-2,2019,4,2,18,b8gqul,How PV-DBOW works,https://www.reddit.com/r/deeplearning/comments/b8gqul/how_pvdbow_works/,jdyr1729,1554195901,"The authors of the Paragraph Vector paper describe PV-DBOW with:

&gt;**2.3. Paragraph Vector without word ordering: Distributed bag of words**  
&gt;  
&gt;The above method considers the concatenation of the paragraph vector with the word vectors to predict the next word in a text window. Another way is to ignore the context words in the input, but force the model to predict words randomly sampled from the paragraph in the output. In reality, what this means is that at each iteration of stochastic gradient descent, we sample a text window, then sample a random word from the text window and form a classification task given the Paragraph Vector.

I have a couple of questions:

1. Why do you need to sample a text window before sampling a random word? To create a batch, why can't you just randomly sample from a list of the form `[(1, ""cat""), (1, ""sat""), ..., (1, ""mat""), (2, ""humpty""), (2, ""dumpty""), ... (2, ""wall""), ...]` where the first item in each tuple represents the paragraph?
2. If hierarchical softmax or negative sampling is used, is stochastic gradient descent still used to update the weights in the network? Or are these optimization methods themselves?",0,1
16,2019-4-2,2019,4,2,19,b8hdow,where to find good practical implementations?,https://www.reddit.com/r/deeplearning/comments/b8hdow/where_to_find_good_practical_implementations/,jast26,1554200415,"Hello first time poster in this sub :)

To keep it short, i have a lot of theoretical knowledge in machine learning and neural networks, and a tiny beat of genetic algorithms. ( i know about CNN, RNN, LSTM, Q learning, NEAT... , more basic concepts as backprop etc...) the thing is that following theoretical courses online i never had proper assignments so i struggle to implement them. Also Im a basic coder, ( i understand loops, arrays, list, basic operators, structs, a bit of vectorization regarding ML,) 

I dont really know the difference between the various libraries out there (tensorflow,pytorch ...?).

Any good tutorials/ courses to get my hands dirty? Im willing to pay (not an exorbitant amount, around 100 bucks) 

I basically learned to code in order to use Unity3d, so c# neural nets using unity would suit me well for a start, otherwise python its ok

PLEASE DONT LINK ME TO A GITHUB CONTAINING BADLY COMMENT CODE 

I prefer a  proper walkthrough because they are faster and easier to understand than reading code from github. 

Thx everyone for their time :D 

",4,1
17,2019-4-2,2019,4,2,23,b8jmv6,Awesome papers and engineering reviews on Computer Vision News of March. Links for free reading!,https://www.reddit.com/r/deeplearning/comments/b8jmv6/awesome_papers_and_engineering_reviews_on/,Gletta,1554213836,"Here are the links to the April 2019 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: many articles about Artificial Intelligence, Deep Learning, Computer Vision and more.

Free subscription on page 32.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019April/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-april-pdf/)

Enjoy!

https://i.redd.it/7y92kgi2yup21.jpg",0,2
18,2019-4-3,2019,4,3,2,b8mith,Hyperparameters Tuning - Deep Learning,https://www.reddit.com/r/deeplearning/comments/b8mith/hyperparameters_tuning_deep_learning/,19abhilash19,1554227552,"Hello! I wrote a blog in which I compiled all the methods I use to keep track of my grid search results for hyperparameter tuning. 

&amp;#x200B;

[https://www.redmarlin.ai/hyperparamter-tuning-deep-learning/](https://www.redmarlin.ai/hyperparamter-tuning-deep-learning/)",1,1
19,2019-4-3,2019,4,3,5,b8ormv,DiffAI v3: provably defending networks 99 layers deep against adversarial attacks.,https://www.reddit.com/r/deeplearning/comments/b8ormv/diffai_v3_provably_defending_networks_99_layers/,mmirman,1554238396,,0,6
20,2019-4-3,2019,4,3,6,b8pc3n,convNets and image resizing,https://www.reddit.com/r/deeplearning/comments/b8pc3n/convnets_and_image_resizing/,shsshs1,1554241175,,0,1
21,2019-4-3,2019,4,3,6,b8pe4t,Best way to deal with class imbalance problem in deep learning?,https://www.reddit.com/r/deeplearning/comments/b8pe4t/best_way_to_deal_with_class_imbalance_problem_in/,MrAaronW,1554241449,I have a dataset which is roughly 1 (pos) : 10 (neg). Is there a recommended way to deal with such kind of dataset besides over/under sampling?,3,2
22,2019-4-3,2019,4,3,9,b8qwnv,"DIY Deep learning workstation, better performance than most of the WS sellers | overheating issue fixed on multiple cards system",https://www.reddit.com/r/deeplearning/comments/b8qwnv/diy_deep_learning_workstation_better_performance/,gimel1213,1554249730,,14,33
23,2019-4-3,2019,4,3,12,b8t7gi,Best way to evaluate segmentation score,https://www.reddit.com/r/deeplearning/comments/b8t7gi/best_way_to_evaluate_segmentation_score/,hpifueshopiuhefp,1554263696,"I am working on an image segmentation and I am wondering what the best way to compute mIOU. For example if my network is trained on images of size 300x300 but the test set has images of arbitrary but strictly smaller size should I resize the images to 300x300 and predict, then resize back to the original resolution or should I pad the images and then crop the real image portion out of the prediction. Or something else?",0,1
24,2019-4-3,2019,4,3,17,b8v6xz,Demand forecasting LSTM model,https://www.reddit.com/r/deeplearning/comments/b8v6xz/demand_forecasting_lstm_model/,naifmeh,1554279121,"Hello,   


Is anyone aware of an available already trained demand forecasting LSTM model ? I would like to fine tune it in order to fit my needs as my dataset is not large enough to give me convincing results by training a raw network from my data :)

&amp;#x200B;

Thanks in advance :)",0,1
25,2019-4-3,2019,4,3,19,b8wa61,Imp Announcement : BTech Engineering Students - Summer Internship with Industrial Training 2019,https://www.reddit.com/r/deeplearning/comments/b8wa61/imp_announcement_btech_engineering_students/,Summerinternship,1554287849,[removed],0,1
26,2019-4-3,2019,4,3,19,b8wfop,"Google open-sources GPipe, a library for efficiently training large deep neural networks",https://www.reddit.com/r/deeplearning/comments/b8wfop/google_opensources_gpipe_a_library_for/,techgig11,1554288911,,1,55
27,2019-4-3,2019,4,3,21,b8xb9y,Deep Learning from Scratch to GPU - 12 - A Simple Neural Network Training API,https://www.reddit.com/r/deeplearning/comments/b8xb9y/deep_learning_from_scratch_to_gpu_12_a_simple/,dragandj,1554294495,,0,2
28,2019-4-3,2019,4,3,22,b8xx8h,"Run:AI takes your AI and runs it, on the super-fast software stack of the future | ZDNet",https://www.reddit.com/r/deeplearning/comments/b8xx8h/runai_takes_your_ai_and_runs_it_on_the_superfast/,ariehkovler,1554297924,,0,1
29,2019-4-4,2019,4,4,1,b90gse,Object detection over monocular single channel images.,https://www.reddit.com/r/deeplearning/comments/b90gse/object_detection_over_monocular_single_channel/,maheshmaceee,1554310279,"Hi folks, I have been working on an interesting project which involves detection of corners of cardboard boxes inside a particular image frame.  I created a train set of 400 images and a test set of 100 images which I manually annotated for the task of object detection. 
I am used yolov3 to break in the idea and try if this is even possible. Yolov3 apparently works great but breaks in particular cases some of which being:
1. Being trained on a small set with not many variation on the box corners, model struggles to detect corners when the boxes have different patterns and shapes. 
2. I tried to change the color space from rgb to grey and did sobel x and y with the same data I have and retrained the model, but not much of a luck with this approach. 

Please feel free to throw in your thoughts and ideas on this and I also have some more related question like:
1. How to come up with an annotation strategy for this particular case as box corners are pretty generic and there isnt a great way to specify boundaries for annotating them.
2. Is there any good approach than object detection which can be leveraged here? 

Peace!",1,1
30,2019-4-4,2019,4,4,2,b90n1c,3D Advanced Neural Network Simulation - Computer vision - Digit Recognit...,https://www.reddit.com/r/deeplearning/comments/b90n1c/3d_advanced_neural_network_simulation_computer/,DevTechRetopall,1554311087,,0,6
31,2019-4-4,2019,4,4,2,b9146e,Appending new classes to recognizer,https://www.reddit.com/r/deeplearning/comments/b9146e/appending_new_classes_to_recognizer/,anilmaddala,1554313328,"I have a pre-trained Image classification model. Is there a way to append a new image classes without loosing the previously trained class recognition?

Which model architectures support this requirement?",1,1
32,2019-4-4,2019,4,4,4,b929xh,Keras Learning Rate Finder: Loss is too sporadic,https://www.reddit.com/r/deeplearning/comments/b929xh/keras_learning_rate_finder_loss_is_too_sporadic/,_sleepyotter,1554318777,"I'm trying to implement the learning rate finder which is what Jeremy Howard uses in [Fast.ai](https://Fast.ai) on a 3D convolutional neural network in Keras. Here are two resources for reference:

* [https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0](https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0)
* [https://www.kaggle.com/paultimothymooney/learning-rate-finder-for-keras](https://www.kaggle.com/paultimothymooney/learning-rate-finder-for-keras)

&amp;#x200B;

In brief, I am trying to predict a 3D bounding box, so this is a regression problem with 6 outputs (x1,y1,z1,x2,y2,z2). The idea is to slowly increment the learning rate until the loss explodes. The inflection point sets the maximum range for the learning rate that you want to use. However, my results don't seem to follow this idea. The loss never seems to dip, unless I make the stopping condition larger.

&amp;#x200B;

The second link is the code that I am trying to use for the LR finder. My network is as follows:

    # Basic Feature Extractor 
    x = Conv3D(filters=32, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv1',kernel_initializer='random_normal')            
          (img_input)
    x = Conv3D(filters=32, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv2',kernel_initializer='random_normal')(x)
    x = Conv3D(filters=64, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv3',kernel_initializer='random_normal')(x)
    x = Conv3D(filters=64, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv4',kernel_initializer='random_normal')(x)
    x = Conv3D(filters=128, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv5',kernel_initializer='random_normal')(x)
    x = BatchNormalization(name='bn_5')(x)
    x = Conv3D(filters=128, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv6',kernel_initializer='random_normal')(x)
    x = Flatten(name='flatten')(x)    
    out = Dense(6, activation='linear', kernel_initializer='random_normal', name='regr_output')(x)

For reference, this model does pretty well on my dataset (aside from the overfitting). Here's a loss vs epoch curve on train and validation :

https://i.redd.it/73ib0m38h3q21.png

&amp;#x200B;

&amp;#x200B;

I'm trying to find a more optimal learning rate. In the results above I used a constant learning rate of 1e-5 which I picked arbitrarily to start off with.

&amp;#x200B;

Starting at a learning rate of 1e-11 and incrementing it over a batch size of 64, 5 epochs, and dataset size of 10,000 images, my loss vs learning rate plot never decreases:

&amp;#x200B;

https://i.redd.it/pssappmul3q21.png

&amp;#x200B;

It isn't until I bump up my stopping condition that the loss goes down, but at this point i'm assuming that my model has already learned enough to decrease the loss.

&amp;#x200B;

https://i.redd.it/qwym1r45m3q21.png

&amp;#x200B;

&amp;#x200B;

**Does this mean that my model is not as sensitive to the learning rate, or is something going wrong here?**

&amp;#x200B;

&amp;#x200B;",0,1
33,2019-4-4,2019,4,4,4,b92fgf,Keras Learning Rate Finder: Loss doesn't decrease,https://www.reddit.com/r/deeplearning/comments/b92fgf/keras_learning_rate_finder_loss_doesnt_decrease/,_sleepyotter,1554319460,"I'm trying to implement the learning rate finder which is what Jeremy Howard uses in [Fast.ai](https://Fast.ai) on a 3D convolutional neural network in Keras. Here are two resources for reference:

* [https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0](https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0)
* [https://www.kaggle.com/paultimothymooney/learning-rate-finder-for-keras](https://www.kaggle.com/paultimothymooney/learning-rate-finder-for-keras)

&amp;#x200B;

In brief, I am trying to predict a 3D bounding box, so this is a regression problem with 6 outputs (x1,y1,z1,x2,y2,z2). The idea is to slowly increment the learning rate until the loss explodes. The inflection point sets the maximum range for the learning rate that you want to use. However, my results don't seem to follow this idea. The loss never seems to dip, unless I make the stopping condition larger.

&amp;#x200B;

The second link is the code that I am trying to use for the LR finder. My network is as follows:

    # Basic Feature Extractor 
    x = Conv3D(filters=32, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv1',kernel_initializer='random_normal')            
          (img_input)
    x = Conv3D(filters=32, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv2',kernel_initializer='random_normal')(x)
    x = Conv3D(filters=64, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv3',kernel_initializer='random_normal')(x)
    x = Conv3D(filters=64, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv4',kernel_initializer='random_normal')(x)
    x = Conv3D(filters=128, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv5',kernel_initializer='random_normal')(x)
    x = BatchNormalization(name='bn_5')(x)
    x = Conv3D(filters=128, kernel_size = (3, 3, 3), strides=(1,1,1), padding='same', \
               activation='relu', name='block1_conv6',kernel_initializer='random_normal')(x)
    x = Flatten(name='flatten')(x)    
    out = Dense(6, activation='linear', kernel_initializer='random_normal', name='regr_output')(x)

For reference, this model does pretty well on my dataset (aside from the overfitting). Here's a loss vs epoch curve on train and validation :

https://i.redd.it/40ptvlqvm3q21.png

I'm trying to find a more optimal learning rate. In the results above I used a constant learning rate of 1e-5 which I picked arbitrarily to start off with.

&amp;#x200B;

Starting at a learning rate of 1e-11 and incrementing it over a batch size of 64, 5 epochs, and dataset size of 10,000 images, my loss vs learning rate plot never decreases:

https://i.redd.it/0x09u6mtm3q21.png

It isn't until I bump up my stopping condition that the loss goes down, but at this point i'm assuming that my model has already learned enough to decrease the loss.

https://i.redd.it/e8koorlum3q21.png

**Does this mean that my model is not as sensitive to the learning rate, or is something going wrong here?**

&amp;#x200B;",2,2
34,2019-4-4,2019,4,4,5,b92z19,How does tf.function work? Weird behaviors and bad performance analysis,https://www.reddit.com/r/deeplearning/comments/b92z19/how_does_tffunction_work_weird_behaviors_and_bad/,pgaleone,1554321984,,0,1
35,2019-4-4,2019,4,4,6,b93xcu,5 AI Companies using Deep Learning in Finance,https://www.reddit.com/r/deeplearning/comments/b93xcu/5_ai_companies_using_deep_learning_in_finance/,jdv9,1554326597,,0,0
36,2019-4-4,2019,4,4,13,b98gg0,"Math question for a non-math person in the topic of ""norms"".",https://www.reddit.com/r/deeplearning/comments/b98gg0/math_question_for_a_nonmath_person_in_the_topic/,eyun89,1554353782,"I am thoroughly reading through [Deep Learning](https://www.deeplearningbook.org/contents/TOC.html) and really want to understand the math. I never had the motivation to understand math until my recent interest in machine learning and deep learning in general. I have this mathematical notations [page](https://en.wikipedia.org/wiki/List_of_mathematical_symbols) from Wikipedia open on the side as I am trying to decode the formulas but am having trouble understanding them as a whole. 

I'm in the section of the book describing [norms](https://en.wikipedia.org/wiki/Norm_(mathematics)) and how a norm is any function that satisfies three listed properties. One of those properties is written as $\forall\alpha\in\mathbb{R},f(\alpha\mathbf{x})=|\alpha|f(\mathbf{x})$  

My current understanding as I look at the formula is that ""For all numbers in alpha(which confuses me from the start, because I found it means proportional to, but it is being used as a variable) is an element of the set of all real numbers and the function of alpha times vector x is equal to the absolute value of alpha times the function of vector x"".

Can anyone help me decode this into regular people words?  ",0,1
37,2019-4-4,2019,4,4,14,b98jvp,"Math question from a non-math person in the topic of ""norms"".",https://www.reddit.com/r/deeplearning/comments/b98jvp/math_question_from_a_nonmath_person_in_the_topic/,eyun89,1554354454,"I am thoroughly reading through \[Deep Learning\]([https://www.deeplearningbook.org/contents/TOC.html](https://www.deeplearningbook.org/contents/TOC.html)) and really want to understand the math. I never had the motivation to understand math until my recent interest in machine learning and deep learning in general. I have this mathematical notations \[page\]([https://en.wikipedia.org/wiki/List\_of\_mathematical\_symbols](https://en.wikipedia.org/wiki/List_of_mathematical_symbols)) from Wikipedia open on the side as I am trying to decode the formulas but am having trouble understanding them as a whole. 

&amp;#x200B;

I'm in the section of the book describing \[norms\]([https://en.wikipedia.org/wiki/Norm\_(mathematics)](https://en.wikipedia.org/wiki/Norm_(mathematics))) and how a norm is any function that satisfies three listed properties. One of those properties is written as \`R,f(x)=f(x)\`.

&amp;#x200B;

My current understanding as I look at the formula is that ""For all numbers in alpha(which confuses me from the start, because I found it means proportional to, but it is being used as a variable) is an element of the set of all real numbers and the function of alpha times vector x is equal to the absolute value of alpha times the function of vector x"".

&amp;#x200B;

Can anyone help me decode this into regular people words?  ",6,8
38,2019-4-4,2019,4,4,21,b9cbe6,[Advice] Best network architecture to use,https://www.reddit.com/r/deeplearning/comments/b9cbe6/advice_best_network_architecture_to_use/,Null_State,1554382286,"I am trying to train a keras network to predict employee performance. I have a large data set that is broken down into discreet time-steps per employee. The issue is the number of time-steps per employee is not fixed.

&amp;#x200B;

What's the best way to handle that? Should I just pad all the sequences to the max length, or should I train the model in batches of matching lengths?

&amp;#x200B;

Also, I was planning on using LSTM layers, does that sound right?

&amp;#x200B;

Sorry if these are basic questions, I'm very new to deep learning.

&amp;#x200B;

Thanks!",0,0
39,2019-4-4,2019,4,4,22,b9csck,Donald Trump AI model tries to sing 'Lose Yourself' by Eminem (1st attempt),https://www.reddit.com/r/deeplearning/comments/b9csck/donald_trump_ai_model_tries_to_sing_lose_yourself/,hanyuqn,1554384953,,20,51
40,2019-4-4,2019,4,4,23,b9dcoy,Classifying logos if one class is a subset of another?,https://www.reddit.com/r/deeplearning/comments/b9dcoy/classifying_logos_if_one_class_is_a_subset_of/,VeniVidiReliqui,1554387811,"\[Advice\] I'm working on making a dataset of logos to train on, but some of the items exist as a part of others. For example, I'm hoping to recognize something like the Windows XP and Windows Vista logos below, but also recognize the Windows logo on its own.

&amp;#x200B;

[Recognize these...](https://i.redd.it/md7d5xzf89q21.jpg)

&amp;#x200B;

[...vs this](https://i.redd.it/bgff0ywg89q21.png)

Am I able to censor subsets of the larger labels with black boxes and learn each piece individually? For example, could I turn the Windows Vista logo above into a ""Windows Vista Text"" class and a ""Windows Icon"" class by covering parts of the image with a black box? Then group both labels together into a ""Windows Vista Icon"" at a different step?",0,1
41,2019-4-5,2019,4,5,0,b9dt24,"GPU Server for ML | GTX 1070Ti $0,12/h",https://www.reddit.com/r/deeplearning/comments/b9dt24/gpu_server_for_ml_gtx_1070ti_012h/,render_rapidly,1554390070,"Hi, I'm offering this very affordable server built for ML:

* 1x GTX 1070Ti, Intel pentium 2 core\*\*, 12 GB RAM, 120 GB SSD
* GPU on motherboard with **PCIe x16** bandwidth
* **Dedicated** server, no VM
* Ubuntu 16.04. Nvidia driver and CUDA  toolkit **pre-installed**
* 100 Mbps download and unlimited bandwidth
*  $25/week, $89/month **($0,12/h)**

*Minimum rental is 1 week. Thanks.*

\*\* [should not be a bottleneck](http://timdettmers.com/2018/12/16/deep-learning-hardware-guide/)

&amp;#x200B;",0,1
42,2019-4-5,2019,4,5,0,b9ef8r,I want to classify multiple numbers in a single image.,https://www.reddit.com/r/deeplearning/comments/b9ef8r/i_want_to_classify_multiple_numbers_in_a_single/,gthm1,1554392970,"Recently, i have trained a ml model on mnist dataset using tensorflow. Now want my model to classify multiple numbers in a  single image (just like yolo or any other object recognizer). How can i do it? ",2,4
43,2019-4-5,2019,4,5,3,b9g72y,New Google Brain Optimizer Reduces BERT Pre-Training Time From Days to Minutes,https://www.reddit.com/r/deeplearning/comments/b9g72y/new_google_brain_optimizer_reduces_bert/,gwen0927,1554401376,,5,16
44,2019-4-5,2019,4,5,3,b9g8ct,Is the Fashion World Ready for AI-Designed Dresses?,https://www.reddit.com/r/deeplearning/comments/b9g8ct/is_the_fashion_world_ready_for_aidesigned_dresses/,gwen0927,1554401544,,1,2
45,2019-4-5,2019,4,5,4,b9guy7,Interesting demos for grade school children,https://www.reddit.com/r/deeplearning/comments/b9guy7/interesting_demos_for_grade_school_children/,justanator101,1554404463,"I am tasked with coming up with a demo of AI and deep learning to make grade school kids interested and aware of what is out there. Our theme is myth busting. One demo we currently have is deep fakes and fake news. 

can anyone propose exciting demos that could be done?",2,1
46,2019-4-5,2019,4,5,5,b9hzdp,LSTM Time Series Prediction,https://www.reddit.com/r/deeplearning/comments/b9hzdp/lstm_time_series_prediction/,AwareDoor,1554409975,"I am trying to understand how time series prediction with LSTM works. For starters, I generated a dataset in which label of each sample is equal to the first feature of the sample three steps before.

i.e

    ```
    1 ,  1  -&gt;  0
    0 ,  0  -&gt;  0
    0 ,  0  -&gt;  0
    1 ,  1  -&gt;  1     
    0 ,  0  -&gt;  0
    0 ,  0  -&gt;  0
    1 ,  1  -&gt;  1
    0 ,  0  -&gt;  0
    1 ,  1  -&gt;  0
    0 ,  0  -&gt;  1
    ``` 

I generated training set and test set with 100000 elements and used the model below.

    ```
    model = Sequential()
    model.add(CuDNNLSTM(20, batch_input_shape=(batch_size, 10, x.shape[2]), return_sequences=True, stateful=True))
    model.add(TimeDistributed(Dense(1, kernel_initializer='normal', activation='sigmoid')))
    # Compile model
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(x,y,validation_data=(xt,yt),verbose=1,epochs=50, batch_size=batch_size, shuffle=False)
    
    predictions = model.predict(xt, batch_size=batch_size)  
    
    ``` 
    
    Results
    
    Epoch 50/50
    10000/10000 [==============================] - 0s 23us/step - loss: 0.4230 - acc: 0.8503 - val_loss: 0.4233 - val_acc: 0.
    
    Confusion Matrix
    array([[42506,  7504],
           [ 7502, 42488]], dtype=int64)

However, the best accuracy I got is  0.8503 and my loss value never changes after 11th epoch.  I tried using different hidden unit values, optimizers and learning rates but could not improve the accuracy.

&amp;#x200B;

Since this is a simple problem I think the accuracy should be better than this. But I cant find what I did wrong.  Any tips would be appreciated. 

&amp;#x200B;",0,1
47,2019-4-5,2019,4,5,8,b9jwyj,Father of GANs Ian GoodFellow Splits Google For Apple,https://www.reddit.com/r/deeplearning/comments/b9jwyj/father_of_gans_ian_goodfellow_splits_google_for/,gwen0927,1554420368,,1,0
48,2019-4-5,2019,4,5,8,b9jxgx,AutoML for deep reinforcement learning?,https://www.reddit.com/r/deeplearning/comments/b9jxgx/automl_for_deep_reinforcement_learning/,ZeroMaxinumXZ,1554420455,I'm trying to think of ways to mix autoML with reinforcement learning. I don't think Network Architecture Search will work as it requires some kind of validation set.  Any papers/suggestions to help me? Thanks.,0,1
49,2019-4-5,2019,4,5,14,b9nh76,AI in healthcare: Google advances in predictive analytics,https://www.reddit.com/r/deeplearning/comments/b9nh76/ai_in_healthcare_google_advances_in_predictive/,patentsandtech,1554443808,,0,10
50,2019-4-5,2019,4,5,16,b9o5lo,"Keras, resize images in np.array with fit.generator?",https://www.reddit.com/r/deeplearning/comments/b9o5lo/keras_resize_images_in_nparray_with_fitgenerator/,granular2,1554449189,"I am using a pretrained model that was trained on images of size 150,150,3. I am experimenting with the fashion MNIST dataset, which has images of the size 28,28,1. So in order to use the pretrained model I should resize the fmnist numpy arrays that contain the images. I would use something like `training_images_resized  = (skimage.transform.resize(image, (150,150,3)) for image in training_images)`  but the resulting array takes up to much memory (13gib limit). So I gather I can use fit.generator and do the resizing there, right? But not sure how to get there, any pointers?

Also I think I have seen something about Keras being able to treat grayscale images as color? maybe not necessary to make three dimensions?

Thanks",5,1
51,2019-4-5,2019,4,5,18,b9ov67,Know any books i could use to write music to oppose the uk government,https://www.reddit.com/r/deeplearning/comments/b9ov67/know_any_books_i_could_use_to_write_music_to/,16yearoldwritingrap,1554455391,Know any books i could use to write music to oppose the uk government masons millionaires billonaires the ones who hide in the shadows i aint afraid anymore ,10,0
52,2019-4-5,2019,4,5,23,b9s581,Do you need a lot of resources to utilize the network you trained?,https://www.reddit.com/r/deeplearning/comments/b9s581/do_you_need_a_lot_of_resources_to_utilize_the/,Seroy,1554475900,"I'm kind of curious about DL, since training it requires a lot of resources.

But what about the part after training it?

Say would be than possible to use the final network on a low powered device (raspberry pi zero, etc ) or do you still need a lot of resources?",6,5
53,2019-4-6,2019,4,6,0,b9svlm,Deep Learning for Overcoming Challenges of Detecting Moving Objects in Video,https://www.reddit.com/r/deeplearning/comments/b9svlm/deep_learning_for_overcoming_challenges_of/,RyanTmthn,1554479536,,0,1
54,2019-4-6,2019,4,6,3,b9uub3,Can this be implemented in any games?,https://www.reddit.com/r/deeplearning/comments/b9uub3/can_this_be_implemented_in_any_games/,GamesRealmTV,1554489095,,1,4
55,2019-4-6,2019,4,6,5,b9w3b5,I am interested in space and deep learning. I have taken deep Learning specialization course on Coursera. Still a month left to complete that specialization. Can anyone help me with the ideas or resources to gather space related datasets and apply some deep learning techniques.,https://www.reddit.com/r/deeplearning/comments/b9w3b5/i_am_interested_in_space_and_deep_learning_i_have/,cherry324,1554495361,,5,2
56,2019-4-6,2019,4,6,7,b9xbi5,How Neural Networks Work- Simply Explained by a Machine Learning Engineer,https://www.reddit.com/r/deeplearning/comments/b9xbi5/how_neural_networks_work_simply_explained_by_a/,DiscoverAI,1554501875,,0,9
57,2019-4-6,2019,4,6,9,b9ylba,Guidance for PhD in Computer Vision and Deep Learning,https://www.reddit.com/r/deeplearning/comments/b9ylba/guidance_for_phd_in_computer_vision_and_deep/,RohitDulam,1554509466,,0,2
58,2019-4-7,2019,4,7,0,ba5db0,Video Dialogue Replacement: World leaders singing 'Imagine',https://www.reddit.com/r/deeplearning/comments/ba5db0/video_dialogue_replacement_world_leaders_singing/,reobb,1554564144,"Hi, I'm from Canny AI, this is a project we did to showcase the potential of the technology:

[https://www.youtube.com/watch?v=R4UxVmYKiGA](https://www.youtube.com/watch?v=R4UxVmYKiGA)",5,20
59,2019-4-7,2019,4,7,4,ba7s2r,"""ICface"", AI that can make an face image lively",https://www.reddit.com/r/deeplearning/comments/ba7s2r/icface_ai_that_can_make_an_face_image_lively/,soumya6097,1554577754,"**Please watch this video to see the ICface in action**: [**https://lnkd.in/gHkmPcS**](https://lnkd.in/gHkmPcS)

Please follow our project page for updates on implementation: [**https://lnkd.in/gusAyjb**](https://lnkd.in/gusAyjb)

Please see our paper for more details: [**https://lnkd.in/gFpGgyS**](https://lnkd.in/gFpGgyS)

![video](chxd86xfzoq21 ""ICface"")",0,1
60,2019-4-7,2019,4,7,4,ba86lp,Anybody have a simple tensorflow 2.0 optimizer example working?,https://www.reddit.com/r/deeplearning/comments/ba86lp/anybody_have_a_simple_tensorflow_20_optimizer/,nobodywillobserve,1554580211,"Should be something like this but I think eager does something or the API has changed?  


    import tensorflow as tf
    import numpy as np
    
    x = tf.Variable(2, name='x', trainable=True, dtype=tf.float32)
    with tf.GradientTape() as t:
        t.watch(x)
        log_x = tf.math.log(x)
        y = tf.math.square(log_x)
    
    opt = tf.optimizers.Adam(0.5)
    # train = opt.minimize(lambda: y, var_list=[x]) # FAILS

&amp;#x200B;",0,5
61,2019-4-7,2019,4,7,6,ba9ej6,Semantic Segmentation on Raspberry Pi Zero,https://www.reddit.com/r/deeplearning/comments/ba9ej6/semantic_segmentation_on_raspberry_pi_zero/,9_ties,1554587554,,0,1
62,2019-4-7,2019,4,7,14,bad9gt,Data Science Deep Learning Training In Bangalore,https://www.reddit.com/r/deeplearning/comments/bad9gt/data_science_deep_learning_training_in_bangalore/,SunilAhujaa,1554615233,If you are looking for data science deep learning institute in Bangalore then Analytixlabs is one of the best options for deep learning training in Bangalore. This is a specialization course which will help you to get a break into AI and Deep Learning domain.,2,0
63,2019-4-7,2019,4,7,18,baep59,Converting y_true and y_pred to numpy arrays in custom loss function in Keras,https://www.reddit.com/r/deeplearning/comments/baep59/converting_y_true_and_y_pred_to_numpy_arrays_in/,Andohuman,1554630279," Hey guys, I was wondering if there was any way to convert my y\_true and y\_pred to numpy arrays as my loss involves a ton of morphological operations depending on y\_true and y\_pred.

In my own testing my loss function works because I supply it with the data for y\_true and y\_pred and convert them to numpy arrays using keras.backend.eval(). However, If i try to compile the model using my loss function in model.compile(loss=my\_loss\_fn()), it gives me errors about feeding values to placeholder, because K.eval can't run during model.compile().

Is there any way to get around this ? I'm kind of on a deadline too and I never expected to encounter such a problem in the first place.

Loss function Code:- [https://pastebin.com/wUJiuNf3](https://pastebin.com/wUJiuNf3)",3,1
64,2019-4-7,2019,4,7,22,bag6lg,Having Trouble with a denoising image with DCGAN .,https://www.reddit.com/r/deeplearning/comments/bag6lg/having_trouble_with_a_denoising_image_with_dcgan/,__sumguy,1554643389," 

I trying to implement a Denoising the image with DCGAN. I am trying to follow this [link](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) .

The implementation in the above link is trying to generate ""Real Looking Fake images"" from the celeb dataset. I have a doubt in how will i implement DCGAN for denoising images.

1. I would take any image data-set and create a noisy images from the original image using opencv (or some other technique)
2. The discriminator will discriminate between noisy and original image.
3. The generator will generate denoised images from the noisy images.

How will i implement this generator part. In the original [link](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) their dataset has only celeb data unlike my data which consists of original and noisy data. How will i modify the generator such that it takes noisy image and generates denoised image . Help me out if i am not understanding things correctly I am relatively new to DL and i want this as my project to be done in the next 7 days . Thanks in Advance",1,6
65,2019-4-7,2019,4,7,23,bagr56,Resources for Anomaly detection of Images?,https://www.reddit.com/r/deeplearning/comments/bagr56/resources_for_anomaly_detection_of_images/,kesaroid,1554647216,"I wanted to build a One class classifier and then detect outliers in my test data. But couldn't find much luck with anomaly detection for images.  Initially I tried extracting the features using Resnet and passing it through One class SVM and even Isolation Tree, but didn't find satisfactory results. Any good resources for the same would be really useful. 
Thanks",1,3
66,2019-4-8,2019,4,8,2,baijre,Final Year Project,https://www.reddit.com/r/deeplearning/comments/baijre/final_year_project/,meishc,1554657308,"Hey guys, Me and my group have some average ML skills. Can anyone recommend some good deep learning project idea for our final year project? or maybe point us in a direction to find an idea?
",2,0
67,2019-4-8,2019,4,8,3,bajn04,Deep Learning With NO Code,https://www.reddit.com/r/deeplearning/comments/bajn04/deep_learning_with_no_code/,lomiag,1554663014,"Hello everyone,

The project is called Deep Learner. This is a project my and my friends worked on during one of the Hackathons I thought it would be appropriate for this sub. The purpose of this project is to allow people prototype Deep Neural networks very very quickly and with writing 0 lines of code. For now you can only build regular dense networks. It also allows for data visualization using Tableau and you can also save models in json format. Please note this is very much work in progress and was made by 4 college students in 24 hours, so there will be bugs. We decided to make this open source, so you are more than welcome to contribute, I have posted a couple issues on github so feel free to contribute.  We are hoping to expand on it in the near future.

[Deep Learner](https://github.com/GioLomia/Deep_Learner)

Let me know if you have any questions &lt;3.",11,36
68,2019-4-8,2019,4,8,6,balhio,Deep Learning and Music - Survey and Discussion,https://www.reddit.com/r/deeplearning/comments/balhio/deep_learning_and_music_survey_and_discussion/,g2ransom,1554673210,"[https://forms.gle/qfkm3HPoj5v2fFfr8](https://forms.gle/qfkm3HPoj5v2fFfr8) \- check out this survey around music and AI

Companies like Google, Facebook, Sony, IBM, and Spotify have spent considerable time and resources towards the intersection of music and artificial intelligence. Think about an AI system that can create music all by itself or a tool that aids a human in the music creation process. Google Magenta has models that generate sequences of music, sounds, and more using different deep learning architectures (GANs, LSTMs, autoencoders).

I've done a good bit of researching projects within the space and want to gather more opinions from folks interested in deep learning. I've attached a 3-5 minute survey and I'd love to get this community's input. It's been the general consensus that AI could not be used for creative tasks, but we see that's not quite the case. Let's start a dialogue!",0,0
69,2019-4-8,2019,4,8,6,balomk,Setup deep learning rig,https://www.reddit.com/r/deeplearning/comments/balomk/setup_deep_learning_rig/,MidnightMiasma,1554674358,"I am a researcher doing work in deep learning, and I just bought a Lambda rig running Ubuntu 18.04 LTS (mandate from my employer to not use cloud services).

Excited to have this machine, but now I have to do system administration for my entire research group and I have relatively little experience with this. I currently have a blank slate and I am hoping that my early decisions will be good ones.

With that in mind:

1) Is there a low footprint system monitoring dashboard I can use to continuously monitor resource utilization and sensors (e.g., GPU temperature)?

2) Is there some way to track (and potentially prioritize) resource use over time by user? (I want to make sure that every one of my students has reasonable access.)

3) I would like a system-wide repository for training data so that each student isn't needlessly replicating data in his/her own directory. I was thinking of a system level folder containing each dataset in a separate folder with appropriate group-level permissions. Is there a smarter way to do this?

4) What would be best practice for working on code across the team? Something like GitLab or Bitbucket? I am a bit ashamed to say that we have mostly just updated our code in the raw as a matter of simplicity, but documentation is a problem especially as students come and go.

&amp;#x200B;

Thanks!",0,4
70,2019-4-8,2019,4,8,13,bapb5h,4x RTX 2080 TI with Quadro Nvlink | Performance Test,https://www.reddit.com/r/deeplearning/comments/bapb5h/4x_rtx_2080_ti_with_quadro_nvlink_performance_test/,gimel1213,1554697294,Check full post here: [https://technopremium.com/blog/4x-rtx-2080-ti-with-quadro-nvlink-performance-test/](https://technopremium.com/blog/4x-rtx-2080-ti-with-quadro-nvlink-performance-test/),0,1
71,2019-4-8,2019,4,8,14,bapx3b,Very small data being predicted as 0,https://www.reddit.com/r/deeplearning/comments/bapx3b/very_small_data_being_predicted_as_0/,Cyclonedx,1554701691,"I have an output that consists of very small values (0.00X) which are being predicted as a 0 by the network.

Do I need to store these values in a particular format before training to prevent this? Also is it a bad idea to normalize impute features which are of a similar size?",0,1
72,2019-4-8,2019,4,8,19,barzd1,Deep Learning Market,https://www.reddit.com/r/deeplearning/comments/barzd1/deep_learning_market/,nareshkumar02,1554718109,[removed],0,1
73,2019-4-9,2019,4,9,0,bauwcp,How can one begin the grad school journey for researching on generative models? What are some good places to start seeking for programs and faculty that supports such uncertain topics?,https://www.reddit.com/r/deeplearning/comments/bauwcp/how_can_one_begin_the_grad_school_journey_for/,alias_is,1554735971,,2,9
74,2019-4-9,2019,4,9,7,bb042v,Automating Visual Inspection using Deep Learning: everything you need to know,https://www.reddit.com/r/deeplearning/comments/bb042v/automating_visual_inspection_using_deep_learning/,manneshiva,1554762661,,0,3
75,2019-4-9,2019,4,9,9,bb1fv6,"[Question] Tensorflow inference run time high on first data point, decreases on subsequent data points. How to reduce?",https://www.reddit.com/r/deeplearning/comments/bb1fv6/question_tensorflow_inference_run_time_high_on/,naboo_random,1554770163,"I am running inference using one of the models from tensorflow's object detection module. I'm looping over my test images in the same session, and doing session.run(). However, on profiling these runs, I realize the first run always has a higher time as compared to the subsequent runs.

I found an answer [here](https://stackoverflow.com/questions/45063489/first-tf-session-run-performs-dramatically-different-from-later-runs-why), as to why that happens, but there was no solution on how to fix.

I'm deploying the object detection inference pipeline on an intel i7 CPU. The time for one session.run(), for 1,2,3, and 4th image looks something like (in seconds):

1. 84.7132628
2. 1.495621681
3. 1.505012751
4. 1.501652718

Just a background on what all I have tried:

* I tried using the TFRecords approach tensorflow gave as a sample [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/oid_inference_and_evaluation.md). I hoped it would work better because it doesn't use a feed\_dict. But since more I/O operations are involved, I'm not sure it'll be ideal. I tried making it work without writing to the disk, but always got some error regarding the encoding of the image.
* I tried using the tensorflow datasets to feed the data, but I wasn't sure how to provide the input, since the during inference I need to provide input for ""image tensor"" key in the graph. Any ideas how to use this to provide input to a frozen graph?

Any help will be greatly appreciated!

TLDR: Looking to reduce the run time of inference for the first image - for deployment purposes.",0,1
76,2019-4-9,2019,4,9,9,bb1knp,"What does it mean ""GANs are notoriously susceptible to mode collapse""?",https://www.reddit.com/r/deeplearning/comments/bb1knp/what_does_it_mean_gans_are_notoriously/,Catherine_Fang,1554770945,"What does it mean ""GANs are notoriously susceptible to mode collapse""?

Can someone explain it in more details?",2,2
77,2019-4-9,2019,4,9,10,bb2870,Free cloud GPU credits for deep learning,https://www.reddit.com/r/deeplearning/comments/bb2870/free_cloud_gpu_credits_for_deep_learning/,whitezl0,1554774926,"Hi, I am offering free credits for you to access 1080Ti GPU instances for deep learning purposes.

I am a co-founder of Tensorpad; where we are creating a service for AI startups to train neural networks. We have paid traffic, but some servers are idle. Hence, we are offering some credits for free, so that students, startups, and others can benefit from ML technologies and help us by using our product and providing honest feedback for us to improve.

You can Sign Up at https://dashboard.tensorpad.com/signup and redeem the code ""REDDIT200"" in the Billing tab. (https://dashboard.tensorpad.com/billing)

Hope this explains our story and motivation for providing free credits.

Here is additional information:
* The instances have 16GB RAM, 4 CPUs cores and one 1080Ti GPU. You can run multiple instances in parallel
* You get access to the JupyterLab environment
* We have pre-installed Tensorflow, Keras, and other ML frameworks
* You can access the terminal through the JupyterLab
* By default, persistent storage is enabled
* TensorBoard comes pre-installed

Here are the available software versions https://docs.tensorpad.com/jobs_env/ For extra free trial hours, use promo code: reddit200

And for questions, please contact me at [ilie@tensorpad.com](mailto:ilie@tensorpad.com). I am looking forward to seeing you on our platform! Sincerely, Ilie Diacov Co-founder and UX researcher at Tensorpad",15,41
78,2019-4-9,2019,4,9,14,bb45xn,Generative Adversarial Networks Projects: Build next-generation generative models using TensorFlow and Keras,https://www.reddit.com/r/deeplearning/comments/bb45xn/generative_adversarial_networks_projects_build/,kailashahirwar12,1554788135,,0,0
79,2019-4-9,2019,4,9,14,bb47m4,MOOC for GANs.,https://www.reddit.com/r/deeplearning/comments/bb47m4/mooc_for_gans/,ragingpot,1554788519,Is there an MOOC which explains GANs in details or a similar resource? Wanna learn about them from scratch. Preferably free resource.,3,5
80,2019-4-9,2019,4,9,16,bb4v6c,Need to Increase Accuracy in SSD-Mobilenet-V1,https://www.reddit.com/r/deeplearning/comments/bb4v6c/need_to_increase_accuracy_in_ssdmobilenetv1/,8222Tamil,1554793767,"I want to deploy tf object detection api in videos.but when using Faster RCNN i get accuracy bt the inference time is too high ,so i changed to mobilenet v1,but has low [accuracy.how](https://accuracy.how) to fine tune SSD-mobilenet-V1 or how to develop the model from scratch?",9,1
81,2019-4-9,2019,4,9,18,bb5odi,How do you prepare your own datasets?,https://www.reddit.com/r/deeplearning/comments/bb5odi/how_do_you_prepare_your_own_datasets/,mehdital,1554800723,"Hi everybody,

I have been facing this problem that most implementations that can be found are made to work directly on some preexisting datasets (Pascal VOC, Coco, Cityscapes etc). I want to create my own dataset (for semantic segmentation purposes) and can't really find any good documentation on how these datasets are formed or how their labels are structured. Until now it has been pure guessing by looking at the data and the xml/json labels. How do you guys do that? Am I missing something somewhere?",0,1
82,2019-4-9,2019,4,9,22,bb7pje,Curated List of 3D Morphable Model Software and Data,https://www.reddit.com/r/deeplearning/comments/bb7pje/curated_list_of_3d_morphable_model_software_and/,sircalvin86,1554815144,[https://github.com/3d-morphable-models/curated-list-of-awesome-3D-Morphable-Model-software-and-data](https://github.com/3d-morphable-models/curated-list-of-awesome-3D-Morphable-Model-software-and-data),0,3
83,2019-4-9,2019,4,9,22,bb876i,Google Colab ram memory overflow,https://www.reddit.com/r/deeplearning/comments/bb876i/google_colab_ram_memory_overflow/,crazy_lazy_life,1554817967,What happens when I am training a model and the ram overflows. Does it allocate new memory while keeping the previous information in a buffer or is it initialised from the beginning.,5,4
84,2019-4-10,2019,4,10,13,bbhqs0,WIFI Dongle that works on Windows 10 and Ubuntu 18.04.2 dual boot?,https://www.reddit.com/r/deeplearning/comments/bbhqs0/wifi_dongle_that_works_on_windows_10_and_ubuntu/,steminist1,1554869904,"Hi! PC building and deep learning noob here.  My apologies in advance if I have left any important information out or if I should have posted this somewhere else. I am about at my wits end with trying to figure this out, so I was hoping some nice people here would have suggestions for me. 

&amp;#x200B;

I recently built a PC (for gaming and to delve into deep learning) running the i7 8700K with a Zotac Amp Extreme 1080TI on the ASUS ROG Strix Z370-F Gaming MOBO. I want to dual boot with Windows 10 (for gaming) and Ubuntu (for GPU accelerated DL). The MOBO does not have Bluetooth or WIFI, which I thought wouldn't be a problem since I can just purchase USB dongles. HA! Bluetooth adapter works great. WIFI..not at all. Joke has been on me for the last week trying to figure this out!

&amp;#x200B;

I wanted a higher-grade WIFI dongle for gaming purposes. The one I have that is working on both Windows 10 and Ubuntu 18.04.2 is only 150 Mbps, so I bought the TP Link 1900AC Archer T4UH adapter that says it has Linux support.  I have tried every driver I could find for the T4UH and worked through countless solutions in forums. One driver that I installed somehow managed to prevent WIFI from even working on the Windows side. Another driver resulted in chaos and I had to completely reinstall Ubuntu. 

&amp;#x200B;

I am at a total loss here. I have searched the internet and cannot find a dongle that people confirm works on both OS's that is above 150 Mbps. Is there anyone out there who is currently running Windows 10 and Ubuntu 18.04.2 dual-boot while using a WIFI adapter for gaming? If so, what adapter are you using? Or maybe I should just get a MOBO that has WIFI and Bluetootht? What about a PCIe WIFI card or will I Just run into the same issues? Does anyone have any other suggestions? I am really excited to start delving into deep learning...kinda sad that I cannot figure this out lol. 

&amp;#x200B;

Thanks all! :)",3,0
85,2019-4-10,2019,4,10,15,bbir18,Multi-server GPU Monitoring Program,https://www.reddit.com/r/deeplearning/comments/bbir18/multiserver_gpu_monitoring_program/,kairos9603,1554877698,"Hi, I'm introducing multi-server gpu monitoring tool.

it it simple to install and setting. Please, use and some comment to github.

Thank you.

Have a nice day!

&amp;#x200B;

pip install ksmi

&amp;#x200B;

[https://github.com/kairos03/kairos-smi](https://github.com/kairos03/kairos-smi)

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/2s4zx496sdr21.png",1,3
86,2019-4-10,2019,4,10,19,bbk9zj,A Quick Easy Guide to Deep Learning with Java  Deeplearaning4j / DL4J - Free sample code to download,https://www.reddit.com/r/deeplearning/comments/bbk9zj/a_quick_easy_guide_to_deep_learning_with_java/,Shilpa_Opencodez,1554891035,,0,1
87,2019-4-10,2019,4,10,20,bbkq39,MRI image pre-processing,https://www.reddit.com/r/deeplearning/comments/bbkq39/mri_image_preprocessing/,GW_KIM,1554894566,"Hi there, i am building a classifier using MRI image(nii data) and i notice that it is important to apply pre-processing on it.

my datum are from ADNI and they are done in some pre-processing( Intensity correction, Scaling)

anyone who recommand  another pre-processing to enhance performance...?",1,1
88,2019-4-10,2019,4,10,21,bblobk,Deep Learning from Scratch to GPU: Initializing Weights,https://www.reddit.com/r/deeplearning/comments/bblobk/deep_learning_from_scratch_to_gpu_initializing/,dragandj,1554900905,,0,23
89,2019-4-10,2019,4,10,23,bbmx1e,Keras: How Should I Approach When a Sample Can Belong To Multiple Categories?,https://www.reddit.com/r/deeplearning/comments/bbmx1e/keras_how_should_i_approach_when_a_sample_can/,jl303,1554907861,"Let's say you're trying to analyze data with images that sometimes have only one object but sometimes have multiple objects on it. For example:

&amp;#x200B;

""person"", ""dog"", ""cat"", ""person,dog"", ""dog,cat""...

&amp;#x200B;

My understanding of multilabels is when you try to predict multiple dimensions: like type and color. ""shirts,red"", ""pants,black""

&amp;#x200B;

Is this still considered multilabels? If not, is there a term for this type of problem?

&amp;#x200B;

As far as preprocessing, should I use sklearn.preprocessing.MultiLabelBinarizer that produces an array for each sample indicating which categories each sample belongs to.

&amp;#x200B;

Could someone could give me some pointers on how I can aproach this?

&amp;#x200B;

Thanks!",4,2
90,2019-4-10,2019,4,10,23,bbmyzn,Beginner Deep Learning Project for Embedded Applications,https://www.reddit.com/r/deeplearning/comments/bbmyzn/beginner_deep_learning_project_for_embedded/,BalajiKulkarni,1554908151,"Hi All, 

I am an Embedded Software developer ,who have developed interest towards to deep learning in recent past. I have gained some good amount of fundamentals in CNN via Coursera and external meet up groups, with hands on experience at beginner level (implemented NN for MNIST dataset, ResNet and DenseNet in progress)

I want to develop an application (preferably vision related) on low foot print devices using pre trained models offline ,which will perform inference on embedded devices.

Please suggest or share any pointers ,if anyone here has some really interesting and useful things which could be done at beginner level for embedded systems.",0,1
91,2019-4-11,2019,4,11,0,bbn2sm,"Bach to the Future (or, Humanising Music With Neural Nets)",https://www.reddit.com/r/deeplearning/comments/bbn2sm/bach_to_the_future_or_humanising_music_with/,point_against_point,1554908736,,0,2
92,2019-4-11,2019,4,11,0,bbn7ku,Resources for GANs?,https://www.reddit.com/r/deeplearning/comments/bbn7ku/resources_for_gans/,kesaroid,1554909439,"I needed a simple approach to learn GAN's. 
Any help would be appreciated.",1,7
93,2019-4-11,2019,4,11,0,bbnf2j,Generative models' likelihood estimation,https://www.reddit.com/r/deeplearning/comments/bbnf2j/generative_models_likelihood_estimation/,lil_uzi_kek,1554910501,"Hi everyone, I'm interested in generative models (e.g. GAN / VAE), but i never thought of ""how can we measure the likelihood of generated samples"". When I asked this question to myself and studied it a little, i've found a lot of approaches for VAE, but almost nothing (except [this](https://arxiv.org/pdf/1611.04273.pdf) paper) for GANs or other decoder-based models.

Can you give me any links to papers which focus on this question or any possible approaches? Thanks a lot!",0,1
94,2019-4-11,2019,4,11,3,bbpikl,Small budget system for data scientists | I will be posting the building guide soon,https://www.reddit.com/r/deeplearning/comments/bbpikl/small_budget_system_for_data_scientists_i_will_be/,gimel1213,1554920935,,25,49
95,2019-4-11,2019,4,11,3,bbpn75,Does anyone remember colour gradient generating GANs?,https://www.reddit.com/r/deeplearning/comments/bbpn75/does_anyone_remember_colour_gradient_generating/,nivm321,1554921572,"Hi,

I had some time ago seen a GAN which produced colour gradients. I don't remember whose work it was. Do you happen to know of any? 

Thanks!",0,2
96,2019-4-11,2019,4,11,4,bbq5mi,Creating a Custom OpenAI Gym Environment for Stock Trading,https://www.reddit.com/r/deeplearning/comments/bbq5mi/creating_a_custom_openai_gym_environment_for/,notadamking,1554924112,,0,8
97,2019-4-11,2019,4,11,4,bbqajc,DataScience Digest (Telegram channel),https://www.reddit.com/r/deeplearning/comments/bbqajc/datascience_digest_telegram_channel/,flyelephant,1554924804,,0,1
98,2019-4-11,2019,4,11,10,bbu4d2,i was wondering if is there any solution has both KNM(Intel Kights Mill) and NVIDIA GPUs in one workstation.,https://www.reddit.com/r/deeplearning/comments/bbu4d2/i_was_wondering_if_is_there_any_solution_has_both/,hawking90a,1554945503,I just want use these solutions (KNL/KNM and GPU) in one workstation.,0,1
99,2019-4-11,2019,4,11,13,bbw2g5,DLBT | User-friendly deep learning benchmark app | Anyone can test and benchmark their hardware GPU-CPU,https://www.reddit.com/r/deeplearning/comments/bbw2g5/dlbt_userfriendly_deep_learning_benchmark_app/,gimel1213,1554958429,"Hi Guys, we have developed a user-friendly app, easy to install for everyone to download and run the benchmark to know how their hardware perform for deep learning applications, you can also upload the results to our wall of fame and be on the Top 10. [\---- DOWNLOAD ----](https://www.technopremium.com)

[DLBT \(User-friendly deep learning app \) ](https://i.redd.it/ag436l5gekr21.png)

&amp;#x200B;

The app helps IT departments to identify a system of multiple GPU's, which one is damage in case of failure and help to purchase department to know what GPU workstation to buy depend on the GPU score in our web. 

&amp;#x200B;

We are updating more features every day and our goal is to make DLBT stand Benchmarking app for ML/DL datacenters and consumer use. 

&amp;#x200B;

We are happy to receive any feedback about, you can download ITS FREE !!!! [\---- DOWNLOAD ----](https://www.technopremium.com)

&amp;#x200B;

If need assistance installing our app after following the steps on the web, please contact our team, and we will be more than happy to help - [support@technopremium.com](mailto:support@technopremium.com)",1,2
100,2019-4-11,2019,4,11,17,bbxi8x,What is the meaning of optimizing input to the model?,https://www.reddit.com/r/deeplearning/comments/bbxi8x/what_is_the_meaning_of_optimizing_input_to_the/,sriharsha_0806,1554972289,"&amp;#x200B;

In the following video,  Ian good fellow explains at 16:00 ""The mapping from parameters of the network to the output of the network is non-Linear because of the weight matrices at each layer of network are multiplied together. So we get extremely nonlinear interactions between parameters and the output. That's what makes the training of Neural Network difficult. But the mapping from input to output is much more linear and predictable, and it means that optimization problems that aim to optimize the input to the model are much easier than optimization problems that aim to optimize the parameters .""  
What did he mean when saying optimizing the input to the model?  
[https://www.youtube.com/watch?v=CIfsB\_EYsVI&amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&amp;index=16](https://www.youtube.com/watch?v=CIfsB_EYsVI&amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&amp;index=16)",1,1
101,2019-4-11,2019,4,11,22,bbzqsi,Looking for datasets of Python code.,https://www.reddit.com/r/deeplearning/comments/bbzqsi/looking_for_datasets_of_python_code/,ZeroMaxinumXZ,1554988528,"Hi, don't know where to post this but...

&amp;#x200B;

I'm looking for a dataset of Python code (or any language) along with brief descriptions of the code to basically try and train a model to generate code.",4,1
102,2019-4-11,2019,4,11,22,bbzsa0,First Time PC Build for Deeplearning,https://www.reddit.com/r/deeplearning/comments/bbzsa0/first_time_pc_build_for_deeplearning/,HUSKODILE,1554988775,"Just put up a new build list for Deeplearning, first time build, any pointers?

I choose a 1600 watts PSU because ultimately i want to expand to 4 graphics card.

Not really sure if the case has heat issues with 4 GPUs running.

With the help of a warmhearted redditor @Really\_popular\_lobster, this is the new list, how do you guys like it?? Thanks in advance.

&amp;#x200B;

\[PCPartPicker part list\]([https://pcpartpicker.com/list/GtP7xG](https://pcpartpicker.com/list/GtP7xG)) / \[Price breakdown by merchant\]([https://pcpartpicker.com/list/GtP7xG/by\_merchant/](https://pcpartpicker.com/list/GtP7xG/by_merchant/))

&amp;#x200B;

&amp;#x200B;

\*\*CPU\*\* | \[AMD - Threadripper 1950X 3.4 GHz 16-Core Processor\]([https://pcpartpicker.com/product/CF7CmG/amd-threadripper-1950x-34ghz-16-core-processor-yd195xa8aewof](https://pcpartpicker.com/product/CF7CmG/amd-threadripper-1950x-34ghz-16-core-processor-yd195xa8aewof)) | $587.90 @ OutletPC

\*\*CPU Cooler\*\* | \[Noctua - NH-U14S TR4-SP3 82.52 CFM CPU Cooler\]([https://pcpartpicker.com/product/nCNypg/noctua-nh-u14s-tr4-sp3-1402-cfm-cpu-cooler-nh-u14s-tr4-sp3](https://pcpartpicker.com/product/nCNypg/noctua-nh-u14s-tr4-sp3-1402-cfm-cpu-cooler-nh-u14s-tr4-sp3)) | $79.90 @ Amazon

\*\*Motherboard\*\* | \[ASRock - X399 Taichi ATX TR4 Motherboard\]([https://pcpartpicker.com/product/kjmxFT/asrock-x399-taichi-atx-tr4-motherboard-x399-taichi](https://pcpartpicker.com/product/kjmxFT/asrock-x399-taichi-atx-tr4-motherboard-x399-taichi)) | $259.99 @ Newegg

\*\*Memory\*\* | \[G.Skill - Ripjaws V Series 64 GB (4 x 16 GB) DDR4-3200 Memory\]([https://pcpartpicker.com/product/7Xbkcf/gskill-memory-f43200c16q64gvk](https://pcpartpicker.com/product/7Xbkcf/gskill-memory-f43200c16q64gvk)) | $400.98 @ Newegg

\*\*Storage\*\* | \[Western Digital - Black NVMe 1 TB M.2-2280 Solid State Drive\]([https://pcpartpicker.com/product/2K22FT/western-digital-black-nvme-1tb-m2-2280-solid-state-drive-wds100t2x0c](https://pcpartpicker.com/product/2K22FT/western-digital-black-nvme-1tb-m2-2280-solid-state-drive-wds100t2x0c)) | $244.90 @ OutletPC

\*\*Video Card\*\* | \[Asus - GeForce RTX 2080 Ti 11 GB Turbo Video Card\]([https://pcpartpicker.com/product/vtqhP6/asus-geforce-rtx-2080-ti-11gb-turbo-video-card-turbo-rtx2080ti-11g](https://pcpartpicker.com/product/vtqhP6/asus-geforce-rtx-2080-ti-11gb-turbo-video-card-turbo-rtx2080ti-11g)) (2-Way SLI) | $1300.00

\*\*Video Card\*\* | \[Asus - GeForce RTX 2080 Ti 11 GB Turbo Video Card\]([https://pcpartpicker.com/product/vtqhP6/asus-geforce-rtx-2080-ti-11gb-turbo-video-card-turbo-rtx2080ti-11g](https://pcpartpicker.com/product/vtqhP6/asus-geforce-rtx-2080-ti-11gb-turbo-video-card-turbo-rtx2080ti-11g)) (2-Way SLI) | $1300.00

\*\*Case\*\* | \[Corsair - 750D Airflow Edition ATX Full Tower Case\]([https://pcpartpicker.com/product/Rwhj4D/corsair-case-cc9011078ww](https://pcpartpicker.com/product/Rwhj4D/corsair-case-cc9011078ww)) | $119.99 @ Newegg

\*\*Power Supply\*\* | \[Corsair - 1600 W 80+ Titanium Certified Fully-Modular ATX Power Supply\]([https://pcpartpicker.com/product/cJbwrH/corsair-1600w-80-titanium-certified-fully-modular-atx-power-supply-cp-9020087-na](https://pcpartpicker.com/product/cJbwrH/corsair-1600w-80-titanium-certified-fully-modular-atx-power-supply-cp-9020087-na)) | $339.99 @ Amazon

| \*Prices include shipping, taxes, rebates, and discounts\* |

| Total (before mail-in rebates) | $4673.65

| Mail-in rebates | -$40.00

| \*\*Total\*\* | \*\*$4633.65\*\*",6,4
103,2019-4-11,2019,4,11,23,bc0qwo,A Google Brain Program Is Learning How to Program,https://www.reddit.com/r/deeplearning/comments/bc0qwo/a_google_brain_program_is_learning_how_to_program/,gwen0927,1554994082,,10,40
104,2019-4-12,2019,4,12,0,bc11jc,Deep Learning for Business: 5 Use Cases,https://www.reddit.com/r/deeplearning/comments/bc11jc/deep_learning_for_business_5_use_cases/,OpenDataSciCon,1554995609,,0,1
105,2019-4-12,2019,4,12,0,bc13dj,A glitch in the LSTM?,https://www.reddit.com/r/deeplearning/comments/bc13dj/a_glitch_in_the_lstm/,polyglotdev,1554995878,,0,1
106,2019-4-12,2019,4,12,2,bc2lo4,TableBank: Benchmark for Image-based Table Detection and Recognition,https://www.reddit.com/r/deeplearning/comments/bc2lo4/tablebank_benchmark_for_imagebased_table/,gwen0927,1555003524,,0,1
107,2019-4-12,2019,4,12,5,bc53a8,NAACL 2019 List of Best Papers,https://www.reddit.com/r/deeplearning/comments/bc53a8/naacl_2019_list_of_best_papers/,gwen0927,1555016338,,0,2
108,2019-4-12,2019,4,12,7,bc5vv4,Neural ODE applications.,https://www.reddit.com/r/deeplearning/comments/bc5vv4/neural_ode_applications/,ragingpot,1555020551,"Has anyone here applied the Neural ODE concept to their own dataset? If so, can you share the results. The dataset must not be a standard one like MNIST, CIFAR etc.",0,3
109,2019-4-12,2019,4,12,7,bc6b7l,Fusing Data Transformations with Neural Network for Fast Inference with MXNet,https://www.reddit.com/r/deeplearning/comments/bc6b7l/fusing_data_transformations_with_neural_network/,gigasquid,1555022927,,0,1
110,2019-4-12,2019,4,12,8,bc6z9t,"[Question] Tensorflow object detection retraining, confidence score really low",https://www.reddit.com/r/deeplearning/comments/bc6z9t/question_tensorflow_object_detection_retraining/,naboo_random,1555026985,"Hi,

I am trying to retrain the tensorflow object detection model - faster r cnn ( pretrained on iNaturalist) data. However, after training for around 60k steps ( where the total loss stabilizes), if I run an evaluation the confidence scores of my detections are too low, of the order of e-5.

The original model has around 2k classes. I'm training on 4 classes - almost equal distribution, with around 900 samples. The data augmentation option is ""random\_horizontal\_flip"".

Should I be increasing the number of samples I have? Maybe have more augmentation options?

Any help will be appreciated! Thanks!",0,0
111,2019-4-12,2019,4,12,14,bc9skp,Does PyTorch or TensorFlow actually use tensors?,https://www.reddit.com/r/deeplearning/comments/bc9skp/does_pytorch_or_tensorflow_actually_use_tensors/,justinecarolin,1555045666,"I don't have a degree in physics nor one in mathematics, 
so I don't know much about tensors.

And I have just started with deep learning.

But as far as I can tell, after reading through the docs, my impression is that PyTorch actually implements good-and-old matrix-and-vector linear algebra, and in addition,

1 names n-d arrays as tensors, which is correct mathematically

2 has some elementary operations on n-d arrays, which demand no knowledge of (mathematical) tensors and may not necessarily be a part of tensor algebra , such as torch.cat(), torch.chunk(), etc.

It occurs to me that tensor algebra is not actually implemented. The closest thing I have found is torch.tensordot() which I am not sure what tensor algebra operation(s) it corresponds to.

Am I missing something? Or is it just PyTorch, while TensorFlow implements proper tensor algebra? Or are deep learning frameworks all like that?
Do I really need to understand tensors other than that they are n-d arrays to do research in deep learning?",19,15
112,2019-4-12,2019,4,12,14,bca3d7,Diagnosis of Celiac Disease and Environmental Enteropathy on Biopsy Images Using Color Balancing on Convolutional Neural Networks,https://www.reddit.com/r/deeplearning/comments/bca3d7/diagnosis_of_celiac_disease_and_environmental/,kk7nc,1555048106,,0,2
113,2019-4-12,2019,4,12,19,bcc68f,"Deeplearning in OpenCV, retraining network",https://www.reddit.com/r/deeplearning/comments/bcc68f/deeplearning_in_opencv_retraining_network/,tobix10,1555066609,"I am making a video surveillance app and I need to detect people. I don't need to detect other stuff that is available in yolov3 (80 classes on COCO dataset). So I think about retraining it, but I am new to the field and really confused about a few things.

First of all, I have quick questions:
1. What is the difference between yolov3 and yolov3-tiny? Accuracy for sure. Smaller training set? Smaller network?
2. Is it reasonable to assume that single class network will have much greater accuracy, will be smaller and faster?
3. Is yolo the fastest out there? Should I use other network for my use case? Remark: my target device has ARM CPU and yolov3 is too slow. yolov3-tiny inference time is acceptable.

Questions related to training:
1. Which dataset should I use: Pascal, COCO, OpenImages?
2. Should I use original dataset or a smaler subset, but with augmented images?
3. OpenImages has 220k real person images. That is a lot. How long may it take to train network?
4. Can I train a network in reasonable time on quad-core CPU or older card GTX770 (2GB only)?

I've also found a repository https://github.com/thatbrguy/Pedestrian-Detection/blob/master/object_detection/g3doc/detection_model_zoo.md, but I can't make models run in OpenCV and from the description those networks don't output confidence values.",0,1
114,2019-4-12,2019,4,12,20,bcc7az,2080ti slower than 2080,https://www.reddit.com/r/deeplearning/comments/bcc7az/2080ti_slower_than_2080/,Den3b_poe,1555066815,"Hello, I'm training an LSTM (2 LSTM layers + 1 fully-connected layer) with Keras (with Tensorflow backend) on two different machines using a single GPU per machine. Surprisingly I obtain slower training on the GPU that in principle should perform better.

There are a lot of discussions about training speed for GPU vs. CPU, or for single vs multi-GPU. However, I wasn't able to find a discussion comparing single GPU vs. single GPU.

The data, the code, the libraries (including versions and releases), the random seed, and the Nvidia driver are exactly the same on the two machines.

First machine: laptop with GeForce RTX 2080 mobile version  
Second machine: workstation with GeForce RTX 2080 Ti

Given these two configurations, I'm expecting a faster training on the second machine: not only the GeForce RTX 2080 Ti is better than GeForce RTX 2080, but also the latter is the laptop version.

Using a batch size of 32 I get the following performances:

* first machine: 27 s per epoch - 38 ms per batch - 1st epoch train loss: 0.8772 - 1st epoch val\_loss: 0.1873
* second machine: 52 s per epoch - 72 ms per batch - 1st epoch train loss: 0.8772 - 1st epoch val\_loss: 0.1873

As you can see the losses are identical, however the RTX 2080 Ti is almost two times slower. I can't understand why this is happening, since in my opinion the RTX 2080 Ti should be faster than the RTX 2080 mobile.  


Any suggestion?",3,1
115,2019-4-12,2019,4,12,21,bccypm,Image augmentation reduced my model's accuracy,https://www.reddit.com/r/deeplearning/comments/bccypm/image_augmentation_reduced_my_models_accuracy/,huzaifakhan771,1555072019,"I trained a model for classifying male and female gender based on their faces. I used 250 images (face only) for each class (male and female) and got an accuracy of about 60 percent (it was incorrect in 8 of the test images). I then augmentee my dataset by apply geometric (rotation, flip) and got a dataset 5 times as big and used it to train the model with it, including the original images. The model then gave me a reduced accuracy if 50 percent. Why did that happen? I though image augmentation can increase accuracy by expanding the dataset. Thank you.",3,1
116,2019-4-12,2019,4,12,22,bcdb8x,Donald Trump AI Demonstrates New Facial Manipulation Project ICface,https://www.reddit.com/r/deeplearning/comments/bcdb8x/donald_trump_ai_demonstrates_new_facial/,hanyuqn,1555074195,,0,2
117,2019-4-12,2019,4,12,22,bcde9h,Udacity Deep Learning Course,https://www.reddit.com/r/deeplearning/comments/bcde9h/udacity_deep_learning_course/,clintdk,1555074683,"Hi everyone! I have currently finished my deep learning course in my data science master but I still feel like quite some knowledge is missing. I have heard good things about the Udacity deep learning course, but I would like to hear you guys opinion! Do you think it has some added value for me? 

&amp;#x200B;

Here is my course description from the university so you get an insight about my foreknowledge: [https://catalogus.tilburguniversity.edu/osiris\_student\_tiuprd/OnderwijsCatalogusSelect.do?selectie=cursus&amp;taal=en&amp;collegejaar=2018&amp;cursus=880008-M-6](https://catalogus.tilburguniversity.edu/osiris_student_tiuprd/OnderwijsCatalogusSelect.do?selectie=cursus&amp;taal=en&amp;collegejaar=2018&amp;cursus=880008-M-6)   


This is what I learned in machine learning: [https://catalogus.tilburguniversity.edu/osiris\_student\_tiuprd/OnderwijsCatalogusSelect.do?selectie=cursus&amp;taal=en&amp;collegejaar=2018&amp;cursus=880083-M-6](https://catalogus.tilburguniversity.edu/osiris_student_tiuprd/OnderwijsCatalogusSelect.do?selectie=cursus&amp;taal=en&amp;collegejaar=2018&amp;cursus=880083-M-6)

&amp;#x200B;

Thanks in advance you guys!",7,22
118,2019-4-12,2019,4,12,22,bcdegs,GanSeg for medical images,https://www.reddit.com/r/deeplearning/comments/bcdegs/ganseg_for_medical_images/,DifficultDifficulty,1555074720,"Hi all,

At my university, I am taking a grad course in which we're select a deep learning project and work on it by the end of the course.  
I had previously developed a set of tools for my [M.Sc](https://M.Sc) project where I need to manipulate sets of medical images in different formats (DICOM, Niftii, Nrrd), pre-process them using SimpleITK and feed them into a deep learning pipeline.  
I figured I could execute that course project using those tools and put it up on github for everyone to use and for me to showcase my skills, as I will finish school very soon and that will give me some visibility for my upcoming job search.

The platform relies on visdom for visualization capabilities, I had implemented functions that allow you to visualize your network's computation graph, the experiment options and hyperparameters, your loss and accuracy curves, the gradient flow graphs through your networks as well as histograms for weight distribution in your layers. The python classes offer different functions to easily extend functionality where you can sample images during training if you're working with images and display them on the browser.

The repository comes with implementations of UNets and ResNets as well as many GAN loss functions such as Wasserstein GAN with gradient penalty. The same class can also be set in non-GAN mode so that it uses a simple cross-entropy loss function.

I had used this code to segment vertebrae from MRIs, reaching a 0.87 dice coefficient.

The code is generic enough to be used for tasks other than image segmentation if you wish to play around with it.

I hope this will be helpful to you.

Please find it in the link down below:

[https://github.com/Roulbac/GanSeg](https://github.com/Roulbac/GanSeg)",0,1
119,2019-4-13,2019,4,13,0,bcexek,Questions About 3D Model Deep Learning Project,https://www.reddit.com/r/deeplearning/comments/bcexek/questions_about_3d_model_deep_learning_project/,_AICurious_,1555083198,"# Background:

I have recently undertaken a project attempting to localize the position of a computer-aided design (CAD) object in 3D space by manipulating the projection of the 3D CAD object onto two orthogonal plane projections of the 3D. Please see image below.

https://i.redd.it/xe38gklwgur21.png

As you can see, the location of the 3D object in the global coordinate system can be determined by shifting the projections of the 3D object on the 2D images to have the silhouette match the previously determined outline.

Previously, this problem has been handled manually by shifting the the 3D object around until its silhouette overlaps with the images. This is a time-consuming process, and with thousands of images, it can quickly become overwhelming.

I proposed that we could utilize deep learning to automate this process, as we have many instances with corresponding solutions, and additionally, it's a repetitive process.

For clarity, the input data contains two 1024x1024 gray-scale images and a variable size .stl file, describing the 3D object. The output data contains a 3x3 rotational matrix (see [here](https://en.wikipedia.org/wiki/Rotation_formalisms_in_three_dimensions) for more details), describing the rotation of the object's unit vectors in the global coordinate system and a 1x3 translation matrix describing the movement of the coordinate system's origin.

The .stl file will typically include two matrices. One matrix describes the vertices of the model, and the other matrix describes indexes of three vertices to connect to form a surface (see [here](https://s3-eu-west-1.amazonaws.com/3dhubs-knowledgebase/how-export-and-3d-print-your-stl-file-right-resolution/visual4.png) for an example).

# Proposed Solution:

In terms of the actual deep learning network, I propose using convolutional and pooling layers to analyze the two images. This will help scale down the data and will hopefully identify features that are relevant to the silhouette of the 3D model. For the 3D model, I was considering using `tensorflow.layers.conv3d()` to create a convolution layer for the 3D inputs, but I am unsure of how to incorporate the matrix with information about what vertices to connect, which is responsible for creating the surfaces. The plan currently is to create a few fully connected layers at the top of the neural network where the information from the 2 images, the 3D model points, and the 3D model connection surfaces is incorporated to produce the desired output. The desired output will most likely be a 1x12 vector (1x9 for rotation matrix concatenated with 1x3 for translation matrix). 

# Concerns:

1) How would you handle the variable input length sequences? I understand that recurrent neural networks (RNNs) can handle variable length input sequences, but my understanding is that this is primarily used in natural language processing and time series data. Is it appropriate to use RNNs in this setting? I could also zero-pad my data to create uniform data lengths, but the problem is that the .stl files have between \~50,000 and 75,000 vertices and between \~110,000-130,000 connections.

2) How would I analyze the 3D model? Is there a way to incorporate the surfaces early on in the 3D convolutional layer? Although unorthodox, do you think that the surface matrix (containing connections between the vertices) could also be analyzed by a 3D convolutional layer, as it has 3 columns of data?

3) Do you think it's practical to have the fully connected layer as described above to combine the outputs from the various convolutional layers (including CNN output for two separate images, one 3D point cloud, and the surface matrix)? Are there other practical ways to combine the data to optimize training?

&amp;#x200B;

Any help, guidance, or advice would be greatly appreciated. Thanks for reading this far!

&amp;#x200B;

Language: Python3.6 

DL Package: Keras on top of TensorFlow",0,0
120,2019-4-13,2019,4,13,3,bcgo47,Thanks to everyone who attended the @missinglinkai #Meetup last night. We had a great turnout! Thanks to our guest speaker @drsrinathsridha &amp; Stanford. Big thanks to @WeWork for hosting us! Watch the recording here: youtu.be/hxGNAREbXmY #DeepLearning,https://www.reddit.com/r/deeplearning/comments/bcgo47/thanks_to_everyone_who_attended_the_missinglinkai/,treguess,1555092041,,0,1
121,2019-4-13,2019,4,13,3,bcgtnt,Stanford presents: Deep Learning for Digitizing Human Physical Skills,https://www.reddit.com/r/deeplearning/comments/bcgtnt/stanford_presents_deep_learning_for_digitizing/,treguess,1555092793,https://www.youtube.com/watch?v=hxGNAREbXmY&amp;feature=share[Deep Learning for Digitizing Human Physical Skils](https://www.youtube.com/watch?v=hxGNAREbXmY&amp;feature=share),1,1
122,2019-4-13,2019,4,13,6,bcj2ca,State-of-the-art multilabel classification algorithm?,https://www.reddit.com/r/deeplearning/comments/bcj2ca/stateoftheart_multilabel_classification_algorithm/,peroquepas923,1555104421,"Hi redditors, I have a database composed of 1000 training samples that have 800 features each in a vectorized form. Each of these samples can belong to 14 different classes at the same; for instance, the label of some sample vector x can be expressed in the following one-hot-coding way:

label\_x = \[1,0,0,0,1,1,0,0,1,0,0,0,0,0\]

Could you recommend me a good state-of-the-art algorithm capable of resolving this kind of problem? I am thinking in using neural networks but since I don't have a lot of training samples it may be hard to obtain a good generalizing model. Another option I've thought of is random forests. However, since I have never worked in multilabel-classification I am a bit lost.

Regards!",3,1
123,2019-4-13,2019,4,13,7,bcjjzf,Deep Learning PhD,https://www.reddit.com/r/deeplearning/comments/bcjjzf/deep_learning_phd/,NikolasTs,1555107151,"Does anybody know any interesting PhD positions in Europe for deep learning? Any recommendation on possible professors as supervisors? 

Thanks in advance!",4,16
124,2019-4-13,2019,4,13,8,bckdwg,Detecting and Localizing Pneumonia from Chest X-Ray Scans with PyTorch,https://www.reddit.com/r/deeplearning/comments/bckdwg/detecting_and_localizing_pneumonia_from_chest/,dkobran,1555112037,,0,3
125,2019-4-13,2019,4,13,18,bcosxe,Usage of fast.ai library in Google Colab,https://www.reddit.com/r/deeplearning/comments/bcosxe/usage_of_fastai_library_in_google_colab/,visvats,1555147531,How to install fast.ai library in Google Colab?,2,1
126,2019-4-13,2019,4,13,20,bcpegq,Looking for a Good Seq2Seq Chatbot Library,https://www.reddit.com/r/deeplearning/comments/bcpegq/looking_for_a_good_seq2seq_chatbot_library/,ZeroMaxinumXZ,1555153374,Is there any good seq2seq chatbot libraries for Python (any ML backend) that allow for plain-text preprocessing? Don't really want to have to build my own seq2seq chatbot from complete scratch... Thanks...,2,7
127,2019-4-14,2019,4,14,4,bctx11,Katie Bauman shows how the black hole imaging reduces to a computer vision problem,https://www.reddit.com/r/deeplearning/comments/bctx11/katie_bauman_shows_how_the_black_hole_imaging/,treguess,1555182129,,0,56
128,2019-4-14,2019,4,14,5,bcuvl5,Which feature detection is used here?,https://www.reddit.com/r/deeplearning/comments/bcuvl5/which_feature_detection_is_used_here/,treguess,1555187382,,0,69
129,2019-4-14,2019,4,14,13,bcz7s6,How could this happen?,https://www.reddit.com/r/deeplearning/comments/bcz7s6/how_could_this_happen/,hungrybear2005,1555216113,"I'm developing some cuda algorithm. For fun, i tested my laptop cpus performance just now. 16384*16384 matrix addition, 3840qm takes 8 seconds while 7700hq takes 38.5seconds. Former one compile&amp;link on vs2013+win7 while later vs2017+win10. Can't believe that 7700hq was so slow. My 3840qm is six years old!",3,1
130,2019-4-14,2019,4,14,13,bczea7,"Can I do Machine learning, Deep learning research if I dont have GPU?",https://www.reddit.com/r/deeplearning/comments/bczea7/can_i_do_machine_learning_deep_learning_research/,manishghimire,1555217620,,3,0
131,2019-4-14,2019,4,14,14,bczk3e,Humans Call GG! OpenAI Five Bots Beat Top Pros OG in Dota 2,https://www.reddit.com/r/deeplearning/comments/bczk3e/humans_call_gg_openai_five_bots_beat_top_pros_og/,gwen0927,1555219017,,0,7
132,2019-4-14,2019,4,14,16,bd0hb7,How to view a HDFS file,https://www.reddit.com/r/deeplearning/comments/bd0hb7/how_to_view_a_hdfs_file/,Pik000,1555227523,"Hi Guys,

&amp;#x200B;

I want to use the fashion-gen dataset for a project I'm working on, the dataset is in the HDFS file format, there are pictures and text etc inside the file but I can't workout how to access anything. Can someone point me in the correct direction to use the file? Sorry if this is a basic question but I seem to have spent alot of the time day googling and still can figure it out. Would like to get the text into pandas if possible.",1,1
133,2019-4-14,2019,4,14,16,bd0ifu,What the SPP block does in yolov3-spp?,https://www.reddit.com/r/deeplearning/comments/bd0ifu/what_the_spp_block_does_in_yolov3spp/,drr21,1555227841,"Hi, I'm currently working with yolo with a dataset with small objects. It seems that yolov3-spp ([https://github.com/AlexeyAB/darknet/blob/master/cfg/yolov3-spp.cfg](https://github.com/AlexeyAB/darknet/blob/master/cfg/yolov3-spp.cfg)) works better than normal yolo when small objects are present. However, I don't understand why? How the spp block makes yolov3 more suitable for small objects? Any idea?

&amp;#x200B;

Thanks!",0,3
134,2019-4-14,2019,4,14,16,bd0j5m,Convolutional Neural Networks: An Intuitive Approach,https://www.reddit.com/r/deeplearning/comments/bd0j5m/convolutional_neural_networks_an_intuitive/,DiscoverAI,1555228042,,0,2
135,2019-4-14,2019,4,14,22,bd2qov,C++ in deep leaning!Help me get trough this!:),https://www.reddit.com/r/deeplearning/comments/bd2qov/c_in_deep_leaninghelp_me_get_trough_this/,Zi6st,1555248530," 

Hi im a new to the deep learning world but im really excited to learn and mabye specialize in this field!

At the moment I know only c++ at a pretty good level .I got a financial aid from Coursera about deep learning ,that was taught in python which i know at a basic level , and i hate it. So i read some articles about c++ in machine learning and in deep learning and i found out that many people use it and actually 90% of the frameworks are coded in c++.So my question is how do i start this adventure into deep learning using c++,what framework does c++ support,is it better to go with ubuntu (atm using windows 10) ,does someone have any resources that they found useful (courses ,articles or blogs).I have to mention that i do have a Nvidia gpu with CUDA capability .",0,0
136,2019-4-15,2019,4,15,2,bd5dzs,A 2019 guide to Human Pose Estimation with Deep Learning,https://www.reddit.com/r/deeplearning/comments/bd5dzs/a_2019_guide_to_human_pose_estimation_with_deep/,manneshiva,1555264290,,1,21
137,2019-4-15,2019,4,15,5,bd6yqc,How to create a pass a keras variable to keras Model as output in Tensorflow 2.0?,https://www.reddit.com/r/deeplearning/comments/bd6yqc/how_to_create_a_pass_a_keras_variable_to_keras/,nobodywillobserve,1555272525,"For example


```python

V = K.variable(V0, name='V', dtype=tf.float32)                                                       

model = keras.models.Model(inputs=a\_input, outputs=\[q, V\])       

```

Doesn't work. Gives 

AttributeError: Tensor.op is meaningless when eager execution is enabled.

Is the only way to create variables in layers?",0,1
138,2019-4-15,2019,4,15,5,bd6zk8,Robot solves a Rubiks cube in a fraction of a second,https://www.reddit.com/r/deeplearning/comments/bd6zk8/robot_solves_a_rubiks_cube_in_a_fraction_of_a/,treguess,1555272661,,1,2
139,2019-4-15,2019,4,15,5,bd71ww,Reducing hdf5 size: VGG16 is over 500MB?,https://www.reddit.com/r/deeplearning/comments/bd71ww/reducing_hdf5_size_vgg16_is_over_500mb/,_sleepyotter,1555273025,"I have an architecture that is using VGG as the base network and the hdf5 file is HUGE. It's roughly 500 MB! I'm using keras and saving the weights by using `model.save_weights('weights.hdf5')`

&amp;#x200B;

From some quick google searches, it seems like the size of the hdf5 is not uncommon: 

* [https://forums.fast.ai/t/why-are-the-hierarchical-data-h5-format-files-so-large/469](https://forums.fast.ai/t/why-are-the-hierarchical-data-h5-format-files-so-large/469)
* [https://github.com/jcjohnson/fast-neural-style/issues/47](https://github.com/jcjohnson/fast-neural-style/issues/47)

&amp;#x200B;

Does anyone know of some ways to reduce the size of these hdf5 files? I'm trying to run it on a server for a web application. 

&amp;#x200B;

Thanks!",2,1
140,2019-4-15,2019,4,15,5,bd75vo,1 How Convolutional Neural Networks Work: An Intuitive Approach,https://www.reddit.com/r/deeplearning/comments/bd75vo/1_how_convolutional_neural_networks_work_an/,DiscoverAI,1555273641,,0,0
141,2019-4-15,2019,4,15,7,bd8bxk,What should the error distribution be across the sample of the KL or cross-entropy of distributions?,https://www.reddit.com/r/deeplearning/comments/bd8bxk/what_should_the_error_distribution_be_across_the/,nobodywillobserve,1555279925,"The title \*is\* confusing.

&amp;#x200B;

Suppose you predict a \*distribution\* y, and your error metric is the per-sample KL or cross-entropy: KL(yp\_i, y\_i) or something like that.

&amp;#x200B;

I see people using the mean cross-entropy but I don't see why that is justified. Sampling it shows that it could tend toward lognormal in some cases but not all. Is there a result published somewhere that I am missing about this?",0,2
142,2019-4-15,2019,4,15,7,bd8tbz,How does one dynamically add new parameters to optimizers in Pytorch?,https://www.reddit.com/r/deeplearning/comments/bd8tbz/how_does_one_dynamically_add_new_parameters_to/,brandojazz,1555282633,"[https://discuss.pytorch.org/t/dynamically-add-parameters-to-optimizer/11537](https://discuss.pytorch.org/t/dynamically-add-parameters-to-optimizer/11537)

[https://stackoverflow.com/questions/55640836/how-does-one-dynamically-add-new-parameters-to-optimizers-in-pytorch](https://stackoverflow.com/questions/55640836/how-does-one-dynamically-add-new-parameters-to-optimizers-in-pytorch)",0,1
143,2019-4-15,2019,4,15,8,bd8yr1,A Rant,https://www.reddit.com/r/deeplearning/comments/bd8yr1/a_rant/,patronus816,1555283558,"Im not really sure if some of you guys may feel the same way but im beginning to think of deep learning as a mechanical process wherein for a project, 

you would make an NN -&gt; CNN or RNN depending on purpose -&gt; look up papers about which is the best one  -&gt; select it and then feed data -&gt; hope it gets high on accuracy or something of the sort -&gt; and then youre finished!

I was wondering what keeps you going or am i wrong to think of it this way? 
I loved Machine Learning of Andrew Ng because it involved multiple paradigms/models but Im struggling to finish the DeepLearning.ai course because i may have lost my passion due to my way of thinking... (p.s. am already on computer vision which is course three or four of the curriculum.)",9,14
144,2019-4-15,2019,4,15,10,bdaa12,Accuracy and Sparse Categorical Cross Entropy decreases,https://www.reddit.com/r/deeplearning/comments/bdaa12/accuracy_and_sparse_categorical_cross_entropy/,rlamarr,1555291734,"Hi guys,
I've been trying to solve this for a few weeks now.
I'm training an Audio classification model which uses float32 40 log-mel filter banks as input to the model which I normalized using min-max normalization.

During training, the validation accuracy and training accuracy increase until they reach a peak of 0.15 and start to decrease and never increase.
I've tried removing BatchNorm and Dropout, and even reducing learning rate to no avail. Though the cross entropy loss keeps on reducing for the train and validation set continously.

I've tried this for a CNN and an LSTM based model but still get same results. 

Please, I really need this.",3,1
145,2019-4-15,2019,4,15,10,bdac9v,How to feed the output back to the input in LSTM?,https://www.reddit.com/r/deeplearning/comments/bdac9v/how_to_feed_the_output_back_to_the_input_in_lstm/,Rinzler187,1555292121,"input1 -(LSTM)-&gt; output1 
output1 -(LSTM) -&gt; output2 
output2 - (LSTM) -&gt; output3",0,0
146,2019-4-15,2019,4,15,11,bdauuy,Developing a Robust Face Generative Adversarial Network with Tensorflow,https://www.reddit.com/r/deeplearning/comments/bdauuy/developing_a_robust_face_generative_adversarial/,DiscoverAI,1555295235,,0,0
147,2019-4-15,2019,4,15,11,bdb5fu,How Neural Networks Work: Simply Explained,https://www.reddit.com/r/deeplearning/comments/bdb5fu/how_neural_networks_work_simply_explained/,DiscoverAI,1555296862,,0,0
148,2019-4-15,2019,4,15,13,bdc3h5,Optimisation theory,https://www.reddit.com/r/deeplearning/comments/bdc3h5/optimisation_theory/,Yonkou94,1555303534,Can someone please suggest me an introductory level course/book on Optimisation Theory?,6,14
149,2019-4-15,2019,4,15,16,bdd7j9,Recurrent Neural Networks: Algorithms and Applications,https://www.reddit.com/r/deeplearning/comments/bdd7j9/recurrent_neural_networks_algorithms_and/,DiscoverAI,1555313178,,0,13
150,2019-4-15,2019,4,15,18,bddv3c,Music Generation with multiple instruments.,https://www.reddit.com/r/deeplearning/comments/bddv3c/music_generation_with_multiple_instruments/,ApenguinElement,1555319557,"I was trying to generate piano music by using LSTM model, now I want to add another instrument by modifying the model. How should I do it? How should I design the model to train on different instruments? Any help would be great.",3,2
151,2019-4-15,2019,4,15,19,bdegbk,DataScience Digest - Issue #16,https://www.reddit.com/r/deeplearning/comments/bdegbk/datascience_digest_issue_16/,flyelephant,1555324513,,0,1
152,2019-4-15,2019,4,15,21,bdf5ak,Deep Learning from Scratch to GPU: Learning a Regression,https://www.reddit.com/r/deeplearning/comments/bdf5ak/deep_learning_from_scratch_to_gpu_learning_a/,dragandj,1555329781,,0,1
153,2019-4-15,2019,4,15,21,bdfdwq,Identifying dog breed with neural networks: from Keras to Android app,https://www.reddit.com/r/deeplearning/comments/bdfdwq/identifying_dog_breed_with_neural_networks_from/,atomlib_com,1555331323,,0,0
154,2019-4-16,2019,4,16,0,bdhmk5,ReWork Deep Learning in Finance Summit,https://www.reddit.com/r/deeplearning/comments/bdhmk5/rework_deep_learning_in_finance_summit/,Yuqing7,1555343741,,0,1
155,2019-4-16,2019,4,16,8,bdmkqa,ML for Chemistry: Jetson tx2 for inference,https://www.reddit.com/r/deeplearning/comments/bdmkqa/ml_for_chemistry_jetson_tx2_for_inference/,expericonatus,1555369338,"New to ML... I have a large data set (300+ experiments, each with 4 unique processing conditions (duration, pressure, temperature, and water activity and a main outcome being chemical % of removal by vapor ). I want to train an ml model to be able to predict optimal processing conditions for a user-specified % removal and vice versa; to predict removal percentage from processing conditions. 

&amp;#x200B;

Any tips (ex.RNN or CNN needed?; software Tensorflow?) or literature you could point me towards would be greatly appreciated!

&amp;#x200B;

Also, can I train the model on the jetson, how long would it take with that number of experiments, each with 5 numerical points of data?",6,3
156,2019-4-16,2019,4,16,11,bdoisv,"Interested in Artificial Intelligence, Machine Learning, Computer Vision, or NLP? Check out this channel for excellent, well-explained, video tutorials.",https://www.reddit.com/r/deeplearning/comments/bdoisv/interested_in_artificial_intelligence_machine/,DiscoverAI,1555380897,,0,4
157,2019-4-16,2019,4,16,11,bdokp9,Problem of multiply tasks training for one network,https://www.reddit.com/r/deeplearning/comments/bdokp9/problem_of_multiply_tasks_training_for_one_network/,ldl19691031,1555381225,"Dear everyone, this is my first time to post on reddit so if there are anything wrong please tell me and I will fix. 

My problem is about training a multiply task network but the dataset do not contains all information.  I want to build a network for 3D pose estimation.  The network will produce a 2d joint heat map like openpose, and a depth map for 3D.

&amp;#x200B;

[Network architecture for two task](https://i.redd.it/ripzxkptajs21.jpg)

Because I cannot got enough good 3d pose data, I decided to mix two datasets: one is a high quality 2D pose dataset (MSCOCO) for 2d joint, and a 3d dataset JTA dataset which is captured from game. I tested only trained in JTA dataset but the 2d heat map result seems not good. So I decided to mix the two dataset. 

I randomly select a data from these two datasets. But the 2d dataset does not contains depth info. So for that, I directly set the depth map loss to zero. I do not know if this is right.

  

[During 2d dataset training, I just set the depth path's loss to zero](https://i.redd.it/fgzyi3utbjs21.jpg)

I also tried these methods:

1. Training 2d heatmaps first. Then fix the 2D layers (contains the public part). Then train the depth map part. The depth map loss convergence to a really high value. This do not work.
2. Only training on 3d dataset. the result do not good. Although 2d heat maps loss convergence to a small value, but the network do not perform will on real life. I think it is because the data is captured in game.
3. I tried real life 3d dataset like MPI-INF. But the lack of variance( especially different light environment and clothes) causes bad result. I tried changing different background. It still do not perform will.

So now these are my questions:

1. My depth maps loss  convergence to a really higher value. And the training time seems really long. Is my training design affect this?
2. I choose to use Adam as optimizer. But since the depth map loss will be randomly set to zero, will this affect the adam's optimization progress because the loss surface is always changing ?
3. Is there any better solution for solving this multiply task training?

&amp;#x200B;

Really thanks for any idea and discussion.",2,4
158,2019-4-16,2019,4,16,13,bdpnd9,LSTMs for Human Activity Recognition,https://www.reddit.com/r/deeplearning/comments/bdpnd9/lstms_for_human_activity_recognition/,GChe,1555388468,,2,1
159,2019-4-16,2019,4,16,14,bdqc1t,Analyzing Source Code Using Neural Networks: A Case Study,https://www.reddit.com/r/deeplearning/comments/bdqc1t/analyzing_source_code_using_neural_networks_a/,TuSharma,1555393778,,0,11
160,2019-4-16,2019,4,16,22,bdtxyi,Applying Long Short-Term Memory for Video Classification Issues,https://www.reddit.com/r/deeplearning/comments/bdtxyi/applying_long_shortterm_memory_for_video/,RyanTmthn,1555421264,,0,16
161,2019-4-17,2019,4,17,1,bdvsf0,Bengio and Marcus at World AI Summit in Montral,https://www.reddit.com/r/deeplearning/comments/bdvsf0/bengio_and_marcus_at_world_ai_summit_in_montral/,gwen0927,1555431222,,0,5
162,2019-4-17,2019,4,17,3,bdxqcr,"Looking to join a community of Machine Learning Students and Developers passionate about AI, Computer Vision, Deep Learning, and Natural Language Processing? Join the DiscoverAI Slack Community here.",https://www.reddit.com/r/deeplearning/comments/bdxqcr/looking_to_join_a_community_of_machine_learning/,DiscoverAI,1555441154,,0,1
163,2019-4-17,2019,4,17,6,bdzrz2,"Boston Dynamics Spot Toughens Up, Hauls a Truck",https://www.reddit.com/r/deeplearning/comments/bdzrz2/boston_dynamics_spot_toughens_up_hauls_a_truck/,gwen0927,1555451777,,0,3
164,2019-4-17,2019,4,17,6,bdzsiy,Color preservation and image sharpening in GANs,https://www.reddit.com/r/deeplearning/comments/bdzsiy/color_preservation_and_image_sharpening_in_gans/,adi1709,1555451865,"I am working on extreme image compression using GANs. The reconstruction from the compressed images are missing color information and low level details. I am using adversarial loss, perceptual loss and MSE for optimization. Is there anything I can do to obtain better (color and sharpness) reconstructed images?",0,1
165,2019-4-17,2019,4,17,16,be5039,Why deep learning may not be the right solution for your business,https://www.reddit.com/r/deeplearning/comments/be5039/why_deep_learning_may_not_be_the_right_solution/,thumbsdrivesmecrazy,1555486352,"Way too many businesses reach for deep learning solutions when they shouldnt.

There are several factors that make relatively simpler models more suitable than their deep learning counterparts: [Why deep learning may not be the right solution for your business](https://dlabs.pl/blog/article/why-deep-learning-may-not-be-the-right-solution-for-your-business)

* Costs - The problems most, especially small, businesses are facing do not really require very complex and sophisticated methods which only increase costs and time.
* Not enough good-quality data - in some cases data sets are not big enough for deep learning which usually demands huge sample sizes.
* Limited interpretability - It is important because of new insights into relationships between numerous variables and expected outcomes, it increases the trust and understandability.",0,5
166,2019-4-17,2019,4,17,18,be5nro,Learning to paint: A Painting AI,https://www.reddit.com/r/deeplearning/comments/be5nro/learning_to_paint_a_painting_ai/,hzwer,1555492568,,6,86
167,2019-4-17,2019,4,17,18,be5t1o,[Project] Training models and running Jupyter Notebooks on AWS Spot Instances (cheaper and simpler than SageMaker),https://www.reddit.com/r/deeplearning/comments/be5t1o/project_training_models_and_running_jupyter/,apls777,1555493868,,0,3
168,2019-4-17,2019,4,17,20,be6p6d,"""Machine Learning: Alchemy for the Modern Computer Scientist"" with Erik Meijer (45min talk from GOTO Copenhagen 2018)",https://www.reddit.com/r/deeplearning/comments/be6p6d/machine_learning_alchemy_for_the_modern_computer/,goto-con,1555500870,,1,1
169,2019-4-17,2019,4,17,21,be6xx2,Experiment: 70fps real-time object detection with Google's Coral Dev Board with Edge TPU,https://www.reddit.com/r/deeplearning/comments/be6xx2/experiment_70fps_realtime_object_detection_with/,paul_read_it,1555502550,"We made a video to share our experience with the Google's Coral Dev Board with Edge TPU: [https://youtu.be/bOYWx1jJCZo](https://youtu.be/bOYWx1jJCZo)

&amp;#x200B;

We tested an object detection live stream under the following conditions:

\- a pretrained MobileNet v2 model, trained on the common objects in context (coco) dataset 

\- a bounding boxes threshold of 45% confidence because there were way too many boxes displayed in the default configuration

\- a camera connected via USB, not the official camera from Coral

&amp;#x200B;

We used this command to run the object detection server described above:

`edgetpu_classify_server \ --source /dev/video1:YUY2:800x600:24/1  \ --model path/to/model/mobilenet_ssd_v2_coco_quant_postprocess_edgetpu.tflite \ --labels path/to/labels/coco_labels.txt --threshold=0.45`

&amp;#x200B;

You can find more demos to play with here:

[https://coral.withgoogle.com/docs/dev-board/camera/](https://coral.withgoogle.com/docs/dev-board/camera/)

&amp;#x200B;

We hope this example helps you to get started with your own project!

&amp;#x200B;

If you have any idea, what we could build with the Coral device, let us know :-)

&amp;#x200B;

Paul",2,6
170,2019-4-17,2019,4,17,22,be7irs,Modelling relationships between objects in an image.,https://www.reddit.com/r/deeplearning/comments/be7irs/modelling_relationships_between_objects_in_an/,RohitDulam,1555506051,,0,3
171,2019-4-18,2019,4,18,0,be902e,Advancing in Deep Learning,https://www.reddit.com/r/deeplearning/comments/be902e/advancing_in_deep_learning/,smukh98,1555514225,"Hey all,
i am an undergrad student and i did a small course on machine learning for engineers.I got acquainted with algorithms like linear regression,logistic regression and all the way upto variational autoencoders and GANS.The course was a simple one as it was an introductory course. I have implemented vanilla classifiers,cnns,vaes etc.

So my question is whats the next step?
I have seen some of my friends writing research papers and publishing them in conferences and journals.Should i too start to write one? If so how should i start. 
Also since i am undergrad ,also tell something that recruiters want from an dl enthusiast.

Thanks in advance",2,4
172,2019-4-18,2019,4,18,3,bebk18,What are the minimum required skills to get a job in ML/DL coming from a Software Engineering (iOS) background?,https://www.reddit.com/r/deeplearning/comments/bebk18/what_are_the_minimum_required_skills_to_get_a_job/,ilikerum2,1555527295,"Hi 

Im currently a masters student learning about ML/AI and prior to my masters I was working as a Software Engineer working on iOS and Android platform. In my deep learning class i'm learning about MLPs, CNNs, RNNs, GANS, VAEs and RL. For assignments we have been doing things like Face Recognition using CNNs, Sequence to Sequence Translations, Building MLP from scratch using numpy. 

I want to know how these skills match up to industry requirements and what are some core skills you think someone with my background should have to qualify to be an ML/DL Engineer. Im very very passionate about this field and even though I don't have a strong math background (undergrad CS) but i'm able to work hard ask a lot of questions and understand the research papers to some extent. I want to work in speech tech or NLP. 

&amp;#x200B;

I would like to think there is  some sort of 80-20 split in terms of skills that are used in the industry. So i just wanted to know how I can acquire them and also how can i build a presence online if I want to stand out and be really good in this area.

&amp;#x200B;

Thanks",4,5
173,2019-4-18,2019,4,18,4,bec8e7,Training an autoencoder for multiple time-series together?,https://www.reddit.com/r/deeplearning/comments/bec8e7/training_an_autoencoder_for_multiple_timeseries/,pk12_,1555530826,"Any tips or suggestions? A reference even?

The time-series are correlated at some intervals. I wonder if I can integrate this information in the training process",2,4
174,2019-4-18,2019,4,18,10,befikm,Want to learn more about how deep Learning broadens the reach of Artificial Intelligence?,https://www.reddit.com/r/deeplearning/comments/befikm/want_to_learn_more_about_how_deep_learning/,treguess,1555549382,Want to learn more about how deep Learning broadens the reach of Artificial Intelligence? Read my article:[Read full article here. ](https://thenewstack.io/deep-learning-broadens-the-reach-of-artificial-intelligence/),0,0
175,2019-4-18,2019,4,18,12,beh18f,Deep Learning: Our journey begins  My Journey with Deep Learning and Computer Vision,https://www.reddit.com/r/deeplearning/comments/beh18f/deep_learning_our_journey_begins_my_journey_with/,msminhas93,1555559057,,1,0
176,2019-4-18,2019,4,18,14,beho8c,Face Recognition: An Introduction for Beginners,https://www.reddit.com/r/deeplearning/comments/beho8c/face_recognition_an_introduction_for_beginners/,spmallick,1555563780,"Face Recognition has been one of the most researched Computer Vision areas till date. So, it is natural to have too much information overload around the same.   
In our latest article, we have tried to simplify the topic and hope that it serves as a beginners' guide on Face Recognition.  
Feel free to comment if you think we have missed out on anything important.

[https://www.learnopencv.com/face-recognition-an-introduction-for-beginners/](https://www.learnopencv.com/face-recognition-an-introduction-for-beginners/) 

Mention reviews and what you want us to work next, in the comments!

P.S : More articles ( with code ) to come.  
[\#LearnOpenCV](https://www.facebook.com/hashtag/learnopencv?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&amp;__tn__=%2ANK-R) [\#OpenCV](https://www.facebook.com/hashtag/opencv?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&amp;__tn__=%2ANK-R) [\#MachineLearning](https://www.facebook.com/hashtag/machinelearning?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&amp;__tn__=%2ANK-R) [\#DeepLearning](https://www.facebook.com/hashtag/deeplearning?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&amp;__tn__=%2ANK-R) [\#AI](https://www.facebook.com/hashtag/ai?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&amp;__tn__=%2ANK-R)[\#ComputerVision](https://www.facebook.com/hashtag/computervision?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&amp;__tn__=%2ANK-R) [\#FaceRecognition](https://www.facebook.com/hashtag/facerecognition?source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&amp;__tn__=%2ANK-R)

https://i.redd.it/xpftawm8gys21.jpg",1,24
177,2019-4-18,2019,4,18,16,beij6s,Visualizing stock trading agents using Matplotlib and Gym,https://www.reddit.com/r/deeplearning/comments/beij6s/visualizing_stock_trading_agents_using_matplotlib/,notadamking,1555570847,,0,8
178,2019-4-18,2019,4,18,16,beim7j,free video: Deep Learning with Python (registration required),https://www.reddit.com/r/deeplearning/comments/beim7j/free_video_deep_learning_with_python_registration/,PacktStaff,1555571553,,0,2
179,2019-4-18,2019,4,18,16,beipjl,"Livestreamed Conference on Deep Learning, AI, Big Data, ML applied to Brain - Jure Leskovec speaking",https://www.reddit.com/r/deeplearning/comments/beipjl/livestreamed_conference_on_deep_learning_ai_big/,ScienTecht,1555572380,,0,3
180,2019-4-19,2019,4,19,0,bemoop,Upgrading CNN With OctConv,https://www.reddit.com/r/deeplearning/comments/bemoop/upgrading_cnn_with_octconv/,gwen0927,1555600267,,2,12
181,2019-4-19,2019,4,19,6,ber9tr,Convolutional layer output size,https://www.reddit.com/r/deeplearning/comments/ber9tr/convolutional_layer_output_size/,RealOden,1555624518,"Hi people,

I'm stuck on a problem and was wondering if anyone would be able to provide me with some answers, as I have not found any when googling. In the following code snippet from ChainerRL they list the output of the last convolutional layer as 3136 when put into the fully-connected (linear) layer:

&amp;#x200B;

&amp;#x200B;

1. **class** NatureDQNHead(chainer.ChainList):
2. """"""DQN's head (Nature version)""""""
3. **def** \_\_init\_\_(self, n\_input\_channels=4, n\_output\_channels=512,
4.         activation=F.relu, bias=0.1):
5. self.n\_input\_channels = n\_input\_channels
6. self.activation = activation
7. self.n\_output\_channels = n\_output\_channels
8.     layers = \[
9.       L.Convolution2D(n\_input\_channels, 32, 8, stride=4,
10.               initial\_bias=bias),
11.       L.Convolution2D(32, 64, 4, stride=2, initial\_bias=bias),
12.       L.Convolution2D(64, 64, 3, stride=1, initial\_bias=bias),
13.       L.Linear(**3136**, n\_output\_channels, initial\_bias=bias), &lt;--------------HERE
14. \]
15. super(NatureDQNHead, self).\_\_init\_\_(\*layers)
16. **def** \_\_call\_\_(self, state):
17.     h = state
18. **for** layer **in** self:
19.       h = self.activation(layer(h))
20. **return** h

&amp;#x200B;

&amp;#x200B;

How do you calculate that output? I need to know as normally None works fine in ChainerRL, as it automatically sets the variable to whatever the output is, but when trying to create an A3C model this is no longer ok. I need the output of the last convolutional layer for the following NN:

&amp;#x200B;

&amp;#x200B;

1. **class** QFunction(chainer.ChainList):
2. **def** \_\_init\_\_(self, obs\_size):
3. self.conv0 = L.ConvolutionND(2, None, 32, ksize=(8,8), stride=(4,4), pad=(3,3))
4. self.conv1 = L.ConvolutionND(2, 32, 64, ksize=(4,4), stride=(2,2), pad=(3,3))
5. self.conv2 = L.ConvolutionND(2, 64, 128, ksize=(3,3), stride=(1,1), pad=(3,3))
6. self.l0 = L.Linear(**None**, 512) &lt;------What should the input be at None?
7.     layers = \[
8. self.conv0,
9. self.conv1,
10. self.conv2,
11. self.l0
12. \]
13. super(QFunction, self).\_\_init\_\_(\*layers)
14. **def** \_\_call\_\_(self, state):
15.     h = state
16. **for** layer **in** self:
17.       h = F.relu(layer(h))
18. **return** h

&amp;#x200B;

&amp;#x200B;

Notice that it also has padding, as it's needed to satisfy an assertion in ChainerRL of some arbitrary calculation of the parameters in the layer. If someone could answer this, I would greatly appreciate it.",1,2
182,2019-4-19,2019,4,19,10,betllg,Helping a total newbie run SC-FEGAN,https://www.reddit.com/r/deeplearning/comments/betllg/helping_a_total_newbie_run_scfegan/,sytrix,1555637836,"I'm sorry if this is the wrong place to ask but I've Googled my issues and I'm at a loss on helpful resources.

I'm not familiar with neural networks but would like to try [SC-FEGAN](https://github.com/JoYoungjoo/SC-FEGAN) out. I have the files, the model, and Python downloaded and I'm stuck on getting this working:

    mv /${HOME}/SC-FEGAN.ckpt.* /${HOME}/ckpt/
    python3 demo.py

Should I be using command prompt or Python to launch the GUI? How do I use the other dependencies listed (tensorflow, numpy, Python3, PyQt5, opencv-python, pyyaml)?

ELI5, any advice would be appreciated, thank you for your time :)",2,1
183,2019-4-19,2019,4,19,10,betokv,"1 Interested in Artificial Intelligence, Machine Learning, Computer Vision, or NLP? Check out this channel for excellent, well-explained, video tutorials.",https://www.reddit.com/r/deeplearning/comments/betokv/1_interested_in_artificial_intelligence_machine/,Bobber123yxz,1555638371,,0,0
184,2019-4-19,2019,4,19,11,betue7,random noise is classified as some class..!,https://www.reddit.com/r/deeplearning/comments/betue7/random_noise_is_classified_as_some_class/,GW_KIM,1555639418,"Hi, i am making some classifier using CNN.

there is 2 class and train loss go low well. and training acc shows good result.

But, when i test it on test data, the result is extremely biased to some class. 

So i feed a random noise to network ,and got a same result (biased)

what's wrong with it...? HELP :(",5,1
185,2019-4-19,2019,4,19,12,beuhrx,AI Draws Awesome Caricatures (WarpGAN),https://www.reddit.com/r/deeplearning/comments/beuhrx/ai_draws_awesome_caricatures_warpgan/,hanyuqn,1555643661,,0,31
186,2019-4-19,2019,4,19,14,bevqqw,Going to #ODSCEast? Get a Free 1-hour consultation,https://www.reddit.com/r/deeplearning/comments/bevqqw/going_to_odsceast_get_a_free_1hour_consultation/,treguess,1555653046,[removed],0,1
187,2019-4-19,2019,4,19,16,bewc7n,new podcasts in the field of artificial intelligence,https://www.reddit.com/r/deeplearning/comments/bewc7n/new_podcasts_in_the_field_of_artificial/,Doctor_who1,1555658135," 

Hello . I want to create podcasts in the field of artificial intelligence, but unfortunately I have no idea what to say in the first issue. I wanted to help if you know the article or topics you can post on the first episode of the podcast.",0,0
188,2019-4-20,2019,4,20,2,bf257k,Are there any significant differences between deep learning and early neural networks? (besides number of layers),https://www.reddit.com/r/deeplearning/comments/bf257k/are_there_any_significant_differences_between/,bobmichal,1555696513,,3,0
189,2019-4-20,2019,4,20,5,bf3y2k,10 Deep Learning Resources for Audio Processing,https://www.reddit.com/r/deeplearning/comments/bf3y2k/10_deep_learning_resources_for_audio_processing/,oblivionreb,1555705926,,1,33
190,2019-4-20,2019,4,20,6,bf4fih,Good tutorials for Sentiment Analysis for EXTREME noob,https://www.reddit.com/r/deeplearning/comments/bf4fih/good_tutorials_for_sentiment_analysis_for_extreme/,stackoverflowcoder,1555708539,"Currently I've only built CNN'S in Keras, and understand python code.",0,1
191,2019-4-20,2019,4,20,7,bf5bnl,Convolutions Convoluted? Nah  My Journey with Deep Learning and Computer Vision,https://www.reddit.com/r/deeplearning/comments/bf5bnl/convolutions_convoluted_nah_my_journey_with_deep/,msminhas93,1555713578,,0,3
192,2019-4-20,2019,4,20,13,bf8amj,(Python) Easy to follow NeuroEvolution tutorial,https://www.reddit.com/r/deeplearning/comments/bf8amj/python_easy_to_follow_neuroevolution_tutorial/,EzitoKo,1555733288,,0,1
193,2019-4-21,2019,4,21,1,bfdyhy,Deep Reinforcement Learning AILearning to Paint like humans,https://www.reddit.com/r/deeplearning/comments/bfdyhy/deep_reinforcement_learning_ailearning_to_paint/,hzwer,1555777372,,1,7
194,2019-4-21,2019,4,21,2,bfevml,Tensorflow and Keras For Neural Networks and Deep Learning,https://www.reddit.com/r/deeplearning/comments/bfevml/tensorflow_and_keras_for_neural_networks_and_deep/,system4norcal,1555782121,,0,1
195,2019-4-21,2019,4,21,3,bffhhn,OKAI - An Interactive Introduction to Artificial Intelligence (AI),https://www.reddit.com/r/deeplearning/comments/bffhhn/okai_an_interactive_introduction_to_artificial/,tydlwav,1555785346,,0,1
196,2019-4-21,2019,4,21,3,bffmve,OKAI - An Interactive Introduction to Artificial Intelligence (AI),https://www.reddit.com/r/deeplearning/comments/bffmve/okai_an_interactive_introduction_to_artificial/,tydlwav,1555786184,,2,28
197,2019-4-21,2019,4,21,5,bfgovk,This video goes over a breast cancer diagnosis model that uses neural networks. Really interesting,https://www.reddit.com/r/deeplearning/comments/bfgovk/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1555792049,,0,2
198,2019-4-21,2019,4,21,11,bfkcp7,Activation Functions,https://www.reddit.com/r/deeplearning/comments/bfkcp7/activation_functions/,ZeroMaxinumXZ,1555814998,"What makes a good activation function? What qualities should I look for in an activation function? For example, in RELU, the output is zero when the input is negative, and in sigmoid, the output is always between zero and one...

&amp;#x200B;

So, what exactly makes a good activation function?",3,4
199,2019-4-21,2019,4,21,12,bfktmx,[R] FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained Object Generation and Discovery (CVPR'19 Oral presentation),https://www.reddit.com/r/deeplearning/comments/bfktmx/r_finegan_unsupervised_hierarchical/,utkarsh2254,1555818356,,3,38
200,2019-4-22,2019,4,22,0,bfpsr7,A few questions,https://www.reddit.com/r/deeplearning/comments/bfpsr7/a_few_questions/,TheUSARMY45,1555859540,"Hello everyone! Im relatively new to the field of Deep Learning, but am itching to learn more. I have academic background in statistical theory with a focus on data science, but have also been taking some Deep Learning classes through Coursera (Andrew Ngs deep learning specialization). I just have a few questions that I wanted to get some input on from this community:

1) I am very well versed in R for most of the analytical things that I do, though I do know a little bit of Python (the coursera course is done in Python). While I know that the big Deep Learning frameworks like Keras and Tensorflow were developed in Python, I was wondering what more I could do to learn more about Deep Learning with R

2) I really want to get into GPU Learning. I have an AMD gpu in my desktop PC and an NVIDIA Quadra K1100m in my laptop. I know that there is limited support for AMD GPUs in Deep Learning right now, but is there anything at all that I can try with this? Alternatively, would my NVIDIA card be up to snuff for practicing with some shallower neural nets? I dont want to fry my GPU just because I know very little about the subject 

Any comments are greatly appreciated! This stuff is so fascinating to me and I am really excited to learn more!",0,1
201,2019-4-22,2019,4,22,0,bfpv6k,Topic in deep learning with potential for most growth,https://www.reddit.com/r/deeplearning/comments/bfpv6k/topic_in_deep_learning_with_potential_for_most/,nicetryho,1555859945,"What areas in deep learning are worth exploring that arent really saturated ? Im seeing a lot of GAN research is being done to generate art, whats another Avenue with a lot less hype and a lot less data contributed?",9,15
202,2019-4-22,2019,4,22,4,bfsaa2,Sparse deep neural topology,https://www.reddit.com/r/deeplearning/comments/bfsaa2/sparse_deep_neural_topology/,ToolTechSoftware,1555873288,"More and more people are looking at Neural Networks that doesnt follow the traditional tensor math or forward feed topology.  

I have been working for years to get Nvidia or other GPU/FPGA to realise this fact that we need new ways to accellerate generic interconnected networks.  

My suggestion is a Neural Network language.  An assembler that can describe low level Neural Network topologies.  I call it CAL.  

By using CAL you can construct any graph cyclic connected topography and run it in an optimizer and a compiler to produce efficient code for backprop or genetic evolution of code.  

Would love to discuss...",2,3
203,2019-4-22,2019,4,22,6,bftnms,EDM music generated using deep recurrent neural networks  please help me to evaluate!,https://www.reddit.com/r/deeplearning/comments/bftnms/edm_music_generated_using_deep_recurrent_neural/,MaxCb,1555880893,"This is for my final year project. Any responses are greatly appreciates, only takes 2 mins! Thank you.

Survey link: https://www.surveygizmo.com/s3/4968707/Generated-Music-Evaluation",11,35
204,2019-4-22,2019,4,22,6,bftsyr,[Question] BERT performing worse than word2vec,https://www.reddit.com/r/deeplearning/comments/bftsyr/question_bert_performing_worse_than_word2vec/,naboo_random,1555881716,"Hi, 

&amp;#x200B;

I am trying to use BERT for a document ranking problem. My task is pretty straightforward. I have to do a similarity ranking for an input document. The only issue here is that I dont have labels - so its more of a qualitative analysis.

I am on my way to try a bunch of document representation techniques - word2vec, para2vec and BERT mainly. 

&amp;#x200B;

For BERT, i came across [this](https://github.com/huggingface/pytorch-pretrained-BERT) library.  I fine tuned the bert-small-uncased model, with around 150,000 documents. I ran it for 5 epochs, with a batch size of 16 and max seq length 128. However, if I compare the performance of Bert representation vs word2vec representations, for some reason word2vec is performing better for me right now. For BERT, I used the last four layers for getting the representation. 

&amp;#x200B;

I am not too sure why the fine tuned model didnt work. I read up [this](https://arxiv.org/pdf/1903.05987.pdf) paper, and [this](https://github.com/huggingface/pytorch-pretrained-BERT/issues/493) other link also that said that BERT performs well when fine tuned for a classification task. However, since I dont have the labels, I fined tuned it as it's done in the paper - in an unsupervised manner.

&amp;#x200B;

Also, my documents vary a lot in their length. So Im sending them sentence wise right now. In the end I have to average over the word embeddings anyway to get the sentence embedding. Any ideas on a better method? I also read [here](https://github.com/hanxiao/bert-as-service)  \- that there are different ways of pooling over the word embeddings to get a fixed embedding. Wondering if there is a comparison of which pooling technique works better? 

&amp;#x200B;

Any help on training BERT better or a better pooling method will be greatly appreciated! 

&amp;#x200B;

Thanks,",0,12
205,2019-4-22,2019,4,22,8,bfv1he,Am I being underpaid? Would a DL position offer a significant pay increase?,https://www.reddit.com/r/deeplearning/comments/bfv1he/am_i_being_underpaid_would_a_dl_position_offer_a/,74throwaway,1555888888,"I currently work in image processing just developing code in Matlab and make around $100K/yr in California, but I get to work from home in CA (near LA). I've only gotten to work with deep learning for a couple months in this job. I have alot of gaps in my resume, but I have about 1.5 yrs experience in this current job along with some freelance work/personal projects in machine learning.

Deep learning seems alot more interesting to me than image processing. Plus, it seems Data Scientists/ML Engineers near LA with around the same experience as me make around 90-175K/yr. So I feel underpaid, but I guess being allowed to work remotely kind of makes up for that. 

Am I right that I'm being underpaid? If I were to spend a few months working on Kaggle projects using Deep Learning, would I have a realistic chance at jobs offering much higher salaries near LA or the Bay Area, such as $150-175K?",1,2
206,2019-4-22,2019,4,22,12,bfxh1l,DL study suggestion,https://www.reddit.com/r/deeplearning/comments/bfxh1l/dl_study_suggestion/,gabrie-ll,1555904058,"Hi,
I've gotten started in ML and DL by my own at uni, but now that I've been using what I studied so far @ a research project, I've been pretty reliant on my teachers to give me pointers as to what to do. What do you guys recommend as far as reading/course material? My main focus is ConvNets, but deep learning in general is really interesting to me and is likely what I'll pursue further on.

So far I've done a ML class (and a couple statistics classes), the ML Andrew Ng course, going through the deeplarning.ai classes on YouTube and reading an image processing book (Gonzalez I think). I'm open to any suggestions, thx in advance bros",1,1
207,2019-4-22,2019,4,22,20,bg15ri,Load word embedding on cpu and training on gpu,https://www.reddit.com/r/deeplearning/comments/bg15ri/load_word_embedding_on_cpu_and_training_on_gpu/,rishabh279,1555933809,"Hey folks,

I am using keras framework to train my bidirectional LSTM model. I am training my model on multiple gpu of amazon instance. The word embedding(WE) that I am using has a size of 24 gb, in addition I have 3-4 lakhs  of training records with each record consisting of 900-1000 words. For this to load ie. WE + training data it requires 256 gb ram of gpu. This is costing me a lot. I am using p3dn.24xlarge instance of amazon. Is there a way to load the WE on cpu and do training on gpu so that I can use a low config instance of amazon which would require low gpu memory and save pretty descent bucks. Thanks in advance.",0,1
208,2019-4-23,2019,4,23,0,bg37ne,Everyone Is an Artist: GauGAN Turns Doodles Into Photorealistic Landscapes,https://www.reddit.com/r/deeplearning/comments/bg37ne/everyone_is_an_artist_gaugan_turns_doodles_into/,Yuqing7,1555945862,,1,29
209,2019-4-23,2019,4,23,0,bg3jze,Bioinformatics,https://www.reddit.com/r/deeplearning/comments/bg3jze/bioinformatics/,prabin96,1555947674,"You are working with a pharma company, who released a new drug that can cure cancer. However, this drug is fatal for patients with a particular set of molecules in their DNA. Let us assume that a single DNA strand is enough to identify if a drug is fatal for a person. Let us also assume that each molecule in the DNA can be one among four types. Problem is, each DNA strand is two billion molecules long, and it is hard to identify problematic molecules manually. 

The company is interested in training a classifier to automatically decide if this treatment is safe for the patient. They have collected DNA strands from ten thousand people. The drug is fatal for hundred among these ten thousand people. You are provided with both the DNA strand data, and its corresponding label (safe or fatal). For clarity, lets assume the label safe is a positive label and label fatal is a negative label. 

This is problem statement, what could be the solution? Could anyone give workflow of this problem from start to end??",8,1
210,2019-4-23,2019,4,23,4,bg67ym,Class activation mapping for videos,https://www.reddit.com/r/deeplearning/comments/bg67ym/class_activation_mapping_for_videos/,kzhang3256,1555961161," Does anyone know how to do class activation mapping for a video (during classification for action detection)? Im using resnet3d50 architecture as pre-trained model. Both pytorch and keras work for me. If anyone knows there is code/github repo doing similar things will be best.   
Thanks!",2,3
211,2019-4-23,2019,4,23,10,bga5d0,"Deep Learning Build, Need some Expertise :)",https://www.reddit.com/r/deeplearning/comments/bga5d0/deep_learning_build_need_some_expertise/,Atralb,1555982259,"Hi guys,

&amp;#x200B;

So I'm planning to build my own computer for making deep learning experiments, but also want to be able to use it as a private server simultaneously, and be able to use it with browser, heavy code editor, etc... sometimes.  
For reference I want to make personal deep learning training experiments in music (and more generally sound) analysis and maybe a bit of video game AI applications experiments (not in relation with the music thing).

&amp;#x200B;

It's my first time building a pc but I will have an experienced friend there to help me when the critical time comes.

&amp;#x200B;

So I mainly followed this guide [https://medium.com/the-mission/how-to-build-the-perfect-deep-learning-computer-and-save-thousands-of-dollars-9ec3b2eb4ce2](https://medium.com/the-mission/how-to-build-the-perfect-deep-learning-computer-and-save-thousands-of-dollars-9ec3b2eb4ce2) in my research along with a bit of that one [https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/](https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/) and many others.

&amp;#x200B;

I don't have very much money but I want to use in potential professional use and I'm in the post-graduation-first-job phase as an IA engineer and paid 1k2 for at least 6 months in an internship so I thought asking a 2k-advance on my parents was a good budget. High end powerful experiment while maintaining not exorbitant prices relatively to my financial means.

&amp;#x200B;

&amp;#x200B;

Therefore, with 2000EUR in mind then, I settle with this temporary build (sorry for the different language) :  
**- Power : Corsair HX1200i** [https://www.amazon.fr/gp/product/B00S8HY0BW/ref=ox\_sc\_act\_title\_2?smid=A1X6FK5RDHNB96&amp;psc=1](https://www.amazon.fr/gp/product/B00S8HY0BW/ref=ox_sc_act_title_2?smid=A1X6FK5RDHNB96&amp;psc=1)

**-** **Motherboard : Gigabyte X399 Aorus Pro, AMD X399**  [https://www.amazon.fr/gp/product/B07KF7M46X/ref=ox\_sc\_act\_title\_3?smid=A1X6FK5RDHNB96&amp;psc=1](https://www.amazon.fr/gp/product/B07KF7M46X/ref=ox_sc_act_title_3?smid=A1X6FK5RDHNB96&amp;psc=1)  
**- Storage : Samsung SSD 970 EVO NVMe M.2 (1TB)- MZ-V7E1T0BW**  [https://www.amazon.fr/gp/product/B07CGJNLBB/ref=ox\_sc\_act\_title\_4?smid=A862111F3B7OV&amp;psc=1](https://www.amazon.fr/gp/product/B07CGJNLBB/ref=ox_sc_act_title_4?smid=A862111F3B7OV&amp;psc=1)  
**- CPU : AMD Ryzen 7 Threadripper 1920X**   [https://www.amazon.fr/gp/product/B074CBJHCT/ref=ox\_sc\_act\_title\_5?smid=A1X6FK5RDHNB96&amp;psc=1](https://www.amazon.fr/gp/product/B074CBJHCT/ref=ox_sc_act_title_5?smid=A1X6FK5RDHNB96&amp;psc=1)

**- GPU : A GTX 1080 ti** but got no amazon link, cause things move fast for it on amazon, so I give it time for when I see a good deal (you can see from 550 to 800)

So first I have a couple questions :

* **GPU :** So here my prime argument is getting the threshold of 10Gb of VRAM. Secondly, in the guide I provided, it is said that the performance (at least in deep learning) is proportional to the amount of CUDA cores, so I made calculation that in my country the 1080 GTX is the best deal. What do you think of these choices in relation to the practice I want to make of it ? Do you have any other thoughts regarding the GPU ? Maybe RTX 2070 or 2080 is better for the price ?
* **Case :** I got it was really important to take dimensions in account when looking for the case.  
The guy is suggesting this (150EUR 270\*465\*476mm) : [https://www.amazon.fr/Lian-Li-PC-O11AIR-Bo%C3%AEtier-pour/dp/B07FJ6PMKW/ref=sr\_1\_fkmrnull\_1?\_\_mk\_fr\_FR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;keywords=%3A+Lian-Li+PC-O11AIR&amp;qid=1555175276&amp;s=gateway&amp;sr=8-1-fkmrnull](https://www.amazon.fr/Lian-Li-PC-O11AIR-Bo%C3%AEtier-pour/dp/B07FJ6PMKW/ref=sr_1_fkmrnull_1?__mk_fr_FR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;keywords=%3A+Lian-Li+PC-O11AIR&amp;qid=1555175276&amp;s=gateway&amp;sr=8-1-fkmrnull)  
Considering the 1080 measures 370\*280\*114mm (for a Gigabyte) Do you think this won't go (50EUR 470\*201\*429mm) : [https://www.amazon.fr/dp/B00RORBQNW/ref=psdc\_430338031\_t1\_B00XPUFY0I](https://www.amazon.fr/dp/B00RORBQNW/ref=psdc_430338031_t1_B00XPUFY0I) ?
* **Fans :** Besides, considering the motherboard configuration (available here [https://c1.neweggimages.com/ProductImageCompressAll1280/13-145-109-V01.jpg](https://c1.neweggimages.com/ProductImageCompressAll1280/13-145-109-V01.jpg)), and considering the case dimension (470\*201\*429) and the GPU dimension and its placing on the motherboard, do you think a fan like this one would be able to fit in :  
Noctua NH-U9 TR4-SP3 [https://www.amazon.fr/gp/product/B074DXFB66/ref=ox\_sc\_saved\_title\_2?smid=A38F5RZ72I2JQ&amp;psc=1](https://www.amazon.fr/gp/product/B074DXFB66/ref=ox_sc_saved_title_2?smid=A38F5RZ72I2JQ&amp;psc=1) ?  
We've done a bit of calculation and considering where the different components will be placed on the motherboard, and, while it was very approximate, we found it would be at least a bit difficult.
* **CPU :** I've done my research mostly last weekend so I don't remember everything but I know I settled for the 1920X cause of the numerous cores and because I kinda believed (but really vaguely) it was better for the price than Intel.But I have since heard that unless using 4 GPUs it was not necessary putting 400EUR for a CPU and maybe taking a 200-300 one and putting the rest of the money in a better gpu was not a bad idea. What is your take on this ?
* **Network Card :** For experienced Deep learning engineers do you think going for a 10Gb Network card like this [https://www.amazon.fr/gp/product/B071JR2ZW8/ref=ox\_sc\_saved\_title\_3?smid=A1X6FK5RDHNB96&amp;psc=1](https://www.amazon.fr/gp/product/B071JR2ZW8/ref=ox_sc_saved_title_3?smid=A1X6FK5RDHNB96&amp;psc=1) a good idea or not really useful ?I currently have 800Mb/s down rates with my laptop in Ethernet, and I don't see myself having to download Terabytes of data so I thought it was more of a gadget than anything, but I perfectly may be wrong.
* **Power :** Is 1200W too much with that build (if the guy's calcuations are right and I understood well, I've done that : GPU 250W (500W for future second card) + 180 W CPU + 150W = 830W =&gt; 1000W and the 1200W is only 25EUR more) ?Is it even overkill to have more than what I need since it wil apparently consume more for nothing and so inflate the electricity bill ?
* **RAM :** Are 16Gb enough for this (10Gb model training + 3 Gb for smth else +  3 System (maybe it's a bit short) ?

&amp;#x200B;

&amp;#x200B;

I think that's all, but I may have forgotten something (you know 420 is just 3 days ago :p), I will maybe add something later. By the way, I'm still open to anything else you might think and will be glad to read you.

Thanks a lot in advance for your help !",9,2
212,2019-4-23,2019,4,23,13,bgc2z1,"[P] Trump, Obama, Jordan Peterson and Neil deGrasse Tyson TTS models sing Straight Outta Compton",https://www.reddit.com/r/deeplearning/comments/bgc2z1/p_trump_obama_jordan_peterson_and_neil_degrasse/,hanyuqn,1555993900,"This is a great demonstration of some of the different TTS models I've trained and how I can control style:

https://www.youtube.com/watch?v=SXTdnk7-2i0

These models were trained using my implementation of the papers ""Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis"" (https://arxiv.org/abs/1803.09017) and ""Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron"" (https://arxiv.org/abs/1803.09047).",2,2
213,2019-4-23,2019,4,23,21,bgfxjz,Deep Learning from Scratch to GPU: Weight Decay,https://www.reddit.com/r/deeplearning/comments/bgfxjz/deep_learning_from_scratch_to_gpu_weight_decay/,dragandj,1556023463,,0,12
214,2019-4-24,2019,4,24,1,bgif7o,Text Classification Algorithms: A Survey,https://www.reddit.com/r/deeplearning/comments/bgif7o/text_classification_algorithms_a_survey/,kk7nc,1556036886,,0,2
215,2019-4-24,2019,4,24,2,bgj8t9,Respected AI pioneer and visionary Nils John Nilsson passed away early this morning,https://www.reddit.com/r/deeplearning/comments/bgj8t9/respected_ai_pioneer_and_visionary_nils_john/,gwen0927,1556040955,,0,62
216,2019-4-24,2019,4,24,6,bglqc7,"TensorFlow, PyTorch or MXNet? A comprehensive evaluation on NLP &amp; CV tasks with Titan RTX",https://www.reddit.com/r/deeplearning/comments/bglqc7/tensorflow_pytorch_or_mxnet_a_comprehensive/,gwen0927,1556053623,,0,10
217,2019-4-24,2019,4,24,6,bglznw,[N] Google Colab now comes with free T4 GPUs,https://www.reddit.com/r/deeplearning/comments/bglznw/n_google_colab_now_comes_with_free_t4_gpus/,tlkh,1556054950,,2,19
218,2019-4-24,2019,4,24,10,bgoo1q,Help! I have to build a ROI pooling layer for my CNN based off Tensorflow.,https://www.reddit.com/r/deeplearning/comments/bgoo1q/help_i_have_to_build_a_roi_pooling_layer_for_my/,SenSyllable,1556070007,"I searched for ROI pooling layer on Tensorflow. But apparently, it's not there, there's one in Caff, but shifting the entire architecture onto Caff is... Difficult.
What are the other options I should look into?",1,1
219,2019-4-24,2019,4,24,15,bgri3t,Query on annotation style,https://www.reddit.com/r/deeplearning/comments/bgri3t/query_on_annotation_style/,Mahe7,1556089051,,12,4
220,2019-4-24,2019,4,24,20,bgtdxg,Achieving State Of The Art Results In Natural Language Processing - Part 1: Fundamental Concepts,https://www.reddit.com/r/deeplearning/comments/bgtdxg/achieving_state_of_the_art_results_in_natural/,lauram16_hello,1556104934,,0,19
221,2019-4-24,2019,4,24,20,bgtknx,"Achieving State Of The Art Results In Natural Language Processing - Part 2: ELMo, BERT and MT-DNN",https://www.reddit.com/r/deeplearning/comments/bgtknx/achieving_state_of_the_art_results_in_natural/,lauram16_hello,1556106185,,0,3
222,2019-4-25,2019,4,25,0,bgw2cs,How Do Open Source Deep Learning Frameworks Stack Up?,https://www.reddit.com/r/deeplearning/comments/bgw2cs/how_do_open_source_deep_learning_frameworks_stack/,pmz,1556120122,,0,0
223,2019-4-25,2019,4,25,2,bgxfrf,Python code,https://www.reddit.com/r/deeplearning/comments/bgxfrf/python_code/,yohandp,1556126935,"Hey! I'm new in machine and deep learning stuffs and I'm learning without import libraries, on python.  I have an question about how calculate between hidden layers in a multiple y network. I'm trying to create an network with 4 entries, 6 hidden, 24 hidden and 8 exits.",4,0
224,2019-4-25,2019,4,25,4,bgyxax,Image Data Generators in Keras  My Journey with Deep Learning and Computer Vision,https://www.reddit.com/r/deeplearning/comments/bgyxax/image_data_generators_in_keras_my_journey_with/,msminhas93,1556134415,,0,1
225,2019-4-25,2019,4,25,6,bh04dh,Convolutional Neural Networks in TensorFlow | Coursera,https://www.reddit.com/r/deeplearning/comments/bh04dh/convolutional_neural_networks_in_tensorflow/,lopespm,1556140577,,2,27
226,2019-4-25,2019,4,25,9,bh2fkw,Question about Object Detection..!,https://www.reddit.com/r/deeplearning/comments/bh2fkw/question_about_object_detection/,GW_KIM,1556153731,"Hi, i am studying about object detection and have some question about it.

In Faster RCNN or YOLO, they predict a bounding boxes from training.

And i wonder if the bounding box information is unique along the classes or general along all objects.

In Yolo the predictions are form of S\*S\*(B\*5 +C). (S: grid, C: class probability, B: bounding boxes + confidence)

In the case, do 'B' have information about the class? (such as position or aspect ratio of the object in general scene)",2,3
227,2019-4-25,2019,4,25,16,bh5v5n,Automate the conversion of unstructured data (PDFs) to structured data,https://www.reddit.com/r/deeplearning/comments/bh5v5n/automate_the_conversion_of_unstructured_data_pdfs/,ak96,1556177912," 

Hey!

I  want to build a program which takes PDFs of electronic product  manuals  as input and converts it into structured data. An example of a  product  manual is this: [http://www8.hp.com/h20195/v2/GetDocument.aspx?docname=c05951186](http://www8.hp.com/h20195/v2/GetDocument.aspx?docname=c05951186)

But  it is not necessary that all product manuals will be of the same  format, they may vary based on company and product sub-category. So, how   do I build an AI engine to automate this: whenever a user uploads a  pdf  like this, the program should be able to extract the information  into structured format? How do I go about that and where do I start? I  guess,  it's necessary to use NLP. Any help or advice would be greatly   appreciated.

Thanks",1,6
228,2019-4-25,2019,4,25,17,bh6ax6,Good for remote neural net? Nivada Quadro K5000 ++,https://www.reddit.com/r/deeplearning/comments/bh6ax6/good_for_remote_neural_net_nivada_quadro_k5000/,ErlingStagge,1556182010,,3,2
229,2019-4-25,2019,4,25,18,bh6ka3,Qutoable Quote,https://www.reddit.com/r/deeplearning/comments/bh6ka3/qutoable_quote/,tvganesh,1556184446,[removed],0,1
230,2019-4-25,2019,4,25,18,bh6nji,Quote of the year!,https://www.reddit.com/r/deeplearning/comments/bh6nji/quote_of_the_year/,tvganesh,1556185242,[removed],0,1
231,2019-4-25,2019,4,25,19,bh76tr,Data Science:Data Mining &amp; Natural Language Processing in R,https://www.reddit.com/r/deeplearning/comments/bh76tr/data_sciencedata_mining_natural_language/,systems4facility,1556189564,,0,1
232,2019-4-25,2019,4,25,20,bh7ag2,The Contrast Machine Vs. Deep Learning,https://www.reddit.com/r/deeplearning/comments/bh7ag2/the_contrast_machine_vs_deep_learning/,technewsninja,1556190272,,1,0
233,2019-4-25,2019,4,25,20,bh7jnw,Researchers find a way to reduce CNN training by 31%,https://www.reddit.com/r/deeplearning/comments/bh7jnw/researchers_find_a_way_to_reduce_cnn_training_by/,BettyWaihenya,1556192113,,0,1
234,2019-4-25,2019,4,25,20,bh7p8j,Newly found variations in backpropagation can significantly improve model training,https://www.reddit.com/r/deeplearning/comments/bh7p8j/newly_found_variations_in_backpropagation_can/,BettyWaihenya,1556193186,,0,1
235,2019-4-25,2019,4,25,21,bh84d4,"Deep Learning Newbie, building a PC, considering Amd CPU",https://www.reddit.com/r/deeplearning/comments/bh84d4/deep_learning_newbie_building_a_pc_considering/,Atralb,1556195875,"Hi guys,

&amp;#x200B;

I'm a new player in deep learning and wanted to ask experienced guys in DL who use AMD's products. I have bought an RTX 2070 as GPU. And I am considering getting a 2nd GPU in the future.

I must say as a disclaimer that this is my first time building a Desktop PC. (A friend will be there to help me put it toghether).

So, I had a couple questions I wanted to ask you, if you please. :)  


* I don't really understand when I need ROCm ? Is it only when I use an Amd GPU or also when having an Amd CPU even if my GPU is Nvidia ?  

* Here are prices in my area :  
\- 2600 =&gt; 162 EUR ($180)  
\- 2600X =&gt; 190 EUR ($211)  
\- 2700 =&gt; 223 EUR ($248)  
\- 2600X =&gt; 291 EUR ($323)  
Regarding my GPU and the fact that I want to be able to run a second one, I thought the 2700 was the best deal here, cause 8 cores (I want to be able to do other things while training is processing, like use it as a server, coding, editing some shit). But since I saw that 2 cores were the max amount needed by GPU, do you think 6 cores will be ok with 2 GPU + my additional usages ?And additionally since clock rate is higher on 2600X than 2700, maybe performance would be even better ? What is your take on this ?

Furthermore, am I aiming at the right CPU level regarding my GPU needs ? if I bought a 2080 ti for the second GPU, would it still be ok ?

* I'm quite lost when choosing a Motherboard. Even if I read a lot about PCIe Lanes and such, different storage sockets, I'm hesistating regarding questions like :what the heck are PCIe x16 in 8x or 4x mode ?? Do I have to consider they are simply the latter ?will the 2 gpus fit in the MOBO ?will it also fit with a Noctua fan (like the double Noctua NH-U9 TR4-SP3) ?How much SATA ports do I need (I bought an Evo Plus 970 1TB and want to have at least 10 TB HDD) ?  
Regarding all that, do you think the ROG STRIX B450-F GAMING is a good deal ?  
Indeed if I looked correctly :  
\-  this is the cheapest AM4 Motherboard that has 2 PCIe x16 really acting as x16 (is it right ?), and I want to have x16 for each GPU  
\- The two PCIe x16 seem to be far enough for the two GPUs, what do you think ? ([look at it here](https://c1.neweggimages.com/NeweggImage/ProductImageCompressAll1280/13-119-140-V07.jpg))  
\- I've got M.2 socket for the Evo Plus. Then it says there are 2 SATA slots. I assume buying 2 big 8-10 Tb HDDs will be okay, right ?  
\- It seems to be a pretty good motherboard for the price, according to what I read. Do you confirm ?  


Thanks a lot in advance for your help :)",7,1
236,2019-4-26,2019,4,26,0,bha0th,Inquiry about best deep learning courses using Tensorflow,https://www.reddit.com/r/deeplearning/comments/bha0th/inquiry_about_best_deep_learning_courses_using/,arnavc,1556206417,"I have been doing deep learning since quite a while, but tensorflow still seems too convoluted to learn.
For example I want to build a seq2seq model in tensorflow, I have done my research and understood the architecture, but I have no idea of how to start building it in tensorflow or how the seq2seq models in tensorflow work.
Could anyone please recommend good tutorials/courses/articles for the same?",4,5
237,2019-4-26,2019,4,26,2,bhb5hr,Andrej Karpathy's recipe for training DNNs,https://www.reddit.com/r/deeplearning/comments/bhb5hr/andrej_karpathys_recipe_for_training_dnns/,intvar,1556212178,[https://karpathy.github.io/2019/04/25/recipe/](https://karpathy.github.io/2019/04/25/recipe/),1,70
238,2019-4-26,2019,4,26,2,bhb6js,Crowd Behavior Analysis,https://www.reddit.com/r/deeplearning/comments/bhb6js/crowd_behavior_analysis/,crazy_lazy_life,1556212318,"So I have tried to build a video classification model that will be able to predict from crowd video footages if the crowd behavior is violent/non-violent. I have this github repo up, containing the details. Any suggestion at improvements is highly appreciated. 
https://github.com/crazylazylife/Crowd-Behaviour-Analysis",0,2
239,2019-4-26,2019,4,26,4,bhcgs6,Close Your Eyes and Ill Scan You: Chinese Face Payment System Vulnerabilities,https://www.reddit.com/r/deeplearning/comments/bhcgs6/close_your_eyes_and_ill_scan_you_chinese_face/,gwen0927,1556218942,,0,1
240,2019-4-26,2019,4,26,4,bhcp23,Can anyone recommend a tutorial for segmentation using deep learning?,https://www.reddit.com/r/deeplearning/comments/bhcp23/can_anyone_recommend_a_tutorial_for_segmentation/,mahadmajeed,1556220134,"Hi, I am really a beginner. I have trained some classifiers in keras but that's pretty much it. I am stuck on a segmentation task. I have png masks of the images but I can't find a good tutorial for how to train using this data. Almost all tutorials recommend making JSON labels. Any help in this regard would be much appreciated. Thanks.",2,1
241,2019-4-26,2019,4,26,4,bhcxao,How ro modify the generator of a GAN?,https://www.reddit.com/r/deeplearning/comments/bhcxao/how_ro_modify_the_generator_of_a_gan/,gaurav__1998,1556221360,"How to tell a neural network, while it's training, to emphasize on certain features? Like I want to tell my generator in GAN to generate pictures of a man with black eyes how would I do that?",2,3
242,2019-4-26,2019,4,26,6,bhdz4o,MuseNet,https://www.reddit.com/r/deeplearning/comments/bhdz4o/musenet/,lopespm,1556226788,,0,5
243,2019-4-26,2019,4,26,12,bhhsvd,Deep dreams vs neural style transfer,https://www.reddit.com/r/deeplearning/comments/bhhsvd/deep_dreams_vs_neural_style_transfer/,Believinginself,1556250054,"Hey guys! After attending a lecture about them, I am a bit confused in the 2 terminologies. I thought both are same but the Prof used both differently. Could someone explain the difference in the two. Thanks.",2,3
244,2019-4-26,2019,4,26,14,bhipcx,Convert xml label to csv,https://www.reddit.com/r/deeplearning/comments/bhipcx/convert_xml_label_to_csv/,nicetryho,1556256623,I used labelimg to label my photos. I have the annotations saved in another folder and they are xml format. I need to use these annotations in Keras to do transfer learning with the data. From what I have read the labels need to be in csv format. How can I make this work?,1,2
245,2019-4-26,2019,4,26,18,bhkej2,"Just starting out, Learned Python .. now what?",https://www.reddit.com/r/deeplearning/comments/bhkej2/just_starting_out_learned_python_now_what/,han1337,1556271376,"I am just starting out with Deep Learning.

Till now I invested some time to learn Python3, which was straight forward.

&amp;#x200B;

From what I understand, currently it is looking like TF will get Keras API.

going the PyTorch Route would be the other option.

&amp;#x200B;

I have been looking into the following Courses for my Next Step:

&amp;#x200B;

* ""Deep Learning A-Z: Hands-On Artificial Neural Networks"" Course on Udemy.
*  Machine Learning Certification by Stanford University (Coursera)
*  Deep Learning Certification by [deeplearning.ai](https://deeplearning.ai) (Coursera)

&amp;#x200B;

Which one would you recommend and why, as of this date?

Which of the Courses is more Keras focused?

&amp;#x200B;

I was thinking of concentraing on Keras.

And once TF2 is not in alpha state anymore, looking into that as well.",9,8
246,2019-4-26,2019,4,26,19,bhklca,Build a deep learning image search to find images on the web,https://www.reddit.com/r/deeplearning/comments/bhklca/build_a_deep_learning_image_search_to_find_images/,gv47,1556273023,"I need to build an deep learning image search to find images containing buildings, and ideally use it to search images on the web - is this feasible?

Most examples appear to run the model on their sample training datasets - what is the feasibility of using the web to run the search on?",0,4
247,2019-4-26,2019,4,26,21,bhlz4e,Creating a realistic deepfake with ML,https://www.reddit.com/r/deeplearning/comments/bhlz4e/creating_a_realistic_deepfake_with_ml/,hanyuqn,1556283521,"This is a realistic deepfake I created for Ben Shapiro using my text-to-speech model to synthesise speech and my method for transferring facial expressions:

https://www.youtube.com/watch?v=sgkiS6wUZ98",8,15
248,2019-4-26,2019,4,26,23,bhn8m6,"CPU's got only 24 PCIe lanes, is it problematic for 2 GPUs ?",https://www.reddit.com/r/deeplearning/comments/bhn8m6/cpus_got_only_24_pcie_lanes_is_it_problematic_for/,Atralb,1556290646,"Hu guys,

&amp;#x200B;

So I've bought the AMD Ryzen 7 2700 for my DL rig. I saw that out of its 32 PCIe lanes only 24 are really usable. So I guess, I will be able to use the first GPU with x16 and the other with 8x. (For reference, I'm considering RTX 2070)  


Will it cause performance drops for the second one. I've seen an article where the author explains less PCIe lanes actually only cause little drops in performance (3% from x4 to x16 according to [source](https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/), ""CPU and PCI-Express"" part), but I'm not sure of it.  


What is your view on this matter ?  


Thanks,",0,1
249,2019-4-27,2019,4,27,0,bhnkok,Probability and Information theory Book for deep learning,https://www.reddit.com/r/deeplearning/comments/bhnkok/probability_and_information_theory_book_for_deep/,bikanation,1556292366,Can anybody recommend for me a book where i can learn the needed concepts to complete my deep learning research ? (other than deeplearning book by ian goodfellow),4,3
250,2019-4-27,2019,4,27,1,bho9y0,Interacting with the latent space of an AutoEncoder,https://www.reddit.com/r/deeplearning/comments/bho9y0/interacting_with_the_latent_space_of_an/,HeavyStatus4,1556296011,"I recently made a simple tool for interacting with the latent space of an autoencoder. This helps you to interpret the role played by each neuron at the bottleneck by visualizing the changes in the reconstructed output.

Project : [https://github.com/koulanurag/visTorch](https://github.com/koulanurag/visTorch)

&amp;#x200B;

I hope this could be useful to others as well.",2,25
251,2019-4-27,2019,4,27,4,bhqfui,[D] Im writing a book: Neural Networks with Swift for TensorFlow,https://www.reddit.com/r/deeplearning/comments/bhqfui/d_im_writing_a_book_neural_networks_with_swift/,rahulbhalley,1556307189,,0,0
252,2019-4-27,2019,4,27,6,bhrsn7,Efficient Optimizer,https://www.reddit.com/r/deeplearning/comments/bhrsn7/efficient_optimizer/,ZeroMaxinumXZ,1556314672,I'm looking for an efficient Keras Optimizer for an autoencoder so that I can use it to get the loss between two states of an agent and then use it with the agent to produce curiosity. I just don't want to burn my GPU out. Any suggestions?,3,2
253,2019-4-27,2019,4,27,11,bhufpj,Floating problems in csv dataset,https://www.reddit.com/r/deeplearning/comments/bhufpj/floating_problems_in_csv_dataset/,weberfrases,1556331159,"Hello Friends,
I have a csv dataset that is increasing for minute, but when have new lines, the backward lines like 5.789123 becomes a 5.789129999999999999999

Some help?
Thanks",1,1
254,2019-4-27,2019,4,27,11,bhujoo,How to Create Machine Learning Models Without Code (AutoML),https://www.reddit.com/r/deeplearning/comments/bhujoo/how_to_create_machine_learning_models_without/,tim_macgyver,1556331941,,1,0
255,2019-4-27,2019,4,27,11,bhunzr,"Interested in Artificial Intelligence, Machine Learning, Computer Vision, or NLP? Check out this channel for excellent, well-explained, video tutorials.",https://www.reddit.com/r/deeplearning/comments/bhunzr/interested_in_artificial_intelligence_machine/,DiscoverAI,1556332797,,0,22
256,2019-4-27,2019,4,27,13,bhvbhu,Problem with Generative Adversarial Networks,https://www.reddit.com/r/deeplearning/comments/bhvbhu/problem_with_generative_adversarial_networks/,A01u,1556337676,"Hi, I've just started learning about Generative Adversarial Networks and I created this NN that attempts to generate a parabola. I was wondering if anyone could take a look at my jupyter notebook and tell me why my beginning iteration has my generated data clustered at the minimum of the parabola.

Here is the notebook:

 [https://github.com/Pie31415/GAN/blob/master/Simple%20GAN.ipynb](https://github.com/Pie31415/GAN/blob/master/Simple%20GAN.ipynb)",1,1
257,2019-4-27,2019,4,27,13,bhvoht,[D] Im writing a book: Neural Networks with Swift for TensorFlow,https://www.reddit.com/r/deeplearning/comments/bhvoht/d_im_writing_a_book_neural_networks_with_swift/,rahulbhalley,1556340554,,0,1
258,2019-4-27,2019,4,27,13,bhvpns,PC build thoughts?,https://www.reddit.com/r/deeplearning/comments/bhvpns/pc_build_thoughts/,stronomia,1556340820,"Hi,

&amp;#x200B;

I'm planning to build a PC so that I can start experimenting with deep learning. Here's a build I've finalised:

&amp;#x200B;

PCPartPicker Part List: [https://pcpartpicker.com/list/zd3X8Y](https://pcpartpicker.com/list/zd3X8Y)

&amp;#x200B;

CPU: AMD - Ryzen 7 2700X 3.7 GHz 8-Core Processor  ($292.89 @ OutletPC) 

Motherboard: Gigabyte - B450 AORUS ELITE ATX AM4 Motherboard  ($99.99 @ Amazon) 

Memory: Corsair - Vengeance LPX 16 GB (2 x 8 GB) DDR4-3000 Memory  ($78.99 @ Amazon) 

Storage: Samsung - 860 QVO 1 TB 2.5"" Solid State Drive  ($117.99 @ Amazon) 

Video Card: Gigabyte - GeForce RTX 2080 8 GB WINDFORCE Video Card  ($699.99 @ Amazon) 

&amp;#x200B;

I'm planning to go with a 650W power supply for this, which I think would be more than adequate.

&amp;#x200B;

What do you guys think? I'm primarily going to start my journey by trying to implement some GAN papers, e.g. DTN. Would this be powerful enough?",0,1
259,2019-4-28,2019,4,28,2,bi1g9z,Advanced Deep Learning Courses,https://www.reddit.com/r/deeplearning/comments/bi1g9z/advanced_deep_learning_courses/,Msadat97,1556386410,"A few months ago, I saw this post on Reddit.  
[Ph.D. level courses:](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses/)[ Machine Learning](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses/)  
I am wondering if anyone can mention such courses in deep learning. 

This course from CMU is the course in deep learning I've ever seen.

&amp;#x200B;

[http://deeplearning.cs.cmu.edu/](http://deeplearning.cs.cmu.edu/)",21,35
260,2019-4-28,2019,4,28,6,bi3rci,Creating Bitcoin trading bots that dont lose money using deep RL,https://www.reddit.com/r/deeplearning/comments/bi3rci/creating_bitcoin_trading_bots_that_dont_lose/,notadamking,1556400062,,0,0
261,2019-4-28,2019,4,28,7,bi4av4,How Recurrent Neural Networks Work: An Application and Algorithm-based Approach,https://www.reddit.com/r/deeplearning/comments/bi4av4/how_recurrent_neural_networks_work_an_application/,DiscoverAI,1556403340,,0,3
262,2019-4-28,2019,4,28,7,bi4cuq,Simply Explained: How Neural Networks Work,https://www.reddit.com/r/deeplearning/comments/bi4cuq/simply_explained_how_neural_networks_work/,DiscoverAI,1556403676,,0,2
263,2019-4-28,2019,4,28,7,bi4gfc,How Convolutional Neural Networks Work: An Intuitive Approach,https://www.reddit.com/r/deeplearning/comments/bi4gfc/how_convolutional_neural_networks_work_an/,DiscoverAI,1556404281,,0,0
264,2019-4-28,2019,4,28,7,bi4q1n,Maxima vs Minima and Global vs Local  Derivative Test for finding them,https://www.reddit.com/r/deeplearning/comments/bi4q1n/maxima_vs_minima_and_global_vs_local_derivative/,msminhas93,1556405911,,2,1
265,2019-4-28,2019,4,28,15,bi8d4g,how to make my model smaller?,https://www.reddit.com/r/deeplearning/comments/bi8d4g/how_to_make_my_model_smaller/,dalalaa,1556432237,"I have a yolov3 model for text\_detection, how can I make it smaller enough to run on CPU without retraining?",0,1
266,2019-4-28,2019,4,28,19,bi9xj9,"I have started learning deep learning. I am taking various courses, so should I go for pytorch or tensorflow 2.0?",https://www.reddit.com/r/deeplearning/comments/bi9xj9/i_have_started_learning_deep_learning_i_am_taking/,datavinci,1556447550,"Apologies if already asked, but I wanted latest takes of people on tensorflow 2.0. I heard it is much better than the previous versions. So wanted to get an opinion of experienced people on this.",22,23
267,2019-4-29,2019,4,29,1,bictck,What next ?,https://www.reddit.com/r/deeplearning/comments/bictck/what_next/,smukh98,1556467791,"Hey all,I am a deep learning enthusiast and I have just completed a course on it. I am confused on what to do next. I have heard fee people writing research papers. 

Can you guys help by telling which conferences to look for and how can I get into research field and also instructing how to a write a research paper.

Thanks in advance",7,0
268,2019-4-29,2019,4,29,2,bidq1s,3 Machine Learning Books that Helped me Level Up,https://www.reddit.com/r/deeplearning/comments/bidq1s/3_machine_learning_books_that_helped_me_level_up/,papereraser,1556472890,,1,37
269,2019-4-29,2019,4,29,13,bikxlg,ReWork AI Events in the coming Months - BlockDelta,https://www.reddit.com/r/deeplearning/comments/bikxlg/rework_ai_events_in_the_coming_months_blockdelta/,BlockDelta,1556512609,,0,4
270,2019-4-29,2019,4,29,14,bilpuf,Advice on which cloud to use.,https://www.reddit.com/r/deeplearning/comments/bilpuf/advice_on_which_cloud_to_use/,Pik000,1556515512,"While writing this is seem very obvious what I should do but wondering if anyone can offer advice etc.

&amp;#x200B;

Im currently building a webapp which utilises Google Vision API, which will then store info returned into a database and then use tensorflow serving for a NN that I have coded and return all this data to SaaS backend. The majority of developers that I talk too only really have experience in AWS. My thoughts are to try and stay in GCP due to the API usage but I am unsure if as people have AWS expernice I should just use that and deal with the transfer.

&amp;#x200B;

Any help, comments etc would be great.",3,5
271,2019-4-29,2019,4,29,21,bip75a,30 Frequently asked Deep Learning Interview Questions and Answers,https://www.reddit.com/r/deeplearning/comments/bip75a/30_frequently_asked_deep_learning_interview/,ritesh1928,1556542760,"Deep Learning is one of the fastest growing fields of information technology. It is a set of techniques that permits machines to predict outputs from a layered set of inputs. Deep Learning is being embraced by companies all over the world, and anyone with software and data skills can find numerous job opportunities in this field.",0,0
272,2019-4-29,2019,4,29,23,bipu7x,"A PyTorch implementation of ""Semi-Supervised Graph Classification: A Hierarchical Graph Perspective"" (WWW 2019)",https://www.reddit.com/r/deeplearning/comments/bipu7x/a_pytorch_implementation_of_semisupervised_graph/,benitorosenberg,1556546601,"&amp;#x200B;

https://i.redd.it/hsoze1lhm7v21.jpg

GitHub: [https://github.com/benedekrozemberczki/SEAL-CI](https://github.com/benedekrozemberczki/SEAL-CI)

Paper: [https://arxiv.org/pdf/1904.05003.pdf](https://arxiv.org/pdf/1904.05003.pdf)

Abstract:

Node classification and graph classification are two graph learning  problems that predict the class label of a node and the class label of a  graph respectively. A node of a graph usually represents a real-world  entity, e.g., a user in a social network, or a protein in a  protein-protein interaction network. In this work, we consider a more  challenging but practically useful setting, in which a node itself is a  graph instance. This leads to a hierarchical graph perspective which  arises in many domains such as social network, biological network and  document collection. For example, in a social network, a group of people  with shared interests forms a user group, whereas a number of user  groups are interconnected via interactions or common members. We study  the node classification problem in the hierarchical graph where a \`node'  is a graph instance, e.g., a user group in the above example. As labels  are usually limited in real-world data, we design two novel  semi-supervised solutions named Semi-supervised graph classification via  Cautious/Active Iteration (or SEAL-C/AI in short). SEAL-C/AI adopt an  iterative framework that takes turns to build or update two classifiers,  one working at the graph instance level and the other at the  hierarchical graph level. To simplify the representation of the  hierarchical graph, we propose a novel supervised, self-attentive graph  embedding method called SAGE, which embeds graph instances of arbitrary  size into fixed-length vectors. Through experiments on synthetic data  and Tencent QQ group data, we demonstrate that SEAL-C/AI not only  outperform competing methods by a significant margin in terms of  accuracy/Macro-F1, but also generate meaningful interpretations of the  learned representations.",0,36
273,2019-4-29,2019,4,29,23,biq7x9,Are LSTM RNN still relevant?,https://www.reddit.com/r/deeplearning/comments/biq7x9/are_lstm_rnn_still_relevant/,NikolasTs,1556548744," Hey guys,

I  am relatively new to deep learning and I've mostly worked with CNNs. I  always thought that RNNs are very powerful and that are here to stay,  especially in NLP. However, today I read this article:

[https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0](https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0)

where it basically states that LSTM is not that good today. Is this true?",12,3
274,2019-4-30,2019,4,30,0,biqpy7,Free cloud GPU credits for deep learning,https://www.reddit.com/r/deeplearning/comments/biqpy7/free_cloud_gpu_credits_for_deep_learning/,whitezl0,1556551398,"Hi, I am offering free credits for 1080Ti GPU instances for deep learning purposes.
I am working on [https://www.tensorpad.com/](https://www.tensorpad.com/?utm_source=reddit&amp;utm_campaign=deeplearning)  developing cloud infrastructure for machine learning.
Part of our computational capacity is idle; hence, were offering credits at a free and discounted rate, so that data scientists can benefit from the resources available, and work on neural networks.
Specs:
	16GB of RAM, 4 CPUs, 1080Ti GPU
	JupyterLab environment with access to the terminal
	Pre-installed Tensorflow, Keras, and other ML frameworks (software versions https://docs.tensorpad.com/jobs_env/)
You can access the free credits by signing up ([https://dashboard.tensorpad.com/](https://dashboard.tensorpad.com/signup?utm_source=reddit&amp;utm_campaign=deeplearning) and redeeming ""REDDIT200"" promo code in the Billing tab ([https://dashboard.tensorpad.com/billing](https://dashboard.tensorpad.com/billing?utm_source=reddit&amp;utm_campaign=deeplearning)).
For any questions, please contact us here, through support@tensorpad.com, or the Intercom on the site.",0,1
275,2019-4-30,2019,4,30,0,biqu3p,Medical Images Application,https://www.reddit.com/r/deeplearning/comments/biqu3p/medical_images_application/,rotyweb,1556552002,"Hey,  I wanted to make an application related to dermatology(Find the skin  disease and recommend treatment or dermatologist accordingly). Then I  came across this [dataset](http://www.dermnet.com/dermatology-pictures-skin-disease-pictures/)  which contains all kind of disease images. So is it easy to identify  disease on the basis of just  dataset and  knowledge of CNN???

P.S:I  have worked only on couple of datasets(MNIST, Dog&amp; Cat, CIFAR-10)  and according to me, we just need to tune hyper-parameters, Good ML Algorithm and find good model for our dataset &amp; our work  is done. Am I right or there are other things too in order to train a model and good results??",1,1
276,2019-4-30,2019,4,30,2,birwid,Deep Learning from Scratch to GPU: Momentum,https://www.reddit.com/r/deeplearning/comments/birwid/deep_learning_from_scratch_to_gpu_momentum/,dragandj,1556557403,,0,0
277,2019-4-30,2019,4,30,3,bist8p,Easier to get jobs in production or research side?,https://www.reddit.com/r/deeplearning/comments/bist8p/easier_to_get_jobs_in_production_or_research_side/,74throwaway,1556562053,"I currently work in image processing using Matlab. I have worked with C++ and CNNs in Python briefly before. From what I understand, most DL jobs fall under the production or research side. In the production roles, C++ is more important, whereas in Python/Tensorflow/Keras/Pytorch are more important in the research roles

Since I don't have much work experience, which types of roles should I aim for? I'm guessing it's easier to get hired at large companies. I'm guessing I should aim for the production roles because the research roles are mostly reserved for just PhDs? I only have an MS

So to get a job at a large company, should I focus on improving my C++? Or use my time to work on projects that demonstrate mastery of DL concepts such as using Variational Autoencoders, GANs, Reinforcement Learning, etc?",2,3
278,2019-4-30,2019,4,30,3,bit2ah,"Grokking Deep Learning by Andrew Trask , possible critical errors in chapters 8 and 9 ?",https://www.reddit.com/r/deeplearning/comments/bit2ah/grokking_deep_learning_by_andrew_trask_possible/,webman19,1556563351,"I was planning to buy the deep learning book , but i saw a review on amazon stating about major flaws in code snippets in the 8th chapter and onward where  activation functions have been wrongly written , thus inaccurate conclusions.

I am a novice in deep learning . I want to know if there are any actual merits to his claims. I'll post the  review.

&amp;#x200B;

 Chapter 8.  
1. The very first code snippet is a simple network that learns from MNIST dataset how to decipher handwritten digits. Its test accuracy is \~70% at iteration 349, and this low number is supposed to show how easily neural network overfits. The real problem though is that this low test accuracy is the result of incorrect implementation of the 'relu2deriv' function that is used in backpropagation. With the fixed function, test accuracy of the same network reaches \~82%. Overfitting is still there, but 82% for fairly simple example is not that bad. Unfortunately all other examples in chapter 8 and 9 that use relu and relu2deriv functions use the same erroneous implementation and are not valid.  
2. To reduce overfitting dropout technique is applied. While high level arguments in the books are clear and valid, dropout implementation is problematic on several levels. First of all, dropout example is incomparable to non-dropout one since they have different layout - the hidden layer size was increased from 40 to 100 nodes and iteration count was decreased from 350 to 300. Moreover, the last logged iteration now is 290 instead of 349. For some reason, these changes were not announced in the text. Secondly, even if we compare two performances, the boost of \~10% that a reader can see should be explained as the result of incorrect implementation of 'relu2deriv'. Despite of what text is saying, dropout in this example is just trying to curb effects of that mistake. If you implement relu2deriv correctly, set up hidden layer nodes count to 100 and iterations to 290, you will not see much difference between non-dropout (88.88% peak test accuracy, 87.6% final test accuracy) and dropout versions (88.09% and 87.34% respectively). So either a reader will be misguided by the book's examples to think that dropout gives an enormous boost, or disillusioned, s/he will be left wondering and searching elsewhere what dropout real efficiency is and if this implementation is correct.  
3. Batch example is just plain wrong. The book says that batched network will be updating weights once per batch, but the implementation keeps updating it with each row of input data. What is really perplexing is that the network wouldn't work with such loop logic. Instead of doing the right thing and fixing the latter, the code divides values of layer\_2\_delta by batch size. And still neither accuracy nor speed are improved. If we implement it correctly with the proper looping logic and proper 'relu2deriv' implementation, we will not get much improvements for test accuracy, but training will be done much faster.  
4. So bottom line is that all improvements in chapter 8 were done just to battle the 'original sin' - incorrect 'relu2deriv' function. With this function fixed and increased number of nodes in the hidden layer, the very fist simple network with relu activation function will perform as good as the network with dropout and batching. The only gain was in speed, and only with the properly implemented batching logic. Of course, all this says nothing about how good dropout is or what the real power of batching is - a reader must go and find the answers in some other sources.  
Chapter 9.  
The biggest part of the chapter is the explanation of how different activation functions can be used in different contexts for greater accuracy. While on theoretical level everything looks valid, code implementation is again misleading.  
1. The same as in chapter 8, it uses a divisor when calculating layer\_2\_delta. While in chapter 8 it was necessary because of the incorrect loop implementation, here it is absolutely uncalled for. The loop this time is correct, but divisor is actually became larger since now it's a product of batch size and layer\_2.shape\[0\], or 100\*100 = 10000. Why? No explanation. Also, alpha is set up unusually high as 2. So, in order to fix that, one has to get rid of the divisor and divide alpha by the same value of 10000. Test accuracy will not change (0.8701 at iteration 290), but the network logic will not be dependent on batch size anymore.  
2. Still, whether's it's the book's version or the fixed one, accuracy doesn't go above 87%. It's still less than 88% of 'plain vanilla' relu example, granted that relu2deriv is implemented properly and hidden nodes count is 100. So all the improvements were in vain - and yes, I realize that test accuracy is not the only parameter to look at. But in the book it's a decisive one, and there's no gain in it from more complex tanh/softmax example.  
3. Just out of curiosity I tried to use properly implemented relu/relu2deriv functions in the fixed example, while keeping softmax function in place. This is first time we can see any gain in accuracy. It centers around 89% which is 1% gain to plain vanilla version. 

&amp;#x200B;

&amp;#x200B;

If so please encourage the author to make necessary fixes. Thank you.",2,2
279,2019-4-30,2019,4,30,3,bit5b6,| Free Full-Text | Text Classification Algorithms: A Survey,https://www.reddit.com/r/deeplearning/comments/bit5b6/free_fulltext_text_classification_algorithms_a/,kk7nc,1556563788,,0,1
280,2019-4-30,2019,4,30,7,bivi1l,How is training a CNN using a validation set different from training a basic neural network with hidden layers,https://www.reddit.com/r/deeplearning/comments/bivi1l/how_is_training_a_cnn_using_a_validation_set/,hellomotorcycle,1556575944,"In regards to training for image classification:

How is training using a validation set in CNNs (mini batch gradient descent) different from using a validation set(s) in a neural network

Do they both use k-nearest neighbor or cross validation...etc?  Every time I read about this I get even more confused.",3,1
281,2019-4-30,2019,4,30,9,bix60o,Understanding Convolution in Neural Net,https://www.reddit.com/r/deeplearning/comments/bix60o/understanding_convolution_in_neural_net/,jai00271,1556585786,Convolution Neural Network: Background &amp; Basics https://dev.to/jai00271/background-basics-21bl,0,1
282,2019-4-30,2019,4,30,11,biy03k,State of the art in accurate object tracking &amp; detection,https://www.reddit.com/r/deeplearning/comments/biy03k/state_of_the_art_in_accurate_object_tracking/,throwaway_8320,1556590842,[removed],0,1
283,2019-4-30,2019,4,30,13,biz4sw,Beginner's Deep Dive Into Neural Networks,https://www.reddit.com/r/deeplearning/comments/biz4sw/beginners_deep_dive_into_neural_networks/,MusingEtMachina,1556598309,,0,10
284,2019-4-30,2019,4,30,18,bj155g,"I highly recommend the Cornell University's ""Machine Learning for Intelligent Systems (CS4780/ CS5780)"" course taught by Associate Professor Kilian Q. Weinberger",https://www.reddit.com/r/deeplearning/comments/bj155g/i_highly_recommend_the_cornell_universitys/,aiforworld2,1556615121,,6,25
285,2019-4-30,2019,4,30,19,bj1vjq,Salient Object Detection in the Deep Learning Era: An In-Depth Survey,https://www.reddit.com/r/deeplearning/comments/bj1vjq/salient_object_detection_in_the_deep_learning_era/,HzFU,1556621415,"[https://arxiv.org/abs/1904.09146](https://arxiv.org/abs/1904.09146)

&amp;#x200B;

All the saliency prediction maps, our constructed dataset with annotations, and codes for evaluation are made publicly available at [https://github.com/wenguanwang/SODsurvey](https://github.com/wenguanwang/SODsurvey)

&amp;#x200B;

As an important problem in computer vision, salient object detection (SOD) from images has been attracting an increasing amount of research effort over the years. Recent advances in SOD, not surprisingly, are dominantly led by deep learning-based solutions (named deep SOD) and reflected by hundreds of published papers. To facilitate the in-depth understanding of deep SODs, in this paper we provide a comprehensive survey covering various aspects ranging from algorithm taxonomy to unsolved open issues. In particular, we first review deep SOD algorithms from different perspectives including network architecture, level of supervision, learning paradigm and object/instance level detection. Following that, we summarize existing SOD evaluation datasets and metrics. Then, we carefully compile a thorough benchmark results of SOD methods based on previous work, and provide detailed analysis of the comparison results. Moreover, we study the performance of SOD algorithms under different attributes, which have been barely explored previously, by constructing a novel SOD dataset with rich attribute annotations. We further analyze, for the first time in the field, the robustness and transferability of deep SOD models w.r.t. adversarial attacks. We also look into the influence of input perturbations, and the generalization and hardness of existing SOD datasets. Finally, we discuss several open issues and challenges of SOD, and point out possible research directions in future.",0,2
286,2019-4-30,2019,4,30,20,bj27nk,"[D] How to Build OpenAI's GPT-2: ""The AI That's Too Dangerous to Release""",https://www.reddit.com/r/deeplearning/comments/bj27nk/d_how_to_build_openais_gpt2_the_ai_thats_too/,pirate7777777,1556623930,,0,2
287,2019-4-30,2019,4,30,20,bj2g41,Model interpretation,https://www.reddit.com/r/deeplearning/comments/bj2g41/model_interpretation/,veranceftw,1556625561,"Hello, is there any article with the SoTA of Model interpretation? I was doing some research on this topic and I would like to know if there are any better alternatives to SHAP for image processing models interpretation.   


Kind regards",2,3
288,2019-4-30,2019,4,30,21,bj2n8a,Any recent interesting Gait Research papers?,https://www.reddit.com/r/deeplearning/comments/bj2n8a/any_recent_interesting_gait_research_papers/,supp0rtlife,1556626848,,0,2
289,2019-4-30,2019,4,30,22,bj3l39,Is Dual Fan enough for RTX 2080 used in deep learning ?,https://www.reddit.com/r/deeplearning/comments/bj3l39/is_dual_fan_enough_for_rtx_2080_used_in_deep/,Atralb,1556632466,,10,3
0,2019-5-1,2019,5,1,11,bjbxgk,CodeGym -- Programming Gym Environment,https://www.reddit.com/r/deeplearning/comments/bjbxgk/codegym_programming_gym_environment/,ZeroMaxinumXZ,1556676748,,0,0
1,2019-5-1,2019,5,1,16,bjecg3,Any suggestions to start developing mobile apps and deep learning ?,https://www.reddit.com/r/deeplearning/comments/bjecg3/any_suggestions_to_start_developing_mobile_apps/,ayoubelma,1556695224,,9,3
2,2019-5-1,2019,5,1,16,bjefca,Which semantic segmentation method should beginner start with?,https://www.reddit.com/r/deeplearning/comments/bjefca/which_semantic_segmentation_method_should/,thraway14,1556696043,"I have a little experience with image processing, computer vision, and machine learning. I recently came across how CNNs have been used recently for image segmentation

I'm currently working on a project in which I have a set of very noisy images (around 50 images total) and I want to locate the objects in the image and separate them from the noise/background. So far, I've only used classical image denoising and edge detection methods. It has been difficult to implement this because the images are very noisy and while the larger objects are difficult to detect, there are some small, faint objects that are very difficult to detect unless I use very specific parameters in the classical computer vision methods that I use

If I understand this correctly, I could use CNNs for this problem by augmenting my original set of images (by applying rotations, transformations, etc?) to get a larger training size that is necessary for CNNs, right? Or could I use transfer learning? The images I'm dealing with are proprietary so I can't discuss them in detail here. But the objects in them are not people, dogs, cats, airplanes, or other common objects in the CNN examples I've read about. Also, because I want to detect the objects with better accuracy than just a bounding box, semantic segmentation is what I should look into for this project, right?

I just recently came across GANs, DL Semantic Segmentation (UNets, Mask RCNNs, DeepLab, etc), etc. Which of these should I start with assuming I have only basic knowledge of CNNs and Deep Learning?",6,10
3,2019-5-1,2019,5,1,21,bjgjgo,Word2vec chatbot - how to start?,https://www.reddit.com/r/deeplearning/comments/bjgjgo/word2vec_chatbot_how_to_start/,maik282,1556713954," 

Hey there

I'm working my way into the chatbot topic right now. I already did some projects with rasa nlu and chatterbot.

Now I want to take the next step and want to create one with word2vec or seq2vec. Building my own corpus and train it with either a Reddit or Wikipedia corpus.

Unfortunately, I don't find good readings, tutorials on the internet. My goal is to create my own corpus (FAQ corpus and General information about my university).

Does anyone have some good readings on this topic? And more important, what's the best way to built the corpus?

\- Can I simply put all my answers in a csv?

\- do I need to do question (column A) - answer (column B) in the csv

\- can I put all the information as continuous text in a text file?

\- Is is better to do it the same way as with rasa nlu? with integer and then possible answers?

Thanks a lot for all your answers

Maik282",1,8
4,2019-5-2,2019,5,2,0,bjifbr,Mask RCNN unmasked,https://www.reddit.com/r/deeplearning/comments/bjifbr/mask_rcnn_unmasked/,prakashjay,1556724525,"Hi, We recently wrote a blog post explaining the workings of mask r-cnn. There is a detailed explanation how RPN with FPNs work. Difference between ROI align and ROI pool and how mask branch has evolved over the faster r-cnn framework allowing instance segmentation. 

&amp;#x200B;

[https://medium.com/@fractaldle/mask-r-cnn-unmasked-c029aa2f1296?source=friends\_link&amp;sk=d16a2abf10a3219c33fe85f7bcbd2ed9](https://medium.com/@fractaldle/mask-r-cnn-unmasked-c029aa2f1296?source=friends_link&amp;sk=d16a2abf10a3219c33fe85f7bcbd2ed9)",0,21
5,2019-5-2,2019,5,2,3,bjkkmg,Advice for challenge/project,https://www.reddit.com/r/deeplearning/comments/bjkkmg/advice_for_challengeproject/,MadMenHitBooker,1556734989,"Hi, i'm fairly new to the DL world, i followed many courses online and I understand the basic concept. I would like to play with the DL framework ( tf, pytorch), but  besides most known dataset i can't find a website focusing on DL problems.

Can someone recommend me good challenges with dataset ( kaggle for instance) for practicing ? Thanks.",3,6
6,2019-5-2,2019,5,2,11,bjpsxq,"Interested in Artificial Intelligence, Machine Learning, Computer Vision, or NLP? Check out this channel for excellent, well-explained, video tutorials.",https://www.reddit.com/r/deeplearning/comments/bjpsxq/interested_in_artificial_intelligence_machine/,DiscoverAI,1556764173,,0,0
7,2019-5-2,2019,5,2,23,bjvu0p,"[Project] Tensorflow implementation of ""Handwritten Indic Character Recognition using Capsule Networks"" [ASPCON 2018]",https://www.reddit.com/r/deeplearning/comments/bjvu0p/project_tensorflow_implementation_of_handwritten/,CodeMusicFreak,1556808639,,0,17
8,2019-5-3,2019,5,3,1,bjww1b,Excellent Webinar by Proceedings of the IEEE on Machine Ethics,https://www.reddit.com/r/deeplearning/comments/bjww1b/excellent_webinar_by_proceedings_of_the_ieee_on/,aiforworld2,1556814154,,0,0
9,2019-5-3,2019,5,3,2,bjxcey,Blockchain and AI - A Match Made in Heaven. BlockDelta,https://www.reddit.com/r/deeplearning/comments/bjxcey/blockchain_and_ai_a_match_made_in_heaven/,BlockDelta,1556816481,,1,0
10,2019-5-3,2019,5,3,2,bjxl61,"AI @Facebook F8 | Self-Supervision, Fairness, Inclusivity and PyTorch 1.1",https://www.reddit.com/r/deeplearning/comments/bjxl61/ai_facebook_f8_selfsupervision_fairness/,Yuqing7,1556817713," Still reeling from a string of damaging news reports accusing it of misinformation, data abuse and violent content; Facebook is hoping its recent AI R&amp;D efforts can help it climb out of the mess its in.

On the second day of its annual F8 developer conference, executives from the social media giant framed AI as a weapon in Facebooks battle against objectionable content. **Our goal is to reduce the prevalence by taking action on violent content proactively with few minutes**, said Facebook CTO Mike Schroepfer.

Link: [https://medium.com/syncedreview/ai-facebook-f8-self-supervision-fairness-inclusivity-and-pytorch-1-1-3951ce45872a](https://medium.com/syncedreview/ai-facebook-f8-self-supervision-fairness-inclusivity-and-pytorch-1-1-3951ce45872a)",0,2
11,2019-5-3,2019,5,3,2,bjxry6,The discipline of Machine Learning,https://www.reddit.com/r/deeplearning/comments/bjxry6/the_discipline_of_machine_learning/,aiforworld2,1556818710,,2,1
12,2019-5-3,2019,5,3,3,bjyoe0,argmax from probability distribution better policy than random sampling from softmax ?,https://www.reddit.com/r/deeplearning/comments/bjyoe0/argmax_from_probability_distribution_better/,samistark86,1556823457," 

Background : I am trying to train Echo State Network for text generation with stochastic optimization using one of the Reinforcement approach, where the optimization depends on the reward signal.

The important question : I have observed that during evaluation, when I sample from the probability distribution, the bleu score is greater. But when I argmax from the distribution, the score is less. I am not sure why does that happen. 

Help needed.",3,8
13,2019-5-3,2019,5,3,5,bjzg40,AI theory and research,https://www.reddit.com/r/deeplearning/comments/bjzg40/ai_theory_and_research/,slayerxor,1556827547,"Hi all. I am coming from a management background and I am interested in the applications of AI in the field of HR and managing people. I have some statistics knowledge, mainly descriptive. I've also done courses of techniques like linear and logistic regression on R, without going much into the theory of it. Right now I am writing my master thesis project on AI and its application in the HR field, as I am doing so my interest and appetite for ML and DL is growing by the day. I am even thinking on doing a PhD and contributing to the field myself.
My interest led me to the course given in Stanford by Andrew Ng. My question is the following, are the lectures given by Andrew enough for me to fully grasp the state of the art of ML and will I be able to do research of my own after completing the course given by him. If not then I'd gladly ask for your instructions as to where should I head in order to achieve my goal.
Thank you all.",2,1
14,2019-5-3,2019,5,3,14,bk4xud,Downloading model weights on baidu,https://www.reddit.com/r/deeplearning/comments/bk4xud/downloading_model_weights_on_baidu/,Appropriate_Pain,1556862197,Can anyone help me with downloading model weights from baidu? I am trying different face detection algorithms and one github implementation has weights which are saved in baidu so I am not able to test it.,1,11
15,2019-5-3,2019,5,3,22,bk8ga7,How to Train GPT-2 model from scratch,https://www.reddit.com/r/deeplearning/comments/bk8ga7/how_to_train_gpt2_model_from_scratch/,Vaiku2718,1556889847,I want to train the model from scratch on my own corpus which is in another language.Pls any guidance towards this would be of great help.,4,5
16,2019-5-4,2019,5,4,0,bk9swp,Building first pc for deep learning. At a loss regarding AMD VS Intel CPUs,https://www.reddit.com/r/deeplearning/comments/bk9swp/building_first_pc_for_deep_learning_at_a_loss/,Atralb,1556897576,"Hi, so I'm building a DL rig for \~2k. I was a complete hardware virgin 3 weeks ago. Since then I read A LOT. Anything I can find on the internet, articles, Reddit (any related subs \^\^), pcpartpicker, specifications and manuals of dozens of Mobos and cpus. I read all I could find on PCIe lanes, CPU usage in DL, storage needs, ram needs, etc....  


I saw a lot of people recommending to have x16 PCIe lanes per GPU and I saw all the benchmarks I could find on this ([Tim Detters](https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/), [Puget Systems (gaming perfs)](https://www.pugetsystems.com/labs/articles/Impact-of-PCI-E-Speed-on-Gaming-Performance-518/), people on reddit) which tell about 5-10% difference in perfs on average.  


Since I want to be able to at least run 2 GPUs at full working load, and a lot of people recommend the Threadripper for its 64 PCIe lanes (e.g. [Jeff Chen](https://medium.com/the-mission/how-to-build-the-perfect-deep-learning-computer-and-save-thousands-of-dollars-9ec3b2eb4ce2)) I thought it was a good idea even if I only want 2 (which would be 2x16+4 for NVMe SSD = 36 PCIe lanes) cause Ryzen CPUs only got 24 lanes usable and Intel CPU with more than 16 PCIe lanes are far more expensive afaik except for old generations ones (but I'll be glad to be proven wrong on that, I don't know much about intel cpus since there so many...).  


However I just saw this post yesterday on r/nvidia : [deep\_learning\_2080ti\_slower\_than\_2080](https://www.reddit.com/r/nvidia/comments/bccbsz/deep_learning_2080ti_slower_than_2080/) where a guy has two rigs, one with 2080 and i7 8700 and on the other 2080Ti with Threadripper 1920X. And people were saying that performance was better in the first rig cause ""8700 is significantly faster in single thread, and most gpu acceleration is single thread"".   


So now I'm completely lost as to if my choice of Threadripper is maybe actually overkill if I can only afford 2 GPUs and maybe an Intel even with 8x PCIe on each would give better performances. Can you help me ? And if you go for Intel could you give me some insight among the legion of CPUs they offer.  


Thanks a lot !",14,23
17,2019-5-4,2019,5,4,6,bkdud8,Gradient Descent Optimization [Part 1],https://www.reddit.com/r/deeplearning/comments/bkdud8/gradient_descent_optimization_part_1/,msminhas93,1556919567,,0,16
18,2019-5-4,2019,5,4,12,bkh2kj,"Face image to variants (age, gender, etc), what's the correct keyword for this?",https://www.reddit.com/r/deeplearning/comments/bkh2kj/face_image_to_variants_age_gender_etc_whats_the/,kwhali,1556940830,"I'm not sure if this is the right sub-reddit to be asking about this, if not and you know the appropriate one please point me to that :)

I'm familiar with the topic a little, but no actual experience using TensorFlow/Keras for GANs(which I think might be what this title is referring to with image2image, pix2pix, something like that; that iirc are based off GANs). I am a generalist developer, so if I could find the information(or preferably a repo, additionally with a trained network already provided), that'd be enough to take it from there.

I'm not sure what keywords to use to find this type of generator. Mostly ends up with classifiers as results. I've seen a few services on social platforms that request your social account details in exchange for rendering you at differing ages, gender, ethnicity, etc. 

I'd rather not provide that, and figure someone may have already published such as open-source on Github? Those services may even be using exactly that. Any advice on what the appropriate keywords would be to search for such? Or if you know of an existing project already that you could point me to directly?",3,2
19,2019-5-4,2019,5,4,12,bkh4vx,"Interested in Artificial Intelligence, Machine Learning, Computer Vision, or NLP? Check out this channel for excellent, well-explained, video tutorials.",https://www.reddit.com/r/deeplearning/comments/bkh4vx/interested_in_artificial_intelligence_machine/,DiscoverAI,1556941335,,0,0
20,2019-5-5,2019,5,5,9,bkrwxx,"Different Approaches to NNs, CNNs, RNNs, etc.",https://www.reddit.com/r/deeplearning/comments/bkrwxx/different_approaches_to_nns_cnns_rnns_etc/,ZeroMaxinumXZ,1557017201,"Basically, I'm looking for a different approach besides your usual CNN or RNN for deep reinforcement learning. What should I use  for the task of reinforcement learning? Spiking NNs seem hard to implement in Tensorflow for reinforcement learning, much less supervised learning due to the whole ""no backpropogation"" thing... I'm looking for any different methods or recommendations for deep reinforcement learning, Thanks.",10,10
21,2019-5-5,2019,5,5,11,bkspkr,Gradient Descent Optimization [Part 2],https://www.reddit.com/r/deeplearning/comments/bkspkr/gradient_descent_optimization_part_2/,msminhas93,1557022565," In this post I take specific 1D and 2D examples to explain how the algorithm works. The post has a link to an interactive utility which allows you to change the learning rate, start point and number of iterations to see how those affect the convergence of the algorithm.

https://expoundai.wordpress.com/2019/05/04/gradient-descent-optimization-part-2/",0,13
22,2019-5-5,2019,5,5,20,bkwse8,"Deep Learning: Master Powerful Deep Learning Tools in R Like Keras, Mxnet, H2O and Others",https://www.reddit.com/r/deeplearning/comments/bkwse8/deep_learning_master_powerful_deep_learning_tools/,dailydeal2019,1557056397,,0,1
23,2019-5-6,2019,5,6,3,bl187g,Grab bag of Neural Network Goodies,https://www.reddit.com/r/deeplearning/comments/bl187g/grab_bag_of_neural_network_goodies/,MusingEtMachina,1557081155,,0,15
24,2019-5-6,2019,5,6,5,bl2j4j,Neural Network,https://www.reddit.com/r/deeplearning/comments/bl2j4j/neural_network/,rotyweb,1557087711," Please answer or provide the link for the following.

Different types of Multilayer feed forward Networks with architecture diagrams

Example to explain the use of multilayer networks in the real world",1,0
25,2019-5-6,2019,5,6,7,bl3xq2,Any Good Bayesian NN Tutorials for TF?,https://www.reddit.com/r/deeplearning/comments/bl3xq2/any_good_bayesian_nn_tutorials_for_tf/,ZeroMaxinumXZ,1557095138,"I'm trying to create a deep q network with some Bayesian layers, but I honestly don't know how to create a Bayesian neural network in TF, could anyone please point me in the right direction to go for this? Any good tutorials/resources would be helpful.q",1,3
26,2019-5-6,2019,5,6,9,bl58mq,"New to CNNs, getting 100% training and validation accuracy?",https://www.reddit.com/r/deeplearning/comments/bl58mq/new_to_cnns_getting_100_training_and_validation/,thenerdbutton,1557102716,"I'm pretty new to using CNNs (I understand the concepts and did the MNIST example with Keras). I'm currently working on a Kaggle dataset with images of parasitized and uninfected cells. I'm basically resizing a bunch of RGB images into 32x32, training a CNN on ~22000 of them and then testing it on the remaining ~5000.

Somehow, I'm getting 100% accuracy on both the training and test sets which I understand is the goal, but also seems really fishy for literally the first time I trained and tested the model. For context, my batch size is 128 and I ran through the entire dataset once. 

I'm randomizing the order using:

idx = np.random.permutation(len(data))
print(idx)
data, labels = data[idx], labels[idx]

and a printout of it seems to show it works.

Could this still be the issue? Or perhaps something about the dataset having equal numbers of parasitized and uninfected cells (the two classes)? What else can cause this? Or should I just accept that it worked?

I know this is a weird question but I'd really appreciate any help. Thanks!",3,2
27,2019-5-6,2019,5,6,12,bl6zpc,OPENCV Kickstarter Campaign,https://www.reddit.com/r/deeplearning/comments/bl6zpc/opencv_kickstarter_campaign/,spmallick,1557113505,"Dear Friends,   
We at OpenCV.org will launch a Kickstarter campaign in about a week for three courses

1. Computer Vision I: Introduction
2. Computer Vision II: Applications 
3. Deep Learning with PyTorch

Please sign up below to stay informed:  
[https://opencv.org/courses](https://opencv.org/courses?fbclid=IwAR09uJ6A2xS5KmeBb0xiPVPlmhyOV9yoywObXtPFUVKGZoQ13s2nQ6HMPQ4)

We need your help to spread the word. Please share this with your friends and colleagues.   
Many thanks,

Satya Mallick &amp; Gary Bradski

![video](odfsrju9giw21)",5,40
28,2019-5-6,2019,5,6,12,bl78ru,Guide: How to setup the Coral Dev Board using Windows only,https://www.reddit.com/r/deeplearning/comments/bl78ru/guide_how_to_setup_the_coral_dev_board_using/,23f34ef32,1557115155,,0,1
29,2019-5-6,2019,5,6,17,bl99x7,"[R] A PyTorch implementation of ""MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing"" (ICML 2019)",https://www.reddit.com/r/deeplearning/comments/bl99x7/r_a_pytorch_implementation_of_mixhop_higherorder/,benitorosenberg,1557129809,"&amp;#x200B;

*Processing img l3nd40iqsjw21...*

GitHub: [https://github.com/benedekrozemberczki/MixHop-and-N-GCN](https://github.com/benedekrozemberczki/MixHop-and-N-GCN)

Paper: [https://arxiv.org/pdf/1905.00067.pdf](https://arxiv.org/pdf/1905.00067.pdf)

Abstract:

Recent  methods generalize convolutional layers from Euclidean domains to   graph-structured data by approximating the eigenbasis of the graph   Laplacian. The computationally-efficient and broadly-used Graph ConvNet   of Kipf &amp; Welling, over-simplifies the approximation, effectively   rendering graph convolution as a neighborhood-averaging operator. This   simplification restricts the model from learning delta operators, the   very premise of the graph Laplacian.  In this work, we propose a new   Graph Convolutional layer which mixes multiple powers of the adjacency   matrix, allowing it to learn delta operators. Our layer exhibits the   same memory footprint and computational complexity as a GCN. We   illustrate the strength of our proposed layer on both synthetic graph   datasets, and on several real-world citation graphs, setting the record   state-of-the-art on Pubmed.",0,1
30,2019-5-6,2019,5,6,17,bl9cpo,A phrase/word classifier model on Tensorflow,https://www.reddit.com/r/deeplearning/comments/bl9cpo/a_phraseword_classifier_model_on_tensorflow/,ak96,1557130416,"I am trying to build a classification model on Tensorflow which should classify the phrases/words from a PDF as category A or category B. So, I build an initial dataset of both categories and then the TF model should parse the document and extract the words/phrases (n-grams) it encounters into the list of category A or category B. How do I do this? Any help would be greatly appreciated.",1,1
31,2019-5-6,2019,5,6,20,blaz84,What Deep Learning is and isn't,https://www.reddit.com/r/deeplearning/comments/blaz84/what_deep_learning_is_and_isnt/,TheTesseractAcademy,1557142313,,0,1
32,2019-5-6,2019,5,6,22,blc5e5,deep learning project management,https://www.reddit.com/r/deeplearning/comments/blc5e5/deep_learning_project_management/,analystanand,1557149110,"Hi
   I am going through few open source to automate the experiment tracking and deployment for our companies task.

I found 2 interesting projects

1. MLFLOW
2. POLYAXON

Please let me know which one is better and why?

I particularly find polyaxon more scalable and intuitive to use and scale. Where as MLFLOW is backed by data bricks.",0,6
33,2019-5-6,2019,5,6,22,blc8fz,Ordering of color augmentations,https://www.reddit.com/r/deeplearning/comments/blc8fz/ordering_of_color_augmentations/,life_vortex,1557149564,"&gt;There can be random augmentations made to brightness, saturation, contrast, hue and saturation

Can they be done in any order, or is there a specific order in which they must be done to be sensible.",1,1
34,2019-5-6,2019,5,6,22,blcee0,what is tf.nn.l2_normalize do?,https://www.reddit.com/r/deeplearning/comments/blcee0/what_is_tfnnl2_normalize_do/,begooboi,1557150493,"In calculating attention this code uses `tf.nn.l2_normalize(output, dim=1)` What is it? Is this batch normalizaton? I have heard about l1 and l2 loss do they have anything in common?

    def attention(self, query, key, value):
        # Equation 1 in Vaswani et al. (2017)
        # 	Scaled dot product between Query and Keys
        output = tf.matmul(query, key, transpose_b=True) / (tf.cast(tf.shape(query)[2], tf.float32) ** 0.5)
        # 	Softmax to get attention weights
        attention_weights = tf.nn.softmax(output)
        # 	Multiply weights by Values
        weighted_sum = tf.matmul(attention_weights, value)
        # Following Figure 1 and Section 3.1 in Vaswani et al. (2017)
        # 	Residual connection ie. add weighted sum to original query
        output = weighted_sum + query
        # 	Layer normalization
        output = tf.nn.l2_normalize(output, dim=1)
        return output, attention_weights",0,1
35,2019-5-6,2019,5,6,23,blcovx,Why RNNs are turing complete but different RNN variants give different performance?,https://www.reddit.com/r/deeplearning/comments/blcovx/why_rnns_are_turing_complete_but_different_rnn/,Catherine_Fang,1557152014,"As we know, RNNs are turing complete. But why raw RNN, LSTM have different accuracy for a certain dataset?

Does RNN variants suppose more assumptions and then reduce the parameter space?

And is it possible to find an equivalent RNN for an arbitrary RNN variant, if we can search over all parameter space?",0,1
36,2019-5-6,2019,5,6,23,blcow4,Learning about Transformer,https://www.reddit.com/r/deeplearning/comments/blcow4/learning_about_transformer/,visvats,1557152015,Check out @VVatsalyas Tweet: https://twitter.com/VVatsalya/status/1125393111499198465?s=09,0,0
37,2019-5-7,2019,5,7,1,blej58,Deep Reinforcement Learning tutorial series,https://www.reddit.com/r/deeplearning/comments/blej58/deep_reinforcement_learning_tutorial_series/,S_T47,1557161261,,1,6
38,2019-5-7,2019,5,7,4,blge1q,"ICLR 2019 | MILA, Microsoft, and MIT Share Best Paper Honours",https://www.reddit.com/r/deeplearning/comments/blge1q/iclr_2019_mila_microsoft_and_mit_share_best_paper/,Yuqing7,1557170381,,3,26
39,2019-5-7,2019,5,7,6,blhrm2,Virtual Machine Mouse Gym Environment,https://www.reddit.com/r/deeplearning/comments/blhrm2/virtual_machine_mouse_gym_environment/,ZeroMaxinumXZ,1557177128,"I'm wanting to build kind of an gym environment for mouse navigation in a VM but I don't know if there's something similar. I know there's OpenAI Universe but it is deprecated...

So, is there anything similar to what Im wanting to build, that isn't deprecated and dead?",1,2
40,2019-5-7,2019,5,7,16,blnly1,Artificial Intelligence Engines,https://www.reddit.com/r/deeplearning/comments/blnly1/artificial_intelligence_engines/,aiforworld2,1557212937,,0,3
41,2019-5-7,2019,5,7,18,blohe1,Understand objective functions in deep learning,https://www.reddit.com/r/deeplearning/comments/blohe1/understand_objective_functions_in_deep_learning/,mQuBits,1557220462,,0,34
42,2019-5-7,2019,5,7,19,blp683,Question about face recognition,https://www.reddit.com/r/deeplearning/comments/blp683/question_about_face_recognition/,Smaug4,1557225856,"Hey guys, I want to train a NN for recognizing my own face. I have a question about the training data. The current method I am using consist on using  a public face dataset (Faces in the wild) as the negative label and photos of my own face as the positive label. Do you think it's the correct approach?",3,2
43,2019-5-8,2019,5,8,1,blsim2,How to learn deep learning?,https://www.reddit.com/r/deeplearning/comments/blsim2/how_to_learn_deep_learning/,fiddellydiddlley,1557245228,What path would you suggest for someone who has only basic programming knowledge and would like to be competent as quickly and easily as possible?,5,2
44,2019-5-8,2019,5,8,1,blsndx,Deep Learning With Python - Informative Tutorial,https://www.reddit.com/r/deeplearning/comments/blsndx/deep_learning_with_python_informative_tutorial/,MainBuilder,1557245894,,0,0
45,2019-5-8,2019,5,8,1,blsti6,visual tracking surveys,https://www.reddit.com/r/deeplearning/comments/blsti6/visual_tracking_surveys/,plusgarbage,1557246733,"hi to all, could you propose me some surveys concerning the visual tracking which explains the state-of-the-art of deep learning metods for the appearance model of the target?",0,1
46,2019-5-8,2019,5,8,2,bltfbk,"Creating A Transcendental Platform For For Ascension-Deep Learning, Mind-Blowing Revelations About Earth-Life, Cognitive Enhancement, Lucid Dreaming Hybrid Mindset Voyagers 24/7, Psy-Intuitive Weavesilk Art, Starseeds, Otherkin, Mediums &amp; Psychics,, Dimension-Shifters, Future Earth(+Discord)",https://www.reddit.com/r/deeplearning/comments/bltfbk/creating_a_transcendental_platform_for_for/,PerfectStormX,1557249659,"Expand your mind and thrive on your path, boost creative potentials! We provide optimal pointers and revelations that can change your life.Overcome and transmute, to transcendental rage/fire/passion, optimal energetic grounds provided.

 [https://www.reddit.com/r/LightWarriorAscension/](https://www.reddit.com/r/LightWarriorAscension/)

 [https://discord.gg/PRVXJak](https://discord.gg/PRVXJak) 

 [https://disboard.org/server/539367976806383616](https://disboard.org/server/539367976806383616)

&amp;#x200B;

[Planetary Rainbow Forge](https://i.redd.it/denhtj16ptw21.jpg)

Comprehensive Introductory Information To The Community, Discord Server And Internal Chatrooms/Mission Objective On Gaia:

&amp;#x200B;

At the shift of ages, and the arrival of the age of Aquarius, golden age as we battle the last inner and outer demons of the Kali Yuga/age of Pisces, this transition time is like no other. A powerful incentive, a leap of faith: Take the first step: make the Quantum Leap, The Interdimensional Shift and Enter The Lightning Grid

&amp;#x200B;

\-Psychic tools, trainings, intent, purpose documentations, pantheon and mentorship/guidance for otherkin and humans alike: All-in-One.

Free Speech, Absolute Tolerance for Mutual Respect and Natural Equality ( circles of responsibility but nonhierarchy).

Diverse Environment, rapidly expanding, work in progress pantheon for the golden age with widest assortments of deities helping out. Friendly and Helpful staff whose best interest is to serve your growth and cooperate on creative works/your development.

 Knowledge on esoteric/transcendental topics generally not discussed/shunned/overlooked/disregarded/labeled as forbidden or far-fetched knowledge by others (metaphysics-spirit science, free energy, universal law, light body process, central nervous system rewiring, DNA-upgrade, cosmic origin, obscure(d) truths, connected dots and converging rivers).

a massive\* self-role assign \*system has been implemented to the server. - With  16 tag/label aspect categories and almost 200 roles taking themes centered around cosmic soular origins into consideration, diversity is maxed out for this platform.

\-""Convert""-friendly- encouraging ex-religious ones for the One-Source path of the truth-seeker lightwarriors/workers/starseeds/otherkin/enlightened human old or mature souls(motto: strength in unity, collaboration versus illusion of separation)

\-Various high-quality reddit/youtube/no-nonsense channeling websites/ news/video post feeds ( of spiritual/esoteric/cosmic theme)

\-Weavesilk avantgarde spirit-art. (Interactive generative art- subliminal, angelic/demonic/divine, spiritual source channeling and through the higher aspects of self outside of the boundaries of the human psyche box/confines. - Surreal, intricate shapes including the semblance of elements of Gothic dark fantasy, with multiple meanings will be created on the screen and you will recognize your ability to master your soul-mind interaction as well, as I fill the screen with this magical stream of thoughts with a natural flow.)

\-Soul ScienceTechnology &amp; Source Transmissions. Logos God, Elohim, Doctor, Scientist, &amp; Architect Of The Age Of Aquarius. 

\-Multiversal Starseed Community. Come join your star families and twin souls, or otherwise join and commune on the older site with archived content in the interim period 

\-Soul technology/higher-self descent to physical vessel: Production of DMT internally without the use of  physical substance and unlock spirit molecule

\-Sections encouraging to showcase your work (media/documents/arts, personal photos)

\-A place of unconditional love and growth for Starseeds, Indigos, Human Angels and Walk Ins' to reunite with their long lost Star Family and Soul Mates.

\-Server voice chat option for those interested

\-Server map for ease of access with descriptions and guidelines for each topic (accessibility)

Our own e-literature (growing library of PDF e-books and Links), videos, (multi)media and psychic tools, image-works not available anywhere else and written/crafted/made/authored exclusively by us.

\-Mainstream launch Mid-February with over 750 members and counting

\-Various integrated bots to fulfill all your mystic/astrology/horoscope-occult reading needs

\-Logos God, Elohim, Doctor, Scientist, &amp; Architect Of The Age Of Aquarius.

\-Futuristic &amp; Future-Oriented Community Dedicated To The Universal Law, Spirit Science, Soul Technologies and Extraterrestrial Soul Origins

\-A joint planetwide effort for reconstructing the new pantheon for the golden age of Aquarius, fusing the ancient with the new influx past with the future to create the new present in the Now with the help of deities and entities of various origins. Spirituality, lightworkers, ascension. 

&amp;#x200B;

We are highly focused and streamlined, yet loose and flexible (effortless effort being the motto). Our basic aim-quintessence is to harness all available energies to create an interdimensional rift/gate to haven that can propel us to 5th dimension and beyond while still connected to Earth but ultimately undergoing physical transfiguration, also fueled by the bowels of the earth likewise (as above so below)- which constructs a beastly cyclotron that irons out certain unwanted specific frequency-sets, diminishes their influence on the collective.

&amp;#x200B;

""As soon as humanity unites on this planet, it will qualify to establish contact with other more advanced civilizations, such as the Agarthans and those from the GF. In fact the Agarthans and some ascended masters such as St. Germain will already help us run the cities of light and the numerous healing centres which will manifest very soon all over the globe. The next step will be visiting other civilizations, but this could only happen after the incarnated human personality has completed the LBP and has ascended at least to 5D by transfiguring from a carbon-based body into crystalline light body.""

The three cities of light will be open portals to the multiverse and to numerous advanced humanoid, and later on, other civilisations, such as the dragons. Alone this fact will make the existence of national states and nations obsolete as all the people will recognize their multidimensional nature and will strive to ascend too and be able to live in these cities of light and enjoy the advantages of a higher dimensional life. In the first place, they will enjoy the healing possibilities there which will help all humans advance rapidly in their LBP and also ascend.

(Source: [http://www.stankovuniversallaw.com](http://www.stankovuniversallaw.com))

&amp;#x200B;

""You see, nothing is ever just about one thing. We are not just sharing information with you. We are also preparing you for contact. Now, all of the other beings from the other star systems that are connecting with you all through the various channels that you have there on Earth are doing the same thing. And certainly those who channel faeries are readying you for more interactions with the fae.""

""We are excited to witness the coming together of humanity and the Arcturian beings that you will be meeting in the flesh. Now, of course, some have already established connections with physical Arcturian beings.  A full and open contact with the fourth and fifth dimensional beings who are from our little star system.""

(Source: [www.danielscranton.com](https://www.danielscranton.com) )

&amp;#x200B;

Keywords: spirituality, starseeds, occult, esoteric, lightworker, light warrior, spiritual awakening, light body, soul technology, quantum, lucid dreaming, astral projection, psychic, chaos magic, otherkin, bilocation, golden age, mentor, indigo, crystalline, human angels, transliminal souls, walk-ins, lucid dream, mental projection, multilocation",10,0
47,2019-5-8,2019,5,8,2,bltqde,Objective functions in deep learning,https://www.reddit.com/r/deeplearning/comments/bltqde/objective_functions_in_deep_learning/,mQuBits,1557251148,,0,3
48,2019-5-8,2019,5,8,4,blv8ea,Enlarging Labeled Handwritten Character Datasets With Capsule Networks,https://www.reddit.com/r/deeplearning/comments/blv8ea/enlarging_labeled_handwritten_character_datasets/,Yuqing7,1557258424,,0,1
49,2019-5-8,2019,5,8,6,blwp34,How to create a model for multiplee classsification in Keras python?,https://www.reddit.com/r/deeplearning/comments/blwp34/how_to_create_a_model_for_multiplee/,connect2robiul,1557265550,"I have 390 row and 286 attribute with 26 class. I use weka SVM and got some result. I  want to improve my result with deep learning methods. Now how to do that? 

Class : 26 

Row : 390 

attribute : 286",1,1
50,2019-5-8,2019,5,8,8,bly2mf,Graph and node embedding for recommendation,https://www.reddit.com/r/deeplearning/comments/bly2mf/graph_and_node_embedding_for_recommendation/,Il_Yeahs,1557272677,"Hi guys,

I want to build a recommendation system using deep learning and embedding approach, but still I don't know where to start, I have a data set with 3 files : user-item rating(1  5), user-user trust, and item categories.

I want to build a graph embedding network to represent the users and items in an embedded space such that the product of user-item embedding vectors gives me an estimation of the rating, can someone tell me how can I do that ?",1,6
51,2019-5-8,2019,5,8,12,bm0cp0,Seeking Your Suggestions &amp; Critiques on Quad GPU Deep Learning Build,https://www.reddit.com/r/deeplearning/comments/bm0cp0/seeking_your_suggestions_critiques_on_quad_gpu/,songanddanceman,1557286045,"Hi Community,

I am interested in building a desktop to conduct Deep Learning over multiple GPUs. 

Some background: I currently use Keras with a TensorFlow backend and emphasize convolutional neural networks. I know that PyTorch uses MKL for numpy acceleration, so Intel CPUs are sometimes preferred  for that reason when using PyTorch. Because I am using TensorFlow, I am leaning toward AMD's threadripper line due to high thread count and number of PCIe lanes. 

I have a tentative parts list created, but wanted to get your thoughts:
[Part list (Final Build will have 2 additional GPUs](https://pcpartpicker.com/list/nKKG9J)

Here are the main points, and my reasoning. Please let me know if there are any choices you support, and please correct me if I misunderstand pros/cons, or you have a strong preference on an aspect. I just here to try to learn from your experience.

* Processor: [AMD - Threadripper 2990WX 3 GHz 32-Core Processor](https://en.wikichip.org/wiki/amd/ryzen_threadripper/2990wx) (Offers 60 PCIe lanes, Enough for 4 GPUs at 8x and for PCIe Storage; Emphasis on high thread count for better parallel CPU-based preprocessing, despite worse single thread performance compared to i9s)
* [Motherboard: ASRock - X399 Taichi ATX](https://www.asrock.com/mb/AMD/X399%20Taichi/index.asp): PCIe slot spacing should allow for 4 dual slot cards with support for up to 128 GB of RAM (8 slots). Also has 3 M.2 slots
* GPUs: [4 EVGA 1080tis](https://www.evga.com/products/specs/gpu.aspx?pn=1190fbf7-7f11-465d-b303-cab0e50fbdc6) (I hear that blower style is preferred for multi GPU systems, but I also hear that large cases can mitigate the issue with non-blower cards)
* Memory: G.Skill - Ripjaws V Series 32 GB (2 x 16 GB) DDR4-3000 Memory (32 GB to start, but can increase the amount up to 128GB
* Storage: Samsung - 970 Evo 1 TB M.2-2280 Solid State Drive (For the primary drive. M.2 for increased speeds vs. SATA)
* Secondary Storage: Seagate  4 TB 3.5"" 5400RPM Internal Hard Drive (For additional space to keep data when not being trained
* Power Supply: [EVGA - SuperNOVA G2 1600 W](https://www.evga.com/products/product.aspx?pn=120-G2-1600-X1) (4 1080ti max power = 1000W + AMD threadripper at 250W)
* Cooling: [Noctua CPU Cooler](https://noctua.at/en/nh-u12s-tr4-sp3)

Are these reasonable specifications?",11,11
52,2019-5-8,2019,5,8,12,bm0eii,What could be possible reasons that my gan model produces same samples but with random noise as input?,https://www.reddit.com/r/deeplearning/comments/bm0eii/what_could_be_possible_reasons_that_my_gan_model/,Al_Pale,1557286370,[removed],0,1
53,2019-5-8,2019,5,8,16,bm2c2o,[need] deep RL for chatbots,https://www.reddit.com/r/deeplearning/comments/bm2c2o/need_deep_rl_for_chatbots/,DeepInEvil,1557300817,"Hi folks, can you recommend some good tutorials on DRL explicitly for chatbots. Some papers and implementation would be nice.
TIA.",1,3
54,2019-5-8,2019,5,8,19,bm3h1o,"Fast-Pytorch with Google Colab: Pytorch Tutorial, Pytorch Implementations",https://www.reddit.com/r/deeplearning/comments/bm3h1o/fastpytorch_with_google_colab_pytorch_tutorial/,obsezer,1557310509,"This    repo aims to cover Pytorch details, Pytorch example implementations,    Pytorch sample codes, running Pytorch codes with Google Colab (with  K80   GPU/CPU) in a nutshell.

**Tutorial Link:** [**https://github.com/omerbsezer/Fast-Pytorch**](https://github.com/omerbsezer/Fast-Pytorch)

## Table of Contents:

* [Fast Pytorch Tutorial](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchtutorial)  

   * [Pytorch Playground](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchplayground)  

      * [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/Pytorch_Playground.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/Pytorch_Playground.ipynb)
   * [Model (Neural Network Layers)](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#model)
   * [Optimizer](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#optimizer)
   * [Loss Functions](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#lossfunctions)
   * [Pooling Layers](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#poolinglayers)
   * [Non-linear activation functions](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#nonlinearactivation)
   * [Basic 2 Layer NN](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#example)
* [Fast Torchvision Tutorial](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#torchvisiontutorial)  

   * [ImageFolder](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#imagefolder)
   * [Transforms](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#transforms)
   * [Datasets](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#datasets)
   * [Models](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#torchvisionmodels)
   * [Utils](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#utils)
* [Pytorch with Google Colab](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchcolab)
* [Pytorch Example Implementations](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchexamples)  

   * [MLP](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#mlp)  

      * MLP 1 Class with Binary Cross Entropy (BCE) Loss: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_1class_BinaryCrossEntropyLoss.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_1class_BinaryCrossEntropyLoss.ipynb)
      * MLP 2 Classes with Cross Entropy Loss: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_2class_CrossEntropyLoss.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_2class_CrossEntropyLoss.ipynb)
      * MLP 3-Layer with MNIST Example: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_3layer_MNIST.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_3layer_MNIST.ipynb)
   * [CNN](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#cnn)  

      * CNN with MNIST Example: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/CNN_Mnist.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/CNN_Mnist.ipynb)
      * Improved CNN with MNIST Example: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/Improved_CNN_Mnist.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/Improved_CNN_Mnist.ipynb)
   * [CNN Visualization](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#cnnvisualization)  

      * CNN Visualization: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/CNN_Visualization.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/CNN_Visualization.ipynb)
   * [RNN](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#rnn)  

      * RNN Text Generation: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/RNN_word_embeddings.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/RNN_word_embeddings.ipynb)
   * [Transfer Learning](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#transferlearning)  

      * Transfer Learning Implementation: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/TransferLearning.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/TransferLearning.ipynb)
   * [DCGAN](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#dcgan)  

      * DCGAN Implementation: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/DCGAN.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/DCGAN.ipynb)
   * [ChatBot](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#chatbot)  

      * Chatbot Implementation: [\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/ChatBot.ipynb), [\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/ChatBot.ipynb)
* [Pytorch Sample Codes](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchsamplecodes)

**Extra:** Reinforcement Learning Tutorial:

[**https://github.com/omerbsezer/Reinforcement\_learning\_tutorial\_with\_demo**](https://github.com/omerbsezer/Reinforcement_learning_tutorial_with_demo)

**Extra:**     Image  Generation With AI:  Generative Models Tutorial with    Python+Tensorflow  Codes (GANs, VAE,  Bayesian Classifier Sampling,    Auto-Regressive Models,  Generative  Models in RL)

**Tutorial Link**: [**https://github.com/omerbsezer/Generative\_Models\_Tutorial\_with\_Demo**](https://github.com/omerbsezer/Generative_Models_Tutorial_with_Demo)",1,27
55,2019-5-8,2019,5,8,20,bm3zyy,Awesome papers and engineering reviews on Computer Vision News of May. Links for free reading!,https://www.reddit.com/r/deeplearning/comments/bm3zyy/awesome_papers_and_engineering_reviews_on/,Gletta,1557314336,"Here are the links to the May 2019 issue of **Computer Vision News**, the magazine of the algorithm community published by RSIP Vision: many articles about Artificial Intelligence, Deep Learning, Computer Vision and more.

Free subscription on page 40.

[**HTML5 version (recommended)**](https://rsipvision.com/ComputerVisionNews-2019May/)

[**PDF version**](https://www.rsipvision.com/computer-vision-news-2019-may-pdf/)

Enjoy!

&amp;#x200B;

https://i.redd.it/naaml5td1zw21.jpg",0,5
56,2019-5-9,2019,5,9,2,bm7tzq,"Deep Learning: Master Powerful Deep Learning Tools in R Like Keras, Mxnet, H2O and Others",https://www.reddit.com/r/deeplearning/comments/bm7tzq/deep_learning_master_powerful_deep_learning_tools/,dailydeal2019,1557335179,,0,1
57,2019-5-9,2019,5,9,2,bm7z7u,A Tutorial on Multi-Label Classification using Deep Learning,https://www.reddit.com/r/deeplearning/comments/bm7z7u/a_tutorial_on_multilabel_classification_using/,thatbrguy_,1557335882,,2,21
58,2019-5-9,2019,5,9,4,bm9kg6,A survey for evaluating our music generation model using LSTM and GAN for our final year project.,https://www.reddit.com/r/deeplearning/comments/bm9kg6/a_survey_for_evaluating_our_music_generation/,ApenguinElement,1557343517,[removed],0,1
59,2019-5-9,2019,5,9,13,bmf9ro,Possible to clear Google Colaboratory GPU RAM programatically,https://www.reddit.com/r/deeplearning/comments/bmf9ro/possible_to_clear_google_colaboratory_gpu_ram/,dxjustice,1557374714,"I'm running multiple iterations of the same CNN script for confirmation purposes, but after each run I get the warning that the colab environment is approachin its GPU RAM limit.

&amp;#x200B;

Is there some way I can clear the GPU memory or refresh it in session?",7,16
60,2019-5-9,2019,5,9,13,bmfgo0,Getting Started with Machine Learning (art project ! ),https://www.reddit.com/r/deeplearning/comments/bmfgo0/getting_started_with_machine_learning_art_project/,GROOVYRA,1557375994,"Hello I am wondering what is the best way to get started with machine learning?

All I am really trying to do is feed a data set ( several thousand images) and see what it feedback as a result of the data

&amp;#x200B;

this is for an art project btw

&amp;#x200B;

just wondering if there is a program already that can be used to enter the images or would the system have to be built based off previous models,,?

 any information is greatly appreciated , thank you",6,1
61,2019-5-9,2019,5,9,16,bmgw43,How Did Deep Learning Come About?,https://www.reddit.com/r/deeplearning/comments/bmgw43/how_did_deep_learning_come_about/,ritesh1928,1557388224,,0,1
62,2019-5-9,2019,5,9,20,bmifrf,Information theory and Probability for Deep learning research,https://www.reddit.com/r/deeplearning/comments/bmifrf/information_theory_and_probability_for_deep/,bikanation,1557400182,Can i just study information theory and probability from khan academy for deep learning research ?,3,0
63,2019-5-10,2019,5,10,1,bmlxax,MIT explains neural networks,https://www.reddit.com/r/deeplearning/comments/bmlxax/mit_explains_neural_networks/,aiforworld2,1557419541,,0,33
64,2019-5-10,2019,5,10,5,bmorc7,Gradient Descent Optimization [Part 3],https://www.reddit.com/r/deeplearning/comments/bmorc7/gradient_descent_optimization_part_3/,msminhas93,1557433460,"This is the final post of the Gradient Descent series. Learn the difference between Stochastic, Mini-Batch and Batch Gradient Descent. Learn commonly used ways to schedule the learning rate. Hope you enjoyed the reading the posts as much as I enjoyed writing them. 

&amp;#x200B;

[https://expoundai.wordpress.com/2019/05/09/gradient-descent-optimization-part-3/](https://expoundai.wordpress.com/2019/05/09/gradient-descent-optimization-part-3/)",0,0
65,2019-5-10,2019,5,10,7,bmq6cv,[video / spark summit] AMD/ROCm and Distributed Deep Learning on Spark/TensorFlow/Hopsworks,https://www.reddit.com/r/deeplearning/comments/bmq6cv/video_spark_summit_amdrocm_and_distributed_deep/,jpdowlin,1557440439,,1,20
66,2019-5-10,2019,5,10,12,bmt8ae,"eed help changing my approach to my BSc thesis (Deep Learning, NLP, classification)",https://www.reddit.com/r/deeplearning/comments/bmt8ae/eed_help_changing_my_approach_to_my_bsc_thesis/,the_parallax_II,1557458054,"Hello,

I want to get involved with whichever task of classification (sentiment analysis, hate speech, etc.) regarding text data, by using deep learning for my bachelor thesis.

I am confused about what should be the aim of the dissertation. I mean, I am not capable to come with something ground breaking or fancy (eg. A new complicated architecture). Beyond building some architectures from papers and testing data on them, what can I do in order to make the thesis more interesting?

Something I have thought of, is to create a pipeline that will retrieve tweets from the Twitter API from different locations and then pass them to a trained model in order to perform some kind of classification and then create a visualization of the world map regarding the topic (eg. brexit-preferences of each country). However, this doesn't make a lot of sense since that procedure could be done more naively by counting specific hashtags on a geographical location. Also, how the dataset could be created and labeled?

Can you help me reconstruct my idea or guide me to a better direction?",6,5
67,2019-5-10,2019,5,10,15,bmuq0e,The Contrast Machine Learning VS Deep Learning,https://www.reddit.com/r/deeplearning/comments/bmuq0e/the_contrast_machine_learning_vs_deep_learning/,technewsninja,1557468459,,0,4
68,2019-5-10,2019,5,10,18,bmwdaf,"Hadoop, MapReduce for Big Data problems : Learn By Example",https://www.reddit.com/r/deeplearning/comments/bmwdaf/hadoop_mapreduce_for_big_data_problems_learn_by/,HannahHumphreys,1557482086,[removed],0,1
69,2019-5-10,2019,5,10,20,bmxdih,Gradient Descent Optimization [Part 3]  Batch vs Mini-Batch vs SGD,https://www.reddit.com/r/deeplearning/comments/bmxdih/gradient_descent_optimization_part_3_batch_vs/,msminhas93,1557489502,,0,17
70,2019-5-10,2019,5,10,21,bmxkxx,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/bmxkxx/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1557490762,[removed],0,1
71,2019-5-10,2019,5,10,22,bmy766,"DL Rig, what would you pick : 2x GTX 1080 or 1x RTX 2080 ?",https://www.reddit.com/r/deeplearning/comments/bmy766/dl_rig_what_would_you_pick_2x_gtx_1080_or_1x_rtx/,Atralb,1557494372,,9,3
72,2019-5-11,2019,5,11,0,bmzkl0,[Research]Segmentation is All You Need to Achieve Robust Object Detection,https://www.reddit.com/r/deeplearning/comments/bmzkl0/researchsegmentation_is_all_you_need_to_achieve/,cdossman,1557501619," [https://medium.com/ai%C2%B3-theory-practice-business/segmentation-is-all-you-need-to-achieve-robust-object-detection-4e60f74b80d](https://medium.com/ai%C2%B3-theory-practice-business/segmentation-is-all-you-need-to-achieve-robust-object-detection-4e60f74b80d) 

Abstract:  We propose a new paradigm of the detection task that is anchor-box free and NMS free. Although the current state-of-the-art model that based on region proposed method has been well-acknowledged for years, however as the basis of RPN, NMS cannot solve the problem of low recall in complicated occlusion situation. This situation is particularly critical when it faces up to complex occlusion. We proposed to use weak-supervised segmentation multimodal annotations to achieve a highly robust object detection performance without NMS. In such cases, we utilize poor annotated Bounding Box annotations to perform a robust object detection performance in the difficult circumstance. We have avoided all hyperparameters related to anchor boxes and NMS. Our proposed model has outperformed previous anchor-based one-stage and multi-stage detectors with the advantage of being much simpler. We have reached a state-of-the-art performance in both accuracies, recall rate",0,5
73,2019-5-11,2019,5,11,0,bmzy45,Google AI | Unsupervised Depth Estimation for Arbitrary Videos,https://www.reddit.com/r/deeplearning/comments/bmzy45/google_ai_unsupervised_depth_estimation_for/,Yuqing7,1557503488,,0,2
74,2019-5-11,2019,5,11,3,bn21iu,Google I/O 2019 | Geoffrey Hinton Says Machines Can Do Anything Humans Can,https://www.reddit.com/r/deeplearning/comments/bn21iu/google_io_2019_geoffrey_hinton_says_machines_can/,Yuqing7,1557513693,,2,1
75,2019-5-11,2019,5,11,4,bn2jkg,Computer Intelligence Group with industry professionals,https://www.reddit.com/r/deeplearning/comments/bn2jkg/computer_intelligence_group_with_industry/,nowsden,1557516164,"Hello I've made a discord server for beginners and experts to talk about the newest tech and the newest things in the software and AI industry. For example me, I work on a website that is all about quantitative finance, I use different ML and DL models there and also different statistical models. Curious ?

For more, just join the server: [https://discord.gg/Wx9wXa4](https://discord.gg/Wx9wXa4)

Thanks for reading :)",0,1
76,2019-5-11,2019,5,11,5,bn3734,A Real-World Application of Deep Learning at Industrial Scale,https://www.reddit.com/r/deeplearning/comments/bn3734/a_realworld_application_of_deep_learning_at/,crubier,1557519323,,0,28
77,2019-5-11,2019,5,11,6,bn3rdc,[AI application] Let your machine teach itself to play flappy bird!,https://www.reddit.com/r/deeplearning/comments/bn3rdc/ai_application_let_your_machine_teach_itself_to/,1991viet,1557522082,,8,86
78,2019-5-11,2019,5,11,6,bn3ykz,Adversarial Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/bn3ykz/adversarial_reinforcement_learning/,ZeroMaxinumXZ,1557523110,I'm trying to think of ways to supplement deep reinforcement learning with adversarial strategies. Are there any papers on this topic I can look into?,0,1
79,2019-5-11,2019,5,11,17,bn9r3w,CNN effective receptive field - question,https://www.reddit.com/r/deeplearning/comments/bn9r3w/cnn_effective_receptive_field_question/,NikolasTs,1557562381,"Hey guys,

&amp;#x200B;

I have a question regarding the effective receptive field in CNNs. I have studied the Stanford lecture: [http://cs231n.github.io/convolutional-networks/](http://cs231n.github.io/convolutional-networks/) but I can't make sense. 

Should the effective receptive field be at most equal to the input size of a CNN? If the opposite happens, will it lead to overfitting? 

I am attaching a E.R.F. calculator: [https://fomoro.com/projects/project/receptive-field-calculator](https://fomoro.com/projects/project/receptive-field-calculator)

&amp;#x200B;

Thanks in advance!",0,2
80,2019-5-11,2019,5,11,21,bnbevi,VAE for Data Augmentation?,https://www.reddit.com/r/deeplearning/comments/bnbevi/vae_for_data_augmentation/,ongteckwu,1557576773,"Hi all,

Are there any state-of-the-art models (VAE/GAN-based?) that can be used to generate augmented images from fresh images? Say the model can randomly perform saturations and brightness changes based upon what kind of image it is (Maybe using Mutual Information)? So let's say I have multiple faces and i want to perform data augmentation with respect to other faces that have been seen previously.

Maybe a cycleGAN trained using an ImageNet discriminator?

Hope to hear about some interesting models or maybe some ideas on how to implement this. 

Also, first time posting in this community. Hope to make new friends here :)",2,6
81,2019-5-11,2019,5,11,21,bnbfa1,How to train an RNN with minibatches using dataloader in PyTorch?,https://www.reddit.com/r/deeplearning/comments/bnbfa1/how_to_train_an_rnn_with_minibatches_using/,ai_badger,1557576854,"I get the following error :

`RuntimeError:  Trying to backward through the graph a second time, but the buffers  have already been freed. Specify retain_graph=True when calling backward  the first time.`

I've posted this question with more details on [stackoverflow](https://stackoverflow.com/questions/56042815/runtime-error-backprop-while-training-a-time-series-model-using-rnn-in-pytorch). Please help.",35,1
82,2019-5-11,2019,5,11,22,bnc4xv,Is Caffe dead?,https://www.reddit.com/r/deeplearning/comments/bnc4xv/is_caffe_dead/,ToughGingerbread,1557581812,"Hello, fellow machine teachers.

I've been wondering if Caffe framework still in the play? 

It seem abandoned, but I can't find any official notice from BVLC / BAIR about closing the project. 

Though Caffe github looks pretty dead to me.",5,8
83,2019-5-11,2019,5,11,23,bncph7,"Free: Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow",https://www.reddit.com/r/deeplearning/comments/bncph7/free_handson_machine_learning_with_scikitlearn/,aiforworld2,1557585302,,20,71
84,2019-5-12,2019,5,12,0,bnd5k2,Introducing TensorFlow Graphics: Computer Graphics Meets Deep Learning,https://www.reddit.com/r/deeplearning/comments/bnd5k2/introducing_tensorflow_graphics_computer_graphics/,aiforworld2,1557587887,,2,18
85,2019-5-12,2019,5,12,1,bne3o3,Introduction to Data Science,https://www.reddit.com/r/deeplearning/comments/bne3o3/introduction_to_data_science/,HannahHumphreys,1557593018,[removed],0,1
86,2019-5-12,2019,5,12,2,bneoeu,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/bneoeu/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1557596088,[removed],0,1
87,2019-5-12,2019,5,12,5,bngr6e,"How good is the darknet framework compared to tensorflow, pytorch etc for deep learning ?",https://www.reddit.com/r/deeplearning/comments/bngr6e/how_good_is_the_darknet_framework_compared_to/,nicetryho,1557607279,Been training models on yolo via transfer learning and have been getting phenomenal results. Training seems to be relatively easy compared to the other frameworks but how does it hold up in comparison?  I am not sure how to construct custom architectures in darknet besides by modifying the cfg file.,8,6
88,2019-5-12,2019,5,12,10,bnjtsl,How to play the piano by PianoCourse101,https://www.reddit.com/r/deeplearning/comments/bnjtsl/how_to_play_the_piano_by_pianocourse101/,piano0011,1557625816," 

Hey guys!

How to play the piano for kids by PianoCourse101 is based on the Bastien Piano Basic Series for children. The Bastien Piano Basic Series consists of four levels. There are the ""Primer Level"", ""Level 1"", ""Level 2"" and ""Level 3"". I will eventually be uploading all of the courses on youtube. The first few lessons of the ""Primer Level"" are free and available on youtube while the rest of the lessons will be available on my website, which will be announced pretty soon. Lesson 1, Lesson 2 and Lesson 3 are paid courses. I believe that PianoCourse101 offers piano lessons that is not only well structured by engaging for children. Utilising a white board with rhythm exercises, explaining terms in a visually presentable manner is one unique method in making learning fun for kids.

[https://www.youtube.com/channel/UC\_pzmnmzz\_4RT0lPFFnRWyQ?sub\_confirmation=1](https://www.youtube.com/channel/UC_pzmnmzz_4RT0lPFFnRWyQ?sub_confirmation=1)",1,0
89,2019-5-12,2019,5,12,21,bnojpc,End of encryption,https://www.reddit.com/r/deeplearning/comments/bnojpc/end_of_encryption/,honghuac,1557664995,,4,0
90,2019-5-13,2019,5,13,0,bnq0ox,has any one encountered a open source implementation for L-VO network?,https://www.reddit.com/r/deeplearning/comments/bnq0ox/has_any_one_encountered_a_open_source/,chadrick-kwag,1557674177,"I am reading ""Learning monocular visual odometry with dense 3D mapping from dense 3D flow"" paper but couldn't find any open source implementation.

&amp;#x200B;

 [https://arxiv.org/abs/1803.02286](https://arxiv.org/abs/1803.02286) 

&amp;#x200B;

Just wondering if anyone has encountered such a thing.

&amp;#x200B;

The authors say they have implemented it in tensorflow but such a bummer that they didn't open the source. It would have been great tho",1,3
91,2019-5-13,2019,5,13,0,bnq3z7,"Applied deep learning tutorial covering basics and variations (Autoencoder, LSTM,...)",https://www.reddit.com/r/deeplearning/comments/bnq3z7/applied_deep_learning_tutorial_covering_basics/,Helveticus99,1557674687,"Hello

I have some machine learning background and I know a little about neural networks. Now I plan to use deep learning in a project using Keras on Python.  In my project I'm using smartphone sensor data as input. Before I start I would like to read or watch a tutorial about deep learning providing the basics but more on an applied side.

I have found the lecture from stanford [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/). It seems to be applied but it only covers CNN and RNN and is tied to visual recognition (I'm working with sensor data and not in the visual domain). I have also found two tutorial articles [http://ai.stanford.edu/\~quocle/tutorial1.pdf](http://ai.stanford.edu/~quocle/tutorial1.pdf) and [http://ai.stanford.edu/\~quocle/tutorial2.pdf](http://ai.stanford.edu/~quocle/tutorial2.pdf). They cover Autoencoders, CNN and RNN but it seems to be less applied and brief.

Does somebody know a good tutorial (article or video) about deep learning which covers the basics but also the different variations like Autoencoders, LSTM and so on. I'm interested in applied introductions, i.e. I'm not interested in proofs and deriving backproagation for all variations. It would also be nice to get some pratical tips about how to train it and so on.",7,36
92,2019-5-13,2019,5,13,0,bnq7la,Towards Standardization of Data Licenses: The Montreal Data License,https://www.reddit.com/r/deeplearning/comments/bnq7la/towards_standardization_of_data_licenses_the/,aiforworld2,1557675231,,0,5
93,2019-5-13,2019,5,13,1,bnr03d,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/bnr03d/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1557679380,[removed],0,1
94,2019-5-13,2019,5,13,17,bo0ssq,"G-7 Science Academies Release Statements on Science and Trust, Artificial Intelligence, Citizen Science",https://www.reddit.com/r/deeplearning/comments/bo0ssq/g7_science_academies_release_statements_on/,aiforworld2,1557735889,,0,3
95,2019-5-13,2019,5,13,19,bo1pqu,Text summarization,https://www.reddit.com/r/deeplearning/comments/bo1pqu/text_summarization/,raghav2234,1557743047,"Hi, 
I wanted to know the state of the art techniques in text summarisation. I have come across a text ranking algorithm but I'm interested in knowing any other deep learning approach. Can anyone give a overview of the various techniques used? 
Thank you.",3,23
96,2019-5-13,2019,5,13,21,bo2v6u,How to apply the learned concepts in tensorflow?,https://www.reddit.com/r/deeplearning/comments/bo2v6u/how_to_apply_the_learned_concepts_in_tensorflow/,SanjivGautamOfficial,1557750664,"I am a novice in machine learning. So, the question is, I learn the basic course, concepts in Youtube, so now I want to implement in tensorflow. I could have chosen Torch, but tensorflow looks like it would be easier for me. But, I cannot get the grasp on how I can implement them. I mean,  even if I read the papers, I am going to get the maths, and the calculations which the tensorflow does in a line or two. So, how can I follow this approach of implementing what I have learned ? Any help from the experts or anyone who has been through this phase please?",1,2
97,2019-5-14,2019,5,14,2,bo68o4,[Research] NextGen MobileNetV3 Definitions,https://www.reddit.com/r/deeplearning/comments/bo68o4/research_nextgen_mobilenetv3_definitions/,cdossman,1557767489," [https://medium.com/ai%C2%B3-theory-practice-business/nextgen-mobilenetv3-definitions-243e396a4c9a](https://medium.com/ai%C2%B3-theory-practice-business/nextgen-mobilenetv3-definitions-243e396a4c9a) 

 We present the next generation of MobileNets based on a combination of complementary search techniques as well as a novel architecture design. MobileNetV3 is tuned to mobile phone CPUs through a combination of hardware-aware network architecture search (NAS) complemented by the NetAdapt algorithm and then subsequently improved through novel architecture advances. This paper starts the exploration of how automated search algorithms and network design can work together to harness complementary approaches improving the overall state of the art. Through this process, we create two new MobileNet models for release: MobileNetV3-Large and MobileNetV3-Small which are targeted for high and low resource use cases. These models are then adapted and applied to the tasks of object detection and semantic segmentation.",2,6
98,2019-5-14,2019,5,14,2,bo6c0b,Deep learning and shallow understanding,https://www.reddit.com/r/deeplearning/comments/bo6c0b/deep_learning_and_shallow_understanding/,GoodStrat,1557767915,,2,1
99,2019-5-14,2019,5,14,3,bo7gln,Bunch of books on Deep Learning &amp; AI are now discounted,https://www.reddit.com/r/deeplearning/comments/bo7gln/bunch_of_books_on_deep_learning_ai_are_now/,KristineDevore,1557773279,,8,24
100,2019-5-14,2019,5,14,10,boc2mu,Free cloud GPU credits for deep learning,https://www.reddit.com/r/deeplearning/comments/boc2mu/free_cloud_gpu_credits_for_deep_learning/,whitezl0,1557796074,"Hi, I am offering free credits for 1080Ti GPU instances for deep learning purposes  more than 12hrs for free

I am working on [https://www.tensorpad.com/](https://www.tensorpad.com/?utm_source=reddit&amp;utm_campaign=deeplearning)  developing cloud infrastructure for machine learning.

Part of our computational capacity is idle; hence, were offering credits at a free and discounted rate, so that data scientists can benefit from the resources available, and work on neural networks.

Specs:
	60GB of RAM, 4 CPUs, 1080Ti GPU
	JupyterLab environment with access to the terminal
	Pre-installed Tensorflow, Keras, and other ML frameworks 

You can access the free credits by signing up ([https://dashboard.tensorpad.com/](https://dashboard.tensorpad.com/signup?utm_source=reddit&amp;utm_campaign=deeplearning) and redeeming ""promo450"" promo code in the Billing tab ([https://dashboard.tensorpad.com/billing](https://dashboard.tensorpad.com/billing?utm_source=reddit&amp;utm_campaign=deeplearning)).

For any questions, please contact us here, through support@tensorpad.com, or the Intercom on the site.",3,31
101,2019-5-14,2019,5,14,15,bof558,Image Segmentation for segmenting rock types from blasted mine faces.,https://www.reddit.com/r/deeplearning/comments/bof558/image_segmentation_for_segmenting_rock_types_from/,adityashrm21,1557815205,,0,0
102,2019-5-14,2019,5,14,15,bof7z5,Image Segmentation using PyTorch,https://www.reddit.com/r/deeplearning/comments/bof7z5/image_segmentation_using_pytorch/,adityashrm21,1557815742,"I recently performed image segmentation using [Fully Convolutional Networks](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf) on an easy dataset (KITTI road dataset) and I am working on doing the same for a more complex dataset of blasted rock faces in a mine to detect different rock types. The challenge here is that there are no clear boundaries between different rocks. It would be great to hear some inputs and how to avoid some pitfalls when approaching this problem.

Here is the link to my project and code in PyTorch: https://github.com/adityashrm21/image-segmentation-pytorch

Feedback welcome!",0,4
103,2019-5-14,2019,5,14,15,bofans,Should I learn deep learning?,https://www.reddit.com/r/deeplearning/comments/bofans/should_i_learn_deep_learning/,matt_murdock_2000,1557816253,I am 18 years old and Ive just completed my first year in college.Is it too early for me to start learning about Deep learning and ML?,24,0
104,2019-5-14,2019,5,14,17,bog1tj,Deep Learning for Data Integration,https://www.reddit.com/r/deeplearning/comments/bog1tj/deep_learning_for_data_integration/,MarioOrlandi,1557821711,[http://dev.thegeeknews.net/c7eabfaf48](http://dev.thegeeknews.net/c7eabfaf48),0,0
105,2019-5-15,2019,5,15,0,bok3e3,Using k-means Clustering with TensorFlow,https://www.reddit.com/r/deeplearning/comments/bok3e3/using_kmeans_clustering_with_tensorflow/,ValVish,1557846370,,0,26
106,2019-5-15,2019,5,15,0,bokgc3,Real-World Machine Learning Projects with Scikit-Learn,https://www.reddit.com/r/deeplearning/comments/bokgc3/realworld_machine_learning_projects_with/,HannahHumphreys,1557848072,[removed],0,1
107,2019-5-15,2019,5,15,2,bolsrz,Create High Resolution GAN Faces with Pretrained NVidia StyleGAN and Google CoLab. No need for a GPU on your machine.,https://www.reddit.com/r/deeplearning/comments/bolsrz/create_high_resolution_gan_faces_with_pretrained/,jeffheaton,1557854499,,0,10
108,2019-5-15,2019,5,15,3,bomxtw,This eye does not exist,https://www.reddit.com/r/deeplearning/comments/bomxtw/this_eye_does_not_exist/,abriosi,1557860075,,0,1
109,2019-5-15,2019,5,15,6,book2p,[Research] You Only Propagate Once(YOPO),https://www.reddit.com/r/deeplearning/comments/book2p/research_you_only_propagate_onceyopo/,cdossman,1557867945," [https://medium.com/ai%C2%B3-theory-practice-business/you-only-propagate-once-yopo-bac6b08a5ff4](https://medium.com/ai%C2%B3-theory-practice-business/you-only-propagate-once-yopo-bac6b08a5ff4) 

Researchers have developed an efficient strategy for accelerating adversarial training for neural networks. We recast the adversarial training for neural networks as a differential game and derive a Pontryagins Maximal Principle for it. Based on the maximal principle, we discover that the adversary is only coupled with the weights of the first layer. This helps us to split the adversary updating from the backpropagation gradient calculation. The new algorithm YOPO avoids accessing the gradient too many times thus reduces the computational time significantly",2,2
110,2019-5-15,2019,5,15,8,boqf7i,"Introducing Deeper Deep Learning (DDL) - The Next Generation State-of-the-Art Approach for Training Deep Neural Networks - Faster, Cheaper, Smarter",https://www.reddit.com/r/deeplearning/comments/boqf7i/introducing_deeper_deep_learning_ddl_the_next/,ai-lover,1557877695,,1,1
111,2019-5-15,2019,5,15,9,boqmq4,Using python for Neural Nerworks,https://www.reddit.com/r/deeplearning/comments/boqmq4/using_python_for_neural_nerworks/,DillonNotDylanPlease,1557878845,"Hey guys, first time posting here, and I'm also very new to python; I usually use C or Java.

I would like to train a neural network to play the game QWOP, but because I am very new to the whole thing, I don't really know how keyboard inputs work.

Does anyone have any suggestions for how I might go about telling the neural network to ""click"" Q, W, O, or P when it needs to?

For any of those unfamiliar with the game QWOP, you are just trying to get runner to reach a finish line by only using those 4 keys. The 4 keys control his upper and lower legs and he needs to stay upright for the most part.

My second question, if it is not to much, is how I would be able to have the python code monitor the screen so to speak to make sure the runner doesn't tilt too far in either direction while he is moving.

Thank you for your time and and help that you can offer.",13,12
112,2019-5-15,2019,5,15,14,botwej,Create your own text classification models based on BERT with 1 API call,https://www.reddit.com/r/deeplearning/comments/botwej/create_your_own_text_classification_models_based/,aks4321,1557898624,,2,15
113,2019-5-15,2019,5,15,18,bovkdq,Object detection and subclass,https://www.reddit.com/r/deeplearning/comments/bovkdq/object_detection_and_subclass/,tmddlf03,1557911106,"Hi, I have a Faster R-CNN object detection network and I'm trying to add a feature to identify the subclass of the detection. So for example, if a dog is detect, the network will also tell if the dog is puddle or shiva. I was thinking of adding a classification part after the detection part but I'm not sure how I can implement this. Can anyone give me any help? If my idea is not the best, I am open for other ideas as well. Thanks in advance!",1,1
114,2019-5-15,2019,5,15,18,bovwsg,Loss function for a semi-supervised clustering problem,https://www.reddit.com/r/deeplearning/comments/bovwsg/loss_function_for_a_semisupervised_clustering/,Magical_Username,1557913721,"Hey guys, I'm trying to train a deep semi-supervised clustering network with a couple constraints: I need exactly n clusters, I need each cluster to have the sum of a particular feature not exceed a given threshold, and of course I need to optimize intra-cluster feature similarity. What I have so far is a two-output autoencoder, with one end being standard reconstruction, the other being a cluster prediction vector. The loss function combines reconstruction loss, KL divergence between the prediction distribution and a student-T distribution, and a mean squared error between total predictions and a uniform distribution. 

The above problem doesn't seem awful to solve, but I do have one more constraint that I can't figure out how to build into the network. I have connectivity constraints on my data as it's originally from a graph, so I can only have two points in the same cluster if a path exists between them in the underlying graph. I've seen there's a lot of research on must-link and cannot-link constraints but that's not quite what I need. 

Has anyone worked with that kind of problem before? I'm having trouble coming up with a way to optimally enforce this constraint. Thanks!",0,1
115,2019-5-15,2019,5,15,21,boxdpc,Real-time protection via Neural Networks,https://www.reddit.com/r/deeplearning/comments/boxdpc/realtime_protection_via_neural_networks/,Holyzone,1557923650,,0,1
116,2019-5-15,2019,5,15,23,boyahr,Is there a deep learning model that can extract end/junction points of lines?,https://www.reddit.com/r/deeplearning/comments/boyahr/is_there_a_deep_learning_model_that_can_extract/,chadrick-kwag,1557928845,"I can't even think of a google keyword to search for related topics. 

&amp;#x200B;

I'm searching for a way to get the end/junction points given an image of a line, like the following.

&amp;#x200B;

https://i.redd.it/whzbml5tsdy21.png

https://i.redd.it/yagtsr5tsdy21.png

&amp;#x200B;

Does anyone know the name of this topic or any similar work done in deep learning?",0,2
117,2019-5-15,2019,5,15,23,boyoh8,2x RTX 2070 or 1 2080 Ti ?,https://www.reddit.com/r/deeplearning/comments/boyoh8/2x_rtx_2070_or_1_2080_ti/,Atralb,1557930869,,29,5
118,2019-5-16,2019,5,16,0,bozf4w,Yoshua Bengio to Lead New Canadian Advisory Council on AI,https://www.reddit.com/r/deeplearning/comments/bozf4w/yoshua_bengio_to_lead_new_canadian_advisory/,Yuqing7,1557934559,,0,11
119,2019-5-16,2019,5,16,1,bp0agj,Math behind Encoder - Decoder networks,https://www.reddit.com/r/deeplearning/comments/bp0agj/math_behind_encoder_decoder_networks/,ccp9696,1557938778,"Hi, i've been studying DL applications and models for some time now and i've been searching for a more in-depth analysis of Encoder Decoder networks, particularly for image segmentation using CNNs. So far, even in reputable papers (U-net), the discription is something like : ""we have this encoder CNN and then the decoder CNN learns how to create accurate image masks from any given image representation from the encoder"". Can someone provide a better analsysis or a link which explains the problem in a more sophisticated way?",7,16
120,2019-5-16,2019,5,16,2,bp0xcy,[Research] Adversarial Examples Are Not Bugs,https://www.reddit.com/r/deeplearning/comments/bp0xcy/research_adversarial_examples_are_not_bugs/,cdossman,1557941839," [https://medium.com/ai%C2%B3-theory-practice-business/adversarial-examples-are-not-bugs-585abca94d3c](https://medium.com/ai%C2%B3-theory-practice-business/adversarial-examples-are-not-bugs-585abca94d3c) 

Abstract:  Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.",0,1
121,2019-5-16,2019,5,16,4,bp27wa,Google Brain NAS-FPN Outperforms SOTA Models for Object Detection,https://www.reddit.com/r/deeplearning/comments/bp27wa/google_brain_nasfpn_outperforms_sota_models_for/,Yuqing7,1557948080,,1,1
122,2019-5-16,2019,5,16,8,bp5931,Where to learn neural network architecture design,https://www.reddit.com/r/deeplearning/comments/bp5931/where_to_learn_neural_network_architecture_design/,DongDilly,1557962948,"So people at Deep Mind and OpenAi comes up with great models that are really innovatively designed. Can someone please tell me how and where I can learn the skill to design a neural network for a specific problem.
 Thank you",12,32
123,2019-5-16,2019,5,16,17,bpa5ju,What are the best ways to improve writing skills in English,https://www.reddit.com/r/deeplearning/comments/bpa5ju/what_are_the_best_ways_to_improve_writing_skills/,AutocraticAcyl,1557996769,[removed],0,1
124,2019-5-16,2019,5,16,19,bpaxba,How to train a CNN on multiple sets with pytorch,https://www.reddit.com/r/deeplearning/comments/bpaxba/how_to_train_a_cnn_on_multiple_sets_with_pytorch/,TheBaris,1558002997,"I have 20 .csv files which have data about some organs. They are way too big to combine since I run out of RAM even trying to merge them. I managed combine 10 of them but my RAM runs out when I load it so they cannot be merged.

I would like to train my CNN on 2-20 and then test it with 1. However my approach seems to reset the net each time I use a new set.

I pasted the output here: https://justpaste.it/28tk0

But to summarize, even after 9 hours of training, the test set is still at between 10% and 20% accuracy (btw there are 23 classes in total). The problem is it doesn't improve at all. However the most important part is, for some reason, after file 14, the test accuracy is always around 40%. For file 3, it's literally always as 13%.

From these results I conclude that I have failed to train the CNN on multiple sets and instead it always resets when I use a new set.

This is what I tried:

    n_epochs = 10
    for epoch in range(n_epochs):
        for i in range(2,21):
            train_dataset = mydata('./data/{}.csv'.format(i), transform= transforms.Compose(
                                [transforms.ToPILImage(), 
                                 transforms.ToTensor(), 
                                 transforms.Normalize(mean=(0.5,), std=(0.5,))]))
            train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size, shuffle=True)
            train(epoch, i)",1,8
125,2019-5-17,2019,5,17,0,bpdx4e,Run Deep Learning Containers on AWS with One Command,https://www.reddit.com/r/deeplearning/comments/bpdx4e/run_deep_learning_containers_on_aws_with_one/,apls777,1558020344,,0,0
126,2019-5-17,2019,5,17,0,bpe4xo,"Google AI yesterday released its latest research result in speech-to-speech translation, the futuristic-sounding Translatotron",https://www.reddit.com/r/deeplearning/comments/bpe4xo/google_ai_yesterday_released_its_latest_research/,Yuqing7,1558021411,,5,55
127,2019-5-17,2019,5,17,0,bpe84g,"Deepfake: The Good, The Bad and the Ugly",https://www.reddit.com/r/deeplearning/comments/bpe84g/deepfake_the_good_the_bad_and_the_ugly/,nahuak,1558021849,,0,1
128,2019-5-17,2019,5,17,1,bpeyxd,[Research] Ian Goodfellow and other Google researchers on semi-supervised learning,https://www.reddit.com/r/deeplearning/comments/bpeyxd/research_ian_goodfellow_and_other_google/,cdossman,1558025532,"  [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-a-holistic-approach-to-semi-supervised-learning-51d82a2ee759](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-a-holistic-approach-to-semi-supervised-learning-51d82a2ee759) 

**Abstract:** Semi-supervised learning has proven to be a powerful paradigm for leveraging unlabeled data to mitigate the reliance on large labeled datasets. In this work, we unify the current dominant approaches for semi-supervised learning to produce a new algorithm, MixMatch, that works by guessing low-entropy labels for data-augmented unlabeled examples and mixing labeled and unlabeled data using MixUp. We show that MixMatch obtains state-of-the-art results by a large margin across many datasets and labeled data amounts. For example, on CIFAR-10 with 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by a factor of 2 on STL-10. We also demonstrate how MixMatch can help achieve a dramatically better accuracy-privacy trade-off for differential privacy. Finally, we perform an ablation study to tease apart which components of MixMatch are most important for its success.",0,5
129,2019-5-17,2019,5,17,2,bpfmrk,Dance Dance Convolution,https://www.reddit.com/r/deeplearning/comments/bpfmrk/dance_dance_convolution/,MusingEtMachina,1558028812,,0,0
130,2019-5-17,2019,5,17,2,bpfoxg,CS230: Deep Learning. Stanford University. Autumn 2018,https://www.reddit.com/r/deeplearning/comments/bpfoxg/cs230_deep_learning_stanford_university_autumn/,asuagar,1558029056,,0,6
131,2019-5-17,2019,5,17,2,bpfq04,Strange GPS data in Comma.ai dataset?! Can someone tell me how to interpret this data? Is it UTM? Then what's the zone?,https://www.reddit.com/r/deeplearning/comments/bpfq04/strange_gps_data_in_commaai_dataset_can_someone/,S1293,1558029194,,0,0
132,2019-5-17,2019,5,17,2,bpfsnd,An introduction to Q-Learning: Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/bpfsnd/an_introduction_to_qlearning_reinforcement/,sdoshi579_,1558029564,,0,5
133,2019-5-17,2019,5,17,8,bpjrq8,Mr. Musk discusses two ways to navigate the road for autonomous vehicle. What are they?,https://www.reddit.com/r/deeplearning/comments/bpjrq8/mr_musk_discusses_two_ways_to_navigate_the_road/,realfake2018,1558049362,"In the [podcast](https://youtu.be/dEv99vxKjVI?t=260) (4:20-7:11) by Lex Fridman with Elon Musk discusses about Tesla car that has two debug views to check sanity of vehicle while in simulation (also while in use- I guess) for its effectiveness in self-driving. 

&amp;#x200B;

1. Augmented vision that draws boxes, labels around the object recognised- also easier for general public to understand and on display on the box.
2. Visualizer that has vector representation which sums up input from all sensors and has no pictures- basically shows the car's view of the world in vector space.  

&amp;#x200B;

My doubt is 'what are they' and does all the other self-driving cars also has similar underlying concept for their development/working . Why does Tesla does not use LiDAR? It only relies on Radar, external facing cameras (8),  GPS, ultrasonic sensors (12),  IMU. Is Tesla cars doing something completely different (like summing vector representation from all sensors should match for car navigation) than only road segmentation, lane detection, vehicle detection, object detection etc for car navigation. What are your thoughts? Anything is highly appreciated.",1,0
134,2019-5-17,2019,5,17,15,bpnk01,A 2019 guide to 3D Human Pose Estimation,https://www.reddit.com/r/deeplearning/comments/bpnk01/a_2019_guide_to_3d_human_pose_estimation/,manneshiva,1558073125,"Human Pose estimation is an important problem that has enjoyed the attention of the Computer Vision community for the past few decades. It is an important step towards understanding people in images and videos. This post covers the basics of 3D Human Pose Estimation and reviews the literature on the topic.

Article Link: [https://blog.nanonets.com/human-pose-estimation-3d-guide/](https://blog.nanonets.com/human-pose-estimation-3d-guide/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=3dhpe&amp;utm_content=dl)",1,1
135,2019-5-17,2019,5,17,17,bponye,4 NVidia 2080 ti Workstation,https://www.reddit.com/r/deeplearning/comments/bponye/4_nvidia_2080_ti_workstation/,ValiRusu19,1558082040,"Hello guys,

&amp;#x200B;

I am kind of a nooby in what concerns the hardware products for deep learning. I am trying right now to build a workstation for high computational deep learning. I found a company that does ""plug and play"" products.

I did a configuration and I would like to ask you for a review, if the product worth the money and if you know anything about this company.

 [https://bizon-tech.com/us/workstations/deeplearning/bizon-g5000#534:1943;536:1870;537:2924;538:2652;539:1878;540:1879;543:2676;557:1955;707:2870;717:2961;740:3197;741:3199](https://bizon-tech.com/us/workstations/deeplearning/bizon-g5000#534:1943;536:1870;537:2924;538:2652;539:1878;540:1879;543:2676;557:1955;707:2870;717:2961;740:3197;741:3199) 

Thank you very much!",11,11
136,2019-5-17,2019,5,17,19,bppck8,Hyperas and Google Colab,https://www.reddit.com/r/deeplearning/comments/bppck8/hyperas_and_google_colab/,Fusken,1558087577,"Did someone make Hyperas run on colab? I always get the error 

&amp;#x200B;

    FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Task-3-with-Hyperas.ipynb'

even though it's there. I'm also loading CSV Data from the exact same folder with the same path.

  
I did all the steps from here: [https://github.com/maxpumperla/hyperas/issues/83](https://github.com/maxpumperla/hyperas/issues/83)

&amp;#x200B;

Also I get this error: When I update it to the right version everything crashes because now Jupyter Notebook needs another Version.

     ERROR: ipython 5.5.0 has requirement prompt-toolkit&lt;2.0.0,&gt;=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible. 

&amp;#x200B;

I tried to optimize with the  *Bayesian optimization*  pack and the results where okay. However, I wanted to try Hyperas. So.. Any ideas?

&amp;#x200B;

Thanks so much for your help and ideas!",0,3
137,2019-5-17,2019,5,17,19,bppq8b,Why Git and Git-LFS is not enough for machine learning reproducibility,https://www.reddit.com/r/deeplearning/comments/bppq8b/why_git_and_gitlfs_is_not_enough_for_machine/,thumbsdrivesmecrazy,1558090419,,1,3
138,2019-5-17,2019,5,17,21,bpqszf,"last year of Software Eng. I have tons of systems design thinking, but no solid programming skills. 1 year of school left and wondering what I should focus on to be prepared for the job hunt, particularly portfolio pieces/projects in domain of deep learning+compVision",https://www.reddit.com/r/deeplearning/comments/bpqszf/last_year_of_software_eng_i_have_tons_of_systems/,uncertain_futuresSE,1558097073,"Here's my situation

* I have experience in graphics programming (c++) along with various game engines, AR dev w/ Hololens
* I have done 2 internships : 1 in finance applications, 1 in AR. I still feel I lack a lot of programming/implementation experience.
* I have the choice of 2 complementary courses from below (that I feel are relevant)...
 * Parallel Architectures
 * Intelligent Systems and Machine Learning

I'm in my last year of Software Engineering (bachelors) and I would like to have a career in the future at some point related to computer vision and deep learning. My education (I feel) has prepared me for systems design thinking - what I'm realizing is that applied skills in dev/programming.

I'm very interested in computer vision+deep learning and I would like to explore more of that. However, as I am searching through a lot of job applications/internships, many of them require at the very least an education level at Masters. I'm uncertain if I want to pursue a Masters, mostly for financial reasons and that I am 31 and feel that I should be getting out in the field for experience.


My questions are

* I have to do one 4 month internship before graduating. What are some entry level internship positions that could help me get my foot into the field - esp. since I am not at a Masters level ?
* What would be a good portfolio pieces that would be good to start working on that would give me an advantage in the job hunt process?",0,1
139,2019-5-17,2019,5,17,23,bprv36,Using TensorFlow Object Detection API for Corrosion Detection and Localization,https://www.reddit.com/r/deeplearning/comments/bprv36/using_tensorflow_object_detection_api_for/,pirate7777777,1558102838,,0,3
140,2019-5-18,2019,5,18,1,bpt7hu,[Research]Adversarial Attacks -- The Implications,https://www.reddit.com/r/deeplearning/comments/bpt7hu/researchadversarial_attacks_the_implications/,cdossman,1558109480," [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-adversarial-attacks-implications-4750c1f47522](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-adversarial-attacks-implications-4750c1f47522) 

**Abstract:**  Deep neural networks are susceptible to adversarial attacks. In computer vision, well-crafted perturbations to images can cause neural networks to make mistakes such as confusing a cat with a computer. Previous adversarial attacks have been designed to degrade performance of models or cause machine learning models to produce specific outputs chosen ahead of time by the attacker. We introduce attacks that instead reprogram the target model to perform a task chosen by the attackerwithout the attacker needing to specify or compute the desired output for each test-time input. This attack finds a single adversarial perturbation, that can be added to all test-time inputs to a machine learning model in order to cause the model to perform a task chosen by the adversaryeven if the model was not trained to do this task. These perturbations can thus be considered a program for the new task. We demonstrate adversarial reprogramming on six ImageNet classification models, repurposing these models to perform a counting task, as well as classification tasks: classification of MNIST and CIFAR-10 examples presented as inputs to the ImageNet model.",2,7
141,2019-5-18,2019,5,18,2,bpu6h2,Deep learning with computer vision,https://www.reddit.com/r/deeplearning/comments/bpu6h2/deep_learning_with_computer_vision/,pk_kumar_17,1558114275,"Hi everyone. We have started a new publication on medium. It's about deep learning with computer vision. We will be covering everything in computer vision right from the basics to deep dive into Computer Vision. Get rid of deep learning hype and read with us. We will make sure u know more than any deep learning and computer vision course out there. Let's read, learn, understand and build deep learning and computer vision systems together. 

Like, share and subscribe.

&amp;#x200B;

All the sessions will be updated weekly so make sure you don't miss out. Thanks.

&amp;#x200B;

[https://medium.com/hitchhikers-guide-to-deep-learning/introduction-to-computer-vision-with-deep-learning-filters-and-kernels-a65eadc9edeb](https://medium.com/hitchhikers-guide-to-deep-learning/introduction-to-computer-vision-with-deep-learning-filters-and-kernels-a65eadc9edeb)",6,13
142,2019-5-18,2019,5,18,3,bpv57h,What to do next,https://www.reddit.com/r/deeplearning/comments/bpv57h/what_to_do_next/,jahifu,1558119116,I have done  course from applied ai. It includes all machine learning and deep learning complete course . Tell me what I can do next and I m not good with the. Coding . Give me some suggestions....,2,0
143,2019-5-18,2019,5,18,8,bpy41i,Data augmentation on irregular graph ?,https://www.reddit.com/r/deeplearning/comments/bpy41i/data_augmentation_on_irregular_graph/,piapple,1558134555,"Is it possible to do data augmentation on irregular graph, similar to image rotation, cropping, resizing ?? 

How helpful is data augmentation on image classification ? ?  Is it helpful on irregular graph as well ? What is your thought ?",3,3
144,2019-5-18,2019,5,18,19,bq2rtm,What is a good custom PC build for deep learning with a budget of around 1 lakh INR (1300 USD)? Or should I just get a new laptop?,https://www.reddit.com/r/deeplearning/comments/bq2rtm/what_is_a_good_custom_pc_build_for_deep_learning/,NidoAnhsirk,1558176967,"Right now I use an Alienware 14(2014)

Specs: 8GB RAM ----- Nvidia GT750M with 2GB VRAM ----- i7 4700MQ

&amp;#x200B;

I'm willing to build a new system on my own, but I'm confused with what my specs should be and what components I should go for. I won't be taking part in competitions(I guess) but will use it for intense research applications.",9,0
145,2019-5-18,2019,5,18,19,bq2s8b,Indian Digits Dataset via CMATERdb in easy to use NumPy format,https://www.reddit.com/r/deeplearning/comments/bq2s8b/indian_digits_dataset_via_cmaterdb_in_easy_to_use/,op_prabhuomkar,1558177069,"CMATERdb is the pattern recognition database repository created at the 'Center for Microprocessor Applications for Training Education and Research' (CMATER) research laboratory, Jadavpur University, Kolkata 700032, INDIA. This database is free for all non-commercial uses. 

**Dataset Description:**

* **CMATERdb 3.1.1: Handwritten Bangla numeral database** is a balanced dataset of total 6000 Bangla numerals (32x32 RGB coloured, 6000 images), each having 600 images per classs(per digit).
* **CMATERdb 3.2.1: Handwritten Devanagari numeral database** is a balanced dataset of total 3000 Bangla numerals (32x32 RGB coloured, 3000 images), each having 300 images per classs(per digit).
* **CMATERdb 3.4.1: Handwritten Telugu numeral database** is a balanced dataset of total 3000 Bangla numerals (32x32 RGB coloured, 3000 images), each having 300 images per classs(per digit).

**Links:**

[GitHub Repository](https://github.com/prabhuomkar/CMATERdb)

[Download Link](https://github.com/prabhuomkar/CMATERdb#get-the-data)

Please acknowledge CMATER explicitly, whenever you use this database for academic and research purposes.",0,28
146,2019-5-18,2019,5,18,20,bq2wfn,Number of capsules in the Primary Capsule Layer of Capsule networks,https://www.reddit.com/r/deeplearning/comments/bq2wfn/number_of_capsules_in_the_primary_capsule_layer/,PyWarrior,1558178024,"What is the Number of capsules in the Primary Capsule Layer of Capsule networks?

&amp;#x200B;

In many articles, it is written that the number of Capsules is 32 but in the paper, by Hinton - **Dynamic Routing between capsules** it is written that   
*""In total PrimaryCapsules has \[32  6  6\]*

*capsule outputs (each output is an 8D vector) and each capsule in the \[6  6\] grid is sharing their*

*weights with each other.""*   


which implies that the layer has 36 capsules.",1,1
147,2019-5-18,2019,5,18,22,bq48lz,Explaining a Deep Learning Black-box Using Deep Variational Information Bottleneck Approach,https://www.reddit.com/r/deeplearning/comments/bq48lz/explaining_a_deep_learning_blackbox_using_deep/,aiforworld2,1558187680,"By Carnegie Mellon University 

https://blog.ml.cmu.edu/2019/05/17/explaining-a-black-box-using-deep-variational-information-bottleneck-approach/",0,2
148,2019-5-18,2019,5,18,23,bq4coq,Usefulness of Deep Learning Analysis for the Diagnosis of Malignancy in Intraductal Papillary Mucinous Neoplasms of the Pancreas,https://www.reddit.com/r/deeplearning/comments/bq4coq/usefulness_of_deep_learning_analysis_for_the/,aiforworld2,1558188403,"Intraductal papillary mucinous neoplasms (IPMNs) are precursor lesions of pancreatic adenocarcinoma. Artificial intelligence (AI) is a mathematical concept whose implementation automates learning and recognizing data patterns. The aim of this study was to investigate whether AIviadeep learning algorithms using endoscopic ultrasonography (EUS) images of IPMNs could predict malignancy.

(Open Access)

https://journals.lww.com/ctg/Pages/articleviewer.aspx?year=9000&amp;issue=00000&amp;article=99976&amp;type=Abstract",0,2
149,2019-5-19,2019,5,19,0,bq4w05,Self-supervised learning in the area of aesthetics,https://www.reddit.com/r/deeplearning/comments/bq4w05/selfsupervised_learning_in_the_area_of_aesthetics/,malaysian_abroad,1558191633,"How can we leverage self-supervised learning in evaluating ""aestheticsness"" of an image? Does anyone have experience with that?",0,3
150,2019-5-19,2019,5,19,1,bq5nqz,Product Matching with Deep Learning,https://www.reddit.com/r/deeplearning/comments/bq5nqz/product_matching_with_deep_learning/,two_a_day,1558195959,,2,16
151,2019-5-19,2019,5,19,3,bq79um,Data Science at Scale,https://www.reddit.com/r/deeplearning/comments/bq79um/data_science_at_scale/,HannahHumphreys,1558204851,[removed],0,1
152,2019-5-19,2019,5,19,15,bqdif3,Creating Big-Ass Network,https://www.reddit.com/r/deeplearning/comments/bqdif3/creating_bigass_network/,Geeks_sid,1558245939,[removed],0,1
153,2019-5-19,2019,5,19,18,bqf0qa,Anyone working on machine learning in fluid mechanics?,https://www.reddit.com/r/deeplearning/comments/bqf0qa/anyone_working_on_machine_learning_in_fluid/,krayzius_wolf,1558258517,I have a few questions,6,4
154,2019-5-19,2019,5,19,18,bqf25y,Autopilot written in Tensorflow for Self Driving Cars,https://www.reddit.com/r/deeplearning/comments/bqf25y/autopilot_written_in_tensorflow_for_self_driving/,LeonDeHill,1558258808,,2,39
155,2019-5-19,2019,5,19,20,bqfo5u,RMSProp moving average: step-size(window size),https://www.reddit.com/r/deeplearning/comments/bqfo5u/rmsprop_moving_average_stepsizewindow_size/,Rowing0914,1558263630,"Hi, morning! it's a bit off-topic tho, I found the interesting question regarding RMSprop.

what is the step-size(window size) of the moving average??

&amp;#x200B;

No information on the internet as far as Professor Google showed me..... so I assume that ppl just use the accumulated moving average from the beginning of the training. but I think if the moving average is the average from the beginning of the learning, it might contain some bad losses..

&amp;#x200B;

so if we can construct a purely clean moving average, RMSprop can work better i guess.",0,1
156,2019-5-19,2019,5,19,21,bqg64e,The Pattern Machine (new Deep Learning series by Art of the Problem focuses on key insights),https://www.reddit.com/r/deeplearning/comments/bqg64e/the_pattern_machine_new_deep_learning_series_by/,britcruise,1558267462,,0,9
157,2019-5-20,2019,5,20,0,bqih7o,Time-series Denoising State-of-the-art Architectures,https://www.reddit.com/r/deeplearning/comments/bqih7o/timeseries_denoising_stateoftheart_architectures/,arjundupa,1558281277,"I've been trying to find state-of-the-art architectures for time-series denoising. Because there doesn't seem to be a standard baseline for this task, I'm finding it difficult to compare various architectures.

So far, I've come across:

1. Asymmetric GAN ([https://link.springer.com/content/pdf/10.1007%2F978-3-319-93040-4\_23.pdf](https://link.springer.com/content/pdf/10.1007%2F978-3-319-93040-4_23.pdf))
2. Deep Feature Loss ([https://arxiv.org/pdf/1806.10522.pdf](https://arxiv.org/pdf/1806.10522.pdf))
3. Wave-U-Net ([https://arxiv.org/pdf/1811.11307v1.pdf](https://arxiv.org/pdf/1811.11307v1.pdf)), or simply WaveNet ([https://arxiv.org/pdf/1706.07162.pdf](https://arxiv.org/pdf/1706.07162.pdf))
4. Denoising Auto-encoders

&amp;#x200B;

What state-of-the-art architectures am I missing?

How can I go about finding which architecture is truly state-of-the-art for time-series denoising?",0,0
158,2019-5-20,2019,5,20,1,bqiu8u,5 min survey on Amazon's AI influence,https://www.reddit.com/r/deeplearning/comments/bqiu8u/5_min_survey_on_amazons_ai_influence/,MihaelGelo,1558283199," 

Hello everyone! As a master degree candidate in The Netherlands, I'm doing a research on to what extent Amazon's e-commerce recommendations affect the purchase decisions. If you've purchased something from Amazon in the last 6 months, I would really appreciate 5 minutes of your time to fill in this questionnaire. Sharing is well appreciated! Thank you!

Link to the survey:

[https://erasmusuniversity.eu.qualtrics.com/jfe/form/SV\_0jOW3i5nxkVALT7](https://erasmusuniversity.eu.qualtrics.com/jfe/form/SV_0jOW3i5nxkVALT7)",0,0
159,2019-5-20,2019,5,20,2,bqjiz6,Back-propagation Demystified [Part 1]  Explanation of back-propagation and computational graphs.,https://www.reddit.com/r/deeplearning/comments/bqjiz6/backpropagation_demystified_part_1_explanation_of/,msminhas93,1558286890,,0,3
160,2019-5-20,2019,5,20,3,bqk4sx,Different writing styles for text generation,https://www.reddit.com/r/deeplearning/comments/bqk4sx/different_writing_styles_for_text_generation/,tetrix994,1558290034,"Hello everyone,

I understand how text generation works but I was wondering if there is a way to train a model that can generate text based on our desires. For example, I have some context and I would like it to generate more poetic , more philosophical or let's say a mix between the two of them with more accent on philosophy.

I am not sure how that would be achieved. I know that OpenAI GPT of BERT can generate quite good texts but I am not sure even with fine-tuning on those topic if there is a way to achieve that.

Maybe a way to do that is with adjusting the temperature of the LSTM but I am not really sure.

Does anyone have an idea how that would be implemented?",0,3
161,2019-5-20,2019,5,20,3,bqkdd0,Weakly labeled object detection,https://www.reddit.com/r/deeplearning/comments/bqkdd0/weakly_labeled_object_detection/,ashiqimran,1558291250,"For my research, I need to use weakly labeled object detection. Anyone can suggest me some good resources on this topic?",0,0
162,2019-5-20,2019,5,20,4,bqkta3,Interested in NLP? Learn how to implement RNNs through Algorithms and Applications in this excellent video tutorial. Good luck!,https://www.reddit.com/r/deeplearning/comments/bqkta3/interested_in_nlp_learn_how_to_implement_rnns/,DiscoverAI,1558293461,,0,0
163,2019-5-20,2019,5,20,4,bqkx18,Make a Face GAN (Generative Adversarial Network) in 15 Minutes,https://www.reddit.com/r/deeplearning/comments/bqkx18/make_a_face_gan_generative_adversarial_network_in/,DiscoverAI,1558293994,,0,31
164,2019-5-20,2019,5,20,4,bql1b9,Image Recognition with Convolutional Neural Networks: Simply Explained,https://www.reddit.com/r/deeplearning/comments/bql1b9/image_recognition_with_convolutional_neural/,DiscoverAI,1558294596,,0,0
165,2019-5-20,2019,5,20,4,bql3wy,Neural Networks: An Excellent Guide for Beginners,https://www.reddit.com/r/deeplearning/comments/bql3wy/neural_networks_an_excellent_guide_for_beginners/,DiscoverAI,1558294976,,0,11
166,2019-5-20,2019,5,20,5,bqlogp,Machine Learning and Data Science with Kaggle,https://www.reddit.com/r/deeplearning/comments/bqlogp/machine_learning_and_data_science_with_kaggle/,DiscoverAI,1558297954,,0,0
167,2019-5-20,2019,5,20,6,bqma9w,PyTorch for the Machine Learning Beginner,https://www.reddit.com/r/deeplearning/comments/bqma9w/pytorch_for_the_machine_learning_beginner/,DiscoverAI,1558301063,,0,0
168,2019-5-20,2019,5,20,7,bqmu3c,Bunch of Deep Learning and ML books are now on sale for $15,https://www.reddit.com/r/deeplearning/comments/bqmu3c/bunch_of_deep_learning_and_ml_books_are_now_on/,ShirleyMoore3,1558303898,,2,5
169,2019-5-20,2019,5,20,9,bqoi7e,Is there a market value for standalone cutting-edge DL algorithms?,https://www.reddit.com/r/deeplearning/comments/bqoi7e/is_there_a_market_value_for_standalone/,rodrigonader,1558313431,"We see many jaw-dropping models being created and becoming open source. Code is released as soon as papers are published and everyone in the field has access to it. Does that mean that by themselves, without a whole set of tools being used together, there is no actual value for those algorithms? For example:

[https://siliconangle.com/2017/05/28/startup-uses-ai-create-gui-source-code-simple-screenshots/](https://siliconangle.com/2017/05/28/startup-uses-ai-create-gui-source-code-simple-screenshots/)

[https://github.com/floydhub/colornet-template](https://github.com/floydhub/colornet-template)

&amp;#x200B;

Turning those into Rest APIs would aggregate value at all? And what is needed for it to become commercial?",2,3
170,2019-5-20,2019,5,20,11,bqpmba,Object Detection in making a map,https://www.reddit.com/r/deeplearning/comments/bqpmba/object_detection_in_making_a_map/,keitaro995,1558319911,"Hello everyone,

I'm working on making a car in simulation that can generate a 2D map using only camera's images(generally adding objects to map by camera's information). I'm thinking of using object detection's results as  input to generate objects in map (for example: if there are 2 or more objects in the image, the model can generate it into a map).

I don't know whether object detection's results can be extracted to do this job,  so can anybody suggest an idea for this task?Thank you and best regards.",0,0
171,2019-5-20,2019,5,20,14,bqrcwb,Excellent Guide on Recurrent Neural Networks,https://www.reddit.com/r/deeplearning/comments/bqrcwb/excellent_guide_on_recurrent_neural_networks/,MammothCost,1558329801,,1,9
172,2019-5-20,2019,5,20,16,bqsc5k,Stock Market Prediction with LSTM network in Python | AI in finance,https://www.reddit.com/r/deeplearning/comments/bqsc5k/stock_market_prediction_with_lstm_network_in/,DevTechRetopall,1558336650,,5,17
173,2019-5-20,2019,5,20,16,bqsl8x,Do you know any online courses in deep learning? Or any useful tips for me as a beginner in this area?,https://www.reddit.com/r/deeplearning/comments/bqsl8x/do_you_know_any_online_courses_in_deep_learning/,MigrantDixie,1558338594,"I decided to start deep learning and actually I don't know what to do at first. I didn't find any courses or teachers who can help me in my city, so started by myself and found only coursera with good feedbacks. But I'm not sure what to do.

By the way, if you're a student or just want to relax from deep learning, you're welcome to my subreddit: r/college_buzz",3,2
174,2019-5-20,2019,5,20,19,bqtq1v,NER model on custom dataset,https://www.reddit.com/r/deeplearning/comments/bqtq1v/ner_model_on_custom_dataset/,ak96,1558347567,"I want to build NER model on custom dataset. Say, I need to recognize features of an electronic product from its manual which essentially means that I need to build NER with a single entity (product-feature). How do I go about doing it in python? Which libraries do you suggest? And for the training data, which do you think is the best annotation tool (commercial or open source)? Is there any way to escape manual labeling by automating it?

Also, please feel free to suggest any other easier solution for this problem.",1,3
175,2019-5-20,2019,5,20,22,bqvdw4,DeepCS: a Code Search Tool Powered by Deep Learning,https://www.reddit.com/r/deeplearning/comments/bqvdw4/deepcs_a_code_search_tool_powered_by_deep_learning/,newthinkingevents,1558358048,"Hey guys, find out more about DeepCS and why this deep learning-based technique performs significantly better than  Lucene-based systems, and even out-performs the state-of-the-art system CodeHow from Robert Rodger at Berlin Buzzwords! Check him out and get your tickets: [https://berlinbuzzwords.de/19/session/deepcs-code-search-tool-powered-deep-learning](https://berlinbuzzwords.de/19/session/deepcs-code-search-tool-powered-deep-learning)

https://i.redd.it/pdc2zys09dz21.jpg",1,5
176,2019-5-21,2019,5,21,0,bqwy1w,Deep learning and arts - An interactive playlist with videos and quizzes!,https://www.reddit.com/r/deeplearning/comments/bqwy1w/deep_learning_and_arts_an_interactive_playlist/,terabapt,1558365901,,3,8
177,2019-5-21,2019,5,21,1,bqxn8y,AWS Cloud Computing for Personal Projects,https://www.reddit.com/r/deeplearning/comments/bqxn8y/aws_cloud_computing_for_personal_projects/,cvantass,1558369160,"Has anyone here had the issue of not having enough computing power to train their own pet projects? Ive got one right now that is pretty much killing my computer to train, so im looking for a way to outsource this training somehow. I came across Amazons AWS cloud computing platform, but I cant say I fully understand how it works. Has anyone used it for such a purpose, or done something similar? Any other suggestions?",13,13
178,2019-5-21,2019,5,21,2,bqy8ai,PhD position open,https://www.reddit.com/r/deeplearning/comments/bqy8ai/phd_position_open/,dee_pandas,1558371881,"Hello. 
I am currently doing my Master's in the USA, and looking forward to doing a PhD in the field after I graduate in summer 2020. My interests are particularly in multimodal language-vision tasks, but I am also interested in core vision problems. 

I know there's a healthy number of people here who are involved with prestigious labs in both the US and Europe. Do you guys know of any possible vacancies for next (2020) fall?",0,0
179,2019-5-21,2019,5,21,3,bqyyep,"Hello, what happens with gitxiv.com ?? he's been offline for a long time",https://www.reddit.com/r/deeplearning/comments/bqyyep/hello_what_happens_with_gitxivcom_hes_been/,Aaron-Ponce-Sandoval,1558375223,,1,1
180,2019-5-21,2019,5,21,3,bqzhpw,"Artificial Intelligence, Machine Learning, and the Future of Prediction with David Weinberger",https://www.reddit.com/r/deeplearning/comments/bqzhpw/artificial_intelligence_machine_learning_and_the/,cpclos,1558377776,,0,0
181,2019-5-21,2019,5,21,5,br0o74,Any bots to train GAN from pinterest?,https://www.reddit.com/r/deeplearning/comments/br0o74/any_bots_to_train_gan_from_pinterest/,NarcolepticNetwork,1558383215,"I'd like to train a GAN by browsing pinterest images. 

Anyone know of a bot that can browse pinterest and send the images (and their tags) as input to a GAN?

Specifically I want to browse all images with a certain tag.",3,1
182,2019-5-21,2019,5,21,8,br35bj,Google Diagnostic AI Aims to Boost Lung Cancer Survival Rates,https://www.reddit.com/r/deeplearning/comments/br35bj/google_diagnostic_ai_aims_to_boost_lung_cancer/,Yuqing7,1558395820,,9,24
183,2019-5-21,2019,5,21,9,br3jua,Excellent and Intuitive Video on Convolutional Neural Networks,https://www.reddit.com/r/deeplearning/comments/br3jua/excellent_and_intuitive_video_on_convolutional/,MammothCost,1558398149,,0,1
184,2019-5-21,2019,5,21,10,br3yp4,Bias Variance Trade-off [Part 1],https://www.reddit.com/r/deeplearning/comments/br3yp4/bias_variance_tradeoff_part_1/,msminhas93,1558400597,,0,4
185,2019-5-21,2019,5,21,11,br4yuq,"This is the 2nd article of series, it's a hands on kernels and their working. It's a little long but I'm sure you'll enjoy it. Feedback is really appreciated.",https://www.reddit.com/r/deeplearning/comments/br4yuq/this_is_the_2nd_article_of_series_its_a_hands_on/,pk_kumar_17,1558406524,,0,2
186,2019-5-21,2019,5,21,13,br5ya8,My implementation of 7 knowledge distillation methods by Tensorflow,https://www.reddit.com/r/deeplearning/comments/br5ya8/my_implementation_of_7_knowledge_distillation/,sseung0703,1558412774,"Hi everyone.

I'm Ph. D student in Korea and my research area is the knowledge distillation. The below link is my Github repo which contains some implemented knowledge distillation method with a short explanation (at now 7 methods).

 [https://github.com/sseung0703/Knowledge\_distillation\_methods\_wtih\_Tensorflow/blob/master/README.md](https://github.com/sseung0703/Knowledge_distillation_methods_wtih_Tensorflow/blob/master/README.md)

&amp;#x200B;

https://i.redd.it/3dowth2erhz21.png",0,1
187,2019-5-21,2019,5,21,14,br69z5,coding deep learning models,https://www.reddit.com/r/deeplearning/comments/br69z5/coding_deep_learning_models/,avradip08,1558415046,"I have basic knowledge about the deep learning field but i feel constrained while applying these concepts into code. Can you help me overcome this issue ?
Please provide some useful resources.",1,3
188,2019-5-21,2019,5,21,14,br6hh5,Signal to Distortion Ratio as Loss Function,https://www.reddit.com/r/deeplearning/comments/br6hh5/signal_to_distortion_ratio_as_loss_function/,arjundupa,1558416550,"I'm trying to de-noise signals using a regular bidirectional RNN. When my loss function is MSE, the model converges relatively quickly and the results are decent.

When I switched to the Signal-to-Distortion-Ratio as my loss function, the model does not seem to learn at all (it is seemingly stuck on spitting out the 0-wave) regardless of how long I train the model for:

&amp;#x200B;

https://i.redd.it/loph3pny2iz21.png

For reference, my implementation of the loss function is here (in Keras):

    def SDR(yTrue,yPred):
        epsilon = 2e-7
        return -K.mean(yPred * yTrue)**2 / (K.mean(yPred**2) + epsilon)

This is actually a function proportional to SDR, as described here: [https://paris.cs.illinois.edu/pubs/venkataramani-apsipa2018.pdf](https://paris.cs.illinois.edu/pubs/venkataramani-apsipa2018.pdf)

Any ideas on why I am getting the results I am?",0,8
189,2019-5-21,2019,5,21,16,br7ezl,Mertons Theory of Scientific Ethos,https://www.reddit.com/r/deeplearning/comments/br7ezl/mertons_theory_of_scientific_ethos/,Usman1234555,1558423819,,1,6
190,2019-5-21,2019,5,21,18,br81eh,Generate Game of Thrones Characters Using StyleGAN,https://www.reddit.com/r/deeplearning/comments/br81eh/generate_game_of_thrones_characters_using_stylegan/,manneshiva,1558429293,"Ever wondered how Snapchat can age you, change your gender, or add makeup to your face? One way is through a nifty Deep Learning algorithm called ""StyleGAN"". Heres everything you need to know about it, all the code you need to implement it, and a sneak preview of what Danaerys and Jon Snows kid might look like. Weve called him Djonerys.

Article link: [https://blog.nanonets.com/stylegan-got/](https://blog.nanonets.com/stylegan-got/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=3dhpe&amp;utm_content=dl)

&amp;#x200B;

&amp;#x200B;

*Processing gif i415o08u4jz21...*",0,1
191,2019-5-21,2019,5,21,18,br878l,Highlights of ICLR 2019,https://www.reddit.com/r/deeplearning/comments/br878l/highlights_of_iclr_2019/,rom1504,1558430540,,4,18
192,2019-5-21,2019,5,21,19,br8wtf,Probability and Statistics for Business and Data Science,https://www.reddit.com/r/deeplearning/comments/br8wtf/probability_and_statistics_for_business_and_data/,HannahHumphreys,1558435904,[removed],0,1
193,2019-5-21,2019,5,21,20,br95wc,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/br95wc/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1558437659,[removed],0,1
194,2019-5-21,2019,5,21,21,br9qb9,The Comprehensive Statistics and Data Science with R,https://www.reddit.com/r/deeplearning/comments/br9qb9/the_comprehensive_statistics_and_data_science/,HannahHumphreys,1558441244,[removed],0,1
195,2019-5-21,2019,5,21,22,bransj,"Build tools in machine learning projects, an overview",https://www.reddit.com/r/deeplearning/comments/bransj/build_tools_in_machine_learning_projects_an/,atomlib_com,1558446655,,0,2
196,2019-5-21,2019,5,21,23,brb6y1,Supervisely: end-to-end web-platform for Deep Learning and Computer Vision,https://www.reddit.com/r/deeplearning/comments/brb6y1/supervisely_endtoend_webplatform_for_deep/,tdionis,1558449518,,0,1
197,2019-5-22,2019,5,22,0,brbn1n,Cant get gpu to work,https://www.reddit.com/r/deeplearning/comments/brbn1n/cant_get_gpu_to_work/,Numanrsheidat,1558451806,"Hello I recently bought a Sager laptop with rtx2070 gpu mainly for deep learning. But I cant get the gpu to work with tensorflow. Tensorflow now recognizes the gpu but whenever I try to run some complex training process I get ""failed to get convolution operation"".This is all with tensorflow-GPU 1.13 and the latest gpu driver, lincudnn 7.5 and cuda 10.0 because as I understood from the forms conda 10.1 is not a good idea. Can anyone please help me.",7,3
198,2019-5-22,2019,5,22,4,brer26,Get discriminator label from GAN,https://www.reddit.com/r/deeplearning/comments/brer26/get_discriminator_label_from_gan/,Bia_CalicoCat,1558467059,"Suppose i trained a CGAN with labels ""real"" or ""fake"" (let's say that a real one is an authentic photgraph and fake is an image produced by another GAN) .

How can i feed it into the trained CGAN and get the discriminator label?",0,0
199,2019-5-22,2019,5,22,6,brfxn0,Facebook Open-Sources Pythia for Vision and Language Multimodal AI Models,https://www.reddit.com/r/deeplearning/comments/brfxn0/facebook_opensources_pythia_for_vision_and/,Yuqing7,1558472898,,5,33
200,2019-5-22,2019,5,22,10,britqk,a role of confidence score in YOLO...?,https://www.reddit.com/r/deeplearning/comments/britqk/a_role_of_confidence_score_in_yolo/,GW_KIM,1558489448,"Hi there, i have question about object detection.

In YOLO, there is a loss about 'there is object in predicted bbox' as confidence score

and In Faster-RCNN there is same kind of thing as YOLO

my question is that, regressed bbox coordinate is trained from bbox ground-truth information, So! i think it includes the information of 'Confidence score'

do it needs 'confidence score' separately...? and why...?",0,1
201,2019-5-22,2019,5,22,14,brkpvn,Image Classification using Transfer Learning in PyTorch,https://www.reddit.com/r/deeplearning/comments/brkpvn/image_classification_using_transfer_learning_in/,spmallick,1558502079,"A question we have often been asked is ""Why PyTorch?""

Well, PyTorch is a joy to work with! It is easy to learn and experiment with, often faster than Tensorflow and as far as popularity is concerned, Google trends show it is gaining momentum.

In our latest article, we describe how to do image classification in PyTorch using transfer learning.  
This post serves as an initial post to a series of upcoming posts, where we apply transfer learning to classify images in different domains such as medical images, art images etc.

[https://www.learnopencv.com/image-classification-using-transfer-learning-in-pytorch/](https://www.learnopencv.com/image-classification-using-transfer-learning-in-pytorch/) 

  
Mention reviews and what you want us to work next, in the comments!

P.S: Have you checked out our Kickstarter Campaign? It's getting amazing support and we would love yours as well!

[https://www.kickstarter.com/projects/satyamallick/ai-courses-by-opencvorg](https://www.kickstarter.com/projects/satyamallick/ai-courses-by-opencvorg)   
Do drop a message if you have any queries regarding the campaign.

https://i.redd.it/vq7e3hv25pz21.png",1,4
202,2019-5-22,2019,5,22,15,brl48q,Is the training fine. I mean the accuracy is already 1 but the training loss is 81.44. Is it okay?,https://www.reddit.com/r/deeplearning/comments/brl48q/is_the_training_fine_i_mean_the_accuracy_is/,crazy_lazy_life,1558505163,,0,0
203,2019-5-22,2019,5,22,15,brl52v,Is the training fine. I mean the accuracy is already 1 but the training loss is 81.44. Is it okay?,https://www.reddit.com/r/deeplearning/comments/brl52v/is_the_training_fine_i_mean_the_accuracy_is/,crazy_lazy_life,1558505343,,0,0
204,2019-5-22,2019,5,22,15,brl5rj,Is the training fine. I mean the accuracy is already 1 but the training loss is 81.44. Is it okay?,https://www.reddit.com/r/deeplearning/comments/brl5rj/is_the_training_fine_i_mean_the_accuracy_is/,crazy_lazy_life,1558505494,,7,0
205,2019-5-22,2019,5,22,18,brmkpl,The best machine learning and deep learning libraries,https://www.reddit.com/r/deeplearning/comments/brmkpl/the_best_machine_learning_and_deep_learning/,raikundalia,1558517421,,0,3
206,2019-5-22,2019,5,22,19,brn659,Python library to control nvidia gpu fan to use more aggressive cooling for DL applications,https://www.reddit.com/r/deeplearning/comments/brn659/python_library_to_control_nvidia_gpu_fan_to_use/,magnusjja,1558521785,,16,39
207,2019-5-22,2019,5,22,23,brpoc1,Autopilot Community. Looking for open source devs and an active community of testers and members.,https://www.reddit.com/r/deeplearning/comments/brpoc1/autopilot_community_looking_for_open_source_devs/,LeonDeHill,1558536431,"Hello everyone, 

we started developing a driving car agent. It's still very experimental so far, so not a really practical agent. But we are working on it. I developed the steering model so far. We are looking for developers and testers and maybe some visionary. 

&amp;#x200B;

Here is the github:  [https://github.com/LeonDeHill/Self-Driving-Car-Tensorflow](https://github.com/LeonDeHill/Self-Driving-Car-Tensorflow) 

And here is our official discord server: [https://discord.gg/nECdb4J](https://discord.gg/nECdb4J) 

Feel free to join and contact me if you have questions.",2,4
208,2019-5-23,2019,5,23,0,brq24l,Computer Graphics + Computer Vision = TensorFlow Graphics,https://www.reddit.com/r/deeplearning/comments/brq24l/computer_graphics_computer_vision_tensorflow/,Yuqing7,1558538397,,0,1
209,2019-5-23,2019,5,23,1,brr1hz,What RAM speed needs for DL ?,https://www.reddit.com/r/deeplearning/comments/brr1hz/what_ram_speed_needs_for_dl/,Atralb,1558543360,"Do you guys know if we need high speed RAM for deep learning ? Can it be a bottleneck in the workflow or even the base speed of DDR4 (2133Mhz) is already well enough ?  


For reference if this is dependent on the setup, I've got a Threadripper 1920X and one 2080 Ti for now.",3,0
210,2019-5-23,2019,5,23,2,brrjq9,[Research]Developing a Self-driving Algorithm for Deployment on a Real Car,https://www.reddit.com/r/deeplearning/comments/brrjq9/researchdeveloping_a_selfdriving_algorithm_for/,cdossman,1558545881," [https://medium.com/ai%C2%B3-theory-practice-business/developing-a-self-driving-algorithm-for-deployment-on-a-real-car-8e9139ab4c00](https://medium.com/ai%C2%B3-theory-practice-business/developing-a-self-driving-algorithm-for-deployment-on-a-real-car-8e9139ab4c00) 

Abstract:  This paper describes the exploration and learnings during the process of developing a self-driving algorithm in simulation, followed by deployment on a real car. We specifically concentrate on the Formula Student Driverless competition. In such competitions, a formula race car, designed and built by students, is challenged to drive through previously unseen tracks that are marked by traffic cones. We explore and highlight the challenges associated with training a deep neural network that uses a single camera as input for inferring car steering angles in real-time. The paper explores in-depth creation of simulation, usage of simulations to train and validate the software stack and then finally the engineering challenges associated with the deployment of the system in real-world.",0,4
211,2019-5-23,2019,5,23,3,brs3w8,TensorWatch  Debugging and Visualization Tool Designed for Deep Learning,https://www.reddit.com/r/deeplearning/comments/brs3w8/tensorwatch_debugging_and_visualization_tool/,sytelus,1558548748,"TensorWatch is a debugging and visualization tool designed for deep learning. It fully leverages Jupyter Notebook to show real time visualizations and offers unique capabilities to query the live training process without having to sprinkle logging statements all over. You can also use TensorWatch to build your own UIs and dashboards. In addition, TensorWatch leverages several excellent libraries for visualizing model graph, review model statistics, explain prediction and so on.

&amp;#x200B;

https://i.redd.it/a5iljo910tz21.png

**GitHub:** [https://github.com/microsoft/tensorwatch](https://github.com/microsoft/tensorwatch)",4,18
212,2019-5-23,2019,5,23,5,brtvkb,CAN SOMEONE HELP ME IN UNDERSTANDING REGULARIZATION?,https://www.reddit.com/r/deeplearning/comments/brtvkb/can_someone_help_me_in_understanding/,FlyingPig01,1558557362,"Also please help me with some projects that I can start building as a complete noob.

Any video coding a neural network from scratch will be highly appreciated. Thanks :)",4,0
213,2019-5-23,2019,5,23,5,brtxt1,Robot arm manipulation using learning,https://www.reddit.com/r/deeplearning/comments/brtxt1/robot_arm_manipulation_using_learning/,Migom6,1558557668,What are the possible ways to find out trajectory for a robot arm to move to a desired goal (using camera). The robot that I'm working on is baxter. I'm searching for some learning algorithm where we don't have to find the inverse kinematics explicitly and the robot learns itself by some kind of reward system or loss function.,4,1
214,2019-5-23,2019,5,23,12,bryej3,Is it wise to learn from scratch? No library,https://www.reddit.com/r/deeplearning/comments/bryej3/is_it_wise_to_learn_from_scratch_no_library/,TheDigitalRhino,1558582770,"I've been teaching myself deep learning. Initially, I decided I would build a vanilla NN, CNN, and RNN only using only numpy. So far I've built a NN, and I'm making my way through an RNN (stuck on BBTT). I've spent nearly a month building these networks (work/college). I have learned a good amount of the fundamentals, but I'm worried I may just be wasting my time. I do plan on using something like keras if I make anything for production. Do you think I should finish up the RNN and CNN, or should I just move to a library?",8,18
215,2019-5-23,2019,5,23,14,brzb8w,Help regarding working with video datasets,https://www.reddit.com/r/deeplearning/comments/brzb8w/help_regarding_working_with_video_datasets/,smukh98,1558589071,"Hey all,I have started working on a self project using UCSD Dataset .I need a little help on how to work with video.My objective is to detect abnormalities like bicyclist among pedestrian etc. I know I have to extract the video frames ,after that I am completely clueless.I have read some papers which use HOG + SVM to classify but they don't tell how they apply it on videos.

Thanks in advance",1,3
216,2019-5-23,2019,5,23,18,bs0ych,Machine Learning Specialization,https://www.reddit.com/r/deeplearning/comments/bs0ych/machine_learning_specialization/,HannahHumphreys,1558604957,[removed],0,1
217,2019-5-23,2019,5,23,20,bs1vid,Final Year Project Ideas,https://www.reddit.com/r/deeplearning/comments/bs1vid/final_year_project_ideas/,AhmedZubairGCU,1558611599,I am looking to do my final year project in deep learning and I am looking for some ideas. I have been looking into some research papers to get some ideas but i cannot think of applying those techniques into some practical application. Can someone provide some good ideas to work on.,3,2
218,2019-5-23,2019,5,23,20,bs1vu9,Evolving the topology of a neural network - Neuroevolution Neural Networ...,https://www.reddit.com/r/deeplearning/comments/bs1vu9/evolving_the_topology_of_a_neural_network/,DevTechRetopall,1558611655,,0,13
219,2019-5-23,2019,5,23,21,bs2j7b,Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-based Image Retrieval,https://www.reddit.com/r/deeplearning/comments/bs2j7b/semantically_tied_paired_cycle_consistency_for/,AnjanDutta,1558615690,PyTorch implementation of the SEM-PCYC model for zero-shot sketch-based image retrieval is available at: [https://github.com/AnjanDutta/sem-pcyc](https://github.com/AnjanDutta/sem-pcyc). Check out the paper at: [https://arxiv.org/abs/1903.03372](https://arxiv.org/abs/1903.03372),0,2
220,2019-5-23,2019,5,23,22,bs2xl5,Free CNN | TF Web App Tutorial: Fashion MNIST Dataset,https://www.reddit.com/r/deeplearning/comments/bs2xl5/free_cnn_tf_web_app_tutorial_fashion_mnist_dataset/,nillicent,1558618004,[**https://ibm-developer.link/deeplylearnt\_fashionista**](https://ibm-developer.link/deeplylearnt_fashionista),0,4
221,2019-5-24,2019,5,24,0,bs45bk,"ACM Announces Best Doctoral Paper, Learning to Learn with Gradients",https://www.reddit.com/r/deeplearning/comments/bs45bk/acm_announces_best_doctoral_paper_learning_to/,Yuqing7,1558624382,,0,21
222,2019-5-24,2019,5,24,1,bs4w3s,How do I get started with Reinforcement Learning?,https://www.reddit.com/r/deeplearning/comments/bs4w3s/how_do_i_get_started_with_reinforcement_learning/,pakodanomics,1558628130,"Hi. I am a Computer Science student and am currently powering through Andrew Ng's ML course. I am interested in learning about Reinforcement Learning.

I am not just interested in learning about the current libraries and modules available for implementing RL, I am interested in learning about the underlying algorithms and mathematics as well, from a further research point of view.

I would also need some resources for the prerequisite topics in ML, Maths, Data Analytics and Programming.

My current background:

1 Sem of Programming in C and Python

1 Sem of Data Structures and Algorithms

1 Sem of Single-Variable Calculus

1 Sem of Linear Algebra

Upcoming: 1 sem of Probability and Statistics, 1 sem of Discrete Maths

How should I go about learning and practising RL?

Thanks.",0,1
223,2019-5-24,2019,5,24,1,bs5681,[P] PyTorch implementation of SEM-PCYC model for zero-shot sketch-based image retrieval,https://www.reddit.com/r/deeplearning/comments/bs5681/p_pytorch_implementation_of_sempcyc_model_for/,AnjanDutta,1558629520,,1,2
224,2019-5-24,2019,5,24,2,bs5t7c,Deep Learning based Image Classification in PyTorch,https://www.reddit.com/r/deeplearning/comments/bs5t7c/deep_learning_based_image_classification_in/,sunitanyk,1558632738,,1,1
225,2019-5-24,2019,5,24,6,bs8hxd,Samsung AI lab develops tech that can animate highly realistic heads using only a few -or in some cases - only one starter image. (Paper: https://arxiv.org/abs/1905.08233),https://www.reddit.com/r/deeplearning/comments/bs8hxd/samsung_ai_lab_develops_tech_that_can_animate/,ai-lover,1558646587,,16,145
226,2019-5-24,2019,5,24,7,bs96ay,Samsung AI Makes the Mona Lisa Speak,https://www.reddit.com/r/deeplearning/comments/bs96ay/samsung_ai_makes_the_mona_lisa_speak/,Yuqing7,1558650345,,0,1
227,2019-5-24,2019,5,24,14,bscxnx,Techniques for Object localisation,https://www.reddit.com/r/deeplearning/comments/bscxnx/techniques_for_object_localisation/,smukh98,1558674521,"Hey all,I have started working on project where I have to find pedestrian and non pedestrian .for that I need to localise them .Can anyone suggest a few techniques .I have read regarding rcnn and yolo but they localise and detect whereas I only need localisation .Any sort of help is appreciated.

Thanks",1,2
228,2019-5-24,2019,5,24,14,bsd0x0,"How to use ELMO, BERT, ULMFit, etc with PyTorch?",https://www.reddit.com/r/deeplearning/comments/bsd0x0/how_to_use_elmo_bert_ulmfit_etc_with_pytorch/,the_parallax_II,1558675278,"Hello,

here has been a great development in recent years regarding transfer learning in NLP. I'd like to take advantage of the techniques mentioned in the title BUT i can't figure out the proper way to do it. Coding and training it from scratch is either extremely hard or impossible! PyTorch itself doesn't provide something native in order to use those pretrained models. ULMfit appears in [fast.ai](https://fast.ai/), ELMO in Allen NLP and BERT in the github repository of hugginface.

I will do my BSc Thesis in Deep Learning &amp; Sentiment Analysis and i can't find good resources in order to learn how to use them. For instance, the example in the github repository of hugginface regarding text classification with BERT, is 1000 lines of code which is kinda discouraging.

Has anyone worked with them in PyTorch? Could someone guide me on how to approach this?

Thank you very much :)",4,3
229,2019-5-24,2019,5,24,14,bsd8uw,Regarding sampling from graphical models,https://www.reddit.com/r/deeplearning/comments/bsd8uw/regarding_sampling_from_graphical_models/,sriharsha_0806,1558677072,"I am reading Structured Probabilistic models for Deep learning chapter of  DeepLearning textbook by Ian goodfellow. I did not get the intuition of the following paragraphs.

&amp;#x200B;

""Otherwise, the conditional distributions we need to sample from are the posterior distributions given the observed variables. These posterior distributions are usually not explicitly specified and parameterized in the model. Inferring these posterior distributions can be costly. In models where this is the case, ancestral sampling is no longer efficient"" 3rd paragraph of sampling from graphical models.

&amp;#x200B;

Can anyone explain this?",2,1
230,2019-5-24,2019,5,24,16,bse4d4,Please help me start machine learning.,https://www.reddit.com/r/deeplearning/comments/bse4d4/please_help_me_start_machine_learning/,hariprasath891996,1558684493,"Hey guys, I was drawn into deep learning by its prowess to solve complex real-life problems. Here's the issue. I'm not a computer science student and I don't know any coding. I started to learn Python 3 on codecademy, is that enough? I don't feel confident enough to move forward to machine learning. Please do recommend a good source to learn enough python for machine and deep learning. Also, I'm planning to take Andrew Ng's machine learning and deep learning course. Heard that the machine learning course is based on Matlab and other languages and not python. Should I still take the course or do you have a more programming friendly machine learning course for me?",5,0
231,2019-5-24,2019,5,24,18,bseui4,Reinforcement Learning for time series forecasting,https://www.reddit.com/r/deeplearning/comments/bseui4/reinforcement_learning_for_time_series_forecasting/,dangling_pntr,1558690810,"I've been reading this [paper](https://www.intechopen.com/online-first/training-deep-neural-networks-with-reinforcement-learning-for-time-series-forecasting). This paper deals with forecasting the next point in time series using reinforcement learning, it uses Deep Belief networks trained with stochastic gradient ascent. I've able to grasp most of the paper. but I am not able to understand the  PI function(eq 16) and step 2 of the SGA algorithm. it says **Predict a future data y\_t=x\_t+1 according to a probability y\_t(x\_t,w) with ANN models which are constructed by parameters W.** 

and the step 4 of the same algorithm where they compute the characteristic eligibility e\_i(t) which is the partial derivative of the log of PI function parameterized by x\_t and w with respect to w\_i.

&amp;#x200B;

can anyone please explain what the author is trying to say here?",2,0
232,2019-5-24,2019,5,24,21,bsgb8l,How do I train GPT-2 on my chat history?,https://www.reddit.com/r/deeplearning/comments/bsgb8l/how_do_i_train_gpt2_on_my_chat_history/,FlyingQuokka,1558700865,"I exported chats from Telegram (total of 732k messages), and I put them all in one text file where each line has the format, ""Sender: message"". I passed this file to the gpt-2-finetuning repository code.  

Am I doing this right? How long should I train?",0,1
233,2019-5-24,2019,5,24,22,bsgxjh,DataScience Digest - Issue #17,https://www.reddit.com/r/deeplearning/comments/bsgxjh/datascience_digest_issue_17/,flyelephant,1558704487,,0,2
234,2019-5-24,2019,5,24,22,bsgyoe,Explorations in Deep Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/bsgyoe/explorations_in_deep_reinforcement_learning/,SiddhantNadkarni,1558704660,,0,0
235,2019-5-25,2019,5,25,1,bsiu8s,"[R] Anjan Dutta and Zeynep Akata. Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-based Image Retrieval, CVPR, 2019",https://www.reddit.com/r/deeplearning/comments/bsiu8s/r_anjan_dutta_and_zeynep_akata_semantically_tied/,AnjanDutta,1558714546,,0,1
236,2019-5-25,2019,5,25,1,bsiyol,"[R] Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-based Image Retrieval, Anjan Dutta and Zeynep Akata, CVPR 2019.",https://www.reddit.com/r/deeplearning/comments/bsiyol/r_semantically_tied_paired_cycle_consistency_for/,AnjanDutta,1558715179,,3,41
237,2019-5-25,2019,5,25,1,bsj2hh,"Moving Camera, Moving People: Google AIs Deep Learning Approach to Depth Prediction",https://www.reddit.com/r/deeplearning/comments/bsj2hh/moving_camera_moving_people_google_ais_deep/,Yuqing7,1558715711,,0,8
238,2019-5-25,2019,5,25,2,bsjr9b,Paper Submissions Break NeurIPS 2019 Paper Submission System,https://www.reddit.com/r/deeplearning/comments/bsjr9b/paper_submissions_break_neurips_2019_paper/,Yuqing7,1558719200,,0,1
239,2019-5-25,2019,5,25,5,bslhvw,Build your own deep learning models on Azure Data Science Virtual Machines,https://www.reddit.com/r/deeplearning/comments/bslhvw/build_your_own_deep_learning_models_on_azure_data/,brminnick,1558728060,,0,2
240,2019-5-25,2019,5,25,7,bsnkrw,"Can an lstm autoencoder learn functions like max, min, and median for time series?",https://www.reddit.com/r/deeplearning/comments/bsnkrw/can_an_lstm_autoencoder_learn_functions_like_max/,pk12_,1558738787,"Guys

Can an lstm autoencoder learn functions like max, min, and median for time series?

Basically, we can get fairly useful information using summary statistics for time series data. I am wondering if we can do away with statistics and let autoencoder learn similar features.

Can you suggest me relevant paper or tutorial?",2,1
241,2019-5-25,2019,5,25,10,bsp72r,"Hello! I am Mauricio Costa (aka Maurice Cost), and I have just started a small show on Youtube where I create softwares from famous series and movies.",https://www.reddit.com/r/deeplearning/comments/bsp72r/hello_i_am_mauricio_costa_aka_maurice_cost_and_i/,mauricecost,1558749018,"It's summer and time to meet new people, have different experiences, and experiment new things (joining Reddit is one of those things for me - I am still figuring out how this works)

Having said that, I have just started a small show on Youtube where I recreate some of the softwares and applications that are used in movies and films that contribute to the comedy of these TV shows.

For this first week, I created Silicon Valley's Hot Dog Identifying App!

Would you mind giving your feedback?

You can check it out here: [https://youtu.be/eWoAW23tMYU](https://youtu.be/eWoAW23tMYU)

You can also ask me anything :)",0,3
242,2019-5-25,2019,5,25,12,bsq3nf,Turning a Semantically Labeled UnrealEngine Scene into Video,https://www.reddit.com/r/deeplearning/comments/bsq3nf/turning_a_semantically_labeled_unrealengine_scene/,rozgo,1558755129,Testing a new GStreamer + UnrealEngine pipeline and decided to try vid2vid first. I expect better results with a better semantic map. The semantic map was created with a custom post-process material and depth pass.,0,1
243,2019-5-25,2019,5,25,12,bsq6ry,"Turning a Semantically Labeled UnrealEngine Scene into ""Photo-real"" Video",https://www.reddit.com/r/deeplearning/comments/bsq6ry/turning_a_semantically_labeled_unrealengine_scene/,rozgo,1558755738,,4,63
244,2019-5-25,2019,5,25,23,bsuv92,Mathematics for Machine Learning,https://www.reddit.com/r/deeplearning/comments/bsuv92/mathematics_for_machine_learning/,HannahHumphreys,1558793154,[removed],0,1
245,2019-5-26,2019,5,26,0,bsvm6a,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/bsvm6a/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1558797443,[removed],0,1
246,2019-5-26,2019,5,26,0,bsvqz0,Free Ai-as-a-service for text summarization,https://www.reddit.com/r/deeplearning/comments/bsvqz0/free_aiasaservice_for_text_summarization/,theamrzaki,1558798170,[removed],0,1
247,2019-5-26,2019,5,26,1,bswkqs,NLP crash course w/ Spacy,https://www.reddit.com/r/deeplearning/comments/bswkqs/nlp_crash_course_w_spacy/,tarunn2799,1558802531,"Hey, so I'm a sophomore at uni rn and I've worked with Computer Vision predominantly, and I have a fair understanding of its concepts. I've been given an assignment to build a chatbot for a small company,  where we extract information from text and feed it to their pre-built RPA engine.   
Anyway, I've to start the assignment in a few days, and I've no experience with NLP before. With some quick reading, I found out Spacy provides industry grade APIs for NLP, and it's fairly easy to implement as well.  

I just need a few resources where I can brief myself with the basic concepts of NLP asap, and then resources for where I can learn how to implement a chatbot using spacy. 

&amp;#x200B;

Thank you!",1,1
248,2019-5-26,2019,5,26,2,bsx8i4,Bunch of books on Deep Learning &amp; Machine Learning are on sale for 48hours more,https://www.reddit.com/r/deeplearning/comments/bsx8i4/bunch_of_books_on_deep_learning_machine_learning/,RebekahPagan,1558806060,,2,1
249,2019-5-26,2019,5,26,5,bsyv76,First Article on Deep Learning! StarGAN,https://www.reddit.com/r/deeplearning/comments/bsyv76/first_article_on_deep_learning_stargan/,brokemybackagain,1558814458,"[https://medium.com/@ashwinbhat2906/deep-learning-notes-stargan-f5506c2ce833](https://medium.com/@ashwinbhat2906/deep-learning-notes-stargan-f5506c2ce833)

Please give it A read and let me know if any suggestions or improvements.",0,11
250,2019-5-26,2019,5,26,7,bt0qtq,[D] ML oriented career path,https://www.reddit.com/r/deeplearning/comments/bt0qtq/d_ml_oriented_career_path/,kokyle,1558824736,"Hi folks! I'd like to hear your opinion about potential convergence of my career path, so feel free to write whatever you think.

I'm second year student (double major in computer science and pure math). I've been on the internship in Microsoft last year (worked on HoloLens) and I'll be doing it again this summer. I'm primarily interested in machine learning and computer vision in general, but I'd like to be very precise with these terms. I'm not planning to pursue any kind of research or academia positions, but software engineering role. CV would be field of interest, but from engineering point of view. Since I have strong mathematical background and solid development skills my ultimate goal would be to combine those two ""with ML on top of it"".

My question is: is it actually possible and reasonable to pursue such a career?",1,5
251,2019-5-26,2019,5,26,11,bt2wf2,Delight me Plz..,https://www.reddit.com/r/deeplearning/comments/bt2wf2/delight_me_plz/,DrDumbenstein,1558838361,,2,0
252,2019-5-26,2019,5,26,11,bt32i6,Guide to Landing Machine Learning and Software Engineering Internships,https://www.reddit.com/r/deeplearning/comments/bt32i6/guide_to_landing_machine_learning_and_software/,DiscoverAI,1558839467,,0,12
253,2019-5-26,2019,5,26,16,bt57e3,Gradient boosting research papers from the last 25 years,https://www.reddit.com/r/deeplearning/comments/bt57e3/gradient_boosting_research_papers_from_the_last/,benitorosenberg,1558855939,"&amp;#x200B;

[https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers](https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers)

A curated list of gradient boosting research papers with implementations from the following conferences.

Machine learning:

1. NeurIPS
2. ICML
3. ICLR

Computer vision:

1. CVPR
2. ICCV
3. ECCV

Natural language processing:

1. ACL
2. NAACL
3. EMNLP

Data Mining:

1. KDD
2. ICDM
3. CIKM
4. WWW

Artificial intelligence:

1. AAAI
2. IJCAI
3. UAI
4. AISTATS",2,33
254,2019-5-26,2019,5,26,20,bt6ugw,"This video goes over a breast cancer diagnosis model that uses neural networks, implemented in python.",https://www.reddit.com/r/deeplearning/comments/bt6ugw/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1558869957,,0,1
255,2019-5-26,2019,5,26,21,bt7dmr,Advanced Regression Optimization with Neural Networks RMSProp - Neural ...,https://www.reddit.com/r/deeplearning/comments/bt7dmr/advanced_regression_optimization_with_neural/,DevTechRetopall,1558873823,,3,7
256,2019-5-27,2019,5,27,3,btb9xf,Am I building a correct LSTM model?,https://www.reddit.com/r/deeplearning/comments/btb9xf/am_i_building_a_correct_lstm_model/,MLforYay,1558895137,"I'm a beginner, and very new to this subject. So I've been wanting to do a lstm model for prediction of disease using deep learning studio. I've tried to find numerous tutorial on how to do lstm for prediction of diseaset and found one which isn't related to disease prediction. I have a dataset with numerical attributes. But the tutorial I found is titled as ""IMDB Review Sentiment Prediction using CNN LSTM"". I followed every step as shown in the video and I'm getting results but I'm not sure if I'm getting correct results because in the youtube video it's shown that model goes like this:  
 Input-&gt;Embedding Layer-&gt;Convolution1d layer-&gt;Maxpooling layer-&gt;Lstm layer-&gt;Dense Layer-&gt;Output.

So I searched for embedding layer, and got that embedding layer is generally used for NLP and other words prediction models. Is using embedding layer correct in my model of predicting a disease dataset? Also since I'm newb, I want to learn why the steps are going the way as it is shown in the video, like embedding to convulutional to maxpooling and so on.",2,3
257,2019-5-27,2019,5,27,3,btbdrm,Ncnn vs tflite on Android in 2019,https://www.reddit.com/r/deeplearning/comments/btbdrm/ncnn_vs_tflite_on_android_in_2019/,soham24,1558895645, Which framework is more optimized for mobile deployment.,0,8
258,2019-5-27,2019,5,27,4,btc8ox,Implementing K-Means Clustering From Scratch: Simply Explained,https://www.reddit.com/r/deeplearning/comments/btc8ox/implementing_kmeans_clustering_from_scratch/,DiscoverAI,1558899853,,1,3
259,2019-5-27,2019,5,27,6,btdjoj,Excellent Guide to Securing Machine Learning Internships,https://www.reddit.com/r/deeplearning/comments/btdjoj/excellent_guide_to_securing_machine_learning/,MammothCost,1558906360,,0,0
260,2019-5-27,2019,5,27,17,btjh4x,"hi . I've decided to create a podcast about deep learning  machine learning  artifical inteligence , neuroscience ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ?",https://www.reddit.com/r/deeplearning/comments/btjh4x/hi_ive_decided_to_create_a_podcast_about_deep/,Doctor_who1,1558945196," 

hi . I've decided to create a podcast about deep learning  machine learning  artifical inteligence , neuroscience ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ?",16,12
261,2019-5-27,2019,5,27,20,btl2oy,anyone saw the new AMD 5 Third-Gen Ryzen CPU which Including 12-Core as I'm planning to build a workstation I wonder what would be the best combination.,https://www.reddit.com/r/deeplearning/comments/btl2oy/anyone_saw_the_new_amd_5_thirdgen_ryzen_cpu_which/,view2killu,1558957646,"as I'm planning to build a new deep learning work station, wonder what would be the best configuration to combine this CPU and   and the GeForce RTX 2080 Graphics Card. any idea guys? any recommendations for the motherboard, cooling system, and case that will fit with this CPU? thanks",0,2
262,2019-5-27,2019,5,27,21,btlaxm,Code for this paper!,https://www.reddit.com/r/deeplearning/comments/btlaxm/code_for_this_paper/,ak96,1558959103,"I am trying to build a question answering model for consumer product details and integrate it with our chatbot later. In that research process, I came across this paper titled 'A simple end-to-end question answering model for product information' : [https://aclweb.org/anthology/W18-3105](https://aclweb.org/anthology/W18-3105) 

This is close enough to what I want to achieve. So, can anyone tell me where I can find its code base or at least point me towards articles/github projects with similar objective so that I can have a foundation to build upon.",4,3
263,2019-5-27,2019,5,27,21,btlmu8,"[WIP Book] Deep Learning for Programmers: An Interactive Tutorial with CUDA, OpenCL, MKL-DNN, Java, and Clojure",https://www.reddit.com/r/deeplearning/comments/btlmu8/wip_book_deep_learning_for_programmers_an/,dragandj,1558961287,,0,22
264,2019-5-28,2019,5,28,0,btng4t,How does one extend a neural network to classify new objects not in the training data?,https://www.reddit.com/r/deeplearning/comments/btng4t/how_does_one_extend_a_neural_network_to_classify/,brandojazz,1558971680,"[https://stats.stackexchange.com/questions/401217/extending-a-neural-network-to-classify-new-objects](https://stats.stackexchange.com/questions/401217/extending-a-neural-network-to-classify-new-objects)

&amp;#x200B;

[https://www.quora.com/unanswered/How-does-one-extend-a-neural-network-to-classify-new-objects-not-in-the-training-data?\_\_filter\_\_=&amp;\_\_nsrc\_\_=2&amp;\_\_snid3\_\_=4512097721](https://www.quora.com/unanswered/How-does-one-extend-a-neural-network-to-classify-new-objects-not-in-the-training-data?__filter__=&amp;__nsrc__=2&amp;__snid3__=4512097721)",0,1
265,2019-5-28,2019,5,28,2,btp29s,10 takeaways from the fast.ai Massive Open Online Course (MOOC),https://www.reddit.com/r/deeplearning/comments/btp29s/10_takeaways_from_the_fastai_massive_open_online/,prdmagnet,1558979744,,0,0
266,2019-5-28,2019,5,28,4,btq2t5,Network Architect,https://www.reddit.com/r/deeplearning/comments/btq2t5/network_architect/,thanku_next,1558984627,"I have a slight technical background and have been working on a project involving a lot of network and database architecture. 

It's made me very interested in network architecture and I was wondering where I could get started learning about it and becoming one?",0,3
267,2019-5-28,2019,5,28,8,btt60e,ARTHuS: Adaptive Real-Time Human Segmentation in Sports through Online Distillation,https://www.reddit.com/r/deeplearning/comments/btt60e/arthus_adaptive_realtime_human_segmentation_in/,josephd,1559001412,,0,13
268,2019-5-28,2019,5,28,10,bttykj,Problem with Generative Adversarial Network for generating anime faces,https://www.reddit.com/r/deeplearning/comments/bttykj/problem_with_generative_adversarial_network_for/,A01u,1559006635,"So recently I've been looking into GANs a lot and I finally decided to make my own anime face generator. I got it to train successfully and has been able to produce images that kinda resemble a face. However, I keep getting an InternalError: GPU sync failed message when I reach about epoch 90. If anyone can help me figure out the problem I would be very thankful.

&amp;#x200B;

Here is my Github repo

[https://github.com/Pie31415/Anime\_GAN/blob/master/dcgan%20anime%20generation.ipynb](https://github.com/Pie31415/Anime_GAN/blob/master/dcgan%20anime%20generation.ipynb)",0,1
269,2019-5-28,2019,5,28,13,btvr5i,Is it possible for an AI to read a PDF and then answer questions about it,https://www.reddit.com/r/deeplearning/comments/btvr5i/is_it_possible_for_an_ai_to_read_a_pdf_and_then/,popcornondemand,1559018334,"I have some PDFs about specific programming languages I found on my computer. Is there a way to have an AI take the text from the PDFs as an input, then be able to answer questions about the language? I'm mostly familiar with Tensorflow and Python, and I'm pretty new to AI and deep learning. Any way to do this?",2,6
270,2019-5-28,2019,5,28,16,btx5iu,Behavioural Cloning,https://www.reddit.com/r/deeplearning/comments/btx5iu/behavioural_cloning/,nachiket273,1559029221,"Behavioural Cloning Implement and blog post :

[https://medium.com/swlh/behavioural-cloning-end-to-end-learning-for-self-driving-cars-50b959708e59?source=friends\_link&amp;sk=b35042f4a8aebf135f10a3dd38a59c5e](https://medium.com/swlh/behavioural-cloning-end-to-end-learning-for-self-driving-cars-50b959708e59?source=friends_link&amp;sk=b35042f4a8aebf135f10a3dd38a59c5e)",0,7
271,2019-5-28,2019,5,28,20,btyo5p,About benign java script data set,https://www.reddit.com/r/deeplearning/comments/btyo5p/about_benign_java_script_data_set/,__sniper,1559041302,"I am working on a project to detect java script codes.But i am not getting core code for P reprocessing  ,any one having benign java script code data-set?",0,0
272,2019-5-28,2019,5,28,20,btytrv,Can apply NLP to a csv file containing dataset obtain by crawling.,https://www.reddit.com/r/deeplearning/comments/btytrv/can_apply_nlp_to_a_csv_file_containing_dataset/,__sniper,1559042441,I am working on a project to detect malicious java scripts . I collected genuine code by crawling in csv formate .Can any one tell that whether i can use that data for preprocessing or not.,6,1
273,2019-5-28,2019,5,28,20,btz2dx,Reconstructing Faces from Voices,https://www.reddit.com/r/deeplearning/comments/btz2dx/reconstructing_faces_from_voices/,taurish,1559044068,,1,17
274,2019-5-28,2019,5,28,21,btze0z,Learning deep learning framework,https://www.reddit.com/r/deeplearning/comments/btze0z/learning_deep_learning_framework/,bikanation,1559046189," I understand machine learning math and deep learning very good as well as new architectures. However i face extreme difficulties when i try to implement or code. I come from a CS background , however i am not used to using high level libraries however i use python on daily basis but not proficient using deep learning frameworks, more used to C++ and JAVA. Can anybody recommend me a path that he followed and worked for him so i can follow too? I prefer pytorch than tensorflow.",1,3
275,2019-5-28,2019,5,28,21,btzjm5,[R] What the Vec? Towards Probabilistically Grounded Embeddings,https://www.reddit.com/r/deeplearning/comments/btzjm5/r_what_the_vec_towards_probabilistically_grounded/,benitorosenberg,1559047169,,0,1
276,2019-5-28,2019,5,28,23,bu0p9w,Any good tutorials on deep writing?,https://www.reddit.com/r/deeplearning/comments/bu0p9w/any_good_tutorials_on_deep_writing/,Anomalix,1559053830,"I want to make an AI that writes text based on what I trained it on (say, a novel). 

I know there's programs for that already, but I want to make one almost from scratch, so I can learn how it works as I go.",0,2
277,2019-5-29,2019,5,29,0,bu16r5,How does SGD come in the picture for Sequence to Sequence models?,https://www.reddit.com/r/deeplearning/comments/bu16r5/how_does_sgd_come_in_the_picture_for_sequence_to/,real_pinocchio,1559056325,,0,0
278,2019-5-29,2019,5,29,0,bu1l24,"Live demo of a dataset (""NSFW"" ML trained model) shared/monetized through Ethereum",https://www.reddit.com/r/deeplearning/comments/bu1l24/live_demo_of_a_dataset_nsfw_ml_trained_model/,jbrg,1559058402,,0,0
279,2019-5-29,2019,5,29,1,bu1uyy,Machine Learning with AWS AI and IBM Watson,https://www.reddit.com/r/deeplearning/comments/bu1uyy/machine_learning_with_aws_ai_and_ibm_watson/,HannahHumphreys,1559059785,[removed],0,1
280,2019-5-29,2019,5,29,2,bu2k1f,Why Relu activation function is non linear?,https://www.reddit.com/r/deeplearning/comments/bu2k1f/why_relu_activation_function_is_non_linear/,srinu1746,1559063142,When input is greater than zero output looking like linear curve only?,4,1
281,2019-5-29,2019,5,29,2,bu2sns,Deep learning databases,https://www.reddit.com/r/deeplearning/comments/bu2sns/deep_learning_databases/,SlickLikeOwl,1559064272,Where can i find some databases to use in my machine learning models?,1,2
282,2019-5-29,2019,5,29,2,bu2xwa,A question on Tensorflow's receptive field table,https://www.reddit.com/r/deeplearning/comments/bu2xwa/a_question_on_tensorflows_receptive_field_table/,deep_curiosity,1559064977,"I'm getting more interests and curiosity in receptive fields (RF). I've found Tensorflow's RF calculation library and their analysis on well-known networks. Here is the link: [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/receptive\_field/RECEPTIVE\_FIELD\_TABLE.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/receptive_field/RECEPTIVE_FIELD_TABLE.md)

&amp;#x200B;

It says, for example \`resnet\_v2\_101\` with input size 321x321, \`resnet\_v2\_101/block4\` has RF size of 1027x1027. Isn't this insanely large RF? Much larger than its input size. 

&amp;#x200B;

So far I've used \`resnet\_v2\_101\` in several projects, but without caring for RF sizes. It turns out the RF size seems huge. How should I interpret this?",0,3
283,2019-5-29,2019,5,29,5,bu4t6z,Explanation of how BERT architecture gets 110M parameters,https://www.reddit.com/r/deeplearning/comments/bu4t6z/explanation_of_how_bert_architecture_gets_110m/,pascaltuna,1559073991,Are there any good resources explaining how the BERT architecture gets 110M parameter size for BERTBase.,0,0
284,2019-5-29,2019,5,29,5,bu5buv,I wanted to know what will happen to a generative network if I switch off its neurons one by one,https://www.reddit.com/r/deeplearning/comments/bu5buv/i_wanted_to_know_what_will_happen_to_a_generative/,ale152,1559076485,,10,80
285,2019-5-29,2019,5,29,14,buar6r,NER from Excel data,https://www.reddit.com/r/deeplearning/comments/buar6r/ner_from_excel_data/,tarunn2799,1559107840,"I have an Excel spreadsheet containing several thousand 'tickets'(techincal complaints) generated by employees in a company for category of issues such as CPU Error, Disk error etc.  and a column having a detailed explanation of each ticket, take CPU Error for instance, its description will contain the CPU Usage, Device ID, and the process which is taking up that much power, but in a paragraph format. 

I'm supposed to extract the required entities/parameters from the description of the tickets, and pass it to the company's RPA backend which will resolve the issue based on the parameters fed to it. 

&amp;#x200B;

I'm a noobie in NLP, so please help me out on what optimal approach I can choose to successfully extract the Category-specific entity data from over 5000 such entries. Manual annotation seems too tedious to implement here.",0,0
286,2019-5-29,2019,5,29,16,bubmys,"torchgpipe, A GPipe implementation in PyTorch",https://www.reddit.com/r/deeplearning/comments/bubmys/torchgpipe_a_gpipe_implementation_in_pytorch/,sublee,1559114759,"[https://github.com/kakaobrain/torchgpipe](https://github.com/kakaobrain/torchgpipe)

Kakao Brain announces torchgpipe, an implementation of GPipe in PyTorch as a handy library.

GPipe is a scalable pipeline parallelism library published by Google Brain. It leverages the training of a giant model which requires much memory. For instance, Google trained AmoebaNet-B with 557M parameters over GPipe.",0,6
287,2019-5-29,2019,5,29,16,bubtj6,Document/Sequence vector generation with multihead self attention,https://www.reddit.com/r/deeplearning/comments/bubtj6/documentsequence_vector_generation_with_multihead/,666BlackJesus666,1559116347,"I coded this model, implementing Transformer(Vaswani et.al.)'s encoder part only, with fully connected layers following that, basically its partial BERT(contextual attention from both sides of a given token), but the objective is to rank a given sequence, trained end to end. The learnt attentionised vectors can be transferred to anything ranging from sentiment analysis to clustering sequences or documents. I further aim to do heirarchical clustering of the inputs.
[Here is the git link](https://github.com/llStringll/Transformer-model-encoder)
I would like for people on this subreddit to go through it and suggest improvements
Thanks",0,7
288,2019-5-29,2019,5,29,20,budc4w,Looking for a simple implementation of YOLO Loss function,https://www.reddit.com/r/deeplearning/comments/budc4w/looking_for_a_simple_implementation_of_yolo_loss/,the_mediocreGuy,1559128481,"Hey reddit,   


I'm trying to implement a tiny version of YOLO to predict bounding boxes in images. I have a model of just 5 layers so I don't have a big network.   


Can someone help with any resources to find a simple implementation of YOLO Loss Function, preferably in TensorFlow?  
I've been through a lot of GitHub repos but they all seem to have complex architecture and difficult to understand loss functions.   


If you could help me out, that'd be great.   


Thank You!",2,10
289,2019-5-29,2019,5,29,20,budr4z,Machine Learning with AWS AI and IBM Watson,https://www.reddit.com/r/deeplearning/comments/budr4z/machine_learning_with_aws_ai_and_ibm_watson/,HannahHumphreys,1559131100,[removed],0,1
290,2019-5-29,2019,5,29,21,bueb3x,Is it possible to 'Rent' Deep learning datasets/AIModels?,https://www.reddit.com/r/deeplearning/comments/bueb3x/is_it_possible_to_rent_deep_learning/,blrm,1559134421,,0,1
291,2019-5-29,2019,5,29,23,bufahe,Deep Learning in R,https://www.reddit.com/r/deeplearning/comments/bufahe/deep_learning_in_r/,HannahHumphreys,1559139819,[removed],0,1
292,2019-5-30,2019,5,30,2,buhehh,"What are some good public data sets/algorithm pairings that are good for an advanced beginner, but represent more production/business use cases?",https://www.reddit.com/r/deeplearning/comments/buhehh/what_are_some_good_public_data_setsalgorithm/,ezeeetm,1559150140,,0,1
293,2019-5-30,2019,5,30,2,buhxfg,[Research] Few-Shot Adversarial Learning of Realistic Neural Talking Head Models,https://www.reddit.com/r/deeplearning/comments/buhxfg/research_fewshot_adversarial_learning_of/,cdossman,1559152729," [https://medium.com/ai%C2%B3-theory-practice-business/creating-personalized-photo-realistic-talking-head-models-34302d247f9b](https://medium.com/ai%C2%B3-theory-practice-business/creating-personalized-photo-realistic-talking-head-models-34302d247f9b) 

**Abstract:**  Several recent works have shown how highly realistic human head images can be obtained by training convolutional neural networks to generate them. In order to create a personalized talking head model, these works require training on a large dataset of images of a single person. However, in many practical scenarios, such personalized talking head models need to be learned from a few image views of a person, potentially even a single image. Here, we present a system with such few-shot capability. It performs lengthy meta-learning on a large dataset of videos, and after that is able to frame few- and one-shot learning of neural talking head models of previously unseen people as adversarial training problems with high capacity generators and discriminators. Crucially, the system is able to initialize the parameters of both the generator and the discriminator in a person-specific way, so that training can be based on just a few images and done quickly, despite the need to tune tens of millions of parameters. We show that such an approach is able to learn highly realistic and personalized talking head models of new people and even portrait paintings",1,12
294,2019-5-30,2019,5,30,6,bukmlc,ML Community Raises Inclusivity Concerns After IEEE Bars Huawei Paper Reviewers,https://www.reddit.com/r/deeplearning/comments/bukmlc/ml_community_raises_inclusivity_concerns_after/,Yuqing7,1559166028,,0,17
295,2019-5-30,2019,5,30,11,bunuh2,Speech2face by MIT ( Paper Download Link:- https://arxiv.org/pdf/1905.09773.pdf?fbclid=IwAR0h1EZQK_FS93MKNF_azctrvhbKRlFhsgdkP5kRXl13OV75ImOh25xNLzI),https://www.reddit.com/r/deeplearning/comments/bunuh2/speech2face_by_mit_paper_download_link/,ai-lover,1559183766,,0,0
296,2019-5-30,2019,5,30,16,buq3dm,"HMDB51 and UCF101 datasets have 3 splits,is it cross validation structure?",https://www.reddit.com/r/deeplearning/comments/buq3dm/hmdb51_and_ucf101_datasets_have_3_splitsis_it/,albert1905,1559199875,"Hi, I have a question about HMDB51 and UCF101 datasets for video action recognition, they have 3 splits, split-1,split-2 and split-3.
Inside of each split it  has another split: train/test or train/val/test.

The way to work with those datasets is to train on split-1 and test on split-1?
the train on split-2 and test on split-2...?
so on..

 Any experience with those datasets for someone?
Thanks.",0,1
297,2019-5-30,2019,5,30,16,buqaw4,Head Pose Estimation using OpenCV and Dlib,https://www.reddit.com/r/deeplearning/comments/buqaw4/head_pose_estimation_using_opencv_and_dlib/,spmallick,1559201617,,2,35
298,2019-5-30,2019,5,30,17,buqkqa,Fully random nets,https://www.reddit.com/r/deeplearning/comments/buqkqa/fully_random_nets/,ToolTechSoftware,1559204048,What are the performance of multilayer forward feed but with random connections between any layer?,10,1
299,2019-5-30,2019,5,30,17,buqs3c,[Discussion] Sentiment Analysis on Videos,https://www.reddit.com/r/deeplearning/comments/buqs3c/discussion_sentiment_analysis_on_videos/,order_chaos_in,1559205958,"
Hello All,
Looking for advice on how to perform sentiment analysis on videos with or without audio? Any pointers to existing thread, project, discussion will be helpful. Even your thoughts on how to preprocess videos, appropriate model architecture would be great. 

My apologies for repost if this has been discussed already. However, as suggested by mod I have googled it online and searched this thread before posting.

Thanks for your time",0,2
300,2019-5-30,2019,5,30,18,bur0ht,The Rise of DataOps - Why Legacy Data Governance Is Broken In the Machine Learning Era,https://www.reddit.com/r/deeplearning/comments/bur0ht/the_rise_of_dataops_why_legacy_data_governance_is/,cmstrump,1559208042,"With adding a consistent version system across all of the code the art of coding moved from craft to engineering - the same thing will happen to data governance: [The Rise of DataOps (from the ashes of Data Governance)](https://towardsdatascience.com/the-rise-of-dataops-from-the-ashes-of-data-governance-da3e0c3ac2c4) (full article)

Currently, data governance teams attempt to apply manual control at various points to control the consistency and quality of the data. The introduction of [DVC](https://dvc.org/) version tracking would allow data governance and engineering teams to engineer the data together, filing bugs against data versions, applying quality control checks to the data compilers, etc.",0,5
301,2019-5-30,2019,5,30,18,bur0x0,artificial intelligence software development company,https://www.reddit.com/r/deeplearning/comments/bur0x0/artificial_intelligence_software_development/,clarke2106,1559208135," 

Artificial intelligence is the most prevalent innovation in the present time. It empowers Machines to take in something from his past encounters. Machines will work as people. Self Driving vehicles are the best case of Artificial intelligence Technology. So on the off chance that you need to use this Artificial intelligence for your business and you should contact a specialist for Artificial intelligence improvement.

In the event that you are searching for the [AI Solutions](http://www.rajasri.com/ai-software-development.html) advancement organization, there a various man-made brainpower improvement organizations are accessible over the world and not every one of the organizations is giving finished **Artificial intelligence Services**. A few organizations just giving different AI improvement administrations. Picking the correct organization likewise a basic errand for entrepreneurs.

&amp;#x200B;

[ artificial intelligence app for android ](https://i.redd.it/e9uwdqhqgb131.png)

**Rajasri Systems**is the [artificial intelligence development](http://www.rajasri.com/ai-software-development.html) and offering complete **Artificial intelligence development services**.We created applications by using a standout amongst the most prevalent innovations Artificial intelligence and conveyed drawing in applications to different ventures. Specialists the individuals who are utilizing applications dependent on AI can without much of a stretch break down the data identified with their buyers. It aids a positive way while connecting with their client and upgrades the capacity of people.

Our Artificial intelligence Services are

1.Machine Learning

2.Cognitive service

3.Natural Language processing

4.Chatbot Development

5.Deep Learning &amp; etc.

We pursue an exceptional system and way to deal with conveying total **Artificial intelligence**answer for our customers. We have a devoted group of engineers who have a great deal of understanding and learning in [artificial intelligence software development company](http://www.rajasri.com/ai-software-development.html) and can guarantee to give best Ai administrations dependent on your prerequisites which will improve the business. Whatever the application thought you have in your psyche possibly it is troublesome or simple, We can change it into the real world

How Our **AI Development** can support your business

1. It upgrades the Sales of your business
2. It investigates the client conduct and finds the intended interest group
3. It backings clients through AI Personal Assistant with discourse acknowledgment.",0,0
302,2019-5-30,2019,5,30,22,but8n9,Writing billion songs with C# and Deep Learning,https://www.reddit.com/r/deeplearning/comments/but8n9/writing_billion_songs_with_c_and_deep_learning/,atomlib_com,1559223299,,0,2
303,2019-5-31,2019,5,31,0,buubnb,Free cloud GPU credits for deep learning,https://www.reddit.com/r/deeplearning/comments/buubnb/free_cloud_gpu_credits_for_deep_learning/,whitezl0,1559229033,"Hi, I am offering free credits for 1080Ti GPU instances for deep learning purposes  more than 12hrs for free

I am working on [https://www.tensorpad.com/](https://www.tensorpad.com/?utm_source=reddit&amp;utm_campaign=deeplearning)  developing cloud infrastructure for machine learning.

Part of our computational capacity is idle; hence, were offering credits at a free and discounted rate, so that data scientists can benefit from the resources available, and work on neural networks.

Specs:
	60GB of RAM, 4 CPUs, 1080Ti GPU
	JupyterLab environment with access to the terminal
	Pre-installed Tensorflow, Keras, and other ML frameworks 

You can access the free credits by signing up ([https://dashboard.tensorpad.com/](https://dashboard.tensorpad.com/signup?utm_source=reddit&amp;utm_campaign=deeplearning) and redeeming ""promo450"" promo code in the Billing tab ([https://dashboard.tensorpad.com/billing](https://dashboard.tensorpad.com/billing?utm_source=reddit&amp;utm_campaign=deeplearning)).

For any questions, please contact us here, through support@tensorpad.com, or the Intercom on the site.",3,43
304,2019-5-31,2019,5,31,1,buv9p7,Hands-on Graph Neural Networks with PyTorch &amp; PyTorch Geometric,https://www.reddit.com/r/deeplearning/comments/buv9p7/handson_graph_neural_networks_with_pytorch/,steeveHuang,1559233921,"PyTorch Geometric is one of the fastest Graph Neural Networks frameworks in the world. In this article, I talked about the basic usage of PyTorch Geometric and how to use it on real-world data. 

[https://medium.com/@huangkh19951228/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8](https://medium.com/@huangkh19951228/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8)",0,2
305,2019-5-31,2019,5,31,1,buviyn,[Project] My implementation of 7 knowledge distillation methods by Tensorflow,https://www.reddit.com/r/deeplearning/comments/buviyn/project_my_implementation_of_7_knowledge/,sseung0703,1559235182,[removed],0,1
306,2019-5-31,2019,5,31,1,buvkq5,Comparison of Symbolic Deep Leaning Frameworks,https://www.reddit.com/r/deeplearning/comments/buvkq5/comparison_of_symbolic_deep_leaning_frameworks/,munzurmorshed,1559235430,,0,1
307,2019-5-31,2019,5,31,2,buw2es,[Research] Domain Adaptation for Vehicle Detection from Birds Eye View LiDAR Point Cloud Data,https://www.reddit.com/r/deeplearning/comments/buw2es/research_domain_adaptation_for_vehicle_detection/,cdossman,1559237805," [https://medium.com/ai%C2%B3-theory-practice-business/bridging-the-gap-between-synthetic-and-real-point-cloud-data-with-domain-adaptation-da-2a57fdd92939](https://medium.com/ai%C2%B3-theory-practice-business/bridging-the-gap-between-synthetic-and-real-point-cloud-data-with-domain-adaptation-da-2a57fdd92939) 

Abstract:  Point cloud data from 3D LiDAR sensors are one of the most crucial sensor modalities for versatile safety-critical applications such as self-driving vehicles. Since the annotations of point cloud data is an expensive and time-consuming process, therefore recently the utilization of simulated environments and 3D LiDAR sensors for this task started to get some popularity. With simulated sensors and environments, the process for obtaining an annotated synthetic point cloud data became much easier. However, the generated synthetic point cloud data are still missing the artifacts usually exist in point cloud data from real 3D LiDAR sensors. As a result, the performance of the trained models on this data for perception tasks when tested on real point cloud data is degraded due to the domain shift between simulated and real environments. Thus, in this work, we are proposing a domain adaptation framework for bridging this gap between synthetic and real point cloud data. Our proposed framework is based on the deep cycle-consistent generative adversarial networks (CycleGAN) architecture. We have evaluated the performance of our proposed framework on the task of vehicle detection from a birds eye view (BEV) point cloud images coming from real 3D LiDAR sensors. The framework has shown competitive results with an improvement of more than 7% in average precision score over other baseline approaches when tested on real BEV point cloud images.",0,1
308,2019-5-31,2019,5,31,3,buwwsu,What is curClass?,https://www.reddit.com/r/deeplearning/comments/buwwsu/what_is_curclass/,eyun89,1559242035,"I'm trying to follow along a dog breed identification tutorial and the author is creating a folder named \`curClass\`. I did a google search with ""curclass"" and ""Deep Learning"" and it is showing up multiple times without explanation. What is it and what is it's purpose?",0,1
309,2019-5-31,2019,5,31,4,buxltu,Getting to Know Keras for New Data Scientists,https://www.reddit.com/r/deeplearning/comments/buxltu/getting_to_know_keras_for_new_data_scientists/,OpenDataSciCon,1559245571,,0,6
310,2019-5-31,2019,5,31,7,buzlof,Is there any framework recommended to start with text to image recognition?,https://www.reddit.com/r/deeplearning/comments/buzlof/is_there_any_framework_recommended_to_start_with/,not_stoic,1559256004,"Hey! I'm new to this community and also I'm working on a project that might have a good scenario to implement text recognition in order to output images for them. Specifically its for autoparts standarization.  
Please, if anyone knows where I could start or which tools I could try it would be great!  
Thanks!",0,1
311,2019-5-31,2019,5,31,14,bv3j6y,Is it possible to make a reinforcement learning framework good at multiple undefined tasks of the same type?,https://www.reddit.com/r/deeplearning/comments/bv3j6y/is_it_possible_to_make_a_reinforcement_learning/,onlynone00,1559279901,"I know that a reinforcement learning framework can become superhumanly good at a given task over time, but what if I need it to be good at multiple tasks, given that all of them follow similar kind of steps.",6,10
312,2019-5-31,2019,5,31,20,bv6eza,How to build a model playing Super Mario Bros using reinforcement learning and tensorflow,https://www.reddit.com/r/deeplearning/comments/bv6eza/how_to_build_a_model_playing_super_mario_bros/,invadrvranjes,1559302530,,0,8
313,2019-5-31,2019,5,31,20,bv6ffp,"As a Machine Learning/Deep Learning expert working on heavy projects, what kind of specs are under the hood of your computer?",https://www.reddit.com/r/deeplearning/comments/bv6ffp/as_a_machine_learningdeep_learning_expert_working/,NidoAnhsirk,1559302625,"Also, can you compare and contrast the pros and cons of working with laptops and custom-built computers for DL/ML?",18,19
314,2019-5-31,2019,5,31,21,bv6utv,Udacitys course on secure and private ML just launched (its free!),https://www.reddit.com/r/deeplearning/comments/bv6utv/udacitys_course_on_secure_and_private_ml_just/,alhparsa,1559305373,,0,47
315,2019-5-31,2019,5,31,21,bv73ia,Generating Comments from Titles with Transformer models,https://www.reddit.com/r/deeplearning/comments/bv73ia/generating_comments_from_titles_with_transformer/,DoeL,1559306823,,0,4
0,2019-6-1,2019,6,1,9,bvf530,"Hello! I am Mauricio Costa, and I am gathering some feedback on the second episode of my small show where I create software from famous series and movies!",https://www.reddit.com/r/deeplearning/comments/bvf530/hello_i_am_mauricio_costa_and_i_am_gathering_some/,mauricecost,1559349929," I have recently joined Reddit, and its been an awesome experience to get feedback and constructive criticism from a lot of people! Loved it :) (I applied a lot of the feedback I got from the first episode on this new one)

Having said that, I have just started a small show on Youtube where I recreate software and applications that are used in movies and films that contribute to the comedy of these TV shows.

I have just posted the second episode, where I recreate Dwight Schrutes doomsday device from The Office!

Would you mind giving your feedback?

You can check it out here: https://youtu.be/WxkZMDmDQcs

Ask me anything :D",1,3
1,2019-6-1,2019,6,1,11,bvfujo,How can I automate event detection in a short video?,https://www.reddit.com/r/deeplearning/comments/bvfujo/how_can_i_automate_event_detection_in_a_short/,Brokoba,1559354672,"At my workplace, we have a video system set up to capture certain remote events that occur, which we can analyze later on. The only problem is that we have to manually tag the starting and ending points of each event within the video.

For example, a video might last for 12 seconds, with the actual event occurring from seconds 4-9. In the next video, though, the event might occur from seconds 3-7, or 3.5-8.5. As it currently stands, we have to manually monitor the video and click ""start"" and ""end"" buttons to denominate the actual event marks. All events look roughly similar to the naked eye.

This feels like a great opportunity for automation (potentially with some sort of CNN?), but I'm not totally sure how, or even what sort of framework would work for this sort of problem.

Any and all help would be appreciated. Thanks!!",3,5
2,2019-6-1,2019,6,1,16,bviaoq,how i can download transcript talks at google youtube channel https://www.youtube.com/watch?v=ByvPp5xGL1I,https://www.reddit.com/r/deeplearning/comments/bviaoq/how_i_can_download_transcript_talks_at_google/,Doctor_who1,1559374041,"how i can download transcript talks at google youtube channel

&amp;#x200B;

 [https://www.youtube.com/watch?v=ByvPp5xGL1I](https://www.youtube.com/watch?v=ByvPp5xGL1I)",0,3
3,2019-6-1,2019,6,1,17,bviok7,[AI application] Let your machine play Super Mario Bros!,https://www.reddit.com/r/deeplearning/comments/bviok7/ai_application_let_your_machine_play_super_mario/,1991viet,1559377775,,9,67
4,2019-6-2,2019,6,2,2,bvn5y5,Artificial Intelligence A-Z: Learn How To Build An AI,https://www.reddit.com/r/deeplearning/comments/bvn5y5/artificial_intelligence_az_learn_how_to_build_an/,HannahHumphreys,1559409523,[removed],0,1
5,2019-6-2,2019,6,2,2,bvnjs0,My first ever article. Please have a look.,https://www.reddit.com/r/deeplearning/comments/bvnjs0/my_first_ever_article_please_have_a_look/,crazy_lazy_life,1559411722,,0,1
6,2019-6-2,2019,6,2,5,bvpa4l,Do you know about the startup called Babble Labs?,https://www.reddit.com/r/deeplearning/comments/bvpa4l/do_you_know_about_the_startup_called_babble_labs/,Gabyleon2019,1559421603,"&amp;#x200B;

The one that just got $14 million Series A Financing from Dell Technologies Capital and Intel Capital to Accelerate Speech Technology.

&amp;#x200B;

It is really cool what they're doing. You can check the info here:

&amp;#x200B;

[https://www.linkedin.com/feed/update/urn:li:activity:6540252895328247808](https://www.linkedin.com/feed/update/urn:li:activity:6540252895328247808)

&amp;#x200B;

\#DeepLearning #ArtificialIntelligence #MachineLearning",0,0
7,2019-6-2,2019,6,2,8,bvrbfw,Remember Recurrent Networks?,https://www.reddit.com/r/deeplearning/comments/bvrbfw/remember_recurrent_networks/,MusingEtMachina,1559433369,,2,5
8,2019-6-2,2019,6,2,12,bvt8ze,Do We Still Need Traditional Pattern Recognition and Signal Processing in the Age of Deep Learning?,https://www.reddit.com/r/deeplearning/comments/bvt8ze/do_we_still_need_traditional_pattern_recognition/,ai-lover,1559446148,,5,39
9,2019-6-3,2019,6,3,0,bvycze,nn_builder - a new package that builds neural networks in 1 line,https://www.reddit.com/r/deeplearning/comments/bvycze/nn_builder_a_new_package_that_builds_neural/,__data_science__,1559488451,"nn\_builder is a new package that lets you build neural networks in 1 line using PyTorch or TensorFlow 2.0 that lots of you might find useful!

Let me know what you think and if you'd like to contribute[https://github.com/p-christ/nn\_builder](https://github.com/p-christ/nn_builder)

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/m7dd5z7bmy131.png",2,13
10,2019-6-3,2019,6,3,4,bw137s,"Google struggles to transcribe the dialogs of Donald duck, to hilarious effect.",https://www.reddit.com/r/deeplearning/comments/bw137s/google_struggles_to_transcribe_the_dialogs_of/,Mr_IO,1559503155,,0,1
11,2019-6-3,2019,6,3,5,bw1kyz,Google Cloud Platform is down,https://www.reddit.com/r/deeplearning/comments/bw1kyz/google_cloud_platform_is_down/,karlpoppery,1559505795,"https://status.cloud.google.com/incident/cloud-networking/19009

https://status.cloud.google.com/",2,20
12,2019-6-3,2019,6,3,5,bw1ucs,YouTube AI struggles to transcribe Donald duck https://youtu.be/U_ZHsk0-eF0,https://www.reddit.com/r/deeplearning/comments/bw1ucs/youtube_ai_struggles_to_transcribe_donald_duck/,Mr_IO,1559507184,,2,2
13,2019-6-3,2019,6,3,10,bw4t0q,Donald Trump AI Tries To Imitate Humans,https://www.reddit.com/r/deeplearning/comments/bw4t0q/donald_trump_ai_tries_to_imitate_humans/,hanyuqn,1559524448,,0,3
14,2019-6-3,2019,6,3,13,bw6sfk,Managing DL experiments,https://www.reddit.com/r/deeplearning/comments/bw6sfk/managing_dl_experiments/,guzguzit,1559537527,"Are there any recommended ways  to easily manage and track DL experiments? (Parameters tuning, different models)

Thanks",3,1
15,2019-6-3,2019,6,3,14,bw72n5,Modeling for custom size images,https://www.reddit.com/r/deeplearning/comments/bw72n5/modeling_for_custom_size_images/,roban-12,1559539714,"I have a model which accepts 100\*100 size images and works perfectly when the test image is of the same size too. 

\[Question 1\] Why does the image not work properly when custom size images are given?

\[Question 2\] I want to train the model on custom size imagery. Any kind of suggestions and techniques would be of great help.

I need this urgently, please help!",3,1
16,2019-6-3,2019,6,3,14,bw74nd,CS 294-112. Deep Reinforcement Learning by Sergey Levine. UC Berkeley. Fall 2018,https://www.reddit.com/r/deeplearning/comments/bw74nd/cs_294112_deep_reinforcement_learning_by_sergey/,ai-lover,1559540132,"**Video Lectures:** https://www.youtube.com/playlist?list=PLkFD6\_40KJIxJMR-j5A1mkxK26gh\_qg37

**Lecture Slides:** http://rail.eecs.berkeley.edu/deeprlcourse/ 

&amp;#x200B;

https://i.redd.it/njnwdbkxv2231.png",1,54
17,2019-6-3,2019,6,3,15,bw7hsf,Advanced Machine Learning,https://www.reddit.com/r/deeplearning/comments/bw7hsf/advanced_machine_learning/,HannahHumphreys,1559543080,[removed],0,1
18,2019-6-3,2019,6,3,15,bw7ntg,Deploying large DL models,https://www.reddit.com/r/deeplearning/comments/bw7ntg/deploying_large_dl_models/,guzguzit,1559544501,"Is there a way to deploy large DL models (&gt;1 GB) in a serverless fashion?

I couldent find any relevant  examples",4,0
19,2019-6-3,2019,6,3,17,bw8f5a,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/bw8f5a/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1559551479,[removed],0,1
20,2019-6-3,2019,6,3,20,bw9pyc,HELP! Deep learning API,https://www.reddit.com/r/deeplearning/comments/bw9pyc/help_deep_learning_api/,defudger,1559562309,Hey! We are about to deploy a deep learning API and would need some help from someone with experience. Please send me a message if you have already done something similar so we can work out a deal! Thanks,2,0
21,2019-6-4,2019,6,4,1,bwceks,[Research] Improving Accuracy and Efficiency through AutoML and Model Scaling,https://www.reddit.com/r/deeplearning/comments/bwceks/research_improving_accuracy_and_efficiency/,cdossman,1559578039," [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-google-ai-on-how-to-scale-up-cnn-to-obtain-better-accuracy-and-efficiency-2cc149cc47b1](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-google-ai-on-how-to-scale-up-cnn-to-obtain-better-accuracy-and-efficiency-2cc149cc47b1) 

 Google AI finds a principled method to scale up a CNN to obtain better accuracy and efficiency",0,1
22,2019-6-4,2019,6,4,2,bwd2r1,Searching for dark matter in CERN's Large Hadron Collider dataset,https://www.reddit.com/r/deeplearning/comments/bwd2r1/searching_for_dark_matter_in_cerns_large_hadron/,0_marauders_0,1559581421,,0,20
23,2019-6-4,2019,6,4,2,bwdkd8,Serverless inference,https://www.reddit.com/r/deeplearning/comments/bwdkd8/serverless_inference/,gautkr91,1559583928,,0,0
24,2019-6-4,2019,6,4,3,bwdwva,PyTorch for Beginners Series,https://www.reddit.com/r/deeplearning/comments/bwdwva/pytorch_for_beginners_series/,spmallick,1559585613,,1,5
25,2019-6-4,2019,6,4,8,bwhddq,How does YouTube recommend videos? - AI EXPLAINED!,https://www.reddit.com/r/deeplearning/comments/bwhddq/how_does_youtube_recommend_videos_ai_explained/,ajhalthor,1559603034,,0,2
26,2019-6-4,2019,6,4,15,bwlpwo,Deep Learning In 5 Minutes | What Is Deep Learning? | Deep Learning Explained Simply,https://www.reddit.com/r/deeplearning/comments/bwlpwo/deep_learning_in_5_minutes_what_is_deep_learning/,MainBuilder,1559631407,,0,1
27,2019-6-4,2019,6,4,17,bwmbsy,Using reinforcement learning to trade Bitcoin for massive profit,https://www.reddit.com/r/deeplearning/comments/bwmbsy/using_reinforcement_learning_to_trade_bitcoin_for/,notadamking,1559636862,,37,4
28,2019-6-4,2019,6,4,17,bwmho0,Python or Octave?,https://www.reddit.com/r/deeplearning/comments/bwmho0/python_or_octave/,hariprasath891996,1559638452,"Hey guys, I'm a beginner with no coding experience. I took an introductory course on python from codecademy. I'm currently working on the Machine learning course by Andrew Ng, he recommends using Matlab or Octave. Should I really go for Octave or try to convert the code to python. I'll be moving on from machine learning to deep learning soon after a few hands-on projects. What do you recommend?",18,3
29,2019-6-4,2019,6,4,18,bwmq36,Deploying a Keras Deep Learning Model as a Web Application in Python,https://www.reddit.com/r/deeplearning/comments/bwmq36/deploying_a_keras_deep_learning_model_as_a_web/,ObsidianAge,1559640572,,0,4
30,2019-6-4,2019,6,4,18,bwms9n,Fairseq on custom dataset,https://www.reddit.com/r/deeplearning/comments/bwms9n/fairseq_on_custom_dataset/,aryancodify,1559641101,,0,2
31,2019-6-4,2019,6,4,22,bwogd7,The intuition behind Word2Vec,https://www.reddit.com/r/deeplearning/comments/bwogd7/the_intuition_behind_word2vec/,pmuens,1559653439,,0,1
32,2019-6-5,2019,6,5,1,bwqyiq,[Research]Towards robust audio spoofing detection,https://www.reddit.com/r/deeplearning/comments/bwqyiq/researchtowards_robust_audio_spoofing_detection/,cdossman,1559666922," [https://medium.com/ai%C2%B3-theory-practice-business/achieving-robust-audio-spoofing-detection-b7ebcf0979c6](https://medium.com/ai%C2%B3-theory-practice-business/achieving-robust-audio-spoofing-detection-b7ebcf0979c6) 

Abstract:  Automatic speaker verification, like every other biometric system, is vulnerable to spoofing attacks. Using only a few minutes of recorded voice of a genuine client of a speaker verification system, attackers can develop a variety of spoofing attacks that might trick such systems. Detecting these attacks using the audio cues present in the recordings is an important challenge. Most existing spoofing detection systems depend on knowing the used spoofing technique. With this research, we aim at overcoming this limitation, by examining robust audio features, both traditional and those learned through an autoencoder, that are generalizable over different types of replay spoofing.",0,1
33,2019-6-5,2019,6,5,2,bwrf5v,25 Websites to Find Data Science Jobs,https://www.reddit.com/r/deeplearning/comments/bwrf5v/25_websites_to_find_data_science_jobs/,ai_jobs,1559669273,,1,27
34,2019-6-5,2019,6,5,3,bws13a,CVPR 2019 Noise-Tolerant Training work `Learning to Learn from Noisy Labeled Data 'https://arxiv.org/pdf/1812.05214.pdf,https://www.reddit.com/r/deeplearning/comments/bws13a/cvpr_2019_noisetolerant_training_work_learning_to/,XinshaoWang,1559672298,"This work achieves promising results with meta-learning. Our result on Clothing 1M is comparable with theirs. [https://www.researchgate.net/publication/333418661\_Emphasis\_Regularisation\_by\_Gradient\_Rescaling\_for\_Training\_Deep\_Neural\_Networks\_with\_Noisy\_Labels/comments](https://www.researchgate.net/publication/333418661_Emphasis_Regularisation_by_Gradient_Rescaling_for_Training_Deep_Neural_Networks_with_Noisy_Labels/comments)

However, their modelling via meta-learning seems extremely complex in practice.

1. Too many hyper-parameters shown in their Algorithm 1 and implementation section 4.2:
2. The number of synthetic mini-batches (meta-training iterations) M;
3. Meta-training step size \\alpha;
4. Meta-learning rate \\eta;
5. Student learning rate \\beta;
6. Exponential moving average (EMA) decay \\gamma;
7. The threshold for data filtering \\tau;
8. The number of samples with label replacement, \\rho;
9. The strategies of iterative training together with iterative data filtering/cleaning, reusing last-round best model as mentor, etc., make it difficult to handle in practice.
10. However, the ideas are interesting and novel:
11. Oracle/Mentor (Consistency loss): To make meta-test reliable, the teacher/mentor model should be reliable and robust to real noisy examples. Therefore, they apply iterative training and iterative data cleaning to make the meta-test consistency loss reliable and an optimisation oracle against real noise.
12. Unaffected by synthetic noise: The meta-training sees synthetic noisy training examples. After training on them, the meta-testing evaluates its consistency with oracle and aims to maximise the consistency, i.e., making it unaffected after seeing synthetic noise.

Quetions arise:

Is meta-learning really a good solution in practice with such many configurations?

Or could we simplfiy its modelling to make it easier in practice?",1,1
35,2019-6-5,2019,6,5,3,bws3te,CapsAttacks: Testing Adversarial Attacks on Capsule Networks,https://www.reddit.com/r/deeplearning/comments/bws3te/capsattacks_testing_adversarial_attacks_on/,Yuqing7,1559672684,,0,0
36,2019-6-5,2019,6,5,3,bws7r0,SELU - The best activation function,https://www.reddit.com/r/deeplearning/comments/bws7r0/selu_the_best_activation_function/,ToolTechSoftware,1559673213,,5,9
37,2019-6-5,2019,6,5,10,bwx1zr,Revolutionizing Medical Diagnosis with Deep Learning: TED Talk,https://www.reddit.com/r/deeplearning/comments/bwx1zr/revolutionizing_medical_diagnosis_with_deep/,DiscoverAI,1559699204,,1,14
38,2019-6-5,2019,6,5,15,bwzeqg,Machine Learning Yearning Draft by Andrew Ng [Download Link],https://www.reddit.com/r/deeplearning/comments/bwzeqg/machine_learning_yearning_draft_by_andrew_ng/,ai-lover,1559715825,"&amp;#x200B;

**Download Link :** https://media.licdn.com/dms/document/C511FAQEU5l\_Z5LYcqA/feedshare-document-pdf-analyzed/0?e=1559797200&amp;v=beta&amp;t=9Nz4PucJiq135Q6Vk-LzSKrgZ4isDHoxJXDHbXP80zI

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/az3jzqsbeh231.png",0,20
39,2019-6-5,2019,6,5,20,bx1hdf,"Efficient Net, GPipe or Amoeba Net implementation for Caffe?",https://www.reddit.com/r/deeplearning/comments/bx1hdf/efficient_net_gpipe_or_amoeba_net_implementation/,adriacabeza,1559734105,"Hi, I usually work with Caffe but with pretty common architectures like Resnet50, however the DL game has changed a lot, and I was wondering if there is any version of these classifications state-of-the-art architecture implemented in Caffe. 

&amp;#x200B;

I have been looking for them and I have not found anything.",0,0
40,2019-6-5,2019,6,5,21,bx1ya5,Machine Learning and Reinforcement Learning in Finance,https://www.reddit.com/r/deeplearning/comments/bx1ya5/machine_learning_and_reinforcement_learning_in/,HannahHumphreys,1559737501,[removed],0,1
41,2019-6-5,2019,6,5,22,bx2avr,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/bx2avr/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1559739741,[removed],0,1
42,2019-6-5,2019,6,5,23,bx3i12,[Research] Object Discovery with a Copy-Pasting GAN,https://www.reddit.com/r/deeplearning/comments/bx3i12/research_object_discovery_with_a_copypasting_gan/,cdossman,1559746612," [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-gans-for-object-discovery-d707437ac6c8](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-gans-for-object-discovery-d707437ac6c8) 

**Abstract:** We tackle the problem of object discovery, where objects are segmented for a given input image, and the system is trained without using any direct supervision whatsoever. A novel copy-pasting GAN framework is proposed, where the generator learns to discover an object in one image by compositing it into another image such that the discriminator cannot tell that the resulting image is fake. After carefully addressing subtle issues, such as preventing the generator from cheating, this game results in the generator learning to select objects, as copy-pasting objects is most likely to fool the discriminator. The system is shown to work well on four very different datasets, including large object appearance variations in challenging cluttered backgrounds.",0,9
43,2019-6-6,2019,6,6,0,bx3zuv,Text generation dataset size,https://www.reddit.com/r/deeplearning/comments/bx3zuv/text_generation_dataset_size/,glowycosmos,1559749211,"Hi,

I was wondering how large the size of your training set should be in terms of MB's/GB's when the aim is to build an RNN that can generate semantically and syntactically (more or less) coherent sentences. I saw that OpenAI uses 40 GB of text. Does anyone know of a source which will give me an indiciation of much text is needed?

Much appreciated!",0,1
44,2019-6-6,2019,6,6,2,bx5c2r,PyTorch for Beginners: Semantic Segmentation using torchvision,https://www.reddit.com/r/deeplearning/comments/bx5c2r/pytorch_for_beginners_semantic_segmentation_using/,spmallick,1559755959,,2,69
45,2019-6-6,2019,6,6,11,bxbdpt,AlexNet and VGG-16 on CIFAR-10,https://www.reddit.com/r/deeplearning/comments/bxbdpt/alexnet_and_vgg16_on_cifar10/,BubblyResponsibility,1559788389,"I'm in the process of building an AlexNet architecture and VGG-16 architecture on the CIFAR-10 dataset. Since the dimensions of the CIFAR-10 dataset is different from ImageNet, I keep getting the following error:

**RuntimeError: Given groups=1, weight of size \[64, 64, 3, 3\], expected input\[6, 3, 32, 32\] to have 64 channels, but got 3 channels instead**

&amp;#x200B;

Any help would be appreciated.",1,1
46,2019-6-6,2019,6,6,11,bxbfez,Best one shot object detector for small rogue like video game Image with &gt;150 classes?,https://www.reddit.com/r/deeplearning/comments/bxbfez/best_one_shot_object_detector_for_small_rogue/,podcast_frog3817,1559788681,"Im deciding between retina net and yolov3.   The target image is a rogue like overview 400pxX400px with small sprite characters moving through dungeon (150+ types) each about 32x32px. Ive read retina net has an advantage using focal loss for imbalance between background and foreground wrt objects of interest . Is this useless for this problem? Should I go with yolov3? I am prioritizing speed over accuracy (hence single shot object detection)

Thanks",0,1
47,2019-6-6,2019,6,6,12,bxbypj,Why do attention models need to choose a maximum sentence length?,https://www.reddit.com/r/deeplearning/comments/bxbypj/why_do_attention_models_need_to_choose_a_maximum/,real_pinocchio,1559792136,,1,2
48,2019-6-6,2019,6,6,15,bxd7bl,Converting INT64 to Float32/16 Tensor (ONNX),https://www.reddit.com/r/deeplearning/comments/bxd7bl/converting_int64_to_float3216_tensor_onnx/,iamalex_,1559800886,"So I'm trying to load a certain ONNX model in OpenCV (other models work fine), but with this one it crashes, when using the ONNX float32 &lt;-&gt; float16 conversion it also gives me an error while the one that is able to load in OpenCV doesn't give any error.

&amp;#x200B;

It also gives this error when I try to convert that ONNX model to Tensorflow:  

    ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int64: 'Tensor(""Mul_3:0"", shape=(), dtype=int64)'

I suppose this is why it isn't working in OpenCV, is there any way to cast the int64 Tensor to a float32 one? I can try to modify the float32 &lt;-&gt; float16 conversion function so that it can also convert int64 to float16, but think this could be quite complex.

&amp;#x200B;

Any tips or advice to help me get on the way of solving this problem and/or casting it from int64 to float32 would be greatly appreciated!!",0,0
49,2019-6-6,2019,6,6,15,bxdeye,localize sound source in visual scenes,https://www.reddit.com/r/deeplearning/comments/bxdeye/localize_sound_source_in_visual_scenes/,kzhang3256,1559802514,"We are looking for a pre-trained model to generate sound source heat map from a video. More specifically, input: video + audio, output: a heatmap showing which part of video generates this audio (i.e. engine of a car)

&amp;#x200B;

Anyone knows paper that has public code for this purpose?

Thanks!",0,2
50,2019-6-7,2019,6,7,0,bxhy35,Maths behind training of RNN Networks,https://www.reddit.com/r/deeplearning/comments/bxhy35/maths_behind_training_of_rnn_networks/,prakhar21,1559834468,"Checkout my latest read on [https://prakhartechviz.blogspot.com/2019/04/training-recurrent-neural-networks.html](https://prakhartechviz.blogspot.com/2019/04/training-recurrent-neural-networks.html)

Feel free to share your thoughts.",1,0
51,2019-6-7,2019,6,7,0,bxibts,A Quick Easy Guide to Deep Learning with Java  Deeplearaning4j / DL4J,https://www.reddit.com/r/deeplearning/comments/bxibts/a_quick_easy_guide_to_deep_learning_with_java/,Shilpa_Opencodez,1559836451,,0,1
52,2019-6-7,2019,6,7,1,bxin2b,Deep Learning Prerequisites: The Numpy Stack in Python,https://www.reddit.com/r/deeplearning/comments/bxin2b/deep_learning_prerequisites_the_numpy_stack_in/,NicholasTower,1559838048,,7,18
53,2019-6-7,2019,6,7,2,bxjoqv,"DeepMind's plan to make AI systems robust, why it's a core design issue, and how to succeed in ML",https://www.reddit.com/r/deeplearning/comments/bxjoqv/deepminds_plan_to_make_ai_systems_robust_why_its/,robwiblin,1559843342,,0,9
54,2019-6-7,2019,6,7,14,bxr1e0,Stanford Image-Paragraph-Captioning Dataset Confusion,https://www.reddit.com/r/deeplearning/comments/bxr1e0/stanford_imageparagraphcaptioning_dataset/,arjundupa,1559886165,"I am working with the Stanford Image-Paragraph-Captioning Dataset: [https://cs.stanford.edu/people/ranjaykrishna/im2p/index.html](https://cs.stanford.edu/people/ranjaykrishna/im2p/index.html)

I wanted to see how many image-caption pairs the data set had, so I downloaded the dataset (which downloads paragraphs\_v1.json) and wrote the following code:

    import json
    with open('Desktop/paragraphs_v1.json') as json_file:  
        data = json.load(json_file)
    print(len(data))

**19561** was the output.

Just for a sanity check, I then downloaded the training, val and test splits and tried to see if their total sum would give me the same number:

    with open('Desktop/train_split.json') as train_split:  
        train_split_data = json.load(train_split)
    with open('Desktop/val_split.json') as val_split:  
        val_split_data = json.load(val_split)
    with open('Desktop/test_split.json') as test_split:  
        test_split_data = json.load(test_split)
    print(len(train_split_data) + len(val_split_data) + len(test_split_data))

**19551** was the output.

Exactly 10 short of what I expected. I have no idea why this simple sanity check isn't working -- any ideas?",1,10
55,2019-6-7,2019,6,7,17,bxrym4,Deep Learning Training Institute In India,https://www.reddit.com/r/deeplearning/comments/bxrym4/deep_learning_training_institute_in_india/,SunilAhujaa,1559894850,Analytixlabs offers Deep learning training course with live project by industry expert. This Deep learning course offers practical and task-oriented training using TensorFlow and Keras on Python platform. For more visit here [https://www.analytixlabs.co.in/ai-deep-learning-training-with-python](https://www.analytixlabs.co.in/ai-deep-learning-training-with-python),0,0
56,2019-6-7,2019,6,7,20,bxtqfk,[Book WIP] Deep Learning for Programmers New Release 0.3.0,https://www.reddit.com/r/deeplearning/comments/bxtqfk/book_wip_deep_learning_for_programmers_new/,dragandj,1559908620,,2,1
57,2019-6-8,2019,6,8,0,bxvuqj,Project to fact check and simplify assertions. Opinions?,https://www.reddit.com/r/deeplearning/comments/bxvuqj/project_to_fact_check_and_simplify_assertions/,atticusfinch975,1559920884,"In my work I often have to research different topics and understand something. Often this is a question or a single term I need to understand. Currently, I find I waste a lot if time:

&amp;#x200B;

* Finding the information
   * Wiki
   * Forums
   * Papers
* Checking the veracity of the information
* Simplifying it down so I can understand it
* Simplify the language

&amp;#x200B;

I feel there should be something out there beyond google search and fact checkers. None seem to",0,4
58,2019-6-8,2019,6,8,1,bxwtij,"[Research] Moving Camera, Moving People: A Deep Learning Approach to Depth Prediction",https://www.reddit.com/r/deeplearning/comments/bxwtij/research_moving_camera_moving_people_a_deep/,cdossman,1559925892, [https://medium.com/ai%C2%B3-theory-practice-business/google-ai-how-to-effectively-design-and-implement-simultaneous-motions-in-camera-and-human-3901f0af957](https://medium.com/ai%C2%B3-theory-practice-business/google-ai-how-to-effectively-design-and-implement-simultaneous-motions-in-camera-and-human-3901f0af957),0,1
59,2019-6-8,2019,6,8,2,bxx1wg,[R] Stanford AI system can change what people said.,https://www.reddit.com/r/deeplearning/comments/bxx1wg/r_stanford_ai_system_can_change_what_people_said/,NicoleK1993,1559927077,,7,84
60,2019-6-8,2019,6,8,7,by0qg1,What kind of questions should I expect from a Deep learning internship interview,https://www.reddit.com/r/deeplearning/comments/by0qg1/what_kind_of_questions_should_i_expect_from_a/,zeroeagle1,1559946418,,0,5
61,2019-6-8,2019,6,8,22,by7v0b,Neural Nets with Haskell,https://www.reddit.com/r/deeplearning/comments/by7v0b/neural_nets_with_haskell/,cvantass,1559999705,"Has anyone here ever built a neural net in Haskell? If so, why did you choose Haskell? What were some advantages/disadvantages? 

I ask because the people I really want to work for use Haskell as their language of choice to build some pretty powerful RNNs, and right now all of my projects are in Python/Tensorflow/Keras, and if I want to get in with these guys I gotta translate them to Haskell. Any hints or tips are welcome, but im mostly just wondering why one would choose to use a functional programming language for something like that.",2,1
62,2019-6-9,2019,6,9,2,byakh5,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/byakh5/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1560016201,[removed],0,1
63,2019-6-9,2019,6,9,4,bybb2a,Interesting AI research that requires little compute,https://www.reddit.com/r/deeplearning/comments/bybb2a/interesting_ai_research_that_requires_little/,LeonDeHill,1560020454,,0,16
64,2019-6-9,2019,6,9,8,bye9a8,"Finally did it! Hey everyone! My name is Maurice, new to reddit, and I currently gather feedback here on reddit about the software and applications that I create inspired in movies and TV shows :)",https://www.reddit.com/r/deeplearning/comments/bye9a8/finally_did_it_hey_everyone_my_name_is_maurice/,mauricecost,1560038371,"I started learning face recognition and the OpenCV library for Python a few weeks ago, and it has been an amazing journey! 

BTW, If you do not know me yet, my name is Maurice, and I started a small show on Youtube, where I recreate software and applications from movies and TV shows. 

I strongly believe that every victory should be celebrated, and a few days ago, I managed to wrap my head around some concepts of face recognition and computer vision, and implement it in Python. I feel really good, and I would like to share it with all of you! (Don't give up on your ideas, push through and you'll eventually make it).

It's been an awesome experience to get feedback and constructive criticism from a lot of people here on reddit. For the past a few days, I've been working on the third episode of this show, where I recreated the face recognition from CSI (Crime Scene Investigation).

PS: If you are interested in seeing what I did, it is right here: [https://youtu.be/eTvtUkce4IE](https://youtu.be/eTvtUkce4IE)

Ask me anything :D",2,3
65,2019-6-9,2019,6,9,9,byes9b,PyTorch Linear Layer 2D Input,https://www.reddit.com/r/deeplearning/comments/byes9b/pytorch_linear_layer_2d_input/,arjundupa,1560041761,"I am trying to use PyTorch's nn.Linear to convert a (batch\_size, 41, 2048) input into an output with shape (batch\_size, 2048):

    att_fc = nn.Linear((41, 2048), 2048)

But this gives me the following error:

    TypeError: 'tuple' object cannot be interpreted as an index

Does the linear layer accept only 1D inputs? How can I go about converting my input of shape (batch\_size, 41, 2048) into an output of shape (batch\_size, 2048) using a fully-connected layer?",1,1
66,2019-6-9,2019,6,9,10,byf5sp,PyTorch Model _forward() Parameters,https://www.reddit.com/r/deeplearning/comments/byf5sp/pytorch_model_forward_parameters/,arjundupa,1560044220,"The following is a collection of relevant parts of my code:

    def setup_vectorModel(opt):
        model = vectorModel(opt)
        return model
    
    class vectorModel(AttModel):
        def __init__(self, opt):
            super(vectorModel, self).__init__(opt)
            self.core = vectorCore(opt)
    
    class vectorCore(nn.Module):
        def __init__(self, opt, use_maxout=False):
            super(vectorCore, self).__init__()
            att_fc = nn.Linear(41, 1)
            output_fc = nn.Linear(2, 1)
            
        def forward(self, att_feats, fc_feats):
            att_feats_reshaped = self.att_fc(att_feats)
            concat = torch.cat((att_feats_reshaped, fc_feats), dim=0)
            output = self.output_fc(concat)
            return output
    
    vectorModel = models.setup_vectorModel(opt).cuda()
    dp_vectorModel = torch.nn.DataParallel(vectorModel)
    dp_vectorModel.train()
    
    semantic_features = dp_vectorModel(att_feats, fc_feats)

I get an error on the last line:

    File ""train.py"", line 168, in train
        semantic_features = dp_vectorModel(att_feats, fc_feats)
    File ""/home/arjun/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/modules/module.py"", line 477, in __call__
        result = self.forward(*input, **kwargs)
    File ""/home/arjun/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/parallel/data_parallel.py"", line 121, in forward
        return self.module(*inputs[0], **kwargs[0])
    File ""/home/arjun/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/modules/module.py"", line 477, in __call__
        result = self.forward(*input, **kwargs)
    File ""/home/arjun/image-paragraph-captioning/models/CaptionModel.py"", line 31, in forward
        return getattr(self, '_'+mode)(*args, **kwargs)
    TypeError: _forward() takes at least 4 arguments (3 given)

Any ideas why my \_forward() function seems to require 4 arguments when it looks like it only requires 2? And why the error says 3 given when I only passed it 2 arguments (att\_feats, fc\_feats)?

Any ideas will be much appreciated, thanks!",2,0
67,2019-6-9,2019,6,9,16,byhqi7,How do I begin with hands-on coding with deep learning.?,https://www.reddit.com/r/deeplearning/comments/byhqi7/how_do_i_begin_with_handson_coding_with_deep/,thak123,1560064406,,9,9
68,2019-6-9,2019,6,9,18,byikfp,Hierarchical Softmax Project. Expert review?,https://www.reddit.com/r/deeplearning/comments/byikfp/hierarchical_softmax_project_expert_review/,ashwinkd,1560072821,"I finished my Hierarchical Softmax Project recently. You can read it here: [https://github.com/AshwinDeshpande96/Hierarchical-Softmax](https://github.com/AshwinDeshpande96/Hierarchical-Softmax)

I initially started with Next-Word Prediction Project: LSTM Sequential data prediction. This is where I noticed that the LSTM Network took a very long time to converge. I looked for solutions among which I found Hierarchical Softmax approach the most intriguing. After numerous research papers, post and videos, I was able to implement the network. And also got promising result. But I am concerned about its relevance today. Papers I found dated back to 2005 - (Morin &amp; Bengio) and 2008-(Mnih &amp; Hinton). I would like to know if this is important in today's community. If not please cite reason and possibly other important problems that need work.",0,1
69,2019-6-10,2019,6,10,1,bylzzm,Wasserstein GAN in Swift for TensorFlow,https://www.reddit.com/r/deeplearning/comments/bylzzm/wasserstein_gan_in_swift_for_tensorflow/,rahulbhalley,1560097717,,0,14
70,2019-6-10,2019,6,10,2,bymmhe,How I made top 0.3% on Kaggle,https://www.reddit.com/r/deeplearning/comments/bymmhe/how_i_made_top_03_on_kaggle/,0_marauders_0,1560101118,,3,75
71,2019-6-10,2019,6,10,2,bymqgj,Style transfer,https://www.reddit.com/r/deeplearning/comments/bymqgj/style_transfer/,FoCDoT,1560101700,,0,3
72,2019-6-10,2019,6,10,3,byn98z,U-Net implementation in PyTorch for FLAIR abnormality segmentation in brain MRI,https://www.reddit.com/r/deeplearning/comments/byn98z/unet_implementation_in_pytorch_for_flair/,ketsok,1560104468,,0,2
73,2019-6-10,2019,6,10,3,bynmsd,What Does the Future Hold For AI Salaries? - BlockDelta,https://www.reddit.com/r/deeplearning/comments/bynmsd/what_does_the_future_hold_for_ai_salaries/,BlockDelta,1560106469,,0,0
74,2019-6-10,2019,6,10,5,byol4n,Train E-Net model on SUN-RGBD indoor dataset,https://www.reddit.com/r/deeplearning/comments/byol4n/train_enet_model_on_sunrgbd_indoor_dataset/,vldmr77,1560111553,"Hello,

I posted [this](https://www.reddit.com/r/computervision/comments/byocg2/train_enet_model_on_sunrgbd_indoor_dataset/) in r/computervision too, maybe I can get help here too. I'm trying to train an E-Net model on the [indoor dataset provided by SUN-RGBD](http://rgbd.cs.princeton.edu/), for my diploma project. However, having little to no experience on deep learning, I have trouble understand any tutorial provided on the web. Can anybody help me with a straight-forward one, or a pre-trained model, please?

What I found so far:

[https://github.com/TimoSaemann/ENet/tree/master/Tutorial](https://github.com/TimoSaemann/ENet/tree/master/Tutorial)

[https://github.com/e-lab/ENet-training/tree/master/train/data](https://github.com/e-lab/ENet-training/tree/master/train/data)

[https://github.com/ankurhanda/sunrgbd-meta-data](https://github.com/ankurhanda/sunrgbd-meta-data)

Also, the original article that teach how to do semantic segmentation on outdoor scenes, using a model trained with Cityscapes dataset, where I found the first tutorial:

[https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/](https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/)",0,1
75,2019-6-10,2019,6,10,6,byp28v,Any hands on experience with the CM1K,https://www.reddit.com/r/deeplearning/comments/byp28v/any_hands_on_experience_with_the_cm1k/,Kainkelly2887,1560114055,"Does anyone have any hands on experience with the CM1K? I saw a indie gogo campaign and a blog post that didn't give me much information, looking to pair this with fpgas like in the indie gogo campaign. Just curious if anyone had more in depth or technical experience with this. Seems like a really odd piece of silicon.",0,1
76,2019-6-10,2019,6,10,6,byp8wr,Backpropagation And Gradient Descent In Neural Networks - Tutorial,https://www.reddit.com/r/deeplearning/comments/byp8wr/backpropagation_and_gradient_descent_in_neural/,MainBuilder,1560115061,,0,1
77,2019-6-10,2019,6,10,7,byq4ea,Is it worth picking up K80's @ $200,https://www.reddit.com/r/deeplearning/comments/byq4ea/is_it_worth_picking_up_k80s_200/,dsync1,1560119911,"I can get a lot of 12 Nvida K80's pulled from off-lease equipment at $200/pop. I've only ever worked with consumer-level cards, and am stepping up an application that has models built and requires classification of incoming data. I have a couple of servers I can put these in... Is it worth it? Or are these antiquated? 

The 24gb/Ram looks very enticing?",2,4
78,2019-6-10,2019,6,10,11,bysnlm,Depthwise Conv2d filters,https://www.reddit.com/r/deeplearning/comments/bysnlm/depthwise_conv2d_filters/,piingpoong,1560135549,"Am I correct in my understanding of depthwise conv2d? if the input image is 8x8x3 and there is 1 filter, which is 3x3x1, the output would be 6x6x3? The same filter is applied to each channel of the initial channels?",1,1
79,2019-6-10,2019,6,10,16,byuotg,Training with multi-GPUs vs single GPU. Take longer time when train with 8 GPUs.,https://www.reddit.com/r/deeplearning/comments/byuotg/training_with_multigpus_vs_single_gpu_take_longer/,TonyLee00,1560150079,"Hi all, I have a benchmark on training time between 1, 2, 4, 6, 8 GPUs. My question is why training with 8 GPUs take a longer time compared to 4 GPU?

My hardware:

CPU: Xeon Silver 4110 2.1Ghz (16Cores)

GPU: 8 x RTX 2080Ti

Memory: 128 Gb

https://i.redd.it/xytm3rt79h331.png",3,2
80,2019-6-10,2019,6,10,16,byv1zz,Output shape meaning for a conv layer,https://www.reddit.com/r/deeplearning/comments/byv1zz/output_shape_meaning_for_a_conv_layer/,dennkiesauros,1560153021,"I am new to deep learning and I am doing a project based on transfer learning. After downloading the weights of VGG16 and adding GlobalMaxPooling2D, Dense, Dropout and a final Dense layer when I print out the summary of my model the output shape for input\_layer shows (None, None, None, 3). Is this alright? Why is it showing 'None'? I have set my img\_width, img\_height = 256, 256. I read in stackoverflow that 'None' allows dynamic image sizes. But on a different code using VGG16 the output shape was something like (None, 156, 156,3).

Sorry if this is a dumb question to ask. Thank you in advance.",3,1
81,2019-6-10,2019,6,10,21,byxjqt,Feel at CVPR as if you were at CVPR! CVPR Daily,https://www.reddit.com/r/deeplearning/comments/byxjqt/feel_at_cvpr_as_if_you_were_at_cvpr_cvpr_daily/,Gletta,1560171557,"**CVPR 2019**, the Computer Vision and Pattern Recognition conference, will take place in Long Beach, CA in less than 2 weeks.

If you are not going to CVPR, you can still receive the **CVPR Daily** every day in your mailbox. We will send you the link to the fresh magazine every morning and you will know the highlights of what is going on at the conference.

[**Register here, it's free!**](https://www.rsipvision.com/feel-at-cvpr-without-being-at-cvpr/)

You can also subscribe colleagues and friends who would like to receive great technology and community updates from CVPR 2019.

Enjoy!

&amp;#x200B;

https://i.redd.it/yjqolwqb1j331.jpg",0,7
82,2019-6-11,2019,6,11,2,bz0vsd,"PyTorch Hub | Check out the models for Researchers and Developers, or learn How it Works",https://www.reddit.com/r/deeplearning/comments/bz0vsd/pytorch_hub_check_out_the_models_for_researchers/,asuagar,1560188796,,2,42
83,2019-6-11,2019,6,11,3,bz1po4,[P] PyTorch Hub: Towards Reproducible Research,https://www.reddit.com/r/deeplearning/comments/bz1po4/p_pytorch_hub_towards_reproducible_research/,rosstaylor90,1560192820,"[https://pytorch.org/blog/towards-reproducible-research-with-pytorch-hub/](https://pytorch.org/blog/towards-reproducible-research-with-pytorch-hub/)

&amp;#x200B;

""Reproducibility is an essential requirement for many fields of research including those based on machine learning techniques. However, many machine learning publications are either not reproducible or are difficult to reproduce. With the continued growth in the number of research publications, including tens of thousands of papers now hosted on arXiv and submissions to conferences at an all time high, research reproducibility is more important than ever. While many of these publications are accompanied by code as well as trained models which is helpful but still leaves a number of steps for users to figure out for themselves.

We are excited to announce the availability of PyTorch Hub, a simple API and workflow that provides the basic building blocks for improving machine learning research reproducibility. PyTorch Hub consists of a pre-trained model repository designed specifically to facilitate research reproducibility and enable new research. It also has built-in support for Colab, integration with Papers With Code and currently contains a broad set of models that include Classification and Segmentation, Generative, Transformers, and more.""",0,1
84,2019-6-11,2019,6,11,6,bz3op6,Any tutorial to learn BERT,https://www.reddit.com/r/deeplearning/comments/bz3op6/any_tutorial_to_learn_bert/,saravanakumar17,1560202617,"Hi guys, I've been trying to learn Google's BERT with pytorch for sometime I've tried huggingface GitHub repo and few other sources, but I couldn't quite figure out how to implement it in an end to end project with pytorch. If you folks knew any resources of this kind, please let me know. Thanks in advance.",7,1
85,2019-6-11,2019,6,11,7,bz4fvf,Rate prediction with TensorFlow Bidirectional RNN,https://www.reddit.com/r/deeplearning/comments/bz4fvf/rate_prediction_with_tensorflow_bidirectional_rnn/,resotto,1560206509,,0,0
86,2019-6-11,2019,6,11,12,bz7d92,"How much machine learning, we must know before start learning deep learning?",https://www.reddit.com/r/deeplearning/comments/bz7d92/how_much_machine_learning_we_must_know_before/,KishanJoshi98,1560223304,"How much in depth knowledge of machine learning is required, before starting deep learning ?",8,0
87,2019-6-11,2019,6,11,12,bz7p37,Is it normal for convolution neural networks?,https://www.reddit.com/r/deeplearning/comments/bz7p37/is_it_normal_for_convolution_neural_networks/,jahifu,1560225545,"Is it normal for cnn for taking so much time 
I have like training-8000 test -2000 samples of dogs and cats 
When I try to fit the  model it takes usually 1 hour per epoch and it's total 25 epochs 
So it's taking lot of time is it normal for the cnn??
Because the tutorial from.which I have learning it takes like 80 sec to train per epoch so I don't what's happening some tell me /:
My pc specs: 1TB Hardisk
                          4GB RAM
                           AMD 480 GPU
                           and name of pc if some details are wrong is    hpay008tx",7,0
88,2019-6-11,2019,6,11,13,bz84i6,Statistics with R,https://www.reddit.com/r/deeplearning/comments/bz84i6/statistics_with_r/,HannahHumphreys,1560228334,[removed],0,1
89,2019-6-11,2019,6,11,14,bz8i9a,GANs?,https://www.reddit.com/r/deeplearning/comments/bz8i9a/gans/,mayyyday,1560230990,"Can we use GANs to detect disguised faces of a particular personality?
Like I have several images of the person with different look(frontal face). So can we build GAN that can detect whether the person's image is real or being impersonated or disguised?",2,0
90,2019-6-11,2019,6,11,14,bz8mxe,Artificial Intelligence Projects with Python-HandsOn,https://www.reddit.com/r/deeplearning/comments/bz8mxe/artificial_intelligence_projects_with/,HannahHumphreys,1560231919,[removed],0,1
91,2019-6-11,2019,6,11,18,bzaiec,Unbounded Table Detection,https://www.reddit.com/r/deeplearning/comments/bzaiec/unbounded_table_detection/,data_autopsy,1560247049,"I'm currently working on page layout analysis. The purpose of this is to do attribute extraction. The whole pipeline consists of some python packages and deep learning models. In some particular cases, we're encountering unbounded tables. Now, neither the deep learning models nor the packages can help in that. We are trying to reconstruct the text based on the coordinates but generalising that is a big problem. We tried training on [Table Bank dataset](https://github.com/doc-analysis/TableBank) but the results were not good (we didn't do any pre-processing). I have attached an image sample. I am not sure how to approach this problem other than table detection and then passing it to OCR for text. 

PS We've tried Faster-RCNN, SSD. The training set is of 92000 images. There are mix of bounded and unbounded tables. Please let me know if pre-processing will help in this case or any other approach you guys can think of.

Thanks.

![img](nynfm58m9p331)",4,3
92,2019-6-11,2019,6,11,20,bzb3dm,Face Detection!,https://www.reddit.com/r/deeplearning/comments/bzb3dm/face_detection/,mayyyday,1560251334,"Could any one give me the list of various types of Algorithms to detect faces? And What would you suggest to use and why?

NOTE: For research purpose, currently I'm trying to use YOLOv3 to detect faces.",4,1
93,2019-6-12,2019,6,12,1,bzeg29,Machine Learning and Reinforcement Learning in Finance,https://www.reddit.com/r/deeplearning/comments/bzeg29/machine_learning_and_reinforcement_learning_in/,HannahHumphreys,1560269610,[removed],0,1
94,2019-6-12,2019,6,12,1,bzex6i,[Research] Voice Mimicry Attacks Assisted by Automatic Speaker Verification,https://www.reddit.com/r/deeplearning/comments/bzex6i/research_voice_mimicry_attacks_assisted_by/,cdossman,1560271861," [https://medium.com/ai%C2%B3-theory-practice-business/towards-designing-more-secure-speaker-verification-systems-7f6fbb3f5912](https://medium.com/ai%C2%B3-theory-practice-business/towards-designing-more-secure-speaker-verification-systems-7f6fbb3f5912) 

Abstract:  In this work, we simulate a scenario, where a publicly available ASV system is used to enhance mimicry attacks against another closed source ASV system. In specific, ASV technology is used to perform a similarity search between the voices of recruited attackers (6) and potential target speakers (7,365) from VoxCeleb corpora to find the closest targets for each of the attackers. In addition, we consider median, furthest, and common targets to serve as a reference point. Our goal is to gain insights how well similarity rankings transfer from the attackers ASV system to the attacked ASV system, whether the attackers are able to improve their attacks by mimicking, and how the properties of the voices of attackers change due to mimicking. We address these questions through ASV experiments, listening tests, and prosodic and formant analyses. For the ASV experiments, we use i-vector technology in the attacker side, and x-vectors in the attacked side. For the listening tests, we recruit listeners through crowdsourcing. The results of the ASV experiments indicate that the speaker similarity scores transfer well from one ASV system to another. Both the ASV experiments and the listening tests reveal that the mimicry attempts do not, in general, help in bringing attackers scores closer to the targets. A detailed analysis shows that mimicking does not improve attacks, when the natural voices of attackers and targets are similar to each other. The analysis of prosody and formants suggests that the attackers were able to considerably change their speaking rates when mimicking, but the changes in F0 and formants were modest. Overall, the results suggest that untrained impersonators do not pose a high threat towards ASV systems, but the use of ASV systems to attack other ASV systems is a potential threat.",0,13
95,2019-6-12,2019,6,12,4,bzgrdz,Can someone give an insight on how to approach this problem? I am thinking of creating an MSWord addon that can track the user's cursor movement. Any help is appreciated!,https://www.reddit.com/r/deeplearning/comments/bzgrdz/can_someone_give_an_insight_on_how_to_approach/,pm_me_your_codebase,1560280131,,1,0
96,2019-6-12,2019,6,12,16,bzo99k,Introduction to Multilayer Neural Networks with TensorFlows Keras API,https://www.reddit.com/r/deeplearning/comments/bzo99k/introduction_to_multilayer_neural_networks_with/,CarlJohnson8x,1560325471,[removed],0,1
97,2019-6-12,2019,6,12,17,bzonx9,How to properly setup tensorflow with anaconda for python 3.5?,https://www.reddit.com/r/deeplearning/comments/bzonx9/how_to_properly_setup_tensorflow_with_anaconda/,atmadeepArya,1560328812,Can someone tell me a good way with required version numbers ? I keep on getting various errors due to version mismatch? Should I use pip or conda for installing tensorflow? Well I want it to be inside a conda environment so can you tell me what is the difference between using two?,9,13
98,2019-6-12,2019,6,12,18,bzp6t6,Pythia (Facebook) Greek god doing Deep learning,https://www.reddit.com/r/deeplearning/comments/bzp6t6/pythia_facebook_greek_god_doing_deep_learning/,whitezl0,1560332878,,0,12
99,2019-6-12,2019,6,12,19,bzpmuq,CI/CD for deploying Deep Learning models,https://www.reddit.com/r/deeplearning/comments/bzpmuq/cicd_for_deploying_deep_learning_models/,neeraj_sujan,1560336158,"Hey, 

&amp;#x200B;

What is the best approach to integrate a CI/CD pipeline in deploying my machine learning models. I want to automate this process where the model is only integrated if a specific criterion is met like for example the accuracy of the model is above a certain threshold. I want to integrate this with the gitlab CI/CD pipeline. What is the best approach to tackle this problem? Thanks",7,7
100,2019-6-12,2019,6,12,20,bzq25t,Training and validation loss completely overlap in a time series regression,https://www.reddit.com/r/deeplearning/comments/bzq25t/training_and_validation_loss_completely_overlap/,BeingSorena,1560339065,"The dataset here is about the arrival rate in a queue. I used one-hot coding to represent the features for the user type, year and hour of arrival in integer_hour column. Before performing any coding, the first few lines of dataset looked like this: enter image description here Afterwards, here's how it looks like:

enter image description here

Here's the code:

my_df= pd.read_csv(""proj_dataset.csv"")
user_types = list(my_df['user_type'].unique())
print(f'Number of user_types: {len(user_types)}')
print(f'user_type: {user_types}')
dummies = pd.get_dummies(my_df['user_type'],prefix='user_type')
df = pd.concat([my_df,dummies],axis=1)
df.drop(['user_type', 'start_time', 'id_timeslot'], axis= 1, inplace= True)
my_list= list(df['id_date'])
for i in range(0, len(my_list)):
    my_list[i]= my_list[i][0:4]
df['id_date']= my_list
years = list(df['id_date'].unique())
print(f'Number of different years: {len(years)}')
print(f'Years: {years}')
dummies = pd.get_dummies(['2012', '2013', '2014', '2015', '2016', '2017', '2018'],prefix='Year')
dummies = pd.get_dummies(df['id_date'],prefix='Year')
df3 = pd.concat([df ,dummies],axis=1)
df3.drop('id_date', axis= 1, inplace= True)
ColumnsTitles= ['integer_hour', 'user_type_A', 'user_type_C', 'user_type_P',
'Year_2012', 'Year_2013', 'Year_2014', 'Year_2015', 'Year_2016',
'Year_2017', 'Year_2018', 'arrivals']
df4=df3.reindex(columns=ColumnsTitles)

hours = list(df['integer_hour'].unique())
dummies = pd.get_dummies(['8', '9', '10', '11', '12', '13', '14', '15', '16', '17'],prefix='hour')
dummies = pd.get_dummies(my_df['integer_hour'],prefix='hour')
my_df = pd.concat([df4,dummies],axis=1)
my_df.drop('integer_hour', axis= 1, inplace= True)
Train_Frame= my_df[:80000]
Test_Frame = my_df[80000:]
Train_Set= Train_Frame.values
Test_Set= Test_Frame.values
Test_Frame.shape;
X_Train= Train_Set[:, 0:20]
Y_Train= Train_Set[:, -1]
X_Test= Test_Set[:, 0:20]
Y_Test= Test_Set[:, -1]
X_Train.shape
model = models.Sequential() 
model.add(layers.Dense(20, input_shape=(20,), kernel_regularizer=regularizers.l1_l2(l1=0.12, l2=0.10), activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(10, input_shape=(20,), kernel_regularizer=regularizers.l1_l2(l1=0.12, l2=0.10), activation='relu'))
model.add(layers.Dropout(0.9))
model.add(layers.Dense(5, input_shape=(20,), kernel_regularizer=regularizers.l1_l2(l1=0.12, l2=0.10), activation='softplus'))

model.add(layers.Dense(1))
model.compile(optimizer='rmsprop', loss='mse', metrics= ['acc'])
history= model.fit(X_Train, Y_Train, verbose=0, epochs= 200, batch_size=1000, validation_data=(X_Test, Y_Test));
Results = model.evaluate(X_Test, Y_Test)
It seems rather odd that the training and validation loss perfectly overlap. As usual, the same is true for training and validation accuracy. Thanks for your answers.

enter image description here",0,1
101,2019-6-12,2019,6,12,22,bzr0mm,Register Now | Webinar: How to use continual learning in your ML models,https://www.reddit.com/r/deeplearning/comments/bzr0mm/register_now_webinar_how_to_use_continual/,Mayalittlepony,1560344896,,0,1
102,2019-6-12,2019,6,12,22,bzr6y2,Setting Rythym in Algorithm (Contd),https://www.reddit.com/r/deeplearning/comments/bzr6y2/setting_rythym_in_algorithm_contd/,BlockDelta,1560345873,,0,2
103,2019-6-12,2019,6,12,22,bzre1i,Confused by the semantics,https://www.reddit.com/r/deeplearning/comments/bzre1i/confused_by_the_semantics/,StrasJam,1560346962,"I am currently working on a project where I am supposed to accurately outline the locations of rows of vegetation (ex. bushes) from satellite imagery. Typically I would have thought of this to be a classification approach (classify areas as either bush-rows or non-bush), but now that I have thought about it some more I am thinking that this might be an object detection problem (detect the linear vegetation objects in the image). It would help me to know which approach best applies to my project so that I can read the proper articles and such so if anyone could give me some insight into which approach is more appropriate for this task I would greatly appreciate it.  


Thanks!!!",6,2
104,2019-6-12,2019,6,12,22,bzrk1q,[Research] Real-Time Adversarial Attacks,https://www.reddit.com/r/deeplearning/comments/bzrk1q/research_realtime_adversarial_attacks/,cdossman,1560347894," [https://medium.com/ai%C2%B3-theory-practice-business/how-about-real-time-adversarial-attacks-6aba92d59c1e?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/how-about-real-time-adversarial-attacks-6aba92d59c1e?postPublishedType=initial) 

**Abstract:**  In recent years, many efforts have demonstrated that modern machine learning algorithms are vulnerable to adversarial attacks, where small, but carefully crafted, perturbations on the input can make them fail. While these attack methods are very effective, they only focus on scenarios where the target model takes static input, i.e., an attacker can observe the entire original sample and then add a perturbation at any point of the sample. These attack approaches are not applicable to situations where the target model takes streaming input, i.e., an attacker is only able to observe past data points and add perturbations to the remaining (unobserved) data points of the input. In this paper, we propose a real-time adversarial attack scheme for machine learning models with streaming inputs",0,1
105,2019-6-13,2019,6,13,0,bzskdq,"Network topology, Resnet50 (for example) or something smaller",https://www.reddit.com/r/deeplearning/comments/bzskdq/network_topology_resnet50_for_example_or/,brechmos,1560353154,"I am reasonably new at NN and all.  I am starting an astrophysics project that will have a couple tasks, one is object classification based on cutouts and the other is object detection (YOLO or faster-RCNN, I think) in a larger image. The objects are not going to be galaxies or stars etc, but regions with more subtle effects in images.  

For the object classification, would it make sense to start with Resnet50 or VGG16 (from Keras) and retrain it on the labeled data, or would it make more sense to start with a less complicated network? There are going to be 3-4 classes that an image might fall into.  So I am \*thinking\* of taking Resnet50, for example, strip off the top layer and add my own that has 3-4 output nodes and then re-train based on the data I have. Part of the answer might be ""you have to try it"" but I would like to hear any intuition before I do that :).

In reading through on the ImageNet trained networks, they seem to focus more on texture in the images rather than structure.  If this is a property of the underlying trained CNN (e.g., Resnet 50) then this might be a benefit to the types of images I am going to have.

Any thoughts or guidance would be appreciated.",2,1
106,2019-6-13,2019,6,13,1,bzt0ea,Projects in Machine Learning : Beginner To Professional,https://www.reddit.com/r/deeplearning/comments/bzt0ea/projects_in_machine_learning_beginner_to/,HannahHumphreys,1560355397,[removed],0,1
107,2019-6-13,2019,6,13,4,bzv8lq,Deep Learning Tutorial for Beginner | Background &amp; History |60 mins of tutorial,https://www.reddit.com/r/deeplearning/comments/bzv8lq/deep_learning_tutorial_for_beginner_background/,KiranKiller,1560366245,,0,1
108,2019-6-13,2019,6,13,4,bzvm0y,Failing at Image Captioning!,https://www.reddit.com/r/deeplearning/comments/bzvm0y/failing_at_image_captioning/,plmlp1,1560368039,"Hello I'm trying to learn CNNs and I've hit a deadend with an Image Captioning project I was working on for fun.

Dataset: 10k images from [Google Conceptual Captions] (https://ai.google.com/research/ConceptualCaptions/download)  
Tutorial I'm mostly following: [Automatic Image Captioning](https://github.com/hlamba28/Automatic-Image-Captioning)  


One difference between my dataset and the Flicker8k dataset in the tutorial is that my dataset only has one caption per image but latter has five captions per image.

The problem is that I am getting the same caption for nearly all images. I have tried to use:
- LSTM instead of GRU cells
- 50 and 200 Glove word embeddings. I even tried to create my own embeddings using all captions in the dataset
- beam search and greedy search to get a prediction

What do I do?",0,1
109,2019-6-13,2019,6,13,4,bzvtgh,Text to image conversion,https://www.reddit.com/r/deeplearning/comments/bzvtgh/text_to_image_conversion/,LolSalaam,1560369042,"Hi all. I'm looking for something that will help me in text to image conversion. 

Text is a paragraph consisting of sentences where each of these sentences are basically instructions on how a room should look like and the image produced is supposed to comply with these instructions.

I'm currently looking into some stackGAN implementations. If someone has any other idea do share.
Would be glad if someone could help.
Thanks:)",1,3
110,2019-6-13,2019,6,13,5,bzwebn,What is the hardest thing about implementing Deep Learning in your business?,https://www.reddit.com/r/deeplearning/comments/bzwebn/what_is_the_hardest_thing_about_implementing_deep/,HenryAILabs,1560371862,,12,23
111,2019-6-13,2019,6,13,10,bzze2x,Enlightenment,https://www.reddit.com/r/deeplearning/comments/bzze2x/enlightenment/,markusdamon5,1560388053,,1,0
112,2019-6-13,2019,6,13,12,c00qum,X-Ray Dataset for Research,https://www.reddit.com/r/deeplearning/comments/c00qum/xray_dataset_for_research/,Redhatchamp00,1560396312,"Hello!

Does anyone know of a dataset of X-ray images of the cervical spine region. I need it for research purposes, but I can't find it anywhere. It would be of great help if someone could share a link to any such database. 

Thanks",0,6
113,2019-6-13,2019,6,13,13,c018gh,An AI-Powered Domain Name Generator,https://www.reddit.com/r/deeplearning/comments/c018gh/an_aipowered_domain_name_generator/,Refeb,1560399497,"Hey there, we are so happy and pleased to share our platform with you today:

&amp;#x200B;

DeepNamer is an AI-powered domain name generator and deep brainstorm platform that can help you find a catchy and creative domain name for your business for free. DeepNamer is built based on a deep sequence-to-sequence (i.e., keywords-to-domain) architecture, which utilizes the most recent natural language processing algorithms such as dynamic recurrent neural networks.

&amp;#x200B;

Note that we find our name DeepNamer via our AI algorithm and our platform inspired by the way startups names their businesses.

**We would be happy to share our platform (**[**DeepNamer.com**](https://DeepNamer.com)**) with you and any comment, feedback or suggestion would be appreciated.**",1,2
114,2019-6-13,2019,6,13,15,c024i5,Deep Learning Frameworks 2019,https://www.reddit.com/r/deeplearning/comments/c024i5/deep_learning_frameworks_2019/,MainBuilder,1560405777,,1,1
115,2019-6-13,2019,6,13,19,c03yjm,Awesome papers and engineering reviews on Computer Vision News of June (with codes!). Links for free reading!,https://www.reddit.com/r/deeplearning/comments/c03yjm/awesome_papers_and_engineering_reviews_on/,Gletta,1560420526,"RSIP Vision has just published the June issue of **Computer Vision News**. Here it is for you to read online.

42 pages with exclusive articles on **AI, computer vision and deep learning**.

Subscribe for free on page 42. Important message about **CVPR** on page 9.

[**HTML5 version (recommended)**](https://www.rsipvision.com/ComputerVisionNews-2019June/)

[**PDF version**](https://www.rsipvision.com/computer-vision-news-2019-june-pdf/)

Enjoy!

&amp;#x200B;

https://i.redd.it/4j1md77pl3431.jpg",4,17
116,2019-6-13,2019,6,13,20,c04eas,Geometric deep learning applications?,https://www.reddit.com/r/deeplearning/comments/c04eas/geometric_deep_learning_applications/,Matimath,1560423725,"Hi all,

do you know any papers that apply spectral graph convolution to solve real life problem (or at least a problem based on real data)? I am particularly interested in those where both learning and inference happen in the same domain.",0,4
117,2019-6-13,2019,6,13,20,c04ife,RealTalk: This Speech Synthesis Model Recreates A Human Voice Perfectly,https://www.reddit.com/r/deeplearning/comments/c04ife/realtalk_this_speech_synthesis_model_recreates_a/,lopespm,1560424460,,1,7
118,2019-6-13,2019,6,13,20,c04lof,PySyft,https://www.reddit.com/r/deeplearning/comments/c04lof/pysyft/,susmit410,1560425082,PySyft and the Emergence of Private Deep Learning by Jesus Rodriguez https://link.medium.com/FXydw6q8tX,1,2
119,2019-6-13,2019,6,13,20,c04pjl,"Telegram group about deep learning ,machine learning , Artificial Intelligence ,....",https://www.reddit.com/r/deeplearning/comments/c04pjl/telegram_group_about_deep_learning_machine/,Doctor_who1,1560425756,"The Main topics that we are going to discuss here are as below:

  Business Development and Business Model in Digital Transformation Age

  Data Science 

  Artificial Intelligence 

  Machine Learning

  Deep Learning

  Cognitive Science

  Neuroscience

&amp;#x200B;

&amp;#x200B;

Please  post in English  language.

&amp;#x200B;

Telegram  group 

join 

[https://t.me/joinchat/CuFqkRQSxRy5M\_6KxhKrCA](https://t.me/joinchat/CuFqkRQSxRy5M_6KxhKrCA)",3,1
120,2019-6-13,2019,6,13,21,c05dnd,"Professor Shai Shen-Orr PhD., Associate Professor at Technion - Israel Institute of Technology, and Founder and Chief Scientist CytoReason, Discussing Artificial Intelligence Speeding Up Drug Discovery",https://www.reddit.com/r/deeplearning/comments/c05dnd/professor_shai_shenorr_phd_associate_professor_at/,bioquarkceo,1560429956,,0,5
121,2019-6-13,2019,6,13,22,c0603g,[Research] How Much Does Audio Matter to Recognize Egocentric Object Interactions?,https://www.reddit.com/r/deeplearning/comments/c0603g/research_how_much_does_audio_matter_to_recognize/,cdossman,1560433503," [https://medium.com/ai%C2%B3-theory-practice-business/how-much-does-audio-matter-to-recognize-egocentric-object-interactions-ed01b2f7c680?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/how-much-does-audio-matter-to-recognize-egocentric-object-interactions-ed01b2f7c680?postPublishedType=initial) 

Abstract:  In this preliminary work, we propose an audio model for egocentric action recognition and explore its usefulness on the parts of the problem (noun, verb, and action classification). Our model achieves a competitive result in terms of verb classification (34.26% accuracy) on a standard benchmark with respect to vision-based state of the art systems, using a comparatively lighter architecture.",0,1
122,2019-6-13,2019,6,13,23,c067pw,"AI, art, and autonomy: an introduction to the Abraham project",https://www.reddit.com/r/deeplearning/comments/c067pw/ai_art_and_autonomy_an_introduction_to_the/,keghn,1560434639,,0,11
123,2019-6-14,2019,6,14,1,c07z8a,Applied Deep Learning Tutorial For Beginners| Theory &amp; Application| 1 Hr Tutorial,https://www.reddit.com/r/deeplearning/comments/c07z8a/applied_deep_learning_tutorial_for_beginners/,KiranKiller,1560443417,,0,0
124,2019-6-14,2019,6,14,2,c08sr7,Can GANs generate conditional y values given x values which y comes from mixture densities?,https://www.reddit.com/r/deeplearning/comments/c08sr7/can_gans_generate_conditional_y_values_given_x/,Shanghoosh,1560447344,"I have a table with two attributes (x,y). for each x there are several y values that come from different normal distributions. Now, I want to generate y values given x. I know Mixture Density Networks do this for me, but I need GANs to do it. I have implemented conditional GANs, but the results are not good, seems random. by the way, my conditional GAN works well on simple functions such as y=x\^2.

my data is like this: 

&amp;#x200B;

[for each x there are several mu and sigma of mixture normal distribution](https://i.redd.it/rgr0sop0t5431.png)

Any answers are appreciated.",0,1
125,2019-6-14,2019,6,14,5,c0b1ma,DeepNamer: An AI-Powered Domain Name Generator,https://www.reddit.com/r/deeplearning/comments/c0b1ma/deepnamer_an_aipowered_domain_name_generator/,Refeb,1560458172,,3,15
126,2019-6-14,2019,6,14,16,c0h92x,Deep learning telegram group and car learning with the collaboration of Kursera website and world experts and researchers including andrew ng,https://www.reddit.com/r/deeplearning/comments/c0h92x/deep_learning_telegram_group_and_car_learning/,Doctor_who1,1560497138," 

The Main topics that we are going to discuss here are as below:

 Data Science

 Artificial Intelligence

 Machine Learning

 Deep Learning

 Cognitive Science

 Neuroscience

Please post in English language.

Telegram group

join

[https://t.me/joinchat/CuFqkRQSxRy5M\_6KxhKrCA](https://t.me/joinchat/CuFqkRQSxRy5M_6KxhKrCA)",0,0
127,2019-6-14,2019,6,14,18,c0i561,AI for Beginners: An introduction to Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/c0i561/ai_for_beginners_an_introduction_to_artificial/,Oratorshub,1560505153,,0,3
128,2019-6-14,2019,6,14,23,c0kpl4,[Research]Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition,https://www.reddit.com/r/deeplearning/comments/c0kpl4/researchinvestigating_the_lombard_effect/,cdossman,1560522377," [https://medium.com/ai%C2%B3-theory-practice-business/the-impact-of-the-lombard-effect-in-audio-visual-speech-recognition-613904484bd4?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/the-impact-of-the-lombard-effect-in-audio-visual-speech-recognition-613904484bd4?postPublishedType=initial) 

Abstract:  Several audio-visual speech recognition models have been recently proposed which aim to improve the robustness over audio-only models in the presence of noise. However, almost all of them ignore the impact of the Lombard effect, i.e., the change in speaking style in noisy environments which aims to make speech more intelligible and affects both the acoustic characteristics of speech and the lip movements. In this paper, we investigate the impact of the Lombard effect in audio-visual speech recognition. To the best of our knowledge, this is the first work which does so using end-to-end deep architectures and presents results on unseen speakers. Our results show that properly modeling Lombard speech is always beneficial. Even if a relatively small amount of Lombard speech is added to the training set then the performance in a real scenario, where noisy Lombard speech is present, can be significantly improved. We also show that the standard approach followed in the literature, where a model is trained and tested on noisy plain speech, provides a correct estimate of the video-only performance and slightly underestimates the audio-visual performance. In case of audio-only approaches, performance is overestimated for SNRs higher than -3dB and underestimated for lower SNRs",0,8
129,2019-6-15,2019,6,15,3,c0nqel,Best course for deep learning,https://www.reddit.com/r/deeplearning/comments/c0nqel/best_course_for_deep_learning/,AhmedZubairGCU,1560538017,I am thinking about starting Andrew Ng's deep learning specialisation. I just wanted to ask if there is some better alternative or is it good enough? Also after completing this is it worth mentioning in my resume?,9,19
130,2019-6-15,2019,6,15,4,c0ob7k,CSDN account,https://www.reddit.com/r/deeplearning/comments/c0ob7k/csdn_account/,davimoises2015,1560541028,"Someone from china, please download a file for min please. It's urgent, because I'm using it for work.

link 1:  [https://download.csdn.net/download/cjxin2009/10751701](https://download.csdn.net/download/cjxin2009/10751701) 

link 2:  [https://download.csdn.net/download/qq\_30091273/10823889](https://download.csdn.net/download/qq_30091273/10823889) 

link 3:   [https://download.csdn.net/download/njfkib/10941006](https://download.csdn.net/download/njfkib/10941006)

link 4:  [https://download.csdn.net/download/mss60/10967014](https://download.csdn.net/download/mss60/10967014)   


Meu E-mail: davi.empresajw@gmail.com",0,1
131,2019-6-15,2019,6,15,14,c0u4oc,Tensorflow gpu on mac Sierra 10.12.6,https://www.reddit.com/r/deeplearning/comments/c0u4oc/tensorflow_gpu_on_mac_sierra_10126/,durgesh2018,1560578304,"I am trying to set tensorflow gpu on Sierra. What is the easiest way to achieve this.

Thank you!",11,8
132,2019-6-15,2019,6,15,22,c0x1ui,Understanding deep learning (part1): Deep neural networks overview,https://www.reddit.com/r/deeplearning/comments/c0x1ui/understanding_deep_learning_part1_deep_neural/,TheTesseractAcademy,1560603710,,1,24
133,2019-6-16,2019,6,16,0,c0yd1b,Understanding deep learning (part 2): Feedforward and recurrent neural networks,https://www.reddit.com/r/deeplearning/comments/c0yd1b/understanding_deep_learning_part_2_feedforward/,TheTesseractAcademy,1560611815,,0,1
134,2019-6-16,2019,6,16,0,c0ydp9,Advanced Data Science with IBM,https://www.reddit.com/r/deeplearning/comments/c0ydp9/advanced_data_science_with_ibm/,HannahHumphreys,1560611918,[removed],0,1
135,2019-6-16,2019,6,16,18,c189gq,Managing image datasets ?,https://www.reddit.com/r/deeplearning/comments/c189gq/managing_image_datasets/,dandashino,1560678388,"Hello,

I am trying to create the datasets management part of a deep learning project.  The use cases that we will be covering will mostly be related to images so I want to focus on that for now. 

My idea was to just make a small API that will handle file management operations on the images (create, delete, move, make directories...) which will represent the datasets. I have recently came across posts where they use hdf5 (which i thought was only a format used by keras/tensorflow cuz iz a bit noob in this)  files to store files/images and their metadata. 

Has anyone tried (or just seen) saving images as hdf5 files for cv datasets?  If so, do you recommend using that for performance gains?",4,10
136,2019-6-16,2019,6,16,20,c18vgr,Video quality for Creating realistic deepfake?,https://www.reddit.com/r/deeplearning/comments/c18vgr/video_quality_for_creating_realistic_deepfake/,Seedani,1560684035,"Just how good does the video quality have to be to create a near-perfect deepfake? 

Is it possible to create a realistic deepfake with a heavily encoded file, for example? 

Thanks!",0,0
137,2019-6-16,2019,6,16,22,c19tco,Model not learning in Keras!,https://www.reddit.com/r/deeplearning/comments/c19tco/model_not_learning_in_keras/,dennkiesauros,1560691237,"So this is my first deep learning project where I am using a pretrained model to classify images using keras. Right now I am using VGG16 to check its performance. But my model is not learning. I have divided the dataset in two ways.

In the first method, I have created 3 directories manually, Train, Test, Validation which have subdirectories of various classes. When I am training and validating my model on this dataset using  datagen.flow, my model has an accuracy over 97%. It has pretty high accuracy on the test data too.

In the second method I have converted the images into numpy arrays and then used sklearn test\_train\_split to create test, train, valid data. But when I am training the model on this set of data, my model  is not learning anything. It shows the same loss, acc, val\_loss, val\_acc over the epochs. I cannot understand why is this happening. I wanted to use this method because I wanted to evaluate the sklearn metrics like confusion matrix and classification report. Is there any way I can use the previous dataset and datagen.flow to evaluate these metrics?

I have tried every possible way to convert my images to numpy arrays. Can anyone please help me?",13,8
138,2019-6-17,2019,6,17,0,c1b7yw,Machine Learning with TensorFlow on Google Cloud Platform,https://www.reddit.com/r/deeplearning/comments/c1b7yw/machine_learning_with_tensorflow_on_google_cloud/,HannahHumphreys,1560699496,[removed],0,1
139,2019-6-17,2019,6,17,1,c1bqg5,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c1bqg5/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1560702267,[removed],0,1
140,2019-6-17,2019,6,17,1,c1c0q6,NVIDIA's AI that generates photorealistic images from your doodles is now in beta stage and open for all to try out,https://www.reddit.com/r/deeplearning/comments/c1c0q6/nvidias_ai_that_generates_photorealistic_images/,azmodeus99,1560703821,,4,48
141,2019-6-17,2019,6,17,2,c1caac,Helper library for NLP tasks: textsearch (fast and configurable text search in Python),https://www.reddit.com/r/deeplearning/comments/c1caac/helper_library_for_nlp_tasks_textsearch_fast_and/,pvkooten,1560705244,,1,1
142,2019-6-17,2019,6,17,3,c1d2e9,Awesome DL and ML Courses,https://www.reddit.com/r/deeplearning/comments/c1d2e9/awesome_dl_and_ml_courses/,Msadat97,1560709289,"Hey guys,

&amp;#x200B;

I've recently found this awesome collection of ml and dl courses.

&amp;#x200B;

[Deep Learning and Machine Learning Drizzle](https://github.com/kmario23/deep-learning-drizzle)

&amp;#x200B;

Hope it'll help interested people. Please add related resources in the comments. (I am personally more interested in ml and dl theory, so your comments would be appreciated).",3,2
143,2019-6-17,2019,6,17,4,c1e1yg,pastiche: a PyTorch implementation of Neural Style Transfer,https://www.reddit.com/r/deeplearning/comments/c1e1yg/pastiche_a_pytorch_implementation_of_neural_style/,dstein64,1560714416,,0,1
144,2019-6-17,2019,6,17,7,c1fm4h,Best GPU for Pytorch?,https://www.reddit.com/r/deeplearning/comments/c1fm4h/best_gpu_for_pytorch/,DeepLearningStudent,1560722732,"Hi all,

&amp;#x200B;

I am a fledgling deep learning student and until fairly recently, for anything but the most basic of prototypes, I have been using my organization's high performance computing cluster for deep learning tasks. However, I would like to do some home prototyping and inference with models I develop or analyze without having to wrestle with the cluster every time and risk maintenance downtime, errors, and other headaches. To that end, I have begun looking for a graphics card that would maximize my ability to prototype from one machine without a dedicated GPU machine. 

&amp;#x200B;

Any recommendations would be appreciated!",4,1
145,2019-6-17,2019,6,17,16,c1klna,How do you tag your data?,https://www.reddit.com/r/deeplearning/comments/c1klna/how_do_you_tag_your_data/,abhiksark,1560755956,"I work as a Machine Learning Engineer, so a lot of work revolves around data. To fulfill our needs we are having a team of dedicated taggers who tag the data suiting the requirements. But it's a slow and an error Prone Process.  How do you/your company manages this task?",12,7
146,2019-6-17,2019,6,17,16,c1kv8e,Classification of image style using deep learning with Python - Custom Web Development Blog,https://www.reddit.com/r/deeplearning/comments/c1kv8e/classification_of_image_style_using_deep_learning/,issart,1560758264,[removed],0,1
147,2019-6-17,2019,6,17,17,c1l12f,difference between 'Image captioning' and 'Scene graph generation'..?,https://www.reddit.com/r/deeplearning/comments/c1l12f/difference_between_image_captioning_and_scene/,GW_KIM,1560759672,"I noticed that recently there some many researches about 'Scene graph generation'

But is there any difference between it and 'Image captioning'..?

Naively, i think we could build Scene graph from output of 'Image captioning'

Thx :)",4,6
148,2019-6-17,2019,6,17,18,c1lotz,Keras - Random word embeddings performing better than pre-trained ones?,https://www.reddit.com/r/deeplearning/comments/c1lotz/keras_random_word_embeddings_performing_better/,rodrigonader,1560765372,"Im having trouble to understand the behavior of my word embedding layer when using pre-trained fixed weights vs random weights. Please see full post here and share your thoughts:

https://stackoverflow.com/q/55051269/10382479",4,7
149,2019-6-17,2019,6,17,19,c1lqm5,A Very General Introduction to Keras,https://www.reddit.com/r/deeplearning/comments/c1lqm5/a_very_general_introduction_to_keras/,Abhi_9991,1560765753,"A quick post about creating a neural network classifier in keras.

Please read and review.

[A Very General Introduciton to Keras](https://dev.to/abhisarshukla/a-very-general-introduction-to-keras-1g33)",0,3
150,2019-6-17,2019,6,17,19,c1lvs7,One-shot learning in DARTS paper,https://www.reddit.com/r/deeplearning/comments/c1lvs7/oneshot_learning_in_darts_paper/,0x7A,1560766891,"I recently read the  ""DARTS - Differentiable Architecture Search"" paper ([https://arxiv.org/abs/1806.09055](https://arxiv.org/abs/1806.09055)) by Liu et al. While it is not mentioned in the paper itself, several reviewers at OpenReview ([https://openreview.net/forum?id=S1eYHoC5FX](https://openreview.net/forum?id=S1eYHoC5FX)) claim that DARTS can be considered a one-shot learning approach. I only know one-shot learning from an object recognition context, so I don't quite see the connection here. Do you have any explanation why DARTS would be a one-shot algorithm?",5,6
151,2019-6-17,2019,6,17,23,c1oj4s,Free cloud GPU credits for deep learning,https://www.reddit.com/r/deeplearning/comments/c1oj4s/free_cloud_gpu_credits_for_deep_learning/,whitezl0,1560783582,"Hi, I am offering free credits for 1080Ti GPU instances for deep learning purposes  more than 12hrs for free

I am working on https://www.tensorpad.com/  developing cloud infrastructure for machine learning.

Part of our computational capacity is idle; hence, were offering credits at a free and discounted rate, so that data scientists can benefit from the resources available, and work on neural networks.

Specs:  60GB of RAM, 4 CPUs, 1080Ti GPU  JupyterLab environment with access to the terminal  Pre-installed Tensorflow, Keras, and other ML frameworks

You can access the free credits by signing up (https://dashboard.tensorpad.com/ and redeeming ""promo450"" promo code in the Billing tab (https://dashboard.tensorpad.com/billing).

For any questions, please contact us here, through support@tensorpad.com, or the Intercom on the site.",0,3
152,2019-6-18,2019,6,18,1,c1pp8a,[Research] Leveraging BERT for Extractive Text Summarization on Lectures,https://www.reddit.com/r/deeplearning/comments/c1pp8a/research_leveraging_bert_for_extractive_text/,cdossman,1560789215," [https://medium.com/ai%C2%B3-theory-practice-business/cloud-based-service-utilizes-bert-for-dynamic-extractive-lecture-summarizations-1b2796291f96?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/cloud-based-service-utilizes-bert-for-dynamic-extractive-lecture-summarizations-1b2796291f96?postPublishedType=initial) 

**Abstract:**  In the last two decades, automatic extractive text summarization on lectures has demonstrated to be a useful tool for collecting key phrases and sentences that best represent the content. However, many current approaches utilize dated approaches, producing sub-par outputs or requiring several hours of manual tuning to produce meaningful results. Recently, new machine learning architectures have provided mechanisms for extractive summarization through the clustering of output embeddings from deep learning models. This paper reports on the project called lecture summarization service, a python-based RESTful service that utilizes the BERT model for text embeddings and K-Means clustering to identify sentences closest to the centroid for summary selection. The purpose of the service was to provide students a utility that could summarize lecture content, based on their desired number of sentences. On top of summary work, the service also includes lecture and summary management, storing content on the cloud which can be used for collaboration.",0,23
153,2019-6-18,2019,6,18,3,c1r8b9,Plotting linear/affine regions of NNs in 2D.,https://www.reddit.com/r/deeplearning/comments/c1r8b9/plotting_linearaffine_regions_of_nns_in_2d/,PureTune,1560796444,"I've been checking out a couple papers on the complexity of NNs with ReLU nonlinearities, expressed through their linear/affine regions (some of these I heard about from ICML recently), e.g.

* [https://arxiv.org/abs/1901.09021](https://arxiv.org/abs/1901.09021)
* [https://arxiv.org/abs/1901.07647](https://arxiv.org/abs/1901.07647)
* [https://papers.nips.cc/paper/5422-on-the-number-of-linear-regions-of-deep-neural-networks.pdf](https://papers.nips.cc/paper/5422-on-the-number-of-linear-regions-of-deep-neural-networks.pdf)
* [https://arxiv.org/abs/1312.6098](https://arxiv.org/abs/1312.6098)

I want to understand this phenomena better, and I was thinking maybe I would do some visualization experiments involving data in 2D. Problem is, I'm not really sure how I would be able to efficiently compute the linear regions, esp. with NNs involving more than one layer. Would anyone here with more experience on this topic mind pointing me in the right direction?",2,2
154,2019-6-18,2019,6,18,3,c1ra31,Debugging your neural net the right way!,https://www.reddit.com/r/deeplearning/comments/c1ra31/debugging_your_neural_net_the_right_way/,solitary_sandman,1560796689,,1,1
155,2019-6-18,2019,6,18,3,c1reat,"Yoshua Bengio on the Turing Award, AI Trends, and Very Unfortunate US-China Tensions",https://www.reddit.com/r/deeplearning/comments/c1reat/yoshua_bengio_on_the_turing_award_ai_trends_and/,Yuqing7,1560797265,,0,4
156,2019-6-18,2019,6,18,6,c1t2tu,What precautions should I take while using a pre trained deep learning model?,https://www.reddit.com/r/deeplearning/comments/c1t2tu/what_precautions_should_i_take_while_using_a_pre/,bananaskywalker,1560805371,"I found a pre-trained model for a task that I am working on in my internship and its results are excellent. However, there are a few caveats:

1) It doesn't handle rotated versions of the input image very well, so I thought of fine-tuning it to fix the model.

2) However, I cannot use the model to develop the project\* as it has a non-commercial license, though it is open source. If I were to fine tune it, can I be legally allowed to call it my own or for my own use, provided I notify the original authors and I give the fine-tuned model back to them?

3) That brings me into an even murkier area, considering I am working for a company, a very small one, and I cannot really release it to be open source and I am not sure if the authors will be okay with it, if I am fine tune it and don't give back to the community.

4) Also, since it is trained on a huge dataset extensively and is currently the only solution out there that works and gives accuracy to make it viable for work.

The project is fine tune the model and develop an API for it, that is meant for commercial use.",0,1
157,2019-6-18,2019,6,18,6,c1t311,"5 minute summary of chapter 1 of ""Reinforcement Learning: An Introduction""",https://www.reddit.com/r/deeplearning/comments/c1t311/5_minute_summary_of_chapter_1_of_reinforcement/,jdyr1729,1560805398,"Hi,

I've distilled the first chapter of Sutton and Barto's book into a 5 minute summary.

I created it for myself, but thought I'd share it here for anybody who'd like a quick overview.

[https://jackdry.com/reinforcement-learning-an-introduction](https://jackdry.com/reinforcement-learning-an-introduction)

Hope you find it useful!

Jack",1,14
158,2019-6-18,2019,6,18,11,c1ws2b,"Quick art by Nvidia GauGAN, this is the mountain in my dream [Site: http://52.12.58.174]",https://www.reddit.com/r/deeplearning/comments/c1ws2b/quick_art_by_nvidia_gaugan_this_is_the_mountain/,bonnieng,1560825927,,10,122
159,2019-6-18,2019,6,18,12,c1x09y,A Simple Implementation of `Neural Style in Keras` [Python],https://www.reddit.com/r/deeplearning/comments/c1x09y/a_simple_implementation_of_neural_style_in_keras/,signal_v_noise,1560827312," 

An implementation of ""A Neural Algorithm of Artistic Style"" ([http://arxiv.org/abs/1508.06576](http://arxiv.org/abs/1508.06576)) in Keras

The code present in this repository is presented in this [blog](https://medium.com/@singhal.amogh1995/utilising-cnns-to-transform-your-model-into-a-budding-artist-1330dc392e25).

The code is written in Keras 2.2.2

Link to Repo:  [https://github.com/devAmoghS/Keras-Style-Transfer](https://github.com/devAmoghS/Keras-Style-Transfer) 

[Project Preview](https://camo.githubusercontent.com/e060da134fe07f5aadf0e900a7223c407306468d/68747470733a2f2f6d656469612e67697068792e636f6d2f6d656469612f6934456c684b65704d5463495a6971636d612f67697068792e676966)",1,2
160,2019-6-18,2019,6,18,13,c1xs71,Machine Learning with AWS AI and IBM Watson,https://www.reddit.com/r/deeplearning/comments/c1xs71/machine_learning_with_aws_ai_and_ibm_watson/,HannahHumphreys,1560832370,[removed],0,1
161,2019-6-18,2019,6,18,20,c20xco,Wrote a guide to setup fastai on your local linux machine with ease,https://www.reddit.com/r/deeplearning/comments/c20xco/wrote_a_guide_to_setup_fastai_on_your_local_linux/,Poad42,1560856149,,0,0
162,2019-6-18,2019,6,18,20,c21cq8,[X-Post] Trying to get more views for a question I have,https://www.reddit.com/r/deeplearning/comments/c21cq8/xpost_trying_to_get_more_views_for_a_question_i/,radcapbill,1560859094,,0,1
163,2019-6-19,2019,6,19,0,c23hgy,[project] DeepTemporalSeg: Temporally Consistent Semantic Segmentation of 3D LiDAR Scans,https://www.reddit.com/r/deeplearning/comments/c23hgy/project_deeptemporalseg_temporally_consistent/,deep_descriptor,1560871034,,4,3
164,2019-6-19,2019,6,19,0,c23sbk,Help for finding research papers on RNN,https://www.reddit.com/r/deeplearning/comments/c23sbk/help_for_finding_research_papers_on_rnn/,sayan_c,1560872502,Can Someone recommend me any research papers on application of recurrent neural networks? I'd greatly appreciate any help.,2,1
165,2019-6-19,2019,6,19,1,c24oqo,Junior looking for feedback,https://www.reddit.com/r/deeplearning/comments/c24oqo/junior_looking_for_feedback/,waterchiller,1560876880,"Hi I am currently trying my hands on deep learning. And I created https://github.com/ChristianSchneeweiss/Dog-Breed-Classification/tree/master model which can predict the breed of a dog with 61% accuracy. I would love if somebody can give me feedback. 

Furthermore I do not think this accuracy is too great, as I saw a reddit post yesterday who created a model which can predict car brands and so on with a 92% accuracy.",0,0
166,2019-6-19,2019,6,19,3,c25m59,Faster R-CNN Object Detection with PyTorch,https://www.reddit.com/r/deeplearning/comments/c25m59/faster_rcnn_object_detection_with_pytorch/,spmallick,1560881218,,2,30
167,2019-6-19,2019,6,19,3,c267fp,[Help] Has anyone trained Yolov3 on COCO?,https://www.reddit.com/r/deeplearning/comments/c267fp/help_has_anyone_trained_yolov3_on_coco/,pitafallafel,1560883998,"Hi, I am trying to retrain Yolov3 on COCO, using [this](https://github.com/YunYang1994/tensorflow-yolov3) repo. I twisted some stuff, changed the input pipeline but after some checks, everything seems right. Training seems to stabilize around 45%mAP@50, which is much lower than the paper (55mAP). I am wondering if maybe the hyperparameters are wrong. I used Adam(1e-4), batch size of 8. After checking several implementations (pjreddie, alexey, ultralytics), it seems they use nesterov + weight decay, with a batch size of 64, so I implemented this version too and am ready to launch it. Now I have several questions:

\- Do you think a simple change of optimizer and batch size could fix this mAP gap? 10% mAP@50 seems a lot.

\- If anyone has successfully trained it, could they share their hyperparameters (nesterov is much slower than Adam, so if a training is successful with Adam it would help a lot). There are not a lot of people on these repos that really detail their training routines, share their loss curves and show the final results.

\- Do you have some leads to debug it?

I am screwing up somewhere, and it is REALLY frustrating me. Thanks for any help",7,4
168,2019-6-19,2019,6,19,8,c298bm,"What's the ""best"" workstation for RTX 2070 &amp; an image processing project?",https://www.reddit.com/r/deeplearning/comments/c298bm/whats_the_best_workstation_for_rtx_2070_an_image/,iheartcookiecrisp,1560898905,"I'm specifically looking to get a workstation that works with NVDIA's RTX 2070 (just one) and AMD CPU (AMD Ryzen). Preferably, the workstation would have 2 GPU slots at least in case I want to add on more GPUs in the future. I know my system needs a lot of memory for the project I'm doing (involves a lot of image processing and CUDA), but other than that, I'm kind of lost as to which workstation would best suit my needs. 

&amp;#x200B;

One system that seems like it could have worked is the [TensorBook from Lambda Labs](https://lambdalabs.com/deep-learning/laptops/tensorbook/basic/customize), but it looks more like a gaming laptop than a deep learning machine.",12,7
169,2019-6-19,2019,6,19,14,c2czw2,How to do when the train image is too large to fed into the network onece time?,https://www.reddit.com/r/deeplearning/comments/c2czw2/how_to_do_when_the_train_image_is_too_large_to/,ruokuanwu,1560921853,"I'm using [voxelmorph](https://github.com/voxelmorph/voxelmorph) to do lung image registration. But my train images are too large to fed into the network, also the images have different shape, and the shape are not regular, some are 513,436...(not multiple of 2, so can not directly use U-NET or other CNN).

To address these problems, I split the train images into 128x128x128 sub-images with step=100. it looks like this: 

&amp;#x200B;

[split images](https://i.redd.it/1n8kexdiy8531.png)

In the predict phase, I also split the image into some sub-images, use the network to predict every sub-image, then I combine the results. But there is a problem that the boundaries of the sub-images look different with the internal region,like this:

&amp;#x200B;

[boundary problem](https://i.redd.it/mct36m1qy8531.png)

My naive approach is smoothig, But I found it does not work. I think this is a common problem. How to fix this? Please help.",3,0
170,2019-6-19,2019,6,19,19,c2f8df,Interviewing for Google AI Residency: My ML Journey,https://www.reddit.com/r/deeplearning/comments/c2f8df/interviewing_for_google_ai_residency_my_ml_journey/,init__27,1560939030,"Hi Everyone! 

The title really says it, I recently made it to the final rounds of the Google AI Residency interviews. This post describes my journey and experience:

&amp;#x200B;

Link to post: [https://medium.com/@init\_27/interviewing-for-google-ai-residency-a-kaggle-gold-finish-dsnet-launch-c621930b043d](https://medium.com/@init_27/interviewing-for-google-ai-residency-a-kaggle-gold-finish-dsnet-launch-c621930b043d)",4,53
171,2019-6-19,2019,6,19,20,c2fzlx,A Quick Easy Guide to Deep Learning with Java  Deeplearaning4j / DL4J,https://www.reddit.com/r/deeplearning/comments/c2fzlx/a_quick_easy_guide_to_deep_learning_with_java/,Shilpa_Opencodez,1560944676,,0,2
172,2019-6-19,2019,6,19,21,c2gmi5,Short Course on DL in South Florida,https://www.reddit.com/r/deeplearning/comments/c2gmi5/short_course_on_dl_in_south_florida/,mpcrlab,1560948320," Calling all enthusiastic learners!This summer you could be part of MPCRs Deep Learning Short Course 

From August 13-16th the Machine Perception and Cognitive Robotics Laboratory will be hosting an expedited learning experience from the very basics of what deep learning is all the way to how we can apply it in our everyday endeavors! By the time you and your friends leave, youll be implementing models and heading conversations in AI. We invite you to check out this amazing opportunity at [http://mpcrlab.com/shortcourse19/](http://mpcrlab.com/shortcourse19/). Please see the details below and well look forward to seeing you soon. [Here is a link to our flyer!](https://imgur.com/a/vxC79Xh)

For any philanthropist who would like to sponsor students, please directly email: [DLshortcourse@pmcrlab.com](mailto:DLshortcourse@pmcrlab.com). People like you really do make a difference!",0,1
173,2019-6-19,2019,6,19,22,c2hf2q,[Research]Word-Level Speech Recognition With a Dynamic Lexicon,https://www.reddit.com/r/deeplearning/comments/c2hf2q/researchwordlevel_speech_recognition_with_a/,cdossman,1560952702," [https://medium.com/ai%C2%B3-theory-practice-business/achieving-efficient-direct-to-word-speech-recognition-d83eba6f57b0?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/achieving-efficient-direct-to-word-speech-recognition-d83eba6f57b0?postPublishedType=initial) 

**Abstract:**  We propose a direct-to-word sequence model with a dynamic lexicon. Our word network constructs word embeddings dynamically from the character level tokens. The word network can be integrated seamlessly with arbitrary sequence models including Connectionist Temporal Classification and encoder-decoder models with attention. Sub-word units are commonly used in speech recognition yet are generated without the use of acoustic context. We show our direct-to-word model can achieve word error rate gains over sub-word level models for speech recognition. Furthermore, we empirically validate that the word-level embeddings we learn contain significant acoustic information, making them more suitable for use in speech recognition. We also show that our direct-to-word approach retains the ability to predict words not seen at training time without any retraining.",0,2
174,2019-6-20,2019,6,20,0,c2i96c,Machine Learning using Azure Machine Learning (AzureML),https://www.reddit.com/r/deeplearning/comments/c2i96c/machine_learning_using_azure_machine_learning/,HannahHumphreys,1560957027,[removed],0,1
175,2019-6-20,2019,6,20,1,c2j0di,Confusion Matrix Simplified,https://www.reddit.com/r/deeplearning/comments/c2j0di/confusion_matrix_simplified/,DataScienceWithRJ,1560960815,"Confusion Matrix 
It is used to describe the performance of classifier. It can be used to derive various model evaluation metrics. 

https://youtu.be/eyLxo1ATD2Q",1,1
176,2019-6-20,2019,6,20,2,c2jq9v,What are some beginner projects in Deep Learning.,https://www.reddit.com/r/deeplearning/comments/c2jq9v/what_are_some_beginner_projects_in_deep_learning/,reddyManudeep,1560964291,I just completed Andrew ng's specialisation.,2,1
177,2019-6-20,2019,6,20,2,c2jqxn,PHP for Beginners  Become a PHP Master  CMS Project,https://www.reddit.com/r/deeplearning/comments/c2jqxn/php_for_beginners_become_a_php_master_cms_project/,Free_Education123,1560964379,,0,1
178,2019-6-20,2019,6,20,2,c2js26,Is it true that Bahdanau's attention mechanism is not Global like Luong's?,https://www.reddit.com/r/deeplearning/comments/c2js26/is_it_true_that_bahdanaus_attention_mechanism_is/,real_pinocchio,1560964530,,1,6
179,2019-6-20,2019,6,20,3,c2knn9,Any good tutorials for using UNets for instance segmentation,https://www.reddit.com/r/deeplearning/comments/c2knn9/any_good_tutorials_for_using_unets_for_instance/,DucotrDumbutt,1560968639,"Hi guys,

I'm currently preparing for a project where I'm going to be analyzing high resolution images of some slides with organic tissue, and need to do per-pixel segmentation on each type of tissue on the slide (muscle tissue, membrane, etc.) And I'm kind of freaking out about it.

I've been looking for tutorials everywhere but they keep being coded in those infernal notebooks that I really can not use. 

I'm working on a remote gpu cluster with keras and tensorflow in python. If someone can direct me to a tutorial or a repo that does instance segmentation on images that doesn't involve stuff like ipython, jupyter, and stuff, I would REALLY appreciate that.

Thanks for the help!",6,6
180,2019-6-20,2019,6,20,4,c2ljfl,Relational Reasoning Tasks,https://www.reddit.com/r/deeplearning/comments/c2ljfl/relational_reasoning_tasks/,lollocat3,1560972837,"I have recently read this paper on Arxiv about recurrent relational networks used to solve relational reasoning tasks: 


https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://arxiv.org/abs/1711.08028&amp;ved=2ahUKEwicnJTjmvbiAhVKY1AKHRTKBmIQFjAAegQIBxAB&amp;usg=AOvVaw2z89rvMn-uSXBe8BArUaqp&amp;cshid=1560970177794

In this paper, the author evaluates the network on the Babi and CLEVR dataset and on Sudokus with 17 givens. I was wondering if any of you knew of other relatively complex relational reasoning tasks on which I could test the architecture on.
Thanks in advance",0,5
181,2019-6-20,2019,6,20,4,c2llnv,Best course of action for a Faster-RCNN implementation,https://www.reddit.com/r/deeplearning/comments/c2llnv/best_course_of_action_for_a_fasterrcnn/,DanMan259,1560973144,"I have a faster-rcnn caffe model that I am using, and was looking to transfer to the tensorflow object detection api. What would be the suggested method for translating the model from caffe to tensorflow.",0,4
182,2019-6-20,2019,6,20,15,c2sgw5,"SEN12MS: Largest, curated satellite imagery dataset",https://www.reddit.com/r/deeplearning/comments/c2sgw5/sen12ms_largest_curated_satellite_imagery_dataset/,burn_in_flames,1561011725,,9,17
183,2019-6-20,2019,6,20,17,c2taom,Can anyone share simple pytorch implementation of style gan?,https://www.reddit.com/r/deeplearning/comments/c2taom/can_anyone_share_simple_pytorch_implementation_of/,sanchit2843,1561017950,,0,1
184,2019-6-20,2019,6,20,18,c2u4q5,Deep learning models combine,https://www.reddit.com/r/deeplearning/comments/c2u4q5/deep_learning_models_combine/,nanitiru18,1561024755,How can I extend image segmentation(UNET) with a classifier for semantic segmentation to get better accuracy.,0,1
185,2019-6-20,2019,6,20,20,c2uz37,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c2uz37/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561030870,[removed],0,1
186,2019-6-20,2019,6,20,22,c2vv9h,Visualizing CNN filters,https://www.reddit.com/r/deeplearning/comments/c2vv9h/visualizing_cnn_filters/,PyWarrior,1561036381,"I want to learn the entire concept of **Visualizing CNN filters**. I have googled many articles over the internet regarding this but I couldn't find any detailed article. 

I want to gain insight over the mathematical concept involved.",17,23
187,2019-6-20,2019,6,20,23,c2wmmx,Tensorflow facenet,https://www.reddit.com/r/deeplearning/comments/c2wmmx/tensorflow_facenet/,alexjolly28,1561040581,"is there anyone who worked with Tensorflow facenet... I'm stuck at validation code...
thank you",0,1
188,2019-6-21,2019,6,21,0,c2xf2o,"[Project] Tensorflow implementation of ""Zero-Shot Knowledge Distillation in Deep Networks """,https://www.reddit.com/r/deeplearning/comments/c2xf2o/project_tensorflow_implementation_of_zeroshot/,sseung0703,1561044545,[removed],0,1
189,2019-6-21,2019,6,21,3,c2zrg7,"CVPR Daily of today, Thursday 20 June - Directly from CVPR 2019 in Long Beach",https://www.reddit.com/r/deeplearning/comments/c2zrg7/cvpr_daily_of_today_thursday_20_june_directly/,Gletta,1561055918,,0,1
190,2019-6-21,2019,6,21,13,c35x26,Best GPU for machine learning / deep learning,https://www.reddit.com/r/deeplearning/comments/c35x26/best_gpu_for_machine_learning_deep_learning/,durgesh2018,1561090242,"Hello everyone!
I want to upgrade my existing GTX 950 for deep learning purpose. Please suggest me a decent GPU under 500 USD.

My build is:
Intel dh87RL mother board
Intel i5 4670 processor
Samsung 256 GB SSD
Corsair VS 550 PSU

Thank you!",15,2
191,2019-6-21,2019,6,21,13,c35y66,Donald Trump Reads The Navy Seal Copypasta (Deepfake),https://www.reddit.com/r/deeplearning/comments/c35y66/donald_trump_reads_the_navy_seal_copypasta/,hanyuqn,1561090440,,0,16
192,2019-6-21,2019,6,21,19,c38ugx,A comprehensive intro to PyTorch,https://www.reddit.com/r/deeplearning/comments/c38ugx/a_comprehensive_intro_to_pytorch/,whitezl0,1561112180,,2,43
193,2019-6-21,2019,6,21,19,c392ah,Course 3 of the deeplearning.ai TensorFlow Specialization is now available: TensorFlow in Practice | Coursera,https://www.reddit.com/r/deeplearning/comments/c392ah/course_3_of_the_deeplearningai_tensorflow/,lopespm,1561113897,,2,17
194,2019-6-21,2019,6,21,21,c3a74w,Generative Adversarial Networks - The Story So Far,https://www.reddit.com/r/deeplearning/comments/c3a74w/generative_adversarial_networks_the_story_so_far/,pirate7777777,1561121615,,0,29
195,2019-6-21,2019,6,21,21,c3a8xq,[Research] Toward Interpretable Music Tagging with Self-Attention,https://www.reddit.com/r/deeplearning/comments/c3a8xq/research_toward_interpretable_music_tagging_with/,cdossman,1561121915," [https://medium.com/ai%C2%B3-theory-practice-business/toward-interpretable-music-tagging-with-self-attention-67a8136048d0?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/toward-interpretable-music-tagging-with-self-attention-67a8136048d0?postPublishedType=initial) 

**Abstract:**  Self-attention is an attention mechanism that learns a representation by relating different positions in the sequence. The transformer, which is a sequence model solely based on self-attention, and its variants achieved state-of-the-art results in many natural language processing tasks. Since music composes its semantics based on the relations between components in sparse positions, adopting the self-attention mechanism to solve music information retrieval (MIR) problems can be beneficial. Hence, we propose a self-attention based deep sequence model for music tagging. The proposed architecture consists of shallow convolutional layers followed by stacked Transformer encoders. Compared to conventional approaches using fully convolutional or recurrent neural networks, our model is more interpretable while reporting competitive results. We validate the performance of our model with the MagnaTagATune and the Million Song Dataset. In addition, we demonstrate the interpretability of the proposed architecture with a heat map visualization.",0,1
196,2019-6-22,2019,6,22,0,c3bqgg,Deep Learning Machine Shutting Off When Using Both GPUs,https://www.reddit.com/r/deeplearning/comments/c3bqgg/deep_learning_machine_shutting_off_when_using/,clarke_msmd,1561129647,"I have been using my machine for a couple of months now to successfully train 3d CNNs. However, recently if I try to train a model using both GPUs, the machine (along with all of the lights on the motherboard) will turn off. The only way to turn the machine back on again is to unplug the PSU, wait \~30 sec and plug back in again. I can still use each card individually, just not at the same time. Any ideas as to what could be going on?

&amp;#x200B;

Motherboard: Asrock Taichi X399

CPU: AMD Threadripper 2950x

GPU: 2x EVGA 2080ti Black edition

PSU: EVGA Supernova 1000 PQ 80+ Platinum

RAM: 4x Corsair LPX 2666 Hz 16 GB

SSD: Samsung 970 Evo 500GB

SSD: Samsung 860 Evo 2TB",4,2
197,2019-6-22,2019,6,22,3,c3eae8,[D] Any references for deep learning on non uniform and unstructured meshes/ grids?,https://www.reddit.com/r/deeplearning/comments/c3eae8/d_any_references_for_deep_learning_on_non_uniform/,pradeep_sinngh,1561141161,,1,5
198,2019-6-22,2019,6,22,4,c3f2sx,"[Revision/Study Group] fast.ai Part 1 2019, Saturdays 4PM IST (Zoom calls)",https://www.reddit.com/r/deeplearning/comments/c3f2sx/revisionstudy_group_fastai_part_1_2019_saturdays/,init__27,1561144745,[removed],0,1
199,2019-6-22,2019,6,22,5,c3fuhs,Hello guys this is one of my project based on face recognition.,https://www.reddit.com/r/deeplearning/comments/c3fuhs/hello_guys_this_is_one_of_my_project_based_on/,Ckvb,1561148337,"https://github.com/CKVB/FACE-RECOGNITION-BASED-SMART-ATTENDANCE-MANAGMENT-SYSTEM-USING-DLIB/blob/master/README.md

I would like to hear some feedback if any.",0,0
200,2019-6-22,2019,6,22,6,c3h3z2,Giving my future reinforced neural network a little boost to learn to play a game,https://www.reddit.com/r/deeplearning/comments/c3h3z2/giving_my_future_reinforced_neural_network_a/,elmazzun,1561154352,"I'm making a neural network that can play The Binding of Isaac.  
Up now, this is what I planned to do:

1. feed YOLO or OpenCV with screenshots from running game;
2. teach the vision library to detect in-game objects: enemies, items, walls, rocks, ...
3. train a reinforced neural network to take decisions according to game events from screenshots.

In all the articles I read about reinforcement learning (offline Chrome dinosaur jumping trees, Flappy Birds, Snake, ...) the neural network is abandoned to itself, making random movements, taking damage, dying, getting a penalty and so on, generation by generation, until it learns how to stay alive.

This is the ""boost"" I wrote about in the title: *instead of making the poor Isaac randomly dying until he learns, is it possible to make him learn by some actual gameplays of mine?*

Let me explain: it would be nice seeing little Isaac making his way through all the enemies, but it would be nicer to make him do more.

* there are hidden rooms: you should blow up a wall in order to discover a hidden room, but you must use bombs which are not infinite; the net can't blow up every wall of the game, not enough bombs and there should be a pattern to discover hidden rooms;
* by learning from my gameplays, the net may learn a not perfect gameplay and I may contaminate its learning, but at least he would not take hundreds of generations to learn that getting hit is not good;
* there are items that have more sinergies with others, but there are so many items that it would faster to code these sinergies and just train the vision library to detect items;
* after defeating a boss, there are choices: go to the next level, go to the bonus room, go back to do something that was not possible to do prior defeting the boss, ...

I'd code what can be coded (like item sinergies), but all other possibilities may be learned from a gameplay, that would be worth hundreds of line codes!  


Back to my original question: I'd like to be a more present father to Isaac and give him some life tips with my gameplays instead of letting him roaming wild xD

What I miss is some theory about this reinforcement learning: **is it possible / advisable / recommended to provide a hybrid learning to this neural network**?  
Is it right to make him learn the basics of the game with my gameplays and then let him walk on his feet with what I taught him?

&amp;#x200B;

Thanks in advance for the support. If this project will sail, I'd love to share my GitHub with you.",1,2
201,2019-6-22,2019,6,22,7,c3hpbq,Building a CIFAR classifier neural network with PyTorch,https://www.reddit.com/r/deeplearning/comments/c3hpbq/building_a_cifar_classifier_neural_network_with/,coffeepants87,1561157321,,0,0
202,2019-6-22,2019,6,22,14,c3lo0m,"Not sure if this is the correct thread, GPU related.",https://www.reddit.com/r/deeplearning/comments/c3lo0m/not_sure_if_this_is_the_correct_thread_gpu_related/,Ryzen120,1561180494,"So hoping someone in this thread can help or direct me to the correct place. Anyways, can one run a Teska k80 GPU for their training models while using another AMD card to just display graphics and do other basic activities while the model is trained using tensorflow ?",3,3
203,2019-6-22,2019,6,22,20,c3ojdp,Using deep learning for indoor autonomous navigation of a small quad-rotor. Need help with research,https://www.reddit.com/r/deeplearning/comments/c3ojdp/using_deep_learning_for_indoor_autonomous/,atmadeepArya,1561202268,"Hi, So for my masters thesis, I want to make a neural network for indoor navigation of a small quad-rotor. The data will be generated initially by a simulation, and then I want to test it in real world. I need help on the following topics:

1. Can you guys help with some research papers of your choice?
2. Which universities/ research groups are doing/interested in this kind of work?
3. What are the absolute basics which I should know before proceeding?

I only have about a year to complete this project (integrated course) so I'm looking for something not-so-difficult.",1,5
204,2019-6-22,2019,6,22,22,c3pisk,Google Colab: FileNotFoundError,https://www.reddit.com/r/deeplearning/comments/c3pisk/google_colab_filenotfounderror/,DebayonDC,1561209019,"`# Run this cell to mount your Google Drive.`

`from google.colab import drive`

`drive.mount('/content/drive')`

&amp;#x200B;

I used the above code as given by the Google colab and drive got mounted successfully but I get a ""File Not Found Error"" when trying to import some data from Google Drive. Someone kindly help me out. The Code that I used for importing data (""images in this case"") is as follows:

&amp;#x200B;

&lt;&gt;

`training_set = train_datagen.flow_from_directory(`

`'content/drive/My Drive/Colab_Data/dataset/training_set',`

`target_size=(64, 64),`

`batch_size=32,`

`class_mode='binary')`

&lt;/&gt;

and the output of the Notebook Error is as follows:

&lt;&gt;

 \--------------------------------------------------------------------------- FileNotFoundError                         Traceback (most recent call last) [&lt;ipython-input-13-ffd4a90d6c52&gt;](https://localhost:8080/#) in &lt;module&gt;()       **3** target\_size=(64, 64),       **4** batch\_size=32, ----&gt; 5         class\_mode='binary')  1 frames[/usr/local/lib/python3.6/dist-packages/keras\_preprocessing/image/image\_data\_generator.py](https://localhost:8080/#) in flow\_from\_directory(self, directory, target\_size, color\_mode, classes, class\_mode, batch\_size, shuffle, seed, save\_to\_dir, save\_prefix, save\_format, follow\_links, subset, interpolation)     **538** follow\_links=follow\_links,     **539** subset=subset, --&gt; 540 interpolation=interpolation     **541**         )     **542**   [/usr/local/lib/python3.6/dist-packages/keras\_preprocessing/image/directory\_iterator.py](https://localhost:8080/#) in \_\_init\_\_(self, directory, image\_data\_generator, target\_size, color\_mode, classes, class\_mode, batch\_size, shuffle, seed, data\_format, save\_to\_dir, save\_prefix, save\_format, follow\_links, subset, interpolation, dtype)     **104** if not classes:     **105** classes = \[\] --&gt; 106 for subdir in sorted(os.listdir(directory)):     **107** if os.path.isdir(os.path.join(directory, subdir)):     **108** classes.append(subdir)  FileNotFoundError: \[Errno 2\] No such file or directory: 'content/drive/My Drive/Colab\_Data/dataset/training\_set' 

&lt;/&gt;",9,5
205,2019-6-22,2019,6,22,22,c3pkp3,Deep learning - price prediction - papers/code,https://www.reddit.com/r/deeplearning/comments/c3pkp3/deep_learning_price_prediction_paperscode/,_synaps_,1561209338,"Hi,

do you know any nice state of the deep learning algorithms or research papers which are treating the topic price prediction or trading suggestion?

thnx!",2,22
206,2019-6-22,2019,6,22,23,c3q5uc,A question about text prediction RNNs,https://www.reddit.com/r/deeplearning/comments/c3q5uc/a_question_about_text_prediction_rnns/,ivxnc,1561212819,"So I want to create a word predict RNN that I am going to feed with the books from one author(I want to capture his style). So when I started thinking about the process, I  got confused by the following: Would training a RNN with one book at a time, then saving it's weights for the next book and so on be the same as loading the same RNN with all of the books at once(if not, which do you think would be better and why). I'm learning ML/DL since January, and this question never occured me really. It's probably very intuitive, but I can't get around it. Thanks in advance",4,4
207,2019-6-22,2019,6,22,23,c3qahv,How Hadoop Helps Solve the Big Data Problem?,https://www.reddit.com/r/deeplearning/comments/c3qahv/how_hadoop_helps_solve_the_big_data_problem/,raj11113,1561213553,,0,2
208,2019-6-23,2019,6,23,0,c3qy0d,IBM Data Science Professional Certificate,https://www.reddit.com/r/deeplearning/comments/c3qy0d/ibm_data_science_professional_certificate/,HannahHumphreys,1561217051,[removed],0,1
209,2019-6-23,2019,6,23,0,c3r77w,Robotics Revolution in Healthcare Industry - Introduction,https://www.reddit.com/r/deeplearning/comments/c3r77w/robotics_revolution_in_healthcare_industry/,BlockDelta,1561218424,,0,1
210,2019-6-23,2019,6,23,1,c3rr73,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c3rr73/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561221249,[removed],0,1
211,2019-6-23,2019,6,23,1,c3s1l4,Indoor localizations and NN/DNN papers,https://www.reddit.com/r/deeplearning/comments/c3s1l4/indoor_localizations_and_nndnn_papers/,konradbjk,1561222674,"Hello,

I am looking for papers about usage of neural or deep neural networks to predict signal errors. Preferably in area of indoor localizations.",3,1
212,2019-6-23,2019,6,23,2,c3s349,Correct way for transfer learning?,https://www.reddit.com/r/deeplearning/comments/c3s349/correct_way_for_transfer_learning/,waterchiller,1561222876,,1,2
213,2019-6-23,2019,6,23,12,c3yvrb,What's the actual reason for exploding gradients?,https://www.reddit.com/r/deeplearning/comments/c3yvrb/whats_the_actual_reason_for_exploding_gradients/,revolutionizescience,1561262297,"In case of vanishing gradients,
1. We know that product of 2 numbers between (0,1) gives still smaller number. 
eg: 0.1 * 0.3 = 0.03
2. So if gradients are smaller then in  case of deep network ,this effects the earlier layers. 
eg. (0.5)^10 = exponentially small. 
3. But why does gradients are smaller in the first place, because we can see that by the graph of derivative of sigmoid or tanh . The range is (0,0.25) for sigmoid and (0,1) for tanh.

So, I want to understand that how does gradients become larger, which in turn causes exploding gradient problem. Help needed.",14,3
214,2019-6-23,2019,6,23,16,c40qff,Performance on CPU vs GPU.,https://www.reddit.com/r/deeplearning/comments/c40qff/performance_on_cpu_vs_gpu/,lxknvlk,1561275934," 

I was making load tests on a model that classifies nsfw images. I was expecting the performance on a high end GPU to be better.

&amp;#x200B;

1) aws c5.large instance (2vCPU, 4 gm mem) using caffe-cpu : processing an image takes about 700ms

2) aws p3.2xlarge specialized deep learning GPU instance with a Tesla V100 GPU, (16gb gpu mem, 8 vCPU, 61gb mem), using caffe-gpu with cuda, cudnn, and all that stuff - and it processes the image in about 950ms.

I expected the processing time to be much faster. Am I misunderstanding something?",9,13
215,2019-6-24,2019,6,24,10,c4gdgv,I wrote my first blog on RNNs!,https://www.reddit.com/r/deeplearning/comments/c4gdgv/i_wrote_my_first_blog_on_rnns/,MLnub22,1561339965,"Hi all, I just wrote my first blog on RNNs and was hoping to get some feedback. This blog post is my current understanding of RNNs, so it would be great to know if what I think I know about RNNs are wrong (especially the math / backpropagation part). 

&amp;#x200B;

Big thanks in advance. I'm open to any discussion around the topic!",3,28
216,2019-6-24,2019,6,24,11,c4gy3l,Edge Computing - Event Horizon Part I,https://www.reddit.com/r/deeplearning/comments/c4gy3l/edge_computing_event_horizon_part_i/,BlockDelta,1561342718,,0,0
217,2019-6-24,2019,6,24,12,c4hnfu,Label Smoothing: An ingredient of higher accuracy when there is mislabeled data,https://www.reddit.com/r/deeplearning/comments/c4hnfu/label_smoothing_an_ingredient_of_higher_accuracy/,solitary_sandman,1561346977,,0,12
218,2019-6-24,2019,6,24,14,c4ipzn,Style Transfer Medley,https://www.reddit.com/r/deeplearning/comments/c4ipzn/style_transfer_medley/,dstein64,1561353911,,0,0
219,2019-6-24,2019,6,24,15,c4jfmp,"Tips for making a GAN's outputs more diverse? This one works fine, but seems to lack variety.",https://www.reddit.com/r/deeplearning/comments/c4jfmp/tips_for_making_a_gans_outputs_more_diverse_this/,patr1234,1561359072,,2,2
220,2019-6-24,2019,6,24,17,c4k533,Attention Mechanisms Implementation,https://www.reddit.com/r/deeplearning/comments/c4k533/attention_mechanisms_implementation/,pylocke,1561364479,"Hi everyone! Attention has been a hot topic in computer vision and natural language processing for a while. While trying to use attention mechanism in a language modeling RNN project of mine, I came up across countless different implementations online. Most of them differed from what I expected to see by reading the papers that introduced the concepts to the domain in the first place, and the challenge doubled since I was trying to use attention for a many-to-one sequence task instead of the conventional many-to-many.

Hence, I created my own implementations and I want to share them with you here in case anyone is going through the same path or just wants to learn about the different attention mechanisms: [https://github.com/ongunuzaymacar/attention-mechanisms](https://github.com/ongunuzaymacar/attention-mechanisms). It includes implementations of various papers and I am hoping to extend it as I encounter different versions. Feel free to share your opinions with me in case you spot something odd or have a suggestion!",0,5
221,2019-6-24,2019,6,24,21,c4n9en,Advice on how to pick the right architecture,https://www.reddit.com/r/deeplearning/comments/c4n9en/advice_on_how_to_pick_the_right_architecture/,zerociudo,1561380734,"Hello, I am creating a car licence plate detection and recognition model for learning purposes and I cant wrap my head around the many architecture choices I have. Basically I am think of using YOLO v2 or v3 to detect the vehicle and the licence plate, then use character segmentation and recognition to extract licence plate characters.

I have seen couple of YOLO v2 papers and I could use architecture similar to DarkNet-19 but I feel like it is quite a lot layers for this problem if I assume that I will have only 1 licence plate per image on my dataset. 

A lot of papers use customized YOLOv2 architectures that I have read and I am not sure how could I customize it for my problem exactly, I did study CNN architectures, but I do not have the intuition for picking right filters sizes or layers amount.

Are there some references on this that I could read/watch or which architecture you would advice?",6,20
222,2019-6-24,2019,6,24,23,c4p8te,[Research] Adversarial Attacks on Copyright Detection Systems,https://www.reddit.com/r/deeplearning/comments/c4p8te/research_adversarial_attacks_on_copyright/,cdossman,1561388109," [https://medium.com/ai%C2%B3-theory-practice-business/adversarial-attacks-on-copyright-detection-systems-3dacc64d9702?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/adversarial-attacks-on-copyright-detection-systems-3dacc64d9702?postPublishedType=initial) 

 It is well-known that many machine learning models are susceptible to so-called ""adversarial attacks,"" in which an attacker evades a classifier by making small perturbations to inputs. This paper discusses how industrial copyright detection tools, which serve a central role on the web, are susceptible to adversarial attacks. We discuss a range of copyright detection systems, and why they are particularly vulnerable to attacks. These vulnerabilities are especially apparent for neural network based systems. As a proof of concept, we describe a well-known music identification method, and implement this system in the form of a neural net. We then attack this system using simple gradient methods. Adversarial music created this way successfully fools industrial systems, including the AudioTag copyright detector and YouTubes Content ID system. Our goal is to raise awareness of the threats posed by adversarial examples in this space, and to highlight the importance of hardening copyright detection systems to attacks.",0,15
223,2019-6-25,2019,6,25,0,c4pxyr,"A PyTorch implementation of ""Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks"" (KDD 2019)",https://www.reddit.com/r/deeplearning/comments/c4pxyr/a_pytorch_implementation_of_clustergcn_an/,benitorosenberg,1561390503,"&amp;#x200B;

https://i.redd.it/b4rp0143qb631.jpg

GitHub: [https://github.com/benedekrozemberczki/ClusterGCN](https://github.com/benedekrozemberczki/ClusterGCN)

Paper: [https://arxiv.org/abs/1905.07953](https://arxiv.org/abs/1905.07953)

Abstract:

Graph  convolutional network (GCN) has been successfully applied to many   graph-based applications; however, training a large-scale GCN remains   challenging. Current SGD-based algorithms suffer from either a high   computational cost that exponentially grows with number of GCN layers,   or a large space requirement for keeping the entire graph and the   embedding of each node in memory. In this paper, we propose Cluster-GCN,   a novel GCN algorithm that is suitable for SGD-based training by   exploiting the graph clustering structure. Cluster-GCN works as the   following: at each step, it samples a block of nodes that associate with   a dense subgraph identified by a graph clustering algorithm, and   restricts the neighborhood search within this subgraph. This simple but   effective strategy leads to significantly improved memory and   computational efficiency while being able to achieve comparable test   accuracy with previous algorithms. To test the scalability of our   algorithm, we create a new Amazon2M data with 2 million nodes and 61   million edges which is more than 5 times larger than the previous   largest publicly available dataset (Reddit). For training a 3-layer GCN   on this data, Cluster-GCN is faster than the previous state-of-the-art   VR-GCN (1523 seconds vs 1961 seconds) and using much less memory (2.2GB   vs 11.2GB). Furthermore, for training 4 layer GCN on this data, our   algorithm can finish in around 36 minutes while all the existing GCN   training algorithms fail to train due to the out-of-memory issue.   Furthermore, Cluster-GCN allows us to train much deeper GCN without much   time and memory overhead, which leads to improved prediction   accuracy---using a 5-layer Cluster-GCN, we achieve state-of-the-art test   F1 score 99.36 on the PPI dataset, while the previous best result was   98.71.",0,1
224,2019-6-25,2019,6,25,0,c4pzb6,Deep Learning Project,https://www.reddit.com/r/deeplearning/comments/c4pzb6/deep_learning_project/,harsh_sagar,1561390634,"Hi Everyone!

I    am sharing the GitHub link to my project 'Image Classification on  Fashion-MNIST dataset using CNN' . I have tried to write a well  commented code, so that   anyone can learn from it. I have also added  some presentation slides for better understanding.

The project is done on Fashion-Mnist dataset  which can be downloaded from Kaggle.

[https://github.com/harshgarg27/LastAssignment\_DeepLeraning\_CNN\_Classification](https://github.com/harshgarg27/LastAssignment_DeepLeraning_CNN_Classification)

Feel free to give suggestions and reviews.

Thanks!",1,2
225,2019-6-25,2019,6,25,1,c4r1cw,I wanted to ask about the inpainting results from all major papers (GAN based approach)?,https://www.reddit.com/r/deeplearning/comments/c4r1cw/i_wanted_to_ask_about_the_inpainting_results_from/,nile6499,1561394292,"The model trained and tested on is often CelebA (Aligned), which results in generating over fitted images. The conference really don't care about over fitting of GANs on a particular dataset? I believe training should be on different dataset than testing.

Training on CelebA, and testing on LFW makes more sense rather than generating over fitted images.",1,5
226,2019-6-25,2019,6,25,5,c4v56s,dnn Compiler,https://www.reddit.com/r/deeplearning/comments/c4v56s/dnn_compiler/,srohit0,1561408306,"Calling all  developers and deep learning enthusiasts for [opensource](https://twitter.com/hashtag/opensource?src=hashtag_click) [\#deeplearning](https://twitter.com/hashtag/deeplearning?src=hashtag_click) [\#compiler](https://twitter.com/hashtag/compiler?src=hashtag_click) [\#development](https://twitter.com/hashtag/development?src=hashtag_click)  targets for [\#ComputerVision](https://twitter.com/hashtag/ComputerVision?src=hashtag_click) [\#embedded](https://twitter.com/hashtag/embedded?src=hashtag_click) [\#application](https://twitter.com/hashtag/application?src=hashtag_click) on [\#platforms](https://twitter.com/hashtag/platforms?src=hashtag_click) like [\#riscV](https://twitter.com/hashtag/riscV?src=hashtag_click) and  [\#RaspberryPi](https://twitter.com/hashtag/RaspberryPi?src=hashtag_click).

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/9olbapry6d631.png",1,0
227,2019-6-25,2019,6,25,5,c4vd4b,Can't fine tune VGG16 to classify dog breeds,https://www.reddit.com/r/deeplearning/comments/c4vd4b/cant_fine_tune_vgg16_to_classify_dog_breeds/,reddyManudeep,1561409080,"I fine-tuned VGG-16 to classify dog breeds using the Stanford Dog dataset with 120 classes.

I removed the FC layers and added a Dense(4096) and Dense(120, softmax). First, for a few epochs, I froze the layers of base vgg-16 to warm up FC layers.( With small learning rate)

After that, I unfroze the last block of Conv layers and trained the model. But still I am not able to achieve a decent acc/val_acc. Is there anything that I can fix? or should I consider fine-tuning other models like resnet etc?",10,4
228,2019-6-25,2019,6,25,10,c4ztzh,computer vision article,https://www.reddit.com/r/deeplearning/comments/c4ztzh/computer_vision_article/,iraf1,1561425583,"hi
I am working in robotics field and computer vision.
I want to write an ISI article about deeplearning and computer vision. can someone help me to pick an up to date and practical subject.
thanks",0,1
229,2019-6-25,2019,6,25,10,c506r5,Image Sequence to Image Sequence Architecture,https://www.reddit.com/r/deeplearning/comments/c506r5/image_sequence_to_image_sequence_architecture/,pmpforever,1561426960,"I have a problem where my data set is a sequence of (satellite) images and I would like to write a model which takes a sequence of images and generates a sequence of new images. These new images are novel but similar to their predecessors. I don't have too much experience with Deep Learning, I understand CNNs and RNNs and bit about LSTMs and GRUs. What kinds of architectures should I look at for solving this type of problem?",3,2
230,2019-6-25,2019,6,25,12,c51pgh,GTX 1080 ti or RTX 2060,https://www.reddit.com/r/deeplearning/comments/c51pgh/gtx_1080_ti_or_rtx_2060/,durgesh2018,1561433438,"Hello everyone,
I am planning to buy a GPU for tinkering with machine learning and deep learning.

Please suggest me a card in 1080ti and RTX 2060.

My budget is 500 USD in Indian market.",34,15
231,2019-6-25,2019,6,25,12,c522wr,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c522wr/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561435190,[removed],0,1
232,2019-6-25,2019,6,25,13,c52g3y,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c52g3y/data_science_career_track_prep_course/,HannahHumphreys,1561436951,[removed],0,1
233,2019-6-25,2019,6,25,15,c545jl,Pytorch 1.0 tutorials??,https://www.reddit.com/r/deeplearning/comments/c545jl/pytorch_10_tutorials/,kunalkarda,1561445691,"I want to learn pytorch but all tuts available on github and on websites are of ver 0.4 
So anyone has some link ??",2,1
234,2019-6-25,2019,6,25,16,c548xz,Google Colab,https://www.reddit.com/r/deeplearning/comments/c548xz/google_colab/,zom8ie99,1561446189,I trained the model using Kaggle GPU. and now I want to try Google Collab's TPU for training the CNN model. So I wanted to know if there are any issues in training the dataset using google colab.,19,6
235,2019-6-25,2019,6,25,18,c55olf,Introducing deep learning,https://www.reddit.com/r/deeplearning/comments/c55olf/introducing_deep_learning/,itspcificp,1561454403,"Dont believe in short term hype, but do believe in long-term vision by Prashant rai https://link.medium.com/pjvwEimUNX",0,1
236,2019-6-25,2019,6,25,19,c56ddq,How to decode an image on the GPU while training a network in Keras?,https://www.reddit.com/r/deeplearning/comments/c56ddq/how_to_decode_an_image_on_the_gpu_while_training/,ale152,1561458195,,0,1
237,2019-6-25,2019,6,25,23,c59nk5,[Research] Google AI: Applying AutoML to Transformer Architectures,https://www.reddit.com/r/deeplearning/comments/c59nk5/research_google_ai_applying_automl_to_transformer/,cdossman,1561474136," [https://medium.com/ai%C2%B3-theory-practice-business/google-ai-applying-automl-to-transformer-architectures-fd2e8402d2f7?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/google-ai-applying-automl-to-transformer-architectures-fd2e8402d2f7?postPublishedType=initial) 

Google AI conducted a large-scale NAS on translation task and discovered the Evolved Transformer (ET). Like most sequence to sequence (seq2seq) neural network architectures, it has an encoder that encodes the input sequence into embeddings and a decoder that uses those embeddings to construct an output sequence; in the case of translation, the input sequence is the sentence to be translated and the output sequence is the translation.",3,1
238,2019-6-25,2019,6,25,23,c59nzk,Neural Machine Translation With Attention Mechanism: Step-by-step Guide,https://www.reddit.com/r/deeplearning/comments/c59nzk/neural_machine_translation_with_attention/,Victor_Stakh,1561474189,,0,1
239,2019-6-26,2019,6,26,0,c59zo1,"Supervisely June Update: Keypoints, Python Scripts, and more!",https://www.reddit.com/r/deeplearning/comments/c59zo1/supervisely_june_update_keypoints_python_scripts/,tdionis,1561475564,,0,1
240,2019-6-26,2019,6,26,0,c5aic6,How big data is transforming the real estate industry,https://www.reddit.com/r/deeplearning/comments/c5aic6/how_big_data_is_transforming_the_real_estate/,raj11113,1561477719,,0,10
241,2019-6-26,2019,6,26,2,c5byyi,Deep Learning Research 2019,https://www.reddit.com/r/deeplearning/comments/c5byyi/deep_learning_research_2019/,selfcreation,1561483582,"Hi everyone!  
I just did a quick Web of Science analysis on deep learning research. As you can see in the screenshot below, there are about 7.000 publications for 2019. Since we're about half into the year, can you say that the publication count will double until the end of 2019? Which would mean that it would be less than 2018?

Thank you for your help!

https://i.redd.it/7c414ptiej631.png",0,1
242,2019-6-26,2019,6,26,2,c5c6bw,"#Learn how to make sure you are getting the best #predictions your model can provide. https://buff.ly/2ZFXbr4 @Experfy #MachineLearning #modeltuning #experfy #experfytraining #courses #ai For more courses, visit experfy.com/training",https://www.reddit.com/r/deeplearning/comments/c5c6bw/learn_how_to_make_sure_you_are_getting_the_best/,tstanya77,1561484397,,0,1
243,2019-6-26,2019,6,26,3,c5cnpv,Mask R-CNN Instance Segmentation with PyTorch,https://www.reddit.com/r/deeplearning/comments/c5cnpv/mask_rcnn_instance_segmentation_with_pytorch/,spmallick,1561486309,,2,58
244,2019-6-26,2019,6,26,3,c5cuez,Learn the fundamentals of deep learning and neural network models.,https://www.reddit.com/r/deeplearning/comments/c5cuez/learn_the_fundamentals_of_deep_learning_and/,VeenaBhargavi,1561487064,,0,0
245,2019-6-26,2019,6,26,11,c5jqq6,Implementation of 19 Regression algorithms in R using CPU performance data.,https://www.reddit.com/r/deeplearning/comments/c5jqq6/implementation_of_19_regression_algorithms_in_r/,HannahHumphreys,1561516249,[removed],0,1
246,2019-6-26,2019,6,26,12,c5kj4y,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c5kj4y/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561520197,[removed],0,1
247,2019-6-26,2019,6,26,13,c5kx3n,How does it work?,https://www.reddit.com/r/deeplearning/comments/c5kx3n/how_does_it_work/,Sahil8141,1561522226,,5,1
248,2019-6-26,2019,6,26,18,c5nr2e,Practical deep learning for coders,https://www.reddit.com/r/deeplearning/comments/c5nr2e/practical_deep_learning_for_coders/,freevideolectures,1561541654,,1,0
249,2019-6-26,2019,6,26,20,c5ohsn,Generating Question-Answer Hierarchies,https://www.reddit.com/r/deeplearning/comments/c5ohsn/generating_questionanswer_hierarchies/,rahulbhalley,1561547238,,0,8
250,2019-6-26,2019,6,26,22,c5pmec,how to call embed .py script to c# ?,https://www.reddit.com/r/deeplearning/comments/c5pmec/how_to_call_embed_py_script_to_c/,lacaai,1561554555,"Hey, I need help, how can I call a .py script from C#?  


I want to call a python script, which is not an .exe.  
The best would be, that I should not install python, nor the libaries, like tensorflow or keras, just add the dlls or dependencies and it would works nicely.",0,1
251,2019-6-26,2019,6,26,23,c5qagn,Using GPT-2 to gennerate realistic text,https://www.reddit.com/r/deeplearning/comments/c5qagn/using_gpt2_to_gennerate_realistic_text/,saravanakumar17,1561558274,"(there are a few spelling mistake in the source text don't mind it) I recently used gpt-2 to generate text and got blown away by the kind of output text accuracy it can deliver. 

[Just for testing purpose only, don't take it seriously.](https://i.redd.it/d6tr4ofskp631.png)",0,2
252,2019-6-26,2019,6,26,23,c5qm08,July 11 Talk on Deep Learning with ACM A.M. Turing Laureate Yann LeCun,https://www.reddit.com/r/deeplearning/comments/c5qm08/july_11_talk_on_deep_learning_with_acm_am_turing/,ACMLearning,1561559959,,0,20
253,2019-6-26,2019,6,26,23,c5qrye,LSTM For Sequential Panel Data,https://www.reddit.com/r/deeplearning/comments/c5qrye/lstm_for_sequential_panel_data/,themoonman237,1561560807,"Hi, 

I'm currently in the process of planning an LSTM or some sort of RNN at least for a data set of sequences I have. 

I've fit a ANN already to test out predictive capabilities and was relatively happy but it's shortcomings are apparent in its inability to  discern temporal relationships between certain features. 

My question, or what I'm looking for is just some insight from any of you folks who might have some experience with LSTM models that aren't strictly for time series data in the usual sense. 

My sequences of data vary in size, and each row in a sequence contains only maybe 5 features that change from 1..N in a given sequence. However this change in each feature is important and predictive. 

Also each sequence stands alone, in that it refers to a single individual object . So if we have 100 sequences that equals 100 objects, unlike in a regular time series where a sequence might measure 1 object i.e bitcoin, stocks etc. 

Any insights or advice on such a problem would be really appreciated!",0,4
254,2019-6-27,2019,6,27,0,c5r7df,GloVe and BERT on a new corpus?,https://www.reddit.com/r/deeplearning/comments/c5r7df/glove_and_bert_on_a_new_corpus/,DeepLearningStudent,1561562922,"Im trying to produce word embeddings from a textual corpus that I have reason to believe is substantially different from the corpora that GloVe and BERT have been trained on. I think I need to generate a vocabulary from the corpus but I am having trouble understanding how. Ive cleaned the corpus so it is white space-separated. However, Im having trouble understanding how to actually refrain these models to produce the desired word embeddings based off of the corpus.

Any simplified explanations, tips, advice, or guides would be greatly appreciated.",1,2
255,2019-6-27,2019,6,27,1,c5s2q1,Deep Learning Applications,https://www.reddit.com/r/deeplearning/comments/c5s2q1/deep_learning_applications/,MainBuilder,1561567234,,0,1
256,2019-6-27,2019,6,27,2,c5svei,[Research] Towards Transfer Learning for End-to-End Speech Synthesis from Deep Pre-Trained Language Models,https://www.reddit.com/r/deeplearning/comments/c5svei/research_towards_transfer_learning_for_endtoend/,cdossman,1561571008," [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-towards-transfer-learning-for-end-to-end-speech-synthesis-from-deep-pre-trained-6395ae8108fa](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-towards-transfer-learning-for-end-to-end-speech-synthesis-from-deep-pre-trained-6395ae8108fa) 

 Modern text-to-speech (TTS) systems are able to generate audio that sounds almost as natural as human speech. However, the bar of developing high-quality TTS systems remains high since a sizable set of studio-quality &lt;text, audio&gt; pairs is usually required. Compared to commercial data used to develop state-of-the-art systems, publicly available data are usually worse in terms of both quality and size. Audio generated by TTS systems trained on publicly available data tends to not only sound less natural, but also exhibits more background noise. In this work, we aim to lower TTS systems' reliance on high-quality data by providing them the textual knowledge extracted by deep pre-trained language models during training. In particular, we investigate the use of BERT to assist the training of Tacotron-2, a state of the art TTS consisting of an encoder and an attention-based decoder.",0,1
257,2019-6-27,2019,6,27,7,c5wves,Can (a variant of) DNN give reasoning for their decisions?,https://www.reddit.com/r/deeplearning/comments/c5wves/can_a_variant_of_dnn_give_reasoning_for_their/,JohannesWurst,1561587158,"(I'm a CS student, but no expert on machine learning.)

When DNNs are used to judge people whether they might be criminals or whether they might be suitable for a job, it would be useful if they can give some arguments, so a user has a basis to decide to trust the decision or not. Some people say they might be racist or sexist, or simple inaccurate.

**As far as I know regular DNN don't provide reasoning, but are there any variants that do?**

In the field of image recognition, with convolutional neural networks or adversarial neural networks, I thought I heard somewhere that you can see which geometrical shapes the network detected as a sub-step in order to categorize a picture as a cat.

In this [work](https://www.youtube.com/watch?v=4VAkrUNLKSo) someone extracted the features that a neural network thought important for human faces: gender, age, size...

Could something similar be used to make e.g. recruiting systems more accountable?

There is also this ""IBM Project Debater"". Could this help in that regard?",5,1
258,2019-6-27,2019,6,27,10,c5yxwm,Implementing K-Means Clustering From Scratch: Simply Explained,https://www.reddit.com/r/deeplearning/comments/c5yxwm/implementing_kmeans_clustering_from_scratch/,DiscoverAI,1561597517,,0,2
259,2019-6-27,2019,6,27,10,c5z92s,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/c5z92s/how_neural_networks_work_simply_explained/,DiscoverAI,1561599369,,1,0
260,2019-6-27,2019,6,27,10,c5zawe,Guide to Securing Machine Learning and Software Engineering Internships,https://www.reddit.com/r/deeplearning/comments/c5zawe/guide_to_securing_machine_learning_and_software/,DiscoverAI,1561599660,,0,26
261,2019-6-27,2019,6,27,11,c5zy1o,Learning Python Artificial Intelligence by Example,https://www.reddit.com/r/deeplearning/comments/c5zy1o/learning_python_artificial_intelligence_by_example/,HannahHumphreys,1561603335,[removed],0,1
262,2019-6-27,2019,6,27,14,c61czy,Google robbed the dropout technique as his own. Ridiculous!,https://www.reddit.com/r/deeplearning/comments/c61czy/google_robbed_the_dropout_technique_as_his_own/,hungrybear2005,1561612148,,1,0
263,2019-6-27,2019,6,27,17,c62yxm,Deep Blueberry Book - five weekend curriculum for self-learners,https://www.reddit.com/r/deeplearning/comments/c62yxm/deep_blueberry_book_five_weekend_curriculum_for/,mikasarei,1561624055,,0,3
264,2019-6-27,2019,6,27,17,c631mm,This is super creepy and scary,https://www.reddit.com/r/deeplearning/comments/c631mm/this_is_super_creepy_and_scary/,mohit__,1561624688,,0,1
265,2019-6-27,2019,6,27,18,c63ibi,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c63ibi/data_science_career_track_prep_course/,HannahHumphreys,1561628452,[removed],0,1
266,2019-6-27,2019,6,27,20,c648jj,The best telegram group on Women in Machine Learning and Computer Vision,https://www.reddit.com/r/deeplearning/comments/c648jj/the_best_telegram_group_on_women_in_machine/,Doctor_who1,1561633941," 

The best telegram group on Women in Machine Learning and Computer Vision with the presence of Professor Fei-Fei Li

join to telegram group

[https://t.me/joinchat/CuFqkU0HkHTloTFnZFtFEA](https://t.me/joinchat/CuFqkU0HkHTloTFnZFtFEA)",1,0
267,2019-6-27,2019,6,27,21,c650yh,Training a single AI model can emit as much carbon as five cars in their lifetimes,https://www.reddit.com/r/deeplearning/comments/c650yh/training_a_single_ai_model_can_emit_as_much/,mercury_new,1561639178,,4,1
268,2019-6-27,2019,6,27,22,c65gtb,I need help for my prediction algorithm project,https://www.reddit.com/r/deeplearning/comments/c65gtb/i_need_help_for_my_prediction_algorithm_project/,TheWipyk,1561641786,"Hi guys!

I want to make a project that predicts which team is more likely to win. [Here](https://drive.google.com/open?id=1qlJU5vuXehomT2VhyngqvgwC7UOkm8RI) is part of the dataset I'm working with. 

The first column indicates the winner, +1 or -1 for team A or B. The following B, C, D columns will be ignored for now. The rest of the Columns indicate a chosen character for team A or B, 0 is not participating. 

&amp;#x200B;

I'm new to deep learning and unsure which algorithm should I use. I was thinking about some matrix manipulation or cluster analysis.

&amp;#x200B;

Thanks!",1,1
269,2019-6-27,2019,6,27,23,c662oo,Laplace - BTCUSD ticker values prediction AI,https://www.reddit.com/r/deeplearning/comments/c662oo/laplace_btcusd_ticker_values_prediction_ai/,resotto,1561645119,,0,0
270,2019-6-28,2019,6,28,0,c66mbs,[Research] Speech Recognition With No Speech Or With Noisy Speech Beyond English,https://www.reddit.com/r/deeplearning/comments/c66mbs/research_speech_recognition_with_no_speech_or/,cdossman,1561647925,"[https://medium.com/ai%C2%B3-theory-practice-business/speech-recognition-with-no-speech-or-with-noisy-speech-beyond-english-86cbce0bca5f?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/speech-recognition-with-no-speech-or-with-noisy-speech-beyond-english-86cbce0bca5f?postPublishedType=initial) 

Abstract: In this paper, researchers demonstrate continuous noisy speech recognition using connectionist temporal classification (CTC) model on limited Chinese vocabulary using electroencephalography (EEG) features with no speech signal as input and we further demonstrate single CTC model based continuous noisy speech recognition on limited joint English and Chinese vocabulary using EEG features with no speech signal as input.",0,1
271,2019-6-28,2019,6,28,0,c66uuo,"Multi-class classification using CNN over PyTorch, and the basics of CNN.",https://www.reddit.com/r/deeplearning/comments/c66uuo/multiclass_classification_using_cnn_over_pytorch/,thevatsalsaglani,1561649099,,0,1
272,2019-6-28,2019,6,28,0,c67539,Geoffrey Hintons Unsupervised Capsule Networks Achieve SOTA Results on SVHN - Medium,https://www.reddit.com/r/deeplearning/comments/c67539/geoffrey_hintons_unsupervised_capsule_networks/,Yuqing7,1561650534,,1,65
273,2019-6-28,2019,6,28,2,c68m3i,10 Big Data Trends to Watch in 2019,https://www.reddit.com/r/deeplearning/comments/c68m3i/10_big_data_trends_to_watch_in_2019/,rohit1221qq,1561657731,,0,1
274,2019-6-28,2019,6,28,4,c69jkm,Port of pretrained tensorflow face recognition models to pytorch,https://www.reddit.com/r/deeplearning/comments/c69jkm/port_of_pretrained_tensorflow_face_recognition/,timesler,1561662289,"[https://github.com/timesler/facenet-pytorch](https://github.com/timesler/facenet-pytorch)

&amp;#x200B;

Hi all, this project contains pytorch pretrained inception resnets ported from the davidsandberg/facenet github repo. Models are implemented and used according to the standard pytorch/torchvision methodology (inheritable model modules, torchvision style model zoo for downloaded/cached pretrained state dictionaries etc.). Currently, the project covers face detection using MTCNN and face recognition. MTCNN is implemented as a single stand-alone pytorch module that wraps the p-, r-, and o-net modules as well as the post-processing, making it easy to chain MTCNN and recognition resnets together in a face recognition pipeline.

&amp;#x200B;

The motivation for the project was the lack of a clean implementation in pytorch that provides the performance of the davidsandberg/facenet github repo. My aim was to build a project that could be easily used to add value existing pytorch projects without a great deal of effort. Performance wise, I see similar or better inference speed on my local machine when compared to the original repo, but that one data point doesn't say a hell of a lot. Any extra testing or feedback much appreciated.

&amp;#x200B;

I'd also like to hear people's opinions on the following design choice:

Currently, the repo contains the necessary pieces for building an inference pipeline (classes for face detection using MTCNN, embedding, and optionally classification), but does not contain code for retraining models (a training script, loss functions, etc). This was a design choice motivated by the desire to keep the project modular and general. Due to the wide range of applications, I thought the implementation would be more accessible and easily integrated into other projects if it were kept as is. I intend on adding some example code that sketches how to retrain using other open-source resources, but I'm not sure this should be added to the repo source.",0,4
275,2019-6-28,2019,6,28,4,c69ljx,The Staggering Cost of Training SOTA AI Models,https://www.reddit.com/r/deeplearning/comments/c69ljx/the_staggering_cost_of_training_sota_ai_models/,Yuqing7,1561662548,,2,1
276,2019-6-28,2019,6,28,20,c6iurd,Label Noise in Rule based Labelling,https://www.reddit.com/r/deeplearning/comments/c6iurd/label_noise_in_rule_based_labelling/,lifeinsrndpt,1561719888,"I have unlabelled data. Generally for classification problems (say sentiment), in order to train a network, you need to generate labels. You look at the dataset, find a pattern that (for binary classification) gives about 70% accuracy when compared to ground truth. 

Now if you directly train a network on such a data, it will converge at the rule you used to label the data.
So instead you remove the rule(say a number/word etc.)  from the dataset, and let the network find another (maybe more complex mapping) to classify the data.

My question is, 
1) with enough data will the network learn to generalise over wrongly labelled data?

I tried with a dataset of 100 document. It works to some extent (measuring qualitatively) but there still some problem. 

2) Is there a some trick to deal with such problem?",0,1
277,2019-6-28,2019,6,28,23,c6l3sr,How big data &amp; Deep Learning is transforming the real estate industry,https://www.reddit.com/r/deeplearning/comments/c6l3sr/how_big_data_deep_learning_is_transforming_the/,rohit1221qq,1561733456,,0,13
278,2019-6-29,2019,6,29,0,c6lvbe,Diffgram: Learn to work with deep learning without code (Product Hunt),https://www.reddit.com/r/deeplearning/comments/c6lvbe/diffgram_learn_to_work_with_deep_learning_without/,diffgram-anthony,1561737319,"[https://www.producthunt.com/posts/diffgram](https://www.producthunt.com/posts/diffgram) 

&amp;#x200B;

https://i.redd.it/hqdab3m9d4731.png

https://i.redd.it/5mde8tl9d4731.png

https://i.redd.it/k6wyrsl9d4731.png

https://i.redd.it/hn6unrl9d4731.png",1,2
279,2019-6-29,2019,6,29,1,c6m6mk,"Uncertainty modelling by using Deep Learning for confident predictions, a research PhD topic.",https://www.reddit.com/r/deeplearning/comments/c6m6mk/uncertainty_modelling_by_using_deep_learning_for/,4xel,1561738839,"Hi there!

Following we present a video to introduce the research topic of my Industrial PhD that is about *Uncertainty modelling by using Deep Learning for confident predictions*:

&amp;#x200B;

(1) Twitter video: [https://twitter.com/dindustrialscat/status/1144204447947665408](https://twitter.com/dindustrialscat/status/1144204447947665408)

(2) Linkedin video: [https://www.linkedin.com/feed/update/urn:li:activity:6549976288814223360](https://www.linkedin.com/feed/update/urn:li:activity:6549976288814223360)

&amp;#x200B;

Actually, the video is a simple introduction to how to capture the different types of uncertainty through deep learning (limited to two minutes...!). However, we hope that soon the different works that I have in review come to light and we can comment on it!  


If you like the video, I would appreciate it if you retweet it (1) and share it with linkedin (2) given that it is the metric used to choose the video of the industrial doctorate winner of the contest where I am participating.  


Thank you very much and if you want to get in touch with us, do not hesitate at any time :)",0,2
280,2019-6-29,2019,6,29,1,c6mct6,"fast.ai Part 2(2019) ""Deep Learning from the Foundations"" is now available publically!",https://www.reddit.com/r/deeplearning/comments/c6mct6/fastai_part_22019_deep_learning_from_the/,init__27,1561739691,[removed],0,1
281,2019-6-29,2019,6,29,1,c6mflb,Created Neural Network from Scratch in plain python and Numpy.,https://www.reddit.com/r/deeplearning/comments/c6mflb/created_neural_network_from_scratch_in_plain/,reddyManudeep,1561740083,"Today I implemented 5- Layer neural network in python without using any deep learning frameworks. It was a tedious experience but, it is totally worth it. I (re)learned a lot of things that work under the hood of DL libraries. Can check my code [here](https://github.com/DeepManuPy/MultiLayer-Perceptrons/blob/master/NN-numpy.py).",3,2
282,2019-6-29,2019,6,29,1,c6mjwo,How to get reproducible results in deep learning ?,https://www.reddit.com/r/deeplearning/comments/c6mjwo/how_to_get_reproducible_results_in_deep_learning/,FluidReality,1561740677,"Say you want to add something to your model that you think might improve overall performance, e.g. some feature engineering or you decide to add to your training data, some new data you acquired. How do you make sure that this is actually increasing performance and that it is not just due to the randomness of the process ?

I kinda see how it goes for traditional ML with traditional IID assumption, fix a seed for anything that is random and just compare. But what about deep learning models ?

For instance, say you have your neural network tuned for some past state. Wouldn't comparing past configuration with new configuration (with the added features or training data) on the same network be biased ? Maybe the feature engineering was relevant but because the network isn't large enough, it is not able to process those additional features. Or maybe adding more data changed the loss surface and the learning rate/batch size tuned to the previous configuration is not well fitted to the new configuration ? Or maybe more data meant more updates per epoch (assuming the batch size is the same), so maybe we missed the optimal training state because we only look at the validation loss per epoch. So surely setting a seed for the randomness of the network training (weights initialization, shuffle after each epoch ... ) is not enough.

I've thought of doing some sort of autoML/gridsearch to optimize on the learning rate/batch size for several seeds on the weights initialization and do some statistical significance on the results but this would take way too much time considering how many things I need to check. I feel like a statistical study on a given network (with hyperparameters fixed) for different weights initialization might not be relevant.

I'm asking this because whenever I change something on the preprocessing side (new feature, new data, different scaling ...), or even weights initialization of the network, the ""optimal"" learning rate I find by hand tuning my network is never the same (and can differ a lot).

Any idea is welcome!",0,4
283,2019-6-29,2019,6,29,3,c6nw46,Part 2: Deep Learning from the Foundations(2019) by Fast.ai is launched!,https://www.reddit.com/r/deeplearning/comments/c6nw46/part_2_deep_learning_from_the_foundations2019_by/,harrshjain,1561747183,,8,71
284,2019-6-29,2019,6,29,4,c6og1w,Deep Learning from the Foundations  fast.ai,https://www.reddit.com/r/deeplearning/comments/c6og1w/deep_learning_from_the_foundations_fastai/,asuagar,1561749859,,0,1
285,2019-6-29,2019,6,29,16,c6vrp0,Introduction to machine learning for coders,https://www.reddit.com/r/deeplearning/comments/c6vrp0/introduction_to_machine_learning_for_coders/,freevideolectures,1561791601, https://freevideolectures.com/course/3742/introduction-to-machine-learning-for-coders#utm\_source=Bm,1,0
286,2019-6-29,2019,6,29,21,c6yh7w,GTX 1660 TI Installation to Desktop,https://www.reddit.com/r/deeplearning/comments/c6yh7w/gtx_1660_ti_installation_to_desktop/,rlamarr,1561811934,"Hi guys, I've been trying to install my new GTX 1660 Ti to my HP Pavilion desktop CPU. I power the graphics card from an external 500W PSU which is connected directly to the GPU and kick started using a clip. This is because the CPU uses 250W PSU. The GPU starts and the vent fan rolls, but when the GPU is installed and I turn on the Desktop CPU, The CPU basically doesn't come up at all until I remove the graphics card and turn it on.
Is this because the Desktop is old or Is the graphics card the faulty one? I really need help installing this.",9,1
287,2019-6-29,2019,6,29,22,c6yydt,Can anyone give an explanation about what are contrastive methods and generative methods in deep learning?,https://www.reddit.com/r/deeplearning/comments/c6yydt/can_anyone_give_an_explanation_about_what_are/,H_uuu,1561814924,,2,1
288,2019-6-30,2019,6,30,3,c72w3m,Any graph CNN work that changes the weight on the edges/links?,https://www.reddit.com/r/deeplearning/comments/c72w3m/any_graph_cnn_work_that_changes_the_weight_on_the/,AbduallahM,1561833432,"I been trying to locate a deep model that do a convolution on the edges and vertices of graphs, any leads?",6,6
289,2019-6-30,2019,6,30,13,c78wo4,How can I improve performance of deep learning model ?,https://www.reddit.com/r/deeplearning/comments/c78wo4/how_can_i_improve_performance_of_deep_learning/,kesha1997,1561867968,I have built a deep learnings image classification  model but the accuracy is not sufficient . Other that augmentation what are different ways to improve performance of model ?,2,1
290,2019-6-30,2019,6,30,13,c792pv,How to build recommendation system using deep learning ?,https://www.reddit.com/r/deeplearning/comments/c792pv/how_to_build_recommendation_system_using_deep/,kesha1997,1561869090,I want to build a recommendation system which will recommend books.I know the theory of recommendation system and its type.but how to implement it ?,3,12
291,2019-6-30,2019,6,30,14,c79mr9,Best practise to deploy multiple deep learning models in production.,https://www.reddit.com/r/deeplearning/comments/c79mr9/best_practise_to_deploy_multiple_deep_learning/,amit2rockon,1561873029,"Hi everyone, I have a query about the best way to deploy multiple deep learning models in production for a scale serving.",2,6
292,2019-6-30,2019,6,30,17,c7azbc,Neuromorphic Hardware: Trying to Put Brain Into Chips,https://www.reddit.com/r/deeplearning/comments/c7azbc/neuromorphic_hardware_trying_to_put_brain_into/,prime_007,1561884249,,0,1
293,2019-6-30,2019,6,30,17,c7b0h0,Machine Learning Specialization,https://www.reddit.com/r/deeplearning/comments/c7b0h0/machine_learning_specialization/,HannahHumphreys,1561884564,[removed],0,1
294,2019-6-30,2019,6,30,18,c7bcmd,Cleaning this data,https://www.reddit.com/r/deeplearning/comments/c7bcmd/cleaning_this_data/,jahifu,1561887725,,5,0
295,2019-6-30,2019,6,30,18,c7be7a,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c7be7a/data_science_career_track_prep_course/,HannahHumphreys,1561888177,[removed],0,1
296,2019-6-30,2019,6,30,20,c7c61p,Is it possible to build a classifier in Deep Learning for 1000 (or 10000) objects of the same species with only one picture each?,https://www.reddit.com/r/deeplearning/comments/c7c61p/is_it_possible_to_build_a_classifier_in_deep/,PolyTrickPony,1561894942,\^,5,2
297,2019-6-30,2019,6,30,21,c7ckfn,Need DNA sequence data with the respective person's facial features,https://www.reddit.com/r/deeplearning/comments/c7ckfn/need_dna_sequence_data_with_the_respective/,clean_pegasus,1561896664,Is there any DNA dataset available that also includes facial features of that respective person?,2,1
0,2019-7-1,2019,7,1,11,c7mohh,What are some NN models that can use auxiliary info during training for image segmentation?,https://www.reddit.com/r/deeplearning/comments/c7mohh/what_are_some_nn_models_that_can_use_auxiliary/,Worth_Bet,1561946500,"For example imagine a poorly shot image of a river (blue) that shows a gap, and the supplementary information are detailed flow directions (green arrows) which help showing the river's true shape (no gap in reality). To **get the river shape**, most image segmentation models I see such as U-Net only uses RGB channels. **Are there any neural network models that can use this kind of auxiliary information along with RGB channels during training** for the image segmentation task?

https://i.redd.it/ap6mosg8nl731.png",2,3
1,2019-7-1,2019,7,1,11,c7mtmz,Learning deep learning in 3 months,https://www.reddit.com/r/deeplearning/comments/c7mtmz/learning_deep_learning_in_3_months/,musedivision,1561947350,,0,1
2,2019-7-1,2019,7,1,14,c7ollj,Difference between Autoencoder Representation and Model Embeddings,https://www.reddit.com/r/deeplearning/comments/c7ollj/difference_between_autoencoder_representation_and/,PyWarrior,1561958731,"Representation 1: While we train an Undercomplete Autoencoder on a data(let's say imagenet), we get a smaller dimension representation by the Hidden Layers.

Representation 2: When we train a multiclass classifier like VGGNet(let's say on imagenet), we also get a representation before the final pooling layers.

&amp;#x200B;

What is the main difference between the two representations of that training data?  
What are the cases when representation 1 will be better than representation 2 and vice-versa?",7,5
3,2019-7-1,2019,7,1,15,c7p2f1,suggestions for best approach for scene text detection,https://www.reddit.com/r/deeplearning/comments/c7p2f1/suggestions_for_best_approach_for_scene_text/,vjycoc,1561962093,"I am trying to extract numbers painted on vessels so that we could track them. I tried CTPN which is giving good results but it is very slow, tried pretrained yolov3 text detection but it is highly inaccurate with these handwritten/painted text i also tried it with custom dataset but it is not detecting any text in the image. vessels are in open area, please suggest better models and approaches related to scene text detection.",3,1
4,2019-7-1,2019,7,1,15,c7p9kg,Begin creating Deep Learning models. A list of things I wish I knew a year ago (xpost /r/learnmachinelearning),https://www.reddit.com/r/deeplearning/comments/c7p9kg/begin_creating_deep_learning_models_a_list_of/,s_cond,1561963582,,1,32
5,2019-7-1,2019,7,1,16,c7pmbi,Suggestions for learning and practicing Linear Algebraic Calculus,https://www.reddit.com/r/deeplearning/comments/c7pmbi/suggestions_for_learning_and_practicing_linear/,fluideborah,1561966238,"Hi everyone! I come from a non-CS/Math background. I have been in the field of Deep Learning for over a year now, but I have worked mostly on implementations. I had taken a course in Deep Learning a while back and am currently doing my Master's Thesis in a specific Deep Learning application. 

&amp;#x200B;

Through my experience so far, I've realized there are fundamental limitations to doing good research unless you are comfortable with the underlying math and calculus that governs Deep Learning and a lot of other Machine Learning algorithms. Plus I personally feel quite unsatisfied with my work knowing that it's not very theoretically rigorous. I know it doesn't happen overnight but that's pretty much why I am asking this question. What is a good way to study and practice intermediate to advanced linear algebra and linear algebraic calculus that's used in Deep Learning + Machine Learning?  


I'd be very excited to know if there are good openly available practice materials + courses out there through which I can work my way upwards step-by-step. Thank you!",9,5
6,2019-7-1,2019,7,1,18,c7qk6n,Extract image patches from NETCDF files,https://www.reddit.com/r/deeplearning/comments/c7qk6n/extract_image_patches_from_netcdf_files/,m9404,1561974017,"I have a huge dataset of NETCDF files, each NETCDF file contains an image and its mask as a numpy multidimensional array. The mask contains flags, the size of the images is (17307 x 6344).

  
What is the best way to extract patches to train a model from these images, such as every patch must contain pixels corresponding to a specific flag (lets say flag\_value =2) in the mask, the patches should be square-sized.",0,1
7,2019-7-1,2019,7,1,21,c7ruu9,Big Data Analytics in Government: How the Public Sector Leverages Data Insights,https://www.reddit.com/r/deeplearning/comments/c7ruu9/big_data_analytics_in_government_how_the_public/,raj11113,1561983432,,0,3
8,2019-7-1,2019,7,1,23,c7t3or,Why does reducing Stride reduce the accuracy of an Object Detection Model?,https://www.reddit.com/r/deeplearning/comments/c7t3or/why_does_reducing_stride_reduce_the_accuracy_of/,ShotInTheEd,1561990556,"Apologies if this question has been answered before already - I am new to this sub!

&amp;#x200B;

I have been playing around with hyperparameters to try to create the most accurate object detection model I can using TensorFlow's faster\_rcnn\_inception\_resnet\_v2\_atrous\_coco pre-trained model. The model can be found under this git repository:  [https://github.com/tensorflow/models/blob/master/research/object\_detection/g3doc/detection\_model\_zoo.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) 

&amp;#x200B;

One of the adjustments I made was to decrease the height\_stride and width\_stride from 8 (default) to 4 under first\_stage\_anchor\_generator in the config file. My expectation was that this would improve the accuracy of the model at the expense of taking longer for inference times but it actually resulted in the model performing really poorly. What happened was precision was very high but recall was extremely low. Does anyone have any insight into why this could be?

&amp;#x200B;

Also, any suggestions on how best to tweak the hyperparameters to maximise the accuracy of a model (disregarding the inference time that is required) would be amazing. For example, I have increased the first\_stage\_max\_proposals which has noticeably increased the accuracy of the model.

&amp;#x200B;

Any help would be really appreciated!",2,0
9,2019-7-1,2019,7,1,23,c7thwf,5 Must read books for Data Scientists,https://www.reddit.com/r/deeplearning/comments/c7thwf/5_must_read_books_for_data_scientists/,HannahHumphreys,1561992651,[removed],0,1
10,2019-7-2,2019,7,2,0,c7tw5e,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c7tw5e/data_science_career_track_prep_course/,HannahHumphreys,1561994597,[removed],0,1
11,2019-7-2,2019,7,2,0,c7u9ra,Simpler RNN architecture,https://www.reddit.com/r/deeplearning/comments/c7u9ra/simpler_rnn_architecture/,axeonthra,1561996159,"Hello,

I would like to know if anyone has tried using simpler transformation function for the state in [Elman network](https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-20). 

I am thinking of something similar along the lines of:  


**h**\[n\] = 0.9 **h**\[n-1\] + 0.1 f(A**x**\[n\]+**b**)      // h - state, x input, state is hit with fixed scalar instead of matrix

**y**\[n\] = g(C **h**\[n\] + **e**)

&amp;#x200B;

All the RNN folks seem to jump into complex state manipulations directly. I could not find any literature for something simpler.

&amp;#x200B;

Best Regards

\~",0,1
12,2019-7-2,2019,7,2,1,c7uke7,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c7uke7/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561997016,[removed],0,1
13,2019-7-2,2019,7,2,2,c7wbpg,Artificial Intelligence for Business,https://www.reddit.com/r/deeplearning/comments/c7wbpg/artificial_intelligence_for_business/,HannahHumphreys,1562002117,[removed],0,1
14,2019-7-2,2019,7,2,10,c82vgc,Bunch of Web Dev &amp; Deep Learning books are now discounted,https://www.reddit.com/r/deeplearning/comments/c82vgc/bunch_of_web_dev_deep_learning_books_are_now/,JesseStromberg8,1562030109,,0,1
15,2019-7-2,2019,7,2,10,c834x0,Bunch of Web-Development books are discounted (including Deep Learning ones),https://www.reddit.com/r/deeplearning/comments/c834x0/bunch_of_webdevelopment_books_are_discounted/,HildaDavidson,1562031654,"It's all in one bundle and it has about 15 different books all on web development while some of them being on Deep Learning strictly. I think it's a pretty thing to own since you can read it and even share it with your friends.

&amp;#x200B;

Check it here:",2,1
16,2019-7-2,2019,7,2,11,c83sys,FFT based CNN,https://www.reddit.com/r/deeplearning/comments/c83sys/fft_based_cnn/,Hariharan__SJ,1562035607,"Can we use the Fft of an image in a CNN? So that instead of Convolution we'll be multiplying the image with the kernel.
Did some googling and I found that this works better for large kernels and not the small ones, still dunno why? Can someone explain this pls",2,15
17,2019-7-2,2019,7,2,13,c84xww,Humble Book Bundle: Open Source Bookshelf by Bleeding Edge Press,https://www.reddit.com/r/deeplearning/comments/c84xww/humble_book_bundle_open_source_bookshelf_by/,Steam_Games,1562042823,,0,4
18,2019-7-2,2019,7,2,15,c85pfq,Competition to improve the medical field!,https://www.reddit.com/r/deeplearning/comments/c85pfq/competition_to_improve_the_medical_field/,LateNightDeveloper,1562048274,"Kaggle is a host of thousands of datasets with an active community, made for developing new technology. It is mostly used for developing Machine Learning and Deep Learning software.

They recently sent me an email of this competition: [Recursion Cellular Image Classification *1] (https://www.kaggle.com/c/recursion-cellular-image-classification/) which I will be discussing in this post.

With the costs of developing new medication, and getting it out to patients as soon as possible, it is no surprise that most patients would rather go without it. This competition contains experimental noise from real biological signals, which developers could use to train their applications in a chance to win $13,000.

The idea is to greatly decrease the costs for treatments and ensure that it goes faster out to patients.

One kernal which exploded in a day is [Nanashis Quick Visualization + EDA *2] (https://www.kaggle.com/jesucristo/quick-visualization-eda/notebook)

Id defenitily recommend checking it out!

Link *1:https://www.kaggle.com/c/recursion-cellular-image-classification/

Link *2:https://www.kaggle.com/jesucristo/quick-visualization-eda/notebook

",0,13
19,2019-7-2,2019,7,2,16,c867v4,Coolest Papers of CVPR 2019,https://www.reddit.com/r/deeplearning/comments/c867v4/coolest_papers_of_cvpr_2019/,PyWarrior,1562052077,What are some of the Coolest papers of CVPR 2019?,2,35
20,2019-7-2,2019,7,2,16,c86eit,TensorFlow 2.0. Main Commands and Operations (compare with TF 1.X),https://www.reddit.com/r/deeplearning/comments/c86eit/tensorflow_20_main_commands_and_operations/,vb100_,1562053527," **TensorFlow 2.0. Main Commands and Operations (compare with TF 1.X)**   
[https://youtu.be/R6BAMldZ1Y4](https://youtu.be/R6BAMldZ1Y4?fbclid=IwAR1DFPU7zoiDD7Nj25ElD3OKS-8XT7nTUdfaQrwxE7QJGYM-GLBg_C7AKIY)

*Processing img cvu4bl2khu731...*",0,5
21,2019-7-2,2019,7,2,18,c86zey,How many records are enough to train landmark detection model?,https://www.reddit.com/r/deeplearning/comments/c86zey/how_many_records_are_enough_to_train_landmark/,nikogamulin,1562058445,"Hi,

&amp;#x200B;

I have a small dataset (approx 120 images) of pupils and am trying to build the model to predict the points (x and y coordinates). Does anyone have any relevant experience in order to provide an estimate of how many images should be annotated to train the model?",2,2
22,2019-7-2,2019,7,2,18,c871vd,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c871vd/data_science_career_track_prep_course/,HannahHumphreys,1562058983,[removed],0,1
23,2019-7-2,2019,7,2,18,c87bwt,Machine Learning Bootcamp: Become a ML Engineer in 6 months. Job Guaranteed.,https://www.reddit.com/r/deeplearning/comments/c87bwt/machine_learning_bootcamp_become_a_ml_engineer_in/,HannahHumphreys,1562061221,[removed],0,1
24,2019-7-2,2019,7,2,19,c87qui,[R] https://arxiv.org/abs/1811.07519 Higher-order Neural Networks for Action Recognition,https://www.reddit.com/r/deeplearning/comments/c87qui/r_httpsarxivorgabs181107519_higherorder_neural/,KaiiHu,1562064295,"I am delighted to announce that I have submitted our recent work to arXiv. Any feedback would be highly appreciated. [https://arxiv.org/abs/1811.07519](https://arxiv.org/abs/1811.07519)

In this paper, we proposed a new architecture: the *higher-order* operation. The term ""*higher order*"" comes from *higher order* functions. A higher order function is a function that takes a function as an argument, or returns a function. Similarly, the outputs of the *higher-order* operation are not feature maps, but a bank of filters for extracting features. Then the network use the filters to extract features.

The intuition comes from the complexity of action recognition. It is much harder to recognize an action in a video than objects in still images. An effective architecture should not only recognize the appearance of target objects associated with the action, but also understand how they relate to other objects in the scene, in both space and time.

&amp;#x200B;

*Processing img nrjlr6er7v731...*

In the figure, we have 4 categories of actions: a) pull something from left to right, b) push something from right to left, c) push something from left to right and d) pull something from right to left. Only understanding the appearance info is not enough since we have only the hand and the object ""something"" in all four actions. It is also insufficient with temporal information. Figure b is the reverse of figure a ""pull something from left to right"", but figure b is not simply the opposite: ""pull something from right to left"". It is important to understand the object-in-context pattern to classify the actions.

As scenes become more complicated and the number of objects whose relations need to be tracked increases, the complexity of the learning task faced by the architecture increases rapidly. The vanilla convolutions use fixed filters to recognize *every* object-in-context pattern required to recognize one category of action, potentially leading to a blow up of the number parameters required for effective recognition of the actions.

In such settings, we do not want to have a huge number of filters to cover all possible object-in-context patterns. It is best if the model can propose/derive a filter given a certain context ---- different filters for different contexts. The model does not need to store all the filters, but needs to learn how to propose a filter. 

We hypothesize that how to propose/derive a filter for a certain context is learnable and design the ""*higher order*"" operation. More explicitly, let \[;\\bm{X};\] and \[;\\bm{Y};\] represent the input and output respectively. Let \[;\\bm{y}\_p;\] and \[;\\bm{x}\_p;\] represent a specific location of \[;\\bm{Y};\] and the set of locations on \[;\\bm{X};\] where \[;\\bm{y}\_p;\] is computed, respectively.",0,1
25,2019-7-2,2019,7,2,22,c89cgl,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c89cgl/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1562074764,[removed],0,1
26,2019-7-2,2019,7,2,22,c89fnt,[Research] Human vs Machine Attention in Neural Networks,https://www.reddit.com/r/deeplearning/comments/c89fnt/research_human_vs_machine_attention_in_neural/,cdossman,1562075293,"[https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-human-vs-machine-attention-in-neural-networks-69a8b59e577f](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-human-vs-machine-attention-in-neural-networks-69a8b59e577f) 

Abstract:  Recent years have witnessed a surge in the popularity of attention mechanisms encoded within deep neural networks. Inspired by the selective attention in the visual cortex, artificial attention is designed to focus a neural network on the most task-relevant input signal. Many works claim that the attention mechanism offers an extra dimension of interpretability by explaining where the neural networks look. However, recent studies demonstrate that artificial attention maps do not always coincide with common intuition. In view of these conflicting evidences, here we make a systematic study on using artificial attention and human attention in neural network design.",0,1
27,2019-7-3,2019,7,3,1,c8az2k,The Role of AI and Machine Learning in Data Quality,https://www.reddit.com/r/deeplearning/comments/c8az2k/the_role_of_ai_and_machine_learning_in_data/,rohit1221qq,1562083227,,0,1
28,2019-7-3,2019,7,3,3,c8d4kz,My GAN creates random weird texture,https://www.reddit.com/r/deeplearning/comments/c8d4kz/my_gan_creates_random_weird_texture/,whiteapplex,1562093516,"Hi, I'm trying to make a GAN from scratch, but the result isn't so great for now.

Here are the results: [https://imgur.com/a/zuPV8Yx](https://imgur.com/a/zuPV8Yx) and the repartition for probabilities of belonging to the set of generated images.

Does anyone understand why ? :/

The generator uses upsample+convolution starting from a random matrix,  the discriminator ends with a fully connected and maxout.",1,0
29,2019-7-3,2019,7,3,3,c8d5zb,Back-propagation Demystified [Part 2]  Computational graphs in PyTorch and Static vs Dynamic graphs,https://www.reddit.com/r/deeplearning/comments/c8d5zb/backpropagation_demystified_part_2_computational/,msminhas93,1562093698,,0,18
30,2019-7-3,2019,7,3,4,c8dfif,Running PyTorch inference on MMS (MXNet Model ServeR),https://www.reddit.com/r/deeplearning/comments/c8dfif/running_pytorch_inference_on_mms_mxnet_model/,gautam5669,1562094888,,0,5
31,2019-7-3,2019,7,3,5,c8ebi7,Recommendations for (pre-built) deep learning PC?,https://www.reddit.com/r/deeplearning/comments/c8ebi7/recommendations_for_prebuilt_deep_learning_pc/,NSFForceDistance,1562097995,"Hi /r/MachineLearning, 

&amp;#x200B;

I am looking to buy a more powerful pre-built machine for deep learning projects. I have searched previous posts on the sub for recommendations on this and the general consensus seems to be ""don't buy pre-built,"" but unfortunately grant funding restrictions don't allow me to buy parts separately and pre-built is my only option. I am looking for something that can handle large datasets of 3D images (typically 512 x 512 x 128-512 before any processing). I am leaning towards something with a 2080 Ti or two 2080's and enough CPU power to be able to handle pre-processing on each batch.

&amp;#x200B;

Does anyone have any experience or recommendations here? My price range is between $2000-$3000. Thanks :)",1,0
32,2019-7-3,2019,7,3,14,c8jzhc,Advice for Beginner in Deep Learning?,https://www.reddit.com/r/deeplearning/comments/c8jzhc/advice_for_beginner_in_deep_learning/,bijeshmohan,1562130377,I've just enrolled in Deep Learning Specialization on Coursera and would like to take some advices from those who already completed the specialization successfully.,3,6
33,2019-7-3,2019,7,3,14,c8k48z,"Joke thought experiment: How hard would it be to make a ""DeepD*ckInYourMouth""?",https://www.reddit.com/r/deeplearning/comments/c8k48z/joke_thought_experiment_how_hard_would_it_be_to/,Last_Username_Alive,1562131301,"I'm not going to develop it cuz i'm sure it would be used for evil (bullying, harassment, abuse etc)  


But i thought about it as a joke for your whatsapp guy buddies: just take any of their pictures and put a dick in their mouth, that would be hilarious.  


So how hard would it be?  


Would it even be possible to take DeepFace and train it with faces with dicks in them and do it?",3,0
34,2019-7-3,2019,7,3,17,c8lhmc,[Free + Online] Workshop on Getting Started with Kaggle using fast.ai + a Beginner friendly Comp,https://www.reddit.com/r/deeplearning/comments/c8lhmc/free_online_workshop_on_getting_started_with/,init__27,1562141840,"Hi Everyone, 

I volunteer at a few meetups, I'm an active Kaggler. The #1 question I've recieved is how to get started on Kaggle. 

&amp;#x200B;

DSNet Community will be hosting  a Workshop (Online + In-Person in Bangalore), everyone is welcome to participate (For free, ofcourse)

&amp;#x200B;

The workshop is aimed to give you a taste of kaggle and how to use [fast.ai](https://fast.ai) for image competitions. Note this will be a very beginner friendly comp and the only pre-req is watching Lec 1-4 from [fast.ai](https://fast.ai).

&amp;#x200B;

\*Schedule: 4-6PM IST, Saturday 6th July for the workshop

Competition: Runs from 4PM IST until 8AM Monday IST\*

We will also try to award prices to the best performers

&amp;#x200B;

Zoom Link to join virtually: [https://zoom.us/j/804236055](https://zoom.us/j/804236055)

Sign up here for a reminder: [http://eepurl.com/ghcImr](http://eepurl.com/ghcImr)

&amp;#x200B;

My Kaggle Profile: [https://kaggle.com/init27](https://www.kaggle.com/init27)

Blog: [https://medium.com/@init\_27](https://medium.com/@init_27)",0,1
35,2019-7-3,2019,7,3,17,c8lo0w,DataScience Digest - Issue #18,https://www.reddit.com/r/deeplearning/comments/c8lo0w/datascience_digest_issue_18/,flyelephant,1562143432,,0,14
36,2019-7-3,2019,7,3,21,c8nn2g,How to encrypt my model?,https://www.reddit.com/r/deeplearning/comments/c8nn2g/how_to_encrypt_my_model/,lacaai,1562157831,"Hello guys, I have a trained model (h5 file) which I would like to give to some customers. I want to encrypt it, and I also want to encrypt my model script. Is there any general way to do it ?  
I use keras with tensorflow backend.",2,5
37,2019-7-3,2019,7,3,22,c8o4az,Predict Intermediate Frames Between Two Frames,https://www.reddit.com/r/deeplearning/comments/c8o4az/predict_intermediate_frames_between_two_frames/,SaumyaaShah2498,1562160658,"Hey, can someone suggest a deep learning approach to generate intermediate images between two input images? I've tried shifting pixels based on optical flow, but it didn't work out. I've also tried the following:

[https://github.com/sniklaus/pytorch-sepconv](https://github.com/sniklaus/pytorch-sepconv)

The result is also not very good. It'll be very helpful if someone could suggest a solution to this. Thank you.

P.S The input images are not extracted from a video. They are captured using a DSLR consecutively.",6,6
38,2019-7-3,2019,7,3,22,c8odjo,[Research] How to Achieve Better Accuracy for Target-speaker Automatic Speech Recognition (ASR),https://www.reddit.com/r/deeplearning/comments/c8odjo/research_how_to_achieve_better_accuracy_for/,cdossman,1562162109,"[https://medium.com/ai%C2%B3-theory-practice-business/how-to-achieve-better-accuracy-for-target-speaker-automatic-speech-recognition-asr-8f96448e3668](https://medium.com/ai%C2%B3-theory-practice-business/how-to-achieve-better-accuracy-for-target-speaker-automatic-speech-recognition-asr-8f96448e3668) 

**Abstract:**  In this paper, we propose a novel auxiliary loss function for target-speaker automatic speech recognition (ASR). Our method automatically extracts and transcribes target speakers utterances from a monaural mixture of multiple speakers speech given a short sample of the target speaker. The proposed auxiliary loss function attempts to additionally maximize interference speaker ASR accuracy during training. This will regularize the network to achieve a better representation for speaker separation, thus achieving better accuracy on the target-speaker ASR. We evaluated our proposed method using two-speaker mixed speech in various signal-to-interference-ratio conditions. We first built a strong target-speaker ASR baseline based on the state-of-the-art lattice-free maximum mutual information. This baseline achieved a word error rate (WER) of 18.06% on the test set while a normal ASR trained with clean data produced a completely corrupted result (WER of 84.71%). Then, our proposed loss further reduced the WER by 6.6% relative to this strong baseline, achieving a WER of 16.87%. In addition to the accuracy improvement, we also showed that the auxiliary output branch for the proposed loss can even be used for a secondary ASR for interference speakers speech.",0,3
39,2019-7-4,2019,7,4,1,c8pyzu,EfficientNet: Theory + Code,https://www.reddit.com/r/deeplearning/comments/c8pyzu/efficientnet_theory_code/,spmallick,1562170347,,2,0
40,2019-7-4,2019,7,4,1,c8q6h0,"RTX 2060 vs RTX 2070 vs GTX1080Ti, which is better for deep learning?",https://www.reddit.com/r/deeplearning/comments/c8q6h0/rtx_2060_vs_rtx_2070_vs_gtx1080ti_which_is_better/,ar0752545,1562171383,,7,12
41,2019-7-4,2019,7,4,3,c8rljr,Baidu PaddlePaddle DL Framework &amp; Huawei Kirin SoC: A Formidable Partnership,https://www.reddit.com/r/deeplearning/comments/c8rljr/baidu_paddlepaddle_dl_framework_huawei_kirin_soc/,Yuqing7,1562178128,,0,5
42,2019-7-4,2019,7,4,3,c8rosx,Power BI A-Z: Hands-On Power BI Training For Data Science!,https://www.reddit.com/r/deeplearning/comments/c8rosx/power_bi_az_handson_power_bi_training_for_data/,HannahHumphreys,1562178549,[removed],0,1
43,2019-7-4,2019,7,4,6,c8u7j3,REQUEST: Female breast size dataset,https://www.reddit.com/r/deeplearning/comments/c8u7j3/request_female_breast_size_dataset/,kyonInsane,1562190825,"I am trying to start one of the greatest human project in deep learning. Not without a proper dataset. The request is following:

1. Front photo of female, dressed in any cloth
2. Full bust measurement 
3. Under bust measurement
Lots of them

Project aiming:
Train a net that is capable of speaking out Bra size and its measurements when provided with casual image.

I was amazed how female people including my wife is being troubled at selecting bras. Any help out there?

PS. don't let any bra company steal this idea from us!",4,0
44,2019-7-4,2019,7,4,7,c8unsz,Two-Stream RNN/CNN for Action Recognition in 3D Videos,https://www.reddit.com/r/deeplearning/comments/c8unsz/twostream_rnncnn_for_action_recognition_in_3d/,babdulhakim2,1562193064,This a very good paper that for action recognition [https://arxiv.org/abs/1703.09783](https://arxiv.org/abs/1703.09783) I wonder if anyone has come across any reusable code that uses RNN and CNN for video classification,0,1
45,2019-7-4,2019,7,4,11,c8wvpr,Any research about...,https://www.reddit.com/r/deeplearning/comments/c8wvpr/any_research_about/,lakshaytalkstocomput,1562206312,Is there any research about detecting a object in a frame of video and instead of detecting it from whole frame(next) it looks for in same region? What is it called if there is any research about it? Any help would be appreciated,1,0
46,2019-7-4,2019,7,4,15,c8yyus,some question about text variant detection,https://www.reddit.com/r/deeplearning/comments/c8yyus/some_question_about_text_variant_detection/,harry771,1562220073," Dear friend of reddit,

I am a CS Student, I have a great interest in deep learning and NLP, that's why I took the cs224n along with other courses in Standford AI degree online. Among those courses, cs224n is my favorite, and I even pick Chatbot as my areaof interest. I apply all those skills I learn from cs224n to all kinds of NLP task I encountered, most of them work pretty well, however, a new problem I met in recent days got me into troubles.

For now, I am working on an NLP task on how to detect variant words. For example, we have samples like those, **yesssss,helloooo**, those are the simple ones. There are some complex samples like these,**126#45@120,1785 8943,abf23612.**These examples(numbers mix with other special symbols and space) I mention here are contact information(like phone numbers or facebook numbers ) some people left in a forum or reddit, so other people can follow them to other platforms. In this way, those who left the number can successfully attract people from this platform to some other platform((like app). Therefore, I need to build a model to identify these strings as contact information, one way to achieve this is using regular expressions to identify these strings, however, the variants of text are too many, we can't block all of them with regular expression. Another way I can think of is using the context as features to identify these contact information, and I reject this method as I go deep into the data. Most of the data I get come from web chatting(like chatting in facebook), the context is relatively short, which is not a good choice for feature engineering(I think).

So, this is the problem I encounter in my task, I wonder if you can give me some advice about how to solve this problem, some references or papers will do me the favor. I really appreciate if you can give me some advice about this problem. Thanks in advance.",3,2
47,2019-7-4,2019,7,4,15,c8z04h,Noob question regarding data set size,https://www.reddit.com/r/deeplearning/comments/c8z04h/noob_question_regarding_data_set_size/,the_fourth_musk3teer,1562220303,"So I'm looking to train a RNN for sentiment analysis. I have a dataset of about 100 000, which is classified as good, neutral, or bad. 

However, the dataset for good and bad are about 10 000 respectively, while the neutral is the remaining 80 000. 

Do I need to have the same amount of data to train my network across all classifications?

I can further convert my dataset to a 5 star system (very bad, bad, neutral, good, very good) but I will face the same issue of not having the same dataset size for training

Thanks in advance for your time!",6,5
48,2019-7-4,2019,7,4,21,c91rsr,ai development services|ai development company,https://www.reddit.com/r/deeplearning/comments/c91rsr/ai_development_servicesai_development_company/,clarke2106,1562241656,[removed],0,1
49,2019-7-4,2019,7,4,23,c939s2,Machine Learning Bootcamp: Become a ML Engineer in 6 months. Job Guaranteed.,https://www.reddit.com/r/deeplearning/comments/c939s2/machine_learning_bootcamp_become_a_ml_engineer_in/,HannahHumphreys,1562250805,[removed],0,1
50,2019-7-4,2019,7,4,23,c93exh,[Research] GANalyze: Toward Visual Definitions of Cognitive Image Properties,https://www.reddit.com/r/deeplearning/comments/c93exh/research_ganalyze_toward_visual_definitions_of/,cdossman,1562251616,"[https://medium.com/ai%C2%B3-theory-practice-business/ganalyze-toward-visual-definitions-of-cognitive-image-properties-d23b22486d6e](https://medium.com/ai%C2%B3-theory-practice-business/ganalyze-toward-visual-definitions-of-cognitive-image-properties-d23b22486d6e) 

Abstract:  We introduce a framework that uses Generative Adversarial Networks (GANs) to study cognitive properties like memorability, aesthetics, and emotional valence. These attributes are of interest because we do not have a concrete visual definition of what they entail. What does it look like for a dog to be more or less memorable? GANs allow us to generate a manifold of natural-looking images with fine-grained differences in their visual attributes. By navigating this manifold in directions that increase memorability, we can visualize what it looks like for a particular generated image to become more or less memorable. The resulting visual definitions"" surface image properties (like object size"") that may underlie memorability. Through behavioral experiments, we verify that our method indeed discovers image manipulations that causally affect human memory performance. We further demonstrate that the same framework can be used to analyze image aesthetics and emotional valence",0,9
51,2019-7-4,2019,7,4,23,c93gyt,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c93gyt/data_science_career_track_prep_course/,HannahHumphreys,1562251943,[removed],0,1
52,2019-7-5,2019,7,5,0,c93yao,CNN Implementation using Flutter,https://www.reddit.com/r/deeplearning/comments/c93yao/cnn_implementation_using_flutter/,zom8ie99,1562254517,How can I implement my CNN model (which is in hdf5 format) in android using Flutter? Is there any tutorial for this ?,4,0
53,2019-7-5,2019,7,5,0,c9422c,Worth waiting for RTX 2060 Super or just go with RTX 2060 from DL perspective?,https://www.reddit.com/r/deeplearning/comments/c9422c/worth_waiting_for_rtx_2060_super_or_just_go_with/,jklipn,1562255098,"Okay, so I just bought an RTX 2060 for $350 inclusive of taxes just before I read the announcement of Nvidia launching the Super cards.  Currently it is sitting unopened in front of me.  

I have been reading and studying ML/DL for the previous 9 months, first by taking Andrew Ng's course, then by studying CS231 notes at Stanford, and finally playing with a few models myself.  I made a speech recognition system for my relatively obscure mother tongue (which is not English), and image recognition system.  Along the way I have read all of the academic journal articles links in CS231 course and various well known blogs.  

Questions:
Given this background, is it worth the time to wait for RTX 2060 Super to start selling on 7/9?

Given this background, is it worth the extra money for RTX 2060 Super when the MSRP is $400, but with my sales tax it would be $431?  So at least $80 more expensive and possibly more close to $100 when taking into account  getting after market cards with good fans.",7,2
54,2019-7-5,2019,7,5,4,c96v4c,Created the fastest and most customizable NLP tokenizer in Python using a novel approach (not regex!),https://www.reddit.com/r/deeplearning/comments/c96v4c/created_the_fastest_and_most_customizable_nlp/,pvkooten,1562269761,[https://github.com/kootenpv/tok](https://github.com/kootenpv/tok),4,42
55,2019-7-5,2019,7,5,5,c97hgw,Facebook just open-sourced their Deep Learning Recommendation Model (DLRM),https://www.reddit.com/r/deeplearning/comments/c97hgw/facebook_just_opensourced_their_deep_learning/,goncaloperes,1562273149,,3,17
56,2019-7-5,2019,7,5,6,c97piv,David Silver's Reinforcement Learning Course [Summary],https://www.reddit.com/r/deeplearning/comments/c97piv/david_silvers_reinforcement_learning_course/,jdyr1729,1562274414,,0,1
57,2019-7-5,2019,7,5,6,c97uth,5 Minute Summary of DeepMind's RL Course (Lecture 1),https://www.reddit.com/r/deeplearning/comments/c97uth/5_minute_summary_of_deepminds_rl_course_lecture_1/,jdyr1729,1562275242,,4,14
58,2019-7-5,2019,7,5,10,c9a0di,How can I review my Tensorflow knowledge?,https://www.reddit.com/r/deeplearning/comments/c9a0di/how_can_i_review_my_tensorflow_knowledge/,gitmonk,1562288893,"I learned to use Tensorflow a year and a half ago, just before I started my undergradute thesis. A lot has happened since then, and I kind of lost the practice (I was not that skilled to begin with). But anyway, what is the most fast and solid way I can review the basics and also learn more specific things like batch normalization and other advanced techniques? I thought about doing a project based learning, but I don't really know where to start. 

A little more context to see if you guys can point me out what to learn: my thesis is about 3D face reconstruction from 2D colored face images and I am currently working with the FRGC dataset.

I beg your pardon in advance if the post is not that clear, English is not my mothertongue.",2,3
59,2019-7-5,2019,7,5,14,c9c9y5,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c9c9y5/data_science_career_track_prep_course/,HannahHumphreys,1562305392,[removed],0,1
60,2019-7-5,2019,7,5,19,c9el13,Accuracy of the model,https://www.reddit.com/r/deeplearning/comments/c9el13/accuracy_of_the_model/,samisoomro24,1562323825,"Hello Everyone Hope you all are doing well. I working on a dataset consists of about 473 images that have 5 classes, some classes have more images and some have less images. I am classifying classes through pre-trained MobileNet model. My question is that how can I increase the accuracy of my model which is now about 30% I have tried data augmentation.",9,1
61,2019-7-5,2019,7,5,22,c9fwlp,[Research] Emotion Recognition Using Fusion of Audio and Video Features,https://www.reddit.com/r/deeplearning/comments/c9fwlp/research_emotion_recognition_using_fusion_of/,cdossman,1562332982,"[https://medium.com/ai%C2%B3-theory-practice-business/emotion-recognition-using-fusion-of-audio-and-video-features-3db8f46dce80](https://medium.com/ai%C2%B3-theory-practice-business/emotion-recognition-using-fusion-of-audio-and-video-features-3db8f46dce80) 

**Abstract:**  In this paper, we propose a fusion approach to continuous emotion recognition that combines visual and auditory modalities in their representation spaces to predict the arousal and valence levels. The proposed approach employs a pre-trained convolution neural network and transfer learning to extract features from video frames that capture the emotional content. For the auditory content, a minimalistic set of parameters such as prosodic, excitation, vocal tract, and spectral descriptors are used as features. The fusion of these two modalities is carried out at a feature level, before training a single support vector regressor (SVR) or at a prediction level, after training one SVR for each modality. The proposed approach also includes preprocessing and postprocessing techniques which contribute favorably to improving the concordance correlation coefficient (CCC). Experimental results for predicting spontaneous and natural emotions on the RECOLA dataset have shown that the proposed approach takes advantage of the complementary information of visual and auditory modalities and provides CCCs of 0.749 and 0.565 for arousal and valence, respectively.",1,16
62,2019-7-5,2019,7,5,23,c9geho,Sketch Notes of Deep Learning,https://www.reddit.com/r/deeplearning/comments/c9geho/sketch_notes_of_deep_learning/,mikasarei,1562335975,,0,1
63,2019-7-6,2019,7,6,3,c9j38x,Trying to measure RTX 2080 Ti usage during Deep Learning predictions,https://www.reddit.com/r/deeplearning/comments/c9j38x/trying_to_measure_rtx_2080_ti_usage_during_deep/,arnauda9,1562349768,"Hello everyone ! I am trying to measure the GPU memory usage and the time spent in the GPU during a prediction. I am having a look at NVML library and I do not understand what is the ""sample period"" and why it depends on the hardware.

[Screenshot of the NVML documentation](https://i.redd.it/tg9hh2eswi831.png)

Do you have any advice on what this means ?

Also, if you have a clear explanation on how to analyse memory and time usage, I would be glad to hear it.

Thanks it advance!",0,0
64,2019-7-6,2019,7,6,5,c9kz42,Any negative effects of applying 1x1 convolutional layers?,https://www.reddit.com/r/deeplearning/comments/c9kz42/any_negative_effects_of_applying_1x1/,Lucky_Gambler,1562359455,"This most likely is a dumb question, but has anyone here heard of or seen the implementation of 1x1 convolution layers (for specifically reducing computation cost) that actually significantly decreased the performance of a network in training? If so, could you post a link to the source code or paper or GitHub?",8,0
65,2019-7-6,2019,7,6,11,c9oc9n,Urgent Help needed. I 'actually' NEED to learn Deep Learning superficially in 3 DAYS. How do I do this?,https://www.reddit.com/r/deeplearning/comments/c9oc9n/urgent_help_needed_i_actually_need_to_learn_deep/,anotheraccount97,1562379405,"I got an internship through my university's 6 month industrial experience program where I was allowed to brag/overstate with fake Skills in order to get allotted a decent organization. I know Soft Dev (Java,DSA etc etc), Python somewhat. 

&amp;#x200B;

They've given me a deep learning profile on the basis of my mention of Tensorflow, Keras etc. Now the intern starts on Monday(3 days from now), so I'll need to learn it superficially so that my manager doesn't get the hint that I was lying. In the course of first week, I wish to learn as much as possible, and then with the ongoing internship of 6 months, I'll try to do my best to become an expert in the same. 

&amp;#x200B;

Please help me by stating exact resources, courses that I can binge through, and videos of workshops/bootcamps that I can go through this Sat/Sun/Mon to gain a presentable knowledge of the DL field, also some ML (I don't know ML too, extremely sorry for the disrespect to this beautiful field). Apologies and Thanks.",13,0
66,2019-7-6,2019,7,6,15,c9qiyx,How to plan and execute your ML and DL projects,https://www.reddit.com/r/deeplearning/comments/c9qiyx/how_to_plan_and_execute_your_ml_and_dl_projects/,pirate7777777,1562395084,,5,30
67,2019-7-6,2019,7,6,17,c9rbs8,How can you constrain the latent variable space of an Autoencoder to quantities that can be interpreted?,https://www.reddit.com/r/deeplearning/comments/c9rbs8/how_can_you_constrain_the_latent_variable_space/,fipeopp,1562401599,,4,4
68,2019-7-6,2019,7,6,17,c9rcqi,Which are creative ways to approach customer churn prediction (besides tree-based models or NNs)?,https://www.reddit.com/r/deeplearning/comments/c9rcqi/which_are_creative_ways_to_approach_customer/,fipeopp,1562401835,,0,1
69,2019-7-6,2019,7,6,20,c9sinx,RNN hidden state and weights shape,https://www.reddit.com/r/deeplearning/comments/c9sinx/rnn_hidden_state_and_weights_shape/,carnivorousdrew,1562411971,"I am having trouble building a RNN cell from scratch. Theoretically the output of the hidden ste function should be a vector of the same shape as the input, therefore the hidden state, hidden state's weight and input weight should be a different shape than the input, right?
What should their sizes be?",2,2
70,2019-7-6,2019,7,6,22,c9tfzm,Big Data,https://www.reddit.com/r/deeplearning/comments/c9tfzm/big_data/,HannahHumphreys,1562418725,[removed],0,1
71,2019-7-7,2019,7,7,3,c9x1o5,Keras loss functions: is there a way to get the indeces of the sample(s) being evaluated?,https://www.reddit.com/r/deeplearning/comments/c9x1o5/keras_loss_functions_is_there_a_way_to_get_the/,Dampware,1562438609,"Disclaimer: I'm relatively new to dl, so I'm very appreciative of any consideration you may give this. 

I have data that includes an image, label as well as some auxiliary tabular data for each sample.

The results I seek are a regression from the image only; in deployment, the associated auxiliary tabular data will not be present, so I don't wish to consider the tabular data in the nn or the regression results. However, I do wish to consider the auxiliary data in the loss function, to penalize the predictions. 

So I'm imagining something like this:
During training, as a prediction and loss is generated for each image / batch, I would use the prediction, the label and the auxiliary tabular data to alter the loss appropriately, before backprop.

To do this I'd need the indices of the samples being considered by the loss function to access the associated aux data. I haven't found a way to access those indices.

Any thoughts? Is this even feasible (using keras w tf) ?

Again, thanks for your time.",7,5
72,2019-7-7,2019,7,7,10,ca1moc,Convlutional implementation of sliding window Algorithm,https://www.reddit.com/r/deeplearning/comments/ca1moc/convlutional_implementation_of_sliding_window/,tahamagdy,1562464775,"I understand the convolutional implementation mechanism, My problem is that I don't know why the it is equivalent to the sequential sliding windows?!",2,2
73,2019-7-7,2019,7,7,17,ca4r34,looking for RTX 2080 Ti air blower coolers as separate component,https://www.reddit.com/r/deeplearning/comments/ca4r34/looking_for_rtx_2080_ti_air_blower_coolers_as/,gpuace,1562488982,"Does anybody know if one can buy RTX 2080 Ti air blower coolers seperatly? Are there companies out there or is there someone who has replaced the RTX 2080 Ti air blower cooler with a water cooler and has one or numerous to spare now? If yes, please send a message with your offer (with shipment to Germany).",3,5
74,2019-7-7,2019,7,7,18,ca4wb3,"Did you know that if you watch ""The Thing"" with the subtitles on you can read the sounds of diarreah?",https://www.reddit.com/r/deeplearning/comments/ca4wb3/did_you_know_that_if_you_watch_the_thing_with_the/,shitknifeactual,1562490331,,1,0
75,2019-7-7,2019,7,7,20,ca5xob,Big Data Analytics Projects with Apache Spark,https://www.reddit.com/r/deeplearning/comments/ca5xob/big_data_analytics_projects_with_apache_spark/,HannahHumphreys,1562499529,[removed],0,1
76,2019-7-8,2019,7,8,0,ca82ac,My first journal entry.,https://www.reddit.com/r/deeplearning/comments/ca82ac/my_first_journal_entry/,jager_2798,1562513531,"Recently my publication titled:  ""Diagnosis of melanoma from dermoscopic images using a deep depthwise separable residual convolutional network "", was accepted at IET Image Processing. We used the ISIC dataset to train our network. Publication link:  [http://ietdl.org/t/h1Rq7b](http://ietdl.org/t/h1Rq7b)",6,20
77,2019-7-8,2019,7,8,14,cagrjt,Google Makes DL Model Deployment Easy With Deep Learning Cloud Containers,https://www.reddit.com/r/deeplearning/comments/cagrjt/google_makes_dl_model_deployment_easy_with_deep/,analyticsindiam,1562562091,,1,27
78,2019-7-8,2019,7,8,17,caiily,New AMD Navi GPUs for deep learning,https://www.reddit.com/r/deeplearning/comments/caiily/new_amd_navi_gpus_for_deep_learning/,drr21,1562575451,What do you think about the new AMD GPUs for deep learning. Will they be a good alternative to Nvidia?,12,15
79,2019-7-8,2019,7,8,17,cailvn,[RL] Tensorflow.js and GridWorld - From Value Fuction to A3C,https://www.reddit.com/r/deeplearning/comments/cailvn/rl_tensorflowjs_and_gridworld_from_value_fuction/,greentecq,1562576224,,0,1
80,2019-7-8,2019,7,8,18,cairc6,Paper with experimental results on when transfer learning makes sense,https://www.reddit.com/r/deeplearning/comments/cairc6/paper_with_experimental_results_on_when_transfer/,pppeer,1562577373,"(also posted in r/MachineLearning)

We wrote a paper with test results on when it makes sense to use transfer learning. The paper was published at IDA a while ago, but I still see this question pop up regularly, and I am also interested in what has been published since on this topic, as proper benchmarking to answer this question still seems to be lacking.

In a nut shell the answer of course is 'when you don't have enough data', but we quantified this through experimentation by varying the number of instances per class, as well as the number of layers 'copied' and more.

The intuition behind the paper is described in this medium post, and you will also find a link to a preprint should you not have access to the conference paper. See [https://medium.com/@petervanderputten/teaching-and-old-dog-new-tricks-transfer-learning-in-deep-neural-networks-ca85992119ec](https://medium.com/@petervanderputten/teaching-and-old-dog-new-tricks-transfer-learning-in-deep-neural-networks-ca85992119ec)

Feedback welcome!",4,1
81,2019-7-8,2019,7,8,19,cajafn,"Does DNN really understand what a ""digits"" means?",https://www.reddit.com/r/deeplearning/comments/cajafn/does_dnn_really_understand_what_a_digits_means/,rockking_jy,1562581310,"I've trained on MNIST(I know it's a bit ancient) with a DNN that's achieve above 99%, but then I use it on my own digit dataset, it's just around 11%. I know the distribution of these two datasets are not the same. But we human beings can figure out the new images with digits.",15,3
82,2019-7-8,2019,7,8,20,cajvtr,Deep Learning Can Now Find Galaxies That Are Million Of Lightyears Away,https://www.reddit.com/r/deeplearning/comments/cajvtr/deep_learning_can_now_find_galaxies_that_are/,analyticsindiam,1562585534,,0,6
83,2019-7-8,2019,7,8,20,cajwfq,Does anybody know where can i find a pre-trained text detection network?,https://www.reddit.com/r/deeplearning/comments/cajwfq/does_anybody_know_where_can_i_find_a_pretrained/,pcrca,1562585647,I'm working on a text detection/recognition task and i don't have the time or resources to train something from scratch so i'm looking for a ready-to-use network for text detection/recogniton,2,1
84,2019-7-8,2019,7,8,21,cakm3c,Deep Nude Algorithm,https://www.reddit.com/r/deeplearning/comments/cakm3c/deep_nude_algorithm/,frankshawn1992,1562590151,I found out that Deep Nude algorithm was deleted from github. Did anyone clone it? Can you please share it?,59,0
85,2019-7-8,2019,7,8,22,cal8nb,Bayesian Machine Learning in Python: A/B Testing,https://www.reddit.com/r/deeplearning/comments/cal8nb/bayesian_machine_learning_in_python_ab_testing/,HannahHumphreys,1562593655,[removed],0,1
86,2019-7-8,2019,7,8,23,caljhk,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/caljhk/data_science_career_track_prep_course/,HannahHumphreys,1562595181,[removed],0,1
87,2019-7-9,2019,7,9,3,caoit2,HyperFoods: Machine intelligent mapping of cancer-beating molecules in foods,https://www.reddit.com/r/deeplearning/comments/caoit2/hyperfoods_machine_intelligent_mapping_of/,srohit0,1562609051,,2,4
88,2019-7-9,2019,7,9,6,carki1,Using Doc2Vec to classify movie reviews,https://www.reddit.com/r/deeplearning/comments/carki1/using_doc2vec_to_classify_movie_reviews/,jdyr1729,1562622928,"Hi,

I just wrote an article explaining how to use gensim's implementation of Paragraph Vector, Doc2Vec, to achieve a state-of-the-art-result on the IMDB movie review problem. 

Thought I'd share it here for anyone who is interested: https://jackdry.com/using-doc2vec-to-classify-movie-reviews 

Hope you find it helpful!

Jack",2,28
89,2019-7-9,2019,7,9,9,catlct,This video goes over a breast cancer diagnosis model that uses neural networks (implemented in python),https://www.reddit.com/r/deeplearning/comments/catlct/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1562633254,,0,2
90,2019-7-9,2019,7,9,9,catp63,"Researcher tricks m3.euagendas.org, the Twitter analysis website, with adversarial inputs",https://www.reddit.com/r/deeplearning/comments/catp63/researcher_tricks_m3euagendasorg_the_twitter/,atomlib_com,1562633849,,0,1
91,2019-7-9,2019,7,9,12,cav2hp,Simple question about siamese nets,https://www.reddit.com/r/deeplearning/comments/cav2hp/simple_question_about_siamese_nets/,hassanzadeh,1562641316,"Hello guys,

what do u call each of the arms in a siamese net?

THanks",0,2
92,2019-7-9,2019,7,9,14,cawakw,Decoding synthetic character into real human,https://www.reddit.com/r/deeplearning/comments/cawakw/decoding_synthetic_character_into_real_human/,rozgo,1562648622,,2,7
93,2019-7-9,2019,7,9,17,cay4jz,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cay4jz/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1562661209,[removed],0,1
94,2019-7-9,2019,7,9,17,cay6rf,Lie detection with EEG sensor,https://www.reddit.com/r/deeplearning/comments/cay6rf/lie_detection_with_eeg_sensor/,clean_pegasus,1562661666,Is it possible to find out if someone is telling the truth using deep learning and neural networks?,2,3
95,2019-7-9,2019,7,9,18,cayd73,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cayd73/data_science_career_track_prep_course/,HannahHumphreys,1562663001,[removed],0,1
96,2019-7-9,2019,7,9,18,caygml,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/caygml/data_science_career_track_prep_course/,HannahHumphreys,1562663711,[removed],0,1
97,2019-7-9,2019,7,9,18,cayl4n,Why Do Neural Networks Generalize So Effortlessly And Other Questions,https://www.reddit.com/r/deeplearning/comments/cayl4n/why_do_neural_networks_generalize_so_effortlessly/,analyticsindiam,1562664604,,0,6
98,2019-7-9,2019,7,9,18,cayohj,Bokeh effect with semantic segmentation or instance segmentation.,https://www.reddit.com/r/deeplearning/comments/cayohj/bokeh_effect_with_semantic_segmentation_or/,clean_pegasus,1562665264,Does Google pixel phones use semantic segmentation or instance segmentation for Bokeh effect?,0,1
99,2019-7-9,2019,7,9,18,cayqlf,Astounding deepfake of Jim Carrey in the Shining.,https://www.reddit.com/r/deeplearning/comments/cayqlf/astounding_deepfake_of_jim_carrey_in_the_shining/,OwlKneeArn,1562665672,,18,79
100,2019-7-9,2019,7,9,22,cb0nr6,Blogpost - Turning a panda into a cat? Why adversarial examples are not scarybut are most likely useful,https://www.reddit.com/r/deeplearning/comments/cb0nr6/blogpost_turning_a_panda_into_a_cat_why/,sonjageorg,1562677723,,0,1
101,2019-7-10,2019,7,10,0,cb21uz,Put down the deep learning: When not to use neural networks and what to do instead,https://www.reddit.com/r/deeplearning/comments/cb21uz/put_down_the_deep_learning_when_not_to_use_neural/,ConfidentMushroom,1562684710,,0,8
102,2019-7-10,2019,7,10,0,cb268i,The Role of AI and Machine Learning in Data Quality,https://www.reddit.com/r/deeplearning/comments/cb268i/the_role_of_ai_and_machine_learning_in_data/,raj11113,1562685292,,0,1
103,2019-7-10,2019,7,10,1,cb37i7,"[WIP book] Deep Learning for Programmers, new release 0.5.0",https://www.reddit.com/r/deeplearning/comments/cb37i7/wip_book_deep_learning_for_programmers_new/,dragandj,1562690059,,0,2
104,2019-7-10,2019,7,10,2,cb43b1,Video Classification - LSTM and 3DConv,https://www.reddit.com/r/deeplearning/comments/cb43b1/video_classification_lstm_and_3dconv/,Beukgevaar,1562693994,"Currently I'm looking into the aspect of Video Classification using python and Keras/Tensorflow, but I'm encountering some errors.

&amp;#x200B;

Basic idea: Trying to identify certain movements from video, which are already split into train and test with subfolders per label with its extracted frames.

&amp;#x200B;

For now this is my code for the LSTM network:

`train_data_dir = './train'`

`validation_data_dir = './test'`

`nb_train_samples = 46822`

`nb_validation_samples = 8994`

`epochs = 10`

`batch_size = 16`

&amp;#x200B;

`input_shape = (img_width, img_height, 3)`

&amp;#x200B;

`#TimeDistributed CNN + LSTM`

`model = Sequential()` 

`model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same', input_shape=(224, 135, 3))))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=""he_normal"")))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Conv2D(64, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(64, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Conv2D(128, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(128, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Conv2D(256, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(256, (3,3), padding='same',)))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Conv2D(512, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(512, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Flatten()))`

&amp;#x200B;

`model.add(Dropout(0.5))`

`model.add(LSTM(256, return_sequences=False, dropout=0.5))`

`model.add(Dense(6))`

`model.add(Activation('softmax'))`  


`model.compile(loss ='categorical_crossentropy', optimizer ='rmsprop', metrics =['accuracy'])`  
`model.summary()`

&amp;#x200B;

`train_datagen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)` 

`test_datagen = ImageDataGenerator(rescale = 1. / 255)`

`train_generator = train_datagen.flow_from_directory(train_data_dir, target_size =(img_width, img_height), batch_size = batch_size, class_mode ='categorical')` 

`validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size =(img_width, img_height), batch_size = batch_size, class_mode ='categorical')` 

`model.fit_generator(train_generator, steps_per_epoch = nb_train_samples // batch_size, epochs = epochs, validation_data = validation_generator, validation_steps = nb_validation_samples // batch_size)`

&amp;#x200B;

And for the 3D Convolutional Network:

......

`model = Sequential()` 

`model.add(Conv3D(32, (3,3,3), input_shape=(20, 224, 135, 3)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))`

`model.add(Conv3D(64, (3,3,3)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))`

`model.add(Conv3D(128, (3,3,3)))`

`model.add(Activation('relu'))`

`model.add(Conv3D(128, (3,3,3)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))`

`model.add(Conv3D(256, (2,2,2)))`

`model.add(Activation('relu'))`

`model.add(Conv3D(256, (2,2,2)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))`

 

`model.add(Flatten())`

`model.add(Dense(1024))`

`model.add(Dropout(0.5))`

`model.add(Dense(1024))`

`model.add(Dropout(0.5))`

`model.add(Dense(6, activation='softmax'))`

......

&amp;#x200B;

But for each of these code 1 get an error:

\- LSTM --&gt; *ValueError: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input\_shape or batch\_input\_shape in the first layer for automatic build.*

It seems like it is ignoring the model.compile line? Or am I missing something?

&amp;#x200B;

\- 3DConv --&gt; *ValueError: Error when checking input: expected conv3d\_1\_input to have 5 dimensions, but got array with shape (16, 224, 135, 3)*  
I have no idea how/where to add the extra dimension for the model.fit\_generator.

&amp;#x200B;

Hope there is someone who is able to assist me with the above.",0,1
105,2019-7-10,2019,7,10,3,cb557v,Awesome AI research reviews: BEST OF CVPR 2019 on Computer Vision News of July (with codes!),https://www.reddit.com/r/deeplearning/comments/cb557v/awesome_ai_research_reviews_best_of_cvpr_2019_on/,Gletta,1562698634,"The July issue of Computer Vision News includes RSIP Vision's choices for BEST OF CVPR 2019.

Read 48 pages with exclusive articles on AI, computer vision and deep learning.

Exclusive interview with Andrew Fitzgibbon on page 20. Subscribe for free on page 48!

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019July/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-july-pdf/)

Enjoy!

&amp;#x200B;

https://i.redd.it/ebp5l24srb931.jpg",0,22
106,2019-7-10,2019,7,10,5,cb6jkg,Custom loss function for occluded landmarks detection,https://www.reddit.com/r/deeplearning/comments/cb6jkg/custom_loss_function_for_occluded_landmarks/,nikogamulin,1562704876,"Hi,

I am building a model which is supposed to detect at most 6 different landmarks on the image. In some cases, some landmarks are occluded.

The output is an 18-dimensional vector. First 6 values are binary (0/1) and determine whether the landmark is visible or occluded. the remaining 12 values represent x and y coordinates for 6 landmarks. The x and y values for occluded landmarks are 0.

The output layer consists of 6 sigmoid and 12 linear units.

The loss function is defined as follows:

`def custom_loss(y_true, y_pred):`

`cLP_true, cRP_true, cCTL_true, cCTR_true, cCBR_true, cCBL_true, yLP_true, xLP_true, yRP_true, xRP_true, yCTL_true,`   
  `xCTL_true, yCTR_true, xCTR_true, yCBR_true, xCBR_true, yCBL_true, xCBL_true = tf.split(y_true, num_or_size_splits=18, axis=1)`

`cLP_pred, cRP_pred, cCTL_pred, cCTR_pred, cCBR_pred, cCBL_pred, yLP_pred, xLP_pred, yRP_pred, xRP_pred, yCTL_pred, xCTL_pred, yCTR_pred, xCTR_pred, yCBR_pred, xCBR_pred, yCBL_pred, xCBL_pred = tf.split(y_pred, num_or_size_splits=18, axis=1)`

`loss_regression = 0`

`loss_regression += cLP_true * ((yLP_pred - yLP_true)**2 + (xLP_pred - xLP_true)**2)`

`loss_regression += cRP_true * ((yRP_pred - yRP_true)**2 + (xRP_pred - xRP_true)**2)`

`loss_regression += cCTL_true * ((yCTL_pred - yCTL_true)**2 + (xCTL_pred - xCTL_true)**2)`

`loss_regression += cCTR_true * ((yCTR_pred - yCTR_true)**2 + (xCTR_pred - xCTR_true)**2)`

`loss_regression += cCBR_true * ((yCBR_pred - yCBR_true)**2 + (xCBR_pred - xCBR_true)**2)`

`loss_regression += cCBL_true * ((yCBL_true - yCBL_pred)**2 + (xCBL_pred - xCBL_true)**2)`



`loss_class = binaryCE([cLP_true, cRP_true, cCTL_true, cCTR_true, cCBR_true, cCBL_true], [cLP_pred, cRP_pred, cCTL_pred, cCTR_pred, cCBR_pred, cCBL_pred])`

   

`return loss_regression + 10 * loss_class`

&amp;#x200B;

I would appreciate any comment/suggestion for further improvement.",0,1
107,2019-7-10,2019,7,10,6,cb6uz9,Image Data Augmentation for Deep Learning,https://www.reddit.com/r/deeplearning/comments/cb6uz9/image_data_augmentation_for_deep_learning/,HenryAILabs,1562706304,[https://www.youtube.com/watch?v=mljRx81K1gY](https://www.youtube.com/watch?v=mljRx81K1gY),0,2
108,2019-7-10,2019,7,10,6,cb7fcn,"Few-shot, weakly or semi-supervised learning if only have 20 training images for segmentation?",https://www.reddit.com/r/deeplearning/comments/cb7fcn/fewshot_weakly_or_semisupervised_learning_if_only/,b3873656,1562708917,"I have a training set of 20 images of semiconductors that I need to perform segmentation for. I was thinking semantic or salient segmentation would work

I'm new to deep learning. From what i understand, semantic segmentation usually requires at least thousands of training images to get good results. But since I only have 20 images, I'm not sure what to do instead. Should I look into few-shot semantic segmentation methods? Or methods that do weakly/semi-supervised learning? What about domain adaptation/transfer learning? 

Or could I just use those 20 images to create like 100,000 images using augmentation, and then use semantic segmentation?

How should I approach this problem?",3,1
109,2019-7-10,2019,7,10,11,cbaqdn,Artificial Intelligence: Become An Expert,https://www.reddit.com/r/deeplearning/comments/cbaqdn/artificial_intelligence_become_an_expert/,ashleymadison1750,1562725817,,0,0
110,2019-7-10,2019,7,10,11,cbarwk,Management of Thyroid Nodules Seen on US Images: Deep Learning May Match Performance of Radiologists,https://www.reddit.com/r/deeplearning/comments/cbarwk/management_of_thyroid_nodules_seen_on_us_images/,ketsok,1562726059,,0,3
111,2019-7-10,2019,7,10,12,cbbh8j,"How do you set up a DBN when the data is the shape of a space, or when the space into which the data is embedded is non Euclidean?",https://www.reddit.com/r/deeplearning/comments/cbbh8j/how_do_you_set_up_a_dbn_when_the_data_is_the/,IntrepidDust,1562729990,"How do you set up a DBN when the data is the shape of a space, such as with a relational database, or when the space into which the data is embedded is non Euclidean, such as on the surface of a sphere or inside a fractal, such as an organ or organism?",0,0
112,2019-7-10,2019,7,10,14,cbcrlg,From Online Courses to Reading Papers,https://www.reddit.com/r/deeplearning/comments/cbcrlg/from_online_courses_to_reading_papers/,patronus816,1562737751,"Hi! I finished Andrew Ng's courses on Deep Learning except the RNN part which was the last module I think? I'm also looking into taking a Master's in Machine Learning and I want it to be computer vision focused. 

I was wondering if there was a bridge between the Ng Courses and individually reading the ""State of the art"" papers? I'm trying to get myself to read these papers as they might potentially lead me to a topic/problem I want to focus on for my Master's thanks!",4,5
113,2019-7-10,2019,7,10,16,cbdv0w,Deepfake video detection. Is it possible?,https://www.reddit.com/r/deeplearning/comments/cbdv0w/deepfake_video_detection_is_it_possible/,testimoni,1562745451,"Hello,

&amp;#x200B;

I am new here and recently became aware of deepfake videos and it amazed me. I was just thinking if there is a way to determine a video containg deepfake content or not? For example, user upload a video to see if this video is deepfake or not. How to determine it programmatically?",12,11
114,2019-7-10,2019,7,10,18,cbehnu,Introduction to TensorWatch,https://www.reddit.com/r/deeplearning/comments/cbehnu/introduction_to_tensorwatch/,whitezl0,1562750460,,0,6
115,2019-7-10,2019,7,10,20,cbfpr4,Someone Finally Done It: DeepFaked Jim Carrey Into The Shining,https://www.reddit.com/r/deeplearning/comments/cbfpr4/someone_finally_done_it_deepfaked_jim_carrey_into/,analyticsindiam,1562759272,,0,2
116,2019-7-11,2019,7,11,0,cbi9ds,Are Commercial Labs Stealing Academias AI Thunder?,https://www.reddit.com/r/deeplearning/comments/cbi9ds/are_commercial_labs_stealing_academias_ai_thunder/,Yuqing7,1562773145,,3,23
117,2019-7-11,2019,7,11,0,cbiijy,Can anyone apply DeepNude on this photo?,https://www.reddit.com/r/deeplearning/comments/cbiijy/can_anyone_apply_deepnude_on_this_photo/,frankshawn1992,1562774372,,11,0
118,2019-7-11,2019,7,11,2,cbjbzx,SQL for Data Science,https://www.reddit.com/r/deeplearning/comments/cbjbzx/sql_for_data_science/,HannahHumphreys,1562778229,[removed],0,1
119,2019-7-11,2019,7,11,2,cbjjm9,Cleft Facial Lip and Palate Images,https://www.reddit.com/r/deeplearning/comments/cbjjm9/cleft_facial_lip_and_palate_images/,samisoomro24,1562779206,,0,2
120,2019-7-11,2019,7,11,3,cbkbw7,How to transform stock data for LSTM-based neural network,https://www.reddit.com/r/deeplearning/comments/cbkbw7/how_to_transform_stock_data_for_lstmbased_neural/,jdyr1729,1562782825,"I am trying to classify stock returns using an LSTM-based neural network.

I would like to use closing price and volume as features (see below), but am unsure of whether I need to transform these (e.g., by differencing) before feeding them into the network?

If anybody has done this sort of thing before and could give me some advice, or could refer me to any papers, I'd be very grateful.

[Closing price and volume](https://i.redd.it/p7n7zun4qi931.png)

Thanks,

Jack",3,1
121,2019-7-11,2019,7,11,12,cbqovr,Announcing a series of blogs on PyTorch C++ API (Libtorch),https://www.reddit.com/r/deeplearning/comments/cbqovr/announcing_a_series_of_blogs_on_pytorch_c_api/,Kushashwa,1562815750,"Hi everyone. 

I'm happy to announce a series of blogs on PyTorch C++ API. When I started using the C++ API, I had lots of problems and thanks to the community at [discuss.pytorch.com](https://discuss.pytorch.com) where I got most of the help. I decided to write blogs on using C++ API for the community. Here it comes! 

There have been 3 blogs as of now, and I would love to hear your comments and feedback on them.

 [https://krshrimali.github.io/Announcing-PyTorch-CPP-Series/](https://krshrimali.github.io/Announcing-PyTorch-CPP-Series/) 

&amp;#x200B;

[Announcing PyTorch C++ API Series! - krshrimali.github.io](https://i.redd.it/ez8mwe51gl931.png)

Thanks!",8,41
122,2019-7-11,2019,7,11,15,cbsjcx,"[HIRING] Machine Learning Engineer, FTE, Redwood City, CA, Salary : 140000 - 220000 USD",https://www.reddit.com/r/deeplearning/comments/cbsjcx/hiring_machine_learning_engineer_fte_redwood_city/,vmanasvi,1562828230,,0,0
123,2019-7-11,2019,7,11,16,cbslo9,Can anybody explain the formulation of the minmax game in GANs ?,https://www.reddit.com/r/deeplearning/comments/cbslo9/can_anybody_explain_the_formulation_of_the_minmax/,styx97,1562828696,,6,5
124,2019-7-11,2019,7,11,19,cbtykw,How big data is transforming the real estate industry,https://www.reddit.com/r/deeplearning/comments/cbtykw/how_big_data_is_transforming_the_real_estate/,raj11113,1562839706,,0,1
125,2019-7-11,2019,7,11,19,cbuceh,Weakly Supervised Object Detection In Practice,https://www.reddit.com/r/deeplearning/comments/cbuceh/weakly_supervised_object_detection_in_practice/,tahaemara,1562842600,"I published a new post on how to make a classification model performs both object classification and object localization in a single forward pass.

[http://emaraic.com/blog/weakly-supervised-detection](http://emaraic.com/blog/weakly-supervised-detection)",0,3
126,2019-7-11,2019,7,11,21,cbv05j,cdQA  a software-suite for easy implementation of Question Answering systems,https://www.reddit.com/r/deeplearning/comments/cbv05j/cdqa_a_softwaresuite_for_easy_implementation_of/,crAAzyKKid,1562847059,"Hi,

&amp;#x200B;

With some colleagues I developed an end-to-end software suite for easy implementation and deployment of Question-Answering systems in Python. It uses a pipeline with classical Information Retrieval techniques and the Deep Learning model BERT.

[https://cdqa-suite.github.io/cdQA-website/](https://cdqa-suite.github.io/cdQA-website/)

[https://github.com/cdqa-suite/cdQA](https://github.com/cdqa-suite/cdQA)

&amp;#x200B;

We wrote an article in TDS explaining how to implement it easily: [https://towardsdatascience.com/how-to-create-your-own-question-answering-system-easily-with-python-2ef8abc8eb5](https://towardsdatascience.com/how-to-create-your-own-question-answering-system-easily-with-python-2ef8abc8eb5)

&amp;#x200B;

Don't hesitate to reach me out if you have questions, comments or ideas of improvement",1,4
127,2019-7-11,2019,7,11,22,cbvkl8,Is discussion of deepnudes ban in this subreddit or not?,https://www.reddit.com/r/deeplearning/comments/cbvkl8/is_discussion_of_deepnudes_ban_in_this_subreddit/,apostle8787,1562850768,,0,6
128,2019-7-11,2019,7,11,23,cbw5fm,How to start with time series forecasting??,https://www.reddit.com/r/deeplearning/comments/cbw5fm/how_to_start_with_time_series_forecasting/,drag_97,1562854783,I have experience with CNN and NN but I want to make some projects on time series forecasting using LSTM . Any advice where should I start?,0,1
129,2019-7-12,2019,7,12,0,cbwlra,The 5th Place Approach to the 2019 ACM Recsys Challenge by Team RosettaAI,https://www.reddit.com/r/deeplearning/comments/cbwlra/the_5th_place_approach_to_the_2019_acm_recsys/,steeveHuang,1562857382,"Just finished the writeup for our 5th place solution in the 2019 ACM RecSys Challenge! This blog post will talk about the datasets, the loss function, the Neural Networks architecture, and feature engineering. Hope you enjoy it :)

&amp;#x200B;

[https://blog.rosetta.ai/the-5th-place-approach-to-the-2019-acm-recsys-challenge-by-team-rosettaai-eb3c4e6178c4](https://blog.rosetta.ai/the-5th-place-approach-to-the-2019-acm-recsys-challenge-by-team-rosettaai-eb3c4e6178c4)",0,1
130,2019-7-12,2019,7,12,1,cbxnky,NLP inference in floating point?,https://www.reddit.com/r/deeplearning/comments/cbxnky/nlp_inference_in_floating_point/,CArchGuy,1562862297,Are there any current NLP models that require floating point operations in inference rather than fixed point ? Thanks,0,1
131,2019-7-12,2019,7,12,4,cbzqp2,AI To Save Snow Leopards,https://www.reddit.com/r/deeplearning/comments/cbzqp2/ai_to_save_snow_leopards/,lomiag,1562871826," I know Microsoft has been all over news with their AI that helps snow leopard preservation community. But I work for a small non-profit organization Kashmir World Foundation, and during my internship I created a program to detect snow leopard in the wild and classify them. So the preservation workers do not spend their valuable time sorting them. Just wanted to share it here.

![img](9s1luucr2q931)

![img](4s3cnotr2q931)",12,45
132,2019-7-12,2019,7,12,7,cc2751,My general understanding to fully connect layer in the neural network.,https://www.reddit.com/r/deeplearning/comments/cc2751/my_general_understanding_to_fully_connect_layer/,jacky_guo,1562883392,"Hi, I have been doing import tensorflow for years. Last night, I was thinking about how the Linear layer works and it reminded me of the basic linear algebra. I want to share my thoughts and hope pytorcher and tensorflowers please leave some comments! 

&amp;#x200B;

From feedforward perspective: Applying Linear layer to tensors (vector) is literally doing space transformation, this transformation should better disentangle the original vector into a better space (projected onto the basis) for downstream tasks (eg:classification).

&amp;#x200B;

From optimization (backward) perspective: Learning a linear layer is finding the transformation basis, so the data in the original space can be better represented in another space (E.g.: output space with two dimensions in the binary classification case).

&amp;#x200B;

Is my understanding correct?",1,1
133,2019-7-12,2019,7,12,8,cc2unk,GPU to run object detection and segmentation model (Under $250),https://www.reddit.com/r/deeplearning/comments/cc2unk/gpu_to_run_object_detection_and_segmentation/,fiorano10,1562886739,"We have a robot with a mini ITX PC and were trying to add a GPU to running our detection and segmentation models (pre-trained). Its enclosed in a sealed box so were looking for a low profile GPU. I found the 1050Ti and 1650 to be good contenders but couldnt find a low profile version for the 1650 under $250. The 1650 has more CUDA cores, and performs 30-50% better. Are there any other options under $250 which we should be looking at?",6,5
134,2019-7-12,2019,7,12,8,cc3dbp,What type of NN would be best for auto punctuation?,https://www.reddit.com/r/deeplearning/comments/cc3dbp/what_type_of_nn_would_be_best_for_auto_punctuation/,TheDigitalRhino,1562889486,,0,1
135,2019-7-12,2019,7,12,11,cc4y3w,Using deep learning to actually learn more efficiently,https://www.reddit.com/r/deeplearning/comments/cc4y3w/using_deep_learning_to_actually_learn_more/,backtoreality0101,1562898471,"Does anyone know of any example programs/code that has been used to help people be more efficient in how they learn or keep up with their respective literature? I work in academics and was wondering if there is a way to combine twitter databases from my field, with text books from the field and then high impact journal publications to create an algorithm that could then be used to learn better? Any ideas on this? Anyone working on something like this?",2,6
136,2019-7-12,2019,7,12,15,cc76x3,Not just another GAN paper  SAGAN,https://www.reddit.com/r/deeplearning/comments/cc76x3/not_just_another_gan_paper_sagan/,Shemetz,1562912836,,2,6
137,2019-7-12,2019,7,12,18,cc8foi,Deep Learning and Modern Natural Language Processing (NLP),https://www.reddit.com/r/deeplearning/comments/cc8foi/deep_learning_and_modern_natural_language/,Amber3825,1562922305, [https://morioh.com/p/c71ad53ac79d](https://morioh.com/p/c71ad53ac79d),1,10
138,2019-7-12,2019,7,12,18,cc8ft6,Advanced Artificial Intelligence Projects with Python,https://www.reddit.com/r/deeplearning/comments/cc8ft6/advanced_artificial_intelligence_projects_with/,HannahHumphreys,1562922330,[removed],0,1
139,2019-7-12,2019,7,12,19,cc8wx2,Are rtx 2070 max q laptops good for deep learning?,https://www.reddit.com/r/deeplearning/comments/cc8wx2/are_rtx_2070_max_q_laptops_good_for_deep_learning/,ar0752545,1562925778,,13,8
140,2019-7-12,2019,7,12,19,cc8xnm,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cc8xnm/data_science_career_track_prep_course/,HannahHumphreys,1562925915,[removed],0,1
141,2019-7-12,2019,7,12,20,cc9ikg,NVIDIA 1050Ti vs 1650,https://www.reddit.com/r/deeplearning/comments/cc9ikg/nvidia_1050ti_vs_1650/,ai_badger,1562930002,Which GPU is better for deep learning? Any compatibility issues with either of the the aforementioned GPUs with Tensorflow/PyTorch?,10,2
142,2019-7-12,2019,7,12,22,ccaxae,Introduction to PyTorch,https://www.reddit.com/r/deeplearning/comments/ccaxae/introduction_to_pytorch/,MaryDBlackwell,1562938505, [https://medium.com/@LisaMariaz/introduction-to-pytorch-291c0ebd7090](https://medium.com/@LisaMariaz/introduction-to-pytorch-291c0ebd7090),0,6
143,2019-7-12,2019,7,12,22,ccaykn,[Research] How we do things with words: Analyzing text as social and cultural data,https://www.reddit.com/r/deeplearning/comments/ccaykn/research_how_we_do_things_with_words_analyzing/,cdossman,1562938702,"[https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-computational-text-analysis-analyzing-text-as-social-and-cultural-data-19139f65d484](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-computational-text-analysis-analyzing-text-as-social-and-cultural-data-19139f65d484) 

Abstract:  In this paper, we have consolidated our experiences, as scholars from very different disciplines, in analyzing text as social and cultural data and described how the research process often unfolds. Each of the steps in the process is time-consuming and labor-intensive. Each presents challenges. And especially when working across disciplines, the research often involves a fair amount of discussioneven negotiationabout what means of operationalization and approaches to analysis are appropriate and feasible. And yet, with a bit of perseverance and mutual understanding, conceptually sound and meaningful work results so that we can truly make use of the exciting opportunities rich textual data offers.",0,3
144,2019-7-13,2019,7,13,0,ccc7hy,AI-Based Photo Restoration,https://www.reddit.com/r/deeplearning/comments/ccc7hy/aibased_photo_restoration/,pvl18,1562944828,,2,51
145,2019-7-13,2019,7,13,0,cccjm7,How to make an image based mode to work on videos?,https://www.reddit.com/r/deeplearning/comments/cccjm7/how_to_make_an_image_based_mode_to_work_on_videos/,AhmedZubairGCU,1562946431,I am looking to make [VITON](https://arxiv.org/pdf/1711.08447.pdf) to work on videos preferably in real time like snapchat filters. Can someone guide me how this can happen and what is the method so it can be done on other models as well. Thanks,0,2
146,2019-7-13,2019,7,13,0,cccmj2,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cccmj2/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1562946807,[removed],0,1
147,2019-7-13,2019,7,13,0,ccco99,Where to find cvpr research papers?,https://www.reddit.com/r/deeplearning/comments/ccco99/where_to_find_cvpr_research_papers/,AhmedZubairGCU,1562947051,I am looking to find research papers for cvpr-ntire 2019 image restoration and enhancement challenge. Also where to find ICCP 2019 research papers? Are these available online for free?,6,2
148,2019-7-13,2019,7,13,3,ccedg8,Lane segmentation,https://www.reddit.com/r/deeplearning/comments/ccedg8/lane_segmentation/,_synaps_,1562954799,"Does anyone know an accessible state of the art lane segmentation model with this quality of outcome:

https://youtu.be/l5xu1DI6pDk",0,1
149,2019-7-13,2019,7,13,11,ccjwix,How to make CNN kernels as diverse as possible,https://www.reddit.com/r/deeplearning/comments/ccjwix/how_to_make_cnn_kernels_as_diverse_as_possible/,hassanzadeh,1562983750,"Hello guys,

I have a CNN with a few filters and I would like to make these filters as distant as possible. What is the right way that I can add  a regularizer term or something similar to the cost so that makes the kernels as distinct as possible?

&amp;#x200B;

Thanks",0,3
150,2019-7-13,2019,7,13,12,cckls5,Examples and best practices for building recommendation systems by Microsoft,https://www.reddit.com/r/deeplearning/comments/cckls5/examples_and_best_practices_for_building/,ConfidentMushroom,1562988173,,0,4
151,2019-7-13,2019,7,13,23,ccpznt,First deep learning rig,https://www.reddit.com/r/deeplearning/comments/ccpznt/first_deep_learning_rig/,nilsiism,1563028476,"Hi Community,

&amp;#x200B;

I'm currently trying to build my first deep learning setup and I'd prefer to spend as little as possible for a decent workstation. I spent the last days reading tons of blog and forum posts, but am even more confused now. I'd really appreciate your help and hope this post isn't too redundant.

Situation:

I'm a PhD student working on mobile robotics. In the lab I use a Dell XPS laptop for all of my work due to the needed mobility. My current work doesn't need a more powerful setup, but the second part of my PhD will become way more DL heavy. Therefore, I'd like to build my own DL workstation at home and start tinkering around with things such that I'm not completely lost once I need to start working on the DL part.

I general I'd like to

\- Compete in Kaggle competitions

\- Prototype and train networks for object segmentation and motion prediction

\- Tinker around with a lot of open source networks available

I should mention that I could have access to a server with 4x 1080ti quite regularly that is little used by other people.

&amp;#x200B;

I put together 3 different setups that I'm considering to build

Setup 1:

[https://pcpartpicker.com/user/nilsiism/saved/#view=qKP8Mp](https://pcpartpicker.com/user/nilsiism/saved/#view=qKP8Mp)

&amp;#x200B;

Setup 2:

[https://pcpartpicker.com/user/nilsiism/saved/#view=6cZXvK](https://pcpartpicker.com/user/nilsiism/saved/#view=6cZXvK)

&amp;#x200B;

Setup 3:

[https://pcpartpicker.com/user/nilsiism/saved/#view=VMGhgs](https://pcpartpicker.com/user/nilsiism/saved/#view=VMGhgs)

&amp;#x200B;

\- I'd use the new 2070 super for setup 1 and 2. It's just that they aren't available at pcpartpicker yet.

\- I'd not run a dual boot but rather have the 1T m2 running Ubuntu 18.04 and the 500GB m2 + 500GB SSD running Windows 10 (I still have the 500GB SSD laying around here).

\- All setups would run with just 1x GPU. There might be a point in time where I would update the system with a 2nd GPU, but if I'll ever need more I'll most likely already work in a company that provides a workstation.

&amp;#x200B;

This are my concerns:

Setup 1: This would be my preferred workstation. I just feel it's the most bang/buck. I'm also considering to get the 9900k instead for the double threads as the price difference is only GBP70, but not sure if it's worth it.I'm just a bit scared how future prove this setup is. Apart from the Xeon and X-series intel GPUs non of the Intel CPUs support more than 16x pcie lanes. How much would the performance of a second GPU suffer (just to mention again, a second is the max I'll ever expect to add to any of this setups) compared to a setup supports +44 lanes?  According to this blog [https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/](https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/) it doesn't really matter, but I feel the rest of the internet is just talking lanes, lanes, lanes, ...

&amp;#x200B;

Setup 2: A more future prove setup for more less the same money would be to use an AMD CPU. However, I'll mainly use Ubuntu on this machine and lacking support kind of scares the crap out of me. In general I'd just really prefer an Intel CPU due to the bigger Ubuntu and DL support in general. I'd only consider this switch for the additional lanes and I don't really understand if I'll ever need them even if I add a second GPU.

&amp;#x200B;

Setup 3: Okay last but not least would be more of a high end setup. It would provide the most future prove workstation, while I could still stick with Intel. Also if I'd go with this CPU I'd also directly go for the bigger GPU. However I feel the bang/buck for this setup is ridiculously bad compared to the other two (I guess that's how it's with all high-end tech).

&amp;#x200B;

Any advice would be really appreciated. I guess my main current concern is: How many pcie lanes do I really need even if I run 2 GPUs.",13,3
152,2019-7-13,2019,7,13,23,ccq7li,Adding Attention in Keras/Seeking Team Member,https://www.reddit.com/r/deeplearning/comments/ccq7li/adding_attention_in_kerasseeking_team_member/,cvantass,1563029729,"Does anyone here know how to add attention to an LSTM model using Keras? I am for some reason struggling to find good/helpful documentation about this online. If anyone has any links that they know actually explain it correctly, that would be much appreciated. 

Alternatively, I am looking for one more team member who knows RNNs well to join my project (in the realm of creative AI) as we get ready to launch. If youre interested, you can message me for the details.",3,14
153,2019-7-14,2019,7,14,0,ccqo7y,Log Loss for Best and Worst answer,https://www.reddit.com/r/deeplearning/comments/ccqo7y/log_loss_for_best_and_worst_answer/,AlexGuilBot,1563032277,"Say I have 5 categorical targets, one of those would be the best answer and one would be the worst. If the model doesn't choose the best, then I want to ensure at least that it doesn't choose the worst without worrying about which of the remaining 3 it chooses. 

Anyone has an idea how I should define my loss function? Some weighting I guess?",0,2
154,2019-7-14,2019,7,14,1,ccre53,How to Use Big Data Analytics to Grow Your Marketing ROI,https://www.reddit.com/r/deeplearning/comments/ccre53/how_to_use_big_data_analytics_to_grow_your/,raj11113,1563036144,,0,1
155,2019-7-14,2019,7,14,3,ccskk2,Using an LSTM-based model to predict EasyJet's stock returns (Keras tutorial),https://www.reddit.com/r/deeplearning/comments/ccskk2/using_an_lstmbased_model_to_predict_easyjets/,jdyr1729,1563042182,"Hi,

I've just written a tutorial explaining how to build an LSTM-based model that predicts the accuracy of EasyJet's stock returns with an accuracy of 55.2%. 

Thought I'd share it here for anyone who is interested:  [https://jackdry.com/using-an-lstm-based-model-to-predict-stock-returns](https://jackdry.com/using-an-lstm-based-model-to-predict-stock-returns) 

Hope you find it useful!

Jack",13,16
156,2019-7-14,2019,7,14,11,ccxl0s,How NLP Is Advancing Asset Management,https://www.reddit.com/r/deeplearning/comments/ccxl0s/how_nlp_is_advancing_asset_management/,Yuqing7,1563069897,,0,3
157,2019-7-14,2019,7,14,12,ccy61n,"[Discussion] Validation loss vs Validation accuracy, what should be given more preference while monitoring network?",https://www.reddit.com/r/deeplearning/comments/ccy61n/discussion_validation_loss_vs_validation_accuracy/,SheerHunter,1563073559,"I always prefer validation loss/accuracy over training loss/accuracy as lots of people do.

Generally I prefer to monitor validation loss as well as validation accuracy when everything is going ideally (i.e. loss going down and accuracy going up).
But at times this metrics dosent behave as they should ideally and we have to choose either one of them. Then what should be all the factors that should be considered to take a decision.

I personally inclines towards validation loss more as compared to validation accuracy. If you have multi-class Classification problem which include at least one dominating class whose Classification is eady and the network is classifying it correctly all the time, then validation accuracy will may go up but in contrast network may not learn remaining class properly.",4,3
158,2019-7-14,2019,7,14,13,ccyu30,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/ccyu30/data_science_career_track_prep_course/,HannahHumphreys,1563077882,[removed],0,1
159,2019-7-14,2019,7,14,14,cczl34,Transfer learning with YOLOv3,https://www.reddit.com/r/deeplearning/comments/cczl34/transfer_learning_with_yolov3/,kphyx,1563083311,"Hey everyone,

I'm a newbie here so excuse me if my question sounds dumb. 

Is it possible to use transfer learning with YOLOv3 if it had been pre-trained on lets say coco dataset?

Basically, what i wanna do is add a new class to the existing set of classes instead of training the network on exclusively my dataset.",2,10
160,2019-7-14,2019,7,14,20,cd21nt,Pytorch RL CPP with ALE,https://www.reddit.com/r/deeplearning/comments/cd21nt/pytorch_rl_cpp_with_ale/,Teenvan1995,1563104182,"Check out Pytorch-RL-CPP: a C++ (Libtorch) implementation of Deep Reinforcement Learning algorithms with C++ Arcade Learning Environment.

[Pytorch-RL-CPP](https://github.com/navneet-nmk/Pytorch-RL-CPP)",0,0
161,2019-7-14,2019,7,14,20,cd27wb,Breast cancer diagnosis with neural networks (implemented in python),https://www.reddit.com/r/deeplearning/comments/cd27wb/breast_cancer_diagnosis_with_neural_networks/,antaloaalonso,1563105530,,2,39
162,2019-7-14,2019,7,14,21,cd2gog,Data augmentation for 2D time series?,https://www.reddit.com/r/deeplearning/comments/cd2gog/data_augmentation_for_2d_time_series/,pk12_,1563107286,"I have time series which has two channels x and y. Can anyone please point me to data augmentation resources for such time series?

Thanks",0,0
163,2019-7-14,2019,7,14,22,cd2zgy,An Intuitive Explanation to Dropout,https://www.reddit.com/r/deeplearning/comments/cd2zgy/an_intuitive_explanation_to_dropout/,alimasri91,1563110711,,2,0
164,2019-7-14,2019,7,14,23,cd3q33,Mathematical Foundation For Machine Learning and AI,https://www.reddit.com/r/deeplearning/comments/cd3q33/mathematical_foundation_for_machine_learning_and/,HannahHumphreys,1563115202,[removed],0,1
165,2019-7-15,2019,7,15,3,cd6kqx,Object Detection of dirt piles,https://www.reddit.com/r/deeplearning/comments/cd6kqx/object_detection_of_dirt_piles/,akg2Deep,1563129984,,12,1
166,2019-7-15,2019,7,15,4,cd763m, Releasing first online 3D Point Cloud labeling tool in Supervisely,https://www.reddit.com/r/deeplearning/comments/cd763m/releasing_first_online_3d_point_cloud_labeling/,tdionis,1563132920,,1,3
167,2019-7-15,2019,7,15,4,cd76om,Deep Learning Structure Guide for Beginners,https://www.reddit.com/r/deeplearning/comments/cd76om/deep_learning_structure_guide_for_beginners/,Magniminda,1563132998," 

### 1- What is deep learning?

&amp;#x200B;

*In* its simplest form, *deep learning*, also known as *deep machine learning* or *deep structured learning*, is a subset of machine learning and refers to neural networks that have the ability to learn the input datas increasingly abstract representations. These days, implementation of deep learning techniques can be found to a great extent, from self-driving cars to academic researches.

### 2- What sets deep learning apart?

&amp;#x200B;

*If* you follow prominent job portals, you can find that theres a significant number of **deep learning professionals** job positions almost all of which are paying really well. Now, you may wonder why do companies hire these professionals? Or, what can such a professional bring to them? Lets have a look.

#### 2.1- Quality and accuracy

&amp;#x200B;

*Every* company wants quality and sometimes work produced by human employees come inferior and with errors. This is particularly true for data processing repetitive tasks. However, a worker powered by deep learning is capable of developing new understandings and producing high-quality, accurate results.

With the help of deep learning, software robots can understand spoken language, recognize more images and data, and work more efficiently. These are the main reasons why companies across the globe are hiring deep learning professionals.

#### 2.2- Increased cost and time benefit

&amp;#x200B;

*In* its simple form, neural networks can be considered as trainable brains. These networks are provided with information and trained to do tasks, and theyll use that training together with new information and their own work experience when it comes to accomplishing those tasks.

Implementation of deep learning in business can save the company a significant amount of time and money. In addition, when time-consuming or repetitive tasks are done efficiently and quickly, employees are freed up to take care of creative tasks that actually need human involvement.",0,1
168,2019-7-15,2019,7,15,5,cd7k93,"Is anyone able to access the ""Sequences, Time Series and Prediction"" deeplearning.ai course?",https://www.reddit.com/r/deeplearning/comments/cd7k93/is_anyone_able_to_access_the_sequences_time/,etmhpe,1563134889,"I am just trying to audit the course on Coursera - here is the link [https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction)

When I click ""Enroll for Free"" and click the ""Audit"" link in the popup nothing happens.  Usually it takes you to the course home after you click ""audit"".  This happening for anyone else?",1,2
169,2019-7-15,2019,7,15,5,cd7o7l,Simple annotated word2vec using Tensorflow 2 [Feedback please!],https://www.reddit.com/r/deeplearning/comments/cd7o7l/simple_annotated_word2vec_using_tensorflow_2/,richardanaya,1563135429,,4,1
170,2019-7-15,2019,7,15,6,cd8evd,Help Us Help Humanity,https://www.reddit.com/r/deeplearning/comments/cd8evd/help_us_help_humanity/,omnihaand,1563139123,"So, I'm the Manager of IT and Cloud Services for an AI startup. We're working on an OCR project to help the education system, but we're getting to the point where or models are too big to train on our dual 2080 Ti host. 

Unfortunately, RTX Titans and Cloud resources are beyond expensive. So, I'm wondering if there are any recommendations for funding or resources that I should look into?

Sorry I couldn't make this funny or nerdy enough T9 get more attention. But, feel free to giggle at our shoestring budget that left is modifying an electrical closet to house some of our hardware.

https://twitter.com/omnihaand/status/1150514745344237568?s=09

No, we don't have an UPS, yet... XD",2,1
171,2019-7-15,2019,7,15,10,cdb70m,LogReLU: A New Activation Function Inspired By ReLU,https://www.reddit.com/r/deeplearning/comments/cdb70m/logrelu_a_new_activation_function_inspired_by_relu/,multisilicon,1563154542,,2,16
172,2019-7-15,2019,7,15,13,cdd00e,Is a PhD in deep learning worth it?,https://www.reddit.com/r/deeplearning/comments/cdd00e/is_a_phd_in_deep_learning_worth_it/,james75yw,1563165642,"I am finishing up my Masters in Computer Science from a public university in the east coast. I worked mostly on VR and some computer graphics and computer vision during my Masters.

I want to get into deep learning as I find it more interesting as I started working on it very recently for a coding challenge. I have an opportunity to start a PhD at the computer engineering department at my school this fall. The lab that I would be joining have 7 students with most of them working on deep learning. The lab has a lot of titan X gpus, more importantly the school has an excellent super computer (top 10 most powerful among schools in USA). 

PhD is a big commitment and I am excited about it, also worried about it at the same time. Is it worth getting a PhD in deep learning? My focus area would be computer vision. I would really appreciate your thoughts on the worthiness of PhD.

I apologize in advance for any typos as I am typing this up on my phone while trying to sleep.",5,2
173,2019-7-15,2019,7,15,16,cdeb5s,"HP Omen 15 dc 1009tx and ROG Scar Strix 3, which laptop is better for deep learning? (Portability is an issue right now, so I can't buy desktop)",https://www.reddit.com/r/deeplearning/comments/cdeb5s/hp_omen_15_dc_1009tx_and_rog_scar_strix_3_which/,ar0752545,1563174966,,1,1
174,2019-7-15,2019,7,15,17,cdexia,Using a Machine Learning Model in a Web Application Client,https://www.reddit.com/r/deeplearning/comments/cdexia/using_a_machine_learning_model_in_a_web/,whitezl0,1563179845,,0,0
175,2019-7-15,2019,7,15,19,cdfua6,Windows or Linux?,https://www.reddit.com/r/deeplearning/comments/cdfua6/windows_or_linux/,NidoAnhsirk,1563186941,"I've just started with Machine learning and Artificial intelligence(Let's say deep learning) course. I have used Windows till this point of time, but would love to know if it's better to start learning with Linux. I've come across many articles and threads that suggest opting for a Linux environment and a few of them suggest sticking with windows as it doesn't make much difference these days(or in the near future). Can you tell me which one to go with, and also the reasons behind your choice?

&amp;#x200B;

P.S: I use an Alienware(12 GB RAM, Nvidia - 2GB VRAM, i7 processor). I'm planning to build my own PC within 6 months.",24,18
176,2019-7-15,2019,7,15,22,cdhog0,"AI-based photo restoration: defects removal, inpainting, colorization",https://www.reddit.com/r/deeplearning/comments/cdhog0/aibased_photo_restoration_defects_removal/,atomlib_com,1563198460,,1,9
177,2019-7-15,2019,7,15,23,cdi897,How to speed-up deep learning research,https://www.reddit.com/r/deeplearning/comments/cdi897/how_to_speedup_deep_learning_research/,councilanderson2,1563201383,"I am working on enhancement tasks using deep generative neural networks. I only have access to one 10 GB GPU, and I really want to speed up my research. I want to experiment with using different architectures but every single trial takes at least 3 days. I have some ideas about comparing multiple models in parallel, by as reducing the model sizes, batch size or the input size. Once I find the best performing model, I can scale things up, though I don't know if this is a good idea. What are your opinions?",4,3
178,2019-7-15,2019,7,15,23,cdii1v,Is there a legitimate (FOSS) easy-to-run program (in cli or not) for personal GPU Benchmarking on Linux ?,https://www.reddit.com/r/deeplearning/comments/cdii1v/is_there_a_legitimate_foss_easytorun_program_in/,Atralb,1563202762,,1,1
179,2019-7-16,2019,7,16,2,cdk89r,Neural Attention Usage,https://www.reddit.com/r/deeplearning/comments/cdk89r/neural_attention_usage/,reverse61,1563210753,"Hi,

&amp;#x200B;

I'm currently investigating the possible uses of neural attention. I believe it's particularly used in LSTM's and basically text-related problems.

&amp;#x200B;

My thought is the following : If I have an image labeled with the number of objects of interest inside (a scalar, then), and I'd like to be able to demonstrate that the algorithm indeed focuses on these objects, I could use a neural attention at some point, and produce both the attention-map, and the result. This wouldn't yield any (I believe) performance gain, but would make the model more human-friendly.

&amp;#x200B;

I couldn't find any paper relative to this particular use of neural attention, but I believe it must have already been done ?

&amp;#x200B;

Do you guys have any thoughts on this ?

&amp;#x200B;

Thanks a lot !",1,1
180,2019-7-16,2019,7,16,6,cdnv4b,"Trying to share my ""projects"" and to find people to work on something with",https://www.reddit.com/r/deeplearning/comments/cdnv4b/trying_to_share_my_projects_and_to_find_people_to/,mishazakharovbmx,1563226649,"Hello! I wrote a few ""projects"" I want to share with you. There is my ml-library: [https://github.com/mishazakharov/ML-library](https://github.com/mishazakharov/ML-library), my dl-library: [https://github.com/mishazakharov/DL-library](https://github.com/mishazakharov/DL-library) and image-classifier: [https://github.com/mishazakharov/ImageClassificator](https://github.com/mishazakharov/ImageClassificator).

I am kind of new to everything. Been doing this for 3-4 months(Python, ml and dl. But I had all the maths needed in my pocket). So I do not claim for high efficiency and ""quality"" of abstractions and code. Posting here just to share my projects, may be someone would like them or give me some advices I definitely need, and also I am LOOKING FOR people to do some fun dl-ml-related projects in order to boost skills and gain knowledge! I feel like my code may look for some of you as a complete garbage, I am a complete newcomer, so take it easy on me, please! Any advice or opportunity is appreciated!!!",13,21
181,2019-7-16,2019,7,16,7,cdo8wb,DL in production: an open source project for deploying your models as JSON APIs on AWS,https://www.reddit.com/r/deeplearning/comments/cdo8wb/dl_in_production_an_open_source_project_for/,ospillinger,1563228509,,0,14
182,2019-7-16,2019,7,16,14,cdsuvd,My first article on TowardsDataScience,https://www.reddit.com/r/deeplearning/comments/cdsuvd/my_first_article_on_towardsdatascience/,jager_2798,1563255037,"Finally I got to contribute to the website I learnt deep learning from. My first article on TDS explaining residual learning: https://towardsdatascience.com/a-deeper-dive-into-residual-learning-d92e0aaa8b32

Feel free to give your feedback!",4,14
183,2019-7-16,2019,7,16,20,cdvz2t,Machine Learning books suggested by top experts like Professor Bengio (U of Montreal) and Daphne Koller (Cofounder of Coursera),https://www.reddit.com/r/deeplearning/comments/cdvz2t/machine_learning_books_suggested_by_top_experts/,TJ1,1563277683,,2,41
184,2019-7-16,2019,7,16,21,cdw96x,Prior Activation Distribution (PAD): A Versatile Representation to Utilize DNN Hidden Units,https://www.reddit.com/r/deeplearning/comments/cdw96x/prior_activation_distribution_pad_a_versatile/,AskLbm,1563279314,,0,1
185,2019-7-16,2019,7,16,21,cdwgu9,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educative",https://www.reddit.com/r/deeplearning/comments/cdwgu9/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1563280550,,0,2
186,2019-7-16,2019,7,16,21,cdwjjq,[Research] Prior Activation Distribution (PAD): A Versatile Representation to Utilize DNN Hidden Units,https://www.reddit.com/r/deeplearning/comments/cdwjjq/research_prior_activation_distribution_pad_a/,AskLbm,1563281006,"Link: [https://arxiv.org/pdf/1907.02711.pdf](https://arxiv.org/pdf/1907.02711.pdf)

&amp;#x200B;

In this paper, we introduce the concept of Prior Activation Distribution (PAD) as a versatile and general technique to capture the typical activation patterns of hidden layer units of a Deep Neural Network used for classification tasks. We show  that  the  combined  neural  activations  of  such  a  hidden  layer  have  class-specific distributional properties, and then define multiple statistical measures to compute how far a test samples activations deviate from such distributions. Using a variety of benchmark datasets (including MNIST, CIFAR10, Fashion-MNIST &amp; notMNIST), we show how such PAD-based measures can be used, independent of  any  training  technique,  to  (a)  derive  fine-grained  uncertainty  estimates  for inferences; (b) provide inferencing accuracy competitive with alternatives that require execution of the full pipeline, and (c) reliably isolate out-of-distribution test samples.",0,1
187,2019-7-17,2019,7,17,1,cdyztq,Train ML Models on Free Cloud GPUs ,https://www.reddit.com/r/deeplearning/comments/cdyztq/train_ml_models_on_free_cloud_gpus/,MMFeaster,1563292978,,1,2
188,2019-7-17,2019,7,17,1,cdzqe2,Automate the diagnosis of Knee Injuries with Deep Learning part 1: an overview of the MRNet Dataset,https://www.reddit.com/r/deeplearning/comments/cdzqe2/automate_the_diagnosis_of_knee_injuries_with_deep/,ahmedbesbes,1563296269,,0,1
189,2019-7-17,2019,7,17,6,ce2zcc,ELMo from scratch in PyTorch?,https://www.reddit.com/r/deeplearning/comments/ce2zcc/elmo_from_scratch_in_pytorch/,Peyaash,1563310855,"In one of my projects I need to train ELMo embeddings.
AllenNLP has an implementation of this but I thought I'll take this opportunity to implement it from scratch.

I always wanted to develop the skill to replicate the result of research papers and experiment with them. So I think implementing this from scratch will give me a kick start. Also, I'll be able to learn a lot about PyTorch.

I already read the paper of ELMo, along with Character-Aware Neural Language Models, Highway Networks, really cool papers!

I'm pretty sure you passed the stage where I am at right now. So it would be tremendously helpful if you could share your opinion, experience and suggestions.

TIA",1,1
190,2019-7-17,2019,7,17,6,ce3bft,LSTM: How to Train a Neural Network to Write like Lovecraft,https://www.reddit.com/r/deeplearning/comments/ce3bft/lstm_how_to_train_a_neural_network_to_write_like/,strikingLoo,1563312398,,0,2
191,2019-7-17,2019,7,17,7,ce3yad,My notes for deeplearing.ai and fast.ai courses,https://www.reddit.com/r/deeplearning/comments/ce3yad/my_notes_for_deeplearingai_and_fastai_courses/,youali,1563315364,"Hello guys,

During the past months I've gone through the deeplearing.ai specialization and fast.ai courses (the two deep learning courses and machine learning course), I've take some notes that I found myself I keep coming to them from time to time. So I though I'd share them and maybe someone will find them helpful, after taking sometime to polish them and correct spelling erros here they are:

- deeplearing.ai notes: https://github.com/y-ouali/fast.ai_notes

- fastai notes:  https://github.com/y-ouali/deeplearning.ai_notes",17,104
192,2019-7-17,2019,7,17,7,ce406g,Implementation of a knee injury classifier from MRI exams using PyTorch and MRNet data,https://www.reddit.com/r/deeplearning/comments/ce406g/implementation_of_a_knee_injury_classifier_from/,ahmedbesbes,1563315605,,0,2
193,2019-7-17,2019,7,17,9,ce5ayc,What are the state of the art strategies in lifelong learning?,https://www.reddit.com/r/deeplearning/comments/ce5ayc/what_are_the_state_of_the_art_strategies_in/,GabiruAttack,1563322233,,0,1
194,2019-7-17,2019,7,17,10,ce621n,Recurrent Neural Networks: Algorithms and Applications,https://www.reddit.com/r/deeplearning/comments/ce621n/recurrent_neural_networks_algorithms_and/,DiscoverAI,1563326320,,0,2
195,2019-7-17,2019,7,17,10,ce6coq,Convolutional Neural Networks: An Intuitive Approach,https://www.reddit.com/r/deeplearning/comments/ce6coq/convolutional_neural_networks_an_intuitive/,DiscoverAI,1563327970,,0,3
196,2019-7-17,2019,7,17,13,ce7wwp,"AMA with *Francois Chollet*, the creator of *Keras*",https://www.reddit.com/r/deeplearning/comments/ce7wwp/ama_with_francois_chollet_the_creator_of_keras/,init__27,1563337087,"KaggleNoobs Community will be hosting an AMA with \*Francois Chollet\*, the creator of \*Keras\*  on 28th July, 2019 during 9 am - 10:30 am PT. 

&amp;#x200B;

To Join, use this slack invite: [https://kagglenoobs.herokuapp.com/ ](https://t.co/BVPAIBoVy7) 

OR 

Leave your questions here, I'll post them during the AMA and post the complete AMA here afterward.  Till then, Francois Chollet was kind enough to share many great pieces of advice in this interview: [https://t.co/SmkDODXlFY](https://t.co/SmkDODXlFY)",0,1
197,2019-7-17,2019,7,17,13,ce7xff,"AMA with Francois Chollet, the creator of Keras",https://www.reddit.com/r/deeplearning/comments/ce7xff/ama_with_francois_chollet_the_creator_of_keras/,init__27,1563337169,[removed],0,1
198,2019-7-17,2019,7,17,14,ce8hd8,Opinions on AMD GPU for deep learning?,https://www.reddit.com/r/deeplearning/comments/ce8hd8/opinions_on_amd_gpu_for_deep_learning/,CzoKc,1563340753,"AMD feels better value for money specs wise but sadly there are is not direct cuda support and libraries are not optimized to be run on AMD GPUs. 

Any thoughts on building a deep learning rig using exclusively AMD GPUs? 

I know is possible to do, but not sure if it will be of good value",5,1
199,2019-7-17,2019,7,17,14,ce8sap,Crater Detection with MaskRCNN,https://www.reddit.com/r/deeplearning/comments/ce8sap/crater_detection_with_maskrcnn/,yrajsm,1563342794,,1,1
200,2019-7-17,2019,7,17,15,ce97dc,Semantic segmetation in panoramic images,https://www.reddit.com/r/deeplearning/comments/ce97dc/semantic_segmetation_in_panoramic_images/,frankshawn1992,1563345700,"Hello,
Does anyone know a software for semantic segmentation in panoramic images (350 images)",0,1
201,2019-7-17,2019,7,17,16,ce9heo,Imbalanced Dataset,https://www.reddit.com/r/deeplearning/comments/ce9heo/imbalanced_dataset/,samisoomro24,1563347650,"Hello Everyone

I am doing image classification using pretrained MobileNet Model and I have dataset about 473 Images which is much less but another problem I am facing that I don't have equal number of Images in each class what should I do please suggest. Thanks",3,3
202,2019-7-17,2019,7,17,18,cear81,Neural networks that don't need to be trained,https://www.reddit.com/r/deeplearning/comments/cear81/neural_networks_that_dont_need_to_be_trained/,fgadaleta,1563357349,,0,10
203,2019-7-17,2019,7,17,21,cebywm,Hi can someone suggest me project idea for object detection?,https://www.reddit.com/r/deeplearning/comments/cebywm/hi_can_someone_suggest_me_project_idea_for_object/,bit2bit2,1563365327,,4,1
204,2019-7-17,2019,7,17,21,cece2t,Projects in Hadoop and Big Data - Learn by Building Apps,https://www.reddit.com/r/deeplearning/comments/cece2t/projects_in_hadoop_and_big_data_learn_by_building/,HannahHumphreys,1563367691,[removed],0,1
205,2019-7-17,2019,7,17,22,cecusu,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cecusu/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1563370151,[removed],0,1
206,2019-7-17,2019,7,17,23,cedlfp,[Research] Advancing Semi-supervised Learning with Unsupervised Data Augmentation,https://www.reddit.com/r/deeplearning/comments/cedlfp/research_advancing_semisupervised_learning_with/,cdossman,1563373803,"[https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-advancing-semi-supervised-learning-with-unsupervised-data-augmentation-uda-f0f3e0ff951f](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-advancing-semi-supervised-learning-with-unsupervised-data-augmentation-uda-f0f3e0ff951f) 

Abstract: In this work, we propose to apply data augmentation to unlabeled data in a semi-supervised learning setting. Our method, named Unsupervised Data Augmentation or UDA, encourages the model predictions to be consistent between an unlabeled example and an augmented unlabeled example. Unlike previous methods that use random noise such as Gaussian noise or dropout noise, UDA has a small twist in that it makes use of harder and more realistic noise generated by state-of-the-art data augmentation methods. This small twist leads to substantial improvements on six language tasks and three vision tasks even when the labeled set is extremely small.",0,2
207,2019-7-17,2019,7,17,23,cedtkp,"[P] Conditional Density Estimation Python Package and Large Benchmark with Neural Networks (MDN, KMN, Normalizing Flow) and Non-/Semi-parametric estimators",https://www.reddit.com/r/deeplearning/comments/cedtkp/p_conditional_density_estimation_python_package/,whiletrue2,1563374871,,0,2
208,2019-7-18,2019,7,18,5,ceie3p,"Lead Data Scientist: Want to become expert in Deep Learning, specifically NLP 1-2 years.",https://www.reddit.com/r/deeplearning/comments/ceie3p/lead_data_scientist_want_to_become_expert_in_deep/,damient9,1563395561,"Hey all!

I was wondering if some in the channel could provide their opinion. Since it may help with the answer I currently work as a Lead Data Scientist and have a Phd in Physics.

Our work does not usually fit within the realm of Deep Learning or neural nets in general. The only difference was some of our NLP work on browsing data. 

My goal in 2 years is to become an expert in Deep Learning. I know that is general. Areas of interest are NLP; perhaps more specifically deriving sentiment and meaning for a classification or action, and strategic. I think I may mean GAN based DL. Deep Learning centered around strategic performance such as winning in games of strategy. So creating an environment then having a algorithm discover the best way to perform based on some metric.  

By expert I mean top 5-10 % in the field. I know the areas of DL I gave are a little general but I imagine I will fine tune once I start through some recommendations. 

So with that goal what would be some advise in terms of catching up on the literature; what should I read? What order? Are their moocs or paid courses that are worth it? Should I follow a certain blog, website, content creator, or person? Really any advise you have. 

Any help is greatly appreciated and reach out if you need more specifications.",11,1
209,2019-7-18,2019,7,18,5,ceifcw,Implementation of mini batch K-means to compute anchor boxes.,https://www.reddit.com/r/deeplearning/comments/ceifcw/implementation_of_mini_batch_kmeans_to_compute/,lameass_nerd,1563395713,"I have implemented mini batch K-means to compute anchor boxes for the task of object detection. Here is the link to my repository

[https://github.com/siddharthgawas/iou-kmeans](https://github.com/siddharthgawas/iou-kmeans)

Suggestions are welcome.",0,2
210,2019-7-18,2019,7,18,7,cejxtp,"What's the ""error delta"" means in backpropagation? error delta equals Gradient derivative?",https://www.reddit.com/r/deeplearning/comments/cejxtp/whats_the_error_delta_means_in_backpropagation/,ytninja,1563402763,"I'm so confused what the ""error delta"" means in backpropagation network. 

When I hear the word ""error"", it means ""cost"". But it's not in backprop.

I'm reading Michael Nielson's book, he said , ""delta error means derivative of each neuron"".

Is error same as Gradient? so Derivative means error?

Michael Nielslon said ""partial derivative Cost function with respect to partial derivtive of each neuron is error delta""

so, ""Ratio"" is error? and we try to calculate derivative to zero?

I feel like ""error"" means ""cost""... but error is not cost? mmm???",2,2
211,2019-7-18,2019,7,18,9,cel6a5,Professional Hacker For Hire!,https://www.reddit.com/r/deeplearning/comments/cel6a5/professional_hacker_for_hire/,k3n3dy15,1563409153,"I have a Direct/Recommended source of an hacker, Contact ROBB via robbm536@gmail.com His always ready to render his services, hire him and he won't disappoint you. He can help hack into any device, social networks including- Facebook, hangouts, I messages, Twitter account, snapshot, Instagram, whatsapp, we chat, text messages., smart phones cloning, tracking emails and also any other media messenger or sites,cridit cord and transfer Do you need specialized and experienced hacking into Educational Institutions, websites, GPS coordinates tracking, surveillance footage, Grades hocking, Clearing of Criminal Records, Clear Credit Card Debts, Drop Money Into Credit Cards, Smartphone Hacksetc. Contact
 robbm536@gmail.com",1,0
212,2019-7-18,2019,7,18,10,celnq5,Implementing K-Means Clustering From Scratch: Simply Explained,https://www.reddit.com/r/deeplearning/comments/celnq5/implementing_kmeans_clustering_from_scratch/,DiscoverAI,1563411847,,4,27
213,2019-7-18,2019,7,18,15,ceonmo,https://ahmedbesbes.com/automate-the-diagnosis-of-knee-injuries-with-deep-learning-part-1-an-overview-of-the-mrnet-dataset.html,https://www.reddit.com/r/deeplearning/comments/ceonmo/httpsahmedbesbescomautomatethediagnosisofkneeinjur/,ahmedbesbes,1563430146,,1,1
214,2019-7-18,2019,7,18,16,cep3xd,How could I approach this?,https://www.reddit.com/r/deeplearning/comments/cep3xd/how_could_i_approach_this/,taudins,1563433470,"My school's chem students were administered printed surveys with 20 ""items"" (not questions, exactly) structured as follows:

                  Chemistry is

1. Boring |_1_|_2_|_3_|_4_|_5_|_6_|_7_| Exciting

2. Easy     |_1_|_2_|_3_|_4_|_5_|_6_|_7_| Hard

...........

20. Work |_1_|_2_|_3_|_4_|_5_|_6_|_7_| Play

In which they were required to circle a value in this 1-7 scale.

The bars and underscores are actually on the survey. These will be scanned in, likely as PDFs.
We already have hundreds of these as they've been collected over the past couple of years...
Needless to say, this would be excruciating to input this data by hand, so I figured as a Stats undergrad who has an interest in finally learning how to use deep learning, there should be a way to apply it here, if that's even a feasible approach to begin with.

Most of the responses are circles, but having looked through a few physical batches myself, some have been marked with x's, slashes, and some have made scratches where they had changed their answer so, some rows will have 2 marks (the scratch out and the intended response).

We had first considered preprocessing by trimming the excess paper in R, and dividing the survey into strips-- a strip for each item row and training a network to recognize a mark, and it's label would be a value 1-7.

I've been considering just using the entire main portion of the survey, a cropping of just the entire list of 20 items, and training a network to output a list of 20 values (1-7), per survey in order, from the top down. Is this even possible?",5,1
215,2019-7-18,2019,7,18,17,cepks3,Superhuman AI for multiplayer poker,https://www.reddit.com/r/deeplearning/comments/cepks3/superhuman_ai_for_multiplayer_poker/,lopespm,1563437027,,1,1
216,2019-7-18,2019,7,18,18,ceq5lp,Google AI Blog: Predicting the Generalization Gap in Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/ceq5lp/google_ai_blog_predicting_the_generalization_gap/,selfdrivingcars360,1563441598,,1,1
217,2019-7-18,2019,7,18,18,ceqgi3,"Help needed: copy mechanism, seq2seq",https://www.reddit.com/r/deeplearning/comments/ceqgi3/help_needed_copy_mechanism_seq2seq/,BalazsSzalontai,1563443878,"I thought my task to solve was simple, but after weeks of trying and searching on Google I couldn't get it working.

The task: a simple seq2seq model, where the input is a short text (some lines), and  the output is a 3-token-long text, which consist only of tokens from the input. In other words, I want to give it a text as an input, and it should give me back 3 tokens from that input as the output. 

The input text is pretty structured, since it's python source code, and the output should be three of the ""main"" variables. (meaning of ""main"" is not important here, since it's part of a bigger project)

I have found an open source github project called CopyNet, I think using that could be the solution, but I wasn't able to get that working either.

I now have a seq2seq model, where it learns from input-output pairs, but it's just guessing, and I can't see any logical predictions, even if I have it train for hours on a powerful GPU.

I have a basic understanding of seq2seq models, I am using keras and have used fast ai before. I feel really stucked, and I'd appreciate any kind of help, such as some example code where copy mechanism is used so that I can understand how it works.",4,1
218,2019-7-18,2019,7,18,19,ceqz2v,Master's study options in the EU?,https://www.reddit.com/r/deeplearning/comments/ceqz2v/masters_study_options_in_the_eu/,Slow_Breakfast,1563447458,"Hi everyone,

I'm planning to start my Master's degree, and looking for options within the EU. I'm quite interested in deep learning - particularly the theoretical aspects of neural networks, rather than just pure applications.

I'm thinking along the lines of exploring new network architectures, looking at how neural networks process information, explainability, that sort of thing (I realise this is a pretty vague explanation of what I want to do, but honestly, as long as I'm doing more than just throwing data at networks to see what sticks, I'm happy). I'm quite excited by the kind of work done at MIT's CSAIL lab (e.g., [their recent work in finding sparse networks](https://openreview.net/forum?id=rJl-b3RcF7)), DeepMind collaborations (e.g. their [curiosity-driven learning paper](https://arxiv.org/abs/1808.04355)), Hinton's recent work on capsule networks and so forth.

Quite frankly, it would be enormously cheaper for me to study within the EU than in the US or the UK, but I have been struggling to find places within the EU where this sort of work is done.  The closest I've been able to find so far is Aalto University in Finland, which offers a Master's degree in machine learning (though not deep learning specifically, as far as I can tell). Does anyone know of any places?",23,13
219,2019-7-18,2019,7,18,20,cer6pz, | AI AINOW,https://www.reddit.com/r/deeplearning/comments/cer6pz/_ai_ainow/,kailashahirwar12,1563448841,,0,0
220,2019-7-18,2019,7,18,20,ceraar,An eXtra Small transformer LM for single GPU training,https://www.reddit.com/r/deeplearning/comments/ceraar/an_extra_small_transformer_lm_for_single_gpu/,bytestorm95,1563449501,,0,2
221,2019-7-18,2019,7,18,22,cesan8,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cesan8/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1563455462,[removed],0,1
222,2019-7-18,2019,7,18,22,cesga1,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cesga1/data_science_career_track_prep_course/,HannahHumphreys,1563456290,[removed],0,1
223,2019-7-18,2019,7,18,23,cetjkk,CNN using RGB pre-trained weights on 4 channel input,https://www.reddit.com/r/deeplearning/comments/cetjkk/cnn_using_rgb_pretrained_weights_on_4_channel/,StrasJam,1563461839,"Is it possible to use a CNN's pre-trained weights on an image with 4 input bands (RGB+NIR) if the network was originally trained on RGB images?

&amp;#x200B;

Would I need to randomly initialize a set of weights for my 4th channel now?",6,3
224,2019-7-19,2019,7,19,0,ceua1w,Conversion of .pb model into .tflite model,https://www.reddit.com/r/deeplearning/comments/ceua1w/conversion_of_pb_model_into_tflite_model/,zom8ie99,1563465293,I have my model trained as .pb file. How can I convert my model into .tflite in **windows** ?,0,2
225,2019-7-19,2019,7,19,6,ceyhsc,I have downloaded a pretrained graph. I want to train it further with my own training set,https://www.reddit.com/r/deeplearning/comments/ceyhsc/i_have_downloaded_a_pretrained_graph_i_want_to/,learningeveryday111,1563485097,"* I am using faster rnn v2 solver. 
* I have cloned a captcha solver git. From there I have downloaded a trained graph which was trained on 1K captcha images. But it is not solving captchas for my own images. I have seen that it works for images similar to those in the training set. 
* I want to know if I can add further train the graph with my own train/test set. I have manually labelled 300 such images. 
* Do I have to edit the config file of the model? Or change the checkpoints? I have no clue
* I assume that my problem must have a systematic answer since it seems obvious that the makers of tensorflow would want to keep training their models with newer data. I lack the knowledge and the vocabulary to look up on the internet. 

Thank you so much ",4,0
226,2019-7-19,2019,7,19,8,cezn60,Pytorch reinforcement learning in C++,https://www.reddit.com/r/deeplearning/comments/cezn60/pytorch_reinforcement_learning_in_c/,Teenvan1995,1563490821,"Check out Pytorch-RL-CPP: a C++ (Libtorch) implementation of Deep Reinforcement Learning algorithms with C++ Arcade Learning Environment.

One of the motivations behind this project was that existing projects with c++ implementations were using hacks to get the gym to work and therefore incurring a significant overhead which kind of breaks the point of having a fast implementation. 

Some of the ideas I have is to have something like fastai but for reinforcement learning in c++. I know it's really ambitious so if anyone wants to help out, send a PR! 
Thanks!

[Pytorch-RL-CPP](https://github.com/navneet-nmk/Pytorch-RL-CPP)",2,21
227,2019-7-19,2019,7,19,9,cf0bvr,Deep Learning inference in floating-point,https://www.reddit.com/r/deeplearning/comments/cf0bvr/deep_learning_inference_in_floatingpoint/,CArchGuy,1563494579,Are there any current natural language processing (NLP) models that require floating-point computations during inference? or can all NLP models be quantized work with fixed-point computations?,0,3
228,2019-7-19,2019,7,19,12,cf2nu7,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cf2nu7/data_science_career_track_prep_course/,HannahHumphreys,1563508306,[removed],0,1
229,2019-7-19,2019,7,19,13,cf2t7g,Announcing the DeepRacer Scholarship Challenge from AWS,https://www.reddit.com/r/deeplearning/comments/cf2t7g/announcing_the_deepracer_scholarship_challenge/,ConfidentMushroom,1563509238,,1,0
230,2019-7-19,2019,7,19,18,cf5le8,Gpu price/value performance,https://www.reddit.com/r/deeplearning/comments/cf5le8/gpu_pricevalue_performance/,imperfectum,1563529866,"I just got interested in deep learning. For now I use Google colab, but I decided to buy some gpu. I'd like to ask you what gpu should I get? In my country used rtx 2070 is a little cheaper than 2060super, and 2070super is 100$ cheaper than used 2080. Used 2070 is ~180$ cheaper than 2070super. Which gpu is best for the money? Is it better to give ~300$ more for used 2080 or go with 2070/2060super?",0,2
231,2019-7-19,2019,7,19,19,cf60gp,"For me, one of the main barriers to the world of deep learning was setting up all the tools. Here's a video that I hope will eliminate this barrier. Hope you guys found it helpful!",https://www.reddit.com/r/deeplearning/comments/cf60gp/for_me_one_of_the_main_barriers_to_the_world_of/,antaloaalonso,1563533072,,4,40
232,2019-7-19,2019,7,19,19,cf60vd,I want to compete in deep learning competitions like Kaggle. Is RTX 2070 super sufficient?,https://www.reddit.com/r/deeplearning/comments/cf60vd/i_want_to_compete_in_deep_learning_competitions/,ar0752545,1563533156,"My processor is Core I9 9900K
16 GB RAM
480 GB SSD",6,1
233,2019-7-19,2019,7,19,23,cf7yn3,[Research] Predicting the Generalization Gap in Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/cf7yn3/research_predicting_the_generalization_gap_in/,cdossman,1563545127,"[https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-predicting-the-generalization-gap-in-deep-neural-networks-60d5568deb5d](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-predicting-the-generalization-gap-in-deep-neural-networks-60d5568deb5d) 

Abstract: we propose the use of a *normalized margin* distribution across network layers as a predictor of the *generalization gap*. We empirically study the relationship between the margin distribution and generalization and show that, after proper normalization of the distances, some basic statistics of the margin distributions can accurately predict the generalization gap. We also make available all the models used as a dataset for studying generalization through the github repository.",0,1
234,2019-7-20,2019,7,20,1,cf9hg0,"AshPy: TensorFlow 2.0 library for distributed training, evaluation, model selection, and fast prototyping",https://www.reddit.com/r/deeplearning/comments/cf9hg0/ashpy_tensorflow_20_library_for_distributed/,pgaleone,1563552746,,0,2
235,2019-7-20,2019,7,20,1,cf9ro2,Brambox: Object detection statistics made easy,https://www.reddit.com/r/deeplearning/comments/cf9ro2/brambox_object_detection_statistics_made_easy/,OPLinux,1563554113,,1,1
236,2019-7-20,2019,7,20,3,cfbfny,Universal function approximator of bounded range function,https://www.reddit.com/r/deeplearning/comments/cfbfny/universal_function_approximator_of_bounded_range/,ranirlol,1563561865,"Hello,

I have a question concerning the universal function approximator property. In my case, the function I want to approximate has a range over \[0,infinity). My question is, if I were to use ReLU as the output function a feedforward neural network in order to match the range of the function, would the universal function approximator theorem still apply? From Hornik (1991), the output function is linear. Any papers that tackle this problem?

Note that within my set-up, I'm constrained to use ReLU as the output function. 

Thanks a lot.",0,0
237,2019-7-20,2019,7,20,4,cfbwwu,Simulated Hardware for Training Neuromorphic Networks,https://www.reddit.com/r/deeplearning/comments/cfbwwu/simulated_hardware_for_training_neuromorphic/,IcyBaba,1563564164,Does anyone have any useful simulation software of analog neural networks or a paper describing a good model for a multi-neuron hardware setup (so I can make a reasonable fidelity simulation)? Does anyone have access to the Intel Loihi research chip?,2,2
238,2019-7-20,2019,7,20,4,cfc7wr,Legacy tensorflow mastery,https://www.reddit.com/r/deeplearning/comments/cfc7wr/legacy_tensorflow_mastery/,lokeshsonii,1563565638,"Hi, I've been using tensorflow native Keras for almost everything I do but I want be an expert in legacy tensorflow instead of Keras. I feel that's where I'll get more control over the framework itself. I'm into computer vision as of now. Can someone recommend the latest book/link/videos to learn more about legacy tensorflow. Thanks!",1,3
239,2019-7-20,2019,7,20,6,cfd55e,Buy another 1080ti or upgrade to single 2080ti (FP16)?,https://www.reddit.com/r/deeplearning/comments/cfd55e/buy_another_1080ti_or_upgrade_to_single_2080ti/,arc144,1563570238,"Hi,  I currently have a single 1080ti, which I use for deep learning  projects and kaggle competitions. I intend to upgrade my rig but I'm not  sure if I should go for another 1080ti or sell my 1080ti and buy a  2080ti. The price for both is almost the same (actually I need to buy  another psu if I go with 2 gpus, so 2x1080ti is more expensive) .

- **2x1080ti**: 
    - **Pros**: can run 2 experiments in parallel, a bit faster and more  memory 
    - **Cons**: more power consumption, need to but another psu, can't  upgrade further

- **2080ti**: 
    - **Pros**: can  train on FP16 (roughly 70% faster than a single 1080ti and almost  doubles the memory), less power consumption, easier to sell later (imo),  can buy a second one later, no need to buy a better psu right now 
    - **Cons**:  less raw memory (11 vs 22), much lower performance than 2x1080ti on  FP32, need to sell my current 1080ti (2 different gpus would be bad I  believe)

Anyone went through a similar experience and can give some advices? Thanks",15,8
240,2019-7-20,2019,7,20,8,cfenwj,Optimizing parameters for CNN autoencoder based on training and validation loss,https://www.reddit.com/r/deeplearning/comments/cfenwj/optimizing_parameters_for_cnn_autoencoder_based/,BlackHawk1001,1563577750,"Hello everybody

&amp;#x200B;

I have designed an autoencoder with a encoder and decoder consiting of 2D convolutational layers (the input are 40'000 2D images). I train the autoencoder using adam optimizer. The autoencoders has the following hyperparameters which I would like to tune (in brackets are my default values):

&amp;#x200B;

 \- Number of layers in encoder and decoder (I start with 2 in decoder and encoder)

 \- Filter size for convolutional layers (I start with 32 and 64)

 \- Convolutional kernel size (I start with 3x3)

 \- Stride size (I start with 2x2)

 \- Dropout (I start with 0.25 after each layer)

 \- Learning rate (0.001)

 \- learning\_rate\_decay (0)

 \- Latent dimension (I start with 8)

 \- Number of units in the dense layer (layer before creating latent space, I start with 16)

 \- Batch size (I start with 128)

&amp;#x200B;

One possibility would be to use just grid or random search but this is very inefficient and takes a long time with so many hyperparameters. Instead, I would like to observe the training and validation loss (using tensorboard) and adjust the parameters accordingly. For example when observing the training and validation loss there could be overfitting or underfitting (or also an increase in loss etc.).

&amp;#x200B;

Are there some general rules or hints how the hyperparameters could be adjusted based on the observed losses or based on other criterions?",0,1
241,2019-7-20,2019,7,20,12,cfh45v,OmniNet: A unified architecture for multi-modal multi-task learning,https://www.reddit.com/r/deeplearning/comments/cfh45v/omninet_a_unified_architecture_for_multimodal/,turing_1997,1563592588,,0,15
242,2019-7-20,2019,7,20,18,cfk3a3,Speed up your reading,https://www.reddit.com/r/deeplearning/comments/cfk3a3/speed_up_your_reading/,davenlin19,1563615985,"Do you want to speed up your online reading with highlighted, skimmed, scanned or summarized resources? Would you benefit from them? What if there is a service for these resources? Would you use this one to better skim, scan and understand your materials?",3,1
243,2019-7-21,2019,7,21,1,cfnkkc,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cfnkkc/data_science_career_track_prep_course/,HannahHumphreys,1563639425,[removed],0,1
244,2019-7-21,2019,7,21,1,cfnxib,is it possible to utilize nvlink for vram pooling using 2 rtx 2070 super gpus?,https://www.reddit.com/r/deeplearning/comments/cfnxib/is_it_possible_to_utilize_nvlink_for_vram_pooling/,Jsom93,1563641354,"Hello everyone one. I'm building a new pc and it will be used for gaming and deep learning. Now I'm trying to choose the best gpu for it (between 1 rtx 2080 ti and 2 rtx 2070 super).

The rtx 2080 ti comes with a 11gb vram. Whereas rtx 2070 super comes with a 8gb vram. And I've read in few places that pooling the vram using nvlink by default is not there but it is uo for developers to implement it. And there are some developers that utilized it for their games.

Now my question is: for keras and tensorflow using python, will the vrams be pooled/shared so I would have 16gb vram out of 2 rtx 2070 super or not?

Also, If it is not possible with nvlink and there is another way to achieve it please tell me. My main concern is having more than 11gb vram without buying quadro/tesla gpus",24,13
245,2019-7-21,2019,7,21,2,cfo7t1,Is Mac good choice for deep learning?,https://www.reddit.com/r/deeplearning/comments/cfo7t1/is_mac_good_choice_for_deep_learning/,testimoni,1563642869,I am new on this topic and would like to start with some practice. I have my MacBook pro. Do you think Mac is suitable for DL projects or i should go with Windows PC?,18,2
246,2019-7-21,2019,7,21,2,cfo839,Efficient Video Generation on Complex Datasets (Codes and paper in the post),https://www.reddit.com/r/deeplearning/comments/cfo839/efficient_video_generation_on_complex_datasets/,ai-lover,1563642909,"Paper: arxiv.org/abs/1907.06571

They used chainer implementation for t-gan : github.com/pfnet-research

DeepMind did it again - they created realistic videos by just watching a ton of youtube videos.",2,1
247,2019-7-21,2019,7,21,2,cfoqq2,Becoming One with the data,https://www.reddit.com/r/deeplearning/comments/cfoqq2/becoming_one_with_the_data/,pirate7777777,1563645529,,0,0
248,2019-7-21,2019,7,21,12,cfumnm,"How to make a deep fake model take into account global transformation(going far away, close etc?)",https://www.reddit.com/r/deeplearning/comments/cfumnm/how_to_make_a_deep_fake_model_take_into_account/,Isamu_Isozaki,1563679504,"# Background info

Hi. I recently got a request to build a deep fake model using [this video](https://www.youtube.com/watch?v=ETbKiHQ2tP0&amp;amp=&amp;feature=youtu.be). Thus, I separated the video into roughly 17000 frames using [this repository](https://github.com/datitran/face2face-demo) and managed to get better landmarks using [this face detection repository](https://github.com/cleardusk/3DDFA). The output picture is below

[The left is the landmarks and the right is the target image](https://i.redd.it/paa9m68dokb31.png)

After a few hours of training, I got an ok output like

&amp;#x200B;

[Output sample](https://i.redd.it/mhilpeakokb31.png)

To clarify, the goal of this project is to

1. Extract landmarks from the input image and to transform that into the blue blob on the left. (Already successful)
2. Transform the blue blob into a face. (semi-successful)

Thus after a couple of days more of training, I switched to running the deep fake.

*Processing img q83o69v4pkb31...*

*Processing img lyyu7gx4pkb31...*

*Processing img i17cw8v4pkb31...*

*Processing img 1ayolex4pkb31...*

Thus, the problems are mostly

1. The deep fake can't handle global transformation(moving far away and close to the camera)
2. The deep fake can't handle face rotation
3. The deep fake consistently causes noise

# Solutions with problems

For now, I will not include increasing data because since it's a deep fake, there is a requirement that the lighting and the location of the camera to be the same. And so I think it is quite strenuous for the user to correct say a 1-hour video of him moving around.

While I may be able to solve 3 with a denoising GAN but I think it is a bit hard for high res images, for 2 I have no idea. For 1, the three solutions I came up with were

1. Do global transformation(scaling, translating) on the input images before training.

Problem: The background will be inconsistent because I need to fill up the empty spaces with black(0 paddings) which is non-ideal. I thought of using pix2pix to fill up the black spots but usually, I see that done with rectangular cut-outs and not usually from most of the image is black. I think I'll try this approach first though.

2. Force input face size(using dlib) to be a specific size. (non-ideal)

3. Use GAN

 Problem: Hard to produce high res(from my limited experience) images and also hard to generate global transformation like being further away.

&amp;#x200B;

Anyway, those are my thoughts and I think it's fair to say that I'm pretty stuck. If anyone has any suggestions please tell me! Modern deep fakes tend to be quite impressive and I will really like for me to be able to make one like them!",4,10
249,2019-7-21,2019,7,21,17,cfwvt2,I want to build my own route navigation model like the one in Google maps. Need help!,https://www.reddit.com/r/deeplearning/comments/cfwvt2/i_want_to_build_my_own_route_navigation_model/,learningeveryday111,1563697574,"I have taken up a project at our Computer Science department where we find the most optimised route between two points, while taking traffic into account. The Google Maps API is not very helpful since it doesnt give us a lot of things to optimise (like giving preference to 8 lane highways etc). It only gives the route directly in a JSON output. 

Id love to know any tutorials, research or a book which teaches about this topic. Can someone help me out with the resources? We expect to complete this project over a year. 

Thank you!",23,19
250,2019-7-21,2019,7,21,20,cfy984,Python Data Products for Predictive Analytics,https://www.reddit.com/r/deeplearning/comments/cfy984/python_data_products_for_predictive_analytics/,HannahHumphreys,1563710322,[removed],0,1
251,2019-7-21,2019,7,21,21,cfylqx,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cfylqx/data_science_career_track_prep_course/,HannahHumphreys,1563713008,[removed],0,1
252,2019-7-22,2019,7,22,2,cg1kev,Help needed: ArcFace in Keras,https://www.reddit.com/r/deeplearning/comments/cg1kev/help_needed_arcface_in_keras/,deflaid,1563730114,"Hi,

I have a working face recognition pipeline in Keras utilizing ResNet50 as a base model. When I use provided code for ArcFace from github ([https://github.com/4uiiurz1/keras-arcface/blob/master/metrics.py](https://github.com/4uiiurz1/keras-arcface/blob/master/metrics.py), not my repo, original paper link provided below), my neural network refuse to learn anything unless a set the \`m\` hyperparameter to zero, i.e. it becomes plain old softmax dense layer. In m=0 setting I can get &gt;99% val acc on CASIA-WebFace subset. Any ideas why is it not working with m=0.35 or m=0.5? I'm really stuck with this for several days now. I though the problem might be too hard to train right away, so I pretrained my model with m=0, then freezed all base model layers and re-trained with m=0.35, but after \~20 epochs I'm converging to \~0.2 acc.

&amp;#x200B;

\[paper link\]

[https://arxiv.org/abs/1801.07698](https://arxiv.org/abs/1801.07698)

\[implementation details\]

I'm using the same base model as in the paper (ResNet50+BN+Dropout+FC+BN), 512-D embedding size, SGD with lr=0.1 with momentum=0.9 and lr schedule same as specified in paper. Data classes are upscaled, so the training data is well balanced. All images in train and dev set are transformed using similarity transformation using 5 facial landmarks provided in SphereFace official repo and resized to 112x96 RGB image.",11,3
253,2019-7-22,2019,7,22,3,cg27hv,Interview with World's First Triple Kaggle Grandmaster: Abhishek Thakur,https://www.reddit.com/r/deeplearning/comments/cg27hv/interview_with_worlds_first_triple_kaggle/,init__27,1563733381,"It's really an honor for me to kick-off The Chai Time Data Science Show with an interview with the Only Triple Grandmaster on Kaggle: 

&amp;#x200B;

Here are the links to the interview. You can find it both in audio and video (of the interview) format:

[Podcast](https://anchor.fm/chaitimedatascience/episodes/Kaggle-Triple-Grandmaster--Abhishek-Thakur-Interview-e4mjoi)

&amp;#x200B;

[Video](https://www.youtube.com/watch?v=vMtORPcjDn8&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=2)

&amp;#x200B;

I'll be releasing 1 episode every Thursday, Sunday. 

Hope you like it, If you have any ideas/comments/suggestions, I'd really love to hear them.",4,8
254,2019-7-22,2019,7,22,12,cg8apu,Cat Vs not cat model Evaluation.,https://www.reddit.com/r/deeplearning/comments/cg8apu/cat_vs_not_cat_model_evaluation/,Herosixty7,1563767748,"I was working on some problem investigating building cat image classifiers. Unfortunately, the classifier ,correctly, classifies Amanda Seyfried as non-cat picture :(

https://i.redd.it/uojn12ae2sb31.png",14,6
255,2019-7-22,2019,7,22,13,cg8gzz,A basic underrating of image embedding,https://www.reddit.com/r/deeplearning/comments/cg8gzz/a_basic_underrating_of_image_embedding/,shivam529,1563768824,"Ive read numerous Articles and sometime I feel I have it all figured out and sometimes I dont, I just wanna know if my basic understanding is right ?  Say i have any deep learning vanilla architecture to start with , barring the output layer, could I use the the last output layer as my image embedding in how much ever dimensions according to my need ?",8,5
256,2019-7-22,2019,7,22,15,cg9py7,Facebook DLRM Is A Game Changer for Recommendation Models,https://www.reddit.com/r/deeplearning/comments/cg9py7/facebook_dlrm_is_a_game_changer_for/,analyticsindiam,1563777549,,0,30
257,2019-7-22,2019,7,22,17,cgah4h,Deep Convolutional Q-Learning with Python and TensorFlow 2.0,https://www.reddit.com/r/deeplearning/comments/cgah4h/deep_convolutional_qlearning_with_python_and/,pmz,1563783486,,0,1
258,2019-7-22,2019,7,22,21,cgckyy,Gated Recurrent Unit (GRU) With PyTorch,https://www.reddit.com/r/deeplearning/comments/cgckyy/gated_recurrent_unit_gru_with_pytorch/,pirate7777777,1563798516,,0,26
259,2019-7-22,2019,7,22,22,cgcy13,A problem with training DCGANs,https://www.reddit.com/r/deeplearning/comments/cgcy13/a_problem_with_training_dcgans/,AbdulhadyFeteiha,1563800657,"I'm trying to generate paintings from Edvard Munch (a Norwegian artist) paintings data set. However, the generator doesn't develop over time! it keeps generating noise.

I claim that this happens due to the very limited data set (210 paintings, all i found).

I use a standard DCGANs architecture with 64\*64\*3 input dimensions. I tried training the model for 190, 1000 epochs with no results.

Below are samples of the output after: 4,20, and 1000 epochs. I hope that you can direct me to the mistake i'm making.

[1000 epochs](https://i.redd.it/er3newm9sub31.png)

[20 epochs](https://i.redd.it/xcgmss47sub31.png)

&amp;#x200B;

[4 epochs](https://i.redd.it/tvdwfdo9sub31.png)

Any ideas?",1,2
260,2019-7-22,2019,7,22,23,cgdmgc,How can I apply deep learning for OCR,https://www.reddit.com/r/deeplearning/comments/cgdmgc/how_can_i_apply_deep_learning_for_ocr/,addcolourtourlife,1563804342,"I need to extract text from scanned documents , eliminating headers, footers, tables etc.. extracting a structured paragraphs 

While using tesseract, able to extract text but it has all the special characters , headers, footers .. etc..

Is there anyway to apply deeplearning to extract clean paragraphs so that I can use it for text analysis?",8,10
261,2019-7-22,2019,7,22,23,cgdtgm,Where can I find a database of hand or finger images?,https://www.reddit.com/r/deeplearning/comments/cgdtgm/where_can_i_find_a_database_of_hand_or_finger/,Gameatro,1563805331,I am looking for a database of just hand or finger images. I don't want finger veins or hand gestures. I am not able to find such a database. All I got from searching on the internet is finger veins and prints or hand gestures. I need just finger images for my deep learning model. Can I get a link to an unlabelled database of that?,0,2
262,2019-7-22,2019,7,22,23,cgdzxi,[Research] A large-scale Corpus of Talk Radio Transcripts,https://www.reddit.com/r/deeplearning/comments/cgdzxi/research_a_largescale_corpus_of_talk_radio/,cdossman,1563806212,"[https://medium.com/ai%C2%B3-theory-practice-business/2-8-billion-words-of-transcribed-speech-for-social-science-and-natural-language-processing-d9857cb74c03](https://medium.com/ai%C2%B3-theory-practice-business/2-8-billion-words-of-transcribed-speech-for-social-science-and-natural-language-processing-d9857cb74c03) 

Abstract:  We introduce RadioTalk, a corpus of speech recognition transcripts sampled from talk radio broadcasts in the United States between October of 2018 and March of 2019. The corpus is intended for use by researchers in the fields of natural language processing, conversational analysis, and the social sciences. The corpus encompasses approximately 2.8 billion words of automatically transcribed speech from 284,000 hours of radio, together with metadata about the speech, such as geographical location, speaker turn boundaries, gender, and radio program information. In this paper we summarize why and how we prepared the corpus, give some descriptive statistics on stations, shows and speakers, and carry out a few high-level analyses.",2,9
263,2019-7-23,2019,7,23,0,cgejdh,A Summary of How Google Deep Learning is Essential to Understand Value of AI ML in World,https://www.reddit.com/r/deeplearning/comments/cgejdh/a_summary_of_how_google_deep_learning_is/,SunilAhujaa,1563808835,"Google Deep Learning Course is a popular segment in the AI and Data Science community. Known for its timely updates and futuristic applications, Data Scientists find all the resources in Google library very relevant to their ongoing projects in Machine Learning. For more information please visit here [https://www.analytixlabs.co.in/blog/2019/07/14/summary-google-deep-learning-essential-understand-value-ai-ml-world/](https://www.analytixlabs.co.in/blog/2019/07/14/summary-google-deep-learning-essential-understand-value-ai-ml-world/)",0,0
264,2019-7-23,2019,7,23,0,cgelk0,Is DCGAN the right method for this?,https://www.reddit.com/r/deeplearning/comments/cgelk0/is_dcgan_the_right_method_for_this/,nexxai,1563809113,"I have about 25,000 different photos of a subject (all with the same resolution of 1280x1024), and what I'd like to do is feed these into some kind of deep learning algorithm, with the intent of having it generate new photos of similar, but not real, subjects.  It would be similar to https://github.com/pearsonkyle/Artificial-Art except rather than generating animated 128x128 mini-photo/videos, I would just want to generate static, full-size photos, one at a time.  

I've got a fairly basic knowledge of deep learning and I want to learn a lot more, but I just want to make sure I'm not spinning my wheels and looking in the wrong place.",4,2
265,2019-7-23,2019,7,23,1,cgf2sx,Bernie Sanders on Jews [ Larry David Deepfake ],https://www.reddit.com/r/deeplearning/comments/cgf2sx/bernie_sanders_on_jews_larry_david_deepfake/,deepfakeblue,1563811375,,0,1
266,2019-7-23,2019,7,23,1,cgfohj,Machine Learning and Big Data Analytics with AWS,https://www.reddit.com/r/deeplearning/comments/cgfohj/machine_learning_and_big_data_analytics_with_aws/,HannahHumphreys,1563814198,[removed],0,1
267,2019-7-23,2019,7,23,8,cgknz1,How to do hyperparameter tuning with Unet in Keras?,https://www.reddit.com/r/deeplearning/comments/cgknz1/how_to_do_hyperparameter_tuning_with_unet_in_keras/,74throwaway,1563837550,"This is what I've tried so far using code from https://github.com/zhixuhao/unet:

    from model import *
    from data import *
    
    from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
    from sklearn.metrics import roc_auc_score
    import sys
    
    space = {
            'lr': hp.choice('lr', [1e-6,5e-5,1e-5,5e-4,1e-4,5e-3,1e-3]),
            'batchi': hp.choice('batchi',  [0,1]),
            'dropout1': hp.choice('dropout1', [.3,.4,.5,.6,.7]),
            'dropout2': hp.choice('dropout2',  [.3,.4,.5,.6,.7]),
            'steps_per_epoch': hp.choice('steps_per_epoch',  [5,10,20]),
            'epochs': hp.choice('epochs',  [1,2,3,4]),
            'down_activation': hp.choice('down_activation',['relu','elu']),
            'up_activation': hp.choice('up_activation',['relu','elu']),
            }
    
    def unet_batch_hyper(space,pretrained_weights = None):
        
        print(""UNET_hyperparameter test"")
    
        input_size = (256,256,1)
        inputs = Input(input_size)
        
        conv1 = Conv2D(64, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(inputs)
        if space['batchi']==1:
            conv1 = BatchNormalization()(conv1)
        conv1 = Conv2D(64, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv1)
        if space['batchi']==1:
            conv1 = BatchNormalization()(conv1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
        conv2 = Conv2D(128, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(pool1)
        if space['batchi']==1:
            conv2 = BatchNormalization()(conv2)
        conv2 = Conv2D(128, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv2)
        if space['batchi']==1:
            conv2 = BatchNormalization()(conv2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
        conv3 = Conv2D(256, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(pool2)
        if space['batchi']==1:
            conv3 = BatchNormalization()(conv3)
        conv3 = Conv2D(256, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv3)
        if space['batchi']==1:
            conv3 = BatchNormalization()(conv3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
        conv4 = Conv2D(512, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(pool3)
        if space['batchi']==1:
            conv4 = BatchNormalization()(conv4)
        conv4 = Conv2D(512, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv4)
        if space['batchi']==1:
            conv4 = BatchNormalization()(conv4)
        drop4 = Dropout(0.5)(conv4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
    
        conv5 = Conv2D(1024, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(pool4)
        if space['batchi']==1:
            conv5 = BatchNormalization()(conv5)
        conv5 = Conv2D(1024, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv5)
        if space['batchi']==1:
            conv5 = BatchNormalization()(conv5)
        drop5 = Dropout(0.5)(conv5)
    
        up6 = Conv2D(512, 2, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
        merge6 = concatenate([drop4,up6], axis = 3)
        conv6 = Conv2D(512, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(merge6)
        conv6 = Conv2D(512, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv6)
    
        up7 = Conv2D(256, 2, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
        merge7 = concatenate([conv3,up7], axis = 3)
        conv7 = Conv2D(256, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(merge7)
        conv7 = Conv2D(256, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv7)
    
        up8 = Conv2D(128, 2, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
        merge8 = concatenate([conv2,up8], axis = 3)
        conv8 = Conv2D(128, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(merge8)
        conv8 = Conv2D(128, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv8)
    
        up9 = Conv2D(64, 2, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
        merge9 = concatenate([conv1,up9], axis = 3)
        conv9 = Conv2D(64, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(merge9)
        conv9 = Conv2D(64, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv9)
        conv9 = Conv2D(2, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv9)
        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)
    
        model = Model(input = inputs, output = conv10)
    
        model.compile(optimizer = Adam(lr = space['lr']), loss = 'binary_crossentropy', metrics = [mean_iou1])#'accuracy'])
        
    
        if(pretrained_weights):
            model.load_weights(pretrained_weights)
    
        lr = space['lr']
        filepath=""weights-LR_""+str(lr)+""-S_20-E_{epoch:02d}-L_{loss:.2f}-batchN.hdf5""
        model_checkpoint = ModelCheckpoint(filepath,monitor='loss',verbose=1, save_best_only=True)
    
        return {'loss': loss1, 'status': STATUS_OK, 'model': model}
    
    trials = Trials()
    best = fmin(unet_batch_hyper, space, algo=tpe.suggest, max_evals=50, trials=trials)
    print('best: ')
    print(best)

Where I wasn't sure what to include for `loss1`. I read some tutorials online about how to use `hyperopt` in Keras, but I couldn't find anything for Unets. What I found online usually included:

    score, acc = model.evaluate(X_val, Y_val, verbose=0)
    return {'loss': -acc, 'status': STATUS_OK, 'model': model}

so instead of `model.fit_generator`, should I instead try the below?

    model.fit(X_train, y_train,     steps_per_epoch=space['steps_per_epoch'],epochs=space['epochs'], verbose = 0,callbacks=[val_call])
    score, acc = model.evaluate(X_test, Y_test, verbose=0)
    return {'loss': -acc, 'status': STATUS_OK, 'model': model}

and thus have to modify `def unet_batch_hyper(space,pretrained_weights = None):` so that it becomes this?

    def unet_batch_hyper(space,X_train, y_train, X_test, Y_test, pretrained_weights = None):",0,1
268,2019-7-23,2019,7,23,19,cgqnmn,Efficient Semantic Text Retrieval with Google's Universal Sentence Encoder and AquilaDB,https://www.reddit.com/r/deeplearning/comments/cgqnmn/efficient_semantic_text_retrieval_with_googles/,iamjbn,1563876219,,8,26
269,2019-7-23,2019,7,23,19,cgqp3b,"Question regarding ""architecture provides the family of possible distributions to sample from""",https://www.reddit.com/r/deeplearning/comments/cgqp3b/question_regarding_architecture_provides_the/,sriharsha_0806,1563876498,"Hi, 

In the Deep learning textbook of Ian Goodfellow, from Differentiable Generator Networks of  Deep Generative Models Chapter. It is mentioned, ""Where the architecture provides the family of possible distributions to sample from and the parameters select a distribution from within that family"". I thought the family of distributions is formed while the Backpropagation algorithm is training the data. But as mentioned in the sentence above the architecture itself provides a family of distributions to select from.",0,1
270,2019-7-23,2019,7,23,19,cgqpde,What is ancestral sampling?,https://www.reddit.com/r/deeplearning/comments/cgqpde/what_is_ancestral_sampling/,sriharsha_0806,1563876545,can anybody explain what is ancestral sampling?,1,3
271,2019-7-24,2019,7,24,0,cgu45l,What technologies does Andrej Karpathy use at Tesla ?,https://www.reddit.com/r/deeplearning/comments/cgu45l/what_technologies_does_andrej_karpathy_use_at/,That_Actuator,1563896005,I am looking for which OS he uses and which Frameworks etc. are used for Autopilot development ?,4,5
272,2019-7-24,2019,7,24,4,cgwysp,Can someone provide me links of some well commented ML/DL paper implementations in Github?,https://www.reddit.com/r/deeplearning/comments/cgwysp/can_someone_provide_me_links_of_some_well/,Hot_Ices,1563908946,"I was planning to read some easy and interesting ML/DL papers along with its implementation. But most of the papers' implementation are not well commented along side the codes. If you know some well commented implementations , please share.",8,22
273,2019-7-24,2019,7,24,4,cgxgql,"2019 Google Scholar Metrics Released, CVPR Cracks the Top Ten",https://www.reddit.com/r/deeplearning/comments/cgxgql/2019_google_scholar_metrics_released_cvpr_cracks/,Yuqing7,1563911246,,0,1
274,2019-7-24,2019,7,24,5,cgy0es,LSTM parameter selection for sequence classification,https://www.reddit.com/r/deeplearning/comments/cgy0es/lstm_parameter_selection_for_sequence/,pk12_,1563913774,"Is there a guidebook or papers which provide ball park parameters for number of hidden units and the number of LSTM nodes?

It seems people just use cross validation, no explainable intuition involved",2,11
275,2019-7-24,2019,7,24,17,ch5cre,Found on GitHub a blazingly fast implementation of Byte Pair Encoding (BPE) algorithm. Much faster than Google SentencePiece.,https://www.reddit.com/r/deeplearning/comments/ch5cre/found_on_github_a_blazingly_fast_implementation/,Yutkin,1563955953,,3,64
276,2019-7-24,2019,7,24,22,ch8ieh,[Research] How much real data do we actually need: Analyzing object detection performance using synthetic and real data,https://www.reddit.com/r/deeplearning/comments/ch8ieh/research_how_much_real_data_do_we_actually_need/,cdossman,1563976634,"Abstract:  In recent years, deep learning models have resulted in a huge amount of progress in various areas, including computer vision. By nature, the supervised training of deep models requires a large amount of data to be available. This ideal case is usually not tractable as the data annotation is a tremendously exhausting and costly task to perform. An alternative is to use synthetic data. In this paper, we take a comprehensive look into the effects of replacing real data with synthetic data. We further analyze the effects of having a limited amount of real data. We use multiple synthetic and real datasets along with a simulation tool to create large amounts of cheaply annotated synthetic data. We analyze the domain similarity of each of these datasets. We provide insights about designing a methodological procedure for training deep networks using these datasets 

 [https://medium.com/ai%C2%B3-theory-practice-business/how-much-real-data-do-we-actually-need-71c4e83bbd33](https://medium.com/ai%C2%B3-theory-practice-business/how-much-real-data-do-we-actually-need-71c4e83bbd33)",0,4
277,2019-7-24,2019,7,24,23,ch8oxe,Machine Learning Subreddits,https://www.reddit.com/r/deeplearning/comments/ch8oxe/machine_learning_subreddits/,antaloaalonso,1563977545,"I've noticed that on many of the ML subreddits, there is a wide variety of libraries and tools used. For the experienced programmer, this may be okay or even preferable. However, if you are like the majority of ML programmers, then this can be intimidating, confusing, and frustrating. For those of you that fall in this category, I would like to invite you to a subreddit ([r/MachineLearningKeras](https://www.reddit.com/r/MachineLearningKeras/)) that will be focused on machine learning with the Keras API. Keras is easy to use, and is a great way to implement various projects. I hope that you will join me in making such a community on Reddit.",1,8
278,2019-7-25,2019,7,25,0,ch9hy6,Are cGANs used to solve image segmentation problem ?,https://www.reddit.com/r/deeplearning/comments/ch9hy6/are_cgans_used_to_solve_image_segmentation_problem/,ReinforcementBoi,1563981473,I have not seen work where people use pix2pix or pix2pixHD to solve image segmentation problems. Why do regression setups work better in segmentation problems ?,3,3
279,2019-7-25,2019,7,25,0,ch9j23,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/ch9j23/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1563981616,[removed],0,1
280,2019-7-25,2019,7,25,1,cha2pa,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cha2pa/data_science_career_track_prep_course/,HannahHumphreys,1563984161,[removed],0,1
281,2019-7-25,2019,7,25,1,cha324,Deep Learning Book,https://www.reddit.com/r/deeplearning/comments/cha324/deep_learning_book/,HippeTeddyBear,1563984207,"I was reading the DL textbook from [here](https://www.deeplearningbook.org/contents/generative_models.html). I understand how the probability of individual elements of hidden layer h gets derived. However, I could not understand the equation (20.15), which derive the conditional distribution of hidden layer h over visible layer v. Here is a screenshot from the textbook 

[Screen Shot from the Textbook](https://i.redd.it/bzw9wb3cy9c31.png)

 I hope to get some explanation of how it is derived. Any help would be appreciated. Thank you very much!",2,9
282,2019-7-25,2019,7,25,1,cha5tg,"Is backpropagation the ""normie stuff"" of machine learning",https://www.reddit.com/r/deeplearning/comments/cha5tg/is_backpropagation_the_normie_stuff_of_machine/,DepHea,1563984540,i hardly understand this shit,7,0
283,2019-7-25,2019,7,25,1,chaf6v,Computer Vision,https://www.reddit.com/r/deeplearning/comments/chaf6v/computer_vision/,HannahHumphreys,1563985736,[removed],0,1
284,2019-7-25,2019,7,25,4,chcyop,L2 norm to find loss in deep learning,https://www.reddit.com/r/deeplearning/comments/chcyop/l2_norm_to_find_loss_in_deep_learning/,shivam529,1563997515,"For finding error between an image and output of a network we use sum of squared error , but most articles then call it L2 norm of matrix substractions of these two images which is the same thing, could someone explain how is it the same thing ?",1,5
285,2019-7-25,2019,7,25,6,che1kd,An Explanation of Self-Supervised Deep Learning,https://www.reddit.com/r/deeplearning/comments/che1kd/an_explanation_of_selfsupervised_deep_learning/,HenryAILabs,1564002536,[https://www.youtube.com/watch?v=lbKg3OSTsgA&amp;t=198s](https://www.youtube.com/watch?v=lbKg3OSTsgA&amp;t=198s),2,3
286,2019-7-25,2019,7,25,13,chj66d,Using OCR to write new documents,https://www.reddit.com/r/deeplearning/comments/chj66d/using_ocr_to_write_new_documents/,TheBrokenArt,1564030373,"I apologize if this is the wrong place for this question as I am just beginning to get involved in the deep learning space.

I couldn't find any resources for what I was looking for specifically, so I figured I'd try asking here.

I'm looking to use OCR and deep learning to feed text files (pdfs, word, etc) on a certain topic to the program and have it predict (or write) new information on the topic, based on the files its received.

Is this something that can be done? If so, how plausible is it for someone new to deep learning (not python language) to get started on a project like this?

Thanks in advance!",2,4
287,2019-7-25,2019,7,25,15,chjvhq,Neural style transfer,https://www.reddit.com/r/deeplearning/comments/chjvhq/neural_style_transfer/,shivam529,1564035146,How would you use more than one style image in case of neural transfer ?,4,2
288,2019-7-25,2019,7,25,15,chjzpu,What is the status of Capsule Network R&amp;D?,https://www.reddit.com/r/deeplearning/comments/chjzpu/what_is_the_status_of_capsule_network_rd/,rahul_roy_youtuber,1564036008,"So, I've started studying about Capsule Network for my classification project and thought about giving it a shot above my CNN implementation. But i saw that it takes about 15 to 20 mins to complete only one epoch, whereas my CNN model takes hardly 15-20 seconds. (My laptop specs: 7th gen i7, GTX 1050Ti, 16GB DDR4 RAM). And I've also noticed that it's been a while since it was introduced but it seems not many people are implementing this. What is the reason? P.S.: I didn't complete my training of the capsule network, as it was taking a really long time on my computer and didn't want to invest my time if it was not much benefitial.",4,17
289,2019-7-25,2019,7,25,16,chkfjp,Questions about Pc recommendations,https://www.reddit.com/r/deeplearning/comments/chkfjp/questions_about_pc_recommendations/,Kidneystoner04,1564039156,"Im currently a student of engineering and recently started researching deep learning more and was wondering if my laptop could do anything basic? It has a gpu with 6gb vram, 16gb of ram, and an intel 8700k Id love to hear any advice yall have.",3,2
290,2019-7-25,2019,7,25,17,chksui,Newbie Deep-Learning Machine Help: AMD ROCm vs NVIDIA CUDA,https://www.reddit.com/r/deeplearning/comments/chksui/newbie_deeplearning_machine_help_amd_rocm_vs/,RisingShogun,1564041946,"Hi! Im starting to get involved with like, the literal beginning of deep learning. Im building a machine because this is the first time I can actually build something of that magnitude + I really want to build something. My main conflict is with the type of interface I want to use. Ill leave some of the specifications Im leaning towards to give a better picture:

OS: Ubuntu Server 18.04
CPU: Ryzen 7 2700X
SSD/HDD: 2TB/6TB
PSU: EVGA P2 750W

Also some additional background info:
Im going for a Computer Science major at my college (penn state gang gang), so MATLAB is going to be used a decent ton when the time comes (in the next couple years)

The main issue is the confusion on what interface I should be using. I did want to use AMD ROCm because Im lowkey an AMD fanboy but also I really dont mind learning a whole lot of the coding language. I do know that CUDA is practically used everywhere and that is like a big bonus. My main concern with either or is being able to run MATLAB in the future when that time comes, so Im trying to go through the process as thoroughly as possible. If anyone has any misconceptions to break down or any input on which direction I should go for (especially any sources for more research), that would be a life saver!

Thanks in advance for any input! :)",7,11
291,2019-7-25,2019,7,25,20,chmijl,FITCKNN with large data sets?,https://www.reddit.com/r/deeplearning/comments/chmijl/fitcknn_with_large_data_sets/,Herosixty7,1564054564," Hello, I have some dataset with size of 39366\*9 table which I need to apply KNN regression. 

My problem arises when I use all the data set the MATLAB gives me an error message:

&amp;#x200B;

 

`Error using bsxfun`

`Requested 900000000x1 (6.7GB) array exceeds`

`maximum array size preference. Creation of arrays`

`greater than this limit may take a long time and`

`cause MATLAB to become unresponsive. See array`

`size limit or preference panel for more`

`information.`

`Error in comparison2 (line 81)`

`S1 =`

`fitcknn(array2table(X_norm),y,'NumNeighbors',K3,'Standardize',1`

&amp;#x200B;

 

I have searched this errror and found some solution suggesting using tall arays 

when I tried it this error appears

 

`Error using fitcknn (line 247)`

`FITCKNN does not support tall arrays.`

 My question is, is it possible to use fitcknn with all of this data or should I try something else? if possible how can I do that?",0,2
292,2019-7-25,2019,7,25,20,chmja1,How to implement CAM for binary classification?,https://www.reddit.com/r/deeplearning/comments/chmja1/how_to_implement_cam_for_binary_classification/,ralek673,1564054705,"Hello!

I am currently working on a personal project reimplementing this paper: [https://arxiv.org/pdf/1712.06957.pdf](https://arxiv.org/pdf/1712.06957.pdf) on PyTorch.

I used a pretrained DenseNet-169 and getting better results than the paper. I need to implement CAM now to visualize results. I found a lot of implemented CAM for DenseNet for a multiclassifier problem, but it doesn't work when with my binary classifier. I also replaced ""the final fully connected layer with one that has a single output, after which we applied a sigmoid nonlinearity"" as mentioned in the paper. 

When I get the outputs from the model, it has only one output (one class): 0 if prob &lt; 0.5, else 1.

I found this: [https://github.com/metalbubble/CAM/blob/master/pytorch\_CAM.py](https://github.com/metalbubble/CAM/blob/master/pytorch_CAM.py) but can't make it work on my model.

It bugs on the line ""cam = weight\_softmax\[idx\].dot(feature\_conv.reshape((nc, h\*w)))"" saying that np.float doesn't have dot function.

I don't know if you guys have any idea.

Thanks a lot,

Ralek",0,2
293,2019-7-25,2019,7,25,22,chnujn,[Research] A Unified Deep Framework for Joint 3D Pose Estimation and Action Recognition from a Single RGB Camera,https://www.reddit.com/r/deeplearning/comments/chnujn/research_a_unified_deep_framework_for_joint_3d/,cdossman,1564062307," **Abstract:** We present a deep learning-based multitask framework for joint 3D human pose estimation and action recognition from RGB video sequences. Our approach proceeds along two stages. In the first, we run a real-time 2D pose detector to determine the precise pixel location of important keypoints of the body. A two-stream neural network is then designed and trained to map detected 2D keypoints into 3D poses. In the second, we deploy the Efficient Neural Architecture Search (ENAS) algorithm to find an optimal network architecture that is used for modeling the spatio-temporal evolution of the estimated 3D poses via an image-based intermediate representation and performing action recognition. Experiments on Human3.6M, MSR Action3D and SBU Kinect Interaction datasets verify the effectiveness of the proposed method on the targeted tasks. Moreover, we show that our method requires a low computational budget for training and inference. 

 [https://medium.com/ai%C2%B3-theory-practice-business/a-unified-deep-framework-for-joint-3d-pose-estimation-and-action-recognition-from-a-single-rgb-45179b6fe774](https://medium.com/ai%C2%B3-theory-practice-business/a-unified-deep-framework-for-joint-3d-pose-estimation-and-action-recognition-from-a-single-rgb-45179b6fe774)",0,4
294,2019-7-26,2019,7,26,1,chpogj,Building on a low-res model,https://www.reddit.com/r/deeplearning/comments/chpogj/building_on_a_lowres_model/,ziapelta,1564070651,"I have trained a model on relatively low resolution images. I'd like to build on this work to process higher resolution images, which will probably involve widening a few layers and possibly adding a few layers. However, the overall model structure will remain the same. Is there a way to leverage the low resolution model weights to speed up training of the higher resolution model?",2,3
295,2019-7-26,2019,7,26,1,chpu3w,Opinion about research project on ASL finger spelling and it's scope,https://www.reddit.com/r/deeplearning/comments/chpu3w/opinion_about_research_project_on_asl_finger/,Denominator_Zero,1564071361,"Hi,
So I have been working on and developed a model for ASL fimger spelling (not the words, just apphabets). I have an accuracy of 80-90% and can implement it real time. The major advantage is the image processing algorithm I use which allows me to localise the hand anywhere in the frame and so I don't need a ROI box. Also the second advantage is the higher accuracy. The model combines blocks from YOLO and inception networks

So I was wondering if this work is suitable for being published as I have no experience about it. I see many videos on Reddit and online hence I'm not sure. Also if it is, is there any upcoming conference where I can submit to

Thanks",1,2
296,2019-7-26,2019,7,26,1,chqa7v,What is inverse transform sampling?,https://www.reddit.com/r/deeplearning/comments/chqa7v/what_is_inverse_transform_sampling/,sriharsha_0806,1564073465,,1,2
297,2019-7-26,2019,7,26,2,chqmjm,Winning Gold Medal on a Kaggle Competition using just kernels: Interview with Ryan Chesler,https://www.reddit.com/r/deeplearning/comments/chqmjm/winning_gold_medal_on_a_kaggle_competition_using/,init__27,1564075035,"To everyone who asks the question if free cloud resources are good enough for Kaggle Competitions, in this Interview with Kaggle Master Ryan Chesler, about his Gold Winning Solution to the Jigsaw ""Unintended Bias in Toxicity Classification"" Kaggle Competition, Ryan mentions their team did almost all of the workflow on JUST Kaggle kernels!  

Video: [https://www.youtube.com/playlist?list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1](https://www.youtube.com/playlist?list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1)

&amp;#x200B;

Podcast: [https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Master--ML-Engineer-Ryan-Chesler--Chai-Time-Data-Science-e4ntbt/a-ajj3f5](https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Master--ML-Engineer-Ryan-Chesler--Chai-Time-Data-Science-e4ntbt/a-ajj3f5)",5,37
298,2019-7-26,2019,7,26,2,chr3zx,There is a really cool tool called SEER,https://www.reddit.com/r/deeplearning/comments/chr3zx/there_is_a_really_cool_tool_called_seer/,ai-lover,1564077280,"It recently obtained real-time face-mirroring ability.  **SEER is created by Takayuki TodoLink:** http://www.takayukitodo.com/ 

&amp;#x200B;

![video](qw00eju7nhc31)",0,3
299,2019-7-26,2019,7,26,3,chrwyb,Best architecture for pixel wise segmentation,https://www.reddit.com/r/deeplearning/comments/chrwyb/best_architecture_for_pixel_wise_segmentation/,shivam529,1564081020,"I want to detect the portion of image which contains tic-tac-toe in it, so Im labeling all my images with 1 and 0 based on my tic-tac-toe and non Tic-tac-toe ROI, I want to feed this into a network and detect the ROI, I came acrosss FCN,U-net and many architectures .. what would be the best architecture provided I have ~300 images to train ?",5,3
300,2019-7-26,2019,7,26,4,chs97p,"Here is a little ""project"" i wrote in neural machine translation field.",https://www.reddit.com/r/deeplearning/comments/chs97p/here_is_a_little_project_i_wrote_in_neural/,mishazakharovbmx,1564082624,"Here is a little translation application that can translate from english to russian - [https://github.com/mishazakharov/NMT](https://github.com/mishazakharov/NMT)

Don't go super-hard on me. I am doing this ml-dl related stuff only for 4 months to be honest, so I am kind of nooby at everything. Also looking for guys that can help me with creating suuuupersimple GUI to ""finish"" a bunch of ""projects"" I have and for this one as well.(Really need you guys, contact with me if you are interested to participate). 

Doing this post just to get some feedbacks on a code i wrote and find ""necessary"" GUI people.",0,0
301,2019-7-26,2019,7,26,4,chsfmy,"Frugal student thinking of building my own rig; I keep seeing that GTX1060 6gb has the most value, but how much of this is hype? I see it everywhere, and maybe I'm looking for any counter arguments.",https://www.reddit.com/r/deeplearning/comments/chsfmy/frugal_student_thinking_of_building_my_own_rig_i/,LANGARTANDCULTURE,1564083493,"Any recommendation for the other parts of the computer, barebone is fine, I don't need anything fancy, I just want the biggest bang for my not so many bucks.   


Thanks!",17,5
302,2019-7-26,2019,7,26,5,cht2zr,Multi-Task Self-Supervised Learning: The future of Computer Vision?,https://www.reddit.com/r/deeplearning/comments/cht2zr/multitask_selfsupervised_learning_the_future_of/,HenryAILabs,1564086590,[https://youtu.be/ODG60cYK7aU](https://youtu.be/ODG60cYK7aU),0,6
303,2019-7-26,2019,7,26,6,chtlqc,Environmental Projects,https://www.reddit.com/r/deeplearning/comments/chtlqc/environmental_projects/,cvantass,1564089049,Does anyone know of any interesting projects out there that are helping to address climate change or other environmental issues? Curious to learn more about what AI can do for the environment.,2,11
304,2019-7-26,2019,7,26,9,chvlbh,Google Colab RAM increase,https://www.reddit.com/r/deeplearning/comments/chvlbh/google_colab_ram_increase/,nulleq,1564099483,"It looks like Colab is beginning to allocate users 24GB worth of RAM instead of the default of 12. Is anyone else seeing this? This morning I tried running my model, and a messaged popped up saying to ""reset runtime to get more ram"" after my session crashed [1]. There also seems to be new UI upgrades?

[1] https://imgur.com/a/n8bUNhu",7,32
305,2019-7-26,2019,7,26,13,chya6a,Cutting Edge Deep Learning for Coders online course video lectures by Prof. Jeremy Howard,https://www.reddit.com/r/deeplearning/comments/chya6a/cutting_edge_deep_learning_for_coders_online/,freevideolectures,1564115411,,0,1
306,2019-7-26,2019,7,26,13,chye04,Are convnets translation invariant?,https://www.reddit.com/r/deeplearning/comments/chye04/are_convnets_translation_invariant/,kjarvind,1564116121,"If conv nets are considered to be translation invariant, how can they predict bonding boxes?",2,1
307,2019-7-26,2019,7,26,17,ci04f6,Face recognition with small dataset - image augmentation,https://www.reddit.com/r/deeplearning/comments/ci04f6/face_recognition_with_small_dataset_image/,marok94,1564128807,"So I need to perform face recognition with 7 person, where I have around 20 images for each person in dataset.

For face recognition, I oriented myself on Adrian Rosenbrock [post](https://www.pyimagesearch.com/2018/09/24/opencv-face-recognition/). I added face alignment step because from experiments I found that alignment step greatly improves accuracy when there are more than 2 (or 3) personas in dataset. 

But to achieve even better accuracy I want to do offline image augmentation. Why offline? Because I use pretrained face detection model and pretrained face embedding model, so only model that I train is final classifer (SVM, RandomForest...). For augmentation I use great library [imgaug](https://github.com/aleju/imgaug). I'll apply rotation, adding noise, cropping... All augmenters have random component in them that randomly decides proportion of augmentation (by how many degrees perform rotation and in which side, what amount of noise to add...)  


What I would like to know is this? Is it preferable to apply each transformation separately (so I'll have n times bigger dataset, where n is number of augmenters) or all of them in sequence ( so I'll have 2x times bigger dataset, or if I apply n different sequences n times bigger dataset). I'm afraid that I some sort of bias if I have 20 normal images, 20 rotated images, 20 noised images...",0,1
308,2019-7-26,2019,7,26,19,ci1er6,DeepSORT: Deep Learning to Track Custom Objects in a Video,https://www.reddit.com/r/deeplearning/comments/ci1er6/deepsort_deep_learning_to_track_custom_objects_in/,manneshiva,1564138704,"Object Detection has seen several recent developments and reached a wide audience but a very important and not widely known extension of the OD is its applications in Object Tracking.

Here is the blog about the theory and challenges in object tracking, how to use pre-trained object detection models to identify and count unique objects and track their trajectories over several frames using the #DeepSORT algorithm! - [https://nanonets.com/blog/object-tracking-deepsort/](https://nanonets.com/blog/object-tracking-deepsort/)

&amp;#x200B;

&amp;#x200B;

[Object tracking using deep learning](https://i.redd.it/fx5fa9jtpmc31.gif)",2,49
309,2019-7-26,2019,7,26,21,ci1ziv,Blog post: The Evolution of Deeplab for Semantic Segmentation,https://www.reddit.com/r/deeplearning/comments/ci1ziv/blog_post_the_evolution_of_deeplab_for_semantic/,beerensahu,1564142537,"The semantic segmentation is the technique of segmenting image with understanding of image in pixel level. The Deeplab from Google is one of the SOTA method for semantic segmentation using deep learning. In this post I have discussed the evolution of Deeplab, beginning from the classical image segmentation techniques through Deep-learning methods to various versions of the Deeplab for semantic segmentation.

Link: [https://towardsdatascience.com/the-evolution-of-deeplab-for-semantic-segmentation-95082b025571](https://towardsdatascience.com/the-evolution-of-deeplab-for-semantic-segmentation-95082b025571)",0,2
310,2019-7-26,2019,7,26,22,ci2n9k,"GitHub - gnes-ai/gnes: GNES is Generic Neural Elastic Search, a cloud-native semantic search system based on deep neural network.",https://www.reddit.com/r/deeplearning/comments/ci2n9k/github_gnesaignes_gnes_is_generic_neural_elastic/,h_xiao,1564146455,,0,4
311,2019-7-26,2019,7,26,23,ci3eu0,[Research] What does it mean to understand a neural network?,https://www.reddit.com/r/deeplearning/comments/ci3eu0/research_what_does_it_mean_to_understand_a_neural/,cdossman,1564150604,"ABSTRACT:  We can define a neural network that can learn to recognize objects in less than 100 lines of code. However, after training, it is characterized by millions of weights that contain the knowledge about many object types across visual scenes. Such networks are thus dramatically easier to understand in terms of the code that makes them than the resulting properties, such as tuning or connections. In analogy, we conjecture that rules for development and learning in brains may be far easier to understand than their resulting properties. The analogy suggests that neuroscience would benefit from a focus on learning and development. 

 [https://medium.com/ai%C2%B3-theory-practice-business/what-does-it-mean-to-understand-a-neural-network-31fec6b1a4fe](https://medium.com/ai%C2%B3-theory-practice-business/what-does-it-mean-to-understand-a-neural-network-31fec6b1a4fe)",0,1
312,2019-7-27,2019,7,27,1,ci507z,Is Inverse reinforcement learning the future of RL ?,https://www.reddit.com/r/deeplearning/comments/ci507z/is_inverse_reinforcement_learning_the_future_of_rl/,MohamedRashad,1564158291,For some time i was thinking that imitation + reinforcement learning will be the solution for the whole RL problem and when i started reading about IRL i found it the best fusion of the two because it learns the reward function from imitation and keeps the agent interacting with the world as normal but i wanted to hear your thoughts about this .... what do you think of IRL ?,0,7
313,2019-7-27,2019,7,27,16,cieqfk,Inception Score in GAN text to image synthesis,https://www.reddit.com/r/deeplearning/comments/cieqfk/inception_score_in_gan_text_to_image_synthesis/,Bishwa12,1564213324,This is the kernel that I have been following [https://www.kaggle.com/bishwa/text-to-image2](https://www.kaggle.com/bishwa/text-to-image2/edit) . My question is how do we calculate Inception Score ? Do we need to save the images generated by generator during training and calculate the inception score on those images ?,2,8
314,2019-7-27,2019,7,27,17,cif0hw,PyTorch Tutorial - Deep Learning Using PyTorch - Learn PyTorch from Basics to Advanced,https://www.reddit.com/r/deeplearning/comments/cif0hw/pytorch_tutorial_deep_learning_using_pytorch/,Corey890,1564215574,[removed],0,1
315,2019-7-27,2019,7,27,17,cif67m,Looking for a simple Deep learning program that predicts a value,https://www.reddit.com/r/deeplearning/comments/cif67m/looking_for_a_simple_deep_learning_program_that/,phadeb,1564216881,"Is there a simple deep learning program that can take as input a text file with 2 columns : time, value and generate as output a text file where it predicts values for the next 3 time periods ?

Input Sample :

    Time;Value
    1;100
    2;120
    3;90

Output sample

    Time;Value
    4;87
    5;111
    6;129

Trained forever until instructed to stop, showing loss value while training.

Bonus : Can continue training from a previous model

Loss value = how big the gap between the past value and the predicted value",2,1
316,2019-7-27,2019,7,27,19,cig5ub,"ACL2019 paper code ""Simple and Effective Text Matching with Richer Alignment Features""",https://www.reddit.com/r/deeplearning/comments/cig5ub/acl2019_paper_code_simple_and_effective_text/,rqyang,1564224973,,0,2
317,2019-7-28,2019,7,28,4,cilgab,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cilgab/data_science_career_track_prep_course/,HannahHumphreys,1564254054,[removed],0,1
318,2019-7-28,2019,7,28,4,ciloec,DL Project Advice,https://www.reddit.com/r/deeplearning/comments/ciloec/dl_project_advice/,tbonelor,1564255112,"Hi everyone! I am currently working on a deep learning project and I am at a point where I haven't made much progress in a while. Any advice or links to resources would be appreciated.

 So the idea is,  given video footage of a soccer player running up to take a penalty kick, I would want the AI to be able to predict which side of the goal the player is going to shoot, as the player is about to kick the ball (not including lower or upper 90s of the goal, only caring about left or ride side to simplify the problem). As far as the data is concerned, I am using video footage data from SoccerNet ( [https://soccer-net.org/](https://soccer-net.org/)  here is the link if anyone wants to check it out), and wrote a script to edit the games to save clips of the game a minute before the official time of the goal, to record the run-up and the shot. The script also makes a copy of that same clip but flipped on the x-axis to create an even distribution of left-footed and right-footed penalties.

That's as far as I've gotten. The best idea that I could come up with is breaking the model into 2 parts: the 1st would be a model that can attempt to generate a Kalman filter based on the movement of the player taking the penalty, and then feeding that trajectory to a neural network to learn to predict either left or right. 

Besides that guess, I have no clue how to approach this problem. To let you know about my experience, I have done a couple of machine learning projects, and took Andrew- Ngs Deep Learning Specialization, which kind of held your hand when working on the Jupiter notebook assignments. I am also not sure about how to label the data as well, or if I am just overcomplicating this project. 

&amp;#x200B;

Thanks in advance or any guidance!",12,20
319,2019-7-28,2019,7,28,6,cin0hm,"Ideas for Deep Learning Systems in July 2019. Packages, Construction/Architecture, and Real Estate.",https://www.reddit.com/r/deeplearning/comments/cin0hm/ideas_for_deep_learning_systems_in_july_2019/,diffgram-anthony,1564261856,,0,2
320,2019-7-28,2019,7,28,11,ciqh1h,What's the hardest thing about training DL models?,https://www.reddit.com/r/deeplearning/comments/ciqh1h/whats_the_hardest_thing_about_training_dl_models/,benur7,1564281001,"Hey guys, what's the hardest thing about training deep learning models? I am trying to conduct market research to discover problems and pains. Any help will be greatly appreciated!",3,0
321,2019-7-28,2019,7,28,14,cirvsc,Transfer learning for tic tac toe segmentation,https://www.reddit.com/r/deeplearning/comments/cirvsc/transfer_learning_for_tic_tac_toe_segmentation/,shivam529,1564290150,"Ive seen cases where people have to segment cars and they use resent architecture for transfer learning and then go ahead with segmentation tasks with say U-net, this sounds plausible to me since the Resnet pretrained model is already good at detecting cars as it has been trained on it. 

Now my question is it, to detect my tic tac toe wouldnt it be wrong to detect it from a pretrained model since it has never been trained on tic tac toe? Or I could you some layer of Resnet which is good at finding vertical and horizontal lines which is what my tic tac toe grid would exist of? So say, 3rd or 4th layer which is good at detecting these lines and hence my tic tac toe and then go ahead with segmenting ? Would this be a transfer learning approach or have I got it wrong ?",2,7
322,2019-7-28,2019,7,28,14,cis95u,DL hardware advice,https://www.reddit.com/r/deeplearning/comments/cis95u/dl_hardware_advice/,AusBarbell,1564292806,"Hi All,
I've looking to get some advice on the hardware required for a CNN training saliency detection models using commonly used data sets such as ECSSD, DUT-OMROM, ect. 
My PC specs are as follows:
* CPU: i5 6600k @ 4.5GHz
* RAM: 16Gb DDR4 3000Mhz
* GPU: GTX 1080 TI 11Gb
My main concern is the CPU and RAM, will these be sufficient?",2,3
323,2019-7-28,2019,7,28,17,citmlv,"Relation Extraction from entities [NLP , LSTM, PyTorch]",https://www.reddit.com/r/deeplearning/comments/citmlv/relation_extraction_from_entities_nlp_lstm_pytorch/,ai_badger,1564303915,"Hi everyone!  

I am working on relation extraction from text data.  

Say, that I have a sentence made of 100 words. This sentence has 4 words as entities (identified through some NER algorithm). The 4 words/entities are - **A, B, C, D**. The relation between **(A, B)** is **X**. The relation between **C, D** is Y.   

So, the triplets are - **(A, X, B)** and **(C, Y, D)**. I don't understand how to formulate the input and output from the model.   


One option is to simply use a classifier like SVM or logistic regression who's input would be A and B. The output would be X. I will do this for all the sentences. But this obviously would not give me correct results because there is some context in the sentence that assigns the relationship between the 2 entities. So, we'll need something like RNN-LSTM to factor that into account. So, now, how would I feed input data to this model? Do I feed the whole sentence? What would the output look like to calculate loss?  

I am just very confused by this. Pls halp.",7,12
324,2019-7-28,2019,7,28,18,citzb6,how to set up an EC2 instance on AWS for training a model on tensorflow for personal use?,https://www.reddit.com/r/deeplearning/comments/citzb6/how_to_set_up_an_ec2_instance_on_aws_for_training/,PreviousGarlics,1564306886,"I have built a couple of scripts that solves a captcha using tensorflow's Object Identification API for a project at college. I have labelled 1K captchas for training(800) and testing(200). Since I am working on a macbook, I don't have a gpu (and thus CUDA).

To test the scripts and the predictions, I ran the program for 10 images+labels for testing and 10 images+labels for training. The training went on for 10 hrs for around 5K steps, only on CPU. Clearly I need some GPU functionality and my institute can compensate me for AWS's charges. I went through some websites for a tutorial on setting up a virtual machine etc but everything looks so complicated and I am not able to find anything that does what I would want to do:

1. I want to run the exact same scripts that I have on my laptop on an AWS instance which has a gpu(maybe p2.xlarge). I have the following files that are needed for training:  


* faster\_rcnn\_inception\_v2\_coco.config
* the label map ie labelmap.pbtxt
* test folder with all the images
* train folder with all the images
* test\_label.csv which has all the labels for each image in the test folder
* train\_label.csv which has all the labels for each image in the train folder
* record files ie. test.record, train.record

I want to create the frozen\_inferene\_graph.pb file and download it. I will then use this graph in another script that just solves the captchas.

I do know that I can create an EC2 instance such as p2.xlarge and maybe run a jupyter notebook on that server, but I don't know how do I move all these files there, run scripts and how to download the forzen\_inference\_graph.pb file.

I believe there must be a standard solution to this problem since it seems too trivial to not have been resolved in 2019. But I am not able to find a suitable or straightforward solution in the ocean of Google search results. Any help help would be deeply appreciated! Thanks!

([I had originally posted this on SuperUser Stack Exchange](https://superuser.com/questions/1464933/how-to-set-up-an-ec2-instance-on-aws-for-training-a-model-on-tensorflow-for-pers))",5,1
325,2019-7-28,2019,7,28,20,ciuxbb,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/ciuxbb/data_science_career_track_prep_course/,HannahHumphreys,1564314499,[removed],0,1
326,2019-7-28,2019,7,28,22,civu6r,Fine Tuning OpenAI's GPT-2 to Generate Jeopardy Questions,https://www.reddit.com/r/deeplearning/comments/civu6r/fine_tuning_openais_gpt2_to_generate_jeopardy/,Automato-YT,1564320669,,0,1
327,2019-7-28,2019,7,28,22,civx9c,Deep Learning vs. Machine Learning: elegir el mejor enfoque,https://www.reddit.com/r/deeplearning/comments/civx9c/deep_learning_vs_machine_learning_elegir_el_mejor/,emanuelpeg,1564321184,,0,0
328,2019-7-29,2019,7,29,2,ciyrb1,"Getting Hired in ML, Building a Portfolio | Interview with the CEO of SharpestMinds (ycombinator W'18): Edouard Harris",https://www.reddit.com/r/deeplearning/comments/ciyrb1/getting_hired_in_ml_building_a_portfolio/,init__27,1564335457,"A chat about SharpestMinds, their ycombinator experience, and especially a great discussion about building a Machine Learning Portfolio and all things about getting hired that I enjoyed a lot.

&amp;#x200B;

Audio: [https://anchor.fm/chaitimedatascience/episodes/Interview-with-CEO-of-SharpestMinds--Edouard-Harris--Chai-Time-Data-Science-e4nti6](https://anchor.fm/chaitimedatascience/episodes/Interview-with-CEO-of-SharpestMinds--Edouard-Harris--Chai-Time-Data-Science-e4nti6)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=2-ejeSFCJJc&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=4](https://www.youtube.com/watch?v=2-ejeSFCJJc&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=4)",0,2
329,2019-7-29,2019,7,29,3,ciznct,What is Deep Tech? And How Relevant Will it Be?,https://www.reddit.com/r/deeplearning/comments/ciznct/what_is_deep_tech_and_how_relevant_will_it_be/,BlockDelta,1564339646,,0,0
330,2019-7-29,2019,7,29,6,cj1ff2,"Suggestions wanted on applying Deep Learning for graphics detection/ recognition from newspaper, magazine, etc.",https://www.reddit.com/r/deeplearning/comments/cj1ff2/suggestions_wanted_on_applying_deep_learning_for/,nirmanlongjam,1564347976,"I am starting a research project on graphics detection/recognition for text-graphics separation from document with complex layout e.g. newspaper, magazine, etc. using Deep Learning.

I am pretty new to Deep Learning. 

Can anyone give suggestions/ pointers to start with the project ?",5,11
331,2019-7-29,2019,7,29,15,cj7e3o,AI and deep learning to tackle traffic congestion,https://www.reddit.com/r/deeplearning/comments/cj7e3o/ai_and_deep_learning_to_tackle_traffic_congestion/,Verma_RJ,1564381502,,0,1
332,2019-7-29,2019,7,29,17,cj8n0g,Sources on Bayesian Deep Learning?,https://www.reddit.com/r/deeplearning/comments/cj8n0g/sources_on_bayesian_deep_learning/,robwoof,1564390642,"Hi everyone. I'm currently trying to get a better picture of Bayesian Deep Learning. We looked at the topic only briefly this year, especially regarding [modelling uncertainty](https://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision) in Computer Vision tasks.
Can you recommend any paper or manual about the basics of Bayesian Neural Nets? Something that covers the standards (if there are any) of Backprop by Bayes, and anything that is important for the topic. Papers on the application of Bayesian Deep Learning are also welcome, since I'd like to reproduce the results of at least one paper in learning about this.
Thank you!",6,28
333,2019-7-29,2019,7,29,20,cj9xmr,Deep Learning Research Group,https://www.reddit.com/r/deeplearning/comments/cj9xmr/deep_learning_research_group/,bikanation,1564399386,"I am looking for a Researching group focusing on deep learning (nlp with deep learning specially) to advance my researching skills because i am not achieving much researching alone. This is my github repo . I am really passionate about researching and continuing in the academic field but want to build strong research portifolio. Also if there is a group contributing to open source project would be great. ( I am not looking for any kinds of payments or money , i want to improve my skills not earn money from research and i can consider it as an unpaid internship)",0,0
334,2019-7-29,2019,7,29,21,cjav7k,Question: is batch classification of N images faster than classifying N images one at a time?,https://www.reddit.com/r/deeplearning/comments/cjav7k/question_is_batch_classification_of_n_images/,Niffler8009,1564404864,"Cant seem to find any info on this. Basically which is faster, classifying a batch of N images or classifying N single image batches?",8,1
335,2019-7-29,2019,7,29,22,cjb8zz,Speech2Face: Infering a face behind a voice,https://www.reddit.com/r/deeplearning/comments/cjb8zz/speech2face_infering_a_face_behind_a_voice/,saintvinasse,1564406916,,0,0
336,2019-7-29,2019,7,29,23,cjc7z6,[Research] Google AI: Learning Better Simulation Methods for Partial Differential Equations,https://www.reddit.com/r/deeplearning/comments/cjc7z6/research_google_ai_learning_better_simulation/,cdossman,1564411705," The worlds fastest supercomputers were designed for modeling physical phenomena, yet they still are not fast enough to robustly predict the impacts of climate change to design controls for airplanes based on airflow or to accurately simulate a fusion reactor. All of these phenomena are modeled by partial differential equations (PDEs), the class of equations that describe everything smooth and continuous in the physical world, and the most common class of simulation problems in science and engineering. To solve these equations, we need faster simulations, but in recent years, Moores law has been slowing.  At the same time, weve seen huge breakthroughs in machine learning (ML) along with faster hardware optimized for it. What does this new paradigm offer for scientific computing?   [https://medium.com/ai%C2%B3-theory-practice-business/google-ai-learning-better-simulation-methods-for-partial-differential-equations-db67a74506d2](https://medium.com/ai%C2%B3-theory-practice-business/google-ai-learning-better-simulation-methods-for-partial-differential-equations-db67a74506d2)",2,9
337,2019-7-30,2019,7,30,0,cjckfr,The Promise of Deep Learning on Graphs,https://www.reddit.com/r/deeplearning/comments/cjckfr/the_promise_of_deep_learning_on_graphs/,BillyPricePgh,1564413232,,1,5
338,2019-7-30,2019,7,30,0,cjcpvn,How to optimize hyperparameters in stacked model?,https://www.reddit.com/r/deeplearning/comments/cjcpvn/how_to_optimize_hyperparameters_in_stacked_model/,jdyr1729,1564413916,"Hi,

I was wondering whether somebody could explain how to optimize hyperparameters for the base learners and meta algorithm when stacking? In many tutorials they seem to be plucked out of thin air!

Thanks,

Jack",0,2
339,2019-7-30,2019,7,30,1,cjdmsx,[Question] Multi-Label Tagging for Images. Why my approach should or shouldn't work.,https://www.reddit.com/r/deeplearning/comments/cjdmsx/question_multilabel_tagging_for_images_why_my/,macromayhem,1564417971,"Hi, I am trying to train a network (MobilenetV2+FC+2output units) for predicting whether an image contains particular tags or not. Tags being: Jacket, Jeans. The output loss is binary cross entropy for each tag. 

&amp;#x200B;

The sample space of possible tag assignments is {(Jeans\[Y\], Jacket\[Y\]:1000), (Jeans\[Y\], Jacket\[X\]:1000), (Jeans\[X\], Jacket\[Y\]:100), (Jeans\[X\], Jacket\[X\]:1000)} along with the number of sample images to train on. Let's say the training images are cropped and contain a person and are of the size 128x64. 

I tried to train it first as a 4 class classification problem. The F1 score is acceptable for all classes except the one with less samples.

&amp;#x200B;

I found out that the number of Jackets\[Y\], Jackets\[X\], Jeans\[Y\] and Jeans\[N\] are roughly the same. I switched the problem from classification to tagging where I modify the training to be independent of input size(hence, batch size fixed at 1). While training now I randomly input either complete image, just the jacket(or upperbody) or the Jeans(lower-body) to the tagging network. 

&amp;#x200B;

This network doesn't learn anything. I tried it with different learning rates but the loss doesn't improve after 1st epoch. 

I have a strong feeling that the network shouldn't work either but I am not able to lay a concrete reason as to why. Any suggestion/help would be appreciated.",0,1
340,2019-7-30,2019,7,30,3,cjfmql,Using endcoded features instead of dataset to train GANs,https://www.reddit.com/r/deeplearning/comments/cjfmql/using_endcoded_features_instead_of_dataset_to/,clean_pegasus,1564426583,Is there are type of GAN that uses encoded features to train the data instead of the complete dataset?,0,1
341,2019-7-30,2019,7,30,5,cjgtqy,Possible to use binary labeled images as training and grayscale images as test for Unet semantic segmentation?,https://www.reddit.com/r/deeplearning/comments/cjgtqy/possible_to_use_binary_labeled_images_as_training/,74throwaway,1564431721,"I'm attempting to perform semantic segmentation using Unet using code from here: https://github.com/zhixuhao/unet

I have a set of grayscale images and their labeled images as binary images. I was wondering if instead of using the grayscale images as the training and the binary labeled images as the test, if it was possible to do the reverse? That is, use the grayscale as test and binary as training. Is this possible and/or not a bad idea?

If it's not a bad idea, how should I go about it? 

I tried the code at: https://pastebin.com/xCaV57Bg, https://pastebin.com/19yxpBE8, https://pastebin.com/RLMFTnQ4

But when I tried it, I got the error saying:

    Error when checking input: expected input_1 to have shape (1024,1024,257) but got array with shape (1024,1024,1)

The error seems to occur at `model.fit_generator(myGene,steps_per_epoch=20,epochs=500,callbacks=[model_checkpoint])` in `run.py`. How can I fix this?",2,1
342,2019-7-30,2019,7,30,6,cjhk5r,"[PSA] ""Deep Learning Cookbook"" on the Machine Learning book bundle ($1)",https://www.reddit.com/r/deeplearning/comments/cjhk5r/psa_deep_learning_cookbook_on_the_machine/,wazuddin,1564434925,,2,14
343,2019-7-30,2019,7,30,13,cjmuf3,Solving the Armadillo Problem - A great short talk about Adversarial Learning,https://www.reddit.com/r/deeplearning/comments/cjmuf3/solving_the_armadillo_problem_a_great_short_talk/,YaelMt,1564462177,,3,20
344,2019-7-30,2019,7,30,15,cjnn40,Multiview 3D reconstruction,https://www.reddit.com/r/deeplearning/comments/cjnn40/multiview_3d_reconstruction/,frankshawn1992,1564467235,"Hi,
Can anyone suggest paper or software which does 3D reconstruction (with texture) of an object from multiple images ?",3,7
345,2019-7-30,2019,7,30,17,cjoxb6,Deep Learning vs Neural Networks,https://www.reddit.com/r/deeplearning/comments/cjoxb6/deep_learning_vs_neural_networks/,OnlineITGuru1,1564476119,,0,1
346,2019-7-30,2019,7,30,18,cjp5ut,How could i fuse multi-dimensional visual feature..?,https://www.reddit.com/r/deeplearning/comments/cjp5ut/how_could_i_fuse_multidimensional_visual_feature/,GW_KIM,1564477869,"Hi there, i am a student studying computer vision.

And i wonder how can i fuse multi-dimensional visual feature.

In object detection, regions(object may exists) show different bbox size; visual feature dimension.

and i want to fuse some feature(before classifer&amp;regressor) from other feature that may shows different dimension.

If the detector is Faster-RCNN, there is ROI-pooling to fix the dimension along all object in a image, but others not.

Is there anyone who give some hint to me about it?

THX :)",0,2
347,2019-7-30,2019,7,30,21,cjqr4k,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cjqr4k/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1564488078,[removed],0,1
348,2019-7-30,2019,7,30,21,cjqwu2,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cjqwu2/data_science_career_track_prep_course/,HannahHumphreys,1564488930,[removed],0,1
349,2019-7-30,2019,7,30,22,cjrw2a,Image preprocessing before applying CNN architectures,https://www.reddit.com/r/deeplearning/comments/cjrw2a/image_preprocessing_before_applying_cnn/,sambalshikhar,1564493899,What are some preprocessing hacks that you have come across which provided better results and why do they work?,7,4
350,2019-7-30,2019,7,30,23,cjsspl,[Research] Deep Learning for Short-Segment Speaker Recognition,https://www.reddit.com/r/deeplearning/comments/cjsspl/research_deep_learning_for_shortsegment_speaker/,cdossman,1564498166,"**Abstract:** Today's interactive devices such as smart-phone assistants and smart speakers often deal with short-duration speech segments. As a result, speaker recognition systems integrated into such devices will be much better suited with models capable of performing the recognition task with short-duration utterances. In this paper, a new deep neural network, UtterIdNet, capable of performing speaker recognition with short speech segments is proposed. Our proposed model utilizes a novel architecture that makes it suitable for short-segment speaker recognition through an efficiently increased use of information in short speech segments. UtterIdNet has been trained and tested on the VoxCeleb datasets, the latest benchmarks in speaker recognition. Evaluations for different segment durations show consistent and stable performance for short segments, with significant improvement over the previous models for segments of 2 seconds, 1 second, and especially sub-second durations (250 ms and 500 ms) 

 [https://arxiv.org/abs/1907.10420](https://arxiv.org/abs/1907.10420)",0,2
351,2019-7-30,2019,7,30,23,cjsu88,Realtime Data Augmentation inefficiency seems insane to me,https://www.reddit.com/r/deeplearning/comments/cjsu88/realtime_data_augmentation_inefficiency_seems/,QuickTurtle9,1564498345,"I am currently learning to use Keras and asking myself why it is recommended to use the realtime data augmentation method (ImageDataGenerator class) ? I tried it with MNIST and a CNN with 540k params but it would take hours to train the model, the performance is so bad. Instead I created a static augmented dataset with 400k images for training plus 10k for validation:

```
number_val = 10000
gen = datagen.flow(train_images[:-number_val], train_labels[:-number_val], batch_size=1000)

train_images_augmented = train_images.tolist()[:-number_val]
train_labels_augmented = train_labels.tolist()[:-number_val]
number_batches = 350
i = 0

for images, labels in gen:
  for image in images:
    train_images_augmented.append(image)
  for label in labels:
    train_labels_augmented.append(label)
  i += 1
  if i &gt;= number_batches:
    break
```

With that it takes just 67 seconds to reach an accuracy of 99.54% on the test dataset.

Is it only used to ensure that 'completely' new records are used in each epoch? And if so, is it really such an advantage that the extreme inefficiency is worthwhile? Another reason I can imagine is that it does not make a big difference on extreme large datasets when you're relying on a generator anyway. But even then it would be massive losses that you would have to accept in every training. Maybe I miss something, then I'm happy about an explanation :-)",7,6
352,2019-7-30,2019,7,30,23,cjsx7l,(Video) Millie Fit: Your On-Demand AI Trainer,https://www.reddit.com/r/deeplearning/comments/cjsx7l/video_millie_fit_your_ondemand_ai_trainer/,nahuak,1564498713,,0,4
353,2019-7-31,2019,7,31,0,cjtpyp,Has anybody tried Weights and Biases (W&amp;B)?,https://www.reddit.com/r/deeplearning/comments/cjtpyp/has_anybody_tried_weights_and_biases_wb/,aeduG,1564502172,"[https://www.wandb.com/](https://www.wandb.com/)

It is a tool to monitor neural nets and plot outputs, error curves, histograms etc. It is very easy to understand, integrates well with PyTorch or TensorFlow, and it is free for academic use. I wonder why not more people are using it.",4,2
354,2019-7-31,2019,7,31,3,cjvwsu,Classifying data from satellite images,https://www.reddit.com/r/deeplearning/comments/cjvwsu/classifying_data_from_satellite_images/,rushan3103,1564511344,How would you get a satellite image and classify the data into either forests or urban areas etc,2,1
355,2019-7-31,2019,7,31,3,cjvwug,I Placed 4th in my First AI Competition. Read my write up of my agent on Unity's ObstacleTower AI Challenge.,https://www.reddit.com/r/deeplearning/comments/cjvwug/i_placed_4th_in_my_first_ai_competition_read_my/,soho-joe,1564511349,,4,49
356,2019-7-31,2019,7,31,6,cjy4xy,Data pollution's effect on deep learning,https://www.reddit.com/r/deeplearning/comments/cjy4xy/data_pollutions_effect_on_deep_learning/,OldCoderK,1564520955,"I'm trying to find a paper that discusses what happens when some training samples are not labeled correctly.

e.g. The image of a cat is labeled as a dog once in 5000 samples.

Any pointers?",0,1
357,2019-7-31,2019,7,31,15,ck4oj3,Learn Artificial Intelligence  5 Free Courses for Beginners,https://www.reddit.com/r/deeplearning/comments/ck4oj3/learn_artificial_intelligence_5_free_courses_for/,skj8,1564555154,,0,0
358,2019-7-31,2019,7,31,16,ck53ld,How to feed video frames to 3D CNN?,https://www.reddit.com/r/deeplearning/comments/ck53ld/how_to_feed_video_frames_to_3d_cnn/,juggy94,1564557948,"I have designed a 3D CNN network, each of my videos have frames of size approx 600x400 and approx 200 such frames. So I can't feed an entire video in one go to the network. So I decided to feed 5 frames at a time,however I can't figure how to access/feed the data accordingly. Right now my data is stored in numpy array with dimensions 10,200,600,400,3 for a dataset of 10 videos. 

I am currently using keras but I don't think I can use simple model.fit, I might have to loop through the data somehow. Or should I try using tensorflow instead and use feed_dict in some way?",0,5
359,2019-7-31,2019,7,31,18,ck65xj,Is it weird when a 14 year old publishes a paper ?,https://www.reddit.com/r/deeplearning/comments/ck65xj/is_it_weird_when_a_14_year_old_publishes_a_paper/,nowsden,1564565682,"Hi everyone, 

is it weird when a 14 year old wants to publish a paper ? I've been working on and with computers for 8 years or and I have been working on a lot of stuff in Machine Learning for 4 years now and wrote several models and algorithms. Now I am working on a Self Driving Car Simulator and I want to publish a paper on it. Is there anything wrong with it or can you recommend me something ? Or give me some tips",40,51
360,2019-7-31,2019,7,31,19,ck6m11,Baidu unveils ERNIE 2.0 natural language framework in Chinese and English,https://www.reddit.com/r/deeplearning/comments/ck6m11/baidu_unveils_ernie_20_natural_language_framework/,worldwide__master,1564568751,,0,1
361,2019-7-31,2019,7,31,19,ck6m5w,Baidu unveils ERNIE 2.0 natural language framework in Chinese and English,https://www.reddit.com/r/deeplearning/comments/ck6m5w/baidu_unveils_ernie_20_natural_language_framework/,worldwide__master,1564568776,,0,2
362,2019-7-31,2019,7,31,20,ck7jhh,Natural Language Processing with Deep Learning online course video lectures by Stanford,https://www.reddit.com/r/deeplearning/comments/ck7jhh/natural_language_processing_with_deep_learning/,freevideolectures,1564574394,,1,1
363,2019-7-31,2019,7,31,21,ck7kcc,3 Reasons why AI Assisted Labeling will destroy Manual labor market,https://www.reddit.com/r/deeplearning/comments/ck7kcc/3_reasons_why_ai_assisted_labeling_will_destroy/,tdionis,1564574533,,1,2
364,2019-7-31,2019,7,31,21,ck7s4l,Human pose estimation on images for iOS using CoreML,https://www.reddit.com/r/deeplearning/comments/ck7s4l/human_pose_estimation_on_images_for_ios_using/,atomlib_com,1564575736,,0,2
365,2019-7-31,2019,7,31,23,ck9hu3,"Getting started with Tensorflow, Keras in Python and R",https://www.reddit.com/r/deeplearning/comments/ck9hu3/getting_started_with_tensorflow_keras_in_python/,tvganesh,1564584647,,0,1
0,2019-8-1,2019,8,1,11,ckii5b,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/ckii5b/data_science_career_track_prep_course/,HannahHumphreys,1564627816,[removed],0,1
1,2019-8-1,2019,8,1,13,ckjm3s,1D conv-net,https://www.reddit.com/r/deeplearning/comments/ckjm3s/1d_convnet/,nicetryho,1564634323,Working with a semi complex 1Dconv network that takes in raw time series data with no prior feature extraction. When training my model seems to learn very quickly only after 10 epochs..what is this a sign of ? I have adjusted the learning rate but even then by 40 its at over 90 acc.,2,1
2,2019-8-1,2019,8,1,14,ckjy1g,AI and deep learning to tackle traffic congestion,https://www.reddit.com/r/deeplearning/comments/ckjy1g/ai_and_deep_learning_to_tackle_traffic_congestion/,Ripple2709,1564636435,,1,4
3,2019-8-1,2019,8,1,16,ckkw00,Classifying Dogs vs Cats problem using Deep Learning in C++!,https://www.reddit.com/r/deeplearning/comments/ckkw00/classifying_dogs_vs_cats_problem_using_deep/,Kushashwa,1564642901,"Hi Everyone!

As some would know from my [last post](https://www.reddit.com/r/deeplearning/comments/cbqovr/announcing_a_series_of_blogs_on_pytorch_c_api/), I have started a series of blogs on using PyTorch C++ API. The recent post is on classifying Dogs vs Cats using a CNN in C++. 

[Link to the blog: https:\/\/krshrimali.github.io\/Classifying-Dogs-Cats-PyTorch-CPP-Part-2\/](https://i.redd.it/mngex1xqcsd31.jpg)

I hope this helps those who are just getting started with Deep Learning and have good hands on C++. I look forward for your feedback and any suggestions, as this keeps me going. 

If anyone faces any problem, or wants to collaborate, you can message me here! 

Happy Learning, fellas!",4,14
4,2019-8-1,2019,8,1,16,ckkx8d,Encrypt keras model (hdf5 or h5),https://www.reddit.com/r/deeplearning/comments/ckkx8d/encrypt_keras_model_hdf5_or_h5/,nanitiru18,1564643135,"How can I encrypt hdf5 or h5 model, cause  reverse engineering is possible in case of only weights are saved in h5 file",7,4
5,2019-8-1,2019,8,1,17,cklmqu,Sharing Papers?,https://www.reddit.com/r/deeplearning/comments/cklmqu/sharing_papers/,Dragonofburdur,1564648454,"Hello, wanted to ask an easy question about papers. Am I allowed share paper links in a public repository to share with my colleagues. I asked google but couldn't really find an answer if there is a regulation about that issue. Thanks.",2,6
6,2019-8-1,2019,8,1,21,cknr59,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cknr59/data_science_career_track_prep_course/,HannahHumphreys,1564662668,[removed],0,1
7,2019-8-1,2019,8,1,22,ckoftq,Career advice by Yoshua and Rich,https://www.reddit.com/r/deeplearning/comments/ckoftq/career_advice_by_yoshua_and_rich/,Nishanth127,1564666402,,0,0
8,2019-8-1,2019,8,1,22,ckojjj,Contextual Emotion Detection in Textual Conversations Using Neural Networks,https://www.reddit.com/r/deeplearning/comments/ckojjj/contextual_emotion_detection_in_textual/,atomlib_com,1564666943,,0,1
9,2019-8-1,2019,8,1,23,ckoybr,"For those of you that are unfamiliar with Keras, here is a great video-introduction that explains exactly what it is.",https://www.reddit.com/r/deeplearning/comments/ckoybr/for_those_of_you_that_are_unfamiliar_with_keras/,antaloaalonso,1564669026,,3,35
10,2019-8-1,2019,8,1,23,ckpdy6,[Research],https://www.reddit.com/r/deeplearning/comments/ckpdy6/research/,cdossman,1564671132," **Abstract**Continuous affect prediction involves the discrete time-continuous regression of affect dimensions. Dimensions to be predicted often include arousal and valence. Continuous affect prediction researchers are now embracing multimodal model input. This provides motivation for researchers to investigate previously unexplored affective cues. Speech-based cues have traditionally received the most attention for affect prediction, however, non-verbal inputs have significant potential to increase the performance of affective computing systems and in addition, allow affect modelling in the absence of speech. However, nonverbal inputs that have received little attention for continuous affect prediction include eye and head-based cues. The eyes are involved in emotion displays and perception while headbased cues have been shown to contribute to emotion conveyance and perception. Additionally, these cues can be estimated noninvasively from video, using modern computer vision tools. This work exploits this gap by comprehensively investigating head and eye-based features and their combination with speech for continuous affect prediction. Hand-crafted, automatically generated and CNN-learned features from these modalities will be investigated for continuous affect prediction. The highest performing feature sets and feature set combinations will answer how effective these features are for the prediction of an individuals affective state. 

 [https://medium.com/@cdossman/hand-crafted-feature-sets-based-on-head-and-eye-based-cues-f4bee0103d3e](https://medium.com/@cdossman/hand-crafted-feature-sets-based-on-head-and-eye-based-cues-f4bee0103d3e)",0,1
11,2019-8-1,2019,8,1,23,ckpf58,"[Research] Speech, Head, and Eye-based Cues for Continuous Affect Prediction",https://www.reddit.com/r/deeplearning/comments/ckpf58/research_speech_head_and_eyebased_cues_for/,cdossman,1564671300," **Abstract**  Continuous affect prediction involves the discrete time-continuous regression of affect dimensions. Dimensions to be predicted often include arousal and valence. Continuous affect prediction researchers are now embracing multimodal model input. This provides motivation for researchers to investigate previously unexplored affective cues. Speech-based cues have traditionally received the most attention for affect prediction, however, non-verbal inputs have significant potential to increase the performance of affective computing systems and in addition, allow affect modelling in the absence of speech. However, nonverbal inputs that have received little attention for continuous affect prediction include eye and head-based cues. The eyes are involved in emotion displays and perception while headbased cues have been shown to contribute to emotion conveyance and perception. Additionally, these cues can be estimated noninvasively from video, using modern computer vision tools. This work exploits this gap by comprehensively investigating head and eye-based features and their combination with speech for continuous affect prediction. Hand-crafted, automatically generated and CNN-learned features from these modalities will be investigated for continuous affect prediction. The highest performing feature sets and feature set combinations will answer how effective these features are for the prediction of an individuals affective state. 

[https://medium.com/@cdossman/hand-crafted-feature-sets-based-on-head-and-eye-based-cues-f4bee0103d3e](https://medium.com/@cdossman/hand-crafted-feature-sets-based-on-head-and-eye-based-cues-f4bee0103d3e)",0,1
12,2019-8-2,2019,8,2,1,ckqkje,Speaker identification through intonation,https://www.reddit.com/r/deeplearning/comments/ckqkje/speaker_identification_through_intonation/,hega72,1564676563,"Hi all
Does anybody know of an approach to identify a speaker although the voice was obfuscated ? I thought I came wrote about an approach that was able to do that but I cant find it anymore. 
Any suggestions ?",0,2
13,2019-8-2,2019,8,2,1,ckqzru,Image augmentation: best way to augment associated xml files that contain bounding box information?,https://www.reddit.com/r/deeplearning/comments/ckqzru/image_augmentation_best_way_to_augment_associated/,ml_runway,1564678459,"Let's say I have an image `train.png` and associated xml file `train_boxes.xml` that contains information about the image, including bounding boxes and their labels (the standard kind of thing you would get with annotation software like labelimg).

Now when I want to augment `train.png` (say, with a rotation or whatever), is there a standard way people then create new xml files? My goal is to create a new image/xml file pair for each augmented image, so `train_aug_1.png` and `train_aug_1_boxes.xml` by simply changing the data in the original xml file (i.e., changing the image path and bounding boxes, but leaving the labels and everything else the same).

I imagine this is such a common workflow but I haven't found anything online about it, and am wondering if there is already a pipeline out there that I can use, or if I should just write it myself (I was planning to just use `imgaug` and `ElementTree` for all the relevant operations):    

-  https://imgaug.readthedocs.io/en/latest/    
-  https://docs.python.org/3.7/library/xml.etree.elementtree.html

I'm curious what people think or if they have any advice I have never done this before...",0,1
14,2019-8-2,2019,8,2,3,cksn2j,Kaggle 1st Pos Solution of Data Science for Good: City of LA Kaggle Comp | Interview with Shivam Bansal,https://www.reddit.com/r/deeplearning/comments/cksn2j/kaggle_1st_pos_solution_of_data_science_for_good/,init__27,1564685840,"Interview with Shivam Bansal about his 1st position Winning solution to the Data Science for Good: City of LA Kaggle Comp

&amp;#x200B;

Podcast: [https://anchor.fm/chaitimedatascience/episodes/Data-Science-for-Good-City-of-LA-Kaggle-Winning-Solution-Interview-with-Kaggle-Kernels-Grandmaster-Shivam-Bansal-e4qc36/a-ak0h7g](https://anchor.fm/chaitimedatascience/episodes/Data-Science-for-Good-City-of-LA-Kaggle-Winning-Solution-Interview-with-Kaggle-Kernels-Grandmaster-Shivam-Bansal-e4qc36/a-ak0h7g)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=VdnUmrRuuWE&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=5](https://www.youtube.com/watch?v=VdnUmrRuuWE&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=5)",0,3
15,2019-8-2,2019,8,2,4,ckstct,[P] Critic - Learning Music Taste With Deep Neural Nets,https://www.reddit.com/r/deeplearning/comments/ckstct/p_critic_learning_music_taste_with_deep_neural/,[deleted],1564686625,[deleted],0,1
16,2019-8-2,2019,8,2,4,cktgol,[I built] Critic - Learning Music Taste With Deep Neural Nets,https://www.reddit.com/r/deeplearning/comments/cktgol/i_built_critic_learning_music_taste_with_deep/,_Radish_Spirit_,1564689576,"[Deployed Web App](https://michaeldarr.github.io/MuCritic_App/)

[Source Code](https://github.com/MichaelDarr/MuCritic)

[Model Explanation](https://michaeldarr.github.io/MuCritic_App/#/about)

Hi all! I graduated with a BS in computer science last spring and have spent the last few months building and deploying my first large-scale ML project. I would love to hear any feedback or criticism you have to offer. Thanks!",1,1
17,2019-8-2,2019,8,2,4,cktgrq,Self-Supervised Learning + GANs outperforms Supervised GANs,https://www.reddit.com/r/deeplearning/comments/cktgrq/selfsupervised_learning_gans_outperforms/,HenryAILabs,1564689585,[https://youtu.be/-oJWFcexolY](https://youtu.be/-oJWFcexolY),0,6
18,2019-8-2,2019,8,2,5,cku3hn,"Tensorflow, GAN, etc, with AMD GPU.",https://www.reddit.com/r/deeplearning/comments/cku3hn/tensorflow_gan_etc_with_amd_gpu/,jgemeigh,1564692499,"Okay, okay, I know, I messed up buying tons of AMD GPU instead of Nvidia.
That's out of the way. 
So I have 40 gpus that I mine with and make a killing on crypto, protein folding, and golem.io

But I have always aspired to put that computing towards something more, that I can do independently. 

I found some code on GitHub today that uses deeplearning to make some amazing Renaissance portraits and anime character faces from selfies and photos. It says it uses tensorflow and GANs.

I am wondering if there is a legitimate way to use AMD gpus to accomplish this stuff. Not asking for a whole explanation, I can do the research myself. But I keep hitting walls in forums that just say amd gpus can't do deeplearning. And I don't believe it. 

Does anyone know if tensorflow, GANs can be used with AMD gpus, and maybe a link to a useful guide on doing so?

Thank you all for any input.",7,4
19,2019-8-2,2019,8,2,11,ckxyb5,Tensorflow proposal for outer product operation,https://www.reddit.com/r/deeplearning/comments/ckxyb5/tensorflow_proposal_for_outer_product_operation/,sz524,1564712141,"&amp;#x200B;

[https://github.com/tensorflow/tensorflow/issues/17564](https://github.com/tensorflow/tensorflow/issues/17564)

[https://github.com/4d55397500/proposed-outer-product-tensorflow](https://github.com/4d55397500/proposed-outer-product-tensorflow)

I have a longstanding issue open in the Tensorflow project to create an outer product operation.

Does anyone else think it ironic that the fundamental operation on tensors of outer product is not supported by Tensorflow?",6,11
20,2019-8-2,2019,8,2,16,cl0z97,Unsupervised Domain Adaptation via Disentangled Representations: Application to Cross-Modality Liver Segmentation,https://www.reddit.com/r/deeplearning/comments/cl0z97/unsupervised_domain_adaptation_via_disentangled/,junlin639,1564731406,,0,3
21,2019-8-2,2019,8,2,20,cl2opw,Artificial Intelligence to speed up trip planning,https://www.reddit.com/r/deeplearning/comments/cl2opw/artificial_intelligence_to_speed_up_trip_planning/,MachineLearning001,1564744173,,0,4
22,2019-8-2,2019,8,2,21,cl3ft6,Data Science with R - Best books to become an Expert,https://www.reddit.com/r/deeplearning/comments/cl3ft6/data_science_with_r_best_books_to_become_an_expert/,HannahHumphreys,1564748820,[removed],0,1
23,2019-8-2,2019,8,2,22,cl48ke,N-Shot Learning: Learning More with Less Data,https://www.reddit.com/r/deeplearning/comments/cl48ke/nshot_learning_learning_more_with_less_data/,pirate7777777,1564753135,,0,36
24,2019-8-3,2019,8,3,0,cl5i7v,[R] Fooling real cars with Deep Learning (Deep Learning + Cybersecurity)),https://www.reddit.com/r/deeplearning/comments/cl5i7v/r_fooling_real_cars_with_deep_learning_deep/,oblongatas_blancas,1564759280,"Hey, posting after /r/MachineLearning

We attacked a real vehicle using Deep Learning to generate real life Adversarial traffic signs, effective on cars from different manufacturers. We used nothing more than a strong GPU and commercially available printing services.

Would love feedback and/or discussion :-)

the paper [https://arxiv.org/abs/1907.00374](https://arxiv.org/abs/1907.00374)

medium post with a Demo video [https://medium.com/@shacharm/fooling-real-cars-with-deep-learning-cace6422c396](https://medium.com/@shacharm/fooling-real-cars-with-deep-learning-cace6422c396)",0,3
25,2019-8-3,2019,8,3,8,clbtzl,Ubuntu Server OS vs Ubuntu Desktop OS help?,https://www.reddit.com/r/deeplearning/comments/clbtzl/ubuntu_server_os_vs_ubuntu_desktop_os_help/,RisingShogun,1564789766,"I'm a beginner in deep learning and was dead set on using Ubuntu for the operating system of the system I am building, however, I ran into a slight roadblock in what version of Ubuntu I should use. I am aware that the Server OS doesn't have a GUI and the Desktop OS does, but is there a benefit of using one OS versus another for deep learning?",4,2
26,2019-8-3,2019,8,3,12,cle28p,Threadripper 2920X vs i7-9800X (can't decide),https://www.reddit.com/r/deeplearning/comments/cle28p/threadripper_2920x_vs_i79800x_cant_decide/,th1nkpatriot,1564802863,"Looking to build a deep learning rig and trying to decide on the AMD Threadripper 2920X vs the Intel i7-9800X CPUs.

This will be used for a signal processing/audio fingerprinting system.

Does one have an advantage/disadvantage in this use-case? Does it matter?",30,10
27,2019-8-3,2019,8,3,13,clefzf,What services do you use for deploying Deep Learning models in production?,https://www.reddit.com/r/deeplearning/comments/clefzf/what_services_do_you_use_for_deploying_deep/,benur7,1564805228,"Hey guys, what services do you currently use for your Deep Learning models in production? I have a Tensorflow Model that I would like to deploy.",4,1
28,2019-8-3,2019,8,3,13,cles4c,N-Shot learning: Learn more with less data,https://www.reddit.com/r/deeplearning/comments/cles4c/nshot_learning_learn_more_with_less_data/,Hsankesara,1564807428,,0,13
29,2019-8-3,2019,8,3,14,clf7qa,Yolo architecture from scratch,https://www.reddit.com/r/deeplearning/comments/clf7qa/yolo_architecture_from_scratch/,shivam529,1564810485,"Can I make a yolo architecture from scratch improvising on lots of things like I know my objects are all of the same size, my objects being digits 1-9, like I dont think I would need anchor boxes and also the fact that I know pre hand my bounding boxes are all of the same size ?",4,2
30,2019-8-4,2019,8,4,2,cll9ro,Artificial Intelligence Projects with Python-HandsOn,https://www.reddit.com/r/deeplearning/comments/cll9ro/artificial_intelligence_projects_with/,HannahHumphreys,1564852897,[removed],0,1
31,2019-8-4,2019,8,4,5,clnkck,Projects Ideas for DGX-1,https://www.reddit.com/r/deeplearning/comments/clnkck/projects_ideas_for_dgx1/,toshn_,1564864799, I will have access to DGX-1 NVIDIA for my final year project. Can you suggest some nice projects ideas and applications where I can make full use of this beast?,14,6
32,2019-8-4,2019,8,4,12,clrv7z,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/clrv7z/data_science_career_track_prep_course/,HannahHumphreys,1564890005,[removed],0,1
33,2019-8-4,2019,8,4,16,cltqdm,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cltqdm/data_science_career_track_prep_course/,HannahHumphreys,1564903821,[removed],0,1
34,2019-8-4,2019,8,4,16,cltv40,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cltv40/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1564905016,[removed],0,1
35,2019-8-4,2019,8,4,21,clvpnh,I need to make my voice sound like Tom Cruise in Top Gun,https://www.reddit.com/r/deeplearning/comments/clvpnh/i_need_to_make_my_voice_sound_like_tom_cruise_in/,omasque,1564921234,"I am trying to achieve something along the lines of the ""Nic Cage in every movie"" vid that went around a while back. Not the part where his face is pasted on characters, but his voice saying the lines. I'm not sure if this was done TTS or by converting the spoken audio in the movie to a trained model(?) of his voice... ideally I would like to do either.

Without boring anyone with too much detail, I am producing some animated clips parodying Top Gun and can do a, let's say South Park-tier Tom Cruise impression. I'd like to be able to record the clips with my inflection and emphasis, then ""train"" that audio on recordings of Tom Cruise dialogue in that movie and several others from the time period, then use some sort of deep learning process to make my recorded dialogue sound more like Cruise.

Failing that, whatever process was used in the Nic Cage clip would suffice, as that is a very convincing level of recognisability in his voice. I've searched and found tutorials and articles about how the face was done, but can't seem to find a lot on the voice.",10,4
36,2019-8-4,2019,8,4,23,clwm84,Same guy Putin  rnn model using news footage by approximating heartbeat,https://www.reddit.com/r/deeplearning/comments/clwm84/same_guy_putin_rnn_model_using_news_footage_by/,godDLL,1564927274,"I'm thinking of disproving the conjecture that Putin **has doubles** on video in the news. I wonder whether a model could be made that would distinguish *Putin* / *Not-Putin* by heart beat approximated from the footage. How would I go about doing that, in 17 simple steps?..

Is that two models, one for deriving the heart-beat from video footage, one for same-guy evaluation?

Or is it more.

How do I even. Approach this, how. Full stop. I cant. How. %)",6,1
37,2019-8-5,2019,8,5,2,clyvfc,"Deep Learning Research, Deep Learning Hardware, Sparse Networks | Interview with Tim Dettmers",https://www.reddit.com/r/deeplearning/comments/clyvfc/deep_learning_research_deep_learning_hardware/,init__27,1564939195,"Interview with Tim Dettmers, PhD Student at University of Washington. 

We talk a lot about DL Research, DL Hardware :smile: and Tim's Kaggle experience 

Audio: https://anchor.fm/chaitimedatascience/episodes/Deep-Learning-Research--Hardware--Kaggle--Interview-with-Tim-Dettmers-e4qcad/a-ak0hr6

Video: https://www.youtube.com/watch?v=4857Lph2ndk&amp;feature=youtu.be",0,8
38,2019-8-5,2019,8,5,4,cm05yi,Transfer Learning with MobileNetV2,https://www.reddit.com/r/deeplearning/comments/cm05yi/transfer_learning_with_mobilenetv2/,mlait1908,1564945502,,0,7
39,2019-8-5,2019,8,5,4,cm08x1,Can't get GAN python program working due to lack of info about dependency version number,https://www.reddit.com/r/deeplearning/comments/cm08x1/cant_get_gan_python_program_working_due_to_lack/,sierrafourteen,1564945887,"Hi all

&amp;#x200B;

I'm trying to get hzwer's [ICCV2019-LearningToPaint](https://github.com/hzwer/ICCV2019-LearningToPaint) software running, but I keep coming up with issues that I'm assuming correspond to changes in dependencies that I'm using - I have some - the github page specifies the below data, although I don't understand how I can have torch as 0.4.1 and as 1.1.0 - but it doesn't tell me what versions other dependencies of dependencies are - meaning that I get problems such as `""AttributeError: module 'PIL' has no attribute 'Image'""`

  Can anyone help me determine what versions I should pick? Is it as simple as finding the versions that were available when the github repository was first created?

&amp;#x200B;

**Listed Dependencies:**

* [PyTorch](http://pytorch.org/) 0.4.1
* [tensorboardX](https://github.com/lanpa/tensorboard-pytorch/tree/master/tensorboardX)
* [opencv-python](https://pypi.org/project/opencv-python/) 3.4.0

&amp;#8203;

    pip3 install torch==1.1.0 pip3 install tensorboardX pip3 install opencv-python",5,1
40,2019-8-5,2019,8,5,11,cm4y0s,Deep Learning Written Website,https://www.reddit.com/r/deeplearning/comments/cm4y0s/deep_learning_written_website/,mrblasto,1564971108,"All the fake news articles on this website are written using a tensor flow.

http://www.blastolabs.com

I just input the stories title and it creates the rest.",10,17
41,2019-8-5,2019,8,5,11,cm55v5,"How to save a model that knows ""English"" but learns a style on a new text dataset?",https://www.reddit.com/r/deeplearning/comments/cm55v5/how_to_save_a_model_that_knows_english_but_learns/,maggles20,1564972423,"So my goal here is to make a webapp that users can write some sentences in (very small data) and train an rnn to learn their style and generate new text. Now I know thag dataset of just a few sentences is too small to train a completely new rnn, just wondering if it's possible to train an rnn on publicly available text data right now for it to learn grammar rules and whatnot now, and then teach it someone's style on just a few sentences?",2,0
42,2019-8-5,2019,8,5,14,cm71zb,#Free #Machinearning course by #Google,https://www.reddit.com/r/deeplearning/comments/cm71zb/free_machinearning_course_by_google/,mlait1908,1564984156,,0,0
43,2019-8-5,2019,8,5,15,cm7i8w,Conversational AI: The Advanced Form of Chatbots,https://www.reddit.com/r/deeplearning/comments/cm7i8w/conversational_ai_the_advanced_form_of_chatbots/,MachineLearning001,1564987392,,0,0
44,2019-8-5,2019,8,5,15,cm7lrv,How To Go Beyond CNNs With Stand-Alone Self-Attention Models,https://www.reddit.com/r/deeplearning/comments/cm7lrv/how_to_go_beyond_cnns_with_standalone/,analyticsindiam,1564988125,,0,1
45,2019-8-5,2019,8,5,16,cm8238,Deep Learning,https://www.reddit.com/r/deeplearning/comments/cm8238/deep_learning/,moizsawan,1564991525,Has anyone ever worked on image classification through graph neural networks?,2,0
46,2019-8-5,2019,8,5,20,cm9j3z,AMD Radeon Pro WX 7100 8GB GFX or NVIDIA Quadro P5000 16GB for DeepLearning?,https://www.reddit.com/r/deeplearning/comments/cm9j3z/amd_radeon_pro_wx_7100_8gb_gfx_or_nvidia_quadro/,testimoni,1565002870,"I have two options available to choose for deep learning projects.

Which one would you choose?

AMD Radeon Pro WX 7100 8GB GFX or NVIDIA Quadro P5000 16GB?",5,1
47,2019-8-5,2019,8,5,20,cm9p1f,What journal was the original GAN paper published?,https://www.reddit.com/r/deeplearning/comments/cm9p1f/what_journal_was_the_original_gan_paper_published/,clean_pegasus,1565003948,Can someone tell me in what journal the original GAN was published?,5,3
48,2019-8-5,2019,8,5,22,cmb7bf,[Research] A Robustly Optimized BERT Pretraining Approach,https://www.reddit.com/r/deeplearning/comments/cmb7bf/research_a_robustly_optimized_bert_pretraining/,cdossman,1565012953,"[https://medium.com/ai%C2%B3-theory-practice-business/researchers-propose-bert-pre-training-procedure-modifications-that-improve-end-task-performance-6fab990afd9a](https://medium.com/ai%C2%B3-theory-practice-business/researchers-propose-bert-pre-training-procedure-modifications-that-improve-end-task-performance-6fab990afd9a) 

Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have a significant impact on the final results. We present a replication study of BERT pretraining that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE, and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.",0,3
49,2019-8-6,2019,8,6,0,cmc6hm,"Harvard Researchers Benchmark TPU, GPU &amp; CPU for Deep Learning",https://www.reddit.com/r/deeplearning/comments/cmc6hm/harvard_researchers_benchmark_tpu_gpu_cpu_for/,Yuqing7,1565017846,,1,10
50,2019-8-6,2019,8,6,1,cmd8u0,OmniNet: A unified architecture for multi-modal multi-task learning,https://www.reddit.com/r/deeplearning/comments/cmd8u0/omninet_a_unified_architecture_for_multimodal/,turing_1997,1565022722,"**Paper title:** OmniNet: A unified architecture for multi-modal multi-task learning

**Paper url:** [https://arxiv.org/abs/1907.07804](https://arxiv.org/abs/1907.07804)

**Code:** [https://github.com/subho406/OmniNet](https://github.com/subho406/OmniNet?fbclid=IwAR08pJ7Fnxq6n4IStevp_dsXCLhak_nW53w1crtn22yGirKBHcwQwH3szYY)

**Abstract:** Transformer is a popularly used neural network architecture, especially for language understanding. We introduce an extended and unified architecture which can be used for tasks involving a variety of modalities like image, text, videos, etc. We propose a spatio-temporal cache mechanism that enables learning spatial dimension of the input in addition to the hidden states corresponding to the temporal input sequence. The proposed architecture further enables a single model to support tasks with multiple input modalities as well as asynchronous multi-task learning, thus we refer to it as OmniNet. For example, a single instance of OmniNet can concurrently learn to perform the tasks of part-of-speech tagging, image captioning, visual question answering and video activity recognition. We demonstrate that training these four tasks together results in about three times compressed model while retaining the performance in comparison to training them individually. We also show that using this neural network pre-trained on some modalities assists in learning an unseen task. This illustrates the generalization capacity of the self-attention mechanism on the spatio-temporal cache present in OmniNet.

&amp;#x200B;

https://i.redd.it/j57h2d1aqne31.png",0,1
51,2019-8-6,2019,8,6,2,cmdn20,Multimodal Future Prediction - CVPR 2019,https://www.reddit.com/r/deeplearning/comments/cmdn20/multimodal_future_prediction_cvpr_2019/,os1a,1565024487,"A  recent work about multimodal future prediction which is critical for AI applied to autonomous driving:

[https://arxiv.org/abs/1906.03631](https://arxiv.org/abs/1906.03631)",0,1
52,2019-8-6,2019,8,6,2,cmefo2,Help for deep learning laptop purchase?,https://www.reddit.com/r/deeplearning/comments/cmefo2/help_for_deep_learning_laptop_purchase/,deep_curiosity,1565027981,"Hello. I'm a deep learning engineer. My company lets me renew my 2-year old laptop. Budget is \~$3,000. I googled many laptops and reviews, but none was similar to my case, so excuse me to advise to the deep learning community.

For information, my old laptop was Acer Predator 17x with NVIDIA 1080. It's super huge and big. I have been very satisfied the build quality and did great job, but its portability was too horrible. (e.g., if you put the laptop on airplane seat desks, the desk almost crashes...)

I also somewhat agree that setting up desktop or cloud and then sshing from laptop is practical, but I already have a multiple of workstations each with 4 Titan Xs. But I also like to have NVIDIA GPU in my laptop because: although I'll not run intense training, many times I need to check my Proof-of-Concept network architecture with small batch sizes and I need to develop my application using CUDA calculation and inference without the Internet.

I'll use Ubuntu Dual boot. Ubuntu with GPU is essential.

So, **my criterion**:

* Development usage, No gaming
* Linux (Ubuntu) boot
* Portability and battery life to work everywhere (Battery life on Linux seems to require optimization anyway..)
* Preferably, decent NVIDIA GPU (Not intense training but for at least forward inference and CUDA calculation)

Here's are my lists:

**Surface book2**: Good portability. NVIDIA 1060. Maybe additional benefits for reading papers. Not sure Ubuntu with GPU. (I found some git repo about optimizing Linux for surface book 2, but still, I feel like the hardware might too optimized to Windows.)

**Lenovo extreme X1**: Temping, but NVIDIA 1050, which sounds too weak even for inference and CUDA (right..?).

**Razer Blade 15 (2019) RTX 2080 Max-Q** vs. **Gigabyte new Aero 15"" OLED RTX 2070 (XA-9US5130SP)**: Highly likely choice. Which one do you recommend if you are familiar with these?

Will be there a better choice? 

Advice please, and let me know if this kind of questions is not appropriate.",6,1
53,2019-8-6,2019,8,6,3,cmeq3s,"Explaining Feedforward, Backpropagation and Optimization: The Math Explained Clearly with Visualizations. I took the time to write this long article (&gt;5k words), and I hope it helps someone understand neural networks better.",https://www.reddit.com/r/deeplearning/comments/cmeq3s/explaining_feedforward_backpropagation_and/,permalip,1565029237,,0,1
54,2019-8-6,2019,8,6,3,cmexqw,what is site to learn neural network with api's?,https://www.reddit.com/r/deeplearning/comments/cmexqw/what_is_site_to_learn_neural_network_with_apis/,manish939,1565030187,learn neural networks working and api's like tenserflow nd keras suggest me the online best courses with practise sheets nd must be free,2,0
55,2019-8-6,2019,8,6,5,cmgjvu,Explaining How DeepMind's Population Based Training Works,https://www.reddit.com/r/deeplearning/comments/cmgjvu/explaining_how_deepminds_population_based/,HenryAILabs,1565037282,[https://www.youtube.com/watch?v=pEANQ8uau88&amp;t=33s](https://www.youtube.com/watch?v=pEANQ8uau88&amp;t=33s),8,29
56,2019-8-6,2019,8,6,9,cmj48h,Pytorch Cheat Sheet for Beginners and Udacity Deep Learning Nanodegree,https://www.reddit.com/r/deeplearning/comments/cmj48h/pytorch_cheat_sheet_for_beginners_and_udacity/,glassjar123,1565049658,,0,1
57,2019-8-6,2019,8,6,10,cmke4w,Which is the better GPU for deep learning? Titan series or Tesla series?,https://www.reddit.com/r/deeplearning/comments/cmke4w/which_is_the_better_gpu_for_deep_learning_titan/,clean_pegasus,1565056626,,2,5
58,2019-8-6,2019,8,6,16,cmnhun,Transporting neural nets?,https://www.reddit.com/r/deeplearning/comments/cmnhun/transporting_neural_nets/,swoonz101,1565076512,"I was wondering if transferring neural nets through TCP/IP was the most efficient way to go about it. I'm working on a deep learning project that has remote deployment along with inference at the edge. Model training is done in the cloud and inference is done at the edge. Given that the network connection available is a bit spotty, I was wondering if there was a faster way to transmit neural nets. Is there any research papers or projects on this subject?",6,2
59,2019-8-6,2019,8,6,18,cmo6ty,When Not to Choose the Best NLP Model,https://www.reddit.com/r/deeplearning/comments/cmo6ty/when_not_to_choose_the_best_nlp_model/,pirate7777777,1565082206,,0,10
60,2019-8-6,2019,8,6,21,cmq4ko,"PyTorch Implementation of various Semantic Segmentation models (deeplabV3+, PSPNet, Unet, ...)",https://www.reddit.com/r/deeplearning/comments/cmq4ko/pytorch_implementation_of_various_semantic/,youali,1565095542,"To get a handle of semantic segmentation methods, I re-implemented some well known models with a clear structured code (following this [PyTorch template](https://github.com/victoresque/pytorch-template)), in particularly:

- The implemented models are: Deeplab V3+ - GCN - PSPnet - Unet - Segnet and FCN

- Supported datasets: Pascal Voc, Cityscapes, ADE20K, COCO stuff,

- Losses: Dice-Loss, CE Dice loss, Focal Loss and Lovasz Softmax,

with various data augmentations and learning rate schedulers (poly learning rate and one cycle).

I though I share this implementation in case anyone might be interested, and here it is :

**Github**: https://github.com/yassouali/pytorch_segmentation",8,49
61,2019-8-7,2019,8,7,0,cmrscv,Why does backpropagation have it's own name? Isn't it just a use of the chain rule?,https://www.reddit.com/r/deeplearning/comments/cmrscv/why_does_backpropagation_have_its_own_name_isnt/,PertPerri,1565104168,"I know that a lot of machine learning is just reusing and renaming things discovered a long time ago in other fields, but come on. When people talk about backpropagation as if it's some fancy algorithm, it distracts from the clever bit that all the deep learning libraries use to calculate gradients: automatic differentiation. Maybe it's just in YouTube tutorials, but everyone seems to talk about calculating gradients and none of them explain what automatic differentiation is or how it works/is implemented in popular libraries.

Perhaps I'm just odd, but I absolutely hate it when people use unnecessary, fancy-sounding words.",11,2
62,2019-8-7,2019,8,7,0,cmsbri,can I use an nvidia 1060 6 GB from a VM (win 10 host)? anything I need to know/do?,https://www.reddit.com/r/deeplearning/comments/cmsbri/can_i_use_an_nvidia_1060_6_gb_from_a_vm_win_10/,remotepie0,1565106741,"Hi,  (terminology: host means the bare metals computer that boots for example I am runnign windows 10, guest is the computer within a VM like if I run a vm and install linux within it then linux is the guest OS.)

I'm curious if I would have any detriment from running my machine learning stuff from inside a VM within my host, Windows 10.  I have a 6 GB nvidia 1060.  I can imagine the VM either can, or can't, just directly pass through the stuff that needs on the card.

What do I need to know?

1.  i.e. what VM can I use (such as Parallels Desktop 14, Oracle VM Virtualbox, VMware Fusion and Workstation?)

2.  Do I need to configure anything special to make the pass-through work properly?

3.  I use windows 10 as the host, but since I am learning about machine learning for the first time I am curious about what guest(s) would be appropriate - also windows 10, or is linux much better?  Which Linux?

I have 16 GB of RAM on the host computer and heard that deep learning doesn't take much ram, so I plan to just give 4 GB to my guest machine.

If this setup is unlikely to work well please let me know.  I suppose I can run the things I'm learning about directly on my host comptuer.  The reason I would not like to do this is to keep from adding things to my computer as I install all the tooling I would use.  For example I woudl prefer not to install python and tensorflow on my (host) computer, just within the guest.  Additionally, I kind of have the idea that later I could upload my guest to the cloud and scale out my learning algorithms without configuring anything else, almost like if I had it as a docker thing.  but this could be kind of stupid.

please let me know what I need to know.  thanks.",5,1
63,2019-8-7,2019,8,7,3,cmu7xy,Fake it 'till you make it: in defence of a simulated approach to build (good) Computer Vision projects,https://www.reddit.com/r/deeplearning/comments/cmu7xy/fake_it_till_you_make_it_in_defence_of_a/,pjgrizel,1565115476,,0,0
64,2019-8-7,2019,8,7,4,cmv3ix,[P] Open source an NLP/speech library DELTA,https://www.reddit.com/r/deeplearning/comments/cmv3ix/p_open_source_an_nlpspeech_library_delta/,hankun11,1565119484,,2,1
65,2019-8-7,2019,8,7,6,cmwsij,"Robust Lane Detection and Tracking Framework for Autonomous Vehicle (Indian Roads) using DeepCNN, Ext. Hough Transform and Kalman Filter.",https://www.reddit.com/r/deeplearning/comments/cmwsij/robust_lane_detection_and_tracking_framework_for/,ayush0016,1565128613,"Being part of the perception team at an autonomous vehicle research group, I had been working on the Lane detection and tracking module for the vehicle.  What made the project challenging were many factors unique to the Indian landscape like highly weathered lanes and unusually congested traffic problems, which took the project close to long 8 months to complete.

The framework is trained and evaluated on the data collected by our experimental vehicle on Indian roads. The dataset consists of a total of 4500 frames with varying driving scenarios, including highways, urban roads, traffic, shadowed lanes, partially visible lanes and curved lanes.",0,1
66,2019-8-7,2019,8,7,8,cmxxon,derivations for recursive neural tensor networks and kernel invariants,https://www.reddit.com/r/deeplearning/comments/cmxxon/derivations_for_recursive_neural_tensor_networks/,sz524,1565134050,"Some notes of mine, one derivations from the RNTN paper, the other invariance forms for kernels (convolutional nets) derived by infinitesimal variation under the corresponding symmetry group. Apologies for the bad handwriting.

[https://github.com/4d55397500/handwritten-notes](https://github.com/4d55397500/handwritten-notes)",0,0
67,2019-8-7,2019,8,7,13,cn0y91,Linear Regression in Machine Learning | MLAIT,https://www.reddit.com/r/deeplearning/comments/cn0y91/linear_regression_in_machine_learning_mlait/,mlait1908,1565150853,,0,1
68,2019-8-7,2019,8,7,15,cn25z2,New to deep learning!,https://www.reddit.com/r/deeplearning/comments/cn25z2/new_to_deep_learning/,YALAMARTHI97,1565159122,"Hey ya guys.. The recent AIs playing games using deep learning has pricked my interest in deep learning and I find myself switching from python based low lvl ML implementation ( like regressions and stuff ... P.s learnt it in Univ not a pretty good implementer of em anyway )

I do have some theoretical knowledge about neural networks . I now wanna try to create an AI bot which can play a certain game by learning from the basic rules and stuff of the game using deep learning .

Am finding it hard to pin point any articles which would guide me on that particular way of creating a bit using deep learning and enabling it to play the game ..

R there any helpful weblinks r articles r psuedo codes of such sort which I can go through .. learn and then implement em ..???

Thanks in advance !

Desperate learner",4,0
69,2019-8-7,2019,8,7,16,cn2vsf,Benefits of Using AI Chatbots in Insurance,https://www.reddit.com/r/deeplearning/comments/cn2vsf/benefits_of_using_ai_chatbots_in_insurance/,MachineLearning001,1565164476,,0,8
70,2019-8-7,2019,8,7,17,cn2zns,Deep insight of AI,https://www.reddit.com/r/deeplearning/comments/cn2zns/deep_insight_of_ai/,OliviaWillson,1565165366,,0,1
71,2019-8-8,2019,8,8,0,cn7a87,Illustrated: 10 CNN Architectures,https://www.reddit.com/r/deeplearning/comments/cn7a87/illustrated_10_cnn_architectures/,raibosome,1565191947,,1,42
72,2019-8-8,2019,8,8,2,cn8p9h,Guys!! I m doing andrew ng s deep learning specialisation . Can anyone help me that how he got Z[1] (with derivation in detail) . It would be nice :) [i alread asked this question in forums but no reply ;( ],https://www.reddit.com/r/deeplearning/comments/cn8p9h/guys_i_m_doing_andrew_ng_s_deep_learning/,Sahil8141,1565198507,,10,1
73,2019-8-8,2019,8,8,4,cnaqe0,"[Research] Robust Lane detection and tracking framework for Autonomous Vehicles(Indian Roads) using Deep CNN, Ext. Hough Transform and Kalman Filter.",https://www.reddit.com/r/deeplearning/comments/cnaqe0/research_robust_lane_detection_and_tracking/,ayush0016,1565207714,"Being part of the perception team at an Autonomous Vehicle research lab I had been working on the development of the lane detection and tracking module for the vehicle catering to Indian road scenario. What made the project challenging were many factors unique to the Indian landscape like highly weathered lanes and unusually congested traffic problems which took the project close to 8 months to complete.  
The framework is trained and evaluated on the data collected by our experimental vehicle on Indian roads. The dataset consists of a total of 4500 frames with varying driving scenarios, including highways, urban roads, traffic, shadowed lanes, partially visible lanes and curved lanes.

Project Page/Github link : [https://github.com/ayush1997/Robust-Lane-Detection-and-Tracking](https://github.com/ayush1997/Robust-Lane-Detection-and-Tracking)",0,1
74,2019-8-8,2019,8,8,5,cnbh00,Trying to understand the foundation of batch normalization,https://www.reddit.com/r/deeplearning/comments/cnbh00/trying_to_understand_the_foundation_of_batch/,cooperbaerseth,1565211087,"I have a basic/fundamental question that I think I've glossed over in the past and would now like to look at more rigorously. 

&amp;#x200B;

For neural networks, why is it so important that we keep the distribution of the data constant as we proceed with training/validation/testing? This basic fact is what batch normalization seems to be based on, but I don't really understand the reason why it's so important. Intuitively or mathematically. 

&amp;#x200B;

Also, any text that explains the idea is very much appreciated. Thanks!!",4,4
75,2019-8-8,2019,8,8,5,cnbhac,"convert video data (.avi, .mp4 etc.) to TensorFlow tfrecords",https://www.reddit.com/r/deeplearning/comments/cnbhac/convert_video_data_avi_mp4_etc_to_tensorflow/,whiletrue2,1565211122,,0,1
76,2019-8-8,2019,8,8,6,cncbyg,Medical image classification,https://www.reddit.com/r/deeplearning/comments/cncbyg/medical_image_classification/,moizsawan,1565215178,"Hi all! I am currently working on a medical based image classification. But now I also have age of the patient as another feature (has a relationship with the outcome). I dont know how to incorporate age feature with the deep features. I have tried concatenation but as expected, the results are poor. I want to use deep features as a separate feature and age feature as a separate feature. Any idea how to go around with this problem (you can also refer me some research paper). In the future, I will have more features such as weight, etc. So I want to have a concrete setup for this problem.",13,9
77,2019-8-8,2019,8,8,8,cnda6y,[Project] Temporal Attentive Alignment for Large-Scale Video Domain Adaptation (ICCV 2019 Oral),https://www.reddit.com/r/deeplearning/comments/cnda6y/project_temporal_attentive_alignment_for/,cmhung34,1565219837,"Hello,  

It's my pleasure to share our recent work on Video Domain Adaptation with you!    
We proposed large-scale cross-domain action datasets, and developed an attention-based spatio-temporal DA mechanism to achieve effective domain alignment.  

Temporal Attentive Alignment for Large-Scale Video Domain Adaptation (ICCV 2019 Oral)  
\[GitHub\] https://github.com/cmhungsteve/TA3N   
\[arXiv\] https://arxiv.org/abs/1907.12743    


Feel free to share with others :)",0,1
78,2019-8-8,2019,8,8,12,cng98o,convNetQuake overfitting,https://www.reddit.com/r/deeplearning/comments/cng98o/convnetquake_overfitting/,arjundupa,1565236418,"I am training the convNetQuake architecture ([https://advances.sciencemag.org/content/advances/4/2/e1700578.full.pdf](https://advances.sciencemag.org/content/advances/4/2/e1700578.full.pdf)) on time-series data for binary classification. 

Here's the architecture in PyTorch:

    class ConvNetQuake(nn.Module):
        def __init__(self):
            super(ConvNetQuake, self).__init__()
            
            self.conv1 = nn.Conv1d(in_channels=2, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv4 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv5 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv6 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv7 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv8 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.linear = nn.Linear(128, 1)
            self.sigmoid = nn.Sigmoid()
    
        def forward(self, x):
            x = F.relu((self.conv1(x)))
            x = F.relu((self.conv2(x)))
            x = F.relu((self.conv3(x)))
            x = F.relu((self.conv4(x)))
            x = F.relu((self.conv5(x)))
            x = F.relu((self.conv6(x)))
            x = F.relu((self.conv7(x)))
            x = F.relu((self.conv8(x)))
            # After the eighth convolution, the features are flattened into a 1D vector of 128 features.
            x = torch.reshape(x, (10, -1))
            # A fully connected layer outputs the class scores
            x = self.linear(x)
            x = self.sigmoid(x)
    
            return x

My issue is that this base model is overfitting on my binary classification task. Here are some accuracies I obtained:

base\_model: 77/78

base\_model + batchNorm(): **87/88**

base\_model + dropout(0.1): 81/82

base\_model + label\_smoothing: 82/83

base\_model + batchNorm() + dropout(0.1): 82/83

base\_model + batchNorm() + label\_smoothing: 85

smaller base\_model (6 layers): 81/82

smaller base\_model (4 layers): 72/73

&amp;#x200B;

&amp;#x200B;

|Model|Accuracy (%)|
|:-|:-|
|base\_model|77/78|
|base\_model + batchNorm()|**87/88**|
|base\_model + dropout(0.1)|81/82|
|base\_model + label\_smoothing|82/83|
|base\_model + batchNorm() + dropout(0.1)|82/83|
|base\_model + batchNorm() + label\_smoothing|85|
|smaller base\_model (6 layers)|81/82|
|smaller base\_model (4 layers)|72/73|

&amp;#x200B;

All of these models overfit, despite the effort to combat this overfitting. Any ideas about what else could be tried?",9,2
79,2019-8-8,2019,8,8,15,cnhmjy,Slow AI response.,https://www.reddit.com/r/deeplearning/comments/cnhmjy/slow_ai_response/,Gkiid,1565244815,"Hello,   


I create a voice recognition on python, and everytime I command the ai, its responses is very slow, like taking 10 seconds to do the task. is it possible to enhance this or make it more faster responsiveness? any libraries needed for it?   


Thanks  


if specs matters, i have:

Ryzen 5 2600x  
Strix 2060   
HyperX 3200mhz RAM 16GB

mic: Plantronics Blackwire 3225 Series.",3,1
80,2019-8-8,2019,8,8,15,cnhykc,Benefits of Using AI Chatbots in Insurance,https://www.reddit.com/r/deeplearning/comments/cnhykc/benefits_of_using_ai_chatbots_in_insurance/,MachineLearning001,1565247027,,0,1
81,2019-8-8,2019,8,8,17,cnixpp,Building a Simple #NeuralNetwork in #Tensorflow | #MLAIT #ml #ai #DeepLearning,https://www.reddit.com/r/deeplearning/comments/cnixpp/building_a_simple_neuralnetwork_in_tensorflow/,mlait1908,1565253920,,0,0
82,2019-8-8,2019,8,8,17,cnj1vw,Real time Face-Detection on the RaspberryPi-4 achieving a frame rate of 15-17 FPS(deep learning),https://www.reddit.com/r/deeplearning/comments/cnj1vw/real_time_facedetection_on_the_raspberrypi4/,shunyaos4ai,1565254792,You can refer to the instructions here: [https://www.instructables.com/id/Real-Time-Face-Detection-on-the-RaspberryPi-4/](https://www.instructables.com/id/Real-Time-Face-Detection-on-the-RaspberryPi-4/) Also you can find the library documentation and APIguide here on github: [https://github.com/shunyaos/shunyaface](https://github.com/shunyaos/shunyaface),5,24
83,2019-8-8,2019,8,8,19,cnk3rt,Collaboration on a research paper,https://www.reddit.com/r/deeplearning/comments/cnk3rt/collaboration_on_a_research_paper/,clean_pegasus,1565261861,I'm working on a research paper on Generative adversarial networks (GANs). Hit me up if you wanna colab.,10,4
84,2019-8-8,2019,8,8,22,cnlwyt,Bridging Microsoft SEAL into TensorFlow,https://www.reddit.com/r/deeplearning/comments/cnlwyt/bridging_microsoft_seal_into_tensorflow/,ybsu,1565271609,Check out this blog about how we bridged Microsoft SEAL into Tensorflow! We hope that this will help bring new privacy preserving features to machine learning and more! [https://medium.com/dropoutlabs/bridging-microsoft-seal-into-tensorflow-b04cc2761ad4](https://medium.com/dropoutlabs/bridging-microsoft-seal-into-tensorflow-b04cc2761ad4),0,2
85,2019-8-8,2019,8,8,22,cnm1gg,Medical Classification (non-image data),https://www.reddit.com/r/deeplearning/comments/cnm1gg/medical_classification_nonimage_data/,moizsawan,1565272206,Hi all! I want to know of state of the art models for predictions on medical data (non image). Thanks.,0,0
86,2019-8-8,2019,8,8,23,cnmcon,[Research] An End-to-End Empathetic Chatbot,https://www.reddit.com/r/deeplearning/comments/cnmcon/research_an_endtoend_empathetic_chatbot/,cdossman,1565273647,"**Abstract:**  In this paper, we present an end-to-end empathetic conversation agent CAiRE. Our system adapts TransferTransfo (Wolf et al., 2019) learning approach that fine-tunes a large-scale pre-trained language model with multi-task objectives: response language modeling, response prediction and dialogue emotion detection. We evaluate our model on the recently proposed empathetic-dialogues dataset (Rashkin et al., 2019), the experiment results show that CAiRE achieves state-of-the-art performance on dialogue emotion detection and empathetic response generation. 

[https://medium.com/ai%C2%B3-theory-practice-business/meet-caire-an-end-to-end-empathetic-conversation-chatbot-2e34abf84afc](https://medium.com/ai%C2%B3-theory-practice-business/meet-caire-an-end-to-end-empathetic-conversation-chatbot-2e34abf84afc)",0,3
87,2019-8-9,2019,8,9,5,cnrcym,Neural network inference pipeline for videos in Tensorflow,https://www.reddit.com/r/deeplearning/comments/cnrcym/neural_network_inference_pipeline_for_videos_in/,alseambusher,1565295526,"Just as we saw a huge influx of images in the past decade or so, we are now seeing a lot of videos being produced on social media. The need to understand and moderate videos using machine learning has never been greater.

In this post, I will show you how to build an efficient pipeline to processes videos in Tensorflow.


https://lifepluslinux.blogspot.com/2019/08/neural-network-inference-pipeline-for.html",0,23
88,2019-8-9,2019,8,9,6,cnsi1x,Gamescom 2019  Game Tech Community Event,https://www.reddit.com/r/deeplearning/comments/cnsi1x/gamescom_2019_game_tech_community_event/,CGAmonster,1565300415,,0,1
89,2019-8-9,2019,8,9,7,cnt00p,Is my assigned task even possible?,https://www.reddit.com/r/deeplearning/comments/cnt00p/is_my_assigned_task_even_possible/,ArmoredBaguette,1565302635,"Hello everyone, i'm a French IT student working as an intern for a very small startup, and long story short, my goal is to build a system that reliably recognizes individual faces in real time. 

After a lot of tinkering, i'm using a custom fine-tuned VGG FACE with Keras. 

&amp;#x200B;

My question is the following: without going into details, is it possible to obtain quick reliable face recognition with this ""cocktail"" (Keras, Fine-tuning, and VGG face).

If yes, what should i look out for?

If No, are there better alternatives?",18,10
90,2019-8-9,2019,8,9,10,cnvkej,Getting Started to Achieving Kaggle Kernels GM Rank #4 in just 9 months | Interview with Shivam Bansal,https://www.reddit.com/r/deeplearning/comments/cnvkej/getting_started_to_achieving_kaggle_kernels_gm/,init__27,1565315503,"Interview with Shivam Bansal, Kernels GM Ranked 4: 

Did you know Shivam made it to the Top 4 Rankings in Kernels after just 9 months of getting started on Kaggle!

We talk about his journey into Data Science, Kaggle. Shivam also shares his pipeline and motivation behind writing kernels. 

(Audio) https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Kernels-GM-Shivam-Bansal-e4qcbe/a-ak0id3

(Video) https://www.youtube.com/watch?v=0K4C1FMVbgQ",0,3
91,2019-8-9,2019,8,9,11,cnvoey,Getting Started to Achieving Kaggle Kernels GM &amp; Rank #2 in just 9 months | Interview with Shivam Bansal,https://www.reddit.com/r/deeplearning/comments/cnvoey/getting_started_to_achieving_kaggle_kernels_gm/,init__27,1565316081,"Interview with Shivam Bansal, Kernels GM Ranked 4: 

Did you know Shivam made it to the Top 2 Rankings in Kernels after just 9 months of getting started on Kaggle!

We talk about his journey into Data Science, Kaggle. Shivam also shares his pipeline and motivation behind writing kernels. 

(Audio) https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Kernels-GM-Shivam-Bansal-e4qcbe/a-ak0id3

(Video) https://www.youtube.com/watch?v=0K4C1FMVbgQ",0,14
92,2019-8-9,2019,8,9,20,co17dr,How AI Is Transforming The Healthcare Sector,https://www.reddit.com/r/deeplearning/comments/co17dr/how_ai_is_transforming_the_healthcare_sector/,MachineLearning001,1565350914,,0,2
93,2019-8-9,2019,8,9,21,co1w38,Explicit construction of manifolds in latent space.,https://www.reddit.com/r/deeplearning/comments/co1w38/explicit_construction_of_manifolds_in_latent_space/,nefrpitou,1565354820,"GANs and VAEs sample from a known distribution like Unit Gaussian and map dataset to it.

I however, want to explicitly map certain images/inputs to exact points in the latent space. For example, if we have a 0-mean 1-std multi-variate gaussian, I want to be able to map certain images in my dataset, explicitly to 0-mean 0.5-std of the latent space. 

Extending the idea further, I want to construct a hypersphere or hypercube in latent n-dimensional space, and want to place certain datapoints at the vertices of this manifold. The rest of the datapoints should be mapped accordingly, based on the training process and the pre-placed datapoints.

Are there any theoretical papers that you know of, that have aimed to do this?",5,12
94,2019-8-9,2019,8,9,23,co2syf,(Video demos) How We Construct a Virtual Beings Brain with Deep Learning,https://www.reddit.com/r/deeplearning/comments/co2syf/video_demos_how_we_construct_a_virtual_beings/,nahuak,1565359417,,0,13
95,2019-8-10,2019,8,10,1,co4wrn,How to annotate/augment images for multi-class semantic segmentation?,https://www.reddit.com/r/deeplearning/comments/co4wrn/how_to_annotateaugment_images_for_multiclass/,74throwaway,1565368801,"I'm confused as to how to annotate images with different classes of objects in them. For example, in ""a simple example"" at: https://imgaug.readthedocs.io/en/latest/source/examples_segmentation_maps.html

The original `segmap` variable has values of 0, 1,..., 5. Yet after the augmentation, if I were to inspect the values of the pixels in column 5 of the `cells` after the augmentation (line `cells.append(segmap_aug.draw(size=image_aug.shape[:2]))`), each pixel takes on rgb values, such as (200,50,50), instead of a single number from 0-5

Aren't the augmented images supposed to have values between 0-5 instead of rgb values if I wanted to use those augmented images directly within a semantic segmentation model, such as Unet from here: https://github.com/zhixuhao/unet ?",0,5
96,2019-8-10,2019,8,10,7,co9bec,"Here are the tools which have lead to the wildfire of deepfakes on the internet. I have used both and did a comparision between the two. Have you checked out the softwares yet? If yes, what did you think?",https://www.reddit.com/r/deeplearning/comments/co9bec/here_are_the_tools_which_have_lead_to_the/,deepfakeblue,1565388380,,0,2
97,2019-8-10,2019,8,10,8,coacyt,Need help building an NLP model,https://www.reddit.com/r/deeplearning/comments/coacyt/need_help_building_an_nlp_model/,gulzainali,1565393588,"I am buidling a deep learning model which can generate relevant questions about businesses. I have a dataset of business reviews. Model should be able to build some questions like ""did you like donut"" or ""how good was the dinner "". I wanted to know if i can find any helpful tutorial/code/paper implementation on building such a model. 

I only know how to build a sequence to sequence model. It would be of great help if you can direct me to a good resource or guide me through the solution in the comments. Thanks in advance!",6,9
98,2019-8-10,2019,8,10,13,codp6e,Any good alternative to deeplearning.net?,https://www.reddit.com/r/deeplearning/comments/codp6e/any_good_alternative_to_deeplearningnet/,pleaseThisNotBeTaken,1565412638,"I just started following [deeplearning.net](https://deeplearning.net) tutorials to start with deeplearning, however, they use Theano and from what I've learnt is that it's effectively dead (the team announced they'll stop any major development back in 2017). I believe those were excellent tutorials for getting started and I just wanted an opinion from people here on what would be a good alternative for the site that uses frameworks like PyTorch, CNTK, Tensorflow.",3,1
99,2019-8-10,2019,8,10,16,coevrf,We developed arrow color detection using transfer learning and online training. For application in self driving mini rovers. It was really fun and exciting.,https://www.reddit.com/r/deeplearning/comments/coevrf/we_developed_arrow_color_detection_using_transfer/,bathon,1565420838,,9,34
100,2019-8-10,2019,8,10,16,cof614,UNet and Segmentation In-depth Explanation,https://www.reddit.com/r/deeplearning/comments/cof614/unet_and_segmentation_indepth_explanation/,bluesky314,1565422929,"Hey guys, I have been working in DL research for about a year and have found very less info explaining how segmentation works in neural networks, especially compared to classification. Beginners have much trouble wrapping their head around how the network is able to segment an entire image, so I made a video to explain what goes on:

[https://www.youtube.com/watch?v=NzY5IJodjek](https://www.youtube.com/watch?v=NzY5IJodjek)

&amp;#x200B;

The people I've shown it to like it and some stuff is not explained anywhere. If you're working on segmentation, it well worth the watch. Feedback and likes appreciated!",1,3
101,2019-8-10,2019,8,10,16,cofa33,[P] Simple PyTorch implementation of Language Model,https://www.reddit.com/r/deeplearning/comments/cofa33/p_simple_pytorch_implementation_of_language_model/,lyeoni,1565423809,"A step-by-step tutorial on how to implement and adapt recurrent language model to Wikipedia text.

A pre-trained BERT, XLNET is publicly available ! But, for NLP beginners, like me, It could be hard to use/adapt after full understanding. For them, I covered whole, end-to-end implementation process for language modeling, using recurrent network, we already know. + do not use torchtext !

I hope that this repo can be a good solution for people who want to have their own language model :)

https://github.com/lyeoni/pretraining-for-language-understanding",0,1
102,2019-8-10,2019,8,10,17,cofbs7,ManiFold Mixup,https://www.reddit.com/r/deeplearning/comments/cofbs7/manifold_mixup/,bluesky314,1565424149,"What do people think about the new regulariser Manifold Mixup explained well here: [https://www.youtube.com/watch?v=1L83tM8nwHU](https://www.youtube.com/watch?v=1L83tM8nwHU)?

&amp;#x200B;

Seems like a great idea",0,4
103,2019-8-10,2019,8,10,21,cohmch,"Hi Everyone, I am planning to build a Deep Learning Machine with config mentioned in the image. Is this config good enough, any suggestion is welcomed. Help me out.",https://www.reddit.com/r/deeplearning/comments/cohmch/hi_everyone_i_am_planning_to_build_a_deep/,mayurat22,1565441339,"&amp;#x200B;

https://i.redd.it/lt25t2eramf31.png",4,1
104,2019-8-10,2019,8,10,22,coi3is,"""Difference Between Artificial Intelligence, Machine Learning and Deep Learning""",https://www.reddit.com/r/deeplearning/comments/coi3is/difference_between_artificial_intelligence/,susanvilleula1,1565444052,,0,3
105,2019-8-10,2019,8,10,23,coifgi,The Modularity of Deep Learning,https://www.reddit.com/r/deeplearning/comments/coifgi/the_modularity_of_deep_learning/,MasterSnipes,1565445830,"[https://jinayjain.code.blog/2019/08/07/the-modularity-of-deep-learning/](https://jinayjain.code.blog/2019/08/07/the-modularity-of-deep-learning/)

I decided to write a post on how extensible and modular the process of training neural networks is, all glued together with the power of backpropagation. It's quite amazing how quickly people can design and iterate on models and this facet of deep learning doesn't appear in many other fields. I thought I'd discuss that in a blogpost so here it is!

I'm new to blogging so any feedback or even a quick follow is appreciated!",0,3
106,2019-8-10,2019,8,10,23,coipcy,"[PSA] ""Deep Learning Cookbook"" on the Machine Learning ebook bundle ($1 - ending in 2 days)",https://www.reddit.com/r/deeplearning/comments/coipcy/psa_deep_learning_cookbook_on_the_machine/,wazuddin,1565447274,,0,1
107,2019-8-11,2019,8,11,0,cojc1u,Reminder: Deep Learning Cookbook on the Machine Learning book pack. Ends in two days,https://www.reddit.com/r/deeplearning/comments/cojc1u/reminder_deep_learning_cookbook_on_the_machine/,tomsmith434,1565450480,,0,1
108,2019-8-11,2019,8,11,0,cojmab,Reminder: Deep Learning Cookbook on the Machine Learning book pack. Ends in two days,https://www.reddit.com/r/deeplearning/comments/cojmab/reminder_deep_learning_cookbook_on_the_machine/,tomsmith434,1565451863," O'Reilly's books are valuable and so is this bundle. The relevant title is on the first tier anyway for $1 so I thought some would appreciate the reminder to quickly grab it.

&amp;#x200B;

[Here](https://twitter.com/Deeplearningthem/status/1160158936881946628)",6,35
109,2019-8-11,2019,8,11,0,cojqh9,Working with large data,https://www.reddit.com/r/deeplearning/comments/cojqh9/working_with_large_data/,sambalshikhar,1565452448, I am working on a project for document type classification.I have approc 400k training samples.I have a 920mx 4gb gpu which is inefficient.The data size is around 100gb which is huge so no colab in action.I am using batches of 16 as that is the max my gpu can fit.What are ur suggestions?,4,3
110,2019-8-11,2019,8,11,2,cokomo,Help with DL framework.,https://www.reddit.com/r/deeplearning/comments/cokomo/help_with_dl_framework/,ragingpot,1565456943,"I'm working on writing a DL framework. I'm looking for an implementation of a convolutional layer in numpy. Also if anyone here has an idea about implemention an autograd package from the ground up, hell would be appreciated. Not looking for any blazing fast performance, just some inside knowledge about how frameworks work.",3,0
111,2019-8-11,2019,8,11,2,col1d8,"Can we discuss exposure bias/teacher forcing, the motivation of the ACL 2019 best paper?",https://www.reddit.com/r/deeplearning/comments/col1d8/can_we_discuss_exposure_biasteacher_forcing_the/,cloudygoose,1565458562,"The ACL 2019 best paper ([https://arxiv.org/pdf/1906.02448.pdf](https://arxiv.org/pdf/1906.02448.pdf)), brings out the exposure bias/teacher forcing again, an important topic in language modeling/language generation.

The point I want to make is, I believe a good way to do research is that you FIRST show me some problem is really serious, and THEN you propose a way to solve it. In the introduction part, they provide a reasoning about their motivations, it makes sense, but it' does not concretely show the problem is serious. As we know, most MLE-trained STOA NMT models are doing well at their job.

So, let's assume exposure bias/teacher forcing is really bad for language generation, can we use a simple way to show it?

I design the following experiment, take a MLE-trained LSTM-LM on some data-set, you feed three types of history prefix sequence to it. And let the model do sampling and complete the sentence.

(1) The ground truth data prefix.

(2) Samples from the model itself.

(3) Completely random sequence, totally rubbish.

These three type of history gives different level of training-inference discrepancy. Now, I expect the quality of the completion samples should be (1) &gt; (2) &gt;&gt; (3), do you agree?

This is the samples I get:

https://i.redd.it/rzm5nqhwpnf31.png

My observation is that, I don't see very significant sample quality difference. Even for the random input, the model quickly start to generate fairly reasonable samples.

This experiment make me seriously question ""is exposure bias really a big problem?"" 

If you also feel interested, please read our paper [https://arxiv.org/pdf/1905.10617.pdf](https://arxiv.org/pdf/1905.10617.pdf) , and comments are welcome.

I think this is also similar to the batch-norm case, you just CLAIM ""covariate shift"" is really bad, you propose batch-norm to solve it, you get good gains. That's great, but does ""covariate shift"" really exist? May not. See [https://arxiv.org/pdf/1805.11604.pdf](https://arxiv.org/pdf/1805.11604.pdf)

Final note, in section 5.7 of the ACL paper, they claimed the performance gain is from solving exposure bias, but I really don't see it. Their arguments can convince me their model is better than baseline, but I don't see how it's related to exposure bias.

And I'm not saying the ACL paper is a bad paper, it's great they get solid gains. I'm just suggesting we should be careful about validating our research motivations.",1,3
112,2019-8-11,2019,8,11,3,colswv,RTX 2080 With Intel i7 8700k !,https://www.reddit.com/r/deeplearning/comments/colswv/rtx_2080_with_intel_i7_8700k/,mayurat22,1565462235,Will RTX 2080 work with full efficiency if tied up with i7-8700k or the performance of the graphic card will reduce because of pcie lane support Intel i7  ?,2,0
113,2019-8-11,2019,8,11,7,coobpx,GPU Tensor Cores vs. FLOPs vs. Memory Bandwidth,https://www.reddit.com/r/deeplearning/comments/coobpx/gpu_tensor_cores_vs_flops_vs_memory_bandwidth/,jahoho,1565474529,"In this relatively popular [blog](https://timdettmers.com/2019/04/03/which-gpu-for-deep-learning/) the author Tim Dettmers explains that when choosing optimal GPU for Convolutional Neural Network architecture, priority should follow: **Tensor Cores &gt; FLOPs &gt; Memory Bandwidth &gt; 16-bit capability**

&amp;nbsp;

With that in mind, would you choose an RTX 2080 Max-Q over an RTX 2070, mainly because it has 28% more tensor cores, although it also has 14% less FLOPs and 14% less Memory Bandwidth than the 2070?

&amp;nbsp;

RTX 2080 Max Q:
- 368 Tensor Cores
- 12.89 TFLOPs (FP16)
- 384 GB/s Memory Bandwidth

&amp;nbsp;

RTX 2070:
- 288 Tensor Cores
- 14.93 TFLOPs (FP16)
- 448 GB/s Memory Bandwidth",3,2
114,2019-8-11,2019,8,11,8,cop826,Tool for visualizing the training of neural networks in a web browser?,https://www.reddit.com/r/deeplearning/comments/cop826/tool_for_visualizing_the_training_of_neural/,notreallysocool,1565479148,"I am aware of TensorSpace.js but AFAIK, it can only visualize a pretrained model. I think it would really helpful if we could visualize the neural network while training (eg: we could see how each weights value changes over epochs and it could provide many other useful visualizations). It would be a really useful tool for debugging. Is there already any tool like this? I am not aware of any such tool.",1,1
115,2019-8-11,2019,8,11,11,cor6s5,Simple PyTorch implementation of Language Model on Wikipedia text,https://www.reddit.com/r/deeplearning/comments/cor6s5/simple_pytorch_implementation_of_language_model/,lyeoni,1565490240," A step-by-step tutorial on how to implement and adapt recurrent language model to Wikipedia text.

A pre-trained BERT, XLNET is publicly available ! But, for NLP beginners, like me, It could be hard to use/adapt after full understanding. For them, I covered whole, end-to-end implementation process for language modeling, using recurrent network, we already know. + do not use torchtext !

I hope that this repo can be a good solution for people who want to have their own language model :)

[https://github.com/lyeoni/pretraining-for-language-understanding](https://github.com/lyeoni/pretraining-for-language-understanding)",3,20
116,2019-8-11,2019,8,11,12,coru9l,What is a Neural Network - Deep learning chapter1. Using neural nets to ...,https://www.reddit.com/r/deeplearning/comments/coru9l/what_is_a_neural_network_deep_learning_chapter1/,poop2u,1565494080,,19,0
117,2019-8-11,2019,8,11,13,cos80u,A good gpu vs a 16gb ram,https://www.reddit.com/r/deeplearning/comments/cos80u/a_good_gpu_vs_a_16gb_ram/,susmit410,1565496382,"I am a newbie to deep learning i don't know any gpu optimizations however I have 16gb ram pc which is fairly good in my opinion to run simple classification algorithms and dqn algos.
The pc has inbuilt gpu too,am not sure tho would i need a gpu ??
Pls help!",9,0
118,2019-8-11,2019,8,11,14,cot4mx,Weakly Supervised Deep Detection Networks,https://www.reddit.com/r/deeplearning/comments/cot4mx/weakly_supervised_deep_detection_networks/,Alkadian,1565502365,,1,4
119,2019-8-11,2019,8,11,20,covh7d,Image Segmentation: Why do UNET outperform sliding-window approaches?,https://www.reddit.com/r/deeplearning/comments/covh7d/image_segmentation_why_do_unet_outperform/,automatedredditor,1565521529,"I'm writing a thesis that heavily focuses on semantic segmentation of biomedical images.

I'm reviewing different segmentation approaches, identifying two main approach branches:

* A **sliding window**\-like approach: a classification network is used over different patches of original image to reconstruct a pixel-by-pixel estimates of the probability maps.
* A **full-image** approach: like the FCNN and UNET approach, rely on fully convolutional architectures and the upscaling phase is incorporated in the network itself using transposed convolutions.[https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597)

The second approach clearly outperforms the first one. I have a vague hunch on why this happens: my hypothesis is that the transposed-convolution operations, being at their core local operations, force local criteria on the segmentation of close pixels so that pixel contiguity is heavily encouraged in the fully convolutional case.

I do not find this kind of explanation satisfying because of two reasons:

1. I do not have papers or real data to support this: I cannot seem to find any paper on the theme.
2. The sliding-window approach has a built-in form of local consistency as well: if overlapping windows share most of the pixels it's reasonable to think that - given the network is not totally chaotic and shows enough linearity - the outputs would be similar.

Do anyone have a bit of insight or source on any of this? Any contribution, even brainstorming or unsupported hypothesis (like mine) is well appreciated.",8,16
120,2019-8-11,2019,8,11,22,cownr8,"Difference Between Artificial Intelligence, Machine Learning and Deep Learning",https://www.reddit.com/r/deeplearning/comments/cownr8/difference_between_artificial_intelligence/,susanvilleula1,1565529703,,2,0
121,2019-8-12,2019,8,12,0,coy7sn,Any AIs Where You Can Give it A Bunch Of Images And Have It Generate A New Image In The Same Style?,https://www.reddit.com/r/deeplearning/comments/coy7sn/any_ais_where_you_can_give_it_a_bunch_of_images/,BloodyPommelStudio,1565538001,I'm looking for an AI downloadable or online where I can give it 1000s of pieces of art from the same artist and have it generate new and unique pictures with the same style.,5,0
122,2019-8-12,2019,8,12,0,coyei4,Training a Neural Network? Start here!,https://www.reddit.com/r/deeplearning/comments/coyei4/training_a_neural_network_start_here/,0_marauders_0,1565538905,,0,0
123,2019-8-12,2019,8,12,1,coyy4d,Burn Wound Dataset,https://www.reddit.com/r/deeplearning/comments/coyy4d/burn_wound_dataset/,asjad18,1565541513,"Hi, I was thinking about working on burn wound classification for my final year project, but I am unable to find any datasets online. Can someone tell me where I can find the required dataset?
Thanks",0,1
124,2019-8-12,2019,8,12,7,cp3nug,"Which tool do people use to make such figures? Draw.io for the boxes maybe, but what about the input/output images?",https://www.reddit.com/r/deeplearning/comments/cp3nug/which_tool_do_people_use_to_make_such_figures/,Jesper89,1565563704,,17,45
125,2019-8-12,2019,8,12,9,cp55jn,Can I load a Caffe2 model in PyTorch?,https://www.reddit.com/r/deeplearning/comments/cp55jn/can_i_load_a_caffe2_model_in_pytorch/,fieldcady,1565571509,"Does anybody know a way to load a model from the [Caffe2 Model Zoo](https://github.com/caffe2/models) with PyTorch?  I found a [notebook](https://github.com/onnx/tutorials/blob/master/tutorials/Caffe2OnnxExport.ipynb) that supposedly loads the models with ONNX (from which I could presumably get it into pytorch), but the code fails for me (google.protobuf.message.DecodeError: Error parsing message).  I'm still kinda a noob with deep learning, so I would really appreciate some help and/or guidance.  Thanks!!",1,1
126,2019-8-12,2019,8,12,15,cp8ebp,"Interview with Kaggle Kernels Grandmaster Ranked #1, ""Artgor"" Andrew Lukyanenko",https://www.reddit.com/r/deeplearning/comments/cp8ebp/interview_with_kaggle_kernels_grandmaster_ranked/,init__27,1565590386,"Just Released the interview with the King of Kaggle Kernels (currently ranked #1) Grandmaster ""Artgor"": Andrew Lukyanenko

We talk about his journey into DS, his current projects at work, his pipeline, insights, and many tips for writing Kaggle Kernels

[https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Kernels-Grandmaster-1-Artgor--Andrew-Lukyanenko-e4r6du/a-ak53o7](https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Kernels-Grandmaster-1-Artgor--Andrew-Lukyanenko-e4r6du/a-ak53o7)",4,5
127,2019-8-12,2019,8,12,16,cp8tzm,How to use OCR APIs for character recognition,https://www.reddit.com/r/deeplearning/comments/cp8tzm/how_to_use_ocr_apis_for_character_recognition/,RubiksCodeNMZ,1565593338,,0,2
128,2019-8-12,2019,8,12,16,cp90ky,Top Deep Learning Frameworks of 2019,https://www.reddit.com/r/deeplearning/comments/cp90ky/top_deep_learning_frameworks_of_2019/,RubiksCodeNMZ,1565594605,,0,0
129,2019-8-12,2019,8,12,17,cp9pah,Machine Learning and Data Analysis ebook bundle is ending in about 9 hours,https://www.reddit.com/r/deeplearning/comments/cp9pah/machine_learning_and_data_analysis_ebook_bundle/,gdotlester,1565599765,"O'Reilly's book bundle. It is valuable imo. The deep learning title is on the first tier for $1 so I thought of sharing.

&amp;#x200B;

[Humble Bundle](https://twitter.com/Thedeeplearningmachine/status/1160158936881946628)",1,18
130,2019-8-12,2019,8,12,20,cpb9p2,Strengthening Cybersecurity with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/cpb9p2/strengthening_cybersecurity_with_artificial/,MachineLearning001,1565610384,,0,0
131,2019-8-12,2019,8,12,21,cpc1qb,Trends in Natural Language Processing,https://www.reddit.com/r/deeplearning/comments/cpc1qb/trends_in_natural_language_processing/,MusingEtMachina,1565614776,,0,4
132,2019-8-12,2019,8,12,22,cpci2f,Best of AI Articles of July,https://www.reddit.com/r/deeplearning/comments/cpci2f/best_of_ai_articles_of_july/,BastouBab,1565617103,"Hi All!  
These are my 10 favorite AI articles and news published in July. They talk about autonomous driving, artificial intelligence, another GAN application.  
What are your best news and articles of the month of July?  
[https://blog.sicara.com/07-2019-best-ai-new-articles-this-month-3e1fa3f6c321](https://blog.sicara.com/07-2019-best-ai-new-articles-this-month-3e1fa3f6c321)",0,8
133,2019-8-13,2019,8,13,1,cpeflp,Building a State of the Art Bacterial Classifier with Paperspace Gradient and Fast.ai,https://www.reddit.com/r/deeplearning/comments/cpeflp/building_a_state_of_the_art_bacterial_classifier/,dkobran,1565626036,,0,24
134,2019-8-13,2019,8,13,1,cpeswz,DenseNet (Medical Classification),https://www.reddit.com/r/deeplearning/comments/cpeswz/densenet_medical_classification/,moizsawan,1565627625,"I have a classification problem where I have an image, age and the weight as features. How can I use DenseNet in the following manner:
-&gt; For example 3 Dense Blocks
-&gt; Input to the first Dense Block = Image
-&gt; Input to the second Dense Block = Output of first Dense Block and the age
-&gt; Input to the third Dense Block = Output of the second Dense Block and the weight
Can DenseNet be used in the following manner? Basically a numeric feature input to a Dense Block.",0,1
135,2019-8-13,2019,8,13,1,cpezmd,DenseNet (Medical classification),https://www.reddit.com/r/deeplearning/comments/cpezmd/densenet_medical_classification/,moizsawan,1565628423,"I have a classification problem where I have an image, age and the weight as features. How can I use DenseNet in the following manner:
For example 3 Dense Blocks.
Input to the first Dense Block = Image.
Input to the second Dense Block = Output of first Dense Block and the age.
Input to the third Dense Block = Output of the second Dense Block and the weight.
Can DenseNet be used in the following manner? Basically a numeric feature input to a Dense Block.",0,1
136,2019-8-13,2019,8,13,4,cpgvq5,Histopathologic Cancer Detection with Transfer Learning using Pytorch,https://www.reddit.com/r/deeplearning/comments/cpgvq5/histopathologic_cancer_detection_with_transfer/,asuagar,1565636509,,0,3
137,2019-8-13,2019,8,13,5,cphwqe,Plant Disease Detector with Fastai,https://www.reddit.com/r/deeplearning/comments/cphwqe/plant_disease_detector_with_fastai/,imskrai,1565640890,"I have created a Web Application for detecting plant diseases.

Using Fast.ai which sits on top of Pytorch with Resnet34 pre-trained model!

Used Plant Village Dataset, Trained it on Google Cloud Platform and deployed it on AWS Elastic Beans!

Accuracy 99.654%

Fork or Star  on GitHub: https://github.com/imskr/Plant_Disease_Detection",0,1
138,2019-8-13,2019,8,13,9,cpl8ou,How to preprocess labeled images for multi-class semantic segmentation?,https://www.reddit.com/r/deeplearning/comments/cpl8ou/how_to_preprocess_labeled_images_for_multiclass/,74throwaway,1565656137,"Let's say I have 100 training images, each of size 512x512. I was able to one-hot encode them using `to_categorical` in Keras with

    numclasses=3 #should this be 4?
    masks_one_hot=to_categorical(maskArr,numclasses)

where `maskArr` is a 100x512x512x1, and `masks_one_hot` is 100x512x512x3. I then saved each image in `masks_one_hot` using `imwrite` into `data/input/label_oneHot` (the non-mask images are in `data/input/image`)

I then performed augmentation:

    data_gen_args = dict(rotation_range=30, width_shift_range=0.05, horizontal_flip=True, vertical_flip=True, ...)
    myGeneratorDefects = trainGeneratorOneHot(20,'data/input','image','label_oneHot',data_gen_args,save_to_dir = ""data/input/aug"",flag_multi_class = True,num_class = numclasses,target_size = (512,512))
     num_batch=3
     for i,batch in enumerate(myGeneratorDefects):
         if(i &gt;= num_batch):
             break

Was I supposed to include `class_mode=""categorical""`? When I tried to, I got some kind of error, I believe it was an `IndexError` with the Unet

Each augmented `mask` then had size of 512x512x3 and had values ranging from 0-255. I then converted it to a 512x512x1 array where each value ranged from 0-2, and then I one-hot encoded it again using `to_categorical`",0,2
139,2019-8-13,2019,8,13,12,cpn6wp,Making a generic line detection algorithm,https://www.reddit.com/r/deeplearning/comments/cpn6wp/making_a_generic_line_detection_algorithm/,muaz65,1565665708,"I am working on soccer field cordinate translation to a (100,100) 2d plane.

The task involves translating original field coordinates of players and ball from the live soccer stream to a 2d cartesian plane. 

The solution proposed in literature is to detect field lines and find the distance of players from the lines so that we can map the distance to our 2d cordinate system. After segmenting the field and removing the noise from the frames the obvious method was either to apply Hough lines or to make contours after using some edge detectors like canny.

Most of the existing literature use the same methodology  in order to segment/detect soccer field lines. But none of them seems to work in a generic manner. 

Hough lines, a cv2 library implementation of hough transform is a parameter specific function. Which doesn't work properly on different camera angles. Contours fails due to the width of line making variations in shape of contours. I tried some deep learning classiers for line Detection but that also failed and to train my own i ll have to label the lines manually which is quite extensive task. I am looking for some generalized line Detection approach which can work for any camera view. Any opinion on the matter is appreciated.",3,1
140,2019-8-13,2019,8,13,15,cpp9ra,Conversational Banking: Future of Banks with Chatbots,https://www.reddit.com/r/deeplearning/comments/cpp9ra/conversational_banking_future_of_banks_with/,MachineLearning001,1565678275,,0,10
141,2019-8-13,2019,8,13,16,cppgpy,[Tutorial] How to perform direct and reverse image search on Flickr30k image data with AquilaDB,https://www.reddit.com/r/deeplearning/comments/cppgpy/tutorial_how_to_perform_direct_and_reverse_image/,iamjbn123,1565679630,,0,1
142,2019-8-13,2019,8,13,16,cppuml,Real-time human action understanding with video data and fully convolutional neural network (Video demo),https://www.reddit.com/r/deeplearning/comments/cppuml/realtime_human_action_understanding_with_video/,nahuak,1565682288,"Hi deep learning redditors,

I'd like to share our most recent human activity recognition video demo at [TwentyBN](https://20bn.com/) with you. The neural network is trained on TwentyBN's [video datasets](https://20bn.com/products/datasets). Check out our most recent newsletter on our efforts in [building a virtual being's brain](http://www.embodiedai.co/issues/a-trip-inside-a-virtual-being-s-brain-with-video-demos-190155).

Feel free to comment below for questions and feedback :)

![video](tw1qqbk076g31 ""TwentyBN's human behavior understanding demo (Credit: TwentyBN)"")",0,46
143,2019-8-13,2019,8,13,17,cpqaov,Computational Neuroscience software project. Looking for talented open source programmers,https://www.reddit.com/r/deeplearning/comments/cpqaov/computational_neuroscience_software_project/,mynercloud,1565685505,"Hello, 

we have a software project for computational neuroscience software. We want to analyze all different kinds of brain and body data using machine learning algorithms. Eventually it will be a huge software library. 

If you have questions, comment under the post or if you are interested or join the discord server for the dev talk [https://discord.gg/EtPghCG](https://discord.gg/EtPghCG). The github repo can be found here [https://github.com/neurapilot/neurapilot](https://github.com/neurapilot/neurapilot)",1,2
144,2019-8-13,2019,8,13,18,cpqx8k,Free Cloud GPU Credits For Deep Learning,https://www.reddit.com/r/deeplearning/comments/cpqx8k/free_cloud_gpu_credits_for_deep_learning/,whitezl0,1565689953,"Hi, I am offering free credits for 1080Ti GPU instances for deep learning purposes  more than 24hrs for free

I am working on https://www.tensorpad.com/  developing cloud infrastructure for machine learning.

Part of our computational capacity is idle; hence, were offering credits at a free and discounted rate, so that data scientists can benefit from the resources available, and work on neural networks.

Specs: 
 60GB of RAM, 4 CPUs, 1080Ti GPU 
 JupyterLab environment with access to the terminal 
 Pre-installed Tensorflow, Keras, and other ML frameworks

You can access the free credits by signing up (https://dashboard.tensorpad.com/ and redeeming ""reddit500"" promo code in the Billing tab (https://dashboard.tensorpad.com/billing).

For any questions, please contact us here, through support@tensorpad.com, or the Intercom on the site.",0,11
145,2019-8-13,2019,8,13,20,cpro3w,[ OpenCV/DL Question ] Realtime scene analysis/detection glasses,https://www.reddit.com/r/deeplearning/comments/cpro3w/opencvdl_question_realtime_scene/,_whitezetsu,1565694887," So I am a final year CS student working on my FYP which is basically glasses for visually impaired people.  
The thing is that we haven't started ML yet, since it's supposed to to be saved for last semester.  
The basic proposal was to use a nVidia x2 to make a path finder for the blind and guide it using voice navigation but it was converted to An android based glasses capable of processing the image \[ using phone/realtime\] and tell the person what's happening in its surrounding.  
Since I am as noob as it gets with ML/DL or CV and so is my partner, can anybody guide  
1: What technologies do we need to learn?  
2: What approach should we use?  
3: Is it possible to do a real time image analysis on such a small device?

P.S: I am good with android programming and I've completed my advanced python course recently if it helps.",0,0
146,2019-8-13,2019,8,13,21,cpsa4f,Awesome Artificial Intelligence Research and Projects on Computer Vision News (with codes!) August 2019,https://www.reddit.com/r/deeplearning/comments/cpsa4f/awesome_artificial_intelligence_research_and/,Gletta,1565698407,"The August issue of Computer Vision News: 38 pages about AI and Deep Learning through both research and practical applications.

Newly improved graphics for easier reading. Don't miss the review of the new Google Research paper and the interview with Julia Elliott, the leader of the competitions team at Kaggle.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019August/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-august-pdf/)

Subscribe for free on page 38.

&amp;#x200B;

https://i.redd.it/ip5r39enj7g31.jpg",0,1
147,2019-8-13,2019,8,13,21,cpsju5,Energy-Efficient Load Balancing in Wireless Sensor Network Matlab | Project Query,https://www.reddit.com/r/deeplearning/comments/cpsju5/energyefficient_load_balancing_in_wireless_sensor/,flyhighwithai,1565699842,,0,1
148,2019-8-14,2019,8,14,3,cpwtsb,Towards Explainable Video Analysis  Visual Attention for Action Recognition,https://www.reddit.com/r/deeplearning/comments/cpwtsb/towards_explainable_video_analysis_visual/,dtransposed,1565719239,"&amp;#x200B;

I am currently researching practical applications of action recognition models with use of attention models. I have decided to share lessons learned from implementing several ideas from research papers in this field. The network learns to classify images from HMDB-51 dataset and creates attention heatmaps which focus on different parts on the image and thus justify model's decision. Heatmaps can be very accurate, to the point that one could probably use them for tracking.

&amp;#x200B;

[Model attends to the relevant part of the video](https://i.redd.it/nj9zulzl99g31.png)

The tutorial contains brief overview of action recognition and visual attention mechanisms. Then I present the network architecture and discuss the results of my project. Additionally, I include github repo with my implementation.

[Here are the results!](https://dtransposed.github.io/blog/Action-Recognition-Attention.html)

I hope you guys find it interesting!",0,8
149,2019-8-14,2019,8,14,7,cq08p1,TensorFlow in Practice Specialization  Build high value-high demand skills which will boost your career and earning growth ,https://www.reddit.com/r/deeplearning/comments/cq08p1/tensorflow_in_practice_specialization_build_high/,internetdigitalentre,1565733933,[removed],0,1
150,2019-8-14,2019,8,14,7,cq0s64,Game Tech Machine Learning Demo Night,https://www.reddit.com/r/deeplearning/comments/cq0s64/game_tech_machine_learning_demo_night/,CGAmonster,1565736413,,0,1
151,2019-8-14,2019,8,14,9,cq2a3q,How to use flow_from_directory in Keras for multi-class semantic segmentation?,https://www.reddit.com/r/deeplearning/comments/cq2a3q/how_to_use_flow_from_directory_in_keras_for/,74throwaway,1565743827,"Let's say I have 100 training grayscale images and 100 RGB training masks, each of size 512x512. I was able to one-hot encode the masks using `to_categorical` in Keras with the below

    numclasses=3
    masks_one_hot=to_categorical(maskArr,numclasses)

where `maskArr` is a 100x512x512x1, and `masks_one_hot` is 100x512x512x3. 

However, to use `ImageDataGenerator` and `flow_from_directory` using `trainGenerator` from https://github.com/zhixuhao/unet/blob/master/data.py, I tried to save the one-hot encoded training images and then read them using `trainGenerator`. However, I noticed after using `imwrite` on them and then reading them with `imread`, they changed from one-hot encoded 512x512x3 to 512x512x3 RGB images. That is, instead of each channel having a value of 0 or 1, they now range from 0-255

As a result, if I do:

    myGenerator = trainGeneratorOneHot(20,'data/membrane/train','image','label',data_gen_args,save_to_dir = ""data/membrane/train/aug"", flag_multi_class = True,
    num_class = 3, target_size=(512,512,3))

    num_batch=3
    for i,batch in enumerate(myGenerator):
        if(i &gt;= num_batch):
            break

where `trainGeneratorOneHot` is below:

    def trainGeneratorOneHot(batch_size,...class_mode=None, image_class_mode=None):

        image_datagen = ImageDataGenerator(**aug_dict)
        mask_datagen = ImageDataGenerator(**aug_dict)
        image_generator = image_datagen.flow_from_directory(train_path,classes = [image_folder], class_mode = image_class_mode, color_mode = image_color_mode,target_size = target_size, ...)
        mask_generator = mask_datagen.flow_from_directory(train_path, classes = [mask_folder], class_mode = class_mode, target_size = target_size,...)
        train_generator = zip(image_generator, mask_generator)

        for (img,mask) in train_generator:
            img,mask = adjustDataOneHot(img,mask)
            yield (img,mask)

    def adjustDataOneHot(img,mask):
        return (img,mask)


Then I get `ValueError: could not broadcast input array from shape (512,512,1) into shape (512,512,3,1)

How can I fix this?",10,0
152,2019-8-14,2019,8,14,14,cq551o,The Batch: a new weekly newsletter from deeplearning.ai!,https://www.reddit.com/r/deeplearning/comments/cq551o/the_batch_a_new_weekly_newsletter_from/,LegendOfHiddnTempl,1565759613,,0,26
153,2019-8-14,2019,8,14,16,cq6afk,Prediction Explanation of Remaining Useful Life Using LSTM,https://www.reddit.com/r/deeplearning/comments/cq6afk/prediction_explanation_of_remaining_useful_life/,flyhighwithai,1565767420,,1,1
154,2019-8-14,2019,8,14,22,cq9s0p,Performance of Distributed TensorFlow: A Multi-Node and Multi-GPU Configuration,https://www.reddit.com/r/deeplearning/comments/cq9s0p/performance_of_distributed_tensorflow_a_multinode/,ValVish,1565789827,"Hi!

I'd like to share [this technical research](https://www.altoros.com/research-papers/performance-of-distributed-tensorflow-a-multi-node-and-multi-gpu-configuration/) embodies performance evaluation of distributed training with TensorFlow under two scenarios: a multi-node and multi-GPU infrastructure configuration. The benchmark was carried out using the Inception architecture as a neural network model and the Camelyon16 data as a training set. To test training scalability of distributed TensorFlow running on an Amazon EC2 cluster, the g2.2xlarge and g2.8xlarge instance types were employed.",0,4
155,2019-8-14,2019,8,14,22,cq9svh,blackbox: A Python module for parallel optimization of expensive black-box functions,https://www.reddit.com/r/deeplearning/comments/cq9svh/blackbox_a_python_module_for_parallel/,paulknysh,1565789946,,0,5
156,2019-8-14,2019,8,14,22,cq9zk2,Gesture generation by Deep Learning: A demo,https://www.reddit.com/r/deeplearning/comments/cq9zk2/gesture_generation_by_deep_learning_a_demo/,Svito-zar,1565790858,,0,33
157,2019-8-15,2019,8,15,1,cqcggz,Is MSI PS63 suitable for starting with deep learning?,https://www.reddit.com/r/deeplearning/comments/cqcggz/is_msi_ps63_suitable_for_starting_with_deep/,lamnhh,1565801842,"I'm planning to get into DL. I asked my teacher for a laptop recommendation and he said to get one with at least 16GB RAM, 512SSD and at least GTX 1050. He said the machine will be used for practicing setting up environment (due to the fact that Google Colab doesn't allow change of CUDA version) and to test some basic DL algorithm locally.

I searched and found the MSI PS63, with the following specs:
- Intel Core i7-8565U (1.8 GHz - 4.6 GHz / 8MB / 4 cores, 8 threads).
- Intel UHD Graphics 620 / NVIDIA GeForce GTX 1650 Max-Q 4GB GDDR5.
- 512GB SSD M.2 NVMe.
- 16GB DDR4 2666MHz.
More detail [here](https://tiki.vn/laptop-msi-ps63-8sc006vn-core-i78565u-gtx-1650-4gb-win10-156-fhd-ips-hang-chinh-hang-p17595402.html?spid=2453613) (sorry, it's in Vietnamese).

Is this device suitable for my purpose? If not, could you recommend me some other ones? My budget is $1500 and my back can't handle anything more than 3 kilograms.

Thanks a lot.",2,1
158,2019-8-15,2019,8,15,3,cqdn02,Online gpu for deep learning project,https://www.reddit.com/r/deeplearning/comments/cqdn02/online_gpu_for_deep_learning_project/,AhmedZubairGCU,1565806949,I will be starting my final year project in my university. I will have to experiment with many cnn architectures and i will require to use gpu online. In past i have used google colab and kaggle to run my code but they were my personal projects. This is a team project and university might provide financial assistance if we specify beforehand. So is there any better option than google colab or kaggle kernel for such project which you have used and found helpful in the past. If there are charges to use them kindly specify. Thanks,4,0
159,2019-8-15,2019,8,15,4,cqeh3o,Does Deep Learning Still Need Backpropagation?,https://www.reddit.com/r/deeplearning/comments/cqeh3o/does_deep_learning_still_need_backpropagation/,Yuqing7,1565810495,,0,1
160,2019-8-15,2019,8,15,11,cqjt9p,Neural Style Transfer - An Intuitive Explanation,https://www.reddit.com/r/deeplearning/comments/cqjt9p/neural_style_transfer_an_intuitive_explanation/,Automato-YT,1565835858,,2,30
161,2019-8-15,2019,8,15,12,cqkqju,Simple PyTorch implementation of Autoregressive Language Model on Wikipedia text,https://www.reddit.com/r/deeplearning/comments/cqkqju/simple_pytorch_implementation_of_autoregressive/,lyeoni,1565840907,"A step-by-step tutorial on how to implement and adapt **Autoregressive language model** to Wikipedia text.

A  pre-trained BERT, XLNET is publicly available ! But, for NLP beginners,  It could be hard to use/adapt after full understanding. For  them, I covered whole, end-to-end implementation process for language  modeling, using unidirectional/bidirectional LSTM network, we already know.

* **- do not use  torchtext library !**
* **+ include trained model file, training logs**

I hope that this repo can be a good solution for people who want to have their own language model :)

[https://github.com/lyeoni/pretraining-for-language-understanding](https://github.com/lyeoni/pretraining-for-language-understanding)",0,1
162,2019-8-15,2019,8,15,19,cqntvk,"[question] why doesn't this Ubuntu vm feel native (quad i7 @3.4 Ghz, 16 GB, Windows 10, nothing else running) in vmware?",https://www.reddit.com/r/deeplearning/comments/cqntvk/question_why_doesnt_this_ubuntu_vm_feel_native/,vmcuriouss,1565863542,"Here is the image:

* https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b

It's a a fully configured deep learning VM.  It's about 7.7GB.

I am running on:

* an i7 3770 quad core at 3.4 Ghz (not the i7 3770K which has no VT-d virtualization extensions - this one does.)

* 16 GB of DDR 3 ram that is clocked at 1600 mhz.  I benchmarked it at 19000 MB/sec in Novabench.

* The GPU in the host is 1060 GPU with 6 GB of RAM - but the image file I linked above explains ""Due to licensing and installation complications, theres no GPU acceleration / CUDA support provided. So you dont need an Nvidia GPU to try this out, but it also wont take advantage of a GPU if you have one.""

* windows 10.

* I have an SSD.  It's not the fastest but the write speed is 214 MB/seconds and the read speed is 253 MB/seconds in Novabench.

* I turned the swap off entirely on the host system and have plenty of RAM left.

Without anything else running on the host computer, which is a pretty fresh install, this VM doesn't feel native at all when entering full screen, regardless if I give it 2 GB (default), 4 GB, or even 8 GB of memory. I turned on the virtualization extensions in my bios and in the vmware settings too!   I went from giving 1 CPU to 2 CPU's to the guest.  None of this helps.

why deson't it feel ""native""?  I mean things like moving the mouse around, opening a new firefox windows, etc.  It's ""obviously"" a VM.

Is it not supposed to feel native or buttery smooth?  I'm just at a loss.  Additionally, I did an update from within it and it updated Ubuntu files at 500 KB/second!  My connection is several megabytes per second.

I feel like I must be missing something....but what??",1,0
163,2019-8-15,2019,8,15,21,cqp9oa,AOD-Net Image Dehazing &amp; Neural Style Transfer (Tensorflow Tutorial),https://www.reddit.com/r/deeplearning/comments/cqp9oa/aodnet_image_dehazing_neural_style_transfer/,tush1995,1565872765,"Hey everyone!  


I have recently started implementing deep learning papers and writing tutorials and explanations for them. Wanted to share my implementation and blog post for the following with the community.   


Open to suggestions and questions :)  


**1) Neural Style Transfer (Iterative): CNN based approach to generate artwork by combining style and content from different images.**  
Github: [https://github.com/tusharsircar95/Iterative-Neural-Style-Transfer](https://github.com/tusharsircar95/Iterative-Neural-Style-Transfer)  
Medium: [https://medium.com/@tusharsircar95/neural-style-transfer-simplified-b91b990028d](https://medium.com/@tusharsircar95/neural-style-transfer-simplified-b91b990028d)

&amp;#x200B;

[Original image of buildings](https://i.redd.it/6i1sebpnxlg31.png)

[Artwork generated by the trained network by combining the image of buildings with popular paintings](https://i.redd.it/w3mr929bxlg31.png)

&amp;#x200B;

**2) AOD-Net Dehazing: Lightweight end-to-end model to de-haze images**  
Github: [https://github.com/tusharsircar95/All-In-One-Image-Dehazing-Tensorflow](https://github.com/tusharsircar95/All-In-One-Image-Dehazing-Tensorflow)  
Medium: [https://medium.com/@tusharsircar95/all-in-one-image-dehazing-aod-paper-explanation-tensorflow-implementation-bb97f6a6f1ef](https://medium.com/@tusharsircar95/all-in-one-image-dehazing-aod-paper-explanation-tensorflow-implementation-bb97f6a6f1ef) 

[AOD-net Image De-hazing Example](https://i.redd.it/fi6ojt9zwlg31.png)

&amp;#x200B;

Cheers! :D",1,9
164,2019-8-16,2019,8,16,1,cqs66d,Exploring what's new in TensorFlow 2.0,https://www.reddit.com/r/deeplearning/comments/cqs66d/exploring_whats_new_in_tensorflow_20/,dkobran,1565886460,,5,10
165,2019-8-16,2019,8,16,1,cqscfb,Train/Val/Test split for small dataset,https://www.reddit.com/r/deeplearning/comments/cqscfb/trainvaltest_split_for_small_dataset/,arjundupa,1565887215,I am working with a very small dataset of just 550 records. What ratio should I use for the train/val/test split?,3,1
166,2019-8-16,2019,8,16,4,cquc0y,NeurIPS 2019 workshop submission,https://www.reddit.com/r/deeplearning/comments/cquc0y/neurips_2019_workshop_submission/,shidilrzf,1565895802,Does anyone know what should be included in an extended abstract submitted to a workshop in NeurIPS? It's only 3 pages. Should I include the results?,0,2
167,2019-8-16,2019,8,16,10,cqzo4q,"NVIDIA's DALI Library, Image Augmentations | Interview with James Dellinger",https://www.reddit.com/r/deeplearning/comments/cqzo4q/nvidias_dali_library_image_augmentations/,init__27,1565920598,"Interview about Image Augmentations, NVIDIA's DALI Library with James Dellinger. 

We talk about performance, convenience, and comparisons of the frameworks against other frameworks.

&amp;#x200B;

Audio: [https://anchor.fm/chaitimedatascience/episodes/NVIDIAs-DALI-Library--Image-Augmentations-Discussion-Interview-with-James-Dellinger-e4r6f7/a-ak5426](https://anchor.fm/chaitimedatascience/episodes/NVIDIAs-DALI-Library--Image-Augmentations-Discussion-Interview-with-James-Dellinger-e4r6f7/a-ak5426)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=IMOqrf5NPUU](https://www.youtube.com/watch?v=IMOqrf5NPUU)",0,12
168,2019-8-16,2019,8,16,14,cr1vmm,Yoshua Bengio's online talk in University of Tehran.,https://www.reddit.com/r/deeplearning/comments/cr1vmm/yoshua_bengios_online_talk_in_university_of_tehran/,Doctor_who1,1565933047,,2,45
169,2019-8-16,2019,8,16,16,cr34z6,Use Deep Learning to Clone Yourself as a Chatbot (Replika AI Review),https://www.reddit.com/r/deeplearning/comments/cr34z6/use_deep_learning_to_clone_yourself_as_a_chatbot/,LimarcAmbalina,1565941453,,3,5
170,2019-8-16,2019,8,16,17,cr3i53,Strengthening Customer Relations with Facebook Messenger Bot,https://www.reddit.com/r/deeplearning/comments/cr3i53/strengthening_customer_relations_with_facebook/,MachineLearning001,1565944176,,0,0
171,2019-8-16,2019,8,16,19,cr4kj3,"When students get stuck, Socratic can help",https://www.reddit.com/r/deeplearning/comments/cr4kj3/when_students_get_stuck_socratic_can_help/,cmillionaire9,1565951729,,0,7
172,2019-8-16,2019,8,16,19,cr4pyy,Scope of collaborative filtering,https://www.reddit.com/r/deeplearning/comments/cr4pyy/scope_of_collaborative_filtering/,vipul115,1565952774,"Hi there!

  


A newbie data scientist at a consulting firm. I recently got introduced to a problem my client is facing. The problem statement goes something like this: Calculate whether/how likely a physician is likely to give consent to receive advertisement emails based on the choices of other physicians who share similar patterns/tastes with him.

(I have data for physicians who do give consent btw)

Collaborative filtering came to mind instantly. I don't have working experience with them but have heard about it from colleagues and I think this might be a solution to the above said problem.

Wanted to know from this sub whether this would be a good direction to go into for this problem.",1,1
173,2019-8-16,2019,8,16,22,cr6h1x,Why does pytorch have operations like addcmul?,https://www.reddit.com/r/deeplearning/comments/cr6h1x/why_does_pytorch_have_operations_like_addcmul/,kjarvind,1565962635,Wondering why pytorch has primitive math ops such as torch.addcmul for things like tensor 1*tensor2 ?,0,1
174,2019-8-16,2019,8,16,23,cr746z,Chatbot with tensorflow,https://www.reddit.com/r/deeplearning/comments/cr746z/chatbot_with_tensorflow/,destroyer2047,1565965698," 

So i was learning from an online tutorial on how to make a chatbot using tensorflow . link - https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/transformer\_chatbot.ipynb#scrollTo=\_B147qKb\_0ks

but there is a problem while running the transformer def which i am not able to solve. Can anyone recommend me another tutorial(who's code actually works because i have encountered this problem in another tutorial) or solve the problem?",7,3
175,2019-8-17,2019,8,17,0,cr85zh,Deep learning model optimization,https://www.reddit.com/r/deeplearning/comments/cr85zh/deep_learning_model_optimization/,aminehy,1565970263,"Have you Optimized your Deep Learning Model Before Deployment? by M. Amine Hadj-Youcef, Ph.D. https://link.medium.com/yYztTgyncZ",0,1
176,2019-8-17,2019,8,17,1,cr8y7p,Japanese team developing tsunami scale damage forecaster with help of AI,https://www.reddit.com/r/deeplearning/comments/cr8y7p/japanese_team_developing_tsunami_scale_damage/,stevevaius,1565973681,,0,9
177,2019-8-17,2019,8,17,3,crakjs,Transfer Learning in PyTorch C++ API on Dogs vs Cas (Blog 06 in the PyTorch C++ Series - using ResNet18),https://www.reddit.com/r/deeplearning/comments/crakjs/transfer_learning_in_pytorch_c_api_on_dogs_vs_cas/,Kushashwa,1565980778,,0,1
178,2019-8-17,2019,8,17,3,craky5,New Blog Release: Transfer Learning using PyTorch C++ API on Dogs vs Cats (ResNet18 Model),https://www.reddit.com/r/deeplearning/comments/craky5/new_blog_release_transfer_learning_using_pytorch/,Kushashwa,1565980824,,0,1
179,2019-8-17,2019,8,17,3,craq4c, Dual pane File Manager for Training Data: old school meets AI in Supervisely,https://www.reddit.com/r/deeplearning/comments/craq4c/dual_pane_file_manager_for_training_data_old/,tdionis,1565981485,,0,0
180,2019-8-17,2019,8,17,4,crazyw,hi i would like some help in understand a error that i m having in predicting a model,https://www.reddit.com/r/deeplearning/comments/crazyw/hi_i_would_like_some_help_in_understand_a_error/,octdubois,1565982702,"i m fairly new to deep learning...i managed to get a script to save a model and i would like to test it by passing some image into it bbut for some reason it keeps on returning errors that i dont see how to debug

https://i.redd.it/1j87uj9t0vg31.png

this is the link to the model : [https://www.kaggle.com/emmarex/plant-disease-detection-using-keras/comments](https://www.kaggle.com/emmarex/plant-disease-detection-using-keras/comments) 

&amp;#x200B;

i tried various ways to transform the image into array but same errors...any help would be greatly appreciated",2,0
181,2019-8-17,2019,8,17,5,crbrr6,Aging Evolution for Neural Architecture Search Explained!,https://www.reddit.com/r/deeplearning/comments/crbrr6/aging_evolution_for_neural_architecture_search/,HenryAILabs,1565986222,[https://youtu.be/y0UvVB8k9rI](https://youtu.be/y0UvVB8k9rI),0,5
182,2019-8-17,2019,8,17,7,crdcp3,Team Name for Gastroenterology DL Research Lab,https://www.reddit.com/r/deeplearning/comments/crdcp3/team_name_for_gastroenterology_dl_research_lab/,InGutWeTrust,1565993594,"We all know the most important part of DL research is coming up with cool names for our projects or teams. Well, my research group is currently struggling coming up with a team name. We are mostly doing computer vision research to aid histopathology-based diagnoses of pediatric gastrointestinal diseases. We have a few naming ideas, but would like to crowd-source it out to get some more feedback:

- Gut AI
- Gut Intelligence
- Gut AIDD (AI for Digestive Diseases)
- Giga Gut
- DeepGut

You can see a common theme in these names... We want it to sound like an academic research group and not like a startup company. I'll post each name below and please upvote, downvote, and comment as you wish. Thanks!",17,8
183,2019-8-17,2019,8,17,8,crekq6,What made backpropagation feasible for deep learning?,https://www.reddit.com/r/deeplearning/comments/crekq6/what_made_backpropagation_feasible_for_deep/,shahriar49,1565999585,"I have read in many texts that in the early days of neural network computing, backpropagation was not successful for deep networks and also computing power was very limited to run simulations. Nowadays with all the deep networks of tens or hundred layers we still use backpropagation for training. What was the problem with backpropagation in old days and what has been changed in training to make it feasible for new deep networks? Just the computational power?",19,10
184,2019-8-17,2019,8,17,14,crhx96,New Blog Release: Transfer Learning using PyTorch C++ API on Dogs vs Cats (ResNet18 Model),https://www.reddit.com/r/deeplearning/comments/crhx96/new_blog_release_transfer_learning_using_pytorch/,Kushashwa,1566018519,"Excited to share 6th Blog in the series of PyTorch C++ Blogs on - Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API.   

Link to the blog: [**https://lnkd.in/fsPR4T4**](https://lnkd.in/fsPR4T4)  

It takes a lot of efforts to publish a blog, making the code readable and explaining important details of it and I hope it reaches out to the maximum number of students who are keen to contribute to the framework as it is still in the baby stage. So please share with your friends and/or students. As always, I look forward to hearing from you on any constructive feedback. 

*Processing img 1f5k2f14zxg31...*",0,1
185,2019-8-17,2019,8,17,18,crk0hk,"Machine Learning, AI and Deep Learning Services | Webtunix",https://www.reddit.com/r/deeplearning/comments/crk0hk/machine_learning_ai_and_deep_learning_services/,OliviaWillson,1566033940,"[**Deep learning** ](https://www.webtunix.com/deep-learning-services)is the branch of **machine learning**. It based on neural networks. Learning can be supervised, semi-supervised or unsupervised. In which we can overcome the challenges of feature extraction. The reason of deep learning models is capable of learning to focus on the right features by themselves. [**Webtunix** ](https://www.webtunix.com/)Provides the best solution and services in artificial intelligence.",0,1
186,2019-8-17,2019,8,17,18,crk8xi,Deep Learning: A beginners diary,https://www.reddit.com/r/deeplearning/comments/crk8xi/deep_learning_a_beginners_diary/,asifali_p,1566035661,"To post some beginners post in this sub-reddit might not be of use. But still its a read worthy piece of information for the newbies joined in this discussion platform. 

 [https://www.infolks.info/blog/blog-post-deep-learning-a-beginners-diary/](https://www.infolks.info/blog/blog-post-deep-learning-a-beginners-diary/)",7,11
187,2019-8-17,2019,8,17,19,crkhe4,rectified nesterov adam,https://www.reddit.com/r/deeplearning/comments/crkhe4/rectified_nesterov_adam/,aloo_matar_,1566037283,"My implementation of rectified nesterov adam optimizer in keras. rnadam combines nesterov accelerated gradient with rectified-adam. Any thoughts on it?

[github-link](https://github.com/niley1nov/keras_rnadam)",0,1
188,2019-8-17,2019,8,17,20,crkzdv,Learn Tensorflow coming from Keras,https://www.reddit.com/r/deeplearning/comments/crkzdv/learn_tensorflow_coming_from_keras/,Atralb,1566041077,"Hi,

I've been working on DL for about a year now with Tensorflow as a backend but always with Keras on top. I've had a bit of introduction to Tensorflow itself by reading the first \~50 pages but stopped when I realized how much more complicated it was compared than Keras and that my knowledge then couldn't justify the hassle of learning it. Keras was far more than enough.   


Now I'd like to come back a bit at Tf but I would love for some resource teaching it with the assumption that you already are familiar and experienced with Keras. Unfortunately, after a lengthy research I didn't find any such article, book, or online course.  


I know I could just go look at resources teaching tensorflow from scratch, but I still wanted to make a discussion in here for those several reasons :  
\- Extensive courses for Tensorflow spend a lot of time explaining the theory and do so in tandem with uncovering tensorflow mechanics and functions. So it's not a straightforward ""skip the explanations"" if you already know theory and practical model building a lot. This creates a lot of ""overhead"" to getting the useful information.  
\- I believe (correct me if i'm wrong) it would actually be really interesting and relevant for our understanding to put corresponding keras and Tf functions at the forefront and compare them to explain how keras ones work under the hood in tensorflow and also to easily get what coding in Tf would enable that Keras can't. In summary a ""Tensorflow when knowing Keras"" course would IMHO be really useful source.  
\- I'm sure a LOT of people are in the same situation as I am, the reason being the overwhelming popularity of Keras and ease of use, while also Tf being overly used.

&amp;#x200B;

So I just wanted to know your opinion about this and also (now that you know my situation) if by chance some of you actually know of such resource or something close/similar to what I'm thinking. Thanks a lot !",2,15
189,2019-8-17,2019,8,17,23,crmreh,"Given noisy data and labels, how to realize a network is good enough?",https://www.reddit.com/r/deeplearning/comments/crmreh/given_noisy_data_and_labels_how_to_realize_a/,shahriar49,1566051827,"I have created a dataset of sequences of Landsat observations for a big number of points that I realized have stable landcover (I did my judgement using Google Earth imagery using its historical view). The purpose is to train a network to decide on a point's landcover type based on its yearly Landsat observations, taking into account the phenological changes through the year to improve classification. I use LSTM network and I can reach classification accuracy over 90% easily.

I can still get some little improvements by enlarging the network and maybe adding some other features to the net, but how can I be confident that what I get is the best achievable? The data is noisy anyway, and more important, the labels are assigned by myself and therefore subject to my personal opinion. I mean, when I was looking in Google Earth to decide which label to assign to a training point, I was definitely using my personal judgement to distinguish a forest from a grassland from a wetland from a bare land (and there is no sharp border between some of them) . Worse than that, I have to use my personal estimate to decide on mixed pixels, for example by majority rule (again, majority is just my eye and brain decision, and may not be 100% accurate). Even my judgement is subject to change through time gradually...

So, with all of the above (which I think any landcover dataset is prone to it), I am pretty sure that no network can achieve 100% accuracy even on a training set (unless network is so big to completely memorize the training dataset). I still hope that the network can learn to classify better than what I could do (even from the biased training dataset) because it is not subject to human errors, but is it really possible? And again, referring to the question in title, how can decide to stop and say a network is really good and can not be better than that in these conditions?",0,2
190,2019-8-17,2019,8,17,23,crmv6j,"Breast cancer diagnosis with neural networks, implemented with Keras and written in Python",https://www.reddit.com/r/deeplearning/comments/crmv6j/breast_cancer_diagnosis_with_neural_networks/,antaloaalonso,1566052412,,0,1
191,2019-8-17,2019,8,17,23,crn0l7,Can these projects work as desired?,https://www.reddit.com/r/deeplearning/comments/crn0l7/can_these_projects_work_as_desired/,Mjjjokes,1566053260,"Summary: 1. predict depth from a single image with an accuracy of 100% (Andrew Ng and Saxena have done this with an accuracy of 67%), then, 2. use a training set of real 3d models to calculate voxels outside of a test 3d model (ideally one generated by the first project) (first predicting a single voxel, then adding that voxel to the set of known voxels, then using the new set of voxels to predict another voxel, and so on).

Will this generate the desired results (being able to calculate voxels outside of a given 3d model, and ultimately, allowing us to see things outside of the original camera scene of a given photo)?",2,2
192,2019-8-17,2019,8,17,23,crn1kf,What are some good resources to get started with Keras?,https://www.reddit.com/r/deeplearning/comments/crn1kf/what_are_some_good_resources_to_get_started_with/,merwanedr,1566053425,,3,2
193,2019-8-18,2019,8,18,1,cro802,CycleGAN learns identity transform,https://www.reddit.com/r/deeplearning/comments/cro802/cyclegan_learns_identity_transform/,ziapelta,1566058720,"I'm building a cycleGAN system to apply an aging filter, i.e. convert young faces to old faces. I've tried many tweaks, but each time both generators learn the identity function, i.e. the forward and reverse cycle image are equal to the original image. I've tried using both an implementation I wrote and one from another individual. Both show the same results. As such, I don't think there is a bug in the code. Can I tweak the way I'm training to prevent this from happening?",2,2
194,2019-8-18,2019,8,18,1,croi61,One-hot all-zero entries in Tensorflow,https://www.reddit.com/r/deeplearning/comments/croi61/onehot_allzero_entries_in_tensorflow/,shahriar49,1566060031,"I have a pixel classification application with training labels (per pixel) being one-hot encoded. For some reason there are pixels that doesn't have valid labels. One solution might be to use sample\_weight option to indirectly mask those pixels from affecting loss and gradient calculations. But I found that in Tensorflow implementation, I can generate one-hot labels being all-zero (which is an invalid one-hot encoding) for those pixels and I will not get any error during model build and training. Are these two methods the same? Is all-zero one-hot label disables loss and gradient calculation for that specific pixel?",5,4
195,2019-8-18,2019,8,18,2,crphfu,How do parameters and number of layers influence the speed of training?,https://www.reddit.com/r/deeplearning/comments/crphfu/how_do_parameters_and_number_of_layers_influence/,MLscivet16,1566064437,"I am choosing between various state of the art architectures for a classification task where speed of training is extremely important (accuracy is too, but let's focus on speed for now). The current model being used for this task is using an Inception v3 architecture (42 layers, 23.8 million parameters with ImageNet). For similar tasks, the state of the art papers use models similar to VGGnet with 22 layers and 144 million parameters (ImageNet). I am new to deep learning and assumed increasing number of layers would increase training time, but there are many more parameters to learn with VGGnet based on the ImageNet results. 

What is a better estimator of training time, number of layers or parameters? Thank you.",3,1
196,2019-8-18,2019,8,18,3,crq5l3,Sports Matches &amp; Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/crq5l3/sports_matches_artificial_intelligence/,cmillionaire9,1566067469,,5,39
197,2019-8-18,2019,8,18,4,crqfcr,Do regularization really make model simpler?,https://www.reddit.com/r/deeplearning/comments/crqfcr/do_regularization_really_make_model_simpler/,shahriar49,1566068744,"I hear a lot that L-2 regularization forces the network weights to be smaller, therefore makes the model simpler and less overfit to the data. But I don't understand clearly how smaller or larger weights can relate to model complexity.  A polynomial of degree inherently supports more complex models than a polynomial of degree 2, whatever the coefficients be.

I understand that with smaller weights the model is less prone to pick up every noise and change in data and try to model it, but this is another story than 'a simpler model' in my mind. If we really want a simpler model, why just not reverting to a polynomial of lower degree and keep the higher polynomial but regularizing its weights? Also, why we can not argue that with smaller weights the network may hurt to pick up strong patterns as well?",11,10
198,2019-8-18,2019,8,18,4,crqznn,How am I supposed to get started with training neural nets on my personal machine as a broke student? (Macbook Pro),https://www.reddit.com/r/deeplearning/comments/crqznn/how_am_i_supposed_to_get_started_with_training/,merwanedr,1566071361,,3,0
199,2019-8-18,2019,8,18,5,crr68f,This may sound silly.. but...,https://www.reddit.com/r/deeplearning/comments/crr68f/this_may_sound_silly_but/,TheoriginalMr,1566072251,"Done with my undergrad. Working as a software developer. 
Haven't worked under any profs back in Uni. Looking forward to master's admission and the admission committee asks for LORs ( Letter of Recommendations )
I don't want to get fake LORs.

So,
I wish to work with / under  you and publish a research paper. (Probably in deep learning). 
If you or some one you know have credentials, good enough to write me a decent LOR and if you believe I could contribute to your research ( I can spend 20 hrs a week ), please ping me. Thanks.",0,0
200,2019-8-18,2019,8,18,8,crto5m,Monte Carlo method in Reinforcement Learning | RL tutorial series,https://www.reddit.com/r/deeplearning/comments/crto5m/monte_carlo_method_in_reinforcement_learning_rl/,Riturajkaushik,1566084602,,0,23
201,2019-8-18,2019,8,18,13,crwsh0,Microsoft has Announced a massive online Global AI hackathon.,https://www.reddit.com/r/deeplearning/comments/crwsh0/microsoft_has_announced_a_massive_online_global/,BatmantoshReturns,1566102383,"https://azureai.devpost.com/

Do actually don't need that much AI knowledge to participate, since you can just use one of Azure's premade services. 

My team is working on different book recommender systems. Feel free to PM about joining us.",0,13
202,2019-8-18,2019,8,18,17,cryqnn,A Very Simple Offline OCR SDK,https://www.reddit.com/r/deeplearning/comments/cryqnn/a_very_simple_offline_ocr_sdk/,multisilicon,1566117036,,2,6
203,2019-8-19,2019,8,19,2,cs4eii,CuDNN implementation of ConvLSTM2D,https://www.reddit.com/r/deeplearning/comments/cs4eii/cudnn_implementation_of_convlstm2d/,shahriar49,1566150290,"I see there is fast CuDNN layer for LSTM and GRU layers as listed in [keras.io](https://keras.io), but I can not find similar CuDDNN implementation for ConvLSTM2D.  Is anybody aware of that?",0,4
204,2019-8-19,2019,8,19,2,cs4jjm,SOTA BLACK BOX EXPLANATIONS AND INTUITIONS,https://www.reddit.com/r/deeplearning/comments/cs4jjm/sota_black_box_explanations_and_intuitions/,S_0ci0path,1566150899,"Is there a list of papers anyone can suggest that could help digest the idea of a neural network? I'd like state of the art papers so that I can see what I can do - being as stupid as I am, to help out or just to fulfill the idea that I might be thinking about this.",1,3
205,2019-8-19,2019,8,19,3,cs4md0,"Pooling VRAM on 2x Titan RTX in PyTorch, Tensorflow?",https://www.reddit.com/r/deeplearning/comments/cs4md0/pooling_vram_on_2x_titan_rtx_in_pytorch_tensorflow/,tripple13,1566151227,"Hey guys, I've cross-checked the internet (wholeheartedly) and I just cannot seem to find conclusive information.

# Does 2x Titan RTX allow to pool memory from 24GB to 48GB in total? If so, How?

From the website of Nvidia the following is shown

['... effective doubling of memory capacity to 48GB ...'](https://i.redd.it/5e01vefmx8h31.png)

Now I happen to run a box with 2x Titan RTX's, and I've installed the NVLink bridge - Does anyone have experience on how to utilize these features on popular frameworks? Ie. PyTorch, Tensorflow?

At the moment it just shows up in my system as two separate Titan RTX's, I just cannot figure out how to enable this feature.",9,12
206,2019-8-19,2019,8,19,6,cs77x8,Help! Basic transfer learning - existing classification model to detection.,https://www.reddit.com/r/deeplearning/comments/cs77x8/help_basic_transfer_learning_existing/,DarkAngelRUS,1566162948,"I am a complete newbie in Neural Networks and Python.
Unfortunately, I currently have to use CNNs to create an object detector from scratch for a particular image class.

I have somehow managed to follow sentdex tutorials and train a classifier model that can separate ""Objects"" from ""Not Objects"". It is trained on my own large dataset which is labelled but doesn't have bounding boxes (it would take me weeks to draw them)


What is the easiest way to upload this model into an object detector?
Where do I start as a layman?
I have seen mentions of MobileNetV2 and YOLO, but not really sure where to upload my model? I was struggling even launching YOLOv2 on examples.

Absolutely panicing right now, wouldn't typically resort to asking questions that I am sure have been answered somewhere. But information so far has been really overwhelming.

Any help would be appreciated!
Thank you!",1,3
207,2019-8-19,2019,8,19,6,cs7qzk,Deep Learning Research - Weekly Update Video,https://www.reddit.com/r/deeplearning/comments/cs7qzk/deep_learning_research_weekly_update_video/,HenryAILabs,1566165433,[https://youtu.be/gG0gSzdEDWM](https://youtu.be/gG0gSzdEDWM),2,21
208,2019-8-19,2019,8,19,15,csdctu,"Introduction to Deep Learning with Keras (Part 5): Using Callbacks and ConvNets - A site aimed at building a Data Science, Artificial Intelligence and Machine Learning empire.",https://www.reddit.com/r/deeplearning/comments/csdctu/introduction_to_deep_learning_with_keras_part_5/,sovit-123,1566196989,,1,1
209,2019-8-19,2019,8,19,15,csdgty,"Interview with Kaggle GrandMaster, Dr. Vladimir Iglovikov about Albumentations: a fast image augmentations library",https://www.reddit.com/r/deeplearning/comments/csdgty/interview_with_kaggle_grandmaster_dr_vladimir/,init__27,1566197781,"Interview with Dr. Vladimir Iglovikov (Kaggle GM, Senior CV Engineer at Lyft) about Albumentations Framework: a fast image augmentations library 

&amp;#x200B;

We talk all about albumentations, image augs and open source. 

&amp;#x200B;

Audio: [https://anchor.fm/chaitimedatascience/episodes/Albumentations-Framework-a-fast-image-augmentations-library--Interview-with-Dr--Vladimir-Iglovikov-e4r6e4](https://anchor.fm/chaitimedatascience/episodes/Albumentations-Framework-a-fast-image-augmentations-library--Interview-with-Dr--Vladimir-Iglovikov-e4r6e4)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=P7vUzcySzkM&amp;feature=youtu.be](https://www.youtube.com/watch?v=P7vUzcySzkM&amp;feature=youtu.be)",0,5
210,2019-8-19,2019,8,19,16,csdnkk,Deeplearning course (coursea),https://www.reddit.com/r/deeplearning/comments/csdnkk/deeplearning_course_coursea/,SSJCalzana,1566199071,"Hi there,

Thinking about doing this deep learning course, but wanted to check if anyone else has done the same or something similar and would suggest before I subscribe to couresa. 

 [https://www.deeplearning.ai/deep-learning-specialization/](https://www.deeplearning.ai/deep-learning-specialization/)",3,1
211,2019-8-19,2019,8,19,16,csdrb8,Transformer with Python and TensorFlow 2.0  Encoder &amp; Decoder,https://www.reddit.com/r/deeplearning/comments/csdrb8/transformer_with_python_and_tensorflow_20_encoder/,RubiksCodeNMZ,1566199850,,0,4
212,2019-8-19,2019,8,19,20,csftkg,Zooming into the world of computer vision applications,https://www.reddit.com/r/deeplearning/comments/csftkg/zooming_into_the_world_of_computer_vision/,MachineLearning001,1566214303,,0,0
213,2019-8-19,2019,8,19,23,cshuu6,"I explained Backpropagation and Optimization with Math and Visualizations in a very clear way. Now I'm looking for your suggestions, in which way I should take my Deep Learning content.",https://www.reddit.com/r/deeplearning/comments/cshuu6/i_explained_backpropagation_and_optimization_with/,permalip,1566225084,"Hey guys, I posted here about 2 weeks ago. People really seemed to like my writing and the way I explained things in my post, which you can view here:

**Link**: [https://mlfromscratch.com/neural-networks-explained/](https://mlfromscratch.com/neural-networks-explained/)

A specific suggestion/some feedback I got on my last post was:

* Make a followup with the code for deep neural networks in Keras (w/ TensorFlow) and PyTorch.
* Make a post about different activation functions (I'm halfway through making this).

The idea is that I would make posts in the same style, with the math clearly walked through and pictures/animations to help understand it. I have this idea of starting from the bottom, getting to know everything, then moving up into the more complicated architectures and newer research.

Given that you have read my last article (it's actually good, it even helped me a lot), what would you say I should make posts about?

Any advice is appreciated.",16,36
214,2019-8-20,2019,8,20,0,csi866,[Research] Recent Advances in Deep Learning Object Detection,https://www.reddit.com/r/deeplearning/comments/csi866/research_recent_advances_in_deep_learning_object/,cdossman,1566226812,"By reviewing a large body of recent related work in literature, researchers systematically analyze the existing object detection frameworks and organize the survey into three major parts: (i) detection components, (ii) learning strategies, and (iii) applications &amp; benchmarks in this paper. They cover a variety of factors affecting the detection performance in detail, such as detector architectures, feature learning, proposal generation, sampling strategies, etc. Finally, they discuss several future directions to facilitate and spur future research for visual object detection with deep learning.

 [https://medium.com/ai%C2%B3-theory-practice-business/here-are-the-recent-advances-in-deep-learning-object-detection-d73dca640526](https://medium.com/ai%C2%B3-theory-practice-business/here-are-the-recent-advances-in-deep-learning-object-detection-d73dca640526)",0,1
215,2019-8-20,2019,8,20,3,cslen0,Of Mice and Machines: Can AI Read Rodents Minds?,https://www.reddit.com/r/deeplearning/comments/cslen0/of_mice_and_machines_can_ai_read_rodents_minds/,Yuqing7,1566240318,,0,4
216,2019-8-20,2019,8,20,4,csmfra,Weight Agnostic Neural Networks - Video Explanation!,https://www.reddit.com/r/deeplearning/comments/csmfra/weight_agnostic_neural_networks_video_explanation/,HenryAILabs,1566244743,[https://youtu.be/QqoKl9N2oCw](https://youtu.be/QqoKl9N2oCw),0,1
217,2019-8-20,2019,8,20,9,csqiey,Build for ML/Deep learning!?,https://www.reddit.com/r/deeplearning/comments/csqiey/build_for_mldeep_learning/,abshk_jr,1566262568,"Hi All,

This is my Freshman Year, and I am planning to build a desktop, the main purposes would be software development, and I will be focusing on Machine learning in the coming year.

This is the build that I have planned currently

CPU

AMD RYZEN 7 3700X

MOTHERBOARD

Asus ROG Strix B450-E Gaming (Wi-Fi)

(I chose this one, because it's a Tier II board, and VRMs are gonna suffice for Overclocking with enough airflow. source : https://docs.google.com/spreadsheets/d/1wmsTYK9Z3-jUX5LGRoFnsZYZiW1pfiDZnKCjaXyzd1o/edit#gid=2112472504 )

RAM

G.Skill Trident Z RGB 8GB DDR4 3200MHz

PSU

CORSAIR CX650

SSD

500GB SAMSUNG SSD 970 EVO PLUS NVME M.2

HDD

Seagate BarraCuda ST1000DM010 1 TB Internal Hard Drive

THERMAL COMPOUND

Noctua NT-H1 Thermal Compound

FANS

Cooler Master MasterFan MF120R ARGB (Triple Pack)

CABINET

Deepcool Matrexx 50 (Black)



GPU

I plan to buy something like an RX570 or GTX1060 for an year or two, then I will be upgrading to some higher card, when I require the computational power. Also I don't game frequently, but even if I do, it's CS:GO, which is not a much GPU taxing game.

I am from India.

Open for all suggestions.",12,1
218,2019-8-20,2019,8,20,15,cstm7o,Tensor-flow implementation explanation tutorial 4,https://www.reddit.com/r/deeplearning/comments/cstm7o/tensorflow_implementation_explanation_tutorial_4/,flyhighwithai,1566281741,,0,1
219,2019-8-20,2019,8,20,15,cstqas,Tensor-flow implementation explanation tutorial 4,https://www.reddit.com/r/deeplearning/comments/cstqas/tensorflow_implementation_explanation_tutorial_4/,flyhighwithai,1566282458,,0,1
220,2019-8-20,2019,8,20,15,csttd0,Tensor-flow implementation explanation tutorial 4,https://www.reddit.com/r/deeplearning/comments/csttd0/tensorflow_implementation_explanation_tutorial_4/,flyhighwithai,1566283168,,0,1
221,2019-8-20,2019,8,20,15,cstwo4,Tensor-Flow Implementation Explanation Tutorial 4,https://www.reddit.com/r/deeplearning/comments/cstwo4/tensorflow_implementation_explanation_tutorial_4/,flyhighwithai,1566283958,,0,1
222,2019-8-20,2019,8,20,17,csuy8t,6 Types of Artificial Neural Networks Currently Being Used in Machine Learning,https://www.reddit.com/r/deeplearning/comments/csuy8t/6_types_of_artificial_neural_networks_currently/,subhamroy021,1566289688,,2,4
223,2019-8-20,2019,8,20,20,csxc6i,I am building a face recognition algorithm that takes attendance for students that appear in the class. How many pictures do I need to train the algorithm for each individual student before I can successfully run it for the whole class?,https://www.reddit.com/r/deeplearning/comments/csxc6i/i_am_building_a_face_recognition_algorithm_that/,vigbig,1566301583,"I am implementing this via Python using OpenCV. 

I am learning this from scratch and from what I learnt is that I need a lot of pictures to train the algorithm to recognize one person. Now I don't know how much is required as many tutorials say more the better , and why I ask is I have to make this not for a student but for an entire class. 

So far I just learnt how to capture a face on camera using Haar Cascade Classifier, that is it.",10,15
224,2019-8-20,2019,8,20,20,csxiis,Video Frame Interpolation via Cyclic Fine-Tuning and Asymmetric Reverse Flow,https://www.reddit.com/r/deeplearning/comments/csxiis/video_frame_interpolation_via_cyclic_finetuning/,mohanne,1566302299," Want to convert your video to slowmotion?  
[https://github.com/MortenHannemose/pytorch-vfi-cft](https://github.com/MortenHannemose/pytorch-vfi-cft)",1,2
225,2019-8-20,2019,8,20,21,csxmgy,SDK for developing artificial intelligence application,https://www.reddit.com/r/deeplearning/comments/csxmgy/sdk_for_developing_artificial_intelligence/,aminehy,1566302771,"Pensar SDK: A Rapid Artificial Intelligence Application Development framework by M. Amine Hadj-Youcef, Ph.D. https://link.medium.com/FOKks3M2iZ",0,2
226,2019-8-20,2019,8,20,22,csyo5o,Semantic Segmentation Choroid Plexus,https://www.reddit.com/r/deeplearning/comments/csyo5o/semantic_segmentation_choroid_plexus/,senthilcaesar,1566307069,,0,2
227,2019-8-21,2019,8,21,0,ct0s7j,Can you recommend any good tutorials that use OpenFace for facial recognition? preferably from scratch?,https://www.reddit.com/r/deeplearning/comments/ct0s7j/can_you_recommend_any_good_tutorials_that_use/,vigbig,1566315200,"I need to learn for a project that would where I have to develop a facial recognition student attendance based system.

OpenFace  has been suggested to me where it serves the purpose of recognising  several faces . And it is easier to use when compared to FaceNet.

I am new to learning Python , the best I have done some far is capturing faces using OpenCV using Haar Cascade Classifier.",0,2
228,2019-8-21,2019,8,21,1,ct1da3,Is it ok for training Dice + Focal losses to be negative?,https://www.reddit.com/r/deeplearning/comments/ct1da3/is_it_ok_for_training_dice_focal_losses_to_be/,74throwaway,1566317357,"I'm running a semantic segmentation model using code from https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb

The loss used is:

    dice_loss = sm.losses.DiceLoss(class_weights=np.array([1, 2, 0.5])) 
    focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()
    total_loss = dice_loss + (1 * focal_loss)

The only differences are that I'm using my own data instead of the CamVid, and I'm trying to predict 3 different classes instead of `car` and `pedestrian` like in that notebook example

I've noticed that although the validation losses have stayed positive and are decreasing, the training losses went from positive and decreased to negative and continue to be more negative:

	Epoch 50/300
	9/9 [==============================] - 1171s 130s/step - loss: 0.0156 - iou_score: 0.6439 - f1-score: 0.6901 - val_loss: 0.1600 - val_iou_score: 0.6910 - val_f1-score: 0.7310
	Epoch 51/300
	9/9 [==============================] - 1173s 130s/step - loss: 0.0022 - iou_score: 0.6491 - f1-score: 0.6941 - val_loss: 0.1517 - val_iou_score: 0.6811 - val_f1-score: 0.7224
	Epoch 52/300
	9/9 [==============================] - 1184s 132s/step - loss: -0.0077 - iou_score: 0.6527 - f1-score: 0.6963 - val_loss: 0.1413 - val_iou_score: 0.6990 - val_f1-score: 0.7380
	Epoch 53/300
	9/9 [==============================] - 1176s 131s/step - loss: -0.0087 - iou_score: 0.6476 - f1-score: 0.6930 - val_loss: 0.1337 - val_iou_score: 0.7204 - val_f1-score: 0.7594
	Epoch 54/300
	9/9 [==============================] - 1166s 130s/step - loss: -0.0052 - iou_score: 0.6516 - f1-score: 0.6959 - val_loss: 0.1294 - val_iou_score: 0.7034 - val_f1-score: 0.7439

Despite the negative training loss, the predictions from the test set continue to improve as the epoch number increases

Is this ok? Or is this a sign that there's something wrong with the code or my setup?",0,1
229,2019-8-21,2019,8,21,1,ct1iiz,Introduction to Self Driving Cars + Source Code,https://www.reddit.com/r/deeplearning/comments/ct1iiz/introduction_to_self_driving_cars_source_code/,mynercloud,1566317904,,3,49
230,2019-8-21,2019,8,21,1,ct2366,A Neural Net compiler for low-memory/low-processing powered embedded devices,https://www.reddit.com/r/deeplearning/comments/ct2366/a_neural_net_compiler_for_lowmemorylowprocessing/,en1gmarikki,1566320019,"Hi folks, I am an undergraduate student working on a compiler that helps us run neural networks on low-memory devices like the raspberry pi , Please feel to review the project and help us improve it .

Introduction : 

The DNN Compiler is designed to **enable and perform** deep learning neural networks by focussing on features of custom ai-accelerators like FPGAs, eFPGAs and other embedded devices like risc-V, raspberry-pi and others. DNN Compiler is ahead of time compiler producing optimized executable based on [LLVM compiler tool chain](https://llvm.org/) and [openAcc](https://www.openacc.org/)specialized for deep neural networks with [ONNX](https://onnx.ai/) as front end. 

Link to the repo:

 [https://github.com/ai-techsystems/dnnCompiler](https://github.com/ai-techsystems/dnnCompiler)",1,12
231,2019-8-21,2019,8,21,5,ct57hs,"On-Device, Real-Time Hand Tracking with MediaPipe. | machinelearning | deeplearning",https://www.reddit.com/r/deeplearning/comments/ct57hs/ondevice_realtime_hand_tracking_with_mediapipe/,cmillionaire9,1566331487,,0,10
232,2019-8-21,2019,8,21,14,ctc739,Is it possible to decode a deep neural network as an analytical expression/formula ?,https://www.reddit.com/r/deeplearning/comments/ctc739/is_it_possible_to_decode_a_deep_neural_network_as/,yourboyrabbit,1566364346,I know a shallow neural network should be simple to do but what about a deep neural network ?,3,1
233,2019-8-21,2019,8,21,14,ctc73p,Improving Business Communications and Human Interactions with NLP,https://www.reddit.com/r/deeplearning/comments/ctc73p/improving_business_communications_and_human/,MachineLearning001,1566364349,,0,8
234,2019-8-21,2019,8,21,14,ctcgvh,FileNotFoundError,https://www.reddit.com/r/deeplearning/comments/ctcgvh/filenotfounderror/,Uninvited_Geist,1566366091,"I'm using the following code:  
training\_set = train\_datagen.flow\_from\_directory('E:\\Project\\dataset\\training\_set',

But I'm getting this error:  
FileNotFoundError: \[Errno 2\] No such file or directory: 'content/gdrive/project/dataset/training\_set'   


I tried using Google Drive (already mounted) with the same error:  
training\_set = train\_datagen.flow\_from\_directory('content/gdrive/project/dataset/training\_set',  


What am I doing wrong?",2,0
235,2019-8-21,2019,8,21,14,ctchh0,Hairsyle Fittng on Head,https://www.reddit.com/r/deeplearning/comments/ctchh0/hairsyle_fittng_on_head/,zom8ie99,1566366208,How does the apps like FaceIt work? I mean How do they fit the haitstyle on the head of the person ! What are the technologies used ? Is there is anything that I could refer ?,0,2
236,2019-8-21,2019,8,21,15,ctcupq,Deep Learning model predicts incorrectly,https://www.reddit.com/r/deeplearning/comments/ctcupq/deep_learning_model_predicts_incorrectly/,zom8ie99,1566368642,"I have trained my self created dataset to 81% train-acc and 80% test acc. The overall taining looks good. But the model predicts incorrect categories. How can I adjust my model so that it can predict accurately ? What parameters should be adjusted ? 

My CNN architecture:

    classifier = Sequential()
    
    classifier.add(Convolution2D(64, (3, 3), input_shape = (32,32,3),padding = 'same',activation = 'relu'))
    classifier.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))  
    
    classifier.add(Convolution2D(128, (3, 3),padding = 'same', activation = 'relu')) classifier.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))  
    
    classifier.add(Convolution2D(256, (3, 3),padding = 'same', activation = 'relu')) classifier.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))
    
    classifier.add(Flatten()) 
    
    classifier.add(Dropout(0.2)) 
    classifier.add(Dense(units = 1024, activation = 'relu')) 
    
    classifier.add(Dropout(0.5)) 
    classifier.add(Dense(units = 5, activation = 'softmax'))

Link to dataset:  [https://www.kaggle.com/zom8ie99/maize-seed](https://www.kaggle.com/zom8ie99/maize-seed) 

Thanks in Advance.",13,1
237,2019-8-21,2019,8,21,15,ctd2wn,Robust Image Text Retrieval From Degraded Document Images,https://www.reddit.com/r/deeplearning/comments/ctd2wn/robust_image_text_retrieval_from_degraded/,flyhighwithai,1566370222,,0,1
238,2019-8-21,2019,8,21,16,ctdizj,Using Machine Learning in Service Level Agreements,https://www.reddit.com/r/deeplearning/comments/ctdizj/using_machine_learning_in_service_level_agreements/,RubiksCodeNMZ,1566373382,,0,0
239,2019-8-21,2019,8,21,17,ctdpwr,Iris Recognition MATLAB Implementation,https://www.reddit.com/r/deeplearning/comments/ctdpwr/iris_recognition_matlab_implementation/,flyhighwithai,1566374842,,0,1
240,2019-8-21,2019,8,21,18,ctej9s,Regression Problem using large scale input,https://www.reddit.com/r/deeplearning/comments/ctej9s/regression_problem_using_large_scale_input/,drjotten,1566380647,"Hi community,

I am researching in Ultra High Field MRI and trying to homogenize MRI images under SAR constrictions. Since DL is pretty new to me I would like to ask you for help. I try to solve a regression problem using a very high number of input feature values: 

Nine 3D field maps (each about 20x20x10 voxel) and 100 other parameters to calculate two single values with a seperate optimization process i want to model with the NN (all in all: roughly 4100 parameters). 

Does anyone have experiences or a recommendation for some NN which is suitable for this kind of large scale inputs and regression output? 

And do you think this modeling is possible with just several thousands of inputs (50 different sets of field maps combined with several sets of those 100 other parameters).

&amp;#x200B;

Thank you very much in advance! :)",3,3
241,2019-8-21,2019,8,21,21,ctg6m5,Microsoft Releases New Version of its Open-Source Distributed Deep Learning Library,https://www.reddit.com/r/deeplearning/comments/ctg6m5/microsoft_releases_new_version_of_its_opensource/,mhamilton723,1566390664,,0,15
242,2019-8-21,2019,8,21,23,cthmbh,Model overfitts for explicit batch sizes,https://www.reddit.com/r/deeplearning/comments/cthmbh/model_overfitts_for_explicit_batch_sizes/,Taxaria,1566397633," Hey :)  
I made a model for time series forecasting. The model works very well. I tried different batch sizes 32, 50, 64, 100, 128 and 256.  
I got the best result for a batch size of 50. With a batch size of 32 the model still works, but it takes too long until the error converges.  
I tried multiple experiments with a batch size of 64. With that batch size the model is not able to learn. The MAE is very high, the training error decreases, but the validation error is very high. It seems, that the model is overfitting for a batch size of 64.  
So I made further experiments with a batch size of 100, 128 and 256.  
100 works of, but not as good as 50. 128 shows the same results as 64. 256 shows good results in training and validation error, but not in the MAE.  
Do you have any ideas why 64 and 128 do not work?  
I know that models tend to overfit, when the batch size is too large, but this reason makes no sense for me in this case.  
Thanks for your help!",0,2
243,2019-8-22,2019,8,22,1,ctjg23,Transfer learning varying results with different models,https://www.reddit.com/r/deeplearning/comments/ctjg23/transfer_learning_varying_results_with_different/,sambalshikhar,1566405977,"I am solving a classification problem on images of documents like, resume,letter,article etc.The best result i got was from vgg16 initialized with imgaenet weights with accuracy of 87% .I fine tuned the last 2 cnn layers of vgg.Doing the same for inception-net,resnet and other models gives terrible results like 20%.What are the reasons that this might happen?",5,1
244,2019-8-22,2019,8,22,2,ctk73z,[Code review] Unofficial Keras implementation of the paper Instance Enhancement Batch Normalization,https://www.reddit.com/r/deeplearning/comments/ctk73z/code_review_unofficial_keras_implementation_of/,cyril_9227,1566409156,"Hello guys,

I don't know if it's the right place to ask this (I'm fairly new to reddit) but I recently implemented a Keras code for the paper  [https://arxiv.org/abs/1908.04008](https://arxiv.org/abs/1908.04008) and I would be super glad if someone experienced would review my code and give me feedbacks (it's my first time doing this kind of stuff)...

Here is the repo link :  [https://github.com/Cyril9227/Keras\_IEBN](https://github.com/Cyril9227/Keras_IEBN) 

The official Pytorch code is here :  [https://github.com/gbup-group/IEBN](https://github.com/gbup-group/IEBN) 

&amp;#x200B;

Thank's a lot :)",0,17
245,2019-8-22,2019,8,22,2,ctkgmv,TensorBoard Empty Scalar Hider: Chrome Extension of hiding empty scalar/panes,https://www.reddit.com/r/deeplearning/comments/ctkgmv/tensorboard_empty_scalar_hider_chrome_extension/,Jasonnor,1566410302,,0,1
246,2019-8-22,2019,8,22,3,ctkjdm,Overfitting in loss but getting good accuracy,https://www.reddit.com/r/deeplearning/comments/ctkjdm/overfitting_in_loss_but_getting_good_accuracy/,shahriar49,1566410629,"I have a LSTM network being trained with a huge amount of data (number of model parameters is around 15,000 and I trained it with a dataset of over 1 million sequences. The training and validation loss graph is shown below:

&amp;#x200B;

https://i.redd.it/9dc2jwppcuh31.png

Does the above graph shows some kind of overfitting?

I tested the network with another big set of test data. The trained model had a training accuracy of 0.945, and when I ran it on test data, I got an accuracy of 0.943. This is very close to training accuracy and therefore no sign of overfitting.

So I am confused!",17,14
247,2019-8-22,2019,8,22,5,ctmwz1,"I didn't know deepmind had a podcast. It's a nice sci-pop style, helpful if you want to explain AI to people who aren't familiar with computer science",https://www.reddit.com/r/deeplearning/comments/ctmwz1/i_didnt_know_deepmind_had_a_podcast_its_a_nice/,cestnestmoi,1566420856,,0,1
248,2019-8-22,2019,8,22,10,ctq2oy,C++ Implementation of the Side Window Filtering(CVPR 2019),https://www.reddit.com/r/deeplearning/comments/ctq2oy/c_implementation_of_the_side_window_filteringcvpr/,Ldpe2G,1566435631,,0,21
249,2019-8-22,2019,8,22,14,ctsy3n,GitHub - MateLabs/AutoOut: Automated Outlier Detection and Treatment Tool,https://www.reddit.com/r/deeplearning/comments/ctsy3n/github_matelabsautoout_automated_outlier/,kailashahirwar12,1566451691,,0,5
250,2019-8-22,2019,8,22,16,cttug9,A Quick &amp; Easy Way Of Knowing Deep Learning In Python,https://www.reddit.com/r/deeplearning/comments/cttug9/a_quick_easy_way_of_knowing_deep_learning_in/,MichaelOconnor1,1566457880,,0,1
251,2019-8-22,2019,8,22,16,cttwsw,Improving Customer Experience with Computer Vision Applications,https://www.reddit.com/r/deeplearning/comments/cttwsw/improving_customer_experience_with_computer/,MachineLearning001,1566458345,,0,4
252,2019-8-22,2019,8,22,16,ctu3nu,One Of The Most Easy-to-use Free Offline OCR For You,https://www.reddit.com/r/deeplearning/comments/ctu3nu/one_of_the_most_easytouse_free_offline_ocr_for_you/,multisilicon,1566459696,,5,3
253,2019-8-22,2019,8,22,16,ctu4eh,Matlab Implementation of Disease Prediction System Using Neural Network,https://www.reddit.com/r/deeplearning/comments/ctu4eh/matlab_implementation_of_disease_prediction/,flyhighwithai,1566459857,,0,1
254,2019-8-22,2019,8,22,16,ctu71x,Listening chatbot,https://www.reddit.com/r/deeplearning/comments/ctu71x/listening_chatbot/,hega72,1566460425,"Hi guys 
I am looking for the following but cant quite find it :
I was wondering if there was a WhatsApp chatbot that I could add to conversations and that would just listen and learn. 
Then I would like to periodically talk to that bot to see how he improves. 
Does that make sense ? Is there such a thing ?",1,3
255,2019-8-22,2019,8,22,17,ctu8w1,Multi-Modal Bio Metric Fusion System Future AI,https://www.reddit.com/r/deeplearning/comments/ctu8w1/multimodal_bio_metric_fusion_system_future_ai/,flyhighwithai,1566460817,,0,1
256,2019-8-22,2019,8,22,19,ctvcer,Open AI - GPT2,https://www.reddit.com/r/deeplearning/comments/ctvcer/open_ai_gpt2/,Tamil94,1566468649,"GPT 2 was released and anyone tried .if yes ,please tell us the efficiency ..

we are trying to use that for machine translation.will it helpful for that....",0,1
257,2019-8-22,2019,8,22,19,ctvftn,Policy iteration &amp; value iteration | RL Tutorial series,https://www.reddit.com/r/deeplearning/comments/ctvftn/policy_iteration_value_iteration_rl_tutorial/,Riturajkaushik,1566469277,,0,1
258,2019-8-22,2019,8,22,19,ctvm3x,Content Based Image Retrieval Using KNN and SVM in Matlab,https://www.reddit.com/r/deeplearning/comments/ctvm3x/content_based_image_retrieval_using_knn_and_svm/,flyhighwithai,1566470410,,0,1
259,2019-8-23,2019,8,23,0,ctyuiu,"Hi, I release Speech Source Separation with more real sounds!",https://www.reddit.com/r/deeplearning/comments/ctyuiu/hi_i_release_speech_source_separation_with_more/,choiilji,1566487051,"Recently, I made more stable Speech Source Separation model with Phase-aware Speech Enhancement with Deep Complex U-Net([https://arxiv.org/abs/1903.03107](https://arxiv.org/abs/1903.03107?fbclid=IwAR05qxXTDmJIXQh3tNVBkAhBs2fIwACSmGVk8ZTuLJwmYk_DvYglbzuPL8w)) .

It's modified several parts of original paper, mainly, two parts are different.

* Audioset ([https://research.google.com/audioset/](https://research.google.com/audioset/?fbclid=IwAR374LGHAxFXZ-E9OY5uc_GSx2kBVgSzdDkLYsMn6s-gzjA8fb2Kr52FgW8)) : background noise augmentation with balanced 18,000 sound samples
* Preemphasis reduces noises occurred intermittently 

&amp;#x200B;

And samples are...

* validation 10 random : [https://drive.google.com/open?id=1CafFnqWn\_QvVPu2feNLn6pnjRYIa\_rbP](https://drive.google.com/open?id=1CafFnqWn_QvVPu2feNLn6pnjRYIa_rbP&amp;fbclid=IwAR2QcmU_oLrJo33I3RgHsnt3VfdPMnPdpYmS4rYbCHDfZ0ziLFF4iCp7feI)
* CC license youtube test 5 sample : [https://drive.google.com/open?id=19Sn6pe5-BtWXYa6OiLbYGH7iCU-mzB8j](https://drive.google.com/open?id=19Sn6pe5-BtWXYa6OiLbYGH7iCU-mzB8j&amp;fbclid=IwAR3jBaB42I5zv9JB6B-CEeT4rXiDevPvcn54CDuNZPMKIIzqXoRbS62enF8)

If you wanna see sources, visit  [https://github.com/AppleHolic/source\_separation](https://github.com/AppleHolic/source_separation) . Welcome feedback!",3,25
260,2019-8-23,2019,8,23,2,cu0udj,Running keras LSTM models with multiple GPU (Tensorflow backend),https://www.reddit.com/r/deeplearning/comments/cu0udj/running_keras_lstm_models_with_multiple_gpu/,shahriar49,1566495733,"I have a keras LSTM model and want to run it under multiple GPUs for speed improvement. But I have some ambiguities:

1- I found that to really get the great speed on GPU I should define my network using CuDNNLSTM layer and not normal LSTM layer. To use multiple GPUs, I looked at  [https://keras.io/utils/#multi\_gpu\_model](https://keras.io/utils/#multi_gpu_model)  and wanted to use multi\_gpu\_model() function to make distributed model. However, in the sample scripts they recommend to define the model on CPU for easy weight sharing, but my CuDNNLSTM model is not deployable on CPU and LSTM model will not benefit from the enhancements provided by GPU. What is the correct approach?

2- So I tried many configurations, including:

\- Group 1(using the normal (non-fast) LSTM layers): placing model on CPU and no copying to GPU; placing model on CPU and then use multi\_gpu\_model to create GPU copies; place model on default GPU and no copying to other GPU; placing model on default GPU and then use multi\_gpu\_model to create two GPU copies.

\- Group2 (using CuDNNLSTM layer and therefore no possibility to place model on CPU): defining a single model (which Tensorflow places it on the default GPU); using multi\_gpu\_model to create two GPU copies.

In all cases, data parallelism (using multi\_gpu\_model) resulted in lower speed of execution. I didn't change anything else in my code and input data pipeline or batch sizes. What is wrong with me?

3- In general, should I only use CuDNN-type layers to get high speed computation with GPUs when I am programming at high level of keras API?",1,1
261,2019-8-23,2019,8,23,3,cu16es,How to Start with Machine Learning,https://www.reddit.com/r/deeplearning/comments/cu16es/how_to_start_with_machine_learning/,atomlib_com,1566497177,,0,1
262,2019-8-23,2019,8,23,3,cu1jlc,AI Cheatsheets: Your favorite cheatsheets are now available on aicheatsheets@gmail.com,https://www.reddit.com/r/deeplearning/comments/cu1jlc/ai_cheatsheets_your_favorite_cheatsheets_are_now/,kailashahirwar12,1566498766,,2,0
263,2019-8-23,2019,8,23,17,cub5nd,Nvidia made an awesome new imaging tool. http://nvidia-research-mingyuliu.com/gaugan,https://www.reddit.com/r/deeplearning/comments/cub5nd/nvidia_made_an_awesome_new_imaging_tool/,susmit410,1566550201,,2,86
264,2019-8-23,2019,8,23,19,cubylt,Visualizing Class Activation Maps to make ConvNets interpretable in medical imaging,https://www.reddit.com/r/deeplearning/comments/cubylt/visualizing_class_activation_maps_to_make/,ahmedbesbes,1566555792,,0,4
265,2019-8-23,2019,8,23,21,cuddtg,[D] Deep Reinforcement Learning (research) engineer as MSc?,https://www.reddit.com/r/deeplearning/comments/cuddtg/d_deep_reinforcement_learning_research_engineer/,Roboserg,1566564344,"I am from Germany and I looked for jobs both here in Germany and USA for Deep Reinforcement Learning positions. Every single position I've found required a Ph.D. I understand why, the field is new and mostly academic / research work. Still I wonder if anyone has any information about getting a job maybe not as a researcher scientist (where Ph.D. would be required) but maybe as a research engineer when having a [M.Sc](https://m.sc/) degree? As a research engineer you implement papers to solve current problems. The question is, is there any hope for the field of Deep Reinforcement Learning currently? I know for ""classic"" Deep Learning (supervised etc) such positions exist, but I am very interested in deep RL.

I am nearning the end of my [M.Sc](https://m.sc/). in robotics with the master thesis being on Deep Learning. I am teaching myself deep RL on my free time and would like to pursue a career in that field. I find RL and agents interacting with the environment fascinating.

Would like to hear your opinion.",0,1
266,2019-8-23,2019,8,23,22,cudkdc,[Project] Keras implementations of Attention-based BatchNormalization papers,https://www.reddit.com/r/deeplearning/comments/cudkdc/project_keras_implementations_of_attentionbased/,cyril_9227,1566565293,"Hello guys,

I have recently implemented two papers about attention-based BatchNormalization.

1) Attentive Normalization

Arxiv link : [https://arxiv.org/abs/1908.01259](https://arxiv.org/abs/1908.01259) 

Official Pytorch implementation : Not yet released but will be available here  [https://github.com/ivMCL/AttentiveNorm](https://github.com/ivMCL/AttentiveNorm) 

My Keras implementation :  [https://github.com/Cyril9227/Keras\_AttentiveNormalization](https://github.com/Cyril9227/Keras_AttentiveNormalization) 

&amp;#x200B;

2) Instance Enhancement Batch Normalization :

Arxiv link :  [https://arxiv.org/abs/1908.01259](https://arxiv.org/abs/1908.01259) 

Official Pytorch implementation :  [https://github.com/gbup-group/IEBN](https://github.com/gbup-group/IEBN) 

My Keras implementation :  [https://github.com/Cyril9227/Keras\_IEBN](https://github.com/Cyril9227/Keras_IEBN) 

&amp;#x200B;

Both implementations work as a simple droppin replacement of standard BatchNorm layer. Any feedbacks are welcome !

&amp;#x200B;

Thank's :)",0,2
267,2019-8-24,2019,8,24,7,cukmpu,"How to package a custom Keras algorithm as a tensorflow model on Sagemaker, so that it can ingest jpeg images from an S3 bucket",https://www.reddit.com/r/deeplearning/comments/cukmpu/how_to_package_a_custom_keras_algorithm_as_a/,ks23ever,1566597635,"I have a custom Keras cnn that I am trying to package as a tensorflow model and deploy on Sagemaker, using batch transform on jpeg images in an S3 bucket.

I followed this tutorial with my own model-- https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/

However I'm wondering how to use a batch transformer instead. I created a transformer object using the model that I loaded from the tutorial--

import sagemaker as sage sess = sage.Session()

transformer = sagemaker.transformer.Transformer( base_transform_job_name='Batch-Transform', model_name='sagemaker-tensorflow-2019-08-22-20-24-12-590', # insert model name here instance_count=1, instance_type='ml.p2.xlarge', output_path=batch_output, sagemaker_session=sess )

and tried all different versions of calling the .transform method, only to have it error out--

transformer.transform(data=batch_input, content_type='application/x-image') transformer.wait()",1,1
268,2019-8-24,2019,8,24,19,cus11v,Gpt-2 online version!,https://www.reddit.com/r/deeplearning/comments/cus11v/gpt2_online_version/,susmit410,1566644368,https://talktotransformer.com/,10,15
269,2019-8-24,2019,8,24,20,cusids,How to check if tensorflow is working exactly as supposed to with TensorRt engine.,https://www.reddit.com/r/deeplearning/comments/cusids/how_to_check_if_tensorflow_is_working_exactly_as/,mr_meeesix,1566647788,"My setup,

 CUDA 10.0  
 cuDnn 7.6  
 tensorflow 1.14  
 tensorrt 5.0

And I've been following the tutorial by [https://github.com/ardianumam/Tensorflow-TensorRT](https://github.com/ardianumam/Tensorflow-TensorRT)

Every time I run the create inference engine I feel nothing is optimized, I get 0 for number of engine nodes. 

    TensorRT model is successfully stored!
    numb. of all_nodes in frozen graph: 8016
    numb. of trt_engine_nodes in TensorRT graph: 0
    numb. of all_nodes in TensorRT graph: 882

Can you guys let me know what or where the issue is and I get zero errors which is bugging me out.

Thanks",0,2
270,2019-8-24,2019,8,24,23,cutqyt,Fortnite DeepLearning AI,https://www.reddit.com/r/deeplearning/comments/cutqyt/fortnite_deeplearning_ai/,Wandrew33,1566655333,Yo whats up boys I was wondering if it was possible to create a bot that can play Fortnite. If it is and youre able to do it you should definitely do it and post a video of it,0,0
271,2019-8-24,2019,8,24,23,cuu5mm,Project approach consultation - RF / DL / ?,https://www.reddit.com/r/deeplearning/comments/cuu5mm/project_approach_consultation_rf_dl/,progmayo,1566657512,"Hi :) hopefully this isn't too long. I tried accentuating things in bold.

I have a specific project in mind I wish to do using AI, but Im unsure which method to use, and where to focus my time in terms of the different courses and lessons available (ML / DL / etc.). The details are less important, but I'd be happy to explain more if needed. For now Ill just describe what Im trying to achieve in general.

**I have sampled points on a general mult-dimensional tensor, and the goal is to find a mapping function of these points that achieves good results in terms of a criteria I set it (MSE), under a certain constraint - some sort of upper bound limitation on the mapping.** The details are less important, the bottom line is that I'm trying to find a mapping for these points g()=? that minimizes MSE under a constraint. So, for X sampled points, I need to find X points that correspond with their mapping. Everything is continuous of course - the sampled points and their mapping.

**Ive already built** a program that does this using scipy.optimize.minimize, which uses **an iterative method** for constrained nonlinear optimization - uses gradient decent to find a local minimum that achieves the criteria under the constraint.

**I want to try to use and test the performance of a neural network, or random forest,** or something along those lines using AI, but I got a bit lost in the videos I started watching, and I did not find a suitable example that was close to what Im trying to achieve. In short, I'm unsure which algorithm I should be using, and if AI is suited for this task at all, or is what I've already built the ""standard"" way of approaching this task, and that's that.

**Id like to ask which approach you think would suit my problem (RF? DL? etc.), and if you believe that these approaches could possibly outperform the straight-forward approach I already implemented using the iterative method**, which suffers from the unwanted local minimum phenomenon, and is relatively slow in general (especially in high dimensions).",1,2
272,2019-8-24,2019,8,24,23,cuu6ii,Simple Perceptron explanation,https://www.reddit.com/r/deeplearning/comments/cuu6ii/simple_perceptron_explanation/,nottingpill,1566657640,,0,30
273,2019-8-25,2019,8,25,1,cuvalt,"Deep Learning : Colorizing Old Films, Charlie Chaplin's as example",https://www.reddit.com/r/deeplearning/comments/cuvalt/deep_learning_colorizing_old_films_charlie/,jadibelum91,1566663047,"**Deep Learning** is used to colorize old films, **Charlie Chaplin**'s as example , the result is absolutely amazing  [https://www.youtube.com/watch?v=IDrK85g0kdM](https://www.youtube.com/watch?v=IDrK85g0kdM)",0,3
274,2019-8-25,2019,8,25,1,cuvbsr,What is a Tensor ?,https://www.reddit.com/r/deeplearning/comments/cuvbsr/what_is_a_tensor/,nowsden,1566663196,,7,29
275,2019-8-25,2019,8,25,8,cv113f,Prevent overfitting in self recorded dataset: Should I remove background to avoid overfitting in action recognition task?,https://www.reddit.com/r/deeplearning/comments/cv113f/prevent_overfitting_in_self_recorded_dataset/,andytran11996,1566690695,"Hello,
I am working on a small project for my bachelor thesis. Its about a drink fridge with 4 cameras mounted on it ( I just make an experiment with 1  drawer). 3 cameras are mounted on 3 corners of the drawer and 1 on the outside.
It should recognize 3 actions: take, put and pretend to put.
I recorded a dataset about 3000 (x4 cameras) videos, 1000 each class. On a same day ( I tried to change objects position each time, also my shirt)
I split the dataset into 3 parts, 60% train, 20% val, 20% test.
Ive got &gt; 95% accuracy on all of 3 sets, for a second, i was thinking well, I did a very good job. But no, in a live test, it predicts badly, always the same class. At first I thought it was just overfitting, and tried to tune the parameters, adding regularization. That didnt help.
I spent another day to record another dataset, and the results were the same. The model trained on one dataset has bad performance in the other dataset.
 I think the background and the surrounding objects could be the reason (sometimes there was a chair, my colleague sitting on the left, etc). But since its a fridge in my company with my PC on the top, I cant move it elsewhere.
My questions are: 
- What should I do in this situation? Is removing the background ( so only
the arm and the object being taken are kept ) a good way to go? Would it solve the problem? If yes, which background subtractor is best?
- Did you ever have the same problem with self recorded dataset? What are common mistakes and it would be very helpful to hear your experience.

There are not too many public datasets for every task, I think that many other beginners like me could also be struggling with self recorded dataset and I hope this post will be helpful to us all.

Thank you :)",0,0
276,2019-8-25,2019,8,25,11,cv2ifz,Can deep learning read mouse mind?,https://www.reddit.com/r/deeplearning/comments/cv2ifz/can_deep_learning_read_mouse_mind/,Yuqing7,1566698642,,0,0
277,2019-8-25,2019,8,25,14,cv4r0y,What is the difference between Optimization and Deep Learning and why should you care,https://www.reddit.com/r/deeplearning/comments/cv4r0y/what_is_the_difference_between_optimization_and/,sudo_su_,1566711637,,0,4
278,2019-8-25,2019,8,25,14,cv4rrj,"Interview with the leader of mlcourse.ai: Dr. Yury Kashnitsky | mlcourse.ai is an open course with the right balance of theory, practise and kaggle.",https://www.reddit.com/r/deeplearning/comments/cv4rrj/interview_with_the_leader_of_mlcourseai_dr_yury/,init__27,1566711778,"mlcourse.ai is a unique course with the right balance of theory+practise and Kaggle. The final iteration of the course starts on 2nd Sept, 2019. Be sure to sign up!

Following is a link to the interview with the leader of the course. Available both as a podcast, video.

In the interview, we talk all about the efforts and decisions behind the course structure. Yury also shares tips for both future students and alumni of the course.

Audio: https://anchor.fm/chaitimedatascience/episodes/Interview-with-the-Leader-of-mlcourse-ai--Dr--Yury-Kashnitsky--Chai-Time-Data-Science-e52r5u/a-alh171

Video: https://www.youtube.com/watch?v=ZmKGQdCyOFY&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=12",0,1
279,2019-8-25,2019,8,25,14,cv4tic,Computer Vision Final Year Project,https://www.reddit.com/r/deeplearning/comments/cv4tic/computer_vision_final_year_project/,TechRanger19,1566712135,"Hi Everyone, I am in my final Year in Computer Science undergraduate programme. I have little math background in CS background, and did an internship as ML Engineer to develop car plates Detector using YOLOv3 and Darknet. I am looking for Computer Vision project as my Final Year Project. There are few projects that I'm looking into:

1. Plant Disease Detection
2. Type of crops classification using drone image
3. Object detection (need suggestion on this)

As for now, I can do object detection, but i'm new for agriculture application of deep learning.Hope you guys can give me advise and suggestion on this.",5,12
280,2019-8-26,2019,8,26,0,cv9vl9,How to preprocess image to match the model input size ?,https://www.reddit.com/r/deeplearning/comments/cv9vl9/how_to_preprocess_image_to_match_the_model_input/,luxowl,1566746952,"Hello dear deeplearning lovers !

I'm reading and implementing some CNN architectures, the Alexnet architecture take 227x227x3 images input.  
How can I preprocess images to match this input size, do I have to crop and scale it ? It seems a little bit ""naive"" to me, are there other better techniques ?

And also, does all models require a fixed size input ? 

English is not my native language, sorry.

Thank you !",12,8
281,2019-8-26,2019,8,26,1,cvaovq,Find free parking space with Machine Learning,https://www.reddit.com/r/deeplearning/comments/cvaovq/find_free_parking_space_with_machine_learning/,cmillionaire9,1566750845,,2,23
282,2019-8-26,2019,8,26,2,cvbatj,Can any one explain me what exactly is happening . I am new to deep learning with almost no experience the training accuracy and validation accuracy are almost same and increase very very slightly with each epoch and they are starting from 0.98,https://www.reddit.com/r/deeplearning/comments/cvbatj/can_any_one_explain_me_what_exactly_is_happening/,codotron318,1566753681,,17,9
283,2019-8-26,2019,8,26,2,cvbln7,Deep Learning Research - Weekly Update Video,https://www.reddit.com/r/deeplearning/comments/cvbln7/deep_learning_research_weekly_update_video/,HenryAILabs,1566755059,"[https://youtu.be/-be-O1mVD\_Q](https://youtu.be/-be-O1mVD_Q)

Thanks for watching! I would really appreciate feedback on this to improve it!!",0,0
284,2019-8-26,2019,8,26,4,cvd1oa,DeepLearningBook by Ian Goodfellow: poor correspondence between local and global structure,https://www.reddit.com/r/deeplearning/comments/cvd1oa/deeplearningbook_by_ian_goodfellow_poor/,notreallysocool,1566761556,This problem is discussed in section 8.2.7 of the book. Are there any papers recently that address this problem?,4,7
285,2019-8-26,2019,8,26,5,cvdza7,Month-to-month model training and maintenance services,https://www.reddit.com/r/deeplearning/comments/cvdza7/monthtomonth_model_training_and_maintenance/,jennysebastian,1566765973,Check us out at [Techsensus.com](https://Techsensus.com) :),0,3
286,2019-8-26,2019,8,26,6,cveqql,Error while running a file for creating a restaurant chatbot,https://www.reddit.com/r/deeplearning/comments/cveqql/error_while_running_a_file_for_creating_a/,Vigneshwar_MS,1566769572,"**Am creating a restaurant search bot using Rasa framework. When i run the nlu\_model.py file, I have run into issues and i work using a mac. Attached an image of the code. Could you please help me to fix this error?**

Getting the below error :

Rasa NLU version: 0.12.3  
spacy==2.0.11Operating system : Macos

Content of model configuration file:  
language: ""en""  
pipeline: spacy\_sklearn

Full stacktrace below:

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/training\_data/training\_data.py:194: UserWarning: Entity 'people' has only 1 training examples! minimum is 2, training may fail.  
self.MIN\_EXAMPLES\_PER\_ENTITY))  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/training\_data/training\_data.py:194: UserWarning: Entity 'price' has only 1 training examples! minimum is 2, training may fail.  
self.MIN\_EXAMPLES\_PER\_ENTITY))  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/utils/**init**.py:236: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read [https://msg.pyyaml.org/load](https://msg.pyyaml.org/load) for full details.  
return yaml.load(read\_file(filename, ""utf-8""))  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/**init**.py:36: FutureWarning: Conversion of the second argument of issubdtype from float  
to np.floating  
is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type  
.  
from .\_conv import register\_converters as \_register\_converters  
Traceback (most recent call last):  
File ""nlu\_model.py"", line 21, in  
train\_nlu('./data/data.json', 'config\_spacy.json', './models/nlu')  
File ""nlu\_model.py"", line 12, in train\_nlu  
trainer = Trainer(config.load(config\_file), builder)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/model.py"", line 149, in **init**  
self.pipeline = self.\_build\_pipeline(cfg, component\_builder)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/model.py"", line 160, in \_build\_pipeline  
component\_name, cfg)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/components.py"", line 420, in create\_component  
cfg)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/registry.py"", line 140, in create\_component\_by\_name  
return component\_clz.create(config)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/utils/spacy\_utils.py"", line 73, in create  
nlp = spacy.load(spacy\_model\_name, parser=False)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/**init**.py"", line 15, in load  
return util.load\_model(name, \*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 112, in load\_model  
return load\_model\_from\_link(name, \*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 129, in load\_model\_from\_link  
return cls.load(\*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/data/en/**init**.py"", line 12, in load  
return load\_model\_from\_init\_py(**file**, \*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 173, in load\_model\_from\_init\_py  
return load\_model\_from\_path(data\_path, meta, \*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 156, in load\_model\_from\_path  
return nlp.from\_disk(model\_path)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/language.py"", line 653, in from\_disk  
util.from\_disk(path, deserializers, exclude)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 511, in from\_disk  
reader(path / key)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/language.py"", line 649, in  
deserializers\[name\] = lambda p, proc=proc: proc.from\_disk(p, vocab=False)  
File ""pipeline.pyx"", line 643, in spacy.pipeline.Tagger.from\_disk  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 511, in from\_disk  
reader(path / key)  
File ""pipeline.pyx"", line 626, in spacy.pipeline.Tagger.from\_disk.load\_model  
File ""pipeline.pyx"", line 627, in spacy.pipeline.Tagger.from\_disk.load\_model  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/thinc/neural/\_classes/model.py"", line 352, in from\_bytes  
copy\_array(dest, param\[b'value'\])  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/thinc/neural/util.py"", line 48, in copy\_array  
dst\[:\] = src  
ValueError: could not broadcast input array from shape (96) into shape (128)",0,1
287,2019-8-26,2019,8,26,10,cvhb6o,Range of parameters for hyperparameter optmization in fully connected layers,https://www.reddit.com/r/deeplearning/comments/cvhb6o/range_of_parameters_for_hyperparameter/,BlackHawk1001,1566782633,"Hello everybody

I have designed a variational autoencoder with 2D convolutions in the encoder and decoder. I have trained this autoenocder on 50'000 unlabelled images (64 x 80). Now, I would like to use this variational autoencoder for classification on labelled data. To achieve that, I have stacked fully connected layers on top of the encoder, i.e. the latent representation is the input to the fully connected layers. I have made the layers of the encoder trainable, so I will retrain also the autoencoder during classification.

In total I have a 30 dimensional latent space and around 1000 data points (i.e. images) in 2 classes.

I think the two most important parameters for the fully connected layers are the amount of layers and the amount of nodes per layer. I think I should choose this using random search but I need some start values or range.

What range to search for the number of layers and number of nodes per layer makes sense? Especially regarding the number of nodes I'm unsure. When my latent space is of dimension 30, should I use &lt; 30 nodes in all layers? Should the number of nodes from layer to layer be multiplied by 2? For example, 64 nodes in first layer, 128 in second and so on.

Finally, is using Batch normalization or dropout for the fully connected layers reasonable in my situation? I have only 1000 data points and probably a very shallow networks (I think there will be no more than 4 layers).",1,11
288,2019-8-26,2019,8,26,15,cvk8vn,"Interview with the creator of MuseNet: Christine Payne all about MuseNet, OpenAI and Deep Learning Research",https://www.reddit.com/r/deeplearning/comments/cvk8vn/interview_with_the_creator_of_musenet_christine/,init__27,1566800601,"Following are links to an Interview with Christine Mcleavy Payne all about MuseNet, Deep Learning Research, OpenAI  and MOOC(s):  

&amp;#x200B;

We also discuss her journey of starting with the courses by [Andrew Ng](https://twitter.com/AndrewYNg) and [fastdotai](https://twitter.com/fastdotai) to transitioning into Research.    


Audio: [https://anchor.fm/chaitimedatascience/episodes/MuseNet--OpenAI-and-Deep-Learning-Research-Interview-with-Christine-Payne-e4r6hb/a-ak54g2](https://anchor.fm/chaitimedatascience/episodes/MuseNet--OpenAI-and-Deep-Learning-Research-Interview-with-Christine-Payne-e4r6hb/a-ak54g2)

Video: [https://www.youtube.com/watch?v=LSEZXPvEV24&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=13](https://www.youtube.com/watch?v=LSEZXPvEV24&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=13)",0,3
289,2019-8-26,2019,8,26,16,cvkuqg,OpenAI just released GPT-2 text generator and its scary,https://www.reddit.com/r/deeplearning/comments/cvkuqg/openai_just_released_gpt2_text_generator_and_its/,mnluxury11,1566805114,,0,1
290,2019-8-26,2019,8,26,17,cvl45i,Course advice welcomed!,https://www.reddit.com/r/deeplearning/comments/cvl45i/course_advice_welcomed/,squeaki,1566807124,"Hi all.

I'm looking to upskill during a period of downtime before moving onward in my industry. I've enrolled on two courses already on Udemy: [Machine Learning A-Z: Hands-On Python &amp; R In Data Science](https://www.udemy.com/machinelearning/) &amp; [Complete Python Bootcamp: Go from zero to hero in Python 3](https://www.udemy.com/complete-python-bootcamp/)

I am wondering if there are courses I could buy now (10% the cost for a few days) that I will benefit from in the future.

I am looking into image processing and object identification.  
There are a lot of options for Neural Networking/Deep Learning, but I've not the experience with the subject  (like you guys in this sub have already), so I'm asking advice as to which might be worth doing. I'm wiling to buy two courses if need be, as they are 'the right price' at the moment... 10 isn't bad and I feel I can work with these prices.

Would be interested in what you folks think!

[https://www.udemy.com/courses/search/?q=neural%20network&amp;src=sac&amp;kw=Neru](https://www.udemy.com/courses/search/?q=neural%20network&amp;src=sac&amp;kw=Neru)",4,4
291,2019-8-26,2019,8,26,17,cvl7kc,Building Engaging Conversational Interfaces with DialogFlow,https://www.reddit.com/r/deeplearning/comments/cvl7kc/building_engaging_conversational_interfaces_with/,MachineLearning001,1566807878,,0,0
292,2019-8-26,2019,8,26,18,cvlted,Satellite Image (SAR) Segmentation Using Neural Networky,https://www.reddit.com/r/deeplearning/comments/cvlted/satellite_image_sar_segmentation_using_neural/,flyhighwithai,1566812550,,0,1
293,2019-8-26,2019,8,26,23,cvotr2,"Memory Error When Building Large Hdf5 on Amazon AMI (p2.xlarge GPU, 61 GB Memory)",https://www.reddit.com/r/deeplearning/comments/cvotr2/memory_error_when_building_large_hdf5_on_amazon/,juanjop777,1566829769,"Whenever I try to  build an hdf5 dataset, I get an error saying that there is not enough space. I built the dataset on my local machine, and  it is approximately 36 GB.   


I am currently using the p2.xlarge instance with GPU, which comes with 61 GB of memory. 

Right as I ssh into the AMI I get the message:  
***Usage of ""\\"" : 53%***  
***Memory usage: 1%***  
When I run **df -h** I get that I have **/dev/xvda1 at 53%, but 30 GB available in udev and tmpfs.**   


I know that hdf5 files store data as binaries directly on Disk. Therefore:

 **---&gt; How can I move the hdf5 file to use Disk for storage, or udev or tmpfs?**

Thank you very much in advance,  


Juan",3,12
294,2019-8-27,2019,8,27,1,cvpzhy,Is cosine similarity differentiable?,https://www.reddit.com/r/deeplearning/comments/cvpzhy/is_cosine_similarity_differentiable/,mellow54,1566835227,"If I have a function f(X) which is a vector of length N and corresponding labels Y also with vector length N, I can compute the cosine similarity between Y and f(X).

If the function f is a neural network and my loss function is cosine\_sim(Y, f(X)) would it be differentiable? I.e. would I be able to train my neural network weights to minimise the cosine similarity loss?",6,10
295,2019-8-27,2019,8,27,5,cvtplb,Confusion in choosing fields to focus on.,https://www.reddit.com/r/deeplearning/comments/cvtplb/confusion_in_choosing_fields_to_focus_on/,Ryotsou,1566851703,"I am really interested in computer vision, but when I focus on vision, someone inside my head starts whispering 'NLP, NLP'. It's really weird and irritating. Should I give a fair amount of time to both of them? Or what do you suggest,",3,0
296,2019-8-27,2019,8,27,8,cvvvaj,GANs for vehicle trajectories,https://www.reddit.com/r/deeplearning/comments/cvvvaj/gans_for_vehicle_trajectories/,AbdulhadyFeteiha,1566861589,"I'm trying to generate a driving scene consisting of 4 vehicles in a street. I have preprocessed a data set and the result is 720 scenes each consisting of 4 vehicles navigating within the scene. Hence, the scene block dimensions are: 4 objects \* 2 coordinates (x,y)\*40samples.

I tried using usual DCGAN and WGAN algorithms treating the dataset as a collection of images with 2 channels(the x,y coordinates) but the results are disappointing as the generated vehicles are doing only one behavior: going back and forth on a diagonal. I interpreted the results as follows; the model can't capture the different navigation behaviors of the cars (moving forward, backward, on a curve, etc.)

I'm trying to migrate to different models, ones having a sequence capturing module (RNN/LSTM). What are your recommendations?

Finally, do you think that the whole project is promising, or it's a dead-ending approach?",0,5
297,2019-8-27,2019,8,27,8,cvwbpj,Speech Specific Text to speech model,https://www.reddit.com/r/deeplearning/comments/cvwbpj/speech_specific_text_to_speech_model/,muaz65,1566863799,"Does anyone here have any idea regarding a pre trained text to speech model which should be capable of generating person specific speech. Like a model should only require a single voice clip of a person and the speech generated by the model should be in the voice of the audio file provided.

I am unable to phrase my question in exact manner. My point is to find a pertained model/ api or something which can do following after training.
-Take a speech sample 
-Take a textual input 
-Generate speech of the given text in (tone/voice/accent) of the sound file given as a sample.

I have seen some models like [deepVoice](https://github.com/r9y9/deepvoice3_pytorch) but i am unable to understand the testing mechanism.",3,4
298,2019-8-27,2019,8,27,9,cvx04n,Create Your Own Synthetic Voice With Just One Hour of Speech (Lyrebird Review),https://www.reddit.com/r/deeplearning/comments/cvx04n/create_your_own_synthetic_voice_with_just_one/,LimarcAmbalina,1566867195,,0,36
299,2019-8-27,2019,8,27,12,cvyxrk,Video scoring with deep learning,https://www.reddit.com/r/deeplearning/comments/cvyxrk/video_scoring_with_deep_learning/,arianaa30,1566877352," I am trying to rank video scenes/frames based on how appealing they are for a viewer. Basically, how ""interesting"" or ""attractive"" a scene inside a video can be for a viewer. My final goal is to generate say a 10-second short summary given a video as input, such as those seen on Youtube when you hover your mouse on a video.

I found an ""aesthetics"" model is good for ranking artistic images, but not good for frames of videos. So it was failing. I need a score based on ""engagement for general audience"". Basically, which scenes/frames of video will drive more clicks, likes, and shares when selected as a thumbnail.

Do we have an available deep-learning model or a prototype doing that? A ready-to-use prototype/model that I can test as opposed to a paper that I need to implement myself. Paper is fine as long as the code is open-source. I'm new and can't yet write a code given a paper.",0,1
300,2019-8-27,2019,8,27,16,cw11o6,When you build NER classifiers using BERT like Language models should the pretrained BERT weights also be adjusted while training the classifier?,https://www.reddit.com/r/deeplearning/comments/cw11o6/when_you_build_ner_classifiers_using_bert_like/,darkangel404,1566891082,,2,4
301,2019-8-27,2019,8,27,17,cw1doh,Who started deep neural embedding idea?,https://www.reddit.com/r/deeplearning/comments/cw1doh/who_started_deep_neural_embedding_idea/,pk12_,1566893569,"Does anyone have a definitive reference?

To my knowledge, Yoshua Bengio had a paper titled ""A Neural Probabilistic Language Model"", but this is for text modality only. 

Did someone propose neural embeddings before them on generating embeddings for various modalities through neural networks?",2,3
302,2019-8-27,2019,8,27,20,cw3byk,Download and analyze textual data from the comfort of your spreadsheet with ParallelDots' SmartReader,https://www.reddit.com/r/deeplearning/comments/cw3byk/download_and_analyze_textual_data_from_the/,anantcoolblabla,1566906635,,0,1
303,2019-8-28,2019,8,28,2,cw81o1,Distilling BERT Models with spaCy,https://www.reddit.com/r/deeplearning/comments/cw81o1/distilling_bert_models_with_spacy/,yvespeirsman,1566928739,,0,25
304,2019-8-28,2019,8,28,3,cw8ktj,Unexpected result in using multiple GPUs in keras/tensorflow,https://www.reddit.com/r/deeplearning/comments/cw8ktj/unexpected_result_in_using_multiple_gpus_in/,shahriar49,1566931127,"I am using TF 1.14 and my computer has two GPUs, so I was interested to utilize both in parallel. I found different ways of doing that and it looks like the platform is very dynamic and I was confused on what to do. I generally found below two methods for doing data parallelization in keras/tensorflow:

&amp;#x200B;

Method 1:

    with tf.device('/cpu:0'):
        model = ...
    parallel_model = multi_gpu_model(model, gpus=2)
    parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

Method 2:

    strategy = tf.distribute.MirroredStrategy()
    with strategy.scope():
        parallel_model = ...
        parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

I tried both of the above methods, and also ran my simulation on a non-parallel mode of training (which uses just one GPU). However, the results were very strange and I don't understand what is the problem. For my specific network and data, in Method 1 the training took around 1100 seconds, while in Method 2 it took 270 seconds. Just using one GPU and halving the batch size (to make it fair to compare with parallel models) the training took around 500 seconds. So, the Method 2 result makes sense as the training time is about half the single GPU case, but what is wrong with the first method? Should I phase it out and just forget it?

P.S. I also see a minor change in reported model summary report that I have not seen previously on my non-multi-gpu machine, which is extra square brackets around the input layer shape \[(None, None, 8)\]:

    Layer (type)                 Output Shape              Param #   
    input_1 (InputLayer)         [(None, None, 8)]         0         
    lstm (LSTM)                  (None, None, 16)          1600      
    lstm_1 (LSTM)                (None, None, 16)          2112      
    lstm_2 (LSTM)                (None, 16)                2112      
    dense (Dense)                (None, 7)                 119       
    Total params: 5,943

What is this?",0,0
305,2019-8-28,2019,8,28,5,cw9y5b,"Should I consider learning this stuff? I'm coming straight to the source, and I promise this isn't bait.",https://www.reddit.com/r/deeplearning/comments/cw9y5b/should_i_consider_learning_this_stuff_im_coming/,HolyCrapItsZombies,1566937213,"I am fascinated with ML/DL, GANs, and the things that I'm seeing on a daily basis.  The GauGAN is an example of the stuff that seems simple but is super impressive, or thispersondoesnotexist/thisarticledoesnotexist. Deepfakes, computer generated voices/text and even AI music simultaneously freak me out, and kickstart my imagination at the same time. I sub and try my best to follow the Lex Fridman AI podcast, even when it gets too technical, so that's about the extent of what I know- I can follow most of what's being discussed, but actually \*do\* none of it.   


I feel like if I had a pocket-sized genius coder with me we could do amazing things just spitballing uses for this tech. But there's just me, with zero coding experience. I programmed a tank game on Commodore 64 when I was 9, back in 1990, and that's it. It was not a joy, and was tedious copy-paste if my childhood memory serves. So is getting fluent this field as daunting as becoming fluent in Mandarin, or high level physics or something like that? I'd be looking to earn eventually, not just fiddle around as a hobby. Somebody talk me into it or out of it please.",3,0
306,2019-8-28,2019,8,28,5,cw9yau,Foundations of Neuroevolution - The NEAT algorithm explained!,https://www.reddit.com/r/deeplearning/comments/cw9yau/foundations_of_neuroevolution_the_neat_algorithm/,HenryAILabs,1566937229,[https://youtu.be/b3D8jPmcw-g](https://youtu.be/b3D8jPmcw-g),2,7
307,2019-8-28,2019,8,28,19,cwj3qm,Deep Learning Based OCR for Text in the Wild,https://www.reddit.com/r/deeplearning/comments/cwj3qm/deep_learning_based_ocr_for_text_in_the_wild/,manneshiva,1566989378,"Learn how to do Optical Character Recognition(OCR) to extract text from passports, number plates, and handwritten texts to PDF, invoices, receipts.  [https://nanonets.com/blog/deep-learning-ocr/](https://nanonets.com/blog/deep-learning-ocr/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=ocrw&amp;utm_content=dl)

https://i.redd.it/t2ppylm866j31.gif",1,24
308,2019-8-28,2019,8,28,20,cwjf1t,Assembling an Ideal Team to Build AI Chatbots,https://www.reddit.com/r/deeplearning/comments/cwjf1t/assembling_an_ideal_team_to_build_ai_chatbots/,MachineLearning001,1566991307,,0,0
309,2019-8-29,2019,8,29,0,cwm39d,[Research] A Realistic Face-to-Face Conversation System based on Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/cwm39d/research_a_realistic_facetoface_conversation/,cdossman,1567004928,[removed],0,1
310,2019-8-29,2019,8,29,2,cwoce5,How to use ML to make an A.I sports commentator?,https://www.reddit.com/r/deeplearning/comments/cwoce5/how_to_use_ml_to_make_an_ai_sports_commentator/,AboutVR018734,1567015083,"I know basics of programming (just starting). I want to teach for an ML program to be a commentator for  EA Sports FIFA Soccer. I am fed up with the slow progress of commentary in these games and its all scripted.

How to I get started?

&amp;#x200B;

Thanks",7,2
311,2019-8-29,2019,8,29,3,cwoiit,Faceswap made easy,https://www.reddit.com/r/deeplearning/comments/cwoiit/faceswap_made_easy/,susmit410,1567015825,,0,1
312,2019-8-29,2019,8,29,7,cwrtx1,How would you prefer using a Deep Learning Library? Let's build one together!,https://www.reddit.com/r/deeplearning/comments/cwrtx1/how_would_you_prefer_using_a_deep_learning/,akifnane,1567030724,"Hi, this will be my first post at Reddit.

I have been working on both Deep Learning and Numeric libraries recently. I was fascinated by matrix expressions and trying to calculate derivatives of matrix terms. I always wanted to have flexibility in deep learning. The libraries that can give you all opportunities with less complexity. I worked hard for two-three weeks to build a deep learning and a numeric library. When I needed a high optimized calculation, I coded it in numeric library and used it in deep learning library. Enough background!

Before building whole library, I'd like to get your ideas and opinions about how it is and it should be. I'm kinda scared to do things before consulting people. So, I am asking you how I should design the library. I will give you some code snippets to let you know what I built.

&amp;#x200B;

Manually assigning weights to a variable:

https://i.redd.it/9e4qjo86l9j31.png

Creating a custom Layer manually (not coded in library, it is temporary code)

https://i.redd.it/118hj0r6l9j31.png

Creating a XOR network (with 3 hidden layers)

https://i.redd.it/qyobbe87l9j31.png

For example we can use loss functions above. new Power(new Minus(model, y), 2); this code means squared error. I can make quick methods for loss functions like squared error etc. For now I don't wanna do over commit before deciding for what's best.

Hyperparameters (Global, not model dependent):

https://i.redd.it/0trsbos9l9j31.png

Training a model:

https://i.redd.it/8tvzur2al9j31.png

I think this is a retty code that no one should be scared of. Training is so easy. Dot minimize! that's all!

I can get rid of 'new' words when creating a layer or terms. (new power new minus etc).

I tested the code on MNIST data. It works. However CNN layers are not implemented. So, generalization of the model is not good as it is when used cnn ofc. But it works :)

How should I go on? Any designing ideas?

I hope I will bring dynamic dimensions for layers.

soon I will publish the library at My [Github Repo](https://github.com/faruknane)",0,1
313,2019-8-29,2019,8,29,9,cwtayb,"""Many Sets of Model Parameters Fit the Data Well""",https://www.reddit.com/r/deeplearning/comments/cwtayb/many_sets_of_model_parameters_fit_the_data_well/,arjundupa,1567038100,"I was reading through Andrew Ng's newest release of The Batch, where a sentence of his caught my attention:

&gt;If the training data set is small and many sets of model parameters fit the data well, for instance, the network may not realize this explicitly, leading to overly confident predictions.

I started wondering the following: if multiple models are trained on a relatively small dataset and all models (initialized to random weights) perform well but have widely varying weights, can the the models be combined in any way for an overall performance gain? Has this been explored?",3,9
314,2019-8-29,2019,8,29,11,cwur7o,Using PyTorch C++ and OpenCV (C++) in Jupyter Notebook using Xeus-Cling?,https://www.reddit.com/r/deeplearning/comments/cwur7o/using_pytorch_c_and_opencv_c_in_jupyter_notebook/,Kushashwa,1567045673,"Hi Everyone!

As some would know, I had started writing blogs on using PyTorch C++ API. Another blog in the series on **Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries** is out. 

Link to the blog:  [https://krshrimali.github.io/Setting-Up-Xeus-Cling-Libtorch-OpenCV/](https://krshrimali.github.io/Setting-Up-Xeus-Cling-Libtorch-OpenCV/) 

Repository:  [https://github.com/krshrimali/Transfer-Learning-Dogs-Cats-Libtorch](https://github.com/krshrimali/Transfer-Learning-Dogs-Cats-Libtorch) 

[Blog 07 in the Series! Check more blogs on: https:\/\/krshrimali.github.io](https://i.redd.it/wmxoz71qtaj31.jpg)

Please share your feedback in the comments below. 

Thanks!",2,20
315,2019-8-29,2019,8,29,12,cwvb6i,Pruning,https://www.reddit.com/r/deeplearning/comments/cwvb6i/pruning/,arjundupa,1567048758,"What are some ways to know that pruning might be possible on your architecture (given your results, train/val loss curve, etc.)? Is there any literature out there that tries to answer this question?",0,1
316,2019-8-29,2019,8,29,16,cwxc83,"Its a No Brainer: An Introduction to Neural Networks (A gentle introduction to neural networks, now with zombies.)",https://www.reddit.com/r/deeplearning/comments/cwxc83/its_a_no_brainer_an_introduction_to_neural/,bugggster,1567062179,,0,3
317,2019-8-29,2019,8,29,16,cwxhlx,How AI and Chatbots are Enriching Mobile Apps,https://www.reddit.com/r/deeplearning/comments/cwxhlx/how_ai_and_chatbots_are_enriching_mobile_apps/,MachineLearning001,1567063234,,2,3
318,2019-8-29,2019,8,29,17,cwy31u,Mask RCNN,https://www.reddit.com/r/deeplearning/comments/cwy31u/mask_rcnn/,wanabe_sarkaribabu,1567067801,"I'm trying to run a demo for object detection program by following a video given on YouTube . However I'm not able to run my CMD commands as they're depicted in video. Can someone suggest me some other video for same ?

Link of the video that I'm watching:

https://youtu.be/2TikTv6PWDw",1,0
319,2019-8-30,2019,8,30,0,cx2g32,How would you prefer using a Deep Learning Library? Let's build one together!,https://www.reddit.com/r/deeplearning/comments/cx2g32/how_would_you_prefer_using_a_deep_learning/,akifnane,1567092544,,6,0
320,2019-8-30,2019,8,30,1,cx3hos,Best 4 Ways to Handle Missing Values in Pandas in Machine Learning,https://www.reddit.com/r/deeplearning/comments/cx3hos/best_4_ways_to_handle_missing_values_in_pandas_in/,subhamroy021,1567097331,,0,0
321,2019-8-30,2019,8,30,5,cx6hx4,Foundations of Neuroevolution - The CoDeepNEAT algorithm explained!,https://www.reddit.com/r/deeplearning/comments/cx6hx4/foundations_of_neuroevolution_the_codeepneat/,HenryAILabs,1567110906,[https://youtu.be/XvCbgwhMVu4](https://youtu.be/XvCbgwhMVu4),0,8
322,2019-8-30,2019,8,30,7,cx7rub,Building projects in order to get an internship,https://www.reddit.com/r/deeplearning/comments/cx7rub/building_projects_in_order_to_get_an_internship/,Krokodeale,1567116579,"Hi guys, 

I'll start my last year in my master's degree and I've got an internship to do for 6 months in 2020. This year is spe AI and I've already done some basic projects in DP. However, for my internship, I wanna be ambitious and try to look for some goods labs in order to get a PhD after.

But I don't know really what kind of projects that I can do to present my lvl in CS. I know it's important to have a good Github profile, but what do people expect from a student at my level ? Any idea from where to start ? I've got the feeling that doing things that have already been done isn't really worth it.

Thank you for you time",1,0
323,2019-8-30,2019,8,30,8,cx8mwp,Good book for neural network starter,https://www.reddit.com/r/deeplearning/comments/cx8mwp/good_book_for_neural_network_starter/,skyquek,1567120685,I am looking for free books that can help me understand the concept of neural network and deep learning. Best is come with some python example. I have some understanding on Machine Learning concept.,3,0
324,2019-8-30,2019,8,30,10,cxa1r3,How to combine multiple dataset that has different focuses,https://www.reddit.com/r/deeplearning/comments/cxa1r3/how_to_combine_multiple_dataset_that_has/,PotentialAnybody,1567128020,"I am currently training an object detection model for traffic obstacle detection. 

While I am thinking of combining different dataset to make the training more robust, I found that, even though some dataset has the class I am interested in, it doesn't always label the other class that I am also training for.

For example, Tsinghua cyclist dataset labels a large number of cyclists, but it doesn't label any cars or pedestrians or traffic light.  

So my question is, how can I combine different dataset (e.g. coco + bdd100k + Tsinghua cyclist), and tell the training that I am only interested in the class it labelled. In other word, how I can tell my network during training that, when you predict a car in the Tsinghua cyclist dataset, don't bother if the ground truth doesn't label a car there, so don't update your weight during the back prop. 

If anyone can share their trick combining dataset, I would really appreciate it.

Thanks in advance",14,10
325,2019-8-30,2019,8,30,11,cxaph7,GTX 1650 laptop or Google colab?,https://www.reddit.com/r/deeplearning/comments/cxaph7/gtx_1650_laptop_or_google_colab/,wade_wilson2120,1567131580,,13,11
326,2019-8-30,2019,8,30,12,cxbovi,few shot face translation GAN: Face swapping video from a single image without training for any face,https://www.reddit.com/r/deeplearning/comments/cxbovi/few_shot_face_translation_gan_face_swapping_video/,PuzzledProgrammer3,1567137222,"Generative adversarial networks integrating modules from FUNIT and SPADE for face-swapping

github link: [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN)

elon musk and taylor swift demo video

![video](9hve1gfydij31)",0,30
327,2019-8-30,2019,8,30,15,cxd3rw,How to determine queries are context related,https://www.reddit.com/r/deeplearning/comments/cxd3rw/how_to_determine_queries_are_context_related/,CharlesLiuChina,1567146434,[removed],0,1
328,2019-8-30,2019,8,30,18,cxeri9,Intuition behind probability theory in image data,https://www.reddit.com/r/deeplearning/comments/cxeri9/intuition_behind_probability_theory_in_image_data/,PyWarrior,1567158950,"I am not able to relate the concepts of probability theory to image theory like 
1. What is the probability distribution of Image data
2. What is fitting a gaussian to an image data and what is it's practicality?

There are many more concepts. I think there is a huge gap between Neural Networks and Probability theory.

Can anyone refer me some good resources including videos or blogs or books which can give me detailed knowledge and complete understanding about probability theory in case of image dataset and help me bridge the gap between Neural Networks and Probability theory.

Thanks in advance",0,1
329,2019-8-30,2019,8,30,20,cxfvw6,Strengthening Cybersecurity with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/cxfvw6/strengthening_cybersecurity_with_artificial/,MachineLearning001,1567166169,,0,0
330,2019-8-31,2019,8,31,5,cxm54p,Is it generally better to look for more cores or more memory when considering GPU,https://www.reddit.com/r/deeplearning/comments/cxm54p/is_it_generally_better_to_look_for_more_cores_or/,dsync1,1567195504,"Basically, should I go with a 2x Titan RTX setup, or a 4x 2080 TI setup in building a rig for mostly NLP experimentation?",9,14
331,2019-8-31,2019,8,31,7,cxnwk9,Transfer Learning for Segmentation Using DeepLabv3 in PyTorch,https://www.reddit.com/r/deeplearning/comments/cxnwk9/transfer_learning_for_segmentation_using/,msminhas93,1567203996,,0,6
332,2019-8-31,2019,8,31,8,cxos4u,Meu Depoimento sobre...,https://www.reddit.com/r/deeplearning/comments/cxos4u/meu_depoimento_sobre/,guilherme_onassis,1567208416,,0,1
333,2019-8-31,2019,8,31,13,cxrgkk,When training Bert for multitask learning should be provide the Bert output to a LSTM layer?,https://www.reddit.com/r/deeplearning/comments/cxrgkk/when_training_bert_for_multitask_learning_should/,darkangel404,1567224198,Bert to LSTM ... Then the output of the LSTM is given to the three output layers and the second output layer is dependent on the first and third is dependant on first and second.,4,0
334,2019-8-31,2019,8,31,13,cxrm0o,"For a AI startup, whats the basic workstation should we have?",https://www.reddit.com/r/deeplearning/comments/cxrm0o/for_a_ai_startup_whats_the_basic_workstation/,stevevaius,1567225199,We decided to get in business of offering ML and DL solutions for Banking (fraud detection) and computer vision ( obj detection-recognition). But we are in short of cash (approx 3-4000 usd we have for workstation) Any offer for our business startup workstation? What should we consider before buy it? what models offer all-in solutions? price/performance focused,29,5
0,2019-9-1,2019,9,1,15,cy6ihy,This package sends your deep learning training metrics to your slack channel/user after ever specified epoch.,https://www.reddit.com/r/deeplearning/comments/cy6ihy/this_package_sends_your_deep_learning_training/,clean_pegasus,1567318212,,3,86
1,2019-9-1,2019,9,1,18,cy7xjs,Would you use my deep learning library?,https://www.reddit.com/r/deeplearning/comments/cy7xjs/would_you_use_my_deep_learning_library/,akifnane,1567330017,"Hi, I have been working to develop a library for deep learning. I found the current libraries so complex. To reduce the complexity with increased accessibility, I wrote my own library which is currently published at Github. With the help of the community, I believe that we will improve it together. You check the project [DeepLearningFramework](https://github.com/faruknane/DeepLearningFramework). If you want to support me:  [afaruknane](https://www.patreon.com/afaruknane) 

&amp;#x200B;

&amp;#x200B;

*Processing img kw96kqy6byj31...*",3,0
2,2019-9-1,2019,9,1,18,cy7yjn,Introduction to Neural Networks and Deep Learning from scratch (with Python code),https://www.reddit.com/r/deeplearning/comments/cy7yjn/introduction_to_neural_networks_and_deep_learning/,ahmedbesbes,1567330274,,0,0
3,2019-9-1,2019,9,1,18,cy7zmo,Introduction to Neural Networks and Deep Learning from scratch (with Python code),https://www.reddit.com/r/deeplearning/comments/cy7zmo/introduction_to_neural_networks_and_deep_learning/,ahmedbesbes,1567330504,"\[Understand basics of Deep Learning from scratch\]

  
If you're willing to understand how neural networks work behind the scene and debug the back-propagation algorithm step by step by yourself, these slides should be a good starting point.   


We will cover deep learning popular applications, the concept of the artificial neuron and how it relates to the biological one, the perceptron and the multi-layer one. We'll also dive in activation functions, loss functions and **formalize the training of a neural net via the back-propagation algorithm.**   


In the last part, you'll learn how to code a fully functioning trainable neural network from scratch. In pure python code only, with no frameworks involved.   


* slides: [https://ahmedbesbes.com/introduction-to-neural-networks-and-deep-learning-from-scratch.html](https://ahmedbesbes.com/introduction-to-neural-networks-and-deep-learning-from-scratch.html?fbclid=IwAR1H62DydAiXxTjEL-BozJ8cfIWoefMWHQmIYQXDHqgThldRFn3rdrxRM4E)
* code: [https://github.com/ahmedbesbes/Neural-Network-from-scratch](https://github.com/ahmedbesbes/Neural-Network-from-scratch?fbclid=IwAR3V1YoIK78eUqe6s_lcHnjeEgGlGrsNi8qpDOOWsMZ4i2_RVuBa1yRKZBA)

[\#deeplearning](https://www.facebook.com/hashtag/deeplearning?source=note&amp;epa=HASHTAG)

![video](5me6qp3icyj31 ""Back-propagation"")",0,1
4,2019-9-1,2019,9,1,21,cy9lvg,"Random Question: Which datasets would you like to obtain for your projects, but is time-consuming to collect or not easily available online?",https://www.reddit.com/r/deeplearning/comments/cy9lvg/random_question_which_datasets_would_you_like_to/,jubashun,1567342605,,1,5
5,2019-9-1,2019,9,1,22,cy9x06,Would it be possible to create a NN which recognizes handwritten numbers using only synthetic data?,https://www.reddit.com/r/deeplearning/comments/cy9x06/would_it_be_possible_to_create_a_nn_which/,Wizard_Dog,1567344401,"Hey, I'm a complete newbie so I'm sorry if this is dumb. I think technically it should be possible to do this by using randomized manipulations on the pictures of numbers written by different fonts. What do you think?",2,2
6,2019-9-2,2019,9,2,1,cybv5o,Machine Learning Practical: 6 Real-World Applications,https://www.reddit.com/r/deeplearning/comments/cybv5o/machine_learning_practical_6_realworld/,HannahHumphreys,1567354409,[removed],0,1
7,2019-9-2,2019,9,2,3,cydfbq,"My goal is to be deep learning engineer with focus on computer vision, can i disregard traditional machine learning methods?",https://www.reddit.com/r/deeplearning/comments/cydfbq/my_goal_is_to_be_deep_learning_engineer_with/,PmMeFunThings,1567361753,"Hi, I want to learn deep learning. (Already doing fro deep learning book) and hands on machine learning and fast.ai. 

I also have some grasp of traditional machine learning (from hands on machine learning and islr) can I dive deeply in to deep learning disregarding traditional approach.

My focus is on computer vision through deep learning. Or should I have to strengthen my intuition of traditional methods too(from participating in kaggle I suppose)
?",12,1
8,2019-9-2,2019,9,2,3,cydu8s,"Machine Learning - Ride in Self-Driving Car [autonomous car, driverless car, robotic car]",https://www.reddit.com/r/deeplearning/comments/cydu8s/machine_learning_ride_in_selfdriving_car/,cmillionaire9,1567363692,,2,11
9,2019-9-2,2019,9,2,4,cye6y6,An open-source data annotation tool for YOLO,https://www.reddit.com/r/deeplearning/comments/cye6y6/an_opensource_data_annotation_tool_for_yolo/,ayvin_tech,1567365327,"If you are familiar with object detection using deep learning, then you must be knowing about the importance of YOLO in this field. It has enabled researchers to train and test object detection quickly and efficiently in their respective works. However, I found that few of the beginners still feel hesitant to train YOLO on their own dataset due to limited knowledge of data annotation in proper format.

Thus, I have open-sourced my data annotation toolbox for YOLO so that the researchers and students can use it to build innovative projects without any limitations. This toolbox, named Yolo Annotation Tool (YAT), can be used to annotate data directly into the format required by YOLO. All you need is to create a label file containing all the class names to be trained.

Code available at [https://github.com/2vin/yolo\_annotation\_tool](https://github.com/2vin/yolo_annotation_tool)",6,13
10,2019-9-2,2019,9,2,5,cyerax,Deep Learning Research - Weekly Update Video,https://www.reddit.com/r/deeplearning/comments/cyerax/deep_learning_research_weekly_update_video/,HenryAILabs,1567368012,[https://youtu.be/kM4sFEaxXn4](https://youtu.be/kM4sFEaxXn4),0,7
11,2019-9-2,2019,9,2,14,cyksbn,Segmentation of fashion items,https://www.reddit.com/r/deeplearning/comments/cyksbn/segmentation_of_fashion_items/,Snehal-Reddy,1567401797,"Any AI researcher working in the field of fashion recommendation would understand the importance of segmentation of fashion items from an image. Ive created a Mask RCNN segmentation tool which can be trained on DeepFashion 2 dataset easily.

Code - https://github.com/Snehal-Reddy/DeepFashion_MRCNN",0,1
12,2019-9-2,2019,9,2,14,cykwj0,Fashion item segmentation,https://www.reddit.com/r/deeplearning/comments/cykwj0/fashion_item_segmentation/,Snehal-Reddy,1567402564,"Any AI researcher working in the field of fahsik recommendation would understand the importance of fashion items segmentation from the image of a person. These segmentation masks are very important as these can be used later on for various other tasks in fashion recommendation.
I have written a Mask-RCNN based segmentation network which can be trained on DeepFashion2 dataset with ease. I hope this will help other researchers.

Code - https://github.com/Snehal-Reddy/DeepFashion_MRCNN",0,7
13,2019-9-2,2019,9,2,15,cylcwf,Transforming CRM Operations With Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/cylcwf/transforming_crm_operations_with_artificial/,MachineLearning001,1567405626,,0,0
14,2019-9-2,2019,9,2,15,cylj6f,How to balance a multi label highly inbalanced large dataset by preprocessing it (down sampling),https://www.reddit.com/r/deeplearning/comments/cylj6f/how_to_balance_a_multi_label_highly_inbalanced/,moshelll,1567406908,I have a huge dataset that has 100 multilabels. Some if them are several times more frequent than the others. I would like to balance it somehow by removing images from the set following some algorithm. I am ok with ending with 10th of the dataset. Any ideas? (other than finding images that has only the frequent labels and removing them... This won't get me far unfortunately),4,1
15,2019-9-2,2019,9,2,17,cym50k,What is the average desired Salary for a first job as a datascientist in deep learning in the US ?,https://www.reddit.com/r/deeplearning/comments/cym50k/what_is_the_average_desired_salary_for_a_first/,Atralb,1567411449,"I come from a EU country and am interested to go work in the US. However, given widely different taxes and social policies compared to Europe, salaries are extremely different and other factors make these differences not simply proportional if we look at different specialties. And I find it difficult to find this specific info publicly on the internet, most numbers given are an average for all datascientist without regard to seniority.  


So that's why I would be grateful if some graduating students or young graduates could give me a little insight on averages salaries for first job in the sector. If you got deeper information I'll gladly read it too !  


Thanks !  


PS : if this matters, I'm mainly coding with Keras with Tensorflow as a backend and happen to progressively become specialized in Computer Vision even though it's not voluntary. Still interested to hear any experience in any field !",18,7
16,2019-9-2,2019,9,2,17,cymb1i,Please help in debugging this code,https://www.reddit.com/r/deeplearning/comments/cymb1i/please_help_in_debugging_this_code/,kioriaanthony,1567412775, [https://www.kaggle.com/kioriaanthony/isic2019v2](https://www.kaggle.com/kioriaanthony/isic2019v2),1,0
17,2019-9-2,2019,9,2,18,cymoju,https://github.com/2vin/deep-gesture-recognition,https://www.reddit.com/r/deeplearning/comments/cymoju/httpsgithubcom2vindeepgesturerecognition/,ayvin_tech,1567415761,"An open-source gesture recognition model for researchers and students to build gesture-enabled devices on the go. Current model supports three hand gestures under varying pose, lighting and rotation. Have a look at how it performed on realtime camera feed.

&amp;#x200B;

*Processing gif r5vs832dd5k31...*

Code available at [https://github.com/2vin/deep-gesture-recognition](https://github.com/2vin/deep-gesture-recognition) 

Feel free to use this DL model in your projects and let me know your feedback.",0,1
18,2019-9-2,2019,9,2,19,cyn84z,Benefits of Using Machine Learning in Supply Chain,https://www.reddit.com/r/deeplearning/comments/cyn84z/benefits_of_using_machine_learning_in_supply_chain/,erpintegration,1567419783,,0,4
19,2019-9-2,2019,9,2,19,cyn9v5,Irregular time interval by LSTM,https://www.reddit.com/r/deeplearning/comments/cyn9v5/irregular_time_interval_by_lstm/,hadi_saadatdoorabi,1567420138,"If we have a sequence of time-series with irregular time interval between each instance then how we can use LSTM (Long Short Term Memory) to predict its label or the time-series value in the next instance (let say we don't want to predict the next event's time, only the value or some specific label) since the time interval is potentially a rich feature for our data.

I can encode the time interval within the instances as a numeric feature in each time instance but is there any time aware LSTM (or Any other RNN model) which considers this interval by nature? (I mean the model accept the time instances array and other features as the model input?!)

P.S: Any sample codes or pesudo-codes are welcome",8,3
20,2019-9-2,2019,9,2,23,cypgn3,Best Online MOOC for Deep Learning,https://www.reddit.com/r/deeplearning/comments/cypgn3/best_online_mooc_for_deep_learning/,blitz_ares,1567433522,"Can you suggest some good online courses(Paid or Free) or resources for someone who has fair knowledge of traditional ML algorithms,but no knowledge on Neural net and other deep learning algorithms.",11,15
21,2019-9-3,2019,9,3,2,cys2k3,Compuational Graphs in TensorFlow,https://www.reddit.com/r/deeplearning/comments/cys2k3/compuational_graphs_in_tensorflow/,msminhas93,1567445313,,0,1
22,2019-9-3,2019,9,3,2,cyscv3,Deep Learning Swag,https://www.reddit.com/r/deeplearning/comments/cyscv3/deep_learning_swag/,juanjop777,1567446538,"Does anyone know about some **cool and geeky/nerdy deep learning swag** out there? Something like a t-shirt, hoodie or mug with all modern heroes of deep learning or the most famous CNN architectures of recent years?!

&amp;#x200B;

Thanks!",9,3
23,2019-9-3,2019,9,3,3,cysiy7,Zao's deepfake app replaces faces in seconds,https://www.reddit.com/r/deeplearning/comments/cysiy7/zaos_deepfake_app_replaces_faces_in_seconds/,cmillionaire9,1567447280,,2,52
24,2019-9-3,2019,9,3,4,cytmg6,Back-propagation Demystified [Part 3] | Computational Graphs in TensorFlow,https://www.reddit.com/r/deeplearning/comments/cytmg6/backpropagation_demystified_part_3_computational/,msminhas93,1567452100,,0,1
25,2019-9-3,2019,9,3,9,cyxlcy,PyWarm: A cleaner way to build neural networks for PyTorch.,https://www.reddit.com/r/deeplearning/comments/cyxlcy/pywarm_a_cleaner_way_to_build_neural_networks_for/,very-blue-season,1567470975,"[https://github.com/blue-season/pywarm](https://github.com/blue-season/pywarm) 

[PyWarm](https://github.com/blue-season/pywarm) is a high-level neural network construction API for PyTorch.

With PyWarm, you can put *all* network data flow logic in the `forward()` method of your model, without the need to define children modules in the `__init__()` method. This result in a much readable model definition in fewer lines of code. Check the github repository for code examples and more details!",2,1
26,2019-9-3,2019,9,3,16,cz1gqt,Interview Questions,https://www.reddit.com/r/deeplearning/comments/cz1gqt/interview_questions/,moizsawan,1567494726,"Hi all!  
I need to take a candidate's interview. His basics of DL are strong. But I need to ask him some tricky questions. Can you please provide me with some tricky questions with the answer key? Thank you",9,0
27,2019-9-3,2019,9,3,19,cz3a8t,Github: Pytorch Text Recognition tool,https://www.reddit.com/r/deeplearning/comments/cz3a8t/github_pytorch_text_recognition_tool/,s3nh_,1567508265,"CRAFT:   [https://arxiv.org/abs/1904.01941](https://arxiv.org/abs/1904.01941)

CRNN: [https://arxiv.org/abs/1507.05717](https://arxiv.org/abs/1507.05717)",0,3
28,2019-9-3,2019,9,3,21,cz4fkg,Best methods to represent molecules for DeepLearning?,https://www.reddit.com/r/deeplearning/comments/cz4fkg/best_methods_to_represent_molecules_for/,HenriqueCSJ,1567514955,"  

Dear colleagues, how are you?

I'm an inorganic chemist doing my PhD using metalorganic molecules. In such molecules we have exotic geometries around the metallic centers and the organic ligands. As I can see, representation of organic molecules is very advanced at this point even with the use of one-line notations like SMILES to simplify how the molecule is represented. The problem with such notations is that they are unable to preserve any geometric information.

In my work, I'm looking exactly at the importance of geometry on some chemical properties, So I have created (and I'm still feeding) a large pandas dataframe with detailed geometric description of the molecules but, so far, I have noticed that none of the representations I tried is able to do MOLECULE &lt;==&gt; REPRESENTATION (I never get my exact molecule back after vectorization).

Are you aware of any method that can preserve the molecular geometry after vectorization?

Thanks in advance for any comments or suggestions.",9,12
29,2019-9-3,2019,9,3,23,cz5ahy,Weight decay in sparse neural networks.,https://www.reddit.com/r/deeplearning/comments/cz5ahy/weight_decay_in_sparse_neural_networks/,ragingpot,1567519410,"I recently got around to thinking about implementing Sparse adam optimizer with weight decay. However I got the intuition that since weight decay is supposed to penalise large weights and force the weights to be smaller, would it be redundant to use it on a neural network with sparse weights since they're already very close to zero? Any insight or help pointing in the right direction would be appreciated. Thank you.",0,1
30,2019-9-3,2019,9,3,23,cz5odk,Why do we use Expectation of log loss function in case of GANs?,https://www.reddit.com/r/deeplearning/comments/cz5odk/why_do_we_use_expectation_of_log_loss_function_in/,Torshak,1567521268,"Why do we use Expectation of log loss function of Discriminator and Generator, when optimising them?",0,1
31,2019-9-4,2019,9,4,0,cz67m3,"Explaning Activation Functions: Visualized and Math Explained Clearly. Code in Notebook along with Pros and Cons for GELU, SELU, ELU etc. I wrote this extensive article (&gt;6k words) and I hope it helps you understand the activation functions better.",https://www.reddit.com/r/deeplearning/comments/cz67m3/explaning_activation_functions_visualized_and/,permalip,1567523729,,0,7
32,2019-9-4,2019,9,4,4,cz97oc,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cz97oc/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1567537346,[removed],0,1
33,2019-9-4,2019,9,4,5,cza1ar,"Chinese DeepFake App Goes Viral, Renewing Concerns About Potential Misuse of Face-Swapping Tech",https://www.reddit.com/r/deeplearning/comments/cza1ar/chinese_deepfake_app_goes_viral_renewing_concerns/,Yuqing7,1567541020,,4,21
34,2019-9-4,2019,9,4,5,czaqyj,Randomly Wired Neural Networks - A new way to look at Neural Architecture Search,https://www.reddit.com/r/deeplearning/comments/czaqyj/randomly_wired_neural_networks_a_new_way_to_look/,HenryAILabs,1567544224,[https://youtu.be/960WIdYaKMM](https://youtu.be/960WIdYaKMM),0,3
35,2019-9-4,2019,9,4,6,czbes1,Deep Learning -- Getting started / Questions about this Steve Jurvetson interview,https://www.reddit.com/r/deeplearning/comments/czbes1/deep_learning_getting_started_questions_about/,ja-mez,1567547244,"Tim Ferriss did \[this interview\](https://tim.blog/2018/06/26/the-tim-ferriss-show-transcripts-steve-jurvetson/) with \[Steve Jurvetson\](https://en.wikipedia.org/wiki/Steve\_Jurvetson) last year. With regard to learning / careers in Deep Learning, he said:

&gt; These are simple Google searches, or I dont know if theres a particular book Id point out. Just to learn about deep learning. Learning about neural networks. The reason I say that is Ive never seen a greater demand for a technology and a scarcity of supply. Like these salaries being afforded to engineers in this area are out of control. A half million dollars for beginners.  
&gt;  
&gt;\----------  
&gt;  
&gt;Another thing I wanted to say about if someone actually wants to get into it, its actually remarkably easy to learn. When I said its weird labor market, arbitrage is, I dont think it takes more than six to eight months to become a real domain expert in this.  
&gt;  
&gt;And you dont have to be spectacularly good at computer science before. The background is just so different from normal computer science that, arguably, a new entrant has a great opportunity to just learn how these things are trained. And forget about normal computer science.

Figured I'd come to the (Reddit) source for this. Given the vague context at this point in the interview, does any particular resource / starting place come to mind? General thoughts on what he was getting at? For example, his quote about beginner salaries of half million dollars sounds high, but he may have had something very specific in mind.

I'm making a gradual career change, and ideally I'd be able to at least start bringing in a little income sooner than later. I have a light IT background (I've built PCs, some office tech support, a little SQL database management), but that was 10 years ago.  I'm fascinated by this field, and I look forward to learning more. 

Your feedback is appreciated. Thanks!",0,1
36,2019-9-4,2019,9,4,6,czbkkf,Deep Learning -- Getting started / Questions about this Steve Jurvetson interview,https://www.reddit.com/r/deeplearning/comments/czbkkf/deep_learning_getting_started_questions_about/,ja-mez,1567547979,"Tim Ferriss did [this interview](https://tim.blog/2018/06/26/the-tim-ferriss-show-transcripts-steve-jurvetson/) with [Steve Jurvetson](https://en.wikipedia.org/wiki/Steve_Jurvetson) last year. With regard to learning / careers in Deep Learning, he said:

&gt;These are simple Google searches, or I dont know if theres a particular book Id point out. Just to learn about deep learning. Learning about neural networks. The reason I say that is Ive never seen a greater demand for a technology and a scarcity of supply. Like these salaries being afforded to engineers in this area are out of control. A half million dollars for beginners.  
\----------  
Another thing I wanted to say about if someone actually wants to get into it, its actually remarkably easy to learn. When I said its weird labor market, arbitrage is, I dont think it takes more than six to eight months to become a real domain expert in this.  
And you dont have to be spectacularly good at computer science before. The background is just so different from normal computer science that, arguably, a new entrant has a great opportunity to just learn how these things are trained. And forget about normal computer science.

Figured I'd come to the (Reddit) source for this. Given the vague context at this point in the interview, does any particular resource / starting place come to mind? General thoughts on what he was getting at? For example, his quotes about ""remarkably easy to learn"" and ""beginner salaries of half million dollars sounds"" high, but he may have had something very specific in mind.

I'm making a gradual career change, and ideally I'd be able to at least start bringing in a little income sooner than later. I have a light IT background (I've built PCs, some office tech support, a little SQL database management), but that was 10 years ago. I'm fascinated by this field, and I look forward to learning more.

Your feedback is appreciated. Thanks!",2,1
37,2019-9-4,2019,9,4,7,czc2i2,"Evolution of Machine Learning, from Server to the Edge",https://www.reddit.com/r/deeplearning/comments/czc2i2/evolution_of_machine_learning_from_server_to_the/,MarceloLopezUru,1567550323,[removed],0,1
38,2019-9-4,2019,9,4,11,czeqbk,Is deep learning have been devoleped to the production level ?,https://www.reddit.com/r/deeplearning/comments/czeqbk/is_deep_learning_have_been_devoleped_to_the/,homilly,1567563850,"As  deep learning have many  disccussion about how to achieve the result, but how it could be used for society and get a production level, is the trend will be developing the GPU instructure and something like kubernetes?",0,0
39,2019-9-4,2019,9,4,16,czhffa,Can anyone please explain me the concept of Linear Dependence and Span in Linear Algebra.I was studying the book deeplearning by Ian Goodfelow and I got a doubt in this section.I have provided the link. Pg no.53,https://www.reddit.com/r/deeplearning/comments/czhffa/can_anyone_please_explain_me_the_concept_of/,masterRJ2404,1567580892,,3,1
40,2019-9-4,2019,9,4,18,czidfj,"Fraudsters deepfake CEO's voice to trick manager into transferring $243,000",https://www.reddit.com/r/deeplearning/comments/czidfj/fraudsters_deepfake_ceos_voice_to_trick_manager/,LimarcAmbalina,1567588257,,10,113
41,2019-9-4,2019,9,4,18,czipr7,Best way to generate synthetic image data,https://www.reddit.com/r/deeplearning/comments/czipr7/best_way_to_generate_synthetic_image_data/,PyWarrior,1567590826,What is the best way to generate synthetic image data?,1,1
42,2019-9-4,2019,9,4,18,cziqb2,is it possible to apply gradient boosting on faster r-cnn?,https://www.reddit.com/r/deeplearning/comments/cziqb2/is_it_possible_to_apply_gradient_boosting_on/,thehoodred,1567590934,i was thinking of applying it on my project for school,0,1
43,2019-9-4,2019,9,4,20,czjp31,Deep Learning for Java how-to,https://www.reddit.com/r/deeplearning/comments/czjp31/deep_learning_for_java_howto/,neomatrix369,1567597341,,0,2
44,2019-9-4,2019,9,4,21,czk3nh,Domain-Agnostic Learning with Anatomy-Consistent Embedding for Cross-Modality Liver Segmentation,https://www.reddit.com/r/deeplearning/comments/czk3nh/domainagnostic_learning_with_anatomyconsistent/,junlin639,1567599643,,0,1
45,2019-9-4,2019,9,4,21,czkeqb,Modes of Probability Distribution,https://www.reddit.com/r/deeplearning/comments/czkeqb/modes_of_probability_distribution/,PyWarrior,1567601304,"What does it mean by this statement ""GAN models may ""miss modes"" of the true distribution""?

I am not able to get this.",0,1
46,2019-9-4,2019,9,4,23,czlg42,Complex output layer regularization implementation,https://www.reddit.com/r/deeplearning/comments/czlg42/complex_output_layer_regularization_implementation/,progmayo,1567606502,"Hi guys. Im building a NN model using keras, and I wish to impose a constraint on it that doesnt (directly) have to do with the weights. Would be very grateful for some help / points me towards some relevant keywords to look up. The constraint I wish to impose is a bit complex, but it can be simplified in the following manner:  
I wish to impose a constraint on the output of certain inputs of the net. For the sake of simplicity, lets say the constraint looks like NN(3)+NN(4) &lt; 10, where NN is the neural net, which can be seen as a function.  
How can I impose such a constraint?

Thank you very much in advance for any help on the subject!",0,1
47,2019-9-4,2019,9,4,23,czll4f,MSc programs in Deep Learning?,https://www.reddit.com/r/deeplearning/comments/czll4f/msc_programs_in_deep_learning/,deepblue-,1567607185,"Hi, I graduated awhile with a BSc in Mathematics. I was also a research assistant in mathematical modelling and data analytics while in school. Unfortunately, I have not found a job in the field, usually applying for data analyst positions. I started doing the deeplearning.ai specialization on coursera and really enjoyed it -- almost finished, just finishing up the last course in the specialization. I plan on completing Andrew Ng's machine learning specialization and the tensorflow in practice specialization over the next little while while I work and save up money. I have doubts this will land me a job, but I remain hopeful. Most jobs seem to require at least an MSc and a lot of experience, at least where I live.

I have always wanted to go back to school for an MSc and maybe a PhD. I would really like to go back and do my MSc in deep learning, but I am having trouble finding programs. I was wondering if anyone knew any good programs for this? Particularly in Canada but I'm open to international. Would these programs be considered under computer science? I would like to be in a more mathematical and in-depth program.",3,1
48,2019-9-5,2019,9,5,2,czoa7b,I am working upon an approach action recognition under which I am estimating actions from pose in one class and identity objects in other class but I am confused how to link these classes like if a person is picking something I need a generalized form he picked pen or a bottle or any other object,https://www.reddit.com/r/deeplearning/comments/czoa7b/i_am_working_upon_an_approach_action_recognition/,lucky31044,1567619520,,0,1
49,2019-9-5,2019,9,5,3,czooyy,YOLOv3 loss function implementation,https://www.reddit.com/r/deeplearning/comments/czooyy/yolov3_loss_function_implementation/,italo3d,1567621376,"Does anyone know of an easy-to-understand implementation of the loss function used by YOLOv3? I have already looked at some of the main YOLOv3 implementations at GitHub, but I always get confused in implementing the loss function as they are very poorly commented. If anyone has already implemented or knows a good reference so that I can better understand the function, I will be very grateful.",3,3
50,2019-9-5,2019,9,5,3,czp5gh,I want to use YOLO for detection of objects of multiple classes. How do I prepare my dataset for it and how do I approach the problem in general?,https://www.reddit.com/r/deeplearning/comments/czp5gh/i_want_to_use_yolo_for_detection_of_objects_of/,yesteaplease,1567623413,"I have 5 classes of objects and finally I want all different classes detected so that I can know the number of items of the class that Im interested in from a scene.

Any papers, tutorials etc that I can follow?

As for the dataset, at the moment I have single object labelled pictures. Will that do? 
Finally I want the detection to work on a scene rather than one object picture.

Im new to this. Please point me in the right direction.

Thank you.",6,1
51,2019-9-5,2019,9,5,3,czp5xu,New A.I. Deepfakes can change your speech,https://www.reddit.com/r/deeplearning/comments/czp5xu/new_ai_deepfakes_can_change_your_speech/,brokeNews,1567623477,,1,0
52,2019-9-5,2019,9,5,4,czpifc,"Merging datasets from ""different"" distributions for a given task",https://www.reddit.com/r/deeplearning/comments/czpifc/merging_datasets_from_different_distributions_for/,tripple13,1567625005,"Hi fellow DL'ers

**Does anyone here have experience merging labelled datasets with somewhat similar domains/distributions with success?**

&amp;#x200B;

Ie. A semantic segmentation task where you would merge datasets taken from different spatial resolutions

Semantic segmentation task of feline animals taken in the wild, combined with a dataset of domesticated feline animals 

An object detection task from a fixed camera point at a highway in NYC, merged with data from a fixed camera point at a highway in LA

&amp;#x200B;

Are there any papers on this topic, any experiences you would like to share?

I am currently performing a semantic segmentation task with aerial photography with slightly different spatial resolution, and slightly different annotation techniques. It seems to be more robust, but very volatile to train, I am experiencing more divergence than otherwise on each of the datasets on their own.

Let's share our experiences!",0,1
53,2019-9-5,2019,9,5,4,czpmh2,I don't understand the codes for Faster RCNN at all,https://www.reddit.com/r/deeplearning/comments/czpmh2/i_dont_understand_the_codes_for_faster_rcnn_at_all/,wintersin1,1567625551,"Hi y'all, so recently I decided to go deeper into the computer vision field. Not long ago I found a very interesting article about FRCNN in Medium and decided to try it out myself, turns out I don't understand these codes at all. I understand the theory behind it but I just don't understand it when it is turned into Python. I spent the whole week looking at these codes and still doesn't understand it at all and frankly I'm really frustrated. Can anyone gives some advice on how to understand and learn to code these from scratch? Or people doesn't code from scratch anymore?  Thanks",1,0
54,2019-9-5,2019,9,5,6,czqq9c,Deep Learning Build $7k budget,https://www.reddit.com/r/deeplearning/comments/czqq9c/deep_learning_build_7k_budget/,iordanissh,1567630870,"I am having really hard time finding the right parts to build a server for deep learning. I am trying to make it as future proof as possible. That being said huge preference on PCIe 4.0, 4x slots for GPU, looking at initially 2x 2080ti but later on expanding to another 2. 

Biggest challenge is motherboard. Any advice or tips?",5,3
55,2019-9-5,2019,9,5,6,czqsxj,Genetic CNN - The easiest way to get started with Neuroevolution,https://www.reddit.com/r/deeplearning/comments/czqsxj/genetic_cnn_the_easiest_way_to_get_started_with/,HenryAILabs,1567631217,[https://youtu.be/GZMcy\_vl5wA](https://youtu.be/GZMcy_vl5wA),0,4
56,2019-9-5,2019,9,5,9,cztqd4,"Stuck between two ideas for science fair, and I don't know which one I should choose",https://www.reddit.com/r/deeplearning/comments/cztqd4/stuck_between_two_ideas_for_science_fair_and_i/,shazam8253,1567645182,"**Hey guys,**

**So I am stuck between 2 ideas for a science fair, and I need a second opinion**

**Idea 1:**   I wanted to use a Reinforcement Learning Model in order to simulate traffic situations. The agent would learn how to control a network of cars stuck in deep traffic in order to increase efficiency, and reduce the amount of harmful gas released into the air. After making this model, I wanted to make an app, or an extension of google maps, that would be controlled by the agent in real traffic situations. The agent would advise the network of drivers to go at a certain speed and time to increase efficiency, and potentially reduce the amount of accidents made in traffic situations. 

&amp;#x200B;

**Idea 2:**  I wanted to use a CNN, or other types of networks to determine what type of skin disease, or abnormality a person could have. Using the trained model, I wanted to make an app to make this technology easily accessible to all people. Many people cannot discern between different skin conditions, making early response in the medical field hard. People do not know when to approach a doctor or when to buy an ointment without a doctors discretion. Early response is critical for skin cancer patients. 

&amp;#x200B;

**This is the current dilemma I am in. If anyone could offer advice on which idea I should go with, and additional advice on different methods I could approach these issues, that would be a huge help. I also want to know how I would go about the first idea, as it doesn't seem as feasible to make as the second idea. Any advice would be greatly appreciated.**",2,0
57,2019-9-5,2019,9,5,15,czx5dd,Transforming CRM Operations With Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/czx5dd/transforming_crm_operations_with_artificial/,Machine_Learning001,1567665491,,0,0
58,2019-9-5,2019,9,5,19,czyz6l,Understanding the Data Augmentation,https://www.reddit.com/r/deeplearning/comments/czyz6l/understanding_the_data_augmentation/,data_autopsy,1567679250,"There are multiple blogs explaining various augmentation techniques, many courses does the same. It's probably a basic question but something that's bugging me for a long time now. How do you decide what techniques to apply? Are they problem specific, data specific or is there something else? I mean I get it we have to provide our model with various scenarios, but where to use them, should we use them all ? It doesn't make much sense to me at the moment other than you have to do it. 

If anyone can explain it here or can point to any online resource, that'll be good.",14,8
59,2019-9-5,2019,9,5,20,czzoa0,Cell Wall Segmentation,https://www.reddit.com/r/deeplearning/comments/czzoa0/cell_wall_segmentation/,moizsawan,1567683763,"Hi all. I have cell images for a medical classification problem. I want to compute geometric features based on the shape of the cell boundary. I have researched online but I could not find a method which works on arbitrary shaped cell walls. There are some methods which work on perfect circular or ellipse shaped cell wall, and they are not good for my problem. Any ideas or implementations?",1,1
60,2019-9-5,2019,9,5,20,czzp54,Awesome Artificial Intelligence Research and Projects on Computer Vision News (with codes!) September 2019,https://www.reddit.com/r/deeplearning/comments/czzp54/awesome_artificial_intelligence_research_and/,Gletta,1567683920,"The September issue of Computer Vision News: 34 pages about AI and Deep Learning through both research and practical applications.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019September/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-september-pdf/)

Technical articles on pages 4-7 and 16-21. Subscribe for free on page 34.

https://i.redd.it/bllz4hfmjrk31.jpg",0,1
61,2019-9-5,2019,9,5,21,d003b3,AI Learns to Park - Deep Reinforcement Learning with Unity ML-Agents,https://www.reddit.com/r/deeplearning/comments/d003b3/ai_learns_to_park_deep_reinforcement_learning/,SamuelArzt,1567686168,,12,64
62,2019-9-6,2019,9,6,0,d02ae1,Junior AI engineer skills and knowledge,https://www.reddit.com/r/deeplearning/comments/d02ae1/junior_ai_engineer_skills_and_knowledge/,karix_02,1567697269,"Hi guys!

I want to apply for job as junior AI engineer with Python. And I'm here to ask some questions. First is what knowledge should junior has. I'mean something like ""Is model with acc 99% safe to use?"", ""What are disadvantages of stochastic gradient descent?"". Second is what skills i need like applying cross-entropy into code or macing good infrastructure of code. I know making own projects is very important but without good infrastructure code is messy and doesnt look good.",0,5
63,2019-9-6,2019,9,6,3,d04ym3,Comparing trained-from-scratch people classifiers and ImageNet models -- inference on Raspberry Pi,https://www.reddit.com/r/deeplearning/comments/d04ym3/comparing_trainedfromscratch_people_classifiers/,aweeeezy,1567709217,"What I'm curious to know is:

* if the simplicity of a model trained from scratch only to classify person/not person (relative to a full ImageNet pre-trained model) would give a high enough inference time performance yield to warrant the additional training cost
* what are peoples' experiences adapting various pre-trained networks to become single class (specifically people) classifiers
* what are people's experiences running conv net inferences on a Raspberry Pi 3 and/or 4 

In the past I have trained a YOLO model using a VGG-16 conv net pre-trained on ImageNet data to predict bounding boxes and classes for 10 different types of classes... 

This model was, at inference time, able to run at about 3-5 FPS on a Nvidia Jetson TX 2 processing 1080p video.

I'm about to undergo an endeavor which, to be brief, is simply a person detector...if I can achieve 3-5 FPS on a Raspberry Pi 3 or 4, that would be excellent.

My plan is to either train a conv net from scratch or adapt an ImageNet pre-trained model for my purpose and then use this conv net in the YOLO architecture to predict bounding boxes for people.

I understand that there will be a difference in development/training time and cost but my expectation is that it won't be _too_ much of a difference considering the resources I have.

My expectation is that:

* a conv net built just to detect people could be much leaner than a pre-trained ImageNet classifier
* perhaps retraining a large pre-trained net would be approximately the same amount of training cost as compared to a from-scratch conv net which has a likely much simpler architecture
* inference on a leaner model will be considerably faster
* classification accuracy will be higher on properly trained from-scratch model built specifically for people classifying versus a bulky pre-trained model built to classify 1000 classes

My fear is that:

* I'll get sub-satisfactory performance from initial attempts
* by the time I get good performance, I'll have iterated multiple times and spent ultimately a lot more time
* and, by the end, I'll have an architecture not too dissimilar from a fully-fledged ImageNet trained model (i.e. inference gains will not be apparent)

Does anyone here have experience comparing performance of trained-from-scratch single class conv net image classifier and repurposed pre-trained models to do the same task?

Does anyone have experience comparing different pre-trained models when repurposed to classify just people?

Does anyone have experience running conv net model inference on a Raspberry Pi?",1,2
64,2019-9-6,2019,9,6,5,d0637e,What can I do to improve my model ?,https://www.reddit.com/r/deeplearning/comments/d0637e/what_can_i_do_to_improve_my_model/,Herosixty7,1567714238,"If I have a data set like this (about 6k rows)

     

[Input Vs Output ](https://i.redd.it/eqty8rrgytk31.png)

If I need to build model to predict the output given any sequence input 

I came up with SVM model that able to predict all my training set within .98% of actual value. Although this is not what I want since I want to predict it more accurately, but I can accept this error. But If I use another test set my model can't predict more than 10% of this data within .98% range. So, What can I do to improve my model to be able to fit previously unseen data given this level of accuracy?

Details of my model as follow:

1- I started first by featuring this input string into 17 different features.

2- Then I have converted each character into corresponding ASCII value ( Just a fancy way to code characters )

3- Divided data set into training and test set with 70-30 ratio

4- I have applied feature normalization for my training set

5- train support vector machine model with Gaussian kernel 

6- use the model to predict output for test set.

7- Evaluate the performance of train and test sets as outlined above. 

&amp;#x200B;

I attached a copy of original dataset",0,1
65,2019-9-6,2019,9,6,5,d066fe,Need help in master's project on deep learning based methods for visual navigation on aerial robots?,https://www.reddit.com/r/deeplearning/comments/d066fe/need_help_in_masters_project_on_deep_learning/,Dr_Samuel_Hayden,1567714646,"Hi guys, I want to implement some ML and DL based methods for autonomous navigation of an aerial bot (a pixhawk/ openpilot REVO based quadcopter with Jetson Nano/ Asus TinkerBoard as a companion computer). Can I get some recommendations for the topic? I have implemented some vision-based algorithm for navigation purposes (followed Jakob Engel, Jurgen Sturm, and Prof. Daniel Cremers ).",0,1
66,2019-9-6,2019,9,6,6,d077mt,Write With Transformer: A web app to compare generative NLP transformer-based models.,https://www.reddit.com/r/deeplearning/comments/d077mt/write_with_transformer_a_web_app_to_compare/,jikkii,1567719270,"Sharing with you a project we've been working on at Hugging Face: [Write With Transformer](https://transformer.huggingface.co/). It is a web app that hosts most state-of-the-art transformer-based NLP generative models like **GPT-2**, **GPT** or **XLNet.**

You can write a context and trigger completions from the generative model you choose, in a Google Doc-like interface. It also includes one of our fine-tuned models, using GPT-2 as a pretrained model and fine-tuning it on Arxiv papers to get NLP/Deep Learning completions.

It's built on top of our library [pytorch-transformers](https://github.com/huggingface/pytorch-transformers). Let us know what you think!",3,4
67,2019-9-6,2019,9,6,14,d0cfwl,Zooming into the world of computer vision applications,https://www.reddit.com/r/deeplearning/comments/d0cfwl/zooming_into_the_world_of_computer_vision/,Machine_Learning001,1567747931,,0,1
68,2019-9-6,2019,9,6,17,d0dva2,Nvidia Card for deep learning - why are Tesla better than Quadro,https://www.reddit.com/r/deeplearning/comments/d0dva2/nvidia_card_for_deep_learning_why_are_tesla/,alex_bababu,1567758511,"Hi, 

some time ago, i have read, Tesla cards are better for deep learning than Quadro cards.

I was wondering why. I would like to lesen how I can determine which Hardware is good for deep learning. How I have to read the specifications. What so i have to Look for? 
Dies anybody have sources i can read to understand?

I would like to be able to compare Hardware myself.

Thank you in advance.",1,2
69,2019-9-6,2019,9,6,20,d0feih,How much to charge for computing (training) of model?,https://www.reddit.com/r/deeplearning/comments/d0feih/how_much_to_charge_for_computing_training_of_model/,tripple13,1567769431,"For all you consultants out there.

**How do you charge your clients for the training/computation time of the models you produce?**

Assumed you own the hardware and do not use AWS/Azure etc.

Do you amortise the price of your equipment over say 1 year and charge an hourly rate?

Do you add a fixed amount every month of computing time?

I'm very curious, information online on this is sparse.",4,2
70,2019-9-6,2019,9,6,22,d0gnp0,We present a (Poly-GAN) novel way for fitting clothes virtually on a person.,https://www.reddit.com/r/deeplearning/comments/d0gnp0/we_present_a_polygan_novel_way_for_fitting/,nile6499,1567776442,"&amp;#x200B;

[https://arxiv.org/abs/1909.02165v1](https://arxiv.org/abs/1909.02165v1)

&gt; We present Poly-GAN, a novel conditional GAN architecture that is motivated by Fashion Synthesis, an application where garments are automatically placed on images of human models at an arbitrary pose. Poly-GAN allows conditioning on multiple inputs and is suitable for many tasks, including image alignment, image stitching, and inpainting. Existing methods have a similar pipeline where three different networks are used to first align garments with the human pose, then perform stitching of the aligned garment and finally refine the results. Poly-GAN is the first instance where a common architecture is used to perform all three tasks. Our novel architecture enforces the conditions at all layers of the encoder and utilizes skip connections from the coarse layers of the encoder to the respective layers of the decoder. Poly-GAN is able to perform a spatial transformation of the garment based on the RGB skeleton of the model at an arbitrary pose. Additionally, Poly-GAN can perform image stitching, regardless of the garment orientation, and inpainting on the garment mask when it contains irregular holes. Our system achieves state-of-the-art quantitative results on Structural Similarity Index metric and Inception Score metric using the DeepFashion dataset.  

We will be happy to share code as well .

Thanks",5,34
71,2019-9-6,2019,9,6,22,d0gp9f,Rent out 2X Tesla V100 machines for 0.3$ / hour,https://www.reddit.com/r/deeplearning/comments/d0gp9f/rent_out_2x_tesla_v100_machines_for_03_hour/,duicr,1567776683,"Head to  [https://vast.ai/console/create/](https://vast.ai/console/create/) 

And use the following search options to get the most deep learning performance / $ / hour

&amp;#x200B;

https://i.redd.it/87sj70d66zk31.png

Reliability is based on online time, starting from 60% and growing about 30% after 24 hours.

Machines are being ""verified"" once a week, but with unverified instances ticked on, you don't have to wait a week to see new ones.

&amp;#x200B;

All your work will run in a secure docker, you can use pre-made ones and even custom ones using  [https://hub.docker.com/](https://hub.docker.com/) 

&amp;#x200B;

**FAQ:**

 [https://vast.ai/faq/](https://vast.ai/faq/)",0,4
72,2019-9-7,2019,9,7,2,d0jmxd,I want to learn Python by working on a project. Where can I find one?,https://www.reddit.com/r/deeplearning/comments/d0jmxd/i_want_to_learn_python_by_working_on_a_project/,Doctor_who1,1567790450," 

# I want to learn Python by working on a project. Where can I find one?",2,0
73,2019-9-7,2019,9,7,4,d0l8tm,how to fuse object detection and edge detection in real time?,https://www.reddit.com/r/deeplearning/comments/d0l8tm/how_to_fuse_object_detection_and_edge_detection/,toiletscrubber,1567797700,"I am new to doing object detection and I want to be able to detect both objects and edges in real time. 

I have been looking at tensorflow model api but I am still figuring out model structure.

For example, in this short driving video at 1:14,  [https://www.youtube.com/watch?v=G2VaJvNNp4k](https://www.youtube.com/watch?v=G2VaJvNNp4k) 

How did they fuse lane detection with object detection? Is that 2 models in parallel?",0,1
74,2019-9-7,2019,9,7,5,d0m2fv,ACL 2019 Conference: ALL papers Word Cloud.,https://www.reddit.com/r/deeplearning/comments/d0m2fv/acl_2019_conference_all_papers_word_cloud/,deep_ak,1567801511,"[https://deeps.site/blog/2019/09/06/conference-word-clouds/](https://deeps.site/blog/2019/09/06/conference-word-clouds/)  


Here is a Rich word cloud containing the most recurring words occurring in the ACL 2019 anthology,  
this might help aspiring students, researchers to have a quick visual glance as to what is happening in the NLP Community.",0,1
75,2019-9-7,2019,9,7,14,d0rvz3,AI Institute Geometry of Deep Learning 2019 [Day 1 | Session 1],https://www.reddit.com/r/deeplearning/comments/d0rvz3/ai_institute_geometry_of_deep_learning_2019_day_1/,ai-lover,1567832534,,2,58
76,2019-9-7,2019,9,7,19,d0uhvq,Introduction to Deep Learning,https://www.reddit.com/r/deeplearning/comments/d0uhvq/introduction_to_deep_learning/,madhu_SEO,1567852870,,0,0
77,2019-9-7,2019,9,7,20,d0uzmq,Variable size of input and output in LSTM,https://www.reddit.com/r/deeplearning/comments/d0uzmq/variable_size_of_input_and_output_in_lstm/,fibonacci_bokertov,1567856627,"Hi! I'm a freshman in LSTM. I've a dataset with variable size of input and output. And I'd like to do many to many architecture (firstly net takes all input sequence then gets to predict output). I dunno how to deal with it. 

My idea is to measure the max size as max_size = max_size(input)+max_size(output) and afterwards to pad my sequences of input and output with 'zeros'.

 For example:
Inputs: [1,2,3] and [1,5,6,7,8]
Otputs: [1,3] and [2,5,7]
After padding:
Inputs: [1,2,3,0,0,0,0,0] and [1,5,6,7,8,0,0,0]
Outputs: [0,0,0,1,3,0,0,0] and [0,0,0,0,0,2,5,7]



Desired architecture:
https://www.google.com/search?q=many+to+many+lstm&amp;tbm=isch&amp;ved=2ahUKEwjClvHQ0L7kAhUBCJoKHR7MD9EQ2-cCegQIABAC&amp;oq=many+to+many+lst&amp;gs_l=mobile-gws-wiz-img.1.0.0i30j0i24l3.4321.6398..7020...0.0..0.107.400.1j3......0....1.........0j0i19.fnMm_M1idyo&amp;ei=epdzXcLxC4GQ6ASemL-IDQ&amp;bih=560&amp;biw=360&amp;client=ms-android-xiaomi&amp;prmd=ivmn#imgrc=LciRGZbURrltvM",0,2
78,2019-9-7,2019,9,7,22,d0vtke,"""And the Bit Goes Down"", Deep Learning Research, Research at Facebook | Interview with Pierre Stock",https://www.reddit.com/r/deeplearning/comments/d0vtke/and_the_bit_goes_down_deep_learning_research/,init__27,1567862032,"Interview with Pierre Stock about DL Research, Research at FAIR, and their recent work: [""And the Bit Goes Down: Revisiting the Quantization of Neural Networks""](https://arxiv.org/pdf/1907.05686.pdf):

&amp;#x200B;

Audio: [https://anchor.fm/chaitimedatascience/episodes/And-the-Bit-Goes-Down--Deep-Learning-Research--Research-at-FAIR--Interview-with-Pierre-Stock-e52rpk/a-alh51k](https://anchor.fm/chaitimedatascience/episodes/And-the-Bit-Goes-Down--Deep-Learning-Research--Research-at-FAIR--Interview-with-Pierre-Stock-e52rpk/a-alh51k)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=okFcSGShE10&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=16](https://www.youtube.com/watch?v=okFcSGShE10&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=16)",0,2
79,2019-9-7,2019,9,7,23,d0wbmx,"An Efficient and Layout-Independent Automatic License Plate Recognition System Based on the YOLO detector (comprehensible paper with public datasets, architectures and weights)",https://www.reddit.com/r/deeplearning/comments/d0wbmx/an_efficient_and_layoutindependent_automatic/,ghostzin,1567864895,,0,5
80,2019-9-8,2019,9,8,2,d0ytg8,How AI recommendation engine works with deeplearning and algorithm data process?,https://www.reddit.com/r/deeplearning/comments/d0ytg8/how_ai_recommendation_engine_works_with/,Tech_videostreaming,1567876917,,0,0
81,2019-9-8,2019,9,8,3,d0zymf,PyTorch Primer For Neural Networks &amp; Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/d0zymf/pytorch_primer_for_neural_networks_deep_learning/,udemudailydeal,1567882313,,0,1
82,2019-9-8,2019,9,8,4,d10e6o,Uploading your selfies to FaceApp and other places that store your information as data is dangerous!,https://www.reddit.com/r/deeplearning/comments/d10e6o/uploading_your_selfies_to_faceapp_and_other/,onmywaytostealyagirl,1567884291, [https://www.snopes.com/news/2019/09/06/zaos-deepfake-face-swapping-app-shows-uploading-your-photos-is-riskier-than-ever/](https://www.snopes.com/news/2019/09/06/zaos-deepfake-face-swapping-app-shows-uploading-your-photos-is-riskier-than-ever/),0,5
83,2019-9-8,2019,9,8,5,d10ypq,Top 22 Best Artificial Intelligence and Machine Learning Books of All Time,https://www.reddit.com/r/deeplearning/comments/d10ypq/top_22_best_artificial_intelligence_and_machine/,newworld-ai,1567887025,,0,4
84,2019-9-8,2019,9,8,7,d12zhs,[AI application] AirGesture - Let's play game without keyboard,https://www.reddit.com/r/deeplearning/comments/d12zhs/ai_application_airgesture_lets_play_game_without/,1991viet,1567896887,,7,93
85,2019-9-8,2019,9,8,12,d166e7,Stochastic vs Batch vs Mini-Batch Gradient Descent in Python,https://www.reddit.com/r/deeplearning/comments/d166e7/stochastic_vs_batch_vs_minibatch_gradient_descent/,bhavesh91,1567914852,,0,1
86,2019-9-8,2019,9,8,17,d18hug,Deep Learning and Self-Driving Cars from MIT: Lectures 01-05,https://www.reddit.com/r/deeplearning/comments/d18hug/deep_learning_and_selfdriving_cars_from_mit/,newworld-ai,1567932053,,1,7
87,2019-9-8,2019,9,8,21,d1a2ky,Waveglow Inference in CUDA C++ (Mel to Speech Model),https://www.reddit.com/r/deeplearning/comments/d1a2ky/waveglow_inference_in_cuda_c_mel_to_speech_model/,murkyCorot,1567944192,"I just wrote the Waveglow (Mel to Speech Model)  inference in CUDA C++, it is up to 3x faster than PyTorch implementation. Please share the comments and any feedback.",4,17
88,2019-9-9,2019,9,9,0,d1ca3b,A beginner-friendly introduction to Activation Functions,https://www.reddit.com/r/deeplearning/comments/d1ca3b/a_beginnerfriendly_introduction_to_activation/,nerdy_wits,1567956261,,0,20
89,2019-9-9,2019,9,9,1,d1d8dp,Thoughts/Suggestions on my Deep Learning workstation config,https://www.reddit.com/r/deeplearning/comments/d1d8dp/thoughtssuggestions_on_my_deep_learning/,AbhedyaK,1567960531,"Hi guys,
Im a developer and an individual deep learning researcher and I wanted to build a personal workstation.  I work with a lot of image data and also looking forward to compete in Kaggle.  So Ive short listed the following components:

Processor -&gt; i7 9700K
GPU -&gt; RTX 2080ti 
RAM -&gt; 32GB DDR4
Motherboard -&gt; MSI Z390 
Storage -&gt; 256GB M.2 SSD and 2TB 7200HDD

Thoughts or suggestions on this configuration would be appreciated! Thanks!",4,1
90,2019-9-9,2019,9,9,3,d1ej4r,Dataset Error in Kaggle,https://www.reddit.com/r/deeplearning/comments/d1ej4r/dataset_error_in_kaggle/,zom8ie99,1567966283,"Dataset is not showing up when uploading into the kaggle kernel. What could be done ?

[The above is my dataset.](https://i.redd.it/8rei3z6vuel31.jpg)

[But when I upload it in Kaggle kernel, it doesnot load the dataset - just showing a question mark.](https://i.redd.it/4oyv216xuel31.jpg)",3,2
91,2019-9-9,2019,9,9,5,d1ggq5,"Deep Learning Research - Weekly Update Video (September 8th, 2019)",https://www.reddit.com/r/deeplearning/comments/d1ggq5/deep_learning_research_weekly_update_video/,HenryAILabs,1567974593,[https://youtu.be/BsOFT9-cc5I](https://youtu.be/BsOFT9-cc5I),0,4
92,2019-9-9,2019,9,9,5,d1gncf,5 Major open problems in Natural Language Processing.,https://www.reddit.com/r/deeplearning/comments/d1gncf/5_major_open_problems_in_natural_language/,deep_ak,1567975393,"[https://deeps.site/blog/2019/09/09/nlp-problems/](https://deeps.site/blog/2019/09/09/nlp-problems/)

Have *compiled* 5 major problems/***opportunities*** **for students, researchers and NLP enthusiasts** to work on with *open pointers to resources*.",4,1
93,2019-9-9,2019,9,9,12,d1lio2,Simple Multi Object Tracking,https://www.reddit.com/r/deeplearning/comments/d1lio2/simple_multi_object_tracking/,aditpandas,1568000171,"&amp;#x200B;

*Processing gif tbb1gfqtnhl31...*",3,8
94,2019-9-9,2019,9,9,14,d1mumz,Global Deep Learning Market Size and Forecast to 2026 | Latest Trends in Technology Industry,https://www.reddit.com/r/deeplearning/comments/d1mumz/global_deep_learning_market_size_and_forecast_to/,manjusha7,1568008569,"The [Global Deep Learning Market](https://www.jsbmarketresearch.com/technology/global-deep-learning-market-size-and-forecast-to-2026) study report will provide a valuable insight with an emphasis on global market including some of the major players and its key development strategies, market share and market ranking analysis. 

![img](smou0aiucil31 ""Deep Learning Market Size "")",0,1
95,2019-9-9,2019,9,9,15,d1nd4h,Facebook Making Its Own Deepfakes To Tackle Widespread of Misinformation,https://www.reddit.com/r/deeplearning/comments/d1nd4h/facebook_making_its_own_deepfakes_to_tackle/,analyticsinsight,1568012092,,3,12
96,2019-9-9,2019,9,9,16,d1njvr,How to integrate of TensorFlow Model in Angular Application?,https://www.reddit.com/r/deeplearning/comments/d1njvr/how_to_integrate_of_tensorflow_model_in_angular/,RubiksCodeNMZ,1568013399,,0,2
97,2019-9-9,2019,9,9,20,d1plk0,Does caffe resizes your image while training,https://www.reddit.com/r/deeplearning/comments/d1plk0/does_caffe_resizes_your_image_while_training/,sirithelion,1568028360,"I saw the source and ***train.prototxt***

transform\_param {     

resize\_param {           

resize\_mode: WARP           

height: 300           

width: 300     

}

}

&amp;#x200B;

My images are 3840 x 2160 pixels with labels &amp; while training height + width == 300. Does this caffe convert my 3840 x 2160 resolution to 300 x 300 &amp; after that it starts to trains? How this happens?",0,1
98,2019-9-9,2019,9,9,21,d1qiql,A small confusion about FAST RCNN.,https://www.reddit.com/r/deeplearning/comments/d1qiql/a_small_confusion_about_fast_rcnn/,yesteaplease,1568033679,"While reading about FAST Im coming to a conclusion that it combines classification and segmentation in one framework? Am I correct in concluding this about FAST RCNN?

Thanks.",6,1
99,2019-9-9,2019,9,9,23,d1rs2y,Document Embedding Techniques: A Literature Review ,https://www.reddit.com/r/deeplearning/comments/d1rs2y/document_embedding_techniques_a_literature_review/,shaypal5,1568040017,"Hey there.

I've written what I believe to be [a thorough but concise literature review on the topic of document embedding techniques](https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d). I hope those of you interested in an introduction to the topic will find it informative. :)

Since I'm in the process of initiating a related project with one of my clients, I'd love to hear about your experience with document embeddings - especially as part of a document clustering pipeline - and any other insights you might have on the subject.

Cheers,  
Shay  
[https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d](https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d)",0,22
100,2019-9-10,2019,9,10,0,d1sqfc,[Research] The LOCATA Challenge,https://www.reddit.com/r/deeplearning/comments/d1sqfc/research_the_locata_challenge/,cdossman,1568044376," [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-the-locata-challenge-16a8270d5fcd](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-the-locata-challenge-16a8270d5fcd) 

The paper:  [https://arxiv.org/pdf/1909.01008.pdf](https://arxiv.org/pdf/1909.01008.pdf)",0,1
101,2019-9-10,2019,9,10,0,d1ssc6,Neural Network Model Builder &amp; Visualiser | Netbrix.ml,https://www.reddit.com/r/deeplearning/comments/d1ssc6/neural_network_model_builder_visualiser_netbrixml/,DataSnaek,1568044619,"# [https://netbrix.ml/](https://netbrix.ml/)

# Introduction

I recently discovered the Mithril.js JavaScript library and wanted a project to build up my skills with it! I ended up going with a simple web app for visualising and editing network models which I've named [netbrix.ml](https://netbrix.ml). I've wanted to build something like this for a while since it seemed like a really good project to improve my web development skills and my understanding of the process of building deep learning models. After reading [this post](https://www.reddit.com/r/deeplearning/comments/coifgi/the_modularity_of_deep_learning/) on /r/deeplearning where the writer gives insight into the modular nature of deep learning and gives the analogy of a deep learning 'lego set' it gave me the motivation to start work on this with that sort of vision in mind and I've now got a decent working web app! 

I'm sure there are existing tools similar to this in existence, so I wanted to keep it as simple as possible and not try to over-engineer it. It's meant to be easy and simple to use!

# Importing Models

It has some cool features at the moment, like the ability to parse `Sequential()` model definitions in Keras e.g.

    test_model = Sequential()
    
    test_model.add(Conv2D(64,(5,5), activation='relu'))
    test_model.add(MaxPooling2D((2,2)))
    test_model.add(Dropout(0.25))

(Alternatively you can paste in Keras JSON definitions from for example `test_model.to_json()`)

Once that simple model definition is imported it will be parsed by the app to create the following neat visualisation:

&amp;#x200B;

https://i.redd.it/imns28k5cll31.png

# Editing Models

From here, you can make all the typical changes you would want to make to a model, including changing/adding layer parameters, adding new layers, changing the order of layers and removing layers, all without having to rely on Google to find the names of layers or their attributes. It can then be easily exported (or copied to the clipboard) with one click as either Python Keras code or a JSON spec which can be imported into Keras. 

# Building Models

It also has some nice features for building models from scratch, like the ability to add blocks of layers that come up in models frequently. Often it's easy to forget the exact optimal order of layers for say a Convolutional block e.g. should pooling come before dropout or vice versa, and what about BatchNorm? Having preconfigured blocks of layers to choose from when building a model helps with this.

On top of that, just having an easily indexable list of layers is useful in itself. 

# Browsing Models

There is also a host of existing model architectures for a variety of machine learning tasks/datasets to explore and this is one of the most helpful features for me personally. Having an easy and centralised way to access a bunch of existing standard model architectures to take inspiration from is really useful! Rather than creating a model from scratch, you can find an existing model on the site, change say the input shape and a few of the hyperparameters and export it as working Keras code in just a few clicks. It's also great for learning about the different architectures commonly used in building models.

# Planned Features

* Integration with TensorFlow.js to have some kind of in-browser training/prototyping
* The ability to share your own model architectures
* Support for variables. Currently you can specify meta tags for a model like 'name' and 'source'. It would be cool to be able to specify variables in this same key/value fashion to allow even easier tuning.
* Better mobile support. The site is relatively responsive at the moment, but not perfect. Hopefully you're not building Keras models on your phone to begin with, but it will work if that's something you wish to do 

So, I'd love to get some feedback on this project! Is it useful? Do you like the design? I'm open to criticism, this is primarily for me to learn 

Thanks for reading!",0,0
102,2019-9-10,2019,9,10,1,d1sva9,Training on good audio to replace dialogue a low quality recording using a transcript?,https://www.reddit.com/r/deeplearning/comments/d1sva9/training_on_good_audio_to_replace_dialogue_a_low/,pr0fess0r,1568044983,"Looking at the growing quality of deep fakes and networks that are developed based on images and video, I wonder how far we've gotten with audio. I have a low-quality, noisy audio recording of a famous person and I thought about tinkering with the idea of transcribing it as text, training a network based on high-quality audio from interviews and audio snippets of that person and then using the resulting model plus the transcription to recreate the noisy recording in better quality in the original author's voice. Does anyone know if there are projects or libraries around that would help with this sort of project?",0,2
103,2019-9-10,2019,9,10,5,d1w6gr,Transformer in 5 minutes,https://www.reddit.com/r/deeplearning/comments/d1w6gr/transformer_in_5_minutes/,very-blue-season,1568059276,https://blue-season.github.io/transformer-in-5-minutes,0,12
104,2019-9-10,2019,9,10,8,d1yzgd,Helmet Detection.,https://www.reddit.com/r/deeplearning/comments/d1yzgd/helmet_detection/,lakshaytalkstocomput,1568071301,I am starting helmet detection project. I would like to know whether the bikers are wearing helmet or not. ( including localization). Any tips and/ or readings??,0,0
105,2019-9-10,2019,9,10,13,d22j51,Which are hyperparameters affected by mini batch size,https://www.reddit.com/r/deeplearning/comments/d22j51/which_are_hyperparameters_affected_by_mini_batch/,mshubham84,1568088998,,15,3
106,2019-9-10,2019,9,10,18,d251im,Evolving neural networks to follow trajectories of arbitrary complexity,https://www.reddit.com/r/deeplearning/comments/d251im/evolving_neural_networks_to_follow_trajectories/,zy469xw23,1568106935,,0,14
107,2019-9-10,2019,9,10,20,d266on,Best books on applied reinforcement learning,https://www.reddit.com/r/deeplearning/comments/d266on/best_books_on_applied_reinforcement_learning/,JurrasicBarf,1568114718,"Im confident in my deep learning now to pick up RL, how should I start?

All theory and later apply it to custom projects?

What are best resources/books on it?

Also is there work in combining generative modeling with RL?",1,2
108,2019-9-10,2019,9,10,20,d26e1g,I wrote a PyTorch-based interface for normalizing flows,https://www.reddit.com/r/deeplearning/comments/d26e1g/i_wrote_a_pytorchbased_interface_for_normalizing/,stevethesteve2,1568115950,"[https://github.com/sshish/NF](https://github.com/sshish/NF)

Models can be easily created by e.g. stacking multiple layers on top of each other, and trained with crossentropy loss and entropy loss.

See examples of how to build a RealNVP or a B-NAF.

The code has pre-defined layers for rotation, permutation, coupling layer, ..., and is easily extensible.

Suggestions and collaborators are welcome.",4,32
109,2019-9-10,2019,9,10,20,d26ip4,Using neural network to create images from rotation and distance.,https://www.reddit.com/r/deeplearning/comments/d26ip4/using_neural_network_to_create_images_from/,Envenger,1568116734,"I am trying to train a neural network to create an image based on the camera distance of the object from the image and   


The training data is the rendered 2d images of a 3d object in different angles and distances.  
Something like this  


https://i.redd.it/wwwv4aujarl31.png

https://i.redd.it/rtspy1tkarl31.png

  


I am starting with simple objects and render the image in size 320x144p first then will try to see if it works with more complex 3d objects.

I was thinking which kind of neural network I should use for a task like this and if there has already been any research done on this field?",0,1
110,2019-9-10,2019,9,10,21,d272kz,"Custom Deep Learning Based OCR models , build number plate detector",https://www.reddit.com/r/deeplearning/comments/d272kz/custom_deep_learning_based_ocr_models_build/,manneshiva,1568119748,"Interesting DIY Article on building number plate detector using attention OCR.  [https://nanonets.com/blog/attention-ocr-for-text-recogntion/](https://nanonets.com/blog/attention-ocr-for-text-recogntion/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=atocr&amp;utm_content=dl) 

OCR is a challenging problem, this blog can be a good source for building custom OCR models.

&amp;#x200B;

![gif](ml1jtdrijrl31)",0,2
111,2019-9-10,2019,9,10,22,d27964,A complete guide to Stochastic Gradient Descent,https://www.reddit.com/r/deeplearning/comments/d27964/a_complete_guide_to_stochastic_gradient_descent/,nerdy_wits,1568120677,,0,0
112,2019-9-10,2019,9,10,22,d27t1r,Important Things to Know About Tensorflow 2.0,https://www.reddit.com/r/deeplearning/comments/d27t1r/important_things_to_know_about_tensorflow_20/,atomlib_com,1568123473,,1,2
113,2019-9-10,2019,9,10,23,d281sn,Chat groups for deep learning enthusiasts or beginners?,https://www.reddit.com/r/deeplearning/comments/d281sn/chat_groups_for_deep_learning_enthusiasts_or/,iwasalilgirl,1568124611,Are there any chat groups like in Telegram or Discord with deep learning enthusiasts sharing their knowledge or experience that will be helpful for everyone?,1,5
114,2019-9-11,2019,9,11,3,d2bk3d,Probability and Statistics for Business and Data Science,https://www.reddit.com/r/deeplearning/comments/d2bk3d/probability_and_statistics_for_business_and_data/,HannahHumphreys,1568138584,[removed],0,1
115,2019-9-11,2019,9,11,4,d2cvkm,Sample weighting didn't help in imbalanced data training,https://www.reddit.com/r/deeplearning/comments/d2cvkm/sample_weighting_didnt_help_in_imbalanced_data/,shahriar49,1568143578,"I am training a two-layer LSTM network with 16 through 32 cells in each layer and had a fairly imbalanced dataset for training. Based on my seven class frequencies, the sample weights calculated through the simple formula of total\_samples/class\_frequency is \[3.7, 5.6, 26.4, 3.2, 191.6, 8.4, 13.2\], and I add this weight for each sample to the tuple of (data, label) output of my dataset generator to run my Keras [model.fit](https://model.fit)() function. But what I see in the output statistics is that the weighted stats are in every aspect worse than unweighted ones (setting all weights equally to 1), even for rare classes (highest weights). Here is the stat:

&amp;#x200B;

For weighted run:

&amp;#x200B;

class     prec.     recall    f1       support

0.0       1.00      0.97      0.98     79785

1.0       0.89      0.88      0.88     52614

2.0       0.61      0.76      0.68     11090

3.0       0.96      0.93      0.95     91160

4.0       0.59      0.92      0.72      1530

5.0       0.89      0.90      0.89     34746

6.0       0.81      0.87      0.84     22289

&amp;#x200B;

accuracy                                 0.92    293214

 macro avg      0.82      0.89      0.85    293214

&amp;#x200B;

For unweighted run:

&amp;#x200B;

class     prec.     recall    f1       support

0.0       0.99      0.99      0.99     79785

1.0       0.90      0.91      0.91     52614

2.0       0.82      0.70      0.75     11090

3.0       0.95      0.96      0.96     91160

4.0       0.83      0.85      0.84      1530

5.0       0.91      0.93      0.92     34746

6.0       0.91      0.87      0.89     22289

&amp;#x200B;

accuracy                                  0.94    293214

macro avg      0.90      0.89      0.89    293214

&amp;#x200B;

what is wrong here?",11,3
116,2019-9-11,2019,9,11,5,d2e395,Novelty Search Explained! (Maze Navigation and Biped Locomotion),https://www.reddit.com/r/deeplearning/comments/d2e395/novelty_search_explained_maze_navigation_and/,HenryAILabs,1568148048,[https://youtu.be/-mxpn95uxS4](https://youtu.be/-mxpn95uxS4),0,1
117,2019-9-11,2019,9,11,10,d2inbq,How to Get Annotated Data for Machine Learning,https://www.reddit.com/r/deeplearning/comments/d2inbq/how_to_get_annotated_data_for_machine_learning/,LimarcAmbalina,1568166807,[https://lionbridge.ai/articles/how-to-get-annotated-data-for-machine-learning/](https://lionbridge.ai/articles/how-to-get-annotated-data-for-machine-learning/),0,1
118,2019-9-11,2019,9,11,12,d2k3es,About Residual Network Back-prop,https://www.reddit.com/r/deeplearning/comments/d2k3es/about_residual_network_backprop/,Sahil8141,1568173473,"I know the concept of forward prop in residual network that how skip connection helping us to build more deep nets . But I cant understand that how backprop work in residual network and what is the role of skip connection in back prop

Can anyone plz explain this in detail??",6,1
119,2019-9-11,2019,9,11,14,d2l6u0,Data scientist in the industry - into research,https://www.reddit.com/r/deeplearning/comments/d2l6u0/data_scientist_in_the_industry_into_research/,bob3421o,1568179394,"For the past few years I've been working as a data scientist applying mostly deep learning for proprietary industry solutions. Would love to shift a little towards proper (applied) research, writing papers etc. I don't have a PhD though. 

What do you think are my options to do so? Is it possible through full time job? Are there companies that encourage applied data scientists to participate in proper research?",4,17
120,2019-9-11,2019,9,11,17,d2mocy,Improving Industrial Processes with Machine Learning,https://www.reddit.com/r/deeplearning/comments/d2mocy/improving_industrial_processes_with_machine/,Machine_Learning001,1568188908,,0,1
121,2019-9-11,2019,9,11,17,d2mpbf,Predicting sales volume given an image of a phone case,https://www.reddit.com/r/deeplearning/comments/d2mpbf/predicting_sales_volume_given_an_image_of_a_phone/,levch,1568189095,"Hey!

So, I'm currently working on a prediction model for my local phone case printing company.

I was given 100 phone case images with different patterns on them and how many of each phone case design was sold.They want me to make a sales volume prediction on a new phone case design.

I have a very brief knowledge of Deep Learning, so I have no idea what works best for this task. Can you recommend anything? Examples, research papers to look into.",9,3
122,2019-9-11,2019,9,11,21,d2pa96,How do I train a nerual network to classify very similar image.,https://www.reddit.com/r/deeplearning/comments/d2pa96/how_do_i_train_a_nerual_network_to_classify_very/,geniusumi,1568204555,"As the following picture, I have many labeled icon as upper picture(Each label has only one image). Also, I grab many icon as the down picture from real game. I want to train a classifier so every time I give them the picture like image2.png, they will feedback ""Juggernaut"".

&amp;#x200B;

Now here is the questions:

1. I don't have enough data, since both machine learning and deeplearning needs a lot of data, how should I do? I know something called data augmentation. But since these data is not similiar compared with the real scenario that data augmentation used for, I'm not sure how to augment these data. 
2. I know there is a traditional way to detect, but it is slow and low accuracy. Since there is distortion and background color. Is it deep learning suitable for this? If so, how? If not, why and what is the best way to do such thing?

Many thanks!

&amp;#x200B;

https://i.redd.it/w4xvum2fgyl31.png",2,3
123,2019-9-11,2019,9,11,23,d2qvuj,Is it possible to know which original features had major Impact in dimensionality reduction after applying autoencoders or UMAP to data,https://www.reddit.com/r/deeplearning/comments/d2qvuj/is_it_possible_to_know_which_original_features/,jaddu6497,1568211532,,4,11
124,2019-9-12,2019,9,12,3,d2uwcf,Machine Learning and Flint Water Crisis,https://www.reddit.com/r/deeplearning/comments/d2uwcf/machine_learning_and_flint_water_crisis/,newworld-ai,1568227556,,0,1
125,2019-9-12,2019,9,12,3,d2v1n6,Which Jupyter environment would you recommend?,https://www.reddit.com/r/deeplearning/comments/d2v1n6/which_jupyter_environment_would_you_recommend/,0_marauders_0,1568228144,"ML friends, I'm super curious - for those of you who use Jupyter, which environment do you use? Which would you recommend?

* Vanilla Jupyter
* JupyterLab
* Kaggle Kernels
* Google Collab
* VS Code Jupyter notebooks

Or another version?

Thank you! :)",0,1
126,2019-9-12,2019,9,12,3,d2v1yk,Which Jupyter environment do you use?,https://www.reddit.com/r/deeplearning/comments/d2v1yk/which_jupyter_environment_do_you_use/,0_marauders_0,1568228180,"ML friends, I'm super curious - for those of you who use Jupyter, which environment do you use? Which would you recommend?

* Vanilla Jupyter
* JupyterLab
* Kaggle Kernels
* Google Collab
* VS Code Jupyter notebooks

Or another version?

Thank you! :)",16,16
127,2019-9-12,2019,9,12,5,d2wq48,Hierarchical Neural Architecture Search - A very clever technique for encoding neural networks!,https://www.reddit.com/r/deeplearning/comments/d2wq48/hierarchical_neural_architecture_search_a_very/,HenryAILabs,1568234836,[https://youtu.be/svOpLZ4Zx4A](https://youtu.be/svOpLZ4Zx4A),0,15
128,2019-9-12,2019,9,12,6,d2xcsc,Judge my built?,https://www.reddit.com/r/deeplearning/comments/d2xcsc/judge_my_built/,iordanissh,1568237385,"[https://pcpartpicker.com/list/PQf9jy](https://pcpartpicker.com/list/PQf9jy)

Any potential problems with it?",5,2
129,2019-9-12,2019,9,12,12,d322ea,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/d322ea/data_science_career_track_prep_course/,HannahHumphreys,1568259011,[removed],0,1
130,2019-9-12,2019,9,12,15,d341u3,Find Deep Learning Jobs and Talents,https://www.reddit.com/r/deeplearning/comments/d341u3/find_deep_learning_jobs_and_talents/,ai_jobs,1568270965,,4,20
131,2019-9-12,2019,9,12,22,d37rl2,rent rtx 2080 ti,https://www.reddit.com/r/deeplearning/comments/d37rl2/rent_rtx_2080_ti/,bitunicom,1568294235,I have 4 rtx 2080 ti free for at least half a year.   Please contact me if any of you need gpu resources.,1,0
132,2019-9-12,2019,9,12,22,d381hn,Need suggestion regarding 3D CNN frameworks,https://www.reddit.com/r/deeplearning/comments/d381hn/need_suggestion_regarding_3d_cnn_frameworks/,Ali4426623,1568295527,"Hi, i am new to deep learning and exploring my options for object recognition.

I previously worked on YOLO's darknet but it is related to object detection rather than recognition.

I need some frameworks to work with object recognition.

BTW i am working on 3D CNN , videos!

Can i have some suggestions?",0,1
133,2019-9-12,2019,9,12,23,d38twz,[Research],https://www.reddit.com/r/deeplearning/comments/d38twz/research/,cdossman,1568299055," 3D Morphable Face Models  Past, Present, and Future. The authors provide a detailed survey of 3D Morphable Face Models over the 20 years since they were first proposed. 

**Abstract**: In this paper, we provide a detailed survey of 3D Morphable Face Models over the 20 years since they were first proposed. The challenges in building and applying these models, namely capture, modeling, image formation, and image analysis, are still active research topics, and we review the state of-the-art in each of these areas. We also look ahead, identifying unsolved challenges, proposing directions for future research.

Summary:  [https://medium.com/ai%C2%B3-theory-practice-business/3d-morphable-face-models-past-present-and-future-b3a7f47e1b04](https://medium.com/ai%C2%B3-theory-practice-business/3d-morphable-face-models-past-present-and-future-b3a7f47e1b04) 

PDF Link:  [https://arxiv.org/pdf/1909.01815.pdf](https://arxiv.org/pdf/1909.01815.pdf)",0,0
134,2019-9-12,2019,9,12,23,d390gk,"Entering college: Computer Engineering, Electrical Engineering, Computer Science or Statistics?",https://www.reddit.com/r/deeplearning/comments/d390gk/entering_college_computer_engineering_electrical/,InfiniteLeverage,1568299853,"Entering college soon and since the past year and a half I've been studying ML pretty rigorously. So far I've loved every day of it and as of right now I like the idea of being able to develop my own machine learning algorithms once I graduate for a living.

My advisor wants me to pick a degree to focus on but I have no idea which of the 4 I posted above will give me the amount of value for developing ML algorithms.

If anyone here who's already graduated could give me some advice, I'd really appreciate it.",3,1
135,2019-9-13,2019,9,13,5,d3e0kq,What creates bias in AI?,https://www.reddit.com/r/deeplearning/comments/d3e0kq/what_creates_bias_in_ai/,ayvin_tech,1568320634,"Is it the extraordinary maths, varying data, binary machines or intelligent humans?    

When it comes to color perception, humans see BLACK and WHITE equal whereas machines see them as BLACK (0) != WHITE (255).    

On the contrary, for machines MALE = FEMALE whereas the person annotating some dataset might not feel the same.  

""Fixing discrimination in algorithmic systems is not something that can be solved easily"" - Andrew Selbst",3,0
136,2019-9-13,2019,9,13,6,d3evh4,Creating a config file to serve multiple models with tensorflow serving. Am I missing something?,https://www.reddit.com/r/deeplearning/comments/d3evh4/creating_a_config_file_to_serve_multiple_models/,FullMetalMahnmut,1568324185,"I have two models I want to serve at once using tensorflow-serving.  To do so it looks like I simply need to pass a config file instead of model name and base path.

Im having trouble generating the config file properly.  I have no experience using Google Protocol Buffers, and I havent been able to figure it out from the usual sources.  Can someone ELI5?",2,1
137,2019-9-13,2019,9,13,13,d3jwyi,Deepfaking images,https://www.reddit.com/r/deeplearning/comments/d3jwyi/deepfaking_images/,pranjalranjan299,1568348291,"Hi! I'm working on a project on deepfakes detection for images. To create a dataset for detection I need to get a lot of deepfake images. I'm looking for some architectures for deepfake image generation so I can quickly create my dataset. Does anyone know about any research done in deepfakes for images? 

The alternative is to create normal deepfake videos and get frames for that but it takes several hours for one video and it's really not viable to create a large dataset.",3,8
138,2019-9-13,2019,9,13,14,d3kjpm,Masters in Artificial Intelligence and Sound/Music,https://www.reddit.com/r/deeplearning/comments/d3kjpm/masters_in_artificial_intelligence_and_soundmusic/,sjibak,1568351969,"I have a bachelor degree in CS and I've 5 years experience of working in multiple tech companies. I have mostly worked in machine learning and artificial intelligence including deep neural nets. Alongside, I am a huge music addict and a self learned amateur piano player and sometimes, I love to compose music out of an experiment. 

Now, I wish to pursue masters. But, I want to give myself a platform where my crave for technology  and passion for music will find the perfect blend. So basically, I want to pursue something which specializes in sound/music and AI/cognitive technology at the same time.

My region preference would be either EU or US. So, I have shortlisted some universities by searching relevant research papers, 

US - Stanford, CMU, NYU

EU - Queen Mary, Johannes Kepler University, Universitat Pompeu Fabra, Ghent University

There are few more universities with research output in this subject in both the regions. But, these are the ones with significant research output. 

I'd love to know about any other university which offers specialization in this particular field of study. And, also if someone can help me with the career opportunities upon completing my masters in such a field?",2,3
139,2019-9-13,2019,9,13,14,d3ktxt,NLP folks: how do you spend your time at work? What aspects of NLP are still in need of most improvement?,https://www.reddit.com/r/deeplearning/comments/d3ktxt/nlp_folks_how_do_you_spend_your_time_at_work_what/,athenysus,1568353732,,1,19
140,2019-9-13,2019,9,13,16,d3lsgn,Can i make a basic deep learning project with NVIDIA GT 220,https://www.reddit.com/r/deeplearning/comments/d3lsgn/can_i_make_a_basic_deep_learning_project_with/,hernancrespo89,1568360074,"I am very new with deep learning. I want to make one of these projects:

Eye and face detection

Eye motion tracking

Object detection

&amp;#x200B;

Is my card enough?",9,10
141,2019-9-13,2019,9,13,16,d3lzda,Conversational AI: The Advanced Form of Chatbots,https://www.reddit.com/r/deeplearning/comments/d3lzda/conversational_ai_the_advanced_form_of_chatbots/,GreenScheme7,1568361450,,0,0
142,2019-9-14,2019,9,14,4,d3u1ud,I made a doodle classifier web app,https://www.reddit.com/r/deeplearning/comments/d3u1ud/i_made_a_doodle_classifier_web_app/,nerdy_wits,1568401947,,0,36
143,2019-9-14,2019,9,14,11,d3zqzk,Project ideas 2019,https://www.reddit.com/r/deeplearning/comments/d3zqzk/project_ideas_2019/,cyborg_404,1568429925,"Please suggest a great final year project in artificial intelligence (machine learning or deep learning)? Something which is not done many times before, like not the common ML projects. DL ideas will be appreciated more.  :)",1,0
144,2019-9-14,2019,9,14,14,d417nb,is adam gradient descent best algorithm,https://www.reddit.com/r/deeplearning/comments/d417nb/is_adam_gradient_descent_best_algorithm/,mshubham84,1568439333,,11,2
145,2019-9-15,2019,9,15,0,d46pw3,Do I really need a laptop with discreet graphics (GTX 1650 4gb)?,https://www.reddit.com/r/deeplearning/comments/d46pw3/do_i_really_need_a_laptop_with_discreet_graphics/,wade_wilson2120,1568475373,"1.Hello deep learning folks I just started data science course. I am new in this area so please give me advice whether I should get a laptop with graphics mentioned above or not.

2.And if you can please give me some pointers in learning this subject in a systematic way.

Thanks in advance",3,8
146,2019-9-15,2019,9,15,4,d49sah,is there source code available of deep learning so i can modify it,https://www.reddit.com/r/deeplearning/comments/d49sah/is_there_source_code_available_of_deep_learning/,mshubham84,1568489289,,10,0
147,2019-9-15,2019,9,15,12,d4f51v,Machine Learning Complete Elite Course:,https://www.reddit.com/r/deeplearning/comments/d4f51v/machine_learning_complete_elite_course/,ShyamTgr,1568516953,,2,1
148,2019-9-15,2019,9,15,14,d4gemo,Some questions from a Deep Learning newbie,https://www.reddit.com/r/deeplearning/comments/d4gemo/some_questions_from_a_deep_learning_newbie/,sysadmin-noob,1568525077,"Hello all,

I hope you're all doing good. I have a couple of questions concerning Deep Learning for Automatic Speech Recognition (ASR) and video analytics.

I am very new to Deep Learning and any advice or detailed explanation is highly appreciated.

The first task I have is to build an ASR for my own language. I did my research and found the following tools on github:

Deep Speech, Wave2letter, Automatic Speech Recognition (by zzw922cn) and Kaldi.

What I really want is to train my own language model (Say We are talking about spoken arabic, or any other language). How to get started ? What is a robust tool I can build ? Should I build my own RNN-CNN-LSTM (which I have no idea how to build) using Tensorflow or it is better to use an out of the box one of the open source tools ? 

The requirement is that I need to deliver this as fast as I can.

The second task is to have a tool to perform video analytics. Meaning I need to detect anomalies in videos. Let's say I want to automate detection of people, strange and anomalous event (Like a car accident, a robbery, ...). What is the best way to go about this given my humble background ? An in depth step by step solution to this problem with hints on how to build my own models using Tensorflow or any library is highly appreciated.

The final question is that do I really need to understand how CNN, RNN and LSTM work if I need to build my own Tensorflow models ? What is a reasonable timeline to perform these two tasks (Just as a simple proof of concept, nothing very fancy).

&amp;#x200B;

Thank you for your time.",2,1
149,2019-9-15,2019,9,15,18,d4i62u,You decide,https://www.reddit.com/r/deeplearning/comments/d4i62u/you_decide/,Dinsras,1568538560,,5,0
150,2019-9-15,2019,9,15,23,d4l9nq,PyTorch implementation of 17 Deep RL algorithms,https://www.reddit.com/r/deeplearning/comments/d4l9nq/pytorch_implementation_of_17_deep_rl_algorithms/,__data_science__,1568558382,"For anyone trying to learn or practice RL, here's a repo with working PyTorch implementations of 17 RL algorithms including DQN, DQN-HER, Double DQN, REINFORCE, DDPG, DDPG-HER, PPO, SAC, SAC Discrete, A3C, A2C etc..

Let me know what you think!

[https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch)",2,49
151,2019-9-16,2019,9,16,3,d4o3wr,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/d4o3wr/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1568570968,[removed],0,1
152,2019-9-16,2019,9,16,4,d4pdkk,"Deep Learning Research Weekly Update #5 - (September 15th, 2019)",https://www.reddit.com/r/deeplearning/comments/d4pdkk/deep_learning_research_weekly_update_5_september/,HenryAILabs,1568576453,[https://youtu.be/dEEiTKZJ\_RE](https://youtu.be/dEEiTKZJ_RE),0,1
153,2019-9-16,2019,9,16,5,d4pn64,A Brief History of AI from 1940s till Today ( Image Credit: Deepkapha.ai ),https://www.reddit.com/r/deeplearning/comments/d4pn64/a_brief_history_of_ai_from_1940s_till_today_image/,ai-lover,1568577622,,1,0
154,2019-9-16,2019,9,16,8,d4s6vj,Deep learning course suggestion for nlp,https://www.reddit.com/r/deeplearning/comments/d4s6vj/deep_learning_course_suggestion_for_nlp/,kamal4493,1568588937,"Any suggestions for a deep learning based course on natural language processing. I know about cs224n from stanford and I am looking for something similar but including recent advancements in this field. A course including transformers and the latest architectures in nlp (ulmfit, bert) would be awesome.",3,13
155,2019-9-16,2019,9,16,14,d4wdtw,Interview with a Deep Learning expert - The Technically Speaking Podcast,https://www.reddit.com/r/deeplearning/comments/d4wdtw/interview_with_a_deep_learning_expert_the/,grtgbln,1568612288,,0,0
156,2019-9-16,2019,9,16,16,d4x3s2,Image Optimization with Machine Learning,https://www.reddit.com/r/deeplearning/comments/d4x3s2/image_optimization_with_machine_learning/,RubiksCodeNMZ,1568617305,,0,3
157,2019-9-16,2019,9,16,16,d4xc2r,The Machine Learning Data Science Path,https://www.reddit.com/r/deeplearning/comments/d4xc2r/the_machine_learning_data_science_path/,KamWithK,1568618944,"I've created a [blog post](https://kamwithk.github.io/path.html#path) detailing different courses, books and places people can learn about data science/machine learning from.

It  categorizes the sources, and gives details on the main differences between them to help decide whether the course is right for you. Make sure to take a look:

[https://kamwithk.github.io/path.html#path](https://kamwithk.github.io/path.html#path)

Btw I've created a [new Twitter account](https://twitter.com/kamwithk_) which I'm using to post updates I make to this and about my AI journey, if you'd like to keep updated follow me!

Any feedback would be greatly appreciated!",4,13
158,2019-9-16,2019,9,16,16,d4xeft,Setting up Smart Homes with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/d4xeft/setting_up_smart_homes_with_artificial/,Techno_SUPPORT,1568619417,,0,0
159,2019-9-16,2019,9,16,20,d4zj28,Attention Mechanism,https://www.reddit.com/r/deeplearning/comments/d4zj28/attention_mechanism/,pirate7777777,1568634475,,0,17
160,2019-9-16,2019,9,16,22,d50l6x,best group telegram about python and machine learning https://t.me/joinchat/CuFqkRPvJlV56vKtsaZmLg,https://www.reddit.com/r/deeplearning/comments/d50l6x/best_group_telegram_about_python_and_machine/,Doctor_who1,1568640104," 

best group telegram about python and machine learning

https://t.me/joinchat/CuFqkRPvJlV56vKtsaZmLg",0,0
161,2019-9-17,2019,9,17,1,d52p1e,Feeding tensorflow estimator with dataset in distributed mode,https://www.reddit.com/r/deeplearning/comments/d52p1e/feeding_tensorflow_estimator_with_dataset_in/,shahriar49,1568649665,"I have below piece of code for running a keras LSTM classifier network on a dataset containing sequence of features and it runs well without problem (details omitted to keep the text readable). My Tensorflow version is 1.13:

    def parse_tfrecord(example):
    features = tf.parse_single_example(example, featuresDict)
    label = features['label']
    data = tf.decode_raw(features['data'], tf.int64)
return data, label

    def read_datasets(pattern, numFiles, numEpochs=None, batchSize=None):
    files = tf.data.Dataset.list_files(pattern)

        def _parse(x):
        x = tf.data.TFRecordDataset(x, compression_type='GZIP')
     return x

        dataset = files.interleave(_parse, cycle_length=numFiles, block_length=1).map(parse_tfrecord)
    dataset = dataset.batch(batchSize)
    dataset = dataset.repeat(numEpochs)
return dataset

    def keras_model(...)

    def main(args):
    ...
    train_data = read_datasets(...)
    val_data = read_datasets(...)
    test_data = read_datasets(...)

        model = keras_model(...)
    model.compile(...)
    model.fit(train_data, epochs=epochs, steps_per_epoch=train_steps, validation_data=val_data,
 validation_steps=val_steps)

    if __name__ == '__main__':
    ...
    main(args)


 I want to run it in distributed mode, so I encapsulate the keras classifier with an estimator object. Distributed learning documentation is unclear on the net, but what I understand from it (and expect it to be) is that I should just modify the main() function like this: 

    def main(args):
    ...
    train_data = read_datasets(...)
    val_data = read_datasets(...)
    test_data = read_datasets(...)

        model = keras_model(...)
    model.compile(...)
    runConfig = tf.estimator.RunConfig(
        session_config=config,
        model_dir=log_dir,
        save_summary_steps=1,
        save_checkpoints_steps=train_steps
    )
    estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=runConfig)
    train_input_fn = train_data.make_one_shot_iterator().get_next
    eval_input_fn = val_data.make_one_shot_iterator().get_next
    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=epochs * train_steps)
    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, start_delay_secs=1, throttle_secs=1, steps=None)
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

    if __name__ == '__main__':
    ...
    TF_CONFIG = {
         'task': ...
         'cluster': ...
    }
    os.environ['TF_CONFIG'] = json.dumps(TF_CONFIG)
    main(args)

 However I get below error traceback: 

    INFO:tensorflow:Calling model_fn.
    Traceback (most recent call last):
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1811, in zeros
        tensor_shape.TensorShape(shape))
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 690, in __init__
        self._dims = [as_dimension(d) for d in dims_iter]
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 690, in &lt;listcomp&gt;
        self._dims = [as_dimension(d) for d in dims_iter]
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 632, in as_dimension
        return Dimension(value)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 185, in __init__
        self._value = int(value)
    TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""LSTM_TFdataset-distributed.py"", line 323, in &lt;module&gt;
        main(a)
      File ""LSTM_TFdataset-distributed.py"", line 233, in main
        tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 471, in train_and_evaluate
        return executor.run()
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 638, in run
        getattr(self, task_to_run)()
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 643, in run_chief
        return self._start_distributed_training()
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 789, in _start_distributed_training
        saving_listeners=saving_listeners)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 358, in train
        loss = self._train_model(input_fn, hooks, saving_listeners)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1124, in _train_model
        return self._train_model_default(input_fn, hooks, saving_listeners)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1154, in _train_model_default
        features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1112, in _call_model_fn
        model_fn_results = self._model_fn(features=features, **kwargs)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\keras.py"", line 278, in model_fn
        labels)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow_estimator\python\estimator\keras.py"", line 201, in _clone_and_build_model
        optimizer_iterations=global_step)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\models.py"", line 466, in clone_and_build_model
        clone = clone_model(model, input_tensors=input_tensors)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\models.py"", line 271, in clone_model
        return _clone_functional_model(model, input_tensors=input_tensors)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\models.py"", line 161, in _clone_functional_model
        **kwargs))
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 701, in __call__
        return super(RNN, self).__call__(inputs, **kwargs)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 554, in __call__
        outputs = self.call(inputs, *args, **kwargs)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 2416, in call
        inputs, mask=mask, training=training, initial_state=initial_state)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 759, in call
        inputs, initial_state, constants)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 863, in _process_inputs
        initial_state = self.get_initial_state(inputs)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 679, in get_initial_state
        inputs=None, batch_size=batch_size, dtype=dtype)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 2194, in get_initial_state
        self, inputs, batch_size, dtype))
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 3001, in _generate_zero_filled_state_for_cell
        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 3017, in _generate_zero_filled_state
        return nest.map_structure(create_zeros, state_size)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\util\nest.py"", line 381, in map_structure
        structure[0], [func(*x) for x in entries])
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\util\nest.py"", line 381, in &lt;listcomp&gt;
        structure[0], [func(*x) for x in entries])
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 3014, in create_zeros
        return array_ops.zeros(init_state_size, dtype=dtype)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1814, in zeros
        shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1039, in convert_to_tensor
        return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1097, in convert_to_tensor_v2
        as_ref=False)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1175, in internal_convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1102, in _autopacking_conversion_function
        return _autopacking_helper(v, dtype, name or ""packed"")
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1054, in _autopacking_helper
        return gen_array_ops.pack(elems_as_tensors, name=scope)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 6426, in pack
        ""Pack"", values=values, axis=axis, name=name)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 350, in _apply_op_helper
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 5713, in _get_graph_from_inputs
        _assert_same_graph(original_graph_element, graph_element)
      File ""D:\Shahriar\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 5649, in _assert_same_graph
        original_item))
    ValueError: Tensor(""lstm/zeros/packed/1:0"", shape=(), dtype=int32, device=/job:chief/task:0) must be from the same graph as Tensor(""strided_slice:0"", shape=(), dtype=int32).
    

 Can anyone help me to solve this problem?",27,3
162,2019-9-17,2019,9,17,4,d556nv,License Plate Recognition,https://www.reddit.com/r/deeplearning/comments/d556nv/license_plate_recognition/,nebu001,1568661810,Can Someone help me in implementing License Plate Recognition?  Actually  I want to build a multi-stage CNN model in which CNN1 would detect  whether a particular image contains car or not using sliding window  approach. Then CNN2 would detect whether the car image contains license  plate or not again using sliding window approach. And then finally CNN3  would extract the character and would apply OCR. I want to implement it  in keras but I am not getting the idea about how to approach it.,0,0
163,2019-9-17,2019,9,17,5,d55xzt,Applied Data Science with Python,https://www.reddit.com/r/deeplearning/comments/d55xzt/applied_data_science_with_python/,HannahHumphreys,1568664850,[removed],0,1
164,2019-9-17,2019,9,17,6,d56o9s,Keras ResNet Implementation Explained!,https://www.reddit.com/r/deeplearning/comments/d56o9s/keras_resnet_implementation_explained/,HenryAILabs,1568667994,https://www.youtube.com/watch?v=DWpijIMpiPY,0,8
165,2019-9-17,2019,9,17,6,d56x3v,Any Way to Rename Images Using OCR Deep Learning ?,https://www.reddit.com/r/deeplearning/comments/d56x3v/any_way_to_rename_images_using_ocr_deep_learning/,ravenfry,1568669061,"Hello, I Have about 1000 images without correct names they are like image001.jpg to image1000.jpg something like that

well is there an app that can read the text on the image to rename the image according to the text on the image?

Example the image is a movie poster so the app will read the text and rename the image? 

Or another way using google reverse image to find similar images and rename the image with the most common name on the same images found with google reverse?

Thanks",6,5
166,2019-9-17,2019,9,17,7,d57eu9,Remember the AI Joe Rogan? My friends company is launching the AI software they used make it and its free!,https://www.reddit.com/r/deeplearning/comments/d57eu9/remember_the_ai_joe_rogan_my_friends_company_is/,thatguyisswell,1568671254,,0,0
167,2019-9-17,2019,9,17,12,d5bkxl,Are there credible analyses of Dessa's voice generation algorithm?,https://www.reddit.com/r/deeplearning/comments/d5bkxl/are_there_credible_analyses_of_dessas_voice/,ziapelta,1568692053,"Recently Dessa showed that they could accurately replicate Joe Rogan's voice ([https://www.youtube.com/watch?time\_continue=3&amp;v=DWK\_iYBl8cA](https://www.youtube.com/watch?time_continue=3&amp;v=DWK_iYBl8cA)), but they have not released the algorithm details. Have others been able reconstruct what they likely did or are there up-to-date write-ups of the state-of-the-art in artificial voice generation?",0,9
168,2019-9-17,2019,9,17,13,d5bw0z,what's next after coursera Andrew Ng's course,https://www.reddit.com/r/deeplearning/comments/d5bw0z/whats_next_after_coursera_andrew_ngs_course/,snip3r77,1568693900,"Of course, completing it we will not have 100% understanding.

Can you guys guide me on how to hone my skills?  
Kaggle? Reading simple CNN papers?

Should I go for [fast.ai](https://fast.ai) ? Will it be good enough if I'm proficient with [fast.ai](https://fast.ai) ?

Appreciate your advice.

Thanks",21,32
169,2019-9-17,2019,9,17,14,d5cq81,Benefits of Using Machine Learning in Supply Chain,https://www.reddit.com/r/deeplearning/comments/d5cq81/benefits_of_using_machine_learning_in_supply_chain/,erpintegration,1568699465,,0,0
170,2019-9-17,2019,9,17,15,d5ctnl,Personal Filesystem Image classifier,https://www.reddit.com/r/deeplearning/comments/d5ctnl/personal_filesystem_image_classifier/,swiix1337,1568700130,"Hello community, I am new here in deep learning.
I am searching an existing project, open source maybe. 
Which allowed me to have a selected root folder with my images. In the root directory are multiple folders with tags, like family, dogs, cats, birthday...
I want to train this model by creating folders(tags) and put my picture in it. And anytime I add a new picture to the root folder I want to get a classification to the existing tags.

That would be the easiest system to manage my photos in my perspective.

When something like this doesn't exist, I will spend my time and program it :)

Would be awesome if someone knows something like this. 

Peace out, have a nice day",3,1
171,2019-9-17,2019,9,17,18,d5ek8n,How Machine Learning Is Improving Business Processes,https://www.reddit.com/r/deeplearning/comments/d5ek8n/how_machine_learning_is_improving_business/,Techno_SUPPORT,1568712924,,0,0
172,2019-9-18,2019,9,18,0,d5iuft,Swift having a bit of a struggle to become the first modern differentiable programming language,https://www.reddit.com/r/deeplearning/comments/d5iuft/swift_having_a_bit_of_a_struggle_to_become_the/,cgarciae,1568735194,,0,1
173,2019-9-18,2019,9,18,0,d5ivfr,Why can't Posterior for all models be computed?,https://www.reddit.com/r/deeplearning/comments/d5ivfr/why_cant_posterior_for_all_models_be_computed/,PyWarrior,1568735315,"Hi Everyone,

I recently read one article on variational inference in which it was written that ***we can't compute posterior for many models***. Why can't we compute posterior for many models?

&amp;#x200B;

Also, it would be great if someone can suggest good articles for variational inference and stuffs required for the topic so that I can get intuition.",1,0
174,2019-9-18,2019,9,18,5,d5myiz,Is the Coevolution of Agents and their Environments the path to AGI? (POET Explained),https://www.reddit.com/r/deeplearning/comments/d5myiz/is_the_coevolution_of_agents_and_their/,HenryAILabs,1568753170,[https://youtu.be/YBC-2zccO0s](https://youtu.be/YBC-2zccO0s),0,0
175,2019-9-18,2019,9,18,8,d5p0uu,Noisy loss in distributed training in tensorflow,https://www.reddit.com/r/deeplearning/comments/d5p0uu/noisy_loss_in_distributed_training_in_tensorflow/,shahriar49,1568762517,"I am working on distributed learning in tensorflow through estimators API, and I always get below training loss graphs in tensorboard when comparing one-machine configuration (one ps and one chief on the same machine) and two-machine configuration (one ps and one chief on machine#1, one worker on machine#2).

&amp;#x200B;

https://i.redd.it/yc65pjdsm8n31.jpg

https://i.redd.it/5nqzbmetm8n31.jpg

Also when I download the graph data, I see that some steps are lost in two-machine distributed training case. My model is defined in keras and I use the standard estimator functions for distributed training in the following format:

    runConfig = tf.estimator.RunConfig(session_config=config, 
                                    model_dir=log_dir,
                                    save_summary_steps=1,
                                    save_checkpoints_steps=train_steps)
    estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=runConfig) 
    train_spec = tf.estimator.TrainSpec(input_fn=lambda: ..., max_steps=...) 
    eval_spec = tf.estimator.EvalSpec(input_fn=lambda:..., start_delay_secs=1, throttle_secs=1, steps=None) tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

What can be the cause for this noisy behavior and missing logs?",0,2
176,2019-9-18,2019,9,18,12,d5ro07,Meta-learning for Binary Classification,https://www.reddit.com/r/deeplearning/comments/d5ro07/metalearning_for_binary_classification/,arjundupa,1568775615,"Has meta-learning been applied to any binary classification tasks?

I don't know too much about meta-learning; does my question even make sense? Could it be used to improve the performance of an existing architecture on a binary classification task?",0,1
177,2019-9-18,2019,9,18,12,d5s7nm,Is multi instance learning a form of self-supervised learning?,https://www.reddit.com/r/deeplearning/comments/d5s7nm/is_multi_instance_learning_a_form_of/,sriharsha_0806,1568778603,,2,3
178,2019-9-18,2019,9,18,14,d5t4nf,Do you recommend a lecture about probabilistic theory ?,https://www.reddit.com/r/deeplearning/comments/d5t4nf/do_you_recommend_a_lecture_about_probabilistic/,sunshower76,1568784168,"Hi
Im interested in CV and Deep learning.
So, I want to study statistics and probablistic theory more.

I studied very basic statistics like PDF, basic bayes rule etc.

I want to understand  Marcov random field, CRF and more statistical knowledge.

Please recommend some lectures thanks!",1,1
179,2019-9-18,2019,9,18,14,d5taz3,AI and deep learning to tackle traffic congestion,https://www.reddit.com/r/deeplearning/comments/d5taz3/ai_and_deep_learning_to_tackle_traffic_congestion/,Ripple2709,1568785285,,1,1
180,2019-9-18,2019,9,18,17,d5usc3,Reducing dependance on RAM,https://www.reddit.com/r/deeplearning/comments/d5usc3/reducing_dependance_on_ram/,Pik000,1568795601,"Hi All,

I'm currently building a model based on the Google Colab image description model. I have my owndata set that I am currently using but the model is taking up stupid amounts of memory (40GB) before it starts the epochs.

Should I look at converting the dataset to a TFrecord and load it  using the below? tf.data.Dataset.from\_tensor\_slices

Just a bit lost on the next steps on making this model a bit easier to train once I get more data.

&amp;#x200B;

Thanks",6,13
181,2019-9-18,2019,9,18,19,d5w07d,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/d5w07d/data_science_career_track_prep_course/,HannahHumphreys,1568804011,[removed],0,1
182,2019-9-18,2019,9,18,21,d5x4cm,How big data is transforming the real estate industry,https://www.reddit.com/r/deeplearning/comments/d5x4cm/how_big_data_is_transforming_the_real_estate/,raj11113,1568810075,,0,1
183,2019-9-18,2019,9,18,22,d5xx9n,deepnude.to - AI that removes clothes from images,https://www.reddit.com/r/deeplearning/comments/d5xx9n/deepnudeto_ai_that_removes_clothes_from_images/,pangiecutie,1568813897,,0,0
184,2019-9-18,2019,9,18,23,d5ynl2,Need a clear simple approach to distributed learning in Tensorflow/Keras,https://www.reddit.com/r/deeplearning/comments/d5ynl2/need_a_clear_simple_approach_to_distributed/,shahriar49,1568817240," I have multiple machines, some with GPUs and some others not. I also have a keras model that works fine on a single machine but I want to train it in a distributed mode because I want to test it with a huge dataset and with a bigger number of layers. There is quite a lot of pages discussing the distribution strategy in tf.distribute, but at the same time there are a lot other pages showing how to do it with encapsulating keras model with an estimator, setting up the TF\_CONFIG parameter and then call tf.estimator.train\_and\_evaluate. I used the second approach personally as it was more straightforward and am struggling to tune and debug it. It works anyway, but I am very confused what is the point in all of strategy-related stuff as I don't see any use them in the second approach, and the documentation is not helping to clear it.

I also have some doubt if my file setting environment is correct: My understanding is that the PS server is going to hold the model parameters and the chief server is going to administer the whole training process, partitioning and distributing data, and saving summaries and checkpoints. So I assume that:

1- The main code for PS, Chief, and Worker machines should be exactly the same, except in TF\_CONFIG definition that defines the task and index for that specific machine.

2- I should have one shared copy of data in a folder available to all chief and workers.

3- I should have one shared log directory accessible by all machines as defined in tf.estimator.RunConfig.

4- Having this setting then a piece of code such as below will do the job (assuming the model has been defined elsewhere and the read\_datasets function returns features and labels for running the model):

    runConfig = tf.estimator.RunConfig(session_config=config, 
                                    model_dir=log_dir,
                                    save_summary_steps=1,
                                    save_checkpoints_steps=train_steps)
    estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=runConfig) 
    train_spec = tf.estimator.TrainSpec(input_fn=lambda: read_datasets(...), max_steps=epochs*train_steps)
    eval_spec = tf.estimator.EvalSpec(input_fn=lambda: read_datasets(...), start_delay_secs=1, throttle_secs=1)
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

Although the above approach seems to work fine, I have still some difficulties understanding how the chief is partitioning the dataset among the workers and how to set the train\_step and batch\_size in this approach. Also I don't know how can I report accuracy and other metrics such as precision/recall/F1 in addition to loss when running the tf.estimator.evaluate  without writing a custom model\_fn for my encapsulated keras estimator.

Any help is greatly appreciated.",0,1
185,2019-9-19,2019,9,19,0,d5z0yu,"How we made landmark recognition in Cloud Mail.ru, and why",https://www.reddit.com/r/deeplearning/comments/d5z0yu/how_we_made_landmark_recognition_in_cloud_mailru/,pvl18,1568818880,,0,5
186,2019-9-19,2019,9,19,4,d62ug5,NeMo (Neural Modules) - a PyTorch toolkit for speech recognition and NLP,https://www.reddit.com/r/deeplearning/comments/d62ug5/nemo_neural_modules_a_pytorch_toolkit_for_speech/,gizcard,1568834957,,0,4
187,2019-9-19,2019,9,19,9,d668o6,How to make your own deep learning accelerator chip!,https://www.reddit.com/r/deeplearning/comments/d668o6/how_to_make_your_own_deep_learning_accelerator/,aks4321,1568852970,,5,21
188,2019-9-19,2019,9,19,10,d66olr,Autonomous Artificial Intelligence Is Entering The World Of Art,https://www.reddit.com/r/deeplearning/comments/d66olr/autonomous_artificial_intelligence_is_entering/,BlastPalace,1568855139,,0,1
189,2019-9-19,2019,9,19,11,d67n36,deepnude.to - AI that removes clothes from images,https://www.reddit.com/r/deeplearning/comments/d67n36/deepnudeto_ai_that_removes_clothes_from_images/,pangiecutie,1568859944,,0,0
190,2019-9-19,2019,9,19,15,d69ung,How does RMSProp gradient descent solve the issue of non-stationary environments?,https://www.reddit.com/r/deeplearning/comments/d69ung/how_does_rmsprop_gradient_descent_solve_the_issue/,mellow54,1568872910,"I've been struggling to get answers for this. My question has mainly 3 parts:

1) what is a non-stationary environment in this context?
2) why is it a problem for SGD?
3) how does RMSProp get around this problem?",0,1
191,2019-9-19,2019,9,19,16,d6aj8j,Applications of Artificial Intelligence (AI) in the Food Industry,https://www.reddit.com/r/deeplearning/comments/d6aj8j/applications_of_artificial_intelligence_ai_in_the/,Ripple2709,1568877513,,0,1
192,2019-9-19,2019,9,19,17,d6b0ru,"[P] SpeedTorch. 4x faster pinned CPU -&gt; GPU data transfer than Pytorch pinned CPU tensors, and 110x faster GPU -&gt; CPU transfer. Augment parameter size by hosting on CPU. Use non sparse optimizers (Adadelta, Adamax, RMSprop, Rprop, etc.) for sparse training (word2vec, node2vec, GloVe, NCF, etc.).",https://www.reddit.com/r/deeplearning/comments/d6b0ru/p_speedtorch_4x_faster_pinned_cpu_gpu_data/,BatmantoshReturns,1568881156,,0,2
193,2019-9-19,2019,9,19,19,d6bwsm,Google to open AI lab in Bangalore,https://www.reddit.com/r/deeplearning/comments/d6bwsm/google_to_open_ai_lab_in_bangalore/,adssidhu86,1568887679,,0,49
194,2019-9-19,2019,9,19,19,d6c5l5,Want to try a fun Image classification App.Try ImageNet Roulette is a provocation designed to help us see into the ways that humans are classified in machine learning systems.,https://www.reddit.com/r/deeplearning/comments/d6c5l5/want_to_try_a_fun_image_classification_apptry/,adssidhu86,1568889299,,3,2
195,2019-9-19,2019,9,19,22,d6e2qj,"Pytorch implementation of ACL2019 paper ""Simple and Effective Text Matching with Richer Alignment Features""",https://www.reddit.com/r/deeplearning/comments/d6e2qj/pytorch_implementation_of_acl2019_paper_simple/,rqyang,1568899816,,0,1
196,2019-9-19,2019,9,19,22,d6e32n,Combining map and padded_batch in tensorlow,https://www.reddit.com/r/deeplearning/comments/d6e32n/combining_map_and_padded_batch_in_tensorlow/,shahriar49,1568899868,To increase the performance on input pipeline tensorflow documentation recommends using tf.contrib.data.map\_and\_batch instead of separate .map and .batch functions ([https://www.tensorflow.org/guide/performance/datasets](https://www.tensorflow.org/guide/performance/datasets)). But how to combine .map and .padded\_batch functions in input pipeline?,0,1
197,2019-9-19,2019,9,19,22,d6eba2,Landmark recognition in Cloud Mail.ru using deep learning: how and why,https://www.reddit.com/r/deeplearning/comments/d6eba2/landmark_recognition_in_cloud_mailru_using_deep/,atomlib_com,1568900959,,0,1
198,2019-9-19,2019,9,19,22,d6ecy7,Machine Learning for your apartment hunt. Part 1,https://www.reddit.com/r/deeplearning/comments/d6ecy7/machine_learning_for_your_apartment_hunt_part_1/,atomlib_com,1568901180,,0,3
199,2019-9-20,2019,9,20,1,d6grhp,Recursively defining a neural network,https://www.reddit.com/r/deeplearning/comments/d6grhp/recursively_defining_a_neural_network/,ggghash,1568911708,"I have been working on this for a few days and haven't found much literature on the topic. Has this been explored and I'm just missing it, or should I write an article about it when I'm done with my research?",4,1
200,2019-9-20,2019,9,20,3,d6i6s8,Human detection with classification,https://www.reddit.com/r/deeplearning/comments/d6i6s8/human_detection_with_classification/,Esc99,1568917848,"Hi! I'm trying to train an algorithm to detect humans in an image. Is it possible to do with mere classification? So, without using an object detector( like faster rcnn, yolo), but a ResNet, Inception or similar?",3,1
201,2019-9-20,2019,9,20,7,d6lqp8,Rewriting Generative Deep Learning Book from David Foster in Pytorch,https://www.reddit.com/r/deeplearning/comments/d6lqp8/rewriting_generative_deep_learning_book_from/,mlslayer,1568933503," Just wanted to say that I'm rewriting the GDL book in Pytorch here [https://github.com/MLSlayer/Generative-Deep-Learning-Code-in-Pytorch](https://github.com/MLSlayer/Generative-Deep-Learning-Code-in-Pytorch)

Any feedback or help would be appreciated!",3,24
202,2019-9-20,2019,9,20,15,d6qo90,What are some good research topics in NLP?,https://www.reddit.com/r/deeplearning/comments/d6qo90/what_are_some_good_research_topics_in_nlp/,GabiruAttack,1568959689,"Hey, I'm trying to start my research in NLP and I'm looking for relevant topics. What do you suggest? Thanks!",1,3
203,2019-9-20,2019,9,20,16,d6r59p,deepnude.to - AI that removes clothes from images,https://www.reddit.com/r/deeplearning/comments/d6r59p/deepnudeto_ai_that_removes_clothes_from_images/,pangiecutie,1568962816,,1,0
204,2019-9-20,2019,9,20,20,d6tj3v,Transforming CRM Operations With Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/d6tj3v/transforming_crm_operations_with_artificial/,Ripple2709,1568978931,,0,3
205,2019-9-21,2019,9,21,1,d6x8yb,Anyone involved in deep reinforcement learning? Here's some research into it.,https://www.reddit.com/r/deeplearning/comments/d6x8yb/anyone_involved_in_deep_reinforcement_learning/,OpenDataSciCon,1568996393,,1,7
206,2019-9-21,2019,9,21,7,d72c7m,A Self-Directed Pathway to Deep Learning,https://www.reddit.com/r/deeplearning/comments/d72c7m/a_selfdirected_pathway_to_deep_learning/,phoenixperson747,1569019389,"Hi everyone,

I'm interested in learning some principles of machine learning and deep learning, and came across this blog post. It looks like a really good pathway to me, but I wanted to get the perspective of those who are already utilizing these principles in the field. Would following something like this make you a competitive job candidate? Are they missing something that is really important to include? Cheers!

[https://towardsdatascience.com/how-to-learn-deep-learning-in-6-months-e45e40ef7d48](https://towardsdatascience.com/how-to-learn-deep-learning-in-6-months-e45e40ef7d48)",5,3
207,2019-9-21,2019,9,21,12,d75evn,AI that Remove Clothes From Images,https://www.reddit.com/r/deeplearning/comments/d75evn/ai_that_remove_clothes_from_images/,23virginities,1569036344,,1,0
208,2019-9-21,2019,9,21,12,d75mo2,can we use CNN deep dream model for audio processing,https://www.reddit.com/r/deeplearning/comments/d75mo2/can_we_use_cnn_deep_dream_model_for_audio/,mshubham84,1569037701,,7,11
209,2019-9-21,2019,9,21,21,d7a2rp,"[Project] torchdata: Implement map, cache, filter etc. within PyTorch's Datasets (like Tensorflow's tf.data and more)",https://www.reddit.com/r/deeplearning/comments/d7a2rp/project_torchdata_implement_map_cache_filter_etc/,szymonmaszke,1569070169,"**Hi /r/deeplearning**,

# What is [torchdata](https://github.com/szymonmaszke/torchdata)

I would like to present you a new open source PyTorch based project ([__torchdata__](https://szymonmaszke.github.io/torchdata/)) which extends capabilities of `torch.utils.data.Dataset` by bringing `map`, `cache` and other operations known from `tensorflow.data.Dataset` (and actually a little more than that).

### All that with a single line of code: `super().__init__()`

For more, check [documentation](https://szymonmaszke.github.io/torchdata/) or [github repository](https://github.com/szymonmaszke/torchdata).

# Functionalities Overview

* Use `map`, `apply`, `reduce` or `filter`
* `cache` data in RAM or on disk (even partial caching, say first `20%` RAM and the rest on disk)
* Full PyTorch's [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and [`IterableDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset&gt;) support (including [`torchvision`](https://pytorch.org/docs/stable/torchvision/index.html))
* General `torchdata.maps` like `Flatten` or `Select`
* Concrete `torchdata.datasets` designed for file reading and other general tasks

# Example

- Create image reading dataset 

        import torchdata
        import torchvision


        class Images(torchdata.Dataset): # Different inheritance
             def __init__(self, path: str):
                super().__init__() # This is the only change
            self.files = [file for file in pathlib.Path(path).glob(""*"")]

        def __getitem__(self, index):
            return Image.open(self.files[index])

        def __len__(self):
            return len(self.files)

- `map` each element to `torch.Tensor` and `cache()` everything in memory:

        images = Images(""./data"").map(torchvision.transforms.ToTensor()).cache()

- concatenate with labels (another `torchdata.Dataset` instance) and iterate over:

        for data, label in images | labels:
            # Do whatever you want with your data

# Installation 

`pip` is the easiest of course:

        pip install torchdata

You can also use `nightly` releases (`torchdata-nightly`) or GPU/CPU Docker based images (check documentation). Hopefully `conda` will be released soon as well, stay tuned

BTW. You can also checkout [__torchfunc__](https://github.com/szymonmaszke/torchfunc), I plan to make a separate post about that in a week or so.

Thanks for reading and checking out the project",8,24
210,2019-9-22,2019,9,22,0,d7c1t4,understand gradient descent,https://www.reddit.com/r/deeplearning/comments/d7c1t4/understand_gradient_descent/,data_engineer,1569080347,,0,0
211,2019-9-22,2019,9,22,4,d7ey0m,Google Colaboratory Local Runtime,https://www.reddit.com/r/deeplearning/comments/d7ey0m/google_colaboratory_local_runtime/,Gijske,1569093766,"&amp;#x200B;

[I am currently working on a school project but I'm extremely new to this stuff, I really want to use my local GPU\(RTX 2080\) when connected to a local runtime, but it is not found. When I train to train my network it is really slow and my CPU\(Ryzen 7 2700x\) spikes to 100&amp;#37;. Can anyone help me?](https://i.redd.it/2slvyu5gzzn31.png)",1,1
212,2019-9-22,2019,9,22,10,d7k064,How to reduce price of system,https://www.reddit.com/r/deeplearning/comments/d7k064/how_to_reduce_price_of_system/,Stanley_C,1569116474,"Hi, here is my planned build. [https://pcpartpicker.com/user/itisyeetimetoday/saved/#view=7PfgJx](https://pcpartpicker.com/user/itisyeetimetoday/saved/#view=7PfgJx)

What is not necessary in my build? I'm trying to reduce the price of the build to 600 dollars or 700 dollars.",7,1
213,2019-9-22,2019,9,22,20,d7p7um,Can I find a healthcare dataset like MNIST to test my models?,https://www.reddit.com/r/deeplearning/comments/d7p7um/can_i_find_a_healthcare_dataset_like_mnist_to/,KatiDev,1569151888,"Literature said: if your model works with MNIST dataset, if maybe works with any other dataset, if your model don't work work with MNIST dataset, it'll never be work with other dataset.

I want to work in healthcare field, I'm asking if there is a medical dataset for cancer (for example) which I can test my models and several frameworks?

Thanks in advance,",8,14
214,2019-9-22,2019,9,22,20,d7pe3w,Best way to run image classifier on Raspberry Pi ?,https://www.reddit.com/r/deeplearning/comments/d7pe3w/best_way_to_run_image_classifier_on_raspberry_pi/,mdcr55,1569153038,"Hello all.

I am new to deep learning and I have a project about using Raspberry Pi with USB camera that detects objects from a video stream.

So which is the way to start with.. ? 
Anyone have idea can help. 

Thanks!",4,3
215,2019-9-23,2019,9,23,1,d7sk4s,Unable to install Caffe for Windows (without CUDA) for Fast RCNN. Please help.,https://www.reddit.com/r/deeplearning/comments/d7sk4s/unable_to_install_caffe_for_windows_without_cuda/,yesteaplease,1569168835,"Hi 

Im trying to install caffe for downloading fast rcnn. Have been trying and now Im at wits end. Im here to seek help.

I cloned it from here: https://github.com/happynear/caffe-windows

Then followed the instructions here: https://youtu.be/GTL44JA0zdw

Im not getting the option to update the packages when I reach the Visual studio step and so Im not able to build the solution. 

Im using Windows 10. No GPU. 

Is there any other way to do it?

Thanks.",0,2
216,2019-9-23,2019,9,23,3,d7uqar,"Machine learning accessible to all, without programming experience",https://www.reddit.com/r/deeplearning/comments/d7uqar/machine_learning_accessible_to_all_without/,cmillionaire9,1569178362,,1,0
217,2019-9-23,2019,9,23,5,d7w1jw,"AI Weekly Update! - September 22nd, 2019",https://www.reddit.com/r/deeplearning/comments/d7w1jw/ai_weekly_update_september_22nd_2019/,HenryAILabs,1569184099,[https://youtu.be/KLrqzvmNxzc](https://youtu.be/KLrqzvmNxzc),0,8
218,2019-9-23,2019,9,23,5,d7wbas,Artificial Intelligence with Python By Prateek Joshi EPUB,https://www.reddit.com/r/deeplearning/comments/d7wbas/artificial_intelligence_with_python_by_prateek/,psychonekk,1569185332,,0,4
219,2019-9-23,2019,9,23,8,d7yn7y,Which way to proceed for distributed learning under tensorflow?,https://www.reddit.com/r/deeplearning/comments/d7yn7y/which_way_to_proceed_for_distributed_learning/,shahriar49,1569196749,"I see a bunch of different methods in many web sites and Tensorflow guides to proceed for implementing a distributed learning example but can not clear my mind on them. Let me be simple and clear: I have model created under keras, have setup the TF\_CONFIG to have a chief, a worker, a ps, and an evaluator server, and I assume that the below code should do the job:

    runConfig = tf.estimator.RunConfig(
    		session_config=config,
    		model_dir=log_dir,
    		save_summary_steps=1,
    		save_checkpoints_steps=train_steps
    		)
    estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=runConfig)
    train_spec = tf.estimator.TrainSpec(input_fn=lambda: read_datasets(...), max_steps=epochs*train_steps)
    eval_spec = tf.estimator.EvalSpec(input_fn=lambda: read_datasets(...), steps=None)
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
    

And then I can see the performance graphs and values on Tensorboard. I assume that the code for all servers are exactly the same except the TF\_CONFIG part, and just one copy of training data is needed to be placed in a shared folder, and one shared directory is set to save model parameters and checkpoints, and the chief is going to synchronize everything on splitting the data between workers and saving the model and summaries. 

There is something here that I am not clear about it: I want to evaluate the trained model on a test data, and I assume that I can just execute the below command to get the evaluated loss and accuracy in a dictionary objecT:

    eval_dic = estimator.evaluate(input_fn=lambda: read_datasets(...), steps=test_steps)

But this code is run by all services (worker, chief, and evaluator), which I don't think should be. Also the result that I get is just null.

In addition, I see pages about distribution strategy and its implications on keras and estimators, which make me so much confused. Do I really need all of these strategy stuff, or just above code is sufficient? What about the input\_fn? I assumed that the chief is taking care of data split but in the tensorflow documentation ([https://www.tensorflow.org/guide/distribute\_strategy](https://www.tensorflow.org/guide/distribute_strategy)) it says different things for keras and estimator implementation, and my application is a keras model encapsulated in an estimator! What should I do?",0,6
220,2019-9-23,2019,9,23,12,d813ry,Automated Vehicles,https://www.reddit.com/r/deeplearning/comments/d813ry/automated_vehicles/,piingpoong,1569209787,"Using C++ and ROS, what is the best deep learning engine for self driving vehicles to use?",0,0
221,2019-9-23,2019,9,23,15,d82v38,When will deep learning finally die out?,https://www.reddit.com/r/deeplearning/comments/d82v38/when_will_deep_learning_finally_die_out/,AmandoAbreu,1569221301,,16,12
222,2019-9-23,2019,9,23,16,d833cf,Training Neural Nets: a Hackers Perspective,https://www.reddit.com/r/deeplearning/comments/d833cf/training_neural_nets_a_hackers_perspective/,pirate7777777,1569222924,,0,0
223,2019-9-23,2019,9,23,16,d83awl,Data generator to handle large image datasets,https://www.reddit.com/r/deeplearning/comments/d83awl/data_generator_to_handle_large_image_datasets/,alpaca1331,1569224490,I am looking for a well documented tutorial to know how to correctly and elegantly program a data generator in order to train a neural network without loading the whole dataset in memory. The problem I have is that there are a lot of implementations around there and I'm not sure if some of them work efficiently. Thanks!,1,8
224,2019-9-23,2019,9,23,16,d83cgh,Engaging Your Customers With WhatsApp Chatbot Integration,https://www.reddit.com/r/deeplearning/comments/d83cgh/engaging_your_customers_with_whatsapp_chatbot/,Ripple2709,1569224807,,0,1
225,2019-9-23,2019,9,23,22,d8693s,DIY invoice scanning app using deep learning and OCR,https://www.reddit.com/r/deeplearning/comments/d8693s/diy_invoice_scanning_app_using_deep_learning_and/,manneshiva,1569243849,"Interesting article on smart data extraction from invoices.   
[https://nanonets.com/blog/invoice-ocr/](https://nanonets.com/blog/invoice-ocr/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=invocr&amp;utm_content=dl)

Build your own invoice scanning app or automate your business process by implementing deep learning and OCR. 

&amp;#x200B;

![gif](zbigyvo1eco31 ""invoice scanning app"")",0,0
226,2019-9-23,2019,9,23,23,d87l9s,Need help in inputting an image and a value into a CNN.,https://www.reddit.com/r/deeplearning/comments/d87l9s/need_help_in_inputting_an_image_and_a_value_into/,fatshortmonk,1569250414,I'm new in this field and I have to develop a model which takes an audio file(Noise) and its SNR(Sound to Noise Ratio) and it outputs four values(3 frequencies and a delta function). I turned the audio files into spectrograms and used them as an input to a CNN but I am not able to input the SNR into it. I am not even sure that this approach will work. Please suggest a solution or a better approach.,1,1
227,2019-9-24,2019,9,24,0,d87ooy,How would you handle a very large input text that can't all be fit into memory,https://www.reddit.com/r/deeplearning/comments/d87ooy/how_would_you_handle_a_very_large_input_text_that/,M0shka,1569250850,"I have a dataset with approximately 300k samples where each sample is a text document with about 25k words. 

I can load it all into memory, but I can't really use a GRU network since I just run into a memory error due to the number of parameters

I tried setting the max vocab length to 35000 and max sequence length to 2500 after which I could run a GRU network. I got a slightly good accuracy but I'm  losing 90% of my data.",3,8
228,2019-9-24,2019,9,24,1,d88p0h,12 Deep Learning Researchers and Leaders you should follow,https://www.reddit.com/r/deeplearning/comments/d88p0h/12_deep_learning_researchers_and_leaders_you/,f4kh3r,1569255254,,0,1
229,2019-9-24,2019,9,24,1,d89bbw,Earthquakes in the Landscape of Neural Network,https://www.reddit.com/r/deeplearning/comments/d89bbw/earthquakes_in_the_landscape_of_neural_network/,itdxer,1569257958,,1,23
230,2019-9-24,2019,9,24,2,d89c6b,Neural network from scratch queries,https://www.reddit.com/r/deeplearning/comments/d89c6b/neural_network_from_scratch_queries/,navdeepsony,1569258054,"I have created a neural network using numpy from scratch. I have performed gradient checking to see whether my backpropagation is working properly or not. I am getting exactly the same derivatives using both gradient checking and the implemented backpropagation algorithm. 

1. Does it means my both forward propagation and back propagation are correctly implemented??

I am applying the same neural network to classify cats vs dogs classification, the dataset obtained from kaggle but the problem is:

2. When my learning rate is high, my cost never decreases.

3. When learning rate is low, the cost decreases gradually but then when it nears 0.0 , I start getting negative cost or 'nan'.

Please solve my above 3 queries as I am a beginner in this field.

Thank you.",5,1
231,2019-9-24,2019,9,24,6,d8df4e,Is distributed learning feasible for my application?,https://www.reddit.com/r/deeplearning/comments/d8df4e/is_distributed_learning_feasible_for_my/,shahriar49,1569274995,"I am running a LSTM network to classify a huge database of remote sensing sequences to their respective landcovers. Code is developed on Tensorflow/Keras and I am trying models with 3 to 7 layers, each having 16 to 64 LSTM cells. Due to huge data size (around 13.5M sample sequences), I am interested to do my model training in distributed mode by data parallelization over multiple GPUs or multiple PCs.  However, my tries by now have not resulted in any improvement over single system version and I am thinking if it is feasible at all or not.

My understanding from data parallelism under Tensorflow/Keras is that there are different workers, a chief, and a parameter server (ps). Model parameters are stored in ps and communicated with workers and chief, and each worker works on a partition of the whole data. Each worker should get the model parameters from ps at the start of each data batch processing, do all the forward and backward propagation and calculate the weight updates and send them back to ps, where the updated model parameters are calculated by chief and stored. Therefore, each worker should read the model parameters before each batch processing.

My simulation batch size is 1024, therefore there are about 13K batches in one epoch of data. Training of a model with 87,000 parameters took 412 seconds in my one-gpu system, which means about 30 ms per batch. A more complex model with 1M parameters took 1900 seconds to process one epoch, which means about 146 ms per batch.

Now that I look at the numbers, I am in doubt if data parallelism is helpful. If two GPUs or CPUs want to communicate 100K or 1M parameters, can it be so fast to be done in a few milliseconds to be negligible? My experiments on a two-GPU system (which doesn't require data transmission over network) resulted in batch processing time of twice single-GPU. Can it be attributed to the small batch processing time? If it is, does it mean that my model is not as complex as necessary for distribution?",0,0
232,2019-9-24,2019,9,24,17,d8k4ed,Deeply Cheap GPU Servers for Deep Learning,https://www.reddit.com/r/deeplearning/comments/d8k4ed/deeply_cheap_gpu_servers_for_deep_learning/,toplahm,1569312703," As [Toplahm](https://www.toplahm.com/), we provide high-performance single&amp;multi GPU cloud solutions for ML/DL. We're a new and passionate company and we have a special promotion for you to experience our service.

* **GTX1080**, Intel G4600 2C:4T, 12 GB RAM, 120GB SSD **$109 /month**
* **2 x GTX1080**, Intel i5-7500 4C:4T, 32 GB RAM, 500GB SSD **$249 /month, $85 /week**

*Promotion expires on Sep 29* and *is available for only 1 server in each type (FCFS).*

*\*All servers have* **1 Gbps** connection.  **99.95% uptime**. All are **dedicated** (no virtualization), GPUs are plugged on motherboard (no risers) with 16 or 8 PCIe lanes.

\*\* Servers come with Nvidia drivers and CUDA runtime pre-installed.

\*\*\* *Nvidia driver licence poses no threat for us, neither for our customers. However, concerned customers can still opt for an Nvidia driver released before the prohibition to be absolutely safe.*

Toplahm Cloud Services [Contact](https://toplahm.com/contact.html) | [Service Terms](https://www.toplahm.com/terms-and-conditions.html) | [Security](https://www.toplahm.com/security.html) | [Knowledge Base](https://www.toplahm.com/knowledge-base.html)",2,0
233,2019-9-24,2019,9,24,18,d8korw,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/d8korw/data_science_career_track_prep_course/,HannahHumphreys,1569316898,[removed],0,1
234,2019-9-24,2019,9,24,22,d8mzj2,Recently Built Deep Learning App,https://www.reddit.com/r/deeplearning/comments/d8mzj2/recently_built_deep_learning_app/,rana_ali_raza,1569330655,"Recently Built Deep Learning Apps:  

Personality Prediction: [https://mbtip.herokuapp.com](https://t.co/GS989xvPBK?amp=1) 

Spam Email: [https://dl-spam-email.herokuapp.com](https://t.co/xcoutKSLNJ?amp=1) 

Spam SMS: [https://dl-spam-sms.herokuapp.com](https://t.co/xXTLSZLcZb?amp=1) 

Luxembourg Pollen in Air: [http://pollen-in-air.herokuapp.com](https://t.co/s7ujLPGAkH?amp=1)

Please share your feedback and some new ideas",0,1
235,2019-9-25,2019,9,25,1,d8poba,Which one is the better model?,https://www.reddit.com/r/deeplearning/comments/d8poba/which_one_is_the_better_model/,navdeepsony,1569342883,"Suppose we are able to train the neural network in 2 ways (where both ways are able to reduce the cost).

 First way is using 55 neurons in the hidden layer and 40000 iterations and the second way is using 1500 neurons with lesser number of iterations. Now which one is a better way to train the model?",6,0
236,2019-9-25,2019,9,25,4,d8rwnj,"I just ran my first Keras model on Google Colab. And it maxed out the 25GB of RAM that I was given. The same happened when I ran it before that on Kaggle, it maxed it out the 14GB of RAM. I don't know what's going on.",https://www.reddit.com/r/deeplearning/comments/d8rwnj/i_just_ran_my_first_keras_model_on_google_colab/,Fallen-Zero,1569352553,"So I building the keras sequential model and adding dense layers. 1000 nodes, 500 nodes, 100 nodes, and 5 nodes as outputs, without dropout layers for regularisation. But as I run this part of the code, the RAM gets maxed out and the session crashes and I have to start all over again. I don't what's happening, I searched online and I couldn't find anything. I hope you can help me. Thanks in advance.",10,2
237,2019-9-25,2019,9,25,5,d8sx8g,Introduction to Reinforcement Learning - Chapter 1 Explained!,https://www.reddit.com/r/deeplearning/comments/d8sx8g/introduction_to_reinforcement_learning_chapter_1/,HenryAILabs,1569356886,[https://youtu.be/4SLGEq\_HZxk](https://youtu.be/4SLGEq_HZxk),14,50
238,2019-9-25,2019,9,25,9,d8vxfr,CRACK YOUR NLP INTERVIEW IN FIRST ATTEMPT,https://www.reddit.com/r/deeplearning/comments/d8vxfr/crack_your_nlp_interview_in_first_attempt/,adityaojha0705,1569371493,"From Zero to Hero in all NLP interview. Ace your next Data Science interview by mastering Natural Language Processing
Get the right set of practice questions which are mostly focused on concepts.

https://www.udemy.com/course/natural-language-processing-nlp-interview-test-series/",0,0
239,2019-9-25,2019,9,25,13,d8ykix,Pretrained models for people detection?,https://www.reddit.com/r/deeplearning/comments/d8ykix/pretrained_models_for_people_detection/,Sebasuraa,1569387225,"  

I have to test different people detection models on a dataset and  count the number of errors and stuff, in order to pick the most accurate  one. I'm thinking of using DarkNet (YOLO), Tensorflow's model and  Pytorch's model, but I need like 2 more, and I don't know if the ones I  mentioned are good enough, so any help in recommending pretrained models  is appreciated.

Thanks!",0,0
240,2019-9-25,2019,9,25,17,d9075w,"""What Is Deep Learning and what It Can Do For You?"" with Diogo Moitinho de Almeida",https://www.reddit.com/r/deeplearning/comments/d9075w/what_is_deep_learning_and_what_it_can_do_for_you/,goto-con,1569398571,,1,0
241,2019-9-25,2019,9,25,17,d909p7,Conversational AI: The Advanced Form of Chatbots,https://www.reddit.com/r/deeplearning/comments/d909p7/conversational_ai_the_advanced_form_of_chatbots/,tech_rebel,1569399099,,0,4
242,2019-9-25,2019,9,25,17,d90baf,Best apporaches to automate invoice data entry using deep learning and OCR,https://www.reddit.com/r/deeplearning/comments/d90baf/best_apporaches_to_automate_invoice_data_entry/,manneshiva,1569399450,"Data extraction via OCR is a challenging problem, this article explains how this process works on invoices and can be a good source for building custom OCR models. [https://nanonets.com/blog/invoice-ocr/](https://nanonets.com/blog/invoice-ocr/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=invocr&amp;utm_content=dl)

Build your own invoice scanning app or automate your business process by implementing deep learning and OCR. 

[invoice ocr ](https://i.redd.it/1qhj61a67po31.gif)",1,4
243,2019-9-26,2019,9,26,1,d95rpk,help with implementing custom loss on the integral of outputs (keras),https://www.reddit.com/r/deeplearning/comments/d95rpk/help_with_implementing_custom_loss_on_the/,progmayo,1569429189,"Hi guys! I'd really appreciate help in a problem I ran into.

**The goal**

I want to implement a custom loss in keras which is an integral on the outputs.Using the notations of keras, custom loss functions are of the form

    def custom_loss(y_true, y_pred):

Where y\_true are the labels and y\_pred are the models' predictions. I also have the inputs X at hand (using a wrapper function around the custom\_loss). This input is of the same shape as the labels / predictions.Using these notations, the loss I wish to impose looks something along the lines of:

&amp;#x200B;

https://i.redd.it/n21u38cpnro31.png

Where f(x) is some function that's irrelevant to this discussion. Note that y\_true are irrelevant to the loss function (and that's ok. I have multiple loss functions, don't worry ;) )

Now x and y\_pred are simply arrays of 1XL for some length L.

For those familiar with scipy.integrate, this integral very easily calculated using the trapz function:

    trapz(y_pred*f(X), X)

&amp;#x200B;

**The problem /technical difficulty**

I'll describe the attempts I've made thus far, and the errors I faced in their implementation:

1. Used tensorflow.py\_function to wrap scipy.integrate.trapzThis returned an error where keras did not know how to calculate the derivative. I'm guessing keras precompiles derivative functions to use in the SGD optimizer?
2. Copied a function I found that implements trapz using keras / tf functions:

&amp;#x200B;

    def trapezoidal_integral_approx(t, y):
        return math_ops.reduce_sum(
                math_ops.multiply(t[1:] - t[:-1],
                                  (y[1:] + y[:-1]) / 2.), 
                name='trapezoidal_integral_approx')

This returned some weird error that I didn't understand:

&gt;tensorflow.python.framework.errors\_impl.InvalidArgumentError: Can not squeeze dim\[0\], expected a dimension of 1, got 1401  
&gt;  
&gt;\[\[{{node loss\_3/encoder\_output\_loss/weighted\_loss/Squeeze}}\]\]

&amp;#x200B;

3. Using tf.contrib.integrate.odeint: [https://www.tensorflow.org/api\_docs/python/tf/contrib/integrate/odeint](https://www.tensorflow.org/api_docs/python/tf/contrib/integrate/odeint)This function just seems unintuitive and not suited for my needs (not trapz). I did not fully try to implement this method, and if someone suggests it, I can give it a try, but it does not accept two arrays as I need it to.

&amp;#x200B;

**Bottom line**

I'd appreciate help in my particular problem,  or a link to some code / example that attempts something similar (loss function that is comprised of an integral on y\_true or y\_pred or something along those lines).

&amp;#x200B;

# Thank you very very much in advance to anyone willing to help :)",1,2
244,2019-9-26,2019,9,26,1,d9609n,A Simple Introduction to Deep Learning - Recognizing Handwritten Digits,https://www.reddit.com/r/deeplearning/comments/d9609n/a_simple_introduction_to_deep_learning/,SwiftMonster,1569430188,,0,1
245,2019-9-26,2019,9,26,1,d961tz,CS 236: Deep Generative Models,https://www.reddit.com/r/deeplearning/comments/d961tz/cs_236_deep_generative_models/,aiforworld2,1569430373,"Lecture Notes Fall 2019-2020


#AI #artificialintelligence #deeplearning #generativemodels
#GANs 

https://deepgenerativemodels.github.io/",3,32
246,2019-9-26,2019,9,26,2,d96it5,Can graphic cards with the same amount of memory fit the same model?,https://www.reddit.com/r/deeplearning/comments/d96it5/can_graphic_cards_with_the_same_amount_of_memory/,klanecek,1569432411,"I'm doing some fine-tuning with tensorflow on a really large model. The model only fits on a 24GB GPU, a Tesla P40 that I am renting at Azure.

Since renting is getting expensive, I'm looking at buying a GPU instead, and I found that the Nvidia Titan RTX, also has 24GB of memory at half the price (5000 vs 2500).

Will the model definitely also fit on the RTX or is it impossible to tell?",8,1
247,2019-9-26,2019,9,26,5,d98v3i,$600 paid study--deep learning engineers wanted! (Not spam),https://www.reddit.com/r/deeplearning/comments/d98v3i/600_paid_studydeep_learning_engineers_wanted_not/,gabbyuegroup,1569442360,"Hi! I work for a UX group in San Jose, CA (https://www.uegroup.com/) and we are working with a client to do research on new deep learning tools. We are looking for deep learning professionals with 2+ years experience (out of school) and medium to high proficiency in C++ and Python. The study is *in person* in San Jose, CA in the next few weeks and you will be compensated $600 for your time.",4,6
248,2019-9-26,2019,9,26,5,d99gdw,Introduction to Reinforcement Learning - Chapter 2 Explained!,https://www.reddit.com/r/deeplearning/comments/d99gdw/introduction_to_reinforcement_learning_chapter_2/,HenryAILabs,1569444906,"[https://youtu.be/9LhNHK1ULxs](https://youtu.be/9LhNHK1ULxs)

I am extremely grateful for the encouragement from the Deep Learning reddit community! I really hope you find these videos useful!",0,1
249,2019-9-26,2019,9,26,14,d9f2t7,A Roundup Review of the Best Deep Learning Books,https://www.reddit.com/r/deeplearning/comments/d9f2t7/a_roundup_review_of_the_best_deep_learning_books/,marylai22,1569474438,,7,39
250,2019-9-26,2019,9,26,14,d9f9ie,Getting started with Deep Learning,https://www.reddit.com/r/deeplearning/comments/d9f9ie/getting_started_with_deep_learning/,codegram,1569475640,,0,0
251,2019-9-26,2019,9,26,16,d9g9is,Suggestion for a compiled language for deep learning,https://www.reddit.com/r/deeplearning/comments/d9g9is/suggestion_for_a_compiled_language_for_deep/,arkrde,1569482578,"Hi all,

Of late I have been trying various deep-learning models for Kaggle competitions. I primarily use PyTorch with Numpy,  Pandas and Scikit-learn for data-munging and building pipelines. The problem that I often run into during training is some syntactical / semantic mistake which, after rectification, requires restarting of the entire training scheme. As the training process is quite time-consuming, this further compounds the problem. I believe this wouldn't have happened in a compiled language e.g. C++ where these errors would have been caught during the compilation phase itself.

Personally, I have been a huge fan of python as a language, and have favored PyTorch over other deep-learning frameworks / libraries because I feel PyTorch is more 'pythonic'. However, for my current purposes, as the code volume increases, I feel increasing difficulty in avoiding the mistakes as I have mentioned above.

However, with compiled langues e.g. C++, I am not sure if there is adequate support for data pre-processing apart from that from various deep learning frameworks / libraries.

I welcome any suggestions in this regard, or any tips / tools in how to avoid them.",3,3
252,2019-9-26,2019,9,26,16,d9gc5z,Automating Water Management Systems Using AI,https://www.reddit.com/r/deeplearning/comments/d9gc5z/automating_water_management_systems_using_ai/,tech_rebel,1569483137,,0,1
253,2019-9-26,2019,9,26,17,d9grl0,How to Improve Search Relevance  5 Types of Search Evaluation,https://www.reddit.com/r/deeplearning/comments/d9grl0/how_to_improve_search_relevance_5_types_of_search/,LimarcAmbalina,1569486497,,0,1
254,2019-9-26,2019,9,26,20,d9ih5m,How to Make CRM Operations Smart With Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/d9ih5m/how_to_make_crm_operations_smart_with_artificial/,tech_rebel,1569498267,,0,1
255,2019-9-26,2019,9,26,22,d9jol6,Feature vector in Artificial Neural Network,https://www.reddit.com/r/deeplearning/comments/d9jol6/feature_vector_in_artificial_neural_network/,jishnu_jj,1569504680,"So I'm implementing a simple ANN where I have a massive input data set. The input data contains all kinds of stuffs like eg: **categorical values**: button,table, image...; **binary values**: true-false...; **continuous variables**: length, width...; **tuple values**: rgb(1,0,0),...; **text values**: file name, absolute location... 

&amp;#x200B;

So my question is how do I take care of this different types of input data, like for

binary values- we can directly encode it to o-1, 

categorical use 1hot encoder to encode to 0-1 matrix. 

But how do I take care of continuous variables, tuple values and texts ??

&amp;#x200B;

And can I parse the date to one single Neural network?",0,1
256,2019-9-26,2019,9,26,23,d9kn07,How do I emulate a book narraters voice using deep learning?,https://www.reddit.com/r/deeplearning/comments/d9kn07/how_do_i_emulate_a_book_narraters_voice_using/,newplayer12345,1569509263,"I have a project in mind but I have little to no idea on how to proceed.

I basically have about 100 hours of some audio books as well as the text in those books.

So my plan is to train a deep network which is able to read a given text in that narraters voice. 

I know that RNNs will be helpful. Not much else apart from that. Could you give me some direction as to how to proceed? Any particular research papers I should look at?

Note that I'm not looking to just read the text in any voice. I'm interested in that particular narrator's voice. And I think a network trained on the voice of a narrator should be able to read given text in the narrator's voice.

Help much appreciated!!",9,18
257,2019-9-27,2019,9,27,5,d9pulj,Technopremium,https://www.reddit.com/r/deeplearning/comments/d9pulj/technopremium/,cibergirl11,1569531579,,0,0
258,2019-9-27,2019,9,27,6,d9pwlw,DL BENCHMARK- go to TECHNOPREMIUM.com for more,https://www.reddit.com/r/deeplearning/comments/d9pwlw/dl_benchmark_go_to_technopremiumcom_for_more/,cibergirl11,1569531821,,0,0
259,2019-9-27,2019,9,27,10,d9tez5,chatbot to help navigate through website,https://www.reddit.com/r/deeplearning/comments/d9tez5/chatbot_to_help_navigate_through_website/,royfeng123,1569548033,"Hi guys, I am planning on building a chatbot/virtual assistant for my website. Basically, what it does is to process the text sent from customers and help them navigate through my website. A good example would be uscis ([https://www.uscis.gov/](https://www.uscis.gov/)). If you click on ""Ask Emma"" on top of the page and ask questions such as ""How to apply for VISA"". It will give you options of what kind of visa you can apply with hyperlink within their website. Of course, that would be my ultimate goal. Right now, I am trying to get to a starting point where I can find some papers or blogs or any resources to answer some basic questions such as: what kind of data I will need to collect, what models would be recommended, is there any tutorial or sample project that I can follow through, etc. Any help would be appreciated. Thank you very much!",1,6
260,2019-9-27,2019,9,27,15,d9wks8,"which are the best tutorial book , website, video for learning python with project / example ?",https://www.reddit.com/r/deeplearning/comments/d9wks8/which_are_the_best_tutorial_book_website_video/,Doctor_who1,1569566789,"which are the best tutorial book , website, video for learning python with project / example ?",2,1
261,2019-9-27,2019,9,27,16,d9x19f,Encoder-decoder model,https://www.reddit.com/r/deeplearning/comments/d9x19f/encoderdecoder_model/,fibonacci_bokertov,1569569992,"Im a freshman in RNN. I want to create a encoder-decoder architecture. As far as i understand this architecture include two RNN with two different weights' matrixes. But i don't figure out how this model will be able to do backpropagation. I'm using Pytorch framework for this purpose. So, if we have two nets, Pytorch 'understand' it and gradient will flow from decoder into decoder?",12,14
262,2019-9-27,2019,9,27,18,d9y089,Deep Learning vs Neural Networks | Difference of DL &amp; NN,https://www.reddit.com/r/deeplearning/comments/d9y089/deep_learning_vs_neural_networks_difference_of_dl/,krishnateja12,1569577202,,2,0
263,2019-9-27,2019,9,27,22,da07vz,Medical Image Classification,https://www.reddit.com/r/deeplearning/comments/da07vz/medical_image_classification/,moizsawan,1569589970,"Hi all. I am working on a medical image based binary classification. So far, I have tried every pre-trained model and have even tried to train some models from scratch. But still I am not getting good results. I have only two features for the patient other than the image. Images are cell images. I have even tried to incorporate non-image data with the image data but still no results. I have also tried handcrafted features for the images but to no use. The issue is that even visually I can not differentiate between the two classes. Any comments on what other methods or approaches I could follow to get a better result? Currently, I am having a \~60% accuracy but I need to get it past 70% at least.",4,2
264,2019-9-28,2019,9,28,1,da2p37,Number of iterations required to reduce cost,https://www.reddit.com/r/deeplearning/comments/da2p37/number_of_iterations_required_to_reduce_cost/,navdeepsony,1569601079,"I am training a neural network and after each iteration cost is reducing. The more the number of iterations we use, the more is the cost reduced. Do we need to take cost very near to 0 or some higher value is also ok. Please guide me when do we need to stop training the model in terms of cost?",3,2
265,2019-9-28,2019,9,28,2,da3pcc,Can #AI be CREATIVE?,https://www.reddit.com/r/deeplearning/comments/da3pcc/can_ai_be_creative/,cmillionaire9,1569605511,,1,0
266,2019-9-28,2019,9,28,3,da482u,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/da482u/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1569607845,[removed],0,1
267,2019-9-28,2019,9,28,4,da5m3v,Object detection based obstacle avoidance,https://www.reddit.com/r/deeplearning/comments/da5m3v/object_detection_based_obstacle_avoidance/,fiorano10,1569614098,"Hey guys, I have a small robot with a stereo camera mounted in the front. The horizontal FOV is ~90. Im running a yolov2 detection model, the detections are used extract the distance to objects and their size. Their positions are then sent to a Constant velocity Kalman tracker. Im not getting good enough tracking results, it needs to work with momentary occlusions. 
Are there any ML based approaches that would be useful?",5,6
268,2019-9-28,2019,9,28,5,da6fi5,Guys I'm trying to create a video colorization based on cnn and inception-resnet-v2. But due to the complexity I couldn't train the model properly any suggestions?,https://www.reddit.com/r/deeplearning/comments/da6fi5/guys_im_trying_to_create_a_video_colorization/,TopCoder1729,1569617756,,3,4
269,2019-9-28,2019,9,28,12,dab4k7,Where are all the Visual Question Answering models? (Whats the best one youve seen?),https://www.reddit.com/r/deeplearning/comments/dab4k7/where_are_all_the_visual_question_answering/,Foolprof,1569642867,"VQA models seem to have lots of applications but Im not seeing them much in daily life (compared to classification or detection models). Surprising as theyve been around for around half of the decade.

Im  planning on implementing a test model to learn and was wondering: whats the best one youve encountered in research or elsewhere? Do you expect them to work well/poorly for certain domains of Q&amp;A?",0,2
270,2019-9-28,2019,9,28,13,dab6o1,Can deep CNN network be deploy locally on weak pc?,https://www.reddit.com/r/deeplearning/comments/dab6o1/can_deep_cnn_network_be_deploy_locally_on_weak_pc/,-GIA,1569643252,"As title said, can a deep model (VGG16 for example) be deployed on an Intel Pentium 4gb ram machine to predict images?",5,5
271,2019-9-28,2019,9,28,17,dadkpt,Deployment.,https://www.reddit.com/r/deeplearning/comments/dadkpt/deployment/,lakshaytalkstocomput,1569660695,"How to deploy deep lesrning models on edge? If i want to sell a device how to i implement my deep lesrning model on device so that people cannot take my model? Any readings , tips ?",9,4
272,2019-9-28,2019,9,28,19,daei2a,(ODSC India 2020 CFP) Got Deep Learning expertise to share with the Data Science and AI community in India?,https://www.reddit.com/r/deeplearning/comments/daei2a/odsc_india_2020_cfp_got_deep_learning_expertise/,yourdigitalvoice,1569667810,"ODSC India is looking for speakers for the 2020 conference in Bengaluru, India. If you've got an innovative application or cutting edge insights into Deep Learning, you should check it out. It's a great way to engage with the community and share your knowledge! Proposal submissions close on October 9. [https://confng.in/ySfDg6gX](https://confng.in/ySfDg6gX)

Conference Focus Areas:

* AI for Engineers
* Open Data Science
* Data Visualization
* Machine Learning &amp; Deep Learning
* Data Science at Scale
* Data Science Kick Start
* Math Behind AI
* Data Management
* DataOps

Conference dates: 16-19 September, 2020",0,8
273,2019-9-28,2019,9,28,19,daej39,"[Project] torchfunc: PyTorch functions to improve performance, analyse and make your deep learning life easier.",https://www.reddit.com/r/deeplearning/comments/daej39/project_torchfunc_pytorch_functions_to_improve/,szymonmaszke,1569668033,"Hi again,

Encouraged by warm welcoming of my previous project last week ([torchdata](https://github.com/szymonmaszke/torchdata), thanks a lot) I'd like to share another PyTorch related project some of you might find helpful and interesting. [Here](https://github.com/szymonmaszke/torchfunc) is GitHub repository and [here](https://szymonmaszke.github.io/torchfunc/) is documentation.

Also, if you have any suggestions/improvements/questions I will be glad to help.

Now, description (taken from project's readme with minor adjustments):

# What is it?

[**torchfunc**](https://szymonmaszke.github.io/torchfunc/) is library revolving around [PyTorch](https://pytorch.org/) with a goal to help you with:


* Improving and analysing performance of your neural network (e.g. Tensor Cores compatibility)
* Record/analyse internal state of `torch.nn.Module` as data passes through it
* Do the above based on external conditions (using single `Callable` to specify it)
* Day-to-day neural network related duties (model size, seeding, performance measurements etc.)
* Get information about your host operating system, CUDA devices and others

# Quick examples

### Get instant performance tips about your module. All problems described by comments will be shown by `torchfunc.performance.tips`:

    class Model(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.convolution = torch.nn.Sequential(
                torch.nn.Conv2d(1, 32, 3),
                torch.nn.ReLU(inplace=True),  # Inplace may harm kernel fusion
                torch.nn.Conv2d(32, 128, 3, groups=32),  # Depthwise is slower in PyTorch
                torch.nn.ReLU(inplace=True),  # Same as before
                torch.nn.Conv2d(128, 250, 3),  # Wrong output size for TensorCores
            )

            self.classifier = torch.nn.Sequential(
                torch.nn.Linear(250, 64),  # Wrong input size for TensorCores
                torch.nn.ReLU(),  # Fine, no info about this layer
                torch.nn.Linear(64, 10),  # Wrong output size for TensorCores
            )

        def forward(self, inputs):
            convolved = torch.nn.AdaptiveAvgPool2d(1)(self.convolution(inputs)).flatten()
            return self.classifier(convolved)

    # All you have to do
    print(torchfunc.performance.tips(Model()))

### Seed globaly (including `numpy` and `cuda`), freeze weights, check inference time and model size:

    # Inb4 MNIST, you can use any module with those functions
    model = torch.nn.Linear(784, 10)
    torchfunc.seed(0)
    frozen = torchfunc.module.freeze(model, bias=False)

    with torchfunc.Timer() as timer:
      frozen(torch.randn(32, 784)
      print(timer.checkpoint()) # Time since the beginning
      frozen(torch.randn(128, 784)
      print(timer.checkpoint()) # Since last checkpoint
      
    print(f""Overall time {timer}; Model size: {torchfunc.sizeof(frozen)}"")


### Record and sum per-layer and per-neuron activation statistics as data passes through network:

    # Still MNIST but any module can be put in it's place
    model = torch.nn.Sequential(
        torch.nn.Linear(784, 100),
        torch.nn.ReLU(),
        torch.nn.Linear(100, 50),
        torch.nn.ReLU(),
        torch.nn.Linear(50, 10),
    )
    # Recorder which sums all inputs to layers
    recorder = torchfunc.hooks.recorders.ForwardPre(reduction=lambda x, y: x+y)
    # Record only for torch.nn.Linear
    recorder.children(model, types=(torch.nn.Linear,))
    # Train your network normally (or pass data through it)
    ...
    # Activations of all neurons of first layer! 
    print(recorder[1]) # You can also post-process this data easily with apply

# Installation

## [pip](&lt;https://pypi.org/project/torchfunc/&gt;)

### Latest release:

```
pip install --user torchfunc
```

### Nightly:

```
pip install --user torchfunc-nightly
```

### One could also check the project out with Docker, see more info in README as this post is getting long I guess",0,7
274,2019-9-29,2019,9,29,5,dalj8r,The best story teller,https://www.reddit.com/r/deeplearning/comments/dalj8r/the_best_story_teller/,Mahgozar,1569703120,"This is just kind of a random thought but recently I watched the whole avengers series again and I noticed an interesting pattern here among the stories I have heard before and their story. I cannot pin point them exactly but it seems there is an actual pattern that can make a story great
Then I started thinking about regenerative models and thought mabe the patterns can be extracted !!! 
Just a random thought ",0,0
275,2019-9-29,2019,9,29,7,damoy9,"Preprocessing with Scikit Learn, Normalization",https://www.reddit.com/r/deeplearning/comments/damoy9/preprocessing_with_scikit_learn_normalization/,cibergirl11,1569708950,,0,5
276,2019-9-29,2019,9,29,11,dap88w,I've been working on using AI to make music and videos and whatnot. Anyone else into this sort of thing?,https://www.reddit.com/r/deeplearning/comments/dap88w/ive_been_working_on_using_ai_to_make_music_and/,poingly,1569722890,,33,46
277,2019-9-29,2019,9,29,15,darh5g,Own system or cloud gpu,https://www.reddit.com/r/deeplearning/comments/darh5g/own_system_or_cloud_gpu/,navdeepsony,1569737429,"Hi friends. I have a system with 1080 gpu,16 gb ram and 250 gb ssd. I tried to use google colab but then i found that my system is faster than google colab as they use k80 gpu which is slower than mine. What cloud service according to you should i use which is faster than my own system to get my results qucickly. Thanks.",0,0
278,2019-9-29,2019,9,29,15,darlow,Newbie using pytorch,https://www.reddit.com/r/deeplearning/comments/darlow/newbie_using_pytorch/,Weap0n_X,1569738365,"Hello everybody! I am a computer science student and I am writing you all since I would need some advice about pytorch. I have never used it before and I need to learn how to use it for my thesis work, which is about digital image processing with deep learning neural networks. Thus, I would need to ask you if there is a book/site/YouTube channel that has some good tutorials about it or even a source with already done projects with similar tasks so that I can learn by analizing their code.",2,0
279,2019-9-29,2019,9,29,17,dasc0b,Improved Hypergradient based optimizers,https://www.reddit.com/r/deeplearning/comments/dasc0b/improved_hypergradient_based_optimizers/,harshalmittal4,1569744043,"This work tries improvements to the existing 'Hypergradient' based optimizers proposed in the paper [Online Learning Rate Adaptation with Hypergradient Descent](https://arxiv.org/pdf/1703.04782.pdf).

We expect that the hypergradient based learning rate update could be more accurate and aim to exploit the gains much better by boosting the learning rate updates with momentum and adaptive gradients, experimenting with

1. Hypergradient descent with momentum, and
2. Adam with Hypergradient,

alongside the model optimizers SGD, SGD with Nesterov(SGDN) and Adam.

The new optimizers are compared with their resepective hypergradient-descent baselines and provide advantages such as better generalization and faster convergence for the loss function. The code and the results of our experiments are available at [https://github.com/harshalmittal4/Hypergradient\_variants](https://github.com/harshalmittal4/Hypergradient_variants).",0,3
280,2019-9-29,2019,9,29,18,dasyij,Construction images,https://www.reddit.com/r/deeplearning/comments/dasyij/construction_images/,NotThatBright123,1569748998,"Hi! Can anyone recommend me places to find images for construction sites? I need to look for concrete structure images such as ""concrete pillars"" and ""concrete stairs"" etc. I tried using image net(can't find it there) and downloading from Google directly. I only have ard 60 decent images for each class atm. I am looking towards 100 to 200 images. Any help would be appreciated. Thank you!!",2,3
281,2019-9-30,2019,9,30,13,db6d52,Yann LeCun made an appearance in my dream [disclaimer: uninteresting af],https://www.reddit.com/r/deeplearning/comments/db6d52/yann_lecun_made_an_appearance_in_my_dream/,Zuckergeist,1569817419,"I'd been watching some of Yann LeCun's talks. After I was fully saturated with Yann LeCun content, I decided to take a nap. What I thought was a timely, much needed nap turned out to be absurd and oddly disturbing. The dream was basically just a whispering low-pitched Yann LeCun caricature saying ""one more convolution, one more convolution, show me one more convolution"" in an extremely calm, terrifying voice. I woke up not being able to solve the mystery of that extra convolution. Just felt I should share this with someone, but didn't know who to tell. And here I am.",6,8
282,2019-9-30,2019,9,30,15,db7a4c,[Need Advice] Should I go for Nvidia GTX 1650 for performing ML/DL?,https://www.reddit.com/r/deeplearning/comments/db7a4c/need_advice_should_i_go_for_nvidia_gtx_1650_for/,BTredBT,1569823240,"I am looking to buy a laptop and came across Lenovo Y540 which has Nividia's GTX 1650, but couldn't find it listed on their website. Should I go fir this one? Also, would it be worth buying a high-end laptop/GPU considering there are cloud services such as Google Colab out there? I'm new to this field and would use it for research projects/Kaggle competitions.",16,3
283,2019-9-30,2019,9,30,15,db7jkw,RNN without a specific input at a time?,https://www.reddit.com/r/deeplearning/comments/db7jkw/rnn_without_a_specific_input_at_a_time/,amitgoren,1569825069,,0,3
284,2019-9-30,2019,9,30,16,db7y66,Model Deployment on Edge.,https://www.reddit.com/r/deeplearning/comments/db7y66/model_deployment_on_edge/,lakshaytalkstocomput,1569827885,"I know i am asking  this again but i think this would be better way to do it! 
""How to deploy models on edge without letting your customers know model parameters?""",4,8
285,2019-9-30,2019,9,30,18,db904w,Deep Learning with Python,https://www.reddit.com/r/deeplearning/comments/db904w/deep_learning_with_python/,krishnateja12,1569835866,,0,1
286,2019-9-30,2019,9,30,19,db9ce5,Top 7 TED Talks about Machine Learning,https://www.reddit.com/r/deeplearning/comments/db9ce5/top_7_ted_talks_about_machine_learning/,RubiksCodeNMZ,1569838093,,0,0
287,2019-9-30,2019,9,30,23,dbc7hu,Deep Learning - APIs,https://www.reddit.com/r/deeplearning/comments/dbc7hu/deep_learning_apis/,GrassberryHigh,1569853054,"There are a lot of cool projects out there which are open source or on the tensorflow hub. I think for most people it's much effort to get them running (installing libraries or even understand tensorflow). **I thought about spinning up a more low-level API hub.** So not wondering if you need python 2 or 3, or downloading Gigabytes of models on your harddrive.

To make an example, e.g., I want to make a cool video I could use a GAN to create images and then use another GAN to apply a style to them, and maybe a third AI to morph between the images to create video frames. The basic concept is something like Zapier for machine learning. 

&amp;#x200B;

https://i.redd.it/559qlzo0lqp31.png

1st) If anybody is interested, reply, or PM me. I'm looking for useful models which can be ""apified"" or people who are struggling in using existing models and who would like to try it out. If you want to earn something on your model that could be achieved with API-rates but I intend to keep al APIs free for personal/non-commercial use.

2nd) I'm myself very new to ML, so I'm wondering how doable this is. E.g., models expect input shapes, I mean most of the work is preparing the dataset, but this is still something the user might be capable of doing on his own.

3rd) I'm grateful for any great models which exist out there. I found some here: [https://github.com/tensorflow/models](https://github.com/tensorflow/models) and on the hub [https://www.tensorflow.org/hub](https://www.tensorflow.org/hub) and these (more general ones): [https://github.com/rasbt/deeplearning-models](https://github.com/rasbt/deeplearning-models)",0,0
0,2019-10-1,2019,10,1,14,dboh2h,Tensorflow 2.0,https://www.reddit.com/r/deeplearning/comments/dboh2h/tensorflow_20/,dhanno65,1569906492,,0,1
1,2019-10-1,2019,10,1,15,dbpf0e,Sequence to Sequence Learning with Neural Networks : Paper Overview,https://www.reddit.com/r/deeplearning/comments/dbpf0e/sequence_to_sequence_learning_with_neural/,i_amujjawal,1569912407,,0,2
2,2019-10-1,2019,10,1,16,dbprap,Wake word detection model using GRU vs LSTM,https://www.reddit.com/r/deeplearning/comments/dbprap/wake_word_detection_model_using_gru_vs_lstm/,raikarsagar,1569914626,Which model architecture is preferable for wake word detection on an embedded platform (prefereably RNN based)? Any suggestions in this regard would be helpful,1,3
3,2019-10-1,2019,10,1,18,dbqu2b,No Code Deep Learning Software,https://www.reddit.com/r/deeplearning/comments/dbqu2b/no_code_deep_learning_software/,MistaSurr,1569922135,"I'm a newbie and looking into using deep learning for some projects, and I am very interested in transfer learning.

I understand that the results may not be the best, but as I am not a maths or coding guru, I like the idea of taking an existing algorithm and retraining it.

To the end, I have been looking for a tool that allows me to upload my own data set and just hit run with minimum configuration, preferably in as a GUI application not through an IDE or command prompt.

I have had a look at Ludwig already, but although it claims to need 'no code' from the reviews and tutorials I have seen that isn't true.

Any recommended tools?",18,1
4,2019-10-1,2019,10,1,22,dbt2zn,Mrcnn,https://www.reddit.com/r/deeplearning/comments/dbt2zn/mrcnn/,raghu_1809,1569935024,Can anybody help me out with mrcnn and how to input to that model ? I'm working on hair segmentation from a face. Thanks in advance.,8,1
5,2019-10-2,2019,10,2,0,dbuvry,Tensorflow 2.0 is out!,https://www.reddit.com/r/deeplearning/comments/dbuvry/tensorflow_20_is_out/,alejandrohall,1569943159,,0,41
6,2019-10-2,2019,10,2,2,dbwvq5,Deep network design principles,https://www.reddit.com/r/deeplearning/comments/dbwvq5/deep_network_design_principles/,sami_abobala,1569951911,"when we build deep learning model(CNN, LSTM, autoencoder..) how to determine the number of layers, number of units in each layer and sometimes the connection between it? The structure of the models in we see in academic papers cannot be purely experimental !!!",0,1
7,2019-10-2,2019,10,2,6,dc0jwc,Which of these Undergrad Courses will be most useful for getting into Graduate Research (PhD)?,https://www.reddit.com/r/deeplearning/comments/dc0jwc/which_of_these_undergrad_courses_will_be_most/,Allentownyeera,1569966924,"I am currently an undergraduate studying math and computer science, and I am interested in getting into graduate school for deep learning research. I am trying to plan out my coursework for the next couple years and would greatly appreciate some help in deciding which courses will add the most value to my skillset (... or will be valued by an admissions committee) 

&amp;#x200B;

I am currently considering: 

&amp;#x200B;

**Math** 

Multivariable Calc II (Just a second semester of Multivariable Calc)

Probability II 

Stochastic Processes (Taken after Probability II)

Statistics II 

Linear Algebra II

Real Analysis

Functional Analysis

Complex Analysis

&amp;#x200B;

**Computer Science**

Numerical Methods

Genetic Algorithms

Theory of Computation 

Natural Language Processing

&amp;#x200B;

&amp;#x200B;

I have already taken Probability I, Linear Algebra I, Multivariable Calc I, Frequentist Statistics, Bayesian Statistics, Ordinary Differential Equations, Discrete Math, Data Mining &amp; Warehousing, Data Structures, and Algorithms. I feel like I have my bases covered, but have read that grad schools value Analysis very highly as a sign of mathematical maturity.",5,1
8,2019-10-2,2019,10,2,11,dc4bwn,Speech Recognition - how to split a sentence into words?,https://www.reddit.com/r/deeplearning/comments/dc4bwn/speech_recognition_how_to_split_a_sentence_into/,mutatedmonkeygenes,1569984713,"Hey there, I'm new to Speech Recognition, and I'm looking for an approach to split a sentence (or multiple sentences) in the form of audio/wav files, into individual words? This sounds like a standard problem, so I'm wondering how people in the industry approach it. Thanks!",0,2
9,2019-10-2,2019,10,2,13,dc5mzn,Deep Learning with Keras  Part 7: Recurrent Neural Networks (7 Series included..),https://www.reddit.com/r/deeplearning/comments/dc5mzn/deep_learning_with_keras_part_7_recurrent_neural/,ai-lover,1569992290,"1. [Deep Learning with Keras Tutorial  Part 1](https://www.marktechpost.com/2019/06/11/deep-learning-with-keras-tutorial-part-1/)

2. [Data Pre-processing for Deep Learning models (Deep Learning with Keras ...Part 2](https://www.marktechpost.com/2019/06/14/data-pre-processing-for-deep-learning-models-deep-learning-with-keras-part-2/)

3. [Regression with Keras (Deep Learning with Keras  Part 3)](https://www.marktechpost.com/2019/06/17/regression-with-keras-deep-learning-with-keras-part-3/)

4. [Deep Learning with Keras  Part 4: Classification](https://www.marktechpost.com/2019/06/24/deep-learning-with-keras-part-4-classification/)

5. [Deep Learning with Keras  Part 5: Convolutional Neural Networks](https://www.marktechpost.com/2019/07/04/deep-learning-with-keras-part-5-convolutional-neural-networks/)

6. [Deep Learning with Keras  Part 6: Textual Data Preprocessing](https://www.marktechpost.com/2019/09/13/deep-learning-with-keras-part-6-textual-data-preprocessing/)

7. [Deep Learning with Keras  Part 7: Recurrent Neural Networks](https://www.marktechpost.com/2019/10/01/deep-learning-with-keras-part-7-recurrent-neural-networks/)",0,18
10,2019-10-2,2019,10,2,17,dc7e1s,Deepfakes video from #TheOffice. Creeped out max.,https://www.reddit.com/r/deeplearning/comments/dc7e1s/deepfakes_video_from_theoffice_creeped_out_max/,warmachine0609,1570005085,,12,148
11,2019-10-2,2019,10,2,23,dcb7xa,CNN with different image sizes,https://www.reddit.com/r/deeplearning/comments/dcb7xa/cnn_with_different_image_sizes/,clean_pegasus,1570027703,How do you work with datasets that have different image sizes? I don't want to resize the image or pad it. Is there any other way?,2,2
12,2019-10-3,2019,10,3,0,dcblcn,Research paper ideas (Computer Vision).,https://www.reddit.com/r/deeplearning/comments/dcblcn/research_paper_ideas_computer_vision/,datguy_paarth,1570029357,"Hi everyone, I am a third year undergraduate student and want to get started into writing research papers on vision. I have completed some projects but can't figure out what to write a paper on. Any ideas will be appreciated.

Also to the mods, will it not be a good idea to have a thread where people can post ideas they have for research or projects and if interested can collaborate?",3,0
13,2019-10-3,2019,10,3,3,dcdzbc,[Blog Post] Saving and Loading Deep Learning Models to resume training in Pytorch,https://www.reddit.com/r/deeplearning/comments/dcdzbc/blog_post_saving_and_loading_deep_learning_models/,thesanerachit,1570039744,"I recently wrote a medium post on how to save and load a deep learning model to resume training it in PyTorch.
Medium post link: https://medium.com/@rachit221195/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61?source=friends_link&amp;sk=39046d215126bb0153d6ab70b0cb837d

I am hoping this would be helpful to people who are new to PyTorch and DeepLearning.
This is my first tech post ever. I would love to get all kinds of feedback on it.",0,1
14,2019-10-3,2019,10,3,3,dceafy,Object Detection in Real Time | Code repo | With Demo,https://www.reddit.com/r/deeplearning/comments/dceafy/object_detection_in_real_time_code_repo_with_demo/,826krishna,1570041119,,1,1
15,2019-10-3,2019,10,3,3,dcef41,Multiclass image classification,https://www.reddit.com/r/deeplearning/comments/dcef41/multiclass_image_classification/,danush321,1570041668,Can anyone give me a good link or even the code for this. I want to give a single image as an input and it should output the top single prediction. Thanks in advance!,0,1
16,2019-10-3,2019,10,3,5,dcfnt9,"Generalized Policy Iteration, Dynamic Programming, and RL for Car Rental Resource Allocation - Reinforcement Learning Chapter 4!",https://www.reddit.com/r/deeplearning/comments/dcfnt9/generalized_policy_iteration_dynamic_programming/,HenryAILabs,1570046749,[https://youtu.be/pcZFjPHO4c0](https://youtu.be/pcZFjPHO4c0),0,1
17,2019-10-3,2019,10,3,7,dchsdp,Quickstart TensorFlow 2.0 Tutorial - Basic Image Classification,https://www.reddit.com/r/deeplearning/comments/dchsdp/quickstart_tensorflow_20_tutorial_basic_image/,mippie_moe,1570055661,,0,5
18,2019-10-3,2019,10,3,7,dchzve,trying to confirm my understanding of image segmentation,https://www.reddit.com/r/deeplearning/comments/dchzve/trying_to_confirm_my_understanding_of_image/,fieldcady,1570056580,"I'm trying to wrap my head around image segmentation (i.e. the output is a 2D array the size of the input image, giving classifications for pixels) rather than a 1D array for classification.  I \*think\* that I get it, but it seems really crude and I would like to confirm.

Looking at \[UNet\]([https://github.com/zhixuhao/unet/blob/master/model.py](https://github.com/zhixuhao/unet/blob/master/model.py)) for example it seems as if each pixel is in effect classified by looking at the area around it and assigning that area to one of k classes that you're trying to identify.  k=2 if you are trying to separate landscape from the sky, for example.  Basically you have a smaller neural network that I will call miniNN - that takes in a sub-image and produces a k-dimensional vector - and you tile miniNN over the whole image like a souped-up convolutional kernel.

This is a limited approach.  For example, if you draw a large circular perimeter (with radius much larger than miniNN's dimensions) on an otherwise homogenous background you cannot segment out the inside from the outside.  You would have to do something like using deep learning to segment out the pixels that are near the perimeter, and then use connectedness to determine whether the other pixels were inside or outside it.

Am I understanding this correctly?  Is there any big innovation that I'm missing?  Thanks!!",0,3
19,2019-10-3,2019,10,3,18,dco99e,[Blog Post] Dense and Sparse Crowd Counting Methods and Techniques - DIY pedestrian detection model,https://www.reddit.com/r/deeplearning/comments/dco99e/blog_post_dense_and_sparse_crowd_counting_methods/,manneshiva,1570093242,"Estimate the number of people from CCTV footage or drone imagery.

[https://nanonets.com/blog/crowd-counting-review/](https://nanonets.com/blog/crowd-counting-review/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=drcrco&amp;utm_content=dl)

&amp;#x200B;

*Processing gif gggbo2tehaq31...*",0,7
20,2019-10-3,2019,10,3,22,dcr02e,Deep Learning from scratch,https://www.reddit.com/r/deeplearning/comments/dcr02e/deep_learning_from_scratch/,zepmck,1570109772,"Dear all,

I need to develop a deep learning application for object detection from scratch using tons of images. Can you please point me to a resource that may explain me where to start from? Which technology to chose? Which libraries? DataLoaders?

Thanks",1,1
21,2019-10-3,2019,10,3,22,dcr90n,Awesome AI Research and Projects on Computer Vision News (with codes!) October 2019,https://www.reddit.com/r/deeplearning/comments/dcr90n/awesome_ai_research_and_projects_on_computer/,Gletta,1570111000,"The October issue of Computer Vision News: 36 pages about AI and Deep Learning through research and practical applications.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019October/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-october-pdf/)

Technical articles on pages 4-8 and 18-23. Subscribe for free on page 36.

&amp;#x200B;

https://i.redd.it/nsya4b6i0cq31.jpg",0,25
22,2019-10-3,2019,10,3,23,dcrc7b,Keras SWA: Stochastic weight averaging callback for Keras,https://www.reddit.com/r/deeplearning/comments/dcrc7b/keras_swa_stochastic_weight_averaging_callback/,lilsmacky,1570111421,"As an exercise for myself I decided to implement SWA, from the paper [Averaging Weights Leads to Wider Optima and Better Generalization](https://arxiv.org/abs/1803.05407). I did it with Keras and decided it might make a nice package.

Repo:

[https://github.com/simon-larsson/keras-swa](https://github.com/simon-larsson/keras-swa)

pip:

`pip install keras-swa`

If you are not familiar with SWA, it is a trick to approximate ensembling by taking a running average of your weights towards the end of training a model. You can read more in this nice [blog post](https://pechyonkin.me/stochastic-weight-averaging/) explaining SWA and it's relatives SSE and FGE.

I currently only implement the constant learning rate schedule from the paper, hoping to add the cyclic one from the paper soon. It is also possible to leave the learning rate to the optimizer or other schedulers. I have also not implemented the batch normalization fix. It requires a forward pass over training data, which I don't know how to do from a callback. So any help there would be appreciated.

I would love for people to try it! Feedback is also welcome! :)",0,2
23,2019-10-4,2019,10,4,5,dcx27t,Model-Free and Off-Policy Learning - Reinforcement Learning Chapter 5!,https://www.reddit.com/r/deeplearning/comments/dcx27t/modelfree_and_offpolicy_learning_reinforcement/,HenryAILabs,1570136140,[https://youtu.be/uiPhlFrwcw8](https://youtu.be/uiPhlFrwcw8),0,4
24,2019-10-4,2019,10,4,16,dd3uoy,Deep,https://www.reddit.com/r/deeplearning/comments/dd3uoy/deep/,connor123646,1570172574,,13,0
25,2019-10-4,2019,10,4,16,dd3vy3,Transforming eCommerce Businesses with Robotic Process Automation,https://www.reddit.com/r/deeplearning/comments/dd3vy3/transforming_ecommerce_businesses_with_robotic/,Ak_Bansal,1570172811,,0,1
26,2019-10-4,2019,10,4,17,dd4n8u,Is Neural Style Transfer is good for final year undergrad project??,https://www.reddit.com/r/deeplearning/comments/dd4n8u/is_neural_style_transfer_is_good_for_final_year/,Pratik668,1570178616,,6,0
27,2019-10-4,2019,10,4,21,dd6fw9,How can I create a nice NN architecture diagram - Beginner?,https://www.reddit.com/r/deeplearning/comments/dd6fw9/how_can_i_create_a_nice_nn_architecture_diagram/,dalastspartan,1570190724,"I am very new to deep learning but I have followed a few online tutorials and I now have a graph of one of my models on TensorBoard: [https://imgur.com/a/cUxWs39](https://imgur.com/a/cUxWs39)

While this is useful I want to also explore other methods in making a nice looking diagram, something along the lines of what was posted here: [https://datascience.stackexchange.com/questions/14899/how-to-draw-deep-learning-network-architecture-diagrams](https://datascience.stackexchange.com/questions/14899/how-to-draw-deep-learning-network-architecture-diagrams), possibly using the NN-SVG tool suggested by Pablo Rivas:  [https://imgur.com/7hCjPNJ](https://imgur.com/7hCjPNJ).

I think I need some more experience to do this right but I want to make sure im accurately portraying the model. Could someone help me in creating a NN diagram using the NN-SVG tool or suggest something else that I can use?

Model below, thanks in advance:

dense\_layers = \[0,1,2\]  
layer\_sizes = \[32, 64, 128\]  
conv\_layers = \[1, 2, 3\]  


for dense\_layer in dense\_layers:  
 for layer\_size in layer\_sizes:  
 for conv\_layer in conv\_layers:  
NAME = ""{}-conv-{}-nodes{}-dense-{}"".format(conv\_layer, layer\_size, dense\_layer, int(time.time()))  
tensorboard = TensorBoard(log\_dir=""logs\\{}"".format(NAME))  
 model = Sequential()

model.add(Conv2D(layer\_size, (3,3), input\_shape = X.shape\[1:\]))  
model.add(Activation(""relu""))  
model.add(MaxPooling2D(pool\_size=(2,2)))  
 for l in range(conv\_layer - 1):  
model.add(Conv2D(layer\_size, (3,3)))  
model.add(Activation(""relu""))  
model.add(MaxPooling2D(pool\_size=(2,2)))  
 model.add(Flatten())  
 for l in range(dense\_layer):  
model.add(Dense(layer\_size))  
model.add(Activation(""relu""))  
model.add(Dropout(0.2))   
 model.add(Dense(1))  
 model.add(Activation('sigmoid'))  


 model.compile(loss='binary\_crossentropy',  
 optimizer=""adam"",  
 metrics=\['accuracy'\])  
model.fit(X\_train, y\_train, batch\_size=32, epochs=15, validation\_split=0.2, shuffle=True, callbacks=\[tensorboard\])  
score = model.evaluate(X\_test, y\_test, batch\_size=32)",3,1
28,2019-10-4,2019,10,4,22,dd76k4,Need help finding supplementary material and dataset for a paper,https://www.reddit.com/r/deeplearning/comments/dd76k4/need_help_finding_supplementary_material_and/,AhmedZubairGCU,1570194736,"The paper in question is [DeepLens: Shallow Depth of Field from a Single Image](https://deeplensprj.github.io/deeplens/DeepLens.html)

In the paper there is mention of supplementary material which I cannot find on the project website. Also the link to database on the website just redirects to github. I have emailed them but received no reply. If any one here have access to these materials kindly share them. Or if you know about any related paper kindly mention them as well.",0,5
29,2019-10-4,2019,10,4,22,dd7amk,Drones and Artificial Intelligence.,https://www.reddit.com/r/deeplearning/comments/dd7amk/drones_and_artificial_intelligence/,cmillionaire9,1570195328,,3,34
30,2019-10-5,2019,10,5,0,dd913a,Label Studio - flexible data labeling and annotation tool,https://www.reddit.com/r/deeplearning/comments/dd913a/label_studio_flexible_data_labeling_and/,michael_htx,1570203507,"It's [https://labelstud.io/](https://labelstud.io/)

Hey, I'm excited to share the news with the community. We're releasing our data labeling tool into the open-source. It's called **Label Studio**. Why yet another one? While working as ML engineers, most of the tools we've used were very specific and required at least some tunning to work with our datasets. Thus the idea of a configurable UI was born.

As you'd build a webpage, you can create a data labeling UI specifically for your needs. The config language is so expressive it usually takes no more than 10-20 lines.

I hope somebody finds it useful. Enjoy and send your feedback!

[https://github.com/heartexlabs/label-studio](https://github.com/heartexlabs/label-studio)

&amp;#x200B;

https://i.redd.it/a1xeuy5nnjq31.png",0,10
31,2019-10-5,2019,10,5,1,dd9iqd,Top 10 techniques for feature selection,https://www.reddit.com/r/deeplearning/comments/dd9iqd/top_10_techniques_for_feature_selection/,nerdy_wits,1570205684,,0,1
32,2019-10-5,2019,10,5,2,ddaj88,Looking for where to start in Computational Photography research,https://www.reddit.com/r/deeplearning/comments/ddaj88/looking_for_where_to_start_in_computational/,soundofhorse,1570210176,"Hey guys,

I know posts like these are a drag but bear with me! I'm fortunate enough to have the opportunity to complete a research project with the help of amazing researching faculty at my University. I can really pick my path to complete my studies. Now I'm no newbie to DL. I've done a small amount of research in using CNN to learn traits of inorganic molecules, I've taken Master's level courses in NLP, DL, Knowledge bases and Imaging. I've read a few research papers on the topic of inverse rendering, and using DL to create HDR images. Those papers really sparked my interest. I really want to use my education to research *something* in the realm of computational photography but don't where to start. So, what are some of your guys favorite papers on the topic that I could read? 

Thanks!",0,3
33,2019-10-5,2019,10,5,6,dddpp4,[Hardware] Advice about picking my next GPU: Turing vs. Pascal,https://www.reddit.com/r/deeplearning/comments/dddpp4/hardware_advice_about_picking_my_next_gpu_turing/,scapocchione,1570223952,"Hi. I own a GTX 1080ti right now. Now, I'd like to buy a new GPU. Budget is around 1000 bucks.

I have the following options:

\- Another 1-2 1080ti, to used just in parallel via the PCIe bus. Using FP16 on a Pascal card gives a modest speedup (5-8%), but whith the effect of almost doubling the memory, which is the main thing about FP16 (in other words, if your training takes a little more, you just wait, but if your minibatches don't fit in memory, you are done). The big advantage of the 1080TIs, for me, is that you have a 11gb memory card for \~500usd/eur.

\- A couple of 1070Super. They are substantially faster (\~30%) than 1080TI in FP16, and a bit slower in FP32. They have the advantage of being NVlink capable, but with half bandwidth. It is somewhat unclear if memory pooling via nvlink does actually work with consumer Nvidia cards. Still, I would have \~16Gb of vram against \~33Gb of 3x1080ti. One potential advantage is that as the main frameworks will cease to support Pascal, Turing would be presumably still supported. Throwing three 1080ti in the trashcan within 1-2 yrs would be a shame (I don't game).

\- A single 2080ti. Fastest consumer card for DL, but still 11Gb at twice the price of a 1080TI. Potential for adding another one in future. Full nvlink bandwidth, but still no memory pooling (at least from what I understand).

What do you think??",12,3
34,2019-10-5,2019,10,5,14,ddj7mv,How do you go from a 750-sampled input to a 600 x 3 output using a CNN?,https://www.reddit.com/r/deeplearning/comments/ddj7mv/how_do_you_go_from_a_750sampled_input_to_a_600_x/,arjundupa,1570254338,"I am trying to reproduce the results of [this](https://www.researchgate.net/publication/327375583_A_Simple_and_Effective_Method_for_Detecting_Myocardial_Infarction_Based_on_Deep_Convolutional_Neural_Network) paper titled: ""A Simple and Effective Method for Detecting Myocardial Infarction Based on Deep Convolutional Neural Network""

The paper says:

&gt;The input to our CNN network is a fixed-size 750 samples.

Because the first layer is a 2D Convolutional layer, which requires a 4D input, I assume the input shape is (batch\_size, 1, 1, 750) -- their input only has one channel (making the 2nd dimension a 1), and that one channel is 1D (making the 3rd dimension a 1 and the 4th dimension equal to 750).

The table on page three with the network architecture says that the first (convolutional) layer has:

&gt;Kernel size: 151 x 3, Stride: 1, Output shape: 600 x 3, and Valid Padding

I tried implementing this with:

    self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 453), stride=1)

But, this gives me an output shape of (1 x 1 x 298). How can I get a (600 x 3) output which is consistent with all of their implementation details? Any ideas what I'm doing wrong?

Any ideas will be much appreciated, thank you!",5,2
35,2019-10-5,2019,10,5,15,ddjiky,"Interview with the CTO of Hugging Face: Julien Chaumond | Hugging Face, Transformers | NLP Research and Open Source + 3 AMA Announcements",https://www.reddit.com/r/deeplearning/comments/ddjiky/interview_with_the_cto_of_hugging_face_julien/,init__27,1570256590,"Interview with the CTO of Hugging Face, Julien Chaumond all about his journey into the field and his path as a CTO of Hugging Face. We also discuss all the amazing work being done at Hugging Face, research and open source as well as about their team.

Audio: https://anchor.fm/chaitimedatascience/episodes/Hugging-Face--Transformers--NLP-Research-and-Open-Source--Interview-with-Julien-Chaumond-e5o819/a-apcirt

Video: https://www.youtube.com/watch?v=kqPEwJVkpnA

AMA Announcements: 
Ill also be interviewing 3 more amazing people in the upcoming week and they have been kind enough to agree to an AMA interview, here are the links to submit your questions:


AMA Interview with Victor Sanh, Research Scientist at Hugging Face, AMA: https://twitter.com/bhutanisanyam1/status/1179836740569223168?s=21

Kaggle IEEE-CIS Fraud Detection Comp, 2nd Pos winner (Team: 2 Uncles and 3 Puppies), Grandmaster CPMP AMA: https://www.kaggle.com/c/ieee-fraud-detection/discussion/111242

6th Pos winner (Team: Zoo), Kaggle Master, Philipp Singer, AMA Interview: https://www.kaggle.com/c/ieee-fraud-detection/discussion/111281",0,23
36,2019-10-6,2019,10,6,0,ddoc3s,From The Brain To AI (Neural Networks | What Is Deep Learning | Deep Learning Basics),https://www.reddit.com/r/deeplearning/comments/ddoc3s/from_the_brain_to_ai_neural_networks_what_is_deep/,enchorb,1570287752,,0,1
37,2019-10-6,2019,10,6,7,ddul8z,Multi Instance Learning,https://www.reddit.com/r/deeplearning/comments/ddul8z/multi_instance_learning/,thisisabujee,1570315423,"Can someone suggest me a good repository for implementing multi instance learning algorithm. I have this problem where i am stuck a bit. if we jave any expert on multi instance learning here, please do comment  below, i have to ask few questions. Thanks",4,13
38,2019-10-6,2019,10,6,8,ddv3pn,Free Book: Getting Started with TensorFlow 2.0,https://www.reddit.com/r/deeplearning/comments/ddv3pn/free_book_getting_started_with_tensorflow_20/,psangrene,1570317678,,0,1
39,2019-10-6,2019,10,6,18,de0yi5,Zooming into the world of computer vision applications,https://www.reddit.com/r/deeplearning/comments/de0yi5/zooming_into_the_world_of_computer_vision/,Ansh_Techie,1570353506,,0,1
40,2019-10-7,2019,10,7,0,de4d9l,Multiple inputs and different training samples,https://www.reddit.com/r/deeplearning/comments/de4d9l/multiple_inputs_and_different_training_samples/,dlnewb69,1570374201,"I have a model that takes 2 inputs, however the number of training samples in both of them are not supposed to be the same. Although it is situational, most of the time samples in input a will be greater than input b. 

Let's say input a has 10,000 training samples and input b has 2000. Is there a way to train them together or I'll have to duplicate the samples in input b?",2,1
41,2019-10-7,2019,10,7,0,de4l53,"AR + AI | AutoML Vision Edge, AutoML Video, and Video Intelligence API",https://www.reddit.com/r/deeplearning/comments/de4l53/ar_ai_automl_vision_edge_automl_video_and_video/,cmillionaire9,1570375240,,3,38
42,2019-10-7,2019,10,7,5,de8ifc,"AI Research Weekly Update Video! - October 6th, 2019",https://www.reddit.com/r/deeplearning/comments/de8ifc/ai_research_weekly_update_video_october_6th_2019/,HenryAILabs,1570392161,[https://youtu.be/rCpvXZSaNlQ](https://youtu.be/rCpvXZSaNlQ),0,1
43,2019-10-7,2019,10,7,6,dea3ww,"Guys, I'm confused with the hypothesis",https://www.reddit.com/r/deeplearning/comments/dea3ww/guys_im_confused_with_the_hypothesis/,kkingbbob,1570399128,"Hey guys! Recently, I'm quite confused about the logic running inside methodology. I did some data science methodology course. It seems quite clear. For example, clarity the research question, aim and objectives -&gt; which approach to use -&gt; data preparation -&gt; data collection -&gt; data evaluation -&gt; deployment etc. Then I read some PhD's dissertation. It's a similar pattern that from the question, based on literature review, proposed a framework or system, then modelling and evaluation. However, I read some social science and medical methodology. OMG! I was lost there. For example, hypothetical deductive is the foundation. First, u need to have a hypothesis. Then sampling, data collection and analyse the data to test the hypothesis. So I'm stuck here! The hypothesis. Many of the data science research doesn't have a hypothesis. Then have a research question, such as how to xxxx to improve xxxx. Is it necessary to have hypothesis in data science project? Or does having a hypothesis means that just transfer this research question into a hypothesis like ""whether this xxxx model can improve xxxx?""",2,0
44,2019-10-7,2019,10,7,8,deb6cv,"Deep Learning with TensorFlow By Giancarlo Zaccone, Md. Rezaul Karim PDF",https://www.reddit.com/r/deeplearning/comments/deb6cv/deep_learning_with_tensorflow_by_giancarlo/,oussamaouti,1570404223,,1,0
45,2019-10-7,2019,10,7,14,def1b9,Need dataset of rgb+d images for portrait mode,https://www.reddit.com/r/deeplearning/comments/def1b9/need_dataset_of_rgbd_images_for_portrait_mode/,AhmedZubairGCU,1570425438,"I need a rgbd image dataset for training a model for portrait mode. Most rgbd images dataset include indoor scenes of furniture, streets, pedestrian or closeups of people. I need a dataset that contain pictures that people take from their smartphones using portrait mode such as portraits of people and some close ups of objects.",1,1
46,2019-10-7,2019,10,7,15,defu32,Accelerating Sales Growth with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/defu32/accelerating_sales_growth_with_artificial/,Anshul_Oodles,1570431009,,1,0
47,2019-10-7,2019,10,7,16,deg94k,Attention is all you need : Paper Overview,https://www.reddit.com/r/deeplearning/comments/deg94k/attention_is_all_you_need_paper_overview/,i_amujjawal,1570434138,,0,2
48,2019-10-7,2019,10,7,19,dehj4t,Looking for resources on Image Analysis and Computer Vision,https://www.reddit.com/r/deeplearning/comments/dehj4t/looking_for_resources_on_image_analysis_and/,JyotinderSingh,1570443686,"I'm starting work on a research project at my university, regarding DL and CV, I'm a newbie to this field and have limited knowledge of the subject. I was wondering if someone could hook me up with some resources for reference smd learning regarding topics such as Image Validation/Analysis and Computer Vision.
My experience includes having worked on basic projects thst were a part of Stanford's CS231n on YouTube.
Thank you!",0,1
49,2019-10-7,2019,10,7,21,deivue,LSTM for solving Class Overlapping Issues,https://www.reddit.com/r/deeplearning/comments/deivue/lstm_for_solving_class_overlapping_issues/,data_autopsy,1570452010,"Do you guys think RNN can help in classification problems with high overlap among classes. I'm working on a dataset having a considerable overlap among the classes. I have tried a lot of stuff from augmentation to transfer learning, by doing binary classification for each class but it's not perfect yet. Do you guys think a feedback loop over cnn will make the matter easy? I'm thinking of writing custom Image generator to generate multiple augmented images of single and then passing it to my cnn block and then using the features extracted there as an input for my lstm. Has anyone worked on this? I need some help. If I'm against the wall, please let me know. Thanks.",4,2
50,2019-10-7,2019,10,7,21,deix64,Deep Learning for Programmers new release 0.10.0 + Momentum and Nesterov Momentum,https://www.reddit.com/r/deeplearning/comments/deix64/deep_learning_for_programmers_new_release_0100/,dragandj,1570452209,,2,7
51,2019-10-7,2019,10,7,22,dej5ee,The Deep Learning Revolution (The MIT Press) hardcover is 28% off,https://www.reddit.com/r/deeplearning/comments/dej5ee/the_deep_learning_revolution_the_mit_press/,Tanderies80,1570453430,,1,0
52,2019-10-7,2019,10,7,22,dej5f6,[Research] On achieving accurate object detection,https://www.reddit.com/r/deeplearning/comments/dej5f6/research_on_achieving_accurate_object_detection/,cdossman,1570453432,"Object Detection Accuracy (mAP) Cheat Sheet: 6 Freebies to Help You Increase the Performance of Your Object Detection Models

 [https://www.linkedin.com/pulse/object-detection-accuracy-map-cheat-sheet-christopher-dossman/?trackingId=uL1wSwcoFRj3dzy%2B3SmmKQ%3D%3D](https://www.linkedin.com/pulse/object-detection-accuracy-map-cheat-sheet-christopher-dossman/?trackingId=uL1wSwcoFRj3dzy%2B3SmmKQ%3D%3D) 

 [https://towardsdatascience.com/object-detection-accuracy-map-cheat-sheet-8f710fd79011](https://towardsdatascience.com/object-detection-accuracy-map-cheat-sheet-8f710fd79011)",0,5
53,2019-10-8,2019,10,8,0,dekqk7,GPU rental for rent.,https://www.reddit.com/r/deeplearning/comments/dekqk7/gpu_rental_for_rent/,WINDY_WINDWARD,1570460962,"i can provide you with a remote access to GPU rigs for training your machine learning purposes 

prices 

2$ for a 24 hour session with a single 1080ti

i also provide amd rigs running vega 64's",0,1
54,2019-10-8,2019,10,8,6,depsjy,"Temporal-Difference Learning, SARSA, &amp; Q-Learning - Reinforcement Learning Chapter 6!",https://www.reddit.com/r/deeplearning/comments/depsjy/temporaldifference_learning_sarsa_qlearning/,HenryAILabs,1570482455,[https://youtu.be/L64E\_NTZJ\_0](https://youtu.be/L64E_NTZJ_0),0,6
55,2019-10-8,2019,10,8,7,der0fr,Survival Analysis with Deep Learning,https://www.reddit.com/r/deeplearning/comments/der0fr/survival_analysis_with_deep_learning/,backtoreality123,1570487763,Hey Im just wondering if anyone has any recommendations on resources to learn how to implement survival analyses with Deep Learning? Ive found some things through Google but just wanted to see if there was anyone with experience in such research and what methods they used.,3,8
56,2019-10-8,2019,10,8,15,devzag,PyTorch Custom Padding,https://www.reddit.com/r/deeplearning/comments/devzag/pytorch_custom_padding/,arjundupa,1570514727,"When I do:

    nn.Conv1d(in_channels=10, out_channels=10, kernel_size=20, stride=1, padding=10)

PyTorch applies a padding of 10 to both sides. 

How do I apply a custom padding of 9 on one side and 10 on the other in PyTorch?",3,4
57,2019-10-8,2019,10,8,20,deydlr,Accelerating Sales Growth with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/deydlr/accelerating_sales_growth_with_artificial/,Binny_gupta,1570532500,,0,0
58,2019-10-8,2019,10,8,20,deylf5,Video Stream Analysis pipeline.,https://www.reddit.com/r/deeplearning/comments/deylf5/video_stream_analysis_pipeline/,lakshaytalkstocomput,1570533836,How to make a scalable system to do video stream analysis using deep learning on cctv cameras? any tips or readings?,2,14
59,2019-10-8,2019,10,8,23,df0ppf,[EMNLP-IJCNLP 2019] Statistics and Accepted paper list with arXiv link,https://www.reddit.com/r/deeplearning/comments/df0ppf/emnlpijcnlp_2019_statistics_and_accepted_paper/,roomylee,1570544895,,0,4
60,2019-10-9,2019,10,9,0,df1e80,]Research] A liquid warping GAN,https://www.reddit.com/r/deeplearning/comments/df1e80/research_a_liquid_warping_gan/,cdossman,1570547883,[removed],0,1
61,2019-10-9,2019,10,9,0,df1tso,Privacy and Learnability in AI?,https://www.reddit.com/r/deeplearning/comments/df1tso/privacy_and_learnability_in_ai/,potato-question-mark,1570549762,"Can anyone guide me to some interesting works on privacy preserving deep learning?

I want to implement a cnn that would preserve the privacy of the images used for training and all. I am not exactly sure of what I want, but I would appreciate any input.

Thanks!",2,1
62,2019-10-9,2019,10,9,6,df6cjw,"n-step Bootstrapping, enabling more data efficient Model-Free Learning - Reinforcement Learning Chapter 7!",https://www.reddit.com/r/deeplearning/comments/df6cjw/nstep_bootstrapping_enabling_more_data_efficient/,HenryAILabs,1570569064,[https://youtu.be/1i5a4yj0Mwg](https://youtu.be/1i5a4yj0Mwg),0,15
63,2019-10-9,2019,10,9,7,df7gi0,"Things impossible for classic Machine Learning, but Deep Learning succeeded in",https://www.reddit.com/r/deeplearning/comments/df7gi0/things_impossible_for_classic_machine_learning/,padschu,1570573565,"What did Deep Learning achieve, that was/seemed to classic Machine Learning?  
Like AlphaGo winning the board game Go against a human top player.  
So, not just like outperforming other Machine Learning, but enabling new stuff.  


What is your favorite?",8,5
64,2019-10-9,2019,10,9,16,dfdwrs,"What is the definition of ""vector-to-vector function""?",https://www.reddit.com/r/deeplearning/comments/dfdwrs/what_is_the_definition_of_vectortovector_function/,otakutyrant,1570607993,I encounter this in Deep Learning.,3,6
65,2019-10-9,2019,10,9,18,dfegvy,Difference of Deep Learning vs Neural Networks,https://www.reddit.com/r/deeplearning/comments/dfegvy/difference_of_deep_learning_vs_neural_networks/,swethasree12,1570612248,,0,0
66,2019-10-9,2019,10,9,19,dffa4n,Accelerating Sales Growth with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/dffa4n/accelerating_sales_growth_with_artificial/,Kushal_Bansal001,1570618045,,1,1
67,2019-10-9,2019,10,9,21,dfgbba,"Implementation of deep learning related scripts(model defs, loss functions etc.) using tensorflow 2",https://www.reddit.com/r/deeplearning/comments/dfgbba/implementation_of_deep_learning_related/,vandit_15,1570624101,,0,2
68,2019-10-9,2019,10,9,23,dfhtp1,"HarDNet, which achieves ~36% inference time reduction",https://www.reddit.com/r/deeplearning/comments/dfhtp1/hardnet_which_achieves_36_inference_time_reduction/,hazarapet,1570631349,,0,1
69,2019-10-10,2019,10,10,3,dflmdf,What is the validation set used for?,https://www.reddit.com/r/deeplearning/comments/dflmdf/what_is_the_validation_set_used_for/,ssd123456789,1570647545,"So I am a but confused about the role of the validation set. I train my model and then use the validation set to tune the hyperparameters? 
That just sounds wrong to me. Wouldn't you want to set your hyperparameters first and then train. For example, the learning rate, what use is it to tune it after the entire training process has taken place?",8,8
70,2019-10-10,2019,10,10,5,dfn2xp,GAN from Scratch,https://www.reddit.com/r/deeplearning/comments/dfn2xp/gan_from_scratch/,Flex1206,1570653803,"Anyone know where I can find a good source on learning how to code up a GAN from scratch? I took Andrew Ng's course on Deep Learning and found it useful to build networks up from scratch; however, I can't seem to find a good tutorial for GAN's. I'm also trying to learn more about the finer details of them so if there aren't any good tutorials I'm also open to any other sources.",19,23
71,2019-10-10,2019,10,10,8,dfpfbc,Question about pretrained models applied to medical imaging,https://www.reddit.com/r/deeplearning/comments/dfpfbc/question_about_pretrained_models_applied_to/,nickryd,1570664041,"Hey, Im pretty new to deep learning but interested in applying previously trained deep learning models onto medical imaging to see if any useful information could be gained from this. Im not aware of any available pre trained models that include thousands/millions of medical images (if there is let me know!) and so my question is more so wondering if there are pre trained models based on large data sets that may not be medical images but could still be useful in analyzing medical images.

For example, wondering if in medical imaging or really any field there is research on using models that were trained on one thing to help classify an unrelated image. Like train on shapes to identify animals. Dont know if this is an area with a lot of research or not much or even what it would be called but would greatly appreciate any recommendations.

My main goal is to run deep learning models off of small datasets that I have access to and would want to improve the predictive ability by applying various other pretrained models. Appreciate any comments or suggestions!",2,2
72,2019-10-10,2019,10,10,11,dfrk16,ClearnRL: RL library that focuses on easy experimental research with cloud logging,https://www.reddit.com/r/deeplearning/comments/dfrk16/clearnrl_rl_library_that_focuses_on_easy/,vwxyzjn,1570674618,,4,1
73,2019-10-10,2019,10,10,12,dfsiaz,Total Beginner (Zero programming experience) trying to develop deep learning algorithm for research...,https://www.reddit.com/r/deeplearning/comments/dfsiaz/total_beginner_zero_programming_experience_trying/,chinnyachebe,1570679842,"I've been assigned to develop a deep learning algorithm for research in laser manufacturing. The problem is that I am in my FIRST year in college and from what I've read online, many of the necessary mathematics used in deep learning requires an in depth understanding of linear algebra (one of the first topics in Andrew Ng's Deep Learning course is REVIEW of linear algebra, meanwhile I'm taking Calc 2) 

I have already done the necessary background research regarding the basic structure and functionality of a deep learning system from a conceptual view, but the thing is, I have absolutely no experience coding in Python or any other language. Will carrying out this research project be impossible? I understand that I can use pre trained models and stuff as a reference point, but will it be doable if someone like me who has zero coding skills and a lack of mathematical knowledge were to try to develop this algorithm? 

By the way, I'm an engineering major...",3,1
74,2019-10-10,2019,10,10,15,dftw0f,Lightweight DL,https://www.reddit.com/r/deeplearning/comments/dftw0f/lightweight_dl/,timisis,1570688378,"Hi, I am trying to get Google Cloud's ""free VM"" and similar to work for me, my reasoning is that the 600MB RAM should be enough for 100MB (and smaller) networks, and I can live with however long that would take on the 1/5 core or whatever Google can guarantee me. Sadly this kind of RAM is certainly not enough to compile python modules when that is necessary, and loading the standard ML libs is a hit and miss. I am generally hitting memory errors. Is there a well known small ML/DL setup? I want to do slow and steady training, for the inference part there are several candidates a google search away. I realize it may be more ""cloudy"" to use some ML free tier and control it from the VM, but I thought there must be some virtue in self-hosting DL for free, however slow.",4,1
75,2019-10-10,2019,10,10,18,dfvf1s,Best Ways to Improve Cloud ERP with AI and Machine Learning,https://www.reddit.com/r/deeplearning/comments/dfvf1s/best_ways_to_improve_cloud_erp_with_ai_and/,erp_oodles,1570699227,,0,1
76,2019-10-10,2019,10,10,20,dfwqtq,Deep Learning with Python,https://www.reddit.com/r/deeplearning/comments/dfwqtq/deep_learning_with_python/,swethasree12,1570707590,,0,1
77,2019-10-10,2019,10,10,23,dfyxmc,[Research] QUANTIZED REINFORCEMENT LEARNING (QUARL),https://www.reddit.com/r/deeplearning/comments/dfyxmc/research_quantized_reinforcement_learning_quarl/,cdossman,1570718275," [https://medium.com/ai%C2%B3-theory-practice-business/what-if-quantization-was-applied-for-reinforcement-learning-c3e6af50b054](https://medium.com/ai%C2%B3-theory-practice-business/what-if-quantization-was-applied-for-reinforcement-learning-c3e6af50b054) 

**Abstract:**  Quantization can help reduce the memory, compute, and energy demands of deep neural networks without significantly harming their quality. However, whether these prior techniques, applied traditionally to image-based models, work with the same efficacy to the sequential decision-making process in reinforcement learning remains an unanswered question. To address this void, we conduct the first comprehensive empirical study that quantifies the effects of quantization on various deep reinforcement learning policies with the intent to reduce their computational resource demands. We apply techniques such as post-training quantization and quantization aware training to a spectrum of reinforcement learning tasks (such as Pong, Breakout, BeamRider and more) and training algorithms (such as PPO, A2C, DDPG, and DQN). Across this spectrum of tasks and learning algorithms, we show that policies can be quantized to 6-8 bits of precision without loss of accuracy. We also show that certain tasks and reinforcement learning algorithms yield policies that are more difficult to quantize due to their effect of widening the models distribution of weights and that quantization aware training consistently improves results over post-training quantization and oftentimes even over the full precision baseline. Finally, we demonstrate real-world applications of quantization for reinforcement learning. We use mixed/half-precision training to train a Pong model 50% faster, and deploy a quantized reinforcement learning-based navigation policy onto an embedded system, achieving an 18 speedup and a 4 reduction in memory usage over an unquantized policy. 

 [https://arxiv.org/pdf/1910.01055.pdf](https://arxiv.org/pdf/1910.01055.pdf)",0,11
78,2019-10-11,2019,10,11,3,dg1y1q,How convert custom Keras code to Onnx?,https://www.reddit.com/r/deeplearning/comments/dg1y1q/how_convert_custom_keras_code_to_onnx/,74throwaway,1570730914,"I'm using the code from https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb

I'm trying to use keras2onnx with it also. I tried

	import keras2onnx
	import onnxruntime

	# convert to onnx model
	onnx_model = keras2onnx.convert_keras(model, model.name)

	# runtime prediction
	content = onnx_model.SerializeToString()
	sess = onnxruntime.InferenceSession(content)
	x = x if isinstance(x, list) else [x]
	feed = dict([(input.name, x[n]) for n, input in enumerate(sess.get_inputs())])
	pred_onnx = sess.run(None, feed)

But I got the following error:

	InvalidArgumentError                      Traceback (most recent call last)
	~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
	    426         results = c_api.TF_GraphImportGraphDefWithResults(
	--&gt; 427             graph._c_graph, serialized, options)  # pylint: disable=protected-access
	    428         results = c_api_util.ScopedTFImportGraphDefResults(results)

	InvalidArgumentError: Node 'block1b_drop/cond/mul/y': Unknown input node '^block1b_drop/cond/switch_t'

	During handling of the above exception, another exception occurred:

	ValueError                                Traceback (most recent call last)
	&lt;ipython-input-16-a5d3ba8b443c&gt; in &lt;module&gt;
	      3 
	      4 # convert to onnx model
	----&gt; 5 onnx_model = keras2onnx.convert_keras(model, model.name)
	      6 
	      7 # runtime prediction

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/main.py in convert_keras(model, name, doc_string, target_opset, channel_first_inputs, debug_mode, custom_op_conversions)
	     98                         custom_op_dict=custom_op_conversions)
	     99     topology.debug_mode = debug_mode
	--&gt; 100     parse_graph(topology, sess.graph, target_opset, output_names)
	    101     topology.compile()
	    102 

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/parser.py in parse_graph(topo, graph, target_opset, output_names)
	    647         topo.raw_model.add_input_name(str_value)
	    648 
	--&gt; 649     return _parse_graph_scope(graph, keras_layer_ts_map, topo, top_level, output_names)

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/parser.py in _parse_graph_scope(graph, keras_node_dict, topology, top_scope, output_names)
	    597             _convert_keras_timedistributed(graph, nodes, layer_key_, model_, varset)
	    598         elif layer_key_ is None or get_converter(type(layer_key_)) is None:
	--&gt; 599             _convert_general_scope(nodes, varset)
	    600         else:
	    601             _convert_keras_scope(graph, nodes, layer_key_, model_, varset)

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/parser.py in _convert_general_scope(node_list, varset)
	    299 
	    300     sess = keras.backend.get_session()
	--&gt; 301     subgraph, replacement = create_subgraph(sess.graph, node_list, sess, operator.full_name)
	    302     setattr(operator, 'subgraph', subgraph)
	    303     vars_, ts = _locate_inputs_by_node(node_list, varset)

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/subgraph.py in create_subgraph(tf_graph, node_list, sess, dst_scope)
	    135     with tf.Graph().as_default() as sub_graph:
	    136         im_scope = """" if dst_scope is None else dst_scope
	--&gt; 137         tf.import_graph_def(output_graph_def, name=im_scope)
	    138         if im_scope:
	    139             replacement = {k_: im_scope + '/' + k_ for k_ in replacement}

	~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
	    505                 'in a future version' if date is None else ('after %s' % date),
	    506                 instructions)
	--&gt; 507       return func(*args, **kwargs)
	    508 
	    509     doc = _add_deprecated_arg_notice_to_docstring(

	~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
	    429       except errors.InvalidArgumentError as e:
	    430         # Convert to ValueError for backwards compatibility.
	--&gt; 431         raise ValueError(str(e))
	    432 
	    433     # Create _DefinedFunctions for any imported functions.

	ValueError: Node 'block1b_drop/cond/mul/y': Unknown input node '^block1b_drop/cond/switch_t'

how can I convert this code to Onnx?",0,1
79,2019-10-11,2019,10,11,5,dg434w,"Facebook Debuts PyTorch 1.3 With PyTorch Mobile, Quantization, TPU Support and More",https://www.reddit.com/r/deeplearning/comments/dg434w/facebook_debuts_pytorch_13_with_pytorch_mobile/,Yuqing7,1570739583,,8,73
80,2019-10-11,2019,10,11,15,dgaz5g,The State of Machine Learning Frameworks in 2019,https://www.reddit.com/r/deeplearning/comments/dgaz5g/the_state_of_machine_learning_frameworks_in_2019/,asuagar,1570774501,,0,2
81,2019-10-11,2019,10,11,15,dgb4h4,Sentence Generation from specific words,https://www.reddit.com/r/deeplearning/comments/dgb4h4/sentence_generation_from_specific_words/,masternachiket,1570775490,"So I am working on a project which requires me to build a sentence generation system, but unlike other sentence generation systems I want my system to take an array of random words and generate a proper sentence using those words only.
Suppose I give my system input as ['Mumbai', 'I', 'from', 'am']
The system's output should be I am from Mumbai. 

Can someone please tell me how I can do this? Python packages and library.

Thank you!",0,1
82,2019-10-11,2019,10,11,16,dgbrng,"Why COCO evaluate with AP, AR by size? what are AR max =1, 10, 100's meaning?",https://www.reddit.com/r/deeplearning/comments/dgbrng/why_coco_evaluate_with_ap_ar_by_size_what_are_ar/,i_m_eden,1570779808,"I'm reading [COCO Metrics](http://cocodataset.org/#detection-eval) right now. And I have 2 questions about it.

This is the Metrics of COCO 

&amp;#x200B;

[Metrics of COCO](https://i.redd.it/r2z923249vr31.png)

&amp;#x200B;

1. I'm wondering why COCO evaluate AP and AR by size. What effect does image size have?
2. They measure AR by max which are 1, 10, 100. And they said AR max=1 is 'AR given 1 detection per image"". Then, if model detect multiple objects per image, how to calculate AR? I can't understand the meaning of 'max'.",0,1
83,2019-10-11,2019,10,11,18,dgcf2x,Understanding Adversarial Attack,https://www.reddit.com/r/deeplearning/comments/dgcf2x/understanding_adversarial_attack/,Mesode,1570784599,"I have watched the Standford deep learning lecture 16, which is about ""Adversarial Examples and Adversarial Training"" held by Ian Goodfellow (the inventor of the GANs). He explains that it is very easy to fool a CNN-classifier by changing an input image while the difference of the images is unrecognizable by human perception. As an example, given an image of a cat, and given that the CNN classifies it correctly as a cat, you can find a transformation of the image such that the image still looks the same by human perception but is classified as a ship! Ian Goodfellow already mentioned that in his well known deep learning book. 

However, I am wondering if you have 10 different CNN-classifier, would it become exponentially harder to find an adversarial image that fools all 10 classifiers or is there some systematic - some ""magic"" behind the  adversarial images?",5,8
84,2019-10-11,2019,10,11,20,dge1qu,AI &amp; Architecture,https://www.reddit.com/r/deeplearning/comments/dge1qu/ai_architecture/,cmillionaire9,1570794781,,3,27
85,2019-10-12,2019,10,12,1,dghv6t,FB Detectron2,https://www.reddit.com/r/deeplearning/comments/dghv6t/fb_detectron2/,qikpal,1570812530,,0,1
86,2019-10-12,2019,10,12,4,dgjpyz,Looking for rgb + depth dataset that contains humans for portrait mode,https://www.reddit.com/r/deeplearning/comments/dgjpyz/looking_for_rgb_depth_dataset_that_contains/,AhmedZubairGCU,1570820863,I am looking at rgb + depth dataset but all such datasets have indoor and outdoor scenes but no humans. I am looking for a dataset that contains humans and animals so it is appropriate to use in training a cnn that creates portrait mode effect. I am also thinking if such dataset is not available I creat a synthetic dataset. I have this idea to use image segmentation and add these segments to photos with known depth map at varying distances. Can anybody guide me how to create such dataset.,2,3
87,2019-10-12,2019,10,12,6,dglo8l,Multi-class semantic segmentation convertible to Onnx?,https://www.reddit.com/r/deeplearning/comments/dglo8l/multiclass_semantic_segmentation_convertible_to/,74throwaway,1570829689,"I need to train a multi-class semantic segmentation NN that can be convertible to Onnx

The only multi-class semantic segmentation NN that I was able to get to run properly was from https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb

However, when I tried to convert that code to Onnx, it wouldn't work

Anyone know of any alternatives?",0,1
88,2019-10-12,2019,10,12,16,dgrzpq,"How do you identify a top article in the field of artificial intelligence such as Deep Landing, Machine Learning, etc.?",https://www.reddit.com/r/deeplearning/comments/dgrzpq/how_do_you_identify_a_top_article_in_the_field_of/,Doctor_who1,1570865764,"How do you identify a top article in the field of artificial intelligence such as Deep Landing, Machine Learning, etc.?",3,1
89,2019-10-12,2019,10,12,18,dgsv4w,Combine #Reinforcement_learning with #deep_learning for abstractive #text_summarization,https://www.reddit.com/r/deeplearning/comments/dgsv4w/combine_reinforcement_learning_with_deep_learning/,theamrzaki,1570872314,[removed],0,1
90,2019-10-12,2019,10,12,21,dgup5t,Anyone with experience with training NLP models?,https://www.reddit.com/r/deeplearning/comments/dgup5t/anyone_with_experience_with_training_nlp_models/,kajobkajob,1570884402,"Hi, I'm looking to do some work with architectures like transformers e.g. bert, albert but I would like to know how much training could cost first.

Could anyone give me ballpark figures for the cost of training from scratch or finetuning with cloud TPUs or AWS?

If I were forced to work on an RTX 2080 what type of models would be feasible?

Since I'm only looking for ballpark figures if the answer depends on some variables could you give the answer with respect to some common cases?",12,8
91,2019-10-13,2019,10,13,0,dgwt7i,"Seeking resources to have a deeper understanding of CNN's intermediate conv layers, how they work to extract feature.",https://www.reddit.com/r/deeplearning/comments/dgwt7i/seeking_resources_to_have_a_deeper_understanding/,bikigoogler,1570895146,"Hey guys, I have started with deep learning.I know basic concept of CNN but i want to know about how the inner layers extract feature . eg. in case of training dog images how the inner layers extract feature like paw, tail etc. Please suggest something that works.",8,2
92,2019-10-13,2019,10,13,2,dgy378,Using Tensorflow/keras with Python multiprocessing pool,https://www.reddit.com/r/deeplearning/comments/dgy378/using_tensorflowkeras_with_python_multiprocessing/,shahriar49,1570901080,"I want to do a neural network training in Tensorflow/Keras but prefer to use python multiprocessing module to maximize use of system resources and save time. What I do is simply like this (I want to run this code on a system without GPU or with one or more GPUs):

        import ... (required modules)
        from multiprocessing import Pool
        import tensorflow as tf
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        sess = tf.Session(config=config)
        tf.keras.backend.set_session(sess)
        
        ... some tf and non-tf variable initializations...
        ... some functions to facilitate reading tensorflow datasets in TFRecord format...
        ... function defining keras model...
        
        # Main worker function
        def doWork(args):
            from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
            from tensorflow.keras.models import load_model
        
            train_data = read_datasets(...)
            val_data = read_datasets(...)
            test_data = read_datasets(...)
        
            if (NumGPUs &gt; 1):
                strategy = tf.distribute.MirroredStrategy()
                with strategy.scope():
                    model = keras_model(...)
                    model.compile(...)
            else:
                model = keras_model(...)
                model.compile(...)
        
            model.fit(train_data, epochs=epochs, steps_per_epoch=train_steps, ...)
            _, test_acc = model.evaluate(test_data, steps=test_steps)
            ...log results...
        
        if __name__ == '__main__':
            pool = Pool(processes=2)
            a1 = &lt;set of parameters for the first run&gt;
            a1 = &lt;set of parameters for the second run&gt;
            pool.map(doWork, (a1, a2))
    

I can run this code on different computers and get my results, but some times I face system hangups (especially if I want to abort execution by pressing CTRL+C) or program termination with different errors, and I guess the above is not the right style of combining Tensorflow/Keras and Python multiprocessing. What is the correct style of writing the above code?",4,1
93,2019-10-13,2019,10,13,6,dh1dn7,"Ubuntu 18.04, Windows 10 - Dual Hard Drive, Dual Boot - best practices?",https://www.reddit.com/r/deeplearning/comments/dh1dn7/ubuntu_1804_windows_10_dual_hard_drive_dual_boot/,Jollyhrothgar,1570916582,"I have a PC with a nice nvidia graphics card, and two fast hard drives. One annoying thing that I have dealt with for years is dual-booting, and getting both systems stable.  


I can always set up the dual boot, but inevitably, the boot loader breaks with an update, the the linux kernel updates, the drivers update (in either windows or linux) and then everything breaks.

&amp;#x200B;

Common symptoms include: loss of the ability to boot into Windows, ability to boot into Linux only, but loss of the ability to log in to the GUI (ssh only). Linux always breaks with an update, and I assume this has to do with CUDA drivers, NVIDIA drivers, and some kind of kernel mismatch. I get so tired of booting into a live CD, repairing the boot loader, reinstalling the OS(s), etc.  


I know this is vague and terrible, but does anyone have a guide, set of best practices, etc that can lead to a harmonious, stable dual boot set up? Does this exist yet?",30,6
94,2019-10-13,2019,10,13,14,dh6c2f,Keras custom loss function with Mahalanobis distance loss how to,https://www.reddit.com/r/deeplearning/comments/dh6c2f/keras_custom_loss_function_with_mahalanobis/,frenomer,1570943417," 

I am trying to implement a custom loss function in Keras using Mahalanobis distance loss. however I always run into this annoying ERROR. 

&gt; ValueError: Shape must be at least rank 2 but is rank 0 for 'loss\_88/dense\_270\_loss/MatrixInverse' (op: 'MatrixInverse') with input shapes: \[\]. 

Mahalanobis distance (or ""generalized squared interpoint distance"" for its squared value\[3\]) can also be defined as a dissimilarity measure between two random vectors x and y of the same distribution with the covariance matrix S.

d(x,y) = square \[Transpose(x-y) \* Inverse(S)\* (x-y)\]

([https://en.wikipedia.org/wiki/Mahalanobis\_distance](https://en.wikipedia.org/wiki/Mahalanobis_distance))

&amp;#x200B;

 

    n_classes = 4 
    n_samples=800 X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=4, n_redundant=0, n_classes=n_classes, n_clusters_per_class=2) 

y = to\_categorical(y)

Xtrainb, testXb, ytrainb, ytestb = train\_test\_split(X, y, test\_size = 0.3, random\_state=42)

&amp;#x200B;

 

    x_trainb = np.reshape(Xtrainb, (Xtrainb.shape[0], Xtrainb.shape[1], 1))
    Xtestb = np.reshape(testXb, (testXb.shape[0], testXb.shape[1], 1))  
    
    densesize = 4
    input_datab = Input(shape=(Xtrainb.shape[1],1)) 
    epochs = 10
    batch_size = 32
    
    
    ########
    def mahalanobis(y_true, y_pred):
        x_minus_mn_with_transpose = K.transpose(y_true - y_pred)
        Covariance = covr1(y_true, y_pred)
        inv_covmat = tf.linalg.inv(Covariance)
        x_minus_mn = y_true - y_pred
        left_term = K.dot(x_minus_mn, inv_covmat)
        D_square = K.dot(left_term, x_minus_mn_with_transpose)
        return D_square
    
    def covr1(y_true, y_pred):
        #x_mean = K.mean(y_true)
        #y_mean = K.mean(y_pred)
        Cov_numerator = K.sum(((y_true - y_pred)*(y_true - y_pred)))
        Cov_denomerator = len(Xtrainb)-1
        Covariance = (Cov_numerator / Cov_denomerator)
        return Covarianc
    
    conv1= Conv1D(filters=80, kernel_size=2, padding='same',   input_dim=Xtrainb.shape[1])(input_datab)
    maxpool = MaxPooling1D(pool_size=3, stride=3 )(conv1)
    conv2= Conv1D(filters=50, kernel_size=2, padding='same',   input_dim=Xtrainb.shape[1])(maxpool)
    maxpool = MaxPooling1D(pool_size=3, stride=3)(conv2)
    flatten = Flatten()(maxpool)
    dense = Dense(84, activation='relu')(flatten)
    dense = Dense(1024, activation='relu')(flatten)
    dense = Dense(densesize, activation='softmax')(dense)
    model = Model(inputs=[input_datab],outputs=[dense])
    model.compile(loss= mahalanobis,  optimizer='adam', metrics=['acc'])
    hist = model.fit(x_trainb, ytrainb, validation_data=(Xtestb, ytestb), epochs=epochs, batch_size=batch_size)",3,6
95,2019-10-13,2019,10,13,21,dh9uy5,nn_builder - builds neural networks with less boilerplate code,https://www.reddit.com/r/deeplearning/comments/dh9uy5/nn_builder_builds_neural_networks_with_less/,__data_science__,1570969104,"nn\_builder is a package that lets you build simple NNs, CNNs and RNNs in 1 line by reducing the amount of boilerplate code. It works with PyTorch and TensorFlow 2.0. Check it out!

https://github.com/p-christ/nn\_builder",2,8
96,2019-10-14,2019,10,14,1,dhd1xq,"AI Weekly News (October 13th, 2019) - PyTorch 1.3, Google's ROBEL, NVIDIA's inception showcase, and many more!",https://www.reddit.com/r/deeplearning/comments/dhd1xq/ai_weekly_news_october_13th_2019_pytorch_13/,HenryAILabs,1570985358,[removed],0,1
97,2019-10-14,2019,10,14,2,dhdpen,Eliminating car collisions with #AI,https://www.reddit.com/r/deeplearning/comments/dhdpen/eliminating_car_collisions_with_ai/,cmillionaire9,1570988320,,0,0
98,2019-10-14,2019,10,14,4,dhfjyr,2x Quadro RTX 5000 or Titan RTX,https://www.reddit.com/r/deeplearning/comments/dhfjyr/2x_quadro_rtx_5000_or_titan_rtx/,Red_HeadRedemption,1570996333,"I'm sorry, if you get tired from these kind of questions, but I got a special offer for 2 Quadro 5000s and I don't know what to do. At the moment I use a MSI 1060 Gaming 6G, but I wamt an upgrade. So there is the oppertunity to get a Titan RTX as well as 2 Quadro RTX 5000, both for 1900. Which one is the better choice ?",7,12
99,2019-10-14,2019,10,14,7,dhhivh,Data transmitting if you can not simulate noise,https://www.reddit.com/r/deeplearning/comments/dhhivh/data_transmitting_if_you_can_not_simulate_noise/,Filarius,1571005345,"I'm just start learning Deep Learning and being curious to see how NN will  find solution for problem from my hobby project.

I'm digging internet and can't find example what I can start from, or any really good idea to use.

I need to create Encoder and Decoder to transmit data over one noisy environment, and you can only observate noise by trasmitting data, and can not make right simulation of this noise. Transmition had to be made manually and take some time.

With my knowladge I think only about next:  
\- source data splited by small chunks, maybe start research with only 1 byte long chunk, next extract bits, so there will be 1D array of ones and zeros  
\- Encoder convert N bits into, lets say... 10\*N bytes

\- using Encoder convert pretty many source data, transmit all at one time, receive signal with noise.

\- and Decoder must recover bits from signal+noise with as low count of errors as possible

&amp;#x200B;

I did some research using things what people usually use to solve it in classic way, so I have starting point to choose data rate to be sure its really possible to recover data after this kind of noise.

 I wish NN Encoder and Deconder will learn noise pattern to allow highest possible data rate without any bit inverted.

But I have no idea where to start from to train NN.  There is Autoencoder NN whats look similar, but I can not simulate right kind of noise in programming code or make classical train because of problem definition. I wonder what will be best way to train NN to solve such problem.",0,3
100,2019-10-14,2019,10,14,7,dhhjx3,"AI Weekly Update #8 - October 13th, 2019!",https://www.reddit.com/r/deeplearning/comments/dhhjx3/ai_weekly_update_8_october_13th_2019/,HenryAILabs,1571005497,[https://youtu.be/cTevyDueL3Q](https://l.facebook.com/l.php?u=https%3A%2F%2Ft.co%2FB3ZqWfRvkW%3Famp%3D1%26fbclid%3DIwAR3zbWz-Ju6AjhIV01qvXNDdruTE9iYGXaWNW4C0roJz8dbZQvyNTqM6QUQ&amp;h=AT2jj0bMHOnY5NFnpl43iF1aHk__VrgSbAZp-nnbUOfTtcChInNrcuGyKx29pRjFVKLUeE74wIfRjp8oCeJbBGu3-uY1XPPOvBVSA_ZaQs5TEC8lBTdDv8qxIB-FJlC8Gm8SiwMvQLrQuB8qOVNUzMQPFGY),0,1
101,2019-10-14,2019,10,14,19,dhoplm,Business Benefits of Using Python for AI Projects,https://www.reddit.com/r/deeplearning/comments/dhoplm/business_benefits_of_using_python_for_ai_projects/,Rohan_Sharma124,1571049108,,0,0
102,2019-10-14,2019,10,14,21,dhpswp,Speech Noise Surpression,https://www.reddit.com/r/deeplearning/comments/dhpswp/speech_noise_surpression/,theShm00,1571055749,"Hey guys,

im starting to work on my masters thesis which should be heading in the direction of implementing a real time noise surpression for speech using neural networks. Im quite new to the field of DL/ML. Im looking for some good example code which helps me understand the procedures needed for training nets on audio. Ive come across the RNNoise project from Mozilla, which has its code open source: [https://people.xiph.org/\~jm/demo/rnnoise/](https://people.xiph.org/~jm/demo/rnnoise/) Trying to understand the code really confuses me atm. So while im trying to understand whats happening there, maybe some of you have some good resources that help me learn? Really nice would be a sort of End-to-End System, which directly outputs the noise free data. 

Do you have anymore tips you can give me as im starting with this topic for my thesis?

thank you :)",5,9
103,2019-10-14,2019,10,14,23,dhrfp3,A group of sites and courseware will benefit you too ..,https://www.reddit.com/r/deeplearning/comments/dhrfp3/a_group_of_sites_and_courseware_will_benefit_you/,saradinto,1571063811,[removed],0,1
104,2019-10-14,2019,10,14,23,dhrj07,Study group- deep learning for molecules generation,https://www.reddit.com/r/deeplearning/comments/dhrj07/study_group_deep_learning_for_molecules_generation/,mostafabenh,1571064227,"I am helping a friend to organize an online study group about neural networks for molecule generation, who is interested in participating?

 You need to be very motivated and have enough free time to study this topic

Add me on LinkedIn if you are interested:  https://www.linkedin.com/in/mostapha-benhenda",5,5
105,2019-10-15,2019,10,15,1,dht76e,[Research] New Dataset for DeepFake Forensics,https://www.reddit.com/r/deeplearning/comments/dht76e/research_new_dataset_for_deepfake_forensics/,cdossman,1571071299," A new dataset and detection algorithms for DeepFake Forensics  
[http://www.cs.albany.edu/\~lsw/celeb-deepfakeforensics.html](http://www.cs.albany.edu/~lsw/celeb-deepfakeforensics.html?fbclid=IwAR2CYyTv91KaEHykj5cN8X3Q_TCcn2auIrivCs5m5TpMs683_hamTXosSOs)",0,1
106,2019-10-15,2019,10,15,3,dhunvy,Pretrained model weights for generative chatbot for interactive conversation.,https://www.reddit.com/r/deeplearning/comments/dhunvy/pretrained_model_weights_for_generative_chatbot/,nik9993,1571077289,"Where can i get a pretrained model weights for rnn, seq2seq chatbot for general purpose interactive chatting.",0,1
107,2019-10-15,2019,10,15,4,dhvdqu,Career Advice in ML and how to read research papers - Andrew Ng's Notes,https://www.reddit.com/r/deeplearning/comments/dhvdqu/career_advice_in_ml_and_how_to_read_research/,deep_ak,1571080318,"Here I have made notes of the **Deep Learning CS230** Lecture given by ***Andrew Ng*** on how to navigate a career in ML/DL and how to read research papers.

[https://deeps.site/blog/2019/10/14/reading-research-papers-career-advice/](https://deeps.site/blog/2019/10/14/reading-research-papers-career-advice/)

The **one hour lecture** has been **summarised into concise 5 minutes** read to ***save out on your time*** with  
visualisations to enrich the delivered content.  


Hope it helps you to build on top of Andrew's insights and save time.",10,91
108,2019-10-15,2019,10,15,6,dhx6hu,Predict future image/cloud,https://www.reddit.com/r/deeplearning/comments/dhx6hu/predict_future_imagecloud/,nii3lsh,1571087492,"I have a lot of images of the sky at some location.   
It is well structured and I have plenty of them.   
Every 15 seconds there is a new picture and I have data of the last year(s).   


At the moment I use optical flow the predict an future image.   
I do this by detecting clouds and calculating the velocity by looking at multiple images in a row.   
2 are enough but it will be more accurate using more images. 

I was wondering if you guys could suggest me a deep learning method to do this? Or some papers that does something similar.  I was thinking of an CNN network where I input 2 images and the output will be 1 image. This image can I compare to the ground truth picture.

Anyone thinks if this might work? Or have other architecture suggestions?

Kind regards =D",0,1
109,2019-10-15,2019,10,15,6,dhxbc9,"Reinforcement Learning Chapter 8! This chapter unifies Model-based and Model-free learning and presents Monte Carlo Tree Search, a key component to the AlphaGo algorithm!",https://www.reddit.com/r/deeplearning/comments/dhxbc9/reinforcement_learning_chapter_8_this_chapter/,HenryAILabs,1571088056,[removed],0,1
110,2019-10-15,2019,10,15,10,di0cln,"Dataset to detect inappropriate content(nudity, violence,drugs etc.,) in images for content moderation",https://www.reddit.com/r/deeplearning/comments/di0cln/dataset_to_detect_inappropriate_contentnudity/,Nike_Zoldyck,1571101858,"I'm looking for some information on how the content filtering works in Facebook, Instagram etc to flag nudity, violence, offensive or toxic comments,religious and racial stereotypes etc. I wasn't able to find any scientific papers about the inner workings or the use of deep learning or Computer vision for it. I'm fairly new to CV and i'm hoping for some guidance on a data set , perhaps for detecting inappropriate content on T-shirts in retail. Any suggestions on how to go about searching or to create a dataset and what to keep in mind? Any algorithms to focus on like yolov3 or faster RCNN to read the text on the t-shirts and understand the context of it would also be extremely helpful",0,0
111,2019-10-15,2019,10,15,11,di13oc,Using RTX 2080 Ti and GTX 1080 Ti in the same computer for distributed training,https://www.reddit.com/r/deeplearning/comments/di13oc/using_rtx_2080_ti_and_gtx_1080_ti_in_the_same/,deep_888,1571105704,"Currently, I have a single GTX 1080 Ti but it is easy to overflow when running large jobs. I'd like to set up a double-GPU workstation and train the model using PyTorch distributed. I read some posts saying that using two different GPUs in one build can work, so I'm considering buying an RTX 2080 Ti. My questions are: 

1. What's the performance of using a combination of RTX 2080 Ti + GTX 1080 Ti, compared to using two GTX 1080 Ti, for PyTorch distributed training? Any communication problem?
2. My motherboard is ROG STRIX Z390-E GAMING, which supports PCI-E 3.0 X16 for single GPU and X8 + X8 for two GPUs. Under this condition, if I buy RTX 2080 Ti as the second GPU, will the performance be equal to that of two GTX 1080 Ti?

Thank you very much in advance!",2,7
112,2019-10-15,2019,10,15,17,di4ome,Is Deep Learning Already Hitting its Limitations?,https://www.reddit.com/r/deeplearning/comments/di4ome/is_deep_learning_already_hitting_its_limitations/,RubiksCodeNMZ,1571126935,,0,1
113,2019-10-15,2019,10,15,17,di4p6s,Neural Graph Learning: Training Neural Networks Using Graphs - paper,https://www.reddit.com/r/deeplearning/comments/di4p6s/neural_graph_learning_training_neural_networks/,RubiksCodeNMZ,1571127039,,0,3
114,2019-10-15,2019,10,15,17,di4t42,Implementation of a character based CNN for text classification in PyTorch + Video Demo,https://www.reddit.com/r/deeplearning/comments/di4t42/implementation_of_a_character_based_cnn_for_text/,ahmedbesbes,1571127799,,0,4
115,2019-10-15,2019,10,15,18,di57s1,How a neural net automatically learn the new data in prod?,https://www.reddit.com/r/deeplearning/comments/di57s1/how_a_neural_net_automatically_learn_the_new_data/,redditaddict07,1571130632,"I am a novice trying to implemented Siamese-LSTM with co-attention to re-write user search queries to queries we understand or we can serve. Still not sure about the architecture or end to end flow. Please correct me if something is missing or wrongly assumed.

Example - 

**Female pregnancy clothe** to  **Women maternity dress.**

As suggested in attached [paper](https://cse.iitkgp.ac.in/~pawang/papers/sigir19.pdf), I will train LSTM on a data-set having two queries(x1, x2), y = 1(same) / 0 (not same).

Once trained and tested, 

I will deploy final model in prod. 

1. Whether it will be a sequence to sequence generation type model, we use for language translation or it will map user entered query to one of our input query **?**   
  \[I prefer to generate a new sequence(s) corresponding to the user entered sequence\] 
2.  Cannot understand, how this model will accommodate new queries which are very specific to our organisation/customers**?** Will I have to retrain the model again and again after analysing the new queries?

\---

It will be really appreciative,  If you can mentor or partner with me for this project. Thank you!",0,1
116,2019-10-15,2019,10,15,20,di6tff,Zooming into the world of computer vision applications,https://www.reddit.com/r/deeplearning/comments/di6tff/zooming_into_the_world_of_computer_vision/,amarsingh1990,1571140525,,0,1
117,2019-10-15,2019,10,15,21,di76je,Properly setting up Linux for DL,https://www.reddit.com/r/deeplearning/comments/di76je/properly_setting_up_linux_for_dl/,AusBarbell,1571142541,"Hi, I'm currently dual booting Ubuntu 18.04 and windows on separate SSDs but I've managed to mess something up and have trouble booting into windows. Are there any tips or guides that I can follow to get a Linux OS up and running with pytorch and full GPU function without affecting my windows installation?",3,3
118,2019-10-15,2019,10,15,22,di7u1g,How to extract features from images,https://www.reddit.com/r/deeplearning/comments/di7u1g/how_to_extract_features_from_images/,nerdy_wits,1571145753,,0,0
119,2019-10-15,2019,10,15,23,di8ioz,[Research] Google AI: Robotics Benchmarks for Learning with Low-Cost Robots,https://www.reddit.com/r/deeplearning/comments/di8ioz/research_google_ai_robotics_benchmarks_for/,cdossman,1571148957," [https://medium.com/ai%C2%B3-theory-practice-business/modular-easy-to-build-and-extend-and-open-source-robotic-platforms-ca719585fb50](https://medium.com/ai%C2%B3-theory-practice-business/modular-easy-to-build-and-extend-and-open-source-robotic-platforms-ca719585fb50) 

**Abstract:**  ROBEL is an open-source platform of cost-effective robots designed for reinforcement learning in the real world. ROBEL introduces two robots, each aimed to accelerate reinforcement learning research in different task domains: DClaw is a three-fingered hand robot that facilitates learning dexterous manipulation tasks, and DKitty is a four-legged robot that facilitates learning agile legged locomotion tasks. These low-cost, modular robots are easy to maintain and are robust enough to sustain on-hardware reinforcement learning from scratch with over 14000 training hours registered on them to date. To leverage this platform, we propose an extensible set of continuous control benchmark tasks for each robot. These tasks feature dense and sparse task objectives and additionally introduce score metrics as hardware-safety. We provide benchmark scores on an initial set of tasks using a variety of learning-based methods. Furthermore, we show that these results can be replicated across copies of the robots located in different institutions.   [https://ai.googleblog.com/2019/10/robel-robotics-benchmarks-for-learning.html](https://ai.googleblog.com/2019/10/robel-robotics-benchmarks-for-learning.html)",0,0
120,2019-10-16,2019,10,16,1,dia26s,Trade Smarter w/ Deep Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/dia26s/trade_smarter_w_deep_reinforcement_learning/,notadamking,1571155727,,2,1
121,2019-10-16,2019,10,16,1,diah50,"Workshop on Theory of Deep Learning by IAS from Oct 15 to Oct 18 2019. Few talks presented here will also be presented at Neurips2019 / Nips2019. Day1: GAN optimization, Hierarchical learning (Spotlight talk), Curse of dimensionality.",https://www.reddit.com/r/deeplearning/comments/diah50/workshop_on_theory_of_deep_learning_by_ias_from/,adssidhu86,1571157467,,0,18
122,2019-10-16,2019,10,16,1,diandi,What is Causal Convolution?,https://www.reddit.com/r/deeplearning/comments/diandi/what_is_causal_convolution/,Sameer3079,1571158170,"I know that it is related to sequential data (time series), but I don't know what it is exactly.",4,13
123,2019-10-16,2019,10,16,3,dibwxg,Workshop on Theory of Deep Learning: Where next?,https://www.reddit.com/r/deeplearning/comments/dibwxg/workshop_on_theory_of_deep_learning_where_next/,aiforworld2,1571163291,"Workshop on Theory of Deep Learning: Where next?

2019-2020

Tuesday, October 15, 2019 - 09:00toFriday, October 18, 2019 - 06:00

At Institute for Advanced Studies 
Princeton University 

#deeplearning

Live Stream: https://www.ias.edu/livestream",0,8
124,2019-10-16,2019,10,16,5,die18r,Explaining OpenAI's Robotic Hand Rubik's Cube Solver!,https://www.reddit.com/r/deeplearning/comments/die18r/explaining_openais_robotic_hand_rubiks_cube_solver/,HenryAILabs,1571171856,"This video will explain some of the details behind the amazing research study from OpenAI using a Meta-Learning Automatic Domain Randomization algorithm to bridge the Sim2Real gap and solve a Rubik's Cube with a Robotic Hand!!

https://youtu.be/2AqGocPOOG4",2,1
125,2019-10-16,2019,10,16,5,died8k,How convert custom Keras code to Onnx?,https://www.reddit.com/r/deeplearning/comments/died8k/how_convert_custom_keras_code_to_onnx/,74throwaway,1571173184,"I'm using the code from https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb

I'm trying to use keras2onnx with it also. I tried

	import keras2onnx
	import onnxruntime

	# convert to onnx model
	onnx_model = keras2onnx.convert_keras(model, model.name)

	# runtime prediction
	content = onnx_model.SerializeToString()
	sess = onnxruntime.InferenceSession(content)
	x = x if isinstance(x, list) else [x]
	feed = dict([(input.name, x[n]) for n, input in enumerate(sess.get_inputs())])
	pred_onnx = sess.run(None, feed)

But I got the following error:

	InvalidArgumentError                      Traceback (most recent call last)
	~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
	    426         results = c_api.TF_GraphImportGraphDefWithResults(
	--&gt; 427             graph._c_graph, serialized, options)  # pylint: disable=protected-access
	    428         results = c_api_util.ScopedTFImportGraphDefResults(results)

	InvalidArgumentError: Node 'block1b_drop/cond/mul/y': Unknown input node '^block1b_drop/cond/switch_t'

	During handling of the above exception, another exception occurred:

	ValueError                                Traceback (most recent call last)
	&lt;ipython-input-16-a5d3ba8b443c&gt; in &lt;module&gt;
	      3 
	      4 # convert to onnx model
	----&gt; 5 onnx_model = keras2onnx.convert_keras(model, model.name)
	      6 
	      7 # runtime prediction

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/main.py in convert_keras(model, name, doc_string, target_opset, channel_first_inputs, debug_mode, custom_op_conversions)
	     98                         custom_op_dict=custom_op_conversions)
	     99     topology.debug_mode = debug_mode
	--&gt; 100     parse_graph(topology, sess.graph, target_opset, output_names)
	    101     topology.compile()
	    102 

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/parser.py in parse_graph(topo, graph, target_opset, output_names)
	    647         topo.raw_model.add_input_name(str_value)
	    648 
	--&gt; 649     return _parse_graph_scope(graph, keras_layer_ts_map, topo, top_level, output_names)

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/parser.py in _parse_graph_scope(graph, keras_node_dict, topology, top_scope, output_names)
	    597             _convert_keras_timedistributed(graph, nodes, layer_key_, model_, varset)
	    598         elif layer_key_ is None or get_converter(type(layer_key_)) is None:
	--&gt; 599             _convert_general_scope(nodes, varset)
	    600         else:
	    601             _convert_keras_scope(graph, nodes, layer_key_, model_, varset)

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/parser.py in _convert_general_scope(node_list, varset)
	    299 
	    300     sess = keras.backend.get_session()
	--&gt; 301     subgraph, replacement = create_subgraph(sess.graph, node_list, sess, operator.full_name)
	    302     setattr(operator, 'subgraph', subgraph)
	    303     vars_, ts = _locate_inputs_by_node(node_list, varset)

	~/anaconda3/lib/python3.6/site-packages/keras2onnx/subgraph.py in create_subgraph(tf_graph, node_list, sess, dst_scope)
	    135     with tf.Graph().as_default() as sub_graph:
	    136         im_scope = """" if dst_scope is None else dst_scope
	--&gt; 137         tf.import_graph_def(output_graph_def, name=im_scope)
	    138         if im_scope:
	    139             replacement = {k_: im_scope + '/' + k_ for k_ in replacement}

	~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
	    505                 'in a future version' if date is None else ('after %s' % date),
	    506                 instructions)
	--&gt; 507       return func(*args, **kwargs)
	    508 
	    509     doc = _add_deprecated_arg_notice_to_docstring(

	~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
	    429       except errors.InvalidArgumentError as e:
	    430         # Convert to ValueError for backwards compatibility.
	--&gt; 431         raise ValueError(str(e))
	    432 
	    433     # Create _DefinedFunctions for any imported functions.

	ValueError: Node 'block1b_drop/cond/mul/y': Unknown input node '^block1b_drop/cond/switch_t'",0,0
126,2019-10-16,2019,10,16,9,dihht2,I want to train a neural network on my e-mails to generate text that sounds like me. how?,https://www.reddit.com/r/deeplearning/comments/dihht2/i_want_to_train_a_neural_network_on_my_emails_to/,britcruise,1571187029,are there cloud services which I can access to train a recurrent network on any text I want to provide? looking to just have some fun,9,6
127,2019-10-16,2019,10,16,11,dij2p2,image segmentation: why use u-net for tasks that would benefit from instance segmentation,https://www.reddit.com/r/deeplearning/comments/dij2p2/image_segmentation_why_use_unet_for_tasks_that/,molly12219,1571194755,"ive noticed a lot of people used u-net for tasks like nucleus segmentation and achieved great results.

doesn't u-net use semantic segmentation? im confused why you wouldn't use mask r-cnn for instance segmentation?

im clearly missing something. can someone explain?",3,14
128,2019-10-16,2019,10,16,17,dimhjh,"In autonomous driving, I want to use deep learning to judge whether the camera is occluded(clean, blur, blocked).",https://www.reddit.com/r/deeplearning/comments/dimhjh/in_autonomous_driving_i_want_to_use_deep_learning/,leozyc,1571215776,"I want to do research on autonomous driving cameras.

In autonomous driving, I want to use deep learning to detect various situations of partial visibility loss, for example, camera overlapping by obstacles, blur , blocked, etc.

What should I do?",2,1
129,2019-10-16,2019,10,16,18,dimunw,NLP - Classification problem,https://www.reddit.com/r/deeplearning/comments/dimunw/nlp_classification_problem/,MistaPrincu,1571218381,"Hi,

Im currently analyzing raw customer reviews .
I cleaned, audited and I used different models to represent textual data ( Word2Vec, Bert). 

I applied Kmeans clustering on this representation and manage to identify useless comment. The idea now is to find a way to analyze the remaining reviews, that are not superrr linearly separable.

I tried LDA, and other clustering algos such as GMM and sphericals but no concluding results.


Do you have any suggestions ? 


Thank you in advance  !",1,3
130,2019-10-16,2019,10,16,22,dipmu0,Introduction to Adversarial Machine Learning,https://www.reddit.com/r/deeplearning/comments/dipmu0/introduction_to_adversarial_machine_learning/,pirate7777777,1571234047,,0,24
131,2019-10-17,2019,10,17,1,dirn2b,Padding tensorflow dataset sequences to a maximum length,https://www.reddit.com/r/deeplearning/comments/dirn2b/padding_tensorflow_dataset_sequences_to_a_maximum/,shahriar49,1571242893,"I have a TFRecord format dataset spread over multiple files with each element in each file being a tuple of (data, label). Data itself is an nx12 array, for which n is variable from element to element. Therefore, I have added the number of rows in the features of each TFRecord entry and then parse it as below:

&amp;#x200B;

    
    featuresDict = {'data': tf.FixedLenFeature([], dtype=tf.string),
                    'rows': tf.FixedLenFeature([], dtype=tf.int64),
                    'label': tf.FixedLenFeature([], dtype=tf.int64)
                   }
        
    def parse_tfrecord(example):
        features = tf.parse_single_example(example, featuresDict)
        label = features['label']
        weight = classWeights[features['label']]
        rows = features['rows']
        data = tf.decode_raw(features['data'], tf.int64)
        data = tf.reshape(data, (rows,12))
        return data, label, weight
        
    def read_datasets(pattern, numFiles, numEpochs=None, batchSize=None):
        files = tf.data.Dataset.list_files(pattern)
    
        def _parse(x):
            x = tf.data.TFRecordDataset(x, compression_type='GZIP')
            return x
       
        dataset = files.interleave(_parse, cycle_length=numFiles, block_length=1).map(parse_tfrecord)
        dataset = dataset.prefetch(buffer_size=batchSize)
        dataset = dataset.repeat(numEpochs)
        return dataset
    

I have used padded\_batch (in read\_datasets function) to fix the input size per batch and it works fine. But I want to do a test with setting a global length for padding such as 100 (same for all batches). I tried with adding this line:

&amp;#x200B;

        data = tf.pad(data, tf.constant([[0,100-rows],[0,0]]))
    

to the parse\_tfrecord() function right before return clause, but I get below error:

&amp;#x200B;

          File ""C:/Users/sshahhey.ESFADMIN.000/.PyCharmCE2019.2/config/scratches/scratch.py"", line 423, in doWork
            test_data = read_datasets(files_test, numFiles, numEpochs=1, batchSize=batch_size)
          File ""C:/Users/sshahhey.ESFADMIN.000/.PyCharmCE2019.2/config/scratches/scratch.py"", line 84, in read_datasets
            dataset = files.interleave(_parse, cycle_length=numFiles, block_length=1, num_parallel_calls=min(numFiles,np)).map(parse_tfrecord, num_parallel_calls=np)
          File ""C:\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1040, in map
            return ParallelMapDataset(self, map_func, num_parallel_calls)
          File ""C:\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 2649, in __init__
            use_inter_op_parallelism)
          File ""C:\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 2611, in __init__
            map_func, ""Dataset.map()"", input_dataset)
          File ""C:\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1860, in __init__
            self._function.add_to_graph(ops.get_default_graph())
          File ""C:\Python36\lib\site-packages\tensorflow\python\framework\function.py"", line 479, in add_to_graph
            self._create_definition_if_needed()
          File ""C:\Python36\lib\site-packages\tensorflow\python\framework\function.py"", line 335, in _create_definition_if_needed
            self._create_definition_if_needed_impl()
          File ""C:\Python36\lib\site-packages\tensorflow\python\framework\function.py"", line 344, in _create_definition_if_needed_impl
            self._capture_by_value, self._caller_device)
          File ""C:\Python36\lib\site-packages\tensorflow\python\framework\function.py"", line 864, in func_graph_from_py_func
            outputs = func(*func_graph.inputs)
          File ""C:\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1794, in tf_data_structured_function_wrapper
            ret = func(*nested_args)
          File ""C:/Users/sshahhey.ESFADMIN.000/.PyCharmCE2019.2/config/scratches/scratch.py"", line 73, in parse_tfrecord
            data = tf.pad(data, tf.constant([[0, 100-rows],[0,0]]))
          File ""C:\Python36\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 208, in constant
            value, dtype=dtype, shape=shape, verify_shape=verify_shape))
          File ""C:\Python36\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 442, in make_tensor_proto
            _AssertCompatible(values, dtype)
          File ""C:\Python36\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 350, in _AssertCompatible
            raise TypeError(""List of Tensors when single Tensor expected"")
        TypeError: List of Tensors when single Tensor expected
    

What is the problem with it and how can I solve it?

&amp;#x200B;

P.S. The reason that I want to impose a global pad is that I get incompatible results when testing a trained model with different batch combinations (having the same model, the aggregation of test results from two separate datasets are not the same as if I interleave both datasets and apply them to the model). So I was suspicious that dynamic per-batch padding may cause this difference.",0,1
132,2019-10-17,2019,10,17,1,dis29u,The Pattern Machine (DL series by Art of the Problem),https://www.reddit.com/r/deeplearning/comments/dis29u/the_pattern_machine_dl_series_by_art_of_the/,britcruise,1571244622,,0,3
133,2019-10-17,2019,10,17,2,disqhg,"Optimizers in Neural Networks Explained: The Math Clearly Explained and Visualization for your Intuition - Adam, RMSprop, AdaGrad, Momentum and Stochastic Gradient Descent.",https://www.reddit.com/r/deeplearning/comments/disqhg/optimizers_in_neural_networks_explained_the_math/,permalip,1571247328,,0,1
134,2019-10-17,2019,10,17,2,dit0rv,Simple Latent/Feature Space Augmentation methods improve BERT's classification performance,https://www.reddit.com/r/deeplearning/comments/dit0rv/simple_latentfeature_space_augmentation_methods/,intvar,1571248498,"[https://arxiv.org/abs/1910.04176](https://arxiv.org/abs/1910.04176)  


This paper shows that simple methods like upsampling, random perturbation improves BERT classification performance. Moreover, these methods are almost as good as complex methods such as CVAE, Delta Encoder etc.",0,2
135,2019-10-17,2019,10,17,4,diukh3,[Natural Language Processing] Extracting attention weights of each token at each layer of transformer in python,https://www.reddit.com/r/deeplearning/comments/diukh3/natural_language_processing_extracting_attention/,h56cho,1571254918,"I am doing some NLP and I am interested in extracting attention weights of individual test token at each layer of transformer via Python.

Is coding up a Transformer (any transformers like Transformer-XL, OpenAL-GPT, GPT2 ,etc.) from the scratch the only way to get attention weights of individual test token at each transformer layer? Is there easier way to perform this task in Python?

Thank you,",2,1
136,2019-10-17,2019,10,17,4,diur96,Artificial intelligence will begin to add ads to films,https://www.reddit.com/r/deeplearning/comments/diur96/artificial_intelligence_will_begin_to_add_ads_to/,cmillionaire9,1571255684,,1,2
137,2019-10-17,2019,10,17,5,divkmr,Best Deep Learning Courses Updated 2019,https://www.reddit.com/r/deeplearning/comments/divkmr/best_deep_learning_courses_updated_2019/,data_datum,1571259030,[https://blog.floydhub.com/best-deep-learning-courses-updated-for-2019/](https://blog.floydhub.com/best-deep-learning-courses-updated-for-2019/),0,1
138,2019-10-17,2019,10,17,11,dj02ev,PyTorch or die,https://www.reddit.com/r/deeplearning/comments/dj02ev/pytorch_or_die/,philippemnoel,1571279946,,23,139
139,2019-10-17,2019,10,17,16,dj2qew,computer vision eye tracking with pupils.,https://www.reddit.com/r/deeplearning/comments/dj2qew/computer_vision_eye_tracking_with_pupils/,tayyabikhlaq,1571296057," 

Hi everyone!

I need some help from you.I want to create an extension which use computer vision to detect where our eye pupil is exactly looking at exact pixel on the screen.

Also kindly answer these questions.

1)Which framework i should use for that purpose?

2)How to integrate it with web browser ?

3)Plz share your resources from wherever they are.

Thank you.",3,2
140,2019-10-17,2019,10,17,20,dj5b44,Automating Business Operations with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/dj5b44/automating_business_operations_with_artificial/,aakansha_chaudhary,1571313268,,0,1
141,2019-10-17,2019,10,17,22,dj6kc3,Julia vs Swift for Deep Learning,https://www.reddit.com/r/deeplearning/comments/dj6kc3/julia_vs_swift_for_deep_learning/,jyoti_6727,1571319694,"Hello, 

I've been using Python for all of my deep learning needs. I am looking to learn another language. Which one would  be better, julia or swift?

Thanks!",5,1
142,2019-10-17,2019,10,17,23,dj7eah,https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-1-a-brief-introduction-a53a849771cf,https://www.reddit.com/r/deeplearning/comments/dj7eah/httpsmediumcomaic2b3theorypracticebusinessreinforc/,cdossman,1571323560,,0,1
143,2019-10-17,2019,10,17,23,dj7f9x,"[Guide] Reinforcement Learning, Part 1: A Brief Introduction",https://www.reddit.com/r/deeplearning/comments/dj7f9x/guide_reinforcement_learning_part_1_a_brief/,cdossman,1571323681,,0,2
144,2019-10-18,2019,10,18,0,dj7m2u,Does Adversarial Example Robustness imply Traditional Perturbation Robustness ?,https://www.reddit.com/r/deeplearning/comments/dj7m2u/does_adversarial_example_robustness_imply/,alfredlaugros,1571324525,"An answer is provided in our paper accepted at ICCV 2019 RLQ Workshop :

[https://arxiv.org/abs/1909.02436](https://arxiv.org/abs/1909.02436)",0,9
145,2019-10-18,2019,10,18,0,dj7q7v,How can I study 10+ hours a day?,https://www.reddit.com/r/deeplearning/comments/dj7q7v/how_can_i_study_10_hours_a_day/,saradinto,1571325014," 

Ive done that for six years, every single day. Weekends, vacations. I wrote an entire book on the topic.

But first, let me tell what to do : *not* that.

Asking    this question, what you ask is really pointless. Your goal should be,    for instance, a certain grade, or being in the top ten percent of  your   class at university. That would be a wiser choice.

What    is the point of studying a lot and go straight to burnout (been  there,   done that), when you can actually be efficient, and work  towards   meaningful objectives, such as grades ?

If you *have* to study ten hours a day every day for more than a year, then something is wrong. *You*    are doing something wrong. For there are a few very hard programs   which  will push you to your limits purposefully, but they often dont   last  this long. Im speaking of the military for instance.

Even    if your grades matter as much as your life, if they can make the    difference between being happy for the rest of it or totally miserable,    as was my case, you dont need to do that.

I    was plagued with life-threatening psychological conditions. I wasnt    sleeping (worst thing for a student). Nightmares every night. I was    deeply depressed, on the border of psychiatric hospital for essentially    the whole [time](http://edumefree.com/welcome/CourseDetails/757/Time-Management-Skills).

The quality of my study was thus, understandably poor.

I *had*    to get efficient. I wasnt fully myself. Its as if I was drunk for    most of the time. Theoretical Physics when youre drunk is hard. Yet I    managed to be on the top of my class for five years, with the highest    grades, and get into Cambridge (in arguably one of the hardest  programs   in the world). And there, you were brutalized if you went  along what  you  were said. Pointless overly difficult exercises.  Basically a kind  of  military boot camp for the mind.

I    wrote an entire book on how you can study efficiently. Its aimed   first  at scientists, but 3/4 of it are applicable to any students.

[Here is](https://www.quora.com/How-do-top-students-manage-their-study-time/answer/Beno%C3%AEt-Seron-2) an example of my ideas.

If you like them, checkout my book ! Most of it is free, on my blog.",1,0
146,2019-10-18,2019,10,18,0,dj7z70,Sotabench: Benchmarking Open Source Models Directly From GitHub,https://www.reddit.com/r/deeplearning/comments/dj7z70/sotabench_benchmarking_open_source_models/,Yuqing7,1571326107,,0,1
147,2019-10-18,2019,10,18,9,djf7io,Any pre-trained models geared towards top-view human detection?,https://www.reddit.com/r/deeplearning/comments/djf7io/any_pretrained_models_geared_towards_topview/,aweeeezy,1571357583,"I'm working on a project that involves detecting/tracking people using an overhead mounted camera (could go either way with regards to standard vs. fish eye lens). 

None of the models I've been benchmarking (MobileNet SSD, YOLOv3, Faster R-CNN, etc.) have had any success when running inference on [top-view footage like this](https://www.youtube.com/watch?v=ReKpjZDRjiE).

Non-deep-learning approaches to human detection from this perspective seem a little daunting at the present moment and I'm in a bit of a time crunch that is making me nervous when thinking about implementing some of the [research I've looked at](https://eprints.soton.ac.uk/363113/). However, as time goes on, it unfortunately seems that this may be the only path forward for me.

Again, the time crunch makes training models an unviable path -- I'm _really_ hoping to find some pre-trained human detection model which I can compile to a tflite model, test, and deploy in the next couple weeks.

Has anyone come across something like this?",17,9
148,2019-10-18,2019,10,18,17,djkd52,Business Benefits of Using Python for AI Projects,https://www.reddit.com/r/deeplearning/comments/djkd52/business_benefits_of_using_python_for_ai_projects/,aaku-101,1571386161,,0,1
149,2019-10-18,2019,10,18,17,djkq4i,visualizing yolo v3,https://www.reddit.com/r/deeplearning/comments/djkq4i/visualizing_yolo_v3/,nanno3000,1571388825,"im looking for ways to visualize the detections that yolo v3 makes. I've found some libraries that do this for yolo v1 or v2, but they don't work on v3.

I want to see how the layer and filter activations look. Something like a detection heatmap ([like here](https://github.com/xueeinstein/darknet-vis)) would be awesome as well.

Does anyone know a repo that does this, or is there a (decently easy) way to do it from scratch?  


the mentioned github repos that dont work:

[github.com/schwittlick/ofxDarknet](https://github.com/schwittlick/ofxDarknet)

[https://github.com/xueeinstein/darknet-vis](https://github.com/xueeinstein/darknet-vis)",0,0
150,2019-10-18,2019,10,18,18,djl2g3,Python Tutorial for Computer Vision and Face Detection with OpenCV,https://www.reddit.com/r/deeplearning/comments/djl2g3/python_tutorial_for_computer_vision_and_face/,Rogers911z,1571391312, [https://www.youtube.com/watch?v=cmyXoFS3G00](https://www.youtube.com/watch?v=cmyXoFS3G00),0,1
151,2019-10-18,2019,10,18,19,djld2z,Research papers.,https://www.reddit.com/r/deeplearning/comments/djld2z/research_papers/,kuthubuddinshaik123,1571393333,"Where can I find them?  
Any particular blog or page?.
For ML &amp; AI.",13,6
152,2019-10-18,2019,10,18,20,djm1sm,Data Science with Deep learning,https://www.reddit.com/r/deeplearning/comments/djm1sm/data_science_with_deep_learning/,tejasree15,1571397622,,0,1
153,2019-10-18,2019,10,18,20,djm4pv,"Get Registered with Deep Learning Training Free Interactive session on, 19th Oct, 10 AM, Hyderabad by Analytics Path",https://www.reddit.com/r/deeplearning/comments/djm4pv/get_registered_with_deep_learning_training_free/,Jony1223,1571398101,,0,1
154,2019-10-18,2019,10,18,20,djm86j,"When a plane crashes they look for black box for the reasons, but when a deep learning solution crashes they look for black box and then look at each other and look at black box and look at each other and look at...",https://www.reddit.com/r/deeplearning/comments/djm86j/when_a_plane_crashes_they_look_for_black_box_for/,ashutoshatpandey,1571398654,,0,0
155,2019-10-18,2019,10,18,21,djmuhh,Neural Network weights initialization,https://www.reddit.com/r/deeplearning/comments/djmuhh/neural_network_weights_initialization/,maciej386,1571401993,"Initialiation of weights is very important for a successful training.

However, all initializations I have seen so far are initializations of a particular layer of neural network in isolation in function of the number of incoming or outgoing neurons.

Is there a deep reason for that or it's just that noone has tried to look into it so far?",4,2
156,2019-10-18,2019,10,18,21,djn3ha,8 GPU Monster Build Thoughts for Deep Learning,https://www.reddit.com/r/deeplearning/comments/djn3ha/8_gpu_monster_build_thoughts_for_deep_learning/,eCurb247,1571403272,"I was thinking of building an 8 GPU build for expandability but struggle to find much on this or guides from anyone who's done it. 

Does anyone know of any useful resources towards it?
Is it much more hassle than a 4GPU build?",12,3
157,2019-10-18,2019,10,18,22,djn916,Padded_batch with pre-padding,https://www.reddit.com/r/deeplearning/comments/djn916/padded_batch_with_prepadding/,shahriar49,1571404023,"I have a dataset of variable-length sequences to feed an LSTM network in Tensorflow/Keras and I want to try and compare pre- and post-padding in the batches, but current padded\_batch function only pads at the sequences end. I know that  pad\_sequences function in keras do padding at either side, but I don't know how to use this function for padded\_batch. My code right now is like this, and I am reading multiple TFRecord files and interleave them to make my mixed dataset:

    featuresDict = {'data': tf.FixedLenFeature([], dtype=tf.string),
                    'rows': tf.FixedLenFeature([], dtype=tf.int64),
                    'label': tf.FixedLenFeature([], dtype=tf.int64)
                   }
    
    def parse_tfrecord(example):
        features = tf.parse_single_example(example, featuresDict)
        label = tf.one_hot(features['label'],N)
        rows = features['rows']
        data = tf.decode_raw(features['data'], tf.int64)
        data = tf.reshape(data, (rows,num_features)
        return data, label
    
    def read_datasets(pattern, numFiles, numEpochs=None, batchSize=None):
        files = tf.data.Dataset.list_files(pattern)
    
        def _parse(x):
            x = tf.data.TFRecordDataset(x, compression_type='GZIP')
            return x
    
        dataset = files.interleave(_parse, cycle_length=numFiles, block_length=1).map(parse_tfrecord)
        padded_shapes = (tf.TensorShape([None, num_features]), tf.TensorShape([N,])))
        dataset = dataset.padded_batch(batchSize, padded_shapes)
        dataset = dataset.prefetch(buffer_size=batchSize)
        dataset = dataset.repeat(numEpochs)
        return dataset",0,5
158,2019-10-18,2019,10,18,22,djnade,Would love you to find mistakes/problems with the outline for my next video on Neural Network history (for my channel art of the problem),https://www.reddit.com/r/deeplearning/comments/djnade/would_love_you_to_find_mistakesproblems_with_the/,britcruise,1571404205,,0,4
159,2019-10-18,2019,10,18,22,djnn01,Energy-based Approaches to Representation Learning - Yann LeCun,https://www.reddit.com/r/deeplearning/comments/djnn01/energybased_approaches_to_representation_learning/,DrJohanson,1571405907,,1,31
160,2019-10-19,2019,10,19,0,djp5dv,Reinforcement learning: Number of epochs not matching calculation in paper.,https://www.reddit.com/r/deeplearning/comments/djp5dv/reinforcement_learning_number_of_epochs_not/,rrz0,1571412717,"I am trying to reproduce results presented in this \[paper\]\[1\]. On page 4, the authors state:

&amp;#x200B;

\&gt; ... we train for 50 epochs (one epoch consists of 19\*2\*50 = 1900 full

\&gt; episodes), which amounts to a total of 4.75\*10\^6 timesteps.

&amp;#x200B;

The 1900 episodes are broken down into Rollouts per MPI worker (2) \* Number of MPI Workers (19) \* Cycles per epoch (50), as shown in the hyper parameters section on page 10.

&amp;#x200B;

When testing on my local machine, using the GitHub \[Baselines repo\]\[2\], I am using 1 MPI worker and the following hyperparams:

&amp;#x200B;

'n\_cycles': 50,  # per epoch

'rollout\_batch\_size': 2,  # per mpi thread

&amp;#x200B;

By the same calculation, this means that I should have 1\*50\*2 = 100 episodes per epoch.

&amp;#x200B;

However when I run \`her\` on \`FetchReach-v1\` turns out I only have 10 episodes per epoch. Her is a log sample:

&amp;#x200B;

&amp;#x200B;

Training...

\---------------------------------

| epoch              | 0        |

| stats\_g/mean       | 0.893    |

| stats\_g/std        | 0.122    |

| stats\_o/mean       | 0.269    |

| stats\_o/std        | 0.0392   |

| test/episode       | 10       |

| test/mean\_Q        | -0.602   |

| test/success\_rate  | 0.5      |

| train/episode      | 10       |  &lt;-- 10 episodes/epoch

| train/success\_rate | 0        |

\---------------------------------

&amp;#x200B;

Why is there this discrepancy? Any suggestions would be appreciated.

&amp;#x200B;

&amp;#x200B;

  \[1\]: [https://arxiv.org/pdf/1802.09464.pdf](https://arxiv.org/pdf/1802.09464.pdf)

  \[2\]: [https://github.com/openai/baselines](https://github.com/openai/baselines)",0,2
161,2019-10-19,2019,10,19,4,djs7bf,Semi-automatic image annoation tool for computer vision tasks. Opensource on github.,https://www.reddit.com/r/deeplearning/comments/djs7bf/semiautomatic_image_annoation_tool_for_computer/,gitarre94,1571425648,,0,3
162,2019-10-19,2019,10,19,5,djtk63,Why is random normal weight initialisation preferred over random uniform weight initialisation in neural networks?,https://www.reddit.com/r/deeplearning/comments/djtk63/why_is_random_normal_weight_initialisation/,pranav2109,1571431432,,5,5
163,2019-10-19,2019,10,19,7,djuxwf,Faces of DeepFake,https://www.reddit.com/r/deeplearning/comments/djuxwf/faces_of_deepfake/,cmillionaire9,1571437756,,3,48
164,2019-10-19,2019,10,19,21,dk37q5,pytorch 1.3 namedtensor,https://www.reddit.com/r/deeplearning/comments/dk37q5/pytorch_13_namedtensor/,stevethesteve2,1571488679,"How helpful is the new API?

I dont see how I can expressively write down

mytensor2 = mytensor1\[:,:-1\]

using the new API",1,5
165,2019-10-19,2019,10,19,22,dk3h7b,[Article] The Difference Between AI and Machine Learning,https://www.reddit.com/r/deeplearning/comments/dk3h7b/article_the_difference_between_ai_and_machine/,cdossman,1571490142,,0,0
166,2019-10-19,2019,10,19,23,dk4g7d,Benchmarking /Transformers on both PyTorch and TensorFlow,https://www.reddit.com/r/deeplearning/comments/dk4g7d/benchmarking_transformers_on_both_pytorch_and/,jikkii,1571495210,"Since our recent release of [Transformers](https://github.com/huggingface/transformers) (previously known as pytorch-pretrained-BERT and pytorch-transformers), we've been working on a comparison between the implementation of our models in PyTorch and in TensorFlow.

We've released a [detailed report](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2) where we benchmark each of the architectures hosted on our repository (BERT, GPT-2, DistilBERT, ...) in PyTorch with and without TorchScript, and in TensorFlow with and without XLA. We benchmark them for inference and the results are visible in the [following spreadsheet](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit#gid=0).

We would love to hear your thoughts on the process.",1,26
167,2019-10-20,2019,10,20,2,dk6i45,Regression on very small images,https://www.reddit.com/r/deeplearning/comments/dk6i45/regression_on_very_small_images/,gulzainali,1571504634,"I am working on a problem where i am trying to build a model to do regression on very small images. These images are simple filled colors of size 20x20 pixels. These are extracted patches.from larger images and due to difference in light i can't simply fetch the color and output a value. Can anyone suggest a good model for this problem? given a simple image filled with color of very small size, i need to predict a certain value Y.",2,1
168,2019-10-20,2019,10,20,2,dk6jlf,"I published a book about neural networks, deep learning and TensorFlow 2.0",https://www.reddit.com/r/deeplearning/comments/dk6jlf/i_published_a_book_about_neural_networks_deep/,pgaleone,1571504817,,2,4
169,2019-10-20,2019,10,20,2,dk6wyb,"Neural networks taught to ""read minds"" in real time",https://www.reddit.com/r/deeplearning/comments/dk6wyb/neural_networks_taught_to_read_minds_in_real_time/,cmillionaire9,1571506440,,12,59
170,2019-10-20,2019,10,20,6,dk9upg,Auto ML dataset subsets: How to design a subset to for hyperparameter testing,https://www.reddit.com/r/deeplearning/comments/dk9upg/auto_ml_dataset_subsets_how_to_design_a_subset_to/,ensaladamental,1571519870,"Im reading about AutoML. There's a lot of vibrant work on the topic. Most interesting nets require however massive resources.   
For argument's sake, say, if you need to optimize the hyperparameters of Imagenet 1000, on a TitanRTX with Resnet18 a single run of 90 epochs is about 30 hours. Resnet50 is 110 hours ( these are my tests on pytorch). Deeper resnets achieve significant improvement on top1 accuracy.  
The resnet paper settles on learning updates every 30 epochs, but the difference in Top1 accuracy between 15 and 30 epochs is minimal. The space of optimizers is large, would second order methods work better? But even within SGD, could we be losing information  on the backpropagation because we are using FP32, or could we be wasting resources by not doing FP16. Could we be losing information because some salient gradient on a latent layer is getting clobbered by the simple weighted sum of the residuals?   
An biological analogy, when signal travels through the dendrite trees it decays with distance and increases nonlinearly with proximity of other dedndrites carrying the same information. Maybe you can say that this is modifying the architecture, but all I'm thinking of is a  variation on adaptive SGDs.   


Question. Is there hope for a principled reduction on a dataset where output dimensions, number of samples, size of data and depth of an architecture can give us clues of what to do with hyperparameters?   
A physical analogy of this could be minaturized testing on fluids; e.g. you want to test flows on a ship you cant just miniaturize the ship, you also have to change to fluid to account for how forces change with scale.   


I found some work on this from 2013, Kwesky et al [Multi-Task Bayesian Optimization,](https://papers.nips.cc/paper/5086-multi-task-bayesian-optimization.pdf) To anyone's knowledge, Is there further work on this topic? This isnt new and standard architectures we are working on today are huge compared to 2013.    
There is an interesting work that I need to understand and implement, Feurer et al 2015 [Efficient and Robust Automated Machine Learning](https://ml.informatik.uni-freiburg.de/papers/15-NIPS-auto-sklearn-preprint.pdf), but it uses dataset similarity.

C Wong et al 2018 [Transfer Learning with Neural AutoML](https://papers.nips.cc/paper/8056-transfer-learning-with-neural-automl.pdf), sidesteps the question - and perhaps this is the way to go, using transfer learning. While I think this approach is very promising as, I am specifically looking at training completely new deep nets, so I have to put it on hold.

Now, I mentioned ImageNet1000 being too large, for a deep search. But while it contains lots of data, it is really tiny compared to the full image net with \~ &gt; 21000 categories and 14M + images; which in turn uses only 1/4 of the nouns in wordnet, which in turn is a barebones (and imbalanced) categorization of our use of nouns. 

Is there an information theory approach to answering this question?",1,3
171,2019-10-20,2019,10,20,6,dk9wh2,Turning a pdf question/answer file into flash cards,https://www.reddit.com/r/deeplearning/comments/dk9wh2/turning_a_pdf_questionanswer_file_into_flash_cards/,backtoreality0101,1571520090,Hey I was wondering if there were any pre trained models that could let me feed a question/answer pdf and the output would be to make flash cards. I have a text book of thousands of questions followed by answers that I could make on my own into flash cards but would take awhile and was looking for a way that an algorithm could look at the pdf and turn that into flash cards. Any suggestions?,0,0
172,2019-10-20,2019,10,20,7,dkam9f,ML OS Discussion,https://www.reddit.com/r/deeplearning/comments/dkam9f/ml_os_discussion/,ZeroMaxinumXZ,1571523489,,0,0
173,2019-10-20,2019,10,20,20,dkijk7,When will CVPR 2019 proceedings appear in IEEE Xplore?,https://www.reddit.com/r/deeplearning/comments/dkijk7/when_will_cvpr_2019_proceedings_appear_in_ieee/,youkaichao,1571571637,It has been quite a long time since the conference took place.,2,7
174,2019-10-21,2019,10,21,3,dknads,"I need help, please",https://www.reddit.com/r/deeplearning/comments/dknads/i_need_help_please/,loveapi,1571594972,"Hi Reddit!
I am new to learning neural networks. Once I found an article about Norman AI. (https://www.bbc.com/news/technology-44040008)
As I understand is it an AI that is trained to perform image captioning, right? This really interested me and I wanted to create something like that. If someone can tell me exactly what to do I will be very grateful. Sorry for my bad english I use google translate",5,0
175,2019-10-21,2019,10,21,6,dkq5m7,"AI Weekly Update #9 - (October 20th, 2019)",https://www.reddit.com/r/deeplearning/comments/dkq5m7/ai_weekly_update_9_october_20th_2019/,HenryAILabs,1571606813,"https://www.youtube.com/watch?v=03kCD18H5nQ

This week's update covers OpenAI's amazing robotic hand and exciting updates such as Facebook's Semi-Weakly Supervised learning framework, Google's MASSIVE (50BN params) Multilingual NMT models, and many more!",3,8
176,2019-10-21,2019,10,21,23,dl1ell,5 Awesome New Features  Python 3.8,https://www.reddit.com/r/deeplearning/comments/dl1ell/5_awesome_new_features_python_38/,RubiksCodeNMZ,1571668390,,4,38
177,2019-10-21,2019,10,21,23,dl1hqe,In case of LSTM implementation with tensorflow is it advisable to reset the initial state to zero for a new batch of data?,https://www.reddit.com/r/deeplearning/comments/dl1hqe/in_case_of_lstm_implementation_with_tensorflow_is/,pranav2109,1571668781,,4,5
178,2019-10-22,2019,10,22,2,dl3k29,My first GAN,https://www.reddit.com/r/deeplearning/comments/dl3k29/my_first_gan/,MartyMcfagg,1571677606,"[https://github.com/ale100584/GAN](https://github.com/ale100584/GAN)

Hello, this is my first attempt with GANs and I wanted to share it with you guys. Please let me know what you think! Thanks",0,1
179,2019-10-22,2019,10,22,3,dl4u1o,Facebook's Semi-Weak Supervised Learning framework explained!,https://www.reddit.com/r/deeplearning/comments/dl4u1o/facebooks_semiweak_supervised_learning_framework/,HenryAILabs,1571683105,"Video Explanation: [https://youtu.be/5cySIwg49RI](https://youtu.be/5cySIwg49RI)

Blog Post: [https://medium.com/@connorshorten300/unlabelled-datas-stock-is-rising-71ed1cf909b7](https://medium.com/@connorshorten300/unlabelled-datas-stock-is-rising-71ed1cf909b7)",0,2
180,2019-10-22,2019,10,22,5,dl6ekv,Self-play by next-state imagination from current action,https://www.reddit.com/r/deeplearning/comments/dl6ekv/selfplay_by_nextstate_imagination_from_current/,ZeroMaxinumXZ,1571689698,,0,1
181,2019-10-22,2019,10,22,7,dl86yq,How/where to learn ML devops? Ie how do I get up and running in GCP or AWS or locally?,https://www.reddit.com/r/deeplearning/comments/dl86yq/howwhere_to_learn_ml_devops_ie_how_do_i_get_up/,zalamandagora,1571697315,"I'm learning ML/DL on-line and am participating in a few Kaggle competitions to drive learning. Unfortunately, the biggest challenge for the last several weeks has been to get a good platform going. Neither Kaggle nor Colab work really well, and trying to run on my GPU-equipped Windows machine was hell as well. 

Looking at Docker and GCP, I just don't understand the instructions for provisioning and installing everything I need to get to a functioning ML environment connected to sufficient high-performance storage. 

I would really appreciate suggestions for how to learn this ""ML devops"" stuff.",2,1
182,2019-10-22,2019,10,22,9,dl9oew,Deep Learning for Computer Vision with Python By Adrian Rosebrock PDF,https://www.reddit.com/r/deeplearning/comments/dl9oew/deep_learning_for_computer_vision_with_python_by/,oussamaouti,1571703880,,2,0
183,2019-10-22,2019,10,22,15,dldnlp,ImageNet State-of-the-art,https://www.reddit.com/r/deeplearning/comments/dldnlp/imagenet_stateoftheart/,arjundupa,1571724340,"Is code for the current state-of-the-art (or one of the best performing models) on ImageNet publicly available?

How much compute does training a state-of-the-art ImageNet model require? Would one NVIDIA V100 suffice?",2,3
184,2019-10-22,2019,10,22,15,dldroc,GitHub - sommerschield/ancient-text-restoration: Restoring ancient text using deep learning: a case study on Greek epigraphy.,https://www.reddit.com/r/deeplearning/comments/dldroc/github_sommerschieldancienttextrestoration/,bil-sabab,1571725070,,1,28
185,2019-10-22,2019,10,22,16,dle9le,[P] GNES Flow: a Pythonic Way to Build Cloud-Native Neural Search Pipelines,https://www.reddit.com/r/deeplearning/comments/dle9le/p_gnes_flow_a_pythonic_way_to_build_cloudnative/,h_xiao,1571728134,,0,3
186,2019-10-22,2019,10,22,17,dlf0r5,AnnoMachine: an application that provides a user-friendly way to visualize &amp; interactively update object detection results,https://www.reddit.com/r/deeplearning/comments/dlf0r5/annomachine_an_application_that_provides_a/,machine_talk,1571733486,"Hi everyone, I'm Trung Tran. I occasionally write on [https://machinetalk.org](https://machinetalk.org).

Recently I have been working on an app called AnnoMachine, an application that aims to provide a user-friendly way to visualize &amp; interactively update object detection results. So what does that even mean?

Here is the introduction video illustrating the idea above:

[https://www.youtube.com/watch?v=NBO1acBqBlo](https://www.youtube.com/watch?v=NBO1acBqBlo)

# Why AnnoMachine?

Most deep learning engineers/practitioners (including myself) spend most of our time on creating deep learning models. So AnnoMachine is an effort of mine to make use of a deep learning model to create an app that can actually solve some kind of problem.

#  How did I create AnnoMachine?

The heart of AnnoMachine is, of course, an object detection model using deep learning. I chose SSD and implemented it on Tensorflow 2.0. Then, the model needs a way to serve the results to the world, right? I use Flask to create a RESTful API. As for the frontend, I used ReactJS to create the UI. I also used nginx for a simple web server.

The project uses the microservice architecture and docker to deploy locally or to AWS EC2. The project can run flawlessly on a single t2.micro instance.

# Source code

The project is open-sourced at [https://github.com/ChunML/AnnoMachine](https://github.com/ChunML/AnnoMachine).

For folks who want to train their own dataset, please use the source code from this repo: [https://github.com/ChunML/ssd-tf2](https://github.com/ChunML/ssd-tf2), a Tensorflow 2.0 implementation of SSD.

Please let me know f you have any questions or feedbacks :D Cheers.",4,2
187,2019-10-22,2019,10,22,21,dlh08f,Military artificial intelligence can be easily and dangerously fooled,https://www.reddit.com/r/deeplearning/comments/dlh08f/military_artificial_intelligence_can_be_easily/,atomlib_com,1571746242,,1,6
188,2019-10-22,2019,10,22,22,dli2hp,Exploring Data Augmentation with Keras and TensorFlow,https://www.reddit.com/r/deeplearning/comments/dli2hp/exploring_data_augmentation_with_keras_and/,thisissumit,1571751523,,0,4
189,2019-10-22,2019,10,22,22,dlib1f,Over 300 Open Datasets for Machine Learning,https://www.reddit.com/r/deeplearning/comments/dlib1f/over_300_open_datasets_for_machine_learning/,LimarcAmbalina,1571752674,,0,2
190,2019-10-23,2019,10,23,2,dll8g8,Harvard &amp; Google Seismic Paper Hit With Rebuttals: Is Deep Learning Suited to Aftershock Prediction?,https://www.reddit.com/r/deeplearning/comments/dll8g8/harvard_google_seismic_paper_hit_with_rebuttals/,Yuqing7,1571765368,,1,23
191,2019-10-23,2019,10,23,4,dln4f5,Fastest Data Structure for Very Large Directed Graph,https://www.reddit.com/r/deeplearning/comments/dln4f5/fastest_data_structure_for_very_large_directed/,raijinraijuu,1571773001,I am trying to store Wikipedia pages as a directed graph and I managed to create a SQL database of the wiki pages. I was curious if you know any data management technology more suited for this task. I posted here because I couldn't find any clear options.,0,1
192,2019-10-23,2019,10,23,7,dlpmb5,Deep Learning for Computer Vision with Python By Adrian Rosebrock PDF,https://www.reddit.com/r/deeplearning/comments/dlpmb5/deep_learning_for_computer_vision_with_python_by/,oussamaouti,1571783035,,0,0
193,2019-10-23,2019,10,23,15,dlv6hj,What is so fascinating about artificial intelligence?,https://www.reddit.com/r/deeplearning/comments/dlv6hj/what_is_so_fascinating_about_artificial/,SunilAhujaa,1571811750,Artificial intelligence courses in India are facilitating a lot of youngsters to delve deep into the subject and we can expect a rise in AI innovation from India in the near future.,2,0
194,2019-10-23,2019,10,23,17,dlwbp0,Powerful Deep learning build,https://www.reddit.com/r/deeplearning/comments/dlwbp0/powerful_deep_learning_build/,prateekish,1571819820,"I have been meaning to assemble a power-packed heavy-duty deep learning machine for a home set-up in India. This should be for long term usage keeping in mind most use-cases \[kaggle, competitive research, a startup idea, etc\]

While I have been through most famous and informative blogs(eg. tim dettmers), I still have a few wrinkles to iron before I jump the gun.

\- 1 rtx titan vs 2 rtx 2080 ti \[solely for AI tasks\] or any other gpu suggestion for that matter. I could even go for 2 rtx titans but i need to be sure they are worth it by offering more than say 4 RTX 2080 TIs . Its a long term investment and i wouldnt want to feel high and dry down the timeline

\- for large networks such as BERT, would the connected GPUs offer linearly added advantages (4 x 11 GB = 44 GB, for tensor cores, etc,) ?

If there are posts that address my queries (and more on the similar build lines) please be kind to point me to those.

Thanks in advance",13,0
195,2019-10-23,2019,10,23,20,dlxp30,Accelerating Sales Growth with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/dlxp30/accelerating_sales_growth_with_artificial/,akira_chaudhary,1571828901,,2,0
196,2019-10-23,2019,10,23,21,dlyjjk,I'm looking for success/failure stories applying unsupervised document embedding techniques,https://www.reddit.com/r/deeplearning/comments/dlyjjk/im_looking_for_successfailure_stories_applying/,shaypal5,1571833509,"Hey everyone! :)

As the title says, I am looking for both success stories and disappointing failures of applications of **modern** unsupervised document embedding techniques on actual problems (as opposed to academic benchmarks, toy datasets, academic evaluation tasks, etc.). The main focus is naturally on industry uses for business/product problems, but I would also love to hear about cases from government bodies, non-profits, use in research (with empirical measurement and where document embedding is one of the tools, not the subject of research) and any other ""real life"" use. I would love to hear about your experience, but connecting me to people you know or even hinting me towards companies or projects you know used these techniques (or tried to) would also be of tremendous help.

What's in it for you? Well, I'm preparing a talk for [the data science track of the CodeteCON #KRK5 conference](https://codetecon.pl/en/#program) based on my [literature review-y blog post on document embedding techniques](https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d), and while I feel I have a pretty good overview of the academic papers, benchmarks and SOTA status up until the most recent stuff to come out in the field at this point in time, I can't say the same for uses in the industry; I have a partial view from my experience in one ongoing project to actually use this, and experience shared by some of my data scientist friends (all in Israel, naturally) - most of it, so far, by the way, is that averaging (good) word embeddings is a very tough ""baseline"" to beat.

This is why I thought reaching out to get a better sense of things in the industry world-wide, and enriching my talk with the status of actual successes and industry applications will give people attending my talk more value, and will serve my attempt to make my talk a status report on the topic.

And (coming back to WIIFM) naturally (I think), I intend to share any (share-able) knowledge I accumulate not only in my talk, but also by adding a section dedicated to it to [the aforementioned blog post](https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d), and maybe even by writing an extended post around it (if enough interesting trends and issues come up). So, hopefully, if you are (like me) interested in this, we might also end up getting, together, a nice overview of where the industry stands at the moment.

What **modern** techniques (so no variants of bag-of-words or topic modeling techniques) am I talking about? These are the ones that I know of (I'd love to hear about others!):

* n-gram embeddings
* Averaging word embeddings (including all variants, e.g. SIF)
* Sent2Vec
* Paragraph vectors (doc2vec)
* Doc2VecC
* Skip-thought vectors
* FastSent
* Quick-thought vectors
* Word Movers Embedding (WME)
* Sentence-BERT (SBERT)
* GPT/GPT2 (can also be supervised)
* Universal Sentence Encoder (can also be supervised)
* GenSen (can also be supervised)

Thank you and cheers,  
Shay :)",5,19
197,2019-10-23,2019,10,23,21,dlyoh9,Deep Learning for automating KYC verification and aml compliances,https://www.reddit.com/r/deeplearning/comments/dlyoh9/deep_learning_for_automating_kyc_verification_and/,manneshiva,1571834191,"Deep Learning in KYC and aml compliances

[https://nanonets.com/blog/kyc-automation-using-deep-learning/](https://nanonets.com/blog/kyc-automation-using-deep-learning/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=kyca&amp;utm_content=dl)",1,0
198,2019-10-23,2019,10,23,22,dlyzzs,"[Research] Researchers Propose MIMO-Speech, a New Neural Sequence-to-Sequence Architecture",https://www.reddit.com/r/deeplearning/comments/dlyzzs/research_researchers_propose_mimospeech_a_new/,cdossman,1571835789,"  [https://medium.com/ai%C2%B3-theory-practice-business/researchers-propose-mimo-speech-a-new-neural-sequence-to-sequence-architecture-19b1e791a53b](https://medium.com/ai%C2%B3-theory-practice-business/researchers-propose-mimo-speech-a-new-neural-sequence-to-sequence-architecture-19b1e791a53b) 

Recently, the end-to-end approach has proven its efficacy in monaural multi-speaker speech recognition. However, high word error rates (WERs) still prevent these systems from being used in practical applications. On the other hand, the spatial information in multi-channel signals has proven helpful in far-field speech recognition tasks. In this work, we propose a novel neural sequence-to-sequence (seq2seq) architecture, MIMO-Speech, which extends the original seq2seq to deal with multi-channel input and multi-channel output so that it can fully model multi-channel multi-speaker speech separation and recognition. MIMO-Speech is a fully neural end-to-end framework, which is optimized only via an ASR criterion. It is comprised of: 1) a monaural masking network, 2) a multi-source neural beamformer, and 3) a multi-output speech recognition model. With this processing, the input overlapped speech is directly mapped to text sequences. We further adopted a curriculum learning strategy, making the best use of the training set to improve the performance. The experiments on the spatialized wsj1-2mix corpus show that our model can achieve more than 60% WER reduction compared to the single-channel system with high quality enhanced signals (SI-SDR = 23.1 dB) obtained by the above separation function.",0,10
199,2019-10-23,2019,10,23,22,dlzjzh,Best tools to know to be marketable?,https://www.reddit.com/r/deeplearning/comments/dlzjzh/best_tools_to_know_to_be_marketable/,nicetryho,1571838430,[removed],0,1
200,2019-10-23,2019,10,23,22,dlznnd,"Please Mods, Make This Sub Karma-Locked",https://www.reddit.com/r/deeplearning/comments/dlznnd/please_mods_make_this_sub_karmalocked/,Atralb,1571838904,"This sub is completely bloated by swarms of posts of random offers, or shitty courses, or low-if-not-null quality medium articles, or even links to github repos. I swear this represents more 40% of the activity on this sub right now.

Someone has to do something. Could you at least set a soft threshold like 200 karma ? And minimum accoimt age ?

Cause I'm telling you this sub is decaying and slowly dying and I find it very sad for our community.

I honestly always go to others subs now if I'm looking for relevant information on the discipline.",0,1
201,2019-10-23,2019,10,23,23,dm0biy,Padded_batch with pre- or post-padding option,https://www.reddit.com/r/deeplearning/comments/dm0biy/padded_batch_with_pre_or_postpadding_option/,shahriar49,1571841918,"I have a dataset of variable-length sequences (a tensorflow TFRecord dataset) to feed an LSTM network and I want to try and compare pre- and post-padding in the batches, but current padded\_batch function only pads at the sequences end. I know that we have tf.keras.preprocessing.sequence.pad\_sequences function in API but I don't know how to apply this function to dataset batch processor. The padded\_batch function in tensorflow does both padding and batching, and it will find the required paddding size per batch dynamically. How can I implement this myself? My code right now is like this, and I am reading multiple TFRecord files and interleave them to make my mixed dataset:

    featuresDict = {'data': tf.FixedLenFeature([], dtype=tf.string),
                    'rows': tf.FixedLenFeature([], dtype=tf.int64),
                    'label': tf.FixedLenFeature([], dtype=tf.int64)
                   }
    
    def parse_tfrecord(example):
        features = tf.parse_single_example(example, featuresDict)
        label = tf.one_hot(features['label'],N)
        rows = features['rows']
        data = tf.decode_raw(features['data'], tf.int64)
        data = tf.reshape(data, (rows,num_features)
        return data, label
    
    def read_datasets(pattern, numFiles, numEpochs=None, batchSize=None):
        files = tf.data.Dataset.list_files(pattern)
    
        def _parse(x):
            x = tf.data.TFRecordDataset(x, compression_type='GZIP')
            return x
    
        dataset = files.interleave(_parse, cycle_length=numFiles, block_length=1).map(parse_tfrecord)
        padded_shapes = (tf.TensorShape([None, num_features]), tf.TensorShape([N,])))
        dataset = dataset.padded_batch(batchSize, padded_shapes)
        dataset = dataset.prefetch(buffer_size=batchSize)
        dataset = dataset.repeat(numEpochs)
        return dataset",0,2
202,2019-10-23,2019,10,23,23,dm0g5p,The Best TensorFlow Class?,https://www.reddit.com/r/deeplearning/comments/dm0g5p/the_best_tensorflow_class/,ChrisBlaaa,1571842517,"Hey folks,
I'm fairly familiar with programming and machine / deep learning. But I'm almost non experienced to tensorFlow and at this point I'm looking for a good Tensorflow class I could enroll.

What I'm not looking for is a keras high level tutorial.
But my feeling after the first little research is, that all provided tf classes are exactly this, keras tutorials...

Do you guys know any real tf class? Either 1.x or 2.0 is welcome. 

Highly appreciate your hints and answers.",2,1
203,2019-10-24,2019,10,24,6,dm5yxj,Deep Learning Specialization - Master Deep Learning &amp; Break into Artificial Intelligence (New career &amp; earnings opportunities),https://www.reddit.com/r/deeplearning/comments/dm5yxj/deep_learning_specialization_master_deep_learning/,internetdigitalentre,1571865590,[removed],0,1
204,2019-10-24,2019,10,24,15,dmcmdr,Deep learning algorithm helps diagnose neurological emergencies,https://www.reddit.com/r/deeplearning/comments/dmcmdr/deep_learning_algorithm_helps_diagnose/,samcharchil,1571899934,,1,22
205,2019-10-24,2019,10,24,17,dmdgvr,AI Jobs + Internships,https://www.reddit.com/r/deeplearning/comments/dmdgvr/ai_jobs_internships/,ai_jobs,1571905996,,0,1
206,2019-10-24,2019,10,24,18,dmdq2g,Neural Network Training Times,https://www.reddit.com/r/deeplearning/comments/dmdq2g/neural_network_training_times/,TobyTheCamel,1571907859,"Sorry for such a simple question but I'm struggling to find confirmation on this. I'm new to neural networks after a background in traditional ML. I've got a computer with an RTX 2070. I've set up all of the NVIDIA/CUDA drivers and installed TF. I don't get any errors and when building models the console output references my GPU.

The problem is that I had a go at running the TF quickstart code ( [https://www.tensorflow.org/tutorials/quickstart/beginner](https://www.tensorflow.org/tutorials/quickstart/beginner)) training a NN on the MNIST dataset with one hidden layer of 128 neurons. This took 5 days to complete 5 epochs. This seemed much slower than I would have expected but maybe that's just my inexperience speaking. Is this a typical training time? If not, what could be at play?",3,0
207,2019-10-24,2019,10,24,18,dmdshw,Deep Image - online upscale and enhance image with deep learning app!,https://www.reddit.com/r/deeplearning/comments/dmdshw/deep_image_online_upscale_and_enhance_image_with/,bartbdm,1571908350,"Hello guys!  
I would like to share with you a new tool - Deep Image ([https://deep-image.ai/](https://deep-image.ai/) ) which is an online AI image enhancer based on Artificial Neural Networks (ANN). It can upscale, enhance and improve picture/photo/image quality. 

Currently the app ([https://deep-image.ai/application/](https://deep-image.ai/application/)) is available in beta version. We're working on improvement of the algorithms to receive better image quality after enhancement. If you use the app and upload your images it would be helpful for us in training the neural networks!

In 2020 we are also going to add some new features to the app.

Hope you find it useful and thanks in advance for your help of uploading.  
Any feedback on the app will be appreciated!

PS below you can find short summary of DeepImage in numbers

*Processing img sr6bj65xggu31...*",0,2
208,2019-10-24,2019,10,24,19,dmenea,visflow for deeplearning,https://www.reddit.com/r/deeplearning/comments/dmenea/visflow_for_deeplearning/,loopy_fun,1571914159,,0,1
209,2019-10-24,2019,10,24,20,dmf76y,Advice for Deep Learning / Computer Vision build,https://www.reddit.com/r/deeplearning/comments/dmf76y/advice_for_deep_learning_computer_vision_build/,Jurge92,1571917408,"Hi there!

I'm currently looking into building a deep learning desktop that will be used for training, validation and maybe even server usage.

The budget is around $2500 USD.

Do you guys have any advice?

Cheers!",1,1
210,2019-10-24,2019,10,24,21,dmfgs1,5 Facial Recognition Trends and Market Predictions 2019,https://www.reddit.com/r/deeplearning/comments/dmfgs1/5_facial_recognition_trends_and_market/,ankur_bansal123,1571918874,,0,1
211,2019-10-24,2019,10,24,21,dmfmx7,LSTM implementation in C for byte level predictions,https://www.reddit.com/r/deeplearning/comments/dmfmx7/lstm_implementation_in_c_for_byte_level/,rickardicus,1571919804,"Hi folks!

I wanted to share a project I have been working on. It is a recurrent neural network that predicts bytes which can be used to mimic e.g. lyrical content (such as books). It uses Adam gradient optimization algorithm and the only requirement for using it is a C compiler (I use GCC). No third parties, just a bunch of C source files needed to be compiled. I have included some pretrained models that might be fun to play around with.

I hope this can serve as an inspiration to anyone wanting to make their own stuff from scratch. 

Feel free to come with constructive comments on what I can add/change or any such requests.
Have a great day!

Here is a link to the GitHub repository:

[LSTM implementation (GitHub)](https://github.com/Ricardicus/recurrent-neural-net) 

Dont forget to give the repository a star if you like it, it would be really appreciated!",0,1
212,2019-10-24,2019,10,24,21,dmfr4p,[Project] LSTM implementation in C for byte level prediction,https://www.reddit.com/r/deeplearning/comments/dmfr4p/project_lstm_implementation_in_c_for_byte_level/,rickardicus,1571920431,"Hi folks!

I wanted to share a project I have been working on. It is a recurrent neural network that predicts bytes which can be used to mimic e.g. lyrical content (such as books). It uses Adam gradient optimization algorithm and the only requirement for using it is a C compiler (I use GCC). No third parties, just a bunch of C source files needed to be compiled. I have included some pretrained models that might be fun to play around with.

I hope this can serve as an inspiration to anyone wanting to make their own stuff from scratch. 

Feel free to come with constructive comments on what I can add/change or any such requests.
Have a great day!

Here is a link to the GitHub repository:

[LSTM implementation (GitHub)](https://github.com/Ricardicus/recurrent-neural-net) 

Dont forget to give the repository a star if you like it, it would be really appreciated!",4,5
213,2019-10-24,2019,10,24,21,dmftfk,Diagnosing brain tumours by routine blood tests using machine learning,https://www.reddit.com/r/deeplearning/comments/dmftfk/diagnosing_brain_tumours_by_routine_blood_tests/,marco_mihajlow,1571920767,"Researchers from Slovenia trained a model that is able to detect brain tumors from simple blood test. This practice is now already in use at the Slovenia's main clinical center, where this model is assiting doctors.

[LINK](https://www.nature.com/articles/s41598-019-51147-3.epdf?author_access_token=PRTjI6CVk0PpBLvEXPRwXdRgN0jAjWel9jnR3ZoTv0OG-qznjOIEjlwb7jpx4Kt-QDpA9EtNMXoSQ1fx666zg80UmD5T3bo8PKtHyVgHgSj4jgXCxaeh-UH5GbXK3_M2PHXJHwFxmo4XgESBecAuTA==)",0,3
214,2019-10-24,2019,10,24,23,dmh9kc,Share the implementation of 44.1K Enhanced Singing Voice Separation.,https://www.reddit.com/r/deeplearning/comments/dmh9kc/share_the_implementation_of_441k_enhanced_singing/,choiilji,1571927670,"Hi guys! I did share my Source Separation (Single Channel) implementation.

github :  [https://github.com/AppleHolic/source\_separation](https://github.com/AppleHolic/source_separation)

Recently I add ""Singing Voice Separation"" with DSD100 dataset.

Mainly, it is trained with 44.1k sample rate to satisfy my ears. And it is trained jointly Voice Bank, DSD100 and Audioset dataset.

&amp;#x200B;

You can checkout the test sample on my youtube playlist that has 5 my favorite songs!

\- List :

  \- Sung Si Kyung - On the Street

  \- Linkin Park - Pushing me Away

  \- Baek Ye Rin - His Ocean

  \- Cheeze - Moments for everyone

  \- Taeyeon - Four Seasons

\- link :  [https://www.youtube.com/playlist?list=PLQ4ukFz6Ieir5bZYOns08\_2gMjt4hYP4I](https://www.youtube.com/playlist?list=PLQ4ukFz6Ieir5bZYOns08_2gMjt4hYP4I)

&amp;#x200B;

One of them, ""Sung Si Kyung - On the street"" is added the shifted vocal track with 2 db volume down. So, it can feel fresh to listeners who did already hear that song.

\- link :  [https://www.youtube.com/watch?v=xmoBUf\_6b0c&amp;list=PLQ4ukFz6Ieir5bZYOns08\_2gMjt4hYP4I&amp;index=1](https://www.youtube.com/watch?v=xmoBUf_6b0c&amp;list=PLQ4ukFz6Ieir5bZYOns08_2gMjt4hYP4I&amp;index=1)

&amp;#x200B;

I will keeping to try my best on application and research area on Speech and Music. If you find some problems or improvement for this model, freely contact me.

Thanks.",5,32
215,2019-10-24,2019,10,24,23,dmhksx,Slam Dunk Video Classification Tutorial (with TF 2.0 Distributed Training!),https://www.reddit.com/r/deeplearning/comments/dmhksx/slam_dunk_video_classification_tutorial_with_tf/,HenryAILabs,1571929061,https://youtu.be/xizl9vZ81jQ,0,5
216,2019-10-25,2019,10,25,0,dmhz2x,Any references on Super-Resolution on Graph using Graph (Convolutional )Neural Network?,https://www.reddit.com/r/deeplearning/comments/dmhz2x/any_references_on_superresolution_on_graph_using/,pradeep_sinngh,1571930726,"Hi everyone,

I was wondering if there is any research/ paper on doing super-resolution on graphs -- going from coarse resolution mesh/ graph to fine resolution mesh/ graph. Any pointers/ references/ thoughts would be appreciated. Thanks a lot.

Q.) How to do DeConvolution on Graph ?

NOTE: I'm considering mesh as a graph and applying graph (conv) neural network to it.",1,2
217,2019-10-25,2019,10,25,1,dmit7v,Literature on Recursive Neural Networks for Tabular Data,https://www.reddit.com/r/deeplearning/comments/dmit7v/literature_on_recursive_neural_networks_for/,cgarciae,1571934315,"I've been watching Fastai's videos and got very interested in embeddings for categorical variables ([https://arxiv.org/abs/1604.06737](https://arxiv.org/abs/1604.06737)), I've also been watching Jeremy's other videos on Random Forrest's, this got me thinking on the possibility of creating a NN with a more complex tree-like structure instead of just concatenating all the embeddings. Recursive Neural Networks have this behavior but I haven't seen literature on these for tabular data after searching on Google.  


Is there something similar that goes by another name or is this just unexplored by researchers?",0,1
218,2019-10-25,2019,10,25,5,dmluln,Attention Visualiztion for Graph Convolution,https://www.reddit.com/r/deeplearning/comments/dmluln/attention_visualiztion_for_graph_convolution/,hmsajjad,1571947291,"Hi, I am quite new to the concept of attention. I am working with graph data and running graph convolution on it to learn node level embedding first. Then an attention layer to aggregate the nodes to learn a graph level embedding. Here is the setup:

graph-&gt;Conv1(Filter size 128)-&gt;Conv2-(Filter size 64&gt;Conv3(Filter size 32) -&gt; Attention -&gt; Some other layers

After three convolution pass i get a matrix of size number\_of\_nodes\_in\_the\_graph X 32 (embedding length). After the attention layer i get a flat vector representation of the graph with length 32. Now i would like to see which graph nodes were important for the final graph embedding. I am using pytorch for this. I cannot seem to figure out how to map the attention output to input. I would greatly appreciate any help!

Thanks",2,5
219,2019-10-25,2019,10,25,5,dmme4g,Project ideas for advanced deep learning course,https://www.reddit.com/r/deeplearning/comments/dmme4g/project_ideas_for_advanced_deep_learning_course/,ranran9991,1571949516,"Hey, reddit  
I have participated a course on advanced deep learning, the main covered topics were

1. GANs and their variations, CycleGan
2. Hypernetworks (and meta learning)
3. Self supervision

We were asked to come up with project ideas (the project should take about 2 weeks) and I would love some suggestions if you have any cool ideas.",2,1
220,2019-10-25,2019,10,25,16,dmtr21,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,https://www.reddit.com/r/deeplearning/comments/dmtr21/exploring_the_limits_of_transfer_learning_with_a/,iordanissh,1571987271,,0,2
221,2019-10-25,2019,10,25,16,dmtyqw,CNN network behavior when a class is having multi-objects data in it.,https://www.reddit.com/r/deeplearning/comments/dmtyqw/cnn_network_behavior_when_a_class_is_having/,VeeranjaneyuluToka,1571988704,"Hi All,  I am training a model with image data and each class has different  distributions of data and still converges. Am wondering what could be  the reason and how the representation are at the end of training?  Anybody has any suggestions or comments on this kind of behavior?  Thanks.",3,9
222,2019-10-25,2019,10,25,18,dmuxcs,Calculate Empowerment in Python,https://www.reddit.com/r/deeplearning/comments/dmuxcs/calculate_empowerment_in_python/,ZeroMaxinumXZ,1571995529,,0,3
223,2019-10-25,2019,10,25,20,dmwa91,"[R] Netflix just open-sourced Polynote, a cool Machine Learning, and Data Science workflow tool",https://www.reddit.com/r/deeplearning/comments/dmwa91/r_netflix_just_opensourced_polynote_a_cool/,cdossman,1572004001," Netflix just open-sourced Polynote, a cool Machine Learning, and Data Science workflow tool

Polynote Website: https://polynote.org/

Github:https://github.com/polynote/polynote?fbclid=IwAR1bF4fcoe7R0rqZIrIeV7c5pYTPprMBzhqsmpEgliOGkf4iJ8I6CNuha\_8",7,50
224,2019-10-25,2019,10,25,20,dmwauv,Prevent Depth Map in Images,https://www.reddit.com/r/deeplearning/comments/dmwauv/prevent_depth_map_in_images/,ap_1690,1572004099,"Hey Everyone is there is some  way from which i can prevent depth map algorithm from predicting depth in an image on some screen .
Example if i have input image on the screen on my laptop then depth map algo will predict the depth in the image rather than predicting the screen and boundaries of my laptop.",5,2
225,2019-10-25,2019,10,25,23,dmxvii,Intro to CoordConv,https://www.reddit.com/r/deeplearning/comments/dmxvii/intro_to_coordconv/,07williamsm,1572012129,,0,2
226,2019-10-26,2019,10,26,1,dmzqc3,Deep Learning Project Consulting with Henry AI Labs,https://www.reddit.com/r/deeplearning/comments/dmzqc3/deep_learning_project_consulting_with_henry_ai/,HenryAILabs,1572020268,[https://www.patreon.com/henryailabs](https://www.patreon.com/henryailabs),1,0
227,2019-10-26,2019,10,26,3,dn1c2w,[R] Asynchronous Search for Directed Hyperparameter Search with PySpark for TensorFlow,https://www.reddit.com/r/deeplearning/comments/dn1c2w/r_asynchronous_search_for_directed_hyperparameter/,jpdowlin,1572027037,,0,5
228,2019-10-26,2019,10,26,9,dn6a2q,[Helpful] Part 2 of Reinforcement Learning: Introduction to the Markov Process,https://www.reddit.com/r/deeplearning/comments/dn6a2q/helpful_part_2_of_reinforcement_learning/,cdossman,1572048838,,0,1
229,2019-10-26,2019,10,26,10,dn77a0,Using Deep Learning to Predict the Olfactory Properties of Molecules,https://www.reddit.com/r/deeplearning/comments/dn77a0/using_deep_learning_to_predict_the_olfactory/,HN_Crosspost_Bot,1572053599,,0,3
230,2019-10-26,2019,10,26,14,dn9wny,Coursera Staff:If you want Andrew Ng to come out and teach the reinforcement learning? Vote this one,https://www.reddit.com/r/deeplearning/comments/dn9wny/coursera_staffif_you_want_andrew_ng_to_come_out/,JonathanSum777,1572069472,"Please vote here in this post if: **you want Andrew Ng to come out and teach the reinforcement learning.**

For more info: please check this post too.

 [https://coursera.community/course-suggestions-51/a-reinforcement-learning-course-by-andrew-ng-2528](https://coursera.community/course-suggestions-51/a-reinforcement-learning-course-by-andrew-ng-2528)",13,156
231,2019-10-26,2019,10,26,16,dnak03,"Google Waymo internship, summer 2020",https://www.reddit.com/r/deeplearning/comments/dnak03/google_waymo_internship_summer_2020/,qikpal,1572074205,,1,1
232,2019-10-27,2019,10,27,1,dngg2x,Deep-Fakes Detection Research,https://www.reddit.com/r/deeplearning/comments/dngg2x/deepfakes_detection_research/,pranjalranjan299,1572108780,"https://youtu.be/cYKxJk3lz8E

This is our latest work on Deep-Fake detection. Watch the whole video to know more. Please like, share and subscribe ",4,4
233,2019-10-27,2019,10,27,4,dnil58,HELP : How to build encoder decoder model,https://www.reddit.com/r/deeplearning/comments/dnil58/help_how_to_build_encoder_decoder_model/,vaibhavkumar049,1572118453,"I am trying to build an encoder-decoder model. encoder as CNN and decoder as RNN or LSTM, so should I pass my image into CNN and then flatten it out and then pass to decoder? or complete channels to decoder?",2,1
234,2019-10-27,2019,10,27,6,dnjtji,"Your feedbacks on my ""Visual Text Correction"" research",https://www.reddit.com/r/deeplearning/comments/dnjtji/your_feedbacks_on_my_visual_text_correction/,amirmz,1572124191,"Hi all,

I would like to get some feedback on one of my current projects, named Visual Text Correction.

[http://openaccess.thecvf.com/content\_ECCV\_2018/html/Amir\_Mazaheri\_Visual\_Text\_Correction\_ECCV\_2018\_paper.html](http://openaccess.thecvf.com/content_ECCV_2018/html/Amir_Mazaheri_Visual_Text_Correction_ECCV_2018_paper.html)

The problem is basically to find an inaccuracy in the description of a video, and simply fix it. However, it is trained on synthetic data (MPI Movie dataset with audio descriptions).

Also, I found the main idea of the newly released VideoBERT paper very similar to my work; however, they mainly focus on rich feature learning and I focus on the application.

Besides your feedback, I appreciate any comments about 

First of all, does anybody aware of any human-made mistakes/typos dataset on video captions?

Secondly, do you think if it is ultimately a useful application to pursue my research on? Like a Software that can rearrange the YouTube captions, detect and remove unrelated texts in Facebook uploaded videos' captions, and etc?

Thanks",0,5
235,2019-10-27,2019,10,27,8,dnlkd3,Legality of celebrity deepfake for music video?,https://www.reddit.com/r/deeplearning/comments/dnlkd3/legality_of_celebrity_deepfake_for_music_video/,whereskob,1572132527,"Looking for some advice!

Shot a music video (cover of meatloaf - Bat Out of hell) and at one point in the story, the band call up Meatloaf who is currently a lookalike but I would really love to deepfake it.

Could this be potentially opening up for legal action or considered just satire? It won't be defamatory or show him in a bad light. Just a bit of fun in a short scene.

Thanks all!",0,1
236,2019-10-27,2019,10,27,14,dnp2ku,Deep Learning portable workstation - Student Advice,https://www.reddit.com/r/deeplearning/comments/dnp2ku/deep_learning_portable_workstation_student_advice/,KrakenML,1572152787,"Hi All,

Was hoping to get some suggestions as I'm starting my Comp science/ Genetics dual major degree next year and would like some laptop advice. Very interested in DL and building my own small projects 

Would the Nvidia Quadro RTX 5000 GPU be beneficial for deep learning?  The razer studio laptop has recently been released with the option to add the Quadro Rtx 5000 or would I be better off just getting the NVIDIAGeForce RTX 2080 with Max-Q Design (8GB GDDR6 VRAM) instead 


https://www.razer.com/gaming-laptops/razer-blade/shop#rtx5000--oled-60hz-9thgen--1tb-mercury",7,0
237,2019-10-27,2019,10,27,14,dnp7wy,How do I classify voice emotion with deep learning?,https://www.reddit.com/r/deeplearning/comments/dnp7wy/how_do_i_classify_voice_emotion_with_deep_learning/,archx64,1572153787,I'm developing a chat bot that can recognize emotion of the user by listening to the voice of the user,6,16
238,2019-10-27,2019,10,27,15,dnps7i,Help: need some advices to convert a 2D model to 3D,https://www.reddit.com/r/deeplearning/comments/dnps7i/help_need_some_advices_to_convert_a_2d_model_to_3d/,oqader,1572157945,"Hello there,

I'm trying to convert an inpainting model ( Nvidia's model: Partial Convolution) from 2D to 3D. I've never worked on 3D models before and this project is considered my graduation project.

I need some guidance in doing that. Any help or advice is highly appreciated",2,2
239,2019-10-28,2019,10,28,4,dny7eo,How to Code Neat Machine Learning Pipelines,https://www.reddit.com/r/deeplearning/comments/dny7eo/how_to_code_neat_machine_learning_pipelines/,GChe,1572204158,,0,13
240,2019-10-28,2019,10,28,7,dnzxhf,Training convolutional variational autoencoders,https://www.reddit.com/r/deeplearning/comments/dnzxhf/training_convolutional_variational_autoencoders/,Mike_Sv86,1572214178,"Hi all.

Iam trying to train a convolutional variational autoencoder (CVAE) on computed tomography (CT) IMAGES (176X224 px) . The training data is normalized between 0 and 1 and Iam using approximately the same model structure as in keras autoencoder tutorial.

https://keras.io/examples/variational_autoencoder/

I only changed the depth and the size of the latent space to 128.

For the loss function I use Mse and KL, with a weight annealing for the KL part. 

When I train the network it seems like it is learning something, but if I try to reconstruct images after training, the output images are just noisy. 

I have no clue what it is Iam doing wrong. 

Any advice would be really great. 

Cheers, 

M",0,1
241,2019-10-28,2019,10,28,9,do1v4v,"Intro to Facial Recognition: What it is, how it works, accuracy",https://www.reddit.com/r/deeplearning/comments/do1v4v/intro_to_facial_recognition_what_it_is_how_it/,LimarcAmbalina,1572224324,,0,2
242,2019-10-28,2019,10,28,14,do4pkq,Training convolutional variational autoencoders,https://www.reddit.com/r/deeplearning/comments/do4pkq/training_convolutional_variational_autoencoders/,Mike_Sv86,1572241515,"Hi all.

Iam trying to train a convolutional variational autoencoder (CVAE) on computed tomography (CT) Images (176X224 px) . The training data is normalized between 0 and 1 and Iam using approximately the same model structure as in keras autoencoder tutorial.

https://keras.io/examples/variational_autoencoder/

I only changed the depth and the size of the latent space to 128.

For the loss function I use Mse and KL, with a weight annealing for the KL part. 

When I train the network it seems like it is learning something, but if I try to reconstruct images after training, the output images are just noisy. 

I have no clue what it is Iam doing wrong. 

Any advice would be really great. 

Cheers, 

M",9,6
243,2019-10-28,2019,10,28,19,do789m,Business Value of Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/do789m/business_value_of_artificial_intelligence/,RubiksCodeNMZ,1572260188,,0,0
244,2019-10-28,2019,10,28,22,do8yq2,A PyTorch implementation for StyleGAN with full features.,https://www.reddit.com/r/deeplearning/comments/do8yq2/a_pytorch_implementation_for_stylegan_with_full/,huangzh13,1572269963,Github:  [https://github.com/huangzh13/StyleGAN.pytorch](https://github.com/huangzh13/StyleGAN.pytorch),0,3
245,2019-10-29,2019,10,29,2,docbbe,"AI Weekly Update - October 28th, 2019",https://www.reddit.com/r/deeplearning/comments/docbbe/ai_weekly_update_october_28th_2019/,HenryAILabs,1572284861,"This update covers Google AI's learning to smell with Graph Neural Networks, NVIDIA's Mellotron Rhymthic Speech Synthesis, Facebook's SlowFast model and many more!

https://youtu.be/S16YXORfZLg",0,0
246,2019-10-29,2019,10,29,4,dodybe,Deep Learning: A Practitioners Approach By Josh Patterson &amp; Adam Gibson PDF,https://www.reddit.com/r/deeplearning/comments/dodybe/deep_learning_a_practitioners_approach_by_josh/,psychonekk,1572291305,,0,0
247,2019-10-29,2019,10,29,5,doemyv,How does ReLu update weights if derivatives are always 1 or 0,https://www.reddit.com/r/deeplearning/comments/doemyv/how_does_relu_update_weights_if_derivatives_are/,StrasJam,1572293942,"I am surely missing something here, but from what I understand, weights are updated based on the gradient of the backpropogated error. But if the gradient of the ReLu is always 1 for values &gt;0, then how does the network learn which weights need to be adjusted compared to others? Wouldn't all weights be updated the same amount due to the gradient being the same?",9,9
248,2019-10-29,2019,10,29,10,doiqv6,Recommender Systems Specialization  Your gateway to new career and income opportunities,https://www.reddit.com/r/deeplearning/comments/doiqv6/recommender_systems_specialization_your_gateway/,internetdigitalentre,1572311746,[removed],0,1
249,2019-10-29,2019,10,29,12,dokjab,How to build a system which can tell which product(s) are being picked up and duration using Computer Vision/Deep Learning?,https://www.reddit.com/r/deeplearning/comments/dokjab/how_to_build_a_system_which_can_tell_which/,deeplearning2018,1572320920,"So a marketing company reached out saying that they need to build a system where a unmanned kiosk has products eg perfumes, markup when customers pick up a product and try, they need to know which product has been picked up and the duration.

I am pretty familiar with the Computer Vision and Deep Learning, so far I have tried edge detection using Canny and Holistically-Nested Edge Detection and place the products on 4 contrasting round/rectangle markers on a white paper background, so far so good

&amp;#x200B;

But what are your ideas around building such a system? Am I on the right track? Any code/ideas that you can please share with me would help fast-track its development",2,0
250,2019-10-29,2019,10,29,13,dokw7e,Where can I find the deep learning TFLOPS performance of Nvidia graphics ?,https://www.reddit.com/r/deeplearning/comments/dokw7e/where_can_i_find_the_deep_learning_tflops/,archx64,1572323008,"I searched for GPU benchmarks and what I found was texture units, shaders and clock speeds. My company wants to build a deep learning server and I have to decide which gpu will be suitable.",3,2
251,2019-10-29,2019,10,29,14,doldcv,How small Resnet can we develop,https://www.reddit.com/r/deeplearning/comments/doldcv/how_small_resnet_can_we_develop/,ap_1690,1572326132,"Hey how small can a Resnet we can make.
Like is resnet8 is possible 
Thanks in advance",2,1
252,2019-10-29,2019,10,29,17,domyhc,KL divergence between variational autoencoder predictions,https://www.reddit.com/r/deeplearning/comments/domyhc/kl_divergence_between_variational_autoencoder/,Mike_Sv86,1572338119,"Hi all.

I trained a VAE and now I wanted to use the KL divergence as a similarity measure. My idea was to send in example to different images through the encoder part, get the latent variables and compare the two distributions.

Unfortunately I have no clue how to implement that in python.

Does anyone know if there is an implementation?

Thanks for any advice,

&amp;#x200B;

cheers,

&amp;#x200B;

M",0,2
253,2019-10-29,2019,10,29,17,don1y4,"[Building a Dataset] How I created a 40,000 labeled audio dataset in 4 hours of work and $500",https://www.reddit.com/r/deeplearning/comments/don1y4/building_a_dataset_how_i_created_a_40000_labeled/,cdossman,1572338848," How I created a 40,000 labeled audio dataset in 4 hours of work and $500

[https://towardsdatascience.com/how-i-created-a-40-000-labeled-audio-dataset-in-4-hours-of-work-and-500-17ad9951b180](https://towardsdatascience.com/how-i-created-a-40-000-labeled-audio-dataset-in-4-hours-of-work-and-500-17ad9951b180)",6,14
254,2019-10-29,2019,10,29,17,don2uu,How to save image Embeddings?,https://www.reddit.com/r/deeplearning/comments/don2uu/how_to_save_image_embeddings/,abhiksark,1572339038,"I am performing a facial recognition task. For this, I am extracting facial embeddings (2048 vector) using a Pretrained Model. For matching the embeddings(features)  I am using Faiss([https://github.com/facebookresearch/faiss](https://github.com/facebookresearch/faiss))

Currently, I am saving embeddings(features) as .npy file. For 50k images, it is approximately taking 500MB of disk space. What is the best way to save embeddings?",3,2
255,2019-10-29,2019,10,29,18,donip0,Introduction to Anomaly Detection with Auto-Encoder on time series,https://www.reddit.com/r/deeplearning/comments/donip0/introduction_to_anomaly_detection_with/,AstroThese,1572342127,,6,90
256,2019-10-29,2019,10,29,19,donoi3,5 Facial Recognition Trends and Market Predictions 2019,https://www.reddit.com/r/deeplearning/comments/donoi3/5_facial_recognition_trends_and_market/,Neil_Patel001,1572343249,,0,1
257,2019-10-29,2019,10,29,19,doo0aj,A deep learning framework for neuroscience,https://www.reddit.com/r/deeplearning/comments/doo0aj/a_deep_learning_framework_for_neuroscience/,eleitl,1572345433,,0,1
258,2019-10-30,2019,10,30,1,dos2h1,I want to start a blog to share my work !!! But how??,https://www.reddit.com/r/deeplearning/comments/dos2h1/i_want_to_start_a_blog_to_share_my_work_but_how/,author31,1572365778,"Hi guys! I have been learning deep learning from scratch for about 11 months. Along the way of learning I tackled a lot of problems, I found that in this DL field there was really few tutorials from scratch to application, they just covered the intermediate layer which is how to build a model. I want to start a blog about covering how to use a certain model to solve real life problem. I really hope that I can get some opinions or advices from you guys.",3,3
259,2019-10-30,2019,10,30,4,doufrr,[Book] Facebook Page of Generative Adversarial Networks Projects by Kailash Ahirwar,https://www.reddit.com/r/deeplearning/comments/doufrr/book_facebook_page_of_generative_adversarial/,kailashahirwar12,1572375726,"Generative Adversarial Networks Projects\[Book\] is my book on GANs projects and practical applications of GANs. To create awareness around my book and GANs, I created a Facebook page. People who are interested in GANs and want to keep themselves updated can follow the page. 

[https://www.facebook.com/gansprojects1](https://www.facebook.com/gansprojects1)

Provide your suggestions on how to improve the page and you might get a free digital copy of the book for free.",0,1
260,2019-10-30,2019,10,30,4,dov8ji,BANANAS: A new method for neural architecture search,https://www.reddit.com/r/deeplearning/comments/dov8ji/bananas_a_new_method_for_neural_architecture/,afathman,1572379063,,0,13
261,2019-10-30,2019,10,30,5,dovvaj,Inference with sequences shorter than training ones,https://www.reddit.com/r/deeplearning/comments/dovvaj/inference_with_sequences_shorter_than_training/,shahriar49,1572381586,"I have an LSTM network trained to classify 1-year sequences of pixel values taken by Landsat to a set of land covers (each time step contains six bands per pixel, and I add 'Day-of-Year' also at each time step before training or testing.

Now my question is that what will happen if I feed the network during test time with sequences shorted than 1-year (say 3 months)? I assume that the network will learn to recognize different time patterns through the year so it can classify it. I can imagine that the network will try to find the best match of the shorter (e.g. 3-month) sequence pattern to the full patterns and classify it accordingly. But is there any theoretical ground for such a thing?",0,1
262,2019-10-30,2019,10,30,6,dowubh,Overview of Facebook Research at ICCV!,https://www.reddit.com/r/deeplearning/comments/dowubh/overview_of_facebook_research_at_iccv/,HenryAILabs,1572385578,[https://youtu.be/W5EsADGw9CA](https://youtu.be/W5EsADGw9CA),0,2
263,2019-10-30,2019,10,30,10,dp04sn,How do I get an ANN to do what I want?,https://www.reddit.com/r/deeplearning/comments/dp04sn/how_do_i_get_an_ann_to_do_what_i_want/,Mjbgtaad56,1572400274,"So, I know this is a fairly broad question, so I'm looking for a fairly broad answer. If I think of some task that I want a neural network to optimize or automate, how should I decided what the inputs and outputs are and what the structure, complexity, and functionality (ie recursion) should be.

For example, tic tac to, a self driving car, or perhaps an ANN powered videogame bot (something I've been interested in).

I know that an ANN is meant to simulate a brain, so I'd assume the inputs should be thought of as senses, and the outputs as muscles, actions, or results (thoughts), but I'm not sure what they should be sometimes or what would be the most effective I/O.",4,0
264,2019-10-30,2019,10,30,11,dp0apq,Advanced Deep Learning Topics,https://www.reddit.com/r/deeplearning/comments/dp0apq/advanced_deep_learning_topics/,data_datum,1572401059, [https://lilianweng.github.io/lil-log/](https://lilianweng.github.io/lil-log/),4,30
265,2019-10-30,2019,10,30,13,dp1ugm,Multiple weak/cheap GPUs or one powerful/expensive one?,https://www.reddit.com/r/deeplearning/comments/dp1ugm/multiple_weakcheap_gpus_or_one_powerfulexpensive/,2assakalan9,1572409317,"All other factors kept constant, what are the differences between training DL models on let's say two 4GB GPUs vs one 8GB GPU? If I know my way around DL libraries and how to use multiple devices, are there any differences?",2,1
266,2019-10-30,2019,10,30,14,dp2idd,AI Learns to Exploit Bugs in OPEN AI's Hide and Seek Game(Best Machine Learning Youtube Videos Under 10 Minutes),https://www.reddit.com/r/deeplearning/comments/dp2idd/ai_learns_to_exploit_bugs_in_open_ais_hide_and/,LimarcAmbalina,1572413774,,0,0
267,2019-10-30,2019,10,30,16,dp3848,Significance and Use Cases of AI Weather Forecasting Across Industries,https://www.reddit.com/r/deeplearning/comments/dp3848/significance_and_use_cases_of_ai_weather/,Neil_Patel001,1572419064,,0,1
268,2019-10-30,2019,10,30,17,dp3p38,Padding with 0s vs Dropping out the last few features?,https://www.reddit.com/r/deeplearning/comments/dp3p38/padding_with_0s_vs_dropping_out_the_last_few/,SEAsFinest,1572422686,"I have a 1d signal which after convoluting gives me a  feature vector of 220480. I have another 1d signal which after convoluting gives me a feature vector of 22030. I am to stack the first feature vector on top of the second one. To do that, I have to max pool the first one to reduce it to 22030. However, as 22030 does not completely divide 220480, I can not accurately use a fixed kernel size of 10 (220480/10 is 22048 which is slightly greater than 22030). To fix this, do I pad with 0s so I can use a kernel size of 11 or do I just drop out the last few features and bring it down to 220300? What are the pros and cons of each approach?

&amp;#x200B;

Thanks",2,6
269,2019-10-30,2019,10,30,18,dp4ent,YOLO object detection - how to use meta file after training a model on custom data,https://www.reddit.com/r/deeplearning/comments/dp4ent/yolo_object_detection_how_to_use_meta_file_after/,yazmaz54,1572428195,"Hi everyone,

I am trying to make a customized yolo model that will learn how to predict ""hands"". I have trained my model and found after some searching that the new generated weights are in the ckpt folder under a .meta file. How can I use this meta file in my code to test my trained model please?",0,1
270,2019-10-30,2019,10,30,19,dp4xv7,"[Research] Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities, and Challenges",https://www.reddit.com/r/deeplearning/comments/dp4xv7/research_explainable_artificial_intelligence_xai/,cdossman,1572431797,[removed],0,1
271,2019-10-31,2019,10,31,0,dp81be,250+ Machine Learning and Deep Learning Resources (Courseware and Lecture Videos),https://www.reddit.com/r/deeplearning/comments/dp81be/250_machine_learning_and_deep_learning_resources/,BlisteringBernacle,1572448175,,2,32
272,2019-10-31,2019,10,31,0,dp84n2,A Deep Learning framework for Neuroscience,https://www.reddit.com/r/deeplearning/comments/dp84n2/a_deep_learning_framework_for_neuroscience/,aiforworld2,1572448585,,0,4
273,2019-10-31,2019,10,31,1,dp93mp,[Research] Harnessing Indirect Training Data for End-to-End Automatic Speech Translation: Tricks of the Trade,https://www.reddit.com/r/deeplearning/comments/dp93mp/research_harnessing_indirect_training_data_for/,cdossman,1572452791,[removed],0,1
274,2019-10-31,2019,10,31,3,dpad3x,Yoshua Bengio on Human vs Machine Intelligence,https://www.reddit.com/r/deeplearning/comments/dpad3x/yoshua_bengio_on_human_vs_machine_intelligence/,Yuqing7,1572458858,,0,1
275,2019-10-31,2019,10,31,3,dparzb,netflow.js Neural Network Visualization,https://www.reddit.com/r/deeplearning/comments/dparzb/netflowjs_neural_network_visualization/,hmkcode,1572460663,,0,1
276,2019-10-31,2019,10,31,3,dpaxt8,netflow.js Neural Network Visualization,https://www.reddit.com/r/deeplearning/comments/dpaxt8/netflowjs_neural_network_visualization/,hmkcode,1572461365,[removed],0,1
277,2019-10-31,2019,10,31,5,dpcaov,What type of network would you use to count things in a still image,https://www.reddit.com/r/deeplearning/comments/dpcaov/what_type_of_network_would_you_use_to_count/,megaku,1572467181,"So, say I want to make a software that counts things from a picture, not too complicated. The images would be simple but I would want the software to ""guess"" what I want it to count, be it apples on a table or coins on the floor. To keep it simple it'll always be round-ish objects on plain backgrounds.  Should I use a convolutional or fully connected network? Got any ideas? Is it doable even? Should I use another ML method?",0,1
278,2019-10-31,2019,10,31,6,dpcyk4,Google Research at ICCV,https://www.reddit.com/r/deeplearning/comments/dpcyk4/google_research_at_iccv/,HenryAILabs,1572469995,[https://youtu.be/z-yvY8iAaHM](https://youtu.be/z-yvY8iAaHM),0,3
279,2019-10-31,2019,10,31,11,dpheni,Why do we use L2 norms and what are the practical use other than getting vector distance?,https://www.reddit.com/r/deeplearning/comments/dpheni/why_do_we_use_l2_norms_and_what_are_the_practical/,mlslayer,1572489814,"Why do we use L2 norms, instead of just taking a sum of all absolute values of a vector? Is there some mathematically reason behind it?  


Also, I've learned that norms represent distance of vectors. For example, if you had two error vectors, you can take the L2 norm to see which vector is worse(distance of error). Are there any other practical uses for norms?",9,4
280,2019-10-31,2019,10,31,12,dpi61w,Bayesian Deep Learning Summer School 2019,https://www.reddit.com/r/deeplearning/comments/dpi61w/bayesian_deep_learning_summer_school_2019/,data_datum,1572493922, [https://github.com/bayesgroup/deepbayes-2019](https://github.com/bayesgroup/deepbayes-2019),9,27
281,2019-10-31,2019,10,31,16,dpjzed,Are there any studies on the generalization performance of FlowNet or FlowNet2?,https://www.reddit.com/r/deeplearning/comments/dpjzed/are_there_any_studies_on_the_generalization/,mr_denoza,1572505972,"I was reading the original paper on FlowNet and the authors have presented their findings on four different data sets, however, I was curious to know if there is any study which highlights the generalization capabilities of these network architectures. For example: the performance of the network trained on Flying Chairs and tested on Sintel data set.",0,3
282,2019-10-31,2019,10,31,16,dpk4lc,Getting same results with half the number of time-steps as in original Hindsight Experience Replay Paper?,https://www.reddit.com/r/deeplearning/comments/dpk4lc/getting_same_results_with_half_the_number_of/,rrz0,1572507066,"I am reproducing the results from Hindsight Experience Replay by Andrychowicz et. al. In the original paper they present the results below, where the agent is trained for 200 epochs.

200 epochs \* 800 episodes \* 50 time steps = 8,000,000 total time steps.

&amp;#x200B;

https://preview.redd.it/bxc42reaxtv31.png?width=1044&amp;format=png&amp;auto=webp&amp;s=5fdbd7fe9b99a4a7951a507cc286225a16024851

I try to reproduce the resutls but instead of using 8 cpu cores, I am using 19 CPU cores.

I train the FetchPickAndPlace for 120 epochs, but with only 50 episodes per epoch. Therefore 120 \* 50 \* 50 = 300,000 iterations. I present the curve below:

&amp;#x200B;

&amp;#x200B;

https://preview.redd.it/i0wqunibxtv31.png?width=651&amp;format=png&amp;auto=webp&amp;s=a836c8df1968a76dabdf1101911bf701e44f708d

&amp;#x200B;

and logger output for the first two epochs:

&amp;#x200B;

&amp;#x200B;

https://preview.redd.it/vo56xz0cxtv31.png?width=233&amp;format=png&amp;auto=webp&amp;s=e1da41ba81ed3460edc27f235313705ac723e2c1

&amp;#x200B;

Now, as can be seen from my tensorboard plot, after 30 epochs we get a steady success rate very close to 1. 30 epochs \* 50 episodes \* 50 time steps = 75,000 iterations. Therefore it took the algorithm 75,000 time steps to learn this environment.

&amp;#x200B;

The original paper took approximately 50 \* 800 \* 50 = 2,000,000 time steps to achieve the same goal.

&amp;#x200B;

How is it that in my case the environment was solved nearly 30 times faster? Are there any flaws in my workings above? Surely I am doing something wrong, right?

&amp;#x200B;

NB: This was not a one off case. I tested again and got the same results.",0,2
283,2019-10-31,2019,10,31,21,dpmu3c,Analyzing 2019 Trends of Artificial Intelligence in Cybersecurity,https://www.reddit.com/r/deeplearning/comments/dpmu3c/analyzing_2019_trends_of_artificial_intelligence/,Harshitkansal,1572525015,,0,1
284,2019-10-31,2019,10,31,22,dpnge6,Error when running model.predict(),https://www.reddit.com/r/deeplearning/comments/dpnge6/error_when_running_modelpredict/,raghu_1809,1572528093,"I am using VGG16 model for which whenever I'm trying to predict, the model gives me an error saying 

""Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 

\[\[{{node block1\_conv1/convolution}}\]\] 	 

\[\[fc2/Relu/\_199\]\]   
""

Can somebody tell me a solution for this, please? thanks in advance.",10,1
0,2019-11-1,2019,11,1,11,dpydxi,Differentiable Inference and Generative Models,https://www.reddit.com/r/deeplearning/comments/dpydxi/differentiable_inference_and_generative_models/,data_datum,1572576280, [https://www.cs.toronto.edu/\~duvenaud/courses/csc2541/index.html](https://www.cs.toronto.edu/~duvenaud/courses/csc2541/index.html),0,1
1,2019-11-1,2019,11,1,12,dpz4qn,caffe: train input with pre-trained network,https://www.reddit.com/r/deeplearning/comments/dpz4qn/caffe_train_input_with_pretrained_network/,arjundupa,1572580510,"I have a pre-trained caffe model for scene recognition. I'd like to find an input image which maximally activates one of the output classes.

The idea is: start with a randomly initialized input image (noise), feed this into the the pre-trained network, see what the probability distribution with respect to each class is (the output of feeding the this input into the network), and then minimize the loss between this output and the desired output (in this case, the desired output would be the one-hot vector corresponding to which class you're looking for).

I am very new to Caffe -- any ideas / pointers as to how I can go about getting started with this?",0,1
2,2019-11-1,2019,11,1,12,dpz5wv,Code Tutorial: Manipulate Hyperparameter Spaces for Hyperparameter Tuning,https://www.reddit.com/r/deeplearning/comments/dpz5wv/code_tutorial_manipulate_hyperparameter_spaces/,GChe,1572580701,,1,1
3,2019-11-1,2019,11,1,13,dpznj2,Here is How to Code Neat Machine Learning Pipelines.,https://www.reddit.com/r/deeplearning/comments/dpznj2/here_is_how_to_code_neat_machine_learning/,GChe,1572583715,,0,1
4,2019-11-1,2019,11,1,22,dq4kqy,"AI, machine learning to dominate CXO agenda over next 5 years | ZDNet",https://www.reddit.com/r/deeplearning/comments/dq4kqy/ai_machine_learning_to_dominate_cxo_agenda_over/,BlisteringBernacle,1572616618,,0,2
5,2019-11-1,2019,11,1,23,dq4t9y,Understanding Images with skimage-Python,https://www.reddit.com/r/deeplearning/comments/dq4t9y/understanding_images_with_skimagepython/,BlisteringBernacle,1572617769,,2,0
6,2019-11-1,2019,11,1,23,dq53vo,Any ideas for podcast name?,https://www.reddit.com/r/deeplearning/comments/dq53vo/any_ideas_for_podcast_name/,Doctor_who1,1572619146," 

i have 've decided to create a podcast about deep learning  machine learning  artifical inteligence , neuroscience ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ? plase hellp me",0,1
7,2019-11-2,2019,11,2,1,dq6tiv,Book Recommendation,https://www.reddit.com/r/deeplearning/comments/dq6tiv/book_recommendation/,Jaszunai,1572626665,"Hi, I've been dabbling in neural networks a bit and was thinking of doing an image classification project. Do you have any recommendations on any good books for Computer Vision?",3,7
8,2019-11-2,2019,11,2,5,dqa1bx,"Boost ResNet ""with a simple twist"": connection to Partial Differential Equations",https://www.reddit.com/r/deeplearning/comments/dqa1bx/boost_resnet_with_a_simple_twist_connection_to/,liuyao12,1572640789,,8,23
9,2019-11-2,2019,11,2,12,dqf2uj,learn to implement NN from the scratch,https://www.reddit.com/r/deeplearning/comments/dqf2uj/learn_to_implement_nn_from_the_scratch/,zhangh12,1572665851,"hello everyone. I am a biostatistician with very little experience in DL. Recently when I looked into a formulation of a specific problem in my area, seems like it could be viewed as a neural network with special activation functions for some layers. Also, a special loss/cost function would be needed. 

I guess given this situation, existing framework of DL would not be applied directly to my problem. I would like to implement the NN from the scratch using C++ or python. I would also like to enable gpu computing in my program. I realized that I have difficulty in design the whole program (e.g. how to make the program be flexible to arbitrary layer structure specified by users, just like the existing frameworks do). In addition, I am not quite sure how to embed cuda code efficiently (I have some experience in cuda programming before). 

&amp;#x200B;

Is there a good repository on github that implements a general NN framework? I would like to learn from an example. Thank you.",3,0
10,2019-11-2,2019,11,2,13,dqfswg,How to build a human emotion recognizer using RAVDESS dataset?,https://www.reddit.com/r/deeplearning/comments/dqfswg/how_to_build_a_human_emotion_recognizer_using/,archx64,1572670501,"I'm making a human emotion recognizer using the RAVDESS dataset. The pipeline is to detect face emotion, speech emotion and speech recognition. After detecting combine detected face and speech emotions and analyze them. Then do sentiment analysis on the words of recognized speech. Is there a better way for the pipe line?",0,4
11,2019-11-2,2019,11,2,17,dqhd6p,Variational autoencoder training,https://www.reddit.com/r/deeplearning/comments/dqhd6p/variational_autoencoder_training/,Mike_Sv86,1572682649,"Hi all.

Iam a little bit confused about variational autoencoders and the KL divergence loss.

When reading about VAEs, there is a term called ""KL divergence collapse"", which as far as I have understood, means that the KL loss decreases to 0.

But isn't that what we want, to make the distribution of the latent space as close as possible to a normal distribution?

When I train a VAE on my dataset, the reconstructions are ok and the KL loss decreases to zero.

Is that a good sign or is it bad that the KL loss is zero?

&amp;#x200B;

Thanks in advance,

cheers,

Michael",14,11
12,2019-11-3,2019,11,3,2,dqmydm,tensorflow-gpu 1.12,https://www.reddit.com/r/deeplearning/comments/dqmydm/tensorflowgpu_112/,yazmaz54,1572714021,"Hi, I need to install tensorflow-gpu 1.12 in order to install a keras-yolo3 module but i am not able to install  tensorflow-gpu 1.12, i installed an anaconda environment which has python3.5 because  tensorflow-gpu 1.12 isn't compatible with python3.6 and above i think but it still doesn't work. can anyone please please please help me?",13,3
13,2019-11-3,2019,11,3,2,dqnor1,I need YOUR help with the NN project!,https://www.reddit.com/r/deeplearning/comments/dqnor1/i_need_your_help_with_the_nn_project/,Treedye,1572717033,"Hi there,

I am a senior in high school here in Ukraine, Eastern Europe and I am developing the project for the Ukrainian Scientific Academy (tournament) among youth, the project's idea is to create a useful and easy-to-use interface to create neural networks, with NO coding needed from the user making his own unique networks.

Please find the attached work-in-progress version of the project below. (NOTE: functions and objects are subject to change, there will be export/import, and everything the manually scripted NN has, but with convenient UI)

&amp;#x200B;

https://i.redd.it/jesigg428bw31.gif

My concern is what to do with the project after the tournament because for me the project seems like a great idea and it would be a stupid move to just throw it away. If you guys have any idea where this project will be really useful, please leave your comment. I was thinking about suggesting schools to implement it, but I am more interested in consumer usage. Any suggestions for the new features are also appreciated.

If you want to join the project and build it together - feel free to dm me, I would love to work with you on this. UI is made on HTML/CSS/JS, I consider using Python to produce the NNs.

Thanks for your time.",1,0
14,2019-11-3,2019,11,3,3,dqnyq1,Why Deep Learning Algorithm takes huge advantages of modern GPUs?,https://www.reddit.com/r/deeplearning/comments/dqnyq1/why_deep_learning_algorithm_takes_huge_advantages/,bastolasushann,1572718186,,4,17
15,2019-11-3,2019,11,3,4,dqpgqm,Machine Learning Will Allow Musicians To Spark Specific Emotions In Listeners,https://www.reddit.com/r/deeplearning/comments/dqpgqm/machine_learning_will_allow_musicians_to_spark/,BlastPalace,1572724529,,0,0
16,2019-11-3,2019,11,3,21,dqzyv9,Pytorch Datasets help,https://www.reddit.com/r/deeplearning/comments/dqzyv9/pytorch_datasets_help/,SEAsFinest,1572785442,"Hi, I'm trying to classify the ESC-50 dataset using pytorch. It comes with a csv file and a set of 2000 audio files. How do I load all of this for training? Pytorch's documentation is unclear to me so I'm sorry if this is a noob question.

&amp;#x200B;

 Here's a link to the screenshot of the beginning of the csv file:

 [https://prnt.sc/pru7yq](https://prnt.sc/pru7yq) 

&amp;#x200B;

And here's the code for loading the data:

import pandas as pd  
import numpy as np  
from torch.utils.data import Dataset, DataLoader  
import torchaudio  
class AudioDataset(Dataset):  
 """"""Audio Files dataset.""""""  
 def \_\_init\_\_(self, csv\_file, root\_dir, transform=None):  
 """"""  
Args:  
csv\_file (string): Path to the csv file with annotations.  
root\_dir (string): Directory with all the audio files.  
transform (callable, optional): Optional transform to be applied  
on a sample.  
""""""  
 self.labels = pd.read\_csv(csv\_file)  
 self.root\_dir = root\_dir  
 self.transform = transform  
 def \_\_len\_\_(self):  
 return len(self.labels)  
 def \_\_getitem\_\_(self, idx):  
 if torch.is\_tensor(idx):  
idx = idx.tolist()  
   
file\_name = os.path.join(self.root\_dir,  
 self.labels.iloc\[idx, 0\])  
data, sample\_rate = torchaudio.load\_wav(file\_name)  
x = data.view(1,1,220500)    #Here I'm just trying to convert each audio file to a Conv1d acceptable format  
landmarks = self.labels.iloc\[idx, 1:\]  
landmarks = np.array(\[landmarks\])  
 \#landmarks = landmarks.astype('float').reshape(-1, 2)  
sample = {'audio': x, 'labels': landmarks}  
 if self.transform:  
sample = self.transform(sample)  
 return sample  
face\_dataset = AudioDataset(csv\_file='/content/drive/My Drive/ESC-50/esc50.csv',  
root\_dir='/content/drive/My Drive/ESC-50/audio')  
dataloader = DataLoader(face\_dataset, batch\_size=16,  
shuffle=True)",5,1
17,2019-11-3,2019,11,3,23,dr1058,shup up call the doctor i see legolas everyone,https://www.reddit.com/r/deeplearning/comments/dr1058/shup_up_call_the_doctor_i_see_legolas_everyone/,ezfopp,1572790913,,0,1
18,2019-11-4,2019,11,4,0,dr1ulz,Help regarding similarity search,https://www.reddit.com/r/deeplearning/comments/dr1ulz/help_regarding_similarity_search/,lonewolf_9,1572794783,"Hi all,

Problem statement :  I have a text ( a sentence / paragraph ) on one side. I have a collection of sentences on other side. Now, for the 1st statement, I need to pick up sentences with best contextual similarity from the database in descending order of some criteria , say, similarity score. The domain is  Life Sciences/ Pharmaceutical/ Healthcare.

Which approach should I proceed with :

1) Elastic search 2) FAISS  3) Building a custom similarity search engine using BERT -as - service. 

Any help will be appreciated.

On the same note, if I don't want to use the database and I have only the 1 sentence as input. However, I want to paraphrase that sentence ( including the context ) in layman terms , how should I proceed ?",4,10
19,2019-11-4,2019,11,4,2,dr3ov4,Recommended native linux laptops with dedicated GPU for &lt;= $1500?,https://www.reddit.com/r/deeplearning/comments/dr3ov4/recommended_native_linux_laptops_with_dedicated/,definitelynotsane,1572802427,"Hi - Looking to spend $1500 or less on a linux laptop that won't have any issues with graphics card drivers, etc.  Would prefer a native install of linux rather than dual booting windows / linux as an MSI machine would force me to do.  

The Lambda laptops start at $2100 so out of my league, and I don't need the full stack pre-installed.  

The system76 systems are pretty expensive despite having similar specs as the MSI desktops (not sure why). An Oryx Pro starts at $1700 and has significantly worse specs than an MSI (GL Series GL65 9SEK-065 15.6"" 144 Hz IPS Intel Core i7 9th Gen 9750H (2.60 GHz) NVIDIA GeForce RTX 2060 16 GB Memory 512 GB NVMe SSD Windows 10 Home 64-bit Gaming Laptop). Not sure why the price discrepancy is so extreme.

Any suggestions?  Thank you!",3,1
20,2019-11-4,2019,11,4,8,dr8tpz,I need help for GANs,https://www.reddit.com/r/deeplearning/comments/dr8tpz/i_need_help_for_gans/,_Berkay_,1572824274,Im searching a kind of algortihm for creating some different vectors from dataset(like image or sound.) but the algortihm that i looked for must have a kind of input. For example i train it with some tagged MNIST data and expect new image of number which i choosed. I heard GANs are good at creating new things. Is there a GAN or any other algorithm that specified at that jobs. Thanks in advance,8,5
21,2019-11-4,2019,11,4,12,drbil6,"What does it mean that ""deep learning"" is ""good"" ?",https://www.reddit.com/r/deeplearning/comments/drbil6/what_does_it_mean_that_deep_learning_is_good/,yetanothernormalG,1572836663,"I wonder if there is some notion in which one could quantify what ""good"" means  
when it comes to deep learning.  


For example, one important aspect in DL is ""throwing away"" not important degrees of freedom. 

In some sense it finds some sort of simple transformations that make two datasets equivalent.

Simple example : machine vision, object recognition.

What transformations are ""equivalent"" transformations ? A bit of rotation, scaling, translation,  
removing colors, changing texture, changing color (of a car, for example), changing the orientation,  
camera angle, source of light. Just to name a few.  


These are all irrelavant degrees of freedom when one wants to classify an image into one that contains a   
car or a motorbike. Just to keep things simple.

Now, the questions comes.

It's not very difficult to write a Stan program that does this without any labeling, having only 100 parameters that   
should be fit.  


Basically you take a software that renders cars, you define some distribution for the parameters to be inferred, and  
then ""just"" do simple Bayesian inference.

This - computation cost aside - would work better than deep learning and it would not need labeled samples.  


Instead, it needs that you specify explicitly what are the degrees of freedom that are not relevant for your classification  
problem. 

So, what deep networks really do, is figuring out the degrees of freedoms that need to be thrown away such that they  
solve your classification problem.  


This is why convnets are useful because they throw away translation symmetric degrees of freedoms, also, polling or what was its name, that throws away scaling related degrees of freedom.

So in essence, deep learning solves an inverse problem, while Bayesian inference solves a ""forward"" problem.

So, if there is some sort of measure, on ""how good a deep learning"" ""something"" is, then it should be related to  
how ""well"" it throws away the ""right"" degrees of freedoms. 

This is a nice idea, because it if problem independent. 

Also, since DL consists of layers, one could wonder, how and where the degrees of freedoms are thrown away.  


If such a measure is found then one could find new training algorithms / or even new algorithms for classification problems, where the algorithm is being built up from building blocks whose task is to throw away degrees of freedoms in one way  
or an other. 

For the case of machine vision, one could engineer such algorithms, since one knows how one can create an image from  
a blueprint, then the questions becomes, if we know the data generating algorithm, then how can we create an algorithm  
that throws away ""the right"" degrees of freedom when inverting the data generating process.

This could be a very specific question, if on starts to think about why deep learning is useful at all.

And maybe more importantly, how can it be made even more useful, if one thinks about such question.

In other words. The problem is the following :

&amp;#x200B;

I have a function (some function, continious or not) with N relvant (fix) +10N irrelevant (randomly varying) input parameters that generates a datasat which has 1000N dimensions and I have only 10N datapoints (that is 10\^4N numbers). The task is, to create an algorithm that predicts the N relevant parameters. If we know what this function is, would that help ? Or would it be better to ""just"" use deep learning ? Or can we use our knowledge of the function to create the inference algorithm ? 

When would Bayesian approach be better and when would deep learning be better ? And why ?

Food for thought.",5,1
22,2019-11-4,2019,11,4,16,dreebx,Nice article on tensorflow 2 and Learning Rates,https://www.reddit.com/r/deeplearning/comments/dreebx/nice_article_on_tensorflow_2_and_learning_rates/,shawemuc,1572853271,How to Improve Training your Deep Neural Network in Tensorflow 2.0 von Simon Hawe https://link.medium.com/UXyF0FASk1,2,16
23,2019-11-4,2019,11,4,17,dret46,Face2Face or something like this,https://www.reddit.com/r/deeplearning/comments/dret46/face2face_or_something_like_this/,sibutum,1572856162,"Hello, anyone here who is experienced and/or can share code for face reenactment like Face2Face or something like this?",5,1
24,2019-11-4,2019,11,4,20,drgby3,Applications of deep learning in the insurance industry,https://www.reddit.com/r/deeplearning/comments/drgby3/applications_of_deep_learning_in_the_insurance/,manneshiva,1572866914,"Build your own scratch and dent detection app or automate KYC by implementing deep learning and OCR. 

[https://nanonets.com/blog/ai-in-insurance/](https://nanonets.com/blog/ai-in-insurance/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=ainsu&amp;utm_content=dl)

&amp;#x200B;

[ai in insurance](https://i.redd.it/po4dxue8nnw31.gif)",2,1
25,2019-11-4,2019,11,4,20,drgcqa,What is the latest technique using in Neural Style Transfer (NST) now ?,https://www.reddit.com/r/deeplearning/comments/drgcqa/what_is_the_latest_technique_using_in_neural/,lmviett,1572867066,"The literature of Gatys et al in 2015 demonstrated the power of CNN in creating artistic. It s been 4 years since then; now ,what kind of neural network is being used for NST?",4,1
26,2019-11-4,2019,11,4,21,drgv5q,5 Facial Recognition Trends and Market Predictions 2019,https://www.reddit.com/r/deeplearning/comments/drgv5q/5_facial_recognition_trends_and_market/,pallavi_sharma,1572870119,,0,0
27,2019-11-5,2019,11,5,0,drjcmq,The test set accuracy is 99%,https://www.reddit.com/r/deeplearning/comments/drjcmq/the_test_set_accuracy_is_99/,cmillionaire9,1572882256,,11,81
28,2019-11-5,2019,11,5,3,drlpjw,"AI Weekly Update - November 4th, 2019!",https://www.reddit.com/r/deeplearning/comments/drlpjw/ai_weekly_update_november_4th_2019/,HenryAILabs,1572891740,"This Weekly Update covers DeepMind's AlphaStar, Microsoft's PipeDream Distributed Training Framework, new tutorials from Tensorflow 2.0 such as HuggingFace in 10 lines of code and many more!

https://youtu.be/-dOW21d8lhU",0,1
29,2019-11-5,2019,11,5,3,drlr0t,University for completing masters in AI / DL/ ML,https://www.reddit.com/r/deeplearning/comments/drlr0t/university_for_completing_masters_in_ai_dl_ml/,kuthubuddinshaik123,1572891913,"I want suggestion on good universities which can provide the above courses. 
US / Canada.
Note;- please let it be budget friendly.",7,3
30,2019-11-5,2019,11,5,5,drn9gn,Need help making Keras generator thread-safe,https://www.reddit.com/r/deeplearning/comments/drn9gn/need_help_making_keras_generator_threadsafe/,Jezebeth,1572897974,"Hello everyone! I'm new to this subreddit, and am really excited to read everything out there. However, during an initial search (multiple, actually) I wasn't able to find any posts on making generator functions thread-safe to use in a Keras fit\_generator() call. 

Backstory: I am working with a CSV that is 38k lines with 4 data points each (so, 38k samples x 4 features). I could probably load this all into memory, but I am hoping to eventually have enough data that it definitely won't fit. I have a generator function (so creatively named generator() below) that feeds my fit\_generator() call with all the samples and batches it wants. However, I recently read up on multiprocessing in Keras, and that my CPU is likely my bottleneck given the GPU is at about... 12% utilization? Somewhere in that ballpark. I've tried just using a wrapper class to try to make it thread-safe, I've made a new class that is supposedly thread-safe, and I'm out of ideas because I keep coming to the same error. The thread-safe generator class is also below, thsf\_generator().

    ValueError: When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.

I am really confused by this because if I comment out the steps\_per\_epoch and validation\_steps in the fit\_generator() call, I still get the error. 

My code is below, any help would be greatly appreciated. I am also open to any optimizations and critiques (I'm not so great with this code - it's been quite a hack and slash to get it working). 

**generator()**

    def generator(data, lookback, lookahead, batch_size=128, step=6):
        i=lookback
        while True:
            if i+batch_size*lookahead&gt;=len(data): i=lookback
            rows=np.arange(i, min(i+batch_size, len(data)))
            i+=1
            samples=np.zeros((len(rows), (-(-lookback//step)), data.shape[-1]))
            targets=np.zeros((len(rows),))
            for j, row in enumerate(rows):
                ind=range(rows[j]-lookback, rows[j], step)
                samples[j]=data.loc[ind]
                targets[j]=data.loc[rows[j]+lookahead]['lowest']
            yield samples, targets

**thsf\_gen()**

    class thsf_gen(Sequence):
        def __init__(self, data, lookback, lookahead, batch_size=128, step=6):
            self.data=data
            self.back, self.ahead, self.i=lookback, lookahead, lookback
            self.batch_size, self.step=batch_size, step
            self.shape=(lookback//step, batch_size)
            self.lock=threading.Lock()
        def __len__(self):
            return int(np.ceil(len(self.data)/float(self.batch_size)))
        def __next__(self):
            with self.lock:
                return self.__getitem__()
        def __getitem__(self):
            if self.i+self.batch_size*self.ahead&gt;=len(self.data): self.i=self.back
            rows=np.arange(self.i, min(self.i+self.batch_size, len(self.data)))
            self.i+=1
            samples=np.zeros((len(rows), (-(-self.back//self.step)), self.data.shape[-1]))
            targets=np.zeros((len(rows),))
            for j, row in enumerate(rows):
                ind=range(rows[j]-self.back, rows[j], self.step)
                samples[j]=self.data.loc[ind]
                targets[j]=self.data.loc[rows[j]+self.ahead]['lowest']
            return samples, targets",10,1
31,2019-11-5,2019,11,5,6,dro75n,Visiting the SOSP 2019 AI System Workshop,https://www.reddit.com/r/deeplearning/comments/dro75n/visiting_the_sosp_2019_ai_system_workshop/,Yuqing7,1572901621,,0,2
32,2019-11-5,2019,11,5,7,drpoqn,Doubt regarding the noise in data,https://www.reddit.com/r/deeplearning/comments/drpoqn/doubt_regarding_the_noise_in_data/,Believinginself,1572907740,"Hey guys, 

I have a doubt. I am confused, for a Deep Learning model while training, given that we know our test data might have noise in it too, whether we should add noise to our train data and let our model learn from the noisy data or should we do the preprocessing step to remove noise in the pipeline and feed the noise removed data. I am asking regarding the efficiency, which one should be preferred and why?

Thanks",1,0
33,2019-11-5,2019,11,5,8,drq6bp,Object Recogntion,https://www.reddit.com/r/deeplearning/comments/drq6bp/object_recogntion/,pranav2109,1572909737,Is there any pretrained model for object recognition trained on dataset other than mscoco in tensor flow or keras?,4,1
34,2019-11-5,2019,11,5,12,drtj6f,Deep Learning Can Be Useful in Eliminating Shortage of Cancer Doctors,https://www.reddit.com/r/deeplearning/comments/drtj6f/deep_learning_can_be_useful_in_eliminating/,analyticsinsight,1572924879,,1,0
35,2019-11-5,2019,11,5,14,druwfd,Deep Learning in the Real World: Dealing with Non-Differentiable Loss Functions,https://www.reddit.com/r/deeplearning/comments/druwfd/deep_learning_in_the_real_world_dealing_with/,HN_Crosspost_Bot,1572932479,,0,4
36,2019-11-5,2019,11,5,16,drvo9f,Deep Learning Inference on Edge Devices,https://www.reddit.com/r/deeplearning/comments/drvo9f/deep_learning_inference_on_edge_devices/,jeffbernard301,1572937456,,1,1
37,2019-11-5,2019,11,5,16,drvt02,Application of deep learning in public policy and governance !!,https://www.reddit.com/r/deeplearning/comments/drvt02/application_of_deep_learning_in_public_policy_and/,cc111222,1572938330,"I just recently bumped with deep learning and it is fascinating but i want to use it for developmental economics for eg. solutions for water and air quality , affordable housing and others. 

Can anyone help me with the process . As a lot of public data is available but how does this fit in  the pipeline and  role of deep learning  along with would really be life saver.",9,6
38,2019-11-5,2019,11,5,21,drybqs,Nice article about how to write better and simpler data science code using funcy,https://www.reddit.com/r/deeplearning/comments/drybqs/nice_article_about_how_to_write_better_and/,shawemuc,1572956166,,0,0
39,2019-11-5,2019,11,5,22,dryzsc,Image document classification,https://www.reddit.com/r/deeplearning/comments/dryzsc/image_document_classification/,sambalshikhar,1572959756," 

https://medium.com/analytics-vidhya/how-i-built-a-document-classification-system-using-deep-convolutional-neural-networks-e1d9a83cbabd

I built a image document classification using Intra-domain transfer learning with inception\_resenet\_v2.Check it out!",0,3
40,2019-11-6,2019,11,6,0,ds1245,Skip connections in Autoencoder,https://www.reddit.com/r/deeplearning/comments/ds1245/skip_connections_in_autoencoder/,Mike_Sv86,1572969175,"Hi all.

I trained an autoencoder for feature extraction purposes. The bottleneck is made up of a fully connected layer with 32 neurons.

When I train my model with skip connections, the reconstructions are perfekt, without them they are a mess, the loss decreases during the first epoch and flattens out after that.

Now Iam wondering if there are any disadvantages with skip connections?

Is my fullly connected layer able to learn good features or is it just ignored due to the skip connections (information leakage?) 

(the model does not seem to Learn something useful without them either though)

Thanks in advance,

Cheers,

Michael",17,10
41,2019-11-6,2019,11,6,4,ds3vex,Do Deep Neural Networks See Faces Like Brains Do?,https://www.reddit.com/r/deeplearning/comments/ds3vex/do_deep_neural_networks_see_faces_like_brains_do/,Yuqing7,1572980864,,0,0
42,2019-11-6,2019,11,6,7,ds7494,Made sentence-similarity calculator,https://www.reddit.com/r/deeplearning/comments/ds7494/made_sentencesimilarity_calculator/,huffonism,1572994730,,0,2
43,2019-11-6,2019,11,6,10,ds96o6,Local entropy maximum in deep belief networks.,https://www.reddit.com/r/deeplearning/comments/ds96o6/local_entropy_maximum_in_deep_belief_networks/,yetanothernormalG,1573004437,"This migh sound trivial or nonsense - but the total
entropy that can be throw away is limitel by the diffence in entopy between the output and input distributions. 

This is nice becouse this gives us an extra constraint that we, both need to maximize the mutual information, between the input and the output. My vague guess is that the  entropy of the network minus the mutual information should be equal to the entropy of the input data. 

This could help in tuning the hyper-parameters (already before the training begins, and making sure, one,way or the other, that during the training the system is driven util the lost entropy is not worse than the entropy loss in the predicted output. The entropy of the output + the entropy loss caused by the network, should be, in ideal case equal to the original entropy.

If you train your deep belief network according to this  idea, then you don't need to wory about regularization. This extra condition makes sure that the network is regularized as much as it could have been.

Also, because this is an extra - purely theoretical calculatnon- no stochasticicity needs to be introduced, explicitly, simply the ""equation of motion""/""steepest descent"" algorithm, extended with this extra entropy term would yield the most relieble predictor, and also calculated point estimates for the mean and variance of each parameter. If our Bayesian model is ""first"" order (not hierarchical, the variances are not random variables) and we have a flat prior, then the this calcultion would agree with the exact Bayesian solution. 

So , a little bit of extra derivation can turn a simple DNN into an exactly solved deep belief network.

It might be even possible to do ""random jumps"" (as it is done in Monte Carlo methods) - akkording to to Metropolis algorithm (or in more generad said, if detailed balance is not violate by the possible jumps).

There are a few interesting thoughts that come to mind in this situation. 

This is basically an algorithm that minimises the Free Energy (F = E-TS)

Systems often freeze below a certain T, especially spin glass like, random systems, they do that even more easily - because liquid configurations are ""just as fine"" as solid ones.  Also, note, that T= dE/dS. 

So, this could be also a steepest descent solution, where the velocity of the ""ball"" which has P-1 number of of spatial degrees of freedom. 

E is the total eneregy in Statistical Physics, in the world of HMC, it depends on the momentum of the ""ball"" and the potential energy of the ""ball"" .

So, in essence, it is pretty straightforward to do HMC without the MC part in DNN-s, this might come handy for searching for a way down (taking into special account how much information are we loosing if we leave the equi-entropic manifold ).  

Ok, so much clever evening thoughts for today :)


Hope it made sense to anyone else than me :)

The reason I wrote about this is the we are allowed to do crazy large jumps, as long as the total energy stays the same. 

So, for example, we could better utilize our neural network if they were ""pinned down"". In other word, all neurons would ""mean"" something. 

For example if the training error does not want to drop then we can start to adjust the network topology, explore several alternatives, akkording to some meaningful way to change the network topology. For example taking away one of the least important (most entropic) wire and connecting two neurons that were yet not connected.  Then trying to stay on the equi-entropic surface, one (can remove a high entropy connection, and replace it with a low entropy connection). Eventually this rearranges the network topology.  Might help removing those 1 million not needed connections and then one could have a chance to understand what that network reallyes means. 

This could also lead to a larger network which is equally accurte (sbut it  generalizes likely better. Since the connections became less entropic and the complexity of the network is higher. So this means that the Neural net was throwing away some irrelevant information and instead created some relevant concepts.

I don't now if this would be so clearly possible if it was not about simple deep belief networks. 

I don't know if ppl are doing this in practice, I am sure they do, but if not, why not?

Cheers,

Jozsef",0,3
44,2019-11-6,2019,11,6,10,ds97v7,How to Build a Deep Learning Computer,https://www.reddit.com/r/deeplearning/comments/ds97v7/how_to_build_a_deep_learning_computer/,MusingEtMachina,1573004593,,17,27
45,2019-11-6,2019,11,6,15,dscco9,[D] Regarding Encryption of Deep Learning Models,https://www.reddit.com/r/deeplearning/comments/dscco9/d_regarding_encryption_of_deep_learning_models/,aseembits93,1573021494,"My team works on deploying models on the edge (android mobile devices).  The data, model, code, everything resides on the client device. Is there any way to protect your model from being probed into by the client? The data and predictions can be unencrypted. Please let me know your thoughts on this and any resources you can point me to. Thanks!",0,1
46,2019-11-6,2019,11,6,16,dsd0g4,AI Insider: What is AI and How Does AI Works? | TechLurn,https://www.reddit.com/r/deeplearning/comments/dsd0g4/ai_insider_what_is_ai_and_how_does_ai_works/,omkar72566,1573025765,,0,1
47,2019-11-6,2019,11,6,17,dsd89v,"DL Book - A^-1 can be represented with only limited precision on a digital computer, WHY?",https://www.reddit.com/r/deeplearning/comments/dsd89v/dl_book_a1_can_be_represented_with_only_limited/,secsilm,1573027264,"In Deep Learningbook 2.3:

https://preview.redd.it/9rv0frorv0x31.png?width=1455&amp;format=png&amp;auto=webp&amp;s=d77f999a35fd89c6e5265d447cd223a3d2e10ab4

If this is due to the calculation of the floating point number, then even if b is used, this problem exists.

Does anyone has a good explanation?",4,3
48,2019-11-6,2019,11,6,18,dsdvr2,Transfer learning behavior on custom image data,https://www.reddit.com/r/deeplearning/comments/dsdvr2/transfer_learning_behavior_on_custom_image_data/,VeeranjaneyuluToka,1573031909,"Hi  All, I am trying to apply transfer learning esp fine-tuning (by  freezing a few layers and allowing a few layers in backprop), i am using  InceptionV3 with ImageNet weights on my own custom data. I have around  76 classes and each class has different objects in it, for ex: class x  has persons, cars, trees and good scenaries etc.. It is not converging  at all with this kind of data. I suspect ImageNet data is kind of  uniformly distributed data (mean that each class has objects of that  type only for ex: cat class has cat images only) but my data is kind of  mixture of Gaussians (mean each class has different objects in it as  described above), is it due to this kind of variation in data or would  there be any other reason. Would really appriaciate if there are any  comments or suggestions on this behavior?",0,1
49,2019-11-6,2019,11,6,19,dsejg2,Numerical gradient descent vs gradient calculation and propagation,https://www.reddit.com/r/deeplearning/comments/dsejg2/numerical_gradient_descent_vs_gradient/,In_for_a_pound,1573036612,"I'm fairly new to gradient based optimisation but was wondering about something.

Why is not done that weights are changed, maybe in staged fashion, and then an approximation of the gradient of error with respect to weights is calculated?

I know it won't be as accurate as taking the derivative of the error function and propagating that backward but considering how SGD is favoured surely some approximation in gradients is workable? It would allow for non-differentiable error functions to be optimised, requiring far less calculation and possibly even avoids the need for back propagation of errors?

Does anyone know of this being done or is it just sub-optimal?

I have heard in passing that this is how optimisation was basically done before the discovery of BP so is that why it has been left behind?",7,0
50,2019-11-6,2019,11,6,23,dsh3io,Cloud services to train ML models,https://www.reddit.com/r/deeplearning/comments/dsh3io/cloud_services_to_train_ml_models/,Jaszunai,1573050780,My PC is unable to handle large datasets. What are some alternatives to training on my PC? Anyone here use cloud services to train their neural networks and have recommendations?,4,2
51,2019-11-7,2019,11,7,2,dsj94t,Object detection,https://www.reddit.com/r/deeplearning/comments/dsj94t/object_detection/,MarkCrass,1573060020,Which Conv net use for object detection ? R-CNN or Mask R-CNN ?,4,1
52,2019-11-7,2019,11,7,2,dsjb6y,Querying about GAN training,https://www.reddit.com/r/deeplearning/comments/dsjb6y/querying_about_gan_training/,ahmedmokhtar97,1573060260,"while training *GAN* network first, i train the Discriminator network to identify the real data,  then i combine the generator and discriminator  together through training leading to question here should i use the learning rate used while training the discriminator to identify real data or not ??  and is there is another way to train GAN network  !!",1,4
53,2019-11-7,2019,11,7,2,dsjtsz,Deep Prognosis: Predicting Mortality in the ICU,https://www.reddit.com/r/deeplearning/comments/dsjtsz/deep_prognosis_predicting_mortality_in_the_icu/,hszafarek,1573062440,,2,24
54,2019-11-7,2019,11,7,3,dsk7u0,Randomly classifying?,https://www.reddit.com/r/deeplearning/comments/dsk7u0/randomly_classifying/,potato-question-mark,1573064074,"Hi

Help me understand this and bear with me if it's a stupid question 

In binary classification, when the accuracy is 50% it means the model is guessing randomly, right?

But for multi class classification, it's not the same. If n_classes = 5, then around 20% accuracy should be when the model is randomly guessing? (1/n_classes)

Thanks!",5,3
55,2019-11-7,2019,11,7,5,dsmeba,600x t-SNE speedups with RAPIDS vs. Sklearn,https://www.reddit.com/r/deeplearning/comments/dsmeba/600x_tsne_speedups_with_rapids_vs_sklearn/,HenryAILabs,1573073674,[removed],0,1
56,2019-11-7,2019,11,7,6,dsn0fc,TensorFlow 2.0 Tutorial in 10 Minutes - Operations (+ Linear Algebra) and CUSTOM training and testing classes.,https://www.reddit.com/r/deeplearning/comments/dsn0fc/tensorflow_20_tutorial_in_10_minutes_operations/,permalip,1573076134,,0,1
57,2019-11-7,2019,11,7,6,dsn5c3,600x t-SNE speedup with RAPIDS!,https://www.reddit.com/r/deeplearning/comments/dsn5c3/600x_tsne_speedup_with_rapids/,HenryAILabs,1573076673,[https://youtu.be/\_4OehmMYr44](https://youtu.be/_4OehmMYr44),0,4
58,2019-11-7,2019,11,7,6,dsn9rh,ProtoPNet Recognizes Birds and Shows Us How in Real Time,https://www.reddit.com/r/deeplearning/comments/dsn9rh/protopnet_recognizes_birds_and_shows_us_how_in/,Yuqing7,1573077156,,2,14
59,2019-11-7,2019,11,7,21,dswtbs,could someone update stackgan,https://www.reddit.com/r/deeplearning/comments/dswtbs/could_someone_update_stackgan/,loopy_fun,1573128430,"could someone update this to the new version of tensorflow so it  can be used in google colab?

[https://github.com/hanzhanggit/StackGAN](https://github.com/hanzhanggit/StackGAN)",2,1
60,2019-11-7,2019,11,7,21,dsx87c,"Saw this review of grokking deep learning on Amazon. Complete noob here, should I still buy/read this book?",https://www.reddit.com/r/deeplearning/comments/dsx87c/saw_this_review_of_grokking_deep_learning_on/,PulkitVyas,1573130753,,9,1
61,2019-11-7,2019,11,7,22,dsxenk,Need Help/Contributions to PyTorch C++ Tutorial for Deep Learning,https://www.reddit.com/r/deeplearning/comments/dsxenk/need_helpcontributions_to_pytorch_c_tutorial_for/,op_prabhuomkar,1573131725,[removed],2,1
62,2019-11-8,2019,11,8,2,dt1fqe,Google T5 Explores the Limits of Transfer Learning,https://www.reddit.com/r/deeplearning/comments/dt1fqe/google_t5_explores_the_limits_of_transfer_learning/,Yuqing7,1573149564,[removed],0,1
63,2019-11-8,2019,11,8,3,dt22ta,Is AutoEncoders in Keras deep learning?,https://www.reddit.com/r/deeplearning/comments/dt22ta/is_autoencoders_in_keras_deep_learning/,fadelbe,1573152152,"The title is enough. I need to make a deep learning project and found a credit card falsification program that uses autoencoders in Keras. I just need to make sure it is indeed a deep learning project and not a machine learning one.

Thank you for any input",2,1
64,2019-11-8,2019,11,8,4,dt2swz,Why my generative adversarial network (gan) is not converging during training?,https://www.reddit.com/r/deeplearning/comments/dt2swz/why_my_generative_adversarial_network_gan_is_not/,classyflyer,1573154906,"I am building a GAN to detect anomalies in images. I built my model on keras because I am only familiar with keras. The generator and discriminator are both an autoencoder, I defined my own loss functions. The concept of this model is this: the model is trained on only normal images and tested on both normal and abnormal images, since the model has only seen normal images during training, it's not able to reconstruct an abnormal image as good as a normal one, so a large reconstruction error can be used as an indication for anomaly. The reason for using 2 autoencoders is that the second reconstructed image will have an even larger distance than the original input thus it can separate the abnormal images even better. I don't know what went wrong but the model doesn't converge no matter how many batches I train it. Can someone please help me find out what went wrong? Thank you so much in advance!

    # Build model
    
    import keras
    from keras import backend as K
    from keras.layers import ReLU, LeakyReLU, Conv2D, Conv2DTranspose, BatchNormalization, concatenate, Flatten, Dense, Reshape
    from keras.models import Model, clone_model
    import numpy as np
    
    
    # Build autoencoder to be the generator
    
    img_shape = (152, 232, 1) # This is the shape of my input images
    latent_dim = 16
    
    inputs = keras.Input(shape=img_shape)
    x = Conv2D(16, 3, padding='same', strides=(2,2), activation='relu')(inputs)
    x = BatchNormalization()(x) 
    x = Conv2D(32, 3, padding='same', strides=(2,2), activation='relu')(x)
    x = BatchNormalization()(x)
    shape = K.int_shape(x)
    x = Flatten()(x)
    latent = Dense(latent_dim, name='latent_vector')(x)
    x = Dense(shape[1] * shape[2] * shape[3])(latent)
    x = Reshape((shape[1], shape[2], shape[3]))(x)
    x = Conv2DTranspose(32, 3, padding='same')(x)
    x = LeakyReLU()(x)
    x = BatchNormalization()(x)
    x = Conv2DTranspose(16, 3, padding='same', strides=(2,2))(x)
    x = LeakyReLU()(x)
    x = BatchNormalization()(x)
    outputs = Conv2DTranspose(1, 3, padding='same', activation='tanh', strides=(2,2))(x)
    
    generator = Model(inputs, outputs)
    
    # Make a second autoencoder to be used as discriminator
    ae_disc = clone_model(generator)
    ae_disc.name=""autoencoder_discriminator""
    
    # Freeze the weights of generator
    generator.trainable = False 
    
    gen_outputs = generator(inputs)
    dis_outputs_1 = ae_disc(inputs)
    dis_outputs_2 = ae_disc(gen_outputs)
    
    # Build discriminator
    discriminator = Model(inputs, [dis_outputs_1, dis_outputs_2])
    
    # Define loss function for discriminator 
    loss_d = K.sum(K.abs(inputs - dis_outputs_1)) - K.sum(K.abs(gen_outputs - dis_outputs_2))
    discriminator.add_loss(loss_d)
    
    # Compile discriminator
    discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)
    discriminator.compile(optimizer=discriminator_optimizer)
    
    # Freeze autoenconder and unfreeze generator
    ae_disc.trainable = False 
    generator.trainable = True 
    
    gen_outputs = generator(inputs)
    gan_outputs_1 = ae_disc(inputs) 
    gan_outputs_2 = ae_disc(gen_outputs)
    
    # Build gan
    gan = Model(inputs, [gan_outputs_1, gan_outputs_2]) 
    
    # Define gan loss
    loss_g = K.sum(K.abs(inputs - gen_outputs)) + K.sum(K.abs(gen_outputs - gan_outputs_2))
    gan.add_loss(loss_g)
    
    # Compile gan
    gan_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)
    gan.compile(optimizer=gan_optimizer)
    
    
    
    # Train model
    
    # Squeeze pixel values into [-1, 1] since I use 'tanh' as activation for the autoencoder output
    x_train = train_imgs.astype('float32') / 255.*2-1 
    
    batch_size = 20
    
    start = 0
    for step in range(1000):
        stop = start + batch_size
        images = x_train[start: stop]
    
        d_loss = discriminator.train_on_batch(images, None)    
        g_loss = gan.train_on_batch(images, None)
    
        start += batch_size
        if start &gt; len(x_train) - batch_size:
            start = 0
    
        # Print losses
        if step % 10 == 0:
            # Print metrics
            print('discriminator loss at step %s: %s' % (step, d_loss))
            print('generator loss at step %s: %s' % (step, g_loss))   

I expected the g\_loss and d\_loss to be smaller and smaller, but they went down after a few batches and kept fluctuating without going down, and I am pretty sure it wasn't overfitted because when I use the trained model to predict a test image, the result is a super blurry image.

I've been trying to get this code to work for days! If you can point me in the right direction it'd be greatly appreciated! Thank you so much!",5,1
65,2019-11-8,2019,11,8,6,dt4cvs,Deep Learning for High-Dimensional Time Series,https://www.reddit.com/r/deeplearning/comments/dt4cvs/deep_learning_for_highdimensional_time_series/,semi_competent,1573160991,,0,1
66,2019-11-8,2019,11,8,6,dt50v4,UNSUPERVISED LEARNING OF 3D REPRESENTATIONS FROM NATURAL IMAGES,https://www.reddit.com/r/deeplearning/comments/dt50v4/unsupervised_learning_of_3d_representations_from/,cmillionaire9,1573163658,,4,1
67,2019-11-8,2019,11,8,9,dt6ut1,Recommendations on GPUs,https://www.reddit.com/r/deeplearning/comments/dt6ut1/recommendations_on_gpus/,topecas,1573171454,[removed],0,1
68,2019-11-8,2019,11,8,10,dt87yo,Classification for low resolution image,https://www.reddit.com/r/deeplearning/comments/dt87yo/classification_for_low_resolution_image/,Yongwook,1573177768,"Hi, I've just joined this community :)

I want to classify low resolution word level text image.

In detail, I want to classify a word image to specific language.

Here's some example below. 

&amp;#x200B;

[Target Result: English](https://preview.redd.it/8k6i1i52adx31.png?width=51&amp;format=png&amp;auto=webp&amp;s=05c232e474def11a43452e6e5b4bb8fb6dcf6f07)

&amp;#x200B;

[Target Result: Korean](https://preview.redd.it/aahpuuv4adx31.png?width=36&amp;format=png&amp;auto=webp&amp;s=d6e99f891ded9003d6447e8903d42f30e7d29c95)

I think, the resolutions of the word images are around (80x30).

The matter is, computational cost and speed.

So, I don't want to scale the image up like (299x299) for Inception network. 

Is there any other solution for this problem?

&amp;#x200B;

Thank you for read this post!",2,1
69,2019-11-8,2019,11,8,10,dt8908,Multi-Million-Dollar AI Data Company Releases New All-in-one Data Annotation Platform (FREE TRIAL),https://www.reddit.com/r/deeplearning/comments/dt8908/multimilliondollar_ai_data_company_releases_new/,LimarcAmbalina,1573177900,[removed],0,1
70,2019-11-8,2019,11,8,12,dt97fx,TensorFlow Flags parsing error: Unknown command line flag 'do_train' Google BERT,https://www.reddit.com/r/deeplearning/comments/dt97fx/tensorflow_flags_parsing_error_unknown_command/,DrowsyTiger22,1573182575,"Hi all,

Im trying to implement google's BERT model as I have a task to complete. 

[https://github.com/tensorflow/models/tree/master/official/nlp/bert](https://github.com/tensorflow/models/tree/master/official/nlp/bert)

1. implement model with parameter do\_train=false, predict data in dev-v1.1.json, creating a CSV file with two columns: question\_id and prediction\_ans to store all your predictions.

I know how to convert the json output into a csv, but when i run the script as shown in the official github, I am getting teh error FLAG Flags parsing error: Unknown command line flag 'do\_train' when in run the script in terminal... so its not recognizing anything in the files. 

I have attached a screenshot of the script and the terminal output. 

[http://prntscr.com/pu0pku](http://prntscr.com/pu0pku)

i think it could be my version of tensorflow? i have v.1.15, installed the tf-nightly build as well, and did the export path thing to connect the path with the model. Im not sure what else could be wrong as it seems like its just not even registering the flags in the run\_squad.py file.",0,1
71,2019-11-8,2019,11,8,12,dt9oyg,How has work on optimizing training cost and model size for deep learning algorithms progressed? Do you have any sources to follow regarding this topic?,https://www.reddit.com/r/deeplearning/comments/dt9oyg/how_has_work_on_optimizing_training_cost_and/,alias_is,1573184973,,0,1
72,2019-11-8,2019,11,8,19,dtdf5n,Greetings from Tessellate Imaging,https://www.reddit.com/r/deeplearning/comments/dtdf5n/greetings_from_tessellate_imaging/,li8bot_,1573208007,[removed],0,1
73,2019-11-8,2019,11,8,19,dtdgb6,Studies in the variation of the features extracted by a CNN?,https://www.reddit.com/r/deeplearning/comments/dtdgb6/studies_in_the_variation_of_the_features/,drr21,1573208207,"Hi, I'm investigating what is the variation in the features extracted by a CNN per class. In other words, if we have a CNN classifier, every time we input an image we can extract a feature layer previous to the classification layer. Let's say we get 1000 features. I'm interesting in knowing what's the variation inside of a class (e.g. dog) for all these 1000 features. Does it follow a gaussian distribution? Or more complex distributions?

I've been looking for work done in this task but I haven't found anything. Do you guys know if someone researched this? Thanks!!",0,1
74,2019-11-8,2019,11,8,22,dtf4y6,Tutorial in how to build nice python CLIs,https://www.reddit.com/r/deeplearning/comments/dtf4y6/tutorial_in_how_to_build_nice_python_clis/,shawemuc,1573218187,How to Write Python Command-Line Interfaces like a Pro  https://link.medium.com/qW8XKsbTr1,0,1
75,2019-11-8,2019,11,8,22,dtf7y6,Problem with training a gan that is chained with a generator(1 input 1 output) and a discriminator (2 inputs 2 outputs).,https://www.reddit.com/r/deeplearning/comments/dtf7y6/problem_with_training_a_gan_that_is_chained_with/,classyflyer,1573218607,"I am building a generator (1 input 2 outputs) and a discriminator (2 inputs and 2 outputs) as two independent networks, and chain them together to build the gan. But unfortunately, when I train the gan, an error keeps telling me that I have to feed values to the first layer of the discriminator, but I think I did feed the following layer to the first layer of the discriminator within the gan. 

    dis_input_1 = keras.activations.linear(gan_inputs)
    

This is the error message I got: 

InvalidArgumentError: You must feed a value for placeholder tensor 'input\_2' with dtype float and shape \[?,152,232,1\] \[\[{{node input\_2}} = Placeholderdtype=DT\_FLOAT, shape=\[?,152,232,1\], \_device=""/job:localhost/replica:0/task:0/device:CPU:0""\]\]

Does anyone know how to fix this? Many thanks in advance!!

This is my entire code:

    import keras
    from keras import backend as K
    from keras.layers import ReLU, LeakyReLU, Conv2D, Conv2DTranspose, BatchNormalization, concatenate, Flatten, Dense, Reshape
    from keras.models import Model, clone_model, load_model
    import numpy as np
    
    
    K.clear_session()
    
    # Build autoencoder to be the generator
    
    img_shape = (152, 232, 1)
    latent_dim = 16
    
    inputs = keras.Input(shape=img_shape)
    x = Conv2D(16, 3, padding='same', strides=(2,2), activation='relu')(inputs)
    x = BatchNormalization()(x)
    x = Conv2D(32, 3, padding='same', strides=(2,2), activation='relu')(x)
    x = BatchNormalization()(x)
    shape = K.int_shape(x)
    x = Flatten()(x)
    latent = Dense(latent_dim, name='latent_vector')(x)
    x = Dense(shape[1] * shape[2] * shape[3])(latent)
    x = Reshape((shape[1], shape[2], shape[3]))(x)
    x = Conv2DTranspose(32, 3, padding='same')(x)
    x = LeakyReLU()(x)
    x = BatchNormalization()(x)
    x = Conv2DTranspose(16, 3, padding='same', strides=(2,2))(x)
    x = LeakyReLU()(x)
    x = BatchNormalization()(x)
    outputs = Conv2DTranspose(1, 3, padding='same', activation='tanh', strides=(2,2))(x)
    
    generator = Model(inputs, outputs)
    generator.summary()
    
    ae_disc = clone_model(generator)
    ae_disc.name=""autoencoder_discriminator""
    
    inputs_1 = keras.Input(shape=img_shape)
    inputs_2 = keras.Input(shape=img_shape)
    dis_outputs_1 = ae_disc(inputs_1)
    dis_outputs_2 = ae_disc(inputs_2)
    
    # Build discriminator
    discriminator = Model([inputs_1, inputs_2], [dis_outputs_1, dis_outputs_2])
    
    # Define loss function for discriminator
    loss_d = K.sum(K.abs(inputs_1 - dis_outputs_1)) - K.sum(K.abs(inputs_2 - dis_outputs_2))
    discriminator.add_loss(loss_d)
    
    # Compile discriminator
    discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)
    discriminator.compile(optimizer=discriminator_optimizer)
    discriminator.summary()
    
    # Freeze discriminator
    discriminator.trainable = False 
    
    gan_inputs = keras.Input(shape=img_shape)
    dis_input_1 = keras.activations.linear(gan_inputs)
    dis_input_2 = generator(gan_inputs)
    [gan_outputs_1, gan_outputs_2] = discriminator([dis_input_1, dis_input_2])
    
    # Build gan
    gan = Model(gan_inputs, [gan_outputs_1, gan_outputs_2]) 
    
    # Define gan loss
    loss_g = K.sum(K.abs(gan_inputs - dis_input_2)) + K.sum(K.abs(dis_input_2 - gan_outputs_2))
    gan.add_loss(loss_g)
    
    # Compile gan
    gan_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)
    gan.compile(optimizer=gan_optimizer)
    gan.summary()
    
    # Train model 
    
    # Squeeze pixel values into [-1, 1] since I use 'tanh' as activation for the autoencoder output
    x_train = train_imgs.astype('float32') / 255.*2-1 
    
    batch_size = 20
    
    start = 0
    for step in range(1000):
        stop = start + batch_size
        images = x_train[start: stop]
        generated_images = generator.predict(images)
    
        d_loss = discriminator.train_on_batch([images, generated_images], None)    
        g_loss = gan.train_on_batch(images, None)
    
        start += batch_size
        if start &gt; len(x_train) - batch_size:
            start = 0
    
        # Print losses
        if step % 10 == 0:
            # Print metrics
            print('discriminator loss at step %s: %s' % (step, d_loss))
            print('generator loss at step %s: %s' % (step, g_loss))",0,1
76,2019-11-8,2019,11,8,23,dtftzk,Learn TensorFlow 2.0: Basic Image Classification Tutorial (Part 1 of 5),https://www.reddit.com/r/deeplearning/comments/dtftzk/learn_tensorflow_20_basic_image_classification/,mippie_moe,1573221730,,1,1
77,2019-11-8,2019,11,8,23,dtgeq0,Conv3D layer with multiple input channels,https://www.reddit.com/r/deeplearning/comments/dtgeq0/conv3d_layer_with_multiple_input_channels/,Mike_Sv86,1573224462,"Hi all.

I have a question regarding keras Conv3D layer. My input are 3D volumes with 4 channels (image plus segmentation masks). 

Now iam wondering how the conv3D layer should be set up to work properly? When I write :

    Conv3D(64, (3, 3, 3), activation='relu', padding='same')(inputs)  

 or

    Conv3D(64, 3, activation='relu', padding='same')(inputs) 

and print out the filter shape it says:

(3, 3, 3, 4, 64)

When I write:  


    Conv3D(64, (3, 3, 4), activation='relu', padding='same')(inputs) 

though, the filter shape is:

(3, 3, 4, 4, 64)

As far as I have understood, the kernel depth should be the same as the image depth, or number of channels.

Now Iam wondering what the correct way is and why the filter shape has 5 dimensions. I would have expected 4 (heigh, width, depth, number of kernels)

&amp;#x200B;

Thanks in advance,

&amp;#x200B;

Cheers,

&amp;#x200B;

M",7,1
78,2019-11-9,2019,11,9,2,dtiaxq,Titanic &amp; Machine Learning Competition: Need somebody to team up with,https://www.reddit.com/r/deeplearning/comments/dtiaxq/titanic_machine_learning_competition_need/,knut_2,1573232585,"I'm looking for somebody to team up with to solve the competition Titanic: Machine Learning from Disaster hosted in [kaggle.com](https://kaggle.com/).

Here's the link:

[https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic)",0,1
79,2019-11-9,2019,11,9,2,dtivam,Choosing cpu / motherboard for a deep learning station,https://www.reddit.com/r/deeplearning/comments/dtivam/choosing_cpu_motherboard_for_a_deep_learning/,S_T47,1573234949,"So Im building a deep learning station because I do deep learning quiet regularly and google cloud just costs too much

I was thinking of the following motherboard;
Asus WS Z390 PRO 
https://www.asus.com/us/Commercial-Servers-Workstations/WS-Z390-PRO/

Mostly because it supports 4 PCIe lanes which allows me to slot more GPUs in (in the future) should I need it (currently I have 1)

Ive heard people say that if you use more GPUs then you need a powerful cpu too. So is the Intel core processors (ones that fit into the 1151 socket) strong enough to run 4 GPUs ? Or more specifically can a Intel core i7 9700k Octa core cpu run 4 GPUs or even 2?",6,1
80,2019-11-9,2019,11,9,4,dtkdm4,RNN not working,https://www.reddit.com/r/deeplearning/comments/dtkdm4/rnn_not_working/,Preetham_Gali,1573241268,,0,1
81,2019-11-9,2019,11,9,4,dtkdrz,Vertical Jump Test with Computer Vision,https://www.reddit.com/r/deeplearning/comments/dtkdrz/vertical_jump_test_with_computer_vision/,HenryAILabs,1573241290,[https://youtu.be/oIqWhCNHa30](https://youtu.be/oIqWhCNHa30),0,1
82,2019-11-9,2019,11,9,4,dtkjb7,help me to find the issue,https://www.reddit.com/r/deeplearning/comments/dtkjb7/help_me_to_find_the_issue/,Preetham_Gali,1573241913,"Can some one please help me out to find the issue with the RNN model which i have written in python.

[https://github.com/preethamgali/RNN\_scratch](https://github.com/preethamgali/RNN_scratch)",2,1
83,2019-11-9,2019,11,9,5,dtlf1d,Questions regarding the design of an experiment with Mask R-CNN,https://www.reddit.com/r/deeplearning/comments/dtlf1d/questions_regarding_the_design_of_an_experiment/,flyingbeanies,1573245470,"Hi, everyone

I'm an undergraduate in Engineering and currently planning an experiment in semantic segmentation using Mask R-CNN (my training data only has mask-type labels, no bouding boxes). I have some questions about training and validation, can someone help me?

**Training**

I have 4 datasets (roughly 30k images): 3 with the same annotation and 1 with more labels. Say, the first 3 have left and right arm labels, while the last one has left arm, right arm, left hand and right hand (my desired labels). I have limited resources (only those $300 in GCP credits). I plan on initializing my weights from COCO or ImageNet. Which is the best strategy:

1. To train with all 3 datasets, freezing my bottom layers and finish training with the final one
2. To train with 1 dataset at a time, freezing the bottom layers for the next dataset until I'm done with the 4th. As in, I train with dataset 1, freeze the bottom layers. Refine for dataset 2, then refine for dataset 3, and finally, for dataset 4.

**Validation**

Considering my resource limitation, how can I guarantee that my analysis is statistically correct? I see many papers training a model once and making affirmations on top of the results for a single iteration (I'm considering training iteration != epoch). Shouldn't I train my model multiple times, say, with a leave-k-out strategy, for instance? In this case, what is an acceptable number of iterations that I should execute?

Thanks a lot!",0,1
84,2019-11-9,2019,11,9,8,dto0py,Training on a cluster,https://www.reddit.com/r/deeplearning/comments/dto0py/training_on_a_cluster/,ssd123456789,1573256721,"I have always either trained models on my own gpu or on Google Colab. However, I need to now train a model on a cluster. All I know is that I need to use SSH and a docker container. Can anyone share any resources that will be helpful in getting started? Couldn't find anything suitable for beginners on YouTube or Google.",2,1
85,2019-11-9,2019,11,9,9,dto8fe,Tensorflow with an AMD GPU in 2019/2020,https://www.reddit.com/r/deeplearning/comments/dto8fe/tensorflow_with_an_amd_gpu_in_20192020/,mobo392,1573257725,,0,1
86,2019-11-9,2019,11,9,9,dtooy1,Java Deep learning cookbook released!,https://www.reddit.com/r/deeplearning/comments/dtooy1/java_deep_learning_cookbook_released/,willis7747,1573259917,[removed],0,1
87,2019-11-9,2019,11,9,11,dtpwsk,Which liquid-cooled RTX 2080 Ti brand to choose? [quiet 4 GPU DL office workstation],https://www.reddit.com/r/deeplearning/comments/dtpwsk/which_liquidcooled_rtx_2080_ti_brand_to_choose/,jakub37,1573266109,"Dear Deep Learning Community,

**tl;dr: What are the best price/value Nvidia RTX 2080 Ti brands for liquid-cooled models worth considering for a future proof, reliable 4 GPU workstation. (3-4 years use).**

I am volunteering to build a 4 GPU, future-proof deep learning workstation for a university lab. The machine will be in the office space and thus we prefer it to be liquid-cooled to reduce the noise. I looked for different GPU brands, and the price differences between liquid cooled models from different companies are substantial. Why is that? Is it good to save money and go with the cheapest?

I found the following RTX 2080 Ti Models so far:

[Zotac GeForce RTX 2080 Ti Graphic Card - 1.35 GHz Core - 1.55 GHz Boost Clock - 11 GB GDDR6](https://www.newegg.com/zotac-rtx-2080-ti-zt-t20810j-10p/p/N82E16814500466) (1244 USD)

[GIGABYTE AORUS GeForce RTX 2080 Ti XTREME WATERFORCE WB 11G Graphics Card, Pre-Installed Waterblock, 11GB 352-Bit GDDR6, GV-N208TAORUSX WB-11GC](https://www.newegg.com/gigabyte-geforce-rtx-2080-ti-gv-n208taorusx-wb-11gc/p/N82E16814932074) (1349 USD)

[EVGA GeForce RTX 2080 Ti FTW3 Ultra Hydro Copper Gaming, 11G-P4-2489-KR, 11GB GDDR6, RGB LED &amp; iCX2 Technology - 9 Thermal Sensors](https://www.amazon.com/EVGA-GeForce-Copper-11G-P4-2489-KR-Technology/dp/B07PWHZT73) (1599 USD)

EVGA brand seems to be a safe choice, according to what I found so far (however I was reading about air-cooled blower style cards). The price for 4 of such GPUs might be to high for decision making people approving the purchase, thus I am looking for alternatives.

I would appreciate your suggestions and comments. Reading a few hardware guides for Deep Learning computer setup, I noticed that the idea of water cooling was recommended but no hardware recommendation were made. Your recommendations with links are welcomed!

Thank you for taking your time to help me in this matter.

Regards, Jakub

P.S. This topic is cross-posted at:

[https://www.reddit.com/r/MachineLearning/comments/dtawvx/which\_liquidcooled\_rtx\_2080\_ti\_brand\_to\_choose/](https://www.reddit.com/r/MachineLearning/comments/dtawvx/which_liquidcooled_rtx_2080_ti_brand_to_choose/)

[https://www.reddit.com/r/buildapc/comments/dtpecb/which\_liquidcooled\_rtx\_2080\_ti\_brand\_to\_choose/](https://www.reddit.com/r/buildapc/comments/dtpecb/which_liquidcooled_rtx_2080_ti_brand_to_choose/)

[https://www.reddit.com/r/MLQuestions/comments/dtpsz7/which\_liquidcooled\_rtx\_2080\_ti\_brand\_to\_choose/](https://www.reddit.com/r/MLQuestions/comments/dtpsz7/which_liquidcooled_rtx_2080_ti_brand_to_choose/)",15,1
88,2019-11-9,2019,11,9,20,dtuv5d,Adding another RTX 2080 Ti or RTX Titan?,https://www.reddit.com/r/deeplearning/comments/dtuv5d/adding_another_rtx_2080_ti_or_rtx_titan/,kitgary,1573299322,"Hi guys, I already have a machine with a RTX 2080 Ti, I want to add another GPU because I want to learn how to train on multiple GPUs and training a larger data set. I can't decide whether I should buy another RTX 2080 Ti and setup NVLink or  buy a RTX Titan instead? Which option is better 2080 Ti NVlink vs 2080 Ti + RTX Titan?

Thanks",8,1
89,2019-11-10,2019,11,10,0,dtxhpi,What can I do to enhance network generalization capability?,https://www.reddit.com/r/deeplearning/comments/dtxhpi/what_can_i_do_to_enhance_network_generalization/,shahriar49,1573314019,"I have a dataset of around 3M training and 300K validation sequences and train an LSTM network with it. I tried many configurations but in most cases I end up with a gap between training and validation loss (and accuracy), as shown in below figure for a 3-layer network of around 90,000 parameters:

&amp;#x200B;

https://preview.redd.it/9izqx9hqkox31.png?width=640&amp;format=png&amp;auto=webp&amp;s=1771440835df1301f6934f6e0d8bbbf81c2df38d

I think it is not the case of overfitting and lack of generalization due to memorizing the input dataset, because number of input samples is way bigger than number of network parameters. What else can be the cause for this gap and how can it be improved?",4,1
90,2019-11-10,2019,11,10,2,dtymkm,2020 AI Residency Guide,https://www.reddit.com/r/deeplearning/comments/dtymkm/2020_ai_residency_guide/,Yuqing7,1573319201,,0,1
91,2019-11-10,2019,11,10,3,dtzqyd,Video processing pipeline with OpenCV,https://www.reddit.com/r/deeplearning/comments/dtzqyd/video_processing_pipeline_with_opencv/,jagin72,1573324348,Hi! Here is [the article](https://medium.com/deepvisionguru/video-processing-pipeline-with-opencv-ac10187d75b) for everybody interested in extracting faces from a video stream using a deep neural networks module from [\#OpenCV](https://www.facebook.com/hashtag/opencv?source=feed_text&amp;epa=HASHTAG). I hope you will like it.,0,1
92,2019-11-10,2019,11,10,6,du1vsn,"Two models containing the same submodel, after training the first model, will the second model's weights be updated also?",https://www.reddit.com/r/deeplearning/comments/du1vsn/two_models_containing_the_same_submodel_after/,classyflyer,1573334272,"Question: after training m1, will the weights in m2 also be updated because it uses the same submodel autoencoder? Thank you very much in advance!

    autoencoder = ...
    
    input1 = keras.Input(shape=img_shape)
    output1 = autoencoder(input1)
    m1 = Model(input1, output1)
    m1.compile(...)
    
    input2 = keras.Input(shape=img_shape)
    output2 = autoencoder(input2)
    m2 = Model(input2, output2)
    m2.compile(...)
    
    # Train model 1 
    m1.train_on_batch(...)",0,1
93,2019-11-10,2019,11,10,8,du3jol,TensorLayer Team Released Reinforcement Learning Algorithm Baseline-RLzoo,https://www.reddit.com/r/deeplearning/comments/du3jol/tensorlayer_team_released_reinforcement_learning/,quantumiracle,1573341927,"Recently,  in order to enable the industry to better use the cutting-edge  reinforcement learning algorithms, the TensorLayer Reinforcement   Learning Team has released a complete library of reinforcement learning   baseline algorithms for the industry  RLzoo. TensorLayer is an  extended  library based on TensorFlow for better supports of basic  neural network  construction and diverse neural network applications.  The RLzoo project  is the first comprehensive open source algorithm  library with  TensorLayer 2.0 and TensorFlow 2.0 since the release of  TensorFlow 2.0.  The library currently supports OpenAI Gym, DeepMind  Control Suite and  other large-scale simulation environments, such as  the robotic learning  environment RLBench, etc.

Link of full post: [https://medium.com/@zhding96/tensorlayer-team-released-reinforcement-learning-algorithm-baseline-rlzoo-2663cfb77904](https://medium.com/@zhding96/tensorlayer-team-released-reinforcement-learning-algorithm-baseline-rlzoo-2663cfb77904)

Link of RLzoo: [https://github.com/tensorlayer/RLzoo](https://github.com/tensorlayer/RLzoo)

Link of RL tutorial: [https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement\_learning](https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement_learning)

Slack group: [https://app.slack.com/client/T5SHUUKNJ/D5SJDERU7](https://app.slack.com/client/T5SHUUKNJ/D5SJDERU7)",2,1
94,2019-11-10,2019,11,10,16,du8ldo,Tensor Core Speedup in FC Network?,https://www.reddit.com/r/deeplearning/comments/du8ldo/tensor_core_speedup_in_fc_network/,salilmathur1690,1573371727,Has anyone benchmarked speed up in fully connected network (without attention/transformer) using a Volta or Turing Tensor Cores?,2,1
95,2019-11-10,2019,11,10,16,du8p0t,Deep learning has a size problem,https://www.reddit.com/r/deeplearning/comments/du8p0t/deep_learning_has_a_size_problem/,HN_Crosspost_Bot,1573372502,,1,1
96,2019-11-10,2019,11,10,22,dub8t7,Fire security warning system(using Yolov3),https://www.reddit.com/r/deeplearning/comments/dub8t7/fire_security_warning_systemusing_yolov3/,christw16,1573391464,"If I use Yolov3 to detect whether there is a fire happened, and then I want to send emails to warn people.

How to send emails automatically?

Thank you.",1,1
97,2019-11-11,2019,11,11,0,dud1h9,AI has learned how to effectively separate audio recordings into music and vocals,https://www.reddit.com/r/deeplearning/comments/dud1h9/ai_has_learned_how_to_effectively_separate_audio/,cmillionaire9,1573400855,,8,1
98,2019-11-11,2019,11,11,8,duj4ye,A simple Android app to transfer Makeup from one face to another. And all processing happens on the device.,https://www.reddit.com/r/deeplearning/comments/duj4ye/a_simple_android_app_to_transfer_makeup_from_one/,cortlandd,1573427511,,7,1
99,2019-11-11,2019,11,11,10,dul1mw,"train a model on synthesis data, generalize it on real data",https://www.reddit.com/r/deeplearning/comments/dul1mw/train_a_model_on_synthesis_data_generalize_it_on/,boostsch,1573436193," I trained a deep learning computer vision model for image segmentation using synthesis data, and it generalizes well on synthesis data. However, when I apply the model in real data, the generalization is not so good. I know I should use some domain adaption techniques, but it is a big topic. Anyone can suggest me some papers that are close to this problem ?",2,1
100,2019-11-11,2019,11,11,17,dupdnz,5 Notable Artificial Intelligence Trends in 2019,https://www.reddit.com/r/deeplearning/comments/dupdnz/5_notable_artificial_intelligence_trends_in_2019/,Karan-Deol,1573459826,,0,1
101,2019-11-11,2019,11,11,18,duq3ar,Awesome Google Tool to build Classifiers - No Code,https://www.reddit.com/r/deeplearning/comments/duq3ar/awesome_google_tool_to_build_classifiers_no_code/,clone290595,1573464717,"I just found this experiment from Google, I've been able to explain Deep Learning to my mom, thanks to this, and that was a hard benchmark.

Very good to build interactive demo's!

[https://teachablemachine.withgoogle.com](https://teachablemachine.withgoogle.com/train/image)",1,1
102,2019-11-11,2019,11,11,19,duqjg9,Transfer Learning with TensorFlow 2,https://www.reddit.com/r/deeplearning/comments/duqjg9/transfer_learning_with_tensorflow_2/,RubiksCodeNMZ,1573467654,,0,1
103,2019-11-11,2019,11,11,20,duqw93,Deep artificial neural networks that can accurately predict the neural responses,https://www.reddit.com/r/deeplearning/comments/duqw93/deep_artificial_neural_networks_that_can/,aiforworld2,1573470057,"A Nature Neuroscience paper shows a deep artificial neural networks that can accurately predict the neural responses produced by a biological brain to arbitrary visual stimuli.

#artificialintelligence #AI #deeplearning #neuralnetworks #brain #Neuroscience 

https://www.nature.com/articles/s41593-019-0517-x.epdf",0,1
104,2019-11-11,2019,11,11,20,dur0cl,Human in the loop workflows for deep learning solutions - OCR review and moderation,https://www.reddit.com/r/deeplearning/comments/dur0cl/human_in_the_loop_workflows_for_deep_learning/,manneshiva,1573470770,"there's a lot of paranoia these days  about how adverse automation's  effects might be on society. there's some tasks that can definitely be automated and will cause certain segments of the workforce their jobs. but alongside, other opportunities will get created that didn't exist  before. our new [blog post](https://nanonets.com/blog/human-in-the-loop-ai/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=hil) discusses how businesses are transforming, about digital information, automation, the future of work and human in the loop workflows as a possible solution to these concerns.

&amp;#x200B;

*Processing gif jojvexrqi1y31...*",0,1
105,2019-11-11,2019,11,11,21,durwiq,Is there a solution for SOTA in the industry for model uncertainty in deep learning?,https://www.reddit.com/r/deeplearning/comments/durwiq/is_there_a_solution_for_sota_in_the_industry_for/,quoniammm,1573476355,[removed],1,1
106,2019-11-12,2019,11,12,0,dutvdi,"Nov 21, Free Talk on PyTorch with Its Co-Author and Maintainer, Adam Paszke",https://www.reddit.com/r/deeplearning/comments/dutvdi/nov_21_free_talk_on_pytorch_with_its_coauthor_and/,ACMLearning,1573485986,,0,1
107,2019-11-12,2019,11,12,0,duu08s,Question regarding data samples for a small dataset,https://www.reddit.com/r/deeplearning/comments/duu08s/question_regarding_data_samples_for_a_small/,topenwor,1573486581,"I'm trying to train an NN for a multiclass text classification problem. The dataset I have is quite small(around 1000-2000 data points) and a total of about 20-30 classes. 

Some classes have more samples available than others, generally around 10-50 more but in some cases 100s more than others. 

For best accuracy and generalization on unknown data, should I limit the number of samples for each class to a certain number or  I should keep the extra samples some of the classes?",3,1
108,2019-11-12,2019,11,12,2,duvpqf,Multiple object detection with CNN,https://www.reddit.com/r/deeplearning/comments/duvpqf/multiple_object_detection_with_cnn/,Betaji2,1573493640,"Hi I am new to deep learning and was wondering if you could detect multiple objects with a CNN in a single frame. For example if I had a CNN trained on cats and dogs and ran a picture of a cat and a dog together through it, then how could I get it to detect both a cat and dog. If this is not possible with a CNN then what method should I use(yolo,SSD,etc). If I could how could do it(in python)?",3,1
109,2019-11-12,2019,11,12,3,duwexu,Open Source Low code transfer learning tool for computer vision,https://www.reddit.com/r/deeplearning/comments/duwexu/open_source_low_code_transfer_learning_tool_for/,abhishek4273,1573496422,"Introducing MONK: An **open-source low code** transfer learning toolkit that acts as a unified wrapper over deep learning frameworks

We used this tool as initial protoypying step while participating in kaggle and codalab competitions, a lot of times accelerating our rankings and reaching top-30% in matter of hours. Ans now releasing it to the public with new future goals. 

Acts as a wrapper over Pytorch, Keras, Mxnet-Gluon

Website: [https://monkai-42.firebaseapp.com/](https://monkai-42.firebaseapp.com/)

Github: [https://github.com/Tessellate-Imaging/monk\_v1](https://github.com/Tessellate-Imaging/monk_v1)

Medium: [https://medium.com/@Abhishek4273/expediting-transfer-learning-the-monks-way-422d7ec40ec6](https://medium.com/@Abhishek4273/expediting-transfer-learning-the-monks-way-422d7ec40ec6)",0,1
110,2019-11-12,2019,11,12,3,duwiq1,Error loading a model (.h5 file) after training yolo-keras classification model,https://www.reddit.com/r/deeplearning/comments/duwiq1/error_loading_a_model_h5_file_after_training/,yazmaz54,1573496824,"I am working on realtime object detection using my laptop's camera with Yolo and Keras. I have trained a model and the resulting output is a .h5 file containing (from my understanding) the model and the weights. When trying to test the model with my webcam I get the following error: ""NameError: name 'yolo\_head' is not defined""

[Here's](https://datascience.stackexchange.com/questions/63017/error-loading-a-model-h5-file-after-training-yolo-keras-classification-model) my code.

Any help would be highly appreciated please I need this for a school project.",3,1
111,2019-11-12,2019,11,12,5,duy5n1,Performance anomaly when testing with part of data,https://www.reddit.com/r/deeplearning/comments/duy5n1/performance_anomaly_when_testing_with_part_of_data/,shahriar49,1573503146,"I have a dataset of around 400K sequences, each sequence being a time-series of imagery observations for a specific pixel within a total of around 32K pixels. The sequences are accumulated over 13 years (each sequence belongs to one year), and I train an LSTM model with different training ratios from 10% to 90% of data (sampling is stratified random). Then I test the model in two scenarios: One time on the whole dataset and another time on one sequences that belong to a specific selected year. I compute overall accuracy and average F1, precision, and recall (averages over classes) and compare the results. I have two problems now:

1- Although in almost all cases I see the performance increases with increasing training ratio from 10% to 90% except in one case of average F1 for ratio of 50%, which is a bit smaller than the same metric for sampling ratio of 30%. What can be the cause? Just random fluctuations?

&amp;#x200B;

2- More important than the above, when I test the trained model on a specific year, the performance measures drop considerably (e.g. overall accuracy of 90% will become 80% or average F1 of 68% become 58%). I don't expect the metrics be exactly the same, but given the sampling for training was done in random and pixels under Landsat measurements was checked to be relatively stable in terms on Landcover conditions, I am a bit surprised by this big performance  decrease. In addition, in this test I have model trained with 70% of data performing considerably worse than model trained with 50% of data (e.g. overall accuracy drop by 5%). Is it just random fluctuation? Doesn't look like that in my eye.",0,1
112,2019-11-12,2019,11,12,5,duyv9i,A great and thorough explanation of convolutional neural networks,https://www.reddit.com/r/deeplearning/comments/duyv9i/a_great_and_thorough_explanation_of_convolutional/,antaloaalonso,1573505808,,2,1
113,2019-11-12,2019,11,12,6,duzfkw,"After watching this - I started to believe that deep learning is not complete BS... if you think it is, like I did, for many years, then watch this. I can imagine that DNNs will change into some form of higher order async functional reactive programming and that might lead to some revolution.",https://www.reddit.com/r/deeplearning/comments/duzfkw/after_watching_this_i_started_to_believe_that/,yetanothernormalG,1573507998,,0,1
114,2019-11-12,2019,11,12,6,duzjh6,Are there any funded conferences with good hindex?,https://www.reddit.com/r/deeplearning/comments/duzjh6/are_there_any_funded_conferences_with_good_hindex/,muaz65,1573508419,"I recently graduated and have 3 publications and 1 submission. All in deep learning and A* confrences. But in order to submit you have to present the paper if accepted. The travel expenditure is quite extensive. Moreover, paper regulations for most confrences cost upto 400$ even for students. Are there any funded conferences with avg Hindex~50 which compensates your travel expenditure?",0,1
115,2019-11-12,2019,11,12,10,dv2ldu,[AI application with source code] Let your machine play Street Fighter!,https://www.reddit.com/r/deeplearning/comments/dv2ldu/ai_application_with_source_code_let_your_machine/,1991viet,1573521839,,12,1
116,2019-11-12,2019,11,12,10,dv2oae,"So Im working on this new project, and I need more data, MUCH more data. So is you could help me out by commenting with some chocolate chip cookie recipes and an honest rating out of 100. This would help me out so much if you could participate.",https://www.reddit.com/r/deeplearning/comments/dv2oae/so_im_working_on_this_new_project_and_i_need_more/,thatnerd69,1573522208,,2,1
117,2019-11-12,2019,11,12,13,dv4wxr,Loss functions for my CNN,https://www.reddit.com/r/deeplearning/comments/dv4wxr/loss_functions_for_my_cnn/,Weap0n_X,1573533198,"Hi everybody! I am currently creating a CNN for digital image processing l, although I would need to implement a loss function different from the standard ones. I would therefore need to ask you if anyone knows where can I find pieces of code with different loss functions created from scratch that I could study in order to learn how to do it (I have already searched on Google but to no avail) or even simple documents, everything that might help me would be extremely welcome.",2,1
118,2019-11-12,2019,11,12,15,dv5xmo,Visualizing output of different filters of CNN,https://www.reddit.com/r/deeplearning/comments/dv5xmo/visualizing_output_of_different_filters_of_cnn/,pranav2109,1573539180,"I am trying to visualize the output of different layers of a CNN for a given input image. The output of the first layer filters are as expected but following that the second and third layers the output are as shown below. In order to visualize I mapped the values to 0-1 but still the problem persists. Is there any specific reason for this?

https://preview.redd.it/93850zpp57y31.png?width=640&amp;format=png&amp;auto=webp&amp;s=b749e88215d09a8fefabd457ed1ead17c751294e",1,1
119,2019-11-12,2019,11,12,16,dv6itq,Visualizing the Future of Computer Vision Across Businesses,https://www.reddit.com/r/deeplearning/comments/dv6itq/visualizing_the_future_of_computer_vision_across/,Karan-Deol,1573542793,,0,1
120,2019-11-12,2019,11,12,19,dv87yw,[Post] Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/dv87yw/post_reinforcement_learning/,cdossman,1573554677," Learning how to train an agent to make decisions that will maximize rewards over time

[https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-4-optimal-policy-search-with-mdp-7fc96158ea8a](https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-4-optimal-policy-search-with-mdp-7fc96158ea8a)",0,1
121,2019-11-13,2019,11,13,3,dvdmxd,Texas A&amp;M and Simon Fraser Universities Open-Source RL Toolkit for Card Games,https://www.reddit.com/r/deeplearning/comments/dvdmxd/texas_am_and_simon_fraser_universities_opensource/,Yuqing7,1573581664,,2,1
122,2019-11-13,2019,11,13,3,dvec5s,Inference in Deep Learning,https://www.reddit.com/r/deeplearning/comments/dvec5s/inference_in_deep_learning/,HenryAILabs,1573584532,[removed],0,1
123,2019-11-13,2019,11,13,8,dviumy,Self-Training with Noisy Student (New ImageNet State-of-the-Art),https://www.reddit.com/r/deeplearning/comments/dviumy/selftraining_with_noisy_student_new_imagenet/,HenryAILabs,1573602482,[https://youtu.be/Y8YaU9mv\_us](https://youtu.be/Y8YaU9mv_us),1,1
124,2019-11-13,2019,11,13,17,dvoqgv,Andrej Karpathys neural network trained on Shakespeares corpus,https://www.reddit.com/r/deeplearning/comments/dvoqgv/andrej_karpathys_neural_network_trained_on/,guacforlife13,1573633359,Was the resulting test produced from his neural network semantically coherent? Grammatically coherent?,2,1
125,2019-11-13,2019,11,13,21,dvqwtc,models for transcription,https://www.reddit.com/r/deeplearning/comments/dvqwtc/models_for_transcription/,kapilg1711,1573647323,"How are acoustic and language models developed for medical and legal transcription services? Is there any way to use the audio files and their transcriptions to build these models? I have many transcription files and their original audio files, but I don't know how to use them to build a model.",1,1
126,2019-11-13,2019,11,13,23,dvsgth,Feature Extraction from Google Maps,https://www.reddit.com/r/deeplearning/comments/dvsgth/feature_extraction_from_google_maps/,pranav2109,1573655066,Is there any work that has been able to extract latent low dimensional features from google maps of the ego vehicle?,4,1
127,2019-11-14,2019,11,14,6,dvyo3e,Is Image/Video Data Collection for Deep Learning is Hard? Share your opinion and we can directly help you with your problem.,https://www.reddit.com/r/deeplearning/comments/dvyo3e/is_imagevideo_data_collection_for_deep_learning/,srbh66,1573680637,,8,1
128,2019-11-14,2019,11,14,7,dvzw1n,Building chess bot for rasberi pi with opencv,https://www.reddit.com/r/deeplearning/comments/dvzw1n/building_chess_bot_for_rasberi_pi_with_opencv/,Jonisas0407,1573685445,"Hello everybody,

I have started attending weekly meetups for ML beginners and all of us needs to think of a project to work on for 10 weeks. I have recently bought a raspi 3 with a camera module and my idea is:

To create a chess bot which would work like this:

- camera on raspi scans the board
- on monitor chess bots move is presented ( i make the move in real life for the bot )
- i make a move
- bots makes a move and so on while scanning the board all the time

Bonus idea:

- instead of playing game from the beginning I could randomly put chess pieces on board and then play from there with the bot


My questions are:

- how would I start to work on this project? I assume I will get the raspi to scan the board and present the live view on monitor.
- what algorithm should I use? There is a dataset on kaggle of 200k chess position images on a board, could I use this to train the model?

Thank you for your suggestions!",2,1
129,2019-11-14,2019,11,14,10,dw27ms,Weird nvidia-smi GPU usage display,https://www.reddit.com/r/deeplearning/comments/dw27ms/weird_nvidiasmi_gpu_usage_display/,Believinginself,1573695768,"Hi, 

I used nvidia-smi to see the GPU memory usage and my GPU 0 has max memory displayed as 11178MiB out of which it displays 6786 MiB is being used. But below that where PIDs are dislayed, it shows 3 users are using GPU 0 each with 5959MiB, 817MiB, 13535MiB resp. The 3rd user's GPU memory usage is more than the capacity of the GPU, how is that possible? Can someone please explain me the weird behavior or if I am interpreting it wrong?",1,1
130,2019-11-14,2019,11,14,12,dw3lnf,A question regarding Mobilenet v3,https://www.reddit.com/r/deeplearning/comments/dw3lnf/a_question_regarding_mobilenet_v3/,awaiss113,1573702581,"I am trying to understand the architecture of Mobilenet v3. I am little confused in the structure. After Conv2d, is 255 added in the output of Conv2d (no. 2 in picture) and then 255 is multiplied by the sum (3 no. in image). and in no. 4, 1x28x28x72 is multiplied by 1x1x1x72. Am I right or I am getting something wrong? After no.4, output size is 1x28x28x72.  
If output of no.3 is multiplied by no.1 then how this multiplication is being done? I am confused at this point.

![img](4gsqpwy5nky31)",1,1
131,2019-11-14,2019,11,14,13,dw48l4,Linux distro,https://www.reddit.com/r/deeplearning/comments/dw48l4/linux_distro/,topecas,1573705914,"Hey everybody! 

Im doing to jump to linux and was just wonder what distro you guys use for DL! I will be using tensorflow 2.0 with NVIDIA GPUS.

Thank you!",0,1
132,2019-11-14,2019,11,14,20,dw7zpy,Any one here tried to create stock perdition,https://www.reddit.com/r/deeplearning/comments/dw7zpy/any_one_here_tried_to_create_stock_perdition/,sarathak7,1573729217,[removed],0,1
133,2019-11-14,2019,11,14,21,dw8rc2,How can a neural net recognize it is out of its training domain?,https://www.reddit.com/r/deeplearning/comments/dw8rc2/how_can_a_neural_net_recognize_it_is_out_of_its/,some_dadaism,1573733943,In a recent kaggle competition with a huge overfitting potential the winning team first searched for features on the training data and after the feature engineering used a Kolmogorov-Smirnov Test for comparing the distribution of the features on the training and validation set. Features with a different distribution on the validation set were excluded. (https://www.kaggle.com/c/LANL-Earthquake-Prediction/discussion/94390#latest-632778) My question is how it is possible to replicate this for a neural network and to realize that the feed forward features of a layer in the end of the network are different from the domain it was trained on? Is there any research that is going into this direction?,13,1
134,2019-11-14,2019,11,14,21,dw8x42,Dropout and Pruning,https://www.reddit.com/r/deeplearning/comments/dw8x42/dropout_and_pruning/,Rebeencs,1573734831," Pruning removes the nodes which add little predictive power for the problem in hand.

&amp;#x200B;

Dropout layer is a regularisation technique, which is used to prevent overfitting during the training phase. Neurons are randomly selected and ignored by the dropout layer during the training phase. Those ignored neurons are temporally removed on the forward pass, and their weights are not updated on the backward pass.

could you please provide some details about their differences, I still think they are doing a similar job, are they?",2,1
135,2019-11-14,2019,11,14,23,dwafhn,Basic question regarding construction of training labels/tensors in YOLOv3 and the concept of anchor box,https://www.reddit.com/r/deeplearning/comments/dwafhn/basic_question_regarding_construction_of_training/,tabmoo,1573742574,[removed],0,1
136,2019-11-15,2019,11,15,0,dwb1h3,Generating Cubism style Modern Art using Generative Adversarial Network(GAN),https://www.reddit.com/r/deeplearning/comments/dwb1h3/generating_cubism_style_modern_art_using/,anyesh,1573745370,"Generating Modern Arts using
Generative Adversarial Network(GAN) on Spell by Anish Shrestha https://link.medium.com/IVnSqLo5A1",0,1
137,2019-11-15,2019,11,15,0,dwb7il,Generating Cubism Style Modern Art using GAN,https://www.reddit.com/r/deeplearning/comments/dwb7il/generating_cubism_style_modern_art_using_gan/,anyesh,1573746102,,3,1
138,2019-11-15,2019,11,15,0,dwbfho,Awesome AI Research and Papers reviewed on Computer Vision News (with codes!) - Nov. 2019,https://www.reddit.com/r/deeplearning/comments/dwbfho/awesome_ai_research_and_papers_reviewed_on/,Gletta,1573747111,"The November issue of Computer Vision News: 38 pages about AI and Deep Learning through research and practical applications.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019November/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-august-pdf/)

Technical articles on pages 4-8 and 24-29. Subscribe for free on page 38.

Enjoy!",0,1
139,2019-11-15,2019,11,15,3,dwdktn,The number of dense layers without activation,https://www.reddit.com/r/deeplearning/comments/dwdktn/the_number_of_dense_layers_without_activation/,fibonacci_bokertov,1573755935,"I've been told that the number of fully connected layers without activation layer between them one after another is limited to 1-2 layers.

 Is this true? I have rnn and then three dense layers, should I use activation layer between fcc layers here?",4,1
140,2019-11-15,2019,11,15,4,dwetp8,Deep Learning in Psychiatry,https://www.reddit.com/r/deeplearning/comments/dwetp8/deep_learning_in_psychiatry/,lkjiomva,1573761230,[removed],0,1
141,2019-11-15,2019,11,15,4,dwevly,FCN full connected network sequence classification ?,https://www.reddit.com/r/deeplearning/comments/dwevly/fcn_full_connected_network_sequence_classification/,nicetryho,1573761451,[removed],0,1
142,2019-11-15,2019,11,15,6,dwgeq2,Looking to use xNN magicsauce to help crack a cold case.,https://www.reddit.com/r/deeplearning/comments/dwgeq2/looking_to_use_xnn_magicsauce_to_help_crack_a/,camwrangles,1573767977,"Hey gang. 

The stakes aren't quite as dramatic as the title, but I thought this would be a great way for me to experiment with deep learning and solve a hit and run at the same time. 

Couple of weeks ago a very inconsiderate woman backed over my motorcycle then proceeded to cover it up by picking the bike up and driving away without leaving a note or inspecting the bike. When I got returned I had no idea it had been damaged, and drove for a couple of blocks before realizing something was off. When I drove back to the scene, I  discovered  the damage, including the fact that my break reservoir was shattered, draining all my brake fluid. I was surley a half a mile away from loosing my front breaks altogether. She literally left me for dead! (cue dramatic music)

Luckily a neighbor security camera caught it all happening. I filed a police report, but unfortunately, I'm unable to recover the license plate so the case is cold.

This is where I was thinking a deep learning project would come in. My thought was that I could set up a similar camera and capture cars parked in this location with similar lighting conditions. I'd then record the actual license plates by hand (or use a higher res camera) so I would have the correct numbers to feed into the training set. 

I've never gone thought this process before, and am not sure if I should use a CNN or GAN here, and frankly not sure what  I would use for a framework (is that the right word). To be honest, I'm not really sure I constructed the last sentence properly. But! I'm eager to learn. I'm a technical person, I enjoy playing around in bash, but I'm just beginning to learn to code. 

I welcome any thoughts, suggestions or advice as I don my digital houndstooth cap and pipe, and begin sleuthing in the AI age. 

&amp;#x200B;

![img](qv8vqax22qy31)

&amp;#x200B;

![video](8ykgowp32qy31)",16,1
143,2019-11-15,2019,11,15,7,dwh1cz,"What are the differences between meta-learning, few-shot learning and imitation learning?",https://www.reddit.com/r/deeplearning/comments/dwh1cz/what_are_the_differences_between_metalearning/,pirilamp,1573770530,[removed],0,1
144,2019-11-15,2019,11,15,13,dwldvm,The Beauty of Deep Neural Networks (Art of the Problem posted today),https://www.reddit.com/r/deeplearning/comments/dwldvm/the_beauty_of_deep_neural_networks_art_of_the/,puppers90,1573791259,,0,1
145,2019-11-15,2019,11,15,19,dwozs8,Kindly let us know your reviews on this in order to improve!,https://www.reddit.com/r/deeplearning/comments/dwozs8/kindly_let_us_know_your_reviews_on_this_in_order/,day1technologies,1573814040,,0,1
146,2019-11-16,2019,11,16,2,dwtvje,Weekly Papers | EMNLP 2019 Best Paper; Facebook XLM-R and More!,https://www.reddit.com/r/deeplearning/comments/dwtvje/weekly_papers_emnlp_2019_best_paper_facebook_xlmr/,Yuqing7,1573838477,,0,1
147,2019-11-16,2019,11,16,4,dwvxvl,DeepMind Research Lead Doina Precup On Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/dwvxvl/deepmind_research_lead_doina_precup_on/,Yuqing7,1573847620,,0,1
148,2019-11-16,2019,11,16,5,dwwmnr,This PyTorch Library Kaolin is Accelerating 3D Deep Learning Research [Paper and Github included in article],https://www.reddit.com/r/deeplearning/comments/dwwmnr/this_pytorch_library_kaolin_is_accelerating_3d/,ai-lover,1573850649,,3,1
149,2019-11-16,2019,11,16,11,dx14vk,Just a fun project :),https://www.reddit.com/r/deeplearning/comments/dx14vk/just_a_fun_project/,JC1DA,1573872527,,1,1
150,2019-11-16,2019,11,16,14,dx2o78,"About beam search. In this 2nd step , i cant to understand that for why for jane we got two outputs . That means for every word there will be 3 words output like for word ""in , jane and September . So total of 9 outputs we will select best 3. And that'y word jane got 2 results(is, visits) ?",https://www.reddit.com/r/deeplearning/comments/dx2o78/about_beam_search_in_this_2nd_step_i_cant_to/,Sahil8141,1573881442,,0,1
151,2019-11-16,2019,11,16,15,dx3icj,My Fun Project --- Need to optimize it further -- Previous link was expired...,https://www.reddit.com/r/deeplearning/comments/dx3icj/my_fun_project_need_to_optimize_it_further/,JC1DA,1573887014,,16,1
152,2019-11-16,2019,11,16,17,dx4874,Resources for understanding Encoder-Decoder networks,https://www.reddit.com/r/deeplearning/comments/dx4874/resources_for_understanding_encoderdecoder/,in_iam,1573892371,"I am trying to design a model for Document Semantic Segmentation. A research paper I'm looking at proposes an encoder-decoder architecture for the model but the paper doesn't go too much into the detail of the architecture.  


Can anyone share with me any/all relevant resources to read up more on Encoder-Decoder models ? (If possible, CNN models)",1,1
153,2019-11-16,2019,11,16,17,dx4e7h,[P] Nearing BERT's accuracy on Sentiment Analysis with a model 56 times smaller by Knowledge Distillation,https://www.reddit.com/r/deeplearning/comments/dx4e7h/p_nearing_berts_accuracy_on_sentiment_analysis/,pirate7777777,1573893672,,0,1
154,2019-11-16,2019,11,16,19,dx5crf,Interesting project ideas for beginner,https://www.reddit.com/r/deeplearning/comments/dx5crf/interesting_project_ideas_for_beginner/,tolo5star,1573900839,"I'm a beginner with some mathematical background and   I am comfortable with python , would love to know any interesting projects as well as some more sources to learn from !",5,1
155,2019-11-17,2019,11,17,1,dx8osj,About beam search,https://www.reddit.com/r/deeplearning/comments/dx8osj/about_beam_search/,Sahil8141,1573920285,,7,1
156,2019-11-17,2019,11,17,7,dxe6hz,Sudden training loss drop.. what is happening?,https://www.reddit.com/r/deeplearning/comments/dxe6hz/sudden_training_loss_drop_what_is_happening/,daisygarland,1573945049,"I was wondering if anyone has seen such a drop in training loss without dropping the learning rate? What could have caused this?

https://preview.redd.it/gpvo31t4p4z31.png?width=1176&amp;format=png&amp;auto=webp&amp;s=d88e3f399d88d4e10480fb3538754d039ceae26a",4,1
157,2019-11-17,2019,11,17,21,dxm4ul,Help request in finding a link,https://www.reddit.com/r/deeplearning/comments/dxm4ul/help_request_in_finding_a_link/,clone290595,1573994775," Crossposting from r/MachineLearning:

Hi, a few months ago I've found in complete serendipity a very cool website, but I can't find it again.

The website was a list of the **several tasks solved by Machine Learning**.

I also think I remember that there was an indicator of ""how much"" the task in question was solved, and I remember that the screen also divides the macro-categories by color.

Can you help me find it?

It was one of the most useful links I've ever seen, and I think it would be good for everyone to have it!

thanks in advance for the help :-)",2,1
158,2019-11-18,2019,11,18,0,dxo2ac,Self- Programmed Self Driving Car with Code,https://www.reddit.com/r/deeplearning/comments/dxo2ac/self_programmed_self_driving_car_with_code/,nowsden,1574005595,"Hello, my last post was this and people said that I should keep you posted so I did that. [https://www.reddit.com/r/deeplearning/comments/ck65xj/is\_it\_weird\_when\_a\_14\_year\_old\_publishes\_a\_paper/](https://www.reddit.com/r/deeplearning/comments/ck65xj/is_it_weird_when_a_14_year_old_publishes_a_paper/). I  came back to my project and kept working on it now I wrote a little post about it. [https://littlemountainman.github.io/2019/11/27/selfdrivingfun/](https://littlemountainman.github.io/2019/11/27/selfdrivingfun/)

I wrote about the development and the steps I took to make this. 

Here is a little sneak peak: 

&amp;#x200B;

https://i.redd.it/j7qxb594p9z31.gif",0,1
159,2019-11-18,2019,11,18,1,dxodbc,Self-Programmed Self Driving Car,https://www.reddit.com/r/deeplearning/comments/dxodbc/selfprogrammed_self_driving_car/,nowsden,1574007008,,0,1
160,2019-11-18,2019,11,18,3,dxpxfn,Deep learning applications in networking and cybersecurity,https://www.reddit.com/r/deeplearning/comments/dxpxfn/deep_learning_applications_in_networking_and/,AlZeus109,1574013718,"Besides anomaly detection, what are other interesting applications of deep learning in networking and cybersecurity?",3,1
161,2019-11-18,2019,11,18,5,dxs3yn,A causal tour of causality - David Lpez Paz -,https://www.reddit.com/r/deeplearning/comments/dxs3yn/a_causal_tour_of_causality_david_lpez_paz/,data_datum,1574022836,"Slides:  [https://drive.google.com/file/d/1IS26HUB20vDKuRGCUGGnukdMxqskRUJ9/view](https://drive.google.com/file/d/1IS26HUB20vDKuRGCUGGnukdMxqskRUJ9/view) 

Video:  [http://tv.vera.com.uy/video/55354](http://tv.vera.com.uy/video/55354)",1,1
162,2019-11-18,2019,11,18,6,dxt9v8,Bias Applications,https://www.reddit.com/r/deeplearning/comments/dxt9v8/bias_applications/,iampaliwal,1574027690,Are there any applications where we can utilise the data bias in the machine learning model?,1,1
163,2019-11-18,2019,11,18,17,dy0n3s,Transfer Learning with TensorFlow 2  Model Fine Tuning,https://www.reddit.com/r/deeplearning/comments/dy0n3s/transfer_learning_with_tensorflow_2_model_fine/,RubiksCodeNMZ,1574066989,,0,1
164,2019-11-18,2019,11,18,18,dy136h,[Research] Explainable Artificial Intelligence (XAI) for 6G: Improving Trust between Human and Machine,https://www.reddit.com/r/deeplearning/comments/dy136h/research_explainable_artificial_intelligence_xai/,cdossman,1574070212,"How can we better build trust between humans and machines? At the heart of our need to add explainability/interpretability/openness to deep learning is the need to build trust in a quantifiable way. Researchers in this paper outline the core concepts of Explainable Artificial Intelligence (XAI) for 6G, including public and legal motivations, definitions of explainability, performance vs. explainability trade-offs, methods to improve explainability, and frameworks to incorporate XAI into future wireless systems.

  
Read more: [https://arxiv.org/abs/1911.04542v1](https://arxiv.org/abs/1911.04542v1?fbclid=IwAR2Pykm3Y_PwC0CozMmLwk2NgRDNJWLhgb9R0sSy1SCxcDAxYBNW1TCVJ-k)",0,1
165,2019-11-18,2019,11,18,20,dy1zuw,AI-powered Optical Character Recognition for Global Businesses,https://www.reddit.com/r/deeplearning/comments/dy1zuw/aipowered_optical_character_recognition_for/,Karan-Deol,1574076560,,0,1
166,2019-11-18,2019,11,18,22,dy3dab,[Research] Interested in Performing End-to-End RL Learning and Experimentation? You Need DeepRacer,https://www.reddit.com/r/deeplearning/comments/dy3dab/research_interested_in_performing_endtoend_rl/,cdossman,1574084739,"To deal with current complexities in training and experimenting RL, researchers recently presented DeepRacer, an experimentation and educational platform for sim2real reinforcement learning.

[https://medium.com/ai%C2%B3-theory-practice-business/interested-in-performing-end-to-end-rl-learning-and-experimentation-you-need-deepracer-d088088ca314](https://medium.com/ai%C2%B3-theory-practice-business/interested-in-performing-end-to-end-rl-learning-and-experimentation-you-need-deepracer-d088088ca314)",0,1
167,2019-11-18,2019,11,18,22,dy3ikz,Bounding box prediction using kalman filter + standard averaging numerical technique,https://www.reddit.com/r/deeplearning/comments/dy3ikz/bounding_box_prediction_using_kalman_filter/,zimmer550king,1574085537,,4,1
168,2019-11-19,2019,11,19,1,dy5cnf,Huawei Tops ETH Zurich 2019 Smartphone Deep Learning Rankings,https://www.reddit.com/r/deeplearning/comments/dy5cnf/huawei_tops_eth_zurich_2019_smartphone_deep/,Yuqing7,1574094067,,1,1
169,2019-11-19,2019,11,19,2,dy6jdk,"About selecting batch size and learning rate, and weight averaging for better generalization. Based on several articles that I encountered recently.",https://www.reddit.com/r/deeplearning/comments/dy6jdk/about_selecting_batch_size_and_learning_rate_and/,senarvi,1574099165,,0,1
170,2019-11-19,2019,11,19,2,dy6lof,Artificial Intelligence and Robotics.,https://www.reddit.com/r/deeplearning/comments/dy6lof/artificial_intelligence_and_robotics/,Fourteen_is_14,1574099429,"These days a lot of courses are being offered on Artificial Intelligence.
The contents of those courses are basically Deep Learning/All kinds of Neural Nets etc.

So I have mainly two questions:
1. Where do Artificial Intelligence and Robotics meet?
2. What are entry level points from career's perspective in those fields?

Additional information apart from these two questions would be helpful too.",1,1
171,2019-11-19,2019,11,19,5,dy8syr,Google Brain Hugo Larochelle on Few-Shot Learning,https://www.reddit.com/r/deeplearning/comments/dy8syr/google_brain_hugo_larochelle_on_fewshot_learning/,Yuqing7,1574108409,,0,1
172,2019-11-19,2019,11,19,6,dy9rhm,Advice on Building a Machine for Deep Learning Research,https://www.reddit.com/r/deeplearning/comments/dy9rhm/advice_on_building_a_machine_for_deep_learning/,TheSmashNGrab,1574112223,"In a nutshell, I'd like to verify that the following build for deep learning research is sensible and if there are ways I can shave off costs or get more bang for my buck with other options: [https://pcpartpicker.com/list/4dj8Mc](https://pcpartpicker.com/list/4dj8Mc)

**Background:** I'm going to be doing research which involves training many different moderately-sized feedforward nets and CNNs. Certainly not at the level of neural architecture search. Without going too much into detail, the research involves comparing neural net performance against other types of models across a number of problems/domains. I intend to train non-neural-net models on the CPU while training the nets on the GPUs.

**Budget/Constraints:** I have about \~$4k to spend at the moment, but can spend more down the line (in next year or so) to buy about 2 more GPUs. As such, in the build above I went with a 2 GPU system that can be easily upgraded to 4 GPUs.

**Rationale for my choices:**

\- I maxed out PSU power, RAM, CPU cores, and chassis size in anticipation of upgrading to 4 GPUs. I don't want to start worrying about PSU/chassis, and CPU/RAM is good for running CPU-heavy experiments in addition to any deep learning on the GPUs going on (even if I upgrade to 4 GPUs, I think each GPU will need at most 2 CPU cores for data batch processing?).

\- In terms of CPU/mobo, from what I've read online it seems like AMD gives you a lot more bang for the buck than Intel, hence the TR+x399 combo. I also don't think it makes sense to wait for the new Ryzen (because they don't have enough PCIe lanes for 4 GPUs?) or the new TR (too expensive).

\- As for the GPUs, I went with GTX 2080 SUPER because that seems like the best option short of 2080 Ti, and I don't think I need the extra memory for my models, so no point paying the premium for the Ti. And I went with blower style, since that seems like a must in terms of cooling if I upgrade to 4 GPUs.

**Questions:**

\- Am I missing any incompatibilities or weird interactions between the components?

\- Are any of the parts/brands I chose not recommended? Perhaps most importantly, PNY for the GPUs?

\- Will this CPU/mobo combo definitely support 4 GTX 2080s? Additionally, If want to install 2 or more NVME SSDs on the mobo, does that affect support for the GPUs (e.g. in terms of PCIe lanes)? Total noob in this regard...

\- Is having blower cards sufficient cooling for the GPUs? Or is additional cooling recommended? And will the answer change in 2 GPU setting vs 4 GPUs?

\- Is there any way to stay around the $4k price point and get 4 2080s right now? Or would that sacrifice too much from the other components?

\-  This will be used in a university setting, and I have the option of putting the build on a rack in the department's server rather than in its own chassis. Ive never installed on a rack before; is that recommended over standalone chassis? And if so, does anyone have advice or resources I can look into for building on a rack?",6,1
173,2019-11-19,2019,11,19,6,dy9vcn,"AI Weekly Update - November 18th, 2019",https://www.reddit.com/r/deeplearning/comments/dy9vcn/ai_weekly_update_november_18th_2019/,HenryAILabs,1574112668,"This Weekly Update covers the new ImageNet state-of-the-art technique with Distillation, a survey on Self-Supervised Learning, trends in Deep Learning and Chip Design from Jeff Dean and many more!

[https://youtu.be/UR1fJs0IIDc](https://youtu.be/UR1fJs0IIDc)",0,1
174,2019-11-19,2019,11,19,10,dydfok,Where to get started. Could use your help yall,https://www.reddit.com/r/deeplearning/comments/dydfok/where_to_get_started_could_use_your_help_yall/,Folow123,1574127886,"Currently switched my major from EE to compsci and statician, Im good at math and know it all minus discrete. Was wondering where I can learn the most machine/ deep learning online? Courses anything I really want to master this subject. I appreciate any and all help",0,1
175,2019-11-19,2019,11,19,11,dydnen,I need help for my project,https://www.reddit.com/r/deeplearning/comments/dydnen/i_need_help_for_my_project/,ApacheT101,1574128854,"Hi, my name is Tan Wei Xian and I am an university student. Currently I am decided to join an international competition and my idea is drone for public safety. 

&amp;#x200B;

Here is my thought about my idea:

1) A surveillance camera detect a criminal in a crowd by using face detection and recognition. The system will send the location to the police department.

&amp;#x200B;

2) The system will send a drone to the area and patrol at there. If the drone spots  the target, it will follow the person and send the current location to the police department. If not, it will patrol at that area.

&amp;#x200B;

Here are my questions:

&amp;#x200B;

1) Do you think this project is possible to do it within five months? If yes, where should I find the resources regarding the system send signal to the drone and drone will fly to that area without any control?

&amp;#x200B;

2) There are two options available for me now, simulation or actual drone, so what method should I choose for this project, if  it is simulation, what software should I choose? If it is actual drone, what drone should I buy? My budget is around 250USD. 

&amp;#x200B;

3) I had contacted with the jury before, he said that I shall make an prototype( an app) . Therefore, does it mean that I don't really need to make a full- functional system?

Thanks a lot!",5,1
176,2019-11-19,2019,11,19,14,dygcgy,Why Deep Learning Beneficial?,https://www.reddit.com/r/deeplearning/comments/dygcgy/why_deep_learning_beneficial/,jefrinadams,1574142890,,0,1
177,2019-11-19,2019,11,19,15,dyguvu,Tensorflow GPU docker image not using GPU,https://www.reddit.com/r/deeplearning/comments/dyguvu/tensorflow_gpu_docker_image_not_using_gpu/,prameshbajra,1574146170,,4,1
178,2019-11-19,2019,11,19,17,dyhirm,5 Notable Artificial Intelligence Trends in 2019,https://www.reddit.com/r/deeplearning/comments/dyhirm/5_notable_artificial_intelligence_trends_in_2019/,aayush-goel,1574150800,,0,1
179,2019-11-19,2019,11,19,17,dyhuyv,List of useful resources - data augmentation,https://www.reddit.com/r/deeplearning/comments/dyhuyv/list_of_useful_resources_data_augmentation/,Chitoyo,1574153368,,0,1
180,2019-11-19,2019,11,19,23,dyl578,Illustrated: Self-Attention,https://www.reddit.com/r/deeplearning/comments/dyl578/illustrated_selfattention/,raibosome,1574173892,,0,1
181,2019-11-20,2019,11,20,2,dyndph,new M.S. in Natural Language Processing in Silicon Valley,https://www.reddit.com/r/deeplearning/comments/dyndph/new_ms_in_natural_language_processing_in_silicon/,marilynawalker,1574183749,[removed],0,1
182,2019-11-20,2019,11,20,3,dyo1ku,Announcing Jupyter Notebooks on AI Cheatsheets (https://www.aicheatsheets.com) - Free 10 Notebook Hours,https://www.reddit.com/r/deeplearning/comments/dyo1ku/announcing_jupyter_notebooks_on_ai_cheatsheets/,kailashahirwar12,1574186576,"Hi Everyone,

Last two months have been hectic for me as we have been working on Jupyter Notebooks for AI Cheatsheets portal.  Two months back, I felt that we need a portal for the beginners with tools to learn data science and machine learning. Sometimes, beginners struggle to acquire resources they need to learn data science and machine learning. 

Finally, we are happy to announce the release of Jupyter Notebooks on AI Cheatsheets portal. Now you can launch Jupyter Notebooks for your data science needs.

We are providing 600 free credits which is equal to 10 Notebook hours. After you use 600 credits, you can request us for a customized package with more credits. 

Visit us at https://www.aicheatsheets.com

Disclaimer: Jupyter Notebooks are in Beta phase and you might face issues while creating or using notebooks. 
We have tried tmake the experience as smooth as possible. In case of any issues, mail us at aicheatsheets@gmail.com.",0,1
183,2019-11-20,2019,11,20,3,dyo4wd,Announcing Jupyter Notebooks on AI Cheatsheets(https://www.aicheatsheets.com) - Free 10 Notebook Hours,https://www.reddit.com/r/deeplearning/comments/dyo4wd/announcing_jupyter_notebooks_on_ai/,kailashahirwar12,1574186952,"Hi Everyone,

Last two months have been hectic for us as we have been working on Jupyter Notebooks for AI Cheatsheets portal.  Two months back, I felt, we need a portal for beginners with tools to learn data science and machine learning. Sometimes, beginners struggle to acquire resources and tools they need to learn data science and machine learning. 

Finally, we are happy to announce the release of Jupyter Notebooks on AI Cheatsheets portal. Now you can launch Jupyter Notebooks for your data science needs.

We are providing 600 free credits which is equal to 10 Notebook hours. After you use 600 credits, you can request us for a customized package with more credits. 

Visit us at [https://www.aicheatsheets.com](https://www.aicheatsheets.com)

We are working on a few more cheatsheets as promised and will release them soon.

Disclaimer: Jupyter Notebooks are in Beta phase and you might face issues while creating or using notebooks. 

We have tried to make the experience as smooth as possible. In case of any issue, reach out to us at [aicheatsheets@gmail.com](mailto:aicheatsheets@gmail.com).",6,1
184,2019-11-20,2019,11,20,4,dypjec,Can Bots Surpass the Realism of Human Dialogue?,https://www.reddit.com/r/deeplearning/comments/dypjec/can_bots_surpass_the_realism_of_human_dialogue/,Yuqing7,1574192581,,2,2
185,2019-11-20,2019,11,20,14,dyxc98,Places365 Dataset,https://www.reddit.com/r/deeplearning/comments/dyxc98/places365_dataset/,arjundupa,1574227143,"Link suggests that the training set of the Places365-Standard dataset is 105 GB. I don't have this much storage. Is there a way I can still access these images?

Also, I have a set of 4000 images that I got from Google Images, and I want to see whether any of these exist in the training set of the Places365-Standard dataset. Is there a way to do this?

Any ideas will be greatly appreciated, thanks!",8,1
186,2019-11-20,2019,11,20,15,dyxyzr,Transforming CRM Operations With Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/dyxyzr/transforming_crm_operations_with_artificial/,Kamlesh_Sarn,1574230671,,0,1
187,2019-11-20,2019,11,20,15,dyy4wf,Neural Responding Machine for Short-Text Conversation,https://www.reddit.com/r/deeplearning/comments/dyy4wf/neural_responding_machine_for_shorttext/,i_amujjawal,1574231698,,0,1
188,2019-11-20,2019,11,20,18,dyzv2d,[Research] Announcing Kaolin - PyTorch Library for Accelerating 3D Deep Learning Research,https://www.reddit.com/r/deeplearning/comments/dyzv2d/research_announcing_kaolin_pytorch_library_for/,cdossman,1574243088," A group of researchers who were working at NVIDIA has introduced Kaolin, a new PyTorch library with an aim to accelerate 3D deep learning research. Kaolin is home for future 3D DL research and you are welcome to make contributions. 

\#PyTorch #3DdeepLearning #ai #aiResearch #educateai #openSourceSoftware

Read more: https://medium.com/ai%C2%B3-theory-practice-business/pytorch-library-for-accelerating-3d-deep-learning-research-6b83df2073bf",0,1
189,2019-11-20,2019,11,20,19,dz0dsi,Is it a good idea to remove the stopwords from the text while performing Deep Learning? (Sentiment Analysis-&gt; RNN),https://www.reddit.com/r/deeplearning/comments/dz0dsi/is_it_a_good_idea_to_remove_the_stopwords_from/,hero_2012,1574246492,"Hi, i was following a course where they taught me about DL. And i am trying to build a sentiment analyser. 

I am using the IMDB movie rating dataset with two labels \`positive\` and \`negative\`.  


While cleaning the reviews, i am performing the following steps.

1. removing punctuations and numbers and other characters and to lowercase

2. remove stopwords

3. remove words with length less than or equal to 2

&amp;#x200B;

However, i have a feeling that removing the stopwords and removing words with length less than 2 is not necessary and this might hurt the prediction by destroying all the structure of the review.",9,1
190,2019-11-20,2019,11,20,19,dz0duh,Sequential combination of CNN and lstm for nlp sentiment analysis,https://www.reddit.com/r/deeplearning/comments/dz0duh/sequential_combination_of_cnn_and_lstm_for_nlp/,ggghash,1574246502,"I'm working on a this approach to sentiment analysis. Pass a 1 hot vector to a CNN convoluting in 1d over n-grams. Then I would like to pass that output along with the original 1 hot sentence vector to an lstm to for sentiment classification.

I'm stuck at the stop between the CNN and lstm. What I'm doing temporarily is just putting them side by side and choosing one each time.

Anyone know of a resource out there to help with this? I'm sure it's been done before.",9,1
191,2019-11-20,2019,11,20,21,dz192e,Harnessing the Intelligence of AI for Content Management,https://www.reddit.com/r/deeplearning/comments/dz192e/harnessing_the_intelligence_of_ai_for_content/,Kunal-sharma,1574251950,,0,1
192,2019-11-20,2019,11,20,22,dz1ubq,Finding Purpose in Life or Why we Exist - Could Stoicism be The Key?,https://www.reddit.com/r/deeplearning/comments/dz1ubq/finding_purpose_in_life_or_why_we_exist_could/,PassionFruit2019,1574255360,,0,1
193,2019-11-20,2019,11,20,22,dz1v4m,Autoencoders,https://www.reddit.com/r/deeplearning/comments/dz1v4m/autoencoders/,atomicBeaver22,1574255487,"Hi everyone, 

Could anyone recommend me a few textbooks and educational resources for generative adversary networks and autoencoders? 

I'm looking for ""deep learning with python"" kind of book. 

Thanks.",7,1
194,2019-11-21,2019,11,21,0,dz38b7,[P] Our team made an app that will tell you if a specific food is allergic to you just by a picture using deep learning and computer vision. I have attached the Github link in the comments.,https://www.reddit.com/r/deeplearning/comments/dz38b7/p_our_team_made_an_app_that_will_tell_you_if_a/,clean_pegasus,1574262231,,19,1
195,2019-11-21,2019,11,21,0,dz3e36,How do anchors in Region Proposal Networks work,https://www.reddit.com/r/deeplearning/comments/dz3e36/how_do_anchors_in_region_proposal_networks_work/,StrasJam,1574262928,"I am having trouble understanding the use of anchors in RPN. From what I understand so far, the final feature map (or maps in case of FPN) is taken as the input for the RPN. RPN first runs a 3x3 convolution on the input, resulting in a new feature map with depth of 512. But here is where I get confused. So a 1x1 convolution is performed twice at each pixel of this 512 depth map, once for the classification (object, nonobject) and once for regression. How do the anchors come into play in all of this. How I understand it is that since the anchors are applied to a given pixel of this 512 depth map, the anchor can be re-projected to the original image based on the field of view of this pixel. So the regression and classification of the 1x1 convolution on this pixel should output 2 classifications and 4 regression values for each of the anchors at this pixel. How can each anchor get a different classification score though? Or a different regression score? Since we are using only a single feature vector of a single pixel in the 512 depth map as input for the classification and regression, how can we tell if one anchor should have a greater classification probability than another. Or how can one anchor get a different regression, again because we only have a single feature vector as the deciding factor.",8,1
196,2019-11-21,2019,11,21,2,dz5ajn,Doing NLP (Swag Task) with GPT-2,https://www.reddit.com/r/deeplearning/comments/dz5ajn/doing_nlp_swag_task_with_gpt2/,h56cho,1574271170,"Hello,

I have a couple of questions about GPT-2. Any help would be highly appreciated.

1. According to the HuggingFace Transformer's website ([https://huggingface.co/transformers/model\_doc/gpt2.html#gpt2doubleheadsmodel](https://huggingface.co/transformers/model_doc/gpt2.html#gpt2doubleheadsmodel)), GPT2DoubleHeadsModel is the GPT2 Model transformer with a language modelling and a multiple-choice classification head on top e.g. for RocStories/SWAG tasks.  Does this mean that the GPT2DoubleHeadsModel can be used for both the regular language modelling tasks (predicting the next token) and also for solving multiple-choice questions? Or does this mean that GPT2DoubleHeadsModel can be used to test machines on the multiple-choice type questions only?
2. How exactly is the SWAG task carried out via GPT-2? For Swag task, do I just feed in the sequence of tokens that represents the question statement along with the sequence that represents multiple choice options into GPT-2, and then simply observe the GPT-2's output, which would denote for the machine's answer to the multiple choice question?

Thank you,",0,1
197,2019-11-21,2019,11,21,3,dz5w8q,Knowledge Distillation with TAs,https://www.reddit.com/r/deeplearning/comments/dz5w8q/knowledge_distillation_with_tas/,HenryAILabs,1574273756,[removed],0,1
198,2019-11-21,2019,11,21,3,dz5yrv,Has anyone programmed mathematical models + deep learning?,https://www.reddit.com/r/deeplearning/comments/dz5yrv/has_anyone_programmed_mathematical_models_deep/,atomicBeaver22,1574274046,"I'm a control systems graduate student trying to program the following paper but using my own mathematical model. 


Https://arxiv.org/pdf/1711.02702&amp;ved=2ahUKEwiv64qwsfnlAhUBWK0KHcv1AQcQFjACegQIBhAB&amp;usg=AOvVaw1bbtns5z5yXOknpz1spM9f

They were kind enough to provide the code that they used for the problem but since I'm not very familiar with the application, it doesn't make much sense.


The problem is that I can only find image processing and sentiment (words) analysis in the internet. I'm looking for a resource that deals with numbers and signals. 

Haven't seen anything on autoencoders and gans for numbers and signals. Any advice or resources?",3,1
199,2019-11-21,2019,11,21,8,dzaid2,RandAugment Explained!,https://www.reddit.com/r/deeplearning/comments/dzaid2/randaugment_explained/,HenryAILabs,1574293745,[https://youtu.be/Zzt9i3gDueE](https://youtu.be/Zzt9i3gDueE),0,1
200,2019-11-21,2019,11,21,12,dzddn6,Created Indoor (Room type) image classification using MONK. Monk is an open-source low-code unified wrapper over major deep learning frameworks. (Links to the blog and framework in comments).,https://www.reddit.com/r/deeplearning/comments/dzddn6/created_indoor_room_type_image_classification/,abhishek4273,1574307513,,4,1
201,2019-11-21,2019,11,21,20,dzhquk,Expansion size from MobileNet V3,https://www.reddit.com/r/deeplearning/comments/dzhquk/expansion_size_from_mobilenet_v3/,Rebeencs,1574334361,[removed],0,1
202,2019-11-21,2019,11,21,23,dzk87m,A good place to start for applying deep learning to algorithmic stock trading?,https://www.reddit.com/r/deeplearning/comments/dzk87m/a_good_place_to_start_for_applying_deep_learning/,phoenix__191,1574347296,"Are there any good MOOC's that can give one a good headstart to work on algorithmic stock trading? There's one specialization on Coursera that involves Reinforcement Learning, is that any good? 

This is for a pet project that my friend and I would like to work on, we don't have a finance background and are relatively new to the field of AI and Machine Learning, it would be great if anyone could suggest how we should go about this. Thanks.",8,1
203,2019-11-22,2019,11,22,3,dzn4pv,Google Brains Nicholas Frosst on Adversarial Examples and Emotional Responses,https://www.reddit.com/r/deeplearning/comments/dzn4pv/google_brains_nicholas_frosst_on_adversarial/,Yuqing7,1574359259,,0,1
204,2019-11-22,2019,11,22,5,dzp2ze,Voila! SOTA French Language Model CamemBERT Debuts,https://www.reddit.com/r/deeplearning/comments/dzp2ze/voila_sota_french_language_model_camembert_debuts/,Yuqing7,1574367005,,0,1
205,2019-11-22,2019,11,22,10,dzt9xi,How multi-head was combined to tokens?,https://www.reddit.com/r/deeplearning/comments/dzt9xi/how_multihead_was_combined_to_tokens/,MrAaronW,1574384405,"I understood that there are multiple attention heads inside BERT. However, how were the attention weights combined to the final hidden state of a token in each layer? For example, \[CLS\] has a hidden size of 1 \* 768 but this was based on 12 attention heads. It would be super nice if someone could point out how to get the final state from these attentions?

&amp;#x200B;

I tried to find the corresponding code in huggingface's repo but I wasn't able to.",0,1
206,2019-11-22,2019,11,22,10,dztzvu,Deep Learning with PyTorch book is now available for free,https://www.reddit.com/r/deeplearning/comments/dztzvu/deep_learning_with_pytorch_book_is_now_available/,ConfidentMushroom,1574387747,,10,1
207,2019-11-22,2019,11,22,16,dzxk7v,Deep Learning with PyTorch,https://www.reddit.com/r/deeplearning/comments/dzxk7v/deep_learning_with_pytorch/,aiforworld2,1574406941,"Deep Learning with PyTorch 

To help developers get started with PyTorch, community is making the 'Deep Learning with PyTorch' book, written by Luca Antiga and Eli Stevens, available for free to the community: 

Free Download:
https://pytorch.org/deep-learning-with-pytorch

https://twitter.com/PyTorch/status/1197603717144432640?s=19",1,1
208,2019-11-22,2019,11,22,18,dzys59,ID card digitization using OCR and graph neural networks. The article will get you started on all the different deep learning based OCR methods and how to use graph convolutional networks for text recognition,https://www.reddit.com/r/deeplearning/comments/dzys59/id_card_digitization_using_ocr_and_graph_neural/,manneshiva,1574415559,,1,1
209,2019-11-22,2019,11,22,18,dzyt7k,Region of interest pooling backpropagation,https://www.reddit.com/r/deeplearning/comments/dzyt7k/region_of_interest_pooling_backpropagation/,0x7A,1574415766,"Hey all,

I'm currently working with the Faster R-CNN object detection network ([https://arxiv.org/pdf/1506.01497.pdf](https://arxiv.org/pdf/1506.01497.pdf)) and wonder how this architecture can be trained end-to-end, as stated in the paper. 

In my understanding, the Region Proposal Network (RPN) outputs (among others) the bounding box offsets for all anchors, leading to the coordinates of all regions of interest. These regions of interest are then fed into a RoI pooling layer, yielding image features which are used for classification as well as further bounding box refinement.

In my opinion, gradients cannot flow back through the RoI pooling layer to the RoI coordinates (which are output by the RPN). So how can the RPN learn to predict good anchor offsets without these gradients? What am I missing here?

Thanks in advance!",0,1
210,2019-11-22,2019,11,22,21,e00l9e,How to tokenize SWAG dataset to use it with GPT-2?,https://www.reddit.com/r/deeplearning/comments/e00l9e/how_to_tokenize_swag_dataset_to_use_it_with_gpt2/,h56cho,1574427250,"Hello,

I am new to NLP so I have lots of questions.

I am interested in doing NLP with GPT-2 and the SWAG dataset ([https://rowanzellers.com/swag/](https://rowanzellers.com/swag/))

&amp;#x200B;

Below is an excerpt from the first data from the SWAG dataset, to show how the dataset is structured:

\`\`\`

,video-id,fold-ind,startphrase,sent1,sent2,gold-source,ending0,ending1,ending2,ending3,label 0,anetv\_jkn6uvmqwh4,3416,

Members of the procession walk down the street holding small horn brass instruments. A drum line,Members of the procession walk down the street holding small horn brass instruments.,A drum line,gold,passes by walking down the street playing their instruments.,has heard approaching them.,arrives and they're outside dancing and asleep.,turns the lead singer watches the performance.,0

\`\`\`

The first line of the data shows how SWAG dataset is structured. Descriptions of the meaning of each item (\`video-id\`, \`fold-ind\`,\`start phrase\`,\`sent1\`... \`ending3\`,\`label\`) can be found on the website below:

[https://github.com/rowanz/swagaf/tree/master/data](https://github.com/rowanz/swagaf/tree/master/data)

How should I tokenize this SWAG dataset to process it with GPT-2 (with the double heads model, for instance)? Can someone please give me an example?

Thank you,",0,1
211,2019-11-22,2019,11,22,22,e00qq2,Is stylized image caption still a direction worth exploring in 2019?,https://www.reddit.com/r/deeplearning/comments/e00qq2/is_stylized_image_caption_still_a_direction_worth/,doragd,1574428078,[removed],0,1
212,2019-11-22,2019,11,22,22,e00thk,Deep Learning PyTorch Template,https://www.reddit.com/r/deeplearning/comments/e00thk/deep_learning_pytorch_template/,FrancescoSZ,1574428480,"*Previosly posted on* r/pytroch *but I think it maybe be usefull to all deep learning enthusiast.*

Hi guys,

I have created a deep learning quick start template for PyTorch. It includes:

* modularity: we split each logic piece into a different python submodule
* data-augmentation: we included [imgaug](https://imgaug.readthedocs.io/en/latest/)
* ready to go: by using [poutyne](https://pypi.org/project/Poutyne/) a Keras-like framework you don't have to write any train loop.
* [torchsummary](https://github.com/sksq96/pytorch-summary) to show a summary of your models
* reduce the learning rate on a plateau
* auto-saving the best model
* experiment tracking with [comet](https://www.comet.ml/)
* logging using python [logging](https://docs.python.org/3/library/logging.html) module
* a playground notebook to quick test/play around

[https://github.com/FrancescoSaverioZuppichini/PyTorch-Deep-Learning-Template](https://github.com/FrancescoSaverioZuppichini/PyTorch-Deep-Learning-Template)

Let me know if you find it useful :)",1,1
213,2019-11-22,2019,11,22,22,e00zcx,Yoshua Bengio on Human-level AI,https://www.reddit.com/r/deeplearning/comments/e00zcx/yoshua_bengio_on_humanlevel_ai/,TheTesseractAcademy,1574429373,,0,1
214,2019-11-22,2019,11,22,22,e012gu,Deep Learning with PyTorch,https://www.reddit.com/r/deeplearning/comments/e012gu/deep_learning_with_pytorch/,HN_Crosspost_Bot,1574429831,,2,1
215,2019-11-22,2019,11,22,22,e01bce,How to process common sense reasoning task with GPT-2?,https://www.reddit.com/r/deeplearning/comments/e01bce/how_to_process_common_sense_reasoning_task_with/,h56cho,1574431072,"Hello,

I am new to NLP so I have lots of questions.  
I am interested in carrying out common sense reasoning task with GPT-2, for example, with Winograd Schema Challenge dataset.

Q1. How should I tokenize the Winograd Schema Challenge dataset to process it with GPT-2 (with the double heads model, for instance)? Can someone please give me an example?

Q2. Can GPT2DoubleHeadsModel ([https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313](https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313)) be used to conduct common sense reasoning task with Winograd Schema Challenge dataset?

Q3. How exactly does the ""next sentence prediction head"" of GPT2DoubleHeadsModel \*[https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313](https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313)) work?

Thank you,",0,1
216,2019-11-23,2019,11,23,2,e045wu,How encoder and decoder work together in Transformer,https://www.reddit.com/r/deeplearning/comments/e045wu/how_encoder_and_decoder_work_together_in/,HippeTeddyBear,1574443708,"What's up guys! Hope everyone is doing well.

I have a question about the Transformer model.  Here is the [paper](https://arxiv.org/pdf/1706.03762.pdf)

From my understanding, the encoder projects each word embedding of inputs into a representation (z) with self-attention considered.  

&gt;In ""encoder-decoder attention"" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder.  

I don't quite understand how the representation (z) got transformed into key and value then applied to the decoder. 

Any help would be appreciated! Have a good day!",0,1
217,2019-11-23,2019,11,23,5,e06f2o,"Why Bounding ""boxes"" and not Bounding ""circles""?",https://www.reddit.com/r/deeplearning/comments/e06f2o/why_bounding_boxes_and_not_bounding_circles/,Believinginself,1574452935,"Why do we have squares/rectangles or boounding ""boxes"" rather than bounding ""circles""? Is it related to computation ease? Would someone be able to give indepth answer to this logic?

Thanks",2,1
218,2019-11-23,2019,11,23,7,e08dn1,"Weekly Papers | Quoc V. Le and Kaiming He Look at Vision; Intelligence, Psychology and AI; Evolving the Hearthstone Meta and More!",https://www.reddit.com/r/deeplearning/comments/e08dn1/weekly_papers_quoc_v_le_and_kaiming_he_look_at/,Yuqing7,1574461087,,0,1
219,2019-11-23,2019,11,23,11,e0bdmu,Promise of spiking neural nets?,https://www.reddit.com/r/deeplearning/comments/e0bdmu/promise_of_spiking_neural_nets/,ndronen,1574474738,"I'm noticing more papers about spiking neural networks on the arXiv and, before I start to delve into them, am wondering whether it's worth the time. The abstracts of some papers claim significant reduction in power consumption, which could be advantageous for inference. Do these claims assume the use of a neuromorphic processor or can the benefits be reaped with CPU/GPU/FPGA? That's inference. And trainkng? How do the best spiking network training schemes work? Is the network first trained with dense layers and then the neurons are modified to make them spiking?",0,1
220,2019-11-23,2019,11,23,15,e0e77q,"Created leaf diseases classifier that can detect 38 diseases using MONK's hyper parameter tuning. Monk is an open-source low-code unified wrapper over major deep learning frameworks. Blog: http://bit.ly/hyper-param-tuning-with-monk, Github: http://bit.ly/monk-github",https://www.reddit.com/r/deeplearning/comments/e0e77q/created_leaf_diseases_classifier_that_can_detect/,abhishek4273,1574490664,,1,1
221,2019-11-23,2019,11,23,16,e0etsr,AI-enabled Time Machine Lens,https://www.reddit.com/r/deeplearning/comments/e0etsr/aienabled_time_machine_lens/,cmillionaire9,1574494919,,5,1
222,2019-11-23,2019,11,23,20,e0glop,OpenAI releases Safety Gym for reinforcement learning | VentureBeat,https://www.reddit.com/r/deeplearning/comments/e0glop/openai_releases_safety_gym_for_reinforcement/,RankLord,1574507557,,0,1
223,2019-11-23,2019,11,23,22,e0hjzg,Should I train my GPT2 neural network on the excerpts on the articles first before I train on the training dataset?,https://www.reddit.com/r/deeplearning/comments/e0hjzg/should_i_train_my_gpt2_neural_network_on_the/,h56cho,1574514074,"Hello,

I am interested in processing ARC dataset with GPT-2 neural network.  
The ARC dataset ([http://nlpprogress.com/english/question\_answering.html](http://nlpprogress.com/english/question_answering.html)) is a question answering, which contains 7,787 genuine grade-school level, multiple-choice science questions. The dataset comes with the regular train/test/val sets of the multiple choice questions, as well as the huge corpus of texts that is extracted from various articles that explains the scientific concepts that can be used to solve these 7,787 multiple choice questions (i.e. this huge corpus is not in the multiple choice format; it's just a series of excerpts from various articles).

My question is, is there a need to train my GPT2 neural network with the series of excerpts from various articles before I train the same network with the training set of multiple-choice questions, since the GPT2 network itself wouldn't have acquired any scientific knowledge that is required to solve these 7,787 multiple-choice questions prior to processing this particular dataset? or is it okay to just directly train the GPT2 neural network based on the training set of multiple choice questions without first training the network on the series of articles?

Thank you,",0,1
224,2019-11-24,2019,11,24,0,e0j1lk,Is the tesla k40 still viable?,https://www.reddit.com/r/deeplearning/comments/e0j1lk/is_the_tesla_k40_still_viable/,LEDNEWB,1574521839,And at what price?,0,1
225,2019-11-24,2019,11,24,0,e0jdgg,How to tokenize ARC dataset (NLP question)?,https://www.reddit.com/r/deeplearning/comments/e0jdgg/how_to_tokenize_arc_dataset_nlp_question/,h56cho,1574523417,"Hello,

I am interested in processing the ARC dataset ([http://nlpprogress.com/english/question\_answering.html](http://nlpprogress.com/english/question_answering.html)) with the GPT2 double heads model neural network. The dataset (tab delimited) is structured as below:

\`\`\`

Question               Answer

Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era? (A) worldwide disease (B) global mountain building (C) rise of mammals that preyed upon plants and animals (D) impact of an asteroid created dust that blocked the sunlight.          D

\`\`\`

I know that I am supposed to tokenize the dataset before passing it into GPT2 double heads model for doing NLP.

How should I tokenize this data? More specifically,

1. should I add a special token before each character that denotes for multiple choice options (A), (B), (C) and (D)?
2. should I add special token before each string that denotes for the contents of the multiple choice options?
3. Am I supposed to add the tokens ""&lt;bos&gt;"" and ""&lt;eos&gt;"" at the beginning and at the end of each question statement?
4. If I am to pass this data into a \*\*GPT2 Double Heads Model\*\* (The GPT2 model with two heads) for processing multiple choice questions,  what should I do with the part that denotes for an actual answer to the multiple choice question?

So for instance, to generate an input sequence for the GPT2 double heads model, should I break up the original question statement into 4 sequences, 1 for each multiple choice option, and apply the tokenization to each of the 4 sequences as below?:

\`\`\`

&lt;bos&gt; Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era? &lt;spec\_token1&gt; (A) &lt;spec\_token2&gt; worldwide disease &lt;eos&gt;

&lt;bos&gt; Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era?  &lt;spec\_token1&gt; (B) &lt;spec\_token2&gt; global mountain building &lt;eos&gt;

&lt;bos&gt; Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era?  &lt;spec\_token1&gt; (C) &lt;spec\_token2&gt; rise of mammals that preyed upon plants and animals &lt;eos&gt;

&lt;bos&gt; Which of these do scientists offer as the most recent explanation as to why many plants and animals died out at the end of the Mesozoic era?  &lt;spec\_token1&gt; (D) &lt;spec\_token2&gt; impact of an asteroid created dust that blocked the sunlight.    &lt;eos&gt;

\`\`\` 

Thank you,

PS: I found this site [https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313](https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313) and it seem to address some of the questions I have, but still this is not a complete help.",0,1
226,2019-11-24,2019,11,24,0,e0jiz0,"PyTorch, RedisAI &amp; Hangar: The missing pieces of a complete deep learning workflow  Sherin Thomas",https://www.reddit.com/r/deeplearning/comments/e0jiz0/pytorch_redisai_hangar_the_missing_pieces_of_a/,gkorland,1574524142,,0,1
227,2019-11-24,2019,11,24,2,e0kshk,Training CoreML Object Detection model from scratch using CreateML,https://www.reddit.com/r/deeplearning/comments/e0kshk/training_coreml_object_detection_model_from/,TomekB,1574529376,,0,1
228,2019-11-24,2019,11,24,2,e0kxwt,Project implementation based on papers,https://www.reddit.com/r/deeplearning/comments/e0kxwt/project_implementation_based_on_papers/,christw16,1574529975,"Hello everyone,
I wanna ask is there any suggestions for doing a project which is based on deep learning papers

Thank you!",2,1
229,2019-11-24,2019,11,24,12,e0td2v,Deep learning models depends on ?,https://www.reddit.com/r/deeplearning/comments/e0td2v/deep_learning_models_depends_on/,santhuraj,1574567602,"How to get good result or outcome when applying machine learning/deep learning models? 
Try to elaborate your opinion.",7,1
230,2019-11-24,2019,11,24,12,e0teqd,Implementing simple probabilistic model with negative log likelihood loss (CS294-158 Deep Unsupervised Learning Spring 2019 Berkeley Uni Week 1 Warm Up Excercise),https://www.reddit.com/r/deeplearning/comments/e0teqd/implementing_simple_probabilistic_model_with/,dosssman,1574567846,,0,1
231,2019-11-24,2019,11,24,13,e0tk4m,Images as input to LSTM + Teacher Forcing- PyTorch,https://www.reddit.com/r/deeplearning/comments/e0tk4m/images_as_input_to_lstm_teacher_forcing_pytorch/,anand_altekar,1574568581,"Hi,

I want to pass data of shape (18,3,128,128) (these are 18 images of shape (3,128,128) at a time in LSTM of 17 layers.  
at time 0 input = (data\[0\], (h\_0,c\_0)) and output = (h\_1,c\_1)  
at time 1 input = (data\[1\], (h\_1, c\_1)) and output = (h\_2\_c\_2)  
  
at time 16 input = (data\[15\], (h\_15, c\_15)) and output = (h\_16, c\_16)

*(I deliberately want to pass the images directly without encoding.)*

Docs mention that input to LSTM should be (seq\_len, batch\_size, hidden\_size)

I'm guessing for me: (seq\_len=18, batch\_size=1, hidden\_size=3\*128\*128) is that correct? 

How would I implement teacher forcing though? I'm trying something on the following lines but can't figure out exactly how to proceed.  (num\_layers=17)

class trialLSTM(nn.Module):

def \_\_init\_\_(self, seq\_len, input\_size, hidden\_size, batch\_size, num\_layers):

super(trialLSTM, self).\_\_init\_\_()

self.seq\_len = seq\_len

self.input\_size = input\_size

self.hidden\_size = hidden\_size

self.batch\_size = batch\_size

self.lstm = nn.LSTM(seq\_len, batch\_size, input\_size)

def init\_hidden(self):

\# initialize the hidden state and the cell state to zeros

hidden = torch.zeros(self.batch\_size, self.hidden\_size)

cell = torch.zeros(self.batch\_size, self.hidden\_size)

return hidden, cell

&amp;#x200B;

def forward(self, x, (h\_0, c\_0)):

output = torch.empty(17, 17) # format is (hidden\_states, time\_steps)

for t in range(seq\_len+1):

if t==0:

hidden, cell = self.lstm(x\[0\], (h\_0,c\_0))

else:

hidden, cell = self.lstm(x\[t\], (h\_1,c\_1))

I don't know how to go forward from here. Please help. Thanks!",7,1
232,2019-11-24,2019,11,24,16,e0veyw,I improved my previous algorithm to predict 3D bounding boxes,https://www.reddit.com/r/deeplearning/comments/e0veyw/i_improved_my_previous_algorithm_to_predict_3d/,zimmer550king,1574580273,,0,1
233,2019-11-24,2019,11,24,18,e0w73r,3 Ways to Encode Categorical Variables for Deep Learning,https://www.reddit.com/r/deeplearning/comments/e0w73r/3_ways_to_encode_categorical_variables_for_deep/,RankLord,1574586084,,0,1
234,2019-11-24,2019,11,24,23,e0z8xp,career guidance,https://www.reddit.com/r/deeplearning/comments/e0z8xp/career_guidance/,Preetham_Gali,1574606202,[removed],0,1
235,2019-11-25,2019,11,25,0,e0zk36,Help needed,https://www.reddit.com/r/deeplearning/comments/e0zk36/help_needed/,salmanc2,1574607934,"Is there anyone who can help me understand a project and explain each individual line of code? The project is on glaucoma detection. I'm trying to do something similar to it but first I need to understand an example project. I'm fairly new to deep learning, so it would be very helpful if someone can explain what's going on over a videochat/voice call. I'll send over the code of anyone is interested. Thank you.",3,1
236,2019-11-25,2019,11,25,4,e12ulo,Mish: A self regularized non-montonic neural activation function,https://www.reddit.com/r/deeplearning/comments/e12ulo/mish_a_self_regularized_nonmontonic_neural/,Xa9aX,1574622184,[removed],0,1
237,2019-11-25,2019,11,25,5,e1423b,"Question: DVD (4:3), Bluray (16:9 cropped) - image restoration with deep learning possible?",https://www.reddit.com/r/deeplearning/comments/e1423b/question_dvd_43_bluray_169_cropped_image/,Nyard,1574627078,[removed],0,1
238,2019-11-25,2019,11,25,12,e19x2n,grid search hyperparameters for an image classification problem,https://www.reddit.com/r/deeplearning/comments/e19x2n/grid_search_hyperparameters_for_an_image/,47xsquared,1574651976,"if you guys or girls have time could you please help answer my question. 

I have tried solving this myself.

Some help could be nice.

Here is the question:

[my question on stackoverflow](https://stackoverflow.com/questions/59023969/grid-search-hyperparameters-for-an-image-classification-model)

Thank you guys!",2,1
239,2019-11-25,2019,11,25,16,e1cbds,Deep Learning based Seed Quality Tester,https://www.reddit.com/r/deeplearning/comments/e1cbds/deep_learning_based_seed_quality_tester/,zom8ie99,1574665254,"Dear researchers,

I have taken a step in merging of Deep Learning with Agriculture and Industry with this first conference paper. Please take a look at it.

Link: [https://www.researchgate.net/publication/337475039\_DEEP\_LEARNING\_BASED\_SEED\_QUALITY\_TESTER](https://www.researchgate.net/publication/337475039_DEEP_LEARNING_BASED_SEED_QUALITY_TESTER)

Feedbacks are highly welcomed.

Thank you",0,1
240,2019-11-25,2019,11,25,16,e1ckvq,Natural Language Processing is redefining human interaction,https://www.reddit.com/r/deeplearning/comments/e1ckvq/natural_language_processing_is_redefining_human/,day1technologies,1574666919,,0,1
241,2019-11-25,2019,11,25,17,e1dazb,"Training and Deploying a Multi-Label Image Classifier using PyTorch, Flask, ReactJS and Firebase data storage Part 1: Multi-Label Image Classification using PyTorch",https://www.reddit.com/r/deeplearning/comments/e1dazb/training_and_deploying_a_multilabel_image/,thevatsalsaglani,1574671708,,8,1
242,2019-11-25,2019,11,25,18,e1dwyc,Deep Learning for Programmers Ebook,https://www.reddit.com/r/deeplearning/comments/e1dwyc/deep_learning_for_programmers_ebook/,RubiksCodeNMZ,1574675791,,0,1
243,2019-11-25,2019,11,25,19,e1edfn,5 Facial Recognition Trends and Market Predictions 2019,https://www.reddit.com/r/deeplearning/comments/e1edfn/5_facial_recognition_trends_and_market/,Kunal-sharma,1574678752,,0,1
244,2019-11-25,2019,11,25,21,e1fpu1,[Blog Post] The fusion of physics simulation and machine learning,https://www.reddit.com/r/deeplearning/comments/e1fpu1/blog_post_the_fusion_of_physics_simulation_and/,akira_AI,1574686718,,0,1
245,2019-11-25,2019,11,25,22,e1fqyx,How to do dynamic pricing using the PAO framework,https://www.reddit.com/r/deeplearning/comments/e1fqyx/how_to_do_dynamic_pricing_using_the_pao_framework/,TheTesseractAcademy,1574686882,,0,1
246,2019-11-25,2019,11,25,22,e1g00g,I found some easy hacks to Learn AI and ML on my own,https://www.reddit.com/r/deeplearning/comments/e1g00g/i_found_some_easy_hacks_to_learn_ai_and_ml_on_my/,KiranKiller,1574688221,"So its been quite a long time  I have struggled with such a question myself for quite some time. That is why I started studying various blogs and watching short YouTube videos which are useful for anyone who wants to learn about Machine Learning  


I came across many blogs and online courses..but recently I read medium blog which I completely related to and it did really help me get started. I now know how important Mathematics is! Specially Probability.  


I think this will help you too!  


 [https://medium.com/@anupamasingh\_12727/how-do-you-learn-machine-learning-ai-on-your-own-cf671f802d3](https://medium.com/@anupamasingh_12727/how-do-you-learn-machine-learning-ai-on-your-own-cf671f802d3)",1,1
247,2019-11-26,2019,11,26,1,e1i1ic,dreaming about deep learning,https://www.reddit.com/r/deeplearning/comments/e1i1ic/dreaming_about_deep_learning/,47xsquared,1574697797,"I dreamt that my deep learning model achieved an accuracy of 80 percent.

I probably dreamt this because I am having trouble improving my image classification model.

I love deep learning!",0,1
248,2019-11-26,2019,11,26,3,e1kpzn,AI Helps Quantum Chemists Determine Molecular Wave Functions,https://www.reddit.com/r/deeplearning/comments/e1kpzn/ai_helps_quantum_chemists_determine_molecular/,Yuqing7,1574708327,,0,1
249,2019-11-26,2019,11,26,4,e1l3yc,"My first DL post! ""Weight initialization  The Why""",https://www.reddit.com/r/deeplearning/comments/e1l3yc/my_first_dl_post_weight_initialization_the_why/,quazar42,1574709835,"It should be a very quick read, this post will help you increase your intuition on why we need to use a good weight initialization strategy, how important is it anyways?

[Here](https://medium.com/@lgvaz/weight-initialization-the-why-874028fa5939?sk=69cdbae17341e2d034202a773839d372) is the link. Any feedback is very much appreciated, I was never a good writer on school so I do have much to learn =)

Thanks all",6,1
250,2019-11-26,2019,11,26,6,e1njln,"AI Weekly Update - November 25th, 2019",https://www.reddit.com/r/deeplearning/comments/e1njln/ai_weekly_update_november_25th_2019/,HenryAILabs,1574719184,https://youtu.be/4SMkOBOM504,0,1
251,2019-11-26,2019,11,26,7,e1nr02,[P] Does anyone know where I can get document datasets with version histories?,https://www.reddit.com/r/deeplearning/comments/e1nr02/p_does_anyone_know_where_i_can_get_document/,crowdsourcerer,1574719984,"I'm looking for large datasets containing documents with version histories. An obvious place to look is GitHub since they store codebases with version histories, but it looks like the [GH Archive](https://www.gharchive.org/) only tracks activity events, not code.

Any of the following kinds of datasets would serve my purposes:  
\- A dump of codebases from source control (e.g. GitHub)  
\- Documents (e.g. Google Docs) with revision histories  
\- Any other set of entities that go through an evolutionary lifecycle from initial to final version.

Any guidance is greatly appreciated; thank you.",1,1
252,2019-11-26,2019,11,26,7,e1nyab,Does anyone know where I can get document datasets with version histories?,https://www.reddit.com/r/deeplearning/comments/e1nyab/does_anyone_know_where_i_can_get_document/,crowdsourcerer,1574720792,"I'm looking for large datasets containing documents with version histories. An obvious place to look is GitHub since they store codebases with version histories, but it looks like the [GH Archive](https://www.gharchive.org/) only tracks activity events, not code.

Any of the following kinds of datasets would serve my purposes:  
\- A dump of codebases from source control (e.g. GitHub)  
\- Documents (e.g. Google Docs) with revision histories  
\- Any other set of entities that go through an evolutionary lifecycle from initial to final version.

Any guidance is greatly appreciated; thank you.",0,1
253,2019-11-26,2019,11,26,10,e1qhpi,"Introducing dKeras, new framework for distributed Keras, 30x inference improvements on large CPUs",https://www.reddit.com/r/deeplearning/comments/e1qhpi/introducing_dkeras_new_framework_for_distributed/,s-offer,1574731682,[removed],0,1
254,2019-11-26,2019,11,26,13,e1sh2h,How to use SSD to send object that it detected to another class in python,https://www.reddit.com/r/deeplearning/comments/e1sh2h/how_to_use_ssd_to_send_object_that_it_detected_to/,Betaji2,1574741217,"Hi, I made a SSD for my robot. The problem I am having is finding the variable that holds the object predictions of the frame or where the object prediction is being made. I have a robot that has to respond to different outside stimuli differently(ex for stair it would trigger the method to go up it). I am using the tensorflow models code for the SSD.  Where can I find where the prediction is being made so I can use that to trigger a certain method?Thx",0,1
255,2019-11-26,2019,11,26,13,e1sse9,Deep Learning with PyTorch [Free Book],https://www.reddit.com/r/deeplearning/comments/e1sse9/deep_learning_with_pytorch_free_book/,ai-lover,1574742852,,6,1
256,2019-11-26,2019,11,26,14,e1t4gb,Pyramid Vector Quantization and Bit Level Sparsity in Weights for Efficient Neural Networks Inference,https://www.reddit.com/r/deeplearning/comments/e1t4gb/pyramid_vector_quantization_and_bit_level/,BLMACPVQ,1574744703," [arxiv.org/abs/1911.10636](https://arxiv.org/abs/1911.10636)

This paper exploits the sparsity of neural networks weights at the level of their bit representation in order to eliminate multipliers from dot product calculations. It's mainly aimed at hardware implementation of inference engines. Dot products are calculated with a slightly modified accumulator. Arbitrary precision of the weights is supported from binary to floating point, with the same simple accumulator.

An analysis of performance  is given for Tiny Yolo v3 as well as a FIR filter.",0,1
257,2019-11-26,2019,11,26,15,e1u5n7,"Deep Learning Outperforming Classic ML Methods, Says Report",https://www.reddit.com/r/deeplearning/comments/e1u5n7/deep_learning_outperforming_classic_ml_methods/,analyticsinsight,1574750561,,1,1
258,2019-11-26,2019,11,26,15,e1u9l4,Image Classification for Images (below 40x40),https://www.reddit.com/r/deeplearning/comments/e1u9l4/image_classification_for_images_below_40x40/,data_autopsy,1574751256,"I have been exploring options for Image Classification for images (as low as 20x20). Image is bit distorted as well compared to CIFAR (32x32). I have tried focal loss during classification but results are not good. Is there any other approach you guys can nudge me towards? Also, I'm having close to 130+ classes and around 30-40 classes are underrepresented as low as 0.001 of training data. Is there a solution for that as well? I would really appreciate the help.",3,1
259,2019-11-26,2019,11,26,17,e1vbru,Would you use Dual Shot Face Detectors to perform Facial Recognition ?,https://www.reddit.com/r/deeplearning/comments/e1vbru/would_you_use_dual_shot_face_detectors_to_perform/,antmoreau,1574758433,,0,1
260,2019-11-26,2019,11,26,18,e1vied,Deep Learning vs Neural Networks,https://www.reddit.com/r/deeplearning/comments/e1vied/deep_learning_vs_neural_networks/,lukky43,1574759714,,0,1
261,2019-11-26,2019,11,26,19,e1w4rs,"I want to build a NN from scratch, where do I start?",https://www.reddit.com/r/deeplearning/comments/e1w4rs/i_want_to_build_a_nn_from_scratch_where_do_i_start/,veranceftw,1574763888,"Hello, I would like to learn how to build a NN from scratch and I am looking for some good articles/tutorials that can get me into it. 

I want to build a simple texture segmentation/classification network so I can tweak it accordingly to my needs, I feel like I am trying to kill a moth with a cannon and starting from scratch could help me understand what I really need and how to adapt my architecture.

I'll be using Pytorch (we all know why)

&amp;#x200B;

Cheers!",1,1
262,2019-11-26,2019,11,26,19,e1waer,High resolution visualizations of loss landscapes that use real data in both video and image format,https://www.reddit.com/r/deeplearning/comments/e1waer/high_resolution_visualizations_of_loss_landscapes/,javismiles,1574764951,,0,1
263,2019-11-26,2019,11,26,19,e1wew5,"High resolution video visualization of mode connectivity using real data | NeurIPS 2018, ARXIV:1802.10026",https://www.reddit.com/r/deeplearning/comments/e1wew5/high_resolution_video_visualization_of_mode/,javismiles,1574765814,,5,1
264,2019-11-26,2019,11,26,20,e1wmz3,Should I use additive or multiplicative inverse as loss regularizing term?,https://www.reddit.com/r/deeplearning/comments/e1wmz3/should_i_use_additive_or_multiplicative_inverse/,marcoroberti,1574767260,[removed],0,1
265,2019-11-26,2019,11,26,20,e1wxf8,Breaking Black-box AI,https://www.reddit.com/r/deeplearning/comments/e1wxf8/breaking_blackbox_ai/,mto96,1574769135,,1,1
266,2019-11-26,2019,11,26,21,e1x2y3,Intel Core i7-9700K or AMD Ryzen 7 3800X?,https://www.reddit.com/r/deeplearning/comments/e1x2y3/intel_core_i79700k_or_amd_ryzen_7_3800x/,baabaaaam,1574770056," I'm currently building a new machine, mostly for ML (NLP). But I can't decide if I should go for Intel or AMD for the CPU. My budget for the CPU is max 400. So which of the two would be better?",5,1
267,2019-11-26,2019,11,26,23,e1yjcb,Importance of joint distribution.,https://www.reddit.com/r/deeplearning/comments/e1yjcb/importance_of_joint_distribution/,santhuraj,1574777944,Why do we care about joint distribution?try to elaborate in few sentences.,3,1
268,2019-11-27,2019,11,27,1,e20h65,Quick question about transformer ( attention is all you need ),https://www.reddit.com/r/deeplearning/comments/e20h65/quick_question_about_transformer_attention_is_all/,nalra1234,1574786349,"I took an implementation [https://github.com/kpot/keras-transformer](https://github.com/kpot/keras-transformer) and made it ""run"" for a simple problem where inputs are batches of sequences.   


My question is, adding heads means you slice the batch of sequences .. Meaning adding heads doesn't add or remove hyperparameters to the network.  
However, adding depth to the attention layers, isn't that supposed to add a lot more hyperparameters? Surprisingly in my model, when I add depth, and do model.summary, it doesn't evolve at all.  


Thanks in advance.",1,1
269,2019-11-27,2019,11,27,3,e22j0a,How do RNNs for text-to-speech know when a character ends?,https://www.reddit.com/r/deeplearning/comments/e22j0a/how_do_rnns_for_texttospeech_know_when_a/,Johannes8,1574794564,"Im a Little confused about what size the single time frame is that the RNN analyses one after the other.

One assumption would be a single sample, so with a samplerate of 16k that would be 1/16000 second. That sure isnt enough to know what character it will be. I so far thought that for each calculation from the RNN it outputs a matrix of probable letters. A CTC for example would then take the most probable ones and apply the loss function. I know how CTC solves the problem of not having aligned input data but still the question is:

How many ms does the RNN take from a spectrogram so it can make meaningful assumptions. If the neural network knew that one letter is 200ms it could simply look at that. But since it doesnt I wonder how it knows when the letter is finished or if it doesnt how can it output something meaningful for say 10x20ms from a 200ms letter.

I assume its the recurrent part that I dont get if we assume the RNN has a bidirectional recurrent layer. Sure it can propagate knowledge to the next iteration but still it has to output a matrix for the current segment aswell.

I hope you know where I struggle to understand. Im currently trying to understand the DeepSpeech architecture by Baidu",0,1
270,2019-11-27,2019,11,27,4,e22s1c,How do RNNs know what to output for a singe time-frame for e2e speech-to-text,https://www.reddit.com/r/deeplearning/comments/e22s1c/how_do_rnns_know_what_to_output_for_a_singe/,Johannes8,1574795509,"Im a little confused about what size the single time frame is that the RNN analyses one after the other from say a 2sec audio recording.

One assumption would be a single sample, so with a samplerate of 16k that would be 1/16000 second. That sure isnt enough to know what character it will be. I so far thought that for each calculation from the RNN it outputs a matrix of probable letters. A CTC for example would then take the most probable ones and apply the loss function. I know how CTC solves the problem of not having aligned input data but still the question is:

How many ms does the RNN take from a spectrogram so it can make meaningful assumptions. If the neural network knew that one letter is 200ms it could simply look at that. But since it doesnt I wonder how it knows when the letter is finished or if it doesnt how can it output something meaningful for say 10x20ms from a 200ms letter.

I assume its the recurrent part that I dont get if we assume the RNN has a bidirectional recurrent layer. Sure it can propagate knowledge to the next iteration but still it has to output a matrix for the current segment aswell.

I hope you know where I struggle to understand. Im currently trying to understand the DeepSpeech architecture by Baidu",0,1
271,2019-11-27,2019,11,27,4,e234n6,MarioNETte: Few-Shot Identity Preservation in Facial Reenactment,https://www.reddit.com/r/deeplearning/comments/e234n6/marionette_fewshot_identity_preservation_in/,Yuqing7,1574796927,,0,1
272,2019-11-27,2019,11,27,6,e24jal,Are chatbots good source of passive income?,https://www.reddit.com/r/deeplearning/comments/e24jal/are_chatbots_good_source_of_passive_income/,DreamOfDestiny,1574802428,"Apologizing for noob question, I am new here.

I will start my master degree in data science next year, and mostly will be busy studying and researching. And to pay tuition fee I was considered to work part time or freelancing. However, I want to give my all to education, to absorb all knowledge that university can give me and therefore, thinking about ways to make money with deep learning ( I self learned basics - intermediate stuff )

I want to know whether making DL/ML chatbots for messengers any profitable? Or there are better way to make some passive income with ML.

Also, I have an idea of regularizing traffics lights with the help of DL/DRL.
But, I assume that this project is more research based and less commercial.",4,1
273,2019-11-27,2019,11,27,6,e24kaj,Help Us Design the Future,https://www.reddit.com/r/deeplearning/comments/e24kaj/help_us_design_the_future/,danae-ixd,1574802538,"Hello!

We are Interaction Design Master's students from the Estonian Academy of Arts and it would be really awesome if you could give us some **real human insight** for our Service Design project.

We are on a quest to bridge the gap between creative innovators and meaningful work.

How?

Take this short **3-minute** survey and we'll show you what's cooking ;)

[https://creativeinnovators.typeform.com/to/Wytz4N](https://creativeinnovators.typeform.com/to/Wytz4N)",2,1
274,2019-11-27,2019,11,27,7,e2604z,Multiplexed CNN: Selective branch training using control signal in Keras,https://www.reddit.com/r/deeplearning/comments/e2604z/multiplexed_cnn_selective_branch_training_using/,ayvin_tech,1574808034,"Training multiplexed cnn model on MNIST data by selectively switching using control signal. It can be useful in training networks like conditional imitation learning, multi-branch output that depends on control action, etc.

Code available at: [https://github.com/2vin/multiplexed\_cnn](https://github.com/2vin/multiplexed_cnn)",4,1
275,2019-11-27,2019,11,27,10,e28862,I need help for a project,https://www.reddit.com/r/deeplearning/comments/e28862/i_need_help_for_a_project/,Betaji2,1574817551,Hi I need help on my SSD.  I trained the model(using the tensorflow models code on github) but I can find where the prediction of the object is being made. I need this to return that prediction so my robot could preform a certain action based on what that prediction is(ex if their is a ball it picks it up). Where can I find where the prediction is being made? Sorry I know it is a bit of a dumb question.,12,1
276,2019-11-27,2019,11,27,10,e28jm1,Surging training loss,https://www.reddit.com/r/deeplearning/comments/e28jm1/surging_training_loss/,shahriar49,1574818982,"I have a 3 layer recurrent neural network (128 cells in each layer - around 330K parameters for the whole network) and train it with datasets of various sizes (I am using RMSprop as the optimizer with its default parameters). But I get below behavior when I train the model with a data set of around 3 million samples or more while everything is fine with smaller datasets:

&amp;#x200B;

https://preview.redd.it/igh97px0v4141.png?width=640&amp;format=png&amp;auto=webp&amp;s=dc1bb649695b628a9beb8b148864755e5a78378a

What can be the reason for surging training accuracy? It doesn't make sense to me that training loss go upward!

I am running my code under Tensorflow/Keras on a machine with an Nvidia GPU. No runtime or memory error encountered during simulation.",5,1
277,2019-11-27,2019,11,27,12,e29liz,"Is it possible and how to do Object Detection on a STM32 microchip with around 1M Flash and 320K RAM? Not necessary real time, but quicker is better.",https://www.reddit.com/r/deeplearning/comments/e29liz/is_it_possible_and_how_to_do_object_detection_on/,rockkingjy,1574823720,[removed],0,1
278,2019-11-27,2019,11,27,17,e2d4ap,Transformer NN,https://www.reddit.com/r/deeplearning/comments/e2d4ap/transformer_nn/,fibonacci_bokertov,1574843289,How can use tge tranformer network for regression? In other words for many to one task?,0,1
279,2019-11-27,2019,11,27,17,e2dcsf,Build and and Deploy a deep learning app to AWS from scratch: an end-to-end tutorial ,https://www.reddit.com/r/deeplearning/comments/e2dcsf/build_and_and_deploy_a_deep_learning_app_to_aws/,ahmedbesbes,1574844831,,0,1
280,2019-11-27,2019,11,27,21,e2f996,[POST] Why tf.keras? One ring to rule them all!,https://www.reddit.com/r/deeplearning/comments/e2f996/post_why_tfkeras_one_ring_to_rule_them_all/,cdossman,1574856986,"Some of the advanced features in TensorFlow 1.0 like Graph, AutoGraph, and Eager Execution certainly get the job done, but what a headache! 

This TensorFlow 1.0 vs 2.0  series demonstrates how you can take advantage of tf.keras, a much more painless way to build models. Check it out  https://medium.com/@lsgrep/tensorflow-1-0-vs-2-0-part-3-tf-keras-ea403bd752c0",0,1
281,2019-11-28,2019,11,28,1,e2i636,"PyTorch implementation of a transformer chatbot. Code is explained with highschool level language, without jargon, down to the fundamentals with diagrams in ipython notebooks",https://www.reddit.com/r/deeplearning/comments/e2i636/pytorch_implementation_of_a_transformer_chatbot/,clam004,1574871087,,7,1
282,2019-11-28,2019,11,28,5,e2m9dm,Which system(laptop) would be better for deep learning ? i5 9300H and GTX- 1650 VS i79750H and GTX- 1050Ti,https://www.reddit.com/r/deeplearning/comments/e2m9dm/which_systemlaptop_would_be_better_for_deep/,no0b123,1574886649,help me out . thanks,4,1
283,2019-11-28,2019,11,28,6,e2n3y2,How could I make a CNN detect multiple objects in a single frame?,https://www.reddit.com/r/deeplearning/comments/e2n3y2/how_could_i_make_a_cnn_detect_multiple_objects_in/,Betaji2,1574889954,I made a CNN but I want to use it to predict more than one object in a single frame. What modifications would I have to make to make to do this? Thx,7,1
284,2019-11-28,2019,11,28,11,e2rgkw,"Go master Lee Sedol quits, unable to win over AI opponents.",https://www.reddit.com/r/deeplearning/comments/e2rgkw/go_master_lee_sedol_quits_unable_to_win_over_ai/,sinhpi,1574909167,,9,1
285,2019-11-28,2019,11,28,12,e2sa3t,what GPU workstation do you recommend?,https://www.reddit.com/r/deeplearning/comments/e2sa3t/what_gpu_workstation_do_you_recommend/,Deepseed_India,1574913000,"I am looking for a pre-built GPU workstation for Deep learning experiments for my lab. I will be sharing the workstation with another labmate. I was looking for configuration details for the Workstation(CPU, RAM, GPUs, cooling, etc). My budget is $12,000.  Any help is appreciated.

I did find a list of vendors from [Reddit post](https://www.reddit.com/r/deeplearning/comments/9lryzf/what_prebuilt_gpu_workstations_do_you_recommend/). Please suggest a few vendors.",0,1
286,2019-11-28,2019,11,28,16,e2ukg2,Request for papers on deep learning based UAV.,https://www.reddit.com/r/deeplearning/comments/e2ukg2/request_for_papers_on_deep_learning_based_uav/,Dr_Samuel_Hayden,1574925829,"Hi, I've done some work on SLAM algorithms for UAV's in my bachelors. For my masters I want to make a deep learning based drone. I have implemented mono and stereo (inertial and non-inertial) algorithms for drones.

Can you guys please suggest me some papers for my project?",1,1
287,2019-11-28,2019,11,28,16,e2uw3e,GANs revolutionize Anti-Money Laundering  the revolution will not be supervised,https://www.reddit.com/r/deeplearning/comments/e2uw3e/gans_revolutionize_antimoney_laundering_the/,jpdowlin,1574927744,,0,1
288,2019-11-28,2019,11,28,19,e2w4bg,How to free up space in disk on Colab TPU?,https://www.reddit.com/r/deeplearning/comments/e2w4bg/how_to_free_up_space_in_disk_on_colab_tpu/,classyflyer,1574935800,"I am training a few deep learning models on Google Colab with runtime type set to TPU. The RAM and disk status shows that I have used most of my disk storage on Colab. Is there a way to reset it? Or to delete something to free up some more disk space? I know that I can change to GPU which will give me a lot more disk space, however, my models take forever to change, so I would really like to stay with TPU. Thanks in advance!",0,1
289,2019-11-28,2019,11,28,20,e2wt0w,Project ideas related to synthetic Music generation.,https://www.reddit.com/r/deeplearning/comments/e2wt0w/project_ideas_related_to_synthetic_music/,bikigoogler,1574940486,"I am reading a paper, [MuseGAN](https://arxiv.org/pdf/1709.06298.pdf) for generating music using GAN. I am searching for project ideas right now  related to synthetic Music generation. So please give me some hint(any ideas) what i can do.",0,1
290,2019-11-28,2019,11,28,21,e2x9r1,"Demonstrating American Sign Language Classification using Monk. Monk is an open-source low-code unified wrapper over major deep learning frameworks. Blog: http://bit.ly/sign_language_classification, Github: http://bit.ly/monk-github",https://www.reddit.com/r/deeplearning/comments/e2x9r1/demonstrating_american_sign_language/,abhishek4273,1574943405,,6,1
291,2019-11-28,2019,11,28,23,e2yx5o,"[Blog post]Introduction of Adversarial Examples Improve Image Recognition , ImageNet SOTA method using Adversarial Training",https://www.reddit.com/r/deeplearning/comments/e2yx5o/blog_postintroduction_of_adversarial_examples/,akira_AI,1574952335,,4,1
292,2019-11-28,2019,11,28,23,e2z166,can understand dataset of radiologist,https://www.reddit.com/r/deeplearning/comments/e2z166/can_understand_dataset_of_radiologist/,longkum,1574952878,[removed],0,1
293,2019-11-29,2019,11,29,4,e32t0m,"Herring, Not Herring: Deep Learning Accelerates Detection and Classification of Underwater Species",https://www.reddit.com/r/deeplearning/comments/e32t0m/herring_not_herring_deep_learning_accelerates/,Yuqing7,1574968919,,0,1
294,2019-11-29,2019,11,29,4,e32vtu,Show HN: Building websites from Sketch using deep learning  public launch,https://www.reddit.com/r/deeplearning/comments/e32vtu/show_hn_building_websites_from_sketch_using_deep/,HN_Crosspost_Bot,1574969236,,0,1
295,2019-11-29,2019,11,29,5,e33jyb,GitHub - kk7nc/Text_Classification: Text Classification Algorithms: A Survey,https://www.reddit.com/r/deeplearning/comments/e33jyb/github_kk7nctext_classification_text/,kk7nc,1574972020,,0,1
296,2019-11-29,2019,11,29,9,e374e8,Should I re-initialize my optimizer and my scheduler every time when I try to fine tune my neural network on a different dataset?,https://www.reddit.com/r/deeplearning/comments/e374e8/should_i_reinitialize_my_optimizer_and_my/,h56cho,1574988636,"Hello,

I am doing NLP, and I have this block of Transformer body that was already trained on dataset A.

Now I am interested in fine tuning this same Transformer on a new dataset B.

In my Python code, should I re-initialize my optimizer and my scheduler before I try to fine tune my neural network on the different dataset?

&amp;#x200B;

Thank you,",2,1
297,2019-11-29,2019,11,29,10,e37pf6,How to tackle a Person Re-Identification problem?,https://www.reddit.com/r/deeplearning/comments/e37pf6/how_to_tackle_a_person_reidentification_problem/,Sebasuraa,1574991649,"Hi, I need to solve a person re-id problem, where I will receive video from security cameras located in different aisles of a store (they don't overlap) and I have to measure how much time a every person spends in that aisle, count the people in it, etc. I imagine the hardest part is to identify the same person across ever camera, and I'm new to ML/DL, so I don't even know where to begin. I've read about ML and NN, I know a little bit about hyperparameters and I've watched 3brown1blue's videos on NNs, so I kind of get the basics, theoretically. I don't even need to build my own NN, I can use pre-trained models, but I don't know how to begin, what to learn first (pytorch, tensorflow, keras, opencv, etc), how should the pipeline of my program look like, etc. Any guidance, book recommendation, videotutorial would be appreciated. Thanks.",3,1
298,2019-11-29,2019,11,29,13,e39q9z,Creating a neural network for fire detection,https://www.reddit.com/r/deeplearning/comments/e39q9z/creating_a_neural_network_for_fire_detection/,PapaP123,1575002053,,2,1
299,2019-11-29,2019,11,29,15,e3aukg,anybody has work on medical image dataset?,https://www.reddit.com/r/deeplearning/comments/e3aukg/anybody_has_work_on_medical_image_dataset/,longkum,1575008430,[removed],0,1
300,2019-11-29,2019,11,29,18,e3cu3h,A list of Monte Carlo tree search research papers,https://www.reddit.com/r/deeplearning/comments/e3cu3h/a_list_of_monte_carlo_tree_search_research_papers/,benitorosenberg,1575021546,"&amp;#x200B;

![img](y9lb5vkyll141)

[https://github.com/benedekrozemberczki/awesome-monte-carlo-tree-search-papers](https://github.com/benedekrozemberczki/awesome-monte-carlo-tree-search-papers)

It was compiled in a semi-automated way and covers content from the following conferences:

* Machine learning
   * [NeurIPS](https://nips.cc/)
   * [ICML](https://icml.cc/)
* Computer vision
   * [CVPR](http://cvpr2019.thecvf.com/)
   * [ICCV](http://iccv2019.thecvf.com/)
* Natural language processing
   * [ACL](http://www.acl2019.org/EN/index.xhtml)
* Data
   * [KDD](https://www.kdd.org/)
* Artificial intelligence
   * [AAAI](https://www.aaai.org/)
   * [AISTATS](https://www.aistats.org/)
   * [IJCAI](https://www.ijcai.org/)
   * [UAI](http://www.auai.org/)",0,1
301,2019-11-29,2019,11,29,20,e3dmll,(Vanilla) Autoencoder generating zero and highly correlated latent space,https://www.reddit.com/r/deeplearning/comments/e3dmll/vanilla_autoencoder_generating_zero_and_highly/,joefromlondon,1575027119,"Hi all, 

I am building an autoencoder for mixed tabular data, essentially for dimensionality reduction to feed to a clustering algorithm (GMM/ k-means/ other). My data is a mixture of continuous and one hot encoded categorical data with around 450 features/ 1000 samples. 

I am reducing the dimension to 3-10 latent variables being passed though a slightly larger hidden layer, with the decoder the same shape (in reverse). I should note I am using Keras with TF backend.

I seem to be facing two problems. The first is that depending on the seed, some of the latent variables are all 0's. could this be because I have too many latent variables or two few? changing the number doesn't seem to remove this phenomenon. 

Another issue is that many of the latent variables are not orthogonal and in some cases highly correlated (Pearson &gt; 0.6). I understand that this isn't necessarily to be expected from an autoencoder as it is from PCA, but can it be rectified?

I am also considering using VAEs as opposed to AE but not completely seeing the benefits at the moment given my application. 

&amp;#x200B;

Any advice, previous experience with similar effects are very welcome. 

&amp;#x200B;

Thanks!",2,1
302,2019-11-29,2019,11,29,21,e3e29x,Basic Image Classification in Tensorflow 2.0,https://www.reddit.com/r/deeplearning/comments/e3e29x/basic_image_classification_in_tensorflow_20/,dasaradhsk,1575030006,,0,1
303,2019-11-29,2019,11,29,22,e3emm5,Swift for TensorFlow [SUBREDDIT],https://www.reddit.com/r/deeplearning/comments/e3emm5/swift_for_tensorflow_subreddit/,rahulbhalley,1575033476,,0,1
304,2019-11-29,2019,11,29,22,e3ezan,Human Action Recognition with Mixed 3D/2D Convolutional Tube Networks (MiCT-Net),https://www.reddit.com/r/deeplearning/comments/e3ezan/human_action_recognition_with_mixed_3d2d/,Fanos6,1575035437,"&amp;#x200B;

[The MiCT-ResNet-18 architecture for action recognition.](https://preview.redd.it/rq4mk6ajqm141.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=894357b02ea51a5dda850a43d75c0f2b449379dd)

Mixed 3D/2D Convolutional Tubes (MiCT) have been proposed by [Microsoft Research](https://www.microsoft.com/en-us/research/uploads/prod/2018/05/Zhou_MiCT_Mixed_3D2D_CVPR_2018_paper.pdf) to improve Human Action Recognition. The key principle is the introduction of a limited number of 3D residual convolutions at select locations of a 2D-CNN backbone pre-trained on ImageNet. The 3D convolution branches learn residual temporal features, which are the motions of objects and persons, while the 2D backbone learns spatial features and generates deeper and more informative feature representations after each spatio-temporal fusion.  

This [repository](https://github.com/fmahoudeau/MiCT-Net-PyTorch) provides a PyTorch implementation of the MiCT-Net architecture using a ResNet backbone and validates the authors approach for small data sets (namely UCF-101) by comparing its performance with a 3D-ResNet. Let me know your comments.",0,1
305,2019-11-29,2019,11,29,23,e3fe8q,How to check output names from a neuron?,https://www.reddit.com/r/deeplearning/comments/e3fe8q/how_to_check_output_names_from_a_neuron/,Betaji2,1575037654,Hi how would I check the output names from a neuron in a SDD? Also could I get the bounding boxes from this as well or is their something else I need to do?,1,1
306,2019-11-30,2019,11,30,0,e3fwqt,ML Paper Notes: My notes of various ML research papers (DL - CV - NLP),https://www.reddit.com/r/deeplearning/comments/e3fwqt/ml_paper_notes_my_notes_of_various_ml_research/,youali,1575040270,"Hello,

As a PhD student, I read quite a lot of papers, and sometimes I make short summaries with a simple latex template to get a better understanding and have clearer idea of the paper's contributions. For a while I stored them in private Github repo, so I tought why note share them, some people might find them helpful.

PS: Sorry for the (sometimes frequent) spelling mistakes.

Here is the Github link: https://github.com/yassouali/ML_paper_notes",4,1
307,2019-11-30,2019,11,30,2,e3hytg,News Update: Deep Learning Ecosystem,https://www.reddit.com/r/deeplearning/comments/e3hytg/news_update_deep_learning_ecosystem/,surkin143,1575049415,"In terms of investments in the field of artificial intelligence &amp; [deep learning ecosystem](https://www.alltheresearch.com/report/312/global-deep-learning-ecosystem-market), the U.S. has overtaken China to grab the topmost spot as a venture capital investment hub. The U.S. attracted the most investment in 2018, accounting for more than 50% of total investments in AI and Deep Learning ecosystem across the globe.  

For more info Click on the link below:

 [https://www.alltheresearch.com/report/312/global-deep-learning-ecosystem-market](https://www.alltheresearch.com/report/312/global-deep-learning-ecosystem-market)",0,1
308,2019-11-30,2019,11,30,3,e3ibiq,Deep Learning Ecosystem Major Interconnectivity,https://www.reddit.com/r/deeplearning/comments/e3ibiq/deep_learning_ecosystem_major_interconnectivity/,surkin143,1575050907,"[**Deep Learning Ecosystem**](https://www.alltheresearch.com/report/312/global-deep-learning-ecosystem-market)

&amp;#x200B;

https://preview.redd.it/20trhwkg1o141.png?width=1167&amp;format=png&amp;auto=webp&amp;s=a6b16e1ce6cac534da63409c0bc9924663e890c1",0,1
309,2019-11-30,2019,11,30,5,e3k8c7,5700 xt in Tensor Flow and Pytorch.,https://www.reddit.com/r/deeplearning/comments/e3k8c7/5700_xt_in_tensor_flow_and_pytorch/,Grek27,1575058730,"Has there been succesfull and smooth integration of the 5700 xt into the Deep Learning frameworks?

CUDA is the popular thing right now and I haven't found a straightforward answer on how to use the 5700s as general compute units but I thought I would check one more time before dropping money on a 2080.",5,1
310,2019-11-30,2019,11,30,7,e3m3jv,Weekly Papers | Multi-Label Deep Forest (MLDF); Huawei UK Critiques DeepMind -Rank,https://www.reddit.com/r/deeplearning/comments/e3m3jv/weekly_papers_multilabel_deep_forest_mldf_huawei/,Yuqing7,1575066243,,0,1
311,2019-11-30,2019,11,30,7,e3mfnk,Tensorbord - connect local with remote machine and run tensorboard from local machine,https://www.reddit.com/r/deeplearning/comments/e3mfnk/tensorbord_connect_local_with_remote_machine_and/,TrustAnonymity,1575067585,"I have logfiles on remote machine and want to run tensorboard from local machine to run files on remote machine.

Please help, thanks.",4,1
312,2019-11-30,2019,11,30,11,e3peko,New to ML. Useful to start reading papers?,https://www.reddit.com/r/deeplearning/comments/e3peko/new_to_ml_useful_to_start_reading_papers/,Jaszunai,1575081560,I've been taking an ML course and feel confident enough to start working on personal projects. At what point is it a good idea to start reading papers to stay up-to-date on developments in the field?,2,1
313,2019-11-30,2019,11,30,16,e3sql4,"Here is a project ""Dlearn"" a human emotion recognition based learning assistant. This is a product of this year's HACKOH/IO . Please let me know your thoughts!",https://www.reddit.com/r/deeplearning/comments/e3sql4/here_is_a_project_dlearn_a_human_emotion/,iamstark07,1575100154,,3,1
